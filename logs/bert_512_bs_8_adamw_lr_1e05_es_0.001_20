2021-11-21 17:14:44,585 => 1.9.1+cu102
2021-11-21 17:14:44,673 => cuda
2021-11-21 17:14:45,132 => loading file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-cased-vocab.txt from cache at /home/yinan/.cache/torch/transformers/5e8a2b4893d13790ed4150ca1906be5f7a03d6c4ddf62296c383f6db42814db2.e13dbb970cb325137104fb2e5f36fe865f27746c6b526f6352861b1980eb80b1
2021-11-21 17:15:00,289 => -------------------------------------------------
2021-11-21 17:15:00,290 => 1 FOLD
2021-11-21 17:15:00,711 => loading configuration file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-cased-config.json from cache at /home/yinan/.cache/torch/transformers/b945b69218e98b3e2c95acf911789741307dec43c698d35fad11c1ae28bda352.9da767be51e1327499df13488672789394e2ca38b877837e52618a67d7002391
2021-11-21 17:15:00,712 => Model config BertConfig {
  "architectures": [
    "BertForMaskedLM"
  ],
  "attention_probs_dropout_prob": 0.1,
  "bos_token_id": null,
  "do_sample": false,
  "eos_token_ids": null,
  "finetuning_task": null,
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "hidden_size": 768,
  "id2label": {
    "0": "LABEL_0",
    "1": "LABEL_1"
  },
  "initializer_range": 0.02,
  "intermediate_size": 3072,
  "is_decoder": false,
  "label2id": {
    "LABEL_0": 0,
    "LABEL_1": 1
  },
  "layer_norm_eps": 1e-12,
  "length_penalty": 1.0,
  "max_length": 20,
  "max_position_embeddings": 512,
  "model_type": "bert",
  "num_attention_heads": 12,
  "num_beams": 1,
  "num_hidden_layers": 12,
  "num_labels": 4,
  "num_return_sequences": 1,
  "output_attentions": false,
  "output_hidden_states": false,
  "output_past": true,
  "pad_token_id": 0,
  "pruned_heads": {},
  "repetition_penalty": 1.0,
  "temperature": 1.0,
  "top_k": 50,
  "top_p": 1.0,
  "torchscript": false,
  "type_vocab_size": 2,
  "use_bfloat16": false,
  "vocab_size": 28996
}

2021-11-21 17:15:01,121 => loading weights file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-cased-pytorch_model.bin from cache at /home/yinan/.cache/torch/transformers/35d8b9d36faaf46728a0192d82bf7d00137490cd6074e8500778afed552a67e5.3fadbea36527ae472139fe84cddaa65454d7429f12d543d80bfc3ad70de55ac2
2021-11-21 17:15:04,898 => Weights of BertForSequenceClassification not initialized from pretrained model: ['classifier.weight', 'classifier.bias']
2021-11-21 17:15:04,898 => Weights from pretrained model not used in BertForSequenceClassification: ['cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias']
2021-11-21 17:16:07,903 => Train: 100.0	Epoch: 1	Iter: 158	Loss: 0.14413	Acc= 49.092	Precision= 52.725	Recall= 48.936	F1_score= 49.008
2021-11-21 17:17:06,516 => Train: 100.0	Epoch: 2	Iter: 158	Loss: 0.06297	Acc= 84.057	Precision= 84.129	Recall= 83.980	F1_score= 83.996
2021-11-21 17:18:05,130 => Train: 100.0	Epoch: 3	Iter: 158	Loss: 0.02543	Acc= 94.633	Precision= 94.637	Recall= 94.623	F1_score= 94.623
2021-11-21 17:19:03,746 => Train: 100.0	Epoch: 4	Iter: 158	Loss: 0.01073	Acc= 98.737	Precision= 98.746	Recall= 98.732	F1_score= 98.738
2021-11-21 17:20:02,337 => Train: 100.0	Epoch: 5	Iter: 158	Loss: 0.00556	Acc= 99.526	Precision= 99.528	Recall= 99.529	F1_score= 99.528
2021-11-21 17:21:00,969 => Train: 100.0	Epoch: 6	Iter: 158	Loss: 0.00382	Acc= 99.684	Precision= 99.686	Recall= 99.686	F1_score= 99.686
2021-11-21 17:21:59,608 => Train: 100.0	Epoch: 7	Iter: 158	Loss: 0.00311	Acc= 99.763	Precision= 99.761	Recall= 99.765	F1_score= 99.763
2021-11-21 17:22:58,174 => Train: 100.0	Epoch: 8	Iter: 158	Loss: 0.00288	Acc= 99.605	Precision= 99.604	Recall= 99.607	F1_score= 99.605
2021-11-21 17:23:56,816 => Train: 100.0	Epoch: 9	Iter: 158	Loss: 0.00225	Acc= 99.763	Precision= 99.766	Recall= 99.765	F1_score= 99.765
2021-11-21 17:24:55,441 => Train: 100.0	Epoch: 10	Iter: 158	Loss: 0.00185	Acc= 99.842	Precision= 99.843	Recall= 99.843	F1_score= 99.843
2021-11-21 17:25:54,004 => Train: 100.0	Epoch: 11	Iter: 158	Loss: 0.00151	Acc= 99.842	Precision= 99.843	Recall= 99.843	F1_score= 99.843
2021-11-21 17:26:52,669 => Train: 100.0	Epoch: 12	Iter: 158	Loss: 0.00133	Acc= 99.921	Precision= 99.922	Recall= 99.921	F1_score= 99.921
2021-11-21 17:27:51,287 => Train: 100.0	Epoch: 13	Iter: 158	Loss: 0.00112	Acc= 99.921	Precision= 99.922	Recall= 99.921	F1_score= 99.921
2021-11-21 17:28:49,874 => Train: 100.0	Epoch: 14	Iter: 158	Loss: 0.00108	Acc= 99.921	Precision= 99.922	Recall= 99.921	F1_score= 99.921
2021-11-21 17:29:48,515 => Train: 100.0	Epoch: 15	Iter: 158	Loss: 0.00080	Acc= 99.921	Precision= 99.922	Recall= 99.921	F1_score= 99.921
2021-11-21 17:29:48,517 => Epoch: 15	early stopped at loss: 0.00080
2021-11-21 17:29:52,032 => Eval: 100.0	Epoch: 15	Iter: 39	Loss: 0.04369	Acc= 93.375	Precision= 93.421	Recall= 93.429	F1_score= 93.405
2021-11-21 17:29:52,033 => -------------------------------------------------
2021-11-21 17:29:52,033 => 2 FOLD
2021-11-21 17:29:52,474 => loading configuration file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-cased-config.json from cache at /home/yinan/.cache/torch/transformers/b945b69218e98b3e2c95acf911789741307dec43c698d35fad11c1ae28bda352.9da767be51e1327499df13488672789394e2ca38b877837e52618a67d7002391
2021-11-21 17:29:52,475 => Model config BertConfig {
  "architectures": [
    "BertForMaskedLM"
  ],
  "attention_probs_dropout_prob": 0.1,
  "bos_token_id": null,
  "do_sample": false,
  "eos_token_ids": null,
  "finetuning_task": null,
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "hidden_size": 768,
  "id2label": {
    "0": "LABEL_0",
    "1": "LABEL_1"
  },
  "initializer_range": 0.02,
  "intermediate_size": 3072,
  "is_decoder": false,
  "label2id": {
    "LABEL_0": 0,
    "LABEL_1": 1
  },
  "layer_norm_eps": 1e-12,
  "length_penalty": 1.0,
  "max_length": 20,
  "max_position_embeddings": 512,
  "model_type": "bert",
  "num_attention_heads": 12,
  "num_beams": 1,
  "num_hidden_layers": 12,
  "num_labels": 4,
  "num_return_sequences": 1,
  "output_attentions": false,
  "output_hidden_states": false,
  "output_past": true,
  "pad_token_id": 0,
  "pruned_heads": {},
  "repetition_penalty": 1.0,
  "temperature": 1.0,
  "top_k": 50,
  "top_p": 1.0,
  "torchscript": false,
  "type_vocab_size": 2,
  "use_bfloat16": false,
  "vocab_size": 28996
}

2021-11-21 17:29:52,898 => loading weights file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-cased-pytorch_model.bin from cache at /home/yinan/.cache/torch/transformers/35d8b9d36faaf46728a0192d82bf7d00137490cd6074e8500778afed552a67e5.3fadbea36527ae472139fe84cddaa65454d7429f12d543d80bfc3ad70de55ac2
2021-11-21 17:29:56,660 => Weights of BertForSequenceClassification not initialized from pretrained model: ['classifier.weight', 'classifier.bias']
2021-11-21 17:29:56,661 => Weights from pretrained model not used in BertForSequenceClassification: ['cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias']
2021-11-21 17:30:55,024 => Train: 100.0	Epoch: 1	Iter: 158	Loss: 0.15170	Acc= 45.620	Precision= 46.600	Recall= 45.246	F1_score= 44.874
2021-11-21 17:31:53,240 => Train: 100.0	Epoch: 2	Iter: 158	Loss: 0.08719	Acc= 75.533	Precision= 76.398	Recall= 75.367	F1_score= 75.293
2021-11-21 17:32:51,509 => Train: 100.0	Epoch: 3	Iter: 158	Loss: 0.04327	Acc= 90.529	Precision= 90.544	Recall= 90.547	F1_score= 90.511
2021-11-21 17:33:49,778 => Train: 100.0	Epoch: 4	Iter: 158	Loss: 0.02035	Acc= 96.369	Precision= 96.350	Recall= 96.379	F1_score= 96.354
2021-11-21 17:34:47,976 => Train: 100.0	Epoch: 5	Iter: 158	Loss: 0.01050	Acc= 98.500	Precision= 98.492	Recall= 98.501	F1_score= 98.496
2021-11-21 17:35:46,248 => Train: 100.0	Epoch: 6	Iter: 158	Loss: 0.00657	Acc= 99.132	Precision= 99.127	Recall= 99.138	F1_score= 99.132
2021-11-21 17:36:44,529 => Train: 100.0	Epoch: 7	Iter: 158	Loss: 0.00453	Acc= 99.526	Precision= 99.522	Recall= 99.529	F1_score= 99.525
2021-11-21 17:37:42,743 => Train: 100.0	Epoch: 8	Iter: 158	Loss: 0.00293	Acc= 99.763	Precision= 99.760	Recall= 99.766	F1_score= 99.763
2021-11-21 17:38:40,996 => Train: 100.0	Epoch: 9	Iter: 158	Loss: 0.00202	Acc= 99.921	Precision= 99.918	Recall= 99.924	F1_score= 99.921
2021-11-21 17:39:39,266 => Train: 100.0	Epoch: 10	Iter: 158	Loss: 0.00147	Acc= 99.921	Precision= 99.918	Recall= 99.924	F1_score= 99.921
2021-11-21 17:40:37,480 => Train: 100.0	Epoch: 11	Iter: 158	Loss: 0.00129	Acc= 99.921	Precision= 99.921	Recall= 99.924	F1_score= 99.922
2021-11-21 17:41:35,744 => Train: 100.0	Epoch: 12	Iter: 158	Loss: 0.00113	Acc= 99.921	Precision= 99.918	Recall= 99.924	F1_score= 99.921
2021-11-21 17:42:34,102 => Train: 100.0	Epoch: 13	Iter: 158	Loss: 0.00092	Acc= 99.921	Precision= 99.921	Recall= 99.924	F1_score= 99.922
2021-11-21 17:42:34,103 => Epoch: 13	early stopped at loss: 0.00092
2021-11-21 17:42:37,557 => Eval: 100.0	Epoch: 13	Iter: 39	Loss: 0.03009	Acc= 93.060	Precision= 93.067	Recall= 93.348	F1_score= 93.029
2021-11-21 17:42:37,557 => -------------------------------------------------
2021-11-21 17:42:37,557 => 3 FOLD
2021-11-21 17:42:38,004 => loading configuration file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-cased-config.json from cache at /home/yinan/.cache/torch/transformers/b945b69218e98b3e2c95acf911789741307dec43c698d35fad11c1ae28bda352.9da767be51e1327499df13488672789394e2ca38b877837e52618a67d7002391
2021-11-21 17:42:38,005 => Model config BertConfig {
  "architectures": [
    "BertForMaskedLM"
  ],
  "attention_probs_dropout_prob": 0.1,
  "bos_token_id": null,
  "do_sample": false,
  "eos_token_ids": null,
  "finetuning_task": null,
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "hidden_size": 768,
  "id2label": {
    "0": "LABEL_0",
    "1": "LABEL_1"
  },
  "initializer_range": 0.02,
  "intermediate_size": 3072,
  "is_decoder": false,
  "label2id": {
    "LABEL_0": 0,
    "LABEL_1": 1
  },
  "layer_norm_eps": 1e-12,
  "length_penalty": 1.0,
  "max_length": 20,
  "max_position_embeddings": 512,
  "model_type": "bert",
  "num_attention_heads": 12,
  "num_beams": 1,
  "num_hidden_layers": 12,
  "num_labels": 4,
  "num_return_sequences": 1,
  "output_attentions": false,
  "output_hidden_states": false,
  "output_past": true,
  "pad_token_id": 0,
  "pruned_heads": {},
  "repetition_penalty": 1.0,
  "temperature": 1.0,
  "top_k": 50,
  "top_p": 1.0,
  "torchscript": false,
  "type_vocab_size": 2,
  "use_bfloat16": false,
  "vocab_size": 28996
}

2021-11-21 17:42:38,435 => loading weights file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-cased-pytorch_model.bin from cache at /home/yinan/.cache/torch/transformers/35d8b9d36faaf46728a0192d82bf7d00137490cd6074e8500778afed552a67e5.3fadbea36527ae472139fe84cddaa65454d7429f12d543d80bfc3ad70de55ac2
2021-11-21 17:42:42,202 => Weights of BertForSequenceClassification not initialized from pretrained model: ['classifier.weight', 'classifier.bias']
2021-11-21 17:42:42,203 => Weights from pretrained model not used in BertForSequenceClassification: ['cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias']
2021-11-21 17:43:40,690 => Train: 100.0	Epoch: 1	Iter: 158	Loss: 0.16438	Acc= 35.912	Precision= 41.226	Recall= 35.705	F1_score= 35.724
2021-11-21 17:44:39,138 => Train: 100.0	Epoch: 2	Iter: 158	Loss: 0.10984	Acc= 67.167	Precision= 67.682	Recall= 67.212	F1_score= 67.277
2021-11-21 17:45:37,554 => Train: 100.0	Epoch: 3	Iter: 158	Loss: 0.05552	Acc= 84.688	Precision= 84.803	Recall= 84.655	F1_score= 84.690
2021-11-21 17:46:35,918 => Train: 100.0	Epoch: 4	Iter: 158	Loss: 0.02442	Acc= 94.712	Precision= 94.730	Recall= 94.697	F1_score= 94.707
2021-11-21 17:47:34,381 => Train: 100.0	Epoch: 5	Iter: 158	Loss: 0.01046	Acc= 98.579	Precision= 98.582	Recall= 98.581	F1_score= 98.581
2021-11-21 17:48:32,838 => Train: 100.0	Epoch: 6	Iter: 158	Loss: 0.00553	Acc= 99.369	Precision= 99.366	Recall= 99.369	F1_score= 99.367
2021-11-21 17:49:31,188 => Train: 100.0	Epoch: 7	Iter: 158	Loss: 0.00341	Acc= 99.763	Precision= 99.760	Recall= 99.764	F1_score= 99.762
2021-11-21 17:50:29,615 => Train: 100.0	Epoch: 8	Iter: 158	Loss: 0.00223	Acc= 99.842	Precision= 99.839	Recall= 99.844	F1_score= 99.841
2021-11-21 17:51:28,011 => Train: 100.0	Epoch: 9	Iter: 158	Loss: 0.00165	Acc= 99.921	Precision= 99.919	Recall= 99.920	F1_score= 99.919
2021-11-21 17:52:26,371 => Train: 100.0	Epoch: 10	Iter: 158	Loss: 0.00145	Acc= 99.921	Precision= 99.919	Recall= 99.920	F1_score= 99.919
2021-11-21 17:53:24,777 => Train: 100.0	Epoch: 11	Iter: 158	Loss: 0.00127	Acc= 99.921	Precision= 99.919	Recall= 99.920	F1_score= 99.919
2021-11-21 17:54:23,164 => Train: 100.0	Epoch: 12	Iter: 158	Loss: 0.00112	Acc= 99.921	Precision= 99.919	Recall= 99.920	F1_score= 99.919
2021-11-21 17:55:21,538 => Train: 100.0	Epoch: 13	Iter: 158	Loss: 0.00102	Acc= 99.921	Precision= 99.919	Recall= 99.920	F1_score= 99.919
2021-11-21 17:56:19,915 => Train: 100.0	Epoch: 14	Iter: 158	Loss: 0.00096	Acc= 99.921	Precision= 99.919	Recall= 99.920	F1_score= 99.919
2021-11-21 17:56:19,930 => Epoch: 14	early stopped at loss: 0.00096
2021-11-21 17:56:23,390 => Eval: 100.0	Epoch: 14	Iter: 39	Loss: 0.03992	Acc= 92.429	Precision= 92.379	Recall= 92.329	F1_score= 92.349
2021-11-21 17:56:23,390 => -------------------------------------------------
2021-11-21 17:56:23,391 => 4 FOLD
2021-11-21 17:56:23,814 => loading configuration file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-cased-config.json from cache at /home/yinan/.cache/torch/transformers/b945b69218e98b3e2c95acf911789741307dec43c698d35fad11c1ae28bda352.9da767be51e1327499df13488672789394e2ca38b877837e52618a67d7002391
2021-11-21 17:56:23,815 => Model config BertConfig {
  "architectures": [
    "BertForMaskedLM"
  ],
  "attention_probs_dropout_prob": 0.1,
  "bos_token_id": null,
  "do_sample": false,
  "eos_token_ids": null,
  "finetuning_task": null,
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "hidden_size": 768,
  "id2label": {
    "0": "LABEL_0",
    "1": "LABEL_1"
  },
  "initializer_range": 0.02,
  "intermediate_size": 3072,
  "is_decoder": false,
  "label2id": {
    "LABEL_0": 0,
    "LABEL_1": 1
  },
  "layer_norm_eps": 1e-12,
  "length_penalty": 1.0,
  "max_length": 20,
  "max_position_embeddings": 512,
  "model_type": "bert",
  "num_attention_heads": 12,
  "num_beams": 1,
  "num_hidden_layers": 12,
  "num_labels": 4,
  "num_return_sequences": 1,
  "output_attentions": false,
  "output_hidden_states": false,
  "output_past": true,
  "pad_token_id": 0,
  "pruned_heads": {},
  "repetition_penalty": 1.0,
  "temperature": 1.0,
  "top_k": 50,
  "top_p": 1.0,
  "torchscript": false,
  "type_vocab_size": 2,
  "use_bfloat16": false,
  "vocab_size": 28996
}

2021-11-21 17:56:24,247 => loading weights file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-cased-pytorch_model.bin from cache at /home/yinan/.cache/torch/transformers/35d8b9d36faaf46728a0192d82bf7d00137490cd6074e8500778afed552a67e5.3fadbea36527ae472139fe84cddaa65454d7429f12d543d80bfc3ad70de55ac2
2021-11-21 17:56:28,002 => Weights of BertForSequenceClassification not initialized from pretrained model: ['classifier.weight', 'classifier.bias']
2021-11-21 17:56:28,002 => Weights from pretrained model not used in BertForSequenceClassification: ['cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias']
2021-11-21 17:57:26,644 => Train: 100.0	Epoch: 1	Iter: 158	Loss: 0.16082	Acc= 39.621	Precision= 42.252	Recall= 38.961	F1_score= 38.449
2021-11-21 17:58:25,143 => Train: 100.0	Epoch: 2	Iter: 158	Loss: 0.09658	Acc= 72.376	Precision= 73.329	Recall= 72.118	F1_score= 72.129
2021-11-21 17:59:23,659 => Train: 100.0	Epoch: 3	Iter: 158	Loss: 0.04472	Acc= 89.897	Precision= 90.034	Recall= 89.857	F1_score= 89.887
2021-11-21 18:00:22,188 => Train: 100.0	Epoch: 4	Iter: 158	Loss: 0.01999	Acc= 96.527	Precision= 96.532	Recall= 96.532	F1_score= 96.523
2021-11-21 18:01:20,675 => Train: 100.0	Epoch: 5	Iter: 158	Loss: 0.00938	Acc= 99.132	Precision= 99.151	Recall= 99.133	F1_score= 99.140
2021-11-21 18:02:19,192 => Train: 100.0	Epoch: 6	Iter: 158	Loss: 0.00626	Acc= 99.448	Precision= 99.459	Recall= 99.434	F1_score= 99.446
2021-11-21 18:03:17,698 => Train: 100.0	Epoch: 7	Iter: 158	Loss: 0.00485	Acc= 99.605	Precision= 99.602	Recall= 99.601	F1_score= 99.600
2021-11-21 18:04:16,204 => Train: 100.0	Epoch: 8	Iter: 158	Loss: 0.00319	Acc= 99.763	Precision= 99.764	Recall= 99.756	F1_score= 99.760
2021-11-21 18:05:14,718 => Train: 100.0	Epoch: 9	Iter: 158	Loss: 0.00260	Acc= 99.842	Precision= 99.837	Recall= 99.837	F1_score= 99.837
2021-11-21 18:06:13,218 => Train: 100.0	Epoch: 10	Iter: 158	Loss: 0.00178	Acc= 99.921	Precision= 99.916	Recall= 99.921	F1_score= 99.918
2021-11-21 18:07:11,716 => Train: 100.0	Epoch: 11	Iter: 158	Loss: 0.00153	Acc= 99.921	Precision= 99.916	Recall= 99.921	F1_score= 99.918
2021-11-21 18:08:10,224 => Train: 100.0	Epoch: 12	Iter: 158	Loss: 0.00142	Acc= 99.921	Precision= 99.916	Recall= 99.921	F1_score= 99.918
2021-11-21 18:09:08,716 => Train: 100.0	Epoch: 13	Iter: 158	Loss: 0.00116	Acc= 99.921	Precision= 99.916	Recall= 99.921	F1_score= 99.918
2021-11-21 18:10:07,228 => Train: 100.0	Epoch: 14	Iter: 158	Loss: 0.00110	Acc= 99.921	Precision= 99.916	Recall= 99.921	F1_score= 99.918
2021-11-21 18:11:05,741 => Train: 100.0	Epoch: 15	Iter: 158	Loss: 0.00102	Acc= 99.921	Precision= 99.916	Recall= 99.921	F1_score= 99.918
2021-11-21 18:12:04,216 => Train: 100.0	Epoch: 16	Iter: 158	Loss: 0.00095	Acc= 99.921	Precision= 99.916	Recall= 99.921	F1_score= 99.918
2021-11-21 18:12:04,217 => Epoch: 16	early stopped at loss: 0.00095
2021-11-21 18:12:07,729 => Eval: 100.0	Epoch: 16	Iter: 39	Loss: 0.04212	Acc= 91.167	Precision= 91.170	Recall= 91.511	F1_score= 91.311
2021-11-21 18:12:07,730 => -------------------------------------------------
2021-11-21 18:12:07,730 => 5 FOLD
2021-11-21 18:12:08,172 => loading configuration file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-cased-config.json from cache at /home/yinan/.cache/torch/transformers/b945b69218e98b3e2c95acf911789741307dec43c698d35fad11c1ae28bda352.9da767be51e1327499df13488672789394e2ca38b877837e52618a67d7002391
2021-11-21 18:12:08,173 => Model config BertConfig {
  "architectures": [
    "BertForMaskedLM"
  ],
  "attention_probs_dropout_prob": 0.1,
  "bos_token_id": null,
  "do_sample": false,
  "eos_token_ids": null,
  "finetuning_task": null,
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "hidden_size": 768,
  "id2label": {
    "0": "LABEL_0",
    "1": "LABEL_1"
  },
  "initializer_range": 0.02,
  "intermediate_size": 3072,
  "is_decoder": false,
  "label2id": {
    "LABEL_0": 0,
    "LABEL_1": 1
  },
  "layer_norm_eps": 1e-12,
  "length_penalty": 1.0,
  "max_length": 20,
  "max_position_embeddings": 512,
  "model_type": "bert",
  "num_attention_heads": 12,
  "num_beams": 1,
  "num_hidden_layers": 12,
  "num_labels": 4,
  "num_return_sequences": 1,
  "output_attentions": false,
  "output_hidden_states": false,
  "output_past": true,
  "pad_token_id": 0,
  "pruned_heads": {},
  "repetition_penalty": 1.0,
  "temperature": 1.0,
  "top_k": 50,
  "top_p": 1.0,
  "torchscript": false,
  "type_vocab_size": 2,
  "use_bfloat16": false,
  "vocab_size": 28996
}

2021-11-21 18:12:08,603 => loading weights file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-cased-pytorch_model.bin from cache at /home/yinan/.cache/torch/transformers/35d8b9d36faaf46728a0192d82bf7d00137490cd6074e8500778afed552a67e5.3fadbea36527ae472139fe84cddaa65454d7429f12d543d80bfc3ad70de55ac2
2021-11-21 18:12:12,367 => Weights of BertForSequenceClassification not initialized from pretrained model: ['classifier.weight', 'classifier.bias']
2021-11-21 18:12:12,367 => Weights from pretrained model not used in BertForSequenceClassification: ['cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias']
2021-11-21 18:13:11,059 => Train: 100.0	Epoch: 1	Iter: 158	Loss: 0.14782	Acc= 48.344	Precision= 49.274	Recall= 48.213	F1_score= 47.854
2021-11-21 18:14:09,695 => Train: 100.0	Epoch: 2	Iter: 158	Loss: 0.07642	Acc= 79.653	Precision= 80.108	Recall= 79.561	F1_score= 79.567
2021-11-21 18:15:08,326 => Train: 100.0	Epoch: 3	Iter: 158	Loss: 0.03185	Acc= 92.035	Precision= 92.091	Recall= 92.013	F1_score= 92.033
2021-11-21 18:16:06,883 => Train: 100.0	Epoch: 4	Iter: 158	Loss: 0.01443	Acc= 97.161	Precision= 97.163	Recall= 97.157	F1_score= 97.157
2021-11-21 18:17:05,492 => Train: 100.0	Epoch: 5	Iter: 158	Loss: 0.00728	Acc= 98.738	Precision= 98.737	Recall= 98.739	F1_score= 98.737
2021-11-21 18:18:04,117 => Train: 100.0	Epoch: 6	Iter: 158	Loss: 0.00424	Acc= 99.448	Precision= 99.446	Recall= 99.448	F1_score= 99.447
2021-11-21 18:19:02,719 => Train: 100.0	Epoch: 7	Iter: 158	Loss: 0.00255	Acc= 99.842	Precision= 99.841	Recall= 99.842	F1_score= 99.841
2021-11-21 18:20:01,324 => Train: 100.0	Epoch: 8	Iter: 158	Loss: 0.00194	Acc= 99.842	Precision= 99.841	Recall= 99.842	F1_score= 99.841
2021-11-21 18:20:59,857 => Train: 100.0	Epoch: 9	Iter: 158	Loss: 0.00176	Acc= 99.842	Precision= 99.841	Recall= 99.842	F1_score= 99.841
2021-11-21 18:21:58,486 => Train: 100.0	Epoch: 10	Iter: 158	Loss: 0.00138	Acc= 99.842	Precision= 99.842	Recall= 99.842	F1_score= 99.842
2021-11-21 18:22:57,104 => Train: 100.0	Epoch: 11	Iter: 158	Loss: 0.00097	Acc= 100.000	Precision= 100.000	Recall= 100.000	F1_score= 100.000
2021-11-21 18:22:57,106 => Epoch: 11	early stopped at loss: 0.00097
2021-11-21 18:23:00,561 => Eval: 100.0	Epoch: 11	Iter: 39	Loss: 0.04861	Acc= 88.924	Precision= 89.197	Recall= 88.803	F1_score= 88.896
2021-11-21 18:23:00,561 => AVERAGE ACCURACY: 91.791
