2021-12-26 14:38:40,669 => 1.9.1+cu102
2021-12-26 14:38:40,670 => cuda
2021-12-26 14:38:41,091 => loading file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-cased-vocab.txt from cache at /home/yinan/.cache/torch/transformers/5e8a2b4893d13790ed4150ca1906be5f7a03d6c4ddf62296c383f6db42814db2.e13dbb970cb325137104fb2e5f36fe865f27746c6b526f6352861b1980eb80b1
2021-12-26 14:38:56,300 => -------------------------------------------------
2021-12-26 14:38:56,300 => 1 FOLD
2021-12-26 14:39:00,978 => loading configuration file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-cased-config.json from cache at /home/yinan/.cache/torch/transformers/b945b69218e98b3e2c95acf911789741307dec43c698d35fad11c1ae28bda352.9da767be51e1327499df13488672789394e2ca38b877837e52618a67d7002391
2021-12-26 14:39:00,979 => Model config BertConfig {
  "architectures": [
    "BertForMaskedLM"
  ],
  "attention_probs_dropout_prob": 0.1,
  "bos_token_id": null,
  "do_sample": false,
  "eos_token_ids": null,
  "finetuning_task": null,
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "hidden_size": 768,
  "id2label": {
    "0": "LABEL_0",
    "1": "LABEL_1"
  },
  "initializer_range": 0.02,
  "intermediate_size": 3072,
  "is_decoder": false,
  "label2id": {
    "LABEL_0": 0,
    "LABEL_1": 1
  },
  "layer_norm_eps": 1e-12,
  "length_penalty": 1.0,
  "max_length": 20,
  "max_position_embeddings": 512,
  "model_type": "bert",
  "num_attention_heads": 12,
  "num_beams": 1,
  "num_hidden_layers": 12,
  "num_labels": 4,
  "num_return_sequences": 1,
  "output_attentions": false,
  "output_hidden_states": false,
  "output_past": true,
  "pad_token_id": 0,
  "pruned_heads": {},
  "repetition_penalty": 1.0,
  "temperature": 1.0,
  "top_k": 50,
  "top_p": 1.0,
  "torchscript": false,
  "type_vocab_size": 2,
  "use_bfloat16": false,
  "vocab_size": 28996
}

2021-12-26 14:39:01,307 => loading weights file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-cased-pytorch_model.bin from cache at /home/yinan/.cache/torch/transformers/35d8b9d36faaf46728a0192d82bf7d00137490cd6074e8500778afed552a67e5.3fadbea36527ae472139fe84cddaa65454d7429f12d543d80bfc3ad70de55ac2
2021-12-26 14:39:05,737 => Weights of BertForSequenceClassification not initialized from pretrained model: ['classifier.weight', 'classifier.bias']
2021-12-26 14:39:05,737 => Weights from pretrained model not used in BertForSequenceClassification: ['cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias']
2021-12-26 14:40:13,608 => Train: 100.0	Epoch: 1	Iter: 158	Loss: 0.14629	Acc= 47.435	Precision= 49.265	Recall= 47.246	F1_score= 47.239
2021-12-26 14:41:13,105 => Train: 100.0	Epoch: 2	Iter: 158	Loss: 0.06301	Acc= 83.741	Precision= 83.809	Recall= 83.677	F1_score= 83.703
2021-12-26 14:42:12,566 => Train: 100.0	Epoch: 3	Iter: 158	Loss: 0.02735	Acc= 94.002	Precision= 94.032	Recall= 93.955	F1_score= 93.979
2021-12-26 14:43:12,159 => Train: 100.0	Epoch: 4	Iter: 158	Loss: 0.01385	Acc= 97.238	Precision= 97.260	Recall= 97.211	F1_score= 97.228
2021-12-26 14:44:11,640 => Train: 100.0	Epoch: 5	Iter: 158	Loss: 0.00620	Acc= 99.211	Precision= 99.217	Recall= 99.210	F1_score= 99.212
2021-12-26 14:45:11,017 => Train: 100.0	Epoch: 6	Iter: 158	Loss: 0.00443	Acc= 99.526	Precision= 99.523	Recall= 99.516	F1_score= 99.519
2021-12-26 14:46:10,488 => Train: 100.0	Epoch: 7	Iter: 158	Loss: 0.00278	Acc= 99.842	Precision= 99.839	Recall= 99.839	F1_score= 99.839
2021-12-26 14:47:09,906 => Train: 100.0	Epoch: 8	Iter: 158	Loss: 0.00238	Acc= 99.842	Precision= 99.839	Recall= 99.839	F1_score= 99.839
2021-12-26 14:48:09,278 => Train: 100.0	Epoch: 9	Iter: 158	Loss: 0.00211	Acc= 99.842	Precision= 99.839	Recall= 99.839	F1_score= 99.839
2021-12-26 14:49:08,697 => Train: 100.0	Epoch: 10	Iter: 158	Loss: 0.00194	Acc= 99.842	Precision= 99.839	Recall= 99.839	F1_score= 99.839
2021-12-26 14:50:08,055 => Train: 100.0	Epoch: 11	Iter: 158	Loss: 0.00173	Acc= 99.842	Precision= 99.839	Recall= 99.839	F1_score= 99.839
2021-12-26 14:51:07,447 => Train: 100.0	Epoch: 12	Iter: 158	Loss: 0.00163	Acc= 99.842	Precision= 99.839	Recall= 99.839	F1_score= 99.839
2021-12-26 14:52:06,837 => Train: 100.0	Epoch: 13	Iter: 158	Loss: 0.00164	Acc= 99.842	Precision= 99.839	Recall= 99.839	F1_score= 99.839
2021-12-26 14:53:06,212 => Train: 100.0	Epoch: 14	Iter: 158	Loss: 0.00151	Acc= 99.842	Precision= 99.839	Recall= 99.839	F1_score= 99.839
2021-12-26 14:54:05,623 => Train: 100.0	Epoch: 15	Iter: 158	Loss: 0.00146	Acc= 99.842	Precision= 99.839	Recall= 99.839	F1_score= 99.839
2021-12-26 14:55:04,913 => Train: 100.0	Epoch: 16	Iter: 158	Loss: 0.00139	Acc= 99.842	Precision= 99.839	Recall= 99.839	F1_score= 99.839
2021-12-26 14:56:04,430 => Train: 100.0	Epoch: 17	Iter: 158	Loss: 0.00135	Acc= 99.842	Precision= 99.839	Recall= 99.839	F1_score= 99.839
2021-12-26 14:57:03,852 => Train: 100.0	Epoch: 18	Iter: 158	Loss: 0.00119	Acc= 99.842	Precision= 99.839	Recall= 99.839	F1_score= 99.839
2021-12-26 14:58:03,224 => Train: 100.0	Epoch: 19	Iter: 158	Loss: 0.00112	Acc= 99.842	Precision= 99.839	Recall= 99.839	F1_score= 99.839
2021-12-26 14:59:02,731 => Train: 100.0	Epoch: 20	Iter: 158	Loss: 0.00072	Acc= 99.921	Precision= 99.920	Recall= 99.918	F1_score= 99.919
2021-12-26 15:00:02,119 => Train: 100.0	Epoch: 21	Iter: 158	Loss: 0.00068	Acc= 99.921	Precision= 99.921	Recall= 99.918	F1_score= 99.920
2021-12-26 15:00:02,120 => Epoch: 21	early stopped at loss: 0.00068
2021-12-26 15:00:11,480 => Eval: 100.0	Epoch: 21	Iter: 39	Loss: 0.05921	Acc= 90.852	Precision= 90.776	Recall= 90.992	F1_score= 90.817
2021-12-26 15:00:11,481 => -------------------------------------------------
2021-12-26 15:00:11,481 => 2 FOLD
2021-12-26 15:00:17,050 => loading configuration file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-cased-config.json from cache at /home/yinan/.cache/torch/transformers/b945b69218e98b3e2c95acf911789741307dec43c698d35fad11c1ae28bda352.9da767be51e1327499df13488672789394e2ca38b877837e52618a67d7002391
2021-12-26 15:00:17,051 => Model config BertConfig {
  "architectures": [
    "BertForMaskedLM"
  ],
  "attention_probs_dropout_prob": 0.1,
  "bos_token_id": null,
  "do_sample": false,
  "eos_token_ids": null,
  "finetuning_task": null,
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "hidden_size": 768,
  "id2label": {
    "0": "LABEL_0",
    "1": "LABEL_1"
  },
  "initializer_range": 0.02,
  "intermediate_size": 3072,
  "is_decoder": false,
  "label2id": {
    "LABEL_0": 0,
    "LABEL_1": 1
  },
  "layer_norm_eps": 1e-12,
  "length_penalty": 1.0,
  "max_length": 20,
  "max_position_embeddings": 512,
  "model_type": "bert",
  "num_attention_heads": 12,
  "num_beams": 1,
  "num_hidden_layers": 12,
  "num_labels": 4,
  "num_return_sequences": 1,
  "output_attentions": false,
  "output_hidden_states": false,
  "output_past": true,
  "pad_token_id": 0,
  "pruned_heads": {},
  "repetition_penalty": 1.0,
  "temperature": 1.0,
  "top_k": 50,
  "top_p": 1.0,
  "torchscript": false,
  "type_vocab_size": 2,
  "use_bfloat16": false,
  "vocab_size": 28996
}

2021-12-26 15:00:17,380 => loading weights file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-cased-pytorch_model.bin from cache at /home/yinan/.cache/torch/transformers/35d8b9d36faaf46728a0192d82bf7d00137490cd6074e8500778afed552a67e5.3fadbea36527ae472139fe84cddaa65454d7429f12d543d80bfc3ad70de55ac2
2021-12-26 15:00:22,348 => Weights of BertForSequenceClassification not initialized from pretrained model: ['classifier.weight', 'classifier.bias']
2021-12-26 15:00:22,350 => Weights from pretrained model not used in BertForSequenceClassification: ['cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias']
2021-12-26 15:01:21,768 => Train: 100.0	Epoch: 1	Iter: 158	Loss: 0.15476	Acc= 42.384	Precision= 43.874	Recall= 42.361	F1_score= 42.322
2021-12-26 15:02:20,765 => Train: 100.0	Epoch: 2	Iter: 158	Loss: 0.07977	Acc= 79.321	Precision= 80.311	Recall= 79.282	F1_score= 79.288
2021-12-26 15:03:19,809 => Train: 100.0	Epoch: 3	Iter: 158	Loss: 0.03505	Acc= 92.186	Precision= 92.283	Recall= 92.172	F1_score= 92.190
2021-12-26 15:04:18,959 => Train: 100.0	Epoch: 4	Iter: 158	Loss: 0.01582	Acc= 96.764	Precision= 96.793	Recall= 96.752	F1_score= 96.762
2021-12-26 15:05:17,920 => Train: 100.0	Epoch: 5	Iter: 158	Loss: 0.00744	Acc= 98.816	Precision= 98.824	Recall= 98.812	F1_score= 98.817
2021-12-26 15:06:17,013 => Train: 100.0	Epoch: 6	Iter: 158	Loss: 0.00364	Acc= 99.448	Precision= 99.452	Recall= 99.445	F1_score= 99.448
2021-12-26 15:07:16,010 => Train: 100.0	Epoch: 7	Iter: 158	Loss: 0.00188	Acc= 100.000	Precision= 100.000	Recall= 100.000	F1_score= 100.000
2021-12-26 15:08:14,965 => Train: 100.0	Epoch: 8	Iter: 158	Loss: 0.00143	Acc= 100.000	Precision= 100.000	Recall= 100.000	F1_score= 100.000
2021-12-26 15:09:13,970 => Train: 100.0	Epoch: 9	Iter: 158	Loss: 0.00116	Acc= 100.000	Precision= 100.000	Recall= 100.000	F1_score= 100.000
2021-12-26 15:10:13,099 => Train: 100.0	Epoch: 10	Iter: 158	Loss: 0.00097	Acc= 100.000	Precision= 100.000	Recall= 100.000	F1_score= 100.000
2021-12-26 15:11:12,131 => Train: 100.0	Epoch: 11	Iter: 158	Loss: 0.00084	Acc= 100.000	Precision= 100.000	Recall= 100.000	F1_score= 100.000
2021-12-26 15:11:12,132 => Epoch: 11	early stopped at loss: 0.00084
2021-12-26 15:11:22,911 => Eval: 100.0	Epoch: 11	Iter: 39	Loss: 0.06040	Acc= 89.274	Precision= 89.166	Recall= 89.221	F1_score= 89.131
2021-12-26 15:11:22,911 => -------------------------------------------------
2021-12-26 15:11:22,911 => 3 FOLD
2021-12-26 15:11:29,134 => loading configuration file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-cased-config.json from cache at /home/yinan/.cache/torch/transformers/b945b69218e98b3e2c95acf911789741307dec43c698d35fad11c1ae28bda352.9da767be51e1327499df13488672789394e2ca38b877837e52618a67d7002391
2021-12-26 15:11:29,136 => Model config BertConfig {
  "architectures": [
    "BertForMaskedLM"
  ],
  "attention_probs_dropout_prob": 0.1,
  "bos_token_id": null,
  "do_sample": false,
  "eos_token_ids": null,
  "finetuning_task": null,
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "hidden_size": 768,
  "id2label": {
    "0": "LABEL_0",
    "1": "LABEL_1"
  },
  "initializer_range": 0.02,
  "intermediate_size": 3072,
  "is_decoder": false,
  "label2id": {
    "LABEL_0": 0,
    "LABEL_1": 1
  },
  "layer_norm_eps": 1e-12,
  "length_penalty": 1.0,
  "max_length": 20,
  "max_position_embeddings": 512,
  "model_type": "bert",
  "num_attention_heads": 12,
  "num_beams": 1,
  "num_hidden_layers": 12,
  "num_labels": 4,
  "num_return_sequences": 1,
  "output_attentions": false,
  "output_hidden_states": false,
  "output_past": true,
  "pad_token_id": 0,
  "pruned_heads": {},
  "repetition_penalty": 1.0,
  "temperature": 1.0,
  "top_k": 50,
  "top_p": 1.0,
  "torchscript": false,
  "type_vocab_size": 2,
  "use_bfloat16": false,
  "vocab_size": 28996
}

2021-12-26 15:11:29,473 => loading weights file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-cased-pytorch_model.bin from cache at /home/yinan/.cache/torch/transformers/35d8b9d36faaf46728a0192d82bf7d00137490cd6074e8500778afed552a67e5.3fadbea36527ae472139fe84cddaa65454d7429f12d543d80bfc3ad70de55ac2
2021-12-26 15:11:34,695 => Weights of BertForSequenceClassification not initialized from pretrained model: ['classifier.weight', 'classifier.bias']
2021-12-26 15:11:34,697 => Weights from pretrained model not used in BertForSequenceClassification: ['cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias']
2021-12-26 15:12:34,413 => Train: 100.0	Epoch: 1	Iter: 158	Loss: 0.15158	Acc= 43.646	Precision= 46.649	Recall= 43.213	F1_score= 42.892
2021-12-26 15:13:33,694 => Train: 100.0	Epoch: 2	Iter: 158	Loss: 0.07968	Acc= 77.506	Precision= 77.396	Recall= 77.324	F1_score= 77.250
2021-12-26 15:14:33,008 => Train: 100.0	Epoch: 3	Iter: 158	Loss: 0.03717	Acc= 91.949	Precision= 91.918	Recall= 91.909	F1_score= 91.909
2021-12-26 15:15:32,346 => Train: 100.0	Epoch: 4	Iter: 158	Loss: 0.01821	Acc= 96.606	Precision= 96.599	Recall= 96.602	F1_score= 96.594
2021-12-26 15:16:31,736 => Train: 100.0	Epoch: 5	Iter: 158	Loss: 0.00895	Acc= 98.816	Precision= 98.813	Recall= 98.824	F1_score= 98.818
2021-12-26 15:17:31,046 => Train: 100.0	Epoch: 6	Iter: 158	Loss: 0.00499	Acc= 99.526	Precision= 99.521	Recall= 99.535	F1_score= 99.527
2021-12-26 15:18:30,403 => Train: 100.0	Epoch: 7	Iter: 158	Loss: 0.00285	Acc= 99.763	Precision= 99.764	Recall= 99.770	F1_score= 99.767
2021-12-26 15:19:29,554 => Train: 100.0	Epoch: 8	Iter: 158	Loss: 0.00221	Acc= 99.763	Precision= 99.756	Recall= 99.770	F1_score= 99.763
2021-12-26 15:20:28,915 => Train: 100.0	Epoch: 9	Iter: 158	Loss: 0.00181	Acc= 99.842	Precision= 99.838	Recall= 99.851	F1_score= 99.844
2021-12-26 15:21:28,144 => Train: 100.0	Epoch: 10	Iter: 158	Loss: 0.00168	Acc= 99.763	Precision= 99.756	Recall= 99.770	F1_score= 99.763
2021-12-26 15:22:27,565 => Train: 100.0	Epoch: 11	Iter: 158	Loss: 0.00127	Acc= 99.921	Precision= 99.920	Recall= 99.925	F1_score= 99.922
2021-12-26 15:23:26,780 => Train: 100.0	Epoch: 12	Iter: 158	Loss: 0.00111	Acc= 99.921	Precision= 99.918	Recall= 99.925	F1_score= 99.922
2021-12-26 15:24:26,149 => Train: 100.0	Epoch: 13	Iter: 158	Loss: 0.00100	Acc= 99.921	Precision= 99.918	Recall= 99.925	F1_score= 99.922
2021-12-26 15:25:25,342 => Train: 100.0	Epoch: 14	Iter: 158	Loss: 0.00087	Acc= 100.000	Precision= 100.000	Recall= 100.000	F1_score= 100.000
2021-12-26 15:25:25,344 => Epoch: 14	early stopped at loss: 0.00087
2021-12-26 15:25:36,145 => Eval: 100.0	Epoch: 14	Iter: 39	Loss: 0.02796	Acc= 93.691	Precision= 93.820	Recall= 93.666	F1_score= 93.738
2021-12-26 15:25:36,145 => -------------------------------------------------
2021-12-26 15:25:36,145 => 4 FOLD
2021-12-26 15:27:15,163 => loading configuration file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-cased-config.json from cache at /home/yinan/.cache/torch/transformers/b945b69218e98b3e2c95acf911789741307dec43c698d35fad11c1ae28bda352.9da767be51e1327499df13488672789394e2ca38b877837e52618a67d7002391
2021-12-26 15:27:15,166 => Model config BertConfig {
  "architectures": [
    "BertForMaskedLM"
  ],
  "attention_probs_dropout_prob": 0.1,
  "bos_token_id": null,
  "do_sample": false,
  "eos_token_ids": null,
  "finetuning_task": null,
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "hidden_size": 768,
  "id2label": {
    "0": "LABEL_0",
    "1": "LABEL_1"
  },
  "initializer_range": 0.02,
  "intermediate_size": 3072,
  "is_decoder": false,
  "label2id": {
    "LABEL_0": 0,
    "LABEL_1": 1
  },
  "layer_norm_eps": 1e-12,
  "length_penalty": 1.0,
  "max_length": 20,
  "max_position_embeddings": 512,
  "model_type": "bert",
  "num_attention_heads": 12,
  "num_beams": 1,
  "num_hidden_layers": 12,
  "num_labels": 4,
  "num_return_sequences": 1,
  "output_attentions": false,
  "output_hidden_states": false,
  "output_past": true,
  "pad_token_id": 0,
  "pruned_heads": {},
  "repetition_penalty": 1.0,
  "temperature": 1.0,
  "top_k": 50,
  "top_p": 1.0,
  "torchscript": false,
  "type_vocab_size": 2,
  "use_bfloat16": false,
  "vocab_size": 28996
}

2021-12-26 15:27:15,525 => loading weights file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-cased-pytorch_model.bin from cache at /home/yinan/.cache/torch/transformers/35d8b9d36faaf46728a0192d82bf7d00137490cd6074e8500778afed552a67e5.3fadbea36527ae472139fe84cddaa65454d7429f12d543d80bfc3ad70de55ac2
2021-12-26 15:27:19,966 => Weights of BertForSequenceClassification not initialized from pretrained model: ['classifier.weight', 'classifier.bias']
2021-12-26 15:27:19,969 => Weights from pretrained model not used in BertForSequenceClassification: ['cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias']
2021-12-26 15:28:19,698 => Train: 100.0	Epoch: 1	Iter: 158	Loss: 0.14305	Acc= 49.803	Precision= 51.648	Recall= 49.412	F1_score= 47.818
2021-12-26 15:29:19,083 => Train: 100.0	Epoch: 2	Iter: 158	Loss: 0.07172	Acc= 80.742	Precision= 80.718	Recall= 80.677	F1_score= 80.686
2021-12-26 15:30:18,508 => Train: 100.0	Epoch: 3	Iter: 158	Loss: 0.03153	Acc= 93.054	Precision= 93.022	Recall= 93.030	F1_score= 93.025
2021-12-26 15:31:17,941 => Train: 100.0	Epoch: 4	Iter: 158	Loss: 0.01508	Acc= 97.395	Precision= 97.390	Recall= 97.392	F1_score= 97.391
2021-12-26 15:32:17,224 => Train: 100.0	Epoch: 5	Iter: 158	Loss: 0.00755	Acc= 99.053	Precision= 99.048	Recall= 99.058	F1_score= 99.053
2021-12-26 15:33:16,701 => Train: 100.0	Epoch: 6	Iter: 158	Loss: 0.00477	Acc= 99.526	Precision= 99.526	Recall= 99.526	F1_score= 99.526
2021-12-26 15:34:16,152 => Train: 100.0	Epoch: 7	Iter: 158	Loss: 0.00350	Acc= 99.763	Precision= 99.761	Recall= 99.766	F1_score= 99.763
2021-12-26 15:35:15,447 => Train: 100.0	Epoch: 8	Iter: 158	Loss: 0.00282	Acc= 99.763	Precision= 99.761	Recall= 99.766	F1_score= 99.763
2021-12-26 15:36:14,818 => Train: 100.0	Epoch: 9	Iter: 158	Loss: 0.00257	Acc= 99.684	Precision= 99.680	Recall= 99.689	F1_score= 99.684
2021-12-26 15:37:14,172 => Train: 100.0	Epoch: 10	Iter: 158	Loss: 0.00196	Acc= 99.763	Precision= 99.757	Recall= 99.766	F1_score= 99.761
2021-12-26 15:38:13,527 => Train: 100.0	Epoch: 11	Iter: 158	Loss: 0.00154	Acc= 99.842	Precision= 99.840	Recall= 99.846	F1_score= 99.842
2021-12-26 15:39:12,967 => Train: 100.0	Epoch: 12	Iter: 158	Loss: 0.00143	Acc= 99.763	Precision= 99.758	Recall= 99.769	F1_score= 99.763
2021-12-26 15:40:12,466 => Train: 100.0	Epoch: 13	Iter: 158	Loss: 0.00115	Acc= 99.921	Precision= 99.920	Recall= 99.923	F1_score= 99.921
2021-12-26 15:41:11,740 => Train: 100.0	Epoch: 14	Iter: 158	Loss: 0.00097	Acc= 99.921	Precision= 99.920	Recall= 99.923	F1_score= 99.921
2021-12-26 15:42:11,296 => Train: 100.0	Epoch: 15	Iter: 158	Loss: 0.00088	Acc= 100.000	Precision= 100.000	Recall= 100.000	F1_score= 100.000
2021-12-26 15:42:11,299 => Epoch: 15	early stopped at loss: 0.00088
2021-12-26 15:42:21,010 => Eval: 100.0	Epoch: 15	Iter: 39	Loss: 0.03413	Acc= 93.060	Precision= 93.057	Recall= 93.151	F1_score= 93.069
2021-12-26 15:42:21,010 => -------------------------------------------------
2021-12-26 15:42:21,010 => 5 FOLD
2021-12-26 15:42:27,457 => loading configuration file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-cased-config.json from cache at /home/yinan/.cache/torch/transformers/b945b69218e98b3e2c95acf911789741307dec43c698d35fad11c1ae28bda352.9da767be51e1327499df13488672789394e2ca38b877837e52618a67d7002391
2021-12-26 15:42:27,459 => Model config BertConfig {
  "architectures": [
    "BertForMaskedLM"
  ],
  "attention_probs_dropout_prob": 0.1,
  "bos_token_id": null,
  "do_sample": false,
  "eos_token_ids": null,
  "finetuning_task": null,
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "hidden_size": 768,
  "id2label": {
    "0": "LABEL_0",
    "1": "LABEL_1"
  },
  "initializer_range": 0.02,
  "intermediate_size": 3072,
  "is_decoder": false,
  "label2id": {
    "LABEL_0": 0,
    "LABEL_1": 1
  },
  "layer_norm_eps": 1e-12,
  "length_penalty": 1.0,
  "max_length": 20,
  "max_position_embeddings": 512,
  "model_type": "bert",
  "num_attention_heads": 12,
  "num_beams": 1,
  "num_hidden_layers": 12,
  "num_labels": 4,
  "num_return_sequences": 1,
  "output_attentions": false,
  "output_hidden_states": false,
  "output_past": true,
  "pad_token_id": 0,
  "pruned_heads": {},
  "repetition_penalty": 1.0,
  "temperature": 1.0,
  "top_k": 50,
  "top_p": 1.0,
  "torchscript": false,
  "type_vocab_size": 2,
  "use_bfloat16": false,
  "vocab_size": 28996
}

2021-12-26 15:42:27,793 => loading weights file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-cased-pytorch_model.bin from cache at /home/yinan/.cache/torch/transformers/35d8b9d36faaf46728a0192d82bf7d00137490cd6074e8500778afed552a67e5.3fadbea36527ae472139fe84cddaa65454d7429f12d543d80bfc3ad70de55ac2
2021-12-26 15:42:32,331 => Weights of BertForSequenceClassification not initialized from pretrained model: ['classifier.weight', 'classifier.bias']
2021-12-26 15:42:32,334 => Weights from pretrained model not used in BertForSequenceClassification: ['cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias']
2021-12-26 15:43:32,279 => Train: 100.0	Epoch: 1	Iter: 158	Loss: 0.15302	Acc= 43.060	Precision= 43.722	Recall= 42.828	F1_score= 42.426
2021-12-26 15:44:31,648 => Train: 100.0	Epoch: 2	Iter: 158	Loss: 0.09582	Acc= 70.820	Precision= 72.621	Recall= 70.417	F1_score= 70.144
2021-12-26 15:45:31,055 => Train: 100.0	Epoch: 3	Iter: 158	Loss: 0.04884	Acc= 88.959	Precision= 89.117	Recall= 88.872	F1_score= 88.909
2021-12-26 15:46:30,472 => Train: 100.0	Epoch: 4	Iter: 158	Loss: 0.02596	Acc= 94.874	Precision= 94.877	Recall= 94.861	F1_score= 94.866
2021-12-26 15:47:29,956 => Train: 100.0	Epoch: 5	Iter: 158	Loss: 0.01350	Acc= 97.634	Precision= 97.621	Recall= 97.637	F1_score= 97.627
2021-12-26 15:48:29,531 => Train: 100.0	Epoch: 6	Iter: 158	Loss: 0.00731	Acc= 99.132	Precision= 99.130	Recall= 99.137	F1_score= 99.132
2021-12-26 15:49:28,926 => Train: 100.0	Epoch: 7	Iter: 158	Loss: 0.00455	Acc= 99.606	Precision= 99.604	Recall= 99.603	F1_score= 99.603
2021-12-26 15:50:28,386 => Train: 100.0	Epoch: 8	Iter: 158	Loss: 0.00374	Acc= 99.527	Precision= 99.526	Recall= 99.530	F1_score= 99.528
2021-12-26 15:51:27,696 => Train: 100.0	Epoch: 9	Iter: 158	Loss: 0.00284	Acc= 99.685	Precision= 99.684	Recall= 99.684	F1_score= 99.684
2021-12-26 15:52:27,219 => Train: 100.0	Epoch: 10	Iter: 158	Loss: 0.00213	Acc= 99.842	Precision= 99.844	Recall= 99.841	F1_score= 99.842
2021-12-26 15:53:26,717 => Train: 100.0	Epoch: 11	Iter: 158	Loss: 0.00175	Acc= 99.921	Precision= 99.922	Recall= 99.920	F1_score= 99.921
2021-12-26 15:54:25,991 => Train: 100.0	Epoch: 12	Iter: 158	Loss: 0.00141	Acc= 99.921	Precision= 99.922	Recall= 99.920	F1_score= 99.921
2021-12-26 15:55:25,424 => Train: 100.0	Epoch: 13	Iter: 158	Loss: 0.00123	Acc= 99.921	Precision= 99.922	Recall= 99.920	F1_score= 99.921
2021-12-26 15:56:24,822 => Train: 100.0	Epoch: 14	Iter: 158	Loss: 0.00103	Acc= 100.000	Precision= 100.000	Recall= 100.000	F1_score= 100.000
2021-12-26 15:57:24,322 => Train: 100.0	Epoch: 15	Iter: 158	Loss: 0.00091	Acc= 100.000	Precision= 100.000	Recall= 100.000	F1_score= 100.000
2021-12-26 15:58:23,750 => Train: 100.0	Epoch: 16	Iter: 158	Loss: 0.00083	Acc= 100.000	Precision= 100.000	Recall= 100.000	F1_score= 100.000
2021-12-26 15:58:23,751 => Epoch: 16	early stopped at loss: 0.00083
2021-12-26 15:58:32,999 => Eval: 100.0	Epoch: 16	Iter: 39	Loss: 0.03109	Acc= 93.038	Precision= 93.060	Recall= 93.112	F1_score= 93.044
2021-12-26 15:58:33,000 => AVERAGE ACCURACY: 91.983
