2021-11-16 02:24:57,701 => 1.10.0
2021-11-16 02:24:57,702 => cuda
2021-11-16 02:24:58,332 => loading file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-cased-vocab.txt from cache at /home/yinan/.cache/torch/transformers/5e8a2b4893d13790ed4150ca1906be5f7a03d6c4ddf62296c383f6db42814db2.e13dbb970cb325137104fb2e5f36fe865f27746c6b526f6352861b1980eb80b1
2021-11-16 02:25:10,114 => -------------------------------------------------
2021-11-16 02:25:10,115 => 1 FOLD
2021-11-16 02:25:10,724 => loading configuration file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-cased-config.json from cache at /home/yinan/.cache/torch/transformers/b945b69218e98b3e2c95acf911789741307dec43c698d35fad11c1ae28bda352.9da767be51e1327499df13488672789394e2ca38b877837e52618a67d7002391
2021-11-16 02:25:10,725 => Model config BertConfig {
  "architectures": [
    "BertForMaskedLM"
  ],
  "attention_probs_dropout_prob": 0.1,
  "bos_token_id": null,
  "do_sample": false,
  "eos_token_ids": null,
  "finetuning_task": null,
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "hidden_size": 768,
  "id2label": {
    "0": "LABEL_0",
    "1": "LABEL_1"
  },
  "initializer_range": 0.02,
  "intermediate_size": 3072,
  "is_decoder": false,
  "label2id": {
    "LABEL_0": 0,
    "LABEL_1": 1
  },
  "layer_norm_eps": 1e-12,
  "length_penalty": 1.0,
  "max_length": 20,
  "max_position_embeddings": 512,
  "model_type": "bert",
  "num_attention_heads": 12,
  "num_beams": 1,
  "num_hidden_layers": 12,
  "num_labels": 4,
  "num_return_sequences": 1,
  "output_attentions": false,
  "output_hidden_states": false,
  "output_past": true,
  "pad_token_id": 0,
  "pruned_heads": {},
  "repetition_penalty": 1.0,
  "temperature": 1.0,
  "top_k": 50,
  "top_p": 1.0,
  "torchscript": false,
  "type_vocab_size": 2,
  "use_bfloat16": false,
  "vocab_size": 28996
}

2021-11-16 02:25:11,150 => loading weights file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-cased-pytorch_model.bin from cache at /home/yinan/.cache/torch/transformers/35d8b9d36faaf46728a0192d82bf7d00137490cd6074e8500778afed552a67e5.3fadbea36527ae472139fe84cddaa65454d7429f12d543d80bfc3ad70de55ac2
2021-11-16 02:25:15,588 => Weights of BertForSequenceClassification not initialized from pretrained model: ['classifier.weight', 'classifier.bias']
2021-11-16 02:25:15,589 => Weights from pretrained model not used in BertForSequenceClassification: ['cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias']
2021-11-16 02:28:43,768 => Train: 100.0	Epoch: 1	Iter: 158	Loss: 0.18643	Acc= 22.889	Precision= 22.853	Recall= 22.880	F1_score= 22.780
2021-11-16 02:32:13,396 => Train: 100.0	Epoch: 2	Iter: 158	Loss: 0.18272	Acc= 23.283	Precision= 23.377	Recall= 23.277	F1_score= 23.314
2021-11-16 02:35:41,263 => Train: 100.0	Epoch: 3	Iter: 158	Loss: 0.18353	Acc= 22.099	Precision= 22.129	Recall= 22.098	F1_score= 22.102
2021-11-16 02:39:14,446 => Train: 100.0	Epoch: 4	Iter: 158	Loss: 0.18101	Acc= 23.836	Precision= 23.867	Recall= 23.847	F1_score= 23.843
2021-11-16 02:44:22,215 => Train: 100.0	Epoch: 5	Iter: 158	Loss: 0.18006	Acc= 24.546	Precision= 24.402	Recall= 24.538	F1_score= 24.449
2021-11-16 02:47:53,970 => Train: 100.0	Epoch: 6	Iter: 158	Loss: 0.18021	Acc= 25.414	Precision= 25.328	Recall= 25.423	F1_score= 25.331
2021-11-16 02:51:25,705 => Train: 100.0	Epoch: 7	Iter: 158	Loss: 0.17889	Acc= 25.651	Precision= 25.644	Recall= 25.639	F1_score= 25.546
2021-11-16 02:54:57,759 => Train: 100.0	Epoch: 8	Iter: 158	Loss: 0.17851	Acc= 24.625	Precision= 24.502	Recall= 24.609	F1_score= 24.470
2021-11-16 02:58:29,801 => Train: 100.0	Epoch: 9	Iter: 158	Loss: 0.17784	Acc= 24.625	Precision= 24.591	Recall= 24.607	F1_score= 24.507
2021-11-16 03:02:00,242 => Train: 100.0	Epoch: 10	Iter: 158	Loss: 0.17886	Acc= 23.994	Precision= 24.069	Recall= 23.977	F1_score= 23.931
2021-11-16 03:07:02,271 => Train: 100.0	Epoch: 11	Iter: 158	Loss: 0.17871	Acc= 25.178	Precision= 25.101	Recall= 25.153	F1_score= 25.024
2021-11-16 03:12:58,709 => Train: 100.0	Epoch: 12	Iter: 158	Loss: 0.17799	Acc= 25.730	Precision= 25.713	Recall= 25.713	F1_score= 25.685
2021-11-16 03:16:29,773 => Train: 100.0	Epoch: 13	Iter: 158	Loss: 0.17694	Acc= 26.677	Precision= 26.616	Recall= 26.647	F1_score= 26.535
2021-11-16 03:20:00,796 => Train: 100.0	Epoch: 14	Iter: 158	Loss: 0.17774	Acc= 24.546	Precision= 24.490	Recall= 24.534	F1_score= 24.493
2021-11-16 03:23:32,649 => Train: 100.0	Epoch: 15	Iter: 158	Loss: 0.17815	Acc= 23.599	Precision= 23.512	Recall= 23.570	F1_score= 23.450
2021-11-16 03:27:14,085 => Train: 100.0	Epoch: 16	Iter: 158	Loss: 0.17739	Acc= 25.414	Precision= 25.421	Recall= 25.400	F1_score= 25.335
2021-11-16 03:30:47,430 => Train: 100.0	Epoch: 17	Iter: 158	Loss: 0.17769	Acc= 25.730	Precision= 25.716	Recall= 25.709	F1_score= 25.661
2021-11-16 03:34:18,116 => Train: 100.0	Epoch: 18	Iter: 158	Loss: 0.17783	Acc= 23.362	Precision= 23.390	Recall= 23.353	F1_score= 23.359
2021-11-16 03:37:51,733 => Train: 100.0	Epoch: 19	Iter: 158	Loss: 0.17639	Acc= 25.572	Precision= 25.460	Recall= 25.550	F1_score= 25.483
2021-11-16 03:41:22,958 => Train: 100.0	Epoch: 20	Iter: 158	Loss: 0.17697	Acc= 23.283	Precision= 23.307	Recall= 23.261	F1_score= 23.207
2021-11-16 03:44:52,024 => Train: 100.0	Epoch: 21	Iter: 158	Loss: 0.17625	Acc= 25.730	Precision= 25.588	Recall= 25.699	F1_score= 25.556
2021-11-16 03:48:21,125 => Train: 100.0	Epoch: 22	Iter: 158	Loss: 0.17725	Acc= 22.968	Precision= 23.057	Recall= 22.962	F1_score= 22.960
2021-11-16 03:51:53,928 => Train: 100.0	Epoch: 23	Iter: 158	Loss: 0.17668	Acc= 24.152	Precision= 23.932	Recall= 24.108	F1_score= 23.937
2021-11-16 03:55:25,253 => Train: 100.0	Epoch: 24	Iter: 158	Loss: 0.17620	Acc= 24.625	Precision= 24.609	Recall= 24.592	F1_score= 24.470
2021-11-16 03:59:00,829 => Train: 100.0	Epoch: 25	Iter: 158	Loss: 0.17548	Acc= 25.888	Precision= 25.648	Recall= 25.846	F1_score= 25.653
2021-11-16 04:04:23,186 => Train: 100.0	Epoch: 26	Iter: 158	Loss: 0.17521	Acc= 26.440	Precision= 26.547	Recall= 26.409	F1_score= 26.296
2021-11-16 04:08:00,725 => Train: 100.0	Epoch: 27	Iter: 158	Loss: 0.17589	Acc= 23.678	Precision= 23.490	Recall= 23.636	F1_score= 23.426
2021-11-16 04:11:29,850 => Train: 100.0	Epoch: 28	Iter: 158	Loss: 0.17624	Acc= 24.783	Precision= 24.772	Recall= 24.761	F1_score= 24.716
2021-11-16 04:15:01,273 => Train: 100.0	Epoch: 29	Iter: 158	Loss: 0.17568	Acc= 24.388	Precision= 24.428	Recall= 24.362	F1_score= 24.284
2021-11-16 04:18:34,543 => Train: 100.0	Epoch: 30	Iter: 158	Loss: 0.17536	Acc= 25.178	Precision= 25.141	Recall= 25.152	F1_score= 25.075
2021-11-16 04:22:04,984 => Train: 100.0	Epoch: 31	Iter: 158	Loss: 0.17581	Acc= 24.625	Precision= 24.460	Recall= 24.591	F1_score= 24.471
2021-11-16 04:25:36,568 => Train: 100.0	Epoch: 32	Iter: 158	Loss: 0.17529	Acc= 26.993	Precision= 27.122	Recall= 26.976	F1_score= 26.955
2021-11-16 04:29:12,718 => Train: 100.0	Epoch: 33	Iter: 158	Loss: 0.17630	Acc= 23.125	Precision= 23.191	Recall= 23.099	F1_score= 23.028
2021-11-16 04:32:49,949 => Train: 100.0	Epoch: 34	Iter: 158	Loss: 0.17623	Acc= 24.467	Precision= 24.153	Recall= 24.419	F1_score= 24.170
2021-11-16 04:36:23,314 => Train: 100.0	Epoch: 35	Iter: 158	Loss: 0.17532	Acc= 23.599	Precision= 23.671	Recall= 23.578	F1_score= 23.533
2021-11-16 04:39:57,537 => Train: 100.0	Epoch: 36	Iter: 158	Loss: 0.17576	Acc= 24.625	Precision= 24.654	Recall= 24.597	F1_score= 24.521
2021-11-16 04:43:33,182 => Train: 100.0	Epoch: 37	Iter: 158	Loss: 0.17464	Acc= 26.361	Precision= 26.345	Recall= 26.332	F1_score= 26.219
2021-11-16 04:47:03,929 => Train: 100.0	Epoch: 38	Iter: 158	Loss: 0.17506	Acc= 27.624	Precision= 27.571	Recall= 27.591	F1_score= 27.482
2021-11-16 04:50:32,801 => Train: 100.0	Epoch: 39	Iter: 158	Loss: 0.17516	Acc= 27.309	Precision= 27.100	Recall= 27.267	F1_score= 27.097
2021-11-16 04:54:08,577 => Train: 100.0	Epoch: 40	Iter: 158	Loss: 0.17460	Acc= 26.993	Precision= 27.074	Recall= 26.970	F1_score= 26.912
2021-11-16 04:57:39,343 => Train: 100.0	Epoch: 41	Iter: 158	Loss: 0.17489	Acc= 25.572	Precision= 25.868	Recall= 25.562	F1_score= 25.596
2021-11-16 05:01:32,776 => Train: 100.0	Epoch: 42	Iter: 158	Loss: 0.17520	Acc= 25.020	Precision= 24.824	Recall= 24.984	F1_score= 24.847
2021-11-16 05:06:02,818 => Train: 100.0	Epoch: 43	Iter: 158	Loss: 0.17496	Acc= 25.809	Precision= 26.095	Recall= 25.799	F1_score= 25.839
2021-11-16 05:10:26,142 => Train: 100.0	Epoch: 44	Iter: 158	Loss: 0.17470	Acc= 24.152	Precision= 24.340	Recall= 24.149	F1_score= 24.180
2021-11-16 05:14:36,052 => Train: 100.0	Epoch: 45	Iter: 158	Loss: 0.17436	Acc= 26.361	Precision= 26.508	Recall= 26.358	F1_score= 26.400
2021-11-16 05:19:11,995 => Train: 100.0	Epoch: 46	Iter: 158	Loss: 0.17508	Acc= 25.020	Precision= 24.967	Recall= 24.988	F1_score= 24.889
2021-11-16 05:23:25,179 => Train: 100.0	Epoch: 47	Iter: 158	Loss: 0.17498	Acc= 24.862	Precision= 24.792	Recall= 24.832	F1_score= 24.739
2021-11-16 05:27:37,009 => Train: 100.0	Epoch: 48	Iter: 158	Loss: 0.17584	Acc= 23.441	Precision= 23.301	Recall= 23.408	F1_score= 23.294
2021-11-16 05:31:51,302 => Train: 100.0	Epoch: 49	Iter: 158	Loss: 0.17414	Acc= 27.624	Precision= 27.556	Recall= 27.591	F1_score= 27.484
2021-11-16 05:36:00,906 => Train: 100.0	Epoch: 50	Iter: 158	Loss: 0.17572	Acc= 24.309	Precision= 24.133	Recall= 24.274	F1_score= 24.128
2021-11-16 05:36:04,380 => Eval: 100.0	Epoch: 50	Iter: 39	Loss: 0.17484	Acc= 25.237	Precision= 6.309	Recall= 25.000	F1_score= 10.076
2021-11-16 05:36:04,380 => -------------------------------------------------
2021-11-16 05:36:04,380 => 2 FOLD
2021-11-16 05:36:04,822 => loading configuration file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-cased-config.json from cache at /home/yinan/.cache/torch/transformers/b945b69218e98b3e2c95acf911789741307dec43c698d35fad11c1ae28bda352.9da767be51e1327499df13488672789394e2ca38b877837e52618a67d7002391
2021-11-16 05:36:04,823 => Model config BertConfig {
  "architectures": [
    "BertForMaskedLM"
  ],
  "attention_probs_dropout_prob": 0.1,
  "bos_token_id": null,
  "do_sample": false,
  "eos_token_ids": null,
  "finetuning_task": null,
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "hidden_size": 768,
  "id2label": {
    "0": "LABEL_0",
    "1": "LABEL_1"
  },
  "initializer_range": 0.02,
  "intermediate_size": 3072,
  "is_decoder": false,
  "label2id": {
    "LABEL_0": 0,
    "LABEL_1": 1
  },
  "layer_norm_eps": 1e-12,
  "length_penalty": 1.0,
  "max_length": 20,
  "max_position_embeddings": 512,
  "model_type": "bert",
  "num_attention_heads": 12,
  "num_beams": 1,
  "num_hidden_layers": 12,
  "num_labels": 4,
  "num_return_sequences": 1,
  "output_attentions": false,
  "output_hidden_states": false,
  "output_past": true,
  "pad_token_id": 0,
  "pruned_heads": {},
  "repetition_penalty": 1.0,
  "temperature": 1.0,
  "top_k": 50,
  "top_p": 1.0,
  "torchscript": false,
  "type_vocab_size": 2,
  "use_bfloat16": false,
  "vocab_size": 28996
}

2021-11-16 05:36:05,282 => loading weights file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-cased-pytorch_model.bin from cache at /home/yinan/.cache/torch/transformers/35d8b9d36faaf46728a0192d82bf7d00137490cd6074e8500778afed552a67e5.3fadbea36527ae472139fe84cddaa65454d7429f12d543d80bfc3ad70de55ac2
2021-11-16 05:36:09,115 => Weights of BertForSequenceClassification not initialized from pretrained model: ['classifier.weight', 'classifier.bias']
2021-11-16 05:36:09,116 => Weights from pretrained model not used in BertForSequenceClassification: ['cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias']
2021-11-16 05:40:18,713 => Train: 100.0	Epoch: 1	Iter: 158	Loss: 0.18749	Acc= 23.994	Precision= 23.927	Recall= 23.943	F1_score= 23.925
2021-11-16 05:44:45,684 => Train: 100.0	Epoch: 2	Iter: 158	Loss: 0.18374	Acc= 25.335	Precision= 25.242	Recall= 25.270	F1_score= 25.203
2021-11-16 05:48:41,395 => Train: 100.0	Epoch: 3	Iter: 158	Loss: 0.18225	Acc= 25.414	Precision= 25.187	Recall= 25.293	F1_score= 25.119
2021-11-16 05:52:48,740 => Train: 100.0	Epoch: 4	Iter: 158	Loss: 0.18146	Acc= 24.230	Precision= 24.149	Recall= 24.166	F1_score= 24.080
2021-11-16 05:59:46,851 => Train: 100.0	Epoch: 5	Iter: 158	Loss: 0.17984	Acc= 24.230	Precision= 24.119	Recall= 24.126	F1_score= 23.952
2021-11-16 06:03:51,917 => Train: 100.0	Epoch: 6	Iter: 158	Loss: 0.17919	Acc= 24.862	Precision= 24.740	Recall= 24.725	F1_score= 24.579
2021-11-16 06:08:04,633 => Train: 100.0	Epoch: 7	Iter: 158	Loss: 0.17853	Acc= 25.414	Precision= 25.043	Recall= 25.224	F1_score= 24.890
2021-11-16 06:12:19,505 => Train: 100.0	Epoch: 8	Iter: 158	Loss: 0.17852	Acc= 25.257	Precision= 24.892	Recall= 25.072	F1_score= 24.841
2021-11-16 06:16:43,811 => Train: 100.0	Epoch: 9	Iter: 158	Loss: 0.17739	Acc= 25.257	Precision= 24.988	Recall= 25.079	F1_score= 24.877
2021-11-16 06:21:09,692 => Train: 100.0	Epoch: 10	Iter: 158	Loss: 0.17827	Acc= 25.257	Precision= 24.841	Recall= 25.033	F1_score= 24.731
2021-11-16 06:28:19,901 => Train: 100.0	Epoch: 11	Iter: 158	Loss: 0.17853	Acc= 24.073	Precision= 23.797	Recall= 23.864	F1_score= 23.614
2021-11-16 06:34:38,633 => Train: 100.0	Epoch: 12	Iter: 158	Loss: 0.17742	Acc= 25.572	Precision= 25.448	Recall= 25.397	F1_score= 25.218
2021-11-16 06:38:54,202 => Train: 100.0	Epoch: 13	Iter: 158	Loss: 0.17826	Acc= 25.099	Precision= 24.733	Recall= 24.881	F1_score= 24.568
2021-11-16 06:43:37,408 => Train: 100.0	Epoch: 14	Iter: 158	Loss: 0.17707	Acc= 24.783	Precision= 24.499	Recall= 24.578	F1_score= 24.330
2021-11-16 06:48:00,817 => Train: 100.0	Epoch: 15	Iter: 158	Loss: 0.17653	Acc= 26.993	Precision= 26.852	Recall= 26.793	F1_score= 26.597
2021-11-16 06:53:06,785 => Train: 100.0	Epoch: 16	Iter: 158	Loss: 0.17635	Acc= 25.967	Precision= 25.526	Recall= 25.713	F1_score= 25.337
2021-11-16 06:57:31,914 => Train: 100.0	Epoch: 17	Iter: 158	Loss: 0.17635	Acc= 26.125	Precision= 25.775	Recall= 25.911	F1_score= 25.577
2021-11-16 07:01:44,602 => Train: 100.0	Epoch: 18	Iter: 158	Loss: 0.17731	Acc= 23.915	Precision= 23.601	Recall= 23.713	F1_score= 23.472
2021-11-16 07:05:59,679 => Train: 100.0	Epoch: 19	Iter: 158	Loss: 0.17698	Acc= 25.099	Precision= 25.018	Recall= 24.916	F1_score= 24.699
2021-11-16 07:10:14,473 => Train: 100.0	Epoch: 20	Iter: 158	Loss: 0.17636	Acc= 23.994	Precision= 23.726	Recall= 23.797	F1_score= 23.508
2021-11-16 07:14:37,865 => Train: 100.0	Epoch: 21	Iter: 158	Loss: 0.17613	Acc= 23.994	Precision= 23.581	Recall= 23.761	F1_score= 23.415
2021-11-16 07:18:54,499 => Train: 100.0	Epoch: 22	Iter: 158	Loss: 0.17597	Acc= 26.125	Precision= 25.592	Recall= 25.840	F1_score= 25.346
2021-11-16 07:23:15,872 => Train: 100.0	Epoch: 23	Iter: 158	Loss: 0.17574	Acc= 25.493	Precision= 25.444	Recall= 25.311	F1_score= 25.122
2021-11-16 07:27:35,032 => Train: 100.0	Epoch: 24	Iter: 158	Loss: 0.17511	Acc= 25.178	Precision= 24.989	Recall= 24.965	F1_score= 24.705
2021-11-16 07:31:59,173 => Train: 100.0	Epoch: 25	Iter: 158	Loss: 0.17563	Acc= 25.730	Precision= 25.393	Recall= 25.489	F1_score= 25.158
2021-11-16 07:37:59,740 => Train: 100.0	Epoch: 26	Iter: 158	Loss: 0.17594	Acc= 25.414	Precision= 25.144	Recall= 25.162	F1_score= 24.792
2021-11-16 07:42:12,860 => Train: 100.0	Epoch: 27	Iter: 158	Loss: 0.17572	Acc= 25.257	Precision= 25.060	Recall= 25.035	F1_score= 24.750
2021-11-16 07:47:00,535 => Train: 100.0	Epoch: 28	Iter: 158	Loss: 0.17597	Acc= 24.862	Precision= 24.309	Recall= 24.581	F1_score= 24.096
2021-11-16 07:51:10,497 => Train: 100.0	Epoch: 29	Iter: 158	Loss: 0.17589	Acc= 23.994	Precision= 23.793	Recall= 23.781	F1_score= 23.504
2021-11-16 07:55:16,956 => Train: 100.0	Epoch: 30	Iter: 158	Loss: 0.17541	Acc= 24.862	Precision= 24.744	Recall= 24.622	F1_score= 24.271
2021-11-16 07:59:38,710 => Train: 100.0	Epoch: 31	Iter: 158	Loss: 0.17541	Acc= 26.125	Precision= 25.704	Recall= 25.858	F1_score= 25.431
2021-11-16 08:04:34,036 => Train: 100.0	Epoch: 32	Iter: 158	Loss: 0.17596	Acc= 24.783	Precision= 24.301	Recall= 24.519	F1_score= 24.074
2021-11-16 08:10:17,371 => Train: 100.0	Epoch: 33	Iter: 158	Loss: 0.17557	Acc= 24.152	Precision= 23.951	Recall= 23.907	F1_score= 23.547
2021-11-16 08:15:29,858 => Train: 100.0	Epoch: 34	Iter: 158	Loss: 0.17517	Acc= 27.230	Precision= 26.484	Recall= 26.899	F1_score= 26.240
2021-11-16 08:20:55,081 => Train: 100.0	Epoch: 35	Iter: 158	Loss: 0.17506	Acc= 25.967	Precision= 25.162	Recall= 25.651	F1_score= 25.090
2021-11-16 08:26:22,341 => Train: 100.0	Epoch: 36	Iter: 158	Loss: 0.17477	Acc= 26.125	Precision= 25.971	Recall= 25.878	F1_score= 25.528
2021-11-16 08:31:55,536 => Train: 100.0	Epoch: 37	Iter: 158	Loss: 0.17602	Acc= 24.073	Precision= 23.943	Recall= 23.835	F1_score= 23.478
2021-11-16 08:37:29,663 => Train: 100.0	Epoch: 38	Iter: 158	Loss: 0.17542	Acc= 24.783	Precision= 24.558	Recall= 24.559	F1_score= 24.264
2021-11-16 08:42:56,612 => Train: 100.0	Epoch: 39	Iter: 158	Loss: 0.17486	Acc= 26.361	Precision= 26.355	Recall= 26.112	F1_score= 25.796
2021-11-16 08:51:05,781 => Train: 100.0	Epoch: 40	Iter: 158	Loss: 0.17493	Acc= 25.888	Precision= 25.677	Recall= 25.650	F1_score= 25.301
2021-11-16 08:57:01,454 => Train: 100.0	Epoch: 41	Iter: 158	Loss: 0.17522	Acc= 26.046	Precision= 26.148	Recall= 25.842	F1_score= 25.590
2021-11-16 09:04:06,945 => Train: 100.0	Epoch: 42	Iter: 158	Loss: 0.17502	Acc= 25.099	Precision= 24.809	Recall= 24.811	F1_score= 24.297
2021-11-16 09:07:26,006 => 1.10.0
2021-11-16 09:07:26,008 => cuda
2021-11-16 09:07:26,536 => loading file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-cased-vocab.txt from cache at /home/yinan/.cache/torch/transformers/5e8a2b4893d13790ed4150ca1906be5f7a03d6c4ddf62296c383f6db42814db2.e13dbb970cb325137104fb2e5f36fe865f27746c6b526f6352861b1980eb80b1
2021-11-16 09:07:38,496 => -------------------------------------------------
2021-11-16 09:07:38,496 => 1 FOLD
2021-11-16 09:07:38,902 => loading configuration file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-cased-config.json from cache at /home/yinan/.cache/torch/transformers/b945b69218e98b3e2c95acf911789741307dec43c698d35fad11c1ae28bda352.9da767be51e1327499df13488672789394e2ca38b877837e52618a67d7002391
2021-11-16 09:07:38,903 => Model config BertConfig {
  "architectures": [
    "BertForMaskedLM"
  ],
  "attention_probs_dropout_prob": 0.1,
  "bos_token_id": null,
  "do_sample": false,
  "eos_token_ids": null,
  "finetuning_task": null,
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "hidden_size": 768,
  "id2label": {
    "0": "LABEL_0",
    "1": "LABEL_1"
  },
  "initializer_range": 0.02,
  "intermediate_size": 3072,
  "is_decoder": false,
  "label2id": {
    "LABEL_0": 0,
    "LABEL_1": 1
  },
  "layer_norm_eps": 1e-12,
  "length_penalty": 1.0,
  "max_length": 20,
  "max_position_embeddings": 512,
  "model_type": "bert",
  "num_attention_heads": 12,
  "num_beams": 1,
  "num_hidden_layers": 12,
  "num_labels": 4,
  "num_return_sequences": 1,
  "output_attentions": false,
  "output_hidden_states": false,
  "output_past": true,
  "pad_token_id": 0,
  "pruned_heads": {},
  "repetition_penalty": 1.0,
  "temperature": 1.0,
  "top_k": 50,
  "top_p": 1.0,
  "torchscript": false,
  "type_vocab_size": 2,
  "use_bfloat16": false,
  "vocab_size": 28996
}

2021-11-16 09:07:39,339 => loading weights file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-cased-pytorch_model.bin from cache at /home/yinan/.cache/torch/transformers/35d8b9d36faaf46728a0192d82bf7d00137490cd6074e8500778afed552a67e5.3fadbea36527ae472139fe84cddaa65454d7429f12d543d80bfc3ad70de55ac2
2021-11-16 09:07:43,174 => Weights of BertForSequenceClassification not initialized from pretrained model: ['classifier.weight', 'classifier.bias']
2021-11-16 09:07:43,175 => Weights from pretrained model not used in BertForSequenceClassification: ['cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias']
2021-11-16 09:12:47,960 => 1.10.0
2021-11-16 09:12:47,961 => cuda
2021-11-16 09:12:48,415 => loading file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-cased-vocab.txt from cache at /home/yinan/.cache/torch/transformers/5e8a2b4893d13790ed4150ca1906be5f7a03d6c4ddf62296c383f6db42814db2.e13dbb970cb325137104fb2e5f36fe865f27746c6b526f6352861b1980eb80b1
2021-11-16 09:13:00,257 => -------------------------------------------------
2021-11-16 09:13:00,257 => 1 FOLD
2021-11-16 09:13:00,667 => loading configuration file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-cased-config.json from cache at /home/yinan/.cache/torch/transformers/b945b69218e98b3e2c95acf911789741307dec43c698d35fad11c1ae28bda352.9da767be51e1327499df13488672789394e2ca38b877837e52618a67d7002391
2021-11-16 09:13:00,668 => Model config BertConfig {
  "architectures": [
    "BertForMaskedLM"
  ],
  "attention_probs_dropout_prob": 0.1,
  "bos_token_id": null,
  "do_sample": false,
  "eos_token_ids": null,
  "finetuning_task": null,
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "hidden_size": 768,
  "id2label": {
    "0": "LABEL_0",
    "1": "LABEL_1"
  },
  "initializer_range": 0.02,
  "intermediate_size": 3072,
  "is_decoder": false,
  "label2id": {
    "LABEL_0": 0,
    "LABEL_1": 1
  },
  "layer_norm_eps": 1e-12,
  "length_penalty": 1.0,
  "max_length": 20,
  "max_position_embeddings": 512,
  "model_type": "bert",
  "num_attention_heads": 12,
  "num_beams": 1,
  "num_hidden_layers": 12,
  "num_labels": 4,
  "num_return_sequences": 1,
  "output_attentions": false,
  "output_hidden_states": false,
  "output_past": true,
  "pad_token_id": 0,
  "pruned_heads": {},
  "repetition_penalty": 1.0,
  "temperature": 1.0,
  "top_k": 50,
  "top_p": 1.0,
  "torchscript": false,
  "type_vocab_size": 2,
  "use_bfloat16": false,
  "vocab_size": 28996
}

2021-11-16 09:13:01,061 => loading weights file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-cased-pytorch_model.bin from cache at /home/yinan/.cache/torch/transformers/35d8b9d36faaf46728a0192d82bf7d00137490cd6074e8500778afed552a67e5.3fadbea36527ae472139fe84cddaa65454d7429f12d543d80bfc3ad70de55ac2
2021-11-16 09:13:04,883 => Weights of BertForSequenceClassification not initialized from pretrained model: ['classifier.weight', 'classifier.bias']
2021-11-16 09:13:04,883 => Weights from pretrained model not used in BertForSequenceClassification: ['cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias']
2021-11-16 09:13:16,959 => 1.10.0
2021-11-16 09:13:16,960 => cuda
2021-11-16 09:13:17,368 => loading file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-cased-vocab.txt from cache at /home/yinan/.cache/torch/transformers/5e8a2b4893d13790ed4150ca1906be5f7a03d6c4ddf62296c383f6db42814db2.e13dbb970cb325137104fb2e5f36fe865f27746c6b526f6352861b1980eb80b1
2021-11-16 09:13:29,179 => -------------------------------------------------
2021-11-16 09:13:29,180 => 1 FOLD
2021-11-16 09:13:29,598 => loading configuration file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-cased-config.json from cache at /home/yinan/.cache/torch/transformers/b945b69218e98b3e2c95acf911789741307dec43c698d35fad11c1ae28bda352.9da767be51e1327499df13488672789394e2ca38b877837e52618a67d7002391
2021-11-16 09:13:29,600 => Model config BertConfig {
  "architectures": [
    "BertForMaskedLM"
  ],
  "attention_probs_dropout_prob": 0.1,
  "bos_token_id": null,
  "do_sample": false,
  "eos_token_ids": null,
  "finetuning_task": null,
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "hidden_size": 768,
  "id2label": {
    "0": "LABEL_0",
    "1": "LABEL_1"
  },
  "initializer_range": 0.02,
  "intermediate_size": 3072,
  "is_decoder": false,
  "label2id": {
    "LABEL_0": 0,
    "LABEL_1": 1
  },
  "layer_norm_eps": 1e-12,
  "length_penalty": 1.0,
  "max_length": 20,
  "max_position_embeddings": 512,
  "model_type": "bert",
  "num_attention_heads": 12,
  "num_beams": 1,
  "num_hidden_layers": 12,
  "num_labels": 4,
  "num_return_sequences": 1,
  "output_attentions": false,
  "output_hidden_states": false,
  "output_past": true,
  "pad_token_id": 0,
  "pruned_heads": {},
  "repetition_penalty": 1.0,
  "temperature": 1.0,
  "top_k": 50,
  "top_p": 1.0,
  "torchscript": false,
  "type_vocab_size": 2,
  "use_bfloat16": false,
  "vocab_size": 28996
}

2021-11-16 09:13:30,003 => loading weights file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-cased-pytorch_model.bin from cache at /home/yinan/.cache/torch/transformers/35d8b9d36faaf46728a0192d82bf7d00137490cd6074e8500778afed552a67e5.3fadbea36527ae472139fe84cddaa65454d7429f12d543d80bfc3ad70de55ac2
2021-11-16 09:13:33,626 => Weights of BertForSequenceClassification not initialized from pretrained model: ['classifier.weight', 'classifier.bias']
2021-11-16 09:13:33,627 => Weights from pretrained model not used in BertForSequenceClassification: ['cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias']
2021-11-16 09:13:44,756 => 1.10.0
2021-11-16 09:13:44,756 => cuda
2021-11-16 09:13:45,173 => loading file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-cased-vocab.txt from cache at /home/yinan/.cache/torch/transformers/5e8a2b4893d13790ed4150ca1906be5f7a03d6c4ddf62296c383f6db42814db2.e13dbb970cb325137104fb2e5f36fe865f27746c6b526f6352861b1980eb80b1
2021-11-16 09:13:57,351 => -------------------------------------------------
2021-11-16 09:13:57,351 => 1 FOLD
2021-11-16 09:13:57,770 => loading configuration file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-cased-config.json from cache at /home/yinan/.cache/torch/transformers/b945b69218e98b3e2c95acf911789741307dec43c698d35fad11c1ae28bda352.9da767be51e1327499df13488672789394e2ca38b877837e52618a67d7002391
2021-11-16 09:13:57,771 => Model config BertConfig {
  "architectures": [
    "BertForMaskedLM"
  ],
  "attention_probs_dropout_prob": 0.1,
  "bos_token_id": null,
  "do_sample": false,
  "eos_token_ids": null,
  "finetuning_task": null,
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "hidden_size": 768,
  "id2label": {
    "0": "LABEL_0",
    "1": "LABEL_1"
  },
  "initializer_range": 0.02,
  "intermediate_size": 3072,
  "is_decoder": false,
  "label2id": {
    "LABEL_0": 0,
    "LABEL_1": 1
  },
  "layer_norm_eps": 1e-12,
  "length_penalty": 1.0,
  "max_length": 20,
  "max_position_embeddings": 512,
  "model_type": "bert",
  "num_attention_heads": 12,
  "num_beams": 1,
  "num_hidden_layers": 12,
  "num_labels": 4,
  "num_return_sequences": 1,
  "output_attentions": false,
  "output_hidden_states": false,
  "output_past": true,
  "pad_token_id": 0,
  "pruned_heads": {},
  "repetition_penalty": 1.0,
  "temperature": 1.0,
  "top_k": 50,
  "top_p": 1.0,
  "torchscript": false,
  "type_vocab_size": 2,
  "use_bfloat16": false,
  "vocab_size": 28996
}

2021-11-16 09:13:58,162 => loading weights file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-cased-pytorch_model.bin from cache at /home/yinan/.cache/torch/transformers/35d8b9d36faaf46728a0192d82bf7d00137490cd6074e8500778afed552a67e5.3fadbea36527ae472139fe84cddaa65454d7429f12d543d80bfc3ad70de55ac2
2021-11-16 09:14:01,763 => Weights of BertForSequenceClassification not initialized from pretrained model: ['classifier.weight', 'classifier.bias']
2021-11-16 09:14:01,764 => Weights from pretrained model not used in BertForSequenceClassification: ['cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias']
2021-11-16 09:14:13,357 => 1.10.0
2021-11-16 09:14:13,357 => cuda
2021-11-16 09:14:13,768 => loading file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-cased-vocab.txt from cache at /home/yinan/.cache/torch/transformers/5e8a2b4893d13790ed4150ca1906be5f7a03d6c4ddf62296c383f6db42814db2.e13dbb970cb325137104fb2e5f36fe865f27746c6b526f6352861b1980eb80b1
2021-11-16 09:14:25,622 => -------------------------------------------------
2021-11-16 09:14:25,622 => 1 FOLD
2021-11-16 09:14:26,038 => loading configuration file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-cased-config.json from cache at /home/yinan/.cache/torch/transformers/b945b69218e98b3e2c95acf911789741307dec43c698d35fad11c1ae28bda352.9da767be51e1327499df13488672789394e2ca38b877837e52618a67d7002391
2021-11-16 09:14:26,039 => Model config BertConfig {
  "architectures": [
    "BertForMaskedLM"
  ],
  "attention_probs_dropout_prob": 0.1,
  "bos_token_id": null,
  "do_sample": false,
  "eos_token_ids": null,
  "finetuning_task": null,
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "hidden_size": 768,
  "id2label": {
    "0": "LABEL_0",
    "1": "LABEL_1"
  },
  "initializer_range": 0.02,
  "intermediate_size": 3072,
  "is_decoder": false,
  "label2id": {
    "LABEL_0": 0,
    "LABEL_1": 1
  },
  "layer_norm_eps": 1e-12,
  "length_penalty": 1.0,
  "max_length": 20,
  "max_position_embeddings": 512,
  "model_type": "bert",
  "num_attention_heads": 12,
  "num_beams": 1,
  "num_hidden_layers": 12,
  "num_labels": 4,
  "num_return_sequences": 1,
  "output_attentions": false,
  "output_hidden_states": false,
  "output_past": true,
  "pad_token_id": 0,
  "pruned_heads": {},
  "repetition_penalty": 1.0,
  "temperature": 1.0,
  "top_k": 50,
  "top_p": 1.0,
  "torchscript": false,
  "type_vocab_size": 2,
  "use_bfloat16": false,
  "vocab_size": 28996
}

2021-11-16 09:14:26,436 => loading weights file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-cased-pytorch_model.bin from cache at /home/yinan/.cache/torch/transformers/35d8b9d36faaf46728a0192d82bf7d00137490cd6074e8500778afed552a67e5.3fadbea36527ae472139fe84cddaa65454d7429f12d543d80bfc3ad70de55ac2
2021-11-16 09:14:30,053 => Weights of BertForSequenceClassification not initialized from pretrained model: ['classifier.weight', 'classifier.bias']
2021-11-16 09:14:30,053 => Weights from pretrained model not used in BertForSequenceClassification: ['cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias']
