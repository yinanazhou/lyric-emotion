2021-11-14 22:03:37,952 => 1.10.0
2021-11-14 22:03:37,953 => cuda
2021-11-14 22:03:38,341 => loading file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-cased-vocab.txt from cache at /home/yinan/.cache/torch/transformers/5e8a2b4893d13790ed4150ca1906be5f7a03d6c4ddf62296c383f6db42814db2.e13dbb970cb325137104fb2e5f36fe865f27746c6b526f6352861b1980eb80b1
2021-11-14 22:03:48,869 => -------------------------------------------------
2021-11-14 22:03:48,877 => 1 FOLD
2021-11-14 22:03:49,406 => loading configuration file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-cased-config.json from cache at /home/yinan/.cache/torch/transformers/b945b69218e98b3e2c95acf911789741307dec43c698d35fad11c1ae28bda352.9da767be51e1327499df13488672789394e2ca38b877837e52618a67d7002391
2021-11-14 22:03:49,407 => Model config BertConfig {
  "architectures": [
    "BertForMaskedLM"
  ],
  "attention_probs_dropout_prob": 0.1,
  "bos_token_id": null,
  "do_sample": false,
  "eos_token_ids": null,
  "finetuning_task": null,
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "hidden_size": 768,
  "id2label": {
    "0": "LABEL_0",
    "1": "LABEL_1"
  },
  "initializer_range": 0.02,
  "intermediate_size": 3072,
  "is_decoder": false,
  "label2id": {
    "LABEL_0": 0,
    "LABEL_1": 1
  },
  "layer_norm_eps": 1e-12,
  "length_penalty": 1.0,
  "max_length": 20,
  "max_position_embeddings": 512,
  "model_type": "bert",
  "num_attention_heads": 12,
  "num_beams": 1,
  "num_hidden_layers": 12,
  "num_labels": 4,
  "num_return_sequences": 1,
  "output_attentions": false,
  "output_hidden_states": false,
  "output_past": true,
  "pad_token_id": 0,
  "pruned_heads": {},
  "repetition_penalty": 1.0,
  "temperature": 1.0,
  "top_k": 50,
  "top_p": 1.0,
  "torchscript": false,
  "type_vocab_size": 2,
  "use_bfloat16": false,
  "vocab_size": 28996
}

2021-11-14 22:03:49,752 => loading weights file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-cased-pytorch_model.bin from cache at /home/yinan/.cache/torch/transformers/35d8b9d36faaf46728a0192d82bf7d00137490cd6074e8500778afed552a67e5.3fadbea36527ae472139fe84cddaa65454d7429f12d543d80bfc3ad70de55ac2
2021-11-14 22:03:53,334 => Weights of BertForSequenceClassification not initialized from pretrained model: ['classifier.weight', 'classifier.bias']
2021-11-14 22:03:53,334 => Weights from pretrained model not used in BertForSequenceClassification: ['cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias']
2021-11-14 22:07:05,414 => Train: 100.0	Epoch: 1	Iter: 79	Loss: 0.12310	Acc= 24.467	Precision= 24.532	Recall= 24.427	F1_score= 24.436
2021-11-14 22:09:58,776 => Train: 100.0	Epoch: 2	Iter: 79	Loss: 0.11522	Acc= 24.783	Precision= 24.820	Recall= 24.781	F1_score= 24.792
2021-11-14 22:12:52,943 => Train: 100.0	Epoch: 3	Iter: 79	Loss: 0.10837	Acc= 23.836	Precision= 23.797	Recall= 23.784	F1_score= 23.744
2021-11-14 22:15:46,075 => Train: 100.0	Epoch: 4	Iter: 79	Loss: 0.10299	Acc= 25.257	Precision= 25.203	Recall= 25.131	F1_score= 25.013
2021-11-14 22:18:39,300 => Train: 100.0	Epoch: 5	Iter: 79	Loss: 0.10337	Acc= 24.941	Precision= 24.757	Recall= 24.821	F1_score= 24.742
2021-11-14 22:21:31,712 => Train: 100.0	Epoch: 6	Iter: 79	Loss: 0.10224	Acc= 26.125	Precision= 25.941	Recall= 25.989	F1_score= 25.781
2021-11-14 22:24:24,828 => Train: 100.0	Epoch: 7	Iter: 79	Loss: 0.10552	Acc= 24.941	Precision= 24.722	Recall= 24.813	F1_score= 24.577
2021-11-14 22:27:17,250 => Train: 100.0	Epoch: 8	Iter: 79	Loss: 0.10717	Acc= 24.704	Precision= 24.580	Recall= 24.580	F1_score= 24.496
2021-11-14 22:30:09,149 => Train: 100.0	Epoch: 9	Iter: 79	Loss: 0.10243	Acc= 24.546	Precision= 24.544	Recall= 24.450	F1_score= 24.387
2021-11-14 22:33:01,687 => Train: 100.0	Epoch: 10	Iter: 79	Loss: 0.10154	Acc= 24.073	Precision= 23.933	Recall= 23.978	F1_score= 23.938
2021-11-14 22:35:53,836 => Train: 100.0	Epoch: 11	Iter: 79	Loss: 0.09825	Acc= 22.968	Precision= 22.862	Recall= 22.906	F1_score= 22.864
2021-11-14 22:38:47,916 => Train: 100.0	Epoch: 12	Iter: 79	Loss: 0.09589	Acc= 23.599	Precision= 23.402	Recall= 23.557	F1_score= 23.423
2021-11-14 22:41:50,964 => Train: 100.0	Epoch: 13	Iter: 79	Loss: 0.09413	Acc= 26.125	Precision= 26.205	Recall= 26.075	F1_score= 26.030
2021-11-14 22:44:43,303 => Train: 100.0	Epoch: 14	Iter: 79	Loss: 0.09373	Acc= 25.651	Precision= 25.480	Recall= 25.666	F1_score= 25.466
2021-11-14 22:47:36,241 => Train: 100.0	Epoch: 15	Iter: 79	Loss: 0.09376	Acc= 24.862	Precision= 24.736	Recall= 24.793	F1_score= 24.647
2021-11-14 22:50:29,157 => Train: 100.0	Epoch: 16	Iter: 79	Loss: 0.09277	Acc= 24.625	Precision= 24.551	Recall= 24.590	F1_score= 24.502
2021-11-14 22:53:22,180 => Train: 100.0	Epoch: 17	Iter: 79	Loss: 0.09190	Acc= 25.257	Precision= 25.149	Recall= 25.174	F1_score= 25.030
2021-11-14 22:56:28,027 => Train: 100.0	Epoch: 18	Iter: 79	Loss: 0.09185	Acc= 27.230	Precision= 27.303	Recall= 27.120	F1_score= 27.038
2021-11-14 22:59:22,942 => Train: 100.0	Epoch: 19	Iter: 79	Loss: 0.09238	Acc= 25.020	Precision= 24.827	Recall= 24.881	F1_score= 24.657
2021-11-14 23:02:16,730 => Train: 100.0	Epoch: 20	Iter: 79	Loss: 0.09305	Acc= 25.257	Precision= 25.221	Recall= 25.157	F1_score= 25.041
2021-11-14 23:02:22,847 => Eval: 100.0	Epoch: 20	Iter: 19	Loss: 0.09224	Acc= 25.237	Precision= 6.309	Recall= 25.000	F1_score= 10.076
2021-11-14 23:02:22,848 => -------------------------------------------------
2021-11-14 23:02:22,848 => 2 FOLD
2021-11-14 23:02:23,206 => loading configuration file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-cased-config.json from cache at /home/yinan/.cache/torch/transformers/b945b69218e98b3e2c95acf911789741307dec43c698d35fad11c1ae28bda352.9da767be51e1327499df13488672789394e2ca38b877837e52618a67d7002391
2021-11-14 23:02:23,207 => Model config BertConfig {
  "architectures": [
    "BertForMaskedLM"
  ],
  "attention_probs_dropout_prob": 0.1,
  "bos_token_id": null,
  "do_sample": false,
  "eos_token_ids": null,
  "finetuning_task": null,
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "hidden_size": 768,
  "id2label": {
    "0": "LABEL_0",
    "1": "LABEL_1"
  },
  "initializer_range": 0.02,
  "intermediate_size": 3072,
  "is_decoder": false,
  "label2id": {
    "LABEL_0": 0,
    "LABEL_1": 1
  },
  "layer_norm_eps": 1e-12,
  "length_penalty": 1.0,
  "max_length": 20,
  "max_position_embeddings": 512,
  "model_type": "bert",
  "num_attention_heads": 12,
  "num_beams": 1,
  "num_hidden_layers": 12,
  "num_labels": 4,
  "num_return_sequences": 1,
  "output_attentions": false,
  "output_hidden_states": false,
  "output_past": true,
  "pad_token_id": 0,
  "pruned_heads": {},
  "repetition_penalty": 1.0,
  "temperature": 1.0,
  "top_k": 50,
  "top_p": 1.0,
  "torchscript": false,
  "type_vocab_size": 2,
  "use_bfloat16": false,
  "vocab_size": 28996
}

2021-11-14 23:02:23,561 => loading weights file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-cased-pytorch_model.bin from cache at /home/yinan/.cache/torch/transformers/35d8b9d36faaf46728a0192d82bf7d00137490cd6074e8500778afed552a67e5.3fadbea36527ae472139fe84cddaa65454d7429f12d543d80bfc3ad70de55ac2
2021-11-14 23:02:27,061 => Weights of BertForSequenceClassification not initialized from pretrained model: ['classifier.weight', 'classifier.bias']
2021-11-14 23:02:27,061 => Weights from pretrained model not used in BertForSequenceClassification: ['cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias']
2021-11-14 23:05:28,142 => Train: 100.0	Epoch: 1	Iter: 79	Loss: 0.12173	Acc= 24.073	Precision= 23.833	Recall= 24.056	F1_score= 23.857
2021-11-14 23:08:20,701 => Train: 100.0	Epoch: 2	Iter: 79	Loss: 0.11106	Acc= 25.178	Precision= 25.105	Recall= 25.104	F1_score= 25.059
2021-11-14 23:11:12,406 => Train: 100.0	Epoch: 3	Iter: 79	Loss: 0.10660	Acc= 24.152	Precision= 24.031	Recall= 24.131	F1_score= 23.976
2021-11-14 23:14:05,002 => Train: 100.0	Epoch: 4	Iter: 79	Loss: 0.10396	Acc= 22.336	Precision= 22.293	Recall= 22.276	F1_score= 22.245
2021-11-14 23:16:57,967 => Train: 100.0	Epoch: 5	Iter: 79	Loss: 0.10193	Acc= 23.283	Precision= 23.172	Recall= 23.182	F1_score= 23.113
2021-11-14 23:19:50,584 => Train: 100.0	Epoch: 6	Iter: 79	Loss: 0.10241	Acc= 24.309	Precision= 24.252	Recall= 24.254	F1_score= 24.247
2021-11-14 23:22:42,565 => Train: 100.0	Epoch: 7	Iter: 79	Loss: 0.09915	Acc= 24.467	Precision= 24.491	Recall= 24.441	F1_score= 24.456
2021-11-14 23:25:35,624 => Train: 100.0	Epoch: 8	Iter: 79	Loss: 0.09810	Acc= 25.178	Precision= 25.033	Recall= 25.144	F1_score= 25.059
2021-11-14 23:28:28,559 => Train: 100.0	Epoch: 9	Iter: 79	Loss: 0.09761	Acc= 26.677	Precision= 26.658	Recall= 26.624	F1_score= 26.567
2021-11-14 23:31:21,426 => Train: 100.0	Epoch: 10	Iter: 79	Loss: 0.09699	Acc= 24.467	Precision= 24.506	Recall= 24.460	F1_score= 24.401
2021-11-14 23:34:14,204 => Train: 100.0	Epoch: 11	Iter: 79	Loss: 0.09764	Acc= 26.361	Precision= 26.640	Recall= 26.308	F1_score= 26.251
2021-11-14 23:37:07,541 => Train: 100.0	Epoch: 12	Iter: 79	Loss: 0.09628	Acc= 24.862	Precision= 24.842	Recall= 24.777	F1_score= 24.743
2021-11-14 23:40:12,536 => Train: 100.0	Epoch: 13	Iter: 79	Loss: 0.09514	Acc= 25.335	Precision= 25.272	Recall= 25.217	F1_score= 25.154
2021-11-14 23:43:04,918 => Train: 100.0	Epoch: 14	Iter: 79	Loss: 0.09458	Acc= 23.994	Precision= 23.818	Recall= 23.908	F1_score= 23.786
2021-11-14 23:45:57,963 => Train: 100.0	Epoch: 15	Iter: 79	Loss: 0.09284	Acc= 25.809	Precision= 25.800	Recall= 25.743	F1_score= 25.669
2021-11-14 23:48:50,496 => Train: 100.0	Epoch: 16	Iter: 79	Loss: 0.09338	Acc= 25.099	Precision= 24.889	Recall= 25.005	F1_score= 24.856
2021-11-14 23:51:43,590 => Train: 100.0	Epoch: 17	Iter: 79	Loss: 0.09253	Acc= 26.677	Precision= 26.554	Recall= 26.581	F1_score= 26.519
2021-11-14 23:54:43,462 => Train: 100.0	Epoch: 18	Iter: 79	Loss: 0.09280	Acc= 24.388	Precision= 24.169	Recall= 24.324	F1_score= 24.145
2021-11-14 23:57:36,354 => Train: 100.0	Epoch: 19	Iter: 79	Loss: 0.09259	Acc= 25.493	Precision= 25.496	Recall= 25.399	F1_score= 25.362
2021-11-15 00:00:28,572 => Train: 100.0	Epoch: 20	Iter: 79	Loss: 0.09259	Acc= 23.441	Precision= 23.342	Recall= 23.360	F1_score= 23.270
2021-11-15 00:00:34,616 => Eval: 100.0	Epoch: 20	Iter: 19	Loss: 0.08807	Acc= 24.921	Precision= 6.230	Recall= 25.000	F1_score= 9.975
2021-11-15 00:00:34,617 => -------------------------------------------------
2021-11-15 00:00:34,617 => 3 FOLD
2021-11-15 00:00:34,988 => loading configuration file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-cased-config.json from cache at /home/yinan/.cache/torch/transformers/b945b69218e98b3e2c95acf911789741307dec43c698d35fad11c1ae28bda352.9da767be51e1327499df13488672789394e2ca38b877837e52618a67d7002391
2021-11-15 00:00:34,989 => Model config BertConfig {
  "architectures": [
    "BertForMaskedLM"
  ],
  "attention_probs_dropout_prob": 0.1,
  "bos_token_id": null,
  "do_sample": false,
  "eos_token_ids": null,
  "finetuning_task": null,
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "hidden_size": 768,
  "id2label": {
    "0": "LABEL_0",
    "1": "LABEL_1"
  },
  "initializer_range": 0.02,
  "intermediate_size": 3072,
  "is_decoder": false,
  "label2id": {
    "LABEL_0": 0,
    "LABEL_1": 1
  },
  "layer_norm_eps": 1e-12,
  "length_penalty": 1.0,
  "max_length": 20,
  "max_position_embeddings": 512,
  "model_type": "bert",
  "num_attention_heads": 12,
  "num_beams": 1,
  "num_hidden_layers": 12,
  "num_labels": 4,
  "num_return_sequences": 1,
  "output_attentions": false,
  "output_hidden_states": false,
  "output_past": true,
  "pad_token_id": 0,
  "pruned_heads": {},
  "repetition_penalty": 1.0,
  "temperature": 1.0,
  "top_k": 50,
  "top_p": 1.0,
  "torchscript": false,
  "type_vocab_size": 2,
  "use_bfloat16": false,
  "vocab_size": 28996
}

2021-11-15 00:00:35,338 => loading weights file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-cased-pytorch_model.bin from cache at /home/yinan/.cache/torch/transformers/35d8b9d36faaf46728a0192d82bf7d00137490cd6074e8500778afed552a67e5.3fadbea36527ae472139fe84cddaa65454d7429f12d543d80bfc3ad70de55ac2
2021-11-15 00:00:38,856 => Weights of BertForSequenceClassification not initialized from pretrained model: ['classifier.weight', 'classifier.bias']
2021-11-15 00:00:38,856 => Weights from pretrained model not used in BertForSequenceClassification: ['cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias']
2021-11-15 00:03:41,673 => Train: 100.0	Epoch: 1	Iter: 79	Loss: 0.16242	Acc= 24.625	Precision= 24.496	Recall= 24.625	F1_score= 24.513
2021-11-15 00:06:33,988 => Train: 100.0	Epoch: 2	Iter: 79	Loss: 0.11051	Acc= 23.047	Precision= 23.174	Recall= 23.046	F1_score= 23.082
2021-11-15 00:09:25,077 => Train: 100.0	Epoch: 3	Iter: 79	Loss: 0.11100	Acc= 23.757	Precision= 23.728	Recall= 23.749	F1_score= 23.713
2021-11-15 00:12:16,600 => Train: 100.0	Epoch: 4	Iter: 79	Loss: 0.10767	Acc= 23.362	Precision= 23.409	Recall= 23.394	F1_score= 23.354
2021-11-15 00:15:07,400 => Train: 100.0	Epoch: 5	Iter: 79	Loss: 0.10396	Acc= 23.599	Precision= 23.625	Recall= 23.604	F1_score= 23.582
2021-11-15 00:17:58,856 => Train: 100.0	Epoch: 6	Iter: 79	Loss: 0.10181	Acc= 25.414	Precision= 25.465	Recall= 25.425	F1_score= 25.383
2021-11-15 00:20:50,914 => Train: 100.0	Epoch: 7	Iter: 79	Loss: 0.10003	Acc= 26.204	Precision= 26.195	Recall= 26.242	F1_score= 26.132
2021-11-15 00:23:43,077 => Train: 100.0	Epoch: 8	Iter: 79	Loss: 0.09921	Acc= 25.967	Precision= 25.998	Recall= 25.983	F1_score= 25.840
2021-11-15 00:26:35,033 => Train: 100.0	Epoch: 9	Iter: 79	Loss: 0.09866	Acc= 24.152	Precision= 24.067	Recall= 24.151	F1_score= 24.049
2021-11-15 00:29:26,649 => Train: 100.0	Epoch: 10	Iter: 79	Loss: 0.09781	Acc= 25.809	Precision= 25.858	Recall= 25.807	F1_score= 25.728
2021-11-15 00:32:18,379 => Train: 100.0	Epoch: 11	Iter: 79	Loss: 0.09851	Acc= 26.993	Precision= 26.759	Recall= 26.968	F1_score= 26.753
2021-11-15 00:35:10,878 => Train: 100.0	Epoch: 12	Iter: 79	Loss: 0.09938	Acc= 25.572	Precision= 25.319	Recall= 25.477	F1_score= 25.265
2021-11-15 00:38:12,923 => Train: 100.0	Epoch: 13	Iter: 79	Loss: 0.09947	Acc= 25.335	Precision= 25.084	Recall= 25.228	F1_score= 24.913
2021-11-15 00:41:04,718 => Train: 100.0	Epoch: 14	Iter: 79	Loss: 0.09586	Acc= 25.730	Precision= 25.714	Recall= 25.640	F1_score= 25.486
2021-11-15 00:43:56,886 => Train: 100.0	Epoch: 15	Iter: 79	Loss: 0.09490	Acc= 24.546	Precision= 24.464	Recall= 24.488	F1_score= 24.330
2021-11-15 00:46:48,798 => Train: 100.0	Epoch: 16	Iter: 79	Loss: 0.09375	Acc= 26.046	Precision= 26.176	Recall= 25.961	F1_score= 25.851
2021-11-15 00:49:41,650 => Train: 100.0	Epoch: 17	Iter: 79	Loss: 0.09311	Acc= 24.862	Precision= 24.661	Recall= 24.766	F1_score= 24.557
2021-11-15 00:52:45,039 => Train: 100.0	Epoch: 18	Iter: 79	Loss: 0.09261	Acc= 25.809	Precision= 25.766	Recall= 25.761	F1_score= 25.618
2021-11-15 00:55:37,302 => Train: 100.0	Epoch: 19	Iter: 79	Loss: 0.09311	Acc= 24.152	Precision= 24.040	Recall= 24.112	F1_score= 23.960
2021-11-15 00:58:28,899 => Train: 100.0	Epoch: 20	Iter: 79	Loss: 0.09163	Acc= 25.888	Precision= 25.850	Recall= 25.806	F1_score= 25.739
2021-11-15 00:58:34,943 => Eval: 100.0	Epoch: 20	Iter: 19	Loss: 0.08910	Acc= 25.552	Precision= 6.388	Recall= 25.000	F1_score= 10.176
2021-11-15 00:58:34,943 => -------------------------------------------------
2021-11-15 00:58:34,943 => 4 FOLD
2021-11-15 00:58:35,362 => loading configuration file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-cased-config.json from cache at /home/yinan/.cache/torch/transformers/b945b69218e98b3e2c95acf911789741307dec43c698d35fad11c1ae28bda352.9da767be51e1327499df13488672789394e2ca38b877837e52618a67d7002391
2021-11-15 00:58:35,363 => Model config BertConfig {
  "architectures": [
    "BertForMaskedLM"
  ],
  "attention_probs_dropout_prob": 0.1,
  "bos_token_id": null,
  "do_sample": false,
  "eos_token_ids": null,
  "finetuning_task": null,
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "hidden_size": 768,
  "id2label": {
    "0": "LABEL_0",
    "1": "LABEL_1"
  },
  "initializer_range": 0.02,
  "intermediate_size": 3072,
  "is_decoder": false,
  "label2id": {
    "LABEL_0": 0,
    "LABEL_1": 1
  },
  "layer_norm_eps": 1e-12,
  "length_penalty": 1.0,
  "max_length": 20,
  "max_position_embeddings": 512,
  "model_type": "bert",
  "num_attention_heads": 12,
  "num_beams": 1,
  "num_hidden_layers": 12,
  "num_labels": 4,
  "num_return_sequences": 1,
  "output_attentions": false,
  "output_hidden_states": false,
  "output_past": true,
  "pad_token_id": 0,
  "pruned_heads": {},
  "repetition_penalty": 1.0,
  "temperature": 1.0,
  "top_k": 50,
  "top_p": 1.0,
  "torchscript": false,
  "type_vocab_size": 2,
  "use_bfloat16": false,
  "vocab_size": 28996
}

2021-11-15 00:58:35,719 => loading weights file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-cased-pytorch_model.bin from cache at /home/yinan/.cache/torch/transformers/35d8b9d36faaf46728a0192d82bf7d00137490cd6074e8500778afed552a67e5.3fadbea36527ae472139fe84cddaa65454d7429f12d543d80bfc3ad70de55ac2
2021-11-15 00:58:39,443 => Weights of BertForSequenceClassification not initialized from pretrained model: ['classifier.weight', 'classifier.bias']
2021-11-15 00:58:39,444 => Weights from pretrained model not used in BertForSequenceClassification: ['cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias']
2021-11-15 01:01:46,713 => Train: 100.0	Epoch: 1	Iter: 79	Loss: 0.12523	Acc= 24.388	Precision= 24.605	Recall= 24.390	F1_score= 24.375
2021-11-15 01:04:35,441 => Train: 100.0	Epoch: 2	Iter: 79	Loss: 0.10858	Acc= 26.125	Precision= 26.068	Recall= 26.099	F1_score= 26.064
2021-11-15 01:07:24,396 => Train: 100.0	Epoch: 3	Iter: 79	Loss: 0.10993	Acc= 25.651	Precision= 25.642	Recall= 25.639	F1_score= 25.600
2021-11-15 01:10:13,434 => Train: 100.0	Epoch: 4	Iter: 79	Loss: 0.10565	Acc= 26.125	Precision= 26.196	Recall= 26.112	F1_score= 26.010
2021-11-15 01:13:02,355 => Train: 100.0	Epoch: 5	Iter: 79	Loss: 0.10463	Acc= 25.651	Precision= 25.752	Recall= 25.637	F1_score= 25.633
2021-11-15 01:15:51,056 => Train: 100.0	Epoch: 6	Iter: 79	Loss: 0.10702	Acc= 25.493	Precision= 25.332	Recall= 25.448	F1_score= 25.208
2021-11-15 01:18:40,069 => Train: 100.0	Epoch: 7	Iter: 79	Loss: 0.10148	Acc= 24.704	Precision= 24.716	Recall= 24.681	F1_score= 24.660
2021-11-15 01:21:29,950 => Train: 100.0	Epoch: 8	Iter: 79	Loss: 0.10020	Acc= 25.493	Precision= 25.374	Recall= 25.468	F1_score= 25.345
2021-11-15 01:24:18,343 => Train: 100.0	Epoch: 9	Iter: 79	Loss: 0.10006	Acc= 25.099	Precision= 24.897	Recall= 25.085	F1_score= 24.894
2021-11-15 01:27:07,332 => Train: 100.0	Epoch: 10	Iter: 79	Loss: 0.09850	Acc= 25.888	Precision= 25.948	Recall= 25.882	F1_score= 25.806
2021-11-15 01:29:56,372 => Train: 100.0	Epoch: 11	Iter: 79	Loss: 0.09811	Acc= 23.678	Precision= 23.438	Recall= 23.671	F1_score= 23.372
2021-11-15 01:32:46,066 => Train: 100.0	Epoch: 12	Iter: 79	Loss: 0.09617	Acc= 24.862	Precision= 24.596	Recall= 24.846	F1_score= 24.474
2021-11-15 01:36:23,481 => Train: 100.0	Epoch: 13	Iter: 79	Loss: 0.09610	Acc= 23.757	Precision= 23.810	Recall= 23.744	F1_score= 23.592
2021-11-15 01:39:12,283 => Train: 100.0	Epoch: 14	Iter: 79	Loss: 0.09477	Acc= 24.625	Precision= 24.882	Recall= 24.607	F1_score= 24.530
2021-11-15 01:42:01,223 => Train: 100.0	Epoch: 15	Iter: 79	Loss: 0.09312	Acc= 26.677	Precision= 26.640	Recall= 26.684	F1_score= 26.598
2021-11-15 01:44:49,955 => Train: 100.0	Epoch: 16	Iter: 79	Loss: 0.09194	Acc= 24.862	Precision= 24.938	Recall= 24.861	F1_score= 24.853
2021-11-15 01:47:39,330 => Train: 100.0	Epoch: 17	Iter: 79	Loss: 0.09199	Acc= 25.651	Precision= 25.781	Recall= 25.678	F1_score= 25.658
2021-11-15 01:50:36,963 => Train: 100.0	Epoch: 18	Iter: 79	Loss: 0.09281	Acc= 25.257	Precision= 25.302	Recall= 25.262	F1_score= 25.220
2021-11-15 01:53:26,441 => Train: 100.0	Epoch: 19	Iter: 79	Loss: 0.09198	Acc= 24.783	Precision= 24.814	Recall= 24.782	F1_score= 24.783
2021-11-15 01:56:15,036 => Train: 100.0	Epoch: 20	Iter: 79	Loss: 0.09171	Acc= 26.125	Precision= 26.133	Recall= 26.132	F1_score= 26.075
2021-11-15 01:56:21,148 => Eval: 100.0	Epoch: 20	Iter: 19	Loss: 0.08906	Acc= 29.022	Precision= 7.256	Recall= 25.000	F1_score= 11.247
2021-11-15 01:56:21,149 => -------------------------------------------------
2021-11-15 01:56:21,149 => 5 FOLD
2021-11-15 01:56:21,545 => loading configuration file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-cased-config.json from cache at /home/yinan/.cache/torch/transformers/b945b69218e98b3e2c95acf911789741307dec43c698d35fad11c1ae28bda352.9da767be51e1327499df13488672789394e2ca38b877837e52618a67d7002391
2021-11-15 01:56:21,545 => Model config BertConfig {
  "architectures": [
    "BertForMaskedLM"
  ],
  "attention_probs_dropout_prob": 0.1,
  "bos_token_id": null,
  "do_sample": false,
  "eos_token_ids": null,
  "finetuning_task": null,
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "hidden_size": 768,
  "id2label": {
    "0": "LABEL_0",
    "1": "LABEL_1"
  },
  "initializer_range": 0.02,
  "intermediate_size": 3072,
  "is_decoder": false,
  "label2id": {
    "LABEL_0": 0,
    "LABEL_1": 1
  },
  "layer_norm_eps": 1e-12,
  "length_penalty": 1.0,
  "max_length": 20,
  "max_position_embeddings": 512,
  "model_type": "bert",
  "num_attention_heads": 12,
  "num_beams": 1,
  "num_hidden_layers": 12,
  "num_labels": 4,
  "num_return_sequences": 1,
  "output_attentions": false,
  "output_hidden_states": false,
  "output_past": true,
  "pad_token_id": 0,
  "pruned_heads": {},
  "repetition_penalty": 1.0,
  "temperature": 1.0,
  "top_k": 50,
  "top_p": 1.0,
  "torchscript": false,
  "type_vocab_size": 2,
  "use_bfloat16": false,
  "vocab_size": 28996
}

2021-11-15 01:56:21,930 => loading weights file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-cased-pytorch_model.bin from cache at /home/yinan/.cache/torch/transformers/35d8b9d36faaf46728a0192d82bf7d00137490cd6074e8500778afed552a67e5.3fadbea36527ae472139fe84cddaa65454d7429f12d543d80bfc3ad70de55ac2
2021-11-15 01:56:25,765 => Weights of BertForSequenceClassification not initialized from pretrained model: ['classifier.weight', 'classifier.bias']
2021-11-15 01:56:25,766 => Weights from pretrained model not used in BertForSequenceClassification: ['cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias']
2021-11-15 01:59:24,042 => Train: 100.0	Epoch: 1	Iter: 79	Loss: 0.14732	Acc= 25.631	Precision= 25.596	Recall= 25.620	F1_score= 25.586
2021-11-15 02:02:13,926 => Train: 100.0	Epoch: 2	Iter: 79	Loss: 0.10924	Acc= 25.158	Precision= 25.118	Recall= 25.117	F1_score= 25.116
2021-11-15 02:05:11,870 => Train: 100.0	Epoch: 3	Iter: 79	Loss: 0.10606	Acc= 25.315	Precision= 25.257	Recall= 25.241	F1_score= 25.243
2021-11-15 02:08:01,339 => Train: 100.0	Epoch: 4	Iter: 79	Loss: 0.10700	Acc= 26.025	Precision= 25.962	Recall= 25.942	F1_score= 25.916
2021-11-15 02:10:50,612 => Train: 100.0	Epoch: 5	Iter: 79	Loss: 0.11082	Acc= 27.129	Precision= 27.035	Recall= 26.996	F1_score= 26.915
2021-11-15 02:13:40,040 => Train: 100.0	Epoch: 6	Iter: 79	Loss: 0.10898	Acc= 24.763	Precision= 24.830	Recall= 24.741	F1_score= 24.747
2021-11-15 02:16:28,815 => Train: 100.0	Epoch: 7	Iter: 79	Loss: 0.10879	Acc= 24.132	Precision= 24.160	Recall= 24.123	F1_score= 23.994
2021-11-15 02:19:18,763 => Train: 100.0	Epoch: 8	Iter: 79	Loss: 0.10237	Acc= 23.502	Precision= 23.462	Recall= 23.441	F1_score= 23.411
2021-11-15 02:22:07,973 => Train: 100.0	Epoch: 9	Iter: 79	Loss: 0.10018	Acc= 22.950	Precision= 22.881	Recall= 22.822	F1_score= 22.805
2021-11-15 02:24:57,283 => Train: 100.0	Epoch: 10	Iter: 79	Loss: 0.09600	Acc= 23.975	Precision= 23.767	Recall= 23.839	F1_score= 23.766
2021-11-15 02:27:47,233 => Train: 100.0	Epoch: 11	Iter: 79	Loss: 0.09645	Acc= 25.079	Precision= 25.009	Recall= 25.011	F1_score= 24.970
2021-11-15 02:30:36,504 => Train: 100.0	Epoch: 12	Iter: 79	Loss: 0.09458	Acc= 23.502	Precision= 23.339	Recall= 23.365	F1_score= 23.272
2021-11-15 02:34:20,057 => Train: 100.0	Epoch: 13	Iter: 79	Loss: 0.09418	Acc= 25.000	Precision= 24.548	Recall= 24.866	F1_score= 24.572
2021-11-15 02:37:09,355 => Train: 100.0	Epoch: 14	Iter: 79	Loss: 0.09382	Acc= 25.000	Precision= 24.801	Recall= 24.894	F1_score= 24.736
2021-11-15 02:39:58,441 => Train: 100.0	Epoch: 15	Iter: 79	Loss: 0.09311	Acc= 25.710	Precision= 25.860	Recall= 25.660	F1_score= 25.642
2021-11-15 02:42:47,922 => Train: 100.0	Epoch: 16	Iter: 79	Loss: 0.09248	Acc= 25.079	Precision= 24.925	Recall= 24.947	F1_score= 24.721
2021-11-15 02:45:37,308 => Train: 100.0	Epoch: 17	Iter: 79	Loss: 0.09275	Acc= 25.552	Precision= 25.490	Recall= 25.442	F1_score= 25.262
2021-11-15 02:48:40,494 => Train: 100.0	Epoch: 18	Iter: 79	Loss: 0.09315	Acc= 25.868	Precision= 25.332	Recall= 25.751	F1_score= 25.263
2021-11-15 02:51:30,886 => Train: 100.0	Epoch: 19	Iter: 79	Loss: 0.09230	Acc= 24.448	Precision= 24.351	Recall= 24.285	F1_score= 24.134
2021-11-15 02:54:20,108 => Train: 100.0	Epoch: 20	Iter: 79	Loss: 0.09235	Acc= 25.158	Precision= 25.164	Recall= 25.036	F1_score= 24.943
2021-11-15 02:54:26,160 => Eval: 100.0	Epoch: 20	Iter: 19	Loss: 0.08800	Acc= 25.949	Precision= 6.487	Recall= 25.000	F1_score= 10.302
2021-11-15 02:54:26,160 => AVERAGE ACCURACY: 26.136
