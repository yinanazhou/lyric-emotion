2021-11-16 01:05:41,058 => 1.10.0
2021-11-16 01:05:41,059 => cuda
2021-11-16 01:05:41,545 => loading file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-cased-vocab.txt from cache at /home/yinan/.cache/torch/transformers/5e8a2b4893d13790ed4150ca1906be5f7a03d6c4ddf62296c383f6db42814db2.e13dbb970cb325137104fb2e5f36fe865f27746c6b526f6352861b1980eb80b1
2021-11-16 01:05:53,453 => -------------------------------------------------
2021-11-16 01:05:53,453 => 1 FOLD
2021-11-16 01:05:54,093 => loading configuration file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-cased-config.json from cache at /home/yinan/.cache/torch/transformers/b945b69218e98b3e2c95acf911789741307dec43c698d35fad11c1ae28bda352.9da767be51e1327499df13488672789394e2ca38b877837e52618a67d7002391
2021-11-16 01:05:54,094 => Model config BertConfig {
  "architectures": [
    "BertForMaskedLM"
  ],
  "attention_probs_dropout_prob": 0.1,
  "bos_token_id": null,
  "do_sample": false,
  "eos_token_ids": null,
  "finetuning_task": null,
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "hidden_size": 768,
  "id2label": {
    "0": "LABEL_0",
    "1": "LABEL_1"
  },
  "initializer_range": 0.02,
  "intermediate_size": 3072,
  "is_decoder": false,
  "label2id": {
    "LABEL_0": 0,
    "LABEL_1": 1
  },
  "layer_norm_eps": 1e-12,
  "length_penalty": 1.0,
  "max_length": 20,
  "max_position_embeddings": 512,
  "model_type": "bert",
  "num_attention_heads": 12,
  "num_beams": 1,
  "num_hidden_layers": 12,
  "num_labels": 4,
  "num_return_sequences": 1,
  "output_attentions": false,
  "output_hidden_states": false,
  "output_past": true,
  "pad_token_id": 0,
  "pruned_heads": {},
  "repetition_penalty": 1.0,
  "temperature": 1.0,
  "top_k": 50,
  "top_p": 1.0,
  "torchscript": false,
  "type_vocab_size": 2,
  "use_bfloat16": false,
  "vocab_size": 28996
}

2021-11-16 01:05:54,527 => loading weights file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-cased-pytorch_model.bin from cache at /home/yinan/.cache/torch/transformers/35d8b9d36faaf46728a0192d82bf7d00137490cd6074e8500778afed552a67e5.3fadbea36527ae472139fe84cddaa65454d7429f12d543d80bfc3ad70de55ac2
2021-11-16 01:05:58,525 => Weights of BertForSequenceClassification not initialized from pretrained model: ['classifier.weight', 'classifier.bias']
2021-11-16 01:05:58,525 => Weights from pretrained model not used in BertForSequenceClassification: ['cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias']
2021-11-16 01:09:51,859 => Train: 100.0	Epoch: 1	Iter: 158	Loss: 1.78675	Acc= 25.020	Precision= 24.970	Recall= 24.957	F1_score= 24.963
2021-11-16 01:13:19,936 => Train: 100.0	Epoch: 2	Iter: 158	Loss: 1.34057	Acc= 24.862	Precision= 24.774	Recall= 24.770	F1_score= 24.772
2021-11-16 01:17:12,254 => Train: 100.0	Epoch: 3	Iter: 158	Loss: 1.54229	Acc= 23.362	Precision= 23.323	Recall= 23.316	F1_score= 23.319
2021-11-16 01:20:39,822 => Train: 100.0	Epoch: 4	Iter: 158	Loss: 1.29638	Acc= 26.046	Precision= 25.877	Recall= 25.902	F1_score= 25.885
2021-11-16 01:24:05,501 => early stopped at loss: 0.04262
2021-11-16 01:24:05,506 => Train:  99.8	Epoch: 5	Iter: 158	Loss: 1.24635	Acc= 25.475	Precision= 25.194	Recall= 25.173	F1_score= 25.182
2021-11-16 01:28:02,698 => Train: 100.0	Epoch: 6	Iter: 158	Loss: 0.95634	Acc= 24.862	Precision= 24.864	Recall= 24.861	F1_score= 24.859
2021-11-16 01:32:06,842 => Train: 100.0	Epoch: 7	Iter: 158	Loss: 0.90311	Acc= 23.599	Precision= 23.521	Recall= 23.528	F1_score= 23.523
2021-11-16 01:35:38,737 => Train: 100.0	Epoch: 8	Iter: 158	Loss: 0.88662	Acc= 25.967	Precision= 25.961	Recall= 25.942	F1_score= 25.948
2021-11-16 01:39:07,466 => Train: 100.0	Epoch: 9	Iter: 158	Loss: 0.81980	Acc= 27.072	Precision= 27.105	Recall= 27.098	F1_score= 27.101
2021-11-16 01:42:38,962 => Train: 100.0	Epoch: 10	Iter: 158	Loss: 0.72677	Acc= 25.809	Precision= 25.753	Recall= 25.748	F1_score= 25.750
2021-11-16 01:46:06,982 => Train: 100.0	Epoch: 11	Iter: 158	Loss: 0.66335	Acc= 25.730	Precision= 25.617	Recall= 25.622	F1_score= 25.617
2021-11-16 01:49:34,523 => Train: 100.0	Epoch: 12	Iter: 158	Loss: 0.63151	Acc= 26.361	Precision= 26.221	Recall= 26.257	F1_score= 26.234
2021-11-16 01:53:01,666 => Train: 100.0	Epoch: 13	Iter: 158	Loss: 0.61522	Acc= 24.546	Precision= 24.462	Recall= 24.467	F1_score= 24.459
2021-11-16 01:56:28,905 => Train: 100.0	Epoch: 14	Iter: 158	Loss: 0.58587	Acc= 24.309	Precision= 24.222	Recall= 24.232	F1_score= 24.226
2021-11-16 01:59:58,541 => Train: 100.0	Epoch: 15	Iter: 158	Loss: 0.49557	Acc= 24.388	Precision= 24.401	Recall= 24.382	F1_score= 24.388
2021-11-16 02:03:28,021 => Train: 100.0	Epoch: 16	Iter: 158	Loss: 0.46524	Acc= 25.335	Precision= 25.303	Recall= 25.319	F1_score= 25.309
2021-11-16 02:06:58,128 => Train: 100.0	Epoch: 17	Iter: 158	Loss: 0.47350	Acc= 24.783	Precision= 24.779	Recall= 24.763	F1_score= 24.769
2021-11-16 02:10:28,046 => Train: 100.0	Epoch: 18	Iter: 158	Loss: 0.38130	Acc= 25.257	Precision= 25.216	Recall= 25.206	F1_score= 25.208
2021-11-16 02:13:56,688 => Train: 100.0	Epoch: 19	Iter: 158	Loss: 0.37934	Acc= 25.572	Precision= 25.518	Recall= 25.476	F1_score= 25.484
2021-11-16 02:17:45,151 => Train: 100.0	Epoch: 20	Iter: 158	Loss: 0.38207	Acc= 25.888	Precision= 25.854	Recall= 25.884	F1_score= 25.857
2021-11-16 02:21:12,932 => Train: 100.0	Epoch: 21	Iter: 158	Loss: 0.32709	Acc= 25.099	Precision= 25.013	Recall= 25.003	F1_score= 25.000
2021-11-16 02:24:41,932 => Train: 100.0	Epoch: 22	Iter: 158	Loss: 0.32763	Acc= 25.414	Precision= 25.409	Recall= 25.390	F1_score= 25.386
2021-11-16 02:28:12,488 => Train: 100.0	Epoch: 23	Iter: 158	Loss: 0.31227	Acc= 24.073	Precision= 24.143	Recall= 24.096	F1_score= 24.113
2021-11-16 02:31:46,457 => Train: 100.0	Epoch: 24	Iter: 158	Loss: 0.30124	Acc= 24.783	Precision= 24.672	Recall= 24.713	F1_score= 24.688
2021-11-16 02:35:26,504 => Train: 100.0	Epoch: 25	Iter: 158	Loss: 0.27130	Acc= 25.493	Precision= 25.416	Recall= 25.432	F1_score= 25.420
2021-11-16 02:40:51,481 => Train: 100.0	Epoch: 26	Iter: 158	Loss: 0.26050	Acc= 24.862	Precision= 24.805	Recall= 24.827	F1_score= 24.813
2021-11-16 02:44:22,970 => Train: 100.0	Epoch: 27	Iter: 158	Loss: 0.26500	Acc= 25.099	Precision= 25.055	Recall= 25.053	F1_score= 25.054
2021-11-16 02:47:52,195 => Train: 100.0	Epoch: 28	Iter: 158	Loss: 0.25270	Acc= 24.073	Precision= 23.825	Recall= 23.887	F1_score= 23.832
2021-11-16 02:51:24,967 => Train: 100.0	Epoch: 29	Iter: 158	Loss: 0.24867	Acc= 24.783	Precision= 24.683	Recall= 24.693	F1_score= 24.686
2021-11-16 02:55:00,335 => Train: 100.0	Epoch: 30	Iter: 158	Loss: 0.23992	Acc= 25.257	Precision= 25.260	Recall= 25.180	F1_score= 25.197
2021-11-16 02:58:33,697 => Train: 100.0	Epoch: 31	Iter: 158	Loss: 0.23293	Acc= 25.493	Precision= 25.309	Recall= 25.322	F1_score= 25.312
2021-11-16 03:03:40,248 => Train: 100.0	Epoch: 32	Iter: 158	Loss: 0.22799	Acc= 26.835	Precision= 26.586	Recall= 26.621	F1_score= 26.581
2021-11-16 03:07:12,289 => Train: 100.0	Epoch: 33	Iter: 158	Loss: 0.23251	Acc= 25.020	Precision= 24.918	Recall= 24.919	F1_score= 24.903
2021-11-16 03:10:43,668 => Train: 100.0	Epoch: 34	Iter: 158	Loss: 0.22997	Acc= 25.257	Precision= 25.165	Recall= 25.139	F1_score= 25.137
2021-11-16 03:14:11,588 => Train: 100.0	Epoch: 35	Iter: 158	Loss: 0.21689	Acc= 25.888	Precision= 25.823	Recall= 25.788	F1_score= 25.788
2021-11-16 03:17:45,058 => Train: 100.0	Epoch: 36	Iter: 158	Loss: 0.21456	Acc= 26.361	Precision= 26.372	Recall= 26.322	F1_score= 26.334
2021-11-16 03:21:16,911 => Train: 100.0	Epoch: 37	Iter: 158	Loss: 0.21654	Acc= 25.651	Precision= 25.574	Recall= 25.572	F1_score= 25.571
2021-11-16 03:24:51,115 => Train: 100.0	Epoch: 38	Iter: 158	Loss: 0.21357	Acc= 26.046	Precision= 25.963	Recall= 25.976	F1_score= 25.965
2021-11-16 03:28:26,387 => Train: 100.0	Epoch: 39	Iter: 158	Loss: 0.21598	Acc= 25.020	Precision= 24.829	Recall= 24.861	F1_score= 24.841
2021-11-16 03:31:58,826 => Train: 100.0	Epoch: 40	Iter: 158	Loss: 0.21148	Acc= 24.467	Precision= 24.331	Recall= 24.367	F1_score= 24.340
2021-11-16 03:35:30,578 => Train: 100.0	Epoch: 41	Iter: 158	Loss: 0.21556	Acc= 23.283	Precision= 23.061	Recall= 23.114	F1_score= 23.043
2021-11-16 03:39:06,313 => Train: 100.0	Epoch: 42	Iter: 158	Loss: 0.21119	Acc= 24.467	Precision= 24.481	Recall= 24.499	F1_score= 24.481
2021-11-16 03:42:38,122 => Train: 100.0	Epoch: 43	Iter: 158	Loss: 0.20509	Acc= 25.493	Precision= 25.404	Recall= 25.407	F1_score= 25.404
2021-11-16 03:46:10,846 => Train: 100.0	Epoch: 44	Iter: 158	Loss: 0.20227	Acc= 24.783	Precision= 24.823	Recall= 24.829	F1_score= 24.820
2021-11-16 03:51:49,199 => Train: 100.0	Epoch: 45	Iter: 158	Loss: 0.20079	Acc= 25.414	Precision= 25.381	Recall= 25.364	F1_score= 25.365
2021-11-16 03:55:20,518 => Train: 100.0	Epoch: 46	Iter: 158	Loss: 0.20582	Acc= 23.757	Precision= 23.753	Recall= 23.730	F1_score= 23.733
2021-11-16 03:58:51,405 => Train: 100.0	Epoch: 47	Iter: 158	Loss: 0.20311	Acc= 24.152	Precision= 23.974	Recall= 23.999	F1_score= 23.982
2021-11-16 04:02:22,554 => Train: 100.0	Epoch: 48	Iter: 158	Loss: 0.20124	Acc= 25.493	Precision= 25.312	Recall= 25.350	F1_score= 25.322
2021-11-16 04:05:53,384 => Train: 100.0	Epoch: 49	Iter: 158	Loss: 0.20088	Acc= 23.678	Precision= 23.590	Recall= 23.598	F1_score= 23.566
2021-11-16 04:09:30,147 => Train: 100.0	Epoch: 50	Iter: 158	Loss: 0.19715	Acc= 25.730	Precision= 25.685	Recall= 25.679	F1_score= 25.676
2021-11-16 04:09:33,542 => Eval: 100.0	Epoch: 50	Iter: 39	Loss: 0.18203	Acc= 26.814	Precision= 6.703	Recall= 25.000	F1_score= 10.572
2021-11-16 04:09:33,542 => -------------------------------------------------
2021-11-16 04:09:33,542 => 2 FOLD
2021-11-16 04:09:33,989 => loading configuration file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-cased-config.json from cache at /home/yinan/.cache/torch/transformers/b945b69218e98b3e2c95acf911789741307dec43c698d35fad11c1ae28bda352.9da767be51e1327499df13488672789394e2ca38b877837e52618a67d7002391
2021-11-16 04:09:33,990 => Model config BertConfig {
  "architectures": [
    "BertForMaskedLM"
  ],
  "attention_probs_dropout_prob": 0.1,
  "bos_token_id": null,
  "do_sample": false,
  "eos_token_ids": null,
  "finetuning_task": null,
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "hidden_size": 768,
  "id2label": {
    "0": "LABEL_0",
    "1": "LABEL_1"
  },
  "initializer_range": 0.02,
  "intermediate_size": 3072,
  "is_decoder": false,
  "label2id": {
    "LABEL_0": 0,
    "LABEL_1": 1
  },
  "layer_norm_eps": 1e-12,
  "length_penalty": 1.0,
  "max_length": 20,
  "max_position_embeddings": 512,
  "model_type": "bert",
  "num_attention_heads": 12,
  "num_beams": 1,
  "num_hidden_layers": 12,
  "num_labels": 4,
  "num_return_sequences": 1,
  "output_attentions": false,
  "output_hidden_states": false,
  "output_past": true,
  "pad_token_id": 0,
  "pruned_heads": {},
  "repetition_penalty": 1.0,
  "temperature": 1.0,
  "top_k": 50,
  "top_p": 1.0,
  "torchscript": false,
  "type_vocab_size": 2,
  "use_bfloat16": false,
  "vocab_size": 28996
}

2021-11-16 04:09:34,396 => loading weights file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-cased-pytorch_model.bin from cache at /home/yinan/.cache/torch/transformers/35d8b9d36faaf46728a0192d82bf7d00137490cd6074e8500778afed552a67e5.3fadbea36527ae472139fe84cddaa65454d7429f12d543d80bfc3ad70de55ac2
2021-11-16 04:09:38,300 => Weights of BertForSequenceClassification not initialized from pretrained model: ['classifier.weight', 'classifier.bias']
2021-11-16 04:09:38,301 => Weights from pretrained model not used in BertForSequenceClassification: ['cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias']
2021-11-16 04:15:02,622 => Train: 100.0	Epoch: 1	Iter: 158	Loss: 2.35036	Acc= 25.967	Precision= 25.991	Recall= 25.969	F1_score= 25.975
2021-11-16 04:18:35,710 => Train: 100.0	Epoch: 2	Iter: 158	Loss: 2.33290	Acc= 26.046	Precision= 26.039	Recall= 26.052	F1_score= 26.043
2021-11-16 04:23:47,190 => Train: 100.0	Epoch: 3	Iter: 158	Loss: 1.42404	Acc= 27.861	Precision= 27.875	Recall= 27.863	F1_score= 27.869
2021-11-16 04:27:23,768 => Train: 100.0	Epoch: 4	Iter: 158	Loss: 1.25037	Acc= 26.677	Precision= 26.666	Recall= 26.683	F1_score= 26.672
2021-11-16 04:30:59,130 => Train: 100.0	Epoch: 5	Iter: 158	Loss: 1.04224	Acc= 27.545	Precision= 27.545	Recall= 27.569	F1_score= 27.554
2021-11-16 04:36:30,634 => Train: 100.0	Epoch: 6	Iter: 158	Loss: 1.53494	Acc= 23.520	Precision= 23.539	Recall= 23.499	F1_score= 23.513
2021-11-16 04:41:51,150 => Train: 100.0	Epoch: 7	Iter: 158	Loss: 0.95673	Acc= 25.178	Precision= 25.168	Recall= 25.166	F1_score= 25.164
2021-11-16 04:45:25,218 => Train: 100.0	Epoch: 8	Iter: 158	Loss: 0.90388	Acc= 24.862	Precision= 24.829	Recall= 24.876	F1_score= 24.850
2021-11-16 04:48:53,567 => Train: 100.0	Epoch: 9	Iter: 158	Loss: 0.88812	Acc= 24.862	Precision= 24.858	Recall= 24.857	F1_score= 24.856
2021-11-16 04:52:28,128 => Train: 100.0	Epoch: 10	Iter: 158	Loss: 0.96931	Acc= 25.178	Precision= 25.142	Recall= 25.185	F1_score= 25.161
2021-11-16 04:56:04,952 => Train: 100.0	Epoch: 11	Iter: 158	Loss: 0.78259	Acc= 25.099	Precision= 25.040	Recall= 25.097	F1_score= 25.063
2021-11-16 04:59:40,220 => Train: 100.0	Epoch: 12	Iter: 158	Loss: 0.84912	Acc= 22.889	Precision= 22.881	Recall= 22.883	F1_score= 22.882
2021-11-16 05:03:54,589 => Train: 100.0	Epoch: 13	Iter: 158	Loss: 0.68350	Acc= 24.152	Precision= 24.165	Recall= 24.158	F1_score= 24.161
2021-11-16 05:08:14,263 => Train: 100.0	Epoch: 14	Iter: 158	Loss: 0.60987	Acc= 23.441	Precision= 23.441	Recall= 23.444	F1_score= 23.442
2021-11-16 05:12:29,576 => Train: 100.0	Epoch: 15	Iter: 158	Loss: 0.54889	Acc= 26.598	Precision= 26.618	Recall= 26.602	F1_score= 26.609
2021-11-16 05:16:44,618 => Train: 100.0	Epoch: 16	Iter: 158	Loss: 0.47459	Acc= 27.072	Precision= 27.067	Recall= 27.094	F1_score= 27.078
2021-11-16 05:21:00,578 => Train: 100.0	Epoch: 17	Iter: 158	Loss: 0.44163	Acc= 26.677	Precision= 26.675	Recall= 26.666	F1_score= 26.659
2021-11-16 05:25:25,501 => Train: 100.0	Epoch: 18	Iter: 158	Loss: 0.43559	Acc= 24.388	Precision= 24.405	Recall= 24.396	F1_score= 24.398
2021-11-16 05:29:50,778 => Train: 100.0	Epoch: 19	Iter: 158	Loss: 0.43151	Acc= 24.862	Precision= 24.869	Recall= 24.863	F1_score= 24.865
2021-11-16 05:36:55,548 => Train: 100.0	Epoch: 20	Iter: 158	Loss: 0.40089	Acc= 25.572	Precision= 25.541	Recall= 25.562	F1_score= 25.549
2021-11-16 05:41:16,545 => Train: 100.0	Epoch: 21	Iter: 158	Loss: 0.37239	Acc= 24.309	Precision= 24.293	Recall= 24.316	F1_score= 24.297
2021-11-16 05:45:16,141 => Train: 100.0	Epoch: 22	Iter: 158	Loss: 0.36065	Acc= 23.362	Precision= 23.323	Recall= 23.353	F1_score= 23.332
2021-11-16 05:49:30,826 => Train: 100.0	Epoch: 23	Iter: 158	Loss: 0.34223	Acc= 24.230	Precision= 24.237	Recall= 24.244	F1_score= 24.240
2021-11-16 05:53:55,100 => Train: 100.0	Epoch: 24	Iter: 158	Loss: 0.32783	Acc= 23.915	Precision= 23.893	Recall= 23.904	F1_score= 23.894
2021-11-16 05:58:23,387 => Train: 100.0	Epoch: 25	Iter: 158	Loss: 0.30968	Acc= 25.178	Precision= 25.166	Recall= 25.173	F1_score= 25.168
2021-11-16 06:06:11,570 => Train: 100.0	Epoch: 26	Iter: 158	Loss: 0.29898	Acc= 22.731	Precision= 22.781	Recall= 22.721	F1_score= 22.732
2021-11-16 06:10:16,850 => Train: 100.0	Epoch: 27	Iter: 158	Loss: 0.29850	Acc= 22.336	Precision= 22.349	Recall= 22.334	F1_score= 22.332
2021-11-16 06:14:46,572 => Train: 100.0	Epoch: 28	Iter: 158	Loss: 0.26076	Acc= 26.677	Precision= 26.654	Recall= 26.667	F1_score= 26.654
2021-11-16 06:19:18,166 => Train: 100.0	Epoch: 29	Iter: 158	Loss: 0.26499	Acc= 23.678	Precision= 23.679	Recall= 23.680	F1_score= 23.665
2021-11-16 06:23:49,388 => Train: 100.0	Epoch: 30	Iter: 158	Loss: 0.26031	Acc= 23.441	Precision= 23.486	Recall= 23.443	F1_score= 23.457
2021-11-16 06:28:14,561 => Train: 100.0	Epoch: 31	Iter: 158	Loss: 0.24152	Acc= 25.572	Precision= 25.553	Recall= 25.590	F1_score= 25.559
2021-11-16 06:34:53,131 => Train: 100.0	Epoch: 32	Iter: 158	Loss: 0.23825	Acc= 25.651	Precision= 25.662	Recall= 25.659	F1_score= 25.650
2021-11-16 06:39:13,231 => Train: 100.0	Epoch: 33	Iter: 158	Loss: 0.23770	Acc= 25.651	Precision= 25.715	Recall= 25.649	F1_score= 25.664
2021-11-16 06:43:24,336 => Train: 100.0	Epoch: 34	Iter: 158	Loss: 0.24271	Acc= 23.520	Precision= 23.505	Recall= 23.533	F1_score= 23.509
2021-11-16 06:47:19,329 => Train: 100.0	Epoch: 35	Iter: 158	Loss: 0.23004	Acc= 25.414	Precision= 25.452	Recall= 25.417	F1_score= 25.404
2021-11-16 06:51:37,813 => Train: 100.0	Epoch: 36	Iter: 158	Loss: 0.23068	Acc= 23.678	Precision= 23.652	Recall= 23.701	F1_score= 23.655
2021-11-16 06:56:13,695 => Train: 100.0	Epoch: 37	Iter: 158	Loss: 0.22474	Acc= 25.257	Precision= 25.246	Recall= 25.269	F1_score= 25.242
2021-11-16 07:00:22,429 => Train: 100.0	Epoch: 38	Iter: 158	Loss: 0.22018	Acc= 25.730	Precision= 25.711	Recall= 25.734	F1_score= 25.716
2021-11-16 07:04:57,841 => Train: 100.0	Epoch: 39	Iter: 158	Loss: 0.21956	Acc= 26.835	Precision= 26.852	Recall= 26.826	F1_score= 26.832
2021-11-16 07:09:25,029 => Train: 100.0	Epoch: 40	Iter: 158	Loss: 0.22231	Acc= 23.283	Precision= 23.266	Recall= 23.280	F1_score= 23.253
2021-11-16 07:13:37,989 => Train: 100.0	Epoch: 41	Iter: 158	Loss: 0.21789	Acc= 25.335	Precision= 25.343	Recall= 25.352	F1_score= 25.347
2021-11-16 07:18:06,403 => Train: 100.0	Epoch: 42	Iter: 158	Loss: 0.21288	Acc= 26.677	Precision= 26.663	Recall= 26.688	F1_score= 26.673
2021-11-16 07:22:29,726 => Train: 100.0	Epoch: 43	Iter: 158	Loss: 0.21086	Acc= 25.178	Precision= 25.208	Recall= 25.169	F1_score= 25.164
2021-11-16 07:26:37,975 => Train: 100.0	Epoch: 44	Iter: 158	Loss: 0.20501	Acc= 27.309	Precision= 27.246	Recall= 27.299	F1_score= 27.248
2021-11-16 07:34:48,322 => Train: 100.0	Epoch: 45	Iter: 158	Loss: 0.21379	Acc= 24.152	Precision= 24.143	Recall= 24.137	F1_score= 24.138
2021-11-16 07:39:01,135 => Train: 100.0	Epoch: 46	Iter: 158	Loss: 0.20362	Acc= 27.072	Precision= 27.056	Recall= 27.053	F1_score= 27.053
2021-11-16 07:43:18,671 => Train: 100.0	Epoch: 47	Iter: 158	Loss: 0.21588	Acc= 24.388	Precision= 24.453	Recall= 24.386	F1_score= 24.397
2021-11-16 07:47:29,725 => Train: 100.0	Epoch: 48	Iter: 158	Loss: 0.21367	Acc= 22.336	Precision= 22.315	Recall= 22.325	F1_score= 22.306
2021-11-16 07:52:35,697 => Train: 100.0	Epoch: 49	Iter: 158	Loss: 0.20589	Acc= 25.257	Precision= 25.258	Recall= 25.264	F1_score= 25.255
2021-11-16 07:56:55,747 => Train: 100.0	Epoch: 50	Iter: 158	Loss: 0.20849	Acc= 24.388	Precision= 24.377	Recall= 24.392	F1_score= 24.373
2021-11-16 07:56:59,136 => Eval: 100.0	Epoch: 50	Iter: 39	Loss: 0.17477	Acc= 28.076	Precision= 7.019	Recall= 25.000	F1_score= 10.961
2021-11-16 07:56:59,136 => -------------------------------------------------
2021-11-16 07:56:59,136 => 3 FOLD
2021-11-16 07:56:59,577 => loading configuration file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-cased-config.json from cache at /home/yinan/.cache/torch/transformers/b945b69218e98b3e2c95acf911789741307dec43c698d35fad11c1ae28bda352.9da767be51e1327499df13488672789394e2ca38b877837e52618a67d7002391
2021-11-16 07:56:59,578 => Model config BertConfig {
  "architectures": [
    "BertForMaskedLM"
  ],
  "attention_probs_dropout_prob": 0.1,
  "bos_token_id": null,
  "do_sample": false,
  "eos_token_ids": null,
  "finetuning_task": null,
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "hidden_size": 768,
  "id2label": {
    "0": "LABEL_0",
    "1": "LABEL_1"
  },
  "initializer_range": 0.02,
  "intermediate_size": 3072,
  "is_decoder": false,
  "label2id": {
    "LABEL_0": 0,
    "LABEL_1": 1
  },
  "layer_norm_eps": 1e-12,
  "length_penalty": 1.0,
  "max_length": 20,
  "max_position_embeddings": 512,
  "model_type": "bert",
  "num_attention_heads": 12,
  "num_beams": 1,
  "num_hidden_layers": 12,
  "num_labels": 4,
  "num_return_sequences": 1,
  "output_attentions": false,
  "output_hidden_states": false,
  "output_past": true,
  "pad_token_id": 0,
  "pruned_heads": {},
  "repetition_penalty": 1.0,
  "temperature": 1.0,
  "top_k": 50,
  "top_p": 1.0,
  "torchscript": false,
  "type_vocab_size": 2,
  "use_bfloat16": false,
  "vocab_size": 28996
}

2021-11-16 07:57:00,035 => loading weights file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-cased-pytorch_model.bin from cache at /home/yinan/.cache/torch/transformers/35d8b9d36faaf46728a0192d82bf7d00137490cd6074e8500778afed552a67e5.3fadbea36527ae472139fe84cddaa65454d7429f12d543d80bfc3ad70de55ac2
2021-11-16 07:57:03,906 => Weights of BertForSequenceClassification not initialized from pretrained model: ['classifier.weight', 'classifier.bias']
2021-11-16 07:57:03,906 => Weights from pretrained model not used in BertForSequenceClassification: ['cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias']
2021-11-16 08:06:12,825 => Train: 100.0	Epoch: 1	Iter: 158	Loss: 2.15082	Acc= 24.941	Precision= 24.890	Recall= 24.871	F1_score= 24.878
2021-11-16 08:12:06,819 => Train: 100.0	Epoch: 2	Iter: 158	Loss: 1.71641	Acc= 25.888	Precision= 25.874	Recall= 25.868	F1_score= 25.870
2021-11-16 08:22:52,549 => Train: 100.0	Epoch: 3	Iter: 158	Loss: 1.46831	Acc= 26.519	Precision= 26.497	Recall= 26.504	F1_score= 26.500
2021-11-16 08:28:28,025 => Train: 100.0	Epoch: 4	Iter: 158	Loss: 1.30497	Acc= 24.704	Precision= 24.662	Recall= 24.652	F1_score= 24.655
2021-11-16 08:34:14,225 => Train: 100.0	Epoch: 5	Iter: 158	Loss: 1.27375	Acc= 23.362	Precision= 23.395	Recall= 23.408	F1_score= 23.400
2021-11-16 08:46:29,306 => Train: 100.0	Epoch: 6	Iter: 158	Loss: 1.29524	Acc= 26.677	Precision= 26.632	Recall= 26.640	F1_score= 26.634
2021-11-16 09:07:19,427 => 1.10.0
2021-11-16 09:07:19,467 => cuda
2021-11-16 09:07:20,279 => loading file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-cased-vocab.txt from cache at /home/yinan/.cache/torch/transformers/5e8a2b4893d13790ed4150ca1906be5f7a03d6c4ddf62296c383f6db42814db2.e13dbb970cb325137104fb2e5f36fe865f27746c6b526f6352861b1980eb80b1
2021-11-16 09:07:32,255 => -------------------------------------------------
2021-11-16 09:07:32,256 => 1 FOLD
2021-11-16 09:07:32,658 => loading configuration file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-cased-config.json from cache at /home/yinan/.cache/torch/transformers/b945b69218e98b3e2c95acf911789741307dec43c698d35fad11c1ae28bda352.9da767be51e1327499df13488672789394e2ca38b877837e52618a67d7002391
2021-11-16 09:07:32,659 => Model config BertConfig {
  "architectures": [
    "BertForMaskedLM"
  ],
  "attention_probs_dropout_prob": 0.1,
  "bos_token_id": null,
  "do_sample": false,
  "eos_token_ids": null,
  "finetuning_task": null,
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "hidden_size": 768,
  "id2label": {
    "0": "LABEL_0",
    "1": "LABEL_1"
  },
  "initializer_range": 0.02,
  "intermediate_size": 3072,
  "is_decoder": false,
  "label2id": {
    "LABEL_0": 0,
    "LABEL_1": 1
  },
  "layer_norm_eps": 1e-12,
  "length_penalty": 1.0,
  "max_length": 20,
  "max_position_embeddings": 512,
  "model_type": "bert",
  "num_attention_heads": 12,
  "num_beams": 1,
  "num_hidden_layers": 12,
  "num_labels": 4,
  "num_return_sequences": 1,
  "output_attentions": false,
  "output_hidden_states": false,
  "output_past": true,
  "pad_token_id": 0,
  "pruned_heads": {},
  "repetition_penalty": 1.0,
  "temperature": 1.0,
  "top_k": 50,
  "top_p": 1.0,
  "torchscript": false,
  "type_vocab_size": 2,
  "use_bfloat16": false,
  "vocab_size": 28996
}

2021-11-16 09:07:33,056 => loading weights file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-cased-pytorch_model.bin from cache at /home/yinan/.cache/torch/transformers/35d8b9d36faaf46728a0192d82bf7d00137490cd6074e8500778afed552a67e5.3fadbea36527ae472139fe84cddaa65454d7429f12d543d80bfc3ad70de55ac2
2021-11-16 09:07:36,909 => Weights of BertForSequenceClassification not initialized from pretrained model: ['classifier.weight', 'classifier.bias']
2021-11-16 09:07:37,006 => Weights from pretrained model not used in BertForSequenceClassification: ['cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias']
2021-11-16 09:13:19,172 => 1.10.0
2021-11-16 09:13:19,194 => cuda
2021-11-16 09:13:19,630 => loading file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-cased-vocab.txt from cache at /home/yinan/.cache/torch/transformers/5e8a2b4893d13790ed4150ca1906be5f7a03d6c4ddf62296c383f6db42814db2.e13dbb970cb325137104fb2e5f36fe865f27746c6b526f6352861b1980eb80b1
2021-11-16 09:13:31,598 => -------------------------------------------------
2021-11-16 09:13:31,599 => 1 FOLD
2021-11-16 09:13:32,025 => loading configuration file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-cased-config.json from cache at /home/yinan/.cache/torch/transformers/b945b69218e98b3e2c95acf911789741307dec43c698d35fad11c1ae28bda352.9da767be51e1327499df13488672789394e2ca38b877837e52618a67d7002391
2021-11-16 09:13:32,027 => Model config BertConfig {
  "architectures": [
    "BertForMaskedLM"
  ],
  "attention_probs_dropout_prob": 0.1,
  "bos_token_id": null,
  "do_sample": false,
  "eos_token_ids": null,
  "finetuning_task": null,
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "hidden_size": 768,
  "id2label": {
    "0": "LABEL_0",
    "1": "LABEL_1"
  },
  "initializer_range": 0.02,
  "intermediate_size": 3072,
  "is_decoder": false,
  "label2id": {
    "LABEL_0": 0,
    "LABEL_1": 1
  },
  "layer_norm_eps": 1e-12,
  "length_penalty": 1.0,
  "max_length": 20,
  "max_position_embeddings": 512,
  "model_type": "bert",
  "num_attention_heads": 12,
  "num_beams": 1,
  "num_hidden_layers": 12,
  "num_labels": 4,
  "num_return_sequences": 1,
  "output_attentions": false,
  "output_hidden_states": false,
  "output_past": true,
  "pad_token_id": 0,
  "pruned_heads": {},
  "repetition_penalty": 1.0,
  "temperature": 1.0,
  "top_k": 50,
  "top_p": 1.0,
  "torchscript": false,
  "type_vocab_size": 2,
  "use_bfloat16": false,
  "vocab_size": 28996
}

2021-11-16 09:13:32,424 => loading weights file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-cased-pytorch_model.bin from cache at /home/yinan/.cache/torch/transformers/35d8b9d36faaf46728a0192d82bf7d00137490cd6074e8500778afed552a67e5.3fadbea36527ae472139fe84cddaa65454d7429f12d543d80bfc3ad70de55ac2
2021-11-16 09:13:36,291 => Weights of BertForSequenceClassification not initialized from pretrained model: ['classifier.weight', 'classifier.bias']
2021-11-16 09:13:36,291 => Weights from pretrained model not used in BertForSequenceClassification: ['cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias']
2021-11-16 09:13:44,934 => 1.10.0
2021-11-16 09:13:44,934 => cuda
2021-11-16 09:13:45,350 => loading file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-cased-vocab.txt from cache at /home/yinan/.cache/torch/transformers/5e8a2b4893d13790ed4150ca1906be5f7a03d6c4ddf62296c383f6db42814db2.e13dbb970cb325137104fb2e5f36fe865f27746c6b526f6352861b1980eb80b1
2021-11-16 09:13:57,212 => -------------------------------------------------
2021-11-16 09:13:57,213 => 1 FOLD
2021-11-16 09:13:57,614 => loading configuration file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-cased-config.json from cache at /home/yinan/.cache/torch/transformers/b945b69218e98b3e2c95acf911789741307dec43c698d35fad11c1ae28bda352.9da767be51e1327499df13488672789394e2ca38b877837e52618a67d7002391
2021-11-16 09:13:57,616 => Model config BertConfig {
  "architectures": [
    "BertForMaskedLM"
  ],
  "attention_probs_dropout_prob": 0.1,
  "bos_token_id": null,
  "do_sample": false,
  "eos_token_ids": null,
  "finetuning_task": null,
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "hidden_size": 768,
  "id2label": {
    "0": "LABEL_0",
    "1": "LABEL_1"
  },
  "initializer_range": 0.02,
  "intermediate_size": 3072,
  "is_decoder": false,
  "label2id": {
    "LABEL_0": 0,
    "LABEL_1": 1
  },
  "layer_norm_eps": 1e-12,
  "length_penalty": 1.0,
  "max_length": 20,
  "max_position_embeddings": 512,
  "model_type": "bert",
  "num_attention_heads": 12,
  "num_beams": 1,
  "num_hidden_layers": 12,
  "num_labels": 4,
  "num_return_sequences": 1,
  "output_attentions": false,
  "output_hidden_states": false,
  "output_past": true,
  "pad_token_id": 0,
  "pruned_heads": {},
  "repetition_penalty": 1.0,
  "temperature": 1.0,
  "top_k": 50,
  "top_p": 1.0,
  "torchscript": false,
  "type_vocab_size": 2,
  "use_bfloat16": false,
  "vocab_size": 28996
}

2021-11-16 09:13:58,014 => loading weights file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-cased-pytorch_model.bin from cache at /home/yinan/.cache/torch/transformers/35d8b9d36faaf46728a0192d82bf7d00137490cd6074e8500778afed552a67e5.3fadbea36527ae472139fe84cddaa65454d7429f12d543d80bfc3ad70de55ac2
2021-11-16 09:14:01,656 => Weights of BertForSequenceClassification not initialized from pretrained model: ['classifier.weight', 'classifier.bias']
2021-11-16 09:14:01,656 => Weights from pretrained model not used in BertForSequenceClassification: ['cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias']
2021-11-16 09:14:27,964 => 1.10.0
2021-11-16 09:14:28,235 => cuda
2021-11-16 09:14:28,681 => loading file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-cased-vocab.txt from cache at /home/yinan/.cache/torch/transformers/5e8a2b4893d13790ed4150ca1906be5f7a03d6c4ddf62296c383f6db42814db2.e13dbb970cb325137104fb2e5f36fe865f27746c6b526f6352861b1980eb80b1
2021-11-16 09:14:40,605 => -------------------------------------------------
2021-11-16 09:14:40,606 => 1 FOLD
2021-11-16 09:14:41,016 => loading configuration file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-cased-config.json from cache at /home/yinan/.cache/torch/transformers/b945b69218e98b3e2c95acf911789741307dec43c698d35fad11c1ae28bda352.9da767be51e1327499df13488672789394e2ca38b877837e52618a67d7002391
2021-11-16 09:14:41,017 => Model config BertConfig {
  "architectures": [
    "BertForMaskedLM"
  ],
  "attention_probs_dropout_prob": 0.1,
  "bos_token_id": null,
  "do_sample": false,
  "eos_token_ids": null,
  "finetuning_task": null,
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "hidden_size": 768,
  "id2label": {
    "0": "LABEL_0",
    "1": "LABEL_1"
  },
  "initializer_range": 0.02,
  "intermediate_size": 3072,
  "is_decoder": false,
  "label2id": {
    "LABEL_0": 0,
    "LABEL_1": 1
  },
  "layer_norm_eps": 1e-12,
  "length_penalty": 1.0,
  "max_length": 20,
  "max_position_embeddings": 512,
  "model_type": "bert",
  "num_attention_heads": 12,
  "num_beams": 1,
  "num_hidden_layers": 12,
  "num_labels": 4,
  "num_return_sequences": 1,
  "output_attentions": false,
  "output_hidden_states": false,
  "output_past": true,
  "pad_token_id": 0,
  "pruned_heads": {},
  "repetition_penalty": 1.0,
  "temperature": 1.0,
  "top_k": 50,
  "top_p": 1.0,
  "torchscript": false,
  "type_vocab_size": 2,
  "use_bfloat16": false,
  "vocab_size": 28996
}

2021-11-16 09:14:41,425 => loading weights file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-cased-pytorch_model.bin from cache at /home/yinan/.cache/torch/transformers/35d8b9d36faaf46728a0192d82bf7d00137490cd6074e8500778afed552a67e5.3fadbea36527ae472139fe84cddaa65454d7429f12d543d80bfc3ad70de55ac2
2021-11-16 09:14:45,292 => Weights of BertForSequenceClassification not initialized from pretrained model: ['classifier.weight', 'classifier.bias']
2021-11-16 09:14:45,292 => Weights from pretrained model not used in BertForSequenceClassification: ['cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias']
2021-11-16 09:14:57,531 => 1.10.0
2021-11-16 09:14:57,532 => cuda
2021-11-16 09:14:57,950 => loading file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-cased-vocab.txt from cache at /home/yinan/.cache/torch/transformers/5e8a2b4893d13790ed4150ca1906be5f7a03d6c4ddf62296c383f6db42814db2.e13dbb970cb325137104fb2e5f36fe865f27746c6b526f6352861b1980eb80b1
