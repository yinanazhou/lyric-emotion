2021-11-14 22:03:49,761 => 1.10.0
2021-11-14 22:03:49,762 => cuda
2021-11-14 22:03:50,132 => loading file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-cased-vocab.txt from cache at /home/yinan/.cache/torch/transformers/5e8a2b4893d13790ed4150ca1906be5f7a03d6c4ddf62296c383f6db42814db2.e13dbb970cb325137104fb2e5f36fe865f27746c6b526f6352861b1980eb80b1
2021-11-14 22:04:00,844 => -------------------------------------------------
2021-11-14 22:04:00,845 => 1 FOLD
2021-11-14 22:04:01,416 => loading configuration file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-cased-config.json from cache at /home/yinan/.cache/torch/transformers/b945b69218e98b3e2c95acf911789741307dec43c698d35fad11c1ae28bda352.9da767be51e1327499df13488672789394e2ca38b877837e52618a67d7002391
2021-11-14 22:04:01,416 => Model config BertConfig {
  "architectures": [
    "BertForMaskedLM"
  ],
  "attention_probs_dropout_prob": 0.1,
  "bos_token_id": null,
  "do_sample": false,
  "eos_token_ids": null,
  "finetuning_task": null,
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "hidden_size": 768,
  "id2label": {
    "0": "LABEL_0",
    "1": "LABEL_1"
  },
  "initializer_range": 0.02,
  "intermediate_size": 3072,
  "is_decoder": false,
  "label2id": {
    "LABEL_0": 0,
    "LABEL_1": 1
  },
  "layer_norm_eps": 1e-12,
  "length_penalty": 1.0,
  "max_length": 20,
  "max_position_embeddings": 512,
  "model_type": "bert",
  "num_attention_heads": 12,
  "num_beams": 1,
  "num_hidden_layers": 12,
  "num_labels": 4,
  "num_return_sequences": 1,
  "output_attentions": false,
  "output_hidden_states": false,
  "output_past": true,
  "pad_token_id": 0,
  "pruned_heads": {},
  "repetition_penalty": 1.0,
  "temperature": 1.0,
  "top_k": 50,
  "top_p": 1.0,
  "torchscript": false,
  "type_vocab_size": 2,
  "use_bfloat16": false,
  "vocab_size": 28996
}

2021-11-14 22:04:01,768 => loading weights file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-cased-pytorch_model.bin from cache at /home/yinan/.cache/torch/transformers/35d8b9d36faaf46728a0192d82bf7d00137490cd6074e8500778afed552a67e5.3fadbea36527ae472139fe84cddaa65454d7429f12d543d80bfc3ad70de55ac2
2021-11-14 22:04:05,373 => Weights of BertForSequenceClassification not initialized from pretrained model: ['classifier.weight', 'classifier.bias']
2021-11-14 22:04:05,373 => Weights from pretrained model not used in BertForSequenceClassification: ['cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias']
2021-11-14 22:07:03,279 => Train: 100.0	Epoch: 1	Iter: 79	Loss: 0.09172	Acc= 26.046	Precision= 26.012	Recall= 26.026	F1_score= 26.009
2021-11-14 22:09:58,205 => Train: 100.0	Epoch: 2	Iter: 79	Loss: 0.09081	Acc= 25.414	Precision= 25.323	Recall= 25.331	F1_score= 25.220
2021-11-14 22:12:53,118 => Train: 100.0	Epoch: 3	Iter: 79	Loss: 0.09133	Acc= 24.862	Precision= 24.819	Recall= 24.827	F1_score= 24.820
2021-11-14 22:16:01,244 => Train: 100.0	Epoch: 4	Iter: 79	Loss: 0.09066	Acc= 25.967	Precision= 25.737	Recall= 25.853	F1_score= 25.686
2021-11-14 22:18:58,504 => Train: 100.0	Epoch: 5	Iter: 79	Loss: 0.09080	Acc= 26.598	Precision= 26.486	Recall= 26.499	F1_score= 26.349
2021-11-14 22:22:08,465 => Train: 100.0	Epoch: 6	Iter: 79	Loss: 0.09031	Acc= 26.440	Precision= 26.262	Recall= 26.303	F1_score= 26.041
2021-11-14 22:25:04,004 => Train: 100.0	Epoch: 7	Iter: 79	Loss: 0.09040	Acc= 25.257	Precision= 25.084	Recall= 25.096	F1_score= 24.615
2021-11-14 22:28:21,497 => Train: 100.0	Epoch: 8	Iter: 79	Loss: 0.09008	Acc= 25.099	Precision= 25.156	Recall= 24.960	F1_score= 24.651
2021-11-14 22:31:28,598 => Train: 100.0	Epoch: 9	Iter: 79	Loss: 0.08991	Acc= 25.888	Precision= 26.009	Recall= 25.754	F1_score= 25.540
2021-11-14 22:34:25,227 => Train: 100.0	Epoch: 10	Iter: 79	Loss: 0.08987	Acc= 24.309	Precision= 24.262	Recall= 24.209	F1_score= 24.020
2021-11-14 22:37:20,295 => Train: 100.0	Epoch: 11	Iter: 79	Loss: 0.08946	Acc= 26.361	Precision= 26.466	Recall= 26.267	F1_score= 26.133
2021-11-14 22:40:14,883 => Train: 100.0	Epoch: 12	Iter: 79	Loss: 0.08940	Acc= 26.283	Precision= 26.030	Recall= 26.160	F1_score= 25.936
2021-11-14 22:43:09,187 => Train: 100.0	Epoch: 13	Iter: 79	Loss: 0.08941	Acc= 25.099	Precision= 25.205	Recall= 25.027	F1_score= 24.918
2021-11-14 22:46:04,383 => Train: 100.0	Epoch: 14	Iter: 79	Loss: 0.08960	Acc= 24.625	Precision= 24.573	Recall= 24.488	F1_score= 24.193
2021-11-14 22:48:59,430 => Train: 100.0	Epoch: 15	Iter: 79	Loss: 0.08885	Acc= 25.730	Precision= 25.686	Recall= 25.605	F1_score= 25.360
2021-11-14 22:51:54,094 => Train: 100.0	Epoch: 16	Iter: 79	Loss: 0.08889	Acc= 25.651	Precision= 25.559	Recall= 25.522	F1_score= 25.299
2021-11-14 22:54:59,496 => Train: 100.0	Epoch: 17	Iter: 79	Loss: 0.08913	Acc= 23.520	Precision= 23.513	Recall= 23.412	F1_score= 23.252
2021-11-14 22:57:54,914 => Train: 100.0	Epoch: 18	Iter: 79	Loss: 0.08916	Acc= 23.757	Precision= 23.519	Recall= 23.628	F1_score= 23.378
2021-11-14 23:00:50,102 => Train: 100.0	Epoch: 19	Iter: 79	Loss: 0.08887	Acc= 23.204	Precision= 23.125	Recall= 23.102	F1_score= 22.941
2021-11-14 23:03:45,686 => Train: 100.0	Epoch: 20	Iter: 79	Loss: 0.08846	Acc= 25.099	Precision= 24.760	Recall= 24.957	F1_score= 24.674
2021-11-14 23:03:51,758 => Eval: 100.0	Epoch: 20	Iter: 19	Loss: 0.08800	Acc= 23.659	Precision= 5.915	Recall= 25.000	F1_score= 9.566
2021-11-14 23:03:51,758 => -------------------------------------------------
2021-11-14 23:03:51,758 => 2 FOLD
2021-11-14 23:03:52,126 => loading configuration file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-cased-config.json from cache at /home/yinan/.cache/torch/transformers/b945b69218e98b3e2c95acf911789741307dec43c698d35fad11c1ae28bda352.9da767be51e1327499df13488672789394e2ca38b877837e52618a67d7002391
2021-11-14 23:03:52,127 => Model config BertConfig {
  "architectures": [
    "BertForMaskedLM"
  ],
  "attention_probs_dropout_prob": 0.1,
  "bos_token_id": null,
  "do_sample": false,
  "eos_token_ids": null,
  "finetuning_task": null,
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "hidden_size": 768,
  "id2label": {
    "0": "LABEL_0",
    "1": "LABEL_1"
  },
  "initializer_range": 0.02,
  "intermediate_size": 3072,
  "is_decoder": false,
  "label2id": {
    "LABEL_0": 0,
    "LABEL_1": 1
  },
  "layer_norm_eps": 1e-12,
  "length_penalty": 1.0,
  "max_length": 20,
  "max_position_embeddings": 512,
  "model_type": "bert",
  "num_attention_heads": 12,
  "num_beams": 1,
  "num_hidden_layers": 12,
  "num_labels": 4,
  "num_return_sequences": 1,
  "output_attentions": false,
  "output_hidden_states": false,
  "output_past": true,
  "pad_token_id": 0,
  "pruned_heads": {},
  "repetition_penalty": 1.0,
  "temperature": 1.0,
  "top_k": 50,
  "top_p": 1.0,
  "torchscript": false,
  "type_vocab_size": 2,
  "use_bfloat16": false,
  "vocab_size": 28996
}

2021-11-14 23:03:52,501 => loading weights file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-cased-pytorch_model.bin from cache at /home/yinan/.cache/torch/transformers/35d8b9d36faaf46728a0192d82bf7d00137490cd6074e8500778afed552a67e5.3fadbea36527ae472139fe84cddaa65454d7429f12d543d80bfc3ad70de55ac2
2021-11-14 23:03:56,044 => Weights of BertForSequenceClassification not initialized from pretrained model: ['classifier.weight', 'classifier.bias']
2021-11-14 23:03:56,044 => Weights from pretrained model not used in BertForSequenceClassification: ['cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias']
2021-11-14 23:06:45,027 => Train: 100.0	Epoch: 1	Iter: 79	Loss: 0.09172	Acc= 25.020	Precision= 24.880	Recall= 24.997	F1_score= 24.870
2021-11-14 23:09:34,270 => Train: 100.0	Epoch: 2	Iter: 79	Loss: 0.08951	Acc= 25.967	Precision= 26.066	Recall= 25.968	F1_score= 25.962
2021-11-14 23:12:23,387 => Train: 100.0	Epoch: 3	Iter: 79	Loss: 0.09015	Acc= 24.941	Precision= 24.953	Recall= 24.958	F1_score= 24.909
2021-11-14 23:15:22,584 => Train: 100.0	Epoch: 4	Iter: 79	Loss: 0.09055	Acc= 23.678	Precision= 23.723	Recall= 23.701	F1_score= 23.686
2021-11-14 23:18:12,482 => Train: 100.0	Epoch: 5	Iter: 79	Loss: 0.08936	Acc= 27.703	Precision= 27.696	Recall= 27.736	F1_score= 27.675
2021-11-14 23:21:15,810 => Train: 100.0	Epoch: 6	Iter: 79	Loss: 0.08918	Acc= 24.783	Precision= 24.796	Recall= 24.798	F1_score= 24.767
2021-11-14 23:24:06,088 => Train: 100.0	Epoch: 7	Iter: 79	Loss: 0.08880	Acc= 25.809	Precision= 25.805	Recall= 25.836	F1_score= 25.755
2021-11-14 23:27:13,242 => Train: 100.0	Epoch: 8	Iter: 79	Loss: 0.08909	Acc= 24.230	Precision= 24.117	Recall= 24.277	F1_score= 24.096
2021-11-14 23:30:11,035 => Train: 100.0	Epoch: 9	Iter: 79	Loss: 0.08924	Acc= 25.493	Precision= 25.535	Recall= 25.522	F1_score= 25.429
2021-11-14 23:33:00,414 => Train: 100.0	Epoch: 10	Iter: 79	Loss: 0.08912	Acc= 26.519	Precision= 26.710	Recall= 26.530	F1_score= 26.534
2021-11-14 23:35:51,073 => Train: 100.0	Epoch: 11	Iter: 79	Loss: 0.08903	Acc= 26.598	Precision= 26.745	Recall= 26.595	F1_score= 26.606
2021-11-14 23:38:40,455 => Train: 100.0	Epoch: 12	Iter: 79	Loss: 0.08921	Acc= 24.862	Precision= 24.836	Recall= 24.883	F1_score= 24.806
2021-11-14 23:41:30,426 => Train: 100.0	Epoch: 13	Iter: 79	Loss: 0.08940	Acc= 23.757	Precision= 23.665	Recall= 23.756	F1_score= 23.675
2021-11-14 23:44:20,285 => Train: 100.0	Epoch: 14	Iter: 79	Loss: 0.08950	Acc= 24.388	Precision= 24.251	Recall= 24.400	F1_score= 24.249
2021-11-14 23:47:10,933 => Train: 100.0	Epoch: 15	Iter: 79	Loss: 0.08820	Acc= 28.019	Precision= 28.081	Recall= 27.997	F1_score= 27.976
2021-11-14 23:50:00,696 => Train: 100.0	Epoch: 16	Iter: 79	Loss: 0.08918	Acc= 23.757	Precision= 23.708	Recall= 23.751	F1_score= 23.682
2021-11-14 23:52:57,554 => Train: 100.0	Epoch: 17	Iter: 79	Loss: 0.08874	Acc= 25.178	Precision= 25.205	Recall= 25.158	F1_score= 25.150
2021-11-14 23:55:47,386 => Train: 100.0	Epoch: 18	Iter: 79	Loss: 0.08851	Acc= 25.730	Precision= 25.523	Recall= 25.674	F1_score= 25.518
2021-11-14 23:58:37,258 => Train: 100.0	Epoch: 19	Iter: 79	Loss: 0.08882	Acc= 25.572	Precision= 25.643	Recall= 25.547	F1_score= 25.536
2021-11-15 00:01:27,103 => Train: 100.0	Epoch: 20	Iter: 79	Loss: 0.08842	Acc= 25.730	Precision= 25.322	Recall= 25.687	F1_score= 25.376
2021-11-15 00:01:33,129 => Eval: 100.0	Epoch: 20	Iter: 19	Loss: 0.08796	Acc= 20.189	Precision= 5.047	Recall= 25.000	F1_score= 8.399
2021-11-15 00:01:33,130 => -------------------------------------------------
2021-11-15 00:01:33,130 => 3 FOLD
2021-11-15 00:01:33,507 => loading configuration file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-cased-config.json from cache at /home/yinan/.cache/torch/transformers/b945b69218e98b3e2c95acf911789741307dec43c698d35fad11c1ae28bda352.9da767be51e1327499df13488672789394e2ca38b877837e52618a67d7002391
2021-11-15 00:01:33,507 => Model config BertConfig {
  "architectures": [
    "BertForMaskedLM"
  ],
  "attention_probs_dropout_prob": 0.1,
  "bos_token_id": null,
  "do_sample": false,
  "eos_token_ids": null,
  "finetuning_task": null,
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "hidden_size": 768,
  "id2label": {
    "0": "LABEL_0",
    "1": "LABEL_1"
  },
  "initializer_range": 0.02,
  "intermediate_size": 3072,
  "is_decoder": false,
  "label2id": {
    "LABEL_0": 0,
    "LABEL_1": 1
  },
  "layer_norm_eps": 1e-12,
  "length_penalty": 1.0,
  "max_length": 20,
  "max_position_embeddings": 512,
  "model_type": "bert",
  "num_attention_heads": 12,
  "num_beams": 1,
  "num_hidden_layers": 12,
  "num_labels": 4,
  "num_return_sequences": 1,
  "output_attentions": false,
  "output_hidden_states": false,
  "output_past": true,
  "pad_token_id": 0,
  "pruned_heads": {},
  "repetition_penalty": 1.0,
  "temperature": 1.0,
  "top_k": 50,
  "top_p": 1.0,
  "torchscript": false,
  "type_vocab_size": 2,
  "use_bfloat16": false,
  "vocab_size": 28996
}

2021-11-15 00:01:33,861 => loading weights file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-cased-pytorch_model.bin from cache at /home/yinan/.cache/torch/transformers/35d8b9d36faaf46728a0192d82bf7d00137490cd6074e8500778afed552a67e5.3fadbea36527ae472139fe84cddaa65454d7429f12d543d80bfc3ad70de55ac2
2021-11-15 00:01:37,365 => Weights of BertForSequenceClassification not initialized from pretrained model: ['classifier.weight', 'classifier.bias']
2021-11-15 00:01:37,365 => Weights from pretrained model not used in BertForSequenceClassification: ['cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias']
2021-11-15 00:04:27,030 => Train: 100.0	Epoch: 1	Iter: 79	Loss: 0.09183	Acc= 23.678	Precision= 23.520	Recall= 23.645	F1_score= 23.409
2021-11-15 00:07:16,622 => Train: 100.0	Epoch: 2	Iter: 79	Loss: 0.09047	Acc= 24.941	Precision= 24.977	Recall= 24.883	F1_score= 24.879
2021-11-15 00:10:06,219 => Train: 100.0	Epoch: 3	Iter: 79	Loss: 0.09065	Acc= 24.625	Precision= 24.643	Recall= 24.565	F1_score= 24.541
2021-11-15 00:13:11,005 => Train: 100.0	Epoch: 4	Iter: 79	Loss: 0.09066	Acc= 24.862	Precision= 24.881	Recall= 24.828	F1_score= 24.809
2021-11-15 00:16:01,749 => Train: 100.0	Epoch: 5	Iter: 79	Loss: 0.09075	Acc= 25.493	Precision= 25.430	Recall= 25.449	F1_score= 25.402
2021-11-15 00:19:08,821 => Train: 100.0	Epoch: 6	Iter: 79	Loss: 0.09013	Acc= 24.309	Precision= 24.298	Recall= 24.275	F1_score= 24.268
2021-11-15 00:21:58,237 => Train: 100.0	Epoch: 7	Iter: 79	Loss: 0.08991	Acc= 25.020	Precision= 24.920	Recall= 24.939	F1_score= 24.873
2021-11-15 00:25:00,842 => Train: 100.0	Epoch: 8	Iter: 79	Loss: 0.08977	Acc= 26.046	Precision= 25.933	Recall= 25.937	F1_score= 25.829
2021-11-15 00:28:00,768 => Train: 100.0	Epoch: 9	Iter: 79	Loss: 0.08994	Acc= 24.309	Precision= 24.200	Recall= 24.228	F1_score= 24.143
2021-11-15 00:30:50,854 => Train: 100.0	Epoch: 10	Iter: 79	Loss: 0.08937	Acc= 25.257	Precision= 25.379	Recall= 25.174	F1_score= 25.096
2021-11-15 00:33:42,778 => Train: 100.0	Epoch: 11	Iter: 79	Loss: 0.08944	Acc= 24.309	Precision= 24.156	Recall= 24.179	F1_score= 23.992
2021-11-15 00:36:33,233 => Train: 100.0	Epoch: 12	Iter: 79	Loss: 0.08941	Acc= 24.073	Precision= 23.980	Recall= 23.950	F1_score= 23.764
2021-11-15 00:39:24,267 => Train: 100.0	Epoch: 13	Iter: 79	Loss: 0.08942	Acc= 23.599	Precision= 23.079	Recall= 23.436	F1_score= 23.081
2021-11-15 00:42:14,425 => Train: 100.0	Epoch: 14	Iter: 79	Loss: 0.08909	Acc= 24.625	Precision= 24.501	Recall= 24.521	F1_score= 24.259
2021-11-15 00:45:04,521 => Train: 100.0	Epoch: 15	Iter: 79	Loss: 0.08890	Acc= 23.994	Precision= 23.731	Recall= 23.830	F1_score= 23.528
2021-11-15 00:47:54,781 => Train: 100.0	Epoch: 16	Iter: 79	Loss: 0.08893	Acc= 23.836	Precision= 24.051	Recall= 23.769	F1_score= 23.719
2021-11-15 00:51:00,109 => Train: 100.0	Epoch: 17	Iter: 79	Loss: 0.08879	Acc= 23.678	Precision= 23.649	Recall= 23.588	F1_score= 23.516
2021-11-15 00:53:50,736 => Train: 100.0	Epoch: 18	Iter: 79	Loss: 0.08824	Acc= 25.020	Precision= 25.049	Recall= 24.933	F1_score= 24.879
2021-11-15 00:56:41,570 => Train: 100.0	Epoch: 19	Iter: 79	Loss: 0.08904	Acc= 25.572	Precision= 25.478	Recall= 25.469	F1_score= 25.358
2021-11-15 00:59:33,153 => Train: 100.0	Epoch: 20	Iter: 79	Loss: 0.08886	Acc= 23.757	Precision= 23.543	Recall= 23.669	F1_score= 23.563
2021-11-15 00:59:39,174 => Eval: 100.0	Epoch: 20	Iter: 19	Loss: 0.08839	Acc= 22.713	Precision= 5.678	Recall= 25.000	F1_score= 9.254
2021-11-15 00:59:39,174 => -------------------------------------------------
2021-11-15 00:59:39,174 => 4 FOLD
2021-11-15 00:59:39,572 => loading configuration file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-cased-config.json from cache at /home/yinan/.cache/torch/transformers/b945b69218e98b3e2c95acf911789741307dec43c698d35fad11c1ae28bda352.9da767be51e1327499df13488672789394e2ca38b877837e52618a67d7002391
2021-11-15 00:59:39,573 => Model config BertConfig {
  "architectures": [
    "BertForMaskedLM"
  ],
  "attention_probs_dropout_prob": 0.1,
  "bos_token_id": null,
  "do_sample": false,
  "eos_token_ids": null,
  "finetuning_task": null,
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "hidden_size": 768,
  "id2label": {
    "0": "LABEL_0",
    "1": "LABEL_1"
  },
  "initializer_range": 0.02,
  "intermediate_size": 3072,
  "is_decoder": false,
  "label2id": {
    "LABEL_0": 0,
    "LABEL_1": 1
  },
  "layer_norm_eps": 1e-12,
  "length_penalty": 1.0,
  "max_length": 20,
  "max_position_embeddings": 512,
  "model_type": "bert",
  "num_attention_heads": 12,
  "num_beams": 1,
  "num_hidden_layers": 12,
  "num_labels": 4,
  "num_return_sequences": 1,
  "output_attentions": false,
  "output_hidden_states": false,
  "output_past": true,
  "pad_token_id": 0,
  "pruned_heads": {},
  "repetition_penalty": 1.0,
  "temperature": 1.0,
  "top_k": 50,
  "top_p": 1.0,
  "torchscript": false,
  "type_vocab_size": 2,
  "use_bfloat16": false,
  "vocab_size": 28996
}

2021-11-15 00:59:39,921 => loading weights file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-cased-pytorch_model.bin from cache at /home/yinan/.cache/torch/transformers/35d8b9d36faaf46728a0192d82bf7d00137490cd6074e8500778afed552a67e5.3fadbea36527ae472139fe84cddaa65454d7429f12d543d80bfc3ad70de55ac2
2021-11-15 00:59:43,541 => Weights of BertForSequenceClassification not initialized from pretrained model: ['classifier.weight', 'classifier.bias']
2021-11-15 00:59:43,541 => Weights from pretrained model not used in BertForSequenceClassification: ['cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias']
2021-11-15 01:02:33,723 => Train: 100.0	Epoch: 1	Iter: 79	Loss: 0.09159	Acc= 24.704	Precision= 24.588	Recall= 24.620	F1_score= 24.596
2021-11-15 01:05:24,147 => Train: 100.0	Epoch: 2	Iter: 79	Loss: 0.09013	Acc= 25.967	Precision= 26.036	Recall= 25.918	F1_score= 25.937
2021-11-15 01:08:15,135 => Train: 100.0	Epoch: 3	Iter: 79	Loss: 0.09041	Acc= 25.730	Precision= 25.608	Recall= 25.658	F1_score= 25.619
2021-11-15 01:11:08,186 => Train: 100.0	Epoch: 4	Iter: 79	Loss: 0.09098	Acc= 22.257	Precision= 22.048	Recall= 22.096	F1_score= 21.989
2021-11-15 01:13:59,621 => Train: 100.0	Epoch: 5	Iter: 79	Loss: 0.08983	Acc= 24.230	Precision= 24.093	Recall= 24.073	F1_score= 23.994
2021-11-15 01:17:08,964 => Train: 100.0	Epoch: 6	Iter: 79	Loss: 0.08974	Acc= 25.335	Precision= 24.645	Recall= 25.026	F1_score= 24.646
2021-11-15 01:20:00,158 => Train: 100.0	Epoch: 7	Iter: 79	Loss: 0.08947	Acc= 25.730	Precision= 25.551	Recall= 25.523	F1_score= 25.349
2021-11-15 01:23:06,753 => Train: 100.0	Epoch: 8	Iter: 79	Loss: 0.08939	Acc= 26.046	Precision= 25.742	Recall= 25.817	F1_score= 25.554
2021-11-15 01:26:03,054 => Train: 100.0	Epoch: 9	Iter: 79	Loss: 0.08982	Acc= 25.967	Precision= 25.828	Recall= 25.755	F1_score= 25.590
2021-11-15 01:28:53,829 => Train: 100.0	Epoch: 10	Iter: 79	Loss: 0.08953	Acc= 25.178	Precision= 24.855	Recall= 24.903	F1_score= 24.561
2021-11-15 01:31:45,209 => Train: 100.0	Epoch: 11	Iter: 79	Loss: 0.08946	Acc= 25.888	Precision= 26.023	Recall= 25.740	F1_score= 25.678
2021-11-15 01:34:35,444 => Train: 100.0	Epoch: 12	Iter: 79	Loss: 0.08924	Acc= 25.809	Precision= 25.713	Recall= 25.615	F1_score= 25.484
2021-11-15 01:37:26,152 => Train: 100.0	Epoch: 13	Iter: 79	Loss: 0.08844	Acc= 26.519	Precision= 26.292	Recall= 26.300	F1_score= 26.122
2021-11-15 01:40:16,696 => Train: 100.0	Epoch: 14	Iter: 79	Loss: 0.08851	Acc= 26.756	Precision= 26.558	Recall= 26.500	F1_score= 26.233
2021-11-15 01:43:07,244 => Train: 100.0	Epoch: 15	Iter: 79	Loss: 0.08936	Acc= 24.230	Precision= 24.084	Recall= 24.041	F1_score= 23.881
2021-11-15 01:45:57,526 => Train: 100.0	Epoch: 16	Iter: 79	Loss: 0.08834	Acc= 27.466	Precision= 27.214	Recall= 27.205	F1_score= 26.921
2021-11-15 01:48:58,050 => Train: 100.0	Epoch: 17	Iter: 79	Loss: 0.08864	Acc= 24.467	Precision= 24.256	Recall= 24.216	F1_score= 23.944
2021-11-15 01:51:49,382 => Train: 100.0	Epoch: 18	Iter: 79	Loss: 0.08911	Acc= 24.625	Precision= 24.280	Recall= 24.376	F1_score= 24.099
2021-11-15 01:54:40,390 => Train: 100.0	Epoch: 19	Iter: 79	Loss: 0.08825	Acc= 26.598	Precision= 25.990	Recall= 26.284	F1_score= 25.863
2021-11-15 01:57:32,203 => Train: 100.0	Epoch: 20	Iter: 79	Loss: 0.08862	Acc= 25.967	Precision= 25.772	Recall= 25.755	F1_score= 25.530
2021-11-15 01:57:38,212 => Eval: 100.0	Epoch: 20	Iter: 19	Loss: 0.08756	Acc= 27.445	Precision= 6.861	Recall= 25.000	F1_score= 10.767
2021-11-15 01:57:38,213 => -------------------------------------------------
2021-11-15 01:57:38,213 => 5 FOLD
2021-11-15 01:57:38,588 => loading configuration file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-cased-config.json from cache at /home/yinan/.cache/torch/transformers/b945b69218e98b3e2c95acf911789741307dec43c698d35fad11c1ae28bda352.9da767be51e1327499df13488672789394e2ca38b877837e52618a67d7002391
2021-11-15 01:57:38,588 => Model config BertConfig {
  "architectures": [
    "BertForMaskedLM"
  ],
  "attention_probs_dropout_prob": 0.1,
  "bos_token_id": null,
  "do_sample": false,
  "eos_token_ids": null,
  "finetuning_task": null,
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "hidden_size": 768,
  "id2label": {
    "0": "LABEL_0",
    "1": "LABEL_1"
  },
  "initializer_range": 0.02,
  "intermediate_size": 3072,
  "is_decoder": false,
  "label2id": {
    "LABEL_0": 0,
    "LABEL_1": 1
  },
  "layer_norm_eps": 1e-12,
  "length_penalty": 1.0,
  "max_length": 20,
  "max_position_embeddings": 512,
  "model_type": "bert",
  "num_attention_heads": 12,
  "num_beams": 1,
  "num_hidden_layers": 12,
  "num_labels": 4,
  "num_return_sequences": 1,
  "output_attentions": false,
  "output_hidden_states": false,
  "output_past": true,
  "pad_token_id": 0,
  "pruned_heads": {},
  "repetition_penalty": 1.0,
  "temperature": 1.0,
  "top_k": 50,
  "top_p": 1.0,
  "torchscript": false,
  "type_vocab_size": 2,
  "use_bfloat16": false,
  "vocab_size": 28996
}

2021-11-15 01:57:38,939 => loading weights file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-cased-pytorch_model.bin from cache at /home/yinan/.cache/torch/transformers/35d8b9d36faaf46728a0192d82bf7d00137490cd6074e8500778afed552a67e5.3fadbea36527ae472139fe84cddaa65454d7429f12d543d80bfc3ad70de55ac2
2021-11-15 01:57:42,542 => Weights of BertForSequenceClassification not initialized from pretrained model: ['classifier.weight', 'classifier.bias']
2021-11-15 01:57:42,542 => Weights from pretrained model not used in BertForSequenceClassification: ['cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias']
2021-11-15 02:00:33,228 => Train: 100.0	Epoch: 1	Iter: 79	Loss: 0.09124	Acc= 25.789	Precision= 25.820	Recall= 25.813	F1_score= 25.789
2021-11-15 02:03:23,744 => Train: 100.0	Epoch: 2	Iter: 79	Loss: 0.09157	Acc= 27.208	Precision= 27.304	Recall= 27.216	F1_score= 27.168
2021-11-15 02:06:14,243 => Train: 100.0	Epoch: 3	Iter: 79	Loss: 0.09160	Acc= 25.237	Precision= 25.126	Recall= 25.191	F1_score= 25.112
2021-11-15 02:09:11,844 => Train: 100.0	Epoch: 4	Iter: 79	Loss: 0.09105	Acc= 25.158	Precision= 25.001	Recall= 25.061	F1_score= 24.980
2021-11-15 02:12:22,080 => Train: 100.0	Epoch: 5	Iter: 79	Loss: 0.09149	Acc= 24.132	Precision= 23.590	Recall= 23.970	F1_score= 23.677
2021-11-15 02:15:25,201 => Train: 100.0	Epoch: 6	Iter: 79	Loss: 0.09061	Acc= 25.631	Precision= 25.315	Recall= 25.464	F1_score= 25.216
2021-11-15 02:18:16,273 => Train: 100.0	Epoch: 7	Iter: 79	Loss: 0.09003	Acc= 24.606	Precision= 24.470	Recall= 24.489	F1_score= 24.350
2021-11-15 02:21:27,913 => Train: 100.0	Epoch: 8	Iter: 79	Loss: 0.09027	Acc= 24.369	Precision= 24.279	Recall= 24.234	F1_score= 24.072
2021-11-15 02:24:32,207 => Train: 100.0	Epoch: 9	Iter: 79	Loss: 0.09000	Acc= 24.606	Precision= 24.333	Recall= 24.439	F1_score= 24.140
2021-11-15 02:27:34,684 => Train: 100.0	Epoch: 10	Iter: 79	Loss: 0.08948	Acc= 25.000	Precision= 24.560	Recall= 24.824	F1_score= 24.364
2021-11-15 02:30:27,064 => Train: 100.0	Epoch: 11	Iter: 79	Loss: 0.08932	Acc= 25.237	Precision= 24.958	Recall= 25.143	F1_score= 24.839
2021-11-15 02:33:17,991 => Train: 100.0	Epoch: 12	Iter: 79	Loss: 0.08946	Acc= 23.738	Precision= 23.154	Recall= 23.595	F1_score= 23.149
2021-11-15 02:36:08,306 => Train: 100.0	Epoch: 13	Iter: 79	Loss: 0.08910	Acc= 24.448	Precision= 23.667	Recall= 24.255	F1_score= 23.562
2021-11-15 02:38:58,888 => Train: 100.0	Epoch: 14	Iter: 79	Loss: 0.08915	Acc= 25.158	Precision= 24.940	Recall= 24.988	F1_score= 24.580
2021-11-15 02:41:49,128 => Train: 100.0	Epoch: 15	Iter: 79	Loss: 0.08905	Acc= 22.950	Precision= 22.636	Recall= 22.756	F1_score= 22.191
2021-11-15 02:44:39,503 => Train: 100.0	Epoch: 16	Iter: 79	Loss: 0.08863	Acc= 24.290	Precision= 24.067	Recall= 24.115	F1_score= 23.719
2021-11-15 02:47:42,413 => Train: 100.0	Epoch: 17	Iter: 79	Loss: 0.08894	Acc= 24.369	Precision= 24.219	Recall= 24.178	F1_score= 23.725
2021-11-15 02:50:32,958 => Train: 100.0	Epoch: 18	Iter: 79	Loss: 0.08878	Acc= 24.369	Precision= 23.732	Recall= 24.150	F1_score= 23.591
2021-11-15 02:53:24,278 => Train: 100.0	Epoch: 19	Iter: 79	Loss: 0.08841	Acc= 25.079	Precision= 24.571	Recall= 24.833	F1_score= 24.266
2021-11-15 02:56:15,395 => Train: 100.0	Epoch: 20	Iter: 79	Loss: 0.08853	Acc= 24.211	Precision= 24.184	Recall= 24.037	F1_score= 23.734
2021-11-15 02:56:21,434 => Eval: 100.0	Epoch: 20	Iter: 19	Loss: 0.08792	Acc= 26.266	Precision= 6.566	Recall= 25.000	F1_score= 10.401
2021-11-15 02:56:21,434 => AVERAGE ACCURACY: 24.054
