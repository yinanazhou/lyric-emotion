2021-12-26 14:37:43,607 => 1.9.1+cu102
2021-12-26 14:37:43,608 => cuda
2021-12-26 14:37:43,949 => loading file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-cased-vocab.txt from cache at /home/yinan/.cache/torch/transformers/5e8a2b4893d13790ed4150ca1906be5f7a03d6c4ddf62296c383f6db42814db2.e13dbb970cb325137104fb2e5f36fe865f27746c6b526f6352861b1980eb80b1
2021-12-26 14:37:55,454 => -------------------------------------------------
2021-12-26 14:37:55,455 => 1 FOLD
2021-12-26 14:37:59,841 => loading configuration file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-cased-config.json from cache at /home/yinan/.cache/torch/transformers/b945b69218e98b3e2c95acf911789741307dec43c698d35fad11c1ae28bda352.9da767be51e1327499df13488672789394e2ca38b877837e52618a67d7002391
2021-12-26 14:37:59,845 => Model config BertConfig {
  "architectures": [
    "BertForMaskedLM"
  ],
  "attention_probs_dropout_prob": 0.1,
  "bos_token_id": null,
  "do_sample": false,
  "eos_token_ids": null,
  "finetuning_task": null,
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "hidden_size": 768,
  "id2label": {
    "0": "LABEL_0",
    "1": "LABEL_1"
  },
  "initializer_range": 0.02,
  "intermediate_size": 3072,
  "is_decoder": false,
  "label2id": {
    "LABEL_0": 0,
    "LABEL_1": 1
  },
  "layer_norm_eps": 1e-12,
  "length_penalty": 1.0,
  "max_length": 20,
  "max_position_embeddings": 512,
  "model_type": "bert",
  "num_attention_heads": 12,
  "num_beams": 1,
  "num_hidden_layers": 12,
  "num_labels": 4,
  "num_return_sequences": 1,
  "output_attentions": false,
  "output_hidden_states": false,
  "output_past": true,
  "pad_token_id": 0,
  "pruned_heads": {},
  "repetition_penalty": 1.0,
  "temperature": 1.0,
  "top_k": 50,
  "top_p": 1.0,
  "torchscript": false,
  "type_vocab_size": 2,
  "use_bfloat16": false,
  "vocab_size": 28996
}

2021-12-26 14:38:00,158 => loading weights file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-cased-pytorch_model.bin from cache at /home/yinan/.cache/torch/transformers/35d8b9d36faaf46728a0192d82bf7d00137490cd6074e8500778afed552a67e5.3fadbea36527ae472139fe84cddaa65454d7429f12d543d80bfc3ad70de55ac2
2021-12-26 14:38:04,130 => Weights of BertForSequenceClassification not initialized from pretrained model: ['classifier.weight', 'classifier.bias']
2021-12-26 14:38:04,130 => Weights from pretrained model not used in BertForSequenceClassification: ['cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias']
2022-01-01 10:50:28,970 => 1.9.1+cu102
2022-01-01 10:50:28,990 => cuda
2022-01-01 10:50:28,990 => Using 4 GPUs!
2022-01-01 10:50:29,679 => loading file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-cased-vocab.txt from cache at /home/yinan/.cache/torch/transformers/5e8a2b4893d13790ed4150ca1906be5f7a03d6c4ddf62296c383f6db42814db2.e13dbb970cb325137104fb2e5f36fe865f27746c6b526f6352861b1980eb80b1
2022-01-01 10:50:41,250 => -------------------------------------------------
2022-01-01 10:50:41,250 => 1 FOLD
2022-01-01 10:50:45,553 => loading configuration file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-cased-config.json from cache at /home/yinan/.cache/torch/transformers/b945b69218e98b3e2c95acf911789741307dec43c698d35fad11c1ae28bda352.9da767be51e1327499df13488672789394e2ca38b877837e52618a67d7002391
2022-01-01 10:50:45,554 => Model config BertConfig {
  "architectures": [
    "BertForMaskedLM"
  ],
  "attention_probs_dropout_prob": 0.1,
  "bos_token_id": null,
  "do_sample": false,
  "eos_token_ids": null,
  "finetuning_task": null,
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "hidden_size": 768,
  "id2label": {
    "0": "LABEL_0",
    "1": "LABEL_1"
  },
  "initializer_range": 0.02,
  "intermediate_size": 3072,
  "is_decoder": false,
  "label2id": {
    "LABEL_0": 0,
    "LABEL_1": 1
  },
  "layer_norm_eps": 1e-12,
  "length_penalty": 1.0,
  "max_length": 20,
  "max_position_embeddings": 512,
  "model_type": "bert",
  "num_attention_heads": 12,
  "num_beams": 1,
  "num_hidden_layers": 12,
  "num_labels": 4,
  "num_return_sequences": 1,
  "output_attentions": false,
  "output_hidden_states": false,
  "output_past": true,
  "pad_token_id": 0,
  "pruned_heads": {},
  "repetition_penalty": 1.0,
  "temperature": 1.0,
  "top_k": 50,
  "top_p": 1.0,
  "torchscript": false,
  "type_vocab_size": 2,
  "use_bfloat16": false,
  "vocab_size": 28996
}

2022-01-01 10:50:45,893 => loading weights file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-cased-pytorch_model.bin from cache at /home/yinan/.cache/torch/transformers/35d8b9d36faaf46728a0192d82bf7d00137490cd6074e8500778afed552a67e5.3fadbea36527ae472139fe84cddaa65454d7429f12d543d80bfc3ad70de55ac2
2022-01-01 10:50:49,730 => Weights of BertForSequenceClassification not initialized from pretrained model: ['classifier.weight', 'classifier.bias']
2022-01-01 10:50:49,730 => Weights from pretrained model not used in BertForSequenceClassification: ['cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias']
2022-01-01 10:52:48,073 => Train: 100.0	Epoch: 1	Iter: 158	Loss: 0.14053	Acc= 51.855	Precision= 55.089	Recall= 51.625	F1_score= 51.541
2022-01-01 10:54:40,021 => Train: 100.0	Epoch: 2	Iter: 158	Loss: 0.06146	Acc= 83.899	Precision= 83.944	Recall= 83.827	F1_score= 83.860
2022-01-01 10:56:33,248 => Train: 100.0	Epoch: 3	Iter: 158	Loss: 0.02909	Acc= 93.449	Precision= 93.455	Recall= 93.415	F1_score= 93.428
2022-01-01 10:58:26,442 => Train: 100.0	Epoch: 4	Iter: 158	Loss: 0.01477	Acc= 97.159	Precision= 97.155	Recall= 97.158	F1_score= 97.156
2022-01-01 11:00:18,752 => Train: 100.0	Epoch: 5	Iter: 158	Loss: 0.00942	Acc= 98.658	Precision= 98.647	Recall= 98.654	F1_score= 98.650
2022-01-01 11:02:11,231 => Train: 100.0	Epoch: 6	Iter: 158	Loss: 0.00455	Acc= 99.526	Precision= 99.520	Recall= 99.525	F1_score= 99.522
2022-01-01 11:02:11,279 => Epoch: 6	early stopped at loss: 0.00455
2022-01-01 11:02:23,940 => Eval: 100.0	Epoch: 6	Iter: 39	Loss: 0.04228	Acc= 88.328	Precision= 88.424	Recall= 88.300	F1_score= 88.310
2022-01-01 11:02:23,941 => -------------------------------------------------
2022-01-01 11:02:23,941 => 2 FOLD
2022-01-01 11:02:28,224 => loading configuration file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-cased-config.json from cache at /home/yinan/.cache/torch/transformers/b945b69218e98b3e2c95acf911789741307dec43c698d35fad11c1ae28bda352.9da767be51e1327499df13488672789394e2ca38b877837e52618a67d7002391
2022-01-01 11:02:28,225 => Model config BertConfig {
  "architectures": [
    "BertForMaskedLM"
  ],
  "attention_probs_dropout_prob": 0.1,
  "bos_token_id": null,
  "do_sample": false,
  "eos_token_ids": null,
  "finetuning_task": null,
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "hidden_size": 768,
  "id2label": {
    "0": "LABEL_0",
    "1": "LABEL_1"
  },
  "initializer_range": 0.02,
  "intermediate_size": 3072,
  "is_decoder": false,
  "label2id": {
    "LABEL_0": 0,
    "LABEL_1": 1
  },
  "layer_norm_eps": 1e-12,
  "length_penalty": 1.0,
  "max_length": 20,
  "max_position_embeddings": 512,
  "model_type": "bert",
  "num_attention_heads": 12,
  "num_beams": 1,
  "num_hidden_layers": 12,
  "num_labels": 4,
  "num_return_sequences": 1,
  "output_attentions": false,
  "output_hidden_states": false,
  "output_past": true,
  "pad_token_id": 0,
  "pruned_heads": {},
  "repetition_penalty": 1.0,
  "temperature": 1.0,
  "top_k": 50,
  "top_p": 1.0,
  "torchscript": false,
  "type_vocab_size": 2,
  "use_bfloat16": false,
  "vocab_size": 28996
}

2022-01-01 11:02:28,583 => loading weights file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-cased-pytorch_model.bin from cache at /home/yinan/.cache/torch/transformers/35d8b9d36faaf46728a0192d82bf7d00137490cd6074e8500778afed552a67e5.3fadbea36527ae472139fe84cddaa65454d7429f12d543d80bfc3ad70de55ac2
2022-01-01 11:02:32,259 => Weights of BertForSequenceClassification not initialized from pretrained model: ['classifier.weight', 'classifier.bias']
2022-01-01 11:02:32,259 => Weights from pretrained model not used in BertForSequenceClassification: ['cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias']
2022-01-01 11:04:24,117 => Train: 100.0	Epoch: 1	Iter: 158	Loss: 0.14063	Acc= 51.223	Precision= 51.033	Recall= 50.784	F1_score= 50.138
2022-01-01 11:06:15,642 => Train: 100.0	Epoch: 2	Iter: 158	Loss: 0.06191	Acc= 84.530	Precision= 84.581	Recall= 84.426	F1_score= 84.456
2022-01-01 11:08:07,199 => Train: 100.0	Epoch: 3	Iter: 158	Loss: 0.02578	Acc= 94.002	Precision= 93.989	Recall= 94.015	F1_score= 93.984
2022-01-01 11:09:58,677 => Train: 100.0	Epoch: 4	Iter: 158	Loss: 0.01100	Acc= 98.106	Precision= 98.101	Recall= 98.118	F1_score= 98.105
2022-01-01 11:11:50,331 => Train: 100.0	Epoch: 5	Iter: 158	Loss: 0.00564	Acc= 99.448	Precision= 99.446	Recall= 99.450	F1_score= 99.448
2022-01-01 11:13:41,784 => Train: 100.0	Epoch: 6	Iter: 158	Loss: 0.00319	Acc= 99.763	Precision= 99.762	Recall= 99.765	F1_score= 99.763
2022-01-01 11:13:41,786 => Epoch: 6	early stopped at loss: 0.00319
2022-01-01 11:13:54,260 => Eval: 100.0	Epoch: 6	Iter: 39	Loss: 0.04934	Acc= 88.959	Precision= 89.163	Recall= 89.019	F1_score= 89.044
2022-01-01 11:13:54,261 => -------------------------------------------------
2022-01-01 11:13:54,261 => 3 FOLD
2022-01-01 11:13:58,559 => loading configuration file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-cased-config.json from cache at /home/yinan/.cache/torch/transformers/b945b69218e98b3e2c95acf911789741307dec43c698d35fad11c1ae28bda352.9da767be51e1327499df13488672789394e2ca38b877837e52618a67d7002391
2022-01-01 11:13:58,560 => Model config BertConfig {
  "architectures": [
    "BertForMaskedLM"
  ],
  "attention_probs_dropout_prob": 0.1,
  "bos_token_id": null,
  "do_sample": false,
  "eos_token_ids": null,
  "finetuning_task": null,
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "hidden_size": 768,
  "id2label": {
    "0": "LABEL_0",
    "1": "LABEL_1"
  },
  "initializer_range": 0.02,
  "intermediate_size": 3072,
  "is_decoder": false,
  "label2id": {
    "LABEL_0": 0,
    "LABEL_1": 1
  },
  "layer_norm_eps": 1e-12,
  "length_penalty": 1.0,
  "max_length": 20,
  "max_position_embeddings": 512,
  "model_type": "bert",
  "num_attention_heads": 12,
  "num_beams": 1,
  "num_hidden_layers": 12,
  "num_labels": 4,
  "num_return_sequences": 1,
  "output_attentions": false,
  "output_hidden_states": false,
  "output_past": true,
  "pad_token_id": 0,
  "pruned_heads": {},
  "repetition_penalty": 1.0,
  "temperature": 1.0,
  "top_k": 50,
  "top_p": 1.0,
  "torchscript": false,
  "type_vocab_size": 2,
  "use_bfloat16": false,
  "vocab_size": 28996
}

2022-01-01 11:13:58,889 => loading weights file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-cased-pytorch_model.bin from cache at /home/yinan/.cache/torch/transformers/35d8b9d36faaf46728a0192d82bf7d00137490cd6074e8500778afed552a67e5.3fadbea36527ae472139fe84cddaa65454d7429f12d543d80bfc3ad70de55ac2
2022-01-01 11:14:02,647 => Weights of BertForSequenceClassification not initialized from pretrained model: ['classifier.weight', 'classifier.bias']
2022-01-01 11:14:02,647 => Weights from pretrained model not used in BertForSequenceClassification: ['cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias']
2022-01-01 11:15:54,321 => Train: 100.0	Epoch: 1	Iter: 158	Loss: 0.14145	Acc= 49.250	Precision= 48.502	Recall= 49.132	F1_score= 48.552
2022-01-01 11:17:46,202 => Train: 100.0	Epoch: 2	Iter: 158	Loss: 0.07260	Acc= 80.110	Precision= 80.106	Recall= 80.073	F1_score= 80.081
2022-01-01 11:19:37,747 => Train: 100.0	Epoch: 3	Iter: 158	Loss: 0.03609	Acc= 91.949	Precision= 91.949	Recall= 91.946	F1_score= 91.944
2022-01-01 11:21:29,577 => Train: 100.0	Epoch: 4	Iter: 158	Loss: 0.01715	Acc= 97.316	Precision= 97.323	Recall= 97.324	F1_score= 97.314
2022-01-01 11:23:21,113 => Train: 100.0	Epoch: 5	Iter: 158	Loss: 0.00918	Acc= 98.816	Precision= 98.816	Recall= 98.823	F1_score= 98.816
2022-01-01 11:25:12,941 => Train: 100.0	Epoch: 6	Iter: 158	Loss: 0.00536	Acc= 99.605	Precision= 99.604	Recall= 99.607	F1_score= 99.605
2022-01-01 11:25:13,014 => Epoch: 6	early stopped at loss: 0.00536
2022-01-01 11:25:25,742 => Eval: 100.0	Epoch: 6	Iter: 39	Loss: 0.03771	Acc= 88.959	Precision= 89.299	Recall= 88.978	F1_score= 88.979
2022-01-01 11:25:25,742 => -------------------------------------------------
2022-01-01 11:25:25,743 => 4 FOLD
2022-01-01 11:25:30,127 => loading configuration file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-cased-config.json from cache at /home/yinan/.cache/torch/transformers/b945b69218e98b3e2c95acf911789741307dec43c698d35fad11c1ae28bda352.9da767be51e1327499df13488672789394e2ca38b877837e52618a67d7002391
2022-01-01 11:25:30,128 => Model config BertConfig {
  "architectures": [
    "BertForMaskedLM"
  ],
  "attention_probs_dropout_prob": 0.1,
  "bos_token_id": null,
  "do_sample": false,
  "eos_token_ids": null,
  "finetuning_task": null,
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "hidden_size": 768,
  "id2label": {
    "0": "LABEL_0",
    "1": "LABEL_1"
  },
  "initializer_range": 0.02,
  "intermediate_size": 3072,
  "is_decoder": false,
  "label2id": {
    "LABEL_0": 0,
    "LABEL_1": 1
  },
  "layer_norm_eps": 1e-12,
  "length_penalty": 1.0,
  "max_length": 20,
  "max_position_embeddings": 512,
  "model_type": "bert",
  "num_attention_heads": 12,
  "num_beams": 1,
  "num_hidden_layers": 12,
  "num_labels": 4,
  "num_return_sequences": 1,
  "output_attentions": false,
  "output_hidden_states": false,
  "output_past": true,
  "pad_token_id": 0,
  "pruned_heads": {},
  "repetition_penalty": 1.0,
  "temperature": 1.0,
  "top_k": 50,
  "top_p": 1.0,
  "torchscript": false,
  "type_vocab_size": 2,
  "use_bfloat16": false,
  "vocab_size": 28996
}

2022-01-01 11:25:30,454 => loading weights file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-cased-pytorch_model.bin from cache at /home/yinan/.cache/torch/transformers/35d8b9d36faaf46728a0192d82bf7d00137490cd6074e8500778afed552a67e5.3fadbea36527ae472139fe84cddaa65454d7429f12d543d80bfc3ad70de55ac2
2022-01-01 11:25:34,107 => Weights of BertForSequenceClassification not initialized from pretrained model: ['classifier.weight', 'classifier.bias']
2022-01-01 11:25:34,108 => Weights from pretrained model not used in BertForSequenceClassification: ['cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias']
2022-01-01 11:27:26,317 => Train: 100.0	Epoch: 1	Iter: 158	Loss: 0.16594	Acc= 35.675	Precision= 35.257	Recall= 35.574	F1_score= 35.241
2022-01-01 11:29:18,758 => Train: 100.0	Epoch: 2	Iter: 158	Loss: 0.12218	Acc= 58.642	Precision= 59.879	Recall= 58.429	F1_score= 58.044
2022-01-01 11:31:11,004 => Train: 100.0	Epoch: 3	Iter: 158	Loss: 0.08587	Acc= 74.980	Precision= 75.963	Recall= 74.894	F1_score= 74.811
2022-01-01 11:33:03,037 => Train: 100.0	Epoch: 4	Iter: 158	Loss: 0.04802	Acc= 87.609	Precision= 87.630	Recall= 87.604	F1_score= 87.608
2022-01-01 11:34:55,099 => Train: 100.0	Epoch: 5	Iter: 158	Loss: 0.02232	Acc= 95.580	Precision= 95.585	Recall= 95.580	F1_score= 95.575
2022-01-01 11:36:47,386 => Train: 100.0	Epoch: 6	Iter: 158	Loss: 0.01605	Acc= 96.764	Precision= 96.752	Recall= 96.753	F1_score= 96.751
2022-01-01 11:38:39,245 => Train: 100.0	Epoch: 7	Iter: 158	Loss: 0.00644	Acc= 99.290	Precision= 99.287	Recall= 99.288	F1_score= 99.288
2022-01-01 11:40:31,060 => Train: 100.0	Epoch: 8	Iter: 158	Loss: 0.00610	Acc= 99.053	Precision= 99.054	Recall= 99.051	F1_score= 99.053
2022-01-01 11:40:31,075 => Epoch: 8	early stopped at loss: 0.00610
2022-01-01 11:40:47,330 => Eval: 100.0	Epoch: 8	Iter: 39	Loss: 0.05380	Acc= 87.697	Precision= 88.607	Recall= 87.122	F1_score= 87.486
2022-01-01 11:40:47,331 => -------------------------------------------------
2022-01-01 11:40:47,331 => 5 FOLD
2022-01-01 11:40:51,888 => loading configuration file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-cased-config.json from cache at /home/yinan/.cache/torch/transformers/b945b69218e98b3e2c95acf911789741307dec43c698d35fad11c1ae28bda352.9da767be51e1327499df13488672789394e2ca38b877837e52618a67d7002391
2022-01-01 11:40:51,889 => Model config BertConfig {
  "architectures": [
    "BertForMaskedLM"
  ],
  "attention_probs_dropout_prob": 0.1,
  "bos_token_id": null,
  "do_sample": false,
  "eos_token_ids": null,
  "finetuning_task": null,
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "hidden_size": 768,
  "id2label": {
    "0": "LABEL_0",
    "1": "LABEL_1"
  },
  "initializer_range": 0.02,
  "intermediate_size": 3072,
  "is_decoder": false,
  "label2id": {
    "LABEL_0": 0,
    "LABEL_1": 1
  },
  "layer_norm_eps": 1e-12,
  "length_penalty": 1.0,
  "max_length": 20,
  "max_position_embeddings": 512,
  "model_type": "bert",
  "num_attention_heads": 12,
  "num_beams": 1,
  "num_hidden_layers": 12,
  "num_labels": 4,
  "num_return_sequences": 1,
  "output_attentions": false,
  "output_hidden_states": false,
  "output_past": true,
  "pad_token_id": 0,
  "pruned_heads": {},
  "repetition_penalty": 1.0,
  "temperature": 1.0,
  "top_k": 50,
  "top_p": 1.0,
  "torchscript": false,
  "type_vocab_size": 2,
  "use_bfloat16": false,
  "vocab_size": 28996
}

2022-01-01 11:40:52,229 => loading weights file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-cased-pytorch_model.bin from cache at /home/yinan/.cache/torch/transformers/35d8b9d36faaf46728a0192d82bf7d00137490cd6074e8500778afed552a67e5.3fadbea36527ae472139fe84cddaa65454d7429f12d543d80bfc3ad70de55ac2
2022-01-01 11:40:55,766 => Weights of BertForSequenceClassification not initialized from pretrained model: ['classifier.weight', 'classifier.bias']
2022-01-01 11:40:55,766 => Weights from pretrained model not used in BertForSequenceClassification: ['cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias']
2022-01-01 11:42:47,264 => Train: 100.0	Epoch: 1	Iter: 158	Loss: 0.14232	Acc= 51.420	Precision= 55.971	Recall= 51.158	F1_score= 50.689
2022-01-01 11:44:41,534 => Train: 100.0	Epoch: 2	Iter: 158	Loss: 0.06856	Acc= 80.915	Precision= 81.129	Recall= 80.743	F1_score= 80.761
2022-01-01 11:46:32,814 => Train: 100.0	Epoch: 3	Iter: 158	Loss: 0.02955	Acc= 93.849	Precision= 93.856	Recall= 93.807	F1_score= 93.825
2022-01-01 11:48:24,377 => Train: 100.0	Epoch: 4	Iter: 158	Loss: 0.01254	Acc= 98.265	Precision= 98.286	Recall= 98.250	F1_score= 98.263
2022-01-01 11:50:16,212 => Train: 100.0	Epoch: 5	Iter: 158	Loss: 0.00624	Acc= 99.527	Precision= 99.523	Recall= 99.526	F1_score= 99.524
2022-01-01 11:52:07,714 => Train: 100.0	Epoch: 6	Iter: 158	Loss: 0.00436	Acc= 99.527	Precision= 99.529	Recall= 99.524	F1_score= 99.526
2022-01-01 11:52:07,735 => Epoch: 6	early stopped at loss: 0.00436
2022-01-01 11:52:19,702 => Eval: 100.0	Epoch: 6	Iter: 39	Loss: 0.03309	Acc= 92.722	Precision= 93.017	Recall= 92.625	F1_score= 92.764
2022-01-01 11:52:19,703 => AVERAGE ACCURACY: 89.333
