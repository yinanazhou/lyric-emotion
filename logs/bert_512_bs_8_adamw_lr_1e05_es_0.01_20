2021-11-21 17:12:51,759 => 1.9.1+cu102
2021-11-21 17:12:51,760 => cuda
2021-11-21 17:12:52,214 => loading file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-cased-vocab.txt from cache at /home/yinan/.cache/torch/transformers/5e8a2b4893d13790ed4150ca1906be5f7a03d6c4ddf62296c383f6db42814db2.e13dbb970cb325137104fb2e5f36fe865f27746c6b526f6352861b1980eb80b1
2021-11-21 17:13:07,440 => -------------------------------------------------
2021-11-21 17:13:07,440 => 1 FOLD
2021-11-21 17:13:07,872 => loading configuration file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-cased-config.json from cache at /home/yinan/.cache/torch/transformers/b945b69218e98b3e2c95acf911789741307dec43c698d35fad11c1ae28bda352.9da767be51e1327499df13488672789394e2ca38b877837e52618a67d7002391
2021-11-21 17:13:07,873 => Model config BertConfig {
  "architectures": [
    "BertForMaskedLM"
  ],
  "attention_probs_dropout_prob": 0.1,
  "bos_token_id": null,
  "do_sample": false,
  "eos_token_ids": null,
  "finetuning_task": null,
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "hidden_size": 768,
  "id2label": {
    "0": "LABEL_0",
    "1": "LABEL_1"
  },
  "initializer_range": 0.02,
  "intermediate_size": 3072,
  "is_decoder": false,
  "label2id": {
    "LABEL_0": 0,
    "LABEL_1": 1
  },
  "layer_norm_eps": 1e-12,
  "length_penalty": 1.0,
  "max_length": 20,
  "max_position_embeddings": 512,
  "model_type": "bert",
  "num_attention_heads": 12,
  "num_beams": 1,
  "num_hidden_layers": 12,
  "num_labels": 4,
  "num_return_sequences": 1,
  "output_attentions": false,
  "output_hidden_states": false,
  "output_past": true,
  "pad_token_id": 0,
  "pruned_heads": {},
  "repetition_penalty": 1.0,
  "temperature": 1.0,
  "top_k": 50,
  "top_p": 1.0,
  "torchscript": false,
  "type_vocab_size": 2,
  "use_bfloat16": false,
  "vocab_size": 28996
}

2021-11-21 17:13:08,298 => loading weights file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-cased-pytorch_model.bin from cache at /home/yinan/.cache/torch/transformers/35d8b9d36faaf46728a0192d82bf7d00137490cd6074e8500778afed552a67e5.3fadbea36527ae472139fe84cddaa65454d7429f12d543d80bfc3ad70de55ac2
2021-11-21 17:13:12,087 => Weights of BertForSequenceClassification not initialized from pretrained model: ['classifier.weight', 'classifier.bias']
2021-11-21 17:13:12,087 => Weights from pretrained model not used in BertForSequenceClassification: ['cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias']
2021-11-21 17:14:15,165 => Train: 100.0	Epoch: 1	Iter: 158	Loss: 0.13927	Acc= 52.013	Precision= 54.158	Recall= 51.898	F1_score= 51.861
2021-11-21 17:15:13,937 => Train: 100.0	Epoch: 2	Iter: 158	Loss: 0.06598	Acc= 82.557	Precision= 82.594	Recall= 82.497	F1_score= 82.496
2021-11-21 17:16:12,736 => Train: 100.0	Epoch: 3	Iter: 158	Loss: 0.02843	Acc= 94.238	Precision= 94.292	Recall= 94.214	F1_score= 94.230
2021-11-21 17:17:11,532 => Train: 100.0	Epoch: 4	Iter: 158	Loss: 0.01320	Acc= 97.632	Precision= 97.636	Recall= 97.625	F1_score= 97.629
2021-11-21 17:18:10,346 => Train: 100.0	Epoch: 5	Iter: 158	Loss: 0.00770	Acc= 98.816	Precision= 98.814	Recall= 98.815	F1_score= 98.814
2021-11-21 17:18:10,348 => Epoch: 5	early stopped at loss: 0.00770
2021-11-21 17:18:13,880 => Eval: 100.0	Epoch: 5	Iter: 39	Loss: 0.04919	Acc= 87.697	Precision= 88.086	Recall= 87.313	F1_score= 87.467
2021-11-21 17:18:13,880 => -------------------------------------------------
2021-11-21 17:18:13,880 => 2 FOLD
2021-11-21 17:18:14,316 => loading configuration file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-cased-config.json from cache at /home/yinan/.cache/torch/transformers/b945b69218e98b3e2c95acf911789741307dec43c698d35fad11c1ae28bda352.9da767be51e1327499df13488672789394e2ca38b877837e52618a67d7002391
2021-11-21 17:18:14,317 => Model config BertConfig {
  "architectures": [
    "BertForMaskedLM"
  ],
  "attention_probs_dropout_prob": 0.1,
  "bos_token_id": null,
  "do_sample": false,
  "eos_token_ids": null,
  "finetuning_task": null,
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "hidden_size": 768,
  "id2label": {
    "0": "LABEL_0",
    "1": "LABEL_1"
  },
  "initializer_range": 0.02,
  "intermediate_size": 3072,
  "is_decoder": false,
  "label2id": {
    "LABEL_0": 0,
    "LABEL_1": 1
  },
  "layer_norm_eps": 1e-12,
  "length_penalty": 1.0,
  "max_length": 20,
  "max_position_embeddings": 512,
  "model_type": "bert",
  "num_attention_heads": 12,
  "num_beams": 1,
  "num_hidden_layers": 12,
  "num_labels": 4,
  "num_return_sequences": 1,
  "output_attentions": false,
  "output_hidden_states": false,
  "output_past": true,
  "pad_token_id": 0,
  "pruned_heads": {},
  "repetition_penalty": 1.0,
  "temperature": 1.0,
  "top_k": 50,
  "top_p": 1.0,
  "torchscript": false,
  "type_vocab_size": 2,
  "use_bfloat16": false,
  "vocab_size": 28996
}

2021-11-21 17:18:14,717 => loading weights file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-cased-pytorch_model.bin from cache at /home/yinan/.cache/torch/transformers/35d8b9d36faaf46728a0192d82bf7d00137490cd6074e8500778afed552a67e5.3fadbea36527ae472139fe84cddaa65454d7429f12d543d80bfc3ad70de55ac2
2021-11-21 17:18:18,530 => Weights of BertForSequenceClassification not initialized from pretrained model: ['classifier.weight', 'classifier.bias']
2021-11-21 17:18:18,530 => Weights from pretrained model not used in BertForSequenceClassification: ['cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias']
2021-11-21 17:19:16,646 => Train: 100.0	Epoch: 1	Iter: 158	Loss: 0.14746	Acc= 48.777	Precision= 52.528	Recall= 48.627	F1_score= 48.019
2021-11-21 17:20:14,686 => Train: 100.0	Epoch: 2	Iter: 158	Loss: 0.06935	Acc= 81.215	Precision= 81.328	Recall= 81.152	F1_score= 81.152
2021-11-21 17:21:12,754 => Train: 100.0	Epoch: 3	Iter: 158	Loss: 0.03009	Acc= 93.370	Precision= 93.405	Recall= 93.375	F1_score= 93.368
2021-11-21 17:22:10,815 => Train: 100.0	Epoch: 4	Iter: 158	Loss: 0.01613	Acc= 97.080	Precision= 97.066	Recall= 97.072	F1_score= 97.066
2021-11-21 17:23:08,803 => Train: 100.0	Epoch: 5	Iter: 158	Loss: 0.00787	Acc= 98.974	Precision= 98.965	Recall= 98.975	F1_score= 98.966
2021-11-21 17:23:08,805 => Epoch: 5	early stopped at loss: 0.00787
2021-11-21 17:23:12,337 => Eval: 100.0	Epoch: 5	Iter: 39	Loss: 0.04241	Acc= 90.536	Precision= 90.915	Recall= 90.425	F1_score= 90.456
2021-11-21 17:23:12,337 => -------------------------------------------------
2021-11-21 17:23:12,337 => 3 FOLD
2021-11-21 17:23:12,780 => loading configuration file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-cased-config.json from cache at /home/yinan/.cache/torch/transformers/b945b69218e98b3e2c95acf911789741307dec43c698d35fad11c1ae28bda352.9da767be51e1327499df13488672789394e2ca38b877837e52618a67d7002391
2021-11-21 17:23:12,781 => Model config BertConfig {
  "architectures": [
    "BertForMaskedLM"
  ],
  "attention_probs_dropout_prob": 0.1,
  "bos_token_id": null,
  "do_sample": false,
  "eos_token_ids": null,
  "finetuning_task": null,
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "hidden_size": 768,
  "id2label": {
    "0": "LABEL_0",
    "1": "LABEL_1"
  },
  "initializer_range": 0.02,
  "intermediate_size": 3072,
  "is_decoder": false,
  "label2id": {
    "LABEL_0": 0,
    "LABEL_1": 1
  },
  "layer_norm_eps": 1e-12,
  "length_penalty": 1.0,
  "max_length": 20,
  "max_position_embeddings": 512,
  "model_type": "bert",
  "num_attention_heads": 12,
  "num_beams": 1,
  "num_hidden_layers": 12,
  "num_labels": 4,
  "num_return_sequences": 1,
  "output_attentions": false,
  "output_hidden_states": false,
  "output_past": true,
  "pad_token_id": 0,
  "pruned_heads": {},
  "repetition_penalty": 1.0,
  "temperature": 1.0,
  "top_k": 50,
  "top_p": 1.0,
  "torchscript": false,
  "type_vocab_size": 2,
  "use_bfloat16": false,
  "vocab_size": 28996
}

2021-11-21 17:23:13,191 => loading weights file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-cased-pytorch_model.bin from cache at /home/yinan/.cache/torch/transformers/35d8b9d36faaf46728a0192d82bf7d00137490cd6074e8500778afed552a67e5.3fadbea36527ae472139fe84cddaa65454d7429f12d543d80bfc3ad70de55ac2
2021-11-21 17:23:16,838 => Weights of BertForSequenceClassification not initialized from pretrained model: ['classifier.weight', 'classifier.bias']
2021-11-21 17:23:16,838 => Weights from pretrained model not used in BertForSequenceClassification: ['cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias']
2021-11-21 17:24:15,860 => Train: 100.0	Epoch: 1	Iter: 158	Loss: 0.14692	Acc= 47.987	Precision= 49.451	Recall= 47.813	F1_score= 47.767
2021-11-21 17:25:14,772 => Train: 100.0	Epoch: 2	Iter: 158	Loss: 0.07027	Acc= 80.426	Precision= 80.416	Recall= 80.401	F1_score= 80.406
2021-11-21 17:26:13,615 => Train: 100.0	Epoch: 3	Iter: 158	Loss: 0.02854	Acc= 93.923	Precision= 93.914	Recall= 93.900	F1_score= 93.902
2021-11-21 17:27:12,520 => Train: 100.0	Epoch: 4	Iter: 158	Loss: 0.01264	Acc= 98.500	Precision= 98.509	Recall= 98.499	F1_score= 98.501
2021-11-21 17:28:11,399 => Train: 100.0	Epoch: 5	Iter: 158	Loss: 0.00721	Acc= 99.290	Precision= 99.295	Recall= 99.299	F1_score= 99.296
2021-11-21 17:28:11,401 => Epoch: 5	early stopped at loss: 0.00721
2021-11-21 17:28:14,872 => Eval: 100.0	Epoch: 5	Iter: 39	Loss: 0.04300	Acc= 90.221	Precision= 90.206	Recall= 89.949	F1_score= 89.989
2021-11-21 17:28:14,872 => -------------------------------------------------
2021-11-21 17:28:14,872 => 4 FOLD
2021-11-21 17:28:15,301 => loading configuration file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-cased-config.json from cache at /home/yinan/.cache/torch/transformers/b945b69218e98b3e2c95acf911789741307dec43c698d35fad11c1ae28bda352.9da767be51e1327499df13488672789394e2ca38b877837e52618a67d7002391
2021-11-21 17:28:15,302 => Model config BertConfig {
  "architectures": [
    "BertForMaskedLM"
  ],
  "attention_probs_dropout_prob": 0.1,
  "bos_token_id": null,
  "do_sample": false,
  "eos_token_ids": null,
  "finetuning_task": null,
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "hidden_size": 768,
  "id2label": {
    "0": "LABEL_0",
    "1": "LABEL_1"
  },
  "initializer_range": 0.02,
  "intermediate_size": 3072,
  "is_decoder": false,
  "label2id": {
    "LABEL_0": 0,
    "LABEL_1": 1
  },
  "layer_norm_eps": 1e-12,
  "length_penalty": 1.0,
  "max_length": 20,
  "max_position_embeddings": 512,
  "model_type": "bert",
  "num_attention_heads": 12,
  "num_beams": 1,
  "num_hidden_layers": 12,
  "num_labels": 4,
  "num_return_sequences": 1,
  "output_attentions": false,
  "output_hidden_states": false,
  "output_past": true,
  "pad_token_id": 0,
  "pruned_heads": {},
  "repetition_penalty": 1.0,
  "temperature": 1.0,
  "top_k": 50,
  "top_p": 1.0,
  "torchscript": false,
  "type_vocab_size": 2,
  "use_bfloat16": false,
  "vocab_size": 28996
}

2021-11-21 17:28:15,701 => loading weights file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-cased-pytorch_model.bin from cache at /home/yinan/.cache/torch/transformers/35d8b9d36faaf46728a0192d82bf7d00137490cd6074e8500778afed552a67e5.3fadbea36527ae472139fe84cddaa65454d7429f12d543d80bfc3ad70de55ac2
2021-11-21 17:28:19,400 => Weights of BertForSequenceClassification not initialized from pretrained model: ['classifier.weight', 'classifier.bias']
2021-11-21 17:28:19,401 => Weights from pretrained model not used in BertForSequenceClassification: ['cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias']
2021-11-21 17:29:17,500 => Train: 100.0	Epoch: 1	Iter: 158	Loss: 0.16728	Acc= 32.123	Precision= 32.449	Recall= 32.136	F1_score= 32.011
2021-11-21 17:30:15,530 => Train: 100.0	Epoch: 2	Iter: 158	Loss: 0.12897	Acc= 55.328	Precision= 58.223	Recall= 54.861	F1_score= 53.966
2021-11-21 17:31:13,565 => Train: 100.0	Epoch: 3	Iter: 158	Loss: 0.08102	Acc= 77.743	Precision= 79.244	Recall= 77.478	F1_score= 77.587
2021-11-21 17:32:11,543 => Train: 100.0	Epoch: 4	Iter: 158	Loss: 0.03933	Acc= 90.766	Precision= 90.792	Recall= 90.744	F1_score= 90.763
2021-11-21 17:33:09,567 => Train: 100.0	Epoch: 5	Iter: 158	Loss: 0.01881	Acc= 96.606	Precision= 96.604	Recall= 96.625	F1_score= 96.611
2021-11-21 17:34:07,597 => Train: 100.0	Epoch: 6	Iter: 158	Loss: 0.01021	Acc= 98.658	Precision= 98.652	Recall= 98.655	F1_score= 98.653
2021-11-21 17:35:05,554 => Train: 100.0	Epoch: 7	Iter: 158	Loss: 0.00607	Acc= 99.526	Precision= 99.529	Recall= 99.518	F1_score= 99.523
2021-11-21 17:35:05,555 => Epoch: 7	early stopped at loss: 0.00607
2021-11-21 17:35:09,074 => Eval: 100.0	Epoch: 7	Iter: 39	Loss: 0.04573	Acc= 87.382	Precision= 88.109	Recall= 87.539	F1_score= 87.418
2021-11-21 17:35:09,074 => -------------------------------------------------
2021-11-21 17:35:09,074 => 5 FOLD
2021-11-21 17:35:09,535 => loading configuration file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-cased-config.json from cache at /home/yinan/.cache/torch/transformers/b945b69218e98b3e2c95acf911789741307dec43c698d35fad11c1ae28bda352.9da767be51e1327499df13488672789394e2ca38b877837e52618a67d7002391
2021-11-21 17:35:09,536 => Model config BertConfig {
  "architectures": [
    "BertForMaskedLM"
  ],
  "attention_probs_dropout_prob": 0.1,
  "bos_token_id": null,
  "do_sample": false,
  "eos_token_ids": null,
  "finetuning_task": null,
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "hidden_size": 768,
  "id2label": {
    "0": "LABEL_0",
    "1": "LABEL_1"
  },
  "initializer_range": 0.02,
  "intermediate_size": 3072,
  "is_decoder": false,
  "label2id": {
    "LABEL_0": 0,
    "LABEL_1": 1
  },
  "layer_norm_eps": 1e-12,
  "length_penalty": 1.0,
  "max_length": 20,
  "max_position_embeddings": 512,
  "model_type": "bert",
  "num_attention_heads": 12,
  "num_beams": 1,
  "num_hidden_layers": 12,
  "num_labels": 4,
  "num_return_sequences": 1,
  "output_attentions": false,
  "output_hidden_states": false,
  "output_past": true,
  "pad_token_id": 0,
  "pruned_heads": {},
  "repetition_penalty": 1.0,
  "temperature": 1.0,
  "top_k": 50,
  "top_p": 1.0,
  "torchscript": false,
  "type_vocab_size": 2,
  "use_bfloat16": false,
  "vocab_size": 28996
}

2021-11-21 17:35:09,956 => loading weights file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-cased-pytorch_model.bin from cache at /home/yinan/.cache/torch/transformers/35d8b9d36faaf46728a0192d82bf7d00137490cd6074e8500778afed552a67e5.3fadbea36527ae472139fe84cddaa65454d7429f12d543d80bfc3ad70de55ac2
2021-11-21 17:35:13,657 => Weights of BertForSequenceClassification not initialized from pretrained model: ['classifier.weight', 'classifier.bias']
2021-11-21 17:35:13,658 => Weights from pretrained model not used in BertForSequenceClassification: ['cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias']
2021-11-21 17:36:12,275 => Train: 100.0	Epoch: 1	Iter: 158	Loss: 0.12958	Acc= 57.177	Precision= 57.238	Recall= 56.985	F1_score= 56.599
2021-11-21 17:37:10,835 => Train: 100.0	Epoch: 2	Iter: 158	Loss: 0.06027	Acc= 84.464	Precision= 84.424	Recall= 84.309	F1_score= 84.269
2021-11-21 17:38:09,341 => Train: 100.0	Epoch: 3	Iter: 158	Loss: 0.02603	Acc= 93.927	Precision= 93.899	Recall= 93.902	F1_score= 93.899
2021-11-21 17:39:07,892 => Train: 100.0	Epoch: 4	Iter: 158	Loss: 0.01076	Acc= 98.028	Precision= 98.013	Recall= 98.021	F1_score= 98.015
2021-11-21 17:40:06,461 => Train: 100.0	Epoch: 5	Iter: 158	Loss: 0.00539	Acc= 99.527	Precision= 99.525	Recall= 99.524	F1_score= 99.524
2021-11-21 17:40:06,462 => Epoch: 5	early stopped at loss: 0.00539
2021-11-21 17:40:09,928 => Eval: 100.0	Epoch: 5	Iter: 39	Loss: 0.04288	Acc= 89.557	Precision= 89.907	Recall= 89.472	F1_score= 89.566
2021-11-21 17:40:09,929 => AVERAGE ACCURACY: 89.079
