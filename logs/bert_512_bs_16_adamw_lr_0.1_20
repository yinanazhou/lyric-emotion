2021-11-14 22:03:22,572 => 1.10.0
2021-11-14 22:03:22,573 => cuda
2021-11-14 22:03:22,957 => loading file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-cased-vocab.txt from cache at /home/yinan/.cache/torch/transformers/5e8a2b4893d13790ed4150ca1906be5f7a03d6c4ddf62296c383f6db42814db2.e13dbb970cb325137104fb2e5f36fe865f27746c6b526f6352861b1980eb80b1
2021-11-14 22:03:33,613 => -------------------------------------------------
2021-11-14 22:03:33,613 => 1 FOLD
2021-11-14 22:03:34,129 => loading configuration file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-cased-config.json from cache at /home/yinan/.cache/torch/transformers/b945b69218e98b3e2c95acf911789741307dec43c698d35fad11c1ae28bda352.9da767be51e1327499df13488672789394e2ca38b877837e52618a67d7002391
2021-11-14 22:03:34,130 => Model config BertConfig {
  "architectures": [
    "BertForMaskedLM"
  ],
  "attention_probs_dropout_prob": 0.1,
  "bos_token_id": null,
  "do_sample": false,
  "eos_token_ids": null,
  "finetuning_task": null,
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "hidden_size": 768,
  "id2label": {
    "0": "LABEL_0",
    "1": "LABEL_1"
  },
  "initializer_range": 0.02,
  "intermediate_size": 3072,
  "is_decoder": false,
  "label2id": {
    "LABEL_0": 0,
    "LABEL_1": 1
  },
  "layer_norm_eps": 1e-12,
  "length_penalty": 1.0,
  "max_length": 20,
  "max_position_embeddings": 512,
  "model_type": "bert",
  "num_attention_heads": 12,
  "num_beams": 1,
  "num_hidden_layers": 12,
  "num_labels": 4,
  "num_return_sequences": 1,
  "output_attentions": false,
  "output_hidden_states": false,
  "output_past": true,
  "pad_token_id": 0,
  "pruned_heads": {},
  "repetition_penalty": 1.0,
  "temperature": 1.0,
  "top_k": 50,
  "top_p": 1.0,
  "torchscript": false,
  "type_vocab_size": 2,
  "use_bfloat16": false,
  "vocab_size": 28996
}

2021-11-14 22:03:34,484 => loading weights file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-cased-pytorch_model.bin from cache at /home/yinan/.cache/torch/transformers/35d8b9d36faaf46728a0192d82bf7d00137490cd6074e8500778afed552a67e5.3fadbea36527ae472139fe84cddaa65454d7429f12d543d80bfc3ad70de55ac2
2021-11-14 22:03:38,030 => Weights of BertForSequenceClassification not initialized from pretrained model: ['classifier.weight', 'classifier.bias']
2021-11-14 22:03:38,030 => Weights from pretrained model not used in BertForSequenceClassification: ['cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias']
2021-11-14 22:06:34,705 => Train: 100.0	Epoch: 1	Iter: 79	Loss: 1.29119	Acc= 24.152	Precision= 24.057	Recall= 24.089	F1_score= 24.066
2021-11-14 22:09:28,312 => Train: 100.0	Epoch: 2	Iter: 79	Loss: 0.71354	Acc= 24.073	Precision= 24.029	Recall= 24.030	F1_score= 24.028
2021-11-14 22:12:22,615 => Train: 100.0	Epoch: 3	Iter: 79	Loss: 0.44815	Acc= 25.099	Precision= 25.133	Recall= 25.094	F1_score= 25.102
2021-11-14 22:15:16,434 => Train: 100.0	Epoch: 4	Iter: 79	Loss: 0.43908	Acc= 23.520	Precision= 23.467	Recall= 23.470	F1_score= 23.468
2021-11-14 22:18:09,819 => Train: 100.0	Epoch: 5	Iter: 79	Loss: 0.38364	Acc= 23.994	Precision= 23.978	Recall= 23.952	F1_score= 23.963
2021-11-14 22:21:03,574 => Train: 100.0	Epoch: 6	Iter: 79	Loss: 0.38366	Acc= 23.678	Precision= 23.658	Recall= 23.653	F1_score= 23.655
2021-11-14 22:23:56,872 => Train: 100.0	Epoch: 7	Iter: 79	Loss: 0.28168	Acc= 26.204	Precision= 26.195	Recall= 26.186	F1_score= 26.190
2021-11-14 22:26:50,444 => Train: 100.0	Epoch: 8	Iter: 79	Loss: 0.30126	Acc= 22.415	Precision= 22.361	Recall= 22.350	F1_score= 22.336
2021-11-14 22:29:58,275 => Train: 100.0	Epoch: 9	Iter: 79	Loss: 0.35694	Acc= 24.230	Precision= 24.228	Recall= 24.192	F1_score= 24.206
2021-11-14 22:32:52,205 => Train: 100.0	Epoch: 10	Iter: 79	Loss: 0.21234	Acc= 24.862	Precision= 24.903	Recall= 24.829	F1_score= 24.853
2021-11-14 22:35:45,948 => Train: 100.0	Epoch: 11	Iter: 79	Loss: 0.24863	Acc= 24.941	Precision= 24.911	Recall= 24.913	F1_score= 24.912
2021-11-14 22:38:39,919 => Train: 100.0	Epoch: 12	Iter: 79	Loss: 0.18688	Acc= 24.230	Precision= 24.133	Recall= 24.175	F1_score= 24.150
2021-11-14 22:41:33,450 => Train: 100.0	Epoch: 13	Iter: 79	Loss: 0.21154	Acc= 24.152	Precision= 24.155	Recall= 24.160	F1_score= 24.153
2021-11-14 22:44:27,318 => Train: 100.0	Epoch: 14	Iter: 79	Loss: 0.18226	Acc= 25.493	Precision= 25.496	Recall= 25.488	F1_score= 25.487
2021-11-14 22:47:21,001 => Train: 100.0	Epoch: 15	Iter: 79	Loss: 0.17222	Acc= 25.493	Precision= 25.459	Recall= 25.436	F1_score= 25.429
2021-11-14 22:50:15,244 => Train: 100.0	Epoch: 16	Iter: 79	Loss: 0.19074	Acc= 27.072	Precision= 26.964	Recall= 26.992	F1_score= 26.969
2021-11-14 22:53:20,495 => Train: 100.0	Epoch: 17	Iter: 79	Loss: 0.16204	Acc= 24.230	Precision= 24.148	Recall= 24.169	F1_score= 24.149
2021-11-14 22:56:23,096 => Train: 100.0	Epoch: 18	Iter: 79	Loss: 0.14010	Acc= 23.362	Precision= 23.138	Recall= 23.249	F1_score= 23.183
2021-11-14 22:59:17,728 => Train: 100.0	Epoch: 19	Iter: 79	Loss: 0.14171	Acc= 24.230	Precision= 24.105	Recall= 24.158	F1_score= 24.118
2021-11-14 23:02:11,713 => Train: 100.0	Epoch: 20	Iter: 79	Loss: 0.13799	Acc= 23.362	Precision= 23.253	Recall= 23.273	F1_score= 23.241
2021-11-14 23:02:17,764 => Eval: 100.0	Epoch: 20	Iter: 19	Loss: 0.12846	Acc= 25.552	Precision= 6.388	Recall= 25.000	F1_score= 10.176
2021-11-14 23:02:17,764 => -------------------------------------------------
2021-11-14 23:02:17,765 => 2 FOLD
2021-11-14 23:02:18,166 => loading configuration file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-cased-config.json from cache at /home/yinan/.cache/torch/transformers/b945b69218e98b3e2c95acf911789741307dec43c698d35fad11c1ae28bda352.9da767be51e1327499df13488672789394e2ca38b877837e52618a67d7002391
2021-11-14 23:02:18,166 => Model config BertConfig {
  "architectures": [
    "BertForMaskedLM"
  ],
  "attention_probs_dropout_prob": 0.1,
  "bos_token_id": null,
  "do_sample": false,
  "eos_token_ids": null,
  "finetuning_task": null,
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "hidden_size": 768,
  "id2label": {
    "0": "LABEL_0",
    "1": "LABEL_1"
  },
  "initializer_range": 0.02,
  "intermediate_size": 3072,
  "is_decoder": false,
  "label2id": {
    "LABEL_0": 0,
    "LABEL_1": 1
  },
  "layer_norm_eps": 1e-12,
  "length_penalty": 1.0,
  "max_length": 20,
  "max_position_embeddings": 512,
  "model_type": "bert",
  "num_attention_heads": 12,
  "num_beams": 1,
  "num_hidden_layers": 12,
  "num_labels": 4,
  "num_return_sequences": 1,
  "output_attentions": false,
  "output_hidden_states": false,
  "output_past": true,
  "pad_token_id": 0,
  "pruned_heads": {},
  "repetition_penalty": 1.0,
  "temperature": 1.0,
  "top_k": 50,
  "top_p": 1.0,
  "torchscript": false,
  "type_vocab_size": 2,
  "use_bfloat16": false,
  "vocab_size": 28996
}

2021-11-14 23:02:18,525 => loading weights file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-cased-pytorch_model.bin from cache at /home/yinan/.cache/torch/transformers/35d8b9d36faaf46728a0192d82bf7d00137490cd6074e8500778afed552a67e5.3fadbea36527ae472139fe84cddaa65454d7429f12d543d80bfc3ad70de55ac2
2021-11-14 23:02:22,367 => Weights of BertForSequenceClassification not initialized from pretrained model: ['classifier.weight', 'classifier.bias']
2021-11-14 23:02:22,367 => Weights from pretrained model not used in BertForSequenceClassification: ['cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias']
2021-11-14 23:05:15,686 => Train: 100.0	Epoch: 1	Iter: 79	Loss: 0.98443	Acc= 24.941	Precision= 24.938	Recall= 24.952	F1_score= 24.934
2021-11-14 23:08:08,439 => Train: 100.0	Epoch: 2	Iter: 79	Loss: 0.86284	Acc= 23.283	Precision= 23.201	Recall= 23.209	F1_score= 23.199
2021-11-14 23:11:01,545 => Train: 100.0	Epoch: 3	Iter: 79	Loss: 0.55989	Acc= 23.204	Precision= 23.308	Recall= 23.269	F1_score= 23.276
2021-11-14 23:13:54,907 => Train: 100.0	Epoch: 4	Iter: 79	Loss: 0.51550	Acc= 24.230	Precision= 24.082	Recall= 24.114	F1_score= 24.095
2021-11-14 23:16:47,874 => Train: 100.0	Epoch: 5	Iter: 79	Loss: 0.41815	Acc= 25.020	Precision= 24.961	Recall= 24.990	F1_score= 24.962
2021-11-14 23:19:41,282 => Train: 100.0	Epoch: 6	Iter: 79	Loss: 0.42198	Acc= 23.520	Precision= 23.463	Recall= 23.498	F1_score= 23.473
2021-11-14 23:22:34,061 => Train: 100.0	Epoch: 7	Iter: 79	Loss: 0.43158	Acc= 23.441	Precision= 23.416	Recall= 23.385	F1_score= 23.388
2021-11-14 23:25:27,372 => Train: 100.0	Epoch: 8	Iter: 79	Loss: 0.31005	Acc= 22.178	Precision= 22.168	Recall= 22.184	F1_score= 22.169
2021-11-14 23:28:23,824 => Train: 100.0	Epoch: 9	Iter: 79	Loss: 0.27649	Acc= 27.072	Precision= 27.070	Recall= 27.056	F1_score= 27.057
2021-11-14 23:31:17,408 => Train: 100.0	Epoch: 10	Iter: 79	Loss: 0.25077	Acc= 25.414	Precision= 25.472	Recall= 25.446	F1_score= 25.458
2021-11-14 23:34:10,322 => Train: 100.0	Epoch: 11	Iter: 79	Loss: 0.24336	Acc= 24.704	Precision= 24.696	Recall= 24.703	F1_score= 24.698
2021-11-14 23:37:03,381 => Train: 100.0	Epoch: 12	Iter: 79	Loss: 0.20996	Acc= 23.836	Precision= 23.780	Recall= 23.809	F1_score= 23.786
2021-11-14 23:39:56,181 => Train: 100.0	Epoch: 13	Iter: 79	Loss: 0.22552	Acc= 23.678	Precision= 23.586	Recall= 23.565	F1_score= 23.574
2021-11-14 23:42:48,750 => Train: 100.0	Epoch: 14	Iter: 79	Loss: 0.19973	Acc= 25.257	Precision= 25.304	Recall= 25.286	F1_score= 25.289
2021-11-14 23:45:42,015 => Train: 100.0	Epoch: 15	Iter: 79	Loss: 0.17301	Acc= 24.625	Precision= 24.579	Recall= 24.581	F1_score= 24.579
2021-11-14 23:48:35,725 => Train: 100.0	Epoch: 16	Iter: 79	Loss: 0.16410	Acc= 24.862	Precision= 24.762	Recall= 24.750	F1_score= 24.736
2021-11-14 23:51:32,766 => Train: 100.0	Epoch: 17	Iter: 79	Loss: 0.15402	Acc= 23.047	Precision= 23.069	Recall= 23.079	F1_score= 23.063
2021-11-14 23:54:34,506 => Train: 100.0	Epoch: 18	Iter: 79	Loss: 0.14824	Acc= 23.204	Precision= 23.222	Recall= 23.224	F1_score= 23.216
2021-11-14 23:57:27,632 => Train: 100.0	Epoch: 19	Iter: 79	Loss: 0.13919	Acc= 24.152	Precision= 24.125	Recall= 24.169	F1_score= 24.136
2021-11-15 00:00:20,998 => Train: 100.0	Epoch: 20	Iter: 79	Loss: 0.14013	Acc= 26.914	Precision= 26.897	Recall= 26.918	F1_score= 26.905
2021-11-15 00:00:27,027 => Eval: 100.0	Epoch: 20	Iter: 19	Loss: 0.15864	Acc= 25.552	Precision= 6.388	Recall= 25.000	F1_score= 10.176
2021-11-15 00:00:27,027 => -------------------------------------------------
2021-11-15 00:00:27,027 => 3 FOLD
2021-11-15 00:00:27,389 => loading configuration file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-cased-config.json from cache at /home/yinan/.cache/torch/transformers/b945b69218e98b3e2c95acf911789741307dec43c698d35fad11c1ae28bda352.9da767be51e1327499df13488672789394e2ca38b877837e52618a67d7002391
2021-11-15 00:00:27,390 => Model config BertConfig {
  "architectures": [
    "BertForMaskedLM"
  ],
  "attention_probs_dropout_prob": 0.1,
  "bos_token_id": null,
  "do_sample": false,
  "eos_token_ids": null,
  "finetuning_task": null,
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "hidden_size": 768,
  "id2label": {
    "0": "LABEL_0",
    "1": "LABEL_1"
  },
  "initializer_range": 0.02,
  "intermediate_size": 3072,
  "is_decoder": false,
  "label2id": {
    "LABEL_0": 0,
    "LABEL_1": 1
  },
  "layer_norm_eps": 1e-12,
  "length_penalty": 1.0,
  "max_length": 20,
  "max_position_embeddings": 512,
  "model_type": "bert",
  "num_attention_heads": 12,
  "num_beams": 1,
  "num_hidden_layers": 12,
  "num_labels": 4,
  "num_return_sequences": 1,
  "output_attentions": false,
  "output_hidden_states": false,
  "output_past": true,
  "pad_token_id": 0,
  "pruned_heads": {},
  "repetition_penalty": 1.0,
  "temperature": 1.0,
  "top_k": 50,
  "top_p": 1.0,
  "torchscript": false,
  "type_vocab_size": 2,
  "use_bfloat16": false,
  "vocab_size": 28996
}

2021-11-15 00:00:27,740 => loading weights file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-cased-pytorch_model.bin from cache at /home/yinan/.cache/torch/transformers/35d8b9d36faaf46728a0192d82bf7d00137490cd6074e8500778afed552a67e5.3fadbea36527ae472139fe84cddaa65454d7429f12d543d80bfc3ad70de55ac2
2021-11-15 00:00:31,456 => Weights of BertForSequenceClassification not initialized from pretrained model: ['classifier.weight', 'classifier.bias']
2021-11-15 00:00:31,456 => Weights from pretrained model not used in BertForSequenceClassification: ['cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias']
2021-11-15 00:03:25,499 => Train: 100.0	Epoch: 1	Iter: 79	Loss: 1.09404	Acc= 25.730	Precision= 25.642	Recall= 25.698	F1_score= 25.659
2021-11-15 00:06:18,802 => Train: 100.0	Epoch: 2	Iter: 79	Loss: 0.75890	Acc= 24.073	Precision= 24.078	Recall= 24.064	F1_score= 24.068
2021-11-15 00:09:13,070 => Train: 100.0	Epoch: 3	Iter: 79	Loss: 0.47933	Acc= 23.757	Precision= 23.724	Recall= 23.732	F1_score= 23.719
2021-11-15 00:12:06,501 => Train: 100.0	Epoch: 4	Iter: 79	Loss: 0.41050	Acc= 25.257	Precision= 25.288	Recall= 25.250	F1_score= 25.262
2021-11-15 00:15:00,540 => Train: 100.0	Epoch: 5	Iter: 79	Loss: 0.34444	Acc= 24.073	Precision= 24.040	Recall= 24.059	F1_score= 24.042
2021-11-15 00:17:54,193 => Train: 100.0	Epoch: 6	Iter: 79	Loss: 0.41839	Acc= 27.151	Precision= 27.126	Recall= 27.139	F1_score= 27.130
2021-11-15 00:20:48,484 => Train: 100.0	Epoch: 7	Iter: 79	Loss: 0.39960	Acc= 24.704	Precision= 24.677	Recall= 24.722	F1_score= 24.694
2021-11-15 00:23:42,304 => Train: 100.0	Epoch: 8	Iter: 79	Loss: 0.34730	Acc= 24.073	Precision= 24.007	Recall= 24.049	F1_score= 24.022
2021-11-15 00:26:45,521 => Train: 100.0	Epoch: 9	Iter: 79	Loss: 0.34414	Acc= 25.730	Precision= 25.750	Recall= 25.712	F1_score= 25.726
2021-11-15 00:29:39,246 => Train: 100.0	Epoch: 10	Iter: 79	Loss: 0.28058	Acc= 23.915	Precision= 23.922	Recall= 23.903	F1_score= 23.908
2021-11-15 00:32:33,539 => Train: 100.0	Epoch: 11	Iter: 79	Loss: 0.30651	Acc= 23.915	Precision= 23.912	Recall= 23.906	F1_score= 23.906
2021-11-15 00:35:27,806 => Train: 100.0	Epoch: 12	Iter: 79	Loss: 0.24349	Acc= 25.335	Precision= 25.308	Recall= 25.315	F1_score= 25.309
2021-11-15 00:38:21,022 => Train: 100.0	Epoch: 13	Iter: 79	Loss: 0.25045	Acc= 23.994	Precision= 23.978	Recall= 23.972	F1_score= 23.961
2021-11-15 00:41:15,053 => Train: 100.0	Epoch: 14	Iter: 79	Loss: 0.23169	Acc= 25.020	Precision= 25.000	Recall= 24.999	F1_score= 24.999
2021-11-15 00:44:08,969 => Train: 100.0	Epoch: 15	Iter: 79	Loss: 0.18803	Acc= 25.414	Precision= 25.430	Recall= 25.428	F1_score= 25.427
2021-11-15 00:47:02,423 => Train: 100.0	Epoch: 16	Iter: 79	Loss: 0.16844	Acc= 25.414	Precision= 25.446	Recall= 25.436	F1_score= 25.438
2021-11-15 00:50:11,631 => Train: 100.0	Epoch: 17	Iter: 79	Loss: 0.17306	Acc= 24.625	Precision= 24.618	Recall= 24.630	F1_score= 24.620
2021-11-15 00:53:17,980 => Train: 100.0	Epoch: 18	Iter: 79	Loss: 0.18471	Acc= 24.230	Precision= 24.247	Recall= 24.251	F1_score= 24.247
2021-11-15 00:56:12,039 => Train: 100.0	Epoch: 19	Iter: 79	Loss: 0.15997	Acc= 24.783	Precision= 24.724	Recall= 24.759	F1_score= 24.729
2021-11-15 00:59:06,046 => Train: 100.0	Epoch: 20	Iter: 79	Loss: 0.14830	Acc= 22.810	Precision= 22.851	Recall= 22.815	F1_score= 22.825
2021-11-15 00:59:12,077 => Eval: 100.0	Epoch: 20	Iter: 19	Loss: 0.11216	Acc= 23.975	Precision= 5.994	Recall= 25.000	F1_score= 9.669
2021-11-15 00:59:12,078 => -------------------------------------------------
2021-11-15 00:59:12,078 => 4 FOLD
2021-11-15 00:59:12,455 => loading configuration file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-cased-config.json from cache at /home/yinan/.cache/torch/transformers/b945b69218e98b3e2c95acf911789741307dec43c698d35fad11c1ae28bda352.9da767be51e1327499df13488672789394e2ca38b877837e52618a67d7002391
2021-11-15 00:59:12,456 => Model config BertConfig {
  "architectures": [
    "BertForMaskedLM"
  ],
  "attention_probs_dropout_prob": 0.1,
  "bos_token_id": null,
  "do_sample": false,
  "eos_token_ids": null,
  "finetuning_task": null,
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "hidden_size": 768,
  "id2label": {
    "0": "LABEL_0",
    "1": "LABEL_1"
  },
  "initializer_range": 0.02,
  "intermediate_size": 3072,
  "is_decoder": false,
  "label2id": {
    "LABEL_0": 0,
    "LABEL_1": 1
  },
  "layer_norm_eps": 1e-12,
  "length_penalty": 1.0,
  "max_length": 20,
  "max_position_embeddings": 512,
  "model_type": "bert",
  "num_attention_heads": 12,
  "num_beams": 1,
  "num_hidden_layers": 12,
  "num_labels": 4,
  "num_return_sequences": 1,
  "output_attentions": false,
  "output_hidden_states": false,
  "output_past": true,
  "pad_token_id": 0,
  "pruned_heads": {},
  "repetition_penalty": 1.0,
  "temperature": 1.0,
  "top_k": 50,
  "top_p": 1.0,
  "torchscript": false,
  "type_vocab_size": 2,
  "use_bfloat16": false,
  "vocab_size": 28996
}

2021-11-15 00:59:12,802 => loading weights file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-cased-pytorch_model.bin from cache at /home/yinan/.cache/torch/transformers/35d8b9d36faaf46728a0192d82bf7d00137490cd6074e8500778afed552a67e5.3fadbea36527ae472139fe84cddaa65454d7429f12d543d80bfc3ad70de55ac2
2021-11-15 00:59:16,544 => Weights of BertForSequenceClassification not initialized from pretrained model: ['classifier.weight', 'classifier.bias']
2021-11-15 00:59:16,545 => Weights from pretrained model not used in BertForSequenceClassification: ['cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias']
2021-11-15 01:02:08,035 => Train: 100.0	Epoch: 1	Iter: 79	Loss: 0.90029	Acc= 24.309	Precision= 24.174	Recall= 24.195	F1_score= 24.181
2021-11-15 01:04:59,765 => Train: 100.0	Epoch: 2	Iter: 79	Loss: 0.80876	Acc= 24.941	Precision= 24.911	Recall= 24.904	F1_score= 24.904
2021-11-15 01:07:51,051 => Train: 100.0	Epoch: 3	Iter: 79	Loss: 0.53790	Acc= 25.730	Precision= 25.598	Recall= 25.577	F1_score= 25.585
2021-11-15 01:10:42,278 => Train: 100.0	Epoch: 4	Iter: 79	Loss: 0.56591	Acc= 25.257	Precision= 25.150	Recall= 25.159	F1_score= 25.152
2021-11-15 01:13:34,386 => Train: 100.0	Epoch: 5	Iter: 79	Loss: 0.58237	Acc= 24.941	Precision= 24.898	Recall= 24.894	F1_score= 24.893
2021-11-15 01:16:25,764 => Train: 100.0	Epoch: 6	Iter: 79	Loss: 0.44414	Acc= 23.441	Precision= 23.445	Recall= 23.389	F1_score= 23.411
2021-11-15 01:19:17,161 => Train: 100.0	Epoch: 7	Iter: 79	Loss: 0.36793	Acc= 26.046	Precision= 26.006	Recall= 26.002	F1_score= 26.002
2021-11-15 01:22:08,583 => Train: 100.0	Epoch: 8	Iter: 79	Loss: 0.28687	Acc= 24.862	Precision= 24.802	Recall= 24.811	F1_score= 24.805
2021-11-15 01:25:07,736 => Train: 100.0	Epoch: 9	Iter: 79	Loss: 0.28898	Acc= 23.520	Precision= 23.497	Recall= 23.504	F1_score= 23.500
2021-11-15 01:27:59,761 => Train: 100.0	Epoch: 10	Iter: 79	Loss: 0.27395	Acc= 23.520	Precision= 23.437	Recall= 23.428	F1_score= 23.422
2021-11-15 01:30:51,646 => Train: 100.0	Epoch: 11	Iter: 79	Loss: 0.25385	Acc= 23.204	Precision= 23.128	Recall= 23.151	F1_score= 23.136
2021-11-15 01:33:43,655 => Train: 100.0	Epoch: 12	Iter: 79	Loss: 0.23642	Acc= 24.467	Precision= 24.388	Recall= 24.380	F1_score= 24.376
2021-11-15 01:36:34,957 => Train: 100.0	Epoch: 13	Iter: 79	Loss: 0.21195	Acc= 23.362	Precision= 23.369	Recall= 23.295	F1_score= 23.326
2021-11-15 01:39:26,023 => Train: 100.0	Epoch: 14	Iter: 79	Loss: 0.19629	Acc= 23.757	Precision= 23.526	Recall= 23.608	F1_score= 23.560
2021-11-15 01:42:16,994 => Train: 100.0	Epoch: 15	Iter: 79	Loss: 0.18032	Acc= 25.888	Precision= 25.824	Recall= 25.808	F1_score= 25.805
2021-11-15 01:45:08,070 => Train: 100.0	Epoch: 16	Iter: 79	Loss: 0.18148	Acc= 26.440	Precision= 26.298	Recall= 26.367	F1_score= 26.325
2021-11-15 01:48:07,519 => Train: 100.0	Epoch: 17	Iter: 79	Loss: 0.18581	Acc= 24.862	Precision= 24.724	Recall= 24.770	F1_score= 24.742
2021-11-15 01:51:35,298 => Train: 100.0	Epoch: 18	Iter: 79	Loss: 0.15314	Acc= 25.730	Precision= 25.560	Recall= 25.608	F1_score= 25.578
2021-11-15 01:54:27,161 => Train: 100.0	Epoch: 19	Iter: 79	Loss: 0.16367	Acc= 25.730	Precision= 25.670	Recall= 25.647	F1_score= 25.645
2021-11-15 01:57:18,468 => Train: 100.0	Epoch: 20	Iter: 79	Loss: 0.15132	Acc= 25.809	Precision= 25.698	Recall= 25.704	F1_score= 25.689
2021-11-15 01:57:24,498 => Eval: 100.0	Epoch: 20	Iter: 19	Loss: 0.09318	Acc= 32.492	Precision= 8.123	Recall= 25.000	F1_score= 12.262
2021-11-15 01:57:24,499 => -------------------------------------------------
2021-11-15 01:57:24,499 => 5 FOLD
2021-11-15 01:57:24,898 => loading configuration file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-cased-config.json from cache at /home/yinan/.cache/torch/transformers/b945b69218e98b3e2c95acf911789741307dec43c698d35fad11c1ae28bda352.9da767be51e1327499df13488672789394e2ca38b877837e52618a67d7002391
2021-11-15 01:57:24,898 => Model config BertConfig {
  "architectures": [
    "BertForMaskedLM"
  ],
  "attention_probs_dropout_prob": 0.1,
  "bos_token_id": null,
  "do_sample": false,
  "eos_token_ids": null,
  "finetuning_task": null,
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "hidden_size": 768,
  "id2label": {
    "0": "LABEL_0",
    "1": "LABEL_1"
  },
  "initializer_range": 0.02,
  "intermediate_size": 3072,
  "is_decoder": false,
  "label2id": {
    "LABEL_0": 0,
    "LABEL_1": 1
  },
  "layer_norm_eps": 1e-12,
  "length_penalty": 1.0,
  "max_length": 20,
  "max_position_embeddings": 512,
  "model_type": "bert",
  "num_attention_heads": 12,
  "num_beams": 1,
  "num_hidden_layers": 12,
  "num_labels": 4,
  "num_return_sequences": 1,
  "output_attentions": false,
  "output_hidden_states": false,
  "output_past": true,
  "pad_token_id": 0,
  "pruned_heads": {},
  "repetition_penalty": 1.0,
  "temperature": 1.0,
  "top_k": 50,
  "top_p": 1.0,
  "torchscript": false,
  "type_vocab_size": 2,
  "use_bfloat16": false,
  "vocab_size": 28996
}

2021-11-15 01:57:25,259 => loading weights file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-cased-pytorch_model.bin from cache at /home/yinan/.cache/torch/transformers/35d8b9d36faaf46728a0192d82bf7d00137490cd6074e8500778afed552a67e5.3fadbea36527ae472139fe84cddaa65454d7429f12d543d80bfc3ad70de55ac2
2021-11-15 01:57:29,013 => Weights of BertForSequenceClassification not initialized from pretrained model: ['classifier.weight', 'classifier.bias']
2021-11-15 01:57:29,013 => Weights from pretrained model not used in BertForSequenceClassification: ['cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias']
2021-11-15 02:00:21,648 => Train: 100.0	Epoch: 1	Iter: 79	Loss: 1.07439	Acc= 25.552	Precision= 25.567	Recall= 25.561	F1_score= 25.562
2021-11-15 02:03:13,719 => Train: 100.0	Epoch: 2	Iter: 79	Loss: 0.49605	Acc= 21.767	Precision= 21.773	Recall= 21.769	F1_score= 21.770
2021-11-15 02:06:06,282 => Train: 100.0	Epoch: 3	Iter: 79	Loss: 0.60366	Acc= 22.713	Precision= 22.713	Recall= 22.699	F1_score= 22.704
2021-11-15 02:08:58,893 => Train: 100.0	Epoch: 4	Iter: 79	Loss: 0.57624	Acc= 25.000	Precision= 25.019	Recall= 25.002	F1_score= 24.999
2021-11-15 02:11:51,456 => Train: 100.0	Epoch: 5	Iter: 79	Loss: 0.35607	Acc= 22.634	Precision= 22.550	Recall= 22.592	F1_score= 22.569
2021-11-15 02:14:43,365 => Train: 100.0	Epoch: 6	Iter: 79	Loss: 0.40155	Acc= 21.924	Precision= 21.899	Recall= 21.911	F1_score= 21.904
2021-11-15 02:17:35,033 => Train: 100.0	Epoch: 7	Iter: 79	Loss: 0.36605	Acc= 24.448	Precision= 24.378	Recall= 24.417	F1_score= 24.389
2021-11-15 02:20:34,611 => Train: 100.0	Epoch: 8	Iter: 79	Loss: 0.41873	Acc= 23.896	Precision= 23.825	Recall= 23.891	F1_score= 23.844
2021-11-15 02:23:33,140 => Train: 100.0	Epoch: 9	Iter: 79	Loss: 0.32006	Acc= 24.685	Precision= 24.714	Recall= 24.693	F1_score= 24.699
2021-11-15 02:26:25,273 => Train: 100.0	Epoch: 10	Iter: 79	Loss: 0.23361	Acc= 23.423	Precision= 23.431	Recall= 23.432	F1_score= 23.425
2021-11-15 02:29:16,655 => Train: 100.0	Epoch: 11	Iter: 79	Loss: 0.24142	Acc= 25.394	Precision= 25.409	Recall= 25.398	F1_score= 25.398
2021-11-15 02:32:08,312 => Train: 100.0	Epoch: 12	Iter: 79	Loss: 0.22078	Acc= 24.211	Precision= 24.180	Recall= 24.202	F1_score= 24.189
2021-11-15 02:35:13,169 => Train: 100.0	Epoch: 13	Iter: 79	Loss: 0.22097	Acc= 25.079	Precision= 25.063	Recall= 25.052	F1_score= 25.049
2021-11-15 02:38:04,440 => Train: 100.0	Epoch: 14	Iter: 79	Loss: 0.19670	Acc= 25.079	Precision= 25.070	Recall= 25.087	F1_score= 25.075
2021-11-15 02:40:55,114 => Train: 100.0	Epoch: 15	Iter: 79	Loss: 0.18622	Acc= 24.132	Precision= 24.162	Recall= 24.152	F1_score= 24.156
2021-11-15 02:43:45,475 => Train: 100.0	Epoch: 16	Iter: 79	Loss: 0.16378	Acc= 25.710	Precision= 25.685	Recall= 25.692	F1_score= 25.688
2021-11-15 02:46:41,904 => Train: 100.0	Epoch: 17	Iter: 79	Loss: 0.15486	Acc= 27.366	Precision= 27.332	Recall= 27.349	F1_score= 27.333
2021-11-15 02:50:37,140 => Train: 100.0	Epoch: 18	Iter: 79	Loss: 0.14732	Acc= 25.710	Precision= 25.704	Recall= 25.705	F1_score= 25.699
2021-11-15 02:53:30,222 => Train: 100.0	Epoch: 19	Iter: 79	Loss: 0.15089	Acc= 24.527	Precision= 24.455	Recall= 24.529	F1_score= 24.476
2021-11-15 02:56:20,709 => Train: 100.0	Epoch: 20	Iter: 79	Loss: 0.14165	Acc= 25.631	Precision= 25.634	Recall= 25.628	F1_score= 25.631
2021-11-15 02:56:26,746 => Eval: 100.0	Epoch: 20	Iter: 19	Loss: 0.16106	Acc= 24.684	Precision= 6.171	Recall= 25.000	F1_score= 9.898
2021-11-15 02:56:26,746 => AVERAGE ACCURACY: 26.451
