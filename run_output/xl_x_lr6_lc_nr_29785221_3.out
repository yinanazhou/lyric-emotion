Unloading StdEnv/2020

Due to MODULEPATH changes, the following have been reloaded:
  1) mii/1.1.1


The following have been reloaded with a version change:
  1) python/3.8.2 => python/3.7.4

Using base prefix '/cvmfs/soft.computecanada.ca/easybuild/software/2017/Core/python/3.7.4'
New python executable in /localscratch/yinan.29785221.0/env/bin/python
Installing setuptools, pip, wheel...
done.
Ignoring pip: markers 'python_version < "3"' don't match your environment
Looking in links: /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/nix/avx2, /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/nix/generic, /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic
Collecting pip
Installing collected packages: pip
  Found existing installation: pip 19.1.1
    Uninstalling pip-19.1.1:
      Successfully uninstalled pip-19.1.1
Successfully installed pip-21.2.3+computecanada
Looking in links: /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/nix/avx2, /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/nix/generic, /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/keras-2.8.0+computecanada-py2.py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/Keras_Preprocessing-1.1.2+computecanada-py3-none-any.whl
Requirement already satisfied: matplotlib in /cvmfs/soft.computecanada.ca/easybuild/software/2017/Core/scipy-stack/2019a/lib/python3.7/site-packages (from -r requirements.txt (line 3)) (3.0.2)
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/nltk-3.6.5+computecanada-py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/scikit_learn-0.22.1+computecanada-cp37-cp37m-linux_x86_64.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/tensorboard-2.3.0+computecanada-py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/tensorboard_plugin_wit-1.7.0+computecanada-py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/tensorflow_gpu-2.3.0+computecanada-cp37-cp37m-linux_x86_64.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/tensorflow_estimator-2.3.0+computecanada-py2.py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/tokenizers-0.5.2+computecanada-cp37-cp37m-linux_x86_64.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/nix/avx2/torch-1.4.0+computecanada-cp37-cp37m-linux_x86_64.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/torchtext-0.6.0+computecanada-py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/torchvision-0.8.2+computecanada-cp37-cp37m-linux_x86_64.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/transformers-2.5.1+computecanada-py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/urllib3-1.26.7+computecanada-py2.py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/tqdm-4.63.1+computecanada-py2.py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/joblib-1.1.0+computecanada-py2.py3-none-any.whl
ERROR: Could not find a version that satisfies the requirement regex>=2021.8.3 (from nltk) (from versions: 2018.1.10+computecanada, 2019.11.1+computecanada, 2020.11.13+computecanada)
ERROR: No matching distribution found for regex>=2021.8.3
Looking in links: /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/nix/avx2, /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/nix/generic, /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic
ERROR: Could not find a version that satisfies the requirement numpy==1.20.0+computacanada (from versions: 1.15.0+computecanada, 1.15.2+computecanada, 1.15.4+computecanada, 1.16.0+computecanada, 1.16.2+computecanada, 1.16.3+computecanada, 1.17.4+computecanada, 1.18.1+computecanada, 1.18.4+computecanada, 1.19.1+computecanada, 1.19.2+computecanada, 1.20.2+computecanada)
ERROR: No matching distribution found for numpy==1.20.0+computacanada
Looking in links: /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/nix/avx2, /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/nix/generic, /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/wandb-0.12.5+computecanada-py2.py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/protobuf-3.19.4+computecanada-py2.py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/six-1.16.0+computecanada-py2.py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/promise-2.3+computecanada-py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/pathtools-0.1.2+computecanada-py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/PyYAML-5.3.1+computecanada-cp37-cp37m-linux_x86_64.whl
Requirement already satisfied: python-dateutil>=2.6.1 in /cvmfs/soft.computecanada.ca/easybuild/software/2017/Core/scipy-stack/2019a/lib/python3.7/site-packages (from wandb) (2.7.5)
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/subprocess32-3.5.4+computecanada-py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/GitPython-3.1.24+computecanada-py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/docker_pycreds-0.4.0+computecanada-py2.py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/psutil-5.7.3+computecanada-cp37-cp37m-linux_x86_64.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/yaspin-2.1.0+computecanada-py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/sentry_sdk-1.5.0+computecanada-py2.py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/click-8.1.0+computecanada-py3-none-any.whl
Requirement already satisfied: requests<3,>=2.0.0 in /cvmfs/soft.computecanada.ca/easybuild/software/2017/Core/scipy-stack/2019a/lib/python3.7/site-packages (from wandb) (2.21.0)
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/shortuuid-1.0.1+computecanada-py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/configparser-5.0.2+computecanada-py3-none-any.whl
Requirement already satisfied: importlib-metadata in /cvmfs/soft.computecanada.ca/easybuild/software/2017/Core/scipy-stack/2019a/lib/python3.7/site-packages (from Click!=8.0.0,>=7.0->wandb) (0.8)
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/typing_extensions-4.1.1+computecanada-py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/gitdb-4.0.9+computecanada-py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/smmap-5.0.0+computecanada-py3-none-any.whl
Requirement already satisfied: certifi>=2017.4.17 in /cvmfs/soft.computecanada.ca/easybuild/software/2017/Core/scipy-stack/2019a/lib/python3.7/site-packages (from requests<3,>=2.0.0->wandb) (2018.11.29)
Requirement already satisfied: idna<2.9,>=2.5 in /cvmfs/soft.computecanada.ca/easybuild/software/2017/Core/scipy-stack/2019a/lib/python3.7/site-packages (from requests<3,>=2.0.0->wandb) (2.8)
Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /cvmfs/soft.computecanada.ca/easybuild/software/2017/Core/scipy-stack/2019a/lib/python3.7/site-packages (from requests<3,>=2.0.0->wandb) (3.0.4)
Requirement already satisfied: urllib3<1.25,>=1.21.1 in /cvmfs/soft.computecanada.ca/easybuild/software/2017/Core/scipy-stack/2019a/lib/python3.7/site-packages (from requests<3,>=2.0.0->wandb) (1.24.1)
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/termcolor-1.1.0+computecanada-py3-none-any.whl
Requirement already satisfied: zipp>=0.3.2 in /cvmfs/soft.computecanada.ca/easybuild/software/2017/Core/scipy-stack/2019a/lib/python3.7/site-packages (from importlib-metadata->Click!=8.0.0,>=7.0->wandb) (0.3.3)
Installing collected packages: smmap, typing-extensions, termcolor, six, gitdb, yaspin, subprocess32, shortuuid, sentry-sdk, PyYAML, psutil, protobuf, promise, pathtools, GitPython, docker-pycreds, configparser, Click, wandb
  Attempting uninstall: six
    Found existing installation: six 1.12.0
    Not uninstalling six at /cvmfs/soft.computecanada.ca/easybuild/software/2017/Core/scipy-stack/2019a/lib/python3.7/site-packages, outside environment /localscratch/yinan.29785221.0/env
    Can't uninstall 'six'. No files were found to uninstall.
Successfully installed Click-8.1.0+computecanada GitPython-3.1.24+computecanada PyYAML-5.3.1+computecanada configparser-5.0.2+computecanada docker-pycreds-0.4.0+computecanada gitdb-4.0.9+computecanada pathtools-0.1.2+computecanada promise-2.3+computecanada protobuf-3.19.4+computecanada psutil-5.7.3+computecanada sentry-sdk-1.5.0+computecanada shortuuid-1.0.1+computecanada six-1.16.0+computecanada smmap-5.0.0+computecanada subprocess32-3.5.4+computecanada termcolor-1.1.0+computecanada typing-extensions-4.1.1+computecanada wandb-0.12.5+computecanada yaspin-2.1.0+computecanada
Looking in links: /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/nix/avx2, /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/nix/generic, /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic
ERROR: Could not find a version that satisfies the requirement sagemaker (from versions: none)
ERROR: No matching distribution found for sagemaker
Looking in links: /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/nix/avx2, /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/nix/generic, /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/torch-1.9.1+computecanada-cp37-cp37m-linux_x86_64.whl
Requirement already satisfied: typing-extensions in /localscratch/yinan.29785221.0/env/lib/python3.7/site-packages (from torch) (4.1.1+computecanada)
Installing collected packages: torch
Successfully installed torch-1.9.1+computecanada
Looking in links: /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/nix/avx2, /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/nix/generic, /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/transformers-2.5.1+computecanada-py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/regex-2020.11.13+computecanada-cp37-cp37m-linux_x86_64.whl
Requirement already satisfied: numpy in /cvmfs/soft.computecanada.ca/easybuild/software/2017/Core/scipy-stack/2019a/lib/python3.7/site-packages (from transformers==2.5.1+computecanada) (1.16.0)
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/sentencepiece-0.1.91+computecanada-cp37-cp37m-linux_x86_64.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/boto3-1.21.14+computecanada-py3-none-any.whl
Requirement already satisfied: requests in /cvmfs/soft.computecanada.ca/easybuild/software/2017/Core/scipy-stack/2019a/lib/python3.7/site-packages (from transformers==2.5.1+computecanada) (2.21.0)
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/tqdm-4.63.1+computecanada-py2.py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/filelock-3.4.2+computecanada-py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/sacremoses-0.0.49+computecanada-py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/tokenizers-0.5.2+computecanada-cp37-cp37m-linux_x86_64.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/s3transfer-0.5.1+computecanada-py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/jmespath-0.10.0+computecanada-py2.py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/botocore-1.24.14+computecanada-py3-none-any.whl
Requirement already satisfied: python-dateutil<3.0.0,>=2.1 in /cvmfs/soft.computecanada.ca/easybuild/software/2017/Core/scipy-stack/2019a/lib/python3.7/site-packages (from botocore<1.25.0,>=1.24.14->boto3->transformers==2.5.1+computecanada) (2.7.5)
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/urllib3-1.26.9+computecanada-py2.py3-none-any.whl
Requirement already satisfied: six>=1.5 in /localscratch/yinan.29785221.0/env/lib/python3.7/site-packages (from python-dateutil<3.0.0,>=2.1->botocore<1.25.0,>=1.24.14->boto3->transformers==2.5.1+computecanada) (1.16.0+computecanada)
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/requests-2.27.1+computecanada-py2.py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/charset_normalizer-2.0.12+computecanada-py3-none-any.whl
Requirement already satisfied: idna<4,>=2.5 in /cvmfs/soft.computecanada.ca/easybuild/software/2017/Core/scipy-stack/2019a/lib/python3.7/site-packages (from requests->transformers==2.5.1+computecanada) (2.8)
Requirement already satisfied: certifi>=2017.4.17 in /cvmfs/soft.computecanada.ca/easybuild/software/2017/Core/scipy-stack/2019a/lib/python3.7/site-packages (from requests->transformers==2.5.1+computecanada) (2018.11.29)
Requirement already satisfied: click in /localscratch/yinan.29785221.0/env/lib/python3.7/site-packages (from sacremoses->transformers==2.5.1+computecanada) (8.1.0+computecanada)
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/joblib-1.1.0+computecanada-py2.py3-none-any.whl
Requirement already satisfied: importlib-metadata in /cvmfs/soft.computecanada.ca/easybuild/software/2017/Core/scipy-stack/2019a/lib/python3.7/site-packages (from click->sacremoses->transformers==2.5.1+computecanada) (0.8)
Requirement already satisfied: zipp>=0.3.2 in /cvmfs/soft.computecanada.ca/easybuild/software/2017/Core/scipy-stack/2019a/lib/python3.7/site-packages (from importlib-metadata->click->sacremoses->transformers==2.5.1+computecanada) (0.3.3)
Installing collected packages: urllib3, jmespath, botocore, tqdm, s3transfer, regex, joblib, charset-normalizer, tokenizers, sentencepiece, sacremoses, requests, filelock, boto3, transformers
  Attempting uninstall: urllib3
    Found existing installation: urllib3 1.24.1
    Not uninstalling urllib3 at /cvmfs/soft.computecanada.ca/easybuild/software/2017/Core/scipy-stack/2019a/lib/python3.7/site-packages, outside environment /localscratch/yinan.29785221.0/env
    Can't uninstall 'urllib3'. No files were found to uninstall.
  Attempting uninstall: requests
    Found existing installation: requests 2.21.0
    Not uninstalling requests at /cvmfs/soft.computecanada.ca/easybuild/software/2017/Core/scipy-stack/2019a/lib/python3.7/site-packages, outside environment /localscratch/yinan.29785221.0/env
    Can't uninstall 'requests'. No files were found to uninstall.
Successfully installed boto3-1.21.14+computecanada botocore-1.24.14+computecanada charset-normalizer-2.0.12+computecanada filelock-3.4.2+computecanada jmespath-0.10.0+computecanada joblib-1.1.0+computecanada regex-2020.11.13+computecanada requests-2.27.1+computecanada s3transfer-0.5.1+computecanada sacremoses-0.0.49+computecanada sentencepiece-0.1.91+computecanada tokenizers-0.5.2+computecanada tqdm-4.63.1+computecanada transformers-2.5.1+computecanada urllib3-1.26.9+computecanada
Looking in links: /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/nix/avx2, /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/nix/generic, /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/tensorflow_gpu-2.3.0+computecanada-cp37-cp37m-linux_x86_64.whl
Requirement already satisfied: wheel>=0.26 in /localscratch/yinan.29785221.0/env/lib/python3.7/site-packages (from tensorflow_gpu==2.3.0+computecanada) (0.33.4)
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/astunparse-1.6.3+computecanada-py2.py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/google_pasta-0.2.0+computecanada-py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/wrapt-1.11.2+computecanada-cp37-cp37m-linux_x86_64.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/tensorboard-2.8.0+computecanada-py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/nix/avx2/h5py-2.10.0+computecanada-cp37-cp37m-linux_x86_64.whl
Requirement already satisfied: protobuf>=3.9.2 in /localscratch/yinan.29785221.0/env/lib/python3.7/site-packages (from tensorflow_gpu==2.3.0+computecanada) (3.19.4+computecanada)
Requirement already satisfied: termcolor>=1.1.0 in /localscratch/yinan.29785221.0/env/lib/python3.7/site-packages (from tensorflow_gpu==2.3.0+computecanada) (1.1.0+computecanada)
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/absl_py-1.0.0+computecanada-py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/gast-0.3.3+computecanada-py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/nix/generic/scipy-1.4.1+computecanada-cp37-cp37m-linux_x86_64.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/Keras_Preprocessing-1.1.2+computecanada-py3-none-any.whl
Requirement already satisfied: six>=1.12.0 in /localscratch/yinan.29785221.0/env/lib/python3.7/site-packages (from tensorflow_gpu==2.3.0+computecanada) (1.16.0+computecanada)
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/grpcio-1.38.0+computecanada-cp37-cp37m-linux_x86_64.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/tensorflow_estimator-2.3.0+computecanada-py2.py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/opt_einsum-3.3.0+computecanada-py3-none-any.whl
Requirement already satisfied: numpy<1.19.0,>=1.16.0 in /cvmfs/soft.computecanada.ca/easybuild/software/2017/Core/scipy-stack/2019a/lib/python3.7/site-packages (from tensorflow_gpu==2.3.0+computecanada) (1.16.0)
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/Markdown-3.3.6+computecanada-py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/google_auth_oauthlib-0.4.6+computecanada-py2.py3-none-any.whl
Requirement already satisfied: requests<3,>=2.21.0 in /localscratch/yinan.29785221.0/env/lib/python3.7/site-packages (from tensorboard<3,>=2.3.0->tensorflow_gpu==2.3.0+computecanada) (2.27.1+computecanada)
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/tensorboard_data_server-0.6.1+computecanada-py3-none-linux_x86_64.whl
Requirement already satisfied: setuptools>=41.0.0 in /localscratch/yinan.29785221.0/env/lib/python3.7/site-packages (from tensorboard<3,>=2.3.0->tensorflow_gpu==2.3.0+computecanada) (41.0.1)
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/google_auth-2.3.3+computecanada-py2.py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/Werkzeug-2.0.3+computecanada-py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/tensorboard_plugin_wit-1.8.0+computecanada-py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/pyasn1_modules-0.2.8+computecanada-py2.py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/cachetools-4.2.4+computecanada-py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/rsa-4.8+computecanada-py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/requests_oauthlib-1.3.0+computecanada-py2.py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/importlib_metadata-4.10.1+computecanada-py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/zipp-3.7.0+computecanada-py3-none-any.whl
Requirement already satisfied: typing-extensions>=3.6.4 in /localscratch/yinan.29785221.0/env/lib/python3.7/site-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard<3,>=2.3.0->tensorflow_gpu==2.3.0+computecanada) (4.1.1+computecanada)
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/pyasn1-0.4.8+computecanada-py2.py3-none-any.whl
Requirement already satisfied: charset-normalizer~=2.0.0 in /localscratch/yinan.29785221.0/env/lib/python3.7/site-packages (from requests<3,>=2.21.0->tensorboard<3,>=2.3.0->tensorflow_gpu==2.3.0+computecanada) (2.0.12+computecanada)
Requirement already satisfied: certifi>=2017.4.17 in /cvmfs/soft.computecanada.ca/easybuild/software/2017/Core/scipy-stack/2019a/lib/python3.7/site-packages (from requests<3,>=2.21.0->tensorboard<3,>=2.3.0->tensorflow_gpu==2.3.0+computecanada) (2018.11.29)
Requirement already satisfied: idna<4,>=2.5 in /cvmfs/soft.computecanada.ca/easybuild/software/2017/Core/scipy-stack/2019a/lib/python3.7/site-packages (from requests<3,>=2.21.0->tensorboard<3,>=2.3.0->tensorflow_gpu==2.3.0+computecanada) (2.8)
Requirement already satisfied: urllib3<1.27,>=1.21.1 in /localscratch/yinan.29785221.0/env/lib/python3.7/site-packages (from requests<3,>=2.21.0->tensorboard<3,>=2.3.0->tensorflow_gpu==2.3.0+computecanada) (1.26.9+computecanada)
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/oauthlib-3.1.1+computecanada-py2.py3-none-any.whl
Installing collected packages: pyasn1, zipp, rsa, pyasn1-modules, oauthlib, cachetools, requests-oauthlib, importlib-metadata, google-auth, werkzeug, tensorboard-plugin-wit, tensorboard-data-server, markdown, grpcio, google-auth-oauthlib, absl-py, wrapt, tensorflow-estimator, tensorboard, scipy, opt-einsum, keras-preprocessing, h5py, google-pasta, gast, astunparse, tensorflow-gpu
  Attempting uninstall: pyasn1
    Found existing installation: pyasn1 0.4.3
    Not uninstalling pyasn1 at /cvmfs/soft.computecanada.ca/easybuild/software/2017/Core/scipy-stack/2019a/lib/python3.7/site-packages, outside environment /localscratch/yinan.29785221.0/env
    Can't uninstall 'pyasn1'. No files were found to uninstall.
  Attempting uninstall: zipp
    Found existing installation: zipp 0.3.3
    Not uninstalling zipp at /cvmfs/soft.computecanada.ca/easybuild/software/2017/Core/scipy-stack/2019a/lib/python3.7/site-packages, outside environment /localscratch/yinan.29785221.0/env
    Can't uninstall 'zipp'. No files were found to uninstall.
  Attempting uninstall: importlib-metadata
    Found existing installation: importlib-metadata 0.8
    Not uninstalling importlib-metadata at /cvmfs/soft.computecanada.ca/easybuild/software/2017/Core/scipy-stack/2019a/lib/python3.7/site-packages, outside environment /localscratch/yinan.29785221.0/env
    Can't uninstall 'importlib-metadata'. No files were found to uninstall.
  Attempting uninstall: scipy
    Found existing installation: scipy 1.2.0
    Not uninstalling scipy at /cvmfs/soft.computecanada.ca/easybuild/software/2017/Core/scipy-stack/2019a/lib/python3.7/site-packages, outside environment /localscratch/yinan.29785221.0/env
    Can't uninstall 'scipy'. No files were found to uninstall.
Successfully installed absl-py-1.0.0+computecanada astunparse-1.6.3+computecanada cachetools-4.2.4+computecanada gast-0.3.3+computecanada google-auth-2.3.3+computecanada google-auth-oauthlib-0.4.6+computecanada google-pasta-0.2.0+computecanada grpcio-1.38.0+computecanada h5py-2.10.0+computecanada importlib-metadata-4.10.1+computecanada keras-preprocessing-1.1.2+computecanada markdown-3.3.6+computecanada oauthlib-3.1.1+computecanada opt-einsum-3.3.0+computecanada pyasn1-0.4.8+computecanada pyasn1-modules-0.2.8+computecanada requests-oauthlib-1.3.0+computecanada rsa-4.8+computecanada scipy-1.4.1+computecanada tensorboard-2.8.0+computecanada tensorboard-data-server-0.6.1+computecanada tensorboard-plugin-wit-1.8.0+computecanada tensorflow-estimator-2.3.0+computecanada tensorflow-gpu-2.3.0+computecanada werkzeug-2.0.3+computecanada wrapt-1.11.2+computecanada zipp-3.7.0+computecanada
Looking in links: /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/nix/avx2, /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/nix/generic, /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/keras-2.8.0+computecanada-py2.py3-none-any.whl
Installing collected packages: Keras
Successfully installed Keras-2.8.0+computecanada
Looking in links: /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/nix/avx2, /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/nix/generic, /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/urllib3-1.26.7+computecanada-py2.py3-none-any.whl
Installing collected packages: urllib3
  Attempting uninstall: urllib3
    Found existing installation: urllib3 1.26.9+computecanada
    Uninstalling urllib3-1.26.9+computecanada:
      Successfully uninstalled urllib3-1.26.9+computecanada
Successfully installed urllib3-1.26.7+computecanada
Looking in links: /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/nix/avx2, /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/nix/generic, /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/nltk-3.7+computecanada-py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/nltk-3.6.5+computecanada-py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/nltk-3.6.3+computecanada-py3-none-any.whl
Requirement already satisfied: regex in /localscratch/yinan.29785221.0/env/lib/python3.7/site-packages (from nltk) (2020.11.13+computecanada)
Requirement already satisfied: tqdm in /localscratch/yinan.29785221.0/env/lib/python3.7/site-packages (from nltk) (4.63.1+computecanada)
Requirement already satisfied: click in /localscratch/yinan.29785221.0/env/lib/python3.7/site-packages (from nltk) (8.1.0+computecanada)
Requirement already satisfied: joblib in /localscratch/yinan.29785221.0/env/lib/python3.7/site-packages (from nltk) (1.1.0+computecanada)
Requirement already satisfied: importlib-metadata in /localscratch/yinan.29785221.0/env/lib/python3.7/site-packages (from click->nltk) (4.10.1+computecanada)
Requirement already satisfied: typing-extensions>=3.6.4 in /localscratch/yinan.29785221.0/env/lib/python3.7/site-packages (from importlib-metadata->click->nltk) (4.1.1+computecanada)
Requirement already satisfied: zipp>=0.5 in /localscratch/yinan.29785221.0/env/lib/python3.7/site-packages (from importlib-metadata->click->nltk) (3.7.0+computecanada)
Installing collected packages: nltk
Successfully installed nltk-3.6.3+computecanada
Looking in links: /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/nix/avx2, /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/nix/generic, /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/scikit_learn-0.22.1+computecanada-cp37-cp37m-linux_x86_64.whl
Requirement already satisfied: numpy>=1.11.0 in /cvmfs/soft.computecanada.ca/easybuild/software/2017/Core/scipy-stack/2019a/lib/python3.7/site-packages (from scikit-learn==0.22.1) (1.16.0)
Requirement already satisfied: scipy>=0.17.0 in /localscratch/yinan.29785221.0/env/lib/python3.7/site-packages (from scikit-learn==0.22.1) (1.4.1+computecanada)
Requirement already satisfied: joblib>=0.11 in /localscratch/yinan.29785221.0/env/lib/python3.7/site-packages (from scikit-learn==0.22.1) (1.1.0+computecanada)
Installing collected packages: scikit-learn
Successfully installed scikit-learn-0.22.1+computecanada
Looking in links: /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/nix/avx2, /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/nix/generic, /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic
Requirement already satisfied: tokenizers==0.5.2 in /localscratch/yinan.29785221.0/env/lib/python3.7/site-packages (0.5.2+computecanada)
wandb: Appending key for api.wandb.ai to your netrc file: /home/yinan/.netrc
Starting Task
2022-03-29 20:33:20.091085: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1
[nltk_data] Downloading package stopwords to /home/yinan/nltk_data...
[nltk_data]   Package stopwords is already up-to-date!
[nltk_data] Downloading package wordnet to /home/yinan/nltk_data...
[nltk_data]   Package wordnet is already up-to-date!
wandb: Currently logged in as: yinanazhou (use `wandb login --relogin` to force relogin)
wandb: wandb version 0.12.11 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
2022-03-29 20:33:31.636918: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1
wandb: Tracking run with wandb version 0.12.5
wandb: Syncing run comic-wind-2
wandb: ⭐️ View project at https://wandb.ai/yinanazhou/xl_512_bs_8_lr_1e06_es_3_lc_True_nr_True_sr_False_stem_False_lemma_False_repeat_1_fold_1
wandb: 🚀 View run at https://wandb.ai/yinanazhou/xl_512_bs_8_lr_1e06_es_3_lc_True_nr_True_sr_False_stem_False_lemma_False_repeat_1_fold_1/runs/jqco90hq
wandb: Run data is saved locally in /project/6002780/yinan/Thesis_MER_Lyrics/lyric-emotion/wandb/run-20220329_203329-jqco90hq
wandb: Run `wandb offline` to turn off syncing.

Validation loss decreased (inf --> 1.439705).  Saving model ...
Validation loss decreased (1.439705 --> 1.419512).  Saving model ...
Validation loss decreased (1.419512 --> 1.402896).  Saving model ...
Validation loss decreased (1.402896 --> 1.389535).  Saving model ...
Validation loss decreased (1.389535 --> 1.379558).  Saving model ...
Validation loss decreased (1.379558 --> 1.370725).  Saving model ...
Validation loss decreased (1.370725 --> 1.364060).  Saving model ...
Validation loss decreased (1.364060 --> 1.358288).  Saving model ...
Validation loss decreased (1.358288 --> 1.352618).  Saving model ...
Validation loss decreased (1.352618 --> 1.347247).  Saving model ...
Validation loss decreased (1.347247 --> 1.341469).  Saving model ...
Validation loss decreased (1.341469 --> 1.336687).  Saving model ...
Validation loss decreased (1.336687 --> 1.331722).  Saving model ...
Validation loss decreased (1.331722 --> 1.326793).  Saving model ...
Validation loss decreased (1.326793 --> 1.321442).  Saving model ...
Validation loss decreased (1.321442 --> 1.317452).  Saving model ...
Validation loss decreased (1.317452 --> 1.311851).  Saving model ...
Validation loss decreased (1.311851 --> 1.305910).  Saving model ...
Validation loss decreased (1.305910 --> 1.300498).  Saving model ...
Validation loss decreased (1.300498 --> 1.294612).  Saving model ...
Validation loss decreased (1.294612 --> 1.289088).  Saving model ...
Validation loss decreased (1.289088 --> 1.282033).  Saving model ...
Validation loss decreased (1.282033 --> 1.278490).  Saving model ...
Validation loss decreased (1.278490 --> 1.271101).  Saving model ...
Validation loss decreased (1.271101 --> 1.265703).  Saving model ...
Validation loss decreased (1.265703 --> 1.261029).  Saving model ...
Validation loss decreased (1.261029 --> 1.254424).  Saving model ...
Validation loss decreased (1.254424 --> 1.250263).  Saving model ...
Validation loss decreased (1.250263 --> 1.247004).  Saving model ...
Validation loss decreased (1.247004 --> 1.245395).  Saving model ...
Validation loss decreased (1.245395 --> 1.242729).  Saving model ...
Validation loss decreased (1.242729 --> 1.237397).  Saving model ...
Validation loss decreased (1.237397 --> 1.235904).  Saving model ...
Validation loss decreased (1.235904 --> 1.230276).  Saving model ...
Validation loss decreased (1.230276 --> 1.227219).  Saving model ...
Validation loss decreased (1.227219 --> 1.220999).  Saving model ...
Validation loss decreased (1.220999 --> 1.215459).  Saving model ...
Validation loss decreased (1.215459 --> 1.214406).  Saving model ...
Validation loss decreased (1.214406 --> 1.209761).  Saving model ...
Validation loss decreased (1.209761 --> 1.208001).  Saving model ...
Validation loss decreased (1.208001 --> 1.201319).  Saving model ...
Validation loss decreased (1.201319 --> 1.197031).  Saving model ...
Validation loss decreased (1.197031 --> 1.194019).  Saving model ...
Validation loss decreased (1.194019 --> 1.193997).  Saving model ...
Validation loss decreased (1.193997 --> 1.189291).  Saving model ...
Validation loss decreased (1.189291 --> 1.186797).  Saving model ...
Validation loss decreased (1.186797 --> 1.185167).  Saving model ...
EarlyStopping counter: 1 out of 3.0
Validation loss decreased (1.185167 --> 1.179282).  Saving model ...
Validation loss decreased (1.179282 --> 1.179126).  Saving model ...
Validation loss decreased (1.179126 --> 1.172249).  Saving model ...
Validation loss decreased (1.172249 --> 1.169561).  Saving model ...
Validation loss decreased (1.169561 --> 1.168631).  Saving model ...
Validation loss decreased (1.168631 --> 1.165754).  Saving model ...
Validation loss decreased (1.165754 --> 1.165563).  Saving model ...
Validation loss decreased (1.165563 --> 1.159924).  Saving model ...
Validation loss decreased (1.159924 --> 1.154075).  Saving model ...
Validation loss decreased (1.154075 --> 1.149934).  Saving model ...
Validation loss decreased (1.149934 --> 1.144026).  Saving model ...
EarlyStopping counter: 1 out of 3.0
Validation loss decreased (1.144026 --> 1.141895).  Saving model ...
Validation loss decreased (1.141895 --> 1.139391).  Saving model ...
Validation loss decreased (1.139391 --> 1.134637).  Saving model ...
EarlyStopping counter: 1 out of 3.0
EarlyStopping counter: 2 out of 3.0
Validation loss decreased (1.134637 --> 1.130837).  Saving model ...
Validation loss decreased (1.130837 --> 1.128263).  Saving model ...
Validation loss decreased (1.128263 --> 1.122229).  Saving model ...
Validation loss decreased (1.122229 --> 1.121355).  Saving model ...
Validation loss decreased (1.121355 --> 1.119745).  Saving model ...
Validation loss decreased (1.119745 --> 1.113369).  Saving model ...
Validation loss decreased (1.113369 --> 1.111985).  Saving model ...
Validation loss decreased (1.111985 --> 1.111388).  Saving model ...
Validation loss decreased (1.111388 --> 1.108078).  Saving model ...
Validation loss decreased (1.108078 --> 1.104047).  Saving model ...
Validation loss decreased (1.104047 --> 1.103267).  Saving model ...
Validation loss decreased (1.103267 --> 1.102833).  Saving model ...
Validation loss decreased (1.102833 --> 1.098015).  Saving model ...
Validation loss decreased (1.098015 --> 1.092954).  Saving model ...
Validation loss decreased (1.092954 --> 1.091071).  Saving model ...
EarlyStopping counter: 1 out of 3.0
EarlyStopping counter: 2 out of 3.0
EarlyStopping counter: 3 out of 3.0
/localscratch/yinan.29785221.0/env/lib/python3.7/site-packages/torch/nn/functional.py:1794: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.
  warnings.warn("nn.functional.tanh is deprecated. Use torch.tanh instead.")
/localscratch/yinan.29785221.0/env/lib/python3.7/site-packages/transformers/optimization.py:155: UserWarning: This overload of add_ is deprecated:
	add_(Number alpha, Tensor other)
Consider using one of the following signatures instead:
	add_(Tensor other, *, Number alpha) (Triggered internally at  ../torch/csrc/utils/python_arg_parser.cpp:1025.)
  exp_avg.mul_(beta1).add_(1.0 - beta1, grad)
wandb: Waiting for W&B process to finish, PID 171564... (success).
wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: \ 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: | 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: / 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: \ 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: | 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: / 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: \ 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: | 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: / 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb:                                                                                
wandb: Run history:
wandb:     e_F1 ▁▂▂▃▄▅▅▅▅▅▆▆▆▆▆▆▆▆▇▇▇▇▇▇▇▇▇▇▇▇██████████
wandb:   e_loss █▇▇▆▆▆▆▆▅▅▅▅▄▄▄▄▄▄▃▃▃▃▃▃▃▃▂▂▂▂▂▂▂▂▁▁▁▁▁▁
wandb:     t_F1 ▁▁▂▃▃▃▃▃▄▄▅▅▅▅▅▆▆▆▇▆▆▇▇▆▆▇▇▇█▇█▇▇▆██▇███
wandb:   t_loss █▇▇▇▇▇▇▆▆▆▆▅▅▅▅▄▄▄▄▄▄▃▃▃▃▃▃▃▂▂▂▂▂▂▂▁▂▁▁▁
wandb: 
wandb: Run summary:
wandb:     e_F1 51.22682
wandb:   e_loss 1.09181
wandb:     t_F1 59.56282
wandb:   t_loss 0.94193
wandb: 
wandb: Synced 4 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Synced comic-wind-2: https://wandb.ai/yinanazhou/xl_512_bs_8_lr_1e06_es_3_lc_True_nr_True_sr_False_stem_False_lemma_False_repeat_1_fold_1/runs/jqco90hq
wandb: Find logs at: ./wandb/run-20220329_203329-jqco90hq/logs/debug.log
wandb: 

wandb: wandb version 0.12.11 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
2022-03-29 21:26:34.175358: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1
wandb: Tracking run with wandb version 0.12.5
wandb: Syncing run tough-yogurt-2
wandb: ⭐️ View project at https://wandb.ai/yinanazhou/xl_512_bs_8_lr_1e06_es_3_lc_True_nr_True_sr_False_stem_False_lemma_False_repeat_1_fold_2
wandb: 🚀 View run at https://wandb.ai/yinanazhou/xl_512_bs_8_lr_1e06_es_3_lc_True_nr_True_sr_False_stem_False_lemma_False_repeat_1_fold_2/runs/2nl4zorl
wandb: Run data is saved locally in /project/6002780/yinan/Thesis_MER_Lyrics/lyric-emotion/wandb/run-20220329_212632-2nl4zorl
wandb: Run `wandb offline` to turn off syncing.

Validation loss decreased (inf --> 1.477667).  Saving model ...
Validation loss decreased (1.477667 --> 1.445929).  Saving model ...
Validation loss decreased (1.445929 --> 1.421504).  Saving model ...
Validation loss decreased (1.421504 --> 1.404218).  Saving model ...
Validation loss decreased (1.404218 --> 1.391549).  Saving model ...
Validation loss decreased (1.391549 --> 1.382126).  Saving model ...
Validation loss decreased (1.382126 --> 1.374560).  Saving model ...
Validation loss decreased (1.374560 --> 1.367926).  Saving model ...
Validation loss decreased (1.367926 --> 1.361629).  Saving model ...
Validation loss decreased (1.361629 --> 1.356079).  Saving model ...
Validation loss decreased (1.356079 --> 1.351647).  Saving model ...
Validation loss decreased (1.351647 --> 1.346654).  Saving model ...
Validation loss decreased (1.346654 --> 1.341916).  Saving model ...
Validation loss decreased (1.341916 --> 1.337450).  Saving model ...
Validation loss decreased (1.337450 --> 1.333015).  Saving model ...
Validation loss decreased (1.333015 --> 1.327632).  Saving model ...
Validation loss decreased (1.327632 --> 1.322474).  Saving model ...
Validation loss decreased (1.322474 --> 1.317137).  Saving model ...
Validation loss decreased (1.317137 --> 1.312018).  Saving model ...
Validation loss decreased (1.312018 --> 1.306949).  Saving model ...
Validation loss decreased (1.306949 --> 1.302196).  Saving model ...
Validation loss decreased (1.302196 --> 1.296014).  Saving model ...
Validation loss decreased (1.296014 --> 1.290682).  Saving model ...
Validation loss decreased (1.290682 --> 1.284690).  Saving model ...
Validation loss decreased (1.284690 --> 1.278988).  Saving model ...
Validation loss decreased (1.278988 --> 1.273834).  Saving model ...
Validation loss decreased (1.273834 --> 1.267921).  Saving model ...
Validation loss decreased (1.267921 --> 1.261086).  Saving model ...
Validation loss decreased (1.261086 --> 1.255302).  Saving model ...
Validation loss decreased (1.255302 --> 1.248199).  Saving model ...
Validation loss decreased (1.248199 --> 1.241962).  Saving model ...
Validation loss decreased (1.241962 --> 1.235455).  Saving model ...
Validation loss decreased (1.235455 --> 1.229177).  Saving model ...
Validation loss decreased (1.229177 --> 1.223348).  Saving model ...
Validation loss decreased (1.223348 --> 1.218764).  Saving model ...
Validation loss decreased (1.218764 --> 1.213381).  Saving model ...
Validation loss decreased (1.213381 --> 1.206875).  Saving model ...
Validation loss decreased (1.206875 --> 1.199870).  Saving model ...
Validation loss decreased (1.199870 --> 1.194069).  Saving model ...
Validation loss decreased (1.194069 --> 1.187895).  Saving model ...
Validation loss decreased (1.187895 --> 1.182092).  Saving model ...
Validation loss decreased (1.182092 --> 1.175888).  Saving model ...
Validation loss decreased (1.175888 --> 1.170657).  Saving model ...
Validation loss decreased (1.170657 --> 1.164384).  Saving model ...
Validation loss decreased (1.164384 --> 1.158671).  Saving model ...
Validation loss decreased (1.158671 --> 1.153280).  Saving model ...
Validation loss decreased (1.153280 --> 1.147685).  Saving model ...
Validation loss decreased (1.147685 --> 1.142602).  Saving model ...
Validation loss decreased (1.142602 --> 1.136436).  Saving model ...
Validation loss decreased (1.136436 --> 1.129186).  Saving model ...
Validation loss decreased (1.129186 --> 1.123270).  Saving model ...
Validation loss decreased (1.123270 --> 1.117088).  Saving model ...
Validation loss decreased (1.117088 --> 1.111228).  Saving model ...
Validation loss decreased (1.111228 --> 1.106188).  Saving model ...
Validation loss decreased (1.106188 --> 1.099563).  Saving model ...
Validation loss decreased (1.099563 --> 1.093709).  Saving model ...
Validation loss decreased (1.093709 --> 1.089040).  Saving model ...
Validation loss decreased (1.089040 --> 1.083735).  Saving model ...
Validation loss decreased (1.083735 --> 1.077982).  Saving model ...
Validation loss decreased (1.077982 --> 1.071669).  Saving model ...
Validation loss decreased (1.071669 --> 1.067300).  Saving model ...
Validation loss decreased (1.067300 --> 1.062902).  Saving model ...
Validation loss decreased (1.062902 --> 1.058217).  Saving model ...
Validation loss decreased (1.058217 --> 1.055085).  Saving model ...
Validation loss decreased (1.055085 --> 1.049560).  Saving model ...
Validation loss decreased (1.049560 --> 1.045541).  Saving model ...
Validation loss decreased (1.045541 --> 1.041046).  Saving model ...
Validation loss decreased (1.041046 --> 1.038123).  Saving model ...
Validation loss decreased (1.038123 --> 1.033052).  Saving model ...
Validation loss decreased (1.033052 --> 1.027835).  Saving model ...
Validation loss decreased (1.027835 --> 1.024301).  Saving model ...
Validation loss decreased (1.024301 --> 1.021649).  Saving model ...
Validation loss decreased (1.021649 --> 1.015120).  Saving model ...
Validation loss decreased (1.015120 --> 1.011486).  Saving model ...
Validation loss decreased (1.011486 --> 1.007626).  Saving model ...
Validation loss decreased (1.007626 --> 1.003360).  Saving model ...
Validation loss decreased (1.003360 --> 0.999892).  Saving model ...
Validation loss decreased (0.999892 --> 0.996969).  Saving model ...
Validation loss decreased (0.996969 --> 0.994088).  Saving model ...
Validation loss decreased (0.994088 --> 0.989969).  Saving model ...
Validation loss decreased (0.989969 --> 0.985606).  Saving model ...
Validation loss decreased (0.985606 --> 0.982827).  Saving model ...
Validation loss decreased (0.982827 --> 0.980378).  Saving model ...
Validation loss decreased (0.980378 --> 0.977495).  Saving model ...
Validation loss decreased (0.977495 --> 0.975704).  Saving model ...
Validation loss decreased (0.975704 --> 0.973024).  Saving model ...
Validation loss decreased (0.973024 --> 0.970177).  Saving model ...
Validation loss decreased (0.970177 --> 0.967508).  Saving model ...
Validation loss decreased (0.967508 --> 0.963780).  Saving model ...
Validation loss decreased (0.963780 --> 0.961327).  Saving model ...
Validation loss decreased (0.961327 --> 0.959388).  Saving model ...
Validation loss decreased (0.959388 --> 0.956617).  Saving model ...
Validation loss decreased (0.956617 --> 0.954516).  Saving model ...
Validation loss decreased (0.954516 --> 0.953059).  Saving model ...
Validation loss decreased (0.953059 --> 0.949526).  Saving model ...
Validation loss decreased (0.949526 --> 0.947823).  Saving model ...
Validation loss decreased (0.947823 --> 0.945226).  Saving model ...
Validation loss decreased (0.945226 --> 0.944444).  Saving model ...
Validation loss decreased (0.944444 --> 0.941997).  Saving model ...
Validation loss decreased (0.941997 --> 0.940554).  Saving model ...
Validation loss decreased (0.940554 --> 0.939307).  Saving model ...
Validation loss decreased (0.939307 --> 0.936983).  Saving model ...
Validation loss decreased (0.936983 --> 0.934265).  Saving model ...
Validation loss decreased (0.934265 --> 0.932718).  Saving model ...
Validation loss decreased (0.932718 --> 0.931047).  Saving model ...
Validation loss decreased (0.931047 --> 0.930091).  Saving model ...
Validation loss decreased (0.930091 --> 0.928848).  Saving model ...
Validation loss decreased (0.928848 --> 0.928698).  Saving model ...
Validation loss decreased (0.928698 --> 0.926563).  Saving model ...
Validation loss decreased (0.926563 --> 0.925600).  Saving model ...
Validation loss decreased (0.925600 --> 0.923824).  Saving model ...
Validation loss decreased (0.923824 --> 0.921987).  Saving model ...
Validation loss decreased (0.921987 --> 0.921562).  Saving model ...
Validation loss decreased (0.921562 --> 0.921076).  Saving model ...
Validation loss decreased (0.921076 --> 0.919952).  Saving model ...
Validation loss decreased (0.919952 --> 0.918801).  Saving model ...
Validation loss decreased (0.918801 --> 0.918074).  Saving model ...
Validation loss decreased (0.918074 --> 0.917036).  Saving model ...
EarlyStopping counter: 1 out of 3.0
Validation loss decreased (0.917036 --> 0.916633).  Saving model ...
Validation loss decreased (0.916633 --> 0.915749).  Saving model ...
Validation loss decreased (0.915749 --> 0.915614).  Saving model ...
EarlyStopping counter: 1 out of 3.0
EarlyStopping counter: 2 out of 3.0
Validation loss decreased (0.915614 --> 0.914463).  Saving model ...
Validation loss decreased (0.914463 --> 0.913893).  Saving model ...
Validation loss decreased (0.913893 --> 0.913038).  Saving model ...
EarlyStopping counter: 1 out of 3.0
Validation loss decreased (0.913038 --> 0.912148).  Saving model ...
Validation loss decreased (0.912148 --> 0.911841).  Saving model ...
EarlyStopping counter: 1 out of 3.0
EarlyStopping counter: 2 out of 3.0
EarlyStopping counter: 3 out of 3.0
/localscratch/yinan.29785221.0/env/lib/python3.7/site-packages/torch/nn/functional.py:1794: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.
  warnings.warn("nn.functional.tanh is deprecated. Use torch.tanh instead.")
wandb: Waiting for W&B process to finish, PID 174519... (success).
wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: \ 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: | 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: / 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: \ 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: | 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: / 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: \ 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: | 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: / 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb:                                                                                
wandb: Run history:
wandb:     e_F1 ▁▁▃▄▄▅▅▅▆▆▆▆▆▆▇▇▇▇▇▇▇▇▇██▇██████████████
wandb:   e_loss █▇▇▇▇▆▆▆▆▅▅▅▄▄▄▄▄▃▃▃▃▂▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁
wandb:     t_F1 ▁▁▂▃▃▄▄▄▄▄▅▅▅▅▅▆▆▆▆▆▆▆▇▇▇▇▇▇▇▇█▇████████
wandb:   t_loss █▇▇▇▇▇▆▆▆▆▆▆▅▅▅▅▄▄▄▄▄▄▃▃▃▃▃▃▂▂▂▂▂▂▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:     e_F1 62.52137
wandb:   e_loss 0.91236
wandb:     t_F1 70.4287
wandb:   t_loss 0.7864
wandb: 
wandb: Synced 4 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Synced tough-yogurt-2: https://wandb.ai/yinanazhou/xl_512_bs_8_lr_1e06_es_3_lc_True_nr_True_sr_False_stem_False_lemma_False_repeat_1_fold_2/runs/2nl4zorl
wandb: Find logs at: ./wandb/run-20220329_212632-2nl4zorl/logs/debug.log
wandb: 

wandb: wandb version 0.12.11 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
2022-03-29 22:54:38.122759: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1
wandb: Tracking run with wandb version 0.12.5
wandb: Syncing run driven-planet-2
wandb: ⭐️ View project at https://wandb.ai/yinanazhou/xl_512_bs_8_lr_1e06_es_3_lc_True_nr_True_sr_False_stem_False_lemma_False_repeat_2_fold_1
wandb: 🚀 View run at https://wandb.ai/yinanazhou/xl_512_bs_8_lr_1e06_es_3_lc_True_nr_True_sr_False_stem_False_lemma_False_repeat_2_fold_1/runs/3vcfeltk
wandb: Run data is saved locally in /project/6002780/yinan/Thesis_MER_Lyrics/lyric-emotion/wandb/run-20220329_225434-3vcfeltk
wandb: Run `wandb offline` to turn off syncing.

Validation loss decreased (inf --> 1.433904).  Saving model ...
Validation loss decreased (1.433904 --> 1.415857).  Saving model ...
Validation loss decreased (1.415857 --> 1.402079).  Saving model ...
Validation loss decreased (1.402079 --> 1.391341).  Saving model ...
Validation loss decreased (1.391341 --> 1.382947).  Saving model ...
Validation loss decreased (1.382947 --> 1.376206).  Saving model ...
Validation loss decreased (1.376206 --> 1.370186).  Saving model ...
Validation loss decreased (1.370186 --> 1.364902).  Saving model ...
Validation loss decreased (1.364902 --> 1.360124).  Saving model ...
Validation loss decreased (1.360124 --> 1.355925).  Saving model ...
Validation loss decreased (1.355925 --> 1.350427).  Saving model ...
Validation loss decreased (1.350427 --> 1.345271).  Saving model ...
Validation loss decreased (1.345271 --> 1.340158).  Saving model ...
Validation loss decreased (1.340158 --> 1.335607).  Saving model ...
Validation loss decreased (1.335607 --> 1.330236).  Saving model ...
Validation loss decreased (1.330236 --> 1.324329).  Saving model ...
Validation loss decreased (1.324329 --> 1.318521).  Saving model ...
Validation loss decreased (1.318521 --> 1.312954).  Saving model ...
Validation loss decreased (1.312954 --> 1.307316).  Saving model ...
Validation loss decreased (1.307316 --> 1.301538).  Saving model ...
Validation loss decreased (1.301538 --> 1.295431).  Saving model ...
Validation loss decreased (1.295431 --> 1.287743).  Saving model ...
Validation loss decreased (1.287743 --> 1.280589).  Saving model ...
Validation loss decreased (1.280589 --> 1.274327).  Saving model ...
Validation loss decreased (1.274327 --> 1.266994).  Saving model ...
Validation loss decreased (1.266994 --> 1.259826).  Saving model ...
Validation loss decreased (1.259826 --> 1.252556).  Saving model ...
Validation loss decreased (1.252556 --> 1.246586).  Saving model ...
Validation loss decreased (1.246586 --> 1.239083).  Saving model ...
Validation loss decreased (1.239083 --> 1.233320).  Saving model ...
Validation loss decreased (1.233320 --> 1.225868).  Saving model ...
Validation loss decreased (1.225868 --> 1.219953).  Saving model ...
Validation loss decreased (1.219953 --> 1.211256).  Saving model ...
Validation loss decreased (1.211256 --> 1.204377).  Saving model ...
Validation loss decreased (1.204377 --> 1.199327).  Saving model ...
Validation loss decreased (1.199327 --> 1.192388).  Saving model ...
Validation loss decreased (1.192388 --> 1.186551).  Saving model ...
Validation loss decreased (1.186551 --> 1.181481).  Saving model ...
Validation loss decreased (1.181481 --> 1.174480).  Saving model ...
Validation loss decreased (1.174480 --> 1.171481).  Saving model ...
Validation loss decreased (1.171481 --> 1.166286).  Saving model ...
Validation loss decreased (1.166286 --> 1.162800).  Saving model ...
Validation loss decreased (1.162800 --> 1.156746).  Saving model ...
Validation loss decreased (1.156746 --> 1.152897).  Saving model ...
Validation loss decreased (1.152897 --> 1.148821).  Saving model ...
Validation loss decreased (1.148821 --> 1.143532).  Saving model ...
Validation loss decreased (1.143532 --> 1.138693).  Saving model ...
Validation loss decreased (1.138693 --> 1.135361).  Saving model ...
Validation loss decreased (1.135361 --> 1.130393).  Saving model ...
Validation loss decreased (1.130393 --> 1.127916).  Saving model ...
Validation loss decreased (1.127916 --> 1.124538).  Saving model ...
Validation loss decreased (1.124538 --> 1.119145).  Saving model ...
Validation loss decreased (1.119145 --> 1.113458).  Saving model ...
Validation loss decreased (1.113458 --> 1.111172).  Saving model ...
Validation loss decreased (1.111172 --> 1.109062).  Saving model ...
Validation loss decreased (1.109062 --> 1.103841).  Saving model ...
Validation loss decreased (1.103841 --> 1.099539).  Saving model ...
Validation loss decreased (1.099539 --> 1.094830).  Saving model ...
Validation loss decreased (1.094830 --> 1.091422).  Saving model ...
Validation loss decreased (1.091422 --> 1.087422).  Saving model ...
Validation loss decreased (1.087422 --> 1.081552).  Saving model ...
Validation loss decreased (1.081552 --> 1.079945).  Saving model ...
Validation loss decreased (1.079945 --> 1.075609).  Saving model ...
Validation loss decreased (1.075609 --> 1.071624).  Saving model ...
Validation loss decreased (1.071624 --> 1.069716).  Saving model ...
Validation loss decreased (1.069716 --> 1.065662).  Saving model ...
Validation loss decreased (1.065662 --> 1.063859).  Saving model ...
Validation loss decreased (1.063859 --> 1.060075).  Saving model ...
Validation loss decreased (1.060075 --> 1.058129).  Saving model ...
Validation loss decreased (1.058129 --> 1.056398).  Saving model ...
Validation loss decreased (1.056398 --> 1.052747).  Saving model ...
Validation loss decreased (1.052747 --> 1.047733).  Saving model ...
Validation loss decreased (1.047733 --> 1.044217).  Saving model ...
Validation loss decreased (1.044217 --> 1.041359).  Saving model ...
Validation loss decreased (1.041359 --> 1.039300).  Saving model ...
Validation loss decreased (1.039300 --> 1.036513).  Saving model ...
Validation loss decreased (1.036513 --> 1.033363).  Saving model ...
EarlyStopping counter: 1 out of 3.0
Validation loss decreased (1.033363 --> 1.031000).  Saving model ...
Validation loss decreased (1.031000 --> 1.029575).  Saving model ...
Validation loss decreased (1.029575 --> 1.026586).  Saving model ...
Validation loss decreased (1.026586 --> 1.024050).  Saving model ...
Validation loss decreased (1.024050 --> 1.022904).  Saving model ...
Validation loss decreased (1.022904 --> 1.020832).  Saving model ...
Validation loss decreased (1.020832 --> 1.017399).  Saving model ...
EarlyStopping counter: 1 out of 3.0
Validation loss decreased (1.017399 --> 1.015662).  Saving model ...
Validation loss decreased (1.015662 --> 1.014498).  Saving model ...
Validation loss decreased (1.014498 --> 1.009734).  Saving model ...
Validation loss decreased (1.009734 --> 1.007759).  Saving model ...
Validation loss decreased (1.007759 --> 1.006385).  Saving model ...
Validation loss decreased (1.006385 --> 1.002513).  Saving model ...
Validation loss decreased (1.002513 --> 0.999957).  Saving model ...
Validation loss decreased (0.999957 --> 0.998538).  Saving model ...
EarlyStopping counter: 1 out of 3.0
Validation loss decreased (0.998538 --> 0.996249).  Saving model ...
Validation loss decreased (0.996249 --> 0.992835).  Saving model ...
EarlyStopping counter: 1 out of 3.0
EarlyStopping counter: 2 out of 3.0
Validation loss decreased (0.992835 --> 0.992345).  Saving model ...
Validation loss decreased (0.992345 --> 0.990914).  Saving model ...
EarlyStopping counter: 1 out of 3.0
Validation loss decreased (0.990914 --> 0.989961).  Saving model ...
Validation loss decreased (0.989961 --> 0.987287).  Saving model ...
Validation loss decreased (0.987287 --> 0.985838).  Saving model ...
Validation loss decreased (0.985838 --> 0.985116).  Saving model ...
Validation loss decreased (0.985116 --> 0.983837).  Saving model ...
Validation loss decreased (0.983837 --> 0.982931).  Saving model ...
Validation loss decreased (0.982931 --> 0.980767).  Saving model ...
Validation loss decreased (0.980767 --> 0.979876).  Saving model ...
EarlyStopping counter: 1 out of 3.0
EarlyStopping counter: 2 out of 3.0
Validation loss decreased (0.979876 --> 0.979143).  Saving model ...
Validation loss decreased (0.979143 --> 0.978036).  Saving model ...
Validation loss decreased (0.978036 --> 0.975712).  Saving model ...
EarlyStopping counter: 1 out of 3.0
EarlyStopping counter: 2 out of 3.0
Validation loss decreased (0.975712 --> 0.973232).  Saving model ...
Validation loss decreased (0.973232 --> 0.971461).  Saving model ...
Validation loss decreased (0.971461 --> 0.970885).  Saving model ...
Validation loss decreased (0.970885 --> 0.970306).  Saving model ...
Validation loss decreased (0.970306 --> 0.969642).  Saving model ...
EarlyStopping counter: 1 out of 3.0
EarlyStopping counter: 2 out of 3.0
Validation loss decreased (0.969642 --> 0.969500).  Saving model ...
Validation loss decreased (0.969500 --> 0.968486).  Saving model ...
EarlyStopping counter: 1 out of 3.0
EarlyStopping counter: 2 out of 3.0
Validation loss decreased (0.968486 --> 0.966923).  Saving model ...
Validation loss decreased (0.966923 --> 0.966609).  Saving model ...
Validation loss decreased (0.966609 --> 0.963656).  Saving model ...
EarlyStopping counter: 1 out of 3.0
Validation loss decreased (0.963656 --> 0.963610).  Saving model ...
Validation loss decreased (0.963610 --> 0.961796).  Saving model ...
EarlyStopping counter: 1 out of 3.0
EarlyStopping counter: 2 out of 3.0
Validation loss decreased (0.961796 --> 0.961501).  Saving model ...
EarlyStopping counter: 1 out of 3.0
EarlyStopping counter: 2 out of 3.0
EarlyStopping counter: 3 out of 3.0
/localscratch/yinan.29785221.0/env/lib/python3.7/site-packages/torch/nn/functional.py:1794: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.
  warnings.warn("nn.functional.tanh is deprecated. Use torch.tanh instead.")
wandb: Waiting for W&B process to finish, PID 179322... (success).
wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: \ 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: | 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: / 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: \ 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: | 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: / 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: \ 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: | 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: / 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb:                                                                                
wandb: Run history:
wandb:     e_F1 ▁▁▃▄▅▅▅▅▆▆▆▆▆▆▆▇▇▇▇▇▇▇▇▇▇▇▇▇██▇█████████
wandb:   e_loss ██▇▇▇▆▆▆▅▅▅▄▄▄▄▃▃▃▃▃▂▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁
wandb:     t_F1 ▁▂▂▃▃▄▄▄▅▅▅▅▅▅▆▆▆▆▆▆▇▆▇▇▇▇▇▇▇▇▇▇█▇█▇████
wandb:   t_loss ██▇▇▇▇▇▆▆▆▆▅▅▅▅▅▄▄▄▄▄▃▃▃▃▃▃▂▂▂▂▂▂▂▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:     e_F1 59.6474
wandb:   e_loss 0.96215
wandb:     t_F1 73.02248
wandb:   t_loss 0.72729
wandb: 
wandb: Synced 4 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Synced driven-planet-2: https://wandb.ai/yinanazhou/xl_512_bs_8_lr_1e06_es_3_lc_True_nr_True_sr_False_stem_False_lemma_False_repeat_2_fold_1/runs/3vcfeltk
wandb: Find logs at: ./wandb/run-20220329_225434-3vcfeltk/logs/debug.log
wandb: 

wandb: wandb version 0.12.11 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
2022-03-30 00:26:56.058374: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1
wandb: Tracking run with wandb version 0.12.5
wandb: Syncing run soft-flower-2
wandb: ⭐️ View project at https://wandb.ai/yinanazhou/xl_512_bs_8_lr_1e06_es_3_lc_True_nr_True_sr_False_stem_False_lemma_False_repeat_2_fold_2
wandb: 🚀 View run at https://wandb.ai/yinanazhou/xl_512_bs_8_lr_1e06_es_3_lc_True_nr_True_sr_False_stem_False_lemma_False_repeat_2_fold_2/runs/3cmx4rwk
wandb: Run data is saved locally in /project/6002780/yinan/Thesis_MER_Lyrics/lyric-emotion/wandb/run-20220330_002653-3cmx4rwk
wandb: Run `wandb offline` to turn off syncing.

Validation loss decreased (inf --> 1.407116).  Saving model ...
Validation loss decreased (1.407116 --> 1.397291).  Saving model ...
Validation loss decreased (1.397291 --> 1.389982).  Saving model ...
Validation loss decreased (1.389982 --> 1.383557).  Saving model ...
Validation loss decreased (1.383557 --> 1.378163).  Saving model ...
Validation loss decreased (1.378163 --> 1.373550).  Saving model ...
Validation loss decreased (1.373550 --> 1.368628).  Saving model ...
Validation loss decreased (1.368628 --> 1.364359).  Saving model ...
Validation loss decreased (1.364359 --> 1.360435).  Saving model ...
Validation loss decreased (1.360435 --> 1.356041).  Saving model ...
Validation loss decreased (1.356041 --> 1.351732).  Saving model ...
Validation loss decreased (1.351732 --> 1.347104).  Saving model ...
Validation loss decreased (1.347104 --> 1.342757).  Saving model ...
Validation loss decreased (1.342757 --> 1.338209).  Saving model ...
Validation loss decreased (1.338209 --> 1.333591).  Saving model ...
Validation loss decreased (1.333591 --> 1.329020).  Saving model ...
Validation loss decreased (1.329020 --> 1.323811).  Saving model ...
Validation loss decreased (1.323811 --> 1.318721).  Saving model ...
Validation loss decreased (1.318721 --> 1.313386).  Saving model ...
Validation loss decreased (1.313386 --> 1.307857).  Saving model ...
Validation loss decreased (1.307857 --> 1.302499).  Saving model ...
Validation loss decreased (1.302499 --> 1.296528).  Saving model ...
Validation loss decreased (1.296528 --> 1.291069).  Saving model ...
Validation loss decreased (1.291069 --> 1.284698).  Saving model ...
Validation loss decreased (1.284698 --> 1.277707).  Saving model ...
Validation loss decreased (1.277707 --> 1.269658).  Saving model ...
Validation loss decreased (1.269658 --> 1.261773).  Saving model ...
Validation loss decreased (1.261773 --> 1.254849).  Saving model ...
Validation loss decreased (1.254849 --> 1.248935).  Saving model ...
Validation loss decreased (1.248935 --> 1.242227).  Saving model ...
Validation loss decreased (1.242227 --> 1.236340).  Saving model ...
Validation loss decreased (1.236340 --> 1.227919).  Saving model ...
Validation loss decreased (1.227919 --> 1.220876).  Saving model ...
Validation loss decreased (1.220876 --> 1.215828).  Saving model ...
Validation loss decreased (1.215828 --> 1.209762).  Saving model ...
Validation loss decreased (1.209762 --> 1.202268).  Saving model ...
Validation loss decreased (1.202268 --> 1.194879).  Saving model ...
Validation loss decreased (1.194879 --> 1.190525).  Saving model ...
Validation loss decreased (1.190525 --> 1.184913).  Saving model ...
Validation loss decreased (1.184913 --> 1.179073).  Saving model ...
Validation loss decreased (1.179073 --> 1.173175).  Saving model ...
Validation loss decreased (1.173175 --> 1.168287).  Saving model ...
Validation loss decreased (1.168287 --> 1.162035).  Saving model ...
Validation loss decreased (1.162035 --> 1.156496).  Saving model ...
Validation loss decreased (1.156496 --> 1.152908).  Saving model ...
Validation loss decreased (1.152908 --> 1.146733).  Saving model ...
Validation loss decreased (1.146733 --> 1.139566).  Saving model ...
Validation loss decreased (1.139566 --> 1.136638).  Saving model ...
Validation loss decreased (1.136638 --> 1.132279).  Saving model ...
Validation loss decreased (1.132279 --> 1.127239).  Saving model ...
Validation loss decreased (1.127239 --> 1.121787).  Saving model ...
Validation loss decreased (1.121787 --> 1.116091).  Saving model ...
Validation loss decreased (1.116091 --> 1.111766).  Saving model ...
Validation loss decreased (1.111766 --> 1.107150).  Saving model ...
Validation loss decreased (1.107150 --> 1.101964).  Saving model ...
Validation loss decreased (1.101964 --> 1.097148).  Saving model ...
Validation loss decreased (1.097148 --> 1.092048).  Saving model ...
Validation loss decreased (1.092048 --> 1.089130).  Saving model ...
Validation loss decreased (1.089130 --> 1.085181).  Saving model ...
Validation loss decreased (1.085181 --> 1.081954).  Saving model ...
Validation loss decreased (1.081954 --> 1.077572).  Saving model ...
Validation loss decreased (1.077572 --> 1.071582).  Saving model ...
Validation loss decreased (1.071582 --> 1.069620).  Saving model ...
Validation loss decreased (1.069620 --> 1.064916).  Saving model ...
Validation loss decreased (1.064916 --> 1.063912).  Saving model ...
Validation loss decreased (1.063912 --> 1.056588).  Saving model ...
Validation loss decreased (1.056588 --> 1.055044).  Saving model ...
Validation loss decreased (1.055044 --> 1.049714).  Saving model ...
Validation loss decreased (1.049714 --> 1.045240).  Saving model ...
Validation loss decreased (1.045240 --> 1.043567).  Saving model ...
Validation loss decreased (1.043567 --> 1.039469).  Saving model ...
Validation loss decreased (1.039469 --> 1.036924).  Saving model ...
Validation loss decreased (1.036924 --> 1.034211).  Saving model ...
Validation loss decreased (1.034211 --> 1.030984).  Saving model ...
Validation loss decreased (1.030984 --> 1.028216).  Saving model ...
Validation loss decreased (1.028216 --> 1.025875).  Saving model ...
Validation loss decreased (1.025875 --> 1.023286).  Saving model ...
Validation loss decreased (1.023286 --> 1.018854).  Saving model ...
Validation loss decreased (1.018854 --> 1.014703).  Saving model ...
Validation loss decreased (1.014703 --> 1.011114).  Saving model ...
Validation loss decreased (1.011114 --> 1.010128).  Saving model ...
Validation loss decreased (1.010128 --> 1.005999).  Saving model ...
Validation loss decreased (1.005999 --> 1.005076).  Saving model ...
Validation loss decreased (1.005076 --> 1.001717).  Saving model ...
Validation loss decreased (1.001717 --> 0.996079).  Saving model ...
Validation loss decreased (0.996079 --> 0.994749).  Saving model ...
Validation loss decreased (0.994749 --> 0.993879).  Saving model ...
EarlyStopping counter: 1 out of 3.0
Validation loss decreased (0.993879 --> 0.992959).  Saving model ...
Validation loss decreased (0.992959 --> 0.990073).  Saving model ...
Validation loss decreased (0.990073 --> 0.985978).  Saving model ...
Validation loss decreased (0.985978 --> 0.984717).  Saving model ...
Validation loss decreased (0.984717 --> 0.984143).  Saving model ...
Validation loss decreased (0.984143 --> 0.982194).  Saving model ...
Validation loss decreased (0.982194 --> 0.978646).  Saving model ...
Validation loss decreased (0.978646 --> 0.976030).  Saving model ...
Validation loss decreased (0.976030 --> 0.974691).  Saving model ...
EarlyStopping counter: 1 out of 3.0
Validation loss decreased (0.974691 --> 0.972559).  Saving model ...
Validation loss decreased (0.972559 --> 0.970260).  Saving model ...
EarlyStopping counter: 1 out of 3.0
Validation loss decreased (0.970260 --> 0.967214).  Saving model ...
Validation loss decreased (0.967214 --> 0.962380).  Saving model ...
Validation loss decreased (0.962380 --> 0.961196).  Saving model ...
Validation loss decreased (0.961196 --> 0.959068).  Saving model ...
Validation loss decreased (0.959068 --> 0.958724).  Saving model ...
Validation loss decreased (0.958724 --> 0.957599).  Saving model ...
Validation loss decreased (0.957599 --> 0.955663).  Saving model ...
Validation loss decreased (0.955663 --> 0.955464).  Saving model ...
Validation loss decreased (0.955464 --> 0.952622).  Saving model ...
Validation loss decreased (0.952622 --> 0.950883).  Saving model ...
EarlyStopping counter: 1 out of 3.0
Validation loss decreased (0.950883 --> 0.950365).  Saving model ...
Validation loss decreased (0.950365 --> 0.947486).  Saving model ...
Validation loss decreased (0.947486 --> 0.945996).  Saving model ...
Validation loss decreased (0.945996 --> 0.943791).  Saving model ...
EarlyStopping counter: 1 out of 3.0
Validation loss decreased (0.943791 --> 0.943324).  Saving model ...
Validation loss decreased (0.943324 --> 0.943057).  Saving model ...
Validation loss decreased (0.943057 --> 0.942131).  Saving model ...
Validation loss decreased (0.942131 --> 0.942036).  Saving model ...
Validation loss decreased (0.942036 --> 0.941282).  Saving model ...
EarlyStopping counter: 1 out of 3.0
Validation loss decreased (0.941282 --> 0.940810).  Saving model ...
Validation loss decreased (0.940810 --> 0.939087).  Saving model ...
Validation loss decreased (0.939087 --> 0.936041).  Saving model ...
Validation loss decreased (0.936041 --> 0.933884).  Saving model ...
EarlyStopping counter: 1 out of 3.0
EarlyStopping counter: 2 out of 3.0
EarlyStopping counter: 3 out of 3.0
/localscratch/yinan.29785221.0/env/lib/python3.7/site-packages/torch/nn/functional.py:1794: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.
  warnings.warn("nn.functional.tanh is deprecated. Use torch.tanh instead.")
wandb: Waiting for W&B process to finish, PID 184353... (success).
wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: \ 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: | 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: / 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: \ 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: | 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: / 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: \ 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: | 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: / 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb:                                                                                
wandb: Run history:
wandb:     e_F1 ▁▂▃▄▅▅▅▆▆▆▆▆▆▆▆▇▇▇▇▇▇▇▇▇▇▇█▇▇▇██████████
wandb:   e_loss ███▇▇▇▇▆▆▆▅▅▅▄▄▄▄▃▃▃▃▃▂▂▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁
wandb:     t_F1 ▁▁▂▃▃▄▃▄▄▅▅▅▆▆▅▆▆▆▆▆▆▆▇▇▇▇▆▇▇▇▇██▇▇▇████
wandb:   t_loss ████▇▇▇▇▆▆▆▆▅▅▅▅▅▄▄▄▄▄▃▃▃▃▃▃▃▂▂▂▂▂▂▂▂▁▁▁
wandb: 
wandb: Run summary:
wandb:     e_F1 62.06694
wandb:   e_loss 0.93497
wandb:     t_F1 68.12285
wandb:   t_loss 0.78331
wandb: 
wandb: Synced 4 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Synced soft-flower-2: https://wandb.ai/yinanazhou/xl_512_bs_8_lr_1e06_es_3_lc_True_nr_True_sr_False_stem_False_lemma_False_repeat_2_fold_2/runs/3cmx4rwk
wandb: Find logs at: ./wandb/run-20220330_002653-3cmx4rwk/logs/debug.log
wandb: 

wandb: wandb version 0.12.11 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
2022-03-30 01:51:39.329053: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1
wandb: Tracking run with wandb version 0.12.5
wandb: Syncing run prime-grass-2
wandb: ⭐️ View project at https://wandb.ai/yinanazhou/xl_512_bs_8_lr_1e06_es_3_lc_True_nr_True_sr_False_stem_False_lemma_False_repeat_3_fold_1
wandb: 🚀 View run at https://wandb.ai/yinanazhou/xl_512_bs_8_lr_1e06_es_3_lc_True_nr_True_sr_False_stem_False_lemma_False_repeat_3_fold_1/runs/4vy1ltxm
wandb: Run data is saved locally in /project/6002780/yinan/Thesis_MER_Lyrics/lyric-emotion/wandb/run-20220330_015136-4vy1ltxm
wandb: Run `wandb offline` to turn off syncing.
wandb: Network error (ReadTimeout), entering retry loop.

Validation loss decreased (inf --> 1.446906).  Saving model ...
Validation loss decreased (1.446906 --> 1.418249).  Saving model ...
Validation loss decreased (1.418249 --> 1.398065).  Saving model ...
Validation loss decreased (1.398065 --> 1.383911).  Saving model ...
Validation loss decreased (1.383911 --> 1.372841).  Saving model ...
Validation loss decreased (1.372841 --> 1.364110).  Saving model ...
Validation loss decreased (1.364110 --> 1.357177).  Saving model ...
Validation loss decreased (1.357177 --> 1.351393).  Saving model ...
Validation loss decreased (1.351393 --> 1.345889).  Saving model ...
Validation loss decreased (1.345889 --> 1.341147).  Saving model ...
Validation loss decreased (1.341147 --> 1.336323).  Saving model ...
Validation loss decreased (1.336323 --> 1.331640).  Saving model ...
Validation loss decreased (1.331640 --> 1.326666).  Saving model ...
Validation loss decreased (1.326666 --> 1.322145).  Saving model ...
Validation loss decreased (1.322145 --> 1.316889).  Saving model ...
Validation loss decreased (1.316889 --> 1.311566).  Saving model ...
Validation loss decreased (1.311566 --> 1.305858).  Saving model ...
Validation loss decreased (1.305858 --> 1.299972).  Saving model ...
Validation loss decreased (1.299972 --> 1.294181).  Saving model ...
Validation loss decreased (1.294181 --> 1.287966).  Saving model ...
Validation loss decreased (1.287966 --> 1.281599).  Saving model ...
Validation loss decreased (1.281599 --> 1.274978).  Saving model ...
Validation loss decreased (1.274978 --> 1.268119).  Saving model ...
Validation loss decreased (1.268119 --> 1.261045).  Saving model ...
Validation loss decreased (1.261045 --> 1.253815).  Saving model ...
Validation loss decreased (1.253815 --> 1.245192).  Saving model ...
Validation loss decreased (1.245192 --> 1.238411).  Saving model ...
Validation loss decreased (1.238411 --> 1.230820).  Saving model ...
Validation loss decreased (1.230820 --> 1.222361).  Saving model ...
Validation loss decreased (1.222361 --> 1.213342).  Saving model ...
Validation loss decreased (1.213342 --> 1.205392).  Saving model ...
Validation loss decreased (1.205392 --> 1.198070).  Saving model ...
Validation loss decreased (1.198070 --> 1.192704).  Saving model ...
Validation loss decreased (1.192704 --> 1.183952).  Saving model ...
Validation loss decreased (1.183952 --> 1.175830).  Saving model ...
Validation loss decreased (1.175830 --> 1.167617).  Saving model ...
Validation loss decreased (1.167617 --> 1.162102).  Saving model ...
Validation loss decreased (1.162102 --> 1.156351).  Saving model ...
Validation loss decreased (1.156351 --> 1.149886).  Saving model ...
Validation loss decreased (1.149886 --> 1.145158).  Saving model ...
Validation loss decreased (1.145158 --> 1.140863).  Saving model ...
Validation loss decreased (1.140863 --> 1.134968).  Saving model ...
Validation loss decreased (1.134968 --> 1.131813).  Saving model ...
Validation loss decreased (1.131813 --> 1.128046).  Saving model ...
Validation loss decreased (1.128046 --> 1.122890).  Saving model ...
Validation loss decreased (1.122890 --> 1.117813).  Saving model ...
Validation loss decreased (1.117813 --> 1.114043).  Saving model ...
Validation loss decreased (1.114043 --> 1.110189).  Saving model ...
Validation loss decreased (1.110189 --> 1.107314).  Saving model ...
Validation loss decreased (1.107314 --> 1.104360).  Saving model ...
Validation loss decreased (1.104360 --> 1.100739).  Saving model ...
Validation loss decreased (1.100739 --> 1.095615).  Saving model ...
Validation loss decreased (1.095615 --> 1.093557).  Saving model ...
Validation loss decreased (1.093557 --> 1.088542).  Saving model ...
Validation loss decreased (1.088542 --> 1.084805).  Saving model ...
Validation loss decreased (1.084805 --> 1.082484).  Saving model ...
Validation loss decreased (1.082484 --> 1.077982).  Saving model ...
EarlyStopping counter: 1 out of 3.0
Validation loss decreased (1.077982 --> 1.073580).  Saving model ...
Validation loss decreased (1.073580 --> 1.071508).  Saving model ...
Validation loss decreased (1.071508 --> 1.068299).  Saving model ...
Validation loss decreased (1.068299 --> 1.065574).  Saving model ...
Validation loss decreased (1.065574 --> 1.062053).  Saving model ...
Validation loss decreased (1.062053 --> 1.057644).  Saving model ...
Validation loss decreased (1.057644 --> 1.055670).  Saving model ...
Validation loss decreased (1.055670 --> 1.053577).  Saving model ...
Validation loss decreased (1.053577 --> 1.050013).  Saving model ...
Validation loss decreased (1.050013 --> 1.049358).  Saving model ...
Validation loss decreased (1.049358 --> 1.045080).  Saving model ...
Validation loss decreased (1.045080 --> 1.041806).  Saving model ...
Validation loss decreased (1.041806 --> 1.038041).  Saving model ...
Validation loss decreased (1.038041 --> 1.037204).  Saving model ...
Validation loss decreased (1.037204 --> 1.033541).  Saving model ...
Validation loss decreased (1.033541 --> 1.031985).  Saving model ...
Validation loss decreased (1.031985 --> 1.030444).  Saving model ...
Validation loss decreased (1.030444 --> 1.029427).  Saving model ...
Validation loss decreased (1.029427 --> 1.027327).  Saving model ...
EarlyStopping counter: 1 out of 3.0
Validation loss decreased (1.027327 --> 1.024179).  Saving model ...
Validation loss decreased (1.024179 --> 1.022462).  Saving model ...
Validation loss decreased (1.022462 --> 1.017598).  Saving model ...
Validation loss decreased (1.017598 --> 1.014790).  Saving model ...
EarlyStopping counter: 1 out of 3.0
EarlyStopping counter: 2 out of 3.0
EarlyStopping counter: 3 out of 3.0
/localscratch/yinan.29785221.0/env/lib/python3.7/site-packages/torch/nn/functional.py:1794: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.
  warnings.warn("nn.functional.tanh is deprecated. Use torch.tanh instead.")
wandb: Waiting for W&B process to finish, PID 189044... (success).
wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: \ 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: | 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: / 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: \ 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: | 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: / 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: \ 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: | 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: / 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: \ 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: | 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: / 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb:                                                                                
wandb: Run history:
wandb:     e_F1 ▁▂▃▅▅▆▆▆▆▇▇▇▇▇▇▇▇▇▇▇▇███████████████████
wandb:   e_loss █▇▇▇▆▆▆▆▆▅▅▅▅▄▄▄▄▃▃▃▃▃▃▂▂▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁
wandb:     t_F1 ▁▁▂▂▃▃▃▄▄▄▄▅▅▅▆▅▆▆▆▆▆▆▆▇▇▇▇▇▇▇█▇█▇▇▇████
wandb:   t_loss █▇▇▇▇▇▇▆▆▆▆▅▅▅▅▅▄▄▄▄▄▄▃▃▃▃▃▂▂▂▂▂▂▂▂▂▂▁▁▁
wandb: 
wandb: Run summary:
wandb:     e_F1 55.73544
wandb:   e_loss 1.01586
wandb:     t_F1 63.58768
wandb:   t_loss 0.90252
wandb: 
wandb: Synced 4 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Synced prime-grass-2: https://wandb.ai/yinanazhou/xl_512_bs_8_lr_1e06_es_3_lc_True_nr_True_sr_False_stem_False_lemma_False_repeat_3_fold_1/runs/4vy1ltxm
wandb: Find logs at: ./wandb/run-20220330_015136-4vy1ltxm/logs/debug.log
wandb: 

wandb: wandb version 0.12.11 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
2022-03-30 02:47:59.479933: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1
wandb: Tracking run with wandb version 0.12.5
wandb: Syncing run toasty-voice-2
wandb: ⭐️ View project at https://wandb.ai/yinanazhou/xl_512_bs_8_lr_1e06_es_3_lc_True_nr_True_sr_False_stem_False_lemma_False_repeat_3_fold_2
wandb: 🚀 View run at https://wandb.ai/yinanazhou/xl_512_bs_8_lr_1e06_es_3_lc_True_nr_True_sr_False_stem_False_lemma_False_repeat_3_fold_2/runs/31kfsovg
wandb: Run data is saved locally in /project/6002780/yinan/Thesis_MER_Lyrics/lyric-emotion/wandb/run-20220330_024757-31kfsovg
wandb: Run `wandb offline` to turn off syncing.

Validation loss decreased (inf --> 1.417207).  Saving model ...
Validation loss decreased (1.417207 --> 1.404861).  Saving model ...
Validation loss decreased (1.404861 --> 1.394175).  Saving model ...
Validation loss decreased (1.394175 --> 1.384941).  Saving model ...
Validation loss decreased (1.384941 --> 1.377840).  Saving model ...
Validation loss decreased (1.377840 --> 1.371627).  Saving model ...
Validation loss decreased (1.371627 --> 1.365321).  Saving model ...
Validation loss decreased (1.365321 --> 1.359665).  Saving model ...
Validation loss decreased (1.359665 --> 1.354239).  Saving model ...
Validation loss decreased (1.354239 --> 1.349222).  Saving model ...
Validation loss decreased (1.349222 --> 1.343868).  Saving model ...
Validation loss decreased (1.343868 --> 1.338315).  Saving model ...
Validation loss decreased (1.338315 --> 1.333095).  Saving model ...
Validation loss decreased (1.333095 --> 1.328466).  Saving model ...
Validation loss decreased (1.328466 --> 1.323584).  Saving model ...
Validation loss decreased (1.323584 --> 1.318017).  Saving model ...
Validation loss decreased (1.318017 --> 1.313205).  Saving model ...
Validation loss decreased (1.313205 --> 1.307652).  Saving model ...
Validation loss decreased (1.307652 --> 1.301824).  Saving model ...
Validation loss decreased (1.301824 --> 1.295019).  Saving model ...
Validation loss decreased (1.295019 --> 1.288235).  Saving model ...
Validation loss decreased (1.288235 --> 1.283583).  Saving model ...
Validation loss decreased (1.283583 --> 1.275032).  Saving model ...
Validation loss decreased (1.275032 --> 1.269030).  Saving model ...
Validation loss decreased (1.269030 --> 1.262970).  Saving model ...
Validation loss decreased (1.262970 --> 1.255448).  Saving model ...
Validation loss decreased (1.255448 --> 1.248192).  Saving model ...
Validation loss decreased (1.248192 --> 1.241319).  Saving model ...
Validation loss decreased (1.241319 --> 1.234751).  Saving model ...
Validation loss decreased (1.234751 --> 1.229111).  Saving model ...
Validation loss decreased (1.229111 --> 1.222492).  Saving model ...
Validation loss decreased (1.222492 --> 1.216795).  Saving model ...
Validation loss decreased (1.216795 --> 1.211400).  Saving model ...
Validation loss decreased (1.211400 --> 1.204875).  Saving model ...
Validation loss decreased (1.204875 --> 1.198857).  Saving model ...
Validation loss decreased (1.198857 --> 1.192190).  Saving model ...
Validation loss decreased (1.192190 --> 1.186232).  Saving model ...
Validation loss decreased (1.186232 --> 1.179436).  Saving model ...
Validation loss decreased (1.179436 --> 1.171877).  Saving model ...
Validation loss decreased (1.171877 --> 1.165256).  Saving model ...
Validation loss decreased (1.165256 --> 1.160913).  Saving model ...
Validation loss decreased (1.160913 --> 1.156067).  Saving model ...
Validation loss decreased (1.156067 --> 1.149936).  Saving model ...
Validation loss decreased (1.149936 --> 1.143930).  Saving model ...
Validation loss decreased (1.143930 --> 1.139858).  Saving model ...
Validation loss decreased (1.139858 --> 1.135351).  Saving model ...
Validation loss decreased (1.135351 --> 1.131349).  Saving model ...
Validation loss decreased (1.131349 --> 1.126955).  Saving model ...
Validation loss decreased (1.126955 --> 1.120798).  Saving model ...
Validation loss decreased (1.120798 --> 1.115978).  Saving model ...
Validation loss decreased (1.115978 --> 1.113570).  Saving model ...
Validation loss decreased (1.113570 --> 1.110680).  Saving model ...
Validation loss decreased (1.110680 --> 1.106556).  Saving model ...
Validation loss decreased (1.106556 --> 1.101103).  Saving model ...
Validation loss decreased (1.101103 --> 1.096084).  Saving model ...
Validation loss decreased (1.096084 --> 1.091711).  Saving model ...
Validation loss decreased (1.091711 --> 1.086600).  Saving model ...
Validation loss decreased (1.086600 --> 1.082135).  Saving model ...
Validation loss decreased (1.082135 --> 1.077917).  Saving model ...
Validation loss decreased (1.077917 --> 1.074280).  Saving model ...
Validation loss decreased (1.074280 --> 1.068863).  Saving model ...
Validation loss decreased (1.068863 --> 1.063657).  Saving model ...
Validation loss decreased (1.063657 --> 1.060914).  Saving model ...
Validation loss decreased (1.060914 --> 1.059468).  Saving model ...
Validation loss decreased (1.059468 --> 1.056566).  Saving model ...
Validation loss decreased (1.056566 --> 1.055416).  Saving model ...
Validation loss decreased (1.055416 --> 1.050318).  Saving model ...
Validation loss decreased (1.050318 --> 1.047153).  Saving model ...
Validation loss decreased (1.047153 --> 1.042541).  Saving model ...
Validation loss decreased (1.042541 --> 1.037258).  Saving model ...
Validation loss decreased (1.037258 --> 1.035382).  Saving model ...
Validation loss decreased (1.035382 --> 1.032307).  Saving model ...
Validation loss decreased (1.032307 --> 1.030463).  Saving model ...
Validation loss decreased (1.030463 --> 1.029112).  Saving model ...
Validation loss decreased (1.029112 --> 1.026917).  Saving model ...
Validation loss decreased (1.026917 --> 1.023972).  Saving model ...
Validation loss decreased (1.023972 --> 1.021652).  Saving model ...
Validation loss decreased (1.021652 --> 1.020007).  Saving model ...
Validation loss decreased (1.020007 --> 1.016957).  Saving model ...
Validation loss decreased (1.016957 --> 1.013533).  Saving model ...
Validation loss decreased (1.013533 --> 1.009803).  Saving model ...
Validation loss decreased (1.009803 --> 1.007792).  Saving model ...
Validation loss decreased (1.007792 --> 1.006223).  Saving model ...
EarlyStopping counter: 1 out of 3.0
Validation loss decreased (1.006223 --> 1.002293).  Saving model ...
Validation loss decreased (1.002293 --> 0.998822).  Saving model ...
Validation loss decreased (0.998822 --> 0.997960).  Saving model ...
Validation loss decreased (0.997960 --> 0.995148).  Saving model ...
Validation loss decreased (0.995148 --> 0.993003).  Saving model ...
Validation loss decreased (0.993003 --> 0.991155).  Saving model ...
Validation loss decreased (0.991155 --> 0.988566).  Saving model ...
Validation loss decreased (0.988566 --> 0.987049).  Saving model ...
Validation loss decreased (0.987049 --> 0.983827).  Saving model ...
Validation loss decreased (0.983827 --> 0.982426).  Saving model ...
Validation loss decreased (0.982426 --> 0.979938).  Saving model ...
Validation loss decreased (0.979938 --> 0.979612).  Saving model ...
Validation loss decreased (0.979612 --> 0.975783).  Saving model ...
Validation loss decreased (0.975783 --> 0.974790).  Saving model ...
Validation loss decreased (0.974790 --> 0.974181).  Saving model ...
Validation loss decreased (0.974181 --> 0.972484).  Saving model ...
Validation loss decreased (0.972484 --> 0.968895).  Saving model ...
Validation loss decreased (0.968895 --> 0.967358).  Saving model ...
Validation loss decreased (0.967358 --> 0.966801).  Saving model ...
Validation loss decreased (0.966801 --> 0.964451).  Saving model ...
Validation loss decreased (0.964451 --> 0.962680).  Saving model ...
EarlyStopping counter: 1 out of 3.0
Validation loss decreased (0.962680 --> 0.962631).  Saving model ...
Validation loss decreased (0.962631 --> 0.961312).  Saving model ...
Validation loss decreased (0.961312 --> 0.959465).  Saving model ...
EarlyStopping counter: 1 out of 3.0
Validation loss decreased (0.959465 --> 0.956889).  Saving model ...
Validation loss decreased (0.956889 --> 0.954902).  Saving model ...
Validation loss decreased (0.954902 --> 0.953530).  Saving model ...
Validation loss decreased (0.953530 --> 0.951865).  Saving model ...
EarlyStopping counter: 1 out of 3.0
Validation loss decreased (0.951865 --> 0.950377).  Saving model ...
EarlyStopping counter: 1 out of 3.0
EarlyStopping counter: 2 out of 3.0
Validation loss decreased (0.950377 --> 0.949821).  Saving model ...
EarlyStopping counter: 1 out of 3.0
Validation loss decreased (0.949821 --> 0.947717).  Saving model ...
Validation loss decreased (0.947717 --> 0.945288).  Saving model ...
Validation loss decreased (0.945288 --> 0.944195).  Saving model ...
EarlyStopping counter: 1 out of 3.0
EarlyStopping counter: 2 out of 3.0
EarlyStopping counter: 3 out of 3.0
/localscratch/yinan.29785221.0/env/lib/python3.7/site-packages/torch/nn/functional.py:1794: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.
  warnings.warn("nn.functional.tanh is deprecated. Use torch.tanh instead.")
wandb: Waiting for W&B process to finish, PID 192249... (success).
wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: \ 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: | 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: / 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: \ 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: | 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: / 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: \ 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: | 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: / 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: \ 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: | 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb:                                                                                
wandb: Run history:
wandb:     e_F1 ▁▂▃▄▅▅▅▅▆▆▆▆▆▆▆▇▇▇▇▇▇▇▇▇▇█▇█████████████
wandb:   e_loss ██▇▇▇▆▆▆▆▅▅▅▄▄▄▄▃▃▃▃▃▃▂▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁
wandb:     t_F1 ▁▁▂▂▃▃▄▄▄▅▅▄▅▅▆▆▆▆▆▆▆▇▇▆▆▇▇▇▇▇▇▇▇▇█▇▇▇██
wandb:   t_loss ███▇▇▇▇▇▆▆▆▆▆▅▅▅▄▄▄▄▄▃▃▄▃▃▃▃▃▃▂▂▂▂▂▂▂▂▁▁
wandb: 
wandb: Run summary:
wandb:     e_F1 60.9846
wandb:   e_loss 0.94487
wandb:     t_F1 70.02484
wandb:   t_loss 0.79303
wandb: 
wandb: Synced 4 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Synced toasty-voice-2: https://wandb.ai/yinanazhou/xl_512_bs_8_lr_1e06_es_3_lc_True_nr_True_sr_False_stem_False_lemma_False_repeat_3_fold_2/runs/31kfsovg
wandb: Find logs at: ./wandb/run-20220330_024757-31kfsovg/logs/debug.log
wandb: 

wandb: wandb version 0.12.11 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
2022-03-30 04:11:15.094978: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1
wandb: Tracking run with wandb version 0.12.5
wandb: Syncing run ethereal-cloud-2
wandb: ⭐️ View project at https://wandb.ai/yinanazhou/xl_512_bs_8_lr_1e06_es_3_lc_True_nr_True_sr_False_stem_False_lemma_False_repeat_4_fold_1
wandb: 🚀 View run at https://wandb.ai/yinanazhou/xl_512_bs_8_lr_1e06_es_3_lc_True_nr_True_sr_False_stem_False_lemma_False_repeat_4_fold_1/runs/10fqmzua
wandb: Run data is saved locally in /project/6002780/yinan/Thesis_MER_Lyrics/lyric-emotion/wandb/run-20220330_041112-10fqmzua
wandb: Run `wandb offline` to turn off syncing.

Validation loss decreased (inf --> 1.442301).  Saving model ...
Validation loss decreased (1.442301 --> 1.422463).  Saving model ...
Validation loss decreased (1.422463 --> 1.406901).  Saving model ...
Validation loss decreased (1.406901 --> 1.394867).  Saving model ...
Validation loss decreased (1.394867 --> 1.384792).  Saving model ...
Validation loss decreased (1.384792 --> 1.377339).  Saving model ...
Validation loss decreased (1.377339 --> 1.371102).  Saving model ...
Validation loss decreased (1.371102 --> 1.365140).  Saving model ...
Validation loss decreased (1.365140 --> 1.359900).  Saving model ...
Validation loss decreased (1.359900 --> 1.355429).  Saving model ...
Validation loss decreased (1.355429 --> 1.351235).  Saving model ...
Validation loss decreased (1.351235 --> 1.347308).  Saving model ...
Validation loss decreased (1.347308 --> 1.343451).  Saving model ...
Validation loss decreased (1.343451 --> 1.338994).  Saving model ...
Validation loss decreased (1.338994 --> 1.334347).  Saving model ...
Validation loss decreased (1.334347 --> 1.329571).  Saving model ...
Validation loss decreased (1.329571 --> 1.325124).  Saving model ...
Validation loss decreased (1.325124 --> 1.320503).  Saving model ...
Validation loss decreased (1.320503 --> 1.315999).  Saving model ...
Validation loss decreased (1.315999 --> 1.310752).  Saving model ...
Validation loss decreased (1.310752 --> 1.305740).  Saving model ...
Validation loss decreased (1.305740 --> 1.300710).  Saving model ...
Validation loss decreased (1.300710 --> 1.295875).  Saving model ...
Validation loss decreased (1.295875 --> 1.290465).  Saving model ...
Validation loss decreased (1.290465 --> 1.285192).  Saving model ...
Validation loss decreased (1.285192 --> 1.279821).  Saving model ...
Validation loss decreased (1.279821 --> 1.273996).  Saving model ...
Validation loss decreased (1.273996 --> 1.268450).  Saving model ...
Validation loss decreased (1.268450 --> 1.263019).  Saving model ...
Validation loss decreased (1.263019 --> 1.257393).  Saving model ...
Validation loss decreased (1.257393 --> 1.252561).  Saving model ...
Validation loss decreased (1.252561 --> 1.247479).  Saving model ...
Validation loss decreased (1.247479 --> 1.242869).  Saving model ...
Validation loss decreased (1.242869 --> 1.237576).  Saving model ...
Validation loss decreased (1.237576 --> 1.232213).  Saving model ...
Validation loss decreased (1.232213 --> 1.227636).  Saving model ...
Validation loss decreased (1.227636 --> 1.223200).  Saving model ...
Validation loss decreased (1.223200 --> 1.219374).  Saving model ...
Validation loss decreased (1.219374 --> 1.215617).  Saving model ...
Validation loss decreased (1.215617 --> 1.209880).  Saving model ...
Validation loss decreased (1.209880 --> 1.205510).  Saving model ...
Validation loss decreased (1.205510 --> 1.200902).  Saving model ...
Validation loss decreased (1.200902 --> 1.196995).  Saving model ...
Validation loss decreased (1.196995 --> 1.191647).  Saving model ...
Validation loss decreased (1.191647 --> 1.186252).  Saving model ...
Validation loss decreased (1.186252 --> 1.180504).  Saving model ...
Validation loss decreased (1.180504 --> 1.176424).  Saving model ...
Validation loss decreased (1.176424 --> 1.172513).  Saving model ...
Validation loss decreased (1.172513 --> 1.168596).  Saving model ...
Validation loss decreased (1.168596 --> 1.165338).  Saving model ...
Validation loss decreased (1.165338 --> 1.161991).  Saving model ...
Validation loss decreased (1.161991 --> 1.157788).  Saving model ...
Validation loss decreased (1.157788 --> 1.154131).  Saving model ...
Validation loss decreased (1.154131 --> 1.150079).  Saving model ...
Validation loss decreased (1.150079 --> 1.147068).  Saving model ...
Validation loss decreased (1.147068 --> 1.143621).  Saving model ...
Validation loss decreased (1.143621 --> 1.140806).  Saving model ...
Validation loss decreased (1.140806 --> 1.136670).  Saving model ...
Validation loss decreased (1.136670 --> 1.133421).  Saving model ...
Validation loss decreased (1.133421 --> 1.128842).  Saving model ...
Validation loss decreased (1.128842 --> 1.124301).  Saving model ...
Validation loss decreased (1.124301 --> 1.120993).  Saving model ...
Validation loss decreased (1.120993 --> 1.118859).  Saving model ...
Validation loss decreased (1.118859 --> 1.116224).  Saving model ...
Validation loss decreased (1.116224 --> 1.114201).  Saving model ...
Validation loss decreased (1.114201 --> 1.111223).  Saving model ...
Validation loss decreased (1.111223 --> 1.108400).  Saving model ...
Validation loss decreased (1.108400 --> 1.106872).  Saving model ...
Validation loss decreased (1.106872 --> 1.104170).  Saving model ...
Validation loss decreased (1.104170 --> 1.101733).  Saving model ...
Validation loss decreased (1.101733 --> 1.099607).  Saving model ...
Validation loss decreased (1.099607 --> 1.097468).  Saving model ...
Validation loss decreased (1.097468 --> 1.094026).  Saving model ...
Validation loss decreased (1.094026 --> 1.092881).  Saving model ...
Validation loss decreased (1.092881 --> 1.090607).  Saving model ...
Validation loss decreased (1.090607 --> 1.089257).  Saving model ...
Validation loss decreased (1.089257 --> 1.087204).  Saving model ...
Validation loss decreased (1.087204 --> 1.083069).  Saving model ...
Validation loss decreased (1.083069 --> 1.081379).  Saving model ...
Validation loss decreased (1.081379 --> 1.077802).  Saving model ...
Validation loss decreased (1.077802 --> 1.074905).  Saving model ...
Validation loss decreased (1.074905 --> 1.073728).  Saving model ...
Validation loss decreased (1.073728 --> 1.072250).  Saving model ...
Validation loss decreased (1.072250 --> 1.069130).  Saving model ...
Validation loss decreased (1.069130 --> 1.067012).  Saving model ...
Validation loss decreased (1.067012 --> 1.064652).  Saving model ...
Validation loss decreased (1.064652 --> 1.062352).  Saving model ...
Validation loss decreased (1.062352 --> 1.059679).  Saving model ...
Validation loss decreased (1.059679 --> 1.057724).  Saving model ...
Validation loss decreased (1.057724 --> 1.055818).  Saving model ...
Validation loss decreased (1.055818 --> 1.054358).  Saving model ...
Validation loss decreased (1.054358 --> 1.052192).  Saving model ...
Validation loss decreased (1.052192 --> 1.051610).  Saving model ...
Validation loss decreased (1.051610 --> 1.049220).  Saving model ...
Validation loss decreased (1.049220 --> 1.046778).  Saving model ...
Validation loss decreased (1.046778 --> 1.044049).  Saving model ...
Validation loss decreased (1.044049 --> 1.041087).  Saving model ...
Validation loss decreased (1.041087 --> 1.040652).  Saving model ...
Validation loss decreased (1.040652 --> 1.040614).  Saving model ...
Validation loss decreased (1.040614 --> 1.040303).  Saving model ...
Validation loss decreased (1.040303 --> 1.038614).  Saving model ...
Validation loss decreased (1.038614 --> 1.036582).  Saving model ...
Validation loss decreased (1.036582 --> 1.034066).  Saving model ...
Validation loss decreased (1.034066 --> 1.032388).  Saving model ...
Validation loss decreased (1.032388 --> 1.031205).  Saving model ...
Validation loss decreased (1.031205 --> 1.030406).  Saving model ...
Validation loss decreased (1.030406 --> 1.030079).  Saving model ...
Validation loss decreased (1.030079 --> 1.028433).  Saving model ...
Validation loss decreased (1.028433 --> 1.027916).  Saving model ...
Validation loss decreased (1.027916 --> 1.027057).  Saving model ...
Validation loss decreased (1.027057 --> 1.025780).  Saving model ...
Validation loss decreased (1.025780 --> 1.024504).  Saving model ...
Validation loss decreased (1.024504 --> 1.023195).  Saving model ...
Validation loss decreased (1.023195 --> 1.022409).  Saving model ...
Validation loss decreased (1.022409 --> 1.021069).  Saving model ...
Validation loss decreased (1.021069 --> 1.019609).  Saving model ...
Validation loss decreased (1.019609 --> 1.017132).  Saving model ...
Validation loss decreased (1.017132 --> 1.016795).  Saving model ...
Validation loss decreased (1.016795 --> 1.014726).  Saving model ...
Validation loss decreased (1.014726 --> 1.013710).  Saving model ...
Validation loss decreased (1.013710 --> 1.011890).  Saving model ...
Validation loss decreased (1.011890 --> 1.009966).  Saving model ...
Validation loss decreased (1.009966 --> 1.008231).  Saving model ...
Validation loss decreased (1.008231 --> 1.007481).  Saving model ...
Validation loss decreased (1.007481 --> 1.006838).  Saving model ...
Validation loss decreased (1.006838 --> 1.006608).  Saving model ...
Validation loss decreased (1.006608 --> 1.006465).  Saving model ...
EarlyStopping counter: 1 out of 3.0
Validation loss decreased (1.006465 --> 1.005139).  Saving model ...
Validation loss decreased (1.005139 --> 1.003767).  Saving model ...
Validation loss decreased (1.003767 --> 1.002105).  Saving model ...
Validation loss decreased (1.002105 --> 1.001511).  Saving model ...
EarlyStopping counter: 1 out of 3.0
Validation loss decreased (1.001511 --> 0.999954).  Saving model ...
EarlyStopping counter: 1 out of 3.0
EarlyStopping counter: 2 out of 3.0
Validation loss decreased (0.999954 --> 0.997070).  Saving model ...
EarlyStopping counter: 1 out of 3.0
Validation loss decreased (0.997070 --> 0.996238).  Saving model ...
Validation loss decreased (0.996238 --> 0.994010).  Saving model ...
Validation loss decreased (0.994010 --> 0.993694).  Saving model ...
EarlyStopping counter: 1 out of 3.0
EarlyStopping counter: 2 out of 3.0
EarlyStopping counter: 3 out of 3.0
/localscratch/yinan.29785221.0/env/lib/python3.7/site-packages/torch/nn/functional.py:1794: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.
  warnings.warn("nn.functional.tanh is deprecated. Use torch.tanh instead.")
wandb: Waiting for W&B process to finish, PID 196864... (success).
wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: \ 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: | 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: / 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: \ 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: | 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: / 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: \ 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: | 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: / 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb:                                                                                
wandb: Run history:
wandb:     e_F1 ▁▁▂▄▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇▇▇▇█▇████████████████
wandb:   e_loss ██▇▇▆▆▆▆▅▅▅▄▄▄▄▃▃▃▃▃▃▂▂▂▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁
wandb:     t_F1 ▁▁▂▂▃▄▄▄▄▅▅▅▅▅▆▆▆▆▆▆▇▇▇▇▇▇▇▇▇▇█▇█▇██████
wandb:   t_loss ███▇▇▇▇▆▆▆▆▅▅▅▅▄▄▄▄▄▄▃▃▃▃▃▃▂▃▂▂▂▂▂▂▂▂▁▁▁
wandb: 
wandb: Run summary:
wandb:     e_F1 54.13224
wandb:   e_loss 0.99391
wandb:     t_F1 70.84226
wandb:   t_loss 0.76264
wandb: 
wandb: Synced 4 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Synced ethereal-cloud-2: https://wandb.ai/yinanazhou/xl_512_bs_8_lr_1e06_es_3_lc_True_nr_True_sr_False_stem_False_lemma_False_repeat_4_fold_1/runs/10fqmzua
wandb: Find logs at: ./wandb/run-20220330_041112-10fqmzua/logs/debug.log
wandb: 

wandb: wandb version 0.12.11 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
2022-03-30 05:46:34.900169: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1
wandb: Tracking run with wandb version 0.12.5
wandb: Syncing run dashing-durian-2
wandb: ⭐️ View project at https://wandb.ai/yinanazhou/xl_512_bs_8_lr_1e06_es_3_lc_True_nr_True_sr_False_stem_False_lemma_False_repeat_4_fold_2
wandb: 🚀 View run at https://wandb.ai/yinanazhou/xl_512_bs_8_lr_1e06_es_3_lc_True_nr_True_sr_False_stem_False_lemma_False_repeat_4_fold_2/runs/2rbhzfrv
wandb: Run data is saved locally in /project/6002780/yinan/Thesis_MER_Lyrics/lyric-emotion/wandb/run-20220330_054632-2rbhzfrv
wandb: Run `wandb offline` to turn off syncing.

Validation loss decreased (inf --> 1.442284).  Saving model ...
Validation loss decreased (1.442284 --> 1.423770).  Saving model ...
Validation loss decreased (1.423770 --> 1.409915).  Saving model ...
Validation loss decreased (1.409915 --> 1.399467).  Saving model ...
Validation loss decreased (1.399467 --> 1.391094).  Saving model ...
Validation loss decreased (1.391094 --> 1.384187).  Saving model ...
Validation loss decreased (1.384187 --> 1.378014).  Saving model ...
Validation loss decreased (1.378014 --> 1.373668).  Saving model ...
Validation loss decreased (1.373668 --> 1.368959).  Saving model ...
Validation loss decreased (1.368959 --> 1.364599).  Saving model ...
Validation loss decreased (1.364599 --> 1.359841).  Saving model ...
Validation loss decreased (1.359841 --> 1.355410).  Saving model ...
Validation loss decreased (1.355410 --> 1.349983).  Saving model ...
Validation loss decreased (1.349983 --> 1.345758).  Saving model ...
Validation loss decreased (1.345758 --> 1.341252).  Saving model ...
Validation loss decreased (1.341252 --> 1.335916).  Saving model ...
Validation loss decreased (1.335916 --> 1.331378).  Saving model ...
Validation loss decreased (1.331378 --> 1.325336).  Saving model ...
Validation loss decreased (1.325336 --> 1.320754).  Saving model ...
Validation loss decreased (1.320754 --> 1.314439).  Saving model ...
Validation loss decreased (1.314439 --> 1.308473).  Saving model ...
Validation loss decreased (1.308473 --> 1.303552).  Saving model ...
Validation loss decreased (1.303552 --> 1.298096).  Saving model ...
Validation loss decreased (1.298096 --> 1.291062).  Saving model ...
Validation loss decreased (1.291062 --> 1.285321).  Saving model ...
Validation loss decreased (1.285321 --> 1.280500).  Saving model ...
Validation loss decreased (1.280500 --> 1.271761).  Saving model ...
Validation loss decreased (1.271761 --> 1.263784).  Saving model ...
Validation loss decreased (1.263784 --> 1.256652).  Saving model ...
Validation loss decreased (1.256652 --> 1.249438).  Saving model ...
Validation loss decreased (1.249438 --> 1.240835).  Saving model ...
Validation loss decreased (1.240835 --> 1.232313).  Saving model ...
Validation loss decreased (1.232313 --> 1.225977).  Saving model ...
Validation loss decreased (1.225977 --> 1.216758).  Saving model ...
Validation loss decreased (1.216758 --> 1.208965).  Saving model ...
Validation loss decreased (1.208965 --> 1.204159).  Saving model ...
Validation loss decreased (1.204159 --> 1.198337).  Saving model ...
Validation loss decreased (1.198337 --> 1.192475).  Saving model ...
Validation loss decreased (1.192475 --> 1.184336).  Saving model ...
Validation loss decreased (1.184336 --> 1.178036).  Saving model ...
Validation loss decreased (1.178036 --> 1.173680).  Saving model ...
Validation loss decreased (1.173680 --> 1.166645).  Saving model ...
Validation loss decreased (1.166645 --> 1.160255).  Saving model ...
Validation loss decreased (1.160255 --> 1.154665).  Saving model ...
Validation loss decreased (1.154665 --> 1.149480).  Saving model ...
Validation loss decreased (1.149480 --> 1.141919).  Saving model ...
Validation loss decreased (1.141919 --> 1.137434).  Saving model ...
Validation loss decreased (1.137434 --> 1.132177).  Saving model ...
Validation loss decreased (1.132177 --> 1.123741).  Saving model ...
Validation loss decreased (1.123741 --> 1.117873).  Saving model ...
Validation loss decreased (1.117873 --> 1.112978).  Saving model ...
Validation loss decreased (1.112978 --> 1.109334).  Saving model ...
Validation loss decreased (1.109334 --> 1.105430).  Saving model ...
Validation loss decreased (1.105430 --> 1.099833).  Saving model ...
Validation loss decreased (1.099833 --> 1.093757).  Saving model ...
Validation loss decreased (1.093757 --> 1.088780).  Saving model ...
Validation loss decreased (1.088780 --> 1.084042).  Saving model ...
Validation loss decreased (1.084042 --> 1.082387).  Saving model ...
Validation loss decreased (1.082387 --> 1.075472).  Saving model ...
Validation loss decreased (1.075472 --> 1.075102).  Saving model ...
Validation loss decreased (1.075102 --> 1.070071).  Saving model ...
Validation loss decreased (1.070071 --> 1.064212).  Saving model ...
Validation loss decreased (1.064212 --> 1.062339).  Saving model ...
Validation loss decreased (1.062339 --> 1.059155).  Saving model ...
Validation loss decreased (1.059155 --> 1.050584).  Saving model ...
Validation loss decreased (1.050584 --> 1.044363).  Saving model ...
Validation loss decreased (1.044363 --> 1.041420).  Saving model ...
Validation loss decreased (1.041420 --> 1.037927).  Saving model ...
Validation loss decreased (1.037927 --> 1.035435).  Saving model ...
Validation loss decreased (1.035435 --> 1.030348).  Saving model ...
Validation loss decreased (1.030348 --> 1.027809).  Saving model ...
Validation loss decreased (1.027809 --> 1.023991).  Saving model ...
Validation loss decreased (1.023991 --> 1.018989).  Saving model ...
Validation loss decreased (1.018989 --> 1.017014).  Saving model ...
Validation loss decreased (1.017014 --> 1.013640).  Saving model ...
Validation loss decreased (1.013640 --> 1.013433).  Saving model ...
EarlyStopping counter: 1 out of 3.0
Validation loss decreased (1.013433 --> 1.007272).  Saving model ...
Validation loss decreased (1.007272 --> 1.007012).  Saving model ...
Validation loss decreased (1.007012 --> 1.004099).  Saving model ...
Validation loss decreased (1.004099 --> 1.001390).  Saving model ...
EarlyStopping counter: 1 out of 3.0
Validation loss decreased (1.001390 --> 1.001063).  Saving model ...
Validation loss decreased (1.001063 --> 0.999872).  Saving model ...
Validation loss decreased (0.999872 --> 0.993707).  Saving model ...
EarlyStopping counter: 1 out of 3.0
Validation loss decreased (0.993707 --> 0.990866).  Saving model ...
Validation loss decreased (0.990866 --> 0.988476).  Saving model ...
Validation loss decreased (0.988476 --> 0.988368).  Saving model ...
Validation loss decreased (0.988368 --> 0.983992).  Saving model ...
Validation loss decreased (0.983992 --> 0.983520).  Saving model ...
Validation loss decreased (0.983520 --> 0.980073).  Saving model ...
Validation loss decreased (0.980073 --> 0.977922).  Saving model ...
Validation loss decreased (0.977922 --> 0.975709).  Saving model ...
Validation loss decreased (0.975709 --> 0.974908).  Saving model ...
Validation loss decreased (0.974908 --> 0.968906).  Saving model ...
EarlyStopping counter: 1 out of 3.0
Validation loss decreased (0.968906 --> 0.966972).  Saving model ...
EarlyStopping counter: 1 out of 3.0
EarlyStopping counter: 2 out of 3.0
Validation loss decreased (0.966972 --> 0.964195).  Saving model ...
EarlyStopping counter: 1 out of 3.0
EarlyStopping counter: 2 out of 3.0
EarlyStopping counter: 3 out of 3.0
/localscratch/yinan.29785221.0/env/lib/python3.7/site-packages/torch/nn/functional.py:1794: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.
  warnings.warn("nn.functional.tanh is deprecated. Use torch.tanh instead.")
wandb: Waiting for W&B process to finish, PID 202078... (success).
wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: \ 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: | 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: / 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: \ 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: | 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: / 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: \ 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: | 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: / 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb:                                                                                
wandb: Run history:
wandb:     e_F1 ▁▁▂▃▄▄▅▅▅▅▅▆▆▆▆▆▆▆▆▇▇▇▇▇▇▇▇▇█▇██████████
wandb:   e_loss ██▇▇▇▇▆▆▆▆▆▅▅▅▄▄▄▄▃▃▃▃▃▃▂▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁
wandb:     t_F1 ▁▂▂▃▃▃▄▄▄▅▅▅▅▅▅▆▆▆▆▅▆▆▆▆▆▆▇▆▇▇▇▇▇▇▇▇▇▇█▇
wandb:   t_loss █▇▇▇▇▇▇▆▇▆▆▆▆▅▅▅▅▄▄▄▄▄▄▃▃▃▃▃▃▂▂▂▂▂▂▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:     e_F1 58.9794
wandb:   e_loss 0.9644
wandb:     t_F1 66.06404
wandb:   t_loss 0.86497
wandb: 
wandb: Synced 4 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Synced dashing-durian-2: https://wandb.ai/yinanazhou/xl_512_bs_8_lr_1e06_es_3_lc_True_nr_True_sr_False_stem_False_lemma_False_repeat_4_fold_2/runs/2rbhzfrv
wandb: Find logs at: ./wandb/run-20220330_054632-2rbhzfrv/logs/debug.log
wandb: 

wandb: wandb version 0.12.11 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
2022-03-30 06:55:16.431511: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1
wandb: Tracking run with wandb version 0.12.5
wandb: Syncing run azure-valley-1
wandb: ⭐️ View project at https://wandb.ai/yinanazhou/xl_512_bs_8_lr_1e06_es_3_lc_True_nr_True_sr_False_stem_False_lemma_False_repeat_5_fold_1
wandb: 🚀 View run at https://wandb.ai/yinanazhou/xl_512_bs_8_lr_1e06_es_3_lc_True_nr_True_sr_False_stem_False_lemma_False_repeat_5_fold_1/runs/25sbszb4
wandb: Run data is saved locally in /project/6002780/yinan/Thesis_MER_Lyrics/lyric-emotion/wandb/run-20220330_065514-25sbszb4
wandb: Run `wandb offline` to turn off syncing.

Validation loss decreased (inf --> 1.403802).  Saving model ...
Validation loss decreased (1.403802 --> 1.397247).  Saving model ...
Validation loss decreased (1.397247 --> 1.391700).  Saving model ...
Validation loss decreased (1.391700 --> 1.387507).  Saving model ...
Validation loss decreased (1.387507 --> 1.383321).  Saving model ...
Validation loss decreased (1.383321 --> 1.379584).  Saving model ...
Validation loss decreased (1.379584 --> 1.376158).  Saving model ...
Validation loss decreased (1.376158 --> 1.372963).  Saving model ...
Validation loss decreased (1.372963 --> 1.369472).  Saving model ...
Validation loss decreased (1.369472 --> 1.365923).  Saving model ...
Validation loss decreased (1.365923 --> 1.362752).  Saving model ...
Validation loss decreased (1.362752 --> 1.359226).  Saving model ...
Validation loss decreased (1.359226 --> 1.355529).  Saving model ...
Validation loss decreased (1.355529 --> 1.351455).  Saving model ...
Validation loss decreased (1.351455 --> 1.347468).  Saving model ...
Validation loss decreased (1.347468 --> 1.343380).  Saving model ...
Validation loss decreased (1.343380 --> 1.339037).  Saving model ...
Validation loss decreased (1.339037 --> 1.334097).  Saving model ...
Validation loss decreased (1.334097 --> 1.329095).  Saving model ...
Validation loss decreased (1.329095 --> 1.324195).  Saving model ...
Validation loss decreased (1.324195 --> 1.317865).  Saving model ...
Validation loss decreased (1.317865 --> 1.312191).  Saving model ...
Validation loss decreased (1.312191 --> 1.306777).  Saving model ...
Validation loss decreased (1.306777 --> 1.300105).  Saving model ...
Validation loss decreased (1.300105 --> 1.293719).  Saving model ...
Validation loss decreased (1.293719 --> 1.286328).  Saving model ...
Validation loss decreased (1.286328 --> 1.279286).  Saving model ...
Validation loss decreased (1.279286 --> 1.271815).  Saving model ...
Validation loss decreased (1.271815 --> 1.263619).  Saving model ...
Validation loss decreased (1.263619 --> 1.254527).  Saving model ...
Validation loss decreased (1.254527 --> 1.245968).  Saving model ...
Validation loss decreased (1.245968 --> 1.237483).  Saving model ...
Validation loss decreased (1.237483 --> 1.229724).  Saving model ...
Validation loss decreased (1.229724 --> 1.221731).  Saving model ...
Validation loss decreased (1.221731 --> 1.214122).  Saving model ...
Validation loss decreased (1.214122 --> 1.206714).  Saving model ...
Validation loss decreased (1.206714 --> 1.197307).  Saving model ...
Validation loss decreased (1.197307 --> 1.189567).  Saving model ...
Validation loss decreased (1.189567 --> 1.183326).  Saving model ...
Validation loss decreased (1.183326 --> 1.175602).  Saving model ...
Validation loss decreased (1.175602 --> 1.168721).  Saving model ...
Validation loss decreased (1.168721 --> 1.161909).  Saving model ...
Validation loss decreased (1.161909 --> 1.155740).  Saving model ...
Validation loss decreased (1.155740 --> 1.149656).  Saving model ...
Validation loss decreased (1.149656 --> 1.144586).  Saving model ...
Validation loss decreased (1.144586 --> 1.138625).  Saving model ...
Validation loss decreased (1.138625 --> 1.133219).  Saving model ...
Validation loss decreased (1.133219 --> 1.127080).  Saving model ...
Validation loss decreased (1.127080 --> 1.122111).  Saving model ...
Validation loss decreased (1.122111 --> 1.117695).  Saving model ...
Validation loss decreased (1.117695 --> 1.113897).  Saving model ...
Validation loss decreased (1.113897 --> 1.110153).  Saving model ...
Validation loss decreased (1.110153 --> 1.104857).  Saving model ...
Validation loss decreased (1.104857 --> 1.100325).  Saving model ...
Validation loss decreased (1.100325 --> 1.096487).  Saving model ...
Validation loss decreased (1.096487 --> 1.092639).  Saving model ...
Validation loss decreased (1.092639 --> 1.088057).  Saving model ...
Validation loss decreased (1.088057 --> 1.084553).  Saving model ...
Validation loss decreased (1.084553 --> 1.080126).  Saving model ...
Validation loss decreased (1.080126 --> 1.076400).  Saving model ...
Validation loss decreased (1.076400 --> 1.072472).  Saving model ...
Validation loss decreased (1.072472 --> 1.067750).  Saving model ...
Validation loss decreased (1.067750 --> 1.063717).  Saving model ...
Validation loss decreased (1.063717 --> 1.059966).  Saving model ...
Validation loss decreased (1.059966 --> 1.056339).  Saving model ...
Validation loss decreased (1.056339 --> 1.052268).  Saving model ...
Validation loss decreased (1.052268 --> 1.048865).  Saving model ...
Validation loss decreased (1.048865 --> 1.044871).  Saving model ...
Validation loss decreased (1.044871 --> 1.041878).  Saving model ...
Validation loss decreased (1.041878 --> 1.039011).  Saving model ...
Validation loss decreased (1.039011 --> 1.036362).  Saving model ...
Validation loss decreased (1.036362 --> 1.033341).  Saving model ...
Validation loss decreased (1.033341 --> 1.030553).  Saving model ...
Validation loss decreased (1.030553 --> 1.026669).  Saving model ...
Validation loss decreased (1.026669 --> 1.025375).  Saving model ...
Validation loss decreased (1.025375 --> 1.022405).  Saving model ...
Validation loss decreased (1.022405 --> 1.019964).  Saving model ...
Validation loss decreased (1.019964 --> 1.017137).  Saving model ...
Validation loss decreased (1.017137 --> 1.014390).  Saving model ...
Validation loss decreased (1.014390 --> 1.012858).  Saving model ...
Validation loss decreased (1.012858 --> 1.010565).  Saving model ...
Validation loss decreased (1.010565 --> 1.007890).  Saving model ...
Validation loss decreased (1.007890 --> 1.005866).  Saving model ...
Validation loss decreased (1.005866 --> 1.003445).  Saving model ...
Validation loss decreased (1.003445 --> 1.001018).  Saving model ...
Validation loss decreased (1.001018 --> 0.999499).  Saving model ...
Validation loss decreased (0.999499 --> 0.997249).  Saving model ...
Validation loss decreased (0.997249 --> 0.995043).  Saving model ...
Validation loss decreased (0.995043 --> 0.993083).  Saving model ...
Validation loss decreased (0.993083 --> 0.991198).  Saving model ...
Validation loss decreased (0.991198 --> 0.989653).  Saving model ...
Validation loss decreased (0.989653 --> 0.988353).  Saving model ...
Validation loss decreased (0.988353 --> 0.986345).  Saving model ...
Validation loss decreased (0.986345 --> 0.984683).  Saving model ...
Validation loss decreased (0.984683 --> 0.982955).  Saving model ...
Validation loss decreased (0.982955 --> 0.980842).  Saving model ...
Validation loss decreased (0.980842 --> 0.979934).  Saving model ...
Validation loss decreased (0.979934 --> 0.977645).  Saving model ...
Validation loss decreased (0.977645 --> 0.976226).  Saving model ...
Validation loss decreased (0.976226 --> 0.975040).  Saving model ...
Validation loss decreased (0.975040 --> 0.973840).  Saving model ...
Validation loss decreased (0.973840 --> 0.972556).  Saving model ...
Validation loss decreased (0.972556 --> 0.971634).  Saving model ...
Validation loss decreased (0.971634 --> 0.971226).  Saving model ...
Validation loss decreased (0.971226 --> 0.970099).  Saving model ...
Validation loss decreased (0.970099 --> 0.969292).  Saving model ...
Validation loss decreased (0.969292 --> 0.968737).  Saving model ...
Validation loss decreased (0.968737 --> 0.968411).  Saving model ...
Validation loss decreased (0.968411 --> 0.967130).  Saving model ...
Validation loss decreased (0.967130 --> 0.966297).  Saving model ...
Validation loss decreased (0.966297 --> 0.964725).  Saving model ...
Validation loss decreased (0.964725 --> 0.963567).  Saving model ...
Validation loss decreased (0.963567 --> 0.962958).  Saving model ...
Validation loss decreased (0.962958 --> 0.962101).  Saving model ...
Validation loss decreased (0.962101 --> 0.961808).  Saving model ...
Validation loss decreased (0.961808 --> 0.960886).  Saving model ...
Validation loss decreased (0.960886 --> 0.959791).  Saving model ...
Validation loss decreased (0.959791 --> 0.959368).  Saving model ...
Validation loss decreased (0.959368 --> 0.958381).  Saving model ...
Validation loss decreased (0.958381 --> 0.957068).  Saving model ...
EarlyStopping counter: 1 out of 3.0
Validation loss decreased (0.957068 --> 0.956602).  Saving model ...
Validation loss decreased (0.956602 --> 0.956275).  Saving model ...
Validation loss decreased (0.956275 --> 0.956034).  Saving model ...
Validation loss decreased (0.956034 --> 0.955474).  Saving model ...
Validation loss decreased (0.955474 --> 0.955198).  Saving model ...
Validation loss decreased (0.955198 --> 0.954562).  Saving model ...
Validation loss decreased (0.954562 --> 0.954259).  Saving model ...
EarlyStopping counter: 1 out of 3.0
EarlyStopping counter: 2 out of 3.0
EarlyStopping counter: 3 out of 3.0
/localscratch/yinan.29785221.0/env/lib/python3.7/site-packages/torch/nn/functional.py:1794: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.
  warnings.warn("nn.functional.tanh is deprecated. Use torch.tanh instead.")
wandb: Waiting for W&B process to finish, PID 205851... (success).
wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: \ 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: | 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: / 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: \ 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: | 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: / 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: \ 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: | 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: / 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb:                                                                                
wandb: Run history:
wandb:     e_F1 ▁▂▃▃▃▄▄▅▅▅▆▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇█████████████
wandb:   e_loss ████▇▇▇▆▆▆▅▅▄▄▄▄▃▃▃▃▃▂▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁
wandb:     t_F1 ▁▂▂▂▂▃▃▃▄▅▄▅▅▅▅▆▆▆▆▆▆▆▆▇▇▇▇▇▇▇▇▇▇▇▇▇▇███
wandb:   t_loss ████▇▇▇▇▆▆▆▆▅▅▅▅▄▄▄▄▄▄▄▃▃▃▃▂▃▂▂▂▂▂▂▂▁▁▁▁
wandb: 
wandb: Run summary:
wandb:     e_F1 55.84481
wandb:   e_loss 0.95461
wandb:     t_F1 71.49441
wandb:   t_loss 0.76162
wandb: 
wandb: Synced 4 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Synced azure-valley-1: https://wandb.ai/yinanazhou/xl_512_bs_8_lr_1e06_es_3_lc_True_nr_True_sr_False_stem_False_lemma_False_repeat_5_fold_1/runs/25sbszb4
wandb: Find logs at: ./wandb/run-20220330_065514-25sbszb4/logs/debug.log
wandb: 

wandb: wandb version 0.12.11 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
2022-03-30 08:21:51.000370: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1
wandb: Tracking run with wandb version 0.12.5
wandb: Syncing run eager-dragon-1
wandb: ⭐️ View project at https://wandb.ai/yinanazhou/xl_512_bs_8_lr_1e06_es_3_lc_True_nr_True_sr_False_stem_False_lemma_False_repeat_5_fold_2
wandb: 🚀 View run at https://wandb.ai/yinanazhou/xl_512_bs_8_lr_1e06_es_3_lc_True_nr_True_sr_False_stem_False_lemma_False_repeat_5_fold_2/runs/2f1dam9y
wandb: Run data is saved locally in /project/6002780/yinan/Thesis_MER_Lyrics/lyric-emotion/wandb/run-20220330_082148-2f1dam9y
wandb: Run `wandb offline` to turn off syncing.

Validation loss decreased (inf --> 1.484410).  Saving model ...
Validation loss decreased (1.484410 --> 1.450298).  Saving model ...
Validation loss decreased (1.450298 --> 1.425774).  Saving model ...
Validation loss decreased (1.425774 --> 1.409124).  Saving model ...
Validation loss decreased (1.409124 --> 1.397033).  Saving model ...
Validation loss decreased (1.397033 --> 1.387924).  Saving model ...
Validation loss decreased (1.387924 --> 1.380849).  Saving model ...
Validation loss decreased (1.380849 --> 1.375523).  Saving model ...
Validation loss decreased (1.375523 --> 1.370795).  Saving model ...
Validation loss decreased (1.370795 --> 1.365886).  Saving model ...
Validation loss decreased (1.365886 --> 1.361777).  Saving model ...
Validation loss decreased (1.361777 --> 1.358029).  Saving model ...
Validation loss decreased (1.358029 --> 1.354147).  Saving model ...
Validation loss decreased (1.354147 --> 1.350374).  Saving model ...
Validation loss decreased (1.350374 --> 1.346162).  Saving model ...
Validation loss decreased (1.346162 --> 1.341932).  Saving model ...
Validation loss decreased (1.341932 --> 1.337584).  Saving model ...
Validation loss decreased (1.337584 --> 1.333167).  Saving model ...
Validation loss decreased (1.333167 --> 1.328959).  Saving model ...
Validation loss decreased (1.328959 --> 1.324492).  Saving model ...
Validation loss decreased (1.324492 --> 1.318717).  Saving model ...
Validation loss decreased (1.318717 --> 1.312414).  Saving model ...
Validation loss decreased (1.312414 --> 1.307080).  Saving model ...
Validation loss decreased (1.307080 --> 1.300782).  Saving model ...
Validation loss decreased (1.300782 --> 1.293885).  Saving model ...
Validation loss decreased (1.293885 --> 1.287157).  Saving model ...
Validation loss decreased (1.287157 --> 1.278271).  Saving model ...
Validation loss decreased (1.278271 --> 1.270715).  Saving model ...
Validation loss decreased (1.270715 --> 1.264211).  Saving model ...
Validation loss decreased (1.264211 --> 1.255932).  Saving model ...
Validation loss decreased (1.255932 --> 1.246800).  Saving model ...
Validation loss decreased (1.246800 --> 1.238391).  Saving model ...
Validation loss decreased (1.238391 --> 1.230897).  Saving model ...
Validation loss decreased (1.230897 --> 1.222942).  Saving model ...
Validation loss decreased (1.222942 --> 1.213074).  Saving model ...
Validation loss decreased (1.213074 --> 1.206119).  Saving model ...
Validation loss decreased (1.206119 --> 1.199107).  Saving model ...
Validation loss decreased (1.199107 --> 1.192662).  Saving model ...
Validation loss decreased (1.192662 --> 1.186685).  Saving model ...
Validation loss decreased (1.186685 --> 1.179297).  Saving model ...
Validation loss decreased (1.179297 --> 1.173271).  Saving model ...
Validation loss decreased (1.173271 --> 1.167696).  Saving model ...
Validation loss decreased (1.167696 --> 1.160171).  Saving model ...
Validation loss decreased (1.160171 --> 1.155291).  Saving model ...
Validation loss decreased (1.155291 --> 1.151160).  Saving model ...
Validation loss decreased (1.151160 --> 1.144097).  Saving model ...
Validation loss decreased (1.144097 --> 1.136298).  Saving model ...
Validation loss decreased (1.136298 --> 1.132761).  Saving model ...
Validation loss decreased (1.132761 --> 1.127525).  Saving model ...
Validation loss decreased (1.127525 --> 1.123203).  Saving model ...
Validation loss decreased (1.123203 --> 1.115769).  Saving model ...
Validation loss decreased (1.115769 --> 1.111766).  Saving model ...
Validation loss decreased (1.111766 --> 1.107357).  Saving model ...
Validation loss decreased (1.107357 --> 1.104094).  Saving model ...
Validation loss decreased (1.104094 --> 1.100588).  Saving model ...
Validation loss decreased (1.100588 --> 1.094360).  Saving model ...
Validation loss decreased (1.094360 --> 1.091575).  Saving model ...
Validation loss decreased (1.091575 --> 1.090433).  Saving model ...
Validation loss decreased (1.090433 --> 1.082258).  Saving model ...
Validation loss decreased (1.082258 --> 1.079083).  Saving model ...
Validation loss decreased (1.079083 --> 1.076554).  Saving model ...
Validation loss decreased (1.076554 --> 1.072486).  Saving model ...
Validation loss decreased (1.072486 --> 1.067144).  Saving model ...
Validation loss decreased (1.067144 --> 1.063153).  Saving model ...
Validation loss decreased (1.063153 --> 1.060008).  Saving model ...
Validation loss decreased (1.060008 --> 1.057093).  Saving model ...
Validation loss decreased (1.057093 --> 1.052843).  Saving model ...
Validation loss decreased (1.052843 --> 1.049157).  Saving model ...
Validation loss decreased (1.049157 --> 1.047244).  Saving model ...
Validation loss decreased (1.047244 --> 1.042811).  Saving model ...
Validation loss decreased (1.042811 --> 1.038398).  Saving model ...
Validation loss decreased (1.038398 --> 1.033525).  Saving model ...
Validation loss decreased (1.033525 --> 1.031030).  Saving model ...
Validation loss decreased (1.031030 --> 1.028393).  Saving model ...
Validation loss decreased (1.028393 --> 1.026723).  Saving model ...
Validation loss decreased (1.026723 --> 1.025911).  Saving model ...
Validation loss decreased (1.025911 --> 1.023629).  Saving model ...
Validation loss decreased (1.023629 --> 1.019811).  Saving model ...
Validation loss decreased (1.019811 --> 1.018061).  Saving model ...
Validation loss decreased (1.018061 --> 1.015819).  Saving model ...
EarlyStopping counter: 1 out of 3.0
Validation loss decreased (1.015819 --> 1.013231).  Saving model ...
EarlyStopping counter: 1 out of 3.0
Validation loss decreased (1.013231 --> 1.012545).  Saving model ...
Validation loss decreased (1.012545 --> 1.006377).  Saving model ...
Validation loss decreased (1.006377 --> 1.002223).  Saving model ...
Validation loss decreased (1.002223 --> 0.999948).  Saving model ...
Validation loss decreased (0.999948 --> 0.997000).  Saving model ...
Validation loss decreased (0.997000 --> 0.995517).  Saving model ...
Validation loss decreased (0.995517 --> 0.994443).  Saving model ...
Validation loss decreased (0.994443 --> 0.992282).  Saving model ...
Validation loss decreased (0.992282 --> 0.989146).  Saving model ...
Validation loss decreased (0.989146 --> 0.988952).  Saving model ...
Validation loss decreased (0.988952 --> 0.987705).  Saving model ...
Validation loss decreased (0.987705 --> 0.985591).  Saving model ...
EarlyStopping counter: 1 out of 3.0
Validation loss decreased (0.985591 --> 0.981440).  Saving model ...
Validation loss decreased (0.981440 --> 0.978959).  Saving model ...
EarlyStopping counter: 1 out of 3.0
Validation loss decreased (0.978959 --> 0.975184).  Saving model ...
Validation loss decreased (0.975184 --> 0.974165).  Saving model ...
Validation loss decreased (0.974165 --> 0.970771).  Saving model ...
EarlyStopping counter: 1 out of 3.0
Validation loss decreased (0.970771 --> 0.968652).  Saving model ...
EarlyStopping counter: 1 out of 3.0
EarlyStopping counter: 2 out of 3.0
Validation loss decreased (0.968652 --> 0.966544).  Saving model ...
Validation loss decreased (0.966544 --> 0.964669).  Saving model ...
EarlyStopping counter: 1 out of 3.0
Validation loss decreased (0.964669 --> 0.964558).  Saving model ...
Validation loss decreased (0.964558 --> 0.963067).  Saving model ...
EarlyStopping counter: 1 out of 3.0
Validation loss decreased (0.963067 --> 0.962313).  Saving model ...
Validation loss decreased (0.962313 --> 0.957630).  Saving model ...
Validation loss decreased (0.957630 --> 0.955134).  Saving model ...
Validation loss decreased (0.955134 --> 0.953038).  Saving model ...
EarlyStopping counter: 1 out of 3.0
EarlyStopping counter: 2 out of 3.0
EarlyStopping counter: 3 out of 3.0
/localscratch/yinan.29785221.0/env/lib/python3.7/site-packages/torch/nn/functional.py:1794: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.
  warnings.warn("nn.functional.tanh is deprecated. Use torch.tanh instead.")
wandb: Waiting for W&B process to finish, PID 210643... (success).
wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: \ 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: | 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: / 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: \ 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: | 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: / 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: \ 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: | 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: / 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb:                                                                                
wandb: Run history:
wandb:     e_F1 ▁▁▃▄▄▅▅▅▅▅▅▆▇▇▇▇▇▇▇▇▇███████████████████
wandb:   e_loss █▇▇▆▆▆▆▆▅▅▅▅▄▄▄▄▃▃▃▃▃▂▂▂▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁
wandb:     t_F1 ▁▂▃▃▃▄▄▄▄▅▅▅▅▆▆▆▆▆▆▆▇▇▇▇▇▇▇▇▇██▇▇███████
wandb:   t_loss █▇▇▇▇▆▆▆▆▆▅▅▅▅▄▄▄▄▄▃▃▃▃▃▃▃▂▃▂▂▂▂▂▂▂▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:     e_F1 60.07609
wandb:   e_loss 0.95344
wandb:     t_F1 67.82794
wandb:   t_loss 0.83565
wandb: 
wandb: Synced 4 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Synced eager-dragon-1: https://wandb.ai/yinanazhou/xl_512_bs_8_lr_1e06_es_3_lc_True_nr_True_sr_False_stem_False_lemma_False_repeat_5_fold_2/runs/2f1dam9y
wandb: Find logs at: ./wandb/run-20220330_082148-2f1dam9y/logs/debug.log
wandb: 

