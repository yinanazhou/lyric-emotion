Unloading StdEnv/2020

Due to MODULEPATH changes, the following have been reloaded:
  1) mii/1.1.1


The following have been reloaded with a version change:
  1) python/3.8.2 => python/3.7.4

Using base prefix '/cvmfs/soft.computecanada.ca/easybuild/software/2017/Core/python/3.7.4'
New python executable in /localscratch/yinan.29019297.0/env/bin/python
Installing setuptools, pip, wheel...
done.
Ignoring pip: markers 'python_version < "3"' don't match your environment
Looking in links: /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/nix/avx2, /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/nix/generic, /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic
Collecting pip
Installing collected packages: pip
  Found existing installation: pip 19.1.1
    Uninstalling pip-19.1.1:
      Successfully uninstalled pip-19.1.1
Successfully installed pip-21.2.3+computecanada
Looking in links: /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/nix/avx2, /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/nix/generic, /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/keras-2.8.0+computecanada-py2.py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/Keras_Preprocessing-1.1.2+computecanada-py3-none-any.whl
Requirement already satisfied: matplotlib in /cvmfs/soft.computecanada.ca/easybuild/software/2017/Core/scipy-stack/2019a/lib/python3.7/site-packages (from -r requirements.txt (line 3)) (3.0.2)
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/nltk-3.6.5+computecanada-py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/scikit_learn-0.22.1+computecanada-cp37-cp37m-linux_x86_64.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/tensorboard-2.3.0+computecanada-py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/tensorboard_plugin_wit-1.7.0+computecanada-py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/tensorflow_gpu-2.3.0+computecanada-cp37-cp37m-linux_x86_64.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/tensorflow_estimator-2.3.0+computecanada-py2.py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/tokenizers-0.5.2+computecanada-cp37-cp37m-linux_x86_64.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/nix/avx2/torch-1.4.0+computecanada-cp37-cp37m-linux_x86_64.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/torchtext-0.6.0+computecanada-py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/torchvision-0.8.2+computecanada-cp37-cp37m-linux_x86_64.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/transformers-2.5.1+computecanada-py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/urllib3-1.26.7+computecanada-py2.py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/joblib-1.1.0+computecanada-py2.py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/click-8.0.4+computecanada-py3-none-any.whl
ERROR: Could not find a version that satisfies the requirement regex>=2021.8.3 (from nltk) (from versions: 2018.1.10+computecanada, 2019.11.1+computecanada, 2020.11.13+computecanada)
ERROR: No matching distribution found for regex>=2021.8.3
Looking in links: /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/nix/avx2, /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/nix/generic, /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic
ERROR: Could not find a version that satisfies the requirement numpy==1.20.0+computacanada (from versions: 1.15.0+computecanada, 1.15.2+computecanada, 1.15.4+computecanada, 1.16.0+computecanada, 1.16.2+computecanada, 1.16.3+computecanada, 1.17.4+computecanada, 1.18.1+computecanada, 1.18.4+computecanada, 1.19.1+computecanada, 1.19.2+computecanada, 1.20.2+computecanada)
ERROR: No matching distribution found for numpy==1.20.0+computacanada
Looking in links: /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/nix/avx2, /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/nix/generic, /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/wandb-0.12.5+computecanada-py2.py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/shortuuid-1.0.1+computecanada-py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/docker_pycreds-0.4.0+computecanada-py2.py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/configparser-5.0.2+computecanada-py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/subprocess32-3.5.4+computecanada-py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/promise-2.3+computecanada-py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/yaspin-2.1.0+computecanada-py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/sentry_sdk-1.5.0+computecanada-py2.py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/psutil-5.7.3+computecanada-cp37-cp37m-linux_x86_64.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/GitPython-3.1.24+computecanada-py3-none-any.whl
Requirement already satisfied: python-dateutil>=2.6.1 in /cvmfs/soft.computecanada.ca/easybuild/software/2017/Core/scipy-stack/2019a/lib/python3.7/site-packages (from wandb) (2.7.5)
Requirement already satisfied: requests<3,>=2.0.0 in /cvmfs/soft.computecanada.ca/easybuild/software/2017/Core/scipy-stack/2019a/lib/python3.7/site-packages (from wandb) (2.21.0)
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/six-1.16.0+computecanada-py2.py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/PyYAML-5.3.1+computecanada-cp37-cp37m-linux_x86_64.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/pathtools-0.1.2+computecanada-py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/click-8.0.4+computecanada-py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/protobuf-3.19.4+computecanada-py2.py3-none-any.whl
Requirement already satisfied: importlib-metadata in /cvmfs/soft.computecanada.ca/easybuild/software/2017/Core/scipy-stack/2019a/lib/python3.7/site-packages (from Click!=8.0.0,>=7.0->wandb) (0.8)
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/gitdb-4.0.9+computecanada-py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/typing_extensions-4.0.1+computecanada-py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/smmap-5.0.0+computecanada-py3-none-any.whl
Requirement already satisfied: certifi>=2017.4.17 in /cvmfs/soft.computecanada.ca/easybuild/software/2017/Core/scipy-stack/2019a/lib/python3.7/site-packages (from requests<3,>=2.0.0->wandb) (2018.11.29)
Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /cvmfs/soft.computecanada.ca/easybuild/software/2017/Core/scipy-stack/2019a/lib/python3.7/site-packages (from requests<3,>=2.0.0->wandb) (3.0.4)
Requirement already satisfied: urllib3<1.25,>=1.21.1 in /cvmfs/soft.computecanada.ca/easybuild/software/2017/Core/scipy-stack/2019a/lib/python3.7/site-packages (from requests<3,>=2.0.0->wandb) (1.24.1)
Requirement already satisfied: idna<2.9,>=2.5 in /cvmfs/soft.computecanada.ca/easybuild/software/2017/Core/scipy-stack/2019a/lib/python3.7/site-packages (from requests<3,>=2.0.0->wandb) (2.8)
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/termcolor-1.1.0+computecanada-py3-none-any.whl
Requirement already satisfied: zipp>=0.3.2 in /cvmfs/soft.computecanada.ca/easybuild/software/2017/Core/scipy-stack/2019a/lib/python3.7/site-packages (from importlib-metadata->Click!=8.0.0,>=7.0->wandb) (0.3.3)
Installing collected packages: smmap, typing-extensions, termcolor, six, gitdb, yaspin, subprocess32, shortuuid, sentry-sdk, PyYAML, psutil, protobuf, promise, pathtools, GitPython, docker-pycreds, configparser, Click, wandb
  Attempting uninstall: six
    Found existing installation: six 1.12.0
    Not uninstalling six at /cvmfs/soft.computecanada.ca/easybuild/software/2017/Core/scipy-stack/2019a/lib/python3.7/site-packages, outside environment /localscratch/yinan.29019297.0/env
    Can't uninstall 'six'. No files were found to uninstall.
Successfully installed Click-8.0.4+computecanada GitPython-3.1.24+computecanada PyYAML-5.3.1+computecanada configparser-5.0.2+computecanada docker-pycreds-0.4.0+computecanada gitdb-4.0.9+computecanada pathtools-0.1.2+computecanada promise-2.3+computecanada protobuf-3.19.4+computecanada psutil-5.7.3+computecanada sentry-sdk-1.5.0+computecanada shortuuid-1.0.1+computecanada six-1.16.0+computecanada smmap-5.0.0+computecanada subprocess32-3.5.4+computecanada termcolor-1.1.0+computecanada typing-extensions-4.0.1+computecanada wandb-0.12.5+computecanada yaspin-2.1.0+computecanada
Looking in links: /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/nix/avx2, /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/nix/generic, /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic
ERROR: Could not find a version that satisfies the requirement sagemaker (from versions: none)
ERROR: No matching distribution found for sagemaker
Looking in links: /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/nix/avx2, /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/nix/generic, /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/torch-1.9.1+computecanada-cp37-cp37m-linux_x86_64.whl
Requirement already satisfied: typing-extensions in /localscratch/yinan.29019297.0/env/lib/python3.7/site-packages (from torch) (4.0.1+computecanada)
Installing collected packages: torch
Successfully installed torch-1.9.1+computecanada
Looking in links: /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/nix/avx2, /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/nix/generic, /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/transformers-2.5.1+computecanada-py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/tokenizers-0.5.2+computecanada-cp37-cp37m-linux_x86_64.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/boto3-1.21.14+computecanada-py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/filelock-3.4.2+computecanada-py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/tqdm-4.63.0+computecanada-py2.py3-none-any.whl
Requirement already satisfied: requests in /cvmfs/soft.computecanada.ca/easybuild/software/2017/Core/scipy-stack/2019a/lib/python3.7/site-packages (from transformers==2.5.1+computecanada) (2.21.0)
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/regex-2020.11.13+computecanada-cp37-cp37m-linux_x86_64.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/sentencepiece-0.1.91+computecanada-cp37-cp37m-linux_x86_64.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/sacremoses-0.0.46+computecanada-py3-none-any.whl
Requirement already satisfied: numpy in /cvmfs/soft.computecanada.ca/easybuild/software/2017/Core/scipy-stack/2019a/lib/python3.7/site-packages (from transformers==2.5.1+computecanada) (1.16.0)
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/jmespath-0.10.0+computecanada-py2.py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/s3transfer-0.5.1+computecanada-py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/botocore-1.24.14+computecanada-py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/urllib3-1.26.8+computecanada-py2.py3-none-any.whl
Requirement already satisfied: python-dateutil<3.0.0,>=2.1 in /cvmfs/soft.computecanada.ca/easybuild/software/2017/Core/scipy-stack/2019a/lib/python3.7/site-packages (from botocore<1.25.0,>=1.24.14->boto3->transformers==2.5.1+computecanada) (2.7.5)
Requirement already satisfied: six>=1.5 in /localscratch/yinan.29019297.0/env/lib/python3.7/site-packages (from python-dateutil<3.0.0,>=2.1->botocore<1.25.0,>=1.24.14->boto3->transformers==2.5.1+computecanada) (1.16.0+computecanada)
Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /cvmfs/soft.computecanada.ca/easybuild/software/2017/Core/scipy-stack/2019a/lib/python3.7/site-packages (from requests->transformers==2.5.1+computecanada) (3.0.4)
Requirement already satisfied: certifi>=2017.4.17 in /cvmfs/soft.computecanada.ca/easybuild/software/2017/Core/scipy-stack/2019a/lib/python3.7/site-packages (from requests->transformers==2.5.1+computecanada) (2018.11.29)
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/requests-2.27.1+computecanada-py2.py3-none-any.whl
Requirement already satisfied: idna<4,>=2.5 in /cvmfs/soft.computecanada.ca/easybuild/software/2017/Core/scipy-stack/2019a/lib/python3.7/site-packages (from requests->transformers==2.5.1+computecanada) (2.8)
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/charset_normalizer-2.0.12+computecanada-py3-none-any.whl
Requirement already satisfied: click in /localscratch/yinan.29019297.0/env/lib/python3.7/site-packages (from sacremoses->transformers==2.5.1+computecanada) (8.0.4+computecanada)
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/joblib-1.1.0+computecanada-py2.py3-none-any.whl
Requirement already satisfied: importlib-metadata in /cvmfs/soft.computecanada.ca/easybuild/software/2017/Core/scipy-stack/2019a/lib/python3.7/site-packages (from click->sacremoses->transformers==2.5.1+computecanada) (0.8)
Requirement already satisfied: zipp>=0.3.2 in /cvmfs/soft.computecanada.ca/easybuild/software/2017/Core/scipy-stack/2019a/lib/python3.7/site-packages (from importlib-metadata->click->sacremoses->transformers==2.5.1+computecanada) (0.3.3)
Installing collected packages: urllib3, jmespath, botocore, tqdm, s3transfer, regex, joblib, charset-normalizer, tokenizers, sentencepiece, sacremoses, requests, filelock, boto3, transformers
  Attempting uninstall: urllib3
    Found existing installation: urllib3 1.24.1
    Not uninstalling urllib3 at /cvmfs/soft.computecanada.ca/easybuild/software/2017/Core/scipy-stack/2019a/lib/python3.7/site-packages, outside environment /localscratch/yinan.29019297.0/env
    Can't uninstall 'urllib3'. No files were found to uninstall.
  Attempting uninstall: requests
    Found existing installation: requests 2.21.0
    Not uninstalling requests at /cvmfs/soft.computecanada.ca/easybuild/software/2017/Core/scipy-stack/2019a/lib/python3.7/site-packages, outside environment /localscratch/yinan.29019297.0/env
    Can't uninstall 'requests'. No files were found to uninstall.
Successfully installed boto3-1.21.14+computecanada botocore-1.24.14+computecanada charset-normalizer-2.0.12+computecanada filelock-3.4.2+computecanada jmespath-0.10.0+computecanada joblib-1.1.0+computecanada regex-2020.11.13+computecanada requests-2.27.1+computecanada s3transfer-0.5.1+computecanada sacremoses-0.0.46+computecanada sentencepiece-0.1.91+computecanada tokenizers-0.5.2+computecanada tqdm-4.63.0+computecanada transformers-2.5.1+computecanada urllib3-1.26.8+computecanada
Looking in links: /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/nix/avx2, /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/nix/generic, /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/tensorflow_gpu-2.3.0+computecanada-cp37-cp37m-linux_x86_64.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/astunparse-1.6.3+computecanada-py2.py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/wrapt-1.11.2+computecanada-cp37-cp37m-linux_x86_64.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/gast-0.3.3+computecanada-py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/grpcio-1.38.0+computecanada-cp37-cp37m-linux_x86_64.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/absl_py-1.0.0+computecanada-py3-none-any.whl
Requirement already satisfied: six>=1.12.0 in /localscratch/yinan.29019297.0/env/lib/python3.7/site-packages (from tensorflow_gpu==2.3.0+computecanada) (1.16.0+computecanada)
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/opt_einsum-3.3.0+computecanada-py3-none-any.whl
Requirement already satisfied: numpy<1.19.0,>=1.16.0 in /cvmfs/soft.computecanada.ca/easybuild/software/2017/Core/scipy-stack/2019a/lib/python3.7/site-packages (from tensorflow_gpu==2.3.0+computecanada) (1.16.0)
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/nix/generic/scipy-1.4.1+computecanada-cp37-cp37m-linux_x86_64.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/nix/avx2/h5py-2.10.0+computecanada-cp37-cp37m-linux_x86_64.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/tensorboard-2.8.0+computecanada-py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/tensorflow_estimator-2.3.0+computecanada-py2.py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/Keras_Preprocessing-1.1.2+computecanada-py3-none-any.whl
Requirement already satisfied: wheel>=0.26 in /localscratch/yinan.29019297.0/env/lib/python3.7/site-packages (from tensorflow_gpu==2.3.0+computecanada) (0.33.4)
Requirement already satisfied: termcolor>=1.1.0 in /localscratch/yinan.29019297.0/env/lib/python3.7/site-packages (from tensorflow_gpu==2.3.0+computecanada) (1.1.0+computecanada)
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/google_pasta-0.2.0+computecanada-py3-none-any.whl
Requirement already satisfied: protobuf>=3.9.2 in /localscratch/yinan.29019297.0/env/lib/python3.7/site-packages (from tensorflow_gpu==2.3.0+computecanada) (3.19.4+computecanada)
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/Werkzeug-2.0.3+computecanada-py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/google_auth_oauthlib-0.4.6+computecanada-py2.py3-none-any.whl
Requirement already satisfied: requests<3,>=2.21.0 in /localscratch/yinan.29019297.0/env/lib/python3.7/site-packages (from tensorboard<3,>=2.3.0->tensorflow_gpu==2.3.0+computecanada) (2.27.1+computecanada)
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/Markdown-3.3.6+computecanada-py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/tensorboard_data_server-0.6.1+computecanada-py3-none-linux_x86_64.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/google_auth-2.3.3+computecanada-py2.py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/tensorboard_plugin_wit-1.8.0+computecanada-py3-none-any.whl
Requirement already satisfied: setuptools>=41.0.0 in /localscratch/yinan.29019297.0/env/lib/python3.7/site-packages (from tensorboard<3,>=2.3.0->tensorflow_gpu==2.3.0+computecanada) (41.0.1)
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/cachetools-4.2.4+computecanada-py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/rsa-4.8+computecanada-py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/pyasn1_modules-0.2.8+computecanada-py2.py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/requests_oauthlib-1.3.0+computecanada-py2.py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/importlib_metadata-4.10.1+computecanada-py3-none-any.whl
Requirement already satisfied: typing-extensions>=3.6.4 in /localscratch/yinan.29019297.0/env/lib/python3.7/site-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard<3,>=2.3.0->tensorflow_gpu==2.3.0+computecanada) (4.0.1+computecanada)
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/zipp-3.7.0+computecanada-py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/pyasn1-0.4.8+computecanada-py2.py3-none-any.whl
Requirement already satisfied: idna<4,>=2.5 in /cvmfs/soft.computecanada.ca/easybuild/software/2017/Core/scipy-stack/2019a/lib/python3.7/site-packages (from requests<3,>=2.21.0->tensorboard<3,>=2.3.0->tensorflow_gpu==2.3.0+computecanada) (2.8)
Requirement already satisfied: certifi>=2017.4.17 in /cvmfs/soft.computecanada.ca/easybuild/software/2017/Core/scipy-stack/2019a/lib/python3.7/site-packages (from requests<3,>=2.21.0->tensorboard<3,>=2.3.0->tensorflow_gpu==2.3.0+computecanada) (2018.11.29)
Requirement already satisfied: charset-normalizer~=2.0.0 in /localscratch/yinan.29019297.0/env/lib/python3.7/site-packages (from requests<3,>=2.21.0->tensorboard<3,>=2.3.0->tensorflow_gpu==2.3.0+computecanada) (2.0.12+computecanada)
Requirement already satisfied: urllib3<1.27,>=1.21.1 in /localscratch/yinan.29019297.0/env/lib/python3.7/site-packages (from requests<3,>=2.21.0->tensorboard<3,>=2.3.0->tensorflow_gpu==2.3.0+computecanada) (1.26.8+computecanada)
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/oauthlib-3.1.1+computecanada-py2.py3-none-any.whl
Installing collected packages: pyasn1, zipp, rsa, pyasn1-modules, oauthlib, cachetools, requests-oauthlib, importlib-metadata, google-auth, werkzeug, tensorboard-plugin-wit, tensorboard-data-server, markdown, grpcio, google-auth-oauthlib, absl-py, wrapt, tensorflow-estimator, tensorboard, scipy, opt-einsum, keras-preprocessing, h5py, google-pasta, gast, astunparse, tensorflow-gpu
  Attempting uninstall: pyasn1
    Found existing installation: pyasn1 0.4.3
    Not uninstalling pyasn1 at /cvmfs/soft.computecanada.ca/easybuild/software/2017/Core/scipy-stack/2019a/lib/python3.7/site-packages, outside environment /localscratch/yinan.29019297.0/env
    Can't uninstall 'pyasn1'. No files were found to uninstall.
  Attempting uninstall: zipp
    Found existing installation: zipp 0.3.3
    Not uninstalling zipp at /cvmfs/soft.computecanada.ca/easybuild/software/2017/Core/scipy-stack/2019a/lib/python3.7/site-packages, outside environment /localscratch/yinan.29019297.0/env
    Can't uninstall 'zipp'. No files were found to uninstall.
  Attempting uninstall: importlib-metadata
    Found existing installation: importlib-metadata 0.8
    Not uninstalling importlib-metadata at /cvmfs/soft.computecanada.ca/easybuild/software/2017/Core/scipy-stack/2019a/lib/python3.7/site-packages, outside environment /localscratch/yinan.29019297.0/env
    Can't uninstall 'importlib-metadata'. No files were found to uninstall.
  Attempting uninstall: scipy
    Found existing installation: scipy 1.2.0
    Not uninstalling scipy at /cvmfs/soft.computecanada.ca/easybuild/software/2017/Core/scipy-stack/2019a/lib/python3.7/site-packages, outside environment /localscratch/yinan.29019297.0/env
    Can't uninstall 'scipy'. No files were found to uninstall.
Successfully installed absl-py-1.0.0+computecanada astunparse-1.6.3+computecanada cachetools-4.2.4+computecanada gast-0.3.3+computecanada google-auth-2.3.3+computecanada google-auth-oauthlib-0.4.6+computecanada google-pasta-0.2.0+computecanada grpcio-1.38.0+computecanada h5py-2.10.0+computecanada importlib-metadata-4.10.1+computecanada keras-preprocessing-1.1.2+computecanada markdown-3.3.6+computecanada oauthlib-3.1.1+computecanada opt-einsum-3.3.0+computecanada pyasn1-0.4.8+computecanada pyasn1-modules-0.2.8+computecanada requests-oauthlib-1.3.0+computecanada rsa-4.8+computecanada scipy-1.4.1+computecanada tensorboard-2.8.0+computecanada tensorboard-data-server-0.6.1+computecanada tensorboard-plugin-wit-1.8.0+computecanada tensorflow-estimator-2.3.0+computecanada tensorflow-gpu-2.3.0+computecanada werkzeug-2.0.3+computecanada wrapt-1.11.2+computecanada zipp-3.7.0+computecanada
Looking in links: /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/nix/avx2, /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/nix/generic, /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/keras-2.8.0+computecanada-py2.py3-none-any.whl
Installing collected packages: Keras
Successfully installed Keras-2.8.0+computecanada
Looking in links: /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/nix/avx2, /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/nix/generic, /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/urllib3-1.26.7+computecanada-py2.py3-none-any.whl
Installing collected packages: urllib3
  Attempting uninstall: urllib3
    Found existing installation: urllib3 1.26.8+computecanada
    Uninstalling urllib3-1.26.8+computecanada:
      Successfully uninstalled urllib3-1.26.8+computecanada
Successfully installed urllib3-1.26.7+computecanada
Looking in links: /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/nix/avx2, /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/nix/generic, /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/nltk-3.7+computecanada-py3-none-any.whl
Requirement already satisfied: joblib in /localscratch/yinan.29019297.0/env/lib/python3.7/site-packages (from nltk) (1.1.0+computecanada)
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/nltk-3.6.5+computecanada-py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/nltk-3.6.3+computecanada-py3-none-any.whl
Requirement already satisfied: regex in /localscratch/yinan.29019297.0/env/lib/python3.7/site-packages (from nltk) (2020.11.13+computecanada)
Requirement already satisfied: tqdm in /localscratch/yinan.29019297.0/env/lib/python3.7/site-packages (from nltk) (4.63.0+computecanada)
Requirement already satisfied: click in /localscratch/yinan.29019297.0/env/lib/python3.7/site-packages (from nltk) (8.0.4+computecanada)
Requirement already satisfied: importlib-metadata in /localscratch/yinan.29019297.0/env/lib/python3.7/site-packages (from click->nltk) (4.10.1+computecanada)
Requirement already satisfied: typing-extensions>=3.6.4 in /localscratch/yinan.29019297.0/env/lib/python3.7/site-packages (from importlib-metadata->click->nltk) (4.0.1+computecanada)
Requirement already satisfied: zipp>=0.5 in /localscratch/yinan.29019297.0/env/lib/python3.7/site-packages (from importlib-metadata->click->nltk) (3.7.0+computecanada)
Installing collected packages: nltk
Successfully installed nltk-3.6.3+computecanada
Looking in links: /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/nix/avx2, /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/nix/generic, /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/scikit_learn-0.22.1+computecanada-cp37-cp37m-linux_x86_64.whl
Requirement already satisfied: numpy>=1.11.0 in /cvmfs/soft.computecanada.ca/easybuild/software/2017/Core/scipy-stack/2019a/lib/python3.7/site-packages (from scikit-learn==0.22.1) (1.16.0)
Requirement already satisfied: scipy>=0.17.0 in /localscratch/yinan.29019297.0/env/lib/python3.7/site-packages (from scikit-learn==0.22.1) (1.4.1+computecanada)
Requirement already satisfied: joblib>=0.11 in /localscratch/yinan.29019297.0/env/lib/python3.7/site-packages (from scikit-learn==0.22.1) (1.1.0+computecanada)
Installing collected packages: scikit-learn
Successfully installed scikit-learn-0.22.1+computecanada
Looking in links: /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/nix/avx2, /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/nix/generic, /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic
Requirement already satisfied: tokenizers==0.5.2 in /localscratch/yinan.29019297.0/env/lib/python3.7/site-packages (0.5.2+computecanada)
wandb: Appending key for api.wandb.ai to your netrc file: /home/yinan/.netrc
Starting Task
2022-03-18 18:45:44.640250: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1
[nltk_data] Downloading package stopwords to /home/yinan/nltk_data...
[nltk_data]   Package stopwords is already up-to-date!
[nltk_data] Downloading package wordnet to /home/yinan/nltk_data...
[nltk_data]   Package wordnet is already up-to-date!
wandb: Currently logged in as: yinanazhou (use `wandb login --relogin` to force relogin)
wandb: wandb version 0.12.11 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
2022-03-18 18:45:58.887421: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1
wandb: Tracking run with wandb version 0.12.5
wandb: Syncing run gallant-energy-2
wandb: ⭐️ View project at https://wandb.ai/yinanazhou/xl_512_bs_8_lr_1e06_es_10_lc_False_nr_False_sr_False_stem_False_lemma_True_repeat_1_fold_1
wandb: 🚀 View run at https://wandb.ai/yinanazhou/xl_512_bs_8_lr_1e06_es_10_lc_False_nr_False_sr_False_stem_False_lemma_True_repeat_1_fold_1/runs/3e8qpfxt
wandb: Run data is saved locally in /project/6002780/yinan/Thesis_MER_Lyrics/lyric-emotion/wandb/run-20220318_184556-3e8qpfxt
wandb: Run `wandb offline` to turn off syncing.

Validation loss decreased (inf --> 1.432546).  Saving model ...
Validation loss decreased (1.432546 --> 1.413126).  Saving model ...
Validation loss decreased (1.413126 --> 1.396755).  Saving model ...
Validation loss decreased (1.396755 --> 1.383684).  Saving model ...
Validation loss decreased (1.383684 --> 1.373420).  Saving model ...
Validation loss decreased (1.373420 --> 1.365059).  Saving model ...
Validation loss decreased (1.365059 --> 1.357237).  Saving model ...
Validation loss decreased (1.357237 --> 1.350860).  Saving model ...
Validation loss decreased (1.350860 --> 1.345819).  Saving model ...
Validation loss decreased (1.345819 --> 1.339794).  Saving model ...
Validation loss decreased (1.339794 --> 1.333211).  Saving model ...
Validation loss decreased (1.333211 --> 1.327532).  Saving model ...
Validation loss decreased (1.327532 --> 1.320957).  Saving model ...
Validation loss decreased (1.320957 --> 1.315761).  Saving model ...
Validation loss decreased (1.315761 --> 1.309923).  Saving model ...
Validation loss decreased (1.309923 --> 1.303239).  Saving model ...
Validation loss decreased (1.303239 --> 1.297425).  Saving model ...
Validation loss decreased (1.297425 --> 1.291823).  Saving model ...
Validation loss decreased (1.291823 --> 1.284710).  Saving model ...
Validation loss decreased (1.284710 --> 1.276107).  Saving model ...
Validation loss decreased (1.276107 --> 1.268505).  Saving model ...
Validation loss decreased (1.268505 --> 1.261320).  Saving model ...
Validation loss decreased (1.261320 --> 1.255386).  Saving model ...
Validation loss decreased (1.255386 --> 1.245741).  Saving model ...
Validation loss decreased (1.245741 --> 1.236896).  Saving model ...
Validation loss decreased (1.236896 --> 1.229123).  Saving model ...
Validation loss decreased (1.229123 --> 1.221927).  Saving model ...
Validation loss decreased (1.221927 --> 1.215503).  Saving model ...
Validation loss decreased (1.215503 --> 1.208406).  Saving model ...
Validation loss decreased (1.208406 --> 1.202564).  Saving model ...
Validation loss decreased (1.202564 --> 1.195145).  Saving model ...
Validation loss decreased (1.195145 --> 1.190457).  Saving model ...
Validation loss decreased (1.190457 --> 1.188558).  Saving model ...
Validation loss decreased (1.188558 --> 1.181519).  Saving model ...
Validation loss decreased (1.181519 --> 1.174924).  Saving model ...
Validation loss decreased (1.174924 --> 1.169742).  Saving model ...
Validation loss decreased (1.169742 --> 1.167609).  Saving model ...
Validation loss decreased (1.167609 --> 1.159269).  Saving model ...
Validation loss decreased (1.159269 --> 1.155949).  Saving model ...
Validation loss decreased (1.155949 --> 1.150369).  Saving model ...
Validation loss decreased (1.150369 --> 1.144295).  Saving model ...
Validation loss decreased (1.144295 --> 1.139610).  Saving model ...
Validation loss decreased (1.139610 --> 1.136293).  Saving model ...
Validation loss decreased (1.136293 --> 1.132175).  Saving model ...
Validation loss decreased (1.132175 --> 1.128546).  Saving model ...
Validation loss decreased (1.128546 --> 1.122662).  Saving model ...
Validation loss decreased (1.122662 --> 1.118791).  Saving model ...
Validation loss decreased (1.118791 --> 1.114800).  Saving model ...
Validation loss decreased (1.114800 --> 1.109543).  Saving model ...
Validation loss decreased (1.109543 --> 1.107728).  Saving model ...
Validation loss decreased (1.107728 --> 1.101190).  Saving model ...
Validation loss decreased (1.101190 --> 1.097861).  Saving model ...
Validation loss decreased (1.097861 --> 1.095947).  Saving model ...
Validation loss decreased (1.095947 --> 1.091612).  Saving model ...
Validation loss decreased (1.091612 --> 1.091463).  Saving model ...
Validation loss decreased (1.091463 --> 1.087062).  Saving model ...
Validation loss decreased (1.087062 --> 1.083768).  Saving model ...
Validation loss decreased (1.083768 --> 1.080771).  Saving model ...
Validation loss decreased (1.080771 --> 1.077325).  Saving model ...
Validation loss decreased (1.077325 --> 1.072794).  Saving model ...
Validation loss decreased (1.072794 --> 1.069951).  Saving model ...
Validation loss decreased (1.069951 --> 1.067529).  Saving model ...
Validation loss decreased (1.067529 --> 1.064658).  Saving model ...
Validation loss decreased (1.064658 --> 1.063071).  Saving model ...
EarlyStopping counter: 1 out of 10.0
Validation loss decreased (1.063071 --> 1.059871).  Saving model ...
Validation loss decreased (1.059871 --> 1.055762).  Saving model ...
Validation loss decreased (1.055762 --> 1.055532).  Saving model ...
Validation loss decreased (1.055532 --> 1.052331).  Saving model ...
Validation loss decreased (1.052331 --> 1.048086).  Saving model ...
Validation loss decreased (1.048086 --> 1.046424).  Saving model ...
Validation loss decreased (1.046424 --> 1.043945).  Saving model ...
Validation loss decreased (1.043945 --> 1.043592).  Saving model ...
Validation loss decreased (1.043592 --> 1.038909).  Saving model ...
Validation loss decreased (1.038909 --> 1.038774).  Saving model ...
Validation loss decreased (1.038774 --> 1.037030).  Saving model ...
Validation loss decreased (1.037030 --> 1.036792).  Saving model ...
Validation loss decreased (1.036792 --> 1.033075).  Saving model ...
Validation loss decreased (1.033075 --> 1.031138).  Saving model ...
Validation loss decreased (1.031138 --> 1.027383).  Saving model ...
Validation loss decreased (1.027383 --> 1.027307).  Saving model ...
Validation loss decreased (1.027307 --> 1.024689).  Saving model ...
EarlyStopping counter: 1 out of 10.0
Validation loss decreased (1.024689 --> 1.021918).  Saving model ...
Validation loss decreased (1.021918 --> 1.021314).  Saving model ...
Validation loss decreased (1.021314 --> 1.017864).  Saving model ...
Validation loss decreased (1.017864 --> 1.017600).  Saving model ...
EarlyStopping counter: 1 out of 10.0
Validation loss decreased (1.017600 --> 1.015980).  Saving model ...
EarlyStopping counter: 1 out of 10.0
Validation loss decreased (1.015980 --> 1.013767).  Saving model ...
Validation loss decreased (1.013767 --> 1.012502).  Saving model ...
Validation loss decreased (1.012502 --> 1.009174).  Saving model ...
EarlyStopping counter: 1 out of 10.0
EarlyStopping counter: 2 out of 10.0
Validation loss decreased (1.009174 --> 1.007474).  Saving model ...
EarlyStopping counter: 1 out of 10.0
Validation loss decreased (1.007474 --> 1.006743).  Saving model ...
Validation loss decreased (1.006743 --> 1.006419).  Saving model ...
EarlyStopping counter: 1 out of 10.0
Validation loss decreased (1.006419 --> 1.005210).  Saving model ...
Validation loss decreased (1.005210 --> 1.004337).  Saving model ...
Validation loss decreased (1.004337 --> 1.004010).  Saving model ...
EarlyStopping counter: 1 out of 10.0
EarlyStopping counter: 2 out of 10.0
Validation loss decreased (1.004010 --> 1.003118).  Saving model ...
EarlyStopping counter: 1 out of 10.0
Validation loss decreased (1.003118 --> 1.001800).  Saving model ...
Validation loss decreased (1.001800 --> 0.997945).  Saving model ...
Validation loss decreased (0.997945 --> 0.996836).  Saving model ...
EarlyStopping counter: 1 out of 10.0
Validation loss decreased (0.996836 --> 0.996739).  Saving model ...
Validation loss decreased (0.996739 --> 0.995916).  Saving model ...
EarlyStopping counter: 1 out of 10.0
Validation loss decreased (0.995916 --> 0.995910).  Saving model ...
Validation loss decreased (0.995910 --> 0.994420).  Saving model ...
Validation loss decreased (0.994420 --> 0.994344).  Saving model ...
EarlyStopping counter: 1 out of 10.0
EarlyStopping counter: 2 out of 10.0
EarlyStopping counter: 3 out of 10.0
EarlyStopping counter: 4 out of 10.0
EarlyStopping counter: 5 out of 10.0
EarlyStopping counter: 6 out of 10.0
EarlyStopping counter: 7 out of 10.0
EarlyStopping counter: 8 out of 10.0
EarlyStopping counter: 9 out of 10.0
Validation loss decreased (0.994344 --> 0.993220).  Saving model ...
EarlyStopping counter: 1 out of 10.0
EarlyStopping counter: 2 out of 10.0
EarlyStopping counter: 3 out of 10.0
EarlyStopping counter: 4 out of 10.0
EarlyStopping counter: 5 out of 10.0
EarlyStopping counter: 6 out of 10.0
Validation loss decreased (0.993220 --> 0.992512).  Saving model ...
EarlyStopping counter: 1 out of 10.0
EarlyStopping counter: 2 out of 10.0
EarlyStopping counter: 3 out of 10.0
EarlyStopping counter: 4 out of 10.0
EarlyStopping counter: 5 out of 10.0
EarlyStopping counter: 6 out of 10.0
EarlyStopping counter: 7 out of 10.0
EarlyStopping counter: 8 out of 10.0
EarlyStopping counter: 9 out of 10.0
EarlyStopping counter: 10 out of 10.0
/localscratch/yinan.29019297.0/env/lib/python3.7/site-packages/torch/nn/functional.py:1794: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.
  warnings.warn("nn.functional.tanh is deprecated. Use torch.tanh instead.")
/localscratch/yinan.29019297.0/env/lib/python3.7/site-packages/transformers/optimization.py:155: UserWarning: This overload of add_ is deprecated:
	add_(Number alpha, Tensor other)
Consider using one of the following signatures instead:
	add_(Tensor other, *, Number alpha) (Triggered internally at  ../torch/csrc/utils/python_arg_parser.cpp:1025.)
  exp_avg.mul_(beta1).add_(1.0 - beta1, grad)
wandb: Waiting for W&B process to finish, PID 213650... (success).
wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: \ 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: | 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: / 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: \ 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: | 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: / 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: \ 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: | 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: / 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb:                                                                                
wandb: Run history:
wandb:     e_F1 ▁▂▃▄▅▅▅▆▆▆▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇███████████████
wandb:   e_loss ██▇▇▆▆▅▅▄▄▄▃▃▃▃▃▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:     t_F1 ▁▂▂▃▃▄▄▅▅▅▅▅▅▅▅▆▆▆▆▆▆▆▆▇▇▇▇▇▇▇▇█▇▇██████
wandb:   t_loss ██▇▇▇▆▆▆▅▅▅▅▅▄▄▄▄▄▃▃▃▃▃▃▃▂▂▂▂▂▂▂▂▂▂▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:     e_F1 59.29511
wandb:   e_loss 0.99655
wandb:     t_F1 75.6555
wandb:   t_loss 0.67576
wandb: 
wandb: Synced 4 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Synced gallant-energy-2: https://wandb.ai/yinanazhou/xl_512_bs_8_lr_1e06_es_10_lc_False_nr_False_sr_False_stem_False_lemma_True_repeat_1_fold_1/runs/3e8qpfxt
wandb: Find logs at: ./wandb/run-20220318_184556-3e8qpfxt/logs/debug.log
wandb: 

wandb: wandb version 0.12.11 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
2022-03-18 20:19:17.258013: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1
wandb: Tracking run with wandb version 0.12.5
wandb: Syncing run stellar-wood-2
wandb: ⭐️ View project at https://wandb.ai/yinanazhou/xl_512_bs_8_lr_1e06_es_10_lc_False_nr_False_sr_False_stem_False_lemma_True_repeat_1_fold_2
wandb: 🚀 View run at https://wandb.ai/yinanazhou/xl_512_bs_8_lr_1e06_es_10_lc_False_nr_False_sr_False_stem_False_lemma_True_repeat_1_fold_2/runs/b388pefx
wandb: Run data is saved locally in /project/6002780/yinan/Thesis_MER_Lyrics/lyric-emotion/wandb/run-20220318_201913-b388pefx
wandb: Run `wandb offline` to turn off syncing.

Validation loss decreased (inf --> 1.612664).  Saving model ...
Validation loss decreased (1.612664 --> 1.538383).  Saving model ...
Validation loss decreased (1.538383 --> 1.485424).  Saving model ...
Validation loss decreased (1.485424 --> 1.449335).  Saving model ...
Validation loss decreased (1.449335 --> 1.420097).  Saving model ...
Validation loss decreased (1.420097 --> 1.401210).  Saving model ...
Validation loss decreased (1.401210 --> 1.387357).  Saving model ...
Validation loss decreased (1.387357 --> 1.376752).  Saving model ...
Validation loss decreased (1.376752 --> 1.368832).  Saving model ...
Validation loss decreased (1.368832 --> 1.361469).  Saving model ...
Validation loss decreased (1.361469 --> 1.353787).  Saving model ...
Validation loss decreased (1.353787 --> 1.346308).  Saving model ...
Validation loss decreased (1.346308 --> 1.339052).  Saving model ...
Validation loss decreased (1.339052 --> 1.331343).  Saving model ...
Validation loss decreased (1.331343 --> 1.321884).  Saving model ...
Validation loss decreased (1.321884 --> 1.314427).  Saving model ...
Validation loss decreased (1.314427 --> 1.306767).  Saving model ...
Validation loss decreased (1.306767 --> 1.299340).  Saving model ...
Validation loss decreased (1.299340 --> 1.293447).  Saving model ...
Validation loss decreased (1.293447 --> 1.285427).  Saving model ...
Validation loss decreased (1.285427 --> 1.275975).  Saving model ...
Validation loss decreased (1.275975 --> 1.265124).  Saving model ...
Validation loss decreased (1.265124 --> 1.254968).  Saving model ...
Validation loss decreased (1.254968 --> 1.245609).  Saving model ...
Validation loss decreased (1.245609 --> 1.236208).  Saving model ...
Validation loss decreased (1.236208 --> 1.228760).  Saving model ...
Validation loss decreased (1.228760 --> 1.221412).  Saving model ...
Validation loss decreased (1.221412 --> 1.212929).  Saving model ...
Validation loss decreased (1.212929 --> 1.204816).  Saving model ...
Validation loss decreased (1.204816 --> 1.196430).  Saving model ...
Validation loss decreased (1.196430 --> 1.189125).  Saving model ...
Validation loss decreased (1.189125 --> 1.181410).  Saving model ...
Validation loss decreased (1.181410 --> 1.175305).  Saving model ...
Validation loss decreased (1.175305 --> 1.168730).  Saving model ...
Validation loss decreased (1.168730 --> 1.160989).  Saving model ...
Validation loss decreased (1.160989 --> 1.154904).  Saving model ...
Validation loss decreased (1.154904 --> 1.149386).  Saving model ...
Validation loss decreased (1.149386 --> 1.143001).  Saving model ...
Validation loss decreased (1.143001 --> 1.136588).  Saving model ...
Validation loss decreased (1.136588 --> 1.130710).  Saving model ...
Validation loss decreased (1.130710 --> 1.122993).  Saving model ...
Validation loss decreased (1.122993 --> 1.115377).  Saving model ...
Validation loss decreased (1.115377 --> 1.108971).  Saving model ...
Validation loss decreased (1.108971 --> 1.104658).  Saving model ...
Validation loss decreased (1.104658 --> 1.099302).  Saving model ...
Validation loss decreased (1.099302 --> 1.094478).  Saving model ...
Validation loss decreased (1.094478 --> 1.089963).  Saving model ...
Validation loss decreased (1.089963 --> 1.088354).  Saving model ...
Validation loss decreased (1.088354 --> 1.082090).  Saving model ...
Validation loss decreased (1.082090 --> 1.077773).  Saving model ...
Validation loss decreased (1.077773 --> 1.071061).  Saving model ...
Validation loss decreased (1.071061 --> 1.066500).  Saving model ...
Validation loss decreased (1.066500 --> 1.059529).  Saving model ...
Validation loss decreased (1.059529 --> 1.055019).  Saving model ...
Validation loss decreased (1.055019 --> 1.051905).  Saving model ...
Validation loss decreased (1.051905 --> 1.048203).  Saving model ...
Validation loss decreased (1.048203 --> 1.042068).  Saving model ...
Validation loss decreased (1.042068 --> 1.037729).  Saving model ...
Validation loss decreased (1.037729 --> 1.037426).  Saving model ...
Validation loss decreased (1.037426 --> 1.034090).  Saving model ...
Validation loss decreased (1.034090 --> 1.032153).  Saving model ...
Validation loss decreased (1.032153 --> 1.029215).  Saving model ...
Validation loss decreased (1.029215 --> 1.023333).  Saving model ...
Validation loss decreased (1.023333 --> 1.018559).  Saving model ...
Validation loss decreased (1.018559 --> 1.012688).  Saving model ...
Validation loss decreased (1.012688 --> 1.007653).  Saving model ...
Validation loss decreased (1.007653 --> 1.006197).  Saving model ...
Validation loss decreased (1.006197 --> 1.003101).  Saving model ...
Validation loss decreased (1.003101 --> 0.997359).  Saving model ...
Validation loss decreased (0.997359 --> 0.994348).  Saving model ...
Validation loss decreased (0.994348 --> 0.990359).  Saving model ...
Validation loss decreased (0.990359 --> 0.987519).  Saving model ...
Validation loss decreased (0.987519 --> 0.986327).  Saving model ...
Validation loss decreased (0.986327 --> 0.982726).  Saving model ...
Validation loss decreased (0.982726 --> 0.981404).  Saving model ...
Validation loss decreased (0.981404 --> 0.977433).  Saving model ...
Validation loss decreased (0.977433 --> 0.974761).  Saving model ...
Validation loss decreased (0.974761 --> 0.973236).  Saving model ...
Validation loss decreased (0.973236 --> 0.969097).  Saving model ...
EarlyStopping counter: 1 out of 10.0
Validation loss decreased (0.969097 --> 0.966296).  Saving model ...
Validation loss decreased (0.966296 --> 0.962684).  Saving model ...
EarlyStopping counter: 1 out of 10.0
EarlyStopping counter: 2 out of 10.0
Validation loss decreased (0.962684 --> 0.959712).  Saving model ...
Validation loss decreased (0.959712 --> 0.958212).  Saving model ...
Validation loss decreased (0.958212 --> 0.957437).  Saving model ...
Validation loss decreased (0.957437 --> 0.957328).  Saving model ...
Validation loss decreased (0.957328 --> 0.952938).  Saving model ...
Validation loss decreased (0.952938 --> 0.951225).  Saving model ...
Validation loss decreased (0.951225 --> 0.948916).  Saving model ...
Validation loss decreased (0.948916 --> 0.948174).  Saving model ...
Validation loss decreased (0.948174 --> 0.947671).  Saving model ...
Validation loss decreased (0.947671 --> 0.942086).  Saving model ...
EarlyStopping counter: 1 out of 10.0
EarlyStopping counter: 2 out of 10.0
EarlyStopping counter: 3 out of 10.0
Validation loss decreased (0.942086 --> 0.940785).  Saving model ...
Validation loss decreased (0.940785 --> 0.939138).  Saving model ...
Validation loss decreased (0.939138 --> 0.937870).  Saving model ...
EarlyStopping counter: 1 out of 10.0
Validation loss decreased (0.937870 --> 0.937527).  Saving model ...
Validation loss decreased (0.937527 --> 0.937006).  Saving model ...
Validation loss decreased (0.937006 --> 0.936050).  Saving model ...
EarlyStopping counter: 1 out of 10.0
Validation loss decreased (0.936050 --> 0.934392).  Saving model ...
Validation loss decreased (0.934392 --> 0.934066).  Saving model ...
EarlyStopping counter: 1 out of 10.0
EarlyStopping counter: 2 out of 10.0
EarlyStopping counter: 3 out of 10.0
EarlyStopping counter: 4 out of 10.0
Validation loss decreased (0.934066 --> 0.933320).  Saving model ...
Validation loss decreased (0.933320 --> 0.932995).  Saving model ...
EarlyStopping counter: 1 out of 10.0
Validation loss decreased (0.932995 --> 0.931808).  Saving model ...
Validation loss decreased (0.931808 --> 0.930294).  Saving model ...
Validation loss decreased (0.930294 --> 0.929756).  Saving model ...
EarlyStopping counter: 1 out of 10.0
EarlyStopping counter: 2 out of 10.0
EarlyStopping counter: 3 out of 10.0
EarlyStopping counter: 4 out of 10.0
EarlyStopping counter: 5 out of 10.0
EarlyStopping counter: 6 out of 10.0
EarlyStopping counter: 7 out of 10.0
EarlyStopping counter: 8 out of 10.0
EarlyStopping counter: 9 out of 10.0
EarlyStopping counter: 10 out of 10.0
/localscratch/yinan.29019297.0/env/lib/python3.7/site-packages/torch/nn/functional.py:1794: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.
  warnings.warn("nn.functional.tanh is deprecated. Use torch.tanh instead.")
wandb: Waiting for W&B process to finish, PID 218660... (success).
wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: \ 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: | 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: / 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: \ 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: | 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: / 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: \ 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: | 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: / 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb:                                                                                
wandb: Run history:
wandb:     e_F1 ▁▁▂▄▅▅▆▆▇▇▇▇▇▇▇▇▇▇▇▇███▇████████████████
wandb:   e_loss █▆▆▅▅▅▅▄▄▄▄▃▃▃▃▃▂▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:     t_F1 ▁▁▂▂▃▄▄▄▄▅▅▅▅▆▆▆▆▆▆▇▆▇▇▆▇▇▇▇▇▇▇▇▇▇▇█████
wandb:   t_loss █▇▆▆▆▆▅▅▅▅▅▅▄▄▄▄▄▃▃▃▃▃▃▃▂▃▂▂▂▂▂▂▂▂▂▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:     e_F1 59.72828
wandb:   e_loss 0.93473
wandb:     t_F1 72.25991
wandb:   t_loss 0.75319
wandb: 
wandb: Synced 4 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Synced stellar-wood-2: https://wandb.ai/yinanazhou/xl_512_bs_8_lr_1e06_es_10_lc_False_nr_False_sr_False_stem_False_lemma_True_repeat_1_fold_2/runs/b388pefx
wandb: Find logs at: ./wandb/run-20220318_201913-b388pefx/logs/debug.log
wandb: 

wandb: wandb version 0.12.11 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
2022-03-18 21:43:30.439758: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1
wandb: Tracking run with wandb version 0.12.5
wandb: Syncing run blooming-forest-2
wandb: ⭐️ View project at https://wandb.ai/yinanazhou/xl_512_bs_8_lr_1e06_es_10_lc_False_nr_False_sr_False_stem_False_lemma_True_repeat_2_fold_1
wandb: 🚀 View run at https://wandb.ai/yinanazhou/xl_512_bs_8_lr_1e06_es_10_lc_False_nr_False_sr_False_stem_False_lemma_True_repeat_2_fold_1/runs/2ukrff4f
wandb: Run data is saved locally in /project/6002780/yinan/Thesis_MER_Lyrics/lyric-emotion/wandb/run-20220318_214325-2ukrff4f
wandb: Run `wandb offline` to turn off syncing.

Validation loss decreased (inf --> 1.430382).  Saving model ...
Validation loss decreased (1.430382 --> 1.414491).  Saving model ...
Validation loss decreased (1.414491 --> 1.400817).  Saving model ...
Validation loss decreased (1.400817 --> 1.390014).  Saving model ...
Validation loss decreased (1.390014 --> 1.381313).  Saving model ...
Validation loss decreased (1.381313 --> 1.373598).  Saving model ...
Validation loss decreased (1.373598 --> 1.365854).  Saving model ...
Validation loss decreased (1.365854 --> 1.359494).  Saving model ...
Validation loss decreased (1.359494 --> 1.353130).  Saving model ...
Validation loss decreased (1.353130 --> 1.346829).  Saving model ...
Validation loss decreased (1.346829 --> 1.340262).  Saving model ...
Validation loss decreased (1.340262 --> 1.333698).  Saving model ...
Validation loss decreased (1.333698 --> 1.326737).  Saving model ...
Validation loss decreased (1.326737 --> 1.320367).  Saving model ...
Validation loss decreased (1.320367 --> 1.313385).  Saving model ...
Validation loss decreased (1.313385 --> 1.305288).  Saving model ...
Validation loss decreased (1.305288 --> 1.297488).  Saving model ...
Validation loss decreased (1.297488 --> 1.289106).  Saving model ...
Validation loss decreased (1.289106 --> 1.281587).  Saving model ...
Validation loss decreased (1.281587 --> 1.273184).  Saving model ...
Validation loss decreased (1.273184 --> 1.265559).  Saving model ...
Validation loss decreased (1.265559 --> 1.257668).  Saving model ...
Validation loss decreased (1.257668 --> 1.250251).  Saving model ...
Validation loss decreased (1.250251 --> 1.242818).  Saving model ...
Validation loss decreased (1.242818 --> 1.235164).  Saving model ...
Validation loss decreased (1.235164 --> 1.228193).  Saving model ...
Validation loss decreased (1.228193 --> 1.221942).  Saving model ...
Validation loss decreased (1.221942 --> 1.215805).  Saving model ...
Validation loss decreased (1.215805 --> 1.208587).  Saving model ...
Validation loss decreased (1.208587 --> 1.202571).  Saving model ...
Validation loss decreased (1.202571 --> 1.195750).  Saving model ...
Validation loss decreased (1.195750 --> 1.188135).  Saving model ...
Validation loss decreased (1.188135 --> 1.181264).  Saving model ...
Validation loss decreased (1.181264 --> 1.175083).  Saving model ...
Validation loss decreased (1.175083 --> 1.168819).  Saving model ...
Validation loss decreased (1.168819 --> 1.162522).  Saving model ...
Validation loss decreased (1.162522 --> 1.155110).  Saving model ...
Validation loss decreased (1.155110 --> 1.147880).  Saving model ...
Validation loss decreased (1.147880 --> 1.141618).  Saving model ...
Validation loss decreased (1.141618 --> 1.135797).  Saving model ...
Validation loss decreased (1.135797 --> 1.128262).  Saving model ...
Validation loss decreased (1.128262 --> 1.122201).  Saving model ...
Validation loss decreased (1.122201 --> 1.116122).  Saving model ...
Validation loss decreased (1.116122 --> 1.110890).  Saving model ...
Validation loss decreased (1.110890 --> 1.105222).  Saving model ...
Validation loss decreased (1.105222 --> 1.100174).  Saving model ...
Validation loss decreased (1.100174 --> 1.095631).  Saving model ...
Validation loss decreased (1.095631 --> 1.090911).  Saving model ...
Validation loss decreased (1.090911 --> 1.085879).  Saving model ...
Validation loss decreased (1.085879 --> 1.080152).  Saving model ...
Validation loss decreased (1.080152 --> 1.074761).  Saving model ...
Validation loss decreased (1.074761 --> 1.069596).  Saving model ...
Validation loss decreased (1.069596 --> 1.066850).  Saving model ...
Validation loss decreased (1.066850 --> 1.060980).  Saving model ...
Validation loss decreased (1.060980 --> 1.056690).  Saving model ...
Validation loss decreased (1.056690 --> 1.052239).  Saving model ...
Validation loss decreased (1.052239 --> 1.048209).  Saving model ...
Validation loss decreased (1.048209 --> 1.043979).  Saving model ...
Validation loss decreased (1.043979 --> 1.040335).  Saving model ...
Validation loss decreased (1.040335 --> 1.036909).  Saving model ...
Validation loss decreased (1.036909 --> 1.033181).  Saving model ...
Validation loss decreased (1.033181 --> 1.029590).  Saving model ...
Validation loss decreased (1.029590 --> 1.026259).  Saving model ...
Validation loss decreased (1.026259 --> 1.023139).  Saving model ...
Validation loss decreased (1.023139 --> 1.020255).  Saving model ...
Validation loss decreased (1.020255 --> 1.017114).  Saving model ...
Validation loss decreased (1.017114 --> 1.013240).  Saving model ...
Validation loss decreased (1.013240 --> 1.011922).  Saving model ...
Validation loss decreased (1.011922 --> 1.008640).  Saving model ...
Validation loss decreased (1.008640 --> 1.005458).  Saving model ...
Validation loss decreased (1.005458 --> 1.001577).  Saving model ...
Validation loss decreased (1.001577 --> 0.998920).  Saving model ...
Validation loss decreased (0.998920 --> 0.996589).  Saving model ...
Validation loss decreased (0.996589 --> 0.993297).  Saving model ...
Validation loss decreased (0.993297 --> 0.991071).  Saving model ...
Validation loss decreased (0.991071 --> 0.988029).  Saving model ...
Validation loss decreased (0.988029 --> 0.985910).  Saving model ...
Validation loss decreased (0.985910 --> 0.983689).  Saving model ...
Validation loss decreased (0.983689 --> 0.980653).  Saving model ...
Validation loss decreased (0.980653 --> 0.978763).  Saving model ...
Validation loss decreased (0.978763 --> 0.976555).  Saving model ...
Validation loss decreased (0.976555 --> 0.975142).  Saving model ...
Validation loss decreased (0.975142 --> 0.972937).  Saving model ...
Validation loss decreased (0.972937 --> 0.971809).  Saving model ...
Validation loss decreased (0.971809 --> 0.969954).  Saving model ...
Validation loss decreased (0.969954 --> 0.968475).  Saving model ...
Validation loss decreased (0.968475 --> 0.966998).  Saving model ...
Validation loss decreased (0.966998 --> 0.965696).  Saving model ...
Validation loss decreased (0.965696 --> 0.964529).  Saving model ...
Validation loss decreased (0.964529 --> 0.963179).  Saving model ...
Validation loss decreased (0.963179 --> 0.962271).  Saving model ...
Validation loss decreased (0.962271 --> 0.960853).  Saving model ...
Validation loss decreased (0.960853 --> 0.959671).  Saving model ...
Validation loss decreased (0.959671 --> 0.958184).  Saving model ...
Validation loss decreased (0.958184 --> 0.956751).  Saving model ...
Validation loss decreased (0.956751 --> 0.956590).  Saving model ...
Validation loss decreased (0.956590 --> 0.956353).  Saving model ...
Validation loss decreased (0.956353 --> 0.955035).  Saving model ...
Validation loss decreased (0.955035 --> 0.953428).  Saving model ...
Validation loss decreased (0.953428 --> 0.952836).  Saving model ...
EarlyStopping counter: 1 out of 10.0
Validation loss decreased (0.952836 --> 0.951658).  Saving model ...
Validation loss decreased (0.951658 --> 0.951063).  Saving model ...
Validation loss decreased (0.951063 --> 0.950738).  Saving model ...
Validation loss decreased (0.950738 --> 0.949887).  Saving model ...
Validation loss decreased (0.949887 --> 0.948606).  Saving model ...
Validation loss decreased (0.948606 --> 0.947661).  Saving model ...
Validation loss decreased (0.947661 --> 0.947657).  Saving model ...
Validation loss decreased (0.947657 --> 0.946776).  Saving model ...
Validation loss decreased (0.946776 --> 0.946138).  Saving model ...
Validation loss decreased (0.946138 --> 0.945630).  Saving model ...
EarlyStopping counter: 1 out of 10.0
EarlyStopping counter: 2 out of 10.0
Validation loss decreased (0.945630 --> 0.944626).  Saving model ...
Validation loss decreased (0.944626 --> 0.944151).  Saving model ...
EarlyStopping counter: 1 out of 10.0
EarlyStopping counter: 2 out of 10.0
EarlyStopping counter: 3 out of 10.0
EarlyStopping counter: 4 out of 10.0
Validation loss decreased (0.944151 --> 0.944056).  Saving model ...
Validation loss decreased (0.944056 --> 0.943869).  Saving model ...
EarlyStopping counter: 1 out of 10.0
EarlyStopping counter: 2 out of 10.0
EarlyStopping counter: 3 out of 10.0
EarlyStopping counter: 4 out of 10.0
EarlyStopping counter: 5 out of 10.0
EarlyStopping counter: 6 out of 10.0
EarlyStopping counter: 7 out of 10.0
EarlyStopping counter: 8 out of 10.0
EarlyStopping counter: 9 out of 10.0
EarlyStopping counter: 10 out of 10.0
/localscratch/yinan.29019297.0/env/lib/python3.7/site-packages/torch/nn/functional.py:1794: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.
  warnings.warn("nn.functional.tanh is deprecated. Use torch.tanh instead.")
wandb: Waiting for W&B process to finish, PID 223178... (success).
wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: \ 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: | 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: / 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: \ 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: | 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: / 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: \ 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: | 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: / 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb:                                                                                
wandb: Run history:
wandb:     e_F1 ▁▂▄▄▄▅▅▆▆▆▆▆▇▇▇▇▇▇▇▇▇▇▇█████████████████
wandb:   e_loss ██▇▇▇▆▆▅▅▅▄▄▄▃▃▃▃▃▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:     t_F1 ▁▁▂▁▃▃▄▄▄▅▅▅▅▆▆▆▆▆▆▆▆▆▇▇▆▇▇▇▇▇▇▇█▇██████
wandb:   t_loss ██▇▇▇▇▆▆▆▆▆▅▅▅▄▄▄▄▄▃▃▃▃▃▃▃▂▂▂▂▂▂▁▂▂▂▁▁▁▁
wandb: 
wandb: Run summary:
wandb:     e_F1 61.08846
wandb:   e_loss 0.94561
wandb:     t_F1 74.62157
wandb:   t_loss 0.70577
wandb: 
wandb: Synced 4 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Synced blooming-forest-2: https://wandb.ai/yinanazhou/xl_512_bs_8_lr_1e06_es_10_lc_False_nr_False_sr_False_stem_False_lemma_True_repeat_2_fold_1/runs/2ukrff4f
wandb: Find logs at: ./wandb/run-20220318_214325-2ukrff4f/logs/debug.log
wandb: 

wandb: wandb version 0.12.11 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
2022-03-18 23:10:33.587407: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1
wandb: Tracking run with wandb version 0.12.5
wandb: Syncing run dark-silence-1
wandb: ⭐️ View project at https://wandb.ai/yinanazhou/xl_512_bs_8_lr_1e06_es_10_lc_False_nr_False_sr_False_stem_False_lemma_True_repeat_2_fold_2
wandb: 🚀 View run at https://wandb.ai/yinanazhou/xl_512_bs_8_lr_1e06_es_10_lc_False_nr_False_sr_False_stem_False_lemma_True_repeat_2_fold_2/runs/1polcwrl
wandb: Run data is saved locally in /project/6002780/yinan/Thesis_MER_Lyrics/lyric-emotion/wandb/run-20220318_231030-1polcwrl
wandb: Run `wandb offline` to turn off syncing.

Validation loss decreased (inf --> 1.453110).  Saving model ...
Validation loss decreased (1.453110 --> 1.432514).  Saving model ...
Validation loss decreased (1.432514 --> 1.416628).  Saving model ...
Validation loss decreased (1.416628 --> 1.404432).  Saving model ...
Validation loss decreased (1.404432 --> 1.394547).  Saving model ...
Validation loss decreased (1.394547 --> 1.386261).  Saving model ...
Validation loss decreased (1.386261 --> 1.379047).  Saving model ...
Validation loss decreased (1.379047 --> 1.372686).  Saving model ...
Validation loss decreased (1.372686 --> 1.366555).  Saving model ...
Validation loss decreased (1.366555 --> 1.361251).  Saving model ...
Validation loss decreased (1.361251 --> 1.355565).  Saving model ...
Validation loss decreased (1.355565 --> 1.349931).  Saving model ...
Validation loss decreased (1.349931 --> 1.344093).  Saving model ...
Validation loss decreased (1.344093 --> 1.338095).  Saving model ...
Validation loss decreased (1.338095 --> 1.332446).  Saving model ...
Validation loss decreased (1.332446 --> 1.327342).  Saving model ...
Validation loss decreased (1.327342 --> 1.321727).  Saving model ...
Validation loss decreased (1.321727 --> 1.315439).  Saving model ...
Validation loss decreased (1.315439 --> 1.309881).  Saving model ...
Validation loss decreased (1.309881 --> 1.304200).  Saving model ...
Validation loss decreased (1.304200 --> 1.297254).  Saving model ...
Validation loss decreased (1.297254 --> 1.289741).  Saving model ...
Validation loss decreased (1.289741 --> 1.282110).  Saving model ...
Validation loss decreased (1.282110 --> 1.274008).  Saving model ...
Validation loss decreased (1.274008 --> 1.265606).  Saving model ...
Validation loss decreased (1.265606 --> 1.258572).  Saving model ...
Validation loss decreased (1.258572 --> 1.250675).  Saving model ...
Validation loss decreased (1.250675 --> 1.242092).  Saving model ...
Validation loss decreased (1.242092 --> 1.233116).  Saving model ...
Validation loss decreased (1.233116 --> 1.224684).  Saving model ...
Validation loss decreased (1.224684 --> 1.217237).  Saving model ...
Validation loss decreased (1.217237 --> 1.209258).  Saving model ...
Validation loss decreased (1.209258 --> 1.202241).  Saving model ...
Validation loss decreased (1.202241 --> 1.193791).  Saving model ...
Validation loss decreased (1.193791 --> 1.185969).  Saving model ...
Validation loss decreased (1.185969 --> 1.179151).  Saving model ...
Validation loss decreased (1.179151 --> 1.172340).  Saving model ...
Validation loss decreased (1.172340 --> 1.163779).  Saving model ...
Validation loss decreased (1.163779 --> 1.154598).  Saving model ...
Validation loss decreased (1.154598 --> 1.146663).  Saving model ...
Validation loss decreased (1.146663 --> 1.139752).  Saving model ...
Validation loss decreased (1.139752 --> 1.134246).  Saving model ...
Validation loss decreased (1.134246 --> 1.127993).  Saving model ...
Validation loss decreased (1.127993 --> 1.121278).  Saving model ...
Validation loss decreased (1.121278 --> 1.114945).  Saving model ...
Validation loss decreased (1.114945 --> 1.109544).  Saving model ...
Validation loss decreased (1.109544 --> 1.104190).  Saving model ...
Validation loss decreased (1.104190 --> 1.098394).  Saving model ...
Validation loss decreased (1.098394 --> 1.093384).  Saving model ...
Validation loss decreased (1.093384 --> 1.087368).  Saving model ...
Validation loss decreased (1.087368 --> 1.082855).  Saving model ...
Validation loss decreased (1.082855 --> 1.078690).  Saving model ...
Validation loss decreased (1.078690 --> 1.071631).  Saving model ...
Validation loss decreased (1.071631 --> 1.067916).  Saving model ...
Validation loss decreased (1.067916 --> 1.063930).  Saving model ...
Validation loss decreased (1.063930 --> 1.060271).  Saving model ...
Validation loss decreased (1.060271 --> 1.056056).  Saving model ...
Validation loss decreased (1.056056 --> 1.051103).  Saving model ...
Validation loss decreased (1.051103 --> 1.047508).  Saving model ...
Validation loss decreased (1.047508 --> 1.042470).  Saving model ...
Validation loss decreased (1.042470 --> 1.039730).  Saving model ...
Validation loss decreased (1.039730 --> 1.034781).  Saving model ...
Validation loss decreased (1.034781 --> 1.030420).  Saving model ...
Validation loss decreased (1.030420 --> 1.026576).  Saving model ...
Validation loss decreased (1.026576 --> 1.021664).  Saving model ...
Validation loss decreased (1.021664 --> 1.018941).  Saving model ...
Validation loss decreased (1.018941 --> 1.016200).  Saving model ...
Validation loss decreased (1.016200 --> 1.013358).  Saving model ...
Validation loss decreased (1.013358 --> 1.010081).  Saving model ...
Validation loss decreased (1.010081 --> 1.006084).  Saving model ...
Validation loss decreased (1.006084 --> 1.003611).  Saving model ...
Validation loss decreased (1.003611 --> 1.000119).  Saving model ...
Validation loss decreased (1.000119 --> 0.998010).  Saving model ...
Validation loss decreased (0.998010 --> 0.996971).  Saving model ...
Validation loss decreased (0.996971 --> 0.991694).  Saving model ...
Validation loss decreased (0.991694 --> 0.990864).  Saving model ...
Validation loss decreased (0.990864 --> 0.987677).  Saving model ...
Validation loss decreased (0.987677 --> 0.984651).  Saving model ...
Validation loss decreased (0.984651 --> 0.983980).  Saving model ...
Validation loss decreased (0.983980 --> 0.983870).  Saving model ...
Validation loss decreased (0.983870 --> 0.982461).  Saving model ...
Validation loss decreased (0.982461 --> 0.980386).  Saving model ...
Validation loss decreased (0.980386 --> 0.977723).  Saving model ...
Validation loss decreased (0.977723 --> 0.974838).  Saving model ...
Validation loss decreased (0.974838 --> 0.970619).  Saving model ...
Validation loss decreased (0.970619 --> 0.969332).  Saving model ...
Validation loss decreased (0.969332 --> 0.966764).  Saving model ...
Validation loss decreased (0.966764 --> 0.966228).  Saving model ...
Validation loss decreased (0.966228 --> 0.964889).  Saving model ...
Validation loss decreased (0.964889 --> 0.963431).  Saving model ...
Validation loss decreased (0.963431 --> 0.959736).  Saving model ...
Validation loss decreased (0.959736 --> 0.958218).  Saving model ...
Validation loss decreased (0.958218 --> 0.956864).  Saving model ...
Validation loss decreased (0.956864 --> 0.954998).  Saving model ...
Validation loss decreased (0.954998 --> 0.953980).  Saving model ...
Validation loss decreased (0.953980 --> 0.952760).  Saving model ...
Validation loss decreased (0.952760 --> 0.952111).  Saving model ...
Validation loss decreased (0.952111 --> 0.948738).  Saving model ...
Validation loss decreased (0.948738 --> 0.947585).  Saving model ...
Validation loss decreased (0.947585 --> 0.946481).  Saving model ...
EarlyStopping counter: 1 out of 10.0
Validation loss decreased (0.946481 --> 0.946391).  Saving model ...
EarlyStopping counter: 1 out of 10.0
Validation loss decreased (0.946391 --> 0.945485).  Saving model ...
Validation loss decreased (0.945485 --> 0.944057).  Saving model ...
Validation loss decreased (0.944057 --> 0.943166).  Saving model ...
Validation loss decreased (0.943166 --> 0.940681).  Saving model ...
Validation loss decreased (0.940681 --> 0.939686).  Saving model ...
EarlyStopping counter: 1 out of 10.0
Validation loss decreased (0.939686 --> 0.938647).  Saving model ...
Validation loss decreased (0.938647 --> 0.937763).  Saving model ...
Validation loss decreased (0.937763 --> 0.937096).  Saving model ...
Validation loss decreased (0.937096 --> 0.936835).  Saving model ...
Validation loss decreased (0.936835 --> 0.935868).  Saving model ...
Validation loss decreased (0.935868 --> 0.935338).  Saving model ...
Validation loss decreased (0.935338 --> 0.934121).  Saving model ...
EarlyStopping counter: 1 out of 10.0
EarlyStopping counter: 2 out of 10.0
Validation loss decreased (0.934121 --> 0.932586).  Saving model ...
Validation loss decreased (0.932586 --> 0.932240).  Saving model ...
Validation loss decreased (0.932240 --> 0.931728).  Saving model ...
EarlyStopping counter: 1 out of 10.0
EarlyStopping counter: 2 out of 10.0
EarlyStopping counter: 3 out of 10.0
Validation loss decreased (0.931728 --> 0.931416).  Saving model ...
Validation loss decreased (0.931416 --> 0.930314).  Saving model ...
Validation loss decreased (0.930314 --> 0.929221).  Saving model ...
Validation loss decreased (0.929221 --> 0.927626).  Saving model ...
EarlyStopping counter: 1 out of 10.0
EarlyStopping counter: 2 out of 10.0
EarlyStopping counter: 3 out of 10.0
EarlyStopping counter: 4 out of 10.0
EarlyStopping counter: 5 out of 10.0
EarlyStopping counter: 6 out of 10.0
EarlyStopping counter: 7 out of 10.0
EarlyStopping counter: 8 out of 10.0
EarlyStopping counter: 9 out of 10.0
EarlyStopping counter: 10 out of 10.0
/localscratch/yinan.29019297.0/env/lib/python3.7/site-packages/torch/nn/functional.py:1794: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.
  warnings.warn("nn.functional.tanh is deprecated. Use torch.tanh instead.")
wandb: Waiting for W&B process to finish, PID 227861... (success).
wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: \ 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: | 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: / 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: \ 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: | 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: / 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: \ 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: | 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: / 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb:                                                                                
wandb: Run history:
wandb:     e_F1 ▁▁▂▃▄▅▅▆▆▆▆▆▆▆▇▇▇▇▇▇▇▇█▇▇▇▇█████████████
wandb:   e_loss ██▇▇▇▆▆▆▅▅▄▄▄▃▃▃▃▃▂▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:     t_F1 ▁▂▂▃▃▃▄▄▄▅▅▅▅▆▆▆▆▇▇▇▆▇▇▇▇▇▇▇▇▇▇█▇███████
wandb:   t_loss ██▇▇▇▇▇▆▆▆▆▅▅▅▅▄▄▄▄▄▄▃▃▃▃▃▃▂▂▂▂▂▂▂▂▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:     e_F1 61.22216
wandb:   e_loss 0.93025
wandb:     t_F1 71.59837
wandb:   t_loss 0.72477
wandb: 
wandb: Synced 4 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Synced dark-silence-1: https://wandb.ai/yinanazhou/xl_512_bs_8_lr_1e06_es_10_lc_False_nr_False_sr_False_stem_False_lemma_True_repeat_2_fold_2/runs/1polcwrl
wandb: Find logs at: ./wandb/run-20220318_231030-1polcwrl/logs/debug.log
wandb: 

wandb: wandb version 0.12.11 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
2022-03-19 00:41:20.892169: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1
wandb: Tracking run with wandb version 0.12.5
wandb: Syncing run classic-surf-1
wandb: ⭐️ View project at https://wandb.ai/yinanazhou/xl_512_bs_8_lr_1e06_es_10_lc_False_nr_False_sr_False_stem_False_lemma_True_repeat_3_fold_1
wandb: 🚀 View run at https://wandb.ai/yinanazhou/xl_512_bs_8_lr_1e06_es_10_lc_False_nr_False_sr_False_stem_False_lemma_True_repeat_3_fold_1/runs/1yesngcm
wandb: Run data is saved locally in /project/6002780/yinan/Thesis_MER_Lyrics/lyric-emotion/wandb/run-20220319_004117-1yesngcm
wandb: Run `wandb offline` to turn off syncing.

Validation loss decreased (inf --> 1.464144).  Saving model ...
Validation loss decreased (1.464144 --> 1.436293).  Saving model ...
Validation loss decreased (1.436293 --> 1.416448).  Saving model ...
Validation loss decreased (1.416448 --> 1.402456).  Saving model ...
Validation loss decreased (1.402456 --> 1.392211).  Saving model ...
Validation loss decreased (1.392211 --> 1.383823).  Saving model ...
Validation loss decreased (1.383823 --> 1.377114).  Saving model ...
Validation loss decreased (1.377114 --> 1.371723).  Saving model ...
Validation loss decreased (1.371723 --> 1.365757).  Saving model ...
Validation loss decreased (1.365757 --> 1.359931).  Saving model ...
Validation loss decreased (1.359931 --> 1.354286).  Saving model ...
Validation loss decreased (1.354286 --> 1.348167).  Saving model ...
Validation loss decreased (1.348167 --> 1.342068).  Saving model ...
Validation loss decreased (1.342068 --> 1.335849).  Saving model ...
Validation loss decreased (1.335849 --> 1.328428).  Saving model ...
Validation loss decreased (1.328428 --> 1.320841).  Saving model ...
Validation loss decreased (1.320841 --> 1.313402).  Saving model ...
Validation loss decreased (1.313402 --> 1.306060).  Saving model ...
Validation loss decreased (1.306060 --> 1.297358).  Saving model ...
Validation loss decreased (1.297358 --> 1.289189).  Saving model ...
Validation loss decreased (1.289189 --> 1.280634).  Saving model ...
Validation loss decreased (1.280634 --> 1.271576).  Saving model ...
Validation loss decreased (1.271576 --> 1.263345).  Saving model ...
Validation loss decreased (1.263345 --> 1.255667).  Saving model ...
Validation loss decreased (1.255667 --> 1.247383).  Saving model ...
Validation loss decreased (1.247383 --> 1.238114).  Saving model ...
Validation loss decreased (1.238114 --> 1.229543).  Saving model ...
Validation loss decreased (1.229543 --> 1.222660).  Saving model ...
Validation loss decreased (1.222660 --> 1.215530).  Saving model ...
Validation loss decreased (1.215530 --> 1.205495).  Saving model ...
Validation loss decreased (1.205495 --> 1.198725).  Saving model ...
Validation loss decreased (1.198725 --> 1.193718).  Saving model ...
Validation loss decreased (1.193718 --> 1.184455).  Saving model ...
Validation loss decreased (1.184455 --> 1.177814).  Saving model ...
Validation loss decreased (1.177814 --> 1.171022).  Saving model ...
Validation loss decreased (1.171022 --> 1.162685).  Saving model ...
Validation loss decreased (1.162685 --> 1.155124).  Saving model ...
Validation loss decreased (1.155124 --> 1.147903).  Saving model ...
Validation loss decreased (1.147903 --> 1.141806).  Saving model ...
Validation loss decreased (1.141806 --> 1.137641).  Saving model ...
Validation loss decreased (1.137641 --> 1.131459).  Saving model ...
Validation loss decreased (1.131459 --> 1.125713).  Saving model ...
Validation loss decreased (1.125713 --> 1.121401).  Saving model ...
Validation loss decreased (1.121401 --> 1.115613).  Saving model ...
Validation loss decreased (1.115613 --> 1.107635).  Saving model ...
Validation loss decreased (1.107635 --> 1.104230).  Saving model ...
Validation loss decreased (1.104230 --> 1.098094).  Saving model ...
Validation loss decreased (1.098094 --> 1.092155).  Saving model ...
Validation loss decreased (1.092155 --> 1.084061).  Saving model ...
Validation loss decreased (1.084061 --> 1.080441).  Saving model ...
Validation loss decreased (1.080441 --> 1.077017).  Saving model ...
Validation loss decreased (1.077017 --> 1.071510).  Saving model ...
Validation loss decreased (1.071510 --> 1.065571).  Saving model ...
Validation loss decreased (1.065571 --> 1.062127).  Saving model ...
Validation loss decreased (1.062127 --> 1.054225).  Saving model ...
Validation loss decreased (1.054225 --> 1.050914).  Saving model ...
Validation loss decreased (1.050914 --> 1.045779).  Saving model ...
Validation loss decreased (1.045779 --> 1.042079).  Saving model ...
Validation loss decreased (1.042079 --> 1.038632).  Saving model ...
Validation loss decreased (1.038632 --> 1.033845).  Saving model ...
Validation loss decreased (1.033845 --> 1.030757).  Saving model ...
Validation loss decreased (1.030757 --> 1.028285).  Saving model ...
Validation loss decreased (1.028285 --> 1.025533).  Saving model ...
Validation loss decreased (1.025533 --> 1.021324).  Saving model ...
Validation loss decreased (1.021324 --> 1.015548).  Saving model ...
Validation loss decreased (1.015548 --> 1.011619).  Saving model ...
Validation loss decreased (1.011619 --> 1.009012).  Saving model ...
Validation loss decreased (1.009012 --> 1.003653).  Saving model ...
Validation loss decreased (1.003653 --> 1.002147).  Saving model ...
Validation loss decreased (1.002147 --> 1.001758).  Saving model ...
Validation loss decreased (1.001758 --> 0.999043).  Saving model ...
Validation loss decreased (0.999043 --> 0.995711).  Saving model ...
Validation loss decreased (0.995711 --> 0.991782).  Saving model ...
Validation loss decreased (0.991782 --> 0.990850).  Saving model ...
Validation loss decreased (0.990850 --> 0.989218).  Saving model ...
Validation loss decreased (0.989218 --> 0.985555).  Saving model ...
Validation loss decreased (0.985555 --> 0.981536).  Saving model ...
EarlyStopping counter: 1 out of 10.0
EarlyStopping counter: 2 out of 10.0
Validation loss decreased (0.981536 --> 0.978399).  Saving model ...
Validation loss decreased (0.978399 --> 0.976413).  Saving model ...
Validation loss decreased (0.976413 --> 0.974488).  Saving model ...
Validation loss decreased (0.974488 --> 0.974115).  Saving model ...
Validation loss decreased (0.974115 --> 0.971542).  Saving model ...
Validation loss decreased (0.971542 --> 0.970035).  Saving model ...
Validation loss decreased (0.970035 --> 0.968549).  Saving model ...
Validation loss decreased (0.968549 --> 0.967895).  Saving model ...
Validation loss decreased (0.967895 --> 0.962639).  Saving model ...
Validation loss decreased (0.962639 --> 0.959718).  Saving model ...
EarlyStopping counter: 1 out of 10.0
Validation loss decreased (0.959718 --> 0.959660).  Saving model ...
Validation loss decreased (0.959660 --> 0.959066).  Saving model ...
Validation loss decreased (0.959066 --> 0.957977).  Saving model ...
Validation loss decreased (0.957977 --> 0.956694).  Saving model ...
Validation loss decreased (0.956694 --> 0.956471).  Saving model ...
Validation loss decreased (0.956471 --> 0.953116).  Saving model ...
Validation loss decreased (0.953116 --> 0.949477).  Saving model ...
Validation loss decreased (0.949477 --> 0.949125).  Saving model ...
EarlyStopping counter: 1 out of 10.0
Validation loss decreased (0.949125 --> 0.948847).  Saving model ...
Validation loss decreased (0.948847 --> 0.947563).  Saving model ...
EarlyStopping counter: 1 out of 10.0
Validation loss decreased (0.947563 --> 0.947341).  Saving model ...
EarlyStopping counter: 1 out of 10.0
EarlyStopping counter: 2 out of 10.0
Validation loss decreased (0.947341 --> 0.946732).  Saving model ...
EarlyStopping counter: 1 out of 10.0
Validation loss decreased (0.946732 --> 0.946380).  Saving model ...
Validation loss decreased (0.946380 --> 0.944768).  Saving model ...
Validation loss decreased (0.944768 --> 0.941597).  Saving model ...
EarlyStopping counter: 1 out of 10.0
EarlyStopping counter: 2 out of 10.0
EarlyStopping counter: 3 out of 10.0
EarlyStopping counter: 4 out of 10.0
EarlyStopping counter: 5 out of 10.0
EarlyStopping counter: 6 out of 10.0
EarlyStopping counter: 7 out of 10.0
EarlyStopping counter: 8 out of 10.0
EarlyStopping counter: 9 out of 10.0
EarlyStopping counter: 10 out of 10.0
/localscratch/yinan.29019297.0/env/lib/python3.7/site-packages/torch/nn/functional.py:1794: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.
  warnings.warn("nn.functional.tanh is deprecated. Use torch.tanh instead.")
wandb: Waiting for W&B process to finish, PID 232721... (success).
wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: \ 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: | 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: / 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: \ 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: | 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: / 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: \ 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: | 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: / 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb:                                                                                
wandb: Run history:
wandb:     e_F1 ▁▁▃▄▄▄▅▆▆▆▆▆▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇████████████
wandb:   e_loss █▇▇▇▆▆▆▅▅▅▄▄▄▄▃▃▃▃▃▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:     t_F1 ▁▁▂▃▄▃▄▄▅▄▅▅▆▆▆▆▆▇▆▇▆▇▇▇▇▇▇▇▇▇▇▇▇███████
wandb:   t_loss ██▇▇▇▇▆▆▆▆▆▅▅▅▅▄▄▄▄▄▃▃▃▃▃▃▂▂▂▂▂▂▂▂▂▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:     e_F1 60.99589
wandb:   e_loss 0.94337
wandb:     t_F1 72.70595
wandb:   t_loss 0.74294
wandb: 
wandb: Synced 4 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Synced classic-surf-1: https://wandb.ai/yinanazhou/xl_512_bs_8_lr_1e06_es_10_lc_False_nr_False_sr_False_stem_False_lemma_True_repeat_3_fold_1/runs/1yesngcm
wandb: Find logs at: ./wandb/run-20220319_004117-1yesngcm/logs/debug.log
wandb: 

wandb: wandb version 0.12.11 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
2022-03-19 02:01:13.587280: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1
wandb: Tracking run with wandb version 0.12.5
wandb: Syncing run morning-rain-1
wandb: ⭐️ View project at https://wandb.ai/yinanazhou/xl_512_bs_8_lr_1e06_es_10_lc_False_nr_False_sr_False_stem_False_lemma_True_repeat_3_fold_2
wandb: 🚀 View run at https://wandb.ai/yinanazhou/xl_512_bs_8_lr_1e06_es_10_lc_False_nr_False_sr_False_stem_False_lemma_True_repeat_3_fold_2/runs/316ua2il
wandb: Run data is saved locally in /project/6002780/yinan/Thesis_MER_Lyrics/lyric-emotion/wandb/run-20220319_020110-316ua2il
wandb: Run `wandb offline` to turn off syncing.

Validation loss decreased (inf --> 1.401231).  Saving model ...
Validation loss decreased (1.401231 --> 1.387546).  Saving model ...
Validation loss decreased (1.387546 --> 1.377880).  Saving model ...
Validation loss decreased (1.377880 --> 1.369960).  Saving model ...
Validation loss decreased (1.369960 --> 1.363075).  Saving model ...
Validation loss decreased (1.363075 --> 1.357061).  Saving model ...
Validation loss decreased (1.357061 --> 1.351664).  Saving model ...
Validation loss decreased (1.351664 --> 1.347275).  Saving model ...
Validation loss decreased (1.347275 --> 1.342416).  Saving model ...
Validation loss decreased (1.342416 --> 1.337657).  Saving model ...
Validation loss decreased (1.337657 --> 1.333074).  Saving model ...
Validation loss decreased (1.333074 --> 1.328795).  Saving model ...
Validation loss decreased (1.328795 --> 1.323746).  Saving model ...
Validation loss decreased (1.323746 --> 1.318320).  Saving model ...
Validation loss decreased (1.318320 --> 1.312836).  Saving model ...
Validation loss decreased (1.312836 --> 1.306845).  Saving model ...
Validation loss decreased (1.306845 --> 1.301138).  Saving model ...
Validation loss decreased (1.301138 --> 1.295653).  Saving model ...
Validation loss decreased (1.295653 --> 1.289336).  Saving model ...
Validation loss decreased (1.289336 --> 1.283096).  Saving model ...
Validation loss decreased (1.283096 --> 1.276512).  Saving model ...
Validation loss decreased (1.276512 --> 1.268956).  Saving model ...
Validation loss decreased (1.268956 --> 1.261027).  Saving model ...
Validation loss decreased (1.261027 --> 1.253069).  Saving model ...
Validation loss decreased (1.253069 --> 1.244687).  Saving model ...
Validation loss decreased (1.244687 --> 1.236510).  Saving model ...
Validation loss decreased (1.236510 --> 1.229005).  Saving model ...
Validation loss decreased (1.229005 --> 1.218179).  Saving model ...
Validation loss decreased (1.218179 --> 1.208707).  Saving model ...
Validation loss decreased (1.208707 --> 1.199497).  Saving model ...
Validation loss decreased (1.199497 --> 1.191246).  Saving model ...
Validation loss decreased (1.191246 --> 1.181989).  Saving model ...
Validation loss decreased (1.181989 --> 1.173439).  Saving model ...
Validation loss decreased (1.173439 --> 1.165381).  Saving model ...
Validation loss decreased (1.165381 --> 1.155424).  Saving model ...
Validation loss decreased (1.155424 --> 1.146404).  Saving model ...
Validation loss decreased (1.146404 --> 1.137594).  Saving model ...
Validation loss decreased (1.137594 --> 1.130607).  Saving model ...
Validation loss decreased (1.130607 --> 1.122009).  Saving model ...
Validation loss decreased (1.122009 --> 1.114863).  Saving model ...
Validation loss decreased (1.114863 --> 1.106961).  Saving model ...
Validation loss decreased (1.106961 --> 1.101614).  Saving model ...
Validation loss decreased (1.101614 --> 1.095812).  Saving model ...
Validation loss decreased (1.095812 --> 1.091663).  Saving model ...
Validation loss decreased (1.091663 --> 1.084260).  Saving model ...
Validation loss decreased (1.084260 --> 1.077972).  Saving model ...
Validation loss decreased (1.077972 --> 1.071831).  Saving model ...
Validation loss decreased (1.071831 --> 1.066325).  Saving model ...
Validation loss decreased (1.066325 --> 1.061844).  Saving model ...
Validation loss decreased (1.061844 --> 1.058051).  Saving model ...
Validation loss decreased (1.058051 --> 1.052699).  Saving model ...
Validation loss decreased (1.052699 --> 1.047230).  Saving model ...
Validation loss decreased (1.047230 --> 1.043445).  Saving model ...
Validation loss decreased (1.043445 --> 1.039144).  Saving model ...
Validation loss decreased (1.039144 --> 1.036291).  Saving model ...
Validation loss decreased (1.036291 --> 1.032571).  Saving model ...
Validation loss decreased (1.032571 --> 1.028832).  Saving model ...
Validation loss decreased (1.028832 --> 1.025147).  Saving model ...
Validation loss decreased (1.025147 --> 1.021775).  Saving model ...
Validation loss decreased (1.021775 --> 1.019311).  Saving model ...
Validation loss decreased (1.019311 --> 1.013720).  Saving model ...
Validation loss decreased (1.013720 --> 1.011714).  Saving model ...
Validation loss decreased (1.011714 --> 1.007963).  Saving model ...
Validation loss decreased (1.007963 --> 1.004328).  Saving model ...
Validation loss decreased (1.004328 --> 1.002021).  Saving model ...
Validation loss decreased (1.002021 --> 0.998196).  Saving model ...
Validation loss decreased (0.998196 --> 0.996585).  Saving model ...
Validation loss decreased (0.996585 --> 0.989878).  Saving model ...
Validation loss decreased (0.989878 --> 0.987559).  Saving model ...
Validation loss decreased (0.987559 --> 0.987168).  Saving model ...
Validation loss decreased (0.987168 --> 0.985313).  Saving model ...
Validation loss decreased (0.985313 --> 0.980735).  Saving model ...
Validation loss decreased (0.980735 --> 0.977677).  Saving model ...
Validation loss decreased (0.977677 --> 0.975542).  Saving model ...
Validation loss decreased (0.975542 --> 0.970564).  Saving model ...
EarlyStopping counter: 1 out of 10.0
Validation loss decreased (0.970564 --> 0.967438).  Saving model ...
Validation loss decreased (0.967438 --> 0.964650).  Saving model ...
Validation loss decreased (0.964650 --> 0.963269).  Saving model ...
Validation loss decreased (0.963269 --> 0.962682).  Saving model ...
Validation loss decreased (0.962682 --> 0.959699).  Saving model ...
Validation loss decreased (0.959699 --> 0.954827).  Saving model ...
Validation loss decreased (0.954827 --> 0.953213).  Saving model ...
Validation loss decreased (0.953213 --> 0.951819).  Saving model ...
Validation loss decreased (0.951819 --> 0.949607).  Saving model ...
Validation loss decreased (0.949607 --> 0.946858).  Saving model ...
Validation loss decreased (0.946858 --> 0.943652).  Saving model ...
EarlyStopping counter: 1 out of 10.0
Validation loss decreased (0.943652 --> 0.942496).  Saving model ...
Validation loss decreased (0.942496 --> 0.941429).  Saving model ...
Validation loss decreased (0.941429 --> 0.940561).  Saving model ...
Validation loss decreased (0.940561 --> 0.939616).  Saving model ...
Validation loss decreased (0.939616 --> 0.939217).  Saving model ...
Validation loss decreased (0.939217 --> 0.938601).  Saving model ...
Validation loss decreased (0.938601 --> 0.936285).  Saving model ...
EarlyStopping counter: 1 out of 10.0
EarlyStopping counter: 2 out of 10.0
Validation loss decreased (0.936285 --> 0.934227).  Saving model ...
Validation loss decreased (0.934227 --> 0.931781).  Saving model ...
EarlyStopping counter: 1 out of 10.0
Validation loss decreased (0.931781 --> 0.931446).  Saving model ...
Validation loss decreased (0.931446 --> 0.931379).  Saving model ...
Validation loss decreased (0.931379 --> 0.930000).  Saving model ...
Validation loss decreased (0.930000 --> 0.925552).  Saving model ...
Validation loss decreased (0.925552 --> 0.923948).  Saving model ...
Validation loss decreased (0.923948 --> 0.922856).  Saving model ...
Validation loss decreased (0.922856 --> 0.922443).  Saving model ...
Validation loss decreased (0.922443 --> 0.921690).  Saving model ...
EarlyStopping counter: 1 out of 10.0
Validation loss decreased (0.921690 --> 0.921097).  Saving model ...
Validation loss decreased (0.921097 --> 0.918363).  Saving model ...
Validation loss decreased (0.918363 --> 0.918285).  Saving model ...
EarlyStopping counter: 1 out of 10.0
EarlyStopping counter: 2 out of 10.0
EarlyStopping counter: 3 out of 10.0
Validation loss decreased (0.918285 --> 0.915846).  Saving model ...
EarlyStopping counter: 1 out of 10.0
EarlyStopping counter: 2 out of 10.0
EarlyStopping counter: 3 out of 10.0
EarlyStopping counter: 4 out of 10.0
Validation loss decreased (0.915846 --> 0.915079).  Saving model ...
Validation loss decreased (0.915079 --> 0.914076).  Saving model ...
EarlyStopping counter: 1 out of 10.0
EarlyStopping counter: 2 out of 10.0
EarlyStopping counter: 3 out of 10.0
Validation loss decreased (0.914076 --> 0.913802).  Saving model ...
EarlyStopping counter: 1 out of 10.0
EarlyStopping counter: 2 out of 10.0
EarlyStopping counter: 3 out of 10.0
EarlyStopping counter: 4 out of 10.0
EarlyStopping counter: 5 out of 10.0
EarlyStopping counter: 6 out of 10.0
Validation loss decreased (0.913802 --> 0.912750).  Saving model ...
EarlyStopping counter: 1 out of 10.0
EarlyStopping counter: 2 out of 10.0
EarlyStopping counter: 3 out of 10.0
EarlyStopping counter: 4 out of 10.0
EarlyStopping counter: 5 out of 10.0
EarlyStopping counter: 6 out of 10.0
EarlyStopping counter: 7 out of 10.0
EarlyStopping counter: 8 out of 10.0
EarlyStopping counter: 9 out of 10.0
EarlyStopping counter: 10 out of 10.0
/localscratch/yinan.29019297.0/env/lib/python3.7/site-packages/torch/nn/functional.py:1794: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.
  warnings.warn("nn.functional.tanh is deprecated. Use torch.tanh instead.")
wandb: Waiting for W&B process to finish, PID 237043... (success).
wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: \ 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: | 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: / 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: \ 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: | 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: / 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: \ 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: | 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: / 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: \ 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: | 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: / 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb:                                                                                
wandb: Run history:
wandb:     e_F1 ▁▂▄▄▄▅▅▅▆▆▆▆▆▆▇▇▇▇▇▇▇▇██████████████████
wandb:   e_loss ██▇▇▇▇▆▆▅▅▄▄▄▃▃▃▃▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:     t_F1 ▁▁▁▂▂▃▄▄▄▄▄▅▅▅▆▆▆▆▆▆▆▆▇▇▆▇▇▇▇▇▇███▇█████
wandb:   t_loss ████▇▇▇▆▆▆▆▅▅▅▅▄▄▄▄▄▃▃▃▃▃▃▃▂▂▂▂▂▂▂▂▂▁▁▁▁
wandb: 
wandb: Run summary:
wandb:     e_F1 63.46197
wandb:   e_loss 0.91559
wandb:     t_F1 71.69806
wandb:   t_loss 0.71702
wandb: 
wandb: Synced 4 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Synced morning-rain-1: https://wandb.ai/yinanazhou/xl_512_bs_8_lr_1e06_es_10_lc_False_nr_False_sr_False_stem_False_lemma_True_repeat_3_fold_2/runs/316ua2il
wandb: Find logs at: ./wandb/run-20220319_020110-316ua2il/logs/debug.log
wandb: 

wandb: wandb version 0.12.11 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
2022-03-19 03:35:01.652439: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1
wandb: Tracking run with wandb version 0.12.5
wandb: Syncing run still-dream-1
wandb: ⭐️ View project at https://wandb.ai/yinanazhou/xl_512_bs_8_lr_1e06_es_10_lc_False_nr_False_sr_False_stem_False_lemma_True_repeat_4_fold_1
wandb: 🚀 View run at https://wandb.ai/yinanazhou/xl_512_bs_8_lr_1e06_es_10_lc_False_nr_False_sr_False_stem_False_lemma_True_repeat_4_fold_1/runs/114gwomg
wandb: Run data is saved locally in /project/6002780/yinan/Thesis_MER_Lyrics/lyric-emotion/wandb/run-20220319_033458-114gwomg
wandb: Run `wandb offline` to turn off syncing.

Validation loss decreased (inf --> 1.458346).  Saving model ...
Validation loss decreased (1.458346 --> 1.435890).  Saving model ...
Validation loss decreased (1.435890 --> 1.419537).  Saving model ...
Validation loss decreased (1.419537 --> 1.406961).  Saving model ...
Validation loss decreased (1.406961 --> 1.397343).  Saving model ...
Validation loss decreased (1.397343 --> 1.389474).  Saving model ...
Validation loss decreased (1.389474 --> 1.383246).  Saving model ...
Validation loss decreased (1.383246 --> 1.377515).  Saving model ...
Validation loss decreased (1.377515 --> 1.372294).  Saving model ...
Validation loss decreased (1.372294 --> 1.367126).  Saving model ...
Validation loss decreased (1.367126 --> 1.362197).  Saving model ...
Validation loss decreased (1.362197 --> 1.356973).  Saving model ...
Validation loss decreased (1.356973 --> 1.352288).  Saving model ...
Validation loss decreased (1.352288 --> 1.347079).  Saving model ...
Validation loss decreased (1.347079 --> 1.341480).  Saving model ...
Validation loss decreased (1.341480 --> 1.335688).  Saving model ...
Validation loss decreased (1.335688 --> 1.330182).  Saving model ...
Validation loss decreased (1.330182 --> 1.324132).  Saving model ...
Validation loss decreased (1.324132 --> 1.317290).  Saving model ...
Validation loss decreased (1.317290 --> 1.309694).  Saving model ...
Validation loss decreased (1.309694 --> 1.302212).  Saving model ...
Validation loss decreased (1.302212 --> 1.294773).  Saving model ...
Validation loss decreased (1.294773 --> 1.287100).  Saving model ...
Validation loss decreased (1.287100 --> 1.278098).  Saving model ...
Validation loss decreased (1.278098 --> 1.268363).  Saving model ...
Validation loss decreased (1.268363 --> 1.259055).  Saving model ...
Validation loss decreased (1.259055 --> 1.248916).  Saving model ...
Validation loss decreased (1.248916 --> 1.240093).  Saving model ...
Validation loss decreased (1.240093 --> 1.230773).  Saving model ...
Validation loss decreased (1.230773 --> 1.220889).  Saving model ...
Validation loss decreased (1.220889 --> 1.213032).  Saving model ...
Validation loss decreased (1.213032 --> 1.205970).  Saving model ...
Validation loss decreased (1.205970 --> 1.198477).  Saving model ...
Validation loss decreased (1.198477 --> 1.191305).  Saving model ...
Validation loss decreased (1.191305 --> 1.184808).  Saving model ...
Validation loss decreased (1.184808 --> 1.178177).  Saving model ...
Validation loss decreased (1.178177 --> 1.172190).  Saving model ...
Validation loss decreased (1.172190 --> 1.166769).  Saving model ...
Validation loss decreased (1.166769 --> 1.160156).  Saving model ...
Validation loss decreased (1.160156 --> 1.154216).  Saving model ...
Validation loss decreased (1.154216 --> 1.149294).  Saving model ...
Validation loss decreased (1.149294 --> 1.144280).  Saving model ...
Validation loss decreased (1.144280 --> 1.137505).  Saving model ...
Validation loss decreased (1.137505 --> 1.130965).  Saving model ...
Validation loss decreased (1.130965 --> 1.125020).  Saving model ...
Validation loss decreased (1.125020 --> 1.119569).  Saving model ...
Validation loss decreased (1.119569 --> 1.114602).  Saving model ...
Validation loss decreased (1.114602 --> 1.110106).  Saving model ...
Validation loss decreased (1.110106 --> 1.105992).  Saving model ...
Validation loss decreased (1.105992 --> 1.102172).  Saving model ...
Validation loss decreased (1.102172 --> 1.096154).  Saving model ...
Validation loss decreased (1.096154 --> 1.090949).  Saving model ...
Validation loss decreased (1.090949 --> 1.085339).  Saving model ...
Validation loss decreased (1.085339 --> 1.082159).  Saving model ...
Validation loss decreased (1.082159 --> 1.076632).  Saving model ...
Validation loss decreased (1.076632 --> 1.072694).  Saving model ...
Validation loss decreased (1.072694 --> 1.069367).  Saving model ...
Validation loss decreased (1.069367 --> 1.064787).  Saving model ...
Validation loss decreased (1.064787 --> 1.060851).  Saving model ...
Validation loss decreased (1.060851 --> 1.057988).  Saving model ...
Validation loss decreased (1.057988 --> 1.052964).  Saving model ...
Validation loss decreased (1.052964 --> 1.051060).  Saving model ...
Validation loss decreased (1.051060 --> 1.048854).  Saving model ...
Validation loss decreased (1.048854 --> 1.043091).  Saving model ...
Validation loss decreased (1.043091 --> 1.041637).  Saving model ...
Validation loss decreased (1.041637 --> 1.036942).  Saving model ...
Validation loss decreased (1.036942 --> 1.032505).  Saving model ...
Validation loss decreased (1.032505 --> 1.030531).  Saving model ...
Validation loss decreased (1.030531 --> 1.028015).  Saving model ...
Validation loss decreased (1.028015 --> 1.026023).  Saving model ...
Validation loss decreased (1.026023 --> 1.021071).  Saving model ...
Validation loss decreased (1.021071 --> 1.017675).  Saving model ...
Validation loss decreased (1.017675 --> 1.014999).  Saving model ...
Validation loss decreased (1.014999 --> 1.009197).  Saving model ...
Validation loss decreased (1.009197 --> 1.008423).  Saving model ...
Validation loss decreased (1.008423 --> 1.005340).  Saving model ...
Validation loss decreased (1.005340 --> 1.002961).  Saving model ...
Validation loss decreased (1.002961 --> 0.999826).  Saving model ...
Validation loss decreased (0.999826 --> 0.995305).  Saving model ...
Validation loss decreased (0.995305 --> 0.995242).  Saving model ...
Validation loss decreased (0.995242 --> 0.993047).  Saving model ...
Validation loss decreased (0.993047 --> 0.991238).  Saving model ...
Validation loss decreased (0.991238 --> 0.988418).  Saving model ...
Validation loss decreased (0.988418 --> 0.986348).  Saving model ...
Validation loss decreased (0.986348 --> 0.984224).  Saving model ...
Validation loss decreased (0.984224 --> 0.980769).  Saving model ...
Validation loss decreased (0.980769 --> 0.980038).  Saving model ...
Validation loss decreased (0.980038 --> 0.979004).  Saving model ...
Validation loss decreased (0.979004 --> 0.977446).  Saving model ...
Validation loss decreased (0.977446 --> 0.975640).  Saving model ...
Validation loss decreased (0.975640 --> 0.974095).  Saving model ...
Validation loss decreased (0.974095 --> 0.972400).  Saving model ...
Validation loss decreased (0.972400 --> 0.970101).  Saving model ...
Validation loss decreased (0.970101 --> 0.968243).  Saving model ...
Validation loss decreased (0.968243 --> 0.967373).  Saving model ...
Validation loss decreased (0.967373 --> 0.966566).  Saving model ...
Validation loss decreased (0.966566 --> 0.964823).  Saving model ...
Validation loss decreased (0.964823 --> 0.964124).  Saving model ...
Validation loss decreased (0.964124 --> 0.963946).  Saving model ...
EarlyStopping counter: 1 out of 10.0
Validation loss decreased (0.963946 --> 0.961560).  Saving model ...
Validation loss decreased (0.961560 --> 0.960678).  Saving model ...
Validation loss decreased (0.960678 --> 0.957776).  Saving model ...
Validation loss decreased (0.957776 --> 0.957581).  Saving model ...
EarlyStopping counter: 1 out of 10.0
EarlyStopping counter: 2 out of 10.0
Validation loss decreased (0.957581 --> 0.955114).  Saving model ...
Validation loss decreased (0.955114 --> 0.952789).  Saving model ...
Validation loss decreased (0.952789 --> 0.951815).  Saving model ...
EarlyStopping counter: 1 out of 10.0
EarlyStopping counter: 2 out of 10.0
EarlyStopping counter: 3 out of 10.0
Validation loss decreased (0.951815 --> 0.950847).  Saving model ...
Validation loss decreased (0.950847 --> 0.949478).  Saving model ...
Validation loss decreased (0.949478 --> 0.947704).  Saving model ...
Validation loss decreased (0.947704 --> 0.947080).  Saving model ...
Validation loss decreased (0.947080 --> 0.946384).  Saving model ...
Validation loss decreased (0.946384 --> 0.943880).  Saving model ...
EarlyStopping counter: 1 out of 10.0
EarlyStopping counter: 2 out of 10.0
EarlyStopping counter: 3 out of 10.0
EarlyStopping counter: 4 out of 10.0
EarlyStopping counter: 5 out of 10.0
EarlyStopping counter: 6 out of 10.0
EarlyStopping counter: 7 out of 10.0
Validation loss decreased (0.943880 --> 0.943161).  Saving model ...
Validation loss decreased (0.943161 --> 0.941773).  Saving model ...
EarlyStopping counter: 1 out of 10.0
EarlyStopping counter: 2 out of 10.0
EarlyStopping counter: 3 out of 10.0
EarlyStopping counter: 4 out of 10.0
EarlyStopping counter: 5 out of 10.0
EarlyStopping counter: 6 out of 10.0
Validation loss decreased (0.941773 --> 0.939831).  Saving model ...
EarlyStopping counter: 1 out of 10.0
EarlyStopping counter: 2 out of 10.0
EarlyStopping counter: 3 out of 10.0
EarlyStopping counter: 4 out of 10.0
EarlyStopping counter: 5 out of 10.0
EarlyStopping counter: 6 out of 10.0
EarlyStopping counter: 7 out of 10.0
EarlyStopping counter: 8 out of 10.0
EarlyStopping counter: 9 out of 10.0
Validation loss decreased (0.939831 --> 0.939464).  Saving model ...
EarlyStopping counter: 1 out of 10.0
EarlyStopping counter: 2 out of 10.0
EarlyStopping counter: 3 out of 10.0
EarlyStopping counter: 4 out of 10.0
EarlyStopping counter: 5 out of 10.0
EarlyStopping counter: 6 out of 10.0
EarlyStopping counter: 7 out of 10.0
EarlyStopping counter: 8 out of 10.0
EarlyStopping counter: 9 out of 10.0
EarlyStopping counter: 10 out of 10.0
/localscratch/yinan.29019297.0/env/lib/python3.7/site-packages/torch/nn/functional.py:1794: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.
  warnings.warn("nn.functional.tanh is deprecated. Use torch.tanh instead.")
wandb: Waiting for W&B process to finish, PID 242053... (success).
wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: \ 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: | 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: / 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: \ 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: | 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: / 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: \ 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: | 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb:                                                                                
wandb: Run history:
wandb:     e_F1 ▁▁▃▄▅▅▆▆▆▆▆▇▇▇▇▇▇▇▇▇▇███████████████████
wandb:   e_loss ██▇▇▇▆▆▅▅▄▄▄▃▃▃▃▂▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:     t_F1 ▁▁▂▃▃▃▄▄▅▅▅▅▆▆▆▆▆▆▇▆▇▇▆▇▇▇▇▇▇▇▇▇█▇▇█████
wandb:   t_loss ██▇▇▇▇▆▆▆▅▅▅▅▅▄▄▄▄▄▃▃▃▃▃▃▃▂▂▂▂▂▂▂▂▂▂▁▁▁▁
wandb: 
wandb: Run summary:
wandb:     e_F1 58.63766
wandb:   e_loss 0.94862
wandb:     t_F1 75.20723
wandb:   t_loss 0.67997
wandb: 
wandb: Synced 4 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Synced still-dream-1: https://wandb.ai/yinanazhou/xl_512_bs_8_lr_1e06_es_10_lc_False_nr_False_sr_False_stem_False_lemma_True_repeat_4_fold_1/runs/114gwomg
wandb: Find logs at: ./wandb/run-20220319_033458-114gwomg/logs/debug.log
wandb: 

wandb: wandb version 0.12.11 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
2022-03-19 05:16:55.507994: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1
wandb: Tracking run with wandb version 0.12.5
wandb: Syncing run prime-pond-1
wandb: ⭐️ View project at https://wandb.ai/yinanazhou/xl_512_bs_8_lr_1e06_es_10_lc_False_nr_False_sr_False_stem_False_lemma_True_repeat_4_fold_2
wandb: 🚀 View run at https://wandb.ai/yinanazhou/xl_512_bs_8_lr_1e06_es_10_lc_False_nr_False_sr_False_stem_False_lemma_True_repeat_4_fold_2/runs/8hen3bps
wandb: Run data is saved locally in /project/6002780/yinan/Thesis_MER_Lyrics/lyric-emotion/wandb/run-20220319_051652-8hen3bps
wandb: Run `wandb offline` to turn off syncing.

Validation loss decreased (inf --> 1.438694).  Saving model ...
Validation loss decreased (1.438694 --> 1.423604).  Saving model ...
Validation loss decreased (1.423604 --> 1.412159).  Saving model ...
Validation loss decreased (1.412159 --> 1.402462).  Saving model ...
Validation loss decreased (1.402462 --> 1.394429).  Saving model ...
Validation loss decreased (1.394429 --> 1.387079).  Saving model ...
Validation loss decreased (1.387079 --> 1.380064).  Saving model ...
Validation loss decreased (1.380064 --> 1.373325).  Saving model ...
Validation loss decreased (1.373325 --> 1.367167).  Saving model ...
Validation loss decreased (1.367167 --> 1.360814).  Saving model ...
Validation loss decreased (1.360814 --> 1.354297).  Saving model ...
Validation loss decreased (1.354297 --> 1.347317).  Saving model ...
Validation loss decreased (1.347317 --> 1.340800).  Saving model ...
Validation loss decreased (1.340800 --> 1.334019).  Saving model ...
Validation loss decreased (1.334019 --> 1.325864).  Saving model ...
Validation loss decreased (1.325864 --> 1.317411).  Saving model ...
Validation loss decreased (1.317411 --> 1.309271).  Saving model ...
Validation loss decreased (1.309271 --> 1.300450).  Saving model ...
Validation loss decreased (1.300450 --> 1.292687).  Saving model ...
Validation loss decreased (1.292687 --> 1.284092).  Saving model ...
Validation loss decreased (1.284092 --> 1.274280).  Saving model ...
Validation loss decreased (1.274280 --> 1.266357).  Saving model ...
Validation loss decreased (1.266357 --> 1.255798).  Saving model ...
Validation loss decreased (1.255798 --> 1.247467).  Saving model ...
Validation loss decreased (1.247467 --> 1.240611).  Saving model ...
Validation loss decreased (1.240611 --> 1.232279).  Saving model ...
Validation loss decreased (1.232279 --> 1.223553).  Saving model ...
Validation loss decreased (1.223553 --> 1.214437).  Saving model ...
Validation loss decreased (1.214437 --> 1.205888).  Saving model ...
Validation loss decreased (1.205888 --> 1.197964).  Saving model ...
Validation loss decreased (1.197964 --> 1.189256).  Saving model ...
Validation loss decreased (1.189256 --> 1.182258).  Saving model ...
Validation loss decreased (1.182258 --> 1.173049).  Saving model ...
Validation loss decreased (1.173049 --> 1.164205).  Saving model ...
Validation loss decreased (1.164205 --> 1.156680).  Saving model ...
Validation loss decreased (1.156680 --> 1.149085).  Saving model ...
Validation loss decreased (1.149085 --> 1.142114).  Saving model ...
Validation loss decreased (1.142114 --> 1.134804).  Saving model ...
Validation loss decreased (1.134804 --> 1.126149).  Saving model ...
Validation loss decreased (1.126149 --> 1.119589).  Saving model ...
Validation loss decreased (1.119589 --> 1.113548).  Saving model ...
Validation loss decreased (1.113548 --> 1.105568).  Saving model ...
Validation loss decreased (1.105568 --> 1.097486).  Saving model ...
Validation loss decreased (1.097486 --> 1.091171).  Saving model ...
Validation loss decreased (1.091171 --> 1.087020).  Saving model ...
Validation loss decreased (1.087020 --> 1.082800).  Saving model ...
Validation loss decreased (1.082800 --> 1.075358).  Saving model ...
Validation loss decreased (1.075358 --> 1.069662).  Saving model ...
Validation loss decreased (1.069662 --> 1.063810).  Saving model ...
Validation loss decreased (1.063810 --> 1.060046).  Saving model ...
Validation loss decreased (1.060046 --> 1.052410).  Saving model ...
Validation loss decreased (1.052410 --> 1.047762).  Saving model ...
Validation loss decreased (1.047762 --> 1.044400).  Saving model ...
Validation loss decreased (1.044400 --> 1.039376).  Saving model ...
Validation loss decreased (1.039376 --> 1.033443).  Saving model ...
Validation loss decreased (1.033443 --> 1.029747).  Saving model ...
Validation loss decreased (1.029747 --> 1.024852).  Saving model ...
Validation loss decreased (1.024852 --> 1.021160).  Saving model ...
Validation loss decreased (1.021160 --> 1.020031).  Saving model ...
Validation loss decreased (1.020031 --> 1.015137).  Saving model ...
Validation loss decreased (1.015137 --> 1.012065).  Saving model ...
Validation loss decreased (1.012065 --> 1.008000).  Saving model ...
Validation loss decreased (1.008000 --> 1.004594).  Saving model ...
Validation loss decreased (1.004594 --> 1.001878).  Saving model ...
Validation loss decreased (1.001878 --> 0.997091).  Saving model ...
Validation loss decreased (0.997091 --> 0.993774).  Saving model ...
Validation loss decreased (0.993774 --> 0.991715).  Saving model ...
Validation loss decreased (0.991715 --> 0.986153).  Saving model ...
Validation loss decreased (0.986153 --> 0.982534).  Saving model ...
Validation loss decreased (0.982534 --> 0.981105).  Saving model ...
Validation loss decreased (0.981105 --> 0.978644).  Saving model ...
Validation loss decreased (0.978644 --> 0.977930).  Saving model ...
Validation loss decreased (0.977930 --> 0.974663).  Saving model ...
Validation loss decreased (0.974663 --> 0.971535).  Saving model ...
Validation loss decreased (0.971535 --> 0.968288).  Saving model ...
Validation loss decreased (0.968288 --> 0.967294).  Saving model ...
Validation loss decreased (0.967294 --> 0.963569).  Saving model ...
Validation loss decreased (0.963569 --> 0.961085).  Saving model ...
Validation loss decreased (0.961085 --> 0.959883).  Saving model ...
Validation loss decreased (0.959883 --> 0.958491).  Saving model ...
Validation loss decreased (0.958491 --> 0.954379).  Saving model ...
Validation loss decreased (0.954379 --> 0.953319).  Saving model ...
Validation loss decreased (0.953319 --> 0.950921).  Saving model ...
Validation loss decreased (0.950921 --> 0.950029).  Saving model ...
EarlyStopping counter: 1 out of 10.0
Validation loss decreased (0.950029 --> 0.947063).  Saving model ...
Validation loss decreased (0.947063 --> 0.946196).  Saving model ...
Validation loss decreased (0.946196 --> 0.944556).  Saving model ...
Validation loss decreased (0.944556 --> 0.943806).  Saving model ...
Validation loss decreased (0.943806 --> 0.942045).  Saving model ...
Validation loss decreased (0.942045 --> 0.937587).  Saving model ...
EarlyStopping counter: 1 out of 10.0
Validation loss decreased (0.937587 --> 0.936486).  Saving model ...
EarlyStopping counter: 1 out of 10.0
EarlyStopping counter: 2 out of 10.0
Validation loss decreased (0.936486 --> 0.935536).  Saving model ...
Validation loss decreased (0.935536 --> 0.932953).  Saving model ...
Validation loss decreased (0.932953 --> 0.932582).  Saving model ...
EarlyStopping counter: 1 out of 10.0
EarlyStopping counter: 2 out of 10.0
Validation loss decreased (0.932582 --> 0.930087).  Saving model ...
Validation loss decreased (0.930087 --> 0.928387).  Saving model ...
Validation loss decreased (0.928387 --> 0.925278).  Saving model ...
EarlyStopping counter: 1 out of 10.0
EarlyStopping counter: 2 out of 10.0
Validation loss decreased (0.925278 --> 0.925234).  Saving model ...
EarlyStopping counter: 1 out of 10.0
EarlyStopping counter: 2 out of 10.0
EarlyStopping counter: 3 out of 10.0
Validation loss decreased (0.925234 --> 0.924991).  Saving model ...
EarlyStopping counter: 1 out of 10.0
Validation loss decreased (0.924991 --> 0.924684).  Saving model ...
EarlyStopping counter: 1 out of 10.0
Validation loss decreased (0.924684 --> 0.924313).  Saving model ...
Validation loss decreased (0.924313 --> 0.921921).  Saving model ...
Validation loss decreased (0.921921 --> 0.921757).  Saving model ...
Validation loss decreased (0.921757 --> 0.921378).  Saving model ...
EarlyStopping counter: 1 out of 10.0
EarlyStopping counter: 2 out of 10.0
EarlyStopping counter: 3 out of 10.0
EarlyStopping counter: 4 out of 10.0
EarlyStopping counter: 5 out of 10.0
EarlyStopping counter: 6 out of 10.0
EarlyStopping counter: 7 out of 10.0
EarlyStopping counter: 8 out of 10.0
EarlyStopping counter: 9 out of 10.0
EarlyStopping counter: 10 out of 10.0
/localscratch/yinan.29019297.0/env/lib/python3.7/site-packages/torch/nn/functional.py:1794: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.
  warnings.warn("nn.functional.tanh is deprecated. Use torch.tanh instead.")
wandb: Waiting for W&B process to finish, PID 247543... (success).
wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: \ 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: | 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: / 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: \ 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: | 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: / 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: \ 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: | 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: / 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb:                                                                                
wandb: Run history:
wandb:     e_F1 ▁▃▃▂▃▄▄▅▅▆▆▆▆▆▆▇▇▇▇▇▇▇▇▇▇█▇▇████████████
wandb:   e_loss ██▇▇▇▆▆▆▅▅▄▄▄▃▃▃▃▃▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:     t_F1 ▁▁▂▂▃▄▃▅▄▅▅▅▅▆▆▆▆▆▆▇▆▇▇▇▇▇▇▇▇▇█▇████████
wandb:   t_loss ██▇▇▇▇▇▆▆▆▅▅▅▅▅▄▄▄▄▄▄▃▃▃▃▃▃▂▂▂▂▂▂▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:     e_F1 62.77122
wandb:   e_loss 0.92813
wandb:     t_F1 71.28539
wandb:   t_loss 0.73621
wandb: 
wandb: Synced 4 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Synced prime-pond-1: https://wandb.ai/yinanazhou/xl_512_bs_8_lr_1e06_es_10_lc_False_nr_False_sr_False_stem_False_lemma_True_repeat_4_fold_2/runs/8hen3bps
wandb: Find logs at: ./wandb/run-20220319_051652-8hen3bps/logs/debug.log
wandb: 

wandb: wandb version 0.12.11 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
2022-03-19 06:39:17.074565: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1
wandb: Tracking run with wandb version 0.12.5
wandb: Syncing run breezy-oath-1
wandb: ⭐️ View project at https://wandb.ai/yinanazhou/xl_512_bs_8_lr_1e06_es_10_lc_False_nr_False_sr_False_stem_False_lemma_True_repeat_5_fold_1
wandb: 🚀 View run at https://wandb.ai/yinanazhou/xl_512_bs_8_lr_1e06_es_10_lc_False_nr_False_sr_False_stem_False_lemma_True_repeat_5_fold_1/runs/3fgp8dca
wandb: Run data is saved locally in /project/6002780/yinan/Thesis_MER_Lyrics/lyric-emotion/wandb/run-20220319_063913-3fgp8dca
wandb: Run `wandb offline` to turn off syncing.

Validation loss decreased (inf --> 1.389775).  Saving model ...
Validation loss decreased (1.389775 --> 1.382607).  Saving model ...
Validation loss decreased (1.382607 --> 1.376587).  Saving model ...
Validation loss decreased (1.376587 --> 1.371487).  Saving model ...
Validation loss decreased (1.371487 --> 1.367063).  Saving model ...
Validation loss decreased (1.367063 --> 1.362536).  Saving model ...
Validation loss decreased (1.362536 --> 1.358584).  Saving model ...
Validation loss decreased (1.358584 --> 1.354203).  Saving model ...
Validation loss decreased (1.354203 --> 1.349947).  Saving model ...
Validation loss decreased (1.349947 --> 1.345686).  Saving model ...
Validation loss decreased (1.345686 --> 1.341385).  Saving model ...
Validation loss decreased (1.341385 --> 1.336695).  Saving model ...
Validation loss decreased (1.336695 --> 1.332043).  Saving model ...
Validation loss decreased (1.332043 --> 1.326910).  Saving model ...
Validation loss decreased (1.326910 --> 1.322148).  Saving model ...
Validation loss decreased (1.322148 --> 1.317093).  Saving model ...
Validation loss decreased (1.317093 --> 1.311080).  Saving model ...
Validation loss decreased (1.311080 --> 1.305815).  Saving model ...
Validation loss decreased (1.305815 --> 1.299596).  Saving model ...
Validation loss decreased (1.299596 --> 1.293564).  Saving model ...
Validation loss decreased (1.293564 --> 1.286712).  Saving model ...
Validation loss decreased (1.286712 --> 1.279635).  Saving model ...
Validation loss decreased (1.279635 --> 1.273256).  Saving model ...
Validation loss decreased (1.273256 --> 1.265285).  Saving model ...
Validation loss decreased (1.265285 --> 1.257739).  Saving model ...
Validation loss decreased (1.257739 --> 1.251313).  Saving model ...
Validation loss decreased (1.251313 --> 1.244503).  Saving model ...
Validation loss decreased (1.244503 --> 1.237178).  Saving model ...
Validation loss decreased (1.237178 --> 1.230533).  Saving model ...
Validation loss decreased (1.230533 --> 1.222895).  Saving model ...
Validation loss decreased (1.222895 --> 1.216482).  Saving model ...
Validation loss decreased (1.216482 --> 1.210006).  Saving model ...
Validation loss decreased (1.210006 --> 1.203115).  Saving model ...
Validation loss decreased (1.203115 --> 1.194868).  Saving model ...
Validation loss decreased (1.194868 --> 1.187973).  Saving model ...
Validation loss decreased (1.187973 --> 1.181031).  Saving model ...
Validation loss decreased (1.181031 --> 1.175049).  Saving model ...
Validation loss decreased (1.175049 --> 1.168987).  Saving model ...
Validation loss decreased (1.168987 --> 1.162197).  Saving model ...
Validation loss decreased (1.162197 --> 1.157057).  Saving model ...
Validation loss decreased (1.157057 --> 1.150743).  Saving model ...
Validation loss decreased (1.150743 --> 1.146706).  Saving model ...
Validation loss decreased (1.146706 --> 1.140973).  Saving model ...
Validation loss decreased (1.140973 --> 1.133915).  Saving model ...
Validation loss decreased (1.133915 --> 1.125986).  Saving model ...
Validation loss decreased (1.125986 --> 1.122757).  Saving model ...
Validation loss decreased (1.122757 --> 1.116837).  Saving model ...
Validation loss decreased (1.116837 --> 1.112667).  Saving model ...
Validation loss decreased (1.112667 --> 1.106930).  Saving model ...
Validation loss decreased (1.106930 --> 1.101770).  Saving model ...
Validation loss decreased (1.101770 --> 1.096454).  Saving model ...
Validation loss decreased (1.096454 --> 1.091196).  Saving model ...
Validation loss decreased (1.091196 --> 1.085757).  Saving model ...
Validation loss decreased (1.085757 --> 1.080236).  Saving model ...
Validation loss decreased (1.080236 --> 1.075606).  Saving model ...
Validation loss decreased (1.075606 --> 1.070520).  Saving model ...
Validation loss decreased (1.070520 --> 1.065025).  Saving model ...
Validation loss decreased (1.065025 --> 1.060120).  Saving model ...
Validation loss decreased (1.060120 --> 1.055604).  Saving model ...
Validation loss decreased (1.055604 --> 1.053098).  Saving model ...
Validation loss decreased (1.053098 --> 1.048399).  Saving model ...
Validation loss decreased (1.048399 --> 1.044786).  Saving model ...
Validation loss decreased (1.044786 --> 1.040632).  Saving model ...
Validation loss decreased (1.040632 --> 1.035076).  Saving model ...
Validation loss decreased (1.035076 --> 1.032493).  Saving model ...
Validation loss decreased (1.032493 --> 1.028212).  Saving model ...
Validation loss decreased (1.028212 --> 1.024201).  Saving model ...
Validation loss decreased (1.024201 --> 1.021410).  Saving model ...
Validation loss decreased (1.021410 --> 1.015796).  Saving model ...
Validation loss decreased (1.015796 --> 1.013132).  Saving model ...
Validation loss decreased (1.013132 --> 1.008479).  Saving model ...
Validation loss decreased (1.008479 --> 1.004140).  Saving model ...
Validation loss decreased (1.004140 --> 0.999873).  Saving model ...
Validation loss decreased (0.999873 --> 0.996904).  Saving model ...
Validation loss decreased (0.996904 --> 0.993310).  Saving model ...
Validation loss decreased (0.993310 --> 0.989832).  Saving model ...
Validation loss decreased (0.989832 --> 0.985367).  Saving model ...
Validation loss decreased (0.985367 --> 0.981668).  Saving model ...
Validation loss decreased (0.981668 --> 0.978676).  Saving model ...
Validation loss decreased (0.978676 --> 0.974626).  Saving model ...
Validation loss decreased (0.974626 --> 0.971724).  Saving model ...
Validation loss decreased (0.971724 --> 0.968657).  Saving model ...
Validation loss decreased (0.968657 --> 0.966310).  Saving model ...
Validation loss decreased (0.966310 --> 0.964101).  Saving model ...
Validation loss decreased (0.964101 --> 0.962200).  Saving model ...
Validation loss decreased (0.962200 --> 0.958998).  Saving model ...
Validation loss decreased (0.958998 --> 0.955932).  Saving model ...
Validation loss decreased (0.955932 --> 0.955853).  Saving model ...
Validation loss decreased (0.955853 --> 0.953465).  Saving model ...
Validation loss decreased (0.953465 --> 0.950021).  Saving model ...
Validation loss decreased (0.950021 --> 0.947727).  Saving model ...
Validation loss decreased (0.947727 --> 0.945798).  Saving model ...
Validation loss decreased (0.945798 --> 0.942763).  Saving model ...
Validation loss decreased (0.942763 --> 0.941181).  Saving model ...
Validation loss decreased (0.941181 --> 0.938882).  Saving model ...
Validation loss decreased (0.938882 --> 0.938108).  Saving model ...
Validation loss decreased (0.938108 --> 0.935766).  Saving model ...
Validation loss decreased (0.935766 --> 0.934328).  Saving model ...
Validation loss decreased (0.934328 --> 0.933476).  Saving model ...
EarlyStopping counter: 1 out of 10.0
Validation loss decreased (0.933476 --> 0.930668).  Saving model ...
Validation loss decreased (0.930668 --> 0.929817).  Saving model ...
Validation loss decreased (0.929817 --> 0.928010).  Saving model ...
Validation loss decreased (0.928010 --> 0.925710).  Saving model ...
Validation loss decreased (0.925710 --> 0.925480).  Saving model ...
Validation loss decreased (0.925480 --> 0.923364).  Saving model ...
Validation loss decreased (0.923364 --> 0.922433).  Saving model ...
Validation loss decreased (0.922433 --> 0.922040).  Saving model ...
Validation loss decreased (0.922040 --> 0.920661).  Saving model ...
Validation loss decreased (0.920661 --> 0.918646).  Saving model ...
Validation loss decreased (0.918646 --> 0.916888).  Saving model ...
Validation loss decreased (0.916888 --> 0.916438).  Saving model ...
Validation loss decreased (0.916438 --> 0.915140).  Saving model ...
Validation loss decreased (0.915140 --> 0.914642).  Saving model ...
Validation loss decreased (0.914642 --> 0.913151).  Saving model ...
Validation loss decreased (0.913151 --> 0.912194).  Saving model ...
Validation loss decreased (0.912194 --> 0.911727).  Saving model ...
EarlyStopping counter: 1 out of 10.0
EarlyStopping counter: 2 out of 10.0
Validation loss decreased (0.911727 --> 0.911211).  Saving model ...
Validation loss decreased (0.911211 --> 0.910470).  Saving model ...
Validation loss decreased (0.910470 --> 0.909491).  Saving model ...
Validation loss decreased (0.909491 --> 0.909144).  Saving model ...
Validation loss decreased (0.909144 --> 0.908405).  Saving model ...
Validation loss decreased (0.908405 --> 0.908329).  Saving model ...
Validation loss decreased (0.908329 --> 0.907731).  Saving model ...
EarlyStopping counter: 1 out of 10.0
EarlyStopping counter: 2 out of 10.0
EarlyStopping counter: 3 out of 10.0
EarlyStopping counter: 4 out of 10.0
EarlyStopping counter: 5 out of 10.0
Validation loss decreased (0.907731 --> 0.907546).  Saving model ...
Validation loss decreased (0.907546 --> 0.907468).  Saving model ...
Validation loss decreased (0.907468 --> 0.907456).  Saving model ...
EarlyStopping counter: 1 out of 10.0
EarlyStopping counter: 2 out of 10.0
EarlyStopping counter: 3 out of 10.0
EarlyStopping counter: 4 out of 10.0
EarlyStopping counter: 5 out of 10.0
EarlyStopping counter: 6 out of 10.0
EarlyStopping counter: 7 out of 10.0
EarlyStopping counter: 8 out of 10.0
EarlyStopping counter: 9 out of 10.0
EarlyStopping counter: 10 out of 10.0
/localscratch/yinan.29019297.0/env/lib/python3.7/site-packages/torch/nn/functional.py:1794: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.
  warnings.warn("nn.functional.tanh is deprecated. Use torch.tanh instead.")
wandb: Waiting for W&B process to finish, PID 251963... (success).
wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: \ 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: | 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: / 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: \ 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: | 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: / 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: \ 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: | 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: / 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb:                                                                                
wandb: Run history:
wandb:     e_F1 ▁▂▃▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▆▆▇▇▇▇▇▇▇▇▇███████████
wandb:   e_loss ███▇▇▇▆▆▆▅▅▅▄▄▄▃▃▃▃▃▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:     t_F1 ▁▁▂▂▂▂▃▄▅▄▄▅▅▆▅▅▆▆▆▆▆▆▇▇▇▇▇▇▇▇▇▇█▇██████
wandb:   t_loss ████▇▇▇▇▆▆▆▆▅▅▅▅▄▄▄▄▄▄▃▃▃▃▃▃▃▂▂▂▂▂▂▂▂▁▁▁
wandb: 
wandb: Run summary:
wandb:     e_F1 64.13888
wandb:   e_loss 0.90864
wandb:     t_F1 74.68289
wandb:   t_loss 0.67582
wandb: 
wandb: Synced 4 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Synced breezy-oath-1: https://wandb.ai/yinanazhou/xl_512_bs_8_lr_1e06_es_10_lc_False_nr_False_sr_False_stem_False_lemma_True_repeat_5_fold_1/runs/3fgp8dca
wandb: Find logs at: ./wandb/run-20220319_063913-3fgp8dca/logs/debug.log
wandb: 

wandb: wandb version 0.12.11 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
2022-03-19 08:13:57.481503: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1
wandb: Tracking run with wandb version 0.12.5
wandb: Syncing run cool-yogurt-1
wandb: ⭐️ View project at https://wandb.ai/yinanazhou/xl_512_bs_8_lr_1e06_es_10_lc_False_nr_False_sr_False_stem_False_lemma_True_repeat_5_fold_2
wandb: 🚀 View run at https://wandb.ai/yinanazhou/xl_512_bs_8_lr_1e06_es_10_lc_False_nr_False_sr_False_stem_False_lemma_True_repeat_5_fold_2/runs/2g6k68j1
wandb: Run data is saved locally in /project/6002780/yinan/Thesis_MER_Lyrics/lyric-emotion/wandb/run-20220319_081354-2g6k68j1
wandb: Run `wandb offline` to turn off syncing.

Validation loss decreased (inf --> 1.402991).  Saving model ...
Validation loss decreased (1.402991 --> 1.394513).  Saving model ...
Validation loss decreased (1.394513 --> 1.387179).  Saving model ...
Validation loss decreased (1.387179 --> 1.380554).  Saving model ...
Validation loss decreased (1.380554 --> 1.374589).  Saving model ...
Validation loss decreased (1.374589 --> 1.369641).  Saving model ...
Validation loss decreased (1.369641 --> 1.364051).  Saving model ...
Validation loss decreased (1.364051 --> 1.358130).  Saving model ...
Validation loss decreased (1.358130 --> 1.352622).  Saving model ...
Validation loss decreased (1.352622 --> 1.346760).  Saving model ...
Validation loss decreased (1.346760 --> 1.341925).  Saving model ...
Validation loss decreased (1.341925 --> 1.336646).  Saving model ...
Validation loss decreased (1.336646 --> 1.330579).  Saving model ...
Validation loss decreased (1.330579 --> 1.324680).  Saving model ...
Validation loss decreased (1.324680 --> 1.318105).  Saving model ...
Validation loss decreased (1.318105 --> 1.311274).  Saving model ...
Validation loss decreased (1.311274 --> 1.303795).  Saving model ...
Validation loss decreased (1.303795 --> 1.296591).  Saving model ...
Validation loss decreased (1.296591 --> 1.290119).  Saving model ...
Validation loss decreased (1.290119 --> 1.283128).  Saving model ...
Validation loss decreased (1.283128 --> 1.275326).  Saving model ...
Validation loss decreased (1.275326 --> 1.267877).  Saving model ...
Validation loss decreased (1.267877 --> 1.260032).  Saving model ...
Validation loss decreased (1.260032 --> 1.251512).  Saving model ...
Validation loss decreased (1.251512 --> 1.243745).  Saving model ...
Validation loss decreased (1.243745 --> 1.235294).  Saving model ...
Validation loss decreased (1.235294 --> 1.226951).  Saving model ...
Validation loss decreased (1.226951 --> 1.219086).  Saving model ...
Validation loss decreased (1.219086 --> 1.211028).  Saving model ...
Validation loss decreased (1.211028 --> 1.203559).  Saving model ...
Validation loss decreased (1.203559 --> 1.195406).  Saving model ...
Validation loss decreased (1.195406 --> 1.186763).  Saving model ...
Validation loss decreased (1.186763 --> 1.179680).  Saving model ...
Validation loss decreased (1.179680 --> 1.170919).  Saving model ...
Validation loss decreased (1.170919 --> 1.162360).  Saving model ...
Validation loss decreased (1.162360 --> 1.153629).  Saving model ...
Validation loss decreased (1.153629 --> 1.147558).  Saving model ...
Validation loss decreased (1.147558 --> 1.139835).  Saving model ...
Validation loss decreased (1.139835 --> 1.132341).  Saving model ...
Validation loss decreased (1.132341 --> 1.123691).  Saving model ...
Validation loss decreased (1.123691 --> 1.117721).  Saving model ...
Validation loss decreased (1.117721 --> 1.111847).  Saving model ...
Validation loss decreased (1.111847 --> 1.104847).  Saving model ...
Validation loss decreased (1.104847 --> 1.097362).  Saving model ...
Validation loss decreased (1.097362 --> 1.092728).  Saving model ...
Validation loss decreased (1.092728 --> 1.087851).  Saving model ...
Validation loss decreased (1.087851 --> 1.081117).  Saving model ...
Validation loss decreased (1.081117 --> 1.074196).  Saving model ...
Validation loss decreased (1.074196 --> 1.072617).  Saving model ...
Validation loss decreased (1.072617 --> 1.067053).  Saving model ...
Validation loss decreased (1.067053 --> 1.063364).  Saving model ...
Validation loss decreased (1.063364 --> 1.057943).  Saving model ...
Validation loss decreased (1.057943 --> 1.054844).  Saving model ...
Validation loss decreased (1.054844 --> 1.048416).  Saving model ...
Validation loss decreased (1.048416 --> 1.044457).  Saving model ...
Validation loss decreased (1.044457 --> 1.040560).  Saving model ...
Validation loss decreased (1.040560 --> 1.036283).  Saving model ...
Validation loss decreased (1.036283 --> 1.033501).  Saving model ...
Validation loss decreased (1.033501 --> 1.031244).  Saving model ...
Validation loss decreased (1.031244 --> 1.028370).  Saving model ...
Validation loss decreased (1.028370 --> 1.024025).  Saving model ...
Validation loss decreased (1.024025 --> 1.022331).  Saving model ...
Validation loss decreased (1.022331 --> 1.018124).  Saving model ...
Validation loss decreased (1.018124 --> 1.014369).  Saving model ...
Validation loss decreased (1.014369 --> 1.010277).  Saving model ...
Validation loss decreased (1.010277 --> 1.006184).  Saving model ...
Validation loss decreased (1.006184 --> 1.003781).  Saving model ...
Validation loss decreased (1.003781 --> 1.001371).  Saving model ...
Validation loss decreased (1.001371 --> 0.997870).  Saving model ...
Validation loss decreased (0.997870 --> 0.995764).  Saving model ...
Validation loss decreased (0.995764 --> 0.994645).  Saving model ...
Validation loss decreased (0.994645 --> 0.992117).  Saving model ...
Validation loss decreased (0.992117 --> 0.990589).  Saving model ...
Validation loss decreased (0.990589 --> 0.988647).  Saving model ...
Validation loss decreased (0.988647 --> 0.987424).  Saving model ...
Validation loss decreased (0.987424 --> 0.984909).  Saving model ...
Validation loss decreased (0.984909 --> 0.980510).  Saving model ...
Validation loss decreased (0.980510 --> 0.976420).  Saving model ...
Validation loss decreased (0.976420 --> 0.974217).  Saving model ...
EarlyStopping counter: 1 out of 10.0
Validation loss decreased (0.974217 --> 0.973292).  Saving model ...
Validation loss decreased (0.973292 --> 0.967846).  Saving model ...
Validation loss decreased (0.967846 --> 0.964882).  Saving model ...
EarlyStopping counter: 1 out of 10.0
EarlyStopping counter: 2 out of 10.0
Validation loss decreased (0.964882 --> 0.963956).  Saving model ...
Validation loss decreased (0.963956 --> 0.962546).  Saving model ...
Validation loss decreased (0.962546 --> 0.960981).  Saving model ...
Validation loss decreased (0.960981 --> 0.960202).  Saving model ...
Validation loss decreased (0.960202 --> 0.959442).  Saving model ...
Validation loss decreased (0.959442 --> 0.956599).  Saving model ...
Validation loss decreased (0.956599 --> 0.955847).  Saving model ...
Validation loss decreased (0.955847 --> 0.954931).  Saving model ...
Validation loss decreased (0.954931 --> 0.952261).  Saving model ...
Validation loss decreased (0.952261 --> 0.950802).  Saving model ...
Validation loss decreased (0.950802 --> 0.948315).  Saving model ...
Validation loss decreased (0.948315 --> 0.947143).  Saving model ...
EarlyStopping counter: 1 out of 10.0
Validation loss decreased (0.947143 --> 0.946738).  Saving model ...
Validation loss decreased (0.946738 --> 0.945878).  Saving model ...
Validation loss decreased (0.945878 --> 0.941937).  Saving model ...
EarlyStopping counter: 1 out of 10.0
EarlyStopping counter: 2 out of 10.0
EarlyStopping counter: 3 out of 10.0
EarlyStopping counter: 4 out of 10.0
EarlyStopping counter: 5 out of 10.0
EarlyStopping counter: 6 out of 10.0
EarlyStopping counter: 7 out of 10.0
Validation loss decreased (0.941937 --> 0.938934).  Saving model ...
EarlyStopping counter: 1 out of 10.0
EarlyStopping counter: 2 out of 10.0
Validation loss decreased (0.938934 --> 0.938615).  Saving model ...
EarlyStopping counter: 1 out of 10.0
Validation loss decreased (0.938615 --> 0.937466).  Saving model ...
EarlyStopping counter: 1 out of 10.0
Validation loss decreased (0.937466 --> 0.936575).  Saving model ...
Validation loss decreased (0.936575 --> 0.936438).  Saving model ...
Validation loss decreased (0.936438 --> 0.934564).  Saving model ...
Validation loss decreased (0.934564 --> 0.933560).  Saving model ...
Validation loss decreased (0.933560 --> 0.932067).  Saving model ...
EarlyStopping counter: 1 out of 10.0
EarlyStopping counter: 2 out of 10.0
EarlyStopping counter: 3 out of 10.0
Validation loss decreased (0.932067 --> 0.930720).  Saving model ...
EarlyStopping counter: 1 out of 10.0
EarlyStopping counter: 2 out of 10.0
EarlyStopping counter: 3 out of 10.0
EarlyStopping counter: 4 out of 10.0
EarlyStopping counter: 5 out of 10.0
EarlyStopping counter: 6 out of 10.0
EarlyStopping counter: 7 out of 10.0
EarlyStopping counter: 8 out of 10.0
EarlyStopping counter: 9 out of 10.0
EarlyStopping counter: 10 out of 10.0
/localscratch/yinan.29019297.0/env/lib/python3.7/site-packages/torch/nn/functional.py:1794: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.
  warnings.warn("nn.functional.tanh is deprecated. Use torch.tanh instead.")
wandb: Waiting for W&B process to finish, PID 257090... (success).
wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: \ 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: | 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: / 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: \ 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: | 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: / 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: \ 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: | 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: / 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb:                                                                                
wandb: Run history:
wandb:     e_F1 ▁▂▃▄▄▅▅▅▆▆▆▆▇▇▇▇▇▇▇▇▇▇▇▇████████████████
wandb:   e_loss ██▇▇▇▇▆▆▅▅▅▄▄▃▃▃▃▃▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:     t_F1 ▁▁▂▂▃▄▄▄▄▄▅▆▅▆▆▆▆▆▇▆▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇███▇█
wandb:   t_loss ███▇▇▇▇▆▆▆▅▅▅▅▅▄▄▄▃▃▃▃▃▃▃▃▂▂▂▂▂▂▂▂▂▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:     e_F1 60.86205
wandb:   e_loss 0.934
wandb:     t_F1 73.84101
wandb:   t_loss 0.72327
wandb: 
wandb: Synced 4 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Synced cool-yogurt-1: https://wandb.ai/yinanazhou/xl_512_bs_8_lr_1e06_es_10_lc_False_nr_False_sr_False_stem_False_lemma_True_repeat_5_fold_2/runs/2g6k68j1
wandb: Find logs at: ./wandb/run-20220319_081354-2g6k68j1/logs/debug.log
wandb: 

