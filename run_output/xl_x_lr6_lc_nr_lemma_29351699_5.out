Unloading StdEnv/2020

Due to MODULEPATH changes, the following have been reloaded:
  1) mii/1.1.1


The following have been reloaded with a version change:
  1) python/3.8.2 => python/3.7.4

Using base prefix '/cvmfs/soft.computecanada.ca/easybuild/software/2017/Core/python/3.7.4'
New python executable in /localscratch/yinan.29365731.0/env/bin/python
Installing setuptools, pip, wheel...
done.
Ignoring pip: markers 'python_version < "3"' don't match your environment
Looking in links: /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/nix/avx2, /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/nix/generic, /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic
Collecting pip
Installing collected packages: pip
  Found existing installation: pip 19.1.1
    Uninstalling pip-19.1.1:
      Successfully uninstalled pip-19.1.1
Successfully installed pip-21.2.3+computecanada
Looking in links: /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/nix/avx2, /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/nix/generic, /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/keras-2.8.0+computecanada-py2.py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/Keras_Preprocessing-1.1.2+computecanada-py3-none-any.whl
Requirement already satisfied: matplotlib in /cvmfs/soft.computecanada.ca/easybuild/software/2017/Core/scipy-stack/2019a/lib/python3.7/site-packages (from -r requirements.txt (line 3)) (3.0.2)
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/nltk-3.6.5+computecanada-py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/scikit_learn-0.22.1+computecanada-cp37-cp37m-linux_x86_64.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/tensorboard-2.3.0+computecanada-py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/tensorboard_plugin_wit-1.7.0+computecanada-py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/tensorflow_gpu-2.3.0+computecanada-cp37-cp37m-linux_x86_64.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/tensorflow_estimator-2.3.0+computecanada-py2.py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/tokenizers-0.5.2+computecanada-cp37-cp37m-linux_x86_64.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/nix/avx2/torch-1.4.0+computecanada-cp37-cp37m-linux_x86_64.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/torchtext-0.6.0+computecanada-py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/torchvision-0.8.2+computecanada-cp37-cp37m-linux_x86_64.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/transformers-2.5.1+computecanada-py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/urllib3-1.26.7+computecanada-py2.py3-none-any.whl
ERROR: Could not find a version that satisfies the requirement regex>=2021.8.3 (from nltk) (from versions: 2018.1.10+computecanada, 2019.11.1+computecanada, 2020.11.13+computecanada)
ERROR: No matching distribution found for regex>=2021.8.3
Looking in links: /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/nix/avx2, /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/nix/generic, /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic
ERROR: Could not find a version that satisfies the requirement numpy==1.20.0+computacanada (from versions: 1.15.0+computecanada, 1.15.2+computecanada, 1.15.4+computecanada, 1.16.0+computecanada, 1.16.2+computecanada, 1.16.3+computecanada, 1.17.4+computecanada, 1.18.1+computecanada, 1.18.4+computecanada, 1.19.1+computecanada, 1.19.2+computecanada, 1.20.2+computecanada)
ERROR: No matching distribution found for numpy==1.20.0+computacanada
Looking in links: /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/nix/avx2, /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/nix/generic, /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/wandb-0.12.5+computecanada-py2.py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/promise-2.3+computecanada-py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/six-1.16.0+computecanada-py2.py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/protobuf-3.19.4+computecanada-py2.py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/shortuuid-1.0.1+computecanada-py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/sentry_sdk-1.5.0+computecanada-py2.py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/docker_pycreds-0.4.0+computecanada-py2.py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/configparser-5.0.2+computecanada-py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/yaspin-2.1.0+computecanada-py3-none-any.whl
Requirement already satisfied: requests<3,>=2.0.0 in /cvmfs/soft.computecanada.ca/easybuild/software/2017/Core/scipy-stack/2019a/lib/python3.7/site-packages (from wandb) (2.21.0)
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/click-8.0.4+computecanada-py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/psutil-5.7.3+computecanada-cp37-cp37m-linux_x86_64.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/PyYAML-5.3.1+computecanada-cp37-cp37m-linux_x86_64.whl
Requirement already satisfied: python-dateutil>=2.6.1 in /cvmfs/soft.computecanada.ca/easybuild/software/2017/Core/scipy-stack/2019a/lib/python3.7/site-packages (from wandb) (2.7.5)
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/GitPython-3.1.24+computecanada-py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/pathtools-0.1.2+computecanada-py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/subprocess32-3.5.4+computecanada-py3-none-any.whl
Requirement already satisfied: importlib-metadata in /cvmfs/soft.computecanada.ca/easybuild/software/2017/Core/scipy-stack/2019a/lib/python3.7/site-packages (from Click!=8.0.0,>=7.0->wandb) (0.8)
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/gitdb-4.0.9+computecanada-py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/typing_extensions-4.0.1+computecanada-py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/smmap-5.0.0+computecanada-py3-none-any.whl
Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /cvmfs/soft.computecanada.ca/easybuild/software/2017/Core/scipy-stack/2019a/lib/python3.7/site-packages (from requests<3,>=2.0.0->wandb) (3.0.4)
Requirement already satisfied: urllib3<1.25,>=1.21.1 in /cvmfs/soft.computecanada.ca/easybuild/software/2017/Core/scipy-stack/2019a/lib/python3.7/site-packages (from requests<3,>=2.0.0->wandb) (1.24.1)
Requirement already satisfied: idna<2.9,>=2.5 in /cvmfs/soft.computecanada.ca/easybuild/software/2017/Core/scipy-stack/2019a/lib/python3.7/site-packages (from requests<3,>=2.0.0->wandb) (2.8)
Requirement already satisfied: certifi>=2017.4.17 in /cvmfs/soft.computecanada.ca/easybuild/software/2017/Core/scipy-stack/2019a/lib/python3.7/site-packages (from requests<3,>=2.0.0->wandb) (2018.11.29)
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/termcolor-1.1.0+computecanada-py3-none-any.whl
Requirement already satisfied: zipp>=0.3.2 in /cvmfs/soft.computecanada.ca/easybuild/software/2017/Core/scipy-stack/2019a/lib/python3.7/site-packages (from importlib-metadata->Click!=8.0.0,>=7.0->wandb) (0.3.3)
Installing collected packages: smmap, typing-extensions, termcolor, six, gitdb, yaspin, subprocess32, shortuuid, sentry-sdk, PyYAML, psutil, protobuf, promise, pathtools, GitPython, docker-pycreds, configparser, Click, wandb
  Attempting uninstall: six
    Found existing installation: six 1.12.0
    Not uninstalling six at /cvmfs/soft.computecanada.ca/easybuild/software/2017/Core/scipy-stack/2019a/lib/python3.7/site-packages, outside environment /localscratch/yinan.29365731.0/env
    Can't uninstall 'six'. No files were found to uninstall.
Successfully installed Click-8.0.4+computecanada GitPython-3.1.24+computecanada PyYAML-5.3.1+computecanada configparser-5.0.2+computecanada docker-pycreds-0.4.0+computecanada gitdb-4.0.9+computecanada pathtools-0.1.2+computecanada promise-2.3+computecanada protobuf-3.19.4+computecanada psutil-5.7.3+computecanada sentry-sdk-1.5.0+computecanada shortuuid-1.0.1+computecanada six-1.16.0+computecanada smmap-5.0.0+computecanada subprocess32-3.5.4+computecanada termcolor-1.1.0+computecanada typing-extensions-4.0.1+computecanada wandb-0.12.5+computecanada yaspin-2.1.0+computecanada
Looking in links: /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/nix/avx2, /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/nix/generic, /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic
ERROR: Could not find a version that satisfies the requirement sagemaker (from versions: none)
ERROR: No matching distribution found for sagemaker
Looking in links: /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/nix/avx2, /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/nix/generic, /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/torch-1.9.1+computecanada-cp37-cp37m-linux_x86_64.whl
Requirement already satisfied: typing-extensions in /localscratch/yinan.29365731.0/env/lib/python3.7/site-packages (from torch) (4.0.1+computecanada)
Installing collected packages: torch
Successfully installed torch-1.9.1+computecanada
Looking in links: /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/nix/avx2, /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/nix/generic, /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/transformers-2.5.1+computecanada-py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/boto3-1.21.14+computecanada-py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/sacremoses-0.0.46+computecanada-py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/tqdm-4.63.0+computecanada-py2.py3-none-any.whl
Requirement already satisfied: requests in /cvmfs/soft.computecanada.ca/easybuild/software/2017/Core/scipy-stack/2019a/lib/python3.7/site-packages (from transformers==2.5.1+computecanada) (2.21.0)
Requirement already satisfied: numpy in /cvmfs/soft.computecanada.ca/easybuild/software/2017/Core/scipy-stack/2019a/lib/python3.7/site-packages (from transformers==2.5.1+computecanada) (1.16.0)
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/tokenizers-0.5.2+computecanada-cp37-cp37m-linux_x86_64.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/sentencepiece-0.1.91+computecanada-cp37-cp37m-linux_x86_64.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/regex-2020.11.13+computecanada-cp37-cp37m-linux_x86_64.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/filelock-3.4.2+computecanada-py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/jmespath-0.10.0+computecanada-py2.py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/s3transfer-0.5.1+computecanada-py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/botocore-1.24.14+computecanada-py3-none-any.whl
Requirement already satisfied: python-dateutil<3.0.0,>=2.1 in /cvmfs/soft.computecanada.ca/easybuild/software/2017/Core/scipy-stack/2019a/lib/python3.7/site-packages (from botocore<1.25.0,>=1.24.14->boto3->transformers==2.5.1+computecanada) (2.7.5)
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/urllib3-1.26.8+computecanada-py2.py3-none-any.whl
Requirement already satisfied: six>=1.5 in /localscratch/yinan.29365731.0/env/lib/python3.7/site-packages (from python-dateutil<3.0.0,>=2.1->botocore<1.25.0,>=1.24.14->boto3->transformers==2.5.1+computecanada) (1.16.0+computecanada)
Requirement already satisfied: idna<2.9,>=2.5 in /cvmfs/soft.computecanada.ca/easybuild/software/2017/Core/scipy-stack/2019a/lib/python3.7/site-packages (from requests->transformers==2.5.1+computecanada) (2.8)
Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /cvmfs/soft.computecanada.ca/easybuild/software/2017/Core/scipy-stack/2019a/lib/python3.7/site-packages (from requests->transformers==2.5.1+computecanada) (3.0.4)
Requirement already satisfied: certifi>=2017.4.17 in /cvmfs/soft.computecanada.ca/easybuild/software/2017/Core/scipy-stack/2019a/lib/python3.7/site-packages (from requests->transformers==2.5.1+computecanada) (2018.11.29)
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/requests-2.27.1+computecanada-py2.py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/charset_normalizer-2.0.12+computecanada-py3-none-any.whl
Requirement already satisfied: click in /localscratch/yinan.29365731.0/env/lib/python3.7/site-packages (from sacremoses->transformers==2.5.1+computecanada) (8.0.4+computecanada)
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/joblib-1.1.0+computecanada-py2.py3-none-any.whl
Requirement already satisfied: importlib-metadata in /cvmfs/soft.computecanada.ca/easybuild/software/2017/Core/scipy-stack/2019a/lib/python3.7/site-packages (from click->sacremoses->transformers==2.5.1+computecanada) (0.8)
Requirement already satisfied: zipp>=0.3.2 in /cvmfs/soft.computecanada.ca/easybuild/software/2017/Core/scipy-stack/2019a/lib/python3.7/site-packages (from importlib-metadata->click->sacremoses->transformers==2.5.1+computecanada) (0.3.3)
Installing collected packages: urllib3, jmespath, botocore, tqdm, s3transfer, regex, joblib, charset-normalizer, tokenizers, sentencepiece, sacremoses, requests, filelock, boto3, transformers
  Attempting uninstall: urllib3
    Found existing installation: urllib3 1.24.1
    Not uninstalling urllib3 at /cvmfs/soft.computecanada.ca/easybuild/software/2017/Core/scipy-stack/2019a/lib/python3.7/site-packages, outside environment /localscratch/yinan.29365731.0/env
    Can't uninstall 'urllib3'. No files were found to uninstall.
  Attempting uninstall: requests
    Found existing installation: requests 2.21.0
    Not uninstalling requests at /cvmfs/soft.computecanada.ca/easybuild/software/2017/Core/scipy-stack/2019a/lib/python3.7/site-packages, outside environment /localscratch/yinan.29365731.0/env
    Can't uninstall 'requests'. No files were found to uninstall.
Successfully installed boto3-1.21.14+computecanada botocore-1.24.14+computecanada charset-normalizer-2.0.12+computecanada filelock-3.4.2+computecanada jmespath-0.10.0+computecanada joblib-1.1.0+computecanada regex-2020.11.13+computecanada requests-2.27.1+computecanada s3transfer-0.5.1+computecanada sacremoses-0.0.46+computecanada sentencepiece-0.1.91+computecanada tokenizers-0.5.2+computecanada tqdm-4.63.0+computecanada transformers-2.5.1+computecanada urllib3-1.26.8+computecanada
Looking in links: /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/nix/avx2, /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/nix/generic, /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/tensorflow_gpu-2.3.0+computecanada-cp37-cp37m-linux_x86_64.whl
Requirement already satisfied: numpy<1.19.0,>=1.16.0 in /cvmfs/soft.computecanada.ca/easybuild/software/2017/Core/scipy-stack/2019a/lib/python3.7/site-packages (from tensorflow_gpu==2.3.0+computecanada) (1.16.0)
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/astunparse-1.6.3+computecanada-py2.py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/nix/generic/scipy-1.4.1+computecanada-cp37-cp37m-linux_x86_64.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/google_pasta-0.2.0+computecanada-py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/Keras_Preprocessing-1.1.2+computecanada-py3-none-any.whl
Requirement already satisfied: termcolor>=1.1.0 in /localscratch/yinan.29365731.0/env/lib/python3.7/site-packages (from tensorflow_gpu==2.3.0+computecanada) (1.1.0+computecanada)
Requirement already satisfied: wheel>=0.26 in /localscratch/yinan.29365731.0/env/lib/python3.7/site-packages (from tensorflow_gpu==2.3.0+computecanada) (0.33.4)
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/tensorboard-2.8.0+computecanada-py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/wrapt-1.11.2+computecanada-cp37-cp37m-linux_x86_64.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/absl_py-1.0.0+computecanada-py3-none-any.whl
Requirement already satisfied: protobuf>=3.9.2 in /localscratch/yinan.29365731.0/env/lib/python3.7/site-packages (from tensorflow_gpu==2.3.0+computecanada) (3.19.4+computecanada)
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/tensorflow_estimator-2.3.0+computecanada-py2.py3-none-any.whl
Requirement already satisfied: six>=1.12.0 in /localscratch/yinan.29365731.0/env/lib/python3.7/site-packages (from tensorflow_gpu==2.3.0+computecanada) (1.16.0+computecanada)
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/gast-0.3.3+computecanada-py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/grpcio-1.38.0+computecanada-cp37-cp37m-linux_x86_64.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/opt_einsum-3.3.0+computecanada-py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/nix/avx2/h5py-2.10.0+computecanada-cp37-cp37m-linux_x86_64.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/google_auth-2.3.3+computecanada-py2.py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/tensorboard_data_server-0.6.1+computecanada-py3-none-linux_x86_64.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/Markdown-3.3.6+computecanada-py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/google_auth_oauthlib-0.4.6+computecanada-py2.py3-none-any.whl
Requirement already satisfied: setuptools>=41.0.0 in /localscratch/yinan.29365731.0/env/lib/python3.7/site-packages (from tensorboard<3,>=2.3.0->tensorflow_gpu==2.3.0+computecanada) (41.0.1)
Requirement already satisfied: requests<3,>=2.21.0 in /localscratch/yinan.29365731.0/env/lib/python3.7/site-packages (from tensorboard<3,>=2.3.0->tensorflow_gpu==2.3.0+computecanada) (2.27.1+computecanada)
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/Werkzeug-2.0.3+computecanada-py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/tensorboard_plugin_wit-1.8.0+computecanada-py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/pyasn1_modules-0.2.8+computecanada-py2.py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/cachetools-4.2.4+computecanada-py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/rsa-4.8+computecanada-py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/requests_oauthlib-1.3.0+computecanada-py2.py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/importlib_metadata-4.10.1+computecanada-py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/zipp-3.7.0+computecanada-py3-none-any.whl
Requirement already satisfied: typing-extensions>=3.6.4 in /localscratch/yinan.29365731.0/env/lib/python3.7/site-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard<3,>=2.3.0->tensorflow_gpu==2.3.0+computecanada) (4.0.1+computecanada)
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/pyasn1-0.4.8+computecanada-py2.py3-none-any.whl
Requirement already satisfied: certifi>=2017.4.17 in /cvmfs/soft.computecanada.ca/easybuild/software/2017/Core/scipy-stack/2019a/lib/python3.7/site-packages (from requests<3,>=2.21.0->tensorboard<3,>=2.3.0->tensorflow_gpu==2.3.0+computecanada) (2018.11.29)
Requirement already satisfied: charset-normalizer~=2.0.0 in /localscratch/yinan.29365731.0/env/lib/python3.7/site-packages (from requests<3,>=2.21.0->tensorboard<3,>=2.3.0->tensorflow_gpu==2.3.0+computecanada) (2.0.12+computecanada)
Requirement already satisfied: idna<4,>=2.5 in /cvmfs/soft.computecanada.ca/easybuild/software/2017/Core/scipy-stack/2019a/lib/python3.7/site-packages (from requests<3,>=2.21.0->tensorboard<3,>=2.3.0->tensorflow_gpu==2.3.0+computecanada) (2.8)
Requirement already satisfied: urllib3<1.27,>=1.21.1 in /localscratch/yinan.29365731.0/env/lib/python3.7/site-packages (from requests<3,>=2.21.0->tensorboard<3,>=2.3.0->tensorflow_gpu==2.3.0+computecanada) (1.26.8+computecanada)
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/oauthlib-3.1.1+computecanada-py2.py3-none-any.whl
Installing collected packages: pyasn1, zipp, rsa, pyasn1-modules, oauthlib, cachetools, requests-oauthlib, importlib-metadata, google-auth, werkzeug, tensorboard-plugin-wit, tensorboard-data-server, markdown, grpcio, google-auth-oauthlib, absl-py, wrapt, tensorflow-estimator, tensorboard, scipy, opt-einsum, keras-preprocessing, h5py, google-pasta, gast, astunparse, tensorflow-gpu
  Attempting uninstall: pyasn1
    Found existing installation: pyasn1 0.4.3
    Not uninstalling pyasn1 at /cvmfs/soft.computecanada.ca/easybuild/software/2017/Core/scipy-stack/2019a/lib/python3.7/site-packages, outside environment /localscratch/yinan.29365731.0/env
    Can't uninstall 'pyasn1'. No files were found to uninstall.
  Attempting uninstall: zipp
    Found existing installation: zipp 0.3.3
    Not uninstalling zipp at /cvmfs/soft.computecanada.ca/easybuild/software/2017/Core/scipy-stack/2019a/lib/python3.7/site-packages, outside environment /localscratch/yinan.29365731.0/env
    Can't uninstall 'zipp'. No files were found to uninstall.
  Attempting uninstall: importlib-metadata
    Found existing installation: importlib-metadata 0.8
    Not uninstalling importlib-metadata at /cvmfs/soft.computecanada.ca/easybuild/software/2017/Core/scipy-stack/2019a/lib/python3.7/site-packages, outside environment /localscratch/yinan.29365731.0/env
    Can't uninstall 'importlib-metadata'. No files were found to uninstall.
  Attempting uninstall: scipy
    Found existing installation: scipy 1.2.0
    Not uninstalling scipy at /cvmfs/soft.computecanada.ca/easybuild/software/2017/Core/scipy-stack/2019a/lib/python3.7/site-packages, outside environment /localscratch/yinan.29365731.0/env
    Can't uninstall 'scipy'. No files were found to uninstall.
Successfully installed absl-py-1.0.0+computecanada astunparse-1.6.3+computecanada cachetools-4.2.4+computecanada gast-0.3.3+computecanada google-auth-2.3.3+computecanada google-auth-oauthlib-0.4.6+computecanada google-pasta-0.2.0+computecanada grpcio-1.38.0+computecanada h5py-2.10.0+computecanada importlib-metadata-4.10.1+computecanada keras-preprocessing-1.1.2+computecanada markdown-3.3.6+computecanada oauthlib-3.1.1+computecanada opt-einsum-3.3.0+computecanada pyasn1-0.4.8+computecanada pyasn1-modules-0.2.8+computecanada requests-oauthlib-1.3.0+computecanada rsa-4.8+computecanada scipy-1.4.1+computecanada tensorboard-2.8.0+computecanada tensorboard-data-server-0.6.1+computecanada tensorboard-plugin-wit-1.8.0+computecanada tensorflow-estimator-2.3.0+computecanada tensorflow-gpu-2.3.0+computecanada werkzeug-2.0.3+computecanada wrapt-1.11.2+computecanada zipp-3.7.0+computecanada
Looking in links: /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/nix/avx2, /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/nix/generic, /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/keras-2.8.0+computecanada-py2.py3-none-any.whl
Installing collected packages: Keras
Successfully installed Keras-2.8.0+computecanada
Looking in links: /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/nix/avx2, /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/nix/generic, /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/urllib3-1.26.7+computecanada-py2.py3-none-any.whl
Installing collected packages: urllib3
  Attempting uninstall: urllib3
    Found existing installation: urllib3 1.26.8+computecanada
    Uninstalling urllib3-1.26.8+computecanada:
      Successfully uninstalled urllib3-1.26.8+computecanada
Successfully installed urllib3-1.26.7+computecanada
Looking in links: /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/nix/avx2, /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/nix/generic, /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/nltk-3.7+computecanada-py3-none-any.whl
Requirement already satisfied: click in /localscratch/yinan.29365731.0/env/lib/python3.7/site-packages (from nltk) (8.0.4+computecanada)
Requirement already satisfied: tqdm in /localscratch/yinan.29365731.0/env/lib/python3.7/site-packages (from nltk) (4.63.0+computecanada)
Requirement already satisfied: joblib in /localscratch/yinan.29365731.0/env/lib/python3.7/site-packages (from nltk) (1.1.0+computecanada)
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/nltk-3.6.5+computecanada-py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/nltk-3.6.3+computecanada-py3-none-any.whl
Requirement already satisfied: regex in /localscratch/yinan.29365731.0/env/lib/python3.7/site-packages (from nltk) (2020.11.13+computecanada)
Requirement already satisfied: importlib-metadata in /localscratch/yinan.29365731.0/env/lib/python3.7/site-packages (from click->nltk) (4.10.1+computecanada)
Requirement already satisfied: typing-extensions>=3.6.4 in /localscratch/yinan.29365731.0/env/lib/python3.7/site-packages (from importlib-metadata->click->nltk) (4.0.1+computecanada)
Requirement already satisfied: zipp>=0.5 in /localscratch/yinan.29365731.0/env/lib/python3.7/site-packages (from importlib-metadata->click->nltk) (3.7.0+computecanada)
Installing collected packages: nltk
Successfully installed nltk-3.6.3+computecanada
Looking in links: /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/nix/avx2, /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/nix/generic, /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/scikit_learn-0.22.1+computecanada-cp37-cp37m-linux_x86_64.whl
Requirement already satisfied: joblib>=0.11 in /localscratch/yinan.29365731.0/env/lib/python3.7/site-packages (from scikit-learn==0.22.1) (1.1.0+computecanada)
Requirement already satisfied: numpy>=1.11.0 in /cvmfs/soft.computecanada.ca/easybuild/software/2017/Core/scipy-stack/2019a/lib/python3.7/site-packages (from scikit-learn==0.22.1) (1.16.0)
Requirement already satisfied: scipy>=0.17.0 in /localscratch/yinan.29365731.0/env/lib/python3.7/site-packages (from scikit-learn==0.22.1) (1.4.1+computecanada)
Installing collected packages: scikit-learn
Successfully installed scikit-learn-0.22.1+computecanada
Looking in links: /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/nix/avx2, /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/nix/generic, /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic
Requirement already satisfied: tokenizers==0.5.2 in /localscratch/yinan.29365731.0/env/lib/python3.7/site-packages (0.5.2+computecanada)
wandb: Appending key for api.wandb.ai to your netrc file: /home/yinan/.netrc
Starting Task
2022-03-24 10:39:27.872443: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1
[nltk_data] Downloading package stopwords to /home/yinan/nltk_data...
[nltk_data]   Package stopwords is already up-to-date!
[nltk_data] Downloading package wordnet to /home/yinan/nltk_data...
[nltk_data]   Package wordnet is already up-to-date!
wandb: Currently logged in as: yinanazhou (use `wandb login --relogin` to force relogin)
wandb: wandb version 0.12.11 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
2022-03-24 10:39:44.220070: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1
wandb: Tracking run with wandb version 0.12.5
wandb: Syncing run feasible-breeze-1
wandb: ⭐️ View project at https://wandb.ai/yinanazhou/xl_512_bs_8_lr_1e06_es_5_lc_True_nr_True_sr_False_stem_False_lemma_True_repeat_1_fold_1
wandb: 🚀 View run at https://wandb.ai/yinanazhou/xl_512_bs_8_lr_1e06_es_5_lc_True_nr_True_sr_False_stem_False_lemma_True_repeat_1_fold_1/runs/22ihias2
wandb: Run data is saved locally in /project/6002780/yinan/Thesis_MER_Lyrics/lyric-emotion/wandb/run-20220324_103941-22ihias2
wandb: Run `wandb offline` to turn off syncing.

Validation loss decreased (inf --> 1.439309).  Saving model ...
Validation loss decreased (1.439309 --> 1.419105).  Saving model ...
Validation loss decreased (1.419105 --> 1.402491).  Saving model ...
Validation loss decreased (1.402491 --> 1.389058).  Saving model ...
Validation loss decreased (1.389058 --> 1.378937).  Saving model ...
Validation loss decreased (1.378937 --> 1.370089).  Saving model ...
Validation loss decreased (1.370089 --> 1.363380).  Saving model ...
Validation loss decreased (1.363380 --> 1.357554).  Saving model ...
Validation loss decreased (1.357554 --> 1.351885).  Saving model ...
Validation loss decreased (1.351885 --> 1.346473).  Saving model ...
Validation loss decreased (1.346473 --> 1.340653).  Saving model ...
Validation loss decreased (1.340653 --> 1.335815).  Saving model ...
Validation loss decreased (1.335815 --> 1.330758).  Saving model ...
Validation loss decreased (1.330758 --> 1.325765).  Saving model ...
Validation loss decreased (1.325765 --> 1.320288).  Saving model ...
Validation loss decreased (1.320288 --> 1.316206).  Saving model ...
Validation loss decreased (1.316206 --> 1.310600).  Saving model ...
Validation loss decreased (1.310600 --> 1.304590).  Saving model ...
Validation loss decreased (1.304590 --> 1.299087).  Saving model ...
Validation loss decreased (1.299087 --> 1.293122).  Saving model ...
Validation loss decreased (1.293122 --> 1.287364).  Saving model ...
Validation loss decreased (1.287364 --> 1.280271).  Saving model ...
Validation loss decreased (1.280271 --> 1.276599).  Saving model ...
Validation loss decreased (1.276599 --> 1.269277).  Saving model ...
Validation loss decreased (1.269277 --> 1.263776).  Saving model ...
Validation loss decreased (1.263776 --> 1.259156).  Saving model ...
Validation loss decreased (1.259156 --> 1.252592).  Saving model ...
Validation loss decreased (1.252592 --> 1.248384).  Saving model ...
Validation loss decreased (1.248384 --> 1.244844).  Saving model ...
Validation loss decreased (1.244844 --> 1.243392).  Saving model ...
Validation loss decreased (1.243392 --> 1.240637).  Saving model ...
Validation loss decreased (1.240637 --> 1.235306).  Saving model ...
Validation loss decreased (1.235306 --> 1.234287).  Saving model ...
Validation loss decreased (1.234287 --> 1.228457).  Saving model ...
Validation loss decreased (1.228457 --> 1.225178).  Saving model ...
Validation loss decreased (1.225178 --> 1.218794).  Saving model ...
Validation loss decreased (1.218794 --> 1.213360).  Saving model ...
Validation loss decreased (1.213360 --> 1.211831).  Saving model ...
Validation loss decreased (1.211831 --> 1.207428).  Saving model ...
Validation loss decreased (1.207428 --> 1.205810).  Saving model ...
Validation loss decreased (1.205810 --> 1.198795).  Saving model ...
Validation loss decreased (1.198795 --> 1.194625).  Saving model ...
Validation loss decreased (1.194625 --> 1.191737).  Saving model ...
EarlyStopping counter: 1 out of 5.0
Validation loss decreased (1.191737 --> 1.186692).  Saving model ...
Validation loss decreased (1.186692 --> 1.184148).  Saving model ...
Validation loss decreased (1.184148 --> 1.182458).  Saving model ...
EarlyStopping counter: 1 out of 5.0
Validation loss decreased (1.182458 --> 1.176040).  Saving model ...
Validation loss decreased (1.176040 --> 1.176023).  Saving model ...
Validation loss decreased (1.176023 --> 1.169389).  Saving model ...
Validation loss decreased (1.169389 --> 1.166622).  Saving model ...
Validation loss decreased (1.166622 --> 1.166117).  Saving model ...
Validation loss decreased (1.166117 --> 1.163209).  Saving model ...
Validation loss decreased (1.163209 --> 1.163055).  Saving model ...
Validation loss decreased (1.163055 --> 1.157392).  Saving model ...
Validation loss decreased (1.157392 --> 1.151576).  Saving model ...
Validation loss decreased (1.151576 --> 1.147402).  Saving model ...
Validation loss decreased (1.147402 --> 1.141575).  Saving model ...
EarlyStopping counter: 1 out of 5.0
Validation loss decreased (1.141575 --> 1.139336).  Saving model ...
Validation loss decreased (1.139336 --> 1.137451).  Saving model ...
Validation loss decreased (1.137451 --> 1.132357).  Saving model ...
EarlyStopping counter: 1 out of 5.0
EarlyStopping counter: 2 out of 5.0
Validation loss decreased (1.132357 --> 1.128460).  Saving model ...
Validation loss decreased (1.128460 --> 1.125789).  Saving model ...
Validation loss decreased (1.125789 --> 1.119857).  Saving model ...
Validation loss decreased (1.119857 --> 1.119150).  Saving model ...
Validation loss decreased (1.119150 --> 1.117602).  Saving model ...
Validation loss decreased (1.117602 --> 1.110618).  Saving model ...
Validation loss decreased (1.110618 --> 1.109347).  Saving model ...
Validation loss decreased (1.109347 --> 1.108646).  Saving model ...
Validation loss decreased (1.108646 --> 1.105010).  Saving model ...
Validation loss decreased (1.105010 --> 1.101256).  Saving model ...
Validation loss decreased (1.101256 --> 1.100464).  Saving model ...
EarlyStopping counter: 1 out of 5.0
Validation loss decreased (1.100464 --> 1.095709).  Saving model ...
Validation loss decreased (1.095709 --> 1.090373).  Saving model ...
Validation loss decreased (1.090373 --> 1.087978).  Saving model ...
EarlyStopping counter: 1 out of 5.0
EarlyStopping counter: 2 out of 5.0
EarlyStopping counter: 3 out of 5.0
Validation loss decreased (1.087978 --> 1.085389).  Saving model ...
Validation loss decreased (1.085389 --> 1.082821).  Saving model ...
Validation loss decreased (1.082821 --> 1.078149).  Saving model ...
Validation loss decreased (1.078149 --> 1.073165).  Saving model ...
EarlyStopping counter: 1 out of 5.0
EarlyStopping counter: 2 out of 5.0
EarlyStopping counter: 3 out of 5.0
EarlyStopping counter: 4 out of 5.0
Validation loss decreased (1.073165 --> 1.072705).  Saving model ...
Validation loss decreased (1.072705 --> 1.070608).  Saving model ...
EarlyStopping counter: 1 out of 5.0
EarlyStopping counter: 2 out of 5.0
Validation loss decreased (1.070608 --> 1.068707).  Saving model ...
Validation loss decreased (1.068707 --> 1.068190).  Saving model ...
Validation loss decreased (1.068190 --> 1.060603).  Saving model ...
Validation loss decreased (1.060603 --> 1.060099).  Saving model ...
EarlyStopping counter: 1 out of 5.0
EarlyStopping counter: 2 out of 5.0
Validation loss decreased (1.060099 --> 1.055535).  Saving model ...
Validation loss decreased (1.055535 --> 1.054814).  Saving model ...
EarlyStopping counter: 1 out of 5.0
Validation loss decreased (1.054814 --> 1.053444).  Saving model ...
Validation loss decreased (1.053444 --> 1.050042).  Saving model ...
Validation loss decreased (1.050042 --> 1.049573).  Saving model ...
Validation loss decreased (1.049573 --> 1.046963).  Saving model ...
Validation loss decreased (1.046963 --> 1.044535).  Saving model ...
Validation loss decreased (1.044535 --> 1.041566).  Saving model ...
EarlyStopping counter: 1 out of 5.0
EarlyStopping counter: 2 out of 5.0
EarlyStopping counter: 3 out of 5.0
EarlyStopping counter: 4 out of 5.0
EarlyStopping counter: 5 out of 5.0
/localscratch/yinan.29365731.0/env/lib/python3.7/site-packages/torch/nn/functional.py:1794: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.
  warnings.warn("nn.functional.tanh is deprecated. Use torch.tanh instead.")
/localscratch/yinan.29365731.0/env/lib/python3.7/site-packages/transformers/optimization.py:155: UserWarning: This overload of add_ is deprecated:
	add_(Number alpha, Tensor other)
Consider using one of the following signatures instead:
	add_(Tensor other, *, Number alpha) (Triggered internally at  ../torch/csrc/utils/python_arg_parser.cpp:1025.)
  exp_avg.mul_(beta1).add_(1.0 - beta1, grad)
wandb: Waiting for W&B process to finish, PID 116586... (success).
wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: \ 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: | 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: / 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: \ 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: | 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: / 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: \ 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: | 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: / 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb:                                                                                
wandb: Run history:
wandb:     e_F1 ▁▂▃▄▅▅▅▅▅▆▆▅▆▆▆▆▆▆▆▆▆▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇████
wandb:   e_loss █▇▇▆▆▆▆▅▅▅▅▄▄▄▄▄▃▃▃▃▃▃▃▂▂▂▂▂▂▂▂▂▂▁▁▁▁▁▁▁
wandb:     t_F1 ▁▁▂▂▃▃▃▄▄▅▅▅▆▅▆▆▆▆▆▆▇▇▆▆▇▇▇▇▇▇▇▇█▇▇█████
wandb:   t_loss ██▇▇▇▇▇▆▆▆▅▅▅▅▄▄▄▄▄▄▃▃▃▃▃▃▃▂▂▂▂▂▂▂▂▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:     e_F1 56.2554
wandb:   e_loss 1.04265
wandb:     t_F1 68.5383
wandb:   t_loss 0.81268
wandb: 
wandb: Synced 4 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Synced feasible-breeze-1: https://wandb.ai/yinanazhou/xl_512_bs_8_lr_1e06_es_5_lc_True_nr_True_sr_False_stem_False_lemma_True_repeat_1_fold_1/runs/22ihias2
wandb: Find logs at: ./wandb/run-20220324_103941-22ihias2/logs/debug.log
wandb: 

wandb: wandb version 0.12.11 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
2022-03-24 11:53:34.383870: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1
wandb: Tracking run with wandb version 0.12.5
wandb: Syncing run fast-yogurt-1
wandb: ⭐️ View project at https://wandb.ai/yinanazhou/xl_512_bs_8_lr_1e06_es_5_lc_True_nr_True_sr_False_stem_False_lemma_True_repeat_1_fold_2
wandb: 🚀 View run at https://wandb.ai/yinanazhou/xl_512_bs_8_lr_1e06_es_5_lc_True_nr_True_sr_False_stem_False_lemma_True_repeat_1_fold_2/runs/3431s1w6
wandb: Run data is saved locally in /project/6002780/yinan/Thesis_MER_Lyrics/lyric-emotion/wandb/run-20220324_115331-3431s1w6
wandb: Run `wandb offline` to turn off syncing.

Validation loss decreased (inf --> 1.434888).  Saving model ...
Validation loss decreased (1.434888 --> 1.418714).  Saving model ...
Validation loss decreased (1.418714 --> 1.408332).  Saving model ...
Validation loss decreased (1.408332 --> 1.400255).  Saving model ...
Validation loss decreased (1.400255 --> 1.393655).  Saving model ...
Validation loss decreased (1.393655 --> 1.387897).  Saving model ...
Validation loss decreased (1.387897 --> 1.383218).  Saving model ...
Validation loss decreased (1.383218 --> 1.378969).  Saving model ...
Validation loss decreased (1.378969 --> 1.374852).  Saving model ...
Validation loss decreased (1.374852 --> 1.370951).  Saving model ...
Validation loss decreased (1.370951 --> 1.367136).  Saving model ...
Validation loss decreased (1.367136 --> 1.363453).  Saving model ...
Validation loss decreased (1.363453 --> 1.359862).  Saving model ...
Validation loss decreased (1.359862 --> 1.355990).  Saving model ...
Validation loss decreased (1.355990 --> 1.352528).  Saving model ...
Validation loss decreased (1.352528 --> 1.348967).  Saving model ...
Validation loss decreased (1.348967 --> 1.345303).  Saving model ...
Validation loss decreased (1.345303 --> 1.341364).  Saving model ...
Validation loss decreased (1.341364 --> 1.337130).  Saving model ...
Validation loss decreased (1.337130 --> 1.332635).  Saving model ...
Validation loss decreased (1.332635 --> 1.328055).  Saving model ...
Validation loss decreased (1.328055 --> 1.323381).  Saving model ...
Validation loss decreased (1.323381 --> 1.318200).  Saving model ...
Validation loss decreased (1.318200 --> 1.313245).  Saving model ...
Validation loss decreased (1.313245 --> 1.307902).  Saving model ...
Validation loss decreased (1.307902 --> 1.301431).  Saving model ...
Validation loss decreased (1.301431 --> 1.295295).  Saving model ...
Validation loss decreased (1.295295 --> 1.288812).  Saving model ...
Validation loss decreased (1.288812 --> 1.282355).  Saving model ...
Validation loss decreased (1.282355 --> 1.275951).  Saving model ...
Validation loss decreased (1.275951 --> 1.268805).  Saving model ...
Validation loss decreased (1.268805 --> 1.261383).  Saving model ...
Validation loss decreased (1.261383 --> 1.254469).  Saving model ...
Validation loss decreased (1.254469 --> 1.247738).  Saving model ...
Validation loss decreased (1.247738 --> 1.239040).  Saving model ...
Validation loss decreased (1.239040 --> 1.230850).  Saving model ...
Validation loss decreased (1.230850 --> 1.223427).  Saving model ...
Validation loss decreased (1.223427 --> 1.215849).  Saving model ...
Validation loss decreased (1.215849 --> 1.208006).  Saving model ...
Validation loss decreased (1.208006 --> 1.200751).  Saving model ...
Validation loss decreased (1.200751 --> 1.193039).  Saving model ...
Validation loss decreased (1.193039 --> 1.185995).  Saving model ...
Validation loss decreased (1.185995 --> 1.179263).  Saving model ...
Validation loss decreased (1.179263 --> 1.171838).  Saving model ...
Validation loss decreased (1.171838 --> 1.166115).  Saving model ...
Validation loss decreased (1.166115 --> 1.160131).  Saving model ...
Validation loss decreased (1.160131 --> 1.153610).  Saving model ...
Validation loss decreased (1.153610 --> 1.146995).  Saving model ...
Validation loss decreased (1.146995 --> 1.140640).  Saving model ...
Validation loss decreased (1.140640 --> 1.134726).  Saving model ...
Validation loss decreased (1.134726 --> 1.128193).  Saving model ...
Validation loss decreased (1.128193 --> 1.122050).  Saving model ...
Validation loss decreased (1.122050 --> 1.116193).  Saving model ...
Validation loss decreased (1.116193 --> 1.110973).  Saving model ...
Validation loss decreased (1.110973 --> 1.104886).  Saving model ...
Validation loss decreased (1.104886 --> 1.099925).  Saving model ...
Validation loss decreased (1.099925 --> 1.094065).  Saving model ...
Validation loss decreased (1.094065 --> 1.089088).  Saving model ...
Validation loss decreased (1.089088 --> 1.084342).  Saving model ...
Validation loss decreased (1.084342 --> 1.079175).  Saving model ...
Validation loss decreased (1.079175 --> 1.073587).  Saving model ...
Validation loss decreased (1.073587 --> 1.070171).  Saving model ...
Validation loss decreased (1.070171 --> 1.066398).  Saving model ...
Validation loss decreased (1.066398 --> 1.061943).  Saving model ...
Validation loss decreased (1.061943 --> 1.056416).  Saving model ...
Validation loss decreased (1.056416 --> 1.053640).  Saving model ...
Validation loss decreased (1.053640 --> 1.047490).  Saving model ...
Validation loss decreased (1.047490 --> 1.042903).  Saving model ...
Validation loss decreased (1.042903 --> 1.039760).  Saving model ...
Validation loss decreased (1.039760 --> 1.035974).  Saving model ...
Validation loss decreased (1.035974 --> 1.031134).  Saving model ...
Validation loss decreased (1.031134 --> 1.027608).  Saving model ...
Validation loss decreased (1.027608 --> 1.024260).  Saving model ...
Validation loss decreased (1.024260 --> 1.019849).  Saving model ...
Validation loss decreased (1.019849 --> 1.017517).  Saving model ...
Validation loss decreased (1.017517 --> 1.015727).  Saving model ...
Validation loss decreased (1.015727 --> 1.011350).  Saving model ...
Validation loss decreased (1.011350 --> 1.008927).  Saving model ...
Validation loss decreased (1.008927 --> 1.006153).  Saving model ...
Validation loss decreased (1.006153 --> 1.002645).  Saving model ...
Validation loss decreased (1.002645 --> 1.000120).  Saving model ...
Validation loss decreased (1.000120 --> 0.995782).  Saving model ...
Validation loss decreased (0.995782 --> 0.992786).  Saving model ...
Validation loss decreased (0.992786 --> 0.991093).  Saving model ...
Validation loss decreased (0.991093 --> 0.987766).  Saving model ...
Validation loss decreased (0.987766 --> 0.985832).  Saving model ...
Validation loss decreased (0.985832 --> 0.984774).  Saving model ...
Validation loss decreased (0.984774 --> 0.981630).  Saving model ...
Validation loss decreased (0.981630 --> 0.979023).  Saving model ...
Validation loss decreased (0.979023 --> 0.976444).  Saving model ...
Validation loss decreased (0.976444 --> 0.975124).  Saving model ...
EarlyStopping counter: 1 out of 5.0
Validation loss decreased (0.975124 --> 0.971608).  Saving model ...
Validation loss decreased (0.971608 --> 0.969425).  Saving model ...
Validation loss decreased (0.969425 --> 0.967201).  Saving model ...
Validation loss decreased (0.967201 --> 0.966145).  Saving model ...
Validation loss decreased (0.966145 --> 0.963417).  Saving model ...
Validation loss decreased (0.963417 --> 0.961578).  Saving model ...
Validation loss decreased (0.961578 --> 0.959745).  Saving model ...
Validation loss decreased (0.959745 --> 0.958389).  Saving model ...
Validation loss decreased (0.958389 --> 0.957283).  Saving model ...
Validation loss decreased (0.957283 --> 0.955163).  Saving model ...
Validation loss decreased (0.955163 --> 0.952992).  Saving model ...
Validation loss decreased (0.952992 --> 0.950938).  Saving model ...
Validation loss decreased (0.950938 --> 0.949840).  Saving model ...
Validation loss decreased (0.949840 --> 0.949052).  Saving model ...
Validation loss decreased (0.949052 --> 0.947185).  Saving model ...
Validation loss decreased (0.947185 --> 0.945794).  Saving model ...
Validation loss decreased (0.945794 --> 0.944543).  Saving model ...
Validation loss decreased (0.944543 --> 0.942486).  Saving model ...
Validation loss decreased (0.942486 --> 0.941317).  Saving model ...
Validation loss decreased (0.941317 --> 0.940221).  Saving model ...
Validation loss decreased (0.940221 --> 0.938223).  Saving model ...
Validation loss decreased (0.938223 --> 0.936816).  Saving model ...
Validation loss decreased (0.936816 --> 0.935625).  Saving model ...
Validation loss decreased (0.935625 --> 0.935282).  Saving model ...
Validation loss decreased (0.935282 --> 0.933962).  Saving model ...
EarlyStopping counter: 1 out of 5.0
Validation loss decreased (0.933962 --> 0.932670).  Saving model ...
EarlyStopping counter: 1 out of 5.0
EarlyStopping counter: 2 out of 5.0
Validation loss decreased (0.932670 --> 0.932633).  Saving model ...
Validation loss decreased (0.932633 --> 0.932239).  Saving model ...
Validation loss decreased (0.932239 --> 0.930880).  Saving model ...
Validation loss decreased (0.930880 --> 0.930235).  Saving model ...
EarlyStopping counter: 1 out of 5.0
Validation loss decreased (0.930235 --> 0.929758).  Saving model ...
Validation loss decreased (0.929758 --> 0.928954).  Saving model ...
Validation loss decreased (0.928954 --> 0.928225).  Saving model ...
EarlyStopping counter: 1 out of 5.0
Validation loss decreased (0.928225 --> 0.927798).  Saving model ...
Validation loss decreased (0.927798 --> 0.926539).  Saving model ...
EarlyStopping counter: 1 out of 5.0
EarlyStopping counter: 2 out of 5.0
EarlyStopping counter: 3 out of 5.0
EarlyStopping counter: 4 out of 5.0
EarlyStopping counter: 5 out of 5.0
/localscratch/yinan.29365731.0/env/lib/python3.7/site-packages/torch/nn/functional.py:1794: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.
  warnings.warn("nn.functional.tanh is deprecated. Use torch.tanh instead.")
wandb: Waiting for W&B process to finish, PID 120554... (success).
wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: \ 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: | 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: / 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: \ 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: | 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: / 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: \ 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: | 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb:                                                                                
wandb: Run history:
wandb:     e_F1 ▁▁▃▄▄▄▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇▇▇▇▇▇▇▇████████████
wandb:   e_loss ██▇▇▇▇▇▆▆▆▅▅▅▄▄▄▃▃▃▃▃▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁
wandb:     t_F1 ▁▂▂▂▂▃▃▄▄▄▄▅▅▅▆▅▆▆▆▆▆▆▆▇▇▆▇▆▇▇▇█▇▇███▇██
wandb:   t_loss ██▇▇▇▇▇▇▆▆▆▆▆▅▅▅▅▅▅▄▄▄▃▃▃▃▃▃▂▃▂▂▂▂▂▁▁▂▁▁
wandb: 
wandb: Run summary:
wandb:     e_F1 61.25947
wandb:   e_loss 0.92764
wandb:     t_F1 72.86107
wandb:   t_loss 0.7641
wandb: 
wandb: Synced 4 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Synced fast-yogurt-1: https://wandb.ai/yinanazhou/xl_512_bs_8_lr_1e06_es_5_lc_True_nr_True_sr_False_stem_False_lemma_True_repeat_1_fold_2/runs/3431s1w6
wandb: Find logs at: ./wandb/run-20220324_115331-3431s1w6/logs/debug.log
wandb: 

wandb: wandb version 0.12.11 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
2022-03-24 13:22:30.406778: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1
wandb: Tracking run with wandb version 0.12.5
wandb: Syncing run devoted-night-1
wandb: ⭐️ View project at https://wandb.ai/yinanazhou/xl_512_bs_8_lr_1e06_es_5_lc_True_nr_True_sr_False_stem_False_lemma_True_repeat_2_fold_1
wandb: 🚀 View run at https://wandb.ai/yinanazhou/xl_512_bs_8_lr_1e06_es_5_lc_True_nr_True_sr_False_stem_False_lemma_True_repeat_2_fold_1/runs/2l0tnz8z
wandb: Run data is saved locally in /project/6002780/yinan/Thesis_MER_Lyrics/lyric-emotion/wandb/run-20220324_132228-2l0tnz8z
wandb: Run `wandb offline` to turn off syncing.

Validation loss decreased (inf --> 1.412583).  Saving model ...
Validation loss decreased (1.412583 --> 1.399676).  Saving model ...
Validation loss decreased (1.399676 --> 1.389808).  Saving model ...
Validation loss decreased (1.389808 --> 1.382466).  Saving model ...
Validation loss decreased (1.382466 --> 1.376598).  Saving model ...
Validation loss decreased (1.376598 --> 1.371309).  Saving model ...
Validation loss decreased (1.371309 --> 1.367077).  Saving model ...
Validation loss decreased (1.367077 --> 1.363264).  Saving model ...
Validation loss decreased (1.363264 --> 1.359436).  Saving model ...
Validation loss decreased (1.359436 --> 1.355630).  Saving model ...
Validation loss decreased (1.355630 --> 1.351547).  Saving model ...
Validation loss decreased (1.351547 --> 1.348111).  Saving model ...
Validation loss decreased (1.348111 --> 1.344133).  Saving model ...
Validation loss decreased (1.344133 --> 1.340118).  Saving model ...
Validation loss decreased (1.340118 --> 1.335718).  Saving model ...
Validation loss decreased (1.335718 --> 1.331350).  Saving model ...
Validation loss decreased (1.331350 --> 1.326902).  Saving model ...
Validation loss decreased (1.326902 --> 1.322678).  Saving model ...
Validation loss decreased (1.322678 --> 1.317751).  Saving model ...
Validation loss decreased (1.317751 --> 1.311869).  Saving model ...
Validation loss decreased (1.311869 --> 1.306052).  Saving model ...
Validation loss decreased (1.306052 --> 1.298642).  Saving model ...
Validation loss decreased (1.298642 --> 1.291040).  Saving model ...
Validation loss decreased (1.291040 --> 1.284048).  Saving model ...
Validation loss decreased (1.284048 --> 1.275887).  Saving model ...
Validation loss decreased (1.275887 --> 1.266349).  Saving model ...
Validation loss decreased (1.266349 --> 1.259232).  Saving model ...
Validation loss decreased (1.259232 --> 1.251138).  Saving model ...
Validation loss decreased (1.251138 --> 1.242067).  Saving model ...
Validation loss decreased (1.242067 --> 1.233709).  Saving model ...
Validation loss decreased (1.233709 --> 1.225724).  Saving model ...
Validation loss decreased (1.225724 --> 1.217087).  Saving model ...
Validation loss decreased (1.217087 --> 1.210033).  Saving model ...
Validation loss decreased (1.210033 --> 1.203735).  Saving model ...
Validation loss decreased (1.203735 --> 1.197312).  Saving model ...
Validation loss decreased (1.197312 --> 1.190049).  Saving model ...
Validation loss decreased (1.190049 --> 1.182897).  Saving model ...
Validation loss decreased (1.182897 --> 1.177562).  Saving model ...
Validation loss decreased (1.177562 --> 1.172069).  Saving model ...
Validation loss decreased (1.172069 --> 1.165621).  Saving model ...
Validation loss decreased (1.165621 --> 1.159323).  Saving model ...
Validation loss decreased (1.159323 --> 1.156094).  Saving model ...
Validation loss decreased (1.156094 --> 1.150867).  Saving model ...
Validation loss decreased (1.150867 --> 1.146484).  Saving model ...
Validation loss decreased (1.146484 --> 1.141764).  Saving model ...
Validation loss decreased (1.141764 --> 1.135280).  Saving model ...
Validation loss decreased (1.135280 --> 1.131158).  Saving model ...
Validation loss decreased (1.131158 --> 1.128859).  Saving model ...
Validation loss decreased (1.128859 --> 1.122244).  Saving model ...
Validation loss decreased (1.122244 --> 1.117990).  Saving model ...
Validation loss decreased (1.117990 --> 1.113733).  Saving model ...
Validation loss decreased (1.113733 --> 1.111057).  Saving model ...
Validation loss decreased (1.111057 --> 1.105239).  Saving model ...
Validation loss decreased (1.105239 --> 1.099966).  Saving model ...
Validation loss decreased (1.099966 --> 1.096358).  Saving model ...
Validation loss decreased (1.096358 --> 1.091832).  Saving model ...
Validation loss decreased (1.091832 --> 1.087613).  Saving model ...
Validation loss decreased (1.087613 --> 1.083736).  Saving model ...
Validation loss decreased (1.083736 --> 1.083691).  Saving model ...
Validation loss decreased (1.083691 --> 1.078081).  Saving model ...
Validation loss decreased (1.078081 --> 1.072563).  Saving model ...
Validation loss decreased (1.072563 --> 1.069425).  Saving model ...
Validation loss decreased (1.069425 --> 1.066911).  Saving model ...
Validation loss decreased (1.066911 --> 1.065796).  Saving model ...
Validation loss decreased (1.065796 --> 1.062500).  Saving model ...
Validation loss decreased (1.062500 --> 1.060538).  Saving model ...
Validation loss decreased (1.060538 --> 1.056768).  Saving model ...
Validation loss decreased (1.056768 --> 1.050010).  Saving model ...
Validation loss decreased (1.050010 --> 1.047092).  Saving model ...
Validation loss decreased (1.047092 --> 1.045091).  Saving model ...
Validation loss decreased (1.045091 --> 1.043210).  Saving model ...
Validation loss decreased (1.043210 --> 1.041164).  Saving model ...
Validation loss decreased (1.041164 --> 1.038727).  Saving model ...
Validation loss decreased (1.038727 --> 1.036357).  Saving model ...
Validation loss decreased (1.036357 --> 1.032406).  Saving model ...
EarlyStopping counter: 1 out of 5.0
Validation loss decreased (1.032406 --> 1.030622).  Saving model ...
Validation loss decreased (1.030622 --> 1.026632).  Saving model ...
Validation loss decreased (1.026632 --> 1.023346).  Saving model ...
EarlyStopping counter: 1 out of 5.0
Validation loss decreased (1.023346 --> 1.021594).  Saving model ...
Validation loss decreased (1.021594 --> 1.017243).  Saving model ...
Validation loss decreased (1.017243 --> 1.014336).  Saving model ...
Validation loss decreased (1.014336 --> 1.014027).  Saving model ...
Validation loss decreased (1.014027 --> 1.011329).  Saving model ...
Validation loss decreased (1.011329 --> 1.009068).  Saving model ...
Validation loss decreased (1.009068 --> 1.007702).  Saving model ...
EarlyStopping counter: 1 out of 5.0
Validation loss decreased (1.007702 --> 1.003766).  Saving model ...
Validation loss decreased (1.003766 --> 1.001740).  Saving model ...
Validation loss decreased (1.001740 --> 1.001116).  Saving model ...
Validation loss decreased (1.001116 --> 1.000623).  Saving model ...
Validation loss decreased (1.000623 --> 0.997372).  Saving model ...
Validation loss decreased (0.997372 --> 0.995883).  Saving model ...
Validation loss decreased (0.995883 --> 0.993246).  Saving model ...
Validation loss decreased (0.993246 --> 0.993215).  Saving model ...
Validation loss decreased (0.993215 --> 0.991084).  Saving model ...
Validation loss decreased (0.991084 --> 0.988145).  Saving model ...
Validation loss decreased (0.988145 --> 0.986091).  Saving model ...
Validation loss decreased (0.986091 --> 0.982816).  Saving model ...
Validation loss decreased (0.982816 --> 0.981393).  Saving model ...
Validation loss decreased (0.981393 --> 0.979247).  Saving model ...
EarlyStopping counter: 1 out of 5.0
EarlyStopping counter: 2 out of 5.0
Validation loss decreased (0.979247 --> 0.978395).  Saving model ...
Validation loss decreased (0.978395 --> 0.976539).  Saving model ...
Validation loss decreased (0.976539 --> 0.975894).  Saving model ...
EarlyStopping counter: 1 out of 5.0
EarlyStopping counter: 2 out of 5.0
Validation loss decreased (0.975894 --> 0.975628).  Saving model ...
Validation loss decreased (0.975628 --> 0.971251).  Saving model ...
EarlyStopping counter: 1 out of 5.0
EarlyStopping counter: 2 out of 5.0
Validation loss decreased (0.971251 --> 0.970935).  Saving model ...
EarlyStopping counter: 1 out of 5.0
EarlyStopping counter: 2 out of 5.0
EarlyStopping counter: 3 out of 5.0
Validation loss decreased (0.970935 --> 0.969237).  Saving model ...
Validation loss decreased (0.969237 --> 0.967573).  Saving model ...
EarlyStopping counter: 1 out of 5.0
Validation loss decreased (0.967573 --> 0.965824).  Saving model ...
Validation loss decreased (0.965824 --> 0.964428).  Saving model ...
Validation loss decreased (0.964428 --> 0.963496).  Saving model ...
EarlyStopping counter: 1 out of 5.0
EarlyStopping counter: 2 out of 5.0
Validation loss decreased (0.963496 --> 0.962990).  Saving model ...
EarlyStopping counter: 1 out of 5.0
Validation loss decreased (0.962990 --> 0.961618).  Saving model ...
Validation loss decreased (0.961618 --> 0.960771).  Saving model ...
EarlyStopping counter: 1 out of 5.0
EarlyStopping counter: 2 out of 5.0
EarlyStopping counter: 3 out of 5.0
EarlyStopping counter: 4 out of 5.0
EarlyStopping counter: 5 out of 5.0
/localscratch/yinan.29365731.0/env/lib/python3.7/site-packages/torch/nn/functional.py:1794: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.
  warnings.warn("nn.functional.tanh is deprecated. Use torch.tanh instead.")
wandb: Waiting for W&B process to finish, PID 125363... (success).
wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: \ 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: | 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: / 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: \ 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: | 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: / 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: \ 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: | 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: / 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: \ 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb:                                                                                
wandb: Run history:
wandb:     e_F1 ▁▂▅▅▆▆▆▆▇▆▇▇▇▇▇▇▇▇▇▇▇██▇███▇████████████
wandb:   e_loss ██▇▇▇▇▆▆▆▅▅▄▄▄▄▃▃▃▃▃▂▂▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁
wandb:     t_F1 ▁▁▂▃▃▃▄▄▄▄▅▅▅▅▅▆▆▆▆▆▇▆▇▇▆▇▇▇▇▇█▇▇███████
wandb:   t_loss ███▇▇▇▇▇▇▆▆▆▅▅▅▅▄▄▄▄▄▄▃▃▃▃▃▂▂▂▂▂▂▂▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:     e_F1 58.96019
wandb:   e_loss 0.96145
wandb:     t_F1 70.6603
wandb:   t_loss 0.76211
wandb: 
wandb: Synced 4 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Synced devoted-night-1: https://wandb.ai/yinanazhou/xl_512_bs_8_lr_1e06_es_5_lc_True_nr_True_sr_False_stem_False_lemma_True_repeat_2_fold_1/runs/2l0tnz8z
wandb: Find logs at: ./wandb/run-20220324_132228-2l0tnz8z/logs/debug.log
wandb: 

wandb: wandb version 0.12.11 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
2022-03-24 14:51:11.935467: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1
wandb: Tracking run with wandb version 0.12.5
wandb: Syncing run bright-sponge-1
wandb: ⭐️ View project at https://wandb.ai/yinanazhou/xl_512_bs_8_lr_1e06_es_5_lc_True_nr_True_sr_False_stem_False_lemma_True_repeat_2_fold_2
wandb: 🚀 View run at https://wandb.ai/yinanazhou/xl_512_bs_8_lr_1e06_es_5_lc_True_nr_True_sr_False_stem_False_lemma_True_repeat_2_fold_2/runs/280y87ed
wandb: Run data is saved locally in /project/6002780/yinan/Thesis_MER_Lyrics/lyric-emotion/wandb/run-20220324_145109-280y87ed
wandb: Run `wandb offline` to turn off syncing.

Validation loss decreased (inf --> 1.456929).  Saving model ...
Validation loss decreased (1.456929 --> 1.432913).  Saving model ...
Validation loss decreased (1.432913 --> 1.415524).  Saving model ...
Validation loss decreased (1.415524 --> 1.401762).  Saving model ...
Validation loss decreased (1.401762 --> 1.390382).  Saving model ...
Validation loss decreased (1.390382 --> 1.381636).  Saving model ...
Validation loss decreased (1.381636 --> 1.374753).  Saving model ...
Validation loss decreased (1.374753 --> 1.369520).  Saving model ...
Validation loss decreased (1.369520 --> 1.364950).  Saving model ...
Validation loss decreased (1.364950 --> 1.360720).  Saving model ...
Validation loss decreased (1.360720 --> 1.356638).  Saving model ...
Validation loss decreased (1.356638 --> 1.352650).  Saving model ...
Validation loss decreased (1.352650 --> 1.348823).  Saving model ...
Validation loss decreased (1.348823 --> 1.345045).  Saving model ...
Validation loss decreased (1.345045 --> 1.341128).  Saving model ...
Validation loss decreased (1.341128 --> 1.336849).  Saving model ...
Validation loss decreased (1.336849 --> 1.332933).  Saving model ...
Validation loss decreased (1.332933 --> 1.329150).  Saving model ...
Validation loss decreased (1.329150 --> 1.324323).  Saving model ...
Validation loss decreased (1.324323 --> 1.320165).  Saving model ...
Validation loss decreased (1.320165 --> 1.316006).  Saving model ...
Validation loss decreased (1.316006 --> 1.310945).  Saving model ...
Validation loss decreased (1.310945 --> 1.306343).  Saving model ...
Validation loss decreased (1.306343 --> 1.301664).  Saving model ...
Validation loss decreased (1.301664 --> 1.296390).  Saving model ...
Validation loss decreased (1.296390 --> 1.291244).  Saving model ...
Validation loss decreased (1.291244 --> 1.285034).  Saving model ...
Validation loss decreased (1.285034 --> 1.280336).  Saving model ...
Validation loss decreased (1.280336 --> 1.274897).  Saving model ...
Validation loss decreased (1.274897 --> 1.270121).  Saving model ...
Validation loss decreased (1.270121 --> 1.265603).  Saving model ...
Validation loss decreased (1.265603 --> 1.260680).  Saving model ...
Validation loss decreased (1.260680 --> 1.254839).  Saving model ...
Validation loss decreased (1.254839 --> 1.248643).  Saving model ...
Validation loss decreased (1.248643 --> 1.243586).  Saving model ...
Validation loss decreased (1.243586 --> 1.238155).  Saving model ...
Validation loss decreased (1.238155 --> 1.234286).  Saving model ...
Validation loss decreased (1.234286 --> 1.228968).  Saving model ...
Validation loss decreased (1.228968 --> 1.223681).  Saving model ...
Validation loss decreased (1.223681 --> 1.218506).  Saving model ...
Validation loss decreased (1.218506 --> 1.211697).  Saving model ...
Validation loss decreased (1.211697 --> 1.206359).  Saving model ...
Validation loss decreased (1.206359 --> 1.202969).  Saving model ...
Validation loss decreased (1.202969 --> 1.196703).  Saving model ...
Validation loss decreased (1.196703 --> 1.190833).  Saving model ...
Validation loss decreased (1.190833 --> 1.186263).  Saving model ...
Validation loss decreased (1.186263 --> 1.181603).  Saving model ...
Validation loss decreased (1.181603 --> 1.176546).  Saving model ...
Validation loss decreased (1.176546 --> 1.171759).  Saving model ...
Validation loss decreased (1.171759 --> 1.165767).  Saving model ...
Validation loss decreased (1.165767 --> 1.161964).  Saving model ...
Validation loss decreased (1.161964 --> 1.155934).  Saving model ...
Validation loss decreased (1.155934 --> 1.151656).  Saving model ...
Validation loss decreased (1.151656 --> 1.147570).  Saving model ...
Validation loss decreased (1.147570 --> 1.139698).  Saving model ...
Validation loss decreased (1.139698 --> 1.135123).  Saving model ...
Validation loss decreased (1.135123 --> 1.131807).  Saving model ...
Validation loss decreased (1.131807 --> 1.128461).  Saving model ...
Validation loss decreased (1.128461 --> 1.128012).  Saving model ...
Validation loss decreased (1.128012 --> 1.123796).  Saving model ...
Validation loss decreased (1.123796 --> 1.119745).  Saving model ...
Validation loss decreased (1.119745 --> 1.117561).  Saving model ...
Validation loss decreased (1.117561 --> 1.111791).  Saving model ...
Validation loss decreased (1.111791 --> 1.107595).  Saving model ...
Validation loss decreased (1.107595 --> 1.100656).  Saving model ...
Validation loss decreased (1.100656 --> 1.097774).  Saving model ...
Validation loss decreased (1.097774 --> 1.093505).  Saving model ...
Validation loss decreased (1.093505 --> 1.093049).  Saving model ...
Validation loss decreased (1.093049 --> 1.088635).  Saving model ...
Validation loss decreased (1.088635 --> 1.084747).  Saving model ...
Validation loss decreased (1.084747 --> 1.082290).  Saving model ...
Validation loss decreased (1.082290 --> 1.076294).  Saving model ...
Validation loss decreased (1.076294 --> 1.072254).  Saving model ...
Validation loss decreased (1.072254 --> 1.067757).  Saving model ...
Validation loss decreased (1.067757 --> 1.063429).  Saving model ...
Validation loss decreased (1.063429 --> 1.060139).  Saving model ...
Validation loss decreased (1.060139 --> 1.056870).  Saving model ...
Validation loss decreased (1.056870 --> 1.052785).  Saving model ...
Validation loss decreased (1.052785 --> 1.051732).  Saving model ...
Validation loss decreased (1.051732 --> 1.047214).  Saving model ...
Validation loss decreased (1.047214 --> 1.041746).  Saving model ...
Validation loss decreased (1.041746 --> 1.038276).  Saving model ...
Validation loss decreased (1.038276 --> 1.034860).  Saving model ...
Validation loss decreased (1.034860 --> 1.031824).  Saving model ...
Validation loss decreased (1.031824 --> 1.030091).  Saving model ...
Validation loss decreased (1.030091 --> 1.027060).  Saving model ...
Validation loss decreased (1.027060 --> 1.025893).  Saving model ...
Validation loss decreased (1.025893 --> 1.023951).  Saving model ...
Validation loss decreased (1.023951 --> 1.023218).  Saving model ...
Validation loss decreased (1.023218 --> 1.019533).  Saving model ...
Validation loss decreased (1.019533 --> 1.018807).  Saving model ...
Validation loss decreased (1.018807 --> 1.017100).  Saving model ...
EarlyStopping counter: 1 out of 5.0
Validation loss decreased (1.017100 --> 1.014229).  Saving model ...
Validation loss decreased (1.014229 --> 1.011871).  Saving model ...
Validation loss decreased (1.011871 --> 1.008341).  Saving model ...
Validation loss decreased (1.008341 --> 1.004183).  Saving model ...
Validation loss decreased (1.004183 --> 1.003550).  Saving model ...
Validation loss decreased (1.003550 --> 1.002912).  Saving model ...
Validation loss decreased (1.002912 --> 1.001279).  Saving model ...
Validation loss decreased (1.001279 --> 0.999648).  Saving model ...
Validation loss decreased (0.999648 --> 0.995548).  Saving model ...
Validation loss decreased (0.995548 --> 0.992676).  Saving model ...
Validation loss decreased (0.992676 --> 0.990295).  Saving model ...
Validation loss decreased (0.990295 --> 0.987561).  Saving model ...
Validation loss decreased (0.987561 --> 0.984114).  Saving model ...
Validation loss decreased (0.984114 --> 0.982221).  Saving model ...
Validation loss decreased (0.982221 --> 0.980893).  Saving model ...
Validation loss decreased (0.980893 --> 0.980054).  Saving model ...
Validation loss decreased (0.980054 --> 0.979998).  Saving model ...
Validation loss decreased (0.979998 --> 0.976495).  Saving model ...
Validation loss decreased (0.976495 --> 0.974119).  Saving model ...
Validation loss decreased (0.974119 --> 0.973238).  Saving model ...
EarlyStopping counter: 1 out of 5.0
Validation loss decreased (0.973238 --> 0.968907).  Saving model ...
Validation loss decreased (0.968907 --> 0.968734).  Saving model ...
Validation loss decreased (0.968734 --> 0.968462).  Saving model ...
Validation loss decreased (0.968462 --> 0.965401).  Saving model ...
EarlyStopping counter: 1 out of 5.0
Validation loss decreased (0.965401 --> 0.963957).  Saving model ...
Validation loss decreased (0.963957 --> 0.961601).  Saving model ...
Validation loss decreased (0.961601 --> 0.959735).  Saving model ...
Validation loss decreased (0.959735 --> 0.958086).  Saving model ...
EarlyStopping counter: 1 out of 5.0
EarlyStopping counter: 2 out of 5.0
Validation loss decreased (0.958086 --> 0.955884).  Saving model ...
EarlyStopping counter: 1 out of 5.0
Validation loss decreased (0.955884 --> 0.955791).  Saving model ...
Validation loss decreased (0.955791 --> 0.952726).  Saving model ...
EarlyStopping counter: 1 out of 5.0
EarlyStopping counter: 2 out of 5.0
Validation loss decreased (0.952726 --> 0.950939).  Saving model ...
Validation loss decreased (0.950939 --> 0.950002).  Saving model ...
EarlyStopping counter: 1 out of 5.0
EarlyStopping counter: 2 out of 5.0
Validation loss decreased (0.950002 --> 0.946223).  Saving model ...
EarlyStopping counter: 1 out of 5.0
EarlyStopping counter: 2 out of 5.0
EarlyStopping counter: 3 out of 5.0
EarlyStopping counter: 4 out of 5.0
Validation loss decreased (0.946223 --> 0.943982).  Saving model ...
EarlyStopping counter: 1 out of 5.0
Validation loss decreased (0.943982 --> 0.942258).  Saving model ...
Validation loss decreased (0.942258 --> 0.937589).  Saving model ...
EarlyStopping counter: 1 out of 5.0
EarlyStopping counter: 2 out of 5.0
EarlyStopping counter: 3 out of 5.0
EarlyStopping counter: 4 out of 5.0
EarlyStopping counter: 5 out of 5.0
/localscratch/yinan.29365731.0/env/lib/python3.7/site-packages/torch/nn/functional.py:1794: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.
  warnings.warn("nn.functional.tanh is deprecated. Use torch.tanh instead.")
wandb: Waiting for W&B process to finish, PID 130343... (success).
wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: \ 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: | 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: / 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: \ 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: | 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: / 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: \ 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: | 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb:                                                                                
wandb: Run history:
wandb:     e_F1 ▁▂▃▃▄▄▄▅▅▅▅▆▆▆▆▇▇▇▇▇▇▇▇▇▇▇▇▇▇███████████
wandb:   e_loss ██▇▇▇▆▆▆▆▅▅▅▅▄▄▄▄▃▃▃▃▃▂▂▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁
wandb:     t_F1 ▁▁▁▂▂▃▂▃▄▄▄▅▅▄▅▅▅▆▅▆▆▆▆▆▆▆▆▇▆▇▇▇▇▇▇█▇███
wandb:   t_loss ███▇▇▇▇▇▆▆▆▆▅▅▅▅▄▄▄▄▄▄▃▃▃▃▃▃▃▂▂▂▂▁▂▁▂▁▁▁
wandb: 
wandb: Run summary:
wandb:     e_F1 60.39171
wandb:   e_loss 0.94092
wandb:     t_F1 68.85829
wandb:   t_loss 0.78756
wandb: 
wandb: Synced 4 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Synced bright-sponge-1: https://wandb.ai/yinanazhou/xl_512_bs_8_lr_1e06_es_5_lc_True_nr_True_sr_False_stem_False_lemma_True_repeat_2_fold_2/runs/280y87ed
wandb: Find logs at: ./wandb/run-20220324_145109-280y87ed/logs/debug.log
wandb: 

wandb: wandb version 0.12.11 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
2022-03-24 16:29:37.166377: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1
wandb: Tracking run with wandb version 0.12.5
wandb: Syncing run prime-surf-1
wandb: ⭐️ View project at https://wandb.ai/yinanazhou/xl_512_bs_8_lr_1e06_es_5_lc_True_nr_True_sr_False_stem_False_lemma_True_repeat_3_fold_1
wandb: 🚀 View run at https://wandb.ai/yinanazhou/xl_512_bs_8_lr_1e06_es_5_lc_True_nr_True_sr_False_stem_False_lemma_True_repeat_3_fold_1/runs/t26yt473
wandb: Run data is saved locally in /project/6002780/yinan/Thesis_MER_Lyrics/lyric-emotion/wandb/run-20220324_162934-t26yt473
wandb: Run `wandb offline` to turn off syncing.

Validation loss decreased (inf --> 1.404140).  Saving model ...
Validation loss decreased (1.404140 --> 1.396755).  Saving model ...
Validation loss decreased (1.396755 --> 1.390513).  Saving model ...
Validation loss decreased (1.390513 --> 1.385417).  Saving model ...
Validation loss decreased (1.385417 --> 1.380912).  Saving model ...
Validation loss decreased (1.380912 --> 1.376629).  Saving model ...
Validation loss decreased (1.376629 --> 1.372831).  Saving model ...
Validation loss decreased (1.372831 --> 1.368849).  Saving model ...
Validation loss decreased (1.368849 --> 1.364702).  Saving model ...
Validation loss decreased (1.364702 --> 1.360709).  Saving model ...
Validation loss decreased (1.360709 --> 1.356812).  Saving model ...
Validation loss decreased (1.356812 --> 1.352976).  Saving model ...
Validation loss decreased (1.352976 --> 1.349122).  Saving model ...
Validation loss decreased (1.349122 --> 1.344846).  Saving model ...
Validation loss decreased (1.344846 --> 1.340412).  Saving model ...
Validation loss decreased (1.340412 --> 1.335939).  Saving model ...
Validation loss decreased (1.335939 --> 1.331732).  Saving model ...
Validation loss decreased (1.331732 --> 1.326867).  Saving model ...
Validation loss decreased (1.326867 --> 1.321886).  Saving model ...
Validation loss decreased (1.321886 --> 1.316572).  Saving model ...
Validation loss decreased (1.316572 --> 1.310596).  Saving model ...
Validation loss decreased (1.310596 --> 1.304487).  Saving model ...
Validation loss decreased (1.304487 --> 1.298352).  Saving model ...
Validation loss decreased (1.298352 --> 1.292761).  Saving model ...
Validation loss decreased (1.292761 --> 1.285756).  Saving model ...
Validation loss decreased (1.285756 --> 1.278317).  Saving model ...
Validation loss decreased (1.278317 --> 1.271589).  Saving model ...
Validation loss decreased (1.271589 --> 1.265527).  Saving model ...
Validation loss decreased (1.265527 --> 1.259838).  Saving model ...
Validation loss decreased (1.259838 --> 1.252108).  Saving model ...
Validation loss decreased (1.252108 --> 1.244536).  Saving model ...
Validation loss decreased (1.244536 --> 1.237839).  Saving model ...
Validation loss decreased (1.237839 --> 1.229688).  Saving model ...
Validation loss decreased (1.229688 --> 1.223836).  Saving model ...
Validation loss decreased (1.223836 --> 1.217982).  Saving model ...
Validation loss decreased (1.217982 --> 1.211522).  Saving model ...
Validation loss decreased (1.211522 --> 1.204095).  Saving model ...
Validation loss decreased (1.204095 --> 1.197485).  Saving model ...
Validation loss decreased (1.197485 --> 1.191341).  Saving model ...
Validation loss decreased (1.191341 --> 1.186501).  Saving model ...
Validation loss decreased (1.186501 --> 1.181652).  Saving model ...
Validation loss decreased (1.181652 --> 1.177364).  Saving model ...
Validation loss decreased (1.177364 --> 1.170777).  Saving model ...
Validation loss decreased (1.170777 --> 1.164764).  Saving model ...
Validation loss decreased (1.164764 --> 1.161687).  Saving model ...
Validation loss decreased (1.161687 --> 1.157646).  Saving model ...
Validation loss decreased (1.157646 --> 1.152126).  Saving model ...
Validation loss decreased (1.152126 --> 1.145642).  Saving model ...
Validation loss decreased (1.145642 --> 1.142172).  Saving model ...
Validation loss decreased (1.142172 --> 1.140796).  Saving model ...
Validation loss decreased (1.140796 --> 1.134382).  Saving model ...
Validation loss decreased (1.134382 --> 1.130019).  Saving model ...
Validation loss decreased (1.130019 --> 1.125437).  Saving model ...
Validation loss decreased (1.125437 --> 1.121558).  Saving model ...
Validation loss decreased (1.121558 --> 1.119971).  Saving model ...
Validation loss decreased (1.119971 --> 1.118861).  Saving model ...
Validation loss decreased (1.118861 --> 1.114636).  Saving model ...
Validation loss decreased (1.114636 --> 1.111344).  Saving model ...
Validation loss decreased (1.111344 --> 1.103978).  Saving model ...
Validation loss decreased (1.103978 --> 1.100907).  Saving model ...
Validation loss decreased (1.100907 --> 1.097438).  Saving model ...
Validation loss decreased (1.097438 --> 1.093474).  Saving model ...
Validation loss decreased (1.093474 --> 1.092328).  Saving model ...
Validation loss decreased (1.092328 --> 1.086885).  Saving model ...
Validation loss decreased (1.086885 --> 1.084381).  Saving model ...
Validation loss decreased (1.084381 --> 1.081294).  Saving model ...
Validation loss decreased (1.081294 --> 1.078433).  Saving model ...
Validation loss decreased (1.078433 --> 1.076806).  Saving model ...
Validation loss decreased (1.076806 --> 1.076329).  Saving model ...
Validation loss decreased (1.076329 --> 1.071688).  Saving model ...
Validation loss decreased (1.071688 --> 1.067568).  Saving model ...
Validation loss decreased (1.067568 --> 1.064963).  Saving model ...
Validation loss decreased (1.064963 --> 1.063779).  Saving model ...
Validation loss decreased (1.063779 --> 1.062643).  Saving model ...
EarlyStopping counter: 1 out of 5.0
Validation loss decreased (1.062643 --> 1.061760).  Saving model ...
Validation loss decreased (1.061760 --> 1.057722).  Saving model ...
Validation loss decreased (1.057722 --> 1.056919).  Saving model ...
Validation loss decreased (1.056919 --> 1.054139).  Saving model ...
Validation loss decreased (1.054139 --> 1.051557).  Saving model ...
Validation loss decreased (1.051557 --> 1.050004).  Saving model ...
Validation loss decreased (1.050004 --> 1.042680).  Saving model ...
Validation loss decreased (1.042680 --> 1.039025).  Saving model ...
Validation loss decreased (1.039025 --> 1.036327).  Saving model ...
EarlyStopping counter: 1 out of 5.0
EarlyStopping counter: 2 out of 5.0
Validation loss decreased (1.036327 --> 1.033501).  Saving model ...
Validation loss decreased (1.033501 --> 1.030005).  Saving model ...
Validation loss decreased (1.030005 --> 1.029732).  Saving model ...
EarlyStopping counter: 1 out of 5.0
Validation loss decreased (1.029732 --> 1.029525).  Saving model ...
Validation loss decreased (1.029525 --> 1.023902).  Saving model ...
Validation loss decreased (1.023902 --> 1.019749).  Saving model ...
Validation loss decreased (1.019749 --> 1.018782).  Saving model ...
Validation loss decreased (1.018782 --> 1.018500).  Saving model ...
EarlyStopping counter: 1 out of 5.0
Validation loss decreased (1.018500 --> 1.016272).  Saving model ...
Validation loss decreased (1.016272 --> 1.015105).  Saving model ...
Validation loss decreased (1.015105 --> 1.012877).  Saving model ...
EarlyStopping counter: 1 out of 5.0
Validation loss decreased (1.012877 --> 1.010910).  Saving model ...
Validation loss decreased (1.010910 --> 1.009296).  Saving model ...
Validation loss decreased (1.009296 --> 1.008286).  Saving model ...
Validation loss decreased (1.008286 --> 1.007061).  Saving model ...
Validation loss decreased (1.007061 --> 1.006336).  Saving model ...
EarlyStopping counter: 1 out of 5.0
Validation loss decreased (1.006336 --> 1.004720).  Saving model ...
EarlyStopping counter: 1 out of 5.0
EarlyStopping counter: 2 out of 5.0
EarlyStopping counter: 3 out of 5.0
Validation loss decreased (1.004720 --> 1.003460).  Saving model ...
Validation loss decreased (1.003460 --> 1.002265).  Saving model ...
Validation loss decreased (1.002265 --> 0.997973).  Saving model ...
EarlyStopping counter: 1 out of 5.0
EarlyStopping counter: 2 out of 5.0
Validation loss decreased (0.997973 --> 0.997869).  Saving model ...
Validation loss decreased (0.997869 --> 0.997630).  Saving model ...
Validation loss decreased (0.997630 --> 0.995412).  Saving model ...
Validation loss decreased (0.995412 --> 0.994910).  Saving model ...
Validation loss decreased (0.994910 --> 0.992219).  Saving model ...
EarlyStopping counter: 1 out of 5.0
EarlyStopping counter: 2 out of 5.0
EarlyStopping counter: 3 out of 5.0
EarlyStopping counter: 4 out of 5.0
EarlyStopping counter: 5 out of 5.0
/localscratch/yinan.29365731.0/env/lib/python3.7/site-packages/torch/nn/functional.py:1794: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.
  warnings.warn("nn.functional.tanh is deprecated. Use torch.tanh instead.")
wandb: Waiting for W&B process to finish, PID 135597... (success).
wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: \ 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: | 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: / 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: \ 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: | 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: / 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: \ 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: | 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: / 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb:                                                                                
wandb: Run history:
wandb:     e_F1 ▁▂▃▃▄▅▅▅▆▆▆▆▆▆▆▆▇▇▇▇▇▇▇▇▇▇▇█▇█▇█████████
wandb:   e_loss ██▇▇▇▇▇▆▆▆▅▅▄▄▄▄▃▃▃▃▃▂▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁
wandb:     t_F1 ▁▂▂▃▃▃▃▄▄▄▅▅▅▆▅▆▆▆▆▆▆▆▇▆▇▇▇▇▇▇▇▇▇▇██████
wandb:   t_loss ███▇▇▇▇▇▆▆▆▆▆▅▅▅▄▄▄▄▄▄▃▃▃▃▃▃▂▂▂▂▂▂▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:     e_F1 55.73613
wandb:   e_loss 0.99431
wandb:     t_F1 73.14349
wandb:   t_loss 0.77684
wandb: 
wandb: Synced 4 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Synced prime-surf-1: https://wandb.ai/yinanazhou/xl_512_bs_8_lr_1e06_es_5_lc_True_nr_True_sr_False_stem_False_lemma_True_repeat_3_fold_1/runs/t26yt473
wandb: Find logs at: ./wandb/run-20220324_162934-t26yt473/logs/debug.log
wandb: 

wandb: wandb version 0.12.11 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
2022-03-24 17:50:28.789730: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1
wandb: Tracking run with wandb version 0.12.5
wandb: Syncing run honest-planet-1
wandb: ⭐️ View project at https://wandb.ai/yinanazhou/xl_512_bs_8_lr_1e06_es_5_lc_True_nr_True_sr_False_stem_False_lemma_True_repeat_3_fold_2
wandb: 🚀 View run at https://wandb.ai/yinanazhou/xl_512_bs_8_lr_1e06_es_5_lc_True_nr_True_sr_False_stem_False_lemma_True_repeat_3_fold_2/runs/x7c534ou
wandb: Run data is saved locally in /project/6002780/yinan/Thesis_MER_Lyrics/lyric-emotion/wandb/run-20220324_175026-x7c534ou
wandb: Run `wandb offline` to turn off syncing.

Validation loss decreased (inf --> 1.406660).  Saving model ...
Validation loss decreased (1.406660 --> 1.392585).  Saving model ...
Validation loss decreased (1.392585 --> 1.382101).  Saving model ...
Validation loss decreased (1.382101 --> 1.374175).  Saving model ...
Validation loss decreased (1.374175 --> 1.367551).  Saving model ...
Validation loss decreased (1.367551 --> 1.361880).  Saving model ...
Validation loss decreased (1.361880 --> 1.356571).  Saving model ...
Validation loss decreased (1.356571 --> 1.352040).  Saving model ...
Validation loss decreased (1.352040 --> 1.347800).  Saving model ...
Validation loss decreased (1.347800 --> 1.343531).  Saving model ...
Validation loss decreased (1.343531 --> 1.339259).  Saving model ...
Validation loss decreased (1.339259 --> 1.335070).  Saving model ...
Validation loss decreased (1.335070 --> 1.330970).  Saving model ...
Validation loss decreased (1.330970 --> 1.326285).  Saving model ...
Validation loss decreased (1.326285 --> 1.321305).  Saving model ...
Validation loss decreased (1.321305 --> 1.316143).  Saving model ...
Validation loss decreased (1.316143 --> 1.311355).  Saving model ...
Validation loss decreased (1.311355 --> 1.306409).  Saving model ...
Validation loss decreased (1.306409 --> 1.301631).  Saving model ...
Validation loss decreased (1.301631 --> 1.296203).  Saving model ...
Validation loss decreased (1.296203 --> 1.291005).  Saving model ...
Validation loss decreased (1.291005 --> 1.285054).  Saving model ...
Validation loss decreased (1.285054 --> 1.278524).  Saving model ...
Validation loss decreased (1.278524 --> 1.271476).  Saving model ...
Validation loss decreased (1.271476 --> 1.265686).  Saving model ...
Validation loss decreased (1.265686 --> 1.258848).  Saving model ...
Validation loss decreased (1.258848 --> 1.252812).  Saving model ...
Validation loss decreased (1.252812 --> 1.245357).  Saving model ...
Validation loss decreased (1.245357 --> 1.237483).  Saving model ...
Validation loss decreased (1.237483 --> 1.230229).  Saving model ...
Validation loss decreased (1.230229 --> 1.223179).  Saving model ...
Validation loss decreased (1.223179 --> 1.215859).  Saving model ...
Validation loss decreased (1.215859 --> 1.209124).  Saving model ...
Validation loss decreased (1.209124 --> 1.200593).  Saving model ...
Validation loss decreased (1.200593 --> 1.191952).  Saving model ...
Validation loss decreased (1.191952 --> 1.184455).  Saving model ...
Validation loss decreased (1.184455 --> 1.177321).  Saving model ...
Validation loss decreased (1.177321 --> 1.169339).  Saving model ...
Validation loss decreased (1.169339 --> 1.162839).  Saving model ...
Validation loss decreased (1.162839 --> 1.155575).  Saving model ...
Validation loss decreased (1.155575 --> 1.147923).  Saving model ...
Validation loss decreased (1.147923 --> 1.143639).  Saving model ...
Validation loss decreased (1.143639 --> 1.138648).  Saving model ...
Validation loss decreased (1.138648 --> 1.131959).  Saving model ...
Validation loss decreased (1.131959 --> 1.126643).  Saving model ...
Validation loss decreased (1.126643 --> 1.119940).  Saving model ...
Validation loss decreased (1.119940 --> 1.114034).  Saving model ...
Validation loss decreased (1.114034 --> 1.109990).  Saving model ...
Validation loss decreased (1.109990 --> 1.102872).  Saving model ...
Validation loss decreased (1.102872 --> 1.095769).  Saving model ...
Validation loss decreased (1.095769 --> 1.091006).  Saving model ...
Validation loss decreased (1.091006 --> 1.087369).  Saving model ...
Validation loss decreased (1.087369 --> 1.083661).  Saving model ...
Validation loss decreased (1.083661 --> 1.078413).  Saving model ...
Validation loss decreased (1.078413 --> 1.074128).  Saving model ...
Validation loss decreased (1.074128 --> 1.070493).  Saving model ...
Validation loss decreased (1.070493 --> 1.065368).  Saving model ...
Validation loss decreased (1.065368 --> 1.060772).  Saving model ...
Validation loss decreased (1.060772 --> 1.056077).  Saving model ...
Validation loss decreased (1.056077 --> 1.051719).  Saving model ...
Validation loss decreased (1.051719 --> 1.046913).  Saving model ...
Validation loss decreased (1.046913 --> 1.044403).  Saving model ...
Validation loss decreased (1.044403 --> 1.040530).  Saving model ...
Validation loss decreased (1.040530 --> 1.036417).  Saving model ...
Validation loss decreased (1.036417 --> 1.033553).  Saving model ...
Validation loss decreased (1.033553 --> 1.029817).  Saving model ...
Validation loss decreased (1.029817 --> 1.025027).  Saving model ...
Validation loss decreased (1.025027 --> 1.020901).  Saving model ...
Validation loss decreased (1.020901 --> 1.017560).  Saving model ...
Validation loss decreased (1.017560 --> 1.014243).  Saving model ...
Validation loss decreased (1.014243 --> 1.011526).  Saving model ...
Validation loss decreased (1.011526 --> 1.008492).  Saving model ...
Validation loss decreased (1.008492 --> 1.004525).  Saving model ...
Validation loss decreased (1.004525 --> 1.002098).  Saving model ...
Validation loss decreased (1.002098 --> 0.998767).  Saving model ...
Validation loss decreased (0.998767 --> 0.996306).  Saving model ...
Validation loss decreased (0.996306 --> 0.992325).  Saving model ...
Validation loss decreased (0.992325 --> 0.988705).  Saving model ...
Validation loss decreased (0.988705 --> 0.985615).  Saving model ...
Validation loss decreased (0.985615 --> 0.982248).  Saving model ...
Validation loss decreased (0.982248 --> 0.980384).  Saving model ...
Validation loss decreased (0.980384 --> 0.977177).  Saving model ...
Validation loss decreased (0.977177 --> 0.976019).  Saving model ...
Validation loss decreased (0.976019 --> 0.972290).  Saving model ...
Validation loss decreased (0.972290 --> 0.970152).  Saving model ...
Validation loss decreased (0.970152 --> 0.967685).  Saving model ...
Validation loss decreased (0.967685 --> 0.966702).  Saving model ...
Validation loss decreased (0.966702 --> 0.964460).  Saving model ...
Validation loss decreased (0.964460 --> 0.961874).  Saving model ...
Validation loss decreased (0.961874 --> 0.959808).  Saving model ...
Validation loss decreased (0.959808 --> 0.958464).  Saving model ...
Validation loss decreased (0.958464 --> 0.956183).  Saving model ...
Validation loss decreased (0.956183 --> 0.954727).  Saving model ...
Validation loss decreased (0.954727 --> 0.952651).  Saving model ...
Validation loss decreased (0.952651 --> 0.950215).  Saving model ...
Validation loss decreased (0.950215 --> 0.948420).  Saving model ...
Validation loss decreased (0.948420 --> 0.947096).  Saving model ...
Validation loss decreased (0.947096 --> 0.944709).  Saving model ...
Validation loss decreased (0.944709 --> 0.944196).  Saving model ...
Validation loss decreased (0.944196 --> 0.943969).  Saving model ...
EarlyStopping counter: 1 out of 5.0
Validation loss decreased (0.943969 --> 0.942524).  Saving model ...
Validation loss decreased (0.942524 --> 0.941661).  Saving model ...
Validation loss decreased (0.941661 --> 0.937513).  Saving model ...
Validation loss decreased (0.937513 --> 0.936747).  Saving model ...
Validation loss decreased (0.936747 --> 0.935173).  Saving model ...
Validation loss decreased (0.935173 --> 0.933590).  Saving model ...
Validation loss decreased (0.933590 --> 0.930951).  Saving model ...
Validation loss decreased (0.930951 --> 0.928859).  Saving model ...
Validation loss decreased (0.928859 --> 0.927122).  Saving model ...
Validation loss decreased (0.927122 --> 0.925649).  Saving model ...
Validation loss decreased (0.925649 --> 0.924699).  Saving model ...
EarlyStopping counter: 1 out of 5.0
Validation loss decreased (0.924699 --> 0.924431).  Saving model ...
Validation loss decreased (0.924431 --> 0.923569).  Saving model ...
Validation loss decreased (0.923569 --> 0.921946).  Saving model ...
EarlyStopping counter: 1 out of 5.0
Validation loss decreased (0.921946 --> 0.920070).  Saving model ...
Validation loss decreased (0.920070 --> 0.919083).  Saving model ...
Validation loss decreased (0.919083 --> 0.918644).  Saving model ...
Validation loss decreased (0.918644 --> 0.917766).  Saving model ...
Validation loss decreased (0.917766 --> 0.916156).  Saving model ...
Validation loss decreased (0.916156 --> 0.915996).  Saving model ...
Validation loss decreased (0.915996 --> 0.915610).  Saving model ...
Validation loss decreased (0.915610 --> 0.914274).  Saving model ...
Validation loss decreased (0.914274 --> 0.913203).  Saving model ...
EarlyStopping counter: 1 out of 5.0
EarlyStopping counter: 2 out of 5.0
Validation loss decreased (0.913203 --> 0.912003).  Saving model ...
EarlyStopping counter: 1 out of 5.0
EarlyStopping counter: 2 out of 5.0
EarlyStopping counter: 3 out of 5.0
Validation loss decreased (0.912003 --> 0.911994).  Saving model ...
Validation loss decreased (0.911994 --> 0.910966).  Saving model ...
Validation loss decreased (0.910966 --> 0.909491).  Saving model ...
EarlyStopping counter: 1 out of 5.0
EarlyStopping counter: 2 out of 5.0
EarlyStopping counter: 3 out of 5.0
EarlyStopping counter: 4 out of 5.0
Validation loss decreased (0.909491 --> 0.909233).  Saving model ...
Validation loss decreased (0.909233 --> 0.907977).  Saving model ...
EarlyStopping counter: 1 out of 5.0
EarlyStopping counter: 2 out of 5.0
EarlyStopping counter: 3 out of 5.0
Validation loss decreased (0.907977 --> 0.907194).  Saving model ...
EarlyStopping counter: 1 out of 5.0
EarlyStopping counter: 2 out of 5.0
Validation loss decreased (0.907194 --> 0.906974).  Saving model ...
Validation loss decreased (0.906974 --> 0.905106).  Saving model ...
EarlyStopping counter: 1 out of 5.0
EarlyStopping counter: 2 out of 5.0
EarlyStopping counter: 3 out of 5.0
EarlyStopping counter: 4 out of 5.0
EarlyStopping counter: 5 out of 5.0
/localscratch/yinan.29365731.0/env/lib/python3.7/site-packages/torch/nn/functional.py:1794: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.
  warnings.warn("nn.functional.tanh is deprecated. Use torch.tanh instead.")
wandb: Waiting for W&B process to finish, PID 139925... (success).
wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: \ 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: | 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: / 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: \ 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: | 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: / 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: \ 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: | 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: / 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb:                                                                                
wandb: Run history:
wandb:     e_F1 ▁▁▃▄▄▄▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇▇▇▇▇▇▇▇▇█▇▇████████
wandb:   e_loss ██▇▇▇▇▆▆▅▅▅▄▄▄▃▃▃▃▂▂▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:     t_F1 ▁▁▂▂▃▃▃▄▄▅▅▅▅▅▅▆▆▆▇▆▇▆▆▇▇▇▇▇▇▇▇▇▇▇██████
wandb:   t_loss ███▇▇▇▇▇▆▆▆▅▅▅▅▄▄▄▄▄▃▃▃▃▃▂▂▂▂▂▂▂▂▂▂▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:     e_F1 63.16954
wandb:   e_loss 0.90607
wandb:     t_F1 70.89115
wandb:   t_loss 0.7298
wandb: 
wandb: Synced 4 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Synced honest-planet-1: https://wandb.ai/yinanazhou/xl_512_bs_8_lr_1e06_es_5_lc_True_nr_True_sr_False_stem_False_lemma_True_repeat_3_fold_2/runs/x7c534ou
wandb: Find logs at: ./wandb/run-20220324_175026-x7c534ou/logs/debug.log
wandb: 

wandb: wandb version 0.12.11 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
2022-03-24 19:32:07.235583: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1
wandb: Tracking run with wandb version 0.12.5
wandb: Syncing run colorful-shadow-1
wandb: ⭐️ View project at https://wandb.ai/yinanazhou/xl_512_bs_8_lr_1e06_es_5_lc_True_nr_True_sr_False_stem_False_lemma_True_repeat_4_fold_1
wandb: 🚀 View run at https://wandb.ai/yinanazhou/xl_512_bs_8_lr_1e06_es_5_lc_True_nr_True_sr_False_stem_False_lemma_True_repeat_4_fold_1/runs/3bbpl2u6
wandb: Run data is saved locally in /project/6002780/yinan/Thesis_MER_Lyrics/lyric-emotion/wandb/run-20220324_193204-3bbpl2u6
wandb: Run `wandb offline` to turn off syncing.

Validation loss decreased (inf --> 1.399628).  Saving model ...
Validation loss decreased (1.399628 --> 1.390526).  Saving model ...
Validation loss decreased (1.390526 --> 1.382194).  Saving model ...
Validation loss decreased (1.382194 --> 1.375716).  Saving model ...
Validation loss decreased (1.375716 --> 1.370134).  Saving model ...
Validation loss decreased (1.370134 --> 1.365138).  Saving model ...
Validation loss decreased (1.365138 --> 1.360416).  Saving model ...
Validation loss decreased (1.360416 --> 1.355634).  Saving model ...
Validation loss decreased (1.355634 --> 1.351476).  Saving model ...
Validation loss decreased (1.351476 --> 1.346770).  Saving model ...
Validation loss decreased (1.346770 --> 1.342455).  Saving model ...
Validation loss decreased (1.342455 --> 1.337481).  Saving model ...
Validation loss decreased (1.337481 --> 1.332433).  Saving model ...
Validation loss decreased (1.332433 --> 1.327434).  Saving model ...
Validation loss decreased (1.327434 --> 1.322429).  Saving model ...
Validation loss decreased (1.322429 --> 1.317589).  Saving model ...
Validation loss decreased (1.317589 --> 1.312158).  Saving model ...
Validation loss decreased (1.312158 --> 1.305672).  Saving model ...
Validation loss decreased (1.305672 --> 1.299871).  Saving model ...
Validation loss decreased (1.299871 --> 1.293049).  Saving model ...
Validation loss decreased (1.293049 --> 1.286514).  Saving model ...
Validation loss decreased (1.286514 --> 1.279649).  Saving model ...
Validation loss decreased (1.279649 --> 1.272145).  Saving model ...
Validation loss decreased (1.272145 --> 1.264854).  Saving model ...
Validation loss decreased (1.264854 --> 1.257769).  Saving model ...
Validation loss decreased (1.257769 --> 1.251198).  Saving model ...
Validation loss decreased (1.251198 --> 1.244813).  Saving model ...
Validation loss decreased (1.244813 --> 1.238339).  Saving model ...
Validation loss decreased (1.238339 --> 1.233182).  Saving model ...
Validation loss decreased (1.233182 --> 1.227018).  Saving model ...
Validation loss decreased (1.227018 --> 1.221243).  Saving model ...
Validation loss decreased (1.221243 --> 1.215677).  Saving model ...
Validation loss decreased (1.215677 --> 1.209577).  Saving model ...
Validation loss decreased (1.209577 --> 1.204295).  Saving model ...
Validation loss decreased (1.204295 --> 1.199865).  Saving model ...
Validation loss decreased (1.199865 --> 1.194484).  Saving model ...
Validation loss decreased (1.194484 --> 1.188829).  Saving model ...
Validation loss decreased (1.188829 --> 1.184332).  Saving model ...
Validation loss decreased (1.184332 --> 1.179520).  Saving model ...
Validation loss decreased (1.179520 --> 1.175579).  Saving model ...
Validation loss decreased (1.175579 --> 1.170733).  Saving model ...
Validation loss decreased (1.170733 --> 1.167252).  Saving model ...
Validation loss decreased (1.167252 --> 1.162195).  Saving model ...
Validation loss decreased (1.162195 --> 1.157894).  Saving model ...
Validation loss decreased (1.157894 --> 1.152703).  Saving model ...
Validation loss decreased (1.152703 --> 1.147078).  Saving model ...
Validation loss decreased (1.147078 --> 1.142398).  Saving model ...
Validation loss decreased (1.142398 --> 1.139011).  Saving model ...
Validation loss decreased (1.139011 --> 1.135201).  Saving model ...
Validation loss decreased (1.135201 --> 1.131645).  Saving model ...
Validation loss decreased (1.131645 --> 1.127641).  Saving model ...
Validation loss decreased (1.127641 --> 1.123594).  Saving model ...
Validation loss decreased (1.123594 --> 1.119280).  Saving model ...
Validation loss decreased (1.119280 --> 1.114990).  Saving model ...
Validation loss decreased (1.114990 --> 1.112257).  Saving model ...
Validation loss decreased (1.112257 --> 1.110158).  Saving model ...
Validation loss decreased (1.110158 --> 1.106486).  Saving model ...
Validation loss decreased (1.106486 --> 1.103507).  Saving model ...
Validation loss decreased (1.103507 --> 1.099721).  Saving model ...
Validation loss decreased (1.099721 --> 1.096526).  Saving model ...
Validation loss decreased (1.096526 --> 1.093022).  Saving model ...
Validation loss decreased (1.093022 --> 1.089875).  Saving model ...
Validation loss decreased (1.089875 --> 1.087428).  Saving model ...
Validation loss decreased (1.087428 --> 1.084093).  Saving model ...
Validation loss decreased (1.084093 --> 1.081928).  Saving model ...
Validation loss decreased (1.081928 --> 1.078007).  Saving model ...
Validation loss decreased (1.078007 --> 1.077033).  Saving model ...
Validation loss decreased (1.077033 --> 1.074291).  Saving model ...
Validation loss decreased (1.074291 --> 1.070771).  Saving model ...
Validation loss decreased (1.070771 --> 1.067253).  Saving model ...
Validation loss decreased (1.067253 --> 1.064460).  Saving model ...
Validation loss decreased (1.064460 --> 1.061145).  Saving model ...
Validation loss decreased (1.061145 --> 1.059673).  Saving model ...
Validation loss decreased (1.059673 --> 1.058619).  Saving model ...
Validation loss decreased (1.058619 --> 1.056815).  Saving model ...
Validation loss decreased (1.056815 --> 1.053607).  Saving model ...
Validation loss decreased (1.053607 --> 1.050689).  Saving model ...
Validation loss decreased (1.050689 --> 1.048112).  Saving model ...
Validation loss decreased (1.048112 --> 1.045279).  Saving model ...
Validation loss decreased (1.045279 --> 1.044891).  Saving model ...
Validation loss decreased (1.044891 --> 1.042720).  Saving model ...
Validation loss decreased (1.042720 --> 1.040583).  Saving model ...
Validation loss decreased (1.040583 --> 1.038160).  Saving model ...
Validation loss decreased (1.038160 --> 1.036161).  Saving model ...
Validation loss decreased (1.036161 --> 1.035266).  Saving model ...
Validation loss decreased (1.035266 --> 1.033149).  Saving model ...
Validation loss decreased (1.033149 --> 1.031960).  Saving model ...
Validation loss decreased (1.031960 --> 1.030405).  Saving model ...
Validation loss decreased (1.030405 --> 1.027233).  Saving model ...
Validation loss decreased (1.027233 --> 1.024032).  Saving model ...
Validation loss decreased (1.024032 --> 1.021090).  Saving model ...
Validation loss decreased (1.021090 --> 1.020723).  Saving model ...
Validation loss decreased (1.020723 --> 1.018411).  Saving model ...
Validation loss decreased (1.018411 --> 1.017513).  Saving model ...
EarlyStopping counter: 1 out of 5.0
Validation loss decreased (1.017513 --> 1.017370).  Saving model ...
Validation loss decreased (1.017370 --> 1.014508).  Saving model ...
Validation loss decreased (1.014508 --> 1.013314).  Saving model ...
Validation loss decreased (1.013314 --> 1.011270).  Saving model ...
EarlyStopping counter: 1 out of 5.0
Validation loss decreased (1.011270 --> 1.010951).  Saving model ...
Validation loss decreased (1.010951 --> 1.008095).  Saving model ...
Validation loss decreased (1.008095 --> 1.007026).  Saving model ...
Validation loss decreased (1.007026 --> 1.006210).  Saving model ...
Validation loss decreased (1.006210 --> 1.002978).  Saving model ...
EarlyStopping counter: 1 out of 5.0
EarlyStopping counter: 2 out of 5.0
Validation loss decreased (1.002978 --> 1.001160).  Saving model ...
Validation loss decreased (1.001160 --> 0.998609).  Saving model ...
Validation loss decreased (0.998609 --> 0.997621).  Saving model ...
EarlyStopping counter: 1 out of 5.0
Validation loss decreased (0.997621 --> 0.994682).  Saving model ...
Validation loss decreased (0.994682 --> 0.994450).  Saving model ...
Validation loss decreased (0.994450 --> 0.992174).  Saving model ...
Validation loss decreased (0.992174 --> 0.991266).  Saving model ...
EarlyStopping counter: 1 out of 5.0
EarlyStopping counter: 2 out of 5.0
Validation loss decreased (0.991266 --> 0.990077).  Saving model ...
Validation loss decreased (0.990077 --> 0.987507).  Saving model ...
EarlyStopping counter: 1 out of 5.0
EarlyStopping counter: 2 out of 5.0
Validation loss decreased (0.987507 --> 0.987012).  Saving model ...
EarlyStopping counter: 1 out of 5.0
Validation loss decreased (0.987012 --> 0.986325).  Saving model ...
EarlyStopping counter: 1 out of 5.0
EarlyStopping counter: 2 out of 5.0
Validation loss decreased (0.986325 --> 0.985038).  Saving model ...
Validation loss decreased (0.985038 --> 0.984326).  Saving model ...
Validation loss decreased (0.984326 --> 0.982752).  Saving model ...
EarlyStopping counter: 1 out of 5.0
EarlyStopping counter: 2 out of 5.0
Validation loss decreased (0.982752 --> 0.982228).  Saving model ...
Validation loss decreased (0.982228 --> 0.980018).  Saving model ...
EarlyStopping counter: 1 out of 5.0
EarlyStopping counter: 2 out of 5.0
EarlyStopping counter: 3 out of 5.0
EarlyStopping counter: 4 out of 5.0
Validation loss decreased (0.980018 --> 0.979769).  Saving model ...
EarlyStopping counter: 1 out of 5.0
Validation loss decreased (0.979769 --> 0.979751).  Saving model ...
Validation loss decreased (0.979751 --> 0.979622).  Saving model ...
EarlyStopping counter: 1 out of 5.0
EarlyStopping counter: 2 out of 5.0
Validation loss decreased (0.979622 --> 0.978230).  Saving model ...
EarlyStopping counter: 1 out of 5.0
EarlyStopping counter: 2 out of 5.0
EarlyStopping counter: 3 out of 5.0
EarlyStopping counter: 4 out of 5.0
EarlyStopping counter: 5 out of 5.0
/localscratch/yinan.29365731.0/env/lib/python3.7/site-packages/torch/nn/functional.py:1794: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.
  warnings.warn("nn.functional.tanh is deprecated. Use torch.tanh instead.")
wandb: Waiting for W&B process to finish, PID 145374... (success).
wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: \ 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: | 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: / 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb:                                                                                
wandb: Run history:
wandb:     e_F1 ▁▂▄▄▅▅▅▆▆▆▆▆▆▆▇▇▇▇▇▇▇▇▇▇▇███████████████
wandb:   e_loss ██▇▇▇▆▆▅▅▅▄▄▄▄▃▃▃▃▃▂▂▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁
wandb:     t_F1 ▁▁▂▂▃▃▄▄▄▄▅▅▅▅▅▆▆▆▆▆▆▆▆▆▇▇▇▇▇▇▇▇████▇███
wandb:   t_loss ████▇▇▇▆▆▆▆▅▅▅▅▄▅▄▄▄▃▄▃▃▃▃▃▃▂▂▂▂▂▂▂▂▂▁▁▁
wandb: 
wandb: Run summary:
wandb:     e_F1 57.16416
wandb:   e_loss 0.97916
wandb:     t_F1 72.0481
wandb:   t_loss 0.73788
wandb: 
wandb: Synced 4 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Synced colorful-shadow-1: https://wandb.ai/yinanazhou/xl_512_bs_8_lr_1e06_es_5_lc_True_nr_True_sr_False_stem_False_lemma_True_repeat_4_fold_1/runs/3bbpl2u6
wandb: Find logs at: ./wandb/run-20220324_193204-3bbpl2u6/logs/debug.log
wandb: 

wandb: wandb version 0.12.11 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
2022-03-24 21:07:23.654196: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1
wandb: Tracking run with wandb version 0.12.5
wandb: Syncing run feasible-shadow-1
wandb: ⭐️ View project at https://wandb.ai/yinanazhou/xl_512_bs_8_lr_1e06_es_5_lc_True_nr_True_sr_False_stem_False_lemma_True_repeat_4_fold_2
wandb: 🚀 View run at https://wandb.ai/yinanazhou/xl_512_bs_8_lr_1e06_es_5_lc_True_nr_True_sr_False_stem_False_lemma_True_repeat_4_fold_2/runs/oryju1k0
wandb: Run data is saved locally in /project/6002780/yinan/Thesis_MER_Lyrics/lyric-emotion/wandb/run-20220324_210721-oryju1k0
wandb: Run `wandb offline` to turn off syncing.

Validation loss decreased (inf --> 1.426821).  Saving model ...
Validation loss decreased (1.426821 --> 1.403482).  Saving model ...
Validation loss decreased (1.403482 --> 1.385261).  Saving model ...
Validation loss decreased (1.385261 --> 1.371966).  Saving model ...
Validation loss decreased (1.371966 --> 1.361259).  Saving model ...
Validation loss decreased (1.361259 --> 1.352210).  Saving model ...
Validation loss decreased (1.352210 --> 1.345879).  Saving model ...
Validation loss decreased (1.345879 --> 1.339523).  Saving model ...
Validation loss decreased (1.339523 --> 1.334566).  Saving model ...
Validation loss decreased (1.334566 --> 1.329177).  Saving model ...
Validation loss decreased (1.329177 --> 1.324513).  Saving model ...
Validation loss decreased (1.324513 --> 1.319595).  Saving model ...
Validation loss decreased (1.319595 --> 1.314524).  Saving model ...
Validation loss decreased (1.314524 --> 1.309684).  Saving model ...
Validation loss decreased (1.309684 --> 1.304770).  Saving model ...
Validation loss decreased (1.304770 --> 1.299889).  Saving model ...
Validation loss decreased (1.299889 --> 1.294903).  Saving model ...
Validation loss decreased (1.294903 --> 1.290162).  Saving model ...
Validation loss decreased (1.290162 --> 1.285607).  Saving model ...
Validation loss decreased (1.285607 --> 1.278893).  Saving model ...
Validation loss decreased (1.278893 --> 1.273076).  Saving model ...
Validation loss decreased (1.273076 --> 1.266766).  Saving model ...
Validation loss decreased (1.266766 --> 1.260367).  Saving model ...
Validation loss decreased (1.260367 --> 1.254986).  Saving model ...
Validation loss decreased (1.254986 --> 1.248419).  Saving model ...
Validation loss decreased (1.248419 --> 1.242051).  Saving model ...
Validation loss decreased (1.242051 --> 1.235526).  Saving model ...
Validation loss decreased (1.235526 --> 1.228711).  Saving model ...
Validation loss decreased (1.228711 --> 1.222381).  Saving model ...
Validation loss decreased (1.222381 --> 1.214416).  Saving model ...
Validation loss decreased (1.214416 --> 1.207770).  Saving model ...
Validation loss decreased (1.207770 --> 1.202162).  Saving model ...
Validation loss decreased (1.202162 --> 1.194729).  Saving model ...
Validation loss decreased (1.194729 --> 1.189948).  Saving model ...
Validation loss decreased (1.189948 --> 1.183672).  Saving model ...
Validation loss decreased (1.183672 --> 1.178106).  Saving model ...
Validation loss decreased (1.178106 --> 1.173565).  Saving model ...
Validation loss decreased (1.173565 --> 1.166594).  Saving model ...
Validation loss decreased (1.166594 --> 1.161090).  Saving model ...
Validation loss decreased (1.161090 --> 1.156752).  Saving model ...
Validation loss decreased (1.156752 --> 1.150399).  Saving model ...
Validation loss decreased (1.150399 --> 1.144519).  Saving model ...
Validation loss decreased (1.144519 --> 1.136479).  Saving model ...
Validation loss decreased (1.136479 --> 1.134308).  Saving model ...
Validation loss decreased (1.134308 --> 1.128815).  Saving model ...
Validation loss decreased (1.128815 --> 1.125543).  Saving model ...
Validation loss decreased (1.125543 --> 1.120132).  Saving model ...
Validation loss decreased (1.120132 --> 1.115880).  Saving model ...
Validation loss decreased (1.115880 --> 1.107722).  Saving model ...
Validation loss decreased (1.107722 --> 1.101988).  Saving model ...
EarlyStopping counter: 1 out of 5.0
Validation loss decreased (1.101988 --> 1.094726).  Saving model ...
Validation loss decreased (1.094726 --> 1.090653).  Saving model ...
Validation loss decreased (1.090653 --> 1.088423).  Saving model ...
Validation loss decreased (1.088423 --> 1.081643).  Saving model ...
Validation loss decreased (1.081643 --> 1.078913).  Saving model ...
Validation loss decreased (1.078913 --> 1.076385).  Saving model ...
Validation loss decreased (1.076385 --> 1.071013).  Saving model ...
Validation loss decreased (1.071013 --> 1.063832).  Saving model ...
EarlyStopping counter: 1 out of 5.0
Validation loss decreased (1.063832 --> 1.061495).  Saving model ...
Validation loss decreased (1.061495 --> 1.054896).  Saving model ...
EarlyStopping counter: 1 out of 5.0
EarlyStopping counter: 2 out of 5.0
Validation loss decreased (1.054896 --> 1.052749).  Saving model ...
Validation loss decreased (1.052749 --> 1.052166).  Saving model ...
Validation loss decreased (1.052166 --> 1.046543).  Saving model ...
Validation loss decreased (1.046543 --> 1.042048).  Saving model ...
Validation loss decreased (1.042048 --> 1.034586).  Saving model ...
EarlyStopping counter: 1 out of 5.0
Validation loss decreased (1.034586 --> 1.029406).  Saving model ...
Validation loss decreased (1.029406 --> 1.025414).  Saving model ...
EarlyStopping counter: 1 out of 5.0
Validation loss decreased (1.025414 --> 1.022401).  Saving model ...
Validation loss decreased (1.022401 --> 1.017801).  Saving model ...
EarlyStopping counter: 1 out of 5.0
Validation loss decreased (1.017801 --> 1.016946).  Saving model ...
EarlyStopping counter: 1 out of 5.0
Validation loss decreased (1.016946 --> 1.013120).  Saving model ...
Validation loss decreased (1.013120 --> 1.009552).  Saving model ...
EarlyStopping counter: 1 out of 5.0
Validation loss decreased (1.009552 --> 1.005363).  Saving model ...
Validation loss decreased (1.005363 --> 1.003008).  Saving model ...
EarlyStopping counter: 1 out of 5.0
Validation loss decreased (1.003008 --> 0.998318).  Saving model ...
Validation loss decreased (0.998318 --> 0.993710).  Saving model ...
EarlyStopping counter: 1 out of 5.0
Validation loss decreased (0.993710 --> 0.991226).  Saving model ...
Validation loss decreased (0.991226 --> 0.991176).  Saving model ...
Validation loss decreased (0.991176 --> 0.990431).  Saving model ...
Validation loss decreased (0.990431 --> 0.986804).  Saving model ...
Validation loss decreased (0.986804 --> 0.983302).  Saving model ...
EarlyStopping counter: 1 out of 5.0
Validation loss decreased (0.983302 --> 0.983068).  Saving model ...
Validation loss decreased (0.983068 --> 0.980866).  Saving model ...
EarlyStopping counter: 1 out of 5.0
Validation loss decreased (0.980866 --> 0.979360).  Saving model ...
Validation loss decreased (0.979360 --> 0.976475).  Saving model ...
EarlyStopping counter: 1 out of 5.0
EarlyStopping counter: 2 out of 5.0
EarlyStopping counter: 3 out of 5.0
Validation loss decreased (0.976475 --> 0.975451).  Saving model ...
EarlyStopping counter: 1 out of 5.0
Validation loss decreased (0.975451 --> 0.972288).  Saving model ...
Validation loss decreased (0.972288 --> 0.971411).  Saving model ...
Validation loss decreased (0.971411 --> 0.968769).  Saving model ...
EarlyStopping counter: 1 out of 5.0
Validation loss decreased (0.968769 --> 0.968227).  Saving model ...
Validation loss decreased (0.968227 --> 0.967576).  Saving model ...
Validation loss decreased (0.967576 --> 0.965730).  Saving model ...
Validation loss decreased (0.965730 --> 0.963972).  Saving model ...
EarlyStopping counter: 1 out of 5.0
Validation loss decreased (0.963972 --> 0.961609).  Saving model ...
EarlyStopping counter: 1 out of 5.0
Validation loss decreased (0.961609 --> 0.959657).  Saving model ...
EarlyStopping counter: 1 out of 5.0
EarlyStopping counter: 2 out of 5.0
EarlyStopping counter: 3 out of 5.0
EarlyStopping counter: 4 out of 5.0
EarlyStopping counter: 5 out of 5.0
/localscratch/yinan.29365731.0/env/lib/python3.7/site-packages/torch/nn/functional.py:1794: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.
  warnings.warn("nn.functional.tanh is deprecated. Use torch.tanh instead.")
wandb: Waiting for W&B process to finish, PID 150485... (success).
wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: \ 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: | 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: / 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: \ 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: | 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: / 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: \ 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: | 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: / 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb:                                                                                
wandb: Run history:
wandb:     e_F1 ▁▂▄▅▆▆▆▆▆▆▇▇▇▇▇▇▇▇▇▇▇▇▇▇█▇▇▇████████████
wandb:   e_loss █▇▇▇▆▆▆▆▅▅▅▄▄▄▄▃▃▃▃▃▂▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁
wandb:     t_F1 ▁▂▃▃▄▃▄▄▄▅▅▅▅▆▆▆▆▇▆▆▇▇▇▇▇▇▇▇▇▇▇██▇██████
wandb:   t_loss █▇▇▇▇▇▇▆▆▆▆▅▅▅▅▄▄▄▄▄▃▃▃▃▃▃▃▃▂▂▂▂▂▂▂▂▂▂▁▁
wandb: 
wandb: Run summary:
wandb:     e_F1 58.07549
wandb:   e_loss 0.96624
wandb:     t_F1 69.47549
wandb:   t_loss 0.77968
wandb: 
wandb: Synced 4 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Synced feasible-shadow-1: https://wandb.ai/yinanazhou/xl_512_bs_8_lr_1e06_es_5_lc_True_nr_True_sr_False_stem_False_lemma_True_repeat_4_fold_2/runs/oryju1k0
wandb: Find logs at: ./wandb/run-20220324_210721-oryju1k0/logs/debug.log
wandb: 

wandb: wandb version 0.12.11 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
2022-03-24 22:24:03.459754: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1
wandb: Tracking run with wandb version 0.12.5
wandb: Syncing run lilac-mountain-1
wandb: ⭐️ View project at https://wandb.ai/yinanazhou/xl_512_bs_8_lr_1e06_es_5_lc_True_nr_True_sr_False_stem_False_lemma_True_repeat_5_fold_1
wandb: 🚀 View run at https://wandb.ai/yinanazhou/xl_512_bs_8_lr_1e06_es_5_lc_True_nr_True_sr_False_stem_False_lemma_True_repeat_5_fold_1/runs/1inqdtyd
wandb: Run data is saved locally in /project/6002780/yinan/Thesis_MER_Lyrics/lyric-emotion/wandb/run-20220324_222401-1inqdtyd
wandb: Run `wandb offline` to turn off syncing.

Validation loss decreased (inf --> 1.411852).  Saving model ...
Validation loss decreased (1.411852 --> 1.402292).  Saving model ...
Validation loss decreased (1.402292 --> 1.394510).  Saving model ...
Validation loss decreased (1.394510 --> 1.388321).  Saving model ...
Validation loss decreased (1.388321 --> 1.383746).  Saving model ...
Validation loss decreased (1.383746 --> 1.379905).  Saving model ...
Validation loss decreased (1.379905 --> 1.376326).  Saving model ...
Validation loss decreased (1.376326 --> 1.373247).  Saving model ...
Validation loss decreased (1.373247 --> 1.370230).  Saving model ...
Validation loss decreased (1.370230 --> 1.367120).  Saving model ...
Validation loss decreased (1.367120 --> 1.364071).  Saving model ...
Validation loss decreased (1.364071 --> 1.361204).  Saving model ...
Validation loss decreased (1.361204 --> 1.357939).  Saving model ...
Validation loss decreased (1.357939 --> 1.354802).  Saving model ...
Validation loss decreased (1.354802 --> 1.351391).  Saving model ...
Validation loss decreased (1.351391 --> 1.347940).  Saving model ...
Validation loss decreased (1.347940 --> 1.344404).  Saving model ...
Validation loss decreased (1.344404 --> 1.340556).  Saving model ...
Validation loss decreased (1.340556 --> 1.336964).  Saving model ...
Validation loss decreased (1.336964 --> 1.332253).  Saving model ...
Validation loss decreased (1.332253 --> 1.327509).  Saving model ...
Validation loss decreased (1.327509 --> 1.322517).  Saving model ...
Validation loss decreased (1.322517 --> 1.317835).  Saving model ...
Validation loss decreased (1.317835 --> 1.312542).  Saving model ...
Validation loss decreased (1.312542 --> 1.307166).  Saving model ...
Validation loss decreased (1.307166 --> 1.301270).  Saving model ...
Validation loss decreased (1.301270 --> 1.294031).  Saving model ...
Validation loss decreased (1.294031 --> 1.288280).  Saving model ...
Validation loss decreased (1.288280 --> 1.281296).  Saving model ...
Validation loss decreased (1.281296 --> 1.275752).  Saving model ...
Validation loss decreased (1.275752 --> 1.268921).  Saving model ...
Validation loss decreased (1.268921 --> 1.263064).  Saving model ...
Validation loss decreased (1.263064 --> 1.256051).  Saving model ...
Validation loss decreased (1.256051 --> 1.250037).  Saving model ...
Validation loss decreased (1.250037 --> 1.243421).  Saving model ...
Validation loss decreased (1.243421 --> 1.237392).  Saving model ...
Validation loss decreased (1.237392 --> 1.232234).  Saving model ...
Validation loss decreased (1.232234 --> 1.226669).  Saving model ...
Validation loss decreased (1.226669 --> 1.222117).  Saving model ...
Validation loss decreased (1.222117 --> 1.216557).  Saving model ...
Validation loss decreased (1.216557 --> 1.211321).  Saving model ...
Validation loss decreased (1.211321 --> 1.206105).  Saving model ...
Validation loss decreased (1.206105 --> 1.201479).  Saving model ...
Validation loss decreased (1.201479 --> 1.195908).  Saving model ...
Validation loss decreased (1.195908 --> 1.190101).  Saving model ...
Validation loss decreased (1.190101 --> 1.183907).  Saving model ...
Validation loss decreased (1.183907 --> 1.178506).  Saving model ...
Validation loss decreased (1.178506 --> 1.174307).  Saving model ...
Validation loss decreased (1.174307 --> 1.170137).  Saving model ...
Validation loss decreased (1.170137 --> 1.164573).  Saving model ...
Validation loss decreased (1.164573 --> 1.159839).  Saving model ...
Validation loss decreased (1.159839 --> 1.154966).  Saving model ...
Validation loss decreased (1.154966 --> 1.151531).  Saving model ...
Validation loss decreased (1.151531 --> 1.147454).  Saving model ...
Validation loss decreased (1.147454 --> 1.143986).  Saving model ...
Validation loss decreased (1.143986 --> 1.141993).  Saving model ...
Validation loss decreased (1.141993 --> 1.137986).  Saving model ...
Validation loss decreased (1.137986 --> 1.134520).  Saving model ...
Validation loss decreased (1.134520 --> 1.129727).  Saving model ...
Validation loss decreased (1.129727 --> 1.124500).  Saving model ...
Validation loss decreased (1.124500 --> 1.121876).  Saving model ...
Validation loss decreased (1.121876 --> 1.118040).  Saving model ...
Validation loss decreased (1.118040 --> 1.114204).  Saving model ...
Validation loss decreased (1.114204 --> 1.110585).  Saving model ...
Validation loss decreased (1.110585 --> 1.104894).  Saving model ...
Validation loss decreased (1.104894 --> 1.101423).  Saving model ...
Validation loss decreased (1.101423 --> 1.096768).  Saving model ...
Validation loss decreased (1.096768 --> 1.093822).  Saving model ...
Validation loss decreased (1.093822 --> 1.089958).  Saving model ...
Validation loss decreased (1.089958 --> 1.087848).  Saving model ...
Validation loss decreased (1.087848 --> 1.085626).  Saving model ...
Validation loss decreased (1.085626 --> 1.081648).  Saving model ...
Validation loss decreased (1.081648 --> 1.078815).  Saving model ...
Validation loss decreased (1.078815 --> 1.076673).  Saving model ...
Validation loss decreased (1.076673 --> 1.072200).  Saving model ...
Validation loss decreased (1.072200 --> 1.067844).  Saving model ...
Validation loss decreased (1.067844 --> 1.065414).  Saving model ...
Validation loss decreased (1.065414 --> 1.061613).  Saving model ...
Validation loss decreased (1.061613 --> 1.058272).  Saving model ...
Validation loss decreased (1.058272 --> 1.055908).  Saving model ...
Validation loss decreased (1.055908 --> 1.053582).  Saving model ...
Validation loss decreased (1.053582 --> 1.051389).  Saving model ...
Validation loss decreased (1.051389 --> 1.047867).  Saving model ...
Validation loss decreased (1.047867 --> 1.045149).  Saving model ...
Validation loss decreased (1.045149 --> 1.044248).  Saving model ...
Validation loss decreased (1.044248 --> 1.042652).  Saving model ...
Validation loss decreased (1.042652 --> 1.039005).  Saving model ...
Validation loss decreased (1.039005 --> 1.036872).  Saving model ...
Validation loss decreased (1.036872 --> 1.036266).  Saving model ...
Validation loss decreased (1.036266 --> 1.034975).  Saving model ...
Validation loss decreased (1.034975 --> 1.032317).  Saving model ...
Validation loss decreased (1.032317 --> 1.029078).  Saving model ...
Validation loss decreased (1.029078 --> 1.025845).  Saving model ...
Validation loss decreased (1.025845 --> 1.024667).  Saving model ...
Validation loss decreased (1.024667 --> 1.023430).  Saving model ...
Validation loss decreased (1.023430 --> 1.020078).  Saving model ...
Validation loss decreased (1.020078 --> 1.019687).  Saving model ...
Validation loss decreased (1.019687 --> 1.017778).  Saving model ...
Validation loss decreased (1.017778 --> 1.014703).  Saving model ...
Validation loss decreased (1.014703 --> 1.013127).  Saving model ...
Validation loss decreased (1.013127 --> 1.011841).  Saving model ...
Validation loss decreased (1.011841 --> 1.010140).  Saving model ...
Validation loss decreased (1.010140 --> 1.009877).  Saving model ...
Validation loss decreased (1.009877 --> 1.007044).  Saving model ...
Validation loss decreased (1.007044 --> 1.005630).  Saving model ...
Validation loss decreased (1.005630 --> 1.004304).  Saving model ...
Validation loss decreased (1.004304 --> 1.003394).  Saving model ...
Validation loss decreased (1.003394 --> 1.001111).  Saving model ...
Validation loss decreased (1.001111 --> 1.000515).  Saving model ...
Validation loss decreased (1.000515 --> 0.999817).  Saving model ...
Validation loss decreased (0.999817 --> 0.996296).  Saving model ...
Validation loss decreased (0.996296 --> 0.995661).  Saving model ...
EarlyStopping counter: 1 out of 5.0
Validation loss decreased (0.995661 --> 0.994472).  Saving model ...
Validation loss decreased (0.994472 --> 0.992621).  Saving model ...
EarlyStopping counter: 1 out of 5.0
Validation loss decreased (0.992621 --> 0.992477).  Saving model ...
Validation loss decreased (0.992477 --> 0.990881).  Saving model ...
EarlyStopping counter: 1 out of 5.0
Validation loss decreased (0.990881 --> 0.989858).  Saving model ...
Validation loss decreased (0.989858 --> 0.989137).  Saving model ...
Validation loss decreased (0.989137 --> 0.987746).  Saving model ...
Validation loss decreased (0.987746 --> 0.987055).  Saving model ...
Validation loss decreased (0.987055 --> 0.985328).  Saving model ...
EarlyStopping counter: 1 out of 5.0
EarlyStopping counter: 2 out of 5.0
EarlyStopping counter: 3 out of 5.0
EarlyStopping counter: 4 out of 5.0
EarlyStopping counter: 5 out of 5.0
/localscratch/yinan.29365731.0/env/lib/python3.7/site-packages/torch/nn/functional.py:1794: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.
  warnings.warn("nn.functional.tanh is deprecated. Use torch.tanh instead.")
wandb: Waiting for W&B process to finish, PID 154552... (success).
wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: \ 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: | 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: / 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: \ 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: | 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: / 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: \ 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: | 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: / 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb:                                                                                
wandb: Run history:
wandb:     e_F1 ▁▁▂▃▄▄▄▅▅▅▆▆▆▆▆▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇█████████
wandb:   e_loss ███▇▇▇▇▆▆▆▅▅▅▅▄▄▄▄▃▃▃▃▃▂▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁
wandb:     t_F1 ▁▁▂▂▃▃▃▃▃▃▄▄▅▅▅▅▆▅▅▆▆▆▆▆▇▇▆▇▇▇▇▇▇▇▇▇██▇█
wandb:   t_loss ████▇▇▇▇▇▇▆▆▆▅▅▅▅▅▄▄▄▄▄▃▃▃▃▃▃▃▃▂▂▂▂▂▂▁▂▁
wandb: 
wandb: Run summary:
wandb:     e_F1 55.1867
wandb:   e_loss 0.98557
wandb:     t_F1 68.30535
wandb:   t_loss 0.7974
wandb: 
wandb: Synced 4 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Synced lilac-mountain-1: https://wandb.ai/yinanazhou/xl_512_bs_8_lr_1e06_es_5_lc_True_nr_True_sr_False_stem_False_lemma_True_repeat_5_fold_1/runs/1inqdtyd
wandb: Find logs at: ./wandb/run-20220324_222401-1inqdtyd/logs/debug.log
wandb: 

wandb: wandb version 0.12.11 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
2022-03-24 23:49:20.959006: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1
wandb: Tracking run with wandb version 0.12.5
wandb: Syncing run rich-tree-1
wandb: ⭐️ View project at https://wandb.ai/yinanazhou/xl_512_bs_8_lr_1e06_es_5_lc_True_nr_True_sr_False_stem_False_lemma_True_repeat_5_fold_2
wandb: 🚀 View run at https://wandb.ai/yinanazhou/xl_512_bs_8_lr_1e06_es_5_lc_True_nr_True_sr_False_stem_False_lemma_True_repeat_5_fold_2/runs/129js2rm
wandb: Run data is saved locally in /project/6002780/yinan/Thesis_MER_Lyrics/lyric-emotion/wandb/run-20220324_234918-129js2rm
wandb: Run `wandb offline` to turn off syncing.

Validation loss decreased (inf --> 1.508854).  Saving model ...
Validation loss decreased (1.508854 --> 1.463585).  Saving model ...
Validation loss decreased (1.463585 --> 1.430248).  Saving model ...
Validation loss decreased (1.430248 --> 1.406279).  Saving model ...
Validation loss decreased (1.406279 --> 1.388257).  Saving model ...
Validation loss decreased (1.388257 --> 1.374855).  Saving model ...
Validation loss decreased (1.374855 --> 1.363740).  Saving model ...
Validation loss decreased (1.363740 --> 1.355808).  Saving model ...
Validation loss decreased (1.355808 --> 1.348841).  Saving model ...
Validation loss decreased (1.348841 --> 1.342832).  Saving model ...
Validation loss decreased (1.342832 --> 1.338128).  Saving model ...
Validation loss decreased (1.338128 --> 1.333329).  Saving model ...
Validation loss decreased (1.333329 --> 1.328008).  Saving model ...
Validation loss decreased (1.328008 --> 1.322044).  Saving model ...
Validation loss decreased (1.322044 --> 1.316799).  Saving model ...
Validation loss decreased (1.316799 --> 1.311142).  Saving model ...
Validation loss decreased (1.311142 --> 1.304295).  Saving model ...
Validation loss decreased (1.304295 --> 1.298499).  Saving model ...
Validation loss decreased (1.298499 --> 1.292477).  Saving model ...
Validation loss decreased (1.292477 --> 1.285893).  Saving model ...
Validation loss decreased (1.285893 --> 1.280679).  Saving model ...
Validation loss decreased (1.280679 --> 1.275360).  Saving model ...
Validation loss decreased (1.275360 --> 1.268532).  Saving model ...
Validation loss decreased (1.268532 --> 1.261874).  Saving model ...
Validation loss decreased (1.261874 --> 1.255293).  Saving model ...
Validation loss decreased (1.255293 --> 1.247581).  Saving model ...
Validation loss decreased (1.247581 --> 1.241229).  Saving model ...
Validation loss decreased (1.241229 --> 1.235392).  Saving model ...
Validation loss decreased (1.235392 --> 1.229197).  Saving model ...
Validation loss decreased (1.229197 --> 1.221551).  Saving model ...
Validation loss decreased (1.221551 --> 1.215302).  Saving model ...
Validation loss decreased (1.215302 --> 1.209673).  Saving model ...
Validation loss decreased (1.209673 --> 1.202622).  Saving model ...
Validation loss decreased (1.202622 --> 1.195219).  Saving model ...
Validation loss decreased (1.195219 --> 1.189447).  Saving model ...
Validation loss decreased (1.189447 --> 1.187162).  Saving model ...
Validation loss decreased (1.187162 --> 1.178122).  Saving model ...
Validation loss decreased (1.178122 --> 1.172217).  Saving model ...
Validation loss decreased (1.172217 --> 1.168411).  Saving model ...
Validation loss decreased (1.168411 --> 1.163650).  Saving model ...
Validation loss decreased (1.163650 --> 1.154853).  Saving model ...
Validation loss decreased (1.154853 --> 1.149175).  Saving model ...
Validation loss decreased (1.149175 --> 1.144346).  Saving model ...
Validation loss decreased (1.144346 --> 1.140458).  Saving model ...
Validation loss decreased (1.140458 --> 1.134144).  Saving model ...
Validation loss decreased (1.134144 --> 1.126539).  Saving model ...
Validation loss decreased (1.126539 --> 1.122521).  Saving model ...
Validation loss decreased (1.122521 --> 1.119116).  Saving model ...
Validation loss decreased (1.119116 --> 1.116638).  Saving model ...
Validation loss decreased (1.116638 --> 1.110817).  Saving model ...
Validation loss decreased (1.110817 --> 1.108375).  Saving model ...
Validation loss decreased (1.108375 --> 1.103829).  Saving model ...
Validation loss decreased (1.103829 --> 1.099623).  Saving model ...
Validation loss decreased (1.099623 --> 1.096928).  Saving model ...
Validation loss decreased (1.096928 --> 1.092964).  Saving model ...
Validation loss decreased (1.092964 --> 1.086456).  Saving model ...
Validation loss decreased (1.086456 --> 1.081672).  Saving model ...
EarlyStopping counter: 1 out of 5.0
Validation loss decreased (1.081672 --> 1.074529).  Saving model ...
Validation loss decreased (1.074529 --> 1.070103).  Saving model ...
Validation loss decreased (1.070103 --> 1.066675).  Saving model ...
Validation loss decreased (1.066675 --> 1.060041).  Saving model ...
Validation loss decreased (1.060041 --> 1.054733).  Saving model ...
Validation loss decreased (1.054733 --> 1.053108).  Saving model ...
Validation loss decreased (1.053108 --> 1.051364).  Saving model ...
Validation loss decreased (1.051364 --> 1.048019).  Saving model ...
Validation loss decreased (1.048019 --> 1.046311).  Saving model ...
Validation loss decreased (1.046311 --> 1.039457).  Saving model ...
Validation loss decreased (1.039457 --> 1.039420).  Saving model ...
Validation loss decreased (1.039420 --> 1.034551).  Saving model ...
Validation loss decreased (1.034551 --> 1.032118).  Saving model ...
EarlyStopping counter: 1 out of 5.0
Validation loss decreased (1.032118 --> 1.029376).  Saving model ...
Validation loss decreased (1.029376 --> 1.024303).  Saving model ...
Validation loss decreased (1.024303 --> 1.021146).  Saving model ...
Validation loss decreased (1.021146 --> 1.020489).  Saving model ...
Validation loss decreased (1.020489 --> 1.019284).  Saving model ...
Validation loss decreased (1.019284 --> 1.018543).  Saving model ...
Validation loss decreased (1.018543 --> 1.013744).  Saving model ...
Validation loss decreased (1.013744 --> 1.010177).  Saving model ...
Validation loss decreased (1.010177 --> 1.007230).  Saving model ...
Validation loss decreased (1.007230 --> 1.005534).  Saving model ...
Validation loss decreased (1.005534 --> 1.003594).  Saving model ...
Validation loss decreased (1.003594 --> 1.003247).  Saving model ...
Validation loss decreased (1.003247 --> 1.000626).  Saving model ...
Validation loss decreased (1.000626 --> 0.999208).  Saving model ...
Validation loss decreased (0.999208 --> 0.996832).  Saving model ...
Validation loss decreased (0.996832 --> 0.992318).  Saving model ...
EarlyStopping counter: 1 out of 5.0
EarlyStopping counter: 2 out of 5.0
Validation loss decreased (0.992318 --> 0.989206).  Saving model ...
EarlyStopping counter: 1 out of 5.0
Validation loss decreased (0.989206 --> 0.987110).  Saving model ...
Validation loss decreased (0.987110 --> 0.985266).  Saving model ...
Validation loss decreased (0.985266 --> 0.984952).  Saving model ...
EarlyStopping counter: 1 out of 5.0
Validation loss decreased (0.984952 --> 0.983561).  Saving model ...
Validation loss decreased (0.983561 --> 0.980278).  Saving model ...
EarlyStopping counter: 1 out of 5.0
EarlyStopping counter: 2 out of 5.0
Validation loss decreased (0.980278 --> 0.977711).  Saving model ...
Validation loss decreased (0.977711 --> 0.975799).  Saving model ...
Validation loss decreased (0.975799 --> 0.973648).  Saving model ...
Validation loss decreased (0.973648 --> 0.972801).  Saving model ...
Validation loss decreased (0.972801 --> 0.971672).  Saving model ...
EarlyStopping counter: 1 out of 5.0
Validation loss decreased (0.971672 --> 0.970991).  Saving model ...
Validation loss decreased (0.970991 --> 0.969521).  Saving model ...
EarlyStopping counter: 1 out of 5.0
Validation loss decreased (0.969521 --> 0.968151).  Saving model ...
Validation loss decreased (0.968151 --> 0.966868).  Saving model ...
Validation loss decreased (0.966868 --> 0.966744).  Saving model ...
Validation loss decreased (0.966744 --> 0.964412).  Saving model ...
Validation loss decreased (0.964412 --> 0.960679).  Saving model ...
EarlyStopping counter: 1 out of 5.0
EarlyStopping counter: 2 out of 5.0
Validation loss decreased (0.960679 --> 0.959175).  Saving model ...
EarlyStopping counter: 1 out of 5.0
EarlyStopping counter: 2 out of 5.0
EarlyStopping counter: 3 out of 5.0
EarlyStopping counter: 4 out of 5.0
EarlyStopping counter: 5 out of 5.0
/localscratch/yinan.29365731.0/env/lib/python3.7/site-packages/torch/nn/functional.py:1794: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.
  warnings.warn("nn.functional.tanh is deprecated. Use torch.tanh instead.")
wandb: Waiting for W&B process to finish, PID 159076... (success).
wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: \ 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: | 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: / 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: \ 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: | 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: / 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: \ 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: | 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: / 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb:                                                                                
wandb: Run history:
wandb:     e_F1 ▁▂▃▄▅▆▆▆▆▆▆▆▆▇▇▇▇▇▇▇▇▇▇█████████████████
wandb:   e_loss █▇▆▆▆▅▅▅▅▅▄▄▄▃▃▃▃▃▃▂▂▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁
wandb:     t_F1 ▁▁▂▃▃▃▄▄▄▄▅▅▅▅▆▆▅▆▆▆▇▇▇▇▇▇▇▇▇▇█▇▇███████
wandb:   t_loss █▇▇▆▆▆▆▆▆▅▅▅▅▄▄▄▄▄▄▄▃▃▃▃▃▃▂▃▂▂▂▂▂▂▂▂▁▁▁▁
wandb: 
wandb: Run summary:
wandb:     e_F1 57.07609
wandb:   e_loss 0.95927
wandb:     t_F1 68.00251
wandb:   t_loss 0.79925
wandb: 
wandb: Synced 4 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Synced rich-tree-1: https://wandb.ai/yinanazhou/xl_512_bs_8_lr_1e06_es_5_lc_True_nr_True_sr_False_stem_False_lemma_True_repeat_5_fold_2/runs/129js2rm
wandb: Find logs at: ./wandb/run-20220324_234918-129js2rm/logs/debug.log
wandb: 

