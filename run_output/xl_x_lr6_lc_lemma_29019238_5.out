Unloading StdEnv/2020

Due to MODULEPATH changes, the following have been reloaded:
  1) mii/1.1.1


The following have been reloaded with a version change:
  1) python/3.8.2 => python/3.7.4

Using base prefix '/cvmfs/soft.computecanada.ca/easybuild/software/2017/Core/python/3.7.4'
New python executable in /localscratch/yinan.29025152.0/env/bin/python
Installing setuptools, pip, wheel...
done.
Ignoring pip: markers 'python_version < "3"' don't match your environment
Looking in links: /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/nix/avx2, /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/nix/generic, /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic
Collecting pip
Installing collected packages: pip
  Found existing installation: pip 19.1.1
    Uninstalling pip-19.1.1:
      Successfully uninstalled pip-19.1.1
Successfully installed pip-21.2.3+computecanada
Looking in links: /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/nix/avx2, /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/nix/generic, /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/keras-2.8.0+computecanada-py2.py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/Keras_Preprocessing-1.1.2+computecanada-py3-none-any.whl
Requirement already satisfied: matplotlib in /cvmfs/soft.computecanada.ca/easybuild/software/2017/Core/scipy-stack/2019a/lib/python3.7/site-packages (from -r requirements.txt (line 3)) (3.0.2)
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/nltk-3.6.5+computecanada-py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/scikit_learn-0.22.1+computecanada-cp37-cp37m-linux_x86_64.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/tensorboard-2.3.0+computecanada-py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/tensorboard_plugin_wit-1.7.0+computecanada-py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/tensorflow_gpu-2.3.0+computecanada-cp37-cp37m-linux_x86_64.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/tensorflow_estimator-2.3.0+computecanada-py2.py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/tokenizers-0.5.2+computecanada-cp37-cp37m-linux_x86_64.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/nix/avx2/torch-1.4.0+computecanada-cp37-cp37m-linux_x86_64.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/torchtext-0.6.0+computecanada-py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/torchvision-0.8.2+computecanada-cp37-cp37m-linux_x86_64.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/transformers-2.5.1+computecanada-py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/urllib3-1.26.7+computecanada-py2.py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/click-8.0.3+computecanada-py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/joblib-1.1.0+computecanada-py2.py3-none-any.whl
ERROR: Could not find a version that satisfies the requirement regex>=2021.8.3 (from nltk) (from versions: 2018.1.10+computecanada, 2019.11.1+computecanada, 2020.11.13+computecanada)
ERROR: No matching distribution found for regex>=2021.8.3
Looking in links: /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/nix/avx2, /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/nix/generic, /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic
ERROR: Could not find a version that satisfies the requirement numpy==1.20.0+computacanada (from versions: 1.15.0+computecanada, 1.15.2+computecanada, 1.15.4+computecanada, 1.16.0+computecanada, 1.16.2+computecanada, 1.16.3+computecanada, 1.17.4+computecanada, 1.18.1+computecanada, 1.18.4+computecanada, 1.19.1+computecanada, 1.19.2+computecanada, 1.20.2+computecanada)
ERROR: No matching distribution found for numpy==1.20.0+computacanada
Looking in links: /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/nix/avx2, /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/nix/generic, /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/wandb-0.12.5+computecanada-py2.py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/psutil-5.7.3+computecanada-cp37-cp37m-linux_x86_64.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/six-1.16.0+computecanada-py2.py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/subprocess32-3.5.4+computecanada-py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/shortuuid-1.0.1+computecanada-py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/PyYAML-5.3.1+computecanada-cp37-cp37m-linux_x86_64.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/promise-2.3+computecanada-py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/yaspin-2.1.0+computecanada-py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/configparser-5.0.2+computecanada-py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/sentry_sdk-1.5.0+computecanada-py2.py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/protobuf-3.19.4+computecanada-py2.py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/pathtools-0.1.2+computecanada-py3-none-any.whl
Requirement already satisfied: requests<3,>=2.0.0 in /cvmfs/soft.computecanada.ca/easybuild/software/2017/Core/scipy-stack/2019a/lib/python3.7/site-packages (from wandb) (2.21.0)
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/click-8.0.3+computecanada-py3-none-any.whl
Requirement already satisfied: python-dateutil>=2.6.1 in /cvmfs/soft.computecanada.ca/easybuild/software/2017/Core/scipy-stack/2019a/lib/python3.7/site-packages (from wandb) (2.7.5)
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/docker_pycreds-0.4.0+computecanada-py2.py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/GitPython-3.1.24+computecanada-py3-none-any.whl
Requirement already satisfied: importlib-metadata in /cvmfs/soft.computecanada.ca/easybuild/software/2017/Core/scipy-stack/2019a/lib/python3.7/site-packages (from Click!=8.0.0,>=7.0->wandb) (0.8)
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/typing_extensions-4.0.1+computecanada-py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/gitdb-4.0.9+computecanada-py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/smmap-5.0.0+computecanada-py3-none-any.whl
Requirement already satisfied: certifi>=2017.4.17 in /cvmfs/soft.computecanada.ca/easybuild/software/2017/Core/scipy-stack/2019a/lib/python3.7/site-packages (from requests<3,>=2.0.0->wandb) (2018.11.29)
Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /cvmfs/soft.computecanada.ca/easybuild/software/2017/Core/scipy-stack/2019a/lib/python3.7/site-packages (from requests<3,>=2.0.0->wandb) (3.0.4)
Requirement already satisfied: urllib3<1.25,>=1.21.1 in /cvmfs/soft.computecanada.ca/easybuild/software/2017/Core/scipy-stack/2019a/lib/python3.7/site-packages (from requests<3,>=2.0.0->wandb) (1.24.1)
Requirement already satisfied: idna<2.9,>=2.5 in /cvmfs/soft.computecanada.ca/easybuild/software/2017/Core/scipy-stack/2019a/lib/python3.7/site-packages (from requests<3,>=2.0.0->wandb) (2.8)
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/termcolor-1.1.0+computecanada-py3-none-any.whl
Requirement already satisfied: zipp>=0.3.2 in /cvmfs/soft.computecanada.ca/easybuild/software/2017/Core/scipy-stack/2019a/lib/python3.7/site-packages (from importlib-metadata->Click!=8.0.0,>=7.0->wandb) (0.3.3)
Installing collected packages: smmap, typing-extensions, termcolor, six, gitdb, yaspin, subprocess32, shortuuid, sentry-sdk, PyYAML, psutil, protobuf, promise, pathtools, GitPython, docker-pycreds, configparser, Click, wandb
  Attempting uninstall: six
    Found existing installation: six 1.12.0
    Not uninstalling six at /cvmfs/soft.computecanada.ca/easybuild/software/2017/Core/scipy-stack/2019a/lib/python3.7/site-packages, outside environment /localscratch/yinan.29025152.0/env
    Can't uninstall 'six'. No files were found to uninstall.
Successfully installed Click-8.0.3+computecanada GitPython-3.1.24+computecanada PyYAML-5.3.1+computecanada configparser-5.0.2+computecanada docker-pycreds-0.4.0+computecanada gitdb-4.0.9+computecanada pathtools-0.1.2+computecanada promise-2.3+computecanada protobuf-3.19.4+computecanada psutil-5.7.3+computecanada sentry-sdk-1.5.0+computecanada shortuuid-1.0.1+computecanada six-1.16.0+computecanada smmap-5.0.0+computecanada subprocess32-3.5.4+computecanada termcolor-1.1.0+computecanada typing-extensions-4.0.1+computecanada wandb-0.12.5+computecanada yaspin-2.1.0+computecanada
Looking in links: /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/nix/avx2, /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/nix/generic, /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic
ERROR: Could not find a version that satisfies the requirement sagemaker (from versions: none)
ERROR: No matching distribution found for sagemaker
Looking in links: /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/nix/avx2, /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/nix/generic, /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/torch-1.9.1+computecanada-cp37-cp37m-linux_x86_64.whl
Requirement already satisfied: typing-extensions in /localscratch/yinan.29025152.0/env/lib/python3.7/site-packages (from torch) (4.0.1+computecanada)
Installing collected packages: torch
Successfully installed torch-1.9.1+computecanada
Looking in links: /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/nix/avx2, /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/nix/generic, /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/transformers-2.5.1+computecanada-py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/regex-2020.11.13+computecanada-cp37-cp37m-linux_x86_64.whl
Requirement already satisfied: requests in /cvmfs/soft.computecanada.ca/easybuild/software/2017/Core/scipy-stack/2019a/lib/python3.7/site-packages (from transformers==2.5.1+computecanada) (2.21.0)
Requirement already satisfied: numpy in /cvmfs/soft.computecanada.ca/easybuild/software/2017/Core/scipy-stack/2019a/lib/python3.7/site-packages (from transformers==2.5.1+computecanada) (1.16.0)
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/sacremoses-0.0.46+computecanada-py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/tokenizers-0.5.2+computecanada-cp37-cp37m-linux_x86_64.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/tqdm-4.63.0+computecanada-py2.py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/sentencepiece-0.1.91+computecanada-cp37-cp37m-linux_x86_64.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/filelock-3.4.2+computecanada-py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/boto3-1.20.52+computecanada-py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/s3transfer-0.5.1+computecanada-py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/botocore-1.23.52+computecanada-py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/jmespath-0.10.0+computecanada-py2.py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/urllib3-1.26.8+computecanada-py2.py3-none-any.whl
Requirement already satisfied: python-dateutil<3.0.0,>=2.1 in /cvmfs/soft.computecanada.ca/easybuild/software/2017/Core/scipy-stack/2019a/lib/python3.7/site-packages (from botocore<1.24.0,>=1.23.52->boto3->transformers==2.5.1+computecanada) (2.7.5)
Requirement already satisfied: six>=1.5 in /localscratch/yinan.29025152.0/env/lib/python3.7/site-packages (from python-dateutil<3.0.0,>=2.1->botocore<1.24.0,>=1.23.52->boto3->transformers==2.5.1+computecanada) (1.16.0+computecanada)
Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /cvmfs/soft.computecanada.ca/easybuild/software/2017/Core/scipy-stack/2019a/lib/python3.7/site-packages (from requests->transformers==2.5.1+computecanada) (3.0.4)
Requirement already satisfied: certifi>=2017.4.17 in /cvmfs/soft.computecanada.ca/easybuild/software/2017/Core/scipy-stack/2019a/lib/python3.7/site-packages (from requests->transformers==2.5.1+computecanada) (2018.11.29)
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/requests-2.27.1+computecanada-py2.py3-none-any.whl
Requirement already satisfied: idna<4,>=2.5 in /cvmfs/soft.computecanada.ca/easybuild/software/2017/Core/scipy-stack/2019a/lib/python3.7/site-packages (from requests->transformers==2.5.1+computecanada) (2.8)
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/charset_normalizer-2.0.11+computecanada-py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/joblib-1.1.0+computecanada-py2.py3-none-any.whl
Requirement already satisfied: click in /localscratch/yinan.29025152.0/env/lib/python3.7/site-packages (from sacremoses->transformers==2.5.1+computecanada) (8.0.3+computecanada)
Requirement already satisfied: importlib-metadata in /cvmfs/soft.computecanada.ca/easybuild/software/2017/Core/scipy-stack/2019a/lib/python3.7/site-packages (from click->sacremoses->transformers==2.5.1+computecanada) (0.8)
Requirement already satisfied: zipp>=0.3.2 in /cvmfs/soft.computecanada.ca/easybuild/software/2017/Core/scipy-stack/2019a/lib/python3.7/site-packages (from importlib-metadata->click->sacremoses->transformers==2.5.1+computecanada) (0.3.3)
Installing collected packages: urllib3, jmespath, botocore, tqdm, s3transfer, regex, joblib, charset-normalizer, tokenizers, sentencepiece, sacremoses, requests, filelock, boto3, transformers
  Attempting uninstall: urllib3
    Found existing installation: urllib3 1.24.1
    Not uninstalling urllib3 at /cvmfs/soft.computecanada.ca/easybuild/software/2017/Core/scipy-stack/2019a/lib/python3.7/site-packages, outside environment /localscratch/yinan.29025152.0/env
    Can't uninstall 'urllib3'. No files were found to uninstall.
  Attempting uninstall: requests
    Found existing installation: requests 2.21.0
    Not uninstalling requests at /cvmfs/soft.computecanada.ca/easybuild/software/2017/Core/scipy-stack/2019a/lib/python3.7/site-packages, outside environment /localscratch/yinan.29025152.0/env
    Can't uninstall 'requests'. No files were found to uninstall.
Successfully installed boto3-1.20.52+computecanada botocore-1.23.52+computecanada charset-normalizer-2.0.11+computecanada filelock-3.4.2+computecanada jmespath-0.10.0+computecanada joblib-1.1.0+computecanada regex-2020.11.13+computecanada requests-2.27.1+computecanada s3transfer-0.5.1+computecanada sacremoses-0.0.46+computecanada sentencepiece-0.1.91+computecanada tokenizers-0.5.2+computecanada tqdm-4.63.0+computecanada transformers-2.5.1+computecanada urllib3-1.26.8+computecanada
Looking in links: /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/nix/avx2, /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/nix/generic, /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/tensorflow_gpu-2.3.0+computecanada-cp37-cp37m-linux_x86_64.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/nix/avx2/h5py-2.10.0+computecanada-cp37-cp37m-linux_x86_64.whl
Requirement already satisfied: protobuf>=3.9.2 in /localscratch/yinan.29025152.0/env/lib/python3.7/site-packages (from tensorflow_gpu==2.3.0+computecanada) (3.19.4+computecanada)
Requirement already satisfied: wheel>=0.26 in /localscratch/yinan.29025152.0/env/lib/python3.7/site-packages (from tensorflow_gpu==2.3.0+computecanada) (0.33.4)
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/astunparse-1.6.3+computecanada-py2.py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/Keras_Preprocessing-1.1.2+computecanada-py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/tensorboard-2.8.0+computecanada-py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/tensorflow_estimator-2.3.0+computecanada-py2.py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/grpcio-1.38.0+computecanada-cp37-cp37m-linux_x86_64.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/wrapt-1.11.2+computecanada-cp37-cp37m-linux_x86_64.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/nix/generic/scipy-1.4.1+computecanada-cp37-cp37m-linux_x86_64.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/absl_py-1.0.0+computecanada-py3-none-any.whl
Requirement already satisfied: six>=1.12.0 in /localscratch/yinan.29025152.0/env/lib/python3.7/site-packages (from tensorflow_gpu==2.3.0+computecanada) (1.16.0+computecanada)
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/google_pasta-0.2.0+computecanada-py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/gast-0.3.3+computecanada-py3-none-any.whl
Requirement already satisfied: numpy<1.19.0,>=1.16.0 in /cvmfs/soft.computecanada.ca/easybuild/software/2017/Core/scipy-stack/2019a/lib/python3.7/site-packages (from tensorflow_gpu==2.3.0+computecanada) (1.16.0)
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/opt_einsum-3.3.0+computecanada-py3-none-any.whl
Requirement already satisfied: termcolor>=1.1.0 in /localscratch/yinan.29025152.0/env/lib/python3.7/site-packages (from tensorflow_gpu==2.3.0+computecanada) (1.1.0+computecanada)
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/Werkzeug-2.0.3+computecanada-py3-none-any.whl
Requirement already satisfied: requests<3,>=2.21.0 in /localscratch/yinan.29025152.0/env/lib/python3.7/site-packages (from tensorboard<3,>=2.3.0->tensorflow_gpu==2.3.0+computecanada) (2.27.1+computecanada)
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/Markdown-3.3.6+computecanada-py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/google_auth_oauthlib-0.4.6+computecanada-py2.py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/tensorboard_plugin_wit-1.8.0+computecanada-py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/google_auth-2.3.3+computecanada-py2.py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/tensorboard_data_server-0.6.1+computecanada-py3-none-linux_x86_64.whl
Requirement already satisfied: setuptools>=41.0.0 in /localscratch/yinan.29025152.0/env/lib/python3.7/site-packages (from tensorboard<3,>=2.3.0->tensorflow_gpu==2.3.0+computecanada) (41.0.1)
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/cachetools-4.2.4+computecanada-py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/rsa-4.8+computecanada-py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/pyasn1_modules-0.2.8+computecanada-py2.py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/requests_oauthlib-1.3.0+computecanada-py2.py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/importlib_metadata-4.10.1+computecanada-py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/zipp-3.7.0+computecanada-py3-none-any.whl
Requirement already satisfied: typing-extensions>=3.6.4 in /localscratch/yinan.29025152.0/env/lib/python3.7/site-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard<3,>=2.3.0->tensorflow_gpu==2.3.0+computecanada) (4.0.1+computecanada)
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/pyasn1-0.4.8+computecanada-py2.py3-none-any.whl
Requirement already satisfied: charset-normalizer~=2.0.0 in /localscratch/yinan.29025152.0/env/lib/python3.7/site-packages (from requests<3,>=2.21.0->tensorboard<3,>=2.3.0->tensorflow_gpu==2.3.0+computecanada) (2.0.11+computecanada)
Requirement already satisfied: idna<4,>=2.5 in /cvmfs/soft.computecanada.ca/easybuild/software/2017/Core/scipy-stack/2019a/lib/python3.7/site-packages (from requests<3,>=2.21.0->tensorboard<3,>=2.3.0->tensorflow_gpu==2.3.0+computecanada) (2.8)
Requirement already satisfied: certifi>=2017.4.17 in /cvmfs/soft.computecanada.ca/easybuild/software/2017/Core/scipy-stack/2019a/lib/python3.7/site-packages (from requests<3,>=2.21.0->tensorboard<3,>=2.3.0->tensorflow_gpu==2.3.0+computecanada) (2018.11.29)
Requirement already satisfied: urllib3<1.27,>=1.21.1 in /localscratch/yinan.29025152.0/env/lib/python3.7/site-packages (from requests<3,>=2.21.0->tensorboard<3,>=2.3.0->tensorflow_gpu==2.3.0+computecanada) (1.26.8+computecanada)
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/oauthlib-3.1.1+computecanada-py2.py3-none-any.whl
Installing collected packages: pyasn1, zipp, rsa, pyasn1-modules, oauthlib, cachetools, requests-oauthlib, importlib-metadata, google-auth, werkzeug, tensorboard-plugin-wit, tensorboard-data-server, markdown, grpcio, google-auth-oauthlib, absl-py, wrapt, tensorflow-estimator, tensorboard, scipy, opt-einsum, keras-preprocessing, h5py, google-pasta, gast, astunparse, tensorflow-gpu
  Attempting uninstall: pyasn1
    Found existing installation: pyasn1 0.4.3
    Not uninstalling pyasn1 at /cvmfs/soft.computecanada.ca/easybuild/software/2017/Core/scipy-stack/2019a/lib/python3.7/site-packages, outside environment /localscratch/yinan.29025152.0/env
    Can't uninstall 'pyasn1'. No files were found to uninstall.
  Attempting uninstall: zipp
    Found existing installation: zipp 0.3.3
    Not uninstalling zipp at /cvmfs/soft.computecanada.ca/easybuild/software/2017/Core/scipy-stack/2019a/lib/python3.7/site-packages, outside environment /localscratch/yinan.29025152.0/env
    Can't uninstall 'zipp'. No files were found to uninstall.
  Attempting uninstall: importlib-metadata
    Found existing installation: importlib-metadata 0.8
    Not uninstalling importlib-metadata at /cvmfs/soft.computecanada.ca/easybuild/software/2017/Core/scipy-stack/2019a/lib/python3.7/site-packages, outside environment /localscratch/yinan.29025152.0/env
    Can't uninstall 'importlib-metadata'. No files were found to uninstall.
  Attempting uninstall: scipy
    Found existing installation: scipy 1.2.0
    Not uninstalling scipy at /cvmfs/soft.computecanada.ca/easybuild/software/2017/Core/scipy-stack/2019a/lib/python3.7/site-packages, outside environment /localscratch/yinan.29025152.0/env
    Can't uninstall 'scipy'. No files were found to uninstall.
Successfully installed absl-py-1.0.0+computecanada astunparse-1.6.3+computecanada cachetools-4.2.4+computecanada gast-0.3.3+computecanada google-auth-2.3.3+computecanada google-auth-oauthlib-0.4.6+computecanada google-pasta-0.2.0+computecanada grpcio-1.38.0+computecanada h5py-2.10.0+computecanada importlib-metadata-4.10.1+computecanada keras-preprocessing-1.1.2+computecanada markdown-3.3.6+computecanada oauthlib-3.1.1+computecanada opt-einsum-3.3.0+computecanada pyasn1-0.4.8+computecanada pyasn1-modules-0.2.8+computecanada requests-oauthlib-1.3.0+computecanada rsa-4.8+computecanada scipy-1.4.1+computecanada tensorboard-2.8.0+computecanada tensorboard-data-server-0.6.1+computecanada tensorboard-plugin-wit-1.8.0+computecanada tensorflow-estimator-2.3.0+computecanada tensorflow-gpu-2.3.0+computecanada werkzeug-2.0.3+computecanada wrapt-1.11.2+computecanada zipp-3.7.0+computecanada
Looking in links: /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/nix/avx2, /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/nix/generic, /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/keras-2.8.0+computecanada-py2.py3-none-any.whl
Installing collected packages: Keras
Successfully installed Keras-2.8.0+computecanada
Looking in links: /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/nix/avx2, /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/nix/generic, /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/urllib3-1.26.7+computecanada-py2.py3-none-any.whl
Installing collected packages: urllib3
  Attempting uninstall: urllib3
    Found existing installation: urllib3 1.26.8+computecanada
    Uninstalling urllib3-1.26.8+computecanada:
      Successfully uninstalled urllib3-1.26.8+computecanada
Successfully installed urllib3-1.26.7+computecanada
Looking in links: /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/nix/avx2, /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/nix/generic, /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/nltk-3.7+computecanada-py3-none-any.whl
Requirement already satisfied: tqdm in /localscratch/yinan.29025152.0/env/lib/python3.7/site-packages (from nltk) (4.63.0+computecanada)
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/nltk-3.6.5+computecanada-py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/nltk-3.6.3+computecanada-py3-none-any.whl
Requirement already satisfied: regex in /localscratch/yinan.29025152.0/env/lib/python3.7/site-packages (from nltk) (2020.11.13+computecanada)
Requirement already satisfied: joblib in /localscratch/yinan.29025152.0/env/lib/python3.7/site-packages (from nltk) (1.1.0+computecanada)
Requirement already satisfied: click in /localscratch/yinan.29025152.0/env/lib/python3.7/site-packages (from nltk) (8.0.3+computecanada)
Requirement already satisfied: importlib-metadata in /localscratch/yinan.29025152.0/env/lib/python3.7/site-packages (from click->nltk) (4.10.1+computecanada)
Requirement already satisfied: zipp>=0.5 in /localscratch/yinan.29025152.0/env/lib/python3.7/site-packages (from importlib-metadata->click->nltk) (3.7.0+computecanada)
Requirement already satisfied: typing-extensions>=3.6.4 in /localscratch/yinan.29025152.0/env/lib/python3.7/site-packages (from importlib-metadata->click->nltk) (4.0.1+computecanada)
Installing collected packages: nltk
Successfully installed nltk-3.6.3+computecanada
Looking in links: /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/nix/avx2, /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/nix/generic, /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/scikit_learn-0.22.1+computecanada-cp37-cp37m-linux_x86_64.whl
Requirement already satisfied: scipy>=0.17.0 in /localscratch/yinan.29025152.0/env/lib/python3.7/site-packages (from scikit-learn==0.22.1) (1.4.1+computecanada)
Requirement already satisfied: joblib>=0.11 in /localscratch/yinan.29025152.0/env/lib/python3.7/site-packages (from scikit-learn==0.22.1) (1.1.0+computecanada)
Requirement already satisfied: numpy>=1.11.0 in /cvmfs/soft.computecanada.ca/easybuild/software/2017/Core/scipy-stack/2019a/lib/python3.7/site-packages (from scikit-learn==0.22.1) (1.16.0)
Installing collected packages: scikit-learn
Successfully installed scikit-learn-0.22.1+computecanada
Looking in links: /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/nix/avx2, /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/nix/generic, /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic
Requirement already satisfied: tokenizers==0.5.2 in /localscratch/yinan.29025152.0/env/lib/python3.7/site-packages (0.5.2+computecanada)
wandb: Appending key for api.wandb.ai to your netrc file: /home/yinan/.netrc
Starting Task
2022-03-15 23:58:17.402243: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1
[nltk_data] Downloading package stopwords to /home/yinan/nltk_data...
[nltk_data]   Package stopwords is already up-to-date!
[nltk_data] Downloading package wordnet to /home/yinan/nltk_data...
[nltk_data]   Package wordnet is already up-to-date!
wandb: Currently logged in as: yinanazhou (use `wandb login --relogin` to force relogin)
wandb: wandb version 0.12.11 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
2022-03-15 23:58:31.859066: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1
wandb: Tracking run with wandb version 0.12.5
wandb: Syncing run fresh-music-3
wandb: ⭐️ View project at https://wandb.ai/yinanazhou/xl_512_bs_8_lr_1e06_es_5_lc_True_nr_False_sr_False_stem_False_lemma_True_repeat_1_fold_1
wandb: 🚀 View run at https://wandb.ai/yinanazhou/xl_512_bs_8_lr_1e06_es_5_lc_True_nr_False_sr_False_stem_False_lemma_True_repeat_1_fold_1/runs/2n95chlp
wandb: Run data is saved locally in /project/6002780/yinan/Thesis_MER_Lyrics/lyric-emotion/wandb/run-20220315_235829-2n95chlp
wandb: Run `wandb offline` to turn off syncing.

Validation loss decreased (inf --> 1.433387).  Saving model ...
Validation loss decreased (1.433387 --> 1.413981).  Saving model ...
Validation loss decreased (1.413981 --> 1.397822).  Saving model ...
Validation loss decreased (1.397822 --> 1.384927).  Saving model ...
Validation loss decreased (1.384927 --> 1.374721).  Saving model ...
Validation loss decreased (1.374721 --> 1.365957).  Saving model ...
Validation loss decreased (1.365957 --> 1.358616).  Saving model ...
Validation loss decreased (1.358616 --> 1.352624).  Saving model ...
Validation loss decreased (1.352624 --> 1.347371).  Saving model ...
Validation loss decreased (1.347371 --> 1.341487).  Saving model ...
Validation loss decreased (1.341487 --> 1.335491).  Saving model ...
Validation loss decreased (1.335491 --> 1.330084).  Saving model ...
Validation loss decreased (1.330084 --> 1.324555).  Saving model ...
Validation loss decreased (1.324555 --> 1.319240).  Saving model ...
Validation loss decreased (1.319240 --> 1.314237).  Saving model ...
Validation loss decreased (1.314237 --> 1.308590).  Saving model ...
Validation loss decreased (1.308590 --> 1.303107).  Saving model ...
Validation loss decreased (1.303107 --> 1.296859).  Saving model ...
Validation loss decreased (1.296859 --> 1.290189).  Saving model ...
Validation loss decreased (1.290189 --> 1.282792).  Saving model ...
Validation loss decreased (1.282792 --> 1.275819).  Saving model ...
Validation loss decreased (1.275819 --> 1.268752).  Saving model ...
Validation loss decreased (1.268752 --> 1.262562).  Saving model ...
Validation loss decreased (1.262562 --> 1.255516).  Saving model ...
Validation loss decreased (1.255516 --> 1.247164).  Saving model ...
Validation loss decreased (1.247164 --> 1.239761).  Saving model ...
Validation loss decreased (1.239761 --> 1.233390).  Saving model ...
Validation loss decreased (1.233390 --> 1.226658).  Saving model ...
Validation loss decreased (1.226658 --> 1.220915).  Saving model ...
Validation loss decreased (1.220915 --> 1.215830).  Saving model ...
Validation loss decreased (1.215830 --> 1.207669).  Saving model ...
Validation loss decreased (1.207669 --> 1.203214).  Saving model ...
Validation loss decreased (1.203214 --> 1.200058).  Saving model ...
Validation loss decreased (1.200058 --> 1.193948).  Saving model ...
Validation loss decreased (1.193948 --> 1.186832).  Saving model ...
Validation loss decreased (1.186832 --> 1.183043).  Saving model ...
Validation loss decreased (1.183043 --> 1.175233).  Saving model ...
Validation loss decreased (1.175233 --> 1.170703).  Saving model ...
Validation loss decreased (1.170703 --> 1.168870).  Saving model ...
Validation loss decreased (1.168870 --> 1.166053).  Saving model ...
Validation loss decreased (1.166053 --> 1.161387).  Saving model ...
Validation loss decreased (1.161387 --> 1.154649).  Saving model ...
Validation loss decreased (1.154649 --> 1.151328).  Saving model ...
Validation loss decreased (1.151328 --> 1.147662).  Saving model ...
Validation loss decreased (1.147662 --> 1.144545).  Saving model ...
Validation loss decreased (1.144545 --> 1.139429).  Saving model ...
Validation loss decreased (1.139429 --> 1.135583).  Saving model ...
Validation loss decreased (1.135583 --> 1.132313).  Saving model ...
Validation loss decreased (1.132313 --> 1.126347).  Saving model ...
Validation loss decreased (1.126347 --> 1.123219).  Saving model ...
Validation loss decreased (1.123219 --> 1.117370).  Saving model ...
Validation loss decreased (1.117370 --> 1.114682).  Saving model ...
Validation loss decreased (1.114682 --> 1.112565).  Saving model ...
Validation loss decreased (1.112565 --> 1.108434).  Saving model ...
EarlyStopping counter: 1 out of 5.0
Validation loss decreased (1.108434 --> 1.104441).  Saving model ...
Validation loss decreased (1.104441 --> 1.099149).  Saving model ...
Validation loss decreased (1.099149 --> 1.093575).  Saving model ...
Validation loss decreased (1.093575 --> 1.088544).  Saving model ...
EarlyStopping counter: 1 out of 5.0
Validation loss decreased (1.088544 --> 1.088525).  Saving model ...
Validation loss decreased (1.088525 --> 1.084370).  Saving model ...
Validation loss decreased (1.084370 --> 1.080092).  Saving model ...
Validation loss decreased (1.080092 --> 1.076291).  Saving model ...
Validation loss decreased (1.076291 --> 1.076033).  Saving model ...
Validation loss decreased (1.076033 --> 1.072529).  Saving model ...
Validation loss decreased (1.072529 --> 1.070793).  Saving model ...
Validation loss decreased (1.070793 --> 1.066482).  Saving model ...
Validation loss decreased (1.066482 --> 1.062048).  Saving model ...
Validation loss decreased (1.062048 --> 1.059040).  Saving model ...
Validation loss decreased (1.059040 --> 1.055943).  Saving model ...
Validation loss decreased (1.055943 --> 1.053744).  Saving model ...
Validation loss decreased (1.053744 --> 1.053065).  Saving model ...
Validation loss decreased (1.053065 --> 1.049087).  Saving model ...
Validation loss decreased (1.049087 --> 1.046876).  Saving model ...
Validation loss decreased (1.046876 --> 1.045297).  Saving model ...
Validation loss decreased (1.045297 --> 1.042906).  Saving model ...
Validation loss decreased (1.042906 --> 1.040165).  Saving model ...
Validation loss decreased (1.040165 --> 1.037659).  Saving model ...
Validation loss decreased (1.037659 --> 1.034924).  Saving model ...
EarlyStopping counter: 1 out of 5.0
EarlyStopping counter: 2 out of 5.0
EarlyStopping counter: 3 out of 5.0
Validation loss decreased (1.034924 --> 1.032577).  Saving model ...
Validation loss decreased (1.032577 --> 1.028134).  Saving model ...
Validation loss decreased (1.028134 --> 1.025002).  Saving model ...
Validation loss decreased (1.025002 --> 1.021671).  Saving model ...
EarlyStopping counter: 1 out of 5.0
Validation loss decreased (1.021671 --> 1.021181).  Saving model ...
Validation loss decreased (1.021181 --> 1.019643).  Saving model ...
Validation loss decreased (1.019643 --> 1.015952).  Saving model ...
Validation loss decreased (1.015952 --> 1.011357).  Saving model ...
EarlyStopping counter: 1 out of 5.0
EarlyStopping counter: 2 out of 5.0
EarlyStopping counter: 3 out of 5.0
Validation loss decreased (1.011357 --> 1.010495).  Saving model ...
Validation loss decreased (1.010495 --> 1.009749).  Saving model ...
Validation loss decreased (1.009749 --> 1.006114).  Saving model ...
EarlyStopping counter: 1 out of 5.0
Validation loss decreased (1.006114 --> 1.005783).  Saving model ...
Validation loss decreased (1.005783 --> 1.003774).  Saving model ...
EarlyStopping counter: 1 out of 5.0
EarlyStopping counter: 2 out of 5.0
EarlyStopping counter: 3 out of 5.0
Validation loss decreased (1.003774 --> 1.002238).  Saving model ...
Validation loss decreased (1.002238 --> 0.998459).  Saving model ...
EarlyStopping counter: 1 out of 5.0
EarlyStopping counter: 2 out of 5.0
Validation loss decreased (0.998459 --> 0.996030).  Saving model ...
Validation loss decreased (0.996030 --> 0.992690).  Saving model ...
Validation loss decreased (0.992690 --> 0.991956).  Saving model ...
EarlyStopping counter: 1 out of 5.0
EarlyStopping counter: 2 out of 5.0
EarlyStopping counter: 3 out of 5.0
EarlyStopping counter: 4 out of 5.0
EarlyStopping counter: 5 out of 5.0
/localscratch/yinan.29025152.0/env/lib/python3.7/site-packages/torch/nn/functional.py:1794: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.
  warnings.warn("nn.functional.tanh is deprecated. Use torch.tanh instead.")
/localscratch/yinan.29025152.0/env/lib/python3.7/site-packages/transformers/optimization.py:155: UserWarning: This overload of add_ is deprecated:
	add_(Number alpha, Tensor other)
Consider using one of the following signatures instead:
	add_(Tensor other, *, Number alpha) (Triggered internally at  ../torch/csrc/utils/python_arg_parser.cpp:1025.)
  exp_avg.mul_(beta1).add_(1.0 - beta1, grad)
wandb: Waiting for W&B process to finish, PID 77008... (success).
wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: \ 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: | 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: / 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: \ 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: | 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: / 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: \ 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: | 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: / 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb:                                                                                
wandb: Run history:
wandb:     e_F1 ▁▁▃▄▅▅▆▆▆▆▆▆▆▆▆▇▇▇▇▇▇▇▇▇▇▇▇▇████████████
wandb:   e_loss █▇▇▇▆▆▆▅▅▅▅▄▄▄▄▃▃▃▃▃▃▂▂▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁
wandb:     t_F1 ▁▁▂▂▃▃▄▄▄▄▅▅▅▅▅▆▆▅▆▆▆▆▆▇▇▇▇▇▇▇▇█▇▇██▇███
wandb:   t_loss ██▇▇▇▇▇▆▆▆▅▅▅▅▄▄▄▄▄▄▃▃▃▃▃▂▃▂▂▂▂▂▂▂▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:     e_F1 58.74583
wandb:   e_loss 0.99325
wandb:     t_F1 68.501
wandb:   t_loss 0.80027
wandb: 
wandb: Synced 4 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Synced fresh-music-3: https://wandb.ai/yinanazhou/xl_512_bs_8_lr_1e06_es_5_lc_True_nr_False_sr_False_stem_False_lemma_True_repeat_1_fold_1/runs/2n95chlp
wandb: Find logs at: ./wandb/run-20220315_235829-2n95chlp/logs/debug.log
wandb: 

wandb: wandb version 0.12.11 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
2022-03-16 01:13:51.114363: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1
wandb: Tracking run with wandb version 0.12.5
wandb: Syncing run curious-salad-3
wandb: ⭐️ View project at https://wandb.ai/yinanazhou/xl_512_bs_8_lr_1e06_es_5_lc_True_nr_False_sr_False_stem_False_lemma_True_repeat_1_fold_2
wandb: 🚀 View run at https://wandb.ai/yinanazhou/xl_512_bs_8_lr_1e06_es_5_lc_True_nr_False_sr_False_stem_False_lemma_True_repeat_1_fold_2/runs/3gkcsuxz
wandb: Run data is saved locally in /project/6002780/yinan/Thesis_MER_Lyrics/lyric-emotion/wandb/run-20220316_011348-3gkcsuxz
wandb: Run `wandb offline` to turn off syncing.
wandb: Network error (ReadTimeout), entering retry loop.

Validation loss decreased (inf --> 1.390527).  Saving model ...
Validation loss decreased (1.390527 --> 1.378385).  Saving model ...
Validation loss decreased (1.378385 --> 1.370073).  Saving model ...
Validation loss decreased (1.370073 --> 1.363025).  Saving model ...
Validation loss decreased (1.363025 --> 1.357291).  Saving model ...
Validation loss decreased (1.357291 --> 1.352726).  Saving model ...
Validation loss decreased (1.352726 --> 1.348511).  Saving model ...
Validation loss decreased (1.348511 --> 1.343617).  Saving model ...
Validation loss decreased (1.343617 --> 1.338970).  Saving model ...
Validation loss decreased (1.338970 --> 1.334084).  Saving model ...
Validation loss decreased (1.334084 --> 1.329531).  Saving model ...
Validation loss decreased (1.329531 --> 1.324806).  Saving model ...
Validation loss decreased (1.324806 --> 1.320026).  Saving model ...
Validation loss decreased (1.320026 --> 1.314950).  Saving model ...
Validation loss decreased (1.314950 --> 1.309706).  Saving model ...
Validation loss decreased (1.309706 --> 1.304918).  Saving model ...
Validation loss decreased (1.304918 --> 1.299338).  Saving model ...
Validation loss decreased (1.299338 --> 1.293151).  Saving model ...
Validation loss decreased (1.293151 --> 1.287251).  Saving model ...
Validation loss decreased (1.287251 --> 1.280917).  Saving model ...
Validation loss decreased (1.280917 --> 1.274582).  Saving model ...
Validation loss decreased (1.274582 --> 1.268513).  Saving model ...
Validation loss decreased (1.268513 --> 1.262025).  Saving model ...
Validation loss decreased (1.262025 --> 1.255214).  Saving model ...
Validation loss decreased (1.255214 --> 1.247452).  Saving model ...
Validation loss decreased (1.247452 --> 1.240377).  Saving model ...
Validation loss decreased (1.240377 --> 1.233637).  Saving model ...
Validation loss decreased (1.233637 --> 1.226385).  Saving model ...
Validation loss decreased (1.226385 --> 1.218541).  Saving model ...
Validation loss decreased (1.218541 --> 1.210968).  Saving model ...
Validation loss decreased (1.210968 --> 1.201808).  Saving model ...
Validation loss decreased (1.201808 --> 1.194610).  Saving model ...
Validation loss decreased (1.194610 --> 1.186763).  Saving model ...
Validation loss decreased (1.186763 --> 1.179117).  Saving model ...
Validation loss decreased (1.179117 --> 1.171656).  Saving model ...
Validation loss decreased (1.171656 --> 1.164217).  Saving model ...
Validation loss decreased (1.164217 --> 1.157620).  Saving model ...
Validation loss decreased (1.157620 --> 1.151104).  Saving model ...
Validation loss decreased (1.151104 --> 1.144797).  Saving model ...
Validation loss decreased (1.144797 --> 1.137997).  Saving model ...
Validation loss decreased (1.137997 --> 1.131534).  Saving model ...
Validation loss decreased (1.131534 --> 1.125442).  Saving model ...
Validation loss decreased (1.125442 --> 1.118368).  Saving model ...
Validation loss decreased (1.118368 --> 1.112332).  Saving model ...
Validation loss decreased (1.112332 --> 1.105845).  Saving model ...
Validation loss decreased (1.105845 --> 1.101155).  Saving model ...
Validation loss decreased (1.101155 --> 1.095415).  Saving model ...
Validation loss decreased (1.095415 --> 1.092126).  Saving model ...
Validation loss decreased (1.092126 --> 1.089042).  Saving model ...
Validation loss decreased (1.089042 --> 1.082868).  Saving model ...
Validation loss decreased (1.082868 --> 1.076440).  Saving model ...
Validation loss decreased (1.076440 --> 1.073447).  Saving model ...
Validation loss decreased (1.073447 --> 1.069317).  Saving model ...
Validation loss decreased (1.069317 --> 1.065419).  Saving model ...
Validation loss decreased (1.065419 --> 1.061552).  Saving model ...
Validation loss decreased (1.061552 --> 1.054768).  Saving model ...
Validation loss decreased (1.054768 --> 1.048972).  Saving model ...
Validation loss decreased (1.048972 --> 1.045963).  Saving model ...
Validation loss decreased (1.045963 --> 1.044283).  Saving model ...
Validation loss decreased (1.044283 --> 1.040600).  Saving model ...
Validation loss decreased (1.040600 --> 1.035460).  Saving model ...
Validation loss decreased (1.035460 --> 1.031657).  Saving model ...
Validation loss decreased (1.031657 --> 1.028923).  Saving model ...
Validation loss decreased (1.028923 --> 1.025849).  Saving model ...
Validation loss decreased (1.025849 --> 1.022593).  Saving model ...
Validation loss decreased (1.022593 --> 1.020800).  Saving model ...
Validation loss decreased (1.020800 --> 1.015635).  Saving model ...
Validation loss decreased (1.015635 --> 1.012528).  Saving model ...
Validation loss decreased (1.012528 --> 1.009974).  Saving model ...
Validation loss decreased (1.009974 --> 1.007811).  Saving model ...
Validation loss decreased (1.007811 --> 1.003059).  Saving model ...
Validation loss decreased (1.003059 --> 1.001073).  Saving model ...
Validation loss decreased (1.001073 --> 0.998658).  Saving model ...
Validation loss decreased (0.998658 --> 0.996488).  Saving model ...
Validation loss decreased (0.996488 --> 0.993305).  Saving model ...
Validation loss decreased (0.993305 --> 0.991376).  Saving model ...
Validation loss decreased (0.991376 --> 0.989603).  Saving model ...
Validation loss decreased (0.989603 --> 0.987677).  Saving model ...
Validation loss decreased (0.987677 --> 0.987401).  Saving model ...
Validation loss decreased (0.987401 --> 0.986716).  Saving model ...
Validation loss decreased (0.986716 --> 0.984186).  Saving model ...
Validation loss decreased (0.984186 --> 0.981996).  Saving model ...
Validation loss decreased (0.981996 --> 0.981608).  Saving model ...
Validation loss decreased (0.981608 --> 0.978813).  Saving model ...
Validation loss decreased (0.978813 --> 0.978789).  Saving model ...
Validation loss decreased (0.978789 --> 0.975276).  Saving model ...
EarlyStopping counter: 1 out of 5.0
EarlyStopping counter: 2 out of 5.0
Validation loss decreased (0.975276 --> 0.973511).  Saving model ...
EarlyStopping counter: 1 out of 5.0
Validation loss decreased (0.973511 --> 0.970240).  Saving model ...
Validation loss decreased (0.970240 --> 0.967145).  Saving model ...
Validation loss decreased (0.967145 --> 0.966215).  Saving model ...
Validation loss decreased (0.966215 --> 0.965160).  Saving model ...
Validation loss decreased (0.965160 --> 0.963797).  Saving model ...
Validation loss decreased (0.963797 --> 0.962181).  Saving model ...
Validation loss decreased (0.962181 --> 0.961057).  Saving model ...
EarlyStopping counter: 1 out of 5.0
Validation loss decreased (0.961057 --> 0.959135).  Saving model ...
EarlyStopping counter: 1 out of 5.0
EarlyStopping counter: 2 out of 5.0
Validation loss decreased (0.959135 --> 0.958707).  Saving model ...
Validation loss decreased (0.958707 --> 0.958263).  Saving model ...
EarlyStopping counter: 1 out of 5.0
Validation loss decreased (0.958263 --> 0.958021).  Saving model ...
Validation loss decreased (0.958021 --> 0.957726).  Saving model ...
Validation loss decreased (0.957726 --> 0.957080).  Saving model ...
EarlyStopping counter: 1 out of 5.0
EarlyStopping counter: 2 out of 5.0
EarlyStopping counter: 3 out of 5.0
Validation loss decreased (0.957080 --> 0.954874).  Saving model ...
EarlyStopping counter: 1 out of 5.0
EarlyStopping counter: 2 out of 5.0
EarlyStopping counter: 3 out of 5.0
EarlyStopping counter: 4 out of 5.0
Validation loss decreased (0.954874 --> 0.954717).  Saving model ...
EarlyStopping counter: 1 out of 5.0
EarlyStopping counter: 2 out of 5.0
EarlyStopping counter: 3 out of 5.0
EarlyStopping counter: 4 out of 5.0
EarlyStopping counter: 5 out of 5.0
/localscratch/yinan.29025152.0/env/lib/python3.7/site-packages/torch/nn/functional.py:1794: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.
  warnings.warn("nn.functional.tanh is deprecated. Use torch.tanh instead.")
wandb: Waiting for W&B process to finish, PID 81162... (success).
wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: \ 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: | 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: / 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: \ 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: | 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: / 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: \ 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: | 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: / 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb:                                                                                
wandb: Run history:
wandb:     e_F1 ▁▄▄▅▅▅▆▆▆▆▆▇▇▇▇▇▇▇▇██▇██████████████████
wandb:   e_loss ██▇▇▇▇▆▆▆▅▅▅▄▄▄▃▃▃▃▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:     t_F1 ▁▂▂▃▃▃▃▃▄▄▅▅▅▅▆▅▆▆▇▇▇▇▆▇▇▇▇▇▇▇▇██████▇▇█
wandb:   t_loss ███▇▇▇▇▇▇▆▆▆▆▅▅▅▄▄▄▄▄▄▄▃▃▃▃▂▂▂▂▂▂▂▂▂▁▂▁▁
wandb: 
wandb: Run summary:
wandb:     e_F1 59.00525
wandb:   e_loss 0.9567
wandb:     t_F1 70.965
wandb:   t_loss 0.77506
wandb: 
wandb: Synced 4 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Synced curious-salad-3: https://wandb.ai/yinanazhou/xl_512_bs_8_lr_1e06_es_5_lc_True_nr_False_sr_False_stem_False_lemma_True_repeat_1_fold_2/runs/3gkcsuxz
wandb: Find logs at: ./wandb/run-20220316_011348-3gkcsuxz/logs/debug.log
wandb: 

wandb: wandb version 0.12.11 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
2022-03-16 02:34:01.587110: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1
wandb: Tracking run with wandb version 0.12.5
wandb: Syncing run fiery-lake-3
wandb: ⭐️ View project at https://wandb.ai/yinanazhou/xl_512_bs_8_lr_1e06_es_5_lc_True_nr_False_sr_False_stem_False_lemma_True_repeat_2_fold_1
wandb: 🚀 View run at https://wandb.ai/yinanazhou/xl_512_bs_8_lr_1e06_es_5_lc_True_nr_False_sr_False_stem_False_lemma_True_repeat_2_fold_1/runs/152tpio0
wandb: Run data is saved locally in /project/6002780/yinan/Thesis_MER_Lyrics/lyric-emotion/wandb/run-20220316_023358-152tpio0
wandb: Run `wandb offline` to turn off syncing.

Validation loss decreased (inf --> 1.391919).  Saving model ...
Validation loss decreased (1.391919 --> 1.388374).  Saving model ...
Validation loss decreased (1.388374 --> 1.384834).  Saving model ...
Validation loss decreased (1.384834 --> 1.381427).  Saving model ...
Validation loss decreased (1.381427 --> 1.378233).  Saving model ...
Validation loss decreased (1.378233 --> 1.374877).  Saving model ...
Validation loss decreased (1.374877 --> 1.371534).  Saving model ...
Validation loss decreased (1.371534 --> 1.368167).  Saving model ...
Validation loss decreased (1.368167 --> 1.364664).  Saving model ...
Validation loss decreased (1.364664 --> 1.361246).  Saving model ...
Validation loss decreased (1.361246 --> 1.357638).  Saving model ...
Validation loss decreased (1.357638 --> 1.353751).  Saving model ...
Validation loss decreased (1.353751 --> 1.349731).  Saving model ...
Validation loss decreased (1.349731 --> 1.345472).  Saving model ...
Validation loss decreased (1.345472 --> 1.341338).  Saving model ...
Validation loss decreased (1.341338 --> 1.336636).  Saving model ...
Validation loss decreased (1.336636 --> 1.331537).  Saving model ...
Validation loss decreased (1.331537 --> 1.326386).  Saving model ...
Validation loss decreased (1.326386 --> 1.321157).  Saving model ...
Validation loss decreased (1.321157 --> 1.315030).  Saving model ...
Validation loss decreased (1.315030 --> 1.308395).  Saving model ...
Validation loss decreased (1.308395 --> 1.301443).  Saving model ...
Validation loss decreased (1.301443 --> 1.294398).  Saving model ...
Validation loss decreased (1.294398 --> 1.286996).  Saving model ...
Validation loss decreased (1.286996 --> 1.278668).  Saving model ...
Validation loss decreased (1.278668 --> 1.270204).  Saving model ...
Validation loss decreased (1.270204 --> 1.260465).  Saving model ...
Validation loss decreased (1.260465 --> 1.251905).  Saving model ...
Validation loss decreased (1.251905 --> 1.241706).  Saving model ...
Validation loss decreased (1.241706 --> 1.230595).  Saving model ...
Validation loss decreased (1.230595 --> 1.220248).  Saving model ...
Validation loss decreased (1.220248 --> 1.209884).  Saving model ...
Validation loss decreased (1.209884 --> 1.200758).  Saving model ...
Validation loss decreased (1.200758 --> 1.192603).  Saving model ...
Validation loss decreased (1.192603 --> 1.182544).  Saving model ...
Validation loss decreased (1.182544 --> 1.172158).  Saving model ...
Validation loss decreased (1.172158 --> 1.163471).  Saving model ...
Validation loss decreased (1.163471 --> 1.154944).  Saving model ...
Validation loss decreased (1.154944 --> 1.147911).  Saving model ...
Validation loss decreased (1.147911 --> 1.141586).  Saving model ...
Validation loss decreased (1.141586 --> 1.134534).  Saving model ...
Validation loss decreased (1.134534 --> 1.128397).  Saving model ...
Validation loss decreased (1.128397 --> 1.121517).  Saving model ...
Validation loss decreased (1.121517 --> 1.116702).  Saving model ...
Validation loss decreased (1.116702 --> 1.112224).  Saving model ...
Validation loss decreased (1.112224 --> 1.105203).  Saving model ...
Validation loss decreased (1.105203 --> 1.099651).  Saving model ...
Validation loss decreased (1.099651 --> 1.094482).  Saving model ...
Validation loss decreased (1.094482 --> 1.090150).  Saving model ...
Validation loss decreased (1.090150 --> 1.085155).  Saving model ...
Validation loss decreased (1.085155 --> 1.080500).  Saving model ...
Validation loss decreased (1.080500 --> 1.075347).  Saving model ...
Validation loss decreased (1.075347 --> 1.071099).  Saving model ...
Validation loss decreased (1.071099 --> 1.066762).  Saving model ...
Validation loss decreased (1.066762 --> 1.063292).  Saving model ...
Validation loss decreased (1.063292 --> 1.058663).  Saving model ...
Validation loss decreased (1.058663 --> 1.055691).  Saving model ...
Validation loss decreased (1.055691 --> 1.050779).  Saving model ...
Validation loss decreased (1.050779 --> 1.047863).  Saving model ...
Validation loss decreased (1.047863 --> 1.043877).  Saving model ...
Validation loss decreased (1.043877 --> 1.041037).  Saving model ...
Validation loss decreased (1.041037 --> 1.037849).  Saving model ...
Validation loss decreased (1.037849 --> 1.033847).  Saving model ...
Validation loss decreased (1.033847 --> 1.031644).  Saving model ...
Validation loss decreased (1.031644 --> 1.027620).  Saving model ...
Validation loss decreased (1.027620 --> 1.024066).  Saving model ...
Validation loss decreased (1.024066 --> 1.021627).  Saving model ...
Validation loss decreased (1.021627 --> 1.019729).  Saving model ...
Validation loss decreased (1.019729 --> 1.016448).  Saving model ...
Validation loss decreased (1.016448 --> 1.014934).  Saving model ...
Validation loss decreased (1.014934 --> 1.012375).  Saving model ...
Validation loss decreased (1.012375 --> 1.010032).  Saving model ...
Validation loss decreased (1.010032 --> 1.007546).  Saving model ...
Validation loss decreased (1.007546 --> 1.004558).  Saving model ...
Validation loss decreased (1.004558 --> 1.002166).  Saving model ...
Validation loss decreased (1.002166 --> 1.000114).  Saving model ...
Validation loss decreased (1.000114 --> 0.997788).  Saving model ...
Validation loss decreased (0.997788 --> 0.996316).  Saving model ...
Validation loss decreased (0.996316 --> 0.994916).  Saving model ...
Validation loss decreased (0.994916 --> 0.993733).  Saving model ...
Validation loss decreased (0.993733 --> 0.993422).  Saving model ...
Validation loss decreased (0.993422 --> 0.991277).  Saving model ...
Validation loss decreased (0.991277 --> 0.989210).  Saving model ...
Validation loss decreased (0.989210 --> 0.987805).  Saving model ...
Validation loss decreased (0.987805 --> 0.985729).  Saving model ...
Validation loss decreased (0.985729 --> 0.984416).  Saving model ...
Validation loss decreased (0.984416 --> 0.982818).  Saving model ...
EarlyStopping counter: 1 out of 5.0
Validation loss decreased (0.982818 --> 0.982434).  Saving model ...
Validation loss decreased (0.982434 --> 0.979734).  Saving model ...
Validation loss decreased (0.979734 --> 0.978656).  Saving model ...
Validation loss decreased (0.978656 --> 0.976391).  Saving model ...
Validation loss decreased (0.976391 --> 0.975839).  Saving model ...
Validation loss decreased (0.975839 --> 0.975117).  Saving model ...
Validation loss decreased (0.975117 --> 0.973755).  Saving model ...
Validation loss decreased (0.973755 --> 0.973033).  Saving model ...
Validation loss decreased (0.973033 --> 0.972734).  Saving model ...
Validation loss decreased (0.972734 --> 0.972381).  Saving model ...
EarlyStopping counter: 1 out of 5.0
Validation loss decreased (0.972381 --> 0.970795).  Saving model ...
Validation loss decreased (0.970795 --> 0.968379).  Saving model ...
EarlyStopping counter: 1 out of 5.0
Validation loss decreased (0.968379 --> 0.968207).  Saving model ...
EarlyStopping counter: 1 out of 5.0
Validation loss decreased (0.968207 --> 0.967199).  Saving model ...
EarlyStopping counter: 1 out of 5.0
Validation loss decreased (0.967199 --> 0.967118).  Saving model ...
Validation loss decreased (0.967118 --> 0.966565).  Saving model ...
Validation loss decreased (0.966565 --> 0.966094).  Saving model ...
EarlyStopping counter: 1 out of 5.0
EarlyStopping counter: 2 out of 5.0
EarlyStopping counter: 3 out of 5.0
EarlyStopping counter: 4 out of 5.0
EarlyStopping counter: 5 out of 5.0
/localscratch/yinan.29025152.0/env/lib/python3.7/site-packages/torch/nn/functional.py:1794: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.
  warnings.warn("nn.functional.tanh is deprecated. Use torch.tanh instead.")
wandb: Waiting for W&B process to finish, PID 85497... (success).
wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: \ 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: | 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: / 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: \ 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: | 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: / 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: \ 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: | 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: / 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb:                                                                                
wandb: Run history:
wandb:     e_F1 ▁▂▂▂▃▃▄▄▅▅▅▆▆▆▆▇▇▇▇███▇▇▇███████████████
wandb:   e_loss ████▇▇▇▇▆▆▆▅▅▄▄▃▃▃▃▃▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:     t_F1 ▁▁▂▂▂▂▃▃▃▄▄▅▅▅▅▅▅▆▆▆▆▆▆▆▆▇▇▇▇▇▇▇▇▇██▇███
wandb:   t_loss ████▇▇▇▇▇▆▆▆▅▅▅▅▄▄▄▄▃▄▃▃▃▃▂▂▂▂▂▂▂▂▂▂▂▁▁▁
wandb: 
wandb: Run summary:
wandb:     e_F1 61.283
wandb:   e_loss 0.96729
wandb:     t_F1 72.75493
wandb:   t_loss 0.76294
wandb: 
wandb: Synced 4 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Synced fiery-lake-3: https://wandb.ai/yinanazhou/xl_512_bs_8_lr_1e06_es_5_lc_True_nr_False_sr_False_stem_False_lemma_True_repeat_2_fold_1/runs/152tpio0
wandb: Find logs at: ./wandb/run-20220316_023358-152tpio0/logs/debug.log
wandb: 

wandb: wandb version 0.12.11 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
2022-03-16 03:49:44.537508: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1
wandb: Tracking run with wandb version 0.12.5
wandb: Syncing run earnest-donkey-1
wandb: ⭐️ View project at https://wandb.ai/yinanazhou/xl_512_bs_8_lr_1e06_es_5_lc_True_nr_False_sr_False_stem_False_lemma_True_repeat_2_fold_2
wandb: 🚀 View run at https://wandb.ai/yinanazhou/xl_512_bs_8_lr_1e06_es_5_lc_True_nr_False_sr_False_stem_False_lemma_True_repeat_2_fold_2/runs/3r32qu91
wandb: Run data is saved locally in /project/6002780/yinan/Thesis_MER_Lyrics/lyric-emotion/wandb/run-20220316_034941-3r32qu91
wandb: Run `wandb offline` to turn off syncing.

Validation loss decreased (inf --> 1.403945).  Saving model ...
Validation loss decreased (1.403945 --> 1.390509).  Saving model ...
Validation loss decreased (1.390509 --> 1.379978).  Saving model ...
Validation loss decreased (1.379978 --> 1.372972).  Saving model ...
Validation loss decreased (1.372972 --> 1.366864).  Saving model ...
Validation loss decreased (1.366864 --> 1.361893).  Saving model ...
Validation loss decreased (1.361893 --> 1.357659).  Saving model ...
Validation loss decreased (1.357659 --> 1.353645).  Saving model ...
Validation loss decreased (1.353645 --> 1.349693).  Saving model ...
Validation loss decreased (1.349693 --> 1.345477).  Saving model ...
Validation loss decreased (1.345477 --> 1.341536).  Saving model ...
Validation loss decreased (1.341536 --> 1.336946).  Saving model ...
Validation loss decreased (1.336946 --> 1.332502).  Saving model ...
Validation loss decreased (1.332502 --> 1.328243).  Saving model ...
Validation loss decreased (1.328243 --> 1.323464).  Saving model ...
Validation loss decreased (1.323464 --> 1.318748).  Saving model ...
Validation loss decreased (1.318748 --> 1.313181).  Saving model ...
Validation loss decreased (1.313181 --> 1.307926).  Saving model ...
Validation loss decreased (1.307926 --> 1.302161).  Saving model ...
Validation loss decreased (1.302161 --> 1.297118).  Saving model ...
Validation loss decreased (1.297118 --> 1.291316).  Saving model ...
Validation loss decreased (1.291316 --> 1.284351).  Saving model ...
Validation loss decreased (1.284351 --> 1.278328).  Saving model ...
Validation loss decreased (1.278328 --> 1.272243).  Saving model ...
Validation loss decreased (1.272243 --> 1.265888).  Saving model ...
Validation loss decreased (1.265888 --> 1.259347).  Saving model ...
Validation loss decreased (1.259347 --> 1.251853).  Saving model ...
Validation loss decreased (1.251853 --> 1.245502).  Saving model ...
Validation loss decreased (1.245502 --> 1.238768).  Saving model ...
Validation loss decreased (1.238768 --> 1.230316).  Saving model ...
Validation loss decreased (1.230316 --> 1.221640).  Saving model ...
Validation loss decreased (1.221640 --> 1.213390).  Saving model ...
Validation loss decreased (1.213390 --> 1.205777).  Saving model ...
Validation loss decreased (1.205777 --> 1.198337).  Saving model ...
Validation loss decreased (1.198337 --> 1.190539).  Saving model ...
Validation loss decreased (1.190539 --> 1.182009).  Saving model ...
Validation loss decreased (1.182009 --> 1.174148).  Saving model ...
Validation loss decreased (1.174148 --> 1.168279).  Saving model ...
Validation loss decreased (1.168279 --> 1.160887).  Saving model ...
Validation loss decreased (1.160887 --> 1.153524).  Saving model ...
Validation loss decreased (1.153524 --> 1.146666).  Saving model ...
Validation loss decreased (1.146666 --> 1.139895).  Saving model ...
Validation loss decreased (1.139895 --> 1.135297).  Saving model ...
Validation loss decreased (1.135297 --> 1.130449).  Saving model ...
Validation loss decreased (1.130449 --> 1.122907).  Saving model ...
Validation loss decreased (1.122907 --> 1.116844).  Saving model ...
Validation loss decreased (1.116844 --> 1.112386).  Saving model ...
Validation loss decreased (1.112386 --> 1.107395).  Saving model ...
Validation loss decreased (1.107395 --> 1.100421).  Saving model ...
Validation loss decreased (1.100421 --> 1.094022).  Saving model ...
Validation loss decreased (1.094022 --> 1.088741).  Saving model ...
Validation loss decreased (1.088741 --> 1.083070).  Saving model ...
Validation loss decreased (1.083070 --> 1.077876).  Saving model ...
Validation loss decreased (1.077876 --> 1.071582).  Saving model ...
Validation loss decreased (1.071582 --> 1.066871).  Saving model ...
Validation loss decreased (1.066871 --> 1.061153).  Saving model ...
Validation loss decreased (1.061153 --> 1.057216).  Saving model ...
Validation loss decreased (1.057216 --> 1.053410).  Saving model ...
Validation loss decreased (1.053410 --> 1.049906).  Saving model ...
Validation loss decreased (1.049906 --> 1.045123).  Saving model ...
Validation loss decreased (1.045123 --> 1.041165).  Saving model ...
Validation loss decreased (1.041165 --> 1.037058).  Saving model ...
Validation loss decreased (1.037058 --> 1.034235).  Saving model ...
Validation loss decreased (1.034235 --> 1.029168).  Saving model ...
Validation loss decreased (1.029168 --> 1.024851).  Saving model ...
Validation loss decreased (1.024851 --> 1.020703).  Saving model ...
Validation loss decreased (1.020703 --> 1.018005).  Saving model ...
Validation loss decreased (1.018005 --> 1.013249).  Saving model ...
Validation loss decreased (1.013249 --> 1.008964).  Saving model ...
Validation loss decreased (1.008964 --> 1.006907).  Saving model ...
Validation loss decreased (1.006907 --> 1.006514).  Saving model ...
Validation loss decreased (1.006514 --> 1.002390).  Saving model ...
Validation loss decreased (1.002390 --> 0.998018).  Saving model ...
Validation loss decreased (0.998018 --> 0.996894).  Saving model ...
Validation loss decreased (0.996894 --> 0.993796).  Saving model ...
Validation loss decreased (0.993796 --> 0.991907).  Saving model ...
Validation loss decreased (0.991907 --> 0.989169).  Saving model ...
Validation loss decreased (0.989169 --> 0.985595).  Saving model ...
Validation loss decreased (0.985595 --> 0.982089).  Saving model ...
Validation loss decreased (0.982089 --> 0.978153).  Saving model ...
Validation loss decreased (0.978153 --> 0.977826).  Saving model ...
Validation loss decreased (0.977826 --> 0.976821).  Saving model ...
Validation loss decreased (0.976821 --> 0.974941).  Saving model ...
Validation loss decreased (0.974941 --> 0.972161).  Saving model ...
Validation loss decreased (0.972161 --> 0.968197).  Saving model ...
Validation loss decreased (0.968197 --> 0.965407).  Saving model ...
Validation loss decreased (0.965407 --> 0.964600).  Saving model ...
Validation loss decreased (0.964600 --> 0.964008).  Saving model ...
Validation loss decreased (0.964008 --> 0.961323).  Saving model ...
Validation loss decreased (0.961323 --> 0.959675).  Saving model ...
Validation loss decreased (0.959675 --> 0.958279).  Saving model ...
Validation loss decreased (0.958279 --> 0.957082).  Saving model ...
Validation loss decreased (0.957082 --> 0.956304).  Saving model ...
Validation loss decreased (0.956304 --> 0.954333).  Saving model ...
Validation loss decreased (0.954333 --> 0.952072).  Saving model ...
Validation loss decreased (0.952072 --> 0.949947).  Saving model ...
Validation loss decreased (0.949947 --> 0.947774).  Saving model ...
Validation loss decreased (0.947774 --> 0.946274).  Saving model ...
Validation loss decreased (0.946274 --> 0.944194).  Saving model ...
Validation loss decreased (0.944194 --> 0.942759).  Saving model ...
Validation loss decreased (0.942759 --> 0.940788).  Saving model ...
Validation loss decreased (0.940788 --> 0.939016).  Saving model ...
Validation loss decreased (0.939016 --> 0.937957).  Saving model ...
Validation loss decreased (0.937957 --> 0.935970).  Saving model ...
Validation loss decreased (0.935970 --> 0.935967).  Saving model ...
Validation loss decreased (0.935967 --> 0.934870).  Saving model ...
Validation loss decreased (0.934870 --> 0.932917).  Saving model ...
Validation loss decreased (0.932917 --> 0.932829).  Saving model ...
Validation loss decreased (0.932829 --> 0.932714).  Saving model ...
Validation loss decreased (0.932714 --> 0.932462).  Saving model ...
Validation loss decreased (0.932462 --> 0.931483).  Saving model ...
Validation loss decreased (0.931483 --> 0.929935).  Saving model ...
Validation loss decreased (0.929935 --> 0.927182).  Saving model ...
EarlyStopping counter: 1 out of 5.0
Validation loss decreased (0.927182 --> 0.925937).  Saving model ...
Validation loss decreased (0.925937 --> 0.923993).  Saving model ...
Validation loss decreased (0.923993 --> 0.923173).  Saving model ...
Validation loss decreased (0.923173 --> 0.922135).  Saving model ...
Validation loss decreased (0.922135 --> 0.921189).  Saving model ...
Validation loss decreased (0.921189 --> 0.920809).  Saving model ...
EarlyStopping counter: 1 out of 5.0
Validation loss decreased (0.920809 --> 0.920307).  Saving model ...
Validation loss decreased (0.920307 --> 0.918886).  Saving model ...
Validation loss decreased (0.918886 --> 0.918792).  Saving model ...
Validation loss decreased (0.918792 --> 0.918452).  Saving model ...
Validation loss decreased (0.918452 --> 0.917373).  Saving model ...
EarlyStopping counter: 1 out of 5.0
EarlyStopping counter: 2 out of 5.0
Validation loss decreased (0.917373 --> 0.916708).  Saving model ...
Validation loss decreased (0.916708 --> 0.915987).  Saving model ...
Validation loss decreased (0.915987 --> 0.915743).  Saving model ...
Validation loss decreased (0.915743 --> 0.914113).  Saving model ...
EarlyStopping counter: 1 out of 5.0
Validation loss decreased (0.914113 --> 0.913762).  Saving model ...
EarlyStopping counter: 1 out of 5.0
Validation loss decreased (0.913762 --> 0.912932).  Saving model ...
EarlyStopping counter: 1 out of 5.0
Validation loss decreased (0.912932 --> 0.912343).  Saving model ...
Validation loss decreased (0.912343 --> 0.911344).  Saving model ...
EarlyStopping counter: 1 out of 5.0
EarlyStopping counter: 2 out of 5.0
EarlyStopping counter: 3 out of 5.0
Validation loss decreased (0.911344 --> 0.910441).  Saving model ...
Validation loss decreased (0.910441 --> 0.910166).  Saving model ...
Validation loss decreased (0.910166 --> 0.910145).  Saving model ...
EarlyStopping counter: 1 out of 5.0
EarlyStopping counter: 2 out of 5.0
EarlyStopping counter: 3 out of 5.0
EarlyStopping counter: 4 out of 5.0
EarlyStopping counter: 5 out of 5.0
/localscratch/yinan.29025152.0/env/lib/python3.7/site-packages/torch/nn/functional.py:1794: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.
  warnings.warn("nn.functional.tanh is deprecated. Use torch.tanh instead.")
wandb: Waiting for W&B process to finish, PID 89599... (success).
wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: \ 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: | 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: / 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: \ 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: | 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: / 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: \ 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: | 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: / 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb:                                                                                
wandb: Run history:
wandb:     e_F1 ▁▂▄▄▄▄▅▅▅▆▆▆▆▆▆▆▇▇▇▇▇▇▇▇▇▇▇▇▇███████████
wandb:   e_loss ██▇▇▇▇▆▆▅▅▅▄▄▄▃▃▃▃▂▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:     t_F1 ▁▂▂▂▃▃▄▄▄▅▅▅▆▅▆▆▆▆▇▆▇▆▇▆▇▇▇▇▇▇█▇█▇▇█████
wandb:   t_loss ███▇▇▇▇▇▆▆▆▆▅▅▅▅▄▄▄▃▃▃▃▃▃▃▃▂▂▂▂▂▂▂▂▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:     e_F1 63.78588
wandb:   e_loss 0.91198
wandb:     t_F1 74.02651
wandb:   t_loss 0.70875
wandb: 
wandb: Synced 4 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Synced earnest-donkey-1: https://wandb.ai/yinanazhou/xl_512_bs_8_lr_1e06_es_5_lc_True_nr_False_sr_False_stem_False_lemma_True_repeat_2_fold_2/runs/3r32qu91
wandb: Find logs at: ./wandb/run-20220316_034941-3r32qu91/logs/debug.log
wandb: 

wandb: wandb version 0.12.11 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
2022-03-16 05:23:56.116524: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1
wandb: Tracking run with wandb version 0.12.5
wandb: Syncing run kind-shadow-1
wandb: ⭐️ View project at https://wandb.ai/yinanazhou/xl_512_bs_8_lr_1e06_es_5_lc_True_nr_False_sr_False_stem_False_lemma_True_repeat_3_fold_1
wandb: 🚀 View run at https://wandb.ai/yinanazhou/xl_512_bs_8_lr_1e06_es_5_lc_True_nr_False_sr_False_stem_False_lemma_True_repeat_3_fold_1/runs/1tgtz35p
wandb: Run data is saved locally in /project/6002780/yinan/Thesis_MER_Lyrics/lyric-emotion/wandb/run-20220316_052352-1tgtz35p
wandb: Run `wandb offline` to turn off syncing.

Validation loss decreased (inf --> 1.430919).  Saving model ...
Validation loss decreased (1.430919 --> 1.417589).  Saving model ...
Validation loss decreased (1.417589 --> 1.408023).  Saving model ...
Validation loss decreased (1.408023 --> 1.400713).  Saving model ...
Validation loss decreased (1.400713 --> 1.394943).  Saving model ...
Validation loss decreased (1.394943 --> 1.389372).  Saving model ...
Validation loss decreased (1.389372 --> 1.384786).  Saving model ...
Validation loss decreased (1.384786 --> 1.380708).  Saving model ...
Validation loss decreased (1.380708 --> 1.376908).  Saving model ...
Validation loss decreased (1.376908 --> 1.373354).  Saving model ...
Validation loss decreased (1.373354 --> 1.369749).  Saving model ...
Validation loss decreased (1.369749 --> 1.366071).  Saving model ...
Validation loss decreased (1.366071 --> 1.362107).  Saving model ...
Validation loss decreased (1.362107 --> 1.358480).  Saving model ...
Validation loss decreased (1.358480 --> 1.354648).  Saving model ...
Validation loss decreased (1.354648 --> 1.350880).  Saving model ...
Validation loss decreased (1.350880 --> 1.346492).  Saving model ...
Validation loss decreased (1.346492 --> 1.341996).  Saving model ...
Validation loss decreased (1.341996 --> 1.336923).  Saving model ...
Validation loss decreased (1.336923 --> 1.332217).  Saving model ...
Validation loss decreased (1.332217 --> 1.327625).  Saving model ...
Validation loss decreased (1.327625 --> 1.322490).  Saving model ...
Validation loss decreased (1.322490 --> 1.317376).  Saving model ...
Validation loss decreased (1.317376 --> 1.311842).  Saving model ...
Validation loss decreased (1.311842 --> 1.306092).  Saving model ...
Validation loss decreased (1.306092 --> 1.299123).  Saving model ...
Validation loss decreased (1.299123 --> 1.292146).  Saving model ...
Validation loss decreased (1.292146 --> 1.285412).  Saving model ...
Validation loss decreased (1.285412 --> 1.276928).  Saving model ...
Validation loss decreased (1.276928 --> 1.270053).  Saving model ...
Validation loss decreased (1.270053 --> 1.261852).  Saving model ...
Validation loss decreased (1.261852 --> 1.252808).  Saving model ...
Validation loss decreased (1.252808 --> 1.245494).  Saving model ...
Validation loss decreased (1.245494 --> 1.236434).  Saving model ...
Validation loss decreased (1.236434 --> 1.227343).  Saving model ...
Validation loss decreased (1.227343 --> 1.218950).  Saving model ...
Validation loss decreased (1.218950 --> 1.210742).  Saving model ...
Validation loss decreased (1.210742 --> 1.202110).  Saving model ...
Validation loss decreased (1.202110 --> 1.194802).  Saving model ...
Validation loss decreased (1.194802 --> 1.185937).  Saving model ...
Validation loss decreased (1.185937 --> 1.180069).  Saving model ...
Validation loss decreased (1.180069 --> 1.173715).  Saving model ...
Validation loss decreased (1.173715 --> 1.167758).  Saving model ...
Validation loss decreased (1.167758 --> 1.162703).  Saving model ...
Validation loss decreased (1.162703 --> 1.156519).  Saving model ...
Validation loss decreased (1.156519 --> 1.151221).  Saving model ...
Validation loss decreased (1.151221 --> 1.143973).  Saving model ...
Validation loss decreased (1.143973 --> 1.138478).  Saving model ...
Validation loss decreased (1.138478 --> 1.132170).  Saving model ...
Validation loss decreased (1.132170 --> 1.126701).  Saving model ...
Validation loss decreased (1.126701 --> 1.121165).  Saving model ...
Validation loss decreased (1.121165 --> 1.115786).  Saving model ...
Validation loss decreased (1.115786 --> 1.111618).  Saving model ...
Validation loss decreased (1.111618 --> 1.106294).  Saving model ...
Validation loss decreased (1.106294 --> 1.101426).  Saving model ...
Validation loss decreased (1.101426 --> 1.097709).  Saving model ...
Validation loss decreased (1.097709 --> 1.093897).  Saving model ...
Validation loss decreased (1.093897 --> 1.090646).  Saving model ...
Validation loss decreased (1.090646 --> 1.086220).  Saving model ...
Validation loss decreased (1.086220 --> 1.081125).  Saving model ...
Validation loss decreased (1.081125 --> 1.077839).  Saving model ...
Validation loss decreased (1.077839 --> 1.074413).  Saving model ...
Validation loss decreased (1.074413 --> 1.069506).  Saving model ...
Validation loss decreased (1.069506 --> 1.064951).  Saving model ...
Validation loss decreased (1.064951 --> 1.061020).  Saving model ...
Validation loss decreased (1.061020 --> 1.055567).  Saving model ...
Validation loss decreased (1.055567 --> 1.051070).  Saving model ...
Validation loss decreased (1.051070 --> 1.049190).  Saving model ...
Validation loss decreased (1.049190 --> 1.043714).  Saving model ...
Validation loss decreased (1.043714 --> 1.040989).  Saving model ...
Validation loss decreased (1.040989 --> 1.038053).  Saving model ...
Validation loss decreased (1.038053 --> 1.035128).  Saving model ...
Validation loss decreased (1.035128 --> 1.031287).  Saving model ...
Validation loss decreased (1.031287 --> 1.028459).  Saving model ...
Validation loss decreased (1.028459 --> 1.024982).  Saving model ...
Validation loss decreased (1.024982 --> 1.022060).  Saving model ...
Validation loss decreased (1.022060 --> 1.017786).  Saving model ...
Validation loss decreased (1.017786 --> 1.014666).  Saving model ...
Validation loss decreased (1.014666 --> 1.013049).  Saving model ...
Validation loss decreased (1.013049 --> 1.010265).  Saving model ...
Validation loss decreased (1.010265 --> 1.007814).  Saving model ...
Validation loss decreased (1.007814 --> 1.005737).  Saving model ...
Validation loss decreased (1.005737 --> 1.003010).  Saving model ...
Validation loss decreased (1.003010 --> 1.000500).  Saving model ...
Validation loss decreased (1.000500 --> 1.000329).  Saving model ...
Validation loss decreased (1.000329 --> 0.998945).  Saving model ...
Validation loss decreased (0.998945 --> 0.998438).  Saving model ...
Validation loss decreased (0.998438 --> 0.997567).  Saving model ...
Validation loss decreased (0.997567 --> 0.996012).  Saving model ...
Validation loss decreased (0.996012 --> 0.995818).  Saving model ...
Validation loss decreased (0.995818 --> 0.994220).  Saving model ...
Validation loss decreased (0.994220 --> 0.991042).  Saving model ...
Validation loss decreased (0.991042 --> 0.988095).  Saving model ...
Validation loss decreased (0.988095 --> 0.984703).  Saving model ...
EarlyStopping counter: 1 out of 5.0
Validation loss decreased (0.984703 --> 0.983678).  Saving model ...
Validation loss decreased (0.983678 --> 0.981583).  Saving model ...
Validation loss decreased (0.981583 --> 0.979286).  Saving model ...
Validation loss decreased (0.979286 --> 0.977040).  Saving model ...
Validation loss decreased (0.977040 --> 0.974291).  Saving model ...
Validation loss decreased (0.974291 --> 0.974022).  Saving model ...
EarlyStopping counter: 1 out of 5.0
Validation loss decreased (0.974022 --> 0.971979).  Saving model ...
Validation loss decreased (0.971979 --> 0.969146).  Saving model ...
Validation loss decreased (0.969146 --> 0.966846).  Saving model ...
Validation loss decreased (0.966846 --> 0.966810).  Saving model ...
Validation loss decreased (0.966810 --> 0.965242).  Saving model ...
EarlyStopping counter: 1 out of 5.0
Validation loss decreased (0.965242 --> 0.964852).  Saving model ...
Validation loss decreased (0.964852 --> 0.964628).  Saving model ...
Validation loss decreased (0.964628 --> 0.963925).  Saving model ...
Validation loss decreased (0.963925 --> 0.961817).  Saving model ...
Validation loss decreased (0.961817 --> 0.961276).  Saving model ...
Validation loss decreased (0.961276 --> 0.961216).  Saving model ...
Validation loss decreased (0.961216 --> 0.960235).  Saving model ...
Validation loss decreased (0.960235 --> 0.959806).  Saving model ...
Validation loss decreased (0.959806 --> 0.959061).  Saving model ...
EarlyStopping counter: 1 out of 5.0
Validation loss decreased (0.959061 --> 0.956930).  Saving model ...
EarlyStopping counter: 1 out of 5.0
Validation loss decreased (0.956930 --> 0.956649).  Saving model ...
EarlyStopping counter: 1 out of 5.0
Validation loss decreased (0.956649 --> 0.955739).  Saving model ...
Validation loss decreased (0.955739 --> 0.954581).  Saving model ...
EarlyStopping counter: 1 out of 5.0
EarlyStopping counter: 2 out of 5.0
Validation loss decreased (0.954581 --> 0.953452).  Saving model ...
Validation loss decreased (0.953452 --> 0.950773).  Saving model ...
EarlyStopping counter: 1 out of 5.0
EarlyStopping counter: 2 out of 5.0
EarlyStopping counter: 3 out of 5.0
EarlyStopping counter: 4 out of 5.0
EarlyStopping counter: 5 out of 5.0
/localscratch/yinan.29025152.0/env/lib/python3.7/site-packages/torch/nn/functional.py:1794: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.
  warnings.warn("nn.functional.tanh is deprecated. Use torch.tanh instead.")
wandb: Waiting for W&B process to finish, PID 94696... (success).
wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: \ 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: | 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: / 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: \ 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: | 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: / 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: \ 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: | 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: / 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: \ 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: | 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb:                                                                                
wandb: Run history:
wandb:     e_F1 ▁▁▃▄▄▅▅▅▆▆▆▇▇▇▇▇▇▇▇▇████████████████████
wandb:   e_loss ██▇▇▇▇▇▆▆▆▅▅▄▄▄▃▃▃▃▃▂▂▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁
wandb:     t_F1 ▁▁▂▂▃▃▃▄▄▄▅▅▅▆▅▆▆▆▆▆▆▆▆▇▇▇▇▇▇▇▇▇▇▇█▇████
wandb:   t_loss ██▇▇▇▇▇▇▇▆▆▆▅▅▅▅▄▄▄▄▄▃▃▃▃▃▃▂▂▂▂▂▂▂▂▂▁▁▁▁
wandb: 
wandb: Run summary:
wandb:     e_F1 61.09355
wandb:   e_loss 0.95131
wandb:     t_F1 68.75921
wandb:   t_loss 0.76954
wandb: 
wandb: Synced 4 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Synced kind-shadow-1: https://wandb.ai/yinanazhou/xl_512_bs_8_lr_1e06_es_5_lc_True_nr_False_sr_False_stem_False_lemma_True_repeat_3_fold_1/runs/1tgtz35p
wandb: Find logs at: ./wandb/run-20220316_052352-1tgtz35p/logs/debug.log
wandb: 

wandb: wandb version 0.12.11 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
2022-03-16 06:49:39.589448: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1
wandb: Tracking run with wandb version 0.12.5
wandb: Syncing run driven-brook-1
wandb: ⭐️ View project at https://wandb.ai/yinanazhou/xl_512_bs_8_lr_1e06_es_5_lc_True_nr_False_sr_False_stem_False_lemma_True_repeat_3_fold_2
wandb: 🚀 View run at https://wandb.ai/yinanazhou/xl_512_bs_8_lr_1e06_es_5_lc_True_nr_False_sr_False_stem_False_lemma_True_repeat_3_fold_2/runs/1q6ocf2k
wandb: Run data is saved locally in /project/6002780/yinan/Thesis_MER_Lyrics/lyric-emotion/wandb/run-20220316_064936-1q6ocf2k
wandb: Run `wandb offline` to turn off syncing.

Validation loss decreased (inf --> 1.407562).  Saving model ...
Validation loss decreased (1.407562 --> 1.396603).  Saving model ...
Validation loss decreased (1.396603 --> 1.387824).  Saving model ...
Validation loss decreased (1.387824 --> 1.380628).  Saving model ...
Validation loss decreased (1.380628 --> 1.374280).  Saving model ...
Validation loss decreased (1.374280 --> 1.368909).  Saving model ...
Validation loss decreased (1.368909 --> 1.363782).  Saving model ...
Validation loss decreased (1.363782 --> 1.359420).  Saving model ...
Validation loss decreased (1.359420 --> 1.354849).  Saving model ...
Validation loss decreased (1.354849 --> 1.350280).  Saving model ...
Validation loss decreased (1.350280 --> 1.345632).  Saving model ...
Validation loss decreased (1.345632 --> 1.341103).  Saving model ...
Validation loss decreased (1.341103 --> 1.336468).  Saving model ...
Validation loss decreased (1.336468 --> 1.331876).  Saving model ...
Validation loss decreased (1.331876 --> 1.327004).  Saving model ...
Validation loss decreased (1.327004 --> 1.322196).  Saving model ...
Validation loss decreased (1.322196 --> 1.316991).  Saving model ...
Validation loss decreased (1.316991 --> 1.311143).  Saving model ...
Validation loss decreased (1.311143 --> 1.304695).  Saving model ...
Validation loss decreased (1.304695 --> 1.299293).  Saving model ...
Validation loss decreased (1.299293 --> 1.292450).  Saving model ...
Validation loss decreased (1.292450 --> 1.285344).  Saving model ...
Validation loss decreased (1.285344 --> 1.277547).  Saving model ...
Validation loss decreased (1.277547 --> 1.269495).  Saving model ...
Validation loss decreased (1.269495 --> 1.261381).  Saving model ...
Validation loss decreased (1.261381 --> 1.253053).  Saving model ...
Validation loss decreased (1.253053 --> 1.245100).  Saving model ...
Validation loss decreased (1.245100 --> 1.236101).  Saving model ...
Validation loss decreased (1.236101 --> 1.228228).  Saving model ...
Validation loss decreased (1.228228 --> 1.220868).  Saving model ...
Validation loss decreased (1.220868 --> 1.212523).  Saving model ...
Validation loss decreased (1.212523 --> 1.204399).  Saving model ...
Validation loss decreased (1.204399 --> 1.196761).  Saving model ...
Validation loss decreased (1.196761 --> 1.189098).  Saving model ...
Validation loss decreased (1.189098 --> 1.182503).  Saving model ...
Validation loss decreased (1.182503 --> 1.176947).  Saving model ...
Validation loss decreased (1.176947 --> 1.169809).  Saving model ...
Validation loss decreased (1.169809 --> 1.161055).  Saving model ...
Validation loss decreased (1.161055 --> 1.154185).  Saving model ...
Validation loss decreased (1.154185 --> 1.150763).  Saving model ...
Validation loss decreased (1.150763 --> 1.143252).  Saving model ...
Validation loss decreased (1.143252 --> 1.137499).  Saving model ...
Validation loss decreased (1.137499 --> 1.131641).  Saving model ...
Validation loss decreased (1.131641 --> 1.126123).  Saving model ...
Validation loss decreased (1.126123 --> 1.119414).  Saving model ...
Validation loss decreased (1.119414 --> 1.113800).  Saving model ...
Validation loss decreased (1.113800 --> 1.108620).  Saving model ...
Validation loss decreased (1.108620 --> 1.102477).  Saving model ...
Validation loss decreased (1.102477 --> 1.097482).  Saving model ...
Validation loss decreased (1.097482 --> 1.090635).  Saving model ...
Validation loss decreased (1.090635 --> 1.085533).  Saving model ...
Validation loss decreased (1.085533 --> 1.081897).  Saving model ...
Validation loss decreased (1.081897 --> 1.078230).  Saving model ...
Validation loss decreased (1.078230 --> 1.071960).  Saving model ...
Validation loss decreased (1.071960 --> 1.069201).  Saving model ...
Validation loss decreased (1.069201 --> 1.064366).  Saving model ...
Validation loss decreased (1.064366 --> 1.059876).  Saving model ...
Validation loss decreased (1.059876 --> 1.056818).  Saving model ...
Validation loss decreased (1.056818 --> 1.053079).  Saving model ...
Validation loss decreased (1.053079 --> 1.048582).  Saving model ...
Validation loss decreased (1.048582 --> 1.043800).  Saving model ...
Validation loss decreased (1.043800 --> 1.040141).  Saving model ...
Validation loss decreased (1.040141 --> 1.037341).  Saving model ...
Validation loss decreased (1.037341 --> 1.033562).  Saving model ...
Validation loss decreased (1.033562 --> 1.029404).  Saving model ...
Validation loss decreased (1.029404 --> 1.024447).  Saving model ...
Validation loss decreased (1.024447 --> 1.020378).  Saving model ...
Validation loss decreased (1.020378 --> 1.017096).  Saving model ...
Validation loss decreased (1.017096 --> 1.015192).  Saving model ...
Validation loss decreased (1.015192 --> 1.013189).  Saving model ...
Validation loss decreased (1.013189 --> 1.011232).  Saving model ...
Validation loss decreased (1.011232 --> 1.008839).  Saving model ...
Validation loss decreased (1.008839 --> 1.006344).  Saving model ...
Validation loss decreased (1.006344 --> 1.002181).  Saving model ...
Validation loss decreased (1.002181 --> 0.998124).  Saving model ...
Validation loss decreased (0.998124 --> 0.997054).  Saving model ...
Validation loss decreased (0.997054 --> 0.995217).  Saving model ...
Validation loss decreased (0.995217 --> 0.991629).  Saving model ...
Validation loss decreased (0.991629 --> 0.989763).  Saving model ...
Validation loss decreased (0.989763 --> 0.989171).  Saving model ...
Validation loss decreased (0.989171 --> 0.986054).  Saving model ...
Validation loss decreased (0.986054 --> 0.984858).  Saving model ...
EarlyStopping counter: 1 out of 5.0
Validation loss decreased (0.984858 --> 0.982679).  Saving model ...
Validation loss decreased (0.982679 --> 0.979502).  Saving model ...
Validation loss decreased (0.979502 --> 0.976705).  Saving model ...
Validation loss decreased (0.976705 --> 0.973733).  Saving model ...
EarlyStopping counter: 1 out of 5.0
Validation loss decreased (0.973733 --> 0.972121).  Saving model ...
Validation loss decreased (0.972121 --> 0.967947).  Saving model ...
Validation loss decreased (0.967947 --> 0.965778).  Saving model ...
Validation loss decreased (0.965778 --> 0.963611).  Saving model ...
EarlyStopping counter: 1 out of 5.0
Validation loss decreased (0.963611 --> 0.960051).  Saving model ...
Validation loss decreased (0.960051 --> 0.957843).  Saving model ...
EarlyStopping counter: 1 out of 5.0
Validation loss decreased (0.957843 --> 0.957825).  Saving model ...
Validation loss decreased (0.957825 --> 0.955493).  Saving model ...
Validation loss decreased (0.955493 --> 0.953159).  Saving model ...
EarlyStopping counter: 1 out of 5.0
EarlyStopping counter: 2 out of 5.0
EarlyStopping counter: 3 out of 5.0
Validation loss decreased (0.953159 --> 0.952426).  Saving model ...
Validation loss decreased (0.952426 --> 0.950313).  Saving model ...
Validation loss decreased (0.950313 --> 0.948423).  Saving model ...
Validation loss decreased (0.948423 --> 0.948305).  Saving model ...
Validation loss decreased (0.948305 --> 0.947135).  Saving model ...
Validation loss decreased (0.947135 --> 0.944616).  Saving model ...
Validation loss decreased (0.944616 --> 0.943901).  Saving model ...
Validation loss decreased (0.943901 --> 0.943388).  Saving model ...
Validation loss decreased (0.943388 --> 0.942631).  Saving model ...
Validation loss decreased (0.942631 --> 0.941995).  Saving model ...
Validation loss decreased (0.941995 --> 0.941550).  Saving model ...
Validation loss decreased (0.941550 --> 0.941422).  Saving model ...
Validation loss decreased (0.941422 --> 0.939239).  Saving model ...
Validation loss decreased (0.939239 --> 0.937479).  Saving model ...
EarlyStopping counter: 1 out of 5.0
EarlyStopping counter: 2 out of 5.0
EarlyStopping counter: 3 out of 5.0
Validation loss decreased (0.937479 --> 0.936477).  Saving model ...
Validation loss decreased (0.936477 --> 0.935538).  Saving model ...
EarlyStopping counter: 1 out of 5.0
Validation loss decreased (0.935538 --> 0.935439).  Saving model ...
Validation loss decreased (0.935439 --> 0.935027).  Saving model ...
EarlyStopping counter: 1 out of 5.0
EarlyStopping counter: 2 out of 5.0
EarlyStopping counter: 3 out of 5.0
EarlyStopping counter: 4 out of 5.0
EarlyStopping counter: 5 out of 5.0
/localscratch/yinan.29025152.0/env/lib/python3.7/site-packages/torch/nn/functional.py:1794: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.
  warnings.warn("nn.functional.tanh is deprecated. Use torch.tanh instead.")
wandb: Waiting for W&B process to finish, PID 99312... (success).
wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: \ 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: | 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: / 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: \ 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: | 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: / 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: \ 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: | 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: / 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb:                                                                                
wandb: Run history:
wandb:     e_F1 ▁▁▃▃▅▅▆▆▆▆▆▆▇▇▇▇▇▇▇▇▇▇▇▇▇▇█▇████████████
wandb:   e_loss ██▇▇▇▇▇▆▆▅▅▅▄▄▄▃▃▃▃▃▂▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁
wandb:     t_F1 ▁▁▂▃▃▃▃▄▅▅▅▅▆▆▆▆▆▆▆▆▆▆▇▇▇▇▇▇▇█▇▇████████
wandb:   t_loss ████▇▇▇▇▆▆▆▆▅▅▅▄▅▄▄▄▃▃▃▃▃▃▂▂▂▂▂▁▂▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:     e_F1 62.38087
wandb:   e_loss 0.93703
wandb:     t_F1 68.71994
wandb:   t_loss 0.75773
wandb: 
wandb: Synced 4 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Synced driven-brook-1: https://wandb.ai/yinanazhou/xl_512_bs_8_lr_1e06_es_5_lc_True_nr_False_sr_False_stem_False_lemma_True_repeat_3_fold_2/runs/1q6ocf2k
wandb: Find logs at: ./wandb/run-20220316_064936-1q6ocf2k/logs/debug.log
wandb: 

wandb: wandb version 0.12.11 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
2022-03-16 08:10:30.683593: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1
wandb: Tracking run with wandb version 0.12.5
wandb: Syncing run playful-energy-1
wandb: ⭐️ View project at https://wandb.ai/yinanazhou/xl_512_bs_8_lr_1e06_es_5_lc_True_nr_False_sr_False_stem_False_lemma_True_repeat_4_fold_1
wandb: 🚀 View run at https://wandb.ai/yinanazhou/xl_512_bs_8_lr_1e06_es_5_lc_True_nr_False_sr_False_stem_False_lemma_True_repeat_4_fold_1/runs/a4wn4tcw
wandb: Run data is saved locally in /project/6002780/yinan/Thesis_MER_Lyrics/lyric-emotion/wandb/run-20220316_081027-a4wn4tcw
wandb: Run `wandb offline` to turn off syncing.

Validation loss decreased (inf --> 1.481616).  Saving model ...
Validation loss decreased (1.481616 --> 1.447286).  Saving model ...
Validation loss decreased (1.447286 --> 1.422880).  Saving model ...
Validation loss decreased (1.422880 --> 1.405300).  Saving model ...
Validation loss decreased (1.405300 --> 1.391114).  Saving model ...
Validation loss decreased (1.391114 --> 1.380909).  Saving model ...
Validation loss decreased (1.380909 --> 1.373348).  Saving model ...
Validation loss decreased (1.373348 --> 1.366992).  Saving model ...
Validation loss decreased (1.366992 --> 1.361289).  Saving model ...
Validation loss decreased (1.361289 --> 1.356001).  Saving model ...
Validation loss decreased (1.356001 --> 1.351114).  Saving model ...
Validation loss decreased (1.351114 --> 1.346255).  Saving model ...
Validation loss decreased (1.346255 --> 1.341397).  Saving model ...
Validation loss decreased (1.341397 --> 1.336312).  Saving model ...
Validation loss decreased (1.336312 --> 1.330687).  Saving model ...
Validation loss decreased (1.330687 --> 1.325458).  Saving model ...
Validation loss decreased (1.325458 --> 1.320247).  Saving model ...
Validation loss decreased (1.320247 --> 1.315005).  Saving model ...
Validation loss decreased (1.315005 --> 1.309473).  Saving model ...
Validation loss decreased (1.309473 --> 1.304029).  Saving model ...
Validation loss decreased (1.304029 --> 1.297876).  Saving model ...
Validation loss decreased (1.297876 --> 1.292059).  Saving model ...
Validation loss decreased (1.292059 --> 1.285947).  Saving model ...
Validation loss decreased (1.285947 --> 1.279641).  Saving model ...
Validation loss decreased (1.279641 --> 1.273173).  Saving model ...
Validation loss decreased (1.273173 --> 1.265883).  Saving model ...
Validation loss decreased (1.265883 --> 1.259552).  Saving model ...
Validation loss decreased (1.259552 --> 1.252160).  Saving model ...
Validation loss decreased (1.252160 --> 1.245453).  Saving model ...
Validation loss decreased (1.245453 --> 1.238286).  Saving model ...
Validation loss decreased (1.238286 --> 1.231738).  Saving model ...
Validation loss decreased (1.231738 --> 1.225361).  Saving model ...
Validation loss decreased (1.225361 --> 1.218347).  Saving model ...
Validation loss decreased (1.218347 --> 1.211605).  Saving model ...
Validation loss decreased (1.211605 --> 1.205588).  Saving model ...
Validation loss decreased (1.205588 --> 1.198087).  Saving model ...
Validation loss decreased (1.198087 --> 1.190637).  Saving model ...
Validation loss decreased (1.190637 --> 1.184493).  Saving model ...
Validation loss decreased (1.184493 --> 1.177403).  Saving model ...
Validation loss decreased (1.177403 --> 1.170683).  Saving model ...
Validation loss decreased (1.170683 --> 1.164922).  Saving model ...
Validation loss decreased (1.164922 --> 1.159711).  Saving model ...
Validation loss decreased (1.159711 --> 1.154255).  Saving model ...
Validation loss decreased (1.154255 --> 1.147462).  Saving model ...
Validation loss decreased (1.147462 --> 1.141845).  Saving model ...
Validation loss decreased (1.141845 --> 1.136660).  Saving model ...
Validation loss decreased (1.136660 --> 1.131158).  Saving model ...
Validation loss decreased (1.131158 --> 1.126415).  Saving model ...
Validation loss decreased (1.126415 --> 1.121599).  Saving model ...
Validation loss decreased (1.121599 --> 1.116404).  Saving model ...
Validation loss decreased (1.116404 --> 1.111401).  Saving model ...
Validation loss decreased (1.111401 --> 1.107059).  Saving model ...
Validation loss decreased (1.107059 --> 1.102605).  Saving model ...
Validation loss decreased (1.102605 --> 1.098997).  Saving model ...
Validation loss decreased (1.098997 --> 1.094536).  Saving model ...
Validation loss decreased (1.094536 --> 1.089124).  Saving model ...
Validation loss decreased (1.089124 --> 1.085601).  Saving model ...
Validation loss decreased (1.085601 --> 1.082106).  Saving model ...
Validation loss decreased (1.082106 --> 1.078796).  Saving model ...
Validation loss decreased (1.078796 --> 1.073871).  Saving model ...
Validation loss decreased (1.073871 --> 1.069779).  Saving model ...
Validation loss decreased (1.069779 --> 1.066813).  Saving model ...
Validation loss decreased (1.066813 --> 1.064949).  Saving model ...
Validation loss decreased (1.064949 --> 1.060731).  Saving model ...
Validation loss decreased (1.060731 --> 1.058166).  Saving model ...
Validation loss decreased (1.058166 --> 1.054309).  Saving model ...
Validation loss decreased (1.054309 --> 1.050697).  Saving model ...
Validation loss decreased (1.050697 --> 1.048933).  Saving model ...
Validation loss decreased (1.048933 --> 1.044442).  Saving model ...
Validation loss decreased (1.044442 --> 1.040275).  Saving model ...
Validation loss decreased (1.040275 --> 1.037053).  Saving model ...
Validation loss decreased (1.037053 --> 1.035385).  Saving model ...
Validation loss decreased (1.035385 --> 1.032791).  Saving model ...
Validation loss decreased (1.032791 --> 1.030785).  Saving model ...
Validation loss decreased (1.030785 --> 1.028886).  Saving model ...
Validation loss decreased (1.028886 --> 1.025347).  Saving model ...
Validation loss decreased (1.025347 --> 1.022766).  Saving model ...
Validation loss decreased (1.022766 --> 1.019775).  Saving model ...
Validation loss decreased (1.019775 --> 1.017300).  Saving model ...
Validation loss decreased (1.017300 --> 1.014994).  Saving model ...
Validation loss decreased (1.014994 --> 1.013314).  Saving model ...
Validation loss decreased (1.013314 --> 1.010652).  Saving model ...
Validation loss decreased (1.010652 --> 1.009429).  Saving model ...
Validation loss decreased (1.009429 --> 1.005500).  Saving model ...
Validation loss decreased (1.005500 --> 1.003939).  Saving model ...
Validation loss decreased (1.003939 --> 1.002792).  Saving model ...
Validation loss decreased (1.002792 --> 1.000609).  Saving model ...
Validation loss decreased (1.000609 --> 0.997795).  Saving model ...
Validation loss decreased (0.997795 --> 0.997687).  Saving model ...
Validation loss decreased (0.997687 --> 0.995736).  Saving model ...
Validation loss decreased (0.995736 --> 0.994343).  Saving model ...
Validation loss decreased (0.994343 --> 0.990412).  Saving model ...
Validation loss decreased (0.990412 --> 0.989969).  Saving model ...
Validation loss decreased (0.989969 --> 0.989926).  Saving model ...
Validation loss decreased (0.989926 --> 0.987167).  Saving model ...
Validation loss decreased (0.987167 --> 0.986374).  Saving model ...
Validation loss decreased (0.986374 --> 0.985201).  Saving model ...
Validation loss decreased (0.985201 --> 0.984124).  Saving model ...
Validation loss decreased (0.984124 --> 0.983033).  Saving model ...
Validation loss decreased (0.983033 --> 0.981252).  Saving model ...
Validation loss decreased (0.981252 --> 0.980121).  Saving model ...
Validation loss decreased (0.980121 --> 0.978489).  Saving model ...
Validation loss decreased (0.978489 --> 0.978205).  Saving model ...
Validation loss decreased (0.978205 --> 0.975344).  Saving model ...
Validation loss decreased (0.975344 --> 0.974920).  Saving model ...
Validation loss decreased (0.974920 --> 0.972018).  Saving model ...
Validation loss decreased (0.972018 --> 0.969753).  Saving model ...
EarlyStopping counter: 1 out of 5.0
EarlyStopping counter: 2 out of 5.0
Validation loss decreased (0.969753 --> 0.968864).  Saving model ...
Validation loss decreased (0.968864 --> 0.965938).  Saving model ...
Validation loss decreased (0.965938 --> 0.965541).  Saving model ...
Validation loss decreased (0.965541 --> 0.964494).  Saving model ...
Validation loss decreased (0.964494 --> 0.962141).  Saving model ...
Validation loss decreased (0.962141 --> 0.961528).  Saving model ...
Validation loss decreased (0.961528 --> 0.961275).  Saving model ...
Validation loss decreased (0.961275 --> 0.961006).  Saving model ...
EarlyStopping counter: 1 out of 5.0
Validation loss decreased (0.961006 --> 0.960041).  Saving model ...
Validation loss decreased (0.960041 --> 0.959559).  Saving model ...
EarlyStopping counter: 1 out of 5.0
EarlyStopping counter: 2 out of 5.0
Validation loss decreased (0.959559 --> 0.958046).  Saving model ...
Validation loss decreased (0.958046 --> 0.955916).  Saving model ...
EarlyStopping counter: 1 out of 5.0
Validation loss decreased (0.955916 --> 0.954870).  Saving model ...
EarlyStopping counter: 1 out of 5.0
EarlyStopping counter: 2 out of 5.0
EarlyStopping counter: 3 out of 5.0
EarlyStopping counter: 4 out of 5.0
EarlyStopping counter: 5 out of 5.0
/localscratch/yinan.29025152.0/env/lib/python3.7/site-packages/torch/nn/functional.py:1794: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.
  warnings.warn("nn.functional.tanh is deprecated. Use torch.tanh instead.")
wandb: Waiting for W&B process to finish, PID 103709... (success).
wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: \ 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: | 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: / 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: \ 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: | 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: / 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: \ 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: | 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: / 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb:                                                                                
wandb: Run history:
wandb:     e_F1 ▁▁▃▄▄▄▅▅▆▆▆▆▆▇▇▇▇▇▇▇▇███████████████████
wandb:   e_loss █▇▇▇▆▆▆▆▅▅▅▄▄▄▄▃▃▃▃▃▂▂▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁
wandb:     t_F1 ▁▂▂▃▄▄▃▄▄▅▅▅▅▆▆▆▆▆▆▇▇▇▇▇▇▇▇▇▇▇▇███▇█████
wandb:   t_loss █▇▇▇▇▇▆▆▆▆▅▅▅▅▄▄▄▄▃▃▃▃▃▃▃▃▃▂▂▂▂▂▂▁▂▂▁▁▁▁
wandb: 
wandb: Run summary:
wandb:     e_F1 58.86424
wandb:   e_loss 0.95537
wandb:     t_F1 69.84712
wandb:   t_loss 0.75797
wandb: 
wandb: Synced 4 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Synced playful-energy-1: https://wandb.ai/yinanazhou/xl_512_bs_8_lr_1e06_es_5_lc_True_nr_False_sr_False_stem_False_lemma_True_repeat_4_fold_1/runs/a4wn4tcw
wandb: Find logs at: ./wandb/run-20220316_081027-a4wn4tcw/logs/debug.log
wandb: 

wandb: wandb version 0.12.11 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
2022-03-16 09:35:48.010674: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1
wandb: Tracking run with wandb version 0.12.5
wandb: Syncing run amber-plant-1
wandb: ⭐️ View project at https://wandb.ai/yinanazhou/xl_512_bs_8_lr_1e06_es_5_lc_True_nr_False_sr_False_stem_False_lemma_True_repeat_4_fold_2
wandb: 🚀 View run at https://wandb.ai/yinanazhou/xl_512_bs_8_lr_1e06_es_5_lc_True_nr_False_sr_False_stem_False_lemma_True_repeat_4_fold_2/runs/1r3boghq
wandb: Run data is saved locally in /project/6002780/yinan/Thesis_MER_Lyrics/lyric-emotion/wandb/run-20220316_093544-1r3boghq
wandb: Run `wandb offline` to turn off syncing.

Validation loss decreased (inf --> 1.427874).  Saving model ...
Validation loss decreased (1.427874 --> 1.412879).  Saving model ...
Validation loss decreased (1.412879 --> 1.401489).  Saving model ...
Validation loss decreased (1.401489 --> 1.392508).  Saving model ...
Validation loss decreased (1.392508 --> 1.386071).  Saving model ...
Validation loss decreased (1.386071 --> 1.380692).  Saving model ...
Validation loss decreased (1.380692 --> 1.375940).  Saving model ...
Validation loss decreased (1.375940 --> 1.371519).  Saving model ...
Validation loss decreased (1.371519 --> 1.367395).  Saving model ...
Validation loss decreased (1.367395 --> 1.363453).  Saving model ...
Validation loss decreased (1.363453 --> 1.359599).  Saving model ...
Validation loss decreased (1.359599 --> 1.355791).  Saving model ...
Validation loss decreased (1.355791 --> 1.351577).  Saving model ...
Validation loss decreased (1.351577 --> 1.347638).  Saving model ...
Validation loss decreased (1.347638 --> 1.344378).  Saving model ...
Validation loss decreased (1.344378 --> 1.340366).  Saving model ...
Validation loss decreased (1.340366 --> 1.335711).  Saving model ...
Validation loss decreased (1.335711 --> 1.331020).  Saving model ...
Validation loss decreased (1.331020 --> 1.326284).  Saving model ...
Validation loss decreased (1.326284 --> 1.321874).  Saving model ...
Validation loss decreased (1.321874 --> 1.315985).  Saving model ...
Validation loss decreased (1.315985 --> 1.310086).  Saving model ...
Validation loss decreased (1.310086 --> 1.303967).  Saving model ...
Validation loss decreased (1.303967 --> 1.297957).  Saving model ...
Validation loss decreased (1.297957 --> 1.290716).  Saving model ...
Validation loss decreased (1.290716 --> 1.283979).  Saving model ...
Validation loss decreased (1.283979 --> 1.275835).  Saving model ...
Validation loss decreased (1.275835 --> 1.269560).  Saving model ...
Validation loss decreased (1.269560 --> 1.261964).  Saving model ...
Validation loss decreased (1.261964 --> 1.253766).  Saving model ...
Validation loss decreased (1.253766 --> 1.245960).  Saving model ...
Validation loss decreased (1.245960 --> 1.238467).  Saving model ...
Validation loss decreased (1.238467 --> 1.228457).  Saving model ...
Validation loss decreased (1.228457 --> 1.219409).  Saving model ...
Validation loss decreased (1.219409 --> 1.210807).  Saving model ...
Validation loss decreased (1.210807 --> 1.203841).  Saving model ...
Validation loss decreased (1.203841 --> 1.195230).  Saving model ...
Validation loss decreased (1.195230 --> 1.186192).  Saving model ...
Validation loss decreased (1.186192 --> 1.181596).  Saving model ...
Validation loss decreased (1.181596 --> 1.172735).  Saving model ...
Validation loss decreased (1.172735 --> 1.165504).  Saving model ...
Validation loss decreased (1.165504 --> 1.157297).  Saving model ...
Validation loss decreased (1.157297 --> 1.149568).  Saving model ...
Validation loss decreased (1.149568 --> 1.141610).  Saving model ...
Validation loss decreased (1.141610 --> 1.133456).  Saving model ...
Validation loss decreased (1.133456 --> 1.126854).  Saving model ...
Validation loss decreased (1.126854 --> 1.119984).  Saving model ...
Validation loss decreased (1.119984 --> 1.115381).  Saving model ...
Validation loss decreased (1.115381 --> 1.108736).  Saving model ...
Validation loss decreased (1.108736 --> 1.103295).  Saving model ...
Validation loss decreased (1.103295 --> 1.096429).  Saving model ...
Validation loss decreased (1.096429 --> 1.091004).  Saving model ...
Validation loss decreased (1.091004 --> 1.084639).  Saving model ...
Validation loss decreased (1.084639 --> 1.079715).  Saving model ...
Validation loss decreased (1.079715 --> 1.074156).  Saving model ...
Validation loss decreased (1.074156 --> 1.068811).  Saving model ...
Validation loss decreased (1.068811 --> 1.063616).  Saving model ...
Validation loss decreased (1.063616 --> 1.059561).  Saving model ...
Validation loss decreased (1.059561 --> 1.054188).  Saving model ...
Validation loss decreased (1.054188 --> 1.051146).  Saving model ...
Validation loss decreased (1.051146 --> 1.046820).  Saving model ...
Validation loss decreased (1.046820 --> 1.042643).  Saving model ...
Validation loss decreased (1.042643 --> 1.035802).  Saving model ...
Validation loss decreased (1.035802 --> 1.030167).  Saving model ...
Validation loss decreased (1.030167 --> 1.027401).  Saving model ...
Validation loss decreased (1.027401 --> 1.023945).  Saving model ...
Validation loss decreased (1.023945 --> 1.018394).  Saving model ...
Validation loss decreased (1.018394 --> 1.016201).  Saving model ...
Validation loss decreased (1.016201 --> 1.011609).  Saving model ...
Validation loss decreased (1.011609 --> 1.009258).  Saving model ...
Validation loss decreased (1.009258 --> 1.005884).  Saving model ...
Validation loss decreased (1.005884 --> 1.001133).  Saving model ...
Validation loss decreased (1.001133 --> 0.996296).  Saving model ...
Validation loss decreased (0.996296 --> 0.995077).  Saving model ...
Validation loss decreased (0.995077 --> 0.992985).  Saving model ...
Validation loss decreased (0.992985 --> 0.987602).  Saving model ...
Validation loss decreased (0.987602 --> 0.986814).  Saving model ...
Validation loss decreased (0.986814 --> 0.983405).  Saving model ...
Validation loss decreased (0.983405 --> 0.980099).  Saving model ...
Validation loss decreased (0.980099 --> 0.975999).  Saving model ...
Validation loss decreased (0.975999 --> 0.974932).  Saving model ...
Validation loss decreased (0.974932 --> 0.971550).  Saving model ...
Validation loss decreased (0.971550 --> 0.971256).  Saving model ...
Validation loss decreased (0.971256 --> 0.967473).  Saving model ...
EarlyStopping counter: 1 out of 5.0
Validation loss decreased (0.967473 --> 0.964757).  Saving model ...
Validation loss decreased (0.964757 --> 0.962905).  Saving model ...
Validation loss decreased (0.962905 --> 0.959091).  Saving model ...
Validation loss decreased (0.959091 --> 0.958198).  Saving model ...
Validation loss decreased (0.958198 --> 0.954979).  Saving model ...
Validation loss decreased (0.954979 --> 0.950051).  Saving model ...
Validation loss decreased (0.950051 --> 0.947697).  Saving model ...
Validation loss decreased (0.947697 --> 0.947403).  Saving model ...
Validation loss decreased (0.947403 --> 0.946429).  Saving model ...
Validation loss decreased (0.946429 --> 0.944688).  Saving model ...
Validation loss decreased (0.944688 --> 0.942262).  Saving model ...
Validation loss decreased (0.942262 --> 0.940520).  Saving model ...
EarlyStopping counter: 1 out of 5.0
Validation loss decreased (0.940520 --> 0.939263).  Saving model ...
Validation loss decreased (0.939263 --> 0.936660).  Saving model ...
Validation loss decreased (0.936660 --> 0.934303).  Saving model ...
Validation loss decreased (0.934303 --> 0.934250).  Saving model ...
Validation loss decreased (0.934250 --> 0.934227).  Saving model ...
Validation loss decreased (0.934227 --> 0.931498).  Saving model ...
Validation loss decreased (0.931498 --> 0.929690).  Saving model ...
EarlyStopping counter: 1 out of 5.0
EarlyStopping counter: 2 out of 5.0
Validation loss decreased (0.929690 --> 0.928995).  Saving model ...
Validation loss decreased (0.928995 --> 0.927433).  Saving model ...
Validation loss decreased (0.927433 --> 0.925552).  Saving model ...
EarlyStopping counter: 1 out of 5.0
EarlyStopping counter: 2 out of 5.0
Validation loss decreased (0.925552 --> 0.924822).  Saving model ...
Validation loss decreased (0.924822 --> 0.923677).  Saving model ...
EarlyStopping counter: 1 out of 5.0
EarlyStopping counter: 2 out of 5.0
Validation loss decreased (0.923677 --> 0.923034).  Saving model ...
Validation loss decreased (0.923034 --> 0.922482).  Saving model ...
Validation loss decreased (0.922482 --> 0.920774).  Saving model ...
Validation loss decreased (0.920774 --> 0.920129).  Saving model ...
Validation loss decreased (0.920129 --> 0.919775).  Saving model ...
EarlyStopping counter: 1 out of 5.0
Validation loss decreased (0.919775 --> 0.918984).  Saving model ...
Validation loss decreased (0.918984 --> 0.918531).  Saving model ...
Validation loss decreased (0.918531 --> 0.917513).  Saving model ...
EarlyStopping counter: 1 out of 5.0
Validation loss decreased (0.917513 --> 0.917362).  Saving model ...
Validation loss decreased (0.917362 --> 0.916795).  Saving model ...
EarlyStopping counter: 1 out of 5.0
EarlyStopping counter: 2 out of 5.0
Validation loss decreased (0.916795 --> 0.916642).  Saving model ...
EarlyStopping counter: 1 out of 5.0
EarlyStopping counter: 2 out of 5.0
Validation loss decreased (0.916642 --> 0.915860).  Saving model ...
EarlyStopping counter: 1 out of 5.0
EarlyStopping counter: 2 out of 5.0
EarlyStopping counter: 3 out of 5.0
EarlyStopping counter: 4 out of 5.0
EarlyStopping counter: 5 out of 5.0
/localscratch/yinan.29025152.0/env/lib/python3.7/site-packages/torch/nn/functional.py:1794: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.
  warnings.warn("nn.functional.tanh is deprecated. Use torch.tanh instead.")
wandb: Waiting for W&B process to finish, PID 108278... (success).
wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: \ 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: | 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: / 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: \ 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: | 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: / 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: \ 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: | 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: / 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb:                                                                                
wandb: Run history:
wandb:     e_F1 ▁▁▃▃▃▄▅▅▆▆▇▇▇▇▇█████████████████████████
wandb:   e_loss ██▇▇▇▇▇▆▆▆▅▅▄▄▄▃▃▃▃▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:     t_F1 ▁▁▂▂▂▃▃▄▄▄▄▅▅▅▅▅▆▆▆▇▆▆▆▇▆▇▇▇▇▇▇▇▇█▇██▇▇█
wandb:   t_loss ███▇▇▇▇▇▆▆▆▆▅▅▅▅▄▄▄▄▄▄▃▃▃▃▃▃▃▂▂▂▂▁▂▂▁▁▁▁
wandb: 
wandb: Run summary:
wandb:     e_F1 61.22785
wandb:   e_loss 0.91765
wandb:     t_F1 72.38786
wandb:   t_loss 0.75864
wandb: 
wandb: Synced 4 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Synced amber-plant-1: https://wandb.ai/yinanazhou/xl_512_bs_8_lr_1e06_es_5_lc_True_nr_False_sr_False_stem_False_lemma_True_repeat_4_fold_2/runs/1r3boghq
wandb: Find logs at: ./wandb/run-20220316_093544-1r3boghq/logs/debug.log
wandb: 

wandb: wandb version 0.12.11 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
2022-03-16 11:07:01.537021: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1
wandb: Tracking run with wandb version 0.12.5
wandb: Syncing run effortless-cloud-1
wandb: ⭐️ View project at https://wandb.ai/yinanazhou/xl_512_bs_8_lr_1e06_es_5_lc_True_nr_False_sr_False_stem_False_lemma_True_repeat_5_fold_1
wandb: 🚀 View run at https://wandb.ai/yinanazhou/xl_512_bs_8_lr_1e06_es_5_lc_True_nr_False_sr_False_stem_False_lemma_True_repeat_5_fold_1/runs/l25ca7l1
wandb: Run data is saved locally in /project/6002780/yinan/Thesis_MER_Lyrics/lyric-emotion/wandb/run-20220316_110657-l25ca7l1
wandb: Run `wandb offline` to turn off syncing.

Validation loss decreased (inf --> 1.466985).  Saving model ...
Validation loss decreased (1.466985 --> 1.429854).  Saving model ...
Validation loss decreased (1.429854 --> 1.402344).  Saving model ...
Validation loss decreased (1.402344 --> 1.382953).  Saving model ...
Validation loss decreased (1.382953 --> 1.368586).  Saving model ...
Validation loss decreased (1.368586 --> 1.359371).  Saving model ...
Validation loss decreased (1.359371 --> 1.351443).  Saving model ...
Validation loss decreased (1.351443 --> 1.344809).  Saving model ...
Validation loss decreased (1.344809 --> 1.338985).  Saving model ...
Validation loss decreased (1.338985 --> 1.333152).  Saving model ...
Validation loss decreased (1.333152 --> 1.326973).  Saving model ...
Validation loss decreased (1.326973 --> 1.320634).  Saving model ...
Validation loss decreased (1.320634 --> 1.313496).  Saving model ...
Validation loss decreased (1.313496 --> 1.308192).  Saving model ...
Validation loss decreased (1.308192 --> 1.301303).  Saving model ...
Validation loss decreased (1.301303 --> 1.295207).  Saving model ...
Validation loss decreased (1.295207 --> 1.288439).  Saving model ...
Validation loss decreased (1.288439 --> 1.281948).  Saving model ...
Validation loss decreased (1.281948 --> 1.275763).  Saving model ...
Validation loss decreased (1.275763 --> 1.269062).  Saving model ...
Validation loss decreased (1.269062 --> 1.261720).  Saving model ...
Validation loss decreased (1.261720 --> 1.255107).  Saving model ...
Validation loss decreased (1.255107 --> 1.248220).  Saving model ...
Validation loss decreased (1.248220 --> 1.240154).  Saving model ...
Validation loss decreased (1.240154 --> 1.233071).  Saving model ...
Validation loss decreased (1.233071 --> 1.226112).  Saving model ...
Validation loss decreased (1.226112 --> 1.219569).  Saving model ...
Validation loss decreased (1.219569 --> 1.213023).  Saving model ...
Validation loss decreased (1.213023 --> 1.206364).  Saving model ...
Validation loss decreased (1.206364 --> 1.199868).  Saving model ...
Validation loss decreased (1.199868 --> 1.193486).  Saving model ...
Validation loss decreased (1.193486 --> 1.187068).  Saving model ...
Validation loss decreased (1.187068 --> 1.180398).  Saving model ...
Validation loss decreased (1.180398 --> 1.173680).  Saving model ...
Validation loss decreased (1.173680 --> 1.167974).  Saving model ...
Validation loss decreased (1.167974 --> 1.162122).  Saving model ...
Validation loss decreased (1.162122 --> 1.155770).  Saving model ...
Validation loss decreased (1.155770 --> 1.150286).  Saving model ...
Validation loss decreased (1.150286 --> 1.144034).  Saving model ...
Validation loss decreased (1.144034 --> 1.137852).  Saving model ...
Validation loss decreased (1.137852 --> 1.132467).  Saving model ...
Validation loss decreased (1.132467 --> 1.127520).  Saving model ...
Validation loss decreased (1.127520 --> 1.122271).  Saving model ...
Validation loss decreased (1.122271 --> 1.116385).  Saving model ...
Validation loss decreased (1.116385 --> 1.111714).  Saving model ...
Validation loss decreased (1.111714 --> 1.106914).  Saving model ...
Validation loss decreased (1.106914 --> 1.101620).  Saving model ...
Validation loss decreased (1.101620 --> 1.095795).  Saving model ...
Validation loss decreased (1.095795 --> 1.090883).  Saving model ...
Validation loss decreased (1.090883 --> 1.086714).  Saving model ...
Validation loss decreased (1.086714 --> 1.082837).  Saving model ...
Validation loss decreased (1.082837 --> 1.077692).  Saving model ...
Validation loss decreased (1.077692 --> 1.073553).  Saving model ...
Validation loss decreased (1.073553 --> 1.069306).  Saving model ...
Validation loss decreased (1.069306 --> 1.064702).  Saving model ...
Validation loss decreased (1.064702 --> 1.061572).  Saving model ...
Validation loss decreased (1.061572 --> 1.056420).  Saving model ...
Validation loss decreased (1.056420 --> 1.051562).  Saving model ...
Validation loss decreased (1.051562 --> 1.048431).  Saving model ...
Validation loss decreased (1.048431 --> 1.044924).  Saving model ...
Validation loss decreased (1.044924 --> 1.041744).  Saving model ...
Validation loss decreased (1.041744 --> 1.037140).  Saving model ...
Validation loss decreased (1.037140 --> 1.033085).  Saving model ...
Validation loss decreased (1.033085 --> 1.030118).  Saving model ...
Validation loss decreased (1.030118 --> 1.027661).  Saving model ...
Validation loss decreased (1.027661 --> 1.025789).  Saving model ...
Validation loss decreased (1.025789 --> 1.023432).  Saving model ...
Validation loss decreased (1.023432 --> 1.019968).  Saving model ...
Validation loss decreased (1.019968 --> 1.016228).  Saving model ...
Validation loss decreased (1.016228 --> 1.014495).  Saving model ...
Validation loss decreased (1.014495 --> 1.010618).  Saving model ...
Validation loss decreased (1.010618 --> 1.007162).  Saving model ...
Validation loss decreased (1.007162 --> 1.003100).  Saving model ...
Validation loss decreased (1.003100 --> 0.998505).  Saving model ...
Validation loss decreased (0.998505 --> 0.996188).  Saving model ...
Validation loss decreased (0.996188 --> 0.993968).  Saving model ...
Validation loss decreased (0.993968 --> 0.990994).  Saving model ...
Validation loss decreased (0.990994 --> 0.987119).  Saving model ...
Validation loss decreased (0.987119 --> 0.983728).  Saving model ...
Validation loss decreased (0.983728 --> 0.983270).  Saving model ...
Validation loss decreased (0.983270 --> 0.980928).  Saving model ...
Validation loss decreased (0.980928 --> 0.978541).  Saving model ...
Validation loss decreased (0.978541 --> 0.975877).  Saving model ...
Validation loss decreased (0.975877 --> 0.975002).  Saving model ...
Validation loss decreased (0.975002 --> 0.971967).  Saving model ...
Validation loss decreased (0.971967 --> 0.971545).  Saving model ...
Validation loss decreased (0.971545 --> 0.969390).  Saving model ...
Validation loss decreased (0.969390 --> 0.968328).  Saving model ...
Validation loss decreased (0.968328 --> 0.967480).  Saving model ...
Validation loss decreased (0.967480 --> 0.965936).  Saving model ...
Validation loss decreased (0.965936 --> 0.965271).  Saving model ...
Validation loss decreased (0.965271 --> 0.961320).  Saving model ...
EarlyStopping counter: 1 out of 5.0
Validation loss decreased (0.961320 --> 0.960748).  Saving model ...
Validation loss decreased (0.960748 --> 0.958516).  Saving model ...
Validation loss decreased (0.958516 --> 0.954913).  Saving model ...
Validation loss decreased (0.954913 --> 0.953252).  Saving model ...
Validation loss decreased (0.953252 --> 0.951335).  Saving model ...
Validation loss decreased (0.951335 --> 0.949864).  Saving model ...
EarlyStopping counter: 1 out of 5.0
Validation loss decreased (0.949864 --> 0.949547).  Saving model ...
Validation loss decreased (0.949547 --> 0.949426).  Saving model ...
Validation loss decreased (0.949426 --> 0.948094).  Saving model ...
Validation loss decreased (0.948094 --> 0.944559).  Saving model ...
Validation loss decreased (0.944559 --> 0.944145).  Saving model ...
Validation loss decreased (0.944145 --> 0.942703).  Saving model ...
EarlyStopping counter: 1 out of 5.0
EarlyStopping counter: 2 out of 5.0
Validation loss decreased (0.942703 --> 0.942520).  Saving model ...
Validation loss decreased (0.942520 --> 0.941887).  Saving model ...
EarlyStopping counter: 1 out of 5.0
EarlyStopping counter: 2 out of 5.0
Validation loss decreased (0.941887 --> 0.938571).  Saving model ...
EarlyStopping counter: 1 out of 5.0
EarlyStopping counter: 2 out of 5.0
EarlyStopping counter: 3 out of 5.0
EarlyStopping counter: 4 out of 5.0
Validation loss decreased (0.938571 --> 0.937857).  Saving model ...
Validation loss decreased (0.937857 --> 0.935072).  Saving model ...
EarlyStopping counter: 1 out of 5.0
EarlyStopping counter: 2 out of 5.0
EarlyStopping counter: 3 out of 5.0
Validation loss decreased (0.935072 --> 0.933731).  Saving model ...
EarlyStopping counter: 1 out of 5.0
EarlyStopping counter: 2 out of 5.0
EarlyStopping counter: 3 out of 5.0
EarlyStopping counter: 4 out of 5.0
Validation loss decreased (0.933731 --> 0.933462).  Saving model ...
EarlyStopping counter: 1 out of 5.0
EarlyStopping counter: 2 out of 5.0
EarlyStopping counter: 3 out of 5.0
EarlyStopping counter: 4 out of 5.0
EarlyStopping counter: 5 out of 5.0
/localscratch/yinan.29025152.0/env/lib/python3.7/site-packages/torch/nn/functional.py:1794: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.
  warnings.warn("nn.functional.tanh is deprecated. Use torch.tanh instead.")
wandb: Waiting for W&B process to finish, PID 113184... (success).
wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: \ 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: | 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: / 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: \ 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: | 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: / 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: \ 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: | 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: / 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb:                                                                                
wandb: Run history:
wandb:     e_F1 ▁▁▄▅▅▆▆▆▆▆▆▆▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇███████████
wandb:   e_loss █▇▇▆▆▆▆▅▅▅▄▄▄▄▃▃▃▃▂▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:     t_F1 ▁▁▃▃▃▃▄▄▄▅▅▅▅▅▆▆▆▆▆▆▆▇▆▆▇▇▇▇▇▇▇▇▇▇▇▇████
wandb:   t_loss ██▇▇▇▇▇▆▆▆▆▅▅▅▅▅▄▄▄▄▄▃▃▃▃▃▃▃▃▃▂▂▂▂▂▂▁▁▁▁
wandb: 
wandb: Run summary:
wandb:     e_F1 62.82576
wandb:   e_loss 0.93711
wandb:     t_F1 73.93936
wandb:   t_loss 0.72448
wandb: 
wandb: Synced 4 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Synced effortless-cloud-1: https://wandb.ai/yinanazhou/xl_512_bs_8_lr_1e06_es_5_lc_True_nr_False_sr_False_stem_False_lemma_True_repeat_5_fold_1/runs/l25ca7l1
wandb: Find logs at: ./wandb/run-20220316_110657-l25ca7l1/logs/debug.log
wandb: 

wandb: wandb version 0.12.11 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
2022-03-16 12:33:15.407725: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1
wandb: Tracking run with wandb version 0.12.5
wandb: Syncing run balmy-glitter-1
wandb: ⭐️ View project at https://wandb.ai/yinanazhou/xl_512_bs_8_lr_1e06_es_5_lc_True_nr_False_sr_False_stem_False_lemma_True_repeat_5_fold_2
wandb: 🚀 View run at https://wandb.ai/yinanazhou/xl_512_bs_8_lr_1e06_es_5_lc_True_nr_False_sr_False_stem_False_lemma_True_repeat_5_fold_2/runs/ppzpj9wl
wandb: Run data is saved locally in /project/6002780/yinan/Thesis_MER_Lyrics/lyric-emotion/wandb/run-20220316_123312-ppzpj9wl
wandb: Run `wandb offline` to turn off syncing.

Validation loss decreased (inf --> 1.396176).  Saving model ...
Validation loss decreased (1.396176 --> 1.383061).  Saving model ...
Validation loss decreased (1.383061 --> 1.374295).  Saving model ...
Validation loss decreased (1.374295 --> 1.368292).  Saving model ...
Validation loss decreased (1.368292 --> 1.363649).  Saving model ...
Validation loss decreased (1.363649 --> 1.359506).  Saving model ...
Validation loss decreased (1.359506 --> 1.355786).  Saving model ...
Validation loss decreased (1.355786 --> 1.352223).  Saving model ...
Validation loss decreased (1.352223 --> 1.348910).  Saving model ...
Validation loss decreased (1.348910 --> 1.345838).  Saving model ...
Validation loss decreased (1.345838 --> 1.342506).  Saving model ...
Validation loss decreased (1.342506 --> 1.339292).  Saving model ...
Validation loss decreased (1.339292 --> 1.335922).  Saving model ...
Validation loss decreased (1.335922 --> 1.332656).  Saving model ...
Validation loss decreased (1.332656 --> 1.328551).  Saving model ...
Validation loss decreased (1.328551 --> 1.324929).  Saving model ...
Validation loss decreased (1.324929 --> 1.321167).  Saving model ...
Validation loss decreased (1.321167 --> 1.316381).  Saving model ...
Validation loss decreased (1.316381 --> 1.311609).  Saving model ...
Validation loss decreased (1.311609 --> 1.306514).  Saving model ...
Validation loss decreased (1.306514 --> 1.301589).  Saving model ...
Validation loss decreased (1.301589 --> 1.295386).  Saving model ...
Validation loss decreased (1.295386 --> 1.289164).  Saving model ...
Validation loss decreased (1.289164 --> 1.282611).  Saving model ...
Validation loss decreased (1.282611 --> 1.276520).  Saving model ...
Validation loss decreased (1.276520 --> 1.270358).  Saving model ...
Validation loss decreased (1.270358 --> 1.262637).  Saving model ...
Validation loss decreased (1.262637 --> 1.256283).  Saving model ...
Validation loss decreased (1.256283 --> 1.249001).  Saving model ...
Validation loss decreased (1.249001 --> 1.242830).  Saving model ...
Validation loss decreased (1.242830 --> 1.235338).  Saving model ...
Validation loss decreased (1.235338 --> 1.227321).  Saving model ...
Validation loss decreased (1.227321 --> 1.220484).  Saving model ...
Validation loss decreased (1.220484 --> 1.214174).  Saving model ...
Validation loss decreased (1.214174 --> 1.208218).  Saving model ...
Validation loss decreased (1.208218 --> 1.201316).  Saving model ...
Validation loss decreased (1.201316 --> 1.194137).  Saving model ...
Validation loss decreased (1.194137 --> 1.187778).  Saving model ...
Validation loss decreased (1.187778 --> 1.181054).  Saving model ...
Validation loss decreased (1.181054 --> 1.175200).  Saving model ...
Validation loss decreased (1.175200 --> 1.167777).  Saving model ...
Validation loss decreased (1.167777 --> 1.159332).  Saving model ...
Validation loss decreased (1.159332 --> 1.152803).  Saving model ...
Validation loss decreased (1.152803 --> 1.145790).  Saving model ...
Validation loss decreased (1.145790 --> 1.141650).  Saving model ...
Validation loss decreased (1.141650 --> 1.136015).  Saving model ...
Validation loss decreased (1.136015 --> 1.128613).  Saving model ...
Validation loss decreased (1.128613 --> 1.123160).  Saving model ...
Validation loss decreased (1.123160 --> 1.118547).  Saving model ...
Validation loss decreased (1.118547 --> 1.112105).  Saving model ...
Validation loss decreased (1.112105 --> 1.106130).  Saving model ...
Validation loss decreased (1.106130 --> 1.102017).  Saving model ...
Validation loss decreased (1.102017 --> 1.097106).  Saving model ...
Validation loss decreased (1.097106 --> 1.090566).  Saving model ...
Validation loss decreased (1.090566 --> 1.084753).  Saving model ...
Validation loss decreased (1.084753 --> 1.076999).  Saving model ...
Validation loss decreased (1.076999 --> 1.071116).  Saving model ...
Validation loss decreased (1.071116 --> 1.066814).  Saving model ...
Validation loss decreased (1.066814 --> 1.062294).  Saving model ...
Validation loss decreased (1.062294 --> 1.057003).  Saving model ...
Validation loss decreased (1.057003 --> 1.053573).  Saving model ...
Validation loss decreased (1.053573 --> 1.048983).  Saving model ...
Validation loss decreased (1.048983 --> 1.045222).  Saving model ...
Validation loss decreased (1.045222 --> 1.041660).  Saving model ...
Validation loss decreased (1.041660 --> 1.037872).  Saving model ...
Validation loss decreased (1.037872 --> 1.033890).  Saving model ...
Validation loss decreased (1.033890 --> 1.028870).  Saving model ...
Validation loss decreased (1.028870 --> 1.026254).  Saving model ...
Validation loss decreased (1.026254 --> 1.023918).  Saving model ...
Validation loss decreased (1.023918 --> 1.022099).  Saving model ...
Validation loss decreased (1.022099 --> 1.017847).  Saving model ...
Validation loss decreased (1.017847 --> 1.014386).  Saving model ...
Validation loss decreased (1.014386 --> 1.012153).  Saving model ...
Validation loss decreased (1.012153 --> 1.009081).  Saving model ...
Validation loss decreased (1.009081 --> 1.004313).  Saving model ...
Validation loss decreased (1.004313 --> 1.002170).  Saving model ...
Validation loss decreased (1.002170 --> 0.998579).  Saving model ...
Validation loss decreased (0.998579 --> 0.995051).  Saving model ...
Validation loss decreased (0.995051 --> 0.991865).  Saving model ...
Validation loss decreased (0.991865 --> 0.989834).  Saving model ...
Validation loss decreased (0.989834 --> 0.987203).  Saving model ...
Validation loss decreased (0.987203 --> 0.985415).  Saving model ...
Validation loss decreased (0.985415 --> 0.982057).  Saving model ...
Validation loss decreased (0.982057 --> 0.980715).  Saving model ...
Validation loss decreased (0.980715 --> 0.978083).  Saving model ...
Validation loss decreased (0.978083 --> 0.975847).  Saving model ...
Validation loss decreased (0.975847 --> 0.975318).  Saving model ...
Validation loss decreased (0.975318 --> 0.973328).  Saving model ...
Validation loss decreased (0.973328 --> 0.970134).  Saving model ...
Validation loss decreased (0.970134 --> 0.967967).  Saving model ...
Validation loss decreased (0.967967 --> 0.965658).  Saving model ...
Validation loss decreased (0.965658 --> 0.965641).  Saving model ...
Validation loss decreased (0.965641 --> 0.963100).  Saving model ...
Validation loss decreased (0.963100 --> 0.961646).  Saving model ...
Validation loss decreased (0.961646 --> 0.961026).  Saving model ...
Validation loss decreased (0.961026 --> 0.958955).  Saving model ...
Validation loss decreased (0.958955 --> 0.957855).  Saving model ...
Validation loss decreased (0.957855 --> 0.956074).  Saving model ...
Validation loss decreased (0.956074 --> 0.955436).  Saving model ...
Validation loss decreased (0.955436 --> 0.955055).  Saving model ...
Validation loss decreased (0.955055 --> 0.953479).  Saving model ...
Validation loss decreased (0.953479 --> 0.950869).  Saving model ...
Validation loss decreased (0.950869 --> 0.950428).  Saving model ...
Validation loss decreased (0.950428 --> 0.949346).  Saving model ...
Validation loss decreased (0.949346 --> 0.946443).  Saving model ...
EarlyStopping counter: 1 out of 5.0
Validation loss decreased (0.946443 --> 0.945511).  Saving model ...
Validation loss decreased (0.945511 --> 0.943181).  Saving model ...
Validation loss decreased (0.943181 --> 0.942052).  Saving model ...
Validation loss decreased (0.942052 --> 0.940954).  Saving model ...
Validation loss decreased (0.940954 --> 0.940056).  Saving model ...
Validation loss decreased (0.940056 --> 0.938333).  Saving model ...
EarlyStopping counter: 1 out of 5.0
EarlyStopping counter: 2 out of 5.0
Validation loss decreased (0.938333 --> 0.937788).  Saving model ...
Validation loss decreased (0.937788 --> 0.935858).  Saving model ...
Validation loss decreased (0.935858 --> 0.934805).  Saving model ...
EarlyStopping counter: 1 out of 5.0
Validation loss decreased (0.934805 --> 0.934568).  Saving model ...
Validation loss decreased (0.934568 --> 0.932735).  Saving model ...
EarlyStopping counter: 1 out of 5.0
Validation loss decreased (0.932735 --> 0.932141).  Saving model ...
Validation loss decreased (0.932141 --> 0.930996).  Saving model ...
EarlyStopping counter: 1 out of 5.0
EarlyStopping counter: 2 out of 5.0
Validation loss decreased (0.930996 --> 0.929847).  Saving model ...
EarlyStopping counter: 1 out of 5.0
Validation loss decreased (0.929847 --> 0.929056).  Saving model ...
Validation loss decreased (0.929056 --> 0.929036).  Saving model ...
Validation loss decreased (0.929036 --> 0.928751).  Saving model ...
Validation loss decreased (0.928751 --> 0.927790).  Saving model ...
EarlyStopping counter: 1 out of 5.0
EarlyStopping counter: 2 out of 5.0
EarlyStopping counter: 3 out of 5.0
EarlyStopping counter: 4 out of 5.0
Validation loss decreased (0.927790 --> 0.927731).  Saving model ...
EarlyStopping counter: 1 out of 5.0
EarlyStopping counter: 2 out of 5.0
EarlyStopping counter: 3 out of 5.0
Validation loss decreased (0.927731 --> 0.927630).  Saving model ...
EarlyStopping counter: 1 out of 5.0
EarlyStopping counter: 2 out of 5.0
EarlyStopping counter: 3 out of 5.0
EarlyStopping counter: 4 out of 5.0
EarlyStopping counter: 5 out of 5.0
/localscratch/yinan.29025152.0/env/lib/python3.7/site-packages/torch/nn/functional.py:1794: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.
  warnings.warn("nn.functional.tanh is deprecated. Use torch.tanh instead.")
wandb: Waiting for W&B process to finish, PID 117834... (success).
wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: \ 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: | 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: / 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: \ 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: | 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: / 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: \ 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: | 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: / 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: \ 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb:                                                                                
wandb: Run history:
wandb:     e_F1 ▁▂▄▅▅▆▆▆▆▆▇▇▇▇▇▇▇▇▇▇▇▇██████████████████
wandb:   e_loss ███▇▇▇▇▆▆▅▅▅▄▄▄▃▃▃▃▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:     t_F1 ▁▂▂▃▃▄▄▅▅▅▆▆▆▆▆▆▆▆▇▇▇▇▇▇▇▇▇▇▇██▇█▇██████
wandb:   t_loss ███▇▇▇▇▆▆▆▆▅▅▅▅▄▄▄▄▃▄▃▃▃▃▂▃▂▂▂▂▂▂▂▂▂▁▁▁▁
wandb: 
wandb: Run summary:
wandb:     e_F1 63.02524
wandb:   e_loss 0.92938
wandb:     t_F1 73.37244
wandb:   t_loss 0.70474
wandb: 
wandb: Synced 4 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Synced balmy-glitter-1: https://wandb.ai/yinanazhou/xl_512_bs_8_lr_1e06_es_5_lc_True_nr_False_sr_False_stem_False_lemma_True_repeat_5_fold_2/runs/ppzpj9wl
wandb: Find logs at: ./wandb/run-20220316_123312-ppzpj9wl/logs/debug.log
wandb: 

