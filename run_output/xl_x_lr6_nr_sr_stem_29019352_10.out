Unloading StdEnv/2020

Due to MODULEPATH changes, the following have been reloaded:
  1) mii/1.1.1


The following have been reloaded with a version change:
  1) python/3.8.2 => python/3.7.4

Using base prefix '/cvmfs/soft.computecanada.ca/easybuild/software/2017/Core/python/3.7.4'
New python executable in /localscratch/yinan.29019352.0/env/bin/python
Installing setuptools, pip, wheel...
done.
Ignoring pip: markers 'python_version < "3"' don't match your environment
Looking in links: /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/nix/avx2, /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/nix/generic, /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic
Collecting pip
Installing collected packages: pip
  Found existing installation: pip 19.1.1
    Uninstalling pip-19.1.1:
      Successfully uninstalled pip-19.1.1
Successfully installed pip-21.2.3+computecanada
Looking in links: /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/nix/avx2, /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/nix/generic, /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/keras-2.8.0+computecanada-py2.py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/Keras_Preprocessing-1.1.2+computecanada-py3-none-any.whl
Requirement already satisfied: matplotlib in /cvmfs/soft.computecanada.ca/easybuild/software/2017/Core/scipy-stack/2019a/lib/python3.7/site-packages (from -r requirements.txt (line 3)) (3.0.2)
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/nltk-3.6.5+computecanada-py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/scikit_learn-0.22.1+computecanada-cp37-cp37m-linux_x86_64.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/tensorboard-2.3.0+computecanada-py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/tensorboard_plugin_wit-1.7.0+computecanada-py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/tensorflow_gpu-2.3.0+computecanada-cp37-cp37m-linux_x86_64.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/tensorflow_estimator-2.3.0+computecanada-py2.py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/tokenizers-0.5.2+computecanada-cp37-cp37m-linux_x86_64.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/nix/avx2/torch-1.4.0+computecanada-cp37-cp37m-linux_x86_64.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/torchtext-0.6.0+computecanada-py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/torchvision-0.8.2+computecanada-cp37-cp37m-linux_x86_64.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/transformers-2.5.1+computecanada-py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/urllib3-1.26.7+computecanada-py2.py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/joblib-1.1.0+computecanada-py2.py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/click-8.0.4+computecanada-py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/tqdm-4.63.0+computecanada-py2.py3-none-any.whl
ERROR: Could not find a version that satisfies the requirement regex>=2021.8.3 (from nltk) (from versions: 2018.1.10+computecanada, 2019.11.1+computecanada, 2020.11.13+computecanada)
ERROR: No matching distribution found for regex>=2021.8.3
Looking in links: /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/nix/avx2, /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/nix/generic, /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic
ERROR: Could not find a version that satisfies the requirement numpy==1.20.0+computacanada (from versions: 1.15.0+computecanada, 1.15.2+computecanada, 1.15.4+computecanada, 1.16.0+computecanada, 1.16.2+computecanada, 1.16.3+computecanada, 1.17.4+computecanada, 1.18.1+computecanada, 1.18.4+computecanada, 1.19.1+computecanada, 1.19.2+computecanada, 1.20.2+computecanada)
ERROR: No matching distribution found for numpy==1.20.0+computacanada
Looking in links: /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/nix/avx2, /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/nix/generic, /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/wandb-0.12.5+computecanada-py2.py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/promise-2.3+computecanada-py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/click-8.0.4+computecanada-py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/GitPython-3.1.24+computecanada-py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/configparser-5.0.2+computecanada-py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/sentry_sdk-1.5.0+computecanada-py2.py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/six-1.16.0+computecanada-py2.py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/pathtools-0.1.2+computecanada-py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/shortuuid-1.0.1+computecanada-py3-none-any.whl
Requirement already satisfied: requests<3,>=2.0.0 in /cvmfs/soft.computecanada.ca/easybuild/software/2017/Core/scipy-stack/2019a/lib/python3.7/site-packages (from wandb) (2.21.0)
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/subprocess32-3.5.4+computecanada-py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/PyYAML-5.3.1+computecanada-cp37-cp37m-linux_x86_64.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/yaspin-2.1.0+computecanada-py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/protobuf-3.19.4+computecanada-py2.py3-none-any.whl
Requirement already satisfied: python-dateutil>=2.6.1 in /cvmfs/soft.computecanada.ca/easybuild/software/2017/Core/scipy-stack/2019a/lib/python3.7/site-packages (from wandb) (2.7.5)
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/psutil-5.7.3+computecanada-cp37-cp37m-linux_x86_64.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/docker_pycreds-0.4.0+computecanada-py2.py3-none-any.whl
Requirement already satisfied: importlib-metadata in /cvmfs/soft.computecanada.ca/easybuild/software/2017/Core/scipy-stack/2019a/lib/python3.7/site-packages (from Click!=8.0.0,>=7.0->wandb) (0.8)
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/typing_extensions-4.0.1+computecanada-py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/gitdb-4.0.9+computecanada-py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/smmap-5.0.0+computecanada-py3-none-any.whl
Requirement already satisfied: urllib3<1.25,>=1.21.1 in /cvmfs/soft.computecanada.ca/easybuild/software/2017/Core/scipy-stack/2019a/lib/python3.7/site-packages (from requests<3,>=2.0.0->wandb) (1.24.1)
Requirement already satisfied: idna<2.9,>=2.5 in /cvmfs/soft.computecanada.ca/easybuild/software/2017/Core/scipy-stack/2019a/lib/python3.7/site-packages (from requests<3,>=2.0.0->wandb) (2.8)
Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /cvmfs/soft.computecanada.ca/easybuild/software/2017/Core/scipy-stack/2019a/lib/python3.7/site-packages (from requests<3,>=2.0.0->wandb) (3.0.4)
Requirement already satisfied: certifi>=2017.4.17 in /cvmfs/soft.computecanada.ca/easybuild/software/2017/Core/scipy-stack/2019a/lib/python3.7/site-packages (from requests<3,>=2.0.0->wandb) (2018.11.29)
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/termcolor-1.1.0+computecanada-py3-none-any.whl
Requirement already satisfied: zipp>=0.3.2 in /cvmfs/soft.computecanada.ca/easybuild/software/2017/Core/scipy-stack/2019a/lib/python3.7/site-packages (from importlib-metadata->Click!=8.0.0,>=7.0->wandb) (0.3.3)
Installing collected packages: smmap, typing-extensions, termcolor, six, gitdb, yaspin, subprocess32, shortuuid, sentry-sdk, PyYAML, psutil, protobuf, promise, pathtools, GitPython, docker-pycreds, configparser, Click, wandb
  Attempting uninstall: six
    Found existing installation: six 1.12.0
    Not uninstalling six at /cvmfs/soft.computecanada.ca/easybuild/software/2017/Core/scipy-stack/2019a/lib/python3.7/site-packages, outside environment /localscratch/yinan.29019352.0/env
    Can't uninstall 'six'. No files were found to uninstall.
Successfully installed Click-8.0.4+computecanada GitPython-3.1.24+computecanada PyYAML-5.3.1+computecanada configparser-5.0.2+computecanada docker-pycreds-0.4.0+computecanada gitdb-4.0.9+computecanada pathtools-0.1.2+computecanada promise-2.3+computecanada protobuf-3.19.4+computecanada psutil-5.7.3+computecanada sentry-sdk-1.5.0+computecanada shortuuid-1.0.1+computecanada six-1.16.0+computecanada smmap-5.0.0+computecanada subprocess32-3.5.4+computecanada termcolor-1.1.0+computecanada typing-extensions-4.0.1+computecanada wandb-0.12.5+computecanada yaspin-2.1.0+computecanada
Looking in links: /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/nix/avx2, /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/nix/generic, /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic
ERROR: Could not find a version that satisfies the requirement sagemaker (from versions: none)
ERROR: No matching distribution found for sagemaker
Looking in links: /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/nix/avx2, /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/nix/generic, /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/torch-1.9.1+computecanada-cp37-cp37m-linux_x86_64.whl
Requirement already satisfied: typing-extensions in /localscratch/yinan.29019352.0/env/lib/python3.7/site-packages (from torch) (4.0.1+computecanada)
Installing collected packages: torch
Successfully installed torch-1.9.1+computecanada
Looking in links: /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/nix/avx2, /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/nix/generic, /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/transformers-2.5.1+computecanada-py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/tqdm-4.63.0+computecanada-py2.py3-none-any.whl
Requirement already satisfied: requests in /cvmfs/soft.computecanada.ca/easybuild/software/2017/Core/scipy-stack/2019a/lib/python3.7/site-packages (from transformers==2.5.1+computecanada) (2.21.0)
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/filelock-3.4.2+computecanada-py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/sentencepiece-0.1.91+computecanada-cp37-cp37m-linux_x86_64.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/tokenizers-0.5.2+computecanada-cp37-cp37m-linux_x86_64.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/sacremoses-0.0.46+computecanada-py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/regex-2020.11.13+computecanada-cp37-cp37m-linux_x86_64.whl
Requirement already satisfied: numpy in /cvmfs/soft.computecanada.ca/easybuild/software/2017/Core/scipy-stack/2019a/lib/python3.7/site-packages (from transformers==2.5.1+computecanada) (1.16.0)
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/boto3-1.21.14+computecanada-py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/s3transfer-0.5.1+computecanada-py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/botocore-1.24.14+computecanada-py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/jmespath-0.10.0+computecanada-py2.py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/urllib3-1.26.8+computecanada-py2.py3-none-any.whl
Requirement already satisfied: python-dateutil<3.0.0,>=2.1 in /cvmfs/soft.computecanada.ca/easybuild/software/2017/Core/scipy-stack/2019a/lib/python3.7/site-packages (from botocore<1.25.0,>=1.24.14->boto3->transformers==2.5.1+computecanada) (2.7.5)
Requirement already satisfied: six>=1.5 in /localscratch/yinan.29019352.0/env/lib/python3.7/site-packages (from python-dateutil<3.0.0,>=2.1->botocore<1.25.0,>=1.24.14->boto3->transformers==2.5.1+computecanada) (1.16.0+computecanada)
Requirement already satisfied: certifi>=2017.4.17 in /cvmfs/soft.computecanada.ca/easybuild/software/2017/Core/scipy-stack/2019a/lib/python3.7/site-packages (from requests->transformers==2.5.1+computecanada) (2018.11.29)
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/requests-2.27.1+computecanada-py2.py3-none-any.whl
Requirement already satisfied: idna<4,>=2.5 in /cvmfs/soft.computecanada.ca/easybuild/software/2017/Core/scipy-stack/2019a/lib/python3.7/site-packages (from requests->transformers==2.5.1+computecanada) (2.8)
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/charset_normalizer-2.0.12+computecanada-py3-none-any.whl
Requirement already satisfied: click in /localscratch/yinan.29019352.0/env/lib/python3.7/site-packages (from sacremoses->transformers==2.5.1+computecanada) (8.0.4+computecanada)
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/joblib-1.1.0+computecanada-py2.py3-none-any.whl
Requirement already satisfied: importlib-metadata in /cvmfs/soft.computecanada.ca/easybuild/software/2017/Core/scipy-stack/2019a/lib/python3.7/site-packages (from click->sacremoses->transformers==2.5.1+computecanada) (0.8)
Requirement already satisfied: zipp>=0.3.2 in /cvmfs/soft.computecanada.ca/easybuild/software/2017/Core/scipy-stack/2019a/lib/python3.7/site-packages (from importlib-metadata->click->sacremoses->transformers==2.5.1+computecanada) (0.3.3)
Installing collected packages: urllib3, jmespath, botocore, tqdm, s3transfer, regex, joblib, charset-normalizer, tokenizers, sentencepiece, sacremoses, requests, filelock, boto3, transformers
  Attempting uninstall: urllib3
    Found existing installation: urllib3 1.24.1
    Not uninstalling urllib3 at /cvmfs/soft.computecanada.ca/easybuild/software/2017/Core/scipy-stack/2019a/lib/python3.7/site-packages, outside environment /localscratch/yinan.29019352.0/env
    Can't uninstall 'urllib3'. No files were found to uninstall.
  Attempting uninstall: requests
    Found existing installation: requests 2.21.0
    Not uninstalling requests at /cvmfs/soft.computecanada.ca/easybuild/software/2017/Core/scipy-stack/2019a/lib/python3.7/site-packages, outside environment /localscratch/yinan.29019352.0/env
    Can't uninstall 'requests'. No files were found to uninstall.
Successfully installed boto3-1.21.14+computecanada botocore-1.24.14+computecanada charset-normalizer-2.0.12+computecanada filelock-3.4.2+computecanada jmespath-0.10.0+computecanada joblib-1.1.0+computecanada regex-2020.11.13+computecanada requests-2.27.1+computecanada s3transfer-0.5.1+computecanada sacremoses-0.0.46+computecanada sentencepiece-0.1.91+computecanada tokenizers-0.5.2+computecanada tqdm-4.63.0+computecanada transformers-2.5.1+computecanada urllib3-1.26.8+computecanada
Looking in links: /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/nix/avx2, /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/nix/generic, /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/tensorflow_gpu-2.3.0+computecanada-cp37-cp37m-linux_x86_64.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/absl_py-1.0.0+computecanada-py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/nix/generic/scipy-1.4.1+computecanada-cp37-cp37m-linux_x86_64.whl
Requirement already satisfied: six>=1.12.0 in /localscratch/yinan.29019352.0/env/lib/python3.7/site-packages (from tensorflow_gpu==2.3.0+computecanada) (1.16.0+computecanada)
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/Keras_Preprocessing-1.1.2+computecanada-py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/tensorboard-2.8.0+computecanada-py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/tensorflow_estimator-2.3.0+computecanada-py2.py3-none-any.whl
Requirement already satisfied: numpy<1.19.0,>=1.16.0 in /cvmfs/soft.computecanada.ca/easybuild/software/2017/Core/scipy-stack/2019a/lib/python3.7/site-packages (from tensorflow_gpu==2.3.0+computecanada) (1.16.0)
Requirement already satisfied: protobuf>=3.9.2 in /localscratch/yinan.29019352.0/env/lib/python3.7/site-packages (from tensorflow_gpu==2.3.0+computecanada) (3.19.4+computecanada)
Requirement already satisfied: termcolor>=1.1.0 in /localscratch/yinan.29019352.0/env/lib/python3.7/site-packages (from tensorflow_gpu==2.3.0+computecanada) (1.1.0+computecanada)
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/astunparse-1.6.3+computecanada-py2.py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/opt_einsum-3.3.0+computecanada-py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/grpcio-1.38.0+computecanada-cp37-cp37m-linux_x86_64.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/wrapt-1.11.2+computecanada-cp37-cp37m-linux_x86_64.whl
Requirement already satisfied: wheel>=0.26 in /localscratch/yinan.29019352.0/env/lib/python3.7/site-packages (from tensorflow_gpu==2.3.0+computecanada) (0.33.4)
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/nix/avx2/h5py-2.10.0+computecanada-cp37-cp37m-linux_x86_64.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/gast-0.3.3+computecanada-py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/google_pasta-0.2.0+computecanada-py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/google_auth-2.3.3+computecanada-py2.py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/tensorboard_data_server-0.6.1+computecanada-py3-none-linux_x86_64.whl
Requirement already satisfied: requests<3,>=2.21.0 in /localscratch/yinan.29019352.0/env/lib/python3.7/site-packages (from tensorboard<3,>=2.3.0->tensorflow_gpu==2.3.0+computecanada) (2.27.1+computecanada)
Requirement already satisfied: setuptools>=41.0.0 in /localscratch/yinan.29019352.0/env/lib/python3.7/site-packages (from tensorboard<3,>=2.3.0->tensorflow_gpu==2.3.0+computecanada) (41.0.1)
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/google_auth_oauthlib-0.4.6+computecanada-py2.py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/tensorboard_plugin_wit-1.8.0+computecanada-py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/Werkzeug-2.0.3+computecanada-py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/Markdown-3.3.6+computecanada-py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/rsa-4.8+computecanada-py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/cachetools-4.2.4+computecanada-py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/pyasn1_modules-0.2.8+computecanada-py2.py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/requests_oauthlib-1.3.0+computecanada-py2.py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/importlib_metadata-4.10.1+computecanada-py3-none-any.whl
Requirement already satisfied: typing-extensions>=3.6.4 in /localscratch/yinan.29019352.0/env/lib/python3.7/site-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard<3,>=2.3.0->tensorflow_gpu==2.3.0+computecanada) (4.0.1+computecanada)
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/zipp-3.7.0+computecanada-py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/pyasn1-0.4.8+computecanada-py2.py3-none-any.whl
Requirement already satisfied: idna<4,>=2.5 in /cvmfs/soft.computecanada.ca/easybuild/software/2017/Core/scipy-stack/2019a/lib/python3.7/site-packages (from requests<3,>=2.21.0->tensorboard<3,>=2.3.0->tensorflow_gpu==2.3.0+computecanada) (2.8)
Requirement already satisfied: charset-normalizer~=2.0.0 in /localscratch/yinan.29019352.0/env/lib/python3.7/site-packages (from requests<3,>=2.21.0->tensorboard<3,>=2.3.0->tensorflow_gpu==2.3.0+computecanada) (2.0.12+computecanada)
Requirement already satisfied: urllib3<1.27,>=1.21.1 in /localscratch/yinan.29019352.0/env/lib/python3.7/site-packages (from requests<3,>=2.21.0->tensorboard<3,>=2.3.0->tensorflow_gpu==2.3.0+computecanada) (1.26.8+computecanada)
Requirement already satisfied: certifi>=2017.4.17 in /cvmfs/soft.computecanada.ca/easybuild/software/2017/Core/scipy-stack/2019a/lib/python3.7/site-packages (from requests<3,>=2.21.0->tensorboard<3,>=2.3.0->tensorflow_gpu==2.3.0+computecanada) (2018.11.29)
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/oauthlib-3.1.1+computecanada-py2.py3-none-any.whl
Installing collected packages: pyasn1, zipp, rsa, pyasn1-modules, oauthlib, cachetools, requests-oauthlib, importlib-metadata, google-auth, werkzeug, tensorboard-plugin-wit, tensorboard-data-server, markdown, grpcio, google-auth-oauthlib, absl-py, wrapt, tensorflow-estimator, tensorboard, scipy, opt-einsum, keras-preprocessing, h5py, google-pasta, gast, astunparse, tensorflow-gpu
  Attempting uninstall: pyasn1
    Found existing installation: pyasn1 0.4.3
    Not uninstalling pyasn1 at /cvmfs/soft.computecanada.ca/easybuild/software/2017/Core/scipy-stack/2019a/lib/python3.7/site-packages, outside environment /localscratch/yinan.29019352.0/env
    Can't uninstall 'pyasn1'. No files were found to uninstall.
  Attempting uninstall: zipp
    Found existing installation: zipp 0.3.3
    Not uninstalling zipp at /cvmfs/soft.computecanada.ca/easybuild/software/2017/Core/scipy-stack/2019a/lib/python3.7/site-packages, outside environment /localscratch/yinan.29019352.0/env
    Can't uninstall 'zipp'. No files were found to uninstall.
  Attempting uninstall: importlib-metadata
    Found existing installation: importlib-metadata 0.8
    Not uninstalling importlib-metadata at /cvmfs/soft.computecanada.ca/easybuild/software/2017/Core/scipy-stack/2019a/lib/python3.7/site-packages, outside environment /localscratch/yinan.29019352.0/env
    Can't uninstall 'importlib-metadata'. No files were found to uninstall.
  Attempting uninstall: scipy
    Found existing installation: scipy 1.2.0
    Not uninstalling scipy at /cvmfs/soft.computecanada.ca/easybuild/software/2017/Core/scipy-stack/2019a/lib/python3.7/site-packages, outside environment /localscratch/yinan.29019352.0/env
    Can't uninstall 'scipy'. No files were found to uninstall.
Successfully installed absl-py-1.0.0+computecanada astunparse-1.6.3+computecanada cachetools-4.2.4+computecanada gast-0.3.3+computecanada google-auth-2.3.3+computecanada google-auth-oauthlib-0.4.6+computecanada google-pasta-0.2.0+computecanada grpcio-1.38.0+computecanada h5py-2.10.0+computecanada importlib-metadata-4.10.1+computecanada keras-preprocessing-1.1.2+computecanada markdown-3.3.6+computecanada oauthlib-3.1.1+computecanada opt-einsum-3.3.0+computecanada pyasn1-0.4.8+computecanada pyasn1-modules-0.2.8+computecanada requests-oauthlib-1.3.0+computecanada rsa-4.8+computecanada scipy-1.4.1+computecanada tensorboard-2.8.0+computecanada tensorboard-data-server-0.6.1+computecanada tensorboard-plugin-wit-1.8.0+computecanada tensorflow-estimator-2.3.0+computecanada tensorflow-gpu-2.3.0+computecanada werkzeug-2.0.3+computecanada wrapt-1.11.2+computecanada zipp-3.7.0+computecanada
Looking in links: /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/nix/avx2, /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/nix/generic, /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/keras-2.8.0+computecanada-py2.py3-none-any.whl
Installing collected packages: Keras
Successfully installed Keras-2.8.0+computecanada
Looking in links: /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/nix/avx2, /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/nix/generic, /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/urllib3-1.26.7+computecanada-py2.py3-none-any.whl
Installing collected packages: urllib3
  Attempting uninstall: urllib3
    Found existing installation: urllib3 1.26.8+computecanada
    Uninstalling urllib3-1.26.8+computecanada:
      Successfully uninstalled urllib3-1.26.8+computecanada
Successfully installed urllib3-1.26.7+computecanada
Looking in links: /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/nix/avx2, /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/nix/generic, /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/nltk-3.7+computecanada-py3-none-any.whl
Requirement already satisfied: click in /localscratch/yinan.29019352.0/env/lib/python3.7/site-packages (from nltk) (8.0.4+computecanada)
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/nltk-3.6.5+computecanada-py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/nltk-3.6.3+computecanada-py3-none-any.whl
Requirement already satisfied: tqdm in /localscratch/yinan.29019352.0/env/lib/python3.7/site-packages (from nltk) (4.63.0+computecanada)
Requirement already satisfied: regex in /localscratch/yinan.29019352.0/env/lib/python3.7/site-packages (from nltk) (2020.11.13+computecanada)
Requirement already satisfied: joblib in /localscratch/yinan.29019352.0/env/lib/python3.7/site-packages (from nltk) (1.1.0+computecanada)
Requirement already satisfied: importlib-metadata in /localscratch/yinan.29019352.0/env/lib/python3.7/site-packages (from click->nltk) (4.10.1+computecanada)
Requirement already satisfied: typing-extensions>=3.6.4 in /localscratch/yinan.29019352.0/env/lib/python3.7/site-packages (from importlib-metadata->click->nltk) (4.0.1+computecanada)
Requirement already satisfied: zipp>=0.5 in /localscratch/yinan.29019352.0/env/lib/python3.7/site-packages (from importlib-metadata->click->nltk) (3.7.0+computecanada)
Installing collected packages: nltk
Successfully installed nltk-3.6.3+computecanada
Looking in links: /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/nix/avx2, /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/nix/generic, /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/scikit_learn-0.22.1+computecanada-cp37-cp37m-linux_x86_64.whl
Requirement already satisfied: joblib>=0.11 in /localscratch/yinan.29019352.0/env/lib/python3.7/site-packages (from scikit-learn==0.22.1) (1.1.0+computecanada)
Requirement already satisfied: scipy>=0.17.0 in /localscratch/yinan.29019352.0/env/lib/python3.7/site-packages (from scikit-learn==0.22.1) (1.4.1+computecanada)
Requirement already satisfied: numpy>=1.11.0 in /cvmfs/soft.computecanada.ca/easybuild/software/2017/Core/scipy-stack/2019a/lib/python3.7/site-packages (from scikit-learn==0.22.1) (1.16.0)
Installing collected packages: scikit-learn
Successfully installed scikit-learn-0.22.1+computecanada
Looking in links: /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/nix/avx2, /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/nix/generic, /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic
Requirement already satisfied: tokenizers==0.5.2 in /localscratch/yinan.29019352.0/env/lib/python3.7/site-packages (0.5.2+computecanada)
wandb: Appending key for api.wandb.ai to your netrc file: /home/yinan/.netrc
Starting Task
2022-03-18 19:31:19.528243: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1
[nltk_data] Downloading package stopwords to /home/yinan/nltk_data...
[nltk_data]   Package stopwords is already up-to-date!
[nltk_data] Downloading package wordnet to /home/yinan/nltk_data...
[nltk_data]   Package wordnet is already up-to-date!
wandb: Currently logged in as: yinanazhou (use `wandb login --relogin` to force relogin)
wandb: wandb version 0.12.11 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
2022-03-18 19:31:34.279582: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1
wandb: Tracking run with wandb version 0.12.5
wandb: Syncing run vague-dust-1
wandb: â­ï¸ View project at https://wandb.ai/yinanazhou/xl_512_bs_8_lr_1e06_es_10_lc_False_nr_True_sr_True_stem_True_lemma_False_repeat_1_fold_1
wandb: ðŸš€ View run at https://wandb.ai/yinanazhou/xl_512_bs_8_lr_1e06_es_10_lc_False_nr_True_sr_True_stem_True_lemma_False_repeat_1_fold_1/runs/20x7giel
wandb: Run data is saved locally in /project/6002780/yinan/Thesis_MER_Lyrics/lyric-emotion/wandb/run-20220318_193132-20x7giel
wandb: Run `wandb offline` to turn off syncing.

Validation loss decreased (inf --> 1.429061).  Saving model ...
Validation loss decreased (1.429061 --> 1.410923).  Saving model ...
Validation loss decreased (1.410923 --> 1.396220).  Saving model ...
Validation loss decreased (1.396220 --> 1.383883).  Saving model ...
Validation loss decreased (1.383883 --> 1.374713).  Saving model ...
Validation loss decreased (1.374713 --> 1.366893).  Saving model ...
Validation loss decreased (1.366893 --> 1.360546).  Saving model ...
Validation loss decreased (1.360546 --> 1.354942).  Saving model ...
Validation loss decreased (1.354942 --> 1.350245).  Saving model ...
Validation loss decreased (1.350245 --> 1.345299).  Saving model ...
Validation loss decreased (1.345299 --> 1.339772).  Saving model ...
Validation loss decreased (1.339772 --> 1.334600).  Saving model ...
Validation loss decreased (1.334600 --> 1.329052).  Saving model ...
Validation loss decreased (1.329052 --> 1.324025).  Saving model ...
Validation loss decreased (1.324025 --> 1.318539).  Saving model ...
Validation loss decreased (1.318539 --> 1.313376).  Saving model ...
Validation loss decreased (1.313376 --> 1.307915).  Saving model ...
Validation loss decreased (1.307915 --> 1.303603).  Saving model ...
Validation loss decreased (1.303603 --> 1.298103).  Saving model ...
Validation loss decreased (1.298103 --> 1.292292).  Saving model ...
Validation loss decreased (1.292292 --> 1.286369).  Saving model ...
Validation loss decreased (1.286369 --> 1.281732).  Saving model ...
Validation loss decreased (1.281732 --> 1.278885).  Saving model ...
Validation loss decreased (1.278885 --> 1.273838).  Saving model ...
Validation loss decreased (1.273838 --> 1.268387).  Saving model ...
Validation loss decreased (1.268387 --> 1.264261).  Saving model ...
Validation loss decreased (1.264261 --> 1.261322).  Saving model ...
Validation loss decreased (1.261322 --> 1.258291).  Saving model ...
Validation loss decreased (1.258291 --> 1.254029).  Saving model ...
Validation loss decreased (1.254029 --> 1.251087).  Saving model ...
Validation loss decreased (1.251087 --> 1.245624).  Saving model ...
Validation loss decreased (1.245624 --> 1.242570).  Saving model ...
Validation loss decreased (1.242570 --> 1.240108).  Saving model ...
Validation loss decreased (1.240108 --> 1.235452).  Saving model ...
Validation loss decreased (1.235452 --> 1.233233).  Saving model ...
Validation loss decreased (1.233233 --> 1.229595).  Saving model ...
Validation loss decreased (1.229595 --> 1.226534).  Saving model ...
Validation loss decreased (1.226534 --> 1.221837).  Saving model ...
Validation loss decreased (1.221837 --> 1.218539).  Saving model ...
Validation loss decreased (1.218539 --> 1.215724).  Saving model ...
Validation loss decreased (1.215724 --> 1.212595).  Saving model ...
Validation loss decreased (1.212595 --> 1.207227).  Saving model ...
Validation loss decreased (1.207227 --> 1.203041).  Saving model ...
Validation loss decreased (1.203041 --> 1.200651).  Saving model ...
Validation loss decreased (1.200651 --> 1.196784).  Saving model ...
Validation loss decreased (1.196784 --> 1.193964).  Saving model ...
Validation loss decreased (1.193964 --> 1.191866).  Saving model ...
Validation loss decreased (1.191866 --> 1.188688).  Saving model ...
Validation loss decreased (1.188688 --> 1.184022).  Saving model ...
Validation loss decreased (1.184022 --> 1.179865).  Saving model ...
Validation loss decreased (1.179865 --> 1.175976).  Saving model ...
Validation loss decreased (1.175976 --> 1.172030).  Saving model ...
Validation loss decreased (1.172030 --> 1.169250).  Saving model ...
Validation loss decreased (1.169250 --> 1.168267).  Saving model ...
Validation loss decreased (1.168267 --> 1.167782).  Saving model ...
Validation loss decreased (1.167782 --> 1.162960).  Saving model ...
Validation loss decreased (1.162960 --> 1.159201).  Saving model ...
Validation loss decreased (1.159201 --> 1.156651).  Saving model ...
Validation loss decreased (1.156651 --> 1.155339).  Saving model ...
Validation loss decreased (1.155339 --> 1.153246).  Saving model ...
Validation loss decreased (1.153246 --> 1.151432).  Saving model ...
Validation loss decreased (1.151432 --> 1.147739).  Saving model ...
Validation loss decreased (1.147739 --> 1.143710).  Saving model ...
Validation loss decreased (1.143710 --> 1.140227).  Saving model ...
Validation loss decreased (1.140227 --> 1.138478).  Saving model ...
Validation loss decreased (1.138478 --> 1.133107).  Saving model ...
Validation loss decreased (1.133107 --> 1.131906).  Saving model ...
Validation loss decreased (1.131906 --> 1.131143).  Saving model ...
Validation loss decreased (1.131143 --> 1.128610).  Saving model ...
Validation loss decreased (1.128610 --> 1.127989).  Saving model ...
Validation loss decreased (1.127989 --> 1.126004).  Saving model ...
Validation loss decreased (1.126004 --> 1.121198).  Saving model ...
Validation loss decreased (1.121198 --> 1.120449).  Saving model ...
Validation loss decreased (1.120449 --> 1.115201).  Saving model ...
Validation loss decreased (1.115201 --> 1.112670).  Saving model ...
EarlyStopping counter: 1 out of 10.0
EarlyStopping counter: 2 out of 10.0
Validation loss decreased (1.112670 --> 1.112454).  Saving model ...
Validation loss decreased (1.112454 --> 1.111873).  Saving model ...
Validation loss decreased (1.111873 --> 1.106969).  Saving model ...
EarlyStopping counter: 1 out of 10.0
EarlyStopping counter: 2 out of 10.0
EarlyStopping counter: 3 out of 10.0
Validation loss decreased (1.106969 --> 1.103559).  Saving model ...
Validation loss decreased (1.103559 --> 1.099419).  Saving model ...
Validation loss decreased (1.099419 --> 1.099383).  Saving model ...
EarlyStopping counter: 1 out of 10.0
EarlyStopping counter: 2 out of 10.0
Validation loss decreased (1.099383 --> 1.097020).  Saving model ...
EarlyStopping counter: 1 out of 10.0
EarlyStopping counter: 2 out of 10.0
Validation loss decreased (1.097020 --> 1.094156).  Saving model ...
EarlyStopping counter: 1 out of 10.0
EarlyStopping counter: 2 out of 10.0
EarlyStopping counter: 3 out of 10.0
Validation loss decreased (1.094156 --> 1.094063).  Saving model ...
Validation loss decreased (1.094063 --> 1.090555).  Saving model ...
Validation loss decreased (1.090555 --> 1.087529).  Saving model ...
EarlyStopping counter: 1 out of 10.0
EarlyStopping counter: 2 out of 10.0
EarlyStopping counter: 3 out of 10.0
EarlyStopping counter: 4 out of 10.0
Validation loss decreased (1.087529 --> 1.084960).  Saving model ...
Validation loss decreased (1.084960 --> 1.083698).  Saving model ...
Validation loss decreased (1.083698 --> 1.082476).  Saving model ...
EarlyStopping counter: 1 out of 10.0
EarlyStopping counter: 2 out of 10.0
EarlyStopping counter: 3 out of 10.0
EarlyStopping counter: 4 out of 10.0
Validation loss decreased (1.082476 --> 1.079855).  Saving model ...
EarlyStopping counter: 1 out of 10.0
Validation loss decreased (1.079855 --> 1.079202).  Saving model ...
EarlyStopping counter: 1 out of 10.0
EarlyStopping counter: 2 out of 10.0
EarlyStopping counter: 3 out of 10.0
Validation loss decreased (1.079202 --> 1.076885).  Saving model ...
Validation loss decreased (1.076885 --> 1.076844).  Saving model ...
Validation loss decreased (1.076844 --> 1.075484).  Saving model ...
EarlyStopping counter: 1 out of 10.0
EarlyStopping counter: 2 out of 10.0
Validation loss decreased (1.075484 --> 1.073581).  Saving model ...
EarlyStopping counter: 1 out of 10.0
Validation loss decreased (1.073581 --> 1.073247).  Saving model ...
EarlyStopping counter: 1 out of 10.0
Validation loss decreased (1.073247 --> 1.071363).  Saving model ...
EarlyStopping counter: 1 out of 10.0
Validation loss decreased (1.071363 --> 1.070693).  Saving model ...
EarlyStopping counter: 1 out of 10.0
EarlyStopping counter: 2 out of 10.0
EarlyStopping counter: 3 out of 10.0
EarlyStopping counter: 4 out of 10.0
EarlyStopping counter: 5 out of 10.0
EarlyStopping counter: 6 out of 10.0
EarlyStopping counter: 7 out of 10.0
EarlyStopping counter: 8 out of 10.0
EarlyStopping counter: 9 out of 10.0
EarlyStopping counter: 10 out of 10.0
/localscratch/yinan.29019352.0/env/lib/python3.7/site-packages/torch/nn/functional.py:1794: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.
  warnings.warn("nn.functional.tanh is deprecated. Use torch.tanh instead.")
/localscratch/yinan.29019352.0/env/lib/python3.7/site-packages/transformers/optimization.py:155: UserWarning: This overload of add_ is deprecated:
	add_(Number alpha, Tensor other)
Consider using one of the following signatures instead:
	add_(Tensor other, *, Number alpha) (Triggered internally at  ../torch/csrc/utils/python_arg_parser.cpp:1025.)
  exp_avg.mul_(beta1).add_(1.0 - beta1, grad)
wandb: Waiting for W&B process to finish, PID 71713... (success).
wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: \ 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: | 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: / 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: \ 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: | 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: / 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: \ 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: | 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: / 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb:                                                                                
wandb: Run history:
wandb:     e_F1 â–â–‚â–„â–„â–„â–…â–†â–…â–…â–†â–†â–†â–†â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ
wandb:   e_loss â–ˆâ–‡â–‡â–†â–†â–†â–…â–…â–…â–…â–„â–„â–„â–„â–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–â–â–â–â–â–â–â–â–â–â–â–
wandb:     t_F1 â–â–‚â–ƒâ–„â–„â–„â–„â–…â–…â–…â–…â–†â–…â–†â–†â–†â–†â–‡â–‡â–‡â–‡â–‡â–†â–‡â–‡â–ˆâ–‡â–‡â–ˆâ–‡â–ˆâ–‡â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ
wandb:   t_loss â–ˆâ–ˆâ–‡â–‡â–‡â–‡â–†â–†â–†â–†â–…â–…â–…â–…â–„â–„â–„â–„â–„â–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–‚â–ƒâ–‚â–‚â–‚â–‚â–‚â–‚â–‚â–â–‚â–â–â–â–
wandb: 
wandb: Run summary:
wandb:     e_F1 55.81882
wandb:   e_loss 1.07303
wandb:     t_F1 67.66083
wandb:   t_loss 0.7954
wandb: 
wandb: Synced 4 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Synced vague-dust-1: https://wandb.ai/yinanazhou/xl_512_bs_8_lr_1e06_es_10_lc_False_nr_True_sr_True_stem_True_lemma_False_repeat_1_fold_1/runs/20x7giel
wandb: Find logs at: ./wandb/run-20220318_193132-20x7giel/logs/debug.log
wandb: 

wandb: wandb version 0.12.11 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
2022-03-18 21:01:25.456200: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1
wandb: Tracking run with wandb version 0.12.5
wandb: Syncing run major-energy-1
wandb: â­ï¸ View project at https://wandb.ai/yinanazhou/xl_512_bs_8_lr_1e06_es_10_lc_False_nr_True_sr_True_stem_True_lemma_False_repeat_1_fold_2
wandb: ðŸš€ View run at https://wandb.ai/yinanazhou/xl_512_bs_8_lr_1e06_es_10_lc_False_nr_True_sr_True_stem_True_lemma_False_repeat_1_fold_2/runs/m53njwef
wandb: Run data is saved locally in /project/6002780/yinan/Thesis_MER_Lyrics/lyric-emotion/wandb/run-20220318_210123-m53njwef
wandb: Run `wandb offline` to turn off syncing.

Validation loss decreased (inf --> 1.404581).  Saving model ...
Validation loss decreased (1.404581 --> 1.391741).  Saving model ...
Validation loss decreased (1.391741 --> 1.382723).  Saving model ...
Validation loss decreased (1.382723 --> 1.374535).  Saving model ...
Validation loss decreased (1.374535 --> 1.367779).  Saving model ...
Validation loss decreased (1.367779 --> 1.362910).  Saving model ...
Validation loss decreased (1.362910 --> 1.357627).  Saving model ...
Validation loss decreased (1.357627 --> 1.353320).  Saving model ...
Validation loss decreased (1.353320 --> 1.348769).  Saving model ...
Validation loss decreased (1.348769 --> 1.344205).  Saving model ...
Validation loss decreased (1.344205 --> 1.340251).  Saving model ...
Validation loss decreased (1.340251 --> 1.335948).  Saving model ...
Validation loss decreased (1.335948 --> 1.331801).  Saving model ...
Validation loss decreased (1.331801 --> 1.327461).  Saving model ...
Validation loss decreased (1.327461 --> 1.323004).  Saving model ...
Validation loss decreased (1.323004 --> 1.318697).  Saving model ...
Validation loss decreased (1.318697 --> 1.314656).  Saving model ...
Validation loss decreased (1.314656 --> 1.310168).  Saving model ...
Validation loss decreased (1.310168 --> 1.305401).  Saving model ...
Validation loss decreased (1.305401 --> 1.301013).  Saving model ...
Validation loss decreased (1.301013 --> 1.295900).  Saving model ...
Validation loss decreased (1.295900 --> 1.290562).  Saving model ...
Validation loss decreased (1.290562 --> 1.285500).  Saving model ...
Validation loss decreased (1.285500 --> 1.280098).  Saving model ...
Validation loss decreased (1.280098 --> 1.274698).  Saving model ...
Validation loss decreased (1.274698 --> 1.268560).  Saving model ...
Validation loss decreased (1.268560 --> 1.263246).  Saving model ...
Validation loss decreased (1.263246 --> 1.257290).  Saving model ...
Validation loss decreased (1.257290 --> 1.251313).  Saving model ...
Validation loss decreased (1.251313 --> 1.244469).  Saving model ...
Validation loss decreased (1.244469 --> 1.237868).  Saving model ...
Validation loss decreased (1.237868 --> 1.231255).  Saving model ...
Validation loss decreased (1.231255 --> 1.224971).  Saving model ...
Validation loss decreased (1.224971 --> 1.218869).  Saving model ...
Validation loss decreased (1.218869 --> 1.211504).  Saving model ...
Validation loss decreased (1.211504 --> 1.204895).  Saving model ...
Validation loss decreased (1.204895 --> 1.198115).  Saving model ...
Validation loss decreased (1.198115 --> 1.192427).  Saving model ...
Validation loss decreased (1.192427 --> 1.186076).  Saving model ...
Validation loss decreased (1.186076 --> 1.179384).  Saving model ...
Validation loss decreased (1.179384 --> 1.172815).  Saving model ...
Validation loss decreased (1.172815 --> 1.166113).  Saving model ...
Validation loss decreased (1.166113 --> 1.159809).  Saving model ...
Validation loss decreased (1.159809 --> 1.154614).  Saving model ...
Validation loss decreased (1.154614 --> 1.149184).  Saving model ...
Validation loss decreased (1.149184 --> 1.144684).  Saving model ...
Validation loss decreased (1.144684 --> 1.139777).  Saving model ...
Validation loss decreased (1.139777 --> 1.134478).  Saving model ...
Validation loss decreased (1.134478 --> 1.130084).  Saving model ...
Validation loss decreased (1.130084 --> 1.125726).  Saving model ...
Validation loss decreased (1.125726 --> 1.121549).  Saving model ...
Validation loss decreased (1.121549 --> 1.115463).  Saving model ...
Validation loss decreased (1.115463 --> 1.109823).  Saving model ...
Validation loss decreased (1.109823 --> 1.105828).  Saving model ...
Validation loss decreased (1.105828 --> 1.102354).  Saving model ...
Validation loss decreased (1.102354 --> 1.097072).  Saving model ...
Validation loss decreased (1.097072 --> 1.091584).  Saving model ...
Validation loss decreased (1.091584 --> 1.088150).  Saving model ...
Validation loss decreased (1.088150 --> 1.083978).  Saving model ...
Validation loss decreased (1.083978 --> 1.079792).  Saving model ...
Validation loss decreased (1.079792 --> 1.075780).  Saving model ...
Validation loss decreased (1.075780 --> 1.070351).  Saving model ...
Validation loss decreased (1.070351 --> 1.066842).  Saving model ...
Validation loss decreased (1.066842 --> 1.062796).  Saving model ...
Validation loss decreased (1.062796 --> 1.058804).  Saving model ...
Validation loss decreased (1.058804 --> 1.055083).  Saving model ...
Validation loss decreased (1.055083 --> 1.050718).  Saving model ...
Validation loss decreased (1.050718 --> 1.047045).  Saving model ...
Validation loss decreased (1.047045 --> 1.044448).  Saving model ...
Validation loss decreased (1.044448 --> 1.040978).  Saving model ...
Validation loss decreased (1.040978 --> 1.036792).  Saving model ...
Validation loss decreased (1.036792 --> 1.033553).  Saving model ...
Validation loss decreased (1.033553 --> 1.031872).  Saving model ...
Validation loss decreased (1.031872 --> 1.028296).  Saving model ...
Validation loss decreased (1.028296 --> 1.026732).  Saving model ...
Validation loss decreased (1.026732 --> 1.022571).  Saving model ...
Validation loss decreased (1.022571 --> 1.019700).  Saving model ...
Validation loss decreased (1.019700 --> 1.016142).  Saving model ...
Validation loss decreased (1.016142 --> 1.014353).  Saving model ...
Validation loss decreased (1.014353 --> 1.012479).  Saving model ...
Validation loss decreased (1.012479 --> 1.011041).  Saving model ...
Validation loss decreased (1.011041 --> 1.008578).  Saving model ...
Validation loss decreased (1.008578 --> 1.006549).  Saving model ...
Validation loss decreased (1.006549 --> 1.005803).  Saving model ...
Validation loss decreased (1.005803 --> 1.004657).  Saving model ...
Validation loss decreased (1.004657 --> 1.002824).  Saving model ...
Validation loss decreased (1.002824 --> 0.998480).  Saving model ...
Validation loss decreased (0.998480 --> 0.994265).  Saving model ...
Validation loss decreased (0.994265 --> 0.991563).  Saving model ...
Validation loss decreased (0.991563 --> 0.989878).  Saving model ...
Validation loss decreased (0.989878 --> 0.988362).  Saving model ...
Validation loss decreased (0.988362 --> 0.986572).  Saving model ...
Validation loss decreased (0.986572 --> 0.984968).  Saving model ...
EarlyStopping counter: 1 out of 10.0
Validation loss decreased (0.984968 --> 0.984504).  Saving model ...
Validation loss decreased (0.984504 --> 0.983194).  Saving model ...
Validation loss decreased (0.983194 --> 0.980840).  Saving model ...
Validation loss decreased (0.980840 --> 0.978422).  Saving model ...
Validation loss decreased (0.978422 --> 0.976681).  Saving model ...
Validation loss decreased (0.976681 --> 0.975097).  Saving model ...
Validation loss decreased (0.975097 --> 0.973901).  Saving model ...
Validation loss decreased (0.973901 --> 0.973086).  Saving model ...
Validation loss decreased (0.973086 --> 0.971436).  Saving model ...
Validation loss decreased (0.971436 --> 0.970812).  Saving model ...
EarlyStopping counter: 1 out of 10.0
Validation loss decreased (0.970812 --> 0.968840).  Saving model ...
EarlyStopping counter: 1 out of 10.0
Validation loss decreased (0.968840 --> 0.967267).  Saving model ...
Validation loss decreased (0.967267 --> 0.967176).  Saving model ...
Validation loss decreased (0.967176 --> 0.965847).  Saving model ...
Validation loss decreased (0.965847 --> 0.964731).  Saving model ...
Validation loss decreased (0.964731 --> 0.964559).  Saving model ...
Validation loss decreased (0.964559 --> 0.962036).  Saving model ...
Validation loss decreased (0.962036 --> 0.960810).  Saving model ...
Validation loss decreased (0.960810 --> 0.960099).  Saving model ...
Validation loss decreased (0.960099 --> 0.958033).  Saving model ...
EarlyStopping counter: 1 out of 10.0
EarlyStopping counter: 2 out of 10.0
EarlyStopping counter: 3 out of 10.0
EarlyStopping counter: 4 out of 10.0
Validation loss decreased (0.958033 --> 0.955145).  Saving model ...
EarlyStopping counter: 1 out of 10.0
EarlyStopping counter: 2 out of 10.0
Validation loss decreased (0.955145 --> 0.955014).  Saving model ...
Validation loss decreased (0.955014 --> 0.954616).  Saving model ...
Validation loss decreased (0.954616 --> 0.953713).  Saving model ...
Validation loss decreased (0.953713 --> 0.953364).  Saving model ...
Validation loss decreased (0.953364 --> 0.951676).  Saving model ...
EarlyStopping counter: 1 out of 10.0
Validation loss decreased (0.951676 --> 0.950755).  Saving model ...
EarlyStopping counter: 1 out of 10.0
EarlyStopping counter: 2 out of 10.0
EarlyStopping counter: 3 out of 10.0
Validation loss decreased (0.950755 --> 0.950672).  Saving model ...
Validation loss decreased (0.950672 --> 0.950472).  Saving model ...
EarlyStopping counter: 1 out of 10.0
EarlyStopping counter: 2 out of 10.0
Validation loss decreased (0.950472 --> 0.949610).  Saving model ...
EarlyStopping counter: 1 out of 10.0
EarlyStopping counter: 2 out of 10.0
Validation loss decreased (0.949610 --> 0.949099).  Saving model ...
EarlyStopping counter: 1 out of 10.0
EarlyStopping counter: 2 out of 10.0
EarlyStopping counter: 3 out of 10.0
EarlyStopping counter: 4 out of 10.0
EarlyStopping counter: 5 out of 10.0
EarlyStopping counter: 6 out of 10.0
EarlyStopping counter: 7 out of 10.0
EarlyStopping counter: 8 out of 10.0
EarlyStopping counter: 9 out of 10.0
EarlyStopping counter: 10 out of 10.0
/localscratch/yinan.29019352.0/env/lib/python3.7/site-packages/torch/nn/functional.py:1794: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.
  warnings.warn("nn.functional.tanh is deprecated. Use torch.tanh instead.")
wandb: Waiting for W&B process to finish, PID 76533... (success).
wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: \ 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: | 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: / 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: \ 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: | 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: / 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: \ 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: | 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: / 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb:                                                                                
wandb: Run history:
wandb:     e_F1 â–â–‚â–„â–…â–…â–†â–†â–†â–†â–†â–†â–†â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–ˆâ–ˆâ–‡â–‡â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ
wandb:   e_loss â–ˆâ–ˆâ–‡â–‡â–‡â–‡â–†â–†â–…â–…â–…â–„â–„â–„â–ƒâ–ƒâ–ƒâ–ƒâ–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:     t_F1 â–â–â–‚â–ƒâ–„â–ƒâ–ƒâ–„â–„â–…â–…â–…â–…â–…â–†â–†â–†â–†â–†â–†â–†â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–ˆâ–‡â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‡
wandb:   t_loss â–ˆâ–ˆâ–ˆâ–‡â–‡â–‡â–‡â–‡â–†â–†â–†â–†â–†â–…â–…â–…â–„â–„â–„â–„â–„â–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–‚â–ƒâ–‚â–‚â–‚â–‚â–‚â–‚â–â–â–â–â–â–
wandb: 
wandb: Run summary:
wandb:     e_F1 59.39351
wandb:   e_loss 0.95068
wandb:     t_F1 73.83523
wandb:   t_loss 0.76578
wandb: 
wandb: Synced 4 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Synced major-energy-1: https://wandb.ai/yinanazhou/xl_512_bs_8_lr_1e06_es_10_lc_False_nr_True_sr_True_stem_True_lemma_False_repeat_1_fold_2/runs/m53njwef
wandb: Find logs at: ./wandb/run-20220318_210123-m53njwef/logs/debug.log
wandb: 

wandb: wandb version 0.12.11 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
2022-03-18 22:39:21.279350: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1
wandb: Tracking run with wandb version 0.12.5
wandb: Syncing run visionary-eon-1
wandb: â­ï¸ View project at https://wandb.ai/yinanazhou/xl_512_bs_8_lr_1e06_es_10_lc_False_nr_True_sr_True_stem_True_lemma_False_repeat_2_fold_1
wandb: ðŸš€ View run at https://wandb.ai/yinanazhou/xl_512_bs_8_lr_1e06_es_10_lc_False_nr_True_sr_True_stem_True_lemma_False_repeat_2_fold_1/runs/1di1rh4u
wandb: Run data is saved locally in /project/6002780/yinan/Thesis_MER_Lyrics/lyric-emotion/wandb/run-20220318_223918-1di1rh4u
wandb: Run `wandb offline` to turn off syncing.

Validation loss decreased (inf --> 1.441922).  Saving model ...
Validation loss decreased (1.441922 --> 1.423319).  Saving model ...
Validation loss decreased (1.423319 --> 1.409739).  Saving model ...
Validation loss decreased (1.409739 --> 1.399833).  Saving model ...
Validation loss decreased (1.399833 --> 1.392990).  Saving model ...
Validation loss decreased (1.392990 --> 1.387248).  Saving model ...
Validation loss decreased (1.387248 --> 1.382319).  Saving model ...
Validation loss decreased (1.382319 --> 1.378314).  Saving model ...
Validation loss decreased (1.378314 --> 1.374526).  Saving model ...
Validation loss decreased (1.374526 --> 1.371074).  Saving model ...
Validation loss decreased (1.371074 --> 1.367700).  Saving model ...
Validation loss decreased (1.367700 --> 1.364167).  Saving model ...
Validation loss decreased (1.364167 --> 1.360791).  Saving model ...
Validation loss decreased (1.360791 --> 1.357035).  Saving model ...
Validation loss decreased (1.357035 --> 1.353392).  Saving model ...
Validation loss decreased (1.353392 --> 1.350337).  Saving model ...
Validation loss decreased (1.350337 --> 1.346692).  Saving model ...
Validation loss decreased (1.346692 --> 1.343035).  Saving model ...
Validation loss decreased (1.343035 --> 1.339670).  Saving model ...
Validation loss decreased (1.339670 --> 1.335767).  Saving model ...
Validation loss decreased (1.335767 --> 1.331036).  Saving model ...
Validation loss decreased (1.331036 --> 1.326947).  Saving model ...
Validation loss decreased (1.326947 --> 1.322110).  Saving model ...
Validation loss decreased (1.322110 --> 1.317927).  Saving model ...
Validation loss decreased (1.317927 --> 1.312991).  Saving model ...
Validation loss decreased (1.312991 --> 1.307740).  Saving model ...
Validation loss decreased (1.307740 --> 1.301892).  Saving model ...
Validation loss decreased (1.301892 --> 1.296217).  Saving model ...
Validation loss decreased (1.296217 --> 1.290500).  Saving model ...
Validation loss decreased (1.290500 --> 1.285299).  Saving model ...
Validation loss decreased (1.285299 --> 1.279820).  Saving model ...
Validation loss decreased (1.279820 --> 1.273235).  Saving model ...
Validation loss decreased (1.273235 --> 1.267760).  Saving model ...
Validation loss decreased (1.267760 --> 1.261019).  Saving model ...
Validation loss decreased (1.261019 --> 1.253243).  Saving model ...
Validation loss decreased (1.253243 --> 1.248490).  Saving model ...
Validation loss decreased (1.248490 --> 1.242675).  Saving model ...
Validation loss decreased (1.242675 --> 1.237653).  Saving model ...
Validation loss decreased (1.237653 --> 1.231765).  Saving model ...
Validation loss decreased (1.231765 --> 1.225913).  Saving model ...
Validation loss decreased (1.225913 --> 1.220274).  Saving model ...
Validation loss decreased (1.220274 --> 1.214555).  Saving model ...
Validation loss decreased (1.214555 --> 1.208852).  Saving model ...
Validation loss decreased (1.208852 --> 1.203233).  Saving model ...
Validation loss decreased (1.203233 --> 1.196310).  Saving model ...
Validation loss decreased (1.196310 --> 1.190881).  Saving model ...
Validation loss decreased (1.190881 --> 1.184471).  Saving model ...
Validation loss decreased (1.184471 --> 1.180716).  Saving model ...
Validation loss decreased (1.180716 --> 1.176043).  Saving model ...
Validation loss decreased (1.176043 --> 1.172964).  Saving model ...
Validation loss decreased (1.172964 --> 1.168805).  Saving model ...
Validation loss decreased (1.168805 --> 1.163991).  Saving model ...
Validation loss decreased (1.163991 --> 1.159228).  Saving model ...
Validation loss decreased (1.159228 --> 1.153800).  Saving model ...
Validation loss decreased (1.153800 --> 1.149526).  Saving model ...
Validation loss decreased (1.149526 --> 1.145634).  Saving model ...
Validation loss decreased (1.145634 --> 1.138637).  Saving model ...
Validation loss decreased (1.138637 --> 1.135944).  Saving model ...
Validation loss decreased (1.135944 --> 1.130830).  Saving model ...
Validation loss decreased (1.130830 --> 1.128958).  Saving model ...
Validation loss decreased (1.128958 --> 1.125073).  Saving model ...
Validation loss decreased (1.125073 --> 1.118117).  Saving model ...
Validation loss decreased (1.118117 --> 1.113955).  Saving model ...
Validation loss decreased (1.113955 --> 1.107972).  Saving model ...
Validation loss decreased (1.107972 --> 1.104713).  Saving model ...
Validation loss decreased (1.104713 --> 1.101093).  Saving model ...
Validation loss decreased (1.101093 --> 1.097930).  Saving model ...
Validation loss decreased (1.097930 --> 1.095477).  Saving model ...
Validation loss decreased (1.095477 --> 1.094188).  Saving model ...
Validation loss decreased (1.094188 --> 1.089947).  Saving model ...
Validation loss decreased (1.089947 --> 1.085613).  Saving model ...
Validation loss decreased (1.085613 --> 1.084330).  Saving model ...
Validation loss decreased (1.084330 --> 1.083308).  Saving model ...
Validation loss decreased (1.083308 --> 1.076228).  Saving model ...
Validation loss decreased (1.076228 --> 1.073980).  Saving model ...
Validation loss decreased (1.073980 --> 1.071039).  Saving model ...
Validation loss decreased (1.071039 --> 1.068819).  Saving model ...
Validation loss decreased (1.068819 --> 1.067120).  Saving model ...
Validation loss decreased (1.067120 --> 1.065064).  Saving model ...
Validation loss decreased (1.065064 --> 1.062370).  Saving model ...
Validation loss decreased (1.062370 --> 1.060725).  Saving model ...
Validation loss decreased (1.060725 --> 1.056153).  Saving model ...
EarlyStopping counter: 1 out of 10.0
Validation loss decreased (1.056153 --> 1.052230).  Saving model ...
Validation loss decreased (1.052230 --> 1.046798).  Saving model ...
EarlyStopping counter: 1 out of 10.0
Validation loss decreased (1.046798 --> 1.043265).  Saving model ...
Validation loss decreased (1.043265 --> 1.043096).  Saving model ...
Validation loss decreased (1.043096 --> 1.041448).  Saving model ...
Validation loss decreased (1.041448 --> 1.038871).  Saving model ...
EarlyStopping counter: 1 out of 10.0
Validation loss decreased (1.038871 --> 1.034512).  Saving model ...
Validation loss decreased (1.034512 --> 1.033574).  Saving model ...
Validation loss decreased (1.033574 --> 1.033117).  Saving model ...
Validation loss decreased (1.033117 --> 1.031131).  Saving model ...
EarlyStopping counter: 1 out of 10.0
Validation loss decreased (1.031131 --> 1.028640).  Saving model ...
Validation loss decreased (1.028640 --> 1.024663).  Saving model ...
Validation loss decreased (1.024663 --> 1.021890).  Saving model ...
Validation loss decreased (1.021890 --> 1.021598).  Saving model ...
EarlyStopping counter: 1 out of 10.0
Validation loss decreased (1.021598 --> 1.020463).  Saving model ...
Validation loss decreased (1.020463 --> 1.019393).  Saving model ...
EarlyStopping counter: 1 out of 10.0
EarlyStopping counter: 2 out of 10.0
EarlyStopping counter: 3 out of 10.0
Validation loss decreased (1.019393 --> 1.017538).  Saving model ...
Validation loss decreased (1.017538 --> 1.016909).  Saving model ...
EarlyStopping counter: 1 out of 10.0
Validation loss decreased (1.016909 --> 1.014103).  Saving model ...
Validation loss decreased (1.014103 --> 1.012975).  Saving model ...
Validation loss decreased (1.012975 --> 1.009619).  Saving model ...
EarlyStopping counter: 1 out of 10.0
EarlyStopping counter: 2 out of 10.0
EarlyStopping counter: 3 out of 10.0
Validation loss decreased (1.009619 --> 1.008320).  Saving model ...
Validation loss decreased (1.008320 --> 1.006818).  Saving model ...
Validation loss decreased (1.006818 --> 1.002428).  Saving model ...
EarlyStopping counter: 1 out of 10.0
EarlyStopping counter: 2 out of 10.0
EarlyStopping counter: 3 out of 10.0
EarlyStopping counter: 4 out of 10.0
EarlyStopping counter: 5 out of 10.0
EarlyStopping counter: 6 out of 10.0
Validation loss decreased (1.002428 --> 0.999553).  Saving model ...
EarlyStopping counter: 1 out of 10.0
EarlyStopping counter: 2 out of 10.0
EarlyStopping counter: 3 out of 10.0
EarlyStopping counter: 4 out of 10.0
EarlyStopping counter: 5 out of 10.0
Validation loss decreased (0.999553 --> 0.998575).  Saving model ...
EarlyStopping counter: 1 out of 10.0
EarlyStopping counter: 2 out of 10.0
EarlyStopping counter: 3 out of 10.0
EarlyStopping counter: 4 out of 10.0
EarlyStopping counter: 5 out of 10.0
EarlyStopping counter: 6 out of 10.0
EarlyStopping counter: 7 out of 10.0
Validation loss decreased (0.998575 --> 0.998286).  Saving model ...
EarlyStopping counter: 1 out of 10.0
EarlyStopping counter: 2 out of 10.0
EarlyStopping counter: 3 out of 10.0
EarlyStopping counter: 4 out of 10.0
EarlyStopping counter: 5 out of 10.0
EarlyStopping counter: 6 out of 10.0
EarlyStopping counter: 7 out of 10.0
EarlyStopping counter: 8 out of 10.0
EarlyStopping counter: 9 out of 10.0
EarlyStopping counter: 10 out of 10.0
/localscratch/yinan.29019352.0/env/lib/python3.7/site-packages/torch/nn/functional.py:1794: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.
  warnings.warn("nn.functional.tanh is deprecated. Use torch.tanh instead.")
wandb: Waiting for W&B process to finish, PID 81777... (success).
wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: \ 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: | 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: / 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: \ 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: | 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: / 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: \ 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: | 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: / 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb:                                                                                
wandb: Run history:
wandb:     e_F1 â–â–‚â–ƒâ–„â–„â–…â–…â–…â–…â–†â–†â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–ˆâ–‡â–‡â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ
wandb:   e_loss â–ˆâ–ˆâ–‡â–‡â–‡â–‡â–†â–†â–†â–…â–…â–…â–„â–„â–„â–ƒâ–ƒâ–ƒâ–ƒâ–‚â–‚â–‚â–‚â–‚â–‚â–‚â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:     t_F1 â–â–‚â–‚â–‚â–ƒâ–ƒâ–„â–„â–„â–„â–„â–…â–…â–…â–†â–…â–†â–†â–†â–†â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–ˆâ–‡â–‡â–‡â–ˆâ–‡â–ˆâ–ˆâ–‡
wandb:   t_loss â–ˆâ–ˆâ–ˆâ–‡â–‡â–‡â–‡â–‡â–‡â–†â–†â–†â–†â–…â–…â–…â–…â–„â–„â–„â–„â–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–â–â–
wandb: 
wandb: Run summary:
wandb:     e_F1 56.45915
wandb:   e_loss 1.0013
wandb:     t_F1 73.81259
wandb:   t_loss 0.7353
wandb: 
wandb: Synced 4 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Synced visionary-eon-1: https://wandb.ai/yinanazhou/xl_512_bs_8_lr_1e06_es_10_lc_False_nr_True_sr_True_stem_True_lemma_False_repeat_2_fold_1/runs/1di1rh4u
wandb: Find logs at: ./wandb/run-20220318_223918-1di1rh4u/logs/debug.log
wandb: 

wandb: wandb version 0.12.11 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
2022-03-19 00:15:59.780537: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1
wandb: Tracking run with wandb version 0.12.5
wandb: Syncing run exalted-leaf-1
wandb: â­ï¸ View project at https://wandb.ai/yinanazhou/xl_512_bs_8_lr_1e06_es_10_lc_False_nr_True_sr_True_stem_True_lemma_False_repeat_2_fold_2
wandb: ðŸš€ View run at https://wandb.ai/yinanazhou/xl_512_bs_8_lr_1e06_es_10_lc_False_nr_True_sr_True_stem_True_lemma_False_repeat_2_fold_2/runs/jaibs8sf
wandb: Run data is saved locally in /project/6002780/yinan/Thesis_MER_Lyrics/lyric-emotion/wandb/run-20220319_001556-jaibs8sf
wandb: Run `wandb offline` to turn off syncing.

Validation loss decreased (inf --> 1.412324).  Saving model ...
Validation loss decreased (1.412324 --> 1.397429).  Saving model ...
Validation loss decreased (1.397429 --> 1.386846).  Saving model ...
Validation loss decreased (1.386846 --> 1.379311).  Saving model ...
Validation loss decreased (1.379311 --> 1.373481).  Saving model ...
Validation loss decreased (1.373481 --> 1.368979).  Saving model ...
Validation loss decreased (1.368979 --> 1.364649).  Saving model ...
Validation loss decreased (1.364649 --> 1.360592).  Saving model ...
Validation loss decreased (1.360592 --> 1.356803).  Saving model ...
Validation loss decreased (1.356803 --> 1.352759).  Saving model ...
Validation loss decreased (1.352759 --> 1.348849).  Saving model ...
Validation loss decreased (1.348849 --> 1.345224).  Saving model ...
Validation loss decreased (1.345224 --> 1.341518).  Saving model ...
Validation loss decreased (1.341518 --> 1.337830).  Saving model ...
Validation loss decreased (1.337830 --> 1.333967).  Saving model ...
Validation loss decreased (1.333967 --> 1.329712).  Saving model ...
Validation loss decreased (1.329712 --> 1.325003).  Saving model ...
Validation loss decreased (1.325003 --> 1.319916).  Saving model ...
Validation loss decreased (1.319916 --> 1.315364).  Saving model ...
Validation loss decreased (1.315364 --> 1.310398).  Saving model ...
Validation loss decreased (1.310398 --> 1.304842).  Saving model ...
Validation loss decreased (1.304842 --> 1.299658).  Saving model ...
Validation loss decreased (1.299658 --> 1.294050).  Saving model ...
Validation loss decreased (1.294050 --> 1.288820).  Saving model ...
Validation loss decreased (1.288820 --> 1.282486).  Saving model ...
Validation loss decreased (1.282486 --> 1.276114).  Saving model ...
Validation loss decreased (1.276114 --> 1.269282).  Saving model ...
Validation loss decreased (1.269282 --> 1.262760).  Saving model ...
Validation loss decreased (1.262760 --> 1.256112).  Saving model ...
Validation loss decreased (1.256112 --> 1.248493).  Saving model ...
Validation loss decreased (1.248493 --> 1.240950).  Saving model ...
Validation loss decreased (1.240950 --> 1.233863).  Saving model ...
Validation loss decreased (1.233863 --> 1.225794).  Saving model ...
Validation loss decreased (1.225794 --> 1.219086).  Saving model ...
Validation loss decreased (1.219086 --> 1.211218).  Saving model ...
Validation loss decreased (1.211218 --> 1.203700).  Saving model ...
Validation loss decreased (1.203700 --> 1.195208).  Saving model ...
Validation loss decreased (1.195208 --> 1.187143).  Saving model ...
Validation loss decreased (1.187143 --> 1.180440).  Saving model ...
Validation loss decreased (1.180440 --> 1.172985).  Saving model ...
Validation loss decreased (1.172985 --> 1.165585).  Saving model ...
Validation loss decreased (1.165585 --> 1.159164).  Saving model ...
Validation loss decreased (1.159164 --> 1.152736).  Saving model ...
Validation loss decreased (1.152736 --> 1.146861).  Saving model ...
Validation loss decreased (1.146861 --> 1.139731).  Saving model ...
Validation loss decreased (1.139731 --> 1.132697).  Saving model ...
Validation loss decreased (1.132697 --> 1.126815).  Saving model ...
Validation loss decreased (1.126815 --> 1.122245).  Saving model ...
Validation loss decreased (1.122245 --> 1.117021).  Saving model ...
Validation loss decreased (1.117021 --> 1.110825).  Saving model ...
Validation loss decreased (1.110825 --> 1.105337).  Saving model ...
Validation loss decreased (1.105337 --> 1.100525).  Saving model ...
Validation loss decreased (1.100525 --> 1.095375).  Saving model ...
Validation loss decreased (1.095375 --> 1.089358).  Saving model ...
Validation loss decreased (1.089358 --> 1.082386).  Saving model ...
Validation loss decreased (1.082386 --> 1.079479).  Saving model ...
Validation loss decreased (1.079479 --> 1.076398).  Saving model ...
Validation loss decreased (1.076398 --> 1.070911).  Saving model ...
Validation loss decreased (1.070911 --> 1.066031).  Saving model ...
Validation loss decreased (1.066031 --> 1.061307).  Saving model ...
Validation loss decreased (1.061307 --> 1.057788).  Saving model ...
Validation loss decreased (1.057788 --> 1.053978).  Saving model ...
Validation loss decreased (1.053978 --> 1.049098).  Saving model ...
Validation loss decreased (1.049098 --> 1.044808).  Saving model ...
Validation loss decreased (1.044808 --> 1.040948).  Saving model ...
Validation loss decreased (1.040948 --> 1.038688).  Saving model ...
Validation loss decreased (1.038688 --> 1.035791).  Saving model ...
Validation loss decreased (1.035791 --> 1.033267).  Saving model ...
Validation loss decreased (1.033267 --> 1.028875).  Saving model ...
Validation loss decreased (1.028875 --> 1.025938).  Saving model ...
Validation loss decreased (1.025938 --> 1.024474).  Saving model ...
Validation loss decreased (1.024474 --> 1.020608).  Saving model ...
Validation loss decreased (1.020608 --> 1.017099).  Saving model ...
Validation loss decreased (1.017099 --> 1.013902).  Saving model ...
Validation loss decreased (1.013902 --> 1.011036).  Saving model ...
Validation loss decreased (1.011036 --> 1.008483).  Saving model ...
Validation loss decreased (1.008483 --> 1.005396).  Saving model ...
Validation loss decreased (1.005396 --> 1.004464).  Saving model ...
Validation loss decreased (1.004464 --> 1.001096).  Saving model ...
Validation loss decreased (1.001096 --> 0.998901).  Saving model ...
Validation loss decreased (0.998901 --> 0.997759).  Saving model ...
Validation loss decreased (0.997759 --> 0.997179).  Saving model ...
Validation loss decreased (0.997179 --> 0.994544).  Saving model ...
Validation loss decreased (0.994544 --> 0.991552).  Saving model ...
Validation loss decreased (0.991552 --> 0.989772).  Saving model ...
Validation loss decreased (0.989772 --> 0.988284).  Saving model ...
Validation loss decreased (0.988284 --> 0.985846).  Saving model ...
Validation loss decreased (0.985846 --> 0.983384).  Saving model ...
Validation loss decreased (0.983384 --> 0.981986).  Saving model ...
Validation loss decreased (0.981986 --> 0.978930).  Saving model ...
Validation loss decreased (0.978930 --> 0.977111).  Saving model ...
Validation loss decreased (0.977111 --> 0.974765).  Saving model ...
Validation loss decreased (0.974765 --> 0.971035).  Saving model ...
Validation loss decreased (0.971035 --> 0.970271).  Saving model ...
Validation loss decreased (0.970271 --> 0.969090).  Saving model ...
Validation loss decreased (0.969090 --> 0.968443).  Saving model ...
Validation loss decreased (0.968443 --> 0.967813).  Saving model ...
EarlyStopping counter: 1 out of 10.0
Validation loss decreased (0.967813 --> 0.967170).  Saving model ...
Validation loss decreased (0.967170 --> 0.964117).  Saving model ...
EarlyStopping counter: 1 out of 10.0
Validation loss decreased (0.964117 --> 0.962651).  Saving model ...
Validation loss decreased (0.962651 --> 0.960692).  Saving model ...
Validation loss decreased (0.960692 --> 0.959478).  Saving model ...
Validation loss decreased (0.959478 --> 0.959125).  Saving model ...
Validation loss decreased (0.959125 --> 0.958383).  Saving model ...
Validation loss decreased (0.958383 --> 0.957093).  Saving model ...
EarlyStopping counter: 1 out of 10.0
Validation loss decreased (0.957093 --> 0.956184).  Saving model ...
Validation loss decreased (0.956184 --> 0.954211).  Saving model ...
Validation loss decreased (0.954211 --> 0.953998).  Saving model ...
Validation loss decreased (0.953998 --> 0.953053).  Saving model ...
EarlyStopping counter: 1 out of 10.0
Validation loss decreased (0.953053 --> 0.951429).  Saving model ...
Validation loss decreased (0.951429 --> 0.950729).  Saving model ...
Validation loss decreased (0.950729 --> 0.950603).  Saving model ...
Validation loss decreased (0.950603 --> 0.950580).  Saving model ...
Validation loss decreased (0.950580 --> 0.949464).  Saving model ...
Validation loss decreased (0.949464 --> 0.949040).  Saving model ...
Validation loss decreased (0.949040 --> 0.948612).  Saving model ...
EarlyStopping counter: 1 out of 10.0
EarlyStopping counter: 2 out of 10.0
EarlyStopping counter: 3 out of 10.0
EarlyStopping counter: 4 out of 10.0
EarlyStopping counter: 5 out of 10.0
EarlyStopping counter: 6 out of 10.0
EarlyStopping counter: 7 out of 10.0
Validation loss decreased (0.948612 --> 0.948245).  Saving model ...
Validation loss decreased (0.948245 --> 0.946458).  Saving model ...
EarlyStopping counter: 1 out of 10.0
EarlyStopping counter: 2 out of 10.0
EarlyStopping counter: 3 out of 10.0
Validation loss decreased (0.946458 --> 0.946070).  Saving model ...
EarlyStopping counter: 1 out of 10.0
Validation loss decreased (0.946070 --> 0.945749).  Saving model ...
EarlyStopping counter: 1 out of 10.0
EarlyStopping counter: 2 out of 10.0
EarlyStopping counter: 3 out of 10.0
EarlyStopping counter: 4 out of 10.0
EarlyStopping counter: 5 out of 10.0
EarlyStopping counter: 6 out of 10.0
EarlyStopping counter: 7 out of 10.0
EarlyStopping counter: 8 out of 10.0
EarlyStopping counter: 9 out of 10.0
EarlyStopping counter: 10 out of 10.0
/localscratch/yinan.29019352.0/env/lib/python3.7/site-packages/torch/nn/functional.py:1794: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.
  warnings.warn("nn.functional.tanh is deprecated. Use torch.tanh instead.")
wandb: Waiting for W&B process to finish, PID 86958... (success).
wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: \ 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: | 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: / 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: \ 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: | 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: / 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: \ 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: | 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb:                                                                                
wandb: Run history:
wandb:     e_F1 â–â–‚â–„â–„â–„â–…â–…â–†â–†â–†â–†â–‡â–†â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ
wandb:   e_loss â–ˆâ–ˆâ–‡â–‡â–‡â–‡â–†â–†â–†â–…â–…â–„â–„â–„â–ƒâ–ƒâ–ƒâ–ƒâ–‚â–‚â–‚â–‚â–‚â–‚â–‚â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:     t_F1 â–â–‚â–‚â–ƒâ–„â–„â–„â–ƒâ–„â–…â–…â–…â–…â–†â–†â–†â–‡â–†â–†â–‡â–‡â–†â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ
wandb:   t_loss â–ˆâ–ˆâ–ˆâ–‡â–‡â–‡â–‡â–‡â–†â–†â–†â–…â–…â–…â–…â–…â–„â–„â–„â–„â–„â–„â–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–‚â–‚â–‚â–‚â–‚â–‚â–‚â–â–â–â–â–
wandb: 
wandb: Run summary:
wandb:     e_F1 59.98576
wandb:   e_loss 0.94919
wandb:     t_F1 68.24945
wandb:   t_loss 0.74733
wandb: 
wandb: Synced 4 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Synced exalted-leaf-1: https://wandb.ai/yinanazhou/xl_512_bs_8_lr_1e06_es_10_lc_False_nr_True_sr_True_stem_True_lemma_False_repeat_2_fold_2/runs/jaibs8sf
wandb: Find logs at: ./wandb/run-20220319_001556-jaibs8sf/logs/debug.log
wandb: 

wandb: wandb version 0.12.11 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
2022-03-19 01:51:07.272819: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1
wandb: Tracking run with wandb version 0.12.5
wandb: Syncing run chocolate-snowball-1
wandb: â­ï¸ View project at https://wandb.ai/yinanazhou/xl_512_bs_8_lr_1e06_es_10_lc_False_nr_True_sr_True_stem_True_lemma_False_repeat_3_fold_1
wandb: ðŸš€ View run at https://wandb.ai/yinanazhou/xl_512_bs_8_lr_1e06_es_10_lc_False_nr_True_sr_True_stem_True_lemma_False_repeat_3_fold_1/runs/ulvlh4ul
wandb: Run data is saved locally in /project/6002780/yinan/Thesis_MER_Lyrics/lyric-emotion/wandb/run-20220319_015104-ulvlh4ul
wandb: Run `wandb offline` to turn off syncing.

Validation loss decreased (inf --> 1.431351).  Saving model ...
Validation loss decreased (1.431351 --> 1.403565).  Saving model ...
Validation loss decreased (1.403565 --> 1.386343).  Saving model ...
Validation loss decreased (1.386343 --> 1.373567).  Saving model ...
Validation loss decreased (1.373567 --> 1.365024).  Saving model ...
Validation loss decreased (1.365024 --> 1.358031).  Saving model ...
Validation loss decreased (1.358031 --> 1.352297).  Saving model ...
Validation loss decreased (1.352297 --> 1.347200).  Saving model ...
Validation loss decreased (1.347200 --> 1.342364).  Saving model ...
Validation loss decreased (1.342364 --> 1.338255).  Saving model ...
Validation loss decreased (1.338255 --> 1.333860).  Saving model ...
Validation loss decreased (1.333860 --> 1.329160).  Saving model ...
Validation loss decreased (1.329160 --> 1.324046).  Saving model ...
Validation loss decreased (1.324046 --> 1.319324).  Saving model ...
Validation loss decreased (1.319324 --> 1.314504).  Saving model ...
Validation loss decreased (1.314504 --> 1.309611).  Saving model ...
Validation loss decreased (1.309611 --> 1.304063).  Saving model ...
Validation loss decreased (1.304063 --> 1.298760).  Saving model ...
Validation loss decreased (1.298760 --> 1.293966).  Saving model ...
Validation loss decreased (1.293966 --> 1.288735).  Saving model ...
Validation loss decreased (1.288735 --> 1.284260).  Saving model ...
Validation loss decreased (1.284260 --> 1.280345).  Saving model ...
Validation loss decreased (1.280345 --> 1.274735).  Saving model ...
Validation loss decreased (1.274735 --> 1.268385).  Saving model ...
Validation loss decreased (1.268385 --> 1.261796).  Saving model ...
Validation loss decreased (1.261796 --> 1.256931).  Saving model ...
Validation loss decreased (1.256931 --> 1.252052).  Saving model ...
Validation loss decreased (1.252052 --> 1.247231).  Saving model ...
Validation loss decreased (1.247231 --> 1.240289).  Saving model ...
Validation loss decreased (1.240289 --> 1.235676).  Saving model ...
Validation loss decreased (1.235676 --> 1.230759).  Saving model ...
Validation loss decreased (1.230759 --> 1.225686).  Saving model ...
Validation loss decreased (1.225686 --> 1.218671).  Saving model ...
Validation loss decreased (1.218671 --> 1.215288).  Saving model ...
Validation loss decreased (1.215288 --> 1.210252).  Saving model ...
Validation loss decreased (1.210252 --> 1.204069).  Saving model ...
Validation loss decreased (1.204069 --> 1.198789).  Saving model ...
Validation loss decreased (1.198789 --> 1.194302).  Saving model ...
Validation loss decreased (1.194302 --> 1.187700).  Saving model ...
Validation loss decreased (1.187700 --> 1.180507).  Saving model ...
Validation loss decreased (1.180507 --> 1.173648).  Saving model ...
Validation loss decreased (1.173648 --> 1.168774).  Saving model ...
Validation loss decreased (1.168774 --> 1.163330).  Saving model ...
Validation loss decreased (1.163330 --> 1.159524).  Saving model ...
Validation loss decreased (1.159524 --> 1.155213).  Saving model ...
Validation loss decreased (1.155213 --> 1.150497).  Saving model ...
Validation loss decreased (1.150497 --> 1.145521).  Saving model ...
Validation loss decreased (1.145521 --> 1.140210).  Saving model ...
Validation loss decreased (1.140210 --> 1.137004).  Saving model ...
Validation loss decreased (1.137004 --> 1.133473).  Saving model ...
Validation loss decreased (1.133473 --> 1.129413).  Saving model ...
Validation loss decreased (1.129413 --> 1.124982).  Saving model ...
Validation loss decreased (1.124982 --> 1.122073).  Saving model ...
Validation loss decreased (1.122073 --> 1.114973).  Saving model ...
Validation loss decreased (1.114973 --> 1.112420).  Saving model ...
Validation loss decreased (1.112420 --> 1.112139).  Saving model ...
Validation loss decreased (1.112139 --> 1.105564).  Saving model ...
Validation loss decreased (1.105564 --> 1.098978).  Saving model ...
Validation loss decreased (1.098978 --> 1.095124).  Saving model ...
Validation loss decreased (1.095124 --> 1.093948).  Saving model ...
Validation loss decreased (1.093948 --> 1.090658).  Saving model ...
Validation loss decreased (1.090658 --> 1.084566).  Saving model ...
Validation loss decreased (1.084566 --> 1.082740).  Saving model ...
Validation loss decreased (1.082740 --> 1.081315).  Saving model ...
Validation loss decreased (1.081315 --> 1.079418).  Saving model ...
Validation loss decreased (1.079418 --> 1.074846).  Saving model ...
Validation loss decreased (1.074846 --> 1.071348).  Saving model ...
Validation loss decreased (1.071348 --> 1.067846).  Saving model ...
EarlyStopping counter: 1 out of 10.0
EarlyStopping counter: 2 out of 10.0
Validation loss decreased (1.067846 --> 1.060981).  Saving model ...
Validation loss decreased (1.060981 --> 1.058531).  Saving model ...
EarlyStopping counter: 1 out of 10.0
Validation loss decreased (1.058531 --> 1.056066).  Saving model ...
Validation loss decreased (1.056066 --> 1.054606).  Saving model ...
Validation loss decreased (1.054606 --> 1.053852).  Saving model ...
Validation loss decreased (1.053852 --> 1.051296).  Saving model ...
Validation loss decreased (1.051296 --> 1.044351).  Saving model ...
Validation loss decreased (1.044351 --> 1.042937).  Saving model ...
Validation loss decreased (1.042937 --> 1.038614).  Saving model ...
EarlyStopping counter: 1 out of 10.0
Validation loss decreased (1.038614 --> 1.036945).  Saving model ...
Validation loss decreased (1.036945 --> 1.035301).  Saving model ...
Validation loss decreased (1.035301 --> 1.034610).  Saving model ...
Validation loss decreased (1.034610 --> 1.032372).  Saving model ...
EarlyStopping counter: 1 out of 10.0
Validation loss decreased (1.032372 --> 1.031303).  Saving model ...
Validation loss decreased (1.031303 --> 1.029721).  Saving model ...
Validation loss decreased (1.029721 --> 1.027891).  Saving model ...
Validation loss decreased (1.027891 --> 1.024862).  Saving model ...
EarlyStopping counter: 1 out of 10.0
EarlyStopping counter: 2 out of 10.0
EarlyStopping counter: 3 out of 10.0
EarlyStopping counter: 4 out of 10.0
Validation loss decreased (1.024862 --> 1.021399).  Saving model ...
Validation loss decreased (1.021399 --> 1.017593).  Saving model ...
Validation loss decreased (1.017593 --> 1.017550).  Saving model ...
Validation loss decreased (1.017550 --> 1.014867).  Saving model ...
EarlyStopping counter: 1 out of 10.0
Validation loss decreased (1.014867 --> 1.014642).  Saving model ...
Validation loss decreased (1.014642 --> 1.013549).  Saving model ...
Validation loss decreased (1.013549 --> 1.013169).  Saving model ...
Validation loss decreased (1.013169 --> 1.010037).  Saving model ...
EarlyStopping counter: 1 out of 10.0
EarlyStopping counter: 2 out of 10.0
EarlyStopping counter: 3 out of 10.0
Validation loss decreased (1.010037 --> 1.009197).  Saving model ...
EarlyStopping counter: 1 out of 10.0
Validation loss decreased (1.009197 --> 1.007391).  Saving model ...
Validation loss decreased (1.007391 --> 1.007079).  Saving model ...
EarlyStopping counter: 1 out of 10.0
Validation loss decreased (1.007079 --> 1.006460).  Saving model ...
Validation loss decreased (1.006460 --> 1.005024).  Saving model ...
EarlyStopping counter: 1 out of 10.0
EarlyStopping counter: 2 out of 10.0
EarlyStopping counter: 3 out of 10.0
EarlyStopping counter: 4 out of 10.0
EarlyStopping counter: 5 out of 10.0
EarlyStopping counter: 6 out of 10.0
EarlyStopping counter: 7 out of 10.0
EarlyStopping counter: 8 out of 10.0
Validation loss decreased (1.005024 --> 1.001657).  Saving model ...
EarlyStopping counter: 1 out of 10.0
Validation loss decreased (1.001657 --> 0.997990).  Saving model ...
EarlyStopping counter: 1 out of 10.0
EarlyStopping counter: 2 out of 10.0
EarlyStopping counter: 3 out of 10.0
EarlyStopping counter: 4 out of 10.0
EarlyStopping counter: 5 out of 10.0
EarlyStopping counter: 6 out of 10.0
EarlyStopping counter: 7 out of 10.0
EarlyStopping counter: 8 out of 10.0
EarlyStopping counter: 9 out of 10.0
EarlyStopping counter: 10 out of 10.0
/localscratch/yinan.29019352.0/env/lib/python3.7/site-packages/torch/nn/functional.py:1794: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.
  warnings.warn("nn.functional.tanh is deprecated. Use torch.tanh instead.")
wandb: Waiting for W&B process to finish, PID 92094... (success).
wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: \ 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: | 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: / 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: \ 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: | 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: / 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: \ 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: | 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: / 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb:                                                                                
wandb: Run history:
wandb:     e_F1 â–â–‚â–„â–„â–„â–…â–…â–…â–†â–†â–†â–†â–‡â–‡â–‡â–‡â–‡â–‡â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ
wandb:   e_loss â–ˆâ–‡â–‡â–‡â–‡â–†â–†â–†â–…â–…â–…â–„â–„â–„â–ƒâ–ƒâ–ƒâ–ƒâ–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:     t_F1 â–â–â–ƒâ–‚â–ƒâ–ƒâ–„â–„â–„â–…â–…â–…â–…â–…â–…â–†â–†â–†â–†â–†â–†â–†â–‡â–†â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–ˆ
wandb:   t_loss â–ˆâ–ˆâ–‡â–‡â–‡â–‡â–‡â–†â–†â–†â–†â–…â–…â–…â–…â–…â–„â–„â–„â–„â–„â–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–â–â–
wandb: 
wandb: Run summary:
wandb:     e_F1 55.10037
wandb:   e_loss 1.00345
wandb:     t_F1 75.18751
wandb:   t_loss 0.72424
wandb: 
wandb: Synced 4 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Synced chocolate-snowball-1: https://wandb.ai/yinanazhou/xl_512_bs_8_lr_1e06_es_10_lc_False_nr_True_sr_True_stem_True_lemma_False_repeat_3_fold_1/runs/ulvlh4ul
wandb: Find logs at: ./wandb/run-20220319_015104-ulvlh4ul/logs/debug.log
wandb: 

wandb: wandb version 0.12.11 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
2022-03-19 03:15:54.611770: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1
wandb: Tracking run with wandb version 0.12.5
wandb: Syncing run balmy-plant-1
wandb: â­ï¸ View project at https://wandb.ai/yinanazhou/xl_512_bs_8_lr_1e06_es_10_lc_False_nr_True_sr_True_stem_True_lemma_False_repeat_3_fold_2
wandb: ðŸš€ View run at https://wandb.ai/yinanazhou/xl_512_bs_8_lr_1e06_es_10_lc_False_nr_True_sr_True_stem_True_lemma_False_repeat_3_fold_2/runs/3cm9twot
wandb: Run data is saved locally in /project/6002780/yinan/Thesis_MER_Lyrics/lyric-emotion/wandb/run-20220319_031551-3cm9twot
wandb: Run `wandb offline` to turn off syncing.

Validation loss decreased (inf --> 1.408734).  Saving model ...
Validation loss decreased (1.408734 --> 1.400469).  Saving model ...
Validation loss decreased (1.400469 --> 1.394164).  Saving model ...
Validation loss decreased (1.394164 --> 1.388408).  Saving model ...
Validation loss decreased (1.388408 --> 1.383642).  Saving model ...
Validation loss decreased (1.383642 --> 1.379296).  Saving model ...
Validation loss decreased (1.379296 --> 1.375397).  Saving model ...
Validation loss decreased (1.375397 --> 1.371607).  Saving model ...
Validation loss decreased (1.371607 --> 1.368077).  Saving model ...
Validation loss decreased (1.368077 --> 1.364390).  Saving model ...
Validation loss decreased (1.364390 --> 1.360856).  Saving model ...
Validation loss decreased (1.360856 --> 1.357013).  Saving model ...
Validation loss decreased (1.357013 --> 1.353160).  Saving model ...
Validation loss decreased (1.353160 --> 1.349104).  Saving model ...
Validation loss decreased (1.349104 --> 1.345781).  Saving model ...
Validation loss decreased (1.345781 --> 1.342179).  Saving model ...
Validation loss decreased (1.342179 --> 1.337949).  Saving model ...
Validation loss decreased (1.337949 --> 1.333977).  Saving model ...
Validation loss decreased (1.333977 --> 1.330016).  Saving model ...
Validation loss decreased (1.330016 --> 1.325991).  Saving model ...
Validation loss decreased (1.325991 --> 1.321205).  Saving model ...
Validation loss decreased (1.321205 --> 1.316541).  Saving model ...
Validation loss decreased (1.316541 --> 1.311151).  Saving model ...
Validation loss decreased (1.311151 --> 1.305406).  Saving model ...
Validation loss decreased (1.305406 --> 1.299009).  Saving model ...
Validation loss decreased (1.299009 --> 1.292948).  Saving model ...
Validation loss decreased (1.292948 --> 1.286630).  Saving model ...
Validation loss decreased (1.286630 --> 1.280303).  Saving model ...
Validation loss decreased (1.280303 --> 1.273907).  Saving model ...
Validation loss decreased (1.273907 --> 1.267104).  Saving model ...
Validation loss decreased (1.267104 --> 1.259423).  Saving model ...
Validation loss decreased (1.259423 --> 1.252551).  Saving model ...
Validation loss decreased (1.252551 --> 1.244475).  Saving model ...
Validation loss decreased (1.244475 --> 1.237803).  Saving model ...
Validation loss decreased (1.237803 --> 1.230719).  Saving model ...
Validation loss decreased (1.230719 --> 1.222288).  Saving model ...
Validation loss decreased (1.222288 --> 1.214975).  Saving model ...
Validation loss decreased (1.214975 --> 1.209381).  Saving model ...
Validation loss decreased (1.209381 --> 1.204044).  Saving model ...
Validation loss decreased (1.204044 --> 1.198072).  Saving model ...
Validation loss decreased (1.198072 --> 1.191596).  Saving model ...
Validation loss decreased (1.191596 --> 1.185242).  Saving model ...
Validation loss decreased (1.185242 --> 1.179726).  Saving model ...
Validation loss decreased (1.179726 --> 1.176379).  Saving model ...
Validation loss decreased (1.176379 --> 1.171663).  Saving model ...
Validation loss decreased (1.171663 --> 1.165833).  Saving model ...
Validation loss decreased (1.165833 --> 1.160088).  Saving model ...
Validation loss decreased (1.160088 --> 1.154681).  Saving model ...
Validation loss decreased (1.154681 --> 1.150027).  Saving model ...
Validation loss decreased (1.150027 --> 1.144737).  Saving model ...
Validation loss decreased (1.144737 --> 1.140801).  Saving model ...
Validation loss decreased (1.140801 --> 1.135421).  Saving model ...
Validation loss decreased (1.135421 --> 1.129524).  Saving model ...
Validation loss decreased (1.129524 --> 1.123655).  Saving model ...
Validation loss decreased (1.123655 --> 1.120293).  Saving model ...
Validation loss decreased (1.120293 --> 1.115811).  Saving model ...
Validation loss decreased (1.115811 --> 1.110731).  Saving model ...
Validation loss decreased (1.110731 --> 1.106783).  Saving model ...
Validation loss decreased (1.106783 --> 1.103008).  Saving model ...
Validation loss decreased (1.103008 --> 1.097861).  Saving model ...
Validation loss decreased (1.097861 --> 1.093137).  Saving model ...
Validation loss decreased (1.093137 --> 1.089186).  Saving model ...
Validation loss decreased (1.089186 --> 1.086480).  Saving model ...
Validation loss decreased (1.086480 --> 1.082766).  Saving model ...
Validation loss decreased (1.082766 --> 1.079848).  Saving model ...
Validation loss decreased (1.079848 --> 1.076179).  Saving model ...
Validation loss decreased (1.076179 --> 1.072973).  Saving model ...
Validation loss decreased (1.072973 --> 1.068124).  Saving model ...
Validation loss decreased (1.068124 --> 1.064221).  Saving model ...
Validation loss decreased (1.064221 --> 1.061108).  Saving model ...
Validation loss decreased (1.061108 --> 1.058544).  Saving model ...
Validation loss decreased (1.058544 --> 1.056000).  Saving model ...
Validation loss decreased (1.056000 --> 1.051869).  Saving model ...
Validation loss decreased (1.051869 --> 1.048532).  Saving model ...
Validation loss decreased (1.048532 --> 1.045805).  Saving model ...
Validation loss decreased (1.045805 --> 1.043162).  Saving model ...
Validation loss decreased (1.043162 --> 1.040019).  Saving model ...
Validation loss decreased (1.040019 --> 1.036863).  Saving model ...
Validation loss decreased (1.036863 --> 1.034491).  Saving model ...
Validation loss decreased (1.034491 --> 1.032978).  Saving model ...
Validation loss decreased (1.032978 --> 1.030372).  Saving model ...
Validation loss decreased (1.030372 --> 1.027435).  Saving model ...
Validation loss decreased (1.027435 --> 1.023503).  Saving model ...
Validation loss decreased (1.023503 --> 1.020367).  Saving model ...
Validation loss decreased (1.020367 --> 1.018232).  Saving model ...
Validation loss decreased (1.018232 --> 1.014715).  Saving model ...
Validation loss decreased (1.014715 --> 1.012760).  Saving model ...
Validation loss decreased (1.012760 --> 1.009695).  Saving model ...
Validation loss decreased (1.009695 --> 1.006764).  Saving model ...
Validation loss decreased (1.006764 --> 1.003842).  Saving model ...
Validation loss decreased (1.003842 --> 1.002568).  Saving model ...
Validation loss decreased (1.002568 --> 1.000864).  Saving model ...
Validation loss decreased (1.000864 --> 0.998786).  Saving model ...
Validation loss decreased (0.998786 --> 0.996532).  Saving model ...
Validation loss decreased (0.996532 --> 0.994482).  Saving model ...
Validation loss decreased (0.994482 --> 0.992684).  Saving model ...
Validation loss decreased (0.992684 --> 0.991126).  Saving model ...
Validation loss decreased (0.991126 --> 0.989757).  Saving model ...
Validation loss decreased (0.989757 --> 0.989602).  Saving model ...
Validation loss decreased (0.989602 --> 0.987475).  Saving model ...
Validation loss decreased (0.987475 --> 0.985382).  Saving model ...
Validation loss decreased (0.985382 --> 0.984853).  Saving model ...
Validation loss decreased (0.984853 --> 0.982477).  Saving model ...
Validation loss decreased (0.982477 --> 0.980100).  Saving model ...
Validation loss decreased (0.980100 --> 0.978898).  Saving model ...
Validation loss decreased (0.978898 --> 0.978083).  Saving model ...
Validation loss decreased (0.978083 --> 0.975156).  Saving model ...
Validation loss decreased (0.975156 --> 0.973731).  Saving model ...
Validation loss decreased (0.973731 --> 0.972468).  Saving model ...
EarlyStopping counter: 1 out of 10.0
Validation loss decreased (0.972468 --> 0.969781).  Saving model ...
Validation loss decreased (0.969781 --> 0.969241).  Saving model ...
Validation loss decreased (0.969241 --> 0.967008).  Saving model ...
Validation loss decreased (0.967008 --> 0.966629).  Saving model ...
Validation loss decreased (0.966629 --> 0.965806).  Saving model ...
Validation loss decreased (0.965806 --> 0.964165).  Saving model ...
EarlyStopping counter: 1 out of 10.0
Validation loss decreased (0.964165 --> 0.962153).  Saving model ...
Validation loss decreased (0.962153 --> 0.961547).  Saving model ...
Validation loss decreased (0.961547 --> 0.961078).  Saving model ...
Validation loss decreased (0.961078 --> 0.959363).  Saving model ...
Validation loss decreased (0.959363 --> 0.957934).  Saving model ...
EarlyStopping counter: 1 out of 10.0
Validation loss decreased (0.957934 --> 0.957599).  Saving model ...
Validation loss decreased (0.957599 --> 0.957409).  Saving model ...
Validation loss decreased (0.957409 --> 0.956560).  Saving model ...
Validation loss decreased (0.956560 --> 0.956111).  Saving model ...
Validation loss decreased (0.956111 --> 0.954998).  Saving model ...
Validation loss decreased (0.954998 --> 0.954323).  Saving model ...
Validation loss decreased (0.954323 --> 0.954164).  Saving model ...
Validation loss decreased (0.954164 --> 0.953877).  Saving model ...
Validation loss decreased (0.953877 --> 0.953084).  Saving model ...
Validation loss decreased (0.953084 --> 0.952795).  Saving model ...
EarlyStopping counter: 1 out of 10.0
EarlyStopping counter: 2 out of 10.0
EarlyStopping counter: 3 out of 10.0
EarlyStopping counter: 4 out of 10.0
Validation loss decreased (0.952795 --> 0.952440).  Saving model ...
Validation loss decreased (0.952440 --> 0.951432).  Saving model ...
EarlyStopping counter: 1 out of 10.0
Validation loss decreased (0.951432 --> 0.950944).  Saving model ...
Validation loss decreased (0.950944 --> 0.950340).  Saving model ...
Validation loss decreased (0.950340 --> 0.949477).  Saving model ...
Validation loss decreased (0.949477 --> 0.949017).  Saving model ...
Validation loss decreased (0.949017 --> 0.948700).  Saving model ...
EarlyStopping counter: 1 out of 10.0
EarlyStopping counter: 2 out of 10.0
Validation loss decreased (0.948700 --> 0.948186).  Saving model ...
Validation loss decreased (0.948186 --> 0.947750).  Saving model ...
EarlyStopping counter: 1 out of 10.0
EarlyStopping counter: 2 out of 10.0
Validation loss decreased (0.947750 --> 0.947230).  Saving model ...
Validation loss decreased (0.947230 --> 0.946862).  Saving model ...
Validation loss decreased (0.946862 --> 0.946427).  Saving model ...
EarlyStopping counter: 1 out of 10.0
EarlyStopping counter: 2 out of 10.0
EarlyStopping counter: 3 out of 10.0
EarlyStopping counter: 4 out of 10.0
EarlyStopping counter: 5 out of 10.0
EarlyStopping counter: 6 out of 10.0
EarlyStopping counter: 7 out of 10.0
EarlyStopping counter: 8 out of 10.0
EarlyStopping counter: 9 out of 10.0
EarlyStopping counter: 10 out of 10.0
/localscratch/yinan.29019352.0/env/lib/python3.7/site-packages/torch/nn/functional.py:1794: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.
  warnings.warn("nn.functional.tanh is deprecated. Use torch.tanh instead.")
wandb: Waiting for W&B process to finish, PID 96635... (success).
wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: \ 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: | 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: / 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: \ 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: | 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: / 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: \ 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: | 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: / 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb:                                                                                
wandb: Run history:
wandb:     e_F1 â–â–ƒâ–ƒâ–„â–„â–…â–…â–†â–†â–†â–†â–†â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ
wandb:   e_loss â–ˆâ–ˆâ–‡â–‡â–‡â–‡â–†â–†â–…â–…â–…â–„â–„â–„â–ƒâ–ƒâ–ƒâ–ƒâ–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:     t_F1 â–â–‚â–ƒâ–ƒâ–ƒâ–ƒâ–„â–„â–„â–„â–…â–…â–…â–…â–†â–†â–†â–†â–†â–†â–†â–†â–†â–‡â–‡â–‡â–‡â–‡â–‡â–ˆâ–‡â–‡â–ˆâ–‡â–‡â–ˆâ–‡â–ˆâ–ˆâ–ˆ
wandb:   t_loss â–ˆâ–ˆâ–‡â–‡â–‡â–‡â–‡â–‡â–†â–†â–†â–…â–…â–…â–…â–„â–„â–„â–„â–„â–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–â–â–â–â–
wandb: 
wandb: Run summary:
wandb:     e_F1 60.26566
wandb:   e_loss 0.94863
wandb:     t_F1 71.77287
wandb:   t_loss 0.73367
wandb: 
wandb: Synced 4 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Synced balmy-plant-1: https://wandb.ai/yinanazhou/xl_512_bs_8_lr_1e06_es_10_lc_False_nr_True_sr_True_stem_True_lemma_False_repeat_3_fold_2/runs/3cm9twot
wandb: Find logs at: ./wandb/run-20220319_031551-3cm9twot/logs/debug.log
wandb: 

wandb: wandb version 0.12.11 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
2022-03-19 04:59:55.863443: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1
wandb: Tracking run with wandb version 0.12.5
wandb: Syncing run daily-river-1
wandb: â­ï¸ View project at https://wandb.ai/yinanazhou/xl_512_bs_8_lr_1e06_es_10_lc_False_nr_True_sr_True_stem_True_lemma_False_repeat_4_fold_1
wandb: ðŸš€ View run at https://wandb.ai/yinanazhou/xl_512_bs_8_lr_1e06_es_10_lc_False_nr_True_sr_True_stem_True_lemma_False_repeat_4_fold_1/runs/fszt1phg
wandb: Run data is saved locally in /project/6002780/yinan/Thesis_MER_Lyrics/lyric-emotion/wandb/run-20220319_045952-fszt1phg
wandb: Run `wandb offline` to turn off syncing.

Validation loss decreased (inf --> 1.385180).  Saving model ...
Validation loss decreased (1.385180 --> 1.378489).  Saving model ...
Validation loss decreased (1.378489 --> 1.373324).  Saving model ...
Validation loss decreased (1.373324 --> 1.368755).  Saving model ...
Validation loss decreased (1.368755 --> 1.365013).  Saving model ...
Validation loss decreased (1.365013 --> 1.361505).  Saving model ...
Validation loss decreased (1.361505 --> 1.358130).  Saving model ...
Validation loss decreased (1.358130 --> 1.355028).  Saving model ...
Validation loss decreased (1.355028 --> 1.351975).  Saving model ...
Validation loss decreased (1.351975 --> 1.348285).  Saving model ...
Validation loss decreased (1.348285 --> 1.344675).  Saving model ...
Validation loss decreased (1.344675 --> 1.341096).  Saving model ...
Validation loss decreased (1.341096 --> 1.337454).  Saving model ...
Validation loss decreased (1.337454 --> 1.333682).  Saving model ...
Validation loss decreased (1.333682 --> 1.329693).  Saving model ...
Validation loss decreased (1.329693 --> 1.325528).  Saving model ...
Validation loss decreased (1.325528 --> 1.321247).  Saving model ...
Validation loss decreased (1.321247 --> 1.316840).  Saving model ...
Validation loss decreased (1.316840 --> 1.312490).  Saving model ...
Validation loss decreased (1.312490 --> 1.307649).  Saving model ...
Validation loss decreased (1.307649 --> 1.302605).  Saving model ...
Validation loss decreased (1.302605 --> 1.298242).  Saving model ...
Validation loss decreased (1.298242 --> 1.292587).  Saving model ...
Validation loss decreased (1.292587 --> 1.287063).  Saving model ...
Validation loss decreased (1.287063 --> 1.281515).  Saving model ...
Validation loss decreased (1.281515 --> 1.276278).  Saving model ...
Validation loss decreased (1.276278 --> 1.269589).  Saving model ...
Validation loss decreased (1.269589 --> 1.263384).  Saving model ...
Validation loss decreased (1.263384 --> 1.256970).  Saving model ...
Validation loss decreased (1.256970 --> 1.250367).  Saving model ...
Validation loss decreased (1.250367 --> 1.243834).  Saving model ...
Validation loss decreased (1.243834 --> 1.236942).  Saving model ...
Validation loss decreased (1.236942 --> 1.230208).  Saving model ...
Validation loss decreased (1.230208 --> 1.222496).  Saving model ...
Validation loss decreased (1.222496 --> 1.216549).  Saving model ...
Validation loss decreased (1.216549 --> 1.209745).  Saving model ...
Validation loss decreased (1.209745 --> 1.201925).  Saving model ...
Validation loss decreased (1.201925 --> 1.195581).  Saving model ...
Validation loss decreased (1.195581 --> 1.188095).  Saving model ...
Validation loss decreased (1.188095 --> 1.181813).  Saving model ...
Validation loss decreased (1.181813 --> 1.175221).  Saving model ...
Validation loss decreased (1.175221 --> 1.170393).  Saving model ...
Validation loss decreased (1.170393 --> 1.164095).  Saving model ...
Validation loss decreased (1.164095 --> 1.158540).  Saving model ...
Validation loss decreased (1.158540 --> 1.153762).  Saving model ...
Validation loss decreased (1.153762 --> 1.149766).  Saving model ...
Validation loss decreased (1.149766 --> 1.145023).  Saving model ...
Validation loss decreased (1.145023 --> 1.141486).  Saving model ...
Validation loss decreased (1.141486 --> 1.136967).  Saving model ...
Validation loss decreased (1.136967 --> 1.133278).  Saving model ...
Validation loss decreased (1.133278 --> 1.128888).  Saving model ...
Validation loss decreased (1.128888 --> 1.124919).  Saving model ...
Validation loss decreased (1.124919 --> 1.120179).  Saving model ...
Validation loss decreased (1.120179 --> 1.115382).  Saving model ...
Validation loss decreased (1.115382 --> 1.112910).  Saving model ...
Validation loss decreased (1.112910 --> 1.108671).  Saving model ...
Validation loss decreased (1.108671 --> 1.104908).  Saving model ...
Validation loss decreased (1.104908 --> 1.101351).  Saving model ...
Validation loss decreased (1.101351 --> 1.098551).  Saving model ...
Validation loss decreased (1.098551 --> 1.095115).  Saving model ...
Validation loss decreased (1.095115 --> 1.091746).  Saving model ...
Validation loss decreased (1.091746 --> 1.087926).  Saving model ...
Validation loss decreased (1.087926 --> 1.084778).  Saving model ...
Validation loss decreased (1.084778 --> 1.082313).  Saving model ...
Validation loss decreased (1.082313 --> 1.080094).  Saving model ...
Validation loss decreased (1.080094 --> 1.076762).  Saving model ...
Validation loss decreased (1.076762 --> 1.074493).  Saving model ...
Validation loss decreased (1.074493 --> 1.072001).  Saving model ...
Validation loss decreased (1.072001 --> 1.069986).  Saving model ...
Validation loss decreased (1.069986 --> 1.066397).  Saving model ...
Validation loss decreased (1.066397 --> 1.064091).  Saving model ...
Validation loss decreased (1.064091 --> 1.062484).  Saving model ...
Validation loss decreased (1.062484 --> 1.060482).  Saving model ...
Validation loss decreased (1.060482 --> 1.058062).  Saving model ...
Validation loss decreased (1.058062 --> 1.055512).  Saving model ...
Validation loss decreased (1.055512 --> 1.053501).  Saving model ...
Validation loss decreased (1.053501 --> 1.051059).  Saving model ...
Validation loss decreased (1.051059 --> 1.049292).  Saving model ...
Validation loss decreased (1.049292 --> 1.047784).  Saving model ...
Validation loss decreased (1.047784 --> 1.045955).  Saving model ...
Validation loss decreased (1.045955 --> 1.043974).  Saving model ...
Validation loss decreased (1.043974 --> 1.041434).  Saving model ...
Validation loss decreased (1.041434 --> 1.039304).  Saving model ...
Validation loss decreased (1.039304 --> 1.037689).  Saving model ...
Validation loss decreased (1.037689 --> 1.036301).  Saving model ...
Validation loss decreased (1.036301 --> 1.034742).  Saving model ...
Validation loss decreased (1.034742 --> 1.031794).  Saving model ...
Validation loss decreased (1.031794 --> 1.030259).  Saving model ...
Validation loss decreased (1.030259 --> 1.029029).  Saving model ...
Validation loss decreased (1.029029 --> 1.028326).  Saving model ...
Validation loss decreased (1.028326 --> 1.025822).  Saving model ...
Validation loss decreased (1.025822 --> 1.023135).  Saving model ...
Validation loss decreased (1.023135 --> 1.021940).  Saving model ...
Validation loss decreased (1.021940 --> 1.021344).  Saving model ...
Validation loss decreased (1.021344 --> 1.020475).  Saving model ...
Validation loss decreased (1.020475 --> 1.019700).  Saving model ...
Validation loss decreased (1.019700 --> 1.016825).  Saving model ...
Validation loss decreased (1.016825 --> 1.015257).  Saving model ...
Validation loss decreased (1.015257 --> 1.014351).  Saving model ...
Validation loss decreased (1.014351 --> 1.012532).  Saving model ...
Validation loss decreased (1.012532 --> 1.011433).  Saving model ...
EarlyStopping counter: 1 out of 10.0
Validation loss decreased (1.011433 --> 1.011018).  Saving model ...
Validation loss decreased (1.011018 --> 1.009463).  Saving model ...
Validation loss decreased (1.009463 --> 1.008051).  Saving model ...
Validation loss decreased (1.008051 --> 1.007141).  Saving model ...
Validation loss decreased (1.007141 --> 1.007135).  Saving model ...
Validation loss decreased (1.007135 --> 1.005642).  Saving model ...
EarlyStopping counter: 1 out of 10.0
Validation loss decreased (1.005642 --> 1.004757).  Saving model ...
Validation loss decreased (1.004757 --> 1.003254).  Saving model ...
EarlyStopping counter: 1 out of 10.0
Validation loss decreased (1.003254 --> 1.002777).  Saving model ...
EarlyStopping counter: 1 out of 10.0
Validation loss decreased (1.002777 --> 1.001956).  Saving model ...
EarlyStopping counter: 1 out of 10.0
Validation loss decreased (1.001956 --> 0.999503).  Saving model ...
Validation loss decreased (0.999503 --> 0.997574).  Saving model ...
Validation loss decreased (0.997574 --> 0.997434).  Saving model ...
EarlyStopping counter: 1 out of 10.0
Validation loss decreased (0.997434 --> 0.997371).  Saving model ...
EarlyStopping counter: 1 out of 10.0
Validation loss decreased (0.997371 --> 0.995906).  Saving model ...
Validation loss decreased (0.995906 --> 0.994523).  Saving model ...
EarlyStopping counter: 1 out of 10.0
EarlyStopping counter: 2 out of 10.0
EarlyStopping counter: 3 out of 10.0
EarlyStopping counter: 4 out of 10.0
EarlyStopping counter: 5 out of 10.0
EarlyStopping counter: 6 out of 10.0
EarlyStopping counter: 7 out of 10.0
EarlyStopping counter: 8 out of 10.0
EarlyStopping counter: 9 out of 10.0
EarlyStopping counter: 10 out of 10.0
/localscratch/yinan.29019352.0/env/lib/python3.7/site-packages/torch/nn/functional.py:1794: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.
  warnings.warn("nn.functional.tanh is deprecated. Use torch.tanh instead.")
wandb: Waiting for W&B process to finish, PID 102201... (success).
wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: \ 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: | 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: / 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: \ 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: | 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: / 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: \ 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: | 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: / 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb:                                                                                
wandb: Run history:
wandb:     e_F1 â–â–‚â–„â–„â–„â–„â–„â–„â–…â–…â–…â–†â–†â–†â–†â–†â–†â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–ˆâ–ˆâ–‡â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ
wandb:   e_loss â–ˆâ–ˆâ–ˆâ–‡â–‡â–‡â–‡â–†â–†â–…â–…â–…â–„â–„â–„â–ƒâ–ƒâ–ƒâ–ƒâ–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:     t_F1 â–â–‚â–‚â–ƒâ–‚â–ƒâ–ƒâ–„â–„â–„â–„â–…â–…â–…â–…â–†â–†â–…â–†â–†â–†â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–ˆâ–ˆâ–‡â–ˆâ–‡â–ˆâ–ˆâ–ˆ
wandb:   t_loss â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‡â–‡â–‡â–‡â–†â–†â–†â–…â–…â–…â–…â–„â–„â–„â–„â–„â–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–â–â–â–â–
wandb: 
wandb: Run summary:
wandb:     e_F1 57.29859
wandb:   e_loss 1.00209
wandb:     t_F1 69.48417
wandb:   t_loss 0.79821
wandb: 
wandb: Synced 4 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Synced daily-river-1: https://wandb.ai/yinanazhou/xl_512_bs_8_lr_1e06_es_10_lc_False_nr_True_sr_True_stem_True_lemma_False_repeat_4_fold_1/runs/fszt1phg
wandb: Find logs at: ./wandb/run-20220319_045952-fszt1phg/logs/debug.log
wandb: 

wandb: wandb version 0.12.11 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
2022-03-19 06:27:47.728555: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1
wandb: Tracking run with wandb version 0.12.5
wandb: Syncing run divine-butterfly-1
wandb: â­ï¸ View project at https://wandb.ai/yinanazhou/xl_512_bs_8_lr_1e06_es_10_lc_False_nr_True_sr_True_stem_True_lemma_False_repeat_4_fold_2
wandb: ðŸš€ View run at https://wandb.ai/yinanazhou/xl_512_bs_8_lr_1e06_es_10_lc_False_nr_True_sr_True_stem_True_lemma_False_repeat_4_fold_2/runs/8g8najxg
wandb: Run data is saved locally in /project/6002780/yinan/Thesis_MER_Lyrics/lyric-emotion/wandb/run-20220319_062744-8g8najxg
wandb: Run `wandb offline` to turn off syncing.

Validation loss decreased (inf --> 1.489138).  Saving model ...
Validation loss decreased (1.489138 --> 1.440189).  Saving model ...
Validation loss decreased (1.440189 --> 1.407247).  Saving model ...
Validation loss decreased (1.407247 --> 1.385720).  Saving model ...
Validation loss decreased (1.385720 --> 1.370635).  Saving model ...
Validation loss decreased (1.370635 --> 1.360738).  Saving model ...
Validation loss decreased (1.360738 --> 1.353778).  Saving model ...
Validation loss decreased (1.353778 --> 1.348018).  Saving model ...
Validation loss decreased (1.348018 --> 1.342509).  Saving model ...
Validation loss decreased (1.342509 --> 1.337733).  Saving model ...
Validation loss decreased (1.337733 --> 1.332868).  Saving model ...
Validation loss decreased (1.332868 --> 1.328681).  Saving model ...
Validation loss decreased (1.328681 --> 1.324404).  Saving model ...
Validation loss decreased (1.324404 --> 1.320670).  Saving model ...
Validation loss decreased (1.320670 --> 1.316279).  Saving model ...
Validation loss decreased (1.316279 --> 1.311471).  Saving model ...
Validation loss decreased (1.311471 --> 1.305349).  Saving model ...
Validation loss decreased (1.305349 --> 1.299054).  Saving model ...
Validation loss decreased (1.299054 --> 1.293113).  Saving model ...
Validation loss decreased (1.293113 --> 1.288167).  Saving model ...
Validation loss decreased (1.288167 --> 1.281537).  Saving model ...
Validation loss decreased (1.281537 --> 1.276320).  Saving model ...
Validation loss decreased (1.276320 --> 1.270652).  Saving model ...
Validation loss decreased (1.270652 --> 1.265005).  Saving model ...
Validation loss decreased (1.265005 --> 1.258265).  Saving model ...
Validation loss decreased (1.258265 --> 1.249760).  Saving model ...
Validation loss decreased (1.249760 --> 1.243659).  Saving model ...
Validation loss decreased (1.243659 --> 1.239130).  Saving model ...
Validation loss decreased (1.239130 --> 1.234560).  Saving model ...
Validation loss decreased (1.234560 --> 1.226345).  Saving model ...
Validation loss decreased (1.226345 --> 1.220626).  Saving model ...
Validation loss decreased (1.220626 --> 1.215049).  Saving model ...
Validation loss decreased (1.215049 --> 1.207558).  Saving model ...
Validation loss decreased (1.207558 --> 1.202443).  Saving model ...
Validation loss decreased (1.202443 --> 1.196087).  Saving model ...
Validation loss decreased (1.196087 --> 1.190896).  Saving model ...
Validation loss decreased (1.190896 --> 1.184590).  Saving model ...
Validation loss decreased (1.184590 --> 1.180849).  Saving model ...
Validation loss decreased (1.180849 --> 1.176790).  Saving model ...
Validation loss decreased (1.176790 --> 1.172162).  Saving model ...
Validation loss decreased (1.172162 --> 1.164547).  Saving model ...
Validation loss decreased (1.164547 --> 1.159342).  Saving model ...
Validation loss decreased (1.159342 --> 1.155282).  Saving model ...
Validation loss decreased (1.155282 --> 1.148770).  Saving model ...
Validation loss decreased (1.148770 --> 1.142519).  Saving model ...
Validation loss decreased (1.142519 --> 1.136508).  Saving model ...
Validation loss decreased (1.136508 --> 1.132754).  Saving model ...
Validation loss decreased (1.132754 --> 1.129572).  Saving model ...
Validation loss decreased (1.129572 --> 1.125115).  Saving model ...
Validation loss decreased (1.125115 --> 1.121454).  Saving model ...
Validation loss decreased (1.121454 --> 1.118503).  Saving model ...
Validation loss decreased (1.118503 --> 1.113851).  Saving model ...
Validation loss decreased (1.113851 --> 1.110162).  Saving model ...
Validation loss decreased (1.110162 --> 1.106579).  Saving model ...
Validation loss decreased (1.106579 --> 1.101310).  Saving model ...
Validation loss decreased (1.101310 --> 1.096296).  Saving model ...
Validation loss decreased (1.096296 --> 1.092321).  Saving model ...
Validation loss decreased (1.092321 --> 1.088274).  Saving model ...
Validation loss decreased (1.088274 --> 1.084859).  Saving model ...
EarlyStopping counter: 1 out of 10.0
Validation loss decreased (1.084859 --> 1.081494).  Saving model ...
Validation loss decreased (1.081494 --> 1.075355).  Saving model ...
Validation loss decreased (1.075355 --> 1.070580).  Saving model ...
Validation loss decreased (1.070580 --> 1.064599).  Saving model ...
Validation loss decreased (1.064599 --> 1.062351).  Saving model ...
Validation loss decreased (1.062351 --> 1.062208).  Saving model ...
Validation loss decreased (1.062208 --> 1.060484).  Saving model ...
Validation loss decreased (1.060484 --> 1.057713).  Saving model ...
Validation loss decreased (1.057713 --> 1.055043).  Saving model ...
Validation loss decreased (1.055043 --> 1.053404).  Saving model ...
Validation loss decreased (1.053404 --> 1.050848).  Saving model ...
Validation loss decreased (1.050848 --> 1.047690).  Saving model ...
Validation loss decreased (1.047690 --> 1.045330).  Saving model ...
Validation loss decreased (1.045330 --> 1.041085).  Saving model ...
Validation loss decreased (1.041085 --> 1.036684).  Saving model ...
Validation loss decreased (1.036684 --> 1.035519).  Saving model ...
Validation loss decreased (1.035519 --> 1.032832).  Saving model ...
Validation loss decreased (1.032832 --> 1.030027).  Saving model ...
Validation loss decreased (1.030027 --> 1.028979).  Saving model ...
Validation loss decreased (1.028979 --> 1.028540).  Saving model ...
Validation loss decreased (1.028540 --> 1.025365).  Saving model ...
Validation loss decreased (1.025365 --> 1.020480).  Saving model ...
EarlyStopping counter: 1 out of 10.0
Validation loss decreased (1.020480 --> 1.019196).  Saving model ...
Validation loss decreased (1.019196 --> 1.016617).  Saving model ...
EarlyStopping counter: 1 out of 10.0
Validation loss decreased (1.016617 --> 1.016366).  Saving model ...
Validation loss decreased (1.016366 --> 1.014072).  Saving model ...
Validation loss decreased (1.014072 --> 1.012130).  Saving model ...
Validation loss decreased (1.012130 --> 1.010830).  Saving model ...
Validation loss decreased (1.010830 --> 1.009245).  Saving model ...
EarlyStopping counter: 1 out of 10.0
Validation loss decreased (1.009245 --> 1.008509).  Saving model ...
Validation loss decreased (1.008509 --> 1.006710).  Saving model ...
Validation loss decreased (1.006710 --> 1.002386).  Saving model ...
Validation loss decreased (1.002386 --> 1.000019).  Saving model ...
EarlyStopping counter: 1 out of 10.0
Validation loss decreased (1.000019 --> 0.998992).  Saving model ...
EarlyStopping counter: 1 out of 10.0
EarlyStopping counter: 2 out of 10.0
Validation loss decreased (0.998992 --> 0.997457).  Saving model ...
EarlyStopping counter: 1 out of 10.0
Validation loss decreased (0.997457 --> 0.995878).  Saving model ...
Validation loss decreased (0.995878 --> 0.992282).  Saving model ...
Validation loss decreased (0.992282 --> 0.991417).  Saving model ...
EarlyStopping counter: 1 out of 10.0
EarlyStopping counter: 2 out of 10.0
EarlyStopping counter: 3 out of 10.0
EarlyStopping counter: 4 out of 10.0
Validation loss decreased (0.991417 --> 0.991118).  Saving model ...
Validation loss decreased (0.991118 --> 0.990789).  Saving model ...
Validation loss decreased (0.990789 --> 0.990039).  Saving model ...
Validation loss decreased (0.990039 --> 0.988528).  Saving model ...
Validation loss decreased (0.988528 --> 0.988202).  Saving model ...
Validation loss decreased (0.988202 --> 0.987127).  Saving model ...
Validation loss decreased (0.987127 --> 0.986544).  Saving model ...
EarlyStopping counter: 1 out of 10.0
Validation loss decreased (0.986544 --> 0.986503).  Saving model ...
Validation loss decreased (0.986503 --> 0.984737).  Saving model ...
Validation loss decreased (0.984737 --> 0.981960).  Saving model ...
Validation loss decreased (0.981960 --> 0.981661).  Saving model ...
EarlyStopping counter: 1 out of 10.0
EarlyStopping counter: 2 out of 10.0
EarlyStopping counter: 3 out of 10.0
EarlyStopping counter: 4 out of 10.0
EarlyStopping counter: 5 out of 10.0
EarlyStopping counter: 6 out of 10.0
EarlyStopping counter: 7 out of 10.0
EarlyStopping counter: 8 out of 10.0
EarlyStopping counter: 9 out of 10.0
EarlyStopping counter: 10 out of 10.0
/localscratch/yinan.29019352.0/env/lib/python3.7/site-packages/torch/nn/functional.py:1794: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.
  warnings.warn("nn.functional.tanh is deprecated. Use torch.tanh instead.")
wandb: Waiting for W&B process to finish, PID 106949... (success).
wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: \ 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: | 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: / 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: \ 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: | 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: / 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: \ 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: | 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: / 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: \ 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: | 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: / 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb:                                                                                
wandb: Run history:
wandb:     e_F1 â–â–‚â–…â–…â–…â–†â–†â–†â–†â–†â–†â–‡â–‡â–‡â–ˆâ–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ
wandb:   e_loss â–ˆâ–‡â–‡â–†â–†â–†â–†â–…â–…â–…â–„â–„â–„â–„â–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:     t_F1 â–â–‚â–ƒâ–ƒâ–„â–„â–„â–„â–„â–…â–…â–…â–…â–†â–†â–†â–†â–‡â–†â–‡â–‡â–‡â–ˆâ–‡â–‡â–‡â–‡â–‡â–‡â–ˆâ–‡â–ˆâ–ˆâ–ˆâ–ˆâ–‡â–ˆâ–ˆâ–ˆâ–ˆ
wandb:   t_loss â–ˆâ–ˆâ–‡â–‡â–‡â–†â–†â–†â–†â–†â–…â–…â–…â–…â–…â–„â–„â–„â–„â–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–‚â–‚â–‚â–ƒâ–‚â–‚â–‚â–‚â–â–‚â–‚â–â–â–â–
wandb: 
wandb: Run summary:
wandb:     e_F1 55.65479
wandb:   e_loss 0.98724
wandb:     t_F1 70.04742
wandb:   t_loss 0.77951
wandb: 
wandb: Synced 4 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Synced divine-butterfly-1: https://wandb.ai/yinanazhou/xl_512_bs_8_lr_1e06_es_10_lc_False_nr_True_sr_True_stem_True_lemma_False_repeat_4_fold_2/runs/8g8najxg
wandb: Find logs at: ./wandb/run-20220319_062744-8g8najxg/logs/debug.log
wandb: 

wandb: wandb version 0.12.11 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
2022-03-19 07:53:30.000308: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1
wandb: Tracking run with wandb version 0.12.5
wandb: Syncing run eternal-breeze-1
wandb: â­ï¸ View project at https://wandb.ai/yinanazhou/xl_512_bs_8_lr_1e06_es_10_lc_False_nr_True_sr_True_stem_True_lemma_False_repeat_5_fold_1
wandb: ðŸš€ View run at https://wandb.ai/yinanazhou/xl_512_bs_8_lr_1e06_es_10_lc_False_nr_True_sr_True_stem_True_lemma_False_repeat_5_fold_1/runs/ljgfelrn
wandb: Run data is saved locally in /project/6002780/yinan/Thesis_MER_Lyrics/lyric-emotion/wandb/run-20220319_075327-ljgfelrn
wandb: Run `wandb offline` to turn off syncing.

Validation loss decreased (inf --> 1.401429).  Saving model ...
Validation loss decreased (1.401429 --> 1.396740).  Saving model ...
Validation loss decreased (1.396740 --> 1.392657).  Saving model ...
Validation loss decreased (1.392657 --> 1.389162).  Saving model ...
Validation loss decreased (1.389162 --> 1.385705).  Saving model ...
Validation loss decreased (1.385705 --> 1.382449).  Saving model ...
Validation loss decreased (1.382449 --> 1.379149).  Saving model ...
Validation loss decreased (1.379149 --> 1.375854).  Saving model ...
Validation loss decreased (1.375854 --> 1.372696).  Saving model ...
Validation loss decreased (1.372696 --> 1.369654).  Saving model ...
Validation loss decreased (1.369654 --> 1.366213).  Saving model ...
Validation loss decreased (1.366213 --> 1.363007).  Saving model ...
Validation loss decreased (1.363007 --> 1.359413).  Saving model ...
Validation loss decreased (1.359413 --> 1.356078).  Saving model ...
Validation loss decreased (1.356078 --> 1.352378).  Saving model ...
Validation loss decreased (1.352378 --> 1.348425).  Saving model ...
Validation loss decreased (1.348425 --> 1.344565).  Saving model ...
Validation loss decreased (1.344565 --> 1.340240).  Saving model ...
Validation loss decreased (1.340240 --> 1.335780).  Saving model ...
Validation loss decreased (1.335780 --> 1.331526).  Saving model ...
Validation loss decreased (1.331526 --> 1.325981).  Saving model ...
Validation loss decreased (1.325981 --> 1.319914).  Saving model ...
Validation loss decreased (1.319914 --> 1.314342).  Saving model ...
Validation loss decreased (1.314342 --> 1.308570).  Saving model ...
Validation loss decreased (1.308570 --> 1.302747).  Saving model ...
Validation loss decreased (1.302747 --> 1.296343).  Saving model ...
Validation loss decreased (1.296343 --> 1.290466).  Saving model ...
Validation loss decreased (1.290466 --> 1.283969).  Saving model ...
Validation loss decreased (1.283969 --> 1.276582).  Saving model ...
Validation loss decreased (1.276582 --> 1.269034).  Saving model ...
Validation loss decreased (1.269034 --> 1.261658).  Saving model ...
Validation loss decreased (1.261658 --> 1.254957).  Saving model ...
Validation loss decreased (1.254957 --> 1.248534).  Saving model ...
Validation loss decreased (1.248534 --> 1.241642).  Saving model ...
Validation loss decreased (1.241642 --> 1.235462).  Saving model ...
Validation loss decreased (1.235462 --> 1.229751).  Saving model ...
Validation loss decreased (1.229751 --> 1.222572).  Saving model ...
Validation loss decreased (1.222572 --> 1.214645).  Saving model ...
Validation loss decreased (1.214645 --> 1.209406).  Saving model ...
Validation loss decreased (1.209406 --> 1.202066).  Saving model ...
Validation loss decreased (1.202066 --> 1.196069).  Saving model ...
Validation loss decreased (1.196069 --> 1.190361).  Saving model ...
Validation loss decreased (1.190361 --> 1.183556).  Saving model ...
Validation loss decreased (1.183556 --> 1.178398).  Saving model ...
Validation loss decreased (1.178398 --> 1.172729).  Saving model ...
Validation loss decreased (1.172729 --> 1.166861).  Saving model ...
Validation loss decreased (1.166861 --> 1.161472).  Saving model ...
Validation loss decreased (1.161472 --> 1.156477).  Saving model ...
Validation loss decreased (1.156477 --> 1.152730).  Saving model ...
Validation loss decreased (1.152730 --> 1.148853).  Saving model ...
Validation loss decreased (1.148853 --> 1.142234).  Saving model ...
Validation loss decreased (1.142234 --> 1.136687).  Saving model ...
Validation loss decreased (1.136687 --> 1.132502).  Saving model ...
Validation loss decreased (1.132502 --> 1.126936).  Saving model ...
Validation loss decreased (1.126936 --> 1.120566).  Saving model ...
Validation loss decreased (1.120566 --> 1.116488).  Saving model ...
Validation loss decreased (1.116488 --> 1.110091).  Saving model ...
Validation loss decreased (1.110091 --> 1.106862).  Saving model ...
Validation loss decreased (1.106862 --> 1.104144).  Saving model ...
Validation loss decreased (1.104144 --> 1.102033).  Saving model ...
Validation loss decreased (1.102033 --> 1.094079).  Saving model ...
Validation loss decreased (1.094079 --> 1.089788).  Saving model ...
Validation loss decreased (1.089788 --> 1.084896).  Saving model ...
Validation loss decreased (1.084896 --> 1.082409).  Saving model ...
Validation loss decreased (1.082409 --> 1.076882).  Saving model ...
Validation loss decreased (1.076882 --> 1.073662).  Saving model ...
Validation loss decreased (1.073662 --> 1.071141).  Saving model ...
Validation loss decreased (1.071141 --> 1.067555).  Saving model ...
Validation loss decreased (1.067555 --> 1.063019).  Saving model ...
Validation loss decreased (1.063019 --> 1.059927).  Saving model ...
Validation loss decreased (1.059927 --> 1.056913).  Saving model ...
Validation loss decreased (1.056913 --> 1.053936).  Saving model ...
Validation loss decreased (1.053936 --> 1.051131).  Saving model ...
Validation loss decreased (1.051131 --> 1.047184).  Saving model ...
Validation loss decreased (1.047184 --> 1.043988).  Saving model ...
Validation loss decreased (1.043988 --> 1.041198).  Saving model ...
Validation loss decreased (1.041198 --> 1.038165).  Saving model ...
Validation loss decreased (1.038165 --> 1.036108).  Saving model ...
Validation loss decreased (1.036108 --> 1.032949).  Saving model ...
Validation loss decreased (1.032949 --> 1.032032).  Saving model ...
Validation loss decreased (1.032032 --> 1.029084).  Saving model ...
Validation loss decreased (1.029084 --> 1.025163).  Saving model ...
Validation loss decreased (1.025163 --> 1.022856).  Saving model ...
Validation loss decreased (1.022856 --> 1.019687).  Saving model ...
Validation loss decreased (1.019687 --> 1.016437).  Saving model ...
Validation loss decreased (1.016437 --> 1.014805).  Saving model ...
Validation loss decreased (1.014805 --> 1.013401).  Saving model ...
Validation loss decreased (1.013401 --> 1.013368).  Saving model ...
Validation loss decreased (1.013368 --> 1.010365).  Saving model ...
Validation loss decreased (1.010365 --> 1.007793).  Saving model ...
Validation loss decreased (1.007793 --> 1.005614).  Saving model ...
Validation loss decreased (1.005614 --> 1.002148).  Saving model ...
Validation loss decreased (1.002148 --> 1.001339).  Saving model ...
Validation loss decreased (1.001339 --> 0.999003).  Saving model ...
Validation loss decreased (0.999003 --> 0.997391).  Saving model ...
EarlyStopping counter: 1 out of 10.0
Validation loss decreased (0.997391 --> 0.996252).  Saving model ...
Validation loss decreased (0.996252 --> 0.995012).  Saving model ...
Validation loss decreased (0.995012 --> 0.993997).  Saving model ...
Validation loss decreased (0.993997 --> 0.990294).  Saving model ...
Validation loss decreased (0.990294 --> 0.988247).  Saving model ...
Validation loss decreased (0.988247 --> 0.988034).  Saving model ...
Validation loss decreased (0.988034 --> 0.986331).  Saving model ...
Validation loss decreased (0.986331 --> 0.985059).  Saving model ...
Validation loss decreased (0.985059 --> 0.982946).  Saving model ...
Validation loss decreased (0.982946 --> 0.981930).  Saving model ...
Validation loss decreased (0.981930 --> 0.981380).  Saving model ...
Validation loss decreased (0.981380 --> 0.980260).  Saving model ...
EarlyStopping counter: 1 out of 10.0
Validation loss decreased (0.980260 --> 0.979000).  Saving model ...
Validation loss decreased (0.979000 --> 0.977650).  Saving model ...
Validation loss decreased (0.977650 --> 0.977074).  Saving model ...
Validation loss decreased (0.977074 --> 0.975826).  Saving model ...
Validation loss decreased (0.975826 --> 0.974283).  Saving model ...
Validation loss decreased (0.974283 --> 0.972640).  Saving model ...
Validation loss decreased (0.972640 --> 0.970862).  Saving model ...
Validation loss decreased (0.970862 --> 0.970620).  Saving model ...
Validation loss decreased (0.970620 --> 0.968917).  Saving model ...
EarlyStopping counter: 1 out of 10.0
Validation loss decreased (0.968917 --> 0.968630).  Saving model ...
Validation loss decreased (0.968630 --> 0.967294).  Saving model ...
Validation loss decreased (0.967294 --> 0.966791).  Saving model ...
Validation loss decreased (0.966791 --> 0.966135).  Saving model ...
Validation loss decreased (0.966135 --> 0.965863).  Saving model ...
EarlyStopping counter: 1 out of 10.0
EarlyStopping counter: 2 out of 10.0
EarlyStopping counter: 3 out of 10.0
EarlyStopping counter: 4 out of 10.0
EarlyStopping counter: 5 out of 10.0
EarlyStopping counter: 6 out of 10.0
EarlyStopping counter: 7 out of 10.0
EarlyStopping counter: 8 out of 10.0
EarlyStopping counter: 9 out of 10.0
EarlyStopping counter: 10 out of 10.0
/localscratch/yinan.29019352.0/env/lib/python3.7/site-packages/torch/nn/functional.py:1794: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.
  warnings.warn("nn.functional.tanh is deprecated. Use torch.tanh instead.")
wandb: Waiting for W&B process to finish, PID 111548... (success).
wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: \ 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: | 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: / 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: \ 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: | 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: / 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: \ 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: | 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: / 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: \ 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: | 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: / 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: \ 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb:                                                                                
wandb: Run history:
wandb:     e_F1 â–â–â–‚â–„â–…â–…â–…â–…â–…â–…â–†â–†â–†â–†â–†â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‡â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ
wandb:   e_loss â–ˆâ–ˆâ–ˆâ–‡â–‡â–‡â–‡â–‡â–†â–†â–…â–…â–…â–„â–„â–„â–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–â–â–â–â–â–â–â–â–â–â–
wandb:     t_F1 â–â–â–‚â–‚â–‚â–‚â–ƒâ–ƒâ–„â–„â–„â–„â–…â–…â–…â–…â–†â–†â–†â–†â–†â–‡â–†â–‡â–†â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‡â–ˆâ–ˆ
wandb:   t_loss â–ˆâ–ˆâ–ˆâ–‡â–‡â–‡â–‡â–‡â–‡â–†â–†â–†â–†â–…â–…â–…â–…â–„â–„â–„â–„â–„â–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–‚â–ƒâ–‚â–‚â–‚â–â–‚â–â–‚â–â–
wandb: 
wandb: Run summary:
wandb:     e_F1 58.2944
wandb:   e_loss 0.96788
wandb:     t_F1 71.24732
wandb:   t_loss 0.76383
wandb: 
wandb: Synced 4 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Synced eternal-breeze-1: https://wandb.ai/yinanazhou/xl_512_bs_8_lr_1e06_es_10_lc_False_nr_True_sr_True_stem_True_lemma_False_repeat_5_fold_1/runs/ljgfelrn
wandb: Find logs at: ./wandb/run-20220319_075327-ljgfelrn/logs/debug.log
wandb: 

wandb: wandb version 0.12.11 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
2022-03-19 09:19:31.445312: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1
wandb: Tracking run with wandb version 0.12.5
wandb: Syncing run sweet-thunder-1
wandb: â­ï¸ View project at https://wandb.ai/yinanazhou/xl_512_bs_8_lr_1e06_es_10_lc_False_nr_True_sr_True_stem_True_lemma_False_repeat_5_fold_2
wandb: ðŸš€ View run at https://wandb.ai/yinanazhou/xl_512_bs_8_lr_1e06_es_10_lc_False_nr_True_sr_True_stem_True_lemma_False_repeat_5_fold_2/runs/3395g292
wandb: Run data is saved locally in /project/6002780/yinan/Thesis_MER_Lyrics/lyric-emotion/wandb/run-20220319_091928-3395g292
wandb: Run `wandb offline` to turn off syncing.

Validation loss decreased (inf --> 1.469545).  Saving model ...
Validation loss decreased (1.469545 --> 1.435982).  Saving model ...
Validation loss decreased (1.435982 --> 1.413535).  Saving model ...
Validation loss decreased (1.413535 --> 1.398679).  Saving model ...
Validation loss decreased (1.398679 --> 1.388962).  Saving model ...
Validation loss decreased (1.388962 --> 1.381650).  Saving model ...
Validation loss decreased (1.381650 --> 1.376578).  Saving model ...
Validation loss decreased (1.376578 --> 1.372345).  Saving model ...
Validation loss decreased (1.372345 --> 1.368858).  Saving model ...
Validation loss decreased (1.368858 --> 1.365396).  Saving model ...
Validation loss decreased (1.365396 --> 1.361505).  Saving model ...
Validation loss decreased (1.361505 --> 1.358889).  Saving model ...
Validation loss decreased (1.358889 --> 1.355664).  Saving model ...
Validation loss decreased (1.355664 --> 1.352131).  Saving model ...
Validation loss decreased (1.352131 --> 1.348574).  Saving model ...
Validation loss decreased (1.348574 --> 1.345121).  Saving model ...
Validation loss decreased (1.345121 --> 1.341191).  Saving model ...
Validation loss decreased (1.341191 --> 1.337708).  Saving model ...
Validation loss decreased (1.337708 --> 1.333288).  Saving model ...
Validation loss decreased (1.333288 --> 1.328812).  Saving model ...
Validation loss decreased (1.328812 --> 1.324476).  Saving model ...
Validation loss decreased (1.324476 --> 1.320521).  Saving model ...
Validation loss decreased (1.320521 --> 1.316868).  Saving model ...
Validation loss decreased (1.316868 --> 1.311198).  Saving model ...
Validation loss decreased (1.311198 --> 1.306846).  Saving model ...
Validation loss decreased (1.306846 --> 1.301265).  Saving model ...
Validation loss decreased (1.301265 --> 1.295706).  Saving model ...
Validation loss decreased (1.295706 --> 1.291037).  Saving model ...
Validation loss decreased (1.291037 --> 1.285196).  Saving model ...
Validation loss decreased (1.285196 --> 1.279708).  Saving model ...
Validation loss decreased (1.279708 --> 1.274051).  Saving model ...
Validation loss decreased (1.274051 --> 1.269274).  Saving model ...
Validation loss decreased (1.269274 --> 1.265206).  Saving model ...
Validation loss decreased (1.265206 --> 1.259385).  Saving model ...
Validation loss decreased (1.259385 --> 1.254675).  Saving model ...
Validation loss decreased (1.254675 --> 1.247467).  Saving model ...
Validation loss decreased (1.247467 --> 1.241896).  Saving model ...
Validation loss decreased (1.241896 --> 1.235244).  Saving model ...
Validation loss decreased (1.235244 --> 1.229337).  Saving model ...
Validation loss decreased (1.229337 --> 1.223648).  Saving model ...
Validation loss decreased (1.223648 --> 1.217920).  Saving model ...
Validation loss decreased (1.217920 --> 1.211266).  Saving model ...
Validation loss decreased (1.211266 --> 1.207336).  Saving model ...
Validation loss decreased (1.207336 --> 1.200539).  Saving model ...
Validation loss decreased (1.200539 --> 1.195480).  Saving model ...
Validation loss decreased (1.195480 --> 1.191802).  Saving model ...
Validation loss decreased (1.191802 --> 1.188271).  Saving model ...
Validation loss decreased (1.188271 --> 1.182925).  Saving model ...
Validation loss decreased (1.182925 --> 1.178859).  Saving model ...
Validation loss decreased (1.178859 --> 1.173493).  Saving model ...
Validation loss decreased (1.173493 --> 1.171114).  Saving model ...
Validation loss decreased (1.171114 --> 1.165808).  Saving model ...
Validation loss decreased (1.165808 --> 1.162721).  Saving model ...
Validation loss decreased (1.162721 --> 1.159051).  Saving model ...
Validation loss decreased (1.159051 --> 1.154480).  Saving model ...
Validation loss decreased (1.154480 --> 1.150652).  Saving model ...
Validation loss decreased (1.150652 --> 1.145646).  Saving model ...
Validation loss decreased (1.145646 --> 1.143784).  Saving model ...
Validation loss decreased (1.143784 --> 1.140251).  Saving model ...
Validation loss decreased (1.140251 --> 1.137026).  Saving model ...
Validation loss decreased (1.137026 --> 1.132051).  Saving model ...
Validation loss decreased (1.132051 --> 1.127174).  Saving model ...
Validation loss decreased (1.127174 --> 1.124302).  Saving model ...
Validation loss decreased (1.124302 --> 1.121457).  Saving model ...
Validation loss decreased (1.121457 --> 1.119618).  Saving model ...
Validation loss decreased (1.119618 --> 1.114715).  Saving model ...
Validation loss decreased (1.114715 --> 1.114308).  Saving model ...
Validation loss decreased (1.114308 --> 1.110760).  Saving model ...
Validation loss decreased (1.110760 --> 1.108984).  Saving model ...
Validation loss decreased (1.108984 --> 1.102032).  Saving model ...
Validation loss decreased (1.102032 --> 1.098935).  Saving model ...
Validation loss decreased (1.098935 --> 1.095882).  Saving model ...
Validation loss decreased (1.095882 --> 1.095444).  Saving model ...
Validation loss decreased (1.095444 --> 1.091160).  Saving model ...
Validation loss decreased (1.091160 --> 1.088389).  Saving model ...
Validation loss decreased (1.088389 --> 1.086224).  Saving model ...
Validation loss decreased (1.086224 --> 1.085203).  Saving model ...
Validation loss decreased (1.085203 --> 1.084221).  Saving model ...
Validation loss decreased (1.084221 --> 1.081700).  Saving model ...
Validation loss decreased (1.081700 --> 1.080635).  Saving model ...
Validation loss decreased (1.080635 --> 1.077508).  Saving model ...
Validation loss decreased (1.077508 --> 1.074791).  Saving model ...
Validation loss decreased (1.074791 --> 1.071479).  Saving model ...
Validation loss decreased (1.071479 --> 1.067711).  Saving model ...
Validation loss decreased (1.067711 --> 1.065843).  Saving model ...
EarlyStopping counter: 1 out of 10.0
Validation loss decreased (1.065843 --> 1.064453).  Saving model ...
Validation loss decreased (1.064453 --> 1.060682).  Saving model ...
Validation loss decreased (1.060682 --> 1.059157).  Saving model ...
EarlyStopping counter: 1 out of 10.0
EarlyStopping counter: 2 out of 10.0
Validation loss decreased (1.059157 --> 1.056116).  Saving model ...
Validation loss decreased (1.056116 --> 1.053815).  Saving model ...
EarlyStopping counter: 1 out of 10.0
EarlyStopping counter: 2 out of 10.0
EarlyStopping counter: 3 out of 10.0
Validation loss decreased (1.053815 --> 1.053059).  Saving model ...
Validation loss decreased (1.053059 --> 1.050705).  Saving model ...
EarlyStopping counter: 1 out of 10.0
EarlyStopping counter: 2 out of 10.0
Validation loss decreased (1.050705 --> 1.044862).  Saving model ...
Validation loss decreased (1.044862 --> 1.040314).  Saving model ...
Validation loss decreased (1.040314 --> 1.040033).  Saving model ...
EarlyStopping counter: 1 out of 10.0
EarlyStopping counter: 2 out of 10.0
EarlyStopping counter: 3 out of 10.0
EarlyStopping counter: 4 out of 10.0
Validation loss decreased (1.040033 --> 1.038956).  Saving model ...
Validation loss decreased (1.038956 --> 1.037510).  Saving model ...
Validation loss decreased (1.037510 --> 1.036468).  Saving model ...
Validation loss decreased (1.036468 --> 1.034253).  Saving model ...
Validation loss decreased (1.034253 --> 1.033295).  Saving model ...
Validation loss decreased (1.033295 --> 1.031523).  Saving model ...
Validation loss decreased (1.031523 --> 1.028676).  Saving model ...
EarlyStopping counter: 1 out of 10.0
Validation loss decreased (1.028676 --> 1.028148).  Saving model ...
EarlyStopping counter: 1 out of 10.0
Validation loss decreased (1.028148 --> 1.024990).  Saving model ...
Validation loss decreased (1.024990 --> 1.023980).  Saving model ...
EarlyStopping counter: 1 out of 10.0
EarlyStopping counter: 2 out of 10.0
EarlyStopping counter: 3 out of 10.0
EarlyStopping counter: 4 out of 10.0
EarlyStopping counter: 5 out of 10.0
Validation loss decreased (1.023980 --> 1.021034).  Saving model ...
EarlyStopping counter: 1 out of 10.0
Validation loss decreased (1.021034 --> 1.020705).  Saving model ...
Validation loss decreased (1.020705 --> 1.018859).  Saving model ...
EarlyStopping counter: 1 out of 10.0
EarlyStopping counter: 2 out of 10.0
EarlyStopping counter: 3 out of 10.0
EarlyStopping counter: 4 out of 10.0
EarlyStopping counter: 5 out of 10.0
Validation loss decreased (1.018859 --> 1.016640).  Saving model ...
EarlyStopping counter: 1 out of 10.0
Validation loss decreased (1.016640 --> 1.015702).  Saving model ...
EarlyStopping counter: 1 out of 10.0
EarlyStopping counter: 2 out of 10.0
EarlyStopping counter: 3 out of 10.0
EarlyStopping counter: 4 out of 10.0
EarlyStopping counter: 5 out of 10.0
EarlyStopping counter: 6 out of 10.0
EarlyStopping counter: 7 out of 10.0
EarlyStopping counter: 8 out of 10.0
EarlyStopping counter: 9 out of 10.0
EarlyStopping counter: 10 out of 10.0
/localscratch/yinan.29019352.0/env/lib/python3.7/site-packages/torch/nn/functional.py:1794: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.
  warnings.warn("nn.functional.tanh is deprecated. Use torch.tanh instead.")
wandb: Waiting for W&B process to finish, PID 116186... (success).
wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: \ 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: | 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: / 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: \ 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: | 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: / 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: \ 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: | 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: / 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb:                                                                                
wandb: Run history:
wandb:     e_F1 â–â–‚â–„â–„â–„â–…â–…â–†â–†â–†â–†â–†â–†â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ
wandb:   e_loss â–ˆâ–‡â–‡â–‡â–†â–†â–†â–†â–…â–…â–…â–„â–„â–„â–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–â–â–â–â–â–â–â–â–â–â–â–
wandb:     t_F1 â–â–â–‚â–ƒâ–ƒâ–„â–„â–„â–„â–„â–…â–…â–…â–†â–†â–†â–†â–†â–†â–†â–†â–†â–‡â–†â–‡â–‡â–‡â–†â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–ˆâ–ˆâ–ˆâ–ˆ
wandb:   t_loss â–ˆâ–ˆâ–‡â–‡â–‡â–‡â–†â–†â–†â–†â–…â–…â–…â–…â–…â–„â–„â–„â–„â–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–‚â–ƒâ–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–â–â–â–
wandb: 
wandb: Run summary:
wandb:     e_F1 56.44908
wandb:   e_loss 1.02501
wandb:     t_F1 70.97482
wandb:   t_loss 0.7781
wandb: 
wandb: Synced 4 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Synced sweet-thunder-1: https://wandb.ai/yinanazhou/xl_512_bs_8_lr_1e06_es_10_lc_False_nr_True_sr_True_stem_True_lemma_False_repeat_5_fold_2/runs/3395g292
wandb: Find logs at: ./wandb/run-20220319_091928-3395g292/logs/debug.log
wandb: 

