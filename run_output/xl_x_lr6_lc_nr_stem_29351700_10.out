Unloading StdEnv/2020

Due to MODULEPATH changes, the following have been reloaded:
  1) mii/1.1.1


The following have been reloaded with a version change:
  1) python/3.8.2 => python/3.7.4

Using base prefix '/cvmfs/soft.computecanada.ca/easybuild/software/2017/Core/python/3.7.4'
New python executable in /localscratch/yinan.29351700.0/env/bin/python
Installing setuptools, pip, wheel...
done.
Ignoring pip: markers 'python_version < "3"' don't match your environment
Looking in links: /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/nix/avx2, /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/nix/generic, /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic
Collecting pip
Installing collected packages: pip
  Found existing installation: pip 19.1.1
    Uninstalling pip-19.1.1:
      Successfully uninstalled pip-19.1.1
Successfully installed pip-21.2.3+computecanada
Looking in links: /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/nix/avx2, /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/nix/generic, /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/keras-2.8.0+computecanada-py2.py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/Keras_Preprocessing-1.1.2+computecanada-py3-none-any.whl
Requirement already satisfied: matplotlib in /cvmfs/soft.computecanada.ca/easybuild/software/2017/Core/scipy-stack/2019a/lib/python3.7/site-packages (from -r requirements.txt (line 3)) (3.0.2)
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/nltk-3.6.5+computecanada-py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/scikit_learn-0.22.1+computecanada-cp37-cp37m-linux_x86_64.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/tensorboard-2.3.0+computecanada-py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/tensorboard_plugin_wit-1.7.0+computecanada-py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/tensorflow_gpu-2.3.0+computecanada-cp37-cp37m-linux_x86_64.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/tensorflow_estimator-2.3.0+computecanada-py2.py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/tokenizers-0.5.2+computecanada-cp37-cp37m-linux_x86_64.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/nix/avx2/torch-1.4.0+computecanada-cp37-cp37m-linux_x86_64.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/torchtext-0.6.0+computecanada-py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/torchvision-0.8.2+computecanada-cp37-cp37m-linux_x86_64.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/transformers-2.5.1+computecanada-py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/urllib3-1.26.7+computecanada-py2.py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/joblib-1.1.0+computecanada-py2.py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/click-8.0.4+computecanada-py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/tqdm-4.63.1+computecanada-py2.py3-none-any.whl
ERROR: Could not find a version that satisfies the requirement regex>=2021.8.3 (from nltk) (from versions: 2018.1.10+computecanada, 2019.11.1+computecanada, 2020.11.13+computecanada)
ERROR: No matching distribution found for regex>=2021.8.3
Looking in links: /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/nix/avx2, /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/nix/generic, /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic
ERROR: Could not find a version that satisfies the requirement numpy==1.20.0+computacanada (from versions: 1.15.0+computecanada, 1.15.2+computecanada, 1.15.4+computecanada, 1.16.0+computecanada, 1.16.2+computecanada, 1.16.3+computecanada, 1.17.4+computecanada, 1.18.1+computecanada, 1.18.4+computecanada, 1.19.1+computecanada, 1.19.2+computecanada, 1.20.2+computecanada)
ERROR: No matching distribution found for numpy==1.20.0+computacanada
Looking in links: /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/nix/avx2, /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/nix/generic, /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/wandb-0.12.5+computecanada-py2.py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/yaspin-2.1.0+computecanada-py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/sentry_sdk-1.5.0+computecanada-py2.py3-none-any.whl
Requirement already satisfied: requests<3,>=2.0.0 in /cvmfs/soft.computecanada.ca/easybuild/software/2017/Core/scipy-stack/2019a/lib/python3.7/site-packages (from wandb) (2.21.0)
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/promise-2.3+computecanada-py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/configparser-5.0.2+computecanada-py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/click-8.0.4+computecanada-py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/six-1.16.0+computecanada-py2.py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/protobuf-3.19.4+computecanada-py2.py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/pathtools-0.1.2+computecanada-py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/GitPython-3.1.24+computecanada-py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/psutil-5.7.3+computecanada-cp37-cp37m-linux_x86_64.whl
Requirement already satisfied: python-dateutil>=2.6.1 in /cvmfs/soft.computecanada.ca/easybuild/software/2017/Core/scipy-stack/2019a/lib/python3.7/site-packages (from wandb) (2.7.5)
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/subprocess32-3.5.4+computecanada-py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/docker_pycreds-0.4.0+computecanada-py2.py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/PyYAML-5.3.1+computecanada-cp37-cp37m-linux_x86_64.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/shortuuid-1.0.1+computecanada-py3-none-any.whl
Requirement already satisfied: importlib-metadata in /cvmfs/soft.computecanada.ca/easybuild/software/2017/Core/scipy-stack/2019a/lib/python3.7/site-packages (from Click!=8.0.0,>=7.0->wandb) (0.8)
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/gitdb-4.0.9+computecanada-py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/typing_extensions-4.1.1+computecanada-py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/smmap-5.0.0+computecanada-py3-none-any.whl
Requirement already satisfied: idna<2.9,>=2.5 in /cvmfs/soft.computecanada.ca/easybuild/software/2017/Core/scipy-stack/2019a/lib/python3.7/site-packages (from requests<3,>=2.0.0->wandb) (2.8)
Requirement already satisfied: urllib3<1.25,>=1.21.1 in /cvmfs/soft.computecanada.ca/easybuild/software/2017/Core/scipy-stack/2019a/lib/python3.7/site-packages (from requests<3,>=2.0.0->wandb) (1.24.1)
Requirement already satisfied: certifi>=2017.4.17 in /cvmfs/soft.computecanada.ca/easybuild/software/2017/Core/scipy-stack/2019a/lib/python3.7/site-packages (from requests<3,>=2.0.0->wandb) (2018.11.29)
Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /cvmfs/soft.computecanada.ca/easybuild/software/2017/Core/scipy-stack/2019a/lib/python3.7/site-packages (from requests<3,>=2.0.0->wandb) (3.0.4)
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/termcolor-1.1.0+computecanada-py3-none-any.whl
Requirement already satisfied: zipp>=0.3.2 in /cvmfs/soft.computecanada.ca/easybuild/software/2017/Core/scipy-stack/2019a/lib/python3.7/site-packages (from importlib-metadata->Click!=8.0.0,>=7.0->wandb) (0.3.3)
Installing collected packages: smmap, typing-extensions, termcolor, six, gitdb, yaspin, subprocess32, shortuuid, sentry-sdk, PyYAML, psutil, protobuf, promise, pathtools, GitPython, docker-pycreds, configparser, Click, wandb
  Attempting uninstall: six
    Found existing installation: six 1.12.0
    Not uninstalling six at /cvmfs/soft.computecanada.ca/easybuild/software/2017/Core/scipy-stack/2019a/lib/python3.7/site-packages, outside environment /localscratch/yinan.29351700.0/env
    Can't uninstall 'six'. No files were found to uninstall.
Successfully installed Click-8.0.4+computecanada GitPython-3.1.24+computecanada PyYAML-5.3.1+computecanada configparser-5.0.2+computecanada docker-pycreds-0.4.0+computecanada gitdb-4.0.9+computecanada pathtools-0.1.2+computecanada promise-2.3+computecanada protobuf-3.19.4+computecanada psutil-5.7.3+computecanada sentry-sdk-1.5.0+computecanada shortuuid-1.0.1+computecanada six-1.16.0+computecanada smmap-5.0.0+computecanada subprocess32-3.5.4+computecanada termcolor-1.1.0+computecanada typing-extensions-4.1.1+computecanada wandb-0.12.5+computecanada yaspin-2.1.0+computecanada
Looking in links: /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/nix/avx2, /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/nix/generic, /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic
ERROR: Could not find a version that satisfies the requirement sagemaker (from versions: none)
ERROR: No matching distribution found for sagemaker
Looking in links: /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/nix/avx2, /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/nix/generic, /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/torch-1.9.1+computecanada-cp37-cp37m-linux_x86_64.whl
Requirement already satisfied: typing-extensions in /localscratch/yinan.29351700.0/env/lib/python3.7/site-packages (from torch) (4.1.1+computecanada)
Installing collected packages: torch
Successfully installed torch-1.9.1+computecanada
Looking in links: /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/nix/avx2, /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/nix/generic, /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/transformers-2.5.1+computecanada-py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/tokenizers-0.5.2+computecanada-cp37-cp37m-linux_x86_64.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/sentencepiece-0.1.91+computecanada-cp37-cp37m-linux_x86_64.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/filelock-3.4.2+computecanada-py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/tqdm-4.63.1+computecanada-py2.py3-none-any.whl
Requirement already satisfied: numpy in /cvmfs/soft.computecanada.ca/easybuild/software/2017/Core/scipy-stack/2019a/lib/python3.7/site-packages (from transformers==2.5.1+computecanada) (1.16.0)
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/regex-2020.11.13+computecanada-cp37-cp37m-linux_x86_64.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/sacremoses-0.0.49+computecanada-py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/boto3-1.21.14+computecanada-py3-none-any.whl
Requirement already satisfied: requests in /cvmfs/soft.computecanada.ca/easybuild/software/2017/Core/scipy-stack/2019a/lib/python3.7/site-packages (from transformers==2.5.1+computecanada) (2.21.0)
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/botocore-1.24.14+computecanada-py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/jmespath-0.10.0+computecanada-py2.py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/s3transfer-0.5.1+computecanada-py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/urllib3-1.26.8+computecanada-py2.py3-none-any.whl
Requirement already satisfied: python-dateutil<3.0.0,>=2.1 in /cvmfs/soft.computecanada.ca/easybuild/software/2017/Core/scipy-stack/2019a/lib/python3.7/site-packages (from botocore<1.25.0,>=1.24.14->boto3->transformers==2.5.1+computecanada) (2.7.5)
Requirement already satisfied: six>=1.5 in /localscratch/yinan.29351700.0/env/lib/python3.7/site-packages (from python-dateutil<3.0.0,>=2.1->botocore<1.25.0,>=1.24.14->boto3->transformers==2.5.1+computecanada) (1.16.0+computecanada)
Requirement already satisfied: idna<2.9,>=2.5 in /cvmfs/soft.computecanada.ca/easybuild/software/2017/Core/scipy-stack/2019a/lib/python3.7/site-packages (from requests->transformers==2.5.1+computecanada) (2.8)
Requirement already satisfied: certifi>=2017.4.17 in /cvmfs/soft.computecanada.ca/easybuild/software/2017/Core/scipy-stack/2019a/lib/python3.7/site-packages (from requests->transformers==2.5.1+computecanada) (2018.11.29)
Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /cvmfs/soft.computecanada.ca/easybuild/software/2017/Core/scipy-stack/2019a/lib/python3.7/site-packages (from requests->transformers==2.5.1+computecanada) (3.0.4)
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/requests-2.27.1+computecanada-py2.py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/charset_normalizer-2.0.12+computecanada-py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/joblib-1.1.0+computecanada-py2.py3-none-any.whl
Requirement already satisfied: click in /localscratch/yinan.29351700.0/env/lib/python3.7/site-packages (from sacremoses->transformers==2.5.1+computecanada) (8.0.4+computecanada)
Requirement already satisfied: importlib-metadata in /cvmfs/soft.computecanada.ca/easybuild/software/2017/Core/scipy-stack/2019a/lib/python3.7/site-packages (from click->sacremoses->transformers==2.5.1+computecanada) (0.8)
Requirement already satisfied: zipp>=0.3.2 in /cvmfs/soft.computecanada.ca/easybuild/software/2017/Core/scipy-stack/2019a/lib/python3.7/site-packages (from importlib-metadata->click->sacremoses->transformers==2.5.1+computecanada) (0.3.3)
Installing collected packages: urllib3, jmespath, botocore, tqdm, s3transfer, regex, joblib, charset-normalizer, tokenizers, sentencepiece, sacremoses, requests, filelock, boto3, transformers
  Attempting uninstall: urllib3
    Found existing installation: urllib3 1.24.1
    Not uninstalling urllib3 at /cvmfs/soft.computecanada.ca/easybuild/software/2017/Core/scipy-stack/2019a/lib/python3.7/site-packages, outside environment /localscratch/yinan.29351700.0/env
    Can't uninstall 'urllib3'. No files were found to uninstall.
  Attempting uninstall: requests
    Found existing installation: requests 2.21.0
    Not uninstalling requests at /cvmfs/soft.computecanada.ca/easybuild/software/2017/Core/scipy-stack/2019a/lib/python3.7/site-packages, outside environment /localscratch/yinan.29351700.0/env
    Can't uninstall 'requests'. No files were found to uninstall.
Successfully installed boto3-1.21.14+computecanada botocore-1.24.14+computecanada charset-normalizer-2.0.12+computecanada filelock-3.4.2+computecanada jmespath-0.10.0+computecanada joblib-1.1.0+computecanada regex-2020.11.13+computecanada requests-2.27.1+computecanada s3transfer-0.5.1+computecanada sacremoses-0.0.49+computecanada sentencepiece-0.1.91+computecanada tokenizers-0.5.2+computecanada tqdm-4.63.1+computecanada transformers-2.5.1+computecanada urllib3-1.26.8+computecanada
Looking in links: /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/nix/avx2, /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/nix/generic, /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/tensorflow_gpu-2.3.0+computecanada-cp37-cp37m-linux_x86_64.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/google_pasta-0.2.0+computecanada-py3-none-any.whl
Requirement already satisfied: termcolor>=1.1.0 in /localscratch/yinan.29351700.0/env/lib/python3.7/site-packages (from tensorflow_gpu==2.3.0+computecanada) (1.1.0+computecanada)
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/grpcio-1.38.0+computecanada-cp37-cp37m-linux_x86_64.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/nix/generic/scipy-1.4.1+computecanada-cp37-cp37m-linux_x86_64.whl
Requirement already satisfied: numpy<1.19.0,>=1.16.0 in /cvmfs/soft.computecanada.ca/easybuild/software/2017/Core/scipy-stack/2019a/lib/python3.7/site-packages (from tensorflow_gpu==2.3.0+computecanada) (1.16.0)
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/tensorflow_estimator-2.3.0+computecanada-py2.py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/wrapt-1.11.2+computecanada-cp37-cp37m-linux_x86_64.whl
Requirement already satisfied: wheel>=0.26 in /localscratch/yinan.29351700.0/env/lib/python3.7/site-packages (from tensorflow_gpu==2.3.0+computecanada) (0.33.4)
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/gast-0.3.3+computecanada-py3-none-any.whl
Requirement already satisfied: six>=1.12.0 in /localscratch/yinan.29351700.0/env/lib/python3.7/site-packages (from tensorflow_gpu==2.3.0+computecanada) (1.16.0+computecanada)
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/astunparse-1.6.3+computecanada-py2.py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/tensorboard-2.8.0+computecanada-py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/Keras_Preprocessing-1.1.2+computecanada-py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/nix/avx2/h5py-2.10.0+computecanada-cp37-cp37m-linux_x86_64.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/opt_einsum-3.3.0+computecanada-py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/absl_py-1.0.0+computecanada-py3-none-any.whl
Requirement already satisfied: protobuf>=3.9.2 in /localscratch/yinan.29351700.0/env/lib/python3.7/site-packages (from tensorflow_gpu==2.3.0+computecanada) (3.19.4+computecanada)
Requirement already satisfied: requests<3,>=2.21.0 in /localscratch/yinan.29351700.0/env/lib/python3.7/site-packages (from tensorboard<3,>=2.3.0->tensorflow_gpu==2.3.0+computecanada) (2.27.1+computecanada)
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/Markdown-3.3.6+computecanada-py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/Werkzeug-2.0.3+computecanada-py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/google_auth_oauthlib-0.4.6+computecanada-py2.py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/tensorboard_data_server-0.6.1+computecanada-py3-none-linux_x86_64.whl
Requirement already satisfied: setuptools>=41.0.0 in /localscratch/yinan.29351700.0/env/lib/python3.7/site-packages (from tensorboard<3,>=2.3.0->tensorflow_gpu==2.3.0+computecanada) (41.0.1)
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/google_auth-2.3.3+computecanada-py2.py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/tensorboard_plugin_wit-1.8.0+computecanada-py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/rsa-4.8+computecanada-py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/cachetools-4.2.4+computecanada-py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/pyasn1_modules-0.2.8+computecanada-py2.py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/requests_oauthlib-1.3.0+computecanada-py2.py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/importlib_metadata-4.10.1+computecanada-py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/zipp-3.7.0+computecanada-py3-none-any.whl
Requirement already satisfied: typing-extensions>=3.6.4 in /localscratch/yinan.29351700.0/env/lib/python3.7/site-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard<3,>=2.3.0->tensorflow_gpu==2.3.0+computecanada) (4.1.1+computecanada)
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/pyasn1-0.4.8+computecanada-py2.py3-none-any.whl
Requirement already satisfied: urllib3<1.27,>=1.21.1 in /localscratch/yinan.29351700.0/env/lib/python3.7/site-packages (from requests<3,>=2.21.0->tensorboard<3,>=2.3.0->tensorflow_gpu==2.3.0+computecanada) (1.26.8+computecanada)
Requirement already satisfied: certifi>=2017.4.17 in /cvmfs/soft.computecanada.ca/easybuild/software/2017/Core/scipy-stack/2019a/lib/python3.7/site-packages (from requests<3,>=2.21.0->tensorboard<3,>=2.3.0->tensorflow_gpu==2.3.0+computecanada) (2018.11.29)
Requirement already satisfied: charset-normalizer~=2.0.0 in /localscratch/yinan.29351700.0/env/lib/python3.7/site-packages (from requests<3,>=2.21.0->tensorboard<3,>=2.3.0->tensorflow_gpu==2.3.0+computecanada) (2.0.12+computecanada)
Requirement already satisfied: idna<4,>=2.5 in /cvmfs/soft.computecanada.ca/easybuild/software/2017/Core/scipy-stack/2019a/lib/python3.7/site-packages (from requests<3,>=2.21.0->tensorboard<3,>=2.3.0->tensorflow_gpu==2.3.0+computecanada) (2.8)
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/oauthlib-3.1.1+computecanada-py2.py3-none-any.whl
Installing collected packages: pyasn1, zipp, rsa, pyasn1-modules, oauthlib, cachetools, requests-oauthlib, importlib-metadata, google-auth, werkzeug, tensorboard-plugin-wit, tensorboard-data-server, markdown, grpcio, google-auth-oauthlib, absl-py, wrapt, tensorflow-estimator, tensorboard, scipy, opt-einsum, keras-preprocessing, h5py, google-pasta, gast, astunparse, tensorflow-gpu
  Attempting uninstall: pyasn1
    Found existing installation: pyasn1 0.4.3
    Not uninstalling pyasn1 at /cvmfs/soft.computecanada.ca/easybuild/software/2017/Core/scipy-stack/2019a/lib/python3.7/site-packages, outside environment /localscratch/yinan.29351700.0/env
    Can't uninstall 'pyasn1'. No files were found to uninstall.
  Attempting uninstall: zipp
    Found existing installation: zipp 0.3.3
    Not uninstalling zipp at /cvmfs/soft.computecanada.ca/easybuild/software/2017/Core/scipy-stack/2019a/lib/python3.7/site-packages, outside environment /localscratch/yinan.29351700.0/env
    Can't uninstall 'zipp'. No files were found to uninstall.
  Attempting uninstall: importlib-metadata
    Found existing installation: importlib-metadata 0.8
    Not uninstalling importlib-metadata at /cvmfs/soft.computecanada.ca/easybuild/software/2017/Core/scipy-stack/2019a/lib/python3.7/site-packages, outside environment /localscratch/yinan.29351700.0/env
    Can't uninstall 'importlib-metadata'. No files were found to uninstall.
  Attempting uninstall: scipy
    Found existing installation: scipy 1.2.0
    Not uninstalling scipy at /cvmfs/soft.computecanada.ca/easybuild/software/2017/Core/scipy-stack/2019a/lib/python3.7/site-packages, outside environment /localscratch/yinan.29351700.0/env
    Can't uninstall 'scipy'. No files were found to uninstall.
Successfully installed absl-py-1.0.0+computecanada astunparse-1.6.3+computecanada cachetools-4.2.4+computecanada gast-0.3.3+computecanada google-auth-2.3.3+computecanada google-auth-oauthlib-0.4.6+computecanada google-pasta-0.2.0+computecanada grpcio-1.38.0+computecanada h5py-2.10.0+computecanada importlib-metadata-4.10.1+computecanada keras-preprocessing-1.1.2+computecanada markdown-3.3.6+computecanada oauthlib-3.1.1+computecanada opt-einsum-3.3.0+computecanada pyasn1-0.4.8+computecanada pyasn1-modules-0.2.8+computecanada requests-oauthlib-1.3.0+computecanada rsa-4.8+computecanada scipy-1.4.1+computecanada tensorboard-2.8.0+computecanada tensorboard-data-server-0.6.1+computecanada tensorboard-plugin-wit-1.8.0+computecanada tensorflow-estimator-2.3.0+computecanada tensorflow-gpu-2.3.0+computecanada werkzeug-2.0.3+computecanada wrapt-1.11.2+computecanada zipp-3.7.0+computecanada
Looking in links: /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/nix/avx2, /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/nix/generic, /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/keras-2.8.0+computecanada-py2.py3-none-any.whl
Installing collected packages: Keras
Successfully installed Keras-2.8.0+computecanada
Looking in links: /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/nix/avx2, /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/nix/generic, /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/urllib3-1.26.7+computecanada-py2.py3-none-any.whl
Installing collected packages: urllib3
  Attempting uninstall: urllib3
    Found existing installation: urllib3 1.26.8+computecanada
    Uninstalling urllib3-1.26.8+computecanada:
      Successfully uninstalled urllib3-1.26.8+computecanada
Successfully installed urllib3-1.26.7+computecanada
Looking in links: /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/nix/avx2, /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/nix/generic, /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/nltk-3.7+computecanada-py3-none-any.whl
Requirement already satisfied: tqdm in /localscratch/yinan.29351700.0/env/lib/python3.7/site-packages (from nltk) (4.63.1+computecanada)
Requirement already satisfied: joblib in /localscratch/yinan.29351700.0/env/lib/python3.7/site-packages (from nltk) (1.1.0+computecanada)
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/nltk-3.6.5+computecanada-py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/nltk-3.6.3+computecanada-py3-none-any.whl
Requirement already satisfied: click in /localscratch/yinan.29351700.0/env/lib/python3.7/site-packages (from nltk) (8.0.4+computecanada)
Requirement already satisfied: regex in /localscratch/yinan.29351700.0/env/lib/python3.7/site-packages (from nltk) (2020.11.13+computecanada)
Requirement already satisfied: importlib-metadata in /localscratch/yinan.29351700.0/env/lib/python3.7/site-packages (from click->nltk) (4.10.1+computecanada)
Requirement already satisfied: zipp>=0.5 in /localscratch/yinan.29351700.0/env/lib/python3.7/site-packages (from importlib-metadata->click->nltk) (3.7.0+computecanada)
Requirement already satisfied: typing-extensions>=3.6.4 in /localscratch/yinan.29351700.0/env/lib/python3.7/site-packages (from importlib-metadata->click->nltk) (4.1.1+computecanada)
Installing collected packages: nltk
Successfully installed nltk-3.6.3+computecanada
Looking in links: /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/nix/avx2, /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/nix/generic, /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/scikit_learn-0.22.1+computecanada-cp37-cp37m-linux_x86_64.whl
Requirement already satisfied: joblib>=0.11 in /localscratch/yinan.29351700.0/env/lib/python3.7/site-packages (from scikit-learn==0.22.1) (1.1.0+computecanada)
Requirement already satisfied: scipy>=0.17.0 in /localscratch/yinan.29351700.0/env/lib/python3.7/site-packages (from scikit-learn==0.22.1) (1.4.1+computecanada)
Requirement already satisfied: numpy>=1.11.0 in /cvmfs/soft.computecanada.ca/easybuild/software/2017/Core/scipy-stack/2019a/lib/python3.7/site-packages (from scikit-learn==0.22.1) (1.16.0)
Installing collected packages: scikit-learn
Successfully installed scikit-learn-0.22.1+computecanada
Looking in links: /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/nix/avx2, /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/nix/generic, /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic
Requirement already satisfied: tokenizers==0.5.2 in /localscratch/yinan.29351700.0/env/lib/python3.7/site-packages (0.5.2+computecanada)
wandb: Appending key for api.wandb.ai to your netrc file: /home/yinan/.netrc
Starting Task
2022-03-25 22:54:10.394622: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1
[nltk_data] Downloading package stopwords to /home/yinan/nltk_data...
[nltk_data]   Package stopwords is already up-to-date!
[nltk_data] Downloading package wordnet to /home/yinan/nltk_data...
[nltk_data]   Package wordnet is already up-to-date!
wandb: Currently logged in as: yinanazhou (use `wandb login --relogin` to force relogin)
wandb: wandb version 0.12.11 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
2022-03-25 22:54:29.011188: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1
wandb: Tracking run with wandb version 0.12.5
wandb: Syncing run revived-vortex-1
wandb: ⭐️ View project at https://wandb.ai/yinanazhou/xl_512_bs_8_lr_1e06_es_10_lc_True_nr_True_sr_False_stem_True_lemma_False_repeat_1_fold_1
wandb: 🚀 View run at https://wandb.ai/yinanazhou/xl_512_bs_8_lr_1e06_es_10_lc_True_nr_True_sr_False_stem_True_lemma_False_repeat_1_fold_1/runs/2ewmvvn4
wandb: Run data is saved locally in /project/6002780/yinan/Thesis_MER_Lyrics/lyric-emotion/wandb/run-20220325_225426-2ewmvvn4
wandb: Run `wandb offline` to turn off syncing.

Validation loss decreased (inf --> 1.432099).  Saving model ...
Validation loss decreased (1.432099 --> 1.413042).  Saving model ...
Validation loss decreased (1.413042 --> 1.397420).  Saving model ...
Validation loss decreased (1.397420 --> 1.385428).  Saving model ...
Validation loss decreased (1.385428 --> 1.375896).  Saving model ...
Validation loss decreased (1.375896 --> 1.367919).  Saving model ...
Validation loss decreased (1.367919 --> 1.361894).  Saving model ...
Validation loss decreased (1.361894 --> 1.356860).  Saving model ...
Validation loss decreased (1.356860 --> 1.352237).  Saving model ...
Validation loss decreased (1.352237 --> 1.347321).  Saving model ...
Validation loss decreased (1.347321 --> 1.342617).  Saving model ...
Validation loss decreased (1.342617 --> 1.338253).  Saving model ...
Validation loss decreased (1.338253 --> 1.334217).  Saving model ...
Validation loss decreased (1.334217 --> 1.330290).  Saving model ...
Validation loss decreased (1.330290 --> 1.325548).  Saving model ...
Validation loss decreased (1.325548 --> 1.322206).  Saving model ...
Validation loss decreased (1.322206 --> 1.318300).  Saving model ...
Validation loss decreased (1.318300 --> 1.313757).  Saving model ...
Validation loss decreased (1.313757 --> 1.309400).  Saving model ...
Validation loss decreased (1.309400 --> 1.305234).  Saving model ...
Validation loss decreased (1.305234 --> 1.300542).  Saving model ...
Validation loss decreased (1.300542 --> 1.294707).  Saving model ...
Validation loss decreased (1.294707 --> 1.290077).  Saving model ...
Validation loss decreased (1.290077 --> 1.284932).  Saving model ...
Validation loss decreased (1.284932 --> 1.279157).  Saving model ...
Validation loss decreased (1.279157 --> 1.274154).  Saving model ...
Validation loss decreased (1.274154 --> 1.268793).  Saving model ...
Validation loss decreased (1.268793 --> 1.265855).  Saving model ...
Validation loss decreased (1.265855 --> 1.263404).  Saving model ...
Validation loss decreased (1.263404 --> 1.260792).  Saving model ...
Validation loss decreased (1.260792 --> 1.257329).  Saving model ...
Validation loss decreased (1.257329 --> 1.252960).  Saving model ...
Validation loss decreased (1.252960 --> 1.251427).  Saving model ...
Validation loss decreased (1.251427 --> 1.245611).  Saving model ...
Validation loss decreased (1.245611 --> 1.242135).  Saving model ...
Validation loss decreased (1.242135 --> 1.239153).  Saving model ...
Validation loss decreased (1.239153 --> 1.234749).  Saving model ...
Validation loss decreased (1.234749 --> 1.232723).  Saving model ...
Validation loss decreased (1.232723 --> 1.230316).  Saving model ...
Validation loss decreased (1.230316 --> 1.228334).  Saving model ...
Validation loss decreased (1.228334 --> 1.223766).  Saving model ...
Validation loss decreased (1.223766 --> 1.219358).  Saving model ...
Validation loss decreased (1.219358 --> 1.216698).  Saving model ...
EarlyStopping counter: 1 out of 10.0
Validation loss decreased (1.216698 --> 1.213713).  Saving model ...
Validation loss decreased (1.213713 --> 1.211325).  Saving model ...
EarlyStopping counter: 1 out of 10.0
Validation loss decreased (1.211325 --> 1.209955).  Saving model ...
Validation loss decreased (1.209955 --> 1.203083).  Saving model ...
Validation loss decreased (1.203083 --> 1.198370).  Saving model ...
Validation loss decreased (1.198370 --> 1.197020).  Saving model ...
Validation loss decreased (1.197020 --> 1.193911).  Saving model ...
Validation loss decreased (1.193911 --> 1.193876).  Saving model ...
Validation loss decreased (1.193876 --> 1.190228).  Saving model ...
EarlyStopping counter: 1 out of 10.0
Validation loss decreased (1.190228 --> 1.185514).  Saving model ...
Validation loss decreased (1.185514 --> 1.178811).  Saving model ...
Validation loss decreased (1.178811 --> 1.176774).  Saving model ...
Validation loss decreased (1.176774 --> 1.173089).  Saving model ...
EarlyStopping counter: 1 out of 10.0
Validation loss decreased (1.173089 --> 1.171397).  Saving model ...
Validation loss decreased (1.171397 --> 1.171198).  Saving model ...
Validation loss decreased (1.171198 --> 1.166246).  Saving model ...
Validation loss decreased (1.166246 --> 1.165828).  Saving model ...
Validation loss decreased (1.165828 --> 1.163128).  Saving model ...
Validation loss decreased (1.163128 --> 1.157968).  Saving model ...
Validation loss decreased (1.157968 --> 1.157533).  Saving model ...
Validation loss decreased (1.157533 --> 1.154896).  Saving model ...
Validation loss decreased (1.154896 --> 1.153766).  Saving model ...
Validation loss decreased (1.153766 --> 1.152341).  Saving model ...
Validation loss decreased (1.152341 --> 1.147907).  Saving model ...
Validation loss decreased (1.147907 --> 1.143615).  Saving model ...
Validation loss decreased (1.143615 --> 1.140623).  Saving model ...
Validation loss decreased (1.140623 --> 1.135741).  Saving model ...
Validation loss decreased (1.135741 --> 1.135268).  Saving model ...
EarlyStopping counter: 1 out of 10.0
EarlyStopping counter: 2 out of 10.0
Validation loss decreased (1.135268 --> 1.131094).  Saving model ...
Validation loss decreased (1.131094 --> 1.124207).  Saving model ...
EarlyStopping counter: 1 out of 10.0
EarlyStopping counter: 2 out of 10.0
EarlyStopping counter: 3 out of 10.0
Validation loss decreased (1.124207 --> 1.123252).  Saving model ...
Validation loss decreased (1.123252 --> 1.117848).  Saving model ...
Validation loss decreased (1.117848 --> 1.117503).  Saving model ...
Validation loss decreased (1.117503 --> 1.113976).  Saving model ...
Validation loss decreased (1.113976 --> 1.105446).  Saving model ...
EarlyStopping counter: 1 out of 10.0
Validation loss decreased (1.105446 --> 1.103815).  Saving model ...
EarlyStopping counter: 1 out of 10.0
EarlyStopping counter: 2 out of 10.0
EarlyStopping counter: 3 out of 10.0
Validation loss decreased (1.103815 --> 1.103791).  Saving model ...
EarlyStopping counter: 1 out of 10.0
Validation loss decreased (1.103791 --> 1.101895).  Saving model ...
Validation loss decreased (1.101895 --> 1.100773).  Saving model ...
Validation loss decreased (1.100773 --> 1.099139).  Saving model ...
Validation loss decreased (1.099139 --> 1.096064).  Saving model ...
Validation loss decreased (1.096064 --> 1.092445).  Saving model ...
EarlyStopping counter: 1 out of 10.0
EarlyStopping counter: 2 out of 10.0
Validation loss decreased (1.092445 --> 1.091686).  Saving model ...
Validation loss decreased (1.091686 --> 1.086334).  Saving model ...
Validation loss decreased (1.086334 --> 1.082824).  Saving model ...
EarlyStopping counter: 1 out of 10.0
Validation loss decreased (1.082824 --> 1.079774).  Saving model ...
EarlyStopping counter: 1 out of 10.0
EarlyStopping counter: 2 out of 10.0
Validation loss decreased (1.079774 --> 1.077148).  Saving model ...
Validation loss decreased (1.077148 --> 1.075520).  Saving model ...
EarlyStopping counter: 1 out of 10.0
EarlyStopping counter: 2 out of 10.0
EarlyStopping counter: 3 out of 10.0
Validation loss decreased (1.075520 --> 1.073732).  Saving model ...
EarlyStopping counter: 1 out of 10.0
EarlyStopping counter: 2 out of 10.0
Validation loss decreased (1.073732 --> 1.070758).  Saving model ...
EarlyStopping counter: 1 out of 10.0
Validation loss decreased (1.070758 --> 1.070594).  Saving model ...
Validation loss decreased (1.070594 --> 1.062531).  Saving model ...
Validation loss decreased (1.062531 --> 1.062460).  Saving model ...
Validation loss decreased (1.062460 --> 1.060279).  Saving model ...
Validation loss decreased (1.060279 --> 1.058972).  Saving model ...
Validation loss decreased (1.058972 --> 1.057617).  Saving model ...
Validation loss decreased (1.057617 --> 1.055909).  Saving model ...
EarlyStopping counter: 1 out of 10.0
EarlyStopping counter: 2 out of 10.0
EarlyStopping counter: 3 out of 10.0
EarlyStopping counter: 4 out of 10.0
Validation loss decreased (1.055909 --> 1.055608).  Saving model ...
EarlyStopping counter: 1 out of 10.0
EarlyStopping counter: 2 out of 10.0
EarlyStopping counter: 3 out of 10.0
Validation loss decreased (1.055608 --> 1.052813).  Saving model ...
EarlyStopping counter: 1 out of 10.0
EarlyStopping counter: 2 out of 10.0
Validation loss decreased (1.052813 --> 1.050601).  Saving model ...
Validation loss decreased (1.050601 --> 1.047282).  Saving model ...
Validation loss decreased (1.047282 --> 1.045825).  Saving model ...
Validation loss decreased (1.045825 --> 1.044961).  Saving model ...
EarlyStopping counter: 1 out of 10.0
EarlyStopping counter: 2 out of 10.0
EarlyStopping counter: 3 out of 10.0
EarlyStopping counter: 4 out of 10.0
EarlyStopping counter: 5 out of 10.0
Validation loss decreased (1.044961 --> 1.043559).  Saving model ...
EarlyStopping counter: 1 out of 10.0
Validation loss decreased (1.043559 --> 1.041746).  Saving model ...
EarlyStopping counter: 1 out of 10.0
Validation loss decreased (1.041746 --> 1.041131).  Saving model ...
EarlyStopping counter: 1 out of 10.0
EarlyStopping counter: 2 out of 10.0
EarlyStopping counter: 3 out of 10.0
EarlyStopping counter: 4 out of 10.0
EarlyStopping counter: 5 out of 10.0
EarlyStopping counter: 6 out of 10.0
EarlyStopping counter: 7 out of 10.0
EarlyStopping counter: 8 out of 10.0
EarlyStopping counter: 9 out of 10.0
EarlyStopping counter: 10 out of 10.0
/localscratch/yinan.29351700.0/env/lib/python3.7/site-packages/torch/nn/functional.py:1794: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.
  warnings.warn("nn.functional.tanh is deprecated. Use torch.tanh instead.")
/localscratch/yinan.29351700.0/env/lib/python3.7/site-packages/transformers/optimization.py:155: UserWarning: This overload of add_ is deprecated:
	add_(Number alpha, Tensor other)
Consider using one of the following signatures instead:
	add_(Tensor other, *, Number alpha) (Triggered internally at  ../torch/csrc/utils/python_arg_parser.cpp:1025.)
  exp_avg.mul_(beta1).add_(1.0 - beta1, grad)
wandb: Waiting for W&B process to finish, PID 173747... (success).
wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: \ 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: | 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: / 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: \ 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: | 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: / 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: \ 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: | 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: / 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: \ 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: | 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: / 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: \ 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: | 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: / 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: \ 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: | 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: / 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: \ 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: | 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: / 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: \ 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: | 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: / 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: \ 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: | 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: / 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: \ 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: | 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: / 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: \ 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: | 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb:                                                                                
wandb: Run history:
wandb:     e_F1 ▁▃▄▅▅▅▆▅▅▆▆▆▆▆▆▆▆▇▇▇▇▇▇▇▇▇▇▇████████████
wandb:   e_loss █▇▇▆▆▆▅▅▅▅▄▄▄▄▄▃▃▃▃▃▃▂▂▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁
wandb:     t_F1 ▁▂▂▃▃▃▄▄▅▅▅▅▅▅▆▆▆▅▆▆▆▆▆▇▇▇▇▇▇▇▇▇▇▇▇▇▇█▇█
wandb:   t_loss █▇█▇▇▇▆▆▆▅▅▅▅▅▄▄▄▄▃▃▃▃▃▃▂▂▂▂▂▂▂▂▂▂▂▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:     e_F1 53.89179
wandb:   e_loss 1.05202
wandb:     t_F1 71.30602
wandb:   t_loss 0.75776
wandb: 
wandb: Synced 4 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Synced revived-vortex-1: https://wandb.ai/yinanazhou/xl_512_bs_8_lr_1e06_es_10_lc_True_nr_True_sr_False_stem_True_lemma_False_repeat_1_fold_1/runs/2ewmvvn4
wandb: Find logs at: ./wandb/run-20220325_225426-2ewmvvn4/logs/debug.log
wandb: 

wandb: wandb version 0.12.11 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
2022-03-26 00:36:58.203023: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1
wandb: Tracking run with wandb version 0.12.5
wandb: Syncing run blooming-star-1
wandb: ⭐️ View project at https://wandb.ai/yinanazhou/xl_512_bs_8_lr_1e06_es_10_lc_True_nr_True_sr_False_stem_True_lemma_False_repeat_1_fold_2
wandb: 🚀 View run at https://wandb.ai/yinanazhou/xl_512_bs_8_lr_1e06_es_10_lc_True_nr_True_sr_False_stem_True_lemma_False_repeat_1_fold_2/runs/zw9wzm6d
wandb: Run data is saved locally in /project/6002780/yinan/Thesis_MER_Lyrics/lyric-emotion/wandb/run-20220326_003656-zw9wzm6d
wandb: Run `wandb offline` to turn off syncing.

Validation loss decreased (inf --> 1.412207).  Saving model ...
Validation loss decreased (1.412207 --> 1.399039).  Saving model ...
Validation loss decreased (1.399039 --> 1.390097).  Saving model ...
Validation loss decreased (1.390097 --> 1.383057).  Saving model ...
Validation loss decreased (1.383057 --> 1.377420).  Saving model ...
Validation loss decreased (1.377420 --> 1.372315).  Saving model ...
Validation loss decreased (1.372315 --> 1.368059).  Saving model ...
Validation loss decreased (1.368059 --> 1.364974).  Saving model ...
Validation loss decreased (1.364974 --> 1.361622).  Saving model ...
Validation loss decreased (1.361622 --> 1.357941).  Saving model ...
Validation loss decreased (1.357941 --> 1.354756).  Saving model ...
Validation loss decreased (1.354756 --> 1.351119).  Saving model ...
Validation loss decreased (1.351119 --> 1.347858).  Saving model ...
Validation loss decreased (1.347858 --> 1.344622).  Saving model ...
Validation loss decreased (1.344622 --> 1.341025).  Saving model ...
Validation loss decreased (1.341025 --> 1.337506).  Saving model ...
Validation loss decreased (1.337506 --> 1.333749).  Saving model ...
Validation loss decreased (1.333749 --> 1.329185).  Saving model ...
Validation loss decreased (1.329185 --> 1.325156).  Saving model ...
Validation loss decreased (1.325156 --> 1.320923).  Saving model ...
Validation loss decreased (1.320923 --> 1.316491).  Saving model ...
Validation loss decreased (1.316491 --> 1.312297).  Saving model ...
Validation loss decreased (1.312297 --> 1.307841).  Saving model ...
Validation loss decreased (1.307841 --> 1.303545).  Saving model ...
Validation loss decreased (1.303545 --> 1.299729).  Saving model ...
Validation loss decreased (1.299729 --> 1.295630).  Saving model ...
Validation loss decreased (1.295630 --> 1.290486).  Saving model ...
Validation loss decreased (1.290486 --> 1.285663).  Saving model ...
Validation loss decreased (1.285663 --> 1.280173).  Saving model ...
Validation loss decreased (1.280173 --> 1.275156).  Saving model ...
Validation loss decreased (1.275156 --> 1.270373).  Saving model ...
Validation loss decreased (1.270373 --> 1.264625).  Saving model ...
Validation loss decreased (1.264625 --> 1.259203).  Saving model ...
Validation loss decreased (1.259203 --> 1.253706).  Saving model ...
Validation loss decreased (1.253706 --> 1.248703).  Saving model ...
Validation loss decreased (1.248703 --> 1.243150).  Saving model ...
Validation loss decreased (1.243150 --> 1.237758).  Saving model ...
Validation loss decreased (1.237758 --> 1.231595).  Saving model ...
Validation loss decreased (1.231595 --> 1.225740).  Saving model ...
Validation loss decreased (1.225740 --> 1.220536).  Saving model ...
Validation loss decreased (1.220536 --> 1.215143).  Saving model ...
Validation loss decreased (1.215143 --> 1.209193).  Saving model ...
Validation loss decreased (1.209193 --> 1.203639).  Saving model ...
Validation loss decreased (1.203639 --> 1.197911).  Saving model ...
Validation loss decreased (1.197911 --> 1.192503).  Saving model ...
Validation loss decreased (1.192503 --> 1.186373).  Saving model ...
Validation loss decreased (1.186373 --> 1.182162).  Saving model ...
Validation loss decreased (1.182162 --> 1.177134).  Saving model ...
Validation loss decreased (1.177134 --> 1.172521).  Saving model ...
Validation loss decreased (1.172521 --> 1.166839).  Saving model ...
Validation loss decreased (1.166839 --> 1.161437).  Saving model ...
Validation loss decreased (1.161437 --> 1.156487).  Saving model ...
Validation loss decreased (1.156487 --> 1.151331).  Saving model ...
Validation loss decreased (1.151331 --> 1.147012).  Saving model ...
Validation loss decreased (1.147012 --> 1.141745).  Saving model ...
Validation loss decreased (1.141745 --> 1.136981).  Saving model ...
Validation loss decreased (1.136981 --> 1.133643).  Saving model ...
Validation loss decreased (1.133643 --> 1.128862).  Saving model ...
Validation loss decreased (1.128862 --> 1.124135).  Saving model ...
Validation loss decreased (1.124135 --> 1.119523).  Saving model ...
Validation loss decreased (1.119523 --> 1.115273).  Saving model ...
Validation loss decreased (1.115273 --> 1.111780).  Saving model ...
Validation loss decreased (1.111780 --> 1.106311).  Saving model ...
Validation loss decreased (1.106311 --> 1.101860).  Saving model ...
Validation loss decreased (1.101860 --> 1.098753).  Saving model ...
Validation loss decreased (1.098753 --> 1.094322).  Saving model ...
Validation loss decreased (1.094322 --> 1.090372).  Saving model ...
Validation loss decreased (1.090372 --> 1.085819).  Saving model ...
Validation loss decreased (1.085819 --> 1.081962).  Saving model ...
Validation loss decreased (1.081962 --> 1.077919).  Saving model ...
Validation loss decreased (1.077919 --> 1.073968).  Saving model ...
Validation loss decreased (1.073968 --> 1.070188).  Saving model ...
Validation loss decreased (1.070188 --> 1.067246).  Saving model ...
Validation loss decreased (1.067246 --> 1.064293).  Saving model ...
Validation loss decreased (1.064293 --> 1.061737).  Saving model ...
Validation loss decreased (1.061737 --> 1.058806).  Saving model ...
Validation loss decreased (1.058806 --> 1.054858).  Saving model ...
Validation loss decreased (1.054858 --> 1.050757).  Saving model ...
Validation loss decreased (1.050757 --> 1.048842).  Saving model ...
Validation loss decreased (1.048842 --> 1.046160).  Saving model ...
Validation loss decreased (1.046160 --> 1.043192).  Saving model ...
Validation loss decreased (1.043192 --> 1.039344).  Saving model ...
Validation loss decreased (1.039344 --> 1.035354).  Saving model ...
Validation loss decreased (1.035354 --> 1.033048).  Saving model ...
Validation loss decreased (1.033048 --> 1.030403).  Saving model ...
Validation loss decreased (1.030403 --> 1.026925).  Saving model ...
Validation loss decreased (1.026925 --> 1.023632).  Saving model ...
Validation loss decreased (1.023632 --> 1.021469).  Saving model ...
Validation loss decreased (1.021469 --> 1.020309).  Saving model ...
Validation loss decreased (1.020309 --> 1.017381).  Saving model ...
Validation loss decreased (1.017381 --> 1.013631).  Saving model ...
Validation loss decreased (1.013631 --> 1.011921).  Saving model ...
Validation loss decreased (1.011921 --> 1.010046).  Saving model ...
Validation loss decreased (1.010046 --> 1.006680).  Saving model ...
Validation loss decreased (1.006680 --> 1.005351).  Saving model ...
Validation loss decreased (1.005351 --> 1.003748).  Saving model ...
Validation loss decreased (1.003748 --> 1.001295).  Saving model ...
Validation loss decreased (1.001295 --> 1.000605).  Saving model ...
Validation loss decreased (1.000605 --> 0.999553).  Saving model ...
Validation loss decreased (0.999553 --> 0.995893).  Saving model ...
Validation loss decreased (0.995893 --> 0.993803).  Saving model ...
Validation loss decreased (0.993803 --> 0.992386).  Saving model ...
Validation loss decreased (0.992386 --> 0.990459).  Saving model ...
Validation loss decreased (0.990459 --> 0.987084).  Saving model ...
Validation loss decreased (0.987084 --> 0.985283).  Saving model ...
Validation loss decreased (0.985283 --> 0.983112).  Saving model ...
Validation loss decreased (0.983112 --> 0.982226).  Saving model ...
Validation loss decreased (0.982226 --> 0.981889).  Saving model ...
Validation loss decreased (0.981889 --> 0.978778).  Saving model ...
Validation loss decreased (0.978778 --> 0.977539).  Saving model ...
Validation loss decreased (0.977539 --> 0.975777).  Saving model ...
Validation loss decreased (0.975777 --> 0.974153).  Saving model ...
Validation loss decreased (0.974153 --> 0.972913).  Saving model ...
Validation loss decreased (0.972913 --> 0.970872).  Saving model ...
Validation loss decreased (0.970872 --> 0.970171).  Saving model ...
Validation loss decreased (0.970171 --> 0.969634).  Saving model ...
Validation loss decreased (0.969634 --> 0.969135).  Saving model ...
Validation loss decreased (0.969135 --> 0.968174).  Saving model ...
Validation loss decreased (0.968174 --> 0.967133).  Saving model ...
Validation loss decreased (0.967133 --> 0.966412).  Saving model ...
Validation loss decreased (0.966412 --> 0.965611).  Saving model ...
Validation loss decreased (0.965611 --> 0.965057).  Saving model ...
EarlyStopping counter: 1 out of 10.0
Validation loss decreased (0.965057 --> 0.964715).  Saving model ...
Validation loss decreased (0.964715 --> 0.964521).  Saving model ...
Validation loss decreased (0.964521 --> 0.964026).  Saving model ...
Validation loss decreased (0.964026 --> 0.961868).  Saving model ...
Validation loss decreased (0.961868 --> 0.960331).  Saving model ...
Validation loss decreased (0.960331 --> 0.960097).  Saving model ...
Validation loss decreased (0.960097 --> 0.959924).  Saving model ...
Validation loss decreased (0.959924 --> 0.958094).  Saving model ...
Validation loss decreased (0.958094 --> 0.957739).  Saving model ...
EarlyStopping counter: 1 out of 10.0
EarlyStopping counter: 2 out of 10.0
EarlyStopping counter: 3 out of 10.0
EarlyStopping counter: 4 out of 10.0
EarlyStopping counter: 5 out of 10.0
EarlyStopping counter: 6 out of 10.0
Validation loss decreased (0.957739 --> 0.957067).  Saving model ...
Validation loss decreased (0.957067 --> 0.956226).  Saving model ...
Validation loss decreased (0.956226 --> 0.955723).  Saving model ...
Validation loss decreased (0.955723 --> 0.955325).  Saving model ...
EarlyStopping counter: 1 out of 10.0
EarlyStopping counter: 2 out of 10.0
EarlyStopping counter: 3 out of 10.0
Validation loss decreased (0.955325 --> 0.954906).  Saving model ...
EarlyStopping counter: 1 out of 10.0
EarlyStopping counter: 2 out of 10.0
Validation loss decreased (0.954906 --> 0.954669).  Saving model ...
EarlyStopping counter: 1 out of 10.0
Validation loss decreased (0.954669 --> 0.954610).  Saving model ...
EarlyStopping counter: 1 out of 10.0
EarlyStopping counter: 2 out of 10.0
EarlyStopping counter: 3 out of 10.0
EarlyStopping counter: 4 out of 10.0
EarlyStopping counter: 5 out of 10.0
EarlyStopping counter: 6 out of 10.0
EarlyStopping counter: 7 out of 10.0
EarlyStopping counter: 8 out of 10.0
EarlyStopping counter: 9 out of 10.0
EarlyStopping counter: 10 out of 10.0
/localscratch/yinan.29351700.0/env/lib/python3.7/site-packages/torch/nn/functional.py:1794: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.
  warnings.warn("nn.functional.tanh is deprecated. Use torch.tanh instead.")
wandb: Waiting for W&B process to finish, PID 179256... (success).
wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: \ 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: | 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: / 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: \ 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: | 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: / 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: \ 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: | 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: / 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb:                                                                                
wandb: Run history:
wandb:     e_F1 ▁▃▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇▇▇▇▇████████████████
wandb:   e_loss ██▇▇▇▇▆▆▆▅▅▅▄▄▄▃▃▃▃▃▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:     t_F1 ▁▂▂▂▃▃▃▄▄▄▅▄▅▅▆▅▅▆▆▇▆▆▆▇▇▇▇███▇█▇██▇████
wandb:   t_loss ████▇▇▇▇▇▇▆▆▆▆▅▅▅▅▄▄▄▄▄▃▃▃▃▂▂▂▂▂▂▂▁▂▁▁▁▁
wandb: 
wandb: Run summary:
wandb:     e_F1 60.2255
wandb:   e_loss 0.95777
wandb:     t_F1 72.08905
wandb:   t_loss 0.75964
wandb: 
wandb: Synced 4 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Synced blooming-star-1: https://wandb.ai/yinanazhou/xl_512_bs_8_lr_1e06_es_10_lc_True_nr_True_sr_False_stem_True_lemma_False_repeat_1_fold_2/runs/zw9wzm6d
wandb: Find logs at: ./wandb/run-20220326_003656-zw9wzm6d/logs/debug.log
wandb: 

wandb: wandb version 0.12.11 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
2022-03-26 02:20:49.616191: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1
wandb: Tracking run with wandb version 0.12.5
wandb: Syncing run glorious-snowball-1
wandb: ⭐️ View project at https://wandb.ai/yinanazhou/xl_512_bs_8_lr_1e06_es_10_lc_True_nr_True_sr_False_stem_True_lemma_False_repeat_2_fold_1
wandb: 🚀 View run at https://wandb.ai/yinanazhou/xl_512_bs_8_lr_1e06_es_10_lc_True_nr_True_sr_False_stem_True_lemma_False_repeat_2_fold_1/runs/28gj6z5d
wandb: Run data is saved locally in /project/6002780/yinan/Thesis_MER_Lyrics/lyric-emotion/wandb/run-20220326_022047-28gj6z5d
wandb: Run `wandb offline` to turn off syncing.

Validation loss decreased (inf --> 1.430411).  Saving model ...
Validation loss decreased (1.430411 --> 1.414577).  Saving model ...
Validation loss decreased (1.414577 --> 1.402227).  Saving model ...
Validation loss decreased (1.402227 --> 1.392359).  Saving model ...
Validation loss decreased (1.392359 --> 1.383959).  Saving model ...
Validation loss decreased (1.383959 --> 1.378104).  Saving model ...
Validation loss decreased (1.378104 --> 1.372689).  Saving model ...
Validation loss decreased (1.372689 --> 1.367302).  Saving model ...
Validation loss decreased (1.367302 --> 1.362473).  Saving model ...
Validation loss decreased (1.362473 --> 1.358062).  Saving model ...
Validation loss decreased (1.358062 --> 1.354037).  Saving model ...
Validation loss decreased (1.354037 --> 1.349679).  Saving model ...
Validation loss decreased (1.349679 --> 1.345593).  Saving model ...
Validation loss decreased (1.345593 --> 1.341224).  Saving model ...
Validation loss decreased (1.341224 --> 1.337089).  Saving model ...
Validation loss decreased (1.337089 --> 1.333082).  Saving model ...
Validation loss decreased (1.333082 --> 1.328927).  Saving model ...
Validation loss decreased (1.328927 --> 1.324233).  Saving model ...
Validation loss decreased (1.324233 --> 1.319171).  Saving model ...
Validation loss decreased (1.319171 --> 1.313339).  Saving model ...
Validation loss decreased (1.313339 --> 1.308049).  Saving model ...
Validation loss decreased (1.308049 --> 1.302137).  Saving model ...
Validation loss decreased (1.302137 --> 1.296104).  Saving model ...
Validation loss decreased (1.296104 --> 1.290036).  Saving model ...
Validation loss decreased (1.290036 --> 1.284680).  Saving model ...
Validation loss decreased (1.284680 --> 1.278989).  Saving model ...
Validation loss decreased (1.278989 --> 1.273166).  Saving model ...
Validation loss decreased (1.273166 --> 1.266195).  Saving model ...
Validation loss decreased (1.266195 --> 1.258455).  Saving model ...
Validation loss decreased (1.258455 --> 1.251509).  Saving model ...
Validation loss decreased (1.251509 --> 1.245784).  Saving model ...
Validation loss decreased (1.245784 --> 1.239345).  Saving model ...
Validation loss decreased (1.239345 --> 1.231235).  Saving model ...
Validation loss decreased (1.231235 --> 1.224273).  Saving model ...
Validation loss decreased (1.224273 --> 1.217980).  Saving model ...
Validation loss decreased (1.217980 --> 1.212158).  Saving model ...
Validation loss decreased (1.212158 --> 1.205960).  Saving model ...
Validation loss decreased (1.205960 --> 1.199074).  Saving model ...
Validation loss decreased (1.199074 --> 1.194047).  Saving model ...
Validation loss decreased (1.194047 --> 1.190055).  Saving model ...
Validation loss decreased (1.190055 --> 1.185099).  Saving model ...
Validation loss decreased (1.185099 --> 1.181517).  Saving model ...
Validation loss decreased (1.181517 --> 1.174503).  Saving model ...
Validation loss decreased (1.174503 --> 1.171144).  Saving model ...
Validation loss decreased (1.171144 --> 1.167604).  Saving model ...
Validation loss decreased (1.167604 --> 1.162596).  Saving model ...
Validation loss decreased (1.162596 --> 1.157254).  Saving model ...
Validation loss decreased (1.157254 --> 1.155787).  Saving model ...
Validation loss decreased (1.155787 --> 1.150294).  Saving model ...
Validation loss decreased (1.150294 --> 1.144626).  Saving model ...
Validation loss decreased (1.144626 --> 1.140799).  Saving model ...
Validation loss decreased (1.140799 --> 1.134835).  Saving model ...
Validation loss decreased (1.134835 --> 1.130422).  Saving model ...
Validation loss decreased (1.130422 --> 1.128760).  Saving model ...
Validation loss decreased (1.128760 --> 1.124877).  Saving model ...
Validation loss decreased (1.124877 --> 1.122099).  Saving model ...
Validation loss decreased (1.122099 --> 1.119442).  Saving model ...
Validation loss decreased (1.119442 --> 1.116748).  Saving model ...
Validation loss decreased (1.116748 --> 1.112030).  Saving model ...
Validation loss decreased (1.112030 --> 1.109542).  Saving model ...
Validation loss decreased (1.109542 --> 1.107355).  Saving model ...
Validation loss decreased (1.107355 --> 1.102987).  Saving model ...
Validation loss decreased (1.102987 --> 1.099854).  Saving model ...
Validation loss decreased (1.099854 --> 1.096331).  Saving model ...
Validation loss decreased (1.096331 --> 1.093943).  Saving model ...
Validation loss decreased (1.093943 --> 1.092394).  Saving model ...
Validation loss decreased (1.092394 --> 1.088402).  Saving model ...
Validation loss decreased (1.088402 --> 1.084210).  Saving model ...
Validation loss decreased (1.084210 --> 1.082666).  Saving model ...
Validation loss decreased (1.082666 --> 1.080006).  Saving model ...
Validation loss decreased (1.080006 --> 1.079285).  Saving model ...
Validation loss decreased (1.079285 --> 1.077087).  Saving model ...
Validation loss decreased (1.077087 --> 1.073595).  Saving model ...
Validation loss decreased (1.073595 --> 1.068901).  Saving model ...
Validation loss decreased (1.068901 --> 1.067513).  Saving model ...
Validation loss decreased (1.067513 --> 1.064507).  Saving model ...
Validation loss decreased (1.064507 --> 1.063645).  Saving model ...
Validation loss decreased (1.063645 --> 1.062419).  Saving model ...
Validation loss decreased (1.062419 --> 1.060386).  Saving model ...
Validation loss decreased (1.060386 --> 1.057799).  Saving model ...
Validation loss decreased (1.057799 --> 1.057775).  Saving model ...
Validation loss decreased (1.057775 --> 1.052109).  Saving model ...
Validation loss decreased (1.052109 --> 1.049116).  Saving model ...
Validation loss decreased (1.049116 --> 1.048865).  Saving model ...
Validation loss decreased (1.048865 --> 1.048229).  Saving model ...
Validation loss decreased (1.048229 --> 1.045768).  Saving model ...
Validation loss decreased (1.045768 --> 1.045441).  Saving model ...
EarlyStopping counter: 1 out of 10.0
Validation loss decreased (1.045441 --> 1.039478).  Saving model ...
EarlyStopping counter: 1 out of 10.0
EarlyStopping counter: 2 out of 10.0
Validation loss decreased (1.039478 --> 1.036738).  Saving model ...
Validation loss decreased (1.036738 --> 1.035674).  Saving model ...
Validation loss decreased (1.035674 --> 1.035298).  Saving model ...
Validation loss decreased (1.035298 --> 1.035160).  Saving model ...
Validation loss decreased (1.035160 --> 1.032833).  Saving model ...
Validation loss decreased (1.032833 --> 1.031404).  Saving model ...
Validation loss decreased (1.031404 --> 1.028344).  Saving model ...
EarlyStopping counter: 1 out of 10.0
Validation loss decreased (1.028344 --> 1.028123).  Saving model ...
Validation loss decreased (1.028123 --> 1.026043).  Saving model ...
Validation loss decreased (1.026043 --> 1.025562).  Saving model ...
Validation loss decreased (1.025562 --> 1.024993).  Saving model ...
Validation loss decreased (1.024993 --> 1.023024).  Saving model ...
Validation loss decreased (1.023024 --> 1.021841).  Saving model ...
Validation loss decreased (1.021841 --> 1.021078).  Saving model ...
EarlyStopping counter: 1 out of 10.0
Validation loss decreased (1.021078 --> 1.018982).  Saving model ...
Validation loss decreased (1.018982 --> 1.016479).  Saving model ...
Validation loss decreased (1.016479 --> 1.015250).  Saving model ...
Validation loss decreased (1.015250 --> 1.014983).  Saving model ...
EarlyStopping counter: 1 out of 10.0
EarlyStopping counter: 2 out of 10.0
EarlyStopping counter: 3 out of 10.0
EarlyStopping counter: 4 out of 10.0
EarlyStopping counter: 5 out of 10.0
Validation loss decreased (1.014983 --> 1.013513).  Saving model ...
Validation loss decreased (1.013513 --> 1.013316).  Saving model ...
Validation loss decreased (1.013316 --> 1.012858).  Saving model ...
Validation loss decreased (1.012858 --> 1.012249).  Saving model ...
Validation loss decreased (1.012249 --> 1.011474).  Saving model ...
EarlyStopping counter: 1 out of 10.0
EarlyStopping counter: 2 out of 10.0
EarlyStopping counter: 3 out of 10.0
EarlyStopping counter: 4 out of 10.0
EarlyStopping counter: 5 out of 10.0
EarlyStopping counter: 6 out of 10.0
Validation loss decreased (1.011474 --> 1.011419).  Saving model ...
EarlyStopping counter: 1 out of 10.0
EarlyStopping counter: 2 out of 10.0
EarlyStopping counter: 3 out of 10.0
EarlyStopping counter: 4 out of 10.0
EarlyStopping counter: 5 out of 10.0
EarlyStopping counter: 6 out of 10.0
EarlyStopping counter: 7 out of 10.0
EarlyStopping counter: 8 out of 10.0
EarlyStopping counter: 9 out of 10.0
EarlyStopping counter: 10 out of 10.0
/localscratch/yinan.29351700.0/env/lib/python3.7/site-packages/torch/nn/functional.py:1794: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.
  warnings.warn("nn.functional.tanh is deprecated. Use torch.tanh instead.")
wandb: Waiting for W&B process to finish, PID 184808... (success).
wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: \ 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: | 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: / 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: \ 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: | 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: / 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb:                                                                                
wandb: Run history:
wandb:     e_F1 ▁▂▄▄▅▅▅▅▆▆▆▆▆▆▇▇▇▇▇▇▇▇▇▇▇▇▇█████████████
wandb:   e_loss ██▇▇▇▆▆▆▅▅▄▄▄▄▃▃▃▃▂▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:     t_F1 ▁▁▂▃▃▃▃▄▄▄▄▅▅▆▅▆▆▆▆▆▆▆▆▇▆▇▆▇▇▇▇█▇▇███▇██
wandb:   t_loss ██▇▇▇▇▇▇▆▆▆▅▅▅▅▅▄▄▄▄▄▄▄▃▃▃▃▃▃▂▂▂▂▂▂▂▂▂▁▁
wandb: 
wandb: Run summary:
wandb:     e_F1 55.20148
wandb:   e_loss 1.01325
wandb:     t_F1 71.89033
wandb:   t_loss 0.72385
wandb: 
wandb: Synced 4 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Synced glorious-snowball-1: https://wandb.ai/yinanazhou/xl_512_bs_8_lr_1e06_es_10_lc_True_nr_True_sr_False_stem_True_lemma_False_repeat_2_fold_1/runs/28gj6z5d
wandb: Find logs at: ./wandb/run-20220326_022047-28gj6z5d/logs/debug.log
wandb: 

wandb: wandb version 0.12.11 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
2022-03-26 03:51:49.603668: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1
wandb: Tracking run with wandb version 0.12.5
wandb: Syncing run feasible-feather-1
wandb: ⭐️ View project at https://wandb.ai/yinanazhou/xl_512_bs_8_lr_1e06_es_10_lc_True_nr_True_sr_False_stem_True_lemma_False_repeat_2_fold_2
wandb: 🚀 View run at https://wandb.ai/yinanazhou/xl_512_bs_8_lr_1e06_es_10_lc_True_nr_True_sr_False_stem_True_lemma_False_repeat_2_fold_2/runs/2nrptrbu
wandb: Run data is saved locally in /project/6002780/yinan/Thesis_MER_Lyrics/lyric-emotion/wandb/run-20220326_035147-2nrptrbu
wandb: Run `wandb offline` to turn off syncing.

Validation loss decreased (inf --> 1.431705).  Saving model ...
Validation loss decreased (1.431705 --> 1.413352).  Saving model ...
Validation loss decreased (1.413352 --> 1.398792).  Saving model ...
Validation loss decreased (1.398792 --> 1.387704).  Saving model ...
Validation loss decreased (1.387704 --> 1.378146).  Saving model ...
Validation loss decreased (1.378146 --> 1.370097).  Saving model ...
Validation loss decreased (1.370097 --> 1.363578).  Saving model ...
Validation loss decreased (1.363578 --> 1.358337).  Saving model ...
Validation loss decreased (1.358337 --> 1.353921).  Saving model ...
Validation loss decreased (1.353921 --> 1.349714).  Saving model ...
Validation loss decreased (1.349714 --> 1.344968).  Saving model ...
Validation loss decreased (1.344968 --> 1.340466).  Saving model ...
Validation loss decreased (1.340466 --> 1.336354).  Saving model ...
Validation loss decreased (1.336354 --> 1.331852).  Saving model ...
Validation loss decreased (1.331852 --> 1.327856).  Saving model ...
Validation loss decreased (1.327856 --> 1.323212).  Saving model ...
Validation loss decreased (1.323212 --> 1.318196).  Saving model ...
Validation loss decreased (1.318196 --> 1.313156).  Saving model ...
Validation loss decreased (1.313156 --> 1.308294).  Saving model ...
Validation loss decreased (1.308294 --> 1.302869).  Saving model ...
Validation loss decreased (1.302869 --> 1.296995).  Saving model ...
Validation loss decreased (1.296995 --> 1.291664).  Saving model ...
Validation loss decreased (1.291664 --> 1.286400).  Saving model ...
Validation loss decreased (1.286400 --> 1.280273).  Saving model ...
Validation loss decreased (1.280273 --> 1.273390).  Saving model ...
Validation loss decreased (1.273390 --> 1.266007).  Saving model ...
Validation loss decreased (1.266007 --> 1.259397).  Saving model ...
Validation loss decreased (1.259397 --> 1.253922).  Saving model ...
Validation loss decreased (1.253922 --> 1.248905).  Saving model ...
Validation loss decreased (1.248905 --> 1.244186).  Saving model ...
Validation loss decreased (1.244186 --> 1.238528).  Saving model ...
Validation loss decreased (1.238528 --> 1.231558).  Saving model ...
Validation loss decreased (1.231558 --> 1.226028).  Saving model ...
Validation loss decreased (1.226028 --> 1.221117).  Saving model ...
Validation loss decreased (1.221117 --> 1.216412).  Saving model ...
Validation loss decreased (1.216412 --> 1.210402).  Saving model ...
Validation loss decreased (1.210402 --> 1.207350).  Saving model ...
Validation loss decreased (1.207350 --> 1.202510).  Saving model ...
Validation loss decreased (1.202510 --> 1.198794).  Saving model ...
Validation loss decreased (1.198794 --> 1.193244).  Saving model ...
Validation loss decreased (1.193244 --> 1.189063).  Saving model ...
Validation loss decreased (1.189063 --> 1.184034).  Saving model ...
Validation loss decreased (1.184034 --> 1.179918).  Saving model ...
Validation loss decreased (1.179918 --> 1.176447).  Saving model ...
Validation loss decreased (1.176447 --> 1.172215).  Saving model ...
Validation loss decreased (1.172215 --> 1.169634).  Saving model ...
Validation loss decreased (1.169634 --> 1.165511).  Saving model ...
Validation loss decreased (1.165511 --> 1.160745).  Saving model ...
Validation loss decreased (1.160745 --> 1.155876).  Saving model ...
Validation loss decreased (1.155876 --> 1.151148).  Saving model ...
Validation loss decreased (1.151148 --> 1.147288).  Saving model ...
Validation loss decreased (1.147288 --> 1.142543).  Saving model ...
Validation loss decreased (1.142543 --> 1.138186).  Saving model ...
Validation loss decreased (1.138186 --> 1.134185).  Saving model ...
Validation loss decreased (1.134185 --> 1.131115).  Saving model ...
Validation loss decreased (1.131115 --> 1.128231).  Saving model ...
Validation loss decreased (1.128231 --> 1.126751).  Saving model ...
Validation loss decreased (1.126751 --> 1.125392).  Saving model ...
Validation loss decreased (1.125392 --> 1.122079).  Saving model ...
Validation loss decreased (1.122079 --> 1.117900).  Saving model ...
Validation loss decreased (1.117900 --> 1.114456).  Saving model ...
Validation loss decreased (1.114456 --> 1.113038).  Saving model ...
Validation loss decreased (1.113038 --> 1.107690).  Saving model ...
Validation loss decreased (1.107690 --> 1.103981).  Saving model ...
Validation loss decreased (1.103981 --> 1.100890).  Saving model ...
Validation loss decreased (1.100890 --> 1.096276).  Saving model ...
Validation loss decreased (1.096276 --> 1.093421).  Saving model ...
Validation loss decreased (1.093421 --> 1.090133).  Saving model ...
Validation loss decreased (1.090133 --> 1.086428).  Saving model ...
Validation loss decreased (1.086428 --> 1.084427).  Saving model ...
Validation loss decreased (1.084427 --> 1.079493).  Saving model ...
Validation loss decreased (1.079493 --> 1.078075).  Saving model ...
Validation loss decreased (1.078075 --> 1.076751).  Saving model ...
Validation loss decreased (1.076751 --> 1.075067).  Saving model ...
Validation loss decreased (1.075067 --> 1.071974).  Saving model ...
Validation loss decreased (1.071974 --> 1.069539).  Saving model ...
Validation loss decreased (1.069539 --> 1.067977).  Saving model ...
Validation loss decreased (1.067977 --> 1.063495).  Saving model ...
Validation loss decreased (1.063495 --> 1.060402).  Saving model ...
Validation loss decreased (1.060402 --> 1.057882).  Saving model ...
Validation loss decreased (1.057882 --> 1.053760).  Saving model ...
Validation loss decreased (1.053760 --> 1.052380).  Saving model ...
Validation loss decreased (1.052380 --> 1.049689).  Saving model ...
Validation loss decreased (1.049689 --> 1.049127).  Saving model ...
Validation loss decreased (1.049127 --> 1.047411).  Saving model ...
Validation loss decreased (1.047411 --> 1.046688).  Saving model ...
Validation loss decreased (1.046688 --> 1.041423).  Saving model ...
Validation loss decreased (1.041423 --> 1.037934).  Saving model ...
Validation loss decreased (1.037934 --> 1.036907).  Saving model ...
Validation loss decreased (1.036907 --> 1.031059).  Saving model ...
Validation loss decreased (1.031059 --> 1.030705).  Saving model ...
Validation loss decreased (1.030705 --> 1.028326).  Saving model ...
Validation loss decreased (1.028326 --> 1.026144).  Saving model ...
EarlyStopping counter: 1 out of 10.0
Validation loss decreased (1.026144 --> 1.025618).  Saving model ...
Validation loss decreased (1.025618 --> 1.021902).  Saving model ...
Validation loss decreased (1.021902 --> 1.018520).  Saving model ...
Validation loss decreased (1.018520 --> 1.016209).  Saving model ...
Validation loss decreased (1.016209 --> 1.011547).  Saving model ...
Validation loss decreased (1.011547 --> 1.008458).  Saving model ...
Validation loss decreased (1.008458 --> 1.006340).  Saving model ...
EarlyStopping counter: 1 out of 10.0
EarlyStopping counter: 2 out of 10.0
EarlyStopping counter: 3 out of 10.0
EarlyStopping counter: 4 out of 10.0
EarlyStopping counter: 5 out of 10.0
Validation loss decreased (1.006340 --> 1.003744).  Saving model ...
Validation loss decreased (1.003744 --> 0.999229).  Saving model ...
Validation loss decreased (0.999229 --> 0.996607).  Saving model ...
EarlyStopping counter: 1 out of 10.0
EarlyStopping counter: 2 out of 10.0
Validation loss decreased (0.996607 --> 0.994223).  Saving model ...
Validation loss decreased (0.994223 --> 0.991687).  Saving model ...
Validation loss decreased (0.991687 --> 0.991066).  Saving model ...
Validation loss decreased (0.991066 --> 0.988932).  Saving model ...
Validation loss decreased (0.988932 --> 0.986097).  Saving model ...
Validation loss decreased (0.986097 --> 0.985092).  Saving model ...
Validation loss decreased (0.985092 --> 0.984614).  Saving model ...
EarlyStopping counter: 1 out of 10.0
Validation loss decreased (0.984614 --> 0.982849).  Saving model ...
Validation loss decreased (0.982849 --> 0.982298).  Saving model ...
EarlyStopping counter: 1 out of 10.0
Validation loss decreased (0.982298 --> 0.980558).  Saving model ...
Validation loss decreased (0.980558 --> 0.977778).  Saving model ...
Validation loss decreased (0.977778 --> 0.975842).  Saving model ...
Validation loss decreased (0.975842 --> 0.974533).  Saving model ...
EarlyStopping counter: 1 out of 10.0
Validation loss decreased (0.974533 --> 0.973994).  Saving model ...
Validation loss decreased (0.973994 --> 0.973049).  Saving model ...
EarlyStopping counter: 1 out of 10.0
EarlyStopping counter: 2 out of 10.0
EarlyStopping counter: 3 out of 10.0
Validation loss decreased (0.973049 --> 0.971017).  Saving model ...
Validation loss decreased (0.971017 --> 0.968569).  Saving model ...
Validation loss decreased (0.968569 --> 0.966804).  Saving model ...
Validation loss decreased (0.966804 --> 0.966124).  Saving model ...
EarlyStopping counter: 1 out of 10.0
EarlyStopping counter: 2 out of 10.0
EarlyStopping counter: 3 out of 10.0
EarlyStopping counter: 4 out of 10.0
Validation loss decreased (0.966124 --> 0.964526).  Saving model ...
EarlyStopping counter: 1 out of 10.0
EarlyStopping counter: 2 out of 10.0
EarlyStopping counter: 3 out of 10.0
Validation loss decreased (0.964526 --> 0.963861).  Saving model ...
Validation loss decreased (0.963861 --> 0.962352).  Saving model ...
Validation loss decreased (0.962352 --> 0.962216).  Saving model ...
Validation loss decreased (0.962216 --> 0.961503).  Saving model ...
EarlyStopping counter: 1 out of 10.0
Validation loss decreased (0.961503 --> 0.960277).  Saving model ...
EarlyStopping counter: 1 out of 10.0
Validation loss decreased (0.960277 --> 0.958312).  Saving model ...
EarlyStopping counter: 1 out of 10.0
EarlyStopping counter: 2 out of 10.0
Validation loss decreased (0.958312 --> 0.958045).  Saving model ...
EarlyStopping counter: 1 out of 10.0
Validation loss decreased (0.958045 --> 0.957360).  Saving model ...
Validation loss decreased (0.957360 --> 0.954688).  Saving model ...
EarlyStopping counter: 1 out of 10.0
EarlyStopping counter: 2 out of 10.0
EarlyStopping counter: 3 out of 10.0
EarlyStopping counter: 4 out of 10.0
EarlyStopping counter: 5 out of 10.0
EarlyStopping counter: 6 out of 10.0
EarlyStopping counter: 7 out of 10.0
EarlyStopping counter: 8 out of 10.0
EarlyStopping counter: 9 out of 10.0
EarlyStopping counter: 10 out of 10.0
/localscratch/yinan.29351700.0/env/lib/python3.7/site-packages/torch/nn/functional.py:1794: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.
  warnings.warn("nn.functional.tanh is deprecated. Use torch.tanh instead.")
wandb: Waiting for W&B process to finish, PID 189676... (success).
wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: \ 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: | 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: / 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: \ 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: | 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: / 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: \ 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: | 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: / 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb:                                                                                
wandb: Run history:
wandb:     e_F1 ▁▂▄▅▆▆▆▆▆▆▆▆▆▆▆▆▇▇▇▇▇▇▇▇▇▇▇▇████████████
wandb:   e_loss █▇▇▇▆▆▆▅▅▅▄▄▄▄▃▃▃▃▃▂▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:     t_F1 ▁▂▃▃▃▄▄▄▅▅▅▅▅▆▆▆▆▆▆▆▆▆▇▇▆▇▇▇▇▇▇▇▇████▇██
wandb:   t_loss ██▇▇▇▇▇▆▆▆▅▅▅▅▅▄▄▄▄▄▃▄▃▃▃▃▃▂▂▃▂▂▂▂▂▂▁▂▁▁
wandb: 
wandb: Run summary:
wandb:     e_F1 60.4892
wandb:   e_loss 0.95852
wandb:     t_F1 72.23036
wandb:   t_loss 0.7346
wandb: 
wandb: Synced 4 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Synced feasible-feather-1: https://wandb.ai/yinanazhou/xl_512_bs_8_lr_1e06_es_10_lc_True_nr_True_sr_False_stem_True_lemma_False_repeat_2_fold_2/runs/2nrptrbu
wandb: Find logs at: ./wandb/run-20220326_035147-2nrptrbu/logs/debug.log
wandb: 

wandb: wandb version 0.12.11 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
2022-03-26 05:40:39.581075: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1
wandb: Tracking run with wandb version 0.12.5
wandb: Syncing run likely-hill-1
wandb: ⭐️ View project at https://wandb.ai/yinanazhou/xl_512_bs_8_lr_1e06_es_10_lc_True_nr_True_sr_False_stem_True_lemma_False_repeat_3_fold_1
wandb: 🚀 View run at https://wandb.ai/yinanazhou/xl_512_bs_8_lr_1e06_es_10_lc_True_nr_True_sr_False_stem_True_lemma_False_repeat_3_fold_1/runs/1yo3rpbc
wandb: Run data is saved locally in /project/6002780/yinan/Thesis_MER_Lyrics/lyric-emotion/wandb/run-20220326_054037-1yo3rpbc
wandb: Run `wandb offline` to turn off syncing.

Validation loss decreased (inf --> 1.425883).  Saving model ...
Validation loss decreased (1.425883 --> 1.409784).  Saving model ...
Validation loss decreased (1.409784 --> 1.398126).  Saving model ...
Validation loss decreased (1.398126 --> 1.389270).  Saving model ...
Validation loss decreased (1.389270 --> 1.382380).  Saving model ...
Validation loss decreased (1.382380 --> 1.376249).  Saving model ...
Validation loss decreased (1.376249 --> 1.370953).  Saving model ...
Validation loss decreased (1.370953 --> 1.366425).  Saving model ...
Validation loss decreased (1.366425 --> 1.362366).  Saving model ...
Validation loss decreased (1.362366 --> 1.358822).  Saving model ...
Validation loss decreased (1.358822 --> 1.355229).  Saving model ...
Validation loss decreased (1.355229 --> 1.351959).  Saving model ...
Validation loss decreased (1.351959 --> 1.348407).  Saving model ...
Validation loss decreased (1.348407 --> 1.345267).  Saving model ...
Validation loss decreased (1.345267 --> 1.341904).  Saving model ...
Validation loss decreased (1.341904 --> 1.338546).  Saving model ...
Validation loss decreased (1.338546 --> 1.334777).  Saving model ...
Validation loss decreased (1.334777 --> 1.331396).  Saving model ...
Validation loss decreased (1.331396 --> 1.328014).  Saving model ...
Validation loss decreased (1.328014 --> 1.324450).  Saving model ...
Validation loss decreased (1.324450 --> 1.320773).  Saving model ...
Validation loss decreased (1.320773 --> 1.317181).  Saving model ...
Validation loss decreased (1.317181 --> 1.313170).  Saving model ...
Validation loss decreased (1.313170 --> 1.308919).  Saving model ...
Validation loss decreased (1.308919 --> 1.305529).  Saving model ...
Validation loss decreased (1.305529 --> 1.301916).  Saving model ...
Validation loss decreased (1.301916 --> 1.297163).  Saving model ...
Validation loss decreased (1.297163 --> 1.292297).  Saving model ...
Validation loss decreased (1.292297 --> 1.288835).  Saving model ...
Validation loss decreased (1.288835 --> 1.284044).  Saving model ...
Validation loss decreased (1.284044 --> 1.279528).  Saving model ...
Validation loss decreased (1.279528 --> 1.274354).  Saving model ...
Validation loss decreased (1.274354 --> 1.269920).  Saving model ...
Validation loss decreased (1.269920 --> 1.265083).  Saving model ...
Validation loss decreased (1.265083 --> 1.260696).  Saving model ...
Validation loss decreased (1.260696 --> 1.256375).  Saving model ...
Validation loss decreased (1.256375 --> 1.252752).  Saving model ...
Validation loss decreased (1.252752 --> 1.247346).  Saving model ...
Validation loss decreased (1.247346 --> 1.240591).  Saving model ...
Validation loss decreased (1.240591 --> 1.234812).  Saving model ...
Validation loss decreased (1.234812 --> 1.230890).  Saving model ...
Validation loss decreased (1.230890 --> 1.227603).  Saving model ...
Validation loss decreased (1.227603 --> 1.221442).  Saving model ...
Validation loss decreased (1.221442 --> 1.218268).  Saving model ...
Validation loss decreased (1.218268 --> 1.213339).  Saving model ...
Validation loss decreased (1.213339 --> 1.209409).  Saving model ...
Validation loss decreased (1.209409 --> 1.205188).  Saving model ...
Validation loss decreased (1.205188 --> 1.199809).  Saving model ...
Validation loss decreased (1.199809 --> 1.196130).  Saving model ...
Validation loss decreased (1.196130 --> 1.191041).  Saving model ...
Validation loss decreased (1.191041 --> 1.186279).  Saving model ...
Validation loss decreased (1.186279 --> 1.182682).  Saving model ...
Validation loss decreased (1.182682 --> 1.181932).  Saving model ...
Validation loss decreased (1.181932 --> 1.177416).  Saving model ...
Validation loss decreased (1.177416 --> 1.173798).  Saving model ...
Validation loss decreased (1.173798 --> 1.170164).  Saving model ...
Validation loss decreased (1.170164 --> 1.167506).  Saving model ...
Validation loss decreased (1.167506 --> 1.162486).  Saving model ...
EarlyStopping counter: 1 out of 10.0
Validation loss decreased (1.162486 --> 1.161454).  Saving model ...
Validation loss decreased (1.161454 --> 1.156908).  Saving model ...
Validation loss decreased (1.156908 --> 1.152992).  Saving model ...
Validation loss decreased (1.152992 --> 1.149638).  Saving model ...
Validation loss decreased (1.149638 --> 1.143775).  Saving model ...
Validation loss decreased (1.143775 --> 1.137902).  Saving model ...
Validation loss decreased (1.137902 --> 1.134892).  Saving model ...
Validation loss decreased (1.134892 --> 1.130919).  Saving model ...
Validation loss decreased (1.130919 --> 1.129255).  Saving model ...
Validation loss decreased (1.129255 --> 1.127271).  Saving model ...
Validation loss decreased (1.127271 --> 1.126275).  Saving model ...
EarlyStopping counter: 1 out of 10.0
Validation loss decreased (1.126275 --> 1.121234).  Saving model ...
Validation loss decreased (1.121234 --> 1.119490).  Saving model ...
Validation loss decreased (1.119490 --> 1.116655).  Saving model ...
Validation loss decreased (1.116655 --> 1.115057).  Saving model ...
Validation loss decreased (1.115057 --> 1.111368).  Saving model ...
Validation loss decreased (1.111368 --> 1.109875).  Saving model ...
Validation loss decreased (1.109875 --> 1.106782).  Saving model ...
Validation loss decreased (1.106782 --> 1.101730).  Saving model ...
Validation loss decreased (1.101730 --> 1.099245).  Saving model ...
Validation loss decreased (1.099245 --> 1.093591).  Saving model ...
EarlyStopping counter: 1 out of 10.0
Validation loss decreased (1.093591 --> 1.091727).  Saving model ...
Validation loss decreased (1.091727 --> 1.091273).  Saving model ...
Validation loss decreased (1.091273 --> 1.088328).  Saving model ...
Validation loss decreased (1.088328 --> 1.087096).  Saving model ...
Validation loss decreased (1.087096 --> 1.082151).  Saving model ...
Validation loss decreased (1.082151 --> 1.079636).  Saving model ...
Validation loss decreased (1.079636 --> 1.078650).  Saving model ...
Validation loss decreased (1.078650 --> 1.075713).  Saving model ...
Validation loss decreased (1.075713 --> 1.072768).  Saving model ...
Validation loss decreased (1.072768 --> 1.070822).  Saving model ...
EarlyStopping counter: 1 out of 10.0
Validation loss decreased (1.070822 --> 1.069925).  Saving model ...
Validation loss decreased (1.069925 --> 1.062105).  Saving model ...
Validation loss decreased (1.062105 --> 1.059861).  Saving model ...
Validation loss decreased (1.059861 --> 1.056855).  Saving model ...
EarlyStopping counter: 1 out of 10.0
EarlyStopping counter: 2 out of 10.0
Validation loss decreased (1.056855 --> 1.056755).  Saving model ...
Validation loss decreased (1.056755 --> 1.052614).  Saving model ...
EarlyStopping counter: 1 out of 10.0
Validation loss decreased (1.052614 --> 1.047761).  Saving model ...
Validation loss decreased (1.047761 --> 1.044236).  Saving model ...
EarlyStopping counter: 1 out of 10.0
Validation loss decreased (1.044236 --> 1.042860).  Saving model ...
EarlyStopping counter: 1 out of 10.0
Validation loss decreased (1.042860 --> 1.042239).  Saving model ...
Validation loss decreased (1.042239 --> 1.039582).  Saving model ...
Validation loss decreased (1.039582 --> 1.036359).  Saving model ...
Validation loss decreased (1.036359 --> 1.035220).  Saving model ...
Validation loss decreased (1.035220 --> 1.031599).  Saving model ...
EarlyStopping counter: 1 out of 10.0
EarlyStopping counter: 2 out of 10.0
Validation loss decreased (1.031599 --> 1.031539).  Saving model ...
Validation loss decreased (1.031539 --> 1.029480).  Saving model ...
Validation loss decreased (1.029480 --> 1.028991).  Saving model ...
Validation loss decreased (1.028991 --> 1.027292).  Saving model ...
Validation loss decreased (1.027292 --> 1.026076).  Saving model ...
Validation loss decreased (1.026076 --> 1.021669).  Saving model ...
EarlyStopping counter: 1 out of 10.0
Validation loss decreased (1.021669 --> 1.020745).  Saving model ...
Validation loss decreased (1.020745 --> 1.018539).  Saving model ...
Validation loss decreased (1.018539 --> 1.018209).  Saving model ...
EarlyStopping counter: 1 out of 10.0
EarlyStopping counter: 2 out of 10.0
Validation loss decreased (1.018209 --> 1.016768).  Saving model ...
EarlyStopping counter: 1 out of 10.0
EarlyStopping counter: 2 out of 10.0
Validation loss decreased (1.016768 --> 1.015137).  Saving model ...
Validation loss decreased (1.015137 --> 1.011952).  Saving model ...
EarlyStopping counter: 1 out of 10.0
EarlyStopping counter: 2 out of 10.0
EarlyStopping counter: 3 out of 10.0
EarlyStopping counter: 4 out of 10.0
EarlyStopping counter: 5 out of 10.0
EarlyStopping counter: 6 out of 10.0
Validation loss decreased (1.011952 --> 1.011284).  Saving model ...
EarlyStopping counter: 1 out of 10.0
Validation loss decreased (1.011284 --> 1.010356).  Saving model ...
EarlyStopping counter: 1 out of 10.0
EarlyStopping counter: 2 out of 10.0
EarlyStopping counter: 3 out of 10.0
Validation loss decreased (1.010356 --> 1.005534).  Saving model ...
Validation loss decreased (1.005534 --> 1.002943).  Saving model ...
EarlyStopping counter: 1 out of 10.0
EarlyStopping counter: 2 out of 10.0
EarlyStopping counter: 3 out of 10.0
Validation loss decreased (1.002943 --> 1.001922).  Saving model ...
EarlyStopping counter: 1 out of 10.0
EarlyStopping counter: 2 out of 10.0
EarlyStopping counter: 3 out of 10.0
EarlyStopping counter: 4 out of 10.0
EarlyStopping counter: 5 out of 10.0
EarlyStopping counter: 6 out of 10.0
EarlyStopping counter: 7 out of 10.0
EarlyStopping counter: 8 out of 10.0
Validation loss decreased (1.001922 --> 0.998629).  Saving model ...
EarlyStopping counter: 1 out of 10.0
EarlyStopping counter: 2 out of 10.0
EarlyStopping counter: 3 out of 10.0
EarlyStopping counter: 4 out of 10.0
EarlyStopping counter: 5 out of 10.0
EarlyStopping counter: 6 out of 10.0
EarlyStopping counter: 7 out of 10.0
EarlyStopping counter: 8 out of 10.0
EarlyStopping counter: 9 out of 10.0
EarlyStopping counter: 10 out of 10.0
/localscratch/yinan.29351700.0/env/lib/python3.7/site-packages/torch/nn/functional.py:1794: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.
  warnings.warn("nn.functional.tanh is deprecated. Use torch.tanh instead.")
wandb: Waiting for W&B process to finish, PID 195482... (success).
wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: \ 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: | 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: / 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: \ 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: | 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: / 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: \ 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: | 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: / 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb:                                                                                
wandb: Run history:
wandb:     e_F1 ▁▁▃▄▅▅▅▅▆▆▆▇▇▇▇▇▇▇▇▇▇████▇▇█████████████
wandb:   e_loss █▇▇▇▇▆▆▆▅▅▅▄▄▄▄▃▃▃▃▃▃▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁
wandb:     t_F1 ▁▂▃▃▃▄▄▄▄▅▅▅▅▅▅▅▆▆▆▆▆▇▆▇▇▇▇▇▇█▇▇▇▇██████
wandb:   t_loss ██▇▇▇▇▇▇▆▆▆▅▅▅▅▅▄▄▄▄▄▃▃▃▃▃▃▃▂▂▂▂▂▂▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:     e_F1 56.45921
wandb:   e_loss 1.00325
wandb:     t_F1 70.36919
wandb:   t_loss 0.7501
wandb: 
wandb: Synced 4 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Synced likely-hill-1: https://wandb.ai/yinanazhou/xl_512_bs_8_lr_1e06_es_10_lc_True_nr_True_sr_False_stem_True_lemma_False_repeat_3_fold_1/runs/1yo3rpbc
wandb: Find logs at: ./wandb/run-20220326_054037-1yo3rpbc/logs/debug.log
wandb: 

wandb: wandb version 0.12.11 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
2022-03-26 07:31:05.113935: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1
wandb: Tracking run with wandb version 0.12.5
wandb: Syncing run astral-feather-1
wandb: ⭐️ View project at https://wandb.ai/yinanazhou/xl_512_bs_8_lr_1e06_es_10_lc_True_nr_True_sr_False_stem_True_lemma_False_repeat_3_fold_2
wandb: 🚀 View run at https://wandb.ai/yinanazhou/xl_512_bs_8_lr_1e06_es_10_lc_True_nr_True_sr_False_stem_True_lemma_False_repeat_3_fold_2/runs/3u2cuxrr
wandb: Run data is saved locally in /project/6002780/yinan/Thesis_MER_Lyrics/lyric-emotion/wandb/run-20220326_073103-3u2cuxrr
wandb: Run `wandb offline` to turn off syncing.

Validation loss decreased (inf --> 1.403375).  Saving model ...
Validation loss decreased (1.403375 --> 1.393298).  Saving model ...
Validation loss decreased (1.393298 --> 1.385166).  Saving model ...
Validation loss decreased (1.385166 --> 1.379242).  Saving model ...
Validation loss decreased (1.379242 --> 1.373855).  Saving model ...
Validation loss decreased (1.373855 --> 1.369321).  Saving model ...
Validation loss decreased (1.369321 --> 1.365138).  Saving model ...
Validation loss decreased (1.365138 --> 1.361603).  Saving model ...
Validation loss decreased (1.361603 --> 1.358011).  Saving model ...
Validation loss decreased (1.358011 --> 1.354489).  Saving model ...
Validation loss decreased (1.354489 --> 1.351150).  Saving model ...
Validation loss decreased (1.351150 --> 1.347178).  Saving model ...
Validation loss decreased (1.347178 --> 1.343821).  Saving model ...
Validation loss decreased (1.343821 --> 1.340855).  Saving model ...
Validation loss decreased (1.340855 --> 1.337290).  Saving model ...
Validation loss decreased (1.337290 --> 1.333309).  Saving model ...
Validation loss decreased (1.333309 --> 1.328941).  Saving model ...
Validation loss decreased (1.328941 --> 1.324758).  Saving model ...
Validation loss decreased (1.324758 --> 1.320991).  Saving model ...
Validation loss decreased (1.320991 --> 1.317385).  Saving model ...
Validation loss decreased (1.317385 --> 1.312234).  Saving model ...
Validation loss decreased (1.312234 --> 1.307665).  Saving model ...
Validation loss decreased (1.307665 --> 1.301970).  Saving model ...
Validation loss decreased (1.301970 --> 1.296695).  Saving model ...
Validation loss decreased (1.296695 --> 1.291557).  Saving model ...
Validation loss decreased (1.291557 --> 1.285857).  Saving model ...
Validation loss decreased (1.285857 --> 1.280559).  Saving model ...
Validation loss decreased (1.280559 --> 1.274737).  Saving model ...
Validation loss decreased (1.274737 --> 1.268921).  Saving model ...
Validation loss decreased (1.268921 --> 1.263131).  Saving model ...
Validation loss decreased (1.263131 --> 1.256110).  Saving model ...
Validation loss decreased (1.256110 --> 1.250282).  Saving model ...
Validation loss decreased (1.250282 --> 1.244237).  Saving model ...
Validation loss decreased (1.244237 --> 1.238034).  Saving model ...
Validation loss decreased (1.238034 --> 1.231686).  Saving model ...
Validation loss decreased (1.231686 --> 1.226327).  Saving model ...
Validation loss decreased (1.226327 --> 1.221282).  Saving model ...
Validation loss decreased (1.221282 --> 1.215188).  Saving model ...
Validation loss decreased (1.215188 --> 1.209893).  Saving model ...
Validation loss decreased (1.209893 --> 1.203880).  Saving model ...
Validation loss decreased (1.203880 --> 1.198368).  Saving model ...
Validation loss decreased (1.198368 --> 1.193373).  Saving model ...
Validation loss decreased (1.193373 --> 1.188456).  Saving model ...
Validation loss decreased (1.188456 --> 1.184504).  Saving model ...
Validation loss decreased (1.184504 --> 1.178819).  Saving model ...
Validation loss decreased (1.178819 --> 1.173626).  Saving model ...
Validation loss decreased (1.173626 --> 1.170071).  Saving model ...
Validation loss decreased (1.170071 --> 1.164312).  Saving model ...
Validation loss decreased (1.164312 --> 1.159455).  Saving model ...
Validation loss decreased (1.159455 --> 1.153636).  Saving model ...
Validation loss decreased (1.153636 --> 1.149436).  Saving model ...
Validation loss decreased (1.149436 --> 1.146061).  Saving model ...
Validation loss decreased (1.146061 --> 1.140522).  Saving model ...
Validation loss decreased (1.140522 --> 1.136093).  Saving model ...
Validation loss decreased (1.136093 --> 1.130851).  Saving model ...
Validation loss decreased (1.130851 --> 1.126260).  Saving model ...
Validation loss decreased (1.126260 --> 1.122012).  Saving model ...
Validation loss decreased (1.122012 --> 1.118485).  Saving model ...
Validation loss decreased (1.118485 --> 1.116741).  Saving model ...
Validation loss decreased (1.116741 --> 1.111003).  Saving model ...
Validation loss decreased (1.111003 --> 1.106162).  Saving model ...
Validation loss decreased (1.106162 --> 1.101692).  Saving model ...
Validation loss decreased (1.101692 --> 1.098672).  Saving model ...
Validation loss decreased (1.098672 --> 1.095105).  Saving model ...
Validation loss decreased (1.095105 --> 1.091154).  Saving model ...
Validation loss decreased (1.091154 --> 1.088151).  Saving model ...
Validation loss decreased (1.088151 --> 1.085024).  Saving model ...
Validation loss decreased (1.085024 --> 1.080670).  Saving model ...
Validation loss decreased (1.080670 --> 1.078368).  Saving model ...
Validation loss decreased (1.078368 --> 1.077943).  Saving model ...
Validation loss decreased (1.077943 --> 1.073633).  Saving model ...
Validation loss decreased (1.073633 --> 1.069416).  Saving model ...
Validation loss decreased (1.069416 --> 1.067317).  Saving model ...
Validation loss decreased (1.067317 --> 1.063964).  Saving model ...
Validation loss decreased (1.063964 --> 1.062051).  Saving model ...
Validation loss decreased (1.062051 --> 1.059370).  Saving model ...
Validation loss decreased (1.059370 --> 1.055357).  Saving model ...
Validation loss decreased (1.055357 --> 1.053917).  Saving model ...
Validation loss decreased (1.053917 --> 1.051397).  Saving model ...
Validation loss decreased (1.051397 --> 1.049164).  Saving model ...
Validation loss decreased (1.049164 --> 1.047780).  Saving model ...
Validation loss decreased (1.047780 --> 1.045230).  Saving model ...
Validation loss decreased (1.045230 --> 1.042322).  Saving model ...
Validation loss decreased (1.042322 --> 1.042085).  Saving model ...
Validation loss decreased (1.042085 --> 1.040145).  Saving model ...
Validation loss decreased (1.040145 --> 1.037445).  Saving model ...
Validation loss decreased (1.037445 --> 1.035897).  Saving model ...
Validation loss decreased (1.035897 --> 1.031762).  Saving model ...
Validation loss decreased (1.031762 --> 1.028696).  Saving model ...
Validation loss decreased (1.028696 --> 1.027992).  Saving model ...
Validation loss decreased (1.027992 --> 1.026367).  Saving model ...
Validation loss decreased (1.026367 --> 1.024827).  Saving model ...
Validation loss decreased (1.024827 --> 1.023815).  Saving model ...
Validation loss decreased (1.023815 --> 1.022482).  Saving model ...
Validation loss decreased (1.022482 --> 1.020677).  Saving model ...
Validation loss decreased (1.020677 --> 1.019176).  Saving model ...
Validation loss decreased (1.019176 --> 1.018335).  Saving model ...
Validation loss decreased (1.018335 --> 1.015824).  Saving model ...
Validation loss decreased (1.015824 --> 1.014430).  Saving model ...
Validation loss decreased (1.014430 --> 1.013123).  Saving model ...
Validation loss decreased (1.013123 --> 1.011273).  Saving model ...
Validation loss decreased (1.011273 --> 1.009269).  Saving model ...
Validation loss decreased (1.009269 --> 1.008920).  Saving model ...
Validation loss decreased (1.008920 --> 1.008684).  Saving model ...
Validation loss decreased (1.008684 --> 1.006781).  Saving model ...
Validation loss decreased (1.006781 --> 1.005164).  Saving model ...
Validation loss decreased (1.005164 --> 1.003821).  Saving model ...
Validation loss decreased (1.003821 --> 1.001663).  Saving model ...
Validation loss decreased (1.001663 --> 1.001018).  Saving model ...
Validation loss decreased (1.001018 --> 0.998711).  Saving model ...
Validation loss decreased (0.998711 --> 0.998294).  Saving model ...
Validation loss decreased (0.998294 --> 0.997043).  Saving model ...
Validation loss decreased (0.997043 --> 0.996185).  Saving model ...
Validation loss decreased (0.996185 --> 0.994244).  Saving model ...
Validation loss decreased (0.994244 --> 0.993777).  Saving model ...
Validation loss decreased (0.993777 --> 0.990981).  Saving model ...
Validation loss decreased (0.990981 --> 0.989717).  Saving model ...
EarlyStopping counter: 1 out of 10.0
Validation loss decreased (0.989717 --> 0.988819).  Saving model ...
Validation loss decreased (0.988819 --> 0.987099).  Saving model ...
EarlyStopping counter: 1 out of 10.0
Validation loss decreased (0.987099 --> 0.986145).  Saving model ...
Validation loss decreased (0.986145 --> 0.984944).  Saving model ...
Validation loss decreased (0.984944 --> 0.983902).  Saving model ...
Validation loss decreased (0.983902 --> 0.981235).  Saving model ...
Validation loss decreased (0.981235 --> 0.979354).  Saving model ...
Validation loss decreased (0.979354 --> 0.978651).  Saving model ...
Validation loss decreased (0.978651 --> 0.977188).  Saving model ...
EarlyStopping counter: 1 out of 10.0
EarlyStopping counter: 2 out of 10.0
EarlyStopping counter: 3 out of 10.0
Validation loss decreased (0.977188 --> 0.976562).  Saving model ...
Validation loss decreased (0.976562 --> 0.976206).  Saving model ...
EarlyStopping counter: 1 out of 10.0
EarlyStopping counter: 2 out of 10.0
Validation loss decreased (0.976206 --> 0.974807).  Saving model ...
Validation loss decreased (0.974807 --> 0.974171).  Saving model ...
Validation loss decreased (0.974171 --> 0.973673).  Saving model ...
Validation loss decreased (0.973673 --> 0.973535).  Saving model ...
Validation loss decreased (0.973535 --> 0.972838).  Saving model ...
Validation loss decreased (0.972838 --> 0.972813).  Saving model ...
EarlyStopping counter: 1 out of 10.0
Validation loss decreased (0.972813 --> 0.972290).  Saving model ...
Validation loss decreased (0.972290 --> 0.971021).  Saving model ...
Validation loss decreased (0.971021 --> 0.970182).  Saving model ...
Validation loss decreased (0.970182 --> 0.969574).  Saving model ...
EarlyStopping counter: 1 out of 10.0
EarlyStopping counter: 2 out of 10.0
EarlyStopping counter: 3 out of 10.0
EarlyStopping counter: 4 out of 10.0
EarlyStopping counter: 5 out of 10.0
Validation loss decreased (0.969574 --> 0.969235).  Saving model ...
EarlyStopping counter: 1 out of 10.0
EarlyStopping counter: 2 out of 10.0
EarlyStopping counter: 3 out of 10.0
EarlyStopping counter: 4 out of 10.0
EarlyStopping counter: 5 out of 10.0
Validation loss decreased (0.969235 --> 0.968652).  Saving model ...
EarlyStopping counter: 1 out of 10.0
Validation loss decreased (0.968652 --> 0.968503).  Saving model ...
EarlyStopping counter: 1 out of 10.0
EarlyStopping counter: 2 out of 10.0
EarlyStopping counter: 3 out of 10.0
EarlyStopping counter: 4 out of 10.0
EarlyStopping counter: 5 out of 10.0
EarlyStopping counter: 6 out of 10.0
EarlyStopping counter: 7 out of 10.0
EarlyStopping counter: 8 out of 10.0
EarlyStopping counter: 9 out of 10.0
EarlyStopping counter: 10 out of 10.0
/localscratch/yinan.29351700.0/env/lib/python3.7/site-packages/torch/nn/functional.py:1794: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.
  warnings.warn("nn.functional.tanh is deprecated. Use torch.tanh instead.")
wandb: Waiting for W&B process to finish, PID 201376... (success).
wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: \ 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: | 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: / 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: \ 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: | 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: / 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: \ 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: | 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: / 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb:                                                                                
wandb: Run history:
wandb:     e_F1 ▁▂▄▄▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇████████████████████
wandb:   e_loss ██▇▇▇▇▆▆▅▅▅▄▄▃▃▃▃▃▂▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:     t_F1 ▁▂▂▃▃▃▄▄▅▅▅▅▅▆▆▆▆▆▆▆▆▇▆▆▇▇▆▇▇▇▇▇▇███████
wandb:   t_loss ████▇▇▇▇▆▆▆▆▅▅▅▄▄▄▄▄▄▄▃▄▃▃▃▂▃▂▂▂▂▂▂▂▁▁▁▁
wandb: 
wandb: Run summary:
wandb:     e_F1 59.28471
wandb:   e_loss 0.9695
wandb:     t_F1 72.3609
wandb:   t_loss 0.73082
wandb: 
wandb: Synced 4 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Synced astral-feather-1: https://wandb.ai/yinanazhou/xl_512_bs_8_lr_1e06_es_10_lc_True_nr_True_sr_False_stem_True_lemma_False_repeat_3_fold_2/runs/3u2cuxrr
wandb: Find logs at: ./wandb/run-20220326_073103-3u2cuxrr/logs/debug.log
wandb: 

wandb: wandb version 0.12.11 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
2022-03-26 09:22:15.722844: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1
wandb: Tracking run with wandb version 0.12.5
wandb: Syncing run dry-sun-1
wandb: ⭐️ View project at https://wandb.ai/yinanazhou/xl_512_bs_8_lr_1e06_es_10_lc_True_nr_True_sr_False_stem_True_lemma_False_repeat_4_fold_1
wandb: 🚀 View run at https://wandb.ai/yinanazhou/xl_512_bs_8_lr_1e06_es_10_lc_True_nr_True_sr_False_stem_True_lemma_False_repeat_4_fold_1/runs/3fkg37zo
wandb: Run data is saved locally in /project/6002780/yinan/Thesis_MER_Lyrics/lyric-emotion/wandb/run-20220326_092213-3fkg37zo
wandb: Run `wandb offline` to turn off syncing.

Validation loss decreased (inf --> 1.405833).  Saving model ...
Validation loss decreased (1.405833 --> 1.395231).  Saving model ...
Validation loss decreased (1.395231 --> 1.387005).  Saving model ...
Validation loss decreased (1.387005 --> 1.380492).  Saving model ...
Validation loss decreased (1.380492 --> 1.375401).  Saving model ...
Validation loss decreased (1.375401 --> 1.370929).  Saving model ...
Validation loss decreased (1.370929 --> 1.366854).  Saving model ...
Validation loss decreased (1.366854 --> 1.362766).  Saving model ...
Validation loss decreased (1.362766 --> 1.359100).  Saving model ...
Validation loss decreased (1.359100 --> 1.355841).  Saving model ...
Validation loss decreased (1.355841 --> 1.352573).  Saving model ...
Validation loss decreased (1.352573 --> 1.349438).  Saving model ...
Validation loss decreased (1.349438 --> 1.346276).  Saving model ...
Validation loss decreased (1.346276 --> 1.342679).  Saving model ...
Validation loss decreased (1.342679 --> 1.338916).  Saving model ...
Validation loss decreased (1.338916 --> 1.335259).  Saving model ...
Validation loss decreased (1.335259 --> 1.331863).  Saving model ...
Validation loss decreased (1.331863 --> 1.327943).  Saving model ...
Validation loss decreased (1.327943 --> 1.324319).  Saving model ...
Validation loss decreased (1.324319 --> 1.320167).  Saving model ...
Validation loss decreased (1.320167 --> 1.315972).  Saving model ...
Validation loss decreased (1.315972 --> 1.311867).  Saving model ...
Validation loss decreased (1.311867 --> 1.306884).  Saving model ...
Validation loss decreased (1.306884 --> 1.302097).  Saving model ...
Validation loss decreased (1.302097 --> 1.297153).  Saving model ...
Validation loss decreased (1.297153 --> 1.292370).  Saving model ...
Validation loss decreased (1.292370 --> 1.287491).  Saving model ...
Validation loss decreased (1.287491 --> 1.282539).  Saving model ...
Validation loss decreased (1.282539 --> 1.276943).  Saving model ...
Validation loss decreased (1.276943 --> 1.270804).  Saving model ...
Validation loss decreased (1.270804 --> 1.265616).  Saving model ...
Validation loss decreased (1.265616 --> 1.260252).  Saving model ...
Validation loss decreased (1.260252 --> 1.254645).  Saving model ...
Validation loss decreased (1.254645 --> 1.249035).  Saving model ...
Validation loss decreased (1.249035 --> 1.243780).  Saving model ...
Validation loss decreased (1.243780 --> 1.238218).  Saving model ...
Validation loss decreased (1.238218 --> 1.231852).  Saving model ...
Validation loss decreased (1.231852 --> 1.226469).  Saving model ...
Validation loss decreased (1.226469 --> 1.221814).  Saving model ...
Validation loss decreased (1.221814 --> 1.216805).  Saving model ...
Validation loss decreased (1.216805 --> 1.209604).  Saving model ...
Validation loss decreased (1.209604 --> 1.203262).  Saving model ...
Validation loss decreased (1.203262 --> 1.197720).  Saving model ...
Validation loss decreased (1.197720 --> 1.192174).  Saving model ...
Validation loss decreased (1.192174 --> 1.185622).  Saving model ...
Validation loss decreased (1.185622 --> 1.181130).  Saving model ...
Validation loss decreased (1.181130 --> 1.176756).  Saving model ...
Validation loss decreased (1.176756 --> 1.170549).  Saving model ...
Validation loss decreased (1.170549 --> 1.165287).  Saving model ...
Validation loss decreased (1.165287 --> 1.161094).  Saving model ...
Validation loss decreased (1.161094 --> 1.154929).  Saving model ...
Validation loss decreased (1.154929 --> 1.151110).  Saving model ...
Validation loss decreased (1.151110 --> 1.147104).  Saving model ...
Validation loss decreased (1.147104 --> 1.143196).  Saving model ...
Validation loss decreased (1.143196 --> 1.140040).  Saving model ...
Validation loss decreased (1.140040 --> 1.135848).  Saving model ...
Validation loss decreased (1.135848 --> 1.132287).  Saving model ...
Validation loss decreased (1.132287 --> 1.128823).  Saving model ...
Validation loss decreased (1.128823 --> 1.125529).  Saving model ...
Validation loss decreased (1.125529 --> 1.121062).  Saving model ...
Validation loss decreased (1.121062 --> 1.118014).  Saving model ...
Validation loss decreased (1.118014 --> 1.115598).  Saving model ...
Validation loss decreased (1.115598 --> 1.112053).  Saving model ...
Validation loss decreased (1.112053 --> 1.109017).  Saving model ...
Validation loss decreased (1.109017 --> 1.105845).  Saving model ...
Validation loss decreased (1.105845 --> 1.103047).  Saving model ...
Validation loss decreased (1.103047 --> 1.100112).  Saving model ...
Validation loss decreased (1.100112 --> 1.097509).  Saving model ...
Validation loss decreased (1.097509 --> 1.094410).  Saving model ...
Validation loss decreased (1.094410 --> 1.092171).  Saving model ...
Validation loss decreased (1.092171 --> 1.088578).  Saving model ...
Validation loss decreased (1.088578 --> 1.085096).  Saving model ...
Validation loss decreased (1.085096 --> 1.082371).  Saving model ...
Validation loss decreased (1.082371 --> 1.079937).  Saving model ...
Validation loss decreased (1.079937 --> 1.077009).  Saving model ...
Validation loss decreased (1.077009 --> 1.074071).  Saving model ...
Validation loss decreased (1.074071 --> 1.071601).  Saving model ...
Validation loss decreased (1.071601 --> 1.069278).  Saving model ...
Validation loss decreased (1.069278 --> 1.067087).  Saving model ...
Validation loss decreased (1.067087 --> 1.064289).  Saving model ...
Validation loss decreased (1.064289 --> 1.062449).  Saving model ...
Validation loss decreased (1.062449 --> 1.059893).  Saving model ...
Validation loss decreased (1.059893 --> 1.058239).  Saving model ...
Validation loss decreased (1.058239 --> 1.055910).  Saving model ...
Validation loss decreased (1.055910 --> 1.053715).  Saving model ...
Validation loss decreased (1.053715 --> 1.051811).  Saving model ...
Validation loss decreased (1.051811 --> 1.050102).  Saving model ...
Validation loss decreased (1.050102 --> 1.048023).  Saving model ...
Validation loss decreased (1.048023 --> 1.045607).  Saving model ...
Validation loss decreased (1.045607 --> 1.043014).  Saving model ...
Validation loss decreased (1.043014 --> 1.041775).  Saving model ...
Validation loss decreased (1.041775 --> 1.040986).  Saving model ...
Validation loss decreased (1.040986 --> 1.038764).  Saving model ...
Validation loss decreased (1.038764 --> 1.038222).  Saving model ...
Validation loss decreased (1.038222 --> 1.037447).  Saving model ...
Validation loss decreased (1.037447 --> 1.035567).  Saving model ...
Validation loss decreased (1.035567 --> 1.034435).  Saving model ...
Validation loss decreased (1.034435 --> 1.031529).  Saving model ...
Validation loss decreased (1.031529 --> 1.029959).  Saving model ...
Validation loss decreased (1.029959 --> 1.029204).  Saving model ...
Validation loss decreased (1.029204 --> 1.027950).  Saving model ...
Validation loss decreased (1.027950 --> 1.025903).  Saving model ...
Validation loss decreased (1.025903 --> 1.024575).  Saving model ...
Validation loss decreased (1.024575 --> 1.023031).  Saving model ...
Validation loss decreased (1.023031 --> 1.022277).  Saving model ...
Validation loss decreased (1.022277 --> 1.021693).  Saving model ...
Validation loss decreased (1.021693 --> 1.020631).  Saving model ...
Validation loss decreased (1.020631 --> 1.019267).  Saving model ...
Validation loss decreased (1.019267 --> 1.019109).  Saving model ...
Validation loss decreased (1.019109 --> 1.018520).  Saving model ...
Validation loss decreased (1.018520 --> 1.017883).  Saving model ...
Validation loss decreased (1.017883 --> 1.016581).  Saving model ...
Validation loss decreased (1.016581 --> 1.015972).  Saving model ...
Validation loss decreased (1.015972 --> 1.014418).  Saving model ...
Validation loss decreased (1.014418 --> 1.013602).  Saving model ...
Validation loss decreased (1.013602 --> 1.013237).  Saving model ...
EarlyStopping counter: 1 out of 10.0
EarlyStopping counter: 2 out of 10.0
Validation loss decreased (1.013237 --> 1.011710).  Saving model ...
Validation loss decreased (1.011710 --> 1.010962).  Saving model ...
Validation loss decreased (1.010962 --> 1.009270).  Saving model ...
Validation loss decreased (1.009270 --> 1.009106).  Saving model ...
EarlyStopping counter: 1 out of 10.0
EarlyStopping counter: 2 out of 10.0
Validation loss decreased (1.009106 --> 1.007722).  Saving model ...
Validation loss decreased (1.007722 --> 1.007109).  Saving model ...
Validation loss decreased (1.007109 --> 1.005149).  Saving model ...
Validation loss decreased (1.005149 --> 1.003947).  Saving model ...
Validation loss decreased (1.003947 --> 1.001997).  Saving model ...
EarlyStopping counter: 1 out of 10.0
EarlyStopping counter: 2 out of 10.0
EarlyStopping counter: 3 out of 10.0
EarlyStopping counter: 4 out of 10.0
EarlyStopping counter: 5 out of 10.0
Validation loss decreased (1.001997 --> 1.000726).  Saving model ...
EarlyStopping counter: 1 out of 10.0
EarlyStopping counter: 2 out of 10.0
EarlyStopping counter: 3 out of 10.0
EarlyStopping counter: 4 out of 10.0
EarlyStopping counter: 5 out of 10.0
EarlyStopping counter: 6 out of 10.0
EarlyStopping counter: 7 out of 10.0
Validation loss decreased (1.000726 --> 0.999542).  Saving model ...
EarlyStopping counter: 1 out of 10.0
EarlyStopping counter: 2 out of 10.0
EarlyStopping counter: 3 out of 10.0
EarlyStopping counter: 4 out of 10.0
EarlyStopping counter: 5 out of 10.0
EarlyStopping counter: 6 out of 10.0
EarlyStopping counter: 7 out of 10.0
EarlyStopping counter: 8 out of 10.0
EarlyStopping counter: 9 out of 10.0
EarlyStopping counter: 10 out of 10.0
/localscratch/yinan.29351700.0/env/lib/python3.7/site-packages/torch/nn/functional.py:1794: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.
  warnings.warn("nn.functional.tanh is deprecated. Use torch.tanh instead.")
wandb: Waiting for W&B process to finish, PID 207331... (success).
wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: \ 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: | 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: / 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: \ 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: | 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: / 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: \ 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: | 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: / 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb:                                                                                
wandb: Run history:
wandb:     e_F1 ▁▁▃▄▅▅▅▅▅▆▆▆▆▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇██████████
wandb:   e_loss ██▇▇▇▇▆▆▆▅▅▄▄▄▄▃▃▃▃▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:     t_F1 ▁▁▂▂▃▃▃▄▄▄▄▅▅▅▆▆▆▅▇▆▆▆▇▆▇▇▇▇▇▇▇▇▇█▇█████
wandb:   t_loss ███▇▇▇▇▇▆▆▆▆▅▅▅▅▄▅▄▄▄▄▃▃▃▃▃▃▃▃▂▂▂▂▂▂▁▁▁▁
wandb: 
wandb: Run summary:
wandb:     e_F1 55.58898
wandb:   e_loss 1.00429
wandb:     t_F1 70.37748
wandb:   t_loss 0.7628
wandb: 
wandb: Synced 4 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Synced dry-sun-1: https://wandb.ai/yinanazhou/xl_512_bs_8_lr_1e06_es_10_lc_True_nr_True_sr_False_stem_True_lemma_False_repeat_4_fold_1/runs/3fkg37zo
wandb: Find logs at: ./wandb/run-20220326_092213-3fkg37zo/logs/debug.log
wandb: 

wandb: wandb version 0.12.11 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
2022-03-26 11:02:07.482415: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1
wandb: Tracking run with wandb version 0.12.5
wandb: Syncing run neat-moon-1
wandb: ⭐️ View project at https://wandb.ai/yinanazhou/xl_512_bs_8_lr_1e06_es_10_lc_True_nr_True_sr_False_stem_True_lemma_False_repeat_4_fold_2
wandb: 🚀 View run at https://wandb.ai/yinanazhou/xl_512_bs_8_lr_1e06_es_10_lc_True_nr_True_sr_False_stem_True_lemma_False_repeat_4_fold_2/runs/3kxh3e8y
wandb: Run data is saved locally in /project/6002780/yinan/Thesis_MER_Lyrics/lyric-emotion/wandb/run-20220326_110205-3kxh3e8y
wandb: Run `wandb offline` to turn off syncing.

Validation loss decreased (inf --> 1.487456).  Saving model ...
Validation loss decreased (1.487456 --> 1.448051).  Saving model ...
Validation loss decreased (1.448051 --> 1.421018).  Saving model ...
Validation loss decreased (1.421018 --> 1.401562).  Saving model ...
Validation loss decreased (1.401562 --> 1.387892).  Saving model ...
Validation loss decreased (1.387892 --> 1.377245).  Saving model ...
Validation loss decreased (1.377245 --> 1.370047).  Saving model ...
Validation loss decreased (1.370047 --> 1.363777).  Saving model ...
Validation loss decreased (1.363777 --> 1.358509).  Saving model ...
Validation loss decreased (1.358509 --> 1.354499).  Saving model ...
Validation loss decreased (1.354499 --> 1.350012).  Saving model ...
Validation loss decreased (1.350012 --> 1.346134).  Saving model ...
Validation loss decreased (1.346134 --> 1.342257).  Saving model ...
Validation loss decreased (1.342257 --> 1.338367).  Saving model ...
Validation loss decreased (1.338367 --> 1.334363).  Saving model ...
Validation loss decreased (1.334363 --> 1.330447).  Saving model ...
Validation loss decreased (1.330447 --> 1.327205).  Saving model ...
Validation loss decreased (1.327205 --> 1.322706).  Saving model ...
Validation loss decreased (1.322706 --> 1.318734).  Saving model ...
Validation loss decreased (1.318734 --> 1.313000).  Saving model ...
Validation loss decreased (1.313000 --> 1.308872).  Saving model ...
Validation loss decreased (1.308872 --> 1.303566).  Saving model ...
Validation loss decreased (1.303566 --> 1.299365).  Saving model ...
Validation loss decreased (1.299365 --> 1.294634).  Saving model ...
Validation loss decreased (1.294634 --> 1.291143).  Saving model ...
Validation loss decreased (1.291143 --> 1.285487).  Saving model ...
Validation loss decreased (1.285487 --> 1.280495).  Saving model ...
Validation loss decreased (1.280495 --> 1.274588).  Saving model ...
Validation loss decreased (1.274588 --> 1.268875).  Saving model ...
Validation loss decreased (1.268875 --> 1.264576).  Saving model ...
Validation loss decreased (1.264576 --> 1.259042).  Saving model ...
Validation loss decreased (1.259042 --> 1.253313).  Saving model ...
Validation loss decreased (1.253313 --> 1.247779).  Saving model ...
Validation loss decreased (1.247779 --> 1.244427).  Saving model ...
Validation loss decreased (1.244427 --> 1.237957).  Saving model ...
Validation loss decreased (1.237957 --> 1.232985).  Saving model ...
Validation loss decreased (1.232985 --> 1.224977).  Saving model ...
Validation loss decreased (1.224977 --> 1.220769).  Saving model ...
Validation loss decreased (1.220769 --> 1.215389).  Saving model ...
Validation loss decreased (1.215389 --> 1.213752).  Saving model ...
Validation loss decreased (1.213752 --> 1.210137).  Saving model ...
Validation loss decreased (1.210137 --> 1.204508).  Saving model ...
Validation loss decreased (1.204508 --> 1.201384).  Saving model ...
Validation loss decreased (1.201384 --> 1.199211).  Saving model ...
Validation loss decreased (1.199211 --> 1.195038).  Saving model ...
Validation loss decreased (1.195038 --> 1.186708).  Saving model ...
Validation loss decreased (1.186708 --> 1.182506).  Saving model ...
EarlyStopping counter: 1 out of 10.0
Validation loss decreased (1.182506 --> 1.180137).  Saving model ...
Validation loss decreased (1.180137 --> 1.176151).  Saving model ...
Validation loss decreased (1.176151 --> 1.164005).  Saving model ...
Validation loss decreased (1.164005 --> 1.156773).  Saving model ...
Validation loss decreased (1.156773 --> 1.153230).  Saving model ...
Validation loss decreased (1.153230 --> 1.148760).  Saving model ...
Validation loss decreased (1.148760 --> 1.145840).  Saving model ...
Validation loss decreased (1.145840 --> 1.142558).  Saving model ...
Validation loss decreased (1.142558 --> 1.140546).  Saving model ...
Validation loss decreased (1.140546 --> 1.138660).  Saving model ...
Validation loss decreased (1.138660 --> 1.131358).  Saving model ...
Validation loss decreased (1.131358 --> 1.126136).  Saving model ...
Validation loss decreased (1.126136 --> 1.125141).  Saving model ...
EarlyStopping counter: 1 out of 10.0
Validation loss decreased (1.125141 --> 1.121760).  Saving model ...
Validation loss decreased (1.121760 --> 1.115834).  Saving model ...
Validation loss decreased (1.115834 --> 1.110473).  Saving model ...
Validation loss decreased (1.110473 --> 1.108218).  Saving model ...
Validation loss decreased (1.108218 --> 1.106708).  Saving model ...
Validation loss decreased (1.106708 --> 1.104925).  Saving model ...
Validation loss decreased (1.104925 --> 1.101376).  Saving model ...
Validation loss decreased (1.101376 --> 1.097307).  Saving model ...
Validation loss decreased (1.097307 --> 1.093389).  Saving model ...
Validation loss decreased (1.093389 --> 1.089829).  Saving model ...
Validation loss decreased (1.089829 --> 1.084963).  Saving model ...
Validation loss decreased (1.084963 --> 1.084291).  Saving model ...
Validation loss decreased (1.084291 --> 1.084271).  Saving model ...
Validation loss decreased (1.084271 --> 1.082576).  Saving model ...
EarlyStopping counter: 1 out of 10.0
Validation loss decreased (1.082576 --> 1.076646).  Saving model ...
EarlyStopping counter: 1 out of 10.0
Validation loss decreased (1.076646 --> 1.073047).  Saving model ...
Validation loss decreased (1.073047 --> 1.070047).  Saving model ...
EarlyStopping counter: 1 out of 10.0
Validation loss decreased (1.070047 --> 1.069433).  Saving model ...
EarlyStopping counter: 1 out of 10.0
Validation loss decreased (1.069433 --> 1.068090).  Saving model ...
Validation loss decreased (1.068090 --> 1.062059).  Saving model ...
Validation loss decreased (1.062059 --> 1.057627).  Saving model ...
Validation loss decreased (1.057627 --> 1.053877).  Saving model ...
Validation loss decreased (1.053877 --> 1.051470).  Saving model ...
EarlyStopping counter: 1 out of 10.0
Validation loss decreased (1.051470 --> 1.049877).  Saving model ...
Validation loss decreased (1.049877 --> 1.049353).  Saving model ...
EarlyStopping counter: 1 out of 10.0
EarlyStopping counter: 2 out of 10.0
Validation loss decreased (1.049353 --> 1.046401).  Saving model ...
Validation loss decreased (1.046401 --> 1.043381).  Saving model ...
Validation loss decreased (1.043381 --> 1.041490).  Saving model ...
Validation loss decreased (1.041490 --> 1.040393).  Saving model ...
Validation loss decreased (1.040393 --> 1.038613).  Saving model ...
Validation loss decreased (1.038613 --> 1.036432).  Saving model ...
EarlyStopping counter: 1 out of 10.0
EarlyStopping counter: 2 out of 10.0
EarlyStopping counter: 3 out of 10.0
Validation loss decreased (1.036432 --> 1.034064).  Saving model ...
Validation loss decreased (1.034064 --> 1.032431).  Saving model ...
Validation loss decreased (1.032431 --> 1.027828).  Saving model ...
EarlyStopping counter: 1 out of 10.0
EarlyStopping counter: 2 out of 10.0
Validation loss decreased (1.027828 --> 1.026796).  Saving model ...
EarlyStopping counter: 1 out of 10.0
Validation loss decreased (1.026796 --> 1.026717).  Saving model ...
EarlyStopping counter: 1 out of 10.0
EarlyStopping counter: 2 out of 10.0
Validation loss decreased (1.026717 --> 1.026471).  Saving model ...
EarlyStopping counter: 1 out of 10.0
Validation loss decreased (1.026471 --> 1.022954).  Saving model ...
Validation loss decreased (1.022954 --> 1.022118).  Saving model ...
EarlyStopping counter: 1 out of 10.0
EarlyStopping counter: 2 out of 10.0
EarlyStopping counter: 3 out of 10.0
EarlyStopping counter: 4 out of 10.0
Validation loss decreased (1.022118 --> 1.021520).  Saving model ...
Validation loss decreased (1.021520 --> 1.019968).  Saving model ...
EarlyStopping counter: 1 out of 10.0
EarlyStopping counter: 2 out of 10.0
Validation loss decreased (1.019968 --> 1.019674).  Saving model ...
Validation loss decreased (1.019674 --> 1.018304).  Saving model ...
EarlyStopping counter: 1 out of 10.0
EarlyStopping counter: 2 out of 10.0
EarlyStopping counter: 3 out of 10.0
Validation loss decreased (1.018304 --> 1.017155).  Saving model ...
Validation loss decreased (1.017155 --> 1.014562).  Saving model ...
Validation loss decreased (1.014562 --> 1.014028).  Saving model ...
EarlyStopping counter: 1 out of 10.0
EarlyStopping counter: 2 out of 10.0
EarlyStopping counter: 3 out of 10.0
EarlyStopping counter: 4 out of 10.0
EarlyStopping counter: 5 out of 10.0
EarlyStopping counter: 6 out of 10.0
EarlyStopping counter: 7 out of 10.0
EarlyStopping counter: 8 out of 10.0
EarlyStopping counter: 9 out of 10.0
EarlyStopping counter: 10 out of 10.0
/localscratch/yinan.29351700.0/env/lib/python3.7/site-packages/torch/nn/functional.py:1794: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.
  warnings.warn("nn.functional.tanh is deprecated. Use torch.tanh instead.")
wandb: Waiting for W&B process to finish, PID 212657... (success).
wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: \ 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: | 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: / 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: \ 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: | 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: / 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: \ 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: | 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: / 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb:                                                                                
wandb: Run history:
wandb:     e_F1 ▁▁▄▅▅▅▆▆▆▆▇▇▇▇▇▇▇███████████████████████
wandb:   e_loss █▇▇▆▆▆▆▅▅▅▅▄▄▄▃▃▃▃▃▂▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:     t_F1 ▁▂▃▃▃▃▄▄▅▅▅▅▅▅▆▆▆▆▆▆▆▆▆▇▆▇▇▇▇▇▇▇▇███████
wandb:   t_loss █▇▇▇▇▇▆▆▆▆▅▅▅▅▄▄▄▄▄▄▄▃▃▃▃▃▃▂▂▂▂▂▂▂▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:     e_F1 55.57664
wandb:   e_loss 1.02247
wandb:     t_F1 66.76501
wandb:   t_loss 0.79665
wandb: 
wandb: Synced 4 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Synced neat-moon-1: https://wandb.ai/yinanazhou/xl_512_bs_8_lr_1e06_es_10_lc_True_nr_True_sr_False_stem_True_lemma_False_repeat_4_fold_2/runs/3kxh3e8y
wandb: Find logs at: ./wandb/run-20220326_110205-3kxh3e8y/logs/debug.log
wandb: 

wandb: wandb version 0.12.11 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
2022-03-26 12:33:58.476366: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1
wandb: Tracking run with wandb version 0.12.5
wandb: Syncing run pious-sun-1
wandb: ⭐️ View project at https://wandb.ai/yinanazhou/xl_512_bs_8_lr_1e06_es_10_lc_True_nr_True_sr_False_stem_True_lemma_False_repeat_5_fold_1
wandb: 🚀 View run at https://wandb.ai/yinanazhou/xl_512_bs_8_lr_1e06_es_10_lc_True_nr_True_sr_False_stem_True_lemma_False_repeat_5_fold_1/runs/bs2k8ayb
wandb: Run data is saved locally in /project/6002780/yinan/Thesis_MER_Lyrics/lyric-emotion/wandb/run-20220326_123356-bs2k8ayb
wandb: Run `wandb offline` to turn off syncing.

Validation loss decreased (inf --> 1.432125).  Saving model ...
Validation loss decreased (1.432125 --> 1.414871).  Saving model ...
Validation loss decreased (1.414871 --> 1.404031).  Saving model ...
Validation loss decreased (1.404031 --> 1.395694).  Saving model ...
Validation loss decreased (1.395694 --> 1.388994).  Saving model ...
Validation loss decreased (1.388994 --> 1.384045).  Saving model ...
Validation loss decreased (1.384045 --> 1.379545).  Saving model ...
Validation loss decreased (1.379545 --> 1.375742).  Saving model ...
Validation loss decreased (1.375742 --> 1.371780).  Saving model ...
Validation loss decreased (1.371780 --> 1.368298).  Saving model ...
Validation loss decreased (1.368298 --> 1.364688).  Saving model ...
Validation loss decreased (1.364688 --> 1.361030).  Saving model ...
Validation loss decreased (1.361030 --> 1.357697).  Saving model ...
Validation loss decreased (1.357697 --> 1.354383).  Saving model ...
Validation loss decreased (1.354383 --> 1.351387).  Saving model ...
Validation loss decreased (1.351387 --> 1.347870).  Saving model ...
Validation loss decreased (1.347870 --> 1.344350).  Saving model ...
Validation loss decreased (1.344350 --> 1.340527).  Saving model ...
Validation loss decreased (1.340527 --> 1.336891).  Saving model ...
Validation loss decreased (1.336891 --> 1.333148).  Saving model ...
Validation loss decreased (1.333148 --> 1.328991).  Saving model ...
Validation loss decreased (1.328991 --> 1.325076).  Saving model ...
Validation loss decreased (1.325076 --> 1.320857).  Saving model ...
Validation loss decreased (1.320857 --> 1.316466).  Saving model ...
Validation loss decreased (1.316466 --> 1.311986).  Saving model ...
Validation loss decreased (1.311986 --> 1.307825).  Saving model ...
Validation loss decreased (1.307825 --> 1.303410).  Saving model ...
Validation loss decreased (1.303410 --> 1.299049).  Saving model ...
Validation loss decreased (1.299049 --> 1.294282).  Saving model ...
Validation loss decreased (1.294282 --> 1.289265).  Saving model ...
Validation loss decreased (1.289265 --> 1.284497).  Saving model ...
Validation loss decreased (1.284497 --> 1.279048).  Saving model ...
Validation loss decreased (1.279048 --> 1.273590).  Saving model ...
Validation loss decreased (1.273590 --> 1.268397).  Saving model ...
Validation loss decreased (1.268397 --> 1.262665).  Saving model ...
Validation loss decreased (1.262665 --> 1.257006).  Saving model ...
Validation loss decreased (1.257006 --> 1.251430).  Saving model ...
Validation loss decreased (1.251430 --> 1.246036).  Saving model ...
Validation loss decreased (1.246036 --> 1.239765).  Saving model ...
Validation loss decreased (1.239765 --> 1.234526).  Saving model ...
Validation loss decreased (1.234526 --> 1.228032).  Saving model ...
Validation loss decreased (1.228032 --> 1.221565).  Saving model ...
Validation loss decreased (1.221565 --> 1.215133).  Saving model ...
Validation loss decreased (1.215133 --> 1.209370).  Saving model ...
Validation loss decreased (1.209370 --> 1.204573).  Saving model ...
Validation loss decreased (1.204573 --> 1.199858).  Saving model ...
Validation loss decreased (1.199858 --> 1.194642).  Saving model ...
Validation loss decreased (1.194642 --> 1.189270).  Saving model ...
Validation loss decreased (1.189270 --> 1.184588).  Saving model ...
Validation loss decreased (1.184588 --> 1.178909).  Saving model ...
Validation loss decreased (1.178909 --> 1.174230).  Saving model ...
Validation loss decreased (1.174230 --> 1.170158).  Saving model ...
Validation loss decreased (1.170158 --> 1.166774).  Saving model ...
Validation loss decreased (1.166774 --> 1.163112).  Saving model ...
Validation loss decreased (1.163112 --> 1.158933).  Saving model ...
Validation loss decreased (1.158933 --> 1.153901).  Saving model ...
Validation loss decreased (1.153901 --> 1.150064).  Saving model ...
Validation loss decreased (1.150064 --> 1.145397).  Saving model ...
Validation loss decreased (1.145397 --> 1.140988).  Saving model ...
Validation loss decreased (1.140988 --> 1.137583).  Saving model ...
Validation loss decreased (1.137583 --> 1.133528).  Saving model ...
Validation loss decreased (1.133528 --> 1.128981).  Saving model ...
Validation loss decreased (1.128981 --> 1.125138).  Saving model ...
Validation loss decreased (1.125138 --> 1.122570).  Saving model ...
Validation loss decreased (1.122570 --> 1.120004).  Saving model ...
Validation loss decreased (1.120004 --> 1.116100).  Saving model ...
Validation loss decreased (1.116100 --> 1.112031).  Saving model ...
Validation loss decreased (1.112031 --> 1.107804).  Saving model ...
Validation loss decreased (1.107804 --> 1.104515).  Saving model ...
Validation loss decreased (1.104515 --> 1.100761).  Saving model ...
Validation loss decreased (1.100761 --> 1.097604).  Saving model ...
Validation loss decreased (1.097604 --> 1.094610).  Saving model ...
Validation loss decreased (1.094610 --> 1.091427).  Saving model ...
Validation loss decreased (1.091427 --> 1.088725).  Saving model ...
Validation loss decreased (1.088725 --> 1.085801).  Saving model ...
Validation loss decreased (1.085801 --> 1.083253).  Saving model ...
Validation loss decreased (1.083253 --> 1.081082).  Saving model ...
Validation loss decreased (1.081082 --> 1.079657).  Saving model ...
Validation loss decreased (1.079657 --> 1.076251).  Saving model ...
Validation loss decreased (1.076251 --> 1.072689).  Saving model ...
Validation loss decreased (1.072689 --> 1.069238).  Saving model ...
Validation loss decreased (1.069238 --> 1.066910).  Saving model ...
Validation loss decreased (1.066910 --> 1.065667).  Saving model ...
Validation loss decreased (1.065667 --> 1.063366).  Saving model ...
Validation loss decreased (1.063366 --> 1.061267).  Saving model ...
Validation loss decreased (1.061267 --> 1.058826).  Saving model ...
Validation loss decreased (1.058826 --> 1.056915).  Saving model ...
Validation loss decreased (1.056915 --> 1.054824).  Saving model ...
Validation loss decreased (1.054824 --> 1.052267).  Saving model ...
Validation loss decreased (1.052267 --> 1.049488).  Saving model ...
Validation loss decreased (1.049488 --> 1.047867).  Saving model ...
Validation loss decreased (1.047867 --> 1.046444).  Saving model ...
Validation loss decreased (1.046444 --> 1.043924).  Saving model ...
Validation loss decreased (1.043924 --> 1.042097).  Saving model ...
Validation loss decreased (1.042097 --> 1.040341).  Saving model ...
Validation loss decreased (1.040341 --> 1.038354).  Saving model ...
Validation loss decreased (1.038354 --> 1.037365).  Saving model ...
Validation loss decreased (1.037365 --> 1.036200).  Saving model ...
Validation loss decreased (1.036200 --> 1.034067).  Saving model ...
Validation loss decreased (1.034067 --> 1.033001).  Saving model ...
Validation loss decreased (1.033001 --> 1.031613).  Saving model ...
Validation loss decreased (1.031613 --> 1.029961).  Saving model ...
Validation loss decreased (1.029961 --> 1.028778).  Saving model ...
Validation loss decreased (1.028778 --> 1.028734).  Saving model ...
Validation loss decreased (1.028734 --> 1.027660).  Saving model ...
Validation loss decreased (1.027660 --> 1.025698).  Saving model ...
Validation loss decreased (1.025698 --> 1.023749).  Saving model ...
Validation loss decreased (1.023749 --> 1.021559).  Saving model ...
Validation loss decreased (1.021559 --> 1.020999).  Saving model ...
Validation loss decreased (1.020999 --> 1.019746).  Saving model ...
Validation loss decreased (1.019746 --> 1.019583).  Saving model ...
Validation loss decreased (1.019583 --> 1.018212).  Saving model ...
Validation loss decreased (1.018212 --> 1.016915).  Saving model ...
Validation loss decreased (1.016915 --> 1.015818).  Saving model ...
Validation loss decreased (1.015818 --> 1.015074).  Saving model ...
Validation loss decreased (1.015074 --> 1.013854).  Saving model ...
Validation loss decreased (1.013854 --> 1.012794).  Saving model ...
Validation loss decreased (1.012794 --> 1.012160).  Saving model ...
EarlyStopping counter: 1 out of 10.0
Validation loss decreased (1.012160 --> 1.012076).  Saving model ...
Validation loss decreased (1.012076 --> 1.009489).  Saving model ...
Validation loss decreased (1.009489 --> 1.009065).  Saving model ...
Validation loss decreased (1.009065 --> 1.008316).  Saving model ...
Validation loss decreased (1.008316 --> 1.006876).  Saving model ...
Validation loss decreased (1.006876 --> 1.005860).  Saving model ...
Validation loss decreased (1.005860 --> 1.005413).  Saving model ...
Validation loss decreased (1.005413 --> 1.004714).  Saving model ...
Validation loss decreased (1.004714 --> 1.004393).  Saving model ...
Validation loss decreased (1.004393 --> 1.003610).  Saving model ...
Validation loss decreased (1.003610 --> 1.003583).  Saving model ...
Validation loss decreased (1.003583 --> 1.003307).  Saving model ...
Validation loss decreased (1.003307 --> 1.002017).  Saving model ...
Validation loss decreased (1.002017 --> 1.001949).  Saving model ...
Validation loss decreased (1.001949 --> 1.000776).  Saving model ...
Validation loss decreased (1.000776 --> 1.000690).  Saving model ...
Validation loss decreased (1.000690 --> 1.000335).  Saving model ...
Validation loss decreased (1.000335 --> 0.999580).  Saving model ...
EarlyStopping counter: 1 out of 10.0
EarlyStopping counter: 2 out of 10.0
EarlyStopping counter: 3 out of 10.0
EarlyStopping counter: 4 out of 10.0
EarlyStopping counter: 5 out of 10.0
EarlyStopping counter: 6 out of 10.0
Validation loss decreased (0.999580 --> 0.999396).  Saving model ...
EarlyStopping counter: 1 out of 10.0
EarlyStopping counter: 2 out of 10.0
Validation loss decreased (0.999396 --> 0.999358).  Saving model ...
Validation loss decreased (0.999358 --> 0.998860).  Saving model ...
Validation loss decreased (0.998860 --> 0.998688).  Saving model ...
Validation loss decreased (0.998688 --> 0.998029).  Saving model ...
Validation loss decreased (0.998029 --> 0.997673).  Saving model ...
EarlyStopping counter: 1 out of 10.0
EarlyStopping counter: 2 out of 10.0
EarlyStopping counter: 3 out of 10.0
EarlyStopping counter: 4 out of 10.0
EarlyStopping counter: 5 out of 10.0
EarlyStopping counter: 6 out of 10.0
EarlyStopping counter: 7 out of 10.0
EarlyStopping counter: 8 out of 10.0
EarlyStopping counter: 9 out of 10.0
EarlyStopping counter: 10 out of 10.0
/localscratch/yinan.29351700.0/env/lib/python3.7/site-packages/torch/nn/functional.py:1794: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.
  warnings.warn("nn.functional.tanh is deprecated. Use torch.tanh instead.")
wandb: Waiting for W&B process to finish, PID 217588... (success).
wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: \ 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: | 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: / 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: \ 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: | 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: / 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: \ 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: | 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: / 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb:                                                                                
wandb: Run history:
wandb:     e_F1 ▁▃▄▄▄▄▅▅▅▆▆▆▆▇▇▇▇▇▇▇▇▇██████████████████
wandb:   e_loss █▇▇▇▇▆▆▆▆▅▅▄▄▄▃▃▃▃▃▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:     t_F1 ▁▂▂▃▃▃▃▄▄▅▅▅▆▅▆▅▆▇▆▆▆▆▇▆▇▇▇▇▇▇▇▇▇▇▇▇████
wandb:   t_loss ███▇▇▇▇▆▆▆▆▆▅▅▅▅▄▄▄▄▄▄▃▃▃▃▃▂▃▂▂▂▂▂▂▂▁▁▁▁
wandb: 
wandb: Run summary:
wandb:     e_F1 54.42745
wandb:   e_loss 1.00147
wandb:     t_F1 73.43625
wandb:   t_loss 0.70667
wandb: 
wandb: Synced 4 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Synced pious-sun-1: https://wandb.ai/yinanazhou/xl_512_bs_8_lr_1e06_es_10_lc_True_nr_True_sr_False_stem_True_lemma_False_repeat_5_fold_1/runs/bs2k8ayb
wandb: Find logs at: ./wandb/run-20220326_123356-bs2k8ayb/logs/debug.log
wandb: 

wandb: wandb version 0.12.11 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
2022-03-26 14:15:48.377326: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1
wandb: Tracking run with wandb version 0.12.5
wandb: Syncing run copper-pond-1
wandb: ⭐️ View project at https://wandb.ai/yinanazhou/xl_512_bs_8_lr_1e06_es_10_lc_True_nr_True_sr_False_stem_True_lemma_False_repeat_5_fold_2
wandb: 🚀 View run at https://wandb.ai/yinanazhou/xl_512_bs_8_lr_1e06_es_10_lc_True_nr_True_sr_False_stem_True_lemma_False_repeat_5_fold_2/runs/1w2lgpao
wandb: Run data is saved locally in /project/6002780/yinan/Thesis_MER_Lyrics/lyric-emotion/wandb/run-20220326_141546-1w2lgpao
wandb: Run `wandb offline` to turn off syncing.

Validation loss decreased (inf --> 1.431630).  Saving model ...
Validation loss decreased (1.431630 --> 1.413961).  Saving model ...
Validation loss decreased (1.413961 --> 1.400556).  Saving model ...
Validation loss decreased (1.400556 --> 1.390354).  Saving model ...
Validation loss decreased (1.390354 --> 1.382918).  Saving model ...
Validation loss decreased (1.382918 --> 1.376362).  Saving model ...
Validation loss decreased (1.376362 --> 1.370833).  Saving model ...
Validation loss decreased (1.370833 --> 1.365959).  Saving model ...
Validation loss decreased (1.365959 --> 1.361748).  Saving model ...
Validation loss decreased (1.361748 --> 1.357713).  Saving model ...
Validation loss decreased (1.357713 --> 1.353491).  Saving model ...
Validation loss decreased (1.353491 --> 1.349276).  Saving model ...
Validation loss decreased (1.349276 --> 1.345152).  Saving model ...
Validation loss decreased (1.345152 --> 1.340826).  Saving model ...
Validation loss decreased (1.340826 --> 1.336370).  Saving model ...
Validation loss decreased (1.336370 --> 1.331540).  Saving model ...
Validation loss decreased (1.331540 --> 1.326952).  Saving model ...
Validation loss decreased (1.326952 --> 1.322457).  Saving model ...
Validation loss decreased (1.322457 --> 1.318032).  Saving model ...
Validation loss decreased (1.318032 --> 1.312470).  Saving model ...
Validation loss decreased (1.312470 --> 1.307268).  Saving model ...
Validation loss decreased (1.307268 --> 1.301601).  Saving model ...
Validation loss decreased (1.301601 --> 1.295508).  Saving model ...
Validation loss decreased (1.295508 --> 1.289486).  Saving model ...
Validation loss decreased (1.289486 --> 1.283167).  Saving model ...
Validation loss decreased (1.283167 --> 1.277109).  Saving model ...
Validation loss decreased (1.277109 --> 1.269048).  Saving model ...
Validation loss decreased (1.269048 --> 1.261930).  Saving model ...
Validation loss decreased (1.261930 --> 1.256015).  Saving model ...
Validation loss decreased (1.256015 --> 1.249968).  Saving model ...
Validation loss decreased (1.249968 --> 1.243837).  Saving model ...
Validation loss decreased (1.243837 --> 1.237256).  Saving model ...
Validation loss decreased (1.237256 --> 1.230775).  Saving model ...
Validation loss decreased (1.230775 --> 1.224810).  Saving model ...
Validation loss decreased (1.224810 --> 1.218635).  Saving model ...
Validation loss decreased (1.218635 --> 1.210273).  Saving model ...
Validation loss decreased (1.210273 --> 1.204515).  Saving model ...
Validation loss decreased (1.204515 --> 1.199252).  Saving model ...
Validation loss decreased (1.199252 --> 1.194630).  Saving model ...
Validation loss decreased (1.194630 --> 1.188433).  Saving model ...
Validation loss decreased (1.188433 --> 1.183123).  Saving model ...
Validation loss decreased (1.183123 --> 1.177983).  Saving model ...
Validation loss decreased (1.177983 --> 1.172958).  Saving model ...
Validation loss decreased (1.172958 --> 1.168627).  Saving model ...
Validation loss decreased (1.168627 --> 1.164956).  Saving model ...
Validation loss decreased (1.164956 --> 1.161195).  Saving model ...
Validation loss decreased (1.161195 --> 1.156712).  Saving model ...
Validation loss decreased (1.156712 --> 1.150285).  Saving model ...
Validation loss decreased (1.150285 --> 1.143124).  Saving model ...
Validation loss decreased (1.143124 --> 1.139343).  Saving model ...
Validation loss decreased (1.139343 --> 1.134868).  Saving model ...
Validation loss decreased (1.134868 --> 1.131283).  Saving model ...
Validation loss decreased (1.131283 --> 1.127803).  Saving model ...
Validation loss decreased (1.127803 --> 1.121483).  Saving model ...
Validation loss decreased (1.121483 --> 1.119741).  Saving model ...
Validation loss decreased (1.119741 --> 1.116677).  Saving model ...
Validation loss decreased (1.116677 --> 1.112732).  Saving model ...
Validation loss decreased (1.112732 --> 1.111384).  Saving model ...
Validation loss decreased (1.111384 --> 1.105114).  Saving model ...
Validation loss decreased (1.105114 --> 1.103465).  Saving model ...
Validation loss decreased (1.103465 --> 1.100285).  Saving model ...
Validation loss decreased (1.100285 --> 1.096374).  Saving model ...
Validation loss decreased (1.096374 --> 1.096373).  Saving model ...
Validation loss decreased (1.096373 --> 1.091130).  Saving model ...
Validation loss decreased (1.091130 --> 1.085972).  Saving model ...
Validation loss decreased (1.085972 --> 1.082398).  Saving model ...
Validation loss decreased (1.082398 --> 1.078586).  Saving model ...
Validation loss decreased (1.078586 --> 1.076270).  Saving model ...
Validation loss decreased (1.076270 --> 1.075346).  Saving model ...
Validation loss decreased (1.075346 --> 1.072341).  Saving model ...
Validation loss decreased (1.072341 --> 1.070020).  Saving model ...
Validation loss decreased (1.070020 --> 1.066097).  Saving model ...
Validation loss decreased (1.066097 --> 1.063088).  Saving model ...
Validation loss decreased (1.063088 --> 1.061282).  Saving model ...
Validation loss decreased (1.061282 --> 1.060821).  Saving model ...
Validation loss decreased (1.060821 --> 1.060248).  Saving model ...
Validation loss decreased (1.060248 --> 1.055290).  Saving model ...
Validation loss decreased (1.055290 --> 1.053944).  Saving model ...
Validation loss decreased (1.053944 --> 1.049630).  Saving model ...
Validation loss decreased (1.049630 --> 1.047619).  Saving model ...
Validation loss decreased (1.047619 --> 1.045436).  Saving model ...
Validation loss decreased (1.045436 --> 1.041649).  Saving model ...
EarlyStopping counter: 1 out of 10.0
Validation loss decreased (1.041649 --> 1.040547).  Saving model ...
Validation loss decreased (1.040547 --> 1.035439).  Saving model ...
Validation loss decreased (1.035439 --> 1.031476).  Saving model ...
Validation loss decreased (1.031476 --> 1.029593).  Saving model ...
Validation loss decreased (1.029593 --> 1.029253).  Saving model ...
Validation loss decreased (1.029253 --> 1.025859).  Saving model ...
EarlyStopping counter: 1 out of 10.0
Validation loss decreased (1.025859 --> 1.022718).  Saving model ...
Validation loss decreased (1.022718 --> 1.020680).  Saving model ...
Validation loss decreased (1.020680 --> 1.018487).  Saving model ...
Validation loss decreased (1.018487 --> 1.017973).  Saving model ...
Validation loss decreased (1.017973 --> 1.015517).  Saving model ...
EarlyStopping counter: 1 out of 10.0
Validation loss decreased (1.015517 --> 1.015400).  Saving model ...
Validation loss decreased (1.015400 --> 1.012645).  Saving model ...
Validation loss decreased (1.012645 --> 1.011945).  Saving model ...
Validation loss decreased (1.011945 --> 1.007186).  Saving model ...
Validation loss decreased (1.007186 --> 1.007183).  Saving model ...
Validation loss decreased (1.007183 --> 1.006177).  Saving model ...
EarlyStopping counter: 1 out of 10.0
Validation loss decreased (1.006177 --> 1.001571).  Saving model ...
Validation loss decreased (1.001571 --> 1.001353).  Saving model ...
EarlyStopping counter: 1 out of 10.0
Validation loss decreased (1.001353 --> 1.000971).  Saving model ...
Validation loss decreased (1.000971 --> 0.998947).  Saving model ...
Validation loss decreased (0.998947 --> 0.995279).  Saving model ...
Validation loss decreased (0.995279 --> 0.993408).  Saving model ...
EarlyStopping counter: 1 out of 10.0
EarlyStopping counter: 2 out of 10.0
Validation loss decreased (0.993408 --> 0.993105).  Saving model ...
Validation loss decreased (0.993105 --> 0.989079).  Saving model ...
Validation loss decreased (0.989079 --> 0.987212).  Saving model ...
EarlyStopping counter: 1 out of 10.0
Validation loss decreased (0.987212 --> 0.986654).  Saving model ...
EarlyStopping counter: 1 out of 10.0
Validation loss decreased (0.986654 --> 0.986100).  Saving model ...
Validation loss decreased (0.986100 --> 0.985455).  Saving model ...
Validation loss decreased (0.985455 --> 0.983714).  Saving model ...
EarlyStopping counter: 1 out of 10.0
EarlyStopping counter: 2 out of 10.0
Validation loss decreased (0.983714 --> 0.979637).  Saving model ...
Validation loss decreased (0.979637 --> 0.979079).  Saving model ...
EarlyStopping counter: 1 out of 10.0
EarlyStopping counter: 2 out of 10.0
Validation loss decreased (0.979079 --> 0.978305).  Saving model ...
EarlyStopping counter: 1 out of 10.0
Validation loss decreased (0.978305 --> 0.976493).  Saving model ...
Validation loss decreased (0.976493 --> 0.975549).  Saving model ...
Validation loss decreased (0.975549 --> 0.973935).  Saving model ...
Validation loss decreased (0.973935 --> 0.973713).  Saving model ...
Validation loss decreased (0.973713 --> 0.972357).  Saving model ...
EarlyStopping counter: 1 out of 10.0
EarlyStopping counter: 2 out of 10.0
EarlyStopping counter: 3 out of 10.0
Validation loss decreased (0.972357 --> 0.970027).  Saving model ...
Validation loss decreased (0.970027 --> 0.969159).  Saving model ...
Validation loss decreased (0.969159 --> 0.967390).  Saving model ...
Validation loss decreased (0.967390 --> 0.966020).  Saving model ...
EarlyStopping counter: 1 out of 10.0
Validation loss decreased (0.966020 --> 0.965518).  Saving model ...
EarlyStopping counter: 1 out of 10.0
EarlyStopping counter: 2 out of 10.0
Validation loss decreased (0.965518 --> 0.964130).  Saving model ...
Validation loss decreased (0.964130 --> 0.963934).  Saving model ...
EarlyStopping counter: 1 out of 10.0
EarlyStopping counter: 2 out of 10.0
EarlyStopping counter: 3 out of 10.0
EarlyStopping counter: 4 out of 10.0
Validation loss decreased (0.963934 --> 0.962840).  Saving model ...
EarlyStopping counter: 1 out of 10.0
EarlyStopping counter: 2 out of 10.0
EarlyStopping counter: 3 out of 10.0
EarlyStopping counter: 4 out of 10.0
EarlyStopping counter: 5 out of 10.0
EarlyStopping counter: 6 out of 10.0
EarlyStopping counter: 7 out of 10.0
Validation loss decreased (0.962840 --> 0.961892).  Saving model ...
EarlyStopping counter: 1 out of 10.0
EarlyStopping counter: 2 out of 10.0
Validation loss decreased (0.961892 --> 0.961623).  Saving model ...
EarlyStopping counter: 1 out of 10.0
EarlyStopping counter: 2 out of 10.0
EarlyStopping counter: 3 out of 10.0
EarlyStopping counter: 4 out of 10.0
Validation loss decreased (0.961623 --> 0.959949).  Saving model ...
EarlyStopping counter: 1 out of 10.0
EarlyStopping counter: 2 out of 10.0
EarlyStopping counter: 3 out of 10.0
EarlyStopping counter: 4 out of 10.0
EarlyStopping counter: 5 out of 10.0
EarlyStopping counter: 6 out of 10.0
EarlyStopping counter: 7 out of 10.0
EarlyStopping counter: 8 out of 10.0
EarlyStopping counter: 9 out of 10.0
Validation loss decreased (0.959949 --> 0.959759).  Saving model ...
Validation loss decreased (0.959759 --> 0.958438).  Saving model ...
EarlyStopping counter: 1 out of 10.0
EarlyStopping counter: 2 out of 10.0
EarlyStopping counter: 3 out of 10.0
EarlyStopping counter: 4 out of 10.0
EarlyStopping counter: 5 out of 10.0
EarlyStopping counter: 6 out of 10.0
EarlyStopping counter: 7 out of 10.0
EarlyStopping counter: 8 out of 10.0
EarlyStopping counter: 9 out of 10.0
EarlyStopping counter: 10 out of 10.0
/localscratch/yinan.29351700.0/env/lib/python3.7/site-packages/torch/nn/functional.py:1794: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.
  warnings.warn("nn.functional.tanh is deprecated. Use torch.tanh instead.")
wandb: Waiting for W&B process to finish, PID 223025... (success).
wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: \ 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: | 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: / 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: \ 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: | 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: / 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: \ 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: | 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: / 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb:                                                                                
wandb: Run history:
wandb:     e_F1 ▁▃▄▄▅▅▆▆▆▆▇▇▇▇▇▇▇▇▇▇▇▇▇█████████████████
wandb:   e_loss █▇▇▇▆▆▅▅▅▄▄▃▃▃▃▃▂▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:     t_F1 ▁▂▂▃▄▄▅▅▅▆▅▅▅▆▆▆▆▆▆▇▆▇▇▇▇▇▇▇▇▇▇▇██▇█████
wandb:   t_loss █▇▇▇▇▇▆▆▆▅▅▅▅▄▄▄▄▄▄▃▃▃▃▃▃▂▂▂▂▂▂▂▂▂▁▂▁▁▁▁
wandb: 
wandb: Run summary:
wandb:     e_F1 60.44404
wandb:   e_loss 0.96424
wandb:     t_F1 73.00191
wandb:   t_loss 0.72302
wandb: 
wandb: Synced 4 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Synced copper-pond-1: https://wandb.ai/yinanazhou/xl_512_bs_8_lr_1e06_es_10_lc_True_nr_True_sr_False_stem_True_lemma_False_repeat_5_fold_2/runs/1w2lgpao
wandb: Find logs at: ./wandb/run-20220326_141546-1w2lgpao/logs/debug.log
wandb: 

