Unloading StdEnv/2020

Due to MODULEPATH changes, the following have been reloaded:
  1) mii/1.1.1


The following have been reloaded with a version change:
  1) python/3.8.2 => python/3.7.4

Using base prefix '/cvmfs/soft.computecanada.ca/easybuild/software/2017/Core/python/3.7.4'
New python executable in /localscratch/yinan.28959366.0/env/bin/python
Installing setuptools, pip, wheel...
done.
Ignoring pip: markers 'python_version < "3"' don't match your environment
Looking in links: /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/nix/avx2, /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/nix/generic, /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic
Collecting pip
Installing collected packages: pip
  Found existing installation: pip 19.1.1
    Uninstalling pip-19.1.1:
      Successfully uninstalled pip-19.1.1
Successfully installed pip-21.2.3+computecanada
Looking in links: /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/nix/avx2, /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/nix/generic, /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/keras-2.8.0+computecanada-py2.py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/Keras_Preprocessing-1.1.2+computecanada-py3-none-any.whl
Requirement already satisfied: matplotlib in /cvmfs/soft.computecanada.ca/easybuild/software/2017/Core/scipy-stack/2019a/lib/python3.7/site-packages (from -r requirements.txt (line 3)) (3.0.2)
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/nltk-3.6.5+computecanada-py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/scikit_learn-0.22.1+computecanada-cp37-cp37m-linux_x86_64.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/tensorboard-2.3.0+computecanada-py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/tensorboard_plugin_wit-1.7.0+computecanada-py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/tensorflow_gpu-2.3.0+computecanada-cp37-cp37m-linux_x86_64.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/tensorflow_estimator-2.3.0+computecanada-py2.py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/tokenizers-0.5.2+computecanada-cp37-cp37m-linux_x86_64.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/nix/avx2/torch-1.4.0+computecanada-cp37-cp37m-linux_x86_64.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/torchtext-0.6.0+computecanada-py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/torchvision-0.8.2+computecanada-cp37-cp37m-linux_x86_64.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/transformers-2.5.1+computecanada-py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/urllib3-1.26.7+computecanada-py2.py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/joblib-1.1.0+computecanada-py2.py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/click-8.0.3+computecanada-py3-none-any.whl
ERROR: Could not find a version that satisfies the requirement regex>=2021.8.3 (from nltk) (from versions: 2018.1.10+computecanada, 2019.11.1+computecanada, 2020.11.13+computecanada)
ERROR: No matching distribution found for regex>=2021.8.3
Looking in links: /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/nix/avx2, /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/nix/generic, /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic
ERROR: Could not find a version that satisfies the requirement numpy==1.20.0+computacanada (from versions: 1.15.0+computecanada, 1.15.2+computecanada, 1.15.4+computecanada, 1.16.0+computecanada, 1.16.2+computecanada, 1.16.3+computecanada, 1.17.4+computecanada, 1.18.1+computecanada, 1.18.4+computecanada, 1.19.1+computecanada, 1.19.2+computecanada, 1.20.2+computecanada)
ERROR: No matching distribution found for numpy==1.20.0+computacanada
Looking in links: /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/nix/avx2, /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/nix/generic, /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/wandb-0.12.5+computecanada-py2.py3-none-any.whl
Requirement already satisfied: python-dateutil>=2.6.1 in /cvmfs/soft.computecanada.ca/easybuild/software/2017/Core/scipy-stack/2019a/lib/python3.7/site-packages (from wandb) (2.7.5)
Requirement already satisfied: requests<3,>=2.0.0 in /cvmfs/soft.computecanada.ca/easybuild/software/2017/Core/scipy-stack/2019a/lib/python3.7/site-packages (from wandb) (2.21.0)
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/psutil-5.7.3+computecanada-cp37-cp37m-linux_x86_64.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/pathtools-0.1.2+computecanada-py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/protobuf-3.19.4+computecanada-py2.py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/click-8.0.3+computecanada-py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/docker_pycreds-0.4.0+computecanada-py2.py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/sentry_sdk-1.5.0+computecanada-py2.py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/subprocess32-3.5.4+computecanada-py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/PyYAML-5.3.1+computecanada-cp37-cp37m-linux_x86_64.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/shortuuid-1.0.1+computecanada-py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/six-1.16.0+computecanada-py2.py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/yaspin-2.1.0+computecanada-py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/promise-2.3+computecanada-py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/configparser-5.0.2+computecanada-py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/GitPython-3.1.24+computecanada-py3-none-any.whl
Requirement already satisfied: importlib-metadata in /cvmfs/soft.computecanada.ca/easybuild/software/2017/Core/scipy-stack/2019a/lib/python3.7/site-packages (from Click!=8.0.0,>=7.0->wandb) (0.8)
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/gitdb-4.0.9+computecanada-py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/typing_extensions-4.0.1+computecanada-py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/smmap-5.0.0+computecanada-py3-none-any.whl
Requirement already satisfied: certifi>=2017.4.17 in /cvmfs/soft.computecanada.ca/easybuild/software/2017/Core/scipy-stack/2019a/lib/python3.7/site-packages (from requests<3,>=2.0.0->wandb) (2018.11.29)
Requirement already satisfied: urllib3<1.25,>=1.21.1 in /cvmfs/soft.computecanada.ca/easybuild/software/2017/Core/scipy-stack/2019a/lib/python3.7/site-packages (from requests<3,>=2.0.0->wandb) (1.24.1)
Requirement already satisfied: idna<2.9,>=2.5 in /cvmfs/soft.computecanada.ca/easybuild/software/2017/Core/scipy-stack/2019a/lib/python3.7/site-packages (from requests<3,>=2.0.0->wandb) (2.8)
Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /cvmfs/soft.computecanada.ca/easybuild/software/2017/Core/scipy-stack/2019a/lib/python3.7/site-packages (from requests<3,>=2.0.0->wandb) (3.0.4)
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/termcolor-1.1.0+computecanada-py3-none-any.whl
Requirement already satisfied: zipp>=0.3.2 in /cvmfs/soft.computecanada.ca/easybuild/software/2017/Core/scipy-stack/2019a/lib/python3.7/site-packages (from importlib-metadata->Click!=8.0.0,>=7.0->wandb) (0.3.3)
Installing collected packages: smmap, typing-extensions, termcolor, six, gitdb, yaspin, subprocess32, shortuuid, sentry-sdk, PyYAML, psutil, protobuf, promise, pathtools, GitPython, docker-pycreds, configparser, Click, wandb
  Attempting uninstall: six
    Found existing installation: six 1.12.0
    Not uninstalling six at /cvmfs/soft.computecanada.ca/easybuild/software/2017/Core/scipy-stack/2019a/lib/python3.7/site-packages, outside environment /localscratch/yinan.28959366.0/env
    Can't uninstall 'six'. No files were found to uninstall.
Successfully installed Click-8.0.3+computecanada GitPython-3.1.24+computecanada PyYAML-5.3.1+computecanada configparser-5.0.2+computecanada docker-pycreds-0.4.0+computecanada gitdb-4.0.9+computecanada pathtools-0.1.2+computecanada promise-2.3+computecanada protobuf-3.19.4+computecanada psutil-5.7.3+computecanada sentry-sdk-1.5.0+computecanada shortuuid-1.0.1+computecanada six-1.16.0+computecanada smmap-5.0.0+computecanada subprocess32-3.5.4+computecanada termcolor-1.1.0+computecanada typing-extensions-4.0.1+computecanada wandb-0.12.5+computecanada yaspin-2.1.0+computecanada
Looking in links: /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/nix/avx2, /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/nix/generic, /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic
ERROR: Could not find a version that satisfies the requirement sagemaker (from versions: none)
ERROR: No matching distribution found for sagemaker
Looking in links: /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/nix/avx2, /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/nix/generic, /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/torch-1.9.1+computecanada-cp37-cp37m-linux_x86_64.whl
Requirement already satisfied: typing-extensions in /localscratch/yinan.28959366.0/env/lib/python3.7/site-packages (from torch) (4.0.1+computecanada)
Installing collected packages: torch
Successfully installed torch-1.9.1+computecanada
Looking in links: /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/nix/avx2, /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/nix/generic, /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/transformers-2.5.1+computecanada-py3-none-any.whl
Requirement already satisfied: numpy in /cvmfs/soft.computecanada.ca/easybuild/software/2017/Core/scipy-stack/2019a/lib/python3.7/site-packages (from transformers==2.5.1+computecanada) (1.16.0)
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/tqdm-4.63.0+computecanada-py2.py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/boto3-1.20.52+computecanada-py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/sentencepiece-0.1.91+computecanada-cp37-cp37m-linux_x86_64.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/filelock-3.4.2+computecanada-py3-none-any.whl
Requirement already satisfied: requests in /cvmfs/soft.computecanada.ca/easybuild/software/2017/Core/scipy-stack/2019a/lib/python3.7/site-packages (from transformers==2.5.1+computecanada) (2.21.0)
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/tokenizers-0.5.2+computecanada-cp37-cp37m-linux_x86_64.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/regex-2020.11.13+computecanada-cp37-cp37m-linux_x86_64.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/sacremoses-0.0.46+computecanada-py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/s3transfer-0.5.1+computecanada-py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/botocore-1.23.52+computecanada-py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/jmespath-0.10.0+computecanada-py2.py3-none-any.whl
Requirement already satisfied: python-dateutil<3.0.0,>=2.1 in /cvmfs/soft.computecanada.ca/easybuild/software/2017/Core/scipy-stack/2019a/lib/python3.7/site-packages (from botocore<1.24.0,>=1.23.52->boto3->transformers==2.5.1+computecanada) (2.7.5)
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/urllib3-1.26.8+computecanada-py2.py3-none-any.whl
Requirement already satisfied: six>=1.5 in /localscratch/yinan.28959366.0/env/lib/python3.7/site-packages (from python-dateutil<3.0.0,>=2.1->botocore<1.24.0,>=1.23.52->boto3->transformers==2.5.1+computecanada) (1.16.0+computecanada)
Requirement already satisfied: idna<2.9,>=2.5 in /cvmfs/soft.computecanada.ca/easybuild/software/2017/Core/scipy-stack/2019a/lib/python3.7/site-packages (from requests->transformers==2.5.1+computecanada) (2.8)
Requirement already satisfied: certifi>=2017.4.17 in /cvmfs/soft.computecanada.ca/easybuild/software/2017/Core/scipy-stack/2019a/lib/python3.7/site-packages (from requests->transformers==2.5.1+computecanada) (2018.11.29)
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/requests-2.27.1+computecanada-py2.py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/charset_normalizer-2.0.11+computecanada-py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/joblib-1.1.0+computecanada-py2.py3-none-any.whl
Requirement already satisfied: click in /localscratch/yinan.28959366.0/env/lib/python3.7/site-packages (from sacremoses->transformers==2.5.1+computecanada) (8.0.3+computecanada)
Requirement already satisfied: importlib-metadata in /cvmfs/soft.computecanada.ca/easybuild/software/2017/Core/scipy-stack/2019a/lib/python3.7/site-packages (from click->sacremoses->transformers==2.5.1+computecanada) (0.8)
Requirement already satisfied: zipp>=0.3.2 in /cvmfs/soft.computecanada.ca/easybuild/software/2017/Core/scipy-stack/2019a/lib/python3.7/site-packages (from importlib-metadata->click->sacremoses->transformers==2.5.1+computecanada) (0.3.3)
Installing collected packages: urllib3, jmespath, botocore, tqdm, s3transfer, regex, joblib, charset-normalizer, tokenizers, sentencepiece, sacremoses, requests, filelock, boto3, transformers
  Attempting uninstall: urllib3
    Found existing installation: urllib3 1.24.1
    Not uninstalling urllib3 at /cvmfs/soft.computecanada.ca/easybuild/software/2017/Core/scipy-stack/2019a/lib/python3.7/site-packages, outside environment /localscratch/yinan.28959366.0/env
    Can't uninstall 'urllib3'. No files were found to uninstall.
  Attempting uninstall: requests
    Found existing installation: requests 2.21.0
    Not uninstalling requests at /cvmfs/soft.computecanada.ca/easybuild/software/2017/Core/scipy-stack/2019a/lib/python3.7/site-packages, outside environment /localscratch/yinan.28959366.0/env
    Can't uninstall 'requests'. No files were found to uninstall.
Successfully installed boto3-1.20.52+computecanada botocore-1.23.52+computecanada charset-normalizer-2.0.11+computecanada filelock-3.4.2+computecanada jmespath-0.10.0+computecanada joblib-1.1.0+computecanada regex-2020.11.13+computecanada requests-2.27.1+computecanada s3transfer-0.5.1+computecanada sacremoses-0.0.46+computecanada sentencepiece-0.1.91+computecanada tokenizers-0.5.2+computecanada tqdm-4.63.0+computecanada transformers-2.5.1+computecanada urllib3-1.26.8+computecanada
Looking in links: /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/nix/avx2, /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/nix/generic, /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/tensorflow_gpu-2.3.0+computecanada-cp37-cp37m-linux_x86_64.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/nix/generic/scipy-1.4.1+computecanada-cp37-cp37m-linux_x86_64.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/gast-0.3.3+computecanada-py3-none-any.whl
Requirement already satisfied: protobuf>=3.9.2 in /localscratch/yinan.28959366.0/env/lib/python3.7/site-packages (from tensorflow_gpu==2.3.0+computecanada) (3.19.4+computecanada)
Requirement already satisfied: termcolor>=1.1.0 in /localscratch/yinan.28959366.0/env/lib/python3.7/site-packages (from tensorflow_gpu==2.3.0+computecanada) (1.1.0+computecanada)
Requirement already satisfied: wheel>=0.26 in /localscratch/yinan.28959366.0/env/lib/python3.7/site-packages (from tensorflow_gpu==2.3.0+computecanada) (0.33.4)
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/opt_einsum-3.3.0+computecanada-py3-none-any.whl
Requirement already satisfied: six>=1.12.0 in /localscratch/yinan.28959366.0/env/lib/python3.7/site-packages (from tensorflow_gpu==2.3.0+computecanada) (1.16.0+computecanada)
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/absl_py-1.0.0+computecanada-py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/tensorboard-2.8.0+computecanada-py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/tensorflow_estimator-2.3.0+computecanada-py2.py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/google_pasta-0.2.0+computecanada-py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/nix/avx2/h5py-2.10.0+computecanada-cp37-cp37m-linux_x86_64.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/wrapt-1.11.2+computecanada-cp37-cp37m-linux_x86_64.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/grpcio-1.38.0+computecanada-cp37-cp37m-linux_x86_64.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/Keras_Preprocessing-1.1.2+computecanada-py3-none-any.whl
Requirement already satisfied: numpy<1.19.0,>=1.16.0 in /cvmfs/soft.computecanada.ca/easybuild/software/2017/Core/scipy-stack/2019a/lib/python3.7/site-packages (from tensorflow_gpu==2.3.0+computecanada) (1.16.0)
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/astunparse-1.6.3+computecanada-py2.py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/tensorboard_plugin_wit-1.8.0+computecanada-py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/Markdown-3.3.6+computecanada-py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/Werkzeug-2.0.3+computecanada-py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/tensorboard_data_server-0.6.1+computecanada-py3-none-linux_x86_64.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/google_auth_oauthlib-0.4.6+computecanada-py2.py3-none-any.whl
Requirement already satisfied: requests<3,>=2.21.0 in /localscratch/yinan.28959366.0/env/lib/python3.7/site-packages (from tensorboard<3,>=2.3.0->tensorflow_gpu==2.3.0+computecanada) (2.27.1+computecanada)
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/google_auth-2.3.3+computecanada-py2.py3-none-any.whl
Requirement already satisfied: setuptools>=41.0.0 in /localscratch/yinan.28959366.0/env/lib/python3.7/site-packages (from tensorboard<3,>=2.3.0->tensorflow_gpu==2.3.0+computecanada) (41.0.1)
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/cachetools-4.2.4+computecanada-py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/pyasn1_modules-0.2.8+computecanada-py2.py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/rsa-4.8+computecanada-py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/requests_oauthlib-1.3.0+computecanada-py2.py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/importlib_metadata-4.10.1+computecanada-py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/zipp-3.7.0+computecanada-py3-none-any.whl
Requirement already satisfied: typing-extensions>=3.6.4 in /localscratch/yinan.28959366.0/env/lib/python3.7/site-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard<3,>=2.3.0->tensorflow_gpu==2.3.0+computecanada) (4.0.1+computecanada)
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/pyasn1-0.4.8+computecanada-py2.py3-none-any.whl
Requirement already satisfied: certifi>=2017.4.17 in /cvmfs/soft.computecanada.ca/easybuild/software/2017/Core/scipy-stack/2019a/lib/python3.7/site-packages (from requests<3,>=2.21.0->tensorboard<3,>=2.3.0->tensorflow_gpu==2.3.0+computecanada) (2018.11.29)
Requirement already satisfied: charset-normalizer~=2.0.0 in /localscratch/yinan.28959366.0/env/lib/python3.7/site-packages (from requests<3,>=2.21.0->tensorboard<3,>=2.3.0->tensorflow_gpu==2.3.0+computecanada) (2.0.11+computecanada)
Requirement already satisfied: urllib3<1.27,>=1.21.1 in /localscratch/yinan.28959366.0/env/lib/python3.7/site-packages (from requests<3,>=2.21.0->tensorboard<3,>=2.3.0->tensorflow_gpu==2.3.0+computecanada) (1.26.8+computecanada)
Requirement already satisfied: idna<4,>=2.5 in /cvmfs/soft.computecanada.ca/easybuild/software/2017/Core/scipy-stack/2019a/lib/python3.7/site-packages (from requests<3,>=2.21.0->tensorboard<3,>=2.3.0->tensorflow_gpu==2.3.0+computecanada) (2.8)
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/oauthlib-3.1.1+computecanada-py2.py3-none-any.whl
Installing collected packages: pyasn1, zipp, rsa, pyasn1-modules, oauthlib, cachetools, requests-oauthlib, importlib-metadata, google-auth, werkzeug, tensorboard-plugin-wit, tensorboard-data-server, markdown, grpcio, google-auth-oauthlib, absl-py, wrapt, tensorflow-estimator, tensorboard, scipy, opt-einsum, keras-preprocessing, h5py, google-pasta, gast, astunparse, tensorflow-gpu
  Attempting uninstall: pyasn1
    Found existing installation: pyasn1 0.4.3
    Not uninstalling pyasn1 at /cvmfs/soft.computecanada.ca/easybuild/software/2017/Core/scipy-stack/2019a/lib/python3.7/site-packages, outside environment /localscratch/yinan.28959366.0/env
    Can't uninstall 'pyasn1'. No files were found to uninstall.
  Attempting uninstall: zipp
    Found existing installation: zipp 0.3.3
    Not uninstalling zipp at /cvmfs/soft.computecanada.ca/easybuild/software/2017/Core/scipy-stack/2019a/lib/python3.7/site-packages, outside environment /localscratch/yinan.28959366.0/env
    Can't uninstall 'zipp'. No files were found to uninstall.
  Attempting uninstall: importlib-metadata
    Found existing installation: importlib-metadata 0.8
    Not uninstalling importlib-metadata at /cvmfs/soft.computecanada.ca/easybuild/software/2017/Core/scipy-stack/2019a/lib/python3.7/site-packages, outside environment /localscratch/yinan.28959366.0/env
    Can't uninstall 'importlib-metadata'. No files were found to uninstall.
  Attempting uninstall: scipy
    Found existing installation: scipy 1.2.0
    Not uninstalling scipy at /cvmfs/soft.computecanada.ca/easybuild/software/2017/Core/scipy-stack/2019a/lib/python3.7/site-packages, outside environment /localscratch/yinan.28959366.0/env
    Can't uninstall 'scipy'. No files were found to uninstall.
Successfully installed absl-py-1.0.0+computecanada astunparse-1.6.3+computecanada cachetools-4.2.4+computecanada gast-0.3.3+computecanada google-auth-2.3.3+computecanada google-auth-oauthlib-0.4.6+computecanada google-pasta-0.2.0+computecanada grpcio-1.38.0+computecanada h5py-2.10.0+computecanada importlib-metadata-4.10.1+computecanada keras-preprocessing-1.1.2+computecanada markdown-3.3.6+computecanada oauthlib-3.1.1+computecanada opt-einsum-3.3.0+computecanada pyasn1-0.4.8+computecanada pyasn1-modules-0.2.8+computecanada requests-oauthlib-1.3.0+computecanada rsa-4.8+computecanada scipy-1.4.1+computecanada tensorboard-2.8.0+computecanada tensorboard-data-server-0.6.1+computecanada tensorboard-plugin-wit-1.8.0+computecanada tensorflow-estimator-2.3.0+computecanada tensorflow-gpu-2.3.0+computecanada werkzeug-2.0.3+computecanada wrapt-1.11.2+computecanada zipp-3.7.0+computecanada
Looking in links: /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/nix/avx2, /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/nix/generic, /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/keras-2.8.0+computecanada-py2.py3-none-any.whl
Installing collected packages: Keras
Successfully installed Keras-2.8.0+computecanada
Looking in links: /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/nix/avx2, /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/nix/generic, /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/urllib3-1.26.7+computecanada-py2.py3-none-any.whl
Installing collected packages: urllib3
  Attempting uninstall: urllib3
    Found existing installation: urllib3 1.26.8+computecanada
    Uninstalling urllib3-1.26.8+computecanada:
      Successfully uninstalled urllib3-1.26.8+computecanada
Successfully installed urllib3-1.26.7+computecanada
Looking in links: /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/nix/avx2, /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/nix/generic, /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/nltk-3.7+computecanada-py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/nltk-3.6.5+computecanada-py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/nltk-3.6.3+computecanada-py3-none-any.whl
Requirement already satisfied: click in /localscratch/yinan.28959366.0/env/lib/python3.7/site-packages (from nltk) (8.0.3+computecanada)
Requirement already satisfied: regex in /localscratch/yinan.28959366.0/env/lib/python3.7/site-packages (from nltk) (2020.11.13+computecanada)
Requirement already satisfied: joblib in /localscratch/yinan.28959366.0/env/lib/python3.7/site-packages (from nltk) (1.1.0+computecanada)
Requirement already satisfied: tqdm in /localscratch/yinan.28959366.0/env/lib/python3.7/site-packages (from nltk) (4.63.0+computecanada)
Requirement already satisfied: importlib-metadata in /localscratch/yinan.28959366.0/env/lib/python3.7/site-packages (from click->nltk) (4.10.1+computecanada)
Requirement already satisfied: typing-extensions>=3.6.4 in /localscratch/yinan.28959366.0/env/lib/python3.7/site-packages (from importlib-metadata->click->nltk) (4.0.1+computecanada)
Requirement already satisfied: zipp>=0.5 in /localscratch/yinan.28959366.0/env/lib/python3.7/site-packages (from importlib-metadata->click->nltk) (3.7.0+computecanada)
Installing collected packages: nltk
Successfully installed nltk-3.6.3+computecanada
Looking in links: /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/nix/avx2, /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/nix/generic, /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/scikit_learn-0.22.1+computecanada-cp37-cp37m-linux_x86_64.whl
Requirement already satisfied: joblib>=0.11 in /localscratch/yinan.28959366.0/env/lib/python3.7/site-packages (from scikit-learn==0.22.1) (1.1.0+computecanada)
Requirement already satisfied: numpy>=1.11.0 in /cvmfs/soft.computecanada.ca/easybuild/software/2017/Core/scipy-stack/2019a/lib/python3.7/site-packages (from scikit-learn==0.22.1) (1.16.0)
Requirement already satisfied: scipy>=0.17.0 in /localscratch/yinan.28959366.0/env/lib/python3.7/site-packages (from scikit-learn==0.22.1) (1.4.1+computecanada)
Installing collected packages: scikit-learn
Successfully installed scikit-learn-0.22.1+computecanada
Looking in links: /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/nix/avx2, /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/nix/generic, /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic
Requirement already satisfied: tokenizers==0.5.2 in /localscratch/yinan.28959366.0/env/lib/python3.7/site-packages (0.5.2+computecanada)
wandb: Appending key for api.wandb.ai to your netrc file: /home/yinan/.netrc
Starting Task
2022-03-15 02:03:24.610599: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1
[nltk_data] Downloading package stopwords to /home/yinan/nltk_data...
[nltk_data]   Package stopwords is already up-to-date!
[nltk_data] Downloading package wordnet to /home/yinan/nltk_data...
[nltk_data]   Package wordnet is already up-to-date!
wandb: Currently logged in as: yinanazhou (use `wandb login --relogin` to force relogin)
wandb: wandb version 0.12.11 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
2022-03-15 02:03:37.528961: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1
wandb: Tracking run with wandb version 0.12.5
wandb: Syncing run laced-breeze-2
wandb: ⭐️ View project at https://wandb.ai/yinanazhou/xl_512_bs_8_lr_1e06_es_10_lc_True_nr_True_sr_True_stem_False_lemma_False_repeat_1_fold_1
wandb: 🚀 View run at https://wandb.ai/yinanazhou/xl_512_bs_8_lr_1e06_es_10_lc_True_nr_True_sr_True_stem_False_lemma_False_repeat_1_fold_1/runs/2r1hwmap
wandb: Run data is saved locally in /project/6002780/yinan/Thesis_MER_Lyrics/lyric-emotion/wandb/run-20220315_020335-2r1hwmap
wandb: Run `wandb offline` to turn off syncing.

Validation loss decreased (inf --> 1.441675).  Saving model ...
Validation loss decreased (1.441675 --> 1.423186).  Saving model ...
Validation loss decreased (1.423186 --> 1.407739).  Saving model ...
Validation loss decreased (1.407739 --> 1.395278).  Saving model ...
Validation loss decreased (1.395278 --> 1.385952).  Saving model ...
Validation loss decreased (1.385952 --> 1.378015).  Saving model ...
Validation loss decreased (1.378015 --> 1.372319).  Saving model ...
Validation loss decreased (1.372319 --> 1.367101).  Saving model ...
Validation loss decreased (1.367101 --> 1.362449).  Saving model ...
Validation loss decreased (1.362449 --> 1.357497).  Saving model ...
Validation loss decreased (1.357497 --> 1.352490).  Saving model ...
Validation loss decreased (1.352490 --> 1.347691).  Saving model ...
Validation loss decreased (1.347691 --> 1.342970).  Saving model ...
Validation loss decreased (1.342970 --> 1.338242).  Saving model ...
Validation loss decreased (1.338242 --> 1.333882).  Saving model ...
Validation loss decreased (1.333882 --> 1.329833).  Saving model ...
Validation loss decreased (1.329833 --> 1.325409).  Saving model ...
Validation loss decreased (1.325409 --> 1.320543).  Saving model ...
Validation loss decreased (1.320543 --> 1.315317).  Saving model ...
Validation loss decreased (1.315317 --> 1.310341).  Saving model ...
Validation loss decreased (1.310341 --> 1.305684).  Saving model ...
Validation loss decreased (1.305684 --> 1.300396).  Saving model ...
Validation loss decreased (1.300396 --> 1.296148).  Saving model ...
Validation loss decreased (1.296148 --> 1.290671).  Saving model ...
Validation loss decreased (1.290671 --> 1.285830).  Saving model ...
Validation loss decreased (1.285830 --> 1.281224).  Saving model ...
Validation loss decreased (1.281224 --> 1.277315).  Saving model ...
Validation loss decreased (1.277315 --> 1.275066).  Saving model ...
Validation loss decreased (1.275066 --> 1.273085).  Saving model ...
Validation loss decreased (1.273085 --> 1.270585).  Saving model ...
Validation loss decreased (1.270585 --> 1.266308).  Saving model ...
Validation loss decreased (1.266308 --> 1.261046).  Saving model ...
Validation loss decreased (1.261046 --> 1.259798).  Saving model ...
Validation loss decreased (1.259798 --> 1.253288).  Saving model ...
Validation loss decreased (1.253288 --> 1.252226).  Saving model ...
Validation loss decreased (1.252226 --> 1.247537).  Saving model ...
Validation loss decreased (1.247537 --> 1.244679).  Saving model ...
Validation loss decreased (1.244679 --> 1.239517).  Saving model ...
Validation loss decreased (1.239517 --> 1.237540).  Saving model ...
Validation loss decreased (1.237540 --> 1.237170).  Saving model ...
Validation loss decreased (1.237170 --> 1.230621).  Saving model ...
Validation loss decreased (1.230621 --> 1.227196).  Saving model ...
Validation loss decreased (1.227196 --> 1.226575).  Saving model ...
Validation loss decreased (1.226575 --> 1.221086).  Saving model ...
Validation loss decreased (1.221086 --> 1.220941).  Saving model ...
Validation loss decreased (1.220941 --> 1.218210).  Saving model ...
Validation loss decreased (1.218210 --> 1.216324).  Saving model ...
Validation loss decreased (1.216324 --> 1.214311).  Saving model ...
Validation loss decreased (1.214311 --> 1.210619).  Saving model ...
Validation loss decreased (1.210619 --> 1.205541).  Saving model ...
Validation loss decreased (1.205541 --> 1.201404).  Saving model ...
Validation loss decreased (1.201404 --> 1.197768).  Saving model ...
Validation loss decreased (1.197768 --> 1.195982).  Saving model ...
Validation loss decreased (1.195982 --> 1.191534).  Saving model ...
EarlyStopping counter: 1 out of 10.0
Validation loss decreased (1.191534 --> 1.189415).  Saving model ...
Validation loss decreased (1.189415 --> 1.188133).  Saving model ...
Validation loss decreased (1.188133 --> 1.184564).  Saving model ...
Validation loss decreased (1.184564 --> 1.178266).  Saving model ...
Validation loss decreased (1.178266 --> 1.178206).  Saving model ...
Validation loss decreased (1.178206 --> 1.173006).  Saving model ...
EarlyStopping counter: 1 out of 10.0
Validation loss decreased (1.173006 --> 1.170363).  Saving model ...
Validation loss decreased (1.170363 --> 1.168316).  Saving model ...
Validation loss decreased (1.168316 --> 1.166168).  Saving model ...
Validation loss decreased (1.166168 --> 1.161845).  Saving model ...
Validation loss decreased (1.161845 --> 1.159450).  Saving model ...
Validation loss decreased (1.159450 --> 1.155724).  Saving model ...
Validation loss decreased (1.155724 --> 1.154208).  Saving model ...
Validation loss decreased (1.154208 --> 1.152667).  Saving model ...
Validation loss decreased (1.152667 --> 1.149243).  Saving model ...
Validation loss decreased (1.149243 --> 1.147071).  Saving model ...
Validation loss decreased (1.147071 --> 1.145694).  Saving model ...
Validation loss decreased (1.145694 --> 1.140263).  Saving model ...
Validation loss decreased (1.140263 --> 1.134228).  Saving model ...
Validation loss decreased (1.134228 --> 1.133849).  Saving model ...
EarlyStopping counter: 1 out of 10.0
Validation loss decreased (1.133849 --> 1.133062).  Saving model ...
Validation loss decreased (1.133062 --> 1.128384).  Saving model ...
Validation loss decreased (1.128384 --> 1.120717).  Saving model ...
EarlyStopping counter: 1 out of 10.0
EarlyStopping counter: 2 out of 10.0
EarlyStopping counter: 3 out of 10.0
EarlyStopping counter: 4 out of 10.0
Validation loss decreased (1.120717 --> 1.117917).  Saving model ...
Validation loss decreased (1.117917 --> 1.108810).  Saving model ...
Validation loss decreased (1.108810 --> 1.104728).  Saving model ...
EarlyStopping counter: 1 out of 10.0
EarlyStopping counter: 2 out of 10.0
EarlyStopping counter: 3 out of 10.0
Validation loss decreased (1.104728 --> 1.100717).  Saving model ...
Validation loss decreased (1.100717 --> 1.098361).  Saving model ...
EarlyStopping counter: 1 out of 10.0
EarlyStopping counter: 2 out of 10.0
EarlyStopping counter: 3 out of 10.0
EarlyStopping counter: 4 out of 10.0
EarlyStopping counter: 5 out of 10.0
Validation loss decreased (1.098361 --> 1.096441).  Saving model ...
Validation loss decreased (1.096441 --> 1.094552).  Saving model ...
EarlyStopping counter: 1 out of 10.0
Validation loss decreased (1.094552 --> 1.092270).  Saving model ...
Validation loss decreased (1.092270 --> 1.090155).  Saving model ...
Validation loss decreased (1.090155 --> 1.084891).  Saving model ...
EarlyStopping counter: 1 out of 10.0
Validation loss decreased (1.084891 --> 1.084865).  Saving model ...
Validation loss decreased (1.084865 --> 1.081225).  Saving model ...
Validation loss decreased (1.081225 --> 1.078288).  Saving model ...
Validation loss decreased (1.078288 --> 1.077156).  Saving model ...
Validation loss decreased (1.077156 --> 1.075131).  Saving model ...
Validation loss decreased (1.075131 --> 1.071867).  Saving model ...
EarlyStopping counter: 1 out of 10.0
EarlyStopping counter: 2 out of 10.0
EarlyStopping counter: 3 out of 10.0
EarlyStopping counter: 4 out of 10.0
EarlyStopping counter: 5 out of 10.0
Validation loss decreased (1.071867 --> 1.071482).  Saving model ...
EarlyStopping counter: 1 out of 10.0
Validation loss decreased (1.071482 --> 1.068983).  Saving model ...
Validation loss decreased (1.068983 --> 1.067395).  Saving model ...
Validation loss decreased (1.067395 --> 1.065161).  Saving model ...
Validation loss decreased (1.065161 --> 1.063052).  Saving model ...
Validation loss decreased (1.063052 --> 1.062935).  Saving model ...
Validation loss decreased (1.062935 --> 1.058124).  Saving model ...
EarlyStopping counter: 1 out of 10.0
EarlyStopping counter: 2 out of 10.0
EarlyStopping counter: 3 out of 10.0
EarlyStopping counter: 4 out of 10.0
EarlyStopping counter: 5 out of 10.0
EarlyStopping counter: 6 out of 10.0
EarlyStopping counter: 7 out of 10.0
EarlyStopping counter: 8 out of 10.0
EarlyStopping counter: 9 out of 10.0
Validation loss decreased (1.058124 --> 1.054475).  Saving model ...
Validation loss decreased (1.054475 --> 1.053281).  Saving model ...
EarlyStopping counter: 1 out of 10.0
EarlyStopping counter: 2 out of 10.0
Validation loss decreased (1.053281 --> 1.050996).  Saving model ...
EarlyStopping counter: 1 out of 10.0
EarlyStopping counter: 2 out of 10.0
EarlyStopping counter: 3 out of 10.0
EarlyStopping counter: 4 out of 10.0
EarlyStopping counter: 5 out of 10.0
EarlyStopping counter: 6 out of 10.0
EarlyStopping counter: 7 out of 10.0
Validation loss decreased (1.050996 --> 1.050884).  Saving model ...
EarlyStopping counter: 1 out of 10.0
EarlyStopping counter: 2 out of 10.0
EarlyStopping counter: 3 out of 10.0
EarlyStopping counter: 4 out of 10.0
Validation loss decreased (1.050884 --> 1.049476).  Saving model ...
EarlyStopping counter: 1 out of 10.0
EarlyStopping counter: 2 out of 10.0
EarlyStopping counter: 3 out of 10.0
EarlyStopping counter: 4 out of 10.0
Validation loss decreased (1.049476 --> 1.048471).  Saving model ...
Validation loss decreased (1.048471 --> 1.045348).  Saving model ...
Validation loss decreased (1.045348 --> 1.044734).  Saving model ...
EarlyStopping counter: 1 out of 10.0
EarlyStopping counter: 2 out of 10.0
EarlyStopping counter: 3 out of 10.0
EarlyStopping counter: 4 out of 10.0
EarlyStopping counter: 5 out of 10.0
EarlyStopping counter: 6 out of 10.0
Validation loss decreased (1.044734 --> 1.042540).  Saving model ...
EarlyStopping counter: 1 out of 10.0
EarlyStopping counter: 2 out of 10.0
EarlyStopping counter: 3 out of 10.0
EarlyStopping counter: 4 out of 10.0
EarlyStopping counter: 5 out of 10.0
EarlyStopping counter: 6 out of 10.0
EarlyStopping counter: 7 out of 10.0
EarlyStopping counter: 8 out of 10.0
EarlyStopping counter: 9 out of 10.0
EarlyStopping counter: 10 out of 10.0
/localscratch/yinan.28959366.0/env/lib/python3.7/site-packages/torch/nn/functional.py:1794: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.
  warnings.warn("nn.functional.tanh is deprecated. Use torch.tanh instead.")
/localscratch/yinan.28959366.0/env/lib/python3.7/site-packages/transformers/optimization.py:155: UserWarning: This overload of add_ is deprecated:
	add_(Number alpha, Tensor other)
Consider using one of the following signatures instead:
	add_(Tensor other, *, Number alpha) (Triggered internally at  ../torch/csrc/utils/python_arg_parser.cpp:1025.)
  exp_avg.mul_(beta1).add_(1.0 - beta1, grad)
wandb: Waiting for W&B process to finish, PID 230660... (success).
wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: \ 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: | 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: / 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: \ 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: | 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: / 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: \ 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: | 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: / 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb:                                                                                
wandb: Run history:
wandb:     e_F1 ▁▂▃▄▄▅▅▅▅▅▆▆▆▆▆▆▆▇▇▇▇▇▇▇████████████████
wandb:   e_loss █▇▇▆▆▆▅▅▅▅▄▄▄▄▃▃▃▃▂▂▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:     t_F1 ▁▂▂▃▃▄▄▄▅▅▅▅▅▆▆▆▆▆▆▆▇▇▇▇▇▇▇▇▇▇▇▇█▇▇▇▇███
wandb:   t_loss █▇▇▇▇▆▆▆▅▅▅▅▅▄▄▄▄▄▄▄▃▃▃▃▃▃▃▂▃▂▂▂▂▂▂▂▂▂▁▁
wandb: 
wandb: Run summary:
wandb:     e_F1 55.03386
wandb:   e_loss 1.05241
wandb:     t_F1 76.01299
wandb:   t_loss 0.63794
wandb: 
wandb: Synced 4 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Synced laced-breeze-2: https://wandb.ai/yinanazhou/xl_512_bs_8_lr_1e06_es_10_lc_True_nr_True_sr_True_stem_False_lemma_False_repeat_1_fold_1/runs/2r1hwmap
wandb: Find logs at: ./wandb/run-20220315_020335-2r1hwmap/logs/debug.log
wandb: 

wandb: wandb version 0.12.11 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
2022-03-15 03:55:55.020221: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1
wandb: Tracking run with wandb version 0.12.5
wandb: Syncing run vague-wind-2
wandb: ⭐️ View project at https://wandb.ai/yinanazhou/xl_512_bs_8_lr_1e06_es_10_lc_True_nr_True_sr_True_stem_False_lemma_False_repeat_1_fold_2
wandb: 🚀 View run at https://wandb.ai/yinanazhou/xl_512_bs_8_lr_1e06_es_10_lc_True_nr_True_sr_True_stem_False_lemma_False_repeat_1_fold_2/runs/1kxcav0n
wandb: Run data is saved locally in /project/6002780/yinan/Thesis_MER_Lyrics/lyric-emotion/wandb/run-20220315_035551-1kxcav0n
wandb: Run `wandb offline` to turn off syncing.

Validation loss decreased (inf --> 1.414901).  Saving model ...
Validation loss decreased (1.414901 --> 1.399010).  Saving model ...
Validation loss decreased (1.399010 --> 1.387372).  Saving model ...
Validation loss decreased (1.387372 --> 1.378949).  Saving model ...
Validation loss decreased (1.378949 --> 1.371676).  Saving model ...
Validation loss decreased (1.371676 --> 1.366442).  Saving model ...
Validation loss decreased (1.366442 --> 1.361314).  Saving model ...
Validation loss decreased (1.361314 --> 1.356775).  Saving model ...
Validation loss decreased (1.356775 --> 1.353402).  Saving model ...
Validation loss decreased (1.353402 --> 1.350231).  Saving model ...
Validation loss decreased (1.350231 --> 1.346940).  Saving model ...
Validation loss decreased (1.346940 --> 1.343945).  Saving model ...
Validation loss decreased (1.343945 --> 1.340372).  Saving model ...
Validation loss decreased (1.340372 --> 1.337090).  Saving model ...
Validation loss decreased (1.337090 --> 1.333648).  Saving model ...
Validation loss decreased (1.333648 --> 1.330808).  Saving model ...
Validation loss decreased (1.330808 --> 1.327376).  Saving model ...
Validation loss decreased (1.327376 --> 1.323531).  Saving model ...
Validation loss decreased (1.323531 --> 1.319916).  Saving model ...
Validation loss decreased (1.319916 --> 1.316087).  Saving model ...
Validation loss decreased (1.316087 --> 1.311784).  Saving model ...
Validation loss decreased (1.311784 --> 1.307919).  Saving model ...
Validation loss decreased (1.307919 --> 1.304179).  Saving model ...
Validation loss decreased (1.304179 --> 1.299242).  Saving model ...
Validation loss decreased (1.299242 --> 1.295034).  Saving model ...
Validation loss decreased (1.295034 --> 1.289498).  Saving model ...
Validation loss decreased (1.289498 --> 1.284530).  Saving model ...
Validation loss decreased (1.284530 --> 1.278286).  Saving model ...
Validation loss decreased (1.278286 --> 1.273423).  Saving model ...
Validation loss decreased (1.273423 --> 1.267087).  Saving model ...
Validation loss decreased (1.267087 --> 1.261828).  Saving model ...
Validation loss decreased (1.261828 --> 1.254302).  Saving model ...
Validation loss decreased (1.254302 --> 1.247567).  Saving model ...
Validation loss decreased (1.247567 --> 1.240897).  Saving model ...
Validation loss decreased (1.240897 --> 1.233160).  Saving model ...
Validation loss decreased (1.233160 --> 1.226667).  Saving model ...
Validation loss decreased (1.226667 --> 1.218164).  Saving model ...
Validation loss decreased (1.218164 --> 1.211594).  Saving model ...
Validation loss decreased (1.211594 --> 1.205297).  Saving model ...
Validation loss decreased (1.205297 --> 1.198413).  Saving model ...
Validation loss decreased (1.198413 --> 1.190715).  Saving model ...
Validation loss decreased (1.190715 --> 1.184607).  Saving model ...
Validation loss decreased (1.184607 --> 1.178485).  Saving model ...
Validation loss decreased (1.178485 --> 1.171256).  Saving model ...
Validation loss decreased (1.171256 --> 1.165585).  Saving model ...
Validation loss decreased (1.165585 --> 1.160377).  Saving model ...
Validation loss decreased (1.160377 --> 1.155893).  Saving model ...
Validation loss decreased (1.155893 --> 1.149533).  Saving model ...
Validation loss decreased (1.149533 --> 1.145487).  Saving model ...
Validation loss decreased (1.145487 --> 1.139899).  Saving model ...
Validation loss decreased (1.139899 --> 1.134154).  Saving model ...
Validation loss decreased (1.134154 --> 1.129719).  Saving model ...
Validation loss decreased (1.129719 --> 1.123975).  Saving model ...
Validation loss decreased (1.123975 --> 1.119167).  Saving model ...
Validation loss decreased (1.119167 --> 1.113989).  Saving model ...
Validation loss decreased (1.113989 --> 1.107941).  Saving model ...
Validation loss decreased (1.107941 --> 1.103103).  Saving model ...
Validation loss decreased (1.103103 --> 1.099089).  Saving model ...
Validation loss decreased (1.099089 --> 1.095125).  Saving model ...
Validation loss decreased (1.095125 --> 1.090995).  Saving model ...
Validation loss decreased (1.090995 --> 1.086389).  Saving model ...
Validation loss decreased (1.086389 --> 1.080349).  Saving model ...
Validation loss decreased (1.080349 --> 1.076073).  Saving model ...
Validation loss decreased (1.076073 --> 1.071877).  Saving model ...
Validation loss decreased (1.071877 --> 1.068951).  Saving model ...
Validation loss decreased (1.068951 --> 1.064805).  Saving model ...
Validation loss decreased (1.064805 --> 1.060321).  Saving model ...
Validation loss decreased (1.060321 --> 1.057794).  Saving model ...
Validation loss decreased (1.057794 --> 1.054782).  Saving model ...
Validation loss decreased (1.054782 --> 1.050722).  Saving model ...
Validation loss decreased (1.050722 --> 1.046665).  Saving model ...
Validation loss decreased (1.046665 --> 1.043211).  Saving model ...
Validation loss decreased (1.043211 --> 1.038870).  Saving model ...
Validation loss decreased (1.038870 --> 1.036316).  Saving model ...
Validation loss decreased (1.036316 --> 1.031107).  Saving model ...
Validation loss decreased (1.031107 --> 1.028195).  Saving model ...
Validation loss decreased (1.028195 --> 1.025172).  Saving model ...
Validation loss decreased (1.025172 --> 1.022545).  Saving model ...
Validation loss decreased (1.022545 --> 1.017998).  Saving model ...
Validation loss decreased (1.017998 --> 1.014778).  Saving model ...
Validation loss decreased (1.014778 --> 1.012807).  Saving model ...
Validation loss decreased (1.012807 --> 1.010121).  Saving model ...
Validation loss decreased (1.010121 --> 1.006340).  Saving model ...
Validation loss decreased (1.006340 --> 1.003594).  Saving model ...
Validation loss decreased (1.003594 --> 1.001574).  Saving model ...
Validation loss decreased (1.001574 --> 0.999272).  Saving model ...
Validation loss decreased (0.999272 --> 0.996025).  Saving model ...
Validation loss decreased (0.996025 --> 0.994413).  Saving model ...
Validation loss decreased (0.994413 --> 0.991057).  Saving model ...
Validation loss decreased (0.991057 --> 0.988904).  Saving model ...
Validation loss decreased (0.988904 --> 0.985796).  Saving model ...
Validation loss decreased (0.985796 --> 0.984519).  Saving model ...
Validation loss decreased (0.984519 --> 0.982854).  Saving model ...
Validation loss decreased (0.982854 --> 0.979618).  Saving model ...
EarlyStopping counter: 1 out of 10.0
Validation loss decreased (0.979618 --> 0.977137).  Saving model ...
Validation loss decreased (0.977137 --> 0.975747).  Saving model ...
Validation loss decreased (0.975747 --> 0.974212).  Saving model ...
Validation loss decreased (0.974212 --> 0.971285).  Saving model ...
Validation loss decreased (0.971285 --> 0.968607).  Saving model ...
Validation loss decreased (0.968607 --> 0.968068).  Saving model ...
Validation loss decreased (0.968068 --> 0.967624).  Saving model ...
Validation loss decreased (0.967624 --> 0.967349).  Saving model ...
Validation loss decreased (0.967349 --> 0.964117).  Saving model ...
Validation loss decreased (0.964117 --> 0.961983).  Saving model ...
EarlyStopping counter: 1 out of 10.0
Validation loss decreased (0.961983 --> 0.961392).  Saving model ...
Validation loss decreased (0.961392 --> 0.958120).  Saving model ...
EarlyStopping counter: 1 out of 10.0
Validation loss decreased (0.958120 --> 0.955752).  Saving model ...
Validation loss decreased (0.955752 --> 0.955588).  Saving model ...
Validation loss decreased (0.955588 --> 0.955443).  Saving model ...
Validation loss decreased (0.955443 --> 0.952960).  Saving model ...
Validation loss decreased (0.952960 --> 0.952033).  Saving model ...
Validation loss decreased (0.952033 --> 0.951535).  Saving model ...
Validation loss decreased (0.951535 --> 0.949222).  Saving model ...
Validation loss decreased (0.949222 --> 0.949216).  Saving model ...
EarlyStopping counter: 1 out of 10.0
Validation loss decreased (0.949216 --> 0.948016).  Saving model ...
EarlyStopping counter: 1 out of 10.0
Validation loss decreased (0.948016 --> 0.946665).  Saving model ...
Validation loss decreased (0.946665 --> 0.945879).  Saving model ...
Validation loss decreased (0.945879 --> 0.945116).  Saving model ...
Validation loss decreased (0.945116 --> 0.944515).  Saving model ...
EarlyStopping counter: 1 out of 10.0
EarlyStopping counter: 2 out of 10.0
Validation loss decreased (0.944515 --> 0.943264).  Saving model ...
Validation loss decreased (0.943264 --> 0.943205).  Saving model ...
Validation loss decreased (0.943205 --> 0.942154).  Saving model ...
Validation loss decreased (0.942154 --> 0.941209).  Saving model ...
Validation loss decreased (0.941209 --> 0.940668).  Saving model ...
Validation loss decreased (0.940668 --> 0.939975).  Saving model ...
Validation loss decreased (0.939975 --> 0.938877).  Saving model ...
EarlyStopping counter: 1 out of 10.0
EarlyStopping counter: 2 out of 10.0
EarlyStopping counter: 3 out of 10.0
Validation loss decreased (0.938877 --> 0.938561).  Saving model ...
EarlyStopping counter: 1 out of 10.0
EarlyStopping counter: 2 out of 10.0
EarlyStopping counter: 3 out of 10.0
EarlyStopping counter: 4 out of 10.0
EarlyStopping counter: 5 out of 10.0
EarlyStopping counter: 6 out of 10.0
EarlyStopping counter: 7 out of 10.0
EarlyStopping counter: 8 out of 10.0
EarlyStopping counter: 9 out of 10.0
EarlyStopping counter: 10 out of 10.0
/localscratch/yinan.28959366.0/env/lib/python3.7/site-packages/torch/nn/functional.py:1794: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.
  warnings.warn("nn.functional.tanh is deprecated. Use torch.tanh instead.")
wandb: Waiting for W&B process to finish, PID 236665... (success).
wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: \ 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: | 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: / 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: \ 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: | 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: / 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: \ 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: | 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: / 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb:                                                                                
wandb: Run history:
wandb:     e_F1 ▁▁▃▅▅▅▅▆▆▆▆▆▆▆▇▇▇▇▇▇▇███████████████████
wandb:   e_loss ██▇▇▇▇▆▆▆▆▅▅▄▄▄▄▃▃▃▃▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:     t_F1 ▁▂▂▂▃▃▄▄▄▄▅▅▅▅▆▅▆▆▆▆▆▇▆▆▇▇▇▇▇▇▇▇████▇███
wandb:   t_loss ███▇▇▇▇▇▇▇▆▆▆▅▅▅▅▄▅▄▄▄▄▃▃▃▃▂▃▃▂▂▂▂▂▂▁▁▁▁
wandb: 
wandb: Run summary:
wandb:     e_F1 58.90867
wandb:   e_loss 0.9407
wandb:     t_F1 74.60422
wandb:   t_loss 0.76527
wandb: 
wandb: Synced 4 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Synced vague-wind-2: https://wandb.ai/yinanazhou/xl_512_bs_8_lr_1e06_es_10_lc_True_nr_True_sr_True_stem_False_lemma_False_repeat_1_fold_2/runs/1kxcav0n
wandb: Find logs at: ./wandb/run-20220315_035551-1kxcav0n/logs/debug.log
wandb: 

wandb: wandb version 0.12.11 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
2022-03-15 05:33:11.101091: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1
wandb: Tracking run with wandb version 0.12.5
wandb: Syncing run earthy-oath-2
wandb: ⭐️ View project at https://wandb.ai/yinanazhou/xl_512_bs_8_lr_1e06_es_10_lc_True_nr_True_sr_True_stem_False_lemma_False_repeat_2_fold_1
wandb: 🚀 View run at https://wandb.ai/yinanazhou/xl_512_bs_8_lr_1e06_es_10_lc_True_nr_True_sr_True_stem_False_lemma_False_repeat_2_fold_1/runs/27bv8cl4
wandb: Run data is saved locally in /project/6002780/yinan/Thesis_MER_Lyrics/lyric-emotion/wandb/run-20220315_053307-27bv8cl4
wandb: Run `wandb offline` to turn off syncing.

Validation loss decreased (inf --> 1.427653).  Saving model ...
Validation loss decreased (1.427653 --> 1.411986).  Saving model ...
Validation loss decreased (1.411986 --> 1.399241).  Saving model ...
Validation loss decreased (1.399241 --> 1.389047).  Saving model ...
Validation loss decreased (1.389047 --> 1.381122).  Saving model ...
Validation loss decreased (1.381122 --> 1.374702).  Saving model ...
Validation loss decreased (1.374702 --> 1.369079).  Saving model ...
Validation loss decreased (1.369079 --> 1.363604).  Saving model ...
Validation loss decreased (1.363604 --> 1.358634).  Saving model ...
Validation loss decreased (1.358634 --> 1.353483).  Saving model ...
Validation loss decreased (1.353483 --> 1.349052).  Saving model ...
Validation loss decreased (1.349052 --> 1.343721).  Saving model ...
Validation loss decreased (1.343721 --> 1.338606).  Saving model ...
Validation loss decreased (1.338606 --> 1.333613).  Saving model ...
Validation loss decreased (1.333613 --> 1.328476).  Saving model ...
Validation loss decreased (1.328476 --> 1.323265).  Saving model ...
Validation loss decreased (1.323265 --> 1.317837).  Saving model ...
Validation loss decreased (1.317837 --> 1.312223).  Saving model ...
Validation loss decreased (1.312223 --> 1.306073).  Saving model ...
Validation loss decreased (1.306073 --> 1.298621).  Saving model ...
Validation loss decreased (1.298621 --> 1.291724).  Saving model ...
Validation loss decreased (1.291724 --> 1.284530).  Saving model ...
Validation loss decreased (1.284530 --> 1.277781).  Saving model ...
Validation loss decreased (1.277781 --> 1.270363).  Saving model ...
Validation loss decreased (1.270363 --> 1.264604).  Saving model ...
Validation loss decreased (1.264604 --> 1.258196).  Saving model ...
Validation loss decreased (1.258196 --> 1.250929).  Saving model ...
Validation loss decreased (1.250929 --> 1.243426).  Saving model ...
Validation loss decreased (1.243426 --> 1.232710).  Saving model ...
Validation loss decreased (1.232710 --> 1.224928).  Saving model ...
Validation loss decreased (1.224928 --> 1.216416).  Saving model ...
Validation loss decreased (1.216416 --> 1.209920).  Saving model ...
Validation loss decreased (1.209920 --> 1.203386).  Saving model ...
Validation loss decreased (1.203386 --> 1.195921).  Saving model ...
Validation loss decreased (1.195921 --> 1.189485).  Saving model ...
Validation loss decreased (1.189485 --> 1.184236).  Saving model ...
Validation loss decreased (1.184236 --> 1.177796).  Saving model ...
Validation loss decreased (1.177796 --> 1.171661).  Saving model ...
Validation loss decreased (1.171661 --> 1.166400).  Saving model ...
Validation loss decreased (1.166400 --> 1.162046).  Saving model ...
Validation loss decreased (1.162046 --> 1.156628).  Saving model ...
Validation loss decreased (1.156628 --> 1.152007).  Saving model ...
Validation loss decreased (1.152007 --> 1.146695).  Saving model ...
Validation loss decreased (1.146695 --> 1.142295).  Saving model ...
Validation loss decreased (1.142295 --> 1.139537).  Saving model ...
Validation loss decreased (1.139537 --> 1.133363).  Saving model ...
Validation loss decreased (1.133363 --> 1.127999).  Saving model ...
EarlyStopping counter: 1 out of 10.0
Validation loss decreased (1.127999 --> 1.119291).  Saving model ...
Validation loss decreased (1.119291 --> 1.116246).  Saving model ...
Validation loss decreased (1.116246 --> 1.111663).  Saving model ...
Validation loss decreased (1.111663 --> 1.106664).  Saving model ...
Validation loss decreased (1.106664 --> 1.102594).  Saving model ...
Validation loss decreased (1.102594 --> 1.098960).  Saving model ...
Validation loss decreased (1.098960 --> 1.094178).  Saving model ...
Validation loss decreased (1.094178 --> 1.091026).  Saving model ...
Validation loss decreased (1.091026 --> 1.086961).  Saving model ...
Validation loss decreased (1.086961 --> 1.084773).  Saving model ...
Validation loss decreased (1.084773 --> 1.080409).  Saving model ...
Validation loss decreased (1.080409 --> 1.078050).  Saving model ...
Validation loss decreased (1.078050 --> 1.075127).  Saving model ...
Validation loss decreased (1.075127 --> 1.072707).  Saving model ...
Validation loss decreased (1.072707 --> 1.068766).  Saving model ...
Validation loss decreased (1.068766 --> 1.065951).  Saving model ...
Validation loss decreased (1.065951 --> 1.062915).  Saving model ...
Validation loss decreased (1.062915 --> 1.059898).  Saving model ...
Validation loss decreased (1.059898 --> 1.057675).  Saving model ...
Validation loss decreased (1.057675 --> 1.054395).  Saving model ...
Validation loss decreased (1.054395 --> 1.051902).  Saving model ...
Validation loss decreased (1.051902 --> 1.046662).  Saving model ...
Validation loss decreased (1.046662 --> 1.046030).  Saving model ...
EarlyStopping counter: 1 out of 10.0
Validation loss decreased (1.046030 --> 1.042420).  Saving model ...
Validation loss decreased (1.042420 --> 1.036781).  Saving model ...
Validation loss decreased (1.036781 --> 1.035117).  Saving model ...
Validation loss decreased (1.035117 --> 1.034487).  Saving model ...
Validation loss decreased (1.034487 --> 1.032168).  Saving model ...
Validation loss decreased (1.032168 --> 1.029051).  Saving model ...
Validation loss decreased (1.029051 --> 1.026369).  Saving model ...
Validation loss decreased (1.026369 --> 1.025238).  Saving model ...
EarlyStopping counter: 1 out of 10.0
Validation loss decreased (1.025238 --> 1.021143).  Saving model ...
Validation loss decreased (1.021143 --> 1.017369).  Saving model ...
Validation loss decreased (1.017369 --> 1.015911).  Saving model ...
Validation loss decreased (1.015911 --> 1.015602).  Saving model ...
Validation loss decreased (1.015602 --> 1.012723).  Saving model ...
EarlyStopping counter: 1 out of 10.0
EarlyStopping counter: 2 out of 10.0
Validation loss decreased (1.012723 --> 1.007473).  Saving model ...
EarlyStopping counter: 1 out of 10.0
Validation loss decreased (1.007473 --> 1.006467).  Saving model ...
Validation loss decreased (1.006467 --> 1.006077).  Saving model ...
Validation loss decreased (1.006077 --> 1.005533).  Saving model ...
Validation loss decreased (1.005533 --> 1.004232).  Saving model ...
Validation loss decreased (1.004232 --> 1.002195).  Saving model ...
Validation loss decreased (1.002195 --> 1.002068).  Saving model ...
Validation loss decreased (1.002068 --> 1.000749).  Saving model ...
Validation loss decreased (1.000749 --> 0.999541).  Saving model ...
Validation loss decreased (0.999541 --> 0.998609).  Saving model ...
Validation loss decreased (0.998609 --> 0.996270).  Saving model ...
Validation loss decreased (0.996270 --> 0.993532).  Saving model ...
Validation loss decreased (0.993532 --> 0.993154).  Saving model ...
EarlyStopping counter: 1 out of 10.0
Validation loss decreased (0.993154 --> 0.991892).  Saving model ...
Validation loss decreased (0.991892 --> 0.990672).  Saving model ...
EarlyStopping counter: 1 out of 10.0
EarlyStopping counter: 2 out of 10.0
Validation loss decreased (0.990672 --> 0.989016).  Saving model ...
Validation loss decreased (0.989016 --> 0.987293).  Saving model ...
Validation loss decreased (0.987293 --> 0.984672).  Saving model ...
EarlyStopping counter: 1 out of 10.0
EarlyStopping counter: 2 out of 10.0
EarlyStopping counter: 3 out of 10.0
Validation loss decreased (0.984672 --> 0.984405).  Saving model ...
Validation loss decreased (0.984405 --> 0.984217).  Saving model ...
EarlyStopping counter: 1 out of 10.0
Validation loss decreased (0.984217 --> 0.983099).  Saving model ...
Validation loss decreased (0.983099 --> 0.981876).  Saving model ...
Validation loss decreased (0.981876 --> 0.981500).  Saving model ...
Validation loss decreased (0.981500 --> 0.980508).  Saving model ...
Validation loss decreased (0.980508 --> 0.979957).  Saving model ...
EarlyStopping counter: 1 out of 10.0
EarlyStopping counter: 2 out of 10.0
EarlyStopping counter: 3 out of 10.0
EarlyStopping counter: 4 out of 10.0
EarlyStopping counter: 5 out of 10.0
EarlyStopping counter: 6 out of 10.0
EarlyStopping counter: 7 out of 10.0
EarlyStopping counter: 8 out of 10.0
EarlyStopping counter: 9 out of 10.0
Validation loss decreased (0.979957 --> 0.979591).  Saving model ...
EarlyStopping counter: 1 out of 10.0
EarlyStopping counter: 2 out of 10.0
EarlyStopping counter: 3 out of 10.0
Validation loss decreased (0.979591 --> 0.979295).  Saving model ...
EarlyStopping counter: 1 out of 10.0
EarlyStopping counter: 2 out of 10.0
EarlyStopping counter: 3 out of 10.0
EarlyStopping counter: 4 out of 10.0
EarlyStopping counter: 5 out of 10.0
EarlyStopping counter: 6 out of 10.0
EarlyStopping counter: 7 out of 10.0
EarlyStopping counter: 8 out of 10.0
EarlyStopping counter: 9 out of 10.0
EarlyStopping counter: 10 out of 10.0
/localscratch/yinan.28959366.0/env/lib/python3.7/site-packages/torch/nn/functional.py:1794: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.
  warnings.warn("nn.functional.tanh is deprecated. Use torch.tanh instead.")
wandb: Waiting for W&B process to finish, PID 241866... (success).
wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: \ 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: | 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: / 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: \ 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: | 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: / 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: \ 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: | 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: / 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: \ 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: | 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: / 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: \ 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: | 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: / 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: \ 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: | 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: / 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb:                                                                                
wandb: Run history:
wandb:     e_F1 ▁▂▃▄▅▅▅▅▆▆▆▆▆▆▇▇▇▇▇▇▇▇▇▇████████████████
wandb:   e_loss ██▇▇▇▆▆▆▅▄▄▄▄▃▃▃▃▂▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:     t_F1 ▁▁▂▃▃▄▄▄▄▅▅▅▅▅▆▆▆▆▆▆▇▆▆▇▇▇▇▇▇▇▇▇▇▇▇▇███▇
wandb:   t_loss ██▇▇▇▇▇▆▆▆▅▅▅▅▅▄▄▄▄▄▃▃▃▃▃▃▃▂▂▂▂▂▂▂▂▂▁▁▁▁
wandb: 
wandb: Run summary:
wandb:     e_F1 58.80302
wandb:   e_loss 0.982
wandb:     t_F1 74.6402
wandb:   t_loss 0.68945
wandb: 
wandb: Synced 4 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Synced earthy-oath-2: https://wandb.ai/yinanazhou/xl_512_bs_8_lr_1e06_es_10_lc_True_nr_True_sr_True_stem_False_lemma_False_repeat_2_fold_1/runs/27bv8cl4
wandb: Find logs at: ./wandb/run-20220315_053307-27bv8cl4/logs/debug.log
wandb: 

wandb: wandb version 0.12.11 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
2022-03-15 07:09:04.673813: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1
wandb: Tracking run with wandb version 0.12.5
wandb: Syncing run visionary-glade-2
wandb: ⭐️ View project at https://wandb.ai/yinanazhou/xl_512_bs_8_lr_1e06_es_10_lc_True_nr_True_sr_True_stem_False_lemma_False_repeat_2_fold_2
wandb: 🚀 View run at https://wandb.ai/yinanazhou/xl_512_bs_8_lr_1e06_es_10_lc_True_nr_True_sr_True_stem_False_lemma_False_repeat_2_fold_2/runs/312rupy9
wandb: Run data is saved locally in /project/6002780/yinan/Thesis_MER_Lyrics/lyric-emotion/wandb/run-20220315_070901-312rupy9
wandb: Run `wandb offline` to turn off syncing.

Validation loss decreased (inf --> 1.435304).  Saving model ...
Validation loss decreased (1.435304 --> 1.414969).  Saving model ...
Validation loss decreased (1.414969 --> 1.401179).  Saving model ...
Validation loss decreased (1.401179 --> 1.390258).  Saving model ...
Validation loss decreased (1.390258 --> 1.382705).  Saving model ...
Validation loss decreased (1.382705 --> 1.377029).  Saving model ...
Validation loss decreased (1.377029 --> 1.372139).  Saving model ...
Validation loss decreased (1.372139 --> 1.367805).  Saving model ...
Validation loss decreased (1.367805 --> 1.363482).  Saving model ...
Validation loss decreased (1.363482 --> 1.359862).  Saving model ...
Validation loss decreased (1.359862 --> 1.356362).  Saving model ...
Validation loss decreased (1.356362 --> 1.352619).  Saving model ...
Validation loss decreased (1.352619 --> 1.348932).  Saving model ...
Validation loss decreased (1.348932 --> 1.345315).  Saving model ...
Validation loss decreased (1.345315 --> 1.341916).  Saving model ...
Validation loss decreased (1.341916 --> 1.338500).  Saving model ...
Validation loss decreased (1.338500 --> 1.334724).  Saving model ...
Validation loss decreased (1.334724 --> 1.330859).  Saving model ...
Validation loss decreased (1.330859 --> 1.326775).  Saving model ...
Validation loss decreased (1.326775 --> 1.322790).  Saving model ...
Validation loss decreased (1.322790 --> 1.318540).  Saving model ...
Validation loss decreased (1.318540 --> 1.313674).  Saving model ...
Validation loss decreased (1.313674 --> 1.308744).  Saving model ...
Validation loss decreased (1.308744 --> 1.304240).  Saving model ...
Validation loss decreased (1.304240 --> 1.298934).  Saving model ...
Validation loss decreased (1.298934 --> 1.293980).  Saving model ...
Validation loss decreased (1.293980 --> 1.289588).  Saving model ...
Validation loss decreased (1.289588 --> 1.283821).  Saving model ...
Validation loss decreased (1.283821 --> 1.278269).  Saving model ...
Validation loss decreased (1.278269 --> 1.273964).  Saving model ...
Validation loss decreased (1.273964 --> 1.268389).  Saving model ...
Validation loss decreased (1.268389 --> 1.263141).  Saving model ...
Validation loss decreased (1.263141 --> 1.256837).  Saving model ...
Validation loss decreased (1.256837 --> 1.249204).  Saving model ...
Validation loss decreased (1.249204 --> 1.243787).  Saving model ...
Validation loss decreased (1.243787 --> 1.237523).  Saving model ...
Validation loss decreased (1.237523 --> 1.232549).  Saving model ...
Validation loss decreased (1.232549 --> 1.224874).  Saving model ...
Validation loss decreased (1.224874 --> 1.218023).  Saving model ...
Validation loss decreased (1.218023 --> 1.213067).  Saving model ...
Validation loss decreased (1.213067 --> 1.206734).  Saving model ...
Validation loss decreased (1.206734 --> 1.200325).  Saving model ...
Validation loss decreased (1.200325 --> 1.195536).  Saving model ...
Validation loss decreased (1.195536 --> 1.192135).  Saving model ...
Validation loss decreased (1.192135 --> 1.186089).  Saving model ...
Validation loss decreased (1.186089 --> 1.180468).  Saving model ...
Validation loss decreased (1.180468 --> 1.176528).  Saving model ...
Validation loss decreased (1.176528 --> 1.170689).  Saving model ...
Validation loss decreased (1.170689 --> 1.168160).  Saving model ...
Validation loss decreased (1.168160 --> 1.164616).  Saving model ...
Validation loss decreased (1.164616 --> 1.161656).  Saving model ...
Validation loss decreased (1.161656 --> 1.154705).  Saving model ...
Validation loss decreased (1.154705 --> 1.151650).  Saving model ...
Validation loss decreased (1.151650 --> 1.148429).  Saving model ...
Validation loss decreased (1.148429 --> 1.145145).  Saving model ...
Validation loss decreased (1.145145 --> 1.137947).  Saving model ...
Validation loss decreased (1.137947 --> 1.135284).  Saving model ...
Validation loss decreased (1.135284 --> 1.132773).  Saving model ...
Validation loss decreased (1.132773 --> 1.127152).  Saving model ...
Validation loss decreased (1.127152 --> 1.123527).  Saving model ...
Validation loss decreased (1.123527 --> 1.119549).  Saving model ...
Validation loss decreased (1.119549 --> 1.114477).  Saving model ...
Validation loss decreased (1.114477 --> 1.110592).  Saving model ...
Validation loss decreased (1.110592 --> 1.106836).  Saving model ...
Validation loss decreased (1.106836 --> 1.103015).  Saving model ...
Validation loss decreased (1.103015 --> 1.100449).  Saving model ...
Validation loss decreased (1.100449 --> 1.097754).  Saving model ...
Validation loss decreased (1.097754 --> 1.092077).  Saving model ...
EarlyStopping counter: 1 out of 10.0
Validation loss decreased (1.092077 --> 1.089997).  Saving model ...
Validation loss decreased (1.089997 --> 1.083590).  Saving model ...
Validation loss decreased (1.083590 --> 1.080948).  Saving model ...
Validation loss decreased (1.080948 --> 1.078084).  Saving model ...
Validation loss decreased (1.078084 --> 1.073848).  Saving model ...
Validation loss decreased (1.073848 --> 1.068160).  Saving model ...
Validation loss decreased (1.068160 --> 1.064953).  Saving model ...
Validation loss decreased (1.064953 --> 1.064649).  Saving model ...
Validation loss decreased (1.064649 --> 1.061992).  Saving model ...
Validation loss decreased (1.061992 --> 1.059716).  Saving model ...
Validation loss decreased (1.059716 --> 1.056109).  Saving model ...
Validation loss decreased (1.056109 --> 1.054531).  Saving model ...
Validation loss decreased (1.054531 --> 1.050190).  Saving model ...
Validation loss decreased (1.050190 --> 1.045909).  Saving model ...
Validation loss decreased (1.045909 --> 1.043912).  Saving model ...
Validation loss decreased (1.043912 --> 1.038480).  Saving model ...
Validation loss decreased (1.038480 --> 1.036974).  Saving model ...
Validation loss decreased (1.036974 --> 1.035351).  Saving model ...
Validation loss decreased (1.035351 --> 1.034001).  Saving model ...
Validation loss decreased (1.034001 --> 1.030427).  Saving model ...
Validation loss decreased (1.030427 --> 1.028175).  Saving model ...
Validation loss decreased (1.028175 --> 1.025382).  Saving model ...
Validation loss decreased (1.025382 --> 1.022415).  Saving model ...
Validation loss decreased (1.022415 --> 1.018602).  Saving model ...
Validation loss decreased (1.018602 --> 1.016407).  Saving model ...
Validation loss decreased (1.016407 --> 1.014163).  Saving model ...
Validation loss decreased (1.014163 --> 1.014112).  Saving model ...
Validation loss decreased (1.014112 --> 1.010248).  Saving model ...
Validation loss decreased (1.010248 --> 1.007697).  Saving model ...
Validation loss decreased (1.007697 --> 1.005853).  Saving model ...
Validation loss decreased (1.005853 --> 1.002276).  Saving model ...
Validation loss decreased (1.002276 --> 0.999743).  Saving model ...
Validation loss decreased (0.999743 --> 0.995365).  Saving model ...
Validation loss decreased (0.995365 --> 0.993122).  Saving model ...
Validation loss decreased (0.993122 --> 0.991884).  Saving model ...
EarlyStopping counter: 1 out of 10.0
EarlyStopping counter: 2 out of 10.0
EarlyStopping counter: 3 out of 10.0
Validation loss decreased (0.991884 --> 0.990606).  Saving model ...
Validation loss decreased (0.990606 --> 0.990240).  Saving model ...
Validation loss decreased (0.990240 --> 0.985715).  Saving model ...
Validation loss decreased (0.985715 --> 0.984887).  Saving model ...
Validation loss decreased (0.984887 --> 0.981213).  Saving model ...
Validation loss decreased (0.981213 --> 0.980376).  Saving model ...
Validation loss decreased (0.980376 --> 0.979075).  Saving model ...
EarlyStopping counter: 1 out of 10.0
Validation loss decreased (0.979075 --> 0.975494).  Saving model ...
Validation loss decreased (0.975494 --> 0.973812).  Saving model ...
Validation loss decreased (0.973812 --> 0.973496).  Saving model ...
Validation loss decreased (0.973496 --> 0.971893).  Saving model ...
EarlyStopping counter: 1 out of 10.0
Validation loss decreased (0.971893 --> 0.969192).  Saving model ...
Validation loss decreased (0.969192 --> 0.968890).  Saving model ...
Validation loss decreased (0.968890 --> 0.966099).  Saving model ...
Validation loss decreased (0.966099 --> 0.964371).  Saving model ...
Validation loss decreased (0.964371 --> 0.963814).  Saving model ...
Validation loss decreased (0.963814 --> 0.961851).  Saving model ...
EarlyStopping counter: 1 out of 10.0
Validation loss decreased (0.961851 --> 0.960331).  Saving model ...
Validation loss decreased (0.960331 --> 0.958202).  Saving model ...
EarlyStopping counter: 1 out of 10.0
Validation loss decreased (0.958202 --> 0.957513).  Saving model ...
Validation loss decreased (0.957513 --> 0.953946).  Saving model ...
EarlyStopping counter: 1 out of 10.0
Validation loss decreased (0.953946 --> 0.953619).  Saving model ...
Validation loss decreased (0.953619 --> 0.953258).  Saving model ...
Validation loss decreased (0.953258 --> 0.952856).  Saving model ...
Validation loss decreased (0.952856 --> 0.951710).  Saving model ...
EarlyStopping counter: 1 out of 10.0
Validation loss decreased (0.951710 --> 0.950945).  Saving model ...
Validation loss decreased (0.950945 --> 0.947351).  Saving model ...
Validation loss decreased (0.947351 --> 0.947028).  Saving model ...
EarlyStopping counter: 1 out of 10.0
Validation loss decreased (0.947028 --> 0.946037).  Saving model ...
EarlyStopping counter: 1 out of 10.0
Validation loss decreased (0.946037 --> 0.943717).  Saving model ...
EarlyStopping counter: 1 out of 10.0
Validation loss decreased (0.943717 --> 0.942745).  Saving model ...
Validation loss decreased (0.942745 --> 0.941345).  Saving model ...
EarlyStopping counter: 1 out of 10.0
EarlyStopping counter: 2 out of 10.0
Validation loss decreased (0.941345 --> 0.940666).  Saving model ...
EarlyStopping counter: 1 out of 10.0
EarlyStopping counter: 2 out of 10.0
EarlyStopping counter: 3 out of 10.0
Validation loss decreased (0.940666 --> 0.939534).  Saving model ...
EarlyStopping counter: 1 out of 10.0
EarlyStopping counter: 2 out of 10.0
EarlyStopping counter: 3 out of 10.0
Validation loss decreased (0.939534 --> 0.938933).  Saving model ...
EarlyStopping counter: 1 out of 10.0
EarlyStopping counter: 2 out of 10.0
EarlyStopping counter: 3 out of 10.0
Validation loss decreased (0.938933 --> 0.937028).  Saving model ...
Validation loss decreased (0.937028 --> 0.936973).  Saving model ...
Validation loss decreased (0.936973 --> 0.935686).  Saving model ...
EarlyStopping counter: 1 out of 10.0
Validation loss decreased (0.935686 --> 0.934729).  Saving model ...
EarlyStopping counter: 1 out of 10.0
EarlyStopping counter: 2 out of 10.0
EarlyStopping counter: 3 out of 10.0
EarlyStopping counter: 4 out of 10.0
EarlyStopping counter: 5 out of 10.0
EarlyStopping counter: 6 out of 10.0
EarlyStopping counter: 7 out of 10.0
EarlyStopping counter: 8 out of 10.0
EarlyStopping counter: 9 out of 10.0
EarlyStopping counter: 10 out of 10.0
/localscratch/yinan.28959366.0/env/lib/python3.7/site-packages/torch/nn/functional.py:1794: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.
  warnings.warn("nn.functional.tanh is deprecated. Use torch.tanh instead.")
wandb: Waiting for W&B process to finish, PID 246981... (success).
wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: \ 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: | 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: / 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: \ 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: | 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: / 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: \ 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: | 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: / 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb:                                                                                
wandb: Run history:
wandb:     e_F1 ▁▂▃▄▅▆▆▆▆▆▆▆▆▇▇▇▇▇▇▇█▇▇▇▇██▇████████████
wandb:   e_loss █▇▇▇▇▆▆▆▅▅▅▄▄▄▃▃▃▃▃▂▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:     t_F1 ▁▂▃▃▃▃▄▄▄▅▅▅▅▆▅▆▆▆▆▆▆▆▆▆▆▇▇▇▇▇▇▇██▇█▇▇██
wandb:   t_loss ██▇▇▇▇▇▆▆▆▆▅▅▅▅▅▄▄▄▄▄▃▃▃▃▃▃▃▃▃▂▂▂▂▂▂▂▁▁▁
wandb: 
wandb: Run summary:
wandb:     e_F1 59.2421
wandb:   e_loss 0.93823
wandb:     t_F1 75.13099
wandb:   t_loss 0.70915
wandb: 
wandb: Synced 4 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Synced visionary-glade-2: https://wandb.ai/yinanazhou/xl_512_bs_8_lr_1e06_es_10_lc_True_nr_True_sr_True_stem_False_lemma_False_repeat_2_fold_2/runs/312rupy9
wandb: Find logs at: ./wandb/run-20220315_070901-312rupy9/logs/debug.log
wandb: 

wandb: wandb version 0.12.11 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
2022-03-15 08:59:56.375535: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1
wandb: Tracking run with wandb version 0.12.5
wandb: Syncing run iconic-forest-2
wandb: ⭐️ View project at https://wandb.ai/yinanazhou/xl_512_bs_8_lr_1e06_es_10_lc_True_nr_True_sr_True_stem_False_lemma_False_repeat_3_fold_1
wandb: 🚀 View run at https://wandb.ai/yinanazhou/xl_512_bs_8_lr_1e06_es_10_lc_True_nr_True_sr_True_stem_False_lemma_False_repeat_3_fold_1/runs/1gfyqrac
wandb: Run data is saved locally in /project/6002780/yinan/Thesis_MER_Lyrics/lyric-emotion/wandb/run-20220315_085953-1gfyqrac
wandb: Run `wandb offline` to turn off syncing.

Validation loss decreased (inf --> 1.398402).  Saving model ...
Validation loss decreased (1.398402 --> 1.393077).  Saving model ...
Validation loss decreased (1.393077 --> 1.388340).  Saving model ...
Validation loss decreased (1.388340 --> 1.384082).  Saving model ...
Validation loss decreased (1.384082 --> 1.380269).  Saving model ...
Validation loss decreased (1.380269 --> 1.376717).  Saving model ...
Validation loss decreased (1.376717 --> 1.373262).  Saving model ...
Validation loss decreased (1.373262 --> 1.369900).  Saving model ...
Validation loss decreased (1.369900 --> 1.366494).  Saving model ...
Validation loss decreased (1.366494 --> 1.363028).  Saving model ...
Validation loss decreased (1.363028 --> 1.359643).  Saving model ...
Validation loss decreased (1.359643 --> 1.356210).  Saving model ...
Validation loss decreased (1.356210 --> 1.352977).  Saving model ...
Validation loss decreased (1.352977 --> 1.349360).  Saving model ...
Validation loss decreased (1.349360 --> 1.345548).  Saving model ...
Validation loss decreased (1.345548 --> 1.341274).  Saving model ...
Validation loss decreased (1.341274 --> 1.336744).  Saving model ...
Validation loss decreased (1.336744 --> 1.332449).  Saving model ...
Validation loss decreased (1.332449 --> 1.327708).  Saving model ...
Validation loss decreased (1.327708 --> 1.322156).  Saving model ...
Validation loss decreased (1.322156 --> 1.316591).  Saving model ...
Validation loss decreased (1.316591 --> 1.310893).  Saving model ...
Validation loss decreased (1.310893 --> 1.304443).  Saving model ...
Validation loss decreased (1.304443 --> 1.297631).  Saving model ...
Validation loss decreased (1.297631 --> 1.290284).  Saving model ...
Validation loss decreased (1.290284 --> 1.282537).  Saving model ...
Validation loss decreased (1.282537 --> 1.275665).  Saving model ...
Validation loss decreased (1.275665 --> 1.268590).  Saving model ...
Validation loss decreased (1.268590 --> 1.261084).  Saving model ...
Validation loss decreased (1.261084 --> 1.253976).  Saving model ...
Validation loss decreased (1.253976 --> 1.246576).  Saving model ...
Validation loss decreased (1.246576 --> 1.239871).  Saving model ...
Validation loss decreased (1.239871 --> 1.234362).  Saving model ...
Validation loss decreased (1.234362 --> 1.229952).  Saving model ...
Validation loss decreased (1.229952 --> 1.222908).  Saving model ...
Validation loss decreased (1.222908 --> 1.217454).  Saving model ...
Validation loss decreased (1.217454 --> 1.210675).  Saving model ...
Validation loss decreased (1.210675 --> 1.205558).  Saving model ...
Validation loss decreased (1.205558 --> 1.199748).  Saving model ...
Validation loss decreased (1.199748 --> 1.195568).  Saving model ...
Validation loss decreased (1.195568 --> 1.190020).  Saving model ...
Validation loss decreased (1.190020 --> 1.186909).  Saving model ...
Validation loss decreased (1.186909 --> 1.182934).  Saving model ...
Validation loss decreased (1.182934 --> 1.179184).  Saving model ...
Validation loss decreased (1.179184 --> 1.174496).  Saving model ...
Validation loss decreased (1.174496 --> 1.169567).  Saving model ...
Validation loss decreased (1.169567 --> 1.165776).  Saving model ...
Validation loss decreased (1.165776 --> 1.161005).  Saving model ...
Validation loss decreased (1.161005 --> 1.154977).  Saving model ...
Validation loss decreased (1.154977 --> 1.153337).  Saving model ...
Validation loss decreased (1.153337 --> 1.148172).  Saving model ...
Validation loss decreased (1.148172 --> 1.144202).  Saving model ...
Validation loss decreased (1.144202 --> 1.138662).  Saving model ...
Validation loss decreased (1.138662 --> 1.133667).  Saving model ...
Validation loss decreased (1.133667 --> 1.127155).  Saving model ...
Validation loss decreased (1.127155 --> 1.126538).  Saving model ...
Validation loss decreased (1.126538 --> 1.121701).  Saving model ...
Validation loss decreased (1.121701 --> 1.118935).  Saving model ...
Validation loss decreased (1.118935 --> 1.116541).  Saving model ...
Validation loss decreased (1.116541 --> 1.111464).  Saving model ...
Validation loss decreased (1.111464 --> 1.109039).  Saving model ...
Validation loss decreased (1.109039 --> 1.101144).  Saving model ...
Validation loss decreased (1.101144 --> 1.099080).  Saving model ...
Validation loss decreased (1.099080 --> 1.095982).  Saving model ...
Validation loss decreased (1.095982 --> 1.095586).  Saving model ...
Validation loss decreased (1.095586 --> 1.089267).  Saving model ...
Validation loss decreased (1.089267 --> 1.087532).  Saving model ...
Validation loss decreased (1.087532 --> 1.079669).  Saving model ...
Validation loss decreased (1.079669 --> 1.074007).  Saving model ...
Validation loss decreased (1.074007 --> 1.073793).  Saving model ...
Validation loss decreased (1.073793 --> 1.070696).  Saving model ...
Validation loss decreased (1.070696 --> 1.068331).  Saving model ...
Validation loss decreased (1.068331 --> 1.065276).  Saving model ...
Validation loss decreased (1.065276 --> 1.063041).  Saving model ...
Validation loss decreased (1.063041 --> 1.059916).  Saving model ...
Validation loss decreased (1.059916 --> 1.054639).  Saving model ...
Validation loss decreased (1.054639 --> 1.053671).  Saving model ...
EarlyStopping counter: 1 out of 10.0
Validation loss decreased (1.053671 --> 1.051569).  Saving model ...
Validation loss decreased (1.051569 --> 1.048903).  Saving model ...
Validation loss decreased (1.048903 --> 1.046679).  Saving model ...
Validation loss decreased (1.046679 --> 1.043692).  Saving model ...
Validation loss decreased (1.043692 --> 1.039375).  Saving model ...
Validation loss decreased (1.039375 --> 1.038153).  Saving model ...
Validation loss decreased (1.038153 --> 1.037003).  Saving model ...
EarlyStopping counter: 1 out of 10.0
Validation loss decreased (1.037003 --> 1.036426).  Saving model ...
Validation loss decreased (1.036426 --> 1.032334).  Saving model ...
Validation loss decreased (1.032334 --> 1.026533).  Saving model ...
EarlyStopping counter: 1 out of 10.0
Validation loss decreased (1.026533 --> 1.025054).  Saving model ...
Validation loss decreased (1.025054 --> 1.024432).  Saving model ...
Validation loss decreased (1.024432 --> 1.024207).  Saving model ...
Validation loss decreased (1.024207 --> 1.021210).  Saving model ...
Validation loss decreased (1.021210 --> 1.015432).  Saving model ...
EarlyStopping counter: 1 out of 10.0
EarlyStopping counter: 2 out of 10.0
EarlyStopping counter: 3 out of 10.0
Validation loss decreased (1.015432 --> 1.014470).  Saving model ...
Validation loss decreased (1.014470 --> 1.012029).  Saving model ...
Validation loss decreased (1.012029 --> 1.011294).  Saving model ...
Validation loss decreased (1.011294 --> 1.008052).  Saving model ...
EarlyStopping counter: 1 out of 10.0
EarlyStopping counter: 2 out of 10.0
Validation loss decreased (1.008052 --> 1.005620).  Saving model ...
EarlyStopping counter: 1 out of 10.0
EarlyStopping counter: 2 out of 10.0
Validation loss decreased (1.005620 --> 1.002545).  Saving model ...
Validation loss decreased (1.002545 --> 1.002161).  Saving model ...
EarlyStopping counter: 1 out of 10.0
EarlyStopping counter: 2 out of 10.0
Validation loss decreased (1.002161 --> 0.999781).  Saving model ...
EarlyStopping counter: 1 out of 10.0
Validation loss decreased (0.999781 --> 0.998947).  Saving model ...
EarlyStopping counter: 1 out of 10.0
EarlyStopping counter: 2 out of 10.0
Validation loss decreased (0.998947 --> 0.998725).  Saving model ...
EarlyStopping counter: 1 out of 10.0
Validation loss decreased (0.998725 --> 0.995324).  Saving model ...
EarlyStopping counter: 1 out of 10.0
Validation loss decreased (0.995324 --> 0.994996).  Saving model ...
EarlyStopping counter: 1 out of 10.0
EarlyStopping counter: 2 out of 10.0
Validation loss decreased (0.994996 --> 0.991891).  Saving model ...
EarlyStopping counter: 1 out of 10.0
EarlyStopping counter: 2 out of 10.0
EarlyStopping counter: 3 out of 10.0
Validation loss decreased (0.991891 --> 0.986580).  Saving model ...
EarlyStopping counter: 1 out of 10.0
EarlyStopping counter: 2 out of 10.0
EarlyStopping counter: 3 out of 10.0
EarlyStopping counter: 4 out of 10.0
EarlyStopping counter: 5 out of 10.0
EarlyStopping counter: 6 out of 10.0
EarlyStopping counter: 7 out of 10.0
EarlyStopping counter: 8 out of 10.0
EarlyStopping counter: 9 out of 10.0
EarlyStopping counter: 10 out of 10.0
/localscratch/yinan.28959366.0/env/lib/python3.7/site-packages/torch/nn/functional.py:1794: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.
  warnings.warn("nn.functional.tanh is deprecated. Use torch.tanh instead.")
wandb: Waiting for W&B process to finish, PID 252871... (success).
wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: \ 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: | 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: / 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: \ 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: | 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: / 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: \ 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: | 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: / 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: \ 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb:                                                                                
wandb: Run history:
wandb:     e_F1 ▁▁▂▃▃▄▅▆▆▅▆▆▆▆▆▆▇▇▇▇▇▇▇▇▇▇▇▇▇███████████
wandb:   e_loss ███▇▇▇▇▆▆▅▅▅▄▄▄▃▃▃▃▃▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:     t_F1 ▁▁▂▃▂▃▃▃▃▄▅▄▅▅▅▆▅▆▆▆▆▆▇▆▇▆▇▇▇▇▇▇▇▇▇█▇▇██
wandb:   t_loss ████▇▇▇▇▇▆▆▆▅▅▅▅▅▅▄▄▄▄▃▃▃▃▃▃▃▃▂▂▂▂▂▂▂▂▂▁
wandb: 
wandb: Run summary:
wandb:     e_F1 57.65896
wandb:   e_loss 0.99242
wandb:     t_F1 73.90576
wandb:   t_loss 0.71272
wandb: 
wandb: Synced 4 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Synced iconic-forest-2: https://wandb.ai/yinanazhou/xl_512_bs_8_lr_1e06_es_10_lc_True_nr_True_sr_True_stem_False_lemma_False_repeat_3_fold_1/runs/1gfyqrac
wandb: Find logs at: ./wandb/run-20220315_085953-1gfyqrac/logs/debug.log
wandb: 

wandb: wandb version 0.12.11 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
2022-03-15 10:28:35.984834: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1
wandb: Tracking run with wandb version 0.12.5
wandb: Syncing run icy-gorge-2
wandb: ⭐️ View project at https://wandb.ai/yinanazhou/xl_512_bs_8_lr_1e06_es_10_lc_True_nr_True_sr_True_stem_False_lemma_False_repeat_3_fold_2
wandb: 🚀 View run at https://wandb.ai/yinanazhou/xl_512_bs_8_lr_1e06_es_10_lc_True_nr_True_sr_True_stem_False_lemma_False_repeat_3_fold_2/runs/33lbuhpu
wandb: Run data is saved locally in /project/6002780/yinan/Thesis_MER_Lyrics/lyric-emotion/wandb/run-20220315_102832-33lbuhpu
wandb: Run `wandb offline` to turn off syncing.
wandb: Network error (ReadTimeout), entering retry loop.
slurmstepd: error: *** JOB 28959366 ON cdr2579 CANCELLED AT 2022-03-15T11:59:31 DUE TO TIME LIMIT ***
