Unloading StdEnv/2020

Due to MODULEPATH changes, the following have been reloaded:
  1) mii/1.1.1


The following have been reloaded with a version change:
  1) python/3.8.2 => python/3.7.4

Using base prefix '/cvmfs/soft.computecanada.ca/easybuild/software/2017/Core/python/3.7.4'
New python executable in /localscratch/yinan.29154792.0/env/bin/python
Installing setuptools, pip, wheel...
done.
Ignoring pip: markers 'python_version < "3"' don't match your environment
Looking in links: /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/nix/avx2, /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/nix/generic, /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic
Collecting pip
Installing collected packages: pip
  Found existing installation: pip 19.1.1
    Uninstalling pip-19.1.1:
      Successfully uninstalled pip-19.1.1
Successfully installed pip-21.2.3+computecanada
Looking in links: /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/nix/avx2, /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/nix/generic, /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/keras-2.8.0+computecanada-py2.py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/Keras_Preprocessing-1.1.2+computecanada-py3-none-any.whl
Requirement already satisfied: matplotlib in /cvmfs/soft.computecanada.ca/easybuild/software/2017/Core/scipy-stack/2019a/lib/python3.7/site-packages (from -r requirements.txt (line 3)) (3.0.2)
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/nltk-3.6.5+computecanada-py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/scikit_learn-0.22.1+computecanada-cp37-cp37m-linux_x86_64.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/tensorboard-2.3.0+computecanada-py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/tensorboard_plugin_wit-1.7.0+computecanada-py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/tensorflow_gpu-2.3.0+computecanada-cp37-cp37m-linux_x86_64.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/tensorflow_estimator-2.3.0+computecanada-py2.py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/tokenizers-0.5.2+computecanada-cp37-cp37m-linux_x86_64.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/nix/avx2/torch-1.4.0+computecanada-cp37-cp37m-linux_x86_64.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/torchtext-0.6.0+computecanada-py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/torchvision-0.8.2+computecanada-cp37-cp37m-linux_x86_64.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/transformers-2.5.1+computecanada-py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/urllib3-1.26.7+computecanada-py2.py3-none-any.whl
ERROR: Could not find a version that satisfies the requirement regex>=2021.8.3 (from nltk) (from versions: 2018.1.10+computecanada, 2019.11.1+computecanada, 2020.11.13+computecanada)
ERROR: No matching distribution found for regex>=2021.8.3
Looking in links: /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/nix/avx2, /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/nix/generic, /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic
ERROR: Could not find a version that satisfies the requirement numpy==1.20.0+computacanada (from versions: 1.15.0+computecanada, 1.15.2+computecanada, 1.15.4+computecanada, 1.16.0+computecanada, 1.16.2+computecanada, 1.16.3+computecanada, 1.17.4+computecanada, 1.18.1+computecanada, 1.18.4+computecanada, 1.19.1+computecanada, 1.19.2+computecanada, 1.20.2+computecanada)
ERROR: No matching distribution found for numpy==1.20.0+computacanada
Looking in links: /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/nix/avx2, /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/nix/generic, /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/wandb-0.12.5+computecanada-py2.py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/configparser-5.0.2+computecanada-py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/pathtools-0.1.2+computecanada-py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/psutil-5.7.3+computecanada-cp37-cp37m-linux_x86_64.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/six-1.16.0+computecanada-py2.py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/sentry_sdk-1.5.0+computecanada-py2.py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/shortuuid-1.0.1+computecanada-py3-none-any.whl
Requirement already satisfied: requests<3,>=2.0.0 in /cvmfs/soft.computecanada.ca/easybuild/software/2017/Core/scipy-stack/2019a/lib/python3.7/site-packages (from wandb) (2.21.0)
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/click-8.0.4+computecanada-py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/promise-2.3+computecanada-py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/docker_pycreds-0.4.0+computecanada-py2.py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/protobuf-3.19.4+computecanada-py2.py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/GitPython-3.1.24+computecanada-py3-none-any.whl
Requirement already satisfied: python-dateutil>=2.6.1 in /cvmfs/soft.computecanada.ca/easybuild/software/2017/Core/scipy-stack/2019a/lib/python3.7/site-packages (from wandb) (2.7.5)
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/yaspin-2.1.0+computecanada-py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/PyYAML-5.3.1+computecanada-cp37-cp37m-linux_x86_64.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/subprocess32-3.5.4+computecanada-py3-none-any.whl
Requirement already satisfied: importlib-metadata in /cvmfs/soft.computecanada.ca/easybuild/software/2017/Core/scipy-stack/2019a/lib/python3.7/site-packages (from Click!=8.0.0,>=7.0->wandb) (0.8)
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/gitdb-4.0.9+computecanada-py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/typing_extensions-4.0.1+computecanada-py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/smmap-5.0.0+computecanada-py3-none-any.whl
Requirement already satisfied: certifi>=2017.4.17 in /cvmfs/soft.computecanada.ca/easybuild/software/2017/Core/scipy-stack/2019a/lib/python3.7/site-packages (from requests<3,>=2.0.0->wandb) (2018.11.29)
Requirement already satisfied: urllib3<1.25,>=1.21.1 in /cvmfs/soft.computecanada.ca/easybuild/software/2017/Core/scipy-stack/2019a/lib/python3.7/site-packages (from requests<3,>=2.0.0->wandb) (1.24.1)
Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /cvmfs/soft.computecanada.ca/easybuild/software/2017/Core/scipy-stack/2019a/lib/python3.7/site-packages (from requests<3,>=2.0.0->wandb) (3.0.4)
Requirement already satisfied: idna<2.9,>=2.5 in /cvmfs/soft.computecanada.ca/easybuild/software/2017/Core/scipy-stack/2019a/lib/python3.7/site-packages (from requests<3,>=2.0.0->wandb) (2.8)
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/termcolor-1.1.0+computecanada-py3-none-any.whl
Requirement already satisfied: zipp>=0.3.2 in /cvmfs/soft.computecanada.ca/easybuild/software/2017/Core/scipy-stack/2019a/lib/python3.7/site-packages (from importlib-metadata->Click!=8.0.0,>=7.0->wandb) (0.3.3)
Installing collected packages: smmap, typing-extensions, termcolor, six, gitdb, yaspin, subprocess32, shortuuid, sentry-sdk, PyYAML, psutil, protobuf, promise, pathtools, GitPython, docker-pycreds, configparser, Click, wandb
  Attempting uninstall: six
    Found existing installation: six 1.12.0
    Not uninstalling six at /cvmfs/soft.computecanada.ca/easybuild/software/2017/Core/scipy-stack/2019a/lib/python3.7/site-packages, outside environment /localscratch/yinan.29154792.0/env
    Can't uninstall 'six'. No files were found to uninstall.
Successfully installed Click-8.0.4+computecanada GitPython-3.1.24+computecanada PyYAML-5.3.1+computecanada configparser-5.0.2+computecanada docker-pycreds-0.4.0+computecanada gitdb-4.0.9+computecanada pathtools-0.1.2+computecanada promise-2.3+computecanada protobuf-3.19.4+computecanada psutil-5.7.3+computecanada sentry-sdk-1.5.0+computecanada shortuuid-1.0.1+computecanada six-1.16.0+computecanada smmap-5.0.0+computecanada subprocess32-3.5.4+computecanada termcolor-1.1.0+computecanada typing-extensions-4.0.1+computecanada wandb-0.12.5+computecanada yaspin-2.1.0+computecanada
Looking in links: /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/nix/avx2, /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/nix/generic, /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic
ERROR: Could not find a version that satisfies the requirement sagemaker (from versions: none)
ERROR: No matching distribution found for sagemaker
Looking in links: /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/nix/avx2, /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/nix/generic, /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/torch-1.9.1+computecanada-cp37-cp37m-linux_x86_64.whl
Requirement already satisfied: typing-extensions in /localscratch/yinan.29154792.0/env/lib/python3.7/site-packages (from torch) (4.0.1+computecanada)
Installing collected packages: torch
Successfully installed torch-1.9.1+computecanada
Looking in links: /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/nix/avx2, /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/nix/generic, /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/transformers-2.5.1+computecanada-py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/sentencepiece-0.1.91+computecanada-cp37-cp37m-linux_x86_64.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/tokenizers-0.5.2+computecanada-cp37-cp37m-linux_x86_64.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/sacremoses-0.0.46+computecanada-py3-none-any.whl
Requirement already satisfied: requests in /cvmfs/soft.computecanada.ca/easybuild/software/2017/Core/scipy-stack/2019a/lib/python3.7/site-packages (from transformers==2.5.1+computecanada) (2.21.0)
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/regex-2020.11.13+computecanada-cp37-cp37m-linux_x86_64.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/boto3-1.21.14+computecanada-py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/filelock-3.4.2+computecanada-py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/tqdm-4.63.0+computecanada-py2.py3-none-any.whl
Requirement already satisfied: numpy in /cvmfs/soft.computecanada.ca/easybuild/software/2017/Core/scipy-stack/2019a/lib/python3.7/site-packages (from transformers==2.5.1+computecanada) (1.16.0)
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/jmespath-0.10.0+computecanada-py2.py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/s3transfer-0.5.1+computecanada-py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/botocore-1.24.14+computecanada-py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/urllib3-1.26.8+computecanada-py2.py3-none-any.whl
Requirement already satisfied: python-dateutil<3.0.0,>=2.1 in /cvmfs/soft.computecanada.ca/easybuild/software/2017/Core/scipy-stack/2019a/lib/python3.7/site-packages (from botocore<1.25.0,>=1.24.14->boto3->transformers==2.5.1+computecanada) (2.7.5)
Requirement already satisfied: six>=1.5 in /localscratch/yinan.29154792.0/env/lib/python3.7/site-packages (from python-dateutil<3.0.0,>=2.1->botocore<1.25.0,>=1.24.14->boto3->transformers==2.5.1+computecanada) (1.16.0+computecanada)
Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /cvmfs/soft.computecanada.ca/easybuild/software/2017/Core/scipy-stack/2019a/lib/python3.7/site-packages (from requests->transformers==2.5.1+computecanada) (3.0.4)
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/requests-2.27.1+computecanada-py2.py3-none-any.whl
Requirement already satisfied: certifi>=2017.4.17 in /cvmfs/soft.computecanada.ca/easybuild/software/2017/Core/scipy-stack/2019a/lib/python3.7/site-packages (from requests->transformers==2.5.1+computecanada) (2018.11.29)
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/charset_normalizer-2.0.12+computecanada-py3-none-any.whl
Requirement already satisfied: idna<4,>=2.5 in /cvmfs/soft.computecanada.ca/easybuild/software/2017/Core/scipy-stack/2019a/lib/python3.7/site-packages (from requests->transformers==2.5.1+computecanada) (2.8)
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/joblib-1.1.0+computecanada-py2.py3-none-any.whl
Requirement already satisfied: click in /localscratch/yinan.29154792.0/env/lib/python3.7/site-packages (from sacremoses->transformers==2.5.1+computecanada) (8.0.4+computecanada)
Requirement already satisfied: importlib-metadata in /cvmfs/soft.computecanada.ca/easybuild/software/2017/Core/scipy-stack/2019a/lib/python3.7/site-packages (from click->sacremoses->transformers==2.5.1+computecanada) (0.8)
Requirement already satisfied: zipp>=0.3.2 in /cvmfs/soft.computecanada.ca/easybuild/software/2017/Core/scipy-stack/2019a/lib/python3.7/site-packages (from importlib-metadata->click->sacremoses->transformers==2.5.1+computecanada) (0.3.3)
Installing collected packages: urllib3, jmespath, botocore, tqdm, s3transfer, regex, joblib, charset-normalizer, tokenizers, sentencepiece, sacremoses, requests, filelock, boto3, transformers
  Attempting uninstall: urllib3
    Found existing installation: urllib3 1.24.1
    Not uninstalling urllib3 at /cvmfs/soft.computecanada.ca/easybuild/software/2017/Core/scipy-stack/2019a/lib/python3.7/site-packages, outside environment /localscratch/yinan.29154792.0/env
    Can't uninstall 'urllib3'. No files were found to uninstall.
  Attempting uninstall: requests
    Found existing installation: requests 2.21.0
    Not uninstalling requests at /cvmfs/soft.computecanada.ca/easybuild/software/2017/Core/scipy-stack/2019a/lib/python3.7/site-packages, outside environment /localscratch/yinan.29154792.0/env
    Can't uninstall 'requests'. No files were found to uninstall.
Successfully installed boto3-1.21.14+computecanada botocore-1.24.14+computecanada charset-normalizer-2.0.12+computecanada filelock-3.4.2+computecanada jmespath-0.10.0+computecanada joblib-1.1.0+computecanada regex-2020.11.13+computecanada requests-2.27.1+computecanada s3transfer-0.5.1+computecanada sacremoses-0.0.46+computecanada sentencepiece-0.1.91+computecanada tokenizers-0.5.2+computecanada tqdm-4.63.0+computecanada transformers-2.5.1+computecanada urllib3-1.26.8+computecanada
Looking in links: /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/nix/avx2, /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/nix/generic, /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/tensorflow_gpu-2.3.0+computecanada-cp37-cp37m-linux_x86_64.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/nix/avx2/h5py-2.10.0+computecanada-cp37-cp37m-linux_x86_64.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/grpcio-1.38.0+computecanada-cp37-cp37m-linux_x86_64.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/opt_einsum-3.3.0+computecanada-py3-none-any.whl
Requirement already satisfied: termcolor>=1.1.0 in /localscratch/yinan.29154792.0/env/lib/python3.7/site-packages (from tensorflow_gpu==2.3.0+computecanada) (1.1.0+computecanada)
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/absl_py-1.0.0+computecanada-py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/nix/generic/scipy-1.4.1+computecanada-cp37-cp37m-linux_x86_64.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/tensorboard-2.8.0+computecanada-py3-none-any.whl
Requirement already satisfied: wheel>=0.26 in /localscratch/yinan.29154792.0/env/lib/python3.7/site-packages (from tensorflow_gpu==2.3.0+computecanada) (0.33.4)
Requirement already satisfied: six>=1.12.0 in /localscratch/yinan.29154792.0/env/lib/python3.7/site-packages (from tensorflow_gpu==2.3.0+computecanada) (1.16.0+computecanada)
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/tensorflow_estimator-2.3.0+computecanada-py2.py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/astunparse-1.6.3+computecanada-py2.py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/gast-0.3.3+computecanada-py3-none-any.whl
Requirement already satisfied: protobuf>=3.9.2 in /localscratch/yinan.29154792.0/env/lib/python3.7/site-packages (from tensorflow_gpu==2.3.0+computecanada) (3.19.4+computecanada)
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/google_pasta-0.2.0+computecanada-py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/wrapt-1.11.2+computecanada-cp37-cp37m-linux_x86_64.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/Keras_Preprocessing-1.1.2+computecanada-py3-none-any.whl
Requirement already satisfied: numpy<1.19.0,>=1.16.0 in /cvmfs/soft.computecanada.ca/easybuild/software/2017/Core/scipy-stack/2019a/lib/python3.7/site-packages (from tensorflow_gpu==2.3.0+computecanada) (1.16.0)
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/Werkzeug-2.0.3+computecanada-py3-none-any.whl
Requirement already satisfied: setuptools>=41.0.0 in /localscratch/yinan.29154792.0/env/lib/python3.7/site-packages (from tensorboard<3,>=2.3.0->tensorflow_gpu==2.3.0+computecanada) (41.0.1)
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/google_auth-2.3.3+computecanada-py2.py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/tensorboard_plugin_wit-1.8.0+computecanada-py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/google_auth_oauthlib-0.4.6+computecanada-py2.py3-none-any.whl
Requirement already satisfied: requests<3,>=2.21.0 in /localscratch/yinan.29154792.0/env/lib/python3.7/site-packages (from tensorboard<3,>=2.3.0->tensorflow_gpu==2.3.0+computecanada) (2.27.1+computecanada)
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/Markdown-3.3.6+computecanada-py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/tensorboard_data_server-0.6.1+computecanada-py3-none-linux_x86_64.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/rsa-4.8+computecanada-py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/cachetools-4.2.4+computecanada-py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/pyasn1_modules-0.2.8+computecanada-py2.py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/requests_oauthlib-1.3.0+computecanada-py2.py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/importlib_metadata-4.10.1+computecanada-py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/zipp-3.7.0+computecanada-py3-none-any.whl
Requirement already satisfied: typing-extensions>=3.6.4 in /localscratch/yinan.29154792.0/env/lib/python3.7/site-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard<3,>=2.3.0->tensorflow_gpu==2.3.0+computecanada) (4.0.1+computecanada)
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/pyasn1-0.4.8+computecanada-py2.py3-none-any.whl
Requirement already satisfied: idna<4,>=2.5 in /cvmfs/soft.computecanada.ca/easybuild/software/2017/Core/scipy-stack/2019a/lib/python3.7/site-packages (from requests<3,>=2.21.0->tensorboard<3,>=2.3.0->tensorflow_gpu==2.3.0+computecanada) (2.8)
Requirement already satisfied: urllib3<1.27,>=1.21.1 in /localscratch/yinan.29154792.0/env/lib/python3.7/site-packages (from requests<3,>=2.21.0->tensorboard<3,>=2.3.0->tensorflow_gpu==2.3.0+computecanada) (1.26.8+computecanada)
Requirement already satisfied: charset-normalizer~=2.0.0 in /localscratch/yinan.29154792.0/env/lib/python3.7/site-packages (from requests<3,>=2.21.0->tensorboard<3,>=2.3.0->tensorflow_gpu==2.3.0+computecanada) (2.0.12+computecanada)
Requirement already satisfied: certifi>=2017.4.17 in /cvmfs/soft.computecanada.ca/easybuild/software/2017/Core/scipy-stack/2019a/lib/python3.7/site-packages (from requests<3,>=2.21.0->tensorboard<3,>=2.3.0->tensorflow_gpu==2.3.0+computecanada) (2018.11.29)
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/oauthlib-3.1.1+computecanada-py2.py3-none-any.whl
Installing collected packages: pyasn1, zipp, rsa, pyasn1-modules, oauthlib, cachetools, requests-oauthlib, importlib-metadata, google-auth, werkzeug, tensorboard-plugin-wit, tensorboard-data-server, markdown, grpcio, google-auth-oauthlib, absl-py, wrapt, tensorflow-estimator, tensorboard, scipy, opt-einsum, keras-preprocessing, h5py, google-pasta, gast, astunparse, tensorflow-gpu
  Attempting uninstall: pyasn1
    Found existing installation: pyasn1 0.4.3
    Not uninstalling pyasn1 at /cvmfs/soft.computecanada.ca/easybuild/software/2017/Core/scipy-stack/2019a/lib/python3.7/site-packages, outside environment /localscratch/yinan.29154792.0/env
    Can't uninstall 'pyasn1'. No files were found to uninstall.
  Attempting uninstall: zipp
    Found existing installation: zipp 0.3.3
    Not uninstalling zipp at /cvmfs/soft.computecanada.ca/easybuild/software/2017/Core/scipy-stack/2019a/lib/python3.7/site-packages, outside environment /localscratch/yinan.29154792.0/env
    Can't uninstall 'zipp'. No files were found to uninstall.
  Attempting uninstall: importlib-metadata
    Found existing installation: importlib-metadata 0.8
    Not uninstalling importlib-metadata at /cvmfs/soft.computecanada.ca/easybuild/software/2017/Core/scipy-stack/2019a/lib/python3.7/site-packages, outside environment /localscratch/yinan.29154792.0/env
    Can't uninstall 'importlib-metadata'. No files were found to uninstall.
  Attempting uninstall: scipy
    Found existing installation: scipy 1.2.0
    Not uninstalling scipy at /cvmfs/soft.computecanada.ca/easybuild/software/2017/Core/scipy-stack/2019a/lib/python3.7/site-packages, outside environment /localscratch/yinan.29154792.0/env
    Can't uninstall 'scipy'. No files were found to uninstall.
Successfully installed absl-py-1.0.0+computecanada astunparse-1.6.3+computecanada cachetools-4.2.4+computecanada gast-0.3.3+computecanada google-auth-2.3.3+computecanada google-auth-oauthlib-0.4.6+computecanada google-pasta-0.2.0+computecanada grpcio-1.38.0+computecanada h5py-2.10.0+computecanada importlib-metadata-4.10.1+computecanada keras-preprocessing-1.1.2+computecanada markdown-3.3.6+computecanada oauthlib-3.1.1+computecanada opt-einsum-3.3.0+computecanada pyasn1-0.4.8+computecanada pyasn1-modules-0.2.8+computecanada requests-oauthlib-1.3.0+computecanada rsa-4.8+computecanada scipy-1.4.1+computecanada tensorboard-2.8.0+computecanada tensorboard-data-server-0.6.1+computecanada tensorboard-plugin-wit-1.8.0+computecanada tensorflow-estimator-2.3.0+computecanada tensorflow-gpu-2.3.0+computecanada werkzeug-2.0.3+computecanada wrapt-1.11.2+computecanada zipp-3.7.0+computecanada
Looking in links: /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/nix/avx2, /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/nix/generic, /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/keras-2.8.0+computecanada-py2.py3-none-any.whl
Installing collected packages: Keras
Successfully installed Keras-2.8.0+computecanada
Looking in links: /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/nix/avx2, /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/nix/generic, /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/urllib3-1.26.7+computecanada-py2.py3-none-any.whl
Installing collected packages: urllib3
  Attempting uninstall: urllib3
    Found existing installation: urllib3 1.26.8+computecanada
    Uninstalling urllib3-1.26.8+computecanada:
      Successfully uninstalled urllib3-1.26.8+computecanada
Successfully installed urllib3-1.26.7+computecanada
Looking in links: /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/nix/avx2, /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/nix/generic, /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/nltk-3.7+computecanada-py3-none-any.whl
Requirement already satisfied: tqdm in /localscratch/yinan.29154792.0/env/lib/python3.7/site-packages (from nltk) (4.63.0+computecanada)
Requirement already satisfied: click in /localscratch/yinan.29154792.0/env/lib/python3.7/site-packages (from nltk) (8.0.4+computecanada)
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/nltk-3.6.5+computecanada-py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/nltk-3.6.3+computecanada-py3-none-any.whl
Requirement already satisfied: regex in /localscratch/yinan.29154792.0/env/lib/python3.7/site-packages (from nltk) (2020.11.13+computecanada)
Requirement already satisfied: joblib in /localscratch/yinan.29154792.0/env/lib/python3.7/site-packages (from nltk) (1.1.0+computecanada)
Requirement already satisfied: importlib-metadata in /localscratch/yinan.29154792.0/env/lib/python3.7/site-packages (from click->nltk) (4.10.1+computecanada)
Requirement already satisfied: zipp>=0.5 in /localscratch/yinan.29154792.0/env/lib/python3.7/site-packages (from importlib-metadata->click->nltk) (3.7.0+computecanada)
Requirement already satisfied: typing-extensions>=3.6.4 in /localscratch/yinan.29154792.0/env/lib/python3.7/site-packages (from importlib-metadata->click->nltk) (4.0.1+computecanada)
Installing collected packages: nltk
Successfully installed nltk-3.6.3+computecanada
Looking in links: /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/nix/avx2, /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/nix/generic, /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/scikit_learn-0.22.1+computecanada-cp37-cp37m-linux_x86_64.whl
Requirement already satisfied: joblib>=0.11 in /localscratch/yinan.29154792.0/env/lib/python3.7/site-packages (from scikit-learn==0.22.1) (1.1.0+computecanada)
Requirement already satisfied: scipy>=0.17.0 in /localscratch/yinan.29154792.0/env/lib/python3.7/site-packages (from scikit-learn==0.22.1) (1.4.1+computecanada)
Requirement already satisfied: numpy>=1.11.0 in /cvmfs/soft.computecanada.ca/easybuild/software/2017/Core/scipy-stack/2019a/lib/python3.7/site-packages (from scikit-learn==0.22.1) (1.16.0)
Installing collected packages: scikit-learn
Successfully installed scikit-learn-0.22.1+computecanada
Looking in links: /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/nix/avx2, /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/nix/generic, /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic
Requirement already satisfied: tokenizers==0.5.2 in /localscratch/yinan.29154792.0/env/lib/python3.7/site-packages (0.5.2+computecanada)
wandb: Appending key for api.wandb.ai to your netrc file: /home/yinan/.netrc
Starting Task
2022-03-17 18:39:38.182747: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1
[nltk_data] Downloading package stopwords to /home/yinan/nltk_data...
[nltk_data]   Package stopwords is already up-to-date!
[nltk_data] Downloading package wordnet to /home/yinan/nltk_data...
[nltk_data]   Package wordnet is already up-to-date!
wandb: Currently logged in as: yinanazhou (use `wandb login --relogin` to force relogin)
wandb: wandb version 0.12.11 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
2022-03-17 18:39:52.247819: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1
wandb: Tracking run with wandb version 0.12.5
wandb: Syncing run peach-leaf-2
wandb: ⭐️ View project at https://wandb.ai/yinanazhou/xl_512_bs_8_lr_1e06_es_5_lc_False_nr_True_sr_False_stem_False_lemma_True_repeat_1_fold_1
wandb: 🚀 View run at https://wandb.ai/yinanazhou/xl_512_bs_8_lr_1e06_es_5_lc_False_nr_True_sr_False_stem_False_lemma_True_repeat_1_fold_1/runs/3q3e1uvn
wandb: Run data is saved locally in /project/6002780/yinan/Thesis_MER_Lyrics/lyric-emotion/wandb/run-20220317_183950-3q3e1uvn
wandb: Run `wandb offline` to turn off syncing.
wandb: Network error (ReadTimeout), entering retry loop.

Validation loss decreased (inf --> 1.433368).  Saving model ...
Validation loss decreased (1.433368 --> 1.413197).  Saving model ...
Validation loss decreased (1.413197 --> 1.396222).  Saving model ...
Validation loss decreased (1.396222 --> 1.382296).  Saving model ...
Validation loss decreased (1.382296 --> 1.371596).  Saving model ...
Validation loss decreased (1.371596 --> 1.362711).  Saving model ...
Validation loss decreased (1.362711 --> 1.355298).  Saving model ...
Validation loss decreased (1.355298 --> 1.348129).  Saving model ...
Validation loss decreased (1.348129 --> 1.342084).  Saving model ...
Validation loss decreased (1.342084 --> 1.335481).  Saving model ...
Validation loss decreased (1.335481 --> 1.328674).  Saving model ...
Validation loss decreased (1.328674 --> 1.322592).  Saving model ...
Validation loss decreased (1.322592 --> 1.315222).  Saving model ...
Validation loss decreased (1.315222 --> 1.308229).  Saving model ...
Validation loss decreased (1.308229 --> 1.300365).  Saving model ...
Validation loss decreased (1.300365 --> 1.292780).  Saving model ...
Validation loss decreased (1.292780 --> 1.285575).  Saving model ...
Validation loss decreased (1.285575 --> 1.279976).  Saving model ...
Validation loss decreased (1.279976 --> 1.272279).  Saving model ...
Validation loss decreased (1.272279 --> 1.264902).  Saving model ...
Validation loss decreased (1.264902 --> 1.257846).  Saving model ...
Validation loss decreased (1.257846 --> 1.252269).  Saving model ...
Validation loss decreased (1.252269 --> 1.248094).  Saving model ...
Validation loss decreased (1.248094 --> 1.242558).  Saving model ...
Validation loss decreased (1.242558 --> 1.236885).  Saving model ...
Validation loss decreased (1.236885 --> 1.232027).  Saving model ...
Validation loss decreased (1.232027 --> 1.228192).  Saving model ...
Validation loss decreased (1.228192 --> 1.222529).  Saving model ...
Validation loss decreased (1.222529 --> 1.217336).  Saving model ...
Validation loss decreased (1.217336 --> 1.213628).  Saving model ...
Validation loss decreased (1.213628 --> 1.208543).  Saving model ...
Validation loss decreased (1.208543 --> 1.204009).  Saving model ...
Validation loss decreased (1.204009 --> 1.201104).  Saving model ...
Validation loss decreased (1.201104 --> 1.195931).  Saving model ...
Validation loss decreased (1.195931 --> 1.192949).  Saving model ...
Validation loss decreased (1.192949 --> 1.188185).  Saving model ...
Validation loss decreased (1.188185 --> 1.186684).  Saving model ...
Validation loss decreased (1.186684 --> 1.180882).  Saving model ...
Validation loss decreased (1.180882 --> 1.176323).  Saving model ...
Validation loss decreased (1.176323 --> 1.174274).  Saving model ...
Validation loss decreased (1.174274 --> 1.169751).  Saving model ...
Validation loss decreased (1.169751 --> 1.164272).  Saving model ...
Validation loss decreased (1.164272 --> 1.161786).  Saving model ...
Validation loss decreased (1.161786 --> 1.159083).  Saving model ...
Validation loss decreased (1.159083 --> 1.154588).  Saving model ...
Validation loss decreased (1.154588 --> 1.151675).  Saving model ...
Validation loss decreased (1.151675 --> 1.150207).  Saving model ...
Validation loss decreased (1.150207 --> 1.144981).  Saving model ...
Validation loss decreased (1.144981 --> 1.139035).  Saving model ...
Validation loss decreased (1.139035 --> 1.135946).  Saving model ...
Validation loss decreased (1.135946 --> 1.130567).  Saving model ...
Validation loss decreased (1.130567 --> 1.129001).  Saving model ...
Validation loss decreased (1.129001 --> 1.127043).  Saving model ...
Validation loss decreased (1.127043 --> 1.123315).  Saving model ...
Validation loss decreased (1.123315 --> 1.122343).  Saving model ...
Validation loss decreased (1.122343 --> 1.118605).  Saving model ...
Validation loss decreased (1.118605 --> 1.116219).  Saving model ...
Validation loss decreased (1.116219 --> 1.113009).  Saving model ...
Validation loss decreased (1.113009 --> 1.108880).  Saving model ...
Validation loss decreased (1.108880 --> 1.106966).  Saving model ...
Validation loss decreased (1.106966 --> 1.106184).  Saving model ...
Validation loss decreased (1.106184 --> 1.102608).  Saving model ...
Validation loss decreased (1.102608 --> 1.099298).  Saving model ...
Validation loss decreased (1.099298 --> 1.096980).  Saving model ...
Validation loss decreased (1.096980 --> 1.096959).  Saving model ...
Validation loss decreased (1.096959 --> 1.092171).  Saving model ...
Validation loss decreased (1.092171 --> 1.089939).  Saving model ...
Validation loss decreased (1.089939 --> 1.089407).  Saving model ...
Validation loss decreased (1.089407 --> 1.086206).  Saving model ...
EarlyStopping counter: 1 out of 5.0
Validation loss decreased (1.086206 --> 1.082880).  Saving model ...
Validation loss decreased (1.082880 --> 1.076103).  Saving model ...
Validation loss decreased (1.076103 --> 1.075812).  Saving model ...
Validation loss decreased (1.075812 --> 1.073970).  Saving model ...
Validation loss decreased (1.073970 --> 1.072363).  Saving model ...
Validation loss decreased (1.072363 --> 1.071560).  Saving model ...
Validation loss decreased (1.071560 --> 1.066718).  Saving model ...
Validation loss decreased (1.066718 --> 1.065496).  Saving model ...
EarlyStopping counter: 1 out of 5.0
Validation loss decreased (1.065496 --> 1.061344).  Saving model ...
EarlyStopping counter: 1 out of 5.0
EarlyStopping counter: 2 out of 5.0
Validation loss decreased (1.061344 --> 1.061072).  Saving model ...
Validation loss decreased (1.061072 --> 1.059627).  Saving model ...
Validation loss decreased (1.059627 --> 1.052267).  Saving model ...
Validation loss decreased (1.052267 --> 1.051768).  Saving model ...
Validation loss decreased (1.051768 --> 1.051181).  Saving model ...
EarlyStopping counter: 1 out of 5.0
EarlyStopping counter: 2 out of 5.0
EarlyStopping counter: 3 out of 5.0
Validation loss decreased (1.051181 --> 1.050121).  Saving model ...
Validation loss decreased (1.050121 --> 1.048421).  Saving model ...
Validation loss decreased (1.048421 --> 1.044520).  Saving model ...
EarlyStopping counter: 1 out of 5.0
EarlyStopping counter: 2 out of 5.0
Validation loss decreased (1.044520 --> 1.043683).  Saving model ...
EarlyStopping counter: 1 out of 5.0
Validation loss decreased (1.043683 --> 1.040988).  Saving model ...
Validation loss decreased (1.040988 --> 1.040930).  Saving model ...
EarlyStopping counter: 1 out of 5.0
Validation loss decreased (1.040930 --> 1.040513).  Saving model ...
EarlyStopping counter: 1 out of 5.0
Validation loss decreased (1.040513 --> 1.037540).  Saving model ...
Validation loss decreased (1.037540 --> 1.034776).  Saving model ...
EarlyStopping counter: 1 out of 5.0
EarlyStopping counter: 2 out of 5.0
Validation loss decreased (1.034776 --> 1.032693).  Saving model ...
Validation loss decreased (1.032693 --> 1.032438).  Saving model ...
Validation loss decreased (1.032438 --> 1.031362).  Saving model ...
Validation loss decreased (1.031362 --> 1.029571).  Saving model ...
EarlyStopping counter: 1 out of 5.0
EarlyStopping counter: 2 out of 5.0
EarlyStopping counter: 3 out of 5.0
EarlyStopping counter: 4 out of 5.0
EarlyStopping counter: 5 out of 5.0
/localscratch/yinan.29154792.0/env/lib/python3.7/site-packages/torch/nn/functional.py:1794: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.
  warnings.warn("nn.functional.tanh is deprecated. Use torch.tanh instead.")
/localscratch/yinan.29154792.0/env/lib/python3.7/site-packages/transformers/optimization.py:155: UserWarning: This overload of add_ is deprecated:
	add_(Number alpha, Tensor other)
Consider using one of the following signatures instead:
	add_(Tensor other, *, Number alpha) (Triggered internally at  ../torch/csrc/utils/python_arg_parser.cpp:1025.)
  exp_avg.mul_(beta1).add_(1.0 - beta1, grad)
wandb: Waiting for W&B process to finish, PID 246317... (success).
wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: \ 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: | 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: / 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: \ 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: | 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: / 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: \ 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: | 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: / 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb:                                                                                
wandb: Run history:
wandb:     e_F1 ▁▂▃▄▄▅▅▅▅▅▆▆▆▆▆▆▆▇▇▇▇▇▇▇▇▇▇▇████████████
wandb:   e_loss █▇▇▆▆▆▅▅▅▄▄▄▄▄▃▃▃▃▃▃▂▂▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁
wandb:     t_F1 ▁▁▃▃▃▄▄▄▄▅▅▅▅▆▆▆▆▆▆▆▆▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇█▇█
wandb:   t_loss ██▇▇▇▇▆▆▆▅▅▅▅▅▄▄▄▄▃▄▃▃▃▃▃▃▂▂▂▂▂▂▂▂▂▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:     e_F1 58.26858
wandb:   e_loss 1.03396
wandb:     t_F1 70.49897
wandb:   t_loss 0.785
wandb: 
wandb: Synced 4 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Synced peach-leaf-2: https://wandb.ai/yinanazhou/xl_512_bs_8_lr_1e06_es_5_lc_False_nr_True_sr_False_stem_False_lemma_True_repeat_1_fold_1/runs/3q3e1uvn
wandb: Find logs at: ./wandb/run-20220317_183950-3q3e1uvn/logs/debug.log
wandb: 

wandb: wandb version 0.12.11 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
2022-03-17 19:54:11.627925: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1
wandb: Tracking run with wandb version 0.12.5
wandb: Syncing run major-wind-2
wandb: ⭐️ View project at https://wandb.ai/yinanazhou/xl_512_bs_8_lr_1e06_es_5_lc_False_nr_True_sr_False_stem_False_lemma_True_repeat_1_fold_2
wandb: 🚀 View run at https://wandb.ai/yinanazhou/xl_512_bs_8_lr_1e06_es_5_lc_False_nr_True_sr_False_stem_False_lemma_True_repeat_1_fold_2/runs/34zs0sl4
wandb: Run data is saved locally in /project/6002780/yinan/Thesis_MER_Lyrics/lyric-emotion/wandb/run-20220317_195408-34zs0sl4
wandb: Run `wandb offline` to turn off syncing.

Validation loss decreased (inf --> 1.419408).  Saving model ...
Validation loss decreased (1.419408 --> 1.405914).  Saving model ...
Validation loss decreased (1.405914 --> 1.396337).  Saving model ...
Validation loss decreased (1.396337 --> 1.389151).  Saving model ...
Validation loss decreased (1.389151 --> 1.382890).  Saving model ...
Validation loss decreased (1.382890 --> 1.377436).  Saving model ...
Validation loss decreased (1.377436 --> 1.372975).  Saving model ...
Validation loss decreased (1.372975 --> 1.368710).  Saving model ...
Validation loss decreased (1.368710 --> 1.364368).  Saving model ...
Validation loss decreased (1.364368 --> 1.360282).  Saving model ...
Validation loss decreased (1.360282 --> 1.356018).  Saving model ...
Validation loss decreased (1.356018 --> 1.351978).  Saving model ...
Validation loss decreased (1.351978 --> 1.347913).  Saving model ...
Validation loss decreased (1.347913 --> 1.343479).  Saving model ...
Validation loss decreased (1.343479 --> 1.339232).  Saving model ...
Validation loss decreased (1.339232 --> 1.334836).  Saving model ...
Validation loss decreased (1.334836 --> 1.330024).  Saving model ...
Validation loss decreased (1.330024 --> 1.324886).  Saving model ...
Validation loss decreased (1.324886 --> 1.319697).  Saving model ...
Validation loss decreased (1.319697 --> 1.314302).  Saving model ...
Validation loss decreased (1.314302 --> 1.309049).  Saving model ...
Validation loss decreased (1.309049 --> 1.303457).  Saving model ...
Validation loss decreased (1.303457 --> 1.297274).  Saving model ...
Validation loss decreased (1.297274 --> 1.290758).  Saving model ...
Validation loss decreased (1.290758 --> 1.284423).  Saving model ...
Validation loss decreased (1.284423 --> 1.276763).  Saving model ...
Validation loss decreased (1.276763 --> 1.268545).  Saving model ...
Validation loss decreased (1.268545 --> 1.260375).  Saving model ...
Validation loss decreased (1.260375 --> 1.252082).  Saving model ...
Validation loss decreased (1.252082 --> 1.244304).  Saving model ...
Validation loss decreased (1.244304 --> 1.234481).  Saving model ...
Validation loss decreased (1.234481 --> 1.224276).  Saving model ...
Validation loss decreased (1.224276 --> 1.215749).  Saving model ...
Validation loss decreased (1.215749 --> 1.205685).  Saving model ...
Validation loss decreased (1.205685 --> 1.196449).  Saving model ...
Validation loss decreased (1.196449 --> 1.186990).  Saving model ...
Validation loss decreased (1.186990 --> 1.178393).  Saving model ...
Validation loss decreased (1.178393 --> 1.170930).  Saving model ...
Validation loss decreased (1.170930 --> 1.164225).  Saving model ...
Validation loss decreased (1.164225 --> 1.157578).  Saving model ...
Validation loss decreased (1.157578 --> 1.150798).  Saving model ...
Validation loss decreased (1.150798 --> 1.146367).  Saving model ...
Validation loss decreased (1.146367 --> 1.140737).  Saving model ...
Validation loss decreased (1.140737 --> 1.132675).  Saving model ...
Validation loss decreased (1.132675 --> 1.126269).  Saving model ...
Validation loss decreased (1.126269 --> 1.119831).  Saving model ...
Validation loss decreased (1.119831 --> 1.115454).  Saving model ...
Validation loss decreased (1.115454 --> 1.109938).  Saving model ...
Validation loss decreased (1.109938 --> 1.104767).  Saving model ...
Validation loss decreased (1.104767 --> 1.098465).  Saving model ...
Validation loss decreased (1.098465 --> 1.093382).  Saving model ...
Validation loss decreased (1.093382 --> 1.088368).  Saving model ...
Validation loss decreased (1.088368 --> 1.083583).  Saving model ...
Validation loss decreased (1.083583 --> 1.077369).  Saving model ...
Validation loss decreased (1.077369 --> 1.073100).  Saving model ...
Validation loss decreased (1.073100 --> 1.067484).  Saving model ...
Validation loss decreased (1.067484 --> 1.061517).  Saving model ...
Validation loss decreased (1.061517 --> 1.057074).  Saving model ...
Validation loss decreased (1.057074 --> 1.052844).  Saving model ...
Validation loss decreased (1.052844 --> 1.048231).  Saving model ...
Validation loss decreased (1.048231 --> 1.041997).  Saving model ...
Validation loss decreased (1.041997 --> 1.038465).  Saving model ...
Validation loss decreased (1.038465 --> 1.034266).  Saving model ...
Validation loss decreased (1.034266 --> 1.030338).  Saving model ...
Validation loss decreased (1.030338 --> 1.026282).  Saving model ...
Validation loss decreased (1.026282 --> 1.021314).  Saving model ...
Validation loss decreased (1.021314 --> 1.019263).  Saving model ...
Validation loss decreased (1.019263 --> 1.014335).  Saving model ...
Validation loss decreased (1.014335 --> 1.010346).  Saving model ...
Validation loss decreased (1.010346 --> 1.007121).  Saving model ...
Validation loss decreased (1.007121 --> 1.003071).  Saving model ...
Validation loss decreased (1.003071 --> 1.001405).  Saving model ...
Validation loss decreased (1.001405 --> 0.997675).  Saving model ...
Validation loss decreased (0.997675 --> 0.994536).  Saving model ...
Validation loss decreased (0.994536 --> 0.991440).  Saving model ...
Validation loss decreased (0.991440 --> 0.988743).  Saving model ...
Validation loss decreased (0.988743 --> 0.984726).  Saving model ...
Validation loss decreased (0.984726 --> 0.982060).  Saving model ...
Validation loss decreased (0.982060 --> 0.980487).  Saving model ...
Validation loss decreased (0.980487 --> 0.976594).  Saving model ...
Validation loss decreased (0.976594 --> 0.975576).  Saving model ...
Validation loss decreased (0.975576 --> 0.973367).  Saving model ...
Validation loss decreased (0.973367 --> 0.970540).  Saving model ...
Validation loss decreased (0.970540 --> 0.968397).  Saving model ...
Validation loss decreased (0.968397 --> 0.967296).  Saving model ...
Validation loss decreased (0.967296 --> 0.966051).  Saving model ...
Validation loss decreased (0.966051 --> 0.964455).  Saving model ...
Validation loss decreased (0.964455 --> 0.962361).  Saving model ...
Validation loss decreased (0.962361 --> 0.961530).  Saving model ...
Validation loss decreased (0.961530 --> 0.959680).  Saving model ...
Validation loss decreased (0.959680 --> 0.958404).  Saving model ...
Validation loss decreased (0.958404 --> 0.956941).  Saving model ...
Validation loss decreased (0.956941 --> 0.955251).  Saving model ...
Validation loss decreased (0.955251 --> 0.953330).  Saving model ...
Validation loss decreased (0.953330 --> 0.951402).  Saving model ...
Validation loss decreased (0.951402 --> 0.948643).  Saving model ...
Validation loss decreased (0.948643 --> 0.946785).  Saving model ...
Validation loss decreased (0.946785 --> 0.945384).  Saving model ...
Validation loss decreased (0.945384 --> 0.943781).  Saving model ...
Validation loss decreased (0.943781 --> 0.942291).  Saving model ...
Validation loss decreased (0.942291 --> 0.941011).  Saving model ...
Validation loss decreased (0.941011 --> 0.939565).  Saving model ...
Validation loss decreased (0.939565 --> 0.938173).  Saving model ...
Validation loss decreased (0.938173 --> 0.936658).  Saving model ...
Validation loss decreased (0.936658 --> 0.935693).  Saving model ...
EarlyStopping counter: 1 out of 5.0
EarlyStopping counter: 2 out of 5.0
Validation loss decreased (0.935693 --> 0.933234).  Saving model ...
Validation loss decreased (0.933234 --> 0.932880).  Saving model ...
Validation loss decreased (0.932880 --> 0.932711).  Saving model ...
Validation loss decreased (0.932711 --> 0.932011).  Saving model ...
Validation loss decreased (0.932011 --> 0.930247).  Saving model ...
EarlyStopping counter: 1 out of 5.0
Validation loss decreased (0.930247 --> 0.929712).  Saving model ...
Validation loss decreased (0.929712 --> 0.928804).  Saving model ...
Validation loss decreased (0.928804 --> 0.928546).  Saving model ...
EarlyStopping counter: 1 out of 5.0
Validation loss decreased (0.928546 --> 0.927510).  Saving model ...
EarlyStopping counter: 1 out of 5.0
EarlyStopping counter: 2 out of 5.0
Validation loss decreased (0.927510 --> 0.926594).  Saving model ...
EarlyStopping counter: 1 out of 5.0
EarlyStopping counter: 2 out of 5.0
EarlyStopping counter: 3 out of 5.0
EarlyStopping counter: 4 out of 5.0
EarlyStopping counter: 5 out of 5.0
/localscratch/yinan.29154792.0/env/lib/python3.7/site-packages/torch/nn/functional.py:1794: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.
  warnings.warn("nn.functional.tanh is deprecated. Use torch.tanh instead.")
wandb: Waiting for W&B process to finish, PID 250324... (success).
wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: \ 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: | 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: / 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: \ 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: | 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: / 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb:                                                                                
wandb: Run history:
wandb:     e_F1 ▁▂▃▄▄▅▅▆▆▆▆▆▇▇▇▇▇▇▇▇▇▇▇█▇███████████████
wandb:   e_loss ██▇▇▇▇▇▆▆▆▅▅▄▄▄▄▃▃▃▃▂▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁
wandb:     t_F1 ▁▁▂▂▂▃▃▃▄▃▅▄▄▅▅▆▅▅▆▆▆▆▆▇▇▇▇▇▇█▇█████████
wandb:   t_loss ██▇▇▇▇▇▇▇▇▆▆▆▅▅▅▅▅▄▄▄▄▄▃▃▃▃▃▃▂▂▂▂▂▂▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:     e_F1 60.56414
wandb:   e_loss 0.9276
wandb:     t_F1 70.94424
wandb:   t_loss 0.78946
wandb: 
wandb: Synced 4 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Synced major-wind-2: https://wandb.ai/yinanazhou/xl_512_bs_8_lr_1e06_es_5_lc_False_nr_True_sr_False_stem_False_lemma_True_repeat_1_fold_2/runs/34zs0sl4
wandb: Find logs at: ./wandb/run-20220317_195408-34zs0sl4/logs/debug.log
wandb: 

wandb: wandb version 0.12.11 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
2022-03-17 21:13:00.899064: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1
wandb: Tracking run with wandb version 0.12.5
wandb: Syncing run faithful-shape-2
wandb: ⭐️ View project at https://wandb.ai/yinanazhou/xl_512_bs_8_lr_1e06_es_5_lc_False_nr_True_sr_False_stem_False_lemma_True_repeat_2_fold_1
wandb: 🚀 View run at https://wandb.ai/yinanazhou/xl_512_bs_8_lr_1e06_es_5_lc_False_nr_True_sr_False_stem_False_lemma_True_repeat_2_fold_1/runs/23aodpsu
wandb: Run data is saved locally in /project/6002780/yinan/Thesis_MER_Lyrics/lyric-emotion/wandb/run-20220317_211257-23aodpsu
wandb: Run `wandb offline` to turn off syncing.
wandb: Network error (ReadTimeout), entering retry loop.

Validation loss decreased (inf --> 1.426177).  Saving model ...
Validation loss decreased (1.426177 --> 1.405896).  Saving model ...
Validation loss decreased (1.405896 --> 1.390392).  Saving model ...
Validation loss decreased (1.390392 --> 1.379284).  Saving model ...
Validation loss decreased (1.379284 --> 1.370512).  Saving model ...
Validation loss decreased (1.370512 --> 1.363761).  Saving model ...
Validation loss decreased (1.363761 --> 1.357971).  Saving model ...
Validation loss decreased (1.357971 --> 1.352409).  Saving model ...
Validation loss decreased (1.352409 --> 1.347696).  Saving model ...
Validation loss decreased (1.347696 --> 1.342989).  Saving model ...
Validation loss decreased (1.342989 --> 1.338153).  Saving model ...
Validation loss decreased (1.338153 --> 1.332795).  Saving model ...
Validation loss decreased (1.332795 --> 1.327601).  Saving model ...
Validation loss decreased (1.327601 --> 1.322046).  Saving model ...
Validation loss decreased (1.322046 --> 1.316929).  Saving model ...
Validation loss decreased (1.316929 --> 1.310970).  Saving model ...
Validation loss decreased (1.310970 --> 1.305104).  Saving model ...
Validation loss decreased (1.305104 --> 1.298662).  Saving model ...
Validation loss decreased (1.298662 --> 1.292121).  Saving model ...
Validation loss decreased (1.292121 --> 1.284153).  Saving model ...
Validation loss decreased (1.284153 --> 1.277010).  Saving model ...
Validation loss decreased (1.277010 --> 1.269852).  Saving model ...
Validation loss decreased (1.269852 --> 1.260926).  Saving model ...
Validation loss decreased (1.260926 --> 1.250939).  Saving model ...
Validation loss decreased (1.250939 --> 1.242009).  Saving model ...
Validation loss decreased (1.242009 --> 1.233793).  Saving model ...
Validation loss decreased (1.233793 --> 1.226645).  Saving model ...
Validation loss decreased (1.226645 --> 1.218754).  Saving model ...
Validation loss decreased (1.218754 --> 1.210923).  Saving model ...
Validation loss decreased (1.210923 --> 1.205148).  Saving model ...
Validation loss decreased (1.205148 --> 1.196811).  Saving model ...
Validation loss decreased (1.196811 --> 1.190075).  Saving model ...
Validation loss decreased (1.190075 --> 1.182272).  Saving model ...
Validation loss decreased (1.182272 --> 1.176329).  Saving model ...
Validation loss decreased (1.176329 --> 1.170415).  Saving model ...
Validation loss decreased (1.170415 --> 1.163866).  Saving model ...
Validation loss decreased (1.163866 --> 1.158287).  Saving model ...
Validation loss decreased (1.158287 --> 1.153967).  Saving model ...
Validation loss decreased (1.153967 --> 1.149486).  Saving model ...
Validation loss decreased (1.149486 --> 1.144218).  Saving model ...
Validation loss decreased (1.144218 --> 1.138866).  Saving model ...
Validation loss decreased (1.138866 --> 1.133014).  Saving model ...
Validation loss decreased (1.133014 --> 1.125976).  Saving model ...
Validation loss decreased (1.125976 --> 1.120641).  Saving model ...
Validation loss decreased (1.120641 --> 1.113140).  Saving model ...
Validation loss decreased (1.113140 --> 1.108719).  Saving model ...
Validation loss decreased (1.108719 --> 1.104362).  Saving model ...
Validation loss decreased (1.104362 --> 1.099044).  Saving model ...
Validation loss decreased (1.099044 --> 1.096170).  Saving model ...
Validation loss decreased (1.096170 --> 1.091258).  Saving model ...
Validation loss decreased (1.091258 --> 1.087567).  Saving model ...
Validation loss decreased (1.087567 --> 1.081622).  Saving model ...
Validation loss decreased (1.081622 --> 1.077836).  Saving model ...
Validation loss decreased (1.077836 --> 1.074476).  Saving model ...
Validation loss decreased (1.074476 --> 1.071312).  Saving model ...
Validation loss decreased (1.071312 --> 1.065153).  Saving model ...
Validation loss decreased (1.065153 --> 1.061721).  Saving model ...
Validation loss decreased (1.061721 --> 1.057032).  Saving model ...
Validation loss decreased (1.057032 --> 1.052051).  Saving model ...
Validation loss decreased (1.052051 --> 1.049085).  Saving model ...
Validation loss decreased (1.049085 --> 1.046127).  Saving model ...
Validation loss decreased (1.046127 --> 1.042202).  Saving model ...
Validation loss decreased (1.042202 --> 1.039750).  Saving model ...
Validation loss decreased (1.039750 --> 1.036104).  Saving model ...
Validation loss decreased (1.036104 --> 1.031937).  Saving model ...
Validation loss decreased (1.031937 --> 1.029315).  Saving model ...
Validation loss decreased (1.029315 --> 1.025681).  Saving model ...
Validation loss decreased (1.025681 --> 1.021783).  Saving model ...
Validation loss decreased (1.021783 --> 1.018261).  Saving model ...
Validation loss decreased (1.018261 --> 1.017289).  Saving model ...
Validation loss decreased (1.017289 --> 1.015045).  Saving model ...
Validation loss decreased (1.015045 --> 1.011319).  Saving model ...
Validation loss decreased (1.011319 --> 1.008706).  Saving model ...
Validation loss decreased (1.008706 --> 1.004924).  Saving model ...
Validation loss decreased (1.004924 --> 1.002956).  Saving model ...
Validation loss decreased (1.002956 --> 1.002725).  Saving model ...
Validation loss decreased (1.002725 --> 0.999854).  Saving model ...
Validation loss decreased (0.999854 --> 0.997482).  Saving model ...
Validation loss decreased (0.997482 --> 0.995997).  Saving model ...
Validation loss decreased (0.995997 --> 0.995880).  Saving model ...
Validation loss decreased (0.995880 --> 0.993637).  Saving model ...
Validation loss decreased (0.993637 --> 0.991973).  Saving model ...
Validation loss decreased (0.991973 --> 0.988896).  Saving model ...
Validation loss decreased (0.988896 --> 0.984589).  Saving model ...
Validation loss decreased (0.984589 --> 0.982603).  Saving model ...
Validation loss decreased (0.982603 --> 0.982321).  Saving model ...
Validation loss decreased (0.982321 --> 0.981466).  Saving model ...
Validation loss decreased (0.981466 --> 0.979197).  Saving model ...
Validation loss decreased (0.979197 --> 0.978105).  Saving model ...
Validation loss decreased (0.978105 --> 0.975673).  Saving model ...
Validation loss decreased (0.975673 --> 0.973768).  Saving model ...
Validation loss decreased (0.973768 --> 0.972228).  Saving model ...
Validation loss decreased (0.972228 --> 0.970574).  Saving model ...
EarlyStopping counter: 1 out of 5.0
EarlyStopping counter: 2 out of 5.0
Validation loss decreased (0.970574 --> 0.969538).  Saving model ...
Validation loss decreased (0.969538 --> 0.968009).  Saving model ...
Validation loss decreased (0.968009 --> 0.967656).  Saving model ...
Validation loss decreased (0.967656 --> 0.966281).  Saving model ...
Validation loss decreased (0.966281 --> 0.963923).  Saving model ...
Validation loss decreased (0.963923 --> 0.963635).  Saving model ...
EarlyStopping counter: 1 out of 5.0
Validation loss decreased (0.963635 --> 0.961910).  Saving model ...
Validation loss decreased (0.961910 --> 0.959463).  Saving model ...
EarlyStopping counter: 1 out of 5.0
Validation loss decreased (0.959463 --> 0.957720).  Saving model ...
Validation loss decreased (0.957720 --> 0.957205).  Saving model ...
Validation loss decreased (0.957205 --> 0.955319).  Saving model ...
Validation loss decreased (0.955319 --> 0.954871).  Saving model ...
EarlyStopping counter: 1 out of 5.0
EarlyStopping counter: 2 out of 5.0
EarlyStopping counter: 3 out of 5.0
Validation loss decreased (0.954871 --> 0.954396).  Saving model ...
EarlyStopping counter: 1 out of 5.0
EarlyStopping counter: 2 out of 5.0
EarlyStopping counter: 3 out of 5.0
EarlyStopping counter: 4 out of 5.0
EarlyStopping counter: 5 out of 5.0
/localscratch/yinan.29154792.0/env/lib/python3.7/site-packages/torch/nn/functional.py:1794: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.
  warnings.warn("nn.functional.tanh is deprecated. Use torch.tanh instead.")
wandb: Waiting for W&B process to finish, PID 254550... (success).
wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: \ 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: | 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: / 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: \ 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: | 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: / 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: \ 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: | 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: / 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb:                                                                                
wandb: Run history:
wandb:     e_F1 ▁▂▄▅▅▅▅▅▆▇▇▇▇▇▇▇▇▇▇▇▇▇██████████████████
wandb:   e_loss █▇▇▇▇▆▆▆▅▅▅▄▄▄▄▃▃▃▃▃▂▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁
wandb:     t_F1 ▁▂▂▂▂▃▃▄▄▄▅▅▅▆▅▆▆▆▆▆▇▆▆▇▇▇▇▇▇▇▇▇▇▇▇▇█▇██
wandb:   t_loss █▇▇▇▇▇▆▆▆▆▅▅▅▅▅▄▄▄▄▄▃▃▃▃▃▃▂▃▂▂▂▂▂▂▂▂▁▁▁▁
wandb: 
wandb: Run summary:
wandb:     e_F1 58.32591
wandb:   e_loss 0.95495
wandb:     t_F1 74.65618
wandb:   t_loss 0.75163
wandb: 
wandb: Synced 4 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Synced faithful-shape-2: https://wandb.ai/yinanazhou/xl_512_bs_8_lr_1e06_es_5_lc_False_nr_True_sr_False_stem_False_lemma_True_repeat_2_fold_1/runs/23aodpsu
wandb: Find logs at: ./wandb/run-20220317_211257-23aodpsu/logs/debug.log
wandb: 

wandb: wandb version 0.12.11 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
2022-03-17 22:29:13.312035: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1
wandb: Tracking run with wandb version 0.12.5
wandb: Syncing run frosty-capybara-1
wandb: ⭐️ View project at https://wandb.ai/yinanazhou/xl_512_bs_8_lr_1e06_es_5_lc_False_nr_True_sr_False_stem_False_lemma_True_repeat_2_fold_2
wandb: 🚀 View run at https://wandb.ai/yinanazhou/xl_512_bs_8_lr_1e06_es_5_lc_False_nr_True_sr_False_stem_False_lemma_True_repeat_2_fold_2/runs/1lvbc0az
wandb: Run data is saved locally in /project/6002780/yinan/Thesis_MER_Lyrics/lyric-emotion/wandb/run-20220317_222910-1lvbc0az
wandb: Run `wandb offline` to turn off syncing.

Validation loss decreased (inf --> 1.427599).  Saving model ...
Validation loss decreased (1.427599 --> 1.412051).  Saving model ...
Validation loss decreased (1.412051 --> 1.399919).  Saving model ...
Validation loss decreased (1.399919 --> 1.389379).  Saving model ...
Validation loss decreased (1.389379 --> 1.380404).  Saving model ...
Validation loss decreased (1.380404 --> 1.373248).  Saving model ...
Validation loss decreased (1.373248 --> 1.366623).  Saving model ...
Validation loss decreased (1.366623 --> 1.359864).  Saving model ...
Validation loss decreased (1.359864 --> 1.353973).  Saving model ...
Validation loss decreased (1.353973 --> 1.348496).  Saving model ...
Validation loss decreased (1.348496 --> 1.343096).  Saving model ...
Validation loss decreased (1.343096 --> 1.337381).  Saving model ...
Validation loss decreased (1.337381 --> 1.332011).  Saving model ...
Validation loss decreased (1.332011 --> 1.326462).  Saving model ...
Validation loss decreased (1.326462 --> 1.320775).  Saving model ...
Validation loss decreased (1.320775 --> 1.314950).  Saving model ...
Validation loss decreased (1.314950 --> 1.308577).  Saving model ...
Validation loss decreased (1.308577 --> 1.303044).  Saving model ...
Validation loss decreased (1.303044 --> 1.297530).  Saving model ...
Validation loss decreased (1.297530 --> 1.291791).  Saving model ...
Validation loss decreased (1.291791 --> 1.284905).  Saving model ...
Validation loss decreased (1.284905 --> 1.276955).  Saving model ...
Validation loss decreased (1.276955 --> 1.269420).  Saving model ...
Validation loss decreased (1.269420 --> 1.261524).  Saving model ...
Validation loss decreased (1.261524 --> 1.254605).  Saving model ...
Validation loss decreased (1.254605 --> 1.246792).  Saving model ...
Validation loss decreased (1.246792 --> 1.239524).  Saving model ...
Validation loss decreased (1.239524 --> 1.232030).  Saving model ...
Validation loss decreased (1.232030 --> 1.224247).  Saving model ...
Validation loss decreased (1.224247 --> 1.217359).  Saving model ...
Validation loss decreased (1.217359 --> 1.209916).  Saving model ...
Validation loss decreased (1.209916 --> 1.203291).  Saving model ...
Validation loss decreased (1.203291 --> 1.195689).  Saving model ...
Validation loss decreased (1.195689 --> 1.188389).  Saving model ...
Validation loss decreased (1.188389 --> 1.182446).  Saving model ...
Validation loss decreased (1.182446 --> 1.176190).  Saving model ...
Validation loss decreased (1.176190 --> 1.170207).  Saving model ...
Validation loss decreased (1.170207 --> 1.163262).  Saving model ...
Validation loss decreased (1.163262 --> 1.158240).  Saving model ...
Validation loss decreased (1.158240 --> 1.152221).  Saving model ...
Validation loss decreased (1.152221 --> 1.145141).  Saving model ...
Validation loss decreased (1.145141 --> 1.141665).  Saving model ...
Validation loss decreased (1.141665 --> 1.134445).  Saving model ...
Validation loss decreased (1.134445 --> 1.128704).  Saving model ...
Validation loss decreased (1.128704 --> 1.124006).  Saving model ...
Validation loss decreased (1.124006 --> 1.118095).  Saving model ...
Validation loss decreased (1.118095 --> 1.113022).  Saving model ...
Validation loss decreased (1.113022 --> 1.107803).  Saving model ...
Validation loss decreased (1.107803 --> 1.101469).  Saving model ...
Validation loss decreased (1.101469 --> 1.096036).  Saving model ...
Validation loss decreased (1.096036 --> 1.090944).  Saving model ...
Validation loss decreased (1.090944 --> 1.086132).  Saving model ...
Validation loss decreased (1.086132 --> 1.081455).  Saving model ...
Validation loss decreased (1.081455 --> 1.075900).  Saving model ...
Validation loss decreased (1.075900 --> 1.071295).  Saving model ...
Validation loss decreased (1.071295 --> 1.066830).  Saving model ...
Validation loss decreased (1.066830 --> 1.064465).  Saving model ...
Validation loss decreased (1.064465 --> 1.059873).  Saving model ...
Validation loss decreased (1.059873 --> 1.055279).  Saving model ...
Validation loss decreased (1.055279 --> 1.049962).  Saving model ...
Validation loss decreased (1.049962 --> 1.047833).  Saving model ...
Validation loss decreased (1.047833 --> 1.045236).  Saving model ...
Validation loss decreased (1.045236 --> 1.039457).  Saving model ...
Validation loss decreased (1.039457 --> 1.037533).  Saving model ...
Validation loss decreased (1.037533 --> 1.034240).  Saving model ...
Validation loss decreased (1.034240 --> 1.030442).  Saving model ...
Validation loss decreased (1.030442 --> 1.027768).  Saving model ...
Validation loss decreased (1.027768 --> 1.022114).  Saving model ...
Validation loss decreased (1.022114 --> 1.019014).  Saving model ...
Validation loss decreased (1.019014 --> 1.016043).  Saving model ...
Validation loss decreased (1.016043 --> 1.013746).  Saving model ...
Validation loss decreased (1.013746 --> 1.009254).  Saving model ...
Validation loss decreased (1.009254 --> 1.006534).  Saving model ...
Validation loss decreased (1.006534 --> 1.004563).  Saving model ...
Validation loss decreased (1.004563 --> 1.001267).  Saving model ...
Validation loss decreased (1.001267 --> 0.997904).  Saving model ...
Validation loss decreased (0.997904 --> 0.994733).  Saving model ...
Validation loss decreased (0.994733 --> 0.991441).  Saving model ...
Validation loss decreased (0.991441 --> 0.987964).  Saving model ...
Validation loss decreased (0.987964 --> 0.985996).  Saving model ...
Validation loss decreased (0.985996 --> 0.984881).  Saving model ...
Validation loss decreased (0.984881 --> 0.980067).  Saving model ...
Validation loss decreased (0.980067 --> 0.979921).  Saving model ...
Validation loss decreased (0.979921 --> 0.978033).  Saving model ...
Validation loss decreased (0.978033 --> 0.976287).  Saving model ...
Validation loss decreased (0.976287 --> 0.974948).  Saving model ...
Validation loss decreased (0.974948 --> 0.972266).  Saving model ...
Validation loss decreased (0.972266 --> 0.969474).  Saving model ...
Validation loss decreased (0.969474 --> 0.967245).  Saving model ...
Validation loss decreased (0.967245 --> 0.965300).  Saving model ...
Validation loss decreased (0.965300 --> 0.963261).  Saving model ...
Validation loss decreased (0.963261 --> 0.962612).  Saving model ...
Validation loss decreased (0.962612 --> 0.958452).  Saving model ...
Validation loss decreased (0.958452 --> 0.956715).  Saving model ...
Validation loss decreased (0.956715 --> 0.952775).  Saving model ...
Validation loss decreased (0.952775 --> 0.952041).  Saving model ...
Validation loss decreased (0.952041 --> 0.950293).  Saving model ...
Validation loss decreased (0.950293 --> 0.949236).  Saving model ...
Validation loss decreased (0.949236 --> 0.948310).  Saving model ...
Validation loss decreased (0.948310 --> 0.946431).  Saving model ...
Validation loss decreased (0.946431 --> 0.945545).  Saving model ...
Validation loss decreased (0.945545 --> 0.944616).  Saving model ...
EarlyStopping counter: 1 out of 5.0
Validation loss decreased (0.944616 --> 0.943431).  Saving model ...
Validation loss decreased (0.943431 --> 0.942612).  Saving model ...
Validation loss decreased (0.942612 --> 0.941139).  Saving model ...
Validation loss decreased (0.941139 --> 0.939594).  Saving model ...
EarlyStopping counter: 1 out of 5.0
EarlyStopping counter: 2 out of 5.0
Validation loss decreased (0.939594 --> 0.938240).  Saving model ...
Validation loss decreased (0.938240 --> 0.934222).  Saving model ...
Validation loss decreased (0.934222 --> 0.931490).  Saving model ...
EarlyStopping counter: 1 out of 5.0
EarlyStopping counter: 2 out of 5.0
EarlyStopping counter: 3 out of 5.0
EarlyStopping counter: 4 out of 5.0
Validation loss decreased (0.931490 --> 0.930222).  Saving model ...
Validation loss decreased (0.930222 --> 0.929965).  Saving model ...
EarlyStopping counter: 1 out of 5.0
EarlyStopping counter: 2 out of 5.0
EarlyStopping counter: 3 out of 5.0
Validation loss decreased (0.929965 --> 0.929849).  Saving model ...
Validation loss decreased (0.929849 --> 0.927433).  Saving model ...
EarlyStopping counter: 1 out of 5.0
EarlyStopping counter: 2 out of 5.0
EarlyStopping counter: 3 out of 5.0
EarlyStopping counter: 4 out of 5.0
EarlyStopping counter: 5 out of 5.0
/localscratch/yinan.29154792.0/env/lib/python3.7/site-packages/torch/nn/functional.py:1794: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.
  warnings.warn("nn.functional.tanh is deprecated. Use torch.tanh instead.")
wandb: Waiting for W&B process to finish, PID 258616... (success).
wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: \ 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: | 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: / 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: \ 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: | 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: / 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: \ 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: | 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: / 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb:                                                                                
wandb: Run history:
wandb:     e_F1 ▁▂▂▃▃▄▅▅▅▆▆▆▆▆▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇██████████
wandb:   e_loss ██▇▇▇▆▆▆▆▅▅▅▄▄▄▃▃▃▃▃▂▂▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁
wandb:     t_F1 ▁▂▂▂▂▃▃▄▄▄▅▅▅▅▆▆▆▆▆▇▆▆▆▇▇▇▇▇▇▇▇▇▇▇▇█████
wandb:   t_loss ███▇▇▇▇▆▆▆▅▆▅▅▅▅▄▄▄▄▄▃▃▃▃▃▃▃▂▂▂▂▂▂▂▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:     e_F1 61.30528
wandb:   e_loss 0.93069
wandb:     t_F1 70.44568
wandb:   t_loss 0.77601
wandb: 
wandb: Synced 4 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Synced frosty-capybara-1: https://wandb.ai/yinanazhou/xl_512_bs_8_lr_1e06_es_5_lc_False_nr_True_sr_False_stem_False_lemma_True_repeat_2_fold_2/runs/1lvbc0az
wandb: Find logs at: ./wandb/run-20220317_222910-1lvbc0az/logs/debug.log
wandb: 

wandb: wandb version 0.12.11 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
2022-03-17 23:51:57.778130: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1
wandb: Tracking run with wandb version 0.12.5
wandb: Syncing run peach-meadow-1
wandb: ⭐️ View project at https://wandb.ai/yinanazhou/xl_512_bs_8_lr_1e06_es_5_lc_False_nr_True_sr_False_stem_False_lemma_True_repeat_3_fold_1
wandb: 🚀 View run at https://wandb.ai/yinanazhou/xl_512_bs_8_lr_1e06_es_5_lc_False_nr_True_sr_False_stem_False_lemma_True_repeat_3_fold_1/runs/hpha7fzi
wandb: Run data is saved locally in /project/6002780/yinan/Thesis_MER_Lyrics/lyric-emotion/wandb/run-20220317_235154-hpha7fzi
wandb: Run `wandb offline` to turn off syncing.

Validation loss decreased (inf --> 1.443563).  Saving model ...
Validation loss decreased (1.443563 --> 1.417665).  Saving model ...
Validation loss decreased (1.417665 --> 1.397645).  Saving model ...
Validation loss decreased (1.397645 --> 1.383415).  Saving model ...
Validation loss decreased (1.383415 --> 1.373180).  Saving model ...
Validation loss decreased (1.373180 --> 1.365136).  Saving model ...
Validation loss decreased (1.365136 --> 1.358959).  Saving model ...
Validation loss decreased (1.358959 --> 1.353489).  Saving model ...
Validation loss decreased (1.353489 --> 1.348742).  Saving model ...
Validation loss decreased (1.348742 --> 1.343742).  Saving model ...
Validation loss decreased (1.343742 --> 1.339519).  Saving model ...
Validation loss decreased (1.339519 --> 1.334899).  Saving model ...
Validation loss decreased (1.334899 --> 1.330306).  Saving model ...
Validation loss decreased (1.330306 --> 1.325415).  Saving model ...
Validation loss decreased (1.325415 --> 1.320836).  Saving model ...
Validation loss decreased (1.320836 --> 1.315135).  Saving model ...
Validation loss decreased (1.315135 --> 1.310172).  Saving model ...
Validation loss decreased (1.310172 --> 1.305675).  Saving model ...
Validation loss decreased (1.305675 --> 1.299804).  Saving model ...
Validation loss decreased (1.299804 --> 1.294182).  Saving model ...
Validation loss decreased (1.294182 --> 1.287682).  Saving model ...
Validation loss decreased (1.287682 --> 1.282081).  Saving model ...
Validation loss decreased (1.282081 --> 1.276180).  Saving model ...
Validation loss decreased (1.276180 --> 1.269881).  Saving model ...
Validation loss decreased (1.269881 --> 1.263264).  Saving model ...
Validation loss decreased (1.263264 --> 1.257393).  Saving model ...
Validation loss decreased (1.257393 --> 1.250274).  Saving model ...
Validation loss decreased (1.250274 --> 1.244052).  Saving model ...
Validation loss decreased (1.244052 --> 1.235286).  Saving model ...
Validation loss decreased (1.235286 --> 1.227194).  Saving model ...
Validation loss decreased (1.227194 --> 1.219057).  Saving model ...
Validation loss decreased (1.219057 --> 1.213385).  Saving model ...
Validation loss decreased (1.213385 --> 1.202983).  Saving model ...
Validation loss decreased (1.202983 --> 1.194854).  Saving model ...
Validation loss decreased (1.194854 --> 1.185000).  Saving model ...
Validation loss decreased (1.185000 --> 1.179946).  Saving model ...
Validation loss decreased (1.179946 --> 1.174143).  Saving model ...
Validation loss decreased (1.174143 --> 1.166071).  Saving model ...
Validation loss decreased (1.166071 --> 1.160400).  Saving model ...
Validation loss decreased (1.160400 --> 1.154283).  Saving model ...
Validation loss decreased (1.154283 --> 1.147348).  Saving model ...
Validation loss decreased (1.147348 --> 1.142486).  Saving model ...
Validation loss decreased (1.142486 --> 1.134917).  Saving model ...
Validation loss decreased (1.134917 --> 1.129785).  Saving model ...
Validation loss decreased (1.129785 --> 1.124150).  Saving model ...
Validation loss decreased (1.124150 --> 1.119999).  Saving model ...
Validation loss decreased (1.119999 --> 1.115767).  Saving model ...
Validation loss decreased (1.115767 --> 1.111901).  Saving model ...
Validation loss decreased (1.111901 --> 1.110088).  Saving model ...
Validation loss decreased (1.110088 --> 1.105077).  Saving model ...
Validation loss decreased (1.105077 --> 1.102686).  Saving model ...
Validation loss decreased (1.102686 --> 1.095581).  Saving model ...
Validation loss decreased (1.095581 --> 1.091188).  Saving model ...
Validation loss decreased (1.091188 --> 1.087308).  Saving model ...
Validation loss decreased (1.087308 --> 1.081320).  Saving model ...
Validation loss decreased (1.081320 --> 1.077969).  Saving model ...
Validation loss decreased (1.077969 --> 1.075702).  Saving model ...
Validation loss decreased (1.075702 --> 1.075078).  Saving model ...
Validation loss decreased (1.075078 --> 1.071457).  Saving model ...
Validation loss decreased (1.071457 --> 1.070298).  Saving model ...
Validation loss decreased (1.070298 --> 1.066885).  Saving model ...
Validation loss decreased (1.066885 --> 1.063967).  Saving model ...
Validation loss decreased (1.063967 --> 1.058411).  Saving model ...
Validation loss decreased (1.058411 --> 1.056112).  Saving model ...
Validation loss decreased (1.056112 --> 1.054176).  Saving model ...
Validation loss decreased (1.054176 --> 1.050409).  Saving model ...
Validation loss decreased (1.050409 --> 1.049901).  Saving model ...
Validation loss decreased (1.049901 --> 1.045940).  Saving model ...
Validation loss decreased (1.045940 --> 1.043034).  Saving model ...
Validation loss decreased (1.043034 --> 1.037327).  Saving model ...
Validation loss decreased (1.037327 --> 1.034992).  Saving model ...
Validation loss decreased (1.034992 --> 1.031634).  Saving model ...
EarlyStopping counter: 1 out of 5.0
EarlyStopping counter: 2 out of 5.0
Validation loss decreased (1.031634 --> 1.028964).  Saving model ...
Validation loss decreased (1.028964 --> 1.025660).  Saving model ...
Validation loss decreased (1.025660 --> 1.022773).  Saving model ...
Validation loss decreased (1.022773 --> 1.022170).  Saving model ...
Validation loss decreased (1.022170 --> 1.017265).  Saving model ...
Validation loss decreased (1.017265 --> 1.013737).  Saving model ...
Validation loss decreased (1.013737 --> 1.013570).  Saving model ...
EarlyStopping counter: 1 out of 5.0
Validation loss decreased (1.013570 --> 1.010867).  Saving model ...
EarlyStopping counter: 1 out of 5.0
Validation loss decreased (1.010867 --> 1.008107).  Saving model ...
Validation loss decreased (1.008107 --> 1.005817).  Saving model ...
Validation loss decreased (1.005817 --> 1.004196).  Saving model ...
Validation loss decreased (1.004196 --> 1.003549).  Saving model ...
Validation loss decreased (1.003549 --> 1.000675).  Saving model ...
EarlyStopping counter: 1 out of 5.0
Validation loss decreased (1.000675 --> 0.997867).  Saving model ...
Validation loss decreased (0.997867 --> 0.992468).  Saving model ...
EarlyStopping counter: 1 out of 5.0
Validation loss decreased (0.992468 --> 0.990930).  Saving model ...
Validation loss decreased (0.990930 --> 0.987729).  Saving model ...
EarlyStopping counter: 1 out of 5.0
EarlyStopping counter: 2 out of 5.0
EarlyStopping counter: 3 out of 5.0
EarlyStopping counter: 4 out of 5.0
EarlyStopping counter: 5 out of 5.0
/localscratch/yinan.29154792.0/env/lib/python3.7/site-packages/torch/nn/functional.py:1794: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.
  warnings.warn("nn.functional.tanh is deprecated. Use torch.tanh instead.")
wandb: Waiting for W&B process to finish, PID 1243... (success).
wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: \ 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: | 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: / 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: \ 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: | 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: / 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: \ 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: | 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: / 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: \ 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: | 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: / 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: \ 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: | 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: / 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb:                                                                                
wandb: Run history:
wandb:     e_F1 ▁▂▃▃▄▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇▇▇▇▇▇█▇█████████████
wandb:   e_loss █▇▇▇▆▆▆▆▆▅▅▅▅▄▄▄▃▃▃▃▃▃▂▂▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁
wandb:     t_F1 ▁▂▂▂▃▃▃▄▄▄▅▄▅▅▅▅▆▆▆▆▆▆▇▆▆▇▇▇▇▇▇▇▇█▇█████
wandb:   t_loss ██▇▇▇▇▆▆▆▆▆▆▅▅▅▅▄▄▄▄▄▃▃▃▃▃▂▃▃▂▂▂▂▂▂▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:     e_F1 57.17795
wandb:   e_loss 0.98909
wandb:     t_F1 68.86338
wandb:   t_loss 0.82214
wandb: 
wandb: Synced 4 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Synced peach-meadow-1: https://wandb.ai/yinanazhou/xl_512_bs_8_lr_1e06_es_5_lc_False_nr_True_sr_False_stem_False_lemma_True_repeat_3_fold_1/runs/hpha7fzi
wandb: Find logs at: ./wandb/run-20220317_235154-hpha7fzi/logs/debug.log
wandb: 

wandb: wandb version 0.12.11 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
2022-03-18 00:54:10.814870: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1
wandb: Tracking run with wandb version 0.12.5
wandb: Syncing run fancy-firebrand-1
wandb: ⭐️ View project at https://wandb.ai/yinanazhou/xl_512_bs_8_lr_1e06_es_5_lc_False_nr_True_sr_False_stem_False_lemma_True_repeat_3_fold_2
wandb: 🚀 View run at https://wandb.ai/yinanazhou/xl_512_bs_8_lr_1e06_es_5_lc_False_nr_True_sr_False_stem_False_lemma_True_repeat_3_fold_2/runs/3kw6h0k4
wandb: Run data is saved locally in /project/6002780/yinan/Thesis_MER_Lyrics/lyric-emotion/wandb/run-20220318_005407-3kw6h0k4
wandb: Run `wandb offline` to turn off syncing.

Validation loss decreased (inf --> 1.464742).  Saving model ...
Validation loss decreased (1.464742 --> 1.438445).  Saving model ...
Validation loss decreased (1.438445 --> 1.417426).  Saving model ...
Validation loss decreased (1.417426 --> 1.399944).  Saving model ...
Validation loss decreased (1.399944 --> 1.387425).  Saving model ...
Validation loss decreased (1.387425 --> 1.377388).  Saving model ...
Validation loss decreased (1.377388 --> 1.369280).  Saving model ...
Validation loss decreased (1.369280 --> 1.363150).  Saving model ...
Validation loss decreased (1.363150 --> 1.357635).  Saving model ...
Validation loss decreased (1.357635 --> 1.352016).  Saving model ...
Validation loss decreased (1.352016 --> 1.347083).  Saving model ...
Validation loss decreased (1.347083 --> 1.341797).  Saving model ...
Validation loss decreased (1.341797 --> 1.336833).  Saving model ...
Validation loss decreased (1.336833 --> 1.332122).  Saving model ...
Validation loss decreased (1.332122 --> 1.326533).  Saving model ...
Validation loss decreased (1.326533 --> 1.321273).  Saving model ...
Validation loss decreased (1.321273 --> 1.315757).  Saving model ...
Validation loss decreased (1.315757 --> 1.309787).  Saving model ...
Validation loss decreased (1.309787 --> 1.305009).  Saving model ...
Validation loss decreased (1.305009 --> 1.298975).  Saving model ...
Validation loss decreased (1.298975 --> 1.292205).  Saving model ...
Validation loss decreased (1.292205 --> 1.286031).  Saving model ...
Validation loss decreased (1.286031 --> 1.280164).  Saving model ...
Validation loss decreased (1.280164 --> 1.273703).  Saving model ...
Validation loss decreased (1.273703 --> 1.267302).  Saving model ...
Validation loss decreased (1.267302 --> 1.259545).  Saving model ...
Validation loss decreased (1.259545 --> 1.252180).  Saving model ...
Validation loss decreased (1.252180 --> 1.246762).  Saving model ...
Validation loss decreased (1.246762 --> 1.239470).  Saving model ...
Validation loss decreased (1.239470 --> 1.233358).  Saving model ...
Validation loss decreased (1.233358 --> 1.227502).  Saving model ...
Validation loss decreased (1.227502 --> 1.219869).  Saving model ...
Validation loss decreased (1.219869 --> 1.210968).  Saving model ...
Validation loss decreased (1.210968 --> 1.203770).  Saving model ...
Validation loss decreased (1.203770 --> 1.197118).  Saving model ...
Validation loss decreased (1.197118 --> 1.192920).  Saving model ...
Validation loss decreased (1.192920 --> 1.186791).  Saving model ...
Validation loss decreased (1.186791 --> 1.179569).  Saving model ...
Validation loss decreased (1.179569 --> 1.173406).  Saving model ...
Validation loss decreased (1.173406 --> 1.167811).  Saving model ...
Validation loss decreased (1.167811 --> 1.164031).  Saving model ...
Validation loss decreased (1.164031 --> 1.159416).  Saving model ...
Validation loss decreased (1.159416 --> 1.153983).  Saving model ...
Validation loss decreased (1.153983 --> 1.147910).  Saving model ...
Validation loss decreased (1.147910 --> 1.143041).  Saving model ...
Validation loss decreased (1.143041 --> 1.136230).  Saving model ...
Validation loss decreased (1.136230 --> 1.131284).  Saving model ...
Validation loss decreased (1.131284 --> 1.126418).  Saving model ...
Validation loss decreased (1.126418 --> 1.121179).  Saving model ...
Validation loss decreased (1.121179 --> 1.115512).  Saving model ...
Validation loss decreased (1.115512 --> 1.109878).  Saving model ...
Validation loss decreased (1.109878 --> 1.105963).  Saving model ...
Validation loss decreased (1.105963 --> 1.102477).  Saving model ...
Validation loss decreased (1.102477 --> 1.095586).  Saving model ...
Validation loss decreased (1.095586 --> 1.092392).  Saving model ...
Validation loss decreased (1.092392 --> 1.086984).  Saving model ...
Validation loss decreased (1.086984 --> 1.082530).  Saving model ...
Validation loss decreased (1.082530 --> 1.077878).  Saving model ...
Validation loss decreased (1.077878 --> 1.072279).  Saving model ...
Validation loss decreased (1.072279 --> 1.069587).  Saving model ...
Validation loss decreased (1.069587 --> 1.065094).  Saving model ...
Validation loss decreased (1.065094 --> 1.060766).  Saving model ...
Validation loss decreased (1.060766 --> 1.058139).  Saving model ...
Validation loss decreased (1.058139 --> 1.054629).  Saving model ...
Validation loss decreased (1.054629 --> 1.051488).  Saving model ...
Validation loss decreased (1.051488 --> 1.047439).  Saving model ...
Validation loss decreased (1.047439 --> 1.044890).  Saving model ...
Validation loss decreased (1.044890 --> 1.041883).  Saving model ...
Validation loss decreased (1.041883 --> 1.037139).  Saving model ...
Validation loss decreased (1.037139 --> 1.032010).  Saving model ...
Validation loss decreased (1.032010 --> 1.029347).  Saving model ...
Validation loss decreased (1.029347 --> 1.024461).  Saving model ...
Validation loss decreased (1.024461 --> 1.021658).  Saving model ...
Validation loss decreased (1.021658 --> 1.020085).  Saving model ...
Validation loss decreased (1.020085 --> 1.019654).  Saving model ...
Validation loss decreased (1.019654 --> 1.014889).  Saving model ...
Validation loss decreased (1.014889 --> 1.013646).  Saving model ...
Validation loss decreased (1.013646 --> 1.010274).  Saving model ...
Validation loss decreased (1.010274 --> 1.006380).  Saving model ...
Validation loss decreased (1.006380 --> 1.001385).  Saving model ...
Validation loss decreased (1.001385 --> 0.999261).  Saving model ...
Validation loss decreased (0.999261 --> 0.997439).  Saving model ...
Validation loss decreased (0.997439 --> 0.992909).  Saving model ...
Validation loss decreased (0.992909 --> 0.990788).  Saving model ...
Validation loss decreased (0.990788 --> 0.986045).  Saving model ...
Validation loss decreased (0.986045 --> 0.984492).  Saving model ...
Validation loss decreased (0.984492 --> 0.982294).  Saving model ...
Validation loss decreased (0.982294 --> 0.979019).  Saving model ...
EarlyStopping counter: 1 out of 5.0
EarlyStopping counter: 2 out of 5.0
Validation loss decreased (0.979019 --> 0.975768).  Saving model ...
Validation loss decreased (0.975768 --> 0.971939).  Saving model ...
Validation loss decreased (0.971939 --> 0.969876).  Saving model ...
Validation loss decreased (0.969876 --> 0.966524).  Saving model ...
Validation loss decreased (0.966524 --> 0.964597).  Saving model ...
Validation loss decreased (0.964597 --> 0.962049).  Saving model ...
Validation loss decreased (0.962049 --> 0.960909).  Saving model ...
Validation loss decreased (0.960909 --> 0.957795).  Saving model ...
Validation loss decreased (0.957795 --> 0.956197).  Saving model ...
Validation loss decreased (0.956197 --> 0.954879).  Saving model ...
Validation loss decreased (0.954879 --> 0.951386).  Saving model ...
Validation loss decreased (0.951386 --> 0.950451).  Saving model ...
Validation loss decreased (0.950451 --> 0.948448).  Saving model ...
EarlyStopping counter: 1 out of 5.0
Validation loss decreased (0.948448 --> 0.947476).  Saving model ...
Validation loss decreased (0.947476 --> 0.946064).  Saving model ...
EarlyStopping counter: 1 out of 5.0
Validation loss decreased (0.946064 --> 0.943920).  Saving model ...
Validation loss decreased (0.943920 --> 0.942209).  Saving model ...
EarlyStopping counter: 1 out of 5.0
Validation loss decreased (0.942209 --> 0.941639).  Saving model ...
Validation loss decreased (0.941639 --> 0.939124).  Saving model ...
Validation loss decreased (0.939124 --> 0.937715).  Saving model ...
Validation loss decreased (0.937715 --> 0.937199).  Saving model ...
Validation loss decreased (0.937199 --> 0.936446).  Saving model ...
Validation loss decreased (0.936446 --> 0.934826).  Saving model ...
Validation loss decreased (0.934826 --> 0.933916).  Saving model ...
Validation loss decreased (0.933916 --> 0.933811).  Saving model ...
Validation loss decreased (0.933811 --> 0.933097).  Saving model ...
Validation loss decreased (0.933097 --> 0.932819).  Saving model ...
Validation loss decreased (0.932819 --> 0.932123).  Saving model ...
Validation loss decreased (0.932123 --> 0.931637).  Saving model ...
Validation loss decreased (0.931637 --> 0.931622).  Saving model ...
Validation loss decreased (0.931622 --> 0.931472).  Saving model ...
Validation loss decreased (0.931472 --> 0.930559).  Saving model ...
Validation loss decreased (0.930559 --> 0.928183).  Saving model ...
Validation loss decreased (0.928183 --> 0.927777).  Saving model ...
Validation loss decreased (0.927777 --> 0.927595).  Saving model ...
EarlyStopping counter: 1 out of 5.0
EarlyStopping counter: 2 out of 5.0
EarlyStopping counter: 3 out of 5.0
EarlyStopping counter: 4 out of 5.0
EarlyStopping counter: 5 out of 5.0
/localscratch/yinan.29154792.0/env/lib/python3.7/site-packages/torch/nn/functional.py:1794: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.
  warnings.warn("nn.functional.tanh is deprecated. Use torch.tanh instead.")
wandb: Waiting for W&B process to finish, PID 4640... (success).
wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: \ 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: | 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: / 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: \ 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: | 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: / 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: \ 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: | 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: / 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb:                                                                                
wandb: Run history:
wandb:     e_F1 ▁▁▃▄▄▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇▇▇▇▇▇█▇████████████
wandb:   e_loss █▇▇▇▇▆▆▆▅▅▅▄▄▄▄▃▃▃▃▃▃▂▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁
wandb:     t_F1 ▁▂▃▃▃▄▄▄▅▅▅▅▅▆▅▆▆▆▆▆▆▆▆▆▇▇▇▇▇█▇▇█████▇▇█
wandb:   t_loss ██▇▇▇▇▆▆▆▅▆▅▅▅▅▄▄▄▄▄▄▃▃▃▃▃▂▂▂▂▂▂▂▂▁▁▁▁▂▁
wandb: 
wandb: Run summary:
wandb:     e_F1 61.13871
wandb:   e_loss 0.92897
wandb:     t_F1 68.6578
wandb:   t_loss 0.80554
wandb: 
wandb: Synced 4 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Synced fancy-firebrand-1: https://wandb.ai/yinanazhou/xl_512_bs_8_lr_1e06_es_5_lc_False_nr_True_sr_False_stem_False_lemma_True_repeat_3_fold_2/runs/3kw6h0k4
wandb: Find logs at: ./wandb/run-20220318_005407-3kw6h0k4/logs/debug.log
wandb: 

wandb: wandb version 0.12.11 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
2022-03-18 02:20:04.945220: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1
wandb: Tracking run with wandb version 0.12.5
wandb: Syncing run feasible-frog-1
wandb: ⭐️ View project at https://wandb.ai/yinanazhou/xl_512_bs_8_lr_1e06_es_5_lc_False_nr_True_sr_False_stem_False_lemma_True_repeat_4_fold_1
wandb: 🚀 View run at https://wandb.ai/yinanazhou/xl_512_bs_8_lr_1e06_es_5_lc_False_nr_True_sr_False_stem_False_lemma_True_repeat_4_fold_1/runs/8pquzcsu
wandb: Run data is saved locally in /project/6002780/yinan/Thesis_MER_Lyrics/lyric-emotion/wandb/run-20220318_022001-8pquzcsu
wandb: Run `wandb offline` to turn off syncing.

Validation loss decreased (inf --> 1.525329).  Saving model ...
Validation loss decreased (1.525329 --> 1.471604).  Saving model ...
Validation loss decreased (1.471604 --> 1.429160).  Saving model ...
Validation loss decreased (1.429160 --> 1.398173).  Saving model ...
Validation loss decreased (1.398173 --> 1.376059).  Saving model ...
Validation loss decreased (1.376059 --> 1.361486).  Saving model ...
Validation loss decreased (1.361486 --> 1.351461).  Saving model ...
Validation loss decreased (1.351461 --> 1.344354).  Saving model ...
Validation loss decreased (1.344354 --> 1.337724).  Saving model ...
Validation loss decreased (1.337724 --> 1.332541).  Saving model ...
Validation loss decreased (1.332541 --> 1.327327).  Saving model ...
Validation loss decreased (1.327327 --> 1.322791).  Saving model ...
Validation loss decreased (1.322791 --> 1.317720).  Saving model ...
Validation loss decreased (1.317720 --> 1.312162).  Saving model ...
Validation loss decreased (1.312162 --> 1.307948).  Saving model ...
Validation loss decreased (1.307948 --> 1.302914).  Saving model ...
Validation loss decreased (1.302914 --> 1.296769).  Saving model ...
Validation loss decreased (1.296769 --> 1.291658).  Saving model ...
Validation loss decreased (1.291658 --> 1.284337).  Saving model ...
Validation loss decreased (1.284337 --> 1.279428).  Saving model ...
Validation loss decreased (1.279428 --> 1.273216).  Saving model ...
Validation loss decreased (1.273216 --> 1.265992).  Saving model ...
Validation loss decreased (1.265992 --> 1.260237).  Saving model ...
Validation loss decreased (1.260237 --> 1.255319).  Saving model ...
Validation loss decreased (1.255319 --> 1.249049).  Saving model ...
Validation loss decreased (1.249049 --> 1.242876).  Saving model ...
Validation loss decreased (1.242876 --> 1.237428).  Saving model ...
Validation loss decreased (1.237428 --> 1.232655).  Saving model ...
Validation loss decreased (1.232655 --> 1.227894).  Saving model ...
Validation loss decreased (1.227894 --> 1.222108).  Saving model ...
Validation loss decreased (1.222108 --> 1.216392).  Saving model ...
Validation loss decreased (1.216392 --> 1.210320).  Saving model ...
Validation loss decreased (1.210320 --> 1.206299).  Saving model ...
Validation loss decreased (1.206299 --> 1.201220).  Saving model ...
Validation loss decreased (1.201220 --> 1.195352).  Saving model ...
Validation loss decreased (1.195352 --> 1.190305).  Saving model ...
Validation loss decreased (1.190305 --> 1.186104).  Saving model ...
Validation loss decreased (1.186104 --> 1.179930).  Saving model ...
Validation loss decreased (1.179930 --> 1.174997).  Saving model ...
Validation loss decreased (1.174997 --> 1.170386).  Saving model ...
Validation loss decreased (1.170386 --> 1.164941).  Saving model ...
Validation loss decreased (1.164941 --> 1.161107).  Saving model ...
Validation loss decreased (1.161107 --> 1.157117).  Saving model ...
Validation loss decreased (1.157117 --> 1.152850).  Saving model ...
Validation loss decreased (1.152850 --> 1.148364).  Saving model ...
Validation loss decreased (1.148364 --> 1.143745).  Saving model ...
Validation loss decreased (1.143745 --> 1.139887).  Saving model ...
Validation loss decreased (1.139887 --> 1.135303).  Saving model ...
Validation loss decreased (1.135303 --> 1.131000).  Saving model ...
Validation loss decreased (1.131000 --> 1.127086).  Saving model ...
Validation loss decreased (1.127086 --> 1.123260).  Saving model ...
Validation loss decreased (1.123260 --> 1.118879).  Saving model ...
Validation loss decreased (1.118879 --> 1.114331).  Saving model ...
Validation loss decreased (1.114331 --> 1.111097).  Saving model ...
Validation loss decreased (1.111097 --> 1.107941).  Saving model ...
Validation loss decreased (1.107941 --> 1.104157).  Saving model ...
Validation loss decreased (1.104157 --> 1.099864).  Saving model ...
Validation loss decreased (1.099864 --> 1.096474).  Saving model ...
Validation loss decreased (1.096474 --> 1.093708).  Saving model ...
Validation loss decreased (1.093708 --> 1.090201).  Saving model ...
Validation loss decreased (1.090201 --> 1.086400).  Saving model ...
Validation loss decreased (1.086400 --> 1.083171).  Saving model ...
Validation loss decreased (1.083171 --> 1.079940).  Saving model ...
Validation loss decreased (1.079940 --> 1.076696).  Saving model ...
Validation loss decreased (1.076696 --> 1.074488).  Saving model ...
Validation loss decreased (1.074488 --> 1.070933).  Saving model ...
Validation loss decreased (1.070933 --> 1.067304).  Saving model ...
Validation loss decreased (1.067304 --> 1.064734).  Saving model ...
Validation loss decreased (1.064734 --> 1.062064).  Saving model ...
Validation loss decreased (1.062064 --> 1.059622).  Saving model ...
Validation loss decreased (1.059622 --> 1.056388).  Saving model ...
Validation loss decreased (1.056388 --> 1.053624).  Saving model ...
Validation loss decreased (1.053624 --> 1.051479).  Saving model ...
Validation loss decreased (1.051479 --> 1.047975).  Saving model ...
Validation loss decreased (1.047975 --> 1.044655).  Saving model ...
Validation loss decreased (1.044655 --> 1.042770).  Saving model ...
Validation loss decreased (1.042770 --> 1.040925).  Saving model ...
Validation loss decreased (1.040925 --> 1.038997).  Saving model ...
Validation loss decreased (1.038997 --> 1.036232).  Saving model ...
Validation loss decreased (1.036232 --> 1.033276).  Saving model ...
Validation loss decreased (1.033276 --> 1.031027).  Saving model ...
Validation loss decreased (1.031027 --> 1.028398).  Saving model ...
Validation loss decreased (1.028398 --> 1.024825).  Saving model ...
Validation loss decreased (1.024825 --> 1.022870).  Saving model ...
Validation loss decreased (1.022870 --> 1.020998).  Saving model ...
Validation loss decreased (1.020998 --> 1.019745).  Saving model ...
Validation loss decreased (1.019745 --> 1.018242).  Saving model ...
Validation loss decreased (1.018242 --> 1.016577).  Saving model ...
Validation loss decreased (1.016577 --> 1.014689).  Saving model ...
Validation loss decreased (1.014689 --> 1.012780).  Saving model ...
Validation loss decreased (1.012780 --> 1.012422).  Saving model ...
Validation loss decreased (1.012422 --> 1.011170).  Saving model ...
Validation loss decreased (1.011170 --> 1.008344).  Saving model ...
Validation loss decreased (1.008344 --> 1.006638).  Saving model ...
Validation loss decreased (1.006638 --> 1.005010).  Saving model ...
Validation loss decreased (1.005010 --> 1.003777).  Saving model ...
Validation loss decreased (1.003777 --> 1.001853).  Saving model ...
Validation loss decreased (1.001853 --> 1.000616).  Saving model ...
EarlyStopping counter: 1 out of 5.0
Validation loss decreased (1.000616 --> 0.998844).  Saving model ...
Validation loss decreased (0.998844 --> 0.998201).  Saving model ...
Validation loss decreased (0.998201 --> 0.996231).  Saving model ...
Validation loss decreased (0.996231 --> 0.995099).  Saving model ...
Validation loss decreased (0.995099 --> 0.992995).  Saving model ...
Validation loss decreased (0.992995 --> 0.992884).  Saving model ...
Validation loss decreased (0.992884 --> 0.992331).  Saving model ...
Validation loss decreased (0.992331 --> 0.990483).  Saving model ...
Validation loss decreased (0.990483 --> 0.990211).  Saving model ...
Validation loss decreased (0.990211 --> 0.987958).  Saving model ...
Validation loss decreased (0.987958 --> 0.987342).  Saving model ...
EarlyStopping counter: 1 out of 5.0
EarlyStopping counter: 2 out of 5.0
Validation loss decreased (0.987342 --> 0.986187).  Saving model ...
EarlyStopping counter: 1 out of 5.0
Validation loss decreased (0.986187 --> 0.984917).  Saving model ...
Validation loss decreased (0.984917 --> 0.984457).  Saving model ...
EarlyStopping counter: 1 out of 5.0
Validation loss decreased (0.984457 --> 0.984257).  Saving model ...
Validation loss decreased (0.984257 --> 0.982960).  Saving model ...
EarlyStopping counter: 1 out of 5.0
EarlyStopping counter: 2 out of 5.0
Validation loss decreased (0.982960 --> 0.980875).  Saving model ...
EarlyStopping counter: 1 out of 5.0
EarlyStopping counter: 2 out of 5.0
Validation loss decreased (0.980875 --> 0.980368).  Saving model ...
EarlyStopping counter: 1 out of 5.0
EarlyStopping counter: 2 out of 5.0
EarlyStopping counter: 3 out of 5.0
EarlyStopping counter: 4 out of 5.0
EarlyStopping counter: 5 out of 5.0
/localscratch/yinan.29154792.0/env/lib/python3.7/site-packages/torch/nn/functional.py:1794: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.
  warnings.warn("nn.functional.tanh is deprecated. Use torch.tanh instead.")
wandb: Waiting for W&B process to finish, PID 9300... (success).
wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: \ 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: | 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: / 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: \ 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: | 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: / 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: \ 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: | 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb:                                                                                
wandb: Run history:
wandb:     e_F1 ▁▃▄▅▅▅▆▆▆▆▆▆▇▇▇▇▇▇▇▇▇▇████▇█████████████
wandb:   e_loss █▇▆▆▆▅▅▅▅▄▄▄▄▃▃▃▃▃▃▂▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:     t_F1 ▁▂▃▃▃▃▄▄▅▅▅▅▅▅▅▆▆▆▆▇▇▆▇▇▇▇▇▇▇▇▇▇▇▇▇▇████
wandb:   t_loss █▇▇▇▇▆▆▆▅▅▅▅▅▄▄▄▄▄▄▃▃▃▃▃▃▃▃▂▂▂▂▂▂▂▂▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:     e_F1 58.17221
wandb:   e_loss 0.98129
wandb:     t_F1 69.97488
wandb:   t_loss 0.75551
wandb: 
wandb: Synced 4 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Synced feasible-frog-1: https://wandb.ai/yinanazhou/xl_512_bs_8_lr_1e06_es_5_lc_False_nr_True_sr_False_stem_False_lemma_True_repeat_4_fold_1/runs/8pquzcsu
wandb: Find logs at: ./wandb/run-20220318_022001-8pquzcsu/logs/debug.log
wandb: 

wandb: wandb version 0.12.11 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
2022-03-18 03:46:58.847474: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1
wandb: Tracking run with wandb version 0.12.5
wandb: Syncing run stoic-bird-1
wandb: ⭐️ View project at https://wandb.ai/yinanazhou/xl_512_bs_8_lr_1e06_es_5_lc_False_nr_True_sr_False_stem_False_lemma_True_repeat_4_fold_2
wandb: 🚀 View run at https://wandb.ai/yinanazhou/xl_512_bs_8_lr_1e06_es_5_lc_False_nr_True_sr_False_stem_False_lemma_True_repeat_4_fold_2/runs/12rhvsal
wandb: Run data is saved locally in /project/6002780/yinan/Thesis_MER_Lyrics/lyric-emotion/wandb/run-20220318_034655-12rhvsal
wandb: Run `wandb offline` to turn off syncing.

Validation loss decreased (inf --> 1.458991).  Saving model ...
Validation loss decreased (1.458991 --> 1.434745).  Saving model ...
Validation loss decreased (1.434745 --> 1.417547).  Saving model ...
Validation loss decreased (1.417547 --> 1.404599).  Saving model ...
Validation loss decreased (1.404599 --> 1.395737).  Saving model ...
Validation loss decreased (1.395737 --> 1.388457).  Saving model ...
Validation loss decreased (1.388457 --> 1.382908).  Saving model ...
Validation loss decreased (1.382908 --> 1.378372).  Saving model ...
Validation loss decreased (1.378372 --> 1.374001).  Saving model ...
Validation loss decreased (1.374001 --> 1.369236).  Saving model ...
Validation loss decreased (1.369236 --> 1.364930).  Saving model ...
Validation loss decreased (1.364930 --> 1.359441).  Saving model ...
Validation loss decreased (1.359441 --> 1.353326).  Saving model ...
Validation loss decreased (1.353326 --> 1.348437).  Saving model ...
Validation loss decreased (1.348437 --> 1.341387).  Saving model ...
Validation loss decreased (1.341387 --> 1.333543).  Saving model ...
Validation loss decreased (1.333543 --> 1.326852).  Saving model ...
Validation loss decreased (1.326852 --> 1.320733).  Saving model ...
Validation loss decreased (1.320733 --> 1.313487).  Saving model ...
Validation loss decreased (1.313487 --> 1.306283).  Saving model ...
Validation loss decreased (1.306283 --> 1.298292).  Saving model ...
Validation loss decreased (1.298292 --> 1.291544).  Saving model ...
Validation loss decreased (1.291544 --> 1.283762).  Saving model ...
Validation loss decreased (1.283762 --> 1.275823).  Saving model ...
Validation loss decreased (1.275823 --> 1.267542).  Saving model ...
Validation loss decreased (1.267542 --> 1.260084).  Saving model ...
Validation loss decreased (1.260084 --> 1.252169).  Saving model ...
Validation loss decreased (1.252169 --> 1.244570).  Saving model ...
Validation loss decreased (1.244570 --> 1.237615).  Saving model ...
Validation loss decreased (1.237615 --> 1.229869).  Saving model ...
Validation loss decreased (1.229869 --> 1.223140).  Saving model ...
Validation loss decreased (1.223140 --> 1.217068).  Saving model ...
Validation loss decreased (1.217068 --> 1.209465).  Saving model ...
Validation loss decreased (1.209465 --> 1.201565).  Saving model ...
Validation loss decreased (1.201565 --> 1.193140).  Saving model ...
Validation loss decreased (1.193140 --> 1.184501).  Saving model ...
Validation loss decreased (1.184501 --> 1.177674).  Saving model ...
Validation loss decreased (1.177674 --> 1.171444).  Saving model ...
Validation loss decreased (1.171444 --> 1.165940).  Saving model ...
Validation loss decreased (1.165940 --> 1.159950).  Saving model ...
Validation loss decreased (1.159950 --> 1.156328).  Saving model ...
Validation loss decreased (1.156328 --> 1.152039).  Saving model ...
Validation loss decreased (1.152039 --> 1.146528).  Saving model ...
Validation loss decreased (1.146528 --> 1.142935).  Saving model ...
Validation loss decreased (1.142935 --> 1.136411).  Saving model ...
Validation loss decreased (1.136411 --> 1.126909).  Saving model ...
Validation loss decreased (1.126909 --> 1.120594).  Saving model ...
Validation loss decreased (1.120594 --> 1.115761).  Saving model ...
Validation loss decreased (1.115761 --> 1.111843).  Saving model ...
Validation loss decreased (1.111843 --> 1.105765).  Saving model ...
Validation loss decreased (1.105765 --> 1.100316).  Saving model ...
Validation loss decreased (1.100316 --> 1.095851).  Saving model ...
Validation loss decreased (1.095851 --> 1.089795).  Saving model ...
Validation loss decreased (1.089795 --> 1.086023).  Saving model ...
Validation loss decreased (1.086023 --> 1.082671).  Saving model ...
Validation loss decreased (1.082671 --> 1.076367).  Saving model ...
Validation loss decreased (1.076367 --> 1.073218).  Saving model ...
Validation loss decreased (1.073218 --> 1.069915).  Saving model ...
Validation loss decreased (1.069915 --> 1.065991).  Saving model ...
Validation loss decreased (1.065991 --> 1.063627).  Saving model ...
Validation loss decreased (1.063627 --> 1.058211).  Saving model ...
Validation loss decreased (1.058211 --> 1.051787).  Saving model ...
Validation loss decreased (1.051787 --> 1.048850).  Saving model ...
Validation loss decreased (1.048850 --> 1.046446).  Saving model ...
Validation loss decreased (1.046446 --> 1.043509).  Saving model ...
Validation loss decreased (1.043509 --> 1.040063).  Saving model ...
Validation loss decreased (1.040063 --> 1.036721).  Saving model ...
Validation loss decreased (1.036721 --> 1.032993).  Saving model ...
Validation loss decreased (1.032993 --> 1.030878).  Saving model ...
Validation loss decreased (1.030878 --> 1.026196).  Saving model ...
Validation loss decreased (1.026196 --> 1.025522).  Saving model ...
Validation loss decreased (1.025522 --> 1.021016).  Saving model ...
EarlyStopping counter: 1 out of 5.0
Validation loss decreased (1.021016 --> 1.018344).  Saving model ...
Validation loss decreased (1.018344 --> 1.015466).  Saving model ...
Validation loss decreased (1.015466 --> 1.013890).  Saving model ...
Validation loss decreased (1.013890 --> 1.012799).  Saving model ...
Validation loss decreased (1.012799 --> 1.009686).  Saving model ...
EarlyStopping counter: 1 out of 5.0
Validation loss decreased (1.009686 --> 1.009018).  Saving model ...
Validation loss decreased (1.009018 --> 1.005454).  Saving model ...
Validation loss decreased (1.005454 --> 1.002050).  Saving model ...
Validation loss decreased (1.002050 --> 1.000678).  Saving model ...
Validation loss decreased (1.000678 --> 0.997642).  Saving model ...
Validation loss decreased (0.997642 --> 0.996857).  Saving model ...
Validation loss decreased (0.996857 --> 0.994703).  Saving model ...
Validation loss decreased (0.994703 --> 0.992201).  Saving model ...
Validation loss decreased (0.992201 --> 0.990763).  Saving model ...
Validation loss decreased (0.990763 --> 0.990184).  Saving model ...
Validation loss decreased (0.990184 --> 0.988695).  Saving model ...
Validation loss decreased (0.988695 --> 0.988133).  Saving model ...
Validation loss decreased (0.988133 --> 0.986041).  Saving model ...
EarlyStopping counter: 1 out of 5.0
EarlyStopping counter: 2 out of 5.0
Validation loss decreased (0.986041 --> 0.982857).  Saving model ...
Validation loss decreased (0.982857 --> 0.980624).  Saving model ...
EarlyStopping counter: 1 out of 5.0
EarlyStopping counter: 2 out of 5.0
Validation loss decreased (0.980624 --> 0.977683).  Saving model ...
Validation loss decreased (0.977683 --> 0.973365).  Saving model ...
EarlyStopping counter: 1 out of 5.0
EarlyStopping counter: 2 out of 5.0
EarlyStopping counter: 3 out of 5.0
EarlyStopping counter: 4 out of 5.0
EarlyStopping counter: 5 out of 5.0
/localscratch/yinan.29154792.0/env/lib/python3.7/site-packages/torch/nn/functional.py:1794: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.
  warnings.warn("nn.functional.tanh is deprecated. Use torch.tanh instead.")
wandb: Waiting for W&B process to finish, PID 13983... (success).
wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: \ 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: | 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: / 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: \ 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: | 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: / 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: \ 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: | 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: / 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: \ 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb:                                                                                
wandb: Run history:
wandb:     e_F1 ▁▁▃▃▃▄▄▄▄▅▅▆▆▆▆▆▆▇▇▇▇▇▇▇▇▇▇▇▇███████████
wandb:   e_loss █▇▇▇▇▆▆▆▆▅▅▅▄▄▄▄▃▃▃▃▃▂▂▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁
wandb:     t_F1 ▁▁▂▂▃▃▃▄▅▅▄▅▅▅▆▆▆▆▆▆▆▆▇▆▇▇▇▇▇▇█▇▇███████
wandb:   t_loss ██▇▇▇▇▇▆▆▆▆▅▅▅▅▄▄▄▄▄▄▃▃▃▃▃▂▂▂▂▂▂▂▂▂▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:     e_F1 60.08254
wandb:   e_loss 0.97362
wandb:     t_F1 68.45855
wandb:   t_loss 0.82647
wandb: 
wandb: Synced 4 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Synced stoic-bird-1: https://wandb.ai/yinanazhou/xl_512_bs_8_lr_1e06_es_5_lc_False_nr_True_sr_False_stem_False_lemma_True_repeat_4_fold_2/runs/12rhvsal
wandb: Find logs at: ./wandb/run-20220318_034655-12rhvsal/logs/debug.log
wandb: 

wandb: wandb version 0.12.11 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
2022-03-18 04:57:14.766270: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1
wandb: Tracking run with wandb version 0.12.5
wandb: Syncing run peach-gorge-1
wandb: ⭐️ View project at https://wandb.ai/yinanazhou/xl_512_bs_8_lr_1e06_es_5_lc_False_nr_True_sr_False_stem_False_lemma_True_repeat_5_fold_1
wandb: 🚀 View run at https://wandb.ai/yinanazhou/xl_512_bs_8_lr_1e06_es_5_lc_False_nr_True_sr_False_stem_False_lemma_True_repeat_5_fold_1/runs/1y79sbke
wandb: Run data is saved locally in /project/6002780/yinan/Thesis_MER_Lyrics/lyric-emotion/wandb/run-20220318_045711-1y79sbke
wandb: Run `wandb offline` to turn off syncing.

Validation loss decreased (inf --> 1.444415).  Saving model ...
Validation loss decreased (1.444415 --> 1.414566).  Saving model ...
Validation loss decreased (1.414566 --> 1.390657).  Saving model ...
Validation loss decreased (1.390657 --> 1.373570).  Saving model ...
Validation loss decreased (1.373570 --> 1.361033).  Saving model ...
Validation loss decreased (1.361033 --> 1.352605).  Saving model ...
Validation loss decreased (1.352605 --> 1.345028).  Saving model ...
Validation loss decreased (1.345028 --> 1.337841).  Saving model ...
Validation loss decreased (1.337841 --> 1.332238).  Saving model ...
Validation loss decreased (1.332238 --> 1.327005).  Saving model ...
Validation loss decreased (1.327005 --> 1.321039).  Saving model ...
Validation loss decreased (1.321039 --> 1.315073).  Saving model ...
Validation loss decreased (1.315073 --> 1.308763).  Saving model ...
Validation loss decreased (1.308763 --> 1.302180).  Saving model ...
Validation loss decreased (1.302180 --> 1.294835).  Saving model ...
Validation loss decreased (1.294835 --> 1.288686).  Saving model ...
Validation loss decreased (1.288686 --> 1.282134).  Saving model ...
Validation loss decreased (1.282134 --> 1.274677).  Saving model ...
Validation loss decreased (1.274677 --> 1.266811).  Saving model ...
Validation loss decreased (1.266811 --> 1.259155).  Saving model ...
Validation loss decreased (1.259155 --> 1.251523).  Saving model ...
Validation loss decreased (1.251523 --> 1.243613).  Saving model ...
Validation loss decreased (1.243613 --> 1.236007).  Saving model ...
Validation loss decreased (1.236007 --> 1.227845).  Saving model ...
Validation loss decreased (1.227845 --> 1.219487).  Saving model ...
Validation loss decreased (1.219487 --> 1.211637).  Saving model ...
Validation loss decreased (1.211637 --> 1.204810).  Saving model ...
Validation loss decreased (1.204810 --> 1.197668).  Saving model ...
Validation loss decreased (1.197668 --> 1.190675).  Saving model ...
Validation loss decreased (1.190675 --> 1.183267).  Saving model ...
Validation loss decreased (1.183267 --> 1.175431).  Saving model ...
Validation loss decreased (1.175431 --> 1.168279).  Saving model ...
Validation loss decreased (1.168279 --> 1.161804).  Saving model ...
Validation loss decreased (1.161804 --> 1.154892).  Saving model ...
Validation loss decreased (1.154892 --> 1.148488).  Saving model ...
Validation loss decreased (1.148488 --> 1.141352).  Saving model ...
Validation loss decreased (1.141352 --> 1.135593).  Saving model ...
Validation loss decreased (1.135593 --> 1.128347).  Saving model ...
Validation loss decreased (1.128347 --> 1.123317).  Saving model ...
Validation loss decreased (1.123317 --> 1.116608).  Saving model ...
Validation loss decreased (1.116608 --> 1.110974).  Saving model ...
Validation loss decreased (1.110974 --> 1.106151).  Saving model ...
Validation loss decreased (1.106151 --> 1.100558).  Saving model ...
Validation loss decreased (1.100558 --> 1.093643).  Saving model ...
Validation loss decreased (1.093643 --> 1.089399).  Saving model ...
Validation loss decreased (1.089399 --> 1.085479).  Saving model ...
Validation loss decreased (1.085479 --> 1.078967).  Saving model ...
Validation loss decreased (1.078967 --> 1.075738).  Saving model ...
Validation loss decreased (1.075738 --> 1.070530).  Saving model ...
Validation loss decreased (1.070530 --> 1.063750).  Saving model ...
Validation loss decreased (1.063750 --> 1.060179).  Saving model ...
Validation loss decreased (1.060179 --> 1.057339).  Saving model ...
Validation loss decreased (1.057339 --> 1.052783).  Saving model ...
Validation loss decreased (1.052783 --> 1.046011).  Saving model ...
Validation loss decreased (1.046011 --> 1.041565).  Saving model ...
Validation loss decreased (1.041565 --> 1.039407).  Saving model ...
Validation loss decreased (1.039407 --> 1.033931).  Saving model ...
Validation loss decreased (1.033931 --> 1.028580).  Saving model ...
Validation loss decreased (1.028580 --> 1.023674).  Saving model ...
Validation loss decreased (1.023674 --> 1.022018).  Saving model ...
Validation loss decreased (1.022018 --> 1.016274).  Saving model ...
Validation loss decreased (1.016274 --> 1.014921).  Saving model ...
Validation loss decreased (1.014921 --> 1.011696).  Saving model ...
Validation loss decreased (1.011696 --> 1.008755).  Saving model ...
Validation loss decreased (1.008755 --> 1.005554).  Saving model ...
Validation loss decreased (1.005554 --> 1.000344).  Saving model ...
Validation loss decreased (1.000344 --> 0.997927).  Saving model ...
Validation loss decreased (0.997927 --> 0.993924).  Saving model ...
Validation loss decreased (0.993924 --> 0.991143).  Saving model ...
Validation loss decreased (0.991143 --> 0.988591).  Saving model ...
Validation loss decreased (0.988591 --> 0.985646).  Saving model ...
Validation loss decreased (0.985646 --> 0.981947).  Saving model ...
Validation loss decreased (0.981947 --> 0.977869).  Saving model ...
Validation loss decreased (0.977869 --> 0.974773).  Saving model ...
Validation loss decreased (0.974773 --> 0.973871).  Saving model ...
Validation loss decreased (0.973871 --> 0.968865).  Saving model ...
Validation loss decreased (0.968865 --> 0.965446).  Saving model ...
EarlyStopping counter: 1 out of 5.0
Validation loss decreased (0.965446 --> 0.963394).  Saving model ...
Validation loss decreased (0.963394 --> 0.959802).  Saving model ...
Validation loss decreased (0.959802 --> 0.957800).  Saving model ...
Validation loss decreased (0.957800 --> 0.956546).  Saving model ...
Validation loss decreased (0.956546 --> 0.953852).  Saving model ...
Validation loss decreased (0.953852 --> 0.951692).  Saving model ...
Validation loss decreased (0.951692 --> 0.949894).  Saving model ...
Validation loss decreased (0.949894 --> 0.949227).  Saving model ...
Validation loss decreased (0.949227 --> 0.947438).  Saving model ...
Validation loss decreased (0.947438 --> 0.946368).  Saving model ...
Validation loss decreased (0.946368 --> 0.943639).  Saving model ...
Validation loss decreased (0.943639 --> 0.943460).  Saving model ...
Validation loss decreased (0.943460 --> 0.943265).  Saving model ...
Validation loss decreased (0.943265 --> 0.939631).  Saving model ...
Validation loss decreased (0.939631 --> 0.936837).  Saving model ...
Validation loss decreased (0.936837 --> 0.935318).  Saving model ...
Validation loss decreased (0.935318 --> 0.934375).  Saving model ...
Validation loss decreased (0.934375 --> 0.932689).  Saving model ...
Validation loss decreased (0.932689 --> 0.932434).  Saving model ...
Validation loss decreased (0.932434 --> 0.932363).  Saving model ...
Validation loss decreased (0.932363 --> 0.929433).  Saving model ...
Validation loss decreased (0.929433 --> 0.927875).  Saving model ...
Validation loss decreased (0.927875 --> 0.926160).  Saving model ...
Validation loss decreased (0.926160 --> 0.924652).  Saving model ...
Validation loss decreased (0.924652 --> 0.924313).  Saving model ...
Validation loss decreased (0.924313 --> 0.923619).  Saving model ...
Validation loss decreased (0.923619 --> 0.922991).  Saving model ...
EarlyStopping counter: 1 out of 5.0
Validation loss decreased (0.922991 --> 0.922447).  Saving model ...
Validation loss decreased (0.922447 --> 0.921751).  Saving model ...
Validation loss decreased (0.921751 --> 0.918924).  Saving model ...
Validation loss decreased (0.918924 --> 0.917084).  Saving model ...
Validation loss decreased (0.917084 --> 0.916927).  Saving model ...
EarlyStopping counter: 1 out of 5.0
EarlyStopping counter: 2 out of 5.0
Validation loss decreased (0.916927 --> 0.916312).  Saving model ...
Validation loss decreased (0.916312 --> 0.914727).  Saving model ...
Validation loss decreased (0.914727 --> 0.914577).  Saving model ...
EarlyStopping counter: 1 out of 5.0
Validation loss decreased (0.914577 --> 0.913807).  Saving model ...
EarlyStopping counter: 1 out of 5.0
EarlyStopping counter: 2 out of 5.0
Validation loss decreased (0.913807 --> 0.912137).  Saving model ...
Validation loss decreased (0.912137 --> 0.911050).  Saving model ...
Validation loss decreased (0.911050 --> 0.910937).  Saving model ...
EarlyStopping counter: 1 out of 5.0
Validation loss decreased (0.910937 --> 0.910854).  Saving model ...
Validation loss decreased (0.910854 --> 0.910184).  Saving model ...
EarlyStopping counter: 1 out of 5.0
Validation loss decreased (0.910184 --> 0.909319).  Saving model ...
EarlyStopping counter: 1 out of 5.0
EarlyStopping counter: 2 out of 5.0
Validation loss decreased (0.909319 --> 0.908761).  Saving model ...
Validation loss decreased (0.908761 --> 0.908227).  Saving model ...
EarlyStopping counter: 1 out of 5.0
EarlyStopping counter: 2 out of 5.0
EarlyStopping counter: 3 out of 5.0
EarlyStopping counter: 4 out of 5.0
EarlyStopping counter: 5 out of 5.0
/localscratch/yinan.29154792.0/env/lib/python3.7/site-packages/torch/nn/functional.py:1794: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.
  warnings.warn("nn.functional.tanh is deprecated. Use torch.tanh instead.")
wandb: Waiting for W&B process to finish, PID 17776... (success).
wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: \ 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: | 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: / 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: \ 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: | 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: / 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: \ 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: | 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: / 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb:                                                                                
wandb: Run history:
wandb:     e_F1 ▁▂▄▅▅▅▅▆▆▇▇▇▇▇▇▇▇▇▇▇▇▇██████████████████
wandb:   e_loss █▇▇▇▆▆▆▅▅▅▄▄▄▃▃▃▃▃▂▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:     t_F1 ▁▁▃▃▃▃▄▄▄▄▄▅▅▅▆▅▆▆▆▆▆▆▆▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇█
wandb:   t_loss ██▇▇▇▇▆▆▆▆▅▅▅▅▄▄▄▄▄▄▄▃▃▃▃▃▃▂▂▂▂▂▂▂▂▂▁▁▁▁
wandb: 
wandb: Run summary:
wandb:     e_F1 61.00065
wandb:   e_loss 0.91175
wandb:     t_F1 73.69596
wandb:   t_loss 0.72746
wandb: 
wandb: Synced 4 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Synced peach-gorge-1: https://wandb.ai/yinanazhou/xl_512_bs_8_lr_1e06_es_5_lc_False_nr_True_sr_False_stem_False_lemma_True_repeat_5_fold_1/runs/1y79sbke
wandb: Find logs at: ./wandb/run-20220318_045711-1y79sbke/logs/debug.log
wandb: 

wandb: wandb version 0.12.11 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
2022-03-18 06:28:50.116561: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1
wandb: Tracking run with wandb version 0.12.5
wandb: Syncing run amber-planet-1
wandb: ⭐️ View project at https://wandb.ai/yinanazhou/xl_512_bs_8_lr_1e06_es_5_lc_False_nr_True_sr_False_stem_False_lemma_True_repeat_5_fold_2
wandb: 🚀 View run at https://wandb.ai/yinanazhou/xl_512_bs_8_lr_1e06_es_5_lc_False_nr_True_sr_False_stem_False_lemma_True_repeat_5_fold_2/runs/3bolbokf
wandb: Run data is saved locally in /project/6002780/yinan/Thesis_MER_Lyrics/lyric-emotion/wandb/run-20220318_062845-3bolbokf
wandb: Run `wandb offline` to turn off syncing.

Validation loss decreased (inf --> 1.435469).  Saving model ...
Validation loss decreased (1.435469 --> 1.408686).  Saving model ...
Validation loss decreased (1.408686 --> 1.389782).  Saving model ...
Validation loss decreased (1.389782 --> 1.374886).  Saving model ...
Validation loss decreased (1.374886 --> 1.363846).  Saving model ...
Validation loss decreased (1.363846 --> 1.355226).  Saving model ...
Validation loss decreased (1.355226 --> 1.348665).  Saving model ...
Validation loss decreased (1.348665 --> 1.342359).  Saving model ...
Validation loss decreased (1.342359 --> 1.336918).  Saving model ...
Validation loss decreased (1.336918 --> 1.331720).  Saving model ...
Validation loss decreased (1.331720 --> 1.325827).  Saving model ...
Validation loss decreased (1.325827 --> 1.320300).  Saving model ...
Validation loss decreased (1.320300 --> 1.314878).  Saving model ...
Validation loss decreased (1.314878 --> 1.309554).  Saving model ...
Validation loss decreased (1.309554 --> 1.304033).  Saving model ...
Validation loss decreased (1.304033 --> 1.297651).  Saving model ...
Validation loss decreased (1.297651 --> 1.291150).  Saving model ...
Validation loss decreased (1.291150 --> 1.283543).  Saving model ...
Validation loss decreased (1.283543 --> 1.276561).  Saving model ...
Validation loss decreased (1.276561 --> 1.270211).  Saving model ...
Validation loss decreased (1.270211 --> 1.262731).  Saving model ...
Validation loss decreased (1.262731 --> 1.255295).  Saving model ...
Validation loss decreased (1.255295 --> 1.247924).  Saving model ...
Validation loss decreased (1.247924 --> 1.239703).  Saving model ...
Validation loss decreased (1.239703 --> 1.231329).  Saving model ...
Validation loss decreased (1.231329 --> 1.223316).  Saving model ...
Validation loss decreased (1.223316 --> 1.215791).  Saving model ...
Validation loss decreased (1.215791 --> 1.207685).  Saving model ...
Validation loss decreased (1.207685 --> 1.200648).  Saving model ...
Validation loss decreased (1.200648 --> 1.192508).  Saving model ...
Validation loss decreased (1.192508 --> 1.184120).  Saving model ...
Validation loss decreased (1.184120 --> 1.176668).  Saving model ...
Validation loss decreased (1.176668 --> 1.169895).  Saving model ...
Validation loss decreased (1.169895 --> 1.162545).  Saving model ...
Validation loss decreased (1.162545 --> 1.154942).  Saving model ...
Validation loss decreased (1.154942 --> 1.148103).  Saving model ...
Validation loss decreased (1.148103 --> 1.142539).  Saving model ...
Validation loss decreased (1.142539 --> 1.136940).  Saving model ...
Validation loss decreased (1.136940 --> 1.131681).  Saving model ...
Validation loss decreased (1.131681 --> 1.125749).  Saving model ...
Validation loss decreased (1.125749 --> 1.120242).  Saving model ...
Validation loss decreased (1.120242 --> 1.115479).  Saving model ...
Validation loss decreased (1.115479 --> 1.110346).  Saving model ...
Validation loss decreased (1.110346 --> 1.105870).  Saving model ...
Validation loss decreased (1.105870 --> 1.102016).  Saving model ...
Validation loss decreased (1.102016 --> 1.097573).  Saving model ...
Validation loss decreased (1.097573 --> 1.091739).  Saving model ...
Validation loss decreased (1.091739 --> 1.086846).  Saving model ...
Validation loss decreased (1.086846 --> 1.081990).  Saving model ...
Validation loss decreased (1.081990 --> 1.078969).  Saving model ...
Validation loss decreased (1.078969 --> 1.073460).  Saving model ...
Validation loss decreased (1.073460 --> 1.069134).  Saving model ...
Validation loss decreased (1.069134 --> 1.066172).  Saving model ...
Validation loss decreased (1.066172 --> 1.061126).  Saving model ...
Validation loss decreased (1.061126 --> 1.057666).  Saving model ...
Validation loss decreased (1.057666 --> 1.055430).  Saving model ...
Validation loss decreased (1.055430 --> 1.053146).  Saving model ...
Validation loss decreased (1.053146 --> 1.050113).  Saving model ...
Validation loss decreased (1.050113 --> 1.046828).  Saving model ...
Validation loss decreased (1.046828 --> 1.043944).  Saving model ...
Validation loss decreased (1.043944 --> 1.041190).  Saving model ...
Validation loss decreased (1.041190 --> 1.038520).  Saving model ...
Validation loss decreased (1.038520 --> 1.035681).  Saving model ...
Validation loss decreased (1.035681 --> 1.033954).  Saving model ...
Validation loss decreased (1.033954 --> 1.030747).  Saving model ...
Validation loss decreased (1.030747 --> 1.027594).  Saving model ...
Validation loss decreased (1.027594 --> 1.025880).  Saving model ...
Validation loss decreased (1.025880 --> 1.023517).  Saving model ...
Validation loss decreased (1.023517 --> 1.020765).  Saving model ...
Validation loss decreased (1.020765 --> 1.018801).  Saving model ...
Validation loss decreased (1.018801 --> 1.015111).  Saving model ...
Validation loss decreased (1.015111 --> 1.014123).  Saving model ...
Validation loss decreased (1.014123 --> 1.010942).  Saving model ...
Validation loss decreased (1.010942 --> 1.006810).  Saving model ...
Validation loss decreased (1.006810 --> 1.004483).  Saving model ...
Validation loss decreased (1.004483 --> 1.002204).  Saving model ...
Validation loss decreased (1.002204 --> 0.999734).  Saving model ...
Validation loss decreased (0.999734 --> 0.995742).  Saving model ...
Validation loss decreased (0.995742 --> 0.992988).  Saving model ...
Validation loss decreased (0.992988 --> 0.990050).  Saving model ...
Validation loss decreased (0.990050 --> 0.985869).  Saving model ...
Validation loss decreased (0.985869 --> 0.984429).  Saving model ...
Validation loss decreased (0.984429 --> 0.982364).  Saving model ...
Validation loss decreased (0.982364 --> 0.979635).  Saving model ...
Validation loss decreased (0.979635 --> 0.977268).  Saving model ...
Validation loss decreased (0.977268 --> 0.976111).  Saving model ...
Validation loss decreased (0.976111 --> 0.974600).  Saving model ...
Validation loss decreased (0.974600 --> 0.973970).  Saving model ...
Validation loss decreased (0.973970 --> 0.972875).  Saving model ...
Validation loss decreased (0.972875 --> 0.968937).  Saving model ...
Validation loss decreased (0.968937 --> 0.968580).  Saving model ...
Validation loss decreased (0.968580 --> 0.966193).  Saving model ...
Validation loss decreased (0.966193 --> 0.963918).  Saving model ...
Validation loss decreased (0.963918 --> 0.963209).  Saving model ...
Validation loss decreased (0.963209 --> 0.962371).  Saving model ...
Validation loss decreased (0.962371 --> 0.961227).  Saving model ...
Validation loss decreased (0.961227 --> 0.960870).  Saving model ...
Validation loss decreased (0.960870 --> 0.958789).  Saving model ...
Validation loss decreased (0.958789 --> 0.955650).  Saving model ...
EarlyStopping counter: 1 out of 5.0
EarlyStopping counter: 2 out of 5.0
Validation loss decreased (0.955650 --> 0.955373).  Saving model ...
Validation loss decreased (0.955373 --> 0.954693).  Saving model ...
Validation loss decreased (0.954693 --> 0.953604).  Saving model ...
Validation loss decreased (0.953604 --> 0.951383).  Saving model ...
Validation loss decreased (0.951383 --> 0.950645).  Saving model ...
Validation loss decreased (0.950645 --> 0.950012).  Saving model ...
EarlyStopping counter: 1 out of 5.0
Validation loss decreased (0.950012 --> 0.948716).  Saving model ...
Validation loss decreased (0.948716 --> 0.946955).  Saving model ...
EarlyStopping counter: 1 out of 5.0
Validation loss decreased (0.946955 --> 0.944496).  Saving model ...
Validation loss decreased (0.944496 --> 0.943324).  Saving model ...
Validation loss decreased (0.943324 --> 0.942744).  Saving model ...
Validation loss decreased (0.942744 --> 0.941620).  Saving model ...
Validation loss decreased (0.941620 --> 0.939143).  Saving model ...
Validation loss decreased (0.939143 --> 0.938473).  Saving model ...
Validation loss decreased (0.938473 --> 0.936337).  Saving model ...
Validation loss decreased (0.936337 --> 0.936280).  Saving model ...
Validation loss decreased (0.936280 --> 0.936154).  Saving model ...
EarlyStopping counter: 1 out of 5.0
EarlyStopping counter: 2 out of 5.0
Validation loss decreased (0.936154 --> 0.935804).  Saving model ...
EarlyStopping counter: 1 out of 5.0
EarlyStopping counter: 2 out of 5.0
EarlyStopping counter: 3 out of 5.0
EarlyStopping counter: 4 out of 5.0
EarlyStopping counter: 5 out of 5.0
/localscratch/yinan.29154792.0/env/lib/python3.7/site-packages/torch/nn/functional.py:1794: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.
  warnings.warn("nn.functional.tanh is deprecated. Use torch.tanh instead.")
wandb: Waiting for W&B process to finish, PID 22719... (success).
wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: \ 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: | 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: / 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: \ 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: | 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: / 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: \ 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: | 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: / 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb:                                                                                
wandb: Run history:
wandb:     e_F1 ▁▃▅▅▆▆▆▆▇▇▇▇▇▇▇▇▇▇▇█████████████████████
wandb:   e_loss █▇▇▇▇▆▆▅▅▅▄▄▄▄▃▃▃▃▃▃▂▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁
wandb:     t_F1 ▁▂▂▃▃▃▄▄▄▅▅▅▅▆▆▆▆▆▆▆▇▇▇▇▇▇▇▇▇▇▇▇▇▇██████
wandb:   t_loss ███▇▇▇▇▆▆▆▆▅▅▅▅▄▄▄▄▄▃▃▃▃▃▃▂▂▂▂▂▂▂▂▂▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:     e_F1 60.36259
wandb:   e_loss 0.93741
wandb:     t_F1 72.53843
wandb:   t_loss 0.76768
wandb: 
wandb: Synced 4 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Synced amber-planet-1: https://wandb.ai/yinanazhou/xl_512_bs_8_lr_1e06_es_5_lc_False_nr_True_sr_False_stem_False_lemma_True_repeat_5_fold_2/runs/3bolbokf
wandb: Find logs at: ./wandb/run-20220318_062845-3bolbokf/logs/debug.log
wandb: 

