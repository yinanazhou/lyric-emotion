Unloading StdEnv/2020

Due to MODULEPATH changes, the following have been reloaded:
  1) mii/1.1.1


The following have been reloaded with a version change:
  1) python/3.8.2 => python/3.7.4

Using base prefix '/cvmfs/soft.computecanada.ca/easybuild/software/2017/Core/python/3.7.4'
New python executable in /localscratch/yinan.29785222.0/env/bin/python
Installing setuptools, pip, wheel...
done.
Ignoring pip: markers 'python_version < "3"' don't match your environment
Looking in links: /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/nix/avx2, /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/nix/generic, /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic
Collecting pip
Installing collected packages: pip
  Found existing installation: pip 19.1.1
    Uninstalling pip-19.1.1:
      Successfully uninstalled pip-19.1.1
Successfully installed pip-21.2.3+computecanada
Looking in links: /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/nix/avx2, /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/nix/generic, /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/keras-2.8.0+computecanada-py2.py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/Keras_Preprocessing-1.1.2+computecanada-py3-none-any.whl
Requirement already satisfied: matplotlib in /cvmfs/soft.computecanada.ca/easybuild/software/2017/Core/scipy-stack/2019a/lib/python3.7/site-packages (from -r requirements.txt (line 3)) (3.0.2)
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/nltk-3.6.5+computecanada-py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/scikit_learn-0.22.1+computecanada-cp37-cp37m-linux_x86_64.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/tensorboard-2.3.0+computecanada-py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/tensorboard_plugin_wit-1.7.0+computecanada-py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/tensorflow_gpu-2.3.0+computecanada-cp37-cp37m-linux_x86_64.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/tensorflow_estimator-2.3.0+computecanada-py2.py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/tokenizers-0.5.2+computecanada-cp37-cp37m-linux_x86_64.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/nix/avx2/torch-1.4.0+computecanada-cp37-cp37m-linux_x86_64.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/torchtext-0.6.0+computecanada-py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/torchvision-0.8.2+computecanada-cp37-cp37m-linux_x86_64.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/transformers-2.5.1+computecanada-py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/urllib3-1.26.7+computecanada-py2.py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/tqdm-4.63.1+computecanada-py2.py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/click-8.1.0+computecanada-py3-none-any.whl
ERROR: Could not find a version that satisfies the requirement regex>=2021.8.3 (from nltk) (from versions: 2018.1.10+computecanada, 2019.11.1+computecanada, 2020.11.13+computecanada)
ERROR: No matching distribution found for regex>=2021.8.3
Looking in links: /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/nix/avx2, /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/nix/generic, /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic
ERROR: Could not find a version that satisfies the requirement numpy==1.20.0+computacanada (from versions: 1.15.0+computecanada, 1.15.2+computecanada, 1.15.4+computecanada, 1.16.0+computecanada, 1.16.2+computecanada, 1.16.3+computecanada, 1.17.4+computecanada, 1.18.1+computecanada, 1.18.4+computecanada, 1.19.1+computecanada, 1.19.2+computecanada, 1.20.2+computecanada)
ERROR: No matching distribution found for numpy==1.20.0+computacanada
Looking in links: /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/nix/avx2, /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/nix/generic, /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/wandb-0.12.5+computecanada-py2.py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/subprocess32-3.5.4+computecanada-py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/six-1.16.0+computecanada-py2.py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/sentry_sdk-1.5.0+computecanada-py2.py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/PyYAML-5.3.1+computecanada-cp37-cp37m-linux_x86_64.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/docker_pycreds-0.4.0+computecanada-py2.py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/protobuf-3.19.4+computecanada-py2.py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/promise-2.3+computecanada-py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/configparser-5.0.2+computecanada-py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/shortuuid-1.0.1+computecanada-py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/GitPython-3.1.24+computecanada-py3-none-any.whl
Requirement already satisfied: python-dateutil>=2.6.1 in /cvmfs/soft.computecanada.ca/easybuild/software/2017/Core/scipy-stack/2019a/lib/python3.7/site-packages (from wandb) (2.7.5)
Requirement already satisfied: requests<3,>=2.0.0 in /cvmfs/soft.computecanada.ca/easybuild/software/2017/Core/scipy-stack/2019a/lib/python3.7/site-packages (from wandb) (2.21.0)
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/click-8.1.0+computecanada-py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/yaspin-2.1.0+computecanada-py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/psutil-5.7.3+computecanada-cp37-cp37m-linux_x86_64.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/pathtools-0.1.2+computecanada-py3-none-any.whl
Requirement already satisfied: importlib-metadata in /cvmfs/soft.computecanada.ca/easybuild/software/2017/Core/scipy-stack/2019a/lib/python3.7/site-packages (from Click!=8.0.0,>=7.0->wandb) (0.8)
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/typing_extensions-4.1.1+computecanada-py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/gitdb-4.0.9+computecanada-py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/smmap-5.0.0+computecanada-py3-none-any.whl
Requirement already satisfied: urllib3<1.25,>=1.21.1 in /cvmfs/soft.computecanada.ca/easybuild/software/2017/Core/scipy-stack/2019a/lib/python3.7/site-packages (from requests<3,>=2.0.0->wandb) (1.24.1)
Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /cvmfs/soft.computecanada.ca/easybuild/software/2017/Core/scipy-stack/2019a/lib/python3.7/site-packages (from requests<3,>=2.0.0->wandb) (3.0.4)
Requirement already satisfied: idna<2.9,>=2.5 in /cvmfs/soft.computecanada.ca/easybuild/software/2017/Core/scipy-stack/2019a/lib/python3.7/site-packages (from requests<3,>=2.0.0->wandb) (2.8)
Requirement already satisfied: certifi>=2017.4.17 in /cvmfs/soft.computecanada.ca/easybuild/software/2017/Core/scipy-stack/2019a/lib/python3.7/site-packages (from requests<3,>=2.0.0->wandb) (2018.11.29)
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/termcolor-1.1.0+computecanada-py3-none-any.whl
Requirement already satisfied: zipp>=0.3.2 in /cvmfs/soft.computecanada.ca/easybuild/software/2017/Core/scipy-stack/2019a/lib/python3.7/site-packages (from importlib-metadata->Click!=8.0.0,>=7.0->wandb) (0.3.3)
Installing collected packages: smmap, typing-extensions, termcolor, six, gitdb, yaspin, subprocess32, shortuuid, sentry-sdk, PyYAML, psutil, protobuf, promise, pathtools, GitPython, docker-pycreds, configparser, Click, wandb
  Attempting uninstall: six
    Found existing installation: six 1.12.0
    Not uninstalling six at /cvmfs/soft.computecanada.ca/easybuild/software/2017/Core/scipy-stack/2019a/lib/python3.7/site-packages, outside environment /localscratch/yinan.29785222.0/env
    Can't uninstall 'six'. No files were found to uninstall.
Successfully installed Click-8.1.0+computecanada GitPython-3.1.24+computecanada PyYAML-5.3.1+computecanada configparser-5.0.2+computecanada docker-pycreds-0.4.0+computecanada gitdb-4.0.9+computecanada pathtools-0.1.2+computecanada promise-2.3+computecanada protobuf-3.19.4+computecanada psutil-5.7.3+computecanada sentry-sdk-1.5.0+computecanada shortuuid-1.0.1+computecanada six-1.16.0+computecanada smmap-5.0.0+computecanada subprocess32-3.5.4+computecanada termcolor-1.1.0+computecanada typing-extensions-4.1.1+computecanada wandb-0.12.5+computecanada yaspin-2.1.0+computecanada
Looking in links: /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/nix/avx2, /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/nix/generic, /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic
ERROR: Could not find a version that satisfies the requirement sagemaker (from versions: none)
ERROR: No matching distribution found for sagemaker
Looking in links: /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/nix/avx2, /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/nix/generic, /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/torch-1.9.1+computecanada-cp37-cp37m-linux_x86_64.whl
Requirement already satisfied: typing-extensions in /localscratch/yinan.29785222.0/env/lib/python3.7/site-packages (from torch) (4.1.1+computecanada)
Installing collected packages: torch
Successfully installed torch-1.9.1+computecanada
Looking in links: /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/nix/avx2, /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/nix/generic, /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/transformers-2.5.1+computecanada-py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/tqdm-4.63.1+computecanada-py2.py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/filelock-3.4.2+computecanada-py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/boto3-1.21.14+computecanada-py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/tokenizers-0.5.2+computecanada-cp37-cp37m-linux_x86_64.whl
Requirement already satisfied: numpy in /cvmfs/soft.computecanada.ca/easybuild/software/2017/Core/scipy-stack/2019a/lib/python3.7/site-packages (from transformers==2.5.1+computecanada) (1.16.0)
Requirement already satisfied: requests in /cvmfs/soft.computecanada.ca/easybuild/software/2017/Core/scipy-stack/2019a/lib/python3.7/site-packages (from transformers==2.5.1+computecanada) (2.21.0)
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/regex-2020.11.13+computecanada-cp37-cp37m-linux_x86_64.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/sacremoses-0.0.49+computecanada-py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/sentencepiece-0.1.91+computecanada-cp37-cp37m-linux_x86_64.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/botocore-1.24.14+computecanada-py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/jmespath-0.10.0+computecanada-py2.py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/s3transfer-0.5.1+computecanada-py3-none-any.whl
Requirement already satisfied: python-dateutil<3.0.0,>=2.1 in /cvmfs/soft.computecanada.ca/easybuild/software/2017/Core/scipy-stack/2019a/lib/python3.7/site-packages (from botocore<1.25.0,>=1.24.14->boto3->transformers==2.5.1+computecanada) (2.7.5)
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/urllib3-1.26.9+computecanada-py2.py3-none-any.whl
Requirement already satisfied: six>=1.5 in /localscratch/yinan.29785222.0/env/lib/python3.7/site-packages (from python-dateutil<3.0.0,>=2.1->botocore<1.25.0,>=1.24.14->boto3->transformers==2.5.1+computecanada) (1.16.0+computecanada)
Requirement already satisfied: idna<2.9,>=2.5 in /cvmfs/soft.computecanada.ca/easybuild/software/2017/Core/scipy-stack/2019a/lib/python3.7/site-packages (from requests->transformers==2.5.1+computecanada) (2.8)
Requirement already satisfied: certifi>=2017.4.17 in /cvmfs/soft.computecanada.ca/easybuild/software/2017/Core/scipy-stack/2019a/lib/python3.7/site-packages (from requests->transformers==2.5.1+computecanada) (2018.11.29)
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/requests-2.27.1+computecanada-py2.py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/charset_normalizer-2.0.12+computecanada-py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/joblib-1.1.0+computecanada-py2.py3-none-any.whl
Requirement already satisfied: click in /localscratch/yinan.29785222.0/env/lib/python3.7/site-packages (from sacremoses->transformers==2.5.1+computecanada) (8.1.0+computecanada)
Requirement already satisfied: importlib-metadata in /cvmfs/soft.computecanada.ca/easybuild/software/2017/Core/scipy-stack/2019a/lib/python3.7/site-packages (from click->sacremoses->transformers==2.5.1+computecanada) (0.8)
Requirement already satisfied: zipp>=0.3.2 in /cvmfs/soft.computecanada.ca/easybuild/software/2017/Core/scipy-stack/2019a/lib/python3.7/site-packages (from importlib-metadata->click->sacremoses->transformers==2.5.1+computecanada) (0.3.3)
Installing collected packages: urllib3, jmespath, botocore, tqdm, s3transfer, regex, joblib, charset-normalizer, tokenizers, sentencepiece, sacremoses, requests, filelock, boto3, transformers
  Attempting uninstall: urllib3
    Found existing installation: urllib3 1.24.1
    Not uninstalling urllib3 at /cvmfs/soft.computecanada.ca/easybuild/software/2017/Core/scipy-stack/2019a/lib/python3.7/site-packages, outside environment /localscratch/yinan.29785222.0/env
    Can't uninstall 'urllib3'. No files were found to uninstall.
  Attempting uninstall: requests
    Found existing installation: requests 2.21.0
    Not uninstalling requests at /cvmfs/soft.computecanada.ca/easybuild/software/2017/Core/scipy-stack/2019a/lib/python3.7/site-packages, outside environment /localscratch/yinan.29785222.0/env
    Can't uninstall 'requests'. No files were found to uninstall.
Successfully installed boto3-1.21.14+computecanada botocore-1.24.14+computecanada charset-normalizer-2.0.12+computecanada filelock-3.4.2+computecanada jmespath-0.10.0+computecanada joblib-1.1.0+computecanada regex-2020.11.13+computecanada requests-2.27.1+computecanada s3transfer-0.5.1+computecanada sacremoses-0.0.49+computecanada sentencepiece-0.1.91+computecanada tokenizers-0.5.2+computecanada tqdm-4.63.1+computecanada transformers-2.5.1+computecanada urllib3-1.26.9+computecanada
Looking in links: /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/nix/avx2, /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/nix/generic, /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/tensorflow_gpu-2.3.0+computecanada-cp37-cp37m-linux_x86_64.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/wrapt-1.11.2+computecanada-cp37-cp37m-linux_x86_64.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/gast-0.3.3+computecanada-py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/google_pasta-0.2.0+computecanada-py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/tensorboard-2.8.0+computecanada-py3-none-any.whl
Requirement already satisfied: six>=1.12.0 in /localscratch/yinan.29785222.0/env/lib/python3.7/site-packages (from tensorflow_gpu==2.3.0+computecanada) (1.16.0+computecanada)
Requirement already satisfied: protobuf>=3.9.2 in /localscratch/yinan.29785222.0/env/lib/python3.7/site-packages (from tensorflow_gpu==2.3.0+computecanada) (3.19.4+computecanada)
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/astunparse-1.6.3+computecanada-py2.py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/absl_py-1.0.0+computecanada-py3-none-any.whl
Requirement already satisfied: numpy<1.19.0,>=1.16.0 in /cvmfs/soft.computecanada.ca/easybuild/software/2017/Core/scipy-stack/2019a/lib/python3.7/site-packages (from tensorflow_gpu==2.3.0+computecanada) (1.16.0)
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/tensorflow_estimator-2.3.0+computecanada-py2.py3-none-any.whl
Requirement already satisfied: termcolor>=1.1.0 in /localscratch/yinan.29785222.0/env/lib/python3.7/site-packages (from tensorflow_gpu==2.3.0+computecanada) (1.1.0+computecanada)
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/nix/avx2/h5py-2.10.0+computecanada-cp37-cp37m-linux_x86_64.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/grpcio-1.38.0+computecanada-cp37-cp37m-linux_x86_64.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/opt_einsum-3.3.0+computecanada-py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/nix/generic/scipy-1.4.1+computecanada-cp37-cp37m-linux_x86_64.whl
Requirement already satisfied: wheel>=0.26 in /localscratch/yinan.29785222.0/env/lib/python3.7/site-packages (from tensorflow_gpu==2.3.0+computecanada) (0.33.4)
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/Keras_Preprocessing-1.1.2+computecanada-py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/google_auth-2.3.3+computecanada-py2.py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/tensorboard_data_server-0.6.1+computecanada-py3-none-linux_x86_64.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/Markdown-3.3.6+computecanada-py3-none-any.whl
Requirement already satisfied: setuptools>=41.0.0 in /localscratch/yinan.29785222.0/env/lib/python3.7/site-packages (from tensorboard<3,>=2.3.0->tensorflow_gpu==2.3.0+computecanada) (41.0.1)
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/Werkzeug-2.0.3+computecanada-py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/google_auth_oauthlib-0.4.6+computecanada-py2.py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/tensorboard_plugin_wit-1.8.0+computecanada-py3-none-any.whl
Requirement already satisfied: requests<3,>=2.21.0 in /localscratch/yinan.29785222.0/env/lib/python3.7/site-packages (from tensorboard<3,>=2.3.0->tensorflow_gpu==2.3.0+computecanada) (2.27.1+computecanada)
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/cachetools-4.2.4+computecanada-py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/pyasn1_modules-0.2.8+computecanada-py2.py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/rsa-4.8+computecanada-py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/requests_oauthlib-1.3.0+computecanada-py2.py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/importlib_metadata-4.10.1+computecanada-py3-none-any.whl
Requirement already satisfied: typing-extensions>=3.6.4 in /localscratch/yinan.29785222.0/env/lib/python3.7/site-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard<3,>=2.3.0->tensorflow_gpu==2.3.0+computecanada) (4.1.1+computecanada)
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/zipp-3.7.0+computecanada-py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/pyasn1-0.4.8+computecanada-py2.py3-none-any.whl
Requirement already satisfied: idna<4,>=2.5 in /cvmfs/soft.computecanada.ca/easybuild/software/2017/Core/scipy-stack/2019a/lib/python3.7/site-packages (from requests<3,>=2.21.0->tensorboard<3,>=2.3.0->tensorflow_gpu==2.3.0+computecanada) (2.8)
Requirement already satisfied: urllib3<1.27,>=1.21.1 in /localscratch/yinan.29785222.0/env/lib/python3.7/site-packages (from requests<3,>=2.21.0->tensorboard<3,>=2.3.0->tensorflow_gpu==2.3.0+computecanada) (1.26.9+computecanada)
Requirement already satisfied: charset-normalizer~=2.0.0 in /localscratch/yinan.29785222.0/env/lib/python3.7/site-packages (from requests<3,>=2.21.0->tensorboard<3,>=2.3.0->tensorflow_gpu==2.3.0+computecanada) (2.0.12+computecanada)
Requirement already satisfied: certifi>=2017.4.17 in /cvmfs/soft.computecanada.ca/easybuild/software/2017/Core/scipy-stack/2019a/lib/python3.7/site-packages (from requests<3,>=2.21.0->tensorboard<3,>=2.3.0->tensorflow_gpu==2.3.0+computecanada) (2018.11.29)
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/oauthlib-3.1.1+computecanada-py2.py3-none-any.whl
Installing collected packages: pyasn1, zipp, rsa, pyasn1-modules, oauthlib, cachetools, requests-oauthlib, importlib-metadata, google-auth, werkzeug, tensorboard-plugin-wit, tensorboard-data-server, markdown, grpcio, google-auth-oauthlib, absl-py, wrapt, tensorflow-estimator, tensorboard, scipy, opt-einsum, keras-preprocessing, h5py, google-pasta, gast, astunparse, tensorflow-gpu
  Attempting uninstall: pyasn1
    Found existing installation: pyasn1 0.4.3
    Not uninstalling pyasn1 at /cvmfs/soft.computecanada.ca/easybuild/software/2017/Core/scipy-stack/2019a/lib/python3.7/site-packages, outside environment /localscratch/yinan.29785222.0/env
    Can't uninstall 'pyasn1'. No files were found to uninstall.
  Attempting uninstall: zipp
    Found existing installation: zipp 0.3.3
    Not uninstalling zipp at /cvmfs/soft.computecanada.ca/easybuild/software/2017/Core/scipy-stack/2019a/lib/python3.7/site-packages, outside environment /localscratch/yinan.29785222.0/env
    Can't uninstall 'zipp'. No files were found to uninstall.
  Attempting uninstall: importlib-metadata
    Found existing installation: importlib-metadata 0.8
    Not uninstalling importlib-metadata at /cvmfs/soft.computecanada.ca/easybuild/software/2017/Core/scipy-stack/2019a/lib/python3.7/site-packages, outside environment /localscratch/yinan.29785222.0/env
    Can't uninstall 'importlib-metadata'. No files were found to uninstall.
  Attempting uninstall: scipy
    Found existing installation: scipy 1.2.0
    Not uninstalling scipy at /cvmfs/soft.computecanada.ca/easybuild/software/2017/Core/scipy-stack/2019a/lib/python3.7/site-packages, outside environment /localscratch/yinan.29785222.0/env
    Can't uninstall 'scipy'. No files were found to uninstall.
Successfully installed absl-py-1.0.0+computecanada astunparse-1.6.3+computecanada cachetools-4.2.4+computecanada gast-0.3.3+computecanada google-auth-2.3.3+computecanada google-auth-oauthlib-0.4.6+computecanada google-pasta-0.2.0+computecanada grpcio-1.38.0+computecanada h5py-2.10.0+computecanada importlib-metadata-4.10.1+computecanada keras-preprocessing-1.1.2+computecanada markdown-3.3.6+computecanada oauthlib-3.1.1+computecanada opt-einsum-3.3.0+computecanada pyasn1-0.4.8+computecanada pyasn1-modules-0.2.8+computecanada requests-oauthlib-1.3.0+computecanada rsa-4.8+computecanada scipy-1.4.1+computecanada tensorboard-2.8.0+computecanada tensorboard-data-server-0.6.1+computecanada tensorboard-plugin-wit-1.8.0+computecanada tensorflow-estimator-2.3.0+computecanada tensorflow-gpu-2.3.0+computecanada werkzeug-2.0.3+computecanada wrapt-1.11.2+computecanada zipp-3.7.0+computecanada
Looking in links: /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/nix/avx2, /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/nix/generic, /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/keras-2.8.0+computecanada-py2.py3-none-any.whl
Installing collected packages: Keras
Successfully installed Keras-2.8.0+computecanada
Looking in links: /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/nix/avx2, /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/nix/generic, /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/urllib3-1.26.7+computecanada-py2.py3-none-any.whl
Installing collected packages: urllib3
  Attempting uninstall: urllib3
    Found existing installation: urllib3 1.26.9+computecanada
    Uninstalling urllib3-1.26.9+computecanada:
      Successfully uninstalled urllib3-1.26.9+computecanada
Successfully installed urllib3-1.26.7+computecanada
Looking in links: /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/nix/avx2, /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/nix/generic, /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/nltk-3.7+computecanada-py3-none-any.whl
Requirement already satisfied: click in /localscratch/yinan.29785222.0/env/lib/python3.7/site-packages (from nltk) (8.1.0+computecanada)
Requirement already satisfied: tqdm in /localscratch/yinan.29785222.0/env/lib/python3.7/site-packages (from nltk) (4.63.1+computecanada)
Requirement already satisfied: joblib in /localscratch/yinan.29785222.0/env/lib/python3.7/site-packages (from nltk) (1.1.0+computecanada)
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/nltk-3.6.5+computecanada-py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/nltk-3.6.3+computecanada-py3-none-any.whl
Requirement already satisfied: regex in /localscratch/yinan.29785222.0/env/lib/python3.7/site-packages (from nltk) (2020.11.13+computecanada)
Requirement already satisfied: importlib-metadata in /localscratch/yinan.29785222.0/env/lib/python3.7/site-packages (from click->nltk) (4.10.1+computecanada)
Requirement already satisfied: zipp>=0.5 in /localscratch/yinan.29785222.0/env/lib/python3.7/site-packages (from importlib-metadata->click->nltk) (3.7.0+computecanada)
Requirement already satisfied: typing-extensions>=3.6.4 in /localscratch/yinan.29785222.0/env/lib/python3.7/site-packages (from importlib-metadata->click->nltk) (4.1.1+computecanada)
Installing collected packages: nltk
Successfully installed nltk-3.6.3+computecanada
Looking in links: /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/nix/avx2, /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/nix/generic, /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/scikit_learn-0.22.1+computecanada-cp37-cp37m-linux_x86_64.whl
Requirement already satisfied: numpy>=1.11.0 in /cvmfs/soft.computecanada.ca/easybuild/software/2017/Core/scipy-stack/2019a/lib/python3.7/site-packages (from scikit-learn==0.22.1) (1.16.0)
Requirement already satisfied: scipy>=0.17.0 in /localscratch/yinan.29785222.0/env/lib/python3.7/site-packages (from scikit-learn==0.22.1) (1.4.1+computecanada)
Requirement already satisfied: joblib>=0.11 in /localscratch/yinan.29785222.0/env/lib/python3.7/site-packages (from scikit-learn==0.22.1) (1.1.0+computecanada)
Installing collected packages: scikit-learn
Successfully installed scikit-learn-0.22.1+computecanada
Looking in links: /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/nix/avx2, /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/nix/generic, /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic
Requirement already satisfied: tokenizers==0.5.2 in /localscratch/yinan.29785222.0/env/lib/python3.7/site-packages (0.5.2+computecanada)
wandb: Appending key for api.wandb.ai to your netrc file: /home/yinan/.netrc
Starting Task
2022-03-30 11:15:14.384009: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1
[nltk_data] Downloading package stopwords to /home/yinan/nltk_data...
[nltk_data]   Package stopwords is already up-to-date!
[nltk_data] Downloading package wordnet to /home/yinan/nltk_data...
[nltk_data]   Package wordnet is already up-to-date!
wandb: Currently logged in as: yinanazhou (use `wandb login --relogin` to force relogin)
wandb: wandb version 0.12.11 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
2022-03-30 11:15:30.830251: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1
wandb: Tracking run with wandb version 0.12.5
wandb: Syncing run avid-silence-2
wandb: ⭐️ View project at https://wandb.ai/yinanazhou/xl_512_bs_8_lr_1e06_es_3_lc_True_nr_True_sr_False_stem_False_lemma_True_repeat_1_fold_1
wandb: 🚀 View run at https://wandb.ai/yinanazhou/xl_512_bs_8_lr_1e06_es_3_lc_True_nr_True_sr_False_stem_False_lemma_True_repeat_1_fold_1/runs/y3gkvzux
wandb: Run data is saved locally in /project/6002780/yinan/Thesis_MER_Lyrics/lyric-emotion/wandb/run-20220330_111528-y3gkvzux
wandb: Run `wandb offline` to turn off syncing.
wandb: Network error (ReadTimeout), entering retry loop.

Validation loss decreased (inf --> 1.439309).  Saving model ...
Validation loss decreased (1.439309 --> 1.419105).  Saving model ...
Validation loss decreased (1.419105 --> 1.402491).  Saving model ...
Validation loss decreased (1.402491 --> 1.389058).  Saving model ...
Validation loss decreased (1.389058 --> 1.378937).  Saving model ...
Validation loss decreased (1.378937 --> 1.370089).  Saving model ...
Validation loss decreased (1.370089 --> 1.363380).  Saving model ...
Validation loss decreased (1.363380 --> 1.357554).  Saving model ...
Validation loss decreased (1.357554 --> 1.351885).  Saving model ...
Validation loss decreased (1.351885 --> 1.346473).  Saving model ...
Validation loss decreased (1.346473 --> 1.340653).  Saving model ...
Validation loss decreased (1.340653 --> 1.335815).  Saving model ...
Validation loss decreased (1.335815 --> 1.330758).  Saving model ...
Validation loss decreased (1.330758 --> 1.325765).  Saving model ...
Validation loss decreased (1.325765 --> 1.320288).  Saving model ...
Validation loss decreased (1.320288 --> 1.316206).  Saving model ...
Validation loss decreased (1.316206 --> 1.310600).  Saving model ...
Validation loss decreased (1.310600 --> 1.304590).  Saving model ...
Validation loss decreased (1.304590 --> 1.299087).  Saving model ...
Validation loss decreased (1.299087 --> 1.293122).  Saving model ...
Validation loss decreased (1.293122 --> 1.287364).  Saving model ...
Validation loss decreased (1.287364 --> 1.280271).  Saving model ...
Validation loss decreased (1.280271 --> 1.276599).  Saving model ...
Validation loss decreased (1.276599 --> 1.269277).  Saving model ...
Validation loss decreased (1.269277 --> 1.263776).  Saving model ...
Validation loss decreased (1.263776 --> 1.259156).  Saving model ...
Validation loss decreased (1.259156 --> 1.252592).  Saving model ...
Validation loss decreased (1.252592 --> 1.248384).  Saving model ...
Validation loss decreased (1.248384 --> 1.244844).  Saving model ...
Validation loss decreased (1.244844 --> 1.243392).  Saving model ...
Validation loss decreased (1.243392 --> 1.240637).  Saving model ...
Validation loss decreased (1.240637 --> 1.235306).  Saving model ...
Validation loss decreased (1.235306 --> 1.234287).  Saving model ...
Validation loss decreased (1.234287 --> 1.228457).  Saving model ...
Validation loss decreased (1.228457 --> 1.225178).  Saving model ...
Validation loss decreased (1.225178 --> 1.218794).  Saving model ...
Validation loss decreased (1.218794 --> 1.213360).  Saving model ...
Validation loss decreased (1.213360 --> 1.211831).  Saving model ...
Validation loss decreased (1.211831 --> 1.207428).  Saving model ...
Validation loss decreased (1.207428 --> 1.205810).  Saving model ...
Validation loss decreased (1.205810 --> 1.198795).  Saving model ...
Validation loss decreased (1.198795 --> 1.194625).  Saving model ...
Validation loss decreased (1.194625 --> 1.191737).  Saving model ...
EarlyStopping counter: 1 out of 3.0
Validation loss decreased (1.191737 --> 1.186692).  Saving model ...
Validation loss decreased (1.186692 --> 1.184148).  Saving model ...
Validation loss decreased (1.184148 --> 1.182458).  Saving model ...
EarlyStopping counter: 1 out of 3.0
Validation loss decreased (1.182458 --> 1.176040).  Saving model ...
Validation loss decreased (1.176040 --> 1.176023).  Saving model ...
Validation loss decreased (1.176023 --> 1.169389).  Saving model ...
Validation loss decreased (1.169389 --> 1.166622).  Saving model ...
Validation loss decreased (1.166622 --> 1.166117).  Saving model ...
Validation loss decreased (1.166117 --> 1.163209).  Saving model ...
Validation loss decreased (1.163209 --> 1.163055).  Saving model ...
Validation loss decreased (1.163055 --> 1.157392).  Saving model ...
Validation loss decreased (1.157392 --> 1.151576).  Saving model ...
Validation loss decreased (1.151576 --> 1.147402).  Saving model ...
Validation loss decreased (1.147402 --> 1.141575).  Saving model ...
EarlyStopping counter: 1 out of 3.0
Validation loss decreased (1.141575 --> 1.139336).  Saving model ...
Validation loss decreased (1.139336 --> 1.137451).  Saving model ...
Validation loss decreased (1.137451 --> 1.132357).  Saving model ...
EarlyStopping counter: 1 out of 3.0
EarlyStopping counter: 2 out of 3.0
Validation loss decreased (1.132357 --> 1.128460).  Saving model ...
Validation loss decreased (1.128460 --> 1.125789).  Saving model ...
Validation loss decreased (1.125789 --> 1.119857).  Saving model ...
Validation loss decreased (1.119857 --> 1.119150).  Saving model ...
Validation loss decreased (1.119150 --> 1.117602).  Saving model ...
Validation loss decreased (1.117602 --> 1.110618).  Saving model ...
Validation loss decreased (1.110618 --> 1.109347).  Saving model ...
Validation loss decreased (1.109347 --> 1.108646).  Saving model ...
Validation loss decreased (1.108646 --> 1.105010).  Saving model ...
Validation loss decreased (1.105010 --> 1.101256).  Saving model ...
Validation loss decreased (1.101256 --> 1.100464).  Saving model ...
EarlyStopping counter: 1 out of 3.0
Validation loss decreased (1.100464 --> 1.095709).  Saving model ...
Validation loss decreased (1.095709 --> 1.090373).  Saving model ...
Validation loss decreased (1.090373 --> 1.087978).  Saving model ...
EarlyStopping counter: 1 out of 3.0
EarlyStopping counter: 2 out of 3.0
EarlyStopping counter: 3 out of 3.0
/localscratch/yinan.29785222.0/env/lib/python3.7/site-packages/torch/nn/functional.py:1794: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.
  warnings.warn("nn.functional.tanh is deprecated. Use torch.tanh instead.")
/localscratch/yinan.29785222.0/env/lib/python3.7/site-packages/transformers/optimization.py:155: UserWarning: This overload of add_ is deprecated:
	add_(Number alpha, Tensor other)
Consider using one of the following signatures instead:
	add_(Tensor other, *, Number alpha) (Triggered internally at  ../torch/csrc/utils/python_arg_parser.cpp:1025.)
  exp_avg.mul_(beta1).add_(1.0 - beta1, grad)
wandb: Waiting for W&B process to finish, PID 144025... (success).
wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: \ 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: | 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: / 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: \ 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: | 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: / 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: \ 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: | 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: / 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: \ 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: | 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: / 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb:                                                                                
wandb: Run history:
wandb:     e_F1 ▁▂▂▄▄▅▅▅▅▅▆▆▆▇▆▆▆▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇█▇████
wandb:   e_loss █▇▇▆▆▆▆▆▅▅▅▅▄▄▄▄▄▄▃▃▃▃▃▃▃▃▂▂▂▂▂▂▂▂▁▁▁▁▁▁
wandb:     t_F1 ▁▁▂▃▃▃▄▃▄▄▅▅▅▅▅▆▆▆▇▆▆▇▇▇▇▇▇▇█▇█▇▇▇██▇███
wandb:   t_loss █▇▇▇▇▇▇▆▆▆▆▅▅▅▅▄▄▄▄▄▄▃▃▃▃▃▃▃▂▂▂▂▂▂▂▁▂▁▁▁
wandb: 
wandb: Run summary:
wandb:     e_F1 51.46746
wandb:   e_loss 1.0887
wandb:     t_F1 59.55787
wandb:   t_loss 0.94185
wandb: 
wandb: Synced 4 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Synced avid-silence-2: https://wandb.ai/yinanazhou/xl_512_bs_8_lr_1e06_es_3_lc_True_nr_True_sr_False_stem_False_lemma_True_repeat_1_fold_1/runs/y3gkvzux
wandb: Find logs at: ./wandb/run-20220330_111528-y3gkvzux/logs/debug.log
wandb: 

wandb: wandb version 0.12.11 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
2022-03-30 12:10:37.022768: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1
wandb: Tracking run with wandb version 0.12.5
wandb: Syncing run lunar-mountain-2
wandb: ⭐️ View project at https://wandb.ai/yinanazhou/xl_512_bs_8_lr_1e06_es_3_lc_True_nr_True_sr_False_stem_False_lemma_True_repeat_1_fold_2
wandb: 🚀 View run at https://wandb.ai/yinanazhou/xl_512_bs_8_lr_1e06_es_3_lc_True_nr_True_sr_False_stem_False_lemma_True_repeat_1_fold_2/runs/qlcbf6ob
wandb: Run data is saved locally in /project/6002780/yinan/Thesis_MER_Lyrics/lyric-emotion/wandb/run-20220330_121034-qlcbf6ob
wandb: Run `wandb offline` to turn off syncing.
wandb: Network error (ReadTimeout), entering retry loop.

Validation loss decreased (inf --> 1.476911).  Saving model ...
Validation loss decreased (1.476911 --> 1.445189).  Saving model ...
Validation loss decreased (1.445189 --> 1.420707).  Saving model ...
Validation loss decreased (1.420707 --> 1.403415).  Saving model ...
Validation loss decreased (1.403415 --> 1.390684).  Saving model ...
Validation loss decreased (1.390684 --> 1.381265).  Saving model ...
Validation loss decreased (1.381265 --> 1.373630).  Saving model ...
Validation loss decreased (1.373630 --> 1.366971).  Saving model ...
Validation loss decreased (1.366971 --> 1.360647).  Saving model ...
Validation loss decreased (1.360647 --> 1.355105).  Saving model ...
Validation loss decreased (1.355105 --> 1.350675).  Saving model ...
Validation loss decreased (1.350675 --> 1.345737).  Saving model ...
Validation loss decreased (1.345737 --> 1.341026).  Saving model ...
Validation loss decreased (1.341026 --> 1.336565).  Saving model ...
Validation loss decreased (1.336565 --> 1.332193).  Saving model ...
Validation loss decreased (1.332193 --> 1.326879).  Saving model ...
Validation loss decreased (1.326879 --> 1.321739).  Saving model ...
Validation loss decreased (1.321739 --> 1.316394).  Saving model ...
Validation loss decreased (1.316394 --> 1.311258).  Saving model ...
Validation loss decreased (1.311258 --> 1.306267).  Saving model ...
Validation loss decreased (1.306267 --> 1.301518).  Saving model ...
Validation loss decreased (1.301518 --> 1.295358).  Saving model ...
Validation loss decreased (1.295358 --> 1.290014).  Saving model ...
Validation loss decreased (1.290014 --> 1.284088).  Saving model ...
Validation loss decreased (1.284088 --> 1.278495).  Saving model ...
Validation loss decreased (1.278495 --> 1.273277).  Saving model ...
Validation loss decreased (1.273277 --> 1.267358).  Saving model ...
Validation loss decreased (1.267358 --> 1.260614).  Saving model ...
Validation loss decreased (1.260614 --> 1.254859).  Saving model ...
Validation loss decreased (1.254859 --> 1.247728).  Saving model ...
Validation loss decreased (1.247728 --> 1.241543).  Saving model ...
Validation loss decreased (1.241543 --> 1.235126).  Saving model ...
Validation loss decreased (1.235126 --> 1.228730).  Saving model ...
Validation loss decreased (1.228730 --> 1.222950).  Saving model ...
Validation loss decreased (1.222950 --> 1.218516).  Saving model ...
Validation loss decreased (1.218516 --> 1.213181).  Saving model ...
Validation loss decreased (1.213181 --> 1.206719).  Saving model ...
Validation loss decreased (1.206719 --> 1.199682).  Saving model ...
Validation loss decreased (1.199682 --> 1.193925).  Saving model ...
Validation loss decreased (1.193925 --> 1.187869).  Saving model ...
Validation loss decreased (1.187869 --> 1.182085).  Saving model ...
Validation loss decreased (1.182085 --> 1.175960).  Saving model ...
Validation loss decreased (1.175960 --> 1.170847).  Saving model ...
Validation loss decreased (1.170847 --> 1.164759).  Saving model ...
Validation loss decreased (1.164759 --> 1.159125).  Saving model ...
Validation loss decreased (1.159125 --> 1.153786).  Saving model ...
Validation loss decreased (1.153786 --> 1.148354).  Saving model ...
Validation loss decreased (1.148354 --> 1.143431).  Saving model ...
Validation loss decreased (1.143431 --> 1.137224).  Saving model ...
Validation loss decreased (1.137224 --> 1.129997).  Saving model ...
Validation loss decreased (1.129997 --> 1.124096).  Saving model ...
Validation loss decreased (1.124096 --> 1.117854).  Saving model ...
Validation loss decreased (1.117854 --> 1.111996).  Saving model ...
Validation loss decreased (1.111996 --> 1.106968).  Saving model ...
Validation loss decreased (1.106968 --> 1.100403).  Saving model ...
Validation loss decreased (1.100403 --> 1.094522).  Saving model ...
Validation loss decreased (1.094522 --> 1.089784).  Saving model ...
Validation loss decreased (1.089784 --> 1.084554).  Saving model ...
Validation loss decreased (1.084554 --> 1.078855).  Saving model ...
Validation loss decreased (1.078855 --> 1.072682).  Saving model ...
Validation loss decreased (1.072682 --> 1.068434).  Saving model ...
Validation loss decreased (1.068434 --> 1.064098).  Saving model ...
Validation loss decreased (1.064098 --> 1.059204).  Saving model ...
Validation loss decreased (1.059204 --> 1.055999).  Saving model ...
Validation loss decreased (1.055999 --> 1.050411).  Saving model ...
Validation loss decreased (1.050411 --> 1.046472).  Saving model ...
Validation loss decreased (1.046472 --> 1.041858).  Saving model ...
Validation loss decreased (1.041858 --> 1.038741).  Saving model ...
Validation loss decreased (1.038741 --> 1.033656).  Saving model ...
Validation loss decreased (1.033656 --> 1.028639).  Saving model ...
Validation loss decreased (1.028639 --> 1.025159).  Saving model ...
Validation loss decreased (1.025159 --> 1.022519).  Saving model ...
Validation loss decreased (1.022519 --> 1.015976).  Saving model ...
Validation loss decreased (1.015976 --> 1.012378).  Saving model ...
Validation loss decreased (1.012378 --> 1.008276).  Saving model ...
Validation loss decreased (1.008276 --> 1.003948).  Saving model ...
Validation loss decreased (1.003948 --> 1.000571).  Saving model ...
Validation loss decreased (1.000571 --> 0.997639).  Saving model ...
Validation loss decreased (0.997639 --> 0.994557).  Saving model ...
Validation loss decreased (0.994557 --> 0.990475).  Saving model ...
Validation loss decreased (0.990475 --> 0.986097).  Saving model ...
Validation loss decreased (0.986097 --> 0.983326).  Saving model ...
Validation loss decreased (0.983326 --> 0.980850).  Saving model ...
Validation loss decreased (0.980850 --> 0.978078).  Saving model ...
Validation loss decreased (0.978078 --> 0.976227).  Saving model ...
Validation loss decreased (0.976227 --> 0.973458).  Saving model ...
Validation loss decreased (0.973458 --> 0.970842).  Saving model ...
Validation loss decreased (0.970842 --> 0.967966).  Saving model ...
Validation loss decreased (0.967966 --> 0.964261).  Saving model ...
Validation loss decreased (0.964261 --> 0.961787).  Saving model ...
Validation loss decreased (0.961787 --> 0.959861).  Saving model ...
Validation loss decreased (0.959861 --> 0.957167).  Saving model ...
Validation loss decreased (0.957167 --> 0.954976).  Saving model ...
Validation loss decreased (0.954976 --> 0.953566).  Saving model ...
Validation loss decreased (0.953566 --> 0.949957).  Saving model ...
Validation loss decreased (0.949957 --> 0.948250).  Saving model ...
Validation loss decreased (0.948250 --> 0.945681).  Saving model ...
Validation loss decreased (0.945681 --> 0.944696).  Saving model ...
Validation loss decreased (0.944696 --> 0.942262).  Saving model ...
Validation loss decreased (0.942262 --> 0.940719).  Saving model ...
Validation loss decreased (0.940719 --> 0.939636).  Saving model ...
Validation loss decreased (0.939636 --> 0.937448).  Saving model ...
Validation loss decreased (0.937448 --> 0.934700).  Saving model ...
Validation loss decreased (0.934700 --> 0.933084).  Saving model ...
Validation loss decreased (0.933084 --> 0.931367).  Saving model ...
Validation loss decreased (0.931367 --> 0.930414).  Saving model ...
Validation loss decreased (0.930414 --> 0.929321).  Saving model ...
Validation loss decreased (0.929321 --> 0.929033).  Saving model ...
Validation loss decreased (0.929033 --> 0.926900).  Saving model ...
Validation loss decreased (0.926900 --> 0.925972).  Saving model ...
Validation loss decreased (0.925972 --> 0.924280).  Saving model ...
Validation loss decreased (0.924280 --> 0.922432).  Saving model ...
Validation loss decreased (0.922432 --> 0.921970).  Saving model ...
Validation loss decreased (0.921970 --> 0.921489).  Saving model ...
Validation loss decreased (0.921489 --> 0.920526).  Saving model ...
Validation loss decreased (0.920526 --> 0.919513).  Saving model ...
Validation loss decreased (0.919513 --> 0.918778).  Saving model ...
Validation loss decreased (0.918778 --> 0.917851).  Saving model ...
EarlyStopping counter: 1 out of 3.0
Validation loss decreased (0.917851 --> 0.917408).  Saving model ...
Validation loss decreased (0.917408 --> 0.916531).  Saving model ...
Validation loss decreased (0.916531 --> 0.916396).  Saving model ...
EarlyStopping counter: 1 out of 3.0
EarlyStopping counter: 2 out of 3.0
Validation loss decreased (0.916396 --> 0.915190).  Saving model ...
Validation loss decreased (0.915190 --> 0.914698).  Saving model ...
Validation loss decreased (0.914698 --> 0.913937).  Saving model ...
EarlyStopping counter: 1 out of 3.0
Validation loss decreased (0.913937 --> 0.913095).  Saving model ...
Validation loss decreased (0.913095 --> 0.912778).  Saving model ...
EarlyStopping counter: 1 out of 3.0
EarlyStopping counter: 2 out of 3.0
EarlyStopping counter: 3 out of 3.0
/localscratch/yinan.29785222.0/env/lib/python3.7/site-packages/torch/nn/functional.py:1794: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.
  warnings.warn("nn.functional.tanh is deprecated. Use torch.tanh instead.")
wandb: Waiting for W&B process to finish, PID 147027... (success).
wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: \ 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: | 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: / 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: \ 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: | 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: / 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: \ 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: | 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: / 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb:                                                                                
wandb: Run history:
wandb:     e_F1 ▁▁▂▄▄▅▅▅▆▆▆▆▆▆▇▇▇▇▇▇▇▇▇██▇██████████████
wandb:   e_loss █▇▇▇▇▆▆▆▆▅▅▅▄▄▄▄▄▃▃▃▃▂▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁
wandb:     t_F1 ▁▁▂▃▃▄▄▄▅▅▅▅▅▅▅▆▆▆▆▆▆▆▇▇▇▇▇▇▇▇█▇████████
wandb:   t_loss █▇▇▇▇▇▆▆▆▆▆▆▅▅▅▅▄▄▄▄▄▄▃▃▃▃▃▃▂▂▂▂▂▂▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:     e_F1 62.49988
wandb:   e_loss 0.91331
wandb:     t_F1 70.02009
wandb:   t_loss 0.78579
wandb: 
wandb: Synced 4 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Synced lunar-mountain-2: https://wandb.ai/yinanazhou/xl_512_bs_8_lr_1e06_es_3_lc_True_nr_True_sr_False_stem_False_lemma_True_repeat_1_fold_2/runs/qlcbf6ob
wandb: Find logs at: ./wandb/run-20220330_121034-qlcbf6ob/logs/debug.log
wandb: 

wandb: wandb version 0.12.11 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
2022-03-30 13:36:21.859831: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1
wandb: Tracking run with wandb version 0.12.5
wandb: Syncing run lucky-tree-2
wandb: ⭐️ View project at https://wandb.ai/yinanazhou/xl_512_bs_8_lr_1e06_es_3_lc_True_nr_True_sr_False_stem_False_lemma_True_repeat_2_fold_1
wandb: 🚀 View run at https://wandb.ai/yinanazhou/xl_512_bs_8_lr_1e06_es_3_lc_True_nr_True_sr_False_stem_False_lemma_True_repeat_2_fold_1/runs/3212gv2q
wandb: Run data is saved locally in /project/6002780/yinan/Thesis_MER_Lyrics/lyric-emotion/wandb/run-20220330_133619-3212gv2q
wandb: Run `wandb offline` to turn off syncing.

Validation loss decreased (inf --> 1.434145).  Saving model ...
Validation loss decreased (1.434145 --> 1.416086).  Saving model ...
Validation loss decreased (1.416086 --> 1.402244).  Saving model ...
Validation loss decreased (1.402244 --> 1.391470).  Saving model ...
Validation loss decreased (1.391470 --> 1.383067).  Saving model ...
Validation loss decreased (1.383067 --> 1.376360).  Saving model ...
Validation loss decreased (1.376360 --> 1.370339).  Saving model ...
Validation loss decreased (1.370339 --> 1.365070).  Saving model ...
Validation loss decreased (1.365070 --> 1.360298).  Saving model ...
Validation loss decreased (1.360298 --> 1.356126).  Saving model ...
Validation loss decreased (1.356126 --> 1.350580).  Saving model ...
Validation loss decreased (1.350580 --> 1.345399).  Saving model ...
Validation loss decreased (1.345399 --> 1.340264).  Saving model ...
Validation loss decreased (1.340264 --> 1.335692).  Saving model ...
Validation loss decreased (1.335692 --> 1.330274).  Saving model ...
Validation loss decreased (1.330274 --> 1.324417).  Saving model ...
Validation loss decreased (1.324417 --> 1.318654).  Saving model ...
Validation loss decreased (1.318654 --> 1.313047).  Saving model ...
Validation loss decreased (1.313047 --> 1.307394).  Saving model ...
Validation loss decreased (1.307394 --> 1.301520).  Saving model ...
Validation loss decreased (1.301520 --> 1.295343).  Saving model ...
Validation loss decreased (1.295343 --> 1.287479).  Saving model ...
Validation loss decreased (1.287479 --> 1.280304).  Saving model ...
Validation loss decreased (1.280304 --> 1.273869).  Saving model ...
Validation loss decreased (1.273869 --> 1.266527).  Saving model ...
Validation loss decreased (1.266527 --> 1.259156).  Saving model ...
Validation loss decreased (1.259156 --> 1.251899).  Saving model ...
Validation loss decreased (1.251899 --> 1.245985).  Saving model ...
Validation loss decreased (1.245985 --> 1.238407).  Saving model ...
Validation loss decreased (1.238407 --> 1.232599).  Saving model ...
Validation loss decreased (1.232599 --> 1.225320).  Saving model ...
Validation loss decreased (1.225320 --> 1.219585).  Saving model ...
Validation loss decreased (1.219585 --> 1.210744).  Saving model ...
Validation loss decreased (1.210744 --> 1.203877).  Saving model ...
Validation loss decreased (1.203877 --> 1.198934).  Saving model ...
Validation loss decreased (1.198934 --> 1.191974).  Saving model ...
Validation loss decreased (1.191974 --> 1.186367).  Saving model ...
Validation loss decreased (1.186367 --> 1.181318).  Saving model ...
Validation loss decreased (1.181318 --> 1.174456).  Saving model ...
Validation loss decreased (1.174456 --> 1.171577).  Saving model ...
Validation loss decreased (1.171577 --> 1.166301).  Saving model ...
Validation loss decreased (1.166301 --> 1.162788).  Saving model ...
Validation loss decreased (1.162788 --> 1.156816).  Saving model ...
Validation loss decreased (1.156816 --> 1.153091).  Saving model ...
Validation loss decreased (1.153091 --> 1.148833).  Saving model ...
Validation loss decreased (1.148833 --> 1.143724).  Saving model ...
Validation loss decreased (1.143724 --> 1.139108).  Saving model ...
Validation loss decreased (1.139108 --> 1.135645).  Saving model ...
Validation loss decreased (1.135645 --> 1.130464).  Saving model ...
Validation loss decreased (1.130464 --> 1.127967).  Saving model ...
Validation loss decreased (1.127967 --> 1.124536).  Saving model ...
Validation loss decreased (1.124536 --> 1.119237).  Saving model ...
Validation loss decreased (1.119237 --> 1.113641).  Saving model ...
Validation loss decreased (1.113641 --> 1.111210).  Saving model ...
Validation loss decreased (1.111210 --> 1.109177).  Saving model ...
Validation loss decreased (1.109177 --> 1.103936).  Saving model ...
Validation loss decreased (1.103936 --> 1.099661).  Saving model ...
Validation loss decreased (1.099661 --> 1.095069).  Saving model ...
Validation loss decreased (1.095069 --> 1.091473).  Saving model ...
Validation loss decreased (1.091473 --> 1.087813).  Saving model ...
Validation loss decreased (1.087813 --> 1.082167).  Saving model ...
Validation loss decreased (1.082167 --> 1.080421).  Saving model ...
Validation loss decreased (1.080421 --> 1.076068).  Saving model ...
Validation loss decreased (1.076068 --> 1.072041).  Saving model ...
Validation loss decreased (1.072041 --> 1.070400).  Saving model ...
Validation loss decreased (1.070400 --> 1.066374).  Saving model ...
Validation loss decreased (1.066374 --> 1.064425).  Saving model ...
Validation loss decreased (1.064425 --> 1.060715).  Saving model ...
Validation loss decreased (1.060715 --> 1.058712).  Saving model ...
Validation loss decreased (1.058712 --> 1.057090).  Saving model ...
Validation loss decreased (1.057090 --> 1.053555).  Saving model ...
Validation loss decreased (1.053555 --> 1.048718).  Saving model ...
Validation loss decreased (1.048718 --> 1.045027).  Saving model ...
Validation loss decreased (1.045027 --> 1.042308).  Saving model ...
Validation loss decreased (1.042308 --> 1.040120).  Saving model ...
Validation loss decreased (1.040120 --> 1.037247).  Saving model ...
Validation loss decreased (1.037247 --> 1.034215).  Saving model ...
Validation loss decreased (1.034215 --> 1.034212).  Saving model ...
Validation loss decreased (1.034212 --> 1.031643).  Saving model ...
Validation loss decreased (1.031643 --> 1.030315).  Saving model ...
Validation loss decreased (1.030315 --> 1.027228).  Saving model ...
Validation loss decreased (1.027228 --> 1.024925).  Saving model ...
Validation loss decreased (1.024925 --> 1.023668).  Saving model ...
Validation loss decreased (1.023668 --> 1.021691).  Saving model ...
Validation loss decreased (1.021691 --> 1.018200).  Saving model ...
EarlyStopping counter: 1 out of 3.0
Validation loss decreased (1.018200 --> 1.016231).  Saving model ...
Validation loss decreased (1.016231 --> 1.015010).  Saving model ...
Validation loss decreased (1.015010 --> 1.010754).  Saving model ...
Validation loss decreased (1.010754 --> 1.008629).  Saving model ...
Validation loss decreased (1.008629 --> 1.007375).  Saving model ...
Validation loss decreased (1.007375 --> 1.003430).  Saving model ...
Validation loss decreased (1.003430 --> 1.000939).  Saving model ...
Validation loss decreased (1.000939 --> 0.999657).  Saving model ...
EarlyStopping counter: 1 out of 3.0
Validation loss decreased (0.999657 --> 0.997613).  Saving model ...
Validation loss decreased (0.997613 --> 0.994084).  Saving model ...
EarlyStopping counter: 1 out of 3.0
EarlyStopping counter: 2 out of 3.0
Validation loss decreased (0.994084 --> 0.993658).  Saving model ...
Validation loss decreased (0.993658 --> 0.992082).  Saving model ...
EarlyStopping counter: 1 out of 3.0
Validation loss decreased (0.992082 --> 0.991048).  Saving model ...
Validation loss decreased (0.991048 --> 0.988475).  Saving model ...
Validation loss decreased (0.988475 --> 0.987233).  Saving model ...
Validation loss decreased (0.987233 --> 0.986568).  Saving model ...
Validation loss decreased (0.986568 --> 0.985281).  Saving model ...
Validation loss decreased (0.985281 --> 0.984422).  Saving model ...
Validation loss decreased (0.984422 --> 0.982376).  Saving model ...
Validation loss decreased (0.982376 --> 0.981406).  Saving model ...
EarlyStopping counter: 1 out of 3.0
EarlyStopping counter: 2 out of 3.0
Validation loss decreased (0.981406 --> 0.980580).  Saving model ...
Validation loss decreased (0.980580 --> 0.979710).  Saving model ...
Validation loss decreased (0.979710 --> 0.977651).  Saving model ...
Validation loss decreased (0.977651 --> 0.977630).  Saving model ...
EarlyStopping counter: 1 out of 3.0
Validation loss decreased (0.977630 --> 0.975050).  Saving model ...
Validation loss decreased (0.975050 --> 0.973191).  Saving model ...
Validation loss decreased (0.973191 --> 0.972675).  Saving model ...
Validation loss decreased (0.972675 --> 0.972147).  Saving model ...
Validation loss decreased (0.972147 --> 0.971502).  Saving model ...
EarlyStopping counter: 1 out of 3.0
EarlyStopping counter: 2 out of 3.0
Validation loss decreased (0.971502 --> 0.971109).  Saving model ...
Validation loss decreased (0.971109 --> 0.970174).  Saving model ...
EarlyStopping counter: 1 out of 3.0
EarlyStopping counter: 2 out of 3.0
Validation loss decreased (0.970174 --> 0.969040).  Saving model ...
Validation loss decreased (0.969040 --> 0.968579).  Saving model ...
Validation loss decreased (0.968579 --> 0.965716).  Saving model ...
EarlyStopping counter: 1 out of 3.0
Validation loss decreased (0.965716 --> 0.965485).  Saving model ...
Validation loss decreased (0.965485 --> 0.964102).  Saving model ...
EarlyStopping counter: 1 out of 3.0
EarlyStopping counter: 2 out of 3.0
Validation loss decreased (0.964102 --> 0.963605).  Saving model ...
EarlyStopping counter: 1 out of 3.0
EarlyStopping counter: 2 out of 3.0
EarlyStopping counter: 3 out of 3.0
/localscratch/yinan.29785222.0/env/lib/python3.7/site-packages/torch/nn/functional.py:1794: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.
  warnings.warn("nn.functional.tanh is deprecated. Use torch.tanh instead.")
wandb: Waiting for W&B process to finish, PID 151600... (success).
wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: \ 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: | 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: / 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: \ 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: | 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: / 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: \ 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: | 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: / 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: \ 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: | 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb:                                                                                
wandb: Run history:
wandb:     e_F1 ▁▁▃▄▄▅▅▅▆▆▆▆▆▆▆▇▇▇▇▇▇▇▇▇▇▇▇▇▇█▇█████████
wandb:   e_loss ██▇▇▇▆▆▆▅▅▅▄▄▄▄▃▃▃▃▂▂▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁
wandb:     t_F1 ▁▂▂▃▃▄▄▄▅▅▅▅▅▅▆▅▆▆▆▆▇▆▇▇▇▇▇▇▇█▇▇▇███████
wandb:   t_loss ██▇▇▇▇▇▆▆▆▆▅▅▅▅▅▄▄▄▄▄▃▃▃▃▃▃▂▂▂▂▂▂▂▁▂▁▁▁▁
wandb: 
wandb: Run summary:
wandb:     e_F1 60.05446
wandb:   e_loss 0.96406
wandb:     t_F1 72.15082
wandb:   t_loss 0.72504
wandb: 
wandb: Synced 4 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Synced lucky-tree-2: https://wandb.ai/yinanazhou/xl_512_bs_8_lr_1e06_es_3_lc_True_nr_True_sr_False_stem_False_lemma_True_repeat_2_fold_1/runs/3212gv2q
wandb: Find logs at: ./wandb/run-20220330_133619-3212gv2q/logs/debug.log
wandb: 

wandb: wandb version 0.12.11 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
2022-03-30 15:04:12.203745: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1
wandb: Tracking run with wandb version 0.12.5
wandb: Syncing run ethereal-wildflower-2
wandb: ⭐️ View project at https://wandb.ai/yinanazhou/xl_512_bs_8_lr_1e06_es_3_lc_True_nr_True_sr_False_stem_False_lemma_True_repeat_2_fold_2
wandb: 🚀 View run at https://wandb.ai/yinanazhou/xl_512_bs_8_lr_1e06_es_3_lc_True_nr_True_sr_False_stem_False_lemma_True_repeat_2_fold_2/runs/51z1h2i0
wandb: Run data is saved locally in /project/6002780/yinan/Thesis_MER_Lyrics/lyric-emotion/wandb/run-20220330_150409-51z1h2i0
wandb: Run `wandb offline` to turn off syncing.

Validation loss decreased (inf --> 1.407310).  Saving model ...
Validation loss decreased (1.407310 --> 1.397475).  Saving model ...
Validation loss decreased (1.397475 --> 1.390153).  Saving model ...
Validation loss decreased (1.390153 --> 1.383693).  Saving model ...
Validation loss decreased (1.383693 --> 1.378304).  Saving model ...
Validation loss decreased (1.378304 --> 1.373670).  Saving model ...
Validation loss decreased (1.373670 --> 1.368758).  Saving model ...
Validation loss decreased (1.368758 --> 1.364502).  Saving model ...
Validation loss decreased (1.364502 --> 1.360584).  Saving model ...
Validation loss decreased (1.360584 --> 1.356151).  Saving model ...
Validation loss decreased (1.356151 --> 1.351880).  Saving model ...
Validation loss decreased (1.351880 --> 1.347262).  Saving model ...
Validation loss decreased (1.347262 --> 1.342919).  Saving model ...
Validation loss decreased (1.342919 --> 1.338375).  Saving model ...
Validation loss decreased (1.338375 --> 1.333767).  Saving model ...
Validation loss decreased (1.333767 --> 1.329208).  Saving model ...
Validation loss decreased (1.329208 --> 1.324018).  Saving model ...
Validation loss decreased (1.324018 --> 1.318902).  Saving model ...
Validation loss decreased (1.318902 --> 1.313643).  Saving model ...
Validation loss decreased (1.313643 --> 1.308112).  Saving model ...
Validation loss decreased (1.308112 --> 1.302754).  Saving model ...
Validation loss decreased (1.302754 --> 1.296784).  Saving model ...
Validation loss decreased (1.296784 --> 1.291207).  Saving model ...
Validation loss decreased (1.291207 --> 1.284810).  Saving model ...
Validation loss decreased (1.284810 --> 1.277847).  Saving model ...
Validation loss decreased (1.277847 --> 1.269836).  Saving model ...
Validation loss decreased (1.269836 --> 1.261981).  Saving model ...
Validation loss decreased (1.261981 --> 1.255088).  Saving model ...
Validation loss decreased (1.255088 --> 1.249415).  Saving model ...
Validation loss decreased (1.249415 --> 1.242685).  Saving model ...
Validation loss decreased (1.242685 --> 1.236713).  Saving model ...
Validation loss decreased (1.236713 --> 1.228189).  Saving model ...
Validation loss decreased (1.228189 --> 1.221285).  Saving model ...
Validation loss decreased (1.221285 --> 1.216175).  Saving model ...
Validation loss decreased (1.216175 --> 1.210265).  Saving model ...
Validation loss decreased (1.210265 --> 1.203011).  Saving model ...
Validation loss decreased (1.203011 --> 1.195615).  Saving model ...
Validation loss decreased (1.195615 --> 1.191325).  Saving model ...
Validation loss decreased (1.191325 --> 1.185563).  Saving model ...
Validation loss decreased (1.185563 --> 1.179662).  Saving model ...
Validation loss decreased (1.179662 --> 1.173938).  Saving model ...
Validation loss decreased (1.173938 --> 1.169133).  Saving model ...
Validation loss decreased (1.169133 --> 1.162918).  Saving model ...
Validation loss decreased (1.162918 --> 1.157409).  Saving model ...
Validation loss decreased (1.157409 --> 1.153677).  Saving model ...
Validation loss decreased (1.153677 --> 1.147460).  Saving model ...
Validation loss decreased (1.147460 --> 1.140639).  Saving model ...
Validation loss decreased (1.140639 --> 1.137722).  Saving model ...
Validation loss decreased (1.137722 --> 1.133146).  Saving model ...
Validation loss decreased (1.133146 --> 1.128255).  Saving model ...
Validation loss decreased (1.128255 --> 1.122570).  Saving model ...
Validation loss decreased (1.122570 --> 1.116972).  Saving model ...
Validation loss decreased (1.116972 --> 1.112999).  Saving model ...
Validation loss decreased (1.112999 --> 1.108142).  Saving model ...
Validation loss decreased (1.108142 --> 1.102564).  Saving model ...
Validation loss decreased (1.102564 --> 1.097768).  Saving model ...
Validation loss decreased (1.097768 --> 1.092893).  Saving model ...
Validation loss decreased (1.092893 --> 1.090072).  Saving model ...
Validation loss decreased (1.090072 --> 1.086231).  Saving model ...
Validation loss decreased (1.086231 --> 1.083083).  Saving model ...
Validation loss decreased (1.083083 --> 1.078996).  Saving model ...
Validation loss decreased (1.078996 --> 1.073057).  Saving model ...
Validation loss decreased (1.073057 --> 1.071041).  Saving model ...
Validation loss decreased (1.071041 --> 1.066468).  Saving model ...
Validation loss decreased (1.066468 --> 1.065258).  Saving model ...
Validation loss decreased (1.065258 --> 1.058252).  Saving model ...
Validation loss decreased (1.058252 --> 1.056430).  Saving model ...
Validation loss decreased (1.056430 --> 1.050926).  Saving model ...
Validation loss decreased (1.050926 --> 1.046446).  Saving model ...
Validation loss decreased (1.046446 --> 1.044757).  Saving model ...
Validation loss decreased (1.044757 --> 1.041096).  Saving model ...
Validation loss decreased (1.041096 --> 1.038231).  Saving model ...
Validation loss decreased (1.038231 --> 1.035300).  Saving model ...
Validation loss decreased (1.035300 --> 1.032319).  Saving model ...
Validation loss decreased (1.032319 --> 1.029711).  Saving model ...
Validation loss decreased (1.029711 --> 1.027403).  Saving model ...
Validation loss decreased (1.027403 --> 1.024508).  Saving model ...
Validation loss decreased (1.024508 --> 1.020185).  Saving model ...
Validation loss decreased (1.020185 --> 1.015805).  Saving model ...
Validation loss decreased (1.015805 --> 1.012282).  Saving model ...
Validation loss decreased (1.012282 --> 1.011650).  Saving model ...
Validation loss decreased (1.011650 --> 1.007529).  Saving model ...
Validation loss decreased (1.007529 --> 1.006647).  Saving model ...
Validation loss decreased (1.006647 --> 1.003078).  Saving model ...
Validation loss decreased (1.003078 --> 0.997502).  Saving model ...
Validation loss decreased (0.997502 --> 0.996126).  Saving model ...
Validation loss decreased (0.996126 --> 0.995280).  Saving model ...
EarlyStopping counter: 1 out of 3.0
Validation loss decreased (0.995280 --> 0.994056).  Saving model ...
Validation loss decreased (0.994056 --> 0.991235).  Saving model ...
Validation loss decreased (0.991235 --> 0.987379).  Saving model ...
Validation loss decreased (0.987379 --> 0.986053).  Saving model ...
Validation loss decreased (0.986053 --> 0.985180).  Saving model ...
Validation loss decreased (0.985180 --> 0.983341).  Saving model ...
Validation loss decreased (0.983341 --> 0.979422).  Saving model ...
Validation loss decreased (0.979422 --> 0.976698).  Saving model ...
Validation loss decreased (0.976698 --> 0.975888).  Saving model ...
EarlyStopping counter: 1 out of 3.0
Validation loss decreased (0.975888 --> 0.974198).  Saving model ...
Validation loss decreased (0.974198 --> 0.971962).  Saving model ...
Validation loss decreased (0.971962 --> 0.971819).  Saving model ...
Validation loss decreased (0.971819 --> 0.968592).  Saving model ...
Validation loss decreased (0.968592 --> 0.963563).  Saving model ...
Validation loss decreased (0.963563 --> 0.962345).  Saving model ...
Validation loss decreased (0.962345 --> 0.960102).  Saving model ...
Validation loss decreased (0.960102 --> 0.959871).  Saving model ...
Validation loss decreased (0.959871 --> 0.958585).  Saving model ...
Validation loss decreased (0.958585 --> 0.956416).  Saving model ...
Validation loss decreased (0.956416 --> 0.956081).  Saving model ...
Validation loss decreased (0.956081 --> 0.953173).  Saving model ...
Validation loss decreased (0.953173 --> 0.951526).  Saving model ...
EarlyStopping counter: 1 out of 3.0
Validation loss decreased (0.951526 --> 0.951159).  Saving model ...
Validation loss decreased (0.951159 --> 0.947935).  Saving model ...
Validation loss decreased (0.947935 --> 0.946579).  Saving model ...
Validation loss decreased (0.946579 --> 0.944477).  Saving model ...
EarlyStopping counter: 1 out of 3.0
Validation loss decreased (0.944477 --> 0.943291).  Saving model ...
Validation loss decreased (0.943291 --> 0.943237).  Saving model ...
Validation loss decreased (0.943237 --> 0.942628).  Saving model ...
Validation loss decreased (0.942628 --> 0.942187).  Saving model ...
Validation loss decreased (0.942187 --> 0.941545).  Saving model ...
EarlyStopping counter: 1 out of 3.0
EarlyStopping counter: 2 out of 3.0
Validation loss decreased (0.941545 --> 0.939627).  Saving model ...
Validation loss decreased (0.939627 --> 0.936359).  Saving model ...
Validation loss decreased (0.936359 --> 0.934291).  Saving model ...
EarlyStopping counter: 1 out of 3.0
EarlyStopping counter: 2 out of 3.0
EarlyStopping counter: 3 out of 3.0
/localscratch/yinan.29785222.0/env/lib/python3.7/site-packages/torch/nn/functional.py:1794: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.
  warnings.warn("nn.functional.tanh is deprecated. Use torch.tanh instead.")
wandb: Waiting for W&B process to finish, PID 156278... (success).
wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: \ 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: | 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: / 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: \ 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: | 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: / 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: \ 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: | 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: / 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb:                                                                                
wandb: Run history:
wandb:     e_F1 ▁▂▃▄▅▅▅▆▆▆▆▆▆▆▆▆▇▇▇▇▇▇▇▇▇██▇████████████
wandb:   e_loss ███▇▇▇▇▆▆▆▅▅▅▄▄▄▄▃▃▃▃▃▂▂▂▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁
wandb:     t_F1 ▁▁▂▃▃▄▃▄▅▅▅▅▆▆▆▆▆▆▆▆▇▆▇▇▇▇▆▇▇▇▇██▇█▇████
wandb:   t_loss ████▇▇▇▇▆▆▆▆▅▅▅▅▅▄▄▄▄▄▃▃▃▃▃▃▃▂▂▂▂▂▂▂▂▁▁▁
wandb: 
wandb: Run summary:
wandb:     e_F1 62.46323
wandb:   e_loss 0.93531
wandb:     t_F1 67.96149
wandb:   t_loss 0.7851
wandb: 
wandb: Synced 4 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Synced ethereal-wildflower-2: https://wandb.ai/yinanazhou/xl_512_bs_8_lr_1e06_es_3_lc_True_nr_True_sr_False_stem_False_lemma_True_repeat_2_fold_2/runs/51z1h2i0
wandb: Find logs at: ./wandb/run-20220330_150409-51z1h2i0/logs/debug.log
wandb: 

wandb: wandb version 0.12.11 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
2022-03-30 16:28:48.653449: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1
wandb: Tracking run with wandb version 0.12.5
wandb: Syncing run true-violet-2
wandb: ⭐️ View project at https://wandb.ai/yinanazhou/xl_512_bs_8_lr_1e06_es_3_lc_True_nr_True_sr_False_stem_False_lemma_True_repeat_3_fold_1
wandb: 🚀 View run at https://wandb.ai/yinanazhou/xl_512_bs_8_lr_1e06_es_3_lc_True_nr_True_sr_False_stem_False_lemma_True_repeat_3_fold_1/runs/3l94n1ra
wandb: Run data is saved locally in /project/6002780/yinan/Thesis_MER_Lyrics/lyric-emotion/wandb/run-20220330_162846-3l94n1ra
wandb: Run `wandb offline` to turn off syncing.

Validation loss decreased (inf --> 1.446662).  Saving model ...
Validation loss decreased (1.446662 --> 1.418008).  Saving model ...
Validation loss decreased (1.418008 --> 1.397886).  Saving model ...
Validation loss decreased (1.397886 --> 1.383736).  Saving model ...
Validation loss decreased (1.383736 --> 1.372795).  Saving model ...
Validation loss decreased (1.372795 --> 1.364056).  Saving model ...
Validation loss decreased (1.364056 --> 1.357138).  Saving model ...
Validation loss decreased (1.357138 --> 1.351293).  Saving model ...
Validation loss decreased (1.351293 --> 1.345734).  Saving model ...
Validation loss decreased (1.345734 --> 1.341001).  Saving model ...
Validation loss decreased (1.341001 --> 1.336183).  Saving model ...
Validation loss decreased (1.336183 --> 1.331547).  Saving model ...
Validation loss decreased (1.331547 --> 1.326570).  Saving model ...
Validation loss decreased (1.326570 --> 1.321997).  Saving model ...
Validation loss decreased (1.321997 --> 1.316723).  Saving model ...
Validation loss decreased (1.316723 --> 1.311443).  Saving model ...
Validation loss decreased (1.311443 --> 1.305749).  Saving model ...
Validation loss decreased (1.305749 --> 1.299900).  Saving model ...
Validation loss decreased (1.299900 --> 1.294115).  Saving model ...
Validation loss decreased (1.294115 --> 1.287909).  Saving model ...
Validation loss decreased (1.287909 --> 1.281561).  Saving model ...
Validation loss decreased (1.281561 --> 1.274954).  Saving model ...
Validation loss decreased (1.274954 --> 1.268129).  Saving model ...
Validation loss decreased (1.268129 --> 1.261090).  Saving model ...
Validation loss decreased (1.261090 --> 1.253853).  Saving model ...
Validation loss decreased (1.253853 --> 1.245267).  Saving model ...
Validation loss decreased (1.245267 --> 1.238445).  Saving model ...
Validation loss decreased (1.238445 --> 1.230850).  Saving model ...
Validation loss decreased (1.230850 --> 1.222498).  Saving model ...
Validation loss decreased (1.222498 --> 1.213545).  Saving model ...
Validation loss decreased (1.213545 --> 1.205690).  Saving model ...
Validation loss decreased (1.205690 --> 1.198554).  Saving model ...
Validation loss decreased (1.198554 --> 1.193335).  Saving model ...
Validation loss decreased (1.193335 --> 1.184587).  Saving model ...
Validation loss decreased (1.184587 --> 1.176738).  Saving model ...
Validation loss decreased (1.176738 --> 1.168761).  Saving model ...
Validation loss decreased (1.168761 --> 1.163326).  Saving model ...
Validation loss decreased (1.163326 --> 1.157833).  Saving model ...
Validation loss decreased (1.157833 --> 1.151419).  Saving model ...
Validation loss decreased (1.151419 --> 1.146706).  Saving model ...
Validation loss decreased (1.146706 --> 1.142495).  Saving model ...
Validation loss decreased (1.142495 --> 1.136546).  Saving model ...
Validation loss decreased (1.136546 --> 1.133466).  Saving model ...
Validation loss decreased (1.133466 --> 1.129691).  Saving model ...
Validation loss decreased (1.129691 --> 1.124669).  Saving model ...
Validation loss decreased (1.124669 --> 1.119417).  Saving model ...
Validation loss decreased (1.119417 --> 1.115475).  Saving model ...
Validation loss decreased (1.115475 --> 1.111612).  Saving model ...
Validation loss decreased (1.111612 --> 1.108731).  Saving model ...
Validation loss decreased (1.108731 --> 1.106019).  Saving model ...
Validation loss decreased (1.106019 --> 1.102306).  Saving model ...
Validation loss decreased (1.102306 --> 1.097053).  Saving model ...
Validation loss decreased (1.097053 --> 1.094893).  Saving model ...
Validation loss decreased (1.094893 --> 1.090046).  Saving model ...
Validation loss decreased (1.090046 --> 1.086087).  Saving model ...
Validation loss decreased (1.086087 --> 1.083651).  Saving model ...
Validation loss decreased (1.083651 --> 1.079375).  Saving model ...
EarlyStopping counter: 1 out of 3.0
Validation loss decreased (1.079375 --> 1.075154).  Saving model ...
Validation loss decreased (1.075154 --> 1.073021).  Saving model ...
Validation loss decreased (1.073021 --> 1.069918).  Saving model ...
Validation loss decreased (1.069918 --> 1.067144).  Saving model ...
Validation loss decreased (1.067144 --> 1.063563).  Saving model ...
Validation loss decreased (1.063563 --> 1.058912).  Saving model ...
Validation loss decreased (1.058912 --> 1.056764).  Saving model ...
Validation loss decreased (1.056764 --> 1.054611).  Saving model ...
Validation loss decreased (1.054611 --> 1.050717).  Saving model ...
Validation loss decreased (1.050717 --> 1.050294).  Saving model ...
Validation loss decreased (1.050294 --> 1.046389).  Saving model ...
Validation loss decreased (1.046389 --> 1.043013).  Saving model ...
Validation loss decreased (1.043013 --> 1.039156).  Saving model ...
Validation loss decreased (1.039156 --> 1.038086).  Saving model ...
Validation loss decreased (1.038086 --> 1.034722).  Saving model ...
Validation loss decreased (1.034722 --> 1.032935).  Saving model ...
Validation loss decreased (1.032935 --> 1.031657).  Saving model ...
Validation loss decreased (1.031657 --> 1.030637).  Saving model ...
Validation loss decreased (1.030637 --> 1.029022).  Saving model ...
EarlyStopping counter: 1 out of 3.0
Validation loss decreased (1.029022 --> 1.025763).  Saving model ...
Validation loss decreased (1.025763 --> 1.024202).  Saving model ...
Validation loss decreased (1.024202 --> 1.019345).  Saving model ...
Validation loss decreased (1.019345 --> 1.016449).  Saving model ...
EarlyStopping counter: 1 out of 3.0
EarlyStopping counter: 2 out of 3.0
EarlyStopping counter: 3 out of 3.0
/localscratch/yinan.29785222.0/env/lib/python3.7/site-packages/torch/nn/functional.py:1794: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.
  warnings.warn("nn.functional.tanh is deprecated. Use torch.tanh instead.")
wandb: Waiting for W&B process to finish, PID 160830... (success).
wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: \ 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: | 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: / 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: \ 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: | 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: / 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: \ 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: | 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: / 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: \ 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: | 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: / 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: \ 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: | 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: / 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: \ 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: | 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: / 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: \ 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb:                                                                                
wandb: Run history:
wandb:     e_F1 ▁▂▃▅▅▆▆▆▆▆▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇██████████████
wandb:   e_loss █▇▇▇▆▆▆▆▆▅▅▅▅▄▄▄▄▃▃▃▃▃▃▂▂▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁
wandb:     t_F1 ▁▂▃▂▃▃▃▄▄▄▄▅▅▅▆▅▆▇▆▆▆▆▆▆▇▇▇▇▇▇█▇██▇▇████
wandb:   t_loss █▇▇▇▇▇▇▆▆▆▆▅▅▅▅▅▄▄▄▄▄▄▃▃▃▃▃▂▂▂▂▂▂▂▂▂▂▁▁▁
wandb: 
wandb: Run summary:
wandb:     e_F1 55.73544
wandb:   e_loss 1.01716
wandb:     t_F1 63.18234
wandb:   t_loss 0.9021
wandb: 
wandb: Synced 4 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Synced true-violet-2: https://wandb.ai/yinanazhou/xl_512_bs_8_lr_1e06_es_3_lc_True_nr_True_sr_False_stem_False_lemma_True_repeat_3_fold_1/runs/3l94n1ra
wandb: Find logs at: ./wandb/run-20220330_162846-3l94n1ra/logs/debug.log
wandb: 

wandb: wandb version 0.12.11 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
2022-03-30 17:24:23.133726: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1
wandb: Tracking run with wandb version 0.12.5
wandb: Syncing run zesty-frost-2
wandb: ⭐️ View project at https://wandb.ai/yinanazhou/xl_512_bs_8_lr_1e06_es_3_lc_True_nr_True_sr_False_stem_False_lemma_True_repeat_3_fold_2
wandb: 🚀 View run at https://wandb.ai/yinanazhou/xl_512_bs_8_lr_1e06_es_3_lc_True_nr_True_sr_False_stem_False_lemma_True_repeat_3_fold_2/runs/3fstizw3
wandb: Run data is saved locally in /project/6002780/yinan/Thesis_MER_Lyrics/lyric-emotion/wandb/run-20220330_172420-3fstizw3
wandb: Run `wandb offline` to turn off syncing.

Validation loss decreased (inf --> 1.416736).  Saving model ...
Validation loss decreased (1.416736 --> 1.404356).  Saving model ...
Validation loss decreased (1.404356 --> 1.393657).  Saving model ...
Validation loss decreased (1.393657 --> 1.384438).  Saving model ...
Validation loss decreased (1.384438 --> 1.377368).  Saving model ...
Validation loss decreased (1.377368 --> 1.371115).  Saving model ...
Validation loss decreased (1.371115 --> 1.364771).  Saving model ...
Validation loss decreased (1.364771 --> 1.359122).  Saving model ...
Validation loss decreased (1.359122 --> 1.353691).  Saving model ...
Validation loss decreased (1.353691 --> 1.348655).  Saving model ...
Validation loss decreased (1.348655 --> 1.343315).  Saving model ...
Validation loss decreased (1.343315 --> 1.337715).  Saving model ...
Validation loss decreased (1.337715 --> 1.332508).  Saving model ...
Validation loss decreased (1.332508 --> 1.327898).  Saving model ...
Validation loss decreased (1.327898 --> 1.323018).  Saving model ...
Validation loss decreased (1.323018 --> 1.317324).  Saving model ...
Validation loss decreased (1.317324 --> 1.312521).  Saving model ...
Validation loss decreased (1.312521 --> 1.306911).  Saving model ...
Validation loss decreased (1.306911 --> 1.301059).  Saving model ...
Validation loss decreased (1.301059 --> 1.294169).  Saving model ...
Validation loss decreased (1.294169 --> 1.287284).  Saving model ...
Validation loss decreased (1.287284 --> 1.282531).  Saving model ...
Validation loss decreased (1.282531 --> 1.273885).  Saving model ...
Validation loss decreased (1.273885 --> 1.267790).  Saving model ...
Validation loss decreased (1.267790 --> 1.261841).  Saving model ...
Validation loss decreased (1.261841 --> 1.254260).  Saving model ...
Validation loss decreased (1.254260 --> 1.247068).  Saving model ...
Validation loss decreased (1.247068 --> 1.240029).  Saving model ...
Validation loss decreased (1.240029 --> 1.233410).  Saving model ...
Validation loss decreased (1.233410 --> 1.227783).  Saving model ...
Validation loss decreased (1.227783 --> 1.221061).  Saving model ...
Validation loss decreased (1.221061 --> 1.215204).  Saving model ...
Validation loss decreased (1.215204 --> 1.209857).  Saving model ...
Validation loss decreased (1.209857 --> 1.203317).  Saving model ...
Validation loss decreased (1.203317 --> 1.197208).  Saving model ...
Validation loss decreased (1.197208 --> 1.190452).  Saving model ...
Validation loss decreased (1.190452 --> 1.184580).  Saving model ...
Validation loss decreased (1.184580 --> 1.177709).  Saving model ...
Validation loss decreased (1.177709 --> 1.170118).  Saving model ...
Validation loss decreased (1.170118 --> 1.163437).  Saving model ...
Validation loss decreased (1.163437 --> 1.159292).  Saving model ...
Validation loss decreased (1.159292 --> 1.154363).  Saving model ...
Validation loss decreased (1.154363 --> 1.148292).  Saving model ...
Validation loss decreased (1.148292 --> 1.142557).  Saving model ...
Validation loss decreased (1.142557 --> 1.138650).  Saving model ...
Validation loss decreased (1.138650 --> 1.134020).  Saving model ...
Validation loss decreased (1.134020 --> 1.130115).  Saving model ...
Validation loss decreased (1.130115 --> 1.125655).  Saving model ...
Validation loss decreased (1.125655 --> 1.119411).  Saving model ...
Validation loss decreased (1.119411 --> 1.114626).  Saving model ...
Validation loss decreased (1.114626 --> 1.112048).  Saving model ...
Validation loss decreased (1.112048 --> 1.109244).  Saving model ...
Validation loss decreased (1.109244 --> 1.105082).  Saving model ...
Validation loss decreased (1.105082 --> 1.099763).  Saving model ...
Validation loss decreased (1.099763 --> 1.094862).  Saving model ...
Validation loss decreased (1.094862 --> 1.090592).  Saving model ...
Validation loss decreased (1.090592 --> 1.085703).  Saving model ...
Validation loss decreased (1.085703 --> 1.081193).  Saving model ...
Validation loss decreased (1.081193 --> 1.076689).  Saving model ...
Validation loss decreased (1.076689 --> 1.073054).  Saving model ...
Validation loss decreased (1.073054 --> 1.067756).  Saving model ...
Validation loss decreased (1.067756 --> 1.062582).  Saving model ...
Validation loss decreased (1.062582 --> 1.059601).  Saving model ...
Validation loss decreased (1.059601 --> 1.058056).  Saving model ...
Validation loss decreased (1.058056 --> 1.055185).  Saving model ...
Validation loss decreased (1.055185 --> 1.053807).  Saving model ...
Validation loss decreased (1.053807 --> 1.048883).  Saving model ...
Validation loss decreased (1.048883 --> 1.045621).  Saving model ...
Validation loss decreased (1.045621 --> 1.041077).  Saving model ...
Validation loss decreased (1.041077 --> 1.035888).  Saving model ...
Validation loss decreased (1.035888 --> 1.033915).  Saving model ...
Validation loss decreased (1.033915 --> 1.030972).  Saving model ...
Validation loss decreased (1.030972 --> 1.028992).  Saving model ...
Validation loss decreased (1.028992 --> 1.027578).  Saving model ...
Validation loss decreased (1.027578 --> 1.025393).  Saving model ...
Validation loss decreased (1.025393 --> 1.022589).  Saving model ...
Validation loss decreased (1.022589 --> 1.020194).  Saving model ...
Validation loss decreased (1.020194 --> 1.018653).  Saving model ...
Validation loss decreased (1.018653 --> 1.015345).  Saving model ...
Validation loss decreased (1.015345 --> 1.011841).  Saving model ...
Validation loss decreased (1.011841 --> 1.008055).  Saving model ...
Validation loss decreased (1.008055 --> 1.005951).  Saving model ...
Validation loss decreased (1.005951 --> 1.004252).  Saving model ...
EarlyStopping counter: 1 out of 3.0
Validation loss decreased (1.004252 --> 1.000244).  Saving model ...
Validation loss decreased (1.000244 --> 0.996697).  Saving model ...
Validation loss decreased (0.996697 --> 0.995874).  Saving model ...
Validation loss decreased (0.995874 --> 0.993203).  Saving model ...
Validation loss decreased (0.993203 --> 0.990839).  Saving model ...
Validation loss decreased (0.990839 --> 0.989045).  Saving model ...
Validation loss decreased (0.989045 --> 0.986447).  Saving model ...
Validation loss decreased (0.986447 --> 0.984761).  Saving model ...
Validation loss decreased (0.984761 --> 0.981527).  Saving model ...
Validation loss decreased (0.981527 --> 0.979987).  Saving model ...
Validation loss decreased (0.979987 --> 0.977517).  Saving model ...
Validation loss decreased (0.977517 --> 0.977173).  Saving model ...
Validation loss decreased (0.977173 --> 0.973219).  Saving model ...
Validation loss decreased (0.973219 --> 0.972448).  Saving model ...
Validation loss decreased (0.972448 --> 0.971759).  Saving model ...
Validation loss decreased (0.971759 --> 0.969839).  Saving model ...
Validation loss decreased (0.969839 --> 0.966153).  Saving model ...
Validation loss decreased (0.966153 --> 0.964368).  Saving model ...
Validation loss decreased (0.964368 --> 0.963816).  Saving model ...
Validation loss decreased (0.963816 --> 0.961805).  Saving model ...
Validation loss decreased (0.961805 --> 0.959993).  Saving model ...
Validation loss decreased (0.959993 --> 0.959807).  Saving model ...
Validation loss decreased (0.959807 --> 0.959781).  Saving model ...
Validation loss decreased (0.959781 --> 0.958402).  Saving model ...
Validation loss decreased (0.958402 --> 0.956361).  Saving model ...
EarlyStopping counter: 1 out of 3.0
Validation loss decreased (0.956361 --> 0.953815).  Saving model ...
Validation loss decreased (0.953815 --> 0.952122).  Saving model ...
Validation loss decreased (0.952122 --> 0.950918).  Saving model ...
Validation loss decreased (0.950918 --> 0.949090).  Saving model ...
EarlyStopping counter: 1 out of 3.0
Validation loss decreased (0.949090 --> 0.947526).  Saving model ...
EarlyStopping counter: 1 out of 3.0
EarlyStopping counter: 2 out of 3.0
Validation loss decreased (0.947526 --> 0.946536).  Saving model ...
EarlyStopping counter: 1 out of 3.0
Validation loss decreased (0.946536 --> 0.944467).  Saving model ...
Validation loss decreased (0.944467 --> 0.942170).  Saving model ...
Validation loss decreased (0.942170 --> 0.940827).  Saving model ...
EarlyStopping counter: 1 out of 3.0
EarlyStopping counter: 2 out of 3.0
EarlyStopping counter: 3 out of 3.0
/localscratch/yinan.29785222.0/env/lib/python3.7/site-packages/torch/nn/functional.py:1794: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.
  warnings.warn("nn.functional.tanh is deprecated. Use torch.tanh instead.")
wandb: Waiting for W&B process to finish, PID 163813... (success).
wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: \ 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: | 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: / 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: \ 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: | 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: / 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: \ 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: | 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: / 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb:                                                                                
wandb: Run history:
wandb:     e_F1 ▁▂▃▄▅▅▅▅▅▆▆▆▆▆▆▆▇▇▇▇▇▇▇▇▇▇▇█▇███████████
wandb:   e_loss ██▇▇▇▆▆▆▆▅▅▅▄▄▄▄▃▃▃▃▃▃▂▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁
wandb:     t_F1 ▁▁▂▂▂▃▄▄▄▄▅▄▅▅▆▆▆▆▆▆▆▇▆▆▇▆▇▇▇▇▇▇▇▇▇▇▇▇██
wandb:   t_loss ████▇▇▇▇▇▆▆▆▆▅▅▅▄▄▄▄▄▃▃▄▃▃▃▃▃▃▂▂▂▂▂▂▂▂▁▁
wandb: 
wandb: Run summary:
wandb:     e_F1 61.38781
wandb:   e_loss 0.94135
wandb:     t_F1 70.43829
wandb:   t_loss 0.79301
wandb: 
wandb: Synced 4 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Synced zesty-frost-2: https://wandb.ai/yinanazhou/xl_512_bs_8_lr_1e06_es_3_lc_True_nr_True_sr_False_stem_False_lemma_True_repeat_3_fold_2/runs/3fstizw3
wandb: Find logs at: ./wandb/run-20220330_172420-3fstizw3/logs/debug.log
wandb: 

wandb: wandb version 0.12.11 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
2022-03-30 18:46:31.937928: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1
wandb: Tracking run with wandb version 0.12.5
wandb: Syncing run still-pyramid-2
wandb: ⭐️ View project at https://wandb.ai/yinanazhou/xl_512_bs_8_lr_1e06_es_3_lc_True_nr_True_sr_False_stem_False_lemma_True_repeat_4_fold_1
wandb: 🚀 View run at https://wandb.ai/yinanazhou/xl_512_bs_8_lr_1e06_es_3_lc_True_nr_True_sr_False_stem_False_lemma_True_repeat_4_fold_1/runs/1jti7qga
wandb: Run data is saved locally in /project/6002780/yinan/Thesis_MER_Lyrics/lyric-emotion/wandb/run-20220330_184627-1jti7qga
wandb: Run `wandb offline` to turn off syncing.

Validation loss decreased (inf --> 1.442157).  Saving model ...
Validation loss decreased (1.442157 --> 1.422226).  Saving model ...
Validation loss decreased (1.422226 --> 1.406734).  Saving model ...
Validation loss decreased (1.406734 --> 1.394671).  Saving model ...
Validation loss decreased (1.394671 --> 1.384569).  Saving model ...
Validation loss decreased (1.384569 --> 1.377062).  Saving model ...
Validation loss decreased (1.377062 --> 1.370814).  Saving model ...
Validation loss decreased (1.370814 --> 1.364795).  Saving model ...
Validation loss decreased (1.364795 --> 1.359477).  Saving model ...
Validation loss decreased (1.359477 --> 1.354976).  Saving model ...
Validation loss decreased (1.354976 --> 1.350752).  Saving model ...
Validation loss decreased (1.350752 --> 1.346784).  Saving model ...
Validation loss decreased (1.346784 --> 1.342855).  Saving model ...
Validation loss decreased (1.342855 --> 1.338327).  Saving model ...
Validation loss decreased (1.338327 --> 1.333664).  Saving model ...
Validation loss decreased (1.333664 --> 1.328859).  Saving model ...
Validation loss decreased (1.328859 --> 1.324321).  Saving model ...
Validation loss decreased (1.324321 --> 1.319677).  Saving model ...
Validation loss decreased (1.319677 --> 1.315128).  Saving model ...
Validation loss decreased (1.315128 --> 1.309736).  Saving model ...
Validation loss decreased (1.309736 --> 1.304652).  Saving model ...
Validation loss decreased (1.304652 --> 1.299552).  Saving model ...
Validation loss decreased (1.299552 --> 1.294726).  Saving model ...
Validation loss decreased (1.294726 --> 1.289229).  Saving model ...
Validation loss decreased (1.289229 --> 1.283919).  Saving model ...
Validation loss decreased (1.283919 --> 1.278497).  Saving model ...
Validation loss decreased (1.278497 --> 1.272562).  Saving model ...
Validation loss decreased (1.272562 --> 1.266969).  Saving model ...
Validation loss decreased (1.266969 --> 1.261533).  Saving model ...
Validation loss decreased (1.261533 --> 1.255901).  Saving model ...
Validation loss decreased (1.255901 --> 1.251109).  Saving model ...
Validation loss decreased (1.251109 --> 1.245907).  Saving model ...
Validation loss decreased (1.245907 --> 1.241261).  Saving model ...
Validation loss decreased (1.241261 --> 1.235914).  Saving model ...
Validation loss decreased (1.235914 --> 1.230593).  Saving model ...
Validation loss decreased (1.230593 --> 1.225943).  Saving model ...
Validation loss decreased (1.225943 --> 1.221373).  Saving model ...
Validation loss decreased (1.221373 --> 1.217370).  Saving model ...
Validation loss decreased (1.217370 --> 1.213567).  Saving model ...
Validation loss decreased (1.213567 --> 1.207802).  Saving model ...
Validation loss decreased (1.207802 --> 1.203464).  Saving model ...
Validation loss decreased (1.203464 --> 1.198955).  Saving model ...
Validation loss decreased (1.198955 --> 1.194923).  Saving model ...
Validation loss decreased (1.194923 --> 1.189686).  Saving model ...
Validation loss decreased (1.189686 --> 1.184277).  Saving model ...
Validation loss decreased (1.184277 --> 1.178534).  Saving model ...
Validation loss decreased (1.178534 --> 1.174561).  Saving model ...
Validation loss decreased (1.174561 --> 1.170754).  Saving model ...
Validation loss decreased (1.170754 --> 1.166896).  Saving model ...
Validation loss decreased (1.166896 --> 1.163625).  Saving model ...
Validation loss decreased (1.163625 --> 1.160158).  Saving model ...
Validation loss decreased (1.160158 --> 1.155995).  Saving model ...
Validation loss decreased (1.155995 --> 1.152538).  Saving model ...
Validation loss decreased (1.152538 --> 1.148557).  Saving model ...
Validation loss decreased (1.148557 --> 1.145863).  Saving model ...
Validation loss decreased (1.145863 --> 1.142400).  Saving model ...
Validation loss decreased (1.142400 --> 1.139679).  Saving model ...
Validation loss decreased (1.139679 --> 1.135633).  Saving model ...
Validation loss decreased (1.135633 --> 1.132433).  Saving model ...
Validation loss decreased (1.132433 --> 1.127428).  Saving model ...
Validation loss decreased (1.127428 --> 1.122823).  Saving model ...
Validation loss decreased (1.122823 --> 1.119585).  Saving model ...
Validation loss decreased (1.119585 --> 1.117462).  Saving model ...
Validation loss decreased (1.117462 --> 1.114672).  Saving model ...
Validation loss decreased (1.114672 --> 1.112712).  Saving model ...
Validation loss decreased (1.112712 --> 1.109858).  Saving model ...
Validation loss decreased (1.109858 --> 1.107155).  Saving model ...
Validation loss decreased (1.107155 --> 1.105564).  Saving model ...
Validation loss decreased (1.105564 --> 1.102934).  Saving model ...
Validation loss decreased (1.102934 --> 1.100500).  Saving model ...
Validation loss decreased (1.100500 --> 1.098449).  Saving model ...
Validation loss decreased (1.098449 --> 1.096149).  Saving model ...
Validation loss decreased (1.096149 --> 1.092722).  Saving model ...
Validation loss decreased (1.092722 --> 1.091574).  Saving model ...
Validation loss decreased (1.091574 --> 1.089425).  Saving model ...
Validation loss decreased (1.089425 --> 1.088245).  Saving model ...
Validation loss decreased (1.088245 --> 1.086396).  Saving model ...
Validation loss decreased (1.086396 --> 1.082000).  Saving model ...
Validation loss decreased (1.082000 --> 1.080203).  Saving model ...
Validation loss decreased (1.080203 --> 1.076734).  Saving model ...
Validation loss decreased (1.076734 --> 1.073935).  Saving model ...
Validation loss decreased (1.073935 --> 1.072768).  Saving model ...
Validation loss decreased (1.072768 --> 1.071048).  Saving model ...
Validation loss decreased (1.071048 --> 1.067740).  Saving model ...
Validation loss decreased (1.067740 --> 1.065690).  Saving model ...
Validation loss decreased (1.065690 --> 1.063353).  Saving model ...
Validation loss decreased (1.063353 --> 1.061183).  Saving model ...
Validation loss decreased (1.061183 --> 1.058601).  Saving model ...
Validation loss decreased (1.058601 --> 1.056706).  Saving model ...
Validation loss decreased (1.056706 --> 1.054830).  Saving model ...
Validation loss decreased (1.054830 --> 1.053400).  Saving model ...
Validation loss decreased (1.053400 --> 1.051171).  Saving model ...
Validation loss decreased (1.051171 --> 1.050605).  Saving model ...
Validation loss decreased (1.050605 --> 1.048192).  Saving model ...
Validation loss decreased (1.048192 --> 1.045738).  Saving model ...
Validation loss decreased (1.045738 --> 1.043043).  Saving model ...
Validation loss decreased (1.043043 --> 1.040201).  Saving model ...
Validation loss decreased (1.040201 --> 1.039795).  Saving model ...
Validation loss decreased (1.039795 --> 1.039679).  Saving model ...
Validation loss decreased (1.039679 --> 1.039495).  Saving model ...
Validation loss decreased (1.039495 --> 1.037935).  Saving model ...
Validation loss decreased (1.037935 --> 1.035843).  Saving model ...
Validation loss decreased (1.035843 --> 1.033109).  Saving model ...
Validation loss decreased (1.033109 --> 1.031639).  Saving model ...
Validation loss decreased (1.031639 --> 1.030507).  Saving model ...
Validation loss decreased (1.030507 --> 1.029849).  Saving model ...
Validation loss decreased (1.029849 --> 1.029518).  Saving model ...
Validation loss decreased (1.029518 --> 1.027755).  Saving model ...
Validation loss decreased (1.027755 --> 1.027293).  Saving model ...
Validation loss decreased (1.027293 --> 1.026334).  Saving model ...
Validation loss decreased (1.026334 --> 1.025137).  Saving model ...
Validation loss decreased (1.025137 --> 1.023717).  Saving model ...
Validation loss decreased (1.023717 --> 1.022622).  Saving model ...
Validation loss decreased (1.022622 --> 1.021941).  Saving model ...
Validation loss decreased (1.021941 --> 1.020566).  Saving model ...
Validation loss decreased (1.020566 --> 1.019025).  Saving model ...
Validation loss decreased (1.019025 --> 1.016594).  Saving model ...
Validation loss decreased (1.016594 --> 1.016551).  Saving model ...
Validation loss decreased (1.016551 --> 1.014662).  Saving model ...
Validation loss decreased (1.014662 --> 1.013686).  Saving model ...
Validation loss decreased (1.013686 --> 1.011735).  Saving model ...
Validation loss decreased (1.011735 --> 1.009924).  Saving model ...
Validation loss decreased (1.009924 --> 1.008156).  Saving model ...
Validation loss decreased (1.008156 --> 1.007346).  Saving model ...
Validation loss decreased (1.007346 --> 1.006820).  Saving model ...
Validation loss decreased (1.006820 --> 1.006759).  Saving model ...
Validation loss decreased (1.006759 --> 1.006565).  Saving model ...
EarlyStopping counter: 1 out of 3.0
Validation loss decreased (1.006565 --> 1.005242).  Saving model ...
Validation loss decreased (1.005242 --> 1.003793).  Saving model ...
Validation loss decreased (1.003793 --> 1.002026).  Saving model ...
Validation loss decreased (1.002026 --> 1.001737).  Saving model ...
Validation loss decreased (1.001737 --> 1.001579).  Saving model ...
Validation loss decreased (1.001579 --> 0.999849).  Saving model ...
EarlyStopping counter: 1 out of 3.0
EarlyStopping counter: 2 out of 3.0
Validation loss decreased (0.999849 --> 0.997061).  Saving model ...
EarlyStopping counter: 1 out of 3.0
Validation loss decreased (0.997061 --> 0.996008).  Saving model ...
Validation loss decreased (0.996008 --> 0.993938).  Saving model ...
Validation loss decreased (0.993938 --> 0.993661).  Saving model ...
EarlyStopping counter: 1 out of 3.0
EarlyStopping counter: 2 out of 3.0
EarlyStopping counter: 3 out of 3.0
/localscratch/yinan.29785222.0/env/lib/python3.7/site-packages/torch/nn/functional.py:1794: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.
  warnings.warn("nn.functional.tanh is deprecated. Use torch.tanh instead.")
wandb: Waiting for W&B process to finish, PID 168199... (success).
wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: \ 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: | 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: / 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: \ 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: | 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: / 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: \ 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: | 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: / 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb:                                                                                
wandb: Run history:
wandb:     e_F1 ▁▁▂▄▄▅▅▅▆▆▆▆▆▇▇▇▇▇▇▇▇▇█▇████████████████
wandb:   e_loss ██▇▇▆▆▆▆▅▅▅▄▄▄▄▃▃▃▃▃▃▂▂▂▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁
wandb:     t_F1 ▁▁▂▂▃▄▄▄▄▅▅▅▅▅▆▆▆▆▆▆▆▇▇▇▇▇▇▇▇▇█▇█▇██████
wandb:   t_loss ███▇▇▇▇▆▆▆▆▅▅▅▅▄▄▄▄▄▄▃▃▃▃▃▃▂▃▂▂▂▂▂▁▂▂▁▁▁
wandb: 
wandb: Run summary:
wandb:     e_F1 54.72318
wandb:   e_loss 0.99377
wandb:     t_F1 70.84702
wandb:   t_loss 0.76508
wandb: 
wandb: Synced 4 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Synced still-pyramid-2: https://wandb.ai/yinanazhou/xl_512_bs_8_lr_1e06_es_3_lc_True_nr_True_sr_False_stem_False_lemma_True_repeat_4_fold_1/runs/1jti7qga
wandb: Find logs at: ./wandb/run-20220330_184627-1jti7qga/logs/debug.log
wandb: 

wandb: wandb version 0.12.11 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
2022-03-30 20:19:00.144244: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1
wandb: Tracking run with wandb version 0.12.5
wandb: Syncing run distinctive-glade-2
wandb: ⭐️ View project at https://wandb.ai/yinanazhou/xl_512_bs_8_lr_1e06_es_3_lc_True_nr_True_sr_False_stem_False_lemma_True_repeat_4_fold_2
wandb: 🚀 View run at https://wandb.ai/yinanazhou/xl_512_bs_8_lr_1e06_es_3_lc_True_nr_True_sr_False_stem_False_lemma_True_repeat_4_fold_2/runs/3muhyclm
wandb: Run data is saved locally in /project/6002780/yinan/Thesis_MER_Lyrics/lyric-emotion/wandb/run-20220330_201857-3muhyclm
wandb: Run `wandb offline` to turn off syncing.

Validation loss decreased (inf --> 1.442457).  Saving model ...
Validation loss decreased (1.442457 --> 1.424020).  Saving model ...
Validation loss decreased (1.424020 --> 1.410229).  Saving model ...
Validation loss decreased (1.410229 --> 1.399785).  Saving model ...
Validation loss decreased (1.399785 --> 1.391399).  Saving model ...
Validation loss decreased (1.391399 --> 1.384533).  Saving model ...
Validation loss decreased (1.384533 --> 1.378428).  Saving model ...
Validation loss decreased (1.378428 --> 1.374087).  Saving model ...
Validation loss decreased (1.374087 --> 1.369400).  Saving model ...
Validation loss decreased (1.369400 --> 1.365067).  Saving model ...
Validation loss decreased (1.365067 --> 1.360345).  Saving model ...
Validation loss decreased (1.360345 --> 1.355943).  Saving model ...
Validation loss decreased (1.355943 --> 1.350514).  Saving model ...
Validation loss decreased (1.350514 --> 1.346365).  Saving model ...
Validation loss decreased (1.346365 --> 1.341893).  Saving model ...
Validation loss decreased (1.341893 --> 1.336625).  Saving model ...
Validation loss decreased (1.336625 --> 1.332118).  Saving model ...
Validation loss decreased (1.332118 --> 1.326091).  Saving model ...
Validation loss decreased (1.326091 --> 1.321512).  Saving model ...
Validation loss decreased (1.321512 --> 1.315247).  Saving model ...
Validation loss decreased (1.315247 --> 1.309329).  Saving model ...
Validation loss decreased (1.309329 --> 1.304514).  Saving model ...
Validation loss decreased (1.304514 --> 1.299053).  Saving model ...
Validation loss decreased (1.299053 --> 1.292015).  Saving model ...
Validation loss decreased (1.292015 --> 1.286196).  Saving model ...
Validation loss decreased (1.286196 --> 1.281528).  Saving model ...
Validation loss decreased (1.281528 --> 1.272647).  Saving model ...
Validation loss decreased (1.272647 --> 1.264609).  Saving model ...
Validation loss decreased (1.264609 --> 1.257421).  Saving model ...
Validation loss decreased (1.257421 --> 1.250282).  Saving model ...
Validation loss decreased (1.250282 --> 1.241819).  Saving model ...
Validation loss decreased (1.241819 --> 1.233392).  Saving model ...
Validation loss decreased (1.233392 --> 1.227344).  Saving model ...
Validation loss decreased (1.227344 --> 1.217997).  Saving model ...
Validation loss decreased (1.217997 --> 1.210101).  Saving model ...
Validation loss decreased (1.210101 --> 1.205147).  Saving model ...
Validation loss decreased (1.205147 --> 1.199267).  Saving model ...
Validation loss decreased (1.199267 --> 1.193610).  Saving model ...
Validation loss decreased (1.193610 --> 1.185658).  Saving model ...
Validation loss decreased (1.185658 --> 1.179456).  Saving model ...
Validation loss decreased (1.179456 --> 1.175497).  Saving model ...
Validation loss decreased (1.175497 --> 1.168424).  Saving model ...
Validation loss decreased (1.168424 --> 1.162131).  Saving model ...
Validation loss decreased (1.162131 --> 1.156665).  Saving model ...
Validation loss decreased (1.156665 --> 1.151337).  Saving model ...
Validation loss decreased (1.151337 --> 1.143449).  Saving model ...
Validation loss decreased (1.143449 --> 1.138562).  Saving model ...
Validation loss decreased (1.138562 --> 1.133327).  Saving model ...
Validation loss decreased (1.133327 --> 1.125078).  Saving model ...
Validation loss decreased (1.125078 --> 1.119383).  Saving model ...
Validation loss decreased (1.119383 --> 1.114232).  Saving model ...
Validation loss decreased (1.114232 --> 1.110746).  Saving model ...
Validation loss decreased (1.110746 --> 1.107455).  Saving model ...
Validation loss decreased (1.107455 --> 1.101534).  Saving model ...
Validation loss decreased (1.101534 --> 1.095552).  Saving model ...
Validation loss decreased (1.095552 --> 1.090478).  Saving model ...
Validation loss decreased (1.090478 --> 1.085893).  Saving model ...
Validation loss decreased (1.085893 --> 1.083871).  Saving model ...
Validation loss decreased (1.083871 --> 1.076874).  Saving model ...
EarlyStopping counter: 1 out of 3.0
Validation loss decreased (1.076874 --> 1.072019).  Saving model ...
Validation loss decreased (1.072019 --> 1.066209).  Saving model ...
Validation loss decreased (1.066209 --> 1.064428).  Saving model ...
Validation loss decreased (1.064428 --> 1.061657).  Saving model ...
Validation loss decreased (1.061657 --> 1.052993).  Saving model ...
Validation loss decreased (1.052993 --> 1.046195).  Saving model ...
Validation loss decreased (1.046195 --> 1.043659).  Saving model ...
Validation loss decreased (1.043659 --> 1.039588).  Saving model ...
Validation loss decreased (1.039588 --> 1.036991).  Saving model ...
Validation loss decreased (1.036991 --> 1.031982).  Saving model ...
Validation loss decreased (1.031982 --> 1.029279).  Saving model ...
Validation loss decreased (1.029279 --> 1.025467).  Saving model ...
Validation loss decreased (1.025467 --> 1.020519).  Saving model ...
Validation loss decreased (1.020519 --> 1.018559).  Saving model ...
Validation loss decreased (1.018559 --> 1.015525).  Saving model ...
Validation loss decreased (1.015525 --> 1.014920).  Saving model ...
EarlyStopping counter: 1 out of 3.0
Validation loss decreased (1.014920 --> 1.008908).  Saving model ...
Validation loss decreased (1.008908 --> 1.008764).  Saving model ...
Validation loss decreased (1.008764 --> 1.006208).  Saving model ...
Validation loss decreased (1.006208 --> 1.002963).  Saving model ...
EarlyStopping counter: 1 out of 3.0
Validation loss decreased (1.002963 --> 1.002390).  Saving model ...
Validation loss decreased (1.002390 --> 1.001603).  Saving model ...
Validation loss decreased (1.001603 --> 0.995279).  Saving model ...
EarlyStopping counter: 1 out of 3.0
Validation loss decreased (0.995279 --> 0.992518).  Saving model ...
Validation loss decreased (0.992518 --> 0.990475).  Saving model ...
Validation loss decreased (0.990475 --> 0.989826).  Saving model ...
Validation loss decreased (0.989826 --> 0.985481).  Saving model ...
Validation loss decreased (0.985481 --> 0.984945).  Saving model ...
Validation loss decreased (0.984945 --> 0.981549).  Saving model ...
Validation loss decreased (0.981549 --> 0.979533).  Saving model ...
Validation loss decreased (0.979533 --> 0.977400).  Saving model ...
Validation loss decreased (0.977400 --> 0.976139).  Saving model ...
Validation loss decreased (0.976139 --> 0.970193).  Saving model ...
Validation loss decreased (0.970193 --> 0.969831).  Saving model ...
Validation loss decreased (0.969831 --> 0.968018).  Saving model ...
EarlyStopping counter: 1 out of 3.0
EarlyStopping counter: 2 out of 3.0
Validation loss decreased (0.968018 --> 0.965207).  Saving model ...
EarlyStopping counter: 1 out of 3.0
EarlyStopping counter: 2 out of 3.0
EarlyStopping counter: 3 out of 3.0
/localscratch/yinan.29785222.0/env/lib/python3.7/site-packages/torch/nn/functional.py:1794: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.
  warnings.warn("nn.functional.tanh is deprecated. Use torch.tanh instead.")
wandb: Waiting for W&B process to finish, PID 173184... (success).
wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: \ 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: | 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: / 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: \ 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: | 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: / 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: \ 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: | 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: / 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb:                                                                                
wandb: Run history:
wandb:     e_F1 ▁▁▂▃▃▄▄▅▅▅▅▆▆▆▆▆▆▆▆▇▇▇▇▇▇▇▇▇▇▇▇▇████████
wandb:   e_loss ██▇▇▇▇▆▆▆▆▆▅▅▅▄▄▄▄▃▃▃▃▃▃▂▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁
wandb:     t_F1 ▁▂▂▃▃▃▄▄▄▄▅▅▅▅▅▆▆▆▆▅▆▆▆▆▆▆▇▇▇▇▇▇▇█▇▇█▇██
wandb:   t_loss █▇▇▇▇▇▇▆▇▆▆▆▆▅▅▅▅▄▄▄▄▄▄▃▃▃▃▃▃▂▂▂▂▂▂▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:     e_F1 59.12959
wandb:   e_loss 0.96552
wandb:     t_F1 66.07235
wandb:   t_loss 0.86835
wandb: 
wandb: Synced 4 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Synced distinctive-glade-2: https://wandb.ai/yinanazhou/xl_512_bs_8_lr_1e06_es_3_lc_True_nr_True_sr_False_stem_False_lemma_True_repeat_4_fold_2/runs/3muhyclm
wandb: Find logs at: ./wandb/run-20220330_201857-3muhyclm/logs/debug.log
wandb: 

wandb: wandb version 0.12.11 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
2022-03-30 21:27:51.820255: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1
wandb: Tracking run with wandb version 0.12.5
wandb: Syncing run super-plant-1
wandb: ⭐️ View project at https://wandb.ai/yinanazhou/xl_512_bs_8_lr_1e06_es_3_lc_True_nr_True_sr_False_stem_False_lemma_True_repeat_5_fold_1
wandb: 🚀 View run at https://wandb.ai/yinanazhou/xl_512_bs_8_lr_1e06_es_3_lc_True_nr_True_sr_False_stem_False_lemma_True_repeat_5_fold_1/runs/3uunvn9o
wandb: Run data is saved locally in /project/6002780/yinan/Thesis_MER_Lyrics/lyric-emotion/wandb/run-20220330_212749-3uunvn9o
wandb: Run `wandb offline` to turn off syncing.

Validation loss decreased (inf --> 1.404229).  Saving model ...
Validation loss decreased (1.404229 --> 1.397694).  Saving model ...
Validation loss decreased (1.397694 --> 1.392187).  Saving model ...
Validation loss decreased (1.392187 --> 1.387978).  Saving model ...
Validation loss decreased (1.387978 --> 1.383773).  Saving model ...
Validation loss decreased (1.383773 --> 1.380019).  Saving model ...
Validation loss decreased (1.380019 --> 1.376581).  Saving model ...
Validation loss decreased (1.376581 --> 1.373365).  Saving model ...
Validation loss decreased (1.373365 --> 1.369865).  Saving model ...
Validation loss decreased (1.369865 --> 1.366324).  Saving model ...
Validation loss decreased (1.366324 --> 1.363164).  Saving model ...
Validation loss decreased (1.363164 --> 1.359647).  Saving model ...
Validation loss decreased (1.359647 --> 1.355966).  Saving model ...
Validation loss decreased (1.355966 --> 1.351912).  Saving model ...
Validation loss decreased (1.351912 --> 1.347927).  Saving model ...
Validation loss decreased (1.347927 --> 1.343820).  Saving model ...
Validation loss decreased (1.343820 --> 1.339472).  Saving model ...
Validation loss decreased (1.339472 --> 1.334528).  Saving model ...
Validation loss decreased (1.334528 --> 1.329567).  Saving model ...
Validation loss decreased (1.329567 --> 1.324705).  Saving model ...
Validation loss decreased (1.324705 --> 1.318465).  Saving model ...
Validation loss decreased (1.318465 --> 1.312897).  Saving model ...
Validation loss decreased (1.312897 --> 1.307480).  Saving model ...
Validation loss decreased (1.307480 --> 1.300909).  Saving model ...
Validation loss decreased (1.300909 --> 1.294509).  Saving model ...
Validation loss decreased (1.294509 --> 1.287157).  Saving model ...
Validation loss decreased (1.287157 --> 1.280239).  Saving model ...
Validation loss decreased (1.280239 --> 1.272810).  Saving model ...
Validation loss decreased (1.272810 --> 1.264663).  Saving model ...
Validation loss decreased (1.264663 --> 1.255522).  Saving model ...
Validation loss decreased (1.255522 --> 1.246882).  Saving model ...
Validation loss decreased (1.246882 --> 1.238319).  Saving model ...
Validation loss decreased (1.238319 --> 1.230526).  Saving model ...
Validation loss decreased (1.230526 --> 1.222594).  Saving model ...
Validation loss decreased (1.222594 --> 1.215058).  Saving model ...
Validation loss decreased (1.215058 --> 1.207679).  Saving model ...
Validation loss decreased (1.207679 --> 1.198376).  Saving model ...
Validation loss decreased (1.198376 --> 1.190722).  Saving model ...
Validation loss decreased (1.190722 --> 1.184495).  Saving model ...
Validation loss decreased (1.184495 --> 1.176885).  Saving model ...
Validation loss decreased (1.176885 --> 1.170063).  Saving model ...
Validation loss decreased (1.170063 --> 1.163432).  Saving model ...
Validation loss decreased (1.163432 --> 1.157179).  Saving model ...
Validation loss decreased (1.157179 --> 1.151102).  Saving model ...
Validation loss decreased (1.151102 --> 1.146074).  Saving model ...
Validation loss decreased (1.146074 --> 1.140183).  Saving model ...
Validation loss decreased (1.140183 --> 1.134685).  Saving model ...
Validation loss decreased (1.134685 --> 1.128481).  Saving model ...
Validation loss decreased (1.128481 --> 1.123689).  Saving model ...
Validation loss decreased (1.123689 --> 1.119205).  Saving model ...
Validation loss decreased (1.119205 --> 1.115501).  Saving model ...
Validation loss decreased (1.115501 --> 1.111737).  Saving model ...
Validation loss decreased (1.111737 --> 1.106434).  Saving model ...
Validation loss decreased (1.106434 --> 1.101950).  Saving model ...
Validation loss decreased (1.101950 --> 1.098163).  Saving model ...
Validation loss decreased (1.098163 --> 1.094410).  Saving model ...
Validation loss decreased (1.094410 --> 1.089857).  Saving model ...
Validation loss decreased (1.089857 --> 1.086574).  Saving model ...
Validation loss decreased (1.086574 --> 1.082171).  Saving model ...
Validation loss decreased (1.082171 --> 1.078316).  Saving model ...
Validation loss decreased (1.078316 --> 1.074406).  Saving model ...
Validation loss decreased (1.074406 --> 1.069633).  Saving model ...
Validation loss decreased (1.069633 --> 1.065719).  Saving model ...
Validation loss decreased (1.065719 --> 1.062051).  Saving model ...
Validation loss decreased (1.062051 --> 1.058488).  Saving model ...
Validation loss decreased (1.058488 --> 1.054257).  Saving model ...
Validation loss decreased (1.054257 --> 1.050734).  Saving model ...
Validation loss decreased (1.050734 --> 1.046618).  Saving model ...
Validation loss decreased (1.046618 --> 1.043756).  Saving model ...
Validation loss decreased (1.043756 --> 1.040778).  Saving model ...
Validation loss decreased (1.040778 --> 1.038167).  Saving model ...
Validation loss decreased (1.038167 --> 1.035137).  Saving model ...
Validation loss decreased (1.035137 --> 1.032311).  Saving model ...
Validation loss decreased (1.032311 --> 1.028537).  Saving model ...
Validation loss decreased (1.028537 --> 1.027282).  Saving model ...
Validation loss decreased (1.027282 --> 1.024295).  Saving model ...
Validation loss decreased (1.024295 --> 1.021783).  Saving model ...
Validation loss decreased (1.021783 --> 1.018995).  Saving model ...
Validation loss decreased (1.018995 --> 1.016146).  Saving model ...
Validation loss decreased (1.016146 --> 1.014620).  Saving model ...
Validation loss decreased (1.014620 --> 1.012297).  Saving model ...
Validation loss decreased (1.012297 --> 1.009783).  Saving model ...
Validation loss decreased (1.009783 --> 1.007735).  Saving model ...
Validation loss decreased (1.007735 --> 1.005143).  Saving model ...
Validation loss decreased (1.005143 --> 1.002726).  Saving model ...
Validation loss decreased (1.002726 --> 1.001162).  Saving model ...
Validation loss decreased (1.001162 --> 0.998978).  Saving model ...
Validation loss decreased (0.998978 --> 0.996729).  Saving model ...
Validation loss decreased (0.996729 --> 0.994666).  Saving model ...
Validation loss decreased (0.994666 --> 0.992662).  Saving model ...
Validation loss decreased (0.992662 --> 0.991116).  Saving model ...
Validation loss decreased (0.991116 --> 0.989781).  Saving model ...
Validation loss decreased (0.989781 --> 0.987671).  Saving model ...
Validation loss decreased (0.987671 --> 0.985880).  Saving model ...
Validation loss decreased (0.985880 --> 0.984200).  Saving model ...
Validation loss decreased (0.984200 --> 0.982155).  Saving model ...
Validation loss decreased (0.982155 --> 0.981300).  Saving model ...
Validation loss decreased (0.981300 --> 0.978936).  Saving model ...
Validation loss decreased (0.978936 --> 0.977435).  Saving model ...
Validation loss decreased (0.977435 --> 0.976460).  Saving model ...
Validation loss decreased (0.976460 --> 0.975201).  Saving model ...
Validation loss decreased (0.975201 --> 0.973969).  Saving model ...
Validation loss decreased (0.973969 --> 0.973035).  Saving model ...
Validation loss decreased (0.973035 --> 0.972574).  Saving model ...
Validation loss decreased (0.972574 --> 0.971450).  Saving model ...
Validation loss decreased (0.971450 --> 0.970698).  Saving model ...
Validation loss decreased (0.970698 --> 0.970079).  Saving model ...
Validation loss decreased (0.970079 --> 0.969634).  Saving model ...
Validation loss decreased (0.969634 --> 0.968463).  Saving model ...
Validation loss decreased (0.968463 --> 0.967547).  Saving model ...
Validation loss decreased (0.967547 --> 0.965960).  Saving model ...
Validation loss decreased (0.965960 --> 0.964840).  Saving model ...
Validation loss decreased (0.964840 --> 0.964161).  Saving model ...
Validation loss decreased (0.964161 --> 0.963391).  Saving model ...
Validation loss decreased (0.963391 --> 0.962974).  Saving model ...
Validation loss decreased (0.962974 --> 0.962082).  Saving model ...
Validation loss decreased (0.962082 --> 0.961057).  Saving model ...
Validation loss decreased (0.961057 --> 0.960595).  Saving model ...
Validation loss decreased (0.960595 --> 0.959667).  Saving model ...
Validation loss decreased (0.959667 --> 0.958278).  Saving model ...
Validation loss decreased (0.958278 --> 0.958264).  Saving model ...
Validation loss decreased (0.958264 --> 0.957782).  Saving model ...
Validation loss decreased (0.957782 --> 0.957566).  Saving model ...
Validation loss decreased (0.957566 --> 0.957165).  Saving model ...
Validation loss decreased (0.957165 --> 0.956641).  Saving model ...
Validation loss decreased (0.956641 --> 0.956390).  Saving model ...
Validation loss decreased (0.956390 --> 0.955822).  Saving model ...
Validation loss decreased (0.955822 --> 0.955531).  Saving model ...
EarlyStopping counter: 1 out of 3.0
EarlyStopping counter: 2 out of 3.0
EarlyStopping counter: 3 out of 3.0
/localscratch/yinan.29785222.0/env/lib/python3.7/site-packages/torch/nn/functional.py:1794: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.
  warnings.warn("nn.functional.tanh is deprecated. Use torch.tanh instead.")
wandb: Waiting for W&B process to finish, PID 176892... (success).
wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: \ 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: | 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: / 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: \ 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: | 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: / 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: \ 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: | 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: / 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb:                                                                                
wandb: Run history:
wandb:     e_F1 ▁▂▃▃▃▄▄▅▅▅▆▆▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇█████████████
wandb:   e_loss ████▇▇▇▆▆▆▅▅▅▄▄▄▃▃▃▃▃▂▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁
wandb:     t_F1 ▁▂▂▂▂▂▃▃▄▅▄▅▅▅▅▆▆▆▆▆▆▆▆▇▇▇▇▇▇▇▇▇▇▇▇█████
wandb:   t_loss ████▇▇▇▇▆▆▆▆▅▅▅▅▄▄▄▄▄▄▄▃▃▃▃▂▃▂▂▂▂▂▂▂▁▁▁▁
wandb: 
wandb: Run summary:
wandb:     e_F1 56.70917
wandb:   e_loss 0.95597
wandb:     t_F1 71.7155
wandb:   t_loss 0.7607
wandb: 
wandb: Synced 4 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Synced super-plant-1: https://wandb.ai/yinanazhou/xl_512_bs_8_lr_1e06_es_3_lc_True_nr_True_sr_False_stem_False_lemma_True_repeat_5_fold_1/runs/3uunvn9o
wandb: Find logs at: ./wandb/run-20220330_212749-3uunvn9o/logs/debug.log
wandb: 

wandb: wandb version 0.12.11 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
2022-03-30 22:54:34.729862: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1
wandb: Tracking run with wandb version 0.12.5
wandb: Syncing run lucky-water-1
wandb: ⭐️ View project at https://wandb.ai/yinanazhou/xl_512_bs_8_lr_1e06_es_3_lc_True_nr_True_sr_False_stem_False_lemma_True_repeat_5_fold_2
wandb: 🚀 View run at https://wandb.ai/yinanazhou/xl_512_bs_8_lr_1e06_es_3_lc_True_nr_True_sr_False_stem_False_lemma_True_repeat_5_fold_2/runs/2l2zck4t
wandb: Run data is saved locally in /project/6002780/yinan/Thesis_MER_Lyrics/lyric-emotion/wandb/run-20220330_225432-2l2zck4t
wandb: Run `wandb offline` to turn off syncing.

Validation loss decreased (inf --> 1.484213).  Saving model ...
Validation loss decreased (1.484213 --> 1.450121).  Saving model ...
Validation loss decreased (1.450121 --> 1.425613).  Saving model ...
Validation loss decreased (1.425613 --> 1.408915).  Saving model ...
Validation loss decreased (1.408915 --> 1.396822).  Saving model ...
Validation loss decreased (1.396822 --> 1.387721).  Saving model ...
Validation loss decreased (1.387721 --> 1.380622).  Saving model ...
Validation loss decreased (1.380622 --> 1.375292).  Saving model ...
Validation loss decreased (1.375292 --> 1.370537).  Saving model ...
Validation loss decreased (1.370537 --> 1.365581).  Saving model ...
Validation loss decreased (1.365581 --> 1.361448).  Saving model ...
Validation loss decreased (1.361448 --> 1.357668).  Saving model ...
Validation loss decreased (1.357668 --> 1.353774).  Saving model ...
Validation loss decreased (1.353774 --> 1.349956).  Saving model ...
Validation loss decreased (1.349956 --> 1.345697).  Saving model ...
Validation loss decreased (1.345697 --> 1.341491).  Saving model ...
Validation loss decreased (1.341491 --> 1.337108).  Saving model ...
Validation loss decreased (1.337108 --> 1.332709).  Saving model ...
Validation loss decreased (1.332709 --> 1.328463).  Saving model ...
Validation loss decreased (1.328463 --> 1.323927).  Saving model ...
Validation loss decreased (1.323927 --> 1.318144).  Saving model ...
Validation loss decreased (1.318144 --> 1.311929).  Saving model ...
Validation loss decreased (1.311929 --> 1.306536).  Saving model ...
Validation loss decreased (1.306536 --> 1.300064).  Saving model ...
Validation loss decreased (1.300064 --> 1.293137).  Saving model ...
Validation loss decreased (1.293137 --> 1.286745).  Saving model ...
Validation loss decreased (1.286745 --> 1.277816).  Saving model ...
Validation loss decreased (1.277816 --> 1.270120).  Saving model ...
Validation loss decreased (1.270120 --> 1.263446).  Saving model ...
Validation loss decreased (1.263446 --> 1.255159).  Saving model ...
Validation loss decreased (1.255159 --> 1.245944).  Saving model ...
Validation loss decreased (1.245944 --> 1.237824).  Saving model ...
Validation loss decreased (1.237824 --> 1.230367).  Saving model ...
Validation loss decreased (1.230367 --> 1.222678).  Saving model ...
Validation loss decreased (1.222678 --> 1.212627).  Saving model ...
Validation loss decreased (1.212627 --> 1.205920).  Saving model ...
Validation loss decreased (1.205920 --> 1.198883).  Saving model ...
Validation loss decreased (1.198883 --> 1.192256).  Saving model ...
Validation loss decreased (1.192256 --> 1.186426).  Saving model ...
Validation loss decreased (1.186426 --> 1.178903).  Saving model ...
Validation loss decreased (1.178903 --> 1.172898).  Saving model ...
Validation loss decreased (1.172898 --> 1.167638).  Saving model ...
Validation loss decreased (1.167638 --> 1.160053).  Saving model ...
Validation loss decreased (1.160053 --> 1.155282).  Saving model ...
Validation loss decreased (1.155282 --> 1.151376).  Saving model ...
Validation loss decreased (1.151376 --> 1.143865).  Saving model ...
Validation loss decreased (1.143865 --> 1.136076).  Saving model ...
Validation loss decreased (1.136076 --> 1.132643).  Saving model ...
Validation loss decreased (1.132643 --> 1.127528).  Saving model ...
Validation loss decreased (1.127528 --> 1.123087).  Saving model ...
Validation loss decreased (1.123087 --> 1.115698).  Saving model ...
Validation loss decreased (1.115698 --> 1.111953).  Saving model ...
Validation loss decreased (1.111953 --> 1.107488).  Saving model ...
Validation loss decreased (1.107488 --> 1.104504).  Saving model ...
Validation loss decreased (1.104504 --> 1.101003).  Saving model ...
Validation loss decreased (1.101003 --> 1.094646).  Saving model ...
Validation loss decreased (1.094646 --> 1.091742).  Saving model ...
Validation loss decreased (1.091742 --> 1.090664).  Saving model ...
Validation loss decreased (1.090664 --> 1.082721).  Saving model ...
Validation loss decreased (1.082721 --> 1.079675).  Saving model ...
Validation loss decreased (1.079675 --> 1.077393).  Saving model ...
Validation loss decreased (1.077393 --> 1.073320).  Saving model ...
Validation loss decreased (1.073320 --> 1.067835).  Saving model ...
Validation loss decreased (1.067835 --> 1.063492).  Saving model ...
Validation loss decreased (1.063492 --> 1.060563).  Saving model ...
Validation loss decreased (1.060563 --> 1.057566).  Saving model ...
Validation loss decreased (1.057566 --> 1.053481).  Saving model ...
Validation loss decreased (1.053481 --> 1.049776).  Saving model ...
Validation loss decreased (1.049776 --> 1.048152).  Saving model ...
Validation loss decreased (1.048152 --> 1.043456).  Saving model ...
Validation loss decreased (1.043456 --> 1.039088).  Saving model ...
Validation loss decreased (1.039088 --> 1.034177).  Saving model ...
Validation loss decreased (1.034177 --> 1.031367).  Saving model ...
Validation loss decreased (1.031367 --> 1.029038).  Saving model ...
Validation loss decreased (1.029038 --> 1.027325).  Saving model ...
Validation loss decreased (1.027325 --> 1.026350).  Saving model ...
Validation loss decreased (1.026350 --> 1.024120).  Saving model ...
Validation loss decreased (1.024120 --> 1.020324).  Saving model ...
Validation loss decreased (1.020324 --> 1.018438).  Saving model ...
Validation loss decreased (1.018438 --> 1.016541).  Saving model ...
Validation loss decreased (1.016541 --> 1.016515).  Saving model ...
Validation loss decreased (1.016515 --> 1.013720).  Saving model ...
EarlyStopping counter: 1 out of 3.0
Validation loss decreased (1.013720 --> 1.012887).  Saving model ...
Validation loss decreased (1.012887 --> 1.006926).  Saving model ...
Validation loss decreased (1.006926 --> 1.002894).  Saving model ...
Validation loss decreased (1.002894 --> 1.000725).  Saving model ...
Validation loss decreased (1.000725 --> 0.997500).  Saving model ...
Validation loss decreased (0.997500 --> 0.996013).  Saving model ...
Validation loss decreased (0.996013 --> 0.994758).  Saving model ...
Validation loss decreased (0.994758 --> 0.992365).  Saving model ...
Validation loss decreased (0.992365 --> 0.989498).  Saving model ...
Validation loss decreased (0.989498 --> 0.989273).  Saving model ...
Validation loss decreased (0.989273 --> 0.988113).  Saving model ...
Validation loss decreased (0.988113 --> 0.986157).  Saving model ...
EarlyStopping counter: 1 out of 3.0
Validation loss decreased (0.986157 --> 0.982033).  Saving model ...
Validation loss decreased (0.982033 --> 0.979819).  Saving model ...
EarlyStopping counter: 1 out of 3.0
Validation loss decreased (0.979819 --> 0.975909).  Saving model ...
Validation loss decreased (0.975909 --> 0.974685).  Saving model ...
Validation loss decreased (0.974685 --> 0.971399).  Saving model ...
EarlyStopping counter: 1 out of 3.0
Validation loss decreased (0.971399 --> 0.969594).  Saving model ...
EarlyStopping counter: 1 out of 3.0
EarlyStopping counter: 2 out of 3.0
Validation loss decreased (0.969594 --> 0.967450).  Saving model ...
Validation loss decreased (0.967450 --> 0.965755).  Saving model ...
EarlyStopping counter: 1 out of 3.0
Validation loss decreased (0.965755 --> 0.965603).  Saving model ...
Validation loss decreased (0.965603 --> 0.964044).  Saving model ...
EarlyStopping counter: 1 out of 3.0
Validation loss decreased (0.964044 --> 0.963321).  Saving model ...
Validation loss decreased (0.963321 --> 0.958678).  Saving model ...
Validation loss decreased (0.958678 --> 0.956246).  Saving model ...
Validation loss decreased (0.956246 --> 0.954269).  Saving model ...
EarlyStopping counter: 1 out of 3.0
EarlyStopping counter: 2 out of 3.0
EarlyStopping counter: 3 out of 3.0
/localscratch/yinan.29785222.0/env/lib/python3.7/site-packages/torch/nn/functional.py:1794: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.
  warnings.warn("nn.functional.tanh is deprecated. Use torch.tanh instead.")
wandb: Waiting for W&B process to finish, PID 181513... (success).
wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: \ 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: | 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: / 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: \ 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: | 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: / 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: \ 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: | 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: / 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb:                                                                                
wandb: Run history:
wandb:     e_F1 ▁▁▃▄▄▅▅▅▅▅▆▆▆▇▇▇▇▇▇▇████████████████████
wandb:   e_loss █▇▇▆▆▆▆▆▅▅▅▅▄▄▄▄▃▃▃▃▃▂▂▂▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁
wandb:     t_F1 ▁▂▃▃▃▄▄▄▄▅▅▅▆▅▆▆▆▆▆▆▇▇▇▇▇▇▇▇▇██▇▇███████
wandb:   t_loss █▇▇▇▇▆▆▆▆▆▅▅▅▅▄▄▄▄▄▃▃▃▃▃▃▃▂▃▂▂▂▂▂▂▂▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:     e_F1 59.44303
wandb:   e_loss 0.95443
wandb:     t_F1 67.76815
wandb:   t_loss 0.83648
wandb: 
wandb: Synced 4 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Synced lucky-water-1: https://wandb.ai/yinanazhou/xl_512_bs_8_lr_1e06_es_3_lc_True_nr_True_sr_False_stem_False_lemma_True_repeat_5_fold_2/runs/2l2zck4t
wandb: Find logs at: ./wandb/run-20220330_225432-2l2zck4t/logs/debug.log
wandb: 

