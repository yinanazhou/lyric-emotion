Unloading StdEnv/2020

Due to MODULEPATH changes, the following have been reloaded:
  1) mii/1.1.1


The following have been reloaded with a version change:
  1) python/3.8.2 => python/3.7.4

Using base prefix '/cvmfs/soft.computecanada.ca/easybuild/software/2017/Core/python/3.7.4'
New python executable in /localscratch/yinan.29785233.0/env/bin/python
Installing setuptools, pip, wheel...
done.
Ignoring pip: markers 'python_version < "3"' don't match your environment
Looking in links: /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/nix/avx2, /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/nix/generic, /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic
Collecting pip
Installing collected packages: pip
  Found existing installation: pip 19.1.1
    Uninstalling pip-19.1.1:
      Successfully uninstalled pip-19.1.1
Successfully installed pip-21.2.3+computecanada
Looking in links: /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/nix/avx2, /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/nix/generic, /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/keras-2.8.0+computecanada-py2.py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/Keras_Preprocessing-1.1.2+computecanada-py3-none-any.whl
Requirement already satisfied: matplotlib in /cvmfs/soft.computecanada.ca/easybuild/software/2017/Core/scipy-stack/2019a/lib/python3.7/site-packages (from -r requirements.txt (line 3)) (3.0.2)
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/nltk-3.6.5+computecanada-py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/scikit_learn-0.22.1+computecanada-cp37-cp37m-linux_x86_64.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/tensorboard-2.3.0+computecanada-py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/tensorboard_plugin_wit-1.7.0+computecanada-py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/tensorflow_gpu-2.3.0+computecanada-cp37-cp37m-linux_x86_64.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/tensorflow_estimator-2.3.0+computecanada-py2.py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/tokenizers-0.5.2+computecanada-cp37-cp37m-linux_x86_64.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/nix/avx2/torch-1.4.0+computecanada-cp37-cp37m-linux_x86_64.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/torchtext-0.6.0+computecanada-py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/torchvision-0.8.2+computecanada-cp37-cp37m-linux_x86_64.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/transformers-2.5.1+computecanada-py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/urllib3-1.26.7+computecanada-py2.py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/joblib-1.1.0+computecanada-py2.py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/tqdm-4.63.1+computecanada-py2.py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/click-8.1.0+computecanada-py3-none-any.whl
ERROR: Could not find a version that satisfies the requirement regex>=2021.8.3 (from nltk) (from versions: 2018.1.10+computecanada, 2019.11.1+computecanada, 2020.11.13+computecanada)
ERROR: No matching distribution found for regex>=2021.8.3
Looking in links: /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/nix/avx2, /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/nix/generic, /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic
ERROR: Could not find a version that satisfies the requirement numpy==1.20.0+computacanada (from versions: 1.15.0+computecanada, 1.15.2+computecanada, 1.15.4+computecanada, 1.16.0+computecanada, 1.16.2+computecanada, 1.16.3+computecanada, 1.17.4+computecanada, 1.18.1+computecanada, 1.18.4+computecanada, 1.19.1+computecanada, 1.19.2+computecanada, 1.20.2+computecanada)
ERROR: No matching distribution found for numpy==1.20.0+computacanada
Looking in links: /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/nix/avx2, /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/nix/generic, /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/wandb-0.12.5+computecanada-py2.py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/shortuuid-1.0.1+computecanada-py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/promise-2.3+computecanada-py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/sentry_sdk-1.5.0+computecanada-py2.py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/subprocess32-3.5.4+computecanada-py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/docker_pycreds-0.4.0+computecanada-py2.py3-none-any.whl
Requirement already satisfied: requests<3,>=2.0.0 in /cvmfs/soft.computecanada.ca/easybuild/software/2017/Core/scipy-stack/2019a/lib/python3.7/site-packages (from wandb) (2.21.0)
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/yaspin-2.1.0+computecanada-py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/psutil-5.7.3+computecanada-cp37-cp37m-linux_x86_64.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/GitPython-3.1.24+computecanada-py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/PyYAML-5.3.1+computecanada-cp37-cp37m-linux_x86_64.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/protobuf-3.19.4+computecanada-py2.py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/pathtools-0.1.2+computecanada-py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/configparser-5.0.2+computecanada-py3-none-any.whl
Requirement already satisfied: python-dateutil>=2.6.1 in /cvmfs/soft.computecanada.ca/easybuild/software/2017/Core/scipy-stack/2019a/lib/python3.7/site-packages (from wandb) (2.7.5)
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/six-1.16.0+computecanada-py2.py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/click-8.1.0+computecanada-py3-none-any.whl
Requirement already satisfied: importlib-metadata in /cvmfs/soft.computecanada.ca/easybuild/software/2017/Core/scipy-stack/2019a/lib/python3.7/site-packages (from Click!=8.0.0,>=7.0->wandb) (0.8)
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/gitdb-4.0.9+computecanada-py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/typing_extensions-4.1.1+computecanada-py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/smmap-5.0.0+computecanada-py3-none-any.whl
Requirement already satisfied: urllib3<1.25,>=1.21.1 in /cvmfs/soft.computecanada.ca/easybuild/software/2017/Core/scipy-stack/2019a/lib/python3.7/site-packages (from requests<3,>=2.0.0->wandb) (1.24.1)
Requirement already satisfied: idna<2.9,>=2.5 in /cvmfs/soft.computecanada.ca/easybuild/software/2017/Core/scipy-stack/2019a/lib/python3.7/site-packages (from requests<3,>=2.0.0->wandb) (2.8)
Requirement already satisfied: certifi>=2017.4.17 in /cvmfs/soft.computecanada.ca/easybuild/software/2017/Core/scipy-stack/2019a/lib/python3.7/site-packages (from requests<3,>=2.0.0->wandb) (2018.11.29)
Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /cvmfs/soft.computecanada.ca/easybuild/software/2017/Core/scipy-stack/2019a/lib/python3.7/site-packages (from requests<3,>=2.0.0->wandb) (3.0.4)
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/termcolor-1.1.0+computecanada-py3-none-any.whl
Requirement already satisfied: zipp>=0.3.2 in /cvmfs/soft.computecanada.ca/easybuild/software/2017/Core/scipy-stack/2019a/lib/python3.7/site-packages (from importlib-metadata->Click!=8.0.0,>=7.0->wandb) (0.3.3)
Installing collected packages: smmap, typing-extensions, termcolor, six, gitdb, yaspin, subprocess32, shortuuid, sentry-sdk, PyYAML, psutil, protobuf, promise, pathtools, GitPython, docker-pycreds, configparser, Click, wandb
  Attempting uninstall: six
    Found existing installation: six 1.12.0
    Not uninstalling six at /cvmfs/soft.computecanada.ca/easybuild/software/2017/Core/scipy-stack/2019a/lib/python3.7/site-packages, outside environment /localscratch/yinan.29785233.0/env
    Can't uninstall 'six'. No files were found to uninstall.
Successfully installed Click-8.1.0+computecanada GitPython-3.1.24+computecanada PyYAML-5.3.1+computecanada configparser-5.0.2+computecanada docker-pycreds-0.4.0+computecanada gitdb-4.0.9+computecanada pathtools-0.1.2+computecanada promise-2.3+computecanada protobuf-3.19.4+computecanada psutil-5.7.3+computecanada sentry-sdk-1.5.0+computecanada shortuuid-1.0.1+computecanada six-1.16.0+computecanada smmap-5.0.0+computecanada subprocess32-3.5.4+computecanada termcolor-1.1.0+computecanada typing-extensions-4.1.1+computecanada wandb-0.12.5+computecanada yaspin-2.1.0+computecanada
Looking in links: /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/nix/avx2, /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/nix/generic, /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic
ERROR: Could not find a version that satisfies the requirement sagemaker (from versions: none)
ERROR: No matching distribution found for sagemaker
Looking in links: /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/nix/avx2, /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/nix/generic, /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/torch-1.9.1+computecanada-cp37-cp37m-linux_x86_64.whl
Requirement already satisfied: typing-extensions in /localscratch/yinan.29785233.0/env/lib/python3.7/site-packages (from torch) (4.1.1+computecanada)
Installing collected packages: torch
Successfully installed torch-1.9.1+computecanada
Looking in links: /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/nix/avx2, /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/nix/generic, /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/transformers-2.5.1+computecanada-py3-none-any.whl
Requirement already satisfied: requests in /cvmfs/soft.computecanada.ca/easybuild/software/2017/Core/scipy-stack/2019a/lib/python3.7/site-packages (from transformers==2.5.1+computecanada) (2.21.0)
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/tqdm-4.63.1+computecanada-py2.py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/regex-2020.11.13+computecanada-cp37-cp37m-linux_x86_64.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/boto3-1.21.14+computecanada-py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/sentencepiece-0.1.91+computecanada-cp37-cp37m-linux_x86_64.whl
Requirement already satisfied: numpy in /cvmfs/soft.computecanada.ca/easybuild/software/2017/Core/scipy-stack/2019a/lib/python3.7/site-packages (from transformers==2.5.1+computecanada) (1.16.0)
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/tokenizers-0.5.2+computecanada-cp37-cp37m-linux_x86_64.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/filelock-3.4.2+computecanada-py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/sacremoses-0.0.49+computecanada-py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/botocore-1.24.14+computecanada-py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/s3transfer-0.5.1+computecanada-py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/jmespath-0.10.0+computecanada-py2.py3-none-any.whl
Requirement already satisfied: python-dateutil<3.0.0,>=2.1 in /cvmfs/soft.computecanada.ca/easybuild/software/2017/Core/scipy-stack/2019a/lib/python3.7/site-packages (from botocore<1.25.0,>=1.24.14->boto3->transformers==2.5.1+computecanada) (2.7.5)
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/urllib3-1.26.9+computecanada-py2.py3-none-any.whl
Requirement already satisfied: six>=1.5 in /localscratch/yinan.29785233.0/env/lib/python3.7/site-packages (from python-dateutil<3.0.0,>=2.1->botocore<1.25.0,>=1.24.14->boto3->transformers==2.5.1+computecanada) (1.16.0+computecanada)
Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /cvmfs/soft.computecanada.ca/easybuild/software/2017/Core/scipy-stack/2019a/lib/python3.7/site-packages (from requests->transformers==2.5.1+computecanada) (3.0.4)
Requirement already satisfied: certifi>=2017.4.17 in /cvmfs/soft.computecanada.ca/easybuild/software/2017/Core/scipy-stack/2019a/lib/python3.7/site-packages (from requests->transformers==2.5.1+computecanada) (2018.11.29)
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/requests-2.27.1+computecanada-py2.py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/charset_normalizer-2.0.12+computecanada-py3-none-any.whl
Requirement already satisfied: idna<4,>=2.5 in /cvmfs/soft.computecanada.ca/easybuild/software/2017/Core/scipy-stack/2019a/lib/python3.7/site-packages (from requests->transformers==2.5.1+computecanada) (2.8)
Requirement already satisfied: click in /localscratch/yinan.29785233.0/env/lib/python3.7/site-packages (from sacremoses->transformers==2.5.1+computecanada) (8.1.0+computecanada)
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/joblib-1.1.0+computecanada-py2.py3-none-any.whl
Requirement already satisfied: importlib-metadata in /cvmfs/soft.computecanada.ca/easybuild/software/2017/Core/scipy-stack/2019a/lib/python3.7/site-packages (from click->sacremoses->transformers==2.5.1+computecanada) (0.8)
Requirement already satisfied: zipp>=0.3.2 in /cvmfs/soft.computecanada.ca/easybuild/software/2017/Core/scipy-stack/2019a/lib/python3.7/site-packages (from importlib-metadata->click->sacremoses->transformers==2.5.1+computecanada) (0.3.3)
Installing collected packages: urllib3, jmespath, botocore, tqdm, s3transfer, regex, joblib, charset-normalizer, tokenizers, sentencepiece, sacremoses, requests, filelock, boto3, transformers
  Attempting uninstall: urllib3
    Found existing installation: urllib3 1.24.1
    Not uninstalling urllib3 at /cvmfs/soft.computecanada.ca/easybuild/software/2017/Core/scipy-stack/2019a/lib/python3.7/site-packages, outside environment /localscratch/yinan.29785233.0/env
    Can't uninstall 'urllib3'. No files were found to uninstall.
  Attempting uninstall: requests
    Found existing installation: requests 2.21.0
    Not uninstalling requests at /cvmfs/soft.computecanada.ca/easybuild/software/2017/Core/scipy-stack/2019a/lib/python3.7/site-packages, outside environment /localscratch/yinan.29785233.0/env
    Can't uninstall 'requests'. No files were found to uninstall.
Successfully installed boto3-1.21.14+computecanada botocore-1.24.14+computecanada charset-normalizer-2.0.12+computecanada filelock-3.4.2+computecanada jmespath-0.10.0+computecanada joblib-1.1.0+computecanada regex-2020.11.13+computecanada requests-2.27.1+computecanada s3transfer-0.5.1+computecanada sacremoses-0.0.49+computecanada sentencepiece-0.1.91+computecanada tokenizers-0.5.2+computecanada tqdm-4.63.1+computecanada transformers-2.5.1+computecanada urllib3-1.26.9+computecanada
Looking in links: /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/nix/avx2, /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/nix/generic, /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/tensorflow_gpu-2.3.0+computecanada-cp37-cp37m-linux_x86_64.whl
Requirement already satisfied: wheel>=0.26 in /localscratch/yinan.29785233.0/env/lib/python3.7/site-packages (from tensorflow_gpu==2.3.0+computecanada) (0.33.4)
Requirement already satisfied: six>=1.12.0 in /localscratch/yinan.29785233.0/env/lib/python3.7/site-packages (from tensorflow_gpu==2.3.0+computecanada) (1.16.0+computecanada)
Requirement already satisfied: termcolor>=1.1.0 in /localscratch/yinan.29785233.0/env/lib/python3.7/site-packages (from tensorflow_gpu==2.3.0+computecanada) (1.1.0+computecanada)
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/Keras_Preprocessing-1.1.2+computecanada-py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/nix/avx2/h5py-2.10.0+computecanada-cp37-cp37m-linux_x86_64.whl
Requirement already satisfied: numpy<1.19.0,>=1.16.0 in /cvmfs/soft.computecanada.ca/easybuild/software/2017/Core/scipy-stack/2019a/lib/python3.7/site-packages (from tensorflow_gpu==2.3.0+computecanada) (1.16.0)
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/absl_py-1.0.0+computecanada-py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/gast-0.3.3+computecanada-py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/wrapt-1.11.2+computecanada-cp37-cp37m-linux_x86_64.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/grpcio-1.38.0+computecanada-cp37-cp37m-linux_x86_64.whl
Requirement already satisfied: protobuf>=3.9.2 in /localscratch/yinan.29785233.0/env/lib/python3.7/site-packages (from tensorflow_gpu==2.3.0+computecanada) (3.19.4+computecanada)
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/tensorflow_estimator-2.3.0+computecanada-py2.py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/nix/generic/scipy-1.4.1+computecanada-cp37-cp37m-linux_x86_64.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/google_pasta-0.2.0+computecanada-py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/tensorboard-2.8.0+computecanada-py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/opt_einsum-3.3.0+computecanada-py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/astunparse-1.6.3+computecanada-py2.py3-none-any.whl
Requirement already satisfied: setuptools>=41.0.0 in /localscratch/yinan.29785233.0/env/lib/python3.7/site-packages (from tensorboard<3,>=2.3.0->tensorflow_gpu==2.3.0+computecanada) (41.0.1)
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/tensorboard_plugin_wit-1.8.0+computecanada-py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/google_auth_oauthlib-0.4.6+computecanada-py2.py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/tensorboard_data_server-0.6.1+computecanada-py3-none-linux_x86_64.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/google_auth-2.3.3+computecanada-py2.py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/Markdown-3.3.6+computecanada-py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/Werkzeug-2.0.3+computecanada-py3-none-any.whl
Requirement already satisfied: requests<3,>=2.21.0 in /localscratch/yinan.29785233.0/env/lib/python3.7/site-packages (from tensorboard<3,>=2.3.0->tensorflow_gpu==2.3.0+computecanada) (2.27.1+computecanada)
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/rsa-4.8+computecanada-py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/cachetools-4.2.4+computecanada-py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/pyasn1_modules-0.2.8+computecanada-py2.py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/requests_oauthlib-1.3.0+computecanada-py2.py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/importlib_metadata-4.10.1+computecanada-py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/zipp-3.7.0+computecanada-py3-none-any.whl
Requirement already satisfied: typing-extensions>=3.6.4 in /localscratch/yinan.29785233.0/env/lib/python3.7/site-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard<3,>=2.3.0->tensorflow_gpu==2.3.0+computecanada) (4.1.1+computecanada)
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/pyasn1-0.4.8+computecanada-py2.py3-none-any.whl
Requirement already satisfied: idna<4,>=2.5 in /cvmfs/soft.computecanada.ca/easybuild/software/2017/Core/scipy-stack/2019a/lib/python3.7/site-packages (from requests<3,>=2.21.0->tensorboard<3,>=2.3.0->tensorflow_gpu==2.3.0+computecanada) (2.8)
Requirement already satisfied: charset-normalizer~=2.0.0 in /localscratch/yinan.29785233.0/env/lib/python3.7/site-packages (from requests<3,>=2.21.0->tensorboard<3,>=2.3.0->tensorflow_gpu==2.3.0+computecanada) (2.0.12+computecanada)
Requirement already satisfied: urllib3<1.27,>=1.21.1 in /localscratch/yinan.29785233.0/env/lib/python3.7/site-packages (from requests<3,>=2.21.0->tensorboard<3,>=2.3.0->tensorflow_gpu==2.3.0+computecanada) (1.26.9+computecanada)
Requirement already satisfied: certifi>=2017.4.17 in /cvmfs/soft.computecanada.ca/easybuild/software/2017/Core/scipy-stack/2019a/lib/python3.7/site-packages (from requests<3,>=2.21.0->tensorboard<3,>=2.3.0->tensorflow_gpu==2.3.0+computecanada) (2018.11.29)
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/oauthlib-3.1.1+computecanada-py2.py3-none-any.whl
Installing collected packages: pyasn1, zipp, rsa, pyasn1-modules, oauthlib, cachetools, requests-oauthlib, importlib-metadata, google-auth, werkzeug, tensorboard-plugin-wit, tensorboard-data-server, markdown, grpcio, google-auth-oauthlib, absl-py, wrapt, tensorflow-estimator, tensorboard, scipy, opt-einsum, keras-preprocessing, h5py, google-pasta, gast, astunparse, tensorflow-gpu
  Attempting uninstall: pyasn1
    Found existing installation: pyasn1 0.4.3
    Not uninstalling pyasn1 at /cvmfs/soft.computecanada.ca/easybuild/software/2017/Core/scipy-stack/2019a/lib/python3.7/site-packages, outside environment /localscratch/yinan.29785233.0/env
    Can't uninstall 'pyasn1'. No files were found to uninstall.
  Attempting uninstall: zipp
    Found existing installation: zipp 0.3.3
    Not uninstalling zipp at /cvmfs/soft.computecanada.ca/easybuild/software/2017/Core/scipy-stack/2019a/lib/python3.7/site-packages, outside environment /localscratch/yinan.29785233.0/env
    Can't uninstall 'zipp'. No files were found to uninstall.
  Attempting uninstall: importlib-metadata
    Found existing installation: importlib-metadata 0.8
    Not uninstalling importlib-metadata at /cvmfs/soft.computecanada.ca/easybuild/software/2017/Core/scipy-stack/2019a/lib/python3.7/site-packages, outside environment /localscratch/yinan.29785233.0/env
    Can't uninstall 'importlib-metadata'. No files were found to uninstall.
  Attempting uninstall: scipy
    Found existing installation: scipy 1.2.0
    Not uninstalling scipy at /cvmfs/soft.computecanada.ca/easybuild/software/2017/Core/scipy-stack/2019a/lib/python3.7/site-packages, outside environment /localscratch/yinan.29785233.0/env
    Can't uninstall 'scipy'. No files were found to uninstall.
Successfully installed absl-py-1.0.0+computecanada astunparse-1.6.3+computecanada cachetools-4.2.4+computecanada gast-0.3.3+computecanada google-auth-2.3.3+computecanada google-auth-oauthlib-0.4.6+computecanada google-pasta-0.2.0+computecanada grpcio-1.38.0+computecanada h5py-2.10.0+computecanada importlib-metadata-4.10.1+computecanada keras-preprocessing-1.1.2+computecanada markdown-3.3.6+computecanada oauthlib-3.1.1+computecanada opt-einsum-3.3.0+computecanada pyasn1-0.4.8+computecanada pyasn1-modules-0.2.8+computecanada requests-oauthlib-1.3.0+computecanada rsa-4.8+computecanada scipy-1.4.1+computecanada tensorboard-2.8.0+computecanada tensorboard-data-server-0.6.1+computecanada tensorboard-plugin-wit-1.8.0+computecanada tensorflow-estimator-2.3.0+computecanada tensorflow-gpu-2.3.0+computecanada werkzeug-2.0.3+computecanada wrapt-1.11.2+computecanada zipp-3.7.0+computecanada
Looking in links: /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/nix/avx2, /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/nix/generic, /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/keras-2.8.0+computecanada-py2.py3-none-any.whl
Installing collected packages: Keras
Successfully installed Keras-2.8.0+computecanada
Looking in links: /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/nix/avx2, /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/nix/generic, /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/urllib3-1.26.7+computecanada-py2.py3-none-any.whl
Installing collected packages: urllib3
  Attempting uninstall: urllib3
    Found existing installation: urllib3 1.26.9+computecanada
    Uninstalling urllib3-1.26.9+computecanada:
      Successfully uninstalled urllib3-1.26.9+computecanada
Successfully installed urllib3-1.26.7+computecanada
Looking in links: /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/nix/avx2, /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/nix/generic, /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/nltk-3.7+computecanada-py3-none-any.whl
Requirement already satisfied: tqdm in /localscratch/yinan.29785233.0/env/lib/python3.7/site-packages (from nltk) (4.63.1+computecanada)
Requirement already satisfied: click in /localscratch/yinan.29785233.0/env/lib/python3.7/site-packages (from nltk) (8.1.0+computecanada)
Requirement already satisfied: joblib in /localscratch/yinan.29785233.0/env/lib/python3.7/site-packages (from nltk) (1.1.0+computecanada)
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/nltk-3.6.5+computecanada-py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/nltk-3.6.3+computecanada-py3-none-any.whl
Requirement already satisfied: regex in /localscratch/yinan.29785233.0/env/lib/python3.7/site-packages (from nltk) (2020.11.13+computecanada)
Requirement already satisfied: importlib-metadata in /localscratch/yinan.29785233.0/env/lib/python3.7/site-packages (from click->nltk) (4.10.1+computecanada)
Requirement already satisfied: zipp>=0.5 in /localscratch/yinan.29785233.0/env/lib/python3.7/site-packages (from importlib-metadata->click->nltk) (3.7.0+computecanada)
Requirement already satisfied: typing-extensions>=3.6.4 in /localscratch/yinan.29785233.0/env/lib/python3.7/site-packages (from importlib-metadata->click->nltk) (4.1.1+computecanada)
Installing collected packages: nltk
Successfully installed nltk-3.6.3+computecanada
Looking in links: /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/nix/avx2, /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/nix/generic, /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/scikit_learn-0.22.1+computecanada-cp37-cp37m-linux_x86_64.whl
Requirement already satisfied: scipy>=0.17.0 in /localscratch/yinan.29785233.0/env/lib/python3.7/site-packages (from scikit-learn==0.22.1) (1.4.1+computecanada)
Requirement already satisfied: numpy>=1.11.0 in /cvmfs/soft.computecanada.ca/easybuild/software/2017/Core/scipy-stack/2019a/lib/python3.7/site-packages (from scikit-learn==0.22.1) (1.16.0)
Requirement already satisfied: joblib>=0.11 in /localscratch/yinan.29785233.0/env/lib/python3.7/site-packages (from scikit-learn==0.22.1) (1.1.0+computecanada)
Installing collected packages: scikit-learn
Successfully installed scikit-learn-0.22.1+computecanada
Looking in links: /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/nix/avx2, /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/nix/generic, /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic
Requirement already satisfied: tokenizers==0.5.2 in /localscratch/yinan.29785233.0/env/lib/python3.7/site-packages (0.5.2+computecanada)
wandb: Appending key for api.wandb.ai to your netrc file: /home/yinan/.netrc
Starting Task
2022-03-31 05:14:47.704391: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1
[nltk_data] Downloading package stopwords to /home/yinan/nltk_data...
[nltk_data]   Package stopwords is already up-to-date!
[nltk_data] Downloading package wordnet to /home/yinan/nltk_data...
[nltk_data]   Package wordnet is already up-to-date!
wandb: Currently logged in as: yinanazhou (use `wandb login --relogin` to force relogin)
wandb: wandb version 0.12.11 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
2022-03-31 05:15:07.962627: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1
wandb: Tracking run with wandb version 0.12.5
wandb: Syncing run warm-cloud-2
wandb: ⭐️ View project at https://wandb.ai/yinanazhou/xl_512_bs_8_lr_1e06_es_3_lc_True_nr_True_sr_False_stem_True_lemma_False_repeat_1_fold_1
wandb: 🚀 View run at https://wandb.ai/yinanazhou/xl_512_bs_8_lr_1e06_es_3_lc_True_nr_True_sr_False_stem_True_lemma_False_repeat_1_fold_1/runs/wp5bhkgq
wandb: Run data is saved locally in /project/6002780/yinan/Thesis_MER_Lyrics/lyric-emotion/wandb/run-20220331_051505-wp5bhkgq
wandb: Run `wandb offline` to turn off syncing.

Validation loss decreased (inf --> 1.432099).  Saving model ...
Validation loss decreased (1.432099 --> 1.413042).  Saving model ...
Validation loss decreased (1.413042 --> 1.397420).  Saving model ...
Validation loss decreased (1.397420 --> 1.385428).  Saving model ...
Validation loss decreased (1.385428 --> 1.375896).  Saving model ...
Validation loss decreased (1.375896 --> 1.367919).  Saving model ...
Validation loss decreased (1.367919 --> 1.361894).  Saving model ...
Validation loss decreased (1.361894 --> 1.356860).  Saving model ...
Validation loss decreased (1.356860 --> 1.352237).  Saving model ...
Validation loss decreased (1.352237 --> 1.347321).  Saving model ...
Validation loss decreased (1.347321 --> 1.342617).  Saving model ...
Validation loss decreased (1.342617 --> 1.338253).  Saving model ...
Validation loss decreased (1.338253 --> 1.334217).  Saving model ...
Validation loss decreased (1.334217 --> 1.330290).  Saving model ...
Validation loss decreased (1.330290 --> 1.325548).  Saving model ...
Validation loss decreased (1.325548 --> 1.322206).  Saving model ...
Validation loss decreased (1.322206 --> 1.318300).  Saving model ...
Validation loss decreased (1.318300 --> 1.313757).  Saving model ...
Validation loss decreased (1.313757 --> 1.309400).  Saving model ...
Validation loss decreased (1.309400 --> 1.305234).  Saving model ...
Validation loss decreased (1.305234 --> 1.300542).  Saving model ...
Validation loss decreased (1.300542 --> 1.294707).  Saving model ...
Validation loss decreased (1.294707 --> 1.290077).  Saving model ...
Validation loss decreased (1.290077 --> 1.284932).  Saving model ...
Validation loss decreased (1.284932 --> 1.279157).  Saving model ...
Validation loss decreased (1.279157 --> 1.274154).  Saving model ...
Validation loss decreased (1.274154 --> 1.268793).  Saving model ...
Validation loss decreased (1.268793 --> 1.265855).  Saving model ...
Validation loss decreased (1.265855 --> 1.263404).  Saving model ...
Validation loss decreased (1.263404 --> 1.260792).  Saving model ...
Validation loss decreased (1.260792 --> 1.257329).  Saving model ...
Validation loss decreased (1.257329 --> 1.252960).  Saving model ...
Validation loss decreased (1.252960 --> 1.251427).  Saving model ...
Validation loss decreased (1.251427 --> 1.245611).  Saving model ...
Validation loss decreased (1.245611 --> 1.242135).  Saving model ...
Validation loss decreased (1.242135 --> 1.239153).  Saving model ...
Validation loss decreased (1.239153 --> 1.234749).  Saving model ...
Validation loss decreased (1.234749 --> 1.232723).  Saving model ...
Validation loss decreased (1.232723 --> 1.230316).  Saving model ...
Validation loss decreased (1.230316 --> 1.228334).  Saving model ...
Validation loss decreased (1.228334 --> 1.223766).  Saving model ...
Validation loss decreased (1.223766 --> 1.219358).  Saving model ...
Validation loss decreased (1.219358 --> 1.216698).  Saving model ...
EarlyStopping counter: 1 out of 3.0
Validation loss decreased (1.216698 --> 1.213713).  Saving model ...
Validation loss decreased (1.213713 --> 1.211325).  Saving model ...
EarlyStopping counter: 1 out of 3.0
Validation loss decreased (1.211325 --> 1.209955).  Saving model ...
Validation loss decreased (1.209955 --> 1.203083).  Saving model ...
Validation loss decreased (1.203083 --> 1.198370).  Saving model ...
Validation loss decreased (1.198370 --> 1.197020).  Saving model ...
Validation loss decreased (1.197020 --> 1.193911).  Saving model ...
Validation loss decreased (1.193911 --> 1.193876).  Saving model ...
Validation loss decreased (1.193876 --> 1.190228).  Saving model ...
EarlyStopping counter: 1 out of 3.0
Validation loss decreased (1.190228 --> 1.185514).  Saving model ...
Validation loss decreased (1.185514 --> 1.178811).  Saving model ...
Validation loss decreased (1.178811 --> 1.176774).  Saving model ...
Validation loss decreased (1.176774 --> 1.173089).  Saving model ...
EarlyStopping counter: 1 out of 3.0
Validation loss decreased (1.173089 --> 1.171397).  Saving model ...
Validation loss decreased (1.171397 --> 1.171198).  Saving model ...
Validation loss decreased (1.171198 --> 1.166246).  Saving model ...
Validation loss decreased (1.166246 --> 1.165828).  Saving model ...
Validation loss decreased (1.165828 --> 1.163128).  Saving model ...
Validation loss decreased (1.163128 --> 1.157968).  Saving model ...
Validation loss decreased (1.157968 --> 1.157533).  Saving model ...
Validation loss decreased (1.157533 --> 1.154896).  Saving model ...
Validation loss decreased (1.154896 --> 1.153766).  Saving model ...
Validation loss decreased (1.153766 --> 1.152341).  Saving model ...
Validation loss decreased (1.152341 --> 1.147907).  Saving model ...
Validation loss decreased (1.147907 --> 1.143615).  Saving model ...
Validation loss decreased (1.143615 --> 1.140623).  Saving model ...
Validation loss decreased (1.140623 --> 1.135741).  Saving model ...
Validation loss decreased (1.135741 --> 1.135268).  Saving model ...
EarlyStopping counter: 1 out of 3.0
EarlyStopping counter: 2 out of 3.0
Validation loss decreased (1.135268 --> 1.131094).  Saving model ...
Validation loss decreased (1.131094 --> 1.124207).  Saving model ...
EarlyStopping counter: 1 out of 3.0
EarlyStopping counter: 2 out of 3.0
EarlyStopping counter: 3 out of 3.0
/localscratch/yinan.29785233.0/env/lib/python3.7/site-packages/torch/nn/functional.py:1794: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.
  warnings.warn("nn.functional.tanh is deprecated. Use torch.tanh instead.")
/localscratch/yinan.29785233.0/env/lib/python3.7/site-packages/transformers/optimization.py:155: UserWarning: This overload of add_ is deprecated:
	add_(Number alpha, Tensor other)
Consider using one of the following signatures instead:
	add_(Tensor other, *, Number alpha) (Triggered internally at  ../torch/csrc/utils/python_arg_parser.cpp:1025.)
  exp_avg.mul_(beta1).add_(1.0 - beta1, grad)
wandb: Waiting for W&B process to finish, PID 29473... (success).
wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: \ 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: | 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: / 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: \ 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: | 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: / 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: \ 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: | 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: / 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb:                                                                                
wandb: Run history:
wandb:     e_F1 ▁▂▃▃▅▅▆▆▆▆▆▆▆▆▆▆▆▆▇▇▇▇▇▇▇▇▇▇▇▇█▇████████
wandb:   e_loss █▇▇▆▆▆▆▆▅▅▅▅▅▄▄▄▄▄▃▃▃▃▃▃▃▃▃▂▂▂▂▂▂▂▂▁▁▁▁▁
wandb:     t_F1 ▁▁▂▃▃▂▃▄▃▄▄▄▅▅▅▅▆▆▆▆▇▇▆▇▆▆▇▆▇▇▇▇▇▇██████
wandb:   t_loss █▇▇▇▇▇▇▇▆▆▆▆▅▅▅▄▄▄▄▄▃▃▃▃▃▂▃▃▂▂▂▂▁▂▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:     e_F1 48.18561
wandb:   e_loss 1.12765
wandb:     t_F1 58.37532
wandb:   t_loss 0.9907
wandb: 
wandb: Synced 4 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Synced warm-cloud-2: https://wandb.ai/yinanazhou/xl_512_bs_8_lr_1e06_es_3_lc_True_nr_True_sr_False_stem_True_lemma_False_repeat_1_fold_1/runs/wp5bhkgq
wandb: Find logs at: ./wandb/run-20220331_051505-wp5bhkgq/logs/debug.log
wandb: 

wandb: wandb version 0.12.11 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
2022-03-31 06:07:28.360424: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1
wandb: Tracking run with wandb version 0.12.5
wandb: Syncing run avid-fire-2
wandb: ⭐️ View project at https://wandb.ai/yinanazhou/xl_512_bs_8_lr_1e06_es_3_lc_True_nr_True_sr_False_stem_True_lemma_False_repeat_1_fold_2
wandb: 🚀 View run at https://wandb.ai/yinanazhou/xl_512_bs_8_lr_1e06_es_3_lc_True_nr_True_sr_False_stem_True_lemma_False_repeat_1_fold_2/runs/af7bdfvr
wandb: Run data is saved locally in /project/6002780/yinan/Thesis_MER_Lyrics/lyric-emotion/wandb/run-20220331_060726-af7bdfvr
wandb: Run `wandb offline` to turn off syncing.

Validation loss decreased (inf --> 1.447773).  Saving model ...
Validation loss decreased (1.447773 --> 1.422715).  Saving model ...
Validation loss decreased (1.422715 --> 1.406041).  Saving model ...
Validation loss decreased (1.406041 --> 1.393908).  Saving model ...
Validation loss decreased (1.393908 --> 1.385552).  Saving model ...
Validation loss decreased (1.385552 --> 1.379240).  Saving model ...
Validation loss decreased (1.379240 --> 1.373787).  Saving model ...
Validation loss decreased (1.373787 --> 1.369804).  Saving model ...
Validation loss decreased (1.369804 --> 1.365751).  Saving model ...
Validation loss decreased (1.365751 --> 1.361882).  Saving model ...
Validation loss decreased (1.361882 --> 1.357986).  Saving model ...
Validation loss decreased (1.357986 --> 1.354381).  Saving model ...
Validation loss decreased (1.354381 --> 1.350650).  Saving model ...
Validation loss decreased (1.350650 --> 1.347021).  Saving model ...
Validation loss decreased (1.347021 --> 1.343585).  Saving model ...
Validation loss decreased (1.343585 --> 1.339915).  Saving model ...
Validation loss decreased (1.339915 --> 1.335819).  Saving model ...
Validation loss decreased (1.335819 --> 1.331991).  Saving model ...
Validation loss decreased (1.331991 --> 1.328054).  Saving model ...
Validation loss decreased (1.328054 --> 1.324009).  Saving model ...
Validation loss decreased (1.324009 --> 1.319931).  Saving model ...
Validation loss decreased (1.319931 --> 1.315666).  Saving model ...
Validation loss decreased (1.315666 --> 1.310559).  Saving model ...
Validation loss decreased (1.310559 --> 1.305959).  Saving model ...
Validation loss decreased (1.305959 --> 1.300644).  Saving model ...
Validation loss decreased (1.300644 --> 1.296093).  Saving model ...
Validation loss decreased (1.296093 --> 1.291422).  Saving model ...
Validation loss decreased (1.291422 --> 1.285931).  Saving model ...
Validation loss decreased (1.285931 --> 1.280604).  Saving model ...
Validation loss decreased (1.280604 --> 1.274324).  Saving model ...
Validation loss decreased (1.274324 --> 1.267743).  Saving model ...
Validation loss decreased (1.267743 --> 1.262698).  Saving model ...
Validation loss decreased (1.262698 --> 1.255868).  Saving model ...
Validation loss decreased (1.255868 --> 1.250186).  Saving model ...
Validation loss decreased (1.250186 --> 1.244547).  Saving model ...
Validation loss decreased (1.244547 --> 1.239179).  Saving model ...
Validation loss decreased (1.239179 --> 1.233400).  Saving model ...
Validation loss decreased (1.233400 --> 1.226960).  Saving model ...
Validation loss decreased (1.226960 --> 1.220589).  Saving model ...
Validation loss decreased (1.220589 --> 1.216031).  Saving model ...
Validation loss decreased (1.216031 --> 1.210879).  Saving model ...
Validation loss decreased (1.210879 --> 1.204770).  Saving model ...
Validation loss decreased (1.204770 --> 1.198194).  Saving model ...
Validation loss decreased (1.198194 --> 1.192703).  Saving model ...
Validation loss decreased (1.192703 --> 1.187430).  Saving model ...
Validation loss decreased (1.187430 --> 1.181458).  Saving model ...
Validation loss decreased (1.181458 --> 1.176289).  Saving model ...
Validation loss decreased (1.176289 --> 1.169975).  Saving model ...
Validation loss decreased (1.169975 --> 1.163865).  Saving model ...
Validation loss decreased (1.163865 --> 1.158909).  Saving model ...
Validation loss decreased (1.158909 --> 1.153713).  Saving model ...
Validation loss decreased (1.153713 --> 1.148351).  Saving model ...
Validation loss decreased (1.148351 --> 1.142466).  Saving model ...
Validation loss decreased (1.142466 --> 1.138514).  Saving model ...
Validation loss decreased (1.138514 --> 1.133671).  Saving model ...
Validation loss decreased (1.133671 --> 1.128757).  Saving model ...
Validation loss decreased (1.128757 --> 1.124056).  Saving model ...
Validation loss decreased (1.124056 --> 1.119411).  Saving model ...
Validation loss decreased (1.119411 --> 1.114589).  Saving model ...
Validation loss decreased (1.114589 --> 1.109480).  Saving model ...
Validation loss decreased (1.109480 --> 1.104957).  Saving model ...
Validation loss decreased (1.104957 --> 1.101130).  Saving model ...
Validation loss decreased (1.101130 --> 1.096859).  Saving model ...
Validation loss decreased (1.096859 --> 1.093289).  Saving model ...
Validation loss decreased (1.093289 --> 1.089256).  Saving model ...
Validation loss decreased (1.089256 --> 1.084851).  Saving model ...
Validation loss decreased (1.084851 --> 1.081045).  Saving model ...
Validation loss decreased (1.081045 --> 1.077209).  Saving model ...
Validation loss decreased (1.077209 --> 1.073475).  Saving model ...
Validation loss decreased (1.073475 --> 1.069387).  Saving model ...
Validation loss decreased (1.069387 --> 1.065841).  Saving model ...
Validation loss decreased (1.065841 --> 1.062503).  Saving model ...
Validation loss decreased (1.062503 --> 1.059139).  Saving model ...
Validation loss decreased (1.059139 --> 1.055569).  Saving model ...
Validation loss decreased (1.055569 --> 1.051732).  Saving model ...
Validation loss decreased (1.051732 --> 1.048571).  Saving model ...
Validation loss decreased (1.048571 --> 1.044816).  Saving model ...
Validation loss decreased (1.044816 --> 1.041664).  Saving model ...
Validation loss decreased (1.041664 --> 1.038474).  Saving model ...
Validation loss decreased (1.038474 --> 1.035767).  Saving model ...
Validation loss decreased (1.035767 --> 1.032746).  Saving model ...
Validation loss decreased (1.032746 --> 1.029574).  Saving model ...
Validation loss decreased (1.029574 --> 1.026874).  Saving model ...
Validation loss decreased (1.026874 --> 1.024029).  Saving model ...
Validation loss decreased (1.024029 --> 1.020954).  Saving model ...
Validation loss decreased (1.020954 --> 1.018675).  Saving model ...
Validation loss decreased (1.018675 --> 1.016283).  Saving model ...
Validation loss decreased (1.016283 --> 1.013684).  Saving model ...
Validation loss decreased (1.013684 --> 1.011468).  Saving model ...
Validation loss decreased (1.011468 --> 1.009160).  Saving model ...
Validation loss decreased (1.009160 --> 1.006324).  Saving model ...
Validation loss decreased (1.006324 --> 1.003501).  Saving model ...
Validation loss decreased (1.003501 --> 1.001038).  Saving model ...
Validation loss decreased (1.001038 --> 0.999176).  Saving model ...
Validation loss decreased (0.999176 --> 0.997192).  Saving model ...
Validation loss decreased (0.997192 --> 0.994574).  Saving model ...
Validation loss decreased (0.994574 --> 0.992482).  Saving model ...
Validation loss decreased (0.992482 --> 0.990593).  Saving model ...
Validation loss decreased (0.990593 --> 0.989106).  Saving model ...
Validation loss decreased (0.989106 --> 0.987137).  Saving model ...
Validation loss decreased (0.987137 --> 0.985324).  Saving model ...
Validation loss decreased (0.985324 --> 0.983870).  Saving model ...
Validation loss decreased (0.983870 --> 0.981739).  Saving model ...
Validation loss decreased (0.981739 --> 0.980956).  Saving model ...
Validation loss decreased (0.980956 --> 0.979628).  Saving model ...
Validation loss decreased (0.979628 --> 0.978034).  Saving model ...
Validation loss decreased (0.978034 --> 0.976294).  Saving model ...
Validation loss decreased (0.976294 --> 0.974634).  Saving model ...
Validation loss decreased (0.974634 --> 0.972739).  Saving model ...
Validation loss decreased (0.972739 --> 0.971519).  Saving model ...
Validation loss decreased (0.971519 --> 0.970443).  Saving model ...
Validation loss decreased (0.970443 --> 0.968918).  Saving model ...
Validation loss decreased (0.968918 --> 0.967714).  Saving model ...
Validation loss decreased (0.967714 --> 0.966326).  Saving model ...
Validation loss decreased (0.966326 --> 0.964837).  Saving model ...
Validation loss decreased (0.964837 --> 0.964105).  Saving model ...
Validation loss decreased (0.964105 --> 0.963053).  Saving model ...
Validation loss decreased (0.963053 --> 0.962360).  Saving model ...
Validation loss decreased (0.962360 --> 0.960887).  Saving model ...
Validation loss decreased (0.960887 --> 0.960205).  Saving model ...
Validation loss decreased (0.960205 --> 0.959065).  Saving model ...
Validation loss decreased (0.959065 --> 0.958792).  Saving model ...
Validation loss decreased (0.958792 --> 0.958721).  Saving model ...
Validation loss decreased (0.958721 --> 0.958595).  Saving model ...
Validation loss decreased (0.958595 --> 0.956689).  Saving model ...
Validation loss decreased (0.956689 --> 0.956489).  Saving model ...
Validation loss decreased (0.956489 --> 0.955624).  Saving model ...
Validation loss decreased (0.955624 --> 0.954579).  Saving model ...
Validation loss decreased (0.954579 --> 0.953639).  Saving model ...
Validation loss decreased (0.953639 --> 0.953006).  Saving model ...
Validation loss decreased (0.953006 --> 0.952194).  Saving model ...
Validation loss decreased (0.952194 --> 0.951871).  Saving model ...
Validation loss decreased (0.951871 --> 0.951488).  Saving model ...
Validation loss decreased (0.951488 --> 0.950018).  Saving model ...
Validation loss decreased (0.950018 --> 0.949221).  Saving model ...
EarlyStopping counter: 1 out of 3.0
Validation loss decreased (0.949221 --> 0.948516).  Saving model ...
Validation loss decreased (0.948516 --> 0.948201).  Saving model ...
Validation loss decreased (0.948201 --> 0.947786).  Saving model ...
EarlyStopping counter: 1 out of 3.0
Validation loss decreased (0.947786 --> 0.947533).  Saving model ...
Validation loss decreased (0.947533 --> 0.946895).  Saving model ...
Validation loss decreased (0.946895 --> 0.945864).  Saving model ...
Validation loss decreased (0.945864 --> 0.945690).  Saving model ...
Validation loss decreased (0.945690 --> 0.945545).  Saving model ...
EarlyStopping counter: 1 out of 3.0
EarlyStopping counter: 2 out of 3.0
EarlyStopping counter: 3 out of 3.0
/localscratch/yinan.29785233.0/env/lib/python3.7/site-packages/torch/nn/functional.py:1794: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.
  warnings.warn("nn.functional.tanh is deprecated. Use torch.tanh instead.")
wandb: Waiting for W&B process to finish, PID 32309... (success).
wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: \ 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: | 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: / 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: \ 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: | 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: / 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: \ 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: | 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: / 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb:                                                                                
wandb: Run history:
wandb:     e_F1 ▁▂▃▄▅▅▅▆▆▆▆▆▇▇▇▇▇▇▇▇▇███████████████████
wandb:   e_loss ██▇▇▇▇▆▆▆▅▅▅▄▄▄▄▃▃▃▃▃▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁
wandb:     t_F1 ▁▁▂▃▃▃▃▄▄▄▅▄▅▅▅▆▆▅▆▆▆▆▆▆▇▇▇▇▇▇▇▇▇██▇████
wandb:   t_loss ███▇▇▇▇▇▇▆▆▆▆▆▅▅▅▅▄▄▄▄▄▃▃▃▃▃▃▂▂▂▂▂▁▂▁▁▁▁
wandb: 
wandb: Run summary:
wandb:     e_F1 58.56174
wandb:   e_loss 0.94646
wandb:     t_F1 69.52178
wandb:   t_loss 0.80695
wandb: 
wandb: Synced 4 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Synced avid-fire-2: https://wandb.ai/yinanazhou/xl_512_bs_8_lr_1e06_es_3_lc_True_nr_True_sr_False_stem_True_lemma_False_repeat_1_fold_2/runs/af7bdfvr
wandb: Find logs at: ./wandb/run-20220331_060726-af7bdfvr/logs/debug.log
wandb: 

wandb: wandb version 0.12.11 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
2022-03-31 07:45:17.947338: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1
wandb: Tracking run with wandb version 0.12.5
wandb: Syncing run giddy-firebrand-2
wandb: ⭐️ View project at https://wandb.ai/yinanazhou/xl_512_bs_8_lr_1e06_es_3_lc_True_nr_True_sr_False_stem_True_lemma_False_repeat_2_fold_1
wandb: 🚀 View run at https://wandb.ai/yinanazhou/xl_512_bs_8_lr_1e06_es_3_lc_True_nr_True_sr_False_stem_True_lemma_False_repeat_2_fold_1/runs/25kckc1h
wandb: Run data is saved locally in /project/6002780/yinan/Thesis_MER_Lyrics/lyric-emotion/wandb/run-20220331_074515-25kckc1h
wandb: Run `wandb offline` to turn off syncing.

Validation loss decreased (inf --> 1.467764).  Saving model ...
Validation loss decreased (1.467764 --> 1.436821).  Saving model ...
Validation loss decreased (1.436821 --> 1.413737).  Saving model ...
Validation loss decreased (1.413737 --> 1.397865).  Saving model ...
Validation loss decreased (1.397865 --> 1.385563).  Saving model ...
Validation loss decreased (1.385563 --> 1.377400).  Saving model ...
Validation loss decreased (1.377400 --> 1.370005).  Saving model ...
Validation loss decreased (1.370005 --> 1.363885).  Saving model ...
Validation loss decreased (1.363885 --> 1.358909).  Saving model ...
Validation loss decreased (1.358909 --> 1.354873).  Saving model ...
Validation loss decreased (1.354873 --> 1.350930).  Saving model ...
Validation loss decreased (1.350930 --> 1.347085).  Saving model ...
Validation loss decreased (1.347085 --> 1.343231).  Saving model ...
Validation loss decreased (1.343231 --> 1.339451).  Saving model ...
Validation loss decreased (1.339451 --> 1.336016).  Saving model ...
Validation loss decreased (1.336016 --> 1.332331).  Saving model ...
Validation loss decreased (1.332331 --> 1.328287).  Saving model ...
Validation loss decreased (1.328287 --> 1.324455).  Saving model ...
Validation loss decreased (1.324455 --> 1.320216).  Saving model ...
Validation loss decreased (1.320216 --> 1.316222).  Saving model ...
Validation loss decreased (1.316222 --> 1.311911).  Saving model ...
Validation loss decreased (1.311911 --> 1.307547).  Saving model ...
Validation loss decreased (1.307547 --> 1.302974).  Saving model ...
Validation loss decreased (1.302974 --> 1.298604).  Saving model ...
Validation loss decreased (1.298604 --> 1.294112).  Saving model ...
Validation loss decreased (1.294112 --> 1.289847).  Saving model ...
Validation loss decreased (1.289847 --> 1.285507).  Saving model ...
Validation loss decreased (1.285507 --> 1.280357).  Saving model ...
Validation loss decreased (1.280357 --> 1.275484).  Saving model ...
Validation loss decreased (1.275484 --> 1.270606).  Saving model ...
Validation loss decreased (1.270606 --> 1.264912).  Saving model ...
Validation loss decreased (1.264912 --> 1.259766).  Saving model ...
Validation loss decreased (1.259766 --> 1.254623).  Saving model ...
Validation loss decreased (1.254623 --> 1.249499).  Saving model ...
Validation loss decreased (1.249499 --> 1.243608).  Saving model ...
Validation loss decreased (1.243608 --> 1.237535).  Saving model ...
Validation loss decreased (1.237535 --> 1.232822).  Saving model ...
Validation loss decreased (1.232822 --> 1.227394).  Saving model ...
Validation loss decreased (1.227394 --> 1.222254).  Saving model ...
Validation loss decreased (1.222254 --> 1.215903).  Saving model ...
Validation loss decreased (1.215903 --> 1.209978).  Saving model ...
Validation loss decreased (1.209978 --> 1.203164).  Saving model ...
Validation loss decreased (1.203164 --> 1.197591).  Saving model ...
Validation loss decreased (1.197591 --> 1.191479).  Saving model ...
Validation loss decreased (1.191479 --> 1.184506).  Saving model ...
Validation loss decreased (1.184506 --> 1.178936).  Saving model ...
Validation loss decreased (1.178936 --> 1.172856).  Saving model ...
Validation loss decreased (1.172856 --> 1.168759).  Saving model ...
Validation loss decreased (1.168759 --> 1.163102).  Saving model ...
Validation loss decreased (1.163102 --> 1.158323).  Saving model ...
Validation loss decreased (1.158323 --> 1.154670).  Saving model ...
Validation loss decreased (1.154670 --> 1.149914).  Saving model ...
Validation loss decreased (1.149914 --> 1.147301).  Saving model ...
Validation loss decreased (1.147301 --> 1.141252).  Saving model ...
Validation loss decreased (1.141252 --> 1.138221).  Saving model ...
Validation loss decreased (1.138221 --> 1.133489).  Saving model ...
Validation loss decreased (1.133489 --> 1.128858).  Saving model ...
Validation loss decreased (1.128858 --> 1.125451).  Saving model ...
Validation loss decreased (1.125451 --> 1.119896).  Saving model ...
Validation loss decreased (1.119896 --> 1.117493).  Saving model ...
Validation loss decreased (1.117493 --> 1.114499).  Saving model ...
Validation loss decreased (1.114499 --> 1.111539).  Saving model ...
Validation loss decreased (1.111539 --> 1.107347).  Saving model ...
Validation loss decreased (1.107347 --> 1.102704).  Saving model ...
Validation loss decreased (1.102704 --> 1.099019).  Saving model ...
Validation loss decreased (1.099019 --> 1.096484).  Saving model ...
Validation loss decreased (1.096484 --> 1.092902).  Saving model ...
Validation loss decreased (1.092902 --> 1.089699).  Saving model ...
Validation loss decreased (1.089699 --> 1.084935).  Saving model ...
Validation loss decreased (1.084935 --> 1.082996).  Saving model ...
Validation loss decreased (1.082996 --> 1.079482).  Saving model ...
Validation loss decreased (1.079482 --> 1.077782).  Saving model ...
Validation loss decreased (1.077782 --> 1.076019).  Saving model ...
Validation loss decreased (1.076019 --> 1.074984).  Saving model ...
Validation loss decreased (1.074984 --> 1.070619).  Saving model ...
Validation loss decreased (1.070619 --> 1.065919).  Saving model ...
Validation loss decreased (1.065919 --> 1.063893).  Saving model ...
Validation loss decreased (1.063893 --> 1.061216).  Saving model ...
Validation loss decreased (1.061216 --> 1.058923).  Saving model ...
Validation loss decreased (1.058923 --> 1.057629).  Saving model ...
Validation loss decreased (1.057629 --> 1.056695).  Saving model ...
Validation loss decreased (1.056695 --> 1.053177).  Saving model ...
Validation loss decreased (1.053177 --> 1.049979).  Saving model ...
Validation loss decreased (1.049979 --> 1.047968).  Saving model ...
Validation loss decreased (1.047968 --> 1.045644).  Saving model ...
Validation loss decreased (1.045644 --> 1.043907).  Saving model ...
Validation loss decreased (1.043907 --> 1.043078).  Saving model ...
Validation loss decreased (1.043078 --> 1.039611).  Saving model ...
Validation loss decreased (1.039611 --> 1.038656).  Saving model ...
Validation loss decreased (1.038656 --> 1.036858).  Saving model ...
Validation loss decreased (1.036858 --> 1.035165).  Saving model ...
Validation loss decreased (1.035165 --> 1.033937).  Saving model ...
Validation loss decreased (1.033937 --> 1.032239).  Saving model ...
Validation loss decreased (1.032239 --> 1.031858).  Saving model ...
Validation loss decreased (1.031858 --> 1.028500).  Saving model ...
Validation loss decreased (1.028500 --> 1.026876).  Saving model ...
Validation loss decreased (1.026876 --> 1.024747).  Saving model ...
Validation loss decreased (1.024747 --> 1.023732).  Saving model ...
Validation loss decreased (1.023732 --> 1.023278).  Saving model ...
Validation loss decreased (1.023278 --> 1.021815).  Saving model ...
Validation loss decreased (1.021815 --> 1.021024).  Saving model ...
Validation loss decreased (1.021024 --> 1.020611).  Saving model ...
Validation loss decreased (1.020611 --> 1.019762).  Saving model ...
Validation loss decreased (1.019762 --> 1.016565).  Saving model ...
EarlyStopping counter: 1 out of 3.0
EarlyStopping counter: 2 out of 3.0
Validation loss decreased (1.016565 --> 1.016239).  Saving model ...
Validation loss decreased (1.016239 --> 1.014324).  Saving model ...
Validation loss decreased (1.014324 --> 1.014224).  Saving model ...
Validation loss decreased (1.014224 --> 1.013221).  Saving model ...
Validation loss decreased (1.013221 --> 1.013151).  Saving model ...
Validation loss decreased (1.013151 --> 1.011562).  Saving model ...
Validation loss decreased (1.011562 --> 1.011107).  Saving model ...
EarlyStopping counter: 1 out of 3.0
Validation loss decreased (1.011107 --> 1.010636).  Saving model ...
Validation loss decreased (1.010636 --> 1.010481).  Saving model ...
EarlyStopping counter: 1 out of 3.0
Validation loss decreased (1.010481 --> 1.009763).  Saving model ...
Validation loss decreased (1.009763 --> 1.008864).  Saving model ...
Validation loss decreased (1.008864 --> 1.007845).  Saving model ...
EarlyStopping counter: 1 out of 3.0
EarlyStopping counter: 2 out of 3.0
EarlyStopping counter: 3 out of 3.0
/localscratch/yinan.29785233.0/env/lib/python3.7/site-packages/torch/nn/functional.py:1794: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.
  warnings.warn("nn.functional.tanh is deprecated. Use torch.tanh instead.")
wandb: Waiting for W&B process to finish, PID 37555... (success).
wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: \ 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: | 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: / 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: \ 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: | 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: / 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: \ 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: | 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: / 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: \ 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: | 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: / 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: \ 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: | 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: / 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: \ 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: | 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: / 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb:                                                                                
wandb: Run history:
wandb:     e_F1 ▁▁▃▄▄▄▅▅▅▆▆▆▆▇▇▇▇▇▇▇▇▇██████████████████
wandb:   e_loss █▇▇▆▆▆▆▆▅▅▅▅▄▄▄▄▃▃▃▃▃▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁
wandb:     t_F1 ▁▁▂▂▃▃▃▄▄▅▅▅▅▅▆▆▆▆▆▆▇▆▆▇█▇▇▇▇█▇▇▇███████
wandb:   t_loss █▇▇▇▇▆▆▆▆▆▆▆▅▅▅▄▄▄▄▄▄▃▃▃▃▃▂▂▂▂▂▂▂▂▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:     e_F1 56.21287
wandb:   e_loss 1.00835
wandb:     t_F1 67.54797
wandb:   t_loss 0.83106
wandb: 
wandb: Synced 4 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Synced giddy-firebrand-2: https://wandb.ai/yinanazhou/xl_512_bs_8_lr_1e06_es_3_lc_True_nr_True_sr_False_stem_True_lemma_False_repeat_2_fold_1/runs/25kckc1h
wandb: Find logs at: ./wandb/run-20220331_074515-25kckc1h/logs/debug.log
wandb: 

wandb: wandb version 0.12.11 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
2022-03-31 09:06:33.532345: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1
wandb: Tracking run with wandb version 0.12.5
wandb: Syncing run misty-morning-2
wandb: ⭐️ View project at https://wandb.ai/yinanazhou/xl_512_bs_8_lr_1e06_es_3_lc_True_nr_True_sr_False_stem_True_lemma_False_repeat_2_fold_2
wandb: 🚀 View run at https://wandb.ai/yinanazhou/xl_512_bs_8_lr_1e06_es_3_lc_True_nr_True_sr_False_stem_True_lemma_False_repeat_2_fold_2/runs/1gq3tct9
wandb: Run data is saved locally in /project/6002780/yinan/Thesis_MER_Lyrics/lyric-emotion/wandb/run-20220331_090631-1gq3tct9
wandb: Run `wandb offline` to turn off syncing.

Validation loss decreased (inf --> 1.387721).  Saving model ...
Validation loss decreased (1.387721 --> 1.383082).  Saving model ...
Validation loss decreased (1.383082 --> 1.378565).  Saving model ...
Validation loss decreased (1.378565 --> 1.374306).  Saving model ...
Validation loss decreased (1.374306 --> 1.370466).  Saving model ...
Validation loss decreased (1.370466 --> 1.367035).  Saving model ...
Validation loss decreased (1.367035 --> 1.363583).  Saving model ...
Validation loss decreased (1.363583 --> 1.360256).  Saving model ...
Validation loss decreased (1.360256 --> 1.356897).  Saving model ...
Validation loss decreased (1.356897 --> 1.353761).  Saving model ...
Validation loss decreased (1.353761 --> 1.350588).  Saving model ...
Validation loss decreased (1.350588 --> 1.347254).  Saving model ...
Validation loss decreased (1.347254 --> 1.343612).  Saving model ...
Validation loss decreased (1.343612 --> 1.340291).  Saving model ...
Validation loss decreased (1.340291 --> 1.336859).  Saving model ...
Validation loss decreased (1.336859 --> 1.333414).  Saving model ...
Validation loss decreased (1.333414 --> 1.329675).  Saving model ...
Validation loss decreased (1.329675 --> 1.325321).  Saving model ...
Validation loss decreased (1.325321 --> 1.321329).  Saving model ...
Validation loss decreased (1.321329 --> 1.317095).  Saving model ...
Validation loss decreased (1.317095 --> 1.312217).  Saving model ...
Validation loss decreased (1.312217 --> 1.307241).  Saving model ...
Validation loss decreased (1.307241 --> 1.301963).  Saving model ...
Validation loss decreased (1.301963 --> 1.296576).  Saving model ...
Validation loss decreased (1.296576 --> 1.291077).  Saving model ...
Validation loss decreased (1.291077 --> 1.286533).  Saving model ...
Validation loss decreased (1.286533 --> 1.281747).  Saving model ...
Validation loss decreased (1.281747 --> 1.275652).  Saving model ...
Validation loss decreased (1.275652 --> 1.269031).  Saving model ...
Validation loss decreased (1.269031 --> 1.263609).  Saving model ...
Validation loss decreased (1.263609 --> 1.257325).  Saving model ...
Validation loss decreased (1.257325 --> 1.251843).  Saving model ...
Validation loss decreased (1.251843 --> 1.246630).  Saving model ...
Validation loss decreased (1.246630 --> 1.240749).  Saving model ...
Validation loss decreased (1.240749 --> 1.234203).  Saving model ...
Validation loss decreased (1.234203 --> 1.228725).  Saving model ...
Validation loss decreased (1.228725 --> 1.223440).  Saving model ...
Validation loss decreased (1.223440 --> 1.219166).  Saving model ...
Validation loss decreased (1.219166 --> 1.214602).  Saving model ...
Validation loss decreased (1.214602 --> 1.209558).  Saving model ...
Validation loss decreased (1.209558 --> 1.204187).  Saving model ...
Validation loss decreased (1.204187 --> 1.200010).  Saving model ...
Validation loss decreased (1.200010 --> 1.196342).  Saving model ...
Validation loss decreased (1.196342 --> 1.192612).  Saving model ...
Validation loss decreased (1.192612 --> 1.188690).  Saving model ...
Validation loss decreased (1.188690 --> 1.184814).  Saving model ...
Validation loss decreased (1.184814 --> 1.179480).  Saving model ...
Validation loss decreased (1.179480 --> 1.175431).  Saving model ...
Validation loss decreased (1.175431 --> 1.170408).  Saving model ...
Validation loss decreased (1.170408 --> 1.166659).  Saving model ...
Validation loss decreased (1.166659 --> 1.162761).  Saving model ...
Validation loss decreased (1.162761 --> 1.158333).  Saving model ...
Validation loss decreased (1.158333 --> 1.155935).  Saving model ...
Validation loss decreased (1.155935 --> 1.152319).  Saving model ...
Validation loss decreased (1.152319 --> 1.147619).  Saving model ...
Validation loss decreased (1.147619 --> 1.144242).  Saving model ...
Validation loss decreased (1.144242 --> 1.139465).  Saving model ...
Validation loss decreased (1.139465 --> 1.137058).  Saving model ...
Validation loss decreased (1.137058 --> 1.136156).  Saving model ...
Validation loss decreased (1.136156 --> 1.129830).  Saving model ...
Validation loss decreased (1.129830 --> 1.127629).  Saving model ...
Validation loss decreased (1.127629 --> 1.124382).  Saving model ...
Validation loss decreased (1.124382 --> 1.123609).  Saving model ...
Validation loss decreased (1.123609 --> 1.119351).  Saving model ...
Validation loss decreased (1.119351 --> 1.113976).  Saving model ...
Validation loss decreased (1.113976 --> 1.110463).  Saving model ...
Validation loss decreased (1.110463 --> 1.107030).  Saving model ...
Validation loss decreased (1.107030 --> 1.104113).  Saving model ...
Validation loss decreased (1.104113 --> 1.100406).  Saving model ...
Validation loss decreased (1.100406 --> 1.098166).  Saving model ...
Validation loss decreased (1.098166 --> 1.094980).  Saving model ...
Validation loss decreased (1.094980 --> 1.092896).  Saving model ...
Validation loss decreased (1.092896 --> 1.090817).  Saving model ...
Validation loss decreased (1.090817 --> 1.086621).  Saving model ...
Validation loss decreased (1.086621 --> 1.083991).  Saving model ...
Validation loss decreased (1.083991 --> 1.082214).  Saving model ...
Validation loss decreased (1.082214 --> 1.078322).  Saving model ...
Validation loss decreased (1.078322 --> 1.073754).  Saving model ...
Validation loss decreased (1.073754 --> 1.072019).  Saving model ...
Validation loss decreased (1.072019 --> 1.068879).  Saving model ...
Validation loss decreased (1.068879 --> 1.064130).  Saving model ...
Validation loss decreased (1.064130 --> 1.063647).  Saving model ...
Validation loss decreased (1.063647 --> 1.061960).  Saving model ...
Validation loss decreased (1.061960 --> 1.059972).  Saving model ...
Validation loss decreased (1.059972 --> 1.056433).  Saving model ...
EarlyStopping counter: 1 out of 3.0
Validation loss decreased (1.056433 --> 1.051162).  Saving model ...
Validation loss decreased (1.051162 --> 1.047456).  Saving model ...
Validation loss decreased (1.047456 --> 1.045005).  Saving model ...
EarlyStopping counter: 1 out of 3.0
Validation loss decreased (1.045005 --> 1.042799).  Saving model ...
Validation loss decreased (1.042799 --> 1.040526).  Saving model ...
Validation loss decreased (1.040526 --> 1.038611).  Saving model ...
Validation loss decreased (1.038611 --> 1.034071).  Saving model ...
Validation loss decreased (1.034071 --> 1.031022).  Saving model ...
EarlyStopping counter: 1 out of 3.0
Validation loss decreased (1.031022 --> 1.029693).  Saving model ...
Validation loss decreased (1.029693 --> 1.026686).  Saving model ...
Validation loss decreased (1.026686 --> 1.024777).  Saving model ...
Validation loss decreased (1.024777 --> 1.023447).  Saving model ...
Validation loss decreased (1.023447 --> 1.021934).  Saving model ...
Validation loss decreased (1.021934 --> 1.020655).  Saving model ...
Validation loss decreased (1.020655 --> 1.019791).  Saving model ...
Validation loss decreased (1.019791 --> 1.016817).  Saving model ...
Validation loss decreased (1.016817 --> 1.014577).  Saving model ...
Validation loss decreased (1.014577 --> 1.008447).  Saving model ...
Validation loss decreased (1.008447 --> 1.008141).  Saving model ...
Validation loss decreased (1.008141 --> 1.006577).  Saving model ...
Validation loss decreased (1.006577 --> 1.006239).  Saving model ...
EarlyStopping counter: 1 out of 3.0
EarlyStopping counter: 2 out of 3.0
Validation loss decreased (1.006239 --> 1.003500).  Saving model ...
Validation loss decreased (1.003500 --> 1.001714).  Saving model ...
Validation loss decreased (1.001714 --> 0.997495).  Saving model ...
EarlyStopping counter: 1 out of 3.0
Validation loss decreased (0.997495 --> 0.996948).  Saving model ...
Validation loss decreased (0.996948 --> 0.992143).  Saving model ...
Validation loss decreased (0.992143 --> 0.990842).  Saving model ...
Validation loss decreased (0.990842 --> 0.990714).  Saving model ...
Validation loss decreased (0.990714 --> 0.988585).  Saving model ...
Validation loss decreased (0.988585 --> 0.988530).  Saving model ...
Validation loss decreased (0.988530 --> 0.987561).  Saving model ...
Validation loss decreased (0.987561 --> 0.984380).  Saving model ...
Validation loss decreased (0.984380 --> 0.984192).  Saving model ...
EarlyStopping counter: 1 out of 3.0
EarlyStopping counter: 2 out of 3.0
EarlyStopping counter: 3 out of 3.0
/localscratch/yinan.29785233.0/env/lib/python3.7/site-packages/torch/nn/functional.py:1794: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.
  warnings.warn("nn.functional.tanh is deprecated. Use torch.tanh instead.")
wandb: Waiting for W&B process to finish, PID 41922... (success).
wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: \ 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: | 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: / 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: \ 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: | 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: / 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: \ 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: | 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: / 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb:                                                                                
wandb: Run history:
wandb:     e_F1 ▁▂▃▄▅▅▅▅▅▅▅▆▆▆▆▇▆▇▇▇▇▇▇▇▇▇▇▇████████████
wandb:   e_loss ███▇▇▇▇▇▆▆▆▅▅▅▄▄▄▄▄▃▃▃▃▃▃▂▂▂▂▂▂▂▂▁▁▁▁▁▁▁
wandb:     t_F1 ▁▁▂▂▃▃▃▄▃▄▄▄▅▅▅▅▅▆▆▆▆▆▆▆▇▇▆▇▇▇▇▇▆▇▇▇████
wandb:   t_loss ██▇█▇▇▇▇▇▆▆▆▆▅▅▅▅▄▄▄▄▄▄▃▃▃▃▃▃▃▂▂▃▂▂▂▁▂▁▁
wandb: 
wandb: Run summary:
wandb:     e_F1 56.14864
wandb:   e_loss 0.98449
wandb:     t_F1 64.52037
wandb:   t_loss 0.86085
wandb: 
wandb: Synced 4 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Synced misty-morning-2: https://wandb.ai/yinanazhou/xl_512_bs_8_lr_1e06_es_3_lc_True_nr_True_sr_False_stem_True_lemma_False_repeat_2_fold_2/runs/1gq3tct9
wandb: Find logs at: ./wandb/run-20220331_090631-1gq3tct9/logs/debug.log
wandb: 

wandb: wandb version 0.12.11 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
2022-03-31 10:28:47.633238: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1
wandb: Tracking run with wandb version 0.12.5
wandb: Syncing run stellar-lake-2
wandb: ⭐️ View project at https://wandb.ai/yinanazhou/xl_512_bs_8_lr_1e06_es_3_lc_True_nr_True_sr_False_stem_True_lemma_False_repeat_3_fold_1
wandb: 🚀 View run at https://wandb.ai/yinanazhou/xl_512_bs_8_lr_1e06_es_3_lc_True_nr_True_sr_False_stem_True_lemma_False_repeat_3_fold_1/runs/2r2xlp0d
wandb: Run data is saved locally in /project/6002780/yinan/Thesis_MER_Lyrics/lyric-emotion/wandb/run-20220331_102844-2r2xlp0d
wandb: Run `wandb offline` to turn off syncing.

Validation loss decreased (inf --> 1.407877).  Saving model ...
Validation loss decreased (1.407877 --> 1.398217).  Saving model ...
Validation loss decreased (1.398217 --> 1.390603).  Saving model ...
Validation loss decreased (1.390603 --> 1.384924).  Saving model ...
Validation loss decreased (1.384924 --> 1.380083).  Saving model ...
Validation loss decreased (1.380083 --> 1.375903).  Saving model ...
Validation loss decreased (1.375903 --> 1.371794).  Saving model ...
Validation loss decreased (1.371794 --> 1.368201).  Saving model ...
Validation loss decreased (1.368201 --> 1.364901).  Saving model ...
Validation loss decreased (1.364901 --> 1.361225).  Saving model ...
Validation loss decreased (1.361225 --> 1.357778).  Saving model ...
Validation loss decreased (1.357778 --> 1.354362).  Saving model ...
Validation loss decreased (1.354362 --> 1.351121).  Saving model ...
Validation loss decreased (1.351121 --> 1.347472).  Saving model ...
Validation loss decreased (1.347472 --> 1.343727).  Saving model ...
Validation loss decreased (1.343727 --> 1.339744).  Saving model ...
Validation loss decreased (1.339744 --> 1.335468).  Saving model ...
Validation loss decreased (1.335468 --> 1.331110).  Saving model ...
Validation loss decreased (1.331110 --> 1.326810).  Saving model ...
Validation loss decreased (1.326810 --> 1.322455).  Saving model ...
Validation loss decreased (1.322455 --> 1.317407).  Saving model ...
Validation loss decreased (1.317407 --> 1.312093).  Saving model ...
Validation loss decreased (1.312093 --> 1.307063).  Saving model ...
Validation loss decreased (1.307063 --> 1.301366).  Saving model ...
Validation loss decreased (1.301366 --> 1.295406).  Saving model ...
Validation loss decreased (1.295406 --> 1.288604).  Saving model ...
Validation loss decreased (1.288604 --> 1.282315).  Saving model ...
Validation loss decreased (1.282315 --> 1.275911).  Saving model ...
Validation loss decreased (1.275911 --> 1.269350).  Saving model ...
Validation loss decreased (1.269350 --> 1.263045).  Saving model ...
Validation loss decreased (1.263045 --> 1.255829).  Saving model ...
Validation loss decreased (1.255829 --> 1.248466).  Saving model ...
Validation loss decreased (1.248466 --> 1.241915).  Saving model ...
Validation loss decreased (1.241915 --> 1.236258).  Saving model ...
Validation loss decreased (1.236258 --> 1.230776).  Saving model ...
Validation loss decreased (1.230776 --> 1.224812).  Saving model ...
Validation loss decreased (1.224812 --> 1.220804).  Saving model ...
Validation loss decreased (1.220804 --> 1.216039).  Saving model ...
Validation loss decreased (1.216039 --> 1.211148).  Saving model ...
Validation loss decreased (1.211148 --> 1.204495).  Saving model ...
Validation loss decreased (1.204495 --> 1.198039).  Saving model ...
Validation loss decreased (1.198039 --> 1.193730).  Saving model ...
Validation loss decreased (1.193730 --> 1.190251).  Saving model ...
Validation loss decreased (1.190251 --> 1.186402).  Saving model ...
Validation loss decreased (1.186402 --> 1.181334).  Saving model ...
Validation loss decreased (1.181334 --> 1.178665).  Saving model ...
Validation loss decreased (1.178665 --> 1.174152).  Saving model ...
Validation loss decreased (1.174152 --> 1.169325).  Saving model ...
Validation loss decreased (1.169325 --> 1.165008).  Saving model ...
Validation loss decreased (1.165008 --> 1.161508).  Saving model ...
Validation loss decreased (1.161508 --> 1.157022).  Saving model ...
Validation loss decreased (1.157022 --> 1.153181).  Saving model ...
Validation loss decreased (1.153181 --> 1.148498).  Saving model ...
Validation loss decreased (1.148498 --> 1.146340).  Saving model ...
Validation loss decreased (1.146340 --> 1.144325).  Saving model ...
Validation loss decreased (1.144325 --> 1.141822).  Saving model ...
Validation loss decreased (1.141822 --> 1.137040).  Saving model ...
Validation loss decreased (1.137040 --> 1.133739).  Saving model ...
Validation loss decreased (1.133739 --> 1.131689).  Saving model ...
Validation loss decreased (1.131689 --> 1.126073).  Saving model ...
Validation loss decreased (1.126073 --> 1.122770).  Saving model ...
Validation loss decreased (1.122770 --> 1.121171).  Saving model ...
Validation loss decreased (1.121171 --> 1.117189).  Saving model ...
Validation loss decreased (1.117189 --> 1.112962).  Saving model ...
Validation loss decreased (1.112962 --> 1.111270).  Saving model ...
Validation loss decreased (1.111270 --> 1.110376).  Saving model ...
Validation loss decreased (1.110376 --> 1.106532).  Saving model ...
Validation loss decreased (1.106532 --> 1.103046).  Saving model ...
Validation loss decreased (1.103046 --> 1.098485).  Saving model ...
Validation loss decreased (1.098485 --> 1.096084).  Saving model ...
Validation loss decreased (1.096084 --> 1.091836).  Saving model ...
Validation loss decreased (1.091836 --> 1.090376).  Saving model ...
Validation loss decreased (1.090376 --> 1.089539).  Saving model ...
Validation loss decreased (1.089539 --> 1.086079).  Saving model ...
Validation loss decreased (1.086079 --> 1.083776).  Saving model ...
Validation loss decreased (1.083776 --> 1.082606).  Saving model ...
Validation loss decreased (1.082606 --> 1.077383).  Saving model ...
Validation loss decreased (1.077383 --> 1.073373).  Saving model ...
Validation loss decreased (1.073373 --> 1.072179).  Saving model ...
Validation loss decreased (1.072179 --> 1.071804).  Saving model ...
Validation loss decreased (1.071804 --> 1.067768).  Saving model ...
Validation loss decreased (1.067768 --> 1.067711).  Saving model ...
Validation loss decreased (1.067711 --> 1.063307).  Saving model ...
Validation loss decreased (1.063307 --> 1.059158).  Saving model ...
Validation loss decreased (1.059158 --> 1.057117).  Saving model ...
EarlyStopping counter: 1 out of 3.0
Validation loss decreased (1.057117 --> 1.054775).  Saving model ...
Validation loss decreased (1.054775 --> 1.053346).  Saving model ...
Validation loss decreased (1.053346 --> 1.051396).  Saving model ...
Validation loss decreased (1.051396 --> 1.050030).  Saving model ...
Validation loss decreased (1.050030 --> 1.046498).  Saving model ...
Validation loss decreased (1.046498 --> 1.045512).  Saving model ...
Validation loss decreased (1.045512 --> 1.043983).  Saving model ...
Validation loss decreased (1.043983 --> 1.042301).  Saving model ...
Validation loss decreased (1.042301 --> 1.041721).  Saving model ...
Validation loss decreased (1.041721 --> 1.040762).  Saving model ...
Validation loss decreased (1.040762 --> 1.040154).  Saving model ...
Validation loss decreased (1.040154 --> 1.037198).  Saving model ...
Validation loss decreased (1.037198 --> 1.037091).  Saving model ...
Validation loss decreased (1.037091 --> 1.034541).  Saving model ...
Validation loss decreased (1.034541 --> 1.029210).  Saving model ...
EarlyStopping counter: 1 out of 3.0
Validation loss decreased (1.029210 --> 1.026729).  Saving model ...
Validation loss decreased (1.026729 --> 1.025334).  Saving model ...
EarlyStopping counter: 1 out of 3.0
EarlyStopping counter: 2 out of 3.0
Validation loss decreased (1.025334 --> 1.019597).  Saving model ...
EarlyStopping counter: 1 out of 3.0
Validation loss decreased (1.019597 --> 1.019370).  Saving model ...
EarlyStopping counter: 1 out of 3.0
Validation loss decreased (1.019370 --> 1.019288).  Saving model ...
Validation loss decreased (1.019288 --> 1.014238).  Saving model ...
EarlyStopping counter: 1 out of 3.0
Validation loss decreased (1.014238 --> 1.012515).  Saving model ...
EarlyStopping counter: 1 out of 3.0
EarlyStopping counter: 2 out of 3.0
EarlyStopping counter: 3 out of 3.0
/localscratch/yinan.29785233.0/env/lib/python3.7/site-packages/torch/nn/functional.py:1794: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.
  warnings.warn("nn.functional.tanh is deprecated. Use torch.tanh instead.")
wandb: Waiting for W&B process to finish, PID 46344... (success).
wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: \ 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: | 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: / 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: \ 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: | 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: / 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: \ 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: | 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: / 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb:                                                                                
wandb: Run history:
wandb:     e_F1 ▁▁▃▄▄▅▅▆▆▆▆▆▆▇▇▇▇▇▇▇▇▇▇▇▇▇▇█████████████
wandb:   e_loss ██▇▇▇▇▇▆▆▆▅▅▅▅▄▄▄▄▃▃▃▃▃▃▂▂▂▂▂▂▂▂▂▁▁▁▁▁▁▁
wandb:     t_F1 ▁▁▂▃▃▂▄▄▄▄▅▅▅▅▅▅▅▆▆▆▆▆▆▇▆▇▇▇▇▇▇███▇███▇█
wandb:   t_loss ███▇▇▇▇▇▇▆▆▆▆▆▅▅▅▅▄▄▄▄▄▄▃▃▃▃▃▃▃▂▂▂▂▂▂▁▁▁
wandb: 
wandb: Run summary:
wandb:     e_F1 54.64117
wandb:   e_loss 1.01343
wandb:     t_F1 66.85175
wandb:   t_loss 0.83509
wandb: 
wandb: Synced 4 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Synced stellar-lake-2: https://wandb.ai/yinanazhou/xl_512_bs_8_lr_1e06_es_3_lc_True_nr_True_sr_False_stem_True_lemma_False_repeat_3_fold_1/runs/2r2xlp0d
wandb: Find logs at: ./wandb/run-20220331_102844-2r2xlp0d/logs/debug.log
wandb: 

wandb: wandb version 0.12.11 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
2022-03-31 11:43:59.580049: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1
wandb: Tracking run with wandb version 0.12.5
wandb: Syncing run still-terrain-2
wandb: ⭐️ View project at https://wandb.ai/yinanazhou/xl_512_bs_8_lr_1e06_es_3_lc_True_nr_True_sr_False_stem_True_lemma_False_repeat_3_fold_2
wandb: 🚀 View run at https://wandb.ai/yinanazhou/xl_512_bs_8_lr_1e06_es_3_lc_True_nr_True_sr_False_stem_True_lemma_False_repeat_3_fold_2/runs/2lq021fl
wandb: Run data is saved locally in /project/6002780/yinan/Thesis_MER_Lyrics/lyric-emotion/wandb/run-20220331_114356-2lq021fl
wandb: Run `wandb offline` to turn off syncing.

Validation loss decreased (inf --> 1.436167).  Saving model ...
Validation loss decreased (1.436167 --> 1.415977).  Saving model ...
Validation loss decreased (1.415977 --> 1.400701).  Saving model ...
Validation loss decreased (1.400701 --> 1.388850).  Saving model ...
Validation loss decreased (1.388850 --> 1.379879).  Saving model ...
Validation loss decreased (1.379879 --> 1.372912).  Saving model ...
Validation loss decreased (1.372912 --> 1.367373).  Saving model ...
Validation loss decreased (1.367373 --> 1.362162).  Saving model ...
Validation loss decreased (1.362162 --> 1.357854).  Saving model ...
Validation loss decreased (1.357854 --> 1.353741).  Saving model ...
Validation loss decreased (1.353741 --> 1.350184).  Saving model ...
Validation loss decreased (1.350184 --> 1.346754).  Saving model ...
Validation loss decreased (1.346754 --> 1.343736).  Saving model ...
Validation loss decreased (1.343736 --> 1.340234).  Saving model ...
Validation loss decreased (1.340234 --> 1.337122).  Saving model ...
Validation loss decreased (1.337122 --> 1.332927).  Saving model ...
Validation loss decreased (1.332927 --> 1.328337).  Saving model ...
Validation loss decreased (1.328337 --> 1.324243).  Saving model ...
Validation loss decreased (1.324243 --> 1.320286).  Saving model ...
Validation loss decreased (1.320286 --> 1.315658).  Saving model ...
Validation loss decreased (1.315658 --> 1.311673).  Saving model ...
Validation loss decreased (1.311673 --> 1.307145).  Saving model ...
Validation loss decreased (1.307145 --> 1.302036).  Saving model ...
Validation loss decreased (1.302036 --> 1.297638).  Saving model ...
Validation loss decreased (1.297638 --> 1.293546).  Saving model ...
Validation loss decreased (1.293546 --> 1.288955).  Saving model ...
Validation loss decreased (1.288955 --> 1.283693).  Saving model ...
Validation loss decreased (1.283693 --> 1.278182).  Saving model ...
Validation loss decreased (1.278182 --> 1.272076).  Saving model ...
Validation loss decreased (1.272076 --> 1.266073).  Saving model ...
Validation loss decreased (1.266073 --> 1.260806).  Saving model ...
Validation loss decreased (1.260806 --> 1.255228).  Saving model ...
Validation loss decreased (1.255228 --> 1.249698).  Saving model ...
Validation loss decreased (1.249698 --> 1.244341).  Saving model ...
Validation loss decreased (1.244341 --> 1.237949).  Saving model ...
Validation loss decreased (1.237949 --> 1.231714).  Saving model ...
Validation loss decreased (1.231714 --> 1.227582).  Saving model ...
Validation loss decreased (1.227582 --> 1.221220).  Saving model ...
Validation loss decreased (1.221220 --> 1.216326).  Saving model ...
Validation loss decreased (1.216326 --> 1.210091).  Saving model ...
Validation loss decreased (1.210091 --> 1.204708).  Saving model ...
Validation loss decreased (1.204708 --> 1.200264).  Saving model ...
Validation loss decreased (1.200264 --> 1.194278).  Saving model ...
Validation loss decreased (1.194278 --> 1.188152).  Saving model ...
Validation loss decreased (1.188152 --> 1.182723).  Saving model ...
Validation loss decreased (1.182723 --> 1.176433).  Saving model ...
Validation loss decreased (1.176433 --> 1.172009).  Saving model ...
Validation loss decreased (1.172009 --> 1.167234).  Saving model ...
Validation loss decreased (1.167234 --> 1.161619).  Saving model ...
Validation loss decreased (1.161619 --> 1.158183).  Saving model ...
Validation loss decreased (1.158183 --> 1.153110).  Saving model ...
Validation loss decreased (1.153110 --> 1.149057).  Saving model ...
Validation loss decreased (1.149057 --> 1.144433).  Saving model ...
Validation loss decreased (1.144433 --> 1.139504).  Saving model ...
Validation loss decreased (1.139504 --> 1.136533).  Saving model ...
Validation loss decreased (1.136533 --> 1.129885).  Saving model ...
Validation loss decreased (1.129885 --> 1.127320).  Saving model ...
Validation loss decreased (1.127320 --> 1.125205).  Saving model ...
Validation loss decreased (1.125205 --> 1.120838).  Saving model ...
Validation loss decreased (1.120838 --> 1.118314).  Saving model ...
Validation loss decreased (1.118314 --> 1.114662).  Saving model ...
Validation loss decreased (1.114662 --> 1.110169).  Saving model ...
Validation loss decreased (1.110169 --> 1.106459).  Saving model ...
Validation loss decreased (1.106459 --> 1.104882).  Saving model ...
Validation loss decreased (1.104882 --> 1.102629).  Saving model ...
Validation loss decreased (1.102629 --> 1.101188).  Saving model ...
Validation loss decreased (1.101188 --> 1.096283).  Saving model ...
Validation loss decreased (1.096283 --> 1.094070).  Saving model ...
Validation loss decreased (1.094070 --> 1.089444).  Saving model ...
Validation loss decreased (1.089444 --> 1.086369).  Saving model ...
Validation loss decreased (1.086369 --> 1.082158).  Saving model ...
Validation loss decreased (1.082158 --> 1.079230).  Saving model ...
Validation loss decreased (1.079230 --> 1.077468).  Saving model ...
Validation loss decreased (1.077468 --> 1.074146).  Saving model ...
Validation loss decreased (1.074146 --> 1.071861).  Saving model ...
Validation loss decreased (1.071861 --> 1.068264).  Saving model ...
Validation loss decreased (1.068264 --> 1.066170).  Saving model ...
Validation loss decreased (1.066170 --> 1.062213).  Saving model ...
Validation loss decreased (1.062213 --> 1.058768).  Saving model ...
Validation loss decreased (1.058768 --> 1.057796).  Saving model ...
Validation loss decreased (1.057796 --> 1.055617).  Saving model ...
Validation loss decreased (1.055617 --> 1.052140).  Saving model ...
Validation loss decreased (1.052140 --> 1.051087).  Saving model ...
Validation loss decreased (1.051087 --> 1.045822).  Saving model ...
Validation loss decreased (1.045822 --> 1.043098).  Saving model ...
Validation loss decreased (1.043098 --> 1.040813).  Saving model ...
Validation loss decreased (1.040813 --> 1.038622).  Saving model ...
Validation loss decreased (1.038622 --> 1.035121).  Saving model ...
Validation loss decreased (1.035121 --> 1.032693).  Saving model ...
Validation loss decreased (1.032693 --> 1.030102).  Saving model ...
Validation loss decreased (1.030102 --> 1.028364).  Saving model ...
Validation loss decreased (1.028364 --> 1.026378).  Saving model ...
Validation loss decreased (1.026378 --> 1.024655).  Saving model ...
Validation loss decreased (1.024655 --> 1.023711).  Saving model ...
Validation loss decreased (1.023711 --> 1.020458).  Saving model ...
Validation loss decreased (1.020458 --> 1.017857).  Saving model ...
Validation loss decreased (1.017857 --> 1.016293).  Saving model ...
Validation loss decreased (1.016293 --> 1.014830).  Saving model ...
EarlyStopping counter: 1 out of 3.0
EarlyStopping counter: 2 out of 3.0
Validation loss decreased (1.014830 --> 1.013836).  Saving model ...
Validation loss decreased (1.013836 --> 1.013069).  Saving model ...
Validation loss decreased (1.013069 --> 1.007838).  Saving model ...
EarlyStopping counter: 1 out of 3.0
Validation loss decreased (1.007838 --> 1.006789).  Saving model ...
Validation loss decreased (1.006789 --> 1.003774).  Saving model ...
Validation loss decreased (1.003774 --> 1.001189).  Saving model ...
EarlyStopping counter: 1 out of 3.0
Validation loss decreased (1.001189 --> 0.998095).  Saving model ...
Validation loss decreased (0.998095 --> 0.997266).  Saving model ...
Validation loss decreased (0.997266 --> 0.994690).  Saving model ...
Validation loss decreased (0.994690 --> 0.993192).  Saving model ...
Validation loss decreased (0.993192 --> 0.991676).  Saving model ...
Validation loss decreased (0.991676 --> 0.990939).  Saving model ...
Validation loss decreased (0.990939 --> 0.990600).  Saving model ...
Validation loss decreased (0.990600 --> 0.988022).  Saving model ...
Validation loss decreased (0.988022 --> 0.986928).  Saving model ...
Validation loss decreased (0.986928 --> 0.985456).  Saving model ...
Validation loss decreased (0.985456 --> 0.985254).  Saving model ...
EarlyStopping counter: 1 out of 3.0
Validation loss decreased (0.985254 --> 0.984606).  Saving model ...
Validation loss decreased (0.984606 --> 0.982733).  Saving model ...
Validation loss decreased (0.982733 --> 0.982702).  Saving model ...
Validation loss decreased (0.982702 --> 0.981714).  Saving model ...
Validation loss decreased (0.981714 --> 0.980913).  Saving model ...
EarlyStopping counter: 1 out of 3.0
Validation loss decreased (0.980913 --> 0.978808).  Saving model ...
Validation loss decreased (0.978808 --> 0.977824).  Saving model ...
Validation loss decreased (0.977824 --> 0.976847).  Saving model ...
Validation loss decreased (0.976847 --> 0.976459).  Saving model ...
Validation loss decreased (0.976459 --> 0.976238).  Saving model ...
Validation loss decreased (0.976238 --> 0.974559).  Saving model ...
Validation loss decreased (0.974559 --> 0.974012).  Saving model ...
EarlyStopping counter: 1 out of 3.0
Validation loss decreased (0.974012 --> 0.972265).  Saving model ...
Validation loss decreased (0.972265 --> 0.971321).  Saving model ...
EarlyStopping counter: 1 out of 3.0
EarlyStopping counter: 2 out of 3.0
EarlyStopping counter: 3 out of 3.0
/localscratch/yinan.29785233.0/env/lib/python3.7/site-packages/torch/nn/functional.py:1794: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.
  warnings.warn("nn.functional.tanh is deprecated. Use torch.tanh instead.")
wandb: Waiting for W&B process to finish, PID 50351... (success).
wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: \ 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: | 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: / 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: \ 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: | 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: / 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: \ 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: | 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: / 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb:                                                                                
wandb: Run history:
wandb:     e_F1 ▁▂▃▃▃▄▄▄▄▄▅▅▅▆▆▆▆▆▆▇▇▇▇▇▇▇▇▇▇▇█▇████████
wandb:   e_loss ██▇▇▇▇▆▆▆▅▅▅▅▄▄▄▃▃▃▃▃▃▂▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁
wandb:     t_F1 ▁▂▂▂▃▃▄▄▄▄▅▅▅▅▅▆▆▆▆▆▆▇▆▇▇▇▇▇▇▇▇▇▇▇██████
wandb:   t_loss ██▇▇▇▇▇▆▆▆▆▅▅▅▅▅▄▄▄▄▄▄▃▃▃▃▃▃▂▂▂▂▂▂▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:     e_F1 59.29694
wandb:   e_loss 0.9717
wandb:     t_F1 68.5354
wandb:   t_loss 0.84065
wandb: 
wandb: Synced 4 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Synced still-terrain-2: https://wandb.ai/yinanazhou/xl_512_bs_8_lr_1e06_es_3_lc_True_nr_True_sr_False_stem_True_lemma_False_repeat_3_fold_2/runs/2lq021fl
wandb: Find logs at: ./wandb/run-20220331_114356-2lq021fl/logs/debug.log
wandb: 

wandb: wandb version 0.12.11 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
2022-03-31 13:13:56.707279: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1
wandb: Tracking run with wandb version 0.12.5
wandb: Syncing run eager-blaze-2
wandb: ⭐️ View project at https://wandb.ai/yinanazhou/xl_512_bs_8_lr_1e06_es_3_lc_True_nr_True_sr_False_stem_True_lemma_False_repeat_4_fold_1
wandb: 🚀 View run at https://wandb.ai/yinanazhou/xl_512_bs_8_lr_1e06_es_3_lc_True_nr_True_sr_False_stem_True_lemma_False_repeat_4_fold_1/runs/19mrnl3p
wandb: Run data is saved locally in /project/6002780/yinan/Thesis_MER_Lyrics/lyric-emotion/wandb/run-20220331_131353-19mrnl3p
wandb: Run `wandb offline` to turn off syncing.

Validation loss decreased (inf --> 1.410312).  Saving model ...
Validation loss decreased (1.410312 --> 1.402987).  Saving model ...
Validation loss decreased (1.402987 --> 1.396557).  Saving model ...
Validation loss decreased (1.396557 --> 1.391362).  Saving model ...
Validation loss decreased (1.391362 --> 1.387148).  Saving model ...
Validation loss decreased (1.387148 --> 1.383487).  Saving model ...
Validation loss decreased (1.383487 --> 1.379934).  Saving model ...
Validation loss decreased (1.379934 --> 1.376670).  Saving model ...
Validation loss decreased (1.376670 --> 1.373602).  Saving model ...
Validation loss decreased (1.373602 --> 1.370469).  Saving model ...
Validation loss decreased (1.370469 --> 1.367344).  Saving model ...
Validation loss decreased (1.367344 --> 1.364064).  Saving model ...
Validation loss decreased (1.364064 --> 1.360980).  Saving model ...
Validation loss decreased (1.360980 --> 1.358091).  Saving model ...
Validation loss decreased (1.358091 --> 1.354588).  Saving model ...
Validation loss decreased (1.354588 --> 1.351205).  Saving model ...
Validation loss decreased (1.351205 --> 1.347710).  Saving model ...
Validation loss decreased (1.347710 --> 1.344335).  Saving model ...
Validation loss decreased (1.344335 --> 1.340225).  Saving model ...
Validation loss decreased (1.340225 --> 1.336202).  Saving model ...
Validation loss decreased (1.336202 --> 1.331996).  Saving model ...
Validation loss decreased (1.331996 --> 1.328031).  Saving model ...
Validation loss decreased (1.328031 --> 1.323719).  Saving model ...
Validation loss decreased (1.323719 --> 1.319468).  Saving model ...
Validation loss decreased (1.319468 --> 1.314871).  Saving model ...
Validation loss decreased (1.314871 --> 1.310329).  Saving model ...
Validation loss decreased (1.310329 --> 1.305902).  Saving model ...
Validation loss decreased (1.305902 --> 1.301673).  Saving model ...
Validation loss decreased (1.301673 --> 1.296300).  Saving model ...
Validation loss decreased (1.296300 --> 1.291250).  Saving model ...
Validation loss decreased (1.291250 --> 1.286326).  Saving model ...
Validation loss decreased (1.286326 --> 1.280973).  Saving model ...
Validation loss decreased (1.280973 --> 1.275303).  Saving model ...
Validation loss decreased (1.275303 --> 1.270197).  Saving model ...
Validation loss decreased (1.270197 --> 1.264904).  Saving model ...
Validation loss decreased (1.264904 --> 1.259664).  Saving model ...
Validation loss decreased (1.259664 --> 1.254964).  Saving model ...
Validation loss decreased (1.254964 --> 1.249768).  Saving model ...
Validation loss decreased (1.249768 --> 1.245340).  Saving model ...
Validation loss decreased (1.245340 --> 1.239996).  Saving model ...
Validation loss decreased (1.239996 --> 1.235117).  Saving model ...
Validation loss decreased (1.235117 --> 1.230144).  Saving model ...
Validation loss decreased (1.230144 --> 1.225164).  Saving model ...
Validation loss decreased (1.225164 --> 1.220220).  Saving model ...
Validation loss decreased (1.220220 --> 1.216077).  Saving model ...
Validation loss decreased (1.216077 --> 1.212041).  Saving model ...
Validation loss decreased (1.212041 --> 1.207499).  Saving model ...
Validation loss decreased (1.207499 --> 1.203210).  Saving model ...
Validation loss decreased (1.203210 --> 1.198754).  Saving model ...
Validation loss decreased (1.198754 --> 1.194561).  Saving model ...
Validation loss decreased (1.194561 --> 1.190933).  Saving model ...
Validation loss decreased (1.190933 --> 1.187127).  Saving model ...
Validation loss decreased (1.187127 --> 1.183464).  Saving model ...
Validation loss decreased (1.183464 --> 1.179222).  Saving model ...
Validation loss decreased (1.179222 --> 1.175592).  Saving model ...
Validation loss decreased (1.175592 --> 1.171471).  Saving model ...
Validation loss decreased (1.171471 --> 1.168754).  Saving model ...
Validation loss decreased (1.168754 --> 1.164206).  Saving model ...
Validation loss decreased (1.164206 --> 1.160338).  Saving model ...
Validation loss decreased (1.160338 --> 1.157222).  Saving model ...
Validation loss decreased (1.157222 --> 1.153894).  Saving model ...
Validation loss decreased (1.153894 --> 1.149755).  Saving model ...
Validation loss decreased (1.149755 --> 1.146347).  Saving model ...
Validation loss decreased (1.146347 --> 1.143798).  Saving model ...
Validation loss decreased (1.143798 --> 1.138561).  Saving model ...
Validation loss decreased (1.138561 --> 1.136004).  Saving model ...
Validation loss decreased (1.136004 --> 1.131723).  Saving model ...
Validation loss decreased (1.131723 --> 1.129554).  Saving model ...
Validation loss decreased (1.129554 --> 1.126507).  Saving model ...
Validation loss decreased (1.126507 --> 1.121916).  Saving model ...
Validation loss decreased (1.121916 --> 1.119129).  Saving model ...
Validation loss decreased (1.119129 --> 1.114626).  Saving model ...
Validation loss decreased (1.114626 --> 1.111419).  Saving model ...
Validation loss decreased (1.111419 --> 1.109763).  Saving model ...
Validation loss decreased (1.109763 --> 1.106434).  Saving model ...
Validation loss decreased (1.106434 --> 1.103561).  Saving model ...
Validation loss decreased (1.103561 --> 1.101391).  Saving model ...
Validation loss decreased (1.101391 --> 1.099458).  Saving model ...
Validation loss decreased (1.099458 --> 1.096454).  Saving model ...
Validation loss decreased (1.096454 --> 1.093023).  Saving model ...
Validation loss decreased (1.093023 --> 1.090138).  Saving model ...
Validation loss decreased (1.090138 --> 1.087602).  Saving model ...
Validation loss decreased (1.087602 --> 1.084228).  Saving model ...
Validation loss decreased (1.084228 --> 1.082695).  Saving model ...
Validation loss decreased (1.082695 --> 1.080656).  Saving model ...
Validation loss decreased (1.080656 --> 1.078091).  Saving model ...
Validation loss decreased (1.078091 --> 1.075615).  Saving model ...
Validation loss decreased (1.075615 --> 1.074509).  Saving model ...
Validation loss decreased (1.074509 --> 1.072724).  Saving model ...
Validation loss decreased (1.072724 --> 1.070567).  Saving model ...
Validation loss decreased (1.070567 --> 1.069727).  Saving model ...
Validation loss decreased (1.069727 --> 1.068839).  Saving model ...
Validation loss decreased (1.068839 --> 1.065772).  Saving model ...
Validation loss decreased (1.065772 --> 1.063655).  Saving model ...
Validation loss decreased (1.063655 --> 1.061960).  Saving model ...
Validation loss decreased (1.061960 --> 1.061207).  Saving model ...
Validation loss decreased (1.061207 --> 1.059525).  Saving model ...
Validation loss decreased (1.059525 --> 1.057419).  Saving model ...
Validation loss decreased (1.057419 --> 1.055975).  Saving model ...
Validation loss decreased (1.055975 --> 1.053870).  Saving model ...
Validation loss decreased (1.053870 --> 1.050793).  Saving model ...
EarlyStopping counter: 1 out of 3.0
Validation loss decreased (1.050793 --> 1.048652).  Saving model ...
EarlyStopping counter: 1 out of 3.0
Validation loss decreased (1.048652 --> 1.046405).  Saving model ...
Validation loss decreased (1.046405 --> 1.045421).  Saving model ...
Validation loss decreased (1.045421 --> 1.044618).  Saving model ...
Validation loss decreased (1.044618 --> 1.042680).  Saving model ...
Validation loss decreased (1.042680 --> 1.041693).  Saving model ...
Validation loss decreased (1.041693 --> 1.038801).  Saving model ...
Validation loss decreased (1.038801 --> 1.037332).  Saving model ...
Validation loss decreased (1.037332 --> 1.035188).  Saving model ...
Validation loss decreased (1.035188 --> 1.033284).  Saving model ...
EarlyStopping counter: 1 out of 3.0
EarlyStopping counter: 2 out of 3.0
Validation loss decreased (1.033284 --> 1.032587).  Saving model ...
Validation loss decreased (1.032587 --> 1.030876).  Saving model ...
EarlyStopping counter: 1 out of 3.0
Validation loss decreased (1.030876 --> 1.030286).  Saving model ...
EarlyStopping counter: 1 out of 3.0
EarlyStopping counter: 2 out of 3.0
Validation loss decreased (1.030286 --> 1.028435).  Saving model ...
Validation loss decreased (1.028435 --> 1.027668).  Saving model ...
Validation loss decreased (1.027668 --> 1.026975).  Saving model ...
Validation loss decreased (1.026975 --> 1.026286).  Saving model ...
Validation loss decreased (1.026286 --> 1.025863).  Saving model ...
Validation loss decreased (1.025863 --> 1.023678).  Saving model ...
Validation loss decreased (1.023678 --> 1.022933).  Saving model ...
EarlyStopping counter: 1 out of 3.0
EarlyStopping counter: 2 out of 3.0
Validation loss decreased (1.022933 --> 1.022027).  Saving model ...
Validation loss decreased (1.022027 --> 1.021088).  Saving model ...
Validation loss decreased (1.021088 --> 1.021037).  Saving model ...
EarlyStopping counter: 1 out of 3.0
EarlyStopping counter: 2 out of 3.0
Validation loss decreased (1.021037 --> 1.020166).  Saving model ...
Validation loss decreased (1.020166 --> 1.019743).  Saving model ...
Validation loss decreased (1.019743 --> 1.018840).  Saving model ...
Validation loss decreased (1.018840 --> 1.018095).  Saving model ...
Validation loss decreased (1.018095 --> 1.017904).  Saving model ...
EarlyStopping counter: 1 out of 3.0
Validation loss decreased (1.017904 --> 1.017717).  Saving model ...
Validation loss decreased (1.017717 --> 1.017129).  Saving model ...
Validation loss decreased (1.017129 --> 1.015398).  Saving model ...
Validation loss decreased (1.015398 --> 1.015201).  Saving model ...
Validation loss decreased (1.015201 --> 1.014689).  Saving model ...
EarlyStopping counter: 1 out of 3.0
Validation loss decreased (1.014689 --> 1.014044).  Saving model ...
EarlyStopping counter: 1 out of 3.0
EarlyStopping counter: 2 out of 3.0
EarlyStopping counter: 3 out of 3.0
/localscratch/yinan.29785233.0/env/lib/python3.7/site-packages/torch/nn/functional.py:1794: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.
  warnings.warn("nn.functional.tanh is deprecated. Use torch.tanh instead.")
wandb: Waiting for W&B process to finish, PID 55169... (success).
wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: \ 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: | 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: / 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: \ 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: | 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: / 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: \ 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: | 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: / 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: \ 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: | 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: / 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb:                                                                                
wandb: Run history:
wandb:     e_F1 ▁▂▃▃▃▄▄▅▅▅▅▅▆▆▆▆▆▆▇▇▇▇▇▇▇▇██████████████
wandb:   e_loss ███▇▇▇▆▆▆▅▅▅▅▄▄▄▃▃▃▃▃▂▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁
wandb:     t_F1 ▁▁▂▃▃▃▃▄▄▅▄▅▆▅▅▆▆▆▆▆▆▆▆▆▇▇▇▇▇▇▇▇████████
wandb:   t_loss ███▇▇▇▇▇▆▆▆▆▅▅▅▅▄▄▄▄▄▄▃▃▃▃▃▃▂▂▂▂▂▂▁▂▁▁▁▁
wandb: 
wandb: Run summary:
wandb:     e_F1 55.64863
wandb:   e_loss 1.01651
wandb:     t_F1 72.12898
wandb:   t_loss 0.77027
wandb: 
wandb: Synced 4 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Synced eager-blaze-2: https://wandb.ai/yinanazhou/xl_512_bs_8_lr_1e06_es_3_lc_True_nr_True_sr_False_stem_True_lemma_False_repeat_4_fold_1/runs/19mrnl3p
wandb: Find logs at: ./wandb/run-20220331_131353-19mrnl3p/logs/debug.log
wandb: 

wandb: wandb version 0.12.11 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
2022-03-31 14:48:35.605604: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1
wandb: Tracking run with wandb version 0.12.5
wandb: Syncing run rich-frost-2
wandb: ⭐️ View project at https://wandb.ai/yinanazhou/xl_512_bs_8_lr_1e06_es_3_lc_True_nr_True_sr_False_stem_True_lemma_False_repeat_4_fold_2
wandb: 🚀 View run at https://wandb.ai/yinanazhou/xl_512_bs_8_lr_1e06_es_3_lc_True_nr_True_sr_False_stem_True_lemma_False_repeat_4_fold_2/runs/2l2l1ysa
wandb: Run data is saved locally in /project/6002780/yinan/Thesis_MER_Lyrics/lyric-emotion/wandb/run-20220331_144833-2l2l1ysa
wandb: Run `wandb offline` to turn off syncing.

Validation loss decreased (inf --> 1.469032).  Saving model ...
Validation loss decreased (1.469032 --> 1.440003).  Saving model ...
Validation loss decreased (1.440003 --> 1.419779).  Saving model ...
Validation loss decreased (1.419779 --> 1.405316).  Saving model ...
Validation loss decreased (1.405316 --> 1.395919).  Saving model ...
Validation loss decreased (1.395919 --> 1.387528).  Saving model ...
Validation loss decreased (1.387528 --> 1.381947).  Saving model ...
Validation loss decreased (1.381947 --> 1.377608).  Saving model ...
Validation loss decreased (1.377608 --> 1.373563).  Saving model ...
Validation loss decreased (1.373563 --> 1.370202).  Saving model ...
Validation loss decreased (1.370202 --> 1.366502).  Saving model ...
Validation loss decreased (1.366502 --> 1.362935).  Saving model ...
Validation loss decreased (1.362935 --> 1.359447).  Saving model ...
Validation loss decreased (1.359447 --> 1.356384).  Saving model ...
Validation loss decreased (1.356384 --> 1.352775).  Saving model ...
Validation loss decreased (1.352775 --> 1.349141).  Saving model ...
Validation loss decreased (1.349141 --> 1.345910).  Saving model ...
Validation loss decreased (1.345910 --> 1.342299).  Saving model ...
Validation loss decreased (1.342299 --> 1.338564).  Saving model ...
Validation loss decreased (1.338564 --> 1.334254).  Saving model ...
Validation loss decreased (1.334254 --> 1.330572).  Saving model ...
Validation loss decreased (1.330572 --> 1.326661).  Saving model ...
Validation loss decreased (1.326661 --> 1.322025).  Saving model ...
Validation loss decreased (1.322025 --> 1.316935).  Saving model ...
Validation loss decreased (1.316935 --> 1.312087).  Saving model ...
Validation loss decreased (1.312087 --> 1.307270).  Saving model ...
Validation loss decreased (1.307270 --> 1.302441).  Saving model ...
Validation loss decreased (1.302441 --> 1.296899).  Saving model ...
Validation loss decreased (1.296899 --> 1.290234).  Saving model ...
Validation loss decreased (1.290234 --> 1.285539).  Saving model ...
Validation loss decreased (1.285539 --> 1.281526).  Saving model ...
Validation loss decreased (1.281526 --> 1.275515).  Saving model ...
Validation loss decreased (1.275515 --> 1.270392).  Saving model ...
Validation loss decreased (1.270392 --> 1.265262).  Saving model ...
Validation loss decreased (1.265262 --> 1.258614).  Saving model ...
Validation loss decreased (1.258614 --> 1.252259).  Saving model ...
Validation loss decreased (1.252259 --> 1.245458).  Saving model ...
Validation loss decreased (1.245458 --> 1.240774).  Saving model ...
Validation loss decreased (1.240774 --> 1.232612).  Saving model ...
Validation loss decreased (1.232612 --> 1.227539).  Saving model ...
Validation loss decreased (1.227539 --> 1.222624).  Saving model ...
Validation loss decreased (1.222624 --> 1.219061).  Saving model ...
Validation loss decreased (1.219061 --> 1.214054).  Saving model ...
Validation loss decreased (1.214054 --> 1.208428).  Saving model ...
Validation loss decreased (1.208428 --> 1.203741).  Saving model ...
Validation loss decreased (1.203741 --> 1.198739).  Saving model ...
Validation loss decreased (1.198739 --> 1.195702).  Saving model ...
Validation loss decreased (1.195702 --> 1.193212).  Saving model ...
Validation loss decreased (1.193212 --> 1.186377).  Saving model ...
Validation loss decreased (1.186377 --> 1.177874).  Saving model ...
Validation loss decreased (1.177874 --> 1.175051).  Saving model ...
Validation loss decreased (1.175051 --> 1.169316).  Saving model ...
Validation loss decreased (1.169316 --> 1.165103).  Saving model ...
Validation loss decreased (1.165103 --> 1.160068).  Saving model ...
Validation loss decreased (1.160068 --> 1.158825).  Saving model ...
Validation loss decreased (1.158825 --> 1.152784).  Saving model ...
EarlyStopping counter: 1 out of 3.0
Validation loss decreased (1.152784 --> 1.148226).  Saving model ...
Validation loss decreased (1.148226 --> 1.146705).  Saving model ...
Validation loss decreased (1.146705 --> 1.141608).  Saving model ...
Validation loss decreased (1.141608 --> 1.138330).  Saving model ...
Validation loss decreased (1.138330 --> 1.134653).  Saving model ...
Validation loss decreased (1.134653 --> 1.132184).  Saving model ...
Validation loss decreased (1.132184 --> 1.130597).  Saving model ...
Validation loss decreased (1.130597 --> 1.123056).  Saving model ...
Validation loss decreased (1.123056 --> 1.119614).  Saving model ...
Validation loss decreased (1.119614 --> 1.117241).  Saving model ...
Validation loss decreased (1.117241 --> 1.116050).  Saving model ...
Validation loss decreased (1.116050 --> 1.114822).  Saving model ...
Validation loss decreased (1.114822 --> 1.109588).  Saving model ...
Validation loss decreased (1.109588 --> 1.103328).  Saving model ...
Validation loss decreased (1.103328 --> 1.100613).  Saving model ...
Validation loss decreased (1.100613 --> 1.097559).  Saving model ...
Validation loss decreased (1.097559 --> 1.095053).  Saving model ...
EarlyStopping counter: 1 out of 3.0
Validation loss decreased (1.095053 --> 1.092384).  Saving model ...
Validation loss decreased (1.092384 --> 1.091909).  Saving model ...
Validation loss decreased (1.091909 --> 1.087935).  Saving model ...
Validation loss decreased (1.087935 --> 1.085147).  Saving model ...
Validation loss decreased (1.085147 --> 1.077703).  Saving model ...
Validation loss decreased (1.077703 --> 1.077394).  Saving model ...
Validation loss decreased (1.077394 --> 1.074163).  Saving model ...
Validation loss decreased (1.074163 --> 1.071942).  Saving model ...
Validation loss decreased (1.071942 --> 1.071292).  Saving model ...
Validation loss decreased (1.071292 --> 1.066071).  Saving model ...
Validation loss decreased (1.066071 --> 1.061973).  Saving model ...
Validation loss decreased (1.061973 --> 1.061804).  Saving model ...
EarlyStopping counter: 1 out of 3.0
Validation loss decreased (1.061804 --> 1.060702).  Saving model ...
Validation loss decreased (1.060702 --> 1.057563).  Saving model ...
Validation loss decreased (1.057563 --> 1.054844).  Saving model ...
EarlyStopping counter: 1 out of 3.0
Validation loss decreased (1.054844 --> 1.053472).  Saving model ...
EarlyStopping counter: 1 out of 3.0
EarlyStopping counter: 2 out of 3.0
Validation loss decreased (1.053472 --> 1.048093).  Saving model ...
EarlyStopping counter: 1 out of 3.0
Validation loss decreased (1.048093 --> 1.046121).  Saving model ...
Validation loss decreased (1.046121 --> 1.040811).  Saving model ...
EarlyStopping counter: 1 out of 3.0
Validation loss decreased (1.040811 --> 1.038248).  Saving model ...
Validation loss decreased (1.038248 --> 1.032949).  Saving model ...
EarlyStopping counter: 1 out of 3.0
EarlyStopping counter: 2 out of 3.0
EarlyStopping counter: 3 out of 3.0
/localscratch/yinan.29785233.0/env/lib/python3.7/site-packages/torch/nn/functional.py:1794: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.
  warnings.warn("nn.functional.tanh is deprecated. Use torch.tanh instead.")
wandb: Waiting for W&B process to finish, PID 60218... (success).
wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: \ 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: | 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: / 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: \ 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: | 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: / 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb:                                                                                
wandb: Run history:
wandb:     e_F1 ▁▁▃▄▄▅▅▅▅▅▅▆▆▆▆▆▆▇▇▇▇▇▇▇▇▇▇▇▇███████████
wandb:   e_loss █▇▇▆▆▆▆▆▆▅▅▅▅▅▄▄▄▄▃▃▃▃▃▃▂▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁
wandb:     t_F1 ▁▂▃▂▃▃▄▄▄▄▄▅▅▅▅▆▆▅▆▆▆▆▆▇▇▇▇▇▇▇▇▇▇▇██▇███
wandb:   t_loss █▇▇▇▇▇▆▆▆▆▆▆▆▅▅▅▅▄▄▄▄▄▄▃▃▃▃▃▃▂▂▂▂▂▂▂▁▁▁▁
wandb: 
wandb: Run summary:
wandb:     e_F1 53.11322
wandb:   e_loss 1.03547
wandb:     t_F1 67.02888
wandb:   t_loss 0.88063
wandb: 
wandb: Synced 4 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Synced rich-frost-2: https://wandb.ai/yinanazhou/xl_512_bs_8_lr_1e06_es_3_lc_True_nr_True_sr_False_stem_True_lemma_False_repeat_4_fold_2/runs/2l2l1ysa
wandb: Find logs at: ./wandb/run-20220331_144833-2l2l1ysa/logs/debug.log
wandb: 

wandb: wandb version 0.12.11 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
2022-03-31 15:56:16.837700: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1
wandb: Tracking run with wandb version 0.12.5
wandb: Syncing run eager-breeze-1
wandb: ⭐️ View project at https://wandb.ai/yinanazhou/xl_512_bs_8_lr_1e06_es_3_lc_True_nr_True_sr_False_stem_True_lemma_False_repeat_5_fold_1
wandb: 🚀 View run at https://wandb.ai/yinanazhou/xl_512_bs_8_lr_1e06_es_3_lc_True_nr_True_sr_False_stem_True_lemma_False_repeat_5_fold_1/runs/3nb4yt3x
wandb: Run data is saved locally in /project/6002780/yinan/Thesis_MER_Lyrics/lyric-emotion/wandb/run-20220331_155614-3nb4yt3x
wandb: Run `wandb offline` to turn off syncing.

Validation loss decreased (inf --> 1.402584).  Saving model ...
Validation loss decreased (1.402584 --> 1.392716).  Saving model ...
Validation loss decreased (1.392716 --> 1.385530).  Saving model ...
Validation loss decreased (1.385530 --> 1.379520).  Saving model ...
Validation loss decreased (1.379520 --> 1.374641).  Saving model ...
Validation loss decreased (1.374641 --> 1.370057).  Saving model ...
Validation loss decreased (1.370057 --> 1.365908).  Saving model ...
Validation loss decreased (1.365908 --> 1.362363).  Saving model ...
Validation loss decreased (1.362363 --> 1.359153).  Saving model ...
Validation loss decreased (1.359153 --> 1.356109).  Saving model ...
Validation loss decreased (1.356109 --> 1.352986).  Saving model ...
Validation loss decreased (1.352986 --> 1.349899).  Saving model ...
Validation loss decreased (1.349899 --> 1.346463).  Saving model ...
Validation loss decreased (1.346463 --> 1.343285).  Saving model ...
Validation loss decreased (1.343285 --> 1.339865).  Saving model ...
Validation loss decreased (1.339865 --> 1.336472).  Saving model ...
Validation loss decreased (1.336472 --> 1.333042).  Saving model ...
Validation loss decreased (1.333042 --> 1.329421).  Saving model ...
Validation loss decreased (1.329421 --> 1.325636).  Saving model ...
Validation loss decreased (1.325636 --> 1.321648).  Saving model ...
Validation loss decreased (1.321648 --> 1.317421).  Saving model ...
Validation loss decreased (1.317421 --> 1.313112).  Saving model ...
Validation loss decreased (1.313112 --> 1.308532).  Saving model ...
Validation loss decreased (1.308532 --> 1.304217).  Saving model ...
Validation loss decreased (1.304217 --> 1.299500).  Saving model ...
Validation loss decreased (1.299500 --> 1.294630).  Saving model ...
Validation loss decreased (1.294630 --> 1.289887).  Saving model ...
Validation loss decreased (1.289887 --> 1.285099).  Saving model ...
Validation loss decreased (1.285099 --> 1.280361).  Saving model ...
Validation loss decreased (1.280361 --> 1.275850).  Saving model ...
Validation loss decreased (1.275850 --> 1.271138).  Saving model ...
Validation loss decreased (1.271138 --> 1.266091).  Saving model ...
Validation loss decreased (1.266091 --> 1.261455).  Saving model ...
Validation loss decreased (1.261455 --> 1.256497).  Saving model ...
Validation loss decreased (1.256497 --> 1.250693).  Saving model ...
Validation loss decreased (1.250693 --> 1.245937).  Saving model ...
Validation loss decreased (1.245937 --> 1.240997).  Saving model ...
Validation loss decreased (1.240997 --> 1.236302).  Saving model ...
Validation loss decreased (1.236302 --> 1.232934).  Saving model ...
Validation loss decreased (1.232934 --> 1.228378).  Saving model ...
Validation loss decreased (1.228378 --> 1.222904).  Saving model ...
Validation loss decreased (1.222904 --> 1.217481).  Saving model ...
Validation loss decreased (1.217481 --> 1.212551).  Saving model ...
Validation loss decreased (1.212551 --> 1.208328).  Saving model ...
Validation loss decreased (1.208328 --> 1.204378).  Saving model ...
Validation loss decreased (1.204378 --> 1.200141).  Saving model ...
Validation loss decreased (1.200141 --> 1.196739).  Saving model ...
Validation loss decreased (1.196739 --> 1.193056).  Saving model ...
Validation loss decreased (1.193056 --> 1.189889).  Saving model ...
Validation loss decreased (1.189889 --> 1.187183).  Saving model ...
Validation loss decreased (1.187183 --> 1.182135).  Saving model ...
Validation loss decreased (1.182135 --> 1.177846).  Saving model ...
Validation loss decreased (1.177846 --> 1.173836).  Saving model ...
Validation loss decreased (1.173836 --> 1.169787).  Saving model ...
Validation loss decreased (1.169787 --> 1.166424).  Saving model ...
Validation loss decreased (1.166424 --> 1.162936).  Saving model ...
Validation loss decreased (1.162936 --> 1.159398).  Saving model ...
Validation loss decreased (1.159398 --> 1.156024).  Saving model ...
Validation loss decreased (1.156024 --> 1.152916).  Saving model ...
Validation loss decreased (1.152916 --> 1.149673).  Saving model ...
Validation loss decreased (1.149673 --> 1.144623).  Saving model ...
Validation loss decreased (1.144623 --> 1.142896).  Saving model ...
Validation loss decreased (1.142896 --> 1.139789).  Saving model ...
Validation loss decreased (1.139789 --> 1.136524).  Saving model ...
Validation loss decreased (1.136524 --> 1.132801).  Saving model ...
Validation loss decreased (1.132801 --> 1.129276).  Saving model ...
Validation loss decreased (1.129276 --> 1.126946).  Saving model ...
Validation loss decreased (1.126946 --> 1.124042).  Saving model ...
Validation loss decreased (1.124042 --> 1.122385).  Saving model ...
Validation loss decreased (1.122385 --> 1.119404).  Saving model ...
Validation loss decreased (1.119404 --> 1.116637).  Saving model ...
Validation loss decreased (1.116637 --> 1.112977).  Saving model ...
Validation loss decreased (1.112977 --> 1.110504).  Saving model ...
Validation loss decreased (1.110504 --> 1.109226).  Saving model ...
Validation loss decreased (1.109226 --> 1.104661).  Saving model ...
Validation loss decreased (1.104661 --> 1.101587).  Saving model ...
Validation loss decreased (1.101587 --> 1.097960).  Saving model ...
Validation loss decreased (1.097960 --> 1.095221).  Saving model ...
Validation loss decreased (1.095221 --> 1.093627).  Saving model ...
Validation loss decreased (1.093627 --> 1.090495).  Saving model ...
Validation loss decreased (1.090495 --> 1.088601).  Saving model ...
Validation loss decreased (1.088601 --> 1.084688).  Saving model ...
Validation loss decreased (1.084688 --> 1.081190).  Saving model ...
Validation loss decreased (1.081190 --> 1.078572).  Saving model ...
Validation loss decreased (1.078572 --> 1.076525).  Saving model ...
Validation loss decreased (1.076525 --> 1.074676).  Saving model ...
Validation loss decreased (1.074676 --> 1.071450).  Saving model ...
Validation loss decreased (1.071450 --> 1.070283).  Saving model ...
Validation loss decreased (1.070283 --> 1.067938).  Saving model ...
Validation loss decreased (1.067938 --> 1.065839).  Saving model ...
Validation loss decreased (1.065839 --> 1.062704).  Saving model ...
Validation loss decreased (1.062704 --> 1.061426).  Saving model ...
Validation loss decreased (1.061426 --> 1.060497).  Saving model ...
Validation loss decreased (1.060497 --> 1.058737).  Saving model ...
Validation loss decreased (1.058737 --> 1.056585).  Saving model ...
Validation loss decreased (1.056585 --> 1.055272).  Saving model ...
Validation loss decreased (1.055272 --> 1.054716).  Saving model ...
Validation loss decreased (1.054716 --> 1.051034).  Saving model ...
Validation loss decreased (1.051034 --> 1.048496).  Saving model ...
Validation loss decreased (1.048496 --> 1.047407).  Saving model ...
Validation loss decreased (1.047407 --> 1.045942).  Saving model ...
Validation loss decreased (1.045942 --> 1.045241).  Saving model ...
Validation loss decreased (1.045241 --> 1.042608).  Saving model ...
Validation loss decreased (1.042608 --> 1.042208).  Saving model ...
Validation loss decreased (1.042208 --> 1.038939).  Saving model ...
Validation loss decreased (1.038939 --> 1.038745).  Saving model ...
Validation loss decreased (1.038745 --> 1.037195).  Saving model ...
Validation loss decreased (1.037195 --> 1.037126).  Saving model ...
Validation loss decreased (1.037126 --> 1.035156).  Saving model ...
Validation loss decreased (1.035156 --> 1.035108).  Saving model ...
Validation loss decreased (1.035108 --> 1.033761).  Saving model ...
Validation loss decreased (1.033761 --> 1.032440).  Saving model ...
Validation loss decreased (1.032440 --> 1.031802).  Saving model ...
Validation loss decreased (1.031802 --> 1.031154).  Saving model ...
Validation loss decreased (1.031154 --> 1.029801).  Saving model ...
Validation loss decreased (1.029801 --> 1.027876).  Saving model ...
Validation loss decreased (1.027876 --> 1.027551).  Saving model ...
Validation loss decreased (1.027551 --> 1.024982).  Saving model ...
Validation loss decreased (1.024982 --> 1.023010).  Saving model ...
Validation loss decreased (1.023010 --> 1.022505).  Saving model ...
EarlyStopping counter: 1 out of 3.0
Validation loss decreased (1.022505 --> 1.022227).  Saving model ...
Validation loss decreased (1.022227 --> 1.020559).  Saving model ...
Validation loss decreased (1.020559 --> 1.018949).  Saving model ...
Validation loss decreased (1.018949 --> 1.017587).  Saving model ...
EarlyStopping counter: 1 out of 3.0
EarlyStopping counter: 2 out of 3.0
EarlyStopping counter: 3 out of 3.0
/localscratch/yinan.29785233.0/env/lib/python3.7/site-packages/torch/nn/functional.py:1794: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.
  warnings.warn("nn.functional.tanh is deprecated. Use torch.tanh instead.")
wandb: Waiting for W&B process to finish, PID 63856... (success).
wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: \ 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: | 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: / 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: \ 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: | 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: / 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: \ 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: | 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: / 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb:                                                                                
wandb: Run history:
wandb:     e_F1 ▁▂▃▃▄▄▄▅▅▅▅▆▆▆▆▆▆▆▆▇▇▇▇▇▇▇▇▇████████████
wandb:   e_loss ██▇▇▇▇▇▆▆▆▅▅▅▅▄▄▄▄▃▃▃▃▃▃▂▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁
wandb:     t_F1 ▁▂▂▂▂▄▃▃▄▄▄▅▅▅▅▅▅▆▆▆▆▇▆▇▇▇▇▇▇▇▇▇▇▇▇▇▇███
wandb:   t_loss ████▇▇▇▇▇▆▆▆▆▅▅▅▅▄▄▄▄▄▄▃▃▃▃▃▃▂▂▂▂▂▂▂▂▁▁▁
wandb: 
wandb: Run summary:
wandb:     e_F1 52.47297
wandb:   e_loss 1.01844
wandb:     t_F1 69.2456
wandb:   t_loss 0.80802
wandb: 
wandb: Synced 4 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Synced eager-breeze-1: https://wandb.ai/yinanazhou/xl_512_bs_8_lr_1e06_es_3_lc_True_nr_True_sr_False_stem_True_lemma_False_repeat_5_fold_1/runs/3nb4yt3x
wandb: Find logs at: ./wandb/run-20220331_155614-3nb4yt3x/logs/debug.log
wandb: 

wandb: wandb version 0.12.11 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
2022-03-31 17:20:28.163789: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1
wandb: Tracking run with wandb version 0.12.5
wandb: Syncing run dashing-resonance-1
wandb: ⭐️ View project at https://wandb.ai/yinanazhou/xl_512_bs_8_lr_1e06_es_3_lc_True_nr_True_sr_False_stem_True_lemma_False_repeat_5_fold_2
wandb: 🚀 View run at https://wandb.ai/yinanazhou/xl_512_bs_8_lr_1e06_es_3_lc_True_nr_True_sr_False_stem_True_lemma_False_repeat_5_fold_2/runs/2d7aa87m
wandb: Run data is saved locally in /project/6002780/yinan/Thesis_MER_Lyrics/lyric-emotion/wandb/run-20220331_172025-2d7aa87m
wandb: Run `wandb offline` to turn off syncing.

Validation loss decreased (inf --> 1.481537).  Saving model ...
Validation loss decreased (1.481537 --> 1.444883).  Saving model ...
Validation loss decreased (1.444883 --> 1.417763).  Saving model ...
Validation loss decreased (1.417763 --> 1.396924).  Saving model ...
Validation loss decreased (1.396924 --> 1.382837).  Saving model ...
Validation loss decreased (1.382837 --> 1.372479).  Saving model ...
Validation loss decreased (1.372479 --> 1.365035).  Saving model ...
Validation loss decreased (1.365035 --> 1.358853).  Saving model ...
Validation loss decreased (1.358853 --> 1.353625).  Saving model ...
Validation loss decreased (1.353625 --> 1.348584).  Saving model ...
Validation loss decreased (1.348584 --> 1.344425).  Saving model ...
Validation loss decreased (1.344425 --> 1.340052).  Saving model ...
Validation loss decreased (1.340052 --> 1.335869).  Saving model ...
Validation loss decreased (1.335869 --> 1.331617).  Saving model ...
Validation loss decreased (1.331617 --> 1.327630).  Saving model ...
Validation loss decreased (1.327630 --> 1.323503).  Saving model ...
Validation loss decreased (1.323503 --> 1.319108).  Saving model ...
Validation loss decreased (1.319108 --> 1.315254).  Saving model ...
Validation loss decreased (1.315254 --> 1.310560).  Saving model ...
Validation loss decreased (1.310560 --> 1.305407).  Saving model ...
Validation loss decreased (1.305407 --> 1.300865).  Saving model ...
Validation loss decreased (1.300865 --> 1.296218).  Saving model ...
Validation loss decreased (1.296218 --> 1.291189).  Saving model ...
Validation loss decreased (1.291189 --> 1.285574).  Saving model ...
Validation loss decreased (1.285574 --> 1.279895).  Saving model ...
Validation loss decreased (1.279895 --> 1.276152).  Saving model ...
Validation loss decreased (1.276152 --> 1.269878).  Saving model ...
Validation loss decreased (1.269878 --> 1.263640).  Saving model ...
Validation loss decreased (1.263640 --> 1.257193).  Saving model ...
Validation loss decreased (1.257193 --> 1.251447).  Saving model ...
Validation loss decreased (1.251447 --> 1.244951).  Saving model ...
Validation loss decreased (1.244951 --> 1.239344).  Saving model ...
Validation loss decreased (1.239344 --> 1.233855).  Saving model ...
Validation loss decreased (1.233855 --> 1.227295).  Saving model ...
Validation loss decreased (1.227295 --> 1.220535).  Saving model ...
Validation loss decreased (1.220535 --> 1.214070).  Saving model ...
Validation loss decreased (1.214070 --> 1.208058).  Saving model ...
Validation loss decreased (1.208058 --> 1.204218).  Saving model ...
Validation loss decreased (1.204218 --> 1.197671).  Saving model ...
Validation loss decreased (1.197671 --> 1.191045).  Saving model ...
Validation loss decreased (1.191045 --> 1.185755).  Saving model ...
Validation loss decreased (1.185755 --> 1.181189).  Saving model ...
Validation loss decreased (1.181189 --> 1.176283).  Saving model ...
Validation loss decreased (1.176283 --> 1.171671).  Saving model ...
Validation loss decreased (1.171671 --> 1.166309).  Saving model ...
Validation loss decreased (1.166309 --> 1.161417).  Saving model ...
Validation loss decreased (1.161417 --> 1.158576).  Saving model ...
Validation loss decreased (1.158576 --> 1.151693).  Saving model ...
Validation loss decreased (1.151693 --> 1.146114).  Saving model ...
Validation loss decreased (1.146114 --> 1.142615).  Saving model ...
Validation loss decreased (1.142615 --> 1.139028).  Saving model ...
Validation loss decreased (1.139028 --> 1.132602).  Saving model ...
Validation loss decreased (1.132602 --> 1.129752).  Saving model ...
Validation loss decreased (1.129752 --> 1.125089).  Saving model ...
Validation loss decreased (1.125089 --> 1.120560).  Saving model ...
Validation loss decreased (1.120560 --> 1.119103).  Saving model ...
Validation loss decreased (1.119103 --> 1.115451).  Saving model ...
Validation loss decreased (1.115451 --> 1.113335).  Saving model ...
Validation loss decreased (1.113335 --> 1.109312).  Saving model ...
Validation loss decreased (1.109312 --> 1.105078).  Saving model ...
Validation loss decreased (1.105078 --> 1.102552).  Saving model ...
Validation loss decreased (1.102552 --> 1.099452).  Saving model ...
Validation loss decreased (1.099452 --> 1.092201).  Saving model ...
Validation loss decreased (1.092201 --> 1.088934).  Saving model ...
Validation loss decreased (1.088934 --> 1.087962).  Saving model ...
Validation loss decreased (1.087962 --> 1.083866).  Saving model ...
Validation loss decreased (1.083866 --> 1.077530).  Saving model ...
Validation loss decreased (1.077530 --> 1.074243).  Saving model ...
Validation loss decreased (1.074243 --> 1.071651).  Saving model ...
Validation loss decreased (1.071651 --> 1.069891).  Saving model ...
Validation loss decreased (1.069891 --> 1.067029).  Saving model ...
Validation loss decreased (1.067029 --> 1.062789).  Saving model ...
EarlyStopping counter: 1 out of 3.0
Validation loss decreased (1.062789 --> 1.060278).  Saving model ...
Validation loss decreased (1.060278 --> 1.056165).  Saving model ...
Validation loss decreased (1.056165 --> 1.052750).  Saving model ...
Validation loss decreased (1.052750 --> 1.049002).  Saving model ...
Validation loss decreased (1.049002 --> 1.046772).  Saving model ...
Validation loss decreased (1.046772 --> 1.046296).  Saving model ...
Validation loss decreased (1.046296 --> 1.041353).  Saving model ...
Validation loss decreased (1.041353 --> 1.039698).  Saving model ...
Validation loss decreased (1.039698 --> 1.037598).  Saving model ...
Validation loss decreased (1.037598 --> 1.036094).  Saving model ...
Validation loss decreased (1.036094 --> 1.033539).  Saving model ...
Validation loss decreased (1.033539 --> 1.029313).  Saving model ...
Validation loss decreased (1.029313 --> 1.027391).  Saving model ...
Validation loss decreased (1.027391 --> 1.026346).  Saving model ...
Validation loss decreased (1.026346 --> 1.025385).  Saving model ...
Validation loss decreased (1.025385 --> 1.023601).  Saving model ...
Validation loss decreased (1.023601 --> 1.022672).  Saving model ...
Validation loss decreased (1.022672 --> 1.020202).  Saving model ...
Validation loss decreased (1.020202 --> 1.019497).  Saving model ...
Validation loss decreased (1.019497 --> 1.018153).  Saving model ...
Validation loss decreased (1.018153 --> 1.016125).  Saving model ...
Validation loss decreased (1.016125 --> 1.010828).  Saving model ...
Validation loss decreased (1.010828 --> 1.010743).  Saving model ...
Validation loss decreased (1.010743 --> 1.007220).  Saving model ...
EarlyStopping counter: 1 out of 3.0
Validation loss decreased (1.007220 --> 1.004259).  Saving model ...
Validation loss decreased (1.004259 --> 1.001123).  Saving model ...
Validation loss decreased (1.001123 --> 1.001077).  Saving model ...
Validation loss decreased (1.001077 --> 0.996468).  Saving model ...
Validation loss decreased (0.996468 --> 0.995176).  Saving model ...
EarlyStopping counter: 1 out of 3.0
Validation loss decreased (0.995176 --> 0.994313).  Saving model ...
Validation loss decreased (0.994313 --> 0.993752).  Saving model ...
Validation loss decreased (0.993752 --> 0.992473).  Saving model ...
Validation loss decreased (0.992473 --> 0.992467).  Saving model ...
EarlyStopping counter: 1 out of 3.0
Validation loss decreased (0.992467 --> 0.987947).  Saving model ...
Validation loss decreased (0.987947 --> 0.987872).  Saving model ...
Validation loss decreased (0.987872 --> 0.987237).  Saving model ...
Validation loss decreased (0.987237 --> 0.984320).  Saving model ...
EarlyStopping counter: 1 out of 3.0
EarlyStopping counter: 2 out of 3.0
Validation loss decreased (0.984320 --> 0.981544).  Saving model ...
Validation loss decreased (0.981544 --> 0.977455).  Saving model ...
EarlyStopping counter: 1 out of 3.0
EarlyStopping counter: 2 out of 3.0
Validation loss decreased (0.977455 --> 0.977338).  Saving model ...
EarlyStopping counter: 1 out of 3.0
Validation loss decreased (0.977338 --> 0.975208).  Saving model ...
EarlyStopping counter: 1 out of 3.0
Validation loss decreased (0.975208 --> 0.972056).  Saving model ...
EarlyStopping counter: 1 out of 3.0
Validation loss decreased (0.972056 --> 0.970287).  Saving model ...
EarlyStopping counter: 1 out of 3.0
Validation loss decreased (0.970287 --> 0.968218).  Saving model ...
Validation loss decreased (0.968218 --> 0.966267).  Saving model ...
EarlyStopping counter: 1 out of 3.0
EarlyStopping counter: 2 out of 3.0
EarlyStopping counter: 3 out of 3.0
/localscratch/yinan.29785233.0/env/lib/python3.7/site-packages/torch/nn/functional.py:1794: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.
  warnings.warn("nn.functional.tanh is deprecated. Use torch.tanh instead.")
wandb: Waiting for W&B process to finish, PID 68363... (success).
wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: \ 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: | 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: / 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: \ 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: | 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: / 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: \ 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: | 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: / 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: \ 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb:                                                                                
wandb: Run history:
wandb:     e_F1 ▁▁▂▄▄▅▆▆▆▆▆▆▆▆▇▇▇▇▇▇▇▇▇▇███▇▇▇██████████
wandb:   e_loss █▇▇▆▆▆▆▆▅▅▅▄▄▄▄▃▃▃▃▃▃▂▂▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁
wandb:     t_F1 ▁▂▂▃▃▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▆▆▆▇▇▇▇▇▇▇▇▇▇█▇▇████
wandb:   t_loss ██▇▇▇▆▆▆▆▆▅▅▅▅▅▄▄▄▄▄▃▃▃▃▃▃▃▂▂▂▂▂▂▁▂▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:     e_F1 60.20042
wandb:   e_loss 0.96903
wandb:     t_F1 67.6562
wandb:   t_loss 0.84201
wandb: 
wandb: Synced 4 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Synced dashing-resonance-1: https://wandb.ai/yinanazhou/xl_512_bs_8_lr_1e06_es_3_lc_True_nr_True_sr_False_stem_True_lemma_False_repeat_5_fold_2/runs/2d7aa87m
wandb: Find logs at: ./wandb/run-20220331_172025-2d7aa87m/logs/debug.log
wandb: 

