Unloading StdEnv/2020

Due to MODULEPATH changes, the following have been reloaded:
  1) mii/1.1.1


The following have been reloaded with a version change:
  1) python/3.8.2 => python/3.7.4

Using base prefix '/cvmfs/soft.computecanada.ca/easybuild/software/2017/Core/python/3.7.4'
New python executable in /localscratch/yinan.29019353.0/env/bin/python
Installing setuptools, pip, wheel...
done.
Ignoring pip: markers 'python_version < "3"' don't match your environment
Looking in links: /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/nix/avx2, /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/nix/generic, /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic
Collecting pip
Installing collected packages: pip
  Found existing installation: pip 19.1.1
    Uninstalling pip-19.1.1:
      Successfully uninstalled pip-19.1.1
Successfully installed pip-21.2.3+computecanada
Looking in links: /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/nix/avx2, /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/nix/generic, /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/keras-2.8.0+computecanada-py2.py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/Keras_Preprocessing-1.1.2+computecanada-py3-none-any.whl
Requirement already satisfied: matplotlib in /cvmfs/soft.computecanada.ca/easybuild/software/2017/Core/scipy-stack/2019a/lib/python3.7/site-packages (from -r requirements.txt (line 3)) (3.0.2)
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/nltk-3.6.5+computecanada-py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/scikit_learn-0.22.1+computecanada-cp37-cp37m-linux_x86_64.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/tensorboard-2.3.0+computecanada-py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/tensorboard_plugin_wit-1.7.0+computecanada-py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/tensorflow_gpu-2.3.0+computecanada-cp37-cp37m-linux_x86_64.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/tensorflow_estimator-2.3.0+computecanada-py2.py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/tokenizers-0.5.2+computecanada-cp37-cp37m-linux_x86_64.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/nix/avx2/torch-1.4.0+computecanada-cp37-cp37m-linux_x86_64.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/torchtext-0.6.0+computecanada-py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/torchvision-0.8.2+computecanada-cp37-cp37m-linux_x86_64.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/transformers-2.5.1+computecanada-py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/urllib3-1.26.7+computecanada-py2.py3-none-any.whl
ERROR: Could not find a version that satisfies the requirement regex>=2021.8.3 (from nltk) (from versions: 2018.1.10+computecanada, 2019.11.1+computecanada, 2020.11.13+computecanada)
ERROR: No matching distribution found for regex>=2021.8.3
Looking in links: /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/nix/avx2, /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/nix/generic, /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic
ERROR: Could not find a version that satisfies the requirement numpy==1.20.0+computacanada (from versions: 1.15.0+computecanada, 1.15.2+computecanada, 1.15.4+computecanada, 1.16.0+computecanada, 1.16.2+computecanada, 1.16.3+computecanada, 1.17.4+computecanada, 1.18.1+computecanada, 1.18.4+computecanada, 1.19.1+computecanada, 1.19.2+computecanada, 1.20.2+computecanada)
ERROR: No matching distribution found for numpy==1.20.0+computacanada
Looking in links: /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/nix/avx2, /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/nix/generic, /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/wandb-0.12.5+computecanada-py2.py3-none-any.whl
Requirement already satisfied: requests<3,>=2.0.0 in /cvmfs/soft.computecanada.ca/easybuild/software/2017/Core/scipy-stack/2019a/lib/python3.7/site-packages (from wandb) (2.21.0)
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/psutil-5.7.3+computecanada-cp37-cp37m-linux_x86_64.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/yaspin-2.1.0+computecanada-py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/sentry_sdk-1.5.0+computecanada-py2.py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/docker_pycreds-0.4.0+computecanada-py2.py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/configparser-5.0.2+computecanada-py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/protobuf-3.19.4+computecanada-py2.py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/click-8.0.4+computecanada-py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/promise-2.3+computecanada-py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/subprocess32-3.5.4+computecanada-py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/pathtools-0.1.2+computecanada-py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/PyYAML-5.3.1+computecanada-cp37-cp37m-linux_x86_64.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/GitPython-3.1.24+computecanada-py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/shortuuid-1.0.1+computecanada-py3-none-any.whl
Requirement already satisfied: python-dateutil>=2.6.1 in /cvmfs/soft.computecanada.ca/easybuild/software/2017/Core/scipy-stack/2019a/lib/python3.7/site-packages (from wandb) (2.7.5)
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/six-1.16.0+computecanada-py2.py3-none-any.whl
Requirement already satisfied: importlib-metadata in /cvmfs/soft.computecanada.ca/easybuild/software/2017/Core/scipy-stack/2019a/lib/python3.7/site-packages (from Click!=8.0.0,>=7.0->wandb) (0.8)
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/typing_extensions-4.0.1+computecanada-py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/gitdb-4.0.9+computecanada-py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/smmap-5.0.0+computecanada-py3-none-any.whl
Requirement already satisfied: urllib3<1.25,>=1.21.1 in /cvmfs/soft.computecanada.ca/easybuild/software/2017/Core/scipy-stack/2019a/lib/python3.7/site-packages (from requests<3,>=2.0.0->wandb) (1.24.1)
Requirement already satisfied: idna<2.9,>=2.5 in /cvmfs/soft.computecanada.ca/easybuild/software/2017/Core/scipy-stack/2019a/lib/python3.7/site-packages (from requests<3,>=2.0.0->wandb) (2.8)
Requirement already satisfied: certifi>=2017.4.17 in /cvmfs/soft.computecanada.ca/easybuild/software/2017/Core/scipy-stack/2019a/lib/python3.7/site-packages (from requests<3,>=2.0.0->wandb) (2018.11.29)
Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /cvmfs/soft.computecanada.ca/easybuild/software/2017/Core/scipy-stack/2019a/lib/python3.7/site-packages (from requests<3,>=2.0.0->wandb) (3.0.4)
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/termcolor-1.1.0+computecanada-py3-none-any.whl
Requirement already satisfied: zipp>=0.3.2 in /cvmfs/soft.computecanada.ca/easybuild/software/2017/Core/scipy-stack/2019a/lib/python3.7/site-packages (from importlib-metadata->Click!=8.0.0,>=7.0->wandb) (0.3.3)
Installing collected packages: smmap, typing-extensions, termcolor, six, gitdb, yaspin, subprocess32, shortuuid, sentry-sdk, PyYAML, psutil, protobuf, promise, pathtools, GitPython, docker-pycreds, configparser, Click, wandb
  Attempting uninstall: six
    Found existing installation: six 1.12.0
    Not uninstalling six at /cvmfs/soft.computecanada.ca/easybuild/software/2017/Core/scipy-stack/2019a/lib/python3.7/site-packages, outside environment /localscratch/yinan.29019353.0/env
    Can't uninstall 'six'. No files were found to uninstall.
Successfully installed Click-8.0.4+computecanada GitPython-3.1.24+computecanada PyYAML-5.3.1+computecanada configparser-5.0.2+computecanada docker-pycreds-0.4.0+computecanada gitdb-4.0.9+computecanada pathtools-0.1.2+computecanada promise-2.3+computecanada protobuf-3.19.4+computecanada psutil-5.7.3+computecanada sentry-sdk-1.5.0+computecanada shortuuid-1.0.1+computecanada six-1.16.0+computecanada smmap-5.0.0+computecanada subprocess32-3.5.4+computecanada termcolor-1.1.0+computecanada typing-extensions-4.0.1+computecanada wandb-0.12.5+computecanada yaspin-2.1.0+computecanada
Looking in links: /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/nix/avx2, /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/nix/generic, /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic
ERROR: Could not find a version that satisfies the requirement sagemaker (from versions: none)
ERROR: No matching distribution found for sagemaker
Looking in links: /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/nix/avx2, /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/nix/generic, /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/torch-1.9.1+computecanada-cp37-cp37m-linux_x86_64.whl
Requirement already satisfied: typing-extensions in /localscratch/yinan.29019353.0/env/lib/python3.7/site-packages (from torch) (4.0.1+computecanada)
Installing collected packages: torch
Successfully installed torch-1.9.1+computecanada
Looking in links: /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/nix/avx2, /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/nix/generic, /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/transformers-2.5.1+computecanada-py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/sacremoses-0.0.46+computecanada-py3-none-any.whl
Requirement already satisfied: requests in /cvmfs/soft.computecanada.ca/easybuild/software/2017/Core/scipy-stack/2019a/lib/python3.7/site-packages (from transformers==2.5.1+computecanada) (2.21.0)
Requirement already satisfied: numpy in /cvmfs/soft.computecanada.ca/easybuild/software/2017/Core/scipy-stack/2019a/lib/python3.7/site-packages (from transformers==2.5.1+computecanada) (1.16.0)
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/filelock-3.4.2+computecanada-py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/sentencepiece-0.1.91+computecanada-cp37-cp37m-linux_x86_64.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/tqdm-4.63.0+computecanada-py2.py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/tokenizers-0.5.2+computecanada-cp37-cp37m-linux_x86_64.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/boto3-1.21.14+computecanada-py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/regex-2020.11.13+computecanada-cp37-cp37m-linux_x86_64.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/jmespath-0.10.0+computecanada-py2.py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/s3transfer-0.5.1+computecanada-py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/botocore-1.24.14+computecanada-py3-none-any.whl
Requirement already satisfied: python-dateutil<3.0.0,>=2.1 in /cvmfs/soft.computecanada.ca/easybuild/software/2017/Core/scipy-stack/2019a/lib/python3.7/site-packages (from botocore<1.25.0,>=1.24.14->boto3->transformers==2.5.1+computecanada) (2.7.5)
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/urllib3-1.26.8+computecanada-py2.py3-none-any.whl
Requirement already satisfied: six>=1.5 in /localscratch/yinan.29019353.0/env/lib/python3.7/site-packages (from python-dateutil<3.0.0,>=2.1->botocore<1.25.0,>=1.24.14->boto3->transformers==2.5.1+computecanada) (1.16.0+computecanada)
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/requests-2.27.1+computecanada-py2.py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/charset_normalizer-2.0.12+computecanada-py3-none-any.whl
Requirement already satisfied: idna<4,>=2.5 in /cvmfs/soft.computecanada.ca/easybuild/software/2017/Core/scipy-stack/2019a/lib/python3.7/site-packages (from requests->transformers==2.5.1+computecanada) (2.8)
Requirement already satisfied: certifi>=2017.4.17 in /cvmfs/soft.computecanada.ca/easybuild/software/2017/Core/scipy-stack/2019a/lib/python3.7/site-packages (from requests->transformers==2.5.1+computecanada) (2018.11.29)
Requirement already satisfied: click in /localscratch/yinan.29019353.0/env/lib/python3.7/site-packages (from sacremoses->transformers==2.5.1+computecanada) (8.0.4+computecanada)
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/joblib-1.1.0+computecanada-py2.py3-none-any.whl
Requirement already satisfied: importlib-metadata in /cvmfs/soft.computecanada.ca/easybuild/software/2017/Core/scipy-stack/2019a/lib/python3.7/site-packages (from click->sacremoses->transformers==2.5.1+computecanada) (0.8)
Requirement already satisfied: zipp>=0.3.2 in /cvmfs/soft.computecanada.ca/easybuild/software/2017/Core/scipy-stack/2019a/lib/python3.7/site-packages (from importlib-metadata->click->sacremoses->transformers==2.5.1+computecanada) (0.3.3)
Installing collected packages: urllib3, jmespath, botocore, tqdm, s3transfer, regex, joblib, charset-normalizer, tokenizers, sentencepiece, sacremoses, requests, filelock, boto3, transformers
  Attempting uninstall: urllib3
    Found existing installation: urllib3 1.24.1
    Not uninstalling urllib3 at /cvmfs/soft.computecanada.ca/easybuild/software/2017/Core/scipy-stack/2019a/lib/python3.7/site-packages, outside environment /localscratch/yinan.29019353.0/env
    Can't uninstall 'urllib3'. No files were found to uninstall.
  Attempting uninstall: requests
    Found existing installation: requests 2.21.0
    Not uninstalling requests at /cvmfs/soft.computecanada.ca/easybuild/software/2017/Core/scipy-stack/2019a/lib/python3.7/site-packages, outside environment /localscratch/yinan.29019353.0/env
    Can't uninstall 'requests'. No files were found to uninstall.
Successfully installed boto3-1.21.14+computecanada botocore-1.24.14+computecanada charset-normalizer-2.0.12+computecanada filelock-3.4.2+computecanada jmespath-0.10.0+computecanada joblib-1.1.0+computecanada regex-2020.11.13+computecanada requests-2.27.1+computecanada s3transfer-0.5.1+computecanada sacremoses-0.0.46+computecanada sentencepiece-0.1.91+computecanada tokenizers-0.5.2+computecanada tqdm-4.63.0+computecanada transformers-2.5.1+computecanada urllib3-1.26.8+computecanada
Looking in links: /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/nix/avx2, /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/nix/generic, /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/tensorflow_gpu-2.3.0+computecanada-cp37-cp37m-linux_x86_64.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/Keras_Preprocessing-1.1.2+computecanada-py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/grpcio-1.38.0+computecanada-cp37-cp37m-linux_x86_64.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/absl_py-1.0.0+computecanada-py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/tensorflow_estimator-2.3.0+computecanada-py2.py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/opt_einsum-3.3.0+computecanada-py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/nix/avx2/h5py-2.10.0+computecanada-cp37-cp37m-linux_x86_64.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/gast-0.3.3+computecanada-py3-none-any.whl
Requirement already satisfied: numpy<1.19.0,>=1.16.0 in /cvmfs/soft.computecanada.ca/easybuild/software/2017/Core/scipy-stack/2019a/lib/python3.7/site-packages (from tensorflow_gpu==2.3.0+computecanada) (1.16.0)
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/wrapt-1.11.2+computecanada-cp37-cp37m-linux_x86_64.whl
Requirement already satisfied: protobuf>=3.9.2 in /localscratch/yinan.29019353.0/env/lib/python3.7/site-packages (from tensorflow_gpu==2.3.0+computecanada) (3.19.4+computecanada)
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/tensorboard-2.8.0+computecanada-py3-none-any.whl
Requirement already satisfied: termcolor>=1.1.0 in /localscratch/yinan.29019353.0/env/lib/python3.7/site-packages (from tensorflow_gpu==2.3.0+computecanada) (1.1.0+computecanada)
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/google_pasta-0.2.0+computecanada-py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/astunparse-1.6.3+computecanada-py2.py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/nix/generic/scipy-1.4.1+computecanada-cp37-cp37m-linux_x86_64.whl
Requirement already satisfied: wheel>=0.26 in /localscratch/yinan.29019353.0/env/lib/python3.7/site-packages (from tensorflow_gpu==2.3.0+computecanada) (0.33.4)
Requirement already satisfied: six>=1.12.0 in /localscratch/yinan.29019353.0/env/lib/python3.7/site-packages (from tensorflow_gpu==2.3.0+computecanada) (1.16.0+computecanada)
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/google_auth-2.3.3+computecanada-py2.py3-none-any.whl
Requirement already satisfied: setuptools>=41.0.0 in /localscratch/yinan.29019353.0/env/lib/python3.7/site-packages (from tensorboard<3,>=2.3.0->tensorflow_gpu==2.3.0+computecanada) (41.0.1)
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/google_auth_oauthlib-0.4.6+computecanada-py2.py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/Markdown-3.3.6+computecanada-py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/tensorboard_data_server-0.6.1+computecanada-py3-none-linux_x86_64.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/tensorboard_plugin_wit-1.8.0+computecanada-py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/Werkzeug-2.0.3+computecanada-py3-none-any.whl
Requirement already satisfied: requests<3,>=2.21.0 in /localscratch/yinan.29019353.0/env/lib/python3.7/site-packages (from tensorboard<3,>=2.3.0->tensorflow_gpu==2.3.0+computecanada) (2.27.1+computecanada)
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/rsa-4.8+computecanada-py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/cachetools-4.2.4+computecanada-py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/pyasn1_modules-0.2.8+computecanada-py2.py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/requests_oauthlib-1.3.0+computecanada-py2.py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/importlib_metadata-4.10.1+computecanada-py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/zipp-3.7.0+computecanada-py3-none-any.whl
Requirement already satisfied: typing-extensions>=3.6.4 in /localscratch/yinan.29019353.0/env/lib/python3.7/site-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard<3,>=2.3.0->tensorflow_gpu==2.3.0+computecanada) (4.0.1+computecanada)
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/pyasn1-0.4.8+computecanada-py2.py3-none-any.whl
Requirement already satisfied: urllib3<1.27,>=1.21.1 in /localscratch/yinan.29019353.0/env/lib/python3.7/site-packages (from requests<3,>=2.21.0->tensorboard<3,>=2.3.0->tensorflow_gpu==2.3.0+computecanada) (1.26.8+computecanada)
Requirement already satisfied: certifi>=2017.4.17 in /cvmfs/soft.computecanada.ca/easybuild/software/2017/Core/scipy-stack/2019a/lib/python3.7/site-packages (from requests<3,>=2.21.0->tensorboard<3,>=2.3.0->tensorflow_gpu==2.3.0+computecanada) (2018.11.29)
Requirement already satisfied: charset-normalizer~=2.0.0 in /localscratch/yinan.29019353.0/env/lib/python3.7/site-packages (from requests<3,>=2.21.0->tensorboard<3,>=2.3.0->tensorflow_gpu==2.3.0+computecanada) (2.0.12+computecanada)
Requirement already satisfied: idna<4,>=2.5 in /cvmfs/soft.computecanada.ca/easybuild/software/2017/Core/scipy-stack/2019a/lib/python3.7/site-packages (from requests<3,>=2.21.0->tensorboard<3,>=2.3.0->tensorflow_gpu==2.3.0+computecanada) (2.8)
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/oauthlib-3.1.1+computecanada-py2.py3-none-any.whl
Installing collected packages: pyasn1, zipp, rsa, pyasn1-modules, oauthlib, cachetools, requests-oauthlib, importlib-metadata, google-auth, werkzeug, tensorboard-plugin-wit, tensorboard-data-server, markdown, grpcio, google-auth-oauthlib, absl-py, wrapt, tensorflow-estimator, tensorboard, scipy, opt-einsum, keras-preprocessing, h5py, google-pasta, gast, astunparse, tensorflow-gpu
  Attempting uninstall: pyasn1
    Found existing installation: pyasn1 0.4.3
    Not uninstalling pyasn1 at /cvmfs/soft.computecanada.ca/easybuild/software/2017/Core/scipy-stack/2019a/lib/python3.7/site-packages, outside environment /localscratch/yinan.29019353.0/env
    Can't uninstall 'pyasn1'. No files were found to uninstall.
  Attempting uninstall: zipp
    Found existing installation: zipp 0.3.3
    Not uninstalling zipp at /cvmfs/soft.computecanada.ca/easybuild/software/2017/Core/scipy-stack/2019a/lib/python3.7/site-packages, outside environment /localscratch/yinan.29019353.0/env
    Can't uninstall 'zipp'. No files were found to uninstall.
  Attempting uninstall: importlib-metadata
    Found existing installation: importlib-metadata 0.8
    Not uninstalling importlib-metadata at /cvmfs/soft.computecanada.ca/easybuild/software/2017/Core/scipy-stack/2019a/lib/python3.7/site-packages, outside environment /localscratch/yinan.29019353.0/env
    Can't uninstall 'importlib-metadata'. No files were found to uninstall.
  Attempting uninstall: scipy
    Found existing installation: scipy 1.2.0
    Not uninstalling scipy at /cvmfs/soft.computecanada.ca/easybuild/software/2017/Core/scipy-stack/2019a/lib/python3.7/site-packages, outside environment /localscratch/yinan.29019353.0/env
    Can't uninstall 'scipy'. No files were found to uninstall.
Successfully installed absl-py-1.0.0+computecanada astunparse-1.6.3+computecanada cachetools-4.2.4+computecanada gast-0.3.3+computecanada google-auth-2.3.3+computecanada google-auth-oauthlib-0.4.6+computecanada google-pasta-0.2.0+computecanada grpcio-1.38.0+computecanada h5py-2.10.0+computecanada importlib-metadata-4.10.1+computecanada keras-preprocessing-1.1.2+computecanada markdown-3.3.6+computecanada oauthlib-3.1.1+computecanada opt-einsum-3.3.0+computecanada pyasn1-0.4.8+computecanada pyasn1-modules-0.2.8+computecanada requests-oauthlib-1.3.0+computecanada rsa-4.8+computecanada scipy-1.4.1+computecanada tensorboard-2.8.0+computecanada tensorboard-data-server-0.6.1+computecanada tensorboard-plugin-wit-1.8.0+computecanada tensorflow-estimator-2.3.0+computecanada tensorflow-gpu-2.3.0+computecanada werkzeug-2.0.3+computecanada wrapt-1.11.2+computecanada zipp-3.7.0+computecanada
Looking in links: /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/nix/avx2, /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/nix/generic, /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/keras-2.8.0+computecanada-py2.py3-none-any.whl
Installing collected packages: Keras
Successfully installed Keras-2.8.0+computecanada
Looking in links: /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/nix/avx2, /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/nix/generic, /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/urllib3-1.26.7+computecanada-py2.py3-none-any.whl
Installing collected packages: urllib3
  Attempting uninstall: urllib3
    Found existing installation: urllib3 1.26.8+computecanada
    Uninstalling urllib3-1.26.8+computecanada:
      Successfully uninstalled urllib3-1.26.8+computecanada
Successfully installed urllib3-1.26.7+computecanada
Looking in links: /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/nix/avx2, /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/nix/generic, /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/nltk-3.7+computecanada-py3-none-any.whl
Requirement already satisfied: joblib in /localscratch/yinan.29019353.0/env/lib/python3.7/site-packages (from nltk) (1.1.0+computecanada)
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/nltk-3.6.5+computecanada-py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/nltk-3.6.3+computecanada-py3-none-any.whl
Requirement already satisfied: regex in /localscratch/yinan.29019353.0/env/lib/python3.7/site-packages (from nltk) (2020.11.13+computecanada)
Requirement already satisfied: tqdm in /localscratch/yinan.29019353.0/env/lib/python3.7/site-packages (from nltk) (4.63.0+computecanada)
Requirement already satisfied: click in /localscratch/yinan.29019353.0/env/lib/python3.7/site-packages (from nltk) (8.0.4+computecanada)
Requirement already satisfied: importlib-metadata in /localscratch/yinan.29019353.0/env/lib/python3.7/site-packages (from click->nltk) (4.10.1+computecanada)
Requirement already satisfied: typing-extensions>=3.6.4 in /localscratch/yinan.29019353.0/env/lib/python3.7/site-packages (from importlib-metadata->click->nltk) (4.0.1+computecanada)
Requirement already satisfied: zipp>=0.5 in /localscratch/yinan.29019353.0/env/lib/python3.7/site-packages (from importlib-metadata->click->nltk) (3.7.0+computecanada)
Installing collected packages: nltk
Successfully installed nltk-3.6.3+computecanada
Looking in links: /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/nix/avx2, /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/nix/generic, /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/scikit_learn-0.22.1+computecanada-cp37-cp37m-linux_x86_64.whl
Requirement already satisfied: joblib>=0.11 in /localscratch/yinan.29019353.0/env/lib/python3.7/site-packages (from scikit-learn==0.22.1) (1.1.0+computecanada)
Requirement already satisfied: scipy>=0.17.0 in /localscratch/yinan.29019353.0/env/lib/python3.7/site-packages (from scikit-learn==0.22.1) (1.4.1+computecanada)
Requirement already satisfied: numpy>=1.11.0 in /cvmfs/soft.computecanada.ca/easybuild/software/2017/Core/scipy-stack/2019a/lib/python3.7/site-packages (from scikit-learn==0.22.1) (1.16.0)
Installing collected packages: scikit-learn
Successfully installed scikit-learn-0.22.1+computecanada
Looking in links: /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/nix/avx2, /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/nix/generic, /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic
Requirement already satisfied: tokenizers==0.5.2 in /localscratch/yinan.29019353.0/env/lib/python3.7/site-packages (0.5.2+computecanada)
wandb: Appending key for api.wandb.ai to your netrc file: /home/yinan/.netrc
Starting Task
2022-03-18 19:38:13.511207: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1
[nltk_data] Downloading package stopwords to /home/yinan/nltk_data...
[nltk_data]   Package stopwords is already up-to-date!
[nltk_data] Downloading package wordnet to /home/yinan/nltk_data...
[nltk_data]   Package wordnet is already up-to-date!
wandb: Currently logged in as: yinanazhou (use `wandb login --relogin` to force relogin)
wandb: wandb version 0.12.11 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
2022-03-18 19:38:31.183325: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1
wandb: Tracking run with wandb version 0.12.5
wandb: Syncing run clear-serenity-2
wandb: ⭐️ View project at https://wandb.ai/yinanazhou/xl_512_bs_8_lr_1e06_es_10_lc_False_nr_True_sr_False_stem_True_lemma_False_repeat_1_fold_1
wandb: 🚀 View run at https://wandb.ai/yinanazhou/xl_512_bs_8_lr_1e06_es_10_lc_False_nr_True_sr_False_stem_True_lemma_False_repeat_1_fold_1/runs/3l2h4s4n
wandb: Run data is saved locally in /project/6002780/yinan/Thesis_MER_Lyrics/lyric-emotion/wandb/run-20220318_193828-3l2h4s4n
wandb: Run `wandb offline` to turn off syncing.

Validation loss decreased (inf --> 1.429610).  Saving model ...
Validation loss decreased (1.429610 --> 1.410610).  Saving model ...
Validation loss decreased (1.410610 --> 1.394058).  Saving model ...
Validation loss decreased (1.394058 --> 1.380720).  Saving model ...
Validation loss decreased (1.380720 --> 1.370384).  Saving model ...
Validation loss decreased (1.370384 --> 1.362188).  Saving model ...
Validation loss decreased (1.362188 --> 1.355357).  Saving model ...
Validation loss decreased (1.355357 --> 1.349489).  Saving model ...
Validation loss decreased (1.349489 --> 1.344061).  Saving model ...
Validation loss decreased (1.344061 --> 1.337906).  Saving model ...
Validation loss decreased (1.337906 --> 1.332308).  Saving model ...
Validation loss decreased (1.332308 --> 1.327101).  Saving model ...
Validation loss decreased (1.327101 --> 1.321444).  Saving model ...
Validation loss decreased (1.321444 --> 1.315772).  Saving model ...
Validation loss decreased (1.315772 --> 1.309046).  Saving model ...
Validation loss decreased (1.309046 --> 1.303488).  Saving model ...
Validation loss decreased (1.303488 --> 1.298232).  Saving model ...
Validation loss decreased (1.298232 --> 1.293404).  Saving model ...
Validation loss decreased (1.293404 --> 1.287221).  Saving model ...
Validation loss decreased (1.287221 --> 1.279560).  Saving model ...
Validation loss decreased (1.279560 --> 1.272830).  Saving model ...
Validation loss decreased (1.272830 --> 1.268484).  Saving model ...
Validation loss decreased (1.268484 --> 1.263801).  Saving model ...
Validation loss decreased (1.263801 --> 1.257566).  Saving model ...
Validation loss decreased (1.257566 --> 1.252531).  Saving model ...
Validation loss decreased (1.252531 --> 1.247467).  Saving model ...
Validation loss decreased (1.247467 --> 1.243241).  Saving model ...
Validation loss decreased (1.243241 --> 1.238626).  Saving model ...
Validation loss decreased (1.238626 --> 1.235311).  Saving model ...
Validation loss decreased (1.235311 --> 1.231885).  Saving model ...
Validation loss decreased (1.231885 --> 1.226629).  Saving model ...
Validation loss decreased (1.226629 --> 1.221752).  Saving model ...
Validation loss decreased (1.221752 --> 1.218405).  Saving model ...
Validation loss decreased (1.218405 --> 1.214105).  Saving model ...
Validation loss decreased (1.214105 --> 1.212170).  Saving model ...
Validation loss decreased (1.212170 --> 1.210059).  Saving model ...
Validation loss decreased (1.210059 --> 1.208710).  Saving model ...
Validation loss decreased (1.208710 --> 1.201573).  Saving model ...
Validation loss decreased (1.201573 --> 1.197366).  Saving model ...
Validation loss decreased (1.197366 --> 1.194696).  Saving model ...
Validation loss decreased (1.194696 --> 1.191445).  Saving model ...
Validation loss decreased (1.191445 --> 1.187498).  Saving model ...
Validation loss decreased (1.187498 --> 1.183596).  Saving model ...
Validation loss decreased (1.183596 --> 1.180420).  Saving model ...
Validation loss decreased (1.180420 --> 1.177196).  Saving model ...
Validation loss decreased (1.177196 --> 1.174113).  Saving model ...
Validation loss decreased (1.174113 --> 1.171812).  Saving model ...
Validation loss decreased (1.171812 --> 1.168172).  Saving model ...
Validation loss decreased (1.168172 --> 1.162328).  Saving model ...
Validation loss decreased (1.162328 --> 1.159442).  Saving model ...
Validation loss decreased (1.159442 --> 1.156276).  Saving model ...
Validation loss decreased (1.156276 --> 1.154955).  Saving model ...
Validation loss decreased (1.154955 --> 1.153054).  Saving model ...
Validation loss decreased (1.153054 --> 1.149631).  Saving model ...
Validation loss decreased (1.149631 --> 1.148099).  Saving model ...
Validation loss decreased (1.148099 --> 1.142688).  Saving model ...
Validation loss decreased (1.142688 --> 1.141948).  Saving model ...
Validation loss decreased (1.141948 --> 1.139787).  Saving model ...
Validation loss decreased (1.139787 --> 1.136243).  Saving model ...
Validation loss decreased (1.136243 --> 1.135520).  Saving model ...
Validation loss decreased (1.135520 --> 1.134357).  Saving model ...
Validation loss decreased (1.134357 --> 1.127855).  Saving model ...
Validation loss decreased (1.127855 --> 1.123666).  Saving model ...
Validation loss decreased (1.123666 --> 1.123431).  Saving model ...
Validation loss decreased (1.123431 --> 1.122418).  Saving model ...
Validation loss decreased (1.122418 --> 1.115770).  Saving model ...
Validation loss decreased (1.115770 --> 1.113271).  Saving model ...
Validation loss decreased (1.113271 --> 1.113140).  Saving model ...
Validation loss decreased (1.113140 --> 1.111595).  Saving model ...
Validation loss decreased (1.111595 --> 1.111172).  Saving model ...
Validation loss decreased (1.111172 --> 1.105888).  Saving model ...
Validation loss decreased (1.105888 --> 1.101486).  Saving model ...
EarlyStopping counter: 1 out of 10.0
Validation loss decreased (1.101486 --> 1.098090).  Saving model ...
Validation loss decreased (1.098090 --> 1.095944).  Saving model ...
EarlyStopping counter: 1 out of 10.0
Validation loss decreased (1.095944 --> 1.095060).  Saving model ...
Validation loss decreased (1.095060 --> 1.091015).  Saving model ...
Validation loss decreased (1.091015 --> 1.090735).  Saving model ...
Validation loss decreased (1.090735 --> 1.085999).  Saving model ...
EarlyStopping counter: 1 out of 10.0
EarlyStopping counter: 2 out of 10.0
EarlyStopping counter: 3 out of 10.0
EarlyStopping counter: 4 out of 10.0
Validation loss decreased (1.085999 --> 1.079641).  Saving model ...
Validation loss decreased (1.079641 --> 1.078208).  Saving model ...
EarlyStopping counter: 1 out of 10.0
EarlyStopping counter: 2 out of 10.0
EarlyStopping counter: 3 out of 10.0
EarlyStopping counter: 4 out of 10.0
Validation loss decreased (1.078208 --> 1.077796).  Saving model ...
Validation loss decreased (1.077796 --> 1.074955).  Saving model ...
EarlyStopping counter: 1 out of 10.0
EarlyStopping counter: 2 out of 10.0
EarlyStopping counter: 3 out of 10.0
Validation loss decreased (1.074955 --> 1.074259).  Saving model ...
EarlyStopping counter: 1 out of 10.0
Validation loss decreased (1.074259 --> 1.070508).  Saving model ...
EarlyStopping counter: 1 out of 10.0
EarlyStopping counter: 2 out of 10.0
EarlyStopping counter: 3 out of 10.0
EarlyStopping counter: 4 out of 10.0
Validation loss decreased (1.070508 --> 1.066958).  Saving model ...
EarlyStopping counter: 1 out of 10.0
EarlyStopping counter: 2 out of 10.0
Validation loss decreased (1.066958 --> 1.066907).  Saving model ...
Validation loss decreased (1.066907 --> 1.063555).  Saving model ...
EarlyStopping counter: 1 out of 10.0
Validation loss decreased (1.063555 --> 1.062262).  Saving model ...
Validation loss decreased (1.062262 --> 1.058367).  Saving model ...
EarlyStopping counter: 1 out of 10.0
EarlyStopping counter: 2 out of 10.0
EarlyStopping counter: 3 out of 10.0
EarlyStopping counter: 4 out of 10.0
EarlyStopping counter: 5 out of 10.0
EarlyStopping counter: 6 out of 10.0
EarlyStopping counter: 7 out of 10.0
EarlyStopping counter: 8 out of 10.0
EarlyStopping counter: 9 out of 10.0
EarlyStopping counter: 10 out of 10.0
/localscratch/yinan.29019353.0/env/lib/python3.7/site-packages/torch/nn/functional.py:1794: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.
  warnings.warn("nn.functional.tanh is deprecated. Use torch.tanh instead.")
/localscratch/yinan.29019353.0/env/lib/python3.7/site-packages/transformers/optimization.py:155: UserWarning: This overload of add_ is deprecated:
	add_(Number alpha, Tensor other)
Consider using one of the following signatures instead:
	add_(Tensor other, *, Number alpha) (Triggered internally at  ../torch/csrc/utils/python_arg_parser.cpp:1025.)
  exp_avg.mul_(beta1).add_(1.0 - beta1, grad)
wandb: Waiting for W&B process to finish, PID 39791... (success).
wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: \ 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: | 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: / 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb:                                                                                
wandb: Run history:
wandb:     e_F1 ▁▂▄▄▅▅▅▆▆▆▆▆▆▇▇▇▇▇▇▇▇▇▇██▇██████████████
wandb:   e_loss █▇▇▆▆▆▅▅▅▄▄▄▄▄▃▃▃▃▃▃▂▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁
wandb:     t_F1 ▁▁▃▂▃▃▄▄▄▅▅▅▅▅▆▆▆▆▆▆▆▇▆▇▇▇▇▇▇█▇███████▇█
wandb:   t_loss ██▇▇▇▇▆▆▆▆▅▅▅▅▄▄▄▄▄▄▃▃▃▃▃▃▃▂▂▂▂▁▂▂▂▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:     e_F1 55.83644
wandb:   e_loss 1.06148
wandb:     t_F1 69.01213
wandb:   t_loss 0.80001
wandb: 
wandb: Synced 4 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Synced clear-serenity-2: https://wandb.ai/yinanazhou/xl_512_bs_8_lr_1e06_es_10_lc_False_nr_True_sr_False_stem_True_lemma_False_repeat_1_fold_1/runs/3l2h4s4n
wandb: Find logs at: ./wandb/run-20220318_193828-3l2h4s4n/logs/debug.log
wandb: 

wandb: wandb version 0.12.11 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
2022-03-18 20:57:13.642430: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1
wandb: Tracking run with wandb version 0.12.5
wandb: Syncing run mild-sound-2
wandb: ⭐️ View project at https://wandb.ai/yinanazhou/xl_512_bs_8_lr_1e06_es_10_lc_False_nr_True_sr_False_stem_True_lemma_False_repeat_1_fold_2
wandb: 🚀 View run at https://wandb.ai/yinanazhou/xl_512_bs_8_lr_1e06_es_10_lc_False_nr_True_sr_False_stem_True_lemma_False_repeat_1_fold_2/runs/1wmhtm2i
wandb: Run data is saved locally in /project/6002780/yinan/Thesis_MER_Lyrics/lyric-emotion/wandb/run-20220318_205709-1wmhtm2i
wandb: Run `wandb offline` to turn off syncing.

Validation loss decreased (inf --> 1.502787).  Saving model ...
Validation loss decreased (1.502787 --> 1.472335).  Saving model ...
Validation loss decreased (1.472335 --> 1.447178).  Saving model ...
Validation loss decreased (1.447178 --> 1.426804).  Saving model ...
Validation loss decreased (1.426804 --> 1.410811).  Saving model ...
Validation loss decreased (1.410811 --> 1.398180).  Saving model ...
Validation loss decreased (1.398180 --> 1.388461).  Saving model ...
Validation loss decreased (1.388461 --> 1.380546).  Saving model ...
Validation loss decreased (1.380546 --> 1.373857).  Saving model ...
Validation loss decreased (1.373857 --> 1.368404).  Saving model ...
Validation loss decreased (1.368404 --> 1.363110).  Saving model ...
Validation loss decreased (1.363110 --> 1.358294).  Saving model ...
Validation loss decreased (1.358294 --> 1.353563).  Saving model ...
Validation loss decreased (1.353563 --> 1.348994).  Saving model ...
Validation loss decreased (1.348994 --> 1.344327).  Saving model ...
Validation loss decreased (1.344327 --> 1.339933).  Saving model ...
Validation loss decreased (1.339933 --> 1.335564).  Saving model ...
Validation loss decreased (1.335564 --> 1.330583).  Saving model ...
Validation loss decreased (1.330583 --> 1.325242).  Saving model ...
Validation loss decreased (1.325242 --> 1.320012).  Saving model ...
Validation loss decreased (1.320012 --> 1.314431).  Saving model ...
Validation loss decreased (1.314431 --> 1.308917).  Saving model ...
Validation loss decreased (1.308917 --> 1.303048).  Saving model ...
Validation loss decreased (1.303048 --> 1.296797).  Saving model ...
Validation loss decreased (1.296797 --> 1.291036).  Saving model ...
Validation loss decreased (1.291036 --> 1.284377).  Saving model ...
Validation loss decreased (1.284377 --> 1.277772).  Saving model ...
Validation loss decreased (1.277772 --> 1.270652).  Saving model ...
Validation loss decreased (1.270652 --> 1.263658).  Saving model ...
Validation loss decreased (1.263658 --> 1.256284).  Saving model ...
Validation loss decreased (1.256284 --> 1.249099).  Saving model ...
Validation loss decreased (1.249099 --> 1.241064).  Saving model ...
Validation loss decreased (1.241064 --> 1.233816).  Saving model ...
Validation loss decreased (1.233816 --> 1.227052).  Saving model ...
Validation loss decreased (1.227052 --> 1.219813).  Saving model ...
Validation loss decreased (1.219813 --> 1.212971).  Saving model ...
Validation loss decreased (1.212971 --> 1.206200).  Saving model ...
Validation loss decreased (1.206200 --> 1.198906).  Saving model ...
Validation loss decreased (1.198906 --> 1.191876).  Saving model ...
Validation loss decreased (1.191876 --> 1.184997).  Saving model ...
Validation loss decreased (1.184997 --> 1.178631).  Saving model ...
Validation loss decreased (1.178631 --> 1.171898).  Saving model ...
Validation loss decreased (1.171898 --> 1.165843).  Saving model ...
Validation loss decreased (1.165843 --> 1.159225).  Saving model ...
Validation loss decreased (1.159225 --> 1.153156).  Saving model ...
Validation loss decreased (1.153156 --> 1.146660).  Saving model ...
Validation loss decreased (1.146660 --> 1.140796).  Saving model ...
Validation loss decreased (1.140796 --> 1.134348).  Saving model ...
Validation loss decreased (1.134348 --> 1.128496).  Saving model ...
Validation loss decreased (1.128496 --> 1.123644).  Saving model ...
Validation loss decreased (1.123644 --> 1.118460).  Saving model ...
Validation loss decreased (1.118460 --> 1.112861).  Saving model ...
Validation loss decreased (1.112861 --> 1.106980).  Saving model ...
Validation loss decreased (1.106980 --> 1.102025).  Saving model ...
Validation loss decreased (1.102025 --> 1.096655).  Saving model ...
Validation loss decreased (1.096655 --> 1.090708).  Saving model ...
Validation loss decreased (1.090708 --> 1.085961).  Saving model ...
Validation loss decreased (1.085961 --> 1.081829).  Saving model ...
Validation loss decreased (1.081829 --> 1.075824).  Saving model ...
Validation loss decreased (1.075824 --> 1.071771).  Saving model ...
Validation loss decreased (1.071771 --> 1.067642).  Saving model ...
Validation loss decreased (1.067642 --> 1.064094).  Saving model ...
Validation loss decreased (1.064094 --> 1.059607).  Saving model ...
Validation loss decreased (1.059607 --> 1.055512).  Saving model ...
Validation loss decreased (1.055512 --> 1.051111).  Saving model ...
Validation loss decreased (1.051111 --> 1.048653).  Saving model ...
Validation loss decreased (1.048653 --> 1.046809).  Saving model ...
Validation loss decreased (1.046809 --> 1.043031).  Saving model ...
Validation loss decreased (1.043031 --> 1.039942).  Saving model ...
Validation loss decreased (1.039942 --> 1.034823).  Saving model ...
Validation loss decreased (1.034823 --> 1.032481).  Saving model ...
Validation loss decreased (1.032481 --> 1.029276).  Saving model ...
Validation loss decreased (1.029276 --> 1.025836).  Saving model ...
Validation loss decreased (1.025836 --> 1.022918).  Saving model ...
Validation loss decreased (1.022918 --> 1.020816).  Saving model ...
Validation loss decreased (1.020816 --> 1.017948).  Saving model ...
Validation loss decreased (1.017948 --> 1.015330).  Saving model ...
Validation loss decreased (1.015330 --> 1.012565).  Saving model ...
Validation loss decreased (1.012565 --> 1.009310).  Saving model ...
Validation loss decreased (1.009310 --> 1.008309).  Saving model ...
Validation loss decreased (1.008309 --> 1.004940).  Saving model ...
Validation loss decreased (1.004940 --> 1.002331).  Saving model ...
Validation loss decreased (1.002331 --> 1.000015).  Saving model ...
Validation loss decreased (1.000015 --> 0.997081).  Saving model ...
Validation loss decreased (0.997081 --> 0.994366).  Saving model ...
Validation loss decreased (0.994366 --> 0.992042).  Saving model ...
Validation loss decreased (0.992042 --> 0.989786).  Saving model ...
Validation loss decreased (0.989786 --> 0.987329).  Saving model ...
Validation loss decreased (0.987329 --> 0.984160).  Saving model ...
Validation loss decreased (0.984160 --> 0.981407).  Saving model ...
Validation loss decreased (0.981407 --> 0.980493).  Saving model ...
Validation loss decreased (0.980493 --> 0.978830).  Saving model ...
Validation loss decreased (0.978830 --> 0.978470).  Saving model ...
Validation loss decreased (0.978470 --> 0.977188).  Saving model ...
Validation loss decreased (0.977188 --> 0.975793).  Saving model ...
Validation loss decreased (0.975793 --> 0.973260).  Saving model ...
Validation loss decreased (0.973260 --> 0.971379).  Saving model ...
Validation loss decreased (0.971379 --> 0.969198).  Saving model ...
Validation loss decreased (0.969198 --> 0.967597).  Saving model ...
EarlyStopping counter: 1 out of 10.0
EarlyStopping counter: 2 out of 10.0
Validation loss decreased (0.967597 --> 0.966941).  Saving model ...
Validation loss decreased (0.966941 --> 0.965360).  Saving model ...
Validation loss decreased (0.965360 --> 0.962727).  Saving model ...
EarlyStopping counter: 1 out of 10.0
Validation loss decreased (0.962727 --> 0.961528).  Saving model ...
Validation loss decreased (0.961528 --> 0.959836).  Saving model ...
Validation loss decreased (0.959836 --> 0.958517).  Saving model ...
Validation loss decreased (0.958517 --> 0.957234).  Saving model ...
Validation loss decreased (0.957234 --> 0.956834).  Saving model ...
Validation loss decreased (0.956834 --> 0.956198).  Saving model ...
Validation loss decreased (0.956198 --> 0.954435).  Saving model ...
Validation loss decreased (0.954435 --> 0.953860).  Saving model ...
Validation loss decreased (0.953860 --> 0.953494).  Saving model ...
EarlyStopping counter: 1 out of 10.0
Validation loss decreased (0.953494 --> 0.952718).  Saving model ...
Validation loss decreased (0.952718 --> 0.952409).  Saving model ...
EarlyStopping counter: 1 out of 10.0
Validation loss decreased (0.952409 --> 0.951062).  Saving model ...
Validation loss decreased (0.951062 --> 0.950178).  Saving model ...
Validation loss decreased (0.950178 --> 0.949699).  Saving model ...
Validation loss decreased (0.949699 --> 0.949144).  Saving model ...
Validation loss decreased (0.949144 --> 0.947916).  Saving model ...
Validation loss decreased (0.947916 --> 0.947771).  Saving model ...
Validation loss decreased (0.947771 --> 0.947343).  Saving model ...
EarlyStopping counter: 1 out of 10.0
EarlyStopping counter: 2 out of 10.0
Validation loss decreased (0.947343 --> 0.947164).  Saving model ...
EarlyStopping counter: 1 out of 10.0
Validation loss decreased (0.947164 --> 0.946735).  Saving model ...
Validation loss decreased (0.946735 --> 0.946099).  Saving model ...
EarlyStopping counter: 1 out of 10.0
Validation loss decreased (0.946099 --> 0.945910).  Saving model ...
Validation loss decreased (0.945910 --> 0.945397).  Saving model ...
EarlyStopping counter: 1 out of 10.0
Validation loss decreased (0.945397 --> 0.945003).  Saving model ...
Validation loss decreased (0.945003 --> 0.944725).  Saving model ...
EarlyStopping counter: 1 out of 10.0
EarlyStopping counter: 2 out of 10.0
EarlyStopping counter: 3 out of 10.0
EarlyStopping counter: 4 out of 10.0
Validation loss decreased (0.944725 --> 0.944417).  Saving model ...
EarlyStopping counter: 1 out of 10.0
EarlyStopping counter: 2 out of 10.0
EarlyStopping counter: 3 out of 10.0
EarlyStopping counter: 4 out of 10.0
EarlyStopping counter: 5 out of 10.0
EarlyStopping counter: 6 out of 10.0
EarlyStopping counter: 7 out of 10.0
EarlyStopping counter: 8 out of 10.0
EarlyStopping counter: 9 out of 10.0
EarlyStopping counter: 10 out of 10.0
/localscratch/yinan.29019353.0/env/lib/python3.7/site-packages/torch/nn/functional.py:1794: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.
  warnings.warn("nn.functional.tanh is deprecated. Use torch.tanh instead.")
wandb: Waiting for W&B process to finish, PID 44045... (success).
wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: \ 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: | 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: / 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: \ 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: | 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: / 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: \ 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: | 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: / 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb:                                                                                
wandb: Run history:
wandb:     e_F1 ▁▁▂▃▄▄▅▅▆▆▆▇▇▇▇▇▇▇▇▇▇▇██▇███████████████
wandb:   e_loss █▇▇▆▆▆▆▅▅▅▄▄▄▃▃▃▃▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:     t_F1 ▁▁▁▂▃▃▃▄▄▅▅▅▅▆▅▆▅▆▆▆▇▆▆▇▇▇▇▇▇▇███▇██████
wandb:   t_loss ██▇▇▇▇▇▆▆▆▅▅▅▅▅▄▄▄▄▄▃▃▃▃▃▃▃▃▂▂▂▂▂▂▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:     e_F1 57.71421
wandb:   e_loss 0.94688
wandb:     t_F1 71.3368
wandb:   t_loss 0.74946
wandb: 
wandb: Synced 4 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Synced mild-sound-2: https://wandb.ai/yinanazhou/xl_512_bs_8_lr_1e06_es_10_lc_False_nr_True_sr_False_stem_True_lemma_False_repeat_1_fold_2/runs/1wmhtm2i
wandb: Find logs at: ./wandb/run-20220318_205709-1wmhtm2i/logs/debug.log
wandb: 

wandb: wandb version 0.12.11 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
2022-03-18 22:34:57.480255: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1
wandb: Tracking run with wandb version 0.12.5
wandb: Syncing run logical-energy-2
wandb: ⭐️ View project at https://wandb.ai/yinanazhou/xl_512_bs_8_lr_1e06_es_10_lc_False_nr_True_sr_False_stem_True_lemma_False_repeat_2_fold_1
wandb: 🚀 View run at https://wandb.ai/yinanazhou/xl_512_bs_8_lr_1e06_es_10_lc_False_nr_True_sr_False_stem_True_lemma_False_repeat_2_fold_1/runs/39888sri
wandb: Run data is saved locally in /project/6002780/yinan/Thesis_MER_Lyrics/lyric-emotion/wandb/run-20220318_223454-39888sri
wandb: Run `wandb offline` to turn off syncing.

Validation loss decreased (inf --> 1.462687).  Saving model ...
Validation loss decreased (1.462687 --> 1.434517).  Saving model ...
Validation loss decreased (1.434517 --> 1.413992).  Saving model ...
Validation loss decreased (1.413992 --> 1.398249).  Saving model ...
Validation loss decreased (1.398249 --> 1.386289).  Saving model ...
Validation loss decreased (1.386289 --> 1.376388).  Saving model ...
Validation loss decreased (1.376388 --> 1.368623).  Saving model ...
Validation loss decreased (1.368623 --> 1.363327).  Saving model ...
Validation loss decreased (1.363327 --> 1.358626).  Saving model ...
Validation loss decreased (1.358626 --> 1.353193).  Saving model ...
Validation loss decreased (1.353193 --> 1.348625).  Saving model ...
Validation loss decreased (1.348625 --> 1.344334).  Saving model ...
Validation loss decreased (1.344334 --> 1.340072).  Saving model ...
Validation loss decreased (1.340072 --> 1.335940).  Saving model ...
Validation loss decreased (1.335940 --> 1.331198).  Saving model ...
Validation loss decreased (1.331198 --> 1.326594).  Saving model ...
Validation loss decreased (1.326594 --> 1.322572).  Saving model ...
Validation loss decreased (1.322572 --> 1.318209).  Saving model ...
Validation loss decreased (1.318209 --> 1.313519).  Saving model ...
Validation loss decreased (1.313519 --> 1.309258).  Saving model ...
Validation loss decreased (1.309258 --> 1.305130).  Saving model ...
Validation loss decreased (1.305130 --> 1.300368).  Saving model ...
Validation loss decreased (1.300368 --> 1.294491).  Saving model ...
Validation loss decreased (1.294491 --> 1.288457).  Saving model ...
Validation loss decreased (1.288457 --> 1.281909).  Saving model ...
Validation loss decreased (1.281909 --> 1.275761).  Saving model ...
Validation loss decreased (1.275761 --> 1.268875).  Saving model ...
Validation loss decreased (1.268875 --> 1.263178).  Saving model ...
Validation loss decreased (1.263178 --> 1.255281).  Saving model ...
Validation loss decreased (1.255281 --> 1.248020).  Saving model ...
Validation loss decreased (1.248020 --> 1.238883).  Saving model ...
Validation loss decreased (1.238883 --> 1.232479).  Saving model ...
Validation loss decreased (1.232479 --> 1.224884).  Saving model ...
Validation loss decreased (1.224884 --> 1.217147).  Saving model ...
Validation loss decreased (1.217147 --> 1.211576).  Saving model ...
Validation loss decreased (1.211576 --> 1.203130).  Saving model ...
Validation loss decreased (1.203130 --> 1.194963).  Saving model ...
Validation loss decreased (1.194963 --> 1.188415).  Saving model ...
Validation loss decreased (1.188415 --> 1.182280).  Saving model ...
Validation loss decreased (1.182280 --> 1.177312).  Saving model ...
Validation loss decreased (1.177312 --> 1.171597).  Saving model ...
Validation loss decreased (1.171597 --> 1.166937).  Saving model ...
Validation loss decreased (1.166937 --> 1.161267).  Saving model ...
Validation loss decreased (1.161267 --> 1.155611).  Saving model ...
Validation loss decreased (1.155611 --> 1.152220).  Saving model ...
Validation loss decreased (1.152220 --> 1.148154).  Saving model ...
Validation loss decreased (1.148154 --> 1.143809).  Saving model ...
Validation loss decreased (1.143809 --> 1.138211).  Saving model ...
Validation loss decreased (1.138211 --> 1.132857).  Saving model ...
Validation loss decreased (1.132857 --> 1.128213).  Saving model ...
Validation loss decreased (1.128213 --> 1.122512).  Saving model ...
Validation loss decreased (1.122512 --> 1.120387).  Saving model ...
Validation loss decreased (1.120387 --> 1.116683).  Saving model ...
Validation loss decreased (1.116683 --> 1.113434).  Saving model ...
Validation loss decreased (1.113434 --> 1.110478).  Saving model ...
Validation loss decreased (1.110478 --> 1.107875).  Saving model ...
Validation loss decreased (1.107875 --> 1.102945).  Saving model ...
Validation loss decreased (1.102945 --> 1.098627).  Saving model ...
Validation loss decreased (1.098627 --> 1.094087).  Saving model ...
Validation loss decreased (1.094087 --> 1.089783).  Saving model ...
Validation loss decreased (1.089783 --> 1.087428).  Saving model ...
Validation loss decreased (1.087428 --> 1.084640).  Saving model ...
EarlyStopping counter: 1 out of 10.0
Validation loss decreased (1.084640 --> 1.084237).  Saving model ...
Validation loss decreased (1.084237 --> 1.078458).  Saving model ...
Validation loss decreased (1.078458 --> 1.075886).  Saving model ...
Validation loss decreased (1.075886 --> 1.072689).  Saving model ...
Validation loss decreased (1.072689 --> 1.068266).  Saving model ...
Validation loss decreased (1.068266 --> 1.066401).  Saving model ...
Validation loss decreased (1.066401 --> 1.062861).  Saving model ...
Validation loss decreased (1.062861 --> 1.060943).  Saving model ...
Validation loss decreased (1.060943 --> 1.058092).  Saving model ...
Validation loss decreased (1.058092 --> 1.056037).  Saving model ...
Validation loss decreased (1.056037 --> 1.051524).  Saving model ...
Validation loss decreased (1.051524 --> 1.049373).  Saving model ...
Validation loss decreased (1.049373 --> 1.048331).  Saving model ...
Validation loss decreased (1.048331 --> 1.047153).  Saving model ...
Validation loss decreased (1.047153 --> 1.046296).  Saving model ...
Validation loss decreased (1.046296 --> 1.042432).  Saving model ...
Validation loss decreased (1.042432 --> 1.041497).  Saving model ...
Validation loss decreased (1.041497 --> 1.039218).  Saving model ...
Validation loss decreased (1.039218 --> 1.034948).  Saving model ...
Validation loss decreased (1.034948 --> 1.033830).  Saving model ...
Validation loss decreased (1.033830 --> 1.033178).  Saving model ...
Validation loss decreased (1.033178 --> 1.032657).  Saving model ...
Validation loss decreased (1.032657 --> 1.031738).  Saving model ...
EarlyStopping counter: 1 out of 10.0
Validation loss decreased (1.031738 --> 1.029494).  Saving model ...
Validation loss decreased (1.029494 --> 1.028248).  Saving model ...
Validation loss decreased (1.028248 --> 1.025699).  Saving model ...
Validation loss decreased (1.025699 --> 1.024652).  Saving model ...
EarlyStopping counter: 1 out of 10.0
EarlyStopping counter: 2 out of 10.0
Validation loss decreased (1.024652 --> 1.023986).  Saving model ...
Validation loss decreased (1.023986 --> 1.022078).  Saving model ...
Validation loss decreased (1.022078 --> 1.020227).  Saving model ...
Validation loss decreased (1.020227 --> 1.018614).  Saving model ...
EarlyStopping counter: 1 out of 10.0
EarlyStopping counter: 2 out of 10.0
EarlyStopping counter: 3 out of 10.0
Validation loss decreased (1.018614 --> 1.015976).  Saving model ...
Validation loss decreased (1.015976 --> 1.014766).  Saving model ...
Validation loss decreased (1.014766 --> 1.013133).  Saving model ...
EarlyStopping counter: 1 out of 10.0
Validation loss decreased (1.013133 --> 1.011748).  Saving model ...
EarlyStopping counter: 1 out of 10.0
EarlyStopping counter: 2 out of 10.0
Validation loss decreased (1.011748 --> 1.010337).  Saving model ...
EarlyStopping counter: 1 out of 10.0
Validation loss decreased (1.010337 --> 1.009413).  Saving model ...
EarlyStopping counter: 1 out of 10.0
Validation loss decreased (1.009413 --> 1.006528).  Saving model ...
EarlyStopping counter: 1 out of 10.0
Validation loss decreased (1.006528 --> 1.006175).  Saving model ...
EarlyStopping counter: 1 out of 10.0
EarlyStopping counter: 2 out of 10.0
EarlyStopping counter: 3 out of 10.0
Validation loss decreased (1.006175 --> 1.004766).  Saving model ...
EarlyStopping counter: 1 out of 10.0
EarlyStopping counter: 2 out of 10.0
EarlyStopping counter: 3 out of 10.0
EarlyStopping counter: 4 out of 10.0
EarlyStopping counter: 5 out of 10.0
EarlyStopping counter: 6 out of 10.0
EarlyStopping counter: 7 out of 10.0
EarlyStopping counter: 8 out of 10.0
EarlyStopping counter: 9 out of 10.0
EarlyStopping counter: 10 out of 10.0
/localscratch/yinan.29019353.0/env/lib/python3.7/site-packages/torch/nn/functional.py:1794: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.
  warnings.warn("nn.functional.tanh is deprecated. Use torch.tanh instead.")
wandb: Waiting for W&B process to finish, PID 49343... (success).
wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: \ 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: | 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: / 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb:                                                                                
wandb: Run history:
wandb:     e_F1 ▁▁▃▄▅▅▅▆▆▇▇▇▇▇▇▇▇▇██████████████████████
wandb:   e_loss █▇▇▇▆▆▆▆▅▅▄▄▄▃▃▃▃▃▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:     t_F1 ▁▁▂▃▃▃▃▄▅▄▄▅▅▅▆▆▆▆▆▆▆▇▆▇▇▇▇▇▇▇█▇█▇█▇█▇██
wandb:   t_loss ██▇▇▇▇▇▆▆▆▆▅▅▅▅▄▄▄▄▄▄▃▃▃▃▃▃▂▂▂▂▂▂▂▂▂▁▁▁▁
wandb: 
wandb: Run summary:
wandb:     e_F1 55.27501
wandb:   e_loss 1.00738
wandb:     t_F1 71.3308
wandb:   t_loss 0.7701
wandb: 
wandb: Synced 4 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Synced logical-energy-2: https://wandb.ai/yinanazhou/xl_512_bs_8_lr_1e06_es_10_lc_False_nr_True_sr_False_stem_True_lemma_False_repeat_2_fold_1/runs/39888sri
wandb: Find logs at: ./wandb/run-20220318_223454-39888sri/logs/debug.log
wandb: 

wandb: wandb version 0.12.11 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
2022-03-18 23:59:00.650443: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1
wandb: Tracking run with wandb version 0.12.5
wandb: Syncing run wandering-plasma-2
wandb: ⭐️ View project at https://wandb.ai/yinanazhou/xl_512_bs_8_lr_1e06_es_10_lc_False_nr_True_sr_False_stem_True_lemma_False_repeat_2_fold_2
wandb: 🚀 View run at https://wandb.ai/yinanazhou/xl_512_bs_8_lr_1e06_es_10_lc_False_nr_True_sr_False_stem_True_lemma_False_repeat_2_fold_2/runs/3r3srfsy
wandb: Run data is saved locally in /project/6002780/yinan/Thesis_MER_Lyrics/lyric-emotion/wandb/run-20220318_235857-3r3srfsy
wandb: Run `wandb offline` to turn off syncing.

Validation loss decreased (inf --> 1.419832).  Saving model ...
Validation loss decreased (1.419832 --> 1.405825).  Saving model ...
Validation loss decreased (1.405825 --> 1.394282).  Saving model ...
Validation loss decreased (1.394282 --> 1.384858).  Saving model ...
Validation loss decreased (1.384858 --> 1.377009).  Saving model ...
Validation loss decreased (1.377009 --> 1.370844).  Saving model ...
Validation loss decreased (1.370844 --> 1.365539).  Saving model ...
Validation loss decreased (1.365539 --> 1.359948).  Saving model ...
Validation loss decreased (1.359948 --> 1.355261).  Saving model ...
Validation loss decreased (1.355261 --> 1.350713).  Saving model ...
Validation loss decreased (1.350713 --> 1.346500).  Saving model ...
Validation loss decreased (1.346500 --> 1.342017).  Saving model ...
Validation loss decreased (1.342017 --> 1.336794).  Saving model ...
Validation loss decreased (1.336794 --> 1.331539).  Saving model ...
Validation loss decreased (1.331539 --> 1.325721).  Saving model ...
Validation loss decreased (1.325721 --> 1.320705).  Saving model ...
Validation loss decreased (1.320705 --> 1.315193).  Saving model ...
Validation loss decreased (1.315193 --> 1.309529).  Saving model ...
Validation loss decreased (1.309529 --> 1.304357).  Saving model ...
Validation loss decreased (1.304357 --> 1.297596).  Saving model ...
Validation loss decreased (1.297596 --> 1.291379).  Saving model ...
Validation loss decreased (1.291379 --> 1.284574).  Saving model ...
Validation loss decreased (1.284574 --> 1.278448).  Saving model ...
Validation loss decreased (1.278448 --> 1.270730).  Saving model ...
Validation loss decreased (1.270730 --> 1.264262).  Saving model ...
Validation loss decreased (1.264262 --> 1.257662).  Saving model ...
Validation loss decreased (1.257662 --> 1.250421).  Saving model ...
Validation loss decreased (1.250421 --> 1.243475).  Saving model ...
Validation loss decreased (1.243475 --> 1.236325).  Saving model ...
Validation loss decreased (1.236325 --> 1.228403).  Saving model ...
Validation loss decreased (1.228403 --> 1.220457).  Saving model ...
Validation loss decreased (1.220457 --> 1.214104).  Saving model ...
Validation loss decreased (1.214104 --> 1.207369).  Saving model ...
Validation loss decreased (1.207369 --> 1.202779).  Saving model ...
Validation loss decreased (1.202779 --> 1.195556).  Saving model ...
Validation loss decreased (1.195556 --> 1.188376).  Saving model ...
Validation loss decreased (1.188376 --> 1.181278).  Saving model ...
Validation loss decreased (1.181278 --> 1.173488).  Saving model ...
Validation loss decreased (1.173488 --> 1.169457).  Saving model ...
Validation loss decreased (1.169457 --> 1.164527).  Saving model ...
Validation loss decreased (1.164527 --> 1.156969).  Saving model ...
Validation loss decreased (1.156969 --> 1.151497).  Saving model ...
Validation loss decreased (1.151497 --> 1.146203).  Saving model ...
Validation loss decreased (1.146203 --> 1.143748).  Saving model ...
Validation loss decreased (1.143748 --> 1.138518).  Saving model ...
Validation loss decreased (1.138518 --> 1.133391).  Saving model ...
Validation loss decreased (1.133391 --> 1.131624).  Saving model ...
Validation loss decreased (1.131624 --> 1.127658).  Saving model ...
Validation loss decreased (1.127658 --> 1.122510).  Saving model ...
Validation loss decreased (1.122510 --> 1.117882).  Saving model ...
Validation loss decreased (1.117882 --> 1.113947).  Saving model ...
Validation loss decreased (1.113947 --> 1.109189).  Saving model ...
Validation loss decreased (1.109189 --> 1.104141).  Saving model ...
Validation loss decreased (1.104141 --> 1.099615).  Saving model ...
Validation loss decreased (1.099615 --> 1.096859).  Saving model ...
Validation loss decreased (1.096859 --> 1.090975).  Saving model ...
Validation loss decreased (1.090975 --> 1.088156).  Saving model ...
Validation loss decreased (1.088156 --> 1.083374).  Saving model ...
Validation loss decreased (1.083374 --> 1.079034).  Saving model ...
Validation loss decreased (1.079034 --> 1.075354).  Saving model ...
Validation loss decreased (1.075354 --> 1.072724).  Saving model ...
Validation loss decreased (1.072724 --> 1.070558).  Saving model ...
Validation loss decreased (1.070558 --> 1.068144).  Saving model ...
Validation loss decreased (1.068144 --> 1.064400).  Saving model ...
Validation loss decreased (1.064400 --> 1.060611).  Saving model ...
Validation loss decreased (1.060611 --> 1.057570).  Saving model ...
Validation loss decreased (1.057570 --> 1.053399).  Saving model ...
Validation loss decreased (1.053399 --> 1.051638).  Saving model ...
Validation loss decreased (1.051638 --> 1.049788).  Saving model ...
Validation loss decreased (1.049788 --> 1.045417).  Saving model ...
Validation loss decreased (1.045417 --> 1.040031).  Saving model ...
Validation loss decreased (1.040031 --> 1.036825).  Saving model ...
EarlyStopping counter: 1 out of 10.0
Validation loss decreased (1.036825 --> 1.034473).  Saving model ...
Validation loss decreased (1.034473 --> 1.032492).  Saving model ...
Validation loss decreased (1.032492 --> 1.027695).  Saving model ...
Validation loss decreased (1.027695 --> 1.024509).  Saving model ...
Validation loss decreased (1.024509 --> 1.023373).  Saving model ...
Validation loss decreased (1.023373 --> 1.022205).  Saving model ...
Validation loss decreased (1.022205 --> 1.019042).  Saving model ...
Validation loss decreased (1.019042 --> 1.018291).  Saving model ...
Validation loss decreased (1.018291 --> 1.015966).  Saving model ...
Validation loss decreased (1.015966 --> 1.011320).  Saving model ...
Validation loss decreased (1.011320 --> 1.010090).  Saving model ...
Validation loss decreased (1.010090 --> 1.009076).  Saving model ...
Validation loss decreased (1.009076 --> 1.007511).  Saving model ...
Validation loss decreased (1.007511 --> 1.005790).  Saving model ...
Validation loss decreased (1.005790 --> 1.005024).  Saving model ...
Validation loss decreased (1.005024 --> 1.001202).  Saving model ...
Validation loss decreased (1.001202 --> 0.999866).  Saving model ...
Validation loss decreased (0.999866 --> 0.999085).  Saving model ...
Validation loss decreased (0.999085 --> 0.995867).  Saving model ...
Validation loss decreased (0.995867 --> 0.994426).  Saving model ...
Validation loss decreased (0.994426 --> 0.994410).  Saving model ...
Validation loss decreased (0.994410 --> 0.993481).  Saving model ...
Validation loss decreased (0.993481 --> 0.991710).  Saving model ...
Validation loss decreased (0.991710 --> 0.989080).  Saving model ...
Validation loss decreased (0.989080 --> 0.987185).  Saving model ...
EarlyStopping counter: 1 out of 10.0
Validation loss decreased (0.987185 --> 0.984889).  Saving model ...
Validation loss decreased (0.984889 --> 0.984405).  Saving model ...
Validation loss decreased (0.984405 --> 0.983754).  Saving model ...
Validation loss decreased (0.983754 --> 0.982759).  Saving model ...
Validation loss decreased (0.982759 --> 0.980237).  Saving model ...
Validation loss decreased (0.980237 --> 0.979864).  Saving model ...
Validation loss decreased (0.979864 --> 0.978075).  Saving model ...
Validation loss decreased (0.978075 --> 0.977523).  Saving model ...
EarlyStopping counter: 1 out of 10.0
Validation loss decreased (0.977523 --> 0.974461).  Saving model ...
Validation loss decreased (0.974461 --> 0.971797).  Saving model ...
Validation loss decreased (0.971797 --> 0.970268).  Saving model ...
EarlyStopping counter: 1 out of 10.0
Validation loss decreased (0.970268 --> 0.968818).  Saving model ...
Validation loss decreased (0.968818 --> 0.968141).  Saving model ...
EarlyStopping counter: 1 out of 10.0
EarlyStopping counter: 2 out of 10.0
EarlyStopping counter: 3 out of 10.0
EarlyStopping counter: 4 out of 10.0
Validation loss decreased (0.968141 --> 0.967031).  Saving model ...
Validation loss decreased (0.967031 --> 0.966396).  Saving model ...
Validation loss decreased (0.966396 --> 0.965739).  Saving model ...
EarlyStopping counter: 1 out of 10.0
Validation loss decreased (0.965739 --> 0.964271).  Saving model ...
EarlyStopping counter: 1 out of 10.0
Validation loss decreased (0.964271 --> 0.959048).  Saving model ...
Validation loss decreased (0.959048 --> 0.958590).  Saving model ...
Validation loss decreased (0.958590 --> 0.957312).  Saving model ...
Validation loss decreased (0.957312 --> 0.956261).  Saving model ...
EarlyStopping counter: 1 out of 10.0
Validation loss decreased (0.956261 --> 0.955677).  Saving model ...
EarlyStopping counter: 1 out of 10.0
EarlyStopping counter: 2 out of 10.0
EarlyStopping counter: 3 out of 10.0
Validation loss decreased (0.955677 --> 0.953930).  Saving model ...
EarlyStopping counter: 1 out of 10.0
EarlyStopping counter: 2 out of 10.0
Validation loss decreased (0.953930 --> 0.953000).  Saving model ...
EarlyStopping counter: 1 out of 10.0
EarlyStopping counter: 2 out of 10.0
EarlyStopping counter: 3 out of 10.0
EarlyStopping counter: 4 out of 10.0
EarlyStopping counter: 5 out of 10.0
Validation loss decreased (0.953000 --> 0.952559).  Saving model ...
Validation loss decreased (0.952559 --> 0.951273).  Saving model ...
EarlyStopping counter: 1 out of 10.0
EarlyStopping counter: 2 out of 10.0
EarlyStopping counter: 3 out of 10.0
EarlyStopping counter: 4 out of 10.0
Validation loss decreased (0.951273 --> 0.949769).  Saving model ...
Validation loss decreased (0.949769 --> 0.947662).  Saving model ...
Validation loss decreased (0.947662 --> 0.947482).  Saving model ...
EarlyStopping counter: 1 out of 10.0
EarlyStopping counter: 2 out of 10.0
EarlyStopping counter: 3 out of 10.0
EarlyStopping counter: 4 out of 10.0
EarlyStopping counter: 5 out of 10.0
EarlyStopping counter: 6 out of 10.0
EarlyStopping counter: 7 out of 10.0
EarlyStopping counter: 8 out of 10.0
EarlyStopping counter: 9 out of 10.0
EarlyStopping counter: 10 out of 10.0
/localscratch/yinan.29019353.0/env/lib/python3.7/site-packages/torch/nn/functional.py:1794: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.
  warnings.warn("nn.functional.tanh is deprecated. Use torch.tanh instead.")
wandb: Waiting for W&B process to finish, PID 53875... (success).
wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: \ 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: | 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: / 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: \ 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: | 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: / 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: \ 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: | 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: / 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb:                                                                                
wandb: Run history:
wandb:     e_F1 ▁▂▃▄▄▅▅▆▆▆▆▆▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇███████████
wandb:   e_loss █▇▇▇▇▆▆▅▅▄▄▄▄▃▃▃▃▂▂▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:     t_F1 ▁▂▂▂▃▃▃▃▄▅▄▅▅▅▆▆▅▆▆▆▆▆▇▆▆▇▇▇▇▇▇▇▇▇▇██▇██
wandb:   t_loss ██▇▇▇▇▇▆▆▅▅▅▅▅▄▄▄▄▄▄▃▃▃▃▃▃▂▂▂▂▂▂▁▂▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:     e_F1 62.15387
wandb:   e_loss 0.9504
wandb:     t_F1 70.07363
wandb:   t_loss 0.76214
wandb: 
wandb: Synced 4 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Synced wandering-plasma-2: https://wandb.ai/yinanazhou/xl_512_bs_8_lr_1e06_es_10_lc_False_nr_True_sr_False_stem_True_lemma_False_repeat_2_fold_2/runs/3r3srfsy
wandb: Find logs at: ./wandb/run-20220318_235857-3r3srfsy/logs/debug.log
wandb: 

wandb: wandb version 0.12.11 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
2022-03-19 01:42:23.767437: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1
wandb: Tracking run with wandb version 0.12.5
wandb: Syncing run fast-mountain-2
wandb: ⭐️ View project at https://wandb.ai/yinanazhou/xl_512_bs_8_lr_1e06_es_10_lc_False_nr_True_sr_False_stem_True_lemma_False_repeat_3_fold_1
wandb: 🚀 View run at https://wandb.ai/yinanazhou/xl_512_bs_8_lr_1e06_es_10_lc_False_nr_True_sr_False_stem_True_lemma_False_repeat_3_fold_1/runs/2z8rny8w
wandb: Run data is saved locally in /project/6002780/yinan/Thesis_MER_Lyrics/lyric-emotion/wandb/run-20220319_014220-2z8rny8w
wandb: Run `wandb offline` to turn off syncing.

Validation loss decreased (inf --> 1.521792).  Saving model ...
Validation loss decreased (1.521792 --> 1.478796).  Saving model ...
Validation loss decreased (1.478796 --> 1.443103).  Saving model ...
Validation loss decreased (1.443103 --> 1.414544).  Saving model ...
Validation loss decreased (1.414544 --> 1.393020).  Saving model ...
Validation loss decreased (1.393020 --> 1.377928).  Saving model ...
Validation loss decreased (1.377928 --> 1.366315).  Saving model ...
Validation loss decreased (1.366315 --> 1.358115).  Saving model ...
Validation loss decreased (1.358115 --> 1.351632).  Saving model ...
Validation loss decreased (1.351632 --> 1.346158).  Saving model ...
Validation loss decreased (1.346158 --> 1.341606).  Saving model ...
Validation loss decreased (1.341606 --> 1.337004).  Saving model ...
Validation loss decreased (1.337004 --> 1.333258).  Saving model ...
Validation loss decreased (1.333258 --> 1.329705).  Saving model ...
Validation loss decreased (1.329705 --> 1.325683).  Saving model ...
Validation loss decreased (1.325683 --> 1.321008).  Saving model ...
Validation loss decreased (1.321008 --> 1.317040).  Saving model ...
Validation loss decreased (1.317040 --> 1.312305).  Saving model ...
Validation loss decreased (1.312305 --> 1.308062).  Saving model ...
Validation loss decreased (1.308062 --> 1.304578).  Saving model ...
Validation loss decreased (1.304578 --> 1.299815).  Saving model ...
Validation loss decreased (1.299815 --> 1.293844).  Saving model ...
Validation loss decreased (1.293844 --> 1.288748).  Saving model ...
Validation loss decreased (1.288748 --> 1.282641).  Saving model ...
Validation loss decreased (1.282641 --> 1.277419).  Saving model ...
Validation loss decreased (1.277419 --> 1.272054).  Saving model ...
Validation loss decreased (1.272054 --> 1.266000).  Saving model ...
Validation loss decreased (1.266000 --> 1.259825).  Saving model ...
Validation loss decreased (1.259825 --> 1.254056).  Saving model ...
Validation loss decreased (1.254056 --> 1.248769).  Saving model ...
Validation loss decreased (1.248769 --> 1.243889).  Saving model ...
Validation loss decreased (1.243889 --> 1.238069).  Saving model ...
Validation loss decreased (1.238069 --> 1.232008).  Saving model ...
Validation loss decreased (1.232008 --> 1.226045).  Saving model ...
Validation loss decreased (1.226045 --> 1.220231).  Saving model ...
Validation loss decreased (1.220231 --> 1.214729).  Saving model ...
Validation loss decreased (1.214729 --> 1.210741).  Saving model ...
Validation loss decreased (1.210741 --> 1.205641).  Saving model ...
Validation loss decreased (1.205641 --> 1.200154).  Saving model ...
Validation loss decreased (1.200154 --> 1.195160).  Saving model ...
Validation loss decreased (1.195160 --> 1.189442).  Saving model ...
Validation loss decreased (1.189442 --> 1.185084).  Saving model ...
Validation loss decreased (1.185084 --> 1.181626).  Saving model ...
Validation loss decreased (1.181626 --> 1.176610).  Saving model ...
Validation loss decreased (1.176610 --> 1.172816).  Saving model ...
Validation loss decreased (1.172816 --> 1.167171).  Saving model ...
Validation loss decreased (1.167171 --> 1.163063).  Saving model ...
Validation loss decreased (1.163063 --> 1.160178).  Saving model ...
Validation loss decreased (1.160178 --> 1.155752).  Saving model ...
Validation loss decreased (1.155752 --> 1.150453).  Saving model ...
Validation loss decreased (1.150453 --> 1.143838).  Saving model ...
Validation loss decreased (1.143838 --> 1.143205).  Saving model ...
Validation loss decreased (1.143205 --> 1.141094).  Saving model ...
Validation loss decreased (1.141094 --> 1.137115).  Saving model ...
Validation loss decreased (1.137115 --> 1.132936).  Saving model ...
Validation loss decreased (1.132936 --> 1.129149).  Saving model ...
Validation loss decreased (1.129149 --> 1.125111).  Saving model ...
Validation loss decreased (1.125111 --> 1.120969).  Saving model ...
Validation loss decreased (1.120969 --> 1.119357).  Saving model ...
Validation loss decreased (1.119357 --> 1.115626).  Saving model ...
Validation loss decreased (1.115626 --> 1.113399).  Saving model ...
Validation loss decreased (1.113399 --> 1.107860).  Saving model ...
Validation loss decreased (1.107860 --> 1.104427).  Saving model ...
Validation loss decreased (1.104427 --> 1.102938).  Saving model ...
Validation loss decreased (1.102938 --> 1.101028).  Saving model ...
Validation loss decreased (1.101028 --> 1.095214).  Saving model ...
EarlyStopping counter: 1 out of 10.0
Validation loss decreased (1.095214 --> 1.091844).  Saving model ...
Validation loss decreased (1.091844 --> 1.085689).  Saving model ...
EarlyStopping counter: 1 out of 10.0
Validation loss decreased (1.085689 --> 1.083932).  Saving model ...
Validation loss decreased (1.083932 --> 1.080134).  Saving model ...
Validation loss decreased (1.080134 --> 1.078972).  Saving model ...
Validation loss decreased (1.078972 --> 1.077098).  Saving model ...
Validation loss decreased (1.077098 --> 1.072693).  Saving model ...
Validation loss decreased (1.072693 --> 1.071435).  Saving model ...
Validation loss decreased (1.071435 --> 1.068240).  Saving model ...
Validation loss decreased (1.068240 --> 1.064221).  Saving model ...
EarlyStopping counter: 1 out of 10.0
Validation loss decreased (1.064221 --> 1.063651).  Saving model ...
Validation loss decreased (1.063651 --> 1.059740).  Saving model ...
Validation loss decreased (1.059740 --> 1.054854).  Saving model ...
EarlyStopping counter: 1 out of 10.0
EarlyStopping counter: 2 out of 10.0
Validation loss decreased (1.054854 --> 1.054214).  Saving model ...
Validation loss decreased (1.054214 --> 1.051475).  Saving model ...
Validation loss decreased (1.051475 --> 1.048031).  Saving model ...
Validation loss decreased (1.048031 --> 1.043093).  Saving model ...
Validation loss decreased (1.043093 --> 1.041240).  Saving model ...
Validation loss decreased (1.041240 --> 1.040696).  Saving model ...
EarlyStopping counter: 1 out of 10.0
Validation loss decreased (1.040696 --> 1.039669).  Saving model ...
EarlyStopping counter: 1 out of 10.0
EarlyStopping counter: 2 out of 10.0
EarlyStopping counter: 3 out of 10.0
Validation loss decreased (1.039669 --> 1.038914).  Saving model ...
EarlyStopping counter: 1 out of 10.0
EarlyStopping counter: 2 out of 10.0
Validation loss decreased (1.038914 --> 1.032617).  Saving model ...
EarlyStopping counter: 1 out of 10.0
EarlyStopping counter: 2 out of 10.0
EarlyStopping counter: 3 out of 10.0
EarlyStopping counter: 4 out of 10.0
EarlyStopping counter: 5 out of 10.0
EarlyStopping counter: 6 out of 10.0
EarlyStopping counter: 7 out of 10.0
EarlyStopping counter: 8 out of 10.0
EarlyStopping counter: 9 out of 10.0
Validation loss decreased (1.032617 --> 1.030802).  Saving model ...
Validation loss decreased (1.030802 --> 1.027736).  Saving model ...
Validation loss decreased (1.027736 --> 1.027363).  Saving model ...
EarlyStopping counter: 1 out of 10.0
EarlyStopping counter: 2 out of 10.0
EarlyStopping counter: 3 out of 10.0
EarlyStopping counter: 4 out of 10.0
Validation loss decreased (1.027363 --> 1.024254).  Saving model ...
Validation loss decreased (1.024254 --> 1.022738).  Saving model ...
Validation loss decreased (1.022738 --> 1.022415).  Saving model ...
EarlyStopping counter: 1 out of 10.0
EarlyStopping counter: 2 out of 10.0
EarlyStopping counter: 3 out of 10.0
Validation loss decreased (1.022415 --> 1.019985).  Saving model ...
EarlyStopping counter: 1 out of 10.0
EarlyStopping counter: 2 out of 10.0
Validation loss decreased (1.019985 --> 1.019493).  Saving model ...
EarlyStopping counter: 1 out of 10.0
EarlyStopping counter: 2 out of 10.0
Validation loss decreased (1.019493 --> 1.018120).  Saving model ...
EarlyStopping counter: 1 out of 10.0
EarlyStopping counter: 2 out of 10.0
Validation loss decreased (1.018120 --> 1.017241).  Saving model ...
EarlyStopping counter: 1 out of 10.0
EarlyStopping counter: 2 out of 10.0
EarlyStopping counter: 3 out of 10.0
Validation loss decreased (1.017241 --> 1.015149).  Saving model ...
EarlyStopping counter: 1 out of 10.0
EarlyStopping counter: 2 out of 10.0
EarlyStopping counter: 3 out of 10.0
EarlyStopping counter: 4 out of 10.0
EarlyStopping counter: 5 out of 10.0
EarlyStopping counter: 6 out of 10.0
EarlyStopping counter: 7 out of 10.0
EarlyStopping counter: 8 out of 10.0
EarlyStopping counter: 9 out of 10.0
EarlyStopping counter: 10 out of 10.0
/localscratch/yinan.29019353.0/env/lib/python3.7/site-packages/torch/nn/functional.py:1794: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.
  warnings.warn("nn.functional.tanh is deprecated. Use torch.tanh instead.")
wandb: Waiting for W&B process to finish, PID 59490... (success).
wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: \ 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: | 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: / 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: \ 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: | 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: / 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: \ 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: | 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: / 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb:                                                                                
wandb: Run history:
wandb:     e_F1 ▁▂▄▄▄▅▅▅▅▆▆▆▆▆▆▇▇▇▇▇▇▇▇▇▇███████████████
wandb:   e_loss █▇▆▆▆▅▅▅▅▄▄▄▃▃▃▃▂▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:     t_F1 ▁▁▃▂▃▃▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▆▆▇▇▇▇▇▇▇█████████
wandb:   t_loss ██▇▇▇▆▆▆▆▆▅▅▅▅▄▄▄▄▄▃▃▃▃▃▃▃▂▂▂▂▂▂▂▂▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:     e_F1 56.69926
wandb:   e_loss 1.0154
wandb:     t_F1 68.37234
wandb:   t_loss 0.77143
wandb: 
wandb: Synced 4 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Synced fast-mountain-2: https://wandb.ai/yinanazhou/xl_512_bs_8_lr_1e06_es_10_lc_False_nr_True_sr_False_stem_True_lemma_False_repeat_3_fold_1/runs/2z8rny8w
wandb: Find logs at: ./wandb/run-20220319_014220-2z8rny8w/logs/debug.log
wandb: 

wandb: wandb version 0.12.11 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
2022-03-19 03:15:20.779444: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1
wandb: Tracking run with wandb version 0.12.5
wandb: Syncing run driven-water-2
wandb: ⭐️ View project at https://wandb.ai/yinanazhou/xl_512_bs_8_lr_1e06_es_10_lc_False_nr_True_sr_False_stem_True_lemma_False_repeat_3_fold_2
wandb: 🚀 View run at https://wandb.ai/yinanazhou/xl_512_bs_8_lr_1e06_es_10_lc_False_nr_True_sr_False_stem_True_lemma_False_repeat_3_fold_2/runs/13fknh1w
wandb: Run data is saved locally in /project/6002780/yinan/Thesis_MER_Lyrics/lyric-emotion/wandb/run-20220319_031517-13fknh1w
wandb: Run `wandb offline` to turn off syncing.

Validation loss decreased (inf --> 1.397925).  Saving model ...
Validation loss decreased (1.397925 --> 1.392808).  Saving model ...
Validation loss decreased (1.392808 --> 1.388679).  Saving model ...
Validation loss decreased (1.388679 --> 1.384477).  Saving model ...
Validation loss decreased (1.384477 --> 1.380805).  Saving model ...
Validation loss decreased (1.380805 --> 1.377002).  Saving model ...
Validation loss decreased (1.377002 --> 1.373475).  Saving model ...
Validation loss decreased (1.373475 --> 1.370120).  Saving model ...
Validation loss decreased (1.370120 --> 1.366736).  Saving model ...
Validation loss decreased (1.366736 --> 1.363126).  Saving model ...
Validation loss decreased (1.363126 --> 1.359431).  Saving model ...
Validation loss decreased (1.359431 --> 1.355454).  Saving model ...
Validation loss decreased (1.355454 --> 1.351737).  Saving model ...
Validation loss decreased (1.351737 --> 1.347557).  Saving model ...
Validation loss decreased (1.347557 --> 1.343338).  Saving model ...
Validation loss decreased (1.343338 --> 1.338790).  Saving model ...
Validation loss decreased (1.338790 --> 1.334544).  Saving model ...
Validation loss decreased (1.334544 --> 1.329366).  Saving model ...
Validation loss decreased (1.329366 --> 1.324382).  Saving model ...
Validation loss decreased (1.324382 --> 1.318743).  Saving model ...
Validation loss decreased (1.318743 --> 1.312917).  Saving model ...
Validation loss decreased (1.312917 --> 1.306631).  Saving model ...
Validation loss decreased (1.306631 --> 1.299732).  Saving model ...
Validation loss decreased (1.299732 --> 1.291664).  Saving model ...
Validation loss decreased (1.291664 --> 1.283561).  Saving model ...
Validation loss decreased (1.283561 --> 1.275484).  Saving model ...
Validation loss decreased (1.275484 --> 1.265892).  Saving model ...
Validation loss decreased (1.265892 --> 1.257686).  Saving model ...
Validation loss decreased (1.257686 --> 1.248663).  Saving model ...
Validation loss decreased (1.248663 --> 1.241130).  Saving model ...
Validation loss decreased (1.241130 --> 1.231658).  Saving model ...
Validation loss decreased (1.231658 --> 1.223815).  Saving model ...
Validation loss decreased (1.223815 --> 1.215485).  Saving model ...
Validation loss decreased (1.215485 --> 1.208774).  Saving model ...
Validation loss decreased (1.208774 --> 1.202051).  Saving model ...
Validation loss decreased (1.202051 --> 1.195844).  Saving model ...
Validation loss decreased (1.195844 --> 1.189822).  Saving model ...
Validation loss decreased (1.189822 --> 1.183454).  Saving model ...
Validation loss decreased (1.183454 --> 1.178160).  Saving model ...
Validation loss decreased (1.178160 --> 1.172805).  Saving model ...
Validation loss decreased (1.172805 --> 1.165901).  Saving model ...
Validation loss decreased (1.165901 --> 1.159871).  Saving model ...
Validation loss decreased (1.159871 --> 1.153644).  Saving model ...
Validation loss decreased (1.153644 --> 1.148698).  Saving model ...
Validation loss decreased (1.148698 --> 1.143068).  Saving model ...
Validation loss decreased (1.143068 --> 1.137466).  Saving model ...
Validation loss decreased (1.137466 --> 1.132131).  Saving model ...
Validation loss decreased (1.132131 --> 1.126988).  Saving model ...
Validation loss decreased (1.126988 --> 1.122523).  Saving model ...
Validation loss decreased (1.122523 --> 1.118199).  Saving model ...
Validation loss decreased (1.118199 --> 1.113552).  Saving model ...
Validation loss decreased (1.113552 --> 1.109382).  Saving model ...
Validation loss decreased (1.109382 --> 1.105112).  Saving model ...
Validation loss decreased (1.105112 --> 1.100813).  Saving model ...
Validation loss decreased (1.100813 --> 1.096792).  Saving model ...
Validation loss decreased (1.096792 --> 1.092779).  Saving model ...
Validation loss decreased (1.092779 --> 1.088054).  Saving model ...
Validation loss decreased (1.088054 --> 1.084577).  Saving model ...
Validation loss decreased (1.084577 --> 1.080566).  Saving model ...
Validation loss decreased (1.080566 --> 1.076675).  Saving model ...
Validation loss decreased (1.076675 --> 1.073707).  Saving model ...
Validation loss decreased (1.073707 --> 1.069979).  Saving model ...
Validation loss decreased (1.069979 --> 1.066059).  Saving model ...
Validation loss decreased (1.066059 --> 1.062713).  Saving model ...
Validation loss decreased (1.062713 --> 1.059975).  Saving model ...
Validation loss decreased (1.059975 --> 1.056699).  Saving model ...
Validation loss decreased (1.056699 --> 1.052908).  Saving model ...
Validation loss decreased (1.052908 --> 1.049254).  Saving model ...
Validation loss decreased (1.049254 --> 1.045025).  Saving model ...
Validation loss decreased (1.045025 --> 1.041492).  Saving model ...
Validation loss decreased (1.041492 --> 1.039139).  Saving model ...
Validation loss decreased (1.039139 --> 1.036096).  Saving model ...
Validation loss decreased (1.036096 --> 1.034280).  Saving model ...
Validation loss decreased (1.034280 --> 1.031366).  Saving model ...
Validation loss decreased (1.031366 --> 1.028165).  Saving model ...
Validation loss decreased (1.028165 --> 1.025374).  Saving model ...
Validation loss decreased (1.025374 --> 1.022469).  Saving model ...
Validation loss decreased (1.022469 --> 1.019534).  Saving model ...
Validation loss decreased (1.019534 --> 1.016275).  Saving model ...
Validation loss decreased (1.016275 --> 1.013595).  Saving model ...
Validation loss decreased (1.013595 --> 1.011377).  Saving model ...
Validation loss decreased (1.011377 --> 1.009710).  Saving model ...
Validation loss decreased (1.009710 --> 1.007555).  Saving model ...
Validation loss decreased (1.007555 --> 1.005707).  Saving model ...
Validation loss decreased (1.005707 --> 1.003217).  Saving model ...
Validation loss decreased (1.003217 --> 1.001713).  Saving model ...
Validation loss decreased (1.001713 --> 0.999486).  Saving model ...
Validation loss decreased (0.999486 --> 0.997036).  Saving model ...
Validation loss decreased (0.997036 --> 0.995582).  Saving model ...
Validation loss decreased (0.995582 --> 0.993206).  Saving model ...
Validation loss decreased (0.993206 --> 0.991855).  Saving model ...
Validation loss decreased (0.991855 --> 0.990551).  Saving model ...
Validation loss decreased (0.990551 --> 0.987810).  Saving model ...
Validation loss decreased (0.987810 --> 0.985912).  Saving model ...
Validation loss decreased (0.985912 --> 0.985086).  Saving model ...
Validation loss decreased (0.985086 --> 0.983865).  Saving model ...
Validation loss decreased (0.983865 --> 0.983357).  Saving model ...
Validation loss decreased (0.983357 --> 0.981236).  Saving model ...
Validation loss decreased (0.981236 --> 0.980087).  Saving model ...
Validation loss decreased (0.980087 --> 0.978589).  Saving model ...
Validation loss decreased (0.978589 --> 0.977794).  Saving model ...
Validation loss decreased (0.977794 --> 0.975679).  Saving model ...
Validation loss decreased (0.975679 --> 0.974072).  Saving model ...
Validation loss decreased (0.974072 --> 0.972431).  Saving model ...
Validation loss decreased (0.972431 --> 0.971261).  Saving model ...
Validation loss decreased (0.971261 --> 0.970369).  Saving model ...
Validation loss decreased (0.970369 --> 0.970148).  Saving model ...
Validation loss decreased (0.970148 --> 0.969258).  Saving model ...
Validation loss decreased (0.969258 --> 0.967703).  Saving model ...
Validation loss decreased (0.967703 --> 0.966389).  Saving model ...
Validation loss decreased (0.966389 --> 0.964659).  Saving model ...
Validation loss decreased (0.964659 --> 0.963640).  Saving model ...
Validation loss decreased (0.963640 --> 0.962987).  Saving model ...
EarlyStopping counter: 1 out of 10.0
Validation loss decreased (0.962987 --> 0.962796).  Saving model ...
Validation loss decreased (0.962796 --> 0.961487).  Saving model ...
Validation loss decreased (0.961487 --> 0.960508).  Saving model ...
Validation loss decreased (0.960508 --> 0.959948).  Saving model ...
EarlyStopping counter: 1 out of 10.0
EarlyStopping counter: 2 out of 10.0
EarlyStopping counter: 3 out of 10.0
Validation loss decreased (0.959948 --> 0.959836).  Saving model ...
Validation loss decreased (0.959836 --> 0.958515).  Saving model ...
Validation loss decreased (0.958515 --> 0.958446).  Saving model ...
Validation loss decreased (0.958446 --> 0.957884).  Saving model ...
Validation loss decreased (0.957884 --> 0.956468).  Saving model ...
EarlyStopping counter: 1 out of 10.0
EarlyStopping counter: 2 out of 10.0
EarlyStopping counter: 3 out of 10.0
EarlyStopping counter: 4 out of 10.0
EarlyStopping counter: 5 out of 10.0
EarlyStopping counter: 6 out of 10.0
EarlyStopping counter: 7 out of 10.0
EarlyStopping counter: 8 out of 10.0
EarlyStopping counter: 9 out of 10.0
EarlyStopping counter: 10 out of 10.0
/localscratch/yinan.29019353.0/env/lib/python3.7/site-packages/torch/nn/functional.py:1794: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.
  warnings.warn("nn.functional.tanh is deprecated. Use torch.tanh instead.")
wandb: Waiting for W&B process to finish, PID 64493... (success).
wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: \ 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: | 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: / 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb:                                                                                
wandb: Run history:
wandb:     e_F1 ▁▂▂▃▄▄▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇▇▇▇▇▇▇█████████████
wandb:   e_loss ███▇▇▇▇▆▆▅▅▅▄▄▄▃▃▃▃▃▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:     t_F1 ▁▁▂▂▂▃▃▃▄▄▅▄▅▆▅▆▆▆▆▆▆▆▆▆▇▇▇▇▇▇▇▇▇▇██████
wandb:   t_loss ████▇▇▇▇▇▆▆▆▅▅▅▅▄▄▄▄▄▄▃▃▃▃▃▃▃▂▂▂▂▂▂▂▁▁▁▁
wandb: 
wandb: Run summary:
wandb:     e_F1 61.13469
wandb:   e_loss 0.95656
wandb:     t_F1 71.21501
wandb:   t_loss 0.75067
wandb: 
wandb: Synced 4 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Synced driven-water-2: https://wandb.ai/yinanazhou/xl_512_bs_8_lr_1e06_es_10_lc_False_nr_True_sr_False_stem_True_lemma_False_repeat_3_fold_2/runs/13fknh1w
wandb: Find logs at: ./wandb/run-20220319_031517-13fknh1w/logs/debug.log
wandb: 

wandb: wandb version 0.12.11 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
2022-03-19 04:42:41.773533: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1
wandb: Tracking run with wandb version 0.12.5
wandb: Syncing run frosty-dawn-2
wandb: ⭐️ View project at https://wandb.ai/yinanazhou/xl_512_bs_8_lr_1e06_es_10_lc_False_nr_True_sr_False_stem_True_lemma_False_repeat_4_fold_1
wandb: 🚀 View run at https://wandb.ai/yinanazhou/xl_512_bs_8_lr_1e06_es_10_lc_False_nr_True_sr_False_stem_True_lemma_False_repeat_4_fold_1/runs/3qb5aixr
wandb: Run data is saved locally in /project/6002780/yinan/Thesis_MER_Lyrics/lyric-emotion/wandb/run-20220319_044237-3qb5aixr
wandb: Run `wandb offline` to turn off syncing.

Validation loss decreased (inf --> 1.437034).  Saving model ...
Validation loss decreased (1.437034 --> 1.414637).  Saving model ...
Validation loss decreased (1.414637 --> 1.398319).  Saving model ...
Validation loss decreased (1.398319 --> 1.387355).  Saving model ...
Validation loss decreased (1.387355 --> 1.379039).  Saving model ...
Validation loss decreased (1.379039 --> 1.371852).  Saving model ...
Validation loss decreased (1.371852 --> 1.366344).  Saving model ...
Validation loss decreased (1.366344 --> 1.361611).  Saving model ...
Validation loss decreased (1.361611 --> 1.357129).  Saving model ...
Validation loss decreased (1.357129 --> 1.352907).  Saving model ...
Validation loss decreased (1.352907 --> 1.348705).  Saving model ...
Validation loss decreased (1.348705 --> 1.343922).  Saving model ...
Validation loss decreased (1.343922 --> 1.339326).  Saving model ...
Validation loss decreased (1.339326 --> 1.333956).  Saving model ...
Validation loss decreased (1.333956 --> 1.328844).  Saving model ...
Validation loss decreased (1.328844 --> 1.323334).  Saving model ...
Validation loss decreased (1.323334 --> 1.317553).  Saving model ...
Validation loss decreased (1.317553 --> 1.312868).  Saving model ...
Validation loss decreased (1.312868 --> 1.307642).  Saving model ...
Validation loss decreased (1.307642 --> 1.301625).  Saving model ...
Validation loss decreased (1.301625 --> 1.295128).  Saving model ...
Validation loss decreased (1.295128 --> 1.289138).  Saving model ...
Validation loss decreased (1.289138 --> 1.282900).  Saving model ...
Validation loss decreased (1.282900 --> 1.276902).  Saving model ...
Validation loss decreased (1.276902 --> 1.271338).  Saving model ...
Validation loss decreased (1.271338 --> 1.265085).  Saving model ...
Validation loss decreased (1.265085 --> 1.259325).  Saving model ...
Validation loss decreased (1.259325 --> 1.251939).  Saving model ...
Validation loss decreased (1.251939 --> 1.245705).  Saving model ...
Validation loss decreased (1.245705 --> 1.239548).  Saving model ...
Validation loss decreased (1.239548 --> 1.233476).  Saving model ...
Validation loss decreased (1.233476 --> 1.227780).  Saving model ...
Validation loss decreased (1.227780 --> 1.221201).  Saving model ...
Validation loss decreased (1.221201 --> 1.216597).  Saving model ...
Validation loss decreased (1.216597 --> 1.210887).  Saving model ...
Validation loss decreased (1.210887 --> 1.204847).  Saving model ...
Validation loss decreased (1.204847 --> 1.198990).  Saving model ...
Validation loss decreased (1.198990 --> 1.193870).  Saving model ...
Validation loss decreased (1.193870 --> 1.188418).  Saving model ...
Validation loss decreased (1.188418 --> 1.183087).  Saving model ...
Validation loss decreased (1.183087 --> 1.178521).  Saving model ...
Validation loss decreased (1.178521 --> 1.173704).  Saving model ...
Validation loss decreased (1.173704 --> 1.168575).  Saving model ...
Validation loss decreased (1.168575 --> 1.163394).  Saving model ...
Validation loss decreased (1.163394 --> 1.158985).  Saving model ...
Validation loss decreased (1.158985 --> 1.155102).  Saving model ...
Validation loss decreased (1.155102 --> 1.150755).  Saving model ...
Validation loss decreased (1.150755 --> 1.146505).  Saving model ...
Validation loss decreased (1.146505 --> 1.142880).  Saving model ...
Validation loss decreased (1.142880 --> 1.138045).  Saving model ...
Validation loss decreased (1.138045 --> 1.133383).  Saving model ...
Validation loss decreased (1.133383 --> 1.129071).  Saving model ...
Validation loss decreased (1.129071 --> 1.124832).  Saving model ...
Validation loss decreased (1.124832 --> 1.120237).  Saving model ...
Validation loss decreased (1.120237 --> 1.116518).  Saving model ...
Validation loss decreased (1.116518 --> 1.113417).  Saving model ...
Validation loss decreased (1.113417 --> 1.109638).  Saving model ...
Validation loss decreased (1.109638 --> 1.106015).  Saving model ...
Validation loss decreased (1.106015 --> 1.102128).  Saving model ...
Validation loss decreased (1.102128 --> 1.099364).  Saving model ...
Validation loss decreased (1.099364 --> 1.096286).  Saving model ...
Validation loss decreased (1.096286 --> 1.093227).  Saving model ...
Validation loss decreased (1.093227 --> 1.090411).  Saving model ...
Validation loss decreased (1.090411 --> 1.087441).  Saving model ...
Validation loss decreased (1.087441 --> 1.084448).  Saving model ...
Validation loss decreased (1.084448 --> 1.082195).  Saving model ...
Validation loss decreased (1.082195 --> 1.079796).  Saving model ...
Validation loss decreased (1.079796 --> 1.076200).  Saving model ...
Validation loss decreased (1.076200 --> 1.072423).  Saving model ...
Validation loss decreased (1.072423 --> 1.069760).  Saving model ...
Validation loss decreased (1.069760 --> 1.067412).  Saving model ...
Validation loss decreased (1.067412 --> 1.065473).  Saving model ...
Validation loss decreased (1.065473 --> 1.063042).  Saving model ...
Validation loss decreased (1.063042 --> 1.060511).  Saving model ...
Validation loss decreased (1.060511 --> 1.057214).  Saving model ...
Validation loss decreased (1.057214 --> 1.056620).  Saving model ...
Validation loss decreased (1.056620 --> 1.054759).  Saving model ...
Validation loss decreased (1.054759 --> 1.052042).  Saving model ...
Validation loss decreased (1.052042 --> 1.049193).  Saving model ...
Validation loss decreased (1.049193 --> 1.046881).  Saving model ...
Validation loss decreased (1.046881 --> 1.044299).  Saving model ...
Validation loss decreased (1.044299 --> 1.042654).  Saving model ...
Validation loss decreased (1.042654 --> 1.040784).  Saving model ...
Validation loss decreased (1.040784 --> 1.039846).  Saving model ...
Validation loss decreased (1.039846 --> 1.036886).  Saving model ...
Validation loss decreased (1.036886 --> 1.035180).  Saving model ...
Validation loss decreased (1.035180 --> 1.034180).  Saving model ...
Validation loss decreased (1.034180 --> 1.033068).  Saving model ...
Validation loss decreased (1.033068 --> 1.030840).  Saving model ...
Validation loss decreased (1.030840 --> 1.029305).  Saving model ...
Validation loss decreased (1.029305 --> 1.027588).  Saving model ...
Validation loss decreased (1.027588 --> 1.024871).  Saving model ...
Validation loss decreased (1.024871 --> 1.023542).  Saving model ...
Validation loss decreased (1.023542 --> 1.021379).  Saving model ...
Validation loss decreased (1.021379 --> 1.020282).  Saving model ...
Validation loss decreased (1.020282 --> 1.018545).  Saving model ...
Validation loss decreased (1.018545 --> 1.018338).  Saving model ...
Validation loss decreased (1.018338 --> 1.016595).  Saving model ...
Validation loss decreased (1.016595 --> 1.014717).  Saving model ...
Validation loss decreased (1.014717 --> 1.012325).  Saving model ...
Validation loss decreased (1.012325 --> 1.011909).  Saving model ...
Validation loss decreased (1.011909 --> 1.011112).  Saving model ...
Validation loss decreased (1.011112 --> 1.009861).  Saving model ...
Validation loss decreased (1.009861 --> 1.007882).  Saving model ...
Validation loss decreased (1.007882 --> 1.006086).  Saving model ...
Validation loss decreased (1.006086 --> 1.004498).  Saving model ...
Validation loss decreased (1.004498 --> 1.004450).  Saving model ...
Validation loss decreased (1.004450 --> 1.003856).  Saving model ...
Validation loss decreased (1.003856 --> 1.002845).  Saving model ...
Validation loss decreased (1.002845 --> 1.001374).  Saving model ...
EarlyStopping counter: 1 out of 10.0
EarlyStopping counter: 2 out of 10.0
Validation loss decreased (1.001374 --> 1.000267).  Saving model ...
Validation loss decreased (1.000267 --> 1.000101).  Saving model ...
Validation loss decreased (1.000101 --> 0.999085).  Saving model ...
EarlyStopping counter: 1 out of 10.0
EarlyStopping counter: 2 out of 10.0
Validation loss decreased (0.999085 --> 0.997915).  Saving model ...
Validation loss decreased (0.997915 --> 0.996882).  Saving model ...
Validation loss decreased (0.996882 --> 0.996840).  Saving model ...
Validation loss decreased (0.996840 --> 0.995380).  Saving model ...
EarlyStopping counter: 1 out of 10.0
Validation loss decreased (0.995380 --> 0.995313).  Saving model ...
Validation loss decreased (0.995313 --> 0.994509).  Saving model ...
EarlyStopping counter: 1 out of 10.0
Validation loss decreased (0.994509 --> 0.994469).  Saving model ...
EarlyStopping counter: 1 out of 10.0
Validation loss decreased (0.994469 --> 0.994424).  Saving model ...
Validation loss decreased (0.994424 --> 0.992585).  Saving model ...
Validation loss decreased (0.992585 --> 0.990404).  Saving model ...
EarlyStopping counter: 1 out of 10.0
EarlyStopping counter: 2 out of 10.0
EarlyStopping counter: 3 out of 10.0
EarlyStopping counter: 4 out of 10.0
EarlyStopping counter: 5 out of 10.0
EarlyStopping counter: 6 out of 10.0
EarlyStopping counter: 7 out of 10.0
EarlyStopping counter: 8 out of 10.0
Validation loss decreased (0.990404 --> 0.989149).  Saving model ...
EarlyStopping counter: 1 out of 10.0
EarlyStopping counter: 2 out of 10.0
EarlyStopping counter: 3 out of 10.0
EarlyStopping counter: 4 out of 10.0
EarlyStopping counter: 5 out of 10.0
EarlyStopping counter: 6 out of 10.0
EarlyStopping counter: 7 out of 10.0
EarlyStopping counter: 8 out of 10.0
EarlyStopping counter: 9 out of 10.0
Validation loss decreased (0.989149 --> 0.988866).  Saving model ...
EarlyStopping counter: 1 out of 10.0
EarlyStopping counter: 2 out of 10.0
EarlyStopping counter: 3 out of 10.0
EarlyStopping counter: 4 out of 10.0
EarlyStopping counter: 5 out of 10.0
EarlyStopping counter: 6 out of 10.0
EarlyStopping counter: 7 out of 10.0
EarlyStopping counter: 8 out of 10.0
EarlyStopping counter: 9 out of 10.0
EarlyStopping counter: 10 out of 10.0
/localscratch/yinan.29019353.0/env/lib/python3.7/site-packages/torch/nn/functional.py:1794: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.
  warnings.warn("nn.functional.tanh is deprecated. Use torch.tanh instead.")
wandb: Waiting for W&B process to finish, PID 69224... (success).
wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: \ 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: | 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: / 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: \ 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: | 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: / 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: \ 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: | 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: / 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb:                                                                                
wandb: Run history:
wandb:     e_F1 ▁▃▄▄▅▅▅▆▆▆▆▆▇▇▇▇▇▇▇▇▇▇▇▇▇███████████████
wandb:   e_loss █▇▇▇▆▆▆▅▅▄▄▄▃▃▃▃▃▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:     t_F1 ▁▂▃▃▃▄▅▅▆▅▆▅▆▅▆▆▇▆▆▇▆▇▇▇▇█▇▇▇▇▇█▇███████
wandb:   t_loss ██▇▇▇▇▆▆▅▆▅▅▅▅▄▄▄▄▄▃▄▃▃▃▃▂▃▃▂▂▂▂▂▂▁▂▁▁▁▁
wandb: 
wandb: Run summary:
wandb:     e_F1 58.95266
wandb:   e_loss 0.99751
wandb:     t_F1 70.66475
wandb:   t_loss 0.71719
wandb: 
wandb: Synced 4 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Synced frosty-dawn-2: https://wandb.ai/yinanazhou/xl_512_bs_8_lr_1e06_es_10_lc_False_nr_True_sr_False_stem_True_lemma_False_repeat_4_fold_1/runs/3qb5aixr
wandb: Find logs at: ./wandb/run-20220319_044237-3qb5aixr/logs/debug.log
wandb: 

wandb: wandb version 0.12.11 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
2022-03-19 06:23:33.065710: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1
wandb: Tracking run with wandb version 0.12.5
wandb: Syncing run floral-vortex-2
wandb: ⭐️ View project at https://wandb.ai/yinanazhou/xl_512_bs_8_lr_1e06_es_10_lc_False_nr_True_sr_False_stem_True_lemma_False_repeat_4_fold_2
wandb: 🚀 View run at https://wandb.ai/yinanazhou/xl_512_bs_8_lr_1e06_es_10_lc_False_nr_True_sr_False_stem_True_lemma_False_repeat_4_fold_2/runs/1ju7nps9
wandb: Run data is saved locally in /project/6002780/yinan/Thesis_MER_Lyrics/lyric-emotion/wandb/run-20220319_062329-1ju7nps9
wandb: Run `wandb offline` to turn off syncing.

Validation loss decreased (inf --> 1.416117).  Saving model ...
Validation loss decreased (1.416117 --> 1.399539).  Saving model ...
Validation loss decreased (1.399539 --> 1.386190).  Saving model ...
Validation loss decreased (1.386190 --> 1.376602).  Saving model ...
Validation loss decreased (1.376602 --> 1.369389).  Saving model ...
Validation loss decreased (1.369389 --> 1.363310).  Saving model ...
Validation loss decreased (1.363310 --> 1.357630).  Saving model ...
Validation loss decreased (1.357630 --> 1.353128).  Saving model ...
Validation loss decreased (1.353128 --> 1.348149).  Saving model ...
Validation loss decreased (1.348149 --> 1.343549).  Saving model ...
Validation loss decreased (1.343549 --> 1.338618).  Saving model ...
Validation loss decreased (1.338618 --> 1.333857).  Saving model ...
Validation loss decreased (1.333857 --> 1.329318).  Saving model ...
Validation loss decreased (1.329318 --> 1.323780).  Saving model ...
Validation loss decreased (1.323780 --> 1.317375).  Saving model ...
Validation loss decreased (1.317375 --> 1.312054).  Saving model ...
Validation loss decreased (1.312054 --> 1.305679).  Saving model ...
Validation loss decreased (1.305679 --> 1.299678).  Saving model ...
Validation loss decreased (1.299678 --> 1.292881).  Saving model ...
Validation loss decreased (1.292881 --> 1.286332).  Saving model ...
Validation loss decreased (1.286332 --> 1.278543).  Saving model ...
Validation loss decreased (1.278543 --> 1.271282).  Saving model ...
Validation loss decreased (1.271282 --> 1.264853).  Saving model ...
Validation loss decreased (1.264853 --> 1.255760).  Saving model ...
Validation loss decreased (1.255760 --> 1.250170).  Saving model ...
Validation loss decreased (1.250170 --> 1.244155).  Saving model ...
Validation loss decreased (1.244155 --> 1.238879).  Saving model ...
Validation loss decreased (1.238879 --> 1.233321).  Saving model ...
Validation loss decreased (1.233321 --> 1.225959).  Saving model ...
Validation loss decreased (1.225959 --> 1.220384).  Saving model ...
Validation loss decreased (1.220384 --> 1.214137).  Saving model ...
Validation loss decreased (1.214137 --> 1.206984).  Saving model ...
Validation loss decreased (1.206984 --> 1.201192).  Saving model ...
Validation loss decreased (1.201192 --> 1.194815).  Saving model ...
Validation loss decreased (1.194815 --> 1.189580).  Saving model ...
Validation loss decreased (1.189580 --> 1.182712).  Saving model ...
Validation loss decreased (1.182712 --> 1.176670).  Saving model ...
Validation loss decreased (1.176670 --> 1.172669).  Saving model ...
Validation loss decreased (1.172669 --> 1.167005).  Saving model ...
Validation loss decreased (1.167005 --> 1.161119).  Saving model ...
Validation loss decreased (1.161119 --> 1.156453).  Saving model ...
Validation loss decreased (1.156453 --> 1.152539).  Saving model ...
Validation loss decreased (1.152539 --> 1.147715).  Saving model ...
Validation loss decreased (1.147715 --> 1.141747).  Saving model ...
Validation loss decreased (1.141747 --> 1.136390).  Saving model ...
Validation loss decreased (1.136390 --> 1.132537).  Saving model ...
Validation loss decreased (1.132537 --> 1.129791).  Saving model ...
Validation loss decreased (1.129791 --> 1.125297).  Saving model ...
Validation loss decreased (1.125297 --> 1.119706).  Saving model ...
Validation loss decreased (1.119706 --> 1.115947).  Saving model ...
Validation loss decreased (1.115947 --> 1.112026).  Saving model ...
Validation loss decreased (1.112026 --> 1.108187).  Saving model ...
Validation loss decreased (1.108187 --> 1.104561).  Saving model ...
Validation loss decreased (1.104561 --> 1.101356).  Saving model ...
Validation loss decreased (1.101356 --> 1.097805).  Saving model ...
Validation loss decreased (1.097805 --> 1.093571).  Saving model ...
Validation loss decreased (1.093571 --> 1.090403).  Saving model ...
Validation loss decreased (1.090403 --> 1.085975).  Saving model ...
Validation loss decreased (1.085975 --> 1.081606).  Saving model ...
Validation loss decreased (1.081606 --> 1.079563).  Saving model ...
Validation loss decreased (1.079563 --> 1.076908).  Saving model ...
Validation loss decreased (1.076908 --> 1.074441).  Saving model ...
Validation loss decreased (1.074441 --> 1.071914).  Saving model ...
Validation loss decreased (1.071914 --> 1.070790).  Saving model ...
Validation loss decreased (1.070790 --> 1.067180).  Saving model ...
Validation loss decreased (1.067180 --> 1.066254).  Saving model ...
EarlyStopping counter: 1 out of 10.0
Validation loss decreased (1.066254 --> 1.062766).  Saving model ...
Validation loss decreased (1.062766 --> 1.058385).  Saving model ...
Validation loss decreased (1.058385 --> 1.053985).  Saving model ...
Validation loss decreased (1.053985 --> 1.051032).  Saving model ...
Validation loss decreased (1.051032 --> 1.048309).  Saving model ...
Validation loss decreased (1.048309 --> 1.045908).  Saving model ...
Validation loss decreased (1.045908 --> 1.043079).  Saving model ...
Validation loss decreased (1.043079 --> 1.041069).  Saving model ...
Validation loss decreased (1.041069 --> 1.037812).  Saving model ...
Validation loss decreased (1.037812 --> 1.034997).  Saving model ...
Validation loss decreased (1.034997 --> 1.033908).  Saving model ...
Validation loss decreased (1.033908 --> 1.033873).  Saving model ...
Validation loss decreased (1.033873 --> 1.031688).  Saving model ...
Validation loss decreased (1.031688 --> 1.029954).  Saving model ...
Validation loss decreased (1.029954 --> 1.027981).  Saving model ...
Validation loss decreased (1.027981 --> 1.025696).  Saving model ...
Validation loss decreased (1.025696 --> 1.022634).  Saving model ...
EarlyStopping counter: 1 out of 10.0
Validation loss decreased (1.022634 --> 1.018222).  Saving model ...
EarlyStopping counter: 1 out of 10.0
EarlyStopping counter: 2 out of 10.0
Validation loss decreased (1.018222 --> 1.017211).  Saving model ...
Validation loss decreased (1.017211 --> 1.015339).  Saving model ...
Validation loss decreased (1.015339 --> 1.014022).  Saving model ...
Validation loss decreased (1.014022 --> 1.012307).  Saving model ...
Validation loss decreased (1.012307 --> 1.012257).  Saving model ...
Validation loss decreased (1.012257 --> 1.008784).  Saving model ...
EarlyStopping counter: 1 out of 10.0
EarlyStopping counter: 2 out of 10.0
Validation loss decreased (1.008784 --> 1.006578).  Saving model ...
EarlyStopping counter: 1 out of 10.0
Validation loss decreased (1.006578 --> 1.005346).  Saving model ...
Validation loss decreased (1.005346 --> 1.001798).  Saving model ...
EarlyStopping counter: 1 out of 10.0
EarlyStopping counter: 2 out of 10.0
EarlyStopping counter: 3 out of 10.0
Validation loss decreased (1.001798 --> 1.000089).  Saving model ...
EarlyStopping counter: 1 out of 10.0
Validation loss decreased (1.000089 --> 0.996657).  Saving model ...
Validation loss decreased (0.996657 --> 0.996359).  Saving model ...
Validation loss decreased (0.996359 --> 0.996200).  Saving model ...
Validation loss decreased (0.996200 --> 0.995227).  Saving model ...
Validation loss decreased (0.995227 --> 0.994167).  Saving model ...
EarlyStopping counter: 1 out of 10.0
EarlyStopping counter: 2 out of 10.0
Validation loss decreased (0.994167 --> 0.993598).  Saving model ...
Validation loss decreased (0.993598 --> 0.990643).  Saving model ...
EarlyStopping counter: 1 out of 10.0
EarlyStopping counter: 2 out of 10.0
Validation loss decreased (0.990643 --> 0.985625).  Saving model ...
EarlyStopping counter: 1 out of 10.0
EarlyStopping counter: 2 out of 10.0
EarlyStopping counter: 3 out of 10.0
EarlyStopping counter: 4 out of 10.0
EarlyStopping counter: 5 out of 10.0
EarlyStopping counter: 6 out of 10.0
EarlyStopping counter: 7 out of 10.0
EarlyStopping counter: 8 out of 10.0
EarlyStopping counter: 9 out of 10.0
Validation loss decreased (0.985625 --> 0.983667).  Saving model ...
EarlyStopping counter: 1 out of 10.0
EarlyStopping counter: 2 out of 10.0
EarlyStopping counter: 3 out of 10.0
EarlyStopping counter: 4 out of 10.0
EarlyStopping counter: 5 out of 10.0
EarlyStopping counter: 6 out of 10.0
EarlyStopping counter: 7 out of 10.0
EarlyStopping counter: 8 out of 10.0
EarlyStopping counter: 9 out of 10.0
EarlyStopping counter: 10 out of 10.0
/localscratch/yinan.29019353.0/env/lib/python3.7/site-packages/torch/nn/functional.py:1794: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.
  warnings.warn("nn.functional.tanh is deprecated. Use torch.tanh instead.")
wandb: Waiting for W&B process to finish, PID 74709... (success).
wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: \ 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: | 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: / 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: \ 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: | 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: / 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: \ 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: | 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: / 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb:                                                                                
wandb: Run history:
wandb:     e_F1 ▁▁▃▅▄▅▅▆▆▆▇▇▇▇▇▇▇▇▇▇▇███████████████████
wandb:   e_loss ██▇▇▇▆▆▅▅▅▄▄▄▃▃▃▃▃▂▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:     t_F1 ▁▁▂▃▃▃▃▄▄▅▅▅▅▅▆▆▆▆▆▇▆▆▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇███
wandb:   t_loss ███▇▇▇▇▆▆▆▆▅▅▅▅▅▄▄▄▃▄▄▃▃▃▃▃▃▂▂▂▂▂▂▂▂▁▁▁▁
wandb: 
wandb: Run summary:
wandb:     e_F1 58.61266
wandb:   e_loss 0.98595
wandb:     t_F1 71.54351
wandb:   t_loss 0.76506
wandb: 
wandb: Synced 4 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Synced floral-vortex-2: https://wandb.ai/yinanazhou/xl_512_bs_8_lr_1e06_es_10_lc_False_nr_True_sr_False_stem_True_lemma_False_repeat_4_fold_2/runs/1ju7nps9
wandb: Find logs at: ./wandb/run-20220319_062329-1ju7nps9/logs/debug.log
wandb: 

wandb: wandb version 0.12.11 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
2022-03-19 07:51:26.543486: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1
wandb: Tracking run with wandb version 0.12.5
wandb: Syncing run gallant-wave-2
wandb: ⭐️ View project at https://wandb.ai/yinanazhou/xl_512_bs_8_lr_1e06_es_10_lc_False_nr_True_sr_False_stem_True_lemma_False_repeat_5_fold_1
wandb: 🚀 View run at https://wandb.ai/yinanazhou/xl_512_bs_8_lr_1e06_es_10_lc_False_nr_True_sr_False_stem_True_lemma_False_repeat_5_fold_1/runs/pit3qd5s
wandb: Run data is saved locally in /project/6002780/yinan/Thesis_MER_Lyrics/lyric-emotion/wandb/run-20220319_075123-pit3qd5s
wandb: Run `wandb offline` to turn off syncing.

Validation loss decreased (inf --> 1.469796).  Saving model ...
Validation loss decreased (1.469796 --> 1.432163).  Saving model ...
Validation loss decreased (1.432163 --> 1.407617).  Saving model ...
Validation loss decreased (1.407617 --> 1.389725).  Saving model ...
Validation loss decreased (1.389725 --> 1.378466).  Saving model ...
Validation loss decreased (1.378466 --> 1.370595).  Saving model ...
Validation loss decreased (1.370595 --> 1.365042).  Saving model ...
Validation loss decreased (1.365042 --> 1.360672).  Saving model ...
Validation loss decreased (1.360672 --> 1.356021).  Saving model ...
Validation loss decreased (1.356021 --> 1.352226).  Saving model ...
Validation loss decreased (1.352226 --> 1.348403).  Saving model ...
Validation loss decreased (1.348403 --> 1.344276).  Saving model ...
Validation loss decreased (1.344276 --> 1.340427).  Saving model ...
Validation loss decreased (1.340427 --> 1.336823).  Saving model ...
Validation loss decreased (1.336823 --> 1.331922).  Saving model ...
Validation loss decreased (1.331922 --> 1.326941).  Saving model ...
Validation loss decreased (1.326941 --> 1.322759).  Saving model ...
Validation loss decreased (1.322759 --> 1.317984).  Saving model ...
Validation loss decreased (1.317984 --> 1.313321).  Saving model ...
Validation loss decreased (1.313321 --> 1.307472).  Saving model ...
Validation loss decreased (1.307472 --> 1.301952).  Saving model ...
Validation loss decreased (1.301952 --> 1.295718).  Saving model ...
Validation loss decreased (1.295718 --> 1.289640).  Saving model ...
Validation loss decreased (1.289640 --> 1.283746).  Saving model ...
Validation loss decreased (1.283746 --> 1.278371).  Saving model ...
Validation loss decreased (1.278371 --> 1.272056).  Saving model ...
Validation loss decreased (1.272056 --> 1.266276).  Saving model ...
Validation loss decreased (1.266276 --> 1.259152).  Saving model ...
Validation loss decreased (1.259152 --> 1.252461).  Saving model ...
Validation loss decreased (1.252461 --> 1.246736).  Saving model ...
Validation loss decreased (1.246736 --> 1.241183).  Saving model ...
Validation loss decreased (1.241183 --> 1.234203).  Saving model ...
Validation loss decreased (1.234203 --> 1.228489).  Saving model ...
Validation loss decreased (1.228489 --> 1.222336).  Saving model ...
Validation loss decreased (1.222336 --> 1.215161).  Saving model ...
Validation loss decreased (1.215161 --> 1.210451).  Saving model ...
Validation loss decreased (1.210451 --> 1.205388).  Saving model ...
Validation loss decreased (1.205388 --> 1.199039).  Saving model ...
Validation loss decreased (1.199039 --> 1.193175).  Saving model ...
Validation loss decreased (1.193175 --> 1.188690).  Saving model ...
Validation loss decreased (1.188690 --> 1.182619).  Saving model ...
Validation loss decreased (1.182619 --> 1.176647).  Saving model ...
Validation loss decreased (1.176647 --> 1.170719).  Saving model ...
Validation loss decreased (1.170719 --> 1.166483).  Saving model ...
Validation loss decreased (1.166483 --> 1.162269).  Saving model ...
Validation loss decreased (1.162269 --> 1.158076).  Saving model ...
Validation loss decreased (1.158076 --> 1.153674).  Saving model ...
Validation loss decreased (1.153674 --> 1.149062).  Saving model ...
Validation loss decreased (1.149062 --> 1.143680).  Saving model ...
Validation loss decreased (1.143680 --> 1.137926).  Saving model ...
Validation loss decreased (1.137926 --> 1.134594).  Saving model ...
Validation loss decreased (1.134594 --> 1.130468).  Saving model ...
Validation loss decreased (1.130468 --> 1.126751).  Saving model ...
Validation loss decreased (1.126751 --> 1.121634).  Saving model ...
Validation loss decreased (1.121634 --> 1.114638).  Saving model ...
Validation loss decreased (1.114638 --> 1.111208).  Saving model ...
Validation loss decreased (1.111208 --> 1.109573).  Saving model ...
Validation loss decreased (1.109573 --> 1.105810).  Saving model ...
Validation loss decreased (1.105810 --> 1.101235).  Saving model ...
Validation loss decreased (1.101235 --> 1.098756).  Saving model ...
Validation loss decreased (1.098756 --> 1.093824).  Saving model ...
Validation loss decreased (1.093824 --> 1.086562).  Saving model ...
Validation loss decreased (1.086562 --> 1.082352).  Saving model ...
Validation loss decreased (1.082352 --> 1.079910).  Saving model ...
Validation loss decreased (1.079910 --> 1.075392).  Saving model ...
Validation loss decreased (1.075392 --> 1.071824).  Saving model ...
EarlyStopping counter: 1 out of 10.0
Validation loss decreased (1.071824 --> 1.067594).  Saving model ...
Validation loss decreased (1.067594 --> 1.064277).  Saving model ...
Validation loss decreased (1.064277 --> 1.056188).  Saving model ...
Validation loss decreased (1.056188 --> 1.052586).  Saving model ...
Validation loss decreased (1.052586 --> 1.050345).  Saving model ...
Validation loss decreased (1.050345 --> 1.049421).  Saving model ...
Validation loss decreased (1.049421 --> 1.047649).  Saving model ...
Validation loss decreased (1.047649 --> 1.047285).  Saving model ...
Validation loss decreased (1.047285 --> 1.043417).  Saving model ...
Validation loss decreased (1.043417 --> 1.039258).  Saving model ...
Validation loss decreased (1.039258 --> 1.035618).  Saving model ...
Validation loss decreased (1.035618 --> 1.034531).  Saving model ...
Validation loss decreased (1.034531 --> 1.031100).  Saving model ...
Validation loss decreased (1.031100 --> 1.028698).  Saving model ...
Validation loss decreased (1.028698 --> 1.027067).  Saving model ...
Validation loss decreased (1.027067 --> 1.023487).  Saving model ...
Validation loss decreased (1.023487 --> 1.020071).  Saving model ...
EarlyStopping counter: 1 out of 10.0
Validation loss decreased (1.020071 --> 1.017398).  Saving model ...
Validation loss decreased (1.017398 --> 1.015918).  Saving model ...
Validation loss decreased (1.015918 --> 1.012272).  Saving model ...
Validation loss decreased (1.012272 --> 1.010555).  Saving model ...
Validation loss decreased (1.010555 --> 1.009002).  Saving model ...
Validation loss decreased (1.009002 --> 1.007378).  Saving model ...
Validation loss decreased (1.007378 --> 1.005994).  Saving model ...
Validation loss decreased (1.005994 --> 1.002658).  Saving model ...
Validation loss decreased (1.002658 --> 1.000784).  Saving model ...
Validation loss decreased (1.000784 --> 0.997848).  Saving model ...
Validation loss decreased (0.997848 --> 0.995792).  Saving model ...
Validation loss decreased (0.995792 --> 0.995572).  Saving model ...
Validation loss decreased (0.995572 --> 0.993208).  Saving model ...
Validation loss decreased (0.993208 --> 0.992232).  Saving model ...
Validation loss decreased (0.992232 --> 0.990917).  Saving model ...
Validation loss decreased (0.990917 --> 0.987918).  Saving model ...
Validation loss decreased (0.987918 --> 0.987397).  Saving model ...
EarlyStopping counter: 1 out of 10.0
Validation loss decreased (0.987397 --> 0.985176).  Saving model ...
Validation loss decreased (0.985176 --> 0.984185).  Saving model ...
Validation loss decreased (0.984185 --> 0.982716).  Saving model ...
Validation loss decreased (0.982716 --> 0.980448).  Saving model ...
Validation loss decreased (0.980448 --> 0.978251).  Saving model ...
Validation loss decreased (0.978251 --> 0.976692).  Saving model ...
Validation loss decreased (0.976692 --> 0.975356).  Saving model ...
EarlyStopping counter: 1 out of 10.0
EarlyStopping counter: 2 out of 10.0
Validation loss decreased (0.975356 --> 0.974312).  Saving model ...
EarlyStopping counter: 1 out of 10.0
Validation loss decreased (0.974312 --> 0.973138).  Saving model ...
Validation loss decreased (0.973138 --> 0.971567).  Saving model ...
Validation loss decreased (0.971567 --> 0.970357).  Saving model ...
Validation loss decreased (0.970357 --> 0.969360).  Saving model ...
Validation loss decreased (0.969360 --> 0.968517).  Saving model ...
Validation loss decreased (0.968517 --> 0.967912).  Saving model ...
Validation loss decreased (0.967912 --> 0.966512).  Saving model ...
Validation loss decreased (0.966512 --> 0.965157).  Saving model ...
Validation loss decreased (0.965157 --> 0.963989).  Saving model ...
Validation loss decreased (0.963989 --> 0.963031).  Saving model ...
Validation loss decreased (0.963031 --> 0.962351).  Saving model ...
EarlyStopping counter: 1 out of 10.0
EarlyStopping counter: 2 out of 10.0
EarlyStopping counter: 3 out of 10.0
Validation loss decreased (0.962351 --> 0.961453).  Saving model ...
EarlyStopping counter: 1 out of 10.0
Validation loss decreased (0.961453 --> 0.960050).  Saving model ...
Validation loss decreased (0.960050 --> 0.959786).  Saving model ...
EarlyStopping counter: 1 out of 10.0
Validation loss decreased (0.959786 --> 0.959499).  Saving model ...
EarlyStopping counter: 1 out of 10.0
EarlyStopping counter: 2 out of 10.0
EarlyStopping counter: 3 out of 10.0
EarlyStopping counter: 4 out of 10.0
EarlyStopping counter: 5 out of 10.0
EarlyStopping counter: 6 out of 10.0
EarlyStopping counter: 7 out of 10.0
EarlyStopping counter: 8 out of 10.0
EarlyStopping counter: 9 out of 10.0
EarlyStopping counter: 10 out of 10.0
/localscratch/yinan.29019353.0/env/lib/python3.7/site-packages/torch/nn/functional.py:1794: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.
  warnings.warn("nn.functional.tanh is deprecated. Use torch.tanh instead.")
wandb: Waiting for W&B process to finish, PID 79430... (success).
wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: \ 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: | 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: / 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: \ 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: | 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: / 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: \ 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: | 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: / 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb:                                                                                
wandb: Run history:
wandb:     e_F1 ▁▂▄▄▄▅▅▆▆▆▆▆▆▆▆▇▇▇▇▇▇▇█▇████████████████
wandb:   e_loss █▇▇▇▆▆▆▆▅▅▅▄▄▄▄▃▃▃▃▂▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:     t_F1 ▁▁▃▃▃▄▃▄▄▄▅▅▅▆▆▆▅▆▆▆▆▆▇▇▇▆▇▇▇▇▇▇█████▇██
wandb:   t_loss ██▇▇▇▇▇▆▆▆▅▅▅▅▅▅▄▄▄▄▄▄▃▃▃▃▃▃▂▂▂▂▂▂▂▂▁▁▁▁
wandb: 
wandb: Run summary:
wandb:     e_F1 57.51055
wandb:   e_loss 0.96072
wandb:     t_F1 72.13798
wandb:   t_loss 0.75124
wandb: 
wandb: Synced 4 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Synced gallant-wave-2: https://wandb.ai/yinanazhou/xl_512_bs_8_lr_1e06_es_10_lc_False_nr_True_sr_False_stem_True_lemma_False_repeat_5_fold_1/runs/pit3qd5s
wandb: Find logs at: ./wandb/run-20220319_075123-pit3qd5s/logs/debug.log
wandb: 

wandb: wandb version 0.12.11 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
2022-03-19 09:21:05.645006: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1
wandb: Tracking run with wandb version 0.12.5
wandb: Syncing run silvery-bee-2
wandb: ⭐️ View project at https://wandb.ai/yinanazhou/xl_512_bs_8_lr_1e06_es_10_lc_False_nr_True_sr_False_stem_True_lemma_False_repeat_5_fold_2
wandb: 🚀 View run at https://wandb.ai/yinanazhou/xl_512_bs_8_lr_1e06_es_10_lc_False_nr_True_sr_False_stem_True_lemma_False_repeat_5_fold_2/runs/2nle905a
wandb: Run data is saved locally in /project/6002780/yinan/Thesis_MER_Lyrics/lyric-emotion/wandb/run-20220319_092102-2nle905a
wandb: Run `wandb offline` to turn off syncing.

Validation loss decreased (inf --> 1.393237).  Saving model ...
Validation loss decreased (1.393237 --> 1.383530).  Saving model ...
Validation loss decreased (1.383530 --> 1.375728).  Saving model ...
Validation loss decreased (1.375728 --> 1.369487).  Saving model ...
Validation loss decreased (1.369487 --> 1.363958).  Saving model ...
Validation loss decreased (1.363958 --> 1.359005).  Saving model ...
Validation loss decreased (1.359005 --> 1.354130).  Saving model ...
Validation loss decreased (1.354130 --> 1.349161).  Saving model ...
Validation loss decreased (1.349161 --> 1.344609).  Saving model ...
Validation loss decreased (1.344609 --> 1.339931).  Saving model ...
Validation loss decreased (1.339931 --> 1.335184).  Saving model ...
Validation loss decreased (1.335184 --> 1.330375).  Saving model ...
Validation loss decreased (1.330375 --> 1.325431).  Saving model ...
Validation loss decreased (1.325431 --> 1.320324).  Saving model ...
Validation loss decreased (1.320324 --> 1.315758).  Saving model ...
Validation loss decreased (1.315758 --> 1.310553).  Saving model ...
Validation loss decreased (1.310553 --> 1.305654).  Saving model ...
Validation loss decreased (1.305654 --> 1.300595).  Saving model ...
Validation loss decreased (1.300595 --> 1.295635).  Saving model ...
Validation loss decreased (1.295635 --> 1.289663).  Saving model ...
Validation loss decreased (1.289663 --> 1.283983).  Saving model ...
Validation loss decreased (1.283983 --> 1.277722).  Saving model ...
Validation loss decreased (1.277722 --> 1.271777).  Saving model ...
Validation loss decreased (1.271777 --> 1.265270).  Saving model ...
Validation loss decreased (1.265270 --> 1.260120).  Saving model ...
Validation loss decreased (1.260120 --> 1.253791).  Saving model ...
Validation loss decreased (1.253791 --> 1.248750).  Saving model ...
Validation loss decreased (1.248750 --> 1.243445).  Saving model ...
Validation loss decreased (1.243445 --> 1.237293).  Saving model ...
Validation loss decreased (1.237293 --> 1.232036).  Saving model ...
Validation loss decreased (1.232036 --> 1.226230).  Saving model ...
Validation loss decreased (1.226230 --> 1.221861).  Saving model ...
Validation loss decreased (1.221861 --> 1.216304).  Saving model ...
Validation loss decreased (1.216304 --> 1.211808).  Saving model ...
Validation loss decreased (1.211808 --> 1.205542).  Saving model ...
Validation loss decreased (1.205542 --> 1.199869).  Saving model ...
Validation loss decreased (1.199869 --> 1.194477).  Saving model ...
Validation loss decreased (1.194477 --> 1.188759).  Saving model ...
Validation loss decreased (1.188759 --> 1.182805).  Saving model ...
Validation loss decreased (1.182805 --> 1.178299).  Saving model ...
Validation loss decreased (1.178299 --> 1.173457).  Saving model ...
Validation loss decreased (1.173457 --> 1.168788).  Saving model ...
Validation loss decreased (1.168788 --> 1.164515).  Saving model ...
Validation loss decreased (1.164515 --> 1.159352).  Saving model ...
Validation loss decreased (1.159352 --> 1.154372).  Saving model ...
Validation loss decreased (1.154372 --> 1.148915).  Saving model ...
Validation loss decreased (1.148915 --> 1.144809).  Saving model ...
Validation loss decreased (1.144809 --> 1.141443).  Saving model ...
Validation loss decreased (1.141443 --> 1.138674).  Saving model ...
Validation loss decreased (1.138674 --> 1.134591).  Saving model ...
Validation loss decreased (1.134591 --> 1.131376).  Saving model ...
Validation loss decreased (1.131376 --> 1.125920).  Saving model ...
Validation loss decreased (1.125920 --> 1.121703).  Saving model ...
Validation loss decreased (1.121703 --> 1.118609).  Saving model ...
Validation loss decreased (1.118609 --> 1.114697).  Saving model ...
Validation loss decreased (1.114697 --> 1.110440).  Saving model ...
Validation loss decreased (1.110440 --> 1.105599).  Saving model ...
Validation loss decreased (1.105599 --> 1.102313).  Saving model ...
Validation loss decreased (1.102313 --> 1.097668).  Saving model ...
Validation loss decreased (1.097668 --> 1.095317).  Saving model ...
Validation loss decreased (1.095317 --> 1.093195).  Saving model ...
Validation loss decreased (1.093195 --> 1.090634).  Saving model ...
Validation loss decreased (1.090634 --> 1.086130).  Saving model ...
Validation loss decreased (1.086130 --> 1.083644).  Saving model ...
Validation loss decreased (1.083644 --> 1.079797).  Saving model ...
Validation loss decreased (1.079797 --> 1.077070).  Saving model ...
Validation loss decreased (1.077070 --> 1.074126).  Saving model ...
Validation loss decreased (1.074126 --> 1.071381).  Saving model ...
Validation loss decreased (1.071381 --> 1.068982).  Saving model ...
Validation loss decreased (1.068982 --> 1.066449).  Saving model ...
Validation loss decreased (1.066449 --> 1.062750).  Saving model ...
Validation loss decreased (1.062750 --> 1.060379).  Saving model ...
Validation loss decreased (1.060379 --> 1.058322).  Saving model ...
Validation loss decreased (1.058322 --> 1.057490).  Saving model ...
Validation loss decreased (1.057490 --> 1.054356).  Saving model ...
Validation loss decreased (1.054356 --> 1.051596).  Saving model ...
Validation loss decreased (1.051596 --> 1.049812).  Saving model ...
Validation loss decreased (1.049812 --> 1.046229).  Saving model ...
Validation loss decreased (1.046229 --> 1.044738).  Saving model ...
Validation loss decreased (1.044738 --> 1.042441).  Saving model ...
Validation loss decreased (1.042441 --> 1.040641).  Saving model ...
Validation loss decreased (1.040641 --> 1.037543).  Saving model ...
Validation loss decreased (1.037543 --> 1.035568).  Saving model ...
Validation loss decreased (1.035568 --> 1.034534).  Saving model ...
Validation loss decreased (1.034534 --> 1.031563).  Saving model ...
Validation loss decreased (1.031563 --> 1.029265).  Saving model ...
Validation loss decreased (1.029265 --> 1.026637).  Saving model ...
EarlyStopping counter: 1 out of 10.0
EarlyStopping counter: 2 out of 10.0
Validation loss decreased (1.026637 --> 1.025077).  Saving model ...
Validation loss decreased (1.025077 --> 1.024689).  Saving model ...
Validation loss decreased (1.024689 --> 1.023971).  Saving model ...
EarlyStopping counter: 1 out of 10.0
Validation loss decreased (1.023971 --> 1.021329).  Saving model ...
Validation loss decreased (1.021329 --> 1.019392).  Saving model ...
Validation loss decreased (1.019392 --> 1.016714).  Saving model ...
Validation loss decreased (1.016714 --> 1.016429).  Saving model ...
EarlyStopping counter: 1 out of 10.0
EarlyStopping counter: 2 out of 10.0
Validation loss decreased (1.016429 --> 1.013635).  Saving model ...
Validation loss decreased (1.013635 --> 1.012867).  Saving model ...
Validation loss decreased (1.012867 --> 1.010665).  Saving model ...
EarlyStopping counter: 1 out of 10.0
Validation loss decreased (1.010665 --> 1.008101).  Saving model ...
Validation loss decreased (1.008101 --> 1.007402).  Saving model ...
EarlyStopping counter: 1 out of 10.0
Validation loss decreased (1.007402 --> 1.005591).  Saving model ...
Validation loss decreased (1.005591 --> 1.004028).  Saving model ...
Validation loss decreased (1.004028 --> 1.003146).  Saving model ...
EarlyStopping counter: 1 out of 10.0
Validation loss decreased (1.003146 --> 1.000974).  Saving model ...
Validation loss decreased (1.000974 --> 1.000581).  Saving model ...
Validation loss decreased (1.000581 --> 0.999821).  Saving model ...
Validation loss decreased (0.999821 --> 0.999494).  Saving model ...
Validation loss decreased (0.999494 --> 0.997646).  Saving model ...
Validation loss decreased (0.997646 --> 0.995787).  Saving model ...
Validation loss decreased (0.995787 --> 0.995548).  Saving model ...
Validation loss decreased (0.995548 --> 0.995105).  Saving model ...
Validation loss decreased (0.995105 --> 0.993588).  Saving model ...
Validation loss decreased (0.993588 --> 0.993543).  Saving model ...
EarlyStopping counter: 1 out of 10.0
Validation loss decreased (0.993543 --> 0.992695).  Saving model ...
EarlyStopping counter: 1 out of 10.0
Validation loss decreased (0.992695 --> 0.992388).  Saving model ...
Validation loss decreased (0.992388 --> 0.991904).  Saving model ...
EarlyStopping counter: 1 out of 10.0
Validation loss decreased (0.991904 --> 0.988708).  Saving model ...
Validation loss decreased (0.988708 --> 0.986952).  Saving model ...
Validation loss decreased (0.986952 --> 0.986543).  Saving model ...
Validation loss decreased (0.986543 --> 0.986112).  Saving model ...
EarlyStopping counter: 1 out of 10.0
EarlyStopping counter: 2 out of 10.0
EarlyStopping counter: 3 out of 10.0
Validation loss decreased (0.986112 --> 0.985307).  Saving model ...
EarlyStopping counter: 1 out of 10.0
EarlyStopping counter: 2 out of 10.0
EarlyStopping counter: 3 out of 10.0
EarlyStopping counter: 4 out of 10.0
EarlyStopping counter: 5 out of 10.0
EarlyStopping counter: 6 out of 10.0
EarlyStopping counter: 7 out of 10.0
EarlyStopping counter: 8 out of 10.0
EarlyStopping counter: 9 out of 10.0
EarlyStopping counter: 10 out of 10.0
/localscratch/yinan.29019353.0/env/lib/python3.7/site-packages/torch/nn/functional.py:1794: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.
  warnings.warn("nn.functional.tanh is deprecated. Use torch.tanh instead.")
wandb: Waiting for W&B process to finish, PID 84331... (success).
wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: \ 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: | 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: / 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: \ 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: | 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: / 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: \ 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: | 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: / 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb:                                                                                
wandb: Run history:
wandb:     e_F1 ▁▂▄▄▅▅▅▆▆▆▆▇▇▇▇▇▇▇▇▇▇▇▇▇▇█▇█████████████
wandb:   e_loss ██▇▇▇▆▆▆▅▅▅▄▄▄▃▃▃▃▃▂▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:     t_F1 ▁▂▂▂▃▄▄▄▄▅▄▅▆▆▆▆▆▆▆▆▇▇▇▆▇▇▆▇▇▇▇▇▇█▇█████
wandb:   t_loss ███▇▇▇▇▆▆▆▆▅▅▅▅▄▄▄▄▄▃▃▃▃▃▃▃▂▃▂▂▂▂▂▂▁▁▁▂▁
wandb: 
wandb: Run summary:
wandb:     e_F1 58.43687
wandb:   e_loss 0.98777
wandb:     t_F1 71.02454
wandb:   t_loss 0.7436
wandb: 
wandb: Synced 4 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Synced silvery-bee-2: https://wandb.ai/yinanazhou/xl_512_bs_8_lr_1e06_es_10_lc_False_nr_True_sr_False_stem_True_lemma_False_repeat_5_fold_2/runs/2nle905a
wandb: Find logs at: ./wandb/run-20220319_092102-2nle905a/logs/debug.log
wandb: 

