Unloading StdEnv/2020

Due to MODULEPATH changes, the following have been reloaded:
  1) mii/1.1.1


The following have been reloaded with a version change:
  1) python/3.8.2 => python/3.7.4

Using base prefix '/cvmfs/soft.computecanada.ca/easybuild/software/2017/Core/python/3.7.4'
New python executable in /localscratch/yinan.29351703.0/env/bin/python
Installing setuptools, pip, wheel...
done.
Ignoring pip: markers 'python_version < "3"' don't match your environment
Looking in links: /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/nix/avx2, /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/nix/generic, /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic
Collecting pip
Installing collected packages: pip
  Found existing installation: pip 19.1.1
    Uninstalling pip-19.1.1:
      Successfully uninstalled pip-19.1.1
Successfully installed pip-21.2.3+computecanada
Looking in links: /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/nix/avx2, /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/nix/generic, /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/keras-2.8.0+computecanada-py2.py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/Keras_Preprocessing-1.1.2+computecanada-py3-none-any.whl
Requirement already satisfied: matplotlib in /cvmfs/soft.computecanada.ca/easybuild/software/2017/Core/scipy-stack/2019a/lib/python3.7/site-packages (from -r requirements.txt (line 3)) (3.0.2)
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/nltk-3.6.5+computecanada-py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/scikit_learn-0.22.1+computecanada-cp37-cp37m-linux_x86_64.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/tensorboard-2.3.0+computecanada-py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/tensorboard_plugin_wit-1.7.0+computecanada-py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/tensorflow_gpu-2.3.0+computecanada-cp37-cp37m-linux_x86_64.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/tensorflow_estimator-2.3.0+computecanada-py2.py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/tokenizers-0.5.2+computecanada-cp37-cp37m-linux_x86_64.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/nix/avx2/torch-1.4.0+computecanada-cp37-cp37m-linux_x86_64.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/torchtext-0.6.0+computecanada-py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/torchvision-0.8.2+computecanada-cp37-cp37m-linux_x86_64.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/transformers-2.5.1+computecanada-py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/urllib3-1.26.7+computecanada-py2.py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/click-8.0.4+computecanada-py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/tqdm-4.63.1+computecanada-py2.py3-none-any.whl
ERROR: Could not find a version that satisfies the requirement regex>=2021.8.3 (from nltk) (from versions: 2018.1.10+computecanada, 2019.11.1+computecanada, 2020.11.13+computecanada)
ERROR: No matching distribution found for regex>=2021.8.3
Looking in links: /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/nix/avx2, /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/nix/generic, /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic
ERROR: Could not find a version that satisfies the requirement numpy==1.20.0+computacanada (from versions: 1.15.0+computecanada, 1.15.2+computecanada, 1.15.4+computecanada, 1.16.0+computecanada, 1.16.2+computecanada, 1.16.3+computecanada, 1.17.4+computecanada, 1.18.1+computecanada, 1.18.4+computecanada, 1.19.1+computecanada, 1.19.2+computecanada, 1.20.2+computecanada)
ERROR: No matching distribution found for numpy==1.20.0+computacanada
Looking in links: /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/nix/avx2, /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/nix/generic, /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/wandb-0.12.5+computecanada-py2.py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/subprocess32-3.5.4+computecanada-py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/sentry_sdk-1.5.0+computecanada-py2.py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/PyYAML-5.3.1+computecanada-cp37-cp37m-linux_x86_64.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/click-8.0.4+computecanada-py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/promise-2.3+computecanada-py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/protobuf-3.19.4+computecanada-py2.py3-none-any.whl
Requirement already satisfied: requests<3,>=2.0.0 in /cvmfs/soft.computecanada.ca/easybuild/software/2017/Core/scipy-stack/2019a/lib/python3.7/site-packages (from wandb) (2.21.0)
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/configparser-5.0.2+computecanada-py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/yaspin-2.1.0+computecanada-py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/psutil-5.7.3+computecanada-cp37-cp37m-linux_x86_64.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/six-1.16.0+computecanada-py2.py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/pathtools-0.1.2+computecanada-py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/docker_pycreds-0.4.0+computecanada-py2.py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/shortuuid-1.0.1+computecanada-py3-none-any.whl
Requirement already satisfied: python-dateutil>=2.6.1 in /cvmfs/soft.computecanada.ca/easybuild/software/2017/Core/scipy-stack/2019a/lib/python3.7/site-packages (from wandb) (2.7.5)
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/GitPython-3.1.24+computecanada-py3-none-any.whl
Requirement already satisfied: importlib-metadata in /cvmfs/soft.computecanada.ca/easybuild/software/2017/Core/scipy-stack/2019a/lib/python3.7/site-packages (from Click!=8.0.0,>=7.0->wandb) (0.8)
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/gitdb-4.0.9+computecanada-py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/typing_extensions-4.1.1+computecanada-py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/smmap-5.0.0+computecanada-py3-none-any.whl
Requirement already satisfied: idna<2.9,>=2.5 in /cvmfs/soft.computecanada.ca/easybuild/software/2017/Core/scipy-stack/2019a/lib/python3.7/site-packages (from requests<3,>=2.0.0->wandb) (2.8)
Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /cvmfs/soft.computecanada.ca/easybuild/software/2017/Core/scipy-stack/2019a/lib/python3.7/site-packages (from requests<3,>=2.0.0->wandb) (3.0.4)
Requirement already satisfied: urllib3<1.25,>=1.21.1 in /cvmfs/soft.computecanada.ca/easybuild/software/2017/Core/scipy-stack/2019a/lib/python3.7/site-packages (from requests<3,>=2.0.0->wandb) (1.24.1)
Requirement already satisfied: certifi>=2017.4.17 in /cvmfs/soft.computecanada.ca/easybuild/software/2017/Core/scipy-stack/2019a/lib/python3.7/site-packages (from requests<3,>=2.0.0->wandb) (2018.11.29)
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/termcolor-1.1.0+computecanada-py3-none-any.whl
Requirement already satisfied: zipp>=0.3.2 in /cvmfs/soft.computecanada.ca/easybuild/software/2017/Core/scipy-stack/2019a/lib/python3.7/site-packages (from importlib-metadata->Click!=8.0.0,>=7.0->wandb) (0.3.3)
Installing collected packages: smmap, typing-extensions, termcolor, six, gitdb, yaspin, subprocess32, shortuuid, sentry-sdk, PyYAML, psutil, protobuf, promise, pathtools, GitPython, docker-pycreds, configparser, Click, wandb
  Attempting uninstall: six
    Found existing installation: six 1.12.0
    Not uninstalling six at /cvmfs/soft.computecanada.ca/easybuild/software/2017/Core/scipy-stack/2019a/lib/python3.7/site-packages, outside environment /localscratch/yinan.29351703.0/env
    Can't uninstall 'six'. No files were found to uninstall.
Successfully installed Click-8.0.4+computecanada GitPython-3.1.24+computecanada PyYAML-5.3.1+computecanada configparser-5.0.2+computecanada docker-pycreds-0.4.0+computecanada gitdb-4.0.9+computecanada pathtools-0.1.2+computecanada promise-2.3+computecanada protobuf-3.19.4+computecanada psutil-5.7.3+computecanada sentry-sdk-1.5.0+computecanada shortuuid-1.0.1+computecanada six-1.16.0+computecanada smmap-5.0.0+computecanada subprocess32-3.5.4+computecanada termcolor-1.1.0+computecanada typing-extensions-4.1.1+computecanada wandb-0.12.5+computecanada yaspin-2.1.0+computecanada
Looking in links: /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/nix/avx2, /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/nix/generic, /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic
ERROR: Could not find a version that satisfies the requirement sagemaker (from versions: none)
ERROR: No matching distribution found for sagemaker
Looking in links: /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/nix/avx2, /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/nix/generic, /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/torch-1.9.1+computecanada-cp37-cp37m-linux_x86_64.whl
Requirement already satisfied: typing-extensions in /localscratch/yinan.29351703.0/env/lib/python3.7/site-packages (from torch) (4.1.1+computecanada)
Installing collected packages: torch
Successfully installed torch-1.9.1+computecanada
Looking in links: /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/nix/avx2, /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/nix/generic, /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/transformers-2.5.1+computecanada-py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/sacremoses-0.0.49+computecanada-py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/filelock-3.4.2+computecanada-py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/tokenizers-0.5.2+computecanada-cp37-cp37m-linux_x86_64.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/tqdm-4.63.1+computecanada-py2.py3-none-any.whl
Requirement already satisfied: numpy in /cvmfs/soft.computecanada.ca/easybuild/software/2017/Core/scipy-stack/2019a/lib/python3.7/site-packages (from transformers==2.5.1+computecanada) (1.16.0)
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/regex-2020.11.13+computecanada-cp37-cp37m-linux_x86_64.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/boto3-1.21.14+computecanada-py3-none-any.whl
Requirement already satisfied: requests in /cvmfs/soft.computecanada.ca/easybuild/software/2017/Core/scipy-stack/2019a/lib/python3.7/site-packages (from transformers==2.5.1+computecanada) (2.21.0)
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/sentencepiece-0.1.91+computecanada-cp37-cp37m-linux_x86_64.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/jmespath-0.10.0+computecanada-py2.py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/s3transfer-0.5.1+computecanada-py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/botocore-1.24.14+computecanada-py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/urllib3-1.26.8+computecanada-py2.py3-none-any.whl
Requirement already satisfied: python-dateutil<3.0.0,>=2.1 in /cvmfs/soft.computecanada.ca/easybuild/software/2017/Core/scipy-stack/2019a/lib/python3.7/site-packages (from botocore<1.25.0,>=1.24.14->boto3->transformers==2.5.1+computecanada) (2.7.5)
Requirement already satisfied: six>=1.5 in /localscratch/yinan.29351703.0/env/lib/python3.7/site-packages (from python-dateutil<3.0.0,>=2.1->botocore<1.25.0,>=1.24.14->boto3->transformers==2.5.1+computecanada) (1.16.0+computecanada)
Requirement already satisfied: certifi>=2017.4.17 in /cvmfs/soft.computecanada.ca/easybuild/software/2017/Core/scipy-stack/2019a/lib/python3.7/site-packages (from requests->transformers==2.5.1+computecanada) (2018.11.29)
Requirement already satisfied: idna<2.9,>=2.5 in /cvmfs/soft.computecanada.ca/easybuild/software/2017/Core/scipy-stack/2019a/lib/python3.7/site-packages (from requests->transformers==2.5.1+computecanada) (2.8)
Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /cvmfs/soft.computecanada.ca/easybuild/software/2017/Core/scipy-stack/2019a/lib/python3.7/site-packages (from requests->transformers==2.5.1+computecanada) (3.0.4)
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/requests-2.27.1+computecanada-py2.py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/charset_normalizer-2.0.12+computecanada-py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/joblib-1.1.0+computecanada-py2.py3-none-any.whl
Requirement already satisfied: click in /localscratch/yinan.29351703.0/env/lib/python3.7/site-packages (from sacremoses->transformers==2.5.1+computecanada) (8.0.4+computecanada)
Requirement already satisfied: importlib-metadata in /cvmfs/soft.computecanada.ca/easybuild/software/2017/Core/scipy-stack/2019a/lib/python3.7/site-packages (from click->sacremoses->transformers==2.5.1+computecanada) (0.8)
Requirement already satisfied: zipp>=0.3.2 in /cvmfs/soft.computecanada.ca/easybuild/software/2017/Core/scipy-stack/2019a/lib/python3.7/site-packages (from importlib-metadata->click->sacremoses->transformers==2.5.1+computecanada) (0.3.3)
Installing collected packages: urllib3, jmespath, botocore, tqdm, s3transfer, regex, joblib, charset-normalizer, tokenizers, sentencepiece, sacremoses, requests, filelock, boto3, transformers
  Attempting uninstall: urllib3
    Found existing installation: urllib3 1.24.1
    Not uninstalling urllib3 at /cvmfs/soft.computecanada.ca/easybuild/software/2017/Core/scipy-stack/2019a/lib/python3.7/site-packages, outside environment /localscratch/yinan.29351703.0/env
    Can't uninstall 'urllib3'. No files were found to uninstall.
  Attempting uninstall: requests
    Found existing installation: requests 2.21.0
    Not uninstalling requests at /cvmfs/soft.computecanada.ca/easybuild/software/2017/Core/scipy-stack/2019a/lib/python3.7/site-packages, outside environment /localscratch/yinan.29351703.0/env
    Can't uninstall 'requests'. No files were found to uninstall.
Successfully installed boto3-1.21.14+computecanada botocore-1.24.14+computecanada charset-normalizer-2.0.12+computecanada filelock-3.4.2+computecanada jmespath-0.10.0+computecanada joblib-1.1.0+computecanada regex-2020.11.13+computecanada requests-2.27.1+computecanada s3transfer-0.5.1+computecanada sacremoses-0.0.49+computecanada sentencepiece-0.1.91+computecanada tokenizers-0.5.2+computecanada tqdm-4.63.1+computecanada transformers-2.5.1+computecanada urllib3-1.26.8+computecanada
Looking in links: /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/nix/avx2, /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/nix/generic, /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/tensorflow_gpu-2.3.0+computecanada-cp37-cp37m-linux_x86_64.whl
Requirement already satisfied: wheel>=0.26 in /localscratch/yinan.29351703.0/env/lib/python3.7/site-packages (from tensorflow_gpu==2.3.0+computecanada) (0.33.4)
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/gast-0.3.3+computecanada-py3-none-any.whl
Requirement already satisfied: numpy<1.19.0,>=1.16.0 in /cvmfs/soft.computecanada.ca/easybuild/software/2017/Core/scipy-stack/2019a/lib/python3.7/site-packages (from tensorflow_gpu==2.3.0+computecanada) (1.16.0)
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/absl_py-1.0.0+computecanada-py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/nix/generic/scipy-1.4.1+computecanada-cp37-cp37m-linux_x86_64.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/tensorboard-2.8.0+computecanada-py3-none-any.whl
Requirement already satisfied: termcolor>=1.1.0 in /localscratch/yinan.29351703.0/env/lib/python3.7/site-packages (from tensorflow_gpu==2.3.0+computecanada) (1.1.0+computecanada)
Requirement already satisfied: protobuf>=3.9.2 in /localscratch/yinan.29351703.0/env/lib/python3.7/site-packages (from tensorflow_gpu==2.3.0+computecanada) (3.19.4+computecanada)
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/wrapt-1.11.2+computecanada-cp37-cp37m-linux_x86_64.whl
Requirement already satisfied: six>=1.12.0 in /localscratch/yinan.29351703.0/env/lib/python3.7/site-packages (from tensorflow_gpu==2.3.0+computecanada) (1.16.0+computecanada)
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/opt_einsum-3.3.0+computecanada-py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/grpcio-1.38.0+computecanada-cp37-cp37m-linux_x86_64.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/nix/avx2/h5py-2.10.0+computecanada-cp37-cp37m-linux_x86_64.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/google_pasta-0.2.0+computecanada-py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/astunparse-1.6.3+computecanada-py2.py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/Keras_Preprocessing-1.1.2+computecanada-py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/tensorflow_estimator-2.3.0+computecanada-py2.py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/Markdown-3.3.6+computecanada-py3-none-any.whl
Requirement already satisfied: setuptools>=41.0.0 in /localscratch/yinan.29351703.0/env/lib/python3.7/site-packages (from tensorboard<3,>=2.3.0->tensorflow_gpu==2.3.0+computecanada) (41.0.1)
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/google_auth-2.3.3+computecanada-py2.py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/tensorboard_data_server-0.6.1+computecanada-py3-none-linux_x86_64.whl
Requirement already satisfied: requests<3,>=2.21.0 in /localscratch/yinan.29351703.0/env/lib/python3.7/site-packages (from tensorboard<3,>=2.3.0->tensorflow_gpu==2.3.0+computecanada) (2.27.1+computecanada)
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/Werkzeug-2.0.3+computecanada-py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/google_auth_oauthlib-0.4.6+computecanada-py2.py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/tensorboard_plugin_wit-1.8.0+computecanada-py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/rsa-4.8+computecanada-py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/cachetools-4.2.4+computecanada-py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/pyasn1_modules-0.2.8+computecanada-py2.py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/requests_oauthlib-1.3.0+computecanada-py2.py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/importlib_metadata-4.10.1+computecanada-py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/zipp-3.7.0+computecanada-py3-none-any.whl
Requirement already satisfied: typing-extensions>=3.6.4 in /localscratch/yinan.29351703.0/env/lib/python3.7/site-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard<3,>=2.3.0->tensorflow_gpu==2.3.0+computecanada) (4.1.1+computecanada)
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/pyasn1-0.4.8+computecanada-py2.py3-none-any.whl
Requirement already satisfied: charset-normalizer~=2.0.0 in /localscratch/yinan.29351703.0/env/lib/python3.7/site-packages (from requests<3,>=2.21.0->tensorboard<3,>=2.3.0->tensorflow_gpu==2.3.0+computecanada) (2.0.12+computecanada)
Requirement already satisfied: certifi>=2017.4.17 in /cvmfs/soft.computecanada.ca/easybuild/software/2017/Core/scipy-stack/2019a/lib/python3.7/site-packages (from requests<3,>=2.21.0->tensorboard<3,>=2.3.0->tensorflow_gpu==2.3.0+computecanada) (2018.11.29)
Requirement already satisfied: urllib3<1.27,>=1.21.1 in /localscratch/yinan.29351703.0/env/lib/python3.7/site-packages (from requests<3,>=2.21.0->tensorboard<3,>=2.3.0->tensorflow_gpu==2.3.0+computecanada) (1.26.8+computecanada)
Requirement already satisfied: idna<4,>=2.5 in /cvmfs/soft.computecanada.ca/easybuild/software/2017/Core/scipy-stack/2019a/lib/python3.7/site-packages (from requests<3,>=2.21.0->tensorboard<3,>=2.3.0->tensorflow_gpu==2.3.0+computecanada) (2.8)
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/oauthlib-3.1.1+computecanada-py2.py3-none-any.whl
Installing collected packages: pyasn1, zipp, rsa, pyasn1-modules, oauthlib, cachetools, requests-oauthlib, importlib-metadata, google-auth, werkzeug, tensorboard-plugin-wit, tensorboard-data-server, markdown, grpcio, google-auth-oauthlib, absl-py, wrapt, tensorflow-estimator, tensorboard, scipy, opt-einsum, keras-preprocessing, h5py, google-pasta, gast, astunparse, tensorflow-gpu
  Attempting uninstall: pyasn1
    Found existing installation: pyasn1 0.4.3
    Not uninstalling pyasn1 at /cvmfs/soft.computecanada.ca/easybuild/software/2017/Core/scipy-stack/2019a/lib/python3.7/site-packages, outside environment /localscratch/yinan.29351703.0/env
    Can't uninstall 'pyasn1'. No files were found to uninstall.
  Attempting uninstall: zipp
    Found existing installation: zipp 0.3.3
    Not uninstalling zipp at /cvmfs/soft.computecanada.ca/easybuild/software/2017/Core/scipy-stack/2019a/lib/python3.7/site-packages, outside environment /localscratch/yinan.29351703.0/env
    Can't uninstall 'zipp'. No files were found to uninstall.
  Attempting uninstall: importlib-metadata
    Found existing installation: importlib-metadata 0.8
    Not uninstalling importlib-metadata at /cvmfs/soft.computecanada.ca/easybuild/software/2017/Core/scipy-stack/2019a/lib/python3.7/site-packages, outside environment /localscratch/yinan.29351703.0/env
    Can't uninstall 'importlib-metadata'. No files were found to uninstall.
  Attempting uninstall: scipy
    Found existing installation: scipy 1.2.0
    Not uninstalling scipy at /cvmfs/soft.computecanada.ca/easybuild/software/2017/Core/scipy-stack/2019a/lib/python3.7/site-packages, outside environment /localscratch/yinan.29351703.0/env
    Can't uninstall 'scipy'. No files were found to uninstall.
Successfully installed absl-py-1.0.0+computecanada astunparse-1.6.3+computecanada cachetools-4.2.4+computecanada gast-0.3.3+computecanada google-auth-2.3.3+computecanada google-auth-oauthlib-0.4.6+computecanada google-pasta-0.2.0+computecanada grpcio-1.38.0+computecanada h5py-2.10.0+computecanada importlib-metadata-4.10.1+computecanada keras-preprocessing-1.1.2+computecanada markdown-3.3.6+computecanada oauthlib-3.1.1+computecanada opt-einsum-3.3.0+computecanada pyasn1-0.4.8+computecanada pyasn1-modules-0.2.8+computecanada requests-oauthlib-1.3.0+computecanada rsa-4.8+computecanada scipy-1.4.1+computecanada tensorboard-2.8.0+computecanada tensorboard-data-server-0.6.1+computecanada tensorboard-plugin-wit-1.8.0+computecanada tensorflow-estimator-2.3.0+computecanada tensorflow-gpu-2.3.0+computecanada werkzeug-2.0.3+computecanada wrapt-1.11.2+computecanada zipp-3.7.0+computecanada
Looking in links: /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/nix/avx2, /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/nix/generic, /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/keras-2.8.0+computecanada-py2.py3-none-any.whl
Installing collected packages: Keras
Successfully installed Keras-2.8.0+computecanada
Looking in links: /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/nix/avx2, /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/nix/generic, /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/urllib3-1.26.7+computecanada-py2.py3-none-any.whl
Installing collected packages: urllib3
  Attempting uninstall: urllib3
    Found existing installation: urllib3 1.26.8+computecanada
    Uninstalling urllib3-1.26.8+computecanada:
      Successfully uninstalled urllib3-1.26.8+computecanada
Successfully installed urllib3-1.26.7+computecanada
Looking in links: /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/nix/avx2, /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/nix/generic, /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/nltk-3.7+computecanada-py3-none-any.whl
Requirement already satisfied: tqdm in /localscratch/yinan.29351703.0/env/lib/python3.7/site-packages (from nltk) (4.63.1+computecanada)
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/nltk-3.6.5+computecanada-py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/nltk-3.6.3+computecanada-py3-none-any.whl
Requirement already satisfied: regex in /localscratch/yinan.29351703.0/env/lib/python3.7/site-packages (from nltk) (2020.11.13+computecanada)
Requirement already satisfied: joblib in /localscratch/yinan.29351703.0/env/lib/python3.7/site-packages (from nltk) (1.1.0+computecanada)
Requirement already satisfied: click in /localscratch/yinan.29351703.0/env/lib/python3.7/site-packages (from nltk) (8.0.4+computecanada)
Requirement already satisfied: importlib-metadata in /localscratch/yinan.29351703.0/env/lib/python3.7/site-packages (from click->nltk) (4.10.1+computecanada)
Requirement already satisfied: zipp>=0.5 in /localscratch/yinan.29351703.0/env/lib/python3.7/site-packages (from importlib-metadata->click->nltk) (3.7.0+computecanada)
Requirement already satisfied: typing-extensions>=3.6.4 in /localscratch/yinan.29351703.0/env/lib/python3.7/site-packages (from importlib-metadata->click->nltk) (4.1.1+computecanada)
Installing collected packages: nltk
Successfully installed nltk-3.6.3+computecanada
Looking in links: /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/nix/avx2, /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/nix/generic, /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/scikit_learn-0.22.1+computecanada-cp37-cp37m-linux_x86_64.whl
Requirement already satisfied: scipy>=0.17.0 in /localscratch/yinan.29351703.0/env/lib/python3.7/site-packages (from scikit-learn==0.22.1) (1.4.1+computecanada)
Requirement already satisfied: numpy>=1.11.0 in /cvmfs/soft.computecanada.ca/easybuild/software/2017/Core/scipy-stack/2019a/lib/python3.7/site-packages (from scikit-learn==0.22.1) (1.16.0)
Requirement already satisfied: joblib>=0.11 in /localscratch/yinan.29351703.0/env/lib/python3.7/site-packages (from scikit-learn==0.22.1) (1.1.0+computecanada)
Installing collected packages: scikit-learn
Successfully installed scikit-learn-0.22.1+computecanada
Looking in links: /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/nix/avx2, /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/nix/generic, /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic
Requirement already satisfied: tokenizers==0.5.2 in /localscratch/yinan.29351703.0/env/lib/python3.7/site-packages (0.5.2+computecanada)
wandb: Appending key for api.wandb.ai to your netrc file: /home/yinan/.netrc
Starting Task
2022-03-27 08:05:38.757176: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1
[nltk_data] Downloading package stopwords to /home/yinan/nltk_data...
[nltk_data]   Package stopwords is already up-to-date!
[nltk_data] Downloading package wordnet to /home/yinan/nltk_data...
[nltk_data]   Package wordnet is already up-to-date!
wandb: Currently logged in as: yinanazhou (use `wandb login --relogin` to force relogin)
wandb: wandb version 0.12.11 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
2022-03-27 08:05:53.260914: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1
wandb: Tracking run with wandb version 0.12.5
wandb: Syncing run amber-thunder-3
wandb: ⭐️ View project at https://wandb.ai/yinanazhou/xl_512_bs_8_lr_1e06_es_10_lc_True_nr_False_sr_True_stem_False_lemma_True_repeat_1_fold_1
wandb: 🚀 View run at https://wandb.ai/yinanazhou/xl_512_bs_8_lr_1e06_es_10_lc_True_nr_False_sr_True_stem_False_lemma_True_repeat_1_fold_1/runs/n4mimqol
wandb: Run data is saved locally in /project/6002780/yinan/Thesis_MER_Lyrics/lyric-emotion/wandb/run-20220327_080551-n4mimqol
wandb: Run `wandb offline` to turn off syncing.

Validation loss decreased (inf --> 1.438662).  Saving model ...
Validation loss decreased (1.438662 --> 1.418969).  Saving model ...
Validation loss decreased (1.418969 --> 1.403382).  Saving model ...
Validation loss decreased (1.403382 --> 1.390048).  Saving model ...
Validation loss decreased (1.390048 --> 1.379928).  Saving model ...
Validation loss decreased (1.379928 --> 1.371191).  Saving model ...
Validation loss decreased (1.371191 --> 1.363661).  Saving model ...
Validation loss decreased (1.363661 --> 1.356854).  Saving model ...
Validation loss decreased (1.356854 --> 1.350653).  Saving model ...
Validation loss decreased (1.350653 --> 1.344162).  Saving model ...
Validation loss decreased (1.344162 --> 1.337356).  Saving model ...
Validation loss decreased (1.337356 --> 1.331363).  Saving model ...
Validation loss decreased (1.331363 --> 1.325025).  Saving model ...
Validation loss decreased (1.325025 --> 1.318984).  Saving model ...
Validation loss decreased (1.318984 --> 1.312663).  Saving model ...
Validation loss decreased (1.312663 --> 1.306021).  Saving model ...
Validation loss decreased (1.306021 --> 1.299364).  Saving model ...
Validation loss decreased (1.299364 --> 1.292628).  Saving model ...
Validation loss decreased (1.292628 --> 1.285848).  Saving model ...
Validation loss decreased (1.285848 --> 1.279659).  Saving model ...
Validation loss decreased (1.279659 --> 1.273118).  Saving model ...
Validation loss decreased (1.273118 --> 1.265195).  Saving model ...
Validation loss decreased (1.265195 --> 1.258462).  Saving model ...
Validation loss decreased (1.258462 --> 1.250862).  Saving model ...
Validation loss decreased (1.250862 --> 1.245325).  Saving model ...
Validation loss decreased (1.245325 --> 1.237701).  Saving model ...
Validation loss decreased (1.237701 --> 1.231093).  Saving model ...
Validation loss decreased (1.231093 --> 1.226174).  Saving model ...
Validation loss decreased (1.226174 --> 1.221484).  Saving model ...
Validation loss decreased (1.221484 --> 1.216581).  Saving model ...
Validation loss decreased (1.216581 --> 1.210763).  Saving model ...
Validation loss decreased (1.210763 --> 1.205853).  Saving model ...
Validation loss decreased (1.205853 --> 1.201370).  Saving model ...
Validation loss decreased (1.201370 --> 1.195136).  Saving model ...
Validation loss decreased (1.195136 --> 1.191259).  Saving model ...
Validation loss decreased (1.191259 --> 1.187036).  Saving model ...
Validation loss decreased (1.187036 --> 1.182244).  Saving model ...
Validation loss decreased (1.182244 --> 1.177507).  Saving model ...
Validation loss decreased (1.177507 --> 1.174492).  Saving model ...
Validation loss decreased (1.174492 --> 1.171837).  Saving model ...
Validation loss decreased (1.171837 --> 1.165009).  Saving model ...
Validation loss decreased (1.165009 --> 1.160841).  Saving model ...
Validation loss decreased (1.160841 --> 1.159077).  Saving model ...
Validation loss decreased (1.159077 --> 1.154768).  Saving model ...
Validation loss decreased (1.154768 --> 1.150731).  Saving model ...
Validation loss decreased (1.150731 --> 1.145090).  Saving model ...
Validation loss decreased (1.145090 --> 1.141891).  Saving model ...
Validation loss decreased (1.141891 --> 1.140450).  Saving model ...
Validation loss decreased (1.140450 --> 1.133511).  Saving model ...
Validation loss decreased (1.133511 --> 1.129204).  Saving model ...
Validation loss decreased (1.129204 --> 1.124862).  Saving model ...
Validation loss decreased (1.124862 --> 1.120329).  Saving model ...
Validation loss decreased (1.120329 --> 1.117900).  Saving model ...
Validation loss decreased (1.117900 --> 1.116377).  Saving model ...
Validation loss decreased (1.116377 --> 1.114637).  Saving model ...
Validation loss decreased (1.114637 --> 1.108824).  Saving model ...
Validation loss decreased (1.108824 --> 1.106498).  Saving model ...
Validation loss decreased (1.106498 --> 1.102776).  Saving model ...
Validation loss decreased (1.102776 --> 1.097893).  Saving model ...
Validation loss decreased (1.097893 --> 1.096522).  Saving model ...
Validation loss decreased (1.096522 --> 1.091725).  Saving model ...
Validation loss decreased (1.091725 --> 1.088873).  Saving model ...
Validation loss decreased (1.088873 --> 1.084478).  Saving model ...
Validation loss decreased (1.084478 --> 1.083351).  Saving model ...
Validation loss decreased (1.083351 --> 1.083036).  Saving model ...
Validation loss decreased (1.083036 --> 1.076852).  Saving model ...
EarlyStopping counter: 1 out of 10.0
Validation loss decreased (1.076852 --> 1.070606).  Saving model ...
Validation loss decreased (1.070606 --> 1.068511).  Saving model ...
Validation loss decreased (1.068511 --> 1.066234).  Saving model ...
Validation loss decreased (1.066234 --> 1.062005).  Saving model ...
Validation loss decreased (1.062005 --> 1.060731).  Saving model ...
Validation loss decreased (1.060731 --> 1.058138).  Saving model ...
Validation loss decreased (1.058138 --> 1.055929).  Saving model ...
Validation loss decreased (1.055929 --> 1.052316).  Saving model ...
Validation loss decreased (1.052316 --> 1.048966).  Saving model ...
Validation loss decreased (1.048966 --> 1.048540).  Saving model ...
Validation loss decreased (1.048540 --> 1.048481).  Saving model ...
Validation loss decreased (1.048481 --> 1.042755).  Saving model ...
Validation loss decreased (1.042755 --> 1.039268).  Saving model ...
Validation loss decreased (1.039268 --> 1.038113).  Saving model ...
Validation loss decreased (1.038113 --> 1.038083).  Saving model ...
Validation loss decreased (1.038083 --> 1.036442).  Saving model ...
Validation loss decreased (1.036442 --> 1.036103).  Saving model ...
Validation loss decreased (1.036103 --> 1.031876).  Saving model ...
Validation loss decreased (1.031876 --> 1.030939).  Saving model ...
Validation loss decreased (1.030939 --> 1.028169).  Saving model ...
Validation loss decreased (1.028169 --> 1.027279).  Saving model ...
Validation loss decreased (1.027279 --> 1.023100).  Saving model ...
Validation loss decreased (1.023100 --> 1.021130).  Saving model ...
Validation loss decreased (1.021130 --> 1.020388).  Saving model ...
Validation loss decreased (1.020388 --> 1.019426).  Saving model ...
Validation loss decreased (1.019426 --> 1.018741).  Saving model ...
EarlyStopping counter: 1 out of 10.0
Validation loss decreased (1.018741 --> 1.017610).  Saving model ...
Validation loss decreased (1.017610 --> 1.016525).  Saving model ...
Validation loss decreased (1.016525 --> 1.014403).  Saving model ...
Validation loss decreased (1.014403 --> 1.011787).  Saving model ...
Validation loss decreased (1.011787 --> 1.009583).  Saving model ...
Validation loss decreased (1.009583 --> 1.009387).  Saving model ...
Validation loss decreased (1.009387 --> 1.007883).  Saving model ...
EarlyStopping counter: 1 out of 10.0
Validation loss decreased (1.007883 --> 1.006802).  Saving model ...
Validation loss decreased (1.006802 --> 1.004851).  Saving model ...
Validation loss decreased (1.004851 --> 1.003764).  Saving model ...
Validation loss decreased (1.003764 --> 0.999239).  Saving model ...
Validation loss decreased (0.999239 --> 0.999113).  Saving model ...
Validation loss decreased (0.999113 --> 0.998331).  Saving model ...
Validation loss decreased (0.998331 --> 0.996616).  Saving model ...
Validation loss decreased (0.996616 --> 0.995545).  Saving model ...
EarlyStopping counter: 1 out of 10.0
EarlyStopping counter: 2 out of 10.0
EarlyStopping counter: 3 out of 10.0
Validation loss decreased (0.995545 --> 0.994521).  Saving model ...
EarlyStopping counter: 1 out of 10.0
Validation loss decreased (0.994521 --> 0.992453).  Saving model ...
Validation loss decreased (0.992453 --> 0.989705).  Saving model ...
Validation loss decreased (0.989705 --> 0.989427).  Saving model ...
EarlyStopping counter: 1 out of 10.0
Validation loss decreased (0.989427 --> 0.988035).  Saving model ...
Validation loss decreased (0.988035 --> 0.987830).  Saving model ...
EarlyStopping counter: 1 out of 10.0
Validation loss decreased (0.987830 --> 0.984172).  Saving model ...
EarlyStopping counter: 1 out of 10.0
Validation loss decreased (0.984172 --> 0.983785).  Saving model ...
EarlyStopping counter: 1 out of 10.0
EarlyStopping counter: 2 out of 10.0
Validation loss decreased (0.983785 --> 0.983343).  Saving model ...
EarlyStopping counter: 1 out of 10.0
EarlyStopping counter: 2 out of 10.0
EarlyStopping counter: 3 out of 10.0
EarlyStopping counter: 4 out of 10.0
EarlyStopping counter: 5 out of 10.0
EarlyStopping counter: 6 out of 10.0
EarlyStopping counter: 7 out of 10.0
EarlyStopping counter: 8 out of 10.0
Validation loss decreased (0.983343 --> 0.982496).  Saving model ...
Validation loss decreased (0.982496 --> 0.979669).  Saving model ...
EarlyStopping counter: 1 out of 10.0
Validation loss decreased (0.979669 --> 0.978559).  Saving model ...
EarlyStopping counter: 1 out of 10.0
EarlyStopping counter: 2 out of 10.0
EarlyStopping counter: 3 out of 10.0
EarlyStopping counter: 4 out of 10.0
EarlyStopping counter: 5 out of 10.0
EarlyStopping counter: 6 out of 10.0
EarlyStopping counter: 7 out of 10.0
EarlyStopping counter: 8 out of 10.0
EarlyStopping counter: 9 out of 10.0
EarlyStopping counter: 10 out of 10.0
/localscratch/yinan.29351703.0/env/lib/python3.7/site-packages/torch/nn/functional.py:1794: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.
  warnings.warn("nn.functional.tanh is deprecated. Use torch.tanh instead.")
/localscratch/yinan.29351703.0/env/lib/python3.7/site-packages/transformers/optimization.py:155: UserWarning: This overload of add_ is deprecated:
	add_(Number alpha, Tensor other)
Consider using one of the following signatures instead:
	add_(Tensor other, *, Number alpha) (Triggered internally at  ../torch/csrc/utils/python_arg_parser.cpp:1025.)
  exp_avg.mul_(beta1).add_(1.0 - beta1, grad)
wandb: Waiting for W&B process to finish, PID 121233... (success).
wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: \ 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: | 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: / 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: \ 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: | 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: / 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: \ 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: | 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: / 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb:                                                                                
wandb: Run history:
wandb:     e_F1 ▁▂▃▄▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇▇▇▇▇▇▇██▇████████████
wandb:   e_loss ██▇▇▆▆▅▅▅▄▄▄▄▃▃▃▃▃▂▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:     t_F1 ▁▁▂▃▃▃▄▄▄▅▅▅▅▆▅▆▆▆▆▆▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇████
wandb:   t_loss ██▇▇▇▆▆▆▅▅▅▅▅▄▄▄▄▄▄▃▃▃▃▃▃▂▂▂▂▂▂▂▂▂▂▂▁▁▁▁
wandb: 
wandb: Run summary:
wandb:     e_F1 57.76812
wandb:   e_loss 0.98091
wandb:     t_F1 74.97177
wandb:   t_loss 0.68238
wandb: 
wandb: Synced 4 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Synced amber-thunder-3: https://wandb.ai/yinanazhou/xl_512_bs_8_lr_1e06_es_10_lc_True_nr_False_sr_True_stem_False_lemma_True_repeat_1_fold_1/runs/n4mimqol
wandb: Find logs at: ./wandb/run-20220327_080551-n4mimqol/logs/debug.log
wandb: 

wandb: wandb version 0.12.11 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
2022-03-27 09:44:50.037206: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1
wandb: Tracking run with wandb version 0.12.5
wandb: Syncing run woven-river-2
wandb: ⭐️ View project at https://wandb.ai/yinanazhou/xl_512_bs_8_lr_1e06_es_10_lc_True_nr_False_sr_True_stem_False_lemma_True_repeat_1_fold_2
wandb: 🚀 View run at https://wandb.ai/yinanazhou/xl_512_bs_8_lr_1e06_es_10_lc_True_nr_False_sr_True_stem_False_lemma_True_repeat_1_fold_2/runs/1plkdldn
wandb: Run data is saved locally in /project/6002780/yinan/Thesis_MER_Lyrics/lyric-emotion/wandb/run-20220327_094447-1plkdldn
wandb: Run `wandb offline` to turn off syncing.

Validation loss decreased (inf --> 1.417804).  Saving model ...
Validation loss decreased (1.417804 --> 1.394307).  Saving model ...
Validation loss decreased (1.394307 --> 1.378017).  Saving model ...
Validation loss decreased (1.378017 --> 1.367020).  Saving model ...
Validation loss decreased (1.367020 --> 1.358492).  Saving model ...
Validation loss decreased (1.358492 --> 1.351499).  Saving model ...
Validation loss decreased (1.351499 --> 1.345678).  Saving model ...
Validation loss decreased (1.345678 --> 1.340066).  Saving model ...
Validation loss decreased (1.340066 --> 1.334920).  Saving model ...
Validation loss decreased (1.334920 --> 1.330287).  Saving model ...
Validation loss decreased (1.330287 --> 1.325854).  Saving model ...
Validation loss decreased (1.325854 --> 1.321502).  Saving model ...
Validation loss decreased (1.321502 --> 1.316824).  Saving model ...
Validation loss decreased (1.316824 --> 1.311933).  Saving model ...
Validation loss decreased (1.311933 --> 1.306667).  Saving model ...
Validation loss decreased (1.306667 --> 1.300540).  Saving model ...
Validation loss decreased (1.300540 --> 1.294411).  Saving model ...
Validation loss decreased (1.294411 --> 1.288565).  Saving model ...
Validation loss decreased (1.288565 --> 1.282038).  Saving model ...
Validation loss decreased (1.282038 --> 1.276207).  Saving model ...
Validation loss decreased (1.276207 --> 1.269971).  Saving model ...
Validation loss decreased (1.269971 --> 1.262806).  Saving model ...
Validation loss decreased (1.262806 --> 1.255231).  Saving model ...
Validation loss decreased (1.255231 --> 1.247424).  Saving model ...
Validation loss decreased (1.247424 --> 1.240013).  Saving model ...
Validation loss decreased (1.240013 --> 1.232350).  Saving model ...
Validation loss decreased (1.232350 --> 1.225529).  Saving model ...
Validation loss decreased (1.225529 --> 1.216810).  Saving model ...
Validation loss decreased (1.216810 --> 1.208563).  Saving model ...
Validation loss decreased (1.208563 --> 1.201013).  Saving model ...
Validation loss decreased (1.201013 --> 1.193287).  Saving model ...
Validation loss decreased (1.193287 --> 1.183811).  Saving model ...
Validation loss decreased (1.183811 --> 1.176000).  Saving model ...
Validation loss decreased (1.176000 --> 1.167822).  Saving model ...
Validation loss decreased (1.167822 --> 1.158911).  Saving model ...
Validation loss decreased (1.158911 --> 1.149754).  Saving model ...
Validation loss decreased (1.149754 --> 1.142056).  Saving model ...
Validation loss decreased (1.142056 --> 1.134541).  Saving model ...
Validation loss decreased (1.134541 --> 1.127707).  Saving model ...
Validation loss decreased (1.127707 --> 1.121718).  Saving model ...
Validation loss decreased (1.121718 --> 1.114383).  Saving model ...
Validation loss decreased (1.114383 --> 1.107003).  Saving model ...
Validation loss decreased (1.107003 --> 1.101221).  Saving model ...
Validation loss decreased (1.101221 --> 1.094976).  Saving model ...
Validation loss decreased (1.094976 --> 1.088251).  Saving model ...
Validation loss decreased (1.088251 --> 1.083316).  Saving model ...
Validation loss decreased (1.083316 --> 1.076473).  Saving model ...
Validation loss decreased (1.076473 --> 1.072143).  Saving model ...
Validation loss decreased (1.072143 --> 1.067530).  Saving model ...
Validation loss decreased (1.067530 --> 1.061620).  Saving model ...
Validation loss decreased (1.061620 --> 1.056091).  Saving model ...
Validation loss decreased (1.056091 --> 1.049487).  Saving model ...
Validation loss decreased (1.049487 --> 1.045738).  Saving model ...
Validation loss decreased (1.045738 --> 1.041917).  Saving model ...
Validation loss decreased (1.041917 --> 1.036896).  Saving model ...
Validation loss decreased (1.036896 --> 1.034583).  Saving model ...
Validation loss decreased (1.034583 --> 1.029839).  Saving model ...
Validation loss decreased (1.029839 --> 1.025562).  Saving model ...
Validation loss decreased (1.025562 --> 1.018417).  Saving model ...
Validation loss decreased (1.018417 --> 1.013450).  Saving model ...
Validation loss decreased (1.013450 --> 1.010683).  Saving model ...
Validation loss decreased (1.010683 --> 1.008216).  Saving model ...
Validation loss decreased (1.008216 --> 1.003679).  Saving model ...
Validation loss decreased (1.003679 --> 1.001667).  Saving model ...
Validation loss decreased (1.001667 --> 0.994873).  Saving model ...
Validation loss decreased (0.994873 --> 0.992930).  Saving model ...
Validation loss decreased (0.992930 --> 0.987440).  Saving model ...
Validation loss decreased (0.987440 --> 0.982935).  Saving model ...
Validation loss decreased (0.982935 --> 0.980379).  Saving model ...
Validation loss decreased (0.980379 --> 0.978256).  Saving model ...
Validation loss decreased (0.978256 --> 0.975387).  Saving model ...
Validation loss decreased (0.975387 --> 0.973317).  Saving model ...
Validation loss decreased (0.973317 --> 0.971145).  Saving model ...
Validation loss decreased (0.971145 --> 0.966454).  Saving model ...
Validation loss decreased (0.966454 --> 0.961314).  Saving model ...
Validation loss decreased (0.961314 --> 0.960442).  Saving model ...
Validation loss decreased (0.960442 --> 0.957555).  Saving model ...
Validation loss decreased (0.957555 --> 0.956034).  Saving model ...
Validation loss decreased (0.956034 --> 0.952531).  Saving model ...
Validation loss decreased (0.952531 --> 0.951582).  Saving model ...
Validation loss decreased (0.951582 --> 0.947955).  Saving model ...
Validation loss decreased (0.947955 --> 0.945405).  Saving model ...
Validation loss decreased (0.945405 --> 0.943272).  Saving model ...
Validation loss decreased (0.943272 --> 0.938139).  Saving model ...
EarlyStopping counter: 1 out of 10.0
Validation loss decreased (0.938139 --> 0.937551).  Saving model ...
EarlyStopping counter: 1 out of 10.0
Validation loss decreased (0.937551 --> 0.934909).  Saving model ...
Validation loss decreased (0.934909 --> 0.932973).  Saving model ...
Validation loss decreased (0.932973 --> 0.931184).  Saving model ...
Validation loss decreased (0.931184 --> 0.926977).  Saving model ...
EarlyStopping counter: 1 out of 10.0
Validation loss decreased (0.926977 --> 0.924199).  Saving model ...
Validation loss decreased (0.924199 --> 0.920575).  Saving model ...
Validation loss decreased (0.920575 --> 0.919779).  Saving model ...
Validation loss decreased (0.919779 --> 0.918193).  Saving model ...
EarlyStopping counter: 1 out of 10.0
EarlyStopping counter: 2 out of 10.0
Validation loss decreased (0.918193 --> 0.915106).  Saving model ...
EarlyStopping counter: 1 out of 10.0
Validation loss decreased (0.915106 --> 0.913971).  Saving model ...
EarlyStopping counter: 1 out of 10.0
Validation loss decreased (0.913971 --> 0.913089).  Saving model ...
Validation loss decreased (0.913089 --> 0.911651).  Saving model ...
EarlyStopping counter: 1 out of 10.0
EarlyStopping counter: 2 out of 10.0
EarlyStopping counter: 3 out of 10.0
Validation loss decreased (0.911651 --> 0.909731).  Saving model ...
Validation loss decreased (0.909731 --> 0.907770).  Saving model ...
Validation loss decreased (0.907770 --> 0.907368).  Saving model ...
Validation loss decreased (0.907368 --> 0.905214).  Saving model ...
EarlyStopping counter: 1 out of 10.0
EarlyStopping counter: 2 out of 10.0
EarlyStopping counter: 3 out of 10.0
EarlyStopping counter: 4 out of 10.0
EarlyStopping counter: 5 out of 10.0
EarlyStopping counter: 6 out of 10.0
EarlyStopping counter: 7 out of 10.0
EarlyStopping counter: 8 out of 10.0
EarlyStopping counter: 9 out of 10.0
Validation loss decreased (0.905214 --> 0.904666).  Saving model ...
EarlyStopping counter: 1 out of 10.0
Validation loss decreased (0.904666 --> 0.904344).  Saving model ...
EarlyStopping counter: 1 out of 10.0
EarlyStopping counter: 2 out of 10.0
EarlyStopping counter: 3 out of 10.0
EarlyStopping counter: 4 out of 10.0
EarlyStopping counter: 5 out of 10.0
EarlyStopping counter: 6 out of 10.0
EarlyStopping counter: 7 out of 10.0
Validation loss decreased (0.904344 --> 0.903475).  Saving model ...
EarlyStopping counter: 1 out of 10.0
EarlyStopping counter: 2 out of 10.0
EarlyStopping counter: 3 out of 10.0
Validation loss decreased (0.903475 --> 0.903101).  Saving model ...
EarlyStopping counter: 1 out of 10.0
EarlyStopping counter: 2 out of 10.0
EarlyStopping counter: 3 out of 10.0
EarlyStopping counter: 4 out of 10.0
EarlyStopping counter: 5 out of 10.0
EarlyStopping counter: 6 out of 10.0
EarlyStopping counter: 7 out of 10.0
EarlyStopping counter: 8 out of 10.0
EarlyStopping counter: 9 out of 10.0
EarlyStopping counter: 10 out of 10.0
/localscratch/yinan.29351703.0/env/lib/python3.7/site-packages/torch/nn/functional.py:1794: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.
  warnings.warn("nn.functional.tanh is deprecated. Use torch.tanh instead.")
wandb: Waiting for W&B process to finish, PID 126506... (success).
wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: \ 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: | 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: / 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: \ 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: | 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: / 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: \ 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: | 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: / 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb:                                                                                
wandb: Run history:
wandb:     e_F1 ▁▃▄▅▅▅▆▆▆▇▇▇▇▇▇▇▇▇██████████████████████
wandb:   e_loss ██▇▇▇▆▆▆▅▅▄▄▄▃▃▃▃▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:     t_F1 ▁▂▃▂▃▃▃▄▄▄▅▅▅▆▆▆▆▆▆▆▇▆▇▇▇▇▇▇▇▇▇▇▇▇██████
wandb:   t_loss ███▇▇▇▇▇▆▆▆▆▅▅▅▅▄▄▄▄▄▄▃▃▃▃▃▃▂▂▂▂▂▂▂▂▂▁▁▁
wandb: 
wandb: Run summary:
wandb:     e_F1 62.95451
wandb:   e_loss 0.91278
wandb:     t_F1 74.63273
wandb:   t_loss 0.69826
wandb: 
wandb: Synced 4 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Synced woven-river-2: https://wandb.ai/yinanazhou/xl_512_bs_8_lr_1e06_es_10_lc_True_nr_False_sr_True_stem_False_lemma_True_repeat_1_fold_2/runs/1plkdldn
wandb: Find logs at: ./wandb/run-20220327_094447-1plkdldn/logs/debug.log
wandb: 

wandb: wandb version 0.12.11 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
2022-03-27 11:17:45.368527: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1
wandb: Tracking run with wandb version 0.12.5
wandb: Syncing run charmed-waterfall-2
wandb: ⭐️ View project at https://wandb.ai/yinanazhou/xl_512_bs_8_lr_1e06_es_10_lc_True_nr_False_sr_True_stem_False_lemma_True_repeat_2_fold_1
wandb: 🚀 View run at https://wandb.ai/yinanazhou/xl_512_bs_8_lr_1e06_es_10_lc_True_nr_False_sr_True_stem_False_lemma_True_repeat_2_fold_1/runs/1m5lktch
wandb: Run data is saved locally in /project/6002780/yinan/Thesis_MER_Lyrics/lyric-emotion/wandb/run-20220327_111743-1m5lktch
wandb: Run `wandb offline` to turn off syncing.

Validation loss decreased (inf --> 1.425301).  Saving model ...
Validation loss decreased (1.425301 --> 1.409819).  Saving model ...
Validation loss decreased (1.409819 --> 1.398547).  Saving model ...
Validation loss decreased (1.398547 --> 1.389222).  Saving model ...
Validation loss decreased (1.389222 --> 1.381625).  Saving model ...
Validation loss decreased (1.381625 --> 1.375275).  Saving model ...
Validation loss decreased (1.375275 --> 1.369232).  Saving model ...
Validation loss decreased (1.369232 --> 1.363534).  Saving model ...
Validation loss decreased (1.363534 --> 1.358327).  Saving model ...
Validation loss decreased (1.358327 --> 1.353281).  Saving model ...
Validation loss decreased (1.353281 --> 1.348031).  Saving model ...
Validation loss decreased (1.348031 --> 1.342280).  Saving model ...
Validation loss decreased (1.342280 --> 1.336923).  Saving model ...
Validation loss decreased (1.336923 --> 1.330945).  Saving model ...
Validation loss decreased (1.330945 --> 1.324815).  Saving model ...
Validation loss decreased (1.324815 --> 1.318504).  Saving model ...
Validation loss decreased (1.318504 --> 1.311393).  Saving model ...
Validation loss decreased (1.311393 --> 1.304041).  Saving model ...
Validation loss decreased (1.304041 --> 1.297282).  Saving model ...
Validation loss decreased (1.297282 --> 1.289703).  Saving model ...
Validation loss decreased (1.289703 --> 1.281370).  Saving model ...
Validation loss decreased (1.281370 --> 1.271843).  Saving model ...
Validation loss decreased (1.271843 --> 1.263948).  Saving model ...
Validation loss decreased (1.263948 --> 1.256024).  Saving model ...
Validation loss decreased (1.256024 --> 1.246526).  Saving model ...
Validation loss decreased (1.246526 --> 1.237610).  Saving model ...
Validation loss decreased (1.237610 --> 1.229144).  Saving model ...
Validation loss decreased (1.229144 --> 1.218863).  Saving model ...
Validation loss decreased (1.218863 --> 1.209477).  Saving model ...
Validation loss decreased (1.209477 --> 1.201184).  Saving model ...
Validation loss decreased (1.201184 --> 1.193328).  Saving model ...
Validation loss decreased (1.193328 --> 1.184103).  Saving model ...
Validation loss decreased (1.184103 --> 1.177250).  Saving model ...
Validation loss decreased (1.177250 --> 1.167502).  Saving model ...
Validation loss decreased (1.167502 --> 1.159952).  Saving model ...
Validation loss decreased (1.159952 --> 1.152452).  Saving model ...
Validation loss decreased (1.152452 --> 1.145657).  Saving model ...
Validation loss decreased (1.145657 --> 1.140446).  Saving model ...
Validation loss decreased (1.140446 --> 1.132759).  Saving model ...
Validation loss decreased (1.132759 --> 1.125679).  Saving model ...
Validation loss decreased (1.125679 --> 1.119488).  Saving model ...
Validation loss decreased (1.119488 --> 1.112730).  Saving model ...
Validation loss decreased (1.112730 --> 1.106669).  Saving model ...
Validation loss decreased (1.106669 --> 1.100638).  Saving model ...
Validation loss decreased (1.100638 --> 1.094249).  Saving model ...
Validation loss decreased (1.094249 --> 1.088359).  Saving model ...
Validation loss decreased (1.088359 --> 1.082687).  Saving model ...
Validation loss decreased (1.082687 --> 1.077739).  Saving model ...
Validation loss decreased (1.077739 --> 1.073481).  Saving model ...
Validation loss decreased (1.073481 --> 1.067795).  Saving model ...
Validation loss decreased (1.067795 --> 1.062635).  Saving model ...
Validation loss decreased (1.062635 --> 1.057822).  Saving model ...
Validation loss decreased (1.057822 --> 1.053182).  Saving model ...
Validation loss decreased (1.053182 --> 1.048876).  Saving model ...
Validation loss decreased (1.048876 --> 1.044010).  Saving model ...
Validation loss decreased (1.044010 --> 1.039396).  Saving model ...
Validation loss decreased (1.039396 --> 1.035714).  Saving model ...
Validation loss decreased (1.035714 --> 1.031422).  Saving model ...
Validation loss decreased (1.031422 --> 1.027597).  Saving model ...
Validation loss decreased (1.027597 --> 1.025437).  Saving model ...
Validation loss decreased (1.025437 --> 1.021834).  Saving model ...
Validation loss decreased (1.021834 --> 1.018501).  Saving model ...
Validation loss decreased (1.018501 --> 1.015912).  Saving model ...
Validation loss decreased (1.015912 --> 1.012319).  Saving model ...
Validation loss decreased (1.012319 --> 1.011581).  Saving model ...
Validation loss decreased (1.011581 --> 1.007806).  Saving model ...
Validation loss decreased (1.007806 --> 1.003660).  Saving model ...
Validation loss decreased (1.003660 --> 1.000539).  Saving model ...
Validation loss decreased (1.000539 --> 0.998196).  Saving model ...
Validation loss decreased (0.998196 --> 0.996007).  Saving model ...
Validation loss decreased (0.996007 --> 0.993188).  Saving model ...
Validation loss decreased (0.993188 --> 0.992397).  Saving model ...
Validation loss decreased (0.992397 --> 0.990430).  Saving model ...
Validation loss decreased (0.990430 --> 0.988445).  Saving model ...
Validation loss decreased (0.988445 --> 0.985464).  Saving model ...
Validation loss decreased (0.985464 --> 0.982918).  Saving model ...
Validation loss decreased (0.982918 --> 0.980491).  Saving model ...
Validation loss decreased (0.980491 --> 0.977819).  Saving model ...
Validation loss decreased (0.977819 --> 0.976403).  Saving model ...
Validation loss decreased (0.976403 --> 0.975085).  Saving model ...
Validation loss decreased (0.975085 --> 0.973234).  Saving model ...
Validation loss decreased (0.973234 --> 0.972042).  Saving model ...
Validation loss decreased (0.972042 --> 0.969486).  Saving model ...
Validation loss decreased (0.969486 --> 0.968930).  Saving model ...
Validation loss decreased (0.968930 --> 0.967389).  Saving model ...
Validation loss decreased (0.967389 --> 0.965630).  Saving model ...
Validation loss decreased (0.965630 --> 0.963861).  Saving model ...
Validation loss decreased (0.963861 --> 0.963044).  Saving model ...
Validation loss decreased (0.963044 --> 0.961831).  Saving model ...
Validation loss decreased (0.961831 --> 0.959727).  Saving model ...
Validation loss decreased (0.959727 --> 0.958300).  Saving model ...
Validation loss decreased (0.958300 --> 0.957493).  Saving model ...
Validation loss decreased (0.957493 --> 0.956885).  Saving model ...
Validation loss decreased (0.956885 --> 0.955713).  Saving model ...
Validation loss decreased (0.955713 --> 0.955014).  Saving model ...
Validation loss decreased (0.955014 --> 0.954468).  Saving model ...
Validation loss decreased (0.954468 --> 0.953627).  Saving model ...
Validation loss decreased (0.953627 --> 0.952050).  Saving model ...
Validation loss decreased (0.952050 --> 0.950888).  Saving model ...
Validation loss decreased (0.950888 --> 0.949561).  Saving model ...
Validation loss decreased (0.949561 --> 0.948308).  Saving model ...
Validation loss decreased (0.948308 --> 0.946997).  Saving model ...
Validation loss decreased (0.946997 --> 0.946747).  Saving model ...
Validation loss decreased (0.946747 --> 0.946724).  Saving model ...
Validation loss decreased (0.946724 --> 0.946343).  Saving model ...
Validation loss decreased (0.946343 --> 0.945464).  Saving model ...
Validation loss decreased (0.945464 --> 0.944732).  Saving model ...
Validation loss decreased (0.944732 --> 0.943951).  Saving model ...
EarlyStopping counter: 1 out of 10.0
Validation loss decreased (0.943951 --> 0.943148).  Saving model ...
Validation loss decreased (0.943148 --> 0.942371).  Saving model ...
Validation loss decreased (0.942371 --> 0.941803).  Saving model ...
EarlyStopping counter: 1 out of 10.0
EarlyStopping counter: 2 out of 10.0
EarlyStopping counter: 3 out of 10.0
EarlyStopping counter: 4 out of 10.0
Validation loss decreased (0.941803 --> 0.940863).  Saving model ...
Validation loss decreased (0.940863 --> 0.940694).  Saving model ...
Validation loss decreased (0.940694 --> 0.940320).  Saving model ...
EarlyStopping counter: 1 out of 10.0
EarlyStopping counter: 2 out of 10.0
EarlyStopping counter: 3 out of 10.0
EarlyStopping counter: 4 out of 10.0
EarlyStopping counter: 5 out of 10.0
EarlyStopping counter: 6 out of 10.0
EarlyStopping counter: 7 out of 10.0
EarlyStopping counter: 8 out of 10.0
EarlyStopping counter: 9 out of 10.0
EarlyStopping counter: 10 out of 10.0
/localscratch/yinan.29351703.0/env/lib/python3.7/site-packages/torch/nn/functional.py:1794: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.
  warnings.warn("nn.functional.tanh is deprecated. Use torch.tanh instead.")
wandb: Waiting for W&B process to finish, PID 131476... (success).
wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: \ 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: | 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: / 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: \ 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: | 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: / 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: \ 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: | 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: / 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb:                                                                                
wandb: Run history:
wandb:     e_F1 ▁▂▃▄▅▅▅▆▆▆▇▇▇▇▇▇▇▇▇▇▇▇█▇████████████████
wandb:   e_loss ██▇▇▇▆▆▆▅▅▄▄▄▃▃▃▃▂▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:     t_F1 ▁▂▃▃▃▃▄▄▄▅▅▅▆▆▆▆▆▆▇▆▆▇▇▇▆▇▇▇▇▇▇▇▇▇██▇███
wandb:   t_loss ██▇▇▇▇▇▆▆▆▆▅▅▅▅▄▄▄▄▄▃▃▃▃▃▃▂▂▂▂▂▂▂▂▂▂▁▁▁▁
wandb: 
wandb: Run summary:
wandb:     e_F1 61.40102
wandb:   e_loss 0.94068
wandb:     t_F1 70.75855
wandb:   t_loss 0.77042
wandb: 
wandb: Synced 4 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Synced charmed-waterfall-2: https://wandb.ai/yinanazhou/xl_512_bs_8_lr_1e06_es_10_lc_True_nr_False_sr_True_stem_False_lemma_True_repeat_2_fold_1/runs/1m5lktch
wandb: Find logs at: ./wandb/run-20220327_111743-1m5lktch/logs/debug.log
wandb: 

wandb: wandb version 0.12.11 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
2022-03-27 12:40:55.968122: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1
wandb: Tracking run with wandb version 0.12.5
wandb: Syncing run firm-deluge-1
wandb: ⭐️ View project at https://wandb.ai/yinanazhou/xl_512_bs_8_lr_1e06_es_10_lc_True_nr_False_sr_True_stem_False_lemma_True_repeat_2_fold_2
wandb: 🚀 View run at https://wandb.ai/yinanazhou/xl_512_bs_8_lr_1e06_es_10_lc_True_nr_False_sr_True_stem_False_lemma_True_repeat_2_fold_2/runs/oobrq711
wandb: Run data is saved locally in /project/6002780/yinan/Thesis_MER_Lyrics/lyric-emotion/wandb/run-20220327_124053-oobrq711
wandb: Run `wandb offline` to turn off syncing.

Validation loss decreased (inf --> 1.493928).  Saving model ...
Validation loss decreased (1.493928 --> 1.462346).  Saving model ...
Validation loss decreased (1.462346 --> 1.437089).  Saving model ...
Validation loss decreased (1.437089 --> 1.417844).  Saving model ...
Validation loss decreased (1.417844 --> 1.401029).  Saving model ...
Validation loss decreased (1.401029 --> 1.387449).  Saving model ...
Validation loss decreased (1.387449 --> 1.376917).  Saving model ...
Validation loss decreased (1.376917 --> 1.368540).  Saving model ...
Validation loss decreased (1.368540 --> 1.360865).  Saving model ...
Validation loss decreased (1.360865 --> 1.353883).  Saving model ...
Validation loss decreased (1.353883 --> 1.347916).  Saving model ...
Validation loss decreased (1.347916 --> 1.342888).  Saving model ...
Validation loss decreased (1.342888 --> 1.336751).  Saving model ...
Validation loss decreased (1.336751 --> 1.331689).  Saving model ...
Validation loss decreased (1.331689 --> 1.326260).  Saving model ...
Validation loss decreased (1.326260 --> 1.319872).  Saving model ...
Validation loss decreased (1.319872 --> 1.314268).  Saving model ...
Validation loss decreased (1.314268 --> 1.308447).  Saving model ...
Validation loss decreased (1.308447 --> 1.303093).  Saving model ...
Validation loss decreased (1.303093 --> 1.297615).  Saving model ...
Validation loss decreased (1.297615 --> 1.291012).  Saving model ...
Validation loss decreased (1.291012 --> 1.283746).  Saving model ...
Validation loss decreased (1.283746 --> 1.276197).  Saving model ...
Validation loss decreased (1.276197 --> 1.269321).  Saving model ...
Validation loss decreased (1.269321 --> 1.262717).  Saving model ...
Validation loss decreased (1.262717 --> 1.254796).  Saving model ...
Validation loss decreased (1.254796 --> 1.246611).  Saving model ...
Validation loss decreased (1.246611 --> 1.238774).  Saving model ...
Validation loss decreased (1.238774 --> 1.230700).  Saving model ...
Validation loss decreased (1.230700 --> 1.222430).  Saving model ...
Validation loss decreased (1.222430 --> 1.213069).  Saving model ...
Validation loss decreased (1.213069 --> 1.205628).  Saving model ...
Validation loss decreased (1.205628 --> 1.198290).  Saving model ...
Validation loss decreased (1.198290 --> 1.190108).  Saving model ...
Validation loss decreased (1.190108 --> 1.181935).  Saving model ...
Validation loss decreased (1.181935 --> 1.174537).  Saving model ...
Validation loss decreased (1.174537 --> 1.168141).  Saving model ...
Validation loss decreased (1.168141 --> 1.161890).  Saving model ...
Validation loss decreased (1.161890 --> 1.156870).  Saving model ...
Validation loss decreased (1.156870 --> 1.149827).  Saving model ...
Validation loss decreased (1.149827 --> 1.144010).  Saving model ...
Validation loss decreased (1.144010 --> 1.137926).  Saving model ...
Validation loss decreased (1.137926 --> 1.131144).  Saving model ...
Validation loss decreased (1.131144 --> 1.124471).  Saving model ...
Validation loss decreased (1.124471 --> 1.118740).  Saving model ...
Validation loss decreased (1.118740 --> 1.114775).  Saving model ...
Validation loss decreased (1.114775 --> 1.109619).  Saving model ...
Validation loss decreased (1.109619 --> 1.102626).  Saving model ...
Validation loss decreased (1.102626 --> 1.097910).  Saving model ...
Validation loss decreased (1.097910 --> 1.093049).  Saving model ...
Validation loss decreased (1.093049 --> 1.089060).  Saving model ...
Validation loss decreased (1.089060 --> 1.084404).  Saving model ...
Validation loss decreased (1.084404 --> 1.079118).  Saving model ...
Validation loss decreased (1.079118 --> 1.074799).  Saving model ...
Validation loss decreased (1.074799 --> 1.068788).  Saving model ...
Validation loss decreased (1.068788 --> 1.064238).  Saving model ...
Validation loss decreased (1.064238 --> 1.058889).  Saving model ...
Validation loss decreased (1.058889 --> 1.056314).  Saving model ...
Validation loss decreased (1.056314 --> 1.053243).  Saving model ...
Validation loss decreased (1.053243 --> 1.048911).  Saving model ...
Validation loss decreased (1.048911 --> 1.044729).  Saving model ...
Validation loss decreased (1.044729 --> 1.042499).  Saving model ...
Validation loss decreased (1.042499 --> 1.038728).  Saving model ...
Validation loss decreased (1.038728 --> 1.033441).  Saving model ...
Validation loss decreased (1.033441 --> 1.029205).  Saving model ...
Validation loss decreased (1.029205 --> 1.025585).  Saving model ...
Validation loss decreased (1.025585 --> 1.020353).  Saving model ...
Validation loss decreased (1.020353 --> 1.016463).  Saving model ...
Validation loss decreased (1.016463 --> 1.013188).  Saving model ...
Validation loss decreased (1.013188 --> 1.010105).  Saving model ...
Validation loss decreased (1.010105 --> 1.006273).  Saving model ...
Validation loss decreased (1.006273 --> 1.005456).  Saving model ...
Validation loss decreased (1.005456 --> 1.001134).  Saving model ...
Validation loss decreased (1.001134 --> 0.996972).  Saving model ...
Validation loss decreased (0.996972 --> 0.993751).  Saving model ...
Validation loss decreased (0.993751 --> 0.989379).  Saving model ...
Validation loss decreased (0.989379 --> 0.986754).  Saving model ...
Validation loss decreased (0.986754 --> 0.985436).  Saving model ...
Validation loss decreased (0.985436 --> 0.983543).  Saving model ...
Validation loss decreased (0.983543 --> 0.980490).  Saving model ...
Validation loss decreased (0.980490 --> 0.978190).  Saving model ...
Validation loss decreased (0.978190 --> 0.975315).  Saving model ...
Validation loss decreased (0.975315 --> 0.973570).  Saving model ...
Validation loss decreased (0.973570 --> 0.970873).  Saving model ...
Validation loss decreased (0.970873 --> 0.967038).  Saving model ...
Validation loss decreased (0.967038 --> 0.965280).  Saving model ...
EarlyStopping counter: 1 out of 10.0
Validation loss decreased (0.965280 --> 0.962019).  Saving model ...
Validation loss decreased (0.962019 --> 0.959496).  Saving model ...
Validation loss decreased (0.959496 --> 0.956554).  Saving model ...
Validation loss decreased (0.956554 --> 0.954966).  Saving model ...
Validation loss decreased (0.954966 --> 0.952563).  Saving model ...
Validation loss decreased (0.952563 --> 0.950754).  Saving model ...
Validation loss decreased (0.950754 --> 0.950468).  Saving model ...
Validation loss decreased (0.950468 --> 0.948892).  Saving model ...
Validation loss decreased (0.948892 --> 0.945459).  Saving model ...
Validation loss decreased (0.945459 --> 0.943404).  Saving model ...
Validation loss decreased (0.943404 --> 0.941556).  Saving model ...
Validation loss decreased (0.941556 --> 0.939271).  Saving model ...
Validation loss decreased (0.939271 --> 0.938436).  Saving model ...
Validation loss decreased (0.938436 --> 0.936474).  Saving model ...
EarlyStopping counter: 1 out of 10.0
EarlyStopping counter: 2 out of 10.0
Validation loss decreased (0.936474 --> 0.934681).  Saving model ...
EarlyStopping counter: 1 out of 10.0
Validation loss decreased (0.934681 --> 0.931842).  Saving model ...
Validation loss decreased (0.931842 --> 0.931267).  Saving model ...
Validation loss decreased (0.931267 --> 0.930113).  Saving model ...
Validation loss decreased (0.930113 --> 0.929227).  Saving model ...
Validation loss decreased (0.929227 --> 0.928179).  Saving model ...
Validation loss decreased (0.928179 --> 0.927386).  Saving model ...
Validation loss decreased (0.927386 --> 0.925563).  Saving model ...
Validation loss decreased (0.925563 --> 0.922131).  Saving model ...
Validation loss decreased (0.922131 --> 0.921213).  Saving model ...
Validation loss decreased (0.921213 --> 0.919642).  Saving model ...
Validation loss decreased (0.919642 --> 0.917483).  Saving model ...
Validation loss decreased (0.917483 --> 0.915232).  Saving model ...
Validation loss decreased (0.915232 --> 0.914159).  Saving model ...
EarlyStopping counter: 1 out of 10.0
Validation loss decreased (0.914159 --> 0.913743).  Saving model ...
Validation loss decreased (0.913743 --> 0.913641).  Saving model ...
Validation loss decreased (0.913641 --> 0.912655).  Saving model ...
Validation loss decreased (0.912655 --> 0.911457).  Saving model ...
Validation loss decreased (0.911457 --> 0.910714).  Saving model ...
Validation loss decreased (0.910714 --> 0.909971).  Saving model ...
Validation loss decreased (0.909971 --> 0.908448).  Saving model ...
Validation loss decreased (0.908448 --> 0.907413).  Saving model ...
Validation loss decreased (0.907413 --> 0.907163).  Saving model ...
EarlyStopping counter: 1 out of 10.0
EarlyStopping counter: 2 out of 10.0
Validation loss decreased (0.907163 --> 0.906176).  Saving model ...
Validation loss decreased (0.906176 --> 0.905466).  Saving model ...
EarlyStopping counter: 1 out of 10.0
EarlyStopping counter: 2 out of 10.0
Validation loss decreased (0.905466 --> 0.904697).  Saving model ...
Validation loss decreased (0.904697 --> 0.903839).  Saving model ...
EarlyStopping counter: 1 out of 10.0
EarlyStopping counter: 2 out of 10.0
EarlyStopping counter: 3 out of 10.0
EarlyStopping counter: 4 out of 10.0
Validation loss decreased (0.903839 --> 0.902979).  Saving model ...
Validation loss decreased (0.902979 --> 0.902163).  Saving model ...
Validation loss decreased (0.902163 --> 0.901920).  Saving model ...
Validation loss decreased (0.901920 --> 0.901094).  Saving model ...
EarlyStopping counter: 1 out of 10.0
Validation loss decreased (0.901094 --> 0.901061).  Saving model ...
EarlyStopping counter: 1 out of 10.0
EarlyStopping counter: 2 out of 10.0
EarlyStopping counter: 3 out of 10.0
EarlyStopping counter: 4 out of 10.0
EarlyStopping counter: 5 out of 10.0
EarlyStopping counter: 6 out of 10.0
EarlyStopping counter: 7 out of 10.0
EarlyStopping counter: 8 out of 10.0
EarlyStopping counter: 9 out of 10.0
EarlyStopping counter: 10 out of 10.0
/localscratch/yinan.29351703.0/env/lib/python3.7/site-packages/torch/nn/functional.py:1794: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.
  warnings.warn("nn.functional.tanh is deprecated. Use torch.tanh instead.")
wandb: Waiting for W&B process to finish, PID 135913... (success).
wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: \ 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: | 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: / 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: \ 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: | 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: / 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: \ 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: | 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: / 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb:                                                                                
wandb: Run history:
wandb:     e_F1 ▁▁▂▃▅▅▆▆▆▆▇▇▇▇▇▇▇▇▇█▇███████████████████
wandb:   e_loss █▇▇▇▆▆▆▅▅▄▄▄▄▃▃▃▃▂▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:     t_F1 ▁▁▂▂▃▃▃▃▄▅▅▅▅▅▆▆▆▆▆▆▇▆▆▇▇▇▇▇▇▇▇▇▇▇█▇████
wandb:   t_loss ██▇▇▇▇▆▆▆▅▅▅▅▅▄▄▄▄▄▃▃▃▃▃▃▂▂▂▂▂▂▂▂▂▁▂▁▁▁▁
wandb: 
wandb: Run summary:
wandb:     e_F1 63.31249
wandb:   e_loss 0.90405
wandb:     t_F1 76.29217
wandb:   t_loss 0.69868
wandb: 
wandb: Synced 4 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Synced firm-deluge-1: https://wandb.ai/yinanazhou/xl_512_bs_8_lr_1e06_es_10_lc_True_nr_False_sr_True_stem_False_lemma_True_repeat_2_fold_2/runs/oobrq711
wandb: Find logs at: ./wandb/run-20220327_124053-oobrq711/logs/debug.log
wandb: 

wandb: wandb version 0.12.11 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
2022-03-27 14:24:01.933745: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1
wandb: Tracking run with wandb version 0.12.5
wandb: Syncing run soft-plasma-1
wandb: ⭐️ View project at https://wandb.ai/yinanazhou/xl_512_bs_8_lr_1e06_es_10_lc_True_nr_False_sr_True_stem_False_lemma_True_repeat_3_fold_1
wandb: 🚀 View run at https://wandb.ai/yinanazhou/xl_512_bs_8_lr_1e06_es_10_lc_True_nr_False_sr_True_stem_False_lemma_True_repeat_3_fold_1/runs/30oohavf
wandb: Run data is saved locally in /project/6002780/yinan/Thesis_MER_Lyrics/lyric-emotion/wandb/run-20220327_142359-30oohavf
wandb: Run `wandb offline` to turn off syncing.

Validation loss decreased (inf --> 1.540090).  Saving model ...
Validation loss decreased (1.540090 --> 1.502193).  Saving model ...
Validation loss decreased (1.502193 --> 1.468507).  Saving model ...
Validation loss decreased (1.468507 --> 1.439208).  Saving model ...
Validation loss decreased (1.439208 --> 1.416804).  Saving model ...
Validation loss decreased (1.416804 --> 1.398336).  Saving model ...
Validation loss decreased (1.398336 --> 1.384506).  Saving model ...
Validation loss decreased (1.384506 --> 1.372771).  Saving model ...
Validation loss decreased (1.372771 --> 1.363955).  Saving model ...
Validation loss decreased (1.363955 --> 1.356256).  Saving model ...
Validation loss decreased (1.356256 --> 1.349074).  Saving model ...
Validation loss decreased (1.349074 --> 1.342360).  Saving model ...
Validation loss decreased (1.342360 --> 1.336207).  Saving model ...
Validation loss decreased (1.336207 --> 1.329274).  Saving model ...
Validation loss decreased (1.329274 --> 1.322996).  Saving model ...
Validation loss decreased (1.322996 --> 1.316241).  Saving model ...
Validation loss decreased (1.316241 --> 1.309268).  Saving model ...
Validation loss decreased (1.309268 --> 1.302574).  Saving model ...
Validation loss decreased (1.302574 --> 1.294574).  Saving model ...
Validation loss decreased (1.294574 --> 1.286444).  Saving model ...
Validation loss decreased (1.286444 --> 1.279103).  Saving model ...
Validation loss decreased (1.279103 --> 1.273434).  Saving model ...
Validation loss decreased (1.273434 --> 1.267075).  Saving model ...
Validation loss decreased (1.267075 --> 1.259337).  Saving model ...
Validation loss decreased (1.259337 --> 1.249899).  Saving model ...
Validation loss decreased (1.249899 --> 1.244330).  Saving model ...
Validation loss decreased (1.244330 --> 1.236628).  Saving model ...
Validation loss decreased (1.236628 --> 1.230133).  Saving model ...
Validation loss decreased (1.230133 --> 1.224562).  Saving model ...
Validation loss decreased (1.224562 --> 1.216888).  Saving model ...
Validation loss decreased (1.216888 --> 1.207445).  Saving model ...
Validation loss decreased (1.207445 --> 1.200377).  Saving model ...
Validation loss decreased (1.200377 --> 1.194905).  Saving model ...
Validation loss decreased (1.194905 --> 1.188735).  Saving model ...
Validation loss decreased (1.188735 --> 1.181556).  Saving model ...
Validation loss decreased (1.181556 --> 1.175320).  Saving model ...
Validation loss decreased (1.175320 --> 1.168929).  Saving model ...
Validation loss decreased (1.168929 --> 1.161723).  Saving model ...
Validation loss decreased (1.161723 --> 1.156280).  Saving model ...
Validation loss decreased (1.156280 --> 1.149161).  Saving model ...
Validation loss decreased (1.149161 --> 1.144375).  Saving model ...
Validation loss decreased (1.144375 --> 1.138220).  Saving model ...
Validation loss decreased (1.138220 --> 1.129258).  Saving model ...
Validation loss decreased (1.129258 --> 1.123644).  Saving model ...
Validation loss decreased (1.123644 --> 1.117683).  Saving model ...
Validation loss decreased (1.117683 --> 1.111073).  Saving model ...
Validation loss decreased (1.111073 --> 1.104121).  Saving model ...
Validation loss decreased (1.104121 --> 1.097212).  Saving model ...
Validation loss decreased (1.097212 --> 1.094254).  Saving model ...
Validation loss decreased (1.094254 --> 1.088996).  Saving model ...
Validation loss decreased (1.088996 --> 1.084299).  Saving model ...
Validation loss decreased (1.084299 --> 1.076619).  Saving model ...
Validation loss decreased (1.076619 --> 1.071082).  Saving model ...
Validation loss decreased (1.071082 --> 1.066202).  Saving model ...
Validation loss decreased (1.066202 --> 1.061793).  Saving model ...
Validation loss decreased (1.061793 --> 1.056606).  Saving model ...
Validation loss decreased (1.056606 --> 1.052920).  Saving model ...
Validation loss decreased (1.052920 --> 1.048517).  Saving model ...
Validation loss decreased (1.048517 --> 1.045678).  Saving model ...
Validation loss decreased (1.045678 --> 1.039295).  Saving model ...
Validation loss decreased (1.039295 --> 1.034803).  Saving model ...
Validation loss decreased (1.034803 --> 1.030153).  Saving model ...
Validation loss decreased (1.030153 --> 1.026578).  Saving model ...
Validation loss decreased (1.026578 --> 1.023626).  Saving model ...
Validation loss decreased (1.023626 --> 1.021462).  Saving model ...
Validation loss decreased (1.021462 --> 1.019708).  Saving model ...
Validation loss decreased (1.019708 --> 1.016886).  Saving model ...
Validation loss decreased (1.016886 --> 1.012285).  Saving model ...
Validation loss decreased (1.012285 --> 1.009604).  Saving model ...
Validation loss decreased (1.009604 --> 1.006615).  Saving model ...
Validation loss decreased (1.006615 --> 1.001505).  Saving model ...
Validation loss decreased (1.001505 --> 0.998091).  Saving model ...
Validation loss decreased (0.998091 --> 0.995528).  Saving model ...
EarlyStopping counter: 1 out of 10.0
Validation loss decreased (0.995528 --> 0.993502).  Saving model ...
Validation loss decreased (0.993502 --> 0.989749).  Saving model ...
Validation loss decreased (0.989749 --> 0.985977).  Saving model ...
Validation loss decreased (0.985977 --> 0.985350).  Saving model ...
Validation loss decreased (0.985350 --> 0.985316).  Saving model ...
Validation loss decreased (0.985316 --> 0.979189).  Saving model ...
Validation loss decreased (0.979189 --> 0.977449).  Saving model ...
EarlyStopping counter: 1 out of 10.0
Validation loss decreased (0.977449 --> 0.976257).  Saving model ...
Validation loss decreased (0.976257 --> 0.970409).  Saving model ...
Validation loss decreased (0.970409 --> 0.968484).  Saving model ...
EarlyStopping counter: 1 out of 10.0
Validation loss decreased (0.968484 --> 0.967613).  Saving model ...
EarlyStopping counter: 1 out of 10.0
Validation loss decreased (0.967613 --> 0.966991).  Saving model ...
Validation loss decreased (0.966991 --> 0.961448).  Saving model ...
Validation loss decreased (0.961448 --> 0.958958).  Saving model ...
Validation loss decreased (0.958958 --> 0.957811).  Saving model ...
EarlyStopping counter: 1 out of 10.0
EarlyStopping counter: 2 out of 10.0
EarlyStopping counter: 3 out of 10.0
Validation loss decreased (0.957811 --> 0.956133).  Saving model ...
Validation loss decreased (0.956133 --> 0.953081).  Saving model ...
Validation loss decreased (0.953081 --> 0.948613).  Saving model ...
EarlyStopping counter: 1 out of 10.0
Validation loss decreased (0.948613 --> 0.948194).  Saving model ...
EarlyStopping counter: 1 out of 10.0
Validation loss decreased (0.948194 --> 0.947946).  Saving model ...
Validation loss decreased (0.947946 --> 0.947360).  Saving model ...
Validation loss decreased (0.947360 --> 0.947071).  Saving model ...
EarlyStopping counter: 1 out of 10.0
Validation loss decreased (0.947071 --> 0.943607).  Saving model ...
EarlyStopping counter: 1 out of 10.0
EarlyStopping counter: 2 out of 10.0
Validation loss decreased (0.943607 --> 0.943130).  Saving model ...
Validation loss decreased (0.943130 --> 0.941796).  Saving model ...
Validation loss decreased (0.941796 --> 0.940865).  Saving model ...
Validation loss decreased (0.940865 --> 0.940843).  Saving model ...
Validation loss decreased (0.940843 --> 0.940375).  Saving model ...
EarlyStopping counter: 1 out of 10.0
EarlyStopping counter: 2 out of 10.0
EarlyStopping counter: 3 out of 10.0
EarlyStopping counter: 4 out of 10.0
EarlyStopping counter: 5 out of 10.0
EarlyStopping counter: 6 out of 10.0
EarlyStopping counter: 7 out of 10.0
EarlyStopping counter: 8 out of 10.0
EarlyStopping counter: 9 out of 10.0
EarlyStopping counter: 10 out of 10.0
/localscratch/yinan.29351703.0/env/lib/python3.7/site-packages/torch/nn/functional.py:1794: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.
  warnings.warn("nn.functional.tanh is deprecated. Use torch.tanh instead.")
wandb: Waiting for W&B process to finish, PID 141396... (success).
wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: \ 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: | 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: / 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: \ 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: | 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: / 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: \ 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: | 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: / 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb:                                                                                
wandb: Run history:
wandb:     e_F1 ▁▃▄▄▄▄▅▅▅▅▆▆▆▆▇▇▇▇▇▇▇▇██████████████████
wandb:   e_loss █▇▆▆▆▅▅▅▅▄▄▄▄▃▃▃▃▂▂▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:     t_F1 ▁▂▂▃▃▄▄▅▅▅▅▅▆▆▆▅▆▇▆▆▆▆▇▇▇▇▇▇▇▇▇▇▇▇▇▇████
wandb:   t_loss █▇▇▇▆▆▆▆▅▅▅▅▅▄▄▄▄▄▃▃▃▃▃▃▃▃▂▂▂▂▂▂▂▂▂▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:     e_F1 60.82802
wandb:   e_loss 0.94112
wandb:     t_F1 74.98549
wandb:   t_loss 0.73819
wandb: 
wandb: Synced 4 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Synced soft-plasma-1: https://wandb.ai/yinanazhou/xl_512_bs_8_lr_1e06_es_10_lc_True_nr_False_sr_True_stem_False_lemma_True_repeat_3_fold_1/runs/30oohavf
wandb: Find logs at: ./wandb/run-20220327_142359-30oohavf/logs/debug.log
wandb: 

wandb: wandb version 0.12.11 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
2022-03-27 15:44:02.196470: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1
wandb: Tracking run with wandb version 0.12.5
wandb: Syncing run super-planet-1
wandb: ⭐️ View project at https://wandb.ai/yinanazhou/xl_512_bs_8_lr_1e06_es_10_lc_True_nr_False_sr_True_stem_False_lemma_True_repeat_3_fold_2
wandb: 🚀 View run at https://wandb.ai/yinanazhou/xl_512_bs_8_lr_1e06_es_10_lc_True_nr_False_sr_True_stem_False_lemma_True_repeat_3_fold_2/runs/3qjd2shn
wandb: Run data is saved locally in /project/6002780/yinan/Thesis_MER_Lyrics/lyric-emotion/wandb/run-20220327_154359-3qjd2shn
wandb: Run `wandb offline` to turn off syncing.

Validation loss decreased (inf --> 1.414874).  Saving model ...
Validation loss decreased (1.414874 --> 1.399276).  Saving model ...
Validation loss decreased (1.399276 --> 1.388017).  Saving model ...
Validation loss decreased (1.388017 --> 1.379641).  Saving model ...
Validation loss decreased (1.379641 --> 1.373499).  Saving model ...
Validation loss decreased (1.373499 --> 1.368085).  Saving model ...
Validation loss decreased (1.368085 --> 1.363082).  Saving model ...
Validation loss decreased (1.363082 --> 1.358233).  Saving model ...
Validation loss decreased (1.358233 --> 1.353639).  Saving model ...
Validation loss decreased (1.353639 --> 1.348936).  Saving model ...
Validation loss decreased (1.348936 --> 1.344163).  Saving model ...
Validation loss decreased (1.344163 --> 1.339399).  Saving model ...
Validation loss decreased (1.339399 --> 1.334276).  Saving model ...
Validation loss decreased (1.334276 --> 1.329032).  Saving model ...
Validation loss decreased (1.329032 --> 1.323189).  Saving model ...
Validation loss decreased (1.323189 --> 1.316994).  Saving model ...
Validation loss decreased (1.316994 --> 1.310798).  Saving model ...
Validation loss decreased (1.310798 --> 1.303760).  Saving model ...
Validation loss decreased (1.303760 --> 1.297462).  Saving model ...
Validation loss decreased (1.297462 --> 1.290700).  Saving model ...
Validation loss decreased (1.290700 --> 1.283661).  Saving model ...
Validation loss decreased (1.283661 --> 1.276340).  Saving model ...
Validation loss decreased (1.276340 --> 1.268119).  Saving model ...
Validation loss decreased (1.268119 --> 1.259242).  Saving model ...
Validation loss decreased (1.259242 --> 1.250999).  Saving model ...
Validation loss decreased (1.250999 --> 1.242928).  Saving model ...
Validation loss decreased (1.242928 --> 1.234681).  Saving model ...
Validation loss decreased (1.234681 --> 1.226375).  Saving model ...
Validation loss decreased (1.226375 --> 1.218040).  Saving model ...
Validation loss decreased (1.218040 --> 1.209296).  Saving model ...
Validation loss decreased (1.209296 --> 1.202147).  Saving model ...
Validation loss decreased (1.202147 --> 1.193868).  Saving model ...
Validation loss decreased (1.193868 --> 1.186586).  Saving model ...
Validation loss decreased (1.186586 --> 1.179792).  Saving model ...
Validation loss decreased (1.179792 --> 1.173134).  Saving model ...
Validation loss decreased (1.173134 --> 1.165365).  Saving model ...
Validation loss decreased (1.165365 --> 1.158257).  Saving model ...
Validation loss decreased (1.158257 --> 1.151187).  Saving model ...
Validation loss decreased (1.151187 --> 1.143546).  Saving model ...
Validation loss decreased (1.143546 --> 1.137342).  Saving model ...
Validation loss decreased (1.137342 --> 1.131183).  Saving model ...
Validation loss decreased (1.131183 --> 1.124971).  Saving model ...
Validation loss decreased (1.124971 --> 1.119680).  Saving model ...
Validation loss decreased (1.119680 --> 1.115235).  Saving model ...
Validation loss decreased (1.115235 --> 1.110428).  Saving model ...
Validation loss decreased (1.110428 --> 1.105121).  Saving model ...
Validation loss decreased (1.105121 --> 1.099519).  Saving model ...
Validation loss decreased (1.099519 --> 1.094032).  Saving model ...
Validation loss decreased (1.094032 --> 1.087813).  Saving model ...
Validation loss decreased (1.087813 --> 1.082716).  Saving model ...
Validation loss decreased (1.082716 --> 1.077838).  Saving model ...
Validation loss decreased (1.077838 --> 1.072844).  Saving model ...
Validation loss decreased (1.072844 --> 1.068399).  Saving model ...
Validation loss decreased (1.068399 --> 1.065391).  Saving model ...
Validation loss decreased (1.065391 --> 1.061505).  Saving model ...
Validation loss decreased (1.061505 --> 1.056075).  Saving model ...
Validation loss decreased (1.056075 --> 1.055729).  Saving model ...
Validation loss decreased (1.055729 --> 1.050542).  Saving model ...
Validation loss decreased (1.050542 --> 1.047143).  Saving model ...
Validation loss decreased (1.047143 --> 1.041859).  Saving model ...
Validation loss decreased (1.041859 --> 1.036682).  Saving model ...
Validation loss decreased (1.036682 --> 1.033145).  Saving model ...
Validation loss decreased (1.033145 --> 1.029161).  Saving model ...
Validation loss decreased (1.029161 --> 1.025747).  Saving model ...
Validation loss decreased (1.025747 --> 1.020848).  Saving model ...
Validation loss decreased (1.020848 --> 1.017306).  Saving model ...
Validation loss decreased (1.017306 --> 1.013906).  Saving model ...
Validation loss decreased (1.013906 --> 1.011515).  Saving model ...
Validation loss decreased (1.011515 --> 1.010174).  Saving model ...
Validation loss decreased (1.010174 --> 1.007250).  Saving model ...
Validation loss decreased (1.007250 --> 1.003739).  Saving model ...
Validation loss decreased (1.003739 --> 1.002545).  Saving model ...
Validation loss decreased (1.002545 --> 0.997097).  Saving model ...
Validation loss decreased (0.997097 --> 0.993672).  Saving model ...
Validation loss decreased (0.993672 --> 0.991724).  Saving model ...
Validation loss decreased (0.991724 --> 0.991062).  Saving model ...
Validation loss decreased (0.991062 --> 0.989528).  Saving model ...
Validation loss decreased (0.989528 --> 0.987207).  Saving model ...
Validation loss decreased (0.987207 --> 0.983283).  Saving model ...
Validation loss decreased (0.983283 --> 0.981668).  Saving model ...
Validation loss decreased (0.981668 --> 0.979795).  Saving model ...
Validation loss decreased (0.979795 --> 0.976874).  Saving model ...
Validation loss decreased (0.976874 --> 0.973822).  Saving model ...
Validation loss decreased (0.973822 --> 0.972181).  Saving model ...
Validation loss decreased (0.972181 --> 0.969005).  Saving model ...
Validation loss decreased (0.969005 --> 0.965757).  Saving model ...
Validation loss decreased (0.965757 --> 0.965433).  Saving model ...
Validation loss decreased (0.965433 --> 0.963948).  Saving model ...
Validation loss decreased (0.963948 --> 0.962226).  Saving model ...
Validation loss decreased (0.962226 --> 0.960943).  Saving model ...
Validation loss decreased (0.960943 --> 0.959125).  Saving model ...
Validation loss decreased (0.959125 --> 0.957411).  Saving model ...
Validation loss decreased (0.957411 --> 0.956853).  Saving model ...
Validation loss decreased (0.956853 --> 0.955356).  Saving model ...
Validation loss decreased (0.955356 --> 0.953026).  Saving model ...
Validation loss decreased (0.953026 --> 0.950368).  Saving model ...
Validation loss decreased (0.950368 --> 0.947907).  Saving model ...
EarlyStopping counter: 1 out of 10.0
Validation loss decreased (0.947907 --> 0.947425).  Saving model ...
Validation loss decreased (0.947425 --> 0.946704).  Saving model ...
Validation loss decreased (0.946704 --> 0.946095).  Saving model ...
Validation loss decreased (0.946095 --> 0.945224).  Saving model ...
Validation loss decreased (0.945224 --> 0.943096).  Saving model ...
Validation loss decreased (0.943096 --> 0.940974).  Saving model ...
Validation loss decreased (0.940974 --> 0.940360).  Saving model ...
Validation loss decreased (0.940360 --> 0.937516).  Saving model ...
Validation loss decreased (0.937516 --> 0.937365).  Saving model ...
Validation loss decreased (0.937365 --> 0.936543).  Saving model ...
Validation loss decreased (0.936543 --> 0.934608).  Saving model ...
Validation loss decreased (0.934608 --> 0.932592).  Saving model ...
Validation loss decreased (0.932592 --> 0.931506).  Saving model ...
EarlyStopping counter: 1 out of 10.0
EarlyStopping counter: 2 out of 10.0
Validation loss decreased (0.931506 --> 0.931498).  Saving model ...
EarlyStopping counter: 1 out of 10.0
Validation loss decreased (0.931498 --> 0.929974).  Saving model ...
Validation loss decreased (0.929974 --> 0.929656).  Saving model ...
Validation loss decreased (0.929656 --> 0.929192).  Saving model ...
Validation loss decreased (0.929192 --> 0.928584).  Saving model ...
Validation loss decreased (0.928584 --> 0.926933).  Saving model ...
Validation loss decreased (0.926933 --> 0.925866).  Saving model ...
EarlyStopping counter: 1 out of 10.0
EarlyStopping counter: 2 out of 10.0
EarlyStopping counter: 3 out of 10.0
Validation loss decreased (0.925866 --> 0.923278).  Saving model ...
EarlyStopping counter: 1 out of 10.0
EarlyStopping counter: 2 out of 10.0
EarlyStopping counter: 3 out of 10.0
EarlyStopping counter: 4 out of 10.0
Validation loss decreased (0.923278 --> 0.922940).  Saving model ...
EarlyStopping counter: 1 out of 10.0
EarlyStopping counter: 2 out of 10.0
EarlyStopping counter: 3 out of 10.0
Validation loss decreased (0.922940 --> 0.922435).  Saving model ...
Validation loss decreased (0.922435 --> 0.921029).  Saving model ...
EarlyStopping counter: 1 out of 10.0
EarlyStopping counter: 2 out of 10.0
EarlyStopping counter: 3 out of 10.0
Validation loss decreased (0.921029 --> 0.919537).  Saving model ...
EarlyStopping counter: 1 out of 10.0
EarlyStopping counter: 2 out of 10.0
EarlyStopping counter: 3 out of 10.0
EarlyStopping counter: 4 out of 10.0
EarlyStopping counter: 5 out of 10.0
EarlyStopping counter: 6 out of 10.0
EarlyStopping counter: 7 out of 10.0
EarlyStopping counter: 8 out of 10.0
Validation loss decreased (0.919537 --> 0.917545).  Saving model ...
EarlyStopping counter: 1 out of 10.0
EarlyStopping counter: 2 out of 10.0
EarlyStopping counter: 3 out of 10.0
EarlyStopping counter: 4 out of 10.0
EarlyStopping counter: 5 out of 10.0
EarlyStopping counter: 6 out of 10.0
EarlyStopping counter: 7 out of 10.0
EarlyStopping counter: 8 out of 10.0
EarlyStopping counter: 9 out of 10.0
EarlyStopping counter: 10 out of 10.0
/localscratch/yinan.29351703.0/env/lib/python3.7/site-packages/torch/nn/functional.py:1794: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.
  warnings.warn("nn.functional.tanh is deprecated. Use torch.tanh instead.")
wandb: Waiting for W&B process to finish, PID 145674... (success).
wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: \ 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: | 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: / 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: \ 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: | 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: / 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: \ 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: | 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: / 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb:                                                                                
wandb: Run history:
wandb:     e_F1 ▁▁▃▄▅▆▆▆▆▆▆▆▇▇▇▇▇▇▇▇▇▇▇▇████████████████
wandb:   e_loss ██▇▇▇▆▆▅▅▄▄▄▃▃▃▃▂▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:     t_F1 ▁▂▂▃▃▃▄▅▅▅▅▅▆▆▆▆▆▆▇▆▇▇▇▇▇▇▇▇▇▇▇▇▇▇██████
wandb:   t_loss ███▇▇▇▆▆▆▆▅▅▅▄▄▄▄▄▃▃▃▃▃▃▃▃▂▂▂▂▂▂▂▂▁▂▁▁▂▁
wandb: 
wandb: Run summary:
wandb:     e_F1 64.30686
wandb:   e_loss 0.91813
wandb:     t_F1 73.13942
wandb:   t_loss 0.68891
wandb: 
wandb: Synced 4 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Synced super-planet-1: https://wandb.ai/yinanazhou/xl_512_bs_8_lr_1e06_es_10_lc_True_nr_False_sr_True_stem_False_lemma_True_repeat_3_fold_2/runs/3qjd2shn
wandb: Find logs at: ./wandb/run-20220327_154359-3qjd2shn/logs/debug.log
wandb: 

wandb: wandb version 0.12.11 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
2022-03-27 17:26:42.630352: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1
wandb: Tracking run with wandb version 0.12.5
wandb: Syncing run fresh-snowflake-1
wandb: ⭐️ View project at https://wandb.ai/yinanazhou/xl_512_bs_8_lr_1e06_es_10_lc_True_nr_False_sr_True_stem_False_lemma_True_repeat_4_fold_1
wandb: 🚀 View run at https://wandb.ai/yinanazhou/xl_512_bs_8_lr_1e06_es_10_lc_True_nr_False_sr_True_stem_False_lemma_True_repeat_4_fold_1/runs/n5iyel17
wandb: Run data is saved locally in /project/6002780/yinan/Thesis_MER_Lyrics/lyric-emotion/wandb/run-20220327_172640-n5iyel17
wandb: Run `wandb offline` to turn off syncing.

Validation loss decreased (inf --> 1.395467).  Saving model ...
Validation loss decreased (1.395467 --> 1.386891).  Saving model ...
Validation loss decreased (1.386891 --> 1.379873).  Saving model ...
Validation loss decreased (1.379873 --> 1.374223).  Saving model ...
Validation loss decreased (1.374223 --> 1.368851).  Saving model ...
Validation loss decreased (1.368851 --> 1.364180).  Saving model ...
Validation loss decreased (1.364180 --> 1.359554).  Saving model ...
Validation loss decreased (1.359554 --> 1.355460).  Saving model ...
Validation loss decreased (1.355460 --> 1.351502).  Saving model ...
Validation loss decreased (1.351502 --> 1.347505).  Saving model ...
Validation loss decreased (1.347505 --> 1.343508).  Saving model ...
Validation loss decreased (1.343508 --> 1.339181).  Saving model ...
Validation loss decreased (1.339181 --> 1.334727).  Saving model ...
Validation loss decreased (1.334727 --> 1.330761).  Saving model ...
Validation loss decreased (1.330761 --> 1.326232).  Saving model ...
Validation loss decreased (1.326232 --> 1.322072).  Saving model ...
Validation loss decreased (1.322072 --> 1.317602).  Saving model ...
Validation loss decreased (1.317602 --> 1.312901).  Saving model ...
Validation loss decreased (1.312901 --> 1.307813).  Saving model ...
Validation loss decreased (1.307813 --> 1.302746).  Saving model ...
Validation loss decreased (1.302746 --> 1.297839).  Saving model ...
Validation loss decreased (1.297839 --> 1.292715).  Saving model ...
Validation loss decreased (1.292715 --> 1.287139).  Saving model ...
Validation loss decreased (1.287139 --> 1.281578).  Saving model ...
Validation loss decreased (1.281578 --> 1.275924).  Saving model ...
Validation loss decreased (1.275924 --> 1.269358).  Saving model ...
Validation loss decreased (1.269358 --> 1.263404).  Saving model ...
Validation loss decreased (1.263404 --> 1.257047).  Saving model ...
Validation loss decreased (1.257047 --> 1.250076).  Saving model ...
Validation loss decreased (1.250076 --> 1.243357).  Saving model ...
Validation loss decreased (1.243357 --> 1.235668).  Saving model ...
Validation loss decreased (1.235668 --> 1.228237).  Saving model ...
Validation loss decreased (1.228237 --> 1.221720).  Saving model ...
Validation loss decreased (1.221720 --> 1.214660).  Saving model ...
Validation loss decreased (1.214660 --> 1.207292).  Saving model ...
Validation loss decreased (1.207292 --> 1.200352).  Saving model ...
Validation loss decreased (1.200352 --> 1.192631).  Saving model ...
Validation loss decreased (1.192631 --> 1.185585).  Saving model ...
Validation loss decreased (1.185585 --> 1.178419).  Saving model ...
Validation loss decreased (1.178419 --> 1.171556).  Saving model ...
Validation loss decreased (1.171556 --> 1.165009).  Saving model ...
Validation loss decreased (1.165009 --> 1.159422).  Saving model ...
Validation loss decreased (1.159422 --> 1.153354).  Saving model ...
Validation loss decreased (1.153354 --> 1.146561).  Saving model ...
Validation loss decreased (1.146561 --> 1.140068).  Saving model ...
Validation loss decreased (1.140068 --> 1.134743).  Saving model ...
Validation loss decreased (1.134743 --> 1.128491).  Saving model ...
Validation loss decreased (1.128491 --> 1.123024).  Saving model ...
Validation loss decreased (1.123024 --> 1.117112).  Saving model ...
Validation loss decreased (1.117112 --> 1.112120).  Saving model ...
Validation loss decreased (1.112120 --> 1.106195).  Saving model ...
Validation loss decreased (1.106195 --> 1.101408).  Saving model ...
Validation loss decreased (1.101408 --> 1.095348).  Saving model ...
Validation loss decreased (1.095348 --> 1.090517).  Saving model ...
Validation loss decreased (1.090517 --> 1.085095).  Saving model ...
Validation loss decreased (1.085095 --> 1.080099).  Saving model ...
Validation loss decreased (1.080099 --> 1.075511).  Saving model ...
Validation loss decreased (1.075511 --> 1.071239).  Saving model ...
Validation loss decreased (1.071239 --> 1.067908).  Saving model ...
Validation loss decreased (1.067908 --> 1.063701).  Saving model ...
Validation loss decreased (1.063701 --> 1.058904).  Saving model ...
Validation loss decreased (1.058904 --> 1.055384).  Saving model ...
Validation loss decreased (1.055384 --> 1.051585).  Saving model ...
Validation loss decreased (1.051585 --> 1.047801).  Saving model ...
Validation loss decreased (1.047801 --> 1.044572).  Saving model ...
Validation loss decreased (1.044572 --> 1.042345).  Saving model ...
Validation loss decreased (1.042345 --> 1.038371).  Saving model ...
Validation loss decreased (1.038371 --> 1.034770).  Saving model ...
Validation loss decreased (1.034770 --> 1.031273).  Saving model ...
Validation loss decreased (1.031273 --> 1.028665).  Saving model ...
Validation loss decreased (1.028665 --> 1.025728).  Saving model ...
Validation loss decreased (1.025728 --> 1.023014).  Saving model ...
Validation loss decreased (1.023014 --> 1.019290).  Saving model ...
Validation loss decreased (1.019290 --> 1.015701).  Saving model ...
Validation loss decreased (1.015701 --> 1.013431).  Saving model ...
Validation loss decreased (1.013431 --> 1.012246).  Saving model ...
Validation loss decreased (1.012246 --> 1.009295).  Saving model ...
Validation loss decreased (1.009295 --> 1.006618).  Saving model ...
Validation loss decreased (1.006618 --> 1.003575).  Saving model ...
Validation loss decreased (1.003575 --> 1.000504).  Saving model ...
Validation loss decreased (1.000504 --> 0.997635).  Saving model ...
Validation loss decreased (0.997635 --> 0.995927).  Saving model ...
Validation loss decreased (0.995927 --> 0.994321).  Saving model ...
Validation loss decreased (0.994321 --> 0.993364).  Saving model ...
Validation loss decreased (0.993364 --> 0.992014).  Saving model ...
Validation loss decreased (0.992014 --> 0.989511).  Saving model ...
Validation loss decreased (0.989511 --> 0.987489).  Saving model ...
Validation loss decreased (0.987489 --> 0.986109).  Saving model ...
Validation loss decreased (0.986109 --> 0.985243).  Saving model ...
Validation loss decreased (0.985243 --> 0.983243).  Saving model ...
Validation loss decreased (0.983243 --> 0.982612).  Saving model ...
Validation loss decreased (0.982612 --> 0.980791).  Saving model ...
Validation loss decreased (0.980791 --> 0.978317).  Saving model ...
Validation loss decreased (0.978317 --> 0.978029).  Saving model ...
Validation loss decreased (0.978029 --> 0.977655).  Saving model ...
Validation loss decreased (0.977655 --> 0.976934).  Saving model ...
Validation loss decreased (0.976934 --> 0.974303).  Saving model ...
Validation loss decreased (0.974303 --> 0.973880).  Saving model ...
Validation loss decreased (0.973880 --> 0.972050).  Saving model ...
Validation loss decreased (0.972050 --> 0.969330).  Saving model ...
EarlyStopping counter: 1 out of 10.0
Validation loss decreased (0.969330 --> 0.968939).  Saving model ...
Validation loss decreased (0.968939 --> 0.968509).  Saving model ...
Validation loss decreased (0.968509 --> 0.967544).  Saving model ...
Validation loss decreased (0.967544 --> 0.966265).  Saving model ...
Validation loss decreased (0.966265 --> 0.964949).  Saving model ...
Validation loss decreased (0.964949 --> 0.963887).  Saving model ...
EarlyStopping counter: 1 out of 10.0
Validation loss decreased (0.963887 --> 0.962323).  Saving model ...
Validation loss decreased (0.962323 --> 0.959227).  Saving model ...
Validation loss decreased (0.959227 --> 0.958343).  Saving model ...
EarlyStopping counter: 1 out of 10.0
EarlyStopping counter: 2 out of 10.0
EarlyStopping counter: 3 out of 10.0
Validation loss decreased (0.958343 --> 0.958317).  Saving model ...
Validation loss decreased (0.958317 --> 0.956469).  Saving model ...
EarlyStopping counter: 1 out of 10.0
EarlyStopping counter: 2 out of 10.0
EarlyStopping counter: 3 out of 10.0
Validation loss decreased (0.956469 --> 0.956434).  Saving model ...
EarlyStopping counter: 1 out of 10.0
EarlyStopping counter: 2 out of 10.0
EarlyStopping counter: 3 out of 10.0
EarlyStopping counter: 4 out of 10.0
EarlyStopping counter: 5 out of 10.0
EarlyStopping counter: 6 out of 10.0
Validation loss decreased (0.956434 --> 0.955395).  Saving model ...
EarlyStopping counter: 1 out of 10.0
EarlyStopping counter: 2 out of 10.0
Validation loss decreased (0.955395 --> 0.953364).  Saving model ...
EarlyStopping counter: 1 out of 10.0
Validation loss decreased (0.953364 --> 0.952773).  Saving model ...
Validation loss decreased (0.952773 --> 0.952465).  Saving model ...
EarlyStopping counter: 1 out of 10.0
Validation loss decreased (0.952465 --> 0.951052).  Saving model ...
Validation loss decreased (0.951052 --> 0.949804).  Saving model ...
EarlyStopping counter: 1 out of 10.0
EarlyStopping counter: 2 out of 10.0
EarlyStopping counter: 3 out of 10.0
EarlyStopping counter: 4 out of 10.0
EarlyStopping counter: 5 out of 10.0
EarlyStopping counter: 6 out of 10.0
EarlyStopping counter: 7 out of 10.0
EarlyStopping counter: 8 out of 10.0
EarlyStopping counter: 9 out of 10.0
EarlyStopping counter: 10 out of 10.0
/localscratch/yinan.29351703.0/env/lib/python3.7/site-packages/torch/nn/functional.py:1794: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.
  warnings.warn("nn.functional.tanh is deprecated. Use torch.tanh instead.")
wandb: Waiting for W&B process to finish, PID 151144... (success).
wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: \ 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: | 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: / 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: \ 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: | 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: / 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: \ 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: | 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: / 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: \ 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: | 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb:                                                                                
wandb: Run history:
wandb:     e_F1 ▁▂▃▄▄▅▅▅▅▆▆▆▆▇▇▇▇▇▇▇▇▇▇▇▇███████████████
wandb:   e_loss ██▇▇▇▇▆▆▆▅▅▄▄▄▃▃▃▃▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:     t_F1 ▁▁▂▃▃▃▃▄▄▄▅▅▅▆▆▆▆▆▆▇▇▇▇▇▇▇▇▇▇▇▇█▇██▇████
wandb:   t_loss ███▇▇▇▇▇▆▆▆▅▅▅▄▄▄▄▄▃▃▃▃▃▃▂▂▂▂▂▂▂▂▂▁▂▁▁▁▁
wandb: 
wandb: Run summary:
wandb:     e_F1 60.87561
wandb:   e_loss 0.95535
wandb:     t_F1 71.16707
wandb:   t_loss 0.7147
wandb: 
wandb: Synced 4 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Synced fresh-snowflake-1: https://wandb.ai/yinanazhou/xl_512_bs_8_lr_1e06_es_10_lc_True_nr_False_sr_True_stem_False_lemma_True_repeat_4_fold_1/runs/n5iyel17
wandb: Find logs at: ./wandb/run-20220327_172640-n5iyel17/logs/debug.log
wandb: 

wandb: wandb version 0.12.11 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
2022-03-27 19:02:53.645967: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1
wandb: Tracking run with wandb version 0.12.5
wandb: Syncing run olive-yogurt-1
wandb: ⭐️ View project at https://wandb.ai/yinanazhou/xl_512_bs_8_lr_1e06_es_10_lc_True_nr_False_sr_True_stem_False_lemma_True_repeat_4_fold_2
wandb: 🚀 View run at https://wandb.ai/yinanazhou/xl_512_bs_8_lr_1e06_es_10_lc_True_nr_False_sr_True_stem_False_lemma_True_repeat_4_fold_2/runs/2mpbt41f
wandb: Run data is saved locally in /project/6002780/yinan/Thesis_MER_Lyrics/lyric-emotion/wandb/run-20220327_190251-2mpbt41f
wandb: Run `wandb offline` to turn off syncing.

Validation loss decreased (inf --> 1.409357).  Saving model ...
Validation loss decreased (1.409357 --> 1.402604).  Saving model ...
Validation loss decreased (1.402604 --> 1.396695).  Saving model ...
Validation loss decreased (1.396695 --> 1.391734).  Saving model ...
Validation loss decreased (1.391734 --> 1.387297).  Saving model ...
Validation loss decreased (1.387297 --> 1.383826).  Saving model ...
Validation loss decreased (1.383826 --> 1.380084).  Saving model ...
Validation loss decreased (1.380084 --> 1.375837).  Saving model ...
Validation loss decreased (1.375837 --> 1.371989).  Saving model ...
Validation loss decreased (1.371989 --> 1.368308).  Saving model ...
Validation loss decreased (1.368308 --> 1.364456).  Saving model ...
Validation loss decreased (1.364456 --> 1.360870).  Saving model ...
Validation loss decreased (1.360870 --> 1.357135).  Saving model ...
Validation loss decreased (1.357135 --> 1.352964).  Saving model ...
Validation loss decreased (1.352964 --> 1.349238).  Saving model ...
Validation loss decreased (1.349238 --> 1.345229).  Saving model ...
Validation loss decreased (1.345229 --> 1.341406).  Saving model ...
Validation loss decreased (1.341406 --> 1.336968).  Saving model ...
Validation loss decreased (1.336968 --> 1.332883).  Saving model ...
Validation loss decreased (1.332883 --> 1.328248).  Saving model ...
Validation loss decreased (1.328248 --> 1.324366).  Saving model ...
Validation loss decreased (1.324366 --> 1.319689).  Saving model ...
Validation loss decreased (1.319689 --> 1.313909).  Saving model ...
Validation loss decreased (1.313909 --> 1.307432).  Saving model ...
Validation loss decreased (1.307432 --> 1.301500).  Saving model ...
Validation loss decreased (1.301500 --> 1.295980).  Saving model ...
Validation loss decreased (1.295980 --> 1.289229).  Saving model ...
Validation loss decreased (1.289229 --> 1.281872).  Saving model ...
Validation loss decreased (1.281872 --> 1.274433).  Saving model ...
Validation loss decreased (1.274433 --> 1.264102).  Saving model ...
Validation loss decreased (1.264102 --> 1.255904).  Saving model ...
Validation loss decreased (1.255904 --> 1.247458).  Saving model ...
Validation loss decreased (1.247458 --> 1.234846).  Saving model ...
Validation loss decreased (1.234846 --> 1.226950).  Saving model ...
Validation loss decreased (1.226950 --> 1.217936).  Saving model ...
Validation loss decreased (1.217936 --> 1.209281).  Saving model ...
Validation loss decreased (1.209281 --> 1.201563).  Saving model ...
Validation loss decreased (1.201563 --> 1.194096).  Saving model ...
Validation loss decreased (1.194096 --> 1.185537).  Saving model ...
Validation loss decreased (1.185537 --> 1.176543).  Saving model ...
Validation loss decreased (1.176543 --> 1.166553).  Saving model ...
Validation loss decreased (1.166553 --> 1.158157).  Saving model ...
Validation loss decreased (1.158157 --> 1.151593).  Saving model ...
Validation loss decreased (1.151593 --> 1.142174).  Saving model ...
Validation loss decreased (1.142174 --> 1.131029).  Saving model ...
Validation loss decreased (1.131029 --> 1.125245).  Saving model ...
Validation loss decreased (1.125245 --> 1.120960).  Saving model ...
Validation loss decreased (1.120960 --> 1.115150).  Saving model ...
Validation loss decreased (1.115150 --> 1.108360).  Saving model ...
Validation loss decreased (1.108360 --> 1.101353).  Saving model ...
Validation loss decreased (1.101353 --> 1.095818).  Saving model ...
Validation loss decreased (1.095818 --> 1.091785).  Saving model ...
Validation loss decreased (1.091785 --> 1.087010).  Saving model ...
Validation loss decreased (1.087010 --> 1.081446).  Saving model ...
Validation loss decreased (1.081446 --> 1.077808).  Saving model ...
Validation loss decreased (1.077808 --> 1.070972).  Saving model ...
Validation loss decreased (1.070972 --> 1.066826).  Saving model ...
Validation loss decreased (1.066826 --> 1.062350).  Saving model ...
Validation loss decreased (1.062350 --> 1.056573).  Saving model ...
Validation loss decreased (1.056573 --> 1.053500).  Saving model ...
Validation loss decreased (1.053500 --> 1.052441).  Saving model ...
Validation loss decreased (1.052441 --> 1.046326).  Saving model ...
Validation loss decreased (1.046326 --> 1.041798).  Saving model ...
Validation loss decreased (1.041798 --> 1.036988).  Saving model ...
Validation loss decreased (1.036988 --> 1.033007).  Saving model ...
Validation loss decreased (1.033007 --> 1.026503).  Saving model ...
Validation loss decreased (1.026503 --> 1.025759).  Saving model ...
Validation loss decreased (1.025759 --> 1.021595).  Saving model ...
Validation loss decreased (1.021595 --> 1.018659).  Saving model ...
Validation loss decreased (1.018659 --> 1.015008).  Saving model ...
Validation loss decreased (1.015008 --> 1.012905).  Saving model ...
Validation loss decreased (1.012905 --> 1.009680).  Saving model ...
Validation loss decreased (1.009680 --> 1.009624).  Saving model ...
Validation loss decreased (1.009624 --> 1.004221).  Saving model ...
Validation loss decreased (1.004221 --> 1.000004).  Saving model ...
Validation loss decreased (1.000004 --> 0.996569).  Saving model ...
Validation loss decreased (0.996569 --> 0.993737).  Saving model ...
Validation loss decreased (0.993737 --> 0.992681).  Saving model ...
Validation loss decreased (0.992681 --> 0.992470).  Saving model ...
Validation loss decreased (0.992470 --> 0.990432).  Saving model ...
Validation loss decreased (0.990432 --> 0.988008).  Saving model ...
Validation loss decreased (0.988008 --> 0.983153).  Saving model ...
Validation loss decreased (0.983153 --> 0.981518).  Saving model ...
Validation loss decreased (0.981518 --> 0.979629).  Saving model ...
Validation loss decreased (0.979629 --> 0.976773).  Saving model ...
Validation loss decreased (0.976773 --> 0.974939).  Saving model ...
EarlyStopping counter: 1 out of 10.0
Validation loss decreased (0.974939 --> 0.972090).  Saving model ...
Validation loss decreased (0.972090 --> 0.971537).  Saving model ...
Validation loss decreased (0.971537 --> 0.969884).  Saving model ...
Validation loss decreased (0.969884 --> 0.968374).  Saving model ...
Validation loss decreased (0.968374 --> 0.966443).  Saving model ...
Validation loss decreased (0.966443 --> 0.964334).  Saving model ...
Validation loss decreased (0.964334 --> 0.963585).  Saving model ...
Validation loss decreased (0.963585 --> 0.961010).  Saving model ...
Validation loss decreased (0.961010 --> 0.959278).  Saving model ...
Validation loss decreased (0.959278 --> 0.958430).  Saving model ...
Validation loss decreased (0.958430 --> 0.957382).  Saving model ...
Validation loss decreased (0.957382 --> 0.956835).  Saving model ...
Validation loss decreased (0.956835 --> 0.955525).  Saving model ...
Validation loss decreased (0.955525 --> 0.954231).  Saving model ...
Validation loss decreased (0.954231 --> 0.952285).  Saving model ...
Validation loss decreased (0.952285 --> 0.952017).  Saving model ...
Validation loss decreased (0.952017 --> 0.951434).  Saving model ...
Validation loss decreased (0.951434 --> 0.951016).  Saving model ...
Validation loss decreased (0.951016 --> 0.950424).  Saving model ...
Validation loss decreased (0.950424 --> 0.949514).  Saving model ...
EarlyStopping counter: 1 out of 10.0
Validation loss decreased (0.949514 --> 0.948223).  Saving model ...
Validation loss decreased (0.948223 --> 0.946369).  Saving model ...
Validation loss decreased (0.946369 --> 0.944037).  Saving model ...
EarlyStopping counter: 1 out of 10.0
EarlyStopping counter: 2 out of 10.0
Validation loss decreased (0.944037 --> 0.943857).  Saving model ...
Validation loss decreased (0.943857 --> 0.942243).  Saving model ...
Validation loss decreased (0.942243 --> 0.941544).  Saving model ...
Validation loss decreased (0.941544 --> 0.940947).  Saving model ...
EarlyStopping counter: 1 out of 10.0
EarlyStopping counter: 2 out of 10.0
EarlyStopping counter: 3 out of 10.0
Validation loss decreased (0.940947 --> 0.940730).  Saving model ...
EarlyStopping counter: 1 out of 10.0
EarlyStopping counter: 2 out of 10.0
EarlyStopping counter: 3 out of 10.0
EarlyStopping counter: 4 out of 10.0
EarlyStopping counter: 5 out of 10.0
EarlyStopping counter: 6 out of 10.0
Validation loss decreased (0.940730 --> 0.939935).  Saving model ...
Validation loss decreased (0.939935 --> 0.939715).  Saving model ...
Validation loss decreased (0.939715 --> 0.938558).  Saving model ...
EarlyStopping counter: 1 out of 10.0
EarlyStopping counter: 2 out of 10.0
EarlyStopping counter: 3 out of 10.0
EarlyStopping counter: 4 out of 10.0
EarlyStopping counter: 5 out of 10.0
EarlyStopping counter: 6 out of 10.0
EarlyStopping counter: 7 out of 10.0
EarlyStopping counter: 8 out of 10.0
EarlyStopping counter: 9 out of 10.0
EarlyStopping counter: 10 out of 10.0
/localscratch/yinan.29351703.0/env/lib/python3.7/site-packages/torch/nn/functional.py:1794: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.
  warnings.warn("nn.functional.tanh is deprecated. Use torch.tanh instead.")
wandb: Waiting for W&B process to finish, PID 156278... (success).
wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: \ 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: | 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: / 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: \ 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: | 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: / 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: \ 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: | 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: / 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb:                                                                                
wandb: Run history:
wandb:     e_F1 ▁▂▃▃▄▄▄▅▅▆▆▆▇▇▇▇▇▇▇█████████████████████
wandb:   e_loss ███▇▇▇▇▆▆▆▅▅▄▄▃▃▃▃▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:     t_F1 ▁▂▁▂▃▂▃▃▄▄▅▅▅▆▆▆▆▆▆▆▆▆▆▇▇▇▇▇▇▇▇▇████████
wandb:   t_loss ████▇▇▇▇▇▇▆▆▅▅▅▅▄▄▄▄▃▃▃▃▃▃▂▂▂▂▂▂▂▂▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:     e_F1 61.78476
wandb:   e_loss 0.94211
wandb:     t_F1 70.8297
wandb:   t_loss 0.75147
wandb: 
wandb: Synced 4 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Synced olive-yogurt-1: https://wandb.ai/yinanazhou/xl_512_bs_8_lr_1e06_es_10_lc_True_nr_False_sr_True_stem_False_lemma_True_repeat_4_fold_2/runs/2mpbt41f
wandb: Find logs at: ./wandb/run-20220327_190251-2mpbt41f/logs/debug.log
wandb: 

wandb: wandb version 0.12.11 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
2022-03-27 20:35:29.619626: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1
wandb: Tracking run with wandb version 0.12.5
wandb: Syncing run lilac-wood-1
wandb: ⭐️ View project at https://wandb.ai/yinanazhou/xl_512_bs_8_lr_1e06_es_10_lc_True_nr_False_sr_True_stem_False_lemma_True_repeat_5_fold_1
wandb: 🚀 View run at https://wandb.ai/yinanazhou/xl_512_bs_8_lr_1e06_es_10_lc_True_nr_False_sr_True_stem_False_lemma_True_repeat_5_fold_1/runs/1eghzvjc
wandb: Run data is saved locally in /project/6002780/yinan/Thesis_MER_Lyrics/lyric-emotion/wandb/run-20220327_203527-1eghzvjc
wandb: Run `wandb offline` to turn off syncing.

Validation loss decreased (inf --> 1.426344).  Saving model ...
Validation loss decreased (1.426344 --> 1.409102).  Saving model ...
Validation loss decreased (1.409102 --> 1.396813).  Saving model ...
Validation loss decreased (1.396813 --> 1.387169).  Saving model ...
Validation loss decreased (1.387169 --> 1.380050).  Saving model ...
Validation loss decreased (1.380050 --> 1.374283).  Saving model ...
Validation loss decreased (1.374283 --> 1.369409).  Saving model ...
Validation loss decreased (1.369409 --> 1.365252).  Saving model ...
Validation loss decreased (1.365252 --> 1.361311).  Saving model ...
Validation loss decreased (1.361311 --> 1.357331).  Saving model ...
Validation loss decreased (1.357331 --> 1.352983).  Saving model ...
Validation loss decreased (1.352983 --> 1.348882).  Saving model ...
Validation loss decreased (1.348882 --> 1.344852).  Saving model ...
Validation loss decreased (1.344852 --> 1.340499).  Saving model ...
Validation loss decreased (1.340499 --> 1.336512).  Saving model ...
Validation loss decreased (1.336512 --> 1.332270).  Saving model ...
Validation loss decreased (1.332270 --> 1.327958).  Saving model ...
Validation loss decreased (1.327958 --> 1.323802).  Saving model ...
Validation loss decreased (1.323802 --> 1.319015).  Saving model ...
Validation loss decreased (1.319015 --> 1.313659).  Saving model ...
Validation loss decreased (1.313659 --> 1.308461).  Saving model ...
Validation loss decreased (1.308461 --> 1.302983).  Saving model ...
Validation loss decreased (1.302983 --> 1.297084).  Saving model ...
Validation loss decreased (1.297084 --> 1.290419).  Saving model ...
Validation loss decreased (1.290419 --> 1.284556).  Saving model ...
Validation loss decreased (1.284556 --> 1.278602).  Saving model ...
Validation loss decreased (1.278602 --> 1.272418).  Saving model ...
Validation loss decreased (1.272418 --> 1.266429).  Saving model ...
Validation loss decreased (1.266429 --> 1.258930).  Saving model ...
Validation loss decreased (1.258930 --> 1.252055).  Saving model ...
Validation loss decreased (1.252055 --> 1.245498).  Saving model ...
Validation loss decreased (1.245498 --> 1.238823).  Saving model ...
Validation loss decreased (1.238823 --> 1.232679).  Saving model ...
Validation loss decreased (1.232679 --> 1.226430).  Saving model ...
Validation loss decreased (1.226430 --> 1.219109).  Saving model ...
Validation loss decreased (1.219109 --> 1.211973).  Saving model ...
Validation loss decreased (1.211973 --> 1.205219).  Saving model ...
Validation loss decreased (1.205219 --> 1.198300).  Saving model ...
Validation loss decreased (1.198300 --> 1.191734).  Saving model ...
Validation loss decreased (1.191734 --> 1.185100).  Saving model ...
Validation loss decreased (1.185100 --> 1.178337).  Saving model ...
Validation loss decreased (1.178337 --> 1.173432).  Saving model ...
Validation loss decreased (1.173432 --> 1.166407).  Saving model ...
Validation loss decreased (1.166407 --> 1.160418).  Saving model ...
Validation loss decreased (1.160418 --> 1.154999).  Saving model ...
Validation loss decreased (1.154999 --> 1.147583).  Saving model ...
Validation loss decreased (1.147583 --> 1.141456).  Saving model ...
Validation loss decreased (1.141456 --> 1.136092).  Saving model ...
Validation loss decreased (1.136092 --> 1.130511).  Saving model ...
Validation loss decreased (1.130511 --> 1.125245).  Saving model ...
Validation loss decreased (1.125245 --> 1.119721).  Saving model ...
Validation loss decreased (1.119721 --> 1.113747).  Saving model ...
Validation loss decreased (1.113747 --> 1.108469).  Saving model ...
Validation loss decreased (1.108469 --> 1.102776).  Saving model ...
Validation loss decreased (1.102776 --> 1.098670).  Saving model ...
Validation loss decreased (1.098670 --> 1.093420).  Saving model ...
Validation loss decreased (1.093420 --> 1.088467).  Saving model ...
Validation loss decreased (1.088467 --> 1.083463).  Saving model ...
Validation loss decreased (1.083463 --> 1.077746).  Saving model ...
Validation loss decreased (1.077746 --> 1.072671).  Saving model ...
Validation loss decreased (1.072671 --> 1.068695).  Saving model ...
Validation loss decreased (1.068695 --> 1.063757).  Saving model ...
Validation loss decreased (1.063757 --> 1.058517).  Saving model ...
Validation loss decreased (1.058517 --> 1.054921).  Saving model ...
Validation loss decreased (1.054921 --> 1.050977).  Saving model ...
Validation loss decreased (1.050977 --> 1.046473).  Saving model ...
Validation loss decreased (1.046473 --> 1.042657).  Saving model ...
Validation loss decreased (1.042657 --> 1.039092).  Saving model ...
Validation loss decreased (1.039092 --> 1.034820).  Saving model ...
Validation loss decreased (1.034820 --> 1.029032).  Saving model ...
Validation loss decreased (1.029032 --> 1.023560).  Saving model ...
Validation loss decreased (1.023560 --> 1.019692).  Saving model ...
Validation loss decreased (1.019692 --> 1.017166).  Saving model ...
Validation loss decreased (1.017166 --> 1.014025).  Saving model ...
Validation loss decreased (1.014025 --> 1.011105).  Saving model ...
Validation loss decreased (1.011105 --> 1.007503).  Saving model ...
Validation loss decreased (1.007503 --> 1.003980).  Saving model ...
Validation loss decreased (1.003980 --> 1.000488).  Saving model ...
Validation loss decreased (1.000488 --> 0.997045).  Saving model ...
Validation loss decreased (0.997045 --> 0.994795).  Saving model ...
Validation loss decreased (0.994795 --> 0.992378).  Saving model ...
Validation loss decreased (0.992378 --> 0.990002).  Saving model ...
Validation loss decreased (0.990002 --> 0.988471).  Saving model ...
Validation loss decreased (0.988471 --> 0.985286).  Saving model ...
Validation loss decreased (0.985286 --> 0.983793).  Saving model ...
Validation loss decreased (0.983793 --> 0.979315).  Saving model ...
Validation loss decreased (0.979315 --> 0.975834).  Saving model ...
Validation loss decreased (0.975834 --> 0.974792).  Saving model ...
Validation loss decreased (0.974792 --> 0.973800).  Saving model ...
Validation loss decreased (0.973800 --> 0.972076).  Saving model ...
Validation loss decreased (0.972076 --> 0.970114).  Saving model ...
Validation loss decreased (0.970114 --> 0.969350).  Saving model ...
Validation loss decreased (0.969350 --> 0.968295).  Saving model ...
Validation loss decreased (0.968295 --> 0.964640).  Saving model ...
Validation loss decreased (0.964640 --> 0.961240).  Saving model ...
Validation loss decreased (0.961240 --> 0.959522).  Saving model ...
Validation loss decreased (0.959522 --> 0.957987).  Saving model ...
Validation loss decreased (0.957987 --> 0.957669).  Saving model ...
Validation loss decreased (0.957669 --> 0.953558).  Saving model ...
Validation loss decreased (0.953558 --> 0.951037).  Saving model ...
Validation loss decreased (0.951037 --> 0.950184).  Saving model ...
Validation loss decreased (0.950184 --> 0.947959).  Saving model ...
Validation loss decreased (0.947959 --> 0.947223).  Saving model ...
Validation loss decreased (0.947223 --> 0.945929).  Saving model ...
Validation loss decreased (0.945929 --> 0.943577).  Saving model ...
Validation loss decreased (0.943577 --> 0.942420).  Saving model ...
Validation loss decreased (0.942420 --> 0.941138).  Saving model ...
Validation loss decreased (0.941138 --> 0.940433).  Saving model ...
EarlyStopping counter: 1 out of 10.0
Validation loss decreased (0.940433 --> 0.937084).  Saving model ...
Validation loss decreased (0.937084 --> 0.936956).  Saving model ...
Validation loss decreased (0.936956 --> 0.934787).  Saving model ...
Validation loss decreased (0.934787 --> 0.933734).  Saving model ...
EarlyStopping counter: 1 out of 10.0
Validation loss decreased (0.933734 --> 0.932797).  Saving model ...
Validation loss decreased (0.932797 --> 0.932544).  Saving model ...
EarlyStopping counter: 1 out of 10.0
Validation loss decreased (0.932544 --> 0.931358).  Saving model ...
Validation loss decreased (0.931358 --> 0.929429).  Saving model ...
Validation loss decreased (0.929429 --> 0.928367).  Saving model ...
Validation loss decreased (0.928367 --> 0.926823).  Saving model ...
Validation loss decreased (0.926823 --> 0.926805).  Saving model ...
Validation loss decreased (0.926805 --> 0.925174).  Saving model ...
Validation loss decreased (0.925174 --> 0.923781).  Saving model ...
Validation loss decreased (0.923781 --> 0.923337).  Saving model ...
EarlyStopping counter: 1 out of 10.0
Validation loss decreased (0.923337 --> 0.922797).  Saving model ...
Validation loss decreased (0.922797 --> 0.921725).  Saving model ...
EarlyStopping counter: 1 out of 10.0
EarlyStopping counter: 2 out of 10.0
Validation loss decreased (0.921725 --> 0.921647).  Saving model ...
EarlyStopping counter: 1 out of 10.0
EarlyStopping counter: 2 out of 10.0
EarlyStopping counter: 3 out of 10.0
EarlyStopping counter: 4 out of 10.0
EarlyStopping counter: 5 out of 10.0
Validation loss decreased (0.921647 --> 0.921149).  Saving model ...
EarlyStopping counter: 1 out of 10.0
EarlyStopping counter: 2 out of 10.0
EarlyStopping counter: 3 out of 10.0
EarlyStopping counter: 4 out of 10.0
EarlyStopping counter: 5 out of 10.0
EarlyStopping counter: 6 out of 10.0
EarlyStopping counter: 7 out of 10.0
EarlyStopping counter: 8 out of 10.0
EarlyStopping counter: 9 out of 10.0
EarlyStopping counter: 10 out of 10.0
/localscratch/yinan.29351703.0/env/lib/python3.7/site-packages/torch/nn/functional.py:1794: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.
  warnings.warn("nn.functional.tanh is deprecated. Use torch.tanh instead.")
wandb: Waiting for W&B process to finish, PID 161219... (success).
wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: \ 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: | 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: / 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: \ 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: | 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: / 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: \ 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb:                                                                                
wandb: Run history:
wandb:     e_F1 ▁▁▃▄▅▆▆▆▆▆▆▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇██████████████
wandb:   e_loss ██▇▇▇▇▆▆▆▅▅▅▄▄▄▃▃▃▃▂▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:     t_F1 ▁▁▂▂▃▃▄▄▄▅▄▅▅▅▆▆▆▆▆▆▆▆▇▇▇▇▇▇▇▇▇▇▇▇▇█████
wandb:   t_loss ████▇▇▇▇▇▆▆▆▅▅▅▅▄▄▄▄▄▄▃▃▃▃▃▃▂▂▂▂▂▂▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:     e_F1 57.87446
wandb:   e_loss 0.92255
wandb:     t_F1 74.02887
wandb:   t_loss 0.71063
wandb: 
wandb: Synced 4 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Synced lilac-wood-1: https://wandb.ai/yinanazhou/xl_512_bs_8_lr_1e06_es_10_lc_True_nr_False_sr_True_stem_False_lemma_True_repeat_5_fold_1/runs/1eghzvjc
wandb: Find logs at: ./wandb/run-20220327_203527-1eghzvjc/logs/debug.log
wandb: 

wandb: wandb version 0.12.11 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
2022-03-27 22:12:31.139076: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1
wandb: Tracking run with wandb version 0.12.5
wandb: Syncing run major-violet-1
wandb: ⭐️ View project at https://wandb.ai/yinanazhou/xl_512_bs_8_lr_1e06_es_10_lc_True_nr_False_sr_True_stem_False_lemma_True_repeat_5_fold_2
wandb: 🚀 View run at https://wandb.ai/yinanazhou/xl_512_bs_8_lr_1e06_es_10_lc_True_nr_False_sr_True_stem_False_lemma_True_repeat_5_fold_2/runs/11js6ni7
wandb: Run data is saved locally in /project/6002780/yinan/Thesis_MER_Lyrics/lyric-emotion/wandb/run-20220327_221228-11js6ni7
wandb: Run `wandb offline` to turn off syncing.

Validation loss decreased (inf --> 1.389875).  Saving model ...
Validation loss decreased (1.389875 --> 1.383541).  Saving model ...
Validation loss decreased (1.383541 --> 1.378039).  Saving model ...
Validation loss decreased (1.378039 --> 1.373665).  Saving model ...
Validation loss decreased (1.373665 --> 1.369349).  Saving model ...
Validation loss decreased (1.369349 --> 1.364947).  Saving model ...
Validation loss decreased (1.364947 --> 1.360857).  Saving model ...
Validation loss decreased (1.360857 --> 1.356777).  Saving model ...
Validation loss decreased (1.356777 --> 1.351958).  Saving model ...
Validation loss decreased (1.351958 --> 1.347737).  Saving model ...
Validation loss decreased (1.347737 --> 1.343583).  Saving model ...
Validation loss decreased (1.343583 --> 1.339564).  Saving model ...
Validation loss decreased (1.339564 --> 1.335409).  Saving model ...
Validation loss decreased (1.335409 --> 1.330821).  Saving model ...
Validation loss decreased (1.330821 --> 1.326060).  Saving model ...
Validation loss decreased (1.326060 --> 1.320948).  Saving model ...
Validation loss decreased (1.320948 --> 1.316114).  Saving model ...
Validation loss decreased (1.316114 --> 1.311270).  Saving model ...
Validation loss decreased (1.311270 --> 1.305783).  Saving model ...
Validation loss decreased (1.305783 --> 1.300258).  Saving model ...
Validation loss decreased (1.300258 --> 1.293345).  Saving model ...
Validation loss decreased (1.293345 --> 1.286409).  Saving model ...
Validation loss decreased (1.286409 --> 1.279713).  Saving model ...
Validation loss decreased (1.279713 --> 1.272727).  Saving model ...
Validation loss decreased (1.272727 --> 1.265718).  Saving model ...
Validation loss decreased (1.265718 --> 1.256991).  Saving model ...
Validation loss decreased (1.256991 --> 1.249843).  Saving model ...
Validation loss decreased (1.249843 --> 1.241523).  Saving model ...
Validation loss decreased (1.241523 --> 1.232909).  Saving model ...
Validation loss decreased (1.232909 --> 1.225846).  Saving model ...
Validation loss decreased (1.225846 --> 1.218298).  Saving model ...
Validation loss decreased (1.218298 --> 1.209830).  Saving model ...
Validation loss decreased (1.209830 --> 1.201739).  Saving model ...
Validation loss decreased (1.201739 --> 1.193260).  Saving model ...
Validation loss decreased (1.193260 --> 1.184280).  Saving model ...
Validation loss decreased (1.184280 --> 1.175466).  Saving model ...
Validation loss decreased (1.175466 --> 1.165865).  Saving model ...
Validation loss decreased (1.165865 --> 1.158343).  Saving model ...
Validation loss decreased (1.158343 --> 1.151117).  Saving model ...
Validation loss decreased (1.151117 --> 1.142432).  Saving model ...
Validation loss decreased (1.142432 --> 1.135024).  Saving model ...
Validation loss decreased (1.135024 --> 1.129152).  Saving model ...
Validation loss decreased (1.129152 --> 1.122376).  Saving model ...
Validation loss decreased (1.122376 --> 1.115608).  Saving model ...
Validation loss decreased (1.115608 --> 1.109549).  Saving model ...
Validation loss decreased (1.109549 --> 1.103489).  Saving model ...
Validation loss decreased (1.103489 --> 1.095983).  Saving model ...
Validation loss decreased (1.095983 --> 1.090944).  Saving model ...
Validation loss decreased (1.090944 --> 1.085537).  Saving model ...
Validation loss decreased (1.085537 --> 1.080918).  Saving model ...
Validation loss decreased (1.080918 --> 1.075899).  Saving model ...
Validation loss decreased (1.075899 --> 1.070105).  Saving model ...
Validation loss decreased (1.070105 --> 1.065426).  Saving model ...
Validation loss decreased (1.065426 --> 1.060325).  Saving model ...
Validation loss decreased (1.060325 --> 1.055950).  Saving model ...
Validation loss decreased (1.055950 --> 1.050231).  Saving model ...
Validation loss decreased (1.050231 --> 1.045664).  Saving model ...
Validation loss decreased (1.045664 --> 1.040626).  Saving model ...
Validation loss decreased (1.040626 --> 1.036758).  Saving model ...
Validation loss decreased (1.036758 --> 1.032890).  Saving model ...
Validation loss decreased (1.032890 --> 1.028864).  Saving model ...
Validation loss decreased (1.028864 --> 1.024764).  Saving model ...
Validation loss decreased (1.024764 --> 1.021480).  Saving model ...
Validation loss decreased (1.021480 --> 1.017379).  Saving model ...
Validation loss decreased (1.017379 --> 1.014306).  Saving model ...
Validation loss decreased (1.014306 --> 1.009985).  Saving model ...
Validation loss decreased (1.009985 --> 1.007213).  Saving model ...
Validation loss decreased (1.007213 --> 1.004743).  Saving model ...
Validation loss decreased (1.004743 --> 1.001334).  Saving model ...
Validation loss decreased (1.001334 --> 0.998567).  Saving model ...
Validation loss decreased (0.998567 --> 0.995420).  Saving model ...
Validation loss decreased (0.995420 --> 0.993188).  Saving model ...
Validation loss decreased (0.993188 --> 0.989783).  Saving model ...
Validation loss decreased (0.989783 --> 0.987859).  Saving model ...
Validation loss decreased (0.987859 --> 0.984037).  Saving model ...
Validation loss decreased (0.984037 --> 0.979814).  Saving model ...
Validation loss decreased (0.979814 --> 0.976833).  Saving model ...
Validation loss decreased (0.976833 --> 0.975258).  Saving model ...
Validation loss decreased (0.975258 --> 0.972279).  Saving model ...
Validation loss decreased (0.972279 --> 0.970982).  Saving model ...
Validation loss decreased (0.970982 --> 0.969251).  Saving model ...
Validation loss decreased (0.969251 --> 0.966245).  Saving model ...
Validation loss decreased (0.966245 --> 0.963559).  Saving model ...
Validation loss decreased (0.963559 --> 0.962764).  Saving model ...
EarlyStopping counter: 1 out of 10.0
Validation loss decreased (0.962764 --> 0.960161).  Saving model ...
Validation loss decreased (0.960161 --> 0.958521).  Saving model ...
EarlyStopping counter: 1 out of 10.0
Validation loss decreased (0.958521 --> 0.956465).  Saving model ...
Validation loss decreased (0.956465 --> 0.953317).  Saving model ...
Validation loss decreased (0.953317 --> 0.950820).  Saving model ...
Validation loss decreased (0.950820 --> 0.949390).  Saving model ...
Validation loss decreased (0.949390 --> 0.946769).  Saving model ...
Validation loss decreased (0.946769 --> 0.946026).  Saving model ...
Validation loss decreased (0.946026 --> 0.944658).  Saving model ...
Validation loss decreased (0.944658 --> 0.943953).  Saving model ...
Validation loss decreased (0.943953 --> 0.941074).  Saving model ...
Validation loss decreased (0.941074 --> 0.939729).  Saving model ...
Validation loss decreased (0.939729 --> 0.939521).  Saving model ...
Validation loss decreased (0.939521 --> 0.936882).  Saving model ...
Validation loss decreased (0.936882 --> 0.935801).  Saving model ...
Validation loss decreased (0.935801 --> 0.933949).  Saving model ...
Validation loss decreased (0.933949 --> 0.932677).  Saving model ...
Validation loss decreased (0.932677 --> 0.932035).  Saving model ...
Validation loss decreased (0.932035 --> 0.931466).  Saving model ...
Validation loss decreased (0.931466 --> 0.929885).  Saving model ...
Validation loss decreased (0.929885 --> 0.928673).  Saving model ...
Validation loss decreased (0.928673 --> 0.928440).  Saving model ...
Validation loss decreased (0.928440 --> 0.926975).  Saving model ...
Validation loss decreased (0.926975 --> 0.926757).  Saving model ...
Validation loss decreased (0.926757 --> 0.926714).  Saving model ...
Validation loss decreased (0.926714 --> 0.925622).  Saving model ...
Validation loss decreased (0.925622 --> 0.924334).  Saving model ...
Validation loss decreased (0.924334 --> 0.923046).  Saving model ...
Validation loss decreased (0.923046 --> 0.922279).  Saving model ...
EarlyStopping counter: 1 out of 10.0
Validation loss decreased (0.922279 --> 0.921078).  Saving model ...
Validation loss decreased (0.921078 --> 0.920741).  Saving model ...
Validation loss decreased (0.920741 --> 0.917936).  Saving model ...
EarlyStopping counter: 1 out of 10.0
Validation loss decreased (0.917936 --> 0.917283).  Saving model ...
Validation loss decreased (0.917283 --> 0.916376).  Saving model ...
EarlyStopping counter: 1 out of 10.0
Validation loss decreased (0.916376 --> 0.915378).  Saving model ...
Validation loss decreased (0.915378 --> 0.914551).  Saving model ...
EarlyStopping counter: 1 out of 10.0
Validation loss decreased (0.914551 --> 0.914488).  Saving model ...
Validation loss decreased (0.914488 --> 0.913386).  Saving model ...
EarlyStopping counter: 1 out of 10.0
EarlyStopping counter: 2 out of 10.0
EarlyStopping counter: 3 out of 10.0
Validation loss decreased (0.913386 --> 0.911915).  Saving model ...
Validation loss decreased (0.911915 --> 0.911174).  Saving model ...
Validation loss decreased (0.911174 --> 0.911074).  Saving model ...
EarlyStopping counter: 1 out of 10.0
EarlyStopping counter: 2 out of 10.0
EarlyStopping counter: 3 out of 10.0
EarlyStopping counter: 4 out of 10.0
EarlyStopping counter: 5 out of 10.0
EarlyStopping counter: 6 out of 10.0
EarlyStopping counter: 7 out of 10.0
Validation loss decreased (0.911074 --> 0.910231).  Saving model ...
Validation loss decreased (0.910231 --> 0.909060).  Saving model ...
EarlyStopping counter: 1 out of 10.0
EarlyStopping counter: 2 out of 10.0
Validation loss decreased (0.909060 --> 0.908099).  Saving model ...
EarlyStopping counter: 1 out of 10.0
EarlyStopping counter: 2 out of 10.0
EarlyStopping counter: 3 out of 10.0
EarlyStopping counter: 4 out of 10.0
EarlyStopping counter: 5 out of 10.0
EarlyStopping counter: 6 out of 10.0
EarlyStopping counter: 7 out of 10.0
EarlyStopping counter: 8 out of 10.0
EarlyStopping counter: 9 out of 10.0
EarlyStopping counter: 10 out of 10.0
/localscratch/yinan.29351703.0/env/lib/python3.7/site-packages/torch/nn/functional.py:1794: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.
  warnings.warn("nn.functional.tanh is deprecated. Use torch.tanh instead.")
wandb: Waiting for W&B process to finish, PID 166386... (success).
wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: \ 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: | 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: / 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: \ 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: | 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: / 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: \ 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: | 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: / 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb:                                                                                
wandb: Run history:
wandb:     e_F1 ▁▂▃▄▅▅▅▅▆▆▆▆▆▇▇▇▇▇██████████████████████
wandb:   e_loss ███▇▇▇▆▆▅▅▄▄▄▃▃▃▃▂▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:     t_F1 ▁▂▂▃▃▃▃▄▅▄▅▅▅▆▆▆▆▆▆▆▆▆▆▇▆▇▇▇▇▇▇██▇█▇▇██▇
wandb:   t_loss ███▇▇▇▇▇▆▆▆▅▅▅▄▄▄▄▄▄▃▃▃▃▃▃▃▃▂▂▂▂▂▂▂▂▁▁▁▂
wandb: 
wandb: Run summary:
wandb:     e_F1 63.79619
wandb:   e_loss 0.91222
wandb:     t_F1 69.75636
wandb:   t_loss 0.74791
wandb: 
wandb: Synced 4 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Synced major-violet-1: https://wandb.ai/yinanazhou/xl_512_bs_8_lr_1e06_es_10_lc_True_nr_False_sr_True_stem_False_lemma_True_repeat_5_fold_2/runs/11js6ni7
wandb: Find logs at: ./wandb/run-20220327_221228-11js6ni7/logs/debug.log
wandb: 

