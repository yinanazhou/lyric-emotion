Unloading StdEnv/2020

Due to MODULEPATH changes, the following have been reloaded:
  1) mii/1.1.1


The following have been reloaded with a version change:
  1) python/3.8.2 => python/3.7.4

Using base prefix '/cvmfs/soft.computecanada.ca/easybuild/software/2017/Core/python/3.7.4'
New python executable in /localscratch/yinan.29152320.0/env/bin/python
Installing setuptools, pip, wheel...
done.
Ignoring pip: markers 'python_version < "3"' don't match your environment
Looking in links: /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/nix/avx2, /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/nix/generic, /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic
Collecting pip
Installing collected packages: pip
  Found existing installation: pip 19.1.1
    Uninstalling pip-19.1.1:
      Successfully uninstalled pip-19.1.1
Successfully installed pip-21.2.3+computecanada
Looking in links: /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/nix/avx2, /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/nix/generic, /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/keras-2.8.0+computecanada-py2.py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/Keras_Preprocessing-1.1.2+computecanada-py3-none-any.whl
Requirement already satisfied: matplotlib in /cvmfs/soft.computecanada.ca/easybuild/software/2017/Core/scipy-stack/2019a/lib/python3.7/site-packages (from -r requirements.txt (line 3)) (3.0.2)
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/nltk-3.6.5+computecanada-py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/scikit_learn-0.22.1+computecanada-cp37-cp37m-linux_x86_64.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/tensorboard-2.3.0+computecanada-py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/tensorboard_plugin_wit-1.7.0+computecanada-py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/tensorflow_gpu-2.3.0+computecanada-cp37-cp37m-linux_x86_64.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/tensorflow_estimator-2.3.0+computecanada-py2.py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/tokenizers-0.5.2+computecanada-cp37-cp37m-linux_x86_64.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/nix/avx2/torch-1.4.0+computecanada-cp37-cp37m-linux_x86_64.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/torchtext-0.6.0+computecanada-py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/torchvision-0.8.2+computecanada-cp37-cp37m-linux_x86_64.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/transformers-2.5.1+computecanada-py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/urllib3-1.26.7+computecanada-py2.py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/joblib-1.1.0+computecanada-py2.py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/click-8.0.4+computecanada-py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/tqdm-4.63.0+computecanada-py2.py3-none-any.whl
ERROR: Could not find a version that satisfies the requirement regex>=2021.8.3 (from nltk) (from versions: 2018.1.10+computecanada, 2019.11.1+computecanada, 2020.11.13+computecanada)
ERROR: No matching distribution found for regex>=2021.8.3
Looking in links: /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/nix/avx2, /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/nix/generic, /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic
ERROR: Could not find a version that satisfies the requirement numpy==1.20.0+computacanada (from versions: 1.15.0+computecanada, 1.15.2+computecanada, 1.15.4+computecanada, 1.16.0+computecanada, 1.16.2+computecanada, 1.16.3+computecanada, 1.17.4+computecanada, 1.18.1+computecanada, 1.18.4+computecanada, 1.19.1+computecanada, 1.19.2+computecanada, 1.20.2+computecanada)
ERROR: No matching distribution found for numpy==1.20.0+computacanada
Looking in links: /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/nix/avx2, /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/nix/generic, /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/wandb-0.12.5+computecanada-py2.py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/sentry_sdk-1.5.0+computecanada-py2.py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/promise-2.3+computecanada-py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/six-1.16.0+computecanada-py2.py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/configparser-5.0.2+computecanada-py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/psutil-5.7.3+computecanada-cp37-cp37m-linux_x86_64.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/GitPython-3.1.24+computecanada-py3-none-any.whl
Requirement already satisfied: python-dateutil>=2.6.1 in /cvmfs/soft.computecanada.ca/easybuild/software/2017/Core/scipy-stack/2019a/lib/python3.7/site-packages (from wandb) (2.7.5)
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/yaspin-2.1.0+computecanada-py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/pathtools-0.1.2+computecanada-py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/shortuuid-1.0.1+computecanada-py3-none-any.whl
Requirement already satisfied: requests<3,>=2.0.0 in /cvmfs/soft.computecanada.ca/easybuild/software/2017/Core/scipy-stack/2019a/lib/python3.7/site-packages (from wandb) (2.21.0)
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/protobuf-3.19.4+computecanada-py2.py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/subprocess32-3.5.4+computecanada-py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/docker_pycreds-0.4.0+computecanada-py2.py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/PyYAML-5.3.1+computecanada-cp37-cp37m-linux_x86_64.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/click-8.0.4+computecanada-py3-none-any.whl
Requirement already satisfied: importlib-metadata in /cvmfs/soft.computecanada.ca/easybuild/software/2017/Core/scipy-stack/2019a/lib/python3.7/site-packages (from Click!=8.0.0,>=7.0->wandb) (0.8)
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/gitdb-4.0.9+computecanada-py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/typing_extensions-4.0.1+computecanada-py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/smmap-5.0.0+computecanada-py3-none-any.whl
Requirement already satisfied: certifi>=2017.4.17 in /cvmfs/soft.computecanada.ca/easybuild/software/2017/Core/scipy-stack/2019a/lib/python3.7/site-packages (from requests<3,>=2.0.0->wandb) (2018.11.29)
Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /cvmfs/soft.computecanada.ca/easybuild/software/2017/Core/scipy-stack/2019a/lib/python3.7/site-packages (from requests<3,>=2.0.0->wandb) (3.0.4)
Requirement already satisfied: idna<2.9,>=2.5 in /cvmfs/soft.computecanada.ca/easybuild/software/2017/Core/scipy-stack/2019a/lib/python3.7/site-packages (from requests<3,>=2.0.0->wandb) (2.8)
Requirement already satisfied: urllib3<1.25,>=1.21.1 in /cvmfs/soft.computecanada.ca/easybuild/software/2017/Core/scipy-stack/2019a/lib/python3.7/site-packages (from requests<3,>=2.0.0->wandb) (1.24.1)
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/termcolor-1.1.0+computecanada-py3-none-any.whl
Requirement already satisfied: zipp>=0.3.2 in /cvmfs/soft.computecanada.ca/easybuild/software/2017/Core/scipy-stack/2019a/lib/python3.7/site-packages (from importlib-metadata->Click!=8.0.0,>=7.0->wandb) (0.3.3)
Installing collected packages: smmap, typing-extensions, termcolor, six, gitdb, yaspin, subprocess32, shortuuid, sentry-sdk, PyYAML, psutil, protobuf, promise, pathtools, GitPython, docker-pycreds, configparser, Click, wandb
  Attempting uninstall: six
    Found existing installation: six 1.12.0
    Not uninstalling six at /cvmfs/soft.computecanada.ca/easybuild/software/2017/Core/scipy-stack/2019a/lib/python3.7/site-packages, outside environment /localscratch/yinan.29152320.0/env
    Can't uninstall 'six'. No files were found to uninstall.
Successfully installed Click-8.0.4+computecanada GitPython-3.1.24+computecanada PyYAML-5.3.1+computecanada configparser-5.0.2+computecanada docker-pycreds-0.4.0+computecanada gitdb-4.0.9+computecanada pathtools-0.1.2+computecanada promise-2.3+computecanada protobuf-3.19.4+computecanada psutil-5.7.3+computecanada sentry-sdk-1.5.0+computecanada shortuuid-1.0.1+computecanada six-1.16.0+computecanada smmap-5.0.0+computecanada subprocess32-3.5.4+computecanada termcolor-1.1.0+computecanada typing-extensions-4.0.1+computecanada wandb-0.12.5+computecanada yaspin-2.1.0+computecanada
Looking in links: /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/nix/avx2, /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/nix/generic, /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic
ERROR: Could not find a version that satisfies the requirement sagemaker (from versions: none)
ERROR: No matching distribution found for sagemaker
Looking in links: /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/nix/avx2, /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/nix/generic, /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/torch-1.9.1+computecanada-cp37-cp37m-linux_x86_64.whl
Requirement already satisfied: typing-extensions in /localscratch/yinan.29152320.0/env/lib/python3.7/site-packages (from torch) (4.0.1+computecanada)
Installing collected packages: torch
Successfully installed torch-1.9.1+computecanada
Looking in links: /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/nix/avx2, /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/nix/generic, /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/transformers-2.5.1+computecanada-py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/boto3-1.21.14+computecanada-py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/sentencepiece-0.1.91+computecanada-cp37-cp37m-linux_x86_64.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/sacremoses-0.0.46+computecanada-py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/regex-2020.11.13+computecanada-cp37-cp37m-linux_x86_64.whl
Requirement already satisfied: requests in /cvmfs/soft.computecanada.ca/easybuild/software/2017/Core/scipy-stack/2019a/lib/python3.7/site-packages (from transformers==2.5.1+computecanada) (2.21.0)
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/filelock-3.4.2+computecanada-py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/tokenizers-0.5.2+computecanada-cp37-cp37m-linux_x86_64.whl
Requirement already satisfied: numpy in /cvmfs/soft.computecanada.ca/easybuild/software/2017/Core/scipy-stack/2019a/lib/python3.7/site-packages (from transformers==2.5.1+computecanada) (1.16.0)
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/tqdm-4.63.0+computecanada-py2.py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/s3transfer-0.5.1+computecanada-py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/jmespath-0.10.0+computecanada-py2.py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/botocore-1.24.14+computecanada-py3-none-any.whl
Requirement already satisfied: python-dateutil<3.0.0,>=2.1 in /cvmfs/soft.computecanada.ca/easybuild/software/2017/Core/scipy-stack/2019a/lib/python3.7/site-packages (from botocore<1.25.0,>=1.24.14->boto3->transformers==2.5.1+computecanada) (2.7.5)
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/urllib3-1.26.8+computecanada-py2.py3-none-any.whl
Requirement already satisfied: six>=1.5 in /localscratch/yinan.29152320.0/env/lib/python3.7/site-packages (from python-dateutil<3.0.0,>=2.1->botocore<1.25.0,>=1.24.14->boto3->transformers==2.5.1+computecanada) (1.16.0+computecanada)
Requirement already satisfied: certifi>=2017.4.17 in /cvmfs/soft.computecanada.ca/easybuild/software/2017/Core/scipy-stack/2019a/lib/python3.7/site-packages (from requests->transformers==2.5.1+computecanada) (2018.11.29)
Requirement already satisfied: idna<2.9,>=2.5 in /cvmfs/soft.computecanada.ca/easybuild/software/2017/Core/scipy-stack/2019a/lib/python3.7/site-packages (from requests->transformers==2.5.1+computecanada) (2.8)
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/requests-2.27.1+computecanada-py2.py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/charset_normalizer-2.0.12+computecanada-py3-none-any.whl
Requirement already satisfied: click in /localscratch/yinan.29152320.0/env/lib/python3.7/site-packages (from sacremoses->transformers==2.5.1+computecanada) (8.0.4+computecanada)
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/joblib-1.1.0+computecanada-py2.py3-none-any.whl
Requirement already satisfied: importlib-metadata in /cvmfs/soft.computecanada.ca/easybuild/software/2017/Core/scipy-stack/2019a/lib/python3.7/site-packages (from click->sacremoses->transformers==2.5.1+computecanada) (0.8)
Requirement already satisfied: zipp>=0.3.2 in /cvmfs/soft.computecanada.ca/easybuild/software/2017/Core/scipy-stack/2019a/lib/python3.7/site-packages (from importlib-metadata->click->sacremoses->transformers==2.5.1+computecanada) (0.3.3)
Installing collected packages: urllib3, jmespath, botocore, tqdm, s3transfer, regex, joblib, charset-normalizer, tokenizers, sentencepiece, sacremoses, requests, filelock, boto3, transformers
  Attempting uninstall: urllib3
    Found existing installation: urllib3 1.24.1
    Not uninstalling urllib3 at /cvmfs/soft.computecanada.ca/easybuild/software/2017/Core/scipy-stack/2019a/lib/python3.7/site-packages, outside environment /localscratch/yinan.29152320.0/env
    Can't uninstall 'urllib3'. No files were found to uninstall.
  Attempting uninstall: requests
    Found existing installation: requests 2.21.0
    Not uninstalling requests at /cvmfs/soft.computecanada.ca/easybuild/software/2017/Core/scipy-stack/2019a/lib/python3.7/site-packages, outside environment /localscratch/yinan.29152320.0/env
    Can't uninstall 'requests'. No files were found to uninstall.
Successfully installed boto3-1.21.14+computecanada botocore-1.24.14+computecanada charset-normalizer-2.0.12+computecanada filelock-3.4.2+computecanada jmespath-0.10.0+computecanada joblib-1.1.0+computecanada regex-2020.11.13+computecanada requests-2.27.1+computecanada s3transfer-0.5.1+computecanada sacremoses-0.0.46+computecanada sentencepiece-0.1.91+computecanada tokenizers-0.5.2+computecanada tqdm-4.63.0+computecanada transformers-2.5.1+computecanada urllib3-1.26.8+computecanada
Looking in links: /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/nix/avx2, /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/nix/generic, /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/tensorflow_gpu-2.3.0+computecanada-cp37-cp37m-linux_x86_64.whl
Requirement already satisfied: numpy<1.19.0,>=1.16.0 in /cvmfs/soft.computecanada.ca/easybuild/software/2017/Core/scipy-stack/2019a/lib/python3.7/site-packages (from tensorflow_gpu==2.3.0+computecanada) (1.16.0)
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/wrapt-1.11.2+computecanada-cp37-cp37m-linux_x86_64.whl
Requirement already satisfied: termcolor>=1.1.0 in /localscratch/yinan.29152320.0/env/lib/python3.7/site-packages (from tensorflow_gpu==2.3.0+computecanada) (1.1.0+computecanada)
Requirement already satisfied: wheel>=0.26 in /localscratch/yinan.29152320.0/env/lib/python3.7/site-packages (from tensorflow_gpu==2.3.0+computecanada) (0.33.4)
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/tensorflow_estimator-2.3.0+computecanada-py2.py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/astunparse-1.6.3+computecanada-py2.py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/absl_py-1.0.0+computecanada-py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/nix/avx2/h5py-2.10.0+computecanada-cp37-cp37m-linux_x86_64.whl
Requirement already satisfied: protobuf>=3.9.2 in /localscratch/yinan.29152320.0/env/lib/python3.7/site-packages (from tensorflow_gpu==2.3.0+computecanada) (3.19.4+computecanada)
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/Keras_Preprocessing-1.1.2+computecanada-py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/gast-0.3.3+computecanada-py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/google_pasta-0.2.0+computecanada-py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/tensorboard-2.8.0+computecanada-py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/opt_einsum-3.3.0+computecanada-py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/nix/generic/scipy-1.4.1+computecanada-cp37-cp37m-linux_x86_64.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/grpcio-1.38.0+computecanada-cp37-cp37m-linux_x86_64.whl
Requirement already satisfied: six>=1.12.0 in /localscratch/yinan.29152320.0/env/lib/python3.7/site-packages (from tensorflow_gpu==2.3.0+computecanada) (1.16.0+computecanada)
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/tensorboard_data_server-0.6.1+computecanada-py3-none-linux_x86_64.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/Markdown-3.3.6+computecanada-py3-none-any.whl
Requirement already satisfied: setuptools>=41.0.0 in /localscratch/yinan.29152320.0/env/lib/python3.7/site-packages (from tensorboard<3,>=2.3.0->tensorflow_gpu==2.3.0+computecanada) (41.0.1)
Requirement already satisfied: requests<3,>=2.21.0 in /localscratch/yinan.29152320.0/env/lib/python3.7/site-packages (from tensorboard<3,>=2.3.0->tensorflow_gpu==2.3.0+computecanada) (2.27.1+computecanada)
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/google_auth-2.3.3+computecanada-py2.py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/Werkzeug-2.0.3+computecanada-py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/google_auth_oauthlib-0.4.6+computecanada-py2.py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/tensorboard_plugin_wit-1.8.0+computecanada-py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/cachetools-4.2.4+computecanada-py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/pyasn1_modules-0.2.8+computecanada-py2.py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/rsa-4.8+computecanada-py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/requests_oauthlib-1.3.0+computecanada-py2.py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/importlib_metadata-4.10.1+computecanada-py3-none-any.whl
Requirement already satisfied: typing-extensions>=3.6.4 in /localscratch/yinan.29152320.0/env/lib/python3.7/site-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard<3,>=2.3.0->tensorflow_gpu==2.3.0+computecanada) (4.0.1+computecanada)
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/zipp-3.7.0+computecanada-py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/pyasn1-0.4.8+computecanada-py2.py3-none-any.whl
Requirement already satisfied: idna<4,>=2.5 in /cvmfs/soft.computecanada.ca/easybuild/software/2017/Core/scipy-stack/2019a/lib/python3.7/site-packages (from requests<3,>=2.21.0->tensorboard<3,>=2.3.0->tensorflow_gpu==2.3.0+computecanada) (2.8)
Requirement already satisfied: certifi>=2017.4.17 in /cvmfs/soft.computecanada.ca/easybuild/software/2017/Core/scipy-stack/2019a/lib/python3.7/site-packages (from requests<3,>=2.21.0->tensorboard<3,>=2.3.0->tensorflow_gpu==2.3.0+computecanada) (2018.11.29)
Requirement already satisfied: charset-normalizer~=2.0.0 in /localscratch/yinan.29152320.0/env/lib/python3.7/site-packages (from requests<3,>=2.21.0->tensorboard<3,>=2.3.0->tensorflow_gpu==2.3.0+computecanada) (2.0.12+computecanada)
Requirement already satisfied: urllib3<1.27,>=1.21.1 in /localscratch/yinan.29152320.0/env/lib/python3.7/site-packages (from requests<3,>=2.21.0->tensorboard<3,>=2.3.0->tensorflow_gpu==2.3.0+computecanada) (1.26.8+computecanada)
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/oauthlib-3.1.1+computecanada-py2.py3-none-any.whl
Installing collected packages: pyasn1, zipp, rsa, pyasn1-modules, oauthlib, cachetools, requests-oauthlib, importlib-metadata, google-auth, werkzeug, tensorboard-plugin-wit, tensorboard-data-server, markdown, grpcio, google-auth-oauthlib, absl-py, wrapt, tensorflow-estimator, tensorboard, scipy, opt-einsum, keras-preprocessing, h5py, google-pasta, gast, astunparse, tensorflow-gpu
  Attempting uninstall: pyasn1
    Found existing installation: pyasn1 0.4.3
    Not uninstalling pyasn1 at /cvmfs/soft.computecanada.ca/easybuild/software/2017/Core/scipy-stack/2019a/lib/python3.7/site-packages, outside environment /localscratch/yinan.29152320.0/env
    Can't uninstall 'pyasn1'. No files were found to uninstall.
  Attempting uninstall: zipp
    Found existing installation: zipp 0.3.3
    Not uninstalling zipp at /cvmfs/soft.computecanada.ca/easybuild/software/2017/Core/scipy-stack/2019a/lib/python3.7/site-packages, outside environment /localscratch/yinan.29152320.0/env
    Can't uninstall 'zipp'. No files were found to uninstall.
  Attempting uninstall: importlib-metadata
    Found existing installation: importlib-metadata 0.8
    Not uninstalling importlib-metadata at /cvmfs/soft.computecanada.ca/easybuild/software/2017/Core/scipy-stack/2019a/lib/python3.7/site-packages, outside environment /localscratch/yinan.29152320.0/env
    Can't uninstall 'importlib-metadata'. No files were found to uninstall.
  Attempting uninstall: scipy
    Found existing installation: scipy 1.2.0
    Not uninstalling scipy at /cvmfs/soft.computecanada.ca/easybuild/software/2017/Core/scipy-stack/2019a/lib/python3.7/site-packages, outside environment /localscratch/yinan.29152320.0/env
    Can't uninstall 'scipy'. No files were found to uninstall.
Successfully installed absl-py-1.0.0+computecanada astunparse-1.6.3+computecanada cachetools-4.2.4+computecanada gast-0.3.3+computecanada google-auth-2.3.3+computecanada google-auth-oauthlib-0.4.6+computecanada google-pasta-0.2.0+computecanada grpcio-1.38.0+computecanada h5py-2.10.0+computecanada importlib-metadata-4.10.1+computecanada keras-preprocessing-1.1.2+computecanada markdown-3.3.6+computecanada oauthlib-3.1.1+computecanada opt-einsum-3.3.0+computecanada pyasn1-0.4.8+computecanada pyasn1-modules-0.2.8+computecanada requests-oauthlib-1.3.0+computecanada rsa-4.8+computecanada scipy-1.4.1+computecanada tensorboard-2.8.0+computecanada tensorboard-data-server-0.6.1+computecanada tensorboard-plugin-wit-1.8.0+computecanada tensorflow-estimator-2.3.0+computecanada tensorflow-gpu-2.3.0+computecanada werkzeug-2.0.3+computecanada wrapt-1.11.2+computecanada zipp-3.7.0+computecanada
Looking in links: /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/nix/avx2, /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/nix/generic, /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/keras-2.8.0+computecanada-py2.py3-none-any.whl
Installing collected packages: Keras
Successfully installed Keras-2.8.0+computecanada
Looking in links: /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/nix/avx2, /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/nix/generic, /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/urllib3-1.26.7+computecanada-py2.py3-none-any.whl
Installing collected packages: urllib3
  Attempting uninstall: urllib3
    Found existing installation: urllib3 1.26.8+computecanada
    Uninstalling urllib3-1.26.8+computecanada:
      Successfully uninstalled urllib3-1.26.8+computecanada
Successfully installed urllib3-1.26.7+computecanada
Looking in links: /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/nix/avx2, /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/nix/generic, /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/nltk-3.7+computecanada-py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/nltk-3.6.5+computecanada-py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/nltk-3.6.3+computecanada-py3-none-any.whl
Requirement already satisfied: tqdm in /localscratch/yinan.29152320.0/env/lib/python3.7/site-packages (from nltk) (4.63.0+computecanada)
Requirement already satisfied: regex in /localscratch/yinan.29152320.0/env/lib/python3.7/site-packages (from nltk) (2020.11.13+computecanada)
Requirement already satisfied: click in /localscratch/yinan.29152320.0/env/lib/python3.7/site-packages (from nltk) (8.0.4+computecanada)
Requirement already satisfied: joblib in /localscratch/yinan.29152320.0/env/lib/python3.7/site-packages (from nltk) (1.1.0+computecanada)
Requirement already satisfied: importlib-metadata in /localscratch/yinan.29152320.0/env/lib/python3.7/site-packages (from click->nltk) (4.10.1+computecanada)
Requirement already satisfied: zipp>=0.5 in /localscratch/yinan.29152320.0/env/lib/python3.7/site-packages (from importlib-metadata->click->nltk) (3.7.0+computecanada)
Requirement already satisfied: typing-extensions>=3.6.4 in /localscratch/yinan.29152320.0/env/lib/python3.7/site-packages (from importlib-metadata->click->nltk) (4.0.1+computecanada)
Installing collected packages: nltk
Successfully installed nltk-3.6.3+computecanada
Looking in links: /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/nix/avx2, /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/nix/generic, /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/scikit_learn-0.22.1+computecanada-cp37-cp37m-linux_x86_64.whl
Requirement already satisfied: joblib>=0.11 in /localscratch/yinan.29152320.0/env/lib/python3.7/site-packages (from scikit-learn==0.22.1) (1.1.0+computecanada)
Requirement already satisfied: numpy>=1.11.0 in /cvmfs/soft.computecanada.ca/easybuild/software/2017/Core/scipy-stack/2019a/lib/python3.7/site-packages (from scikit-learn==0.22.1) (1.16.0)
Requirement already satisfied: scipy>=0.17.0 in /localscratch/yinan.29152320.0/env/lib/python3.7/site-packages (from scikit-learn==0.22.1) (1.4.1+computecanada)
Installing collected packages: scikit-learn
Successfully installed scikit-learn-0.22.1+computecanada
Looking in links: /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/nix/avx2, /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/nix/generic, /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic
Requirement already satisfied: tokenizers==0.5.2 in /localscratch/yinan.29152320.0/env/lib/python3.7/site-packages (0.5.2+computecanada)
wandb: Appending key for api.wandb.ai to your netrc file: /home/yinan/.netrc
Starting Task
2022-03-17 17:17:24.120723: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1
[nltk_data] Downloading package stopwords to /home/yinan/nltk_data...
[nltk_data]   Package stopwords is already up-to-date!
[nltk_data] Downloading package wordnet to /home/yinan/nltk_data...
[nltk_data]   Package wordnet is already up-to-date!
wandb: Currently logged in as: yinanazhou (use `wandb login --relogin` to force relogin)
wandb: wandb version 0.12.11 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
2022-03-17 17:17:45.943874: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1
wandb: Tracking run with wandb version 0.12.5
wandb: Syncing run lively-waterfall-2
wandb: ⭐️ View project at https://wandb.ai/yinanazhou/xl_512_bs_8_lr_1e06_es_5_lc_True_nr_False_sr_False_stem_True_lemma_False_repeat_1_fold_1
wandb: 🚀 View run at https://wandb.ai/yinanazhou/xl_512_bs_8_lr_1e06_es_5_lc_True_nr_False_sr_False_stem_True_lemma_False_repeat_1_fold_1/runs/jh7yzy6n
wandb: Run data is saved locally in /project/6002780/yinan/Thesis_MER_Lyrics/lyric-emotion/wandb/run-20220317_171743-jh7yzy6n
wandb: Run `wandb offline` to turn off syncing.

Validation loss decreased (inf --> 1.428701).  Saving model ...
Validation loss decreased (1.428701 --> 1.410853).  Saving model ...
Validation loss decreased (1.410853 --> 1.395251).  Saving model ...
Validation loss decreased (1.395251 --> 1.383025).  Saving model ...
Validation loss decreased (1.383025 --> 1.373606).  Saving model ...
Validation loss decreased (1.373606 --> 1.365513).  Saving model ...
Validation loss decreased (1.365513 --> 1.359243).  Saving model ...
Validation loss decreased (1.359243 --> 1.354053).  Saving model ...
Validation loss decreased (1.354053 --> 1.349347).  Saving model ...
Validation loss decreased (1.349347 --> 1.344091).  Saving model ...
Validation loss decreased (1.344091 --> 1.338948).  Saving model ...
Validation loss decreased (1.338948 --> 1.334549).  Saving model ...
Validation loss decreased (1.334549 --> 1.330014).  Saving model ...
Validation loss decreased (1.330014 --> 1.326011).  Saving model ...
Validation loss decreased (1.326011 --> 1.322037).  Saving model ...
Validation loss decreased (1.322037 --> 1.317563).  Saving model ...
Validation loss decreased (1.317563 --> 1.313114).  Saving model ...
Validation loss decreased (1.313114 --> 1.307988).  Saving model ...
Validation loss decreased (1.307988 --> 1.303102).  Saving model ...
Validation loss decreased (1.303102 --> 1.297448).  Saving model ...
Validation loss decreased (1.297448 --> 1.291545).  Saving model ...
Validation loss decreased (1.291545 --> 1.285765).  Saving model ...
Validation loss decreased (1.285765 --> 1.280325).  Saving model ...
Validation loss decreased (1.280325 --> 1.274800).  Saving model ...
Validation loss decreased (1.274800 --> 1.267605).  Saving model ...
Validation loss decreased (1.267605 --> 1.260850).  Saving model ...
Validation loss decreased (1.260850 --> 1.254354).  Saving model ...
Validation loss decreased (1.254354 --> 1.248109).  Saving model ...
Validation loss decreased (1.248109 --> 1.240828).  Saving model ...
Validation loss decreased (1.240828 --> 1.235054).  Saving model ...
Validation loss decreased (1.235054 --> 1.228738).  Saving model ...
Validation loss decreased (1.228738 --> 1.222475).  Saving model ...
Validation loss decreased (1.222475 --> 1.217441).  Saving model ...
Validation loss decreased (1.217441 --> 1.212890).  Saving model ...
Validation loss decreased (1.212890 --> 1.207891).  Saving model ...
Validation loss decreased (1.207891 --> 1.203062).  Saving model ...
Validation loss decreased (1.203062 --> 1.196801).  Saving model ...
Validation loss decreased (1.196801 --> 1.188847).  Saving model ...
Validation loss decreased (1.188847 --> 1.185200).  Saving model ...
Validation loss decreased (1.185200 --> 1.182521).  Saving model ...
Validation loss decreased (1.182521 --> 1.177406).  Saving model ...
Validation loss decreased (1.177406 --> 1.172767).  Saving model ...
Validation loss decreased (1.172767 --> 1.169202).  Saving model ...
Validation loss decreased (1.169202 --> 1.164803).  Saving model ...
Validation loss decreased (1.164803 --> 1.160273).  Saving model ...
Validation loss decreased (1.160273 --> 1.156590).  Saving model ...
Validation loss decreased (1.156590 --> 1.154493).  Saving model ...
Validation loss decreased (1.154493 --> 1.152687).  Saving model ...
Validation loss decreased (1.152687 --> 1.145348).  Saving model ...
Validation loss decreased (1.145348 --> 1.142695).  Saving model ...
Validation loss decreased (1.142695 --> 1.141223).  Saving model ...
Validation loss decreased (1.141223 --> 1.135138).  Saving model ...
Validation loss decreased (1.135138 --> 1.133451).  Saving model ...
Validation loss decreased (1.133451 --> 1.129744).  Saving model ...
Validation loss decreased (1.129744 --> 1.129062).  Saving model ...
Validation loss decreased (1.129062 --> 1.121108).  Saving model ...
Validation loss decreased (1.121108 --> 1.117402).  Saving model ...
Validation loss decreased (1.117402 --> 1.114661).  Saving model ...
Validation loss decreased (1.114661 --> 1.110383).  Saving model ...
Validation loss decreased (1.110383 --> 1.110366).  Saving model ...
Validation loss decreased (1.110366 --> 1.108722).  Saving model ...
Validation loss decreased (1.108722 --> 1.105206).  Saving model ...
Validation loss decreased (1.105206 --> 1.101474).  Saving model ...
Validation loss decreased (1.101474 --> 1.097470).  Saving model ...
Validation loss decreased (1.097470 --> 1.097292).  Saving model ...
Validation loss decreased (1.097292 --> 1.094743).  Saving model ...
Validation loss decreased (1.094743 --> 1.093423).  Saving model ...
Validation loss decreased (1.093423 --> 1.088006).  Saving model ...
Validation loss decreased (1.088006 --> 1.081736).  Saving model ...
Validation loss decreased (1.081736 --> 1.081129).  Saving model ...
Validation loss decreased (1.081129 --> 1.077172).  Saving model ...
Validation loss decreased (1.077172 --> 1.076355).  Saving model ...
Validation loss decreased (1.076355 --> 1.074248).  Saving model ...
Validation loss decreased (1.074248 --> 1.072177).  Saving model ...
Validation loss decreased (1.072177 --> 1.067253).  Saving model ...
EarlyStopping counter: 1 out of 5.0
Validation loss decreased (1.067253 --> 1.066481).  Saving model ...
Validation loss decreased (1.066481 --> 1.062597).  Saving model ...
Validation loss decreased (1.062597 --> 1.056995).  Saving model ...
Validation loss decreased (1.056995 --> 1.055189).  Saving model ...
EarlyStopping counter: 1 out of 5.0
EarlyStopping counter: 2 out of 5.0
EarlyStopping counter: 3 out of 5.0
EarlyStopping counter: 4 out of 5.0
Validation loss decreased (1.055189 --> 1.050956).  Saving model ...
Validation loss decreased (1.050956 --> 1.049468).  Saving model ...
Validation loss decreased (1.049468 --> 1.046428).  Saving model ...
Validation loss decreased (1.046428 --> 1.045543).  Saving model ...
Validation loss decreased (1.045543 --> 1.043721).  Saving model ...
EarlyStopping counter: 1 out of 5.0
Validation loss decreased (1.043721 --> 1.041781).  Saving model ...
Validation loss decreased (1.041781 --> 1.039145).  Saving model ...
Validation loss decreased (1.039145 --> 1.038333).  Saving model ...
EarlyStopping counter: 1 out of 5.0
EarlyStopping counter: 2 out of 5.0
Validation loss decreased (1.038333 --> 1.035767).  Saving model ...
EarlyStopping counter: 1 out of 5.0
Validation loss decreased (1.035767 --> 1.034350).  Saving model ...
EarlyStopping counter: 1 out of 5.0
Validation loss decreased (1.034350 --> 1.030522).  Saving model ...
EarlyStopping counter: 1 out of 5.0
EarlyStopping counter: 2 out of 5.0
EarlyStopping counter: 3 out of 5.0
EarlyStopping counter: 4 out of 5.0
EarlyStopping counter: 5 out of 5.0
/localscratch/yinan.29152320.0/env/lib/python3.7/site-packages/torch/nn/functional.py:1794: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.
  warnings.warn("nn.functional.tanh is deprecated. Use torch.tanh instead.")
/localscratch/yinan.29152320.0/env/lib/python3.7/site-packages/transformers/optimization.py:155: UserWarning: This overload of add_ is deprecated:
	add_(Number alpha, Tensor other)
Consider using one of the following signatures instead:
	add_(Tensor other, *, Number alpha) (Triggered internally at  ../torch/csrc/utils/python_arg_parser.cpp:1025.)
  exp_avg.mul_(beta1).add_(1.0 - beta1, grad)
wandb: Waiting for W&B process to finish, PID 73514... (success).
wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: \ 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: | 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: / 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: \ 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: | 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: / 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: \ 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: | 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: / 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb:                                                                                
wandb: Run history:
wandb:     e_F1 ▁▁▂▄▅▅▆▆▆▆▆▆▆▆▇▇▇▇▇▇▇▇██████████████████
wandb:   e_loss █▇▇▇▆▆▆▆▅▅▅▅▄▄▄▄▃▃▃▃▃▂▂▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁
wandb:     t_F1 ▁▂▃▃▃▄▄▄▅▅▅▅▆▆▆▆▆▆▇▇▇▇▇▇▇▇▇▇██▇█████████
wandb:   t_loss ██▇▇▇▇▇▆▆▆▆▅▅▅▅▅▄▄▄▄▃▄▃▃▃▃▃▃▂▂▂▂▂▂▂▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:     e_F1 54.17125
wandb:   e_loss 1.03254
wandb:     t_F1 63.96623
wandb:   t_loss 0.85416
wandb: 
wandb: Synced 4 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Synced lively-waterfall-2: https://wandb.ai/yinanazhou/xl_512_bs_8_lr_1e06_es_5_lc_True_nr_False_sr_False_stem_True_lemma_False_repeat_1_fold_1/runs/jh7yzy6n
wandb: Find logs at: ./wandb/run-20220317_171743-jh7yzy6n/logs/debug.log
wandb: 

wandb: wandb version 0.12.11 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
2022-03-17 18:27:42.350455: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1
wandb: Tracking run with wandb version 0.12.5
wandb: Syncing run desert-dawn-2
wandb: ⭐️ View project at https://wandb.ai/yinanazhou/xl_512_bs_8_lr_1e06_es_5_lc_True_nr_False_sr_False_stem_True_lemma_False_repeat_1_fold_2
wandb: 🚀 View run at https://wandb.ai/yinanazhou/xl_512_bs_8_lr_1e06_es_5_lc_True_nr_False_sr_False_stem_True_lemma_False_repeat_1_fold_2/runs/kkf83deq
wandb: Run data is saved locally in /project/6002780/yinan/Thesis_MER_Lyrics/lyric-emotion/wandb/run-20220317_182739-kkf83deq
wandb: Run `wandb offline` to turn off syncing.
wandb: Network error (ReadTimeout), entering retry loop.

Validation loss decreased (inf --> 1.456923).  Saving model ...
Validation loss decreased (1.456923 --> 1.426958).  Saving model ...
Validation loss decreased (1.426958 --> 1.405443).  Saving model ...
Validation loss decreased (1.405443 --> 1.389043).  Saving model ...
Validation loss decreased (1.389043 --> 1.374997).  Saving model ...
Validation loss decreased (1.374997 --> 1.365735).  Saving model ...
Validation loss decreased (1.365735 --> 1.357731).  Saving model ...
Validation loss decreased (1.357731 --> 1.351696).  Saving model ...
Validation loss decreased (1.351696 --> 1.346988).  Saving model ...
Validation loss decreased (1.346988 --> 1.342517).  Saving model ...
Validation loss decreased (1.342517 --> 1.339086).  Saving model ...
Validation loss decreased (1.339086 --> 1.335494).  Saving model ...
Validation loss decreased (1.335494 --> 1.332456).  Saving model ...
Validation loss decreased (1.332456 --> 1.329536).  Saving model ...
Validation loss decreased (1.329536 --> 1.326108).  Saving model ...
Validation loss decreased (1.326108 --> 1.323027).  Saving model ...
Validation loss decreased (1.323027 --> 1.320207).  Saving model ...
Validation loss decreased (1.320207 --> 1.317166).  Saving model ...
Validation loss decreased (1.317166 --> 1.313759).  Saving model ...
Validation loss decreased (1.313759 --> 1.310445).  Saving model ...
Validation loss decreased (1.310445 --> 1.306982).  Saving model ...
Validation loss decreased (1.306982 --> 1.302952).  Saving model ...
Validation loss decreased (1.302952 --> 1.298826).  Saving model ...
Validation loss decreased (1.298826 --> 1.294493).  Saving model ...
Validation loss decreased (1.294493 --> 1.290612).  Saving model ...
Validation loss decreased (1.290612 --> 1.285554).  Saving model ...
Validation loss decreased (1.285554 --> 1.281383).  Saving model ...
Validation loss decreased (1.281383 --> 1.276530).  Saving model ...
Validation loss decreased (1.276530 --> 1.271576).  Saving model ...
Validation loss decreased (1.271576 --> 1.266903).  Saving model ...
Validation loss decreased (1.266903 --> 1.261655).  Saving model ...
Validation loss decreased (1.261655 --> 1.256883).  Saving model ...
Validation loss decreased (1.256883 --> 1.251783).  Saving model ...
Validation loss decreased (1.251783 --> 1.246926).  Saving model ...
Validation loss decreased (1.246926 --> 1.241418).  Saving model ...
Validation loss decreased (1.241418 --> 1.234855).  Saving model ...
Validation loss decreased (1.234855 --> 1.229395).  Saving model ...
Validation loss decreased (1.229395 --> 1.224196).  Saving model ...
Validation loss decreased (1.224196 --> 1.218906).  Saving model ...
Validation loss decreased (1.218906 --> 1.213118).  Saving model ...
Validation loss decreased (1.213118 --> 1.208843).  Saving model ...
Validation loss decreased (1.208843 --> 1.202795).  Saving model ...
Validation loss decreased (1.202795 --> 1.197575).  Saving model ...
Validation loss decreased (1.197575 --> 1.192423).  Saving model ...
Validation loss decreased (1.192423 --> 1.187096).  Saving model ...
Validation loss decreased (1.187096 --> 1.181717).  Saving model ...
Validation loss decreased (1.181717 --> 1.176464).  Saving model ...
Validation loss decreased (1.176464 --> 1.171791).  Saving model ...
Validation loss decreased (1.171791 --> 1.166287).  Saving model ...
Validation loss decreased (1.166287 --> 1.161264).  Saving model ...
Validation loss decreased (1.161264 --> 1.155222).  Saving model ...
Validation loss decreased (1.155222 --> 1.150620).  Saving model ...
Validation loss decreased (1.150620 --> 1.145947).  Saving model ...
Validation loss decreased (1.145947 --> 1.140463).  Saving model ...
Validation loss decreased (1.140463 --> 1.136176).  Saving model ...
Validation loss decreased (1.136176 --> 1.130635).  Saving model ...
Validation loss decreased (1.130635 --> 1.126597).  Saving model ...
Validation loss decreased (1.126597 --> 1.123000).  Saving model ...
Validation loss decreased (1.123000 --> 1.118902).  Saving model ...
Validation loss decreased (1.118902 --> 1.114039).  Saving model ...
Validation loss decreased (1.114039 --> 1.110385).  Saving model ...
Validation loss decreased (1.110385 --> 1.105148).  Saving model ...
Validation loss decreased (1.105148 --> 1.101670).  Saving model ...
Validation loss decreased (1.101670 --> 1.096781).  Saving model ...
Validation loss decreased (1.096781 --> 1.094117).  Saving model ...
Validation loss decreased (1.094117 --> 1.089730).  Saving model ...
Validation loss decreased (1.089730 --> 1.084635).  Saving model ...
Validation loss decreased (1.084635 --> 1.080363).  Saving model ...
Validation loss decreased (1.080363 --> 1.076352).  Saving model ...
Validation loss decreased (1.076352 --> 1.072979).  Saving model ...
Validation loss decreased (1.072979 --> 1.068486).  Saving model ...
Validation loss decreased (1.068486 --> 1.064597).  Saving model ...
Validation loss decreased (1.064597 --> 1.061471).  Saving model ...
Validation loss decreased (1.061471 --> 1.056507).  Saving model ...
Validation loss decreased (1.056507 --> 1.053549).  Saving model ...
Validation loss decreased (1.053549 --> 1.051343).  Saving model ...
Validation loss decreased (1.051343 --> 1.049051).  Saving model ...
Validation loss decreased (1.049051 --> 1.045476).  Saving model ...
Validation loss decreased (1.045476 --> 1.042090).  Saving model ...
Validation loss decreased (1.042090 --> 1.038864).  Saving model ...
Validation loss decreased (1.038864 --> 1.035057).  Saving model ...
Validation loss decreased (1.035057 --> 1.031139).  Saving model ...
Validation loss decreased (1.031139 --> 1.029572).  Saving model ...
Validation loss decreased (1.029572 --> 1.024117).  Saving model ...
Validation loss decreased (1.024117 --> 1.022923).  Saving model ...
Validation loss decreased (1.022923 --> 1.019063).  Saving model ...
Validation loss decreased (1.019063 --> 1.017000).  Saving model ...
Validation loss decreased (1.017000 --> 1.013193).  Saving model ...
Validation loss decreased (1.013193 --> 1.010969).  Saving model ...
Validation loss decreased (1.010969 --> 1.008457).  Saving model ...
Validation loss decreased (1.008457 --> 1.007243).  Saving model ...
Validation loss decreased (1.007243 --> 1.004035).  Saving model ...
EarlyStopping counter: 1 out of 5.0
Validation loss decreased (1.004035 --> 1.001986).  Saving model ...
Validation loss decreased (1.001986 --> 0.998709).  Saving model ...
Validation loss decreased (0.998709 --> 0.997715).  Saving model ...
Validation loss decreased (0.997715 --> 0.993587).  Saving model ...
Validation loss decreased (0.993587 --> 0.993049).  Saving model ...
Validation loss decreased (0.993049 --> 0.990747).  Saving model ...
EarlyStopping counter: 1 out of 5.0
Validation loss decreased (0.990747 --> 0.989067).  Saving model ...
Validation loss decreased (0.989067 --> 0.986914).  Saving model ...
Validation loss decreased (0.986914 --> 0.983282).  Saving model ...
Validation loss decreased (0.983282 --> 0.981665).  Saving model ...
Validation loss decreased (0.981665 --> 0.980546).  Saving model ...
Validation loss decreased (0.980546 --> 0.979376).  Saving model ...
Validation loss decreased (0.979376 --> 0.978635).  Saving model ...
Validation loss decreased (0.978635 --> 0.976176).  Saving model ...
EarlyStopping counter: 1 out of 5.0
Validation loss decreased (0.976176 --> 0.973628).  Saving model ...
EarlyStopping counter: 1 out of 5.0
Validation loss decreased (0.973628 --> 0.973474).  Saving model ...
Validation loss decreased (0.973474 --> 0.969304).  Saving model ...
EarlyStopping counter: 1 out of 5.0
EarlyStopping counter: 2 out of 5.0
Validation loss decreased (0.969304 --> 0.968310).  Saving model ...
Validation loss decreased (0.968310 --> 0.965003).  Saving model ...
Validation loss decreased (0.965003 --> 0.963722).  Saving model ...
EarlyStopping counter: 1 out of 5.0
Validation loss decreased (0.963722 --> 0.962494).  Saving model ...
EarlyStopping counter: 1 out of 5.0
Validation loss decreased (0.962494 --> 0.959151).  Saving model ...
EarlyStopping counter: 1 out of 5.0
EarlyStopping counter: 2 out of 5.0
EarlyStopping counter: 3 out of 5.0
EarlyStopping counter: 4 out of 5.0
EarlyStopping counter: 5 out of 5.0
/localscratch/yinan.29152320.0/env/lib/python3.7/site-packages/torch/nn/functional.py:1794: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.
  warnings.warn("nn.functional.tanh is deprecated. Use torch.tanh instead.")
wandb: Waiting for W&B process to finish, PID 77237... (success).
wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: \ 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: | 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: / 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: \ 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: | 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: / 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: \ 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: | 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: / 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb:                                                                                
wandb: Run history:
wandb:     e_F1 ▁▂▄▅▅▄▅▅▅▅▅▆▆▆▆▇▇▇▇▇▇▇▇▇████████████████
wandb:   e_loss █▇▇▆▆▆▆▆▆▅▅▅▅▄▄▄▄▃▃▃▃▃▂▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁
wandb:     t_F1 ▁▂▃▃▃▃▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▆▇▆▇▇▇▇▇▇▇▇▇▇▇▇████
wandb:   t_loss █▇▇▇▇▆▆▆▆▆▅▅▅▅▅▅▄▄▄▄▄▃▃▃▃▃▃▃▂▂▂▂▂▂▂▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:     e_F1 59.37191
wandb:   e_loss 0.95926
wandb:     t_F1 68.52003
wandb:   t_loss 0.83747
wandb: 
wandb: Synced 4 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Synced desert-dawn-2: https://wandb.ai/yinanazhou/xl_512_bs_8_lr_1e06_es_5_lc_True_nr_False_sr_False_stem_True_lemma_False_repeat_1_fold_2/runs/kkf83deq
wandb: Find logs at: ./wandb/run-20220317_182739-kkf83deq/logs/debug.log
wandb: 

wandb: wandb version 0.12.11 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
2022-03-17 19:52:04.507988: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1
wandb: Tracking run with wandb version 0.12.5
wandb: Syncing run peachy-field-2
wandb: ⭐️ View project at https://wandb.ai/yinanazhou/xl_512_bs_8_lr_1e06_es_5_lc_True_nr_False_sr_False_stem_True_lemma_False_repeat_2_fold_1
wandb: 🚀 View run at https://wandb.ai/yinanazhou/xl_512_bs_8_lr_1e06_es_5_lc_True_nr_False_sr_False_stem_True_lemma_False_repeat_2_fold_1/runs/qhcdtz0f
wandb: Run data is saved locally in /project/6002780/yinan/Thesis_MER_Lyrics/lyric-emotion/wandb/run-20220317_195202-qhcdtz0f
wandb: Run `wandb offline` to turn off syncing.

Validation loss decreased (inf --> 1.427531).  Saving model ...
Validation loss decreased (1.427531 --> 1.414821).  Saving model ...
Validation loss decreased (1.414821 --> 1.405278).  Saving model ...
Validation loss decreased (1.405278 --> 1.397724).  Saving model ...
Validation loss decreased (1.397724 --> 1.391637).  Saving model ...
Validation loss decreased (1.391637 --> 1.385576).  Saving model ...
Validation loss decreased (1.385576 --> 1.380873).  Saving model ...
Validation loss decreased (1.380873 --> 1.376506).  Saving model ...
Validation loss decreased (1.376506 --> 1.372002).  Saving model ...
Validation loss decreased (1.372002 --> 1.367581).  Saving model ...
Validation loss decreased (1.367581 --> 1.363428).  Saving model ...
Validation loss decreased (1.363428 --> 1.358651).  Saving model ...
Validation loss decreased (1.358651 --> 1.354480).  Saving model ...
Validation loss decreased (1.354480 --> 1.349504).  Saving model ...
Validation loss decreased (1.349504 --> 1.344103).  Saving model ...
Validation loss decreased (1.344103 --> 1.338851).  Saving model ...
Validation loss decreased (1.338851 --> 1.332915).  Saving model ...
Validation loss decreased (1.332915 --> 1.326998).  Saving model ...
Validation loss decreased (1.326998 --> 1.320096).  Saving model ...
Validation loss decreased (1.320096 --> 1.313249).  Saving model ...
Validation loss decreased (1.313249 --> 1.306121).  Saving model ...
Validation loss decreased (1.306121 --> 1.298573).  Saving model ...
Validation loss decreased (1.298573 --> 1.291460).  Saving model ...
Validation loss decreased (1.291460 --> 1.282555).  Saving model ...
Validation loss decreased (1.282555 --> 1.275004).  Saving model ...
Validation loss decreased (1.275004 --> 1.267558).  Saving model ...
Validation loss decreased (1.267558 --> 1.260973).  Saving model ...
Validation loss decreased (1.260973 --> 1.253914).  Saving model ...
Validation loss decreased (1.253914 --> 1.247253).  Saving model ...
Validation loss decreased (1.247253 --> 1.239901).  Saving model ...
Validation loss decreased (1.239901 --> 1.232908).  Saving model ...
Validation loss decreased (1.232908 --> 1.224505).  Saving model ...
Validation loss decreased (1.224505 --> 1.218323).  Saving model ...
Validation loss decreased (1.218323 --> 1.211181).  Saving model ...
Validation loss decreased (1.211181 --> 1.204786).  Saving model ...
Validation loss decreased (1.204786 --> 1.198334).  Saving model ...
Validation loss decreased (1.198334 --> 1.191060).  Saving model ...
Validation loss decreased (1.191060 --> 1.184864).  Saving model ...
Validation loss decreased (1.184864 --> 1.179152).  Saving model ...
Validation loss decreased (1.179152 --> 1.172769).  Saving model ...
Validation loss decreased (1.172769 --> 1.166939).  Saving model ...
Validation loss decreased (1.166939 --> 1.161075).  Saving model ...
Validation loss decreased (1.161075 --> 1.155053).  Saving model ...
Validation loss decreased (1.155053 --> 1.150302).  Saving model ...
Validation loss decreased (1.150302 --> 1.144530).  Saving model ...
Validation loss decreased (1.144530 --> 1.139546).  Saving model ...
Validation loss decreased (1.139546 --> 1.134289).  Saving model ...
Validation loss decreased (1.134289 --> 1.129350).  Saving model ...
Validation loss decreased (1.129350 --> 1.125086).  Saving model ...
Validation loss decreased (1.125086 --> 1.119412).  Saving model ...
Validation loss decreased (1.119412 --> 1.115244).  Saving model ...
Validation loss decreased (1.115244 --> 1.110657).  Saving model ...
Validation loss decreased (1.110657 --> 1.107163).  Saving model ...
Validation loss decreased (1.107163 --> 1.102327).  Saving model ...
Validation loss decreased (1.102327 --> 1.097523).  Saving model ...
Validation loss decreased (1.097523 --> 1.093670).  Saving model ...
Validation loss decreased (1.093670 --> 1.089619).  Saving model ...
Validation loss decreased (1.089619 --> 1.085679).  Saving model ...
Validation loss decreased (1.085679 --> 1.081339).  Saving model ...
Validation loss decreased (1.081339 --> 1.077123).  Saving model ...
Validation loss decreased (1.077123 --> 1.074199).  Saving model ...
Validation loss decreased (1.074199 --> 1.070616).  Saving model ...
Validation loss decreased (1.070616 --> 1.067213).  Saving model ...
Validation loss decreased (1.067213 --> 1.063909).  Saving model ...
Validation loss decreased (1.063909 --> 1.061501).  Saving model ...
Validation loss decreased (1.061501 --> 1.058677).  Saving model ...
Validation loss decreased (1.058677 --> 1.054899).  Saving model ...
Validation loss decreased (1.054899 --> 1.052189).  Saving model ...
Validation loss decreased (1.052189 --> 1.050375).  Saving model ...
Validation loss decreased (1.050375 --> 1.047567).  Saving model ...
Validation loss decreased (1.047567 --> 1.044857).  Saving model ...
Validation loss decreased (1.044857 --> 1.042168).  Saving model ...
Validation loss decreased (1.042168 --> 1.040267).  Saving model ...
Validation loss decreased (1.040267 --> 1.037032).  Saving model ...
Validation loss decreased (1.037032 --> 1.033695).  Saving model ...
Validation loss decreased (1.033695 --> 1.031372).  Saving model ...
Validation loss decreased (1.031372 --> 1.030016).  Saving model ...
Validation loss decreased (1.030016 --> 1.028109).  Saving model ...
Validation loss decreased (1.028109 --> 1.026489).  Saving model ...
Validation loss decreased (1.026489 --> 1.023804).  Saving model ...
Validation loss decreased (1.023804 --> 1.023037).  Saving model ...
Validation loss decreased (1.023037 --> 1.021355).  Saving model ...
Validation loss decreased (1.021355 --> 1.019313).  Saving model ...
Validation loss decreased (1.019313 --> 1.017520).  Saving model ...
Validation loss decreased (1.017520 --> 1.015125).  Saving model ...
Validation loss decreased (1.015125 --> 1.014156).  Saving model ...
Validation loss decreased (1.014156 --> 1.012740).  Saving model ...
Validation loss decreased (1.012740 --> 1.011002).  Saving model ...
Validation loss decreased (1.011002 --> 1.009872).  Saving model ...
Validation loss decreased (1.009872 --> 1.008389).  Saving model ...
Validation loss decreased (1.008389 --> 1.007705).  Saving model ...
Validation loss decreased (1.007705 --> 1.006618).  Saving model ...
Validation loss decreased (1.006618 --> 1.005170).  Saving model ...
Validation loss decreased (1.005170 --> 1.003595).  Saving model ...
EarlyStopping counter: 1 out of 5.0
Validation loss decreased (1.003595 --> 1.002167).  Saving model ...
Validation loss decreased (1.002167 --> 1.001181).  Saving model ...
Validation loss decreased (1.001181 --> 1.000831).  Saving model ...
Validation loss decreased (1.000831 --> 1.000349).  Saving model ...
Validation loss decreased (1.000349 --> 0.998115).  Saving model ...
Validation loss decreased (0.998115 --> 0.996643).  Saving model ...
Validation loss decreased (0.996643 --> 0.995936).  Saving model ...
Validation loss decreased (0.995936 --> 0.995146).  Saving model ...
EarlyStopping counter: 1 out of 5.0
EarlyStopping counter: 2 out of 5.0
Validation loss decreased (0.995146 --> 0.994718).  Saving model ...
Validation loss decreased (0.994718 --> 0.994063).  Saving model ...
Validation loss decreased (0.994063 --> 0.992958).  Saving model ...
Validation loss decreased (0.992958 --> 0.992505).  Saving model ...
Validation loss decreased (0.992505 --> 0.990354).  Saving model ...
Validation loss decreased (0.990354 --> 0.990006).  Saving model ...
Validation loss decreased (0.990006 --> 0.989726).  Saving model ...
EarlyStopping counter: 1 out of 5.0
EarlyStopping counter: 2 out of 5.0
EarlyStopping counter: 3 out of 5.0
Validation loss decreased (0.989726 --> 0.989393).  Saving model ...
EarlyStopping counter: 1 out of 5.0
EarlyStopping counter: 2 out of 5.0
EarlyStopping counter: 3 out of 5.0
EarlyStopping counter: 4 out of 5.0
Validation loss decreased (0.989393 --> 0.989280).  Saving model ...
Validation loss decreased (0.989280 --> 0.988763).  Saving model ...
Validation loss decreased (0.988763 --> 0.988572).  Saving model ...
EarlyStopping counter: 1 out of 5.0
EarlyStopping counter: 2 out of 5.0
EarlyStopping counter: 3 out of 5.0
EarlyStopping counter: 4 out of 5.0
EarlyStopping counter: 5 out of 5.0
/localscratch/yinan.29152320.0/env/lib/python3.7/site-packages/torch/nn/functional.py:1794: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.
  warnings.warn("nn.functional.tanh is deprecated. Use torch.tanh instead.")
wandb: Waiting for W&B process to finish, PID 81692... (success).
wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: \ 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: | 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: / 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb:                                                                                
wandb: Run history:
wandb:     e_F1 ▁▁▃▄▅▅▅▆▆▇▇▇▇▇▇▇▇▇█▇████████████████████
wandb:   e_loss ██▇▇▇▇▆▆▆▅▅▄▄▄▃▃▃▃▂▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:     t_F1 ▁▂▂▃▄▃▄▄▄▄▅▅▆▆▆▆▆▆▇▆▇▇▇▇▇▇▇▇▇█▇█████████
wandb:   t_loss ███▇▇▇▇▇▆▆▆▆▅▅▅▄▄▄▄▄▃▃▃▃▃▃▃▂▂▂▂▂▂▂▂▁▂▁▁▁
wandb: 
wandb: Run summary:
wandb:     e_F1 56.79402
wandb:   e_loss 0.99131
wandb:     t_F1 71.24838
wandb:   t_loss 0.77224
wandb: 
wandb: Synced 4 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Synced peachy-field-2: https://wandb.ai/yinanazhou/xl_512_bs_8_lr_1e06_es_5_lc_True_nr_False_sr_False_stem_True_lemma_False_repeat_2_fold_1/runs/qhcdtz0f
wandb: Find logs at: ./wandb/run-20220317_195202-qhcdtz0f/logs/debug.log
wandb: 

wandb: wandb version 0.12.11 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
2022-03-17 21:17:03.130556: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1
wandb: Tracking run with wandb version 0.12.5
wandb: Syncing run dazzling-cloud-2
wandb: ⭐️ View project at https://wandb.ai/yinanazhou/xl_512_bs_8_lr_1e06_es_5_lc_True_nr_False_sr_False_stem_True_lemma_False_repeat_2_fold_2
wandb: 🚀 View run at https://wandb.ai/yinanazhou/xl_512_bs_8_lr_1e06_es_5_lc_True_nr_False_sr_False_stem_True_lemma_False_repeat_2_fold_2/runs/29ow4jrb
wandb: Run data is saved locally in /project/6002780/yinan/Thesis_MER_Lyrics/lyric-emotion/wandb/run-20220317_211659-29ow4jrb
wandb: Run `wandb offline` to turn off syncing.
wandb: Network error (ReadTimeout), entering retry loop.

Validation loss decreased (inf --> 1.435585).  Saving model ...
Validation loss decreased (1.435585 --> 1.419007).  Saving model ...
Validation loss decreased (1.419007 --> 1.406566).  Saving model ...
Validation loss decreased (1.406566 --> 1.397075).  Saving model ...
Validation loss decreased (1.397075 --> 1.389777).  Saving model ...
Validation loss decreased (1.389777 --> 1.383813).  Saving model ...
Validation loss decreased (1.383813 --> 1.378462).  Saving model ...
Validation loss decreased (1.378462 --> 1.373865).  Saving model ...
Validation loss decreased (1.373865 --> 1.369544).  Saving model ...
Validation loss decreased (1.369544 --> 1.365505).  Saving model ...
Validation loss decreased (1.365505 --> 1.361946).  Saving model ...
Validation loss decreased (1.361946 --> 1.358411).  Saving model ...
Validation loss decreased (1.358411 --> 1.354858).  Saving model ...
Validation loss decreased (1.354858 --> 1.351386).  Saving model ...
Validation loss decreased (1.351386 --> 1.347799).  Saving model ...
Validation loss decreased (1.347799 --> 1.343843).  Saving model ...
Validation loss decreased (1.343843 --> 1.340344).  Saving model ...
Validation loss decreased (1.340344 --> 1.336299).  Saving model ...
Validation loss decreased (1.336299 --> 1.332022).  Saving model ...
Validation loss decreased (1.332022 --> 1.327744).  Saving model ...
Validation loss decreased (1.327744 --> 1.322702).  Saving model ...
Validation loss decreased (1.322702 --> 1.317528).  Saving model ...
Validation loss decreased (1.317528 --> 1.312351).  Saving model ...
Validation loss decreased (1.312351 --> 1.307195).  Saving model ...
Validation loss decreased (1.307195 --> 1.301305).  Saving model ...
Validation loss decreased (1.301305 --> 1.295145).  Saving model ...
Validation loss decreased (1.295145 --> 1.288698).  Saving model ...
Validation loss decreased (1.288698 --> 1.282951).  Saving model ...
Validation loss decreased (1.282951 --> 1.277330).  Saving model ...
Validation loss decreased (1.277330 --> 1.270438).  Saving model ...
Validation loss decreased (1.270438 --> 1.264718).  Saving model ...
Validation loss decreased (1.264718 --> 1.257344).  Saving model ...
Validation loss decreased (1.257344 --> 1.249016).  Saving model ...
Validation loss decreased (1.249016 --> 1.242652).  Saving model ...
Validation loss decreased (1.242652 --> 1.236249).  Saving model ...
Validation loss decreased (1.236249 --> 1.228375).  Saving model ...
Validation loss decreased (1.228375 --> 1.220632).  Saving model ...
Validation loss decreased (1.220632 --> 1.213572).  Saving model ...
Validation loss decreased (1.213572 --> 1.207134).  Saving model ...
Validation loss decreased (1.207134 --> 1.200630).  Saving model ...
Validation loss decreased (1.200630 --> 1.194835).  Saving model ...
Validation loss decreased (1.194835 --> 1.189071).  Saving model ...
Validation loss decreased (1.189071 --> 1.181510).  Saving model ...
Validation loss decreased (1.181510 --> 1.175762).  Saving model ...
Validation loss decreased (1.175762 --> 1.169490).  Saving model ...
Validation loss decreased (1.169490 --> 1.162495).  Saving model ...
Validation loss decreased (1.162495 --> 1.156270).  Saving model ...
Validation loss decreased (1.156270 --> 1.151242).  Saving model ...
Validation loss decreased (1.151242 --> 1.145893).  Saving model ...
Validation loss decreased (1.145893 --> 1.140551).  Saving model ...
Validation loss decreased (1.140551 --> 1.135271).  Saving model ...
Validation loss decreased (1.135271 --> 1.129653).  Saving model ...
Validation loss decreased (1.129653 --> 1.124299).  Saving model ...
Validation loss decreased (1.124299 --> 1.119864).  Saving model ...
Validation loss decreased (1.119864 --> 1.114669).  Saving model ...
Validation loss decreased (1.114669 --> 1.111838).  Saving model ...
Validation loss decreased (1.111838 --> 1.108323).  Saving model ...
Validation loss decreased (1.108323 --> 1.103435).  Saving model ...
Validation loss decreased (1.103435 --> 1.098118).  Saving model ...
Validation loss decreased (1.098118 --> 1.094545).  Saving model ...
Validation loss decreased (1.094545 --> 1.091615).  Saving model ...
Validation loss decreased (1.091615 --> 1.087597).  Saving model ...
Validation loss decreased (1.087597 --> 1.083608).  Saving model ...
Validation loss decreased (1.083608 --> 1.078822).  Saving model ...
Validation loss decreased (1.078822 --> 1.075793).  Saving model ...
Validation loss decreased (1.075793 --> 1.071192).  Saving model ...
Validation loss decreased (1.071192 --> 1.066794).  Saving model ...
Validation loss decreased (1.066794 --> 1.064395).  Saving model ...
Validation loss decreased (1.064395 --> 1.059918).  Saving model ...
Validation loss decreased (1.059918 --> 1.056468).  Saving model ...
Validation loss decreased (1.056468 --> 1.054201).  Saving model ...
Validation loss decreased (1.054201 --> 1.050199).  Saving model ...
Validation loss decreased (1.050199 --> 1.047432).  Saving model ...
Validation loss decreased (1.047432 --> 1.044953).  Saving model ...
Validation loss decreased (1.044953 --> 1.042155).  Saving model ...
Validation loss decreased (1.042155 --> 1.039210).  Saving model ...
Validation loss decreased (1.039210 --> 1.036284).  Saving model ...
Validation loss decreased (1.036284 --> 1.033368).  Saving model ...
Validation loss decreased (1.033368 --> 1.031004).  Saving model ...
Validation loss decreased (1.031004 --> 1.027213).  Saving model ...
Validation loss decreased (1.027213 --> 1.024272).  Saving model ...
Validation loss decreased (1.024272 --> 1.021358).  Saving model ...
Validation loss decreased (1.021358 --> 1.019077).  Saving model ...
Validation loss decreased (1.019077 --> 1.016455).  Saving model ...
Validation loss decreased (1.016455 --> 1.012720).  Saving model ...
Validation loss decreased (1.012720 --> 1.010152).  Saving model ...
Validation loss decreased (1.010152 --> 1.007296).  Saving model ...
Validation loss decreased (1.007296 --> 1.003239).  Saving model ...
Validation loss decreased (1.003239 --> 1.000011).  Saving model ...
Validation loss decreased (1.000011 --> 0.999166).  Saving model ...
Validation loss decreased (0.999166 --> 0.998215).  Saving model ...
Validation loss decreased (0.998215 --> 0.995437).  Saving model ...
Validation loss decreased (0.995437 --> 0.991660).  Saving model ...
Validation loss decreased (0.991660 --> 0.988293).  Saving model ...
Validation loss decreased (0.988293 --> 0.986683).  Saving model ...
Validation loss decreased (0.986683 --> 0.985110).  Saving model ...
Validation loss decreased (0.985110 --> 0.981877).  Saving model ...
Validation loss decreased (0.981877 --> 0.979662).  Saving model ...
Validation loss decreased (0.979662 --> 0.977652).  Saving model ...
Validation loss decreased (0.977652 --> 0.975400).  Saving model ...
Validation loss decreased (0.975400 --> 0.973436).  Saving model ...
Validation loss decreased (0.973436 --> 0.973124).  Saving model ...
Validation loss decreased (0.973124 --> 0.971370).  Saving model ...
Validation loss decreased (0.971370 --> 0.968015).  Saving model ...
Validation loss decreased (0.968015 --> 0.967117).  Saving model ...
Validation loss decreased (0.967117 --> 0.965790).  Saving model ...
Validation loss decreased (0.965790 --> 0.964034).  Saving model ...
Validation loss decreased (0.964034 --> 0.962537).  Saving model ...
Validation loss decreased (0.962537 --> 0.959486).  Saving model ...
Validation loss decreased (0.959486 --> 0.957916).  Saving model ...
Validation loss decreased (0.957916 --> 0.956157).  Saving model ...
Validation loss decreased (0.956157 --> 0.954110).  Saving model ...
Validation loss decreased (0.954110 --> 0.953487).  Saving model ...
Validation loss decreased (0.953487 --> 0.952775).  Saving model ...
EarlyStopping counter: 1 out of 5.0
Validation loss decreased (0.952775 --> 0.952226).  Saving model ...
Validation loss decreased (0.952226 --> 0.950278).  Saving model ...
EarlyStopping counter: 1 out of 5.0
Validation loss decreased (0.950278 --> 0.949095).  Saving model ...
Validation loss decreased (0.949095 --> 0.947800).  Saving model ...
Validation loss decreased (0.947800 --> 0.946529).  Saving model ...
Validation loss decreased (0.946529 --> 0.944686).  Saving model ...
Validation loss decreased (0.944686 --> 0.942140).  Saving model ...
EarlyStopping counter: 1 out of 5.0
Validation loss decreased (0.942140 --> 0.941758).  Saving model ...
Validation loss decreased (0.941758 --> 0.940657).  Saving model ...
EarlyStopping counter: 1 out of 5.0
Validation loss decreased (0.940657 --> 0.940619).  Saving model ...
Validation loss decreased (0.940619 --> 0.939956).  Saving model ...
Validation loss decreased (0.939956 --> 0.938122).  Saving model ...
Validation loss decreased (0.938122 --> 0.938100).  Saving model ...
Validation loss decreased (0.938100 --> 0.935535).  Saving model ...
EarlyStopping counter: 1 out of 5.0
Validation loss decreased (0.935535 --> 0.934588).  Saving model ...
Validation loss decreased (0.934588 --> 0.933589).  Saving model ...
EarlyStopping counter: 1 out of 5.0
Validation loss decreased (0.933589 --> 0.932469).  Saving model ...
Validation loss decreased (0.932469 --> 0.931491).  Saving model ...
EarlyStopping counter: 1 out of 5.0
EarlyStopping counter: 2 out of 5.0
EarlyStopping counter: 3 out of 5.0
Validation loss decreased (0.931491 --> 0.930246).  Saving model ...
Validation loss decreased (0.930246 --> 0.928838).  Saving model ...
Validation loss decreased (0.928838 --> 0.928657).  Saving model ...
EarlyStopping counter: 1 out of 5.0
Validation loss decreased (0.928657 --> 0.927870).  Saving model ...
Validation loss decreased (0.927870 --> 0.927585).  Saving model ...
EarlyStopping counter: 1 out of 5.0
Validation loss decreased (0.927585 --> 0.925584).  Saving model ...
EarlyStopping counter: 1 out of 5.0
Validation loss decreased (0.925584 --> 0.925564).  Saving model ...
EarlyStopping counter: 1 out of 5.0
EarlyStopping counter: 2 out of 5.0
EarlyStopping counter: 3 out of 5.0
EarlyStopping counter: 4 out of 5.0
EarlyStopping counter: 5 out of 5.0
/localscratch/yinan.29152320.0/env/lib/python3.7/site-packages/torch/nn/functional.py:1794: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.
  warnings.warn("nn.functional.tanh is deprecated. Use torch.tanh instead.")
wandb: Waiting for W&B process to finish, PID 86221... (success).
wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: \ 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: | 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: / 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: \ 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: | 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: / 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: \ 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: | 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: / 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb:                                                                                
wandb: Run history:
wandb:     e_F1 ▁▁▂▃▄▅▅▆▆▆▆▆▆▇▇▇▇▇▇▇▇███████████████████
wandb:   e_loss ██▇▇▇▇▆▆▆▅▅▅▄▄▄▃▃▃▃▃▂▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁
wandb:     t_F1 ▁▂▂▃▃▄▄▄▅▅▅▅▆▅▆▆▆▆▆▆▇▇▇▇▇▇▇█▇▇██████████
wandb:   t_loss ███▇▇▇▇▆▆▆▆▅▅▅▅▄▄▄▄▄▃▃▃▃▃▃▂▂▂▂▂▂▂▂▂▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:     e_F1 60.51654
wandb:   e_loss 0.92705
wandb:     t_F1 69.22668
wandb:   t_loss 0.74908
wandb: 
wandb: Synced 4 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Synced dazzling-cloud-2: https://wandb.ai/yinanazhou/xl_512_bs_8_lr_1e06_es_5_lc_True_nr_False_sr_False_stem_True_lemma_False_repeat_2_fold_2/runs/29ow4jrb
wandb: Find logs at: ./wandb/run-20220317_211659-29ow4jrb/logs/debug.log
wandb: 

wandb: wandb version 0.12.11 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
2022-03-17 22:56:40.900752: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1
wandb: Tracking run with wandb version 0.12.5
wandb: Syncing run bright-river-2
wandb: ⭐️ View project at https://wandb.ai/yinanazhou/xl_512_bs_8_lr_1e06_es_5_lc_True_nr_False_sr_False_stem_True_lemma_False_repeat_3_fold_1
wandb: 🚀 View run at https://wandb.ai/yinanazhou/xl_512_bs_8_lr_1e06_es_5_lc_True_nr_False_sr_False_stem_True_lemma_False_repeat_3_fold_1/runs/35ggcsf6
wandb: Run data is saved locally in /project/6002780/yinan/Thesis_MER_Lyrics/lyric-emotion/wandb/run-20220317_225637-35ggcsf6
wandb: Run `wandb offline` to turn off syncing.

Validation loss decreased (inf --> 1.437754).  Saving model ...
Validation loss decreased (1.437754 --> 1.418211).  Saving model ...
Validation loss decreased (1.418211 --> 1.402736).  Saving model ...
Validation loss decreased (1.402736 --> 1.389481).  Saving model ...
Validation loss decreased (1.389481 --> 1.380322).  Saving model ...
Validation loss decreased (1.380322 --> 1.372566).  Saving model ...
Validation loss decreased (1.372566 --> 1.366194).  Saving model ...
Validation loss decreased (1.366194 --> 1.360955).  Saving model ...
Validation loss decreased (1.360955 --> 1.356475).  Saving model ...
Validation loss decreased (1.356475 --> 1.352851).  Saving model ...
Validation loss decreased (1.352851 --> 1.348915).  Saving model ...
Validation loss decreased (1.348915 --> 1.345054).  Saving model ...
Validation loss decreased (1.345054 --> 1.341277).  Saving model ...
Validation loss decreased (1.341277 --> 1.337562).  Saving model ...
Validation loss decreased (1.337562 --> 1.333859).  Saving model ...
Validation loss decreased (1.333859 --> 1.330262).  Saving model ...
Validation loss decreased (1.330262 --> 1.327000).  Saving model ...
Validation loss decreased (1.327000 --> 1.323583).  Saving model ...
Validation loss decreased (1.323583 --> 1.319910).  Saving model ...
Validation loss decreased (1.319910 --> 1.315941).  Saving model ...
Validation loss decreased (1.315941 --> 1.311946).  Saving model ...
Validation loss decreased (1.311946 --> 1.307958).  Saving model ...
Validation loss decreased (1.307958 --> 1.303763).  Saving model ...
Validation loss decreased (1.303763 --> 1.299880).  Saving model ...
Validation loss decreased (1.299880 --> 1.295525).  Saving model ...
Validation loss decreased (1.295525 --> 1.290776).  Saving model ...
Validation loss decreased (1.290776 --> 1.285854).  Saving model ...
Validation loss decreased (1.285854 --> 1.280923).  Saving model ...
Validation loss decreased (1.280923 --> 1.275657).  Saving model ...
Validation loss decreased (1.275657 --> 1.270129).  Saving model ...
Validation loss decreased (1.270129 --> 1.265363).  Saving model ...
Validation loss decreased (1.265363 --> 1.260222).  Saving model ...
Validation loss decreased (1.260222 --> 1.255124).  Saving model ...
Validation loss decreased (1.255124 --> 1.249941).  Saving model ...
Validation loss decreased (1.249941 --> 1.244456).  Saving model ...
Validation loss decreased (1.244456 --> 1.239023).  Saving model ...
Validation loss decreased (1.239023 --> 1.233837).  Saving model ...
Validation loss decreased (1.233837 --> 1.228451).  Saving model ...
Validation loss decreased (1.228451 --> 1.222464).  Saving model ...
Validation loss decreased (1.222464 --> 1.217439).  Saving model ...
Validation loss decreased (1.217439 --> 1.212032).  Saving model ...
Validation loss decreased (1.212032 --> 1.207435).  Saving model ...
Validation loss decreased (1.207435 --> 1.201369).  Saving model ...
Validation loss decreased (1.201369 --> 1.197159).  Saving model ...
Validation loss decreased (1.197159 --> 1.191492).  Saving model ...
Validation loss decreased (1.191492 --> 1.185779).  Saving model ...
Validation loss decreased (1.185779 --> 1.180849).  Saving model ...
Validation loss decreased (1.180849 --> 1.177712).  Saving model ...
Validation loss decreased (1.177712 --> 1.172818).  Saving model ...
Validation loss decreased (1.172818 --> 1.167116).  Saving model ...
Validation loss decreased (1.167116 --> 1.160690).  Saving model ...
Validation loss decreased (1.160690 --> 1.155282).  Saving model ...
Validation loss decreased (1.155282 --> 1.152623).  Saving model ...
Validation loss decreased (1.152623 --> 1.146470).  Saving model ...
Validation loss decreased (1.146470 --> 1.141618).  Saving model ...
Validation loss decreased (1.141618 --> 1.137732).  Saving model ...
Validation loss decreased (1.137732 --> 1.132644).  Saving model ...
Validation loss decreased (1.132644 --> 1.127397).  Saving model ...
Validation loss decreased (1.127397 --> 1.123294).  Saving model ...
Validation loss decreased (1.123294 --> 1.120164).  Saving model ...
Validation loss decreased (1.120164 --> 1.116113).  Saving model ...
Validation loss decreased (1.116113 --> 1.111071).  Saving model ...
Validation loss decreased (1.111071 --> 1.107121).  Saving model ...
Validation loss decreased (1.107121 --> 1.104530).  Saving model ...
Validation loss decreased (1.104530 --> 1.100726).  Saving model ...
Validation loss decreased (1.100726 --> 1.098474).  Saving model ...
Validation loss decreased (1.098474 --> 1.092437).  Saving model ...
Validation loss decreased (1.092437 --> 1.089682).  Saving model ...
Validation loss decreased (1.089682 --> 1.086015).  Saving model ...
Validation loss decreased (1.086015 --> 1.083152).  Saving model ...
Validation loss decreased (1.083152 --> 1.080225).  Saving model ...
Validation loss decreased (1.080225 --> 1.075522).  Saving model ...
Validation loss decreased (1.075522 --> 1.073095).  Saving model ...
Validation loss decreased (1.073095 --> 1.069959).  Saving model ...
Validation loss decreased (1.069959 --> 1.067529).  Saving model ...
Validation loss decreased (1.067529 --> 1.064845).  Saving model ...
Validation loss decreased (1.064845 --> 1.060816).  Saving model ...
Validation loss decreased (1.060816 --> 1.057835).  Saving model ...
Validation loss decreased (1.057835 --> 1.053333).  Saving model ...
Validation loss decreased (1.053333 --> 1.050181).  Saving model ...
Validation loss decreased (1.050181 --> 1.048152).  Saving model ...
Validation loss decreased (1.048152 --> 1.046493).  Saving model ...
Validation loss decreased (1.046493 --> 1.042128).  Saving model ...
Validation loss decreased (1.042128 --> 1.039969).  Saving model ...
Validation loss decreased (1.039969 --> 1.039728).  Saving model ...
Validation loss decreased (1.039728 --> 1.037582).  Saving model ...
Validation loss decreased (1.037582 --> 1.034985).  Saving model ...
Validation loss decreased (1.034985 --> 1.033807).  Saving model ...
Validation loss decreased (1.033807 --> 1.029909).  Saving model ...
Validation loss decreased (1.029909 --> 1.027200).  Saving model ...
Validation loss decreased (1.027200 --> 1.025208).  Saving model ...
Validation loss decreased (1.025208 --> 1.021594).  Saving model ...
Validation loss decreased (1.021594 --> 1.020564).  Saving model ...
Validation loss decreased (1.020564 --> 1.019763).  Saving model ...
EarlyStopping counter: 1 out of 5.0
Validation loss decreased (1.019763 --> 1.018177).  Saving model ...
Validation loss decreased (1.018177 --> 1.015393).  Saving model ...
Validation loss decreased (1.015393 --> 1.012425).  Saving model ...
EarlyStopping counter: 1 out of 5.0
EarlyStopping counter: 2 out of 5.0
Validation loss decreased (1.012425 --> 1.009476).  Saving model ...
Validation loss decreased (1.009476 --> 1.004580).  Saving model ...
Validation loss decreased (1.004580 --> 1.002640).  Saving model ...
Validation loss decreased (1.002640 --> 1.000621).  Saving model ...
Validation loss decreased (1.000621 --> 0.999328).  Saving model ...
Validation loss decreased (0.999328 --> 0.998260).  Saving model ...
Validation loss decreased (0.998260 --> 0.997600).  Saving model ...
Validation loss decreased (0.997600 --> 0.995419).  Saving model ...
EarlyStopping counter: 1 out of 5.0
EarlyStopping counter: 2 out of 5.0
Validation loss decreased (0.995419 --> 0.993482).  Saving model ...
Validation loss decreased (0.993482 --> 0.989221).  Saving model ...
EarlyStopping counter: 1 out of 5.0
EarlyStopping counter: 2 out of 5.0
Validation loss decreased (0.989221 --> 0.988546).  Saving model ...
EarlyStopping counter: 1 out of 5.0
Validation loss decreased (0.988546 --> 0.987851).  Saving model ...
Validation loss decreased (0.987851 --> 0.984375).  Saving model ...
Validation loss decreased (0.984375 --> 0.984274).  Saving model ...
Validation loss decreased (0.984274 --> 0.981634).  Saving model ...
Validation loss decreased (0.981634 --> 0.981372).  Saving model ...
Validation loss decreased (0.981372 --> 0.977472).  Saving model ...
EarlyStopping counter: 1 out of 5.0
Validation loss decreased (0.977472 --> 0.976749).  Saving model ...
EarlyStopping counter: 1 out of 5.0
EarlyStopping counter: 2 out of 5.0
EarlyStopping counter: 3 out of 5.0
EarlyStopping counter: 4 out of 5.0
EarlyStopping counter: 5 out of 5.0
/localscratch/yinan.29152320.0/env/lib/python3.7/site-packages/torch/nn/functional.py:1794: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.
  warnings.warn("nn.functional.tanh is deprecated. Use torch.tanh instead.")
wandb: Waiting for W&B process to finish, PID 91494... (success).
wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: \ 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: | 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: / 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: \ 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: | 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: / 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: \ 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: | 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: / 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb:                                                                                
wandb: Run history:
wandb:     e_F1 ▁▂▃▄▅▅▅▅▅▅▅▅▆▆▆▆▇▇▇▇▇▇▇▇▇▇▇█████████████
wandb:   e_loss ██▇▇▇▆▆▆▆▆▅▅▅▄▄▄▄▄▃▃▃▃▃▂▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁
wandb:     t_F1 ▁▁▂▂▂▃▃▄▄▄▄▄▅▅▅▅▆▆▆▆▆▆▇▇▆▇▇▇▇▇▇█▇█▇█████
wandb:   t_loss ███▇▇▇▇▇▇▆▆▆▆▅▅▅▅▄▄▄▄▄▃▃▃▃▃▃▂▂▂▂▂▂▂▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:     e_F1 58.19315
wandb:   e_loss 0.9803
wandb:     t_F1 67.44586
wandb:   t_loss 0.81315
wandb: 
wandb: Synced 4 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Synced bright-river-2: https://wandb.ai/yinanazhou/xl_512_bs_8_lr_1e06_es_5_lc_True_nr_False_sr_False_stem_True_lemma_False_repeat_3_fold_1/runs/35ggcsf6
wandb: Find logs at: ./wandb/run-20220317_225637-35ggcsf6/logs/debug.log
wandb: 

wandb: wandb version 0.12.11 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
2022-03-18 00:19:36.273647: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1
wandb: Tracking run with wandb version 0.12.5
wandb: Syncing run crisp-glade-2
wandb: ⭐️ View project at https://wandb.ai/yinanazhou/xl_512_bs_8_lr_1e06_es_5_lc_True_nr_False_sr_False_stem_True_lemma_False_repeat_3_fold_2
wandb: 🚀 View run at https://wandb.ai/yinanazhou/xl_512_bs_8_lr_1e06_es_5_lc_True_nr_False_sr_False_stem_True_lemma_False_repeat_3_fold_2/runs/2nft29k5
wandb: Run data is saved locally in /project/6002780/yinan/Thesis_MER_Lyrics/lyric-emotion/wandb/run-20220318_001933-2nft29k5
wandb: Run `wandb offline` to turn off syncing.

Validation loss decreased (inf --> 1.478330).  Saving model ...
Validation loss decreased (1.478330 --> 1.451309).  Saving model ...
Validation loss decreased (1.451309 --> 1.431821).  Saving model ...
Validation loss decreased (1.431821 --> 1.418322).  Saving model ...
Validation loss decreased (1.418322 --> 1.407972).  Saving model ...
Validation loss decreased (1.407972 --> 1.399553).  Saving model ...
Validation loss decreased (1.399553 --> 1.392598).  Saving model ...
Validation loss decreased (1.392598 --> 1.386253).  Saving model ...
Validation loss decreased (1.386253 --> 1.381132).  Saving model ...
Validation loss decreased (1.381132 --> 1.376268).  Saving model ...
Validation loss decreased (1.376268 --> 1.371547).  Saving model ...
Validation loss decreased (1.371547 --> 1.367262).  Saving model ...
Validation loss decreased (1.367262 --> 1.362702).  Saving model ...
Validation loss decreased (1.362702 --> 1.358378).  Saving model ...
Validation loss decreased (1.358378 --> 1.353973).  Saving model ...
Validation loss decreased (1.353973 --> 1.349185).  Saving model ...
Validation loss decreased (1.349185 --> 1.344197).  Saving model ...
Validation loss decreased (1.344197 --> 1.339785).  Saving model ...
Validation loss decreased (1.339785 --> 1.334779).  Saving model ...
Validation loss decreased (1.334779 --> 1.329637).  Saving model ...
Validation loss decreased (1.329637 --> 1.324254).  Saving model ...
Validation loss decreased (1.324254 --> 1.319139).  Saving model ...
Validation loss decreased (1.319139 --> 1.313819).  Saving model ...
Validation loss decreased (1.313819 --> 1.308594).  Saving model ...
Validation loss decreased (1.308594 --> 1.302864).  Saving model ...
Validation loss decreased (1.302864 --> 1.296135).  Saving model ...
Validation loss decreased (1.296135 --> 1.289914).  Saving model ...
Validation loss decreased (1.289914 --> 1.284454).  Saving model ...
Validation loss decreased (1.284454 --> 1.277378).  Saving model ...
Validation loss decreased (1.277378 --> 1.270077).  Saving model ...
Validation loss decreased (1.270077 --> 1.263826).  Saving model ...
Validation loss decreased (1.263826 --> 1.257272).  Saving model ...
Validation loss decreased (1.257272 --> 1.251496).  Saving model ...
Validation loss decreased (1.251496 --> 1.244262).  Saving model ...
Validation loss decreased (1.244262 --> 1.236758).  Saving model ...
Validation loss decreased (1.236758 --> 1.230194).  Saving model ...
Validation loss decreased (1.230194 --> 1.222637).  Saving model ...
Validation loss decreased (1.222637 --> 1.215028).  Saving model ...
Validation loss decreased (1.215028 --> 1.208120).  Saving model ...
Validation loss decreased (1.208120 --> 1.201684).  Saving model ...
Validation loss decreased (1.201684 --> 1.195014).  Saving model ...
Validation loss decreased (1.195014 --> 1.188626).  Saving model ...
Validation loss decreased (1.188626 --> 1.181620).  Saving model ...
Validation loss decreased (1.181620 --> 1.176115).  Saving model ...
Validation loss decreased (1.176115 --> 1.169783).  Saving model ...
Validation loss decreased (1.169783 --> 1.165118).  Saving model ...
Validation loss decreased (1.165118 --> 1.159668).  Saving model ...
Validation loss decreased (1.159668 --> 1.154851).  Saving model ...
Validation loss decreased (1.154851 --> 1.149448).  Saving model ...
Validation loss decreased (1.149448 --> 1.144210).  Saving model ...
Validation loss decreased (1.144210 --> 1.139269).  Saving model ...
Validation loss decreased (1.139269 --> 1.135289).  Saving model ...
Validation loss decreased (1.135289 --> 1.129805).  Saving model ...
Validation loss decreased (1.129805 --> 1.124672).  Saving model ...
Validation loss decreased (1.124672 --> 1.117954).  Saving model ...
Validation loss decreased (1.117954 --> 1.112844).  Saving model ...
Validation loss decreased (1.112844 --> 1.108991).  Saving model ...
Validation loss decreased (1.108991 --> 1.104446).  Saving model ...
Validation loss decreased (1.104446 --> 1.098606).  Saving model ...
Validation loss decreased (1.098606 --> 1.095721).  Saving model ...
Validation loss decreased (1.095721 --> 1.090243).  Saving model ...
Validation loss decreased (1.090243 --> 1.087702).  Saving model ...
Validation loss decreased (1.087702 --> 1.083151).  Saving model ...
Validation loss decreased (1.083151 --> 1.079842).  Saving model ...
Validation loss decreased (1.079842 --> 1.075992).  Saving model ...
Validation loss decreased (1.075992 --> 1.072643).  Saving model ...
Validation loss decreased (1.072643 --> 1.070277).  Saving model ...
Validation loss decreased (1.070277 --> 1.065651).  Saving model ...
Validation loss decreased (1.065651 --> 1.062983).  Saving model ...
Validation loss decreased (1.062983 --> 1.060188).  Saving model ...
Validation loss decreased (1.060188 --> 1.057995).  Saving model ...
Validation loss decreased (1.057995 --> 1.054510).  Saving model ...
Validation loss decreased (1.054510 --> 1.054148).  Saving model ...
Validation loss decreased (1.054148 --> 1.050060).  Saving model ...
Validation loss decreased (1.050060 --> 1.048517).  Saving model ...
Validation loss decreased (1.048517 --> 1.044562).  Saving model ...
Validation loss decreased (1.044562 --> 1.043437).  Saving model ...
Validation loss decreased (1.043437 --> 1.040458).  Saving model ...
Validation loss decreased (1.040458 --> 1.034368).  Saving model ...
Validation loss decreased (1.034368 --> 1.031753).  Saving model ...
Validation loss decreased (1.031753 --> 1.030037).  Saving model ...
Validation loss decreased (1.030037 --> 1.027435).  Saving model ...
Validation loss decreased (1.027435 --> 1.024142).  Saving model ...
Validation loss decreased (1.024142 --> 1.020311).  Saving model ...
Validation loss decreased (1.020311 --> 1.019815).  Saving model ...
Validation loss decreased (1.019815 --> 1.018144).  Saving model ...
Validation loss decreased (1.018144 --> 1.014962).  Saving model ...
Validation loss decreased (1.014962 --> 1.014789).  Saving model ...
Validation loss decreased (1.014789 --> 1.010593).  Saving model ...
Validation loss decreased (1.010593 --> 1.008465).  Saving model ...
Validation loss decreased (1.008465 --> 1.007188).  Saving model ...
Validation loss decreased (1.007188 --> 1.004752).  Saving model ...
Validation loss decreased (1.004752 --> 1.004130).  Saving model ...
Validation loss decreased (1.004130 --> 1.001569).  Saving model ...
EarlyStopping counter: 1 out of 5.0
Validation loss decreased (1.001569 --> 0.998577).  Saving model ...
Validation loss decreased (0.998577 --> 0.995641).  Saving model ...
Validation loss decreased (0.995641 --> 0.994184).  Saving model ...
Validation loss decreased (0.994184 --> 0.992781).  Saving model ...
Validation loss decreased (0.992781 --> 0.992486).  Saving model ...
Validation loss decreased (0.992486 --> 0.992046).  Saving model ...
Validation loss decreased (0.992046 --> 0.988336).  Saving model ...
Validation loss decreased (0.988336 --> 0.987579).  Saving model ...
Validation loss decreased (0.987579 --> 0.986011).  Saving model ...
EarlyStopping counter: 1 out of 5.0
Validation loss decreased (0.986011 --> 0.985453).  Saving model ...
Validation loss decreased (0.985453 --> 0.984091).  Saving model ...
Validation loss decreased (0.984091 --> 0.980762).  Saving model ...
Validation loss decreased (0.980762 --> 0.978789).  Saving model ...
Validation loss decreased (0.978789 --> 0.976354).  Saving model ...
EarlyStopping counter: 1 out of 5.0
EarlyStopping counter: 2 out of 5.0
EarlyStopping counter: 3 out of 5.0
EarlyStopping counter: 4 out of 5.0
EarlyStopping counter: 5 out of 5.0
/localscratch/yinan.29152320.0/env/lib/python3.7/site-packages/torch/nn/functional.py:1794: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.
  warnings.warn("nn.functional.tanh is deprecated. Use torch.tanh instead.")
wandb: Waiting for W&B process to finish, PID 95919... (success).
wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: \ 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: | 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: / 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: \ 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: | 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: / 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: \ 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: | 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: / 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb:                                                                                
wandb: Run history:
wandb:     e_F1 ▁▁▁▂▃▄▅▆▆▆▆▆▇▇▇▇▇▇▇▇████████████████████
wandb:   e_loss █▇▇▇▆▆▆▆▆▅▅▅▅▄▄▄▄▃▃▃▃▃▂▂▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁
wandb:     t_F1 ▁▁▂▃▃▃▄▄▅▅▅▅▆▅▆▆▆▆▆▆▇▆▇▆▇▇▇▇▇▇██▇█████▇█
wandb:   t_loss █▇▇▇▆▇▆▆▆▆▆▅▅▅▅▅▅▄▄▄▃▃▃▃▃▃▂▃▂▂▂▂▂▂▂▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:     e_F1 57.88197
wandb:   e_loss 0.98058
wandb:     t_F1 69.48767
wandb:   t_loss 0.82703
wandb: 
wandb: Synced 4 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Synced crisp-glade-2: https://wandb.ai/yinanazhou/xl_512_bs_8_lr_1e06_es_5_lc_True_nr_False_sr_False_stem_True_lemma_False_repeat_3_fold_2/runs/2nft29k5
wandb: Find logs at: ./wandb/run-20220318_001933-2nft29k5/logs/debug.log
wandb: 

wandb: wandb version 0.12.11 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
2022-03-18 01:33:06.749086: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1
wandb: Tracking run with wandb version 0.12.5
wandb: Syncing run glamorous-dust-2
wandb: ⭐️ View project at https://wandb.ai/yinanazhou/xl_512_bs_8_lr_1e06_es_5_lc_True_nr_False_sr_False_stem_True_lemma_False_repeat_4_fold_1
wandb: 🚀 View run at https://wandb.ai/yinanazhou/xl_512_bs_8_lr_1e06_es_5_lc_True_nr_False_sr_False_stem_True_lemma_False_repeat_4_fold_1/runs/29k2wtsd
wandb: Run data is saved locally in /project/6002780/yinan/Thesis_MER_Lyrics/lyric-emotion/wandb/run-20220318_013303-29k2wtsd
wandb: Run `wandb offline` to turn off syncing.
wandb: Network error (ReadTimeout), entering retry loop.

Validation loss decreased (inf --> 1.495275).  Saving model ...
Validation loss decreased (1.495275 --> 1.462428).  Saving model ...
Validation loss decreased (1.462428 --> 1.436339).  Saving model ...
Validation loss decreased (1.436339 --> 1.415620).  Saving model ...
Validation loss decreased (1.415620 --> 1.399448).  Saving model ...
Validation loss decreased (1.399448 --> 1.387851).  Saving model ...
Validation loss decreased (1.387851 --> 1.379593).  Saving model ...
Validation loss decreased (1.379593 --> 1.372638).  Saving model ...
Validation loss decreased (1.372638 --> 1.367127).  Saving model ...
Validation loss decreased (1.367127 --> 1.362797).  Saving model ...
Validation loss decreased (1.362797 --> 1.358759).  Saving model ...
Validation loss decreased (1.358759 --> 1.354755).  Saving model ...
Validation loss decreased (1.354755 --> 1.350569).  Saving model ...
Validation loss decreased (1.350569 --> 1.346467).  Saving model ...
Validation loss decreased (1.346467 --> 1.342539).  Saving model ...
Validation loss decreased (1.342539 --> 1.338511).  Saving model ...
Validation loss decreased (1.338511 --> 1.334100).  Saving model ...
Validation loss decreased (1.334100 --> 1.329676).  Saving model ...
Validation loss decreased (1.329676 --> 1.324854).  Saving model ...
Validation loss decreased (1.324854 --> 1.320448).  Saving model ...
Validation loss decreased (1.320448 --> 1.316015).  Saving model ...
Validation loss decreased (1.316015 --> 1.312011).  Saving model ...
Validation loss decreased (1.312011 --> 1.306668).  Saving model ...
Validation loss decreased (1.306668 --> 1.301772).  Saving model ...
Validation loss decreased (1.301772 --> 1.296896).  Saving model ...
Validation loss decreased (1.296896 --> 1.291976).  Saving model ...
Validation loss decreased (1.291976 --> 1.287130).  Saving model ...
Validation loss decreased (1.287130 --> 1.281920).  Saving model ...
Validation loss decreased (1.281920 --> 1.276693).  Saving model ...
Validation loss decreased (1.276693 --> 1.270972).  Saving model ...
Validation loss decreased (1.270972 --> 1.266131).  Saving model ...
Validation loss decreased (1.266131 --> 1.262219).  Saving model ...
Validation loss decreased (1.262219 --> 1.257498).  Saving model ...
Validation loss decreased (1.257498 --> 1.252068).  Saving model ...
Validation loss decreased (1.252068 --> 1.246892).  Saving model ...
Validation loss decreased (1.246892 --> 1.241621).  Saving model ...
Validation loss decreased (1.241621 --> 1.236213).  Saving model ...
Validation loss decreased (1.236213 --> 1.230473).  Saving model ...
Validation loss decreased (1.230473 --> 1.225405).  Saving model ...
Validation loss decreased (1.225405 --> 1.221455).  Saving model ...
Validation loss decreased (1.221455 --> 1.215932).  Saving model ...
Validation loss decreased (1.215932 --> 1.210633).  Saving model ...
Validation loss decreased (1.210633 --> 1.205528).  Saving model ...
Validation loss decreased (1.205528 --> 1.201170).  Saving model ...
Validation loss decreased (1.201170 --> 1.195630).  Saving model ...
Validation loss decreased (1.195630 --> 1.190954).  Saving model ...
Validation loss decreased (1.190954 --> 1.185842).  Saving model ...
Validation loss decreased (1.185842 --> 1.180733).  Saving model ...
Validation loss decreased (1.180733 --> 1.176441).  Saving model ...
Validation loss decreased (1.176441 --> 1.172251).  Saving model ...
Validation loss decreased (1.172251 --> 1.167485).  Saving model ...
Validation loss decreased (1.167485 --> 1.162161).  Saving model ...
Validation loss decreased (1.162161 --> 1.156960).  Saving model ...
Validation loss decreased (1.156960 --> 1.153357).  Saving model ...
Validation loss decreased (1.153357 --> 1.149243).  Saving model ...
Validation loss decreased (1.149243 --> 1.144964).  Saving model ...
Validation loss decreased (1.144964 --> 1.140896).  Saving model ...
Validation loss decreased (1.140896 --> 1.137031).  Saving model ...
Validation loss decreased (1.137031 --> 1.132942).  Saving model ...
Validation loss decreased (1.132942 --> 1.128815).  Saving model ...
Validation loss decreased (1.128815 --> 1.125860).  Saving model ...
Validation loss decreased (1.125860 --> 1.121766).  Saving model ...
Validation loss decreased (1.121766 --> 1.117056).  Saving model ...
Validation loss decreased (1.117056 --> 1.114565).  Saving model ...
Validation loss decreased (1.114565 --> 1.111177).  Saving model ...
Validation loss decreased (1.111177 --> 1.108167).  Saving model ...
Validation loss decreased (1.108167 --> 1.104935).  Saving model ...
Validation loss decreased (1.104935 --> 1.101668).  Saving model ...
Validation loss decreased (1.101668 --> 1.098217).  Saving model ...
Validation loss decreased (1.098217 --> 1.094395).  Saving model ...
Validation loss decreased (1.094395 --> 1.090871).  Saving model ...
Validation loss decreased (1.090871 --> 1.087380).  Saving model ...
Validation loss decreased (1.087380 --> 1.083955).  Saving model ...
Validation loss decreased (1.083955 --> 1.079949).  Saving model ...
Validation loss decreased (1.079949 --> 1.076165).  Saving model ...
Validation loss decreased (1.076165 --> 1.073827).  Saving model ...
Validation loss decreased (1.073827 --> 1.071200).  Saving model ...
Validation loss decreased (1.071200 --> 1.068836).  Saving model ...
Validation loss decreased (1.068836 --> 1.066646).  Saving model ...
Validation loss decreased (1.066646 --> 1.063580).  Saving model ...
Validation loss decreased (1.063580 --> 1.061186).  Saving model ...
Validation loss decreased (1.061186 --> 1.059011).  Saving model ...
Validation loss decreased (1.059011 --> 1.056470).  Saving model ...
Validation loss decreased (1.056470 --> 1.054340).  Saving model ...
Validation loss decreased (1.054340 --> 1.051896).  Saving model ...
Validation loss decreased (1.051896 --> 1.050094).  Saving model ...
Validation loss decreased (1.050094 --> 1.047632).  Saving model ...
Validation loss decreased (1.047632 --> 1.045275).  Saving model ...
Validation loss decreased (1.045275 --> 1.044526).  Saving model ...
Validation loss decreased (1.044526 --> 1.042973).  Saving model ...
Validation loss decreased (1.042973 --> 1.040155).  Saving model ...
Validation loss decreased (1.040155 --> 1.039123).  Saving model ...
Validation loss decreased (1.039123 --> 1.037407).  Saving model ...
Validation loss decreased (1.037407 --> 1.035082).  Saving model ...
Validation loss decreased (1.035082 --> 1.032068).  Saving model ...
Validation loss decreased (1.032068 --> 1.029405).  Saving model ...
Validation loss decreased (1.029405 --> 1.026634).  Saving model ...
Validation loss decreased (1.026634 --> 1.025238).  Saving model ...
Validation loss decreased (1.025238 --> 1.023260).  Saving model ...
Validation loss decreased (1.023260 --> 1.021188).  Saving model ...
Validation loss decreased (1.021188 --> 1.019323).  Saving model ...
Validation loss decreased (1.019323 --> 1.018619).  Saving model ...
Validation loss decreased (1.018619 --> 1.016889).  Saving model ...
Validation loss decreased (1.016889 --> 1.016074).  Saving model ...
Validation loss decreased (1.016074 --> 1.014131).  Saving model ...
Validation loss decreased (1.014131 --> 1.012714).  Saving model ...
Validation loss decreased (1.012714 --> 1.011798).  Saving model ...
Validation loss decreased (1.011798 --> 1.010992).  Saving model ...
Validation loss decreased (1.010992 --> 1.009620).  Saving model ...
Validation loss decreased (1.009620 --> 1.008333).  Saving model ...
EarlyStopping counter: 1 out of 5.0
Validation loss decreased (1.008333 --> 1.007627).  Saving model ...
Validation loss decreased (1.007627 --> 1.006876).  Saving model ...
Validation loss decreased (1.006876 --> 1.003928).  Saving model ...
Validation loss decreased (1.003928 --> 1.002030).  Saving model ...
Validation loss decreased (1.002030 --> 1.000814).  Saving model ...
Validation loss decreased (1.000814 --> 0.999413).  Saving model ...
Validation loss decreased (0.999413 --> 0.997459).  Saving model ...
Validation loss decreased (0.997459 --> 0.996298).  Saving model ...
EarlyStopping counter: 1 out of 5.0
EarlyStopping counter: 2 out of 5.0
EarlyStopping counter: 3 out of 5.0
Validation loss decreased (0.996298 --> 0.995097).  Saving model ...
Validation loss decreased (0.995097 --> 0.995089).  Saving model ...
Validation loss decreased (0.995089 --> 0.994365).  Saving model ...
Validation loss decreased (0.994365 --> 0.993572).  Saving model ...
Validation loss decreased (0.993572 --> 0.991223).  Saving model ...
EarlyStopping counter: 1 out of 5.0
Validation loss decreased (0.991223 --> 0.990573).  Saving model ...
Validation loss decreased (0.990573 --> 0.989195).  Saving model ...
Validation loss decreased (0.989195 --> 0.987549).  Saving model ...
EarlyStopping counter: 1 out of 5.0
Validation loss decreased (0.987549 --> 0.986558).  Saving model ...
Validation loss decreased (0.986558 --> 0.986076).  Saving model ...
Validation loss decreased (0.986076 --> 0.985405).  Saving model ...
EarlyStopping counter: 1 out of 5.0
Validation loss decreased (0.985405 --> 0.984112).  Saving model ...
Validation loss decreased (0.984112 --> 0.983728).  Saving model ...
EarlyStopping counter: 1 out of 5.0
EarlyStopping counter: 2 out of 5.0
Validation loss decreased (0.983728 --> 0.981503).  Saving model ...
EarlyStopping counter: 1 out of 5.0
EarlyStopping counter: 2 out of 5.0
EarlyStopping counter: 3 out of 5.0
EarlyStopping counter: 4 out of 5.0
EarlyStopping counter: 5 out of 5.0
/localscratch/yinan.29152320.0/env/lib/python3.7/site-packages/torch/nn/functional.py:1794: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.
  warnings.warn("nn.functional.tanh is deprecated. Use torch.tanh instead.")
wandb: Waiting for W&B process to finish, PID 99882... (success).
wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: \ 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: | 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: / 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: \ 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: | 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: / 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: \ 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: | 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: / 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb:                                                                                
wandb: Run history:
wandb:     e_F1 ▁▂▃▄▄▅▅▅▆▆▆▆▆▆▆▆▇▇▇▇▇▇▇▇▇▇██████████████
wandb:   e_loss █▇▇▆▆▆▆▆▅▅▅▄▄▄▄▃▃▃▃▃▂▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁
wandb:     t_F1 ▁▂▂▃▃▃▄▄▄▄▅▅▅▅▆▆▆▆▆▆▆▆▇▇▆▆▇▇▇▇▇▇▇▇▇█▇▇██
wandb:   t_loss ██▇▇▇▇▆▆▆▆▅▅▅▅▄▄▄▄▄▄▄▃▃▃▃▃▃▂▂▂▂▂▂▂▂▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:     e_F1 56.91217
wandb:   e_loss 0.98288
wandb:     t_F1 71.23899
wandb:   t_loss 0.79166
wandb: 
wandb: Synced 4 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Synced glamorous-dust-2: https://wandb.ai/yinanazhou/xl_512_bs_8_lr_1e06_es_5_lc_True_nr_False_sr_False_stem_True_lemma_False_repeat_4_fold_1/runs/29k2wtsd
wandb: Find logs at: ./wandb/run-20220318_013303-29k2wtsd/logs/debug.log
wandb: 

wandb: wandb version 0.12.11 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
2022-03-18 03:09:52.045083: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1
wandb: Tracking run with wandb version 0.12.5
wandb: Syncing run confused-planet-2
wandb: ⭐️ View project at https://wandb.ai/yinanazhou/xl_512_bs_8_lr_1e06_es_5_lc_True_nr_False_sr_False_stem_True_lemma_False_repeat_4_fold_2
wandb: 🚀 View run at https://wandb.ai/yinanazhou/xl_512_bs_8_lr_1e06_es_5_lc_True_nr_False_sr_False_stem_True_lemma_False_repeat_4_fold_2/runs/1q2qkwe3
wandb: Run data is saved locally in /project/6002780/yinan/Thesis_MER_Lyrics/lyric-emotion/wandb/run-20220318_030948-1q2qkwe3
wandb: Run `wandb offline` to turn off syncing.

Validation loss decreased (inf --> 1.403550).  Saving model ...
Validation loss decreased (1.403550 --> 1.395671).  Saving model ...
Validation loss decreased (1.395671 --> 1.389815).  Saving model ...
Validation loss decreased (1.389815 --> 1.384119).  Saving model ...
Validation loss decreased (1.384119 --> 1.378806).  Saving model ...
Validation loss decreased (1.378806 --> 1.373985).  Saving model ...
Validation loss decreased (1.373985 --> 1.370012).  Saving model ...
Validation loss decreased (1.370012 --> 1.366333).  Saving model ...
Validation loss decreased (1.366333 --> 1.362282).  Saving model ...
Validation loss decreased (1.362282 --> 1.358162).  Saving model ...
Validation loss decreased (1.358162 --> 1.354330).  Saving model ...
Validation loss decreased (1.354330 --> 1.350765).  Saving model ...
Validation loss decreased (1.350765 --> 1.347111).  Saving model ...
Validation loss decreased (1.347111 --> 1.343082).  Saving model ...
Validation loss decreased (1.343082 --> 1.339095).  Saving model ...
Validation loss decreased (1.339095 --> 1.335053).  Saving model ...
Validation loss decreased (1.335053 --> 1.330838).  Saving model ...
Validation loss decreased (1.330838 --> 1.326638).  Saving model ...
Validation loss decreased (1.326638 --> 1.322809).  Saving model ...
Validation loss decreased (1.322809 --> 1.318474).  Saving model ...
Validation loss decreased (1.318474 --> 1.313793).  Saving model ...
Validation loss decreased (1.313793 --> 1.308767).  Saving model ...
Validation loss decreased (1.308767 --> 1.303464).  Saving model ...
Validation loss decreased (1.303464 --> 1.297841).  Saving model ...
Validation loss decreased (1.297841 --> 1.292209).  Saving model ...
Validation loss decreased (1.292209 --> 1.286070).  Saving model ...
Validation loss decreased (1.286070 --> 1.279760).  Saving model ...
Validation loss decreased (1.279760 --> 1.272203).  Saving model ...
Validation loss decreased (1.272203 --> 1.265152).  Saving model ...
Validation loss decreased (1.265152 --> 1.257429).  Saving model ...
Validation loss decreased (1.257429 --> 1.249944).  Saving model ...
Validation loss decreased (1.249944 --> 1.242005).  Saving model ...
Validation loss decreased (1.242005 --> 1.234274).  Saving model ...
Validation loss decreased (1.234274 --> 1.227154).  Saving model ...
Validation loss decreased (1.227154 --> 1.218350).  Saving model ...
Validation loss decreased (1.218350 --> 1.210938).  Saving model ...
Validation loss decreased (1.210938 --> 1.201369).  Saving model ...
Validation loss decreased (1.201369 --> 1.194005).  Saving model ...
Validation loss decreased (1.194005 --> 1.188399).  Saving model ...
Validation loss decreased (1.188399 --> 1.180477).  Saving model ...
Validation loss decreased (1.180477 --> 1.173281).  Saving model ...
Validation loss decreased (1.173281 --> 1.167216).  Saving model ...
Validation loss decreased (1.167216 --> 1.161244).  Saving model ...
Validation loss decreased (1.161244 --> 1.153892).  Saving model ...
Validation loss decreased (1.153892 --> 1.147979).  Saving model ...
Validation loss decreased (1.147979 --> 1.143239).  Saving model ...
Validation loss decreased (1.143239 --> 1.137135).  Saving model ...
Validation loss decreased (1.137135 --> 1.132655).  Saving model ...
Validation loss decreased (1.132655 --> 1.127170).  Saving model ...
Validation loss decreased (1.127170 --> 1.120961).  Saving model ...
Validation loss decreased (1.120961 --> 1.113994).  Saving model ...
Validation loss decreased (1.113994 --> 1.111707).  Saving model ...
Validation loss decreased (1.111707 --> 1.107180).  Saving model ...
Validation loss decreased (1.107180 --> 1.103869).  Saving model ...
Validation loss decreased (1.103869 --> 1.098676).  Saving model ...
Validation loss decreased (1.098676 --> 1.096227).  Saving model ...
Validation loss decreased (1.096227 --> 1.090554).  Saving model ...
Validation loss decreased (1.090554 --> 1.085516).  Saving model ...
Validation loss decreased (1.085516 --> 1.080075).  Saving model ...
Validation loss decreased (1.080075 --> 1.077918).  Saving model ...
Validation loss decreased (1.077918 --> 1.073544).  Saving model ...
Validation loss decreased (1.073544 --> 1.069366).  Saving model ...
Validation loss decreased (1.069366 --> 1.062825).  Saving model ...
Validation loss decreased (1.062825 --> 1.058252).  Saving model ...
Validation loss decreased (1.058252 --> 1.056342).  Saving model ...
Validation loss decreased (1.056342 --> 1.050931).  Saving model ...
Validation loss decreased (1.050931 --> 1.048576).  Saving model ...
Validation loss decreased (1.048576 --> 1.044347).  Saving model ...
Validation loss decreased (1.044347 --> 1.042845).  Saving model ...
Validation loss decreased (1.042845 --> 1.039825).  Saving model ...
Validation loss decreased (1.039825 --> 1.038422).  Saving model ...
Validation loss decreased (1.038422 --> 1.030692).  Saving model ...
Validation loss decreased (1.030692 --> 1.029597).  Saving model ...
Validation loss decreased (1.029597 --> 1.026739).  Saving model ...
Validation loss decreased (1.026739 --> 1.023687).  Saving model ...
Validation loss decreased (1.023687 --> 1.021158).  Saving model ...
Validation loss decreased (1.021158 --> 1.018443).  Saving model ...
Validation loss decreased (1.018443 --> 1.015737).  Saving model ...
Validation loss decreased (1.015737 --> 1.010174).  Saving model ...
Validation loss decreased (1.010174 --> 1.008687).  Saving model ...
Validation loss decreased (1.008687 --> 1.005143).  Saving model ...
Validation loss decreased (1.005143 --> 1.001859).  Saving model ...
Validation loss decreased (1.001859 --> 0.999834).  Saving model ...
Validation loss decreased (0.999834 --> 0.997132).  Saving model ...
Validation loss decreased (0.997132 --> 0.993422).  Saving model ...
Validation loss decreased (0.993422 --> 0.990692).  Saving model ...
Validation loss decreased (0.990692 --> 0.988014).  Saving model ...
Validation loss decreased (0.988014 --> 0.987301).  Saving model ...
Validation loss decreased (0.987301 --> 0.985497).  Saving model ...
Validation loss decreased (0.985497 --> 0.983182).  Saving model ...
EarlyStopping counter: 1 out of 5.0
EarlyStopping counter: 2 out of 5.0
Validation loss decreased (0.983182 --> 0.979003).  Saving model ...
Validation loss decreased (0.979003 --> 0.976413).  Saving model ...
Validation loss decreased (0.976413 --> 0.975590).  Saving model ...
Validation loss decreased (0.975590 --> 0.974110).  Saving model ...
EarlyStopping counter: 1 out of 5.0
Validation loss decreased (0.974110 --> 0.973138).  Saving model ...
Validation loss decreased (0.973138 --> 0.971976).  Saving model ...
Validation loss decreased (0.971976 --> 0.968140).  Saving model ...
EarlyStopping counter: 1 out of 5.0
Validation loss decreased (0.968140 --> 0.967839).  Saving model ...
Validation loss decreased (0.967839 --> 0.966928).  Saving model ...
Validation loss decreased (0.966928 --> 0.965577).  Saving model ...
Validation loss decreased (0.965577 --> 0.963225).  Saving model ...
EarlyStopping counter: 1 out of 5.0
Validation loss decreased (0.963225 --> 0.961996).  Saving model ...
Validation loss decreased (0.961996 --> 0.961470).  Saving model ...
Validation loss decreased (0.961470 --> 0.960565).  Saving model ...
Validation loss decreased (0.960565 --> 0.960255).  Saving model ...
Validation loss decreased (0.960255 --> 0.958363).  Saving model ...
Validation loss decreased (0.958363 --> 0.957903).  Saving model ...
Validation loss decreased (0.957903 --> 0.955451).  Saving model ...
EarlyStopping counter: 1 out of 5.0
Validation loss decreased (0.955451 --> 0.953336).  Saving model ...
Validation loss decreased (0.953336 --> 0.952519).  Saving model ...
Validation loss decreased (0.952519 --> 0.952206).  Saving model ...
EarlyStopping counter: 1 out of 5.0
EarlyStopping counter: 2 out of 5.0
Validation loss decreased (0.952206 --> 0.951899).  Saving model ...
Validation loss decreased (0.951899 --> 0.950323).  Saving model ...
Validation loss decreased (0.950323 --> 0.949951).  Saving model ...
EarlyStopping counter: 1 out of 5.0
EarlyStopping counter: 2 out of 5.0
EarlyStopping counter: 3 out of 5.0
EarlyStopping counter: 4 out of 5.0
EarlyStopping counter: 5 out of 5.0
/localscratch/yinan.29152320.0/env/lib/python3.7/site-packages/torch/nn/functional.py:1794: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.
  warnings.warn("nn.functional.tanh is deprecated. Use torch.tanh instead.")
wandb: Waiting for W&B process to finish, PID 105028... (success).
wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: \ 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: | 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: / 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: \ 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: | 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: / 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: \ 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: | 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: / 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb:                                                                                
wandb: Run history:
wandb:     e_F1 ▁▂▃▄▄▅▅▅▅▆▆▆▇▇▇▇▇▇▇▇▇▇█▇▇███████████████
wandb:   e_loss ██▇▇▇▇▇▆▆▆▅▅▅▄▄▄▃▃▃▃▃▂▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁
wandb:     t_F1 ▁▁▁▂▂▂▃▃▄▃▄▅▅▅▅▅▅▆▇▆▆▆▆▇▇▇▇▇▇▇▇███▇█████
wandb:   t_loss █████▇▇▇▇▇▆▆▆▅▅▅▅▅▄▄▄▄▄▃▃▃▃▂▃▂▂▂▂▁▂▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:     e_F1 60.81106
wandb:   e_loss 0.95164
wandb:     t_F1 68.00451
wandb:   t_loss 0.80913
wandb: 
wandb: Synced 4 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Synced confused-planet-2: https://wandb.ai/yinanazhou/xl_512_bs_8_lr_1e06_es_5_lc_True_nr_False_sr_False_stem_True_lemma_False_repeat_4_fold_2/runs/1q2qkwe3
wandb: Find logs at: ./wandb/run-20220318_030948-1q2qkwe3/logs/debug.log
wandb: 

wandb: wandb version 0.12.11 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
2022-03-18 04:34:06.487973: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1
wandb: Tracking run with wandb version 0.12.5
wandb: Syncing run vivid-rain-2
wandb: ⭐️ View project at https://wandb.ai/yinanazhou/xl_512_bs_8_lr_1e06_es_5_lc_True_nr_False_sr_False_stem_True_lemma_False_repeat_5_fold_1
wandb: 🚀 View run at https://wandb.ai/yinanazhou/xl_512_bs_8_lr_1e06_es_5_lc_True_nr_False_sr_False_stem_True_lemma_False_repeat_5_fold_1/runs/28bwghwr
wandb: Run data is saved locally in /project/6002780/yinan/Thesis_MER_Lyrics/lyric-emotion/wandb/run-20220318_043403-28bwghwr
wandb: Run `wandb offline` to turn off syncing.

Validation loss decreased (inf --> 1.460848).  Saving model ...
Validation loss decreased (1.460848 --> 1.427633).  Saving model ...
Validation loss decreased (1.427633 --> 1.402790).  Saving model ...
Validation loss decreased (1.402790 --> 1.385266).  Saving model ...
Validation loss decreased (1.385266 --> 1.372144).  Saving model ...
Validation loss decreased (1.372144 --> 1.363348).  Saving model ...
Validation loss decreased (1.363348 --> 1.355979).  Saving model ...
Validation loss decreased (1.355979 --> 1.349744).  Saving model ...
Validation loss decreased (1.349744 --> 1.344790).  Saving model ...
Validation loss decreased (1.344790 --> 1.339671).  Saving model ...
Validation loss decreased (1.339671 --> 1.334469).  Saving model ...
Validation loss decreased (1.334469 --> 1.329540).  Saving model ...
Validation loss decreased (1.329540 --> 1.324092).  Saving model ...
Validation loss decreased (1.324092 --> 1.319508).  Saving model ...
Validation loss decreased (1.319508 --> 1.313638).  Saving model ...
Validation loss decreased (1.313638 --> 1.308587).  Saving model ...
Validation loss decreased (1.308587 --> 1.302833).  Saving model ...
Validation loss decreased (1.302833 --> 1.297037).  Saving model ...
Validation loss decreased (1.297037 --> 1.291621).  Saving model ...
Validation loss decreased (1.291621 --> 1.286238).  Saving model ...
Validation loss decreased (1.286238 --> 1.280401).  Saving model ...
Validation loss decreased (1.280401 --> 1.274657).  Saving model ...
Validation loss decreased (1.274657 --> 1.268838).  Saving model ...
Validation loss decreased (1.268838 --> 1.262521).  Saving model ...
Validation loss decreased (1.262521 --> 1.256227).  Saving model ...
Validation loss decreased (1.256227 --> 1.249148).  Saving model ...
Validation loss decreased (1.249148 --> 1.243094).  Saving model ...
Validation loss decreased (1.243094 --> 1.236049).  Saving model ...
Validation loss decreased (1.236049 --> 1.228969).  Saving model ...
Validation loss decreased (1.228969 --> 1.222729).  Saving model ...
Validation loss decreased (1.222729 --> 1.215949).  Saving model ...
Validation loss decreased (1.215949 --> 1.209055).  Saving model ...
Validation loss decreased (1.209055 --> 1.202280).  Saving model ...
Validation loss decreased (1.202280 --> 1.196109).  Saving model ...
Validation loss decreased (1.196109 --> 1.189919).  Saving model ...
Validation loss decreased (1.189919 --> 1.183132).  Saving model ...
Validation loss decreased (1.183132 --> 1.176816).  Saving model ...
Validation loss decreased (1.176816 --> 1.171027).  Saving model ...
Validation loss decreased (1.171027 --> 1.165386).  Saving model ...
Validation loss decreased (1.165386 --> 1.159406).  Saving model ...
Validation loss decreased (1.159406 --> 1.153746).  Saving model ...
Validation loss decreased (1.153746 --> 1.147819).  Saving model ...
Validation loss decreased (1.147819 --> 1.142432).  Saving model ...
Validation loss decreased (1.142432 --> 1.137507).  Saving model ...
Validation loss decreased (1.137507 --> 1.132311).  Saving model ...
Validation loss decreased (1.132311 --> 1.127765).  Saving model ...
Validation loss decreased (1.127765 --> 1.122307).  Saving model ...
Validation loss decreased (1.122307 --> 1.116630).  Saving model ...
Validation loss decreased (1.116630 --> 1.111483).  Saving model ...
Validation loss decreased (1.111483 --> 1.106816).  Saving model ...
Validation loss decreased (1.106816 --> 1.102385).  Saving model ...
Validation loss decreased (1.102385 --> 1.097478).  Saving model ...
Validation loss decreased (1.097478 --> 1.092964).  Saving model ...
Validation loss decreased (1.092964 --> 1.088334).  Saving model ...
Validation loss decreased (1.088334 --> 1.083727).  Saving model ...
Validation loss decreased (1.083727 --> 1.080858).  Saving model ...
Validation loss decreased (1.080858 --> 1.077398).  Saving model ...
Validation loss decreased (1.077398 --> 1.072149).  Saving model ...
Validation loss decreased (1.072149 --> 1.068353).  Saving model ...
Validation loss decreased (1.068353 --> 1.064348).  Saving model ...
Validation loss decreased (1.064348 --> 1.060858).  Saving model ...
Validation loss decreased (1.060858 --> 1.057196).  Saving model ...
Validation loss decreased (1.057196 --> 1.053343).  Saving model ...
Validation loss decreased (1.053343 --> 1.049437).  Saving model ...
Validation loss decreased (1.049437 --> 1.047140).  Saving model ...
Validation loss decreased (1.047140 --> 1.044417).  Saving model ...
Validation loss decreased (1.044417 --> 1.041036).  Saving model ...
Validation loss decreased (1.041036 --> 1.037790).  Saving model ...
Validation loss decreased (1.037790 --> 1.035790).  Saving model ...
Validation loss decreased (1.035790 --> 1.031737).  Saving model ...
Validation loss decreased (1.031737 --> 1.027395).  Saving model ...
Validation loss decreased (1.027395 --> 1.024746).  Saving model ...
Validation loss decreased (1.024746 --> 1.020978).  Saving model ...
Validation loss decreased (1.020978 --> 1.016351).  Saving model ...
Validation loss decreased (1.016351 --> 1.014371).  Saving model ...
Validation loss decreased (1.014371 --> 1.011994).  Saving model ...
Validation loss decreased (1.011994 --> 1.009212).  Saving model ...
Validation loss decreased (1.009212 --> 1.005191).  Saving model ...
Validation loss decreased (1.005191 --> 1.002238).  Saving model ...
Validation loss decreased (1.002238 --> 0.999734).  Saving model ...
Validation loss decreased (0.999734 --> 0.997178).  Saving model ...
Validation loss decreased (0.997178 --> 0.995340).  Saving model ...
Validation loss decreased (0.995340 --> 0.992965).  Saving model ...
Validation loss decreased (0.992965 --> 0.991606).  Saving model ...
Validation loss decreased (0.991606 --> 0.988762).  Saving model ...
Validation loss decreased (0.988762 --> 0.986374).  Saving model ...
Validation loss decreased (0.986374 --> 0.983223).  Saving model ...
Validation loss decreased (0.983223 --> 0.982591).  Saving model ...
Validation loss decreased (0.982591 --> 0.981512).  Saving model ...
Validation loss decreased (0.981512 --> 0.980722).  Saving model ...
Validation loss decreased (0.980722 --> 0.979273).  Saving model ...
Validation loss decreased (0.979273 --> 0.974433).  Saving model ...
Validation loss decreased (0.974433 --> 0.973246).  Saving model ...
Validation loss decreased (0.973246 --> 0.971916).  Saving model ...
Validation loss decreased (0.971916 --> 0.970064).  Saving model ...
Validation loss decreased (0.970064 --> 0.968200).  Saving model ...
Validation loss decreased (0.968200 --> 0.966791).  Saving model ...
Validation loss decreased (0.966791 --> 0.963455).  Saving model ...
Validation loss decreased (0.963455 --> 0.961293).  Saving model ...
EarlyStopping counter: 1 out of 5.0
Validation loss decreased (0.961293 --> 0.960452).  Saving model ...
Validation loss decreased (0.960452 --> 0.959795).  Saving model ...
Validation loss decreased (0.959795 --> 0.958282).  Saving model ...
Validation loss decreased (0.958282 --> 0.955303).  Saving model ...
Validation loss decreased (0.955303 --> 0.954460).  Saving model ...
Validation loss decreased (0.954460 --> 0.953587).  Saving model ...
EarlyStopping counter: 1 out of 5.0
EarlyStopping counter: 2 out of 5.0
EarlyStopping counter: 3 out of 5.0
EarlyStopping counter: 4 out of 5.0
Validation loss decreased (0.953587 --> 0.952879).  Saving model ...
Validation loss decreased (0.952879 --> 0.951223).  Saving model ...
Validation loss decreased (0.951223 --> 0.949312).  Saving model ...
Validation loss decreased (0.949312 --> 0.949155).  Saving model ...
EarlyStopping counter: 1 out of 5.0
EarlyStopping counter: 2 out of 5.0
EarlyStopping counter: 3 out of 5.0
Validation loss decreased (0.949155 --> 0.948644).  Saving model ...
Validation loss decreased (0.948644 --> 0.947087).  Saving model ...
EarlyStopping counter: 1 out of 5.0
Validation loss decreased (0.947087 --> 0.946090).  Saving model ...
Validation loss decreased (0.946090 --> 0.945346).  Saving model ...
Validation loss decreased (0.945346 --> 0.943595).  Saving model ...
EarlyStopping counter: 1 out of 5.0
EarlyStopping counter: 2 out of 5.0
EarlyStopping counter: 3 out of 5.0
EarlyStopping counter: 4 out of 5.0
EarlyStopping counter: 5 out of 5.0
/localscratch/yinan.29152320.0/env/lib/python3.7/site-packages/torch/nn/functional.py:1794: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.
  warnings.warn("nn.functional.tanh is deprecated. Use torch.tanh instead.")
wandb: Waiting for W&B process to finish, PID 109533... (success).
wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: \ 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: | 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: / 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: \ 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: | 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: / 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: \ 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: | 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: / 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb:                                                                                
wandb: Run history:
wandb:     e_F1 ▁▁▄▅▅▅▅▆▆▆▆▆▆▇▇▇▇▇▇▇▇▇▇█████████████████
wandb:   e_loss █▇▇▇▆▆▆▆▅▅▅▄▄▄▄▃▃▃▃▃▂▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁
wandb:     t_F1 ▁▁▃▃▃▃▄▄▅▅▅▅▅▅▅▅▆▆▆▆▆▆▇▆▆▇▇▇▇▇▇▇▇▇███▇██
wandb:   t_loss ██▇▇▇▇▇▆▆▆▆▆▅▅▅▅▅▅▄▄▄▄▄▃▃▃▃▃▃▂▃▂▂▂▂▂▂▂▁▁
wandb: 
wandb: Run summary:
wandb:     e_F1 59.8674
wandb:   e_loss 0.94425
wandb:     t_F1 72.9934
wandb:   t_loss 0.73416
wandb: 
wandb: Synced 4 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Synced vivid-rain-2: https://wandb.ai/yinanazhou/xl_512_bs_8_lr_1e06_es_5_lc_True_nr_False_sr_False_stem_True_lemma_False_repeat_5_fold_1/runs/28bwghwr
wandb: Find logs at: ./wandb/run-20220318_043403-28bwghwr/logs/debug.log
wandb: 

wandb: wandb version 0.12.11 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
2022-03-18 05:57:45.325364: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1
wandb: Tracking run with wandb version 0.12.5
wandb: Syncing run denim-silence-2
wandb: ⭐️ View project at https://wandb.ai/yinanazhou/xl_512_bs_8_lr_1e06_es_5_lc_True_nr_False_sr_False_stem_True_lemma_False_repeat_5_fold_2
wandb: 🚀 View run at https://wandb.ai/yinanazhou/xl_512_bs_8_lr_1e06_es_5_lc_True_nr_False_sr_False_stem_True_lemma_False_repeat_5_fold_2/runs/3hzfyiru
wandb: Run data is saved locally in /project/6002780/yinan/Thesis_MER_Lyrics/lyric-emotion/wandb/run-20220318_055741-3hzfyiru
wandb: Run `wandb offline` to turn off syncing.

Validation loss decreased (inf --> 1.530651).  Saving model ...
Validation loss decreased (1.530651 --> 1.489694).  Saving model ...
Validation loss decreased (1.489694 --> 1.456018).  Saving model ...
Validation loss decreased (1.456018 --> 1.429106).  Saving model ...
Validation loss decreased (1.429106 --> 1.408067).  Saving model ...
Validation loss decreased (1.408067 --> 1.392119).  Saving model ...
Validation loss decreased (1.392119 --> 1.379043).  Saving model ...
Validation loss decreased (1.379043 --> 1.369752).  Saving model ...
Validation loss decreased (1.369752 --> 1.362454).  Saving model ...
Validation loss decreased (1.362454 --> 1.356589).  Saving model ...
Validation loss decreased (1.356589 --> 1.351172).  Saving model ...
Validation loss decreased (1.351172 --> 1.346377).  Saving model ...
Validation loss decreased (1.346377 --> 1.341982).  Saving model ...
Validation loss decreased (1.341982 --> 1.337771).  Saving model ...
Validation loss decreased (1.337771 --> 1.333592).  Saving model ...
Validation loss decreased (1.333592 --> 1.329497).  Saving model ...
Validation loss decreased (1.329497 --> 1.325039).  Saving model ...
Validation loss decreased (1.325039 --> 1.320744).  Saving model ...
Validation loss decreased (1.320744 --> 1.316093).  Saving model ...
Validation loss decreased (1.316093 --> 1.311174).  Saving model ...
Validation loss decreased (1.311174 --> 1.306147).  Saving model ...
Validation loss decreased (1.306147 --> 1.301067).  Saving model ...
Validation loss decreased (1.301067 --> 1.294917).  Saving model ...
Validation loss decreased (1.294917 --> 1.288990).  Saving model ...
Validation loss decreased (1.288990 --> 1.283665).  Saving model ...
Validation loss decreased (1.283665 --> 1.277740).  Saving model ...
Validation loss decreased (1.277740 --> 1.271588).  Saving model ...
Validation loss decreased (1.271588 --> 1.265687).  Saving model ...
Validation loss decreased (1.265687 --> 1.259140).  Saving model ...
Validation loss decreased (1.259140 --> 1.253396).  Saving model ...
Validation loss decreased (1.253396 --> 1.247504).  Saving model ...
Validation loss decreased (1.247504 --> 1.241398).  Saving model ...
Validation loss decreased (1.241398 --> 1.234670).  Saving model ...
Validation loss decreased (1.234670 --> 1.229369).  Saving model ...
Validation loss decreased (1.229369 --> 1.222853).  Saving model ...
Validation loss decreased (1.222853 --> 1.216979).  Saving model ...
Validation loss decreased (1.216979 --> 1.210865).  Saving model ...
Validation loss decreased (1.210865 --> 1.205826).  Saving model ...
Validation loss decreased (1.205826 --> 1.200063).  Saving model ...
Validation loss decreased (1.200063 --> 1.193413).  Saving model ...
Validation loss decreased (1.193413 --> 1.185616).  Saving model ...
Validation loss decreased (1.185616 --> 1.179186).  Saving model ...
Validation loss decreased (1.179186 --> 1.173290).  Saving model ...
Validation loss decreased (1.173290 --> 1.167368).  Saving model ...
Validation loss decreased (1.167368 --> 1.162235).  Saving model ...
Validation loss decreased (1.162235 --> 1.157106).  Saving model ...
Validation loss decreased (1.157106 --> 1.151051).  Saving model ...
Validation loss decreased (1.151051 --> 1.146431).  Saving model ...
Validation loss decreased (1.146431 --> 1.140138).  Saving model ...
Validation loss decreased (1.140138 --> 1.134304).  Saving model ...
Validation loss decreased (1.134304 --> 1.128386).  Saving model ...
Validation loss decreased (1.128386 --> 1.121069).  Saving model ...
Validation loss decreased (1.121069 --> 1.115708).  Saving model ...
Validation loss decreased (1.115708 --> 1.111436).  Saving model ...
Validation loss decreased (1.111436 --> 1.107292).  Saving model ...
Validation loss decreased (1.107292 --> 1.101270).  Saving model ...
Validation loss decreased (1.101270 --> 1.096828).  Saving model ...
Validation loss decreased (1.096828 --> 1.093247).  Saving model ...
Validation loss decreased (1.093247 --> 1.088178).  Saving model ...
Validation loss decreased (1.088178 --> 1.081789).  Saving model ...
Validation loss decreased (1.081789 --> 1.076131).  Saving model ...
Validation loss decreased (1.076131 --> 1.072125).  Saving model ...
Validation loss decreased (1.072125 --> 1.068299).  Saving model ...
Validation loss decreased (1.068299 --> 1.064475).  Saving model ...
Validation loss decreased (1.064475 --> 1.060006).  Saving model ...
Validation loss decreased (1.060006 --> 1.056925).  Saving model ...
Validation loss decreased (1.056925 --> 1.052876).  Saving model ...
Validation loss decreased (1.052876 --> 1.048479).  Saving model ...
Validation loss decreased (1.048479 --> 1.045679).  Saving model ...
Validation loss decreased (1.045679 --> 1.042936).  Saving model ...
Validation loss decreased (1.042936 --> 1.039511).  Saving model ...
Validation loss decreased (1.039511 --> 1.034836).  Saving model ...
Validation loss decreased (1.034836 --> 1.031975).  Saving model ...
Validation loss decreased (1.031975 --> 1.029803).  Saving model ...
Validation loss decreased (1.029803 --> 1.025750).  Saving model ...
Validation loss decreased (1.025750 --> 1.021689).  Saving model ...
Validation loss decreased (1.021689 --> 1.019719).  Saving model ...
Validation loss decreased (1.019719 --> 1.016701).  Saving model ...
Validation loss decreased (1.016701 --> 1.012342).  Saving model ...
Validation loss decreased (1.012342 --> 1.009022).  Saving model ...
Validation loss decreased (1.009022 --> 1.005846).  Saving model ...
Validation loss decreased (1.005846 --> 1.002753).  Saving model ...
Validation loss decreased (1.002753 --> 1.000508).  Saving model ...
Validation loss decreased (1.000508 --> 0.997986).  Saving model ...
Validation loss decreased (0.997986 --> 0.995660).  Saving model ...
Validation loss decreased (0.995660 --> 0.993372).  Saving model ...
Validation loss decreased (0.993372 --> 0.991369).  Saving model ...
Validation loss decreased (0.991369 --> 0.988993).  Saving model ...
Validation loss decreased (0.988993 --> 0.988305).  Saving model ...
Validation loss decreased (0.988305 --> 0.984786).  Saving model ...
Validation loss decreased (0.984786 --> 0.981224).  Saving model ...
Validation loss decreased (0.981224 --> 0.980109).  Saving model ...
Validation loss decreased (0.980109 --> 0.978417).  Saving model ...
Validation loss decreased (0.978417 --> 0.976231).  Saving model ...
Validation loss decreased (0.976231 --> 0.975269).  Saving model ...
Validation loss decreased (0.975269 --> 0.972894).  Saving model ...
Validation loss decreased (0.972894 --> 0.971059).  Saving model ...
Validation loss decreased (0.971059 --> 0.969272).  Saving model ...
Validation loss decreased (0.969272 --> 0.966723).  Saving model ...
Validation loss decreased (0.966723 --> 0.964828).  Saving model ...
Validation loss decreased (0.964828 --> 0.962710).  Saving model ...
Validation loss decreased (0.962710 --> 0.961966).  Saving model ...
Validation loss decreased (0.961966 --> 0.961123).  Saving model ...
Validation loss decreased (0.961123 --> 0.960276).  Saving model ...
Validation loss decreased (0.960276 --> 0.958752).  Saving model ...
Validation loss decreased (0.958752 --> 0.956285).  Saving model ...
Validation loss decreased (0.956285 --> 0.954944).  Saving model ...
Validation loss decreased (0.954944 --> 0.953000).  Saving model ...
Validation loss decreased (0.953000 --> 0.951820).  Saving model ...
Validation loss decreased (0.951820 --> 0.949623).  Saving model ...
Validation loss decreased (0.949623 --> 0.948948).  Saving model ...
Validation loss decreased (0.948948 --> 0.947583).  Saving model ...
Validation loss decreased (0.947583 --> 0.945802).  Saving model ...
Validation loss decreased (0.945802 --> 0.943711).  Saving model ...
Validation loss decreased (0.943711 --> 0.942735).  Saving model ...
Validation loss decreased (0.942735 --> 0.941556).  Saving model ...
Validation loss decreased (0.941556 --> 0.940334).  Saving model ...
EarlyStopping counter: 1 out of 5.0
Validation loss decreased (0.940334 --> 0.937545).  Saving model ...
Validation loss decreased (0.937545 --> 0.935934).  Saving model ...
Validation loss decreased (0.935934 --> 0.935809).  Saving model ...
Validation loss decreased (0.935809 --> 0.933689).  Saving model ...
EarlyStopping counter: 1 out of 5.0
Validation loss decreased (0.933689 --> 0.933199).  Saving model ...
EarlyStopping counter: 1 out of 5.0
Validation loss decreased (0.933199 --> 0.932525).  Saving model ...
Validation loss decreased (0.932525 --> 0.932357).  Saving model ...
Validation loss decreased (0.932357 --> 0.930006).  Saving model ...
EarlyStopping counter: 1 out of 5.0
Validation loss decreased (0.930006 --> 0.928298).  Saving model ...
Validation loss decreased (0.928298 --> 0.926624).  Saving model ...
Validation loss decreased (0.926624 --> 0.926372).  Saving model ...
EarlyStopping counter: 1 out of 5.0
EarlyStopping counter: 2 out of 5.0
Validation loss decreased (0.926372 --> 0.925333).  Saving model ...
Validation loss decreased (0.925333 --> 0.924222).  Saving model ...
Validation loss decreased (0.924222 --> 0.923910).  Saving model ...
Validation loss decreased (0.923910 --> 0.923152).  Saving model ...
Validation loss decreased (0.923152 --> 0.923038).  Saving model ...
Validation loss decreased (0.923038 --> 0.922443).  Saving model ...
Validation loss decreased (0.922443 --> 0.922245).  Saving model ...
EarlyStopping counter: 1 out of 5.0
EarlyStopping counter: 2 out of 5.0
EarlyStopping counter: 3 out of 5.0
Validation loss decreased (0.922245 --> 0.921352).  Saving model ...
Validation loss decreased (0.921352 --> 0.920659).  Saving model ...
EarlyStopping counter: 1 out of 5.0
EarlyStopping counter: 2 out of 5.0
EarlyStopping counter: 3 out of 5.0
Validation loss decreased (0.920659 --> 0.920589).  Saving model ...
Validation loss decreased (0.920589 --> 0.919322).  Saving model ...
Validation loss decreased (0.919322 --> 0.918272).  Saving model ...
EarlyStopping counter: 1 out of 5.0
EarlyStopping counter: 2 out of 5.0
EarlyStopping counter: 3 out of 5.0
EarlyStopping counter: 4 out of 5.0
EarlyStopping counter: 5 out of 5.0
/localscratch/yinan.29152320.0/env/lib/python3.7/site-packages/torch/nn/functional.py:1794: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.
  warnings.warn("nn.functional.tanh is deprecated. Use torch.tanh instead.")
wandb: Waiting for W&B process to finish, PID 113990... (success).
wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: \ 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: | 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: / 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: \ 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: | 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: / 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: \ 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: | 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: / 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb:                                                                                
wandb: Run history:
wandb:     e_F1 ▁▁▂▃▄▄▄▅▅▅▆▆▆▆▆▇▇▇▇▇▇▇██████████████████
wandb:   e_loss █▇▇▆▆▆▆▅▅▅▄▄▄▃▃▃▃▃▂▂▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:     t_F1 ▁▁▂▃▃▃▄▄▄▄▅▅▅▆▆▆▆▆▆▆▆▇▆▇▇▇▇█▇▇▇▇▇▇██▇███
wandb:   t_loss ██▇▆▇▆▆▆▆▆▅▅▅▄▄▄▄▄▄▃▃▃▃▃▂▃▂▂▂▂▂▂▂▂▁▂▁▁▁▁
wandb: 
wandb: Run summary:
wandb:     e_F1 61.9342
wandb:   e_loss 0.92049
wandb:     t_F1 71.87611
wandb:   t_loss 0.73247
wandb: 
wandb: Synced 4 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Synced denim-silence-2: https://wandb.ai/yinanazhou/xl_512_bs_8_lr_1e06_es_5_lc_True_nr_False_sr_False_stem_True_lemma_False_repeat_5_fold_2/runs/3hzfyiru
wandb: Find logs at: ./wandb/run-20220318_055741-3hzfyiru/logs/debug.log
wandb: 

