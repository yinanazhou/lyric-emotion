Unloading StdEnv/2020

Due to MODULEPATH changes, the following have been reloaded:
  1) mii/1.1.1


The following have been reloaded with a version change:
  1) python/3.8.2 => python/3.7.4

Using base prefix '/cvmfs/soft.computecanada.ca/easybuild/software/2017/Core/python/3.7.4'
New python executable in /localscratch/yinan.29479425.0/env/bin/python
Installing setuptools, pip, wheel...
done.
Ignoring pip: markers 'python_version < "3"' don't match your environment
Looking in links: /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/nix/avx2, /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/nix/generic, /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic
Collecting pip
Installing collected packages: pip
  Found existing installation: pip 19.1.1
    Uninstalling pip-19.1.1:
      Successfully uninstalled pip-19.1.1
Successfully installed pip-21.2.3+computecanada
Looking in links: /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/nix/avx2, /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/nix/generic, /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/keras-2.8.0+computecanada-py2.py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/Keras_Preprocessing-1.1.2+computecanada-py3-none-any.whl
Requirement already satisfied: matplotlib in /cvmfs/soft.computecanada.ca/easybuild/software/2017/Core/scipy-stack/2019a/lib/python3.7/site-packages (from -r requirements.txt (line 3)) (3.0.2)
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/nltk-3.6.5+computecanada-py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/scikit_learn-0.22.1+computecanada-cp37-cp37m-linux_x86_64.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/tensorboard-2.3.0+computecanada-py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/tensorboard_plugin_wit-1.7.0+computecanada-py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/tensorflow_gpu-2.3.0+computecanada-cp37-cp37m-linux_x86_64.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/tensorflow_estimator-2.3.0+computecanada-py2.py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/tokenizers-0.5.2+computecanada-cp37-cp37m-linux_x86_64.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/nix/avx2/torch-1.4.0+computecanada-cp37-cp37m-linux_x86_64.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/torchtext-0.6.0+computecanada-py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/torchvision-0.8.2+computecanada-cp37-cp37m-linux_x86_64.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/transformers-2.5.1+computecanada-py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/urllib3-1.26.7+computecanada-py2.py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/tqdm-4.63.1+computecanada-py2.py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/joblib-1.1.0+computecanada-py2.py3-none-any.whl
ERROR: Could not find a version that satisfies the requirement regex>=2021.8.3 (from nltk) (from versions: 2018.1.10+computecanada, 2019.11.1+computecanada, 2020.11.13+computecanada)
ERROR: No matching distribution found for regex>=2021.8.3
Looking in links: /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/nix/avx2, /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/nix/generic, /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic
ERROR: Could not find a version that satisfies the requirement numpy==1.20.0+computacanada (from versions: 1.15.0+computecanada, 1.15.2+computecanada, 1.15.4+computecanada, 1.16.0+computecanada, 1.16.2+computecanada, 1.16.3+computecanada, 1.17.4+computecanada, 1.18.1+computecanada, 1.18.4+computecanada, 1.19.1+computecanada, 1.19.2+computecanada, 1.20.2+computecanada)
ERROR: No matching distribution found for numpy==1.20.0+computacanada
Looking in links: /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/nix/avx2, /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/nix/generic, /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/wandb-0.12.5+computecanada-py2.py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/promise-2.3+computecanada-py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/shortuuid-1.0.1+computecanada-py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/subprocess32-3.5.4+computecanada-py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/GitPython-3.1.24+computecanada-py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/docker_pycreds-0.4.0+computecanada-py2.py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/yaspin-2.1.0+computecanada-py3-none-any.whl
Requirement already satisfied: python-dateutil>=2.6.1 in /cvmfs/soft.computecanada.ca/easybuild/software/2017/Core/scipy-stack/2019a/lib/python3.7/site-packages (from wandb) (2.7.5)
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/sentry_sdk-1.5.0+computecanada-py2.py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/six-1.16.0+computecanada-py2.py3-none-any.whl
Requirement already satisfied: requests<3,>=2.0.0 in /cvmfs/soft.computecanada.ca/easybuild/software/2017/Core/scipy-stack/2019a/lib/python3.7/site-packages (from wandb) (2.21.0)
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/protobuf-3.19.4+computecanada-py2.py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/psutil-5.7.3+computecanada-cp37-cp37m-linux_x86_64.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/configparser-5.0.2+computecanada-py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/pathtools-0.1.2+computecanada-py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/click-8.0.4+computecanada-py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/PyYAML-5.3.1+computecanada-cp37-cp37m-linux_x86_64.whl
Requirement already satisfied: importlib-metadata in /cvmfs/soft.computecanada.ca/easybuild/software/2017/Core/scipy-stack/2019a/lib/python3.7/site-packages (from Click!=8.0.0,>=7.0->wandb) (0.8)
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/typing_extensions-4.1.1+computecanada-py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/gitdb-4.0.9+computecanada-py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/smmap-5.0.0+computecanada-py3-none-any.whl
Requirement already satisfied: idna<2.9,>=2.5 in /cvmfs/soft.computecanada.ca/easybuild/software/2017/Core/scipy-stack/2019a/lib/python3.7/site-packages (from requests<3,>=2.0.0->wandb) (2.8)
Requirement already satisfied: certifi>=2017.4.17 in /cvmfs/soft.computecanada.ca/easybuild/software/2017/Core/scipy-stack/2019a/lib/python3.7/site-packages (from requests<3,>=2.0.0->wandb) (2018.11.29)
Requirement already satisfied: urllib3<1.25,>=1.21.1 in /cvmfs/soft.computecanada.ca/easybuild/software/2017/Core/scipy-stack/2019a/lib/python3.7/site-packages (from requests<3,>=2.0.0->wandb) (1.24.1)
Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /cvmfs/soft.computecanada.ca/easybuild/software/2017/Core/scipy-stack/2019a/lib/python3.7/site-packages (from requests<3,>=2.0.0->wandb) (3.0.4)
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/termcolor-1.1.0+computecanada-py3-none-any.whl
Requirement already satisfied: zipp>=0.3.2 in /cvmfs/soft.computecanada.ca/easybuild/software/2017/Core/scipy-stack/2019a/lib/python3.7/site-packages (from importlib-metadata->Click!=8.0.0,>=7.0->wandb) (0.3.3)
Installing collected packages: smmap, typing-extensions, termcolor, six, gitdb, yaspin, subprocess32, shortuuid, sentry-sdk, PyYAML, psutil, protobuf, promise, pathtools, GitPython, docker-pycreds, configparser, Click, wandb
  Attempting uninstall: six
    Found existing installation: six 1.12.0
    Not uninstalling six at /cvmfs/soft.computecanada.ca/easybuild/software/2017/Core/scipy-stack/2019a/lib/python3.7/site-packages, outside environment /localscratch/yinan.29479425.0/env
    Can't uninstall 'six'. No files were found to uninstall.
Successfully installed Click-8.0.4+computecanada GitPython-3.1.24+computecanada PyYAML-5.3.1+computecanada configparser-5.0.2+computecanada docker-pycreds-0.4.0+computecanada gitdb-4.0.9+computecanada pathtools-0.1.2+computecanada promise-2.3+computecanada protobuf-3.19.4+computecanada psutil-5.7.3+computecanada sentry-sdk-1.5.0+computecanada shortuuid-1.0.1+computecanada six-1.16.0+computecanada smmap-5.0.0+computecanada subprocess32-3.5.4+computecanada termcolor-1.1.0+computecanada typing-extensions-4.1.1+computecanada wandb-0.12.5+computecanada yaspin-2.1.0+computecanada
Looking in links: /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/nix/avx2, /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/nix/generic, /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic
ERROR: Could not find a version that satisfies the requirement sagemaker (from versions: none)
ERROR: No matching distribution found for sagemaker
Looking in links: /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/nix/avx2, /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/nix/generic, /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/torch-1.9.1+computecanada-cp37-cp37m-linux_x86_64.whl
Requirement already satisfied: typing-extensions in /localscratch/yinan.29479425.0/env/lib/python3.7/site-packages (from torch) (4.1.1+computecanada)
Installing collected packages: torch
Successfully installed torch-1.9.1+computecanada
Looking in links: /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/nix/avx2, /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/nix/generic, /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/transformers-2.5.1+computecanada-py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/tokenizers-0.5.2+computecanada-cp37-cp37m-linux_x86_64.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/sentencepiece-0.1.91+computecanada-cp37-cp37m-linux_x86_64.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/sacremoses-0.0.49+computecanada-py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/regex-2020.11.13+computecanada-cp37-cp37m-linux_x86_64.whl
Requirement already satisfied: requests in /cvmfs/soft.computecanada.ca/easybuild/software/2017/Core/scipy-stack/2019a/lib/python3.7/site-packages (from transformers==2.5.1+computecanada) (2.21.0)
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/filelock-3.4.2+computecanada-py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/tqdm-4.63.1+computecanada-py2.py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/boto3-1.21.14+computecanada-py3-none-any.whl
Requirement already satisfied: numpy in /cvmfs/soft.computecanada.ca/easybuild/software/2017/Core/scipy-stack/2019a/lib/python3.7/site-packages (from transformers==2.5.1+computecanada) (1.16.0)
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/s3transfer-0.5.1+computecanada-py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/jmespath-0.10.0+computecanada-py2.py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/botocore-1.24.14+computecanada-py3-none-any.whl
Requirement already satisfied: python-dateutil<3.0.0,>=2.1 in /cvmfs/soft.computecanada.ca/easybuild/software/2017/Core/scipy-stack/2019a/lib/python3.7/site-packages (from botocore<1.25.0,>=1.24.14->boto3->transformers==2.5.1+computecanada) (2.7.5)
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/urllib3-1.26.8+computecanada-py2.py3-none-any.whl
Requirement already satisfied: six>=1.5 in /localscratch/yinan.29479425.0/env/lib/python3.7/site-packages (from python-dateutil<3.0.0,>=2.1->botocore<1.25.0,>=1.24.14->boto3->transformers==2.5.1+computecanada) (1.16.0+computecanada)
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/requests-2.27.1+computecanada-py2.py3-none-any.whl
Requirement already satisfied: idna<4,>=2.5 in /cvmfs/soft.computecanada.ca/easybuild/software/2017/Core/scipy-stack/2019a/lib/python3.7/site-packages (from requests->transformers==2.5.1+computecanada) (2.8)
Requirement already satisfied: certifi>=2017.4.17 in /cvmfs/soft.computecanada.ca/easybuild/software/2017/Core/scipy-stack/2019a/lib/python3.7/site-packages (from requests->transformers==2.5.1+computecanada) (2018.11.29)
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/charset_normalizer-2.0.12+computecanada-py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/joblib-1.1.0+computecanada-py2.py3-none-any.whl
Requirement already satisfied: click in /localscratch/yinan.29479425.0/env/lib/python3.7/site-packages (from sacremoses->transformers==2.5.1+computecanada) (8.0.4+computecanada)
Requirement already satisfied: importlib-metadata in /cvmfs/soft.computecanada.ca/easybuild/software/2017/Core/scipy-stack/2019a/lib/python3.7/site-packages (from click->sacremoses->transformers==2.5.1+computecanada) (0.8)
Requirement already satisfied: zipp>=0.3.2 in /cvmfs/soft.computecanada.ca/easybuild/software/2017/Core/scipy-stack/2019a/lib/python3.7/site-packages (from importlib-metadata->click->sacremoses->transformers==2.5.1+computecanada) (0.3.3)
Installing collected packages: urllib3, jmespath, botocore, tqdm, s3transfer, regex, joblib, charset-normalizer, tokenizers, sentencepiece, sacremoses, requests, filelock, boto3, transformers
  Attempting uninstall: urllib3
    Found existing installation: urllib3 1.24.1
    Not uninstalling urllib3 at /cvmfs/soft.computecanada.ca/easybuild/software/2017/Core/scipy-stack/2019a/lib/python3.7/site-packages, outside environment /localscratch/yinan.29479425.0/env
    Can't uninstall 'urllib3'. No files were found to uninstall.
  Attempting uninstall: requests
    Found existing installation: requests 2.21.0
    Not uninstalling requests at /cvmfs/soft.computecanada.ca/easybuild/software/2017/Core/scipy-stack/2019a/lib/python3.7/site-packages, outside environment /localscratch/yinan.29479425.0/env
    Can't uninstall 'requests'. No files were found to uninstall.
Successfully installed boto3-1.21.14+computecanada botocore-1.24.14+computecanada charset-normalizer-2.0.12+computecanada filelock-3.4.2+computecanada jmespath-0.10.0+computecanada joblib-1.1.0+computecanada regex-2020.11.13+computecanada requests-2.27.1+computecanada s3transfer-0.5.1+computecanada sacremoses-0.0.49+computecanada sentencepiece-0.1.91+computecanada tokenizers-0.5.2+computecanada tqdm-4.63.1+computecanada transformers-2.5.1+computecanada urllib3-1.26.8+computecanada
Looking in links: /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/nix/avx2, /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/nix/generic, /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/tensorflow_gpu-2.3.0+computecanada-cp37-cp37m-linux_x86_64.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/tensorflow_estimator-2.3.0+computecanada-py2.py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/tensorboard-2.8.0+computecanada-py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/nix/generic/scipy-1.4.1+computecanada-cp37-cp37m-linux_x86_64.whl
Requirement already satisfied: numpy<1.19.0,>=1.16.0 in /cvmfs/soft.computecanada.ca/easybuild/software/2017/Core/scipy-stack/2019a/lib/python3.7/site-packages (from tensorflow_gpu==2.3.0+computecanada) (1.16.0)
Requirement already satisfied: termcolor>=1.1.0 in /localscratch/yinan.29479425.0/env/lib/python3.7/site-packages (from tensorflow_gpu==2.3.0+computecanada) (1.1.0+computecanada)
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/astunparse-1.6.3+computecanada-py2.py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/google_pasta-0.2.0+computecanada-py3-none-any.whl
Requirement already satisfied: six>=1.12.0 in /localscratch/yinan.29479425.0/env/lib/python3.7/site-packages (from tensorflow_gpu==2.3.0+computecanada) (1.16.0+computecanada)
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/wrapt-1.11.2+computecanada-cp37-cp37m-linux_x86_64.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/grpcio-1.38.0+computecanada-cp37-cp37m-linux_x86_64.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/absl_py-1.0.0+computecanada-py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/gast-0.3.3+computecanada-py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/nix/avx2/h5py-2.10.0+computecanada-cp37-cp37m-linux_x86_64.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/opt_einsum-3.3.0+computecanada-py3-none-any.whl
Requirement already satisfied: protobuf>=3.9.2 in /localscratch/yinan.29479425.0/env/lib/python3.7/site-packages (from tensorflow_gpu==2.3.0+computecanada) (3.19.4+computecanada)
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/Keras_Preprocessing-1.1.2+computecanada-py3-none-any.whl
Requirement already satisfied: wheel>=0.26 in /localscratch/yinan.29479425.0/env/lib/python3.7/site-packages (from tensorflow_gpu==2.3.0+computecanada) (0.33.4)
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/tensorboard_data_server-0.6.1+computecanada-py3-none-linux_x86_64.whl
Requirement already satisfied: requests<3,>=2.21.0 in /localscratch/yinan.29479425.0/env/lib/python3.7/site-packages (from tensorboard<3,>=2.3.0->tensorflow_gpu==2.3.0+computecanada) (2.27.1+computecanada)
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/tensorboard_plugin_wit-1.8.0+computecanada-py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/google_auth-2.3.3+computecanada-py2.py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/Werkzeug-2.0.3+computecanada-py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/Markdown-3.3.6+computecanada-py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/google_auth_oauthlib-0.4.6+computecanada-py2.py3-none-any.whl
Requirement already satisfied: setuptools>=41.0.0 in /localscratch/yinan.29479425.0/env/lib/python3.7/site-packages (from tensorboard<3,>=2.3.0->tensorflow_gpu==2.3.0+computecanada) (41.0.1)
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/rsa-4.8+computecanada-py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/cachetools-4.2.4+computecanada-py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/pyasn1_modules-0.2.8+computecanada-py2.py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/requests_oauthlib-1.3.0+computecanada-py2.py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/importlib_metadata-4.10.1+computecanada-py3-none-any.whl
Requirement already satisfied: typing-extensions>=3.6.4 in /localscratch/yinan.29479425.0/env/lib/python3.7/site-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard<3,>=2.3.0->tensorflow_gpu==2.3.0+computecanada) (4.1.1+computecanada)
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/zipp-3.7.0+computecanada-py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/pyasn1-0.4.8+computecanada-py2.py3-none-any.whl
Requirement already satisfied: certifi>=2017.4.17 in /cvmfs/soft.computecanada.ca/easybuild/software/2017/Core/scipy-stack/2019a/lib/python3.7/site-packages (from requests<3,>=2.21.0->tensorboard<3,>=2.3.0->tensorflow_gpu==2.3.0+computecanada) (2018.11.29)
Requirement already satisfied: charset-normalizer~=2.0.0 in /localscratch/yinan.29479425.0/env/lib/python3.7/site-packages (from requests<3,>=2.21.0->tensorboard<3,>=2.3.0->tensorflow_gpu==2.3.0+computecanada) (2.0.12+computecanada)
Requirement already satisfied: idna<4,>=2.5 in /cvmfs/soft.computecanada.ca/easybuild/software/2017/Core/scipy-stack/2019a/lib/python3.7/site-packages (from requests<3,>=2.21.0->tensorboard<3,>=2.3.0->tensorflow_gpu==2.3.0+computecanada) (2.8)
Requirement already satisfied: urllib3<1.27,>=1.21.1 in /localscratch/yinan.29479425.0/env/lib/python3.7/site-packages (from requests<3,>=2.21.0->tensorboard<3,>=2.3.0->tensorflow_gpu==2.3.0+computecanada) (1.26.8+computecanada)
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/oauthlib-3.1.1+computecanada-py2.py3-none-any.whl
Installing collected packages: pyasn1, zipp, rsa, pyasn1-modules, oauthlib, cachetools, requests-oauthlib, importlib-metadata, google-auth, werkzeug, tensorboard-plugin-wit, tensorboard-data-server, markdown, grpcio, google-auth-oauthlib, absl-py, wrapt, tensorflow-estimator, tensorboard, scipy, opt-einsum, keras-preprocessing, h5py, google-pasta, gast, astunparse, tensorflow-gpu
  Attempting uninstall: pyasn1
    Found existing installation: pyasn1 0.4.3
    Not uninstalling pyasn1 at /cvmfs/soft.computecanada.ca/easybuild/software/2017/Core/scipy-stack/2019a/lib/python3.7/site-packages, outside environment /localscratch/yinan.29479425.0/env
    Can't uninstall 'pyasn1'. No files were found to uninstall.
  Attempting uninstall: zipp
    Found existing installation: zipp 0.3.3
    Not uninstalling zipp at /cvmfs/soft.computecanada.ca/easybuild/software/2017/Core/scipy-stack/2019a/lib/python3.7/site-packages, outside environment /localscratch/yinan.29479425.0/env
    Can't uninstall 'zipp'. No files were found to uninstall.
  Attempting uninstall: importlib-metadata
    Found existing installation: importlib-metadata 0.8
    Not uninstalling importlib-metadata at /cvmfs/soft.computecanada.ca/easybuild/software/2017/Core/scipy-stack/2019a/lib/python3.7/site-packages, outside environment /localscratch/yinan.29479425.0/env
    Can't uninstall 'importlib-metadata'. No files were found to uninstall.
  Attempting uninstall: scipy
    Found existing installation: scipy 1.2.0
    Not uninstalling scipy at /cvmfs/soft.computecanada.ca/easybuild/software/2017/Core/scipy-stack/2019a/lib/python3.7/site-packages, outside environment /localscratch/yinan.29479425.0/env
    Can't uninstall 'scipy'. No files were found to uninstall.
Successfully installed absl-py-1.0.0+computecanada astunparse-1.6.3+computecanada cachetools-4.2.4+computecanada gast-0.3.3+computecanada google-auth-2.3.3+computecanada google-auth-oauthlib-0.4.6+computecanada google-pasta-0.2.0+computecanada grpcio-1.38.0+computecanada h5py-2.10.0+computecanada importlib-metadata-4.10.1+computecanada keras-preprocessing-1.1.2+computecanada markdown-3.3.6+computecanada oauthlib-3.1.1+computecanada opt-einsum-3.3.0+computecanada pyasn1-0.4.8+computecanada pyasn1-modules-0.2.8+computecanada requests-oauthlib-1.3.0+computecanada rsa-4.8+computecanada scipy-1.4.1+computecanada tensorboard-2.8.0+computecanada tensorboard-data-server-0.6.1+computecanada tensorboard-plugin-wit-1.8.0+computecanada tensorflow-estimator-2.3.0+computecanada tensorflow-gpu-2.3.0+computecanada werkzeug-2.0.3+computecanada wrapt-1.11.2+computecanada zipp-3.7.0+computecanada
Looking in links: /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/nix/avx2, /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/nix/generic, /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/keras-2.8.0+computecanada-py2.py3-none-any.whl
Installing collected packages: Keras
Successfully installed Keras-2.8.0+computecanada
Looking in links: /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/nix/avx2, /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/nix/generic, /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/urllib3-1.26.7+computecanada-py2.py3-none-any.whl
Installing collected packages: urllib3
  Attempting uninstall: urllib3
    Found existing installation: urllib3 1.26.8+computecanada
    Uninstalling urllib3-1.26.8+computecanada:
      Successfully uninstalled urllib3-1.26.8+computecanada
Successfully installed urllib3-1.26.7+computecanada
Looking in links: /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/nix/avx2, /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/nix/generic, /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/nltk-3.7+computecanada-py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/nltk-3.6.5+computecanada-py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/nltk-3.6.3+computecanada-py3-none-any.whl
Requirement already satisfied: click in /localscratch/yinan.29479425.0/env/lib/python3.7/site-packages (from nltk) (8.0.4+computecanada)
Requirement already satisfied: tqdm in /localscratch/yinan.29479425.0/env/lib/python3.7/site-packages (from nltk) (4.63.1+computecanada)
Requirement already satisfied: regex in /localscratch/yinan.29479425.0/env/lib/python3.7/site-packages (from nltk) (2020.11.13+computecanada)
Requirement already satisfied: joblib in /localscratch/yinan.29479425.0/env/lib/python3.7/site-packages (from nltk) (1.1.0+computecanada)
Requirement already satisfied: importlib-metadata in /localscratch/yinan.29479425.0/env/lib/python3.7/site-packages (from click->nltk) (4.10.1+computecanada)
Requirement already satisfied: typing-extensions>=3.6.4 in /localscratch/yinan.29479425.0/env/lib/python3.7/site-packages (from importlib-metadata->click->nltk) (4.1.1+computecanada)
Requirement already satisfied: zipp>=0.5 in /localscratch/yinan.29479425.0/env/lib/python3.7/site-packages (from importlib-metadata->click->nltk) (3.7.0+computecanada)
Installing collected packages: nltk
Successfully installed nltk-3.6.3+computecanada
Looking in links: /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/nix/avx2, /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/nix/generic, /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/scikit_learn-0.22.1+computecanada-cp37-cp37m-linux_x86_64.whl
Requirement already satisfied: joblib>=0.11 in /localscratch/yinan.29479425.0/env/lib/python3.7/site-packages (from scikit-learn==0.22.1) (1.1.0+computecanada)
Requirement already satisfied: scipy>=0.17.0 in /localscratch/yinan.29479425.0/env/lib/python3.7/site-packages (from scikit-learn==0.22.1) (1.4.1+computecanada)
Requirement already satisfied: numpy>=1.11.0 in /cvmfs/soft.computecanada.ca/easybuild/software/2017/Core/scipy-stack/2019a/lib/python3.7/site-packages (from scikit-learn==0.22.1) (1.16.0)
Installing collected packages: scikit-learn
Successfully installed scikit-learn-0.22.1+computecanada
Looking in links: /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/nix/avx2, /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/nix/generic, /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic
Requirement already satisfied: tokenizers==0.5.2 in /localscratch/yinan.29479425.0/env/lib/python3.7/site-packages (0.5.2+computecanada)
wandb: Appending key for api.wandb.ai to your netrc file: /home/yinan/.netrc
Starting Task
2022-03-25 06:38:03.032244: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1
[nltk_data] Downloading package stopwords to /home/yinan/nltk_data...
[nltk_data]   Package stopwords is already up-to-date!
[nltk_data] Downloading package wordnet to /home/yinan/nltk_data...
[nltk_data]   Package wordnet is already up-to-date!
wandb: Currently logged in as: yinanazhou (use `wandb login --relogin` to force relogin)
wandb: wandb version 0.12.11 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
2022-03-25 06:38:21.937584: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1
wandb: Tracking run with wandb version 0.12.5
wandb: Syncing run dry-lake-1
wandb: ⭐️ View project at https://wandb.ai/yinanazhou/xl_512_bs_8_lr_1e06_es_5_lc_True_nr_True_sr_False_stem_True_lemma_False_repeat_1_fold_1
wandb: 🚀 View run at https://wandb.ai/yinanazhou/xl_512_bs_8_lr_1e06_es_5_lc_True_nr_True_sr_False_stem_True_lemma_False_repeat_1_fold_1/runs/2jql4ktl
wandb: Run data is saved locally in /project/6002780/yinan/Thesis_MER_Lyrics/lyric-emotion/wandb/run-20220325_063819-2jql4ktl
wandb: Run `wandb offline` to turn off syncing.

Validation loss decreased (inf --> 1.432099).  Saving model ...
Validation loss decreased (1.432099 --> 1.413042).  Saving model ...
Validation loss decreased (1.413042 --> 1.397420).  Saving model ...
Validation loss decreased (1.397420 --> 1.385428).  Saving model ...
Validation loss decreased (1.385428 --> 1.375896).  Saving model ...
Validation loss decreased (1.375896 --> 1.367919).  Saving model ...
Validation loss decreased (1.367919 --> 1.361894).  Saving model ...
Validation loss decreased (1.361894 --> 1.356860).  Saving model ...
Validation loss decreased (1.356860 --> 1.352237).  Saving model ...
Validation loss decreased (1.352237 --> 1.347321).  Saving model ...
Validation loss decreased (1.347321 --> 1.342617).  Saving model ...
Validation loss decreased (1.342617 --> 1.338253).  Saving model ...
Validation loss decreased (1.338253 --> 1.334217).  Saving model ...
Validation loss decreased (1.334217 --> 1.330290).  Saving model ...
Validation loss decreased (1.330290 --> 1.325548).  Saving model ...
Validation loss decreased (1.325548 --> 1.322206).  Saving model ...
Validation loss decreased (1.322206 --> 1.318300).  Saving model ...
Validation loss decreased (1.318300 --> 1.313757).  Saving model ...
Validation loss decreased (1.313757 --> 1.309400).  Saving model ...
Validation loss decreased (1.309400 --> 1.305234).  Saving model ...
Validation loss decreased (1.305234 --> 1.300542).  Saving model ...
Validation loss decreased (1.300542 --> 1.294707).  Saving model ...
Validation loss decreased (1.294707 --> 1.290077).  Saving model ...
Validation loss decreased (1.290077 --> 1.284932).  Saving model ...
Validation loss decreased (1.284932 --> 1.279157).  Saving model ...
Validation loss decreased (1.279157 --> 1.274154).  Saving model ...
Validation loss decreased (1.274154 --> 1.268793).  Saving model ...
Validation loss decreased (1.268793 --> 1.265855).  Saving model ...
Validation loss decreased (1.265855 --> 1.263404).  Saving model ...
Validation loss decreased (1.263404 --> 1.260792).  Saving model ...
Validation loss decreased (1.260792 --> 1.257329).  Saving model ...
Validation loss decreased (1.257329 --> 1.252960).  Saving model ...
Validation loss decreased (1.252960 --> 1.251427).  Saving model ...
Validation loss decreased (1.251427 --> 1.245611).  Saving model ...
Validation loss decreased (1.245611 --> 1.242135).  Saving model ...
Validation loss decreased (1.242135 --> 1.239153).  Saving model ...
Validation loss decreased (1.239153 --> 1.234749).  Saving model ...
Validation loss decreased (1.234749 --> 1.232723).  Saving model ...
Validation loss decreased (1.232723 --> 1.230316).  Saving model ...
Validation loss decreased (1.230316 --> 1.228334).  Saving model ...
Validation loss decreased (1.228334 --> 1.223766).  Saving model ...
Validation loss decreased (1.223766 --> 1.219358).  Saving model ...
Validation loss decreased (1.219358 --> 1.216698).  Saving model ...
EarlyStopping counter: 1 out of 5.0
Validation loss decreased (1.216698 --> 1.213713).  Saving model ...
Validation loss decreased (1.213713 --> 1.211325).  Saving model ...
EarlyStopping counter: 1 out of 5.0
Validation loss decreased (1.211325 --> 1.209955).  Saving model ...
Validation loss decreased (1.209955 --> 1.203083).  Saving model ...
Validation loss decreased (1.203083 --> 1.198370).  Saving model ...
Validation loss decreased (1.198370 --> 1.197020).  Saving model ...
Validation loss decreased (1.197020 --> 1.193911).  Saving model ...
Validation loss decreased (1.193911 --> 1.193876).  Saving model ...
Validation loss decreased (1.193876 --> 1.190228).  Saving model ...
EarlyStopping counter: 1 out of 5.0
Validation loss decreased (1.190228 --> 1.185514).  Saving model ...
Validation loss decreased (1.185514 --> 1.178811).  Saving model ...
Validation loss decreased (1.178811 --> 1.176774).  Saving model ...
Validation loss decreased (1.176774 --> 1.173089).  Saving model ...
EarlyStopping counter: 1 out of 5.0
Validation loss decreased (1.173089 --> 1.171397).  Saving model ...
Validation loss decreased (1.171397 --> 1.171198).  Saving model ...
Validation loss decreased (1.171198 --> 1.166246).  Saving model ...
Validation loss decreased (1.166246 --> 1.165828).  Saving model ...
Validation loss decreased (1.165828 --> 1.163128).  Saving model ...
Validation loss decreased (1.163128 --> 1.157968).  Saving model ...
Validation loss decreased (1.157968 --> 1.157533).  Saving model ...
Validation loss decreased (1.157533 --> 1.154896).  Saving model ...
Validation loss decreased (1.154896 --> 1.153766).  Saving model ...
Validation loss decreased (1.153766 --> 1.152341).  Saving model ...
Validation loss decreased (1.152341 --> 1.147907).  Saving model ...
Validation loss decreased (1.147907 --> 1.143615).  Saving model ...
Validation loss decreased (1.143615 --> 1.140623).  Saving model ...
Validation loss decreased (1.140623 --> 1.135741).  Saving model ...
Validation loss decreased (1.135741 --> 1.135268).  Saving model ...
EarlyStopping counter: 1 out of 5.0
EarlyStopping counter: 2 out of 5.0
Validation loss decreased (1.135268 --> 1.131094).  Saving model ...
Validation loss decreased (1.131094 --> 1.124207).  Saving model ...
EarlyStopping counter: 1 out of 5.0
EarlyStopping counter: 2 out of 5.0
EarlyStopping counter: 3 out of 5.0
Validation loss decreased (1.124207 --> 1.123252).  Saving model ...
Validation loss decreased (1.123252 --> 1.117848).  Saving model ...
Validation loss decreased (1.117848 --> 1.117503).  Saving model ...
Validation loss decreased (1.117503 --> 1.113976).  Saving model ...
Validation loss decreased (1.113976 --> 1.105446).  Saving model ...
EarlyStopping counter: 1 out of 5.0
Validation loss decreased (1.105446 --> 1.103815).  Saving model ...
EarlyStopping counter: 1 out of 5.0
EarlyStopping counter: 2 out of 5.0
EarlyStopping counter: 3 out of 5.0
Validation loss decreased (1.103815 --> 1.103791).  Saving model ...
EarlyStopping counter: 1 out of 5.0
Validation loss decreased (1.103791 --> 1.101895).  Saving model ...
Validation loss decreased (1.101895 --> 1.100773).  Saving model ...
Validation loss decreased (1.100773 --> 1.099139).  Saving model ...
Validation loss decreased (1.099139 --> 1.096064).  Saving model ...
Validation loss decreased (1.096064 --> 1.092445).  Saving model ...
EarlyStopping counter: 1 out of 5.0
EarlyStopping counter: 2 out of 5.0
Validation loss decreased (1.092445 --> 1.091686).  Saving model ...
Validation loss decreased (1.091686 --> 1.086334).  Saving model ...
Validation loss decreased (1.086334 --> 1.082824).  Saving model ...
EarlyStopping counter: 1 out of 5.0
Validation loss decreased (1.082824 --> 1.079774).  Saving model ...
EarlyStopping counter: 1 out of 5.0
EarlyStopping counter: 2 out of 5.0
Validation loss decreased (1.079774 --> 1.077148).  Saving model ...
Validation loss decreased (1.077148 --> 1.075520).  Saving model ...
EarlyStopping counter: 1 out of 5.0
EarlyStopping counter: 2 out of 5.0
EarlyStopping counter: 3 out of 5.0
Validation loss decreased (1.075520 --> 1.073732).  Saving model ...
EarlyStopping counter: 1 out of 5.0
EarlyStopping counter: 2 out of 5.0
Validation loss decreased (1.073732 --> 1.070758).  Saving model ...
EarlyStopping counter: 1 out of 5.0
Validation loss decreased (1.070758 --> 1.070594).  Saving model ...
Validation loss decreased (1.070594 --> 1.062531).  Saving model ...
Validation loss decreased (1.062531 --> 1.062460).  Saving model ...
Validation loss decreased (1.062460 --> 1.060279).  Saving model ...
Validation loss decreased (1.060279 --> 1.058972).  Saving model ...
Validation loss decreased (1.058972 --> 1.057617).  Saving model ...
Validation loss decreased (1.057617 --> 1.055909).  Saving model ...
EarlyStopping counter: 1 out of 5.0
EarlyStopping counter: 2 out of 5.0
EarlyStopping counter: 3 out of 5.0
EarlyStopping counter: 4 out of 5.0
Validation loss decreased (1.055909 --> 1.055608).  Saving model ...
EarlyStopping counter: 1 out of 5.0
EarlyStopping counter: 2 out of 5.0
EarlyStopping counter: 3 out of 5.0
Validation loss decreased (1.055608 --> 1.052813).  Saving model ...
EarlyStopping counter: 1 out of 5.0
EarlyStopping counter: 2 out of 5.0
Validation loss decreased (1.052813 --> 1.050601).  Saving model ...
Validation loss decreased (1.050601 --> 1.047282).  Saving model ...
Validation loss decreased (1.047282 --> 1.045825).  Saving model ...
Validation loss decreased (1.045825 --> 1.044961).  Saving model ...
EarlyStopping counter: 1 out of 5.0
EarlyStopping counter: 2 out of 5.0
EarlyStopping counter: 3 out of 5.0
EarlyStopping counter: 4 out of 5.0
EarlyStopping counter: 5 out of 5.0
/localscratch/yinan.29479425.0/env/lib/python3.7/site-packages/torch/nn/functional.py:1794: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.
  warnings.warn("nn.functional.tanh is deprecated. Use torch.tanh instead.")
/localscratch/yinan.29479425.0/env/lib/python3.7/site-packages/transformers/optimization.py:155: UserWarning: This overload of add_ is deprecated:
	add_(Number alpha, Tensor other)
Consider using one of the following signatures instead:
	add_(Tensor other, *, Number alpha) (Triggered internally at  ../torch/csrc/utils/python_arg_parser.cpp:1025.)
  exp_avg.mul_(beta1).add_(1.0 - beta1, grad)
wandb: Waiting for W&B process to finish, PID 144486... (success).
wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: \ 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: | 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: / 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: \ 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: | 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: / 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: \ 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: | 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: / 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: \ 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb:                                                                                
wandb: Run history:
wandb:     e_F1 ▁▂▃▅▅▅▆▆▅▆▆▆▆▆▆▆▆▇▇▇▇▇▇▇▇▇▇▇▇███████████
wandb:   e_loss █▇▇▇▆▆▆▅▅▅▅▄▄▄▄▄▃▃▃▃▃▃▃▂▂▂▂▂▂▂▂▂▂▁▁▁▁▁▁▁
wandb:     t_F1 ▁▁▂▃▃▃▄▄▄▅▅▅▅▆▅▆▆▆▆▆▇▇▆▆▇▇▇▇▇▇▇▇▇█▇██▇▇▇
wandb:   t_loss ███▇▇▆▆▆▆▅▅▅▅▄▄▄▄▄▄▄▃▃▃▃▃▂▂▂▂▂▂▂▂▂▂▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:     e_F1 53.26684
wandb:   e_loss 1.04834
wandb:     t_F1 71.76053
wandb:   t_loss 0.76338
wandb: 
wandb: Synced 4 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Synced dry-lake-1: https://wandb.ai/yinanazhou/xl_512_bs_8_lr_1e06_es_5_lc_True_nr_True_sr_False_stem_True_lemma_False_repeat_1_fold_1/runs/2jql4ktl
wandb: Find logs at: ./wandb/run-20220325_063819-2jql4ktl/logs/debug.log
wandb: 

wandb: wandb version 0.12.11 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
2022-03-25 08:13:32.777748: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1
wandb: Tracking run with wandb version 0.12.5
wandb: Syncing run comic-glitter-1
wandb: ⭐️ View project at https://wandb.ai/yinanazhou/xl_512_bs_8_lr_1e06_es_5_lc_True_nr_True_sr_False_stem_True_lemma_False_repeat_1_fold_2
wandb: 🚀 View run at https://wandb.ai/yinanazhou/xl_512_bs_8_lr_1e06_es_5_lc_True_nr_True_sr_False_stem_True_lemma_False_repeat_1_fold_2/runs/2jx8vrfz
wandb: Run data is saved locally in /project/6002780/yinan/Thesis_MER_Lyrics/lyric-emotion/wandb/run-20220325_081330-2jx8vrfz
wandb: Run `wandb offline` to turn off syncing.

Validation loss decreased (inf --> 1.468545).  Saving model ...
Validation loss decreased (1.468545 --> 1.438164).  Saving model ...
Validation loss decreased (1.438164 --> 1.416886).  Saving model ...
Validation loss decreased (1.416886 --> 1.401214).  Saving model ...
Validation loss decreased (1.401214 --> 1.389114).  Saving model ...
Validation loss decreased (1.389114 --> 1.380200).  Saving model ...
Validation loss decreased (1.380200 --> 1.373743).  Saving model ...
Validation loss decreased (1.373743 --> 1.367668).  Saving model ...
Validation loss decreased (1.367668 --> 1.362998).  Saving model ...
Validation loss decreased (1.362998 --> 1.358395).  Saving model ...
Validation loss decreased (1.358395 --> 1.354426).  Saving model ...
Validation loss decreased (1.354426 --> 1.350429).  Saving model ...
Validation loss decreased (1.350429 --> 1.346959).  Saving model ...
Validation loss decreased (1.346959 --> 1.343504).  Saving model ...
Validation loss decreased (1.343504 --> 1.340206).  Saving model ...
Validation loss decreased (1.340206 --> 1.337053).  Saving model ...
Validation loss decreased (1.337053 --> 1.333523).  Saving model ...
Validation loss decreased (1.333523 --> 1.330163).  Saving model ...
Validation loss decreased (1.330163 --> 1.326245).  Saving model ...
Validation loss decreased (1.326245 --> 1.322351).  Saving model ...
Validation loss decreased (1.322351 --> 1.317609).  Saving model ...
Validation loss decreased (1.317609 --> 1.312957).  Saving model ...
Validation loss decreased (1.312957 --> 1.308861).  Saving model ...
Validation loss decreased (1.308861 --> 1.304073).  Saving model ...
Validation loss decreased (1.304073 --> 1.299459).  Saving model ...
Validation loss decreased (1.299459 --> 1.294521).  Saving model ...
Validation loss decreased (1.294521 --> 1.289123).  Saving model ...
Validation loss decreased (1.289123 --> 1.284102).  Saving model ...
Validation loss decreased (1.284102 --> 1.278391).  Saving model ...
Validation loss decreased (1.278391 --> 1.272612).  Saving model ...
Validation loss decreased (1.272612 --> 1.266793).  Saving model ...
Validation loss decreased (1.266793 --> 1.260045).  Saving model ...
Validation loss decreased (1.260045 --> 1.253091).  Saving model ...
Validation loss decreased (1.253091 --> 1.246534).  Saving model ...
Validation loss decreased (1.246534 --> 1.239907).  Saving model ...
Validation loss decreased (1.239907 --> 1.233338).  Saving model ...
Validation loss decreased (1.233338 --> 1.226489).  Saving model ...
Validation loss decreased (1.226489 --> 1.219570).  Saving model ...
Validation loss decreased (1.219570 --> 1.213178).  Saving model ...
Validation loss decreased (1.213178 --> 1.207076).  Saving model ...
Validation loss decreased (1.207076 --> 1.198752).  Saving model ...
Validation loss decreased (1.198752 --> 1.191419).  Saving model ...
Validation loss decreased (1.191419 --> 1.184662).  Saving model ...
Validation loss decreased (1.184662 --> 1.176593).  Saving model ...
Validation loss decreased (1.176593 --> 1.169755).  Saving model ...
Validation loss decreased (1.169755 --> 1.163896).  Saving model ...
Validation loss decreased (1.163896 --> 1.159602).  Saving model ...
Validation loss decreased (1.159602 --> 1.153488).  Saving model ...
Validation loss decreased (1.153488 --> 1.147554).  Saving model ...
Validation loss decreased (1.147554 --> 1.141636).  Saving model ...
Validation loss decreased (1.141636 --> 1.136056).  Saving model ...
Validation loss decreased (1.136056 --> 1.130602).  Saving model ...
Validation loss decreased (1.130602 --> 1.125771).  Saving model ...
Validation loss decreased (1.125771 --> 1.120723).  Saving model ...
Validation loss decreased (1.120723 --> 1.116256).  Saving model ...
Validation loss decreased (1.116256 --> 1.111827).  Saving model ...
Validation loss decreased (1.111827 --> 1.107496).  Saving model ...
Validation loss decreased (1.107496 --> 1.102443).  Saving model ...
Validation loss decreased (1.102443 --> 1.097486).  Saving model ...
Validation loss decreased (1.097486 --> 1.093337).  Saving model ...
Validation loss decreased (1.093337 --> 1.089226).  Saving model ...
Validation loss decreased (1.089226 --> 1.085088).  Saving model ...
Validation loss decreased (1.085088 --> 1.081746).  Saving model ...
Validation loss decreased (1.081746 --> 1.077686).  Saving model ...
Validation loss decreased (1.077686 --> 1.073250).  Saving model ...
Validation loss decreased (1.073250 --> 1.069005).  Saving model ...
Validation loss decreased (1.069005 --> 1.065194).  Saving model ...
Validation loss decreased (1.065194 --> 1.061704).  Saving model ...
Validation loss decreased (1.061704 --> 1.058206).  Saving model ...
Validation loss decreased (1.058206 --> 1.054423).  Saving model ...
Validation loss decreased (1.054423 --> 1.051025).  Saving model ...
Validation loss decreased (1.051025 --> 1.048177).  Saving model ...
Validation loss decreased (1.048177 --> 1.044442).  Saving model ...
Validation loss decreased (1.044442 --> 1.040637).  Saving model ...
Validation loss decreased (1.040637 --> 1.037283).  Saving model ...
Validation loss decreased (1.037283 --> 1.034653).  Saving model ...
Validation loss decreased (1.034653 --> 1.032205).  Saving model ...
Validation loss decreased (1.032205 --> 1.028283).  Saving model ...
Validation loss decreased (1.028283 --> 1.025568).  Saving model ...
Validation loss decreased (1.025568 --> 1.022447).  Saving model ...
Validation loss decreased (1.022447 --> 1.019345).  Saving model ...
Validation loss decreased (1.019345 --> 1.017071).  Saving model ...
Validation loss decreased (1.017071 --> 1.013788).  Saving model ...
Validation loss decreased (1.013788 --> 1.010920).  Saving model ...
Validation loss decreased (1.010920 --> 1.008136).  Saving model ...
Validation loss decreased (1.008136 --> 1.005089).  Saving model ...
Validation loss decreased (1.005089 --> 1.002097).  Saving model ...
Validation loss decreased (1.002097 --> 0.999929).  Saving model ...
Validation loss decreased (0.999929 --> 0.997685).  Saving model ...
Validation loss decreased (0.997685 --> 0.995457).  Saving model ...
Validation loss decreased (0.995457 --> 0.993932).  Saving model ...
Validation loss decreased (0.993932 --> 0.991381).  Saving model ...
Validation loss decreased (0.991381 --> 0.988940).  Saving model ...
Validation loss decreased (0.988940 --> 0.986837).  Saving model ...
Validation loss decreased (0.986837 --> 0.984514).  Saving model ...
Validation loss decreased (0.984514 --> 0.982254).  Saving model ...
Validation loss decreased (0.982254 --> 0.980540).  Saving model ...
Validation loss decreased (0.980540 --> 0.978972).  Saving model ...
Validation loss decreased (0.978972 --> 0.978112).  Saving model ...
Validation loss decreased (0.978112 --> 0.975524).  Saving model ...
Validation loss decreased (0.975524 --> 0.973642).  Saving model ...
Validation loss decreased (0.973642 --> 0.972115).  Saving model ...
Validation loss decreased (0.972115 --> 0.970788).  Saving model ...
Validation loss decreased (0.970788 --> 0.969501).  Saving model ...
Validation loss decreased (0.969501 --> 0.967714).  Saving model ...
Validation loss decreased (0.967714 --> 0.965491).  Saving model ...
Validation loss decreased (0.965491 --> 0.964381).  Saving model ...
Validation loss decreased (0.964381 --> 0.963455).  Saving model ...
Validation loss decreased (0.963455 --> 0.962270).  Saving model ...
Validation loss decreased (0.962270 --> 0.960425).  Saving model ...
Validation loss decreased (0.960425 --> 0.958520).  Saving model ...
Validation loss decreased (0.958520 --> 0.956867).  Saving model ...
Validation loss decreased (0.956867 --> 0.955858).  Saving model ...
Validation loss decreased (0.955858 --> 0.955073).  Saving model ...
Validation loss decreased (0.955073 --> 0.954557).  Saving model ...
Validation loss decreased (0.954557 --> 0.954012).  Saving model ...
Validation loss decreased (0.954012 --> 0.951610).  Saving model ...
Validation loss decreased (0.951610 --> 0.950383).  Saving model ...
Validation loss decreased (0.950383 --> 0.949107).  Saving model ...
Validation loss decreased (0.949107 --> 0.948277).  Saving model ...
Validation loss decreased (0.948277 --> 0.947359).  Saving model ...
Validation loss decreased (0.947359 --> 0.947045).  Saving model ...
Validation loss decreased (0.947045 --> 0.946978).  Saving model ...
Validation loss decreased (0.946978 --> 0.944862).  Saving model ...
Validation loss decreased (0.944862 --> 0.944527).  Saving model ...
Validation loss decreased (0.944527 --> 0.944020).  Saving model ...
EarlyStopping counter: 1 out of 5.0
Validation loss decreased (0.944020 --> 0.943188).  Saving model ...
Validation loss decreased (0.943188 --> 0.942801).  Saving model ...
EarlyStopping counter: 1 out of 5.0
Validation loss decreased (0.942801 --> 0.942497).  Saving model ...
Validation loss decreased (0.942497 --> 0.942334).  Saving model ...
Validation loss decreased (0.942334 --> 0.942198).  Saving model ...
Validation loss decreased (0.942198 --> 0.941533).  Saving model ...
Validation loss decreased (0.941533 --> 0.941030).  Saving model ...
EarlyStopping counter: 1 out of 5.0
Validation loss decreased (0.941030 --> 0.940947).  Saving model ...
EarlyStopping counter: 1 out of 5.0
Validation loss decreased (0.940947 --> 0.940832).  Saving model ...
EarlyStopping counter: 1 out of 5.0
Validation loss decreased (0.940832 --> 0.940632).  Saving model ...
Validation loss decreased (0.940632 --> 0.940358).  Saving model ...
Validation loss decreased (0.940358 --> 0.940282).  Saving model ...
Validation loss decreased (0.940282 --> 0.939949).  Saving model ...
EarlyStopping counter: 1 out of 5.0
Validation loss decreased (0.939949 --> 0.939715).  Saving model ...
EarlyStopping counter: 1 out of 5.0
EarlyStopping counter: 2 out of 5.0
EarlyStopping counter: 3 out of 5.0
EarlyStopping counter: 4 out of 5.0
EarlyStopping counter: 5 out of 5.0
/localscratch/yinan.29479425.0/env/lib/python3.7/site-packages/torch/nn/functional.py:1794: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.
  warnings.warn("nn.functional.tanh is deprecated. Use torch.tanh instead.")
wandb: Waiting for W&B process to finish, PID 149591... (success).
wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: \ 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: | 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: / 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: \ 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: | 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: / 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: \ 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: | 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: / 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb:                                                                                
wandb: Run history:
wandb:     e_F1 ▁▁▂▄▅▅▅▆▆▆▆▆▆▇▇▇▇▇▇▇▇▇█▇▇███████████████
wandb:   e_loss █▇▇▇▇▆▆▆▅▅▅▅▄▄▄▃▃▃▃▂▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:     t_F1 ▁▁▂▃▃▃▃▃▄▄▄▄▅▅▅▅▆▆▆▆▆▆▆▇▇▇▆▇▇▇▇▇▇▇▇▇██▇▇
wandb:   t_loss ██▇▇▇▇▇▇▆▆▆▆▅▅▅▅▅▄▄▄▄▃▃▃▃▂▃▂▂▂▂▂▂▁▂▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:     e_F1 60.01972
wandb:   e_loss 0.94131
wandb:     t_F1 70.5133
wandb:   t_loss 0.77574
wandb: 
wandb: Synced 4 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Synced comic-glitter-1: https://wandb.ai/yinanazhou/xl_512_bs_8_lr_1e06_es_5_lc_True_nr_True_sr_False_stem_True_lemma_False_repeat_1_fold_2/runs/2jx8vrfz
wandb: Find logs at: ./wandb/run-20220325_081330-2jx8vrfz/logs/debug.log
wandb: 

wandb: wandb version 0.12.11 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
2022-03-25 09:52:48.612744: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1
wandb: Tracking run with wandb version 0.12.5
wandb: Syncing run pleasant-cloud-1
wandb: ⭐️ View project at https://wandb.ai/yinanazhou/xl_512_bs_8_lr_1e06_es_5_lc_True_nr_True_sr_False_stem_True_lemma_False_repeat_2_fold_1
wandb: 🚀 View run at https://wandb.ai/yinanazhou/xl_512_bs_8_lr_1e06_es_5_lc_True_nr_True_sr_False_stem_True_lemma_False_repeat_2_fold_1/runs/24x286sb
wandb: Run data is saved locally in /project/6002780/yinan/Thesis_MER_Lyrics/lyric-emotion/wandb/run-20220325_095246-24x286sb
wandb: Run `wandb offline` to turn off syncing.

Validation loss decreased (inf --> 1.543902).  Saving model ...
Validation loss decreased (1.543902 --> 1.497465).  Saving model ...
Validation loss decreased (1.497465 --> 1.462672).  Saving model ...
Validation loss decreased (1.462672 --> 1.438406).  Saving model ...
Validation loss decreased (1.438406 --> 1.419762).  Saving model ...
Validation loss decreased (1.419762 --> 1.406059).  Saving model ...
Validation loss decreased (1.406059 --> 1.396189).  Saving model ...
Validation loss decreased (1.396189 --> 1.389781).  Saving model ...
Validation loss decreased (1.389781 --> 1.383617).  Saving model ...
Validation loss decreased (1.383617 --> 1.378204).  Saving model ...
Validation loss decreased (1.378204 --> 1.373442).  Saving model ...
Validation loss decreased (1.373442 --> 1.368169).  Saving model ...
Validation loss decreased (1.368169 --> 1.363002).  Saving model ...
Validation loss decreased (1.363002 --> 1.357746).  Saving model ...
Validation loss decreased (1.357746 --> 1.352411).  Saving model ...
Validation loss decreased (1.352411 --> 1.347457).  Saving model ...
Validation loss decreased (1.347457 --> 1.342376).  Saving model ...
Validation loss decreased (1.342376 --> 1.336864).  Saving model ...
Validation loss decreased (1.336864 --> 1.330238).  Saving model ...
Validation loss decreased (1.330238 --> 1.323176).  Saving model ...
Validation loss decreased (1.323176 --> 1.316266).  Saving model ...
Validation loss decreased (1.316266 --> 1.308337).  Saving model ...
Validation loss decreased (1.308337 --> 1.301422).  Saving model ...
Validation loss decreased (1.301422 --> 1.293737).  Saving model ...
Validation loss decreased (1.293737 --> 1.286460).  Saving model ...
Validation loss decreased (1.286460 --> 1.279634).  Saving model ...
Validation loss decreased (1.279634 --> 1.273732).  Saving model ...
Validation loss decreased (1.273732 --> 1.265928).  Saving model ...
Validation loss decreased (1.265928 --> 1.259363).  Saving model ...
Validation loss decreased (1.259363 --> 1.253182).  Saving model ...
Validation loss decreased (1.253182 --> 1.248293).  Saving model ...
Validation loss decreased (1.248293 --> 1.242501).  Saving model ...
Validation loss decreased (1.242501 --> 1.235487).  Saving model ...
Validation loss decreased (1.235487 --> 1.228694).  Saving model ...
Validation loss decreased (1.228694 --> 1.222432).  Saving model ...
Validation loss decreased (1.222432 --> 1.216968).  Saving model ...
Validation loss decreased (1.216968 --> 1.210977).  Saving model ...
Validation loss decreased (1.210977 --> 1.205165).  Saving model ...
Validation loss decreased (1.205165 --> 1.200888).  Saving model ...
Validation loss decreased (1.200888 --> 1.195730).  Saving model ...
Validation loss decreased (1.195730 --> 1.190673).  Saving model ...
Validation loss decreased (1.190673 --> 1.186515).  Saving model ...
Validation loss decreased (1.186515 --> 1.180901).  Saving model ...
Validation loss decreased (1.180901 --> 1.175997).  Saving model ...
Validation loss decreased (1.175997 --> 1.170851).  Saving model ...
Validation loss decreased (1.170851 --> 1.166840).  Saving model ...
Validation loss decreased (1.166840 --> 1.162381).  Saving model ...
Validation loss decreased (1.162381 --> 1.159056).  Saving model ...
Validation loss decreased (1.159056 --> 1.153701).  Saving model ...
Validation loss decreased (1.153701 --> 1.148857).  Saving model ...
Validation loss decreased (1.148857 --> 1.144037).  Saving model ...
Validation loss decreased (1.144037 --> 1.140154).  Saving model ...
Validation loss decreased (1.140154 --> 1.136127).  Saving model ...
Validation loss decreased (1.136127 --> 1.132044).  Saving model ...
Validation loss decreased (1.132044 --> 1.128700).  Saving model ...
Validation loss decreased (1.128700 --> 1.125905).  Saving model ...
Validation loss decreased (1.125905 --> 1.122479).  Saving model ...
Validation loss decreased (1.122479 --> 1.118570).  Saving model ...
Validation loss decreased (1.118570 --> 1.115505).  Saving model ...
Validation loss decreased (1.115505 --> 1.113002).  Saving model ...
Validation loss decreased (1.113002 --> 1.109660).  Saving model ...
Validation loss decreased (1.109660 --> 1.106319).  Saving model ...
Validation loss decreased (1.106319 --> 1.103446).  Saving model ...
Validation loss decreased (1.103446 --> 1.101107).  Saving model ...
Validation loss decreased (1.101107 --> 1.098795).  Saving model ...
Validation loss decreased (1.098795 --> 1.094862).  Saving model ...
Validation loss decreased (1.094862 --> 1.092513).  Saving model ...
Validation loss decreased (1.092513 --> 1.088340).  Saving model ...
Validation loss decreased (1.088340 --> 1.086755).  Saving model ...
Validation loss decreased (1.086755 --> 1.084117).  Saving model ...
Validation loss decreased (1.084117 --> 1.081946).  Saving model ...
Validation loss decreased (1.081946 --> 1.080804).  Saving model ...
Validation loss decreased (1.080804 --> 1.079771).  Saving model ...
Validation loss decreased (1.079771 --> 1.076023).  Saving model ...
Validation loss decreased (1.076023 --> 1.072855).  Saving model ...
Validation loss decreased (1.072855 --> 1.071637).  Saving model ...
Validation loss decreased (1.071637 --> 1.069157).  Saving model ...
Validation loss decreased (1.069157 --> 1.066536).  Saving model ...
Validation loss decreased (1.066536 --> 1.065249).  Saving model ...
Validation loss decreased (1.065249 --> 1.063220).  Saving model ...
Validation loss decreased (1.063220 --> 1.060936).  Saving model ...
Validation loss decreased (1.060936 --> 1.059437).  Saving model ...
EarlyStopping counter: 1 out of 5.0
Validation loss decreased (1.059437 --> 1.056753).  Saving model ...
Validation loss decreased (1.056753 --> 1.056246).  Saving model ...
Validation loss decreased (1.056246 --> 1.054621).  Saving model ...
Validation loss decreased (1.054621 --> 1.052936).  Saving model ...
Validation loss decreased (1.052936 --> 1.051347).  Saving model ...
Validation loss decreased (1.051347 --> 1.050019).  Saving model ...
Validation loss decreased (1.050019 --> 1.048280).  Saving model ...
Validation loss decreased (1.048280 --> 1.046853).  Saving model ...
Validation loss decreased (1.046853 --> 1.045892).  Saving model ...
Validation loss decreased (1.045892 --> 1.044574).  Saving model ...
Validation loss decreased (1.044574 --> 1.042164).  Saving model ...
Validation loss decreased (1.042164 --> 1.040618).  Saving model ...
Validation loss decreased (1.040618 --> 1.039972).  Saving model ...
EarlyStopping counter: 1 out of 5.0
Validation loss decreased (1.039972 --> 1.039487).  Saving model ...
Validation loss decreased (1.039487 --> 1.037159).  Saving model ...
Validation loss decreased (1.037159 --> 1.035553).  Saving model ...
EarlyStopping counter: 1 out of 5.0
Validation loss decreased (1.035553 --> 1.035294).  Saving model ...
Validation loss decreased (1.035294 --> 1.033942).  Saving model ...
Validation loss decreased (1.033942 --> 1.032808).  Saving model ...
Validation loss decreased (1.032808 --> 1.030440).  Saving model ...
EarlyStopping counter: 1 out of 5.0
Validation loss decreased (1.030440 --> 1.029047).  Saving model ...
Validation loss decreased (1.029047 --> 1.028427).  Saving model ...
Validation loss decreased (1.028427 --> 1.028303).  Saving model ...
EarlyStopping counter: 1 out of 5.0
Validation loss decreased (1.028303 --> 1.027267).  Saving model ...
Validation loss decreased (1.027267 --> 1.027013).  Saving model ...
Validation loss decreased (1.027013 --> 1.026862).  Saving model ...
Validation loss decreased (1.026862 --> 1.025269).  Saving model ...
Validation loss decreased (1.025269 --> 1.024720).  Saving model ...
Validation loss decreased (1.024720 --> 1.024664).  Saving model ...
Validation loss decreased (1.024664 --> 1.024444).  Saving model ...
EarlyStopping counter: 1 out of 5.0
EarlyStopping counter: 2 out of 5.0
EarlyStopping counter: 3 out of 5.0
EarlyStopping counter: 4 out of 5.0
EarlyStopping counter: 5 out of 5.0
/localscratch/yinan.29479425.0/env/lib/python3.7/site-packages/torch/nn/functional.py:1794: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.
  warnings.warn("nn.functional.tanh is deprecated. Use torch.tanh instead.")
wandb: Waiting for W&B process to finish, PID 154886... (success).
wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: \ 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: | 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: / 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: \ 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: | 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: / 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: \ 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: | 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: / 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: \ 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: | 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb:                                                                                
wandb: Run history:
wandb:     e_F1 ▁▂▃▄▄▄▄▅▅▆▆▆▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇█████████████
wandb:   e_loss █▇▆▆▆▅▅▅▅▄▄▄▃▃▃▃▃▃▂▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:     t_F1 ▁▂▃▃▃▄▄▄▄▅▅▅▅▅▆▆▆▆▆▆▆▇▇▇▇▇█▇▇█▇▇▇▇▇█████
wandb:   t_loss █▇▆▆▆▆▆▆▆▅▅▅▅▄▄▄▄▄▄▄▃▃▃▃▃▂▂▂▂▂▂▂▂▁▂▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:     e_F1 54.97314
wandb:   e_loss 1.02563
wandb:     t_F1 66.22207
wandb:   t_loss 0.82918
wandb: 
wandb: Synced 4 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Synced pleasant-cloud-1: https://wandb.ai/yinanazhou/xl_512_bs_8_lr_1e06_es_5_lc_True_nr_True_sr_False_stem_True_lemma_False_repeat_2_fold_1/runs/24x286sb
wandb: Find logs at: ./wandb/run-20220325_095246-24x286sb/logs/debug.log
wandb: 

wandb: wandb version 0.12.11 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
2022-03-25 11:09:17.422554: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1
wandb: Tracking run with wandb version 0.12.5
wandb: Syncing run vocal-blaze-1
wandb: ⭐️ View project at https://wandb.ai/yinanazhou/xl_512_bs_8_lr_1e06_es_5_lc_True_nr_True_sr_False_stem_True_lemma_False_repeat_2_fold_2
wandb: 🚀 View run at https://wandb.ai/yinanazhou/xl_512_bs_8_lr_1e06_es_5_lc_True_nr_True_sr_False_stem_True_lemma_False_repeat_2_fold_2/runs/30kid0zz
wandb: Run data is saved locally in /project/6002780/yinan/Thesis_MER_Lyrics/lyric-emotion/wandb/run-20220325_110915-30kid0zz
wandb: Run `wandb offline` to turn off syncing.

Validation loss decreased (inf --> 1.397345).  Saving model ...
Validation loss decreased (1.397345 --> 1.392272).  Saving model ...
Validation loss decreased (1.392272 --> 1.388381).  Saving model ...
Validation loss decreased (1.388381 --> 1.384834).  Saving model ...
Validation loss decreased (1.384834 --> 1.381693).  Saving model ...
Validation loss decreased (1.381693 --> 1.378735).  Saving model ...
Validation loss decreased (1.378735 --> 1.375477).  Saving model ...
Validation loss decreased (1.375477 --> 1.372748).  Saving model ...
Validation loss decreased (1.372748 --> 1.369977).  Saving model ...
Validation loss decreased (1.369977 --> 1.367240).  Saving model ...
Validation loss decreased (1.367240 --> 1.364685).  Saving model ...
Validation loss decreased (1.364685 --> 1.361829).  Saving model ...
Validation loss decreased (1.361829 --> 1.359000).  Saving model ...
Validation loss decreased (1.359000 --> 1.356022).  Saving model ...
Validation loss decreased (1.356022 --> 1.353011).  Saving model ...
Validation loss decreased (1.353011 --> 1.349899).  Saving model ...
Validation loss decreased (1.349899 --> 1.346743).  Saving model ...
Validation loss decreased (1.346743 --> 1.343698).  Saving model ...
Validation loss decreased (1.343698 --> 1.340394).  Saving model ...
Validation loss decreased (1.340394 --> 1.336841).  Saving model ...
Validation loss decreased (1.336841 --> 1.333079).  Saving model ...
Validation loss decreased (1.333079 --> 1.328926).  Saving model ...
Validation loss decreased (1.328926 --> 1.324845).  Saving model ...
Validation loss decreased (1.324845 --> 1.320613).  Saving model ...
Validation loss decreased (1.320613 --> 1.316480).  Saving model ...
Validation loss decreased (1.316480 --> 1.311648).  Saving model ...
Validation loss decreased (1.311648 --> 1.306961).  Saving model ...
Validation loss decreased (1.306961 --> 1.302663).  Saving model ...
Validation loss decreased (1.302663 --> 1.297273).  Saving model ...
Validation loss decreased (1.297273 --> 1.292232).  Saving model ...
Validation loss decreased (1.292232 --> 1.287389).  Saving model ...
Validation loss decreased (1.287389 --> 1.281938).  Saving model ...
Validation loss decreased (1.281938 --> 1.276099).  Saving model ...
Validation loss decreased (1.276099 --> 1.270398).  Saving model ...
Validation loss decreased (1.270398 --> 1.265679).  Saving model ...
Validation loss decreased (1.265679 --> 1.259940).  Saving model ...
Validation loss decreased (1.259940 --> 1.255236).  Saving model ...
Validation loss decreased (1.255236 --> 1.249165).  Saving model ...
Validation loss decreased (1.249165 --> 1.244984).  Saving model ...
Validation loss decreased (1.244984 --> 1.240166).  Saving model ...
Validation loss decreased (1.240166 --> 1.234265).  Saving model ...
Validation loss decreased (1.234265 --> 1.227799).  Saving model ...
Validation loss decreased (1.227799 --> 1.222158).  Saving model ...
Validation loss decreased (1.222158 --> 1.218582).  Saving model ...
Validation loss decreased (1.218582 --> 1.214146).  Saving model ...
Validation loss decreased (1.214146 --> 1.208881).  Saving model ...
Validation loss decreased (1.208881 --> 1.205775).  Saving model ...
Validation loss decreased (1.205775 --> 1.200948).  Saving model ...
Validation loss decreased (1.200948 --> 1.196440).  Saving model ...
Validation loss decreased (1.196440 --> 1.191664).  Saving model ...
Validation loss decreased (1.191664 --> 1.186743).  Saving model ...
Validation loss decreased (1.186743 --> 1.183034).  Saving model ...
Validation loss decreased (1.183034 --> 1.177999).  Saving model ...
Validation loss decreased (1.177999 --> 1.174006).  Saving model ...
Validation loss decreased (1.174006 --> 1.173029).  Saving model ...
Validation loss decreased (1.173029 --> 1.168634).  Saving model ...
Validation loss decreased (1.168634 --> 1.168360).  Saving model ...
Validation loss decreased (1.168360 --> 1.162183).  Saving model ...
Validation loss decreased (1.162183 --> 1.157983).  Saving model ...
Validation loss decreased (1.157983 --> 1.155699).  Saving model ...
Validation loss decreased (1.155699 --> 1.155291).  Saving model ...
Validation loss decreased (1.155291 --> 1.152720).  Saving model ...
Validation loss decreased (1.152720 --> 1.145661).  Saving model ...
Validation loss decreased (1.145661 --> 1.143652).  Saving model ...
Validation loss decreased (1.143652 --> 1.137937).  Saving model ...
Validation loss decreased (1.137937 --> 1.133664).  Saving model ...
Validation loss decreased (1.133664 --> 1.128534).  Saving model ...
Validation loss decreased (1.128534 --> 1.126621).  Saving model ...
Validation loss decreased (1.126621 --> 1.122511).  Saving model ...
Validation loss decreased (1.122511 --> 1.122211).  Saving model ...
Validation loss decreased (1.122211 --> 1.119054).  Saving model ...
Validation loss decreased (1.119054 --> 1.116500).  Saving model ...
Validation loss decreased (1.116500 --> 1.110383).  Saving model ...
EarlyStopping counter: 1 out of 5.0
Validation loss decreased (1.110383 --> 1.107609).  Saving model ...
Validation loss decreased (1.107609 --> 1.103542).  Saving model ...
Validation loss decreased (1.103542 --> 1.098008).  Saving model ...
Validation loss decreased (1.098008 --> 1.097121).  Saving model ...
Validation loss decreased (1.097121 --> 1.094178).  Saving model ...
Validation loss decreased (1.094178 --> 1.093364).  Saving model ...
Validation loss decreased (1.093364 --> 1.088586).  Saving model ...
EarlyStopping counter: 1 out of 5.0
Validation loss decreased (1.088586 --> 1.085120).  Saving model ...
Validation loss decreased (1.085120 --> 1.082227).  Saving model ...
Validation loss decreased (1.082227 --> 1.079198).  Saving model ...
Validation loss decreased (1.079198 --> 1.077686).  Saving model ...
Validation loss decreased (1.077686 --> 1.077561).  Saving model ...
Validation loss decreased (1.077561 --> 1.072196).  Saving model ...
Validation loss decreased (1.072196 --> 1.069511).  Saving model ...
Validation loss decreased (1.069511 --> 1.068091).  Saving model ...
Validation loss decreased (1.068091 --> 1.061811).  Saving model ...
EarlyStopping counter: 1 out of 5.0
Validation loss decreased (1.061811 --> 1.055539).  Saving model ...
Validation loss decreased (1.055539 --> 1.053722).  Saving model ...
EarlyStopping counter: 1 out of 5.0
Validation loss decreased (1.053722 --> 1.053410).  Saving model ...
Validation loss decreased (1.053410 --> 1.052469).  Saving model ...
Validation loss decreased (1.052469 --> 1.049307).  Saving model ...
EarlyStopping counter: 1 out of 5.0
EarlyStopping counter: 2 out of 5.0
Validation loss decreased (1.049307 --> 1.046318).  Saving model ...
Validation loss decreased (1.046318 --> 1.043018).  Saving model ...
Validation loss decreased (1.043018 --> 1.041842).  Saving model ...
Validation loss decreased (1.041842 --> 1.036910).  Saving model ...
EarlyStopping counter: 1 out of 5.0
Validation loss decreased (1.036910 --> 1.035513).  Saving model ...
Validation loss decreased (1.035513 --> 1.030968).  Saving model ...
EarlyStopping counter: 1 out of 5.0
Validation loss decreased (1.030968 --> 1.029645).  Saving model ...
Validation loss decreased (1.029645 --> 1.027732).  Saving model ...
Validation loss decreased (1.027732 --> 1.026490).  Saving model ...
Validation loss decreased (1.026490 --> 1.022241).  Saving model ...
EarlyStopping counter: 1 out of 5.0
EarlyStopping counter: 2 out of 5.0
EarlyStopping counter: 3 out of 5.0
Validation loss decreased (1.022241 --> 1.022062).  Saving model ...
Validation loss decreased (1.022062 --> 1.018994).  Saving model ...
Validation loss decreased (1.018994 --> 1.017566).  Saving model ...
Validation loss decreased (1.017566 --> 1.015263).  Saving model ...
Validation loss decreased (1.015263 --> 1.013920).  Saving model ...
EarlyStopping counter: 1 out of 5.0
Validation loss decreased (1.013920 --> 1.011449).  Saving model ...
Validation loss decreased (1.011449 --> 1.010965).  Saving model ...
Validation loss decreased (1.010965 --> 1.010598).  Saving model ...
EarlyStopping counter: 1 out of 5.0
EarlyStopping counter: 2 out of 5.0
Validation loss decreased (1.010598 --> 1.010480).  Saving model ...
Validation loss decreased (1.010480 --> 1.006525).  Saving model ...
Validation loss decreased (1.006525 --> 1.004504).  Saving model ...
Validation loss decreased (1.004504 --> 1.003154).  Saving model ...
Validation loss decreased (1.003154 --> 1.000571).  Saving model ...
Validation loss decreased (1.000571 --> 1.000273).  Saving model ...
Validation loss decreased (1.000273 --> 0.998915).  Saving model ...
Validation loss decreased (0.998915 --> 0.995987).  Saving model ...
EarlyStopping counter: 1 out of 5.0
EarlyStopping counter: 2 out of 5.0
EarlyStopping counter: 3 out of 5.0
EarlyStopping counter: 4 out of 5.0
EarlyStopping counter: 5 out of 5.0
/localscratch/yinan.29479425.0/env/lib/python3.7/site-packages/torch/nn/functional.py:1794: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.
  warnings.warn("nn.functional.tanh is deprecated. Use torch.tanh instead.")
wandb: Waiting for W&B process to finish, PID 158992... (success).
wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: \ 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: | 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: / 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: \ 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: | 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: / 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb:                                                                                
wandb: Run history:
wandb:     e_F1 ▁▁▂▃▃▃▄▄▄▅▅▅▆▆▆▆▆▆▇▇▇▇▇▇▇▇▇▇▇▇▇█████████
wandb:   e_loss ███▇▇▇▇▇▆▆▆▅▅▅▄▄▄▄▄▃▃▃▃▃▃▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁
wandb:     t_F1 ▂▁▂▂▂▂▃▄▅▄▄▅▄▆▆▅▅▆▆▆▆▇▆▆▇▇▇█▇▇█▇█▇██▇███
wandb:   t_loss ████▇▇▇▇▇▆▆▆▆▅▅▅▅▅▄▄▄▄▄▄▄▃▃▂▃▂▂▂▂▂▂▂▂▂▂▁
wandb: 
wandb: Run summary:
wandb:     e_F1 55.83674
wandb:   e_loss 0.99668
wandb:     t_F1 65.98418
wandb:   t_loss 0.84217
wandb: 
wandb: Synced 4 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Synced vocal-blaze-1: https://wandb.ai/yinanazhou/xl_512_bs_8_lr_1e06_es_5_lc_True_nr_True_sr_False_stem_True_lemma_False_repeat_2_fold_2/runs/30kid0zz
wandb: Find logs at: ./wandb/run-20220325_110915-30kid0zz/logs/debug.log
wandb: 

wandb: wandb version 0.12.11 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
2022-03-25 12:39:36.466354: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1
wandb: Tracking run with wandb version 0.12.5
wandb: Syncing run true-wind-1
wandb: ⭐️ View project at https://wandb.ai/yinanazhou/xl_512_bs_8_lr_1e06_es_5_lc_True_nr_True_sr_False_stem_True_lemma_False_repeat_3_fold_1
wandb: 🚀 View run at https://wandb.ai/yinanazhou/xl_512_bs_8_lr_1e06_es_5_lc_True_nr_True_sr_False_stem_True_lemma_False_repeat_3_fold_1/runs/1kpnjrvl
wandb: Run data is saved locally in /project/6002780/yinan/Thesis_MER_Lyrics/lyric-emotion/wandb/run-20220325_123934-1kpnjrvl
wandb: Run `wandb offline` to turn off syncing.

Validation loss decreased (inf --> 1.456131).  Saving model ...
Validation loss decreased (1.456131 --> 1.431545).  Saving model ...
Validation loss decreased (1.431545 --> 1.416127).  Saving model ...
Validation loss decreased (1.416127 --> 1.405902).  Saving model ...
Validation loss decreased (1.405902 --> 1.398182).  Saving model ...
Validation loss decreased (1.398182 --> 1.392211).  Saving model ...
Validation loss decreased (1.392211 --> 1.387555).  Saving model ...
Validation loss decreased (1.387555 --> 1.383844).  Saving model ...
Validation loss decreased (1.383844 --> 1.380463).  Saving model ...
Validation loss decreased (1.380463 --> 1.377322).  Saving model ...
Validation loss decreased (1.377322 --> 1.374029).  Saving model ...
Validation loss decreased (1.374029 --> 1.370916).  Saving model ...
Validation loss decreased (1.370916 --> 1.367917).  Saving model ...
Validation loss decreased (1.367917 --> 1.364519).  Saving model ...
Validation loss decreased (1.364519 --> 1.361245).  Saving model ...
Validation loss decreased (1.361245 --> 1.357806).  Saving model ...
Validation loss decreased (1.357806 --> 1.354278).  Saving model ...
Validation loss decreased (1.354278 --> 1.350774).  Saving model ...
Validation loss decreased (1.350774 --> 1.347286).  Saving model ...
Validation loss decreased (1.347286 --> 1.342931).  Saving model ...
Validation loss decreased (1.342931 --> 1.339343).  Saving model ...
Validation loss decreased (1.339343 --> 1.334790).  Saving model ...
Validation loss decreased (1.334790 --> 1.330623).  Saving model ...
Validation loss decreased (1.330623 --> 1.325732).  Saving model ...
Validation loss decreased (1.325732 --> 1.321408).  Saving model ...
Validation loss decreased (1.321408 --> 1.315980).  Saving model ...
Validation loss decreased (1.315980 --> 1.309516).  Saving model ...
Validation loss decreased (1.309516 --> 1.303822).  Saving model ...
Validation loss decreased (1.303822 --> 1.298274).  Saving model ...
Validation loss decreased (1.298274 --> 1.290925).  Saving model ...
Validation loss decreased (1.290925 --> 1.284061).  Saving model ...
Validation loss decreased (1.284061 --> 1.277628).  Saving model ...
Validation loss decreased (1.277628 --> 1.270585).  Saving model ...
Validation loss decreased (1.270585 --> 1.264703).  Saving model ...
Validation loss decreased (1.264703 --> 1.258354).  Saving model ...
Validation loss decreased (1.258354 --> 1.252422).  Saving model ...
Validation loss decreased (1.252422 --> 1.246190).  Saving model ...
Validation loss decreased (1.246190 --> 1.239399).  Saving model ...
Validation loss decreased (1.239399 --> 1.233042).  Saving model ...
Validation loss decreased (1.233042 --> 1.227200).  Saving model ...
Validation loss decreased (1.227200 --> 1.220773).  Saving model ...
Validation loss decreased (1.220773 --> 1.214741).  Saving model ...
Validation loss decreased (1.214741 --> 1.208990).  Saving model ...
Validation loss decreased (1.208990 --> 1.203987).  Saving model ...
Validation loss decreased (1.203987 --> 1.198684).  Saving model ...
Validation loss decreased (1.198684 --> 1.193963).  Saving model ...
Validation loss decreased (1.193963 --> 1.189114).  Saving model ...
Validation loss decreased (1.189114 --> 1.184810).  Saving model ...
Validation loss decreased (1.184810 --> 1.178107).  Saving model ...
Validation loss decreased (1.178107 --> 1.173221).  Saving model ...
Validation loss decreased (1.173221 --> 1.168579).  Saving model ...
Validation loss decreased (1.168579 --> 1.163599).  Saving model ...
Validation loss decreased (1.163599 --> 1.160241).  Saving model ...
Validation loss decreased (1.160241 --> 1.154607).  Saving model ...
Validation loss decreased (1.154607 --> 1.150154).  Saving model ...
Validation loss decreased (1.150154 --> 1.145941).  Saving model ...
Validation loss decreased (1.145941 --> 1.142028).  Saving model ...
Validation loss decreased (1.142028 --> 1.138574).  Saving model ...
Validation loss decreased (1.138574 --> 1.131923).  Saving model ...
Validation loss decreased (1.131923 --> 1.128174).  Saving model ...
Validation loss decreased (1.128174 --> 1.125930).  Saving model ...
Validation loss decreased (1.125930 --> 1.121122).  Saving model ...
Validation loss decreased (1.121122 --> 1.119283).  Saving model ...
Validation loss decreased (1.119283 --> 1.115602).  Saving model ...
Validation loss decreased (1.115602 --> 1.110015).  Saving model ...
Validation loss decreased (1.110015 --> 1.105023).  Saving model ...
EarlyStopping counter: 1 out of 5.0
Validation loss decreased (1.105023 --> 1.102720).  Saving model ...
Validation loss decreased (1.102720 --> 1.100775).  Saving model ...
Validation loss decreased (1.100775 --> 1.094856).  Saving model ...
Validation loss decreased (1.094856 --> 1.089666).  Saving model ...
Validation loss decreased (1.089666 --> 1.086159).  Saving model ...
Validation loss decreased (1.086159 --> 1.084098).  Saving model ...
Validation loss decreased (1.084098 --> 1.082383).  Saving model ...
Validation loss decreased (1.082383 --> 1.079567).  Saving model ...
Validation loss decreased (1.079567 --> 1.075364).  Saving model ...
Validation loss decreased (1.075364 --> 1.072329).  Saving model ...
Validation loss decreased (1.072329 --> 1.071975).  Saving model ...
Validation loss decreased (1.071975 --> 1.069137).  Saving model ...
EarlyStopping counter: 1 out of 5.0
Validation loss decreased (1.069137 --> 1.066794).  Saving model ...
Validation loss decreased (1.066794 --> 1.063838).  Saving model ...
Validation loss decreased (1.063838 --> 1.059701).  Saving model ...
Validation loss decreased (1.059701 --> 1.057749).  Saving model ...
Validation loss decreased (1.057749 --> 1.055637).  Saving model ...
Validation loss decreased (1.055637 --> 1.053052).  Saving model ...
Validation loss decreased (1.053052 --> 1.049525).  Saving model ...
Validation loss decreased (1.049525 --> 1.048239).  Saving model ...
Validation loss decreased (1.048239 --> 1.044840).  Saving model ...
Validation loss decreased (1.044840 --> 1.043600).  Saving model ...
Validation loss decreased (1.043600 --> 1.039247).  Saving model ...
Validation loss decreased (1.039247 --> 1.038629).  Saving model ...
Validation loss decreased (1.038629 --> 1.035133).  Saving model ...
EarlyStopping counter: 1 out of 5.0
EarlyStopping counter: 2 out of 5.0
Validation loss decreased (1.035133 --> 1.034460).  Saving model ...
Validation loss decreased (1.034460 --> 1.031621).  Saving model ...
Validation loss decreased (1.031621 --> 1.030637).  Saving model ...
EarlyStopping counter: 1 out of 5.0
Validation loss decreased (1.030637 --> 1.029894).  Saving model ...
Validation loss decreased (1.029894 --> 1.028941).  Saving model ...
Validation loss decreased (1.028941 --> 1.024867).  Saving model ...
Validation loss decreased (1.024867 --> 1.020102).  Saving model ...
EarlyStopping counter: 1 out of 5.0
Validation loss decreased (1.020102 --> 1.019925).  Saving model ...
Validation loss decreased (1.019925 --> 1.018811).  Saving model ...
EarlyStopping counter: 1 out of 5.0
Validation loss decreased (1.018811 --> 1.018639).  Saving model ...
EarlyStopping counter: 1 out of 5.0
Validation loss decreased (1.018639 --> 1.016573).  Saving model ...
Validation loss decreased (1.016573 --> 1.016036).  Saving model ...
EarlyStopping counter: 1 out of 5.0
Validation loss decreased (1.016036 --> 1.013738).  Saving model ...
Validation loss decreased (1.013738 --> 1.009542).  Saving model ...
Validation loss decreased (1.009542 --> 1.007154).  Saving model ...
EarlyStopping counter: 1 out of 5.0
EarlyStopping counter: 2 out of 5.0
Validation loss decreased (1.007154 --> 1.005951).  Saving model ...
EarlyStopping counter: 1 out of 5.0
Validation loss decreased (1.005951 --> 1.004416).  Saving model ...
Validation loss decreased (1.004416 --> 1.003350).  Saving model ...
EarlyStopping counter: 1 out of 5.0
EarlyStopping counter: 2 out of 5.0
EarlyStopping counter: 3 out of 5.0
Validation loss decreased (1.003350 --> 1.002658).  Saving model ...
EarlyStopping counter: 1 out of 5.0
Validation loss decreased (1.002658 --> 1.001580).  Saving model ...
Validation loss decreased (1.001580 --> 0.999049).  Saving model ...
EarlyStopping counter: 1 out of 5.0
EarlyStopping counter: 2 out of 5.0
Validation loss decreased (0.999049 --> 0.998680).  Saving model ...
EarlyStopping counter: 1 out of 5.0
Validation loss decreased (0.998680 --> 0.997529).  Saving model ...
Validation loss decreased (0.997529 --> 0.993961).  Saving model ...
EarlyStopping counter: 1 out of 5.0
EarlyStopping counter: 2 out of 5.0
EarlyStopping counter: 3 out of 5.0
EarlyStopping counter: 4 out of 5.0
EarlyStopping counter: 5 out of 5.0
/localscratch/yinan.29479425.0/env/lib/python3.7/site-packages/torch/nn/functional.py:1794: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.
  warnings.warn("nn.functional.tanh is deprecated. Use torch.tanh instead.")
wandb: Waiting for W&B process to finish, PID 163821... (success).
wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: \ 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: | 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: / 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: \ 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: | 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: / 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: \ 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: | 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: / 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb:                                                                                
wandb: Run history:
wandb:     e_F1 ▁▁▃▄▄▅▅▆▆▆▆▆▇▇▇▇▇▇▇▇▇▇▇▇████████████████
wandb:   e_loss ██▇▇▇▇▆▆▆▆▅▅▅▄▄▄▃▃▃▃▃▂▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁
wandb:     t_F1 ▁▁▂▃▃▃▄▄▃▄▅▅▅▅▆▆▅▆▆▇▆▆▇▇▆▇▇▇▇▇██▇▇██████
wandb:   t_loss ██▇▇▇▇▇▆▇▆▆▅▅▅▅▅▅▄▄▃▄▄▃▃▃▃▃▂▂▂▂▂▂▂▂▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:     e_F1 55.31262
wandb:   e_loss 0.99798
wandb:     t_F1 67.75775
wandb:   t_loss 0.80382
wandb: 
wandb: Synced 4 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Synced true-wind-1: https://wandb.ai/yinanazhou/xl_512_bs_8_lr_1e06_es_5_lc_True_nr_True_sr_False_stem_True_lemma_False_repeat_3_fold_1/runs/1kpnjrvl
wandb: Find logs at: ./wandb/run-20220325_123934-1kpnjrvl/logs/debug.log
wandb: 

wandb: wandb version 0.12.11 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
2022-03-25 14:11:12.748844: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1
wandb: Tracking run with wandb version 0.12.5
wandb: Syncing run eager-moon-1
wandb: ⭐️ View project at https://wandb.ai/yinanazhou/xl_512_bs_8_lr_1e06_es_5_lc_True_nr_True_sr_False_stem_True_lemma_False_repeat_3_fold_2
wandb: 🚀 View run at https://wandb.ai/yinanazhou/xl_512_bs_8_lr_1e06_es_5_lc_True_nr_True_sr_False_stem_True_lemma_False_repeat_3_fold_2/runs/z8z5ebcr
wandb: Run data is saved locally in /project/6002780/yinan/Thesis_MER_Lyrics/lyric-emotion/wandb/run-20220325_141110-z8z5ebcr
wandb: Run `wandb offline` to turn off syncing.

Validation loss decreased (inf --> 1.496085).  Saving model ...
Validation loss decreased (1.496085 --> 1.471633).  Saving model ...
Validation loss decreased (1.471633 --> 1.452363).  Saving model ...
Validation loss decreased (1.452363 --> 1.437033).  Saving model ...
Validation loss decreased (1.437033 --> 1.426535).  Saving model ...
Validation loss decreased (1.426535 --> 1.418073).  Saving model ...
Validation loss decreased (1.418073 --> 1.411073).  Saving model ...
Validation loss decreased (1.411073 --> 1.404766).  Saving model ...
Validation loss decreased (1.404766 --> 1.399969).  Saving model ...
Validation loss decreased (1.399969 --> 1.395607).  Saving model ...
Validation loss decreased (1.395607 --> 1.391056).  Saving model ...
Validation loss decreased (1.391056 --> 1.386944).  Saving model ...
Validation loss decreased (1.386944 --> 1.383352).  Saving model ...
Validation loss decreased (1.383352 --> 1.379805).  Saving model ...
Validation loss decreased (1.379805 --> 1.375534).  Saving model ...
Validation loss decreased (1.375534 --> 1.371713).  Saving model ...
Validation loss decreased (1.371713 --> 1.367549).  Saving model ...
Validation loss decreased (1.367549 --> 1.363408).  Saving model ...
Validation loss decreased (1.363408 --> 1.359142).  Saving model ...
Validation loss decreased (1.359142 --> 1.355018).  Saving model ...
Validation loss decreased (1.355018 --> 1.350061).  Saving model ...
Validation loss decreased (1.350061 --> 1.344437).  Saving model ...
Validation loss decreased (1.344437 --> 1.338698).  Saving model ...
Validation loss decreased (1.338698 --> 1.332504).  Saving model ...
Validation loss decreased (1.332504 --> 1.326912).  Saving model ...
Validation loss decreased (1.326912 --> 1.320936).  Saving model ...
Validation loss decreased (1.320936 --> 1.315937).  Saving model ...
Validation loss decreased (1.315937 --> 1.309222).  Saving model ...
Validation loss decreased (1.309222 --> 1.304889).  Saving model ...
Validation loss decreased (1.304889 --> 1.298929).  Saving model ...
Validation loss decreased (1.298929 --> 1.293297).  Saving model ...
Validation loss decreased (1.293297 --> 1.286605).  Saving model ...
Validation loss decreased (1.286605 --> 1.280555).  Saving model ...
Validation loss decreased (1.280555 --> 1.274511).  Saving model ...
Validation loss decreased (1.274511 --> 1.268867).  Saving model ...
Validation loss decreased (1.268867 --> 1.262340).  Saving model ...
Validation loss decreased (1.262340 --> 1.256236).  Saving model ...
Validation loss decreased (1.256236 --> 1.251498).  Saving model ...
Validation loss decreased (1.251498 --> 1.244649).  Saving model ...
Validation loss decreased (1.244649 --> 1.239041).  Saving model ...
Validation loss decreased (1.239041 --> 1.233219).  Saving model ...
Validation loss decreased (1.233219 --> 1.227243).  Saving model ...
Validation loss decreased (1.227243 --> 1.221363).  Saving model ...
Validation loss decreased (1.221363 --> 1.215411).  Saving model ...
Validation loss decreased (1.215411 --> 1.209413).  Saving model ...
Validation loss decreased (1.209413 --> 1.204312).  Saving model ...
Validation loss decreased (1.204312 --> 1.199533).  Saving model ...
Validation loss decreased (1.199533 --> 1.194710).  Saving model ...
Validation loss decreased (1.194710 --> 1.188781).  Saving model ...
Validation loss decreased (1.188781 --> 1.182800).  Saving model ...
Validation loss decreased (1.182800 --> 1.177950).  Saving model ...
Validation loss decreased (1.177950 --> 1.172995).  Saving model ...
Validation loss decreased (1.172995 --> 1.169018).  Saving model ...
Validation loss decreased (1.169018 --> 1.165132).  Saving model ...
Validation loss decreased (1.165132 --> 1.161625).  Saving model ...
Validation loss decreased (1.161625 --> 1.156042).  Saving model ...
Validation loss decreased (1.156042 --> 1.149135).  Saving model ...
Validation loss decreased (1.149135 --> 1.144055).  Saving model ...
Validation loss decreased (1.144055 --> 1.140782).  Saving model ...
Validation loss decreased (1.140782 --> 1.137334).  Saving model ...
Validation loss decreased (1.137334 --> 1.133277).  Saving model ...
Validation loss decreased (1.133277 --> 1.129095).  Saving model ...
Validation loss decreased (1.129095 --> 1.125529).  Saving model ...
Validation loss decreased (1.125529 --> 1.124267).  Saving model ...
Validation loss decreased (1.124267 --> 1.119965).  Saving model ...
Validation loss decreased (1.119965 --> 1.115664).  Saving model ...
Validation loss decreased (1.115664 --> 1.110468).  Saving model ...
Validation loss decreased (1.110468 --> 1.108353).  Saving model ...
Validation loss decreased (1.108353 --> 1.105355).  Saving model ...
Validation loss decreased (1.105355 --> 1.100382).  Saving model ...
Validation loss decreased (1.100382 --> 1.096846).  Saving model ...
Validation loss decreased (1.096846 --> 1.094868).  Saving model ...
Validation loss decreased (1.094868 --> 1.091131).  Saving model ...
Validation loss decreased (1.091131 --> 1.087506).  Saving model ...
Validation loss decreased (1.087506 --> 1.084065).  Saving model ...
Validation loss decreased (1.084065 --> 1.080005).  Saving model ...
Validation loss decreased (1.080005 --> 1.075800).  Saving model ...
Validation loss decreased (1.075800 --> 1.073014).  Saving model ...
Validation loss decreased (1.073014 --> 1.071815).  Saving model ...
Validation loss decreased (1.071815 --> 1.069854).  Saving model ...
Validation loss decreased (1.069854 --> 1.069138).  Saving model ...
Validation loss decreased (1.069138 --> 1.066288).  Saving model ...
Validation loss decreased (1.066288 --> 1.064025).  Saving model ...
Validation loss decreased (1.064025 --> 1.063029).  Saving model ...
Validation loss decreased (1.063029 --> 1.057910).  Saving model ...
Validation loss decreased (1.057910 --> 1.056952).  Saving model ...
Validation loss decreased (1.056952 --> 1.055021).  Saving model ...
Validation loss decreased (1.055021 --> 1.050857).  Saving model ...
Validation loss decreased (1.050857 --> 1.048450).  Saving model ...
Validation loss decreased (1.048450 --> 1.046968).  Saving model ...
Validation loss decreased (1.046968 --> 1.044286).  Saving model ...
Validation loss decreased (1.044286 --> 1.042492).  Saving model ...
Validation loss decreased (1.042492 --> 1.040551).  Saving model ...
Validation loss decreased (1.040551 --> 1.039165).  Saving model ...
Validation loss decreased (1.039165 --> 1.037487).  Saving model ...
Validation loss decreased (1.037487 --> 1.035450).  Saving model ...
Validation loss decreased (1.035450 --> 1.032526).  Saving model ...
Validation loss decreased (1.032526 --> 1.030923).  Saving model ...
Validation loss decreased (1.030923 --> 1.027615).  Saving model ...
Validation loss decreased (1.027615 --> 1.025713).  Saving model ...
Validation loss decreased (1.025713 --> 1.023299).  Saving model ...
Validation loss decreased (1.023299 --> 1.022984).  Saving model ...
Validation loss decreased (1.022984 --> 1.022488).  Saving model ...
Validation loss decreased (1.022488 --> 1.019260).  Saving model ...
Validation loss decreased (1.019260 --> 1.017529).  Saving model ...
Validation loss decreased (1.017529 --> 1.015421).  Saving model ...
Validation loss decreased (1.015421 --> 1.014209).  Saving model ...
Validation loss decreased (1.014209 --> 1.010140).  Saving model ...
Validation loss decreased (1.010140 --> 1.009091).  Saving model ...
Validation loss decreased (1.009091 --> 1.007318).  Saving model ...
Validation loss decreased (1.007318 --> 1.006046).  Saving model ...
Validation loss decreased (1.006046 --> 1.004987).  Saving model ...
Validation loss decreased (1.004987 --> 1.004968).  Saving model ...
Validation loss decreased (1.004968 --> 1.002325).  Saving model ...
EarlyStopping counter: 1 out of 5.0
Validation loss decreased (1.002325 --> 1.001566).  Saving model ...
Validation loss decreased (1.001566 --> 1.000898).  Saving model ...
Validation loss decreased (1.000898 --> 0.999242).  Saving model ...
Validation loss decreased (0.999242 --> 0.998146).  Saving model ...
Validation loss decreased (0.998146 --> 0.996001).  Saving model ...
EarlyStopping counter: 1 out of 5.0
Validation loss decreased (0.996001 --> 0.995413).  Saving model ...
Validation loss decreased (0.995413 --> 0.994107).  Saving model ...
Validation loss decreased (0.994107 --> 0.992453).  Saving model ...
Validation loss decreased (0.992453 --> 0.991985).  Saving model ...
Validation loss decreased (0.991985 --> 0.989451).  Saving model ...
Validation loss decreased (0.989451 --> 0.987993).  Saving model ...
Validation loss decreased (0.987993 --> 0.986136).  Saving model ...
EarlyStopping counter: 1 out of 5.0
EarlyStopping counter: 2 out of 5.0
EarlyStopping counter: 3 out of 5.0
EarlyStopping counter: 4 out of 5.0
Validation loss decreased (0.986136 --> 0.985871).  Saving model ...
EarlyStopping counter: 1 out of 5.0
EarlyStopping counter: 2 out of 5.0
Validation loss decreased (0.985871 --> 0.984486).  Saving model ...
Validation loss decreased (0.984486 --> 0.982351).  Saving model ...
Validation loss decreased (0.982351 --> 0.981927).  Saving model ...
Validation loss decreased (0.981927 --> 0.981137).  Saving model ...
EarlyStopping counter: 1 out of 5.0
Validation loss decreased (0.981137 --> 0.980828).  Saving model ...
Validation loss decreased (0.980828 --> 0.980661).  Saving model ...
Validation loss decreased (0.980661 --> 0.978560).  Saving model ...
EarlyStopping counter: 1 out of 5.0
Validation loss decreased (0.978560 --> 0.977733).  Saving model ...
EarlyStopping counter: 1 out of 5.0
EarlyStopping counter: 2 out of 5.0
EarlyStopping counter: 3 out of 5.0
EarlyStopping counter: 4 out of 5.0
Validation loss decreased (0.977733 --> 0.976659).  Saving model ...
Validation loss decreased (0.976659 --> 0.975438).  Saving model ...
Validation loss decreased (0.975438 --> 0.973646).  Saving model ...
EarlyStopping counter: 1 out of 5.0
EarlyStopping counter: 2 out of 5.0
EarlyStopping counter: 3 out of 5.0
EarlyStopping counter: 4 out of 5.0
Validation loss decreased (0.973646 --> 0.973251).  Saving model ...
EarlyStopping counter: 1 out of 5.0
Validation loss decreased (0.973251 --> 0.973086).  Saving model ...
Validation loss decreased (0.973086 --> 0.971815).  Saving model ...
EarlyStopping counter: 1 out of 5.0
Validation loss decreased (0.971815 --> 0.971211).  Saving model ...
Validation loss decreased (0.971211 --> 0.970527).  Saving model ...
Validation loss decreased (0.970527 --> 0.968361).  Saving model ...
EarlyStopping counter: 1 out of 5.0
EarlyStopping counter: 2 out of 5.0
EarlyStopping counter: 3 out of 5.0
Validation loss decreased (0.968361 --> 0.967851).  Saving model ...
EarlyStopping counter: 1 out of 5.0
EarlyStopping counter: 2 out of 5.0
EarlyStopping counter: 3 out of 5.0
EarlyStopping counter: 4 out of 5.0
Validation loss decreased (0.967851 --> 0.967338).  Saving model ...
Validation loss decreased (0.967338 --> 0.966781).  Saving model ...
EarlyStopping counter: 1 out of 5.0
EarlyStopping counter: 2 out of 5.0
EarlyStopping counter: 3 out of 5.0
EarlyStopping counter: 4 out of 5.0
EarlyStopping counter: 5 out of 5.0
/localscratch/yinan.29479425.0/env/lib/python3.7/site-packages/torch/nn/functional.py:1794: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.
  warnings.warn("nn.functional.tanh is deprecated. Use torch.tanh instead.")
wandb: Waiting for W&B process to finish, PID 168726... (success).
wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: \ 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: | 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: / 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: \ 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: | 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: / 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: \ 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: | 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: / 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb:                                                                                
wandb: Run history:
wandb:     e_F1 ▁▂▃▄▄▄▅▅▅▅▆▆▆▆▆▆▇▇▇▇▇▇▇▇▇▇█▇████████████
wandb:   e_loss █▇▇▇▆▆▆▅▅▅▄▄▄▃▃▃▃▂▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:     t_F1 ▁▂▂▂▃▄▃▄▅▅▅▅▅▆▆▆▆▆▆▆▆▇▆▇▇▇▇▇▇▇▇▇▇▇▇▇▇███
wandb:   t_loss ██▇▇▇▇▆▆▆▆▅▅▅▄▄▄▄▄▄▃▃▃▃▃▃▃▂▂▂▂▂▂▂▁▂▂▂▁▁▁
wandb: 
wandb: Run summary:
wandb:     e_F1 60.50541
wandb:   e_loss 0.96962
wandb:     t_F1 75.56713
wandb:   t_loss 0.69563
wandb: 
wandb: Synced 4 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Synced eager-moon-1: https://wandb.ai/yinanazhou/xl_512_bs_8_lr_1e06_es_5_lc_True_nr_True_sr_False_stem_True_lemma_False_repeat_3_fold_2/runs/z8z5ebcr
wandb: Find logs at: ./wandb/run-20220325_141110-z8z5ebcr/logs/debug.log
wandb: 

wandb: wandb version 0.12.11 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
2022-03-25 16:08:02.416726: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1
wandb: Tracking run with wandb version 0.12.5
wandb: Syncing run desert-planet-1
wandb: ⭐️ View project at https://wandb.ai/yinanazhou/xl_512_bs_8_lr_1e06_es_5_lc_True_nr_True_sr_False_stem_True_lemma_False_repeat_4_fold_1
wandb: 🚀 View run at https://wandb.ai/yinanazhou/xl_512_bs_8_lr_1e06_es_5_lc_True_nr_True_sr_False_stem_True_lemma_False_repeat_4_fold_1/runs/14fn2rye
wandb: Run data is saved locally in /project/6002780/yinan/Thesis_MER_Lyrics/lyric-emotion/wandb/run-20220325_160759-14fn2rye
wandb: Run `wandb offline` to turn off syncing.

Validation loss decreased (inf --> 1.395534).  Saving model ...
Validation loss decreased (1.395534 --> 1.389070).  Saving model ...
Validation loss decreased (1.389070 --> 1.383872).  Saving model ...
Validation loss decreased (1.383872 --> 1.378972).  Saving model ...
Validation loss decreased (1.378972 --> 1.374528).  Saving model ...
Validation loss decreased (1.374528 --> 1.370969).  Saving model ...
Validation loss decreased (1.370969 --> 1.367738).  Saving model ...
Validation loss decreased (1.367738 --> 1.364763).  Saving model ...
Validation loss decreased (1.364763 --> 1.361357).  Saving model ...
Validation loss decreased (1.361357 --> 1.358428).  Saving model ...
Validation loss decreased (1.358428 --> 1.355452).  Saving model ...
Validation loss decreased (1.355452 --> 1.352276).  Saving model ...
Validation loss decreased (1.352276 --> 1.349273).  Saving model ...
Validation loss decreased (1.349273 --> 1.346260).  Saving model ...
Validation loss decreased (1.346260 --> 1.342589).  Saving model ...
Validation loss decreased (1.342589 --> 1.338959).  Saving model ...
Validation loss decreased (1.338959 --> 1.335303).  Saving model ...
Validation loss decreased (1.335303 --> 1.331496).  Saving model ...
Validation loss decreased (1.331496 --> 1.327696).  Saving model ...
Validation loss decreased (1.327696 --> 1.323193).  Saving model ...
Validation loss decreased (1.323193 --> 1.318725).  Saving model ...
Validation loss decreased (1.318725 --> 1.314448).  Saving model ...
Validation loss decreased (1.314448 --> 1.309726).  Saving model ...
Validation loss decreased (1.309726 --> 1.305240).  Saving model ...
Validation loss decreased (1.305240 --> 1.300231).  Saving model ...
Validation loss decreased (1.300231 --> 1.295560).  Saving model ...
Validation loss decreased (1.295560 --> 1.290469).  Saving model ...
Validation loss decreased (1.290469 --> 1.285112).  Saving model ...
Validation loss decreased (1.285112 --> 1.280352).  Saving model ...
Validation loss decreased (1.280352 --> 1.275026).  Saving model ...
Validation loss decreased (1.275026 --> 1.270489).  Saving model ...
Validation loss decreased (1.270489 --> 1.265822).  Saving model ...
Validation loss decreased (1.265822 --> 1.261632).  Saving model ...
Validation loss decreased (1.261632 --> 1.256794).  Saving model ...
Validation loss decreased (1.256794 --> 1.251720).  Saving model ...
Validation loss decreased (1.251720 --> 1.246372).  Saving model ...
Validation loss decreased (1.246372 --> 1.242242).  Saving model ...
Validation loss decreased (1.242242 --> 1.237435).  Saving model ...
Validation loss decreased (1.237435 --> 1.232285).  Saving model ...
Validation loss decreased (1.232285 --> 1.227802).  Saving model ...
Validation loss decreased (1.227802 --> 1.223416).  Saving model ...
Validation loss decreased (1.223416 --> 1.219480).  Saving model ...
Validation loss decreased (1.219480 --> 1.214037).  Saving model ...
Validation loss decreased (1.214037 --> 1.209579).  Saving model ...
Validation loss decreased (1.209579 --> 1.205815).  Saving model ...
Validation loss decreased (1.205815 --> 1.202929).  Saving model ...
Validation loss decreased (1.202929 --> 1.198971).  Saving model ...
Validation loss decreased (1.198971 --> 1.195390).  Saving model ...
Validation loss decreased (1.195390 --> 1.192597).  Saving model ...
Validation loss decreased (1.192597 --> 1.189030).  Saving model ...
Validation loss decreased (1.189030 --> 1.186121).  Saving model ...
Validation loss decreased (1.186121 --> 1.182491).  Saving model ...
Validation loss decreased (1.182491 --> 1.179596).  Saving model ...
Validation loss decreased (1.179596 --> 1.176296).  Saving model ...
Validation loss decreased (1.176296 --> 1.173449).  Saving model ...
Validation loss decreased (1.173449 --> 1.170333).  Saving model ...
Validation loss decreased (1.170333 --> 1.166987).  Saving model ...
Validation loss decreased (1.166987 --> 1.164364).  Saving model ...
Validation loss decreased (1.164364 --> 1.161901).  Saving model ...
Validation loss decreased (1.161901 --> 1.159459).  Saving model ...
Validation loss decreased (1.159459 --> 1.155749).  Saving model ...
Validation loss decreased (1.155749 --> 1.152082).  Saving model ...
Validation loss decreased (1.152082 --> 1.149611).  Saving model ...
Validation loss decreased (1.149611 --> 1.146961).  Saving model ...
Validation loss decreased (1.146961 --> 1.143614).  Saving model ...
Validation loss decreased (1.143614 --> 1.139932).  Saving model ...
Validation loss decreased (1.139932 --> 1.137513).  Saving model ...
Validation loss decreased (1.137513 --> 1.134303).  Saving model ...
Validation loss decreased (1.134303 --> 1.132541).  Saving model ...
Validation loss decreased (1.132541 --> 1.130498).  Saving model ...
Validation loss decreased (1.130498 --> 1.127298).  Saving model ...
Validation loss decreased (1.127298 --> 1.124912).  Saving model ...
Validation loss decreased (1.124912 --> 1.121933).  Saving model ...
Validation loss decreased (1.121933 --> 1.119555).  Saving model ...
Validation loss decreased (1.119555 --> 1.117505).  Saving model ...
Validation loss decreased (1.117505 --> 1.115141).  Saving model ...
Validation loss decreased (1.115141 --> 1.112375).  Saving model ...
Validation loss decreased (1.112375 --> 1.110177).  Saving model ...
Validation loss decreased (1.110177 --> 1.107688).  Saving model ...
Validation loss decreased (1.107688 --> 1.105532).  Saving model ...
Validation loss decreased (1.105532 --> 1.102783).  Saving model ...
Validation loss decreased (1.102783 --> 1.101555).  Saving model ...
Validation loss decreased (1.101555 --> 1.098241).  Saving model ...
Validation loss decreased (1.098241 --> 1.095885).  Saving model ...
Validation loss decreased (1.095885 --> 1.093834).  Saving model ...
Validation loss decreased (1.093834 --> 1.092867).  Saving model ...
Validation loss decreased (1.092867 --> 1.091002).  Saving model ...
Validation loss decreased (1.091002 --> 1.088443).  Saving model ...
Validation loss decreased (1.088443 --> 1.087913).  Saving model ...
Validation loss decreased (1.087913 --> 1.086486).  Saving model ...
Validation loss decreased (1.086486 --> 1.084225).  Saving model ...
Validation loss decreased (1.084225 --> 1.081671).  Saving model ...
Validation loss decreased (1.081671 --> 1.079380).  Saving model ...
Validation loss decreased (1.079380 --> 1.078073).  Saving model ...
Validation loss decreased (1.078073 --> 1.077540).  Saving model ...
Validation loss decreased (1.077540 --> 1.076712).  Saving model ...
Validation loss decreased (1.076712 --> 1.073544).  Saving model ...
EarlyStopping counter: 1 out of 5.0
Validation loss decreased (1.073544 --> 1.071308).  Saving model ...
Validation loss decreased (1.071308 --> 1.069233).  Saving model ...
Validation loss decreased (1.069233 --> 1.066165).  Saving model ...
Validation loss decreased (1.066165 --> 1.065611).  Saving model ...
EarlyStopping counter: 1 out of 5.0
EarlyStopping counter: 2 out of 5.0
Validation loss decreased (1.065611 --> 1.064871).  Saving model ...
Validation loss decreased (1.064871 --> 1.062163).  Saving model ...
Validation loss decreased (1.062163 --> 1.060977).  Saving model ...
EarlyStopping counter: 1 out of 5.0
Validation loss decreased (1.060977 --> 1.060244).  Saving model ...
Validation loss decreased (1.060244 --> 1.059299).  Saving model ...
Validation loss decreased (1.059299 --> 1.057088).  Saving model ...
EarlyStopping counter: 1 out of 5.0
Validation loss decreased (1.057088 --> 1.054376).  Saving model ...
Validation loss decreased (1.054376 --> 1.053642).  Saving model ...
Validation loss decreased (1.053642 --> 1.051959).  Saving model ...
Validation loss decreased (1.051959 --> 1.050403).  Saving model ...
Validation loss decreased (1.050403 --> 1.049644).  Saving model ...
Validation loss decreased (1.049644 --> 1.048599).  Saving model ...
Validation loss decreased (1.048599 --> 1.047960).  Saving model ...
EarlyStopping counter: 1 out of 5.0
Validation loss decreased (1.047960 --> 1.047301).  Saving model ...
Validation loss decreased (1.047301 --> 1.046334).  Saving model ...
Validation loss decreased (1.046334 --> 1.044038).  Saving model ...
EarlyStopping counter: 1 out of 5.0
Validation loss decreased (1.044038 --> 1.043054).  Saving model ...
EarlyStopping counter: 1 out of 5.0
EarlyStopping counter: 2 out of 5.0
EarlyStopping counter: 3 out of 5.0
EarlyStopping counter: 4 out of 5.0
Validation loss decreased (1.043054 --> 1.042119).  Saving model ...
Validation loss decreased (1.042119 --> 1.041646).  Saving model ...
Validation loss decreased (1.041646 --> 1.041284).  Saving model ...
EarlyStopping counter: 1 out of 5.0
Validation loss decreased (1.041284 --> 1.040979).  Saving model ...
Validation loss decreased (1.040979 --> 1.039953).  Saving model ...
Validation loss decreased (1.039953 --> 1.039796).  Saving model ...
EarlyStopping counter: 1 out of 5.0
Validation loss decreased (1.039796 --> 1.039136).  Saving model ...
EarlyStopping counter: 1 out of 5.0
EarlyStopping counter: 2 out of 5.0
EarlyStopping counter: 3 out of 5.0
EarlyStopping counter: 4 out of 5.0
Validation loss decreased (1.039136 --> 1.039089).  Saving model ...
Validation loss decreased (1.039089 --> 1.037947).  Saving model ...
EarlyStopping counter: 1 out of 5.0
EarlyStopping counter: 2 out of 5.0
Validation loss decreased (1.037947 --> 1.036487).  Saving model ...
Validation loss decreased (1.036487 --> 1.034535).  Saving model ...
EarlyStopping counter: 1 out of 5.0
EarlyStopping counter: 2 out of 5.0
EarlyStopping counter: 3 out of 5.0
EarlyStopping counter: 4 out of 5.0
EarlyStopping counter: 5 out of 5.0
/localscratch/yinan.29479425.0/env/lib/python3.7/site-packages/torch/nn/functional.py:1794: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.
  warnings.warn("nn.functional.tanh is deprecated. Use torch.tanh instead.")
wandb: Waiting for W&B process to finish, PID 174943... (success).
wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: \ 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: | 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: / 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: \ 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: | 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: / 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: \ 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: | 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: / 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb:                                                                                
wandb: Run history:
wandb:     e_F1 ▁▁▃▃▄▄▅▅▅▆▆▆▆▆▆▆▇▇▇▇▇▇▇▇▇▇▇▇▇███████████
wandb:   e_loss ███▇▇▇▆▆▆▅▅▄▄▄▄▄▃▃▃▃▂▂▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁
wandb:     t_F1 ▁▁▂▂▂▃▃▄▄▄▄▄▅▅▅▆▅▆▆▆▆▆▆▆▆▇▇▇▇▇▇▇▇▇▇▇▇▇▇█
wandb:   t_loss ████▇▇▇▇▇▆▆▆▅▅▅▅▅▄▄▄▄▄▄▃▃▃▃▃▂▃▂▂▂▂▂▁▂▁▁▁
wandb: 
wandb: Run summary:
wandb:     e_F1 54.44071
wandb:   e_loss 1.04133
wandb:     t_F1 69.47826
wandb:   t_loss 0.76565
wandb: 
wandb: Synced 4 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Synced desert-planet-1: https://wandb.ai/yinanazhou/xl_512_bs_8_lr_1e06_es_5_lc_True_nr_True_sr_False_stem_True_lemma_False_repeat_4_fold_1/runs/14fn2rye
wandb: Find logs at: ./wandb/run-20220325_160759-14fn2rye/logs/debug.log
wandb: 

wandb: wandb version 0.12.11 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
2022-03-25 17:48:31.481652: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1
wandb: Tracking run with wandb version 0.12.5
wandb: Syncing run fallen-water-1
wandb: ⭐️ View project at https://wandb.ai/yinanazhou/xl_512_bs_8_lr_1e06_es_5_lc_True_nr_True_sr_False_stem_True_lemma_False_repeat_4_fold_2
wandb: 🚀 View run at https://wandb.ai/yinanazhou/xl_512_bs_8_lr_1e06_es_5_lc_True_nr_True_sr_False_stem_True_lemma_False_repeat_4_fold_2/runs/2pfsx4tg
wandb: Run data is saved locally in /project/6002780/yinan/Thesis_MER_Lyrics/lyric-emotion/wandb/run-20220325_174829-2pfsx4tg
wandb: Run `wandb offline` to turn off syncing.

Validation loss decreased (inf --> 1.438096).  Saving model ...
Validation loss decreased (1.438096 --> 1.420933).  Saving model ...
Validation loss decreased (1.420933 --> 1.408416).  Saving model ...
Validation loss decreased (1.408416 --> 1.399417).  Saving model ...
Validation loss decreased (1.399417 --> 1.392714).  Saving model ...
Validation loss decreased (1.392714 --> 1.387053).  Saving model ...
Validation loss decreased (1.387053 --> 1.382495).  Saving model ...
Validation loss decreased (1.382495 --> 1.378787).  Saving model ...
Validation loss decreased (1.378787 --> 1.374999).  Saving model ...
Validation loss decreased (1.374999 --> 1.371976).  Saving model ...
Validation loss decreased (1.371976 --> 1.368700).  Saving model ...
Validation loss decreased (1.368700 --> 1.365254).  Saving model ...
Validation loss decreased (1.365254 --> 1.362389).  Saving model ...
Validation loss decreased (1.362389 --> 1.359467).  Saving model ...
Validation loss decreased (1.359467 --> 1.356771).  Saving model ...
Validation loss decreased (1.356771 --> 1.353766).  Saving model ...
Validation loss decreased (1.353766 --> 1.350786).  Saving model ...
Validation loss decreased (1.350786 --> 1.347498).  Saving model ...
Validation loss decreased (1.347498 --> 1.344698).  Saving model ...
Validation loss decreased (1.344698 --> 1.341627).  Saving model ...
Validation loss decreased (1.341627 --> 1.338389).  Saving model ...
Validation loss decreased (1.338389 --> 1.334851).  Saving model ...
Validation loss decreased (1.334851 --> 1.331712).  Saving model ...
Validation loss decreased (1.331712 --> 1.327585).  Saving model ...
Validation loss decreased (1.327585 --> 1.323260).  Saving model ...
Validation loss decreased (1.323260 --> 1.319198).  Saving model ...
Validation loss decreased (1.319198 --> 1.314317).  Saving model ...
Validation loss decreased (1.314317 --> 1.310494).  Saving model ...
Validation loss decreased (1.310494 --> 1.305316).  Saving model ...
Validation loss decreased (1.305316 --> 1.301042).  Saving model ...
Validation loss decreased (1.301042 --> 1.296760).  Saving model ...
Validation loss decreased (1.296760 --> 1.292863).  Saving model ...
Validation loss decreased (1.292863 --> 1.287234).  Saving model ...
Validation loss decreased (1.287234 --> 1.282526).  Saving model ...
Validation loss decreased (1.282526 --> 1.277287).  Saving model ...
Validation loss decreased (1.277287 --> 1.270723).  Saving model ...
Validation loss decreased (1.270723 --> 1.267039).  Saving model ...
Validation loss decreased (1.267039 --> 1.261094).  Saving model ...
Validation loss decreased (1.261094 --> 1.254760).  Saving model ...
Validation loss decreased (1.254760 --> 1.247963).  Saving model ...
Validation loss decreased (1.247963 --> 1.240638).  Saving model ...
Validation loss decreased (1.240638 --> 1.232287).  Saving model ...
Validation loss decreased (1.232287 --> 1.224202).  Saving model ...
Validation loss decreased (1.224202 --> 1.220671).  Saving model ...
Validation loss decreased (1.220671 --> 1.215499).  Saving model ...
Validation loss decreased (1.215499 --> 1.210080).  Saving model ...
Validation loss decreased (1.210080 --> 1.204426).  Saving model ...
Validation loss decreased (1.204426 --> 1.199741).  Saving model ...
Validation loss decreased (1.199741 --> 1.191790).  Saving model ...
Validation loss decreased (1.191790 --> 1.185219).  Saving model ...
Validation loss decreased (1.185219 --> 1.182999).  Saving model ...
EarlyStopping counter: 1 out of 5.0
Validation loss decreased (1.182999 --> 1.176538).  Saving model ...
Validation loss decreased (1.176538 --> 1.171694).  Saving model ...
Validation loss decreased (1.171694 --> 1.168758).  Saving model ...
Validation loss decreased (1.168758 --> 1.164232).  Saving model ...
Validation loss decreased (1.164232 --> 1.158266).  Saving model ...
Validation loss decreased (1.158266 --> 1.155417).  Saving model ...
Validation loss decreased (1.155417 --> 1.150685).  Saving model ...
Validation loss decreased (1.150685 --> 1.146363).  Saving model ...
Validation loss decreased (1.146363 --> 1.140348).  Saving model ...
Validation loss decreased (1.140348 --> 1.134963).  Saving model ...
Validation loss decreased (1.134963 --> 1.133255).  Saving model ...
Validation loss decreased (1.133255 --> 1.127698).  Saving model ...
Validation loss decreased (1.127698 --> 1.125561).  Saving model ...
Validation loss decreased (1.125561 --> 1.122922).  Saving model ...
Validation loss decreased (1.122922 --> 1.116751).  Saving model ...
Validation loss decreased (1.116751 --> 1.111805).  Saving model ...
EarlyStopping counter: 1 out of 5.0
Validation loss decreased (1.111805 --> 1.108482).  Saving model ...
Validation loss decreased (1.108482 --> 1.103280).  Saving model ...
Validation loss decreased (1.103280 --> 1.099710).  Saving model ...
Validation loss decreased (1.099710 --> 1.098360).  Saving model ...
EarlyStopping counter: 1 out of 5.0
Validation loss decreased (1.098360 --> 1.094269).  Saving model ...
Validation loss decreased (1.094269 --> 1.090407).  Saving model ...
Validation loss decreased (1.090407 --> 1.088691).  Saving model ...
Validation loss decreased (1.088691 --> 1.087549).  Saving model ...
Validation loss decreased (1.087549 --> 1.080564).  Saving model ...
Validation loss decreased (1.080564 --> 1.080130).  Saving model ...
Validation loss decreased (1.080130 --> 1.075521).  Saving model ...
Validation loss decreased (1.075521 --> 1.074818).  Saving model ...
Validation loss decreased (1.074818 --> 1.071482).  Saving model ...
Validation loss decreased (1.071482 --> 1.068812).  Saving model ...
Validation loss decreased (1.068812 --> 1.066567).  Saving model ...
Validation loss decreased (1.066567 --> 1.065850).  Saving model ...
Validation loss decreased (1.065850 --> 1.063618).  Saving model ...
Validation loss decreased (1.063618 --> 1.058919).  Saving model ...
Validation loss decreased (1.058919 --> 1.058113).  Saving model ...
Validation loss decreased (1.058113 --> 1.057470).  Saving model ...
Validation loss decreased (1.057470 --> 1.054183).  Saving model ...
EarlyStopping counter: 1 out of 5.0
Validation loss decreased (1.054183 --> 1.051497).  Saving model ...
EarlyStopping counter: 1 out of 5.0
Validation loss decreased (1.051497 --> 1.051109).  Saving model ...
Validation loss decreased (1.051109 --> 1.043576).  Saving model ...
Validation loss decreased (1.043576 --> 1.042885).  Saving model ...
EarlyStopping counter: 1 out of 5.0
Validation loss decreased (1.042885 --> 1.041191).  Saving model ...
Validation loss decreased (1.041191 --> 1.037147).  Saving model ...
EarlyStopping counter: 1 out of 5.0
EarlyStopping counter: 2 out of 5.0
Validation loss decreased (1.037147 --> 1.036441).  Saving model ...
Validation loss decreased (1.036441 --> 1.033514).  Saving model ...
Validation loss decreased (1.033514 --> 1.033015).  Saving model ...
Validation loss decreased (1.033015 --> 1.027550).  Saving model ...
Validation loss decreased (1.027550 --> 1.026636).  Saving model ...
EarlyStopping counter: 1 out of 5.0
Validation loss decreased (1.026636 --> 1.024449).  Saving model ...
Validation loss decreased (1.024449 --> 1.023249).  Saving model ...
EarlyStopping counter: 1 out of 5.0
EarlyStopping counter: 2 out of 5.0
EarlyStopping counter: 3 out of 5.0
EarlyStopping counter: 4 out of 5.0
EarlyStopping counter: 5 out of 5.0
/localscratch/yinan.29479425.0/env/lib/python3.7/site-packages/torch/nn/functional.py:1794: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.
  warnings.warn("nn.functional.tanh is deprecated. Use torch.tanh instead.")
wandb: Waiting for W&B process to finish, PID 180274... (success).
wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: \ 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: | 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: / 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb:                                                                                
wandb: Run history:
wandb:     e_F1 ▁▁▂▄▅▅▅▅▅▅▆▅▆▆▆▆▇▇▇▇▇▇▇▇▇▇▇▇████████████
wandb:   e_loss █▇▇▇▇▇▆▆▆▆▆▅▅▅▅▄▄▄▄▃▃▃▃▂▂▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁
wandb:     t_F1 ▁▂▂▃▃▄▃▃▄▄▅▅▅▅▅▅▅▆▆▆▆▆▇▆▇▆▇▇▇▇▇▇▇▇▇█████
wandb:   t_loss ██▇▇▇▇▇▇▆▆▆▆▆▅▅▅▅▅▄▄▄▄▄▃▃▃▃▃▃▃▃▂▂▂▂▁▂▁▁▁
wandb: 
wandb: Run summary:
wandb:     e_F1 54.29893
wandb:   e_loss 1.02939
wandb:     t_F1 63.48834
wandb:   t_loss 0.89603
wandb: 
wandb: Synced 4 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Synced fallen-water-1: https://wandb.ai/yinanazhou/xl_512_bs_8_lr_1e06_es_5_lc_True_nr_True_sr_False_stem_True_lemma_False_repeat_4_fold_2/runs/2pfsx4tg
wandb: Find logs at: ./wandb/run-20220325_174829-2pfsx4tg/logs/debug.log
wandb: 

wandb: wandb version 0.12.11 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
2022-03-25 19:02:04.650814: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1
wandb: Tracking run with wandb version 0.12.5
wandb: Syncing run fragrant-surf-1
wandb: ⭐️ View project at https://wandb.ai/yinanazhou/xl_512_bs_8_lr_1e06_es_5_lc_True_nr_True_sr_False_stem_True_lemma_False_repeat_5_fold_1
wandb: 🚀 View run at https://wandb.ai/yinanazhou/xl_512_bs_8_lr_1e06_es_5_lc_True_nr_True_sr_False_stem_True_lemma_False_repeat_5_fold_1/runs/31ynbeio
wandb: Run data is saved locally in /project/6002780/yinan/Thesis_MER_Lyrics/lyric-emotion/wandb/run-20220325_190202-31ynbeio
wandb: Run `wandb offline` to turn off syncing.

Validation loss decreased (inf --> 1.439549).  Saving model ...
Validation loss decreased (1.439549 --> 1.409921).  Saving model ...
Validation loss decreased (1.409921 --> 1.391718).  Saving model ...
Validation loss decreased (1.391718 --> 1.380180).  Saving model ...
Validation loss decreased (1.380180 --> 1.371716).  Saving model ...
Validation loss decreased (1.371716 --> 1.365556).  Saving model ...
Validation loss decreased (1.365556 --> 1.360788).  Saving model ...
Validation loss decreased (1.360788 --> 1.356375).  Saving model ...
Validation loss decreased (1.356375 --> 1.352693).  Saving model ...
Validation loss decreased (1.352693 --> 1.349036).  Saving model ...
Validation loss decreased (1.349036 --> 1.345048).  Saving model ...
Validation loss decreased (1.345048 --> 1.341236).  Saving model ...
Validation loss decreased (1.341236 --> 1.337501).  Saving model ...
Validation loss decreased (1.337501 --> 1.333566).  Saving model ...
Validation loss decreased (1.333566 --> 1.328897).  Saving model ...
Validation loss decreased (1.328897 --> 1.324668).  Saving model ...
Validation loss decreased (1.324668 --> 1.319859).  Saving model ...
Validation loss decreased (1.319859 --> 1.315515).  Saving model ...
Validation loss decreased (1.315515 --> 1.311255).  Saving model ...
Validation loss decreased (1.311255 --> 1.306786).  Saving model ...
Validation loss decreased (1.306786 --> 1.301918).  Saving model ...
Validation loss decreased (1.301918 --> 1.297426).  Saving model ...
Validation loss decreased (1.297426 --> 1.292265).  Saving model ...
Validation loss decreased (1.292265 --> 1.287168).  Saving model ...
Validation loss decreased (1.287168 --> 1.282928).  Saving model ...
Validation loss decreased (1.282928 --> 1.278228).  Saving model ...
Validation loss decreased (1.278228 --> 1.272971).  Saving model ...
Validation loss decreased (1.272971 --> 1.267823).  Saving model ...
Validation loss decreased (1.267823 --> 1.262393).  Saving model ...
Validation loss decreased (1.262393 --> 1.256902).  Saving model ...
Validation loss decreased (1.256902 --> 1.252286).  Saving model ...
Validation loss decreased (1.252286 --> 1.247635).  Saving model ...
Validation loss decreased (1.247635 --> 1.242334).  Saving model ...
Validation loss decreased (1.242334 --> 1.237373).  Saving model ...
Validation loss decreased (1.237373 --> 1.232208).  Saving model ...
Validation loss decreased (1.232208 --> 1.226777).  Saving model ...
Validation loss decreased (1.226777 --> 1.222067).  Saving model ...
Validation loss decreased (1.222067 --> 1.217264).  Saving model ...
Validation loss decreased (1.217264 --> 1.212187).  Saving model ...
Validation loss decreased (1.212187 --> 1.207821).  Saving model ...
Validation loss decreased (1.207821 --> 1.203955).  Saving model ...
Validation loss decreased (1.203955 --> 1.199182).  Saving model ...
Validation loss decreased (1.199182 --> 1.194515).  Saving model ...
Validation loss decreased (1.194515 --> 1.189362).  Saving model ...
Validation loss decreased (1.189362 --> 1.183923).  Saving model ...
Validation loss decreased (1.183923 --> 1.180059).  Saving model ...
Validation loss decreased (1.180059 --> 1.175024).  Saving model ...
Validation loss decreased (1.175024 --> 1.170005).  Saving model ...
Validation loss decreased (1.170005 --> 1.165398).  Saving model ...
Validation loss decreased (1.165398 --> 1.162479).  Saving model ...
Validation loss decreased (1.162479 --> 1.157436).  Saving model ...
Validation loss decreased (1.157436 --> 1.153789).  Saving model ...
Validation loss decreased (1.153789 --> 1.149499).  Saving model ...
Validation loss decreased (1.149499 --> 1.145961).  Saving model ...
Validation loss decreased (1.145961 --> 1.141919).  Saving model ...
Validation loss decreased (1.141919 --> 1.138015).  Saving model ...
Validation loss decreased (1.138015 --> 1.134405).  Saving model ...
Validation loss decreased (1.134405 --> 1.131549).  Saving model ...
Validation loss decreased (1.131549 --> 1.127792).  Saving model ...
Validation loss decreased (1.127792 --> 1.124946).  Saving model ...
Validation loss decreased (1.124946 --> 1.121136).  Saving model ...
Validation loss decreased (1.121136 --> 1.118530).  Saving model ...
Validation loss decreased (1.118530 --> 1.114210).  Saving model ...
Validation loss decreased (1.114210 --> 1.110839).  Saving model ...
Validation loss decreased (1.110839 --> 1.108437).  Saving model ...
Validation loss decreased (1.108437 --> 1.103904).  Saving model ...
Validation loss decreased (1.103904 --> 1.102811).  Saving model ...
Validation loss decreased (1.102811 --> 1.101046).  Saving model ...
Validation loss decreased (1.101046 --> 1.097191).  Saving model ...
Validation loss decreased (1.097191 --> 1.093188).  Saving model ...
Validation loss decreased (1.093188 --> 1.091164).  Saving model ...
Validation loss decreased (1.091164 --> 1.087661).  Saving model ...
Validation loss decreased (1.087661 --> 1.084857).  Saving model ...
Validation loss decreased (1.084857 --> 1.082502).  Saving model ...
Validation loss decreased (1.082502 --> 1.079884).  Saving model ...
Validation loss decreased (1.079884 --> 1.075933).  Saving model ...
Validation loss decreased (1.075933 --> 1.072369).  Saving model ...
Validation loss decreased (1.072369 --> 1.070141).  Saving model ...
Validation loss decreased (1.070141 --> 1.068278).  Saving model ...
Validation loss decreased (1.068278 --> 1.066040).  Saving model ...
Validation loss decreased (1.066040 --> 1.064178).  Saving model ...
Validation loss decreased (1.064178 --> 1.062332).  Saving model ...
Validation loss decreased (1.062332 --> 1.059334).  Saving model ...
Validation loss decreased (1.059334 --> 1.056451).  Saving model ...
Validation loss decreased (1.056451 --> 1.053255).  Saving model ...
Validation loss decreased (1.053255 --> 1.052740).  Saving model ...
Validation loss decreased (1.052740 --> 1.049827).  Saving model ...
Validation loss decreased (1.049827 --> 1.048121).  Saving model ...
Validation loss decreased (1.048121 --> 1.046487).  Saving model ...
Validation loss decreased (1.046487 --> 1.044681).  Saving model ...
Validation loss decreased (1.044681 --> 1.043175).  Saving model ...
Validation loss decreased (1.043175 --> 1.041424).  Saving model ...
Validation loss decreased (1.041424 --> 1.038861).  Saving model ...
Validation loss decreased (1.038861 --> 1.038010).  Saving model ...
Validation loss decreased (1.038010 --> 1.037051).  Saving model ...
Validation loss decreased (1.037051 --> 1.036504).  Saving model ...
Validation loss decreased (1.036504 --> 1.035006).  Saving model ...
Validation loss decreased (1.035006 --> 1.032323).  Saving model ...
Validation loss decreased (1.032323 --> 1.031371).  Saving model ...
Validation loss decreased (1.031371 --> 1.030365).  Saving model ...
Validation loss decreased (1.030365 --> 1.029137).  Saving model ...
Validation loss decreased (1.029137 --> 1.027374).  Saving model ...
Validation loss decreased (1.027374 --> 1.024129).  Saving model ...
Validation loss decreased (1.024129 --> 1.023834).  Saving model ...
Validation loss decreased (1.023834 --> 1.022247).  Saving model ...
Validation loss decreased (1.022247 --> 1.019639).  Saving model ...
EarlyStopping counter: 1 out of 5.0
Validation loss decreased (1.019639 --> 1.018680).  Saving model ...
Validation loss decreased (1.018680 --> 1.017480).  Saving model ...
EarlyStopping counter: 1 out of 5.0
Validation loss decreased (1.017480 --> 1.016386).  Saving model ...
Validation loss decreased (1.016386 --> 1.015074).  Saving model ...
Validation loss decreased (1.015074 --> 1.012732).  Saving model ...
Validation loss decreased (1.012732 --> 1.010355).  Saving model ...
Validation loss decreased (1.010355 --> 1.008916).  Saving model ...
Validation loss decreased (1.008916 --> 1.008388).  Saving model ...
EarlyStopping counter: 1 out of 5.0
Validation loss decreased (1.008388 --> 1.007291).  Saving model ...
Validation loss decreased (1.007291 --> 1.006207).  Saving model ...
Validation loss decreased (1.006207 --> 1.005591).  Saving model ...
Validation loss decreased (1.005591 --> 1.005046).  Saving model ...
Validation loss decreased (1.005046 --> 1.003613).  Saving model ...
Validation loss decreased (1.003613 --> 1.002470).  Saving model ...
Validation loss decreased (1.002470 --> 1.001128).  Saving model ...
Validation loss decreased (1.001128 --> 1.000806).  Saving model ...
EarlyStopping counter: 1 out of 5.0
Validation loss decreased (1.000806 --> 1.000425).  Saving model ...
Validation loss decreased (1.000425 --> 1.000375).  Saving model ...
Validation loss decreased (1.000375 --> 0.999482).  Saving model ...
Validation loss decreased (0.999482 --> 0.999343).  Saving model ...
Validation loss decreased (0.999343 --> 0.998811).  Saving model ...
EarlyStopping counter: 1 out of 5.0
EarlyStopping counter: 2 out of 5.0
EarlyStopping counter: 3 out of 5.0
EarlyStopping counter: 4 out of 5.0
EarlyStopping counter: 5 out of 5.0
/localscratch/yinan.29479425.0/env/lib/python3.7/site-packages/torch/nn/functional.py:1794: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.
  warnings.warn("nn.functional.tanh is deprecated. Use torch.tanh instead.")
wandb: Waiting for W&B process to finish, PID 184206... (success).
wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: \ 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: | 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: / 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: \ 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: | 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: / 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: \ 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: | 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: / 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: \ 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: | 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: / 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb:                                                                                
wandb: Run history:
wandb:     e_F1 ▁▂▄▄▅▅▅▆▆▆▆▆▆▆▆▇▇▇▇▇▇▇▇▇▇▇▇▇███▇████████
wandb:   e_loss █▇▇▇▇▆▆▆▆▅▅▅▄▄▄▄▃▃▃▃▃▂▂▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁
wandb:     t_F1 ▁▂▃▃▃▄▄▄▄▅▅▅▅▅▆▆▆▆▆▆▆▇▆▆▆▇▇▇▇▇▇▇▇▇▇█▇███
wandb:   t_loss ██▇▇▇▇▇▆▆▆▆▆▆▅▅▅▅▅▄▄▄▃▄▃▃▃▃▃▃▂▂▂▂▂▂▂▂▁▁▁
wandb: 
wandb: Run summary:
wandb:     e_F1 54.8049
wandb:   e_loss 0.99964
wandb:     t_F1 71.84395
wandb:   t_loss 0.76805
wandb: 
wandb: Synced 4 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Synced fragrant-surf-1: https://wandb.ai/yinanazhou/xl_512_bs_8_lr_1e06_es_5_lc_True_nr_True_sr_False_stem_True_lemma_False_repeat_5_fold_1/runs/31ynbeio
wandb: Find logs at: ./wandb/run-20220325_190202-31ynbeio/logs/debug.log
wandb: 

wandb: wandb version 0.12.11 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
2022-03-25 20:29:39.558382: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1
wandb: Tracking run with wandb version 0.12.5
wandb: Syncing run electric-thunder-1
wandb: ⭐️ View project at https://wandb.ai/yinanazhou/xl_512_bs_8_lr_1e06_es_5_lc_True_nr_True_sr_False_stem_True_lemma_False_repeat_5_fold_2
wandb: 🚀 View run at https://wandb.ai/yinanazhou/xl_512_bs_8_lr_1e06_es_5_lc_True_nr_True_sr_False_stem_True_lemma_False_repeat_5_fold_2/runs/138x5mro
wandb: Run data is saved locally in /project/6002780/yinan/Thesis_MER_Lyrics/lyric-emotion/wandb/run-20220325_202937-138x5mro
wandb: Run `wandb offline` to turn off syncing.

Validation loss decreased (inf --> 1.480056).  Saving model ...
Validation loss decreased (1.480056 --> 1.446098).  Saving model ...
Validation loss decreased (1.446098 --> 1.421379).  Saving model ...
Validation loss decreased (1.421379 --> 1.405334).  Saving model ...
Validation loss decreased (1.405334 --> 1.394070).  Saving model ...
Validation loss decreased (1.394070 --> 1.385574).  Saving model ...
Validation loss decreased (1.385574 --> 1.379569).  Saving model ...
Validation loss decreased (1.379569 --> 1.374821).  Saving model ...
Validation loss decreased (1.374821 --> 1.370757).  Saving model ...
Validation loss decreased (1.370757 --> 1.366863).  Saving model ...
Validation loss decreased (1.366863 --> 1.363561).  Saving model ...
Validation loss decreased (1.363561 --> 1.360245).  Saving model ...
Validation loss decreased (1.360245 --> 1.356431).  Saving model ...
Validation loss decreased (1.356431 --> 1.352866).  Saving model ...
Validation loss decreased (1.352866 --> 1.349215).  Saving model ...
Validation loss decreased (1.349215 --> 1.345608).  Saving model ...
Validation loss decreased (1.345608 --> 1.341529).  Saving model ...
Validation loss decreased (1.341529 --> 1.337824).  Saving model ...
Validation loss decreased (1.337824 --> 1.333423).  Saving model ...
Validation loss decreased (1.333423 --> 1.329500).  Saving model ...
Validation loss decreased (1.329500 --> 1.325174).  Saving model ...
Validation loss decreased (1.325174 --> 1.321403).  Saving model ...
Validation loss decreased (1.321403 --> 1.317172).  Saving model ...
Validation loss decreased (1.317172 --> 1.312129).  Saving model ...
Validation loss decreased (1.312129 --> 1.307124).  Saving model ...
Validation loss decreased (1.307124 --> 1.300996).  Saving model ...
Validation loss decreased (1.300996 --> 1.296524).  Saving model ...
Validation loss decreased (1.296524 --> 1.292257).  Saving model ...
Validation loss decreased (1.292257 --> 1.286026).  Saving model ...
Validation loss decreased (1.286026 --> 1.281699).  Saving model ...
Validation loss decreased (1.281699 --> 1.277043).  Saving model ...
Validation loss decreased (1.277043 --> 1.271731).  Saving model ...
Validation loss decreased (1.271731 --> 1.266631).  Saving model ...
Validation loss decreased (1.266631 --> 1.260508).  Saving model ...
Validation loss decreased (1.260508 --> 1.253494).  Saving model ...
Validation loss decreased (1.253494 --> 1.247423).  Saving model ...
Validation loss decreased (1.247423 --> 1.240011).  Saving model ...
Validation loss decreased (1.240011 --> 1.232871).  Saving model ...
Validation loss decreased (1.232871 --> 1.227721).  Saving model ...
Validation loss decreased (1.227721 --> 1.221710).  Saving model ...
Validation loss decreased (1.221710 --> 1.216018).  Saving model ...
Validation loss decreased (1.216018 --> 1.210503).  Saving model ...
Validation loss decreased (1.210503 --> 1.207096).  Saving model ...
Validation loss decreased (1.207096 --> 1.199421).  Saving model ...
Validation loss decreased (1.199421 --> 1.192953).  Saving model ...
Validation loss decreased (1.192953 --> 1.188114).  Saving model ...
Validation loss decreased (1.188114 --> 1.183424).  Saving model ...
Validation loss decreased (1.183424 --> 1.177329).  Saving model ...
Validation loss decreased (1.177329 --> 1.172768).  Saving model ...
Validation loss decreased (1.172768 --> 1.166539).  Saving model ...
Validation loss decreased (1.166539 --> 1.160394).  Saving model ...
Validation loss decreased (1.160394 --> 1.156369).  Saving model ...
Validation loss decreased (1.156369 --> 1.152193).  Saving model ...
Validation loss decreased (1.152193 --> 1.147233).  Saving model ...
Validation loss decreased (1.147233 --> 1.143383).  Saving model ...
Validation loss decreased (1.143383 --> 1.138985).  Saving model ...
Validation loss decreased (1.138985 --> 1.136110).  Saving model ...
Validation loss decreased (1.136110 --> 1.133742).  Saving model ...
Validation loss decreased (1.133742 --> 1.129894).  Saving model ...
Validation loss decreased (1.129894 --> 1.125745).  Saving model ...
Validation loss decreased (1.125745 --> 1.121516).  Saving model ...
Validation loss decreased (1.121516 --> 1.118572).  Saving model ...
Validation loss decreased (1.118572 --> 1.116863).  Saving model ...
Validation loss decreased (1.116863 --> 1.114861).  Saving model ...
Validation loss decreased (1.114861 --> 1.112615).  Saving model ...
Validation loss decreased (1.112615 --> 1.107815).  Saving model ...
Validation loss decreased (1.107815 --> 1.101971).  Saving model ...
Validation loss decreased (1.101971 --> 1.099962).  Saving model ...
Validation loss decreased (1.099962 --> 1.095369).  Saving model ...
Validation loss decreased (1.095369 --> 1.092482).  Saving model ...
Validation loss decreased (1.092482 --> 1.089909).  Saving model ...
Validation loss decreased (1.089909 --> 1.086361).  Saving model ...
Validation loss decreased (1.086361 --> 1.083811).  Saving model ...
Validation loss decreased (1.083811 --> 1.080850).  Saving model ...
Validation loss decreased (1.080850 --> 1.079936).  Saving model ...
Validation loss decreased (1.079936 --> 1.077179).  Saving model ...
Validation loss decreased (1.077179 --> 1.074522).  Saving model ...
Validation loss decreased (1.074522 --> 1.072390).  Saving model ...
Validation loss decreased (1.072390 --> 1.071093).  Saving model ...
Validation loss decreased (1.071093 --> 1.067388).  Saving model ...
Validation loss decreased (1.067388 --> 1.062733).  Saving model ...
Validation loss decreased (1.062733 --> 1.060307).  Saving model ...
Validation loss decreased (1.060307 --> 1.059759).  Saving model ...
Validation loss decreased (1.059759 --> 1.057662).  Saving model ...
Validation loss decreased (1.057662 --> 1.054193).  Saving model ...
Validation loss decreased (1.054193 --> 1.052655).  Saving model ...
Validation loss decreased (1.052655 --> 1.050251).  Saving model ...
Validation loss decreased (1.050251 --> 1.045123).  Saving model ...
Validation loss decreased (1.045123 --> 1.044657).  Saving model ...
Validation loss decreased (1.044657 --> 1.043860).  Saving model ...
Validation loss decreased (1.043860 --> 1.041806).  Saving model ...
Validation loss decreased (1.041806 --> 1.038550).  Saving model ...
Validation loss decreased (1.038550 --> 1.037838).  Saving model ...
Validation loss decreased (1.037838 --> 1.036638).  Saving model ...
Validation loss decreased (1.036638 --> 1.033113).  Saving model ...
EarlyStopping counter: 1 out of 5.0
Validation loss decreased (1.033113 --> 1.032954).  Saving model ...
Validation loss decreased (1.032954 --> 1.028282).  Saving model ...
Validation loss decreased (1.028282 --> 1.028184).  Saving model ...
EarlyStopping counter: 1 out of 5.0
Validation loss decreased (1.028184 --> 1.023092).  Saving model ...
Validation loss decreased (1.023092 --> 1.019353).  Saving model ...
Validation loss decreased (1.019353 --> 1.019027).  Saving model ...
Validation loss decreased (1.019027 --> 1.016565).  Saving model ...
Validation loss decreased (1.016565 --> 1.015319).  Saving model ...
Validation loss decreased (1.015319 --> 1.015047).  Saving model ...
Validation loss decreased (1.015047 --> 1.012789).  Saving model ...
Validation loss decreased (1.012789 --> 1.008878).  Saving model ...
EarlyStopping counter: 1 out of 5.0
EarlyStopping counter: 2 out of 5.0
EarlyStopping counter: 3 out of 5.0
Validation loss decreased (1.008878 --> 1.006210).  Saving model ...
Validation loss decreased (1.006210 --> 1.004594).  Saving model ...
Validation loss decreased (1.004594 --> 1.002477).  Saving model ...
EarlyStopping counter: 1 out of 5.0
EarlyStopping counter: 2 out of 5.0
EarlyStopping counter: 3 out of 5.0
Validation loss decreased (1.002477 --> 1.000902).  Saving model ...
Validation loss decreased (1.000902 --> 0.998811).  Saving model ...
Validation loss decreased (0.998811 --> 0.997852).  Saving model ...
Validation loss decreased (0.997852 --> 0.996686).  Saving model ...
Validation loss decreased (0.996686 --> 0.995478).  Saving model ...
Validation loss decreased (0.995478 --> 0.994596).  Saving model ...
Validation loss decreased (0.994596 --> 0.994245).  Saving model ...
Validation loss decreased (0.994245 --> 0.992150).  Saving model ...
EarlyStopping counter: 1 out of 5.0
EarlyStopping counter: 2 out of 5.0
Validation loss decreased (0.992150 --> 0.991396).  Saving model ...
EarlyStopping counter: 1 out of 5.0
Validation loss decreased (0.991396 --> 0.987927).  Saving model ...
Validation loss decreased (0.987927 --> 0.986306).  Saving model ...
EarlyStopping counter: 1 out of 5.0
EarlyStopping counter: 2 out of 5.0
Validation loss decreased (0.986306 --> 0.985951).  Saving model ...
Validation loss decreased (0.985951 --> 0.983508).  Saving model ...
Validation loss decreased (0.983508 --> 0.982234).  Saving model ...
EarlyStopping counter: 1 out of 5.0
EarlyStopping counter: 2 out of 5.0
EarlyStopping counter: 3 out of 5.0
Validation loss decreased (0.982234 --> 0.981758).  Saving model ...
Validation loss decreased (0.981758 --> 0.981105).  Saving model ...
Validation loss decreased (0.981105 --> 0.979836).  Saving model ...
EarlyStopping counter: 1 out of 5.0
EarlyStopping counter: 2 out of 5.0
EarlyStopping counter: 3 out of 5.0
EarlyStopping counter: 4 out of 5.0
Validation loss decreased (0.979836 --> 0.978000).  Saving model ...
EarlyStopping counter: 1 out of 5.0
EarlyStopping counter: 2 out of 5.0
Validation loss decreased (0.978000 --> 0.977002).  Saving model ...
Validation loss decreased (0.977002 --> 0.976173).  Saving model ...
EarlyStopping counter: 1 out of 5.0
EarlyStopping counter: 2 out of 5.0
EarlyStopping counter: 3 out of 5.0
EarlyStopping counter: 4 out of 5.0
Validation loss decreased (0.976173 --> 0.975108).  Saving model ...
EarlyStopping counter: 1 out of 5.0
Validation loss decreased (0.975108 --> 0.973338).  Saving model ...
EarlyStopping counter: 1 out of 5.0
EarlyStopping counter: 2 out of 5.0
EarlyStopping counter: 3 out of 5.0
EarlyStopping counter: 4 out of 5.0
EarlyStopping counter: 5 out of 5.0
/localscratch/yinan.29479425.0/env/lib/python3.7/site-packages/torch/nn/functional.py:1794: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.
  warnings.warn("nn.functional.tanh is deprecated. Use torch.tanh instead.")
wandb: Waiting for W&B process to finish, PID 188883... (success).
wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: \ 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: | 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: / 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: \ 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: | 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: / 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: \ 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: | 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: / 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb:                                                                                
wandb: Run history:
wandb:     e_F1 ▁▃▄▄▅▅▆▆▆▇▇▇▇███████████████████████████
wandb:   e_loss █▇▇▇▆▆▆▆▅▅▅▄▄▄▃▃▃▃▃▂▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:     t_F1 ▁▂▃▃▃▃▄▄▅▅▅▅▅▅▆▅▆▆▆▆▆▇▇▇▇▇▇▇▇▇██▇▇▇█████
wandb:   t_loss █▇▇▇▇▇▆▆▆▅▆▅▅▅▅▄▄▄▄▄▄▃▃▃▃▃▂▂▂▂▂▂▂▂▂▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:     e_F1 58.17223
wandb:   e_loss 0.97528
wandb:     t_F1 68.19672
wandb:   t_loss 0.77449
wandb: 
wandb: Synced 4 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Synced electric-thunder-1: https://wandb.ai/yinanazhou/xl_512_bs_8_lr_1e06_es_5_lc_True_nr_True_sr_False_stem_True_lemma_False_repeat_5_fold_2/runs/138x5mro
wandb: Find logs at: ./wandb/run-20220325_202937-138x5mro/logs/debug.log
wandb: 

