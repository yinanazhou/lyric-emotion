Unloading StdEnv/2020

Due to MODULEPATH changes, the following have been reloaded:
  1) mii/1.1.1


The following have been reloaded with a version change:
  1) python/3.8.2 => python/3.7.4

Using base prefix '/cvmfs/soft.computecanada.ca/easybuild/software/2017/Core/python/3.7.4'
New python executable in /localscratch/yinan.29546396.0/env/bin/python
Installing setuptools, pip, wheel...
done.
Ignoring pip: markers 'python_version < "3"' don't match your environment
Looking in links: /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/nix/avx2, /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/nix/generic, /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic
Collecting pip
Installing collected packages: pip
  Found existing installation: pip 19.1.1
    Uninstalling pip-19.1.1:
      Successfully uninstalled pip-19.1.1
Successfully installed pip-21.2.3+computecanada
Looking in links: /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/nix/avx2, /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/nix/generic, /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/keras-2.8.0+computecanada-py2.py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/Keras_Preprocessing-1.1.2+computecanada-py3-none-any.whl
Requirement already satisfied: matplotlib in /cvmfs/soft.computecanada.ca/easybuild/software/2017/Core/scipy-stack/2019a/lib/python3.7/site-packages (from -r requirements.txt (line 3)) (3.0.2)
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/nltk-3.6.5+computecanada-py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/scikit_learn-0.22.1+computecanada-cp37-cp37m-linux_x86_64.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/tensorboard-2.3.0+computecanada-py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/tensorboard_plugin_wit-1.7.0+computecanada-py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/tensorflow_gpu-2.3.0+computecanada-cp37-cp37m-linux_x86_64.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/tensorflow_estimator-2.3.0+computecanada-py2.py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/tokenizers-0.5.2+computecanada-cp37-cp37m-linux_x86_64.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/nix/avx2/torch-1.4.0+computecanada-cp37-cp37m-linux_x86_64.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/torchtext-0.6.0+computecanada-py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/torchvision-0.8.2+computecanada-cp37-cp37m-linux_x86_64.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/transformers-2.5.1+computecanada-py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/urllib3-1.26.7+computecanada-py2.py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/joblib-1.1.0+computecanada-py2.py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/click-8.0.4+computecanada-py3-none-any.whl
ERROR: Could not find a version that satisfies the requirement regex>=2021.8.3 (from nltk) (from versions: 2018.1.10+computecanada, 2019.11.1+computecanada, 2020.11.13+computecanada)
ERROR: No matching distribution found for regex>=2021.8.3
Looking in links: /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/nix/avx2, /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/nix/generic, /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic
ERROR: Could not find a version that satisfies the requirement numpy==1.20.0+computacanada (from versions: 1.15.0+computecanada, 1.15.2+computecanada, 1.15.4+computecanada, 1.16.0+computecanada, 1.16.2+computecanada, 1.16.3+computecanada, 1.17.4+computecanada, 1.18.1+computecanada, 1.18.4+computecanada, 1.19.1+computecanada, 1.19.2+computecanada, 1.20.2+computecanada)
ERROR: No matching distribution found for numpy==1.20.0+computacanada
Looking in links: /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/nix/avx2, /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/nix/generic, /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/wandb-0.12.5+computecanada-py2.py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/GitPython-3.1.24+computecanada-py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/configparser-5.0.2+computecanada-py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/protobuf-3.19.4+computecanada-py2.py3-none-any.whl
Requirement already satisfied: requests<3,>=2.0.0 in /cvmfs/soft.computecanada.ca/easybuild/software/2017/Core/scipy-stack/2019a/lib/python3.7/site-packages (from wandb) (2.21.0)
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/promise-2.3+computecanada-py3-none-any.whl
Requirement already satisfied: python-dateutil>=2.6.1 in /cvmfs/soft.computecanada.ca/easybuild/software/2017/Core/scipy-stack/2019a/lib/python3.7/site-packages (from wandb) (2.7.5)
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/subprocess32-3.5.4+computecanada-py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/click-8.0.4+computecanada-py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/shortuuid-1.0.1+computecanada-py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/yaspin-2.1.0+computecanada-py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/six-1.16.0+computecanada-py2.py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/psutil-5.7.3+computecanada-cp37-cp37m-linux_x86_64.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/PyYAML-5.3.1+computecanada-cp37-cp37m-linux_x86_64.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/sentry_sdk-1.5.0+computecanada-py2.py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/docker_pycreds-0.4.0+computecanada-py2.py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/pathtools-0.1.2+computecanada-py3-none-any.whl
Requirement already satisfied: importlib-metadata in /cvmfs/soft.computecanada.ca/easybuild/software/2017/Core/scipy-stack/2019a/lib/python3.7/site-packages (from Click!=8.0.0,>=7.0->wandb) (0.8)
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/typing_extensions-4.1.1+computecanada-py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/gitdb-4.0.9+computecanada-py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/smmap-5.0.0+computecanada-py3-none-any.whl
Requirement already satisfied: urllib3<1.25,>=1.21.1 in /cvmfs/soft.computecanada.ca/easybuild/software/2017/Core/scipy-stack/2019a/lib/python3.7/site-packages (from requests<3,>=2.0.0->wandb) (1.24.1)
Requirement already satisfied: certifi>=2017.4.17 in /cvmfs/soft.computecanada.ca/easybuild/software/2017/Core/scipy-stack/2019a/lib/python3.7/site-packages (from requests<3,>=2.0.0->wandb) (2018.11.29)
Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /cvmfs/soft.computecanada.ca/easybuild/software/2017/Core/scipy-stack/2019a/lib/python3.7/site-packages (from requests<3,>=2.0.0->wandb) (3.0.4)
Requirement already satisfied: idna<2.9,>=2.5 in /cvmfs/soft.computecanada.ca/easybuild/software/2017/Core/scipy-stack/2019a/lib/python3.7/site-packages (from requests<3,>=2.0.0->wandb) (2.8)
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/termcolor-1.1.0+computecanada-py3-none-any.whl
Requirement already satisfied: zipp>=0.3.2 in /cvmfs/soft.computecanada.ca/easybuild/software/2017/Core/scipy-stack/2019a/lib/python3.7/site-packages (from importlib-metadata->Click!=8.0.0,>=7.0->wandb) (0.3.3)
Installing collected packages: smmap, typing-extensions, termcolor, six, gitdb, yaspin, subprocess32, shortuuid, sentry-sdk, PyYAML, psutil, protobuf, promise, pathtools, GitPython, docker-pycreds, configparser, Click, wandb
  Attempting uninstall: six
    Found existing installation: six 1.12.0
    Not uninstalling six at /cvmfs/soft.computecanada.ca/easybuild/software/2017/Core/scipy-stack/2019a/lib/python3.7/site-packages, outside environment /localscratch/yinan.29546396.0/env
    Can't uninstall 'six'. No files were found to uninstall.
Successfully installed Click-8.0.4+computecanada GitPython-3.1.24+computecanada PyYAML-5.3.1+computecanada configparser-5.0.2+computecanada docker-pycreds-0.4.0+computecanada gitdb-4.0.9+computecanada pathtools-0.1.2+computecanada promise-2.3+computecanada protobuf-3.19.4+computecanada psutil-5.7.3+computecanada sentry-sdk-1.5.0+computecanada shortuuid-1.0.1+computecanada six-1.16.0+computecanada smmap-5.0.0+computecanada subprocess32-3.5.4+computecanada termcolor-1.1.0+computecanada typing-extensions-4.1.1+computecanada wandb-0.12.5+computecanada yaspin-2.1.0+computecanada
Looking in links: /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/nix/avx2, /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/nix/generic, /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic
ERROR: Could not find a version that satisfies the requirement sagemaker (from versions: none)
ERROR: No matching distribution found for sagemaker
Looking in links: /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/nix/avx2, /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/nix/generic, /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/torch-1.9.1+computecanada-cp37-cp37m-linux_x86_64.whl
Requirement already satisfied: typing-extensions in /localscratch/yinan.29546396.0/env/lib/python3.7/site-packages (from torch) (4.1.1+computecanada)
Installing collected packages: torch
Successfully installed torch-1.9.1+computecanada
Looking in links: /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/nix/avx2, /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/nix/generic, /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/transformers-2.5.1+computecanada-py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/sentencepiece-0.1.91+computecanada-cp37-cp37m-linux_x86_64.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/regex-2020.11.13+computecanada-cp37-cp37m-linux_x86_64.whl
Requirement already satisfied: numpy in /cvmfs/soft.computecanada.ca/easybuild/software/2017/Core/scipy-stack/2019a/lib/python3.7/site-packages (from transformers==2.5.1+computecanada) (1.16.0)
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/filelock-3.4.2+computecanada-py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/boto3-1.21.14+computecanada-py3-none-any.whl
Requirement already satisfied: requests in /cvmfs/soft.computecanada.ca/easybuild/software/2017/Core/scipy-stack/2019a/lib/python3.7/site-packages (from transformers==2.5.1+computecanada) (2.21.0)
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/sacremoses-0.0.49+computecanada-py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/tqdm-4.63.1+computecanada-py2.py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/tokenizers-0.5.2+computecanada-cp37-cp37m-linux_x86_64.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/s3transfer-0.5.1+computecanada-py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/botocore-1.24.14+computecanada-py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/jmespath-0.10.0+computecanada-py2.py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/urllib3-1.26.8+computecanada-py2.py3-none-any.whl
Requirement already satisfied: python-dateutil<3.0.0,>=2.1 in /cvmfs/soft.computecanada.ca/easybuild/software/2017/Core/scipy-stack/2019a/lib/python3.7/site-packages (from botocore<1.25.0,>=1.24.14->boto3->transformers==2.5.1+computecanada) (2.7.5)
Requirement already satisfied: six>=1.5 in /localscratch/yinan.29546396.0/env/lib/python3.7/site-packages (from python-dateutil<3.0.0,>=2.1->botocore<1.25.0,>=1.24.14->boto3->transformers==2.5.1+computecanada) (1.16.0+computecanada)
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/requests-2.27.1+computecanada-py2.py3-none-any.whl
Requirement already satisfied: certifi>=2017.4.17 in /cvmfs/soft.computecanada.ca/easybuild/software/2017/Core/scipy-stack/2019a/lib/python3.7/site-packages (from requests->transformers==2.5.1+computecanada) (2018.11.29)
Requirement already satisfied: idna<4,>=2.5 in /cvmfs/soft.computecanada.ca/easybuild/software/2017/Core/scipy-stack/2019a/lib/python3.7/site-packages (from requests->transformers==2.5.1+computecanada) (2.8)
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/charset_normalizer-2.0.12+computecanada-py3-none-any.whl
Requirement already satisfied: click in /localscratch/yinan.29546396.0/env/lib/python3.7/site-packages (from sacremoses->transformers==2.5.1+computecanada) (8.0.4+computecanada)
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/joblib-1.1.0+computecanada-py2.py3-none-any.whl
Requirement already satisfied: importlib-metadata in /cvmfs/soft.computecanada.ca/easybuild/software/2017/Core/scipy-stack/2019a/lib/python3.7/site-packages (from click->sacremoses->transformers==2.5.1+computecanada) (0.8)
Requirement already satisfied: zipp>=0.3.2 in /cvmfs/soft.computecanada.ca/easybuild/software/2017/Core/scipy-stack/2019a/lib/python3.7/site-packages (from importlib-metadata->click->sacremoses->transformers==2.5.1+computecanada) (0.3.3)
Installing collected packages: urllib3, jmespath, botocore, tqdm, s3transfer, regex, joblib, charset-normalizer, tokenizers, sentencepiece, sacremoses, requests, filelock, boto3, transformers
  Attempting uninstall: urllib3
    Found existing installation: urllib3 1.24.1
    Not uninstalling urllib3 at /cvmfs/soft.computecanada.ca/easybuild/software/2017/Core/scipy-stack/2019a/lib/python3.7/site-packages, outside environment /localscratch/yinan.29546396.0/env
    Can't uninstall 'urllib3'. No files were found to uninstall.
  Attempting uninstall: requests
    Found existing installation: requests 2.21.0
    Not uninstalling requests at /cvmfs/soft.computecanada.ca/easybuild/software/2017/Core/scipy-stack/2019a/lib/python3.7/site-packages, outside environment /localscratch/yinan.29546396.0/env
    Can't uninstall 'requests'. No files were found to uninstall.
Successfully installed boto3-1.21.14+computecanada botocore-1.24.14+computecanada charset-normalizer-2.0.12+computecanada filelock-3.4.2+computecanada jmespath-0.10.0+computecanada joblib-1.1.0+computecanada regex-2020.11.13+computecanada requests-2.27.1+computecanada s3transfer-0.5.1+computecanada sacremoses-0.0.49+computecanada sentencepiece-0.1.91+computecanada tokenizers-0.5.2+computecanada tqdm-4.63.1+computecanada transformers-2.5.1+computecanada urllib3-1.26.8+computecanada
Looking in links: /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/nix/avx2, /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/nix/generic, /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/tensorflow_gpu-2.3.0+computecanada-cp37-cp37m-linux_x86_64.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/nix/avx2/h5py-2.10.0+computecanada-cp37-cp37m-linux_x86_64.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/tensorboard-2.8.0+computecanada-py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/nix/generic/scipy-1.4.1+computecanada-cp37-cp37m-linux_x86_64.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/tensorflow_estimator-2.3.0+computecanada-py2.py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/grpcio-1.38.0+computecanada-cp37-cp37m-linux_x86_64.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/absl_py-1.0.0+computecanada-py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/gast-0.3.3+computecanada-py3-none-any.whl
Requirement already satisfied: protobuf>=3.9.2 in /localscratch/yinan.29546396.0/env/lib/python3.7/site-packages (from tensorflow_gpu==2.3.0+computecanada) (3.19.4+computecanada)
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/opt_einsum-3.3.0+computecanada-py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/google_pasta-0.2.0+computecanada-py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/wrapt-1.11.2+computecanada-cp37-cp37m-linux_x86_64.whl
Requirement already satisfied: wheel>=0.26 in /localscratch/yinan.29546396.0/env/lib/python3.7/site-packages (from tensorflow_gpu==2.3.0+computecanada) (0.33.4)
Requirement already satisfied: termcolor>=1.1.0 in /localscratch/yinan.29546396.0/env/lib/python3.7/site-packages (from tensorflow_gpu==2.3.0+computecanada) (1.1.0+computecanada)
Requirement already satisfied: six>=1.12.0 in /localscratch/yinan.29546396.0/env/lib/python3.7/site-packages (from tensorflow_gpu==2.3.0+computecanada) (1.16.0+computecanada)
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/Keras_Preprocessing-1.1.2+computecanada-py3-none-any.whl
Requirement already satisfied: numpy<1.19.0,>=1.16.0 in /cvmfs/soft.computecanada.ca/easybuild/software/2017/Core/scipy-stack/2019a/lib/python3.7/site-packages (from tensorflow_gpu==2.3.0+computecanada) (1.16.0)
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/astunparse-1.6.3+computecanada-py2.py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/tensorboard_plugin_wit-1.8.0+computecanada-py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/google_auth-2.3.3+computecanada-py2.py3-none-any.whl
Requirement already satisfied: setuptools>=41.0.0 in /localscratch/yinan.29546396.0/env/lib/python3.7/site-packages (from tensorboard<3,>=2.3.0->tensorflow_gpu==2.3.0+computecanada) (41.0.1)
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/Werkzeug-2.0.3+computecanada-py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/Markdown-3.3.6+computecanada-py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/google_auth_oauthlib-0.4.6+computecanada-py2.py3-none-any.whl
Requirement already satisfied: requests<3,>=2.21.0 in /localscratch/yinan.29546396.0/env/lib/python3.7/site-packages (from tensorboard<3,>=2.3.0->tensorflow_gpu==2.3.0+computecanada) (2.27.1+computecanada)
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/tensorboard_data_server-0.6.1+computecanada-py3-none-linux_x86_64.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/cachetools-4.2.4+computecanada-py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/rsa-4.8+computecanada-py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/pyasn1_modules-0.2.8+computecanada-py2.py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/requests_oauthlib-1.3.0+computecanada-py2.py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/importlib_metadata-4.10.1+computecanada-py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/zipp-3.7.0+computecanada-py3-none-any.whl
Requirement already satisfied: typing-extensions>=3.6.4 in /localscratch/yinan.29546396.0/env/lib/python3.7/site-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard<3,>=2.3.0->tensorflow_gpu==2.3.0+computecanada) (4.1.1+computecanada)
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/pyasn1-0.4.8+computecanada-py2.py3-none-any.whl
Requirement already satisfied: idna<4,>=2.5 in /cvmfs/soft.computecanada.ca/easybuild/software/2017/Core/scipy-stack/2019a/lib/python3.7/site-packages (from requests<3,>=2.21.0->tensorboard<3,>=2.3.0->tensorflow_gpu==2.3.0+computecanada) (2.8)
Requirement already satisfied: charset-normalizer~=2.0.0 in /localscratch/yinan.29546396.0/env/lib/python3.7/site-packages (from requests<3,>=2.21.0->tensorboard<3,>=2.3.0->tensorflow_gpu==2.3.0+computecanada) (2.0.12+computecanada)
Requirement already satisfied: certifi>=2017.4.17 in /cvmfs/soft.computecanada.ca/easybuild/software/2017/Core/scipy-stack/2019a/lib/python3.7/site-packages (from requests<3,>=2.21.0->tensorboard<3,>=2.3.0->tensorflow_gpu==2.3.0+computecanada) (2018.11.29)
Requirement already satisfied: urllib3<1.27,>=1.21.1 in /localscratch/yinan.29546396.0/env/lib/python3.7/site-packages (from requests<3,>=2.21.0->tensorboard<3,>=2.3.0->tensorflow_gpu==2.3.0+computecanada) (1.26.8+computecanada)
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/oauthlib-3.1.1+computecanada-py2.py3-none-any.whl
Installing collected packages: pyasn1, zipp, rsa, pyasn1-modules, oauthlib, cachetools, requests-oauthlib, importlib-metadata, google-auth, werkzeug, tensorboard-plugin-wit, tensorboard-data-server, markdown, grpcio, google-auth-oauthlib, absl-py, wrapt, tensorflow-estimator, tensorboard, scipy, opt-einsum, keras-preprocessing, h5py, google-pasta, gast, astunparse, tensorflow-gpu
  Attempting uninstall: pyasn1
    Found existing installation: pyasn1 0.4.3
    Not uninstalling pyasn1 at /cvmfs/soft.computecanada.ca/easybuild/software/2017/Core/scipy-stack/2019a/lib/python3.7/site-packages, outside environment /localscratch/yinan.29546396.0/env
    Can't uninstall 'pyasn1'. No files were found to uninstall.
  Attempting uninstall: zipp
    Found existing installation: zipp 0.3.3
    Not uninstalling zipp at /cvmfs/soft.computecanada.ca/easybuild/software/2017/Core/scipy-stack/2019a/lib/python3.7/site-packages, outside environment /localscratch/yinan.29546396.0/env
    Can't uninstall 'zipp'. No files were found to uninstall.
  Attempting uninstall: importlib-metadata
    Found existing installation: importlib-metadata 0.8
    Not uninstalling importlib-metadata at /cvmfs/soft.computecanada.ca/easybuild/software/2017/Core/scipy-stack/2019a/lib/python3.7/site-packages, outside environment /localscratch/yinan.29546396.0/env
    Can't uninstall 'importlib-metadata'. No files were found to uninstall.
  Attempting uninstall: scipy
    Found existing installation: scipy 1.2.0
    Not uninstalling scipy at /cvmfs/soft.computecanada.ca/easybuild/software/2017/Core/scipy-stack/2019a/lib/python3.7/site-packages, outside environment /localscratch/yinan.29546396.0/env
    Can't uninstall 'scipy'. No files were found to uninstall.
Successfully installed absl-py-1.0.0+computecanada astunparse-1.6.3+computecanada cachetools-4.2.4+computecanada gast-0.3.3+computecanada google-auth-2.3.3+computecanada google-auth-oauthlib-0.4.6+computecanada google-pasta-0.2.0+computecanada grpcio-1.38.0+computecanada h5py-2.10.0+computecanada importlib-metadata-4.10.1+computecanada keras-preprocessing-1.1.2+computecanada markdown-3.3.6+computecanada oauthlib-3.1.1+computecanada opt-einsum-3.3.0+computecanada pyasn1-0.4.8+computecanada pyasn1-modules-0.2.8+computecanada requests-oauthlib-1.3.0+computecanada rsa-4.8+computecanada scipy-1.4.1+computecanada tensorboard-2.8.0+computecanada tensorboard-data-server-0.6.1+computecanada tensorboard-plugin-wit-1.8.0+computecanada tensorflow-estimator-2.3.0+computecanada tensorflow-gpu-2.3.0+computecanada werkzeug-2.0.3+computecanada wrapt-1.11.2+computecanada zipp-3.7.0+computecanada
Looking in links: /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/nix/avx2, /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/nix/generic, /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/keras-2.8.0+computecanada-py2.py3-none-any.whl
Installing collected packages: Keras
Successfully installed Keras-2.8.0+computecanada
Looking in links: /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/nix/avx2, /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/nix/generic, /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/urllib3-1.26.7+computecanada-py2.py3-none-any.whl
Installing collected packages: urllib3
  Attempting uninstall: urllib3
    Found existing installation: urllib3 1.26.8+computecanada
    Uninstalling urllib3-1.26.8+computecanada:
      Successfully uninstalled urllib3-1.26.8+computecanada
Successfully installed urllib3-1.26.7+computecanada
Looking in links: /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/nix/avx2, /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/nix/generic, /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/nltk-3.7+computecanada-py3-none-any.whl
Requirement already satisfied: tqdm in /localscratch/yinan.29546396.0/env/lib/python3.7/site-packages (from nltk) (4.63.1+computecanada)
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/nltk-3.6.5+computecanada-py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/nltk-3.6.3+computecanada-py3-none-any.whl
Requirement already satisfied: regex in /localscratch/yinan.29546396.0/env/lib/python3.7/site-packages (from nltk) (2020.11.13+computecanada)
Requirement already satisfied: joblib in /localscratch/yinan.29546396.0/env/lib/python3.7/site-packages (from nltk) (1.1.0+computecanada)
Requirement already satisfied: click in /localscratch/yinan.29546396.0/env/lib/python3.7/site-packages (from nltk) (8.0.4+computecanada)
Requirement already satisfied: importlib-metadata in /localscratch/yinan.29546396.0/env/lib/python3.7/site-packages (from click->nltk) (4.10.1+computecanada)
Requirement already satisfied: zipp>=0.5 in /localscratch/yinan.29546396.0/env/lib/python3.7/site-packages (from importlib-metadata->click->nltk) (3.7.0+computecanada)
Requirement already satisfied: typing-extensions>=3.6.4 in /localscratch/yinan.29546396.0/env/lib/python3.7/site-packages (from importlib-metadata->click->nltk) (4.1.1+computecanada)
Installing collected packages: nltk
Successfully installed nltk-3.6.3+computecanada
Looking in links: /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/nix/avx2, /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/nix/generic, /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/scikit_learn-0.22.1+computecanada-cp37-cp37m-linux_x86_64.whl
Requirement already satisfied: numpy>=1.11.0 in /cvmfs/soft.computecanada.ca/easybuild/software/2017/Core/scipy-stack/2019a/lib/python3.7/site-packages (from scikit-learn==0.22.1) (1.16.0)
Requirement already satisfied: joblib>=0.11 in /localscratch/yinan.29546396.0/env/lib/python3.7/site-packages (from scikit-learn==0.22.1) (1.1.0+computecanada)
Requirement already satisfied: scipy>=0.17.0 in /localscratch/yinan.29546396.0/env/lib/python3.7/site-packages (from scikit-learn==0.22.1) (1.4.1+computecanada)
Installing collected packages: scikit-learn
Successfully installed scikit-learn-0.22.1+computecanada
Looking in links: /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/nix/avx2, /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/nix/generic, /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic
Requirement already satisfied: tokenizers==0.5.2 in /localscratch/yinan.29546396.0/env/lib/python3.7/site-packages (0.5.2+computecanada)
wandb: Appending key for api.wandb.ai to your netrc file: /home/yinan/.netrc
Starting Task
2022-03-26 01:38:33.661188: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1
[nltk_data] Downloading package stopwords to /home/yinan/nltk_data...
[nltk_data]   Package stopwords is already up-to-date!
[nltk_data] Downloading package wordnet to /home/yinan/nltk_data...
[nltk_data]   Package wordnet is already up-to-date!
wandb: Currently logged in as: yinanazhou (use `wandb login --relogin` to force relogin)
wandb: wandb version 0.12.11 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
2022-03-26 01:38:48.205206: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1
wandb: Tracking run with wandb version 0.12.5
wandb: Syncing run fallen-jazz-3
wandb: ⭐️ View project at https://wandb.ai/yinanazhou/xl_512_bs_8_lr_1e06_es_5_lc_True_nr_False_sr_True_stem_False_lemma_True_repeat_1_fold_1
wandb: 🚀 View run at https://wandb.ai/yinanazhou/xl_512_bs_8_lr_1e06_es_5_lc_True_nr_False_sr_True_stem_False_lemma_True_repeat_1_fold_1/runs/u9zmn7rh
wandb: Run data is saved locally in /project/6002780/yinan/Thesis_MER_Lyrics/lyric-emotion/wandb/run-20220326_013846-u9zmn7rh
wandb: Run `wandb offline` to turn off syncing.

Validation loss decreased (inf --> 1.438662).  Saving model ...
Validation loss decreased (1.438662 --> 1.418969).  Saving model ...
Validation loss decreased (1.418969 --> 1.403382).  Saving model ...
Validation loss decreased (1.403382 --> 1.390048).  Saving model ...
Validation loss decreased (1.390048 --> 1.379928).  Saving model ...
Validation loss decreased (1.379928 --> 1.371191).  Saving model ...
Validation loss decreased (1.371191 --> 1.363661).  Saving model ...
Validation loss decreased (1.363661 --> 1.356854).  Saving model ...
Validation loss decreased (1.356854 --> 1.350653).  Saving model ...
Validation loss decreased (1.350653 --> 1.344162).  Saving model ...
Validation loss decreased (1.344162 --> 1.337356).  Saving model ...
Validation loss decreased (1.337356 --> 1.331363).  Saving model ...
Validation loss decreased (1.331363 --> 1.325025).  Saving model ...
Validation loss decreased (1.325025 --> 1.318984).  Saving model ...
Validation loss decreased (1.318984 --> 1.312663).  Saving model ...
Validation loss decreased (1.312663 --> 1.306021).  Saving model ...
Validation loss decreased (1.306021 --> 1.299364).  Saving model ...
Validation loss decreased (1.299364 --> 1.292628).  Saving model ...
Validation loss decreased (1.292628 --> 1.285848).  Saving model ...
Validation loss decreased (1.285848 --> 1.279659).  Saving model ...
Validation loss decreased (1.279659 --> 1.273118).  Saving model ...
Validation loss decreased (1.273118 --> 1.265195).  Saving model ...
Validation loss decreased (1.265195 --> 1.258462).  Saving model ...
Validation loss decreased (1.258462 --> 1.250862).  Saving model ...
Validation loss decreased (1.250862 --> 1.245325).  Saving model ...
Validation loss decreased (1.245325 --> 1.237701).  Saving model ...
Validation loss decreased (1.237701 --> 1.231093).  Saving model ...
Validation loss decreased (1.231093 --> 1.226174).  Saving model ...
Validation loss decreased (1.226174 --> 1.221484).  Saving model ...
Validation loss decreased (1.221484 --> 1.216581).  Saving model ...
Validation loss decreased (1.216581 --> 1.210763).  Saving model ...
Validation loss decreased (1.210763 --> 1.205853).  Saving model ...
Validation loss decreased (1.205853 --> 1.201370).  Saving model ...
Validation loss decreased (1.201370 --> 1.195136).  Saving model ...
Validation loss decreased (1.195136 --> 1.191259).  Saving model ...
Validation loss decreased (1.191259 --> 1.187036).  Saving model ...
Validation loss decreased (1.187036 --> 1.182244).  Saving model ...
Validation loss decreased (1.182244 --> 1.177507).  Saving model ...
Validation loss decreased (1.177507 --> 1.174492).  Saving model ...
Validation loss decreased (1.174492 --> 1.171837).  Saving model ...
Validation loss decreased (1.171837 --> 1.165009).  Saving model ...
Validation loss decreased (1.165009 --> 1.160841).  Saving model ...
Validation loss decreased (1.160841 --> 1.159077).  Saving model ...
Validation loss decreased (1.159077 --> 1.154768).  Saving model ...
Validation loss decreased (1.154768 --> 1.150731).  Saving model ...
Validation loss decreased (1.150731 --> 1.145090).  Saving model ...
Validation loss decreased (1.145090 --> 1.141891).  Saving model ...
Validation loss decreased (1.141891 --> 1.140450).  Saving model ...
Validation loss decreased (1.140450 --> 1.133511).  Saving model ...
Validation loss decreased (1.133511 --> 1.129204).  Saving model ...
Validation loss decreased (1.129204 --> 1.124862).  Saving model ...
Validation loss decreased (1.124862 --> 1.120329).  Saving model ...
Validation loss decreased (1.120329 --> 1.117900).  Saving model ...
Validation loss decreased (1.117900 --> 1.116377).  Saving model ...
Validation loss decreased (1.116377 --> 1.114637).  Saving model ...
Validation loss decreased (1.114637 --> 1.108824).  Saving model ...
Validation loss decreased (1.108824 --> 1.106498).  Saving model ...
Validation loss decreased (1.106498 --> 1.102776).  Saving model ...
Validation loss decreased (1.102776 --> 1.097893).  Saving model ...
Validation loss decreased (1.097893 --> 1.096522).  Saving model ...
Validation loss decreased (1.096522 --> 1.091725).  Saving model ...
Validation loss decreased (1.091725 --> 1.088873).  Saving model ...
Validation loss decreased (1.088873 --> 1.084478).  Saving model ...
Validation loss decreased (1.084478 --> 1.083351).  Saving model ...
Validation loss decreased (1.083351 --> 1.083036).  Saving model ...
Validation loss decreased (1.083036 --> 1.076852).  Saving model ...
EarlyStopping counter: 1 out of 5.0
Validation loss decreased (1.076852 --> 1.070606).  Saving model ...
Validation loss decreased (1.070606 --> 1.068511).  Saving model ...
Validation loss decreased (1.068511 --> 1.066234).  Saving model ...
Validation loss decreased (1.066234 --> 1.062005).  Saving model ...
Validation loss decreased (1.062005 --> 1.060731).  Saving model ...
Validation loss decreased (1.060731 --> 1.058138).  Saving model ...
Validation loss decreased (1.058138 --> 1.055929).  Saving model ...
Validation loss decreased (1.055929 --> 1.052316).  Saving model ...
Validation loss decreased (1.052316 --> 1.048966).  Saving model ...
Validation loss decreased (1.048966 --> 1.048540).  Saving model ...
Validation loss decreased (1.048540 --> 1.048481).  Saving model ...
Validation loss decreased (1.048481 --> 1.042755).  Saving model ...
Validation loss decreased (1.042755 --> 1.039268).  Saving model ...
Validation loss decreased (1.039268 --> 1.038113).  Saving model ...
Validation loss decreased (1.038113 --> 1.038083).  Saving model ...
Validation loss decreased (1.038083 --> 1.036442).  Saving model ...
Validation loss decreased (1.036442 --> 1.036103).  Saving model ...
Validation loss decreased (1.036103 --> 1.031876).  Saving model ...
Validation loss decreased (1.031876 --> 1.030939).  Saving model ...
Validation loss decreased (1.030939 --> 1.028169).  Saving model ...
Validation loss decreased (1.028169 --> 1.027279).  Saving model ...
Validation loss decreased (1.027279 --> 1.023100).  Saving model ...
Validation loss decreased (1.023100 --> 1.021130).  Saving model ...
Validation loss decreased (1.021130 --> 1.020388).  Saving model ...
Validation loss decreased (1.020388 --> 1.019426).  Saving model ...
Validation loss decreased (1.019426 --> 1.018741).  Saving model ...
EarlyStopping counter: 1 out of 5.0
Validation loss decreased (1.018741 --> 1.017610).  Saving model ...
Validation loss decreased (1.017610 --> 1.016525).  Saving model ...
Validation loss decreased (1.016525 --> 1.014403).  Saving model ...
Validation loss decreased (1.014403 --> 1.011787).  Saving model ...
Validation loss decreased (1.011787 --> 1.009583).  Saving model ...
Validation loss decreased (1.009583 --> 1.009387).  Saving model ...
Validation loss decreased (1.009387 --> 1.007883).  Saving model ...
EarlyStopping counter: 1 out of 5.0
Validation loss decreased (1.007883 --> 1.006802).  Saving model ...
Validation loss decreased (1.006802 --> 1.004851).  Saving model ...
Validation loss decreased (1.004851 --> 1.003764).  Saving model ...
Validation loss decreased (1.003764 --> 0.999239).  Saving model ...
Validation loss decreased (0.999239 --> 0.999113).  Saving model ...
Validation loss decreased (0.999113 --> 0.998331).  Saving model ...
Validation loss decreased (0.998331 --> 0.996616).  Saving model ...
Validation loss decreased (0.996616 --> 0.995545).  Saving model ...
EarlyStopping counter: 1 out of 5.0
EarlyStopping counter: 2 out of 5.0
EarlyStopping counter: 3 out of 5.0
Validation loss decreased (0.995545 --> 0.994521).  Saving model ...
EarlyStopping counter: 1 out of 5.0
Validation loss decreased (0.994521 --> 0.992453).  Saving model ...
Validation loss decreased (0.992453 --> 0.989705).  Saving model ...
Validation loss decreased (0.989705 --> 0.989427).  Saving model ...
EarlyStopping counter: 1 out of 5.0
Validation loss decreased (0.989427 --> 0.988035).  Saving model ...
Validation loss decreased (0.988035 --> 0.987830).  Saving model ...
EarlyStopping counter: 1 out of 5.0
Validation loss decreased (0.987830 --> 0.984172).  Saving model ...
EarlyStopping counter: 1 out of 5.0
Validation loss decreased (0.984172 --> 0.983785).  Saving model ...
EarlyStopping counter: 1 out of 5.0
EarlyStopping counter: 2 out of 5.0
Validation loss decreased (0.983785 --> 0.983343).  Saving model ...
EarlyStopping counter: 1 out of 5.0
EarlyStopping counter: 2 out of 5.0
EarlyStopping counter: 3 out of 5.0
EarlyStopping counter: 4 out of 5.0
EarlyStopping counter: 5 out of 5.0
/localscratch/yinan.29546396.0/env/lib/python3.7/site-packages/torch/nn/functional.py:1794: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.
  warnings.warn("nn.functional.tanh is deprecated. Use torch.tanh instead.")
/localscratch/yinan.29546396.0/env/lib/python3.7/site-packages/transformers/optimization.py:155: UserWarning: This overload of add_ is deprecated:
	add_(Number alpha, Tensor other)
Consider using one of the following signatures instead:
	add_(Tensor other, *, Number alpha) (Triggered internally at  ../torch/csrc/utils/python_arg_parser.cpp:1025.)
  exp_avg.mul_(beta1).add_(1.0 - beta1, grad)
wandb: Waiting for W&B process to finish, PID 206560... (success).
wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: \ 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: | 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: / 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: \ 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: | 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: / 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: \ 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: | 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: / 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb:                                                                                
wandb: Run history:
wandb:     e_F1 ▁▂▃▄▅▅▅▅▅▆▆▆▆▆▆▇▇▇▇▇▇▇▇▇▇▇▇▇▇█▇█████████
wandb:   e_loss ██▇▇▆▆▆▅▅▅▄▄▄▄▄▃▃▃▃▃▂▂▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁
wandb:     t_F1 ▁▁▂▃▃▃▄▄▄▅▅▅▆▆▆▆▆▆▆▆▆▆▇▇▇▇▇▇▇▇▇▇█▇█▇█▇██
wandb:   t_loss ██▇▇▇▇▆▆▆▅▅▅▅▄▄▄▄▄▃▃▃▃▃▃▃▃▂▂▂▂▂▂▂▂▂▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:     e_F1 57.64881
wandb:   e_loss 0.9847
wandb:     t_F1 70.67017
wandb:   t_loss 0.7554
wandb: 
wandb: Synced 4 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Synced fallen-jazz-3: https://wandb.ai/yinanazhou/xl_512_bs_8_lr_1e06_es_5_lc_True_nr_False_sr_True_stem_False_lemma_True_repeat_1_fold_1/runs/u9zmn7rh
wandb: Find logs at: ./wandb/run-20220326_013846-u9zmn7rh/logs/debug.log
wandb: 

wandb: wandb version 0.12.11 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
2022-03-26 03:03:44.777683: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1
wandb: Tracking run with wandb version 0.12.5
wandb: Syncing run stilted-haze-2
wandb: ⭐️ View project at https://wandb.ai/yinanazhou/xl_512_bs_8_lr_1e06_es_5_lc_True_nr_False_sr_True_stem_False_lemma_True_repeat_1_fold_2
wandb: 🚀 View run at https://wandb.ai/yinanazhou/xl_512_bs_8_lr_1e06_es_5_lc_True_nr_False_sr_True_stem_False_lemma_True_repeat_1_fold_2/runs/1ir57yzz
wandb: Run data is saved locally in /project/6002780/yinan/Thesis_MER_Lyrics/lyric-emotion/wandb/run-20220326_030342-1ir57yzz
wandb: Run `wandb offline` to turn off syncing.

Validation loss decreased (inf --> 1.453611).  Saving model ...
Validation loss decreased (1.453611 --> 1.430149).  Saving model ...
Validation loss decreased (1.430149 --> 1.411884).  Saving model ...
Validation loss decreased (1.411884 --> 1.397133).  Saving model ...
Validation loss decreased (1.397133 --> 1.386215).  Saving model ...
Validation loss decreased (1.386215 --> 1.377333).  Saving model ...
Validation loss decreased (1.377333 --> 1.369792).  Saving model ...
Validation loss decreased (1.369792 --> 1.363149).  Saving model ...
Validation loss decreased (1.363149 --> 1.356551).  Saving model ...
Validation loss decreased (1.356551 --> 1.351050).  Saving model ...
Validation loss decreased (1.351050 --> 1.345671).  Saving model ...
Validation loss decreased (1.345671 --> 1.340475).  Saving model ...
Validation loss decreased (1.340475 --> 1.334472).  Saving model ...
Validation loss decreased (1.334472 --> 1.327804).  Saving model ...
Validation loss decreased (1.327804 --> 1.321675).  Saving model ...
Validation loss decreased (1.321675 --> 1.315736).  Saving model ...
Validation loss decreased (1.315736 --> 1.308748).  Saving model ...
Validation loss decreased (1.308748 --> 1.302017).  Saving model ...
Validation loss decreased (1.302017 --> 1.294866).  Saving model ...
Validation loss decreased (1.294866 --> 1.288762).  Saving model ...
Validation loss decreased (1.288762 --> 1.282260).  Saving model ...
Validation loss decreased (1.282260 --> 1.274792).  Saving model ...
Validation loss decreased (1.274792 --> 1.266294).  Saving model ...
Validation loss decreased (1.266294 --> 1.258486).  Saving model ...
Validation loss decreased (1.258486 --> 1.251049).  Saving model ...
Validation loss decreased (1.251049 --> 1.243936).  Saving model ...
Validation loss decreased (1.243936 --> 1.236879).  Saving model ...
Validation loss decreased (1.236879 --> 1.229835).  Saving model ...
Validation loss decreased (1.229835 --> 1.221916).  Saving model ...
Validation loss decreased (1.221916 --> 1.214276).  Saving model ...
Validation loss decreased (1.214276 --> 1.206020).  Saving model ...
Validation loss decreased (1.206020 --> 1.198103).  Saving model ...
Validation loss decreased (1.198103 --> 1.190758).  Saving model ...
Validation loss decreased (1.190758 --> 1.182211).  Saving model ...
Validation loss decreased (1.182211 --> 1.175527).  Saving model ...
Validation loss decreased (1.175527 --> 1.167426).  Saving model ...
Validation loss decreased (1.167426 --> 1.161132).  Saving model ...
Validation loss decreased (1.161132 --> 1.154088).  Saving model ...
Validation loss decreased (1.154088 --> 1.145428).  Saving model ...
Validation loss decreased (1.145428 --> 1.136563).  Saving model ...
Validation loss decreased (1.136563 --> 1.128465).  Saving model ...
Validation loss decreased (1.128465 --> 1.122196).  Saving model ...
Validation loss decreased (1.122196 --> 1.116239).  Saving model ...
Validation loss decreased (1.116239 --> 1.110901).  Saving model ...
Validation loss decreased (1.110901 --> 1.104310).  Saving model ...
Validation loss decreased (1.104310 --> 1.098257).  Saving model ...
Validation loss decreased (1.098257 --> 1.092966).  Saving model ...
Validation loss decreased (1.092966 --> 1.086839).  Saving model ...
Validation loss decreased (1.086839 --> 1.078171).  Saving model ...
Validation loss decreased (1.078171 --> 1.073037).  Saving model ...
Validation loss decreased (1.073037 --> 1.066867).  Saving model ...
Validation loss decreased (1.066867 --> 1.061725).  Saving model ...
Validation loss decreased (1.061725 --> 1.055423).  Saving model ...
Validation loss decreased (1.055423 --> 1.050368).  Saving model ...
Validation loss decreased (1.050368 --> 1.044760).  Saving model ...
Validation loss decreased (1.044760 --> 1.040062).  Saving model ...
Validation loss decreased (1.040062 --> 1.037171).  Saving model ...
Validation loss decreased (1.037171 --> 1.032472).  Saving model ...
Validation loss decreased (1.032472 --> 1.026905).  Saving model ...
Validation loss decreased (1.026905 --> 1.022863).  Saving model ...
Validation loss decreased (1.022863 --> 1.018831).  Saving model ...
Validation loss decreased (1.018831 --> 1.014685).  Saving model ...
Validation loss decreased (1.014685 --> 1.011119).  Saving model ...
Validation loss decreased (1.011119 --> 1.007206).  Saving model ...
Validation loss decreased (1.007206 --> 1.003640).  Saving model ...
Validation loss decreased (1.003640 --> 1.000182).  Saving model ...
Validation loss decreased (1.000182 --> 0.995259).  Saving model ...
Validation loss decreased (0.995259 --> 0.992020).  Saving model ...
Validation loss decreased (0.992020 --> 0.988202).  Saving model ...
Validation loss decreased (0.988202 --> 0.985295).  Saving model ...
Validation loss decreased (0.985295 --> 0.982673).  Saving model ...
Validation loss decreased (0.982673 --> 0.979976).  Saving model ...
Validation loss decreased (0.979976 --> 0.978231).  Saving model ...
Validation loss decreased (0.978231 --> 0.975384).  Saving model ...
Validation loss decreased (0.975384 --> 0.973922).  Saving model ...
Validation loss decreased (0.973922 --> 0.967557).  Saving model ...
Validation loss decreased (0.967557 --> 0.963962).  Saving model ...
Validation loss decreased (0.963962 --> 0.962626).  Saving model ...
Validation loss decreased (0.962626 --> 0.958866).  Saving model ...
Validation loss decreased (0.958866 --> 0.955792).  Saving model ...
EarlyStopping counter: 1 out of 5.0
Validation loss decreased (0.955792 --> 0.952007).  Saving model ...
Validation loss decreased (0.952007 --> 0.951361).  Saving model ...
Validation loss decreased (0.951361 --> 0.948965).  Saving model ...
Validation loss decreased (0.948965 --> 0.945870).  Saving model ...
Validation loss decreased (0.945870 --> 0.943498).  Saving model ...
Validation loss decreased (0.943498 --> 0.941829).  Saving model ...
Validation loss decreased (0.941829 --> 0.938664).  Saving model ...
EarlyStopping counter: 1 out of 5.0
Validation loss decreased (0.938664 --> 0.937419).  Saving model ...
Validation loss decreased (0.937419 --> 0.934950).  Saving model ...
Validation loss decreased (0.934950 --> 0.931595).  Saving model ...
Validation loss decreased (0.931595 --> 0.930222).  Saving model ...
EarlyStopping counter: 1 out of 5.0
Validation loss decreased (0.930222 --> 0.927504).  Saving model ...
Validation loss decreased (0.927504 --> 0.926849).  Saving model ...
EarlyStopping counter: 1 out of 5.0
Validation loss decreased (0.926849 --> 0.925147).  Saving model ...
Validation loss decreased (0.925147 --> 0.924308).  Saving model ...
Validation loss decreased (0.924308 --> 0.921704).  Saving model ...
Validation loss decreased (0.921704 --> 0.920226).  Saving model ...
EarlyStopping counter: 1 out of 5.0
EarlyStopping counter: 2 out of 5.0
EarlyStopping counter: 3 out of 5.0
Validation loss decreased (0.920226 --> 0.918228).  Saving model ...
Validation loss decreased (0.918228 --> 0.917565).  Saving model ...
Validation loss decreased (0.917565 --> 0.916350).  Saving model ...
Validation loss decreased (0.916350 --> 0.915461).  Saving model ...
EarlyStopping counter: 1 out of 5.0
Validation loss decreased (0.915461 --> 0.913031).  Saving model ...
Validation loss decreased (0.913031 --> 0.912145).  Saving model ...
EarlyStopping counter: 1 out of 5.0
EarlyStopping counter: 2 out of 5.0
Validation loss decreased (0.912145 --> 0.912057).  Saving model ...
Validation loss decreased (0.912057 --> 0.910891).  Saving model ...
Validation loss decreased (0.910891 --> 0.909338).  Saving model ...
EarlyStopping counter: 1 out of 5.0
EarlyStopping counter: 2 out of 5.0
EarlyStopping counter: 3 out of 5.0
EarlyStopping counter: 4 out of 5.0
EarlyStopping counter: 5 out of 5.0
/localscratch/yinan.29546396.0/env/lib/python3.7/site-packages/torch/nn/functional.py:1794: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.
  warnings.warn("nn.functional.tanh is deprecated. Use torch.tanh instead.")
wandb: Waiting for W&B process to finish, PID 211228... (success).
wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: \ 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: | 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: / 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: \ 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: | 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: / 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: \ 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: | 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: / 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb:                                                                                
wandb: Run history:
wandb:     e_F1 ▁▃▃▄▄▄▅▅▅▅▆▆▆▇▇▇▇▇▇▇█▇▇▇████████████████
wandb:   e_loss █▇▇▇▆▆▆▆▅▅▅▅▄▄▄▃▃▃▃▃▂▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁
wandb:     t_F1 ▁▁▂▂▃▃▃▄▄▄▄▅▅▅▅▅▆▆▆▆▆▆▆▇▇▇▇▇▇▇▇▇▇█▇█▇███
wandb:   t_loss ██▇▇▇▇▇▆▆▆▆▆▅▅▅▄▄▄▄▄▄▄▃▃▃▃▃▃▂▂▂▂▂▂▂▂▁▁▁▁
wandb: 
wandb: Run summary:
wandb:     e_F1 60.68126
wandb:   e_loss 0.90957
wandb:     t_F1 71.20303
wandb:   t_loss 0.77824
wandb: 
wandb: Synced 4 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Synced stilted-haze-2: https://wandb.ai/yinanazhou/xl_512_bs_8_lr_1e06_es_5_lc_True_nr_False_sr_True_stem_False_lemma_True_repeat_1_fold_2/runs/1ir57yzz
wandb: Find logs at: ./wandb/run-20220326_030342-1ir57yzz/logs/debug.log
wandb: 

wandb: wandb version 0.12.11 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
2022-03-26 04:23:48.201525: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1
wandb: Tracking run with wandb version 0.12.5
wandb: Syncing run warm-glitter-2
wandb: ⭐️ View project at https://wandb.ai/yinanazhou/xl_512_bs_8_lr_1e06_es_5_lc_True_nr_False_sr_True_stem_False_lemma_True_repeat_2_fold_1
wandb: 🚀 View run at https://wandb.ai/yinanazhou/xl_512_bs_8_lr_1e06_es_5_lc_True_nr_False_sr_True_stem_False_lemma_True_repeat_2_fold_1/runs/3xr73ry4
wandb: Run data is saved locally in /project/6002780/yinan/Thesis_MER_Lyrics/lyric-emotion/wandb/run-20220326_042345-3xr73ry4
wandb: Run `wandb offline` to turn off syncing.

Validation loss decreased (inf --> 1.421546).  Saving model ...
Validation loss decreased (1.421546 --> 1.409288).  Saving model ...
Validation loss decreased (1.409288 --> 1.400155).  Saving model ...
Validation loss decreased (1.400155 --> 1.392557).  Saving model ...
Validation loss decreased (1.392557 --> 1.386105).  Saving model ...
Validation loss decreased (1.386105 --> 1.380498).  Saving model ...
Validation loss decreased (1.380498 --> 1.374758).  Saving model ...
Validation loss decreased (1.374758 --> 1.369887).  Saving model ...
Validation loss decreased (1.369887 --> 1.365103).  Saving model ...
Validation loss decreased (1.365103 --> 1.360771).  Saving model ...
Validation loss decreased (1.360771 --> 1.355470).  Saving model ...
Validation loss decreased (1.355470 --> 1.350523).  Saving model ...
Validation loss decreased (1.350523 --> 1.345695).  Saving model ...
Validation loss decreased (1.345695 --> 1.340437).  Saving model ...
Validation loss decreased (1.340437 --> 1.335104).  Saving model ...
Validation loss decreased (1.335104 --> 1.329453).  Saving model ...
Validation loss decreased (1.329453 --> 1.323407).  Saving model ...
Validation loss decreased (1.323407 --> 1.317099).  Saving model ...
Validation loss decreased (1.317099 --> 1.310589).  Saving model ...
Validation loss decreased (1.310589 --> 1.302963).  Saving model ...
Validation loss decreased (1.302963 --> 1.296176).  Saving model ...
Validation loss decreased (1.296176 --> 1.288339).  Saving model ...
Validation loss decreased (1.288339 --> 1.279663).  Saving model ...
Validation loss decreased (1.279663 --> 1.271323).  Saving model ...
Validation loss decreased (1.271323 --> 1.262924).  Saving model ...
Validation loss decreased (1.262924 --> 1.254474).  Saving model ...
Validation loss decreased (1.254474 --> 1.247741).  Saving model ...
Validation loss decreased (1.247741 --> 1.239785).  Saving model ...
Validation loss decreased (1.239785 --> 1.230135).  Saving model ...
Validation loss decreased (1.230135 --> 1.222580).  Saving model ...
Validation loss decreased (1.222580 --> 1.215277).  Saving model ...
Validation loss decreased (1.215277 --> 1.207120).  Saving model ...
Validation loss decreased (1.207120 --> 1.198412).  Saving model ...
Validation loss decreased (1.198412 --> 1.189801).  Saving model ...
Validation loss decreased (1.189801 --> 1.181880).  Saving model ...
Validation loss decreased (1.181880 --> 1.174854).  Saving model ...
Validation loss decreased (1.174854 --> 1.166749).  Saving model ...
Validation loss decreased (1.166749 --> 1.159186).  Saving model ...
Validation loss decreased (1.159186 --> 1.151910).  Saving model ...
Validation loss decreased (1.151910 --> 1.146092).  Saving model ...
Validation loss decreased (1.146092 --> 1.139443).  Saving model ...
Validation loss decreased (1.139443 --> 1.132305).  Saving model ...
Validation loss decreased (1.132305 --> 1.125698).  Saving model ...
Validation loss decreased (1.125698 --> 1.119815).  Saving model ...
Validation loss decreased (1.119815 --> 1.113614).  Saving model ...
Validation loss decreased (1.113614 --> 1.107813).  Saving model ...
Validation loss decreased (1.107813 --> 1.102480).  Saving model ...
Validation loss decreased (1.102480 --> 1.097465).  Saving model ...
Validation loss decreased (1.097465 --> 1.091484).  Saving model ...
Validation loss decreased (1.091484 --> 1.085607).  Saving model ...
Validation loss decreased (1.085607 --> 1.081757).  Saving model ...
Validation loss decreased (1.081757 --> 1.076847).  Saving model ...
Validation loss decreased (1.076847 --> 1.072915).  Saving model ...
Validation loss decreased (1.072915 --> 1.068632).  Saving model ...
Validation loss decreased (1.068632 --> 1.065271).  Saving model ...
Validation loss decreased (1.065271 --> 1.060414).  Saving model ...
Validation loss decreased (1.060414 --> 1.055888).  Saving model ...
Validation loss decreased (1.055888 --> 1.051520).  Saving model ...
Validation loss decreased (1.051520 --> 1.046782).  Saving model ...
Validation loss decreased (1.046782 --> 1.044926).  Saving model ...
Validation loss decreased (1.044926 --> 1.042947).  Saving model ...
Validation loss decreased (1.042947 --> 1.038908).  Saving model ...
Validation loss decreased (1.038908 --> 1.037124).  Saving model ...
Validation loss decreased (1.037124 --> 1.033501).  Saving model ...
Validation loss decreased (1.033501 --> 1.030939).  Saving model ...
Validation loss decreased (1.030939 --> 1.027258).  Saving model ...
Validation loss decreased (1.027258 --> 1.023914).  Saving model ...
Validation loss decreased (1.023914 --> 1.020798).  Saving model ...
Validation loss decreased (1.020798 --> 1.017349).  Saving model ...
Validation loss decreased (1.017349 --> 1.016146).  Saving model ...
Validation loss decreased (1.016146 --> 1.011982).  Saving model ...
Validation loss decreased (1.011982 --> 1.009827).  Saving model ...
Validation loss decreased (1.009827 --> 1.008243).  Saving model ...
Validation loss decreased (1.008243 --> 1.006883).  Saving model ...
Validation loss decreased (1.006883 --> 1.004019).  Saving model ...
Validation loss decreased (1.004019 --> 1.000461).  Saving model ...
Validation loss decreased (1.000461 --> 0.998731).  Saving model ...
Validation loss decreased (0.998731 --> 0.996089).  Saving model ...
Validation loss decreased (0.996089 --> 0.995473).  Saving model ...
Validation loss decreased (0.995473 --> 0.993511).  Saving model ...
Validation loss decreased (0.993511 --> 0.991364).  Saving model ...
Validation loss decreased (0.991364 --> 0.990815).  Saving model ...
Validation loss decreased (0.990815 --> 0.989219).  Saving model ...
Validation loss decreased (0.989219 --> 0.988271).  Saving model ...
Validation loss decreased (0.988271 --> 0.988131).  Saving model ...
Validation loss decreased (0.988131 --> 0.985382).  Saving model ...
Validation loss decreased (0.985382 --> 0.983208).  Saving model ...
Validation loss decreased (0.983208 --> 0.981044).  Saving model ...
Validation loss decreased (0.981044 --> 0.978961).  Saving model ...
Validation loss decreased (0.978961 --> 0.978073).  Saving model ...
Validation loss decreased (0.978073 --> 0.976288).  Saving model ...
Validation loss decreased (0.976288 --> 0.975165).  Saving model ...
Validation loss decreased (0.975165 --> 0.974110).  Saving model ...
Validation loss decreased (0.974110 --> 0.972476).  Saving model ...
Validation loss decreased (0.972476 --> 0.969769).  Saving model ...
EarlyStopping counter: 1 out of 5.0
EarlyStopping counter: 2 out of 5.0
EarlyStopping counter: 3 out of 5.0
Validation loss decreased (0.969769 --> 0.968767).  Saving model ...
Validation loss decreased (0.968767 --> 0.966744).  Saving model ...
EarlyStopping counter: 1 out of 5.0
Validation loss decreased (0.966744 --> 0.965897).  Saving model ...
EarlyStopping counter: 1 out of 5.0
EarlyStopping counter: 2 out of 5.0
Validation loss decreased (0.965897 --> 0.965318).  Saving model ...
EarlyStopping counter: 1 out of 5.0
Validation loss decreased (0.965318 --> 0.964825).  Saving model ...
Validation loss decreased (0.964825 --> 0.964805).  Saving model ...
Validation loss decreased (0.964805 --> 0.964664).  Saving model ...
EarlyStopping counter: 1 out of 5.0
Validation loss decreased (0.964664 --> 0.964159).  Saving model ...
Validation loss decreased (0.964159 --> 0.963356).  Saving model ...
EarlyStopping counter: 1 out of 5.0
EarlyStopping counter: 2 out of 5.0
Validation loss decreased (0.963356 --> 0.962389).  Saving model ...
EarlyStopping counter: 1 out of 5.0
Validation loss decreased (0.962389 --> 0.962322).  Saving model ...
Validation loss decreased (0.962322 --> 0.961649).  Saving model ...
Validation loss decreased (0.961649 --> 0.960515).  Saving model ...
EarlyStopping counter: 1 out of 5.0
EarlyStopping counter: 2 out of 5.0
EarlyStopping counter: 3 out of 5.0
EarlyStopping counter: 4 out of 5.0
EarlyStopping counter: 5 out of 5.0
/localscratch/yinan.29546396.0/env/lib/python3.7/site-packages/torch/nn/functional.py:1794: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.
  warnings.warn("nn.functional.tanh is deprecated. Use torch.tanh instead.")
wandb: Waiting for W&B process to finish, PID 215506... (success).
wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: \ 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: | 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: / 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: \ 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: | 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb:                                                                                
wandb: Run history:
wandb:     e_F1 ▁▂▃▄▅▆▆▆▆▇▇▇▇▇▇▇▇▇▇▇████████████████████
wandb:   e_loss ██▇▇▇▇▆▆▅▅▅▄▄▄▃▃▃▃▂▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:     t_F1 ▁▁▂▃▃▃▃▄▄▄▅▅▅▅▅▆▆▆▇▇▇▇▇▇▆▇▇▇▇▇█▇██▇█▇███
wandb:   t_loss ███▇▇▇▇▇▇▆▆▆▆▅▅▅▄▄▄▄▃▃▃▃▃▃▂▂▂▂▂▂▂▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:     e_F1 59.56377
wandb:   e_loss 0.96092
wandb:     t_F1 71.50089
wandb:   t_loss 0.78487
wandb: 
wandb: Synced 4 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Synced warm-glitter-2: https://wandb.ai/yinanazhou/xl_512_bs_8_lr_1e06_es_5_lc_True_nr_False_sr_True_stem_False_lemma_True_repeat_2_fold_1/runs/3xr73ry4
wandb: Find logs at: ./wandb/run-20220326_042345-3xr73ry4/logs/debug.log
wandb: 

wandb: wandb version 0.12.11 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
2022-03-26 05:45:46.348446: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1
wandb: Tracking run with wandb version 0.12.5
wandb: Syncing run stoic-moon-1
wandb: ⭐️ View project at https://wandb.ai/yinanazhou/xl_512_bs_8_lr_1e06_es_5_lc_True_nr_False_sr_True_stem_False_lemma_True_repeat_2_fold_2
wandb: 🚀 View run at https://wandb.ai/yinanazhou/xl_512_bs_8_lr_1e06_es_5_lc_True_nr_False_sr_True_stem_False_lemma_True_repeat_2_fold_2/runs/3ag8w7ru
wandb: Run data is saved locally in /project/6002780/yinan/Thesis_MER_Lyrics/lyric-emotion/wandb/run-20220326_054543-3ag8w7ru
wandb: Run `wandb offline` to turn off syncing.

Validation loss decreased (inf --> 1.390284).  Saving model ...
Validation loss decreased (1.390284 --> 1.383929).  Saving model ...
Validation loss decreased (1.383929 --> 1.378293).  Saving model ...
Validation loss decreased (1.378293 --> 1.373224).  Saving model ...
Validation loss decreased (1.373224 --> 1.368749).  Saving model ...
Validation loss decreased (1.368749 --> 1.364761).  Saving model ...
Validation loss decreased (1.364761 --> 1.360920).  Saving model ...
Validation loss decreased (1.360920 --> 1.356726).  Saving model ...
Validation loss decreased (1.356726 --> 1.352415).  Saving model ...
Validation loss decreased (1.352415 --> 1.348254).  Saving model ...
Validation loss decreased (1.348254 --> 1.344079).  Saving model ...
Validation loss decreased (1.344079 --> 1.339610).  Saving model ...
Validation loss decreased (1.339610 --> 1.335097).  Saving model ...
Validation loss decreased (1.335097 --> 1.330497).  Saving model ...
Validation loss decreased (1.330497 --> 1.325772).  Saving model ...
Validation loss decreased (1.325772 --> 1.320916).  Saving model ...
Validation loss decreased (1.320916 --> 1.315555).  Saving model ...
Validation loss decreased (1.315555 --> 1.309522).  Saving model ...
Validation loss decreased (1.309522 --> 1.303812).  Saving model ...
Validation loss decreased (1.303812 --> 1.297434).  Saving model ...
Validation loss decreased (1.297434 --> 1.289523).  Saving model ...
Validation loss decreased (1.289523 --> 1.282150).  Saving model ...
Validation loss decreased (1.282150 --> 1.274617).  Saving model ...
Validation loss decreased (1.274617 --> 1.265553).  Saving model ...
Validation loss decreased (1.265553 --> 1.256114).  Saving model ...
Validation loss decreased (1.256114 --> 1.247165).  Saving model ...
Validation loss decreased (1.247165 --> 1.237988).  Saving model ...
Validation loss decreased (1.237988 --> 1.228591).  Saving model ...
Validation loss decreased (1.228591 --> 1.219947).  Saving model ...
Validation loss decreased (1.219947 --> 1.212002).  Saving model ...
Validation loss decreased (1.212002 --> 1.205540).  Saving model ...
Validation loss decreased (1.205540 --> 1.196821).  Saving model ...
Validation loss decreased (1.196821 --> 1.188471).  Saving model ...
Validation loss decreased (1.188471 --> 1.182710).  Saving model ...
Validation loss decreased (1.182710 --> 1.175035).  Saving model ...
Validation loss decreased (1.175035 --> 1.168654).  Saving model ...
Validation loss decreased (1.168654 --> 1.162049).  Saving model ...
Validation loss decreased (1.162049 --> 1.158593).  Saving model ...
Validation loss decreased (1.158593 --> 1.152175).  Saving model ...
Validation loss decreased (1.152175 --> 1.147354).  Saving model ...
Validation loss decreased (1.147354 --> 1.140887).  Saving model ...
Validation loss decreased (1.140887 --> 1.134258).  Saving model ...
Validation loss decreased (1.134258 --> 1.128701).  Saving model ...
Validation loss decreased (1.128701 --> 1.122947).  Saving model ...
Validation loss decreased (1.122947 --> 1.116642).  Saving model ...
Validation loss decreased (1.116642 --> 1.109700).  Saving model ...
Validation loss decreased (1.109700 --> 1.106895).  Saving model ...
Validation loss decreased (1.106895 --> 1.100854).  Saving model ...
Validation loss decreased (1.100854 --> 1.094397).  Saving model ...
Validation loss decreased (1.094397 --> 1.091016).  Saving model ...
Validation loss decreased (1.091016 --> 1.086452).  Saving model ...
Validation loss decreased (1.086452 --> 1.081813).  Saving model ...
Validation loss decreased (1.081813 --> 1.075144).  Saving model ...
Validation loss decreased (1.075144 --> 1.069993).  Saving model ...
Validation loss decreased (1.069993 --> 1.064389).  Saving model ...
Validation loss decreased (1.064389 --> 1.060625).  Saving model ...
Validation loss decreased (1.060625 --> 1.055266).  Saving model ...
Validation loss decreased (1.055266 --> 1.050495).  Saving model ...
Validation loss decreased (1.050495 --> 1.045409).  Saving model ...
Validation loss decreased (1.045409 --> 1.041841).  Saving model ...
Validation loss decreased (1.041841 --> 1.040014).  Saving model ...
Validation loss decreased (1.040014 --> 1.034617).  Saving model ...
Validation loss decreased (1.034617 --> 1.030695).  Saving model ...
Validation loss decreased (1.030695 --> 1.027488).  Saving model ...
Validation loss decreased (1.027488 --> 1.026657).  Saving model ...
Validation loss decreased (1.026657 --> 1.024666).  Saving model ...
Validation loss decreased (1.024666 --> 1.019595).  Saving model ...
Validation loss decreased (1.019595 --> 1.013739).  Saving model ...
Validation loss decreased (1.013739 --> 1.010957).  Saving model ...
Validation loss decreased (1.010957 --> 1.007407).  Saving model ...
Validation loss decreased (1.007407 --> 1.005534).  Saving model ...
Validation loss decreased (1.005534 --> 1.000776).  Saving model ...
Validation loss decreased (1.000776 --> 0.996280).  Saving model ...
Validation loss decreased (0.996280 --> 0.994662).  Saving model ...
Validation loss decreased (0.994662 --> 0.991646).  Saving model ...
Validation loss decreased (0.991646 --> 0.988471).  Saving model ...
Validation loss decreased (0.988471 --> 0.984628).  Saving model ...
Validation loss decreased (0.984628 --> 0.983518).  Saving model ...
Validation loss decreased (0.983518 --> 0.979742).  Saving model ...
Validation loss decreased (0.979742 --> 0.977805).  Saving model ...
Validation loss decreased (0.977805 --> 0.974390).  Saving model ...
Validation loss decreased (0.974390 --> 0.972051).  Saving model ...
Validation loss decreased (0.972051 --> 0.969250).  Saving model ...
Validation loss decreased (0.969250 --> 0.967670).  Saving model ...
Validation loss decreased (0.967670 --> 0.966366).  Saving model ...
Validation loss decreased (0.966366 --> 0.963457).  Saving model ...
Validation loss decreased (0.963457 --> 0.960741).  Saving model ...
EarlyStopping counter: 1 out of 5.0
Validation loss decreased (0.960741 --> 0.957774).  Saving model ...
Validation loss decreased (0.957774 --> 0.955595).  Saving model ...
Validation loss decreased (0.955595 --> 0.951052).  Saving model ...
Validation loss decreased (0.951052 --> 0.948782).  Saving model ...
Validation loss decreased (0.948782 --> 0.946899).  Saving model ...
Validation loss decreased (0.946899 --> 0.945447).  Saving model ...
Validation loss decreased (0.945447 --> 0.944037).  Saving model ...
Validation loss decreased (0.944037 --> 0.941874).  Saving model ...
EarlyStopping counter: 1 out of 5.0
Validation loss decreased (0.941874 --> 0.941388).  Saving model ...
Validation loss decreased (0.941388 --> 0.939555).  Saving model ...
Validation loss decreased (0.939555 --> 0.938534).  Saving model ...
Validation loss decreased (0.938534 --> 0.936628).  Saving model ...
Validation loss decreased (0.936628 --> 0.935299).  Saving model ...
Validation loss decreased (0.935299 --> 0.934562).  Saving model ...
Validation loss decreased (0.934562 --> 0.933135).  Saving model ...
Validation loss decreased (0.933135 --> 0.931223).  Saving model ...
Validation loss decreased (0.931223 --> 0.929429).  Saving model ...
Validation loss decreased (0.929429 --> 0.929286).  Saving model ...
Validation loss decreased (0.929286 --> 0.928424).  Saving model ...
Validation loss decreased (0.928424 --> 0.926903).  Saving model ...
Validation loss decreased (0.926903 --> 0.926272).  Saving model ...
Validation loss decreased (0.926272 --> 0.924541).  Saving model ...
EarlyStopping counter: 1 out of 5.0
Validation loss decreased (0.924541 --> 0.921938).  Saving model ...
Validation loss decreased (0.921938 --> 0.920677).  Saving model ...
Validation loss decreased (0.920677 --> 0.920139).  Saving model ...
Validation loss decreased (0.920139 --> 0.917505).  Saving model ...
Validation loss decreased (0.917505 --> 0.916380).  Saving model ...
EarlyStopping counter: 1 out of 5.0
EarlyStopping counter: 2 out of 5.0
Validation loss decreased (0.916380 --> 0.916352).  Saving model ...
Validation loss decreased (0.916352 --> 0.915654).  Saving model ...
Validation loss decreased (0.915654 --> 0.913119).  Saving model ...
Validation loss decreased (0.913119 --> 0.912493).  Saving model ...
Validation loss decreased (0.912493 --> 0.911610).  Saving model ...
EarlyStopping counter: 1 out of 5.0
EarlyStopping counter: 2 out of 5.0
EarlyStopping counter: 3 out of 5.0
EarlyStopping counter: 4 out of 5.0
EarlyStopping counter: 5 out of 5.0
/localscratch/yinan.29546396.0/env/lib/python3.7/site-packages/torch/nn/functional.py:1794: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.
  warnings.warn("nn.functional.tanh is deprecated. Use torch.tanh instead.")
wandb: Waiting for W&B process to finish, PID 219871... (success).
wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: \ 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: | 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: / 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: \ 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: | 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: / 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: \ 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: | 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: / 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: \ 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb:                                                                                
wandb: Run history:
wandb:     e_F1 ▁▂▃▃▃▄▄▅▅▅▆▆▆▆▆▇▇▇▇▇▇▇▇▇▇▇██████████████
wandb:   e_loss ███▇▇▇▇▆▆▅▅▅▄▄▄▄▄▃▃▃▃▃▂▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁
wandb:     t_F1 ▁▁▃▃▂▃▃▄▃▄▅▅▅▅▆▅▆▆▆▇▆▆▇▆▇▇▇▆▇▇█▇█▇█▇▇▇██
wandb:   t_loss ███▇▇▇▇▇▇▆▆▆▅▅▅▅▄▄▄▄▄▃▃▃▃▃▃▃▂▃▂▂▂▂▂▂▂▁▁▁
wandb: 
wandb: Run summary:
wandb:     e_F1 62.28254
wandb:   e_loss 0.91247
wandb:     t_F1 73.8906
wandb:   t_loss 0.75294
wandb: 
wandb: Synced 4 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Synced stoic-moon-1: https://wandb.ai/yinanazhou/xl_512_bs_8_lr_1e06_es_5_lc_True_nr_False_sr_True_stem_False_lemma_True_repeat_2_fold_2/runs/3ag8w7ru
wandb: Find logs at: ./wandb/run-20220326_054543-3ag8w7ru/logs/debug.log
wandb: 

wandb: wandb version 0.12.11 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
2022-03-26 07:09:45.127223: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1
wandb: Tracking run with wandb version 0.12.5
wandb: Syncing run leafy-deluge-1
wandb: ⭐️ View project at https://wandb.ai/yinanazhou/xl_512_bs_8_lr_1e06_es_5_lc_True_nr_False_sr_True_stem_False_lemma_True_repeat_3_fold_1
wandb: 🚀 View run at https://wandb.ai/yinanazhou/xl_512_bs_8_lr_1e06_es_5_lc_True_nr_False_sr_True_stem_False_lemma_True_repeat_3_fold_1/runs/3hvu1cyo
wandb: Run data is saved locally in /project/6002780/yinan/Thesis_MER_Lyrics/lyric-emotion/wandb/run-20220326_070942-3hvu1cyo
wandb: Run `wandb offline` to turn off syncing.

Validation loss decreased (inf --> 1.415615).  Saving model ...
Validation loss decreased (1.415615 --> 1.405343).  Saving model ...
Validation loss decreased (1.405343 --> 1.396814).  Saving model ...
Validation loss decreased (1.396814 --> 1.389869).  Saving model ...
Validation loss decreased (1.389869 --> 1.383478).  Saving model ...
Validation loss decreased (1.383478 --> 1.377738).  Saving model ...
Validation loss decreased (1.377738 --> 1.372496).  Saving model ...
Validation loss decreased (1.372496 --> 1.367405).  Saving model ...
Validation loss decreased (1.367405 --> 1.362507).  Saving model ...
Validation loss decreased (1.362507 --> 1.357906).  Saving model ...
Validation loss decreased (1.357906 --> 1.352671).  Saving model ...
Validation loss decreased (1.352671 --> 1.347647).  Saving model ...
Validation loss decreased (1.347647 --> 1.342321).  Saving model ...
Validation loss decreased (1.342321 --> 1.337143).  Saving model ...
Validation loss decreased (1.337143 --> 1.331760).  Saving model ...
Validation loss decreased (1.331760 --> 1.325322).  Saving model ...
Validation loss decreased (1.325322 --> 1.319726).  Saving model ...
Validation loss decreased (1.319726 --> 1.313908).  Saving model ...
Validation loss decreased (1.313908 --> 1.308820).  Saving model ...
Validation loss decreased (1.308820 --> 1.302615).  Saving model ...
Validation loss decreased (1.302615 --> 1.294381).  Saving model ...
Validation loss decreased (1.294381 --> 1.286801).  Saving model ...
Validation loss decreased (1.286801 --> 1.278503).  Saving model ...
Validation loss decreased (1.278503 --> 1.269239).  Saving model ...
Validation loss decreased (1.269239 --> 1.261131).  Saving model ...
Validation loss decreased (1.261131 --> 1.252393).  Saving model ...
Validation loss decreased (1.252393 --> 1.243836).  Saving model ...
Validation loss decreased (1.243836 --> 1.236151).  Saving model ...
Validation loss decreased (1.236151 --> 1.227032).  Saving model ...
Validation loss decreased (1.227032 --> 1.219015).  Saving model ...
Validation loss decreased (1.219015 --> 1.211484).  Saving model ...
Validation loss decreased (1.211484 --> 1.204426).  Saving model ...
Validation loss decreased (1.204426 --> 1.197533).  Saving model ...
Validation loss decreased (1.197533 --> 1.190805).  Saving model ...
Validation loss decreased (1.190805 --> 1.184702).  Saving model ...
Validation loss decreased (1.184702 --> 1.179016).  Saving model ...
Validation loss decreased (1.179016 --> 1.172225).  Saving model ...
Validation loss decreased (1.172225 --> 1.166563).  Saving model ...
Validation loss decreased (1.166563 --> 1.161459).  Saving model ...
Validation loss decreased (1.161459 --> 1.155009).  Saving model ...
Validation loss decreased (1.155009 --> 1.149679).  Saving model ...
Validation loss decreased (1.149679 --> 1.143042).  Saving model ...
Validation loss decreased (1.143042 --> 1.137815).  Saving model ...
Validation loss decreased (1.137815 --> 1.132528).  Saving model ...
Validation loss decreased (1.132528 --> 1.127010).  Saving model ...
Validation loss decreased (1.127010 --> 1.122313).  Saving model ...
Validation loss decreased (1.122313 --> 1.118273).  Saving model ...
Validation loss decreased (1.118273 --> 1.113048).  Saving model ...
Validation loss decreased (1.113048 --> 1.107279).  Saving model ...
Validation loss decreased (1.107279 --> 1.102659).  Saving model ...
Validation loss decreased (1.102659 --> 1.097641).  Saving model ...
Validation loss decreased (1.097641 --> 1.092364).  Saving model ...
Validation loss decreased (1.092364 --> 1.089090).  Saving model ...
Validation loss decreased (1.089090 --> 1.085845).  Saving model ...
Validation loss decreased (1.085845 --> 1.081131).  Saving model ...
Validation loss decreased (1.081131 --> 1.078024).  Saving model ...
Validation loss decreased (1.078024 --> 1.073995).  Saving model ...
Validation loss decreased (1.073995 --> 1.068633).  Saving model ...
Validation loss decreased (1.068633 --> 1.064525).  Saving model ...
Validation loss decreased (1.064525 --> 1.059808).  Saving model ...
Validation loss decreased (1.059808 --> 1.055638).  Saving model ...
Validation loss decreased (1.055638 --> 1.053427).  Saving model ...
Validation loss decreased (1.053427 --> 1.049869).  Saving model ...
Validation loss decreased (1.049869 --> 1.047487).  Saving model ...
Validation loss decreased (1.047487 --> 1.045207).  Saving model ...
Validation loss decreased (1.045207 --> 1.041507).  Saving model ...
Validation loss decreased (1.041507 --> 1.037583).  Saving model ...
Validation loss decreased (1.037583 --> 1.034075).  Saving model ...
Validation loss decreased (1.034075 --> 1.031155).  Saving model ...
Validation loss decreased (1.031155 --> 1.028916).  Saving model ...
Validation loss decreased (1.028916 --> 1.024512).  Saving model ...
Validation loss decreased (1.024512 --> 1.022385).  Saving model ...
Validation loss decreased (1.022385 --> 1.021033).  Saving model ...
Validation loss decreased (1.021033 --> 1.017763).  Saving model ...
Validation loss decreased (1.017763 --> 1.015874).  Saving model ...
Validation loss decreased (1.015874 --> 1.011141).  Saving model ...
Validation loss decreased (1.011141 --> 1.009510).  Saving model ...
Validation loss decreased (1.009510 --> 1.007082).  Saving model ...
Validation loss decreased (1.007082 --> 1.005667).  Saving model ...
Validation loss decreased (1.005667 --> 1.003598).  Saving model ...
Validation loss decreased (1.003598 --> 1.001240).  Saving model ...
Validation loss decreased (1.001240 --> 0.998915).  Saving model ...
Validation loss decreased (0.998915 --> 0.995775).  Saving model ...
Validation loss decreased (0.995775 --> 0.994698).  Saving model ...
Validation loss decreased (0.994698 --> 0.992961).  Saving model ...
Validation loss decreased (0.992961 --> 0.990967).  Saving model ...
Validation loss decreased (0.990967 --> 0.989146).  Saving model ...
Validation loss decreased (0.989146 --> 0.987660).  Saving model ...
EarlyStopping counter: 1 out of 5.0
Validation loss decreased (0.987660 --> 0.986063).  Saving model ...
Validation loss decreased (0.986063 --> 0.985971).  Saving model ...
Validation loss decreased (0.985971 --> 0.982469).  Saving model ...
Validation loss decreased (0.982469 --> 0.981315).  Saving model ...
Validation loss decreased (0.981315 --> 0.980748).  Saving model ...
EarlyStopping counter: 1 out of 5.0
Validation loss decreased (0.980748 --> 0.980153).  Saving model ...
Validation loss decreased (0.980153 --> 0.978124).  Saving model ...
Validation loss decreased (0.978124 --> 0.976594).  Saving model ...
Validation loss decreased (0.976594 --> 0.975363).  Saving model ...
Validation loss decreased (0.975363 --> 0.974000).  Saving model ...
Validation loss decreased (0.974000 --> 0.973168).  Saving model ...
Validation loss decreased (0.973168 --> 0.972546).  Saving model ...
Validation loss decreased (0.972546 --> 0.971952).  Saving model ...
Validation loss decreased (0.971952 --> 0.970755).  Saving model ...
Validation loss decreased (0.970755 --> 0.970175).  Saving model ...
Validation loss decreased (0.970175 --> 0.967940).  Saving model ...
Validation loss decreased (0.967940 --> 0.967543).  Saving model ...
EarlyStopping counter: 1 out of 5.0
Validation loss decreased (0.967543 --> 0.966217).  Saving model ...
Validation loss decreased (0.966217 --> 0.965616).  Saving model ...
Validation loss decreased (0.965616 --> 0.964850).  Saving model ...
Validation loss decreased (0.964850 --> 0.963608).  Saving model ...
Validation loss decreased (0.963608 --> 0.963126).  Saving model ...
EarlyStopping counter: 1 out of 5.0
EarlyStopping counter: 2 out of 5.0
EarlyStopping counter: 3 out of 5.0
Validation loss decreased (0.963126 --> 0.962983).  Saving model ...
Validation loss decreased (0.962983 --> 0.962059).  Saving model ...
EarlyStopping counter: 1 out of 5.0
EarlyStopping counter: 2 out of 5.0
Validation loss decreased (0.962059 --> 0.960633).  Saving model ...
Validation loss decreased (0.960633 --> 0.959241).  Saving model ...
Validation loss decreased (0.959241 --> 0.958710).  Saving model ...
EarlyStopping counter: 1 out of 5.0
EarlyStopping counter: 2 out of 5.0
Validation loss decreased (0.958710 --> 0.958409).  Saving model ...
EarlyStopping counter: 1 out of 5.0
EarlyStopping counter: 2 out of 5.0
Validation loss decreased (0.958409 --> 0.957862).  Saving model ...
Validation loss decreased (0.957862 --> 0.956772).  Saving model ...
Validation loss decreased (0.956772 --> 0.956760).  Saving model ...
EarlyStopping counter: 1 out of 5.0
EarlyStopping counter: 2 out of 5.0
EarlyStopping counter: 3 out of 5.0
EarlyStopping counter: 4 out of 5.0
EarlyStopping counter: 5 out of 5.0
/localscratch/yinan.29546396.0/env/lib/python3.7/site-packages/torch/nn/functional.py:1794: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.
  warnings.warn("nn.functional.tanh is deprecated. Use torch.tanh instead.")
wandb: Waiting for W&B process to finish, PID 224374... (success).
wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: \ 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: | 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: / 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: \ 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: | 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: / 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: \ 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: | 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: / 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb:                                                                                
wandb: Run history:
wandb:     e_F1 ▁▂▃▄▅▆▆▆▆▆▆▆▆▆▇▇▇▇▇▇▇██▇████████████████
wandb:   e_loss ██▇▇▇▇▆▆▅▅▄▄▄▄▃▃▃▃▃▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:     t_F1 ▁▂▂▂▃▃▃▄▄▅▅▅▅▆▅▅▇▆▆▆▆▆▆▇▇▇▇▇▇▇▇▇▇▇██████
wandb:   t_loss ███▇▇▇▇▇▇▆▆▅▅▅▅▅▄▄▄▄▄▃▃▃▃▃▃▂▂▂▂▂▂▂▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:     e_F1 60.59622
wandb:   e_loss 0.95696
wandb:     t_F1 75.29136
wandb:   t_loss 0.70954
wandb: 
wandb: Synced 4 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Synced leafy-deluge-1: https://wandb.ai/yinanazhou/xl_512_bs_8_lr_1e06_es_5_lc_True_nr_False_sr_True_stem_False_lemma_True_repeat_3_fold_1/runs/3hvu1cyo
wandb: Find logs at: ./wandb/run-20220326_070942-3hvu1cyo/logs/debug.log
wandb: 

wandb: wandb version 0.12.11 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
2022-03-26 08:39:51.956567: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1
wandb: Tracking run with wandb version 0.12.5
wandb: Syncing run solar-gorge-1
wandb: ⭐️ View project at https://wandb.ai/yinanazhou/xl_512_bs_8_lr_1e06_es_5_lc_True_nr_False_sr_True_stem_False_lemma_True_repeat_3_fold_2
wandb: 🚀 View run at https://wandb.ai/yinanazhou/xl_512_bs_8_lr_1e06_es_5_lc_True_nr_False_sr_True_stem_False_lemma_True_repeat_3_fold_2/runs/13a933om
wandb: Run data is saved locally in /project/6002780/yinan/Thesis_MER_Lyrics/lyric-emotion/wandb/run-20220326_083949-13a933om
wandb: Run `wandb offline` to turn off syncing.

Validation loss decreased (inf --> 1.430212).  Saving model ...
Validation loss decreased (1.430212 --> 1.410340).  Saving model ...
Validation loss decreased (1.410340 --> 1.393960).  Saving model ...
Validation loss decreased (1.393960 --> 1.381507).  Saving model ...
Validation loss decreased (1.381507 --> 1.371975).  Saving model ...
Validation loss decreased (1.371975 --> 1.364356).  Saving model ...
Validation loss decreased (1.364356 --> 1.358491).  Saving model ...
Validation loss decreased (1.358491 --> 1.352168).  Saving model ...
Validation loss decreased (1.352168 --> 1.346419).  Saving model ...
Validation loss decreased (1.346419 --> 1.340866).  Saving model ...
Validation loss decreased (1.340866 --> 1.335986).  Saving model ...
Validation loss decreased (1.335986 --> 1.331372).  Saving model ...
Validation loss decreased (1.331372 --> 1.325697).  Saving model ...
Validation loss decreased (1.325697 --> 1.320749).  Saving model ...
Validation loss decreased (1.320749 --> 1.315300).  Saving model ...
Validation loss decreased (1.315300 --> 1.309563).  Saving model ...
Validation loss decreased (1.309563 --> 1.303297).  Saving model ...
Validation loss decreased (1.303297 --> 1.297220).  Saving model ...
Validation loss decreased (1.297220 --> 1.291110).  Saving model ...
Validation loss decreased (1.291110 --> 1.284091).  Saving model ...
Validation loss decreased (1.284091 --> 1.278276).  Saving model ...
Validation loss decreased (1.278276 --> 1.271310).  Saving model ...
Validation loss decreased (1.271310 --> 1.263760).  Saving model ...
Validation loss decreased (1.263760 --> 1.255339).  Saving model ...
Validation loss decreased (1.255339 --> 1.248618).  Saving model ...
Validation loss decreased (1.248618 --> 1.241626).  Saving model ...
Validation loss decreased (1.241626 --> 1.235235).  Saving model ...
Validation loss decreased (1.235235 --> 1.227014).  Saving model ...
Validation loss decreased (1.227014 --> 1.219045).  Saving model ...
Validation loss decreased (1.219045 --> 1.212255).  Saving model ...
Validation loss decreased (1.212255 --> 1.204197).  Saving model ...
Validation loss decreased (1.204197 --> 1.196281).  Saving model ...
Validation loss decreased (1.196281 --> 1.188750).  Saving model ...
Validation loss decreased (1.188750 --> 1.181577).  Saving model ...
Validation loss decreased (1.181577 --> 1.174353).  Saving model ...
Validation loss decreased (1.174353 --> 1.167378).  Saving model ...
Validation loss decreased (1.167378 --> 1.160924).  Saving model ...
Validation loss decreased (1.160924 --> 1.155036).  Saving model ...
Validation loss decreased (1.155036 --> 1.148021).  Saving model ...
Validation loss decreased (1.148021 --> 1.140736).  Saving model ...
Validation loss decreased (1.140736 --> 1.135058).  Saving model ...
Validation loss decreased (1.135058 --> 1.129790).  Saving model ...
Validation loss decreased (1.129790 --> 1.124638).  Saving model ...
Validation loss decreased (1.124638 --> 1.118347).  Saving model ...
Validation loss decreased (1.118347 --> 1.113422).  Saving model ...
Validation loss decreased (1.113422 --> 1.106102).  Saving model ...
Validation loss decreased (1.106102 --> 1.099580).  Saving model ...
Validation loss decreased (1.099580 --> 1.094546).  Saving model ...
Validation loss decreased (1.094546 --> 1.090146).  Saving model ...
Validation loss decreased (1.090146 --> 1.085241).  Saving model ...
Validation loss decreased (1.085241 --> 1.079689).  Saving model ...
Validation loss decreased (1.079689 --> 1.075536).  Saving model ...
Validation loss decreased (1.075536 --> 1.069669).  Saving model ...
Validation loss decreased (1.069669 --> 1.065424).  Saving model ...
Validation loss decreased (1.065424 --> 1.060712).  Saving model ...
Validation loss decreased (1.060712 --> 1.055497).  Saving model ...
Validation loss decreased (1.055497 --> 1.049378).  Saving model ...
Validation loss decreased (1.049378 --> 1.045184).  Saving model ...
Validation loss decreased (1.045184 --> 1.040110).  Saving model ...
Validation loss decreased (1.040110 --> 1.036628).  Saving model ...
Validation loss decreased (1.036628 --> 1.033610).  Saving model ...
Validation loss decreased (1.033610 --> 1.029865).  Saving model ...
Validation loss decreased (1.029865 --> 1.025540).  Saving model ...
Validation loss decreased (1.025540 --> 1.021375).  Saving model ...
Validation loss decreased (1.021375 --> 1.018578).  Saving model ...
Validation loss decreased (1.018578 --> 1.016054).  Saving model ...
Validation loss decreased (1.016054 --> 1.013488).  Saving model ...
Validation loss decreased (1.013488 --> 1.010158).  Saving model ...
Validation loss decreased (1.010158 --> 1.005472).  Saving model ...
Validation loss decreased (1.005472 --> 1.000747).  Saving model ...
Validation loss decreased (1.000747 --> 0.996703).  Saving model ...
Validation loss decreased (0.996703 --> 0.995173).  Saving model ...
Validation loss decreased (0.995173 --> 0.992654).  Saving model ...
Validation loss decreased (0.992654 --> 0.990421).  Saving model ...
Validation loss decreased (0.990421 --> 0.987155).  Saving model ...
Validation loss decreased (0.987155 --> 0.983906).  Saving model ...
Validation loss decreased (0.983906 --> 0.980259).  Saving model ...
Validation loss decreased (0.980259 --> 0.975934).  Saving model ...
Validation loss decreased (0.975934 --> 0.973849).  Saving model ...
Validation loss decreased (0.973849 --> 0.973109).  Saving model ...
Validation loss decreased (0.973109 --> 0.971105).  Saving model ...
Validation loss decreased (0.971105 --> 0.967823).  Saving model ...
Validation loss decreased (0.967823 --> 0.963453).  Saving model ...
Validation loss decreased (0.963453 --> 0.961101).  Saving model ...
Validation loss decreased (0.961101 --> 0.958282).  Saving model ...
Validation loss decreased (0.958282 --> 0.957196).  Saving model ...
Validation loss decreased (0.957196 --> 0.955724).  Saving model ...
Validation loss decreased (0.955724 --> 0.954675).  Saving model ...
Validation loss decreased (0.954675 --> 0.952383).  Saving model ...
Validation loss decreased (0.952383 --> 0.948689).  Saving model ...
Validation loss decreased (0.948689 --> 0.946854).  Saving model ...
Validation loss decreased (0.946854 --> 0.944652).  Saving model ...
Validation loss decreased (0.944652 --> 0.943354).  Saving model ...
Validation loss decreased (0.943354 --> 0.941798).  Saving model ...
Validation loss decreased (0.941798 --> 0.941016).  Saving model ...
Validation loss decreased (0.941016 --> 0.939330).  Saving model ...
Validation loss decreased (0.939330 --> 0.936776).  Saving model ...
Validation loss decreased (0.936776 --> 0.933504).  Saving model ...
Validation loss decreased (0.933504 --> 0.930606).  Saving model ...
Validation loss decreased (0.930606 --> 0.930522).  Saving model ...
Validation loss decreased (0.930522 --> 0.928888).  Saving model ...
Validation loss decreased (0.928888 --> 0.928075).  Saving model ...
Validation loss decreased (0.928075 --> 0.925929).  Saving model ...
Validation loss decreased (0.925929 --> 0.925554).  Saving model ...
Validation loss decreased (0.925554 --> 0.924851).  Saving model ...
Validation loss decreased (0.924851 --> 0.923959).  Saving model ...
Validation loss decreased (0.923959 --> 0.922732).  Saving model ...
EarlyStopping counter: 1 out of 5.0
Validation loss decreased (0.922732 --> 0.921002).  Saving model ...
Validation loss decreased (0.921002 --> 0.919978).  Saving model ...
EarlyStopping counter: 1 out of 5.0
EarlyStopping counter: 2 out of 5.0
Validation loss decreased (0.919978 --> 0.918465).  Saving model ...
Validation loss decreased (0.918465 --> 0.918050).  Saving model ...
EarlyStopping counter: 1 out of 5.0
Validation loss decreased (0.918050 --> 0.916432).  Saving model ...
EarlyStopping counter: 1 out of 5.0
Validation loss decreased (0.916432 --> 0.915930).  Saving model ...
EarlyStopping counter: 1 out of 5.0
EarlyStopping counter: 2 out of 5.0
Validation loss decreased (0.915930 --> 0.915128).  Saving model ...
Validation loss decreased (0.915128 --> 0.913869).  Saving model ...
EarlyStopping counter: 1 out of 5.0
EarlyStopping counter: 2 out of 5.0
Validation loss decreased (0.913869 --> 0.913230).  Saving model ...
Validation loss decreased (0.913230 --> 0.911653).  Saving model ...
EarlyStopping counter: 1 out of 5.0
EarlyStopping counter: 2 out of 5.0
EarlyStopping counter: 3 out of 5.0
EarlyStopping counter: 4 out of 5.0
Validation loss decreased (0.911653 --> 0.910282).  Saving model ...
EarlyStopping counter: 1 out of 5.0
EarlyStopping counter: 2 out of 5.0
Validation loss decreased (0.910282 --> 0.910164).  Saving model ...
Validation loss decreased (0.910164 --> 0.909560).  Saving model ...
EarlyStopping counter: 1 out of 5.0
EarlyStopping counter: 2 out of 5.0
EarlyStopping counter: 3 out of 5.0
Validation loss decreased (0.909560 --> 0.909500).  Saving model ...
EarlyStopping counter: 1 out of 5.0
EarlyStopping counter: 2 out of 5.0
EarlyStopping counter: 3 out of 5.0
EarlyStopping counter: 4 out of 5.0
EarlyStopping counter: 5 out of 5.0
/localscratch/yinan.29546396.0/env/lib/python3.7/site-packages/torch/nn/functional.py:1794: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.
  warnings.warn("nn.functional.tanh is deprecated. Use torch.tanh instead.")
wandb: Waiting for W&B process to finish, PID 229180... (success).
wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: \ 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: | 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: / 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: \ 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: | 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: / 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: \ 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: | 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: / 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb:                                                                                
wandb: Run history:
wandb:     e_F1 ▁▂▃▄▅▅▆▆▆▆▆▇▇▇▇▇▇▇▇▇▇▇██████████████████
wandb:   e_loss ██▇▇▇▆▆▆▅▅▄▄▄▄▃▃▃▃▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:     t_F1 ▁▁▂▂▂▃▃▃▄▄▅▅▅▅▅▆▆▆▆▆▆▇▆▇▆▇▇▇▇▇▇▇▇▇▇▇████
wandb:   t_loss ██▇▇▇▇▇▇▆▆▆▅▅▅▅▄▄▄▄▄▄▃▃▃▃▃▂▂▂▂▂▂▂▂▂▂▁▁▁▁
wandb: 
wandb: Run summary:
wandb:     e_F1 63.34857
wandb:   e_loss 0.9111
wandb:     t_F1 71.28812
wandb:   t_loss 0.72522
wandb: 
wandb: Synced 4 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Synced solar-gorge-1: https://wandb.ai/yinanazhou/xl_512_bs_8_lr_1e06_es_5_lc_True_nr_False_sr_True_stem_False_lemma_True_repeat_3_fold_2/runs/13a933om
wandb: Find logs at: ./wandb/run-20220326_083949-13a933om/logs/debug.log
wandb: 

wandb: wandb version 0.12.11 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
2022-03-26 10:13:22.825609: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1
wandb: Tracking run with wandb version 0.12.5
wandb: Syncing run decent-plasma-1
wandb: ⭐️ View project at https://wandb.ai/yinanazhou/xl_512_bs_8_lr_1e06_es_5_lc_True_nr_False_sr_True_stem_False_lemma_True_repeat_4_fold_1
wandb: 🚀 View run at https://wandb.ai/yinanazhou/xl_512_bs_8_lr_1e06_es_5_lc_True_nr_False_sr_True_stem_False_lemma_True_repeat_4_fold_1/runs/2q2t9988
wandb: Run data is saved locally in /project/6002780/yinan/Thesis_MER_Lyrics/lyric-emotion/wandb/run-20220326_101320-2q2t9988
wandb: Run `wandb offline` to turn off syncing.

Validation loss decreased (inf --> 1.417511).  Saving model ...
Validation loss decreased (1.417511 --> 1.403385).  Saving model ...
Validation loss decreased (1.403385 --> 1.392050).  Saving model ...
Validation loss decreased (1.392050 --> 1.383120).  Saving model ...
Validation loss decreased (1.383120 --> 1.375888).  Saving model ...
Validation loss decreased (1.375888 --> 1.369433).  Saving model ...
Validation loss decreased (1.369433 --> 1.363675).  Saving model ...
Validation loss decreased (1.363675 --> 1.358219).  Saving model ...
Validation loss decreased (1.358219 --> 1.353713).  Saving model ...
Validation loss decreased (1.353713 --> 1.348899).  Saving model ...
Validation loss decreased (1.348899 --> 1.344413).  Saving model ...
Validation loss decreased (1.344413 --> 1.339425).  Saving model ...
Validation loss decreased (1.339425 --> 1.334709).  Saving model ...
Validation loss decreased (1.334709 --> 1.330236).  Saving model ...
Validation loss decreased (1.330236 --> 1.325255).  Saving model ...
Validation loss decreased (1.325255 --> 1.320099).  Saving model ...
Validation loss decreased (1.320099 --> 1.314527).  Saving model ...
Validation loss decreased (1.314527 --> 1.309530).  Saving model ...
Validation loss decreased (1.309530 --> 1.303607).  Saving model ...
Validation loss decreased (1.303607 --> 1.297984).  Saving model ...
Validation loss decreased (1.297984 --> 1.292183).  Saving model ...
Validation loss decreased (1.292183 --> 1.285225).  Saving model ...
Validation loss decreased (1.285225 --> 1.278101).  Saving model ...
Validation loss decreased (1.278101 --> 1.270732).  Saving model ...
Validation loss decreased (1.270732 --> 1.263604).  Saving model ...
Validation loss decreased (1.263604 --> 1.255491).  Saving model ...
Validation loss decreased (1.255491 --> 1.247656).  Saving model ...
Validation loss decreased (1.247656 --> 1.239710).  Saving model ...
Validation loss decreased (1.239710 --> 1.231337).  Saving model ...
Validation loss decreased (1.231337 --> 1.223680).  Saving model ...
Validation loss decreased (1.223680 --> 1.216142).  Saving model ...
Validation loss decreased (1.216142 --> 1.208387).  Saving model ...
Validation loss decreased (1.208387 --> 1.201006).  Saving model ...
Validation loss decreased (1.201006 --> 1.192882).  Saving model ...
Validation loss decreased (1.192882 --> 1.185618).  Saving model ...
Validation loss decreased (1.185618 --> 1.177436).  Saving model ...
Validation loss decreased (1.177436 --> 1.170140).  Saving model ...
Validation loss decreased (1.170140 --> 1.162975).  Saving model ...
Validation loss decreased (1.162975 --> 1.156024).  Saving model ...
Validation loss decreased (1.156024 --> 1.150021).  Saving model ...
Validation loss decreased (1.150021 --> 1.144056).  Saving model ...
Validation loss decreased (1.144056 --> 1.138352).  Saving model ...
Validation loss decreased (1.138352 --> 1.133263).  Saving model ...
Validation loss decreased (1.133263 --> 1.127783).  Saving model ...
Validation loss decreased (1.127783 --> 1.122592).  Saving model ...
Validation loss decreased (1.122592 --> 1.116561).  Saving model ...
Validation loss decreased (1.116561 --> 1.111438).  Saving model ...
Validation loss decreased (1.111438 --> 1.106722).  Saving model ...
Validation loss decreased (1.106722 --> 1.102070).  Saving model ...
Validation loss decreased (1.102070 --> 1.098399).  Saving model ...
Validation loss decreased (1.098399 --> 1.093175).  Saving model ...
Validation loss decreased (1.093175 --> 1.088711).  Saving model ...
Validation loss decreased (1.088711 --> 1.086251).  Saving model ...
Validation loss decreased (1.086251 --> 1.083065).  Saving model ...
Validation loss decreased (1.083065 --> 1.078084).  Saving model ...
Validation loss decreased (1.078084 --> 1.075341).  Saving model ...
Validation loss decreased (1.075341 --> 1.073065).  Saving model ...
Validation loss decreased (1.073065 --> 1.067053).  Saving model ...
Validation loss decreased (1.067053 --> 1.064368).  Saving model ...
Validation loss decreased (1.064368 --> 1.060218).  Saving model ...
Validation loss decreased (1.060218 --> 1.056751).  Saving model ...
Validation loss decreased (1.056751 --> 1.056473).  Saving model ...
Validation loss decreased (1.056473 --> 1.051487).  Saving model ...
Validation loss decreased (1.051487 --> 1.048373).  Saving model ...
Validation loss decreased (1.048373 --> 1.045820).  Saving model ...
Validation loss decreased (1.045820 --> 1.043488).  Saving model ...
Validation loss decreased (1.043488 --> 1.039969).  Saving model ...
Validation loss decreased (1.039969 --> 1.036460).  Saving model ...
Validation loss decreased (1.036460 --> 1.034965).  Saving model ...
Validation loss decreased (1.034965 --> 1.031964).  Saving model ...
Validation loss decreased (1.031964 --> 1.028469).  Saving model ...
Validation loss decreased (1.028469 --> 1.025526).  Saving model ...
Validation loss decreased (1.025526 --> 1.023158).  Saving model ...
Validation loss decreased (1.023158 --> 1.020023).  Saving model ...
Validation loss decreased (1.020023 --> 1.016734).  Saving model ...
Validation loss decreased (1.016734 --> 1.015135).  Saving model ...
Validation loss decreased (1.015135 --> 1.013690).  Saving model ...
Validation loss decreased (1.013690 --> 1.012005).  Saving model ...
Validation loss decreased (1.012005 --> 1.009869).  Saving model ...
Validation loss decreased (1.009869 --> 1.007911).  Saving model ...
Validation loss decreased (1.007911 --> 1.006230).  Saving model ...
Validation loss decreased (1.006230 --> 1.004679).  Saving model ...
Validation loss decreased (1.004679 --> 1.002824).  Saving model ...
Validation loss decreased (1.002824 --> 1.001766).  Saving model ...
Validation loss decreased (1.001766 --> 1.000065).  Saving model ...
Validation loss decreased (1.000065 --> 0.997842).  Saving model ...
Validation loss decreased (0.997842 --> 0.994980).  Saving model ...
Validation loss decreased (0.994980 --> 0.993223).  Saving model ...
Validation loss decreased (0.993223 --> 0.991934).  Saving model ...
Validation loss decreased (0.991934 --> 0.989261).  Saving model ...
Validation loss decreased (0.989261 --> 0.988063).  Saving model ...
Validation loss decreased (0.988063 --> 0.986049).  Saving model ...
Validation loss decreased (0.986049 --> 0.985324).  Saving model ...
Validation loss decreased (0.985324 --> 0.984795).  Saving model ...
Validation loss decreased (0.984795 --> 0.983857).  Saving model ...
Validation loss decreased (0.983857 --> 0.982036).  Saving model ...
EarlyStopping counter: 1 out of 5.0
EarlyStopping counter: 2 out of 5.0
Validation loss decreased (0.982036 --> 0.980506).  Saving model ...
Validation loss decreased (0.980506 --> 0.978593).  Saving model ...
Validation loss decreased (0.978593 --> 0.978076).  Saving model ...
Validation loss decreased (0.978076 --> 0.976013).  Saving model ...
EarlyStopping counter: 1 out of 5.0
Validation loss decreased (0.976013 --> 0.974777).  Saving model ...
Validation loss decreased (0.974777 --> 0.974325).  Saving model ...
Validation loss decreased (0.974325 --> 0.973929).  Saving model ...
Validation loss decreased (0.973929 --> 0.973686).  Saving model ...
Validation loss decreased (0.973686 --> 0.972380).  Saving model ...
Validation loss decreased (0.972380 --> 0.971729).  Saving model ...
Validation loss decreased (0.971729 --> 0.971306).  Saving model ...
EarlyStopping counter: 1 out of 5.0
Validation loss decreased (0.971306 --> 0.971203).  Saving model ...
Validation loss decreased (0.971203 --> 0.969960).  Saving model ...
Validation loss decreased (0.969960 --> 0.967303).  Saving model ...
EarlyStopping counter: 1 out of 5.0
EarlyStopping counter: 2 out of 5.0
EarlyStopping counter: 3 out of 5.0
Validation loss decreased (0.967303 --> 0.966026).  Saving model ...
Validation loss decreased (0.966026 --> 0.965761).  Saving model ...
EarlyStopping counter: 1 out of 5.0
EarlyStopping counter: 2 out of 5.0
Validation loss decreased (0.965761 --> 0.965048).  Saving model ...
EarlyStopping counter: 1 out of 5.0
Validation loss decreased (0.965048 --> 0.963820).  Saving model ...
Validation loss decreased (0.963820 --> 0.962632).  Saving model ...
EarlyStopping counter: 1 out of 5.0
EarlyStopping counter: 2 out of 5.0
EarlyStopping counter: 3 out of 5.0
Validation loss decreased (0.962632 --> 0.962451).  Saving model ...
Validation loss decreased (0.962451 --> 0.960502).  Saving model ...
EarlyStopping counter: 1 out of 5.0
EarlyStopping counter: 2 out of 5.0
EarlyStopping counter: 3 out of 5.0
EarlyStopping counter: 4 out of 5.0
EarlyStopping counter: 5 out of 5.0
/localscratch/yinan.29546396.0/env/lib/python3.7/site-packages/torch/nn/functional.py:1794: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.
  warnings.warn("nn.functional.tanh is deprecated. Use torch.tanh instead.")
wandb: Waiting for W&B process to finish, PID 234208... (success).
wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: \ 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: | 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: / 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: \ 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: | 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: / 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: \ 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: | 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: / 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb:                                                                                
wandb: Run history:
wandb:     e_F1 ▁▁▃▄▄▄▄▅▅▆▆▆▆▇▇▇▇▇▇█████████████████████
wandb:   e_loss ██▇▇▇▇▆▆▅▅▅▄▄▃▃▃▃▃▃▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:     t_F1 ▁▂▃▃▃▃▃▄▄▅▅▅▅▅▆▅▆▆▆▆▆▆▆▆▇▇▇▆▇▇▇▇▇▇██████
wandb:   t_loss ██▇▇▇▇▇▆▆▆▆▅▅▅▅▄▄▄▄▄▄▃▃▃▃▂▂▃▂▂▂▂▂▂▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:     e_F1 57.69534
wandb:   e_loss 0.96256
wandb:     t_F1 73.37576
wandb:   t_loss 0.72592
wandb: 
wandb: Synced 4 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Synced decent-plasma-1: https://wandb.ai/yinanazhou/xl_512_bs_8_lr_1e06_es_5_lc_True_nr_False_sr_True_stem_False_lemma_True_repeat_4_fold_1/runs/2q2t9988
wandb: Find logs at: ./wandb/run-20220326_101320-2q2t9988/logs/debug.log
wandb: 

wandb: wandb version 0.12.11 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
2022-03-26 11:37:59.020534: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1
wandb: Tracking run with wandb version 0.12.5
wandb: Syncing run stellar-sun-1
wandb: ⭐️ View project at https://wandb.ai/yinanazhou/xl_512_bs_8_lr_1e06_es_5_lc_True_nr_False_sr_True_stem_False_lemma_True_repeat_4_fold_2
wandb: 🚀 View run at https://wandb.ai/yinanazhou/xl_512_bs_8_lr_1e06_es_5_lc_True_nr_False_sr_True_stem_False_lemma_True_repeat_4_fold_2/runs/sl2sjhst
wandb: Run data is saved locally in /project/6002780/yinan/Thesis_MER_Lyrics/lyric-emotion/wandb/run-20220326_113756-sl2sjhst
wandb: Run `wandb offline` to turn off syncing.

Validation loss decreased (inf --> 1.417552).  Saving model ...
Validation loss decreased (1.417552 --> 1.403625).  Saving model ...
Validation loss decreased (1.403625 --> 1.394402).  Saving model ...
Validation loss decreased (1.394402 --> 1.386858).  Saving model ...
Validation loss decreased (1.386858 --> 1.380311).  Saving model ...
Validation loss decreased (1.380311 --> 1.375789).  Saving model ...
Validation loss decreased (1.375789 --> 1.370932).  Saving model ...
Validation loss decreased (1.370932 --> 1.366210).  Saving model ...
Validation loss decreased (1.366210 --> 1.361520).  Saving model ...
Validation loss decreased (1.361520 --> 1.356996).  Saving model ...
Validation loss decreased (1.356996 --> 1.352497).  Saving model ...
Validation loss decreased (1.352497 --> 1.347954).  Saving model ...
Validation loss decreased (1.347954 --> 1.342945).  Saving model ...
Validation loss decreased (1.342945 --> 1.337701).  Saving model ...
Validation loss decreased (1.337701 --> 1.332669).  Saving model ...
Validation loss decreased (1.332669 --> 1.327058).  Saving model ...
Validation loss decreased (1.327058 --> 1.320674).  Saving model ...
Validation loss decreased (1.320674 --> 1.314784).  Saving model ...
Validation loss decreased (1.314784 --> 1.309071).  Saving model ...
Validation loss decreased (1.309071 --> 1.300983).  Saving model ...
Validation loss decreased (1.300983 --> 1.294300).  Saving model ...
Validation loss decreased (1.294300 --> 1.285938).  Saving model ...
Validation loss decreased (1.285938 --> 1.277995).  Saving model ...
Validation loss decreased (1.277995 --> 1.270303).  Saving model ...
Validation loss decreased (1.270303 --> 1.261511).  Saving model ...
Validation loss decreased (1.261511 --> 1.252623).  Saving model ...
Validation loss decreased (1.252623 --> 1.242422).  Saving model ...
Validation loss decreased (1.242422 --> 1.233266).  Saving model ...
Validation loss decreased (1.233266 --> 1.223100).  Saving model ...
Validation loss decreased (1.223100 --> 1.214241).  Saving model ...
Validation loss decreased (1.214241 --> 1.205404).  Saving model ...
Validation loss decreased (1.205404 --> 1.197990).  Saving model ...
Validation loss decreased (1.197990 --> 1.189752).  Saving model ...
Validation loss decreased (1.189752 --> 1.182539).  Saving model ...
Validation loss decreased (1.182539 --> 1.173250).  Saving model ...
Validation loss decreased (1.173250 --> 1.167091).  Saving model ...
Validation loss decreased (1.167091 --> 1.159808).  Saving model ...
Validation loss decreased (1.159808 --> 1.152964).  Saving model ...
Validation loss decreased (1.152964 --> 1.144704).  Saving model ...
Validation loss decreased (1.144704 --> 1.139052).  Saving model ...
Validation loss decreased (1.139052 --> 1.131753).  Saving model ...
Validation loss decreased (1.131753 --> 1.125371).  Saving model ...
Validation loss decreased (1.125371 --> 1.118683).  Saving model ...
Validation loss decreased (1.118683 --> 1.112837).  Saving model ...
Validation loss decreased (1.112837 --> 1.105132).  Saving model ...
Validation loss decreased (1.105132 --> 1.100080).  Saving model ...
Validation loss decreased (1.100080 --> 1.096531).  Saving model ...
Validation loss decreased (1.096531 --> 1.090765).  Saving model ...
Validation loss decreased (1.090765 --> 1.085109).  Saving model ...
Validation loss decreased (1.085109 --> 1.078738).  Saving model ...
Validation loss decreased (1.078738 --> 1.074084).  Saving model ...
Validation loss decreased (1.074084 --> 1.066442).  Saving model ...
Validation loss decreased (1.066442 --> 1.062285).  Saving model ...
Validation loss decreased (1.062285 --> 1.060329).  Saving model ...
Validation loss decreased (1.060329 --> 1.058024).  Saving model ...
Validation loss decreased (1.058024 --> 1.053800).  Saving model ...
Validation loss decreased (1.053800 --> 1.051393).  Saving model ...
Validation loss decreased (1.051393 --> 1.045458).  Saving model ...
Validation loss decreased (1.045458 --> 1.041313).  Saving model ...
Validation loss decreased (1.041313 --> 1.037724).  Saving model ...
Validation loss decreased (1.037724 --> 1.033666).  Saving model ...
Validation loss decreased (1.033666 --> 1.028281).  Saving model ...
Validation loss decreased (1.028281 --> 1.022548).  Saving model ...
Validation loss decreased (1.022548 --> 1.017656).  Saving model ...
Validation loss decreased (1.017656 --> 1.013129).  Saving model ...
Validation loss decreased (1.013129 --> 1.009721).  Saving model ...
Validation loss decreased (1.009721 --> 1.006801).  Saving model ...
Validation loss decreased (1.006801 --> 1.005169).  Saving model ...
Validation loss decreased (1.005169 --> 1.001402).  Saving model ...
Validation loss decreased (1.001402 --> 0.997400).  Saving model ...
Validation loss decreased (0.997400 --> 0.993953).  Saving model ...
Validation loss decreased (0.993953 --> 0.990278).  Saving model ...
Validation loss decreased (0.990278 --> 0.988283).  Saving model ...
Validation loss decreased (0.988283 --> 0.985641).  Saving model ...
Validation loss decreased (0.985641 --> 0.982631).  Saving model ...
Validation loss decreased (0.982631 --> 0.982176).  Saving model ...
Validation loss decreased (0.982176 --> 0.980679).  Saving model ...
Validation loss decreased (0.980679 --> 0.977162).  Saving model ...
Validation loss decreased (0.977162 --> 0.975839).  Saving model ...
Validation loss decreased (0.975839 --> 0.972391).  Saving model ...
Validation loss decreased (0.972391 --> 0.971499).  Saving model ...
Validation loss decreased (0.971499 --> 0.968438).  Saving model ...
Validation loss decreased (0.968438 --> 0.966295).  Saving model ...
Validation loss decreased (0.966295 --> 0.965195).  Saving model ...
Validation loss decreased (0.965195 --> 0.964531).  Saving model ...
Validation loss decreased (0.964531 --> 0.962890).  Saving model ...
Validation loss decreased (0.962890 --> 0.961021).  Saving model ...
Validation loss decreased (0.961021 --> 0.959388).  Saving model ...
Validation loss decreased (0.959388 --> 0.958295).  Saving model ...
Validation loss decreased (0.958295 --> 0.955494).  Saving model ...
Validation loss decreased (0.955494 --> 0.952839).  Saving model ...
Validation loss decreased (0.952839 --> 0.951056).  Saving model ...
Validation loss decreased (0.951056 --> 0.949779).  Saving model ...
Validation loss decreased (0.949779 --> 0.948885).  Saving model ...
Validation loss decreased (0.948885 --> 0.946244).  Saving model ...
EarlyStopping counter: 1 out of 5.0
Validation loss decreased (0.946244 --> 0.944560).  Saving model ...
Validation loss decreased (0.944560 --> 0.943449).  Saving model ...
Validation loss decreased (0.943449 --> 0.941052).  Saving model ...
Validation loss decreased (0.941052 --> 0.939422).  Saving model ...
Validation loss decreased (0.939422 --> 0.939056).  Saving model ...
Validation loss decreased (0.939056 --> 0.936812).  Saving model ...
Validation loss decreased (0.936812 --> 0.935254).  Saving model ...
EarlyStopping counter: 1 out of 5.0
EarlyStopping counter: 2 out of 5.0
EarlyStopping counter: 3 out of 5.0
Validation loss decreased (0.935254 --> 0.934616).  Saving model ...
Validation loss decreased (0.934616 --> 0.933304).  Saving model ...
Validation loss decreased (0.933304 --> 0.931381).  Saving model ...
Validation loss decreased (0.931381 --> 0.930955).  Saving model ...
Validation loss decreased (0.930955 --> 0.929603).  Saving model ...
Validation loss decreased (0.929603 --> 0.928207).  Saving model ...
Validation loss decreased (0.928207 --> 0.927819).  Saving model ...
EarlyStopping counter: 1 out of 5.0
Validation loss decreased (0.927819 --> 0.926303).  Saving model ...
Validation loss decreased (0.926303 --> 0.926202).  Saving model ...
Validation loss decreased (0.926202 --> 0.925828).  Saving model ...
Validation loss decreased (0.925828 --> 0.924630).  Saving model ...
Validation loss decreased (0.924630 --> 0.924600).  Saving model ...
Validation loss decreased (0.924600 --> 0.923751).  Saving model ...
Validation loss decreased (0.923751 --> 0.923130).  Saving model ...
EarlyStopping counter: 1 out of 5.0
Validation loss decreased (0.923130 --> 0.922978).  Saving model ...
Validation loss decreased (0.922978 --> 0.922275).  Saving model ...
Validation loss decreased (0.922275 --> 0.922026).  Saving model ...
Validation loss decreased (0.922026 --> 0.920846).  Saving model ...
Validation loss decreased (0.920846 --> 0.919680).  Saving model ...
EarlyStopping counter: 1 out of 5.0
EarlyStopping counter: 2 out of 5.0
EarlyStopping counter: 3 out of 5.0
EarlyStopping counter: 4 out of 5.0
Validation loss decreased (0.919680 --> 0.919538).  Saving model ...
Validation loss decreased (0.919538 --> 0.919397).  Saving model ...
EarlyStopping counter: 1 out of 5.0
EarlyStopping counter: 2 out of 5.0
Validation loss decreased (0.919397 --> 0.918439).  Saving model ...
EarlyStopping counter: 1 out of 5.0
EarlyStopping counter: 2 out of 5.0
EarlyStopping counter: 3 out of 5.0
EarlyStopping counter: 4 out of 5.0
EarlyStopping counter: 5 out of 5.0
/localscratch/yinan.29546396.0/env/lib/python3.7/site-packages/torch/nn/functional.py:1794: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.
  warnings.warn("nn.functional.tanh is deprecated. Use torch.tanh instead.")
wandb: Waiting for W&B process to finish, PID 238711... (success).
wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: \ 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: | 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: / 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: \ 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: | 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: / 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: \ 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: | 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: / 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb:                                                                                
wandb: Run history:
wandb:     e_F1 ▁▂▃▄▅▅▆▆▆▆▇▇▇▇▇▇▇▇▇▇▇▇▇█▇▇▇█████████████
wandb:   e_loss ██▇▇▇▇▆▆▅▅▅▄▄▃▃▃▃▃▂▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:     t_F1 ▁▂▂▃▃▃▄▄▅▅▅▅▅▅▆▆▆▆▇▆▆▇▇▇▇▇▇▇▇▇█▇▇██▇▇█▇█
wandb:   t_loss ██▇▇▇▇▇▇▆▆▆▆▅▅▅▄▄▄▄▄▄▃▃▃▃▂▂▃▂▂▂▂▂▁▂▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:     e_F1 62.93129
wandb:   e_loss 0.91964
wandb:     t_F1 73.93234
wandb:   t_loss 0.725
wandb: 
wandb: Synced 4 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Synced stellar-sun-1: https://wandb.ai/yinanazhou/xl_512_bs_8_lr_1e06_es_5_lc_True_nr_False_sr_True_stem_False_lemma_True_repeat_4_fold_2/runs/sl2sjhst
wandb: Find logs at: ./wandb/run-20220326_113756-sl2sjhst/logs/debug.log
wandb: 

wandb: wandb version 0.12.11 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
2022-03-26 13:11:11.380342: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1
wandb: Tracking run with wandb version 0.12.5
wandb: Syncing run wobbly-frost-1
wandb: ⭐️ View project at https://wandb.ai/yinanazhou/xl_512_bs_8_lr_1e06_es_5_lc_True_nr_False_sr_True_stem_False_lemma_True_repeat_5_fold_1
wandb: 🚀 View run at https://wandb.ai/yinanazhou/xl_512_bs_8_lr_1e06_es_5_lc_True_nr_False_sr_True_stem_False_lemma_True_repeat_5_fold_1/runs/1qgj0733
wandb: Run data is saved locally in /project/6002780/yinan/Thesis_MER_Lyrics/lyric-emotion/wandb/run-20220326_131109-1qgj0733
wandb: Run `wandb offline` to turn off syncing.

Validation loss decreased (inf --> 1.416183).  Saving model ...
Validation loss decreased (1.416183 --> 1.402650).  Saving model ...
Validation loss decreased (1.402650 --> 1.393766).  Saving model ...
Validation loss decreased (1.393766 --> 1.386454).  Saving model ...
Validation loss decreased (1.386454 --> 1.380927).  Saving model ...
Validation loss decreased (1.380927 --> 1.375573).  Saving model ...
Validation loss decreased (1.375573 --> 1.371353).  Saving model ...
Validation loss decreased (1.371353 --> 1.367540).  Saving model ...
Validation loss decreased (1.367540 --> 1.363735).  Saving model ...
Validation loss decreased (1.363735 --> 1.359441).  Saving model ...
Validation loss decreased (1.359441 --> 1.355377).  Saving model ...
Validation loss decreased (1.355377 --> 1.351376).  Saving model ...
Validation loss decreased (1.351376 --> 1.346960).  Saving model ...
Validation loss decreased (1.346960 --> 1.342795).  Saving model ...
Validation loss decreased (1.342795 --> 1.338390).  Saving model ...
Validation loss decreased (1.338390 --> 1.334069).  Saving model ...
Validation loss decreased (1.334069 --> 1.329423).  Saving model ...
Validation loss decreased (1.329423 --> 1.324462).  Saving model ...
Validation loss decreased (1.324462 --> 1.319374).  Saving model ...
Validation loss decreased (1.319374 --> 1.313756).  Saving model ...
Validation loss decreased (1.313756 --> 1.307530).  Saving model ...
Validation loss decreased (1.307530 --> 1.301171).  Saving model ...
Validation loss decreased (1.301171 --> 1.295228).  Saving model ...
Validation loss decreased (1.295228 --> 1.288466).  Saving model ...
Validation loss decreased (1.288466 --> 1.282203).  Saving model ...
Validation loss decreased (1.282203 --> 1.275079).  Saving model ...
Validation loss decreased (1.275079 --> 1.267984).  Saving model ...
Validation loss decreased (1.267984 --> 1.260734).  Saving model ...
Validation loss decreased (1.260734 --> 1.253231).  Saving model ...
Validation loss decreased (1.253231 --> 1.245992).  Saving model ...
Validation loss decreased (1.245992 --> 1.238760).  Saving model ...
Validation loss decreased (1.238760 --> 1.230471).  Saving model ...
Validation loss decreased (1.230471 --> 1.222643).  Saving model ...
Validation loss decreased (1.222643 --> 1.214826).  Saving model ...
Validation loss decreased (1.214826 --> 1.207810).  Saving model ...
Validation loss decreased (1.207810 --> 1.200168).  Saving model ...
Validation loss decreased (1.200168 --> 1.192370).  Saving model ...
Validation loss decreased (1.192370 --> 1.185168).  Saving model ...
Validation loss decreased (1.185168 --> 1.177432).  Saving model ...
Validation loss decreased (1.177432 --> 1.170932).  Saving model ...
Validation loss decreased (1.170932 --> 1.165356).  Saving model ...
Validation loss decreased (1.165356 --> 1.157831).  Saving model ...
Validation loss decreased (1.157831 --> 1.151502).  Saving model ...
Validation loss decreased (1.151502 --> 1.146358).  Saving model ...
Validation loss decreased (1.146358 --> 1.140487).  Saving model ...
Validation loss decreased (1.140487 --> 1.134664).  Saving model ...
Validation loss decreased (1.134664 --> 1.129012).  Saving model ...
Validation loss decreased (1.129012 --> 1.123064).  Saving model ...
Validation loss decreased (1.123064 --> 1.117687).  Saving model ...
Validation loss decreased (1.117687 --> 1.112511).  Saving model ...
Validation loss decreased (1.112511 --> 1.107481).  Saving model ...
Validation loss decreased (1.107481 --> 1.103096).  Saving model ...
Validation loss decreased (1.103096 --> 1.097770).  Saving model ...
Validation loss decreased (1.097770 --> 1.092657).  Saving model ...
Validation loss decreased (1.092657 --> 1.088273).  Saving model ...
Validation loss decreased (1.088273 --> 1.083502).  Saving model ...
Validation loss decreased (1.083502 --> 1.078080).  Saving model ...
Validation loss decreased (1.078080 --> 1.074199).  Saving model ...
Validation loss decreased (1.074199 --> 1.070496).  Saving model ...
Validation loss decreased (1.070496 --> 1.065962).  Saving model ...
Validation loss decreased (1.065962 --> 1.062489).  Saving model ...
Validation loss decreased (1.062489 --> 1.059504).  Saving model ...
Validation loss decreased (1.059504 --> 1.055704).  Saving model ...
Validation loss decreased (1.055704 --> 1.052633).  Saving model ...
Validation loss decreased (1.052633 --> 1.049947).  Saving model ...
Validation loss decreased (1.049947 --> 1.045201).  Saving model ...
Validation loss decreased (1.045201 --> 1.041282).  Saving model ...
Validation loss decreased (1.041282 --> 1.037874).  Saving model ...
Validation loss decreased (1.037874 --> 1.035171).  Saving model ...
Validation loss decreased (1.035171 --> 1.031755).  Saving model ...
Validation loss decreased (1.031755 --> 1.029985).  Saving model ...
Validation loss decreased (1.029985 --> 1.026941).  Saving model ...
Validation loss decreased (1.026941 --> 1.022543).  Saving model ...
Validation loss decreased (1.022543 --> 1.019755).  Saving model ...
Validation loss decreased (1.019755 --> 1.018245).  Saving model ...
Validation loss decreased (1.018245 --> 1.014918).  Saving model ...
Validation loss decreased (1.014918 --> 1.013132).  Saving model ...
Validation loss decreased (1.013132 --> 1.010748).  Saving model ...
Validation loss decreased (1.010748 --> 1.007656).  Saving model ...
Validation loss decreased (1.007656 --> 1.004986).  Saving model ...
Validation loss decreased (1.004986 --> 1.004025).  Saving model ...
Validation loss decreased (1.004025 --> 1.000975).  Saving model ...
Validation loss decreased (1.000975 --> 0.999301).  Saving model ...
Validation loss decreased (0.999301 --> 0.996672).  Saving model ...
Validation loss decreased (0.996672 --> 0.994869).  Saving model ...
Validation loss decreased (0.994869 --> 0.992412).  Saving model ...
Validation loss decreased (0.992412 --> 0.990609).  Saving model ...
Validation loss decreased (0.990609 --> 0.988205).  Saving model ...
Validation loss decreased (0.988205 --> 0.985854).  Saving model ...
Validation loss decreased (0.985854 --> 0.983757).  Saving model ...
Validation loss decreased (0.983757 --> 0.981604).  Saving model ...
Validation loss decreased (0.981604 --> 0.980780).  Saving model ...
Validation loss decreased (0.980780 --> 0.979823).  Saving model ...
Validation loss decreased (0.979823 --> 0.977112).  Saving model ...
Validation loss decreased (0.977112 --> 0.976639).  Saving model ...
Validation loss decreased (0.976639 --> 0.974806).  Saving model ...
Validation loss decreased (0.974806 --> 0.973161).  Saving model ...
Validation loss decreased (0.973161 --> 0.971735).  Saving model ...
EarlyStopping counter: 1 out of 5.0
Validation loss decreased (0.971735 --> 0.970229).  Saving model ...
Validation loss decreased (0.970229 --> 0.969978).  Saving model ...
Validation loss decreased (0.969978 --> 0.967789).  Saving model ...
Validation loss decreased (0.967789 --> 0.967474).  Saving model ...
Validation loss decreased (0.967474 --> 0.966318).  Saving model ...
EarlyStopping counter: 1 out of 5.0
Validation loss decreased (0.966318 --> 0.965184).  Saving model ...
Validation loss decreased (0.965184 --> 0.961607).  Saving model ...
Validation loss decreased (0.961607 --> 0.960338).  Saving model ...
EarlyStopping counter: 1 out of 5.0
Validation loss decreased (0.960338 --> 0.959544).  Saving model ...
EarlyStopping counter: 1 out of 5.0
Validation loss decreased (0.959544 --> 0.958359).  Saving model ...
EarlyStopping counter: 1 out of 5.0
EarlyStopping counter: 2 out of 5.0
Validation loss decreased (0.958359 --> 0.958118).  Saving model ...
Validation loss decreased (0.958118 --> 0.956823).  Saving model ...
Validation loss decreased (0.956823 --> 0.955279).  Saving model ...
Validation loss decreased (0.955279 --> 0.953777).  Saving model ...
Validation loss decreased (0.953777 --> 0.951726).  Saving model ...
EarlyStopping counter: 1 out of 5.0
EarlyStopping counter: 2 out of 5.0
EarlyStopping counter: 3 out of 5.0
Validation loss decreased (0.951726 --> 0.950652).  Saving model ...
Validation loss decreased (0.950652 --> 0.950273).  Saving model ...
EarlyStopping counter: 1 out of 5.0
Validation loss decreased (0.950273 --> 0.948786).  Saving model ...
EarlyStopping counter: 1 out of 5.0
EarlyStopping counter: 2 out of 5.0
EarlyStopping counter: 3 out of 5.0
Validation loss decreased (0.948786 --> 0.947942).  Saving model ...
EarlyStopping counter: 1 out of 5.0
EarlyStopping counter: 2 out of 5.0
EarlyStopping counter: 3 out of 5.0
Validation loss decreased (0.947942 --> 0.947498).  Saving model ...
Validation loss decreased (0.947498 --> 0.946393).  Saving model ...
EarlyStopping counter: 1 out of 5.0
Validation loss decreased (0.946393 --> 0.946175).  Saving model ...
Validation loss decreased (0.946175 --> 0.945634).  Saving model ...
Validation loss decreased (0.945634 --> 0.945364).  Saving model ...
EarlyStopping counter: 1 out of 5.0
EarlyStopping counter: 2 out of 5.0
EarlyStopping counter: 3 out of 5.0
EarlyStopping counter: 4 out of 5.0
EarlyStopping counter: 5 out of 5.0
/localscratch/yinan.29546396.0/env/lib/python3.7/site-packages/torch/nn/functional.py:1794: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.
  warnings.warn("nn.functional.tanh is deprecated. Use torch.tanh instead.")
wandb: Waiting for W&B process to finish, PID 243718... (success).
wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: \ 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: | 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: / 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: \ 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: | 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: / 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: \ 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: | 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: / 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb:                                                                                
wandb: Run history:
wandb:     e_F1 ▁▂▄▄▅▅▅▆▆▇▇▇▇▇▇▇▇▇▇▇▇▇█▇▇███████████████
wandb:   e_loss ██▇▇▇▇▆▆▆▅▅▄▄▄▃▃▃▃▃▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:     t_F1 ▁▁▂▃▂▄▄▄▄▅▅▅▅▅▅▆▆▆▆▇▇▇▇▇▇▇▇▇▇▇▇█▇▇██▇███
wandb:   t_loss ███▇▇▇▇▇▇▆▅▅▅▅▅▄▄▄▄▃▃▃▃▃▃▃▃▂▂▂▂▂▂▂▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:     e_F1 59.02772
wandb:   e_loss 0.94885
wandb:     t_F1 73.53485
wandb:   t_loss 0.72039
wandb: 
wandb: Synced 4 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Synced wobbly-frost-1: https://wandb.ai/yinanazhou/xl_512_bs_8_lr_1e06_es_5_lc_True_nr_False_sr_True_stem_False_lemma_True_repeat_5_fold_1/runs/1qgj0733
wandb: Find logs at: ./wandb/run-20220326_131109-1qgj0733/logs/debug.log
wandb: 

wandb: wandb version 0.12.11 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
2022-03-26 14:46:11.443412: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1
wandb: Tracking run with wandb version 0.12.5
wandb: Syncing run vivid-violet-1
wandb: ⭐️ View project at https://wandb.ai/yinanazhou/xl_512_bs_8_lr_1e06_es_5_lc_True_nr_False_sr_True_stem_False_lemma_True_repeat_5_fold_2
wandb: 🚀 View run at https://wandb.ai/yinanazhou/xl_512_bs_8_lr_1e06_es_5_lc_True_nr_False_sr_True_stem_False_lemma_True_repeat_5_fold_2/runs/2imn0c3g
wandb: Run data is saved locally in /project/6002780/yinan/Thesis_MER_Lyrics/lyric-emotion/wandb/run-20220326_144608-2imn0c3g
wandb: Run `wandb offline` to turn off syncing.

Validation loss decreased (inf --> 1.478896).  Saving model ...
Validation loss decreased (1.478896 --> 1.439806).  Saving model ...
Validation loss decreased (1.439806 --> 1.407252).  Saving model ...
Validation loss decreased (1.407252 --> 1.385608).  Saving model ...
Validation loss decreased (1.385608 --> 1.370624).  Saving model ...
Validation loss decreased (1.370624 --> 1.357662).  Saving model ...
Validation loss decreased (1.357662 --> 1.348871).  Saving model ...
Validation loss decreased (1.348871 --> 1.341641).  Saving model ...
Validation loss decreased (1.341641 --> 1.334901).  Saving model ...
Validation loss decreased (1.334901 --> 1.328488).  Saving model ...
Validation loss decreased (1.328488 --> 1.322428).  Saving model ...
Validation loss decreased (1.322428 --> 1.316239).  Saving model ...
Validation loss decreased (1.316239 --> 1.310310).  Saving model ...
Validation loss decreased (1.310310 --> 1.304619).  Saving model ...
Validation loss decreased (1.304619 --> 1.298375).  Saving model ...
Validation loss decreased (1.298375 --> 1.292873).  Saving model ...
Validation loss decreased (1.292873 --> 1.286789).  Saving model ...
Validation loss decreased (1.286789 --> 1.281356).  Saving model ...
Validation loss decreased (1.281356 --> 1.274890).  Saving model ...
Validation loss decreased (1.274890 --> 1.269063).  Saving model ...
Validation loss decreased (1.269063 --> 1.262820).  Saving model ...
Validation loss decreased (1.262820 --> 1.255725).  Saving model ...
Validation loss decreased (1.255725 --> 1.248342).  Saving model ...
Validation loss decreased (1.248342 --> 1.241244).  Saving model ...
Validation loss decreased (1.241244 --> 1.235767).  Saving model ...
Validation loss decreased (1.235767 --> 1.228982).  Saving model ...
Validation loss decreased (1.228982 --> 1.221548).  Saving model ...
Validation loss decreased (1.221548 --> 1.214005).  Saving model ...
Validation loss decreased (1.214005 --> 1.207699).  Saving model ...
Validation loss decreased (1.207699 --> 1.200756).  Saving model ...
Validation loss decreased (1.200756 --> 1.193341).  Saving model ...
Validation loss decreased (1.193341 --> 1.187109).  Saving model ...
Validation loss decreased (1.187109 --> 1.181134).  Saving model ...
Validation loss decreased (1.181134 --> 1.174168).  Saving model ...
Validation loss decreased (1.174168 --> 1.167530).  Saving model ...
Validation loss decreased (1.167530 --> 1.161097).  Saving model ...
Validation loss decreased (1.161097 --> 1.154491).  Saving model ...
Validation loss decreased (1.154491 --> 1.148083).  Saving model ...
Validation loss decreased (1.148083 --> 1.141810).  Saving model ...
Validation loss decreased (1.141810 --> 1.136143).  Saving model ...
Validation loss decreased (1.136143 --> 1.131493).  Saving model ...
Validation loss decreased (1.131493 --> 1.125622).  Saving model ...
Validation loss decreased (1.125622 --> 1.120400).  Saving model ...
Validation loss decreased (1.120400 --> 1.114985).  Saving model ...
Validation loss decreased (1.114985 --> 1.110675).  Saving model ...
Validation loss decreased (1.110675 --> 1.105778).  Saving model ...
Validation loss decreased (1.105778 --> 1.100574).  Saving model ...
Validation loss decreased (1.100574 --> 1.095668).  Saving model ...
Validation loss decreased (1.095668 --> 1.091402).  Saving model ...
Validation loss decreased (1.091402 --> 1.086079).  Saving model ...
Validation loss decreased (1.086079 --> 1.080516).  Saving model ...
Validation loss decreased (1.080516 --> 1.076296).  Saving model ...
Validation loss decreased (1.076296 --> 1.071919).  Saving model ...
Validation loss decreased (1.071919 --> 1.067222).  Saving model ...
Validation loss decreased (1.067222 --> 1.062331).  Saving model ...
Validation loss decreased (1.062331 --> 1.057371).  Saving model ...
Validation loss decreased (1.057371 --> 1.053356).  Saving model ...
Validation loss decreased (1.053356 --> 1.049356).  Saving model ...
Validation loss decreased (1.049356 --> 1.046513).  Saving model ...
Validation loss decreased (1.046513 --> 1.041966).  Saving model ...
Validation loss decreased (1.041966 --> 1.035480).  Saving model ...
Validation loss decreased (1.035480 --> 1.031748).  Saving model ...
Validation loss decreased (1.031748 --> 1.027090).  Saving model ...
Validation loss decreased (1.027090 --> 1.023255).  Saving model ...
Validation loss decreased (1.023255 --> 1.017938).  Saving model ...
Validation loss decreased (1.017938 --> 1.014271).  Saving model ...
Validation loss decreased (1.014271 --> 1.010344).  Saving model ...
Validation loss decreased (1.010344 --> 1.006378).  Saving model ...
Validation loss decreased (1.006378 --> 1.003474).  Saving model ...
Validation loss decreased (1.003474 --> 0.999972).  Saving model ...
Validation loss decreased (0.999972 --> 0.996971).  Saving model ...
Validation loss decreased (0.996971 --> 0.993724).  Saving model ...
Validation loss decreased (0.993724 --> 0.990119).  Saving model ...
Validation loss decreased (0.990119 --> 0.988771).  Saving model ...
Validation loss decreased (0.988771 --> 0.985113).  Saving model ...
Validation loss decreased (0.985113 --> 0.981588).  Saving model ...
Validation loss decreased (0.981588 --> 0.978761).  Saving model ...
Validation loss decreased (0.978761 --> 0.975976).  Saving model ...
Validation loss decreased (0.975976 --> 0.973988).  Saving model ...
Validation loss decreased (0.973988 --> 0.971059).  Saving model ...
Validation loss decreased (0.971059 --> 0.967429).  Saving model ...
Validation loss decreased (0.967429 --> 0.964990).  Saving model ...
Validation loss decreased (0.964990 --> 0.963141).  Saving model ...
Validation loss decreased (0.963141 --> 0.960549).  Saving model ...
Validation loss decreased (0.960549 --> 0.957772).  Saving model ...
Validation loss decreased (0.957772 --> 0.955377).  Saving model ...
Validation loss decreased (0.955377 --> 0.952524).  Saving model ...
Validation loss decreased (0.952524 --> 0.951137).  Saving model ...
Validation loss decreased (0.951137 --> 0.947911).  Saving model ...
Validation loss decreased (0.947911 --> 0.945572).  Saving model ...
Validation loss decreased (0.945572 --> 0.943967).  Saving model ...
Validation loss decreased (0.943967 --> 0.942168).  Saving model ...
Validation loss decreased (0.942168 --> 0.939415).  Saving model ...
Validation loss decreased (0.939415 --> 0.937848).  Saving model ...
Validation loss decreased (0.937848 --> 0.935418).  Saving model ...
Validation loss decreased (0.935418 --> 0.933988).  Saving model ...
Validation loss decreased (0.933988 --> 0.932595).  Saving model ...
Validation loss decreased (0.932595 --> 0.930082).  Saving model ...
Validation loss decreased (0.930082 --> 0.928922).  Saving model ...
Validation loss decreased (0.928922 --> 0.927469).  Saving model ...
Validation loss decreased (0.927469 --> 0.925162).  Saving model ...
Validation loss decreased (0.925162 --> 0.923104).  Saving model ...
Validation loss decreased (0.923104 --> 0.921912).  Saving model ...
Validation loss decreased (0.921912 --> 0.920007).  Saving model ...
Validation loss decreased (0.920007 --> 0.919284).  Saving model ...
Validation loss decreased (0.919284 --> 0.918270).  Saving model ...
Validation loss decreased (0.918270 --> 0.917190).  Saving model ...
Validation loss decreased (0.917190 --> 0.916612).  Saving model ...
Validation loss decreased (0.916612 --> 0.915346).  Saving model ...
Validation loss decreased (0.915346 --> 0.914442).  Saving model ...
Validation loss decreased (0.914442 --> 0.914081).  Saving model ...
Validation loss decreased (0.914081 --> 0.912709).  Saving model ...
Validation loss decreased (0.912709 --> 0.911874).  Saving model ...
Validation loss decreased (0.911874 --> 0.911324).  Saving model ...
Validation loss decreased (0.911324 --> 0.910352).  Saving model ...
Validation loss decreased (0.910352 --> 0.910257).  Saving model ...
Validation loss decreased (0.910257 --> 0.908730).  Saving model ...
Validation loss decreased (0.908730 --> 0.908415).  Saving model ...
Validation loss decreased (0.908415 --> 0.907107).  Saving model ...
EarlyStopping counter: 1 out of 5.0
Validation loss decreased (0.907107 --> 0.906563).  Saving model ...
Validation loss decreased (0.906563 --> 0.905247).  Saving model ...
EarlyStopping counter: 1 out of 5.0
Validation loss decreased (0.905247 --> 0.903529).  Saving model ...
Validation loss decreased (0.903529 --> 0.902961).  Saving model ...
Validation loss decreased (0.902961 --> 0.902003).  Saving model ...
Validation loss decreased (0.902003 --> 0.901945).  Saving model ...
EarlyStopping counter: 1 out of 5.0
Validation loss decreased (0.901945 --> 0.901790).  Saving model ...
Validation loss decreased (0.901790 --> 0.899094).  Saving model ...
EarlyStopping counter: 1 out of 5.0
EarlyStopping counter: 2 out of 5.0
EarlyStopping counter: 3 out of 5.0
EarlyStopping counter: 4 out of 5.0
Validation loss decreased (0.899094 --> 0.896802).  Saving model ...
Validation loss decreased (0.896802 --> 0.896016).  Saving model ...
EarlyStopping counter: 1 out of 5.0
Validation loss decreased (0.896016 --> 0.895653).  Saving model ...
EarlyStopping counter: 1 out of 5.0
EarlyStopping counter: 2 out of 5.0
EarlyStopping counter: 3 out of 5.0
EarlyStopping counter: 4 out of 5.0
EarlyStopping counter: 5 out of 5.0
/localscratch/yinan.29546396.0/env/lib/python3.7/site-packages/torch/nn/functional.py:1794: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.
  warnings.warn("nn.functional.tanh is deprecated. Use torch.tanh instead.")
wandb: Waiting for W&B process to finish, PID 248771... (success).
wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: \ 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: | 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: / 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: \ 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: | 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: / 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: \ 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: | 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: / 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb:                                                                                
wandb: Run history:
wandb:     e_F1 ▁▁▃▄▄▅▅▅▆▆▆▆▆▆▇▇▇▇▇▇▇▇▇▇▇███████████████
wandb:   e_loss █▇▇▆▆▆▆▅▅▅▄▄▄▄▃▃▃▃▃▂▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:     t_F1 ▁▁▃▃▃▃▄▄▄▅▅▅▅▆▆▆▆▆▆▆▆▇▆▆▇▇▇▇██▇█▇▇█▇████
wandb:   t_loss ██▇▇▇▇▆▆▆▅▅▅▅▄▄▄▄▄▄▃▃▃▃▃▃▂▂▂▂▂▂▂▂▂▁▂▁▁▁▁
wandb: 
wandb: Run summary:
wandb:     e_F1 63.49449
wandb:   e_loss 0.89739
wandb:     t_F1 69.95736
wandb:   t_loss 0.74871
wandb: 
wandb: Synced 4 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Synced vivid-violet-1: https://wandb.ai/yinanazhou/xl_512_bs_8_lr_1e06_es_5_lc_True_nr_False_sr_True_stem_False_lemma_True_repeat_5_fold_2/runs/2imn0c3g
wandb: Find logs at: ./wandb/run-20220326_144608-2imn0c3g/logs/debug.log
wandb: 

