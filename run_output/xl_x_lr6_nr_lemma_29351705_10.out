Unloading StdEnv/2020

Due to MODULEPATH changes, the following have been reloaded:
  1) mii/1.1.1


The following have been reloaded with a version change:
  1) python/3.8.2 => python/3.7.4

Using base prefix '/cvmfs/soft.computecanada.ca/easybuild/software/2017/Core/python/3.7.4'
New python executable in /localscratch/yinan.29351705.0/env/bin/python
Installing setuptools, pip, wheel...
done.
Ignoring pip: markers 'python_version < "3"' don't match your environment
Looking in links: /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/nix/avx2, /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/nix/generic, /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic
Collecting pip
Installing collected packages: pip
  Found existing installation: pip 19.1.1
    Uninstalling pip-19.1.1:
      Successfully uninstalled pip-19.1.1
Successfully installed pip-21.2.3+computecanada
Looking in links: /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/nix/avx2, /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/nix/generic, /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/keras-2.8.0+computecanada-py2.py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/Keras_Preprocessing-1.1.2+computecanada-py3-none-any.whl
Requirement already satisfied: matplotlib in /cvmfs/soft.computecanada.ca/easybuild/software/2017/Core/scipy-stack/2019a/lib/python3.7/site-packages (from -r requirements.txt (line 3)) (3.0.2)
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/nltk-3.6.5+computecanada-py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/scikit_learn-0.22.1+computecanada-cp37-cp37m-linux_x86_64.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/tensorboard-2.3.0+computecanada-py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/tensorboard_plugin_wit-1.7.0+computecanada-py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/tensorflow_gpu-2.3.0+computecanada-cp37-cp37m-linux_x86_64.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/tensorflow_estimator-2.3.0+computecanada-py2.py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/tokenizers-0.5.2+computecanada-cp37-cp37m-linux_x86_64.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/nix/avx2/torch-1.4.0+computecanada-cp37-cp37m-linux_x86_64.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/torchtext-0.6.0+computecanada-py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/torchvision-0.8.2+computecanada-cp37-cp37m-linux_x86_64.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/transformers-2.5.1+computecanada-py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/urllib3-1.26.7+computecanada-py2.py3-none-any.whl
ERROR: Could not find a version that satisfies the requirement regex>=2021.8.3 (from nltk) (from versions: 2018.1.10+computecanada, 2019.11.1+computecanada, 2020.11.13+computecanada)
ERROR: No matching distribution found for regex>=2021.8.3
Looking in links: /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/nix/avx2, /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/nix/generic, /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic
ERROR: Could not find a version that satisfies the requirement numpy==1.20.0+computacanada (from versions: 1.15.0+computecanada, 1.15.2+computecanada, 1.15.4+computecanada, 1.16.0+computecanada, 1.16.2+computecanada, 1.16.3+computecanada, 1.17.4+computecanada, 1.18.1+computecanada, 1.18.4+computecanada, 1.19.1+computecanada, 1.19.2+computecanada, 1.20.2+computecanada)
ERROR: No matching distribution found for numpy==1.20.0+computacanada
Looking in links: /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/nix/avx2, /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/nix/generic, /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/wandb-0.12.5+computecanada-py2.py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/configparser-5.0.2+computecanada-py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/GitPython-3.1.24+computecanada-py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/six-1.16.0+computecanada-py2.py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/yaspin-2.1.0+computecanada-py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/promise-2.3+computecanada-py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/subprocess32-3.5.4+computecanada-py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/docker_pycreds-0.4.0+computecanada-py2.py3-none-any.whl
Requirement already satisfied: python-dateutil>=2.6.1 in /cvmfs/soft.computecanada.ca/easybuild/software/2017/Core/scipy-stack/2019a/lib/python3.7/site-packages (from wandb) (2.7.5)
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/psutil-5.7.3+computecanada-cp37-cp37m-linux_x86_64.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/sentry_sdk-1.5.0+computecanada-py2.py3-none-any.whl
Requirement already satisfied: requests<3,>=2.0.0 in /cvmfs/soft.computecanada.ca/easybuild/software/2017/Core/scipy-stack/2019a/lib/python3.7/site-packages (from wandb) (2.21.0)
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/pathtools-0.1.2+computecanada-py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/click-8.0.4+computecanada-py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/PyYAML-5.3.1+computecanada-cp37-cp37m-linux_x86_64.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/shortuuid-1.0.1+computecanada-py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/protobuf-3.19.4+computecanada-py2.py3-none-any.whl
Requirement already satisfied: importlib-metadata in /cvmfs/soft.computecanada.ca/easybuild/software/2017/Core/scipy-stack/2019a/lib/python3.7/site-packages (from Click!=8.0.0,>=7.0->wandb) (0.8)
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/typing_extensions-4.1.1+computecanada-py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/gitdb-4.0.9+computecanada-py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/smmap-5.0.0+computecanada-py3-none-any.whl
Requirement already satisfied: urllib3<1.25,>=1.21.1 in /cvmfs/soft.computecanada.ca/easybuild/software/2017/Core/scipy-stack/2019a/lib/python3.7/site-packages (from requests<3,>=2.0.0->wandb) (1.24.1)
Requirement already satisfied: certifi>=2017.4.17 in /cvmfs/soft.computecanada.ca/easybuild/software/2017/Core/scipy-stack/2019a/lib/python3.7/site-packages (from requests<3,>=2.0.0->wandb) (2018.11.29)
Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /cvmfs/soft.computecanada.ca/easybuild/software/2017/Core/scipy-stack/2019a/lib/python3.7/site-packages (from requests<3,>=2.0.0->wandb) (3.0.4)
Requirement already satisfied: idna<2.9,>=2.5 in /cvmfs/soft.computecanada.ca/easybuild/software/2017/Core/scipy-stack/2019a/lib/python3.7/site-packages (from requests<3,>=2.0.0->wandb) (2.8)
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/termcolor-1.1.0+computecanada-py3-none-any.whl
Requirement already satisfied: zipp>=0.3.2 in /cvmfs/soft.computecanada.ca/easybuild/software/2017/Core/scipy-stack/2019a/lib/python3.7/site-packages (from importlib-metadata->Click!=8.0.0,>=7.0->wandb) (0.3.3)
Installing collected packages: smmap, typing-extensions, termcolor, six, gitdb, yaspin, subprocess32, shortuuid, sentry-sdk, PyYAML, psutil, protobuf, promise, pathtools, GitPython, docker-pycreds, configparser, Click, wandb
  Attempting uninstall: six
    Found existing installation: six 1.12.0
    Not uninstalling six at /cvmfs/soft.computecanada.ca/easybuild/software/2017/Core/scipy-stack/2019a/lib/python3.7/site-packages, outside environment /localscratch/yinan.29351705.0/env
    Can't uninstall 'six'. No files were found to uninstall.
Successfully installed Click-8.0.4+computecanada GitPython-3.1.24+computecanada PyYAML-5.3.1+computecanada configparser-5.0.2+computecanada docker-pycreds-0.4.0+computecanada gitdb-4.0.9+computecanada pathtools-0.1.2+computecanada promise-2.3+computecanada protobuf-3.19.4+computecanada psutil-5.7.3+computecanada sentry-sdk-1.5.0+computecanada shortuuid-1.0.1+computecanada six-1.16.0+computecanada smmap-5.0.0+computecanada subprocess32-3.5.4+computecanada termcolor-1.1.0+computecanada typing-extensions-4.1.1+computecanada wandb-0.12.5+computecanada yaspin-2.1.0+computecanada
Looking in links: /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/nix/avx2, /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/nix/generic, /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic
ERROR: Could not find a version that satisfies the requirement sagemaker (from versions: none)
ERROR: No matching distribution found for sagemaker
Looking in links: /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/nix/avx2, /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/nix/generic, /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/torch-1.9.1+computecanada-cp37-cp37m-linux_x86_64.whl
Requirement already satisfied: typing-extensions in /localscratch/yinan.29351705.0/env/lib/python3.7/site-packages (from torch) (4.1.1+computecanada)
Installing collected packages: torch
Successfully installed torch-1.9.1+computecanada
Looking in links: /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/nix/avx2, /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/nix/generic, /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/transformers-2.5.1+computecanada-py3-none-any.whl
Requirement already satisfied: numpy in /cvmfs/soft.computecanada.ca/easybuild/software/2017/Core/scipy-stack/2019a/lib/python3.7/site-packages (from transformers==2.5.1+computecanada) (1.16.0)
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/tqdm-4.63.1+computecanada-py2.py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/sentencepiece-0.1.91+computecanada-cp37-cp37m-linux_x86_64.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/regex-2020.11.13+computecanada-cp37-cp37m-linux_x86_64.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/filelock-3.4.2+computecanada-py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/boto3-1.21.14+computecanada-py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/tokenizers-0.5.2+computecanada-cp37-cp37m-linux_x86_64.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/sacremoses-0.0.49+computecanada-py3-none-any.whl
Requirement already satisfied: requests in /cvmfs/soft.computecanada.ca/easybuild/software/2017/Core/scipy-stack/2019a/lib/python3.7/site-packages (from transformers==2.5.1+computecanada) (2.21.0)
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/botocore-1.24.14+computecanada-py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/s3transfer-0.5.1+computecanada-py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/jmespath-0.10.0+computecanada-py2.py3-none-any.whl
Requirement already satisfied: python-dateutil<3.0.0,>=2.1 in /cvmfs/soft.computecanada.ca/easybuild/software/2017/Core/scipy-stack/2019a/lib/python3.7/site-packages (from botocore<1.25.0,>=1.24.14->boto3->transformers==2.5.1+computecanada) (2.7.5)
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/urllib3-1.26.8+computecanada-py2.py3-none-any.whl
Requirement already satisfied: six>=1.5 in /localscratch/yinan.29351705.0/env/lib/python3.7/site-packages (from python-dateutil<3.0.0,>=2.1->botocore<1.25.0,>=1.24.14->boto3->transformers==2.5.1+computecanada) (1.16.0+computecanada)
Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /cvmfs/soft.computecanada.ca/easybuild/software/2017/Core/scipy-stack/2019a/lib/python3.7/site-packages (from requests->transformers==2.5.1+computecanada) (3.0.4)
Requirement already satisfied: certifi>=2017.4.17 in /cvmfs/soft.computecanada.ca/easybuild/software/2017/Core/scipy-stack/2019a/lib/python3.7/site-packages (from requests->transformers==2.5.1+computecanada) (2018.11.29)
Requirement already satisfied: idna<2.9,>=2.5 in /cvmfs/soft.computecanada.ca/easybuild/software/2017/Core/scipy-stack/2019a/lib/python3.7/site-packages (from requests->transformers==2.5.1+computecanada) (2.8)
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/requests-2.27.1+computecanada-py2.py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/charset_normalizer-2.0.12+computecanada-py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/joblib-1.1.0+computecanada-py2.py3-none-any.whl
Requirement already satisfied: click in /localscratch/yinan.29351705.0/env/lib/python3.7/site-packages (from sacremoses->transformers==2.5.1+computecanada) (8.0.4+computecanada)
Requirement already satisfied: importlib-metadata in /cvmfs/soft.computecanada.ca/easybuild/software/2017/Core/scipy-stack/2019a/lib/python3.7/site-packages (from click->sacremoses->transformers==2.5.1+computecanada) (0.8)
Requirement already satisfied: zipp>=0.3.2 in /cvmfs/soft.computecanada.ca/easybuild/software/2017/Core/scipy-stack/2019a/lib/python3.7/site-packages (from importlib-metadata->click->sacremoses->transformers==2.5.1+computecanada) (0.3.3)
Installing collected packages: urllib3, jmespath, botocore, tqdm, s3transfer, regex, joblib, charset-normalizer, tokenizers, sentencepiece, sacremoses, requests, filelock, boto3, transformers
  Attempting uninstall: urllib3
    Found existing installation: urllib3 1.24.1
    Not uninstalling urllib3 at /cvmfs/soft.computecanada.ca/easybuild/software/2017/Core/scipy-stack/2019a/lib/python3.7/site-packages, outside environment /localscratch/yinan.29351705.0/env
    Can't uninstall 'urllib3'. No files were found to uninstall.
  Attempting uninstall: requests
    Found existing installation: requests 2.21.0
    Not uninstalling requests at /cvmfs/soft.computecanada.ca/easybuild/software/2017/Core/scipy-stack/2019a/lib/python3.7/site-packages, outside environment /localscratch/yinan.29351705.0/env
    Can't uninstall 'requests'. No files were found to uninstall.
Successfully installed boto3-1.21.14+computecanada botocore-1.24.14+computecanada charset-normalizer-2.0.12+computecanada filelock-3.4.2+computecanada jmespath-0.10.0+computecanada joblib-1.1.0+computecanada regex-2020.11.13+computecanada requests-2.27.1+computecanada s3transfer-0.5.1+computecanada sacremoses-0.0.49+computecanada sentencepiece-0.1.91+computecanada tokenizers-0.5.2+computecanada tqdm-4.63.1+computecanada transformers-2.5.1+computecanada urllib3-1.26.8+computecanada
Looking in links: /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/nix/avx2, /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/nix/generic, /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/tensorflow_gpu-2.3.0+computecanada-cp37-cp37m-linux_x86_64.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/nix/avx2/h5py-2.10.0+computecanada-cp37-cp37m-linux_x86_64.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/wrapt-1.11.2+computecanada-cp37-cp37m-linux_x86_64.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/absl_py-1.0.0+computecanada-py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/grpcio-1.38.0+computecanada-cp37-cp37m-linux_x86_64.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/tensorboard-2.8.0+computecanada-py3-none-any.whl
Requirement already satisfied: termcolor>=1.1.0 in /localscratch/yinan.29351705.0/env/lib/python3.7/site-packages (from tensorflow_gpu==2.3.0+computecanada) (1.1.0+computecanada)
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/opt_einsum-3.3.0+computecanada-py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/astunparse-1.6.3+computecanada-py2.py3-none-any.whl
Requirement already satisfied: numpy<1.19.0,>=1.16.0 in /cvmfs/soft.computecanada.ca/easybuild/software/2017/Core/scipy-stack/2019a/lib/python3.7/site-packages (from tensorflow_gpu==2.3.0+computecanada) (1.16.0)
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/google_pasta-0.2.0+computecanada-py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/Keras_Preprocessing-1.1.2+computecanada-py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/gast-0.3.3+computecanada-py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/nix/generic/scipy-1.4.1+computecanada-cp37-cp37m-linux_x86_64.whl
Requirement already satisfied: protobuf>=3.9.2 in /localscratch/yinan.29351705.0/env/lib/python3.7/site-packages (from tensorflow_gpu==2.3.0+computecanada) (3.19.4+computecanada)
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/tensorflow_estimator-2.3.0+computecanada-py2.py3-none-any.whl
Requirement already satisfied: wheel>=0.26 in /localscratch/yinan.29351705.0/env/lib/python3.7/site-packages (from tensorflow_gpu==2.3.0+computecanada) (0.33.4)
Requirement already satisfied: six>=1.12.0 in /localscratch/yinan.29351705.0/env/lib/python3.7/site-packages (from tensorflow_gpu==2.3.0+computecanada) (1.16.0+computecanada)
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/google_auth-2.3.3+computecanada-py2.py3-none-any.whl
Requirement already satisfied: requests<3,>=2.21.0 in /localscratch/yinan.29351705.0/env/lib/python3.7/site-packages (from tensorboard<3,>=2.3.0->tensorflow_gpu==2.3.0+computecanada) (2.27.1+computecanada)
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/tensorboard_data_server-0.6.1+computecanada-py3-none-linux_x86_64.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/google_auth_oauthlib-0.4.6+computecanada-py2.py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/tensorboard_plugin_wit-1.8.0+computecanada-py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/Werkzeug-2.0.3+computecanada-py3-none-any.whl
Requirement already satisfied: setuptools>=41.0.0 in /localscratch/yinan.29351705.0/env/lib/python3.7/site-packages (from tensorboard<3,>=2.3.0->tensorflow_gpu==2.3.0+computecanada) (41.0.1)
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/Markdown-3.3.6+computecanada-py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/rsa-4.8+computecanada-py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/cachetools-4.2.4+computecanada-py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/pyasn1_modules-0.2.8+computecanada-py2.py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/requests_oauthlib-1.3.0+computecanada-py2.py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/importlib_metadata-4.10.1+computecanada-py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/zipp-3.7.0+computecanada-py3-none-any.whl
Requirement already satisfied: typing-extensions>=3.6.4 in /localscratch/yinan.29351705.0/env/lib/python3.7/site-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard<3,>=2.3.0->tensorflow_gpu==2.3.0+computecanada) (4.1.1+computecanada)
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/pyasn1-0.4.8+computecanada-py2.py3-none-any.whl
Requirement already satisfied: urllib3<1.27,>=1.21.1 in /localscratch/yinan.29351705.0/env/lib/python3.7/site-packages (from requests<3,>=2.21.0->tensorboard<3,>=2.3.0->tensorflow_gpu==2.3.0+computecanada) (1.26.8+computecanada)
Requirement already satisfied: charset-normalizer~=2.0.0 in /localscratch/yinan.29351705.0/env/lib/python3.7/site-packages (from requests<3,>=2.21.0->tensorboard<3,>=2.3.0->tensorflow_gpu==2.3.0+computecanada) (2.0.12+computecanada)
Requirement already satisfied: certifi>=2017.4.17 in /cvmfs/soft.computecanada.ca/easybuild/software/2017/Core/scipy-stack/2019a/lib/python3.7/site-packages (from requests<3,>=2.21.0->tensorboard<3,>=2.3.0->tensorflow_gpu==2.3.0+computecanada) (2018.11.29)
Requirement already satisfied: idna<4,>=2.5 in /cvmfs/soft.computecanada.ca/easybuild/software/2017/Core/scipy-stack/2019a/lib/python3.7/site-packages (from requests<3,>=2.21.0->tensorboard<3,>=2.3.0->tensorflow_gpu==2.3.0+computecanada) (2.8)
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/oauthlib-3.1.1+computecanada-py2.py3-none-any.whl
Installing collected packages: pyasn1, zipp, rsa, pyasn1-modules, oauthlib, cachetools, requests-oauthlib, importlib-metadata, google-auth, werkzeug, tensorboard-plugin-wit, tensorboard-data-server, markdown, grpcio, google-auth-oauthlib, absl-py, wrapt, tensorflow-estimator, tensorboard, scipy, opt-einsum, keras-preprocessing, h5py, google-pasta, gast, astunparse, tensorflow-gpu
  Attempting uninstall: pyasn1
    Found existing installation: pyasn1 0.4.3
    Not uninstalling pyasn1 at /cvmfs/soft.computecanada.ca/easybuild/software/2017/Core/scipy-stack/2019a/lib/python3.7/site-packages, outside environment /localscratch/yinan.29351705.0/env
    Can't uninstall 'pyasn1'. No files were found to uninstall.
  Attempting uninstall: zipp
    Found existing installation: zipp 0.3.3
    Not uninstalling zipp at /cvmfs/soft.computecanada.ca/easybuild/software/2017/Core/scipy-stack/2019a/lib/python3.7/site-packages, outside environment /localscratch/yinan.29351705.0/env
    Can't uninstall 'zipp'. No files were found to uninstall.
  Attempting uninstall: importlib-metadata
    Found existing installation: importlib-metadata 0.8
    Not uninstalling importlib-metadata at /cvmfs/soft.computecanada.ca/easybuild/software/2017/Core/scipy-stack/2019a/lib/python3.7/site-packages, outside environment /localscratch/yinan.29351705.0/env
    Can't uninstall 'importlib-metadata'. No files were found to uninstall.
  Attempting uninstall: scipy
    Found existing installation: scipy 1.2.0
    Not uninstalling scipy at /cvmfs/soft.computecanada.ca/easybuild/software/2017/Core/scipy-stack/2019a/lib/python3.7/site-packages, outside environment /localscratch/yinan.29351705.0/env
    Can't uninstall 'scipy'. No files were found to uninstall.
Successfully installed absl-py-1.0.0+computecanada astunparse-1.6.3+computecanada cachetools-4.2.4+computecanada gast-0.3.3+computecanada google-auth-2.3.3+computecanada google-auth-oauthlib-0.4.6+computecanada google-pasta-0.2.0+computecanada grpcio-1.38.0+computecanada h5py-2.10.0+computecanada importlib-metadata-4.10.1+computecanada keras-preprocessing-1.1.2+computecanada markdown-3.3.6+computecanada oauthlib-3.1.1+computecanada opt-einsum-3.3.0+computecanada pyasn1-0.4.8+computecanada pyasn1-modules-0.2.8+computecanada requests-oauthlib-1.3.0+computecanada rsa-4.8+computecanada scipy-1.4.1+computecanada tensorboard-2.8.0+computecanada tensorboard-data-server-0.6.1+computecanada tensorboard-plugin-wit-1.8.0+computecanada tensorflow-estimator-2.3.0+computecanada tensorflow-gpu-2.3.0+computecanada werkzeug-2.0.3+computecanada wrapt-1.11.2+computecanada zipp-3.7.0+computecanada
Looking in links: /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/nix/avx2, /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/nix/generic, /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/keras-2.8.0+computecanada-py2.py3-none-any.whl
Installing collected packages: Keras
Successfully installed Keras-2.8.0+computecanada
Looking in links: /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/nix/avx2, /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/nix/generic, /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/urllib3-1.26.7+computecanada-py2.py3-none-any.whl
Installing collected packages: urllib3
  Attempting uninstall: urllib3
    Found existing installation: urllib3 1.26.8+computecanada
    Uninstalling urllib3-1.26.8+computecanada:
      Successfully uninstalled urllib3-1.26.8+computecanada
Successfully installed urllib3-1.26.7+computecanada
Looking in links: /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/nix/avx2, /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/nix/generic, /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/nltk-3.7+computecanada-py3-none-any.whl
Requirement already satisfied: joblib in /localscratch/yinan.29351705.0/env/lib/python3.7/site-packages (from nltk) (1.1.0+computecanada)
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/nltk-3.6.5+computecanada-py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/nltk-3.6.3+computecanada-py3-none-any.whl
Requirement already satisfied: click in /localscratch/yinan.29351705.0/env/lib/python3.7/site-packages (from nltk) (8.0.4+computecanada)
Requirement already satisfied: tqdm in /localscratch/yinan.29351705.0/env/lib/python3.7/site-packages (from nltk) (4.63.1+computecanada)
Requirement already satisfied: regex in /localscratch/yinan.29351705.0/env/lib/python3.7/site-packages (from nltk) (2020.11.13+computecanada)
Requirement already satisfied: importlib-metadata in /localscratch/yinan.29351705.0/env/lib/python3.7/site-packages (from click->nltk) (4.10.1+computecanada)
Requirement already satisfied: zipp>=0.5 in /localscratch/yinan.29351705.0/env/lib/python3.7/site-packages (from importlib-metadata->click->nltk) (3.7.0+computecanada)
Requirement already satisfied: typing-extensions>=3.6.4 in /localscratch/yinan.29351705.0/env/lib/python3.7/site-packages (from importlib-metadata->click->nltk) (4.1.1+computecanada)
Installing collected packages: nltk
Successfully installed nltk-3.6.3+computecanada
Looking in links: /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/nix/avx2, /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/nix/generic, /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/scikit_learn-0.22.1+computecanada-cp37-cp37m-linux_x86_64.whl
Requirement already satisfied: joblib>=0.11 in /localscratch/yinan.29351705.0/env/lib/python3.7/site-packages (from scikit-learn==0.22.1) (1.1.0+computecanada)
Requirement already satisfied: numpy>=1.11.0 in /cvmfs/soft.computecanada.ca/easybuild/software/2017/Core/scipy-stack/2019a/lib/python3.7/site-packages (from scikit-learn==0.22.1) (1.16.0)
Requirement already satisfied: scipy>=0.17.0 in /localscratch/yinan.29351705.0/env/lib/python3.7/site-packages (from scikit-learn==0.22.1) (1.4.1+computecanada)
Installing collected packages: scikit-learn
Successfully installed scikit-learn-0.22.1+computecanada
Looking in links: /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/nix/avx2, /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/nix/generic, /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic
Requirement already satisfied: tokenizers==0.5.2 in /localscratch/yinan.29351705.0/env/lib/python3.7/site-packages (0.5.2+computecanada)
wandb: Appending key for api.wandb.ai to your netrc file: /home/yinan/.netrc
Starting Task
2022-03-27 09:18:05.345352: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1
[nltk_data] Downloading package stopwords to /home/yinan/nltk_data...
[nltk_data]   Package stopwords is already up-to-date!
[nltk_data] Downloading package wordnet to /home/yinan/nltk_data...
[nltk_data]   Package wordnet is already up-to-date!
wandb: Currently logged in as: yinanazhou (use `wandb login --relogin` to force relogin)
wandb: wandb version 0.12.11 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
2022-03-27 09:18:17.774683: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1
wandb: Tracking run with wandb version 0.12.5
wandb: Syncing run polished-butterfly-3
wandb: ⭐️ View project at https://wandb.ai/yinanazhou/xl_512_bs_8_lr_1e06_es_10_lc_False_nr_True_sr_False_stem_False_lemma_True_repeat_1_fold_1
wandb: 🚀 View run at https://wandb.ai/yinanazhou/xl_512_bs_8_lr_1e06_es_10_lc_False_nr_True_sr_False_stem_False_lemma_True_repeat_1_fold_1/runs/2rb3xiq0
wandb: Run data is saved locally in /project/6002780/yinan/Thesis_MER_Lyrics/lyric-emotion/wandb/run-20220327_091815-2rb3xiq0
wandb: Run `wandb offline` to turn off syncing.

Validation loss decreased (inf --> 1.433368).  Saving model ...
Validation loss decreased (1.433368 --> 1.413197).  Saving model ...
Validation loss decreased (1.413197 --> 1.396222).  Saving model ...
Validation loss decreased (1.396222 --> 1.382296).  Saving model ...
Validation loss decreased (1.382296 --> 1.371596).  Saving model ...
Validation loss decreased (1.371596 --> 1.362711).  Saving model ...
Validation loss decreased (1.362711 --> 1.355298).  Saving model ...
Validation loss decreased (1.355298 --> 1.348129).  Saving model ...
Validation loss decreased (1.348129 --> 1.342084).  Saving model ...
Validation loss decreased (1.342084 --> 1.335481).  Saving model ...
Validation loss decreased (1.335481 --> 1.328674).  Saving model ...
Validation loss decreased (1.328674 --> 1.322592).  Saving model ...
Validation loss decreased (1.322592 --> 1.315222).  Saving model ...
Validation loss decreased (1.315222 --> 1.308229).  Saving model ...
Validation loss decreased (1.308229 --> 1.300365).  Saving model ...
Validation loss decreased (1.300365 --> 1.292780).  Saving model ...
Validation loss decreased (1.292780 --> 1.285575).  Saving model ...
Validation loss decreased (1.285575 --> 1.279976).  Saving model ...
Validation loss decreased (1.279976 --> 1.272279).  Saving model ...
Validation loss decreased (1.272279 --> 1.264902).  Saving model ...
Validation loss decreased (1.264902 --> 1.257846).  Saving model ...
Validation loss decreased (1.257846 --> 1.252269).  Saving model ...
Validation loss decreased (1.252269 --> 1.248094).  Saving model ...
Validation loss decreased (1.248094 --> 1.242558).  Saving model ...
Validation loss decreased (1.242558 --> 1.236885).  Saving model ...
Validation loss decreased (1.236885 --> 1.232027).  Saving model ...
Validation loss decreased (1.232027 --> 1.228192).  Saving model ...
Validation loss decreased (1.228192 --> 1.222529).  Saving model ...
Validation loss decreased (1.222529 --> 1.217336).  Saving model ...
Validation loss decreased (1.217336 --> 1.213628).  Saving model ...
Validation loss decreased (1.213628 --> 1.208543).  Saving model ...
Validation loss decreased (1.208543 --> 1.204009).  Saving model ...
Validation loss decreased (1.204009 --> 1.201104).  Saving model ...
Validation loss decreased (1.201104 --> 1.195931).  Saving model ...
Validation loss decreased (1.195931 --> 1.192949).  Saving model ...
Validation loss decreased (1.192949 --> 1.188185).  Saving model ...
Validation loss decreased (1.188185 --> 1.186684).  Saving model ...
Validation loss decreased (1.186684 --> 1.180882).  Saving model ...
Validation loss decreased (1.180882 --> 1.176323).  Saving model ...
Validation loss decreased (1.176323 --> 1.174274).  Saving model ...
Validation loss decreased (1.174274 --> 1.169751).  Saving model ...
Validation loss decreased (1.169751 --> 1.164272).  Saving model ...
Validation loss decreased (1.164272 --> 1.161786).  Saving model ...
Validation loss decreased (1.161786 --> 1.159083).  Saving model ...
Validation loss decreased (1.159083 --> 1.154588).  Saving model ...
Validation loss decreased (1.154588 --> 1.151675).  Saving model ...
Validation loss decreased (1.151675 --> 1.150207).  Saving model ...
Validation loss decreased (1.150207 --> 1.144981).  Saving model ...
Validation loss decreased (1.144981 --> 1.139035).  Saving model ...
Validation loss decreased (1.139035 --> 1.135946).  Saving model ...
Validation loss decreased (1.135946 --> 1.130567).  Saving model ...
Validation loss decreased (1.130567 --> 1.129001).  Saving model ...
Validation loss decreased (1.129001 --> 1.127043).  Saving model ...
Validation loss decreased (1.127043 --> 1.123315).  Saving model ...
Validation loss decreased (1.123315 --> 1.122343).  Saving model ...
Validation loss decreased (1.122343 --> 1.118605).  Saving model ...
Validation loss decreased (1.118605 --> 1.116219).  Saving model ...
Validation loss decreased (1.116219 --> 1.113009).  Saving model ...
Validation loss decreased (1.113009 --> 1.108880).  Saving model ...
Validation loss decreased (1.108880 --> 1.106966).  Saving model ...
Validation loss decreased (1.106966 --> 1.106184).  Saving model ...
Validation loss decreased (1.106184 --> 1.102608).  Saving model ...
Validation loss decreased (1.102608 --> 1.099298).  Saving model ...
Validation loss decreased (1.099298 --> 1.096980).  Saving model ...
Validation loss decreased (1.096980 --> 1.096959).  Saving model ...
Validation loss decreased (1.096959 --> 1.092171).  Saving model ...
Validation loss decreased (1.092171 --> 1.089939).  Saving model ...
Validation loss decreased (1.089939 --> 1.089407).  Saving model ...
Validation loss decreased (1.089407 --> 1.086206).  Saving model ...
EarlyStopping counter: 1 out of 10.0
Validation loss decreased (1.086206 --> 1.082880).  Saving model ...
Validation loss decreased (1.082880 --> 1.076103).  Saving model ...
Validation loss decreased (1.076103 --> 1.075812).  Saving model ...
Validation loss decreased (1.075812 --> 1.073970).  Saving model ...
Validation loss decreased (1.073970 --> 1.072363).  Saving model ...
Validation loss decreased (1.072363 --> 1.071560).  Saving model ...
Validation loss decreased (1.071560 --> 1.066718).  Saving model ...
Validation loss decreased (1.066718 --> 1.065496).  Saving model ...
EarlyStopping counter: 1 out of 10.0
Validation loss decreased (1.065496 --> 1.061344).  Saving model ...
EarlyStopping counter: 1 out of 10.0
EarlyStopping counter: 2 out of 10.0
Validation loss decreased (1.061344 --> 1.061072).  Saving model ...
Validation loss decreased (1.061072 --> 1.059627).  Saving model ...
Validation loss decreased (1.059627 --> 1.052267).  Saving model ...
Validation loss decreased (1.052267 --> 1.051768).  Saving model ...
Validation loss decreased (1.051768 --> 1.051181).  Saving model ...
EarlyStopping counter: 1 out of 10.0
EarlyStopping counter: 2 out of 10.0
EarlyStopping counter: 3 out of 10.0
Validation loss decreased (1.051181 --> 1.050121).  Saving model ...
Validation loss decreased (1.050121 --> 1.048421).  Saving model ...
Validation loss decreased (1.048421 --> 1.044520).  Saving model ...
EarlyStopping counter: 1 out of 10.0
EarlyStopping counter: 2 out of 10.0
Validation loss decreased (1.044520 --> 1.043683).  Saving model ...
EarlyStopping counter: 1 out of 10.0
Validation loss decreased (1.043683 --> 1.040988).  Saving model ...
Validation loss decreased (1.040988 --> 1.040930).  Saving model ...
EarlyStopping counter: 1 out of 10.0
Validation loss decreased (1.040930 --> 1.040513).  Saving model ...
EarlyStopping counter: 1 out of 10.0
Validation loss decreased (1.040513 --> 1.037540).  Saving model ...
Validation loss decreased (1.037540 --> 1.034776).  Saving model ...
EarlyStopping counter: 1 out of 10.0
EarlyStopping counter: 2 out of 10.0
Validation loss decreased (1.034776 --> 1.032693).  Saving model ...
Validation loss decreased (1.032693 --> 1.032438).  Saving model ...
Validation loss decreased (1.032438 --> 1.031362).  Saving model ...
Validation loss decreased (1.031362 --> 1.029571).  Saving model ...
EarlyStopping counter: 1 out of 10.0
EarlyStopping counter: 2 out of 10.0
EarlyStopping counter: 3 out of 10.0
EarlyStopping counter: 4 out of 10.0
EarlyStopping counter: 5 out of 10.0
EarlyStopping counter: 6 out of 10.0
Validation loss decreased (1.029571 --> 1.028612).  Saving model ...
Validation loss decreased (1.028612 --> 1.027274).  Saving model ...
EarlyStopping counter: 1 out of 10.0
Validation loss decreased (1.027274 --> 1.024947).  Saving model ...
EarlyStopping counter: 1 out of 10.0
EarlyStopping counter: 2 out of 10.0
Validation loss decreased (1.024947 --> 1.024598).  Saving model ...
EarlyStopping counter: 1 out of 10.0
Validation loss decreased (1.024598 --> 1.023650).  Saving model ...
EarlyStopping counter: 1 out of 10.0
Validation loss decreased (1.023650 --> 1.023413).  Saving model ...
EarlyStopping counter: 1 out of 10.0
EarlyStopping counter: 2 out of 10.0
Validation loss decreased (1.023413 --> 1.019503).  Saving model ...
EarlyStopping counter: 1 out of 10.0
EarlyStopping counter: 2 out of 10.0
EarlyStopping counter: 3 out of 10.0
EarlyStopping counter: 4 out of 10.0
EarlyStopping counter: 5 out of 10.0
EarlyStopping counter: 6 out of 10.0
EarlyStopping counter: 7 out of 10.0
EarlyStopping counter: 8 out of 10.0
EarlyStopping counter: 9 out of 10.0
EarlyStopping counter: 10 out of 10.0
/localscratch/yinan.29351705.0/env/lib/python3.7/site-packages/torch/nn/functional.py:1794: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.
  warnings.warn("nn.functional.tanh is deprecated. Use torch.tanh instead.")
/localscratch/yinan.29351705.0/env/lib/python3.7/site-packages/transformers/optimization.py:155: UserWarning: This overload of add_ is deprecated:
	add_(Number alpha, Tensor other)
Consider using one of the following signatures instead:
	add_(Tensor other, *, Number alpha) (Triggered internally at  ../torch/csrc/utils/python_arg_parser.cpp:1025.)
  exp_avg.mul_(beta1).add_(1.0 - beta1, grad)
wandb: Waiting for W&B process to finish, PID 2223... (success).
wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: \ 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: | 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: / 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: \ 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: | 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: / 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: \ 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: | 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: / 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb:                                                                                
wandb: Run history:
wandb:     e_F1 ▁▂▃▄▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇▇▇▇▇▇████████████████
wandb:   e_loss █▇▇▆▆▆▅▅▄▄▄▄▃▃▃▃▃▂▂▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:     t_F1 ▁▁▂▃▄▃▄▄▅▅▅▅▅▆▆▆▆▆▆▇▇▆▇▆▇▇▇▇▇▇▇█▇▇█▇████
wandb:   t_loss ██▇▇▇▆▆▆▅▅▅▅▄▄▄▄▄▃▃▃▃▃▃▃▂▃▂▂▂▂▂▂▂▂▂▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:     e_F1 57.72489
wandb:   e_loss 1.02047
wandb:     t_F1 72.91967
wandb:   t_loss 0.73586
wandb: 
wandb: Synced 4 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Synced polished-butterfly-3: https://wandb.ai/yinanazhou/xl_512_bs_8_lr_1e06_es_10_lc_False_nr_True_sr_False_stem_False_lemma_True_repeat_1_fold_1/runs/2rb3xiq0
wandb: Find logs at: ./wandb/run-20220327_091815-2rb3xiq0/logs/debug.log
wandb: 

wandb: wandb version 0.12.11 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
2022-03-27 10:47:17.874300: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1
wandb: Tracking run with wandb version 0.12.5
wandb: Syncing run decent-plant-3
wandb: ⭐️ View project at https://wandb.ai/yinanazhou/xl_512_bs_8_lr_1e06_es_10_lc_False_nr_True_sr_False_stem_False_lemma_True_repeat_1_fold_2
wandb: 🚀 View run at https://wandb.ai/yinanazhou/xl_512_bs_8_lr_1e06_es_10_lc_False_nr_True_sr_False_stem_False_lemma_True_repeat_1_fold_2/runs/2m1wvcbl
wandb: Run data is saved locally in /project/6002780/yinan/Thesis_MER_Lyrics/lyric-emotion/wandb/run-20220327_104714-2m1wvcbl
wandb: Run `wandb offline` to turn off syncing.

Validation loss decreased (inf --> 1.407543).  Saving model ...
Validation loss decreased (1.407543 --> 1.395564).  Saving model ...
Validation loss decreased (1.395564 --> 1.386678).  Saving model ...
Validation loss decreased (1.386678 --> 1.380304).  Saving model ...
Validation loss decreased (1.380304 --> 1.374686).  Saving model ...
Validation loss decreased (1.374686 --> 1.369775).  Saving model ...
Validation loss decreased (1.369775 --> 1.364699).  Saving model ...
Validation loss decreased (1.364699 --> 1.360210).  Saving model ...
Validation loss decreased (1.360210 --> 1.355717).  Saving model ...
Validation loss decreased (1.355717 --> 1.351411).  Saving model ...
Validation loss decreased (1.351411 --> 1.346978).  Saving model ...
Validation loss decreased (1.346978 --> 1.342274).  Saving model ...
Validation loss decreased (1.342274 --> 1.337512).  Saving model ...
Validation loss decreased (1.337512 --> 1.333410).  Saving model ...
Validation loss decreased (1.333410 --> 1.328347).  Saving model ...
Validation loss decreased (1.328347 --> 1.323581).  Saving model ...
Validation loss decreased (1.323581 --> 1.318624).  Saving model ...
Validation loss decreased (1.318624 --> 1.313160).  Saving model ...
Validation loss decreased (1.313160 --> 1.307338).  Saving model ...
Validation loss decreased (1.307338 --> 1.301615).  Saving model ...
Validation loss decreased (1.301615 --> 1.296219).  Saving model ...
Validation loss decreased (1.296219 --> 1.290968).  Saving model ...
Validation loss decreased (1.290968 --> 1.284875).  Saving model ...
Validation loss decreased (1.284875 --> 1.278562).  Saving model ...
Validation loss decreased (1.278562 --> 1.271069).  Saving model ...
Validation loss decreased (1.271069 --> 1.263656).  Saving model ...
Validation loss decreased (1.263656 --> 1.256074).  Saving model ...
Validation loss decreased (1.256074 --> 1.249109).  Saving model ...
Validation loss decreased (1.249109 --> 1.240850).  Saving model ...
Validation loss decreased (1.240850 --> 1.233760).  Saving model ...
Validation loss decreased (1.233760 --> 1.224947).  Saving model ...
Validation loss decreased (1.224947 --> 1.216185).  Saving model ...
Validation loss decreased (1.216185 --> 1.207532).  Saving model ...
Validation loss decreased (1.207532 --> 1.198050).  Saving model ...
Validation loss decreased (1.198050 --> 1.189906).  Saving model ...
Validation loss decreased (1.189906 --> 1.180991).  Saving model ...
Validation loss decreased (1.180991 --> 1.172338).  Saving model ...
Validation loss decreased (1.172338 --> 1.163483).  Saving model ...
Validation loss decreased (1.163483 --> 1.155330).  Saving model ...
Validation loss decreased (1.155330 --> 1.148551).  Saving model ...
Validation loss decreased (1.148551 --> 1.141886).  Saving model ...
Validation loss decreased (1.141886 --> 1.134842).  Saving model ...
Validation loss decreased (1.134842 --> 1.129023).  Saving model ...
Validation loss decreased (1.129023 --> 1.123263).  Saving model ...
Validation loss decreased (1.123263 --> 1.116807).  Saving model ...
Validation loss decreased (1.116807 --> 1.110205).  Saving model ...
Validation loss decreased (1.110205 --> 1.104208).  Saving model ...
Validation loss decreased (1.104208 --> 1.098801).  Saving model ...
Validation loss decreased (1.098801 --> 1.093261).  Saving model ...
Validation loss decreased (1.093261 --> 1.088198).  Saving model ...
Validation loss decreased (1.088198 --> 1.082885).  Saving model ...
Validation loss decreased (1.082885 --> 1.078000).  Saving model ...
Validation loss decreased (1.078000 --> 1.073835).  Saving model ...
Validation loss decreased (1.073835 --> 1.070132).  Saving model ...
Validation loss decreased (1.070132 --> 1.063746).  Saving model ...
Validation loss decreased (1.063746 --> 1.059329).  Saving model ...
Validation loss decreased (1.059329 --> 1.054406).  Saving model ...
Validation loss decreased (1.054406 --> 1.050886).  Saving model ...
Validation loss decreased (1.050886 --> 1.047305).  Saving model ...
Validation loss decreased (1.047305 --> 1.043457).  Saving model ...
Validation loss decreased (1.043457 --> 1.040125).  Saving model ...
Validation loss decreased (1.040125 --> 1.036243).  Saving model ...
Validation loss decreased (1.036243 --> 1.032422).  Saving model ...
Validation loss decreased (1.032422 --> 1.027494).  Saving model ...
Validation loss decreased (1.027494 --> 1.023695).  Saving model ...
Validation loss decreased (1.023695 --> 1.020032).  Saving model ...
Validation loss decreased (1.020032 --> 1.016943).  Saving model ...
Validation loss decreased (1.016943 --> 1.012949).  Saving model ...
Validation loss decreased (1.012949 --> 1.007114).  Saving model ...
Validation loss decreased (1.007114 --> 1.003841).  Saving model ...
Validation loss decreased (1.003841 --> 0.999895).  Saving model ...
Validation loss decreased (0.999895 --> 0.997189).  Saving model ...
Validation loss decreased (0.997189 --> 0.992984).  Saving model ...
Validation loss decreased (0.992984 --> 0.990046).  Saving model ...
Validation loss decreased (0.990046 --> 0.987871).  Saving model ...
Validation loss decreased (0.987871 --> 0.984578).  Saving model ...
Validation loss decreased (0.984578 --> 0.981346).  Saving model ...
Validation loss decreased (0.981346 --> 0.979649).  Saving model ...
Validation loss decreased (0.979649 --> 0.978531).  Saving model ...
Validation loss decreased (0.978531 --> 0.975616).  Saving model ...
Validation loss decreased (0.975616 --> 0.972882).  Saving model ...
Validation loss decreased (0.972882 --> 0.971605).  Saving model ...
Validation loss decreased (0.971605 --> 0.968473).  Saving model ...
Validation loss decreased (0.968473 --> 0.966538).  Saving model ...
Validation loss decreased (0.966538 --> 0.965392).  Saving model ...
Validation loss decreased (0.965392 --> 0.961944).  Saving model ...
Validation loss decreased (0.961944 --> 0.959311).  Saving model ...
Validation loss decreased (0.959311 --> 0.956427).  Saving model ...
Validation loss decreased (0.956427 --> 0.954767).  Saving model ...
Validation loss decreased (0.954767 --> 0.953688).  Saving model ...
Validation loss decreased (0.953688 --> 0.951969).  Saving model ...
Validation loss decreased (0.951969 --> 0.950040).  Saving model ...
Validation loss decreased (0.950040 --> 0.948273).  Saving model ...
Validation loss decreased (0.948273 --> 0.946205).  Saving model ...
Validation loss decreased (0.946205 --> 0.945765).  Saving model ...
Validation loss decreased (0.945765 --> 0.945077).  Saving model ...
Validation loss decreased (0.945077 --> 0.943543).  Saving model ...
Validation loss decreased (0.943543 --> 0.940382).  Saving model ...
Validation loss decreased (0.940382 --> 0.939888).  Saving model ...
Validation loss decreased (0.939888 --> 0.939845).  Saving model ...
EarlyStopping counter: 1 out of 10.0
Validation loss decreased (0.939845 --> 0.938382).  Saving model ...
Validation loss decreased (0.938382 --> 0.936411).  Saving model ...
Validation loss decreased (0.936411 --> 0.936372).  Saving model ...
Validation loss decreased (0.936372 --> 0.936063).  Saving model ...
Validation loss decreased (0.936063 --> 0.934853).  Saving model ...
Validation loss decreased (0.934853 --> 0.933467).  Saving model ...
Validation loss decreased (0.933467 --> 0.932664).  Saving model ...
Validation loss decreased (0.932664 --> 0.932322).  Saving model ...
Validation loss decreased (0.932322 --> 0.931874).  Saving model ...
Validation loss decreased (0.931874 --> 0.931377).  Saving model ...
Validation loss decreased (0.931377 --> 0.930630).  Saving model ...
Validation loss decreased (0.930630 --> 0.930158).  Saving model ...
Validation loss decreased (0.930158 --> 0.929418).  Saving model ...
Validation loss decreased (0.929418 --> 0.929098).  Saving model ...
EarlyStopping counter: 1 out of 10.0
Validation loss decreased (0.929098 --> 0.928572).  Saving model ...
Validation loss decreased (0.928572 --> 0.928571).  Saving model ...
Validation loss decreased (0.928571 --> 0.928471).  Saving model ...
Validation loss decreased (0.928471 --> 0.927838).  Saving model ...
Validation loss decreased (0.927838 --> 0.927580).  Saving model ...
EarlyStopping counter: 1 out of 10.0
Validation loss decreased (0.927580 --> 0.927425).  Saving model ...
Validation loss decreased (0.927425 --> 0.927278).  Saving model ...
EarlyStopping counter: 1 out of 10.0
Validation loss decreased (0.927278 --> 0.927119).  Saving model ...
Validation loss decreased (0.927119 --> 0.926579).  Saving model ...
EarlyStopping counter: 1 out of 10.0
Validation loss decreased (0.926579 --> 0.926018).  Saving model ...
EarlyStopping counter: 1 out of 10.0
EarlyStopping counter: 2 out of 10.0
EarlyStopping counter: 3 out of 10.0
EarlyStopping counter: 4 out of 10.0
EarlyStopping counter: 5 out of 10.0
EarlyStopping counter: 6 out of 10.0
EarlyStopping counter: 7 out of 10.0
EarlyStopping counter: 8 out of 10.0
EarlyStopping counter: 9 out of 10.0
EarlyStopping counter: 10 out of 10.0
/localscratch/yinan.29351705.0/env/lib/python3.7/site-packages/torch/nn/functional.py:1794: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.
  warnings.warn("nn.functional.tanh is deprecated. Use torch.tanh instead.")
wandb: Waiting for W&B process to finish, PID 6996... (success).
wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: \ 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: | 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: / 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: \ 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: | 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: / 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: \ 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: | 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: / 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: \ 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb:                                                                                
wandb: Run history:
wandb:     e_F1 ▁▂▃▄▄▄▅▅▆▆▆▇▇▇▇▇▇▇▇▇▇▇██████████████████
wandb:   e_loss ██▇▇▇▇▆▆▆▅▅▄▄▄▃▃▃▃▃▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:     t_F1 ▁▂▂▂▃▃▃▄▄▅▅▅▅▆▅▆▆▆▆▆▆▆▇▇▇▇▇▇▇▇▇▇▇▇▇█████
wandb:   t_loss ███▇▇▇▇▇▇▆▆▆▆▅▅▅▅▄▄▄▄▄▃▃▃▃▃▃▃▂▂▂▂▂▂▂▁▁▁▁
wandb: 
wandb: Run summary:
wandb:     e_F1 60.12927
wandb:   e_loss 0.92917
wandb:     t_F1 74.61586
wandb:   t_loss 0.72571
wandb: 
wandb: Synced 4 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Synced decent-plant-3: https://wandb.ai/yinanazhou/xl_512_bs_8_lr_1e06_es_10_lc_False_nr_True_sr_False_stem_False_lemma_True_repeat_1_fold_2/runs/2m1wvcbl
wandb: Find logs at: ./wandb/run-20220327_104714-2m1wvcbl/logs/debug.log
wandb: 

wandb: wandb version 0.12.11 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
2022-03-27 12:19:14.672044: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1
wandb: Tracking run with wandb version 0.12.5
wandb: Syncing run zesty-snowball-3
wandb: ⭐️ View project at https://wandb.ai/yinanazhou/xl_512_bs_8_lr_1e06_es_10_lc_False_nr_True_sr_False_stem_False_lemma_True_repeat_2_fold_1
wandb: 🚀 View run at https://wandb.ai/yinanazhou/xl_512_bs_8_lr_1e06_es_10_lc_False_nr_True_sr_False_stem_False_lemma_True_repeat_2_fold_1/runs/3kqyujv5
wandb: Run data is saved locally in /project/6002780/yinan/Thesis_MER_Lyrics/lyric-emotion/wandb/run-20220327_121911-3kqyujv5
wandb: Run `wandb offline` to turn off syncing.

Validation loss decreased (inf --> 1.459010).  Saving model ...
Validation loss decreased (1.459010 --> 1.426802).  Saving model ...
Validation loss decreased (1.426802 --> 1.404660).  Saving model ...
Validation loss decreased (1.404660 --> 1.390094).  Saving model ...
Validation loss decreased (1.390094 --> 1.380242).  Saving model ...
Validation loss decreased (1.380242 --> 1.373305).  Saving model ...
Validation loss decreased (1.373305 --> 1.367676).  Saving model ...
Validation loss decreased (1.367676 --> 1.361980).  Saving model ...
Validation loss decreased (1.361980 --> 1.356693).  Saving model ...
Validation loss decreased (1.356693 --> 1.351854).  Saving model ...
Validation loss decreased (1.351854 --> 1.346707).  Saving model ...
Validation loss decreased (1.346707 --> 1.341376).  Saving model ...
Validation loss decreased (1.341376 --> 1.336984).  Saving model ...
Validation loss decreased (1.336984 --> 1.331200).  Saving model ...
Validation loss decreased (1.331200 --> 1.324920).  Saving model ...
Validation loss decreased (1.324920 --> 1.317639).  Saving model ...
Validation loss decreased (1.317639 --> 1.310292).  Saving model ...
Validation loss decreased (1.310292 --> 1.301861).  Saving model ...
Validation loss decreased (1.301861 --> 1.294218).  Saving model ...
Validation loss decreased (1.294218 --> 1.285473).  Saving model ...
Validation loss decreased (1.285473 --> 1.277471).  Saving model ...
Validation loss decreased (1.277471 --> 1.268683).  Saving model ...
Validation loss decreased (1.268683 --> 1.259599).  Saving model ...
Validation loss decreased (1.259599 --> 1.251029).  Saving model ...
Validation loss decreased (1.251029 --> 1.243798).  Saving model ...
Validation loss decreased (1.243798 --> 1.235625).  Saving model ...
Validation loss decreased (1.235625 --> 1.228484).  Saving model ...
Validation loss decreased (1.228484 --> 1.222252).  Saving model ...
Validation loss decreased (1.222252 --> 1.213994).  Saving model ...
Validation loss decreased (1.213994 --> 1.206151).  Saving model ...
Validation loss decreased (1.206151 --> 1.198168).  Saving model ...
Validation loss decreased (1.198168 --> 1.191469).  Saving model ...
Validation loss decreased (1.191469 --> 1.185093).  Saving model ...
Validation loss decreased (1.185093 --> 1.177550).  Saving model ...
Validation loss decreased (1.177550 --> 1.171780).  Saving model ...
Validation loss decreased (1.171780 --> 1.164316).  Saving model ...
Validation loss decreased (1.164316 --> 1.158410).  Saving model ...
Validation loss decreased (1.158410 --> 1.152294).  Saving model ...
Validation loss decreased (1.152294 --> 1.146477).  Saving model ...
Validation loss decreased (1.146477 --> 1.141558).  Saving model ...
Validation loss decreased (1.141558 --> 1.135861).  Saving model ...
Validation loss decreased (1.135861 --> 1.131116).  Saving model ...
Validation loss decreased (1.131116 --> 1.125336).  Saving model ...
Validation loss decreased (1.125336 --> 1.118822).  Saving model ...
Validation loss decreased (1.118822 --> 1.114992).  Saving model ...
Validation loss decreased (1.114992 --> 1.109294).  Saving model ...
Validation loss decreased (1.109294 --> 1.104150).  Saving model ...
Validation loss decreased (1.104150 --> 1.099587).  Saving model ...
Validation loss decreased (1.099587 --> 1.094904).  Saving model ...
Validation loss decreased (1.094904 --> 1.089766).  Saving model ...
Validation loss decreased (1.089766 --> 1.085349).  Saving model ...
Validation loss decreased (1.085349 --> 1.080783).  Saving model ...
Validation loss decreased (1.080783 --> 1.075347).  Saving model ...
Validation loss decreased (1.075347 --> 1.070677).  Saving model ...
Validation loss decreased (1.070677 --> 1.066822).  Saving model ...
Validation loss decreased (1.066822 --> 1.063157).  Saving model ...
Validation loss decreased (1.063157 --> 1.060569).  Saving model ...
Validation loss decreased (1.060569 --> 1.056547).  Saving model ...
Validation loss decreased (1.056547 --> 1.052557).  Saving model ...
Validation loss decreased (1.052557 --> 1.050322).  Saving model ...
Validation loss decreased (1.050322 --> 1.046457).  Saving model ...
Validation loss decreased (1.046457 --> 1.043441).  Saving model ...
Validation loss decreased (1.043441 --> 1.039062).  Saving model ...
Validation loss decreased (1.039062 --> 1.035873).  Saving model ...
Validation loss decreased (1.035873 --> 1.032300).  Saving model ...
Validation loss decreased (1.032300 --> 1.028380).  Saving model ...
Validation loss decreased (1.028380 --> 1.025593).  Saving model ...
Validation loss decreased (1.025593 --> 1.022923).  Saving model ...
Validation loss decreased (1.022923 --> 1.019584).  Saving model ...
Validation loss decreased (1.019584 --> 1.016247).  Saving model ...
Validation loss decreased (1.016247 --> 1.013508).  Saving model ...
Validation loss decreased (1.013508 --> 1.010486).  Saving model ...
Validation loss decreased (1.010486 --> 1.008307).  Saving model ...
Validation loss decreased (1.008307 --> 1.006681).  Saving model ...
Validation loss decreased (1.006681 --> 1.004228).  Saving model ...
Validation loss decreased (1.004228 --> 1.002060).  Saving model ...
Validation loss decreased (1.002060 --> 1.000525).  Saving model ...
Validation loss decreased (1.000525 --> 0.997879).  Saving model ...
Validation loss decreased (0.997879 --> 0.997228).  Saving model ...
Validation loss decreased (0.997228 --> 0.995326).  Saving model ...
Validation loss decreased (0.995326 --> 0.992749).  Saving model ...
Validation loss decreased (0.992749 --> 0.989803).  Saving model ...
Validation loss decreased (0.989803 --> 0.986725).  Saving model ...
Validation loss decreased (0.986725 --> 0.984153).  Saving model ...
Validation loss decreased (0.984153 --> 0.982468).  Saving model ...
Validation loss decreased (0.982468 --> 0.980921).  Saving model ...
Validation loss decreased (0.980921 --> 0.979547).  Saving model ...
Validation loss decreased (0.979547 --> 0.979063).  Saving model ...
Validation loss decreased (0.979063 --> 0.977432).  Saving model ...
Validation loss decreased (0.977432 --> 0.976410).  Saving model ...
Validation loss decreased (0.976410 --> 0.974353).  Saving model ...
EarlyStopping counter: 1 out of 10.0
Validation loss decreased (0.974353 --> 0.973573).  Saving model ...
Validation loss decreased (0.973573 --> 0.969432).  Saving model ...
Validation loss decreased (0.969432 --> 0.967001).  Saving model ...
Validation loss decreased (0.967001 --> 0.966899).  Saving model ...
EarlyStopping counter: 1 out of 10.0
Validation loss decreased (0.966899 --> 0.965044).  Saving model ...
Validation loss decreased (0.965044 --> 0.964065).  Saving model ...
Validation loss decreased (0.964065 --> 0.962886).  Saving model ...
Validation loss decreased (0.962886 --> 0.961942).  Saving model ...
Validation loss decreased (0.961942 --> 0.960833).  Saving model ...
Validation loss decreased (0.960833 --> 0.960349).  Saving model ...
EarlyStopping counter: 1 out of 10.0
Validation loss decreased (0.960349 --> 0.959658).  Saving model ...
Validation loss decreased (0.959658 --> 0.958001).  Saving model ...
Validation loss decreased (0.958001 --> 0.957249).  Saving model ...
Validation loss decreased (0.957249 --> 0.955543).  Saving model ...
Validation loss decreased (0.955543 --> 0.955448).  Saving model ...
Validation loss decreased (0.955448 --> 0.955419).  Saving model ...
EarlyStopping counter: 1 out of 10.0
EarlyStopping counter: 2 out of 10.0
EarlyStopping counter: 3 out of 10.0
Validation loss decreased (0.955419 --> 0.955008).  Saving model ...
Validation loss decreased (0.955008 --> 0.953825).  Saving model ...
Validation loss decreased (0.953825 --> 0.951519).  Saving model ...
Validation loss decreased (0.951519 --> 0.951467).  Saving model ...
EarlyStopping counter: 1 out of 10.0
Validation loss decreased (0.951467 --> 0.950843).  Saving model ...
EarlyStopping counter: 1 out of 10.0
EarlyStopping counter: 2 out of 10.0
Validation loss decreased (0.950843 --> 0.950473).  Saving model ...
EarlyStopping counter: 1 out of 10.0
EarlyStopping counter: 2 out of 10.0
EarlyStopping counter: 3 out of 10.0
EarlyStopping counter: 4 out of 10.0
EarlyStopping counter: 5 out of 10.0
EarlyStopping counter: 6 out of 10.0
EarlyStopping counter: 7 out of 10.0
EarlyStopping counter: 8 out of 10.0
EarlyStopping counter: 9 out of 10.0
EarlyStopping counter: 10 out of 10.0
/localscratch/yinan.29351705.0/env/lib/python3.7/site-packages/torch/nn/functional.py:1794: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.
  warnings.warn("nn.functional.tanh is deprecated. Use torch.tanh instead.")
wandb: Waiting for W&B process to finish, PID 11999... (success).
wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: \ 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: | 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: / 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: \ 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: | 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: / 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: \ 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: | 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: / 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb:                                                                                
wandb: Run history:
wandb:     e_F1 ▁▂▄▅▅▅▅▆▆▆▆▇▇▇▇▇▇███████████████████████
wandb:   e_loss █▇▇▇▇▆▆▅▅▅▄▄▄▃▃▃▃▃▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:     t_F1 ▁▁▃▃▃▄▄▅▄▅▅▆▆▆▅▆▆▆▇▇▆▆▇▇▇▇▇▇▇▇▇▇▇█▇██▇██
wandb:   t_loss ██▇▇▇▇▆▆▆▆▅▅▅▅▅▄▄▄▄▄▃▃▃▃▃▃▂▂▂▂▂▂▂▂▂▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:     e_F1 57.94662
wandb:   e_loss 0.95255
wandb:     t_F1 69.93595
wandb:   t_loss 0.73965
wandb: 
wandb: Synced 4 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Synced zesty-snowball-3: https://wandb.ai/yinanazhou/xl_512_bs_8_lr_1e06_es_10_lc_False_nr_True_sr_False_stem_False_lemma_True_repeat_2_fold_1/runs/3kqyujv5
wandb: Find logs at: ./wandb/run-20220327_121911-3kqyujv5/logs/debug.log
wandb: 

wandb: wandb version 0.12.11 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
2022-03-27 13:46:24.458217: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1
wandb: Tracking run with wandb version 0.12.5
wandb: Syncing run gentle-grass-1
wandb: ⭐️ View project at https://wandb.ai/yinanazhou/xl_512_bs_8_lr_1e06_es_10_lc_False_nr_True_sr_False_stem_False_lemma_True_repeat_2_fold_2
wandb: 🚀 View run at https://wandb.ai/yinanazhou/xl_512_bs_8_lr_1e06_es_10_lc_False_nr_True_sr_False_stem_False_lemma_True_repeat_2_fold_2/runs/230jf3pu
wandb: Run data is saved locally in /project/6002780/yinan/Thesis_MER_Lyrics/lyric-emotion/wandb/run-20220327_134622-230jf3pu
wandb: Run `wandb offline` to turn off syncing.

Validation loss decreased (inf --> 1.436959).  Saving model ...
Validation loss decreased (1.436959 --> 1.425480).  Saving model ...
Validation loss decreased (1.425480 --> 1.415686).  Saving model ...
Validation loss decreased (1.415686 --> 1.407390).  Saving model ...
Validation loss decreased (1.407390 --> 1.400524).  Saving model ...
Validation loss decreased (1.400524 --> 1.394050).  Saving model ...
Validation loss decreased (1.394050 --> 1.388420).  Saving model ...
Validation loss decreased (1.388420 --> 1.383228).  Saving model ...
Validation loss decreased (1.383228 --> 1.377950).  Saving model ...
Validation loss decreased (1.377950 --> 1.373111).  Saving model ...
Validation loss decreased (1.373111 --> 1.368283).  Saving model ...
Validation loss decreased (1.368283 --> 1.363735).  Saving model ...
Validation loss decreased (1.363735 --> 1.358654).  Saving model ...
Validation loss decreased (1.358654 --> 1.353483).  Saving model ...
Validation loss decreased (1.353483 --> 1.348203).  Saving model ...
Validation loss decreased (1.348203 --> 1.343340).  Saving model ...
Validation loss decreased (1.343340 --> 1.337933).  Saving model ...
Validation loss decreased (1.337933 --> 1.331977).  Saving model ...
Validation loss decreased (1.331977 --> 1.325146).  Saving model ...
Validation loss decreased (1.325146 --> 1.318092).  Saving model ...
Validation loss decreased (1.318092 --> 1.310584).  Saving model ...
Validation loss decreased (1.310584 --> 1.302606).  Saving model ...
Validation loss decreased (1.302606 --> 1.294562).  Saving model ...
Validation loss decreased (1.294562 --> 1.285669).  Saving model ...
Validation loss decreased (1.285669 --> 1.277412).  Saving model ...
Validation loss decreased (1.277412 --> 1.266866).  Saving model ...
Validation loss decreased (1.266866 --> 1.257342).  Saving model ...
Validation loss decreased (1.257342 --> 1.250290).  Saving model ...
Validation loss decreased (1.250290 --> 1.242023).  Saving model ...
Validation loss decreased (1.242023 --> 1.231863).  Saving model ...
Validation loss decreased (1.231863 --> 1.222972).  Saving model ...
Validation loss decreased (1.222972 --> 1.215361).  Saving model ...
Validation loss decreased (1.215361 --> 1.208819).  Saving model ...
Validation loss decreased (1.208819 --> 1.201522).  Saving model ...
Validation loss decreased (1.201522 --> 1.191834).  Saving model ...
Validation loss decreased (1.191834 --> 1.183760).  Saving model ...
Validation loss decreased (1.183760 --> 1.174754).  Saving model ...
Validation loss decreased (1.174754 --> 1.167751).  Saving model ...
Validation loss decreased (1.167751 --> 1.162176).  Saving model ...
Validation loss decreased (1.162176 --> 1.155856).  Saving model ...
Validation loss decreased (1.155856 --> 1.147648).  Saving model ...
Validation loss decreased (1.147648 --> 1.140442).  Saving model ...
Validation loss decreased (1.140442 --> 1.132191).  Saving model ...
Validation loss decreased (1.132191 --> 1.126713).  Saving model ...
Validation loss decreased (1.126713 --> 1.121073).  Saving model ...
Validation loss decreased (1.121073 --> 1.116886).  Saving model ...
Validation loss decreased (1.116886 --> 1.109951).  Saving model ...
Validation loss decreased (1.109951 --> 1.104957).  Saving model ...
Validation loss decreased (1.104957 --> 1.099888).  Saving model ...
Validation loss decreased (1.099888 --> 1.095053).  Saving model ...
Validation loss decreased (1.095053 --> 1.088681).  Saving model ...
Validation loss decreased (1.088681 --> 1.086120).  Saving model ...
Validation loss decreased (1.086120 --> 1.081260).  Saving model ...
Validation loss decreased (1.081260 --> 1.074567).  Saving model ...
Validation loss decreased (1.074567 --> 1.070717).  Saving model ...
Validation loss decreased (1.070717 --> 1.068049).  Saving model ...
Validation loss decreased (1.068049 --> 1.064511).  Saving model ...
Validation loss decreased (1.064511 --> 1.057332).  Saving model ...
Validation loss decreased (1.057332 --> 1.052271).  Saving model ...
Validation loss decreased (1.052271 --> 1.046112).  Saving model ...
Validation loss decreased (1.046112 --> 1.041213).  Saving model ...
Validation loss decreased (1.041213 --> 1.040427).  Saving model ...
Validation loss decreased (1.040427 --> 1.035104).  Saving model ...
Validation loss decreased (1.035104 --> 1.032719).  Saving model ...
Validation loss decreased (1.032719 --> 1.028447).  Saving model ...
Validation loss decreased (1.028447 --> 1.026589).  Saving model ...
Validation loss decreased (1.026589 --> 1.022122).  Saving model ...
Validation loss decreased (1.022122 --> 1.019276).  Saving model ...
Validation loss decreased (1.019276 --> 1.015287).  Saving model ...
Validation loss decreased (1.015287 --> 1.011801).  Saving model ...
Validation loss decreased (1.011801 --> 1.006872).  Saving model ...
Validation loss decreased (1.006872 --> 1.005308).  Saving model ...
Validation loss decreased (1.005308 --> 1.002873).  Saving model ...
Validation loss decreased (1.002873 --> 1.002361).  Saving model ...
Validation loss decreased (1.002361 --> 0.999643).  Saving model ...
Validation loss decreased (0.999643 --> 0.996756).  Saving model ...
Validation loss decreased (0.996756 --> 0.995475).  Saving model ...
Validation loss decreased (0.995475 --> 0.990720).  Saving model ...
Validation loss decreased (0.990720 --> 0.987789).  Saving model ...
Validation loss decreased (0.987789 --> 0.985863).  Saving model ...
Validation loss decreased (0.985863 --> 0.983662).  Saving model ...
Validation loss decreased (0.983662 --> 0.980660).  Saving model ...
Validation loss decreased (0.980660 --> 0.977895).  Saving model ...
Validation loss decreased (0.977895 --> 0.973563).  Saving model ...
Validation loss decreased (0.973563 --> 0.973307).  Saving model ...
Validation loss decreased (0.973307 --> 0.971903).  Saving model ...
Validation loss decreased (0.971903 --> 0.969039).  Saving model ...
EarlyStopping counter: 1 out of 10.0
Validation loss decreased (0.969039 --> 0.966720).  Saving model ...
Validation loss decreased (0.966720 --> 0.966149).  Saving model ...
Validation loss decreased (0.966149 --> 0.964798).  Saving model ...
Validation loss decreased (0.964798 --> 0.962303).  Saving model ...
Validation loss decreased (0.962303 --> 0.960617).  Saving model ...
Validation loss decreased (0.960617 --> 0.959787).  Saving model ...
Validation loss decreased (0.959787 --> 0.957807).  Saving model ...
Validation loss decreased (0.957807 --> 0.955467).  Saving model ...
Validation loss decreased (0.955467 --> 0.954310).  Saving model ...
Validation loss decreased (0.954310 --> 0.949817).  Saving model ...
EarlyStopping counter: 1 out of 10.0
EarlyStopping counter: 2 out of 10.0
EarlyStopping counter: 3 out of 10.0
Validation loss decreased (0.949817 --> 0.947883).  Saving model ...
Validation loss decreased (0.947883 --> 0.947154).  Saving model ...
EarlyStopping counter: 1 out of 10.0
Validation loss decreased (0.947154 --> 0.944792).  Saving model ...
EarlyStopping counter: 1 out of 10.0
Validation loss decreased (0.944792 --> 0.944699).  Saving model ...
EarlyStopping counter: 1 out of 10.0
Validation loss decreased (0.944699 --> 0.942838).  Saving model ...
EarlyStopping counter: 1 out of 10.0
Validation loss decreased (0.942838 --> 0.941239).  Saving model ...
Validation loss decreased (0.941239 --> 0.941135).  Saving model ...
Validation loss decreased (0.941135 --> 0.940463).  Saving model ...
Validation loss decreased (0.940463 --> 0.937951).  Saving model ...
Validation loss decreased (0.937951 --> 0.936607).  Saving model ...
Validation loss decreased (0.936607 --> 0.934615).  Saving model ...
Validation loss decreased (0.934615 --> 0.932991).  Saving model ...
EarlyStopping counter: 1 out of 10.0
EarlyStopping counter: 2 out of 10.0
EarlyStopping counter: 3 out of 10.0
EarlyStopping counter: 4 out of 10.0
EarlyStopping counter: 5 out of 10.0
Validation loss decreased (0.932991 --> 0.931892).  Saving model ...
EarlyStopping counter: 1 out of 10.0
EarlyStopping counter: 2 out of 10.0
Validation loss decreased (0.931892 --> 0.931478).  Saving model ...
EarlyStopping counter: 1 out of 10.0
Validation loss decreased (0.931478 --> 0.931299).  Saving model ...
Validation loss decreased (0.931299 --> 0.930729).  Saving model ...
Validation loss decreased (0.930729 --> 0.929681).  Saving model ...
EarlyStopping counter: 1 out of 10.0
EarlyStopping counter: 2 out of 10.0
Validation loss decreased (0.929681 --> 0.929141).  Saving model ...
EarlyStopping counter: 1 out of 10.0
EarlyStopping counter: 2 out of 10.0
EarlyStopping counter: 3 out of 10.0
EarlyStopping counter: 4 out of 10.0
Validation loss decreased (0.929141 --> 0.928537).  Saving model ...
EarlyStopping counter: 1 out of 10.0
Validation loss decreased (0.928537 --> 0.928450).  Saving model ...
EarlyStopping counter: 1 out of 10.0
EarlyStopping counter: 2 out of 10.0
EarlyStopping counter: 3 out of 10.0
EarlyStopping counter: 4 out of 10.0
EarlyStopping counter: 5 out of 10.0
EarlyStopping counter: 6 out of 10.0
EarlyStopping counter: 7 out of 10.0
EarlyStopping counter: 8 out of 10.0
EarlyStopping counter: 9 out of 10.0
EarlyStopping counter: 10 out of 10.0
/localscratch/yinan.29351705.0/env/lib/python3.7/site-packages/torch/nn/functional.py:1794: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.
  warnings.warn("nn.functional.tanh is deprecated. Use torch.tanh instead.")
wandb: Waiting for W&B process to finish, PID 16654... (success).
wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: \ 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: | 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: / 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: \ 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: | 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: / 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: \ 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: | 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: / 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb:                                                                                
wandb: Run history:
wandb:     e_F1 ▁▁▂▃▄▅▅▅▆▆▆▆▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇█████████████
wandb:   e_loss ██▇▇▇▆▆▆▅▅▄▄▄▃▃▃▃▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:     t_F1 ▁▁▂▂▂▃▃▄▅▅▅▅▅▅▆▆▆▆▆▇▆▇▇▇▇▇▇█▇█████▇█████
wandb:   t_loss ███▇▇▇▇▆▆▆▆▅▅▅▄▄▄▄▄▃▄▃▃▃▃▂▂▂▂▂▂▂▂▂▂▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:     e_F1 64.55479
wandb:   e_loss 0.93573
wandb:     t_F1 72.07655
wandb:   t_loss 0.71986
wandb: 
wandb: Synced 4 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Synced gentle-grass-1: https://wandb.ai/yinanazhou/xl_512_bs_8_lr_1e06_es_10_lc_False_nr_True_sr_False_stem_False_lemma_True_repeat_2_fold_2/runs/230jf3pu
wandb: Find logs at: ./wandb/run-20220327_134622-230jf3pu/logs/debug.log
wandb: 

wandb: wandb version 0.12.11 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
2022-03-27 15:23:54.026962: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1
wandb: Tracking run with wandb version 0.12.5
wandb: Syncing run balmy-morning-1
wandb: ⭐️ View project at https://wandb.ai/yinanazhou/xl_512_bs_8_lr_1e06_es_10_lc_False_nr_True_sr_False_stem_False_lemma_True_repeat_3_fold_1
wandb: 🚀 View run at https://wandb.ai/yinanazhou/xl_512_bs_8_lr_1e06_es_10_lc_False_nr_True_sr_False_stem_False_lemma_True_repeat_3_fold_1/runs/pw1733hu
wandb: Run data is saved locally in /project/6002780/yinan/Thesis_MER_Lyrics/lyric-emotion/wandb/run-20220327_152351-pw1733hu
wandb: Run `wandb offline` to turn off syncing.

Validation loss decreased (inf --> 1.524384).  Saving model ...
Validation loss decreased (1.524384 --> 1.477737).  Saving model ...
Validation loss decreased (1.477737 --> 1.440643).  Saving model ...
Validation loss decreased (1.440643 --> 1.411126).  Saving model ...
Validation loss decreased (1.411126 --> 1.388931).  Saving model ...
Validation loss decreased (1.388931 --> 1.373554).  Saving model ...
Validation loss decreased (1.373554 --> 1.362133).  Saving model ...
Validation loss decreased (1.362133 --> 1.353883).  Saving model ...
Validation loss decreased (1.353883 --> 1.346808).  Saving model ...
Validation loss decreased (1.346808 --> 1.341127).  Saving model ...
Validation loss decreased (1.341127 --> 1.336515).  Saving model ...
Validation loss decreased (1.336515 --> 1.331237).  Saving model ...
Validation loss decreased (1.331237 --> 1.327362).  Saving model ...
Validation loss decreased (1.327362 --> 1.323142).  Saving model ...
Validation loss decreased (1.323142 --> 1.317920).  Saving model ...
Validation loss decreased (1.317920 --> 1.311824).  Saving model ...
Validation loss decreased (1.311824 --> 1.306723).  Saving model ...
Validation loss decreased (1.306723 --> 1.300108).  Saving model ...
Validation loss decreased (1.300108 --> 1.294589).  Saving model ...
Validation loss decreased (1.294589 --> 1.290580).  Saving model ...
Validation loss decreased (1.290580 --> 1.285327).  Saving model ...
Validation loss decreased (1.285327 --> 1.277753).  Saving model ...
Validation loss decreased (1.277753 --> 1.271429).  Saving model ...
Validation loss decreased (1.271429 --> 1.265151).  Saving model ...
Validation loss decreased (1.265151 --> 1.259204).  Saving model ...
Validation loss decreased (1.259204 --> 1.254383).  Saving model ...
Validation loss decreased (1.254383 --> 1.248828).  Saving model ...
Validation loss decreased (1.248828 --> 1.241475).  Saving model ...
Validation loss decreased (1.241475 --> 1.235334).  Saving model ...
Validation loss decreased (1.235334 --> 1.229731).  Saving model ...
Validation loss decreased (1.229731 --> 1.224701).  Saving model ...
Validation loss decreased (1.224701 --> 1.218658).  Saving model ...
Validation loss decreased (1.218658 --> 1.210828).  Saving model ...
Validation loss decreased (1.210828 --> 1.204818).  Saving model ...
Validation loss decreased (1.204818 --> 1.198531).  Saving model ...
Validation loss decreased (1.198531 --> 1.192121).  Saving model ...
Validation loss decreased (1.192121 --> 1.186234).  Saving model ...
Validation loss decreased (1.186234 --> 1.183216).  Saving model ...
Validation loss decreased (1.183216 --> 1.177621).  Saving model ...
Validation loss decreased (1.177621 --> 1.172001).  Saving model ...
Validation loss decreased (1.172001 --> 1.167028).  Saving model ...
Validation loss decreased (1.167028 --> 1.163999).  Saving model ...
Validation loss decreased (1.163999 --> 1.159845).  Saving model ...
Validation loss decreased (1.159845 --> 1.153765).  Saving model ...
Validation loss decreased (1.153765 --> 1.150573).  Saving model ...
Validation loss decreased (1.150573 --> 1.142739).  Saving model ...
Validation loss decreased (1.142739 --> 1.138163).  Saving model ...
Validation loss decreased (1.138163 --> 1.134938).  Saving model ...
Validation loss decreased (1.134938 --> 1.132747).  Saving model ...
Validation loss decreased (1.132747 --> 1.127902).  Saving model ...
Validation loss decreased (1.127902 --> 1.120118).  Saving model ...
Validation loss decreased (1.120118 --> 1.119562).  Saving model ...
Validation loss decreased (1.119562 --> 1.115797).  Saving model ...
Validation loss decreased (1.115797 --> 1.112085).  Saving model ...
Validation loss decreased (1.112085 --> 1.109346).  Saving model ...
Validation loss decreased (1.109346 --> 1.105368).  Saving model ...
Validation loss decreased (1.105368 --> 1.102872).  Saving model ...
EarlyStopping counter: 1 out of 10.0
Validation loss decreased (1.102872 --> 1.098874).  Saving model ...
Validation loss decreased (1.098874 --> 1.095369).  Saving model ...
Validation loss decreased (1.095369 --> 1.092831).  Saving model ...
Validation loss decreased (1.092831 --> 1.087601).  Saving model ...
Validation loss decreased (1.087601 --> 1.083748).  Saving model ...
Validation loss decreased (1.083748 --> 1.078911).  Saving model ...
EarlyStopping counter: 1 out of 10.0
Validation loss decreased (1.078911 --> 1.074358).  Saving model ...
EarlyStopping counter: 1 out of 10.0
Validation loss decreased (1.074358 --> 1.067550).  Saving model ...
Validation loss decreased (1.067550 --> 1.063057).  Saving model ...
EarlyStopping counter: 1 out of 10.0
EarlyStopping counter: 2 out of 10.0
Validation loss decreased (1.063057 --> 1.059090).  Saving model ...
Validation loss decreased (1.059090 --> 1.056838).  Saving model ...
Validation loss decreased (1.056838 --> 1.056126).  Saving model ...
Validation loss decreased (1.056126 --> 1.051180).  Saving model ...
Validation loss decreased (1.051180 --> 1.048606).  Saving model ...
Validation loss decreased (1.048606 --> 1.045115).  Saving model ...
Validation loss decreased (1.045115 --> 1.044434).  Saving model ...
Validation loss decreased (1.044434 --> 1.041340).  Saving model ...
Validation loss decreased (1.041340 --> 1.039567).  Saving model ...
Validation loss decreased (1.039567 --> 1.036775).  Saving model ...
Validation loss decreased (1.036775 --> 1.033437).  Saving model ...
EarlyStopping counter: 1 out of 10.0
EarlyStopping counter: 2 out of 10.0
EarlyStopping counter: 3 out of 10.0
Validation loss decreased (1.033437 --> 1.032739).  Saving model ...
Validation loss decreased (1.032739 --> 1.028983).  Saving model ...
Validation loss decreased (1.028983 --> 1.024741).  Saving model ...
Validation loss decreased (1.024741 --> 1.021162).  Saving model ...
Validation loss decreased (1.021162 --> 1.019190).  Saving model ...
EarlyStopping counter: 1 out of 10.0
Validation loss decreased (1.019190 --> 1.018133).  Saving model ...
EarlyStopping counter: 1 out of 10.0
EarlyStopping counter: 2 out of 10.0
Validation loss decreased (1.018133 --> 1.017994).  Saving model ...
EarlyStopping counter: 1 out of 10.0
EarlyStopping counter: 2 out of 10.0
Validation loss decreased (1.017994 --> 1.017385).  Saving model ...
Validation loss decreased (1.017385 --> 1.010098).  Saving model ...
EarlyStopping counter: 1 out of 10.0
EarlyStopping counter: 2 out of 10.0
EarlyStopping counter: 3 out of 10.0
EarlyStopping counter: 4 out of 10.0
Validation loss decreased (1.010098 --> 1.010097).  Saving model ...
EarlyStopping counter: 1 out of 10.0
EarlyStopping counter: 2 out of 10.0
EarlyStopping counter: 3 out of 10.0
EarlyStopping counter: 4 out of 10.0
EarlyStopping counter: 5 out of 10.0
Validation loss decreased (1.010097 --> 1.006177).  Saving model ...
Validation loss decreased (1.006177 --> 1.004002).  Saving model ...
EarlyStopping counter: 1 out of 10.0
EarlyStopping counter: 2 out of 10.0
EarlyStopping counter: 3 out of 10.0
EarlyStopping counter: 4 out of 10.0
Validation loss decreased (1.004002 --> 1.003319).  Saving model ...
EarlyStopping counter: 1 out of 10.0
Validation loss decreased (1.003319 --> 1.000883).  Saving model ...
EarlyStopping counter: 1 out of 10.0
EarlyStopping counter: 2 out of 10.0
EarlyStopping counter: 3 out of 10.0
EarlyStopping counter: 4 out of 10.0
EarlyStopping counter: 5 out of 10.0
EarlyStopping counter: 6 out of 10.0
EarlyStopping counter: 7 out of 10.0
EarlyStopping counter: 8 out of 10.0
EarlyStopping counter: 9 out of 10.0
EarlyStopping counter: 10 out of 10.0
/localscratch/yinan.29351705.0/env/lib/python3.7/site-packages/torch/nn/functional.py:1794: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.
  warnings.warn("nn.functional.tanh is deprecated. Use torch.tanh instead.")
wandb: Waiting for W&B process to finish, PID 21955... (success).
wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: \ 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: | 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: / 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: \ 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: | 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: / 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: \ 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: | 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: / 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb:                                                                                
wandb: Run history:
wandb:     e_F1 ▁▂▄▄▄▄▅▅▅▅▆▆▆▇▇▇▇▇▇▇▇▇██████████████████
wandb:   e_loss █▇▆▆▆▅▅▅▅▄▄▄▄▃▃▃▃▃▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:     t_F1 ▁▁▂▂▃▃▃▃▄▅▄▅▅▅▅▅▅▆▆▆▆▆▇▆▆▆▇▇▇▇▇▇█▇▇▇████
wandb:   t_loss ██▇▇▇▆▆▆▆▆▅▅▅▅▅▄▄▄▄▄▃▃▃▃▃▃▂▂▂▂▂▂▂▂▂▂▁▁▁▁
wandb: 
wandb: Run summary:
wandb:     e_F1 58.55546
wandb:   e_loss 1.00435
wandb:     t_F1 72.02231
wandb:   t_loss 0.75741
wandb: 
wandb: Synced 4 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Synced balmy-morning-1: https://wandb.ai/yinanazhou/xl_512_bs_8_lr_1e06_es_10_lc_False_nr_True_sr_False_stem_False_lemma_True_repeat_3_fold_1/runs/pw1733hu
wandb: Find logs at: ./wandb/run-20220327_152351-pw1733hu/logs/debug.log
wandb: 

wandb: wandb version 0.12.11 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
2022-03-27 16:48:07.971414: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1
wandb: Tracking run with wandb version 0.12.5
wandb: Syncing run efficient-aardvark-1
wandb: ⭐️ View project at https://wandb.ai/yinanazhou/xl_512_bs_8_lr_1e06_es_10_lc_False_nr_True_sr_False_stem_False_lemma_True_repeat_3_fold_2
wandb: 🚀 View run at https://wandb.ai/yinanazhou/xl_512_bs_8_lr_1e06_es_10_lc_False_nr_True_sr_False_stem_False_lemma_True_repeat_3_fold_2/runs/35qip7sv
wandb: Run data is saved locally in /project/6002780/yinan/Thesis_MER_Lyrics/lyric-emotion/wandb/run-20220327_164805-35qip7sv
wandb: Run `wandb offline` to turn off syncing.

Validation loss decreased (inf --> 1.421812).  Saving model ...
Validation loss decreased (1.421812 --> 1.408242).  Saving model ...
Validation loss decreased (1.408242 --> 1.397135).  Saving model ...
Validation loss decreased (1.397135 --> 1.389023).  Saving model ...
Validation loss decreased (1.389023 --> 1.381508).  Saving model ...
Validation loss decreased (1.381508 --> 1.374874).  Saving model ...
Validation loss decreased (1.374874 --> 1.368919).  Saving model ...
Validation loss decreased (1.368919 --> 1.363161).  Saving model ...
Validation loss decreased (1.363161 --> 1.357712).  Saving model ...
Validation loss decreased (1.357712 --> 1.352053).  Saving model ...
Validation loss decreased (1.352053 --> 1.346035).  Saving model ...
Validation loss decreased (1.346035 --> 1.339825).  Saving model ...
Validation loss decreased (1.339825 --> 1.334478).  Saving model ...
Validation loss decreased (1.334478 --> 1.328996).  Saving model ...
Validation loss decreased (1.328996 --> 1.322646).  Saving model ...
Validation loss decreased (1.322646 --> 1.316517).  Saving model ...
Validation loss decreased (1.316517 --> 1.310038).  Saving model ...
Validation loss decreased (1.310038 --> 1.302994).  Saving model ...
Validation loss decreased (1.302994 --> 1.295776).  Saving model ...
Validation loss decreased (1.295776 --> 1.288962).  Saving model ...
Validation loss decreased (1.288962 --> 1.282609).  Saving model ...
Validation loss decreased (1.282609 --> 1.275690).  Saving model ...
Validation loss decreased (1.275690 --> 1.268287).  Saving model ...
Validation loss decreased (1.268287 --> 1.260698).  Saving model ...
Validation loss decreased (1.260698 --> 1.252989).  Saving model ...
Validation loss decreased (1.252989 --> 1.245785).  Saving model ...
Validation loss decreased (1.245785 --> 1.238352).  Saving model ...
Validation loss decreased (1.238352 --> 1.231339).  Saving model ...
Validation loss decreased (1.231339 --> 1.224012).  Saving model ...
Validation loss decreased (1.224012 --> 1.218047).  Saving model ...
Validation loss decreased (1.218047 --> 1.211957).  Saving model ...
Validation loss decreased (1.211957 --> 1.205809).  Saving model ...
Validation loss decreased (1.205809 --> 1.200695).  Saving model ...
Validation loss decreased (1.200695 --> 1.195280).  Saving model ...
Validation loss decreased (1.195280 --> 1.188941).  Saving model ...
Validation loss decreased (1.188941 --> 1.182923).  Saving model ...
Validation loss decreased (1.182923 --> 1.176106).  Saving model ...
Validation loss decreased (1.176106 --> 1.170329).  Saving model ...
Validation loss decreased (1.170329 --> 1.166037).  Saving model ...
Validation loss decreased (1.166037 --> 1.160856).  Saving model ...
Validation loss decreased (1.160856 --> 1.156900).  Saving model ...
Validation loss decreased (1.156900 --> 1.149516).  Saving model ...
Validation loss decreased (1.149516 --> 1.144129).  Saving model ...
Validation loss decreased (1.144129 --> 1.138198).  Saving model ...
Validation loss decreased (1.138198 --> 1.133643).  Saving model ...
Validation loss decreased (1.133643 --> 1.127632).  Saving model ...
Validation loss decreased (1.127632 --> 1.122327).  Saving model ...
Validation loss decreased (1.122327 --> 1.117408).  Saving model ...
Validation loss decreased (1.117408 --> 1.111565).  Saving model ...
Validation loss decreased (1.111565 --> 1.107006).  Saving model ...
Validation loss decreased (1.107006 --> 1.101972).  Saving model ...
Validation loss decreased (1.101972 --> 1.097223).  Saving model ...
Validation loss decreased (1.097223 --> 1.092636).  Saving model ...
Validation loss decreased (1.092636 --> 1.087384).  Saving model ...
Validation loss decreased (1.087384 --> 1.080792).  Saving model ...
Validation loss decreased (1.080792 --> 1.076080).  Saving model ...
Validation loss decreased (1.076080 --> 1.072331).  Saving model ...
Validation loss decreased (1.072331 --> 1.067596).  Saving model ...
Validation loss decreased (1.067596 --> 1.065132).  Saving model ...
Validation loss decreased (1.065132 --> 1.061153).  Saving model ...
Validation loss decreased (1.061153 --> 1.058066).  Saving model ...
Validation loss decreased (1.058066 --> 1.053831).  Saving model ...
Validation loss decreased (1.053831 --> 1.048655).  Saving model ...
Validation loss decreased (1.048655 --> 1.044385).  Saving model ...
Validation loss decreased (1.044385 --> 1.040484).  Saving model ...
Validation loss decreased (1.040484 --> 1.037333).  Saving model ...
Validation loss decreased (1.037333 --> 1.033814).  Saving model ...
Validation loss decreased (1.033814 --> 1.030251).  Saving model ...
Validation loss decreased (1.030251 --> 1.026960).  Saving model ...
Validation loss decreased (1.026960 --> 1.024501).  Saving model ...
Validation loss decreased (1.024501 --> 1.023743).  Saving model ...
Validation loss decreased (1.023743 --> 1.019131).  Saving model ...
Validation loss decreased (1.019131 --> 1.015565).  Saving model ...
Validation loss decreased (1.015565 --> 1.012308).  Saving model ...
Validation loss decreased (1.012308 --> 1.009591).  Saving model ...
Validation loss decreased (1.009591 --> 1.005861).  Saving model ...
Validation loss decreased (1.005861 --> 1.003131).  Saving model ...
Validation loss decreased (1.003131 --> 1.001064).  Saving model ...
Validation loss decreased (1.001064 --> 0.997000).  Saving model ...
Validation loss decreased (0.997000 --> 0.993763).  Saving model ...
Validation loss decreased (0.993763 --> 0.991477).  Saving model ...
Validation loss decreased (0.991477 --> 0.990120).  Saving model ...
Validation loss decreased (0.990120 --> 0.987713).  Saving model ...
Validation loss decreased (0.987713 --> 0.985013).  Saving model ...
Validation loss decreased (0.985013 --> 0.982498).  Saving model ...
Validation loss decreased (0.982498 --> 0.979485).  Saving model ...
Validation loss decreased (0.979485 --> 0.977615).  Saving model ...
Validation loss decreased (0.977615 --> 0.975031).  Saving model ...
Validation loss decreased (0.975031 --> 0.972669).  Saving model ...
Validation loss decreased (0.972669 --> 0.970744).  Saving model ...
Validation loss decreased (0.970744 --> 0.968431).  Saving model ...
Validation loss decreased (0.968431 --> 0.967163).  Saving model ...
Validation loss decreased (0.967163 --> 0.965322).  Saving model ...
Validation loss decreased (0.965322 --> 0.964255).  Saving model ...
Validation loss decreased (0.964255 --> 0.962241).  Saving model ...
Validation loss decreased (0.962241 --> 0.960166).  Saving model ...
Validation loss decreased (0.960166 --> 0.958140).  Saving model ...
Validation loss decreased (0.958140 --> 0.956429).  Saving model ...
Validation loss decreased (0.956429 --> 0.955190).  Saving model ...
Validation loss decreased (0.955190 --> 0.953911).  Saving model ...
Validation loss decreased (0.953911 --> 0.951957).  Saving model ...
Validation loss decreased (0.951957 --> 0.950444).  Saving model ...
Validation loss decreased (0.950444 --> 0.949233).  Saving model ...
Validation loss decreased (0.949233 --> 0.947863).  Saving model ...
Validation loss decreased (0.947863 --> 0.945662).  Saving model ...
Validation loss decreased (0.945662 --> 0.944546).  Saving model ...
Validation loss decreased (0.944546 --> 0.943458).  Saving model ...
Validation loss decreased (0.943458 --> 0.943088).  Saving model ...
Validation loss decreased (0.943088 --> 0.941908).  Saving model ...
Validation loss decreased (0.941908 --> 0.940829).  Saving model ...
Validation loss decreased (0.940829 --> 0.940029).  Saving model ...
Validation loss decreased (0.940029 --> 0.939406).  Saving model ...
Validation loss decreased (0.939406 --> 0.937987).  Saving model ...
Validation loss decreased (0.937987 --> 0.936857).  Saving model ...
Validation loss decreased (0.936857 --> 0.936276).  Saving model ...
Validation loss decreased (0.936276 --> 0.935428).  Saving model ...
Validation loss decreased (0.935428 --> 0.934293).  Saving model ...
Validation loss decreased (0.934293 --> 0.933691).  Saving model ...
Validation loss decreased (0.933691 --> 0.933170).  Saving model ...
Validation loss decreased (0.933170 --> 0.932218).  Saving model ...
Validation loss decreased (0.932218 --> 0.931356).  Saving model ...
Validation loss decreased (0.931356 --> 0.931036).  Saving model ...
Validation loss decreased (0.931036 --> 0.930810).  Saving model ...
Validation loss decreased (0.930810 --> 0.929515).  Saving model ...
Validation loss decreased (0.929515 --> 0.929173).  Saving model ...
EarlyStopping counter: 1 out of 10.0
Validation loss decreased (0.929173 --> 0.928064).  Saving model ...
Validation loss decreased (0.928064 --> 0.927504).  Saving model ...
Validation loss decreased (0.927504 --> 0.927139).  Saving model ...
EarlyStopping counter: 1 out of 10.0
EarlyStopping counter: 2 out of 10.0
Validation loss decreased (0.927139 --> 0.926875).  Saving model ...
Validation loss decreased (0.926875 --> 0.925838).  Saving model ...
Validation loss decreased (0.925838 --> 0.925746).  Saving model ...
Validation loss decreased (0.925746 --> 0.924903).  Saving model ...
EarlyStopping counter: 1 out of 10.0
EarlyStopping counter: 2 out of 10.0
EarlyStopping counter: 3 out of 10.0
EarlyStopping counter: 4 out of 10.0
EarlyStopping counter: 5 out of 10.0
EarlyStopping counter: 6 out of 10.0
EarlyStopping counter: 7 out of 10.0
EarlyStopping counter: 8 out of 10.0
EarlyStopping counter: 9 out of 10.0
EarlyStopping counter: 10 out of 10.0
/localscratch/yinan.29351705.0/env/lib/python3.7/site-packages/torch/nn/functional.py:1794: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.
  warnings.warn("nn.functional.tanh is deprecated. Use torch.tanh instead.")
wandb: Waiting for W&B process to finish, PID 26452... (success).
wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: \ 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: | 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: / 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: \ 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: | 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: / 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: \ 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: | 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: / 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb:                                                                                
wandb: Run history:
wandb:     e_F1 ▁▁▃▄▅▅▆▆▆▆▆▆▆▇▇▇▇▇▇▇▇▇▇▇████████████████
wandb:   e_loss ██▇▇▇▆▆▆▅▅▅▄▄▄▃▃▃▃▃▂▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:     t_F1 ▁▂▂▃▃▃▄▄▅▅▅▆▅▅▆▆▆▆▆▇▆▇▇▇▇▇▆▇▇▇█▇▇█▇█████
wandb:   t_loss █▇▇▇▇▇▇▆▆▆▅▅▅▅▅▄▄▄▄▃▄▃▃▃▃▂▃▂▂▂▂▂▂▂▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:     e_F1 62.9479
wandb:   e_loss 0.92914
wandb:     t_F1 73.04106
wandb:   t_loss 0.74837
wandb: 
wandb: Synced 4 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Synced efficient-aardvark-1: https://wandb.ai/yinanazhou/xl_512_bs_8_lr_1e06_es_10_lc_False_nr_True_sr_False_stem_False_lemma_True_repeat_3_fold_2/runs/35qip7sv
wandb: Find logs at: ./wandb/run-20220327_164805-35qip7sv/logs/debug.log
wandb: 

wandb: wandb version 0.12.11 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
2022-03-27 18:24:03.721514: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1
wandb: Tracking run with wandb version 0.12.5
wandb: Syncing run eager-resonance-1
wandb: ⭐️ View project at https://wandb.ai/yinanazhou/xl_512_bs_8_lr_1e06_es_10_lc_False_nr_True_sr_False_stem_False_lemma_True_repeat_4_fold_1
wandb: 🚀 View run at https://wandb.ai/yinanazhou/xl_512_bs_8_lr_1e06_es_10_lc_False_nr_True_sr_False_stem_False_lemma_True_repeat_4_fold_1/runs/31xiordg
wandb: Run data is saved locally in /project/6002780/yinan/Thesis_MER_Lyrics/lyric-emotion/wandb/run-20220327_182401-31xiordg
wandb: Run `wandb offline` to turn off syncing.

Validation loss decreased (inf --> 1.426750).  Saving model ...
Validation loss decreased (1.426750 --> 1.412052).  Saving model ...
Validation loss decreased (1.412052 --> 1.401469).  Saving model ...
Validation loss decreased (1.401469 --> 1.392844).  Saving model ...
Validation loss decreased (1.392844 --> 1.385641).  Saving model ...
Validation loss decreased (1.385641 --> 1.379189).  Saving model ...
Validation loss decreased (1.379189 --> 1.373576).  Saving model ...
Validation loss decreased (1.373576 --> 1.368358).  Saving model ...
Validation loss decreased (1.368358 --> 1.363485).  Saving model ...
Validation loss decreased (1.363485 --> 1.358764).  Saving model ...
Validation loss decreased (1.358764 --> 1.353604).  Saving model ...
Validation loss decreased (1.353604 --> 1.348521).  Saving model ...
Validation loss decreased (1.348521 --> 1.343732).  Saving model ...
Validation loss decreased (1.343732 --> 1.338410).  Saving model ...
Validation loss decreased (1.338410 --> 1.332718).  Saving model ...
Validation loss decreased (1.332718 --> 1.326883).  Saving model ...
Validation loss decreased (1.326883 --> 1.320746).  Saving model ...
Validation loss decreased (1.320746 --> 1.314807).  Saving model ...
Validation loss decreased (1.314807 --> 1.308611).  Saving model ...
Validation loss decreased (1.308611 --> 1.301313).  Saving model ...
Validation loss decreased (1.301313 --> 1.294742).  Saving model ...
Validation loss decreased (1.294742 --> 1.286888).  Saving model ...
Validation loss decreased (1.286888 --> 1.279775).  Saving model ...
Validation loss decreased (1.279775 --> 1.273328).  Saving model ...
Validation loss decreased (1.273328 --> 1.266698).  Saving model ...
Validation loss decreased (1.266698 --> 1.260075).  Saving model ...
Validation loss decreased (1.260075 --> 1.253076).  Saving model ...
Validation loss decreased (1.253076 --> 1.246433).  Saving model ...
Validation loss decreased (1.246433 --> 1.239435).  Saving model ...
Validation loss decreased (1.239435 --> 1.232927).  Saving model ...
Validation loss decreased (1.232927 --> 1.226211).  Saving model ...
Validation loss decreased (1.226211 --> 1.220389).  Saving model ...
Validation loss decreased (1.220389 --> 1.215280).  Saving model ...
Validation loss decreased (1.215280 --> 1.210009).  Saving model ...
Validation loss decreased (1.210009 --> 1.204433).  Saving model ...
Validation loss decreased (1.204433 --> 1.198025).  Saving model ...
Validation loss decreased (1.198025 --> 1.193107).  Saving model ...
Validation loss decreased (1.193107 --> 1.187799).  Saving model ...
Validation loss decreased (1.187799 --> 1.182712).  Saving model ...
Validation loss decreased (1.182712 --> 1.178034).  Saving model ...
Validation loss decreased (1.178034 --> 1.173693).  Saving model ...
Validation loss decreased (1.173693 --> 1.169382).  Saving model ...
Validation loss decreased (1.169382 --> 1.163418).  Saving model ...
Validation loss decreased (1.163418 --> 1.158512).  Saving model ...
Validation loss decreased (1.158512 --> 1.155358).  Saving model ...
Validation loss decreased (1.155358 --> 1.150995).  Saving model ...
Validation loss decreased (1.150995 --> 1.146025).  Saving model ...
Validation loss decreased (1.146025 --> 1.141150).  Saving model ...
Validation loss decreased (1.141150 --> 1.137504).  Saving model ...
Validation loss decreased (1.137504 --> 1.133272).  Saving model ...
Validation loss decreased (1.133272 --> 1.130018).  Saving model ...
Validation loss decreased (1.130018 --> 1.125460).  Saving model ...
Validation loss decreased (1.125460 --> 1.120549).  Saving model ...
Validation loss decreased (1.120549 --> 1.116721).  Saving model ...
Validation loss decreased (1.116721 --> 1.112525).  Saving model ...
Validation loss decreased (1.112525 --> 1.109292).  Saving model ...
Validation loss decreased (1.109292 --> 1.106466).  Saving model ...
Validation loss decreased (1.106466 --> 1.103139).  Saving model ...
Validation loss decreased (1.103139 --> 1.099060).  Saving model ...
Validation loss decreased (1.099060 --> 1.095502).  Saving model ...
Validation loss decreased (1.095502 --> 1.091978).  Saving model ...
Validation loss decreased (1.091978 --> 1.087688).  Saving model ...
Validation loss decreased (1.087688 --> 1.084322).  Saving model ...
Validation loss decreased (1.084322 --> 1.081514).  Saving model ...
Validation loss decreased (1.081514 --> 1.078647).  Saving model ...
Validation loss decreased (1.078647 --> 1.075559).  Saving model ...
Validation loss decreased (1.075559 --> 1.072488).  Saving model ...
Validation loss decreased (1.072488 --> 1.069573).  Saving model ...
Validation loss decreased (1.069573 --> 1.067082).  Saving model ...
Validation loss decreased (1.067082 --> 1.065215).  Saving model ...
Validation loss decreased (1.065215 --> 1.063448).  Saving model ...
Validation loss decreased (1.063448 --> 1.061054).  Saving model ...
Validation loss decreased (1.061054 --> 1.057757).  Saving model ...
Validation loss decreased (1.057757 --> 1.055763).  Saving model ...
Validation loss decreased (1.055763 --> 1.052401).  Saving model ...
Validation loss decreased (1.052401 --> 1.049562).  Saving model ...
Validation loss decreased (1.049562 --> 1.047505).  Saving model ...
Validation loss decreased (1.047505 --> 1.045326).  Saving model ...
Validation loss decreased (1.045326 --> 1.043618).  Saving model ...
Validation loss decreased (1.043618 --> 1.042666).  Saving model ...
Validation loss decreased (1.042666 --> 1.040443).  Saving model ...
Validation loss decreased (1.040443 --> 1.038018).  Saving model ...
Validation loss decreased (1.038018 --> 1.035828).  Saving model ...
Validation loss decreased (1.035828 --> 1.033549).  Saving model ...
Validation loss decreased (1.033549 --> 1.031943).  Saving model ...
Validation loss decreased (1.031943 --> 1.030516).  Saving model ...
Validation loss decreased (1.030516 --> 1.028005).  Saving model ...
Validation loss decreased (1.028005 --> 1.026348).  Saving model ...
Validation loss decreased (1.026348 --> 1.024893).  Saving model ...
Validation loss decreased (1.024893 --> 1.022148).  Saving model ...
Validation loss decreased (1.022148 --> 1.020923).  Saving model ...
Validation loss decreased (1.020923 --> 1.019790).  Saving model ...
Validation loss decreased (1.019790 --> 1.019149).  Saving model ...
Validation loss decreased (1.019149 --> 1.018185).  Saving model ...
EarlyStopping counter: 1 out of 10.0
Validation loss decreased (1.018185 --> 1.015937).  Saving model ...
Validation loss decreased (1.015937 --> 1.014698).  Saving model ...
Validation loss decreased (1.014698 --> 1.014673).  Saving model ...
Validation loss decreased (1.014673 --> 1.011898).  Saving model ...
Validation loss decreased (1.011898 --> 1.010337).  Saving model ...
Validation loss decreased (1.010337 --> 1.009545).  Saving model ...
Validation loss decreased (1.009545 --> 1.007956).  Saving model ...
Validation loss decreased (1.007956 --> 1.007614).  Saving model ...
Validation loss decreased (1.007614 --> 1.006892).  Saving model ...
EarlyStopping counter: 1 out of 10.0
Validation loss decreased (1.006892 --> 1.005445).  Saving model ...
Validation loss decreased (1.005445 --> 1.003877).  Saving model ...
Validation loss decreased (1.003877 --> 1.002327).  Saving model ...
Validation loss decreased (1.002327 --> 1.001755).  Saving model ...
EarlyStopping counter: 1 out of 10.0
Validation loss decreased (1.001755 --> 1.001309).  Saving model ...
EarlyStopping counter: 1 out of 10.0
Validation loss decreased (1.001309 --> 0.999879).  Saving model ...
EarlyStopping counter: 1 out of 10.0
EarlyStopping counter: 2 out of 10.0
Validation loss decreased (0.999879 --> 0.998199).  Saving model ...
Validation loss decreased (0.998199 --> 0.996682).  Saving model ...
Validation loss decreased (0.996682 --> 0.995319).  Saving model ...
EarlyStopping counter: 1 out of 10.0
EarlyStopping counter: 2 out of 10.0
EarlyStopping counter: 3 out of 10.0
EarlyStopping counter: 4 out of 10.0
EarlyStopping counter: 5 out of 10.0
Validation loss decreased (0.995319 --> 0.994133).  Saving model ...
Validation loss decreased (0.994133 --> 0.993876).  Saving model ...
Validation loss decreased (0.993876 --> 0.993064).  Saving model ...
EarlyStopping counter: 1 out of 10.0
EarlyStopping counter: 2 out of 10.0
Validation loss decreased (0.993064 --> 0.991675).  Saving model ...
EarlyStopping counter: 1 out of 10.0
EarlyStopping counter: 2 out of 10.0
Validation loss decreased (0.991675 --> 0.991649).  Saving model ...
EarlyStopping counter: 1 out of 10.0
Validation loss decreased (0.991649 --> 0.991618).  Saving model ...
EarlyStopping counter: 1 out of 10.0
EarlyStopping counter: 2 out of 10.0
Validation loss decreased (0.991618 --> 0.991042).  Saving model ...
Validation loss decreased (0.991042 --> 0.988842).  Saving model ...
EarlyStopping counter: 1 out of 10.0
EarlyStopping counter: 2 out of 10.0
EarlyStopping counter: 3 out of 10.0
EarlyStopping counter: 4 out of 10.0
EarlyStopping counter: 5 out of 10.0
EarlyStopping counter: 6 out of 10.0
EarlyStopping counter: 7 out of 10.0
EarlyStopping counter: 8 out of 10.0
EarlyStopping counter: 9 out of 10.0
EarlyStopping counter: 10 out of 10.0
/localscratch/yinan.29351705.0/env/lib/python3.7/site-packages/torch/nn/functional.py:1794: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.
  warnings.warn("nn.functional.tanh is deprecated. Use torch.tanh instead.")
wandb: Waiting for W&B process to finish, PID 31587... (success).
wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: \ 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: | 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: / 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: \ 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: | 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: / 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: \ 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: | 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: / 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: \ 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: | 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: / 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb:                                                                                
wandb: Run history:
wandb:     e_F1 ▁▂▃▄▅▅▅▆▆▆▆▆▆▆▇▇▇▇▇▇▇▇▇█████████████████
wandb:   e_loss ██▇▇▇▆▆▅▅▅▄▄▄▃▃▃▃▂▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:     t_F1 ▁▁▂▂▃▃▄▄▄▅▄▅▆▅▆▆▆▆▆▆▆▇▆▆▇▇▇▇▇▇▇▇█▇██▇██▇
wandb:   t_loss ███▇▇▇▇▆▆▆▆▅▅▅▅▄▄▄▄▄▄▃▃▃▃▃▃▂▂▂▂▂▂▂▁▂▁▁▁▁
wandb: 
wandb: Run summary:
wandb:     e_F1 57.03362
wandb:   e_loss 0.99716
wandb:     t_F1 69.68991
wandb:   t_loss 0.73293
wandb: 
wandb: Synced 4 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Synced eager-resonance-1: https://wandb.ai/yinanazhou/xl_512_bs_8_lr_1e06_es_10_lc_False_nr_True_sr_False_stem_False_lemma_True_repeat_4_fold_1/runs/31xiordg
wandb: Find logs at: ./wandb/run-20220327_182401-31xiordg/logs/debug.log
wandb: 

wandb: wandb version 0.12.11 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
2022-03-27 20:01:38.686678: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1
wandb: Tracking run with wandb version 0.12.5
wandb: Syncing run astral-plant-1
wandb: ⭐️ View project at https://wandb.ai/yinanazhou/xl_512_bs_8_lr_1e06_es_10_lc_False_nr_True_sr_False_stem_False_lemma_True_repeat_4_fold_2
wandb: 🚀 View run at https://wandb.ai/yinanazhou/xl_512_bs_8_lr_1e06_es_10_lc_False_nr_True_sr_False_stem_False_lemma_True_repeat_4_fold_2/runs/1t1t6ocz
wandb: Run data is saved locally in /project/6002780/yinan/Thesis_MER_Lyrics/lyric-emotion/wandb/run-20220327_200136-1t1t6ocz
wandb: Run `wandb offline` to turn off syncing.

Validation loss decreased (inf --> 1.421599).  Saving model ...
Validation loss decreased (1.421599 --> 1.399105).  Saving model ...
Validation loss decreased (1.399105 --> 1.383988).  Saving model ...
Validation loss decreased (1.383988 --> 1.373384).  Saving model ...
Validation loss decreased (1.373384 --> 1.364604).  Saving model ...
Validation loss decreased (1.364604 --> 1.357824).  Saving model ...
Validation loss decreased (1.357824 --> 1.352070).  Saving model ...
Validation loss decreased (1.352070 --> 1.347120).  Saving model ...
Validation loss decreased (1.347120 --> 1.341617).  Saving model ...
Validation loss decreased (1.341617 --> 1.335912).  Saving model ...
Validation loss decreased (1.335912 --> 1.330934).  Saving model ...
Validation loss decreased (1.330934 --> 1.325030).  Saving model ...
Validation loss decreased (1.325030 --> 1.319562).  Saving model ...
Validation loss decreased (1.319562 --> 1.314287).  Saving model ...
Validation loss decreased (1.314287 --> 1.309656).  Saving model ...
Validation loss decreased (1.309656 --> 1.302964).  Saving model ...
Validation loss decreased (1.302964 --> 1.298031).  Saving model ...
Validation loss decreased (1.298031 --> 1.291683).  Saving model ...
Validation loss decreased (1.291683 --> 1.283890).  Saving model ...
Validation loss decreased (1.283890 --> 1.277432).  Saving model ...
Validation loss decreased (1.277432 --> 1.270371).  Saving model ...
Validation loss decreased (1.270371 --> 1.262249).  Saving model ...
Validation loss decreased (1.262249 --> 1.254492).  Saving model ...
Validation loss decreased (1.254492 --> 1.246512).  Saving model ...
Validation loss decreased (1.246512 --> 1.238520).  Saving model ...
Validation loss decreased (1.238520 --> 1.230070).  Saving model ...
Validation loss decreased (1.230070 --> 1.224957).  Saving model ...
Validation loss decreased (1.224957 --> 1.215248).  Saving model ...
Validation loss decreased (1.215248 --> 1.208750).  Saving model ...
Validation loss decreased (1.208750 --> 1.200880).  Saving model ...
Validation loss decreased (1.200880 --> 1.192196).  Saving model ...
Validation loss decreased (1.192196 --> 1.184307).  Saving model ...
Validation loss decreased (1.184307 --> 1.176710).  Saving model ...
Validation loss decreased (1.176710 --> 1.169758).  Saving model ...
Validation loss decreased (1.169758 --> 1.163765).  Saving model ...
Validation loss decreased (1.163765 --> 1.157576).  Saving model ...
Validation loss decreased (1.157576 --> 1.151999).  Saving model ...
Validation loss decreased (1.151999 --> 1.146691).  Saving model ...
Validation loss decreased (1.146691 --> 1.140850).  Saving model ...
Validation loss decreased (1.140850 --> 1.136374).  Saving model ...
Validation loss decreased (1.136374 --> 1.134485).  Saving model ...
Validation loss decreased (1.134485 --> 1.127183).  Saving model ...
Validation loss decreased (1.127183 --> 1.119152).  Saving model ...
Validation loss decreased (1.119152 --> 1.113220).  Saving model ...
Validation loss decreased (1.113220 --> 1.108979).  Saving model ...
Validation loss decreased (1.108979 --> 1.106800).  Saving model ...
Validation loss decreased (1.106800 --> 1.103525).  Saving model ...
Validation loss decreased (1.103525 --> 1.097880).  Saving model ...
Validation loss decreased (1.097880 --> 1.092665).  Saving model ...
Validation loss decreased (1.092665 --> 1.089319).  Saving model ...
Validation loss decreased (1.089319 --> 1.087224).  Saving model ...
Validation loss decreased (1.087224 --> 1.080283).  Saving model ...
Validation loss decreased (1.080283 --> 1.075873).  Saving model ...
Validation loss decreased (1.075873 --> 1.074753).  Saving model ...
Validation loss decreased (1.074753 --> 1.068600).  Saving model ...
Validation loss decreased (1.068600 --> 1.062200).  Saving model ...
Validation loss decreased (1.062200 --> 1.059207).  Saving model ...
Validation loss decreased (1.059207 --> 1.055507).  Saving model ...
Validation loss decreased (1.055507 --> 1.051615).  Saving model ...
Validation loss decreased (1.051615 --> 1.049729).  Saving model ...
Validation loss decreased (1.049729 --> 1.046186).  Saving model ...
Validation loss decreased (1.046186 --> 1.042863).  Saving model ...
Validation loss decreased (1.042863 --> 1.042629).  Saving model ...
Validation loss decreased (1.042629 --> 1.037800).  Saving model ...
Validation loss decreased (1.037800 --> 1.035509).  Saving model ...
Validation loss decreased (1.035509 --> 1.032510).  Saving model ...
Validation loss decreased (1.032510 --> 1.028953).  Saving model ...
Validation loss decreased (1.028953 --> 1.028136).  Saving model ...
Validation loss decreased (1.028136 --> 1.026738).  Saving model ...
Validation loss decreased (1.026738 --> 1.022786).  Saving model ...
Validation loss decreased (1.022786 --> 1.021489).  Saving model ...
Validation loss decreased (1.021489 --> 1.018976).  Saving model ...
Validation loss decreased (1.018976 --> 1.015331).  Saving model ...
Validation loss decreased (1.015331 --> 1.015174).  Saving model ...
Validation loss decreased (1.015174 --> 1.010042).  Saving model ...
Validation loss decreased (1.010042 --> 1.006858).  Saving model ...
Validation loss decreased (1.006858 --> 1.006635).  Saving model ...
EarlyStopping counter: 1 out of 10.0
Validation loss decreased (1.006635 --> 1.006069).  Saving model ...
Validation loss decreased (1.006069 --> 1.003629).  Saving model ...
Validation loss decreased (1.003629 --> 1.000654).  Saving model ...
EarlyStopping counter: 1 out of 10.0
EarlyStopping counter: 2 out of 10.0
Validation loss decreased (1.000654 --> 0.998619).  Saving model ...
EarlyStopping counter: 1 out of 10.0
EarlyStopping counter: 2 out of 10.0
Validation loss decreased (0.998619 --> 0.994793).  Saving model ...
Validation loss decreased (0.994793 --> 0.990600).  Saving model ...
Validation loss decreased (0.990600 --> 0.989263).  Saving model ...
EarlyStopping counter: 1 out of 10.0
EarlyStopping counter: 2 out of 10.0
EarlyStopping counter: 3 out of 10.0
EarlyStopping counter: 4 out of 10.0
Validation loss decreased (0.989263 --> 0.988721).  Saving model ...
Validation loss decreased (0.988721 --> 0.987790).  Saving model ...
EarlyStopping counter: 1 out of 10.0
EarlyStopping counter: 2 out of 10.0
EarlyStopping counter: 3 out of 10.0
EarlyStopping counter: 4 out of 10.0
EarlyStopping counter: 5 out of 10.0
EarlyStopping counter: 6 out of 10.0
EarlyStopping counter: 7 out of 10.0
Validation loss decreased (0.987790 --> 0.986907).  Saving model ...
EarlyStopping counter: 1 out of 10.0
EarlyStopping counter: 2 out of 10.0
Validation loss decreased (0.986907 --> 0.985558).  Saving model ...
EarlyStopping counter: 1 out of 10.0
Validation loss decreased (0.985558 --> 0.983733).  Saving model ...
EarlyStopping counter: 1 out of 10.0
EarlyStopping counter: 2 out of 10.0
Validation loss decreased (0.983733 --> 0.983393).  Saving model ...
EarlyStopping counter: 1 out of 10.0
EarlyStopping counter: 2 out of 10.0
EarlyStopping counter: 3 out of 10.0
EarlyStopping counter: 4 out of 10.0
Validation loss decreased (0.983393 --> 0.979879).  Saving model ...
EarlyStopping counter: 1 out of 10.0
EarlyStopping counter: 2 out of 10.0
EarlyStopping counter: 3 out of 10.0
EarlyStopping counter: 4 out of 10.0
EarlyStopping counter: 5 out of 10.0
EarlyStopping counter: 6 out of 10.0
EarlyStopping counter: 7 out of 10.0
EarlyStopping counter: 8 out of 10.0
EarlyStopping counter: 9 out of 10.0
EarlyStopping counter: 10 out of 10.0
/localscratch/yinan.29351705.0/env/lib/python3.7/site-packages/torch/nn/functional.py:1794: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.
  warnings.warn("nn.functional.tanh is deprecated. Use torch.tanh instead.")
wandb: Waiting for W&B process to finish, PID 36793... (success).
wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: \ 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: | 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: / 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: \ 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: | 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: / 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: \ 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: | 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: / 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb:                                                                                
wandb: Run history:
wandb:     e_F1 ▁▃▅▅▆▆▆▆▆▆▇▇▇▇▇▇▇▇▇▇▇▇▇▇████████████████
wandb:   e_loss █▇▇▇▆▆▆▅▅▅▄▄▄▃▃▃▃▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:     t_F1 ▁▂▃▃▃▄▄▅▄▄▅▅▅▆▆▆▆▆▇▇▇▇▇▇▇▇▇▇▇▇▇█▇█▇█████
wandb:   t_loss ██▇▇▇▇▆▆▆▆▅▅▅▅▅▄▄▄▄▄▃▃▃▃▃▃▃▂▂▂▂▂▂▂▂▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:     e_F1 60.23915
wandb:   e_loss 0.98275
wandb:     t_F1 71.52945
wandb:   t_loss 0.75235
wandb: 
wandb: Synced 4 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Synced astral-plant-1: https://wandb.ai/yinanazhou/xl_512_bs_8_lr_1e06_es_10_lc_False_nr_True_sr_False_stem_False_lemma_True_repeat_4_fold_2/runs/1t1t6ocz
wandb: Find logs at: ./wandb/run-20220327_200136-1t1t6ocz/logs/debug.log
wandb: 

wandb: wandb version 0.12.11 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
2022-03-27 21:24:27.335214: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1
wandb: Tracking run with wandb version 0.12.5
wandb: Syncing run gentle-snowflake-1
wandb: ⭐️ View project at https://wandb.ai/yinanazhou/xl_512_bs_8_lr_1e06_es_10_lc_False_nr_True_sr_False_stem_False_lemma_True_repeat_5_fold_1
wandb: 🚀 View run at https://wandb.ai/yinanazhou/xl_512_bs_8_lr_1e06_es_10_lc_False_nr_True_sr_False_stem_False_lemma_True_repeat_5_fold_1/runs/1vi28sy3
wandb: Run data is saved locally in /project/6002780/yinan/Thesis_MER_Lyrics/lyric-emotion/wandb/run-20220327_212425-1vi28sy3
wandb: Run `wandb offline` to turn off syncing.

Validation loss decreased (inf --> 1.446595).  Saving model ...
Validation loss decreased (1.446595 --> 1.420511).  Saving model ...
Validation loss decreased (1.420511 --> 1.402339).  Saving model ...
Validation loss decreased (1.402339 --> 1.387780).  Saving model ...
Validation loss decreased (1.387780 --> 1.377923).  Saving model ...
Validation loss decreased (1.377923 --> 1.369915).  Saving model ...
Validation loss decreased (1.369915 --> 1.362575).  Saving model ...
Validation loss decreased (1.362575 --> 1.356539).  Saving model ...
Validation loss decreased (1.356539 --> 1.351533).  Saving model ...
Validation loss decreased (1.351533 --> 1.346418).  Saving model ...
Validation loss decreased (1.346418 --> 1.341660).  Saving model ...
Validation loss decreased (1.341660 --> 1.336960).  Saving model ...
Validation loss decreased (1.336960 --> 1.332192).  Saving model ...
Validation loss decreased (1.332192 --> 1.327397).  Saving model ...
Validation loss decreased (1.327397 --> 1.322381).  Saving model ...
Validation loss decreased (1.322381 --> 1.317122).  Saving model ...
Validation loss decreased (1.317122 --> 1.312022).  Saving model ...
Validation loss decreased (1.312022 --> 1.306577).  Saving model ...
Validation loss decreased (1.306577 --> 1.300665).  Saving model ...
Validation loss decreased (1.300665 --> 1.294647).  Saving model ...
Validation loss decreased (1.294647 --> 1.288181).  Saving model ...
Validation loss decreased (1.288181 --> 1.282157).  Saving model ...
Validation loss decreased (1.282157 --> 1.275527).  Saving model ...
Validation loss decreased (1.275527 --> 1.268445).  Saving model ...
Validation loss decreased (1.268445 --> 1.261270).  Saving model ...
Validation loss decreased (1.261270 --> 1.254525).  Saving model ...
Validation loss decreased (1.254525 --> 1.246614).  Saving model ...
Validation loss decreased (1.246614 --> 1.239007).  Saving model ...
Validation loss decreased (1.239007 --> 1.231582).  Saving model ...
Validation loss decreased (1.231582 --> 1.223910).  Saving model ...
Validation loss decreased (1.223910 --> 1.217462).  Saving model ...
Validation loss decreased (1.217462 --> 1.210009).  Saving model ...
Validation loss decreased (1.210009 --> 1.201851).  Saving model ...
Validation loss decreased (1.201851 --> 1.194330).  Saving model ...
Validation loss decreased (1.194330 --> 1.186597).  Saving model ...
Validation loss decreased (1.186597 --> 1.178268).  Saving model ...
Validation loss decreased (1.178268 --> 1.171737).  Saving model ...
Validation loss decreased (1.171737 --> 1.165613).  Saving model ...
Validation loss decreased (1.165613 --> 1.158294).  Saving model ...
Validation loss decreased (1.158294 --> 1.150929).  Saving model ...
Validation loss decreased (1.150929 --> 1.145562).  Saving model ...
Validation loss decreased (1.145562 --> 1.139353).  Saving model ...
Validation loss decreased (1.139353 --> 1.133084).  Saving model ...
Validation loss decreased (1.133084 --> 1.128064).  Saving model ...
Validation loss decreased (1.128064 --> 1.122841).  Saving model ...
Validation loss decreased (1.122841 --> 1.117412).  Saving model ...
Validation loss decreased (1.117412 --> 1.112076).  Saving model ...
Validation loss decreased (1.112076 --> 1.106473).  Saving model ...
Validation loss decreased (1.106473 --> 1.102526).  Saving model ...
Validation loss decreased (1.102526 --> 1.097021).  Saving model ...
Validation loss decreased (1.097021 --> 1.090875).  Saving model ...
Validation loss decreased (1.090875 --> 1.086425).  Saving model ...
Validation loss decreased (1.086425 --> 1.081116).  Saving model ...
Validation loss decreased (1.081116 --> 1.077628).  Saving model ...
Validation loss decreased (1.077628 --> 1.073557).  Saving model ...
Validation loss decreased (1.073557 --> 1.068854).  Saving model ...
Validation loss decreased (1.068854 --> 1.066020).  Saving model ...
Validation loss decreased (1.066020 --> 1.062844).  Saving model ...
Validation loss decreased (1.062844 --> 1.059402).  Saving model ...
Validation loss decreased (1.059402 --> 1.055395).  Saving model ...
Validation loss decreased (1.055395 --> 1.052012).  Saving model ...
Validation loss decreased (1.052012 --> 1.049003).  Saving model ...
Validation loss decreased (1.049003 --> 1.044849).  Saving model ...
Validation loss decreased (1.044849 --> 1.043251).  Saving model ...
Validation loss decreased (1.043251 --> 1.040021).  Saving model ...
Validation loss decreased (1.040021 --> 1.036648).  Saving model ...
Validation loss decreased (1.036648 --> 1.032423).  Saving model ...
Validation loss decreased (1.032423 --> 1.029685).  Saving model ...
Validation loss decreased (1.029685 --> 1.024216).  Saving model ...
Validation loss decreased (1.024216 --> 1.020930).  Saving model ...
Validation loss decreased (1.020930 --> 1.018176).  Saving model ...
Validation loss decreased (1.018176 --> 1.013315).  Saving model ...
Validation loss decreased (1.013315 --> 1.009766).  Saving model ...
Validation loss decreased (1.009766 --> 1.007831).  Saving model ...
Validation loss decreased (1.007831 --> 1.004440).  Saving model ...
Validation loss decreased (1.004440 --> 1.001524).  Saving model ...
Validation loss decreased (1.001524 --> 0.999232).  Saving model ...
Validation loss decreased (0.999232 --> 0.996861).  Saving model ...
Validation loss decreased (0.996861 --> 0.994164).  Saving model ...
Validation loss decreased (0.994164 --> 0.990467).  Saving model ...
Validation loss decreased (0.990467 --> 0.987901).  Saving model ...
Validation loss decreased (0.987901 --> 0.985475).  Saving model ...
Validation loss decreased (0.985475 --> 0.984187).  Saving model ...
Validation loss decreased (0.984187 --> 0.982292).  Saving model ...
Validation loss decreased (0.982292 --> 0.978435).  Saving model ...
Validation loss decreased (0.978435 --> 0.976223).  Saving model ...
Validation loss decreased (0.976223 --> 0.973895).  Saving model ...
Validation loss decreased (0.973895 --> 0.971279).  Saving model ...
Validation loss decreased (0.971279 --> 0.970383).  Saving model ...
Validation loss decreased (0.970383 --> 0.967984).  Saving model ...
Validation loss decreased (0.967984 --> 0.964000).  Saving model ...
Validation loss decreased (0.964000 --> 0.961115).  Saving model ...
Validation loss decreased (0.961115 --> 0.959607).  Saving model ...
Validation loss decreased (0.959607 --> 0.959305).  Saving model ...
Validation loss decreased (0.959305 --> 0.958903).  Saving model ...
Validation loss decreased (0.958903 --> 0.956160).  Saving model ...
Validation loss decreased (0.956160 --> 0.955147).  Saving model ...
Validation loss decreased (0.955147 --> 0.953811).  Saving model ...
Validation loss decreased (0.953811 --> 0.951294).  Saving model ...
Validation loss decreased (0.951294 --> 0.948265).  Saving model ...
Validation loss decreased (0.948265 --> 0.946579).  Saving model ...
Validation loss decreased (0.946579 --> 0.946486).  Saving model ...
Validation loss decreased (0.946486 --> 0.945668).  Saving model ...
Validation loss decreased (0.945668 --> 0.943972).  Saving model ...
Validation loss decreased (0.943972 --> 0.942952).  Saving model ...
Validation loss decreased (0.942952 --> 0.941049).  Saving model ...
Validation loss decreased (0.941049 --> 0.940490).  Saving model ...
Validation loss decreased (0.940490 --> 0.939392).  Saving model ...
Validation loss decreased (0.939392 --> 0.937456).  Saving model ...
Validation loss decreased (0.937456 --> 0.937256).  Saving model ...
Validation loss decreased (0.937256 --> 0.934747).  Saving model ...
Validation loss decreased (0.934747 --> 0.932974).  Saving model ...
Validation loss decreased (0.932974 --> 0.932544).  Saving model ...
Validation loss decreased (0.932544 --> 0.931462).  Saving model ...
Validation loss decreased (0.931462 --> 0.930594).  Saving model ...
Validation loss decreased (0.930594 --> 0.929750).  Saving model ...
Validation loss decreased (0.929750 --> 0.928351).  Saving model ...
Validation loss decreased (0.928351 --> 0.927904).  Saving model ...
Validation loss decreased (0.927904 --> 0.927059).  Saving model ...
Validation loss decreased (0.927059 --> 0.926298).  Saving model ...
Validation loss decreased (0.926298 --> 0.925256).  Saving model ...
Validation loss decreased (0.925256 --> 0.924482).  Saving model ...
Validation loss decreased (0.924482 --> 0.923470).  Saving model ...
EarlyStopping counter: 1 out of 10.0
Validation loss decreased (0.923470 --> 0.922888).  Saving model ...
Validation loss decreased (0.922888 --> 0.922266).  Saving model ...
Validation loss decreased (0.922266 --> 0.921644).  Saving model ...
Validation loss decreased (0.921644 --> 0.921009).  Saving model ...
Validation loss decreased (0.921009 --> 0.920779).  Saving model ...
Validation loss decreased (0.920779 --> 0.920683).  Saving model ...
Validation loss decreased (0.920683 --> 0.920449).  Saving model ...
EarlyStopping counter: 1 out of 10.0
EarlyStopping counter: 2 out of 10.0
Validation loss decreased (0.920449 --> 0.920259).  Saving model ...
Validation loss decreased (0.920259 --> 0.919804).  Saving model ...
EarlyStopping counter: 1 out of 10.0
EarlyStopping counter: 2 out of 10.0
Validation loss decreased (0.919804 --> 0.919558).  Saving model ...
EarlyStopping counter: 1 out of 10.0
EarlyStopping counter: 2 out of 10.0
EarlyStopping counter: 3 out of 10.0
EarlyStopping counter: 4 out of 10.0
EarlyStopping counter: 5 out of 10.0
EarlyStopping counter: 6 out of 10.0
EarlyStopping counter: 7 out of 10.0
EarlyStopping counter: 8 out of 10.0
EarlyStopping counter: 9 out of 10.0
EarlyStopping counter: 10 out of 10.0
/localscratch/yinan.29351705.0/env/lib/python3.7/site-packages/torch/nn/functional.py:1794: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.
  warnings.warn("nn.functional.tanh is deprecated. Use torch.tanh instead.")
wandb: Waiting for W&B process to finish, PID 41220... (success).
wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: \ 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: | 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: / 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: \ 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: | 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: / 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: \ 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: | 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: / 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb:                                                                                
wandb: Run history:
wandb:     e_F1 ▁▂▄▄▅▅▅▆▆▆▇▇▇▇▇▇▇▇▇▇▇▇▇█████████████████
wandb:   e_loss ██▇▇▇▆▆▅▅▅▄▄▄▃▃▃▃▃▃▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:     t_F1 ▁▂▃▃▃▄▄▅▄▄▅▆▅▆▅▆▆▆▆▆▇▇▆▇▇▇▇▇▇▇█▇████████
wandb:   t_loss ██▇▇▇▇▇▆▆▆▆▅▅▅▄▄▄▄▄▄▃▃▃▃▃▃▃▂▂▂▂▂▂▂▂▂▁▁▁▁
wandb: 
wandb: Run summary:
wandb:     e_F1 61.05459
wandb:   e_loss 0.92195
wandb:     t_F1 72.10258
wandb:   t_loss 0.74453
wandb: 
wandb: Synced 4 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Synced gentle-snowflake-1: https://wandb.ai/yinanazhou/xl_512_bs_8_lr_1e06_es_10_lc_False_nr_True_sr_False_stem_False_lemma_True_repeat_5_fold_1/runs/1vi28sy3
wandb: Find logs at: ./wandb/run-20220327_212425-1vi28sy3/logs/debug.log
wandb: 

wandb: wandb version 0.12.11 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
2022-03-27 23:01:35.027917: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1
wandb: Tracking run with wandb version 0.12.5
wandb: Syncing run faithful-serenity-1
wandb: ⭐️ View project at https://wandb.ai/yinanazhou/xl_512_bs_8_lr_1e06_es_10_lc_False_nr_True_sr_False_stem_False_lemma_True_repeat_5_fold_2
wandb: 🚀 View run at https://wandb.ai/yinanazhou/xl_512_bs_8_lr_1e06_es_10_lc_False_nr_True_sr_False_stem_False_lemma_True_repeat_5_fold_2/runs/xnt43k5i
wandb: Run data is saved locally in /project/6002780/yinan/Thesis_MER_Lyrics/lyric-emotion/wandb/run-20220327_230132-xnt43k5i
wandb: Run `wandb offline` to turn off syncing.

Validation loss decreased (inf --> 1.405436).  Saving model ...
Validation loss decreased (1.405436 --> 1.395835).  Saving model ...
Validation loss decreased (1.395835 --> 1.388542).  Saving model ...
Validation loss decreased (1.388542 --> 1.383028).  Saving model ...
Validation loss decreased (1.383028 --> 1.377557).  Saving model ...
Validation loss decreased (1.377557 --> 1.373127).  Saving model ...
Validation loss decreased (1.373127 --> 1.368496).  Saving model ...
Validation loss decreased (1.368496 --> 1.364358).  Saving model ...
Validation loss decreased (1.364358 --> 1.360190).  Saving model ...
Validation loss decreased (1.360190 --> 1.356060).  Saving model ...
Validation loss decreased (1.356060 --> 1.351745).  Saving model ...
Validation loss decreased (1.351745 --> 1.347095).  Saving model ...
Validation loss decreased (1.347095 --> 1.342824).  Saving model ...
Validation loss decreased (1.342824 --> 1.337967).  Saving model ...
Validation loss decreased (1.337967 --> 1.332986).  Saving model ...
Validation loss decreased (1.332986 --> 1.327798).  Saving model ...
Validation loss decreased (1.327798 --> 1.322001).  Saving model ...
Validation loss decreased (1.322001 --> 1.316993).  Saving model ...
Validation loss decreased (1.316993 --> 1.310298).  Saving model ...
Validation loss decreased (1.310298 --> 1.303892).  Saving model ...
Validation loss decreased (1.303892 --> 1.297284).  Saving model ...
Validation loss decreased (1.297284 --> 1.290834).  Saving model ...
Validation loss decreased (1.290834 --> 1.283842).  Saving model ...
Validation loss decreased (1.283842 --> 1.277886).  Saving model ...
Validation loss decreased (1.277886 --> 1.270502).  Saving model ...
Validation loss decreased (1.270502 --> 1.263062).  Saving model ...
Validation loss decreased (1.263062 --> 1.255844).  Saving model ...
Validation loss decreased (1.255844 --> 1.247528).  Saving model ...
Validation loss decreased (1.247528 --> 1.240039).  Saving model ...
Validation loss decreased (1.240039 --> 1.233682).  Saving model ...
Validation loss decreased (1.233682 --> 1.226090).  Saving model ...
Validation loss decreased (1.226090 --> 1.220108).  Saving model ...
Validation loss decreased (1.220108 --> 1.214121).  Saving model ...
Validation loss decreased (1.214121 --> 1.206906).  Saving model ...
Validation loss decreased (1.206906 --> 1.199084).  Saving model ...
Validation loss decreased (1.199084 --> 1.191108).  Saving model ...
Validation loss decreased (1.191108 --> 1.184573).  Saving model ...
Validation loss decreased (1.184573 --> 1.178627).  Saving model ...
Validation loss decreased (1.178627 --> 1.173276).  Saving model ...
Validation loss decreased (1.173276 --> 1.166359).  Saving model ...
Validation loss decreased (1.166359 --> 1.161627).  Saving model ...
Validation loss decreased (1.161627 --> 1.157200).  Saving model ...
Validation loss decreased (1.157200 --> 1.151677).  Saving model ...
Validation loss decreased (1.151677 --> 1.146424).  Saving model ...
Validation loss decreased (1.146424 --> 1.140104).  Saving model ...
Validation loss decreased (1.140104 --> 1.136875).  Saving model ...
Validation loss decreased (1.136875 --> 1.134886).  Saving model ...
Validation loss decreased (1.134886 --> 1.129748).  Saving model ...
Validation loss decreased (1.129748 --> 1.123687).  Saving model ...
Validation loss decreased (1.123687 --> 1.119169).  Saving model ...
Validation loss decreased (1.119169 --> 1.115521).  Saving model ...
Validation loss decreased (1.115521 --> 1.111553).  Saving model ...
Validation loss decreased (1.111553 --> 1.105315).  Saving model ...
Validation loss decreased (1.105315 --> 1.099922).  Saving model ...
Validation loss decreased (1.099922 --> 1.094829).  Saving model ...
Validation loss decreased (1.094829 --> 1.089947).  Saving model ...
Validation loss decreased (1.089947 --> 1.086027).  Saving model ...
Validation loss decreased (1.086027 --> 1.085234).  Saving model ...
Validation loss decreased (1.085234 --> 1.079088).  Saving model ...
Validation loss decreased (1.079088 --> 1.076900).  Saving model ...
Validation loss decreased (1.076900 --> 1.072083).  Saving model ...
Validation loss decreased (1.072083 --> 1.070025).  Saving model ...
Validation loss decreased (1.070025 --> 1.066283).  Saving model ...
Validation loss decreased (1.066283 --> 1.062426).  Saving model ...
Validation loss decreased (1.062426 --> 1.058160).  Saving model ...
Validation loss decreased (1.058160 --> 1.054295).  Saving model ...
Validation loss decreased (1.054295 --> 1.053862).  Saving model ...
Validation loss decreased (1.053862 --> 1.051028).  Saving model ...
Validation loss decreased (1.051028 --> 1.048541).  Saving model ...
Validation loss decreased (1.048541 --> 1.045665).  Saving model ...
Validation loss decreased (1.045665 --> 1.043742).  Saving model ...
Validation loss decreased (1.043742 --> 1.039394).  Saving model ...
Validation loss decreased (1.039394 --> 1.032496).  Saving model ...
Validation loss decreased (1.032496 --> 1.030166).  Saving model ...
Validation loss decreased (1.030166 --> 1.028151).  Saving model ...
Validation loss decreased (1.028151 --> 1.026308).  Saving model ...
Validation loss decreased (1.026308 --> 1.025417).  Saving model ...
Validation loss decreased (1.025417 --> 1.023124).  Saving model ...
Validation loss decreased (1.023124 --> 1.022669).  Saving model ...
Validation loss decreased (1.022669 --> 1.022207).  Saving model ...
Validation loss decreased (1.022207 --> 1.019291).  Saving model ...
Validation loss decreased (1.019291 --> 1.016775).  Saving model ...
EarlyStopping counter: 1 out of 10.0
Validation loss decreased (1.016775 --> 1.014324).  Saving model ...
Validation loss decreased (1.014324 --> 1.011173).  Saving model ...
Validation loss decreased (1.011173 --> 1.006412).  Saving model ...
Validation loss decreased (1.006412 --> 1.006157).  Saving model ...
Validation loss decreased (1.006157 --> 1.003786).  Saving model ...
Validation loss decreased (1.003786 --> 1.002425).  Saving model ...
Validation loss decreased (1.002425 --> 1.001782).  Saving model ...
Validation loss decreased (1.001782 --> 0.998171).  Saving model ...
Validation loss decreased (0.998171 --> 0.997131).  Saving model ...
Validation loss decreased (0.997131 --> 0.995161).  Saving model ...
Validation loss decreased (0.995161 --> 0.993442).  Saving model ...
Validation loss decreased (0.993442 --> 0.991955).  Saving model ...
Validation loss decreased (0.991955 --> 0.990756).  Saving model ...
Validation loss decreased (0.990756 --> 0.989972).  Saving model ...
Validation loss decreased (0.989972 --> 0.987799).  Saving model ...
Validation loss decreased (0.987799 --> 0.987221).  Saving model ...
EarlyStopping counter: 1 out of 10.0
Validation loss decreased (0.987221 --> 0.986899).  Saving model ...
EarlyStopping counter: 1 out of 10.0
Validation loss decreased (0.986899 --> 0.984573).  Saving model ...
Validation loss decreased (0.984573 --> 0.980556).  Saving model ...
Validation loss decreased (0.980556 --> 0.979373).  Saving model ...
Validation loss decreased (0.979373 --> 0.977680).  Saving model ...
Validation loss decreased (0.977680 --> 0.977139).  Saving model ...
EarlyStopping counter: 1 out of 10.0
Validation loss decreased (0.977139 --> 0.975435).  Saving model ...
EarlyStopping counter: 1 out of 10.0
Validation loss decreased (0.975435 --> 0.973562).  Saving model ...
EarlyStopping counter: 1 out of 10.0
Validation loss decreased (0.973562 --> 0.972912).  Saving model ...
EarlyStopping counter: 1 out of 10.0
EarlyStopping counter: 2 out of 10.0
EarlyStopping counter: 3 out of 10.0
Validation loss decreased (0.972912 --> 0.972530).  Saving model ...
Validation loss decreased (0.972530 --> 0.972043).  Saving model ...
Validation loss decreased (0.972043 --> 0.969306).  Saving model ...
Validation loss decreased (0.969306 --> 0.967945).  Saving model ...
Validation loss decreased (0.967945 --> 0.965232).  Saving model ...
Validation loss decreased (0.965232 --> 0.964860).  Saving model ...
EarlyStopping counter: 1 out of 10.0
EarlyStopping counter: 2 out of 10.0
EarlyStopping counter: 3 out of 10.0
EarlyStopping counter: 4 out of 10.0
EarlyStopping counter: 5 out of 10.0
EarlyStopping counter: 6 out of 10.0
EarlyStopping counter: 7 out of 10.0
EarlyStopping counter: 8 out of 10.0
EarlyStopping counter: 9 out of 10.0
EarlyStopping counter: 10 out of 10.0
/localscratch/yinan.29351705.0/env/lib/python3.7/site-packages/torch/nn/functional.py:1794: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.
  warnings.warn("nn.functional.tanh is deprecated. Use torch.tanh instead.")
wandb: Waiting for W&B process to finish, PID 46424... (success).
wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: \ 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: | 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: / 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: \ 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: | 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: / 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: \ 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: | 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: / 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: \ 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: | 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: / 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: \ 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: | 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: / 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: \ 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb:                                                                                
wandb: Run history:
wandb:     e_F1 ▁▃▄▄▅▅▅▆▆▆▆▇▇▇▇▇▇▇▇▇█▇██████████████████
wandb:   e_loss ██▇▇▇▇▆▆▆▅▅▄▄▄▄▃▃▃▃▃▂▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁
wandb:     t_F1 ▁▁▂▂▃▃▄▄▅▅▅▅▆▆▆▆▆▆▆▆▆▇▇▇▇▇▇▇▇▇▇▇████████
wandb:   t_loss ███▇▇▇▇▇▆▆▆▅▅▅▅▄▄▄▄▄▄▃▃▃▃▃▂▂▂▂▂▂▂▂▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:     e_F1 59.02728
wandb:   e_loss 0.96858
wandb:     t_F1 71.55061
wandb:   t_loss 0.76579
wandb: 
wandb: Synced 4 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Synced faithful-serenity-1: https://wandb.ai/yinanazhou/xl_512_bs_8_lr_1e06_es_10_lc_False_nr_True_sr_False_stem_False_lemma_True_repeat_5_fold_2/runs/xnt43k5i
wandb: Find logs at: ./wandb/run-20220327_230132-xnt43k5i/logs/debug.log
wandb: 

