Unloading StdEnv/2020

Due to MODULEPATH changes, the following have been reloaded:
  1) mii/1.1.1


The following have been reloaded with a version change:
  1) python/3.8.2 => python/3.7.4

Using base prefix '/cvmfs/soft.computecanada.ca/easybuild/software/2017/Core/python/3.7.4'
New python executable in /localscratch/yinan.28285244.0/env/bin/python
Installing setuptools, pip, wheel...
done.
Ignoring pip: markers 'python_version < "3"' don't match your environment
Looking in links: /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/nix/avx2, /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/nix/generic, /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic
Collecting pip
Installing collected packages: pip
  Found existing installation: pip 19.1.1
    Uninstalling pip-19.1.1:
      Successfully uninstalled pip-19.1.1
Successfully installed pip-21.2.3+computecanada
Looking in links: /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/nix/avx2, /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/nix/generic, /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/keras-2.8.0+computecanada-py2.py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/Keras_Preprocessing-1.1.2+computecanada-py3-none-any.whl
Requirement already satisfied: matplotlib in /cvmfs/soft.computecanada.ca/easybuild/software/2017/Core/scipy-stack/2019a/lib/python3.7/site-packages (from -r requirements.txt (line 3)) (3.0.2)
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/nltk-3.6.5+computecanada-py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/scikit_learn-0.22.1+computecanada-cp37-cp37m-linux_x86_64.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/tensorboard-2.3.0+computecanada-py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/tensorboard_plugin_wit-1.7.0+computecanada-py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/tensorflow_gpu-2.3.0+computecanada-cp37-cp37m-linux_x86_64.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/tensorflow_estimator-2.3.0+computecanada-py2.py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/tokenizers-0.5.2+computecanada-cp37-cp37m-linux_x86_64.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/nix/avx2/torch-1.4.0+computecanada-cp37-cp37m-linux_x86_64.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/torchtext-0.6.0+computecanada-py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/torchvision-0.8.2+computecanada-cp37-cp37m-linux_x86_64.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/transformers-2.5.1+computecanada-py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/urllib3-1.26.7+computecanada-py2.py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/click-8.0.3+computecanada-py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/tqdm-4.63.0+computecanada-py2.py3-none-any.whl
ERROR: Could not find a version that satisfies the requirement regex>=2021.8.3 (from nltk) (from versions: 2018.1.10+computecanada, 2019.11.1+computecanada, 2020.11.13+computecanada)
ERROR: No matching distribution found for regex>=2021.8.3
Looking in links: /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/nix/avx2, /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/nix/generic, /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic
ERROR: Could not find a version that satisfies the requirement numpy==1.20.0+computacanada (from versions: 1.15.0+computecanada, 1.15.2+computecanada, 1.15.4+computecanada, 1.16.0+computecanada, 1.16.2+computecanada, 1.16.3+computecanada, 1.17.4+computecanada, 1.18.1+computecanada, 1.18.4+computecanada, 1.19.1+computecanada, 1.19.2+computecanada, 1.20.2+computecanada)
ERROR: No matching distribution found for numpy==1.20.0+computacanada
Looking in links: /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/nix/avx2, /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/nix/generic, /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/wandb-0.12.5+computecanada-py2.py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/promise-2.3+computecanada-py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/pathtools-0.1.2+computecanada-py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/click-8.0.3+computecanada-py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/PyYAML-5.3.1+computecanada-cp37-cp37m-linux_x86_64.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/psutil-5.7.3+computecanada-cp37-cp37m-linux_x86_64.whl
Requirement already satisfied: python-dateutil>=2.6.1 in /cvmfs/soft.computecanada.ca/easybuild/software/2017/Core/scipy-stack/2019a/lib/python3.7/site-packages (from wandb) (2.7.5)
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/protobuf-3.19.3+computecanada-py2.py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/six-1.16.0+computecanada-py2.py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/shortuuid-1.0.1+computecanada-py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/subprocess32-3.5.4+computecanada-py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/GitPython-3.1.24+computecanada-py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/docker_pycreds-0.4.0+computecanada-py2.py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/yaspin-2.1.0+computecanada-py3-none-any.whl
Requirement already satisfied: requests<3,>=2.0.0 in /cvmfs/soft.computecanada.ca/easybuild/software/2017/Core/scipy-stack/2019a/lib/python3.7/site-packages (from wandb) (2.21.0)
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/sentry_sdk-1.5.0+computecanada-py2.py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/configparser-5.0.2+computecanada-py3-none-any.whl
Requirement already satisfied: importlib-metadata in /cvmfs/soft.computecanada.ca/easybuild/software/2017/Core/scipy-stack/2019a/lib/python3.7/site-packages (from Click!=8.0.0,>=7.0->wandb) (0.8)
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/typing_extensions-4.0.1+computecanada-py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/gitdb-4.0.9+computecanada-py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/smmap-5.0.0+computecanada-py3-none-any.whl
Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /cvmfs/soft.computecanada.ca/easybuild/software/2017/Core/scipy-stack/2019a/lib/python3.7/site-packages (from requests<3,>=2.0.0->wandb) (3.0.4)
Requirement already satisfied: urllib3<1.25,>=1.21.1 in /cvmfs/soft.computecanada.ca/easybuild/software/2017/Core/scipy-stack/2019a/lib/python3.7/site-packages (from requests<3,>=2.0.0->wandb) (1.24.1)
Requirement already satisfied: certifi>=2017.4.17 in /cvmfs/soft.computecanada.ca/easybuild/software/2017/Core/scipy-stack/2019a/lib/python3.7/site-packages (from requests<3,>=2.0.0->wandb) (2018.11.29)
Requirement already satisfied: idna<2.9,>=2.5 in /cvmfs/soft.computecanada.ca/easybuild/software/2017/Core/scipy-stack/2019a/lib/python3.7/site-packages (from requests<3,>=2.0.0->wandb) (2.8)
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/termcolor-1.1.0+computecanada-py3-none-any.whl
Requirement already satisfied: zipp>=0.3.2 in /cvmfs/soft.computecanada.ca/easybuild/software/2017/Core/scipy-stack/2019a/lib/python3.7/site-packages (from importlib-metadata->Click!=8.0.0,>=7.0->wandb) (0.3.3)
Installing collected packages: smmap, typing-extensions, termcolor, six, gitdb, yaspin, subprocess32, shortuuid, sentry-sdk, PyYAML, psutil, protobuf, promise, pathtools, GitPython, docker-pycreds, configparser, Click, wandb
  Attempting uninstall: six
    Found existing installation: six 1.12.0
    Not uninstalling six at /cvmfs/soft.computecanada.ca/easybuild/software/2017/Core/scipy-stack/2019a/lib/python3.7/site-packages, outside environment /localscratch/yinan.28285244.0/env
    Can't uninstall 'six'. No files were found to uninstall.
Successfully installed Click-8.0.3+computecanada GitPython-3.1.24+computecanada PyYAML-5.3.1+computecanada configparser-5.0.2+computecanada docker-pycreds-0.4.0+computecanada gitdb-4.0.9+computecanada pathtools-0.1.2+computecanada promise-2.3+computecanada protobuf-3.19.3+computecanada psutil-5.7.3+computecanada sentry-sdk-1.5.0+computecanada shortuuid-1.0.1+computecanada six-1.16.0+computecanada smmap-5.0.0+computecanada subprocess32-3.5.4+computecanada termcolor-1.1.0+computecanada typing-extensions-4.0.1+computecanada wandb-0.12.5+computecanada yaspin-2.1.0+computecanada
Looking in links: /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/nix/avx2, /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/nix/generic, /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic
ERROR: Could not find a version that satisfies the requirement sagemaker (from versions: none)
ERROR: No matching distribution found for sagemaker
Looking in links: /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/nix/avx2, /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/nix/generic, /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/torch-1.9.1+computecanada-cp37-cp37m-linux_x86_64.whl
Requirement already satisfied: typing-extensions in /localscratch/yinan.28285244.0/env/lib/python3.7/site-packages (from torch) (4.0.1+computecanada)
Installing collected packages: torch
Successfully installed torch-1.9.1+computecanada
Looking in links: /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/nix/avx2, /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/nix/generic, /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/transformers-2.5.1+computecanada-py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/sacremoses-0.0.46+computecanada-py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/tokenizers-0.5.2+computecanada-cp37-cp37m-linux_x86_64.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/sentencepiece-0.1.91+computecanada-cp37-cp37m-linux_x86_64.whl
Requirement already satisfied: numpy in /cvmfs/soft.computecanada.ca/easybuild/software/2017/Core/scipy-stack/2019a/lib/python3.7/site-packages (from transformers==2.5.1+computecanada) (1.16.0)
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/regex-2020.11.13+computecanada-cp37-cp37m-linux_x86_64.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/filelock-3.4.2+computecanada-py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/boto3-1.20.52+computecanada-py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/tqdm-4.63.0+computecanada-py2.py3-none-any.whl
Requirement already satisfied: requests in /cvmfs/soft.computecanada.ca/easybuild/software/2017/Core/scipy-stack/2019a/lib/python3.7/site-packages (from transformers==2.5.1+computecanada) (2.21.0)
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/s3transfer-0.5.1+computecanada-py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/botocore-1.23.52+computecanada-py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/jmespath-0.10.0+computecanada-py2.py3-none-any.whl
Requirement already satisfied: python-dateutil<3.0.0,>=2.1 in /cvmfs/soft.computecanada.ca/easybuild/software/2017/Core/scipy-stack/2019a/lib/python3.7/site-packages (from botocore<1.24.0,>=1.23.52->boto3->transformers==2.5.1+computecanada) (2.7.5)
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/urllib3-1.26.8+computecanada-py2.py3-none-any.whl
Requirement already satisfied: six>=1.5 in /localscratch/yinan.28285244.0/env/lib/python3.7/site-packages (from python-dateutil<3.0.0,>=2.1->botocore<1.24.0,>=1.23.52->boto3->transformers==2.5.1+computecanada) (1.16.0+computecanada)
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/requests-2.27.1+computecanada-py2.py3-none-any.whl
Requirement already satisfied: idna<4,>=2.5 in /cvmfs/soft.computecanada.ca/easybuild/software/2017/Core/scipy-stack/2019a/lib/python3.7/site-packages (from requests->transformers==2.5.1+computecanada) (2.8)
Requirement already satisfied: certifi>=2017.4.17 in /cvmfs/soft.computecanada.ca/easybuild/software/2017/Core/scipy-stack/2019a/lib/python3.7/site-packages (from requests->transformers==2.5.1+computecanada) (2018.11.29)
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/charset_normalizer-2.0.11+computecanada-py3-none-any.whl
Requirement already satisfied: click in /localscratch/yinan.28285244.0/env/lib/python3.7/site-packages (from sacremoses->transformers==2.5.1+computecanada) (8.0.3+computecanada)
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/joblib-1.1.0+computecanada-py2.py3-none-any.whl
Requirement already satisfied: importlib-metadata in /cvmfs/soft.computecanada.ca/easybuild/software/2017/Core/scipy-stack/2019a/lib/python3.7/site-packages (from click->sacremoses->transformers==2.5.1+computecanada) (0.8)
Requirement already satisfied: zipp>=0.3.2 in /cvmfs/soft.computecanada.ca/easybuild/software/2017/Core/scipy-stack/2019a/lib/python3.7/site-packages (from importlib-metadata->click->sacremoses->transformers==2.5.1+computecanada) (0.3.3)
Installing collected packages: urllib3, jmespath, botocore, tqdm, s3transfer, regex, joblib, charset-normalizer, tokenizers, sentencepiece, sacremoses, requests, filelock, boto3, transformers
  Attempting uninstall: urllib3
    Found existing installation: urllib3 1.24.1
    Not uninstalling urllib3 at /cvmfs/soft.computecanada.ca/easybuild/software/2017/Core/scipy-stack/2019a/lib/python3.7/site-packages, outside environment /localscratch/yinan.28285244.0/env
    Can't uninstall 'urllib3'. No files were found to uninstall.
  Attempting uninstall: requests
    Found existing installation: requests 2.21.0
    Not uninstalling requests at /cvmfs/soft.computecanada.ca/easybuild/software/2017/Core/scipy-stack/2019a/lib/python3.7/site-packages, outside environment /localscratch/yinan.28285244.0/env
    Can't uninstall 'requests'. No files were found to uninstall.
Successfully installed boto3-1.20.52+computecanada botocore-1.23.52+computecanada charset-normalizer-2.0.11+computecanada filelock-3.4.2+computecanada jmespath-0.10.0+computecanada joblib-1.1.0+computecanada regex-2020.11.13+computecanada requests-2.27.1+computecanada s3transfer-0.5.1+computecanada sacremoses-0.0.46+computecanada sentencepiece-0.1.91+computecanada tokenizers-0.5.2+computecanada tqdm-4.63.0+computecanada transformers-2.5.1+computecanada urllib3-1.26.8+computecanada
Looking in links: /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/nix/avx2, /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/nix/generic, /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/tensorflow_gpu-2.3.0+computecanada-cp37-cp37m-linux_x86_64.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/nix/avx2/h5py-2.10.0+computecanada-cp37-cp37m-linux_x86_64.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/wrapt-1.11.2+computecanada-cp37-cp37m-linux_x86_64.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/astunparse-1.6.3+computecanada-py2.py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/google_pasta-0.2.0+computecanada-py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/Keras_Preprocessing-1.1.2+computecanada-py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/opt_einsum-3.3.0+computecanada-py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/nix/generic/scipy-1.4.1+computecanada-cp37-cp37m-linux_x86_64.whl
Requirement already satisfied: numpy<1.19.0,>=1.16.0 in /cvmfs/soft.computecanada.ca/easybuild/software/2017/Core/scipy-stack/2019a/lib/python3.7/site-packages (from tensorflow_gpu==2.3.0+computecanada) (1.16.0)
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/absl_py-1.0.0+computecanada-py3-none-any.whl
Requirement already satisfied: protobuf>=3.9.2 in /localscratch/yinan.28285244.0/env/lib/python3.7/site-packages (from tensorflow_gpu==2.3.0+computecanada) (3.19.3+computecanada)
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/tensorboard-2.8.0+computecanada-py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/grpcio-1.38.0+computecanada-cp37-cp37m-linux_x86_64.whl
Requirement already satisfied: six>=1.12.0 in /localscratch/yinan.28285244.0/env/lib/python3.7/site-packages (from tensorflow_gpu==2.3.0+computecanada) (1.16.0+computecanada)
Requirement already satisfied: wheel>=0.26 in /localscratch/yinan.28285244.0/env/lib/python3.7/site-packages (from tensorflow_gpu==2.3.0+computecanada) (0.33.4)
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/gast-0.3.3+computecanada-py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/tensorflow_estimator-2.3.0+computecanada-py2.py3-none-any.whl
Requirement already satisfied: termcolor>=1.1.0 in /localscratch/yinan.28285244.0/env/lib/python3.7/site-packages (from tensorflow_gpu==2.3.0+computecanada) (1.1.0+computecanada)
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/google_auth_oauthlib-0.4.6+computecanada-py2.py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/tensorboard_plugin_wit-1.8.0+computecanada-py3-none-any.whl
Requirement already satisfied: requests<3,>=2.21.0 in /localscratch/yinan.28285244.0/env/lib/python3.7/site-packages (from tensorboard<3,>=2.3.0->tensorflow_gpu==2.3.0+computecanada) (2.27.1+computecanada)
Requirement already satisfied: setuptools>=41.0.0 in /localscratch/yinan.28285244.0/env/lib/python3.7/site-packages (from tensorboard<3,>=2.3.0->tensorflow_gpu==2.3.0+computecanada) (41.0.1)
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/tensorboard_data_server-0.6.1+computecanada-py3-none-linux_x86_64.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/Werkzeug-2.0.3+computecanada-py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/google_auth-2.3.3+computecanada-py2.py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/Markdown-3.3.6+computecanada-py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/cachetools-4.2.4+computecanada-py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/pyasn1_modules-0.2.8+computecanada-py2.py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/rsa-4.8+computecanada-py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/requests_oauthlib-1.3.0+computecanada-py2.py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/importlib_metadata-4.10.1+computecanada-py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/zipp-3.7.0+computecanada-py3-none-any.whl
Requirement already satisfied: typing-extensions>=3.6.4 in /localscratch/yinan.28285244.0/env/lib/python3.7/site-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard<3,>=2.3.0->tensorflow_gpu==2.3.0+computecanada) (4.0.1+computecanada)
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/pyasn1-0.4.8+computecanada-py2.py3-none-any.whl
Requirement already satisfied: urllib3<1.27,>=1.21.1 in /localscratch/yinan.28285244.0/env/lib/python3.7/site-packages (from requests<3,>=2.21.0->tensorboard<3,>=2.3.0->tensorflow_gpu==2.3.0+computecanada) (1.26.8+computecanada)
Requirement already satisfied: certifi>=2017.4.17 in /cvmfs/soft.computecanada.ca/easybuild/software/2017/Core/scipy-stack/2019a/lib/python3.7/site-packages (from requests<3,>=2.21.0->tensorboard<3,>=2.3.0->tensorflow_gpu==2.3.0+computecanada) (2018.11.29)
Requirement already satisfied: idna<4,>=2.5 in /cvmfs/soft.computecanada.ca/easybuild/software/2017/Core/scipy-stack/2019a/lib/python3.7/site-packages (from requests<3,>=2.21.0->tensorboard<3,>=2.3.0->tensorflow_gpu==2.3.0+computecanada) (2.8)
Requirement already satisfied: charset-normalizer~=2.0.0 in /localscratch/yinan.28285244.0/env/lib/python3.7/site-packages (from requests<3,>=2.21.0->tensorboard<3,>=2.3.0->tensorflow_gpu==2.3.0+computecanada) (2.0.11+computecanada)
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/oauthlib-3.1.1+computecanada-py2.py3-none-any.whl
Installing collected packages: pyasn1, zipp, rsa, pyasn1-modules, oauthlib, cachetools, requests-oauthlib, importlib-metadata, google-auth, werkzeug, tensorboard-plugin-wit, tensorboard-data-server, markdown, grpcio, google-auth-oauthlib, absl-py, wrapt, tensorflow-estimator, tensorboard, scipy, opt-einsum, keras-preprocessing, h5py, google-pasta, gast, astunparse, tensorflow-gpu
  Attempting uninstall: pyasn1
    Found existing installation: pyasn1 0.4.3
    Not uninstalling pyasn1 at /cvmfs/soft.computecanada.ca/easybuild/software/2017/Core/scipy-stack/2019a/lib/python3.7/site-packages, outside environment /localscratch/yinan.28285244.0/env
    Can't uninstall 'pyasn1'. No files were found to uninstall.
  Attempting uninstall: zipp
    Found existing installation: zipp 0.3.3
    Not uninstalling zipp at /cvmfs/soft.computecanada.ca/easybuild/software/2017/Core/scipy-stack/2019a/lib/python3.7/site-packages, outside environment /localscratch/yinan.28285244.0/env
    Can't uninstall 'zipp'. No files were found to uninstall.
  Attempting uninstall: importlib-metadata
    Found existing installation: importlib-metadata 0.8
    Not uninstalling importlib-metadata at /cvmfs/soft.computecanada.ca/easybuild/software/2017/Core/scipy-stack/2019a/lib/python3.7/site-packages, outside environment /localscratch/yinan.28285244.0/env
    Can't uninstall 'importlib-metadata'. No files were found to uninstall.
  Attempting uninstall: scipy
    Found existing installation: scipy 1.2.0
    Not uninstalling scipy at /cvmfs/soft.computecanada.ca/easybuild/software/2017/Core/scipy-stack/2019a/lib/python3.7/site-packages, outside environment /localscratch/yinan.28285244.0/env
    Can't uninstall 'scipy'. No files were found to uninstall.
Successfully installed absl-py-1.0.0+computecanada astunparse-1.6.3+computecanada cachetools-4.2.4+computecanada gast-0.3.3+computecanada google-auth-2.3.3+computecanada google-auth-oauthlib-0.4.6+computecanada google-pasta-0.2.0+computecanada grpcio-1.38.0+computecanada h5py-2.10.0+computecanada importlib-metadata-4.10.1+computecanada keras-preprocessing-1.1.2+computecanada markdown-3.3.6+computecanada oauthlib-3.1.1+computecanada opt-einsum-3.3.0+computecanada pyasn1-0.4.8+computecanada pyasn1-modules-0.2.8+computecanada requests-oauthlib-1.3.0+computecanada rsa-4.8+computecanada scipy-1.4.1+computecanada tensorboard-2.8.0+computecanada tensorboard-data-server-0.6.1+computecanada tensorboard-plugin-wit-1.8.0+computecanada tensorflow-estimator-2.3.0+computecanada tensorflow-gpu-2.3.0+computecanada werkzeug-2.0.3+computecanada wrapt-1.11.2+computecanada zipp-3.7.0+computecanada
Looking in links: /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/nix/avx2, /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/nix/generic, /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/keras-2.8.0+computecanada-py2.py3-none-any.whl
Installing collected packages: Keras
Successfully installed Keras-2.8.0+computecanada
Looking in links: /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/nix/avx2, /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/nix/generic, /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/urllib3-1.26.7+computecanada-py2.py3-none-any.whl
Installing collected packages: urllib3
  Attempting uninstall: urllib3
    Found existing installation: urllib3 1.26.8+computecanada
    Uninstalling urllib3-1.26.8+computecanada:
      Successfully uninstalled urllib3-1.26.8+computecanada
Successfully installed urllib3-1.26.7+computecanada
Looking in links: /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/nix/avx2, /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/nix/generic, /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/nltk-3.7+computecanada-py3-none-any.whl
Requirement already satisfied: click in /localscratch/yinan.28285244.0/env/lib/python3.7/site-packages (from nltk) (8.0.3+computecanada)
Requirement already satisfied: joblib in /localscratch/yinan.28285244.0/env/lib/python3.7/site-packages (from nltk) (1.1.0+computecanada)
Requirement already satisfied: tqdm in /localscratch/yinan.28285244.0/env/lib/python3.7/site-packages (from nltk) (4.63.0+computecanada)
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/nltk-3.6.5+computecanada-py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/nltk-3.6.3+computecanada-py3-none-any.whl
Requirement already satisfied: regex in /localscratch/yinan.28285244.0/env/lib/python3.7/site-packages (from nltk) (2020.11.13+computecanada)
Requirement already satisfied: importlib-metadata in /localscratch/yinan.28285244.0/env/lib/python3.7/site-packages (from click->nltk) (4.10.1+computecanada)
Requirement already satisfied: zipp>=0.5 in /localscratch/yinan.28285244.0/env/lib/python3.7/site-packages (from importlib-metadata->click->nltk) (3.7.0+computecanada)
Requirement already satisfied: typing-extensions>=3.6.4 in /localscratch/yinan.28285244.0/env/lib/python3.7/site-packages (from importlib-metadata->click->nltk) (4.0.1+computecanada)
Installing collected packages: nltk
Successfully installed nltk-3.6.3+computecanada
Looking in links: /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/nix/avx2, /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/nix/generic, /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/scikit_learn-0.22.1+computecanada-cp37-cp37m-linux_x86_64.whl
Requirement already satisfied: numpy>=1.11.0 in /cvmfs/soft.computecanada.ca/easybuild/software/2017/Core/scipy-stack/2019a/lib/python3.7/site-packages (from scikit-learn==0.22.1) (1.16.0)
Requirement already satisfied: scipy>=0.17.0 in /localscratch/yinan.28285244.0/env/lib/python3.7/site-packages (from scikit-learn==0.22.1) (1.4.1+computecanada)
Requirement already satisfied: joblib>=0.11 in /localscratch/yinan.28285244.0/env/lib/python3.7/site-packages (from scikit-learn==0.22.1) (1.1.0+computecanada)
Installing collected packages: scikit-learn
Successfully installed scikit-learn-0.22.1+computecanada
Looking in links: /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/nix/avx2, /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/nix/generic, /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic
Requirement already satisfied: tokenizers==0.5.2 in /localscratch/yinan.28285244.0/env/lib/python3.7/site-packages (0.5.2+computecanada)
wandb: Appending key for api.wandb.ai to your netrc file: /home/yinan/.netrc
Starting Task
2022-03-05 06:37:24.644359: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1
[nltk_data] Downloading package stopwords to /home/yinan/nltk_data...
[nltk_data]   Package stopwords is already up-to-date!
[nltk_data] Downloading package wordnet to /home/yinan/nltk_data...
[nltk_data]   Package wordnet is already up-to-date!
wandb: Currently logged in as: yinanazhou (use `wandb login --relogin` to force relogin)
wandb: wandb version 0.12.11 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
2022-03-05 06:37:37.630404: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1
wandb: Tracking run with wandb version 0.12.5
wandb: Syncing run silver-planet-1
wandb: ⭐️ View project at https://wandb.ai/yinanazhou/xl_512_bs_8_lr_1e06_es_20_lc_False_nr_False_stem_False_lemma_True_repeat_1_fold_1
wandb: 🚀 View run at https://wandb.ai/yinanazhou/xl_512_bs_8_lr_1e06_es_20_lc_False_nr_False_stem_False_lemma_True_repeat_1_fold_1/runs/30wfcius
wandb: Run data is saved locally in /project/6002780/yinan/Thesis_MER_Lyrics/lyric-emotion/wandb/run-20220305_063735-30wfcius
wandb: Run `wandb offline` to turn off syncing.

Validation loss decreased (inf --> 1.372028).  Saving model ...
Validation loss decreased (1.372028 --> 1.331746).  Saving model ...
Validation loss decreased (1.331746 --> 1.296138).  Saving model ...
Validation loss decreased (1.296138 --> 1.264129).  Saving model ...
Validation loss decreased (1.264129 --> 1.228090).  Saving model ...
Validation loss decreased (1.228090 --> 1.200422).  Saving model ...
Validation loss decreased (1.200422 --> 1.168643).  Saving model ...
Validation loss decreased (1.168643 --> 1.141614).  Saving model ...
Validation loss decreased (1.141614 --> 1.120796).  Saving model ...
Validation loss decreased (1.120796 --> 1.089751).  Saving model ...
Validation loss decreased (1.089751 --> 1.064941).  Saving model ...
Validation loss decreased (1.064941 --> 1.036064).  Saving model ...
Validation loss decreased (1.036064 --> 1.029420).  Saving model ...
Validation loss decreased (1.029420 --> 1.020862).  Saving model ...
Validation loss decreased (1.020862 --> 0.996920).  Saving model ...
Validation loss decreased (0.996920 --> 0.995684).  Saving model ...
Validation loss decreased (0.995684 --> 0.986227).  Saving model ...
Validation loss decreased (0.986227 --> 0.975694).  Saving model ...
Validation loss decreased (0.975694 --> 0.975142).  Saving model ...
Validation loss decreased (0.975142 --> 0.965283).  Saving model ...
EarlyStopping counter: 1 out of 20.0
EarlyStopping counter: 2 out of 20.0
Validation loss decreased (0.965283 --> 0.962835).  Saving model ...
Validation loss decreased (0.962835 --> 0.958667).  Saving model ...
Validation loss decreased (0.958667 --> 0.957542).  Saving model ...
EarlyStopping counter: 1 out of 20.0
EarlyStopping counter: 2 out of 20.0
EarlyStopping counter: 3 out of 20.0
EarlyStopping counter: 4 out of 20.0
EarlyStopping counter: 5 out of 20.0
EarlyStopping counter: 6 out of 20.0
EarlyStopping counter: 7 out of 20.0
EarlyStopping counter: 8 out of 20.0
EarlyStopping counter: 9 out of 20.0
EarlyStopping counter: 10 out of 20.0
EarlyStopping counter: 11 out of 20.0
EarlyStopping counter: 12 out of 20.0
EarlyStopping counter: 13 out of 20.0
EarlyStopping counter: 14 out of 20.0
EarlyStopping counter: 15 out of 20.0
EarlyStopping counter: 16 out of 20.0
EarlyStopping counter: 17 out of 20.0
EarlyStopping counter: 18 out of 20.0
EarlyStopping counter: 19 out of 20.0
EarlyStopping counter: 20 out of 20.0
/localscratch/yinan.28285244.0/env/lib/python3.7/site-packages/torch/nn/functional.py:1794: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.
  warnings.warn("nn.functional.tanh is deprecated. Use torch.tanh instead.")
/localscratch/yinan.28285244.0/env/lib/python3.7/site-packages/transformers/optimization.py:155: UserWarning: This overload of add_ is deprecated:
	add_(Number alpha, Tensor other)
Consider using one of the following signatures instead:
	add_(Tensor other, *, Number alpha) (Triggered internally at  ../torch/csrc/utils/python_arg_parser.cpp:1025.)
  exp_avg.mul_(beta1).add_(1.0 - beta1, grad)
wandb: Waiting for W&B process to finish, PID 207657... (success).
wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: \ 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: | 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: / 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: \ 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: | 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: / 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: \ 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: | 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: / 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb:                                                                                
wandb: Run history:
wandb:     e_F1 ▁▄▄▅▅▆▅▆▆▇▇▇▇█▇▇█▇▇▇████████████████████
wandb:   e_loss █▇▇▆▆▅▅▄▃▃▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▂▂▁▁▂▂▂▂▂▂▂▂▃
wandb:     t_F1 ▁▂▂▃▃▄▄▄▅▅▅▅▆▆▆▆▆▆▆▇▆▇▇▇▇▇▇▇▇▇▇▇▇███████
wandb:   t_loss ██▇▇▇▇▆▆▆▅▅▅▅▄▄▄▄▃▃▃▃▃▃▃▃▂▂▂▂▂▂▂▂▁▂▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:     e_F1 60.26121
wandb:   e_loss 1.05705
wandb:     t_F1 91.11795
wandb:   t_loss 0.31991
wandb: 
wandb: Synced 4 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Synced silver-planet-1: https://wandb.ai/yinanazhou/xl_512_bs_8_lr_1e06_es_20_lc_False_nr_False_stem_False_lemma_True_repeat_1_fold_1/runs/30wfcius
wandb: Find logs at: ./wandb/run-20220305_063735-30wfcius/logs/debug.log
wandb: 

wandb: wandb version 0.12.11 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
2022-03-05 07:20:33.728052: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1
wandb: Tracking run with wandb version 0.12.5
wandb: Syncing run woven-eon-1
wandb: ⭐️ View project at https://wandb.ai/yinanazhou/xl_512_bs_8_lr_1e06_es_20_lc_False_nr_False_stem_False_lemma_True_repeat_1_fold_2
wandb: 🚀 View run at https://wandb.ai/yinanazhou/xl_512_bs_8_lr_1e06_es_20_lc_False_nr_False_stem_False_lemma_True_repeat_1_fold_2/runs/fu71qw0o
wandb: Run data is saved locally in /project/6002780/yinan/Thesis_MER_Lyrics/lyric-emotion/wandb/run-20220305_072030-fu71qw0o
wandb: Run `wandb offline` to turn off syncing.

Validation loss decreased (inf --> 1.391072).  Saving model ...
Validation loss decreased (1.391072 --> 1.361631).  Saving model ...
Validation loss decreased (1.361631 --> 1.337592).  Saving model ...
Validation loss decreased (1.337592 --> 1.310678).  Saving model ...
Validation loss decreased (1.310678 --> 1.282433).  Saving model ...
Validation loss decreased (1.282433 --> 1.253844).  Saving model ...
Validation loss decreased (1.253844 --> 1.221813).  Saving model ...
Validation loss decreased (1.221813 --> 1.190175).  Saving model ...
Validation loss decreased (1.190175 --> 1.155924).  Saving model ...
Validation loss decreased (1.155924 --> 1.121924).  Saving model ...
Validation loss decreased (1.121924 --> 1.090168).  Saving model ...
Validation loss decreased (1.090168 --> 1.060758).  Saving model ...
Validation loss decreased (1.060758 --> 1.036515).  Saving model ...
Validation loss decreased (1.036515 --> 1.013391).  Saving model ...
Validation loss decreased (1.013391 --> 0.994302).  Saving model ...
Validation loss decreased (0.994302 --> 0.982267).  Saving model ...
Validation loss decreased (0.982267 --> 0.965620).  Saving model ...
Validation loss decreased (0.965620 --> 0.953877).  Saving model ...
Validation loss decreased (0.953877 --> 0.945805).  Saving model ...
Validation loss decreased (0.945805 --> 0.940139).  Saving model ...
Validation loss decreased (0.940139 --> 0.936020).  Saving model ...
Validation loss decreased (0.936020 --> 0.930812).  Saving model ...
Validation loss decreased (0.930812 --> 0.926020).  Saving model ...
Validation loss decreased (0.926020 --> 0.923004).  Saving model ...
Validation loss decreased (0.923004 --> 0.921366).  Saving model ...
Validation loss decreased (0.921366 --> 0.919519).  Saving model ...
EarlyStopping counter: 1 out of 20.0
EarlyStopping counter: 2 out of 20.0
EarlyStopping counter: 3 out of 20.0
EarlyStopping counter: 4 out of 20.0
EarlyStopping counter: 5 out of 20.0
EarlyStopping counter: 6 out of 20.0
EarlyStopping counter: 7 out of 20.0
EarlyStopping counter: 8 out of 20.0
EarlyStopping counter: 9 out of 20.0
EarlyStopping counter: 10 out of 20.0
EarlyStopping counter: 11 out of 20.0
EarlyStopping counter: 12 out of 20.0
EarlyStopping counter: 13 out of 20.0
EarlyStopping counter: 14 out of 20.0
EarlyStopping counter: 15 out of 20.0
EarlyStopping counter: 16 out of 20.0
EarlyStopping counter: 17 out of 20.0
EarlyStopping counter: 18 out of 20.0
EarlyStopping counter: 19 out of 20.0
EarlyStopping counter: 20 out of 20.0
/localscratch/yinan.28285244.0/env/lib/python3.7/site-packages/torch/nn/functional.py:1794: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.
  warnings.warn("nn.functional.tanh is deprecated. Use torch.tanh instead.")
wandb: Waiting for W&B process to finish, PID 209989... (success).
wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: \ 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: | 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: / 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb:                                                                                
wandb: Run history:
wandb:     e_F1 ▁▂▄▄▅▅▆▆▇▇▇▇▇▇██████████████████████████
wandb:   e_loss ██▇▇▆▆▅▅▄▄▃▃▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▂▂▂▂▂▂▂▂▃▃▃
wandb:     t_F1 ▁▂▂▂▃▃▃▄▄▄▅▅▅▅▅▆▅▆▆▆▆▆▆▆▇▇▇▇▇▇▇▇▇██▇████
wandb:   t_loss █▇▇▇▇▇▇▆▆▆▆▅▅▅▅▄▄▄▄▄▃▃▃▃▃▃▃▃▂▂▂▂▂▂▂▂▁▁▁▁
wandb: 
wandb: Run summary:
wandb:     e_F1 62.18745
wandb:   e_loss 1.05092
wandb:     t_F1 93.20998
wandb:   t_loss 0.29513
wandb: 
wandb: Synced 4 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Synced woven-eon-1: https://wandb.ai/yinanazhou/xl_512_bs_8_lr_1e06_es_20_lc_False_nr_False_stem_False_lemma_True_repeat_1_fold_2/runs/fu71qw0o
wandb: Find logs at: ./wandb/run-20220305_072030-fu71qw0o/logs/debug.log
wandb: 

wandb: wandb version 0.12.11 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
2022-03-05 08:04:26.107537: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1
wandb: Tracking run with wandb version 0.12.5
wandb: Syncing run sparkling-donkey-1
wandb: ⭐️ View project at https://wandb.ai/yinanazhou/xl_512_bs_8_lr_1e06_es_20_lc_False_nr_False_stem_False_lemma_True_repeat_2_fold_1
wandb: 🚀 View run at https://wandb.ai/yinanazhou/xl_512_bs_8_lr_1e06_es_20_lc_False_nr_False_stem_False_lemma_True_repeat_2_fold_1/runs/1fmuaa60
wandb: Run data is saved locally in /project/6002780/yinan/Thesis_MER_Lyrics/lyric-emotion/wandb/run-20220305_080422-1fmuaa60
wandb: Run `wandb offline` to turn off syncing.

Validation loss decreased (inf --> 1.349679).  Saving model ...
Validation loss decreased (1.349679 --> 1.323569).  Saving model ...
Validation loss decreased (1.323569 --> 1.297866).  Saving model ...
Validation loss decreased (1.297866 --> 1.265588).  Saving model ...
Validation loss decreased (1.265588 --> 1.234131).  Saving model ...
Validation loss decreased (1.234131 --> 1.195903).  Saving model ...
Validation loss decreased (1.195903 --> 1.147208).  Saving model ...
Validation loss decreased (1.147208 --> 1.106021).  Saving model ...
Validation loss decreased (1.106021 --> 1.067021).  Saving model ...
Validation loss decreased (1.067021 --> 1.035272).  Saving model ...
Validation loss decreased (1.035272 --> 1.015073).  Saving model ...
Validation loss decreased (1.015073 --> 0.996862).  Saving model ...
Validation loss decreased (0.996862 --> 0.979617).  Saving model ...
Validation loss decreased (0.979617 --> 0.961472).  Saving model ...
Validation loss decreased (0.961472 --> 0.956963).  Saving model ...
Validation loss decreased (0.956963 --> 0.948845).  Saving model ...
Validation loss decreased (0.948845 --> 0.940977).  Saving model ...
Validation loss decreased (0.940977 --> 0.935180).  Saving model ...
Validation loss decreased (0.935180 --> 0.930424).  Saving model ...
Validation loss decreased (0.930424 --> 0.915570).  Saving model ...
EarlyStopping counter: 1 out of 20.0
EarlyStopping counter: 2 out of 20.0
EarlyStopping counter: 3 out of 20.0
EarlyStopping counter: 4 out of 20.0
EarlyStopping counter: 5 out of 20.0
EarlyStopping counter: 6 out of 20.0
EarlyStopping counter: 7 out of 20.0
EarlyStopping counter: 8 out of 20.0
EarlyStopping counter: 9 out of 20.0
EarlyStopping counter: 10 out of 20.0
EarlyStopping counter: 11 out of 20.0
EarlyStopping counter: 12 out of 20.0
EarlyStopping counter: 13 out of 20.0
EarlyStopping counter: 14 out of 20.0
EarlyStopping counter: 15 out of 20.0
EarlyStopping counter: 16 out of 20.0
EarlyStopping counter: 17 out of 20.0
EarlyStopping counter: 18 out of 20.0
EarlyStopping counter: 19 out of 20.0
EarlyStopping counter: 20 out of 20.0
/localscratch/yinan.28285244.0/env/lib/python3.7/site-packages/torch/nn/functional.py:1794: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.
  warnings.warn("nn.functional.tanh is deprecated. Use torch.tanh instead.")
wandb: Waiting for W&B process to finish, PID 212341... (success).
wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: \ 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: | 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: / 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: \ 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: | 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: / 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: \ 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: | 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: / 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb:                                                                                
wandb: Run history:
wandb:     e_F1 ▁▃▄▄▅▆▇▇▇▇██▇█▇██████████▇██████████████
wandb:   e_loss ██▇▇▆▆▅▄▃▃▃▂▂▂▂▂▁▁▁▁▁▁▁▁▁▂▁▁▂▂▂▂▂▂▂▂▃▃▃▃
wandb:     t_F1 ▁▂▂▃▃▃▄▄▄▅▅▅▅▆▆▆▆▆▆▆▇▇▇▆▇▇▇▇▇▇▇▇████████
wandb:   t_loss ███▇▇▇▇▆▆▆▆▅▅▅▅▄▄▄▄▄▃▃▃▃▃▃▃▃▂▂▂▂▂▂▂▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:     e_F1 61.93037
wandb:   e_loss 1.05699
wandb:     t_F1 91.68361
wandb:   t_loss 0.31195
wandb: 
wandb: Synced 4 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Synced sparkling-donkey-1: https://wandb.ai/yinanazhou/xl_512_bs_8_lr_1e06_es_20_lc_False_nr_False_stem_False_lemma_True_repeat_2_fold_1/runs/1fmuaa60
wandb: Find logs at: ./wandb/run-20220305_080422-1fmuaa60/logs/debug.log
wandb: 

wandb: wandb version 0.12.11 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
2022-03-05 08:42:23.540875: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1
wandb: Tracking run with wandb version 0.12.5
wandb: Syncing run leafy-pond-1
wandb: ⭐️ View project at https://wandb.ai/yinanazhou/xl_512_bs_8_lr_1e06_es_20_lc_False_nr_False_stem_False_lemma_True_repeat_2_fold_2
wandb: 🚀 View run at https://wandb.ai/yinanazhou/xl_512_bs_8_lr_1e06_es_20_lc_False_nr_False_stem_False_lemma_True_repeat_2_fold_2/runs/22b46g6f
wandb: Run data is saved locally in /project/6002780/yinan/Thesis_MER_Lyrics/lyric-emotion/wandb/run-20220305_084220-22b46g6f
wandb: Run `wandb offline` to turn off syncing.

Validation loss decreased (inf --> 1.389533).  Saving model ...
Validation loss decreased (1.389533 --> 1.348181).  Saving model ...
Validation loss decreased (1.348181 --> 1.323812).  Saving model ...
Validation loss decreased (1.323812 --> 1.298286).  Saving model ...
Validation loss decreased (1.298286 --> 1.266538).  Saving model ...
Validation loss decreased (1.266538 --> 1.227575).  Saving model ...
Validation loss decreased (1.227575 --> 1.189133).  Saving model ...
Validation loss decreased (1.189133 --> 1.147983).  Saving model ...
Validation loss decreased (1.147983 --> 1.119371).  Saving model ...
Validation loss decreased (1.119371 --> 1.077405).  Saving model ...
Validation loss decreased (1.077405 --> 1.054891).  Saving model ...
Validation loss decreased (1.054891 --> 1.020842).  Saving model ...
Validation loss decreased (1.020842 --> 1.006520).  Saving model ...
Validation loss decreased (1.006520 --> 0.977700).  Saving model ...
Validation loss decreased (0.977700 --> 0.955147).  Saving model ...
Validation loss decreased (0.955147 --> 0.941613).  Saving model ...
Validation loss decreased (0.941613 --> 0.932968).  Saving model ...
Validation loss decreased (0.932968 --> 0.930722).  Saving model ...
Validation loss decreased (0.930722 --> 0.921688).  Saving model ...
Validation loss decreased (0.921688 --> 0.906226).  Saving model ...
Validation loss decreased (0.906226 --> 0.904422).  Saving model ...
Validation loss decreased (0.904422 --> 0.901773).  Saving model ...
Validation loss decreased (0.901773 --> 0.897219).  Saving model ...
EarlyStopping counter: 1 out of 20.0
EarlyStopping counter: 2 out of 20.0
EarlyStopping counter: 3 out of 20.0
EarlyStopping counter: 4 out of 20.0
EarlyStopping counter: 5 out of 20.0
EarlyStopping counter: 6 out of 20.0
EarlyStopping counter: 7 out of 20.0
EarlyStopping counter: 8 out of 20.0
EarlyStopping counter: 9 out of 20.0
EarlyStopping counter: 10 out of 20.0
EarlyStopping counter: 11 out of 20.0
EarlyStopping counter: 12 out of 20.0
EarlyStopping counter: 13 out of 20.0
EarlyStopping counter: 14 out of 20.0
EarlyStopping counter: 15 out of 20.0
EarlyStopping counter: 16 out of 20.0
EarlyStopping counter: 17 out of 20.0
EarlyStopping counter: 18 out of 20.0
EarlyStopping counter: 19 out of 20.0
EarlyStopping counter: 20 out of 20.0
/localscratch/yinan.28285244.0/env/lib/python3.7/site-packages/torch/nn/functional.py:1794: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.
  warnings.warn("nn.functional.tanh is deprecated. Use torch.tanh instead.")
wandb: Waiting for W&B process to finish, PID 214412... (success).
wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: \ 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: | 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: / 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: \ 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: | 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: / 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: \ 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: | 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: / 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb:                                                                                
wandb: Run history:
wandb:     e_F1 ▁▂▃▄▄▅▆▅▆▆▆▇▇█▇███████████████████▇█▇███
wandb:   e_loss █▇▇▇▆▆▅▅▄▄▃▃▃▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▂▂▂▂▂▃▃▃▃▃▃
wandb:     t_F1 ▁▁▂▂▃▃▄▄▄▄▅▅▅▅▅▆▆▆▆▆▆▇▆▇▇▇▇▇▇▇██████████
wandb:   t_loss ███▇▇▇▇▆▆▆▆▅▅▅▄▄▄▄▄▄▃▃▃▃▃▃▂▂▂▂▂▂▂▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:     e_F1 59.86002
wandb:   e_loss 1.0563
wandb:     t_F1 93.87173
wandb:   t_loss 0.25019
wandb: 
wandb: Synced 4 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Synced leafy-pond-1: https://wandb.ai/yinanazhou/xl_512_bs_8_lr_1e06_es_20_lc_False_nr_False_stem_False_lemma_True_repeat_2_fold_2/runs/22b46g6f
wandb: Find logs at: ./wandb/run-20220305_084220-22b46g6f/logs/debug.log
wandb: 

wandb: wandb version 0.12.11 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
2022-03-05 09:22:55.404580: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1
wandb: Tracking run with wandb version 0.12.5
wandb: Syncing run crimson-terrain-1
wandb: ⭐️ View project at https://wandb.ai/yinanazhou/xl_512_bs_8_lr_1e06_es_20_lc_False_nr_False_stem_False_lemma_True_repeat_3_fold_1
wandb: 🚀 View run at https://wandb.ai/yinanazhou/xl_512_bs_8_lr_1e06_es_20_lc_False_nr_False_stem_False_lemma_True_repeat_3_fold_1/runs/50sjttux
wandb: Run data is saved locally in /project/6002780/yinan/Thesis_MER_Lyrics/lyric-emotion/wandb/run-20220305_092252-50sjttux
wandb: Run `wandb offline` to turn off syncing.

Validation loss decreased (inf --> 1.390572).  Saving model ...
Validation loss decreased (1.390572 --> 1.350992).  Saving model ...
Validation loss decreased (1.350992 --> 1.319483).  Saving model ...
Validation loss decreased (1.319483 --> 1.291244).  Saving model ...
Validation loss decreased (1.291244 --> 1.255201).  Saving model ...
Validation loss decreased (1.255201 --> 1.215782).  Saving model ...
Validation loss decreased (1.215782 --> 1.188320).  Saving model ...
Validation loss decreased (1.188320 --> 1.158114).  Saving model ...
Validation loss decreased (1.158114 --> 1.125201).  Saving model ...
Validation loss decreased (1.125201 --> 1.114135).  Saving model ...
Validation loss decreased (1.114135 --> 1.072012).  Saving model ...
Validation loss decreased (1.072012 --> 1.049567).  Saving model ...
Validation loss decreased (1.049567 --> 1.038268).  Saving model ...
Validation loss decreased (1.038268 --> 1.015319).  Saving model ...
Validation loss decreased (1.015319 --> 0.998182).  Saving model ...
Validation loss decreased (0.998182 --> 0.981980).  Saving model ...
Validation loss decreased (0.981980 --> 0.970466).  Saving model ...
Validation loss decreased (0.970466 --> 0.969715).  Saving model ...
Validation loss decreased (0.969715 --> 0.948783).  Saving model ...
Validation loss decreased (0.948783 --> 0.939629).  Saving model ...
Validation loss decreased (0.939629 --> 0.936680).  Saving model ...
Validation loss decreased (0.936680 --> 0.933337).  Saving model ...
Validation loss decreased (0.933337 --> 0.932198).  Saving model ...
Validation loss decreased (0.932198 --> 0.927812).  Saving model ...
Validation loss decreased (0.927812 --> 0.923079).  Saving model ...
EarlyStopping counter: 1 out of 20.0
Validation loss decreased (0.923079 --> 0.922532).  Saving model ...
EarlyStopping counter: 1 out of 20.0
EarlyStopping counter: 2 out of 20.0
EarlyStopping counter: 3 out of 20.0
EarlyStopping counter: 4 out of 20.0
EarlyStopping counter: 5 out of 20.0
EarlyStopping counter: 6 out of 20.0
EarlyStopping counter: 7 out of 20.0
EarlyStopping counter: 8 out of 20.0
EarlyStopping counter: 9 out of 20.0
EarlyStopping counter: 10 out of 20.0
EarlyStopping counter: 11 out of 20.0
EarlyStopping counter: 12 out of 20.0
EarlyStopping counter: 13 out of 20.0
EarlyStopping counter: 14 out of 20.0
EarlyStopping counter: 15 out of 20.0
EarlyStopping counter: 16 out of 20.0
EarlyStopping counter: 17 out of 20.0
EarlyStopping counter: 18 out of 20.0
EarlyStopping counter: 19 out of 20.0
EarlyStopping counter: 20 out of 20.0
/localscratch/yinan.28285244.0/env/lib/python3.7/site-packages/torch/nn/functional.py:1794: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.
  warnings.warn("nn.functional.tanh is deprecated. Use torch.tanh instead.")
wandb: Waiting for W&B process to finish, PID 216609... (success).
wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: \ 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: | 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: / 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb:                                                                                
wandb: Run history:
wandb:     e_F1 ▁▂▃▄▄▄▅▅▆▆▆▇▇▇▇█▇▇▇▇▇▇██████████████████
wandb:   e_loss █▇▇▇▆▅▅▄▄▃▃▃▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▂▂▂▂▂▂▂▂▂▃
wandb:     t_F1 ▁▁▃▃▃▃▄▄▅▄▅▅▅▅▆▆▆▆▆▆▇▇▇▇▇▇▇▇▇▇▇▇█▇██████
wandb:   t_loss ██▇▇▇▇▆▆▆▆▅▅▅▅▄▄▄▄▄▃▃▃▃▃▃▃▃▃▂▂▂▂▂▂▂▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:     e_F1 62.96856
wandb:   e_loss 1.02544
wandb:     t_F1 92.35683
wandb:   t_loss 0.30807
wandb: 
wandb: Synced 4 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Synced crimson-terrain-1: https://wandb.ai/yinanazhou/xl_512_bs_8_lr_1e06_es_20_lc_False_nr_False_stem_False_lemma_True_repeat_3_fold_1/runs/50sjttux
wandb: Find logs at: ./wandb/run-20220305_092252-50sjttux/logs/debug.log
wandb: 

wandb: wandb version 0.12.11 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
2022-03-05 10:07:29.527310: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1
wandb: Tracking run with wandb version 0.12.5
wandb: Syncing run confused-night-1
wandb: ⭐️ View project at https://wandb.ai/yinanazhou/xl_512_bs_8_lr_1e06_es_20_lc_False_nr_False_stem_False_lemma_True_repeat_3_fold_2
wandb: 🚀 View run at https://wandb.ai/yinanazhou/xl_512_bs_8_lr_1e06_es_20_lc_False_nr_False_stem_False_lemma_True_repeat_3_fold_2/runs/yq7tnk6e
wandb: Run data is saved locally in /project/6002780/yinan/Thesis_MER_Lyrics/lyric-emotion/wandb/run-20220305_100726-yq7tnk6e
wandb: Run `wandb offline` to turn off syncing.

Validation loss decreased (inf --> 1.364862).  Saving model ...
Validation loss decreased (1.364862 --> 1.338743).  Saving model ...
Validation loss decreased (1.338743 --> 1.318784).  Saving model ...
Validation loss decreased (1.318784 --> 1.290529).  Saving model ...
Validation loss decreased (1.290529 --> 1.259818).  Saving model ...
Validation loss decreased (1.259818 --> 1.216534).  Saving model ...
Validation loss decreased (1.216534 --> 1.169447).  Saving model ...
Validation loss decreased (1.169447 --> 1.129931).  Saving model ...
Validation loss decreased (1.129931 --> 1.084324).  Saving model ...
Validation loss decreased (1.084324 --> 1.055567).  Saving model ...
Validation loss decreased (1.055567 --> 1.016957).  Saving model ...
Validation loss decreased (1.016957 --> 0.994654).  Saving model ...
Validation loss decreased (0.994654 --> 0.979860).  Saving model ...
Validation loss decreased (0.979860 --> 0.959961).  Saving model ...
Validation loss decreased (0.959961 --> 0.943693).  Saving model ...
Validation loss decreased (0.943693 --> 0.934233).  Saving model ...
Validation loss decreased (0.934233 --> 0.922221).  Saving model ...
Validation loss decreased (0.922221 --> 0.918966).  Saving model ...
Validation loss decreased (0.918966 --> 0.915085).  Saving model ...
Validation loss decreased (0.915085 --> 0.914148).  Saving model ...
Validation loss decreased (0.914148 --> 0.913291).  Saving model ...
Validation loss decreased (0.913291 --> 0.905564).  Saving model ...
EarlyStopping counter: 1 out of 20.0
EarlyStopping counter: 2 out of 20.0
Validation loss decreased (0.905564 --> 0.905440).  Saving model ...
EarlyStopping counter: 1 out of 20.0
EarlyStopping counter: 2 out of 20.0
EarlyStopping counter: 3 out of 20.0
EarlyStopping counter: 4 out of 20.0
EarlyStopping counter: 5 out of 20.0
EarlyStopping counter: 6 out of 20.0
EarlyStopping counter: 7 out of 20.0
EarlyStopping counter: 8 out of 20.0
EarlyStopping counter: 9 out of 20.0
EarlyStopping counter: 10 out of 20.0
EarlyStopping counter: 11 out of 20.0
EarlyStopping counter: 12 out of 20.0
EarlyStopping counter: 13 out of 20.0
EarlyStopping counter: 14 out of 20.0
EarlyStopping counter: 15 out of 20.0
EarlyStopping counter: 16 out of 20.0
EarlyStopping counter: 17 out of 20.0
EarlyStopping counter: 18 out of 20.0
EarlyStopping counter: 19 out of 20.0
EarlyStopping counter: 20 out of 20.0
/localscratch/yinan.28285244.0/env/lib/python3.7/site-packages/torch/nn/functional.py:1794: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.
  warnings.warn("nn.functional.tanh is deprecated. Use torch.tanh instead.")
wandb: Waiting for W&B process to finish, PID 219036... (success).
wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: \ 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: | 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: / 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: \ 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: | 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: / 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: \ 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: | 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: / 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: \ 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb:                                                                                
wandb: Run history:
wandb:     e_F1 ▁▃▅▄▅▆▇▇▇▇▇▇▇█▇█▇█▇▇██████████████████▇█
wandb:   e_loss ██▇▇▆▆▅▄▃▃▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▂▂▂▂▂▂▃▃▃▃
wandb:     t_F1 ▁▂▂▂▃▃▄▄▄▄▅▅▅▅▅▆▆▆▆▆▆▆▆▆▇▇▇▇▇▇▇▇▇▇██████
wandb:   t_loss ███▇▇▇▇▇▆▆▅▅▅▅▅▄▄▄▄▄▃▃▃▃▃▃▃▃▂▂▂▂▂▂▂▂▁▁▁▁
wandb: 
wandb: Run summary:
wandb:     e_F1 61.44706
wandb:   e_loss 1.04742
wandb:     t_F1 94.44993
wandb:   t_loss 0.25067
wandb: 
wandb: Synced 4 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Synced confused-night-1: https://wandb.ai/yinanazhou/xl_512_bs_8_lr_1e06_es_20_lc_False_nr_False_stem_False_lemma_True_repeat_3_fold_2/runs/yq7tnk6e
wandb: Find logs at: ./wandb/run-20220305_100726-yq7tnk6e/logs/debug.log
wandb: 

wandb: wandb version 0.12.11 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
2022-03-05 10:50:18.393138: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1
wandb: Tracking run with wandb version 0.12.5
wandb: Syncing run classic-wind-1
wandb: ⭐️ View project at https://wandb.ai/yinanazhou/xl_512_bs_8_lr_1e06_es_20_lc_False_nr_False_stem_False_lemma_True_repeat_4_fold_1
wandb: 🚀 View run at https://wandb.ai/yinanazhou/xl_512_bs_8_lr_1e06_es_20_lc_False_nr_False_stem_False_lemma_True_repeat_4_fold_1/runs/1z26ze5c
wandb: Run data is saved locally in /project/6002780/yinan/Thesis_MER_Lyrics/lyric-emotion/wandb/run-20220305_105015-1z26ze5c
wandb: Run `wandb offline` to turn off syncing.

Validation loss decreased (inf --> 1.378688).  Saving model ...
Validation loss decreased (1.378688 --> 1.350980).  Saving model ...
Validation loss decreased (1.350980 --> 1.324549).  Saving model ...
Validation loss decreased (1.324549 --> 1.294894).  Saving model ...
Validation loss decreased (1.294894 --> 1.268065).  Saving model ...
Validation loss decreased (1.268065 --> 1.234470).  Saving model ...
Validation loss decreased (1.234470 --> 1.192197).  Saving model ...
Validation loss decreased (1.192197 --> 1.162583).  Saving model ...
Validation loss decreased (1.162583 --> 1.130547).  Saving model ...
Validation loss decreased (1.130547 --> 1.092519).  Saving model ...
Validation loss decreased (1.092519 --> 1.062759).  Saving model ...
Validation loss decreased (1.062759 --> 1.029821).  Saving model ...
Validation loss decreased (1.029821 --> 1.012153).  Saving model ...
Validation loss decreased (1.012153 --> 0.986973).  Saving model ...
Validation loss decreased (0.986973 --> 0.966773).  Saving model ...
Validation loss decreased (0.966773 --> 0.947525).  Saving model ...
Validation loss decreased (0.947525 --> 0.932612).  Saving model ...
Validation loss decreased (0.932612 --> 0.920546).  Saving model ...
Validation loss decreased (0.920546 --> 0.907958).  Saving model ...
EarlyStopping counter: 1 out of 20.0
Validation loss decreased (0.907958 --> 0.896881).  Saving model ...
Validation loss decreased (0.896881 --> 0.891117).  Saving model ...
EarlyStopping counter: 1 out of 20.0
Validation loss decreased (0.891117 --> 0.883705).  Saving model ...
EarlyStopping counter: 1 out of 20.0
EarlyStopping counter: 2 out of 20.0
EarlyStopping counter: 3 out of 20.0
EarlyStopping counter: 4 out of 20.0
EarlyStopping counter: 5 out of 20.0
EarlyStopping counter: 6 out of 20.0
EarlyStopping counter: 7 out of 20.0
EarlyStopping counter: 8 out of 20.0
EarlyStopping counter: 9 out of 20.0
EarlyStopping counter: 10 out of 20.0
EarlyStopping counter: 11 out of 20.0
EarlyStopping counter: 12 out of 20.0
EarlyStopping counter: 13 out of 20.0
EarlyStopping counter: 14 out of 20.0
EarlyStopping counter: 15 out of 20.0
EarlyStopping counter: 16 out of 20.0
EarlyStopping counter: 17 out of 20.0
EarlyStopping counter: 18 out of 20.0
EarlyStopping counter: 19 out of 20.0
EarlyStopping counter: 20 out of 20.0
/localscratch/yinan.28285244.0/env/lib/python3.7/site-packages/torch/nn/functional.py:1794: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.
  warnings.warn("nn.functional.tanh is deprecated. Use torch.tanh instead.")
wandb: Waiting for W&B process to finish, PID 221323... (success).
wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: \ 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: | 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: / 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: \ 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: | 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: / 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: \ 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: | 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: / 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb:                                                                                
wandb: Run history:
wandb:     e_F1 ▁▃▄▄▅▅▅▅▆▆▇▇▇▇█▇████████████████████████
wandb:   e_loss ██▇▇▆▆▅▅▄▄▃▃▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▂▂▂▂▂▂▂▃▃▃
wandb:     t_F1 ▁▂▂▃▃▃▄▃▄▄▅▅▅▅▅▆▆▆▆▆▆▆▆▇▇▆▇▇▇▇▇▇▇▇██▇███
wandb:   t_loss ███▇▇▇▇▆▆▆▆▅▅▅▅▅▄▄▄▄▃▃▃▃▃▃▃▃▃▂▂▂▂▂▂▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:     e_F1 62.91381
wandb:   e_loss 1.02762
wandb:     t_F1 92.82778
wandb:   t_loss 0.28854
wandb: 
wandb: Synced 4 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Synced classic-wind-1: https://wandb.ai/yinanazhou/xl_512_bs_8_lr_1e06_es_20_lc_False_nr_False_stem_False_lemma_True_repeat_4_fold_1/runs/1z26ze5c
wandb: Find logs at: ./wandb/run-20220305_105015-1z26ze5c/logs/debug.log
wandb: 

wandb: wandb version 0.12.11 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
2022-03-05 11:32:17.676445: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1
wandb: Tracking run with wandb version 0.12.5
wandb: Syncing run soft-meadow-1
wandb: ⭐️ View project at https://wandb.ai/yinanazhou/xl_512_bs_8_lr_1e06_es_20_lc_False_nr_False_stem_False_lemma_True_repeat_4_fold_2
wandb: 🚀 View run at https://wandb.ai/yinanazhou/xl_512_bs_8_lr_1e06_es_20_lc_False_nr_False_stem_False_lemma_True_repeat_4_fold_2/runs/2hqo0dsx
wandb: Run data is saved locally in /project/6002780/yinan/Thesis_MER_Lyrics/lyric-emotion/wandb/run-20220305_113214-2hqo0dsx
wandb: Run `wandb offline` to turn off syncing.

Validation loss decreased (inf --> 1.386587).  Saving model ...
Validation loss decreased (1.386587 --> 1.358646).  Saving model ...
Validation loss decreased (1.358646 --> 1.334902).  Saving model ...
Validation loss decreased (1.334902 --> 1.308423).  Saving model ...
Validation loss decreased (1.308423 --> 1.274265).  Saving model ...
Validation loss decreased (1.274265 --> 1.247491).  Saving model ...
Validation loss decreased (1.247491 --> 1.210384).  Saving model ...
Validation loss decreased (1.210384 --> 1.175749).  Saving model ...
Validation loss decreased (1.175749 --> 1.136779).  Saving model ...
Validation loss decreased (1.136779 --> 1.108164).  Saving model ...
Validation loss decreased (1.108164 --> 1.069295).  Saving model ...
Validation loss decreased (1.069295 --> 1.043755).  Saving model ...
Validation loss decreased (1.043755 --> 1.025666).  Saving model ...
Validation loss decreased (1.025666 --> 1.013574).  Saving model ...
Validation loss decreased (1.013574 --> 0.990148).  Saving model ...
Validation loss decreased (0.990148 --> 0.978856).  Saving model ...
Validation loss decreased (0.978856 --> 0.961370).  Saving model ...
Validation loss decreased (0.961370 --> 0.956337).  Saving model ...
Validation loss decreased (0.956337 --> 0.943913).  Saving model ...
EarlyStopping counter: 1 out of 20.0
Validation loss decreased (0.943913 --> 0.933149).  Saving model ...
Validation loss decreased (0.933149 --> 0.929608).  Saving model ...
Validation loss decreased (0.929608 --> 0.923627).  Saving model ...
Validation loss decreased (0.923627 --> 0.921656).  Saving model ...
Validation loss decreased (0.921656 --> 0.920976).  Saving model ...
EarlyStopping counter: 1 out of 20.0
EarlyStopping counter: 2 out of 20.0
Validation loss decreased (0.920976 --> 0.920970).  Saving model ...
EarlyStopping counter: 1 out of 20.0
EarlyStopping counter: 2 out of 20.0
EarlyStopping counter: 3 out of 20.0
EarlyStopping counter: 4 out of 20.0
EarlyStopping counter: 5 out of 20.0
EarlyStopping counter: 6 out of 20.0
EarlyStopping counter: 7 out of 20.0
EarlyStopping counter: 8 out of 20.0
EarlyStopping counter: 9 out of 20.0
EarlyStopping counter: 10 out of 20.0
EarlyStopping counter: 11 out of 20.0
EarlyStopping counter: 12 out of 20.0
EarlyStopping counter: 13 out of 20.0
EarlyStopping counter: 14 out of 20.0
EarlyStopping counter: 15 out of 20.0
EarlyStopping counter: 16 out of 20.0
EarlyStopping counter: 17 out of 20.0
EarlyStopping counter: 18 out of 20.0
EarlyStopping counter: 19 out of 20.0
EarlyStopping counter: 20 out of 20.0
/localscratch/yinan.28285244.0/env/lib/python3.7/site-packages/torch/nn/functional.py:1794: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.
  warnings.warn("nn.functional.tanh is deprecated. Use torch.tanh instead.")
wandb: Waiting for W&B process to finish, PID 223615... (success).
wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: \ 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: | 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: / 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: \ 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: | 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: / 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: \ 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: | 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: / 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb:                                                                                
wandb: Run history:
wandb:     e_F1 ▁▃▃▄▅▅▅▆▆▇▇▇█▇██████████████████████████
wandb:   e_loss ██▇▇▆▅▅▄▄▃▃▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▂▂▂▂▂▂▂▃▃▃▃▄
wandb:     t_F1 ▁▁▂▂▂▃▄▄▄▅▅▅▅▅▅▆▆▆▆▆▆▆▆▆▇▇▇▇▇▇▇▇▇▇██████
wandb:   t_loss ████▇▇▇▆▆▆▅▅▅▅▅▄▄▄▄▄▄▃▃▃▃▃▃▂▂▂▂▂▂▂▂▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:     e_F1 60.38087
wandb:   e_loss 1.10209
wandb:     t_F1 97.0332
wandb:   t_loss 0.19979
wandb: 
wandb: Synced 4 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Synced soft-meadow-1: https://wandb.ai/yinanazhou/xl_512_bs_8_lr_1e06_es_20_lc_False_nr_False_stem_False_lemma_True_repeat_4_fold_2/runs/2hqo0dsx
wandb: Find logs at: ./wandb/run-20220305_113214-2hqo0dsx/logs/debug.log
wandb: 

wandb: wandb version 0.12.11 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
2022-03-05 12:17:57.450126: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1
wandb: Tracking run with wandb version 0.12.5
wandb: Syncing run rose-aardvark-1
wandb: ⭐️ View project at https://wandb.ai/yinanazhou/xl_512_bs_8_lr_1e06_es_20_lc_False_nr_False_stem_False_lemma_True_repeat_5_fold_1
wandb: 🚀 View run at https://wandb.ai/yinanazhou/xl_512_bs_8_lr_1e06_es_20_lc_False_nr_False_stem_False_lemma_True_repeat_5_fold_1/runs/228f04jk
wandb: Run data is saved locally in /project/6002780/yinan/Thesis_MER_Lyrics/lyric-emotion/wandb/run-20220305_121754-228f04jk
wandb: Run `wandb offline` to turn off syncing.

Validation loss decreased (inf --> 1.404944).  Saving model ...
Validation loss decreased (1.404944 --> 1.370584).  Saving model ...
Validation loss decreased (1.370584 --> 1.349405).  Saving model ...
Validation loss decreased (1.349405 --> 1.323439).  Saving model ...
Validation loss decreased (1.323439 --> 1.296355).  Saving model ...
Validation loss decreased (1.296355 --> 1.266672).  Saving model ...
Validation loss decreased (1.266672 --> 1.231369).  Saving model ...
Validation loss decreased (1.231369 --> 1.198700).  Saving model ...
Validation loss decreased (1.198700 --> 1.152799).  Saving model ...
Validation loss decreased (1.152799 --> 1.115709).  Saving model ...
Validation loss decreased (1.115709 --> 1.087893).  Saving model ...
Validation loss decreased (1.087893 --> 1.056426).  Saving model ...
Validation loss decreased (1.056426 --> 1.029926).  Saving model ...
Validation loss decreased (1.029926 --> 1.011801).  Saving model ...
Validation loss decreased (1.011801 --> 0.986946).  Saving model ...
Validation loss decreased (0.986946 --> 0.977995).  Saving model ...
Validation loss decreased (0.977995 --> 0.959129).  Saving model ...
Validation loss decreased (0.959129 --> 0.943312).  Saving model ...
Validation loss decreased (0.943312 --> 0.942401).  Saving model ...
Validation loss decreased (0.942401 --> 0.920406).  Saving model ...
EarlyStopping counter: 1 out of 20.0
Validation loss decreased (0.920406 --> 0.908424).  Saving model ...
EarlyStopping counter: 1 out of 20.0
Validation loss decreased (0.908424 --> 0.898842).  Saving model ...
EarlyStopping counter: 1 out of 20.0
EarlyStopping counter: 2 out of 20.0
EarlyStopping counter: 3 out of 20.0
EarlyStopping counter: 4 out of 20.0
EarlyStopping counter: 5 out of 20.0
EarlyStopping counter: 6 out of 20.0
EarlyStopping counter: 7 out of 20.0
EarlyStopping counter: 8 out of 20.0
EarlyStopping counter: 9 out of 20.0
EarlyStopping counter: 10 out of 20.0
EarlyStopping counter: 11 out of 20.0
EarlyStopping counter: 12 out of 20.0
EarlyStopping counter: 13 out of 20.0
EarlyStopping counter: 14 out of 20.0
EarlyStopping counter: 15 out of 20.0
EarlyStopping counter: 16 out of 20.0
EarlyStopping counter: 17 out of 20.0
EarlyStopping counter: 18 out of 20.0
EarlyStopping counter: 19 out of 20.0
EarlyStopping counter: 20 out of 20.0
/localscratch/yinan.28285244.0/env/lib/python3.7/site-packages/torch/nn/functional.py:1794: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.
  warnings.warn("nn.functional.tanh is deprecated. Use torch.tanh instead.")
wandb: Waiting for W&B process to finish, PID 226108... (success).
wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: \ 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: | 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb:                                                                                
wandb: Run history:
wandb:     e_F1 ▁▂▃▄▅▅▅▆▇▆▇▇▇▇▇▇▇▇█▇██▇█████████████████
wandb:   e_loss ██▇▇▆▆▆▅▅▄▃▃▃▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▂▁▂▂▂▂▂▂▂
wandb:     t_F1 ▁▂▂▃▃▃▃▄▄▅▅▅▅▅▅▅▆▆▆▆▆▆▆▇▇▇▇▇▇▇▇█████████
wandb:   t_loss ███▇▇▇▇▇▆▆▆▅▅▅▅▅▄▄▄▄▃▃▃▃▃▃▃▃▂▂▂▂▂▂▂▂▁▁▁▁
wandb: 
wandb: Run summary:
wandb:     e_F1 61.9622
wandb:   e_loss 0.98818
wandb:     t_F1 92.37038
wandb:   t_loss 0.30212
wandb: 
wandb: Synced 4 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Synced rose-aardvark-1: https://wandb.ai/yinanazhou/xl_512_bs_8_lr_1e06_es_20_lc_False_nr_False_stem_False_lemma_True_repeat_5_fold_1/runs/228f04jk
wandb: Find logs at: ./wandb/run-20220305_121754-228f04jk/logs/debug.log
wandb: 

wandb: wandb version 0.12.11 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
2022-03-05 12:59:54.232560: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1
wandb: Tracking run with wandb version 0.12.5
wandb: Syncing run ethereal-universe-1
wandb: ⭐️ View project at https://wandb.ai/yinanazhou/xl_512_bs_8_lr_1e06_es_20_lc_False_nr_False_stem_False_lemma_True_repeat_5_fold_2
wandb: 🚀 View run at https://wandb.ai/yinanazhou/xl_512_bs_8_lr_1e06_es_20_lc_False_nr_False_stem_False_lemma_True_repeat_5_fold_2/runs/135q0r6a
wandb: Run data is saved locally in /project/6002780/yinan/Thesis_MER_Lyrics/lyric-emotion/wandb/run-20220305_125951-135q0r6a
wandb: Run `wandb offline` to turn off syncing.

Validation loss decreased (inf --> 1.389202).  Saving model ...
Validation loss decreased (1.389202 --> 1.369179).  Saving model ...
Validation loss decreased (1.369179 --> 1.354213).  Saving model ...
Validation loss decreased (1.354213 --> 1.333911).  Saving model ...
Validation loss decreased (1.333911 --> 1.305738).  Saving model ...
Validation loss decreased (1.305738 --> 1.277727).  Saving model ...
Validation loss decreased (1.277727 --> 1.245430).  Saving model ...
Validation loss decreased (1.245430 --> 1.221892).  Saving model ...
Validation loss decreased (1.221892 --> 1.162911).  Saving model ...
Validation loss decreased (1.162911 --> 1.135594).  Saving model ...
Validation loss decreased (1.135594 --> 1.111455).  Saving model ...
Validation loss decreased (1.111455 --> 1.093619).  Saving model ...
Validation loss decreased (1.093619 --> 1.071068).  Saving model ...
Validation loss decreased (1.071068 --> 1.052025).  Saving model ...
Validation loss decreased (1.052025 --> 1.029345).  Saving model ...
Validation loss decreased (1.029345 --> 1.017971).  Saving model ...
Validation loss decreased (1.017971 --> 0.991804).  Saving model ...
Validation loss decreased (0.991804 --> 0.981909).  Saving model ...
Validation loss decreased (0.981909 --> 0.971446).  Saving model ...
Validation loss decreased (0.971446 --> 0.962475).  Saving model ...
Validation loss decreased (0.962475 --> 0.949357).  Saving model ...
Validation loss decreased (0.949357 --> 0.945156).  Saving model ...
Validation loss decreased (0.945156 --> 0.939663).  Saving model ...
Validation loss decreased (0.939663 --> 0.931852).  Saving model ...
Validation loss decreased (0.931852 --> 0.924505).  Saving model ...
Validation loss decreased (0.924505 --> 0.914241).  Saving model ...
EarlyStopping counter: 1 out of 20.0
Validation loss decreased (0.914241 --> 0.908269).  Saving model ...
EarlyStopping counter: 1 out of 20.0
EarlyStopping counter: 2 out of 20.0
Validation loss decreased (0.908269 --> 0.907823).  Saving model ...
Validation loss decreased (0.907823 --> 0.906274).  Saving model ...
Validation loss decreased (0.906274 --> 0.905980).  Saving model ...
EarlyStopping counter: 1 out of 20.0
Validation loss decreased (0.905980 --> 0.903310).  Saving model ...
EarlyStopping counter: 1 out of 20.0
EarlyStopping counter: 2 out of 20.0
EarlyStopping counter: 3 out of 20.0
EarlyStopping counter: 4 out of 20.0
EarlyStopping counter: 5 out of 20.0
EarlyStopping counter: 6 out of 20.0
EarlyStopping counter: 7 out of 20.0
EarlyStopping counter: 8 out of 20.0
EarlyStopping counter: 9 out of 20.0
EarlyStopping counter: 10 out of 20.0
EarlyStopping counter: 11 out of 20.0
EarlyStopping counter: 12 out of 20.0
EarlyStopping counter: 13 out of 20.0
EarlyStopping counter: 14 out of 20.0
EarlyStopping counter: 15 out of 20.0
EarlyStopping counter: 16 out of 20.0
EarlyStopping counter: 17 out of 20.0
EarlyStopping counter: 18 out of 20.0
EarlyStopping counter: 19 out of 20.0
EarlyStopping counter: 20 out of 20.0
/localscratch/yinan.28285244.0/env/lib/python3.7/site-packages/torch/nn/functional.py:1794: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.
  warnings.warn("nn.functional.tanh is deprecated. Use torch.tanh instead.")
wandb: Waiting for W&B process to finish, PID 228354... (success).
wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: \ 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: | 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: / 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: \ 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: | 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: / 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: \ 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: | 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: / 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb:                                                                                
wandb: Run history:
wandb:     e_F1 ▁▂▂▄▄▅▆▆▇▇▇▇▇▇▇▇████▇███████████████████
wandb:   e_loss ██▇▇▆▆▅▄▄▃▃▃▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▂▂▂▂▂▂▃
wandb:     t_F1 ▁▂▂▃▃▃▄▄▄▅▅▅▅▅▅▆▆▆▆▆▆▆▆▇▇▇▇▇▇▇▇▇▇▇██████
wandb:   t_loss ███▇▇▇▇▇▆▆▆▅▅▅▅▅▄▄▄▄▄▃▃▃▃▃▃▃▂▂▂▂▂▂▂▂▁▁▁▁
wandb: 
wandb: Run summary:
wandb:     e_F1 64.25513
wandb:   e_loss 1.01474
wandb:     t_F1 95.96718
wandb:   t_loss 0.23488
wandb: 
wandb: Synced 4 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Synced ethereal-universe-1: https://wandb.ai/yinanazhou/xl_512_bs_8_lr_1e06_es_20_lc_False_nr_False_stem_False_lemma_True_repeat_5_fold_2/runs/135q0r6a
wandb: Find logs at: ./wandb/run-20220305_125951-135q0r6a/logs/debug.log
wandb: 

