Unloading StdEnv/2020

Due to MODULEPATH changes, the following have been reloaded:
  1) mii/1.1.1


The following have been reloaded with a version change:
  1) python/3.8.2 => python/3.7.4

Using base prefix '/cvmfs/soft.computecanada.ca/easybuild/software/2017/Core/python/3.7.4'
New python executable in /localscratch/yinan.29019290.0/env/bin/python
Installing setuptools, pip, wheel...
done.
Ignoring pip: markers 'python_version < "3"' don't match your environment
Looking in links: /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/nix/avx2, /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/nix/generic, /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic
Collecting pip
Installing collected packages: pip
  Found existing installation: pip 19.1.1
    Uninstalling pip-19.1.1:
      Successfully uninstalled pip-19.1.1
Successfully installed pip-21.2.3+computecanada
Looking in links: /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/nix/avx2, /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/nix/generic, /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/keras-2.8.0+computecanada-py2.py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/Keras_Preprocessing-1.1.2+computecanada-py3-none-any.whl
Requirement already satisfied: matplotlib in /cvmfs/soft.computecanada.ca/easybuild/software/2017/Core/scipy-stack/2019a/lib/python3.7/site-packages (from -r requirements.txt (line 3)) (3.0.2)
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/nltk-3.6.5+computecanada-py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/scikit_learn-0.22.1+computecanada-cp37-cp37m-linux_x86_64.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/tensorboard-2.3.0+computecanada-py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/tensorboard_plugin_wit-1.7.0+computecanada-py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/tensorflow_gpu-2.3.0+computecanada-cp37-cp37m-linux_x86_64.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/tensorflow_estimator-2.3.0+computecanada-py2.py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/tokenizers-0.5.2+computecanada-cp37-cp37m-linux_x86_64.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/nix/avx2/torch-1.4.0+computecanada-cp37-cp37m-linux_x86_64.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/torchtext-0.6.0+computecanada-py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/torchvision-0.8.2+computecanada-cp37-cp37m-linux_x86_64.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/transformers-2.5.1+computecanada-py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/urllib3-1.26.7+computecanada-py2.py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/tqdm-4.63.0+computecanada-py2.py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/click-8.0.4+computecanada-py3-none-any.whl
ERROR: Could not find a version that satisfies the requirement regex>=2021.8.3 (from nltk) (from versions: 2018.1.10+computecanada, 2019.11.1+computecanada, 2020.11.13+computecanada)
ERROR: No matching distribution found for regex>=2021.8.3
Looking in links: /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/nix/avx2, /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/nix/generic, /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic
ERROR: Could not find a version that satisfies the requirement numpy==1.20.0+computacanada (from versions: 1.15.0+computecanada, 1.15.2+computecanada, 1.15.4+computecanada, 1.16.0+computecanada, 1.16.2+computecanada, 1.16.3+computecanada, 1.17.4+computecanada, 1.18.1+computecanada, 1.18.4+computecanada, 1.19.1+computecanada, 1.19.2+computecanada, 1.20.2+computecanada)
ERROR: No matching distribution found for numpy==1.20.0+computacanada
Looking in links: /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/nix/avx2, /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/nix/generic, /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/wandb-0.12.5+computecanada-py2.py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/yaspin-2.1.0+computecanada-py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/configparser-5.0.2+computecanada-py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/promise-2.3+computecanada-py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/six-1.16.0+computecanada-py2.py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/sentry_sdk-1.5.0+computecanada-py2.py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/GitPython-3.1.24+computecanada-py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/docker_pycreds-0.4.0+computecanada-py2.py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/protobuf-3.19.4+computecanada-py2.py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/click-8.0.4+computecanada-py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/PyYAML-5.3.1+computecanada-cp37-cp37m-linux_x86_64.whl
Requirement already satisfied: requests<3,>=2.0.0 in /cvmfs/soft.computecanada.ca/easybuild/software/2017/Core/scipy-stack/2019a/lib/python3.7/site-packages (from wandb) (2.21.0)
Requirement already satisfied: python-dateutil>=2.6.1 in /cvmfs/soft.computecanada.ca/easybuild/software/2017/Core/scipy-stack/2019a/lib/python3.7/site-packages (from wandb) (2.7.5)
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/shortuuid-1.0.1+computecanada-py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/subprocess32-3.5.4+computecanada-py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/psutil-5.7.3+computecanada-cp37-cp37m-linux_x86_64.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/pathtools-0.1.2+computecanada-py3-none-any.whl
Requirement already satisfied: importlib-metadata in /cvmfs/soft.computecanada.ca/easybuild/software/2017/Core/scipy-stack/2019a/lib/python3.7/site-packages (from Click!=8.0.0,>=7.0->wandb) (0.8)
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/typing_extensions-4.0.1+computecanada-py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/gitdb-4.0.9+computecanada-py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/smmap-5.0.0+computecanada-py3-none-any.whl
Requirement already satisfied: idna<2.9,>=2.5 in /cvmfs/soft.computecanada.ca/easybuild/software/2017/Core/scipy-stack/2019a/lib/python3.7/site-packages (from requests<3,>=2.0.0->wandb) (2.8)
Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /cvmfs/soft.computecanada.ca/easybuild/software/2017/Core/scipy-stack/2019a/lib/python3.7/site-packages (from requests<3,>=2.0.0->wandb) (3.0.4)
Requirement already satisfied: certifi>=2017.4.17 in /cvmfs/soft.computecanada.ca/easybuild/software/2017/Core/scipy-stack/2019a/lib/python3.7/site-packages (from requests<3,>=2.0.0->wandb) (2018.11.29)
Requirement already satisfied: urllib3<1.25,>=1.21.1 in /cvmfs/soft.computecanada.ca/easybuild/software/2017/Core/scipy-stack/2019a/lib/python3.7/site-packages (from requests<3,>=2.0.0->wandb) (1.24.1)
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/termcolor-1.1.0+computecanada-py3-none-any.whl
Requirement already satisfied: zipp>=0.3.2 in /cvmfs/soft.computecanada.ca/easybuild/software/2017/Core/scipy-stack/2019a/lib/python3.7/site-packages (from importlib-metadata->Click!=8.0.0,>=7.0->wandb) (0.3.3)
Installing collected packages: smmap, typing-extensions, termcolor, six, gitdb, yaspin, subprocess32, shortuuid, sentry-sdk, PyYAML, psutil, protobuf, promise, pathtools, GitPython, docker-pycreds, configparser, Click, wandb
  Attempting uninstall: six
    Found existing installation: six 1.12.0
    Not uninstalling six at /cvmfs/soft.computecanada.ca/easybuild/software/2017/Core/scipy-stack/2019a/lib/python3.7/site-packages, outside environment /localscratch/yinan.29019290.0/env
    Can't uninstall 'six'. No files were found to uninstall.
Successfully installed Click-8.0.4+computecanada GitPython-3.1.24+computecanada PyYAML-5.3.1+computecanada configparser-5.0.2+computecanada docker-pycreds-0.4.0+computecanada gitdb-4.0.9+computecanada pathtools-0.1.2+computecanada promise-2.3+computecanada protobuf-3.19.4+computecanada psutil-5.7.3+computecanada sentry-sdk-1.5.0+computecanada shortuuid-1.0.1+computecanada six-1.16.0+computecanada smmap-5.0.0+computecanada subprocess32-3.5.4+computecanada termcolor-1.1.0+computecanada typing-extensions-4.0.1+computecanada wandb-0.12.5+computecanada yaspin-2.1.0+computecanada
Looking in links: /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/nix/avx2, /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/nix/generic, /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic
ERROR: Could not find a version that satisfies the requirement sagemaker (from versions: none)
ERROR: No matching distribution found for sagemaker
Looking in links: /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/nix/avx2, /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/nix/generic, /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/torch-1.9.1+computecanada-cp37-cp37m-linux_x86_64.whl
Requirement already satisfied: typing-extensions in /localscratch/yinan.29019290.0/env/lib/python3.7/site-packages (from torch) (4.0.1+computecanada)
Installing collected packages: torch
Successfully installed torch-1.9.1+computecanada
Looking in links: /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/nix/avx2, /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/nix/generic, /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/transformers-2.5.1+computecanada-py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/tqdm-4.63.0+computecanada-py2.py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/sentencepiece-0.1.91+computecanada-cp37-cp37m-linux_x86_64.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/tokenizers-0.5.2+computecanada-cp37-cp37m-linux_x86_64.whl
Requirement already satisfied: requests in /cvmfs/soft.computecanada.ca/easybuild/software/2017/Core/scipy-stack/2019a/lib/python3.7/site-packages (from transformers==2.5.1+computecanada) (2.21.0)
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/regex-2020.11.13+computecanada-cp37-cp37m-linux_x86_64.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/sacremoses-0.0.46+computecanada-py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/filelock-3.4.2+computecanada-py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/boto3-1.21.14+computecanada-py3-none-any.whl
Requirement already satisfied: numpy in /cvmfs/soft.computecanada.ca/easybuild/software/2017/Core/scipy-stack/2019a/lib/python3.7/site-packages (from transformers==2.5.1+computecanada) (1.16.0)
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/s3transfer-0.5.1+computecanada-py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/jmespath-0.10.0+computecanada-py2.py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/botocore-1.24.14+computecanada-py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/urllib3-1.26.8+computecanada-py2.py3-none-any.whl
Requirement already satisfied: python-dateutil<3.0.0,>=2.1 in /cvmfs/soft.computecanada.ca/easybuild/software/2017/Core/scipy-stack/2019a/lib/python3.7/site-packages (from botocore<1.25.0,>=1.24.14->boto3->transformers==2.5.1+computecanada) (2.7.5)
Requirement already satisfied: six>=1.5 in /localscratch/yinan.29019290.0/env/lib/python3.7/site-packages (from python-dateutil<3.0.0,>=2.1->botocore<1.25.0,>=1.24.14->boto3->transformers==2.5.1+computecanada) (1.16.0+computecanada)
Requirement already satisfied: certifi>=2017.4.17 in /cvmfs/soft.computecanada.ca/easybuild/software/2017/Core/scipy-stack/2019a/lib/python3.7/site-packages (from requests->transformers==2.5.1+computecanada) (2018.11.29)
Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /cvmfs/soft.computecanada.ca/easybuild/software/2017/Core/scipy-stack/2019a/lib/python3.7/site-packages (from requests->transformers==2.5.1+computecanada) (3.0.4)
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/requests-2.27.1+computecanada-py2.py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/charset_normalizer-2.0.12+computecanada-py3-none-any.whl
Requirement already satisfied: idna<4,>=2.5 in /cvmfs/soft.computecanada.ca/easybuild/software/2017/Core/scipy-stack/2019a/lib/python3.7/site-packages (from requests->transformers==2.5.1+computecanada) (2.8)
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/joblib-1.1.0+computecanada-py2.py3-none-any.whl
Requirement already satisfied: click in /localscratch/yinan.29019290.0/env/lib/python3.7/site-packages (from sacremoses->transformers==2.5.1+computecanada) (8.0.4+computecanada)
Requirement already satisfied: importlib-metadata in /cvmfs/soft.computecanada.ca/easybuild/software/2017/Core/scipy-stack/2019a/lib/python3.7/site-packages (from click->sacremoses->transformers==2.5.1+computecanada) (0.8)
Requirement already satisfied: zipp>=0.3.2 in /cvmfs/soft.computecanada.ca/easybuild/software/2017/Core/scipy-stack/2019a/lib/python3.7/site-packages (from importlib-metadata->click->sacremoses->transformers==2.5.1+computecanada) (0.3.3)
Installing collected packages: urllib3, jmespath, botocore, tqdm, s3transfer, regex, joblib, charset-normalizer, tokenizers, sentencepiece, sacremoses, requests, filelock, boto3, transformers
  Attempting uninstall: urllib3
    Found existing installation: urllib3 1.24.1
    Not uninstalling urllib3 at /cvmfs/soft.computecanada.ca/easybuild/software/2017/Core/scipy-stack/2019a/lib/python3.7/site-packages, outside environment /localscratch/yinan.29019290.0/env
    Can't uninstall 'urllib3'. No files were found to uninstall.
  Attempting uninstall: requests
    Found existing installation: requests 2.21.0
    Not uninstalling requests at /cvmfs/soft.computecanada.ca/easybuild/software/2017/Core/scipy-stack/2019a/lib/python3.7/site-packages, outside environment /localscratch/yinan.29019290.0/env
    Can't uninstall 'requests'. No files were found to uninstall.
Successfully installed boto3-1.21.14+computecanada botocore-1.24.14+computecanada charset-normalizer-2.0.12+computecanada filelock-3.4.2+computecanada jmespath-0.10.0+computecanada joblib-1.1.0+computecanada regex-2020.11.13+computecanada requests-2.27.1+computecanada s3transfer-0.5.1+computecanada sacremoses-0.0.46+computecanada sentencepiece-0.1.91+computecanada tokenizers-0.5.2+computecanada tqdm-4.63.0+computecanada transformers-2.5.1+computecanada urllib3-1.26.8+computecanada
Looking in links: /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/nix/avx2, /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/nix/generic, /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/tensorflow_gpu-2.3.0+computecanada-cp37-cp37m-linux_x86_64.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/nix/generic/scipy-1.4.1+computecanada-cp37-cp37m-linux_x86_64.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/nix/avx2/h5py-2.10.0+computecanada-cp37-cp37m-linux_x86_64.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/absl_py-1.0.0+computecanada-py3-none-any.whl
Requirement already satisfied: termcolor>=1.1.0 in /localscratch/yinan.29019290.0/env/lib/python3.7/site-packages (from tensorflow_gpu==2.3.0+computecanada) (1.1.0+computecanada)
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/grpcio-1.38.0+computecanada-cp37-cp37m-linux_x86_64.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/opt_einsum-3.3.0+computecanada-py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/google_pasta-0.2.0+computecanada-py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/gast-0.3.3+computecanada-py3-none-any.whl
Requirement already satisfied: numpy<1.19.0,>=1.16.0 in /cvmfs/soft.computecanada.ca/easybuild/software/2017/Core/scipy-stack/2019a/lib/python3.7/site-packages (from tensorflow_gpu==2.3.0+computecanada) (1.16.0)
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/wrapt-1.11.2+computecanada-cp37-cp37m-linux_x86_64.whl
Requirement already satisfied: protobuf>=3.9.2 in /localscratch/yinan.29019290.0/env/lib/python3.7/site-packages (from tensorflow_gpu==2.3.0+computecanada) (3.19.4+computecanada)
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/tensorflow_estimator-2.3.0+computecanada-py2.py3-none-any.whl
Requirement already satisfied: wheel>=0.26 in /localscratch/yinan.29019290.0/env/lib/python3.7/site-packages (from tensorflow_gpu==2.3.0+computecanada) (0.33.4)
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/astunparse-1.6.3+computecanada-py2.py3-none-any.whl
Requirement already satisfied: six>=1.12.0 in /localscratch/yinan.29019290.0/env/lib/python3.7/site-packages (from tensorflow_gpu==2.3.0+computecanada) (1.16.0+computecanada)
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/tensorboard-2.8.0+computecanada-py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/Keras_Preprocessing-1.1.2+computecanada-py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/Markdown-3.3.6+computecanada-py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/Werkzeug-2.0.3+computecanada-py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/tensorboard_data_server-0.6.1+computecanada-py3-none-linux_x86_64.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/google_auth_oauthlib-0.4.6+computecanada-py2.py3-none-any.whl
Requirement already satisfied: requests<3,>=2.21.0 in /localscratch/yinan.29019290.0/env/lib/python3.7/site-packages (from tensorboard<3,>=2.3.0->tensorflow_gpu==2.3.0+computecanada) (2.27.1+computecanada)
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/google_auth-2.3.3+computecanada-py2.py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/tensorboard_plugin_wit-1.8.0+computecanada-py3-none-any.whl
Requirement already satisfied: setuptools>=41.0.0 in /localscratch/yinan.29019290.0/env/lib/python3.7/site-packages (from tensorboard<3,>=2.3.0->tensorflow_gpu==2.3.0+computecanada) (41.0.1)
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/rsa-4.8+computecanada-py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/pyasn1_modules-0.2.8+computecanada-py2.py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/cachetools-4.2.4+computecanada-py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/requests_oauthlib-1.3.0+computecanada-py2.py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/importlib_metadata-4.10.1+computecanada-py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/zipp-3.7.0+computecanada-py3-none-any.whl
Requirement already satisfied: typing-extensions>=3.6.4 in /localscratch/yinan.29019290.0/env/lib/python3.7/site-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard<3,>=2.3.0->tensorflow_gpu==2.3.0+computecanada) (4.0.1+computecanada)
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/pyasn1-0.4.8+computecanada-py2.py3-none-any.whl
Requirement already satisfied: idna<4,>=2.5 in /cvmfs/soft.computecanada.ca/easybuild/software/2017/Core/scipy-stack/2019a/lib/python3.7/site-packages (from requests<3,>=2.21.0->tensorboard<3,>=2.3.0->tensorflow_gpu==2.3.0+computecanada) (2.8)
Requirement already satisfied: urllib3<1.27,>=1.21.1 in /localscratch/yinan.29019290.0/env/lib/python3.7/site-packages (from requests<3,>=2.21.0->tensorboard<3,>=2.3.0->tensorflow_gpu==2.3.0+computecanada) (1.26.8+computecanada)
Requirement already satisfied: certifi>=2017.4.17 in /cvmfs/soft.computecanada.ca/easybuild/software/2017/Core/scipy-stack/2019a/lib/python3.7/site-packages (from requests<3,>=2.21.0->tensorboard<3,>=2.3.0->tensorflow_gpu==2.3.0+computecanada) (2018.11.29)
Requirement already satisfied: charset-normalizer~=2.0.0 in /localscratch/yinan.29019290.0/env/lib/python3.7/site-packages (from requests<3,>=2.21.0->tensorboard<3,>=2.3.0->tensorflow_gpu==2.3.0+computecanada) (2.0.12+computecanada)
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/oauthlib-3.1.1+computecanada-py2.py3-none-any.whl
Installing collected packages: pyasn1, zipp, rsa, pyasn1-modules, oauthlib, cachetools, requests-oauthlib, importlib-metadata, google-auth, werkzeug, tensorboard-plugin-wit, tensorboard-data-server, markdown, grpcio, google-auth-oauthlib, absl-py, wrapt, tensorflow-estimator, tensorboard, scipy, opt-einsum, keras-preprocessing, h5py, google-pasta, gast, astunparse, tensorflow-gpu
  Attempting uninstall: pyasn1
    Found existing installation: pyasn1 0.4.3
    Not uninstalling pyasn1 at /cvmfs/soft.computecanada.ca/easybuild/software/2017/Core/scipy-stack/2019a/lib/python3.7/site-packages, outside environment /localscratch/yinan.29019290.0/env
    Can't uninstall 'pyasn1'. No files were found to uninstall.
  Attempting uninstall: zipp
    Found existing installation: zipp 0.3.3
    Not uninstalling zipp at /cvmfs/soft.computecanada.ca/easybuild/software/2017/Core/scipy-stack/2019a/lib/python3.7/site-packages, outside environment /localscratch/yinan.29019290.0/env
    Can't uninstall 'zipp'. No files were found to uninstall.
  Attempting uninstall: importlib-metadata
    Found existing installation: importlib-metadata 0.8
    Not uninstalling importlib-metadata at /cvmfs/soft.computecanada.ca/easybuild/software/2017/Core/scipy-stack/2019a/lib/python3.7/site-packages, outside environment /localscratch/yinan.29019290.0/env
    Can't uninstall 'importlib-metadata'. No files were found to uninstall.
  Attempting uninstall: scipy
    Found existing installation: scipy 1.2.0
    Not uninstalling scipy at /cvmfs/soft.computecanada.ca/easybuild/software/2017/Core/scipy-stack/2019a/lib/python3.7/site-packages, outside environment /localscratch/yinan.29019290.0/env
    Can't uninstall 'scipy'. No files were found to uninstall.
Successfully installed absl-py-1.0.0+computecanada astunparse-1.6.3+computecanada cachetools-4.2.4+computecanada gast-0.3.3+computecanada google-auth-2.3.3+computecanada google-auth-oauthlib-0.4.6+computecanada google-pasta-0.2.0+computecanada grpcio-1.38.0+computecanada h5py-2.10.0+computecanada importlib-metadata-4.10.1+computecanada keras-preprocessing-1.1.2+computecanada markdown-3.3.6+computecanada oauthlib-3.1.1+computecanada opt-einsum-3.3.0+computecanada pyasn1-0.4.8+computecanada pyasn1-modules-0.2.8+computecanada requests-oauthlib-1.3.0+computecanada rsa-4.8+computecanada scipy-1.4.1+computecanada tensorboard-2.8.0+computecanada tensorboard-data-server-0.6.1+computecanada tensorboard-plugin-wit-1.8.0+computecanada tensorflow-estimator-2.3.0+computecanada tensorflow-gpu-2.3.0+computecanada werkzeug-2.0.3+computecanada wrapt-1.11.2+computecanada zipp-3.7.0+computecanada
Looking in links: /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/nix/avx2, /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/nix/generic, /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/keras-2.8.0+computecanada-py2.py3-none-any.whl
Installing collected packages: Keras
Successfully installed Keras-2.8.0+computecanada
Looking in links: /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/nix/avx2, /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/nix/generic, /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/urllib3-1.26.7+computecanada-py2.py3-none-any.whl
Installing collected packages: urllib3
  Attempting uninstall: urllib3
    Found existing installation: urllib3 1.26.8+computecanada
    Uninstalling urllib3-1.26.8+computecanada:
      Successfully uninstalled urllib3-1.26.8+computecanada
Successfully installed urllib3-1.26.7+computecanada
Looking in links: /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/nix/avx2, /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/nix/generic, /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/nltk-3.7+computecanada-py3-none-any.whl
Requirement already satisfied: click in /localscratch/yinan.29019290.0/env/lib/python3.7/site-packages (from nltk) (8.0.4+computecanada)
Requirement already satisfied: joblib in /localscratch/yinan.29019290.0/env/lib/python3.7/site-packages (from nltk) (1.1.0+computecanada)
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/nltk-3.6.5+computecanada-py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/nltk-3.6.3+computecanada-py3-none-any.whl
Requirement already satisfied: regex in /localscratch/yinan.29019290.0/env/lib/python3.7/site-packages (from nltk) (2020.11.13+computecanada)
Requirement already satisfied: tqdm in /localscratch/yinan.29019290.0/env/lib/python3.7/site-packages (from nltk) (4.63.0+computecanada)
Requirement already satisfied: importlib-metadata in /localscratch/yinan.29019290.0/env/lib/python3.7/site-packages (from click->nltk) (4.10.1+computecanada)
Requirement already satisfied: zipp>=0.5 in /localscratch/yinan.29019290.0/env/lib/python3.7/site-packages (from importlib-metadata->click->nltk) (3.7.0+computecanada)
Requirement already satisfied: typing-extensions>=3.6.4 in /localscratch/yinan.29019290.0/env/lib/python3.7/site-packages (from importlib-metadata->click->nltk) (4.0.1+computecanada)
Installing collected packages: nltk
Successfully installed nltk-3.6.3+computecanada
Looking in links: /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/nix/avx2, /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/nix/generic, /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/scikit_learn-0.22.1+computecanada-cp37-cp37m-linux_x86_64.whl
Requirement already satisfied: scipy>=0.17.0 in /localscratch/yinan.29019290.0/env/lib/python3.7/site-packages (from scikit-learn==0.22.1) (1.4.1+computecanada)
Requirement already satisfied: numpy>=1.11.0 in /cvmfs/soft.computecanada.ca/easybuild/software/2017/Core/scipy-stack/2019a/lib/python3.7/site-packages (from scikit-learn==0.22.1) (1.16.0)
Requirement already satisfied: joblib>=0.11 in /localscratch/yinan.29019290.0/env/lib/python3.7/site-packages (from scikit-learn==0.22.1) (1.1.0+computecanada)
Installing collected packages: scikit-learn
Successfully installed scikit-learn-0.22.1+computecanada
Looking in links: /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/nix/avx2, /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/nix/generic, /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic
Requirement already satisfied: tokenizers==0.5.2 in /localscratch/yinan.29019290.0/env/lib/python3.7/site-packages (0.5.2+computecanada)
wandb: Appending key for api.wandb.ai to your netrc file: /home/yinan/.netrc
Starting Task
2022-03-18 18:45:42.645449: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1
[nltk_data] Downloading package stopwords to /home/yinan/nltk_data...
[nltk_data]   Package stopwords is already up-to-date!
[nltk_data] Downloading package wordnet to /home/yinan/nltk_data...
[nltk_data]   Package wordnet is already up-to-date!
wandb: Currently logged in as: yinanazhou (use `wandb login --relogin` to force relogin)
wandb: wandb version 0.12.11 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
2022-03-18 18:46:01.746894: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1
wandb: Tracking run with wandb version 0.12.5
wandb: Syncing run feasible-smoke-2
wandb: ⭐️ View project at https://wandb.ai/yinanazhou/xl_512_bs_8_lr_1e06_es_10_lc_True_nr_False_sr_False_stem_True_lemma_False_repeat_1_fold_1
wandb: 🚀 View run at https://wandb.ai/yinanazhou/xl_512_bs_8_lr_1e06_es_10_lc_True_nr_False_sr_False_stem_True_lemma_False_repeat_1_fold_1/runs/2xiesjgv
wandb: Run data is saved locally in /project/6002780/yinan/Thesis_MER_Lyrics/lyric-emotion/wandb/run-20220318_184559-2xiesjgv
wandb: Run `wandb offline` to turn off syncing.

Validation loss decreased (inf --> 1.428701).  Saving model ...
Validation loss decreased (1.428701 --> 1.410853).  Saving model ...
Validation loss decreased (1.410853 --> 1.395251).  Saving model ...
Validation loss decreased (1.395251 --> 1.383025).  Saving model ...
Validation loss decreased (1.383025 --> 1.373606).  Saving model ...
Validation loss decreased (1.373606 --> 1.365513).  Saving model ...
Validation loss decreased (1.365513 --> 1.359243).  Saving model ...
Validation loss decreased (1.359243 --> 1.354053).  Saving model ...
Validation loss decreased (1.354053 --> 1.349347).  Saving model ...
Validation loss decreased (1.349347 --> 1.344091).  Saving model ...
Validation loss decreased (1.344091 --> 1.338948).  Saving model ...
Validation loss decreased (1.338948 --> 1.334549).  Saving model ...
Validation loss decreased (1.334549 --> 1.330014).  Saving model ...
Validation loss decreased (1.330014 --> 1.326011).  Saving model ...
Validation loss decreased (1.326011 --> 1.322037).  Saving model ...
Validation loss decreased (1.322037 --> 1.317563).  Saving model ...
Validation loss decreased (1.317563 --> 1.313114).  Saving model ...
Validation loss decreased (1.313114 --> 1.307988).  Saving model ...
Validation loss decreased (1.307988 --> 1.303102).  Saving model ...
Validation loss decreased (1.303102 --> 1.297448).  Saving model ...
Validation loss decreased (1.297448 --> 1.291545).  Saving model ...
Validation loss decreased (1.291545 --> 1.285765).  Saving model ...
Validation loss decreased (1.285765 --> 1.280325).  Saving model ...
Validation loss decreased (1.280325 --> 1.274800).  Saving model ...
Validation loss decreased (1.274800 --> 1.267605).  Saving model ...
Validation loss decreased (1.267605 --> 1.260850).  Saving model ...
Validation loss decreased (1.260850 --> 1.254354).  Saving model ...
Validation loss decreased (1.254354 --> 1.248109).  Saving model ...
Validation loss decreased (1.248109 --> 1.240828).  Saving model ...
Validation loss decreased (1.240828 --> 1.235054).  Saving model ...
Validation loss decreased (1.235054 --> 1.228738).  Saving model ...
Validation loss decreased (1.228738 --> 1.222475).  Saving model ...
Validation loss decreased (1.222475 --> 1.217441).  Saving model ...
Validation loss decreased (1.217441 --> 1.212890).  Saving model ...
Validation loss decreased (1.212890 --> 1.207891).  Saving model ...
Validation loss decreased (1.207891 --> 1.203062).  Saving model ...
Validation loss decreased (1.203062 --> 1.196801).  Saving model ...
Validation loss decreased (1.196801 --> 1.188847).  Saving model ...
Validation loss decreased (1.188847 --> 1.185200).  Saving model ...
Validation loss decreased (1.185200 --> 1.182521).  Saving model ...
Validation loss decreased (1.182521 --> 1.177406).  Saving model ...
Validation loss decreased (1.177406 --> 1.172767).  Saving model ...
Validation loss decreased (1.172767 --> 1.169202).  Saving model ...
Validation loss decreased (1.169202 --> 1.164803).  Saving model ...
Validation loss decreased (1.164803 --> 1.160273).  Saving model ...
Validation loss decreased (1.160273 --> 1.156590).  Saving model ...
Validation loss decreased (1.156590 --> 1.154493).  Saving model ...
Validation loss decreased (1.154493 --> 1.152687).  Saving model ...
Validation loss decreased (1.152687 --> 1.145348).  Saving model ...
Validation loss decreased (1.145348 --> 1.142695).  Saving model ...
Validation loss decreased (1.142695 --> 1.141223).  Saving model ...
Validation loss decreased (1.141223 --> 1.135138).  Saving model ...
Validation loss decreased (1.135138 --> 1.133451).  Saving model ...
Validation loss decreased (1.133451 --> 1.129744).  Saving model ...
Validation loss decreased (1.129744 --> 1.129062).  Saving model ...
Validation loss decreased (1.129062 --> 1.121108).  Saving model ...
Validation loss decreased (1.121108 --> 1.117402).  Saving model ...
Validation loss decreased (1.117402 --> 1.114661).  Saving model ...
Validation loss decreased (1.114661 --> 1.110383).  Saving model ...
Validation loss decreased (1.110383 --> 1.110366).  Saving model ...
Validation loss decreased (1.110366 --> 1.108722).  Saving model ...
Validation loss decreased (1.108722 --> 1.105206).  Saving model ...
Validation loss decreased (1.105206 --> 1.101474).  Saving model ...
Validation loss decreased (1.101474 --> 1.097470).  Saving model ...
Validation loss decreased (1.097470 --> 1.097292).  Saving model ...
Validation loss decreased (1.097292 --> 1.094743).  Saving model ...
Validation loss decreased (1.094743 --> 1.093423).  Saving model ...
Validation loss decreased (1.093423 --> 1.088006).  Saving model ...
Validation loss decreased (1.088006 --> 1.081736).  Saving model ...
Validation loss decreased (1.081736 --> 1.081129).  Saving model ...
Validation loss decreased (1.081129 --> 1.077172).  Saving model ...
Validation loss decreased (1.077172 --> 1.076355).  Saving model ...
Validation loss decreased (1.076355 --> 1.074248).  Saving model ...
Validation loss decreased (1.074248 --> 1.072177).  Saving model ...
Validation loss decreased (1.072177 --> 1.067253).  Saving model ...
EarlyStopping counter: 1 out of 10.0
Validation loss decreased (1.067253 --> 1.066481).  Saving model ...
Validation loss decreased (1.066481 --> 1.062597).  Saving model ...
Validation loss decreased (1.062597 --> 1.056995).  Saving model ...
Validation loss decreased (1.056995 --> 1.055189).  Saving model ...
EarlyStopping counter: 1 out of 10.0
EarlyStopping counter: 2 out of 10.0
EarlyStopping counter: 3 out of 10.0
EarlyStopping counter: 4 out of 10.0
Validation loss decreased (1.055189 --> 1.050956).  Saving model ...
Validation loss decreased (1.050956 --> 1.049468).  Saving model ...
Validation loss decreased (1.049468 --> 1.046428).  Saving model ...
Validation loss decreased (1.046428 --> 1.045543).  Saving model ...
Validation loss decreased (1.045543 --> 1.043721).  Saving model ...
EarlyStopping counter: 1 out of 10.0
Validation loss decreased (1.043721 --> 1.041781).  Saving model ...
Validation loss decreased (1.041781 --> 1.039145).  Saving model ...
Validation loss decreased (1.039145 --> 1.038333).  Saving model ...
EarlyStopping counter: 1 out of 10.0
EarlyStopping counter: 2 out of 10.0
Validation loss decreased (1.038333 --> 1.035767).  Saving model ...
EarlyStopping counter: 1 out of 10.0
Validation loss decreased (1.035767 --> 1.034350).  Saving model ...
EarlyStopping counter: 1 out of 10.0
Validation loss decreased (1.034350 --> 1.030522).  Saving model ...
EarlyStopping counter: 1 out of 10.0
EarlyStopping counter: 2 out of 10.0
EarlyStopping counter: 3 out of 10.0
EarlyStopping counter: 4 out of 10.0
EarlyStopping counter: 5 out of 10.0
Validation loss decreased (1.030522 --> 1.028781).  Saving model ...
Validation loss decreased (1.028781 --> 1.027078).  Saving model ...
Validation loss decreased (1.027078 --> 1.026624).  Saving model ...
Validation loss decreased (1.026624 --> 1.026549).  Saving model ...
Validation loss decreased (1.026549 --> 1.022952).  Saving model ...
EarlyStopping counter: 1 out of 10.0
EarlyStopping counter: 2 out of 10.0
EarlyStopping counter: 3 out of 10.0
EarlyStopping counter: 4 out of 10.0
EarlyStopping counter: 5 out of 10.0
Validation loss decreased (1.022952 --> 1.022317).  Saving model ...
Validation loss decreased (1.022317 --> 1.020753).  Saving model ...
Validation loss decreased (1.020753 --> 1.020155).  Saving model ...
EarlyStopping counter: 1 out of 10.0
Validation loss decreased (1.020155 --> 1.018517).  Saving model ...
Validation loss decreased (1.018517 --> 1.015303).  Saving model ...
Validation loss decreased (1.015303 --> 1.014701).  Saving model ...
Validation loss decreased (1.014701 --> 1.013659).  Saving model ...
EarlyStopping counter: 1 out of 10.0
Validation loss decreased (1.013659 --> 1.013598).  Saving model ...
EarlyStopping counter: 1 out of 10.0
EarlyStopping counter: 2 out of 10.0
Validation loss decreased (1.013598 --> 1.013346).  Saving model ...
EarlyStopping counter: 1 out of 10.0
EarlyStopping counter: 2 out of 10.0
Validation loss decreased (1.013346 --> 1.011154).  Saving model ...
EarlyStopping counter: 1 out of 10.0
EarlyStopping counter: 2 out of 10.0
EarlyStopping counter: 3 out of 10.0
EarlyStopping counter: 4 out of 10.0
EarlyStopping counter: 5 out of 10.0
EarlyStopping counter: 6 out of 10.0
EarlyStopping counter: 7 out of 10.0
EarlyStopping counter: 8 out of 10.0
EarlyStopping counter: 9 out of 10.0
EarlyStopping counter: 10 out of 10.0
/localscratch/yinan.29019290.0/env/lib/python3.7/site-packages/torch/nn/functional.py:1794: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.
  warnings.warn("nn.functional.tanh is deprecated. Use torch.tanh instead.")
/localscratch/yinan.29019290.0/env/lib/python3.7/site-packages/transformers/optimization.py:155: UserWarning: This overload of add_ is deprecated:
	add_(Number alpha, Tensor other)
Consider using one of the following signatures instead:
	add_(Tensor other, *, Number alpha) (Triggered internally at  ../torch/csrc/utils/python_arg_parser.cpp:1025.)
  exp_avg.mul_(beta1).add_(1.0 - beta1, grad)
wandb: Waiting for W&B process to finish, PID 50072... (success).
wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: \ 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: | 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: / 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: \ 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: | 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: / 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: \ 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: | 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: / 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb:                                                                                
wandb: Run history:
wandb:     e_F1 ▁▂▃▅▅▅▆▆▆▆▆▆▆▆▇▇▇▇▇▇▇▇▇▇█▇███▇██▇███████
wandb:   e_loss ██▇▇▆▆▆▅▅▅▄▄▄▃▃▃▃▃▂▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:     t_F1 ▁▁▂▃▃▃▄▄▅▅▅▅▅▆▆▆▆▆▆▆▆▆▇▆▇▇▇▇█▇██▇███████
wandb:   t_loss ███▇▇▇▇▆▆▆▅▅▅▄▄▄▄▄▃▃▃▃▃▃▃▂▂▂▂▂▂▂▂▂▂▂▁▁▁▁
wandb: 
wandb: Run summary:
wandb:     e_F1 57.64582
wandb:   e_loss 1.01666
wandb:     t_F1 73.33115
wandb:   t_loss 0.71679
wandb: 
wandb: Synced 4 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Synced feasible-smoke-2: https://wandb.ai/yinanazhou/xl_512_bs_8_lr_1e06_es_10_lc_True_nr_False_sr_False_stem_True_lemma_False_repeat_1_fold_1/runs/2xiesjgv
wandb: Find logs at: ./wandb/run-20220318_184559-2xiesjgv/logs/debug.log
wandb: 

wandb: wandb version 0.12.11 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
2022-03-18 20:16:17.377079: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1
wandb: Tracking run with wandb version 0.12.5
wandb: Syncing run fancy-wildflower-2
wandb: ⭐️ View project at https://wandb.ai/yinanazhou/xl_512_bs_8_lr_1e06_es_10_lc_True_nr_False_sr_False_stem_True_lemma_False_repeat_1_fold_2
wandb: 🚀 View run at https://wandb.ai/yinanazhou/xl_512_bs_8_lr_1e06_es_10_lc_True_nr_False_sr_False_stem_True_lemma_False_repeat_1_fold_2/runs/1xthdc3g
wandb: Run data is saved locally in /project/6002780/yinan/Thesis_MER_Lyrics/lyric-emotion/wandb/run-20220318_201614-1xthdc3g
wandb: Run `wandb offline` to turn off syncing.

Validation loss decreased (inf --> 1.419127).  Saving model ...
Validation loss decreased (1.419127 --> 1.407903).  Saving model ...
Validation loss decreased (1.407903 --> 1.398345).  Saving model ...
Validation loss decreased (1.398345 --> 1.390326).  Saving model ...
Validation loss decreased (1.390326 --> 1.383529).  Saving model ...
Validation loss decreased (1.383529 --> 1.377023).  Saving model ...
Validation loss decreased (1.377023 --> 1.371764).  Saving model ...
Validation loss decreased (1.371764 --> 1.366842).  Saving model ...
Validation loss decreased (1.366842 --> 1.362540).  Saving model ...
Validation loss decreased (1.362540 --> 1.358110).  Saving model ...
Validation loss decreased (1.358110 --> 1.353891).  Saving model ...
Validation loss decreased (1.353891 --> 1.349516).  Saving model ...
Validation loss decreased (1.349516 --> 1.345645).  Saving model ...
Validation loss decreased (1.345645 --> 1.341429).  Saving model ...
Validation loss decreased (1.341429 --> 1.336966).  Saving model ...
Validation loss decreased (1.336966 --> 1.332306).  Saving model ...
Validation loss decreased (1.332306 --> 1.327700).  Saving model ...
Validation loss decreased (1.327700 --> 1.322660).  Saving model ...
Validation loss decreased (1.322660 --> 1.317786).  Saving model ...
Validation loss decreased (1.317786 --> 1.313085).  Saving model ...
Validation loss decreased (1.313085 --> 1.308753).  Saving model ...
Validation loss decreased (1.308753 --> 1.303664).  Saving model ...
Validation loss decreased (1.303664 --> 1.298991).  Saving model ...
Validation loss decreased (1.298991 --> 1.293323).  Saving model ...
Validation loss decreased (1.293323 --> 1.287059).  Saving model ...
Validation loss decreased (1.287059 --> 1.281196).  Saving model ...
Validation loss decreased (1.281196 --> 1.275379).  Saving model ...
Validation loss decreased (1.275379 --> 1.268853).  Saving model ...
Validation loss decreased (1.268853 --> 1.262856).  Saving model ...
Validation loss decreased (1.262856 --> 1.256206).  Saving model ...
Validation loss decreased (1.256206 --> 1.248762).  Saving model ...
Validation loss decreased (1.248762 --> 1.241577).  Saving model ...
Validation loss decreased (1.241577 --> 1.234733).  Saving model ...
Validation loss decreased (1.234733 --> 1.227787).  Saving model ...
Validation loss decreased (1.227787 --> 1.221081).  Saving model ...
Validation loss decreased (1.221081 --> 1.214111).  Saving model ...
Validation loss decreased (1.214111 --> 1.206981).  Saving model ...
Validation loss decreased (1.206981 --> 1.200165).  Saving model ...
Validation loss decreased (1.200165 --> 1.193807).  Saving model ...
Validation loss decreased (1.193807 --> 1.187073).  Saving model ...
Validation loss decreased (1.187073 --> 1.180589).  Saving model ...
Validation loss decreased (1.180589 --> 1.174675).  Saving model ...
Validation loss decreased (1.174675 --> 1.169677).  Saving model ...
Validation loss decreased (1.169677 --> 1.163805).  Saving model ...
Validation loss decreased (1.163805 --> 1.159309).  Saving model ...
Validation loss decreased (1.159309 --> 1.152993).  Saving model ...
Validation loss decreased (1.152993 --> 1.146876).  Saving model ...
Validation loss decreased (1.146876 --> 1.140714).  Saving model ...
Validation loss decreased (1.140714 --> 1.136189).  Saving model ...
Validation loss decreased (1.136189 --> 1.128873).  Saving model ...
Validation loss decreased (1.128873 --> 1.125390).  Saving model ...
Validation loss decreased (1.125390 --> 1.122363).  Saving model ...
Validation loss decreased (1.122363 --> 1.114181).  Saving model ...
Validation loss decreased (1.114181 --> 1.108679).  Saving model ...
Validation loss decreased (1.108679 --> 1.105210).  Saving model ...
Validation loss decreased (1.105210 --> 1.100359).  Saving model ...
Validation loss decreased (1.100359 --> 1.094925).  Saving model ...
Validation loss decreased (1.094925 --> 1.091420).  Saving model ...
Validation loss decreased (1.091420 --> 1.086783).  Saving model ...
Validation loss decreased (1.086783 --> 1.082979).  Saving model ...
Validation loss decreased (1.082979 --> 1.076321).  Saving model ...
Validation loss decreased (1.076321 --> 1.074968).  Saving model ...
Validation loss decreased (1.074968 --> 1.070347).  Saving model ...
Validation loss decreased (1.070347 --> 1.067367).  Saving model ...
Validation loss decreased (1.067367 --> 1.063258).  Saving model ...
Validation loss decreased (1.063258 --> 1.056454).  Saving model ...
Validation loss decreased (1.056454 --> 1.052465).  Saving model ...
Validation loss decreased (1.052465 --> 1.046750).  Saving model ...
Validation loss decreased (1.046750 --> 1.044233).  Saving model ...
Validation loss decreased (1.044233 --> 1.040061).  Saving model ...
Validation loss decreased (1.040061 --> 1.039635).  Saving model ...
Validation loss decreased (1.039635 --> 1.035604).  Saving model ...
Validation loss decreased (1.035604 --> 1.033378).  Saving model ...
Validation loss decreased (1.033378 --> 1.030290).  Saving model ...
Validation loss decreased (1.030290 --> 1.026083).  Saving model ...
Validation loss decreased (1.026083 --> 1.023225).  Saving model ...
Validation loss decreased (1.023225 --> 1.018982).  Saving model ...
Validation loss decreased (1.018982 --> 1.016651).  Saving model ...
Validation loss decreased (1.016651 --> 1.014115).  Saving model ...
Validation loss decreased (1.014115 --> 1.011801).  Saving model ...
Validation loss decreased (1.011801 --> 1.008653).  Saving model ...
Validation loss decreased (1.008653 --> 1.004259).  Saving model ...
Validation loss decreased (1.004259 --> 1.003415).  Saving model ...
Validation loss decreased (1.003415 --> 1.001705).  Saving model ...
Validation loss decreased (1.001705 --> 1.000500).  Saving model ...
Validation loss decreased (1.000500 --> 0.996156).  Saving model ...
Validation loss decreased (0.996156 --> 0.994986).  Saving model ...
Validation loss decreased (0.994986 --> 0.993377).  Saving model ...
Validation loss decreased (0.993377 --> 0.992939).  Saving model ...
Validation loss decreased (0.992939 --> 0.990335).  Saving model ...
Validation loss decreased (0.990335 --> 0.988807).  Saving model ...
Validation loss decreased (0.988807 --> 0.988368).  Saving model ...
Validation loss decreased (0.988368 --> 0.985449).  Saving model ...
Validation loss decreased (0.985449 --> 0.984692).  Saving model ...
Validation loss decreased (0.984692 --> 0.983822).  Saving model ...
Validation loss decreased (0.983822 --> 0.981450).  Saving model ...
Validation loss decreased (0.981450 --> 0.977625).  Saving model ...
Validation loss decreased (0.977625 --> 0.975968).  Saving model ...
Validation loss decreased (0.975968 --> 0.973311).  Saving model ...
Validation loss decreased (0.973311 --> 0.973197).  Saving model ...
Validation loss decreased (0.973197 --> 0.970894).  Saving model ...
Validation loss decreased (0.970894 --> 0.968674).  Saving model ...
Validation loss decreased (0.968674 --> 0.965059).  Saving model ...
EarlyStopping counter: 1 out of 10.0
Validation loss decreased (0.965059 --> 0.964824).  Saving model ...
Validation loss decreased (0.964824 --> 0.963493).  Saving model ...
Validation loss decreased (0.963493 --> 0.963455).  Saving model ...
Validation loss decreased (0.963455 --> 0.962035).  Saving model ...
Validation loss decreased (0.962035 --> 0.960276).  Saving model ...
EarlyStopping counter: 1 out of 10.0
EarlyStopping counter: 2 out of 10.0
Validation loss decreased (0.960276 --> 0.958790).  Saving model ...
EarlyStopping counter: 1 out of 10.0
Validation loss decreased (0.958790 --> 0.958519).  Saving model ...
Validation loss decreased (0.958519 --> 0.957801).  Saving model ...
EarlyStopping counter: 1 out of 10.0
Validation loss decreased (0.957801 --> 0.957620).  Saving model ...
Validation loss decreased (0.957620 --> 0.957587).  Saving model ...
Validation loss decreased (0.957587 --> 0.955452).  Saving model ...
EarlyStopping counter: 1 out of 10.0
Validation loss decreased (0.955452 --> 0.954580).  Saving model ...
EarlyStopping counter: 1 out of 10.0
EarlyStopping counter: 2 out of 10.0
Validation loss decreased (0.954580 --> 0.953513).  Saving model ...
EarlyStopping counter: 1 out of 10.0
EarlyStopping counter: 2 out of 10.0
EarlyStopping counter: 3 out of 10.0
EarlyStopping counter: 4 out of 10.0
EarlyStopping counter: 5 out of 10.0
EarlyStopping counter: 6 out of 10.0
EarlyStopping counter: 7 out of 10.0
EarlyStopping counter: 8 out of 10.0
EarlyStopping counter: 9 out of 10.0
EarlyStopping counter: 10 out of 10.0
/localscratch/yinan.29019290.0/env/lib/python3.7/site-packages/torch/nn/functional.py:1794: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.
  warnings.warn("nn.functional.tanh is deprecated. Use torch.tanh instead.")
wandb: Waiting for W&B process to finish, PID 54889... (success).
wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: \ 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: | 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: / 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: \ 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: | 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: / 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: \ 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: | 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: / 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: \ 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: | 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb:                                                                                
wandb: Run history:
wandb:     e_F1 ▁▁▂▄▄▅▆▅▆▆▆▆▇▇▇▇▇▇▇▇▇▇███▇██████████████
wandb:   e_loss ██▇▇▇▇▆▆▆▅▅▅▄▄▄▄▃▃▃▃▂▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁
wandb:     t_F1 ▁▁▂▂▂▂▃▄▃▄▄▄▅▅▅▆▅▆▆▆▆▆▆▇▇▇▇▇▇█▇▇█▇██████
wandb:   t_loss █████▇▇▇▇▆▆▆▆▅▅▅▅▅▄▄▄▄▃▃▃▃▂▃▂▂▂▂▂▂▂▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:     e_F1 60.0122
wandb:   e_loss 0.95407
wandb:     t_F1 71.55614
wandb:   t_loss 0.75975
wandb: 
wandb: Synced 4 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Synced fancy-wildflower-2: https://wandb.ai/yinanazhou/xl_512_bs_8_lr_1e06_es_10_lc_True_nr_False_sr_False_stem_True_lemma_False_repeat_1_fold_2/runs/1xthdc3g
wandb: Find logs at: ./wandb/run-20220318_201614-1xthdc3g/logs/debug.log
wandb: 

wandb: wandb version 0.12.11 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
2022-03-18 21:44:43.410663: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1
wandb: Tracking run with wandb version 0.12.5
wandb: Syncing run drawn-darkness-2
wandb: ⭐️ View project at https://wandb.ai/yinanazhou/xl_512_bs_8_lr_1e06_es_10_lc_True_nr_False_sr_False_stem_True_lemma_False_repeat_2_fold_1
wandb: 🚀 View run at https://wandb.ai/yinanazhou/xl_512_bs_8_lr_1e06_es_10_lc_True_nr_False_sr_False_stem_True_lemma_False_repeat_2_fold_1/runs/1ks9hhrp
wandb: Run data is saved locally in /project/6002780/yinan/Thesis_MER_Lyrics/lyric-emotion/wandb/run-20220318_214440-1ks9hhrp
wandb: Run `wandb offline` to turn off syncing.

Validation loss decreased (inf --> 1.422357).  Saving model ...
Validation loss decreased (1.422357 --> 1.414368).  Saving model ...
Validation loss decreased (1.414368 --> 1.408107).  Saving model ...
Validation loss decreased (1.408107 --> 1.403023).  Saving model ...
Validation loss decreased (1.403023 --> 1.398641).  Saving model ...
Validation loss decreased (1.398641 --> 1.394770).  Saving model ...
Validation loss decreased (1.394770 --> 1.390796).  Saving model ...
Validation loss decreased (1.390796 --> 1.387105).  Saving model ...
Validation loss decreased (1.387105 --> 1.383599).  Saving model ...
Validation loss decreased (1.383599 --> 1.380164).  Saving model ...
Validation loss decreased (1.380164 --> 1.376648).  Saving model ...
Validation loss decreased (1.376648 --> 1.373104).  Saving model ...
Validation loss decreased (1.373104 --> 1.369504).  Saving model ...
Validation loss decreased (1.369504 --> 1.366255).  Saving model ...
Validation loss decreased (1.366255 --> 1.362435).  Saving model ...
Validation loss decreased (1.362435 --> 1.358428).  Saving model ...
Validation loss decreased (1.358428 --> 1.354512).  Saving model ...
Validation loss decreased (1.354512 --> 1.350506).  Saving model ...
Validation loss decreased (1.350506 --> 1.346165).  Saving model ...
Validation loss decreased (1.346165 --> 1.341509).  Saving model ...
Validation loss decreased (1.341509 --> 1.336990).  Saving model ...
Validation loss decreased (1.336990 --> 1.332318).  Saving model ...
Validation loss decreased (1.332318 --> 1.327133).  Saving model ...
Validation loss decreased (1.327133 --> 1.321132).  Saving model ...
Validation loss decreased (1.321132 --> 1.314579).  Saving model ...
Validation loss decreased (1.314579 --> 1.307496).  Saving model ...
Validation loss decreased (1.307496 --> 1.300237).  Saving model ...
Validation loss decreased (1.300237 --> 1.292738).  Saving model ...
Validation loss decreased (1.292738 --> 1.286126).  Saving model ...
Validation loss decreased (1.286126 --> 1.278083).  Saving model ...
Validation loss decreased (1.278083 --> 1.268853).  Saving model ...
Validation loss decreased (1.268853 --> 1.261356).  Saving model ...
Validation loss decreased (1.261356 --> 1.252811).  Saving model ...
Validation loss decreased (1.252811 --> 1.243111).  Saving model ...
Validation loss decreased (1.243111 --> 1.235225).  Saving model ...
Validation loss decreased (1.235225 --> 1.226568).  Saving model ...
Validation loss decreased (1.226568 --> 1.219390).  Saving model ...
Validation loss decreased (1.219390 --> 1.211069).  Saving model ...
Validation loss decreased (1.211069 --> 1.203299).  Saving model ...
Validation loss decreased (1.203299 --> 1.196678).  Saving model ...
Validation loss decreased (1.196678 --> 1.189382).  Saving model ...
Validation loss decreased (1.189382 --> 1.183628).  Saving model ...
Validation loss decreased (1.183628 --> 1.177509).  Saving model ...
Validation loss decreased (1.177509 --> 1.172376).  Saving model ...
Validation loss decreased (1.172376 --> 1.166155).  Saving model ...
Validation loss decreased (1.166155 --> 1.160655).  Saving model ...
Validation loss decreased (1.160655 --> 1.155040).  Saving model ...
Validation loss decreased (1.155040 --> 1.149048).  Saving model ...
Validation loss decreased (1.149048 --> 1.144916).  Saving model ...
Validation loss decreased (1.144916 --> 1.139636).  Saving model ...
Validation loss decreased (1.139636 --> 1.133875).  Saving model ...
Validation loss decreased (1.133875 --> 1.130747).  Saving model ...
Validation loss decreased (1.130747 --> 1.127031).  Saving model ...
Validation loss decreased (1.127031 --> 1.120911).  Saving model ...
Validation loss decreased (1.120911 --> 1.116390).  Saving model ...
Validation loss decreased (1.116390 --> 1.111999).  Saving model ...
Validation loss decreased (1.111999 --> 1.108126).  Saving model ...
Validation loss decreased (1.108126 --> 1.104526).  Saving model ...
Validation loss decreased (1.104526 --> 1.100656).  Saving model ...
Validation loss decreased (1.100656 --> 1.096385).  Saving model ...
Validation loss decreased (1.096385 --> 1.093714).  Saving model ...
Validation loss decreased (1.093714 --> 1.090810).  Saving model ...
Validation loss decreased (1.090810 --> 1.087497).  Saving model ...
Validation loss decreased (1.087497 --> 1.084362).  Saving model ...
Validation loss decreased (1.084362 --> 1.081348).  Saving model ...
Validation loss decreased (1.081348 --> 1.076025).  Saving model ...
Validation loss decreased (1.076025 --> 1.072266).  Saving model ...
Validation loss decreased (1.072266 --> 1.069082).  Saving model ...
Validation loss decreased (1.069082 --> 1.067437).  Saving model ...
Validation loss decreased (1.067437 --> 1.063531).  Saving model ...
Validation loss decreased (1.063531 --> 1.061628).  Saving model ...
Validation loss decreased (1.061628 --> 1.058757).  Saving model ...
Validation loss decreased (1.058757 --> 1.056176).  Saving model ...
Validation loss decreased (1.056176 --> 1.052949).  Saving model ...
Validation loss decreased (1.052949 --> 1.049874).  Saving model ...
Validation loss decreased (1.049874 --> 1.046548).  Saving model ...
Validation loss decreased (1.046548 --> 1.043790).  Saving model ...
Validation loss decreased (1.043790 --> 1.040618).  Saving model ...
Validation loss decreased (1.040618 --> 1.038763).  Saving model ...
Validation loss decreased (1.038763 --> 1.037124).  Saving model ...
Validation loss decreased (1.037124 --> 1.036127).  Saving model ...
Validation loss decreased (1.036127 --> 1.034196).  Saving model ...
Validation loss decreased (1.034196 --> 1.032288).  Saving model ...
Validation loss decreased (1.032288 --> 1.030705).  Saving model ...
Validation loss decreased (1.030705 --> 1.029128).  Saving model ...
Validation loss decreased (1.029128 --> 1.027507).  Saving model ...
Validation loss decreased (1.027507 --> 1.025289).  Saving model ...
Validation loss decreased (1.025289 --> 1.024589).  Saving model ...
Validation loss decreased (1.024589 --> 1.022238).  Saving model ...
Validation loss decreased (1.022238 --> 1.020709).  Saving model ...
Validation loss decreased (1.020709 --> 1.019293).  Saving model ...
Validation loss decreased (1.019293 --> 1.019128).  Saving model ...
Validation loss decreased (1.019128 --> 1.016681).  Saving model ...
Validation loss decreased (1.016681 --> 1.015181).  Saving model ...
Validation loss decreased (1.015181 --> 1.014704).  Saving model ...
Validation loss decreased (1.014704 --> 1.014088).  Saving model ...
Validation loss decreased (1.014088 --> 1.013356).  Saving model ...
Validation loss decreased (1.013356 --> 1.012489).  Saving model ...
Validation loss decreased (1.012489 --> 1.010661).  Saving model ...
Validation loss decreased (1.010661 --> 1.010352).  Saving model ...
Validation loss decreased (1.010352 --> 1.009998).  Saving model ...
Validation loss decreased (1.009998 --> 1.007963).  Saving model ...
Validation loss decreased (1.007963 --> 1.006839).  Saving model ...
Validation loss decreased (1.006839 --> 1.006286).  Saving model ...
Validation loss decreased (1.006286 --> 1.005956).  Saving model ...
EarlyStopping counter: 1 out of 10.0
Validation loss decreased (1.005956 --> 1.004986).  Saving model ...
Validation loss decreased (1.004986 --> 1.003908).  Saving model ...
Validation loss decreased (1.003908 --> 1.003271).  Saving model ...
EarlyStopping counter: 1 out of 10.0
Validation loss decreased (1.003271 --> 1.002304).  Saving model ...
Validation loss decreased (1.002304 --> 1.002124).  Saving model ...
Validation loss decreased (1.002124 --> 1.001275).  Saving model ...
Validation loss decreased (1.001275 --> 1.000642).  Saving model ...
EarlyStopping counter: 1 out of 10.0
Validation loss decreased (1.000642 --> 0.999779).  Saving model ...
EarlyStopping counter: 1 out of 10.0
EarlyStopping counter: 2 out of 10.0
Validation loss decreased (0.999779 --> 0.999301).  Saving model ...
Validation loss decreased (0.999301 --> 0.998164).  Saving model ...
Validation loss decreased (0.998164 --> 0.997912).  Saving model ...
EarlyStopping counter: 1 out of 10.0
EarlyStopping counter: 2 out of 10.0
Validation loss decreased (0.997912 --> 0.997904).  Saving model ...
EarlyStopping counter: 1 out of 10.0
EarlyStopping counter: 2 out of 10.0
EarlyStopping counter: 3 out of 10.0
EarlyStopping counter: 4 out of 10.0
EarlyStopping counter: 5 out of 10.0
Validation loss decreased (0.997904 --> 0.997666).  Saving model ...
Validation loss decreased (0.997666 --> 0.997580).  Saving model ...
EarlyStopping counter: 1 out of 10.0
EarlyStopping counter: 2 out of 10.0
EarlyStopping counter: 3 out of 10.0
EarlyStopping counter: 4 out of 10.0
Validation loss decreased (0.997580 --> 0.997449).  Saving model ...
EarlyStopping counter: 1 out of 10.0
EarlyStopping counter: 2 out of 10.0
EarlyStopping counter: 3 out of 10.0
EarlyStopping counter: 4 out of 10.0
EarlyStopping counter: 5 out of 10.0
EarlyStopping counter: 6 out of 10.0
EarlyStopping counter: 7 out of 10.0
EarlyStopping counter: 8 out of 10.0
EarlyStopping counter: 9 out of 10.0
EarlyStopping counter: 10 out of 10.0
/localscratch/yinan.29019290.0/env/lib/python3.7/site-packages/torch/nn/functional.py:1794: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.
  warnings.warn("nn.functional.tanh is deprecated. Use torch.tanh instead.")
wandb: Waiting for W&B process to finish, PID 59582... (success).
wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: \ 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: | 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: / 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: \ 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: | 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: / 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: \ 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: | 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: / 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb:                                                                                
wandb: Run history:
wandb:     e_F1 ▁▁▂▃▄▅▆▆▆▇▇▇▇▇▇▇█▇▇█████████████████████
wandb:   e_loss ███▇▇▇▆▆▆▅▅▄▄▃▃▃▃▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:     t_F1 ▁▁▂▃▃▃▃▄▅▄▅▅▆▆▆▆▆▇▇▇▇▇▇▇▇▇▇▇▇█████▇█████
wandb:   t_loss ███▇▇▇▇▇▆▆▆▆▅▅▅▅▄▄▄▄▄▃▃▃▃▃▂▃▂▂▂▂▂▂▂▂▂▁▁▁
wandb: 
wandb: Run summary:
wandb:     e_F1 58.33947
wandb:   e_loss 1.0002
wandb:     t_F1 73.29271
wandb:   t_loss 0.69829
wandb: 
wandb: Synced 4 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Synced drawn-darkness-2: https://wandb.ai/yinanazhou/xl_512_bs_8_lr_1e06_es_10_lc_True_nr_False_sr_False_stem_True_lemma_False_repeat_2_fold_1/runs/1ks9hhrp
wandb: Find logs at: ./wandb/run-20220318_214440-1ks9hhrp/logs/debug.log
wandb: 

wandb: wandb version 0.12.11 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
2022-03-18 23:21:22.747905: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1
wandb: Tracking run with wandb version 0.12.5
wandb: Syncing run winter-water-2
wandb: ⭐️ View project at https://wandb.ai/yinanazhou/xl_512_bs_8_lr_1e06_es_10_lc_True_nr_False_sr_False_stem_True_lemma_False_repeat_2_fold_2
wandb: 🚀 View run at https://wandb.ai/yinanazhou/xl_512_bs_8_lr_1e06_es_10_lc_True_nr_False_sr_False_stem_True_lemma_False_repeat_2_fold_2/runs/jv3zucrt
wandb: Run data is saved locally in /project/6002780/yinan/Thesis_MER_Lyrics/lyric-emotion/wandb/run-20220318_232119-jv3zucrt
wandb: Run `wandb offline` to turn off syncing.

Validation loss decreased (inf --> 1.406028).  Saving model ...
Validation loss decreased (1.406028 --> 1.399954).  Saving model ...
Validation loss decreased (1.399954 --> 1.394379).  Saving model ...
Validation loss decreased (1.394379 --> 1.389478).  Saving model ...
Validation loss decreased (1.389478 --> 1.385160).  Saving model ...
Validation loss decreased (1.385160 --> 1.381037).  Saving model ...
Validation loss decreased (1.381037 --> 1.377370).  Saving model ...
Validation loss decreased (1.377370 --> 1.373486).  Saving model ...
Validation loss decreased (1.373486 --> 1.369663).  Saving model ...
Validation loss decreased (1.369663 --> 1.366231).  Saving model ...
Validation loss decreased (1.366231 --> 1.362765).  Saving model ...
Validation loss decreased (1.362765 --> 1.359156).  Saving model ...
Validation loss decreased (1.359156 --> 1.355380).  Saving model ...
Validation loss decreased (1.355380 --> 1.351928).  Saving model ...
Validation loss decreased (1.351928 --> 1.348533).  Saving model ...
Validation loss decreased (1.348533 --> 1.344427).  Saving model ...
Validation loss decreased (1.344427 --> 1.340872).  Saving model ...
Validation loss decreased (1.340872 --> 1.337114).  Saving model ...
Validation loss decreased (1.337114 --> 1.332898).  Saving model ...
Validation loss decreased (1.332898 --> 1.328477).  Saving model ...
Validation loss decreased (1.328477 --> 1.324183).  Saving model ...
Validation loss decreased (1.324183 --> 1.320089).  Saving model ...
Validation loss decreased (1.320089 --> 1.315888).  Saving model ...
Validation loss decreased (1.315888 --> 1.310978).  Saving model ...
Validation loss decreased (1.310978 --> 1.305380).  Saving model ...
Validation loss decreased (1.305380 --> 1.299573).  Saving model ...
Validation loss decreased (1.299573 --> 1.293828).  Saving model ...
Validation loss decreased (1.293828 --> 1.288351).  Saving model ...
Validation loss decreased (1.288351 --> 1.282775).  Saving model ...
Validation loss decreased (1.282775 --> 1.277004).  Saving model ...
Validation loss decreased (1.277004 --> 1.270487).  Saving model ...
Validation loss decreased (1.270487 --> 1.263057).  Saving model ...
Validation loss decreased (1.263057 --> 1.254983).  Saving model ...
Validation loss decreased (1.254983 --> 1.248837).  Saving model ...
Validation loss decreased (1.248837 --> 1.241961).  Saving model ...
Validation loss decreased (1.241961 --> 1.235732).  Saving model ...
Validation loss decreased (1.235732 --> 1.228311).  Saving model ...
Validation loss decreased (1.228311 --> 1.222664).  Saving model ...
Validation loss decreased (1.222664 --> 1.214624).  Saving model ...
Validation loss decreased (1.214624 --> 1.208693).  Saving model ...
Validation loss decreased (1.208693 --> 1.202461).  Saving model ...
Validation loss decreased (1.202461 --> 1.196717).  Saving model ...
Validation loss decreased (1.196717 --> 1.190016).  Saving model ...
Validation loss decreased (1.190016 --> 1.184504).  Saving model ...
Validation loss decreased (1.184504 --> 1.179279).  Saving model ...
Validation loss decreased (1.179279 --> 1.172971).  Saving model ...
Validation loss decreased (1.172971 --> 1.167623).  Saving model ...
Validation loss decreased (1.167623 --> 1.161493).  Saving model ...
Validation loss decreased (1.161493 --> 1.155344).  Saving model ...
Validation loss decreased (1.155344 --> 1.150212).  Saving model ...
Validation loss decreased (1.150212 --> 1.143803).  Saving model ...
Validation loss decreased (1.143803 --> 1.138571).  Saving model ...
Validation loss decreased (1.138571 --> 1.134198).  Saving model ...
Validation loss decreased (1.134198 --> 1.128715).  Saving model ...
Validation loss decreased (1.128715 --> 1.122307).  Saving model ...
Validation loss decreased (1.122307 --> 1.117395).  Saving model ...
Validation loss decreased (1.117395 --> 1.113085).  Saving model ...
Validation loss decreased (1.113085 --> 1.108829).  Saving model ...
Validation loss decreased (1.108829 --> 1.103838).  Saving model ...
Validation loss decreased (1.103838 --> 1.099215).  Saving model ...
Validation loss decreased (1.099215 --> 1.094605).  Saving model ...
Validation loss decreased (1.094605 --> 1.088225).  Saving model ...
Validation loss decreased (1.088225 --> 1.085853).  Saving model ...
Validation loss decreased (1.085853 --> 1.080587).  Saving model ...
Validation loss decreased (1.080587 --> 1.077339).  Saving model ...
Validation loss decreased (1.077339 --> 1.071916).  Saving model ...
Validation loss decreased (1.071916 --> 1.069199).  Saving model ...
Validation loss decreased (1.069199 --> 1.064467).  Saving model ...
Validation loss decreased (1.064467 --> 1.062618).  Saving model ...
Validation loss decreased (1.062618 --> 1.056444).  Saving model ...
Validation loss decreased (1.056444 --> 1.053077).  Saving model ...
Validation loss decreased (1.053077 --> 1.049901).  Saving model ...
Validation loss decreased (1.049901 --> 1.046273).  Saving model ...
Validation loss decreased (1.046273 --> 1.042799).  Saving model ...
Validation loss decreased (1.042799 --> 1.041010).  Saving model ...
Validation loss decreased (1.041010 --> 1.036085).  Saving model ...
Validation loss decreased (1.036085 --> 1.033426).  Saving model ...
Validation loss decreased (1.033426 --> 1.031211).  Saving model ...
Validation loss decreased (1.031211 --> 1.027755).  Saving model ...
Validation loss decreased (1.027755 --> 1.027012).  Saving model ...
Validation loss decreased (1.027012 --> 1.023090).  Saving model ...
Validation loss decreased (1.023090 --> 1.018527).  Saving model ...
Validation loss decreased (1.018527 --> 1.017224).  Saving model ...
Validation loss decreased (1.017224 --> 1.017159).  Saving model ...
Validation loss decreased (1.017159 --> 1.011441).  Saving model ...
Validation loss decreased (1.011441 --> 1.006709).  Saving model ...
Validation loss decreased (1.006709 --> 1.005671).  Saving model ...
Validation loss decreased (1.005671 --> 1.000941).  Saving model ...
Validation loss decreased (1.000941 --> 0.998546).  Saving model ...
Validation loss decreased (0.998546 --> 0.994584).  Saving model ...
Validation loss decreased (0.994584 --> 0.993180).  Saving model ...
Validation loss decreased (0.993180 --> 0.992001).  Saving model ...
Validation loss decreased (0.992001 --> 0.988749).  Saving model ...
EarlyStopping counter: 1 out of 10.0
Validation loss decreased (0.988749 --> 0.985058).  Saving model ...
Validation loss decreased (0.985058 --> 0.982875).  Saving model ...
Validation loss decreased (0.982875 --> 0.980792).  Saving model ...
Validation loss decreased (0.980792 --> 0.980571).  Saving model ...
Validation loss decreased (0.980571 --> 0.980112).  Saving model ...
Validation loss decreased (0.980112 --> 0.977648).  Saving model ...
Validation loss decreased (0.977648 --> 0.975949).  Saving model ...
Validation loss decreased (0.975949 --> 0.974044).  Saving model ...
Validation loss decreased (0.974044 --> 0.972392).  Saving model ...
Validation loss decreased (0.972392 --> 0.969356).  Saving model ...
Validation loss decreased (0.969356 --> 0.967478).  Saving model ...
Validation loss decreased (0.967478 --> 0.965519).  Saving model ...
EarlyStopping counter: 1 out of 10.0
Validation loss decreased (0.965519 --> 0.965306).  Saving model ...
Validation loss decreased (0.965306 --> 0.963296).  Saving model ...
Validation loss decreased (0.963296 --> 0.962751).  Saving model ...
Validation loss decreased (0.962751 --> 0.962174).  Saving model ...
Validation loss decreased (0.962174 --> 0.960035).  Saving model ...
Validation loss decreased (0.960035 --> 0.955667).  Saving model ...
Validation loss decreased (0.955667 --> 0.955297).  Saving model ...
EarlyStopping counter: 1 out of 10.0
Validation loss decreased (0.955297 --> 0.953996).  Saving model ...
Validation loss decreased (0.953996 --> 0.952765).  Saving model ...
Validation loss decreased (0.952765 --> 0.952029).  Saving model ...
Validation loss decreased (0.952029 --> 0.950216).  Saving model ...
Validation loss decreased (0.950216 --> 0.947786).  Saving model ...
Validation loss decreased (0.947786 --> 0.946575).  Saving model ...
EarlyStopping counter: 1 out of 10.0
EarlyStopping counter: 2 out of 10.0
Validation loss decreased (0.946575 --> 0.945361).  Saving model ...
Validation loss decreased (0.945361 --> 0.943730).  Saving model ...
Validation loss decreased (0.943730 --> 0.942924).  Saving model ...
EarlyStopping counter: 1 out of 10.0
Validation loss decreased (0.942924 --> 0.941482).  Saving model ...
EarlyStopping counter: 1 out of 10.0
Validation loss decreased (0.941482 --> 0.940200).  Saving model ...
EarlyStopping counter: 1 out of 10.0
EarlyStopping counter: 2 out of 10.0
Validation loss decreased (0.940200 --> 0.939841).  Saving model ...
EarlyStopping counter: 1 out of 10.0
EarlyStopping counter: 2 out of 10.0
Validation loss decreased (0.939841 --> 0.937309).  Saving model ...
Validation loss decreased (0.937309 --> 0.936878).  Saving model ...
EarlyStopping counter: 1 out of 10.0
EarlyStopping counter: 2 out of 10.0
Validation loss decreased (0.936878 --> 0.936478).  Saving model ...
Validation loss decreased (0.936478 --> 0.936234).  Saving model ...
Validation loss decreased (0.936234 --> 0.935918).  Saving model ...
Validation loss decreased (0.935918 --> 0.934859).  Saving model ...
Validation loss decreased (0.934859 --> 0.933261).  Saving model ...
EarlyStopping counter: 1 out of 10.0
EarlyStopping counter: 2 out of 10.0
EarlyStopping counter: 3 out of 10.0
Validation loss decreased (0.933261 --> 0.931786).  Saving model ...
EarlyStopping counter: 1 out of 10.0
EarlyStopping counter: 2 out of 10.0
EarlyStopping counter: 3 out of 10.0
EarlyStopping counter: 4 out of 10.0
EarlyStopping counter: 5 out of 10.0
EarlyStopping counter: 6 out of 10.0
EarlyStopping counter: 7 out of 10.0
EarlyStopping counter: 8 out of 10.0
EarlyStopping counter: 9 out of 10.0
EarlyStopping counter: 10 out of 10.0
/localscratch/yinan.29019290.0/env/lib/python3.7/site-packages/torch/nn/functional.py:1794: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.
  warnings.warn("nn.functional.tanh is deprecated. Use torch.tanh instead.")
wandb: Waiting for W&B process to finish, PID 64729... (success).
wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: \ 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: | 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: / 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: \ 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: | 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: / 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: \ 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: | 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: / 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: \ 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb:                                                                                
wandb: Run history:
wandb:     e_F1 ▁▁▂▃▄▄▄▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇█████████████████
wandb:   e_loss ██▇▇▇▇▆▆▆▅▅▅▄▄▄▃▃▃▃▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:     t_F1 ▁▁▂▃▃▃▃▄▄▄▅▅▅▆▆▆▆▆▆▇▇▇▇▆▇▇▇▇▇▇█▇▇▇▇█▇███
wandb:   t_loss ██▇▇▇▇▇▇▆▆▆▅▅▅▅▄▄▄▄▄▃▃▃▃▃▂▃▂▂▂▂▂▂▂▂▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:     e_F1 61.12587
wandb:   e_loss 0.93266
wandb:     t_F1 70.67549
wandb:   t_loss 0.74894
wandb: 
wandb: Synced 4 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Synced winter-water-2: https://wandb.ai/yinanazhou/xl_512_bs_8_lr_1e06_es_10_lc_True_nr_False_sr_False_stem_True_lemma_False_repeat_2_fold_2/runs/jv3zucrt
wandb: Find logs at: ./wandb/run-20220318_232119-jv3zucrt/logs/debug.log
wandb: 

wandb: wandb version 0.12.11 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
2022-03-19 01:02:14.750243: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1
wandb: Tracking run with wandb version 0.12.5
wandb: Syncing run glad-voice-2
wandb: ⭐️ View project at https://wandb.ai/yinanazhou/xl_512_bs_8_lr_1e06_es_10_lc_True_nr_False_sr_False_stem_True_lemma_False_repeat_3_fold_1
wandb: 🚀 View run at https://wandb.ai/yinanazhou/xl_512_bs_8_lr_1e06_es_10_lc_True_nr_False_sr_False_stem_True_lemma_False_repeat_3_fold_1/runs/dwrrq6ar
wandb: Run data is saved locally in /project/6002780/yinan/Thesis_MER_Lyrics/lyric-emotion/wandb/run-20220319_010211-dwrrq6ar
wandb: Run `wandb offline` to turn off syncing.

Validation loss decreased (inf --> 1.421775).  Saving model ...
Validation loss decreased (1.421775 --> 1.404751).  Saving model ...
Validation loss decreased (1.404751 --> 1.390950).  Saving model ...
Validation loss decreased (1.390950 --> 1.378994).  Saving model ...
Validation loss decreased (1.378994 --> 1.370131).  Saving model ...
Validation loss decreased (1.370131 --> 1.363319).  Saving model ...
Validation loss decreased (1.363319 --> 1.356983).  Saving model ...
Validation loss decreased (1.356983 --> 1.351218).  Saving model ...
Validation loss decreased (1.351218 --> 1.346613).  Saving model ...
Validation loss decreased (1.346613 --> 1.342181).  Saving model ...
Validation loss decreased (1.342181 --> 1.338051).  Saving model ...
Validation loss decreased (1.338051 --> 1.333575).  Saving model ...
Validation loss decreased (1.333575 --> 1.329033).  Saving model ...
Validation loss decreased (1.329033 --> 1.324889).  Saving model ...
Validation loss decreased (1.324889 --> 1.320561).  Saving model ...
Validation loss decreased (1.320561 --> 1.316013).  Saving model ...
Validation loss decreased (1.316013 --> 1.311180).  Saving model ...
Validation loss decreased (1.311180 --> 1.306343).  Saving model ...
Validation loss decreased (1.306343 --> 1.301783).  Saving model ...
Validation loss decreased (1.301783 --> 1.296459).  Saving model ...
Validation loss decreased (1.296459 --> 1.291436).  Saving model ...
Validation loss decreased (1.291436 --> 1.286163).  Saving model ...
Validation loss decreased (1.286163 --> 1.281757).  Saving model ...
Validation loss decreased (1.281757 --> 1.276318).  Saving model ...
Validation loss decreased (1.276318 --> 1.270999).  Saving model ...
Validation loss decreased (1.270999 --> 1.264169).  Saving model ...
Validation loss decreased (1.264169 --> 1.258016).  Saving model ...
Validation loss decreased (1.258016 --> 1.252389).  Saving model ...
Validation loss decreased (1.252389 --> 1.244812).  Saving model ...
Validation loss decreased (1.244812 --> 1.238548).  Saving model ...
Validation loss decreased (1.238548 --> 1.232521).  Saving model ...
Validation loss decreased (1.232521 --> 1.225816).  Saving model ...
Validation loss decreased (1.225816 --> 1.218344).  Saving model ...
Validation loss decreased (1.218344 --> 1.213007).  Saving model ...
Validation loss decreased (1.213007 --> 1.206940).  Saving model ...
Validation loss decreased (1.206940 --> 1.201073).  Saving model ...
Validation loss decreased (1.201073 --> 1.193901).  Saving model ...
Validation loss decreased (1.193901 --> 1.188415).  Saving model ...
Validation loss decreased (1.188415 --> 1.180817).  Saving model ...
Validation loss decreased (1.180817 --> 1.173351).  Saving model ...
Validation loss decreased (1.173351 --> 1.166710).  Saving model ...
Validation loss decreased (1.166710 --> 1.158992).  Saving model ...
Validation loss decreased (1.158992 --> 1.153690).  Saving model ...
Validation loss decreased (1.153690 --> 1.146673).  Saving model ...
Validation loss decreased (1.146673 --> 1.139099).  Saving model ...
Validation loss decreased (1.139099 --> 1.134512).  Saving model ...
Validation loss decreased (1.134512 --> 1.130514).  Saving model ...
Validation loss decreased (1.130514 --> 1.126200).  Saving model ...
Validation loss decreased (1.126200 --> 1.119924).  Saving model ...
Validation loss decreased (1.119924 --> 1.117435).  Saving model ...
Validation loss decreased (1.117435 --> 1.112152).  Saving model ...
Validation loss decreased (1.112152 --> 1.109877).  Saving model ...
Validation loss decreased (1.109877 --> 1.106985).  Saving model ...
Validation loss decreased (1.106985 --> 1.101151).  Saving model ...
Validation loss decreased (1.101151 --> 1.096391).  Saving model ...
Validation loss decreased (1.096391 --> 1.092425).  Saving model ...
Validation loss decreased (1.092425 --> 1.088001).  Saving model ...
Validation loss decreased (1.088001 --> 1.084757).  Saving model ...
Validation loss decreased (1.084757 --> 1.081263).  Saving model ...
Validation loss decreased (1.081263 --> 1.078635).  Saving model ...
Validation loss decreased (1.078635 --> 1.072316).  Saving model ...
Validation loss decreased (1.072316 --> 1.069160).  Saving model ...
Validation loss decreased (1.069160 --> 1.068389).  Saving model ...
Validation loss decreased (1.068389 --> 1.065908).  Saving model ...
Validation loss decreased (1.065908 --> 1.062809).  Saving model ...
Validation loss decreased (1.062809 --> 1.061290).  Saving model ...
Validation loss decreased (1.061290 --> 1.058104).  Saving model ...
Validation loss decreased (1.058104 --> 1.056720).  Saving model ...
Validation loss decreased (1.056720 --> 1.052112).  Saving model ...
Validation loss decreased (1.052112 --> 1.048834).  Saving model ...
Validation loss decreased (1.048834 --> 1.044205).  Saving model ...
EarlyStopping counter: 1 out of 10.0
Validation loss decreased (1.044205 --> 1.042481).  Saving model ...
Validation loss decreased (1.042481 --> 1.038259).  Saving model ...
Validation loss decreased (1.038259 --> 1.036273).  Saving model ...
EarlyStopping counter: 1 out of 10.0
Validation loss decreased (1.036273 --> 1.035840).  Saving model ...
EarlyStopping counter: 1 out of 10.0
Validation loss decreased (1.035840 --> 1.032954).  Saving model ...
Validation loss decreased (1.032954 --> 1.026072).  Saving model ...
Validation loss decreased (1.026072 --> 1.023430).  Saving model ...
Validation loss decreased (1.023430 --> 1.021801).  Saving model ...
Validation loss decreased (1.021801 --> 1.018718).  Saving model ...
Validation loss decreased (1.018718 --> 1.017249).  Saving model ...
EarlyStopping counter: 1 out of 10.0
Validation loss decreased (1.017249 --> 1.016298).  Saving model ...
EarlyStopping counter: 1 out of 10.0
Validation loss decreased (1.016298 --> 1.014326).  Saving model ...
Validation loss decreased (1.014326 --> 1.009941).  Saving model ...
Validation loss decreased (1.009941 --> 1.006967).  Saving model ...
Validation loss decreased (1.006967 --> 1.005305).  Saving model ...
EarlyStopping counter: 1 out of 10.0
Validation loss decreased (1.005305 --> 1.005013).  Saving model ...
Validation loss decreased (1.005013 --> 1.004794).  Saving model ...
Validation loss decreased (1.004794 --> 1.003858).  Saving model ...
Validation loss decreased (1.003858 --> 1.002710).  Saving model ...
Validation loss decreased (1.002710 --> 1.000575).  Saving model ...
EarlyStopping counter: 1 out of 10.0
Validation loss decreased (1.000575 --> 0.998401).  Saving model ...
Validation loss decreased (0.998401 --> 0.995062).  Saving model ...
EarlyStopping counter: 1 out of 10.0
Validation loss decreased (0.995062 --> 0.994916).  Saving model ...
Validation loss decreased (0.994916 --> 0.992695).  Saving model ...
Validation loss decreased (0.992695 --> 0.991455).  Saving model ...
EarlyStopping counter: 1 out of 10.0
EarlyStopping counter: 2 out of 10.0
Validation loss decreased (0.991455 --> 0.990671).  Saving model ...
EarlyStopping counter: 1 out of 10.0
Validation loss decreased (0.990671 --> 0.990594).  Saving model ...
Validation loss decreased (0.990594 --> 0.989788).  Saving model ...
Validation loss decreased (0.989788 --> 0.988784).  Saving model ...
Validation loss decreased (0.988784 --> 0.986960).  Saving model ...
Validation loss decreased (0.986960 --> 0.984891).  Saving model ...
EarlyStopping counter: 1 out of 10.0
Validation loss decreased (0.984891 --> 0.983315).  Saving model ...
Validation loss decreased (0.983315 --> 0.979540).  Saving model ...
EarlyStopping counter: 1 out of 10.0
EarlyStopping counter: 2 out of 10.0
EarlyStopping counter: 3 out of 10.0
EarlyStopping counter: 4 out of 10.0
EarlyStopping counter: 5 out of 10.0
Validation loss decreased (0.979540 --> 0.978954).  Saving model ...
Validation loss decreased (0.978954 --> 0.978619).  Saving model ...
Validation loss decreased (0.978619 --> 0.975993).  Saving model ...
Validation loss decreased (0.975993 --> 0.975385).  Saving model ...
EarlyStopping counter: 1 out of 10.0
EarlyStopping counter: 2 out of 10.0
Validation loss decreased (0.975385 --> 0.975035).  Saving model ...
EarlyStopping counter: 1 out of 10.0
EarlyStopping counter: 2 out of 10.0
Validation loss decreased (0.975035 --> 0.973944).  Saving model ...
Validation loss decreased (0.973944 --> 0.972190).  Saving model ...
EarlyStopping counter: 1 out of 10.0
EarlyStopping counter: 2 out of 10.0
EarlyStopping counter: 3 out of 10.0
EarlyStopping counter: 4 out of 10.0
EarlyStopping counter: 5 out of 10.0
Validation loss decreased (0.972190 --> 0.971512).  Saving model ...
EarlyStopping counter: 1 out of 10.0
Validation loss decreased (0.971512 --> 0.970416).  Saving model ...
EarlyStopping counter: 1 out of 10.0
EarlyStopping counter: 2 out of 10.0
EarlyStopping counter: 3 out of 10.0
EarlyStopping counter: 4 out of 10.0
EarlyStopping counter: 5 out of 10.0
EarlyStopping counter: 6 out of 10.0
EarlyStopping counter: 7 out of 10.0
Validation loss decreased (0.970416 --> 0.968347).  Saving model ...
EarlyStopping counter: 1 out of 10.0
EarlyStopping counter: 2 out of 10.0
Validation loss decreased (0.968347 --> 0.967257).  Saving model ...
EarlyStopping counter: 1 out of 10.0
EarlyStopping counter: 2 out of 10.0
EarlyStopping counter: 3 out of 10.0
EarlyStopping counter: 4 out of 10.0
EarlyStopping counter: 5 out of 10.0
EarlyStopping counter: 6 out of 10.0
EarlyStopping counter: 7 out of 10.0
EarlyStopping counter: 8 out of 10.0
EarlyStopping counter: 9 out of 10.0
EarlyStopping counter: 10 out of 10.0
/localscratch/yinan.29019290.0/env/lib/python3.7/site-packages/torch/nn/functional.py:1794: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.
  warnings.warn("nn.functional.tanh is deprecated. Use torch.tanh instead.")
wandb: Waiting for W&B process to finish, PID 70126... (success).
wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: \ 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: | 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: / 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: \ 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: | 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: / 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: \ 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: | 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: / 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb:                                                                                
wandb: Run history:
wandb:     e_F1 ▁▂▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇▇██████████████████████
wandb:   e_loss █▇▇▇▆▆▆▅▅▅▄▄▃▃▃▃▂▂▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:     t_F1 ▁▂▃▃▃▄▄▄▄▅▅▅▅▆▅▆▆▆▆▇▇▇▇▇▇▇▇▇▇▇▇█████████
wandb:   t_loss ██▇▇▇▇▆▆▆▆▅▅▅▄▅▄▄▄▄▃▃▃▃▃▃▃▂▂▂▂▂▂▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:     e_F1 58.29386
wandb:   e_loss 0.97408
wandb:     t_F1 76.39893
wandb:   t_loss 0.68537
wandb: 
wandb: Synced 4 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Synced glad-voice-2: https://wandb.ai/yinanazhou/xl_512_bs_8_lr_1e06_es_10_lc_True_nr_False_sr_False_stem_True_lemma_False_repeat_3_fold_1/runs/dwrrq6ar
wandb: Find logs at: ./wandb/run-20220319_010211-dwrrq6ar/logs/debug.log
wandb: 

wandb: wandb version 0.12.11 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
2022-03-19 02:48:10.244764: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1
wandb: Tracking run with wandb version 0.12.5
wandb: Syncing run drawn-plasma-2
wandb: ⭐️ View project at https://wandb.ai/yinanazhou/xl_512_bs_8_lr_1e06_es_10_lc_True_nr_False_sr_False_stem_True_lemma_False_repeat_3_fold_2
wandb: 🚀 View run at https://wandb.ai/yinanazhou/xl_512_bs_8_lr_1e06_es_10_lc_True_nr_False_sr_False_stem_True_lemma_False_repeat_3_fold_2/runs/3u6idqpe
wandb: Run data is saved locally in /project/6002780/yinan/Thesis_MER_Lyrics/lyric-emotion/wandb/run-20220319_024806-3u6idqpe
wandb: Run `wandb offline` to turn off syncing.

Validation loss decreased (inf --> 1.525895).  Saving model ...
Validation loss decreased (1.525895 --> 1.487617).  Saving model ...
Validation loss decreased (1.487617 --> 1.457324).  Saving model ...
Validation loss decreased (1.457324 --> 1.433049).  Saving model ...
Validation loss decreased (1.433049 --> 1.413656).  Saving model ...
Validation loss decreased (1.413656 --> 1.398341).  Saving model ...
Validation loss decreased (1.398341 --> 1.385517).  Saving model ...
Validation loss decreased (1.385517 --> 1.376504).  Saving model ...
Validation loss decreased (1.376504 --> 1.369638).  Saving model ...
Validation loss decreased (1.369638 --> 1.364344).  Saving model ...
Validation loss decreased (1.364344 --> 1.359609).  Saving model ...
Validation loss decreased (1.359609 --> 1.354657).  Saving model ...
Validation loss decreased (1.354657 --> 1.349975).  Saving model ...
Validation loss decreased (1.349975 --> 1.345752).  Saving model ...
Validation loss decreased (1.345752 --> 1.341653).  Saving model ...
Validation loss decreased (1.341653 --> 1.337341).  Saving model ...
Validation loss decreased (1.337341 --> 1.332325).  Saving model ...
Validation loss decreased (1.332325 --> 1.327542).  Saving model ...
Validation loss decreased (1.327542 --> 1.322814).  Saving model ...
Validation loss decreased (1.322814 --> 1.317954).  Saving model ...
Validation loss decreased (1.317954 --> 1.313286).  Saving model ...
Validation loss decreased (1.313286 --> 1.308060).  Saving model ...
Validation loss decreased (1.308060 --> 1.303286).  Saving model ...
Validation loss decreased (1.303286 --> 1.297424).  Saving model ...
Validation loss decreased (1.297424 --> 1.291382).  Saving model ...
Validation loss decreased (1.291382 --> 1.286574).  Saving model ...
Validation loss decreased (1.286574 --> 1.280663).  Saving model ...
Validation loss decreased (1.280663 --> 1.274552).  Saving model ...
Validation loss decreased (1.274552 --> 1.268064).  Saving model ...
Validation loss decreased (1.268064 --> 1.262019).  Saving model ...
Validation loss decreased (1.262019 --> 1.256531).  Saving model ...
Validation loss decreased (1.256531 --> 1.249921).  Saving model ...
Validation loss decreased (1.249921 --> 1.244131).  Saving model ...
Validation loss decreased (1.244131 --> 1.236696).  Saving model ...
Validation loss decreased (1.236696 --> 1.228844).  Saving model ...
Validation loss decreased (1.228844 --> 1.221526).  Saving model ...
Validation loss decreased (1.221526 --> 1.215866).  Saving model ...
Validation loss decreased (1.215866 --> 1.210424).  Saving model ...
Validation loss decreased (1.210424 --> 1.204273).  Saving model ...
Validation loss decreased (1.204273 --> 1.199095).  Saving model ...
Validation loss decreased (1.199095 --> 1.194343).  Saving model ...
Validation loss decreased (1.194343 --> 1.186615).  Saving model ...
Validation loss decreased (1.186615 --> 1.179971).  Saving model ...
Validation loss decreased (1.179971 --> 1.175049).  Saving model ...
Validation loss decreased (1.175049 --> 1.169425).  Saving model ...
Validation loss decreased (1.169425 --> 1.164583).  Saving model ...
Validation loss decreased (1.164583 --> 1.159425).  Saving model ...
Validation loss decreased (1.159425 --> 1.153445).  Saving model ...
Validation loss decreased (1.153445 --> 1.147582).  Saving model ...
Validation loss decreased (1.147582 --> 1.143459).  Saving model ...
Validation loss decreased (1.143459 --> 1.137497).  Saving model ...
Validation loss decreased (1.137497 --> 1.131976).  Saving model ...
Validation loss decreased (1.131976 --> 1.127621).  Saving model ...
Validation loss decreased (1.127621 --> 1.122979).  Saving model ...
Validation loss decreased (1.122979 --> 1.118943).  Saving model ...
Validation loss decreased (1.118943 --> 1.115483).  Saving model ...
Validation loss decreased (1.115483 --> 1.111016).  Saving model ...
Validation loss decreased (1.111016 --> 1.105281).  Saving model ...
Validation loss decreased (1.105281 --> 1.099255).  Saving model ...
Validation loss decreased (1.099255 --> 1.094502).  Saving model ...
Validation loss decreased (1.094502 --> 1.090914).  Saving model ...
Validation loss decreased (1.090914 --> 1.086122).  Saving model ...
Validation loss decreased (1.086122 --> 1.081692).  Saving model ...
Validation loss decreased (1.081692 --> 1.077214).  Saving model ...
Validation loss decreased (1.077214 --> 1.075266).  Saving model ...
Validation loss decreased (1.075266 --> 1.071882).  Saving model ...
Validation loss decreased (1.071882 --> 1.068358).  Saving model ...
Validation loss decreased (1.068358 --> 1.065033).  Saving model ...
Validation loss decreased (1.065033 --> 1.061118).  Saving model ...
Validation loss decreased (1.061118 --> 1.057608).  Saving model ...
Validation loss decreased (1.057608 --> 1.055312).  Saving model ...
Validation loss decreased (1.055312 --> 1.051548).  Saving model ...
Validation loss decreased (1.051548 --> 1.048566).  Saving model ...
Validation loss decreased (1.048566 --> 1.046888).  Saving model ...
Validation loss decreased (1.046888 --> 1.045527).  Saving model ...
Validation loss decreased (1.045527 --> 1.043421).  Saving model ...
EarlyStopping counter: 1 out of 10.0
Validation loss decreased (1.043421 --> 1.039906).  Saving model ...
Validation loss decreased (1.039906 --> 1.035576).  Saving model ...
Validation loss decreased (1.035576 --> 1.034427).  Saving model ...
Validation loss decreased (1.034427 --> 1.030779).  Saving model ...
Validation loss decreased (1.030779 --> 1.027959).  Saving model ...
Validation loss decreased (1.027959 --> 1.025471).  Saving model ...
Validation loss decreased (1.025471 --> 1.024271).  Saving model ...
Validation loss decreased (1.024271 --> 1.022050).  Saving model ...
Validation loss decreased (1.022050 --> 1.019382).  Saving model ...
Validation loss decreased (1.019382 --> 1.018777).  Saving model ...
Validation loss decreased (1.018777 --> 1.017181).  Saving model ...
Validation loss decreased (1.017181 --> 1.016424).  Saving model ...
Validation loss decreased (1.016424 --> 1.012076).  Saving model ...
Validation loss decreased (1.012076 --> 1.011521).  Saving model ...
Validation loss decreased (1.011521 --> 1.009421).  Saving model ...
Validation loss decreased (1.009421 --> 1.006390).  Saving model ...
Validation loss decreased (1.006390 --> 1.005947).  Saving model ...
Validation loss decreased (1.005947 --> 1.005056).  Saving model ...
Validation loss decreased (1.005056 --> 1.003825).  Saving model ...
Validation loss decreased (1.003825 --> 1.001088).  Saving model ...
Validation loss decreased (1.001088 --> 0.998750).  Saving model ...
EarlyStopping counter: 1 out of 10.0
EarlyStopping counter: 2 out of 10.0
Validation loss decreased (0.998750 --> 0.998628).  Saving model ...
EarlyStopping counter: 1 out of 10.0
Validation loss decreased (0.998628 --> 0.998072).  Saving model ...
Validation loss decreased (0.998072 --> 0.996439).  Saving model ...
EarlyStopping counter: 1 out of 10.0
Validation loss decreased (0.996439 --> 0.995074).  Saving model ...
Validation loss decreased (0.995074 --> 0.992230).  Saving model ...
Validation loss decreased (0.992230 --> 0.992046).  Saving model ...
Validation loss decreased (0.992046 --> 0.990426).  Saving model ...
EarlyStopping counter: 1 out of 10.0
Validation loss decreased (0.990426 --> 0.990183).  Saving model ...
EarlyStopping counter: 1 out of 10.0
EarlyStopping counter: 2 out of 10.0
Validation loss decreased (0.990183 --> 0.989467).  Saving model ...
Validation loss decreased (0.989467 --> 0.988918).  Saving model ...
EarlyStopping counter: 1 out of 10.0
Validation loss decreased (0.988918 --> 0.987523).  Saving model ...
Validation loss decreased (0.987523 --> 0.986268).  Saving model ...
EarlyStopping counter: 1 out of 10.0
EarlyStopping counter: 2 out of 10.0
Validation loss decreased (0.986268 --> 0.984924).  Saving model ...
EarlyStopping counter: 1 out of 10.0
EarlyStopping counter: 2 out of 10.0
Validation loss decreased (0.984924 --> 0.981696).  Saving model ...
EarlyStopping counter: 1 out of 10.0
Validation loss decreased (0.981696 --> 0.980446).  Saving model ...
EarlyStopping counter: 1 out of 10.0
EarlyStopping counter: 2 out of 10.0
EarlyStopping counter: 3 out of 10.0
Validation loss decreased (0.980446 --> 0.979833).  Saving model ...
EarlyStopping counter: 1 out of 10.0
Validation loss decreased (0.979833 --> 0.979341).  Saving model ...
Validation loss decreased (0.979341 --> 0.979063).  Saving model ...
EarlyStopping counter: 1 out of 10.0
EarlyStopping counter: 2 out of 10.0
EarlyStopping counter: 3 out of 10.0
EarlyStopping counter: 4 out of 10.0
EarlyStopping counter: 5 out of 10.0
EarlyStopping counter: 6 out of 10.0
EarlyStopping counter: 7 out of 10.0
EarlyStopping counter: 8 out of 10.0
EarlyStopping counter: 9 out of 10.0
EarlyStopping counter: 10 out of 10.0
/localscratch/yinan.29019290.0/env/lib/python3.7/site-packages/torch/nn/functional.py:1794: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.
  warnings.warn("nn.functional.tanh is deprecated. Use torch.tanh instead.")
wandb: Waiting for W&B process to finish, PID 75864... (success).
wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: \ 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: | 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: / 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: \ 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: | 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: / 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: \ 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: | 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: / 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb:                                                                                
wandb: Run history:
wandb:     e_F1 ▁▁▄▄▄▅▅▅▆▆▆▆▆▇▇▇▇▇▇▇▇▇██████████████████
wandb:   e_loss █▇▆▆▆▆▆▅▅▅▄▄▄▃▃▃▃▂▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:     t_F1 ▁▂▃▃▄▄▄▄▅▅▅▆▆▆▆▆▆▆▆▆▇▇▇▇▇▇▇▇▇▇▇█▇██▇█▇██
wandb:   t_loss ██▇▇▆▆▆▆▆▆▆▅▅▅▄▄▄▄▄▄▃▃▃▃▃▃▃▂▂▂▂▂▂▂▂▂▂▂▁▁
wandb: 
wandb: Run summary:
wandb:     e_F1 59.72209
wandb:   e_loss 0.98412
wandb:     t_F1 69.50412
wandb:   t_loss 0.74767
wandb: 
wandb: Synced 4 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Synced drawn-plasma-2: https://wandb.ai/yinanazhou/xl_512_bs_8_lr_1e06_es_10_lc_True_nr_False_sr_False_stem_True_lemma_False_repeat_3_fold_2/runs/3u6idqpe
wandb: Find logs at: ./wandb/run-20220319_024806-3u6idqpe/logs/debug.log
wandb: 

wandb: wandb version 0.12.11 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
2022-03-19 04:20:41.626691: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1
wandb: Tracking run with wandb version 0.12.5
wandb: Syncing run comfy-river-2
wandb: ⭐️ View project at https://wandb.ai/yinanazhou/xl_512_bs_8_lr_1e06_es_10_lc_True_nr_False_sr_False_stem_True_lemma_False_repeat_4_fold_1
wandb: 🚀 View run at https://wandb.ai/yinanazhou/xl_512_bs_8_lr_1e06_es_10_lc_True_nr_False_sr_False_stem_True_lemma_False_repeat_4_fold_1/runs/1uvld4rd
wandb: Run data is saved locally in /project/6002780/yinan/Thesis_MER_Lyrics/lyric-emotion/wandb/run-20220319_042038-1uvld4rd
wandb: Run `wandb offline` to turn off syncing.

Validation loss decreased (inf --> 1.404624).  Saving model ...
Validation loss decreased (1.404624 --> 1.391467).  Saving model ...
Validation loss decreased (1.391467 --> 1.381618).  Saving model ...
Validation loss decreased (1.381618 --> 1.373255).  Saving model ...
Validation loss decreased (1.373255 --> 1.366909).  Saving model ...
Validation loss decreased (1.366909 --> 1.361240).  Saving model ...
Validation loss decreased (1.361240 --> 1.356278).  Saving model ...
Validation loss decreased (1.356278 --> 1.351593).  Saving model ...
Validation loss decreased (1.351593 --> 1.347431).  Saving model ...
Validation loss decreased (1.347431 --> 1.343127).  Saving model ...
Validation loss decreased (1.343127 --> 1.338906).  Saving model ...
Validation loss decreased (1.338906 --> 1.334344).  Saving model ...
Validation loss decreased (1.334344 --> 1.329944).  Saving model ...
Validation loss decreased (1.329944 --> 1.325505).  Saving model ...
Validation loss decreased (1.325505 --> 1.320849).  Saving model ...
Validation loss decreased (1.320849 --> 1.315726).  Saving model ...
Validation loss decreased (1.315726 --> 1.310473).  Saving model ...
Validation loss decreased (1.310473 --> 1.305326).  Saving model ...
Validation loss decreased (1.305326 --> 1.299544).  Saving model ...
Validation loss decreased (1.299544 --> 1.293915).  Saving model ...
Validation loss decreased (1.293915 --> 1.288355).  Saving model ...
Validation loss decreased (1.288355 --> 1.282178).  Saving model ...
Validation loss decreased (1.282178 --> 1.276217).  Saving model ...
Validation loss decreased (1.276217 --> 1.270285).  Saving model ...
Validation loss decreased (1.270285 --> 1.263588).  Saving model ...
Validation loss decreased (1.263588 --> 1.256096).  Saving model ...
Validation loss decreased (1.256096 --> 1.249592).  Saving model ...
Validation loss decreased (1.249592 --> 1.243147).  Saving model ...
Validation loss decreased (1.243147 --> 1.236302).  Saving model ...
Validation loss decreased (1.236302 --> 1.230293).  Saving model ...
Validation loss decreased (1.230293 --> 1.223450).  Saving model ...
Validation loss decreased (1.223450 --> 1.217239).  Saving model ...
Validation loss decreased (1.217239 --> 1.211148).  Saving model ...
Validation loss decreased (1.211148 --> 1.205018).  Saving model ...
Validation loss decreased (1.205018 --> 1.198044).  Saving model ...
Validation loss decreased (1.198044 --> 1.191985).  Saving model ...
Validation loss decreased (1.191985 --> 1.185668).  Saving model ...
Validation loss decreased (1.185668 --> 1.179711).  Saving model ...
Validation loss decreased (1.179711 --> 1.173590).  Saving model ...
Validation loss decreased (1.173590 --> 1.168784).  Saving model ...
Validation loss decreased (1.168784 --> 1.163569).  Saving model ...
Validation loss decreased (1.163569 --> 1.158034).  Saving model ...
Validation loss decreased (1.158034 --> 1.152155).  Saving model ...
Validation loss decreased (1.152155 --> 1.146987).  Saving model ...
Validation loss decreased (1.146987 --> 1.142157).  Saving model ...
Validation loss decreased (1.142157 --> 1.136614).  Saving model ...
Validation loss decreased (1.136614 --> 1.131681).  Saving model ...
Validation loss decreased (1.131681 --> 1.126569).  Saving model ...
Validation loss decreased (1.126569 --> 1.121686).  Saving model ...
Validation loss decreased (1.121686 --> 1.117439).  Saving model ...
Validation loss decreased (1.117439 --> 1.113067).  Saving model ...
Validation loss decreased (1.113067 --> 1.107520).  Saving model ...
Validation loss decreased (1.107520 --> 1.103337).  Saving model ...
Validation loss decreased (1.103337 --> 1.099347).  Saving model ...
Validation loss decreased (1.099347 --> 1.095258).  Saving model ...
Validation loss decreased (1.095258 --> 1.091136).  Saving model ...
Validation loss decreased (1.091136 --> 1.086513).  Saving model ...
Validation loss decreased (1.086513 --> 1.081295).  Saving model ...
Validation loss decreased (1.081295 --> 1.077619).  Saving model ...
Validation loss decreased (1.077619 --> 1.073428).  Saving model ...
Validation loss decreased (1.073428 --> 1.069174).  Saving model ...
Validation loss decreased (1.069174 --> 1.065836).  Saving model ...
Validation loss decreased (1.065836 --> 1.062842).  Saving model ...
Validation loss decreased (1.062842 --> 1.059167).  Saving model ...
Validation loss decreased (1.059167 --> 1.055935).  Saving model ...
Validation loss decreased (1.055935 --> 1.053457).  Saving model ...
Validation loss decreased (1.053457 --> 1.049241).  Saving model ...
Validation loss decreased (1.049241 --> 1.045715).  Saving model ...
Validation loss decreased (1.045715 --> 1.042581).  Saving model ...
Validation loss decreased (1.042581 --> 1.039755).  Saving model ...
Validation loss decreased (1.039755 --> 1.036442).  Saving model ...
Validation loss decreased (1.036442 --> 1.034042).  Saving model ...
Validation loss decreased (1.034042 --> 1.031068).  Saving model ...
Validation loss decreased (1.031068 --> 1.028793).  Saving model ...
Validation loss decreased (1.028793 --> 1.025274).  Saving model ...
Validation loss decreased (1.025274 --> 1.022110).  Saving model ...
Validation loss decreased (1.022110 --> 1.019615).  Saving model ...
Validation loss decreased (1.019615 --> 1.017861).  Saving model ...
Validation loss decreased (1.017861 --> 1.015550).  Saving model ...
Validation loss decreased (1.015550 --> 1.013641).  Saving model ...
Validation loss decreased (1.013641 --> 1.010972).  Saving model ...
Validation loss decreased (1.010972 --> 1.009339).  Saving model ...
Validation loss decreased (1.009339 --> 1.007711).  Saving model ...
Validation loss decreased (1.007711 --> 1.006643).  Saving model ...
Validation loss decreased (1.006643 --> 1.004842).  Saving model ...
Validation loss decreased (1.004842 --> 1.001609).  Saving model ...
Validation loss decreased (1.001609 --> 0.998729).  Saving model ...
Validation loss decreased (0.998729 --> 0.996547).  Saving model ...
Validation loss decreased (0.996547 --> 0.994647).  Saving model ...
EarlyStopping counter: 1 out of 10.0
Validation loss decreased (0.994647 --> 0.993020).  Saving model ...
Validation loss decreased (0.993020 --> 0.992183).  Saving model ...
Validation loss decreased (0.992183 --> 0.990102).  Saving model ...
Validation loss decreased (0.990102 --> 0.988512).  Saving model ...
EarlyStopping counter: 1 out of 10.0
Validation loss decreased (0.988512 --> 0.984853).  Saving model ...
EarlyStopping counter: 1 out of 10.0
Validation loss decreased (0.984853 --> 0.983353).  Saving model ...
Validation loss decreased (0.983353 --> 0.982823).  Saving model ...
Validation loss decreased (0.982823 --> 0.982383).  Saving model ...
Validation loss decreased (0.982383 --> 0.980442).  Saving model ...
Validation loss decreased (0.980442 --> 0.979182).  Saving model ...
Validation loss decreased (0.979182 --> 0.977683).  Saving model ...
Validation loss decreased (0.977683 --> 0.977059).  Saving model ...
Validation loss decreased (0.977059 --> 0.975594).  Saving model ...
Validation loss decreased (0.975594 --> 0.973926).  Saving model ...
Validation loss decreased (0.973926 --> 0.971776).  Saving model ...
Validation loss decreased (0.971776 --> 0.970864).  Saving model ...
EarlyStopping counter: 1 out of 10.0
Validation loss decreased (0.970864 --> 0.969781).  Saving model ...
Validation loss decreased (0.969781 --> 0.969571).  Saving model ...
Validation loss decreased (0.969571 --> 0.968393).  Saving model ...
Validation loss decreased (0.968393 --> 0.967960).  Saving model ...
Validation loss decreased (0.967960 --> 0.965881).  Saving model ...
EarlyStopping counter: 1 out of 10.0
Validation loss decreased (0.965881 --> 0.965369).  Saving model ...
EarlyStopping counter: 1 out of 10.0
EarlyStopping counter: 2 out of 10.0
EarlyStopping counter: 3 out of 10.0
EarlyStopping counter: 4 out of 10.0
Validation loss decreased (0.965369 --> 0.965202).  Saving model ...
Validation loss decreased (0.965202 --> 0.964749).  Saving model ...
Validation loss decreased (0.964749 --> 0.963477).  Saving model ...
Validation loss decreased (0.963477 --> 0.962317).  Saving model ...
EarlyStopping counter: 1 out of 10.0
Validation loss decreased (0.962317 --> 0.961030).  Saving model ...
EarlyStopping counter: 1 out of 10.0
EarlyStopping counter: 2 out of 10.0
EarlyStopping counter: 3 out of 10.0
Validation loss decreased (0.961030 --> 0.958802).  Saving model ...
EarlyStopping counter: 1 out of 10.0
EarlyStopping counter: 2 out of 10.0
EarlyStopping counter: 3 out of 10.0
EarlyStopping counter: 4 out of 10.0
EarlyStopping counter: 5 out of 10.0
EarlyStopping counter: 6 out of 10.0
EarlyStopping counter: 7 out of 10.0
EarlyStopping counter: 8 out of 10.0
EarlyStopping counter: 9 out of 10.0
EarlyStopping counter: 10 out of 10.0
/localscratch/yinan.29019290.0/env/lib/python3.7/site-packages/torch/nn/functional.py:1794: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.
  warnings.warn("nn.functional.tanh is deprecated. Use torch.tanh instead.")
wandb: Waiting for W&B process to finish, PID 80854... (success).
wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: \ 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: | 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: / 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: \ 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: | 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: / 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: \ 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: | 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: / 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb:                                                                                
wandb: Run history:
wandb:     e_F1 ▁▂▄▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇▇▇▇█▇▇████████████████
wandb:   e_loss ██▇▇▇▇▆▆▅▅▅▄▄▄▄▃▃▃▃▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:     t_F1 ▁▁▂▃▄▃▄▄▄▅▄▅▅▆▆▆▆▆▆▆▆▇▆▇▇▇▇▇▇▇▇▇▇▇██▇▇▇█
wandb:   t_loss ███▇▇▇▇▆▆▆▆▅▅▅▅▄▄▄▄▄▄▃▃▃▃▃▂▂▂▂▂▂▂▂▂▁▁▂▁▁
wandb: 
wandb: Run summary:
wandb:     e_F1 58.56978
wandb:   e_loss 0.95972
wandb:     t_F1 73.22675
wandb:   t_loss 0.74649
wandb: 
wandb: Synced 4 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Synced comfy-river-2: https://wandb.ai/yinanazhou/xl_512_bs_8_lr_1e06_es_10_lc_True_nr_False_sr_False_stem_True_lemma_False_repeat_4_fold_1/runs/1uvld4rd
wandb: Find logs at: ./wandb/run-20220319_042038-1uvld4rd/logs/debug.log
wandb: 

wandb: wandb version 0.12.11 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
2022-03-19 05:53:11.836174: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1
wandb: Tracking run with wandb version 0.12.5
wandb: Syncing run dandy-donkey-2
wandb: ⭐️ View project at https://wandb.ai/yinanazhou/xl_512_bs_8_lr_1e06_es_10_lc_True_nr_False_sr_False_stem_True_lemma_False_repeat_4_fold_2
wandb: 🚀 View run at https://wandb.ai/yinanazhou/xl_512_bs_8_lr_1e06_es_10_lc_True_nr_False_sr_False_stem_True_lemma_False_repeat_4_fold_2/runs/2tfht8fd
wandb: Run data is saved locally in /project/6002780/yinan/Thesis_MER_Lyrics/lyric-emotion/wandb/run-20220319_055308-2tfht8fd
wandb: Run `wandb offline` to turn off syncing.

Validation loss decreased (inf --> 1.387662).  Saving model ...
Validation loss decreased (1.387662 --> 1.377979).  Saving model ...
Validation loss decreased (1.377979 --> 1.371554).  Saving model ...
Validation loss decreased (1.371554 --> 1.366525).  Saving model ...
Validation loss decreased (1.366525 --> 1.362266).  Saving model ...
Validation loss decreased (1.362266 --> 1.358452).  Saving model ...
Validation loss decreased (1.358452 --> 1.354801).  Saving model ...
Validation loss decreased (1.354801 --> 1.351629).  Saving model ...
Validation loss decreased (1.351629 --> 1.348475).  Saving model ...
Validation loss decreased (1.348475 --> 1.345191).  Saving model ...
Validation loss decreased (1.345191 --> 1.341912).  Saving model ...
Validation loss decreased (1.341912 --> 1.338674).  Saving model ...
Validation loss decreased (1.338674 --> 1.335556).  Saving model ...
Validation loss decreased (1.335556 --> 1.331989).  Saving model ...
Validation loss decreased (1.331989 --> 1.328117).  Saving model ...
Validation loss decreased (1.328117 --> 1.324141).  Saving model ...
Validation loss decreased (1.324141 --> 1.319978).  Saving model ...
Validation loss decreased (1.319978 --> 1.315770).  Saving model ...
Validation loss decreased (1.315770 --> 1.311518).  Saving model ...
Validation loss decreased (1.311518 --> 1.306841).  Saving model ...
Validation loss decreased (1.306841 --> 1.302205).  Saving model ...
Validation loss decreased (1.302205 --> 1.297897).  Saving model ...
Validation loss decreased (1.297897 --> 1.292950).  Saving model ...
Validation loss decreased (1.292950 --> 1.287948).  Saving model ...
Validation loss decreased (1.287948 --> 1.282213).  Saving model ...
Validation loss decreased (1.282213 --> 1.276130).  Saving model ...
Validation loss decreased (1.276130 --> 1.270402).  Saving model ...
Validation loss decreased (1.270402 --> 1.264383).  Saving model ...
Validation loss decreased (1.264383 --> 1.256638).  Saving model ...
Validation loss decreased (1.256638 --> 1.249814).  Saving model ...
Validation loss decreased (1.249814 --> 1.241997).  Saving model ...
Validation loss decreased (1.241997 --> 1.233699).  Saving model ...
Validation loss decreased (1.233699 --> 1.225519).  Saving model ...
Validation loss decreased (1.225519 --> 1.216855).  Saving model ...
Validation loss decreased (1.216855 --> 1.209034).  Saving model ...
Validation loss decreased (1.209034 --> 1.199884).  Saving model ...
Validation loss decreased (1.199884 --> 1.191902).  Saving model ...
Validation loss decreased (1.191902 --> 1.184186).  Saving model ...
Validation loss decreased (1.184186 --> 1.178017).  Saving model ...
Validation loss decreased (1.178017 --> 1.170435).  Saving model ...
Validation loss decreased (1.170435 --> 1.163154).  Saving model ...
Validation loss decreased (1.163154 --> 1.156510).  Saving model ...
Validation loss decreased (1.156510 --> 1.148756).  Saving model ...
Validation loss decreased (1.148756 --> 1.142409).  Saving model ...
Validation loss decreased (1.142409 --> 1.135877).  Saving model ...
Validation loss decreased (1.135877 --> 1.127473).  Saving model ...
Validation loss decreased (1.127473 --> 1.121313).  Saving model ...
Validation loss decreased (1.121313 --> 1.114808).  Saving model ...
Validation loss decreased (1.114808 --> 1.108764).  Saving model ...
Validation loss decreased (1.108764 --> 1.102441).  Saving model ...
Validation loss decreased (1.102441 --> 1.098213).  Saving model ...
Validation loss decreased (1.098213 --> 1.094290).  Saving model ...
Validation loss decreased (1.094290 --> 1.089677).  Saving model ...
Validation loss decreased (1.089677 --> 1.085611).  Saving model ...
Validation loss decreased (1.085611 --> 1.079989).  Saving model ...
Validation loss decreased (1.079989 --> 1.076019).  Saving model ...
Validation loss decreased (1.076019 --> 1.072186).  Saving model ...
Validation loss decreased (1.072186 --> 1.067939).  Saving model ...
Validation loss decreased (1.067939 --> 1.064728).  Saving model ...
Validation loss decreased (1.064728 --> 1.061684).  Saving model ...
Validation loss decreased (1.061684 --> 1.058417).  Saving model ...
Validation loss decreased (1.058417 --> 1.052372).  Saving model ...
Validation loss decreased (1.052372 --> 1.049780).  Saving model ...
Validation loss decreased (1.049780 --> 1.045714).  Saving model ...
Validation loss decreased (1.045714 --> 1.041655).  Saving model ...
Validation loss decreased (1.041655 --> 1.037344).  Saving model ...
Validation loss decreased (1.037344 --> 1.034050).  Saving model ...
Validation loss decreased (1.034050 --> 1.031334).  Saving model ...
Validation loss decreased (1.031334 --> 1.027243).  Saving model ...
Validation loss decreased (1.027243 --> 1.024385).  Saving model ...
Validation loss decreased (1.024385 --> 1.023226).  Saving model ...
Validation loss decreased (1.023226 --> 1.020528).  Saving model ...
Validation loss decreased (1.020528 --> 1.018460).  Saving model ...
Validation loss decreased (1.018460 --> 1.014538).  Saving model ...
Validation loss decreased (1.014538 --> 1.011317).  Saving model ...
Validation loss decreased (1.011317 --> 1.010499).  Saving model ...
Validation loss decreased (1.010499 --> 1.007907).  Saving model ...
Validation loss decreased (1.007907 --> 1.005046).  Saving model ...
Validation loss decreased (1.005046 --> 1.002985).  Saving model ...
Validation loss decreased (1.002985 --> 1.000135).  Saving model ...
Validation loss decreased (1.000135 --> 0.998713).  Saving model ...
Validation loss decreased (0.998713 --> 0.997257).  Saving model ...
Validation loss decreased (0.997257 --> 0.996012).  Saving model ...
Validation loss decreased (0.996012 --> 0.992288).  Saving model ...
Validation loss decreased (0.992288 --> 0.988382).  Saving model ...
Validation loss decreased (0.988382 --> 0.987894).  Saving model ...
Validation loss decreased (0.987894 --> 0.985960).  Saving model ...
Validation loss decreased (0.985960 --> 0.982710).  Saving model ...
Validation loss decreased (0.982710 --> 0.982107).  Saving model ...
Validation loss decreased (0.982107 --> 0.981659).  Saving model ...
Validation loss decreased (0.981659 --> 0.980584).  Saving model ...
Validation loss decreased (0.980584 --> 0.979432).  Saving model ...
Validation loss decreased (0.979432 --> 0.976111).  Saving model ...
Validation loss decreased (0.976111 --> 0.975519).  Saving model ...
Validation loss decreased (0.975519 --> 0.973686).  Saving model ...
Validation loss decreased (0.973686 --> 0.970804).  Saving model ...
EarlyStopping counter: 1 out of 10.0
EarlyStopping counter: 2 out of 10.0
EarlyStopping counter: 3 out of 10.0
Validation loss decreased (0.970804 --> 0.969849).  Saving model ...
Validation loss decreased (0.969849 --> 0.968787).  Saving model ...
Validation loss decreased (0.968787 --> 0.967286).  Saving model ...
Validation loss decreased (0.967286 --> 0.965254).  Saving model ...
Validation loss decreased (0.965254 --> 0.963992).  Saving model ...
Validation loss decreased (0.963992 --> 0.961775).  Saving model ...
EarlyStopping counter: 1 out of 10.0
EarlyStopping counter: 2 out of 10.0
EarlyStopping counter: 3 out of 10.0
Validation loss decreased (0.961775 --> 0.961403).  Saving model ...
Validation loss decreased (0.961403 --> 0.960024).  Saving model ...
Validation loss decreased (0.960024 --> 0.959704).  Saving model ...
Validation loss decreased (0.959704 --> 0.958579).  Saving model ...
Validation loss decreased (0.958579 --> 0.957001).  Saving model ...
Validation loss decreased (0.957001 --> 0.954516).  Saving model ...
Validation loss decreased (0.954516 --> 0.953310).  Saving model ...
EarlyStopping counter: 1 out of 10.0
EarlyStopping counter: 2 out of 10.0
Validation loss decreased (0.953310 --> 0.953049).  Saving model ...
EarlyStopping counter: 1 out of 10.0
EarlyStopping counter: 2 out of 10.0
EarlyStopping counter: 3 out of 10.0
EarlyStopping counter: 4 out of 10.0
EarlyStopping counter: 5 out of 10.0
Validation loss decreased (0.953049 --> 0.953019).  Saving model ...
Validation loss decreased (0.953019 --> 0.951909).  Saving model ...
EarlyStopping counter: 1 out of 10.0
EarlyStopping counter: 2 out of 10.0
EarlyStopping counter: 3 out of 10.0
Validation loss decreased (0.951909 --> 0.951802).  Saving model ...
Validation loss decreased (0.951802 --> 0.950514).  Saving model ...
EarlyStopping counter: 1 out of 10.0
Validation loss decreased (0.950514 --> 0.950025).  Saving model ...
EarlyStopping counter: 1 out of 10.0
EarlyStopping counter: 2 out of 10.0
EarlyStopping counter: 3 out of 10.0
EarlyStopping counter: 4 out of 10.0
EarlyStopping counter: 5 out of 10.0
Validation loss decreased (0.950025 --> 0.949417).  Saving model ...
EarlyStopping counter: 1 out of 10.0
EarlyStopping counter: 2 out of 10.0
EarlyStopping counter: 3 out of 10.0
EarlyStopping counter: 4 out of 10.0
EarlyStopping counter: 5 out of 10.0
EarlyStopping counter: 6 out of 10.0
EarlyStopping counter: 7 out of 10.0
EarlyStopping counter: 8 out of 10.0
EarlyStopping counter: 9 out of 10.0
EarlyStopping counter: 10 out of 10.0
/localscratch/yinan.29019290.0/env/lib/python3.7/site-packages/torch/nn/functional.py:1794: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.
  warnings.warn("nn.functional.tanh is deprecated. Use torch.tanh instead.")
wandb: Waiting for W&B process to finish, PID 85770... (success).
wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: \ 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: | 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: / 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: \ 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: | 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: / 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: \ 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: | 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: / 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb:                                                                                
wandb: Run history:
wandb:     e_F1 ▁▃▅▅▅▅▅▅▆▆▆▆▇▇▇▇▇▇██████████████████████
wandb:   e_loss ███▇▇▇▇▆▆▅▅▄▄▃▃▃▃▃▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:     t_F1 ▁▁▂▂▂▃▂▃▅▄▅▅▆▆▅▆▆▆▆▆▇▆▇▆▆▇▇▇▇▇▇▇▇▇█▇████
wandb:   t_loss ████▇▇▇▇▆▆▆▆▅▅▅▄▄▄▄▄▄▃▃▃▃▃▃▂▂▂▂▂▂▂▂▂▁▁▁▁
wandb: 
wandb: Run summary:
wandb:     e_F1 60.67906
wandb:   e_loss 0.95373
wandb:     t_F1 73.15837
wandb:   t_loss 0.72453
wandb: 
wandb: Synced 4 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Synced dandy-donkey-2: https://wandb.ai/yinanazhou/xl_512_bs_8_lr_1e06_es_10_lc_True_nr_False_sr_False_stem_True_lemma_False_repeat_4_fold_2/runs/2tfht8fd
wandb: Find logs at: ./wandb/run-20220319_055308-2tfht8fd/logs/debug.log
wandb: 

wandb: wandb version 0.12.11 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
2022-03-19 07:30:31.283922: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1
wandb: Tracking run with wandb version 0.12.5
wandb: Syncing run azure-firefly-2
wandb: ⭐️ View project at https://wandb.ai/yinanazhou/xl_512_bs_8_lr_1e06_es_10_lc_True_nr_False_sr_False_stem_True_lemma_False_repeat_5_fold_1
wandb: 🚀 View run at https://wandb.ai/yinanazhou/xl_512_bs_8_lr_1e06_es_10_lc_True_nr_False_sr_False_stem_True_lemma_False_repeat_5_fold_1/runs/16jtacti
wandb: Run data is saved locally in /project/6002780/yinan/Thesis_MER_Lyrics/lyric-emotion/wandb/run-20220319_073028-16jtacti
wandb: Run `wandb offline` to turn off syncing.

Validation loss decreased (inf --> 1.400073).  Saving model ...
Validation loss decreased (1.400073 --> 1.392246).  Saving model ...
Validation loss decreased (1.392246 --> 1.386171).  Saving model ...
Validation loss decreased (1.386171 --> 1.381627).  Saving model ...
Validation loss decreased (1.381627 --> 1.377524).  Saving model ...
Validation loss decreased (1.377524 --> 1.373801).  Saving model ...
Validation loss decreased (1.373801 --> 1.370401).  Saving model ...
Validation loss decreased (1.370401 --> 1.367221).  Saving model ...
Validation loss decreased (1.367221 --> 1.364049).  Saving model ...
Validation loss decreased (1.364049 --> 1.360991).  Saving model ...
Validation loss decreased (1.360991 --> 1.357609).  Saving model ...
Validation loss decreased (1.357609 --> 1.354394).  Saving model ...
Validation loss decreased (1.354394 --> 1.351304).  Saving model ...
Validation loss decreased (1.351304 --> 1.348137).  Saving model ...
Validation loss decreased (1.348137 --> 1.344800).  Saving model ...
Validation loss decreased (1.344800 --> 1.341145).  Saving model ...
Validation loss decreased (1.341145 --> 1.337216).  Saving model ...
Validation loss decreased (1.337216 --> 1.333601).  Saving model ...
Validation loss decreased (1.333601 --> 1.329683).  Saving model ...
Validation loss decreased (1.329683 --> 1.325661).  Saving model ...
Validation loss decreased (1.325661 --> 1.321650).  Saving model ...
Validation loss decreased (1.321650 --> 1.316328).  Saving model ...
Validation loss decreased (1.316328 --> 1.311649).  Saving model ...
Validation loss decreased (1.311649 --> 1.307352).  Saving model ...
Validation loss decreased (1.307352 --> 1.302720).  Saving model ...
Validation loss decreased (1.302720 --> 1.297321).  Saving model ...
Validation loss decreased (1.297321 --> 1.291727).  Saving model ...
Validation loss decreased (1.291727 --> 1.285958).  Saving model ...
Validation loss decreased (1.285958 --> 1.279774).  Saving model ...
Validation loss decreased (1.279774 --> 1.273419).  Saving model ...
Validation loss decreased (1.273419 --> 1.267174).  Saving model ...
Validation loss decreased (1.267174 --> 1.261497).  Saving model ...
Validation loss decreased (1.261497 --> 1.255072).  Saving model ...
Validation loss decreased (1.255072 --> 1.247237).  Saving model ...
Validation loss decreased (1.247237 --> 1.240194).  Saving model ...
Validation loss decreased (1.240194 --> 1.232679).  Saving model ...
Validation loss decreased (1.232679 --> 1.225942).  Saving model ...
Validation loss decreased (1.225942 --> 1.218861).  Saving model ...
Validation loss decreased (1.218861 --> 1.211900).  Saving model ...
Validation loss decreased (1.211900 --> 1.205812).  Saving model ...
Validation loss decreased (1.205812 --> 1.199565).  Saving model ...
Validation loss decreased (1.199565 --> 1.193158).  Saving model ...
Validation loss decreased (1.193158 --> 1.188275).  Saving model ...
Validation loss decreased (1.188275 --> 1.181577).  Saving model ...
Validation loss decreased (1.181577 --> 1.176554).  Saving model ...
Validation loss decreased (1.176554 --> 1.171942).  Saving model ...
Validation loss decreased (1.171942 --> 1.167403).  Saving model ...
Validation loss decreased (1.167403 --> 1.161076).  Saving model ...
Validation loss decreased (1.161076 --> 1.155474).  Saving model ...
Validation loss decreased (1.155474 --> 1.150921).  Saving model ...
Validation loss decreased (1.150921 --> 1.146891).  Saving model ...
Validation loss decreased (1.146891 --> 1.142605).  Saving model ...
Validation loss decreased (1.142605 --> 1.138233).  Saving model ...
Validation loss decreased (1.138233 --> 1.133853).  Saving model ...
Validation loss decreased (1.133853 --> 1.129468).  Saving model ...
Validation loss decreased (1.129468 --> 1.125055).  Saving model ...
Validation loss decreased (1.125055 --> 1.121138).  Saving model ...
Validation loss decreased (1.121138 --> 1.116925).  Saving model ...
Validation loss decreased (1.116925 --> 1.112743).  Saving model ...
Validation loss decreased (1.112743 --> 1.109908).  Saving model ...
Validation loss decreased (1.109908 --> 1.106688).  Saving model ...
Validation loss decreased (1.106688 --> 1.102584).  Saving model ...
Validation loss decreased (1.102584 --> 1.098788).  Saving model ...
Validation loss decreased (1.098788 --> 1.094882).  Saving model ...
Validation loss decreased (1.094882 --> 1.090868).  Saving model ...
Validation loss decreased (1.090868 --> 1.088210).  Saving model ...
Validation loss decreased (1.088210 --> 1.084769).  Saving model ...
Validation loss decreased (1.084769 --> 1.081466).  Saving model ...
Validation loss decreased (1.081466 --> 1.078441).  Saving model ...
Validation loss decreased (1.078441 --> 1.074635).  Saving model ...
Validation loss decreased (1.074635 --> 1.070839).  Saving model ...
Validation loss decreased (1.070839 --> 1.068339).  Saving model ...
Validation loss decreased (1.068339 --> 1.065330).  Saving model ...
Validation loss decreased (1.065330 --> 1.061883).  Saving model ...
Validation loss decreased (1.061883 --> 1.059536).  Saving model ...
Validation loss decreased (1.059536 --> 1.055473).  Saving model ...
Validation loss decreased (1.055473 --> 1.051885).  Saving model ...
Validation loss decreased (1.051885 --> 1.050051).  Saving model ...
Validation loss decreased (1.050051 --> 1.047617).  Saving model ...
Validation loss decreased (1.047617 --> 1.045725).  Saving model ...
Validation loss decreased (1.045725 --> 1.044517).  Saving model ...
Validation loss decreased (1.044517 --> 1.041764).  Saving model ...
Validation loss decreased (1.041764 --> 1.037947).  Saving model ...
Validation loss decreased (1.037947 --> 1.037076).  Saving model ...
Validation loss decreased (1.037076 --> 1.036910).  Saving model ...
Validation loss decreased (1.036910 --> 1.034369).  Saving model ...
Validation loss decreased (1.034369 --> 1.033976).  Saving model ...
Validation loss decreased (1.033976 --> 1.031013).  Saving model ...
Validation loss decreased (1.031013 --> 1.028571).  Saving model ...
EarlyStopping counter: 1 out of 10.0
Validation loss decreased (1.028571 --> 1.024709).  Saving model ...
Validation loss decreased (1.024709 --> 1.021593).  Saving model ...
Validation loss decreased (1.021593 --> 1.021252).  Saving model ...
Validation loss decreased (1.021252 --> 1.020104).  Saving model ...
Validation loss decreased (1.020104 --> 1.018108).  Saving model ...
Validation loss decreased (1.018108 --> 1.014840).  Saving model ...
Validation loss decreased (1.014840 --> 1.014129).  Saving model ...
Validation loss decreased (1.014129 --> 1.010726).  Saving model ...
Validation loss decreased (1.010726 --> 1.009471).  Saving model ...
EarlyStopping counter: 1 out of 10.0
Validation loss decreased (1.009471 --> 1.006495).  Saving model ...
EarlyStopping counter: 1 out of 10.0
Validation loss decreased (1.006495 --> 1.004649).  Saving model ...
Validation loss decreased (1.004649 --> 1.003379).  Saving model ...
EarlyStopping counter: 1 out of 10.0
EarlyStopping counter: 2 out of 10.0
EarlyStopping counter: 3 out of 10.0
Validation loss decreased (1.003379 --> 1.001411).  Saving model ...
Validation loss decreased (1.001411 --> 0.999407).  Saving model ...
EarlyStopping counter: 1 out of 10.0
EarlyStopping counter: 2 out of 10.0
Validation loss decreased (0.999407 --> 0.995427).  Saving model ...
Validation loss decreased (0.995427 --> 0.993599).  Saving model ...
EarlyStopping counter: 1 out of 10.0
Validation loss decreased (0.993599 --> 0.991766).  Saving model ...
Validation loss decreased (0.991766 --> 0.991040).  Saving model ...
EarlyStopping counter: 1 out of 10.0
EarlyStopping counter: 2 out of 10.0
Validation loss decreased (0.991040 --> 0.990263).  Saving model ...
Validation loss decreased (0.990263 --> 0.990153).  Saving model ...
EarlyStopping counter: 1 out of 10.0
EarlyStopping counter: 2 out of 10.0
EarlyStopping counter: 3 out of 10.0
EarlyStopping counter: 4 out of 10.0
EarlyStopping counter: 5 out of 10.0
EarlyStopping counter: 6 out of 10.0
EarlyStopping counter: 7 out of 10.0
EarlyStopping counter: 8 out of 10.0
EarlyStopping counter: 9 out of 10.0
EarlyStopping counter: 10 out of 10.0
/localscratch/yinan.29019290.0/env/lib/python3.7/site-packages/torch/nn/functional.py:1794: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.
  warnings.warn("nn.functional.tanh is deprecated. Use torch.tanh instead.")
wandb: Waiting for W&B process to finish, PID 90951... (success).
wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: \ 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: | 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: / 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: \ 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: | 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: / 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: \ 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: | 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: / 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb:                                                                                
wandb: Run history:
wandb:     e_F1 ▁▂▃▄▄▅▅▅▅▆▆▆▆▆▇▆▇▇▇▇▇▇▇▇▇▇▇▇▇███████████
wandb:   e_loss ███▇▇▇▇▇▆▆▅▅▅▄▄▄▄▃▃▃▃▂▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁
wandb:     t_F1 ▁▁▂▃▃▃▄▃▄▄▅▅▅▆▅▆▆▅▆▆▆▇▇▆▇▇▇▇▇▇▇██▇██████
wandb:   t_loss ███▇▇▇▇▇▇▆▆▆▆▅▅▅▅▅▄▄▄▄▃▄▃▃▃▃▃▃▂▂▂▂▂▂▂▁▁▁
wandb: 
wandb: Run summary:
wandb:     e_F1 57.71034
wandb:   e_loss 0.99036
wandb:     t_F1 68.53018
wandb:   t_loss 0.8125
wandb: 
wandb: Synced 4 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Synced azure-firefly-2: https://wandb.ai/yinanazhou/xl_512_bs_8_lr_1e06_es_10_lc_True_nr_False_sr_False_stem_True_lemma_False_repeat_5_fold_1/runs/16jtacti
wandb: Find logs at: ./wandb/run-20220319_073028-16jtacti/logs/debug.log
wandb: 

wandb: wandb version 0.12.11 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
2022-03-19 08:56:28.034219: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1
wandb: Tracking run with wandb version 0.12.5
wandb: Syncing run copper-aardvark-2
wandb: ⭐️ View project at https://wandb.ai/yinanazhou/xl_512_bs_8_lr_1e06_es_10_lc_True_nr_False_sr_False_stem_True_lemma_False_repeat_5_fold_2
wandb: 🚀 View run at https://wandb.ai/yinanazhou/xl_512_bs_8_lr_1e06_es_10_lc_True_nr_False_sr_False_stem_True_lemma_False_repeat_5_fold_2/runs/3l1fsaar
wandb: Run data is saved locally in /project/6002780/yinan/Thesis_MER_Lyrics/lyric-emotion/wandb/run-20220319_085623-3l1fsaar
wandb: Run `wandb offline` to turn off syncing.

Validation loss decreased (inf --> 1.439480).  Saving model ...
Validation loss decreased (1.439480 --> 1.419599).  Saving model ...
Validation loss decreased (1.419599 --> 1.405434).  Saving model ...
Validation loss decreased (1.405434 --> 1.393282).  Saving model ...
Validation loss decreased (1.393282 --> 1.384031).  Saving model ...
Validation loss decreased (1.384031 --> 1.376814).  Saving model ...
Validation loss decreased (1.376814 --> 1.370828).  Saving model ...
Validation loss decreased (1.370828 --> 1.365462).  Saving model ...
Validation loss decreased (1.365462 --> 1.361060).  Saving model ...
Validation loss decreased (1.361060 --> 1.356834).  Saving model ...
Validation loss decreased (1.356834 --> 1.352706).  Saving model ...
Validation loss decreased (1.352706 --> 1.348293).  Saving model ...
Validation loss decreased (1.348293 --> 1.344145).  Saving model ...
Validation loss decreased (1.344145 --> 1.339532).  Saving model ...
Validation loss decreased (1.339532 --> 1.335666).  Saving model ...
Validation loss decreased (1.335666 --> 1.331226).  Saving model ...
Validation loss decreased (1.331226 --> 1.327120).  Saving model ...
Validation loss decreased (1.327120 --> 1.322404).  Saving model ...
Validation loss decreased (1.322404 --> 1.317528).  Saving model ...
Validation loss decreased (1.317528 --> 1.312942).  Saving model ...
Validation loss decreased (1.312942 --> 1.307963).  Saving model ...
Validation loss decreased (1.307963 --> 1.302179).  Saving model ...
Validation loss decreased (1.302179 --> 1.297473).  Saving model ...
Validation loss decreased (1.297473 --> 1.291622).  Saving model ...
Validation loss decreased (1.291622 --> 1.286166).  Saving model ...
Validation loss decreased (1.286166 --> 1.280130).  Saving model ...
Validation loss decreased (1.280130 --> 1.274785).  Saving model ...
Validation loss decreased (1.274785 --> 1.268552).  Saving model ...
Validation loss decreased (1.268552 --> 1.261848).  Saving model ...
Validation loss decreased (1.261848 --> 1.254509).  Saving model ...
Validation loss decreased (1.254509 --> 1.247857).  Saving model ...
Validation loss decreased (1.247857 --> 1.241527).  Saving model ...
Validation loss decreased (1.241527 --> 1.233415).  Saving model ...
Validation loss decreased (1.233415 --> 1.225613).  Saving model ...
Validation loss decreased (1.225613 --> 1.219244).  Saving model ...
Validation loss decreased (1.219244 --> 1.211805).  Saving model ...
Validation loss decreased (1.211805 --> 1.204200).  Saving model ...
Validation loss decreased (1.204200 --> 1.197670).  Saving model ...
Validation loss decreased (1.197670 --> 1.189511).  Saving model ...
Validation loss decreased (1.189511 --> 1.181227).  Saving model ...
Validation loss decreased (1.181227 --> 1.173998).  Saving model ...
Validation loss decreased (1.173998 --> 1.167353).  Saving model ...
Validation loss decreased (1.167353 --> 1.160126).  Saving model ...
Validation loss decreased (1.160126 --> 1.152533).  Saving model ...
Validation loss decreased (1.152533 --> 1.146048).  Saving model ...
Validation loss decreased (1.146048 --> 1.137796).  Saving model ...
Validation loss decreased (1.137796 --> 1.130853).  Saving model ...
Validation loss decreased (1.130853 --> 1.124196).  Saving model ...
Validation loss decreased (1.124196 --> 1.117335).  Saving model ...
Validation loss decreased (1.117335 --> 1.111112).  Saving model ...
Validation loss decreased (1.111112 --> 1.105823).  Saving model ...
Validation loss decreased (1.105823 --> 1.100860).  Saving model ...
Validation loss decreased (1.100860 --> 1.095461).  Saving model ...
Validation loss decreased (1.095461 --> 1.090305).  Saving model ...
Validation loss decreased (1.090305 --> 1.083349).  Saving model ...
Validation loss decreased (1.083349 --> 1.077954).  Saving model ...
Validation loss decreased (1.077954 --> 1.073930).  Saving model ...
Validation loss decreased (1.073930 --> 1.070008).  Saving model ...
Validation loss decreased (1.070008 --> 1.066036).  Saving model ...
Validation loss decreased (1.066036 --> 1.063304).  Saving model ...
Validation loss decreased (1.063304 --> 1.060183).  Saving model ...
Validation loss decreased (1.060183 --> 1.054577).  Saving model ...
Validation loss decreased (1.054577 --> 1.053269).  Saving model ...
Validation loss decreased (1.053269 --> 1.047943).  Saving model ...
Validation loss decreased (1.047943 --> 1.044581).  Saving model ...
Validation loss decreased (1.044581 --> 1.039439).  Saving model ...
Validation loss decreased (1.039439 --> 1.034925).  Saving model ...
Validation loss decreased (1.034925 --> 1.031039).  Saving model ...
Validation loss decreased (1.031039 --> 1.028989).  Saving model ...
Validation loss decreased (1.028989 --> 1.026204).  Saving model ...
Validation loss decreased (1.026204 --> 1.021773).  Saving model ...
Validation loss decreased (1.021773 --> 1.017512).  Saving model ...
Validation loss decreased (1.017512 --> 1.016259).  Saving model ...
Validation loss decreased (1.016259 --> 1.013203).  Saving model ...
Validation loss decreased (1.013203 --> 1.009029).  Saving model ...
Validation loss decreased (1.009029 --> 1.006905).  Saving model ...
Validation loss decreased (1.006905 --> 1.005943).  Saving model ...
Validation loss decreased (1.005943 --> 1.004572).  Saving model ...
Validation loss decreased (1.004572 --> 1.000986).  Saving model ...
Validation loss decreased (1.000986 --> 0.997576).  Saving model ...
Validation loss decreased (0.997576 --> 0.996517).  Saving model ...
Validation loss decreased (0.996517 --> 0.994781).  Saving model ...
Validation loss decreased (0.994781 --> 0.991432).  Saving model ...
Validation loss decreased (0.991432 --> 0.988746).  Saving model ...
Validation loss decreased (0.988746 --> 0.987427).  Saving model ...
Validation loss decreased (0.987427 --> 0.984753).  Saving model ...
Validation loss decreased (0.984753 --> 0.983266).  Saving model ...
Validation loss decreased (0.983266 --> 0.982812).  Saving model ...
Validation loss decreased (0.982812 --> 0.979547).  Saving model ...
Validation loss decreased (0.979547 --> 0.978856).  Saving model ...
Validation loss decreased (0.978856 --> 0.977808).  Saving model ...
Validation loss decreased (0.977808 --> 0.973964).  Saving model ...
Validation loss decreased (0.973964 --> 0.971386).  Saving model ...
Validation loss decreased (0.971386 --> 0.969988).  Saving model ...
EarlyStopping counter: 1 out of 10.0
Validation loss decreased (0.969988 --> 0.966836).  Saving model ...
Validation loss decreased (0.966836 --> 0.965112).  Saving model ...
Validation loss decreased (0.965112 --> 0.964056).  Saving model ...
Validation loss decreased (0.964056 --> 0.961740).  Saving model ...
Validation loss decreased (0.961740 --> 0.959884).  Saving model ...
Validation loss decreased (0.959884 --> 0.956937).  Saving model ...
EarlyStopping counter: 1 out of 10.0
EarlyStopping counter: 2 out of 10.0
Validation loss decreased (0.956937 --> 0.955994).  Saving model ...
Validation loss decreased (0.955994 --> 0.955780).  Saving model ...
Validation loss decreased (0.955780 --> 0.952845).  Saving model ...
EarlyStopping counter: 1 out of 10.0
Validation loss decreased (0.952845 --> 0.950551).  Saving model ...
Validation loss decreased (0.950551 --> 0.945961).  Saving model ...
Validation loss decreased (0.945961 --> 0.943987).  Saving model ...
EarlyStopping counter: 1 out of 10.0
EarlyStopping counter: 2 out of 10.0
EarlyStopping counter: 3 out of 10.0
Validation loss decreased (0.943987 --> 0.942949).  Saving model ...
Validation loss decreased (0.942949 --> 0.940629).  Saving model ...
Validation loss decreased (0.940629 --> 0.940305).  Saving model ...
Validation loss decreased (0.940305 --> 0.938882).  Saving model ...
Validation loss decreased (0.938882 --> 0.938199).  Saving model ...
Validation loss decreased (0.938199 --> 0.937001).  Saving model ...
EarlyStopping counter: 1 out of 10.0
EarlyStopping counter: 2 out of 10.0
Validation loss decreased (0.937001 --> 0.935278).  Saving model ...
Validation loss decreased (0.935278 --> 0.933494).  Saving model ...
EarlyStopping counter: 1 out of 10.0
EarlyStopping counter: 2 out of 10.0
Validation loss decreased (0.933494 --> 0.931084).  Saving model ...
Validation loss decreased (0.931084 --> 0.930973).  Saving model ...
Validation loss decreased (0.930973 --> 0.930583).  Saving model ...
Validation loss decreased (0.930583 --> 0.930141).  Saving model ...
EarlyStopping counter: 1 out of 10.0
EarlyStopping counter: 2 out of 10.0
Validation loss decreased (0.930141 --> 0.929094).  Saving model ...
EarlyStopping counter: 1 out of 10.0
Validation loss decreased (0.929094 --> 0.929034).  Saving model ...
EarlyStopping counter: 1 out of 10.0
EarlyStopping counter: 2 out of 10.0
EarlyStopping counter: 3 out of 10.0
EarlyStopping counter: 4 out of 10.0
EarlyStopping counter: 5 out of 10.0
Validation loss decreased (0.929034 --> 0.927613).  Saving model ...
Validation loss decreased (0.927613 --> 0.926033).  Saving model ...
Validation loss decreased (0.926033 --> 0.923069).  Saving model ...
EarlyStopping counter: 1 out of 10.0
EarlyStopping counter: 2 out of 10.0
EarlyStopping counter: 3 out of 10.0
EarlyStopping counter: 4 out of 10.0
EarlyStopping counter: 5 out of 10.0
Validation loss decreased (0.923069 --> 0.921448).  Saving model ...
Validation loss decreased (0.921448 --> 0.919190).  Saving model ...
EarlyStopping counter: 1 out of 10.0
EarlyStopping counter: 2 out of 10.0
EarlyStopping counter: 3 out of 10.0
EarlyStopping counter: 4 out of 10.0
EarlyStopping counter: 5 out of 10.0
Validation loss decreased (0.919190 --> 0.917873).  Saving model ...
EarlyStopping counter: 1 out of 10.0
EarlyStopping counter: 2 out of 10.0
EarlyStopping counter: 3 out of 10.0
EarlyStopping counter: 4 out of 10.0
EarlyStopping counter: 5 out of 10.0
EarlyStopping counter: 6 out of 10.0
EarlyStopping counter: 7 out of 10.0
EarlyStopping counter: 8 out of 10.0
EarlyStopping counter: 9 out of 10.0
EarlyStopping counter: 10 out of 10.0
/localscratch/yinan.29019290.0/env/lib/python3.7/site-packages/torch/nn/functional.py:1794: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.
  warnings.warn("nn.functional.tanh is deprecated. Use torch.tanh instead.")
wandb: Waiting for W&B process to finish, PID 95522... (success).
wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: \ 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: | 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: / 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: \ 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: | 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: / 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: \ 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: | 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: / 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb:                                                                                
wandb: Run history:
wandb:     e_F1 ▁▂▄▅▅▅▅▆▆▆▆▇▇▇▇▇▇▇▇▇████████████████████
wandb:   e_loss █▇▇▇▇▆▆▆▅▅▄▄▄▃▃▃▃▂▂▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:     t_F1 ▁▁▂▃▃▃▄▄▄▅▅▅▆▆▆▆▆▆▇▆▆▇▇▇▇▇▇▇▇▇▇▇██▇█▇███
wandb:   t_loss ██▇▇▇▇▇▆▆▆▅▅▅▅▄▄▄▄▃▃▃▃▃▃▃▂▂▂▂▂▂▂▂▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:     e_F1 63.91613
wandb:   e_loss 0.92102
wandb:     t_F1 72.54715
wandb:   t_loss 0.72278
wandb: 
wandb: Synced 4 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Synced copper-aardvark-2: https://wandb.ai/yinanazhou/xl_512_bs_8_lr_1e06_es_10_lc_True_nr_False_sr_False_stem_True_lemma_False_repeat_5_fold_2/runs/3l1fsaar
wandb: Find logs at: ./wandb/run-20220319_085623-3l1fsaar/logs/debug.log
wandb: 

