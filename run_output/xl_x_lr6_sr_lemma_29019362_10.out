Unloading StdEnv/2020

Due to MODULEPATH changes, the following have been reloaded:
  1) mii/1.1.1


The following have been reloaded with a version change:
  1) python/3.8.2 => python/3.7.4

Using base prefix '/cvmfs/soft.computecanada.ca/easybuild/software/2017/Core/python/3.7.4'
New python executable in /localscratch/yinan.29019362.0/env/bin/python
Installing setuptools, pip, wheel...
done.
Ignoring pip: markers 'python_version < "3"' don't match your environment
Looking in links: /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/nix/avx2, /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/nix/generic, /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic
Collecting pip
Installing collected packages: pip
  Found existing installation: pip 19.1.1
    Uninstalling pip-19.1.1:
      Successfully uninstalled pip-19.1.1
Successfully installed pip-21.2.3+computecanada
Looking in links: /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/nix/avx2, /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/nix/generic, /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/keras-2.8.0+computecanada-py2.py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/Keras_Preprocessing-1.1.2+computecanada-py3-none-any.whl
Requirement already satisfied: matplotlib in /cvmfs/soft.computecanada.ca/easybuild/software/2017/Core/scipy-stack/2019a/lib/python3.7/site-packages (from -r requirements.txt (line 3)) (3.0.2)
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/nltk-3.6.5+computecanada-py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/scikit_learn-0.22.1+computecanada-cp37-cp37m-linux_x86_64.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/tensorboard-2.3.0+computecanada-py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/tensorboard_plugin_wit-1.7.0+computecanada-py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/tensorflow_gpu-2.3.0+computecanada-cp37-cp37m-linux_x86_64.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/tensorflow_estimator-2.3.0+computecanada-py2.py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/tokenizers-0.5.2+computecanada-cp37-cp37m-linux_x86_64.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/nix/avx2/torch-1.4.0+computecanada-cp37-cp37m-linux_x86_64.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/torchtext-0.6.0+computecanada-py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/torchvision-0.8.2+computecanada-cp37-cp37m-linux_x86_64.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/transformers-2.5.1+computecanada-py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/urllib3-1.26.7+computecanada-py2.py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/tqdm-4.63.0+computecanada-py2.py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/joblib-1.1.0+computecanada-py2.py3-none-any.whl
ERROR: Could not find a version that satisfies the requirement regex>=2021.8.3 (from nltk) (from versions: 2018.1.10+computecanada, 2019.11.1+computecanada, 2020.11.13+computecanada)
ERROR: No matching distribution found for regex>=2021.8.3
Looking in links: /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/nix/avx2, /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/nix/generic, /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic
ERROR: Could not find a version that satisfies the requirement numpy==1.20.0+computacanada (from versions: 1.15.0+computecanada, 1.15.2+computecanada, 1.15.4+computecanada, 1.16.0+computecanada, 1.16.2+computecanada, 1.16.3+computecanada, 1.17.4+computecanada, 1.18.1+computecanada, 1.18.4+computecanada, 1.19.1+computecanada, 1.19.2+computecanada, 1.20.2+computecanada)
ERROR: No matching distribution found for numpy==1.20.0+computacanada
Looking in links: /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/nix/avx2, /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/nix/generic, /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/wandb-0.12.5+computecanada-py2.py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/protobuf-3.19.4+computecanada-py2.py3-none-any.whl
Requirement already satisfied: requests<3,>=2.0.0 in /cvmfs/soft.computecanada.ca/easybuild/software/2017/Core/scipy-stack/2019a/lib/python3.7/site-packages (from wandb) (2.21.0)
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/promise-2.3+computecanada-py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/psutil-5.7.3+computecanada-cp37-cp37m-linux_x86_64.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/sentry_sdk-1.5.0+computecanada-py2.py3-none-any.whl
Requirement already satisfied: python-dateutil>=2.6.1 in /cvmfs/soft.computecanada.ca/easybuild/software/2017/Core/scipy-stack/2019a/lib/python3.7/site-packages (from wandb) (2.7.5)
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/PyYAML-5.3.1+computecanada-cp37-cp37m-linux_x86_64.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/six-1.16.0+computecanada-py2.py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/click-8.0.4+computecanada-py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/subprocess32-3.5.4+computecanada-py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/shortuuid-1.0.1+computecanada-py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/pathtools-0.1.2+computecanada-py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/GitPython-3.1.24+computecanada-py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/docker_pycreds-0.4.0+computecanada-py2.py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/yaspin-2.1.0+computecanada-py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/configparser-5.0.2+computecanada-py3-none-any.whl
Requirement already satisfied: importlib-metadata in /cvmfs/soft.computecanada.ca/easybuild/software/2017/Core/scipy-stack/2019a/lib/python3.7/site-packages (from Click!=8.0.0,>=7.0->wandb) (0.8)
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/typing_extensions-4.0.1+computecanada-py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/gitdb-4.0.9+computecanada-py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/smmap-5.0.0+computecanada-py3-none-any.whl
Requirement already satisfied: idna<2.9,>=2.5 in /cvmfs/soft.computecanada.ca/easybuild/software/2017/Core/scipy-stack/2019a/lib/python3.7/site-packages (from requests<3,>=2.0.0->wandb) (2.8)
Requirement already satisfied: certifi>=2017.4.17 in /cvmfs/soft.computecanada.ca/easybuild/software/2017/Core/scipy-stack/2019a/lib/python3.7/site-packages (from requests<3,>=2.0.0->wandb) (2018.11.29)
Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /cvmfs/soft.computecanada.ca/easybuild/software/2017/Core/scipy-stack/2019a/lib/python3.7/site-packages (from requests<3,>=2.0.0->wandb) (3.0.4)
Requirement already satisfied: urllib3<1.25,>=1.21.1 in /cvmfs/soft.computecanada.ca/easybuild/software/2017/Core/scipy-stack/2019a/lib/python3.7/site-packages (from requests<3,>=2.0.0->wandb) (1.24.1)
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/termcolor-1.1.0+computecanada-py3-none-any.whl
Requirement already satisfied: zipp>=0.3.2 in /cvmfs/soft.computecanada.ca/easybuild/software/2017/Core/scipy-stack/2019a/lib/python3.7/site-packages (from importlib-metadata->Click!=8.0.0,>=7.0->wandb) (0.3.3)
Installing collected packages: smmap, typing-extensions, termcolor, six, gitdb, yaspin, subprocess32, shortuuid, sentry-sdk, PyYAML, psutil, protobuf, promise, pathtools, GitPython, docker-pycreds, configparser, Click, wandb
  Attempting uninstall: six
    Found existing installation: six 1.12.0
    Not uninstalling six at /cvmfs/soft.computecanada.ca/easybuild/software/2017/Core/scipy-stack/2019a/lib/python3.7/site-packages, outside environment /localscratch/yinan.29019362.0/env
    Can't uninstall 'six'. No files were found to uninstall.
Successfully installed Click-8.0.4+computecanada GitPython-3.1.24+computecanada PyYAML-5.3.1+computecanada configparser-5.0.2+computecanada docker-pycreds-0.4.0+computecanada gitdb-4.0.9+computecanada pathtools-0.1.2+computecanada promise-2.3+computecanada protobuf-3.19.4+computecanada psutil-5.7.3+computecanada sentry-sdk-1.5.0+computecanada shortuuid-1.0.1+computecanada six-1.16.0+computecanada smmap-5.0.0+computecanada subprocess32-3.5.4+computecanada termcolor-1.1.0+computecanada typing-extensions-4.0.1+computecanada wandb-0.12.5+computecanada yaspin-2.1.0+computecanada
Looking in links: /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/nix/avx2, /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/nix/generic, /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic
ERROR: Could not find a version that satisfies the requirement sagemaker (from versions: none)
ERROR: No matching distribution found for sagemaker
Looking in links: /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/nix/avx2, /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/nix/generic, /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/torch-1.9.1+computecanada-cp37-cp37m-linux_x86_64.whl
Requirement already satisfied: typing-extensions in /localscratch/yinan.29019362.0/env/lib/python3.7/site-packages (from torch) (4.0.1+computecanada)
Installing collected packages: torch
Successfully installed torch-1.9.1+computecanada
Looking in links: /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/nix/avx2, /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/nix/generic, /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/transformers-2.5.1+computecanada-py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/tqdm-4.63.0+computecanada-py2.py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/sacremoses-0.0.46+computecanada-py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/boto3-1.21.14+computecanada-py3-none-any.whl
Requirement already satisfied: requests in /cvmfs/soft.computecanada.ca/easybuild/software/2017/Core/scipy-stack/2019a/lib/python3.7/site-packages (from transformers==2.5.1+computecanada) (2.21.0)
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/regex-2020.11.13+computecanada-cp37-cp37m-linux_x86_64.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/filelock-3.4.2+computecanada-py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/sentencepiece-0.1.91+computecanada-cp37-cp37m-linux_x86_64.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/tokenizers-0.5.2+computecanada-cp37-cp37m-linux_x86_64.whl
Requirement already satisfied: numpy in /cvmfs/soft.computecanada.ca/easybuild/software/2017/Core/scipy-stack/2019a/lib/python3.7/site-packages (from transformers==2.5.1+computecanada) (1.16.0)
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/s3transfer-0.5.1+computecanada-py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/botocore-1.24.14+computecanada-py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/jmespath-0.10.0+computecanada-py2.py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/urllib3-1.26.8+computecanada-py2.py3-none-any.whl
Requirement already satisfied: python-dateutil<3.0.0,>=2.1 in /cvmfs/soft.computecanada.ca/easybuild/software/2017/Core/scipy-stack/2019a/lib/python3.7/site-packages (from botocore<1.25.0,>=1.24.14->boto3->transformers==2.5.1+computecanada) (2.7.5)
Requirement already satisfied: six>=1.5 in /localscratch/yinan.29019362.0/env/lib/python3.7/site-packages (from python-dateutil<3.0.0,>=2.1->botocore<1.25.0,>=1.24.14->boto3->transformers==2.5.1+computecanada) (1.16.0+computecanada)
Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /cvmfs/soft.computecanada.ca/easybuild/software/2017/Core/scipy-stack/2019a/lib/python3.7/site-packages (from requests->transformers==2.5.1+computecanada) (3.0.4)
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/requests-2.27.1+computecanada-py2.py3-none-any.whl
Requirement already satisfied: idna<4,>=2.5 in /cvmfs/soft.computecanada.ca/easybuild/software/2017/Core/scipy-stack/2019a/lib/python3.7/site-packages (from requests->transformers==2.5.1+computecanada) (2.8)
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/charset_normalizer-2.0.12+computecanada-py3-none-any.whl
Requirement already satisfied: certifi>=2017.4.17 in /cvmfs/soft.computecanada.ca/easybuild/software/2017/Core/scipy-stack/2019a/lib/python3.7/site-packages (from requests->transformers==2.5.1+computecanada) (2018.11.29)
Requirement already satisfied: click in /localscratch/yinan.29019362.0/env/lib/python3.7/site-packages (from sacremoses->transformers==2.5.1+computecanada) (8.0.4+computecanada)
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/joblib-1.1.0+computecanada-py2.py3-none-any.whl
Requirement already satisfied: importlib-metadata in /cvmfs/soft.computecanada.ca/easybuild/software/2017/Core/scipy-stack/2019a/lib/python3.7/site-packages (from click->sacremoses->transformers==2.5.1+computecanada) (0.8)
Requirement already satisfied: zipp>=0.3.2 in /cvmfs/soft.computecanada.ca/easybuild/software/2017/Core/scipy-stack/2019a/lib/python3.7/site-packages (from importlib-metadata->click->sacremoses->transformers==2.5.1+computecanada) (0.3.3)
Installing collected packages: urllib3, jmespath, botocore, tqdm, s3transfer, regex, joblib, charset-normalizer, tokenizers, sentencepiece, sacremoses, requests, filelock, boto3, transformers
  Attempting uninstall: urllib3
    Found existing installation: urllib3 1.24.1
    Not uninstalling urllib3 at /cvmfs/soft.computecanada.ca/easybuild/software/2017/Core/scipy-stack/2019a/lib/python3.7/site-packages, outside environment /localscratch/yinan.29019362.0/env
    Can't uninstall 'urllib3'. No files were found to uninstall.
  Attempting uninstall: requests
    Found existing installation: requests 2.21.0
    Not uninstalling requests at /cvmfs/soft.computecanada.ca/easybuild/software/2017/Core/scipy-stack/2019a/lib/python3.7/site-packages, outside environment /localscratch/yinan.29019362.0/env
    Can't uninstall 'requests'. No files were found to uninstall.
Successfully installed boto3-1.21.14+computecanada botocore-1.24.14+computecanada charset-normalizer-2.0.12+computecanada filelock-3.4.2+computecanada jmespath-0.10.0+computecanada joblib-1.1.0+computecanada regex-2020.11.13+computecanada requests-2.27.1+computecanada s3transfer-0.5.1+computecanada sacremoses-0.0.46+computecanada sentencepiece-0.1.91+computecanada tokenizers-0.5.2+computecanada tqdm-4.63.0+computecanada transformers-2.5.1+computecanada urllib3-1.26.8+computecanada
Looking in links: /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/nix/avx2, /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/nix/generic, /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/tensorflow_gpu-2.3.0+computecanada-cp37-cp37m-linux_x86_64.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/nix/generic/scipy-1.4.1+computecanada-cp37-cp37m-linux_x86_64.whl
Requirement already satisfied: six>=1.12.0 in /localscratch/yinan.29019362.0/env/lib/python3.7/site-packages (from tensorflow_gpu==2.3.0+computecanada) (1.16.0+computecanada)
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/tensorflow_estimator-2.3.0+computecanada-py2.py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/grpcio-1.38.0+computecanada-cp37-cp37m-linux_x86_64.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/opt_einsum-3.3.0+computecanada-py3-none-any.whl
Requirement already satisfied: wheel>=0.26 in /localscratch/yinan.29019362.0/env/lib/python3.7/site-packages (from tensorflow_gpu==2.3.0+computecanada) (0.33.4)
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/google_pasta-0.2.0+computecanada-py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/tensorboard-2.8.0+computecanada-py3-none-any.whl
Requirement already satisfied: termcolor>=1.1.0 in /localscratch/yinan.29019362.0/env/lib/python3.7/site-packages (from tensorflow_gpu==2.3.0+computecanada) (1.1.0+computecanada)
Requirement already satisfied: numpy<1.19.0,>=1.16.0 in /cvmfs/soft.computecanada.ca/easybuild/software/2017/Core/scipy-stack/2019a/lib/python3.7/site-packages (from tensorflow_gpu==2.3.0+computecanada) (1.16.0)
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/gast-0.3.3+computecanada-py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/wrapt-1.11.2+computecanada-cp37-cp37m-linux_x86_64.whl
Requirement already satisfied: protobuf>=3.9.2 in /localscratch/yinan.29019362.0/env/lib/python3.7/site-packages (from tensorflow_gpu==2.3.0+computecanada) (3.19.4+computecanada)
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/absl_py-1.0.0+computecanada-py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/astunparse-1.6.3+computecanada-py2.py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/nix/avx2/h5py-2.10.0+computecanada-cp37-cp37m-linux_x86_64.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/Keras_Preprocessing-1.1.2+computecanada-py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/tensorboard_data_server-0.6.1+computecanada-py3-none-linux_x86_64.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/tensorboard_plugin_wit-1.8.0+computecanada-py3-none-any.whl
Requirement already satisfied: requests<3,>=2.21.0 in /localscratch/yinan.29019362.0/env/lib/python3.7/site-packages (from tensorboard<3,>=2.3.0->tensorflow_gpu==2.3.0+computecanada) (2.27.1+computecanada)
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/Werkzeug-2.0.3+computecanada-py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/google_auth-2.3.3+computecanada-py2.py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/Markdown-3.3.6+computecanada-py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/google_auth_oauthlib-0.4.6+computecanada-py2.py3-none-any.whl
Requirement already satisfied: setuptools>=41.0.0 in /localscratch/yinan.29019362.0/env/lib/python3.7/site-packages (from tensorboard<3,>=2.3.0->tensorflow_gpu==2.3.0+computecanada) (41.0.1)
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/pyasn1_modules-0.2.8+computecanada-py2.py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/cachetools-4.2.4+computecanada-py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/rsa-4.8+computecanada-py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/requests_oauthlib-1.3.0+computecanada-py2.py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/importlib_metadata-4.10.1+computecanada-py3-none-any.whl
Requirement already satisfied: typing-extensions>=3.6.4 in /localscratch/yinan.29019362.0/env/lib/python3.7/site-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard<3,>=2.3.0->tensorflow_gpu==2.3.0+computecanada) (4.0.1+computecanada)
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/zipp-3.7.0+computecanada-py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/pyasn1-0.4.8+computecanada-py2.py3-none-any.whl
Requirement already satisfied: certifi>=2017.4.17 in /cvmfs/soft.computecanada.ca/easybuild/software/2017/Core/scipy-stack/2019a/lib/python3.7/site-packages (from requests<3,>=2.21.0->tensorboard<3,>=2.3.0->tensorflow_gpu==2.3.0+computecanada) (2018.11.29)
Requirement already satisfied: urllib3<1.27,>=1.21.1 in /localscratch/yinan.29019362.0/env/lib/python3.7/site-packages (from requests<3,>=2.21.0->tensorboard<3,>=2.3.0->tensorflow_gpu==2.3.0+computecanada) (1.26.8+computecanada)
Requirement already satisfied: idna<4,>=2.5 in /cvmfs/soft.computecanada.ca/easybuild/software/2017/Core/scipy-stack/2019a/lib/python3.7/site-packages (from requests<3,>=2.21.0->tensorboard<3,>=2.3.0->tensorflow_gpu==2.3.0+computecanada) (2.8)
Requirement already satisfied: charset-normalizer~=2.0.0 in /localscratch/yinan.29019362.0/env/lib/python3.7/site-packages (from requests<3,>=2.21.0->tensorboard<3,>=2.3.0->tensorflow_gpu==2.3.0+computecanada) (2.0.12+computecanada)
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/oauthlib-3.1.1+computecanada-py2.py3-none-any.whl
Installing collected packages: pyasn1, zipp, rsa, pyasn1-modules, oauthlib, cachetools, requests-oauthlib, importlib-metadata, google-auth, werkzeug, tensorboard-plugin-wit, tensorboard-data-server, markdown, grpcio, google-auth-oauthlib, absl-py, wrapt, tensorflow-estimator, tensorboard, scipy, opt-einsum, keras-preprocessing, h5py, google-pasta, gast, astunparse, tensorflow-gpu
  Attempting uninstall: pyasn1
    Found existing installation: pyasn1 0.4.3
    Not uninstalling pyasn1 at /cvmfs/soft.computecanada.ca/easybuild/software/2017/Core/scipy-stack/2019a/lib/python3.7/site-packages, outside environment /localscratch/yinan.29019362.0/env
    Can't uninstall 'pyasn1'. No files were found to uninstall.
  Attempting uninstall: zipp
    Found existing installation: zipp 0.3.3
    Not uninstalling zipp at /cvmfs/soft.computecanada.ca/easybuild/software/2017/Core/scipy-stack/2019a/lib/python3.7/site-packages, outside environment /localscratch/yinan.29019362.0/env
    Can't uninstall 'zipp'. No files were found to uninstall.
  Attempting uninstall: importlib-metadata
    Found existing installation: importlib-metadata 0.8
    Not uninstalling importlib-metadata at /cvmfs/soft.computecanada.ca/easybuild/software/2017/Core/scipy-stack/2019a/lib/python3.7/site-packages, outside environment /localscratch/yinan.29019362.0/env
    Can't uninstall 'importlib-metadata'. No files were found to uninstall.
  Attempting uninstall: scipy
    Found existing installation: scipy 1.2.0
    Not uninstalling scipy at /cvmfs/soft.computecanada.ca/easybuild/software/2017/Core/scipy-stack/2019a/lib/python3.7/site-packages, outside environment /localscratch/yinan.29019362.0/env
    Can't uninstall 'scipy'. No files were found to uninstall.
Successfully installed absl-py-1.0.0+computecanada astunparse-1.6.3+computecanada cachetools-4.2.4+computecanada gast-0.3.3+computecanada google-auth-2.3.3+computecanada google-auth-oauthlib-0.4.6+computecanada google-pasta-0.2.0+computecanada grpcio-1.38.0+computecanada h5py-2.10.0+computecanada importlib-metadata-4.10.1+computecanada keras-preprocessing-1.1.2+computecanada markdown-3.3.6+computecanada oauthlib-3.1.1+computecanada opt-einsum-3.3.0+computecanada pyasn1-0.4.8+computecanada pyasn1-modules-0.2.8+computecanada requests-oauthlib-1.3.0+computecanada rsa-4.8+computecanada scipy-1.4.1+computecanada tensorboard-2.8.0+computecanada tensorboard-data-server-0.6.1+computecanada tensorboard-plugin-wit-1.8.0+computecanada tensorflow-estimator-2.3.0+computecanada tensorflow-gpu-2.3.0+computecanada werkzeug-2.0.3+computecanada wrapt-1.11.2+computecanada zipp-3.7.0+computecanada
Looking in links: /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/nix/avx2, /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/nix/generic, /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/keras-2.8.0+computecanada-py2.py3-none-any.whl
Installing collected packages: Keras
Successfully installed Keras-2.8.0+computecanada
Looking in links: /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/nix/avx2, /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/nix/generic, /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/urllib3-1.26.7+computecanada-py2.py3-none-any.whl
Installing collected packages: urllib3
  Attempting uninstall: urllib3
    Found existing installation: urllib3 1.26.8+computecanada
    Uninstalling urllib3-1.26.8+computecanada:
      Successfully uninstalled urllib3-1.26.8+computecanada
Successfully installed urllib3-1.26.7+computecanada
Looking in links: /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/nix/avx2, /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/nix/generic, /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/nltk-3.7+computecanada-py3-none-any.whl
Requirement already satisfied: tqdm in /localscratch/yinan.29019362.0/env/lib/python3.7/site-packages (from nltk) (4.63.0+computecanada)
Requirement already satisfied: joblib in /localscratch/yinan.29019362.0/env/lib/python3.7/site-packages (from nltk) (1.1.0+computecanada)
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/nltk-3.6.5+computecanada-py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/nltk-3.6.3+computecanada-py3-none-any.whl
Requirement already satisfied: regex in /localscratch/yinan.29019362.0/env/lib/python3.7/site-packages (from nltk) (2020.11.13+computecanada)
Requirement already satisfied: click in /localscratch/yinan.29019362.0/env/lib/python3.7/site-packages (from nltk) (8.0.4+computecanada)
Requirement already satisfied: importlib-metadata in /localscratch/yinan.29019362.0/env/lib/python3.7/site-packages (from click->nltk) (4.10.1+computecanada)
Requirement already satisfied: zipp>=0.5 in /localscratch/yinan.29019362.0/env/lib/python3.7/site-packages (from importlib-metadata->click->nltk) (3.7.0+computecanada)
Requirement already satisfied: typing-extensions>=3.6.4 in /localscratch/yinan.29019362.0/env/lib/python3.7/site-packages (from importlib-metadata->click->nltk) (4.0.1+computecanada)
Installing collected packages: nltk
Successfully installed nltk-3.6.3+computecanada
Looking in links: /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/nix/avx2, /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/nix/generic, /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/scikit_learn-0.22.1+computecanada-cp37-cp37m-linux_x86_64.whl
Requirement already satisfied: joblib>=0.11 in /localscratch/yinan.29019362.0/env/lib/python3.7/site-packages (from scikit-learn==0.22.1) (1.1.0+computecanada)
Requirement already satisfied: numpy>=1.11.0 in /cvmfs/soft.computecanada.ca/easybuild/software/2017/Core/scipy-stack/2019a/lib/python3.7/site-packages (from scikit-learn==0.22.1) (1.16.0)
Requirement already satisfied: scipy>=0.17.0 in /localscratch/yinan.29019362.0/env/lib/python3.7/site-packages (from scikit-learn==0.22.1) (1.4.1+computecanada)
Installing collected packages: scikit-learn
Successfully installed scikit-learn-0.22.1+computecanada
Looking in links: /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/nix/avx2, /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/nix/generic, /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic
Requirement already satisfied: tokenizers==0.5.2 in /localscratch/yinan.29019362.0/env/lib/python3.7/site-packages (0.5.2+computecanada)
wandb: Appending key for api.wandb.ai to your netrc file: /home/yinan/.netrc
Starting Task
2022-03-18 19:48:23.511586: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1
[nltk_data] Downloading package stopwords to /home/yinan/nltk_data...
[nltk_data]   Package stopwords is already up-to-date!
[nltk_data] Downloading package wordnet to /home/yinan/nltk_data...
[nltk_data]   Package wordnet is already up-to-date!
wandb: Currently logged in as: yinanazhou (use `wandb login --relogin` to force relogin)
wandb: wandb version 0.12.11 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
2022-03-18 19:48:36.412110: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1
wandb: Tracking run with wandb version 0.12.5
wandb: Syncing run noble-paper-2
wandb: ⭐️ View project at https://wandb.ai/yinanazhou/xl_512_bs_8_lr_1e06_es_10_lc_False_nr_False_sr_True_stem_False_lemma_True_repeat_1_fold_1
wandb: 🚀 View run at https://wandb.ai/yinanazhou/xl_512_bs_8_lr_1e06_es_10_lc_False_nr_False_sr_True_stem_False_lemma_True_repeat_1_fold_1/runs/nb2sarcl
wandb: Run data is saved locally in /project/6002780/yinan/Thesis_MER_Lyrics/lyric-emotion/wandb/run-20220318_194834-nb2sarcl
wandb: Run `wandb offline` to turn off syncing.

Validation loss decreased (inf --> 1.427574).  Saving model ...
Validation loss decreased (1.427574 --> 1.407930).  Saving model ...
Validation loss decreased (1.407930 --> 1.391188).  Saving model ...
Validation loss decreased (1.391188 --> 1.378406).  Saving model ...
Validation loss decreased (1.378406 --> 1.368410).  Saving model ...
Validation loss decreased (1.368410 --> 1.358918).  Saving model ...
Validation loss decreased (1.358918 --> 1.351319).  Saving model ...
Validation loss decreased (1.351319 --> 1.344903).  Saving model ...
Validation loss decreased (1.344903 --> 1.339149).  Saving model ...
Validation loss decreased (1.339149 --> 1.332976).  Saving model ...
Validation loss decreased (1.332976 --> 1.326100).  Saving model ...
Validation loss decreased (1.326100 --> 1.320705).  Saving model ...
Validation loss decreased (1.320705 --> 1.313481).  Saving model ...
Validation loss decreased (1.313481 --> 1.307109).  Saving model ...
Validation loss decreased (1.307109 --> 1.299803).  Saving model ...
Validation loss decreased (1.299803 --> 1.292455).  Saving model ...
Validation loss decreased (1.292455 --> 1.284967).  Saving model ...
Validation loss decreased (1.284967 --> 1.278097).  Saving model ...
Validation loss decreased (1.278097 --> 1.269714).  Saving model ...
Validation loss decreased (1.269714 --> 1.262231).  Saving model ...
Validation loss decreased (1.262231 --> 1.255325).  Saving model ...
Validation loss decreased (1.255325 --> 1.247585).  Saving model ...
Validation loss decreased (1.247585 --> 1.241129).  Saving model ...
Validation loss decreased (1.241129 --> 1.232712).  Saving model ...
Validation loss decreased (1.232712 --> 1.225695).  Saving model ...
Validation loss decreased (1.225695 --> 1.218015).  Saving model ...
Validation loss decreased (1.218015 --> 1.214286).  Saving model ...
Validation loss decreased (1.214286 --> 1.207433).  Saving model ...
Validation loss decreased (1.207433 --> 1.199062).  Saving model ...
Validation loss decreased (1.199062 --> 1.195034).  Saving model ...
Validation loss decreased (1.195034 --> 1.187588).  Saving model ...
Validation loss decreased (1.187588 --> 1.181286).  Saving model ...
Validation loss decreased (1.181286 --> 1.180440).  Saving model ...
Validation loss decreased (1.180440 --> 1.172941).  Saving model ...
Validation loss decreased (1.172941 --> 1.168939).  Saving model ...
Validation loss decreased (1.168939 --> 1.164877).  Saving model ...
Validation loss decreased (1.164877 --> 1.160460).  Saving model ...
Validation loss decreased (1.160460 --> 1.153775).  Saving model ...
Validation loss decreased (1.153775 --> 1.151359).  Saving model ...
Validation loss decreased (1.151359 --> 1.147598).  Saving model ...
Validation loss decreased (1.147598 --> 1.142637).  Saving model ...
Validation loss decreased (1.142637 --> 1.137179).  Saving model ...
Validation loss decreased (1.137179 --> 1.134156).  Saving model ...
Validation loss decreased (1.134156 --> 1.130756).  Saving model ...
Validation loss decreased (1.130756 --> 1.125356).  Saving model ...
Validation loss decreased (1.125356 --> 1.120109).  Saving model ...
Validation loss decreased (1.120109 --> 1.117292).  Saving model ...
Validation loss decreased (1.117292 --> 1.112945).  Saving model ...
Validation loss decreased (1.112945 --> 1.109079).  Saving model ...
Validation loss decreased (1.109079 --> 1.105831).  Saving model ...
Validation loss decreased (1.105831 --> 1.100185).  Saving model ...
Validation loss decreased (1.100185 --> 1.095979).  Saving model ...
Validation loss decreased (1.095979 --> 1.090696).  Saving model ...
Validation loss decreased (1.090696 --> 1.086962).  Saving model ...
Validation loss decreased (1.086962 --> 1.085998).  Saving model ...
Validation loss decreased (1.085998 --> 1.082645).  Saving model ...
Validation loss decreased (1.082645 --> 1.080462).  Saving model ...
Validation loss decreased (1.080462 --> 1.077956).  Saving model ...
Validation loss decreased (1.077956 --> 1.073260).  Saving model ...
Validation loss decreased (1.073260 --> 1.072747).  Saving model ...
Validation loss decreased (1.072747 --> 1.071362).  Saving model ...
Validation loss decreased (1.071362 --> 1.069358).  Saving model ...
Validation loss decreased (1.069358 --> 1.064137).  Saving model ...
Validation loss decreased (1.064137 --> 1.062307).  Saving model ...
Validation loss decreased (1.062307 --> 1.060420).  Saving model ...
Validation loss decreased (1.060420 --> 1.055827).  Saving model ...
Validation loss decreased (1.055827 --> 1.055073).  Saving model ...
Validation loss decreased (1.055073 --> 1.054841).  Saving model ...
Validation loss decreased (1.054841 --> 1.051524).  Saving model ...
Validation loss decreased (1.051524 --> 1.046707).  Saving model ...
Validation loss decreased (1.046707 --> 1.045170).  Saving model ...
Validation loss decreased (1.045170 --> 1.041382).  Saving model ...
Validation loss decreased (1.041382 --> 1.038693).  Saving model ...
Validation loss decreased (1.038693 --> 1.034640).  Saving model ...
Validation loss decreased (1.034640 --> 1.033413).  Saving model ...
Validation loss decreased (1.033413 --> 1.031635).  Saving model ...
EarlyStopping counter: 1 out of 10.0
Validation loss decreased (1.031635 --> 1.030768).  Saving model ...
Validation loss decreased (1.030768 --> 1.025036).  Saving model ...
EarlyStopping counter: 1 out of 10.0
Validation loss decreased (1.025036 --> 1.024246).  Saving model ...
Validation loss decreased (1.024246 --> 1.020912).  Saving model ...
Validation loss decreased (1.020912 --> 1.019065).  Saving model ...
Validation loss decreased (1.019065 --> 1.018093).  Saving model ...
Validation loss decreased (1.018093 --> 1.013402).  Saving model ...
Validation loss decreased (1.013402 --> 1.010681).  Saving model ...
Validation loss decreased (1.010681 --> 1.010309).  Saving model ...
EarlyStopping counter: 1 out of 10.0
EarlyStopping counter: 2 out of 10.0
Validation loss decreased (1.010309 --> 1.008136).  Saving model ...
Validation loss decreased (1.008136 --> 1.007944).  Saving model ...
Validation loss decreased (1.007944 --> 1.006597).  Saving model ...
Validation loss decreased (1.006597 --> 1.004391).  Saving model ...
EarlyStopping counter: 1 out of 10.0
EarlyStopping counter: 2 out of 10.0
Validation loss decreased (1.004391 --> 1.001653).  Saving model ...
Validation loss decreased (1.001653 --> 1.001614).  Saving model ...
Validation loss decreased (1.001614 --> 1.000610).  Saving model ...
Validation loss decreased (1.000610 --> 0.998616).  Saving model ...
EarlyStopping counter: 1 out of 10.0
EarlyStopping counter: 2 out of 10.0
EarlyStopping counter: 3 out of 10.0
Validation loss decreased (0.998616 --> 0.996599).  Saving model ...
EarlyStopping counter: 1 out of 10.0
EarlyStopping counter: 2 out of 10.0
Validation loss decreased (0.996599 --> 0.996482).  Saving model ...
Validation loss decreased (0.996482 --> 0.995976).  Saving model ...
Validation loss decreased (0.995976 --> 0.995883).  Saving model ...
Validation loss decreased (0.995883 --> 0.992848).  Saving model ...
Validation loss decreased (0.992848 --> 0.991446).  Saving model ...
EarlyStopping counter: 1 out of 10.0
EarlyStopping counter: 2 out of 10.0
EarlyStopping counter: 3 out of 10.0
EarlyStopping counter: 4 out of 10.0
EarlyStopping counter: 5 out of 10.0
EarlyStopping counter: 6 out of 10.0
Validation loss decreased (0.991446 --> 0.988850).  Saving model ...
Validation loss decreased (0.988850 --> 0.987066).  Saving model ...
EarlyStopping counter: 1 out of 10.0
Validation loss decreased (0.987066 --> 0.984334).  Saving model ...
EarlyStopping counter: 1 out of 10.0
EarlyStopping counter: 2 out of 10.0
EarlyStopping counter: 3 out of 10.0
EarlyStopping counter: 4 out of 10.0
EarlyStopping counter: 5 out of 10.0
EarlyStopping counter: 6 out of 10.0
EarlyStopping counter: 7 out of 10.0
EarlyStopping counter: 8 out of 10.0
EarlyStopping counter: 9 out of 10.0
EarlyStopping counter: 10 out of 10.0
/localscratch/yinan.29019362.0/env/lib/python3.7/site-packages/torch/nn/functional.py:1794: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.
  warnings.warn("nn.functional.tanh is deprecated. Use torch.tanh instead.")
/localscratch/yinan.29019362.0/env/lib/python3.7/site-packages/transformers/optimization.py:155: UserWarning: This overload of add_ is deprecated:
	add_(Number alpha, Tensor other)
Consider using one of the following signatures instead:
	add_(Tensor other, *, Number alpha) (Triggered internally at  ../torch/csrc/utils/python_arg_parser.cpp:1025.)
  exp_avg.mul_(beta1).add_(1.0 - beta1, grad)
wandb: Waiting for W&B process to finish, PID 258890... (success).
wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: \ 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: | 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: / 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: \ 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: | 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: / 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: \ 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: | 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: / 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: \ 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: | 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: / 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: \ 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: | 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: / 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: \ 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: | 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: / 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: \ 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: | 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: / 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: \ 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: | 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: / 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: \ 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: | 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: / 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: \ 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: | 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: / 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: \ 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: | 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: / 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: \ 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: | 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: / 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: \ 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: | 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: / 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: \ 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: | 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: / 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: \ 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: | 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: / 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: \ 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb:                                                                                
wandb: Run history:
wandb:     e_F1 ▁▂▄▄▄▅▅▅▆▆▆▆▇▇▆▇▇▇▇▇▇▇▇▇▇▇██████████████
wandb:   e_loss ██▇▇▆▆▆▅▅▄▄▄▄▃▃▃▃▃▂▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:     t_F1 ▁▁▂▂▃▄▄▄▄▅▅▆▅▅▅▆▆▆▆▇▆▇▇▆▇▇▇▇▇▇▇▇▇█▇█████
wandb:   t_loss ██▇▇▇▆▆▆▆▅▅▅▅▄▅▄▄▄▄▃▃▃▃▃▃▃▂▃▂▂▂▂▂▂▂▂▂▁▁▁
wandb: 
wandb: Run summary:
wandb:     e_F1 58.94569
wandb:   e_loss 0.98464
wandb:     t_F1 73.11963
wandb:   t_loss 0.711
wandb: 
wandb: Synced 4 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Synced noble-paper-2: https://wandb.ai/yinanazhou/xl_512_bs_8_lr_1e06_es_10_lc_False_nr_False_sr_True_stem_False_lemma_True_repeat_1_fold_1/runs/nb2sarcl
wandb: Find logs at: ./wandb/run-20220318_194834-nb2sarcl/logs/debug.log
wandb: 

wandb: wandb version 0.12.11 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
2022-03-18 21:15:23.515734: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1
wandb: Tracking run with wandb version 0.12.5
wandb: Syncing run cerulean-shadow-2
wandb: ⭐️ View project at https://wandb.ai/yinanazhou/xl_512_bs_8_lr_1e06_es_10_lc_False_nr_False_sr_True_stem_False_lemma_True_repeat_1_fold_2
wandb: 🚀 View run at https://wandb.ai/yinanazhou/xl_512_bs_8_lr_1e06_es_10_lc_False_nr_False_sr_True_stem_False_lemma_True_repeat_1_fold_2/runs/8adofnv8
wandb: Run data is saved locally in /project/6002780/yinan/Thesis_MER_Lyrics/lyric-emotion/wandb/run-20220318_211520-8adofnv8
wandb: Run `wandb offline` to turn off syncing.

Validation loss decreased (inf --> 1.413375).  Saving model ...
Validation loss decreased (1.413375 --> 1.401636).  Saving model ...
Validation loss decreased (1.401636 --> 1.392987).  Saving model ...
Validation loss decreased (1.392987 --> 1.385797).  Saving model ...
Validation loss decreased (1.385797 --> 1.380684).  Saving model ...
Validation loss decreased (1.380684 --> 1.375892).  Saving model ...
Validation loss decreased (1.375892 --> 1.371857).  Saving model ...
Validation loss decreased (1.371857 --> 1.367172).  Saving model ...
Validation loss decreased (1.367172 --> 1.362709).  Saving model ...
Validation loss decreased (1.362709 --> 1.358544).  Saving model ...
Validation loss decreased (1.358544 --> 1.352694).  Saving model ...
Validation loss decreased (1.352694 --> 1.347201).  Saving model ...
Validation loss decreased (1.347201 --> 1.341767).  Saving model ...
Validation loss decreased (1.341767 --> 1.336527).  Saving model ...
Validation loss decreased (1.336527 --> 1.331219).  Saving model ...
Validation loss decreased (1.331219 --> 1.323723).  Saving model ...
Validation loss decreased (1.323723 --> 1.317045).  Saving model ...
Validation loss decreased (1.317045 --> 1.310890).  Saving model ...
Validation loss decreased (1.310890 --> 1.303661).  Saving model ...
Validation loss decreased (1.303661 --> 1.296878).  Saving model ...
Validation loss decreased (1.296878 --> 1.289809).  Saving model ...
Validation loss decreased (1.289809 --> 1.280972).  Saving model ...
Validation loss decreased (1.280972 --> 1.274764).  Saving model ...
Validation loss decreased (1.274764 --> 1.268519).  Saving model ...
Validation loss decreased (1.268519 --> 1.260204).  Saving model ...
Validation loss decreased (1.260204 --> 1.251366).  Saving model ...
Validation loss decreased (1.251366 --> 1.244410).  Saving model ...
Validation loss decreased (1.244410 --> 1.236601).  Saving model ...
Validation loss decreased (1.236601 --> 1.228023).  Saving model ...
Validation loss decreased (1.228023 --> 1.219799).  Saving model ...
Validation loss decreased (1.219799 --> 1.212350).  Saving model ...
Validation loss decreased (1.212350 --> 1.204446).  Saving model ...
Validation loss decreased (1.204446 --> 1.198014).  Saving model ...
Validation loss decreased (1.198014 --> 1.190245).  Saving model ...
Validation loss decreased (1.190245 --> 1.183131).  Saving model ...
Validation loss decreased (1.183131 --> 1.173558).  Saving model ...
Validation loss decreased (1.173558 --> 1.164543).  Saving model ...
Validation loss decreased (1.164543 --> 1.156708).  Saving model ...
Validation loss decreased (1.156708 --> 1.149379).  Saving model ...
Validation loss decreased (1.149379 --> 1.143652).  Saving model ...
Validation loss decreased (1.143652 --> 1.138807).  Saving model ...
Validation loss decreased (1.138807 --> 1.132539).  Saving model ...
Validation loss decreased (1.132539 --> 1.125294).  Saving model ...
Validation loss decreased (1.125294 --> 1.118164).  Saving model ...
Validation loss decreased (1.118164 --> 1.112728).  Saving model ...
Validation loss decreased (1.112728 --> 1.106046).  Saving model ...
Validation loss decreased (1.106046 --> 1.099453).  Saving model ...
Validation loss decreased (1.099453 --> 1.093385).  Saving model ...
Validation loss decreased (1.093385 --> 1.088260).  Saving model ...
Validation loss decreased (1.088260 --> 1.083580).  Saving model ...
Validation loss decreased (1.083580 --> 1.077149).  Saving model ...
Validation loss decreased (1.077149 --> 1.071408).  Saving model ...
Validation loss decreased (1.071408 --> 1.065239).  Saving model ...
Validation loss decreased (1.065239 --> 1.059908).  Saving model ...
Validation loss decreased (1.059908 --> 1.054224).  Saving model ...
Validation loss decreased (1.054224 --> 1.050983).  Saving model ...
Validation loss decreased (1.050983 --> 1.045651).  Saving model ...
Validation loss decreased (1.045651 --> 1.042005).  Saving model ...
Validation loss decreased (1.042005 --> 1.038666).  Saving model ...
Validation loss decreased (1.038666 --> 1.032339).  Saving model ...
Validation loss decreased (1.032339 --> 1.027628).  Saving model ...
Validation loss decreased (1.027628 --> 1.025069).  Saving model ...
Validation loss decreased (1.025069 --> 1.021437).  Saving model ...
Validation loss decreased (1.021437 --> 1.017827).  Saving model ...
Validation loss decreased (1.017827 --> 1.012564).  Saving model ...
Validation loss decreased (1.012564 --> 1.009776).  Saving model ...
Validation loss decreased (1.009776 --> 1.005715).  Saving model ...
Validation loss decreased (1.005715 --> 1.001962).  Saving model ...
Validation loss decreased (1.001962 --> 0.997856).  Saving model ...
Validation loss decreased (0.997856 --> 0.994418).  Saving model ...
Validation loss decreased (0.994418 --> 0.991092).  Saving model ...
Validation loss decreased (0.991092 --> 0.987055).  Saving model ...
Validation loss decreased (0.987055 --> 0.985797).  Saving model ...
Validation loss decreased (0.985797 --> 0.982297).  Saving model ...
Validation loss decreased (0.982297 --> 0.980094).  Saving model ...
Validation loss decreased (0.980094 --> 0.978026).  Saving model ...
Validation loss decreased (0.978026 --> 0.975180).  Saving model ...
Validation loss decreased (0.975180 --> 0.972260).  Saving model ...
Validation loss decreased (0.972260 --> 0.970834).  Saving model ...
Validation loss decreased (0.970834 --> 0.968386).  Saving model ...
Validation loss decreased (0.968386 --> 0.967167).  Saving model ...
Validation loss decreased (0.967167 --> 0.964652).  Saving model ...
Validation loss decreased (0.964652 --> 0.962733).  Saving model ...
Validation loss decreased (0.962733 --> 0.960260).  Saving model ...
Validation loss decreased (0.960260 --> 0.958787).  Saving model ...
Validation loss decreased (0.958787 --> 0.955277).  Saving model ...
Validation loss decreased (0.955277 --> 0.954434).  Saving model ...
Validation loss decreased (0.954434 --> 0.951950).  Saving model ...
Validation loss decreased (0.951950 --> 0.951018).  Saving model ...
Validation loss decreased (0.951018 --> 0.950327).  Saving model ...
Validation loss decreased (0.950327 --> 0.950086).  Saving model ...
Validation loss decreased (0.950086 --> 0.948393).  Saving model ...
Validation loss decreased (0.948393 --> 0.946196).  Saving model ...
EarlyStopping counter: 1 out of 10.0
EarlyStopping counter: 2 out of 10.0
Validation loss decreased (0.946196 --> 0.942829).  Saving model ...
EarlyStopping counter: 1 out of 10.0
Validation loss decreased (0.942829 --> 0.942601).  Saving model ...
Validation loss decreased (0.942601 --> 0.941049).  Saving model ...
Validation loss decreased (0.941049 --> 0.940315).  Saving model ...
Validation loss decreased (0.940315 --> 0.939873).  Saving model ...
Validation loss decreased (0.939873 --> 0.937848).  Saving model ...
Validation loss decreased (0.937848 --> 0.935023).  Saving model ...
EarlyStopping counter: 1 out of 10.0
EarlyStopping counter: 2 out of 10.0
EarlyStopping counter: 3 out of 10.0
EarlyStopping counter: 4 out of 10.0
Validation loss decreased (0.935023 --> 0.932840).  Saving model ...
EarlyStopping counter: 1 out of 10.0
Validation loss decreased (0.932840 --> 0.931049).  Saving model ...
EarlyStopping counter: 1 out of 10.0
EarlyStopping counter: 2 out of 10.0
EarlyStopping counter: 3 out of 10.0
EarlyStopping counter: 4 out of 10.0
EarlyStopping counter: 5 out of 10.0
EarlyStopping counter: 6 out of 10.0
EarlyStopping counter: 7 out of 10.0
EarlyStopping counter: 8 out of 10.0
EarlyStopping counter: 9 out of 10.0
EarlyStopping counter: 10 out of 10.0
/localscratch/yinan.29019362.0/env/lib/python3.7/site-packages/torch/nn/functional.py:1794: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.
  warnings.warn("nn.functional.tanh is deprecated. Use torch.tanh instead.")
wandb: Waiting for W&B process to finish, PID 1764... (success).
wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: \ 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: | 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: / 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: \ 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: | 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: / 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb:                                                                                
wandb: Run history:
wandb:     e_F1 ▁▂▂▃▄▄▄▄▅▅▆▆▆▆▇▇▇▇▇▇▇███████████████████
wandb:   e_loss ██▇▇▇▇▆▆▆▅▅▅▄▄▄▄▃▃▃▃▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:     t_F1 ▁▂▂▂▃▃▃▄▄▄▅▅▆▅▅▆▆▆▆▇▇▇▇▇▇▇▇▇▇▇▇█▇▇██████
wandb:   t_loss ██▇▇▇▇▇▇▆▆▆▆▅▅▅▅▅▄▄▄▄▃▃▃▃▃▃▃▃▂▂▂▂▂▂▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:     e_F1 61.67521
wandb:   e_loss 0.93319
wandb:     t_F1 71.93127
wandb:   t_loss 0.76928
wandb: 
wandb: Synced 4 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Synced cerulean-shadow-2: https://wandb.ai/yinanazhou/xl_512_bs_8_lr_1e06_es_10_lc_False_nr_False_sr_True_stem_False_lemma_True_repeat_1_fold_2/runs/8adofnv8
wandb: Find logs at: ./wandb/run-20220318_211520-8adofnv8/logs/debug.log
wandb: 

wandb: wandb version 0.12.11 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
2022-03-18 22:35:30.715622: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1
wandb: Tracking run with wandb version 0.12.5
wandb: Syncing run hopeful-grass-2
wandb: ⭐️ View project at https://wandb.ai/yinanazhou/xl_512_bs_8_lr_1e06_es_10_lc_False_nr_False_sr_True_stem_False_lemma_True_repeat_2_fold_1
wandb: 🚀 View run at https://wandb.ai/yinanazhou/xl_512_bs_8_lr_1e06_es_10_lc_False_nr_False_sr_True_stem_False_lemma_True_repeat_2_fold_1/runs/3k7amt31
wandb: Run data is saved locally in /project/6002780/yinan/Thesis_MER_Lyrics/lyric-emotion/wandb/run-20220318_223528-3k7amt31
wandb: Run `wandb offline` to turn off syncing.

Validation loss decreased (inf --> 1.407934).  Saving model ...
Validation loss decreased (1.407934 --> 1.401690).  Saving model ...
Validation loss decreased (1.401690 --> 1.395784).  Saving model ...
Validation loss decreased (1.395784 --> 1.390603).  Saving model ...
Validation loss decreased (1.390603 --> 1.385951).  Saving model ...
Validation loss decreased (1.385951 --> 1.381762).  Saving model ...
Validation loss decreased (1.381762 --> 1.377615).  Saving model ...
Validation loss decreased (1.377615 --> 1.373570).  Saving model ...
Validation loss decreased (1.373570 --> 1.369275).  Saving model ...
Validation loss decreased (1.369275 --> 1.364926).  Saving model ...
Validation loss decreased (1.364926 --> 1.360193).  Saving model ...
Validation loss decreased (1.360193 --> 1.356487).  Saving model ...
Validation loss decreased (1.356487 --> 1.352138).  Saving model ...
Validation loss decreased (1.352138 --> 1.347786).  Saving model ...
Validation loss decreased (1.347786 --> 1.343099).  Saving model ...
Validation loss decreased (1.343099 --> 1.338393).  Saving model ...
Validation loss decreased (1.338393 --> 1.333912).  Saving model ...
Validation loss decreased (1.333912 --> 1.328765).  Saving model ...
Validation loss decreased (1.328765 --> 1.323208).  Saving model ...
Validation loss decreased (1.323208 --> 1.317791).  Saving model ...
Validation loss decreased (1.317791 --> 1.312300).  Saving model ...
Validation loss decreased (1.312300 --> 1.306295).  Saving model ...
Validation loss decreased (1.306295 --> 1.299979).  Saving model ...
Validation loss decreased (1.299979 --> 1.292077).  Saving model ...
Validation loss decreased (1.292077 --> 1.284049).  Saving model ...
Validation loss decreased (1.284049 --> 1.276735).  Saving model ...
Validation loss decreased (1.276735 --> 1.266883).  Saving model ...
Validation loss decreased (1.266883 --> 1.258387).  Saving model ...
Validation loss decreased (1.258387 --> 1.248891).  Saving model ...
Validation loss decreased (1.248891 --> 1.240811).  Saving model ...
Validation loss decreased (1.240811 --> 1.232721).  Saving model ...
Validation loss decreased (1.232721 --> 1.223486).  Saving model ...
Validation loss decreased (1.223486 --> 1.215336).  Saving model ...
Validation loss decreased (1.215336 --> 1.207014).  Saving model ...
Validation loss decreased (1.207014 --> 1.200629).  Saving model ...
Validation loss decreased (1.200629 --> 1.193661).  Saving model ...
Validation loss decreased (1.193661 --> 1.185901).  Saving model ...
Validation loss decreased (1.185901 --> 1.179213).  Saving model ...
Validation loss decreased (1.179213 --> 1.171966).  Saving model ...
Validation loss decreased (1.171966 --> 1.165363).  Saving model ...
Validation loss decreased (1.165363 --> 1.159195).  Saving model ...
Validation loss decreased (1.159195 --> 1.151978).  Saving model ...
Validation loss decreased (1.151978 --> 1.145649).  Saving model ...
Validation loss decreased (1.145649 --> 1.139715).  Saving model ...
Validation loss decreased (1.139715 --> 1.134299).  Saving model ...
Validation loss decreased (1.134299 --> 1.128204).  Saving model ...
Validation loss decreased (1.128204 --> 1.122339).  Saving model ...
Validation loss decreased (1.122339 --> 1.117399).  Saving model ...
Validation loss decreased (1.117399 --> 1.112517).  Saving model ...
Validation loss decreased (1.112517 --> 1.106568).  Saving model ...
Validation loss decreased (1.106568 --> 1.099935).  Saving model ...
Validation loss decreased (1.099935 --> 1.096463).  Saving model ...
Validation loss decreased (1.096463 --> 1.089745).  Saving model ...
Validation loss decreased (1.089745 --> 1.084846).  Saving model ...
Validation loss decreased (1.084846 --> 1.080048).  Saving model ...
Validation loss decreased (1.080048 --> 1.075232).  Saving model ...
Validation loss decreased (1.075232 --> 1.070863).  Saving model ...
Validation loss decreased (1.070863 --> 1.064193).  Saving model ...
Validation loss decreased (1.064193 --> 1.059470).  Saving model ...
Validation loss decreased (1.059470 --> 1.054584).  Saving model ...
Validation loss decreased (1.054584 --> 1.049867).  Saving model ...
Validation loss decreased (1.049867 --> 1.045043).  Saving model ...
Validation loss decreased (1.045043 --> 1.040188).  Saving model ...
Validation loss decreased (1.040188 --> 1.036776).  Saving model ...
Validation loss decreased (1.036776 --> 1.032265).  Saving model ...
Validation loss decreased (1.032265 --> 1.027316).  Saving model ...
Validation loss decreased (1.027316 --> 1.024041).  Saving model ...
Validation loss decreased (1.024041 --> 1.021709).  Saving model ...
Validation loss decreased (1.021709 --> 1.018204).  Saving model ...
Validation loss decreased (1.018204 --> 1.014745).  Saving model ...
Validation loss decreased (1.014745 --> 1.012579).  Saving model ...
Validation loss decreased (1.012579 --> 1.008337).  Saving model ...
Validation loss decreased (1.008337 --> 1.004902).  Saving model ...
Validation loss decreased (1.004902 --> 1.002342).  Saving model ...
Validation loss decreased (1.002342 --> 0.999766).  Saving model ...
Validation loss decreased (0.999766 --> 0.996884).  Saving model ...
Validation loss decreased (0.996884 --> 0.994733).  Saving model ...
Validation loss decreased (0.994733 --> 0.991419).  Saving model ...
Validation loss decreased (0.991419 --> 0.987713).  Saving model ...
Validation loss decreased (0.987713 --> 0.984309).  Saving model ...
Validation loss decreased (0.984309 --> 0.981211).  Saving model ...
Validation loss decreased (0.981211 --> 0.978310).  Saving model ...
Validation loss decreased (0.978310 --> 0.976743).  Saving model ...
Validation loss decreased (0.976743 --> 0.974726).  Saving model ...
Validation loss decreased (0.974726 --> 0.972364).  Saving model ...
Validation loss decreased (0.972364 --> 0.969903).  Saving model ...
Validation loss decreased (0.969903 --> 0.967226).  Saving model ...
Validation loss decreased (0.967226 --> 0.963734).  Saving model ...
Validation loss decreased (0.963734 --> 0.963253).  Saving model ...
Validation loss decreased (0.963253 --> 0.961264).  Saving model ...
Validation loss decreased (0.961264 --> 0.958054).  Saving model ...
Validation loss decreased (0.958054 --> 0.956274).  Saving model ...
Validation loss decreased (0.956274 --> 0.955025).  Saving model ...
Validation loss decreased (0.955025 --> 0.953899).  Saving model ...
Validation loss decreased (0.953899 --> 0.952014).  Saving model ...
Validation loss decreased (0.952014 --> 0.949250).  Saving model ...
Validation loss decreased (0.949250 --> 0.948387).  Saving model ...
Validation loss decreased (0.948387 --> 0.948319).  Saving model ...
Validation loss decreased (0.948319 --> 0.947614).  Saving model ...
Validation loss decreased (0.947614 --> 0.946985).  Saving model ...
Validation loss decreased (0.946985 --> 0.945470).  Saving model ...
Validation loss decreased (0.945470 --> 0.943688).  Saving model ...
Validation loss decreased (0.943688 --> 0.942310).  Saving model ...
Validation loss decreased (0.942310 --> 0.940935).  Saving model ...
Validation loss decreased (0.940935 --> 0.939870).  Saving model ...
Validation loss decreased (0.939870 --> 0.939741).  Saving model ...
EarlyStopping counter: 1 out of 10.0
Validation loss decreased (0.939741 --> 0.938675).  Saving model ...
Validation loss decreased (0.938675 --> 0.937475).  Saving model ...
Validation loss decreased (0.937475 --> 0.936690).  Saving model ...
Validation loss decreased (0.936690 --> 0.935751).  Saving model ...
Validation loss decreased (0.935751 --> 0.935411).  Saving model ...
Validation loss decreased (0.935411 --> 0.934154).  Saving model ...
EarlyStopping counter: 1 out of 10.0
EarlyStopping counter: 2 out of 10.0
Validation loss decreased (0.934154 --> 0.934065).  Saving model ...
EarlyStopping counter: 1 out of 10.0
EarlyStopping counter: 2 out of 10.0
EarlyStopping counter: 3 out of 10.0
EarlyStopping counter: 4 out of 10.0
EarlyStopping counter: 5 out of 10.0
EarlyStopping counter: 6 out of 10.0
EarlyStopping counter: 7 out of 10.0
Validation loss decreased (0.934065 --> 0.933090).  Saving model ...
Validation loss decreased (0.933090 --> 0.932268).  Saving model ...
Validation loss decreased (0.932268 --> 0.931498).  Saving model ...
Validation loss decreased (0.931498 --> 0.930050).  Saving model ...
EarlyStopping counter: 1 out of 10.0
EarlyStopping counter: 2 out of 10.0
EarlyStopping counter: 3 out of 10.0
EarlyStopping counter: 4 out of 10.0
EarlyStopping counter: 5 out of 10.0
EarlyStopping counter: 6 out of 10.0
EarlyStopping counter: 7 out of 10.0
EarlyStopping counter: 8 out of 10.0
EarlyStopping counter: 9 out of 10.0
EarlyStopping counter: 10 out of 10.0
/localscratch/yinan.29019362.0/env/lib/python3.7/site-packages/torch/nn/functional.py:1794: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.
  warnings.warn("nn.functional.tanh is deprecated. Use torch.tanh instead.")
wandb: Waiting for W&B process to finish, PID 6069... (success).
wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: \ 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: | 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: / 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: \ 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: | 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: / 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: \ 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: | 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: / 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb:                                                                                
wandb: Run history:
wandb:     e_F1 ▁▂▃▄▄▄▅▅▅▆▆▆▆▆▆▆▇▇▇▇▇▇▇▇████████████████
wandb:   e_loss ███▇▇▇▇▆▆▅▅▅▄▄▄▃▃▃▃▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:     t_F1 ▁▁▁▂▂▂▂▃▄▄▄▄▅▅▅▆▅▆▆▆▆▆▇▇▇▇▇▇▇▇▇▇▇█▇█▇███
wandb:   t_loss ████▇▇▇▇▇▆▆▆▆▅▅▅▅▄▄▄▄▃▃▃▃▂▂▃▂▂▂▂▂▁▂▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:     e_F1 59.11597
wandb:   e_loss 0.9339
wandb:     t_F1 72.27148
wandb:   t_loss 0.73033
wandb: 
wandb: Synced 4 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Synced hopeful-grass-2: https://wandb.ai/yinanazhou/xl_512_bs_8_lr_1e06_es_10_lc_False_nr_False_sr_True_stem_False_lemma_True_repeat_2_fold_1/runs/3k7amt31
wandb: Find logs at: ./wandb/run-20220318_223528-3k7amt31/logs/debug.log
wandb: 

wandb: wandb version 0.12.11 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
2022-03-19 00:06:50.973668: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1
wandb: Tracking run with wandb version 0.12.5
wandb: Syncing run wise-moon-2
wandb: ⭐️ View project at https://wandb.ai/yinanazhou/xl_512_bs_8_lr_1e06_es_10_lc_False_nr_False_sr_True_stem_False_lemma_True_repeat_2_fold_2
wandb: 🚀 View run at https://wandb.ai/yinanazhou/xl_512_bs_8_lr_1e06_es_10_lc_False_nr_False_sr_True_stem_False_lemma_True_repeat_2_fold_2/runs/1ide8nt0
wandb: Run data is saved locally in /project/6002780/yinan/Thesis_MER_Lyrics/lyric-emotion/wandb/run-20220319_000647-1ide8nt0
wandb: Run `wandb offline` to turn off syncing.

Validation loss decreased (inf --> 1.375734).  Saving model ...
Validation loss decreased (1.375734 --> 1.369930).  Saving model ...
Validation loss decreased (1.369930 --> 1.364336).  Saving model ...
Validation loss decreased (1.364336 --> 1.359105).  Saving model ...
Validation loss decreased (1.359105 --> 1.354113).  Saving model ...
Validation loss decreased (1.354113 --> 1.348888).  Saving model ...
Validation loss decreased (1.348888 --> 1.344547).  Saving model ...
Validation loss decreased (1.344547 --> 1.340212).  Saving model ...
Validation loss decreased (1.340212 --> 1.335888).  Saving model ...
Validation loss decreased (1.335888 --> 1.331015).  Saving model ...
Validation loss decreased (1.331015 --> 1.325647).  Saving model ...
Validation loss decreased (1.325647 --> 1.320096).  Saving model ...
Validation loss decreased (1.320096 --> 1.314963).  Saving model ...
Validation loss decreased (1.314963 --> 1.309632).  Saving model ...
Validation loss decreased (1.309632 --> 1.303074).  Saving model ...
Validation loss decreased (1.303074 --> 1.296557).  Saving model ...
Validation loss decreased (1.296557 --> 1.289875).  Saving model ...
Validation loss decreased (1.289875 --> 1.282706).  Saving model ...
Validation loss decreased (1.282706 --> 1.275865).  Saving model ...
Validation loss decreased (1.275865 --> 1.269039).  Saving model ...
Validation loss decreased (1.269039 --> 1.260892).  Saving model ...
Validation loss decreased (1.260892 --> 1.252502).  Saving model ...
Validation loss decreased (1.252502 --> 1.244071).  Saving model ...
Validation loss decreased (1.244071 --> 1.234924).  Saving model ...
Validation loss decreased (1.234924 --> 1.225385).  Saving model ...
Validation loss decreased (1.225385 --> 1.216058).  Saving model ...
Validation loss decreased (1.216058 --> 1.206372).  Saving model ...
Validation loss decreased (1.206372 --> 1.195580).  Saving model ...
Validation loss decreased (1.195580 --> 1.188221).  Saving model ...
Validation loss decreased (1.188221 --> 1.178563).  Saving model ...
Validation loss decreased (1.178563 --> 1.170502).  Saving model ...
Validation loss decreased (1.170502 --> 1.161975).  Saving model ...
Validation loss decreased (1.161975 --> 1.154538).  Saving model ...
Validation loss decreased (1.154538 --> 1.148931).  Saving model ...
Validation loss decreased (1.148931 --> 1.143389).  Saving model ...
Validation loss decreased (1.143389 --> 1.138769).  Saving model ...
Validation loss decreased (1.138769 --> 1.132678).  Saving model ...
Validation loss decreased (1.132678 --> 1.126657).  Saving model ...
Validation loss decreased (1.126657 --> 1.119760).  Saving model ...
Validation loss decreased (1.119760 --> 1.112633).  Saving model ...
Validation loss decreased (1.112633 --> 1.106801).  Saving model ...
Validation loss decreased (1.106801 --> 1.103160).  Saving model ...
Validation loss decreased (1.103160 --> 1.097894).  Saving model ...
Validation loss decreased (1.097894 --> 1.091301).  Saving model ...
Validation loss decreased (1.091301 --> 1.086627).  Saving model ...
Validation loss decreased (1.086627 --> 1.083162).  Saving model ...
Validation loss decreased (1.083162 --> 1.077091).  Saving model ...
Validation loss decreased (1.077091 --> 1.072843).  Saving model ...
Validation loss decreased (1.072843 --> 1.068308).  Saving model ...
Validation loss decreased (1.068308 --> 1.062101).  Saving model ...
Validation loss decreased (1.062101 --> 1.057455).  Saving model ...
Validation loss decreased (1.057455 --> 1.054748).  Saving model ...
Validation loss decreased (1.054748 --> 1.050968).  Saving model ...
Validation loss decreased (1.050968 --> 1.046102).  Saving model ...
Validation loss decreased (1.046102 --> 1.043602).  Saving model ...
Validation loss decreased (1.043602 --> 1.038892).  Saving model ...
Validation loss decreased (1.038892 --> 1.038167).  Saving model ...
Validation loss decreased (1.038167 --> 1.033214).  Saving model ...
Validation loss decreased (1.033214 --> 1.028888).  Saving model ...
Validation loss decreased (1.028888 --> 1.023222).  Saving model ...
Validation loss decreased (1.023222 --> 1.019130).  Saving model ...
Validation loss decreased (1.019130 --> 1.017702).  Saving model ...
Validation loss decreased (1.017702 --> 1.015553).  Saving model ...
Validation loss decreased (1.015553 --> 1.013612).  Saving model ...
Validation loss decreased (1.013612 --> 1.006987).  Saving model ...
Validation loss decreased (1.006987 --> 1.004602).  Saving model ...
Validation loss decreased (1.004602 --> 1.000628).  Saving model ...
Validation loss decreased (1.000628 --> 0.994139).  Saving model ...
Validation loss decreased (0.994139 --> 0.991868).  Saving model ...
Validation loss decreased (0.991868 --> 0.988666).  Saving model ...
Validation loss decreased (0.988666 --> 0.988140).  Saving model ...
Validation loss decreased (0.988140 --> 0.984952).  Saving model ...
Validation loss decreased (0.984952 --> 0.984812).  Saving model ...
Validation loss decreased (0.984812 --> 0.981645).  Saving model ...
Validation loss decreased (0.981645 --> 0.977974).  Saving model ...
Validation loss decreased (0.977974 --> 0.975344).  Saving model ...
Validation loss decreased (0.975344 --> 0.974262).  Saving model ...
Validation loss decreased (0.974262 --> 0.970183).  Saving model ...
Validation loss decreased (0.970183 --> 0.967649).  Saving model ...
Validation loss decreased (0.967649 --> 0.966069).  Saving model ...
Validation loss decreased (0.966069 --> 0.962937).  Saving model ...
Validation loss decreased (0.962937 --> 0.960126).  Saving model ...
Validation loss decreased (0.960126 --> 0.955467).  Saving model ...
Validation loss decreased (0.955467 --> 0.953572).  Saving model ...
Validation loss decreased (0.953572 --> 0.952452).  Saving model ...
Validation loss decreased (0.952452 --> 0.951915).  Saving model ...
Validation loss decreased (0.951915 --> 0.949266).  Saving model ...
Validation loss decreased (0.949266 --> 0.948488).  Saving model ...
Validation loss decreased (0.948488 --> 0.947052).  Saving model ...
Validation loss decreased (0.947052 --> 0.943516).  Saving model ...
Validation loss decreased (0.943516 --> 0.941661).  Saving model ...
Validation loss decreased (0.941661 --> 0.940823).  Saving model ...
Validation loss decreased (0.940823 --> 0.939198).  Saving model ...
Validation loss decreased (0.939198 --> 0.938050).  Saving model ...
Validation loss decreased (0.938050 --> 0.935818).  Saving model ...
Validation loss decreased (0.935818 --> 0.933995).  Saving model ...
Validation loss decreased (0.933995 --> 0.933136).  Saving model ...
Validation loss decreased (0.933136 --> 0.932637).  Saving model ...
EarlyStopping counter: 1 out of 10.0
Validation loss decreased (0.932637 --> 0.930714).  Saving model ...
Validation loss decreased (0.930714 --> 0.930012).  Saving model ...
EarlyStopping counter: 1 out of 10.0
Validation loss decreased (0.930012 --> 0.928421).  Saving model ...
Validation loss decreased (0.928421 --> 0.926684).  Saving model ...
Validation loss decreased (0.926684 --> 0.922477).  Saving model ...
Validation loss decreased (0.922477 --> 0.921612).  Saving model ...
Validation loss decreased (0.921612 --> 0.921088).  Saving model ...
Validation loss decreased (0.921088 --> 0.920411).  Saving model ...
Validation loss decreased (0.920411 --> 0.918730).  Saving model ...
Validation loss decreased (0.918730 --> 0.918578).  Saving model ...
EarlyStopping counter: 1 out of 10.0
EarlyStopping counter: 2 out of 10.0
Validation loss decreased (0.918578 --> 0.916653).  Saving model ...
Validation loss decreased (0.916653 --> 0.915949).  Saving model ...
Validation loss decreased (0.915949 --> 0.914652).  Saving model ...
EarlyStopping counter: 1 out of 10.0
Validation loss decreased (0.914652 --> 0.914391).  Saving model ...
EarlyStopping counter: 1 out of 10.0
Validation loss decreased (0.914391 --> 0.914240).  Saving model ...
Validation loss decreased (0.914240 --> 0.914074).  Saving model ...
EarlyStopping counter: 1 out of 10.0
Validation loss decreased (0.914074 --> 0.912779).  Saving model ...
Validation loss decreased (0.912779 --> 0.912014).  Saving model ...
Validation loss decreased (0.912014 --> 0.911663).  Saving model ...
Validation loss decreased (0.911663 --> 0.911060).  Saving model ...
Validation loss decreased (0.911060 --> 0.910376).  Saving model ...
EarlyStopping counter: 1 out of 10.0
EarlyStopping counter: 2 out of 10.0
EarlyStopping counter: 3 out of 10.0
EarlyStopping counter: 4 out of 10.0
EarlyStopping counter: 5 out of 10.0
EarlyStopping counter: 6 out of 10.0
EarlyStopping counter: 7 out of 10.0
EarlyStopping counter: 8 out of 10.0
EarlyStopping counter: 9 out of 10.0
EarlyStopping counter: 10 out of 10.0
/localscratch/yinan.29019362.0/env/lib/python3.7/site-packages/torch/nn/functional.py:1794: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.
  warnings.warn("nn.functional.tanh is deprecated. Use torch.tanh instead.")
wandb: Waiting for W&B process to finish, PID 11027... (success).
wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: \ 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: | 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: / 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: \ 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: | 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: / 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: \ 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: | 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: / 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb:                                                                                
wandb: Run history:
wandb:     e_F1 ▁▃▃▃▄▄▄▅▅▆▆▆▆▆▆▆▇▇▇▇▇▇▇▇████████████████
wandb:   e_loss ███▇▇▇▆▆▅▅▄▄▄▄▃▃▃▃▃▂▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:     t_F1 ▁▁▂▃▂▃▃▄▄▄▅▅▅▅▅▆▆▆▇▆▆▆▆▆▇▇▇▇▇▇▇▇██▇▇▇███
wandb:   t_loss ███▇▇▇▇▆▆▆▆▅▅▅▅▅▄▄▄▄▄▃▃▃▃▃▃▂▂▂▂▂▂▂▂▂▁▁▁▁
wandb: 
wandb: Run summary:
wandb:     e_F1 62.45408
wandb:   e_loss 0.91204
wandb:     t_F1 72.86432
wandb:   t_loss 0.7285
wandb: 
wandb: Synced 4 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Synced wise-moon-2: https://wandb.ai/yinanazhou/xl_512_bs_8_lr_1e06_es_10_lc_False_nr_False_sr_True_stem_False_lemma_True_repeat_2_fold_2/runs/1ide8nt0
wandb: Find logs at: ./wandb/run-20220319_000647-1ide8nt0/logs/debug.log
wandb: 

wandb: wandb version 0.12.11 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
2022-03-19 01:37:19.387710: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1
wandb: Tracking run with wandb version 0.12.5
wandb: Syncing run sunny-surf-2
wandb: ⭐️ View project at https://wandb.ai/yinanazhou/xl_512_bs_8_lr_1e06_es_10_lc_False_nr_False_sr_True_stem_False_lemma_True_repeat_3_fold_1
wandb: 🚀 View run at https://wandb.ai/yinanazhou/xl_512_bs_8_lr_1e06_es_10_lc_False_nr_False_sr_True_stem_False_lemma_True_repeat_3_fold_1/runs/3vg9uu34
wandb: Run data is saved locally in /project/6002780/yinan/Thesis_MER_Lyrics/lyric-emotion/wandb/run-20220319_013716-3vg9uu34
wandb: Run `wandb offline` to turn off syncing.

Validation loss decreased (inf --> 1.388179).  Saving model ...
Validation loss decreased (1.388179 --> 1.379325).  Saving model ...
Validation loss decreased (1.379325 --> 1.372751).  Saving model ...
Validation loss decreased (1.372751 --> 1.366837).  Saving model ...
Validation loss decreased (1.366837 --> 1.361522).  Saving model ...
Validation loss decreased (1.361522 --> 1.357096).  Saving model ...
Validation loss decreased (1.357096 --> 1.352519).  Saving model ...
Validation loss decreased (1.352519 --> 1.348268).  Saving model ...
Validation loss decreased (1.348268 --> 1.343778).  Saving model ...
Validation loss decreased (1.343778 --> 1.339597).  Saving model ...
Validation loss decreased (1.339597 --> 1.334979).  Saving model ...
Validation loss decreased (1.334979 --> 1.329349).  Saving model ...
Validation loss decreased (1.329349 --> 1.324455).  Saving model ...
Validation loss decreased (1.324455 --> 1.318841).  Saving model ...
Validation loss decreased (1.318841 --> 1.312513).  Saving model ...
Validation loss decreased (1.312513 --> 1.305761).  Saving model ...
Validation loss decreased (1.305761 --> 1.300000).  Saving model ...
Validation loss decreased (1.300000 --> 1.293240).  Saving model ...
Validation loss decreased (1.293240 --> 1.287055).  Saving model ...
Validation loss decreased (1.287055 --> 1.279195).  Saving model ...
Validation loss decreased (1.279195 --> 1.272001).  Saving model ...
Validation loss decreased (1.272001 --> 1.265361).  Saving model ...
Validation loss decreased (1.265361 --> 1.258289).  Saving model ...
Validation loss decreased (1.258289 --> 1.252349).  Saving model ...
Validation loss decreased (1.252349 --> 1.244443).  Saving model ...
Validation loss decreased (1.244443 --> 1.236047).  Saving model ...
Validation loss decreased (1.236047 --> 1.228738).  Saving model ...
Validation loss decreased (1.228738 --> 1.220041).  Saving model ...
Validation loss decreased (1.220041 --> 1.214357).  Saving model ...
Validation loss decreased (1.214357 --> 1.208031).  Saving model ...
Validation loss decreased (1.208031 --> 1.202330).  Saving model ...
Validation loss decreased (1.202330 --> 1.193231).  Saving model ...
Validation loss decreased (1.193231 --> 1.185064).  Saving model ...
Validation loss decreased (1.185064 --> 1.177558).  Saving model ...
Validation loss decreased (1.177558 --> 1.172501).  Saving model ...
Validation loss decreased (1.172501 --> 1.163894).  Saving model ...
Validation loss decreased (1.163894 --> 1.157639).  Saving model ...
Validation loss decreased (1.157639 --> 1.153330).  Saving model ...
Validation loss decreased (1.153330 --> 1.147746).  Saving model ...
Validation loss decreased (1.147746 --> 1.142671).  Saving model ...
Validation loss decreased (1.142671 --> 1.138148).  Saving model ...
Validation loss decreased (1.138148 --> 1.134898).  Saving model ...
Validation loss decreased (1.134898 --> 1.126997).  Saving model ...
Validation loss decreased (1.126997 --> 1.120050).  Saving model ...
Validation loss decreased (1.120050 --> 1.114218).  Saving model ...
Validation loss decreased (1.114218 --> 1.111569).  Saving model ...
Validation loss decreased (1.111569 --> 1.104694).  Saving model ...
Validation loss decreased (1.104694 --> 1.101243).  Saving model ...
Validation loss decreased (1.101243 --> 1.097409).  Saving model ...
Validation loss decreased (1.097409 --> 1.092887).  Saving model ...
Validation loss decreased (1.092887 --> 1.089765).  Saving model ...
Validation loss decreased (1.089765 --> 1.086097).  Saving model ...
Validation loss decreased (1.086097 --> 1.080938).  Saving model ...
Validation loss decreased (1.080938 --> 1.075673).  Saving model ...
Validation loss decreased (1.075673 --> 1.068988).  Saving model ...
Validation loss decreased (1.068988 --> 1.065424).  Saving model ...
Validation loss decreased (1.065424 --> 1.061015).  Saving model ...
Validation loss decreased (1.061015 --> 1.056768).  Saving model ...
Validation loss decreased (1.056768 --> 1.053248).  Saving model ...
EarlyStopping counter: 1 out of 10.0
Validation loss decreased (1.053248 --> 1.050346).  Saving model ...
Validation loss decreased (1.050346 --> 1.045642).  Saving model ...
Validation loss decreased (1.045642 --> 1.042781).  Saving model ...
Validation loss decreased (1.042781 --> 1.039394).  Saving model ...
Validation loss decreased (1.039394 --> 1.036398).  Saving model ...
Validation loss decreased (1.036398 --> 1.032629).  Saving model ...
Validation loss decreased (1.032629 --> 1.027888).  Saving model ...
EarlyStopping counter: 1 out of 10.0
Validation loss decreased (1.027888 --> 1.025627).  Saving model ...
Validation loss decreased (1.025627 --> 1.021458).  Saving model ...
Validation loss decreased (1.021458 --> 1.019028).  Saving model ...
Validation loss decreased (1.019028 --> 1.015863).  Saving model ...
Validation loss decreased (1.015863 --> 1.012700).  Saving model ...
Validation loss decreased (1.012700 --> 1.009013).  Saving model ...
Validation loss decreased (1.009013 --> 1.006251).  Saving model ...
Validation loss decreased (1.006251 --> 1.001899).  Saving model ...
Validation loss decreased (1.001899 --> 1.000715).  Saving model ...
Validation loss decreased (1.000715 --> 0.998934).  Saving model ...
EarlyStopping counter: 1 out of 10.0
Validation loss decreased (0.998934 --> 0.997298).  Saving model ...
Validation loss decreased (0.997298 --> 0.996526).  Saving model ...
Validation loss decreased (0.996526 --> 0.991978).  Saving model ...
Validation loss decreased (0.991978 --> 0.990498).  Saving model ...
EarlyStopping counter: 1 out of 10.0
Validation loss decreased (0.990498 --> 0.987968).  Saving model ...
Validation loss decreased (0.987968 --> 0.986935).  Saving model ...
Validation loss decreased (0.986935 --> 0.985178).  Saving model ...
EarlyStopping counter: 1 out of 10.0
Validation loss decreased (0.985178 --> 0.983989).  Saving model ...
Validation loss decreased (0.983989 --> 0.981819).  Saving model ...
Validation loss decreased (0.981819 --> 0.978606).  Saving model ...
EarlyStopping counter: 1 out of 10.0
Validation loss decreased (0.978606 --> 0.975512).  Saving model ...
Validation loss decreased (0.975512 --> 0.975445).  Saving model ...
Validation loss decreased (0.975445 --> 0.973205).  Saving model ...
Validation loss decreased (0.973205 --> 0.970433).  Saving model ...
Validation loss decreased (0.970433 --> 0.970256).  Saving model ...
EarlyStopping counter: 1 out of 10.0
EarlyStopping counter: 2 out of 10.0
EarlyStopping counter: 3 out of 10.0
EarlyStopping counter: 4 out of 10.0
Validation loss decreased (0.970256 --> 0.970204).  Saving model ...
EarlyStopping counter: 1 out of 10.0
Validation loss decreased (0.970204 --> 0.969080).  Saving model ...
Validation loss decreased (0.969080 --> 0.967155).  Saving model ...
EarlyStopping counter: 1 out of 10.0
EarlyStopping counter: 2 out of 10.0
EarlyStopping counter: 3 out of 10.0
EarlyStopping counter: 4 out of 10.0
EarlyStopping counter: 5 out of 10.0
EarlyStopping counter: 6 out of 10.0
EarlyStopping counter: 7 out of 10.0
Validation loss decreased (0.967155 --> 0.963917).  Saving model ...
EarlyStopping counter: 1 out of 10.0
EarlyStopping counter: 2 out of 10.0
EarlyStopping counter: 3 out of 10.0
EarlyStopping counter: 4 out of 10.0
Validation loss decreased (0.963917 --> 0.963541).  Saving model ...
Validation loss decreased (0.963541 --> 0.963500).  Saving model ...
EarlyStopping counter: 1 out of 10.0
EarlyStopping counter: 2 out of 10.0
EarlyStopping counter: 3 out of 10.0
EarlyStopping counter: 4 out of 10.0
EarlyStopping counter: 5 out of 10.0
EarlyStopping counter: 6 out of 10.0
EarlyStopping counter: 7 out of 10.0
EarlyStopping counter: 8 out of 10.0
EarlyStopping counter: 9 out of 10.0
EarlyStopping counter: 10 out of 10.0
/localscratch/yinan.29019362.0/env/lib/python3.7/site-packages/torch/nn/functional.py:1794: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.
  warnings.warn("nn.functional.tanh is deprecated. Use torch.tanh instead.")
wandb: Waiting for W&B process to finish, PID 15894... (success).
wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: \ 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: | 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: / 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: \ 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: | 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: / 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: \ 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: | 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: / 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: \ 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: | 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: / 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: \ 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: | 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: / 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: \ 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: | 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: / 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: \ 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb:                                                                                
wandb: Run history:
wandb:     e_F1 ▁▃▄▄▅▅▅▆▆▇▇▇▇▆▇▇▇▇▇▇█▇██████████████████
wandb:   e_loss ██▇▇▇▇▆▆▆▅▅▄▄▄▃▃▃▃▃▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:     t_F1 ▁▁▂▂▃▃▄▄▄▄▅▅▅▅▆▆▆▆▆▆▆▆▆▇▇▇▇▇▇▇█▇████████
wandb:   t_loss ████▇▇▇▇▆▆▆▆▅▅▅▅▅▄▄▄▄▃▃▃▃▃▂▂▃▂▂▂▂▂▂▂▁▁▁▁
wandb: 
wandb: Run summary:
wandb:     e_F1 59.3982
wandb:   e_loss 0.96991
wandb:     t_F1 76.13685
wandb:   t_loss 0.70118
wandb: 
wandb: Synced 4 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Synced sunny-surf-2: https://wandb.ai/yinanazhou/xl_512_bs_8_lr_1e06_es_10_lc_False_nr_False_sr_True_stem_False_lemma_True_repeat_3_fold_1/runs/3vg9uu34
wandb: Find logs at: ./wandb/run-20220319_013716-3vg9uu34/logs/debug.log
wandb: 

wandb: wandb version 0.12.11 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
2022-03-19 03:01:10.581294: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1
wandb: Tracking run with wandb version 0.12.5
wandb: Syncing run earthy-grass-2
wandb: ⭐️ View project at https://wandb.ai/yinanazhou/xl_512_bs_8_lr_1e06_es_10_lc_False_nr_False_sr_True_stem_False_lemma_True_repeat_3_fold_2
wandb: 🚀 View run at https://wandb.ai/yinanazhou/xl_512_bs_8_lr_1e06_es_10_lc_False_nr_False_sr_True_stem_False_lemma_True_repeat_3_fold_2/runs/35jg8ybs
wandb: Run data is saved locally in /project/6002780/yinan/Thesis_MER_Lyrics/lyric-emotion/wandb/run-20220319_030107-35jg8ybs
wandb: Run `wandb offline` to turn off syncing.

Validation loss decreased (inf --> 1.408969).  Saving model ...
Validation loss decreased (1.408969 --> 1.400809).  Saving model ...
Validation loss decreased (1.400809 --> 1.393689).  Saving model ...
Validation loss decreased (1.393689 --> 1.386904).  Saving model ...
Validation loss decreased (1.386904 --> 1.381114).  Saving model ...
Validation loss decreased (1.381114 --> 1.375160).  Saving model ...
Validation loss decreased (1.375160 --> 1.369771).  Saving model ...
Validation loss decreased (1.369771 --> 1.364596).  Saving model ...
Validation loss decreased (1.364596 --> 1.359092).  Saving model ...
Validation loss decreased (1.359092 --> 1.353217).  Saving model ...
Validation loss decreased (1.353217 --> 1.347523).  Saving model ...
Validation loss decreased (1.347523 --> 1.342782).  Saving model ...
Validation loss decreased (1.342782 --> 1.337731).  Saving model ...
Validation loss decreased (1.337731 --> 1.332456).  Saving model ...
Validation loss decreased (1.332456 --> 1.326610).  Saving model ...
Validation loss decreased (1.326610 --> 1.321297).  Saving model ...
Validation loss decreased (1.321297 --> 1.314907).  Saving model ...
Validation loss decreased (1.314907 --> 1.309016).  Saving model ...
Validation loss decreased (1.309016 --> 1.302647).  Saving model ...
Validation loss decreased (1.302647 --> 1.295777).  Saving model ...
Validation loss decreased (1.295777 --> 1.288849).  Saving model ...
Validation loss decreased (1.288849 --> 1.281157).  Saving model ...
Validation loss decreased (1.281157 --> 1.271580).  Saving model ...
Validation loss decreased (1.271580 --> 1.262166).  Saving model ...
Validation loss decreased (1.262166 --> 1.254353).  Saving model ...
Validation loss decreased (1.254353 --> 1.245453).  Saving model ...
Validation loss decreased (1.245453 --> 1.235876).  Saving model ...
Validation loss decreased (1.235876 --> 1.226564).  Saving model ...
Validation loss decreased (1.226564 --> 1.218659).  Saving model ...
Validation loss decreased (1.218659 --> 1.209353).  Saving model ...
Validation loss decreased (1.209353 --> 1.200550).  Saving model ...
Validation loss decreased (1.200550 --> 1.193351).  Saving model ...
Validation loss decreased (1.193351 --> 1.185055).  Saving model ...
Validation loss decreased (1.185055 --> 1.178412).  Saving model ...
Validation loss decreased (1.178412 --> 1.170253).  Saving model ...
Validation loss decreased (1.170253 --> 1.161610).  Saving model ...
Validation loss decreased (1.161610 --> 1.154469).  Saving model ...
Validation loss decreased (1.154469 --> 1.146191).  Saving model ...
Validation loss decreased (1.146191 --> 1.139046).  Saving model ...
Validation loss decreased (1.139046 --> 1.130537).  Saving model ...
Validation loss decreased (1.130537 --> 1.124616).  Saving model ...
Validation loss decreased (1.124616 --> 1.117727).  Saving model ...
Validation loss decreased (1.117727 --> 1.110287).  Saving model ...
Validation loss decreased (1.110287 --> 1.103786).  Saving model ...
Validation loss decreased (1.103786 --> 1.097611).  Saving model ...
Validation loss decreased (1.097611 --> 1.091843).  Saving model ...
Validation loss decreased (1.091843 --> 1.083997).  Saving model ...
Validation loss decreased (1.083997 --> 1.076086).  Saving model ...
Validation loss decreased (1.076086 --> 1.069193).  Saving model ...
Validation loss decreased (1.069193 --> 1.062267).  Saving model ...
Validation loss decreased (1.062267 --> 1.056765).  Saving model ...
Validation loss decreased (1.056765 --> 1.051881).  Saving model ...
Validation loss decreased (1.051881 --> 1.047306).  Saving model ...
Validation loss decreased (1.047306 --> 1.043452).  Saving model ...
Validation loss decreased (1.043452 --> 1.040072).  Saving model ...
Validation loss decreased (1.040072 --> 1.035069).  Saving model ...
Validation loss decreased (1.035069 --> 1.030958).  Saving model ...
Validation loss decreased (1.030958 --> 1.027189).  Saving model ...
Validation loss decreased (1.027189 --> 1.020985).  Saving model ...
Validation loss decreased (1.020985 --> 1.015736).  Saving model ...
Validation loss decreased (1.015736 --> 1.012734).  Saving model ...
Validation loss decreased (1.012734 --> 1.006192).  Saving model ...
Validation loss decreased (1.006192 --> 1.002087).  Saving model ...
Validation loss decreased (1.002087 --> 0.997578).  Saving model ...
Validation loss decreased (0.997578 --> 0.995539).  Saving model ...
Validation loss decreased (0.995539 --> 0.992195).  Saving model ...
Validation loss decreased (0.992195 --> 0.989217).  Saving model ...
Validation loss decreased (0.989217 --> 0.986391).  Saving model ...
Validation loss decreased (0.986391 --> 0.982199).  Saving model ...
Validation loss decreased (0.982199 --> 0.978298).  Saving model ...
Validation loss decreased (0.978298 --> 0.973947).  Saving model ...
Validation loss decreased (0.973947 --> 0.969952).  Saving model ...
Validation loss decreased (0.969952 --> 0.966950).  Saving model ...
Validation loss decreased (0.966950 --> 0.962735).  Saving model ...
Validation loss decreased (0.962735 --> 0.961542).  Saving model ...
Validation loss decreased (0.961542 --> 0.957200).  Saving model ...
Validation loss decreased (0.957200 --> 0.952638).  Saving model ...
Validation loss decreased (0.952638 --> 0.951368).  Saving model ...
Validation loss decreased (0.951368 --> 0.946906).  Saving model ...
Validation loss decreased (0.946906 --> 0.942382).  Saving model ...
Validation loss decreased (0.942382 --> 0.938950).  Saving model ...
Validation loss decreased (0.938950 --> 0.936024).  Saving model ...
Validation loss decreased (0.936024 --> 0.934503).  Saving model ...
Validation loss decreased (0.934503 --> 0.932090).  Saving model ...
Validation loss decreased (0.932090 --> 0.930385).  Saving model ...
Validation loss decreased (0.930385 --> 0.926782).  Saving model ...
EarlyStopping counter: 1 out of 10.0
Validation loss decreased (0.926782 --> 0.921928).  Saving model ...
Validation loss decreased (0.921928 --> 0.919307).  Saving model ...
Validation loss decreased (0.919307 --> 0.915383).  Saving model ...
EarlyStopping counter: 1 out of 10.0
Validation loss decreased (0.915383 --> 0.914715).  Saving model ...
Validation loss decreased (0.914715 --> 0.911248).  Saving model ...
Validation loss decreased (0.911248 --> 0.910302).  Saving model ...
Validation loss decreased (0.910302 --> 0.907443).  Saving model ...
Validation loss decreased (0.907443 --> 0.906552).  Saving model ...
Validation loss decreased (0.906552 --> 0.903461).  Saving model ...
EarlyStopping counter: 1 out of 10.0
Validation loss decreased (0.903461 --> 0.900989).  Saving model ...
Validation loss decreased (0.900989 --> 0.899754).  Saving model ...
Validation loss decreased (0.899754 --> 0.897702).  Saving model ...
Validation loss decreased (0.897702 --> 0.895513).  Saving model ...
Validation loss decreased (0.895513 --> 0.895178).  Saving model ...
Validation loss decreased (0.895178 --> 0.894839).  Saving model ...
Validation loss decreased (0.894839 --> 0.894531).  Saving model ...
Validation loss decreased (0.894531 --> 0.893357).  Saving model ...
Validation loss decreased (0.893357 --> 0.891754).  Saving model ...
Validation loss decreased (0.891754 --> 0.889453).  Saving model ...
Validation loss decreased (0.889453 --> 0.888560).  Saving model ...
Validation loss decreased (0.888560 --> 0.886730).  Saving model ...
EarlyStopping counter: 1 out of 10.0
EarlyStopping counter: 2 out of 10.0
EarlyStopping counter: 3 out of 10.0
Validation loss decreased (0.886730 --> 0.884915).  Saving model ...
Validation loss decreased (0.884915 --> 0.884598).  Saving model ...
Validation loss decreased (0.884598 --> 0.882407).  Saving model ...
Validation loss decreased (0.882407 --> 0.881174).  Saving model ...
Validation loss decreased (0.881174 --> 0.880320).  Saving model ...
EarlyStopping counter: 1 out of 10.0
EarlyStopping counter: 2 out of 10.0
Validation loss decreased (0.880320 --> 0.880168).  Saving model ...
Validation loss decreased (0.880168 --> 0.878964).  Saving model ...
EarlyStopping counter: 1 out of 10.0
Validation loss decreased (0.878964 --> 0.877540).  Saving model ...
EarlyStopping counter: 1 out of 10.0
EarlyStopping counter: 2 out of 10.0
EarlyStopping counter: 3 out of 10.0
EarlyStopping counter: 4 out of 10.0
EarlyStopping counter: 5 out of 10.0
EarlyStopping counter: 6 out of 10.0
EarlyStopping counter: 7 out of 10.0
Validation loss decreased (0.877540 --> 0.877482).  Saving model ...
EarlyStopping counter: 1 out of 10.0
EarlyStopping counter: 2 out of 10.0
Validation loss decreased (0.877482 --> 0.877401).  Saving model ...
Validation loss decreased (0.877401 --> 0.876263).  Saving model ...
EarlyStopping counter: 1 out of 10.0
Validation loss decreased (0.876263 --> 0.875442).  Saving model ...
EarlyStopping counter: 1 out of 10.0
EarlyStopping counter: 2 out of 10.0
EarlyStopping counter: 3 out of 10.0
EarlyStopping counter: 4 out of 10.0
EarlyStopping counter: 5 out of 10.0
EarlyStopping counter: 6 out of 10.0
EarlyStopping counter: 7 out of 10.0
EarlyStopping counter: 8 out of 10.0
EarlyStopping counter: 9 out of 10.0
EarlyStopping counter: 10 out of 10.0
/localscratch/yinan.29019362.0/env/lib/python3.7/site-packages/torch/nn/functional.py:1794: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.
  warnings.warn("nn.functional.tanh is deprecated. Use torch.tanh instead.")
wandb: Waiting for W&B process to finish, PID 20407... (success).
wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: \ 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: | 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: / 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: \ 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: | 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: / 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: \ 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: | 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: / 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb:                                                                                
wandb: Run history:
wandb:     e_F1 ▁▁▂▃▄▅▆▅▅▆▆▇▇▇▇▇▇▇▇▇▇▇▇▇████████████████
wandb:   e_loss ███▇▇▇▆▆▅▅▅▄▄▃▃▃▃▃▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:     t_F1 ▁▂▂▃▃▄▄▄▅▄▅▅▆▆▆▆▆▆▆▆▇▇▇▇▇▇▇▇▇▇▇██▇▇█████
wandb:   t_loss ███▇▇▇▇▆▆▆▆▆▅▅▅▄▄▄▄▄▃▃▃▃▃▃▂▂▂▂▂▂▂▂▂▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:     e_F1 64.44647
wandb:   e_loss 0.88026
wandb:     t_F1 72.52954
wandb:   t_loss 0.72318
wandb: 
wandb: Synced 4 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Synced earthy-grass-2: https://wandb.ai/yinanazhou/xl_512_bs_8_lr_1e06_es_10_lc_False_nr_False_sr_True_stem_False_lemma_True_repeat_3_fold_2/runs/35jg8ybs
wandb: Find logs at: ./wandb/run-20220319_030107-35jg8ybs/logs/debug.log
wandb: 

wandb: wandb version 0.12.11 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
2022-03-19 04:35:10.552579: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1
wandb: Tracking run with wandb version 0.12.5
wandb: Syncing run twilight-sun-2
wandb: ⭐️ View project at https://wandb.ai/yinanazhou/xl_512_bs_8_lr_1e06_es_10_lc_False_nr_False_sr_True_stem_False_lemma_True_repeat_4_fold_1
wandb: 🚀 View run at https://wandb.ai/yinanazhou/xl_512_bs_8_lr_1e06_es_10_lc_False_nr_False_sr_True_stem_False_lemma_True_repeat_4_fold_1/runs/3afe6hmi
wandb: Run data is saved locally in /project/6002780/yinan/Thesis_MER_Lyrics/lyric-emotion/wandb/run-20220319_043506-3afe6hmi
wandb: Run `wandb offline` to turn off syncing.

Validation loss decreased (inf --> 1.430307).  Saving model ...
Validation loss decreased (1.430307 --> 1.403616).  Saving model ...
Validation loss decreased (1.403616 --> 1.385577).  Saving model ...
Validation loss decreased (1.385577 --> 1.371324).  Saving model ...
Validation loss decreased (1.371324 --> 1.361356).  Saving model ...
Validation loss decreased (1.361356 --> 1.353516).  Saving model ...
Validation loss decreased (1.353516 --> 1.346557).  Saving model ...
Validation loss decreased (1.346557 --> 1.340584).  Saving model ...
Validation loss decreased (1.340584 --> 1.334686).  Saving model ...
Validation loss decreased (1.334686 --> 1.329443).  Saving model ...
Validation loss decreased (1.329443 --> 1.324190).  Saving model ...
Validation loss decreased (1.324190 --> 1.318336).  Saving model ...
Validation loss decreased (1.318336 --> 1.312182).  Saving model ...
Validation loss decreased (1.312182 --> 1.305460).  Saving model ...
Validation loss decreased (1.305460 --> 1.298820).  Saving model ...
Validation loss decreased (1.298820 --> 1.292483).  Saving model ...
Validation loss decreased (1.292483 --> 1.285662).  Saving model ...
Validation loss decreased (1.285662 --> 1.279141).  Saving model ...
Validation loss decreased (1.279141 --> 1.271464).  Saving model ...
Validation loss decreased (1.271464 --> 1.264249).  Saving model ...
Validation loss decreased (1.264249 --> 1.256832).  Saving model ...
Validation loss decreased (1.256832 --> 1.249443).  Saving model ...
Validation loss decreased (1.249443 --> 1.240942).  Saving model ...
Validation loss decreased (1.240942 --> 1.234464).  Saving model ...
Validation loss decreased (1.234464 --> 1.227546).  Saving model ...
Validation loss decreased (1.227546 --> 1.220445).  Saving model ...
Validation loss decreased (1.220445 --> 1.213150).  Saving model ...
Validation loss decreased (1.213150 --> 1.205345).  Saving model ...
Validation loss decreased (1.205345 --> 1.199340).  Saving model ...
Validation loss decreased (1.199340 --> 1.193169).  Saving model ...
Validation loss decreased (1.193169 --> 1.187538).  Saving model ...
Validation loss decreased (1.187538 --> 1.180949).  Saving model ...
Validation loss decreased (1.180949 --> 1.174359).  Saving model ...
Validation loss decreased (1.174359 --> 1.168382).  Saving model ...
Validation loss decreased (1.168382 --> 1.162252).  Saving model ...
Validation loss decreased (1.162252 --> 1.156816).  Saving model ...
Validation loss decreased (1.156816 --> 1.150599).  Saving model ...
Validation loss decreased (1.150599 --> 1.145582).  Saving model ...
Validation loss decreased (1.145582 --> 1.139786).  Saving model ...
Validation loss decreased (1.139786 --> 1.135059).  Saving model ...
Validation loss decreased (1.135059 --> 1.129466).  Saving model ...
Validation loss decreased (1.129466 --> 1.124868).  Saving model ...
Validation loss decreased (1.124868 --> 1.120106).  Saving model ...
Validation loss decreased (1.120106 --> 1.115338).  Saving model ...
Validation loss decreased (1.115338 --> 1.111214).  Saving model ...
Validation loss decreased (1.111214 --> 1.106561).  Saving model ...
Validation loss decreased (1.106561 --> 1.102368).  Saving model ...
Validation loss decreased (1.102368 --> 1.098424).  Saving model ...
Validation loss decreased (1.098424 --> 1.094000).  Saving model ...
Validation loss decreased (1.094000 --> 1.088462).  Saving model ...
Validation loss decreased (1.088462 --> 1.083571).  Saving model ...
Validation loss decreased (1.083571 --> 1.079364).  Saving model ...
Validation loss decreased (1.079364 --> 1.075756).  Saving model ...
Validation loss decreased (1.075756 --> 1.071228).  Saving model ...
Validation loss decreased (1.071228 --> 1.066741).  Saving model ...
Validation loss decreased (1.066741 --> 1.062532).  Saving model ...
Validation loss decreased (1.062532 --> 1.058233).  Saving model ...
Validation loss decreased (1.058233 --> 1.054501).  Saving model ...
Validation loss decreased (1.054501 --> 1.051196).  Saving model ...
Validation loss decreased (1.051196 --> 1.047352).  Saving model ...
Validation loss decreased (1.047352 --> 1.044276).  Saving model ...
Validation loss decreased (1.044276 --> 1.041677).  Saving model ...
Validation loss decreased (1.041677 --> 1.038448).  Saving model ...
Validation loss decreased (1.038448 --> 1.035049).  Saving model ...
Validation loss decreased (1.035049 --> 1.032031).  Saving model ...
Validation loss decreased (1.032031 --> 1.028566).  Saving model ...
Validation loss decreased (1.028566 --> 1.025534).  Saving model ...
Validation loss decreased (1.025534 --> 1.022899).  Saving model ...
Validation loss decreased (1.022899 --> 1.019681).  Saving model ...
Validation loss decreased (1.019681 --> 1.016253).  Saving model ...
Validation loss decreased (1.016253 --> 1.013499).  Saving model ...
Validation loss decreased (1.013499 --> 1.010704).  Saving model ...
Validation loss decreased (1.010704 --> 1.008357).  Saving model ...
Validation loss decreased (1.008357 --> 1.005975).  Saving model ...
Validation loss decreased (1.005975 --> 1.003187).  Saving model ...
Validation loss decreased (1.003187 --> 1.001365).  Saving model ...
Validation loss decreased (1.001365 --> 0.998126).  Saving model ...
Validation loss decreased (0.998126 --> 0.995247).  Saving model ...
Validation loss decreased (0.995247 --> 0.992680).  Saving model ...
Validation loss decreased (0.992680 --> 0.990864).  Saving model ...
Validation loss decreased (0.990864 --> 0.988544).  Saving model ...
Validation loss decreased (0.988544 --> 0.985852).  Saving model ...
Validation loss decreased (0.985852 --> 0.983219).  Saving model ...
Validation loss decreased (0.983219 --> 0.981173).  Saving model ...
Validation loss decreased (0.981173 --> 0.980441).  Saving model ...
Validation loss decreased (0.980441 --> 0.978152).  Saving model ...
Validation loss decreased (0.978152 --> 0.976309).  Saving model ...
Validation loss decreased (0.976309 --> 0.975272).  Saving model ...
Validation loss decreased (0.975272 --> 0.973303).  Saving model ...
Validation loss decreased (0.973303 --> 0.972183).  Saving model ...
Validation loss decreased (0.972183 --> 0.971030).  Saving model ...
Validation loss decreased (0.971030 --> 0.969854).  Saving model ...
Validation loss decreased (0.969854 --> 0.968107).  Saving model ...
Validation loss decreased (0.968107 --> 0.966427).  Saving model ...
EarlyStopping counter: 1 out of 10.0
Validation loss decreased (0.966427 --> 0.964498).  Saving model ...
Validation loss decreased (0.964498 --> 0.964085).  Saving model ...
Validation loss decreased (0.964085 --> 0.963283).  Saving model ...
EarlyStopping counter: 1 out of 10.0
Validation loss decreased (0.963283 --> 0.961526).  Saving model ...
Validation loss decreased (0.961526 --> 0.959768).  Saving model ...
Validation loss decreased (0.959768 --> 0.958313).  Saving model ...
EarlyStopping counter: 1 out of 10.0
Validation loss decreased (0.958313 --> 0.958009).  Saving model ...
Validation loss decreased (0.958009 --> 0.956230).  Saving model ...
Validation loss decreased (0.956230 --> 0.955477).  Saving model ...
EarlyStopping counter: 1 out of 10.0
Validation loss decreased (0.955477 --> 0.954667).  Saving model ...
Validation loss decreased (0.954667 --> 0.954459).  Saving model ...
Validation loss decreased (0.954459 --> 0.953088).  Saving model ...
Validation loss decreased (0.953088 --> 0.950962).  Saving model ...
EarlyStopping counter: 1 out of 10.0
EarlyStopping counter: 2 out of 10.0
EarlyStopping counter: 3 out of 10.0
EarlyStopping counter: 4 out of 10.0
Validation loss decreased (0.950962 --> 0.950936).  Saving model ...
Validation loss decreased (0.950936 --> 0.950863).  Saving model ...
Validation loss decreased (0.950863 --> 0.949776).  Saving model ...
Validation loss decreased (0.949776 --> 0.948526).  Saving model ...
EarlyStopping counter: 1 out of 10.0
Validation loss decreased (0.948526 --> 0.947770).  Saving model ...
Validation loss decreased (0.947770 --> 0.946818).  Saving model ...
Validation loss decreased (0.946818 --> 0.946215).  Saving model ...
Validation loss decreased (0.946215 --> 0.946051).  Saving model ...
EarlyStopping counter: 1 out of 10.0
EarlyStopping counter: 2 out of 10.0
EarlyStopping counter: 3 out of 10.0
Validation loss decreased (0.946051 --> 0.946003).  Saving model ...
EarlyStopping counter: 1 out of 10.0
EarlyStopping counter: 2 out of 10.0
EarlyStopping counter: 3 out of 10.0
EarlyStopping counter: 4 out of 10.0
EarlyStopping counter: 5 out of 10.0
EarlyStopping counter: 6 out of 10.0
EarlyStopping counter: 7 out of 10.0
EarlyStopping counter: 8 out of 10.0
Validation loss decreased (0.946003 --> 0.945685).  Saving model ...
EarlyStopping counter: 1 out of 10.0
EarlyStopping counter: 2 out of 10.0
EarlyStopping counter: 3 out of 10.0
EarlyStopping counter: 4 out of 10.0
EarlyStopping counter: 5 out of 10.0
EarlyStopping counter: 6 out of 10.0
EarlyStopping counter: 7 out of 10.0
EarlyStopping counter: 8 out of 10.0
EarlyStopping counter: 9 out of 10.0
EarlyStopping counter: 10 out of 10.0
/localscratch/yinan.29019362.0/env/lib/python3.7/site-packages/torch/nn/functional.py:1794: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.
  warnings.warn("nn.functional.tanh is deprecated. Use torch.tanh instead.")
wandb: Waiting for W&B process to finish, PID 25682... (success).
wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: \ 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: | 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: / 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: \ 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: | 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: / 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: \ 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: | 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: / 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb:                                                                                
wandb: Run history:
wandb:     e_F1 ▁▂▄▄▄▅▅▆▆▆▆▆▇▇▇▇▇▇▇▇▇▇▇█████████████████
wandb:   e_loss ██▇▇▆▆▅▅▅▄▄▄▃▃▃▃▃▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:     t_F1 ▁▂▂▃▃▃▄▄▄▅▅▅▆▆▆▆▆▆▆▆▆▆▆▆▇▇▆▇▇▇▇▇▇▇▇▇▇▇██
wandb:   t_loss ██▇▇▇▇▆▆▆▅▅▅▅▅▄▄▄▄▄▄▃▃▃▃▃▃▃▂▂▂▂▂▂▂▂▂▁▁▁▁
wandb: 
wandb: Run summary:
wandb:     e_F1 60.19216
wandb:   e_loss 0.95033
wandb:     t_F1 73.40016
wandb:   t_loss 0.71989
wandb: 
wandb: Synced 4 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Synced twilight-sun-2: https://wandb.ai/yinanazhou/xl_512_bs_8_lr_1e06_es_10_lc_False_nr_False_sr_True_stem_False_lemma_True_repeat_4_fold_1/runs/3afe6hmi
wandb: Find logs at: ./wandb/run-20220319_043506-3afe6hmi/logs/debug.log
wandb: 

wandb: wandb version 0.12.11 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
2022-03-19 06:09:31.746190: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1
wandb: Tracking run with wandb version 0.12.5
wandb: Syncing run misunderstood-planet-2
wandb: ⭐️ View project at https://wandb.ai/yinanazhou/xl_512_bs_8_lr_1e06_es_10_lc_False_nr_False_sr_True_stem_False_lemma_True_repeat_4_fold_2
wandb: 🚀 View run at https://wandb.ai/yinanazhou/xl_512_bs_8_lr_1e06_es_10_lc_False_nr_False_sr_True_stem_False_lemma_True_repeat_4_fold_2/runs/26qir3jk
wandb: Run data is saved locally in /project/6002780/yinan/Thesis_MER_Lyrics/lyric-emotion/wandb/run-20220319_060928-26qir3jk
wandb: Run `wandb offline` to turn off syncing.

Validation loss decreased (inf --> 1.414596).  Saving model ...
Validation loss decreased (1.414596 --> 1.396133).  Saving model ...
Validation loss decreased (1.396133 --> 1.382334).  Saving model ...
Validation loss decreased (1.382334 --> 1.371987).  Saving model ...
Validation loss decreased (1.371987 --> 1.363302).  Saving model ...
Validation loss decreased (1.363302 --> 1.355327).  Saving model ...
Validation loss decreased (1.355327 --> 1.348490).  Saving model ...
Validation loss decreased (1.348490 --> 1.342058).  Saving model ...
Validation loss decreased (1.342058 --> 1.336423).  Saving model ...
Validation loss decreased (1.336423 --> 1.330530).  Saving model ...
Validation loss decreased (1.330530 --> 1.324569).  Saving model ...
Validation loss decreased (1.324569 --> 1.318796).  Saving model ...
Validation loss decreased (1.318796 --> 1.311807).  Saving model ...
Validation loss decreased (1.311807 --> 1.304706).  Saving model ...
Validation loss decreased (1.304706 --> 1.298025).  Saving model ...
Validation loss decreased (1.298025 --> 1.289958).  Saving model ...
Validation loss decreased (1.289958 --> 1.281187).  Saving model ...
Validation loss decreased (1.281187 --> 1.273012).  Saving model ...
Validation loss decreased (1.273012 --> 1.264806).  Saving model ...
Validation loss decreased (1.264806 --> 1.256303).  Saving model ...
Validation loss decreased (1.256303 --> 1.247530).  Saving model ...
Validation loss decreased (1.247530 --> 1.239108).  Saving model ...
Validation loss decreased (1.239108 --> 1.230184).  Saving model ...
Validation loss decreased (1.230184 --> 1.223028).  Saving model ...
Validation loss decreased (1.223028 --> 1.212782).  Saving model ...
Validation loss decreased (1.212782 --> 1.204570).  Saving model ...
Validation loss decreased (1.204570 --> 1.195637).  Saving model ...
Validation loss decreased (1.195637 --> 1.187514).  Saving model ...
Validation loss decreased (1.187514 --> 1.179148).  Saving model ...
Validation loss decreased (1.179148 --> 1.170647).  Saving model ...
Validation loss decreased (1.170647 --> 1.161284).  Saving model ...
Validation loss decreased (1.161284 --> 1.154865).  Saving model ...
Validation loss decreased (1.154865 --> 1.148116).  Saving model ...
Validation loss decreased (1.148116 --> 1.139355).  Saving model ...
Validation loss decreased (1.139355 --> 1.131135).  Saving model ...
Validation loss decreased (1.131135 --> 1.123843).  Saving model ...
Validation loss decreased (1.123843 --> 1.116067).  Saving model ...
Validation loss decreased (1.116067 --> 1.107581).  Saving model ...
Validation loss decreased (1.107581 --> 1.101739).  Saving model ...
Validation loss decreased (1.101739 --> 1.095418).  Saving model ...
Validation loss decreased (1.095418 --> 1.089059).  Saving model ...
Validation loss decreased (1.089059 --> 1.083227).  Saving model ...
Validation loss decreased (1.083227 --> 1.078820).  Saving model ...
Validation loss decreased (1.078820 --> 1.072335).  Saving model ...
Validation loss decreased (1.072335 --> 1.067136).  Saving model ...
Validation loss decreased (1.067136 --> 1.062438).  Saving model ...
Validation loss decreased (1.062438 --> 1.056444).  Saving model ...
Validation loss decreased (1.056444 --> 1.051558).  Saving model ...
Validation loss decreased (1.051558 --> 1.046670).  Saving model ...
Validation loss decreased (1.046670 --> 1.043740).  Saving model ...
Validation loss decreased (1.043740 --> 1.039237).  Saving model ...
Validation loss decreased (1.039237 --> 1.034331).  Saving model ...
Validation loss decreased (1.034331 --> 1.029487).  Saving model ...
Validation loss decreased (1.029487 --> 1.025140).  Saving model ...
Validation loss decreased (1.025140 --> 1.022962).  Saving model ...
Validation loss decreased (1.022962 --> 1.018709).  Saving model ...
Validation loss decreased (1.018709 --> 1.014313).  Saving model ...
Validation loss decreased (1.014313 --> 1.010001).  Saving model ...
Validation loss decreased (1.010001 --> 1.005565).  Saving model ...
Validation loss decreased (1.005565 --> 1.002488).  Saving model ...
Validation loss decreased (1.002488 --> 0.998171).  Saving model ...
Validation loss decreased (0.998171 --> 0.997010).  Saving model ...
Validation loss decreased (0.997010 --> 0.994873).  Saving model ...
Validation loss decreased (0.994873 --> 0.991810).  Saving model ...
Validation loss decreased (0.991810 --> 0.987167).  Saving model ...
Validation loss decreased (0.987167 --> 0.983514).  Saving model ...
Validation loss decreased (0.983514 --> 0.978546).  Saving model ...
Validation loss decreased (0.978546 --> 0.976761).  Saving model ...
Validation loss decreased (0.976761 --> 0.974850).  Saving model ...
Validation loss decreased (0.974850 --> 0.971339).  Saving model ...
Validation loss decreased (0.971339 --> 0.969415).  Saving model ...
Validation loss decreased (0.969415 --> 0.967187).  Saving model ...
Validation loss decreased (0.967187 --> 0.965036).  Saving model ...
Validation loss decreased (0.965036 --> 0.961552).  Saving model ...
Validation loss decreased (0.961552 --> 0.959052).  Saving model ...
Validation loss decreased (0.959052 --> 0.957693).  Saving model ...
Validation loss decreased (0.957693 --> 0.955094).  Saving model ...
Validation loss decreased (0.955094 --> 0.952512).  Saving model ...
Validation loss decreased (0.952512 --> 0.949790).  Saving model ...
Validation loss decreased (0.949790 --> 0.948630).  Saving model ...
Validation loss decreased (0.948630 --> 0.945904).  Saving model ...
Validation loss decreased (0.945904 --> 0.945395).  Saving model ...
Validation loss decreased (0.945395 --> 0.942910).  Saving model ...
Validation loss decreased (0.942910 --> 0.939662).  Saving model ...
Validation loss decreased (0.939662 --> 0.937069).  Saving model ...
EarlyStopping counter: 1 out of 10.0
Validation loss decreased (0.937069 --> 0.935752).  Saving model ...
Validation loss decreased (0.935752 --> 0.933524).  Saving model ...
Validation loss decreased (0.933524 --> 0.932737).  Saving model ...
Validation loss decreased (0.932737 --> 0.930196).  Saving model ...
Validation loss decreased (0.930196 --> 0.929103).  Saving model ...
Validation loss decreased (0.929103 --> 0.928417).  Saving model ...
Validation loss decreased (0.928417 --> 0.927795).  Saving model ...
EarlyStopping counter: 1 out of 10.0
EarlyStopping counter: 2 out of 10.0
EarlyStopping counter: 3 out of 10.0
EarlyStopping counter: 4 out of 10.0
Validation loss decreased (0.927795 --> 0.926875).  Saving model ...
Validation loss decreased (0.926875 --> 0.926530).  Saving model ...
Validation loss decreased (0.926530 --> 0.923183).  Saving model ...
Validation loss decreased (0.923183 --> 0.921167).  Saving model ...
EarlyStopping counter: 1 out of 10.0
Validation loss decreased (0.921167 --> 0.920229).  Saving model ...
EarlyStopping counter: 1 out of 10.0
EarlyStopping counter: 2 out of 10.0
Validation loss decreased (0.920229 --> 0.920008).  Saving model ...
Validation loss decreased (0.920008 --> 0.918585).  Saving model ...
Validation loss decreased (0.918585 --> 0.917049).  Saving model ...
EarlyStopping counter: 1 out of 10.0
EarlyStopping counter: 2 out of 10.0
EarlyStopping counter: 3 out of 10.0
EarlyStopping counter: 4 out of 10.0
Validation loss decreased (0.917049 --> 0.916525).  Saving model ...
EarlyStopping counter: 1 out of 10.0
EarlyStopping counter: 2 out of 10.0
EarlyStopping counter: 3 out of 10.0
EarlyStopping counter: 4 out of 10.0
EarlyStopping counter: 5 out of 10.0
EarlyStopping counter: 6 out of 10.0
EarlyStopping counter: 7 out of 10.0
EarlyStopping counter: 8 out of 10.0
EarlyStopping counter: 9 out of 10.0
EarlyStopping counter: 10 out of 10.0
/localscratch/yinan.29019362.0/env/lib/python3.7/site-packages/torch/nn/functional.py:1794: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.
  warnings.warn("nn.functional.tanh is deprecated. Use torch.tanh instead.")
wandb: Waiting for W&B process to finish, PID 30776... (success).
wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: \ 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: | 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: / 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: \ 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: | 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: / 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: \ 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: | 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: / 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb:                                                                                
wandb: Run history:
wandb:     e_F1 ▁▃▄▄▅▅▆▆▆▇▇▇▇▇▇▇▇▇██████████████████████
wandb:   e_loss █▇▇▇▇▆▆▆▅▅▄▄▄▃▃▃▃▃▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:     t_F1 ▁▂▂▃▃▃▄▄▅▅▅▅▅▆▆▆▆▆▆▆▇▇▆▆▇▇▇▇▇▇▇▇█▇▇█████
wandb:   t_loss ██▇▇▇▇▇▆▆▆▅▅▅▅▅▄▄▄▄▄▃▃▃▃▃▃▃▂▂▂▂▂▂▂▂▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:     e_F1 61.75689
wandb:   e_loss 0.91721
wandb:     t_F1 72.68807
wandb:   t_loss 0.75985
wandb: 
wandb: Synced 4 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Synced misunderstood-planet-2: https://wandb.ai/yinanazhou/xl_512_bs_8_lr_1e06_es_10_lc_False_nr_False_sr_True_stem_False_lemma_True_repeat_4_fold_2/runs/26qir3jk
wandb: Find logs at: ./wandb/run-20220319_060928-26qir3jk/logs/debug.log
wandb: 

wandb: wandb version 0.12.11 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
2022-03-19 07:30:57.755849: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1
wandb: Tracking run with wandb version 0.12.5
wandb: Syncing run deft-darkness-2
wandb: ⭐️ View project at https://wandb.ai/yinanazhou/xl_512_bs_8_lr_1e06_es_10_lc_False_nr_False_sr_True_stem_False_lemma_True_repeat_5_fold_1
wandb: 🚀 View run at https://wandb.ai/yinanazhou/xl_512_bs_8_lr_1e06_es_10_lc_False_nr_False_sr_True_stem_False_lemma_True_repeat_5_fold_1/runs/i6w7trpr
wandb: Run data is saved locally in /project/6002780/yinan/Thesis_MER_Lyrics/lyric-emotion/wandb/run-20220319_073054-i6w7trpr
wandb: Run `wandb offline` to turn off syncing.

Validation loss decreased (inf --> 1.413807).  Saving model ...
Validation loss decreased (1.413807 --> 1.404103).  Saving model ...
Validation loss decreased (1.404103 --> 1.396498).  Saving model ...
Validation loss decreased (1.396498 --> 1.390087).  Saving model ...
Validation loss decreased (1.390087 --> 1.384714).  Saving model ...
Validation loss decreased (1.384714 --> 1.379891).  Saving model ...
Validation loss decreased (1.379891 --> 1.375368).  Saving model ...
Validation loss decreased (1.375368 --> 1.370957).  Saving model ...
Validation loss decreased (1.370957 --> 1.366782).  Saving model ...
Validation loss decreased (1.366782 --> 1.362933).  Saving model ...
Validation loss decreased (1.362933 --> 1.358897).  Saving model ...
Validation loss decreased (1.358897 --> 1.354712).  Saving model ...
Validation loss decreased (1.354712 --> 1.350722).  Saving model ...
Validation loss decreased (1.350722 --> 1.346254).  Saving model ...
Validation loss decreased (1.346254 --> 1.342022).  Saving model ...
Validation loss decreased (1.342022 --> 1.337898).  Saving model ...
Validation loss decreased (1.337898 --> 1.333167).  Saving model ...
Validation loss decreased (1.333167 --> 1.328921).  Saving model ...
Validation loss decreased (1.328921 --> 1.323674).  Saving model ...
Validation loss decreased (1.323674 --> 1.317793).  Saving model ...
Validation loss decreased (1.317793 --> 1.312341).  Saving model ...
Validation loss decreased (1.312341 --> 1.307036).  Saving model ...
Validation loss decreased (1.307036 --> 1.301078).  Saving model ...
Validation loss decreased (1.301078 --> 1.295041).  Saving model ...
Validation loss decreased (1.295041 --> 1.288644).  Saving model ...
Validation loss decreased (1.288644 --> 1.281666).  Saving model ...
Validation loss decreased (1.281666 --> 1.274399).  Saving model ...
Validation loss decreased (1.274399 --> 1.266900).  Saving model ...
Validation loss decreased (1.266900 --> 1.259860).  Saving model ...
Validation loss decreased (1.259860 --> 1.251910).  Saving model ...
Validation loss decreased (1.251910 --> 1.243426).  Saving model ...
Validation loss decreased (1.243426 --> 1.235608).  Saving model ...
Validation loss decreased (1.235608 --> 1.227157).  Saving model ...
Validation loss decreased (1.227157 --> 1.218597).  Saving model ...
Validation loss decreased (1.218597 --> 1.210497).  Saving model ...
Validation loss decreased (1.210497 --> 1.202423).  Saving model ...
Validation loss decreased (1.202423 --> 1.194676).  Saving model ...
Validation loss decreased (1.194676 --> 1.187411).  Saving model ...
Validation loss decreased (1.187411 --> 1.180540).  Saving model ...
Validation loss decreased (1.180540 --> 1.174452).  Saving model ...
Validation loss decreased (1.174452 --> 1.169324).  Saving model ...
Validation loss decreased (1.169324 --> 1.162043).  Saving model ...
Validation loss decreased (1.162043 --> 1.157108).  Saving model ...
Validation loss decreased (1.157108 --> 1.151763).  Saving model ...
Validation loss decreased (1.151763 --> 1.145424).  Saving model ...
Validation loss decreased (1.145424 --> 1.139713).  Saving model ...
Validation loss decreased (1.139713 --> 1.134589).  Saving model ...
Validation loss decreased (1.134589 --> 1.128424).  Saving model ...
Validation loss decreased (1.128424 --> 1.121777).  Saving model ...
Validation loss decreased (1.121777 --> 1.114895).  Saving model ...
Validation loss decreased (1.114895 --> 1.110683).  Saving model ...
Validation loss decreased (1.110683 --> 1.106058).  Saving model ...
Validation loss decreased (1.106058 --> 1.098875).  Saving model ...
Validation loss decreased (1.098875 --> 1.094446).  Saving model ...
Validation loss decreased (1.094446 --> 1.089796).  Saving model ...
Validation loss decreased (1.089796 --> 1.086592).  Saving model ...
Validation loss decreased (1.086592 --> 1.081903).  Saving model ...
Validation loss decreased (1.081903 --> 1.076644).  Saving model ...
Validation loss decreased (1.076644 --> 1.071074).  Saving model ...
Validation loss decreased (1.071074 --> 1.067254).  Saving model ...
Validation loss decreased (1.067254 --> 1.062227).  Saving model ...
Validation loss decreased (1.062227 --> 1.058990).  Saving model ...
Validation loss decreased (1.058990 --> 1.054021).  Saving model ...
Validation loss decreased (1.054021 --> 1.048899).  Saving model ...
Validation loss decreased (1.048899 --> 1.043001).  Saving model ...
Validation loss decreased (1.043001 --> 1.038909).  Saving model ...
Validation loss decreased (1.038909 --> 1.034336).  Saving model ...
Validation loss decreased (1.034336 --> 1.030023).  Saving model ...
Validation loss decreased (1.030023 --> 1.025451).  Saving model ...
Validation loss decreased (1.025451 --> 1.021022).  Saving model ...
Validation loss decreased (1.021022 --> 1.016792).  Saving model ...
Validation loss decreased (1.016792 --> 1.013441).  Saving model ...
Validation loss decreased (1.013441 --> 1.008269).  Saving model ...
Validation loss decreased (1.008269 --> 1.005641).  Saving model ...
Validation loss decreased (1.005641 --> 1.003151).  Saving model ...
Validation loss decreased (1.003151 --> 0.999356).  Saving model ...
Validation loss decreased (0.999356 --> 0.996098).  Saving model ...
Validation loss decreased (0.996098 --> 0.991496).  Saving model ...
Validation loss decreased (0.991496 --> 0.988438).  Saving model ...
Validation loss decreased (0.988438 --> 0.984466).  Saving model ...
Validation loss decreased (0.984466 --> 0.981465).  Saving model ...
Validation loss decreased (0.981465 --> 0.978727).  Saving model ...
Validation loss decreased (0.978727 --> 0.976522).  Saving model ...
Validation loss decreased (0.976522 --> 0.972959).  Saving model ...
Validation loss decreased (0.972959 --> 0.970301).  Saving model ...
Validation loss decreased (0.970301 --> 0.967446).  Saving model ...
Validation loss decreased (0.967446 --> 0.964770).  Saving model ...
Validation loss decreased (0.964770 --> 0.961433).  Saving model ...
Validation loss decreased (0.961433 --> 0.958531).  Saving model ...
Validation loss decreased (0.958531 --> 0.956716).  Saving model ...
Validation loss decreased (0.956716 --> 0.953433).  Saving model ...
Validation loss decreased (0.953433 --> 0.950715).  Saving model ...
Validation loss decreased (0.950715 --> 0.948414).  Saving model ...
Validation loss decreased (0.948414 --> 0.946589).  Saving model ...
Validation loss decreased (0.946589 --> 0.944796).  Saving model ...
Validation loss decreased (0.944796 --> 0.942390).  Saving model ...
Validation loss decreased (0.942390 --> 0.940614).  Saving model ...
Validation loss decreased (0.940614 --> 0.939716).  Saving model ...
Validation loss decreased (0.939716 --> 0.938064).  Saving model ...
Validation loss decreased (0.938064 --> 0.935606).  Saving model ...
Validation loss decreased (0.935606 --> 0.933959).  Saving model ...
Validation loss decreased (0.933959 --> 0.932318).  Saving model ...
Validation loss decreased (0.932318 --> 0.930704).  Saving model ...
Validation loss decreased (0.930704 --> 0.929138).  Saving model ...
Validation loss decreased (0.929138 --> 0.927284).  Saving model ...
Validation loss decreased (0.927284 --> 0.925814).  Saving model ...
Validation loss decreased (0.925814 --> 0.924580).  Saving model ...
Validation loss decreased (0.924580 --> 0.923145).  Saving model ...
Validation loss decreased (0.923145 --> 0.921604).  Saving model ...
Validation loss decreased (0.921604 --> 0.920857).  Saving model ...
Validation loss decreased (0.920857 --> 0.919538).  Saving model ...
Validation loss decreased (0.919538 --> 0.918742).  Saving model ...
Validation loss decreased (0.918742 --> 0.918258).  Saving model ...
Validation loss decreased (0.918258 --> 0.917124).  Saving model ...
Validation loss decreased (0.917124 --> 0.916170).  Saving model ...
Validation loss decreased (0.916170 --> 0.915399).  Saving model ...
Validation loss decreased (0.915399 --> 0.913921).  Saving model ...
Validation loss decreased (0.913921 --> 0.913568).  Saving model ...
Validation loss decreased (0.913568 --> 0.913367).  Saving model ...
Validation loss decreased (0.913367 --> 0.912340).  Saving model ...
Validation loss decreased (0.912340 --> 0.911193).  Saving model ...
Validation loss decreased (0.911193 --> 0.910278).  Saving model ...
Validation loss decreased (0.910278 --> 0.909228).  Saving model ...
EarlyStopping counter: 1 out of 10.0
Validation loss decreased (0.909228 --> 0.908479).  Saving model ...
Validation loss decreased (0.908479 --> 0.907941).  Saving model ...
Validation loss decreased (0.907941 --> 0.907023).  Saving model ...
Validation loss decreased (0.907023 --> 0.906637).  Saving model ...
Validation loss decreased (0.906637 --> 0.906611).  Saving model ...
Validation loss decreased (0.906611 --> 0.906131).  Saving model ...
Validation loss decreased (0.906131 --> 0.905370).  Saving model ...
Validation loss decreased (0.905370 --> 0.905325).  Saving model ...
Validation loss decreased (0.905325 --> 0.904817).  Saving model ...
Validation loss decreased (0.904817 --> 0.904169).  Saving model ...
Validation loss decreased (0.904169 --> 0.903613).  Saving model ...
Validation loss decreased (0.903613 --> 0.903489).  Saving model ...
EarlyStopping counter: 1 out of 10.0
Validation loss decreased (0.903489 --> 0.903055).  Saving model ...
EarlyStopping counter: 1 out of 10.0
EarlyStopping counter: 2 out of 10.0
EarlyStopping counter: 3 out of 10.0
EarlyStopping counter: 4 out of 10.0
EarlyStopping counter: 5 out of 10.0
EarlyStopping counter: 6 out of 10.0
EarlyStopping counter: 7 out of 10.0
EarlyStopping counter: 8 out of 10.0
EarlyStopping counter: 9 out of 10.0
EarlyStopping counter: 10 out of 10.0
/localscratch/yinan.29019362.0/env/lib/python3.7/site-packages/torch/nn/functional.py:1794: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.
  warnings.warn("nn.functional.tanh is deprecated. Use torch.tanh instead.")
wandb: Waiting for W&B process to finish, PID 35150... (success).
wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: \ 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: | 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: / 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: \ 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: | 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: / 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: \ 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: | 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: / 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb:                                                                                
wandb: Run history:
wandb:     e_F1 ▁▂▂▃▄▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇▇▇▇▇▇▇▇████████████
wandb:   e_loss ███▇▇▇▆▆▆▅▅▅▄▄▄▃▃▃▃▃▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:     t_F1 ▁▁▂▂▃▃▃▄▄▄▅▅▅▅▆▆▆▆▆▆▆▆▇▇▇▇▇▇▇▇█▇▇█▇█████
wandb:   t_loss ████▇▇▇▇▇▆▆▆▅▅▅▅▅▄▄▄▄▄▃▃▃▃▃▃▂▂▂▂▂▂▂▂▁▁▁▁
wandb: 
wandb: Run summary:
wandb:     e_F1 62.23709
wandb:   e_loss 0.90568
wandb:     t_F1 75.09855
wandb:   t_loss 0.68357
wandb: 
wandb: Synced 4 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Synced deft-darkness-2: https://wandb.ai/yinanazhou/xl_512_bs_8_lr_1e06_es_10_lc_False_nr_False_sr_True_stem_False_lemma_True_repeat_5_fold_1/runs/i6w7trpr
wandb: Find logs at: ./wandb/run-20220319_073054-i6w7trpr/logs/debug.log
wandb: 

wandb: wandb version 0.12.11 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
2022-03-19 09:08:11.201522: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1
wandb: Tracking run with wandb version 0.12.5
wandb: Syncing run devoted-field-2
wandb: ⭐️ View project at https://wandb.ai/yinanazhou/xl_512_bs_8_lr_1e06_es_10_lc_False_nr_False_sr_True_stem_False_lemma_True_repeat_5_fold_2
wandb: 🚀 View run at https://wandb.ai/yinanazhou/xl_512_bs_8_lr_1e06_es_10_lc_False_nr_False_sr_True_stem_False_lemma_True_repeat_5_fold_2/runs/3vprdbsd
wandb: Run data is saved locally in /project/6002780/yinan/Thesis_MER_Lyrics/lyric-emotion/wandb/run-20220319_090808-3vprdbsd
wandb: Run `wandb offline` to turn off syncing.

Validation loss decreased (inf --> 1.379402).  Saving model ...
Validation loss decreased (1.379402 --> 1.373603).  Saving model ...
Validation loss decreased (1.373603 --> 1.367685).  Saving model ...
Validation loss decreased (1.367685 --> 1.362732).  Saving model ...
Validation loss decreased (1.362732 --> 1.357905).  Saving model ...
Validation loss decreased (1.357905 --> 1.353467).  Saving model ...
Validation loss decreased (1.353467 --> 1.349277).  Saving model ...
Validation loss decreased (1.349277 --> 1.344432).  Saving model ...
Validation loss decreased (1.344432 --> 1.340114).  Saving model ...
Validation loss decreased (1.340114 --> 1.335987).  Saving model ...
Validation loss decreased (1.335987 --> 1.331734).  Saving model ...
Validation loss decreased (1.331734 --> 1.326415).  Saving model ...
Validation loss decreased (1.326415 --> 1.321434).  Saving model ...
Validation loss decreased (1.321434 --> 1.316688).  Saving model ...
Validation loss decreased (1.316688 --> 1.311570).  Saving model ...
Validation loss decreased (1.311570 --> 1.306053).  Saving model ...
Validation loss decreased (1.306053 --> 1.299860).  Saving model ...
Validation loss decreased (1.299860 --> 1.294176).  Saving model ...
Validation loss decreased (1.294176 --> 1.288754).  Saving model ...
Validation loss decreased (1.288754 --> 1.282703).  Saving model ...
Validation loss decreased (1.282703 --> 1.276706).  Saving model ...
Validation loss decreased (1.276706 --> 1.269504).  Saving model ...
Validation loss decreased (1.269504 --> 1.261359).  Saving model ...
Validation loss decreased (1.261359 --> 1.254481).  Saving model ...
Validation loss decreased (1.254481 --> 1.246432).  Saving model ...
Validation loss decreased (1.246432 --> 1.238473).  Saving model ...
Validation loss decreased (1.238473 --> 1.231270).  Saving model ...
Validation loss decreased (1.231270 --> 1.224797).  Saving model ...
Validation loss decreased (1.224797 --> 1.217114).  Saving model ...
Validation loss decreased (1.217114 --> 1.210435).  Saving model ...
Validation loss decreased (1.210435 --> 1.201490).  Saving model ...
Validation loss decreased (1.201490 --> 1.194027).  Saving model ...
Validation loss decreased (1.194027 --> 1.186813).  Saving model ...
Validation loss decreased (1.186813 --> 1.179937).  Saving model ...
Validation loss decreased (1.179937 --> 1.172782).  Saving model ...
Validation loss decreased (1.172782 --> 1.165263).  Saving model ...
Validation loss decreased (1.165263 --> 1.158833).  Saving model ...
Validation loss decreased (1.158833 --> 1.153079).  Saving model ...
Validation loss decreased (1.153079 --> 1.146149).  Saving model ...
Validation loss decreased (1.146149 --> 1.140152).  Saving model ...
Validation loss decreased (1.140152 --> 1.134597).  Saving model ...
Validation loss decreased (1.134597 --> 1.127741).  Saving model ...
Validation loss decreased (1.127741 --> 1.121833).  Saving model ...
Validation loss decreased (1.121833 --> 1.115132).  Saving model ...
Validation loss decreased (1.115132 --> 1.109701).  Saving model ...
Validation loss decreased (1.109701 --> 1.102900).  Saving model ...
Validation loss decreased (1.102900 --> 1.096725).  Saving model ...
Validation loss decreased (1.096725 --> 1.092483).  Saving model ...
Validation loss decreased (1.092483 --> 1.087821).  Saving model ...
Validation loss decreased (1.087821 --> 1.082274).  Saving model ...
Validation loss decreased (1.082274 --> 1.077968).  Saving model ...
Validation loss decreased (1.077968 --> 1.073056).  Saving model ...
Validation loss decreased (1.073056 --> 1.069376).  Saving model ...
Validation loss decreased (1.069376 --> 1.064105).  Saving model ...
Validation loss decreased (1.064105 --> 1.059337).  Saving model ...
Validation loss decreased (1.059337 --> 1.055378).  Saving model ...
Validation loss decreased (1.055378 --> 1.050188).  Saving model ...
Validation loss decreased (1.050188 --> 1.045113).  Saving model ...
Validation loss decreased (1.045113 --> 1.041918).  Saving model ...
Validation loss decreased (1.041918 --> 1.036679).  Saving model ...
Validation loss decreased (1.036679 --> 1.034700).  Saving model ...
Validation loss decreased (1.034700 --> 1.031915).  Saving model ...
Validation loss decreased (1.031915 --> 1.028657).  Saving model ...
Validation loss decreased (1.028657 --> 1.024887).  Saving model ...
Validation loss decreased (1.024887 --> 1.020683).  Saving model ...
Validation loss decreased (1.020683 --> 1.017257).  Saving model ...
Validation loss decreased (1.017257 --> 1.014285).  Saving model ...
Validation loss decreased (1.014285 --> 1.012074).  Saving model ...
Validation loss decreased (1.012074 --> 1.009614).  Saving model ...
Validation loss decreased (1.009614 --> 1.005233).  Saving model ...
Validation loss decreased (1.005233 --> 1.002838).  Saving model ...
Validation loss decreased (1.002838 --> 1.001059).  Saving model ...
Validation loss decreased (1.001059 --> 0.996758).  Saving model ...
Validation loss decreased (0.996758 --> 0.991595).  Saving model ...
Validation loss decreased (0.991595 --> 0.988798).  Saving model ...
Validation loss decreased (0.988798 --> 0.986504).  Saving model ...
Validation loss decreased (0.986504 --> 0.985190).  Saving model ...
Validation loss decreased (0.985190 --> 0.983261).  Saving model ...
Validation loss decreased (0.983261 --> 0.980051).  Saving model ...
Validation loss decreased (0.980051 --> 0.977609).  Saving model ...
Validation loss decreased (0.977609 --> 0.974665).  Saving model ...
Validation loss decreased (0.974665 --> 0.971888).  Saving model ...
Validation loss decreased (0.971888 --> 0.968959).  Saving model ...
Validation loss decreased (0.968959 --> 0.968410).  Saving model ...
Validation loss decreased (0.968410 --> 0.966738).  Saving model ...
Validation loss decreased (0.966738 --> 0.965279).  Saving model ...
Validation loss decreased (0.965279 --> 0.962923).  Saving model ...
Validation loss decreased (0.962923 --> 0.960065).  Saving model ...
Validation loss decreased (0.960065 --> 0.958186).  Saving model ...
Validation loss decreased (0.958186 --> 0.956366).  Saving model ...
Validation loss decreased (0.956366 --> 0.953429).  Saving model ...
Validation loss decreased (0.953429 --> 0.952017).  Saving model ...
Validation loss decreased (0.952017 --> 0.948311).  Saving model ...
Validation loss decreased (0.948311 --> 0.947474).  Saving model ...
Validation loss decreased (0.947474 --> 0.945181).  Saving model ...
Validation loss decreased (0.945181 --> 0.944511).  Saving model ...
Validation loss decreased (0.944511 --> 0.943249).  Saving model ...
Validation loss decreased (0.943249 --> 0.943234).  Saving model ...
Validation loss decreased (0.943234 --> 0.940032).  Saving model ...
Validation loss decreased (0.940032 --> 0.938113).  Saving model ...
EarlyStopping counter: 1 out of 10.0
Validation loss decreased (0.938113 --> 0.934563).  Saving model ...
Validation loss decreased (0.934563 --> 0.933923).  Saving model ...
EarlyStopping counter: 1 out of 10.0
Validation loss decreased (0.933923 --> 0.931450).  Saving model ...
Validation loss decreased (0.931450 --> 0.930746).  Saving model ...
Validation loss decreased (0.930746 --> 0.929646).  Saving model ...
EarlyStopping counter: 1 out of 10.0
Validation loss decreased (0.929646 --> 0.928788).  Saving model ...
EarlyStopping counter: 1 out of 10.0
Validation loss decreased (0.928788 --> 0.925138).  Saving model ...
Validation loss decreased (0.925138 --> 0.923513).  Saving model ...
Validation loss decreased (0.923513 --> 0.922566).  Saving model ...
EarlyStopping counter: 1 out of 10.0
EarlyStopping counter: 2 out of 10.0
EarlyStopping counter: 3 out of 10.0
EarlyStopping counter: 4 out of 10.0
EarlyStopping counter: 5 out of 10.0
Validation loss decreased (0.922566 --> 0.920389).  Saving model ...
EarlyStopping counter: 1 out of 10.0
EarlyStopping counter: 2 out of 10.0
Validation loss decreased (0.920389 --> 0.917887).  Saving model ...
Validation loss decreased (0.917887 --> 0.916713).  Saving model ...
Validation loss decreased (0.916713 --> 0.914926).  Saving model ...
EarlyStopping counter: 1 out of 10.0
Validation loss decreased (0.914926 --> 0.914308).  Saving model ...
EarlyStopping counter: 1 out of 10.0
EarlyStopping counter: 2 out of 10.0
Validation loss decreased (0.914308 --> 0.912509).  Saving model ...
Validation loss decreased (0.912509 --> 0.911752).  Saving model ...
Validation loss decreased (0.911752 --> 0.911050).  Saving model ...
Validation loss decreased (0.911050 --> 0.910882).  Saving model ...
EarlyStopping counter: 1 out of 10.0
EarlyStopping counter: 2 out of 10.0
EarlyStopping counter: 3 out of 10.0
Validation loss decreased (0.910882 --> 0.910220).  Saving model ...
Validation loss decreased (0.910220 --> 0.910188).  Saving model ...
EarlyStopping counter: 1 out of 10.0
EarlyStopping counter: 2 out of 10.0
Validation loss decreased (0.910188 --> 0.909541).  Saving model ...
EarlyStopping counter: 1 out of 10.0
Validation loss decreased (0.909541 --> 0.908847).  Saving model ...
EarlyStopping counter: 1 out of 10.0
EarlyStopping counter: 2 out of 10.0
EarlyStopping counter: 3 out of 10.0
EarlyStopping counter: 4 out of 10.0
EarlyStopping counter: 5 out of 10.0
EarlyStopping counter: 6 out of 10.0
Validation loss decreased (0.908847 --> 0.908512).  Saving model ...
Validation loss decreased (0.908512 --> 0.908247).  Saving model ...
Validation loss decreased (0.908247 --> 0.908012).  Saving model ...
EarlyStopping counter: 1 out of 10.0
Validation loss decreased (0.908012 --> 0.907599).  Saving model ...
Validation loss decreased (0.907599 --> 0.907465).  Saving model ...
EarlyStopping counter: 1 out of 10.0
EarlyStopping counter: 2 out of 10.0
EarlyStopping counter: 3 out of 10.0
EarlyStopping counter: 4 out of 10.0
EarlyStopping counter: 5 out of 10.0
Validation loss decreased (0.907465 --> 0.907131).  Saving model ...
Validation loss decreased (0.907131 --> 0.905859).  Saving model ...
EarlyStopping counter: 1 out of 10.0
EarlyStopping counter: 2 out of 10.0
EarlyStopping counter: 3 out of 10.0
EarlyStopping counter: 4 out of 10.0
EarlyStopping counter: 5 out of 10.0
EarlyStopping counter: 6 out of 10.0
EarlyStopping counter: 7 out of 10.0
EarlyStopping counter: 8 out of 10.0
EarlyStopping counter: 9 out of 10.0
EarlyStopping counter: 10 out of 10.0
/localscratch/yinan.29019362.0/env/lib/python3.7/site-packages/torch/nn/functional.py:1794: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.
  warnings.warn("nn.functional.tanh is deprecated. Use torch.tanh instead.")
wandb: Waiting for W&B process to finish, PID 40399... (success).
wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: \ 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: | 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: / 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: \ 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: | 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: / 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: \ 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: | 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: / 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb:                                                                                
wandb: Run history:
wandb:     e_F1 ▁▂▃▄▄▄▄▅▅▆▆▆▆▆▇▇▇▇▇▇▇▇▇▇████████████████
wandb:   e_loss ██▇▇▇▆▆▅▅▄▄▄▃▃▃▃▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:     t_F1 ▁▂▂▃▃▃▄▄▅▅▅▅▅▆▅▆▆▆▆▆▆▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇██▇█
wandb:   t_loss ████▇▇▇▆▆▆▅▅▅▅▅▄▄▄▄▃▃▃▃▃▃▃▂▂▂▂▂▂▂▂▂▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:     e_F1 62.71209
wandb:   e_loss 0.91364
wandb:     t_F1 77.12015
wandb:   t_loss 0.64682
wandb: 
wandb: Synced 4 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Synced devoted-field-2: https://wandb.ai/yinanazhou/xl_512_bs_8_lr_1e06_es_10_lc_False_nr_False_sr_True_stem_False_lemma_True_repeat_5_fold_2/runs/3vprdbsd
wandb: Find logs at: ./wandb/run-20220319_090808-3vprdbsd/logs/debug.log
wandb: 

