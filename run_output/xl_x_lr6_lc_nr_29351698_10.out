Unloading StdEnv/2020

Due to MODULEPATH changes, the following have been reloaded:
  1) mii/1.1.1


The following have been reloaded with a version change:
  1) python/3.8.2 => python/3.7.4

Using base prefix '/cvmfs/soft.computecanada.ca/easybuild/software/2017/Core/python/3.7.4'
New python executable in /localscratch/yinan.29351698.0/env/bin/python
Installing setuptools, pip, wheel...
done.
Ignoring pip: markers 'python_version < "3"' don't match your environment
Looking in links: /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/nix/avx2, /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/nix/generic, /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic
Collecting pip
Installing collected packages: pip
  Found existing installation: pip 19.1.1
    Uninstalling pip-19.1.1:
      Successfully uninstalled pip-19.1.1
Successfully installed pip-21.2.3+computecanada
Looking in links: /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/nix/avx2, /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/nix/generic, /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/keras-2.8.0+computecanada-py2.py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/Keras_Preprocessing-1.1.2+computecanada-py3-none-any.whl
Requirement already satisfied: matplotlib in /cvmfs/soft.computecanada.ca/easybuild/software/2017/Core/scipy-stack/2019a/lib/python3.7/site-packages (from -r requirements.txt (line 3)) (3.0.2)
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/nltk-3.6.5+computecanada-py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/scikit_learn-0.22.1+computecanada-cp37-cp37m-linux_x86_64.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/tensorboard-2.3.0+computecanada-py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/tensorboard_plugin_wit-1.7.0+computecanada-py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/tensorflow_gpu-2.3.0+computecanada-cp37-cp37m-linux_x86_64.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/tensorflow_estimator-2.3.0+computecanada-py2.py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/tokenizers-0.5.2+computecanada-cp37-cp37m-linux_x86_64.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/nix/avx2/torch-1.4.0+computecanada-cp37-cp37m-linux_x86_64.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/torchtext-0.6.0+computecanada-py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/torchvision-0.8.2+computecanada-cp37-cp37m-linux_x86_64.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/transformers-2.5.1+computecanada-py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/urllib3-1.26.7+computecanada-py2.py3-none-any.whl
ERROR: Could not find a version that satisfies the requirement regex>=2021.8.3 (from nltk) (from versions: 2018.1.10+computecanada, 2019.11.1+computecanada, 2020.11.13+computecanada)
ERROR: No matching distribution found for regex>=2021.8.3
Looking in links: /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/nix/avx2, /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/nix/generic, /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic
ERROR: Could not find a version that satisfies the requirement numpy==1.20.0+computacanada (from versions: 1.15.0+computecanada, 1.15.2+computecanada, 1.15.4+computecanada, 1.16.0+computecanada, 1.16.2+computecanada, 1.16.3+computecanada, 1.17.4+computecanada, 1.18.1+computecanada, 1.18.4+computecanada, 1.19.1+computecanada, 1.19.2+computecanada, 1.20.2+computecanada)
ERROR: No matching distribution found for numpy==1.20.0+computacanada
Looking in links: /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/nix/avx2, /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/nix/generic, /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/wandb-0.12.5+computecanada-py2.py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/click-8.0.4+computecanada-py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/shortuuid-1.0.1+computecanada-py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/subprocess32-3.5.4+computecanada-py3-none-any.whl
Requirement already satisfied: python-dateutil>=2.6.1 in /cvmfs/soft.computecanada.ca/easybuild/software/2017/Core/scipy-stack/2019a/lib/python3.7/site-packages (from wandb) (2.7.5)
Requirement already satisfied: requests<3,>=2.0.0 in /cvmfs/soft.computecanada.ca/easybuild/software/2017/Core/scipy-stack/2019a/lib/python3.7/site-packages (from wandb) (2.21.0)
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/protobuf-3.19.4+computecanada-py2.py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/PyYAML-5.3.1+computecanada-cp37-cp37m-linux_x86_64.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/sentry_sdk-1.5.0+computecanada-py2.py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/pathtools-0.1.2+computecanada-py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/yaspin-2.1.0+computecanada-py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/six-1.16.0+computecanada-py2.py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/docker_pycreds-0.4.0+computecanada-py2.py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/promise-2.3+computecanada-py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/configparser-5.0.2+computecanada-py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/GitPython-3.1.24+computecanada-py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/psutil-5.7.3+computecanada-cp37-cp37m-linux_x86_64.whl
Requirement already satisfied: importlib-metadata in /cvmfs/soft.computecanada.ca/easybuild/software/2017/Core/scipy-stack/2019a/lib/python3.7/site-packages (from Click!=8.0.0,>=7.0->wandb) (0.8)
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/typing_extensions-4.0.1+computecanada-py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/gitdb-4.0.9+computecanada-py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/smmap-5.0.0+computecanada-py3-none-any.whl
Requirement already satisfied: urllib3<1.25,>=1.21.1 in /cvmfs/soft.computecanada.ca/easybuild/software/2017/Core/scipy-stack/2019a/lib/python3.7/site-packages (from requests<3,>=2.0.0->wandb) (1.24.1)
Requirement already satisfied: certifi>=2017.4.17 in /cvmfs/soft.computecanada.ca/easybuild/software/2017/Core/scipy-stack/2019a/lib/python3.7/site-packages (from requests<3,>=2.0.0->wandb) (2018.11.29)
Requirement already satisfied: idna<2.9,>=2.5 in /cvmfs/soft.computecanada.ca/easybuild/software/2017/Core/scipy-stack/2019a/lib/python3.7/site-packages (from requests<3,>=2.0.0->wandb) (2.8)
Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /cvmfs/soft.computecanada.ca/easybuild/software/2017/Core/scipy-stack/2019a/lib/python3.7/site-packages (from requests<3,>=2.0.0->wandb) (3.0.4)
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/termcolor-1.1.0+computecanada-py3-none-any.whl
Requirement already satisfied: zipp>=0.3.2 in /cvmfs/soft.computecanada.ca/easybuild/software/2017/Core/scipy-stack/2019a/lib/python3.7/site-packages (from importlib-metadata->Click!=8.0.0,>=7.0->wandb) (0.3.3)
Installing collected packages: smmap, typing-extensions, termcolor, six, gitdb, yaspin, subprocess32, shortuuid, sentry-sdk, PyYAML, psutil, protobuf, promise, pathtools, GitPython, docker-pycreds, configparser, Click, wandb
  Attempting uninstall: six
    Found existing installation: six 1.12.0
    Not uninstalling six at /cvmfs/soft.computecanada.ca/easybuild/software/2017/Core/scipy-stack/2019a/lib/python3.7/site-packages, outside environment /localscratch/yinan.29351698.0/env
    Can't uninstall 'six'. No files were found to uninstall.
Successfully installed Click-8.0.4+computecanada GitPython-3.1.24+computecanada PyYAML-5.3.1+computecanada configparser-5.0.2+computecanada docker-pycreds-0.4.0+computecanada gitdb-4.0.9+computecanada pathtools-0.1.2+computecanada promise-2.3+computecanada protobuf-3.19.4+computecanada psutil-5.7.3+computecanada sentry-sdk-1.5.0+computecanada shortuuid-1.0.1+computecanada six-1.16.0+computecanada smmap-5.0.0+computecanada subprocess32-3.5.4+computecanada termcolor-1.1.0+computecanada typing-extensions-4.0.1+computecanada wandb-0.12.5+computecanada yaspin-2.1.0+computecanada
Looking in links: /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/nix/avx2, /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/nix/generic, /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic
ERROR: Could not find a version that satisfies the requirement sagemaker (from versions: none)
ERROR: No matching distribution found for sagemaker
Looking in links: /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/nix/avx2, /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/nix/generic, /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/torch-1.9.1+computecanada-cp37-cp37m-linux_x86_64.whl
Requirement already satisfied: typing-extensions in /localscratch/yinan.29351698.0/env/lib/python3.7/site-packages (from torch) (4.0.1+computecanada)
Installing collected packages: torch
Successfully installed torch-1.9.1+computecanada
Looking in links: /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/nix/avx2, /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/nix/generic, /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/transformers-2.5.1+computecanada-py3-none-any.whl
Requirement already satisfied: requests in /cvmfs/soft.computecanada.ca/easybuild/software/2017/Core/scipy-stack/2019a/lib/python3.7/site-packages (from transformers==2.5.1+computecanada) (2.21.0)
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/boto3-1.21.14+computecanada-py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/tqdm-4.63.0+computecanada-py2.py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/regex-2020.11.13+computecanada-cp37-cp37m-linux_x86_64.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/filelock-3.4.2+computecanada-py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/sentencepiece-0.1.91+computecanada-cp37-cp37m-linux_x86_64.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/sacremoses-0.0.46+computecanada-py3-none-any.whl
Requirement already satisfied: numpy in /cvmfs/soft.computecanada.ca/easybuild/software/2017/Core/scipy-stack/2019a/lib/python3.7/site-packages (from transformers==2.5.1+computecanada) (1.16.0)
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/tokenizers-0.5.2+computecanada-cp37-cp37m-linux_x86_64.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/s3transfer-0.5.1+computecanada-py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/jmespath-0.10.0+computecanada-py2.py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/botocore-1.24.14+computecanada-py3-none-any.whl
Requirement already satisfied: python-dateutil<3.0.0,>=2.1 in /cvmfs/soft.computecanada.ca/easybuild/software/2017/Core/scipy-stack/2019a/lib/python3.7/site-packages (from botocore<1.25.0,>=1.24.14->boto3->transformers==2.5.1+computecanada) (2.7.5)
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/urllib3-1.26.8+computecanada-py2.py3-none-any.whl
Requirement already satisfied: six>=1.5 in /localscratch/yinan.29351698.0/env/lib/python3.7/site-packages (from python-dateutil<3.0.0,>=2.1->botocore<1.25.0,>=1.24.14->boto3->transformers==2.5.1+computecanada) (1.16.0+computecanada)
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/requests-2.27.1+computecanada-py2.py3-none-any.whl
Requirement already satisfied: certifi>=2017.4.17 in /cvmfs/soft.computecanada.ca/easybuild/software/2017/Core/scipy-stack/2019a/lib/python3.7/site-packages (from requests->transformers==2.5.1+computecanada) (2018.11.29)
Requirement already satisfied: idna<4,>=2.5 in /cvmfs/soft.computecanada.ca/easybuild/software/2017/Core/scipy-stack/2019a/lib/python3.7/site-packages (from requests->transformers==2.5.1+computecanada) (2.8)
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/charset_normalizer-2.0.12+computecanada-py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/joblib-1.1.0+computecanada-py2.py3-none-any.whl
Requirement already satisfied: click in /localscratch/yinan.29351698.0/env/lib/python3.7/site-packages (from sacremoses->transformers==2.5.1+computecanada) (8.0.4+computecanada)
Requirement already satisfied: importlib-metadata in /cvmfs/soft.computecanada.ca/easybuild/software/2017/Core/scipy-stack/2019a/lib/python3.7/site-packages (from click->sacremoses->transformers==2.5.1+computecanada) (0.8)
Requirement already satisfied: zipp>=0.3.2 in /cvmfs/soft.computecanada.ca/easybuild/software/2017/Core/scipy-stack/2019a/lib/python3.7/site-packages (from importlib-metadata->click->sacremoses->transformers==2.5.1+computecanada) (0.3.3)
Installing collected packages: urllib3, jmespath, botocore, tqdm, s3transfer, regex, joblib, charset-normalizer, tokenizers, sentencepiece, sacremoses, requests, filelock, boto3, transformers
  Attempting uninstall: urllib3
    Found existing installation: urllib3 1.24.1
    Not uninstalling urllib3 at /cvmfs/soft.computecanada.ca/easybuild/software/2017/Core/scipy-stack/2019a/lib/python3.7/site-packages, outside environment /localscratch/yinan.29351698.0/env
    Can't uninstall 'urllib3'. No files were found to uninstall.
  Attempting uninstall: requests
    Found existing installation: requests 2.21.0
    Not uninstalling requests at /cvmfs/soft.computecanada.ca/easybuild/software/2017/Core/scipy-stack/2019a/lib/python3.7/site-packages, outside environment /localscratch/yinan.29351698.0/env
    Can't uninstall 'requests'. No files were found to uninstall.
Successfully installed boto3-1.21.14+computecanada botocore-1.24.14+computecanada charset-normalizer-2.0.12+computecanada filelock-3.4.2+computecanada jmespath-0.10.0+computecanada joblib-1.1.0+computecanada regex-2020.11.13+computecanada requests-2.27.1+computecanada s3transfer-0.5.1+computecanada sacremoses-0.0.46+computecanada sentencepiece-0.1.91+computecanada tokenizers-0.5.2+computecanada tqdm-4.63.0+computecanada transformers-2.5.1+computecanada urllib3-1.26.8+computecanada
Looking in links: /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/nix/avx2, /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/nix/generic, /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/tensorflow_gpu-2.3.0+computecanada-cp37-cp37m-linux_x86_64.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/Keras_Preprocessing-1.1.2+computecanada-py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/grpcio-1.38.0+computecanada-cp37-cp37m-linux_x86_64.whl
Requirement already satisfied: numpy<1.19.0,>=1.16.0 in /cvmfs/soft.computecanada.ca/easybuild/software/2017/Core/scipy-stack/2019a/lib/python3.7/site-packages (from tensorflow_gpu==2.3.0+computecanada) (1.16.0)
Requirement already satisfied: protobuf>=3.9.2 in /localscratch/yinan.29351698.0/env/lib/python3.7/site-packages (from tensorflow_gpu==2.3.0+computecanada) (3.19.4+computecanada)
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/tensorflow_estimator-2.3.0+computecanada-py2.py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/wrapt-1.11.2+computecanada-cp37-cp37m-linux_x86_64.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/nix/avx2/h5py-2.10.0+computecanada-cp37-cp37m-linux_x86_64.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/google_pasta-0.2.0+computecanada-py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/absl_py-1.0.0+computecanada-py3-none-any.whl
Requirement already satisfied: termcolor>=1.1.0 in /localscratch/yinan.29351698.0/env/lib/python3.7/site-packages (from tensorflow_gpu==2.3.0+computecanada) (1.1.0+computecanada)
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/tensorboard-2.8.0+computecanada-py3-none-any.whl
Requirement already satisfied: six>=1.12.0 in /localscratch/yinan.29351698.0/env/lib/python3.7/site-packages (from tensorflow_gpu==2.3.0+computecanada) (1.16.0+computecanada)
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/gast-0.3.3+computecanada-py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/opt_einsum-3.3.0+computecanada-py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/nix/generic/scipy-1.4.1+computecanada-cp37-cp37m-linux_x86_64.whl
Requirement already satisfied: wheel>=0.26 in /localscratch/yinan.29351698.0/env/lib/python3.7/site-packages (from tensorflow_gpu==2.3.0+computecanada) (0.33.4)
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/astunparse-1.6.3+computecanada-py2.py3-none-any.whl
Requirement already satisfied: requests<3,>=2.21.0 in /localscratch/yinan.29351698.0/env/lib/python3.7/site-packages (from tensorboard<3,>=2.3.0->tensorflow_gpu==2.3.0+computecanada) (2.27.1+computecanada)
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/tensorboard_data_server-0.6.1+computecanada-py3-none-linux_x86_64.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/Werkzeug-2.0.3+computecanada-py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/google_auth-2.3.3+computecanada-py2.py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/Markdown-3.3.6+computecanada-py3-none-any.whl
Requirement already satisfied: setuptools>=41.0.0 in /localscratch/yinan.29351698.0/env/lib/python3.7/site-packages (from tensorboard<3,>=2.3.0->tensorflow_gpu==2.3.0+computecanada) (41.0.1)
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/google_auth_oauthlib-0.4.6+computecanada-py2.py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/tensorboard_plugin_wit-1.8.0+computecanada-py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/rsa-4.8+computecanada-py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/cachetools-4.2.4+computecanada-py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/pyasn1_modules-0.2.8+computecanada-py2.py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/requests_oauthlib-1.3.0+computecanada-py2.py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/importlib_metadata-4.10.1+computecanada-py3-none-any.whl
Requirement already satisfied: typing-extensions>=3.6.4 in /localscratch/yinan.29351698.0/env/lib/python3.7/site-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard<3,>=2.3.0->tensorflow_gpu==2.3.0+computecanada) (4.0.1+computecanada)
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/zipp-3.7.0+computecanada-py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/pyasn1-0.4.8+computecanada-py2.py3-none-any.whl
Requirement already satisfied: certifi>=2017.4.17 in /cvmfs/soft.computecanada.ca/easybuild/software/2017/Core/scipy-stack/2019a/lib/python3.7/site-packages (from requests<3,>=2.21.0->tensorboard<3,>=2.3.0->tensorflow_gpu==2.3.0+computecanada) (2018.11.29)
Requirement already satisfied: charset-normalizer~=2.0.0 in /localscratch/yinan.29351698.0/env/lib/python3.7/site-packages (from requests<3,>=2.21.0->tensorboard<3,>=2.3.0->tensorflow_gpu==2.3.0+computecanada) (2.0.12+computecanada)
Requirement already satisfied: idna<4,>=2.5 in /cvmfs/soft.computecanada.ca/easybuild/software/2017/Core/scipy-stack/2019a/lib/python3.7/site-packages (from requests<3,>=2.21.0->tensorboard<3,>=2.3.0->tensorflow_gpu==2.3.0+computecanada) (2.8)
Requirement already satisfied: urllib3<1.27,>=1.21.1 in /localscratch/yinan.29351698.0/env/lib/python3.7/site-packages (from requests<3,>=2.21.0->tensorboard<3,>=2.3.0->tensorflow_gpu==2.3.0+computecanada) (1.26.8+computecanada)
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/oauthlib-3.1.1+computecanada-py2.py3-none-any.whl
Installing collected packages: pyasn1, zipp, rsa, pyasn1-modules, oauthlib, cachetools, requests-oauthlib, importlib-metadata, google-auth, werkzeug, tensorboard-plugin-wit, tensorboard-data-server, markdown, grpcio, google-auth-oauthlib, absl-py, wrapt, tensorflow-estimator, tensorboard, scipy, opt-einsum, keras-preprocessing, h5py, google-pasta, gast, astunparse, tensorflow-gpu
  Attempting uninstall: pyasn1
    Found existing installation: pyasn1 0.4.3
    Not uninstalling pyasn1 at /cvmfs/soft.computecanada.ca/easybuild/software/2017/Core/scipy-stack/2019a/lib/python3.7/site-packages, outside environment /localscratch/yinan.29351698.0/env
    Can't uninstall 'pyasn1'. No files were found to uninstall.
  Attempting uninstall: zipp
    Found existing installation: zipp 0.3.3
    Not uninstalling zipp at /cvmfs/soft.computecanada.ca/easybuild/software/2017/Core/scipy-stack/2019a/lib/python3.7/site-packages, outside environment /localscratch/yinan.29351698.0/env
    Can't uninstall 'zipp'. No files were found to uninstall.
  Attempting uninstall: importlib-metadata
    Found existing installation: importlib-metadata 0.8
    Not uninstalling importlib-metadata at /cvmfs/soft.computecanada.ca/easybuild/software/2017/Core/scipy-stack/2019a/lib/python3.7/site-packages, outside environment /localscratch/yinan.29351698.0/env
    Can't uninstall 'importlib-metadata'. No files were found to uninstall.
  Attempting uninstall: scipy
    Found existing installation: scipy 1.2.0
    Not uninstalling scipy at /cvmfs/soft.computecanada.ca/easybuild/software/2017/Core/scipy-stack/2019a/lib/python3.7/site-packages, outside environment /localscratch/yinan.29351698.0/env
    Can't uninstall 'scipy'. No files were found to uninstall.
Successfully installed absl-py-1.0.0+computecanada astunparse-1.6.3+computecanada cachetools-4.2.4+computecanada gast-0.3.3+computecanada google-auth-2.3.3+computecanada google-auth-oauthlib-0.4.6+computecanada google-pasta-0.2.0+computecanada grpcio-1.38.0+computecanada h5py-2.10.0+computecanada importlib-metadata-4.10.1+computecanada keras-preprocessing-1.1.2+computecanada markdown-3.3.6+computecanada oauthlib-3.1.1+computecanada opt-einsum-3.3.0+computecanada pyasn1-0.4.8+computecanada pyasn1-modules-0.2.8+computecanada requests-oauthlib-1.3.0+computecanada rsa-4.8+computecanada scipy-1.4.1+computecanada tensorboard-2.8.0+computecanada tensorboard-data-server-0.6.1+computecanada tensorboard-plugin-wit-1.8.0+computecanada tensorflow-estimator-2.3.0+computecanada tensorflow-gpu-2.3.0+computecanada werkzeug-2.0.3+computecanada wrapt-1.11.2+computecanada zipp-3.7.0+computecanada
Looking in links: /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/nix/avx2, /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/nix/generic, /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/keras-2.8.0+computecanada-py2.py3-none-any.whl
Installing collected packages: Keras
Successfully installed Keras-2.8.0+computecanada
Looking in links: /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/nix/avx2, /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/nix/generic, /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/urllib3-1.26.7+computecanada-py2.py3-none-any.whl
Installing collected packages: urllib3
  Attempting uninstall: urllib3
    Found existing installation: urllib3 1.26.8+computecanada
    Uninstalling urllib3-1.26.8+computecanada:
      Successfully uninstalled urllib3-1.26.8+computecanada
Successfully installed urllib3-1.26.7+computecanada
Looking in links: /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/nix/avx2, /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/nix/generic, /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/nltk-3.7+computecanada-py3-none-any.whl
Requirement already satisfied: joblib in /localscratch/yinan.29351698.0/env/lib/python3.7/site-packages (from nltk) (1.1.0+computecanada)
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/nltk-3.6.5+computecanada-py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/nltk-3.6.3+computecanada-py3-none-any.whl
Requirement already satisfied: tqdm in /localscratch/yinan.29351698.0/env/lib/python3.7/site-packages (from nltk) (4.63.0+computecanada)
Requirement already satisfied: regex in /localscratch/yinan.29351698.0/env/lib/python3.7/site-packages (from nltk) (2020.11.13+computecanada)
Requirement already satisfied: click in /localscratch/yinan.29351698.0/env/lib/python3.7/site-packages (from nltk) (8.0.4+computecanada)
Requirement already satisfied: importlib-metadata in /localscratch/yinan.29351698.0/env/lib/python3.7/site-packages (from click->nltk) (4.10.1+computecanada)
Requirement already satisfied: zipp>=0.5 in /localscratch/yinan.29351698.0/env/lib/python3.7/site-packages (from importlib-metadata->click->nltk) (3.7.0+computecanada)
Requirement already satisfied: typing-extensions>=3.6.4 in /localscratch/yinan.29351698.0/env/lib/python3.7/site-packages (from importlib-metadata->click->nltk) (4.0.1+computecanada)
Installing collected packages: nltk
Successfully installed nltk-3.6.3+computecanada
Looking in links: /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/nix/avx2, /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/nix/generic, /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/scikit_learn-0.22.1+computecanada-cp37-cp37m-linux_x86_64.whl
Requirement already satisfied: scipy>=0.17.0 in /localscratch/yinan.29351698.0/env/lib/python3.7/site-packages (from scikit-learn==0.22.1) (1.4.1+computecanada)
Requirement already satisfied: numpy>=1.11.0 in /cvmfs/soft.computecanada.ca/easybuild/software/2017/Core/scipy-stack/2019a/lib/python3.7/site-packages (from scikit-learn==0.22.1) (1.16.0)
Requirement already satisfied: joblib>=0.11 in /localscratch/yinan.29351698.0/env/lib/python3.7/site-packages (from scikit-learn==0.22.1) (1.1.0+computecanada)
Installing collected packages: scikit-learn
Successfully installed scikit-learn-0.22.1+computecanada
Looking in links: /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/nix/avx2, /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/nix/generic, /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic
Requirement already satisfied: tokenizers==0.5.2 in /localscratch/yinan.29351698.0/env/lib/python3.7/site-packages (0.5.2+computecanada)
wandb: Appending key for api.wandb.ai to your netrc file: /home/yinan/.netrc
Starting Task
2022-03-24 07:53:52.599625: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1
[nltk_data] Downloading package stopwords to /home/yinan/nltk_data...
[nltk_data]   Package stopwords is already up-to-date!
[nltk_data] Downloading package wordnet to /home/yinan/nltk_data...
[nltk_data]   Package wordnet is already up-to-date!
wandb: Currently logged in as: yinanazhou (use `wandb login --relogin` to force relogin)
wandb: wandb version 0.12.11 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
2022-03-24 07:54:03.135828: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1
wandb: Tracking run with wandb version 0.12.5
wandb: Syncing run leafy-jazz-2
wandb: ⭐️ View project at https://wandb.ai/yinanazhou/xl_512_bs_8_lr_1e06_es_10_lc_True_nr_True_sr_False_stem_False_lemma_False_repeat_1_fold_1
wandb: 🚀 View run at https://wandb.ai/yinanazhou/xl_512_bs_8_lr_1e06_es_10_lc_True_nr_True_sr_False_stem_False_lemma_False_repeat_1_fold_1/runs/1bvcv2xl
wandb: Run data is saved locally in /project/6002780/yinan/Thesis_MER_Lyrics/lyric-emotion/wandb/run-20220324_075401-1bvcv2xl
wandb: Run `wandb offline` to turn off syncing.

Validation loss decreased (inf --> 1.439705).  Saving model ...
Validation loss decreased (1.439705 --> 1.419512).  Saving model ...
Validation loss decreased (1.419512 --> 1.402896).  Saving model ...
Validation loss decreased (1.402896 --> 1.389535).  Saving model ...
Validation loss decreased (1.389535 --> 1.379558).  Saving model ...
Validation loss decreased (1.379558 --> 1.370725).  Saving model ...
Validation loss decreased (1.370725 --> 1.364060).  Saving model ...
Validation loss decreased (1.364060 --> 1.358288).  Saving model ...
Validation loss decreased (1.358288 --> 1.352618).  Saving model ...
Validation loss decreased (1.352618 --> 1.347247).  Saving model ...
Validation loss decreased (1.347247 --> 1.341469).  Saving model ...
Validation loss decreased (1.341469 --> 1.336687).  Saving model ...
Validation loss decreased (1.336687 --> 1.331722).  Saving model ...
Validation loss decreased (1.331722 --> 1.326793).  Saving model ...
Validation loss decreased (1.326793 --> 1.321442).  Saving model ...
Validation loss decreased (1.321442 --> 1.317452).  Saving model ...
Validation loss decreased (1.317452 --> 1.311851).  Saving model ...
Validation loss decreased (1.311851 --> 1.305910).  Saving model ...
Validation loss decreased (1.305910 --> 1.300498).  Saving model ...
Validation loss decreased (1.300498 --> 1.294612).  Saving model ...
Validation loss decreased (1.294612 --> 1.289088).  Saving model ...
Validation loss decreased (1.289088 --> 1.282033).  Saving model ...
Validation loss decreased (1.282033 --> 1.278490).  Saving model ...
Validation loss decreased (1.278490 --> 1.271101).  Saving model ...
Validation loss decreased (1.271101 --> 1.265703).  Saving model ...
Validation loss decreased (1.265703 --> 1.261029).  Saving model ...
Validation loss decreased (1.261029 --> 1.254424).  Saving model ...
Validation loss decreased (1.254424 --> 1.250263).  Saving model ...
Validation loss decreased (1.250263 --> 1.247004).  Saving model ...
Validation loss decreased (1.247004 --> 1.245395).  Saving model ...
Validation loss decreased (1.245395 --> 1.242729).  Saving model ...
Validation loss decreased (1.242729 --> 1.237397).  Saving model ...
Validation loss decreased (1.237397 --> 1.235904).  Saving model ...
Validation loss decreased (1.235904 --> 1.230276).  Saving model ...
Validation loss decreased (1.230276 --> 1.227219).  Saving model ...
Validation loss decreased (1.227219 --> 1.220999).  Saving model ...
Validation loss decreased (1.220999 --> 1.215459).  Saving model ...
Validation loss decreased (1.215459 --> 1.214406).  Saving model ...
Validation loss decreased (1.214406 --> 1.209761).  Saving model ...
Validation loss decreased (1.209761 --> 1.208001).  Saving model ...
Validation loss decreased (1.208001 --> 1.201319).  Saving model ...
Validation loss decreased (1.201319 --> 1.197031).  Saving model ...
Validation loss decreased (1.197031 --> 1.194019).  Saving model ...
Validation loss decreased (1.194019 --> 1.193997).  Saving model ...
Validation loss decreased (1.193997 --> 1.189291).  Saving model ...
Validation loss decreased (1.189291 --> 1.186797).  Saving model ...
Validation loss decreased (1.186797 --> 1.185167).  Saving model ...
EarlyStopping counter: 1 out of 10.0
Validation loss decreased (1.185167 --> 1.179282).  Saving model ...
Validation loss decreased (1.179282 --> 1.179126).  Saving model ...
Validation loss decreased (1.179126 --> 1.172249).  Saving model ...
Validation loss decreased (1.172249 --> 1.169561).  Saving model ...
Validation loss decreased (1.169561 --> 1.168631).  Saving model ...
Validation loss decreased (1.168631 --> 1.165754).  Saving model ...
Validation loss decreased (1.165754 --> 1.165563).  Saving model ...
Validation loss decreased (1.165563 --> 1.159924).  Saving model ...
Validation loss decreased (1.159924 --> 1.154075).  Saving model ...
Validation loss decreased (1.154075 --> 1.149934).  Saving model ...
Validation loss decreased (1.149934 --> 1.144026).  Saving model ...
EarlyStopping counter: 1 out of 10.0
Validation loss decreased (1.144026 --> 1.141895).  Saving model ...
Validation loss decreased (1.141895 --> 1.139391).  Saving model ...
Validation loss decreased (1.139391 --> 1.134637).  Saving model ...
EarlyStopping counter: 1 out of 10.0
EarlyStopping counter: 2 out of 10.0
Validation loss decreased (1.134637 --> 1.130837).  Saving model ...
Validation loss decreased (1.130837 --> 1.128263).  Saving model ...
Validation loss decreased (1.128263 --> 1.122229).  Saving model ...
Validation loss decreased (1.122229 --> 1.121355).  Saving model ...
Validation loss decreased (1.121355 --> 1.119745).  Saving model ...
Validation loss decreased (1.119745 --> 1.113369).  Saving model ...
Validation loss decreased (1.113369 --> 1.111985).  Saving model ...
Validation loss decreased (1.111985 --> 1.111388).  Saving model ...
Validation loss decreased (1.111388 --> 1.108078).  Saving model ...
Validation loss decreased (1.108078 --> 1.104047).  Saving model ...
Validation loss decreased (1.104047 --> 1.103267).  Saving model ...
Validation loss decreased (1.103267 --> 1.102833).  Saving model ...
Validation loss decreased (1.102833 --> 1.098015).  Saving model ...
Validation loss decreased (1.098015 --> 1.092954).  Saving model ...
Validation loss decreased (1.092954 --> 1.091071).  Saving model ...
EarlyStopping counter: 1 out of 10.0
EarlyStopping counter: 2 out of 10.0
EarlyStopping counter: 3 out of 10.0
Validation loss decreased (1.091071 --> 1.088426).  Saving model ...
Validation loss decreased (1.088426 --> 1.086415).  Saving model ...
Validation loss decreased (1.086415 --> 1.081795).  Saving model ...
Validation loss decreased (1.081795 --> 1.076227).  Saving model ...
EarlyStopping counter: 1 out of 10.0
EarlyStopping counter: 2 out of 10.0
EarlyStopping counter: 3 out of 10.0
Validation loss decreased (1.076227 --> 1.076158).  Saving model ...
Validation loss decreased (1.076158 --> 1.075998).  Saving model ...
Validation loss decreased (1.075998 --> 1.073468).  Saving model ...
EarlyStopping counter: 1 out of 10.0
EarlyStopping counter: 2 out of 10.0
Validation loss decreased (1.073468 --> 1.071521).  Saving model ...
Validation loss decreased (1.071521 --> 1.070522).  Saving model ...
Validation loss decreased (1.070522 --> 1.063458).  Saving model ...
Validation loss decreased (1.063458 --> 1.062997).  Saving model ...
EarlyStopping counter: 1 out of 10.0
EarlyStopping counter: 2 out of 10.0
Validation loss decreased (1.062997 --> 1.058527).  Saving model ...
Validation loss decreased (1.058527 --> 1.057909).  Saving model ...
Validation loss decreased (1.057909 --> 1.056703).  Saving model ...
Validation loss decreased (1.056703 --> 1.055632).  Saving model ...
Validation loss decreased (1.055632 --> 1.052692).  Saving model ...
Validation loss decreased (1.052692 --> 1.052595).  Saving model ...
Validation loss decreased (1.052595 --> 1.049691).  Saving model ...
Validation loss decreased (1.049691 --> 1.047494).  Saving model ...
Validation loss decreased (1.047494 --> 1.044458).  Saving model ...
EarlyStopping counter: 1 out of 10.0
EarlyStopping counter: 2 out of 10.0
EarlyStopping counter: 3 out of 10.0
EarlyStopping counter: 4 out of 10.0
EarlyStopping counter: 5 out of 10.0
Validation loss decreased (1.044458 --> 1.043136).  Saving model ...
Validation loss decreased (1.043136 --> 1.038603).  Saving model ...
Validation loss decreased (1.038603 --> 1.036479).  Saving model ...
Validation loss decreased (1.036479 --> 1.034389).  Saving model ...
Validation loss decreased (1.034389 --> 1.031973).  Saving model ...
EarlyStopping counter: 1 out of 10.0
Validation loss decreased (1.031973 --> 1.031230).  Saving model ...
Validation loss decreased (1.031230 --> 1.027849).  Saving model ...
EarlyStopping counter: 1 out of 10.0
Validation loss decreased (1.027849 --> 1.026845).  Saving model ...
Validation loss decreased (1.026845 --> 1.026224).  Saving model ...
EarlyStopping counter: 1 out of 10.0
EarlyStopping counter: 2 out of 10.0
EarlyStopping counter: 3 out of 10.0
Validation loss decreased (1.026224 --> 1.024811).  Saving model ...
Validation loss decreased (1.024811 --> 1.024381).  Saving model ...
EarlyStopping counter: 1 out of 10.0
Validation loss decreased (1.024381 --> 1.021788).  Saving model ...
Validation loss decreased (1.021788 --> 1.020333).  Saving model ...
EarlyStopping counter: 1 out of 10.0
EarlyStopping counter: 2 out of 10.0
EarlyStopping counter: 3 out of 10.0
Validation loss decreased (1.020333 --> 1.018223).  Saving model ...
Validation loss decreased (1.018223 --> 1.018061).  Saving model ...
EarlyStopping counter: 1 out of 10.0
EarlyStopping counter: 2 out of 10.0
EarlyStopping counter: 3 out of 10.0
EarlyStopping counter: 4 out of 10.0
EarlyStopping counter: 5 out of 10.0
Validation loss decreased (1.018061 --> 1.014636).  Saving model ...
Validation loss decreased (1.014636 --> 1.013544).  Saving model ...
EarlyStopping counter: 1 out of 10.0
EarlyStopping counter: 2 out of 10.0
EarlyStopping counter: 3 out of 10.0
Validation loss decreased (1.013544 --> 1.012678).  Saving model ...
Validation loss decreased (1.012678 --> 1.010186).  Saving model ...
EarlyStopping counter: 1 out of 10.0
Validation loss decreased (1.010186 --> 1.010108).  Saving model ...
EarlyStopping counter: 1 out of 10.0
Validation loss decreased (1.010108 --> 1.009077).  Saving model ...
Validation loss decreased (1.009077 --> 1.005800).  Saving model ...
EarlyStopping counter: 1 out of 10.0
EarlyStopping counter: 2 out of 10.0
EarlyStopping counter: 3 out of 10.0
EarlyStopping counter: 4 out of 10.0
EarlyStopping counter: 5 out of 10.0
EarlyStopping counter: 6 out of 10.0
EarlyStopping counter: 7 out of 10.0
EarlyStopping counter: 8 out of 10.0
EarlyStopping counter: 9 out of 10.0
EarlyStopping counter: 10 out of 10.0
/localscratch/yinan.29351698.0/env/lib/python3.7/site-packages/torch/nn/functional.py:1794: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.
  warnings.warn("nn.functional.tanh is deprecated. Use torch.tanh instead.")
/localscratch/yinan.29351698.0/env/lib/python3.7/site-packages/transformers/optimization.py:155: UserWarning: This overload of add_ is deprecated:
	add_(Number alpha, Tensor other)
Consider using one of the following signatures instead:
	add_(Tensor other, *, Number alpha) (Triggered internally at  ../torch/csrc/utils/python_arg_parser.cpp:1025.)
  exp_avg.mul_(beta1).add_(1.0 - beta1, grad)
wandb: Waiting for W&B process to finish, PID 88968... (success).
wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: \ 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: | 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: / 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: \ 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: | 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: / 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: \ 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: | 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: / 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: \ 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb:                                                                                
wandb: Run history:
wandb:     e_F1 ▁▂▄▄▅▅▅▅▅▆▆▆▆▆▆▆▆▆▇▇▇▇▇▇▇▇████▇█████████
wandb:   e_loss █▇▇▆▆▆▅▅▅▅▄▄▄▄▃▃▃▃▃▂▂▂▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁
wandb:     t_F1 ▁▂▂▃▃▄▄▄▅▅▅▅▅▅▆▆▅▆▅▆▇▆▇▇▇▇▇▇▇▇▇▇▇▇▇█████
wandb:   t_loss █▇█▇▇▆▆▆▆▅▅▅▄▅▄▄▄▄▄▃▃▃▃▃▂▂▂▂▂▂▂▂▂▂▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:     e_F1 57.25595
wandb:   e_loss 1.01565
wandb:     t_F1 74.0466
wandb:   t_loss 0.69737
wandb: 
wandb: Synced 4 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Synced leafy-jazz-2: https://wandb.ai/yinanazhou/xl_512_bs_8_lr_1e06_es_10_lc_True_nr_True_sr_False_stem_False_lemma_False_repeat_1_fold_1/runs/1bvcv2xl
wandb: Find logs at: ./wandb/run-20220324_075401-1bvcv2xl/logs/debug.log
wandb: 

wandb: wandb version 0.12.11 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
2022-03-24 09:39:11.814574: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1
wandb: Tracking run with wandb version 0.12.5
wandb: Syncing run curious-music-2
wandb: ⭐️ View project at https://wandb.ai/yinanazhou/xl_512_bs_8_lr_1e06_es_10_lc_True_nr_True_sr_False_stem_False_lemma_False_repeat_1_fold_2
wandb: 🚀 View run at https://wandb.ai/yinanazhou/xl_512_bs_8_lr_1e06_es_10_lc_True_nr_True_sr_False_stem_False_lemma_False_repeat_1_fold_2/runs/ffkwd7n0
wandb: Run data is saved locally in /project/6002780/yinan/Thesis_MER_Lyrics/lyric-emotion/wandb/run-20220324_093909-ffkwd7n0
wandb: Run `wandb offline` to turn off syncing.

Validation loss decreased (inf --> 1.514618).  Saving model ...
Validation loss decreased (1.514618 --> 1.466998).  Saving model ...
Validation loss decreased (1.466998 --> 1.437521).  Saving model ...
Validation loss decreased (1.437521 --> 1.420343).  Saving model ...
Validation loss decreased (1.420343 --> 1.409124).  Saving model ...
Validation loss decreased (1.409124 --> 1.401703).  Saving model ...
Validation loss decreased (1.401703 --> 1.396382).  Saving model ...
Validation loss decreased (1.396382 --> 1.391626).  Saving model ...
Validation loss decreased (1.391626 --> 1.387137).  Saving model ...
Validation loss decreased (1.387137 --> 1.382839).  Saving model ...
Validation loss decreased (1.382839 --> 1.378801).  Saving model ...
Validation loss decreased (1.378801 --> 1.372687).  Saving model ...
Validation loss decreased (1.372687 --> 1.367986).  Saving model ...
Validation loss decreased (1.367986 --> 1.363603).  Saving model ...
Validation loss decreased (1.363603 --> 1.358547).  Saving model ...
Validation loss decreased (1.358547 --> 1.353940).  Saving model ...
Validation loss decreased (1.353940 --> 1.348383).  Saving model ...
Validation loss decreased (1.348383 --> 1.343722).  Saving model ...
Validation loss decreased (1.343722 --> 1.338779).  Saving model ...
Validation loss decreased (1.338779 --> 1.333652).  Saving model ...
Validation loss decreased (1.333652 --> 1.328639).  Saving model ...
Validation loss decreased (1.328639 --> 1.323374).  Saving model ...
Validation loss decreased (1.323374 --> 1.317826).  Saving model ...
Validation loss decreased (1.317826 --> 1.312511).  Saving model ...
Validation loss decreased (1.312511 --> 1.306750).  Saving model ...
Validation loss decreased (1.306750 --> 1.300561).  Saving model ...
Validation loss decreased (1.300561 --> 1.294904).  Saving model ...
Validation loss decreased (1.294904 --> 1.288768).  Saving model ...
Validation loss decreased (1.288768 --> 1.282928).  Saving model ...
Validation loss decreased (1.282928 --> 1.277279).  Saving model ...
Validation loss decreased (1.277279 --> 1.271486).  Saving model ...
Validation loss decreased (1.271486 --> 1.265372).  Saving model ...
Validation loss decreased (1.265372 --> 1.259242).  Saving model ...
Validation loss decreased (1.259242 --> 1.251859).  Saving model ...
Validation loss decreased (1.251859 --> 1.245584).  Saving model ...
Validation loss decreased (1.245584 --> 1.239496).  Saving model ...
Validation loss decreased (1.239496 --> 1.233419).  Saving model ...
Validation loss decreased (1.233419 --> 1.227286).  Saving model ...
Validation loss decreased (1.227286 --> 1.221122).  Saving model ...
Validation loss decreased (1.221122 --> 1.214986).  Saving model ...
Validation loss decreased (1.214986 --> 1.208963).  Saving model ...
Validation loss decreased (1.208963 --> 1.201599).  Saving model ...
Validation loss decreased (1.201599 --> 1.195010).  Saving model ...
Validation loss decreased (1.195010 --> 1.187766).  Saving model ...
Validation loss decreased (1.187766 --> 1.180848).  Saving model ...
Validation loss decreased (1.180848 --> 1.173891).  Saving model ...
Validation loss decreased (1.173891 --> 1.167473).  Saving model ...
Validation loss decreased (1.167473 --> 1.160826).  Saving model ...
Validation loss decreased (1.160826 --> 1.154631).  Saving model ...
Validation loss decreased (1.154631 --> 1.148348).  Saving model ...
Validation loss decreased (1.148348 --> 1.142012).  Saving model ...
Validation loss decreased (1.142012 --> 1.135753).  Saving model ...
Validation loss decreased (1.135753 --> 1.129300).  Saving model ...
Validation loss decreased (1.129300 --> 1.123560).  Saving model ...
Validation loss decreased (1.123560 --> 1.117719).  Saving model ...
Validation loss decreased (1.117719 --> 1.111657).  Saving model ...
Validation loss decreased (1.111657 --> 1.106734).  Saving model ...
Validation loss decreased (1.106734 --> 1.100771).  Saving model ...
Validation loss decreased (1.100771 --> 1.095014).  Saving model ...
Validation loss decreased (1.095014 --> 1.089366).  Saving model ...
Validation loss decreased (1.089366 --> 1.084392).  Saving model ...
Validation loss decreased (1.084392 --> 1.079370).  Saving model ...
Validation loss decreased (1.079370 --> 1.073657).  Saving model ...
Validation loss decreased (1.073657 --> 1.068614).  Saving model ...
Validation loss decreased (1.068614 --> 1.064185).  Saving model ...
Validation loss decreased (1.064185 --> 1.060298).  Saving model ...
Validation loss decreased (1.060298 --> 1.056838).  Saving model ...
Validation loss decreased (1.056838 --> 1.051922).  Saving model ...
Validation loss decreased (1.051922 --> 1.047396).  Saving model ...
Validation loss decreased (1.047396 --> 1.043511).  Saving model ...
Validation loss decreased (1.043511 --> 1.039340).  Saving model ...
Validation loss decreased (1.039340 --> 1.035369).  Saving model ...
Validation loss decreased (1.035369 --> 1.030980).  Saving model ...
Validation loss decreased (1.030980 --> 1.027092).  Saving model ...
Validation loss decreased (1.027092 --> 1.023860).  Saving model ...
Validation loss decreased (1.023860 --> 1.020216).  Saving model ...
Validation loss decreased (1.020216 --> 1.016997).  Saving model ...
Validation loss decreased (1.016997 --> 1.013192).  Saving model ...
Validation loss decreased (1.013192 --> 1.009220).  Saving model ...
Validation loss decreased (1.009220 --> 1.006354).  Saving model ...
Validation loss decreased (1.006354 --> 1.002380).  Saving model ...
Validation loss decreased (1.002380 --> 0.999636).  Saving model ...
Validation loss decreased (0.999636 --> 0.996106).  Saving model ...
Validation loss decreased (0.996106 --> 0.993826).  Saving model ...
Validation loss decreased (0.993826 --> 0.990690).  Saving model ...
Validation loss decreased (0.990690 --> 0.987998).  Saving model ...
Validation loss decreased (0.987998 --> 0.985171).  Saving model ...
Validation loss decreased (0.985171 --> 0.982713).  Saving model ...
Validation loss decreased (0.982713 --> 0.979643).  Saving model ...
Validation loss decreased (0.979643 --> 0.977568).  Saving model ...
Validation loss decreased (0.977568 --> 0.975008).  Saving model ...
Validation loss decreased (0.975008 --> 0.972364).  Saving model ...
Validation loss decreased (0.972364 --> 0.970005).  Saving model ...
Validation loss decreased (0.970005 --> 0.967830).  Saving model ...
Validation loss decreased (0.967830 --> 0.966047).  Saving model ...
Validation loss decreased (0.966047 --> 0.964214).  Saving model ...
Validation loss decreased (0.964214 --> 0.962546).  Saving model ...
Validation loss decreased (0.962546 --> 0.960855).  Saving model ...
Validation loss decreased (0.960855 --> 0.959122).  Saving model ...
Validation loss decreased (0.959122 --> 0.956910).  Saving model ...
Validation loss decreased (0.956910 --> 0.954617).  Saving model ...
Validation loss decreased (0.954617 --> 0.951901).  Saving model ...
Validation loss decreased (0.951901 --> 0.951240).  Saving model ...
Validation loss decreased (0.951240 --> 0.949446).  Saving model ...
Validation loss decreased (0.949446 --> 0.947682).  Saving model ...
Validation loss decreased (0.947682 --> 0.946200).  Saving model ...
Validation loss decreased (0.946200 --> 0.944776).  Saving model ...
Validation loss decreased (0.944776 --> 0.942822).  Saving model ...
Validation loss decreased (0.942822 --> 0.942686).  Saving model ...
Validation loss decreased (0.942686 --> 0.940969).  Saving model ...
Validation loss decreased (0.940969 --> 0.939342).  Saving model ...
Validation loss decreased (0.939342 --> 0.939107).  Saving model ...
Validation loss decreased (0.939107 --> 0.938453).  Saving model ...
Validation loss decreased (0.938453 --> 0.937008).  Saving model ...
Validation loss decreased (0.937008 --> 0.936868).  Saving model ...
Validation loss decreased (0.936868 --> 0.936277).  Saving model ...
Validation loss decreased (0.936277 --> 0.935002).  Saving model ...
Validation loss decreased (0.935002 --> 0.934052).  Saving model ...
Validation loss decreased (0.934052 --> 0.933034).  Saving model ...
EarlyStopping counter: 1 out of 10.0
Validation loss decreased (0.933034 --> 0.932830).  Saving model ...
Validation loss decreased (0.932830 --> 0.930085).  Saving model ...
Validation loss decreased (0.930085 --> 0.929448).  Saving model ...
Validation loss decreased (0.929448 --> 0.927396).  Saving model ...
Validation loss decreased (0.927396 --> 0.927131).  Saving model ...
EarlyStopping counter: 1 out of 10.0
EarlyStopping counter: 2 out of 10.0
EarlyStopping counter: 3 out of 10.0
EarlyStopping counter: 4 out of 10.0
EarlyStopping counter: 5 out of 10.0
Validation loss decreased (0.927131 --> 0.926099).  Saving model ...
Validation loss decreased (0.926099 --> 0.925973).  Saving model ...
Validation loss decreased (0.925973 --> 0.925555).  Saving model ...
Validation loss decreased (0.925555 --> 0.925442).  Saving model ...
EarlyStopping counter: 1 out of 10.0
Validation loss decreased (0.925442 --> 0.924583).  Saving model ...
EarlyStopping counter: 1 out of 10.0
Validation loss decreased (0.924583 --> 0.923435).  Saving model ...
EarlyStopping counter: 1 out of 10.0
Validation loss decreased (0.923435 --> 0.922611).  Saving model ...
Validation loss decreased (0.922611 --> 0.922257).  Saving model ...
EarlyStopping counter: 1 out of 10.0
EarlyStopping counter: 2 out of 10.0
EarlyStopping counter: 3 out of 10.0
Validation loss decreased (0.922257 --> 0.922254).  Saving model ...
EarlyStopping counter: 1 out of 10.0
Validation loss decreased (0.922254 --> 0.921903).  Saving model ...
EarlyStopping counter: 1 out of 10.0
EarlyStopping counter: 2 out of 10.0
EarlyStopping counter: 3 out of 10.0
EarlyStopping counter: 4 out of 10.0
EarlyStopping counter: 5 out of 10.0
EarlyStopping counter: 6 out of 10.0
EarlyStopping counter: 7 out of 10.0
EarlyStopping counter: 8 out of 10.0
EarlyStopping counter: 9 out of 10.0
EarlyStopping counter: 10 out of 10.0
/localscratch/yinan.29351698.0/env/lib/python3.7/site-packages/torch/nn/functional.py:1794: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.
  warnings.warn("nn.functional.tanh is deprecated. Use torch.tanh instead.")
wandb: Waiting for W&B process to finish, PID 94605... (success).
wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: \ 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: | 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: / 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: \ 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: | 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: / 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: \ 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: | 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: / 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb:                                                                                
wandb: Run history:
wandb:     e_F1 ▁▂▃▄▄▄▄▅▅▅▅▆▆▆▇▇▇▇▇▇▇▇██████████████████
wandb:   e_loss █▇▇▇▇▆▆▆▅▅▅▄▄▄▃▃▃▃▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:     t_F1 ▁▂▂▃▃▃▃▄▄▄▅▅▅▅▅▆▆▆▆▆▆▆▆▇▇▇▇▇▇▇▇▇▇▇██████
wandb:   t_loss █▇▇▇▇▇▆▆▆▆▆▅▅▅▅▄▄▄▄▄▃▄▃▃▃▃▂▂▂▂▂▂▁▂▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:     e_F1 62.15688
wandb:   e_loss 0.92659
wandb:     t_F1 74.19845
wandb:   t_loss 0.71646
wandb: 
wandb: Synced 4 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Synced curious-music-2: https://wandb.ai/yinanazhou/xl_512_bs_8_lr_1e06_es_10_lc_True_nr_True_sr_False_stem_False_lemma_False_repeat_1_fold_2/runs/ffkwd7n0
wandb: Find logs at: ./wandb/run-20220324_093909-ffkwd7n0/logs/debug.log
wandb: 

wandb: wandb version 0.12.11 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
2022-03-24 11:22:39.326884: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1
wandb: Tracking run with wandb version 0.12.5
wandb: Syncing run firm-music-2
wandb: ⭐️ View project at https://wandb.ai/yinanazhou/xl_512_bs_8_lr_1e06_es_10_lc_True_nr_True_sr_False_stem_False_lemma_False_repeat_2_fold_1
wandb: 🚀 View run at https://wandb.ai/yinanazhou/xl_512_bs_8_lr_1e06_es_10_lc_True_nr_True_sr_False_stem_False_lemma_False_repeat_2_fold_1/runs/ge0vo9j9
wandb: Run data is saved locally in /project/6002780/yinan/Thesis_MER_Lyrics/lyric-emotion/wandb/run-20220324_112236-ge0vo9j9
wandb: Run `wandb offline` to turn off syncing.

Validation loss decreased (inf --> 1.405493).  Saving model ...
Validation loss decreased (1.405493 --> 1.394754).  Saving model ...
Validation loss decreased (1.394754 --> 1.386056).  Saving model ...
Validation loss decreased (1.386056 --> 1.379246).  Saving model ...
Validation loss decreased (1.379246 --> 1.373622).  Saving model ...
Validation loss decreased (1.373622 --> 1.368374).  Saving model ...
Validation loss decreased (1.368374 --> 1.363667).  Saving model ...
Validation loss decreased (1.363667 --> 1.359080).  Saving model ...
Validation loss decreased (1.359080 --> 1.355402).  Saving model ...
Validation loss decreased (1.355402 --> 1.350940).  Saving model ...
Validation loss decreased (1.350940 --> 1.346895).  Saving model ...
Validation loss decreased (1.346895 --> 1.342683).  Saving model ...
Validation loss decreased (1.342683 --> 1.338893).  Saving model ...
Validation loss decreased (1.338893 --> 1.334081).  Saving model ...
Validation loss decreased (1.334081 --> 1.329784).  Saving model ...
Validation loss decreased (1.329784 --> 1.325160).  Saving model ...
Validation loss decreased (1.325160 --> 1.319870).  Saving model ...
Validation loss decreased (1.319870 --> 1.313563).  Saving model ...
Validation loss decreased (1.313563 --> 1.308162).  Saving model ...
Validation loss decreased (1.308162 --> 1.302572).  Saving model ...
Validation loss decreased (1.302572 --> 1.296167).  Saving model ...
Validation loss decreased (1.296167 --> 1.289510).  Saving model ...
Validation loss decreased (1.289510 --> 1.283368).  Saving model ...
Validation loss decreased (1.283368 --> 1.276933).  Saving model ...
Validation loss decreased (1.276933 --> 1.270071).  Saving model ...
Validation loss decreased (1.270071 --> 1.263132).  Saving model ...
Validation loss decreased (1.263132 --> 1.256483).  Saving model ...
Validation loss decreased (1.256483 --> 1.248533).  Saving model ...
Validation loss decreased (1.248533 --> 1.241820).  Saving model ...
Validation loss decreased (1.241820 --> 1.234402).  Saving model ...
Validation loss decreased (1.234402 --> 1.224975).  Saving model ...
Validation loss decreased (1.224975 --> 1.217616).  Saving model ...
Validation loss decreased (1.217616 --> 1.210360).  Saving model ...
Validation loss decreased (1.210360 --> 1.203512).  Saving model ...
Validation loss decreased (1.203512 --> 1.195984).  Saving model ...
Validation loss decreased (1.195984 --> 1.187257).  Saving model ...
Validation loss decreased (1.187257 --> 1.180909).  Saving model ...
Validation loss decreased (1.180909 --> 1.174252).  Saving model ...
Validation loss decreased (1.174252 --> 1.168812).  Saving model ...
Validation loss decreased (1.168812 --> 1.162242).  Saving model ...
Validation loss decreased (1.162242 --> 1.156263).  Saving model ...
Validation loss decreased (1.156263 --> 1.151120).  Saving model ...
Validation loss decreased (1.151120 --> 1.146706).  Saving model ...
Validation loss decreased (1.146706 --> 1.141058).  Saving model ...
Validation loss decreased (1.141058 --> 1.135717).  Saving model ...
Validation loss decreased (1.135717 --> 1.131608).  Saving model ...
Validation loss decreased (1.131608 --> 1.128571).  Saving model ...
Validation loss decreased (1.128571 --> 1.125146).  Saving model ...
Validation loss decreased (1.125146 --> 1.120944).  Saving model ...
Validation loss decreased (1.120944 --> 1.115911).  Saving model ...
Validation loss decreased (1.115911 --> 1.110289).  Saving model ...
Validation loss decreased (1.110289 --> 1.106471).  Saving model ...
Validation loss decreased (1.106471 --> 1.102010).  Saving model ...
Validation loss decreased (1.102010 --> 1.097297).  Saving model ...
Validation loss decreased (1.097297 --> 1.093568).  Saving model ...
Validation loss decreased (1.093568 --> 1.092550).  Saving model ...
Validation loss decreased (1.092550 --> 1.086165).  Saving model ...
Validation loss decreased (1.086165 --> 1.082987).  Saving model ...
Validation loss decreased (1.082987 --> 1.080703).  Saving model ...
Validation loss decreased (1.080703 --> 1.078005).  Saving model ...
Validation loss decreased (1.078005 --> 1.074061).  Saving model ...
Validation loss decreased (1.074061 --> 1.070361).  Saving model ...
Validation loss decreased (1.070361 --> 1.065705).  Saving model ...
Validation loss decreased (1.065705 --> 1.064090).  Saving model ...
Validation loss decreased (1.064090 --> 1.060451).  Saving model ...
Validation loss decreased (1.060451 --> 1.057287).  Saving model ...
Validation loss decreased (1.057287 --> 1.053913).  Saving model ...
Validation loss decreased (1.053913 --> 1.049452).  Saving model ...
Validation loss decreased (1.049452 --> 1.047909).  Saving model ...
Validation loss decreased (1.047909 --> 1.047338).  Saving model ...
Validation loss decreased (1.047338 --> 1.043518).  Saving model ...
Validation loss decreased (1.043518 --> 1.039298).  Saving model ...
Validation loss decreased (1.039298 --> 1.036961).  Saving model ...
Validation loss decreased (1.036961 --> 1.036009).  Saving model ...
Validation loss decreased (1.036009 --> 1.033950).  Saving model ...
Validation loss decreased (1.033950 --> 1.032168).  Saving model ...
Validation loss decreased (1.032168 --> 1.029029).  Saving model ...
Validation loss decreased (1.029029 --> 1.026776).  Saving model ...
Validation loss decreased (1.026776 --> 1.026063).  Saving model ...
Validation loss decreased (1.026063 --> 1.022868).  Saving model ...
Validation loss decreased (1.022868 --> 1.019825).  Saving model ...
Validation loss decreased (1.019825 --> 1.019493).  Saving model ...
Validation loss decreased (1.019493 --> 1.018176).  Saving model ...
Validation loss decreased (1.018176 --> 1.015478).  Saving model ...
Validation loss decreased (1.015478 --> 1.015348).  Saving model ...
Validation loss decreased (1.015348 --> 1.014111).  Saving model ...
Validation loss decreased (1.014111 --> 1.011436).  Saving model ...
Validation loss decreased (1.011436 --> 1.010767).  Saving model ...
Validation loss decreased (1.010767 --> 1.008567).  Saving model ...
Validation loss decreased (1.008567 --> 1.006184).  Saving model ...
EarlyStopping counter: 1 out of 10.0
Validation loss decreased (1.006184 --> 1.005461).  Saving model ...
Validation loss decreased (1.005461 --> 1.004255).  Saving model ...
Validation loss decreased (1.004255 --> 1.002631).  Saving model ...
Validation loss decreased (1.002631 --> 1.001079).  Saving model ...
Validation loss decreased (1.001079 --> 0.999242).  Saving model ...
Validation loss decreased (0.999242 --> 0.996901).  Saving model ...
Validation loss decreased (0.996901 --> 0.995706).  Saving model ...
Validation loss decreased (0.995706 --> 0.993391).  Saving model ...
Validation loss decreased (0.993391 --> 0.992792).  Saving model ...
Validation loss decreased (0.992792 --> 0.990996).  Saving model ...
Validation loss decreased (0.990996 --> 0.987956).  Saving model ...
EarlyStopping counter: 1 out of 10.0
Validation loss decreased (0.987956 --> 0.986833).  Saving model ...
Validation loss decreased (0.986833 --> 0.985945).  Saving model ...
Validation loss decreased (0.985945 --> 0.983917).  Saving model ...
Validation loss decreased (0.983917 --> 0.982282).  Saving model ...
EarlyStopping counter: 1 out of 10.0
Validation loss decreased (0.982282 --> 0.981332).  Saving model ...
Validation loss decreased (0.981332 --> 0.979936).  Saving model ...
Validation loss decreased (0.979936 --> 0.977466).  Saving model ...
EarlyStopping counter: 1 out of 10.0
EarlyStopping counter: 2 out of 10.0
Validation loss decreased (0.977466 --> 0.976600).  Saving model ...
Validation loss decreased (0.976600 --> 0.975274).  Saving model ...
Validation loss decreased (0.975274 --> 0.974616).  Saving model ...
Validation loss decreased (0.974616 --> 0.973477).  Saving model ...
Validation loss decreased (0.973477 --> 0.971114).  Saving model ...
Validation loss decreased (0.971114 --> 0.970433).  Saving model ...
EarlyStopping counter: 1 out of 10.0
EarlyStopping counter: 2 out of 10.0
EarlyStopping counter: 3 out of 10.0
Validation loss decreased (0.970433 --> 0.969314).  Saving model ...
EarlyStopping counter: 1 out of 10.0
EarlyStopping counter: 2 out of 10.0
EarlyStopping counter: 3 out of 10.0
EarlyStopping counter: 4 out of 10.0
Validation loss decreased (0.969314 --> 0.968884).  Saving model ...
Validation loss decreased (0.968884 --> 0.966779).  Saving model ...
Validation loss decreased (0.966779 --> 0.966171).  Saving model ...
EarlyStopping counter: 1 out of 10.0
EarlyStopping counter: 2 out of 10.0
EarlyStopping counter: 3 out of 10.0
Validation loss decreased (0.966171 --> 0.965542).  Saving model ...
EarlyStopping counter: 1 out of 10.0
EarlyStopping counter: 2 out of 10.0
EarlyStopping counter: 3 out of 10.0
Validation loss decreased (0.965542 --> 0.964886).  Saving model ...
EarlyStopping counter: 1 out of 10.0
EarlyStopping counter: 2 out of 10.0
EarlyStopping counter: 3 out of 10.0
EarlyStopping counter: 4 out of 10.0
EarlyStopping counter: 5 out of 10.0
EarlyStopping counter: 6 out of 10.0
EarlyStopping counter: 7 out of 10.0
EarlyStopping counter: 8 out of 10.0
EarlyStopping counter: 9 out of 10.0
EarlyStopping counter: 10 out of 10.0
/localscratch/yinan.29351698.0/env/lib/python3.7/site-packages/torch/nn/functional.py:1794: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.
  warnings.warn("nn.functional.tanh is deprecated. Use torch.tanh instead.")
wandb: Waiting for W&B process to finish, PID 100161... (success).
wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: \ 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: | 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: / 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: \ 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: | 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: / 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: \ 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: | 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: / 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb:                                                                                
wandb: Run history:
wandb:     e_F1 ▁▂▃▄▅▅▅▆▆▆▆▆▇▇▇▇▇▇▇▇▇██▇████████████████
wandb:   e_loss ██▇▇▇▆▆▆▅▅▄▄▄▃▃▃▃▃▂▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:     t_F1 ▁▁▂▃▃▃▃▄▄▅▅▅▅▅▆▆▆▆▆▆▆▇▇▇▇▇▇▇▇▇▇▇▇███████
wandb:   t_loss ███▇▇▇▇▆▆▆▆▆▅▅▅▄▄▄▄▄▃▃▃▃▃▃▃▂▂▂▂▂▂▂▂▂▁▁▁▁
wandb: 
wandb: Run summary:
wandb:     e_F1 59.41888
wandb:   e_loss 0.96747
wandb:     t_F1 74.85339
wandb:   t_loss 0.69063
wandb: 
wandb: Synced 4 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Synced firm-music-2: https://wandb.ai/yinanazhou/xl_512_bs_8_lr_1e06_es_10_lc_True_nr_True_sr_False_stem_False_lemma_False_repeat_2_fold_1/runs/ge0vo9j9
wandb: Find logs at: ./wandb/run-20220324_112236-ge0vo9j9/logs/debug.log
wandb: 

wandb: wandb version 0.12.11 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
2022-03-24 12:59:59.018023: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1
wandb: Tracking run with wandb version 0.12.5
wandb: Syncing run denim-dream-2
wandb: ⭐️ View project at https://wandb.ai/yinanazhou/xl_512_bs_8_lr_1e06_es_10_lc_True_nr_True_sr_False_stem_False_lemma_False_repeat_2_fold_2
wandb: 🚀 View run at https://wandb.ai/yinanazhou/xl_512_bs_8_lr_1e06_es_10_lc_True_nr_True_sr_False_stem_False_lemma_False_repeat_2_fold_2/runs/3oc3nxn9
wandb: Run data is saved locally in /project/6002780/yinan/Thesis_MER_Lyrics/lyric-emotion/wandb/run-20220324_125956-3oc3nxn9
wandb: Run `wandb offline` to turn off syncing.

Validation loss decreased (inf --> 1.443003).  Saving model ...
Validation loss decreased (1.443003 --> 1.426815).  Saving model ...
Validation loss decreased (1.426815 --> 1.415322).  Saving model ...
Validation loss decreased (1.415322 --> 1.406639).  Saving model ...
Validation loss decreased (1.406639 --> 1.399976).  Saving model ...
Validation loss decreased (1.399976 --> 1.394388).  Saving model ...
Validation loss decreased (1.394388 --> 1.389120).  Saving model ...
Validation loss decreased (1.389120 --> 1.384318).  Saving model ...
Validation loss decreased (1.384318 --> 1.379694).  Saving model ...
Validation loss decreased (1.379694 --> 1.375794).  Saving model ...
Validation loss decreased (1.375794 --> 1.372012).  Saving model ...
Validation loss decreased (1.372012 --> 1.367706).  Saving model ...
Validation loss decreased (1.367706 --> 1.363446).  Saving model ...
Validation loss decreased (1.363446 --> 1.359401).  Saving model ...
Validation loss decreased (1.359401 --> 1.354948).  Saving model ...
Validation loss decreased (1.354948 --> 1.350567).  Saving model ...
Validation loss decreased (1.350567 --> 1.346042).  Saving model ...
Validation loss decreased (1.346042 --> 1.340627).  Saving model ...
Validation loss decreased (1.340627 --> 1.335741).  Saving model ...
Validation loss decreased (1.335741 --> 1.330453).  Saving model ...
Validation loss decreased (1.330453 --> 1.325064).  Saving model ...
Validation loss decreased (1.325064 --> 1.319484).  Saving model ...
Validation loss decreased (1.319484 --> 1.314117).  Saving model ...
Validation loss decreased (1.314117 --> 1.308049).  Saving model ...
Validation loss decreased (1.308049 --> 1.302380).  Saving model ...
Validation loss decreased (1.302380 --> 1.295059).  Saving model ...
Validation loss decreased (1.295059 --> 1.288119).  Saving model ...
Validation loss decreased (1.288119 --> 1.280592).  Saving model ...
Validation loss decreased (1.280592 --> 1.272504).  Saving model ...
Validation loss decreased (1.272504 --> 1.265583).  Saving model ...
Validation loss decreased (1.265583 --> 1.258652).  Saving model ...
Validation loss decreased (1.258652 --> 1.251279).  Saving model ...
Validation loss decreased (1.251279 --> 1.243536).  Saving model ...
Validation loss decreased (1.243536 --> 1.235979).  Saving model ...
Validation loss decreased (1.235979 --> 1.229738).  Saving model ...
Validation loss decreased (1.229738 --> 1.224412).  Saving model ...
Validation loss decreased (1.224412 --> 1.217876).  Saving model ...
Validation loss decreased (1.217876 --> 1.210910).  Saving model ...
Validation loss decreased (1.210910 --> 1.204900).  Saving model ...
Validation loss decreased (1.204900 --> 1.198734).  Saving model ...
Validation loss decreased (1.198734 --> 1.192828).  Saving model ...
Validation loss decreased (1.192828 --> 1.187284).  Saving model ...
Validation loss decreased (1.187284 --> 1.183526).  Saving model ...
Validation loss decreased (1.183526 --> 1.178392).  Saving model ...
Validation loss decreased (1.178392 --> 1.172821).  Saving model ...
Validation loss decreased (1.172821 --> 1.169692).  Saving model ...
Validation loss decreased (1.169692 --> 1.165973).  Saving model ...
Validation loss decreased (1.165973 --> 1.161917).  Saving model ...
Validation loss decreased (1.161917 --> 1.155946).  Saving model ...
Validation loss decreased (1.155946 --> 1.151413).  Saving model ...
Validation loss decreased (1.151413 --> 1.142954).  Saving model ...
Validation loss decreased (1.142954 --> 1.137990).  Saving model ...
Validation loss decreased (1.137990 --> 1.133631).  Saving model ...
Validation loss decreased (1.133631 --> 1.127929).  Saving model ...
Validation loss decreased (1.127929 --> 1.124338).  Saving model ...
Validation loss decreased (1.124338 --> 1.119970).  Saving model ...
Validation loss decreased (1.119970 --> 1.114164).  Saving model ...
Validation loss decreased (1.114164 --> 1.107712).  Saving model ...
Validation loss decreased (1.107712 --> 1.101596).  Saving model ...
Validation loss decreased (1.101596 --> 1.099415).  Saving model ...
Validation loss decreased (1.099415 --> 1.094883).  Saving model ...
Validation loss decreased (1.094883 --> 1.092349).  Saving model ...
Validation loss decreased (1.092349 --> 1.087893).  Saving model ...
Validation loss decreased (1.087893 --> 1.084081).  Saving model ...
Validation loss decreased (1.084081 --> 1.080424).  Saving model ...
Validation loss decreased (1.080424 --> 1.075120).  Saving model ...
Validation loss decreased (1.075120 --> 1.072074).  Saving model ...
Validation loss decreased (1.072074 --> 1.067835).  Saving model ...
Validation loss decreased (1.067835 --> 1.061920).  Saving model ...
Validation loss decreased (1.061920 --> 1.058214).  Saving model ...
Validation loss decreased (1.058214 --> 1.056714).  Saving model ...
Validation loss decreased (1.056714 --> 1.053011).  Saving model ...
Validation loss decreased (1.053011 --> 1.049836).  Saving model ...
Validation loss decreased (1.049836 --> 1.047500).  Saving model ...
Validation loss decreased (1.047500 --> 1.040690).  Saving model ...
Validation loss decreased (1.040690 --> 1.038420).  Saving model ...
Validation loss decreased (1.038420 --> 1.035128).  Saving model ...
Validation loss decreased (1.035128 --> 1.032680).  Saving model ...
Validation loss decreased (1.032680 --> 1.029908).  Saving model ...
Validation loss decreased (1.029908 --> 1.025621).  Saving model ...
Validation loss decreased (1.025621 --> 1.023076).  Saving model ...
Validation loss decreased (1.023076 --> 1.020957).  Saving model ...
Validation loss decreased (1.020957 --> 1.016773).  Saving model ...
Validation loss decreased (1.016773 --> 1.013990).  Saving model ...
Validation loss decreased (1.013990 --> 1.011335).  Saving model ...
Validation loss decreased (1.011335 --> 1.008189).  Saving model ...
Validation loss decreased (1.008189 --> 1.004962).  Saving model ...
Validation loss decreased (1.004962 --> 1.000965).  Saving model ...
Validation loss decreased (1.000965 --> 0.997368).  Saving model ...
Validation loss decreased (0.997368 --> 0.995162).  Saving model ...
Validation loss decreased (0.995162 --> 0.993606).  Saving model ...
Validation loss decreased (0.993606 --> 0.992992).  Saving model ...
Validation loss decreased (0.992992 --> 0.990274).  Saving model ...
Validation loss decreased (0.990274 --> 0.988772).  Saving model ...
Validation loss decreased (0.988772 --> 0.985929).  Saving model ...
Validation loss decreased (0.985929 --> 0.983533).  Saving model ...
Validation loss decreased (0.983533 --> 0.979516).  Saving model ...
EarlyStopping counter: 1 out of 10.0
Validation loss decreased (0.979516 --> 0.979392).  Saving model ...
Validation loss decreased (0.979392 --> 0.978831).  Saving model ...
Validation loss decreased (0.978831 --> 0.973923).  Saving model ...
Validation loss decreased (0.973923 --> 0.972415).  Saving model ...
Validation loss decreased (0.972415 --> 0.969043).  Saving model ...
Validation loss decreased (0.969043 --> 0.966694).  Saving model ...
Validation loss decreased (0.966694 --> 0.966297).  Saving model ...
Validation loss decreased (0.966297 --> 0.963983).  Saving model ...
Validation loss decreased (0.963983 --> 0.961580).  Saving model ...
Validation loss decreased (0.961580 --> 0.958915).  Saving model ...
EarlyStopping counter: 1 out of 10.0
EarlyStopping counter: 2 out of 10.0
EarlyStopping counter: 3 out of 10.0
Validation loss decreased (0.958915 --> 0.955443).  Saving model ...
Validation loss decreased (0.955443 --> 0.952204).  Saving model ...
Validation loss decreased (0.952204 --> 0.951392).  Saving model ...
EarlyStopping counter: 1 out of 10.0
Validation loss decreased (0.951392 --> 0.950921).  Saving model ...
Validation loss decreased (0.950921 --> 0.949640).  Saving model ...
Validation loss decreased (0.949640 --> 0.945725).  Saving model ...
EarlyStopping counter: 1 out of 10.0
EarlyStopping counter: 2 out of 10.0
Validation loss decreased (0.945725 --> 0.944396).  Saving model ...
Validation loss decreased (0.944396 --> 0.942777).  Saving model ...
Validation loss decreased (0.942777 --> 0.938289).  Saving model ...
EarlyStopping counter: 1 out of 10.0
EarlyStopping counter: 2 out of 10.0
Validation loss decreased (0.938289 --> 0.937901).  Saving model ...
Validation loss decreased (0.937901 --> 0.937829).  Saving model ...
Validation loss decreased (0.937829 --> 0.936705).  Saving model ...
Validation loss decreased (0.936705 --> 0.933593).  Saving model ...
Validation loss decreased (0.933593 --> 0.932387).  Saving model ...
EarlyStopping counter: 1 out of 10.0
EarlyStopping counter: 2 out of 10.0
EarlyStopping counter: 3 out of 10.0
EarlyStopping counter: 4 out of 10.0
EarlyStopping counter: 5 out of 10.0
Validation loss decreased (0.932387 --> 0.930182).  Saving model ...
Validation loss decreased (0.930182 --> 0.929386).  Saving model ...
Validation loss decreased (0.929386 --> 0.927360).  Saving model ...
EarlyStopping counter: 1 out of 10.0
EarlyStopping counter: 2 out of 10.0
EarlyStopping counter: 3 out of 10.0
EarlyStopping counter: 4 out of 10.0
EarlyStopping counter: 5 out of 10.0
EarlyStopping counter: 6 out of 10.0
EarlyStopping counter: 7 out of 10.0
Validation loss decreased (0.927360 --> 0.925167).  Saving model ...
EarlyStopping counter: 1 out of 10.0
EarlyStopping counter: 2 out of 10.0
EarlyStopping counter: 3 out of 10.0
EarlyStopping counter: 4 out of 10.0
EarlyStopping counter: 5 out of 10.0
EarlyStopping counter: 6 out of 10.0
EarlyStopping counter: 7 out of 10.0
EarlyStopping counter: 8 out of 10.0
EarlyStopping counter: 9 out of 10.0
EarlyStopping counter: 10 out of 10.0
/localscratch/yinan.29351698.0/env/lib/python3.7/site-packages/torch/nn/functional.py:1794: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.
  warnings.warn("nn.functional.tanh is deprecated. Use torch.tanh instead.")
wandb: Waiting for W&B process to finish, PID 105376... (success).
wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: \ 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: | 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: / 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb:                                                                                
wandb: Run history:
wandb:     e_F1 ▁▁▂▃▄▅▅▅▆▆▆▆▆▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇████████████
wandb:   e_loss ██▇▇▇▇▆▆▆▅▅▅▄▄▄▃▃▃▃▃▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:     t_F1 ▁▁▂▂▃▃▃▄▄▄▅▅▅▅▆▅▆▆▆▆▆▆▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇███
wandb:   t_loss ███▇▇▇▇▇▆▆▆▅▅▅▅▅▄▄▄▄▄▃▃▃▃▃▃▂▃▂▂▂▂▂▂▂▂▁▂▁
wandb: 
wandb: Run summary:
wandb:     e_F1 61.94347
wandb:   e_loss 0.92786
wandb:     t_F1 73.41956
wandb:   t_loss 0.6941
wandb: 
wandb: Synced 4 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Synced denim-dream-2: https://wandb.ai/yinanazhou/xl_512_bs_8_lr_1e06_es_10_lc_True_nr_True_sr_False_stem_False_lemma_False_repeat_2_fold_2/runs/3oc3nxn9
wandb: Find logs at: ./wandb/run-20220324_125956-3oc3nxn9/logs/debug.log
wandb: 

wandb: wandb version 0.12.11 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
2022-03-24 14:41:08.859032: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1
wandb: Tracking run with wandb version 0.12.5
wandb: Syncing run snowy-thunder-1
wandb: ⭐️ View project at https://wandb.ai/yinanazhou/xl_512_bs_8_lr_1e06_es_10_lc_True_nr_True_sr_False_stem_False_lemma_False_repeat_3_fold_1
wandb: 🚀 View run at https://wandb.ai/yinanazhou/xl_512_bs_8_lr_1e06_es_10_lc_True_nr_True_sr_False_stem_False_lemma_False_repeat_3_fold_1/runs/3pjuov1q
wandb: Run data is saved locally in /project/6002780/yinan/Thesis_MER_Lyrics/lyric-emotion/wandb/run-20220324_144103-3pjuov1q
wandb: Run `wandb offline` to turn off syncing.

Validation loss decreased (inf --> 1.423696).  Saving model ...
Validation loss decreased (1.423696 --> 1.407002).  Saving model ...
Validation loss decreased (1.407002 --> 1.394638).  Saving model ...
Validation loss decreased (1.394638 --> 1.385226).  Saving model ...
Validation loss decreased (1.385226 --> 1.378403).  Saving model ...
Validation loss decreased (1.378403 --> 1.372012).  Saving model ...
Validation loss decreased (1.372012 --> 1.366319).  Saving model ...
Validation loss decreased (1.366319 --> 1.361564).  Saving model ...
Validation loss decreased (1.361564 --> 1.357137).  Saving model ...
Validation loss decreased (1.357137 --> 1.353128).  Saving model ...
Validation loss decreased (1.353128 --> 1.349029).  Saving model ...
Validation loss decreased (1.349029 --> 1.345463).  Saving model ...
Validation loss decreased (1.345463 --> 1.341424).  Saving model ...
Validation loss decreased (1.341424 --> 1.337985).  Saving model ...
Validation loss decreased (1.337985 --> 1.333925).  Saving model ...
Validation loss decreased (1.333925 --> 1.330029).  Saving model ...
Validation loss decreased (1.330029 --> 1.325419).  Saving model ...
Validation loss decreased (1.325419 --> 1.321350).  Saving model ...
Validation loss decreased (1.321350 --> 1.317244).  Saving model ...
Validation loss decreased (1.317244 --> 1.313105).  Saving model ...
Validation loss decreased (1.313105 --> 1.308417).  Saving model ...
Validation loss decreased (1.308417 --> 1.303937).  Saving model ...
Validation loss decreased (1.303937 --> 1.298527).  Saving model ...
Validation loss decreased (1.298527 --> 1.293054).  Saving model ...
Validation loss decreased (1.293054 --> 1.288916).  Saving model ...
Validation loss decreased (1.288916 --> 1.283659).  Saving model ...
Validation loss decreased (1.283659 --> 1.277361).  Saving model ...
Validation loss decreased (1.277361 --> 1.270794).  Saving model ...
Validation loss decreased (1.270794 --> 1.265680).  Saving model ...
Validation loss decreased (1.265680 --> 1.259775).  Saving model ...
Validation loss decreased (1.259775 --> 1.252882).  Saving model ...
Validation loss decreased (1.252882 --> 1.245621).  Saving model ...
Validation loss decreased (1.245621 --> 1.239182).  Saving model ...
Validation loss decreased (1.239182 --> 1.233221).  Saving model ...
Validation loss decreased (1.233221 --> 1.229011).  Saving model ...
Validation loss decreased (1.229011 --> 1.222911).  Saving model ...
Validation loss decreased (1.222911 --> 1.217674).  Saving model ...
Validation loss decreased (1.217674 --> 1.212042).  Saving model ...
Validation loss decreased (1.212042 --> 1.205377).  Saving model ...
Validation loss decreased (1.205377 --> 1.198097).  Saving model ...
Validation loss decreased (1.198097 --> 1.195228).  Saving model ...
Validation loss decreased (1.195228 --> 1.192137).  Saving model ...
Validation loss decreased (1.192137 --> 1.187284).  Saving model ...
Validation loss decreased (1.187284 --> 1.182017).  Saving model ...
Validation loss decreased (1.182017 --> 1.180550).  Saving model ...
Validation loss decreased (1.180550 --> 1.176947).  Saving model ...
Validation loss decreased (1.176947 --> 1.170911).  Saving model ...
Validation loss decreased (1.170911 --> 1.165109).  Saving model ...
Validation loss decreased (1.165109 --> 1.160231).  Saving model ...
Validation loss decreased (1.160231 --> 1.157742).  Saving model ...
Validation loss decreased (1.157742 --> 1.151582).  Saving model ...
Validation loss decreased (1.151582 --> 1.149799).  Saving model ...
EarlyStopping counter: 1 out of 10.0
Validation loss decreased (1.149799 --> 1.145685).  Saving model ...
Validation loss decreased (1.145685 --> 1.141268).  Saving model ...
Validation loss decreased (1.141268 --> 1.137925).  Saving model ...
Validation loss decreased (1.137925 --> 1.136341).  Saving model ...
Validation loss decreased (1.136341 --> 1.133203).  Saving model ...
Validation loss decreased (1.133203 --> 1.131353).  Saving model ...
Validation loss decreased (1.131353 --> 1.129498).  Saving model ...
Validation loss decreased (1.129498 --> 1.125249).  Saving model ...
Validation loss decreased (1.125249 --> 1.124538).  Saving model ...
Validation loss decreased (1.124538 --> 1.120966).  Saving model ...
Validation loss decreased (1.120966 --> 1.114503).  Saving model ...
Validation loss decreased (1.114503 --> 1.108997).  Saving model ...
Validation loss decreased (1.108997 --> 1.106378).  Saving model ...
Validation loss decreased (1.106378 --> 1.102878).  Saving model ...
Validation loss decreased (1.102878 --> 1.100667).  Saving model ...
Validation loss decreased (1.100667 --> 1.098718).  Saving model ...
Validation loss decreased (1.098718 --> 1.096226).  Saving model ...
EarlyStopping counter: 1 out of 10.0
Validation loss decreased (1.096226 --> 1.094481).  Saving model ...
Validation loss decreased (1.094481 --> 1.091445).  Saving model ...
Validation loss decreased (1.091445 --> 1.088923).  Saving model ...
Validation loss decreased (1.088923 --> 1.087044).  Saving model ...
Validation loss decreased (1.087044 --> 1.080239).  Saving model ...
Validation loss decreased (1.080239 --> 1.078866).  Saving model ...
Validation loss decreased (1.078866 --> 1.077554).  Saving model ...
Validation loss decreased (1.077554 --> 1.075242).  Saving model ...
Validation loss decreased (1.075242 --> 1.071664).  Saving model ...
Validation loss decreased (1.071664 --> 1.067789).  Saving model ...
Validation loss decreased (1.067789 --> 1.065033).  Saving model ...
Validation loss decreased (1.065033 --> 1.060142).  Saving model ...
Validation loss decreased (1.060142 --> 1.059848).  Saving model ...
EarlyStopping counter: 1 out of 10.0
EarlyStopping counter: 2 out of 10.0
Validation loss decreased (1.059848 --> 1.057676).  Saving model ...
Validation loss decreased (1.057676 --> 1.054548).  Saving model ...
Validation loss decreased (1.054548 --> 1.051102).  Saving model ...
Validation loss decreased (1.051102 --> 1.050133).  Saving model ...
Validation loss decreased (1.050133 --> 1.045867).  Saving model ...
Validation loss decreased (1.045867 --> 1.041632).  Saving model ...
EarlyStopping counter: 1 out of 10.0
Validation loss decreased (1.041632 --> 1.040449).  Saving model ...
Validation loss decreased (1.040449 --> 1.034229).  Saving model ...
Validation loss decreased (1.034229 --> 1.033344).  Saving model ...
Validation loss decreased (1.033344 --> 1.029837).  Saving model ...
EarlyStopping counter: 1 out of 10.0
EarlyStopping counter: 2 out of 10.0
Validation loss decreased (1.029837 --> 1.028716).  Saving model ...
Validation loss decreased (1.028716 --> 1.023741).  Saving model ...
Validation loss decreased (1.023741 --> 1.022960).  Saving model ...
Validation loss decreased (1.022960 --> 1.021907).  Saving model ...
Validation loss decreased (1.021907 --> 1.020514).  Saving model ...
Validation loss decreased (1.020514 --> 1.019509).  Saving model ...
Validation loss decreased (1.019509 --> 1.017770).  Saving model ...
EarlyStopping counter: 1 out of 10.0
EarlyStopping counter: 2 out of 10.0
Validation loss decreased (1.017770 --> 1.015809).  Saving model ...
Validation loss decreased (1.015809 --> 1.014458).  Saving model ...
Validation loss decreased (1.014458 --> 1.012607).  Saving model ...
Validation loss decreased (1.012607 --> 1.006812).  Saving model ...
EarlyStopping counter: 1 out of 10.0
EarlyStopping counter: 2 out of 10.0
EarlyStopping counter: 3 out of 10.0
EarlyStopping counter: 4 out of 10.0
EarlyStopping counter: 5 out of 10.0
Validation loss decreased (1.006812 --> 1.006011).  Saving model ...
Validation loss decreased (1.006011 --> 1.002781).  Saving model ...
Validation loss decreased (1.002781 --> 1.001153).  Saving model ...
Validation loss decreased (1.001153 --> 0.998204).  Saving model ...
Validation loss decreased (0.998204 --> 0.994153).  Saving model ...
EarlyStopping counter: 1 out of 10.0
EarlyStopping counter: 2 out of 10.0
EarlyStopping counter: 3 out of 10.0
EarlyStopping counter: 4 out of 10.0
EarlyStopping counter: 5 out of 10.0
Validation loss decreased (0.994153 --> 0.992527).  Saving model ...
Validation loss decreased (0.992527 --> 0.992280).  Saving model ...
Validation loss decreased (0.992280 --> 0.991378).  Saving model ...
EarlyStopping counter: 1 out of 10.0
EarlyStopping counter: 2 out of 10.0
EarlyStopping counter: 3 out of 10.0
EarlyStopping counter: 4 out of 10.0
EarlyStopping counter: 5 out of 10.0
EarlyStopping counter: 6 out of 10.0
EarlyStopping counter: 7 out of 10.0
EarlyStopping counter: 8 out of 10.0
EarlyStopping counter: 9 out of 10.0
EarlyStopping counter: 10 out of 10.0
/localscratch/yinan.29351698.0/env/lib/python3.7/site-packages/torch/nn/functional.py:1794: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.
  warnings.warn("nn.functional.tanh is deprecated. Use torch.tanh instead.")
wandb: Waiting for W&B process to finish, PID 111039... (success).
wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: \ 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: | 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: / 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb:                                                                                
wandb: Run history:
wandb:     e_F1 ▁▁▃▅▅▅▅▅▆▆▆▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇████████
wandb:   e_loss ██▇▇▇▇▆▆▆▅▅▄▄▄▄▄▃▃▃▃▃▂▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁
wandb:     t_F1 ▁▁▂▂▃▃▄▄▄▄▄▅▅▆▅▅▆▆▆▆▆▇▆▆▆▇▇▇▇▇█▇▇▇██▇███
wandb:   t_loss ███▇▇▇▇▇▆▆▆▅▅▅▅▅▄▄▄▄▄▃▄▃▃▃▃▃▃▂▂▂▂▂▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:     e_F1 57.74912
wandb:   e_loss 0.99402
wandb:     t_F1 71.87666
wandb:   t_loss 0.75711
wandb: 
wandb: Synced 4 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Synced snowy-thunder-1: https://wandb.ai/yinanazhou/xl_512_bs_8_lr_1e06_es_10_lc_True_nr_True_sr_False_stem_False_lemma_False_repeat_3_fold_1/runs/3pjuov1q
wandb: Find logs at: ./wandb/run-20220324_144103-3pjuov1q/logs/debug.log
wandb: 

wandb: wandb version 0.12.11 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
2022-03-24 16:13:34.238282: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1
wandb: Tracking run with wandb version 0.12.5
wandb: Syncing run resilient-smoke-1
wandb: ⭐️ View project at https://wandb.ai/yinanazhou/xl_512_bs_8_lr_1e06_es_10_lc_True_nr_True_sr_False_stem_False_lemma_False_repeat_3_fold_2
wandb: 🚀 View run at https://wandb.ai/yinanazhou/xl_512_bs_8_lr_1e06_es_10_lc_True_nr_True_sr_False_stem_False_lemma_False_repeat_3_fold_2/runs/yb6f85aw
wandb: Run data is saved locally in /project/6002780/yinan/Thesis_MER_Lyrics/lyric-emotion/wandb/run-20220324_161331-yb6f85aw
wandb: Run `wandb offline` to turn off syncing.

Validation loss decreased (inf --> 1.427794).  Saving model ...
Validation loss decreased (1.427794 --> 1.412182).  Saving model ...
Validation loss decreased (1.412182 --> 1.399612).  Saving model ...
Validation loss decreased (1.399612 --> 1.390347).  Saving model ...
Validation loss decreased (1.390347 --> 1.383570).  Saving model ...
Validation loss decreased (1.383570 --> 1.377339).  Saving model ...
Validation loss decreased (1.377339 --> 1.372374).  Saving model ...
Validation loss decreased (1.372374 --> 1.367952).  Saving model ...
Validation loss decreased (1.367952 --> 1.363394).  Saving model ...
Validation loss decreased (1.363394 --> 1.359002).  Saving model ...
Validation loss decreased (1.359002 --> 1.354712).  Saving model ...
Validation loss decreased (1.354712 --> 1.350916).  Saving model ...
Validation loss decreased (1.350916 --> 1.346885).  Saving model ...
Validation loss decreased (1.346885 --> 1.342506).  Saving model ...
Validation loss decreased (1.342506 --> 1.337748).  Saving model ...
Validation loss decreased (1.337748 --> 1.333062).  Saving model ...
Validation loss decreased (1.333062 --> 1.327899).  Saving model ...
Validation loss decreased (1.327899 --> 1.322950).  Saving model ...
Validation loss decreased (1.322950 --> 1.317617).  Saving model ...
Validation loss decreased (1.317617 --> 1.312046).  Saving model ...
Validation loss decreased (1.312046 --> 1.306195).  Saving model ...
Validation loss decreased (1.306195 --> 1.300060).  Saving model ...
Validation loss decreased (1.300060 --> 1.293203).  Saving model ...
Validation loss decreased (1.293203 --> 1.286015).  Saving model ...
Validation loss decreased (1.286015 --> 1.279412).  Saving model ...
Validation loss decreased (1.279412 --> 1.272511).  Saving model ...
Validation loss decreased (1.272511 --> 1.265288).  Saving model ...
Validation loss decreased (1.265288 --> 1.258014).  Saving model ...
Validation loss decreased (1.258014 --> 1.250625).  Saving model ...
Validation loss decreased (1.250625 --> 1.241371).  Saving model ...
Validation loss decreased (1.241371 --> 1.231788).  Saving model ...
Validation loss decreased (1.231788 --> 1.223711).  Saving model ...
Validation loss decreased (1.223711 --> 1.214805).  Saving model ...
Validation loss decreased (1.214805 --> 1.206198).  Saving model ...
Validation loss decreased (1.206198 --> 1.198597).  Saving model ...
Validation loss decreased (1.198597 --> 1.189685).  Saving model ...
Validation loss decreased (1.189685 --> 1.180419).  Saving model ...
Validation loss decreased (1.180419 --> 1.175156).  Saving model ...
Validation loss decreased (1.175156 --> 1.166733).  Saving model ...
Validation loss decreased (1.166733 --> 1.158889).  Saving model ...
Validation loss decreased (1.158889 --> 1.153628).  Saving model ...
Validation loss decreased (1.153628 --> 1.146924).  Saving model ...
Validation loss decreased (1.146924 --> 1.141890).  Saving model ...
Validation loss decreased (1.141890 --> 1.136174).  Saving model ...
Validation loss decreased (1.136174 --> 1.129391).  Saving model ...
Validation loss decreased (1.129391 --> 1.123117).  Saving model ...
Validation loss decreased (1.123117 --> 1.117586).  Saving model ...
Validation loss decreased (1.117586 --> 1.111788).  Saving model ...
Validation loss decreased (1.111788 --> 1.107702).  Saving model ...
Validation loss decreased (1.107702 --> 1.104251).  Saving model ...
Validation loss decreased (1.104251 --> 1.098006).  Saving model ...
Validation loss decreased (1.098006 --> 1.092297).  Saving model ...
Validation loss decreased (1.092297 --> 1.088029).  Saving model ...
Validation loss decreased (1.088029 --> 1.084410).  Saving model ...
Validation loss decreased (1.084410 --> 1.078383).  Saving model ...
Validation loss decreased (1.078383 --> 1.074402).  Saving model ...
Validation loss decreased (1.074402 --> 1.069074).  Saving model ...
Validation loss decreased (1.069074 --> 1.064827).  Saving model ...
Validation loss decreased (1.064827 --> 1.061870).  Saving model ...
Validation loss decreased (1.061870 --> 1.058756).  Saving model ...
Validation loss decreased (1.058756 --> 1.056865).  Saving model ...
Validation loss decreased (1.056865 --> 1.052857).  Saving model ...
Validation loss decreased (1.052857 --> 1.047785).  Saving model ...
Validation loss decreased (1.047785 --> 1.043072).  Saving model ...
Validation loss decreased (1.043072 --> 1.039714).  Saving model ...
Validation loss decreased (1.039714 --> 1.036518).  Saving model ...
Validation loss decreased (1.036518 --> 1.033206).  Saving model ...
Validation loss decreased (1.033206 --> 1.029017).  Saving model ...
Validation loss decreased (1.029017 --> 1.026139).  Saving model ...
Validation loss decreased (1.026139 --> 1.022537).  Saving model ...
Validation loss decreased (1.022537 --> 1.019844).  Saving model ...
Validation loss decreased (1.019844 --> 1.017833).  Saving model ...
Validation loss decreased (1.017833 --> 1.013481).  Saving model ...
Validation loss decreased (1.013481 --> 1.010635).  Saving model ...
Validation loss decreased (1.010635 --> 1.009312).  Saving model ...
Validation loss decreased (1.009312 --> 1.006130).  Saving model ...
Validation loss decreased (1.006130 --> 1.004189).  Saving model ...
Validation loss decreased (1.004189 --> 1.000726).  Saving model ...
Validation loss decreased (1.000726 --> 0.997146).  Saving model ...
Validation loss decreased (0.997146 --> 0.993710).  Saving model ...
Validation loss decreased (0.993710 --> 0.991510).  Saving model ...
Validation loss decreased (0.991510 --> 0.990101).  Saving model ...
Validation loss decreased (0.990101 --> 0.985728).  Saving model ...
Validation loss decreased (0.985728 --> 0.984383).  Saving model ...
Validation loss decreased (0.984383 --> 0.983237).  Saving model ...
Validation loss decreased (0.983237 --> 0.980240).  Saving model ...
Validation loss decreased (0.980240 --> 0.977184).  Saving model ...
Validation loss decreased (0.977184 --> 0.974551).  Saving model ...
Validation loss decreased (0.974551 --> 0.972308).  Saving model ...
Validation loss decreased (0.972308 --> 0.969466).  Saving model ...
Validation loss decreased (0.969466 --> 0.966084).  Saving model ...
Validation loss decreased (0.966084 --> 0.964657).  Saving model ...
Validation loss decreased (0.964657 --> 0.963375).  Saving model ...
Validation loss decreased (0.963375 --> 0.961328).  Saving model ...
Validation loss decreased (0.961328 --> 0.958523).  Saving model ...
Validation loss decreased (0.958523 --> 0.956725).  Saving model ...
Validation loss decreased (0.956725 --> 0.953515).  Saving model ...
Validation loss decreased (0.953515 --> 0.951825).  Saving model ...
Validation loss decreased (0.951825 --> 0.950094).  Saving model ...
Validation loss decreased (0.950094 --> 0.948881).  Saving model ...
Validation loss decreased (0.948881 --> 0.945738).  Saving model ...
Validation loss decreased (0.945738 --> 0.944846).  Saving model ...
Validation loss decreased (0.944846 --> 0.943076).  Saving model ...
Validation loss decreased (0.943076 --> 0.940215).  Saving model ...
Validation loss decreased (0.940215 --> 0.939560).  Saving model ...
Validation loss decreased (0.939560 --> 0.938197).  Saving model ...
Validation loss decreased (0.938197 --> 0.937946).  Saving model ...
Validation loss decreased (0.937946 --> 0.935910).  Saving model ...
Validation loss decreased (0.935910 --> 0.935313).  Saving model ...
Validation loss decreased (0.935313 --> 0.933567).  Saving model ...
Validation loss decreased (0.933567 --> 0.931567).  Saving model ...
Validation loss decreased (0.931567 --> 0.929603).  Saving model ...
Validation loss decreased (0.929603 --> 0.928850).  Saving model ...
Validation loss decreased (0.928850 --> 0.928174).  Saving model ...
Validation loss decreased (0.928174 --> 0.926843).  Saving model ...
Validation loss decreased (0.926843 --> 0.925630).  Saving model ...
EarlyStopping counter: 1 out of 10.0
Validation loss decreased (0.925630 --> 0.925447).  Saving model ...
Validation loss decreased (0.925447 --> 0.923879).  Saving model ...
Validation loss decreased (0.923879 --> 0.922522).  Saving model ...
Validation loss decreased (0.922522 --> 0.920897).  Saving model ...
Validation loss decreased (0.920897 --> 0.919902).  Saving model ...
Validation loss decreased (0.919902 --> 0.919854).  Saving model ...
Validation loss decreased (0.919854 --> 0.918400).  Saving model ...
Validation loss decreased (0.918400 --> 0.917382).  Saving model ...
Validation loss decreased (0.917382 --> 0.916916).  Saving model ...
Validation loss decreased (0.916916 --> 0.916556).  Saving model ...
Validation loss decreased (0.916556 --> 0.915079).  Saving model ...
Validation loss decreased (0.915079 --> 0.914588).  Saving model ...
EarlyStopping counter: 1 out of 10.0
EarlyStopping counter: 2 out of 10.0
Validation loss decreased (0.914588 --> 0.912717).  Saving model ...
Validation loss decreased (0.912717 --> 0.912609).  Saving model ...
Validation loss decreased (0.912609 --> 0.910337).  Saving model ...
Validation loss decreased (0.910337 --> 0.909442).  Saving model ...
Validation loss decreased (0.909442 --> 0.909136).  Saving model ...
Validation loss decreased (0.909136 --> 0.907633).  Saving model ...
Validation loss decreased (0.907633 --> 0.907383).  Saving model ...
Validation loss decreased (0.907383 --> 0.906335).  Saving model ...
Validation loss decreased (0.906335 --> 0.905616).  Saving model ...
EarlyStopping counter: 1 out of 10.0
Validation loss decreased (0.905616 --> 0.904399).  Saving model ...
Validation loss decreased (0.904399 --> 0.903759).  Saving model ...
EarlyStopping counter: 1 out of 10.0
EarlyStopping counter: 2 out of 10.0
EarlyStopping counter: 3 out of 10.0
EarlyStopping counter: 4 out of 10.0
EarlyStopping counter: 5 out of 10.0
EarlyStopping counter: 6 out of 10.0
EarlyStopping counter: 7 out of 10.0
EarlyStopping counter: 8 out of 10.0
EarlyStopping counter: 9 out of 10.0
EarlyStopping counter: 10 out of 10.0
/localscratch/yinan.29351698.0/env/lib/python3.7/site-packages/torch/nn/functional.py:1794: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.
  warnings.warn("nn.functional.tanh is deprecated. Use torch.tanh instead.")
wandb: Waiting for W&B process to finish, PID 115974... (success).
wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: \ 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: | 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: / 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: \ 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: | 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: / 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: \ 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: | 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: / 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb:                                                                                
wandb: Run history:
wandb:     e_F1 ▁▁▃▄▅▅▅▆▆▆▇▇▇▇▇▇▇▇▇▇▇▇▇▇████████████████
wandb:   e_loss ██▇▇▇▇▆▆▅▅▅▄▄▄▃▃▃▃▃▂▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:     t_F1 ▁▂▂▃▃▄▄▄▅▅▅▅▅▆▅▆▆▆▆▇▇▆▆▇▇▇▇▇▇███▇▇██████
wandb:   t_loss ███▇▇▇▇▆▆▆▆▅▅▅▅▄▄▄▄▄▃▃▃▃▃▃▂▃▂▂▂▂▂▂▂▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:     e_F1 64.32533
wandb:   e_loss 0.90415
wandb:     t_F1 71.04576
wandb:   t_loss 0.73138
wandb: 
wandb: Synced 4 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Synced resilient-smoke-1: https://wandb.ai/yinanazhou/xl_512_bs_8_lr_1e06_es_10_lc_True_nr_True_sr_False_stem_False_lemma_False_repeat_3_fold_2/runs/yb6f85aw
wandb: Find logs at: ./wandb/run-20220324_161331-yb6f85aw/logs/debug.log
wandb: 

wandb: wandb version 0.12.11 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
2022-03-24 17:53:02.784620: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1
wandb: Tracking run with wandb version 0.12.5
wandb: Syncing run electric-sea-1
wandb: ⭐️ View project at https://wandb.ai/yinanazhou/xl_512_bs_8_lr_1e06_es_10_lc_True_nr_True_sr_False_stem_False_lemma_False_repeat_4_fold_1
wandb: 🚀 View run at https://wandb.ai/yinanazhou/xl_512_bs_8_lr_1e06_es_10_lc_True_nr_True_sr_False_stem_False_lemma_False_repeat_4_fold_1/runs/2j3v30e9
wandb: Run data is saved locally in /project/6002780/yinan/Thesis_MER_Lyrics/lyric-emotion/wandb/run-20220324_175300-2j3v30e9
wandb: Run `wandb offline` to turn off syncing.

Validation loss decreased (inf --> 1.560270).  Saving model ...
Validation loss decreased (1.560270 --> 1.523084).  Saving model ...
Validation loss decreased (1.523084 --> 1.491300).  Saving model ...
Validation loss decreased (1.491300 --> 1.461749).  Saving model ...
Validation loss decreased (1.461749 --> 1.436700).  Saving model ...
Validation loss decreased (1.436700 --> 1.414248).  Saving model ...
Validation loss decreased (1.414248 --> 1.394981).  Saving model ...
Validation loss decreased (1.394981 --> 1.379965).  Saving model ...
Validation loss decreased (1.379965 --> 1.367471).  Saving model ...
Validation loss decreased (1.367471 --> 1.358751).  Saving model ...
Validation loss decreased (1.358751 --> 1.350430).  Saving model ...
Validation loss decreased (1.350430 --> 1.342915).  Saving model ...
Validation loss decreased (1.342915 --> 1.335812).  Saving model ...
Validation loss decreased (1.335812 --> 1.329486).  Saving model ...
Validation loss decreased (1.329486 --> 1.323967).  Saving model ...
Validation loss decreased (1.323967 --> 1.317991).  Saving model ...
Validation loss decreased (1.317991 --> 1.311999).  Saving model ...
Validation loss decreased (1.311999 --> 1.306299).  Saving model ...
Validation loss decreased (1.306299 --> 1.300806).  Saving model ...
Validation loss decreased (1.300806 --> 1.295117).  Saving model ...
Validation loss decreased (1.295117 --> 1.289651).  Saving model ...
Validation loss decreased (1.289651 --> 1.283659).  Saving model ...
Validation loss decreased (1.283659 --> 1.277978).  Saving model ...
Validation loss decreased (1.277978 --> 1.272645).  Saving model ...
Validation loss decreased (1.272645 --> 1.266669).  Saving model ...
Validation loss decreased (1.266669 --> 1.260819).  Saving model ...
Validation loss decreased (1.260819 --> 1.254489).  Saving model ...
Validation loss decreased (1.254489 --> 1.248591).  Saving model ...
Validation loss decreased (1.248591 --> 1.242819).  Saving model ...
Validation loss decreased (1.242819 --> 1.237234).  Saving model ...
Validation loss decreased (1.237234 --> 1.230789).  Saving model ...
Validation loss decreased (1.230789 --> 1.225715).  Saving model ...
Validation loss decreased (1.225715 --> 1.219892).  Saving model ...
Validation loss decreased (1.219892 --> 1.214303).  Saving model ...
Validation loss decreased (1.214303 --> 1.208118).  Saving model ...
Validation loss decreased (1.208118 --> 1.202129).  Saving model ...
Validation loss decreased (1.202129 --> 1.196427).  Saving model ...
Validation loss decreased (1.196427 --> 1.191000).  Saving model ...
Validation loss decreased (1.191000 --> 1.184839).  Saving model ...
Validation loss decreased (1.184839 --> 1.180076).  Saving model ...
Validation loss decreased (1.180076 --> 1.175939).  Saving model ...
Validation loss decreased (1.175939 --> 1.171309).  Saving model ...
Validation loss decreased (1.171309 --> 1.168610).  Saving model ...
Validation loss decreased (1.168610 --> 1.163260).  Saving model ...
Validation loss decreased (1.163260 --> 1.157766).  Saving model ...
Validation loss decreased (1.157766 --> 1.153167).  Saving model ...
Validation loss decreased (1.153167 --> 1.147867).  Saving model ...
Validation loss decreased (1.147867 --> 1.142914).  Saving model ...
Validation loss decreased (1.142914 --> 1.138351).  Saving model ...
Validation loss decreased (1.138351 --> 1.135496).  Saving model ...
Validation loss decreased (1.135496 --> 1.131815).  Saving model ...
Validation loss decreased (1.131815 --> 1.125820).  Saving model ...
Validation loss decreased (1.125820 --> 1.122199).  Saving model ...
Validation loss decreased (1.122199 --> 1.118253).  Saving model ...
Validation loss decreased (1.118253 --> 1.115841).  Saving model ...
Validation loss decreased (1.115841 --> 1.110057).  Saving model ...
Validation loss decreased (1.110057 --> 1.106352).  Saving model ...
Validation loss decreased (1.106352 --> 1.102596).  Saving model ...
Validation loss decreased (1.102596 --> 1.098981).  Saving model ...
Validation loss decreased (1.098981 --> 1.094983).  Saving model ...
Validation loss decreased (1.094983 --> 1.092180).  Saving model ...
Validation loss decreased (1.092180 --> 1.088232).  Saving model ...
Validation loss decreased (1.088232 --> 1.085213).  Saving model ...
Validation loss decreased (1.085213 --> 1.082139).  Saving model ...
Validation loss decreased (1.082139 --> 1.078126).  Saving model ...
Validation loss decreased (1.078126 --> 1.075771).  Saving model ...
Validation loss decreased (1.075771 --> 1.073194).  Saving model ...
Validation loss decreased (1.073194 --> 1.071336).  Saving model ...
Validation loss decreased (1.071336 --> 1.066784).  Saving model ...
Validation loss decreased (1.066784 --> 1.065130).  Saving model ...
Validation loss decreased (1.065130 --> 1.061926).  Saving model ...
Validation loss decreased (1.061926 --> 1.059436).  Saving model ...
Validation loss decreased (1.059436 --> 1.056157).  Saving model ...
Validation loss decreased (1.056157 --> 1.053623).  Saving model ...
Validation loss decreased (1.053623 --> 1.050823).  Saving model ...
Validation loss decreased (1.050823 --> 1.048762).  Saving model ...
Validation loss decreased (1.048762 --> 1.046777).  Saving model ...
Validation loss decreased (1.046777 --> 1.044421).  Saving model ...
Validation loss decreased (1.044421 --> 1.042202).  Saving model ...
Validation loss decreased (1.042202 --> 1.040561).  Saving model ...
Validation loss decreased (1.040561 --> 1.038233).  Saving model ...
Validation loss decreased (1.038233 --> 1.037521).  Saving model ...
Validation loss decreased (1.037521 --> 1.036222).  Saving model ...
Validation loss decreased (1.036222 --> 1.033041).  Saving model ...
Validation loss decreased (1.033041 --> 1.031336).  Saving model ...
Validation loss decreased (1.031336 --> 1.030506).  Saving model ...
Validation loss decreased (1.030506 --> 1.029152).  Saving model ...
Validation loss decreased (1.029152 --> 1.026330).  Saving model ...
Validation loss decreased (1.026330 --> 1.024136).  Saving model ...
Validation loss decreased (1.024136 --> 1.021264).  Saving model ...
Validation loss decreased (1.021264 --> 1.018845).  Saving model ...
Validation loss decreased (1.018845 --> 1.018441).  Saving model ...
Validation loss decreased (1.018441 --> 1.015522).  Saving model ...
Validation loss decreased (1.015522 --> 1.013651).  Saving model ...
EarlyStopping counter: 1 out of 10.0
EarlyStopping counter: 2 out of 10.0
Validation loss decreased (1.013651 --> 1.012255).  Saving model ...
Validation loss decreased (1.012255 --> 1.011337).  Saving model ...
Validation loss decreased (1.011337 --> 1.008489).  Saving model ...
Validation loss decreased (1.008489 --> 1.007258).  Saving model ...
Validation loss decreased (1.007258 --> 1.005691).  Saving model ...
Validation loss decreased (1.005691 --> 1.004963).  Saving model ...
Validation loss decreased (1.004963 --> 1.003370).  Saving model ...
Validation loss decreased (1.003370 --> 1.001229).  Saving model ...
Validation loss decreased (1.001229 --> 0.999802).  Saving model ...
Validation loss decreased (0.999802 --> 0.997228).  Saving model ...
Validation loss decreased (0.997228 --> 0.996432).  Saving model ...
Validation loss decreased (0.996432 --> 0.995094).  Saving model ...
Validation loss decreased (0.995094 --> 0.993900).  Saving model ...
Validation loss decreased (0.993900 --> 0.993369).  Saving model ...
Validation loss decreased (0.993369 --> 0.991723).  Saving model ...
Validation loss decreased (0.991723 --> 0.990951).  Saving model ...
Validation loss decreased (0.990951 --> 0.989968).  Saving model ...
Validation loss decreased (0.989968 --> 0.987975).  Saving model ...
Validation loss decreased (0.987975 --> 0.987664).  Saving model ...
Validation loss decreased (0.987664 --> 0.986420).  Saving model ...
Validation loss decreased (0.986420 --> 0.985288).  Saving model ...
EarlyStopping counter: 1 out of 10.0
Validation loss decreased (0.985288 --> 0.984509).  Saving model ...
Validation loss decreased (0.984509 --> 0.981898).  Saving model ...
Validation loss decreased (0.981898 --> 0.981442).  Saving model ...
Validation loss decreased (0.981442 --> 0.981106).  Saving model ...
Validation loss decreased (0.981106 --> 0.980879).  Saving model ...
EarlyStopping counter: 1 out of 10.0
Validation loss decreased (0.980879 --> 0.979310).  Saving model ...
Validation loss decreased (0.979310 --> 0.976456).  Saving model ...
Validation loss decreased (0.976456 --> 0.974712).  Saving model ...
Validation loss decreased (0.974712 --> 0.973610).  Saving model ...
EarlyStopping counter: 1 out of 10.0
EarlyStopping counter: 2 out of 10.0
EarlyStopping counter: 3 out of 10.0
Validation loss decreased (0.973610 --> 0.973020).  Saving model ...
Validation loss decreased (0.973020 --> 0.971320).  Saving model ...
EarlyStopping counter: 1 out of 10.0
EarlyStopping counter: 2 out of 10.0
EarlyStopping counter: 3 out of 10.0
EarlyStopping counter: 4 out of 10.0
EarlyStopping counter: 5 out of 10.0
Validation loss decreased (0.971320 --> 0.971040).  Saving model ...
Validation loss decreased (0.971040 --> 0.968515).  Saving model ...
Validation loss decreased (0.968515 --> 0.967956).  Saving model ...
EarlyStopping counter: 1 out of 10.0
Validation loss decreased (0.967956 --> 0.964652).  Saving model ...
EarlyStopping counter: 1 out of 10.0
EarlyStopping counter: 2 out of 10.0
EarlyStopping counter: 3 out of 10.0
Validation loss decreased (0.964652 --> 0.964135).  Saving model ...
Validation loss decreased (0.964135 --> 0.963925).  Saving model ...
Validation loss decreased (0.963925 --> 0.963402).  Saving model ...
Validation loss decreased (0.963402 --> 0.963354).  Saving model ...
EarlyStopping counter: 1 out of 10.0
EarlyStopping counter: 2 out of 10.0
EarlyStopping counter: 3 out of 10.0
EarlyStopping counter: 4 out of 10.0
EarlyStopping counter: 5 out of 10.0
EarlyStopping counter: 6 out of 10.0
EarlyStopping counter: 7 out of 10.0
EarlyStopping counter: 8 out of 10.0
EarlyStopping counter: 9 out of 10.0
EarlyStopping counter: 10 out of 10.0
/localscratch/yinan.29351698.0/env/lib/python3.7/site-packages/torch/nn/functional.py:1794: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.
  warnings.warn("nn.functional.tanh is deprecated. Use torch.tanh instead.")
wandb: Waiting for W&B process to finish, PID 121277... (success).
wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: \ 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: | 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: / 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: \ 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: | 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: / 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: \ 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: | 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: / 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb:                                                                                
wandb: Run history:
wandb:     e_F1 ▁▂▃▅▅▅▆▆▆▆▆▆▆▇▇▇▇▇▇▇████████████████████
wandb:   e_loss █▇▆▆▅▅▅▄▄▄▄▃▃▃▃▃▂▂▂▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:     t_F1 ▁▁▁▂▃▂▃▃▄▄▅▄▅▅▅▅▅▆▆▆▆▆▇▆▆▆▇▇▇▇▇▇▇▇▇█▇▇▇▇
wandb:   t_loss █▇▇▇▆▆▆▆▅▅▅▅▅▄▄▄▄▄▄▃▃▃▃▃▃▃▂▂▂▂▂▂▂▂▂▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:     e_F1 58.25824
wandb:   e_loss 0.96586
wandb:     t_F1 72.87318
wandb:   t_loss 0.70224
wandb: 
wandb: Synced 4 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Synced electric-sea-1: https://wandb.ai/yinanazhou/xl_512_bs_8_lr_1e06_es_10_lc_True_nr_True_sr_False_stem_False_lemma_False_repeat_4_fold_1/runs/2j3v30e9
wandb: Find logs at: ./wandb/run-20220324_175300-2j3v30e9/logs/debug.log
wandb: 

wandb: wandb version 0.12.11 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
2022-03-24 19:38:24.666981: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1
wandb: Tracking run with wandb version 0.12.5
wandb: Syncing run charmed-forest-1
wandb: ⭐️ View project at https://wandb.ai/yinanazhou/xl_512_bs_8_lr_1e06_es_10_lc_True_nr_True_sr_False_stem_False_lemma_False_repeat_4_fold_2
wandb: 🚀 View run at https://wandb.ai/yinanazhou/xl_512_bs_8_lr_1e06_es_10_lc_True_nr_True_sr_False_stem_False_lemma_False_repeat_4_fold_2/runs/11cjn4se
wandb: Run data is saved locally in /project/6002780/yinan/Thesis_MER_Lyrics/lyric-emotion/wandb/run-20220324_193822-11cjn4se
wandb: Run `wandb offline` to turn off syncing.

Validation loss decreased (inf --> 1.566208).  Saving model ...
Validation loss decreased (1.566208 --> 1.515098).  Saving model ...
Validation loss decreased (1.515098 --> 1.474472).  Saving model ...
Validation loss decreased (1.474472 --> 1.442845).  Saving model ...
Validation loss decreased (1.442845 --> 1.421301).  Saving model ...
Validation loss decreased (1.421301 --> 1.403707).  Saving model ...
Validation loss decreased (1.403707 --> 1.390584).  Saving model ...
Validation loss decreased (1.390584 --> 1.380500).  Saving model ...
Validation loss decreased (1.380500 --> 1.372400).  Saving model ...
Validation loss decreased (1.372400 --> 1.366075).  Saving model ...
Validation loss decreased (1.366075 --> 1.360622).  Saving model ...
Validation loss decreased (1.360622 --> 1.355359).  Saving model ...
Validation loss decreased (1.355359 --> 1.351284).  Saving model ...
Validation loss decreased (1.351284 --> 1.346746).  Saving model ...
Validation loss decreased (1.346746 --> 1.342584).  Saving model ...
Validation loss decreased (1.342584 --> 1.338607).  Saving model ...
Validation loss decreased (1.338607 --> 1.335190).  Saving model ...
Validation loss decreased (1.335190 --> 1.331113).  Saving model ...
Validation loss decreased (1.331113 --> 1.326902).  Saving model ...
Validation loss decreased (1.326902 --> 1.321527).  Saving model ...
Validation loss decreased (1.321527 --> 1.317051).  Saving model ...
Validation loss decreased (1.317051 --> 1.311710).  Saving model ...
Validation loss decreased (1.311710 --> 1.306761).  Saving model ...
Validation loss decreased (1.306761 --> 1.300976).  Saving model ...
Validation loss decreased (1.300976 --> 1.295505).  Saving model ...
Validation loss decreased (1.295505 --> 1.290267).  Saving model ...
Validation loss decreased (1.290267 --> 1.284825).  Saving model ...
Validation loss decreased (1.284825 --> 1.279129).  Saving model ...
Validation loss decreased (1.279129 --> 1.272069).  Saving model ...
Validation loss decreased (1.272069 --> 1.265014).  Saving model ...
Validation loss decreased (1.265014 --> 1.258244).  Saving model ...
Validation loss decreased (1.258244 --> 1.252943).  Saving model ...
Validation loss decreased (1.252943 --> 1.245991).  Saving model ...
Validation loss decreased (1.245991 --> 1.240095).  Saving model ...
Validation loss decreased (1.240095 --> 1.231400).  Saving model ...
Validation loss decreased (1.231400 --> 1.223014).  Saving model ...
Validation loss decreased (1.223014 --> 1.216139).  Saving model ...
Validation loss decreased (1.216139 --> 1.208994).  Saving model ...
Validation loss decreased (1.208994 --> 1.204082).  Saving model ...
Validation loss decreased (1.204082 --> 1.199144).  Saving model ...
Validation loss decreased (1.199144 --> 1.192710).  Saving model ...
Validation loss decreased (1.192710 --> 1.185685).  Saving model ...
Validation loss decreased (1.185685 --> 1.179941).  Saving model ...
Validation loss decreased (1.179941 --> 1.170532).  Saving model ...
Validation loss decreased (1.170532 --> 1.166639).  Saving model ...
Validation loss decreased (1.166639 --> 1.160092).  Saving model ...
Validation loss decreased (1.160092 --> 1.153454).  Saving model ...
Validation loss decreased (1.153454 --> 1.146822).  Saving model ...
Validation loss decreased (1.146822 --> 1.141739).  Saving model ...
Validation loss decreased (1.141739 --> 1.136554).  Saving model ...
Validation loss decreased (1.136554 --> 1.130772).  Saving model ...
Validation loss decreased (1.130772 --> 1.123923).  Saving model ...
Validation loss decreased (1.123923 --> 1.121065).  Saving model ...
Validation loss decreased (1.121065 --> 1.117150).  Saving model ...
Validation loss decreased (1.117150 --> 1.109835).  Saving model ...
Validation loss decreased (1.109835 --> 1.103327).  Saving model ...
Validation loss decreased (1.103327 --> 1.098196).  Saving model ...
Validation loss decreased (1.098196 --> 1.094042).  Saving model ...
Validation loss decreased (1.094042 --> 1.092559).  Saving model ...
Validation loss decreased (1.092559 --> 1.086035).  Saving model ...
Validation loss decreased (1.086035 --> 1.082673).  Saving model ...
Validation loss decreased (1.082673 --> 1.079442).  Saving model ...
Validation loss decreased (1.079442 --> 1.076724).  Saving model ...
Validation loss decreased (1.076724 --> 1.072815).  Saving model ...
Validation loss decreased (1.072815 --> 1.069481).  Saving model ...
Validation loss decreased (1.069481 --> 1.063125).  Saving model ...
Validation loss decreased (1.063125 --> 1.063101).  Saving model ...
Validation loss decreased (1.063101 --> 1.059975).  Saving model ...
Validation loss decreased (1.059975 --> 1.057797).  Saving model ...
Validation loss decreased (1.057797 --> 1.052142).  Saving model ...
Validation loss decreased (1.052142 --> 1.049634).  Saving model ...
Validation loss decreased (1.049634 --> 1.047904).  Saving model ...
Validation loss decreased (1.047904 --> 1.046178).  Saving model ...
Validation loss decreased (1.046178 --> 1.041582).  Saving model ...
Validation loss decreased (1.041582 --> 1.034479).  Saving model ...
Validation loss decreased (1.034479 --> 1.029677).  Saving model ...
Validation loss decreased (1.029677 --> 1.021975).  Saving model ...
EarlyStopping counter: 1 out of 10.0
EarlyStopping counter: 2 out of 10.0
EarlyStopping counter: 3 out of 10.0
Validation loss decreased (1.021975 --> 1.019304).  Saving model ...
Validation loss decreased (1.019304 --> 1.015320).  Saving model ...
Validation loss decreased (1.015320 --> 1.014941).  Saving model ...
Validation loss decreased (1.014941 --> 1.010213).  Saving model ...
Validation loss decreased (1.010213 --> 1.002074).  Saving model ...
EarlyStopping counter: 1 out of 10.0
EarlyStopping counter: 2 out of 10.0
Validation loss decreased (1.002074 --> 1.000367).  Saving model ...
Validation loss decreased (1.000367 --> 0.996242).  Saving model ...
Validation loss decreased (0.996242 --> 0.993602).  Saving model ...
Validation loss decreased (0.993602 --> 0.992160).  Saving model ...
Validation loss decreased (0.992160 --> 0.990493).  Saving model ...
EarlyStopping counter: 1 out of 10.0
Validation loss decreased (0.990493 --> 0.988200).  Saving model ...
Validation loss decreased (0.988200 --> 0.985205).  Saving model ...
Validation loss decreased (0.985205 --> 0.982172).  Saving model ...
Validation loss decreased (0.982172 --> 0.981162).  Saving model ...
Validation loss decreased (0.981162 --> 0.980896).  Saving model ...
Validation loss decreased (0.980896 --> 0.979411).  Saving model ...
Validation loss decreased (0.979411 --> 0.975743).  Saving model ...
Validation loss decreased (0.975743 --> 0.974814).  Saving model ...
EarlyStopping counter: 1 out of 10.0
EarlyStopping counter: 2 out of 10.0
Validation loss decreased (0.974814 --> 0.974730).  Saving model ...
Validation loss decreased (0.974730 --> 0.971785).  Saving model ...
EarlyStopping counter: 1 out of 10.0
Validation loss decreased (0.971785 --> 0.971094).  Saving model ...
Validation loss decreased (0.971094 --> 0.968967).  Saving model ...
EarlyStopping counter: 1 out of 10.0
EarlyStopping counter: 2 out of 10.0
EarlyStopping counter: 3 out of 10.0
Validation loss decreased (0.968967 --> 0.967148).  Saving model ...
Validation loss decreased (0.967148 --> 0.965524).  Saving model ...
Validation loss decreased (0.965524 --> 0.960387).  Saving model ...
EarlyStopping counter: 1 out of 10.0
EarlyStopping counter: 2 out of 10.0
Validation loss decreased (0.960387 --> 0.958093).  Saving model ...
Validation loss decreased (0.958093 --> 0.954900).  Saving model ...
EarlyStopping counter: 1 out of 10.0
EarlyStopping counter: 2 out of 10.0
EarlyStopping counter: 3 out of 10.0
EarlyStopping counter: 4 out of 10.0
EarlyStopping counter: 5 out of 10.0
Validation loss decreased (0.954900 --> 0.951141).  Saving model ...
EarlyStopping counter: 1 out of 10.0
Validation loss decreased (0.951141 --> 0.950181).  Saving model ...
EarlyStopping counter: 1 out of 10.0
EarlyStopping counter: 2 out of 10.0
EarlyStopping counter: 3 out of 10.0
EarlyStopping counter: 4 out of 10.0
EarlyStopping counter: 5 out of 10.0
EarlyStopping counter: 6 out of 10.0
EarlyStopping counter: 7 out of 10.0
Validation loss decreased (0.950181 --> 0.948185).  Saving model ...
Validation loss decreased (0.948185 --> 0.947503).  Saving model ...
EarlyStopping counter: 1 out of 10.0
Validation loss decreased (0.947503 --> 0.942225).  Saving model ...
EarlyStopping counter: 1 out of 10.0
EarlyStopping counter: 2 out of 10.0
EarlyStopping counter: 3 out of 10.0
EarlyStopping counter: 4 out of 10.0
EarlyStopping counter: 5 out of 10.0
EarlyStopping counter: 6 out of 10.0
EarlyStopping counter: 7 out of 10.0
EarlyStopping counter: 8 out of 10.0
EarlyStopping counter: 9 out of 10.0
EarlyStopping counter: 10 out of 10.0
/localscratch/yinan.29351698.0/env/lib/python3.7/site-packages/torch/nn/functional.py:1794: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.
  warnings.warn("nn.functional.tanh is deprecated. Use torch.tanh instead.")
wandb: Waiting for W&B process to finish, PID 126910... (success).
wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: \ 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: | 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: / 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: \ 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: | 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: / 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: \ 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: | 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: / 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: \ 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb:                                                                                
wandb: Run history:
wandb:     e_F1 ▁▁▂▃▄▄▅▅▅▆▆▆▇▇▇▇▇▇▇▇▇▇██████████████████
wandb:   e_loss █▇▆▆▆▆▅▅▅▅▄▄▄▃▃▃▃▃▂▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:     t_F1 ▁▁▂▂▃▄▄▄▄▄▅▅▆▆▆▆▆▆▆▇▇▆▇▇▇▇▇▇▇▇▇▇███▇████
wandb:   t_loss █▇▇▇▆▆▆▆▆▆▅▅▅▅▄▄▄▄▄▃▃▃▃▃▃▃▂▂▂▂▂▂▂▂▂▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:     e_F1 60.26721
wandb:   e_loss 0.94782
wandb:     t_F1 71.93505
wandb:   t_loss 0.75252
wandb: 
wandb: Synced 4 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Synced charmed-forest-1: https://wandb.ai/yinanazhou/xl_512_bs_8_lr_1e06_es_10_lc_True_nr_True_sr_False_stem_False_lemma_False_repeat_4_fold_2/runs/11cjn4se
wandb: Find logs at: ./wandb/run-20220324_193822-11cjn4se/logs/debug.log
wandb: 

wandb: wandb version 0.12.11 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
2022-03-24 21:14:47.910643: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1
wandb: Tracking run with wandb version 0.12.5
wandb: Syncing run smart-shadow-1
wandb: ⭐️ View project at https://wandb.ai/yinanazhou/xl_512_bs_8_lr_1e06_es_10_lc_True_nr_True_sr_False_stem_False_lemma_False_repeat_5_fold_1
wandb: 🚀 View run at https://wandb.ai/yinanazhou/xl_512_bs_8_lr_1e06_es_10_lc_True_nr_True_sr_False_stem_False_lemma_False_repeat_5_fold_1/runs/2r6qr4an
wandb: Run data is saved locally in /project/6002780/yinan/Thesis_MER_Lyrics/lyric-emotion/wandb/run-20220324_211445-2r6qr4an
wandb: Run `wandb offline` to turn off syncing.

Validation loss decreased (inf --> 1.407542).  Saving model ...
Validation loss decreased (1.407542 --> 1.396589).  Saving model ...
Validation loss decreased (1.396589 --> 1.388512).  Saving model ...
Validation loss decreased (1.388512 --> 1.381958).  Saving model ...
Validation loss decreased (1.381958 --> 1.376626).  Saving model ...
Validation loss decreased (1.376626 --> 1.372151).  Saving model ...
Validation loss decreased (1.372151 --> 1.368114).  Saving model ...
Validation loss decreased (1.368114 --> 1.364390).  Saving model ...
Validation loss decreased (1.364390 --> 1.360619).  Saving model ...
Validation loss decreased (1.360619 --> 1.357430).  Saving model ...
Validation loss decreased (1.357430 --> 1.353692).  Saving model ...
Validation loss decreased (1.353692 --> 1.350073).  Saving model ...
Validation loss decreased (1.350073 --> 1.347093).  Saving model ...
Validation loss decreased (1.347093 --> 1.343497).  Saving model ...
Validation loss decreased (1.343497 --> 1.340165).  Saving model ...
Validation loss decreased (1.340165 --> 1.336437).  Saving model ...
Validation loss decreased (1.336437 --> 1.332054).  Saving model ...
Validation loss decreased (1.332054 --> 1.327997).  Saving model ...
Validation loss decreased (1.327997 --> 1.323725).  Saving model ...
Validation loss decreased (1.323725 --> 1.319151).  Saving model ...
Validation loss decreased (1.319151 --> 1.314382).  Saving model ...
Validation loss decreased (1.314382 --> 1.309736).  Saving model ...
Validation loss decreased (1.309736 --> 1.304291).  Saving model ...
Validation loss decreased (1.304291 --> 1.299239).  Saving model ...
Validation loss decreased (1.299239 --> 1.293734).  Saving model ...
Validation loss decreased (1.293734 --> 1.287053).  Saving model ...
Validation loss decreased (1.287053 --> 1.281122).  Saving model ...
Validation loss decreased (1.281122 --> 1.273709).  Saving model ...
Validation loss decreased (1.273709 --> 1.267423).  Saving model ...
Validation loss decreased (1.267423 --> 1.260800).  Saving model ...
Validation loss decreased (1.260800 --> 1.253865).  Saving model ...
Validation loss decreased (1.253865 --> 1.246449).  Saving model ...
Validation loss decreased (1.246449 --> 1.239383).  Saving model ...
Validation loss decreased (1.239383 --> 1.231786).  Saving model ...
Validation loss decreased (1.231786 --> 1.224308).  Saving model ...
Validation loss decreased (1.224308 --> 1.217361).  Saving model ...
Validation loss decreased (1.217361 --> 1.212526).  Saving model ...
Validation loss decreased (1.212526 --> 1.205386).  Saving model ...
Validation loss decreased (1.205386 --> 1.196319).  Saving model ...
Validation loss decreased (1.196319 --> 1.189081).  Saving model ...
Validation loss decreased (1.189081 --> 1.182331).  Saving model ...
Validation loss decreased (1.182331 --> 1.174983).  Saving model ...
Validation loss decreased (1.174983 --> 1.168621).  Saving model ...
Validation loss decreased (1.168621 --> 1.163479).  Saving model ...
Validation loss decreased (1.163479 --> 1.157600).  Saving model ...
Validation loss decreased (1.157600 --> 1.152418).  Saving model ...
Validation loss decreased (1.152418 --> 1.147315).  Saving model ...
Validation loss decreased (1.147315 --> 1.141836).  Saving model ...
Validation loss decreased (1.141836 --> 1.136797).  Saving model ...
Validation loss decreased (1.136797 --> 1.131653).  Saving model ...
Validation loss decreased (1.131653 --> 1.127501).  Saving model ...
Validation loss decreased (1.127501 --> 1.123861).  Saving model ...
Validation loss decreased (1.123861 --> 1.118320).  Saving model ...
Validation loss decreased (1.118320 --> 1.113910).  Saving model ...
Validation loss decreased (1.113910 --> 1.110596).  Saving model ...
Validation loss decreased (1.110596 --> 1.105407).  Saving model ...
Validation loss decreased (1.105407 --> 1.101025).  Saving model ...
Validation loss decreased (1.101025 --> 1.097401).  Saving model ...
Validation loss decreased (1.097401 --> 1.094568).  Saving model ...
Validation loss decreased (1.094568 --> 1.093505).  Saving model ...
Validation loss decreased (1.093505 --> 1.091335).  Saving model ...
Validation loss decreased (1.091335 --> 1.085281).  Saving model ...
Validation loss decreased (1.085281 --> 1.079491).  Saving model ...
Validation loss decreased (1.079491 --> 1.076817).  Saving model ...
Validation loss decreased (1.076817 --> 1.072108).  Saving model ...
Validation loss decreased (1.072108 --> 1.071004).  Saving model ...
Validation loss decreased (1.071004 --> 1.064812).  Saving model ...
Validation loss decreased (1.064812 --> 1.062385).  Saving model ...
Validation loss decreased (1.062385 --> 1.059504).  Saving model ...
Validation loss decreased (1.059504 --> 1.055154).  Saving model ...
Validation loss decreased (1.055154 --> 1.053514).  Saving model ...
Validation loss decreased (1.053514 --> 1.052315).  Saving model ...
Validation loss decreased (1.052315 --> 1.047568).  Saving model ...
Validation loss decreased (1.047568 --> 1.044755).  Saving model ...
Validation loss decreased (1.044755 --> 1.042040).  Saving model ...
Validation loss decreased (1.042040 --> 1.038460).  Saving model ...
Validation loss decreased (1.038460 --> 1.035562).  Saving model ...
Validation loss decreased (1.035562 --> 1.033049).  Saving model ...
Validation loss decreased (1.033049 --> 1.029920).  Saving model ...
Validation loss decreased (1.029920 --> 1.026723).  Saving model ...
Validation loss decreased (1.026723 --> 1.023536).  Saving model ...
Validation loss decreased (1.023536 --> 1.019601).  Saving model ...
Validation loss decreased (1.019601 --> 1.018946).  Saving model ...
Validation loss decreased (1.018946 --> 1.017302).  Saving model ...
Validation loss decreased (1.017302 --> 1.014817).  Saving model ...
Validation loss decreased (1.014817 --> 1.014348).  Saving model ...
Validation loss decreased (1.014348 --> 1.011053).  Saving model ...
Validation loss decreased (1.011053 --> 1.010217).  Saving model ...
Validation loss decreased (1.010217 --> 1.006786).  Saving model ...
Validation loss decreased (1.006786 --> 1.003047).  Saving model ...
Validation loss decreased (1.003047 --> 1.002604).  Saving model ...
Validation loss decreased (1.002604 --> 1.000200).  Saving model ...
Validation loss decreased (1.000200 --> 0.998235).  Saving model ...
Validation loss decreased (0.998235 --> 0.995550).  Saving model ...
Validation loss decreased (0.995550 --> 0.993459).  Saving model ...
Validation loss decreased (0.993459 --> 0.992409).  Saving model ...
Validation loss decreased (0.992409 --> 0.991249).  Saving model ...
Validation loss decreased (0.991249 --> 0.988934).  Saving model ...
Validation loss decreased (0.988934 --> 0.987106).  Saving model ...
Validation loss decreased (0.987106 --> 0.984138).  Saving model ...
EarlyStopping counter: 1 out of 10.0
Validation loss decreased (0.984138 --> 0.982039).  Saving model ...
Validation loss decreased (0.982039 --> 0.979474).  Saving model ...
Validation loss decreased (0.979474 --> 0.978806).  Saving model ...
Validation loss decreased (0.978806 --> 0.977494).  Saving model ...
Validation loss decreased (0.977494 --> 0.976491).  Saving model ...
Validation loss decreased (0.976491 --> 0.975985).  Saving model ...
Validation loss decreased (0.975985 --> 0.974705).  Saving model ...
Validation loss decreased (0.974705 --> 0.973629).  Saving model ...
Validation loss decreased (0.973629 --> 0.971058).  Saving model ...
Validation loss decreased (0.971058 --> 0.969532).  Saving model ...
Validation loss decreased (0.969532 --> 0.969525).  Saving model ...
EarlyStopping counter: 1 out of 10.0
Validation loss decreased (0.969525 --> 0.969004).  Saving model ...
Validation loss decreased (0.969004 --> 0.965615).  Saving model ...
Validation loss decreased (0.965615 --> 0.965137).  Saving model ...
Validation loss decreased (0.965137 --> 0.964092).  Saving model ...
Validation loss decreased (0.964092 --> 0.961975).  Saving model ...
Validation loss decreased (0.961975 --> 0.961242).  Saving model ...
Validation loss decreased (0.961242 --> 0.960998).  Saving model ...
EarlyStopping counter: 1 out of 10.0
Validation loss decreased (0.960998 --> 0.959630).  Saving model ...
Validation loss decreased (0.959630 --> 0.958549).  Saving model ...
Validation loss decreased (0.958549 --> 0.958051).  Saving model ...
Validation loss decreased (0.958051 --> 0.957527).  Saving model ...
EarlyStopping counter: 1 out of 10.0
Validation loss decreased (0.957527 --> 0.955837).  Saving model ...
EarlyStopping counter: 1 out of 10.0
EarlyStopping counter: 2 out of 10.0
EarlyStopping counter: 3 out of 10.0
Validation loss decreased (0.955837 --> 0.955178).  Saving model ...
Validation loss decreased (0.955178 --> 0.954653).  Saving model ...
EarlyStopping counter: 1 out of 10.0
EarlyStopping counter: 2 out of 10.0
EarlyStopping counter: 3 out of 10.0
EarlyStopping counter: 4 out of 10.0
Validation loss decreased (0.954653 --> 0.953313).  Saving model ...
Validation loss decreased (0.953313 --> 0.952592).  Saving model ...
EarlyStopping counter: 1 out of 10.0
EarlyStopping counter: 2 out of 10.0
EarlyStopping counter: 3 out of 10.0
EarlyStopping counter: 4 out of 10.0
EarlyStopping counter: 5 out of 10.0
EarlyStopping counter: 6 out of 10.0
EarlyStopping counter: 7 out of 10.0
EarlyStopping counter: 8 out of 10.0
EarlyStopping counter: 9 out of 10.0
EarlyStopping counter: 10 out of 10.0
/localscratch/yinan.29351698.0/env/lib/python3.7/site-packages/torch/nn/functional.py:1794: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.
  warnings.warn("nn.functional.tanh is deprecated. Use torch.tanh instead.")
wandb: Waiting for W&B process to finish, PID 132069... (success).
wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: \ 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: | 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: / 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: \ 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: | 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: / 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: \ 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: | 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: / 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: \ 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb:                                                                                
wandb: Run history:
wandb:     e_F1 ▁▁▃▅▆▆▆▆▆▆▆▇▇▇▇▇▇▇▇▇▇▇▇█████████████████
wandb:   e_loss ██▇▇▇▇▆▆▆▅▅▄▄▄▄▃▃▃▃▃▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:     t_F1 ▁▂▂▃▃▃▄▄▄▄▆▅▆▆▅▆▆▆▇▆▇▇▇▇▇▇▇▇▇▇▇█▇██▇▇█▇█
wandb:   t_loss █▇█▇▇▇▇▆▇▆▆▆▅▅▅▄▄▄▄▄▃▃▃▃▃▃▃▃▂▂▂▂▂▂▂▂▂▁▁▁
wandb: 
wandb: Run summary:
wandb:     e_F1 57.59746
wandb:   e_loss 0.95568
wandb:     t_F1 74.56192
wandb:   t_loss 0.71399
wandb: 
wandb: Synced 4 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Synced smart-shadow-1: https://wandb.ai/yinanazhou/xl_512_bs_8_lr_1e06_es_10_lc_True_nr_True_sr_False_stem_False_lemma_False_repeat_5_fold_1/runs/2r6qr4an
wandb: Find logs at: ./wandb/run-20220324_211445-2r6qr4an/logs/debug.log
wandb: 

wandb: wandb version 0.12.11 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
2022-03-24 22:52:27.713037: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1
wandb: Tracking run with wandb version 0.12.5
wandb: Syncing run revived-lion-1
wandb: ⭐️ View project at https://wandb.ai/yinanazhou/xl_512_bs_8_lr_1e06_es_10_lc_True_nr_True_sr_False_stem_False_lemma_False_repeat_5_fold_2
wandb: 🚀 View run at https://wandb.ai/yinanazhou/xl_512_bs_8_lr_1e06_es_10_lc_True_nr_True_sr_False_stem_False_lemma_False_repeat_5_fold_2/runs/1yw9q9vu
wandb: Run data is saved locally in /project/6002780/yinan/Thesis_MER_Lyrics/lyric-emotion/wandb/run-20220324_225225-1yw9q9vu
wandb: Run `wandb offline` to turn off syncing.

Validation loss decreased (inf --> 1.407212).  Saving model ...
Validation loss decreased (1.407212 --> 1.397951).  Saving model ...
Validation loss decreased (1.397951 --> 1.390940).  Saving model ...
Validation loss decreased (1.390940 --> 1.385099).  Saving model ...
Validation loss decreased (1.385099 --> 1.379651).  Saving model ...
Validation loss decreased (1.379651 --> 1.374636).  Saving model ...
Validation loss decreased (1.374636 --> 1.370965).  Saving model ...
Validation loss decreased (1.370965 --> 1.366387).  Saving model ...
Validation loss decreased (1.366387 --> 1.362556).  Saving model ...
Validation loss decreased (1.362556 --> 1.358380).  Saving model ...
Validation loss decreased (1.358380 --> 1.353576).  Saving model ...
Validation loss decreased (1.353576 --> 1.349011).  Saving model ...
Validation loss decreased (1.349011 --> 1.345134).  Saving model ...
Validation loss decreased (1.345134 --> 1.341360).  Saving model ...
Validation loss decreased (1.341360 --> 1.337229).  Saving model ...
Validation loss decreased (1.337229 --> 1.332889).  Saving model ...
Validation loss decreased (1.332889 --> 1.327439).  Saving model ...
Validation loss decreased (1.327439 --> 1.322286).  Saving model ...
Validation loss decreased (1.322286 --> 1.316617).  Saving model ...
Validation loss decreased (1.316617 --> 1.310367).  Saving model ...
Validation loss decreased (1.310367 --> 1.303996).  Saving model ...
Validation loss decreased (1.303996 --> 1.297830).  Saving model ...
Validation loss decreased (1.297830 --> 1.290312).  Saving model ...
Validation loss decreased (1.290312 --> 1.284051).  Saving model ...
Validation loss decreased (1.284051 --> 1.275772).  Saving model ...
Validation loss decreased (1.275772 --> 1.267270).  Saving model ...
Validation loss decreased (1.267270 --> 1.259875).  Saving model ...
Validation loss decreased (1.259875 --> 1.253302).  Saving model ...
Validation loss decreased (1.253302 --> 1.243495).  Saving model ...
Validation loss decreased (1.243495 --> 1.234643).  Saving model ...
Validation loss decreased (1.234643 --> 1.227417).  Saving model ...
Validation loss decreased (1.227417 --> 1.219980).  Saving model ...
Validation loss decreased (1.219980 --> 1.212265).  Saving model ...
Validation loss decreased (1.212265 --> 1.205180).  Saving model ...
Validation loss decreased (1.205180 --> 1.199699).  Saving model ...
Validation loss decreased (1.199699 --> 1.191504).  Saving model ...
Validation loss decreased (1.191504 --> 1.183215).  Saving model ...
Validation loss decreased (1.183215 --> 1.176816).  Saving model ...
Validation loss decreased (1.176816 --> 1.172289).  Saving model ...
Validation loss decreased (1.172289 --> 1.166261).  Saving model ...
Validation loss decreased (1.166261 --> 1.161162).  Saving model ...
Validation loss decreased (1.161162 --> 1.154100).  Saving model ...
Validation loss decreased (1.154100 --> 1.146526).  Saving model ...
Validation loss decreased (1.146526 --> 1.143633).  Saving model ...
Validation loss decreased (1.143633 --> 1.139490).  Saving model ...
Validation loss decreased (1.139490 --> 1.135439).  Saving model ...
Validation loss decreased (1.135439 --> 1.130676).  Saving model ...
Validation loss decreased (1.130676 --> 1.126797).  Saving model ...
Validation loss decreased (1.126797 --> 1.123262).  Saving model ...
Validation loss decreased (1.123262 --> 1.118358).  Saving model ...
Validation loss decreased (1.118358 --> 1.114281).  Saving model ...
Validation loss decreased (1.114281 --> 1.110422).  Saving model ...
Validation loss decreased (1.110422 --> 1.107427).  Saving model ...
Validation loss decreased (1.107427 --> 1.101443).  Saving model ...
Validation loss decreased (1.101443 --> 1.097050).  Saving model ...
Validation loss decreased (1.097050 --> 1.092428).  Saving model ...
Validation loss decreased (1.092428 --> 1.091563).  Saving model ...
Validation loss decreased (1.091563 --> 1.087126).  Saving model ...
Validation loss decreased (1.087126 --> 1.080039).  Saving model ...
Validation loss decreased (1.080039 --> 1.078233).  Saving model ...
Validation loss decreased (1.078233 --> 1.076797).  Saving model ...
Validation loss decreased (1.076797 --> 1.069575).  Saving model ...
Validation loss decreased (1.069575 --> 1.065969).  Saving model ...
Validation loss decreased (1.065969 --> 1.064269).  Saving model ...
Validation loss decreased (1.064269 --> 1.059926).  Saving model ...
Validation loss decreased (1.059926 --> 1.056082).  Saving model ...
EarlyStopping counter: 1 out of 10.0
Validation loss decreased (1.056082 --> 1.050019).  Saving model ...
Validation loss decreased (1.050019 --> 1.045244).  Saving model ...
Validation loss decreased (1.045244 --> 1.041987).  Saving model ...
Validation loss decreased (1.041987 --> 1.038926).  Saving model ...
Validation loss decreased (1.038926 --> 1.035360).  Saving model ...
Validation loss decreased (1.035360 --> 1.032520).  Saving model ...
Validation loss decreased (1.032520 --> 1.029517).  Saving model ...
Validation loss decreased (1.029517 --> 1.027656).  Saving model ...
EarlyStopping counter: 1 out of 10.0
Validation loss decreased (1.027656 --> 1.024137).  Saving model ...
EarlyStopping counter: 1 out of 10.0
Validation loss decreased (1.024137 --> 1.021774).  Saving model ...
Validation loss decreased (1.021774 --> 1.019420).  Saving model ...
Validation loss decreased (1.019420 --> 1.017213).  Saving model ...
Validation loss decreased (1.017213 --> 1.012777).  Saving model ...
Validation loss decreased (1.012777 --> 1.008256).  Saving model ...
Validation loss decreased (1.008256 --> 1.005370).  Saving model ...
Validation loss decreased (1.005370 --> 1.004263).  Saving model ...
Validation loss decreased (1.004263 --> 1.003280).  Saving model ...
Validation loss decreased (1.003280 --> 0.998725).  Saving model ...
EarlyStopping counter: 1 out of 10.0
Validation loss decreased (0.998725 --> 0.998497).  Saving model ...
Validation loss decreased (0.998497 --> 0.994201).  Saving model ...
EarlyStopping counter: 1 out of 10.0
Validation loss decreased (0.994201 --> 0.991552).  Saving model ...
Validation loss decreased (0.991552 --> 0.990510).  Saving model ...
Validation loss decreased (0.990510 --> 0.990510).  Saving model ...
Validation loss decreased (0.990510 --> 0.987298).  Saving model ...
Validation loss decreased (0.987298 --> 0.982559).  Saving model ...
EarlyStopping counter: 1 out of 10.0
Validation loss decreased (0.982559 --> 0.981341).  Saving model ...
EarlyStopping counter: 1 out of 10.0
Validation loss decreased (0.981341 --> 0.980118).  Saving model ...
Validation loss decreased (0.980118 --> 0.978998).  Saving model ...
EarlyStopping counter: 1 out of 10.0
EarlyStopping counter: 2 out of 10.0
Validation loss decreased (0.978998 --> 0.978518).  Saving model ...
Validation loss decreased (0.978518 --> 0.977100).  Saving model ...
Validation loss decreased (0.977100 --> 0.975408).  Saving model ...
Validation loss decreased (0.975408 --> 0.970401).  Saving model ...
Validation loss decreased (0.970401 --> 0.968665).  Saving model ...
Validation loss decreased (0.968665 --> 0.965228).  Saving model ...
EarlyStopping counter: 1 out of 10.0
EarlyStopping counter: 2 out of 10.0
Validation loss decreased (0.965228 --> 0.965024).  Saving model ...
Validation loss decreased (0.965024 --> 0.962268).  Saving model ...
Validation loss decreased (0.962268 --> 0.962019).  Saving model ...
Validation loss decreased (0.962019 --> 0.959436).  Saving model ...
EarlyStopping counter: 1 out of 10.0
Validation loss decreased (0.959436 --> 0.959236).  Saving model ...
Validation loss decreased (0.959236 --> 0.958243).  Saving model ...
Validation loss decreased (0.958243 --> 0.957418).  Saving model ...
Validation loss decreased (0.957418 --> 0.956573).  Saving model ...
Validation loss decreased (0.956573 --> 0.956548).  Saving model ...
EarlyStopping counter: 1 out of 10.0
EarlyStopping counter: 2 out of 10.0
Validation loss decreased (0.956548 --> 0.954499).  Saving model ...
EarlyStopping counter: 1 out of 10.0
Validation loss decreased (0.954499 --> 0.952982).  Saving model ...
EarlyStopping counter: 1 out of 10.0
EarlyStopping counter: 2 out of 10.0
EarlyStopping counter: 3 out of 10.0
EarlyStopping counter: 4 out of 10.0
EarlyStopping counter: 5 out of 10.0
Validation loss decreased (0.952982 --> 0.952913).  Saving model ...
Validation loss decreased (0.952913 --> 0.950896).  Saving model ...
EarlyStopping counter: 1 out of 10.0
EarlyStopping counter: 2 out of 10.0
EarlyStopping counter: 3 out of 10.0
Validation loss decreased (0.950896 --> 0.950179).  Saving model ...
Validation loss decreased (0.950179 --> 0.948133).  Saving model ...
Validation loss decreased (0.948133 --> 0.946106).  Saving model ...
EarlyStopping counter: 1 out of 10.0
EarlyStopping counter: 2 out of 10.0
EarlyStopping counter: 3 out of 10.0
EarlyStopping counter: 4 out of 10.0
EarlyStopping counter: 5 out of 10.0
EarlyStopping counter: 6 out of 10.0
EarlyStopping counter: 7 out of 10.0
Validation loss decreased (0.946106 --> 0.945502).  Saving model ...
Validation loss decreased (0.945502 --> 0.944656).  Saving model ...
Validation loss decreased (0.944656 --> 0.943479).  Saving model ...
EarlyStopping counter: 1 out of 10.0
Validation loss decreased (0.943479 --> 0.941906).  Saving model ...
EarlyStopping counter: 1 out of 10.0
EarlyStopping counter: 2 out of 10.0
EarlyStopping counter: 3 out of 10.0
EarlyStopping counter: 4 out of 10.0
EarlyStopping counter: 5 out of 10.0
EarlyStopping counter: 6 out of 10.0
EarlyStopping counter: 7 out of 10.0
EarlyStopping counter: 8 out of 10.0
EarlyStopping counter: 9 out of 10.0
EarlyStopping counter: 10 out of 10.0
/localscratch/yinan.29351698.0/env/lib/python3.7/site-packages/torch/nn/functional.py:1794: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.
  warnings.warn("nn.functional.tanh is deprecated. Use torch.tanh instead.")
wandb: Waiting for W&B process to finish, PID 137256... (success).
wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: \ 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: | 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: / 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: \ 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: | 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: / 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: \ 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: | 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: / 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb:                                                                                
wandb: Run history:
wandb:     e_F1 ▁▂▃▃▄▄▅▅▆▆▇▇▇▇▇▇▇▇▇▇▇▇█▇████████████████
wandb:   e_loss ██▇▇▇▆▆▅▅▅▄▄▄▃▃▃▃▂▂▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:     t_F1 ▁▁▂▂▃▃▄▄▅▄▄▅▅▅▆▆▆▆▆▆▆▆▇▆▇▇▆▇▇▇▇▇▇▇▇▇█▇██
wandb:   t_loss ██▇▇▇▇▆▆▆▆▆▅▅▅▄▄▄▄▄▄▄▃▃▃▃▃▃▂▂▂▂▂▂▂▂▂▁▂▁▁
wandb: 
wandb: Run summary:
wandb:     e_F1 60.11262
wandb:   e_loss 0.94508
wandb:     t_F1 73.26104
wandb:   t_loss 0.7136
wandb: 
wandb: Synced 4 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Synced revived-lion-1: https://wandb.ai/yinanazhou/xl_512_bs_8_lr_1e06_es_10_lc_True_nr_True_sr_False_stem_False_lemma_False_repeat_5_fold_2/runs/1yw9q9vu
wandb: Find logs at: ./wandb/run-20220324_225225-1yw9q9vu/logs/debug.log
wandb: 

