Unloading StdEnv/2020

Due to MODULEPATH changes, the following have been reloaded:
  1) mii/1.1.1


The following have been reloaded with a version change:
  1) python/3.8.2 => python/3.7.4

Using base prefix '/cvmfs/soft.computecanada.ca/easybuild/software/2017/Core/python/3.7.4'
New python executable in /localscratch/yinan.29351708.0/env/bin/python
Installing setuptools, pip, wheel...
done.
Ignoring pip: markers 'python_version < "3"' don't match your environment
Looking in links: /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/nix/avx2, /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/nix/generic, /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic
Collecting pip
Installing collected packages: pip
  Found existing installation: pip 19.1.1
    Uninstalling pip-19.1.1:
      Successfully uninstalled pip-19.1.1
Successfully installed pip-21.2.3+computecanada
Looking in links: /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/nix/avx2, /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/nix/generic, /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/keras-2.8.0+computecanada-py2.py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/Keras_Preprocessing-1.1.2+computecanada-py3-none-any.whl
Requirement already satisfied: matplotlib in /cvmfs/soft.computecanada.ca/easybuild/software/2017/Core/scipy-stack/2019a/lib/python3.7/site-packages (from -r requirements.txt (line 3)) (3.0.2)
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/nltk-3.6.5+computecanada-py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/scikit_learn-0.22.1+computecanada-cp37-cp37m-linux_x86_64.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/tensorboard-2.3.0+computecanada-py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/tensorboard_plugin_wit-1.7.0+computecanada-py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/tensorflow_gpu-2.3.0+computecanada-cp37-cp37m-linux_x86_64.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/tensorflow_estimator-2.3.0+computecanada-py2.py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/tokenizers-0.5.2+computecanada-cp37-cp37m-linux_x86_64.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/nix/avx2/torch-1.4.0+computecanada-cp37-cp37m-linux_x86_64.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/torchtext-0.6.0+computecanada-py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/torchvision-0.8.2+computecanada-cp37-cp37m-linux_x86_64.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/transformers-2.5.1+computecanada-py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/urllib3-1.26.7+computecanada-py2.py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/joblib-1.1.0+computecanada-py2.py3-none-any.whl
ERROR: Could not find a version that satisfies the requirement regex>=2021.8.3 (from nltk) (from versions: 2018.1.10+computecanada, 2019.11.1+computecanada, 2020.11.13+computecanada)
ERROR: No matching distribution found for regex>=2021.8.3
Looking in links: /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/nix/avx2, /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/nix/generic, /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic
ERROR: Could not find a version that satisfies the requirement numpy==1.20.0+computacanada (from versions: 1.15.0+computecanada, 1.15.2+computecanada, 1.15.4+computecanada, 1.16.0+computecanada, 1.16.2+computecanada, 1.16.3+computecanada, 1.17.4+computecanada, 1.18.1+computecanada, 1.18.4+computecanada, 1.19.1+computecanada, 1.19.2+computecanada, 1.20.2+computecanada)
ERROR: No matching distribution found for numpy==1.20.0+computacanada
Looking in links: /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/nix/avx2, /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/nix/generic, /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/wandb-0.12.5+computecanada-py2.py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/sentry_sdk-1.5.0+computecanada-py2.py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/protobuf-3.19.4+computecanada-py2.py3-none-any.whl
Requirement already satisfied: python-dateutil>=2.6.1 in /cvmfs/soft.computecanada.ca/easybuild/software/2017/Core/scipy-stack/2019a/lib/python3.7/site-packages (from wandb) (2.7.5)
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/promise-2.3+computecanada-py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/configparser-5.0.2+computecanada-py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/click-8.0.4+computecanada-py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/psutil-5.7.3+computecanada-cp37-cp37m-linux_x86_64.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/docker_pycreds-0.4.0+computecanada-py2.py3-none-any.whl
Requirement already satisfied: requests<3,>=2.0.0 in /cvmfs/soft.computecanada.ca/easybuild/software/2017/Core/scipy-stack/2019a/lib/python3.7/site-packages (from wandb) (2.21.0)
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/yaspin-2.1.0+computecanada-py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/six-1.16.0+computecanada-py2.py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/GitPython-3.1.24+computecanada-py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/PyYAML-5.3.1+computecanada-cp37-cp37m-linux_x86_64.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/shortuuid-1.0.1+computecanada-py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/pathtools-0.1.2+computecanada-py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/subprocess32-3.5.4+computecanada-py3-none-any.whl
Requirement already satisfied: importlib-metadata in /cvmfs/soft.computecanada.ca/easybuild/software/2017/Core/scipy-stack/2019a/lib/python3.7/site-packages (from Click!=8.0.0,>=7.0->wandb) (0.8)
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/typing_extensions-4.1.1+computecanada-py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/gitdb-4.0.9+computecanada-py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/smmap-5.0.0+computecanada-py3-none-any.whl
Requirement already satisfied: urllib3<1.25,>=1.21.1 in /cvmfs/soft.computecanada.ca/easybuild/software/2017/Core/scipy-stack/2019a/lib/python3.7/site-packages (from requests<3,>=2.0.0->wandb) (1.24.1)
Requirement already satisfied: idna<2.9,>=2.5 in /cvmfs/soft.computecanada.ca/easybuild/software/2017/Core/scipy-stack/2019a/lib/python3.7/site-packages (from requests<3,>=2.0.0->wandb) (2.8)
Requirement already satisfied: certifi>=2017.4.17 in /cvmfs/soft.computecanada.ca/easybuild/software/2017/Core/scipy-stack/2019a/lib/python3.7/site-packages (from requests<3,>=2.0.0->wandb) (2018.11.29)
Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /cvmfs/soft.computecanada.ca/easybuild/software/2017/Core/scipy-stack/2019a/lib/python3.7/site-packages (from requests<3,>=2.0.0->wandb) (3.0.4)
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/termcolor-1.1.0+computecanada-py3-none-any.whl
Requirement already satisfied: zipp>=0.3.2 in /cvmfs/soft.computecanada.ca/easybuild/software/2017/Core/scipy-stack/2019a/lib/python3.7/site-packages (from importlib-metadata->Click!=8.0.0,>=7.0->wandb) (0.3.3)
Installing collected packages: smmap, typing-extensions, termcolor, six, gitdb, yaspin, subprocess32, shortuuid, sentry-sdk, PyYAML, psutil, protobuf, promise, pathtools, GitPython, docker-pycreds, configparser, Click, wandb
  Attempting uninstall: six
    Found existing installation: six 1.12.0
    Not uninstalling six at /cvmfs/soft.computecanada.ca/easybuild/software/2017/Core/scipy-stack/2019a/lib/python3.7/site-packages, outside environment /localscratch/yinan.29351708.0/env
    Can't uninstall 'six'. No files were found to uninstall.
Successfully installed Click-8.0.4+computecanada GitPython-3.1.24+computecanada PyYAML-5.3.1+computecanada configparser-5.0.2+computecanada docker-pycreds-0.4.0+computecanada gitdb-4.0.9+computecanada pathtools-0.1.2+computecanada promise-2.3+computecanada protobuf-3.19.4+computecanada psutil-5.7.3+computecanada sentry-sdk-1.5.0+computecanada shortuuid-1.0.1+computecanada six-1.16.0+computecanada smmap-5.0.0+computecanada subprocess32-3.5.4+computecanada termcolor-1.1.0+computecanada typing-extensions-4.1.1+computecanada wandb-0.12.5+computecanada yaspin-2.1.0+computecanada
Looking in links: /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/nix/avx2, /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/nix/generic, /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic
ERROR: Could not find a version that satisfies the requirement sagemaker (from versions: none)
ERROR: No matching distribution found for sagemaker
Looking in links: /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/nix/avx2, /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/nix/generic, /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/torch-1.9.1+computecanada-cp37-cp37m-linux_x86_64.whl
Requirement already satisfied: typing-extensions in /localscratch/yinan.29351708.0/env/lib/python3.7/site-packages (from torch) (4.1.1+computecanada)
Installing collected packages: torch
Successfully installed torch-1.9.1+computecanada
Looking in links: /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/nix/avx2, /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/nix/generic, /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/transformers-2.5.1+computecanada-py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/boto3-1.21.14+computecanada-py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/tqdm-4.63.1+computecanada-py2.py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/filelock-3.4.2+computecanada-py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/sacremoses-0.0.49+computecanada-py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/regex-2020.11.13+computecanada-cp37-cp37m-linux_x86_64.whl
Requirement already satisfied: requests in /cvmfs/soft.computecanada.ca/easybuild/software/2017/Core/scipy-stack/2019a/lib/python3.7/site-packages (from transformers==2.5.1+computecanada) (2.21.0)
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/tokenizers-0.5.2+computecanada-cp37-cp37m-linux_x86_64.whl
Requirement already satisfied: numpy in /cvmfs/soft.computecanada.ca/easybuild/software/2017/Core/scipy-stack/2019a/lib/python3.7/site-packages (from transformers==2.5.1+computecanada) (1.16.0)
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/sentencepiece-0.1.91+computecanada-cp37-cp37m-linux_x86_64.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/jmespath-0.10.0+computecanada-py2.py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/botocore-1.24.14+computecanada-py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/s3transfer-0.5.1+computecanada-py3-none-any.whl
Requirement already satisfied: python-dateutil<3.0.0,>=2.1 in /cvmfs/soft.computecanada.ca/easybuild/software/2017/Core/scipy-stack/2019a/lib/python3.7/site-packages (from botocore<1.25.0,>=1.24.14->boto3->transformers==2.5.1+computecanada) (2.7.5)
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/urllib3-1.26.8+computecanada-py2.py3-none-any.whl
Requirement already satisfied: six>=1.5 in /localscratch/yinan.29351708.0/env/lib/python3.7/site-packages (from python-dateutil<3.0.0,>=2.1->botocore<1.25.0,>=1.24.14->boto3->transformers==2.5.1+computecanada) (1.16.0+computecanada)
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/requests-2.27.1+computecanada-py2.py3-none-any.whl
Requirement already satisfied: idna<4,>=2.5 in /cvmfs/soft.computecanada.ca/easybuild/software/2017/Core/scipy-stack/2019a/lib/python3.7/site-packages (from requests->transformers==2.5.1+computecanada) (2.8)
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/charset_normalizer-2.0.12+computecanada-py3-none-any.whl
Requirement already satisfied: certifi>=2017.4.17 in /cvmfs/soft.computecanada.ca/easybuild/software/2017/Core/scipy-stack/2019a/lib/python3.7/site-packages (from requests->transformers==2.5.1+computecanada) (2018.11.29)
Requirement already satisfied: click in /localscratch/yinan.29351708.0/env/lib/python3.7/site-packages (from sacremoses->transformers==2.5.1+computecanada) (8.0.4+computecanada)
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/joblib-1.1.0+computecanada-py2.py3-none-any.whl
Requirement already satisfied: importlib-metadata in /cvmfs/soft.computecanada.ca/easybuild/software/2017/Core/scipy-stack/2019a/lib/python3.7/site-packages (from click->sacremoses->transformers==2.5.1+computecanada) (0.8)
Requirement already satisfied: zipp>=0.3.2 in /cvmfs/soft.computecanada.ca/easybuild/software/2017/Core/scipy-stack/2019a/lib/python3.7/site-packages (from importlib-metadata->click->sacremoses->transformers==2.5.1+computecanada) (0.3.3)
Installing collected packages: urllib3, jmespath, botocore, tqdm, s3transfer, regex, joblib, charset-normalizer, tokenizers, sentencepiece, sacremoses, requests, filelock, boto3, transformers
  Attempting uninstall: urllib3
    Found existing installation: urllib3 1.24.1
    Not uninstalling urllib3 at /cvmfs/soft.computecanada.ca/easybuild/software/2017/Core/scipy-stack/2019a/lib/python3.7/site-packages, outside environment /localscratch/yinan.29351708.0/env
    Can't uninstall 'urllib3'. No files were found to uninstall.
  Attempting uninstall: requests
    Found existing installation: requests 2.21.0
    Not uninstalling requests at /cvmfs/soft.computecanada.ca/easybuild/software/2017/Core/scipy-stack/2019a/lib/python3.7/site-packages, outside environment /localscratch/yinan.29351708.0/env
    Can't uninstall 'requests'. No files were found to uninstall.
Successfully installed boto3-1.21.14+computecanada botocore-1.24.14+computecanada charset-normalizer-2.0.12+computecanada filelock-3.4.2+computecanada jmespath-0.10.0+computecanada joblib-1.1.0+computecanada regex-2020.11.13+computecanada requests-2.27.1+computecanada s3transfer-0.5.1+computecanada sacremoses-0.0.49+computecanada sentencepiece-0.1.91+computecanada tokenizers-0.5.2+computecanada tqdm-4.63.1+computecanada transformers-2.5.1+computecanada urllib3-1.26.8+computecanada
Looking in links: /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/nix/avx2, /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/nix/generic, /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/tensorflow_gpu-2.3.0+computecanada-cp37-cp37m-linux_x86_64.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/gast-0.3.3+computecanada-py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/opt_einsum-3.3.0+computecanada-py3-none-any.whl
Requirement already satisfied: protobuf>=3.9.2 in /localscratch/yinan.29351708.0/env/lib/python3.7/site-packages (from tensorflow_gpu==2.3.0+computecanada) (3.19.4+computecanada)
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/nix/generic/scipy-1.4.1+computecanada-cp37-cp37m-linux_x86_64.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/absl_py-1.0.0+computecanada-py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/Keras_Preprocessing-1.1.2+computecanada-py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/nix/avx2/h5py-2.10.0+computecanada-cp37-cp37m-linux_x86_64.whl
Requirement already satisfied: six>=1.12.0 in /localscratch/yinan.29351708.0/env/lib/python3.7/site-packages (from tensorflow_gpu==2.3.0+computecanada) (1.16.0+computecanada)
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/tensorflow_estimator-2.3.0+computecanada-py2.py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/grpcio-1.38.0+computecanada-cp37-cp37m-linux_x86_64.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/astunparse-1.6.3+computecanada-py2.py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/tensorboard-2.8.0+computecanada-py3-none-any.whl
Requirement already satisfied: wheel>=0.26 in /localscratch/yinan.29351708.0/env/lib/python3.7/site-packages (from tensorflow_gpu==2.3.0+computecanada) (0.33.4)
Requirement already satisfied: numpy<1.19.0,>=1.16.0 in /cvmfs/soft.computecanada.ca/easybuild/software/2017/Core/scipy-stack/2019a/lib/python3.7/site-packages (from tensorflow_gpu==2.3.0+computecanada) (1.16.0)
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/wrapt-1.11.2+computecanada-cp37-cp37m-linux_x86_64.whl
Requirement already satisfied: termcolor>=1.1.0 in /localscratch/yinan.29351708.0/env/lib/python3.7/site-packages (from tensorflow_gpu==2.3.0+computecanada) (1.1.0+computecanada)
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/google_pasta-0.2.0+computecanada-py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/google_auth_oauthlib-0.4.6+computecanada-py2.py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/Werkzeug-2.0.3+computecanada-py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/tensorboard_plugin_wit-1.8.0+computecanada-py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/google_auth-2.3.3+computecanada-py2.py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/tensorboard_data_server-0.6.1+computecanada-py3-none-linux_x86_64.whl
Requirement already satisfied: setuptools>=41.0.0 in /localscratch/yinan.29351708.0/env/lib/python3.7/site-packages (from tensorboard<3,>=2.3.0->tensorflow_gpu==2.3.0+computecanada) (41.0.1)
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/Markdown-3.3.6+computecanada-py3-none-any.whl
Requirement already satisfied: requests<3,>=2.21.0 in /localscratch/yinan.29351708.0/env/lib/python3.7/site-packages (from tensorboard<3,>=2.3.0->tensorflow_gpu==2.3.0+computecanada) (2.27.1+computecanada)
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/pyasn1_modules-0.2.8+computecanada-py2.py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/rsa-4.8+computecanada-py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/cachetools-4.2.4+computecanada-py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/requests_oauthlib-1.3.0+computecanada-py2.py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/importlib_metadata-4.10.1+computecanada-py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/zipp-3.7.0+computecanada-py3-none-any.whl
Requirement already satisfied: typing-extensions>=3.6.4 in /localscratch/yinan.29351708.0/env/lib/python3.7/site-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard<3,>=2.3.0->tensorflow_gpu==2.3.0+computecanada) (4.1.1+computecanada)
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/pyasn1-0.4.8+computecanada-py2.py3-none-any.whl
Requirement already satisfied: certifi>=2017.4.17 in /cvmfs/soft.computecanada.ca/easybuild/software/2017/Core/scipy-stack/2019a/lib/python3.7/site-packages (from requests<3,>=2.21.0->tensorboard<3,>=2.3.0->tensorflow_gpu==2.3.0+computecanada) (2018.11.29)
Requirement already satisfied: idna<4,>=2.5 in /cvmfs/soft.computecanada.ca/easybuild/software/2017/Core/scipy-stack/2019a/lib/python3.7/site-packages (from requests<3,>=2.21.0->tensorboard<3,>=2.3.0->tensorflow_gpu==2.3.0+computecanada) (2.8)
Requirement already satisfied: urllib3<1.27,>=1.21.1 in /localscratch/yinan.29351708.0/env/lib/python3.7/site-packages (from requests<3,>=2.21.0->tensorboard<3,>=2.3.0->tensorflow_gpu==2.3.0+computecanada) (1.26.8+computecanada)
Requirement already satisfied: charset-normalizer~=2.0.0 in /localscratch/yinan.29351708.0/env/lib/python3.7/site-packages (from requests<3,>=2.21.0->tensorboard<3,>=2.3.0->tensorflow_gpu==2.3.0+computecanada) (2.0.12+computecanada)
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/oauthlib-3.1.1+computecanada-py2.py3-none-any.whl
Installing collected packages: pyasn1, zipp, rsa, pyasn1-modules, oauthlib, cachetools, requests-oauthlib, importlib-metadata, google-auth, werkzeug, tensorboard-plugin-wit, tensorboard-data-server, markdown, grpcio, google-auth-oauthlib, absl-py, wrapt, tensorflow-estimator, tensorboard, scipy, opt-einsum, keras-preprocessing, h5py, google-pasta, gast, astunparse, tensorflow-gpu
  Attempting uninstall: pyasn1
    Found existing installation: pyasn1 0.4.3
    Not uninstalling pyasn1 at /cvmfs/soft.computecanada.ca/easybuild/software/2017/Core/scipy-stack/2019a/lib/python3.7/site-packages, outside environment /localscratch/yinan.29351708.0/env
    Can't uninstall 'pyasn1'. No files were found to uninstall.
  Attempting uninstall: zipp
    Found existing installation: zipp 0.3.3
    Not uninstalling zipp at /cvmfs/soft.computecanada.ca/easybuild/software/2017/Core/scipy-stack/2019a/lib/python3.7/site-packages, outside environment /localscratch/yinan.29351708.0/env
    Can't uninstall 'zipp'. No files were found to uninstall.
  Attempting uninstall: importlib-metadata
    Found existing installation: importlib-metadata 0.8
    Not uninstalling importlib-metadata at /cvmfs/soft.computecanada.ca/easybuild/software/2017/Core/scipy-stack/2019a/lib/python3.7/site-packages, outside environment /localscratch/yinan.29351708.0/env
    Can't uninstall 'importlib-metadata'. No files were found to uninstall.
  Attempting uninstall: scipy
    Found existing installation: scipy 1.2.0
    Not uninstalling scipy at /cvmfs/soft.computecanada.ca/easybuild/software/2017/Core/scipy-stack/2019a/lib/python3.7/site-packages, outside environment /localscratch/yinan.29351708.0/env
    Can't uninstall 'scipy'. No files were found to uninstall.
Successfully installed absl-py-1.0.0+computecanada astunparse-1.6.3+computecanada cachetools-4.2.4+computecanada gast-0.3.3+computecanada google-auth-2.3.3+computecanada google-auth-oauthlib-0.4.6+computecanada google-pasta-0.2.0+computecanada grpcio-1.38.0+computecanada h5py-2.10.0+computecanada importlib-metadata-4.10.1+computecanada keras-preprocessing-1.1.2+computecanada markdown-3.3.6+computecanada oauthlib-3.1.1+computecanada opt-einsum-3.3.0+computecanada pyasn1-0.4.8+computecanada pyasn1-modules-0.2.8+computecanada requests-oauthlib-1.3.0+computecanada rsa-4.8+computecanada scipy-1.4.1+computecanada tensorboard-2.8.0+computecanada tensorboard-data-server-0.6.1+computecanada tensorboard-plugin-wit-1.8.0+computecanada tensorflow-estimator-2.3.0+computecanada tensorflow-gpu-2.3.0+computecanada werkzeug-2.0.3+computecanada wrapt-1.11.2+computecanada zipp-3.7.0+computecanada
Looking in links: /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/nix/avx2, /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/nix/generic, /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/keras-2.8.0+computecanada-py2.py3-none-any.whl
Installing collected packages: Keras
Successfully installed Keras-2.8.0+computecanada
Looking in links: /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/nix/avx2, /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/nix/generic, /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/urllib3-1.26.7+computecanada-py2.py3-none-any.whl
Installing collected packages: urllib3
  Attempting uninstall: urllib3
    Found existing installation: urllib3 1.26.8+computecanada
    Uninstalling urllib3-1.26.8+computecanada:
      Successfully uninstalled urllib3-1.26.8+computecanada
Successfully installed urllib3-1.26.7+computecanada
Looking in links: /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/nix/avx2, /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/nix/generic, /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/nltk-3.7+computecanada-py3-none-any.whl
Requirement already satisfied: click in /localscratch/yinan.29351708.0/env/lib/python3.7/site-packages (from nltk) (8.0.4+computecanada)
Requirement already satisfied: joblib in /localscratch/yinan.29351708.0/env/lib/python3.7/site-packages (from nltk) (1.1.0+computecanada)
Requirement already satisfied: tqdm in /localscratch/yinan.29351708.0/env/lib/python3.7/site-packages (from nltk) (4.63.1+computecanada)
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/nltk-3.6.5+computecanada-py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/nltk-3.6.3+computecanada-py3-none-any.whl
Requirement already satisfied: regex in /localscratch/yinan.29351708.0/env/lib/python3.7/site-packages (from nltk) (2020.11.13+computecanada)
Requirement already satisfied: importlib-metadata in /localscratch/yinan.29351708.0/env/lib/python3.7/site-packages (from click->nltk) (4.10.1+computecanada)
Requirement already satisfied: typing-extensions>=3.6.4 in /localscratch/yinan.29351708.0/env/lib/python3.7/site-packages (from importlib-metadata->click->nltk) (4.1.1+computecanada)
Requirement already satisfied: zipp>=0.5 in /localscratch/yinan.29351708.0/env/lib/python3.7/site-packages (from importlib-metadata->click->nltk) (3.7.0+computecanada)
Installing collected packages: nltk
Successfully installed nltk-3.6.3+computecanada
Looking in links: /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/nix/avx2, /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/nix/generic, /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/scikit_learn-0.22.1+computecanada-cp37-cp37m-linux_x86_64.whl
Requirement already satisfied: joblib>=0.11 in /localscratch/yinan.29351708.0/env/lib/python3.7/site-packages (from scikit-learn==0.22.1) (1.1.0+computecanada)
Requirement already satisfied: numpy>=1.11.0 in /cvmfs/soft.computecanada.ca/easybuild/software/2017/Core/scipy-stack/2019a/lib/python3.7/site-packages (from scikit-learn==0.22.1) (1.16.0)
Requirement already satisfied: scipy>=0.17.0 in /localscratch/yinan.29351708.0/env/lib/python3.7/site-packages (from scikit-learn==0.22.1) (1.4.1+computecanada)
Installing collected packages: scikit-learn
Successfully installed scikit-learn-0.22.1+computecanada
Looking in links: /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/nix/avx2, /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/nix/generic, /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic
Requirement already satisfied: tokenizers==0.5.2 in /localscratch/yinan.29351708.0/env/lib/python3.7/site-packages (0.5.2+computecanada)
wandb: Appending key for api.wandb.ai to your netrc file: /home/yinan/.netrc
Starting Task
2022-03-28 05:50:58.748612: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1
[nltk_data] Downloading package stopwords to /home/yinan/nltk_data...
[nltk_data]   Package stopwords is already up-to-date!
[nltk_data] Downloading package wordnet to /home/yinan/nltk_data...
[nltk_data]   Package wordnet is already up-to-date!
wandb: Currently logged in as: yinanazhou (use `wandb login --relogin` to force relogin)
wandb: wandb version 0.12.11 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
2022-03-28 05:51:14.209350: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1
wandb: Tracking run with wandb version 0.12.5
wandb: Syncing run crisp-bee-3
wandb: ⭐️ View project at https://wandb.ai/yinanazhou/xl_512_bs_8_lr_1e06_es_5_lc_False_nr_False_sr_True_stem_False_lemma_True_repeat_1_fold_1
wandb: 🚀 View run at https://wandb.ai/yinanazhou/xl_512_bs_8_lr_1e06_es_5_lc_False_nr_False_sr_True_stem_False_lemma_True_repeat_1_fold_1/runs/1bnq8pcj
wandb: Run data is saved locally in /project/6002780/yinan/Thesis_MER_Lyrics/lyric-emotion/wandb/run-20220328_055111-1bnq8pcj
wandb: Run `wandb offline` to turn off syncing.

Validation loss decreased (inf --> 1.427574).  Saving model ...
Validation loss decreased (1.427574 --> 1.407930).  Saving model ...
Validation loss decreased (1.407930 --> 1.391188).  Saving model ...
Validation loss decreased (1.391188 --> 1.378406).  Saving model ...
Validation loss decreased (1.378406 --> 1.368410).  Saving model ...
Validation loss decreased (1.368410 --> 1.358918).  Saving model ...
Validation loss decreased (1.358918 --> 1.351319).  Saving model ...
Validation loss decreased (1.351319 --> 1.344903).  Saving model ...
Validation loss decreased (1.344903 --> 1.339149).  Saving model ...
Validation loss decreased (1.339149 --> 1.332976).  Saving model ...
Validation loss decreased (1.332976 --> 1.326100).  Saving model ...
Validation loss decreased (1.326100 --> 1.320705).  Saving model ...
Validation loss decreased (1.320705 --> 1.313481).  Saving model ...
Validation loss decreased (1.313481 --> 1.307109).  Saving model ...
Validation loss decreased (1.307109 --> 1.299803).  Saving model ...
Validation loss decreased (1.299803 --> 1.292455).  Saving model ...
Validation loss decreased (1.292455 --> 1.284967).  Saving model ...
Validation loss decreased (1.284967 --> 1.278097).  Saving model ...
Validation loss decreased (1.278097 --> 1.269714).  Saving model ...
Validation loss decreased (1.269714 --> 1.262231).  Saving model ...
Validation loss decreased (1.262231 --> 1.255325).  Saving model ...
Validation loss decreased (1.255325 --> 1.247585).  Saving model ...
Validation loss decreased (1.247585 --> 1.241129).  Saving model ...
Validation loss decreased (1.241129 --> 1.232712).  Saving model ...
Validation loss decreased (1.232712 --> 1.225695).  Saving model ...
Validation loss decreased (1.225695 --> 1.218015).  Saving model ...
Validation loss decreased (1.218015 --> 1.214286).  Saving model ...
Validation loss decreased (1.214286 --> 1.207433).  Saving model ...
Validation loss decreased (1.207433 --> 1.199062).  Saving model ...
Validation loss decreased (1.199062 --> 1.195034).  Saving model ...
Validation loss decreased (1.195034 --> 1.187588).  Saving model ...
Validation loss decreased (1.187588 --> 1.181286).  Saving model ...
Validation loss decreased (1.181286 --> 1.180440).  Saving model ...
Validation loss decreased (1.180440 --> 1.172941).  Saving model ...
Validation loss decreased (1.172941 --> 1.168939).  Saving model ...
Validation loss decreased (1.168939 --> 1.164877).  Saving model ...
Validation loss decreased (1.164877 --> 1.160460).  Saving model ...
Validation loss decreased (1.160460 --> 1.153775).  Saving model ...
Validation loss decreased (1.153775 --> 1.151359).  Saving model ...
Validation loss decreased (1.151359 --> 1.147598).  Saving model ...
Validation loss decreased (1.147598 --> 1.142637).  Saving model ...
Validation loss decreased (1.142637 --> 1.137179).  Saving model ...
Validation loss decreased (1.137179 --> 1.134156).  Saving model ...
Validation loss decreased (1.134156 --> 1.130756).  Saving model ...
Validation loss decreased (1.130756 --> 1.125356).  Saving model ...
Validation loss decreased (1.125356 --> 1.120109).  Saving model ...
Validation loss decreased (1.120109 --> 1.117292).  Saving model ...
Validation loss decreased (1.117292 --> 1.112945).  Saving model ...
Validation loss decreased (1.112945 --> 1.109079).  Saving model ...
Validation loss decreased (1.109079 --> 1.105831).  Saving model ...
Validation loss decreased (1.105831 --> 1.100185).  Saving model ...
Validation loss decreased (1.100185 --> 1.095979).  Saving model ...
Validation loss decreased (1.095979 --> 1.090696).  Saving model ...
Validation loss decreased (1.090696 --> 1.086962).  Saving model ...
Validation loss decreased (1.086962 --> 1.085998).  Saving model ...
Validation loss decreased (1.085998 --> 1.082645).  Saving model ...
Validation loss decreased (1.082645 --> 1.080462).  Saving model ...
Validation loss decreased (1.080462 --> 1.077956).  Saving model ...
Validation loss decreased (1.077956 --> 1.073260).  Saving model ...
Validation loss decreased (1.073260 --> 1.072747).  Saving model ...
Validation loss decreased (1.072747 --> 1.071362).  Saving model ...
Validation loss decreased (1.071362 --> 1.069358).  Saving model ...
Validation loss decreased (1.069358 --> 1.064137).  Saving model ...
Validation loss decreased (1.064137 --> 1.062307).  Saving model ...
Validation loss decreased (1.062307 --> 1.060420).  Saving model ...
Validation loss decreased (1.060420 --> 1.055827).  Saving model ...
Validation loss decreased (1.055827 --> 1.055073).  Saving model ...
Validation loss decreased (1.055073 --> 1.054841).  Saving model ...
Validation loss decreased (1.054841 --> 1.051524).  Saving model ...
Validation loss decreased (1.051524 --> 1.046707).  Saving model ...
Validation loss decreased (1.046707 --> 1.045170).  Saving model ...
Validation loss decreased (1.045170 --> 1.041382).  Saving model ...
Validation loss decreased (1.041382 --> 1.038693).  Saving model ...
Validation loss decreased (1.038693 --> 1.034640).  Saving model ...
Validation loss decreased (1.034640 --> 1.033413).  Saving model ...
Validation loss decreased (1.033413 --> 1.031635).  Saving model ...
EarlyStopping counter: 1 out of 5.0
Validation loss decreased (1.031635 --> 1.030768).  Saving model ...
Validation loss decreased (1.030768 --> 1.025036).  Saving model ...
EarlyStopping counter: 1 out of 5.0
Validation loss decreased (1.025036 --> 1.024246).  Saving model ...
Validation loss decreased (1.024246 --> 1.020912).  Saving model ...
Validation loss decreased (1.020912 --> 1.019065).  Saving model ...
Validation loss decreased (1.019065 --> 1.018093).  Saving model ...
Validation loss decreased (1.018093 --> 1.013402).  Saving model ...
Validation loss decreased (1.013402 --> 1.010681).  Saving model ...
Validation loss decreased (1.010681 --> 1.010309).  Saving model ...
EarlyStopping counter: 1 out of 5.0
EarlyStopping counter: 2 out of 5.0
Validation loss decreased (1.010309 --> 1.008136).  Saving model ...
Validation loss decreased (1.008136 --> 1.007944).  Saving model ...
Validation loss decreased (1.007944 --> 1.006597).  Saving model ...
Validation loss decreased (1.006597 --> 1.004391).  Saving model ...
EarlyStopping counter: 1 out of 5.0
EarlyStopping counter: 2 out of 5.0
Validation loss decreased (1.004391 --> 1.001653).  Saving model ...
Validation loss decreased (1.001653 --> 1.001614).  Saving model ...
Validation loss decreased (1.001614 --> 1.000610).  Saving model ...
Validation loss decreased (1.000610 --> 0.998616).  Saving model ...
EarlyStopping counter: 1 out of 5.0
EarlyStopping counter: 2 out of 5.0
EarlyStopping counter: 3 out of 5.0
Validation loss decreased (0.998616 --> 0.996599).  Saving model ...
EarlyStopping counter: 1 out of 5.0
EarlyStopping counter: 2 out of 5.0
Validation loss decreased (0.996599 --> 0.996482).  Saving model ...
Validation loss decreased (0.996482 --> 0.995976).  Saving model ...
Validation loss decreased (0.995976 --> 0.995883).  Saving model ...
Validation loss decreased (0.995883 --> 0.992848).  Saving model ...
Validation loss decreased (0.992848 --> 0.991446).  Saving model ...
EarlyStopping counter: 1 out of 5.0
EarlyStopping counter: 2 out of 5.0
EarlyStopping counter: 3 out of 5.0
EarlyStopping counter: 4 out of 5.0
EarlyStopping counter: 5 out of 5.0
/localscratch/yinan.29351708.0/env/lib/python3.7/site-packages/torch/nn/functional.py:1794: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.
  warnings.warn("nn.functional.tanh is deprecated. Use torch.tanh instead.")
/localscratch/yinan.29351708.0/env/lib/python3.7/site-packages/transformers/optimization.py:155: UserWarning: This overload of add_ is deprecated:
	add_(Number alpha, Tensor other)
Consider using one of the following signatures instead:
	add_(Tensor other, *, Number alpha) (Triggered internally at  ../torch/csrc/utils/python_arg_parser.cpp:1025.)
  exp_avg.mul_(beta1).add_(1.0 - beta1, grad)
wandb: Waiting for W&B process to finish, PID 78047... (success).
wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: \ 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: | 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: / 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: \ 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: | 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: / 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: \ 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: | 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: / 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb:                                                                                
wandb: Run history:
wandb:     e_F1 ▁▂▃▄▅▅▅▅▆▆▆▆▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇█████████████
wandb:   e_loss █▇▇▇▆▆▆▅▅▅▄▄▄▄▃▃▃▃▃▂▂▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁
wandb:     t_F1 ▁▂▃▂▃▃▄▄▄▅▅▅▅▅▆▆▆▆▇▆▇▆▆▇▇▇▇▇▇▇▇▇▇█▇█████
wandb:   t_loss ██▇▇▇▇▆▆▆▆▅▅▅▅▄▄▄▄▃▄▃▃▃▃▃▃▂▂▂▂▂▂▂▂▂▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:     e_F1 57.57366
wandb:   e_loss 0.99433
wandb:     t_F1 69.32004
wandb:   t_loss 0.77627
wandb: 
wandb: Synced 4 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Synced crisp-bee-3: https://wandb.ai/yinanazhou/xl_512_bs_8_lr_1e06_es_5_lc_False_nr_False_sr_True_stem_False_lemma_True_repeat_1_fold_1/runs/1bnq8pcj
wandb: Find logs at: ./wandb/run-20220328_055111-1bnq8pcj/logs/debug.log
wandb: 

wandb: wandb version 0.12.11 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
2022-03-28 07:06:10.781520: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1
wandb: Tracking run with wandb version 0.12.5
wandb: Syncing run frosty-hill-3
wandb: ⭐️ View project at https://wandb.ai/yinanazhou/xl_512_bs_8_lr_1e06_es_5_lc_False_nr_False_sr_True_stem_False_lemma_True_repeat_1_fold_2
wandb: 🚀 View run at https://wandb.ai/yinanazhou/xl_512_bs_8_lr_1e06_es_5_lc_False_nr_False_sr_True_stem_False_lemma_True_repeat_1_fold_2/runs/tngcrhsm
wandb: Run data is saved locally in /project/6002780/yinan/Thesis_MER_Lyrics/lyric-emotion/wandb/run-20220328_070607-tngcrhsm
wandb: Run `wandb offline` to turn off syncing.

Validation loss decreased (inf --> 1.413924).  Saving model ...
Validation loss decreased (1.413924 --> 1.401458).  Saving model ...
Validation loss decreased (1.401458 --> 1.392931).  Saving model ...
Validation loss decreased (1.392931 --> 1.386047).  Saving model ...
Validation loss decreased (1.386047 --> 1.379667).  Saving model ...
Validation loss decreased (1.379667 --> 1.374090).  Saving model ...
Validation loss decreased (1.374090 --> 1.369460).  Saving model ...
Validation loss decreased (1.369460 --> 1.364705).  Saving model ...
Validation loss decreased (1.364705 --> 1.360164).  Saving model ...
Validation loss decreased (1.360164 --> 1.355700).  Saving model ...
Validation loss decreased (1.355700 --> 1.351435).  Saving model ...
Validation loss decreased (1.351435 --> 1.347007).  Saving model ...
Validation loss decreased (1.347007 --> 1.342512).  Saving model ...
Validation loss decreased (1.342512 --> 1.337873).  Saving model ...
Validation loss decreased (1.337873 --> 1.333802).  Saving model ...
Validation loss decreased (1.333802 --> 1.329244).  Saving model ...
Validation loss decreased (1.329244 --> 1.324075).  Saving model ...
Validation loss decreased (1.324075 --> 1.318596).  Saving model ...
Validation loss decreased (1.318596 --> 1.312774).  Saving model ...
Validation loss decreased (1.312774 --> 1.307461).  Saving model ...
Validation loss decreased (1.307461 --> 1.301400).  Saving model ...
Validation loss decreased (1.301400 --> 1.295471).  Saving model ...
Validation loss decreased (1.295471 --> 1.288426).  Saving model ...
Validation loss decreased (1.288426 --> 1.281646).  Saving model ...
Validation loss decreased (1.281646 --> 1.275509).  Saving model ...
Validation loss decreased (1.275509 --> 1.267342).  Saving model ...
Validation loss decreased (1.267342 --> 1.260288).  Saving model ...
Validation loss decreased (1.260288 --> 1.252257).  Saving model ...
Validation loss decreased (1.252257 --> 1.244083).  Saving model ...
Validation loss decreased (1.244083 --> 1.236040).  Saving model ...
Validation loss decreased (1.236040 --> 1.225895).  Saving model ...
Validation loss decreased (1.225895 --> 1.215969).  Saving model ...
Validation loss decreased (1.215969 --> 1.207977).  Saving model ...
Validation loss decreased (1.207977 --> 1.198711).  Saving model ...
Validation loss decreased (1.198711 --> 1.190366).  Saving model ...
Validation loss decreased (1.190366 --> 1.181246).  Saving model ...
Validation loss decreased (1.181246 --> 1.173247).  Saving model ...
Validation loss decreased (1.173247 --> 1.165383).  Saving model ...
Validation loss decreased (1.165383 --> 1.157702).  Saving model ...
Validation loss decreased (1.157702 --> 1.149707).  Saving model ...
Validation loss decreased (1.149707 --> 1.142947).  Saving model ...
Validation loss decreased (1.142947 --> 1.137298).  Saving model ...
Validation loss decreased (1.137298 --> 1.131568).  Saving model ...
Validation loss decreased (1.131568 --> 1.125561).  Saving model ...
Validation loss decreased (1.125561 --> 1.119115).  Saving model ...
Validation loss decreased (1.119115 --> 1.113486).  Saving model ...
Validation loss decreased (1.113486 --> 1.106745).  Saving model ...
Validation loss decreased (1.106745 --> 1.101928).  Saving model ...
Validation loss decreased (1.101928 --> 1.095698).  Saving model ...
Validation loss decreased (1.095698 --> 1.090333).  Saving model ...
Validation loss decreased (1.090333 --> 1.084211).  Saving model ...
Validation loss decreased (1.084211 --> 1.078207).  Saving model ...
Validation loss decreased (1.078207 --> 1.071191).  Saving model ...
Validation loss decreased (1.071191 --> 1.067130).  Saving model ...
Validation loss decreased (1.067130 --> 1.061682).  Saving model ...
Validation loss decreased (1.061682 --> 1.057861).  Saving model ...
Validation loss decreased (1.057861 --> 1.053094).  Saving model ...
Validation loss decreased (1.053094 --> 1.048247).  Saving model ...
Validation loss decreased (1.048247 --> 1.042603).  Saving model ...
Validation loss decreased (1.042603 --> 1.037966).  Saving model ...
Validation loss decreased (1.037966 --> 1.033709).  Saving model ...
Validation loss decreased (1.033709 --> 1.029552).  Saving model ...
Validation loss decreased (1.029552 --> 1.025264).  Saving model ...
Validation loss decreased (1.025264 --> 1.021237).  Saving model ...
Validation loss decreased (1.021237 --> 1.018856).  Saving model ...
Validation loss decreased (1.018856 --> 1.012170).  Saving model ...
Validation loss decreased (1.012170 --> 1.009115).  Saving model ...
Validation loss decreased (1.009115 --> 1.005724).  Saving model ...
Validation loss decreased (1.005724 --> 1.002747).  Saving model ...
Validation loss decreased (1.002747 --> 0.998883).  Saving model ...
Validation loss decreased (0.998883 --> 0.997012).  Saving model ...
Validation loss decreased (0.997012 --> 0.993441).  Saving model ...
Validation loss decreased (0.993441 --> 0.991937).  Saving model ...
Validation loss decreased (0.991937 --> 0.990032).  Saving model ...
Validation loss decreased (0.990032 --> 0.985196).  Saving model ...
Validation loss decreased (0.985196 --> 0.981892).  Saving model ...
Validation loss decreased (0.981892 --> 0.979845).  Saving model ...
Validation loss decreased (0.979845 --> 0.977568).  Saving model ...
Validation loss decreased (0.977568 --> 0.975080).  Saving model ...
Validation loss decreased (0.975080 --> 0.972121).  Saving model ...
Validation loss decreased (0.972121 --> 0.969184).  Saving model ...
Validation loss decreased (0.969184 --> 0.966887).  Saving model ...
Validation loss decreased (0.966887 --> 0.964430).  Saving model ...
Validation loss decreased (0.964430 --> 0.961204).  Saving model ...
Validation loss decreased (0.961204 --> 0.959244).  Saving model ...
Validation loss decreased (0.959244 --> 0.956382).  Saving model ...
Validation loss decreased (0.956382 --> 0.954094).  Saving model ...
Validation loss decreased (0.954094 --> 0.954024).  Saving model ...
Validation loss decreased (0.954024 --> 0.953021).  Saving model ...
Validation loss decreased (0.953021 --> 0.951515).  Saving model ...
Validation loss decreased (0.951515 --> 0.950458).  Saving model ...
Validation loss decreased (0.950458 --> 0.946953).  Saving model ...
Validation loss decreased (0.946953 --> 0.946387).  Saving model ...
Validation loss decreased (0.946387 --> 0.945566).  Saving model ...
Validation loss decreased (0.945566 --> 0.943429).  Saving model ...
EarlyStopping counter: 1 out of 5.0
EarlyStopping counter: 2 out of 5.0
EarlyStopping counter: 3 out of 5.0
Validation loss decreased (0.943429 --> 0.941730).  Saving model ...
Validation loss decreased (0.941730 --> 0.940531).  Saving model ...
Validation loss decreased (0.940531 --> 0.937019).  Saving model ...
Validation loss decreased (0.937019 --> 0.936792).  Saving model ...
Validation loss decreased (0.936792 --> 0.934950).  Saving model ...
EarlyStopping counter: 1 out of 5.0
EarlyStopping counter: 2 out of 5.0
EarlyStopping counter: 3 out of 5.0
EarlyStopping counter: 4 out of 5.0
Validation loss decreased (0.934950 --> 0.932082).  Saving model ...
EarlyStopping counter: 1 out of 5.0
EarlyStopping counter: 2 out of 5.0
Validation loss decreased (0.932082 --> 0.930562).  Saving model ...
EarlyStopping counter: 1 out of 5.0
EarlyStopping counter: 2 out of 5.0
EarlyStopping counter: 3 out of 5.0
EarlyStopping counter: 4 out of 5.0
EarlyStopping counter: 5 out of 5.0
/localscratch/yinan.29351708.0/env/lib/python3.7/site-packages/torch/nn/functional.py:1794: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.
  warnings.warn("nn.functional.tanh is deprecated. Use torch.tanh instead.")
wandb: Waiting for W&B process to finish, PID 82200... (success).
wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: \ 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: | 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: / 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: \ 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: | 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: / 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: \ 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: | 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: / 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb:                                                                                
wandb: Run history:
wandb:     e_F1 ▁▂▃▃▄▅▅▅▆▆▆▇▇▇▇▇▇███████████████████████
wandb:   e_loss ██▇▇▇▇▇▆▆▆▅▅▅▄▄▄▃▃▃▃▃▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁
wandb:     t_F1 ▁▁▂▂▃▃▃▃▄▄▄▅▅▅▅▆▆▆▆▆▆▆▇▇▇▇▇▇▇▇█▇▇███████
wandb:   t_loss ███▇▇▇▇▇▇▆▆▆▆▅▅▅▄▄▄▄▄▄▄▃▃▃▃▂▃▃▂▂▂▂▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:     e_F1 59.26193
wandb:   e_loss 0.93147
wandb:     t_F1 69.40268
wandb:   t_loss 0.80746
wandb: 
wandb: Synced 4 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Synced frosty-hill-3: https://wandb.ai/yinanazhou/xl_512_bs_8_lr_1e06_es_5_lc_False_nr_False_sr_True_stem_False_lemma_True_repeat_1_fold_2/runs/tngcrhsm
wandb: Find logs at: ./wandb/run-20220328_070607-tngcrhsm/logs/debug.log
wandb: 

wandb: wandb version 0.12.11 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
2022-03-28 08:23:15.598902: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1
wandb: Tracking run with wandb version 0.12.5
wandb: Syncing run lyric-water-3
wandb: ⭐️ View project at https://wandb.ai/yinanazhou/xl_512_bs_8_lr_1e06_es_5_lc_False_nr_False_sr_True_stem_False_lemma_True_repeat_2_fold_1
wandb: 🚀 View run at https://wandb.ai/yinanazhou/xl_512_bs_8_lr_1e06_es_5_lc_False_nr_False_sr_True_stem_False_lemma_True_repeat_2_fold_1/runs/1314mbvm
wandb: Run data is saved locally in /project/6002780/yinan/Thesis_MER_Lyrics/lyric-emotion/wandb/run-20220328_082311-1314mbvm
wandb: Run `wandb offline` to turn off syncing.

Validation loss decreased (inf --> 1.483851).  Saving model ...
Validation loss decreased (1.483851 --> 1.454954).  Saving model ...
Validation loss decreased (1.454954 --> 1.433867).  Saving model ...
Validation loss decreased (1.433867 --> 1.417027).  Saving model ...
Validation loss decreased (1.417027 --> 1.404399).  Saving model ...
Validation loss decreased (1.404399 --> 1.393990).  Saving model ...
Validation loss decreased (1.393990 --> 1.385782).  Saving model ...
Validation loss decreased (1.385782 --> 1.379006).  Saving model ...
Validation loss decreased (1.379006 --> 1.372939).  Saving model ...
Validation loss decreased (1.372939 --> 1.367300).  Saving model ...
Validation loss decreased (1.367300 --> 1.362055).  Saving model ...
Validation loss decreased (1.362055 --> 1.356308).  Saving model ...
Validation loss decreased (1.356308 --> 1.350164).  Saving model ...
Validation loss decreased (1.350164 --> 1.344485).  Saving model ...
Validation loss decreased (1.344485 --> 1.338632).  Saving model ...
Validation loss decreased (1.338632 --> 1.332695).  Saving model ...
Validation loss decreased (1.332695 --> 1.326820).  Saving model ...
Validation loss decreased (1.326820 --> 1.319700).  Saving model ...
Validation loss decreased (1.319700 --> 1.312587).  Saving model ...
Validation loss decreased (1.312587 --> 1.304591).  Saving model ...
Validation loss decreased (1.304591 --> 1.295962).  Saving model ...
Validation loss decreased (1.295962 --> 1.287033).  Saving model ...
Validation loss decreased (1.287033 --> 1.279047).  Saving model ...
Validation loss decreased (1.279047 --> 1.271588).  Saving model ...
Validation loss decreased (1.271588 --> 1.264877).  Saving model ...
Validation loss decreased (1.264877 --> 1.254220).  Saving model ...
Validation loss decreased (1.254220 --> 1.245937).  Saving model ...
Validation loss decreased (1.245937 --> 1.237062).  Saving model ...
Validation loss decreased (1.237062 --> 1.230333).  Saving model ...
Validation loss decreased (1.230333 --> 1.220085).  Saving model ...
Validation loss decreased (1.220085 --> 1.213038).  Saving model ...
Validation loss decreased (1.213038 --> 1.205548).  Saving model ...
Validation loss decreased (1.205548 --> 1.199014).  Saving model ...
Validation loss decreased (1.199014 --> 1.192646).  Saving model ...
Validation loss decreased (1.192646 --> 1.184911).  Saving model ...
Validation loss decreased (1.184911 --> 1.176069).  Saving model ...
Validation loss decreased (1.176069 --> 1.168243).  Saving model ...
Validation loss decreased (1.168243 --> 1.163780).  Saving model ...
Validation loss decreased (1.163780 --> 1.158748).  Saving model ...
Validation loss decreased (1.158748 --> 1.151820).  Saving model ...
Validation loss decreased (1.151820 --> 1.143591).  Saving model ...
Validation loss decreased (1.143591 --> 1.137841).  Saving model ...
Validation loss decreased (1.137841 --> 1.129613).  Saving model ...
Validation loss decreased (1.129613 --> 1.123309).  Saving model ...
Validation loss decreased (1.123309 --> 1.121123).  Saving model ...
Validation loss decreased (1.121123 --> 1.115776).  Saving model ...
Validation loss decreased (1.115776 --> 1.111210).  Saving model ...
Validation loss decreased (1.111210 --> 1.104359).  Saving model ...
Validation loss decreased (1.104359 --> 1.096330).  Saving model ...
Validation loss decreased (1.096330 --> 1.093598).  Saving model ...
Validation loss decreased (1.093598 --> 1.088193).  Saving model ...
Validation loss decreased (1.088193 --> 1.082333).  Saving model ...
Validation loss decreased (1.082333 --> 1.077174).  Saving model ...
Validation loss decreased (1.077174 --> 1.074248).  Saving model ...
Validation loss decreased (1.074248 --> 1.069057).  Saving model ...
Validation loss decreased (1.069057 --> 1.064335).  Saving model ...
Validation loss decreased (1.064335 --> 1.060663).  Saving model ...
Validation loss decreased (1.060663 --> 1.056455).  Saving model ...
Validation loss decreased (1.056455 --> 1.050081).  Saving model ...
Validation loss decreased (1.050081 --> 1.047537).  Saving model ...
Validation loss decreased (1.047537 --> 1.045242).  Saving model ...
Validation loss decreased (1.045242 --> 1.039294).  Saving model ...
Validation loss decreased (1.039294 --> 1.036921).  Saving model ...
Validation loss decreased (1.036921 --> 1.033563).  Saving model ...
Validation loss decreased (1.033563 --> 1.033449).  Saving model ...
Validation loss decreased (1.033449 --> 1.028833).  Saving model ...
Validation loss decreased (1.028833 --> 1.027465).  Saving model ...
Validation loss decreased (1.027465 --> 1.023330).  Saving model ...
Validation loss decreased (1.023330 --> 1.018938).  Saving model ...
Validation loss decreased (1.018938 --> 1.013790).  Saving model ...
Validation loss decreased (1.013790 --> 1.009649).  Saving model ...
Validation loss decreased (1.009649 --> 1.007198).  Saving model ...
Validation loss decreased (1.007198 --> 1.005124).  Saving model ...
Validation loss decreased (1.005124 --> 1.003251).  Saving model ...
Validation loss decreased (1.003251 --> 1.001120).  Saving model ...
Validation loss decreased (1.001120 --> 0.998172).  Saving model ...
Validation loss decreased (0.998172 --> 0.993284).  Saving model ...
Validation loss decreased (0.993284 --> 0.990854).  Saving model ...
Validation loss decreased (0.990854 --> 0.988805).  Saving model ...
Validation loss decreased (0.988805 --> 0.987993).  Saving model ...
Validation loss decreased (0.987993 --> 0.983825).  Saving model ...
Validation loss decreased (0.983825 --> 0.983368).  Saving model ...
Validation loss decreased (0.983368 --> 0.980959).  Saving model ...
Validation loss decreased (0.980959 --> 0.976838).  Saving model ...
Validation loss decreased (0.976838 --> 0.974577).  Saving model ...
EarlyStopping counter: 1 out of 5.0
Validation loss decreased (0.974577 --> 0.973092).  Saving model ...
Validation loss decreased (0.973092 --> 0.970540).  Saving model ...
Validation loss decreased (0.970540 --> 0.968861).  Saving model ...
Validation loss decreased (0.968861 --> 0.968673).  Saving model ...
Validation loss decreased (0.968673 --> 0.965981).  Saving model ...
Validation loss decreased (0.965981 --> 0.963726).  Saving model ...
EarlyStopping counter: 1 out of 5.0
Validation loss decreased (0.963726 --> 0.963079).  Saving model ...
Validation loss decreased (0.963079 --> 0.962320).  Saving model ...
Validation loss decreased (0.962320 --> 0.961508).  Saving model ...
Validation loss decreased (0.961508 --> 0.960146).  Saving model ...
Validation loss decreased (0.960146 --> 0.956493).  Saving model ...
EarlyStopping counter: 1 out of 5.0
Validation loss decreased (0.956493 --> 0.955209).  Saving model ...
Validation loss decreased (0.955209 --> 0.953484).  Saving model ...
Validation loss decreased (0.953484 --> 0.952843).  Saving model ...
Validation loss decreased (0.952843 --> 0.950706).  Saving model ...
Validation loss decreased (0.950706 --> 0.950641).  Saving model ...
Validation loss decreased (0.950641 --> 0.950590).  Saving model ...
Validation loss decreased (0.950590 --> 0.950058).  Saving model ...
Validation loss decreased (0.950058 --> 0.947953).  Saving model ...
EarlyStopping counter: 1 out of 5.0
Validation loss decreased (0.947953 --> 0.947406).  Saving model ...
Validation loss decreased (0.947406 --> 0.946116).  Saving model ...
EarlyStopping counter: 1 out of 5.0
Validation loss decreased (0.946116 --> 0.945832).  Saving model ...
Validation loss decreased (0.945832 --> 0.945817).  Saving model ...
Validation loss decreased (0.945817 --> 0.944551).  Saving model ...
Validation loss decreased (0.944551 --> 0.943920).  Saving model ...
EarlyStopping counter: 1 out of 5.0
EarlyStopping counter: 2 out of 5.0
EarlyStopping counter: 3 out of 5.0
EarlyStopping counter: 4 out of 5.0
EarlyStopping counter: 5 out of 5.0
/localscratch/yinan.29351708.0/env/lib/python3.7/site-packages/torch/nn/functional.py:1794: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.
  warnings.warn("nn.functional.tanh is deprecated. Use torch.tanh instead.")
wandb: Waiting for W&B process to finish, PID 86422... (success).
wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: \ 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: | 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: / 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: \ 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: | 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: / 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: \ 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: | 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: / 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb:                                                                                
wandb: Run history:
wandb:     e_F1 ▁▁▃▄▄▄▄▅▅▅▆▆▆▆▇▇▇▇▇▇▇▇▇▇█▇██████████████
wandb:   e_loss █▇▇▆▆▆▆▅▅▅▄▄▄▄▃▃▃▃▃▂▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:     t_F1 ▁▂▃▃▃▄▄▄▄▄▅▅▆▆▆▆▆▆▆▇▆▇▇▇▇▇▇▇▇▇▇█▇▇██████
wandb:   t_loss █▇▇▇▆▆▆▆▆▆▅▅▅▅▄▄▄▄▄▃▃▃▃▃▃▂▂▂▂▂▂▂▂▂▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:     e_F1 59.59623
wandb:   e_loss 0.94445
wandb:     t_F1 70.614
wandb:   t_loss 0.77907
wandb: 
wandb: Synced 4 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Synced lyric-water-3: https://wandb.ai/yinanazhou/xl_512_bs_8_lr_1e06_es_5_lc_False_nr_False_sr_True_stem_False_lemma_True_repeat_2_fold_1/runs/1314mbvm
wandb: Find logs at: ./wandb/run-20220328_082311-1314mbvm/logs/debug.log
wandb: 

wandb: wandb version 0.12.11 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
2022-03-28 09:42:54.997371: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1
wandb: Tracking run with wandb version 0.12.5
wandb: Syncing run solar-morning-2
wandb: ⭐️ View project at https://wandb.ai/yinanazhou/xl_512_bs_8_lr_1e06_es_5_lc_False_nr_False_sr_True_stem_False_lemma_True_repeat_2_fold_2
wandb: 🚀 View run at https://wandb.ai/yinanazhou/xl_512_bs_8_lr_1e06_es_5_lc_False_nr_False_sr_True_stem_False_lemma_True_repeat_2_fold_2/runs/3cgbqo75
wandb: Run data is saved locally in /project/6002780/yinan/Thesis_MER_Lyrics/lyric-emotion/wandb/run-20220328_094252-3cgbqo75
wandb: Run `wandb offline` to turn off syncing.

Validation loss decreased (inf --> 1.407967).  Saving model ...
Validation loss decreased (1.407967 --> 1.392985).  Saving model ...
Validation loss decreased (1.392985 --> 1.382383).  Saving model ...
Validation loss decreased (1.382383 --> 1.374960).  Saving model ...
Validation loss decreased (1.374960 --> 1.368815).  Saving model ...
Validation loss decreased (1.368815 --> 1.363890).  Saving model ...
Validation loss decreased (1.363890 --> 1.359950).  Saving model ...
Validation loss decreased (1.359950 --> 1.356030).  Saving model ...
Validation loss decreased (1.356030 --> 1.351862).  Saving model ...
Validation loss decreased (1.351862 --> 1.347826).  Saving model ...
Validation loss decreased (1.347826 --> 1.343856).  Saving model ...
Validation loss decreased (1.343856 --> 1.339579).  Saving model ...
Validation loss decreased (1.339579 --> 1.335147).  Saving model ...
Validation loss decreased (1.335147 --> 1.330975).  Saving model ...
Validation loss decreased (1.330975 --> 1.325794).  Saving model ...
Validation loss decreased (1.325794 --> 1.320957).  Saving model ...
Validation loss decreased (1.320957 --> 1.315909).  Saving model ...
Validation loss decreased (1.315909 --> 1.311031).  Saving model ...
Validation loss decreased (1.311031 --> 1.305417).  Saving model ...
Validation loss decreased (1.305417 --> 1.300463).  Saving model ...
Validation loss decreased (1.300463 --> 1.294216).  Saving model ...
Validation loss decreased (1.294216 --> 1.286739).  Saving model ...
Validation loss decreased (1.286739 --> 1.281540).  Saving model ...
Validation loss decreased (1.281540 --> 1.277048).  Saving model ...
Validation loss decreased (1.277048 --> 1.270474).  Saving model ...
Validation loss decreased (1.270474 --> 1.264530).  Saving model ...
Validation loss decreased (1.264530 --> 1.257739).  Saving model ...
Validation loss decreased (1.257739 --> 1.253151).  Saving model ...
Validation loss decreased (1.253151 --> 1.246222).  Saving model ...
Validation loss decreased (1.246222 --> 1.239843).  Saving model ...
Validation loss decreased (1.239843 --> 1.233239).  Saving model ...
Validation loss decreased (1.233239 --> 1.226883).  Saving model ...
Validation loss decreased (1.226883 --> 1.219351).  Saving model ...
Validation loss decreased (1.219351 --> 1.212916).  Saving model ...
Validation loss decreased (1.212916 --> 1.207014).  Saving model ...
Validation loss decreased (1.207014 --> 1.196368).  Saving model ...
Validation loss decreased (1.196368 --> 1.187638).  Saving model ...
Validation loss decreased (1.187638 --> 1.178872).  Saving model ...
Validation loss decreased (1.178872 --> 1.169569).  Saving model ...
Validation loss decreased (1.169569 --> 1.162523).  Saving model ...
Validation loss decreased (1.162523 --> 1.156086).  Saving model ...
Validation loss decreased (1.156086 --> 1.148863).  Saving model ...
Validation loss decreased (1.148863 --> 1.141172).  Saving model ...
Validation loss decreased (1.141172 --> 1.135680).  Saving model ...
Validation loss decreased (1.135680 --> 1.127594).  Saving model ...
Validation loss decreased (1.127594 --> 1.124240).  Saving model ...
Validation loss decreased (1.124240 --> 1.118002).  Saving model ...
Validation loss decreased (1.118002 --> 1.112117).  Saving model ...
Validation loss decreased (1.112117 --> 1.104487).  Saving model ...
Validation loss decreased (1.104487 --> 1.098639).  Saving model ...
Validation loss decreased (1.098639 --> 1.091781).  Saving model ...
Validation loss decreased (1.091781 --> 1.086658).  Saving model ...
Validation loss decreased (1.086658 --> 1.080881).  Saving model ...
Validation loss decreased (1.080881 --> 1.075403).  Saving model ...
Validation loss decreased (1.075403 --> 1.071371).  Saving model ...
Validation loss decreased (1.071371 --> 1.068479).  Saving model ...
Validation loss decreased (1.068479 --> 1.065467).  Saving model ...
Validation loss decreased (1.065467 --> 1.059929).  Saving model ...
Validation loss decreased (1.059929 --> 1.055468).  Saving model ...
Validation loss decreased (1.055468 --> 1.052447).  Saving model ...
Validation loss decreased (1.052447 --> 1.047964).  Saving model ...
Validation loss decreased (1.047964 --> 1.044540).  Saving model ...
Validation loss decreased (1.044540 --> 1.039959).  Saving model ...
Validation loss decreased (1.039959 --> 1.034107).  Saving model ...
Validation loss decreased (1.034107 --> 1.031560).  Saving model ...
Validation loss decreased (1.031560 --> 1.028767).  Saving model ...
Validation loss decreased (1.028767 --> 1.024662).  Saving model ...
Validation loss decreased (1.024662 --> 1.021566).  Saving model ...
Validation loss decreased (1.021566 --> 1.019427).  Saving model ...
Validation loss decreased (1.019427 --> 1.017821).  Saving model ...
Validation loss decreased (1.017821 --> 1.013449).  Saving model ...
Validation loss decreased (1.013449 --> 1.009852).  Saving model ...
Validation loss decreased (1.009852 --> 1.005786).  Saving model ...
Validation loss decreased (1.005786 --> 1.004658).  Saving model ...
Validation loss decreased (1.004658 --> 1.000762).  Saving model ...
Validation loss decreased (1.000762 --> 0.998519).  Saving model ...
Validation loss decreased (0.998519 --> 0.994676).  Saving model ...
Validation loss decreased (0.994676 --> 0.991581).  Saving model ...
Validation loss decreased (0.991581 --> 0.989228).  Saving model ...
Validation loss decreased (0.989228 --> 0.985801).  Saving model ...
Validation loss decreased (0.985801 --> 0.985484).  Saving model ...
Validation loss decreased (0.985484 --> 0.983237).  Saving model ...
Validation loss decreased (0.983237 --> 0.979406).  Saving model ...
Validation loss decreased (0.979406 --> 0.978235).  Saving model ...
Validation loss decreased (0.978235 --> 0.973959).  Saving model ...
Validation loss decreased (0.973959 --> 0.969529).  Saving model ...
Validation loss decreased (0.969529 --> 0.969438).  Saving model ...
EarlyStopping counter: 1 out of 5.0
Validation loss decreased (0.969438 --> 0.967406).  Saving model ...
Validation loss decreased (0.967406 --> 0.964223).  Saving model ...
Validation loss decreased (0.964223 --> 0.962486).  Saving model ...
Validation loss decreased (0.962486 --> 0.961079).  Saving model ...
Validation loss decreased (0.961079 --> 0.960498).  Saving model ...
Validation loss decreased (0.960498 --> 0.958578).  Saving model ...
Validation loss decreased (0.958578 --> 0.958104).  Saving model ...
Validation loss decreased (0.958104 --> 0.956329).  Saving model ...
Validation loss decreased (0.956329 --> 0.954820).  Saving model ...
EarlyStopping counter: 1 out of 5.0
Validation loss decreased (0.954820 --> 0.953388).  Saving model ...
Validation loss decreased (0.953388 --> 0.950703).  Saving model ...
Validation loss decreased (0.950703 --> 0.949402).  Saving model ...
Validation loss decreased (0.949402 --> 0.946343).  Saving model ...
Validation loss decreased (0.946343 --> 0.945058).  Saving model ...
Validation loss decreased (0.945058 --> 0.943426).  Saving model ...
Validation loss decreased (0.943426 --> 0.943356).  Saving model ...
Validation loss decreased (0.943356 --> 0.941046).  Saving model ...
Validation loss decreased (0.941046 --> 0.940294).  Saving model ...
Validation loss decreased (0.940294 --> 0.940057).  Saving model ...
EarlyStopping counter: 1 out of 5.0
EarlyStopping counter: 2 out of 5.0
EarlyStopping counter: 3 out of 5.0
Validation loss decreased (0.940057 --> 0.938962).  Saving model ...
Validation loss decreased (0.938962 --> 0.936110).  Saving model ...
Validation loss decreased (0.936110 --> 0.935208).  Saving model ...
Validation loss decreased (0.935208 --> 0.934461).  Saving model ...
Validation loss decreased (0.934461 --> 0.934446).  Saving model ...
Validation loss decreased (0.934446 --> 0.932870).  Saving model ...
Validation loss decreased (0.932870 --> 0.931330).  Saving model ...
Validation loss decreased (0.931330 --> 0.930506).  Saving model ...
EarlyStopping counter: 1 out of 5.0
EarlyStopping counter: 2 out of 5.0
Validation loss decreased (0.930506 --> 0.930121).  Saving model ...
Validation loss decreased (0.930121 --> 0.929946).  Saving model ...
EarlyStopping counter: 1 out of 5.0
Validation loss decreased (0.929946 --> 0.929333).  Saving model ...
Validation loss decreased (0.929333 --> 0.927822).  Saving model ...
EarlyStopping counter: 1 out of 5.0
EarlyStopping counter: 2 out of 5.0
EarlyStopping counter: 3 out of 5.0
EarlyStopping counter: 4 out of 5.0
Validation loss decreased (0.927822 --> 0.925745).  Saving model ...
Validation loss decreased (0.925745 --> 0.924759).  Saving model ...
EarlyStopping counter: 1 out of 5.0
EarlyStopping counter: 2 out of 5.0
EarlyStopping counter: 3 out of 5.0
Validation loss decreased (0.924759 --> 0.924561).  Saving model ...
EarlyStopping counter: 1 out of 5.0
EarlyStopping counter: 2 out of 5.0
EarlyStopping counter: 3 out of 5.0
EarlyStopping counter: 4 out of 5.0
EarlyStopping counter: 5 out of 5.0
/localscratch/yinan.29351708.0/env/lib/python3.7/site-packages/torch/nn/functional.py:1794: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.
  warnings.warn("nn.functional.tanh is deprecated. Use torch.tanh instead.")
wandb: Waiting for W&B process to finish, PID 90824... (success).
wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: \ 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: | 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: / 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: \ 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: | 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: / 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: \ 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: | 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: / 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb:                                                                                
wandb: Run history:
wandb:     e_F1 ▁▃▄▄▄▄▄▄▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇███████
wandb:   e_loss ██▇▇▇▇▆▆▆▆▅▅▄▄▄▃▃▃▃▂▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:     t_F1 ▁▂▂▂▃▃▄▄▄▅▅▅▆▅▅▆▆▆▇▆▆▇▆▇▇▇▇▇▇█▇▇███▇████
wandb:   t_loss ███▇▇▇▇▇▆▆▆▅▅▅▅▄▄▄▄▄▃▃▃▃▃▃▂▂▂▂▂▂▂▂▁▂▁▁▁▁
wandb: 
wandb: Run summary:
wandb:     e_F1 63.25554
wandb:   e_loss 0.92482
wandb:     t_F1 72.80572
wandb:   t_loss 0.72254
wandb: 
wandb: Synced 4 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Synced solar-morning-2: https://wandb.ai/yinanazhou/xl_512_bs_8_lr_1e06_es_5_lc_False_nr_False_sr_True_stem_False_lemma_True_repeat_2_fold_2/runs/3cgbqo75
wandb: Find logs at: ./wandb/run-20220328_094252-3cgbqo75/logs/debug.log
wandb: 

wandb: wandb version 0.12.11 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
2022-03-28 11:12:59.813071: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1
wandb: Tracking run with wandb version 0.12.5
wandb: Syncing run firm-oath-2
wandb: ⭐️ View project at https://wandb.ai/yinanazhou/xl_512_bs_8_lr_1e06_es_5_lc_False_nr_False_sr_True_stem_False_lemma_True_repeat_3_fold_1
wandb: 🚀 View run at https://wandb.ai/yinanazhou/xl_512_bs_8_lr_1e06_es_5_lc_False_nr_False_sr_True_stem_False_lemma_True_repeat_3_fold_1/runs/3qr1opw2
wandb: Run data is saved locally in /project/6002780/yinan/Thesis_MER_Lyrics/lyric-emotion/wandb/run-20220328_111257-3qr1opw2
wandb: Run `wandb offline` to turn off syncing.

Validation loss decreased (inf --> 1.428655).  Saving model ...
Validation loss decreased (1.428655 --> 1.417327).  Saving model ...
Validation loss decreased (1.417327 --> 1.408128).  Saving model ...
Validation loss decreased (1.408128 --> 1.401289).  Saving model ...
Validation loss decreased (1.401289 --> 1.394840).  Saving model ...
Validation loss decreased (1.394840 --> 1.389313).  Saving model ...
Validation loss decreased (1.389313 --> 1.384063).  Saving model ...
Validation loss decreased (1.384063 --> 1.379594).  Saving model ...
Validation loss decreased (1.379594 --> 1.374710).  Saving model ...
Validation loss decreased (1.374710 --> 1.370292).  Saving model ...
Validation loss decreased (1.370292 --> 1.365780).  Saving model ...
Validation loss decreased (1.365780 --> 1.361020).  Saving model ...
Validation loss decreased (1.361020 --> 1.356619).  Saving model ...
Validation loss decreased (1.356619 --> 1.351643).  Saving model ...
Validation loss decreased (1.351643 --> 1.346424).  Saving model ...
Validation loss decreased (1.346424 --> 1.341098).  Saving model ...
Validation loss decreased (1.341098 --> 1.335200).  Saving model ...
Validation loss decreased (1.335200 --> 1.328673).  Saving model ...
Validation loss decreased (1.328673 --> 1.322132).  Saving model ...
Validation loss decreased (1.322132 --> 1.314713).  Saving model ...
Validation loss decreased (1.314713 --> 1.307173).  Saving model ...
Validation loss decreased (1.307173 --> 1.298304).  Saving model ...
Validation loss decreased (1.298304 --> 1.290237).  Saving model ...
Validation loss decreased (1.290237 --> 1.281285).  Saving model ...
Validation loss decreased (1.281285 --> 1.272179).  Saving model ...
Validation loss decreased (1.272179 --> 1.263581).  Saving model ...
Validation loss decreased (1.263581 --> 1.255190).  Saving model ...
Validation loss decreased (1.255190 --> 1.248998).  Saving model ...
Validation loss decreased (1.248998 --> 1.240737).  Saving model ...
Validation loss decreased (1.240737 --> 1.231874).  Saving model ...
Validation loss decreased (1.231874 --> 1.223882).  Saving model ...
Validation loss decreased (1.223882 --> 1.217627).  Saving model ...
Validation loss decreased (1.217627 --> 1.209857).  Saving model ...
Validation loss decreased (1.209857 --> 1.201577).  Saving model ...
Validation loss decreased (1.201577 --> 1.192631).  Saving model ...
Validation loss decreased (1.192631 --> 1.185484).  Saving model ...
Validation loss decreased (1.185484 --> 1.178763).  Saving model ...
Validation loss decreased (1.178763 --> 1.172102).  Saving model ...
Validation loss decreased (1.172102 --> 1.165313).  Saving model ...
Validation loss decreased (1.165313 --> 1.159846).  Saving model ...
Validation loss decreased (1.159846 --> 1.152492).  Saving model ...
Validation loss decreased (1.152492 --> 1.146170).  Saving model ...
Validation loss decreased (1.146170 --> 1.139240).  Saving model ...
Validation loss decreased (1.139240 --> 1.133925).  Saving model ...
Validation loss decreased (1.133925 --> 1.128542).  Saving model ...
Validation loss decreased (1.128542 --> 1.121258).  Saving model ...
Validation loss decreased (1.121258 --> 1.115404).  Saving model ...
Validation loss decreased (1.115404 --> 1.110055).  Saving model ...
Validation loss decreased (1.110055 --> 1.103846).  Saving model ...
Validation loss decreased (1.103846 --> 1.098878).  Saving model ...
Validation loss decreased (1.098878 --> 1.092941).  Saving model ...
Validation loss decreased (1.092941 --> 1.088575).  Saving model ...
Validation loss decreased (1.088575 --> 1.084068).  Saving model ...
Validation loss decreased (1.084068 --> 1.078919).  Saving model ...
Validation loss decreased (1.078919 --> 1.073778).  Saving model ...
Validation loss decreased (1.073778 --> 1.069722).  Saving model ...
Validation loss decreased (1.069722 --> 1.063798).  Saving model ...
Validation loss decreased (1.063798 --> 1.058510).  Saving model ...
Validation loss decreased (1.058510 --> 1.054033).  Saving model ...
Validation loss decreased (1.054033 --> 1.053002).  Saving model ...
Validation loss decreased (1.053002 --> 1.050761).  Saving model ...
Validation loss decreased (1.050761 --> 1.049784).  Saving model ...
Validation loss decreased (1.049784 --> 1.042620).  Saving model ...
Validation loss decreased (1.042620 --> 1.038361).  Saving model ...
Validation loss decreased (1.038361 --> 1.032828).  Saving model ...
Validation loss decreased (1.032828 --> 1.029665).  Saving model ...
Validation loss decreased (1.029665 --> 1.026000).  Saving model ...
Validation loss decreased (1.026000 --> 1.022888).  Saving model ...
Validation loss decreased (1.022888 --> 1.020352).  Saving model ...
Validation loss decreased (1.020352 --> 1.017470).  Saving model ...
Validation loss decreased (1.017470 --> 1.013400).  Saving model ...
Validation loss decreased (1.013400 --> 1.009851).  Saving model ...
Validation loss decreased (1.009851 --> 1.008441).  Saving model ...
Validation loss decreased (1.008441 --> 1.002441).  Saving model ...
Validation loss decreased (1.002441 --> 0.998341).  Saving model ...
Validation loss decreased (0.998341 --> 0.996569).  Saving model ...
Validation loss decreased (0.996569 --> 0.995639).  Saving model ...
Validation loss decreased (0.995639 --> 0.992695).  Saving model ...
Validation loss decreased (0.992695 --> 0.991339).  Saving model ...
Validation loss decreased (0.991339 --> 0.989836).  Saving model ...
Validation loss decreased (0.989836 --> 0.987041).  Saving model ...
Validation loss decreased (0.987041 --> 0.984617).  Saving model ...
Validation loss decreased (0.984617 --> 0.979933).  Saving model ...
Validation loss decreased (0.979933 --> 0.977400).  Saving model ...
EarlyStopping counter: 1 out of 5.0
Validation loss decreased (0.977400 --> 0.974360).  Saving model ...
EarlyStopping counter: 1 out of 5.0
Validation loss decreased (0.974360 --> 0.971274).  Saving model ...
Validation loss decreased (0.971274 --> 0.969116).  Saving model ...
EarlyStopping counter: 1 out of 5.0
EarlyStopping counter: 2 out of 5.0
EarlyStopping counter: 3 out of 5.0
Validation loss decreased (0.969116 --> 0.965993).  Saving model ...
EarlyStopping counter: 1 out of 5.0
Validation loss decreased (0.965993 --> 0.964394).  Saving model ...
Validation loss decreased (0.964394 --> 0.963897).  Saving model ...
Validation loss decreased (0.963897 --> 0.961344).  Saving model ...
Validation loss decreased (0.961344 --> 0.958870).  Saving model ...
EarlyStopping counter: 1 out of 5.0
EarlyStopping counter: 2 out of 5.0
Validation loss decreased (0.958870 --> 0.958443).  Saving model ...
EarlyStopping counter: 1 out of 5.0
Validation loss decreased (0.958443 --> 0.956336).  Saving model ...
Validation loss decreased (0.956336 --> 0.954357).  Saving model ...
Validation loss decreased (0.954357 --> 0.952557).  Saving model ...
EarlyStopping counter: 1 out of 5.0
Validation loss decreased (0.952557 --> 0.951901).  Saving model ...
EarlyStopping counter: 1 out of 5.0
EarlyStopping counter: 2 out of 5.0
EarlyStopping counter: 3 out of 5.0
EarlyStopping counter: 4 out of 5.0
EarlyStopping counter: 5 out of 5.0
/localscratch/yinan.29351708.0/env/lib/python3.7/site-packages/torch/nn/functional.py:1794: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.
  warnings.warn("nn.functional.tanh is deprecated. Use torch.tanh instead.")
wandb: Waiting for W&B process to finish, PID 95805... (success).
wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: \ 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: | 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: / 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: \ 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: | 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: / 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: \ 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: | 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: / 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb:                                                                                
wandb: Run history:
wandb:     e_F1 ▁▁▂▃▄▅▅▆▆▆▆▆▆▆▇▇▇▇▇▇▇▇▇▇▇▇▇█████████████
wandb:   e_loss ██▇▇▇▇▇▆▆▆▅▅▅▄▄▄▃▃▃▃▃▂▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁
wandb:     t_F1 ▁▁▂▂▃▃▃▄▄▄▄▅▅▆▅▆▆▆▇▆▇▆▇▇▇▇▇████▇████████
wandb:   t_loss ████▇▇▇▇▇▆▆▆▆▅▅▅▄▄▄▄▄▄▃▃▃▃▃▂▂▂▂▂▂▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:     e_F1 60.94597
wandb:   e_loss 0.95443
wandb:     t_F1 67.83415
wandb:   t_loss 0.82673
wandb: 
wandb: Synced 4 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Synced firm-oath-2: https://wandb.ai/yinanazhou/xl_512_bs_8_lr_1e06_es_5_lc_False_nr_False_sr_True_stem_False_lemma_True_repeat_3_fold_1/runs/3qr1opw2
wandb: Find logs at: ./wandb/run-20220328_111257-3qr1opw2/logs/debug.log
wandb: 

wandb: wandb version 0.12.11 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
2022-03-28 12:27:27.343813: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1
wandb: Tracking run with wandb version 0.12.5
wandb: Syncing run good-puddle-2
wandb: ⭐️ View project at https://wandb.ai/yinanazhou/xl_512_bs_8_lr_1e06_es_5_lc_False_nr_False_sr_True_stem_False_lemma_True_repeat_3_fold_2
wandb: 🚀 View run at https://wandb.ai/yinanazhou/xl_512_bs_8_lr_1e06_es_5_lc_False_nr_False_sr_True_stem_False_lemma_True_repeat_3_fold_2/runs/2g1f34av
wandb: Run data is saved locally in /project/6002780/yinan/Thesis_MER_Lyrics/lyric-emotion/wandb/run-20220328_122724-2g1f34av
wandb: Run `wandb offline` to turn off syncing.

Validation loss decreased (inf --> 1.504588).  Saving model ...
Validation loss decreased (1.504588 --> 1.467269).  Saving model ...
Validation loss decreased (1.467269 --> 1.439634).  Saving model ...
Validation loss decreased (1.439634 --> 1.420066).  Saving model ...
Validation loss decreased (1.420066 --> 1.404740).  Saving model ...
Validation loss decreased (1.404740 --> 1.393464).  Saving model ...
Validation loss decreased (1.393464 --> 1.384672).  Saving model ...
Validation loss decreased (1.384672 --> 1.377305).  Saving model ...
Validation loss decreased (1.377305 --> 1.370488).  Saving model ...
Validation loss decreased (1.370488 --> 1.363845).  Saving model ...
Validation loss decreased (1.363845 --> 1.358142).  Saving model ...
Validation loss decreased (1.358142 --> 1.351776).  Saving model ...
Validation loss decreased (1.351776 --> 1.345205).  Saving model ...
Validation loss decreased (1.345205 --> 1.338981).  Saving model ...
Validation loss decreased (1.338981 --> 1.332355).  Saving model ...
Validation loss decreased (1.332355 --> 1.324702).  Saving model ...
Validation loss decreased (1.324702 --> 1.317282).  Saving model ...
Validation loss decreased (1.317282 --> 1.310331).  Saving model ...
Validation loss decreased (1.310331 --> 1.302685).  Saving model ...
Validation loss decreased (1.302685 --> 1.294144).  Saving model ...
Validation loss decreased (1.294144 --> 1.285685).  Saving model ...
Validation loss decreased (1.285685 --> 1.276215).  Saving model ...
Validation loss decreased (1.276215 --> 1.266440).  Saving model ...
Validation loss decreased (1.266440 --> 1.259181).  Saving model ...
Validation loss decreased (1.259181 --> 1.250836).  Saving model ...
Validation loss decreased (1.250836 --> 1.241426).  Saving model ...
Validation loss decreased (1.241426 --> 1.233441).  Saving model ...
Validation loss decreased (1.233441 --> 1.224883).  Saving model ...
Validation loss decreased (1.224883 --> 1.216036).  Saving model ...
Validation loss decreased (1.216036 --> 1.208781).  Saving model ...
Validation loss decreased (1.208781 --> 1.200813).  Saving model ...
Validation loss decreased (1.200813 --> 1.194095).  Saving model ...
Validation loss decreased (1.194095 --> 1.188706).  Saving model ...
Validation loss decreased (1.188706 --> 1.179352).  Saving model ...
Validation loss decreased (1.179352 --> 1.174786).  Saving model ...
Validation loss decreased (1.174786 --> 1.167771).  Saving model ...
Validation loss decreased (1.167771 --> 1.159254).  Saving model ...
Validation loss decreased (1.159254 --> 1.152539).  Saving model ...
Validation loss decreased (1.152539 --> 1.142923).  Saving model ...
Validation loss decreased (1.142923 --> 1.136626).  Saving model ...
Validation loss decreased (1.136626 --> 1.127645).  Saving model ...
Validation loss decreased (1.127645 --> 1.119615).  Saving model ...
Validation loss decreased (1.119615 --> 1.117185).  Saving model ...
Validation loss decreased (1.117185 --> 1.109582).  Saving model ...
Validation loss decreased (1.109582 --> 1.106175).  Saving model ...
Validation loss decreased (1.106175 --> 1.102576).  Saving model ...
Validation loss decreased (1.102576 --> 1.099061).  Saving model ...
Validation loss decreased (1.099061 --> 1.088613).  Saving model ...
Validation loss decreased (1.088613 --> 1.080668).  Saving model ...
Validation loss decreased (1.080668 --> 1.074840).  Saving model ...
Validation loss decreased (1.074840 --> 1.071619).  Saving model ...
Validation loss decreased (1.071619 --> 1.065504).  Saving model ...
Validation loss decreased (1.065504 --> 1.058682).  Saving model ...
Validation loss decreased (1.058682 --> 1.050522).  Saving model ...
Validation loss decreased (1.050522 --> 1.044521).  Saving model ...
Validation loss decreased (1.044521 --> 1.039498).  Saving model ...
Validation loss decreased (1.039498 --> 1.035694).  Saving model ...
Validation loss decreased (1.035694 --> 1.033584).  Saving model ...
Validation loss decreased (1.033584 --> 1.026206).  Saving model ...
Validation loss decreased (1.026206 --> 1.020818).  Saving model ...
Validation loss decreased (1.020818 --> 1.017888).  Saving model ...
Validation loss decreased (1.017888 --> 1.013927).  Saving model ...
Validation loss decreased (1.013927 --> 1.011460).  Saving model ...
Validation loss decreased (1.011460 --> 1.004794).  Saving model ...
Validation loss decreased (1.004794 --> 1.000513).  Saving model ...
Validation loss decreased (1.000513 --> 0.998303).  Saving model ...
Validation loss decreased (0.998303 --> 0.994722).  Saving model ...
Validation loss decreased (0.994722 --> 0.990705).  Saving model ...
Validation loss decreased (0.990705 --> 0.984666).  Saving model ...
Validation loss decreased (0.984666 --> 0.982080).  Saving model ...
Validation loss decreased (0.982080 --> 0.976504).  Saving model ...
Validation loss decreased (0.976504 --> 0.975549).  Saving model ...
Validation loss decreased (0.975549 --> 0.970746).  Saving model ...
Validation loss decreased (0.970746 --> 0.968964).  Saving model ...
Validation loss decreased (0.968964 --> 0.965555).  Saving model ...
Validation loss decreased (0.965555 --> 0.961312).  Saving model ...
Validation loss decreased (0.961312 --> 0.958260).  Saving model ...
Validation loss decreased (0.958260 --> 0.956341).  Saving model ...
Validation loss decreased (0.956341 --> 0.952527).  Saving model ...
Validation loss decreased (0.952527 --> 0.950237).  Saving model ...
Validation loss decreased (0.950237 --> 0.949978).  Saving model ...
Validation loss decreased (0.949978 --> 0.947378).  Saving model ...
Validation loss decreased (0.947378 --> 0.942894).  Saving model ...
Validation loss decreased (0.942894 --> 0.939768).  Saving model ...
Validation loss decreased (0.939768 --> 0.937746).  Saving model ...
Validation loss decreased (0.937746 --> 0.935340).  Saving model ...
Validation loss decreased (0.935340 --> 0.932413).  Saving model ...
EarlyStopping counter: 1 out of 5.0
EarlyStopping counter: 2 out of 5.0
Validation loss decreased (0.932413 --> 0.930065).  Saving model ...
Validation loss decreased (0.930065 --> 0.928707).  Saving model ...
EarlyStopping counter: 1 out of 5.0
Validation loss decreased (0.928707 --> 0.928521).  Saving model ...
Validation loss decreased (0.928521 --> 0.925496).  Saving model ...
Validation loss decreased (0.925496 --> 0.919438).  Saving model ...
Validation loss decreased (0.919438 --> 0.915166).  Saving model ...
Validation loss decreased (0.915166 --> 0.915065).  Saving model ...
Validation loss decreased (0.915065 --> 0.914122).  Saving model ...
Validation loss decreased (0.914122 --> 0.912093).  Saving model ...
Validation loss decreased (0.912093 --> 0.911169).  Saving model ...
EarlyStopping counter: 1 out of 5.0
Validation loss decreased (0.911169 --> 0.910782).  Saving model ...
EarlyStopping counter: 1 out of 5.0
Validation loss decreased (0.910782 --> 0.910544).  Saving model ...
EarlyStopping counter: 1 out of 5.0
EarlyStopping counter: 2 out of 5.0
Validation loss decreased (0.910544 --> 0.905089).  Saving model ...
EarlyStopping counter: 1 out of 5.0
Validation loss decreased (0.905089 --> 0.904546).  Saving model ...
Validation loss decreased (0.904546 --> 0.902141).  Saving model ...
EarlyStopping counter: 1 out of 5.0
Validation loss decreased (0.902141 --> 0.901138).  Saving model ...
EarlyStopping counter: 1 out of 5.0
EarlyStopping counter: 2 out of 5.0
EarlyStopping counter: 3 out of 5.0
EarlyStopping counter: 4 out of 5.0
Validation loss decreased (0.901138 --> 0.899741).  Saving model ...
Validation loss decreased (0.899741 --> 0.897645).  Saving model ...
EarlyStopping counter: 1 out of 5.0
Validation loss decreased (0.897645 --> 0.897256).  Saving model ...
Validation loss decreased (0.897256 --> 0.895821).  Saving model ...
EarlyStopping counter: 1 out of 5.0
EarlyStopping counter: 2 out of 5.0
Validation loss decreased (0.895821 --> 0.894487).  Saving model ...
EarlyStopping counter: 1 out of 5.0
EarlyStopping counter: 2 out of 5.0
EarlyStopping counter: 3 out of 5.0
EarlyStopping counter: 4 out of 5.0
EarlyStopping counter: 5 out of 5.0
/localscratch/yinan.29351708.0/env/lib/python3.7/site-packages/torch/nn/functional.py:1794: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.
  warnings.warn("nn.functional.tanh is deprecated. Use torch.tanh instead.")
wandb: Waiting for W&B process to finish, PID 99879... (success).
wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: \ 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: | 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: / 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: \ 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: | 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: / 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: \ 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: | 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: / 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb:                                                                                
wandb: Run history:
wandb:     e_F1 ▁▁▂▃▃▄▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇▇▇█▇███████████████
wandb:   e_loss █▇▇▇▆▆▆▅▅▅▄▄▄▄▄▃▃▃▃▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:     t_F1 ▁▁▂▂▃▄▄▅▅▅▅▅▆▆▆▆▆▆▆▆▆▇▇▇▇▇▇█▇▇█▇█▇▇█████
wandb:   t_loss █▇▇▇▇▆▆▆▆▆▅▅▅▄▄▄▄▄▄▄▃▃▃▃▃▃▂▂▂▂▂▂▂▂▂▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:     e_F1 62.67963
wandb:   e_loss 0.89846
wandb:     t_F1 71.26117
wandb:   t_loss 0.77517
wandb: 
wandb: Synced 4 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Synced good-puddle-2: https://wandb.ai/yinanazhou/xl_512_bs_8_lr_1e06_es_5_lc_False_nr_False_sr_True_stem_False_lemma_True_repeat_3_fold_2/runs/2g1f34av
wandb: Find logs at: ./wandb/run-20220328_122724-2g1f34av/logs/debug.log
wandb: 

wandb: wandb version 0.12.11 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
2022-03-28 13:53:11.295041: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1
wandb: Tracking run with wandb version 0.12.5
wandb: Syncing run visionary-armadillo-2
wandb: ⭐️ View project at https://wandb.ai/yinanazhou/xl_512_bs_8_lr_1e06_es_5_lc_False_nr_False_sr_True_stem_False_lemma_True_repeat_4_fold_1
wandb: 🚀 View run at https://wandb.ai/yinanazhou/xl_512_bs_8_lr_1e06_es_5_lc_False_nr_False_sr_True_stem_False_lemma_True_repeat_4_fold_1/runs/383p1t9r
wandb: Run data is saved locally in /project/6002780/yinan/Thesis_MER_Lyrics/lyric-emotion/wandb/run-20220328_135309-383p1t9r
wandb: Run `wandb offline` to turn off syncing.

Validation loss decreased (inf --> 1.532094).  Saving model ...
Validation loss decreased (1.532094 --> 1.480149).  Saving model ...
Validation loss decreased (1.480149 --> 1.440028).  Saving model ...
Validation loss decreased (1.440028 --> 1.411059).  Saving model ...
Validation loss decreased (1.411059 --> 1.389820).  Saving model ...
Validation loss decreased (1.389820 --> 1.374945).  Saving model ...
Validation loss decreased (1.374945 --> 1.363675).  Saving model ...
Validation loss decreased (1.363675 --> 1.355794).  Saving model ...
Validation loss decreased (1.355794 --> 1.349916).  Saving model ...
Validation loss decreased (1.349916 --> 1.344583).  Saving model ...
Validation loss decreased (1.344583 --> 1.339623).  Saving model ...
Validation loss decreased (1.339623 --> 1.334626).  Saving model ...
Validation loss decreased (1.334626 --> 1.328686).  Saving model ...
Validation loss decreased (1.328686 --> 1.323435).  Saving model ...
Validation loss decreased (1.323435 --> 1.317658).  Saving model ...
Validation loss decreased (1.317658 --> 1.311517).  Saving model ...
Validation loss decreased (1.311517 --> 1.305678).  Saving model ...
Validation loss decreased (1.305678 --> 1.298588).  Saving model ...
Validation loss decreased (1.298588 --> 1.291535).  Saving model ...
Validation loss decreased (1.291535 --> 1.283481).  Saving model ...
Validation loss decreased (1.283481 --> 1.275481).  Saving model ...
Validation loss decreased (1.275481 --> 1.266328).  Saving model ...
Validation loss decreased (1.266328 --> 1.258760).  Saving model ...
Validation loss decreased (1.258760 --> 1.251204).  Saving model ...
Validation loss decreased (1.251204 --> 1.244356).  Saving model ...
Validation loss decreased (1.244356 --> 1.237591).  Saving model ...
Validation loss decreased (1.237591 --> 1.232150).  Saving model ...
Validation loss decreased (1.232150 --> 1.225718).  Saving model ...
Validation loss decreased (1.225718 --> 1.218701).  Saving model ...
Validation loss decreased (1.218701 --> 1.211268).  Saving model ...
Validation loss decreased (1.211268 --> 1.204046).  Saving model ...
Validation loss decreased (1.204046 --> 1.197018).  Saving model ...
Validation loss decreased (1.197018 --> 1.190983).  Saving model ...
Validation loss decreased (1.190983 --> 1.184535).  Saving model ...
Validation loss decreased (1.184535 --> 1.177377).  Saving model ...
Validation loss decreased (1.177377 --> 1.170109).  Saving model ...
Validation loss decreased (1.170109 --> 1.164022).  Saving model ...
Validation loss decreased (1.164022 --> 1.158301).  Saving model ...
Validation loss decreased (1.158301 --> 1.153049).  Saving model ...
Validation loss decreased (1.153049 --> 1.147203).  Saving model ...
Validation loss decreased (1.147203 --> 1.140761).  Saving model ...
Validation loss decreased (1.140761 --> 1.135993).  Saving model ...
Validation loss decreased (1.135993 --> 1.131459).  Saving model ...
Validation loss decreased (1.131459 --> 1.125674).  Saving model ...
Validation loss decreased (1.125674 --> 1.119470).  Saving model ...
Validation loss decreased (1.119470 --> 1.113951).  Saving model ...
Validation loss decreased (1.113951 --> 1.108141).  Saving model ...
Validation loss decreased (1.108141 --> 1.102409).  Saving model ...
Validation loss decreased (1.102409 --> 1.098185).  Saving model ...
Validation loss decreased (1.098185 --> 1.092348).  Saving model ...
Validation loss decreased (1.092348 --> 1.088204).  Saving model ...
Validation loss decreased (1.088204 --> 1.084821).  Saving model ...
Validation loss decreased (1.084821 --> 1.080427).  Saving model ...
Validation loss decreased (1.080427 --> 1.077634).  Saving model ...
Validation loss decreased (1.077634 --> 1.074419).  Saving model ...
Validation loss decreased (1.074419 --> 1.069946).  Saving model ...
Validation loss decreased (1.069946 --> 1.066312).  Saving model ...
Validation loss decreased (1.066312 --> 1.061982).  Saving model ...
Validation loss decreased (1.061982 --> 1.057678).  Saving model ...
Validation loss decreased (1.057678 --> 1.053706).  Saving model ...
Validation loss decreased (1.053706 --> 1.050583).  Saving model ...
Validation loss decreased (1.050583 --> 1.047150).  Saving model ...
Validation loss decreased (1.047150 --> 1.045851).  Saving model ...
Validation loss decreased (1.045851 --> 1.041877).  Saving model ...
Validation loss decreased (1.041877 --> 1.039440).  Saving model ...
Validation loss decreased (1.039440 --> 1.036110).  Saving model ...
Validation loss decreased (1.036110 --> 1.032556).  Saving model ...
Validation loss decreased (1.032556 --> 1.028931).  Saving model ...
Validation loss decreased (1.028931 --> 1.026688).  Saving model ...
Validation loss decreased (1.026688 --> 1.026247).  Saving model ...
Validation loss decreased (1.026247 --> 1.021821).  Saving model ...
Validation loss decreased (1.021821 --> 1.018880).  Saving model ...
Validation loss decreased (1.018880 --> 1.017201).  Saving model ...
Validation loss decreased (1.017201 --> 1.015422).  Saving model ...
Validation loss decreased (1.015422 --> 1.010970).  Saving model ...
Validation loss decreased (1.010970 --> 1.009375).  Saving model ...
Validation loss decreased (1.009375 --> 1.007630).  Saving model ...
Validation loss decreased (1.007630 --> 1.005063).  Saving model ...
Validation loss decreased (1.005063 --> 1.001984).  Saving model ...
Validation loss decreased (1.001984 --> 0.998184).  Saving model ...
Validation loss decreased (0.998184 --> 0.997202).  Saving model ...
Validation loss decreased (0.997202 --> 0.995498).  Saving model ...
Validation loss decreased (0.995498 --> 0.994055).  Saving model ...
Validation loss decreased (0.994055 --> 0.991280).  Saving model ...
Validation loss decreased (0.991280 --> 0.989693).  Saving model ...
Validation loss decreased (0.989693 --> 0.987405).  Saving model ...
Validation loss decreased (0.987405 --> 0.985348).  Saving model ...
EarlyStopping counter: 1 out of 5.0
Validation loss decreased (0.985348 --> 0.981570).  Saving model ...
Validation loss decreased (0.981570 --> 0.979662).  Saving model ...
Validation loss decreased (0.979662 --> 0.979088).  Saving model ...
Validation loss decreased (0.979088 --> 0.977559).  Saving model ...
Validation loss decreased (0.977559 --> 0.976217).  Saving model ...
Validation loss decreased (0.976217 --> 0.975592).  Saving model ...
Validation loss decreased (0.975592 --> 0.972198).  Saving model ...
Validation loss decreased (0.972198 --> 0.970064).  Saving model ...
Validation loss decreased (0.970064 --> 0.969407).  Saving model ...
Validation loss decreased (0.969407 --> 0.968257).  Saving model ...
Validation loss decreased (0.968257 --> 0.965285).  Saving model ...
Validation loss decreased (0.965285 --> 0.962154).  Saving model ...
EarlyStopping counter: 1 out of 5.0
EarlyStopping counter: 2 out of 5.0
EarlyStopping counter: 3 out of 5.0
EarlyStopping counter: 4 out of 5.0
Validation loss decreased (0.962154 --> 0.961667).  Saving model ...
Validation loss decreased (0.961667 --> 0.960386).  Saving model ...
Validation loss decreased (0.960386 --> 0.958710).  Saving model ...
Validation loss decreased (0.958710 --> 0.958609).  Saving model ...
Validation loss decreased (0.958609 --> 0.957145).  Saving model ...
Validation loss decreased (0.957145 --> 0.956050).  Saving model ...
Validation loss decreased (0.956050 --> 0.956011).  Saving model ...
EarlyStopping counter: 1 out of 5.0
EarlyStopping counter: 2 out of 5.0
Validation loss decreased (0.956011 --> 0.954933).  Saving model ...
Validation loss decreased (0.954933 --> 0.954766).  Saving model ...
EarlyStopping counter: 1 out of 5.0
EarlyStopping counter: 2 out of 5.0
Validation loss decreased (0.954766 --> 0.954751).  Saving model ...
Validation loss decreased (0.954751 --> 0.953099).  Saving model ...
EarlyStopping counter: 1 out of 5.0
EarlyStopping counter: 2 out of 5.0
EarlyStopping counter: 3 out of 5.0
EarlyStopping counter: 4 out of 5.0
Validation loss decreased (0.953099 --> 0.952314).  Saving model ...
EarlyStopping counter: 1 out of 5.0
EarlyStopping counter: 2 out of 5.0
EarlyStopping counter: 3 out of 5.0
EarlyStopping counter: 4 out of 5.0
EarlyStopping counter: 5 out of 5.0
/localscratch/yinan.29351708.0/env/lib/python3.7/site-packages/torch/nn/functional.py:1794: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.
  warnings.warn("nn.functional.tanh is deprecated. Use torch.tanh instead.")
wandb: Waiting for W&B process to finish, PID 104598... (success).
wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: \ 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: | 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: / 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: \ 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: | 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: / 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: \ 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: | 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: / 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb:                                                                                
wandb: Run history:
wandb:     e_F1 ▁▂▅▅▅▅▅▆▆▆▆▇▇▇▇▇▇▇███▇██████████████████
wandb:   e_loss █▇▆▆▆▆▅▅▅▄▄▄▄▃▃▃▃▃▂▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:     t_F1 ▁▁▂▃▃▄▄▄▅▅▅▅▅▅▅▆▆▆▆▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇██▇██
wandb:   t_loss ██▇▇▆▆▆▆▆▅▅▅▅▄▄▄▄▄▃▃▃▃▃▃▂▂▂▂▂▂▂▂▂▂▂▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:     e_F1 58.64899
wandb:   e_loss 0.95577
wandb:     t_F1 66.99784
wandb:   t_loss 0.76942
wandb: 
wandb: Synced 4 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Synced visionary-armadillo-2: https://wandb.ai/yinanazhou/xl_512_bs_8_lr_1e06_es_5_lc_False_nr_False_sr_True_stem_False_lemma_True_repeat_4_fold_1/runs/383p1t9r
wandb: Find logs at: ./wandb/run-20220328_135309-383p1t9r/logs/debug.log
wandb: 

wandb: wandb version 0.12.11 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
2022-03-28 15:15:43.625079: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1
wandb: Tracking run with wandb version 0.12.5
wandb: Syncing run twilight-dream-2
wandb: ⭐️ View project at https://wandb.ai/yinanazhou/xl_512_bs_8_lr_1e06_es_5_lc_False_nr_False_sr_True_stem_False_lemma_True_repeat_4_fold_2
wandb: 🚀 View run at https://wandb.ai/yinanazhou/xl_512_bs_8_lr_1e06_es_5_lc_False_nr_False_sr_True_stem_False_lemma_True_repeat_4_fold_2/runs/2okgsb3i
wandb: Run data is saved locally in /project/6002780/yinan/Thesis_MER_Lyrics/lyric-emotion/wandb/run-20220328_151541-2okgsb3i
wandb: Run `wandb offline` to turn off syncing.

Validation loss decreased (inf --> 1.399368).  Saving model ...
Validation loss decreased (1.399368 --> 1.386287).  Saving model ...
Validation loss decreased (1.386287 --> 1.376074).  Saving model ...
Validation loss decreased (1.376074 --> 1.367659).  Saving model ...
Validation loss decreased (1.367659 --> 1.361107).  Saving model ...
Validation loss decreased (1.361107 --> 1.355441).  Saving model ...
Validation loss decreased (1.355441 --> 1.349972).  Saving model ...
Validation loss decreased (1.349972 --> 1.345156).  Saving model ...
Validation loss decreased (1.345156 --> 1.339698).  Saving model ...
Validation loss decreased (1.339698 --> 1.335021).  Saving model ...
Validation loss decreased (1.335021 --> 1.329868).  Saving model ...
Validation loss decreased (1.329868 --> 1.324833).  Saving model ...
Validation loss decreased (1.324833 --> 1.319296).  Saving model ...
Validation loss decreased (1.319296 --> 1.314138).  Saving model ...
Validation loss decreased (1.314138 --> 1.307993).  Saving model ...
Validation loss decreased (1.307993 --> 1.301650).  Saving model ...
Validation loss decreased (1.301650 --> 1.295809).  Saving model ...
Validation loss decreased (1.295809 --> 1.289614).  Saving model ...
Validation loss decreased (1.289614 --> 1.282952).  Saving model ...
Validation loss decreased (1.282952 --> 1.276621).  Saving model ...
Validation loss decreased (1.276621 --> 1.269178).  Saving model ...
Validation loss decreased (1.269178 --> 1.260626).  Saving model ...
Validation loss decreased (1.260626 --> 1.251408).  Saving model ...
Validation loss decreased (1.251408 --> 1.241890).  Saving model ...
Validation loss decreased (1.241890 --> 1.232975).  Saving model ...
Validation loss decreased (1.232975 --> 1.224386).  Saving model ...
Validation loss decreased (1.224386 --> 1.215275).  Saving model ...
Validation loss decreased (1.215275 --> 1.205507).  Saving model ...
Validation loss decreased (1.205507 --> 1.196200).  Saving model ...
Validation loss decreased (1.196200 --> 1.186207).  Saving model ...
Validation loss decreased (1.186207 --> 1.177141).  Saving model ...
Validation loss decreased (1.177141 --> 1.167739).  Saving model ...
Validation loss decreased (1.167739 --> 1.161677).  Saving model ...
Validation loss decreased (1.161677 --> 1.152300).  Saving model ...
Validation loss decreased (1.152300 --> 1.145787).  Saving model ...
Validation loss decreased (1.145787 --> 1.138757).  Saving model ...
Validation loss decreased (1.138757 --> 1.132466).  Saving model ...
Validation loss decreased (1.132466 --> 1.124897).  Saving model ...
Validation loss decreased (1.124897 --> 1.118942).  Saving model ...
Validation loss decreased (1.118942 --> 1.112557).  Saving model ...
Validation loss decreased (1.112557 --> 1.106102).  Saving model ...
Validation loss decreased (1.106102 --> 1.100297).  Saving model ...
Validation loss decreased (1.100297 --> 1.095026).  Saving model ...
Validation loss decreased (1.095026 --> 1.091708).  Saving model ...
Validation loss decreased (1.091708 --> 1.087753).  Saving model ...
Validation loss decreased (1.087753 --> 1.082053).  Saving model ...
Validation loss decreased (1.082053 --> 1.077204).  Saving model ...
Validation loss decreased (1.077204 --> 1.071987).  Saving model ...
Validation loss decreased (1.071987 --> 1.067194).  Saving model ...
Validation loss decreased (1.067194 --> 1.063396).  Saving model ...
Validation loss decreased (1.063396 --> 1.058424).  Saving model ...
Validation loss decreased (1.058424 --> 1.052166).  Saving model ...
Validation loss decreased (1.052166 --> 1.048135).  Saving model ...
Validation loss decreased (1.048135 --> 1.042508).  Saving model ...
Validation loss decreased (1.042508 --> 1.038154).  Saving model ...
Validation loss decreased (1.038154 --> 1.035317).  Saving model ...
Validation loss decreased (1.035317 --> 1.031520).  Saving model ...
Validation loss decreased (1.031520 --> 1.029863).  Saving model ...
Validation loss decreased (1.029863 --> 1.026266).  Saving model ...
Validation loss decreased (1.026266 --> 1.023772).  Saving model ...
Validation loss decreased (1.023772 --> 1.019426).  Saving model ...
Validation loss decreased (1.019426 --> 1.015260).  Saving model ...
Validation loss decreased (1.015260 --> 1.010534).  Saving model ...
Validation loss decreased (1.010534 --> 1.007247).  Saving model ...
Validation loss decreased (1.007247 --> 1.004542).  Saving model ...
Validation loss decreased (1.004542 --> 1.000274).  Saving model ...
Validation loss decreased (1.000274 --> 0.998699).  Saving model ...
Validation loss decreased (0.998699 --> 0.995163).  Saving model ...
Validation loss decreased (0.995163 --> 0.991741).  Saving model ...
Validation loss decreased (0.991741 --> 0.989708).  Saving model ...
Validation loss decreased (0.989708 --> 0.987669).  Saving model ...
Validation loss decreased (0.987669 --> 0.985417).  Saving model ...
Validation loss decreased (0.985417 --> 0.983469).  Saving model ...
Validation loss decreased (0.983469 --> 0.981659).  Saving model ...
Validation loss decreased (0.981659 --> 0.977634).  Saving model ...
Validation loss decreased (0.977634 --> 0.976904).  Saving model ...
Validation loss decreased (0.976904 --> 0.974137).  Saving model ...
Validation loss decreased (0.974137 --> 0.968159).  Saving model ...
Validation loss decreased (0.968159 --> 0.966642).  Saving model ...
EarlyStopping counter: 1 out of 5.0
Validation loss decreased (0.966642 --> 0.965607).  Saving model ...
EarlyStopping counter: 1 out of 5.0
Validation loss decreased (0.965607 --> 0.961918).  Saving model ...
Validation loss decreased (0.961918 --> 0.960064).  Saving model ...
EarlyStopping counter: 1 out of 5.0
EarlyStopping counter: 2 out of 5.0
Validation loss decreased (0.960064 --> 0.957748).  Saving model ...
Validation loss decreased (0.957748 --> 0.956674).  Saving model ...
Validation loss decreased (0.956674 --> 0.956100).  Saving model ...
Validation loss decreased (0.956100 --> 0.956028).  Saving model ...
Validation loss decreased (0.956028 --> 0.954377).  Saving model ...
Validation loss decreased (0.954377 --> 0.953018).  Saving model ...
EarlyStopping counter: 1 out of 5.0
EarlyStopping counter: 2 out of 5.0
Validation loss decreased (0.953018 --> 0.950515).  Saving model ...
EarlyStopping counter: 1 out of 5.0
Validation loss decreased (0.950515 --> 0.949342).  Saving model ...
EarlyStopping counter: 1 out of 5.0
Validation loss decreased (0.949342 --> 0.948238).  Saving model ...
Validation loss decreased (0.948238 --> 0.947304).  Saving model ...
Validation loss decreased (0.947304 --> 0.943748).  Saving model ...
EarlyStopping counter: 1 out of 5.0
EarlyStopping counter: 2 out of 5.0
EarlyStopping counter: 3 out of 5.0
Validation loss decreased (0.943748 --> 0.942026).  Saving model ...
EarlyStopping counter: 1 out of 5.0
EarlyStopping counter: 2 out of 5.0
EarlyStopping counter: 3 out of 5.0
EarlyStopping counter: 4 out of 5.0
EarlyStopping counter: 5 out of 5.0
/localscratch/yinan.29351708.0/env/lib/python3.7/site-packages/torch/nn/functional.py:1794: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.
  warnings.warn("nn.functional.tanh is deprecated. Use torch.tanh instead.")
wandb: Waiting for W&B process to finish, PID 109135... (success).
wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: \ 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: | 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: / 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: \ 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: | 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: / 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: \ 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: | 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: / 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb:                                                                                
wandb: Run history:
wandb:     e_F1 ▁▂▄▄▄▅▅▅▆▆▆▆▆▆▆▇▇▇▇▇▇▇▇▇████████████████
wandb:   e_loss ██▇▇▇▇▆▆▆▅▅▅▄▄▄▃▃▃▃▃▂▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁
wandb:     t_F1 ▁▂▂▃▃▃▃▄▄▄▅▅▅▅▆▅▆▆▆▇▆▆▇▇▇▇▇█▇▇█▇▇▇▇▇▇▇▇█
wandb:   t_loss ██▇▇▇▇▇▆▆▆▆▅▅▅▅▅▅▄▄▄▄▄▃▃▃▃▃▂▃▂▂▂▂▂▂▂▂▂▁▁
wandb: 
wandb: Run summary:
wandb:     e_F1 63.08839
wandb:   e_loss 0.94538
wandb:     t_F1 71.55421
wandb:   t_loss 0.7807
wandb: 
wandb: Synced 4 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Synced twilight-dream-2: https://wandb.ai/yinanazhou/xl_512_bs_8_lr_1e06_es_5_lc_False_nr_False_sr_True_stem_False_lemma_True_repeat_4_fold_2/runs/2okgsb3i
wandb: Find logs at: ./wandb/run-20220328_151541-2okgsb3i/logs/debug.log
wandb: 

wandb: wandb version 0.12.11 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
2022-03-28 16:28:50.348634: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1
wandb: Tracking run with wandb version 0.12.5
wandb: Syncing run colorful-galaxy-2
wandb: ⭐️ View project at https://wandb.ai/yinanazhou/xl_512_bs_8_lr_1e06_es_5_lc_False_nr_False_sr_True_stem_False_lemma_True_repeat_5_fold_1
wandb: 🚀 View run at https://wandb.ai/yinanazhou/xl_512_bs_8_lr_1e06_es_5_lc_False_nr_False_sr_True_stem_False_lemma_True_repeat_5_fold_1/runs/25nok7mp
wandb: Run data is saved locally in /project/6002780/yinan/Thesis_MER_Lyrics/lyric-emotion/wandb/run-20220328_162848-25nok7mp
wandb: Run `wandb offline` to turn off syncing.

Validation loss decreased (inf --> 1.416641).  Saving model ...
Validation loss decreased (1.416641 --> 1.396581).  Saving model ...
Validation loss decreased (1.396581 --> 1.382813).  Saving model ...
Validation loss decreased (1.382813 --> 1.372749).  Saving model ...
Validation loss decreased (1.372749 --> 1.364846).  Saving model ...
Validation loss decreased (1.364846 --> 1.358557).  Saving model ...
Validation loss decreased (1.358557 --> 1.353950).  Saving model ...
Validation loss decreased (1.353950 --> 1.348855).  Saving model ...
Validation loss decreased (1.348855 --> 1.344206).  Saving model ...
Validation loss decreased (1.344206 --> 1.339583).  Saving model ...
Validation loss decreased (1.339583 --> 1.334418).  Saving model ...
Validation loss decreased (1.334418 --> 1.329570).  Saving model ...
Validation loss decreased (1.329570 --> 1.324274).  Saving model ...
Validation loss decreased (1.324274 --> 1.318741).  Saving model ...
Validation loss decreased (1.318741 --> 1.312714).  Saving model ...
Validation loss decreased (1.312714 --> 1.306740).  Saving model ...
Validation loss decreased (1.306740 --> 1.301459).  Saving model ...
Validation loss decreased (1.301459 --> 1.294427).  Saving model ...
Validation loss decreased (1.294427 --> 1.287064).  Saving model ...
Validation loss decreased (1.287064 --> 1.279229).  Saving model ...
Validation loss decreased (1.279229 --> 1.270115).  Saving model ...
Validation loss decreased (1.270115 --> 1.262269).  Saving model ...
Validation loss decreased (1.262269 --> 1.254048).  Saving model ...
Validation loss decreased (1.254048 --> 1.247232).  Saving model ...
Validation loss decreased (1.247232 --> 1.239708).  Saving model ...
Validation loss decreased (1.239708 --> 1.230844).  Saving model ...
Validation loss decreased (1.230844 --> 1.222403).  Saving model ...
Validation loss decreased (1.222403 --> 1.215064).  Saving model ...
Validation loss decreased (1.215064 --> 1.208794).  Saving model ...
Validation loss decreased (1.208794 --> 1.200353).  Saving model ...
Validation loss decreased (1.200353 --> 1.192944).  Saving model ...
Validation loss decreased (1.192944 --> 1.186479).  Saving model ...
Validation loss decreased (1.186479 --> 1.178864).  Saving model ...
Validation loss decreased (1.178864 --> 1.171769).  Saving model ...
Validation loss decreased (1.171769 --> 1.165561).  Saving model ...
Validation loss decreased (1.165561 --> 1.159066).  Saving model ...
Validation loss decreased (1.159066 --> 1.151684).  Saving model ...
Validation loss decreased (1.151684 --> 1.145665).  Saving model ...
Validation loss decreased (1.145665 --> 1.140909).  Saving model ...
Validation loss decreased (1.140909 --> 1.134607).  Saving model ...
Validation loss decreased (1.134607 --> 1.128155).  Saving model ...
Validation loss decreased (1.128155 --> 1.122808).  Saving model ...
Validation loss decreased (1.122808 --> 1.119156).  Saving model ...
Validation loss decreased (1.119156 --> 1.116390).  Saving model ...
Validation loss decreased (1.116390 --> 1.111575).  Saving model ...
Validation loss decreased (1.111575 --> 1.105086).  Saving model ...
Validation loss decreased (1.105086 --> 1.094789).  Saving model ...
Validation loss decreased (1.094789 --> 1.091273).  Saving model ...
Validation loss decreased (1.091273 --> 1.084464).  Saving model ...
Validation loss decreased (1.084464 --> 1.080514).  Saving model ...
Validation loss decreased (1.080514 --> 1.076831).  Saving model ...
Validation loss decreased (1.076831 --> 1.073059).  Saving model ...
Validation loss decreased (1.073059 --> 1.068240).  Saving model ...
Validation loss decreased (1.068240 --> 1.064360).  Saving model ...
Validation loss decreased (1.064360 --> 1.061037).  Saving model ...
Validation loss decreased (1.061037 --> 1.056967).  Saving model ...
Validation loss decreased (1.056967 --> 1.052669).  Saving model ...
Validation loss decreased (1.052669 --> 1.049216).  Saving model ...
Validation loss decreased (1.049216 --> 1.045449).  Saving model ...
Validation loss decreased (1.045449 --> 1.042085).  Saving model ...
Validation loss decreased (1.042085 --> 1.039458).  Saving model ...
Validation loss decreased (1.039458 --> 1.034521).  Saving model ...
Validation loss decreased (1.034521 --> 1.028542).  Saving model ...
Validation loss decreased (1.028542 --> 1.026125).  Saving model ...
Validation loss decreased (1.026125 --> 1.022634).  Saving model ...
Validation loss decreased (1.022634 --> 1.019234).  Saving model ...
Validation loss decreased (1.019234 --> 1.015472).  Saving model ...
Validation loss decreased (1.015472 --> 1.011703).  Saving model ...
Validation loss decreased (1.011703 --> 1.008794).  Saving model ...
Validation loss decreased (1.008794 --> 1.005899).  Saving model ...
Validation loss decreased (1.005899 --> 1.001902).  Saving model ...
Validation loss decreased (1.001902 --> 0.999166).  Saving model ...
EarlyStopping counter: 1 out of 5.0
Validation loss decreased (0.999166 --> 0.994931).  Saving model ...
Validation loss decreased (0.994931 --> 0.993882).  Saving model ...
Validation loss decreased (0.993882 --> 0.990926).  Saving model ...
Validation loss decreased (0.990926 --> 0.989386).  Saving model ...
Validation loss decreased (0.989386 --> 0.985265).  Saving model ...
EarlyStopping counter: 1 out of 5.0
Validation loss decreased (0.985265 --> 0.982527).  Saving model ...
Validation loss decreased (0.982527 --> 0.979246).  Saving model ...
Validation loss decreased (0.979246 --> 0.974990).  Saving model ...
Validation loss decreased (0.974990 --> 0.970827).  Saving model ...
Validation loss decreased (0.970827 --> 0.969288).  Saving model ...
Validation loss decreased (0.969288 --> 0.967488).  Saving model ...
EarlyStopping counter: 1 out of 5.0
Validation loss decreased (0.967488 --> 0.966329).  Saving model ...
Validation loss decreased (0.966329 --> 0.961994).  Saving model ...
EarlyStopping counter: 1 out of 5.0
EarlyStopping counter: 2 out of 5.0
Validation loss decreased (0.961994 --> 0.960351).  Saving model ...
Validation loss decreased (0.960351 --> 0.958852).  Saving model ...
Validation loss decreased (0.958852 --> 0.953872).  Saving model ...
Validation loss decreased (0.953872 --> 0.950899).  Saving model ...
Validation loss decreased (0.950899 --> 0.950073).  Saving model ...
EarlyStopping counter: 1 out of 5.0
Validation loss decreased (0.950073 --> 0.945696).  Saving model ...
EarlyStopping counter: 1 out of 5.0
EarlyStopping counter: 2 out of 5.0
EarlyStopping counter: 3 out of 5.0
Validation loss decreased (0.945696 --> 0.942978).  Saving model ...
Validation loss decreased (0.942978 --> 0.940199).  Saving model ...
EarlyStopping counter: 1 out of 5.0
Validation loss decreased (0.940199 --> 0.938281).  Saving model ...
Validation loss decreased (0.938281 --> 0.935691).  Saving model ...
EarlyStopping counter: 1 out of 5.0
EarlyStopping counter: 2 out of 5.0
Validation loss decreased (0.935691 --> 0.935155).  Saving model ...
Validation loss decreased (0.935155 --> 0.933750).  Saving model ...
EarlyStopping counter: 1 out of 5.0
EarlyStopping counter: 2 out of 5.0
Validation loss decreased (0.933750 --> 0.932914).  Saving model ...
Validation loss decreased (0.932914 --> 0.931029).  Saving model ...
Validation loss decreased (0.931029 --> 0.928540).  Saving model ...
EarlyStopping counter: 1 out of 5.0
EarlyStopping counter: 2 out of 5.0
Validation loss decreased (0.928540 --> 0.928013).  Saving model ...
EarlyStopping counter: 1 out of 5.0
Validation loss decreased (0.928013 --> 0.927217).  Saving model ...
EarlyStopping counter: 1 out of 5.0
EarlyStopping counter: 2 out of 5.0
Validation loss decreased (0.927217 --> 0.924076).  Saving model ...
EarlyStopping counter: 1 out of 5.0
EarlyStopping counter: 2 out of 5.0
EarlyStopping counter: 3 out of 5.0
EarlyStopping counter: 4 out of 5.0
EarlyStopping counter: 5 out of 5.0
/localscratch/yinan.29351708.0/env/lib/python3.7/site-packages/torch/nn/functional.py:1794: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.
  warnings.warn("nn.functional.tanh is deprecated. Use torch.tanh instead.")
wandb: Waiting for W&B process to finish, PID 113127... (success).
wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: \ 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: | 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: / 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: \ 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: | 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: / 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: \ 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: | 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: / 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb:                                                                                
wandb: Run history:
wandb:     e_F1 ▁▃▄▄▄▄▄▅▅▆▆▆▆▆▆▇▇▇▇▇▇▇▇▇▇▇██████████████
wandb:   e_loss █▇▇▇▇▆▆▆▅▅▅▄▄▄▄▃▃▃▃▃▂▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁
wandb:     t_F1 ▁▂▃▃▄▄▄▄▅▅▅▅▅▆▆▆▆▆▆▆▇▆▇▇▆▇▇▆▇▇▇▇▇▇▇▇▇▇██
wandb:   t_loss ██▇▇▇▇▇▆▆▆▆▅▅▅▅▄▄▄▄▄▄▄▃▃▃▃▃▃▂▂▂▂▂▂▂▂▁▂▁▁
wandb: 
wandb: Run summary:
wandb:     e_F1 61.34624
wandb:   e_loss 0.93012
wandb:     t_F1 74.53192
wandb:   t_loss 0.72674
wandb: 
wandb: Synced 4 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Synced colorful-galaxy-2: https://wandb.ai/yinanazhou/xl_512_bs_8_lr_1e06_es_5_lc_False_nr_False_sr_True_stem_False_lemma_True_repeat_5_fold_1/runs/25nok7mp
wandb: Find logs at: ./wandb/run-20220328_162848-25nok7mp/logs/debug.log
wandb: 

wandb: wandb version 0.12.11 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
2022-03-28 17:50:23.502151: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1
wandb: Tracking run with wandb version 0.12.5
wandb: Syncing run fallen-cloud-2
wandb: ⭐️ View project at https://wandb.ai/yinanazhou/xl_512_bs_8_lr_1e06_es_5_lc_False_nr_False_sr_True_stem_False_lemma_True_repeat_5_fold_2
wandb: 🚀 View run at https://wandb.ai/yinanazhou/xl_512_bs_8_lr_1e06_es_5_lc_False_nr_False_sr_True_stem_False_lemma_True_repeat_5_fold_2/runs/2pkva1pd
wandb: Run data is saved locally in /project/6002780/yinan/Thesis_MER_Lyrics/lyric-emotion/wandb/run-20220328_175021-2pkva1pd
wandb: Run `wandb offline` to turn off syncing.

Validation loss decreased (inf --> 1.383628).  Saving model ...
Validation loss decreased (1.383628 --> 1.377681).  Saving model ...
Validation loss decreased (1.377681 --> 1.372694).  Saving model ...
Validation loss decreased (1.372694 --> 1.367594).  Saving model ...
Validation loss decreased (1.367594 --> 1.362943).  Saving model ...
Validation loss decreased (1.362943 --> 1.358518).  Saving model ...
Validation loss decreased (1.358518 --> 1.353648).  Saving model ...
Validation loss decreased (1.353648 --> 1.349043).  Saving model ...
Validation loss decreased (1.349043 --> 1.344288).  Saving model ...
Validation loss decreased (1.344288 --> 1.339846).  Saving model ...
Validation loss decreased (1.339846 --> 1.334853).  Saving model ...
Validation loss decreased (1.334853 --> 1.329499).  Saving model ...
Validation loss decreased (1.329499 --> 1.324828).  Saving model ...
Validation loss decreased (1.324828 --> 1.319384).  Saving model ...
Validation loss decreased (1.319384 --> 1.313911).  Saving model ...
Validation loss decreased (1.313911 --> 1.308464).  Saving model ...
Validation loss decreased (1.308464 --> 1.302198).  Saving model ...
Validation loss decreased (1.302198 --> 1.295966).  Saving model ...
Validation loss decreased (1.295966 --> 1.289684).  Saving model ...
Validation loss decreased (1.289684 --> 1.282663).  Saving model ...
Validation loss decreased (1.282663 --> 1.275281).  Saving model ...
Validation loss decreased (1.275281 --> 1.267359).  Saving model ...
Validation loss decreased (1.267359 --> 1.259164).  Saving model ...
Validation loss decreased (1.259164 --> 1.251568).  Saving model ...
Validation loss decreased (1.251568 --> 1.243233).  Saving model ...
Validation loss decreased (1.243233 --> 1.234881).  Saving model ...
Validation loss decreased (1.234881 --> 1.226541).  Saving model ...
Validation loss decreased (1.226541 --> 1.217857).  Saving model ...
Validation loss decreased (1.217857 --> 1.209170).  Saving model ...
Validation loss decreased (1.209170 --> 1.200705).  Saving model ...
Validation loss decreased (1.200705 --> 1.192753).  Saving model ...
Validation loss decreased (1.192753 --> 1.183909).  Saving model ...
Validation loss decreased (1.183909 --> 1.175095).  Saving model ...
Validation loss decreased (1.175095 --> 1.165143).  Saving model ...
Validation loss decreased (1.165143 --> 1.156259).  Saving model ...
Validation loss decreased (1.156259 --> 1.146498).  Saving model ...
Validation loss decreased (1.146498 --> 1.138834).  Saving model ...
Validation loss decreased (1.138834 --> 1.130984).  Saving model ...
Validation loss decreased (1.130984 --> 1.120587).  Saving model ...
Validation loss decreased (1.120587 --> 1.111733).  Saving model ...
Validation loss decreased (1.111733 --> 1.102713).  Saving model ...
Validation loss decreased (1.102713 --> 1.094638).  Saving model ...
Validation loss decreased (1.094638 --> 1.088675).  Saving model ...
Validation loss decreased (1.088675 --> 1.081170).  Saving model ...
Validation loss decreased (1.081170 --> 1.075492).  Saving model ...
Validation loss decreased (1.075492 --> 1.069855).  Saving model ...
Validation loss decreased (1.069855 --> 1.062032).  Saving model ...
Validation loss decreased (1.062032 --> 1.054960).  Saving model ...
Validation loss decreased (1.054960 --> 1.050393).  Saving model ...
Validation loss decreased (1.050393 --> 1.044432).  Saving model ...
Validation loss decreased (1.044432 --> 1.039311).  Saving model ...
Validation loss decreased (1.039311 --> 1.033650).  Saving model ...
Validation loss decreased (1.033650 --> 1.029394).  Saving model ...
Validation loss decreased (1.029394 --> 1.025962).  Saving model ...
Validation loss decreased (1.025962 --> 1.019572).  Saving model ...
Validation loss decreased (1.019572 --> 1.014886).  Saving model ...
Validation loss decreased (1.014886 --> 1.012997).  Saving model ...
Validation loss decreased (1.012997 --> 1.008619).  Saving model ...
Validation loss decreased (1.008619 --> 1.005051).  Saving model ...
Validation loss decreased (1.005051 --> 1.001190).  Saving model ...
Validation loss decreased (1.001190 --> 0.998312).  Saving model ...
Validation loss decreased (0.998312 --> 0.994152).  Saving model ...
Validation loss decreased (0.994152 --> 0.989259).  Saving model ...
Validation loss decreased (0.989259 --> 0.985941).  Saving model ...
Validation loss decreased (0.985941 --> 0.983410).  Saving model ...
Validation loss decreased (0.983410 --> 0.979257).  Saving model ...
Validation loss decreased (0.979257 --> 0.976384).  Saving model ...
Validation loss decreased (0.976384 --> 0.975075).  Saving model ...
Validation loss decreased (0.975075 --> 0.971953).  Saving model ...
Validation loss decreased (0.971953 --> 0.970100).  Saving model ...
Validation loss decreased (0.970100 --> 0.966867).  Saving model ...
Validation loss decreased (0.966867 --> 0.964405).  Saving model ...
Validation loss decreased (0.964405 --> 0.962379).  Saving model ...
Validation loss decreased (0.962379 --> 0.959754).  Saving model ...
Validation loss decreased (0.959754 --> 0.957614).  Saving model ...
Validation loss decreased (0.957614 --> 0.956162).  Saving model ...
Validation loss decreased (0.956162 --> 0.953821).  Saving model ...
Validation loss decreased (0.953821 --> 0.951420).  Saving model ...
Validation loss decreased (0.951420 --> 0.947702).  Saving model ...
Validation loss decreased (0.947702 --> 0.947468).  Saving model ...
Validation loss decreased (0.947468 --> 0.945779).  Saving model ...
Validation loss decreased (0.945779 --> 0.944517).  Saving model ...
EarlyStopping counter: 1 out of 5.0
Validation loss decreased (0.944517 --> 0.942532).  Saving model ...
Validation loss decreased (0.942532 --> 0.939812).  Saving model ...
Validation loss decreased (0.939812 --> 0.936713).  Saving model ...
EarlyStopping counter: 1 out of 5.0
Validation loss decreased (0.936713 --> 0.935174).  Saving model ...
EarlyStopping counter: 1 out of 5.0
EarlyStopping counter: 2 out of 5.0
Validation loss decreased (0.935174 --> 0.932488).  Saving model ...
Validation loss decreased (0.932488 --> 0.929653).  Saving model ...
Validation loss decreased (0.929653 --> 0.927251).  Saving model ...
Validation loss decreased (0.927251 --> 0.927226).  Saving model ...
Validation loss decreased (0.927226 --> 0.923566).  Saving model ...
EarlyStopping counter: 1 out of 5.0
Validation loss decreased (0.923566 --> 0.923434).  Saving model ...
Validation loss decreased (0.923434 --> 0.921085).  Saving model ...
Validation loss decreased (0.921085 --> 0.920668).  Saving model ...
Validation loss decreased (0.920668 --> 0.920516).  Saving model ...
EarlyStopping counter: 1 out of 5.0
Validation loss decreased (0.920516 --> 0.918655).  Saving model ...
Validation loss decreased (0.918655 --> 0.915087).  Saving model ...
EarlyStopping counter: 1 out of 5.0
EarlyStopping counter: 2 out of 5.0
Validation loss decreased (0.915087 --> 0.914930).  Saving model ...
Validation loss decreased (0.914930 --> 0.912033).  Saving model ...
EarlyStopping counter: 1 out of 5.0
Validation loss decreased (0.912033 --> 0.911159).  Saving model ...
EarlyStopping counter: 1 out of 5.0
Validation loss decreased (0.911159 --> 0.910419).  Saving model ...
EarlyStopping counter: 1 out of 5.0
EarlyStopping counter: 2 out of 5.0
EarlyStopping counter: 3 out of 5.0
EarlyStopping counter: 4 out of 5.0
EarlyStopping counter: 5 out of 5.0
/localscratch/yinan.29351708.0/env/lib/python3.7/site-packages/torch/nn/functional.py:1794: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.
  warnings.warn("nn.functional.tanh is deprecated. Use torch.tanh instead.")
wandb: Waiting for W&B process to finish, PID 117587... (success).
wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: \ 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: | 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: / 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: \ 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: | 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: / 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: \ 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: | 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: / 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb:                                                                                
wandb: Run history:
wandb:     e_F1 ▁▂▃▃▄▄▄▅▅▆▆▆▆▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇███████████
wandb:   e_loss ███▇▇▇▇▆▆▆▅▅▄▄▄▃▃▃▃▃▂▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁
wandb:     t_F1 ▁▂▁▂▃▃▃▃▄▅▅▅▅▆▆▆▆▆▆▇▆▇▆▆▇▇▇▇▇▇█▇████████
wandb:   t_loss ███▇▇▇▇▇▇▆▆▆▅▅▅▄▄▄▄▄▄▃▃▃▃▃▃▃▃▂▂▂▂▂▂▂▁▁▁▁
wandb: 
wandb: Run summary:
wandb:     e_F1 63.44359
wandb:   e_loss 0.91243
wandb:     t_F1 69.54727
wandb:   t_loss 0.7952
wandb: 
wandb: Synced 4 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Synced fallen-cloud-2: https://wandb.ai/yinanazhou/xl_512_bs_8_lr_1e06_es_5_lc_False_nr_False_sr_True_stem_False_lemma_True_repeat_5_fold_2/runs/2pkva1pd
wandb: Find logs at: ./wandb/run-20220328_175021-2pkva1pd/logs/debug.log
wandb: 

