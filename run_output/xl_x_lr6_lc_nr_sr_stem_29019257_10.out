Unloading StdEnv/2020

Due to MODULEPATH changes, the following have been reloaded:
  1) mii/1.1.1


The following have been reloaded with a version change:
  1) python/3.8.2 => python/3.7.4

Using base prefix '/cvmfs/soft.computecanada.ca/easybuild/software/2017/Core/python/3.7.4'
New python executable in /localscratch/yinan.29019257.0/env/bin/python
Installing setuptools, pip, wheel...
done.
Ignoring pip: markers 'python_version < "3"' don't match your environment
Looking in links: /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/nix/avx2, /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/nix/generic, /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic
Collecting pip
Installing collected packages: pip
  Found existing installation: pip 19.1.1
    Uninstalling pip-19.1.1:
      Successfully uninstalled pip-19.1.1
Successfully installed pip-21.2.3+computecanada
Looking in links: /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/nix/avx2, /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/nix/generic, /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/keras-2.8.0+computecanada-py2.py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/Keras_Preprocessing-1.1.2+computecanada-py3-none-any.whl
Requirement already satisfied: matplotlib in /cvmfs/soft.computecanada.ca/easybuild/software/2017/Core/scipy-stack/2019a/lib/python3.7/site-packages (from -r requirements.txt (line 3)) (3.0.2)
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/nltk-3.6.5+computecanada-py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/scikit_learn-0.22.1+computecanada-cp37-cp37m-linux_x86_64.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/tensorboard-2.3.0+computecanada-py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/tensorboard_plugin_wit-1.7.0+computecanada-py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/tensorflow_gpu-2.3.0+computecanada-cp37-cp37m-linux_x86_64.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/tensorflow_estimator-2.3.0+computecanada-py2.py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/tokenizers-0.5.2+computecanada-cp37-cp37m-linux_x86_64.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/nix/avx2/torch-1.4.0+computecanada-cp37-cp37m-linux_x86_64.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/torchtext-0.6.0+computecanada-py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/torchvision-0.8.2+computecanada-cp37-cp37m-linux_x86_64.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/transformers-2.5.1+computecanada-py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/urllib3-1.26.7+computecanada-py2.py3-none-any.whl
ERROR: Could not find a version that satisfies the requirement regex>=2021.8.3 (from nltk) (from versions: 2018.1.10+computecanada, 2019.11.1+computecanada, 2020.11.13+computecanada)
ERROR: No matching distribution found for regex>=2021.8.3
Looking in links: /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/nix/avx2, /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/nix/generic, /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic
ERROR: Could not find a version that satisfies the requirement numpy==1.20.0+computacanada (from versions: 1.15.0+computecanada, 1.15.2+computecanada, 1.15.4+computecanada, 1.16.0+computecanada, 1.16.2+computecanada, 1.16.3+computecanada, 1.17.4+computecanada, 1.18.1+computecanada, 1.18.4+computecanada, 1.19.1+computecanada, 1.19.2+computecanada, 1.20.2+computecanada)
ERROR: No matching distribution found for numpy==1.20.0+computacanada
Looking in links: /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/nix/avx2, /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/nix/generic, /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/wandb-0.12.5+computecanada-py2.py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/promise-2.3+computecanada-py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/six-1.16.0+computecanada-py2.py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/configparser-5.0.2+computecanada-py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/protobuf-3.19.4+computecanada-py2.py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/shortuuid-1.0.1+computecanada-py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/sentry_sdk-1.5.0+computecanada-py2.py3-none-any.whl
Requirement already satisfied: requests<3,>=2.0.0 in /cvmfs/soft.computecanada.ca/easybuild/software/2017/Core/scipy-stack/2019a/lib/python3.7/site-packages (from wandb) (2.21.0)
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/click-8.0.4+computecanada-py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/psutil-5.7.3+computecanada-cp37-cp37m-linux_x86_64.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/PyYAML-5.3.1+computecanada-cp37-cp37m-linux_x86_64.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/docker_pycreds-0.4.0+computecanada-py2.py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/pathtools-0.1.2+computecanada-py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/GitPython-3.1.24+computecanada-py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/subprocess32-3.5.4+computecanada-py3-none-any.whl
Requirement already satisfied: python-dateutil>=2.6.1 in /cvmfs/soft.computecanada.ca/easybuild/software/2017/Core/scipy-stack/2019a/lib/python3.7/site-packages (from wandb) (2.7.5)
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/yaspin-2.1.0+computecanada-py3-none-any.whl
Requirement already satisfied: importlib-metadata in /cvmfs/soft.computecanada.ca/easybuild/software/2017/Core/scipy-stack/2019a/lib/python3.7/site-packages (from Click!=8.0.0,>=7.0->wandb) (0.8)
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/typing_extensions-4.0.1+computecanada-py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/gitdb-4.0.9+computecanada-py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/smmap-5.0.0+computecanada-py3-none-any.whl
Requirement already satisfied: urllib3<1.25,>=1.21.1 in /cvmfs/soft.computecanada.ca/easybuild/software/2017/Core/scipy-stack/2019a/lib/python3.7/site-packages (from requests<3,>=2.0.0->wandb) (1.24.1)
Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /cvmfs/soft.computecanada.ca/easybuild/software/2017/Core/scipy-stack/2019a/lib/python3.7/site-packages (from requests<3,>=2.0.0->wandb) (3.0.4)
Requirement already satisfied: idna<2.9,>=2.5 in /cvmfs/soft.computecanada.ca/easybuild/software/2017/Core/scipy-stack/2019a/lib/python3.7/site-packages (from requests<3,>=2.0.0->wandb) (2.8)
Requirement already satisfied: certifi>=2017.4.17 in /cvmfs/soft.computecanada.ca/easybuild/software/2017/Core/scipy-stack/2019a/lib/python3.7/site-packages (from requests<3,>=2.0.0->wandb) (2018.11.29)
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/termcolor-1.1.0+computecanada-py3-none-any.whl
Requirement already satisfied: zipp>=0.3.2 in /cvmfs/soft.computecanada.ca/easybuild/software/2017/Core/scipy-stack/2019a/lib/python3.7/site-packages (from importlib-metadata->Click!=8.0.0,>=7.0->wandb) (0.3.3)
Installing collected packages: smmap, typing-extensions, termcolor, six, gitdb, yaspin, subprocess32, shortuuid, sentry-sdk, PyYAML, psutil, protobuf, promise, pathtools, GitPython, docker-pycreds, configparser, Click, wandb
  Attempting uninstall: six
    Found existing installation: six 1.12.0
    Not uninstalling six at /cvmfs/soft.computecanada.ca/easybuild/software/2017/Core/scipy-stack/2019a/lib/python3.7/site-packages, outside environment /localscratch/yinan.29019257.0/env
    Can't uninstall 'six'. No files were found to uninstall.
Successfully installed Click-8.0.4+computecanada GitPython-3.1.24+computecanada PyYAML-5.3.1+computecanada configparser-5.0.2+computecanada docker-pycreds-0.4.0+computecanada gitdb-4.0.9+computecanada pathtools-0.1.2+computecanada promise-2.3+computecanada protobuf-3.19.4+computecanada psutil-5.7.3+computecanada sentry-sdk-1.5.0+computecanada shortuuid-1.0.1+computecanada six-1.16.0+computecanada smmap-5.0.0+computecanada subprocess32-3.5.4+computecanada termcolor-1.1.0+computecanada typing-extensions-4.0.1+computecanada wandb-0.12.5+computecanada yaspin-2.1.0+computecanada
Looking in links: /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/nix/avx2, /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/nix/generic, /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic
ERROR: Could not find a version that satisfies the requirement sagemaker (from versions: none)
ERROR: No matching distribution found for sagemaker
Looking in links: /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/nix/avx2, /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/nix/generic, /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/torch-1.9.1+computecanada-cp37-cp37m-linux_x86_64.whl
Requirement already satisfied: typing-extensions in /localscratch/yinan.29019257.0/env/lib/python3.7/site-packages (from torch) (4.0.1+computecanada)
Installing collected packages: torch
Successfully installed torch-1.9.1+computecanada
Looking in links: /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/nix/avx2, /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/nix/generic, /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/transformers-2.5.1+computecanada-py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/tqdm-4.63.0+computecanada-py2.py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/boto3-1.21.14+computecanada-py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/filelock-3.4.2+computecanada-py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/sentencepiece-0.1.91+computecanada-cp37-cp37m-linux_x86_64.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/sacremoses-0.0.46+computecanada-py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/regex-2020.11.13+computecanada-cp37-cp37m-linux_x86_64.whl
Requirement already satisfied: requests in /cvmfs/soft.computecanada.ca/easybuild/software/2017/Core/scipy-stack/2019a/lib/python3.7/site-packages (from transformers==2.5.1+computecanada) (2.21.0)
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/tokenizers-0.5.2+computecanada-cp37-cp37m-linux_x86_64.whl
Requirement already satisfied: numpy in /cvmfs/soft.computecanada.ca/easybuild/software/2017/Core/scipy-stack/2019a/lib/python3.7/site-packages (from transformers==2.5.1+computecanada) (1.16.0)
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/s3transfer-0.5.1+computecanada-py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/jmespath-0.10.0+computecanada-py2.py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/botocore-1.24.14+computecanada-py3-none-any.whl
Requirement already satisfied: python-dateutil<3.0.0,>=2.1 in /cvmfs/soft.computecanada.ca/easybuild/software/2017/Core/scipy-stack/2019a/lib/python3.7/site-packages (from botocore<1.25.0,>=1.24.14->boto3->transformers==2.5.1+computecanada) (2.7.5)
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/urllib3-1.26.8+computecanada-py2.py3-none-any.whl
Requirement already satisfied: six>=1.5 in /localscratch/yinan.29019257.0/env/lib/python3.7/site-packages (from python-dateutil<3.0.0,>=2.1->botocore<1.25.0,>=1.24.14->boto3->transformers==2.5.1+computecanada) (1.16.0+computecanada)
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/requests-2.27.1+computecanada-py2.py3-none-any.whl
Requirement already satisfied: idna<4,>=2.5 in /cvmfs/soft.computecanada.ca/easybuild/software/2017/Core/scipy-stack/2019a/lib/python3.7/site-packages (from requests->transformers==2.5.1+computecanada) (2.8)
Requirement already satisfied: certifi>=2017.4.17 in /cvmfs/soft.computecanada.ca/easybuild/software/2017/Core/scipy-stack/2019a/lib/python3.7/site-packages (from requests->transformers==2.5.1+computecanada) (2018.11.29)
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/charset_normalizer-2.0.12+computecanada-py3-none-any.whl
Requirement already satisfied: click in /localscratch/yinan.29019257.0/env/lib/python3.7/site-packages (from sacremoses->transformers==2.5.1+computecanada) (8.0.4+computecanada)
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/joblib-1.1.0+computecanada-py2.py3-none-any.whl
Requirement already satisfied: importlib-metadata in /cvmfs/soft.computecanada.ca/easybuild/software/2017/Core/scipy-stack/2019a/lib/python3.7/site-packages (from click->sacremoses->transformers==2.5.1+computecanada) (0.8)
Requirement already satisfied: zipp>=0.3.2 in /cvmfs/soft.computecanada.ca/easybuild/software/2017/Core/scipy-stack/2019a/lib/python3.7/site-packages (from importlib-metadata->click->sacremoses->transformers==2.5.1+computecanada) (0.3.3)
Installing collected packages: urllib3, jmespath, botocore, tqdm, s3transfer, regex, joblib, charset-normalizer, tokenizers, sentencepiece, sacremoses, requests, filelock, boto3, transformers
  Attempting uninstall: urllib3
    Found existing installation: urllib3 1.24.1
    Not uninstalling urllib3 at /cvmfs/soft.computecanada.ca/easybuild/software/2017/Core/scipy-stack/2019a/lib/python3.7/site-packages, outside environment /localscratch/yinan.29019257.0/env
    Can't uninstall 'urllib3'. No files were found to uninstall.
  Attempting uninstall: requests
    Found existing installation: requests 2.21.0
    Not uninstalling requests at /cvmfs/soft.computecanada.ca/easybuild/software/2017/Core/scipy-stack/2019a/lib/python3.7/site-packages, outside environment /localscratch/yinan.29019257.0/env
    Can't uninstall 'requests'. No files were found to uninstall.
Successfully installed boto3-1.21.14+computecanada botocore-1.24.14+computecanada charset-normalizer-2.0.12+computecanada filelock-3.4.2+computecanada jmespath-0.10.0+computecanada joblib-1.1.0+computecanada regex-2020.11.13+computecanada requests-2.27.1+computecanada s3transfer-0.5.1+computecanada sacremoses-0.0.46+computecanada sentencepiece-0.1.91+computecanada tokenizers-0.5.2+computecanada tqdm-4.63.0+computecanada transformers-2.5.1+computecanada urllib3-1.26.8+computecanada
Looking in links: /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/nix/avx2, /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/nix/generic, /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/tensorflow_gpu-2.3.0+computecanada-cp37-cp37m-linux_x86_64.whl
Requirement already satisfied: six>=1.12.0 in /localscratch/yinan.29019257.0/env/lib/python3.7/site-packages (from tensorflow_gpu==2.3.0+computecanada) (1.16.0+computecanada)
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/gast-0.3.3+computecanada-py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/tensorflow_estimator-2.3.0+computecanada-py2.py3-none-any.whl
Requirement already satisfied: wheel>=0.26 in /localscratch/yinan.29019257.0/env/lib/python3.7/site-packages (from tensorflow_gpu==2.3.0+computecanada) (0.33.4)
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/absl_py-1.0.0+computecanada-py3-none-any.whl
Requirement already satisfied: numpy<1.19.0,>=1.16.0 in /cvmfs/soft.computecanada.ca/easybuild/software/2017/Core/scipy-stack/2019a/lib/python3.7/site-packages (from tensorflow_gpu==2.3.0+computecanada) (1.16.0)
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/google_pasta-0.2.0+computecanada-py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/nix/generic/scipy-1.4.1+computecanada-cp37-cp37m-linux_x86_64.whl
Requirement already satisfied: protobuf>=3.9.2 in /localscratch/yinan.29019257.0/env/lib/python3.7/site-packages (from tensorflow_gpu==2.3.0+computecanada) (3.19.4+computecanada)
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/grpcio-1.38.0+computecanada-cp37-cp37m-linux_x86_64.whl
Requirement already satisfied: termcolor>=1.1.0 in /localscratch/yinan.29019257.0/env/lib/python3.7/site-packages (from tensorflow_gpu==2.3.0+computecanada) (1.1.0+computecanada)
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/wrapt-1.11.2+computecanada-cp37-cp37m-linux_x86_64.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/nix/avx2/h5py-2.10.0+computecanada-cp37-cp37m-linux_x86_64.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/tensorboard-2.8.0+computecanada-py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/Keras_Preprocessing-1.1.2+computecanada-py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/astunparse-1.6.3+computecanada-py2.py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/opt_einsum-3.3.0+computecanada-py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/tensorboard_data_server-0.6.1+computecanada-py3-none-linux_x86_64.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/tensorboard_plugin_wit-1.8.0+computecanada-py3-none-any.whl
Requirement already satisfied: setuptools>=41.0.0 in /localscratch/yinan.29019257.0/env/lib/python3.7/site-packages (from tensorboard<3,>=2.3.0->tensorflow_gpu==2.3.0+computecanada) (41.0.1)
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/Werkzeug-2.0.3+computecanada-py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/Markdown-3.3.6+computecanada-py3-none-any.whl
Requirement already satisfied: requests<3,>=2.21.0 in /localscratch/yinan.29019257.0/env/lib/python3.7/site-packages (from tensorboard<3,>=2.3.0->tensorflow_gpu==2.3.0+computecanada) (2.27.1+computecanada)
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/google_auth-2.3.3+computecanada-py2.py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/google_auth_oauthlib-0.4.6+computecanada-py2.py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/pyasn1_modules-0.2.8+computecanada-py2.py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/cachetools-4.2.4+computecanada-py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/rsa-4.8+computecanada-py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/requests_oauthlib-1.3.0+computecanada-py2.py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/importlib_metadata-4.10.1+computecanada-py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/zipp-3.7.0+computecanada-py3-none-any.whl
Requirement already satisfied: typing-extensions>=3.6.4 in /localscratch/yinan.29019257.0/env/lib/python3.7/site-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard<3,>=2.3.0->tensorflow_gpu==2.3.0+computecanada) (4.0.1+computecanada)
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/pyasn1-0.4.8+computecanada-py2.py3-none-any.whl
Requirement already satisfied: urllib3<1.27,>=1.21.1 in /localscratch/yinan.29019257.0/env/lib/python3.7/site-packages (from requests<3,>=2.21.0->tensorboard<3,>=2.3.0->tensorflow_gpu==2.3.0+computecanada) (1.26.8+computecanada)
Requirement already satisfied: idna<4,>=2.5 in /cvmfs/soft.computecanada.ca/easybuild/software/2017/Core/scipy-stack/2019a/lib/python3.7/site-packages (from requests<3,>=2.21.0->tensorboard<3,>=2.3.0->tensorflow_gpu==2.3.0+computecanada) (2.8)
Requirement already satisfied: charset-normalizer~=2.0.0 in /localscratch/yinan.29019257.0/env/lib/python3.7/site-packages (from requests<3,>=2.21.0->tensorboard<3,>=2.3.0->tensorflow_gpu==2.3.0+computecanada) (2.0.12+computecanada)
Requirement already satisfied: certifi>=2017.4.17 in /cvmfs/soft.computecanada.ca/easybuild/software/2017/Core/scipy-stack/2019a/lib/python3.7/site-packages (from requests<3,>=2.21.0->tensorboard<3,>=2.3.0->tensorflow_gpu==2.3.0+computecanada) (2018.11.29)
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/oauthlib-3.1.1+computecanada-py2.py3-none-any.whl
Installing collected packages: pyasn1, zipp, rsa, pyasn1-modules, oauthlib, cachetools, requests-oauthlib, importlib-metadata, google-auth, werkzeug, tensorboard-plugin-wit, tensorboard-data-server, markdown, grpcio, google-auth-oauthlib, absl-py, wrapt, tensorflow-estimator, tensorboard, scipy, opt-einsum, keras-preprocessing, h5py, google-pasta, gast, astunparse, tensorflow-gpu
  Attempting uninstall: pyasn1
    Found existing installation: pyasn1 0.4.3
    Not uninstalling pyasn1 at /cvmfs/soft.computecanada.ca/easybuild/software/2017/Core/scipy-stack/2019a/lib/python3.7/site-packages, outside environment /localscratch/yinan.29019257.0/env
    Can't uninstall 'pyasn1'. No files were found to uninstall.
  Attempting uninstall: zipp
    Found existing installation: zipp 0.3.3
    Not uninstalling zipp at /cvmfs/soft.computecanada.ca/easybuild/software/2017/Core/scipy-stack/2019a/lib/python3.7/site-packages, outside environment /localscratch/yinan.29019257.0/env
    Can't uninstall 'zipp'. No files were found to uninstall.
  Attempting uninstall: importlib-metadata
    Found existing installation: importlib-metadata 0.8
    Not uninstalling importlib-metadata at /cvmfs/soft.computecanada.ca/easybuild/software/2017/Core/scipy-stack/2019a/lib/python3.7/site-packages, outside environment /localscratch/yinan.29019257.0/env
    Can't uninstall 'importlib-metadata'. No files were found to uninstall.
  Attempting uninstall: scipy
    Found existing installation: scipy 1.2.0
    Not uninstalling scipy at /cvmfs/soft.computecanada.ca/easybuild/software/2017/Core/scipy-stack/2019a/lib/python3.7/site-packages, outside environment /localscratch/yinan.29019257.0/env
    Can't uninstall 'scipy'. No files were found to uninstall.
Successfully installed absl-py-1.0.0+computecanada astunparse-1.6.3+computecanada cachetools-4.2.4+computecanada gast-0.3.3+computecanada google-auth-2.3.3+computecanada google-auth-oauthlib-0.4.6+computecanada google-pasta-0.2.0+computecanada grpcio-1.38.0+computecanada h5py-2.10.0+computecanada importlib-metadata-4.10.1+computecanada keras-preprocessing-1.1.2+computecanada markdown-3.3.6+computecanada oauthlib-3.1.1+computecanada opt-einsum-3.3.0+computecanada pyasn1-0.4.8+computecanada pyasn1-modules-0.2.8+computecanada requests-oauthlib-1.3.0+computecanada rsa-4.8+computecanada scipy-1.4.1+computecanada tensorboard-2.8.0+computecanada tensorboard-data-server-0.6.1+computecanada tensorboard-plugin-wit-1.8.0+computecanada tensorflow-estimator-2.3.0+computecanada tensorflow-gpu-2.3.0+computecanada werkzeug-2.0.3+computecanada wrapt-1.11.2+computecanada zipp-3.7.0+computecanada
Looking in links: /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/nix/avx2, /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/nix/generic, /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/keras-2.8.0+computecanada-py2.py3-none-any.whl
Installing collected packages: Keras
Successfully installed Keras-2.8.0+computecanada
Looking in links: /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/nix/avx2, /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/nix/generic, /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/urllib3-1.26.7+computecanada-py2.py3-none-any.whl
Installing collected packages: urllib3
  Attempting uninstall: urllib3
    Found existing installation: urllib3 1.26.8+computecanada
    Uninstalling urllib3-1.26.8+computecanada:
      Successfully uninstalled urllib3-1.26.8+computecanada
Successfully installed urllib3-1.26.7+computecanada
Looking in links: /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/nix/avx2, /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/nix/generic, /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/nltk-3.7+computecanada-py3-none-any.whl
Requirement already satisfied: click in /localscratch/yinan.29019257.0/env/lib/python3.7/site-packages (from nltk) (8.0.4+computecanada)
Requirement already satisfied: joblib in /localscratch/yinan.29019257.0/env/lib/python3.7/site-packages (from nltk) (1.1.0+computecanada)
Requirement already satisfied: tqdm in /localscratch/yinan.29019257.0/env/lib/python3.7/site-packages (from nltk) (4.63.0+computecanada)
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/nltk-3.6.5+computecanada-py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/nltk-3.6.3+computecanada-py3-none-any.whl
Requirement already satisfied: regex in /localscratch/yinan.29019257.0/env/lib/python3.7/site-packages (from nltk) (2020.11.13+computecanada)
Requirement already satisfied: importlib-metadata in /localscratch/yinan.29019257.0/env/lib/python3.7/site-packages (from click->nltk) (4.10.1+computecanada)
Requirement already satisfied: zipp>=0.5 in /localscratch/yinan.29019257.0/env/lib/python3.7/site-packages (from importlib-metadata->click->nltk) (3.7.0+computecanada)
Requirement already satisfied: typing-extensions>=3.6.4 in /localscratch/yinan.29019257.0/env/lib/python3.7/site-packages (from importlib-metadata->click->nltk) (4.0.1+computecanada)
Installing collected packages: nltk
Successfully installed nltk-3.6.3+computecanada
Looking in links: /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/nix/avx2, /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/nix/generic, /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/scikit_learn-0.22.1+computecanada-cp37-cp37m-linux_x86_64.whl
Requirement already satisfied: joblib>=0.11 in /localscratch/yinan.29019257.0/env/lib/python3.7/site-packages (from scikit-learn==0.22.1) (1.1.0+computecanada)
Requirement already satisfied: scipy>=0.17.0 in /localscratch/yinan.29019257.0/env/lib/python3.7/site-packages (from scikit-learn==0.22.1) (1.4.1+computecanada)
Requirement already satisfied: numpy>=1.11.0 in /cvmfs/soft.computecanada.ca/easybuild/software/2017/Core/scipy-stack/2019a/lib/python3.7/site-packages (from scikit-learn==0.22.1) (1.16.0)
Installing collected packages: scikit-learn
Successfully installed scikit-learn-0.22.1+computecanada
Looking in links: /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/nix/avx2, /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/nix/generic, /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic
Requirement already satisfied: tokenizers==0.5.2 in /localscratch/yinan.29019257.0/env/lib/python3.7/site-packages (0.5.2+computecanada)
wandb: Appending key for api.wandb.ai to your netrc file: /home/yinan/.netrc
Starting Task
2022-03-17 05:23:49.817371: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1
[nltk_data] Downloading package stopwords to /home/yinan/nltk_data...
[nltk_data]   Package stopwords is already up-to-date!
[nltk_data] Downloading package wordnet to /home/yinan/nltk_data...
[nltk_data]   Package wordnet is already up-to-date!
wandb: Currently logged in as: yinanazhou (use `wandb login --relogin` to force relogin)
wandb: wandb version 0.12.11 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
2022-03-17 05:24:08.329940: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1
wandb: Tracking run with wandb version 0.12.5
wandb: Syncing run rural-grass-2
wandb: ⭐️ View project at https://wandb.ai/yinanazhou/xl_512_bs_8_lr_1e06_es_10_lc_True_nr_True_sr_True_stem_True_lemma_False_repeat_1_fold_1
wandb: 🚀 View run at https://wandb.ai/yinanazhou/xl_512_bs_8_lr_1e06_es_10_lc_True_nr_True_sr_True_stem_True_lemma_False_repeat_1_fold_1/runs/ilnpc585
wandb: Run data is saved locally in /project/6002780/yinan/Thesis_MER_Lyrics/lyric-emotion/wandb/run-20220317_052406-ilnpc585
wandb: Run `wandb offline` to turn off syncing.

Validation loss decreased (inf --> 1.430802).  Saving model ...
Validation loss decreased (1.430802 --> 1.412844).  Saving model ...
Validation loss decreased (1.412844 --> 1.397584).  Saving model ...
Validation loss decreased (1.397584 --> 1.386169).  Saving model ...
Validation loss decreased (1.386169 --> 1.377412).  Saving model ...
Validation loss decreased (1.377412 --> 1.369765).  Saving model ...
Validation loss decreased (1.369765 --> 1.364451).  Saving model ...
Validation loss decreased (1.364451 --> 1.359499).  Saving model ...
Validation loss decreased (1.359499 --> 1.355043).  Saving model ...
Validation loss decreased (1.355043 --> 1.350380).  Saving model ...
Validation loss decreased (1.350380 --> 1.346062).  Saving model ...
Validation loss decreased (1.346062 --> 1.342096).  Saving model ...
Validation loss decreased (1.342096 --> 1.338372).  Saving model ...
Validation loss decreased (1.338372 --> 1.334480).  Saving model ...
Validation loss decreased (1.334480 --> 1.330222).  Saving model ...
Validation loss decreased (1.330222 --> 1.326268).  Saving model ...
Validation loss decreased (1.326268 --> 1.322305).  Saving model ...
Validation loss decreased (1.322305 --> 1.318177).  Saving model ...
Validation loss decreased (1.318177 --> 1.313915).  Saving model ...
Validation loss decreased (1.313915 --> 1.308910).  Saving model ...
Validation loss decreased (1.308910 --> 1.304758).  Saving model ...
Validation loss decreased (1.304758 --> 1.300695).  Saving model ...
Validation loss decreased (1.300695 --> 1.296857).  Saving model ...
Validation loss decreased (1.296857 --> 1.292195).  Saving model ...
Validation loss decreased (1.292195 --> 1.287799).  Saving model ...
Validation loss decreased (1.287799 --> 1.283709).  Saving model ...
Validation loss decreased (1.283709 --> 1.279681).  Saving model ...
Validation loss decreased (1.279681 --> 1.276568).  Saving model ...
Validation loss decreased (1.276568 --> 1.274172).  Saving model ...
Validation loss decreased (1.274172 --> 1.271892).  Saving model ...
Validation loss decreased (1.271892 --> 1.269055).  Saving model ...
Validation loss decreased (1.269055 --> 1.264359).  Saving model ...
Validation loss decreased (1.264359 --> 1.263599).  Saving model ...
Validation loss decreased (1.263599 --> 1.258447).  Saving model ...
Validation loss decreased (1.258447 --> 1.258193).  Saving model ...
Validation loss decreased (1.258193 --> 1.254563).  Saving model ...
Validation loss decreased (1.254563 --> 1.252902).  Saving model ...
Validation loss decreased (1.252902 --> 1.249198).  Saving model ...
Validation loss decreased (1.249198 --> 1.247007).  Saving model ...
Validation loss decreased (1.247007 --> 1.244498).  Saving model ...
Validation loss decreased (1.244498 --> 1.240359).  Saving model ...
Validation loss decreased (1.240359 --> 1.235253).  Saving model ...
Validation loss decreased (1.235253 --> 1.232360).  Saving model ...
EarlyStopping counter: 1 out of 10.0
Validation loss decreased (1.232360 --> 1.229351).  Saving model ...
Validation loss decreased (1.229351 --> 1.226187).  Saving model ...
Validation loss decreased (1.226187 --> 1.225632).  Saving model ...
Validation loss decreased (1.225632 --> 1.222413).  Saving model ...
Validation loss decreased (1.222413 --> 1.221576).  Saving model ...
Validation loss decreased (1.221576 --> 1.217515).  Saving model ...
Validation loss decreased (1.217515 --> 1.217336).  Saving model ...
Validation loss decreased (1.217336 --> 1.213143).  Saving model ...
Validation loss decreased (1.213143 --> 1.211339).  Saving model ...
Validation loss decreased (1.211339 --> 1.209193).  Saving model ...
Validation loss decreased (1.209193 --> 1.207602).  Saving model ...
Validation loss decreased (1.207602 --> 1.202671).  Saving model ...
Validation loss decreased (1.202671 --> 1.198777).  Saving model ...
Validation loss decreased (1.198777 --> 1.195545).  Saving model ...
EarlyStopping counter: 1 out of 10.0
EarlyStopping counter: 2 out of 10.0
Validation loss decreased (1.195545 --> 1.188393).  Saving model ...
EarlyStopping counter: 1 out of 10.0
Validation loss decreased (1.188393 --> 1.181933).  Saving model ...
Validation loss decreased (1.181933 --> 1.181053).  Saving model ...
Validation loss decreased (1.181053 --> 1.180043).  Saving model ...
Validation loss decreased (1.180043 --> 1.174617).  Saving model ...
Validation loss decreased (1.174617 --> 1.173421).  Saving model ...
Validation loss decreased (1.173421 --> 1.170380).  Saving model ...
Validation loss decreased (1.170380 --> 1.168580).  Saving model ...
EarlyStopping counter: 1 out of 10.0
Validation loss decreased (1.168580 --> 1.166111).  Saving model ...
Validation loss decreased (1.166111 --> 1.165434).  Saving model ...
Validation loss decreased (1.165434 --> 1.162438).  Saving model ...
Validation loss decreased (1.162438 --> 1.155211).  Saving model ...
Validation loss decreased (1.155211 --> 1.152384).  Saving model ...
EarlyStopping counter: 1 out of 10.0
EarlyStopping counter: 2 out of 10.0
Validation loss decreased (1.152384 --> 1.148845).  Saving model ...
Validation loss decreased (1.148845 --> 1.145520).  Saving model ...
Validation loss decreased (1.145520 --> 1.142184).  Saving model ...
Validation loss decreased (1.142184 --> 1.141996).  Saving model ...
Validation loss decreased (1.141996 --> 1.141032).  Saving model ...
Validation loss decreased (1.141032 --> 1.139475).  Saving model ...
Validation loss decreased (1.139475 --> 1.138199).  Saving model ...
Validation loss decreased (1.138199 --> 1.132230).  Saving model ...
Validation loss decreased (1.132230 --> 1.126876).  Saving model ...
Validation loss decreased (1.126876 --> 1.126766).  Saving model ...
EarlyStopping counter: 1 out of 10.0
Validation loss decreased (1.126766 --> 1.125239).  Saving model ...
Validation loss decreased (1.125239 --> 1.123873).  Saving model ...
Validation loss decreased (1.123873 --> 1.120806).  Saving model ...
EarlyStopping counter: 1 out of 10.0
Validation loss decreased (1.120806 --> 1.120740).  Saving model ...
Validation loss decreased (1.120740 --> 1.119868).  Saving model ...
EarlyStopping counter: 1 out of 10.0
Validation loss decreased (1.119868 --> 1.116751).  Saving model ...
EarlyStopping counter: 1 out of 10.0
Validation loss decreased (1.116751 --> 1.114840).  Saving model ...
Validation loss decreased (1.114840 --> 1.111464).  Saving model ...
Validation loss decreased (1.111464 --> 1.111410).  Saving model ...
Validation loss decreased (1.111410 --> 1.111180).  Saving model ...
Validation loss decreased (1.111180 --> 1.109421).  Saving model ...
Validation loss decreased (1.109421 --> 1.103078).  Saving model ...
EarlyStopping counter: 1 out of 10.0
Validation loss decreased (1.103078 --> 1.102789).  Saving model ...
Validation loss decreased (1.102789 --> 1.098237).  Saving model ...
Validation loss decreased (1.098237 --> 1.095197).  Saving model ...
EarlyStopping counter: 1 out of 10.0
Validation loss decreased (1.095197 --> 1.094284).  Saving model ...
Validation loss decreased (1.094284 --> 1.087418).  Saving model ...
EarlyStopping counter: 1 out of 10.0
EarlyStopping counter: 2 out of 10.0
EarlyStopping counter: 3 out of 10.0
EarlyStopping counter: 4 out of 10.0
EarlyStopping counter: 5 out of 10.0
EarlyStopping counter: 6 out of 10.0
EarlyStopping counter: 7 out of 10.0
Validation loss decreased (1.087418 --> 1.086362).  Saving model ...
Validation loss decreased (1.086362 --> 1.086146).  Saving model ...
Validation loss decreased (1.086146 --> 1.081499).  Saving model ...
Validation loss decreased (1.081499 --> 1.078169).  Saving model ...
EarlyStopping counter: 1 out of 10.0
Validation loss decreased (1.078169 --> 1.074296).  Saving model ...
Validation loss decreased (1.074296 --> 1.074023).  Saving model ...
Validation loss decreased (1.074023 --> 1.073705).  Saving model ...
EarlyStopping counter: 1 out of 10.0
EarlyStopping counter: 2 out of 10.0
EarlyStopping counter: 3 out of 10.0
Validation loss decreased (1.073705 --> 1.072853).  Saving model ...
EarlyStopping counter: 1 out of 10.0
EarlyStopping counter: 2 out of 10.0
EarlyStopping counter: 3 out of 10.0
EarlyStopping counter: 4 out of 10.0
Validation loss decreased (1.072853 --> 1.071051).  Saving model ...
EarlyStopping counter: 1 out of 10.0
EarlyStopping counter: 2 out of 10.0
Validation loss decreased (1.071051 --> 1.069813).  Saving model ...
Validation loss decreased (1.069813 --> 1.069597).  Saving model ...
EarlyStopping counter: 1 out of 10.0
Validation loss decreased (1.069597 --> 1.063671).  Saving model ...
EarlyStopping counter: 1 out of 10.0
Validation loss decreased (1.063671 --> 1.063644).  Saving model ...
EarlyStopping counter: 1 out of 10.0
EarlyStopping counter: 2 out of 10.0
EarlyStopping counter: 3 out of 10.0
EarlyStopping counter: 4 out of 10.0
Validation loss decreased (1.063644 --> 1.063150).  Saving model ...
EarlyStopping counter: 1 out of 10.0
Validation loss decreased (1.063150 --> 1.062243).  Saving model ...
Validation loss decreased (1.062243 --> 1.061827).  Saving model ...
EarlyStopping counter: 1 out of 10.0
EarlyStopping counter: 2 out of 10.0
EarlyStopping counter: 3 out of 10.0
EarlyStopping counter: 4 out of 10.0
Validation loss decreased (1.061827 --> 1.060616).  Saving model ...
Validation loss decreased (1.060616 --> 1.056358).  Saving model ...
EarlyStopping counter: 1 out of 10.0
EarlyStopping counter: 2 out of 10.0
EarlyStopping counter: 3 out of 10.0
EarlyStopping counter: 4 out of 10.0
EarlyStopping counter: 5 out of 10.0
EarlyStopping counter: 6 out of 10.0
EarlyStopping counter: 7 out of 10.0
EarlyStopping counter: 8 out of 10.0
EarlyStopping counter: 9 out of 10.0
EarlyStopping counter: 10 out of 10.0
/localscratch/yinan.29019257.0/env/lib/python3.7/site-packages/torch/nn/functional.py:1794: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.
  warnings.warn("nn.functional.tanh is deprecated. Use torch.tanh instead.")
/localscratch/yinan.29019257.0/env/lib/python3.7/site-packages/transformers/optimization.py:155: UserWarning: This overload of add_ is deprecated:
	add_(Number alpha, Tensor other)
Consider using one of the following signatures instead:
	add_(Tensor other, *, Number alpha) (Triggered internally at  ../torch/csrc/utils/python_arg_parser.cpp:1025.)
  exp_avg.mul_(beta1).add_(1.0 - beta1, grad)
wandb: Waiting for W&B process to finish, PID 88784... (success).
wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: \ 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: | 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: / 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: \ 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: | 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: / 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: \ 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: | 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: / 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb:                                                                                
wandb: Run history:
wandb:     e_F1 ▁▃▄▄▄▅▅▅▅▅▆▆▆▆▆▆▆▇▇▇▇▇▇▇▇▇▇▇▇███████████
wandb:   e_loss █▇▇▆▆▆▅▅▅▅▄▄▄▄▄▃▃▃▃▃▂▂▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁
wandb:     t_F1 ▁▂▂▃▃▄▄▄▅▅▅▆▆▅▆▆▆▆▆▇▆▇▇▇▇▇▇▇▇▇███▇██████
wandb:   t_loss █▇▇▇▇▆▆▆▆▅▅▅▄▅▄▄▄▄▄▃▃▃▃▃▃▃▂▂▂▂▂▂▁▁▂▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:     e_F1 53.31829
wandb:   e_loss 1.06595
wandb:     t_F1 69.3076
wandb:   t_loss 0.74176
wandb: 
wandb: Synced 4 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Synced rural-grass-2: https://wandb.ai/yinanazhou/xl_512_bs_8_lr_1e06_es_10_lc_True_nr_True_sr_True_stem_True_lemma_False_repeat_1_fold_1/runs/ilnpc585
wandb: Find logs at: ./wandb/run-20220317_052406-ilnpc585/logs/debug.log
wandb: 

wandb: wandb version 0.12.11 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
2022-03-17 07:10:11.724071: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1
wandb: Tracking run with wandb version 0.12.5
wandb: Syncing run silver-morning-1
wandb: ⭐️ View project at https://wandb.ai/yinanazhou/xl_512_bs_8_lr_1e06_es_10_lc_True_nr_True_sr_True_stem_True_lemma_False_repeat_1_fold_2
wandb: 🚀 View run at https://wandb.ai/yinanazhou/xl_512_bs_8_lr_1e06_es_10_lc_True_nr_True_sr_True_stem_True_lemma_False_repeat_1_fold_2/runs/37i83ftp
wandb: Run data is saved locally in /project/6002780/yinan/Thesis_MER_Lyrics/lyric-emotion/wandb/run-20220317_071008-37i83ftp
wandb: Run `wandb offline` to turn off syncing.

Validation loss decreased (inf --> 1.500107).  Saving model ...
Validation loss decreased (1.500107 --> 1.454231).  Saving model ...
Validation loss decreased (1.454231 --> 1.425723).  Saving model ...
Validation loss decreased (1.425723 --> 1.409317).  Saving model ...
Validation loss decreased (1.409317 --> 1.397978).  Saving model ...
Validation loss decreased (1.397978 --> 1.390963).  Saving model ...
Validation loss decreased (1.390963 --> 1.385040).  Saving model ...
Validation loss decreased (1.385040 --> 1.380769).  Saving model ...
Validation loss decreased (1.380769 --> 1.377083).  Saving model ...
Validation loss decreased (1.377083 --> 1.373764).  Saving model ...
Validation loss decreased (1.373764 --> 1.370306).  Saving model ...
Validation loss decreased (1.370306 --> 1.366031).  Saving model ...
Validation loss decreased (1.366031 --> 1.361927).  Saving model ...
Validation loss decreased (1.361927 --> 1.358376).  Saving model ...
Validation loss decreased (1.358376 --> 1.354112).  Saving model ...
Validation loss decreased (1.354112 --> 1.350247).  Saving model ...
Validation loss decreased (1.350247 --> 1.345737).  Saving model ...
Validation loss decreased (1.345737 --> 1.342101).  Saving model ...
Validation loss decreased (1.342101 --> 1.338442).  Saving model ...
Validation loss decreased (1.338442 --> 1.334604).  Saving model ...
Validation loss decreased (1.334604 --> 1.330426).  Saving model ...
Validation loss decreased (1.330426 --> 1.326653).  Saving model ...
Validation loss decreased (1.326653 --> 1.322494).  Saving model ...
Validation loss decreased (1.322494 --> 1.318119).  Saving model ...
Validation loss decreased (1.318119 --> 1.313703).  Saving model ...
Validation loss decreased (1.313703 --> 1.308965).  Saving model ...
Validation loss decreased (1.308965 --> 1.304231).  Saving model ...
Validation loss decreased (1.304231 --> 1.299556).  Saving model ...
Validation loss decreased (1.299556 --> 1.294084).  Saving model ...
Validation loss decreased (1.294084 --> 1.289493).  Saving model ...
Validation loss decreased (1.289493 --> 1.285509).  Saving model ...
Validation loss decreased (1.285509 --> 1.280549).  Saving model ...
Validation loss decreased (1.280549 --> 1.275353).  Saving model ...
Validation loss decreased (1.275353 --> 1.269599).  Saving model ...
Validation loss decreased (1.269599 --> 1.264216).  Saving model ...
Validation loss decreased (1.264216 --> 1.259076).  Saving model ...
Validation loss decreased (1.259076 --> 1.254368).  Saving model ...
Validation loss decreased (1.254368 --> 1.249788).  Saving model ...
Validation loss decreased (1.249788 --> 1.244945).  Saving model ...
Validation loss decreased (1.244945 --> 1.240334).  Saving model ...
Validation loss decreased (1.240334 --> 1.235291).  Saving model ...
Validation loss decreased (1.235291 --> 1.229842).  Saving model ...
Validation loss decreased (1.229842 --> 1.224733).  Saving model ...
Validation loss decreased (1.224733 --> 1.219368).  Saving model ...
Validation loss decreased (1.219368 --> 1.213496).  Saving model ...
Validation loss decreased (1.213496 --> 1.207755).  Saving model ...
Validation loss decreased (1.207755 --> 1.201499).  Saving model ...
Validation loss decreased (1.201499 --> 1.196494).  Saving model ...
Validation loss decreased (1.196494 --> 1.190321).  Saving model ...
Validation loss decreased (1.190321 --> 1.184937).  Saving model ...
Validation loss decreased (1.184937 --> 1.180039).  Saving model ...
Validation loss decreased (1.180039 --> 1.174429).  Saving model ...
Validation loss decreased (1.174429 --> 1.169022).  Saving model ...
Validation loss decreased (1.169022 --> 1.164124).  Saving model ...
Validation loss decreased (1.164124 --> 1.158895).  Saving model ...
Validation loss decreased (1.158895 --> 1.153566).  Saving model ...
Validation loss decreased (1.153566 --> 1.148658).  Saving model ...
Validation loss decreased (1.148658 --> 1.143349).  Saving model ...
Validation loss decreased (1.143349 --> 1.137944).  Saving model ...
Validation loss decreased (1.137944 --> 1.132684).  Saving model ...
Validation loss decreased (1.132684 --> 1.127351).  Saving model ...
Validation loss decreased (1.127351 --> 1.121793).  Saving model ...
Validation loss decreased (1.121793 --> 1.116463).  Saving model ...
Validation loss decreased (1.116463 --> 1.112427).  Saving model ...
Validation loss decreased (1.112427 --> 1.107664).  Saving model ...
Validation loss decreased (1.107664 --> 1.103567).  Saving model ...
Validation loss decreased (1.103567 --> 1.099610).  Saving model ...
Validation loss decreased (1.099610 --> 1.094958).  Saving model ...
Validation loss decreased (1.094958 --> 1.090508).  Saving model ...
Validation loss decreased (1.090508 --> 1.086982).  Saving model ...
Validation loss decreased (1.086982 --> 1.081918).  Saving model ...
Validation loss decreased (1.081918 --> 1.077567).  Saving model ...
Validation loss decreased (1.077567 --> 1.074117).  Saving model ...
Validation loss decreased (1.074117 --> 1.069779).  Saving model ...
Validation loss decreased (1.069779 --> 1.065719).  Saving model ...
Validation loss decreased (1.065719 --> 1.062118).  Saving model ...
Validation loss decreased (1.062118 --> 1.058322).  Saving model ...
Validation loss decreased (1.058322 --> 1.055334).  Saving model ...
Validation loss decreased (1.055334 --> 1.052401).  Saving model ...
Validation loss decreased (1.052401 --> 1.049631).  Saving model ...
Validation loss decreased (1.049631 --> 1.045706).  Saving model ...
Validation loss decreased (1.045706 --> 1.042660).  Saving model ...
Validation loss decreased (1.042660 --> 1.039610).  Saving model ...
Validation loss decreased (1.039610 --> 1.036473).  Saving model ...
Validation loss decreased (1.036473 --> 1.033149).  Saving model ...
Validation loss decreased (1.033149 --> 1.030201).  Saving model ...
Validation loss decreased (1.030201 --> 1.027832).  Saving model ...
Validation loss decreased (1.027832 --> 1.024953).  Saving model ...
Validation loss decreased (1.024953 --> 1.021370).  Saving model ...
Validation loss decreased (1.021370 --> 1.018896).  Saving model ...
Validation loss decreased (1.018896 --> 1.016155).  Saving model ...
Validation loss decreased (1.016155 --> 1.013639).  Saving model ...
Validation loss decreased (1.013639 --> 1.011044).  Saving model ...
Validation loss decreased (1.011044 --> 1.009138).  Saving model ...
Validation loss decreased (1.009138 --> 1.006816).  Saving model ...
Validation loss decreased (1.006816 --> 1.004592).  Saving model ...
Validation loss decreased (1.004592 --> 1.002498).  Saving model ...
Validation loss decreased (1.002498 --> 1.000177).  Saving model ...
Validation loss decreased (1.000177 --> 0.997452).  Saving model ...
Validation loss decreased (0.997452 --> 0.995742).  Saving model ...
Validation loss decreased (0.995742 --> 0.993527).  Saving model ...
Validation loss decreased (0.993527 --> 0.991208).  Saving model ...
Validation loss decreased (0.991208 --> 0.989183).  Saving model ...
Validation loss decreased (0.989183 --> 0.987727).  Saving model ...
Validation loss decreased (0.987727 --> 0.985501).  Saving model ...
Validation loss decreased (0.985501 --> 0.984032).  Saving model ...
Validation loss decreased (0.984032 --> 0.982255).  Saving model ...
Validation loss decreased (0.982255 --> 0.980397).  Saving model ...
Validation loss decreased (0.980397 --> 0.978903).  Saving model ...
Validation loss decreased (0.978903 --> 0.977133).  Saving model ...
Validation loss decreased (0.977133 --> 0.975911).  Saving model ...
Validation loss decreased (0.975911 --> 0.974569).  Saving model ...
Validation loss decreased (0.974569 --> 0.973188).  Saving model ...
Validation loss decreased (0.973188 --> 0.972200).  Saving model ...
Validation loss decreased (0.972200 --> 0.971086).  Saving model ...
Validation loss decreased (0.971086 --> 0.969307).  Saving model ...
Validation loss decreased (0.969307 --> 0.967878).  Saving model ...
Validation loss decreased (0.967878 --> 0.966846).  Saving model ...
Validation loss decreased (0.966846 --> 0.966304).  Saving model ...
Validation loss decreased (0.966304 --> 0.965279).  Saving model ...
Validation loss decreased (0.965279 --> 0.964011).  Saving model ...
Validation loss decreased (0.964011 --> 0.963614).  Saving model ...
Validation loss decreased (0.963614 --> 0.962114).  Saving model ...
Validation loss decreased (0.962114 --> 0.961915).  Saving model ...
Validation loss decreased (0.961915 --> 0.960789).  Saving model ...
Validation loss decreased (0.960789 --> 0.960269).  Saving model ...
Validation loss decreased (0.960269 --> 0.959272).  Saving model ...
Validation loss decreased (0.959272 --> 0.958755).  Saving model ...
Validation loss decreased (0.958755 --> 0.957995).  Saving model ...
Validation loss decreased (0.957995 --> 0.957376).  Saving model ...
Validation loss decreased (0.957376 --> 0.957225).  Saving model ...
Validation loss decreased (0.957225 --> 0.956677).  Saving model ...
Validation loss decreased (0.956677 --> 0.956306).  Saving model ...
Validation loss decreased (0.956306 --> 0.955346).  Saving model ...
Validation loss decreased (0.955346 --> 0.954837).  Saving model ...
Validation loss decreased (0.954837 --> 0.954218).  Saving model ...
Validation loss decreased (0.954218 --> 0.953914).  Saving model ...
Validation loss decreased (0.953914 --> 0.953225).  Saving model ...
Validation loss decreased (0.953225 --> 0.952996).  Saving model ...
EarlyStopping counter: 1 out of 10.0
Validation loss decreased (0.952996 --> 0.951698).  Saving model ...
Validation loss decreased (0.951698 --> 0.951223).  Saving model ...
Validation loss decreased (0.951223 --> 0.951142).  Saving model ...
Validation loss decreased (0.951142 --> 0.950500).  Saving model ...
Validation loss decreased (0.950500 --> 0.949948).  Saving model ...
Validation loss decreased (0.949948 --> 0.949354).  Saving model ...
Validation loss decreased (0.949354 --> 0.948507).  Saving model ...
EarlyStopping counter: 1 out of 10.0
EarlyStopping counter: 2 out of 10.0
EarlyStopping counter: 3 out of 10.0
EarlyStopping counter: 4 out of 10.0
EarlyStopping counter: 5 out of 10.0
Validation loss decreased (0.948507 --> 0.948434).  Saving model ...
Validation loss decreased (0.948434 --> 0.948373).  Saving model ...
EarlyStopping counter: 1 out of 10.0
EarlyStopping counter: 2 out of 10.0
EarlyStopping counter: 3 out of 10.0
EarlyStopping counter: 4 out of 10.0
EarlyStopping counter: 5 out of 10.0
EarlyStopping counter: 6 out of 10.0
EarlyStopping counter: 7 out of 10.0
EarlyStopping counter: 8 out of 10.0
EarlyStopping counter: 9 out of 10.0
EarlyStopping counter: 10 out of 10.0
/localscratch/yinan.29019257.0/env/lib/python3.7/site-packages/torch/nn/functional.py:1794: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.
  warnings.warn("nn.functional.tanh is deprecated. Use torch.tanh instead.")
wandb: Waiting for W&B process to finish, PID 94493... (success).
wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: \ 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: | 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: / 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: \ 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: | 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: / 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: \ 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: | 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: / 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: \ 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb:                                                                                
wandb: Run history:
wandb:     e_F1 ▁▂▃▄▅▅▆▆▆▆▆▇▇▇▇▇▇▇▇▇▇▇▇██▇██████████████
wandb:   e_loss █▇▇▇▆▆▆▆▅▅▅▅▄▄▄▃▃▃▃▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:     t_F1 ▁▂▂▃▃▃▄▃▄▄▄▅▅▅▆▅▆▆▅▆▆▆▆▆▇▇▇█▇▇██▇▇▇█████
wandb:   t_loss █▇▇▇▇▇▆▆▆▆▆▅▅▅▅▅▄▄▄▄▄▃▃▃▃▃▃▂▂▂▂▂▂▁▂▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:     e_F1 59.40669
wandb:   e_loss 0.94903
wandb:     t_F1 71.56671
wandb:   t_loss 0.78073
wandb: 
wandb: Synced 4 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Synced silver-morning-1: https://wandb.ai/yinanazhou/xl_512_bs_8_lr_1e06_es_10_lc_True_nr_True_sr_True_stem_True_lemma_False_repeat_1_fold_2/runs/37i83ftp
wandb: Find logs at: ./wandb/run-20220317_071008-37i83ftp/logs/debug.log
wandb: 

wandb: wandb version 0.12.11 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
2022-03-17 08:54:52.729291: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1
wandb: Tracking run with wandb version 0.12.5
wandb: Syncing run hardy-shape-1
wandb: ⭐️ View project at https://wandb.ai/yinanazhou/xl_512_bs_8_lr_1e06_es_10_lc_True_nr_True_sr_True_stem_True_lemma_False_repeat_2_fold_1
wandb: 🚀 View run at https://wandb.ai/yinanazhou/xl_512_bs_8_lr_1e06_es_10_lc_True_nr_True_sr_True_stem_True_lemma_False_repeat_2_fold_1/runs/1i1a8qz3
wandb: Run data is saved locally in /project/6002780/yinan/Thesis_MER_Lyrics/lyric-emotion/wandb/run-20220317_085449-1i1a8qz3
wandb: Run `wandb offline` to turn off syncing.

Validation loss decreased (inf --> 1.409993).  Saving model ...
Validation loss decreased (1.409993 --> 1.396863).  Saving model ...
Validation loss decreased (1.396863 --> 1.386296).  Saving model ...
Validation loss decreased (1.386296 --> 1.378734).  Saving model ...
Validation loss decreased (1.378734 --> 1.372884).  Saving model ...
Validation loss decreased (1.372884 --> 1.367933).  Saving model ...
Validation loss decreased (1.367933 --> 1.363651).  Saving model ...
Validation loss decreased (1.363651 --> 1.359839).  Saving model ...
Validation loss decreased (1.359839 --> 1.356485).  Saving model ...
Validation loss decreased (1.356485 --> 1.353347).  Saving model ...
Validation loss decreased (1.353347 --> 1.349902).  Saving model ...
Validation loss decreased (1.349902 --> 1.346442).  Saving model ...
Validation loss decreased (1.346442 --> 1.343002).  Saving model ...
Validation loss decreased (1.343002 --> 1.339841).  Saving model ...
Validation loss decreased (1.339841 --> 1.336418).  Saving model ...
Validation loss decreased (1.336418 --> 1.333048).  Saving model ...
Validation loss decreased (1.333048 --> 1.329667).  Saving model ...
Validation loss decreased (1.329667 --> 1.326297).  Saving model ...
Validation loss decreased (1.326297 --> 1.322901).  Saving model ...
Validation loss decreased (1.322901 --> 1.319140).  Saving model ...
Validation loss decreased (1.319140 --> 1.314959).  Saving model ...
Validation loss decreased (1.314959 --> 1.311014).  Saving model ...
Validation loss decreased (1.311014 --> 1.306728).  Saving model ...
Validation loss decreased (1.306728 --> 1.302761).  Saving model ...
Validation loss decreased (1.302761 --> 1.298985).  Saving model ...
Validation loss decreased (1.298985 --> 1.294037).  Saving model ...
Validation loss decreased (1.294037 --> 1.289964).  Saving model ...
Validation loss decreased (1.289964 --> 1.285930).  Saving model ...
Validation loss decreased (1.285930 --> 1.281169).  Saving model ...
Validation loss decreased (1.281169 --> 1.276410).  Saving model ...
Validation loss decreased (1.276410 --> 1.271258).  Saving model ...
Validation loss decreased (1.271258 --> 1.265564).  Saving model ...
Validation loss decreased (1.265564 --> 1.258858).  Saving model ...
Validation loss decreased (1.258858 --> 1.253855).  Saving model ...
Validation loss decreased (1.253855 --> 1.248296).  Saving model ...
Validation loss decreased (1.248296 --> 1.242010).  Saving model ...
Validation loss decreased (1.242010 --> 1.235383).  Saving model ...
Validation loss decreased (1.235383 --> 1.228973).  Saving model ...
Validation loss decreased (1.228973 --> 1.223024).  Saving model ...
Validation loss decreased (1.223024 --> 1.216703).  Saving model ...
Validation loss decreased (1.216703 --> 1.210809).  Saving model ...
Validation loss decreased (1.210809 --> 1.204745).  Saving model ...
Validation loss decreased (1.204745 --> 1.197906).  Saving model ...
Validation loss decreased (1.197906 --> 1.191358).  Saving model ...
Validation loss decreased (1.191358 --> 1.186111).  Saving model ...
Validation loss decreased (1.186111 --> 1.181716).  Saving model ...
Validation loss decreased (1.181716 --> 1.176000).  Saving model ...
Validation loss decreased (1.176000 --> 1.170982).  Saving model ...
Validation loss decreased (1.170982 --> 1.167791).  Saving model ...
Validation loss decreased (1.167791 --> 1.163715).  Saving model ...
Validation loss decreased (1.163715 --> 1.158591).  Saving model ...
Validation loss decreased (1.158591 --> 1.157729).  Saving model ...
Validation loss decreased (1.157729 --> 1.155439).  Saving model ...
Validation loss decreased (1.155439 --> 1.149779).  Saving model ...
Validation loss decreased (1.149779 --> 1.145757).  Saving model ...
Validation loss decreased (1.145757 --> 1.141558).  Saving model ...
Validation loss decreased (1.141558 --> 1.138025).  Saving model ...
Validation loss decreased (1.138025 --> 1.134335).  Saving model ...
Validation loss decreased (1.134335 --> 1.132894).  Saving model ...
Validation loss decreased (1.132894 --> 1.129455).  Saving model ...
Validation loss decreased (1.129455 --> 1.124910).  Saving model ...
Validation loss decreased (1.124910 --> 1.123542).  Saving model ...
Validation loss decreased (1.123542 --> 1.121519).  Saving model ...
Validation loss decreased (1.121519 --> 1.118047).  Saving model ...
Validation loss decreased (1.118047 --> 1.114402).  Saving model ...
Validation loss decreased (1.114402 --> 1.110948).  Saving model ...
Validation loss decreased (1.110948 --> 1.109297).  Saving model ...
Validation loss decreased (1.109297 --> 1.104769).  Saving model ...
Validation loss decreased (1.104769 --> 1.101650).  Saving model ...
Validation loss decreased (1.101650 --> 1.098798).  Saving model ...
Validation loss decreased (1.098798 --> 1.096888).  Saving model ...
Validation loss decreased (1.096888 --> 1.095802).  Saving model ...
Validation loss decreased (1.095802 --> 1.092272).  Saving model ...
Validation loss decreased (1.092272 --> 1.088247).  Saving model ...
Validation loss decreased (1.088247 --> 1.087312).  Saving model ...
Validation loss decreased (1.087312 --> 1.085105).  Saving model ...
Validation loss decreased (1.085105 --> 1.082950).  Saving model ...
Validation loss decreased (1.082950 --> 1.081782).  Saving model ...
Validation loss decreased (1.081782 --> 1.080158).  Saving model ...
Validation loss decreased (1.080158 --> 1.076057).  Saving model ...
Validation loss decreased (1.076057 --> 1.074001).  Saving model ...
Validation loss decreased (1.074001 --> 1.073916).  Saving model ...
Validation loss decreased (1.073916 --> 1.070321).  Saving model ...
Validation loss decreased (1.070321 --> 1.067828).  Saving model ...
Validation loss decreased (1.067828 --> 1.067453).  Saving model ...
Validation loss decreased (1.067453 --> 1.065117).  Saving model ...
EarlyStopping counter: 1 out of 10.0
Validation loss decreased (1.065117 --> 1.061319).  Saving model ...
Validation loss decreased (1.061319 --> 1.059924).  Saving model ...
Validation loss decreased (1.059924 --> 1.057807).  Saving model ...
EarlyStopping counter: 1 out of 10.0
Validation loss decreased (1.057807 --> 1.054827).  Saving model ...
Validation loss decreased (1.054827 --> 1.054760).  Saving model ...
Validation loss decreased (1.054760 --> 1.053923).  Saving model ...
Validation loss decreased (1.053923 --> 1.052170).  Saving model ...
Validation loss decreased (1.052170 --> 1.049766).  Saving model ...
Validation loss decreased (1.049766 --> 1.049034).  Saving model ...
Validation loss decreased (1.049034 --> 1.048369).  Saving model ...
Validation loss decreased (1.048369 --> 1.044941).  Saving model ...
Validation loss decreased (1.044941 --> 1.044004).  Saving model ...
Validation loss decreased (1.044004 --> 1.040697).  Saving model ...
Validation loss decreased (1.040697 --> 1.040135).  Saving model ...
EarlyStopping counter: 1 out of 10.0
EarlyStopping counter: 2 out of 10.0
Validation loss decreased (1.040135 --> 1.037816).  Saving model ...
Validation loss decreased (1.037816 --> 1.035888).  Saving model ...
Validation loss decreased (1.035888 --> 1.034550).  Saving model ...
Validation loss decreased (1.034550 --> 1.032793).  Saving model ...
EarlyStopping counter: 1 out of 10.0
Validation loss decreased (1.032793 --> 1.031069).  Saving model ...
Validation loss decreased (1.031069 --> 1.029216).  Saving model ...
Validation loss decreased (1.029216 --> 1.028532).  Saving model ...
Validation loss decreased (1.028532 --> 1.028168).  Saving model ...
EarlyStopping counter: 1 out of 10.0
Validation loss decreased (1.028168 --> 1.027258).  Saving model ...
EarlyStopping counter: 1 out of 10.0
Validation loss decreased (1.027258 --> 1.027208).  Saving model ...
EarlyStopping counter: 1 out of 10.0
Validation loss decreased (1.027208 --> 1.026874).  Saving model ...
Validation loss decreased (1.026874 --> 1.025015).  Saving model ...
EarlyStopping counter: 1 out of 10.0
EarlyStopping counter: 2 out of 10.0
EarlyStopping counter: 3 out of 10.0
Validation loss decreased (1.025015 --> 1.024818).  Saving model ...
Validation loss decreased (1.024818 --> 1.024487).  Saving model ...
EarlyStopping counter: 1 out of 10.0
Validation loss decreased (1.024487 --> 1.021928).  Saving model ...
EarlyStopping counter: 1 out of 10.0
EarlyStopping counter: 2 out of 10.0
Validation loss decreased (1.021928 --> 1.021341).  Saving model ...
EarlyStopping counter: 1 out of 10.0
EarlyStopping counter: 2 out of 10.0
EarlyStopping counter: 3 out of 10.0
Validation loss decreased (1.021341 --> 1.020759).  Saving model ...
EarlyStopping counter: 1 out of 10.0
EarlyStopping counter: 2 out of 10.0
EarlyStopping counter: 3 out of 10.0
EarlyStopping counter: 4 out of 10.0
EarlyStopping counter: 5 out of 10.0
EarlyStopping counter: 6 out of 10.0
EarlyStopping counter: 7 out of 10.0
EarlyStopping counter: 8 out of 10.0
EarlyStopping counter: 9 out of 10.0
EarlyStopping counter: 10 out of 10.0
/localscratch/yinan.29019257.0/env/lib/python3.7/site-packages/torch/nn/functional.py:1794: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.
  warnings.warn("nn.functional.tanh is deprecated. Use torch.tanh instead.")
wandb: Waiting for W&B process to finish, PID 100091... (success).
wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: \ 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: | 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: / 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: \ 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: | 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: / 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: \ 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: | 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: / 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: \ 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: | 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: / 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: \ 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: | 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: / 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: \ 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: | 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: / 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb:                                                                                
wandb: Run history:
wandb:     e_F1 ▁▁▃▄▄▅▅▅▅▆▆▆▆▇▇▇▇▇▇▇▇▇▇█████████████████
wandb:   e_loss ██▇▇▇▇▆▆▆▅▅▄▄▄▄▃▃▃▃▂▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:     t_F1 ▁▁▂▂▂▃▃▄▄▄▅▅▅▅▅▅▆▅▆▆▆▆▆▆▇▆▆▇▇▇▇▇▇▇▇▇████
wandb:   t_loss ███▇▇▇▇▇▆▇▆▆▆▅▅▅▄▄▄▄▄▄▄▃▃▃▃▃▂▃▂▂▂▂▂▂▁▁▁▁
wandb: 
wandb: Run summary:
wandb:     e_F1 56.50415
wandb:   e_loss 1.02309
wandb:     t_F1 73.48522
wandb:   t_loss 0.74462
wandb: 
wandb: Synced 4 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Synced hardy-shape-1: https://wandb.ai/yinanazhou/xl_512_bs_8_lr_1e06_es_10_lc_True_nr_True_sr_True_stem_True_lemma_False_repeat_2_fold_1/runs/1i1a8qz3
wandb: Find logs at: ./wandb/run-20220317_085449-1i1a8qz3/logs/debug.log
wandb: 

wandb: wandb version 0.12.11 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
2022-03-17 10:30:24.488605: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1
wandb: Tracking run with wandb version 0.12.5
wandb: Syncing run frosty-leaf-1
wandb: ⭐️ View project at https://wandb.ai/yinanazhou/xl_512_bs_8_lr_1e06_es_10_lc_True_nr_True_sr_True_stem_True_lemma_False_repeat_2_fold_2
wandb: 🚀 View run at https://wandb.ai/yinanazhou/xl_512_bs_8_lr_1e06_es_10_lc_True_nr_True_sr_True_stem_True_lemma_False_repeat_2_fold_2/runs/3s2fbrgr
wandb: Run data is saved locally in /project/6002780/yinan/Thesis_MER_Lyrics/lyric-emotion/wandb/run-20220317_103021-3s2fbrgr
wandb: Run `wandb offline` to turn off syncing.

Validation loss decreased (inf --> 1.394829).  Saving model ...
Validation loss decreased (1.394829 --> 1.386953).  Saving model ...
Validation loss decreased (1.386953 --> 1.381279).  Saving model ...
Validation loss decreased (1.381279 --> 1.376227).  Saving model ...
Validation loss decreased (1.376227 --> 1.372263).  Saving model ...
Validation loss decreased (1.372263 --> 1.368509).  Saving model ...
Validation loss decreased (1.368509 --> 1.365271).  Saving model ...
Validation loss decreased (1.365271 --> 1.361832).  Saving model ...
Validation loss decreased (1.361832 --> 1.358591).  Saving model ...
Validation loss decreased (1.358591 --> 1.355426).  Saving model ...
Validation loss decreased (1.355426 --> 1.352123).  Saving model ...
Validation loss decreased (1.352123 --> 1.349002).  Saving model ...
Validation loss decreased (1.349002 --> 1.345952).  Saving model ...
Validation loss decreased (1.345952 --> 1.342496).  Saving model ...
Validation loss decreased (1.342496 --> 1.338514).  Saving model ...
Validation loss decreased (1.338514 --> 1.334405).  Saving model ...
Validation loss decreased (1.334405 --> 1.330446).  Saving model ...
Validation loss decreased (1.330446 --> 1.326044).  Saving model ...
Validation loss decreased (1.326044 --> 1.321631).  Saving model ...
Validation loss decreased (1.321631 --> 1.317515).  Saving model ...
Validation loss decreased (1.317515 --> 1.312623).  Saving model ...
Validation loss decreased (1.312623 --> 1.307749).  Saving model ...
Validation loss decreased (1.307749 --> 1.301863).  Saving model ...
Validation loss decreased (1.301863 --> 1.296242).  Saving model ...
Validation loss decreased (1.296242 --> 1.290191).  Saving model ...
Validation loss decreased (1.290191 --> 1.283873).  Saving model ...
Validation loss decreased (1.283873 --> 1.278157).  Saving model ...
Validation loss decreased (1.278157 --> 1.272806).  Saving model ...
Validation loss decreased (1.272806 --> 1.265985).  Saving model ...
Validation loss decreased (1.265985 --> 1.257857).  Saving model ...
Validation loss decreased (1.257857 --> 1.251714).  Saving model ...
Validation loss decreased (1.251714 --> 1.246723).  Saving model ...
Validation loss decreased (1.246723 --> 1.242206).  Saving model ...
Validation loss decreased (1.242206 --> 1.233677).  Saving model ...
Validation loss decreased (1.233677 --> 1.226306).  Saving model ...
Validation loss decreased (1.226306 --> 1.218937).  Saving model ...
Validation loss decreased (1.218937 --> 1.211160).  Saving model ...
Validation loss decreased (1.211160 --> 1.207032).  Saving model ...
Validation loss decreased (1.207032 --> 1.201736).  Saving model ...
Validation loss decreased (1.201736 --> 1.196745).  Saving model ...
Validation loss decreased (1.196745 --> 1.189353).  Saving model ...
Validation loss decreased (1.189353 --> 1.186089).  Saving model ...
Validation loss decreased (1.186089 --> 1.182309).  Saving model ...
Validation loss decreased (1.182309 --> 1.176924).  Saving model ...
Validation loss decreased (1.176924 --> 1.173703).  Saving model ...
Validation loss decreased (1.173703 --> 1.170788).  Saving model ...
Validation loss decreased (1.170788 --> 1.163810).  Saving model ...
Validation loss decreased (1.163810 --> 1.160230).  Saving model ...
Validation loss decreased (1.160230 --> 1.155886).  Saving model ...
Validation loss decreased (1.155886 --> 1.154410).  Saving model ...
Validation loss decreased (1.154410 --> 1.148839).  Saving model ...
Validation loss decreased (1.148839 --> 1.144558).  Saving model ...
Validation loss decreased (1.144558 --> 1.140471).  Saving model ...
Validation loss decreased (1.140471 --> 1.136544).  Saving model ...
Validation loss decreased (1.136544 --> 1.133077).  Saving model ...
Validation loss decreased (1.133077 --> 1.129448).  Saving model ...
Validation loss decreased (1.129448 --> 1.127268).  Saving model ...
Validation loss decreased (1.127268 --> 1.124402).  Saving model ...
Validation loss decreased (1.124402 --> 1.119778).  Saving model ...
Validation loss decreased (1.119778 --> 1.112835).  Saving model ...
EarlyStopping counter: 1 out of 10.0
Validation loss decreased (1.112835 --> 1.111584).  Saving model ...
Validation loss decreased (1.111584 --> 1.107115).  Saving model ...
Validation loss decreased (1.107115 --> 1.102718).  Saving model ...
Validation loss decreased (1.102718 --> 1.099222).  Saving model ...
Validation loss decreased (1.099222 --> 1.096294).  Saving model ...
Validation loss decreased (1.096294 --> 1.093663).  Saving model ...
Validation loss decreased (1.093663 --> 1.089834).  Saving model ...
Validation loss decreased (1.089834 --> 1.087870).  Saving model ...
Validation loss decreased (1.087870 --> 1.083535).  Saving model ...
Validation loss decreased (1.083535 --> 1.078526).  Saving model ...
Validation loss decreased (1.078526 --> 1.075600).  Saving model ...
EarlyStopping counter: 1 out of 10.0
Validation loss decreased (1.075600 --> 1.072246).  Saving model ...
Validation loss decreased (1.072246 --> 1.066416).  Saving model ...
Validation loss decreased (1.066416 --> 1.066131).  Saving model ...
Validation loss decreased (1.066131 --> 1.061150).  Saving model ...
EarlyStopping counter: 1 out of 10.0
Validation loss decreased (1.061150 --> 1.059899).  Saving model ...
Validation loss decreased (1.059899 --> 1.057625).  Saving model ...
Validation loss decreased (1.057625 --> 1.056141).  Saving model ...
Validation loss decreased (1.056141 --> 1.053214).  Saving model ...
Validation loss decreased (1.053214 --> 1.051537).  Saving model ...
Validation loss decreased (1.051537 --> 1.046646).  Saving model ...
Validation loss decreased (1.046646 --> 1.043937).  Saving model ...
Validation loss decreased (1.043937 --> 1.040153).  Saving model ...
Validation loss decreased (1.040153 --> 1.035537).  Saving model ...
EarlyStopping counter: 1 out of 10.0
Validation loss decreased (1.035537 --> 1.035504).  Saving model ...
Validation loss decreased (1.035504 --> 1.031773).  Saving model ...
Validation loss decreased (1.031773 --> 1.029438).  Saving model ...
Validation loss decreased (1.029438 --> 1.024151).  Saving model ...
Validation loss decreased (1.024151 --> 1.021871).  Saving model ...
Validation loss decreased (1.021871 --> 1.019557).  Saving model ...
Validation loss decreased (1.019557 --> 1.018562).  Saving model ...
EarlyStopping counter: 1 out of 10.0
Validation loss decreased (1.018562 --> 1.018347).  Saving model ...
Validation loss decreased (1.018347 --> 1.016198).  Saving model ...
Validation loss decreased (1.016198 --> 1.010620).  Saving model ...
Validation loss decreased (1.010620 --> 1.008486).  Saving model ...
EarlyStopping counter: 1 out of 10.0
EarlyStopping counter: 2 out of 10.0
Validation loss decreased (1.008486 --> 1.006010).  Saving model ...
Validation loss decreased (1.006010 --> 1.004949).  Saving model ...
Validation loss decreased (1.004949 --> 1.003425).  Saving model ...
Validation loss decreased (1.003425 --> 0.999133).  Saving model ...
EarlyStopping counter: 1 out of 10.0
Validation loss decreased (0.999133 --> 0.996371).  Saving model ...
Validation loss decreased (0.996371 --> 0.992071).  Saving model ...
Validation loss decreased (0.992071 --> 0.989911).  Saving model ...
EarlyStopping counter: 1 out of 10.0
EarlyStopping counter: 2 out of 10.0
Validation loss decreased (0.989911 --> 0.987694).  Saving model ...
Validation loss decreased (0.987694 --> 0.984524).  Saving model ...
EarlyStopping counter: 1 out of 10.0
EarlyStopping counter: 2 out of 10.0
EarlyStopping counter: 3 out of 10.0
EarlyStopping counter: 4 out of 10.0
EarlyStopping counter: 5 out of 10.0
Validation loss decreased (0.984524 --> 0.981901).  Saving model ...
Validation loss decreased (0.981901 --> 0.977540).  Saving model ...
EarlyStopping counter: 1 out of 10.0
EarlyStopping counter: 2 out of 10.0
Validation loss decreased (0.977540 --> 0.975181).  Saving model ...
EarlyStopping counter: 1 out of 10.0
Validation loss decreased (0.975181 --> 0.974622).  Saving model ...
Validation loss decreased (0.974622 --> 0.972660).  Saving model ...
EarlyStopping counter: 1 out of 10.0
Validation loss decreased (0.972660 --> 0.972577).  Saving model ...
EarlyStopping counter: 1 out of 10.0
Validation loss decreased (0.972577 --> 0.970410).  Saving model ...
Validation loss decreased (0.970410 --> 0.970164).  Saving model ...
EarlyStopping counter: 1 out of 10.0
Validation loss decreased (0.970164 --> 0.969613).  Saving model ...
Validation loss decreased (0.969613 --> 0.967618).  Saving model ...
Validation loss decreased (0.967618 --> 0.965193).  Saving model ...
Validation loss decreased (0.965193 --> 0.962294).  Saving model ...
EarlyStopping counter: 1 out of 10.0
Validation loss decreased (0.962294 --> 0.962163).  Saving model ...
Validation loss decreased (0.962163 --> 0.961703).  Saving model ...
Validation loss decreased (0.961703 --> 0.959410).  Saving model ...
Validation loss decreased (0.959410 --> 0.959084).  Saving model ...
Validation loss decreased (0.959084 --> 0.958132).  Saving model ...
EarlyStopping counter: 1 out of 10.0
EarlyStopping counter: 2 out of 10.0
EarlyStopping counter: 3 out of 10.0
EarlyStopping counter: 4 out of 10.0
EarlyStopping counter: 5 out of 10.0
EarlyStopping counter: 6 out of 10.0
EarlyStopping counter: 7 out of 10.0
EarlyStopping counter: 8 out of 10.0
EarlyStopping counter: 9 out of 10.0
Validation loss decreased (0.958132 --> 0.957421).  Saving model ...
EarlyStopping counter: 1 out of 10.0
Validation loss decreased (0.957421 --> 0.957065).  Saving model ...
Validation loss decreased (0.957065 --> 0.955658).  Saving model ...
Validation loss decreased (0.955658 --> 0.954598).  Saving model ...
EarlyStopping counter: 1 out of 10.0
EarlyStopping counter: 2 out of 10.0
EarlyStopping counter: 3 out of 10.0
EarlyStopping counter: 4 out of 10.0
Validation loss decreased (0.954598 --> 0.952998).  Saving model ...
Validation loss decreased (0.952998 --> 0.950180).  Saving model ...
EarlyStopping counter: 1 out of 10.0
EarlyStopping counter: 2 out of 10.0
EarlyStopping counter: 3 out of 10.0
EarlyStopping counter: 4 out of 10.0
EarlyStopping counter: 5 out of 10.0
EarlyStopping counter: 6 out of 10.0
EarlyStopping counter: 7 out of 10.0
EarlyStopping counter: 8 out of 10.0
Validation loss decreased (0.950180 --> 0.949819).  Saving model ...
EarlyStopping counter: 1 out of 10.0
EarlyStopping counter: 2 out of 10.0
EarlyStopping counter: 3 out of 10.0
EarlyStopping counter: 4 out of 10.0
EarlyStopping counter: 5 out of 10.0
EarlyStopping counter: 6 out of 10.0
EarlyStopping counter: 7 out of 10.0
Validation loss decreased (0.949819 --> 0.948938).  Saving model ...
EarlyStopping counter: 1 out of 10.0
EarlyStopping counter: 2 out of 10.0
EarlyStopping counter: 3 out of 10.0
EarlyStopping counter: 4 out of 10.0
EarlyStopping counter: 5 out of 10.0
EarlyStopping counter: 6 out of 10.0
EarlyStopping counter: 7 out of 10.0
EarlyStopping counter: 8 out of 10.0
EarlyStopping counter: 9 out of 10.0
EarlyStopping counter: 10 out of 10.0
/localscratch/yinan.29019257.0/env/lib/python3.7/site-packages/torch/nn/functional.py:1794: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.
  warnings.warn("nn.functional.tanh is deprecated. Use torch.tanh instead.")
wandb: Waiting for W&B process to finish, PID 105194... (success).
wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: \ 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: | 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: / 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: \ 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: | 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: / 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: \ 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: | 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: / 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb:                                                                                
wandb: Run history:
wandb:     e_F1 ▁▂▃▃▄▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇▇█▇███▇▇▇██████████
wandb:   e_loss ██▇▇▇▆▆▆▅▅▄▄▄▃▃▃▃▃▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:     t_F1 ▁▂▂▃▃▄▄▄▄▅▅▅▅▅▆▆▆▆▆▆▆▆▇▇▇▇▇▇▇▇▇██▇███▇██
wandb:   t_loss ███▇▇▇▇▆▆▆▅▅▅▅▅▄▄▄▄▄▄▃▃▃▃▃▂▃▂▂▂▂▁▂▁▂▁▁▁▁
wandb: 
wandb: Run summary:
wandb:     e_F1 58.22554
wandb:   e_loss 0.95811
wandb:     t_F1 71.45886
wandb:   t_loss 0.72807
wandb: 
wandb: Synced 4 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Synced frosty-leaf-1: https://wandb.ai/yinanazhou/xl_512_bs_8_lr_1e06_es_10_lc_True_nr_True_sr_True_stem_True_lemma_False_repeat_2_fold_2/runs/3s2fbrgr
wandb: Find logs at: ./wandb/run-20220317_103021-3s2fbrgr/logs/debug.log
wandb: 

wandb: wandb version 0.12.11 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
2022-03-17 12:31:10.890887: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1
wandb: Tracking run with wandb version 0.12.5
wandb: Syncing run giddy-grass-1
wandb: ⭐️ View project at https://wandb.ai/yinanazhou/xl_512_bs_8_lr_1e06_es_10_lc_True_nr_True_sr_True_stem_True_lemma_False_repeat_3_fold_1
wandb: 🚀 View run at https://wandb.ai/yinanazhou/xl_512_bs_8_lr_1e06_es_10_lc_True_nr_True_sr_True_stem_True_lemma_False_repeat_3_fold_1/runs/2p1jfqgs
wandb: Run data is saved locally in /project/6002780/yinan/Thesis_MER_Lyrics/lyric-emotion/wandb/run-20220317_123107-2p1jfqgs
wandb: Run `wandb offline` to turn off syncing.

Validation loss decreased (inf --> 1.423569).  Saving model ...
Validation loss decreased (1.423569 --> 1.411017).  Saving model ...
Validation loss decreased (1.411017 --> 1.401665).  Saving model ...
Validation loss decreased (1.401665 --> 1.395213).  Saving model ...
Validation loss decreased (1.395213 --> 1.389597).  Saving model ...
Validation loss decreased (1.389597 --> 1.384827).  Saving model ...
Validation loss decreased (1.384827 --> 1.380721).  Saving model ...
Validation loss decreased (1.380721 --> 1.377440).  Saving model ...
Validation loss decreased (1.377440 --> 1.374060).  Saving model ...
Validation loss decreased (1.374060 --> 1.370676).  Saving model ...
Validation loss decreased (1.370676 --> 1.367643).  Saving model ...
Validation loss decreased (1.367643 --> 1.364710).  Saving model ...
Validation loss decreased (1.364710 --> 1.361959).  Saving model ...
Validation loss decreased (1.361959 --> 1.359250).  Saving model ...
Validation loss decreased (1.359250 --> 1.356073).  Saving model ...
Validation loss decreased (1.356073 --> 1.352671).  Saving model ...
Validation loss decreased (1.352671 --> 1.349230).  Saving model ...
Validation loss decreased (1.349230 --> 1.345325).  Saving model ...
Validation loss decreased (1.345325 --> 1.341940).  Saving model ...
Validation loss decreased (1.341940 --> 1.338538).  Saving model ...
Validation loss decreased (1.338538 --> 1.335189).  Saving model ...
Validation loss decreased (1.335189 --> 1.331679).  Saving model ...
Validation loss decreased (1.331679 --> 1.327774).  Saving model ...
Validation loss decreased (1.327774 --> 1.323081).  Saving model ...
Validation loss decreased (1.323081 --> 1.319513).  Saving model ...
Validation loss decreased (1.319513 --> 1.315300).  Saving model ...
Validation loss decreased (1.315300 --> 1.311377).  Saving model ...
Validation loss decreased (1.311377 --> 1.306712).  Saving model ...
Validation loss decreased (1.306712 --> 1.302391).  Saving model ...
Validation loss decreased (1.302391 --> 1.297955).  Saving model ...
Validation loss decreased (1.297955 --> 1.293675).  Saving model ...
Validation loss decreased (1.293675 --> 1.289494).  Saving model ...
Validation loss decreased (1.289494 --> 1.283565).  Saving model ...
Validation loss decreased (1.283565 --> 1.278114).  Saving model ...
Validation loss decreased (1.278114 --> 1.273602).  Saving model ...
Validation loss decreased (1.273602 --> 1.269148).  Saving model ...
Validation loss decreased (1.269148 --> 1.263089).  Saving model ...
Validation loss decreased (1.263089 --> 1.259079).  Saving model ...
Validation loss decreased (1.259079 --> 1.255289).  Saving model ...
Validation loss decreased (1.255289 --> 1.250542).  Saving model ...
Validation loss decreased (1.250542 --> 1.244533).  Saving model ...
Validation loss decreased (1.244533 --> 1.240549).  Saving model ...
Validation loss decreased (1.240549 --> 1.236686).  Saving model ...
Validation loss decreased (1.236686 --> 1.233263).  Saving model ...
Validation loss decreased (1.233263 --> 1.226146).  Saving model ...
Validation loss decreased (1.226146 --> 1.223249).  Saving model ...
Validation loss decreased (1.223249 --> 1.218569).  Saving model ...
Validation loss decreased (1.218569 --> 1.211146).  Saving model ...
Validation loss decreased (1.211146 --> 1.206024).  Saving model ...
Validation loss decreased (1.206024 --> 1.204357).  Saving model ...
Validation loss decreased (1.204357 --> 1.198553).  Saving model ...
Validation loss decreased (1.198553 --> 1.195677).  Saving model ...
Validation loss decreased (1.195677 --> 1.191656).  Saving model ...
Validation loss decreased (1.191656 --> 1.190756).  Saving model ...
Validation loss decreased (1.190756 --> 1.186809).  Saving model ...
Validation loss decreased (1.186809 --> 1.182713).  Saving model ...
Validation loss decreased (1.182713 --> 1.179338).  Saving model ...
Validation loss decreased (1.179338 --> 1.177576).  Saving model ...
Validation loss decreased (1.177576 --> 1.174824).  Saving model ...
Validation loss decreased (1.174824 --> 1.168983).  Saving model ...
Validation loss decreased (1.168983 --> 1.165447).  Saving model ...
Validation loss decreased (1.165447 --> 1.162042).  Saving model ...
Validation loss decreased (1.162042 --> 1.159302).  Saving model ...
Validation loss decreased (1.159302 --> 1.155696).  Saving model ...
Validation loss decreased (1.155696 --> 1.155309).  Saving model ...
Validation loss decreased (1.155309 --> 1.149715).  Saving model ...
Validation loss decreased (1.149715 --> 1.147762).  Saving model ...
Validation loss decreased (1.147762 --> 1.143015).  Saving model ...
Validation loss decreased (1.143015 --> 1.139299).  Saving model ...
Validation loss decreased (1.139299 --> 1.135790).  Saving model ...
Validation loss decreased (1.135790 --> 1.134576).  Saving model ...
Validation loss decreased (1.134576 --> 1.131955).  Saving model ...
Validation loss decreased (1.131955 --> 1.126532).  Saving model ...
Validation loss decreased (1.126532 --> 1.125313).  Saving model ...
Validation loss decreased (1.125313 --> 1.120520).  Saving model ...
Validation loss decreased (1.120520 --> 1.119404).  Saving model ...
Validation loss decreased (1.119404 --> 1.114712).  Saving model ...
Validation loss decreased (1.114712 --> 1.112833).  Saving model ...
EarlyStopping counter: 1 out of 10.0
Validation loss decreased (1.112833 --> 1.109802).  Saving model ...
Validation loss decreased (1.109802 --> 1.106503).  Saving model ...
Validation loss decreased (1.106503 --> 1.102846).  Saving model ...
Validation loss decreased (1.102846 --> 1.096496).  Saving model ...
EarlyStopping counter: 1 out of 10.0
Validation loss decreased (1.096496 --> 1.093889).  Saving model ...
Validation loss decreased (1.093889 --> 1.093087).  Saving model ...
Validation loss decreased (1.093087 --> 1.089894).  Saving model ...
Validation loss decreased (1.089894 --> 1.088235).  Saving model ...
Validation loss decreased (1.088235 --> 1.085985).  Saving model ...
EarlyStopping counter: 1 out of 10.0
Validation loss decreased (1.085985 --> 1.083126).  Saving model ...
Validation loss decreased (1.083126 --> 1.081234).  Saving model ...
Validation loss decreased (1.081234 --> 1.080124).  Saving model ...
Validation loss decreased (1.080124 --> 1.077819).  Saving model ...
EarlyStopping counter: 1 out of 10.0
Validation loss decreased (1.077819 --> 1.076880).  Saving model ...
Validation loss decreased (1.076880 --> 1.073814).  Saving model ...
Validation loss decreased (1.073814 --> 1.070045).  Saving model ...
Validation loss decreased (1.070045 --> 1.068901).  Saving model ...
Validation loss decreased (1.068901 --> 1.065178).  Saving model ...
Validation loss decreased (1.065178 --> 1.064928).  Saving model ...
EarlyStopping counter: 1 out of 10.0
Validation loss decreased (1.064928 --> 1.061375).  Saving model ...
EarlyStopping counter: 1 out of 10.0
Validation loss decreased (1.061375 --> 1.058422).  Saving model ...
EarlyStopping counter: 1 out of 10.0
Validation loss decreased (1.058422 --> 1.053821).  Saving model ...
Validation loss decreased (1.053821 --> 1.053205).  Saving model ...
Validation loss decreased (1.053205 --> 1.048535).  Saving model ...
EarlyStopping counter: 1 out of 10.0
EarlyStopping counter: 2 out of 10.0
Validation loss decreased (1.048535 --> 1.047740).  Saving model ...
EarlyStopping counter: 1 out of 10.0
EarlyStopping counter: 2 out of 10.0
Validation loss decreased (1.047740 --> 1.046176).  Saving model ...
EarlyStopping counter: 1 out of 10.0
Validation loss decreased (1.046176 --> 1.042373).  Saving model ...
Validation loss decreased (1.042373 --> 1.042108).  Saving model ...
EarlyStopping counter: 1 out of 10.0
Validation loss decreased (1.042108 --> 1.039471).  Saving model ...
Validation loss decreased (1.039471 --> 1.038811).  Saving model ...
Validation loss decreased (1.038811 --> 1.037001).  Saving model ...
EarlyStopping counter: 1 out of 10.0
EarlyStopping counter: 2 out of 10.0
EarlyStopping counter: 3 out of 10.0
EarlyStopping counter: 4 out of 10.0
EarlyStopping counter: 5 out of 10.0
Validation loss decreased (1.037001 --> 1.035411).  Saving model ...
Validation loss decreased (1.035411 --> 1.030712).  Saving model ...
EarlyStopping counter: 1 out of 10.0
EarlyStopping counter: 2 out of 10.0
Validation loss decreased (1.030712 --> 1.029740).  Saving model ...
EarlyStopping counter: 1 out of 10.0
Validation loss decreased (1.029740 --> 1.025626).  Saving model ...
EarlyStopping counter: 1 out of 10.0
Validation loss decreased (1.025626 --> 1.025257).  Saving model ...
EarlyStopping counter: 1 out of 10.0
EarlyStopping counter: 2 out of 10.0
Validation loss decreased (1.025257 --> 1.025244).  Saving model ...
EarlyStopping counter: 1 out of 10.0
Validation loss decreased (1.025244 --> 1.023119).  Saving model ...
Validation loss decreased (1.023119 --> 1.021914).  Saving model ...
EarlyStopping counter: 1 out of 10.0
EarlyStopping counter: 2 out of 10.0
EarlyStopping counter: 3 out of 10.0
Validation loss decreased (1.021914 --> 1.020315).  Saving model ...
EarlyStopping counter: 1 out of 10.0
EarlyStopping counter: 2 out of 10.0
EarlyStopping counter: 3 out of 10.0
EarlyStopping counter: 4 out of 10.0
EarlyStopping counter: 5 out of 10.0
EarlyStopping counter: 6 out of 10.0
EarlyStopping counter: 7 out of 10.0
EarlyStopping counter: 8 out of 10.0
EarlyStopping counter: 9 out of 10.0
EarlyStopping counter: 10 out of 10.0
/localscratch/yinan.29019257.0/env/lib/python3.7/site-packages/torch/nn/functional.py:1794: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.
  warnings.warn("nn.functional.tanh is deprecated. Use torch.tanh instead.")
wandb: Waiting for W&B process to finish, PID 111695... (success).
wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: \ 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: | 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: / 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: \ 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: | 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: / 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: \ 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: | 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: / 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: \ 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: | 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: / 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb:                                                                                
wandb: Run history:
wandb:     e_F1 ▁▂▃▄▄▅▅▅▅▆▆▆▆▆▆▇▇▇▇▇▇▇▇█▇▇▇█████████████
wandb:   e_loss ██▇▇▇▇▆▆▆▅▅▅▄▄▄▄▃▃▃▃▃▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁
wandb:     t_F1 ▁▁▂▂▃▂▃▃▄▃▄▄▅▄▅▅▅▆▆▆▆▆▆▆▇▇▇▇▇▇▇▇▇▇▇█████
wandb:   t_loss ███▇▇▇▇▇▇▆▆▆▆▆▅▅▅▄▄▄▄▄▄▄▃▃▃▃▂▂▃▂▂▂▂▂▁▁▁▁
wandb: 
wandb: Run summary:
wandb:     e_F1 55.84627
wandb:   e_loss 1.0284
wandb:     t_F1 73.49063
wandb:   t_loss 0.73537
wandb: 
wandb: Synced 4 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Synced giddy-grass-1: https://wandb.ai/yinanazhou/xl_512_bs_8_lr_1e06_es_10_lc_True_nr_True_sr_True_stem_True_lemma_False_repeat_3_fold_1/runs/2p1jfqgs
wandb: Find logs at: ./wandb/run-20220317_123107-2p1jfqgs/logs/debug.log
wandb: 

wandb: wandb version 0.12.11 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
2022-03-17 14:14:07.805516: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1
wandb: Tracking run with wandb version 0.12.5
wandb: Syncing run silver-energy-1
wandb: ⭐️ View project at https://wandb.ai/yinanazhou/xl_512_bs_8_lr_1e06_es_10_lc_True_nr_True_sr_True_stem_True_lemma_False_repeat_3_fold_2
wandb: 🚀 View run at https://wandb.ai/yinanazhou/xl_512_bs_8_lr_1e06_es_10_lc_True_nr_True_sr_True_stem_True_lemma_False_repeat_3_fold_2/runs/y4tuned7
wandb: Run data is saved locally in /project/6002780/yinan/Thesis_MER_Lyrics/lyric-emotion/wandb/run-20220317_141404-y4tuned7
wandb: Run `wandb offline` to turn off syncing.

Validation loss decreased (inf --> 1.440449).  Saving model ...
Validation loss decreased (1.440449 --> 1.423472).  Saving model ...
Validation loss decreased (1.423472 --> 1.410973).  Saving model ...
Validation loss decreased (1.410973 --> 1.401378).  Saving model ...
Validation loss decreased (1.401378 --> 1.393862).  Saving model ...
Validation loss decreased (1.393862 --> 1.387943).  Saving model ...
Validation loss decreased (1.387943 --> 1.382384).  Saving model ...
Validation loss decreased (1.382384 --> 1.378015).  Saving model ...
Validation loss decreased (1.378015 --> 1.373634).  Saving model ...
Validation loss decreased (1.373634 --> 1.370028).  Saving model ...
Validation loss decreased (1.370028 --> 1.366467).  Saving model ...
Validation loss decreased (1.366467 --> 1.362667).  Saving model ...
Validation loss decreased (1.362667 --> 1.358776).  Saving model ...
Validation loss decreased (1.358776 --> 1.355008).  Saving model ...
Validation loss decreased (1.355008 --> 1.351283).  Saving model ...
Validation loss decreased (1.351283 --> 1.347327).  Saving model ...
Validation loss decreased (1.347327 --> 1.343817).  Saving model ...
Validation loss decreased (1.343817 --> 1.339357).  Saving model ...
Validation loss decreased (1.339357 --> 1.335155).  Saving model ...
Validation loss decreased (1.335155 --> 1.331332).  Saving model ...
Validation loss decreased (1.331332 --> 1.326859).  Saving model ...
Validation loss decreased (1.326859 --> 1.322087).  Saving model ...
Validation loss decreased (1.322087 --> 1.316985).  Saving model ...
Validation loss decreased (1.316985 --> 1.312417).  Saving model ...
Validation loss decreased (1.312417 --> 1.307168).  Saving model ...
Validation loss decreased (1.307168 --> 1.301249).  Saving model ...
Validation loss decreased (1.301249 --> 1.295290).  Saving model ...
Validation loss decreased (1.295290 --> 1.288797).  Saving model ...
Validation loss decreased (1.288797 --> 1.282511).  Saving model ...
Validation loss decreased (1.282511 --> 1.275025).  Saving model ...
Validation loss decreased (1.275025 --> 1.267922).  Saving model ...
Validation loss decreased (1.267922 --> 1.259989).  Saving model ...
Validation loss decreased (1.259989 --> 1.253036).  Saving model ...
Validation loss decreased (1.253036 --> 1.247691).  Saving model ...
Validation loss decreased (1.247691 --> 1.240390).  Saving model ...
Validation loss decreased (1.240390 --> 1.233524).  Saving model ...
Validation loss decreased (1.233524 --> 1.227912).  Saving model ...
Validation loss decreased (1.227912 --> 1.222659).  Saving model ...
Validation loss decreased (1.222659 --> 1.218015).  Saving model ...
Validation loss decreased (1.218015 --> 1.210642).  Saving model ...
Validation loss decreased (1.210642 --> 1.203593).  Saving model ...
Validation loss decreased (1.203593 --> 1.197832).  Saving model ...
Validation loss decreased (1.197832 --> 1.193029).  Saving model ...
Validation loss decreased (1.193029 --> 1.188525).  Saving model ...
Validation loss decreased (1.188525 --> 1.184231).  Saving model ...
Validation loss decreased (1.184231 --> 1.179190).  Saving model ...
Validation loss decreased (1.179190 --> 1.173373).  Saving model ...
Validation loss decreased (1.173373 --> 1.168071).  Saving model ...
Validation loss decreased (1.168071 --> 1.164792).  Saving model ...
Validation loss decreased (1.164792 --> 1.159066).  Saving model ...
Validation loss decreased (1.159066 --> 1.154448).  Saving model ...
Validation loss decreased (1.154448 --> 1.150101).  Saving model ...
Validation loss decreased (1.150101 --> 1.145417).  Saving model ...
Validation loss decreased (1.145417 --> 1.141518).  Saving model ...
Validation loss decreased (1.141518 --> 1.137462).  Saving model ...
Validation loss decreased (1.137462 --> 1.134346).  Saving model ...
Validation loss decreased (1.134346 --> 1.130118).  Saving model ...
Validation loss decreased (1.130118 --> 1.124602).  Saving model ...
Validation loss decreased (1.124602 --> 1.119772).  Saving model ...
Validation loss decreased (1.119772 --> 1.115846).  Saving model ...
Validation loss decreased (1.115846 --> 1.112919).  Saving model ...
Validation loss decreased (1.112919 --> 1.108051).  Saving model ...
Validation loss decreased (1.108051 --> 1.104620).  Saving model ...
Validation loss decreased (1.104620 --> 1.101444).  Saving model ...
Validation loss decreased (1.101444 --> 1.097915).  Saving model ...
Validation loss decreased (1.097915 --> 1.095176).  Saving model ...
Validation loss decreased (1.095176 --> 1.092229).  Saving model ...
Validation loss decreased (1.092229 --> 1.088594).  Saving model ...
Validation loss decreased (1.088594 --> 1.084838).  Saving model ...
Validation loss decreased (1.084838 --> 1.081325).  Saving model ...
Validation loss decreased (1.081325 --> 1.078334).  Saving model ...
Validation loss decreased (1.078334 --> 1.074458).  Saving model ...
Validation loss decreased (1.074458 --> 1.072190).  Saving model ...
Validation loss decreased (1.072190 --> 1.070141).  Saving model ...
Validation loss decreased (1.070141 --> 1.066088).  Saving model ...
Validation loss decreased (1.066088 --> 1.063303).  Saving model ...
Validation loss decreased (1.063303 --> 1.058462).  Saving model ...
Validation loss decreased (1.058462 --> 1.055989).  Saving model ...
Validation loss decreased (1.055989 --> 1.053902).  Saving model ...
Validation loss decreased (1.053902 --> 1.051798).  Saving model ...
Validation loss decreased (1.051798 --> 1.050303).  Saving model ...
Validation loss decreased (1.050303 --> 1.047576).  Saving model ...
Validation loss decreased (1.047576 --> 1.044491).  Saving model ...
Validation loss decreased (1.044491 --> 1.041718).  Saving model ...
Validation loss decreased (1.041718 --> 1.038455).  Saving model ...
Validation loss decreased (1.038455 --> 1.037012).  Saving model ...
Validation loss decreased (1.037012 --> 1.034398).  Saving model ...
Validation loss decreased (1.034398 --> 1.032132).  Saving model ...
Validation loss decreased (1.032132 --> 1.030277).  Saving model ...
Validation loss decreased (1.030277 --> 1.027830).  Saving model ...
Validation loss decreased (1.027830 --> 1.025340).  Saving model ...
Validation loss decreased (1.025340 --> 1.022350).  Saving model ...
Validation loss decreased (1.022350 --> 1.020315).  Saving model ...
Validation loss decreased (1.020315 --> 1.018437).  Saving model ...
Validation loss decreased (1.018437 --> 1.015323).  Saving model ...
EarlyStopping counter: 1 out of 10.0
Validation loss decreased (1.015323 --> 1.012397).  Saving model ...
Validation loss decreased (1.012397 --> 1.011008).  Saving model ...
Validation loss decreased (1.011008 --> 1.009676).  Saving model ...
Validation loss decreased (1.009676 --> 1.007110).  Saving model ...
Validation loss decreased (1.007110 --> 1.004854).  Saving model ...
Validation loss decreased (1.004854 --> 1.002780).  Saving model ...
EarlyStopping counter: 1 out of 10.0
Validation loss decreased (1.002780 --> 1.001819).  Saving model ...
Validation loss decreased (1.001819 --> 0.998627).  Saving model ...
Validation loss decreased (0.998627 --> 0.997767).  Saving model ...
Validation loss decreased (0.997767 --> 0.994997).  Saving model ...
Validation loss decreased (0.994997 --> 0.992957).  Saving model ...
Validation loss decreased (0.992957 --> 0.992527).  Saving model ...
Validation loss decreased (0.992527 --> 0.990370).  Saving model ...
Validation loss decreased (0.990370 --> 0.989443).  Saving model ...
Validation loss decreased (0.989443 --> 0.987619).  Saving model ...
Validation loss decreased (0.987619 --> 0.986361).  Saving model ...
Validation loss decreased (0.986361 --> 0.985339).  Saving model ...
Validation loss decreased (0.985339 --> 0.984634).  Saving model ...
Validation loss decreased (0.984634 --> 0.983053).  Saving model ...
Validation loss decreased (0.983053 --> 0.981809).  Saving model ...
Validation loss decreased (0.981809 --> 0.980839).  Saving model ...
Validation loss decreased (0.980839 --> 0.980010).  Saving model ...
Validation loss decreased (0.980010 --> 0.978364).  Saving model ...
Validation loss decreased (0.978364 --> 0.978269).  Saving model ...
Validation loss decreased (0.978269 --> 0.977529).  Saving model ...
Validation loss decreased (0.977529 --> 0.977027).  Saving model ...
Validation loss decreased (0.977027 --> 0.976037).  Saving model ...
Validation loss decreased (0.976037 --> 0.975339).  Saving model ...
Validation loss decreased (0.975339 --> 0.975072).  Saving model ...
Validation loss decreased (0.975072 --> 0.974408).  Saving model ...
Validation loss decreased (0.974408 --> 0.972026).  Saving model ...
Validation loss decreased (0.972026 --> 0.971712).  Saving model ...
Validation loss decreased (0.971712 --> 0.971154).  Saving model ...
Validation loss decreased (0.971154 --> 0.971081).  Saving model ...
Validation loss decreased (0.971081 --> 0.969761).  Saving model ...
Validation loss decreased (0.969761 --> 0.967958).  Saving model ...
Validation loss decreased (0.967958 --> 0.967680).  Saving model ...
Validation loss decreased (0.967680 --> 0.966507).  Saving model ...
EarlyStopping counter: 1 out of 10.0
Validation loss decreased (0.966507 --> 0.965483).  Saving model ...
Validation loss decreased (0.965483 --> 0.965051).  Saving model ...
Validation loss decreased (0.965051 --> 0.964691).  Saving model ...
EarlyStopping counter: 1 out of 10.0
EarlyStopping counter: 2 out of 10.0
EarlyStopping counter: 3 out of 10.0
Validation loss decreased (0.964691 --> 0.964482).  Saving model ...
EarlyStopping counter: 1 out of 10.0
EarlyStopping counter: 2 out of 10.0
EarlyStopping counter: 3 out of 10.0
Validation loss decreased (0.964482 --> 0.964460).  Saving model ...
Validation loss decreased (0.964460 --> 0.963935).  Saving model ...
Validation loss decreased (0.963935 --> 0.963154).  Saving model ...
EarlyStopping counter: 1 out of 10.0
Validation loss decreased (0.963154 --> 0.962722).  Saving model ...
Validation loss decreased (0.962722 --> 0.961579).  Saving model ...
EarlyStopping counter: 1 out of 10.0
Validation loss decreased (0.961579 --> 0.961446).  Saving model ...
EarlyStopping counter: 1 out of 10.0
Validation loss decreased (0.961446 --> 0.961285).  Saving model ...
Validation loss decreased (0.961285 --> 0.961150).  Saving model ...
Validation loss decreased (0.961150 --> 0.960952).  Saving model ...
Validation loss decreased (0.960952 --> 0.960515).  Saving model ...
EarlyStopping counter: 1 out of 10.0
EarlyStopping counter: 2 out of 10.0
EarlyStopping counter: 3 out of 10.0
EarlyStopping counter: 4 out of 10.0
EarlyStopping counter: 5 out of 10.0
EarlyStopping counter: 6 out of 10.0
EarlyStopping counter: 7 out of 10.0
EarlyStopping counter: 8 out of 10.0
EarlyStopping counter: 9 out of 10.0
EarlyStopping counter: 10 out of 10.0
/localscratch/yinan.29019257.0/env/lib/python3.7/site-packages/torch/nn/functional.py:1794: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.
  warnings.warn("nn.functional.tanh is deprecated. Use torch.tanh instead.")
wandb: Waiting for W&B process to finish, PID 117202... (success).
wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: \ 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: | 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: / 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb:                                                                                
wandb: Run history:
wandb:     e_F1 ▁▂▄▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇▇▇▇▇▇▇▇▇██████████████
wandb:   e_loss █▇▇▇▇▆▆▆▅▅▄▄▄▄▃▃▃▃▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:     t_F1 ▁▂▂▃▃▃▄▄▄▅▅▅▆▆▆▆▆▆▆▆▆▇▇▇▇▇▇▇▇▇▇▇████████
wandb:   t_loss ███▇▇▇▇▇▆▆▆▅▅▅▅▅▄▄▄▄▄▄▃▃▃▃▃▃▂▂▂▂▂▂▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:     e_F1 59.05668
wandb:   e_loss 0.96262
wandb:     t_F1 71.36691
wandb:   t_loss 0.74132
wandb: 
wandb: Synced 4 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Synced silver-energy-1: https://wandb.ai/yinanazhou/xl_512_bs_8_lr_1e06_es_10_lc_True_nr_True_sr_True_stem_True_lemma_False_repeat_3_fold_2/runs/y4tuned7
wandb: Find logs at: ./wandb/run-20220317_141404-y4tuned7/logs/debug.log
wandb: 

wandb: wandb version 0.12.11 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
2022-03-17 16:03:30.302865: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1
wandb: Tracking run with wandb version 0.12.5
wandb: Syncing run peachy-snow-1
wandb: ⭐️ View project at https://wandb.ai/yinanazhou/xl_512_bs_8_lr_1e06_es_10_lc_True_nr_True_sr_True_stem_True_lemma_False_repeat_4_fold_1
wandb: 🚀 View run at https://wandb.ai/yinanazhou/xl_512_bs_8_lr_1e06_es_10_lc_True_nr_True_sr_True_stem_True_lemma_False_repeat_4_fold_1/runs/81kyc7nh
wandb: Run data is saved locally in /project/6002780/yinan/Thesis_MER_Lyrics/lyric-emotion/wandb/run-20220317_160327-81kyc7nh
wandb: Run `wandb offline` to turn off syncing.

Validation loss decreased (inf --> 1.408282).  Saving model ...
Validation loss decreased (1.408282 --> 1.395024).  Saving model ...
Validation loss decreased (1.395024 --> 1.385466).  Saving model ...
Validation loss decreased (1.385466 --> 1.378338).  Saving model ...
Validation loss decreased (1.378338 --> 1.372073).  Saving model ...
Validation loss decreased (1.372073 --> 1.366836).  Saving model ...
Validation loss decreased (1.366836 --> 1.361937).  Saving model ...
Validation loss decreased (1.361937 --> 1.357868).  Saving model ...
Validation loss decreased (1.357868 --> 1.353343).  Saving model ...
Validation loss decreased (1.353343 --> 1.349372).  Saving model ...
Validation loss decreased (1.349372 --> 1.345366).  Saving model ...
Validation loss decreased (1.345366 --> 1.341365).  Saving model ...
Validation loss decreased (1.341365 --> 1.337742).  Saving model ...
Validation loss decreased (1.337742 --> 1.334045).  Saving model ...
Validation loss decreased (1.334045 --> 1.329632).  Saving model ...
Validation loss decreased (1.329632 --> 1.325353).  Saving model ...
Validation loss decreased (1.325353 --> 1.320569).  Saving model ...
Validation loss decreased (1.320569 --> 1.315921).  Saving model ...
Validation loss decreased (1.315921 --> 1.311345).  Saving model ...
Validation loss decreased (1.311345 --> 1.306642).  Saving model ...
Validation loss decreased (1.306642 --> 1.302060).  Saving model ...
Validation loss decreased (1.302060 --> 1.296978).  Saving model ...
Validation loss decreased (1.296978 --> 1.291931).  Saving model ...
Validation loss decreased (1.291931 --> 1.286620).  Saving model ...
Validation loss decreased (1.286620 --> 1.280679).  Saving model ...
Validation loss decreased (1.280679 --> 1.275285).  Saving model ...
Validation loss decreased (1.275285 --> 1.269753).  Saving model ...
Validation loss decreased (1.269753 --> 1.263809).  Saving model ...
Validation loss decreased (1.263809 --> 1.257595).  Saving model ...
Validation loss decreased (1.257595 --> 1.251058).  Saving model ...
Validation loss decreased (1.251058 --> 1.245131).  Saving model ...
Validation loss decreased (1.245131 --> 1.239414).  Saving model ...
Validation loss decreased (1.239414 --> 1.233801).  Saving model ...
Validation loss decreased (1.233801 --> 1.228688).  Saving model ...
Validation loss decreased (1.228688 --> 1.223288).  Saving model ...
Validation loss decreased (1.223288 --> 1.218375).  Saving model ...
Validation loss decreased (1.218375 --> 1.212812).  Saving model ...
Validation loss decreased (1.212812 --> 1.208100).  Saving model ...
Validation loss decreased (1.208100 --> 1.202609).  Saving model ...
Validation loss decreased (1.202609 --> 1.197495).  Saving model ...
Validation loss decreased (1.197495 --> 1.192178).  Saving model ...
Validation loss decreased (1.192178 --> 1.187165).  Saving model ...
Validation loss decreased (1.187165 --> 1.182244).  Saving model ...
Validation loss decreased (1.182244 --> 1.177484).  Saving model ...
Validation loss decreased (1.177484 --> 1.172310).  Saving model ...
Validation loss decreased (1.172310 --> 1.168136).  Saving model ...
Validation loss decreased (1.168136 --> 1.163633).  Saving model ...
Validation loss decreased (1.163633 --> 1.157747).  Saving model ...
Validation loss decreased (1.157747 --> 1.152995).  Saving model ...
Validation loss decreased (1.152995 --> 1.148971).  Saving model ...
Validation loss decreased (1.148971 --> 1.145954).  Saving model ...
Validation loss decreased (1.145954 --> 1.140611).  Saving model ...
Validation loss decreased (1.140611 --> 1.136989).  Saving model ...
Validation loss decreased (1.136989 --> 1.131842).  Saving model ...
Validation loss decreased (1.131842 --> 1.126995).  Saving model ...
Validation loss decreased (1.126995 --> 1.122331).  Saving model ...
Validation loss decreased (1.122331 --> 1.118985).  Saving model ...
Validation loss decreased (1.118985 --> 1.114609).  Saving model ...
Validation loss decreased (1.114609 --> 1.111394).  Saving model ...
Validation loss decreased (1.111394 --> 1.108635).  Saving model ...
Validation loss decreased (1.108635 --> 1.105113).  Saving model ...
Validation loss decreased (1.105113 --> 1.101831).  Saving model ...
Validation loss decreased (1.101831 --> 1.099101).  Saving model ...
Validation loss decreased (1.099101 --> 1.096340).  Saving model ...
Validation loss decreased (1.096340 --> 1.092994).  Saving model ...
Validation loss decreased (1.092994 --> 1.089332).  Saving model ...
Validation loss decreased (1.089332 --> 1.086253).  Saving model ...
Validation loss decreased (1.086253 --> 1.084255).  Saving model ...
Validation loss decreased (1.084255 --> 1.081133).  Saving model ...
Validation loss decreased (1.081133 --> 1.078689).  Saving model ...
Validation loss decreased (1.078689 --> 1.076743).  Saving model ...
Validation loss decreased (1.076743 --> 1.074699).  Saving model ...
Validation loss decreased (1.074699 --> 1.071875).  Saving model ...
Validation loss decreased (1.071875 --> 1.069272).  Saving model ...
Validation loss decreased (1.069272 --> 1.067029).  Saving model ...
Validation loss decreased (1.067029 --> 1.064735).  Saving model ...
Validation loss decreased (1.064735 --> 1.062159).  Saving model ...
Validation loss decreased (1.062159 --> 1.060693).  Saving model ...
Validation loss decreased (1.060693 --> 1.058657).  Saving model ...
Validation loss decreased (1.058657 --> 1.055961).  Saving model ...
Validation loss decreased (1.055961 --> 1.053286).  Saving model ...
Validation loss decreased (1.053286 --> 1.050746).  Saving model ...
Validation loss decreased (1.050746 --> 1.048760).  Saving model ...
Validation loss decreased (1.048760 --> 1.046806).  Saving model ...
Validation loss decreased (1.046806 --> 1.045571).  Saving model ...
Validation loss decreased (1.045571 --> 1.044027).  Saving model ...
Validation loss decreased (1.044027 --> 1.042451).  Saving model ...
Validation loss decreased (1.042451 --> 1.040893).  Saving model ...
Validation loss decreased (1.040893 --> 1.039467).  Saving model ...
Validation loss decreased (1.039467 --> 1.037933).  Saving model ...
Validation loss decreased (1.037933 --> 1.036350).  Saving model ...
Validation loss decreased (1.036350 --> 1.035777).  Saving model ...
Validation loss decreased (1.035777 --> 1.034552).  Saving model ...
Validation loss decreased (1.034552 --> 1.033948).  Saving model ...
Validation loss decreased (1.033948 --> 1.032899).  Saving model ...
Validation loss decreased (1.032899 --> 1.032577).  Saving model ...
Validation loss decreased (1.032577 --> 1.031209).  Saving model ...
Validation loss decreased (1.031209 --> 1.029296).  Saving model ...
Validation loss decreased (1.029296 --> 1.028136).  Saving model ...
Validation loss decreased (1.028136 --> 1.027055).  Saving model ...
Validation loss decreased (1.027055 --> 1.025777).  Saving model ...
Validation loss decreased (1.025777 --> 1.024432).  Saving model ...
Validation loss decreased (1.024432 --> 1.023759).  Saving model ...
Validation loss decreased (1.023759 --> 1.022918).  Saving model ...
Validation loss decreased (1.022918 --> 1.022015).  Saving model ...
Validation loss decreased (1.022015 --> 1.020545).  Saving model ...
Validation loss decreased (1.020545 --> 1.018888).  Saving model ...
Validation loss decreased (1.018888 --> 1.018611).  Saving model ...
Validation loss decreased (1.018611 --> 1.016918).  Saving model ...
EarlyStopping counter: 1 out of 10.0
Validation loss decreased (1.016918 --> 1.016578).  Saving model ...
Validation loss decreased (1.016578 --> 1.015929).  Saving model ...
Validation loss decreased (1.015929 --> 1.015527).  Saving model ...
Validation loss decreased (1.015527 --> 1.015328).  Saving model ...
Validation loss decreased (1.015328 --> 1.013932).  Saving model ...
Validation loss decreased (1.013932 --> 1.012577).  Saving model ...
Validation loss decreased (1.012577 --> 1.012200).  Saving model ...
Validation loss decreased (1.012200 --> 1.011083).  Saving model ...
Validation loss decreased (1.011083 --> 1.010846).  Saving model ...
Validation loss decreased (1.010846 --> 1.010714).  Saving model ...
EarlyStopping counter: 1 out of 10.0
EarlyStopping counter: 2 out of 10.0
Validation loss decreased (1.010714 --> 1.010166).  Saving model ...
Validation loss decreased (1.010166 --> 1.009621).  Saving model ...
Validation loss decreased (1.009621 --> 1.008518).  Saving model ...
EarlyStopping counter: 1 out of 10.0
EarlyStopping counter: 2 out of 10.0
EarlyStopping counter: 3 out of 10.0
EarlyStopping counter: 4 out of 10.0
EarlyStopping counter: 5 out of 10.0
EarlyStopping counter: 6 out of 10.0
EarlyStopping counter: 7 out of 10.0
EarlyStopping counter: 8 out of 10.0
Validation loss decreased (1.008518 --> 1.008263).  Saving model ...
Validation loss decreased (1.008263 --> 1.008060).  Saving model ...
Validation loss decreased (1.008060 --> 1.007973).  Saving model ...
EarlyStopping counter: 1 out of 10.0
Validation loss decreased (1.007973 --> 1.006923).  Saving model ...
Validation loss decreased (1.006923 --> 1.005706).  Saving model ...
EarlyStopping counter: 1 out of 10.0
EarlyStopping counter: 2 out of 10.0
EarlyStopping counter: 3 out of 10.0
EarlyStopping counter: 4 out of 10.0
EarlyStopping counter: 5 out of 10.0
EarlyStopping counter: 6 out of 10.0
EarlyStopping counter: 7 out of 10.0
EarlyStopping counter: 8 out of 10.0
EarlyStopping counter: 9 out of 10.0
EarlyStopping counter: 10 out of 10.0
/localscratch/yinan.29019257.0/env/lib/python3.7/site-packages/torch/nn/functional.py:1794: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.
  warnings.warn("nn.functional.tanh is deprecated. Use torch.tanh instead.")
wandb: Waiting for W&B process to finish, PID 123059... (success).
wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: \ 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: | 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: / 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: \ 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: | 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: / 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: \ 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: | 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: / 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb:                                                                                
wandb: Run history:
wandb:     e_F1 ▁▁▃▄▄▄▅▅▅▆▆▆▇▇▇▇▇▇▇▇▇▇▇▇█▇▇█████████████
wandb:   e_loss ██▇▇▇▆▆▆▅▅▅▄▄▄▃▃▃▃▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:     t_F1 ▁▂▂▂▃▃▃▄▄▄▅▄▅▅▅▅▆▆▆▆▆▆▆▇▆▇▇▇▇▇▇▇▇█▇▇██▇█
wandb:   t_loss ████▇▇▇▆▆▆▆▆▅▅▅▅▄▄▄▄▄▃▃▃▃▃▃▃▂▂▂▂▂▂▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:     e_F1 56.50629
wandb:   e_loss 1.01273
wandb:     t_F1 69.59033
wandb:   t_loss 0.8129
wandb: 
wandb: Synced 4 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Synced peachy-snow-1: https://wandb.ai/yinanazhou/xl_512_bs_8_lr_1e06_es_10_lc_True_nr_True_sr_True_stem_True_lemma_False_repeat_4_fold_1/runs/81kyc7nh
wandb: Find logs at: ./wandb/run-20220317_160327-81kyc7nh/logs/debug.log
wandb: 

wandb: wandb version 0.12.11 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
2022-03-17 17:42:11.034539: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1
wandb: Tracking run with wandb version 0.12.5
wandb: Syncing run sandy-blaze-1
wandb: ⭐️ View project at https://wandb.ai/yinanazhou/xl_512_bs_8_lr_1e06_es_10_lc_True_nr_True_sr_True_stem_True_lemma_False_repeat_4_fold_2
wandb: 🚀 View run at https://wandb.ai/yinanazhou/xl_512_bs_8_lr_1e06_es_10_lc_True_nr_True_sr_True_stem_True_lemma_False_repeat_4_fold_2/runs/7896810c
wandb: Run data is saved locally in /project/6002780/yinan/Thesis_MER_Lyrics/lyric-emotion/wandb/run-20220317_174208-7896810c
wandb: Run `wandb offline` to turn off syncing.

Validation loss decreased (inf --> 1.471814).  Saving model ...
Validation loss decreased (1.471814 --> 1.449279).  Saving model ...
Validation loss decreased (1.449279 --> 1.431506).  Saving model ...
Validation loss decreased (1.431506 --> 1.417038).  Saving model ...
Validation loss decreased (1.417038 --> 1.404530).  Saving model ...
Validation loss decreased (1.404530 --> 1.394531).  Saving model ...
Validation loss decreased (1.394531 --> 1.386512).  Saving model ...
Validation loss decreased (1.386512 --> 1.379421).  Saving model ...
Validation loss decreased (1.379421 --> 1.373626).  Saving model ...
Validation loss decreased (1.373626 --> 1.368927).  Saving model ...
Validation loss decreased (1.368927 --> 1.364858).  Saving model ...
Validation loss decreased (1.364858 --> 1.361008).  Saving model ...
Validation loss decreased (1.361008 --> 1.357884).  Saving model ...
Validation loss decreased (1.357884 --> 1.354376).  Saving model ...
Validation loss decreased (1.354376 --> 1.350451).  Saving model ...
Validation loss decreased (1.350451 --> 1.347034).  Saving model ...
Validation loss decreased (1.347034 --> 1.343283).  Saving model ...
Validation loss decreased (1.343283 --> 1.339480).  Saving model ...
Validation loss decreased (1.339480 --> 1.335814).  Saving model ...
Validation loss decreased (1.335814 --> 1.332833).  Saving model ...
Validation loss decreased (1.332833 --> 1.328730).  Saving model ...
Validation loss decreased (1.328730 --> 1.324436).  Saving model ...
Validation loss decreased (1.324436 --> 1.319737).  Saving model ...
Validation loss decreased (1.319737 --> 1.316082).  Saving model ...
Validation loss decreased (1.316082 --> 1.312105).  Saving model ...
Validation loss decreased (1.312105 --> 1.307424).  Saving model ...
Validation loss decreased (1.307424 --> 1.302498).  Saving model ...
Validation loss decreased (1.302498 --> 1.297752).  Saving model ...
Validation loss decreased (1.297752 --> 1.292534).  Saving model ...
Validation loss decreased (1.292534 --> 1.286945).  Saving model ...
Validation loss decreased (1.286945 --> 1.279969).  Saving model ...
Validation loss decreased (1.279969 --> 1.274221).  Saving model ...
Validation loss decreased (1.274221 --> 1.269807).  Saving model ...
Validation loss decreased (1.269807 --> 1.263103).  Saving model ...
Validation loss decreased (1.263103 --> 1.257235).  Saving model ...
Validation loss decreased (1.257235 --> 1.250792).  Saving model ...
Validation loss decreased (1.250792 --> 1.247525).  Saving model ...
Validation loss decreased (1.247525 --> 1.243009).  Saving model ...
Validation loss decreased (1.243009 --> 1.237470).  Saving model ...
Validation loss decreased (1.237470 --> 1.233334).  Saving model ...
Validation loss decreased (1.233334 --> 1.227641).  Saving model ...
Validation loss decreased (1.227641 --> 1.225389).  Saving model ...
Validation loss decreased (1.225389 --> 1.222805).  Saving model ...
Validation loss decreased (1.222805 --> 1.217805).  Saving model ...
Validation loss decreased (1.217805 --> 1.211422).  Saving model ...
Validation loss decreased (1.211422 --> 1.205818).  Saving model ...
Validation loss decreased (1.205818 --> 1.201943).  Saving model ...
Validation loss decreased (1.201943 --> 1.200862).  Saving model ...
Validation loss decreased (1.200862 --> 1.193898).  Saving model ...
Validation loss decreased (1.193898 --> 1.190790).  Saving model ...
Validation loss decreased (1.190790 --> 1.185966).  Saving model ...
Validation loss decreased (1.185966 --> 1.180774).  Saving model ...
Validation loss decreased (1.180774 --> 1.173758).  Saving model ...
Validation loss decreased (1.173758 --> 1.171231).  Saving model ...
Validation loss decreased (1.171231 --> 1.169271).  Saving model ...
Validation loss decreased (1.169271 --> 1.165384).  Saving model ...
Validation loss decreased (1.165384 --> 1.165299).  Saving model ...
Validation loss decreased (1.165299 --> 1.160401).  Saving model ...
Validation loss decreased (1.160401 --> 1.156977).  Saving model ...
Validation loss decreased (1.156977 --> 1.154103).  Saving model ...
Validation loss decreased (1.154103 --> 1.150770).  Saving model ...
Validation loss decreased (1.150770 --> 1.145026).  Saving model ...
Validation loss decreased (1.145026 --> 1.144498).  Saving model ...
Validation loss decreased (1.144498 --> 1.141014).  Saving model ...
Validation loss decreased (1.141014 --> 1.137768).  Saving model ...
Validation loss decreased (1.137768 --> 1.130779).  Saving model ...
Validation loss decreased (1.130779 --> 1.128581).  Saving model ...
Validation loss decreased (1.128581 --> 1.127403).  Saving model ...
Validation loss decreased (1.127403 --> 1.124807).  Saving model ...
EarlyStopping counter: 1 out of 10.0
Validation loss decreased (1.124807 --> 1.120922).  Saving model ...
Validation loss decreased (1.120922 --> 1.116060).  Saving model ...
Validation loss decreased (1.116060 --> 1.115210).  Saving model ...
Validation loss decreased (1.115210 --> 1.109883).  Saving model ...
Validation loss decreased (1.109883 --> 1.109711).  Saving model ...
Validation loss decreased (1.109711 --> 1.107871).  Saving model ...
Validation loss decreased (1.107871 --> 1.105845).  Saving model ...
Validation loss decreased (1.105845 --> 1.104862).  Saving model ...
Validation loss decreased (1.104862 --> 1.101168).  Saving model ...
Validation loss decreased (1.101168 --> 1.099326).  Saving model ...
EarlyStopping counter: 1 out of 10.0
Validation loss decreased (1.099326 --> 1.095718).  Saving model ...
EarlyStopping counter: 1 out of 10.0
Validation loss decreased (1.095718 --> 1.093226).  Saving model ...
Validation loss decreased (1.093226 --> 1.089324).  Saving model ...
Validation loss decreased (1.089324 --> 1.088288).  Saving model ...
Validation loss decreased (1.088288 --> 1.084220).  Saving model ...
Validation loss decreased (1.084220 --> 1.080971).  Saving model ...
Validation loss decreased (1.080971 --> 1.074861).  Saving model ...
Validation loss decreased (1.074861 --> 1.073165).  Saving model ...
EarlyStopping counter: 1 out of 10.0
Validation loss decreased (1.073165 --> 1.072255).  Saving model ...
EarlyStopping counter: 1 out of 10.0
Validation loss decreased (1.072255 --> 1.070524).  Saving model ...
EarlyStopping counter: 1 out of 10.0
Validation loss decreased (1.070524 --> 1.070519).  Saving model ...
Validation loss decreased (1.070519 --> 1.068749).  Saving model ...
EarlyStopping counter: 1 out of 10.0
EarlyStopping counter: 2 out of 10.0
Validation loss decreased (1.068749 --> 1.065034).  Saving model ...
Validation loss decreased (1.065034 --> 1.063852).  Saving model ...
Validation loss decreased (1.063852 --> 1.061057).  Saving model ...
EarlyStopping counter: 1 out of 10.0
EarlyStopping counter: 2 out of 10.0
EarlyStopping counter: 3 out of 10.0
Validation loss decreased (1.061057 --> 1.058109).  Saving model ...
Validation loss decreased (1.058109 --> 1.056369).  Saving model ...
EarlyStopping counter: 1 out of 10.0
Validation loss decreased (1.056369 --> 1.054990).  Saving model ...
Validation loss decreased (1.054990 --> 1.050770).  Saving model ...
Validation loss decreased (1.050770 --> 1.050507).  Saving model ...
Validation loss decreased (1.050507 --> 1.050501).  Saving model ...
EarlyStopping counter: 1 out of 10.0
EarlyStopping counter: 2 out of 10.0
Validation loss decreased (1.050501 --> 1.050059).  Saving model ...
EarlyStopping counter: 1 out of 10.0
Validation loss decreased (1.050059 --> 1.049478).  Saving model ...
EarlyStopping counter: 1 out of 10.0
EarlyStopping counter: 2 out of 10.0
Validation loss decreased (1.049478 --> 1.048045).  Saving model ...
EarlyStopping counter: 1 out of 10.0
Validation loss decreased (1.048045 --> 1.046548).  Saving model ...
EarlyStopping counter: 1 out of 10.0
Validation loss decreased (1.046548 --> 1.045276).  Saving model ...
Validation loss decreased (1.045276 --> 1.043945).  Saving model ...
Validation loss decreased (1.043945 --> 1.043267).  Saving model ...
EarlyStopping counter: 1 out of 10.0
EarlyStopping counter: 2 out of 10.0
EarlyStopping counter: 3 out of 10.0
EarlyStopping counter: 4 out of 10.0
EarlyStopping counter: 5 out of 10.0
EarlyStopping counter: 6 out of 10.0
EarlyStopping counter: 7 out of 10.0
EarlyStopping counter: 8 out of 10.0
EarlyStopping counter: 9 out of 10.0
EarlyStopping counter: 10 out of 10.0
/localscratch/yinan.29019257.0/env/lib/python3.7/site-packages/torch/nn/functional.py:1794: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.
  warnings.warn("nn.functional.tanh is deprecated. Use torch.tanh instead.")
wandb: Waiting for W&B process to finish, PID 128344... (success).
wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: \ 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: | 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: / 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: \ 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: | 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: / 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: \ 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: | 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: / 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb:                                                                                
wandb: Run history:
wandb:     e_F1 ▁▁▂▄▅▅▅▅▅▅▅▅▆▆▆▆▆▆▆▆▇▇▇▇▇▇▇▇▇▇▇▇████████
wandb:   e_loss █▇▇▆▆▆▆▆▅▅▅▄▄▄▄▃▃▃▃▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:     t_F1 ▁▁▁▂▂▂▃▄▃▄▅▄▅▅▅▆▆▅▆▆▆▆▇▆▇▇▇▇▇▇▇▇▇████▇██
wandb:   t_loss ██▇▇▇▇▆▆▆▆▅▅▅▅▅▄▄▄▄▄▄▃▃▃▃▃▂▂▂▂▂▂▂▂▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:     e_F1 55.59384
wandb:   e_loss 1.04526
wandb:     t_F1 68.89464
wandb:   t_loss 0.82397
wandb: 
wandb: Synced 4 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Synced sandy-blaze-1: https://wandb.ai/yinanazhou/xl_512_bs_8_lr_1e06_es_10_lc_True_nr_True_sr_True_stem_True_lemma_False_repeat_4_fold_2/runs/7896810c
wandb: Find logs at: ./wandb/run-20220317_174208-7896810c/logs/debug.log
wandb: 

wandb: wandb version 0.12.11 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
2022-03-17 19:11:57.858499: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1
wandb: Tracking run with wandb version 0.12.5
wandb: Syncing run resilient-music-1
wandb: ⭐️ View project at https://wandb.ai/yinanazhou/xl_512_bs_8_lr_1e06_es_10_lc_True_nr_True_sr_True_stem_True_lemma_False_repeat_5_fold_1
wandb: 🚀 View run at https://wandb.ai/yinanazhou/xl_512_bs_8_lr_1e06_es_10_lc_True_nr_True_sr_True_stem_True_lemma_False_repeat_5_fold_1/runs/2tcrm44h
wandb: Run data is saved locally in /project/6002780/yinan/Thesis_MER_Lyrics/lyric-emotion/wandb/run-20220317_191155-2tcrm44h
wandb: Run `wandb offline` to turn off syncing.
wandb: Network error (ReadTimeout), entering retry loop.

Validation loss decreased (inf --> 1.507879).  Saving model ...
Validation loss decreased (1.507879 --> 1.466896).  Saving model ...
Validation loss decreased (1.466896 --> 1.437237).  Saving model ...
Validation loss decreased (1.437237 --> 1.416421).  Saving model ...
Validation loss decreased (1.416421 --> 1.401247).  Saving model ...
Validation loss decreased (1.401247 --> 1.389821).  Saving model ...
Validation loss decreased (1.389821 --> 1.381778).  Saving model ...
Validation loss decreased (1.381778 --> 1.375381).  Saving model ...
Validation loss decreased (1.375381 --> 1.369520).  Saving model ...
Validation loss decreased (1.369520 --> 1.364385).  Saving model ...
Validation loss decreased (1.364385 --> 1.360111).  Saving model ...
Validation loss decreased (1.360111 --> 1.356076).  Saving model ...
Validation loss decreased (1.356076 --> 1.351714).  Saving model ...
Validation loss decreased (1.351714 --> 1.347480).  Saving model ...
Validation loss decreased (1.347480 --> 1.343328).  Saving model ...
Validation loss decreased (1.343328 --> 1.338540).  Saving model ...
Validation loss decreased (1.338540 --> 1.334116).  Saving model ...
Validation loss decreased (1.334116 --> 1.330232).  Saving model ...
Validation loss decreased (1.330232 --> 1.325636).  Saving model ...
Validation loss decreased (1.325636 --> 1.320417).  Saving model ...
Validation loss decreased (1.320417 --> 1.315657).  Saving model ...
Validation loss decreased (1.315657 --> 1.311354).  Saving model ...
Validation loss decreased (1.311354 --> 1.306584).  Saving model ...
Validation loss decreased (1.306584 --> 1.301299).  Saving model ...
Validation loss decreased (1.301299 --> 1.295986).  Saving model ...
Validation loss decreased (1.295986 --> 1.290325).  Saving model ...
Validation loss decreased (1.290325 --> 1.285288).  Saving model ...
Validation loss decreased (1.285288 --> 1.278431).  Saving model ...
Validation loss decreased (1.278431 --> 1.271462).  Saving model ...
Validation loss decreased (1.271462 --> 1.264937).  Saving model ...
Validation loss decreased (1.264937 --> 1.259656).  Saving model ...
Validation loss decreased (1.259656 --> 1.254035).  Saving model ...
Validation loss decreased (1.254035 --> 1.249193).  Saving model ...
Validation loss decreased (1.249193 --> 1.243910).  Saving model ...
Validation loss decreased (1.243910 --> 1.239156).  Saving model ...
Validation loss decreased (1.239156 --> 1.233046).  Saving model ...
Validation loss decreased (1.233046 --> 1.228185).  Saving model ...
Validation loss decreased (1.228185 --> 1.223442).  Saving model ...
Validation loss decreased (1.223442 --> 1.219450).  Saving model ...
Validation loss decreased (1.219450 --> 1.216394).  Saving model ...
Validation loss decreased (1.216394 --> 1.212005).  Saving model ...
Validation loss decreased (1.212005 --> 1.207841).  Saving model ...
Validation loss decreased (1.207841 --> 1.203262).  Saving model ...
Validation loss decreased (1.203262 --> 1.199722).  Saving model ...
Validation loss decreased (1.199722 --> 1.195190).  Saving model ...
Validation loss decreased (1.195190 --> 1.190453).  Saving model ...
Validation loss decreased (1.190453 --> 1.186183).  Saving model ...
Validation loss decreased (1.186183 --> 1.183364).  Saving model ...
Validation loss decreased (1.183364 --> 1.177722).  Saving model ...
Validation loss decreased (1.177722 --> 1.173169).  Saving model ...
Validation loss decreased (1.173169 --> 1.170751).  Saving model ...
Validation loss decreased (1.170751 --> 1.166048).  Saving model ...
Validation loss decreased (1.166048 --> 1.163767).  Saving model ...
Validation loss decreased (1.163767 --> 1.157234).  Saving model ...
Validation loss decreased (1.157234 --> 1.154153).  Saving model ...
Validation loss decreased (1.154153 --> 1.150113).  Saving model ...
Validation loss decreased (1.150113 --> 1.146559).  Saving model ...
Validation loss decreased (1.146559 --> 1.142066).  Saving model ...
Validation loss decreased (1.142066 --> 1.137166).  Saving model ...
Validation loss decreased (1.137166 --> 1.132612).  Saving model ...
Validation loss decreased (1.132612 --> 1.130326).  Saving model ...
Validation loss decreased (1.130326 --> 1.125995).  Saving model ...
Validation loss decreased (1.125995 --> 1.122427).  Saving model ...
Validation loss decreased (1.122427 --> 1.120575).  Saving model ...
Validation loss decreased (1.120575 --> 1.118986).  Saving model ...
Validation loss decreased (1.118986 --> 1.114771).  Saving model ...
Validation loss decreased (1.114771 --> 1.109133).  Saving model ...
Validation loss decreased (1.109133 --> 1.105232).  Saving model ...
Validation loss decreased (1.105232 --> 1.102012).  Saving model ...
Validation loss decreased (1.102012 --> 1.101788).  Saving model ...
Validation loss decreased (1.101788 --> 1.098340).  Saving model ...
Validation loss decreased (1.098340 --> 1.095539).  Saving model ...
Validation loss decreased (1.095539 --> 1.092830).  Saving model ...
Validation loss decreased (1.092830 --> 1.088596).  Saving model ...
Validation loss decreased (1.088596 --> 1.087841).  Saving model ...
Validation loss decreased (1.087841 --> 1.085944).  Saving model ...
Validation loss decreased (1.085944 --> 1.077220).  Saving model ...
Validation loss decreased (1.077220 --> 1.075628).  Saving model ...
Validation loss decreased (1.075628 --> 1.072484).  Saving model ...
Validation loss decreased (1.072484 --> 1.070509).  Saving model ...
Validation loss decreased (1.070509 --> 1.068401).  Saving model ...
Validation loss decreased (1.068401 --> 1.066137).  Saving model ...
Validation loss decreased (1.066137 --> 1.064298).  Saving model ...
Validation loss decreased (1.064298 --> 1.062203).  Saving model ...
EarlyStopping counter: 1 out of 10.0
Validation loss decreased (1.062203 --> 1.060559).  Saving model ...
Validation loss decreased (1.060559 --> 1.054484).  Saving model ...
Validation loss decreased (1.054484 --> 1.051753).  Saving model ...
Validation loss decreased (1.051753 --> 1.049527).  Saving model ...
EarlyStopping counter: 1 out of 10.0
Validation loss decreased (1.049527 --> 1.048233).  Saving model ...
Validation loss decreased (1.048233 --> 1.044305).  Saving model ...
Validation loss decreased (1.044305 --> 1.042441).  Saving model ...
EarlyStopping counter: 1 out of 10.0
Validation loss decreased (1.042441 --> 1.041633).  Saving model ...
Validation loss decreased (1.041633 --> 1.038299).  Saving model ...
Validation loss decreased (1.038299 --> 1.035956).  Saving model ...
Validation loss decreased (1.035956 --> 1.035570).  Saving model ...
EarlyStopping counter: 1 out of 10.0
Validation loss decreased (1.035570 --> 1.034473).  Saving model ...
Validation loss decreased (1.034473 --> 1.031854).  Saving model ...
Validation loss decreased (1.031854 --> 1.029395).  Saving model ...
Validation loss decreased (1.029395 --> 1.024206).  Saving model ...
Validation loss decreased (1.024206 --> 1.023795).  Saving model ...
EarlyStopping counter: 1 out of 10.0
Validation loss decreased (1.023795 --> 1.021074).  Saving model ...
Validation loss decreased (1.021074 --> 1.019834).  Saving model ...
Validation loss decreased (1.019834 --> 1.017345).  Saving model ...
Validation loss decreased (1.017345 --> 1.014543).  Saving model ...
Validation loss decreased (1.014543 --> 1.014211).  Saving model ...
EarlyStopping counter: 1 out of 10.0
EarlyStopping counter: 2 out of 10.0
Validation loss decreased (1.014211 --> 1.010473).  Saving model ...
Validation loss decreased (1.010473 --> 1.009083).  Saving model ...
EarlyStopping counter: 1 out of 10.0
EarlyStopping counter: 2 out of 10.0
Validation loss decreased (1.009083 --> 1.008914).  Saving model ...
Validation loss decreased (1.008914 --> 1.006691).  Saving model ...
Validation loss decreased (1.006691 --> 1.004213).  Saving model ...
Validation loss decreased (1.004213 --> 1.003812).  Saving model ...
Validation loss decreased (1.003812 --> 1.001948).  Saving model ...
EarlyStopping counter: 1 out of 10.0
Validation loss decreased (1.001948 --> 1.001179).  Saving model ...
Validation loss decreased (1.001179 --> 1.000849).  Saving model ...
EarlyStopping counter: 1 out of 10.0
Validation loss decreased (1.000849 --> 1.000345).  Saving model ...
Validation loss decreased (1.000345 --> 1.000299).  Saving model ...
Validation loss decreased (1.000299 --> 0.999493).  Saving model ...
EarlyStopping counter: 1 out of 10.0
EarlyStopping counter: 2 out of 10.0
EarlyStopping counter: 3 out of 10.0
Validation loss decreased (0.999493 --> 0.998280).  Saving model ...
EarlyStopping counter: 1 out of 10.0
Validation loss decreased (0.998280 --> 0.997691).  Saving model ...
Validation loss decreased (0.997691 --> 0.996881).  Saving model ...
EarlyStopping counter: 1 out of 10.0
Validation loss decreased (0.996881 --> 0.996716).  Saving model ...
EarlyStopping counter: 1 out of 10.0
EarlyStopping counter: 2 out of 10.0
EarlyStopping counter: 3 out of 10.0
EarlyStopping counter: 4 out of 10.0
EarlyStopping counter: 5 out of 10.0
EarlyStopping counter: 6 out of 10.0
EarlyStopping counter: 7 out of 10.0
EarlyStopping counter: 8 out of 10.0
Validation loss decreased (0.996716 --> 0.995978).  Saving model ...
Validation loss decreased (0.995978 --> 0.993626).  Saving model ...
EarlyStopping counter: 1 out of 10.0
EarlyStopping counter: 2 out of 10.0
EarlyStopping counter: 3 out of 10.0
EarlyStopping counter: 4 out of 10.0
EarlyStopping counter: 5 out of 10.0
EarlyStopping counter: 6 out of 10.0
EarlyStopping counter: 7 out of 10.0
EarlyStopping counter: 8 out of 10.0
EarlyStopping counter: 9 out of 10.0
EarlyStopping counter: 10 out of 10.0
/localscratch/yinan.29019257.0/env/lib/python3.7/site-packages/torch/nn/functional.py:1794: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.
  warnings.warn("nn.functional.tanh is deprecated. Use torch.tanh instead.")
wandb: Waiting for W&B process to finish, PID 133181... (success).
wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: \ 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: | 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: / 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: \ 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: | 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: / 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: \ 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: | 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: / 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb:                                                                                
wandb: Run history:
wandb:     e_F1 ▁▂▃▄▅▅▆▆▆▆▆▆▇▇▇▇▇▇▇▇▇▇▇█▇▇██████████████
wandb:   e_loss █▇▇▆▆▆▆▅▅▅▄▄▄▄▃▃▃▃▂▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:     t_F1 ▁▁▂▂▃▃▄▄▅▅▅▅▅▆▆▆▆▆▆▆▆▇▇▇▇▇▇▇▇▇▇█████████
wandb:   t_loss ██▇▇▇▇▇▆▆▆▆▅▅▅▅▅▄▄▄▄▄▃▃▃▃▃▃▃▂▂▂▂▂▂▂▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:     e_F1 57.77308
wandb:   e_loss 0.99836
wandb:     t_F1 73.30112
wandb:   t_loss 0.7221
wandb: 
wandb: Synced 4 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Synced resilient-music-1: https://wandb.ai/yinanazhou/xl_512_bs_8_lr_1e06_es_10_lc_True_nr_True_sr_True_stem_True_lemma_False_repeat_5_fold_1/runs/2tcrm44h
wandb: Find logs at: ./wandb/run-20220317_191155-2tcrm44h/logs/debug.log
wandb: 

wandb: wandb version 0.12.11 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
2022-03-17 20:53:01.506370: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1
wandb: Tracking run with wandb version 0.12.5
wandb: Syncing run dark-resonance-1
wandb: ⭐️ View project at https://wandb.ai/yinanazhou/xl_512_bs_8_lr_1e06_es_10_lc_True_nr_True_sr_True_stem_True_lemma_False_repeat_5_fold_2
wandb: 🚀 View run at https://wandb.ai/yinanazhou/xl_512_bs_8_lr_1e06_es_10_lc_True_nr_True_sr_True_stem_True_lemma_False_repeat_5_fold_2/runs/3lmzfear
wandb: Run data is saved locally in /project/6002780/yinan/Thesis_MER_Lyrics/lyric-emotion/wandb/run-20220317_205258-3lmzfear
wandb: Run `wandb offline` to turn off syncing.
wandb: Network error (ReadTimeout), entering retry loop.

Validation loss decreased (inf --> 1.492252).  Saving model ...
Validation loss decreased (1.492252 --> 1.461133).  Saving model ...
Validation loss decreased (1.461133 --> 1.436921).  Saving model ...
Validation loss decreased (1.436921 --> 1.418495).  Saving model ...
Validation loss decreased (1.418495 --> 1.403784).  Saving model ...
Validation loss decreased (1.403784 --> 1.392479).  Saving model ...
Validation loss decreased (1.392479 --> 1.383243).  Saving model ...
Validation loss decreased (1.383243 --> 1.375124).  Saving model ...
Validation loss decreased (1.375124 --> 1.369438).  Saving model ...
Validation loss decreased (1.369438 --> 1.362291).  Saving model ...
Validation loss decreased (1.362291 --> 1.357570).  Saving model ...
Validation loss decreased (1.357570 --> 1.352420).  Saving model ...
Validation loss decreased (1.352420 --> 1.347932).  Saving model ...
Validation loss decreased (1.347932 --> 1.343622).  Saving model ...
Validation loss decreased (1.343622 --> 1.338609).  Saving model ...
Validation loss decreased (1.338609 --> 1.333847).  Saving model ...
Validation loss decreased (1.333847 --> 1.329091).  Saving model ...
Validation loss decreased (1.329091 --> 1.323550).  Saving model ...
Validation loss decreased (1.323550 --> 1.318853).  Saving model ...
Validation loss decreased (1.318853 --> 1.314769).  Saving model ...
Validation loss decreased (1.314769 --> 1.309694).  Saving model ...
Validation loss decreased (1.309694 --> 1.303755).  Saving model ...
Validation loss decreased (1.303755 --> 1.296982).  Saving model ...
Validation loss decreased (1.296982 --> 1.291443).  Saving model ...
Validation loss decreased (1.291443 --> 1.285646).  Saving model ...
Validation loss decreased (1.285646 --> 1.279996).  Saving model ...
Validation loss decreased (1.279996 --> 1.273817).  Saving model ...
Validation loss decreased (1.273817 --> 1.267811).  Saving model ...
Validation loss decreased (1.267811 --> 1.261772).  Saving model ...
Validation loss decreased (1.261772 --> 1.255782).  Saving model ...
Validation loss decreased (1.255782 --> 1.249258).  Saving model ...
Validation loss decreased (1.249258 --> 1.242029).  Saving model ...
Validation loss decreased (1.242029 --> 1.236705).  Saving model ...
Validation loss decreased (1.236705 --> 1.231127).  Saving model ...
Validation loss decreased (1.231127 --> 1.226357).  Saving model ...
Validation loss decreased (1.226357 --> 1.221467).  Saving model ...
Validation loss decreased (1.221467 --> 1.216958).  Saving model ...
Validation loss decreased (1.216958 --> 1.213438).  Saving model ...
Validation loss decreased (1.213438 --> 1.209637).  Saving model ...
Validation loss decreased (1.209637 --> 1.203822).  Saving model ...
Validation loss decreased (1.203822 --> 1.199719).  Saving model ...
Validation loss decreased (1.199719 --> 1.197579).  Saving model ...
Validation loss decreased (1.197579 --> 1.195647).  Saving model ...
Validation loss decreased (1.195647 --> 1.188985).  Saving model ...
Validation loss decreased (1.188985 --> 1.182600).  Saving model ...
Validation loss decreased (1.182600 --> 1.177702).  Saving model ...
Validation loss decreased (1.177702 --> 1.175623).  Saving model ...
Validation loss decreased (1.175623 --> 1.171132).  Saving model ...
Validation loss decreased (1.171132 --> 1.166649).  Saving model ...
Validation loss decreased (1.166649 --> 1.162380).  Saving model ...
Validation loss decreased (1.162380 --> 1.159451).  Saving model ...
Validation loss decreased (1.159451 --> 1.154835).  Saving model ...
Validation loss decreased (1.154835 --> 1.152477).  Saving model ...
Validation loss decreased (1.152477 --> 1.152314).  Saving model ...
Validation loss decreased (1.152314 --> 1.148697).  Saving model ...
Validation loss decreased (1.148697 --> 1.142098).  Saving model ...
Validation loss decreased (1.142098 --> 1.137267).  Saving model ...
Validation loss decreased (1.137267 --> 1.133794).  Saving model ...
Validation loss decreased (1.133794 --> 1.128780).  Saving model ...
Validation loss decreased (1.128780 --> 1.126894).  Saving model ...
Validation loss decreased (1.126894 --> 1.125217).  Saving model ...
Validation loss decreased (1.125217 --> 1.120672).  Saving model ...
Validation loss decreased (1.120672 --> 1.114074).  Saving model ...
Validation loss decreased (1.114074 --> 1.114035).  Saving model ...
Validation loss decreased (1.114035 --> 1.112705).  Saving model ...
Validation loss decreased (1.112705 --> 1.110876).  Saving model ...
Validation loss decreased (1.110876 --> 1.110301).  Saving model ...
Validation loss decreased (1.110301 --> 1.106927).  Saving model ...
Validation loss decreased (1.106927 --> 1.103512).  Saving model ...
Validation loss decreased (1.103512 --> 1.100930).  Saving model ...
Validation loss decreased (1.100930 --> 1.096040).  Saving model ...
Validation loss decreased (1.096040 --> 1.090968).  Saving model ...
Validation loss decreased (1.090968 --> 1.089232).  Saving model ...
Validation loss decreased (1.089232 --> 1.086146).  Saving model ...
Validation loss decreased (1.086146 --> 1.083777).  Saving model ...
Validation loss decreased (1.083777 --> 1.079829).  Saving model ...
Validation loss decreased (1.079829 --> 1.074660).  Saving model ...
EarlyStopping counter: 1 out of 10.0
Validation loss decreased (1.074660 --> 1.072695).  Saving model ...
Validation loss decreased (1.072695 --> 1.071060).  Saving model ...
Validation loss decreased (1.071060 --> 1.070752).  Saving model ...
Validation loss decreased (1.070752 --> 1.068537).  Saving model ...
Validation loss decreased (1.068537 --> 1.066825).  Saving model ...
Validation loss decreased (1.066825 --> 1.063927).  Saving model ...
Validation loss decreased (1.063927 --> 1.063747).  Saving model ...
Validation loss decreased (1.063747 --> 1.062655).  Saving model ...
Validation loss decreased (1.062655 --> 1.062158).  Saving model ...
Validation loss decreased (1.062158 --> 1.058845).  Saving model ...
Validation loss decreased (1.058845 --> 1.056604).  Saving model ...
EarlyStopping counter: 1 out of 10.0
Validation loss decreased (1.056604 --> 1.053961).  Saving model ...
EarlyStopping counter: 1 out of 10.0
Validation loss decreased (1.053961 --> 1.052894).  Saving model ...
Validation loss decreased (1.052894 --> 1.050806).  Saving model ...
Validation loss decreased (1.050806 --> 1.048738).  Saving model ...
EarlyStopping counter: 1 out of 10.0
Validation loss decreased (1.048738 --> 1.048701).  Saving model ...
Validation loss decreased (1.048701 --> 1.045977).  Saving model ...
EarlyStopping counter: 1 out of 10.0
Validation loss decreased (1.045977 --> 1.040536).  Saving model ...
Validation loss decreased (1.040536 --> 1.034825).  Saving model ...
EarlyStopping counter: 1 out of 10.0
Validation loss decreased (1.034825 --> 1.034460).  Saving model ...
EarlyStopping counter: 1 out of 10.0
Validation loss decreased (1.034460 --> 1.029750).  Saving model ...
EarlyStopping counter: 1 out of 10.0
EarlyStopping counter: 2 out of 10.0
EarlyStopping counter: 3 out of 10.0
EarlyStopping counter: 4 out of 10.0
Validation loss decreased (1.029750 --> 1.026991).  Saving model ...
EarlyStopping counter: 1 out of 10.0
Validation loss decreased (1.026991 --> 1.022851).  Saving model ...
EarlyStopping counter: 1 out of 10.0
Validation loss decreased (1.022851 --> 1.021777).  Saving model ...
Validation loss decreased (1.021777 --> 1.017940).  Saving model ...
Validation loss decreased (1.017940 --> 1.016889).  Saving model ...
EarlyStopping counter: 1 out of 10.0
EarlyStopping counter: 2 out of 10.0
EarlyStopping counter: 3 out of 10.0
Validation loss decreased (1.016889 --> 1.013882).  Saving model ...
Validation loss decreased (1.013882 --> 1.011229).  Saving model ...
EarlyStopping counter: 1 out of 10.0
EarlyStopping counter: 2 out of 10.0
EarlyStopping counter: 3 out of 10.0
Validation loss decreased (1.011229 --> 1.010205).  Saving model ...
EarlyStopping counter: 1 out of 10.0
Validation loss decreased (1.010205 --> 1.009041).  Saving model ...
EarlyStopping counter: 1 out of 10.0
Validation loss decreased (1.009041 --> 1.007189).  Saving model ...
Validation loss decreased (1.007189 --> 1.004184).  Saving model ...
EarlyStopping counter: 1 out of 10.0
EarlyStopping counter: 2 out of 10.0
EarlyStopping counter: 3 out of 10.0
EarlyStopping counter: 4 out of 10.0
EarlyStopping counter: 5 out of 10.0
EarlyStopping counter: 6 out of 10.0
Validation loss decreased (1.004184 --> 1.002926).  Saving model ...
Validation loss decreased (1.002926 --> 1.001784).  Saving model ...
EarlyStopping counter: 1 out of 10.0
EarlyStopping counter: 2 out of 10.0
EarlyStopping counter: 3 out of 10.0
EarlyStopping counter: 4 out of 10.0
Validation loss decreased (1.001784 --> 1.001520).  Saving model ...
Validation loss decreased (1.001520 --> 1.001256).  Saving model ...
Validation loss decreased (1.001256 --> 1.000300).  Saving model ...
EarlyStopping counter: 1 out of 10.0
EarlyStopping counter: 2 out of 10.0
EarlyStopping counter: 3 out of 10.0
EarlyStopping counter: 4 out of 10.0
Validation loss decreased (1.000300 --> 0.999330).  Saving model ...
Validation loss decreased (0.999330 --> 0.997681).  Saving model ...
Validation loss decreased (0.997681 --> 0.994758).  Saving model ...
EarlyStopping counter: 1 out of 10.0
EarlyStopping counter: 2 out of 10.0
EarlyStopping counter: 3 out of 10.0
EarlyStopping counter: 4 out of 10.0
EarlyStopping counter: 5 out of 10.0
EarlyStopping counter: 6 out of 10.0
EarlyStopping counter: 7 out of 10.0
EarlyStopping counter: 8 out of 10.0
EarlyStopping counter: 9 out of 10.0
EarlyStopping counter: 10 out of 10.0
/localscratch/yinan.29019257.0/env/lib/python3.7/site-packages/torch/nn/functional.py:1794: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.
  warnings.warn("nn.functional.tanh is deprecated. Use torch.tanh instead.")
wandb: Waiting for W&B process to finish, PID 138565... (success).
wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: \ 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: | 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: / 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: \ 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: | 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: / 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: \ 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: | 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: / 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb:                                                                                
wandb: Run history:
wandb:     e_F1 ▁▂▄▅▅▅▆▆▆▆▆▆▆▆▆▇▇▇▇▇▇▇▇▇▇▇▇▇████████████
wandb:   e_loss █▇▇▆▆▆▅▅▅▄▄▄▄▃▃▃▃▃▂▂▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:     t_F1 ▁▁▂▃▃▃▃▄▄▄▅▅▅▅▅▆▆▆▆▆▆▆▆▇▆▇▇▇▇▇▇▇▇▇▇▇▇▇▇█
wandb:   t_loss ██▇▇▇▇▆▆▆▆▅▅▅▅▄▄▄▄▄▃▃▃▃▃▃▂▃▂▃▂▂▂▂▂▂▂▁▂▂▁
wandb: 
wandb: Run summary:
wandb:     e_F1 57.95768
wandb:   e_loss 0.99717
wandb:     t_F1 73.94262
wandb:   t_loss 0.73662
wandb: 
wandb: Synced 4 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Synced dark-resonance-1: https://wandb.ai/yinanazhou/xl_512_bs_8_lr_1e06_es_10_lc_True_nr_True_sr_True_stem_True_lemma_False_repeat_5_fold_2/runs/3lmzfear
wandb: Find logs at: ./wandb/run-20220317_205258-3lmzfear/logs/debug.log
wandb: 

