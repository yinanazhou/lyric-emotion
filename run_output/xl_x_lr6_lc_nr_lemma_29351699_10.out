Unloading StdEnv/2020

Due to MODULEPATH changes, the following have been reloaded:
  1) mii/1.1.1


The following have been reloaded with a version change:
  1) python/3.8.2 => python/3.7.4

Using base prefix '/cvmfs/soft.computecanada.ca/easybuild/software/2017/Core/python/3.7.4'
New python executable in /localscratch/yinan.29351699.0/env/bin/python
Installing setuptools, pip, wheel...
done.
Ignoring pip: markers 'python_version < "3"' don't match your environment
Looking in links: /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/nix/avx2, /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/nix/generic, /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic
Collecting pip
Installing collected packages: pip
  Found existing installation: pip 19.1.1
    Uninstalling pip-19.1.1:
      Successfully uninstalled pip-19.1.1
Successfully installed pip-21.2.3+computecanada
Looking in links: /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/nix/avx2, /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/nix/generic, /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/keras-2.8.0+computecanada-py2.py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/Keras_Preprocessing-1.1.2+computecanada-py3-none-any.whl
Requirement already satisfied: matplotlib in /cvmfs/soft.computecanada.ca/easybuild/software/2017/Core/scipy-stack/2019a/lib/python3.7/site-packages (from -r requirements.txt (line 3)) (3.0.2)
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/nltk-3.6.5+computecanada-py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/scikit_learn-0.22.1+computecanada-cp37-cp37m-linux_x86_64.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/tensorboard-2.3.0+computecanada-py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/tensorboard_plugin_wit-1.7.0+computecanada-py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/tensorflow_gpu-2.3.0+computecanada-cp37-cp37m-linux_x86_64.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/tensorflow_estimator-2.3.0+computecanada-py2.py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/tokenizers-0.5.2+computecanada-cp37-cp37m-linux_x86_64.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/nix/avx2/torch-1.4.0+computecanada-cp37-cp37m-linux_x86_64.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/torchtext-0.6.0+computecanada-py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/torchvision-0.8.2+computecanada-cp37-cp37m-linux_x86_64.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/transformers-2.5.1+computecanada-py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/urllib3-1.26.7+computecanada-py2.py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/tqdm-4.63.1+computecanada-py2.py3-none-any.whl
ERROR: Could not find a version that satisfies the requirement regex>=2021.8.3 (from nltk) (from versions: 2018.1.10+computecanada, 2019.11.1+computecanada, 2020.11.13+computecanada)
ERROR: No matching distribution found for regex>=2021.8.3
Looking in links: /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/nix/avx2, /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/nix/generic, /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic
ERROR: Could not find a version that satisfies the requirement numpy==1.20.0+computacanada (from versions: 1.15.0+computecanada, 1.15.2+computecanada, 1.15.4+computecanada, 1.16.0+computecanada, 1.16.2+computecanada, 1.16.3+computecanada, 1.17.4+computecanada, 1.18.1+computecanada, 1.18.4+computecanada, 1.19.1+computecanada, 1.19.2+computecanada, 1.20.2+computecanada)
ERROR: No matching distribution found for numpy==1.20.0+computacanada
Looking in links: /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/nix/avx2, /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/nix/generic, /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/wandb-0.12.5+computecanada-py2.py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/PyYAML-5.3.1+computecanada-cp37-cp37m-linux_x86_64.whl
Requirement already satisfied: python-dateutil>=2.6.1 in /cvmfs/soft.computecanada.ca/easybuild/software/2017/Core/scipy-stack/2019a/lib/python3.7/site-packages (from wandb) (2.7.5)
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/configparser-5.0.2+computecanada-py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/subprocess32-3.5.4+computecanada-py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/pathtools-0.1.2+computecanada-py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/sentry_sdk-1.5.0+computecanada-py2.py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/yaspin-2.1.0+computecanada-py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/click-8.0.4+computecanada-py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/promise-2.3+computecanada-py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/shortuuid-1.0.1+computecanada-py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/GitPython-3.1.24+computecanada-py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/protobuf-3.19.4+computecanada-py2.py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/psutil-5.7.3+computecanada-cp37-cp37m-linux_x86_64.whl
Requirement already satisfied: requests<3,>=2.0.0 in /cvmfs/soft.computecanada.ca/easybuild/software/2017/Core/scipy-stack/2019a/lib/python3.7/site-packages (from wandb) (2.21.0)
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/six-1.16.0+computecanada-py2.py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/docker_pycreds-0.4.0+computecanada-py2.py3-none-any.whl
Requirement already satisfied: importlib-metadata in /cvmfs/soft.computecanada.ca/easybuild/software/2017/Core/scipy-stack/2019a/lib/python3.7/site-packages (from Click!=8.0.0,>=7.0->wandb) (0.8)
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/typing_extensions-4.1.1+computecanada-py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/gitdb-4.0.9+computecanada-py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/smmap-5.0.0+computecanada-py3-none-any.whl
Requirement already satisfied: urllib3<1.25,>=1.21.1 in /cvmfs/soft.computecanada.ca/easybuild/software/2017/Core/scipy-stack/2019a/lib/python3.7/site-packages (from requests<3,>=2.0.0->wandb) (1.24.1)
Requirement already satisfied: certifi>=2017.4.17 in /cvmfs/soft.computecanada.ca/easybuild/software/2017/Core/scipy-stack/2019a/lib/python3.7/site-packages (from requests<3,>=2.0.0->wandb) (2018.11.29)
Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /cvmfs/soft.computecanada.ca/easybuild/software/2017/Core/scipy-stack/2019a/lib/python3.7/site-packages (from requests<3,>=2.0.0->wandb) (3.0.4)
Requirement already satisfied: idna<2.9,>=2.5 in /cvmfs/soft.computecanada.ca/easybuild/software/2017/Core/scipy-stack/2019a/lib/python3.7/site-packages (from requests<3,>=2.0.0->wandb) (2.8)
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/termcolor-1.1.0+computecanada-py3-none-any.whl
Requirement already satisfied: zipp>=0.3.2 in /cvmfs/soft.computecanada.ca/easybuild/software/2017/Core/scipy-stack/2019a/lib/python3.7/site-packages (from importlib-metadata->Click!=8.0.0,>=7.0->wandb) (0.3.3)
Installing collected packages: smmap, typing-extensions, termcolor, six, gitdb, yaspin, subprocess32, shortuuid, sentry-sdk, PyYAML, psutil, protobuf, promise, pathtools, GitPython, docker-pycreds, configparser, Click, wandb
  Attempting uninstall: six
    Found existing installation: six 1.12.0
    Not uninstalling six at /cvmfs/soft.computecanada.ca/easybuild/software/2017/Core/scipy-stack/2019a/lib/python3.7/site-packages, outside environment /localscratch/yinan.29351699.0/env
    Can't uninstall 'six'. No files were found to uninstall.
Successfully installed Click-8.0.4+computecanada GitPython-3.1.24+computecanada PyYAML-5.3.1+computecanada configparser-5.0.2+computecanada docker-pycreds-0.4.0+computecanada gitdb-4.0.9+computecanada pathtools-0.1.2+computecanada promise-2.3+computecanada protobuf-3.19.4+computecanada psutil-5.7.3+computecanada sentry-sdk-1.5.0+computecanada shortuuid-1.0.1+computecanada six-1.16.0+computecanada smmap-5.0.0+computecanada subprocess32-3.5.4+computecanada termcolor-1.1.0+computecanada typing-extensions-4.1.1+computecanada wandb-0.12.5+computecanada yaspin-2.1.0+computecanada
Looking in links: /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/nix/avx2, /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/nix/generic, /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic
ERROR: Could not find a version that satisfies the requirement sagemaker (from versions: none)
ERROR: No matching distribution found for sagemaker
Looking in links: /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/nix/avx2, /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/nix/generic, /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/torch-1.9.1+computecanada-cp37-cp37m-linux_x86_64.whl
Requirement already satisfied: typing-extensions in /localscratch/yinan.29351699.0/env/lib/python3.7/site-packages (from torch) (4.1.1+computecanada)
Installing collected packages: torch
Successfully installed torch-1.9.1+computecanada
Looking in links: /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/nix/avx2, /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/nix/generic, /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/transformers-2.5.1+computecanada-py3-none-any.whl
Requirement already satisfied: numpy in /cvmfs/soft.computecanada.ca/easybuild/software/2017/Core/scipy-stack/2019a/lib/python3.7/site-packages (from transformers==2.5.1+computecanada) (1.16.0)
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/filelock-3.4.2+computecanada-py3-none-any.whl
Requirement already satisfied: requests in /cvmfs/soft.computecanada.ca/easybuild/software/2017/Core/scipy-stack/2019a/lib/python3.7/site-packages (from transformers==2.5.1+computecanada) (2.21.0)
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/sacremoses-0.0.49+computecanada-py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/regex-2020.11.13+computecanada-cp37-cp37m-linux_x86_64.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/sentencepiece-0.1.91+computecanada-cp37-cp37m-linux_x86_64.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/boto3-1.21.14+computecanada-py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/tqdm-4.63.1+computecanada-py2.py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/tokenizers-0.5.2+computecanada-cp37-cp37m-linux_x86_64.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/botocore-1.24.14+computecanada-py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/s3transfer-0.5.1+computecanada-py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/jmespath-0.10.0+computecanada-py2.py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/urllib3-1.26.8+computecanada-py2.py3-none-any.whl
Requirement already satisfied: python-dateutil<3.0.0,>=2.1 in /cvmfs/soft.computecanada.ca/easybuild/software/2017/Core/scipy-stack/2019a/lib/python3.7/site-packages (from botocore<1.25.0,>=1.24.14->boto3->transformers==2.5.1+computecanada) (2.7.5)
Requirement already satisfied: six>=1.5 in /localscratch/yinan.29351699.0/env/lib/python3.7/site-packages (from python-dateutil<3.0.0,>=2.1->botocore<1.25.0,>=1.24.14->boto3->transformers==2.5.1+computecanada) (1.16.0+computecanada)
Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /cvmfs/soft.computecanada.ca/easybuild/software/2017/Core/scipy-stack/2019a/lib/python3.7/site-packages (from requests->transformers==2.5.1+computecanada) (3.0.4)
Requirement already satisfied: idna<2.9,>=2.5 in /cvmfs/soft.computecanada.ca/easybuild/software/2017/Core/scipy-stack/2019a/lib/python3.7/site-packages (from requests->transformers==2.5.1+computecanada) (2.8)
Requirement already satisfied: certifi>=2017.4.17 in /cvmfs/soft.computecanada.ca/easybuild/software/2017/Core/scipy-stack/2019a/lib/python3.7/site-packages (from requests->transformers==2.5.1+computecanada) (2018.11.29)
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/requests-2.27.1+computecanada-py2.py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/charset_normalizer-2.0.12+computecanada-py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/joblib-1.1.0+computecanada-py2.py3-none-any.whl
Requirement already satisfied: click in /localscratch/yinan.29351699.0/env/lib/python3.7/site-packages (from sacremoses->transformers==2.5.1+computecanada) (8.0.4+computecanada)
Requirement already satisfied: importlib-metadata in /cvmfs/soft.computecanada.ca/easybuild/software/2017/Core/scipy-stack/2019a/lib/python3.7/site-packages (from click->sacremoses->transformers==2.5.1+computecanada) (0.8)
Requirement already satisfied: zipp>=0.3.2 in /cvmfs/soft.computecanada.ca/easybuild/software/2017/Core/scipy-stack/2019a/lib/python3.7/site-packages (from importlib-metadata->click->sacremoses->transformers==2.5.1+computecanada) (0.3.3)
Installing collected packages: urllib3, jmespath, botocore, tqdm, s3transfer, regex, joblib, charset-normalizer, tokenizers, sentencepiece, sacremoses, requests, filelock, boto3, transformers
  Attempting uninstall: urllib3
    Found existing installation: urllib3 1.24.1
    Not uninstalling urllib3 at /cvmfs/soft.computecanada.ca/easybuild/software/2017/Core/scipy-stack/2019a/lib/python3.7/site-packages, outside environment /localscratch/yinan.29351699.0/env
    Can't uninstall 'urllib3'. No files were found to uninstall.
  Attempting uninstall: requests
    Found existing installation: requests 2.21.0
    Not uninstalling requests at /cvmfs/soft.computecanada.ca/easybuild/software/2017/Core/scipy-stack/2019a/lib/python3.7/site-packages, outside environment /localscratch/yinan.29351699.0/env
    Can't uninstall 'requests'. No files were found to uninstall.
Successfully installed boto3-1.21.14+computecanada botocore-1.24.14+computecanada charset-normalizer-2.0.12+computecanada filelock-3.4.2+computecanada jmespath-0.10.0+computecanada joblib-1.1.0+computecanada regex-2020.11.13+computecanada requests-2.27.1+computecanada s3transfer-0.5.1+computecanada sacremoses-0.0.49+computecanada sentencepiece-0.1.91+computecanada tokenizers-0.5.2+computecanada tqdm-4.63.1+computecanada transformers-2.5.1+computecanada urllib3-1.26.8+computecanada
Looking in links: /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/nix/avx2, /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/nix/generic, /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/tensorflow_gpu-2.3.0+computecanada-cp37-cp37m-linux_x86_64.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/opt_einsum-3.3.0+computecanada-py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/nix/generic/scipy-1.4.1+computecanada-cp37-cp37m-linux_x86_64.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/nix/avx2/h5py-2.10.0+computecanada-cp37-cp37m-linux_x86_64.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/absl_py-1.0.0+computecanada-py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/wrapt-1.11.2+computecanada-cp37-cp37m-linux_x86_64.whl
Requirement already satisfied: six>=1.12.0 in /localscratch/yinan.29351699.0/env/lib/python3.7/site-packages (from tensorflow_gpu==2.3.0+computecanada) (1.16.0+computecanada)
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/tensorboard-2.8.0+computecanada-py3-none-any.whl
Requirement already satisfied: numpy<1.19.0,>=1.16.0 in /cvmfs/soft.computecanada.ca/easybuild/software/2017/Core/scipy-stack/2019a/lib/python3.7/site-packages (from tensorflow_gpu==2.3.0+computecanada) (1.16.0)
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/google_pasta-0.2.0+computecanada-py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/tensorflow_estimator-2.3.0+computecanada-py2.py3-none-any.whl
Requirement already satisfied: protobuf>=3.9.2 in /localscratch/yinan.29351699.0/env/lib/python3.7/site-packages (from tensorflow_gpu==2.3.0+computecanada) (3.19.4+computecanada)
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/gast-0.3.3+computecanada-py3-none-any.whl
Requirement already satisfied: wheel>=0.26 in /localscratch/yinan.29351699.0/env/lib/python3.7/site-packages (from tensorflow_gpu==2.3.0+computecanada) (0.33.4)
Requirement already satisfied: termcolor>=1.1.0 in /localscratch/yinan.29351699.0/env/lib/python3.7/site-packages (from tensorflow_gpu==2.3.0+computecanada) (1.1.0+computecanada)
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/grpcio-1.38.0+computecanada-cp37-cp37m-linux_x86_64.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/Keras_Preprocessing-1.1.2+computecanada-py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/astunparse-1.6.3+computecanada-py2.py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/google_auth-2.3.3+computecanada-py2.py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/google_auth_oauthlib-0.4.6+computecanada-py2.py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/Werkzeug-2.0.3+computecanada-py3-none-any.whl
Requirement already satisfied: requests<3,>=2.21.0 in /localscratch/yinan.29351699.0/env/lib/python3.7/site-packages (from tensorboard<3,>=2.3.0->tensorflow_gpu==2.3.0+computecanada) (2.27.1+computecanada)
Requirement already satisfied: setuptools>=41.0.0 in /localscratch/yinan.29351699.0/env/lib/python3.7/site-packages (from tensorboard<3,>=2.3.0->tensorflow_gpu==2.3.0+computecanada) (41.0.1)
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/tensorboard_plugin_wit-1.8.0+computecanada-py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/tensorboard_data_server-0.6.1+computecanada-py3-none-linux_x86_64.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/Markdown-3.3.6+computecanada-py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/cachetools-4.2.4+computecanada-py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/pyasn1_modules-0.2.8+computecanada-py2.py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/rsa-4.8+computecanada-py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/requests_oauthlib-1.3.0+computecanada-py2.py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/importlib_metadata-4.10.1+computecanada-py3-none-any.whl
Requirement already satisfied: typing-extensions>=3.6.4 in /localscratch/yinan.29351699.0/env/lib/python3.7/site-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard<3,>=2.3.0->tensorflow_gpu==2.3.0+computecanada) (4.1.1+computecanada)
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/zipp-3.7.0+computecanada-py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/pyasn1-0.4.8+computecanada-py2.py3-none-any.whl
Requirement already satisfied: idna<4,>=2.5 in /cvmfs/soft.computecanada.ca/easybuild/software/2017/Core/scipy-stack/2019a/lib/python3.7/site-packages (from requests<3,>=2.21.0->tensorboard<3,>=2.3.0->tensorflow_gpu==2.3.0+computecanada) (2.8)
Requirement already satisfied: certifi>=2017.4.17 in /cvmfs/soft.computecanada.ca/easybuild/software/2017/Core/scipy-stack/2019a/lib/python3.7/site-packages (from requests<3,>=2.21.0->tensorboard<3,>=2.3.0->tensorflow_gpu==2.3.0+computecanada) (2018.11.29)
Requirement already satisfied: charset-normalizer~=2.0.0 in /localscratch/yinan.29351699.0/env/lib/python3.7/site-packages (from requests<3,>=2.21.0->tensorboard<3,>=2.3.0->tensorflow_gpu==2.3.0+computecanada) (2.0.12+computecanada)
Requirement already satisfied: urllib3<1.27,>=1.21.1 in /localscratch/yinan.29351699.0/env/lib/python3.7/site-packages (from requests<3,>=2.21.0->tensorboard<3,>=2.3.0->tensorflow_gpu==2.3.0+computecanada) (1.26.8+computecanada)
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/oauthlib-3.1.1+computecanada-py2.py3-none-any.whl
Installing collected packages: pyasn1, zipp, rsa, pyasn1-modules, oauthlib, cachetools, requests-oauthlib, importlib-metadata, google-auth, werkzeug, tensorboard-plugin-wit, tensorboard-data-server, markdown, grpcio, google-auth-oauthlib, absl-py, wrapt, tensorflow-estimator, tensorboard, scipy, opt-einsum, keras-preprocessing, h5py, google-pasta, gast, astunparse, tensorflow-gpu
  Attempting uninstall: pyasn1
    Found existing installation: pyasn1 0.4.3
    Not uninstalling pyasn1 at /cvmfs/soft.computecanada.ca/easybuild/software/2017/Core/scipy-stack/2019a/lib/python3.7/site-packages, outside environment /localscratch/yinan.29351699.0/env
    Can't uninstall 'pyasn1'. No files were found to uninstall.
  Attempting uninstall: zipp
    Found existing installation: zipp 0.3.3
    Not uninstalling zipp at /cvmfs/soft.computecanada.ca/easybuild/software/2017/Core/scipy-stack/2019a/lib/python3.7/site-packages, outside environment /localscratch/yinan.29351699.0/env
    Can't uninstall 'zipp'. No files were found to uninstall.
  Attempting uninstall: importlib-metadata
    Found existing installation: importlib-metadata 0.8
    Not uninstalling importlib-metadata at /cvmfs/soft.computecanada.ca/easybuild/software/2017/Core/scipy-stack/2019a/lib/python3.7/site-packages, outside environment /localscratch/yinan.29351699.0/env
    Can't uninstall 'importlib-metadata'. No files were found to uninstall.
  Attempting uninstall: scipy
    Found existing installation: scipy 1.2.0
    Not uninstalling scipy at /cvmfs/soft.computecanada.ca/easybuild/software/2017/Core/scipy-stack/2019a/lib/python3.7/site-packages, outside environment /localscratch/yinan.29351699.0/env
    Can't uninstall 'scipy'. No files were found to uninstall.
Successfully installed absl-py-1.0.0+computecanada astunparse-1.6.3+computecanada cachetools-4.2.4+computecanada gast-0.3.3+computecanada google-auth-2.3.3+computecanada google-auth-oauthlib-0.4.6+computecanada google-pasta-0.2.0+computecanada grpcio-1.38.0+computecanada h5py-2.10.0+computecanada importlib-metadata-4.10.1+computecanada keras-preprocessing-1.1.2+computecanada markdown-3.3.6+computecanada oauthlib-3.1.1+computecanada opt-einsum-3.3.0+computecanada pyasn1-0.4.8+computecanada pyasn1-modules-0.2.8+computecanada requests-oauthlib-1.3.0+computecanada rsa-4.8+computecanada scipy-1.4.1+computecanada tensorboard-2.8.0+computecanada tensorboard-data-server-0.6.1+computecanada tensorboard-plugin-wit-1.8.0+computecanada tensorflow-estimator-2.3.0+computecanada tensorflow-gpu-2.3.0+computecanada werkzeug-2.0.3+computecanada wrapt-1.11.2+computecanada zipp-3.7.0+computecanada
Looking in links: /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/nix/avx2, /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/nix/generic, /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/keras-2.8.0+computecanada-py2.py3-none-any.whl
Installing collected packages: Keras
Successfully installed Keras-2.8.0+computecanada
Looking in links: /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/nix/avx2, /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/nix/generic, /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/urllib3-1.26.7+computecanada-py2.py3-none-any.whl
Installing collected packages: urllib3
  Attempting uninstall: urllib3
    Found existing installation: urllib3 1.26.8+computecanada
    Uninstalling urllib3-1.26.8+computecanada:
      Successfully uninstalled urllib3-1.26.8+computecanada
Successfully installed urllib3-1.26.7+computecanada
Looking in links: /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/nix/avx2, /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/nix/generic, /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/nltk-3.7+computecanada-py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/nltk-3.6.5+computecanada-py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/nltk-3.6.3+computecanada-py3-none-any.whl
Requirement already satisfied: click in /localscratch/yinan.29351699.0/env/lib/python3.7/site-packages (from nltk) (8.0.4+computecanada)
Requirement already satisfied: regex in /localscratch/yinan.29351699.0/env/lib/python3.7/site-packages (from nltk) (2020.11.13+computecanada)
Requirement already satisfied: tqdm in /localscratch/yinan.29351699.0/env/lib/python3.7/site-packages (from nltk) (4.63.1+computecanada)
Requirement already satisfied: joblib in /localscratch/yinan.29351699.0/env/lib/python3.7/site-packages (from nltk) (1.1.0+computecanada)
Requirement already satisfied: importlib-metadata in /localscratch/yinan.29351699.0/env/lib/python3.7/site-packages (from click->nltk) (4.10.1+computecanada)
Requirement already satisfied: zipp>=0.5 in /localscratch/yinan.29351699.0/env/lib/python3.7/site-packages (from importlib-metadata->click->nltk) (3.7.0+computecanada)
Requirement already satisfied: typing-extensions>=3.6.4 in /localscratch/yinan.29351699.0/env/lib/python3.7/site-packages (from importlib-metadata->click->nltk) (4.1.1+computecanada)
Installing collected packages: nltk
Successfully installed nltk-3.6.3+computecanada
Looking in links: /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/nix/avx2, /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/nix/generic, /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/scikit_learn-0.22.1+computecanada-cp37-cp37m-linux_x86_64.whl
Requirement already satisfied: numpy>=1.11.0 in /cvmfs/soft.computecanada.ca/easybuild/software/2017/Core/scipy-stack/2019a/lib/python3.7/site-packages (from scikit-learn==0.22.1) (1.16.0)
Requirement already satisfied: joblib>=0.11 in /localscratch/yinan.29351699.0/env/lib/python3.7/site-packages (from scikit-learn==0.22.1) (1.1.0+computecanada)
Requirement already satisfied: scipy>=0.17.0 in /localscratch/yinan.29351699.0/env/lib/python3.7/site-packages (from scikit-learn==0.22.1) (1.4.1+computecanada)
Installing collected packages: scikit-learn
Successfully installed scikit-learn-0.22.1+computecanada
Looking in links: /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/nix/avx2, /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/nix/generic, /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic
Requirement already satisfied: tokenizers==0.5.2 in /localscratch/yinan.29351699.0/env/lib/python3.7/site-packages (0.5.2+computecanada)
wandb: Appending key for api.wandb.ai to your netrc file: /home/yinan/.netrc
Starting Task
2022-03-25 04:25:53.737288: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1
[nltk_data] Downloading package stopwords to /home/yinan/nltk_data...
[nltk_data]   Package stopwords is already up-to-date!
[nltk_data] Downloading package wordnet to /home/yinan/nltk_data...
[nltk_data]   Package wordnet is already up-to-date!
wandb: Currently logged in as: yinanazhou (use `wandb login --relogin` to force relogin)
wandb: wandb version 0.12.11 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
2022-03-25 04:26:10.061469: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1
wandb: Tracking run with wandb version 0.12.5
wandb: Syncing run curious-mountain-1
wandb: ⭐️ View project at https://wandb.ai/yinanazhou/xl_512_bs_8_lr_1e06_es_10_lc_True_nr_True_sr_False_stem_False_lemma_True_repeat_1_fold_1
wandb: 🚀 View run at https://wandb.ai/yinanazhou/xl_512_bs_8_lr_1e06_es_10_lc_True_nr_True_sr_False_stem_False_lemma_True_repeat_1_fold_1/runs/1ihbxzoy
wandb: Run data is saved locally in /project/6002780/yinan/Thesis_MER_Lyrics/lyric-emotion/wandb/run-20220325_042607-1ihbxzoy
wandb: Run `wandb offline` to turn off syncing.

Validation loss decreased (inf --> 1.439309).  Saving model ...
Validation loss decreased (1.439309 --> 1.419105).  Saving model ...
Validation loss decreased (1.419105 --> 1.402491).  Saving model ...
Validation loss decreased (1.402491 --> 1.389058).  Saving model ...
Validation loss decreased (1.389058 --> 1.378937).  Saving model ...
Validation loss decreased (1.378937 --> 1.370089).  Saving model ...
Validation loss decreased (1.370089 --> 1.363380).  Saving model ...
Validation loss decreased (1.363380 --> 1.357554).  Saving model ...
Validation loss decreased (1.357554 --> 1.351885).  Saving model ...
Validation loss decreased (1.351885 --> 1.346473).  Saving model ...
Validation loss decreased (1.346473 --> 1.340653).  Saving model ...
Validation loss decreased (1.340653 --> 1.335815).  Saving model ...
Validation loss decreased (1.335815 --> 1.330758).  Saving model ...
Validation loss decreased (1.330758 --> 1.325765).  Saving model ...
Validation loss decreased (1.325765 --> 1.320288).  Saving model ...
Validation loss decreased (1.320288 --> 1.316206).  Saving model ...
Validation loss decreased (1.316206 --> 1.310600).  Saving model ...
Validation loss decreased (1.310600 --> 1.304590).  Saving model ...
Validation loss decreased (1.304590 --> 1.299087).  Saving model ...
Validation loss decreased (1.299087 --> 1.293122).  Saving model ...
Validation loss decreased (1.293122 --> 1.287364).  Saving model ...
Validation loss decreased (1.287364 --> 1.280271).  Saving model ...
Validation loss decreased (1.280271 --> 1.276599).  Saving model ...
Validation loss decreased (1.276599 --> 1.269277).  Saving model ...
Validation loss decreased (1.269277 --> 1.263776).  Saving model ...
Validation loss decreased (1.263776 --> 1.259156).  Saving model ...
Validation loss decreased (1.259156 --> 1.252592).  Saving model ...
Validation loss decreased (1.252592 --> 1.248384).  Saving model ...
Validation loss decreased (1.248384 --> 1.244844).  Saving model ...
Validation loss decreased (1.244844 --> 1.243392).  Saving model ...
Validation loss decreased (1.243392 --> 1.240637).  Saving model ...
Validation loss decreased (1.240637 --> 1.235306).  Saving model ...
Validation loss decreased (1.235306 --> 1.234287).  Saving model ...
Validation loss decreased (1.234287 --> 1.228457).  Saving model ...
Validation loss decreased (1.228457 --> 1.225178).  Saving model ...
Validation loss decreased (1.225178 --> 1.218794).  Saving model ...
Validation loss decreased (1.218794 --> 1.213360).  Saving model ...
Validation loss decreased (1.213360 --> 1.211831).  Saving model ...
Validation loss decreased (1.211831 --> 1.207428).  Saving model ...
Validation loss decreased (1.207428 --> 1.205810).  Saving model ...
Validation loss decreased (1.205810 --> 1.198795).  Saving model ...
Validation loss decreased (1.198795 --> 1.194625).  Saving model ...
Validation loss decreased (1.194625 --> 1.191737).  Saving model ...
EarlyStopping counter: 1 out of 10.0
Validation loss decreased (1.191737 --> 1.186692).  Saving model ...
Validation loss decreased (1.186692 --> 1.184148).  Saving model ...
Validation loss decreased (1.184148 --> 1.182458).  Saving model ...
EarlyStopping counter: 1 out of 10.0
Validation loss decreased (1.182458 --> 1.176040).  Saving model ...
Validation loss decreased (1.176040 --> 1.176023).  Saving model ...
Validation loss decreased (1.176023 --> 1.169389).  Saving model ...
Validation loss decreased (1.169389 --> 1.166622).  Saving model ...
Validation loss decreased (1.166622 --> 1.166117).  Saving model ...
Validation loss decreased (1.166117 --> 1.163209).  Saving model ...
Validation loss decreased (1.163209 --> 1.163055).  Saving model ...
Validation loss decreased (1.163055 --> 1.157392).  Saving model ...
Validation loss decreased (1.157392 --> 1.151576).  Saving model ...
Validation loss decreased (1.151576 --> 1.147402).  Saving model ...
Validation loss decreased (1.147402 --> 1.141575).  Saving model ...
EarlyStopping counter: 1 out of 10.0
Validation loss decreased (1.141575 --> 1.139336).  Saving model ...
Validation loss decreased (1.139336 --> 1.137451).  Saving model ...
Validation loss decreased (1.137451 --> 1.132357).  Saving model ...
EarlyStopping counter: 1 out of 10.0
EarlyStopping counter: 2 out of 10.0
Validation loss decreased (1.132357 --> 1.128460).  Saving model ...
Validation loss decreased (1.128460 --> 1.125789).  Saving model ...
Validation loss decreased (1.125789 --> 1.119857).  Saving model ...
Validation loss decreased (1.119857 --> 1.119150).  Saving model ...
Validation loss decreased (1.119150 --> 1.117602).  Saving model ...
Validation loss decreased (1.117602 --> 1.110618).  Saving model ...
Validation loss decreased (1.110618 --> 1.109347).  Saving model ...
Validation loss decreased (1.109347 --> 1.108646).  Saving model ...
Validation loss decreased (1.108646 --> 1.105010).  Saving model ...
Validation loss decreased (1.105010 --> 1.101256).  Saving model ...
Validation loss decreased (1.101256 --> 1.100464).  Saving model ...
EarlyStopping counter: 1 out of 10.0
Validation loss decreased (1.100464 --> 1.095709).  Saving model ...
Validation loss decreased (1.095709 --> 1.090373).  Saving model ...
Validation loss decreased (1.090373 --> 1.087978).  Saving model ...
EarlyStopping counter: 1 out of 10.0
EarlyStopping counter: 2 out of 10.0
EarlyStopping counter: 3 out of 10.0
Validation loss decreased (1.087978 --> 1.085389).  Saving model ...
Validation loss decreased (1.085389 --> 1.082821).  Saving model ...
Validation loss decreased (1.082821 --> 1.078149).  Saving model ...
Validation loss decreased (1.078149 --> 1.073165).  Saving model ...
EarlyStopping counter: 1 out of 10.0
EarlyStopping counter: 2 out of 10.0
EarlyStopping counter: 3 out of 10.0
EarlyStopping counter: 4 out of 10.0
Validation loss decreased (1.073165 --> 1.072705).  Saving model ...
Validation loss decreased (1.072705 --> 1.070608).  Saving model ...
EarlyStopping counter: 1 out of 10.0
EarlyStopping counter: 2 out of 10.0
Validation loss decreased (1.070608 --> 1.068707).  Saving model ...
Validation loss decreased (1.068707 --> 1.068190).  Saving model ...
Validation loss decreased (1.068190 --> 1.060603).  Saving model ...
Validation loss decreased (1.060603 --> 1.060099).  Saving model ...
EarlyStopping counter: 1 out of 10.0
EarlyStopping counter: 2 out of 10.0
Validation loss decreased (1.060099 --> 1.055535).  Saving model ...
Validation loss decreased (1.055535 --> 1.054814).  Saving model ...
EarlyStopping counter: 1 out of 10.0
Validation loss decreased (1.054814 --> 1.053444).  Saving model ...
Validation loss decreased (1.053444 --> 1.050042).  Saving model ...
Validation loss decreased (1.050042 --> 1.049573).  Saving model ...
Validation loss decreased (1.049573 --> 1.046963).  Saving model ...
Validation loss decreased (1.046963 --> 1.044535).  Saving model ...
Validation loss decreased (1.044535 --> 1.041566).  Saving model ...
EarlyStopping counter: 1 out of 10.0
EarlyStopping counter: 2 out of 10.0
EarlyStopping counter: 3 out of 10.0
EarlyStopping counter: 4 out of 10.0
EarlyStopping counter: 5 out of 10.0
Validation loss decreased (1.041566 --> 1.040659).  Saving model ...
Validation loss decreased (1.040659 --> 1.036211).  Saving model ...
Validation loss decreased (1.036211 --> 1.034260).  Saving model ...
Validation loss decreased (1.034260 --> 1.032359).  Saving model ...
Validation loss decreased (1.032359 --> 1.029771).  Saving model ...
EarlyStopping counter: 1 out of 10.0
Validation loss decreased (1.029771 --> 1.028691).  Saving model ...
Validation loss decreased (1.028691 --> 1.025334).  Saving model ...
EarlyStopping counter: 1 out of 10.0
Validation loss decreased (1.025334 --> 1.024099).  Saving model ...
Validation loss decreased (1.024099 --> 1.022825).  Saving model ...
EarlyStopping counter: 1 out of 10.0
EarlyStopping counter: 2 out of 10.0
EarlyStopping counter: 3 out of 10.0
Validation loss decreased (1.022825 --> 1.022060).  Saving model ...
Validation loss decreased (1.022060 --> 1.021231).  Saving model ...
EarlyStopping counter: 1 out of 10.0
Validation loss decreased (1.021231 --> 1.018729).  Saving model ...
Validation loss decreased (1.018729 --> 1.017415).  Saving model ...
EarlyStopping counter: 1 out of 10.0
EarlyStopping counter: 2 out of 10.0
EarlyStopping counter: 3 out of 10.0
Validation loss decreased (1.017415 --> 1.014993).  Saving model ...
Validation loss decreased (1.014993 --> 1.014643).  Saving model ...
EarlyStopping counter: 1 out of 10.0
EarlyStopping counter: 2 out of 10.0
EarlyStopping counter: 3 out of 10.0
EarlyStopping counter: 4 out of 10.0
EarlyStopping counter: 5 out of 10.0
Validation loss decreased (1.014643 --> 1.011501).  Saving model ...
Validation loss decreased (1.011501 --> 1.010438).  Saving model ...
EarlyStopping counter: 1 out of 10.0
EarlyStopping counter: 2 out of 10.0
EarlyStopping counter: 3 out of 10.0
Validation loss decreased (1.010438 --> 1.009200).  Saving model ...
Validation loss decreased (1.009200 --> 1.006944).  Saving model ...
EarlyStopping counter: 1 out of 10.0
EarlyStopping counter: 2 out of 10.0
EarlyStopping counter: 3 out of 10.0
Validation loss decreased (1.006944 --> 1.006441).  Saving model ...
Validation loss decreased (1.006441 --> 1.002861).  Saving model ...
EarlyStopping counter: 1 out of 10.0
EarlyStopping counter: 2 out of 10.0
EarlyStopping counter: 3 out of 10.0
EarlyStopping counter: 4 out of 10.0
EarlyStopping counter: 5 out of 10.0
EarlyStopping counter: 6 out of 10.0
EarlyStopping counter: 7 out of 10.0
EarlyStopping counter: 8 out of 10.0
EarlyStopping counter: 9 out of 10.0
EarlyStopping counter: 10 out of 10.0
/localscratch/yinan.29351699.0/env/lib/python3.7/site-packages/torch/nn/functional.py:1794: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.
  warnings.warn("nn.functional.tanh is deprecated. Use torch.tanh instead.")
/localscratch/yinan.29351699.0/env/lib/python3.7/site-packages/transformers/optimization.py:155: UserWarning: This overload of add_ is deprecated:
	add_(Number alpha, Tensor other)
Consider using one of the following signatures instead:
	add_(Tensor other, *, Number alpha) (Triggered internally at  ../torch/csrc/utils/python_arg_parser.cpp:1025.)
  exp_avg.mul_(beta1).add_(1.0 - beta1, grad)
wandb: Waiting for W&B process to finish, PID 114079... (success).
wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: \ 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: | 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: / 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: \ 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: | 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: / 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: \ 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: | 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: / 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb:                                                                                
wandb: Run history:
wandb:     e_F1 ▁▂▄▄▄▅▅▅▅▆▆▆▆▆▆▆▆▆▇▇▇▇▇▇▇▇██████████████
wandb:   e_loss █▇▇▆▆▆▅▅▅▅▄▄▄▄▃▃▃▃▃▂▂▂▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁
wandb:     t_F1 ▁▂▂▃▃▄▄▄▄▅▅▅▅▅▆▆▅▆▅▆▇▆▇▇▇▇▇▇▇▇▇▇▇▇▇█████
wandb:   t_loss █▇█▇▇▇▆▆▆▅▅▅▄▅▄▄▄▄▄▃▃▃▃▃▂▂▂▂▂▂▂▁▂▂▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:     e_F1 57.96143
wandb:   e_loss 1.01214
wandb:     t_F1 74.90539
wandb:   t_loss 0.69772
wandb: 
wandb: Synced 4 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Synced curious-mountain-1: https://wandb.ai/yinanazhou/xl_512_bs_8_lr_1e06_es_10_lc_True_nr_True_sr_False_stem_False_lemma_True_repeat_1_fold_1/runs/1ihbxzoy
wandb: Find logs at: ./wandb/run-20220325_042607-1ihbxzoy/logs/debug.log
wandb: 

wandb: wandb version 0.12.11 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
2022-03-25 06:11:42.852110: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1
wandb: Tracking run with wandb version 0.12.5
wandb: Syncing run dry-armadillo-1
wandb: ⭐️ View project at https://wandb.ai/yinanazhou/xl_512_bs_8_lr_1e06_es_10_lc_True_nr_True_sr_False_stem_False_lemma_True_repeat_1_fold_2
wandb: 🚀 View run at https://wandb.ai/yinanazhou/xl_512_bs_8_lr_1e06_es_10_lc_True_nr_True_sr_False_stem_False_lemma_True_repeat_1_fold_2/runs/k775otqy
wandb: Run data is saved locally in /project/6002780/yinan/Thesis_MER_Lyrics/lyric-emotion/wandb/run-20220325_061140-k775otqy
wandb: Run `wandb offline` to turn off syncing.

Validation loss decreased (inf --> 1.514655).  Saving model ...
Validation loss decreased (1.514655 --> 1.467074).  Saving model ...
Validation loss decreased (1.467074 --> 1.437477).  Saving model ...
Validation loss decreased (1.437477 --> 1.420194).  Saving model ...
Validation loss decreased (1.420194 --> 1.408874).  Saving model ...
Validation loss decreased (1.408874 --> 1.401429).  Saving model ...
Validation loss decreased (1.401429 --> 1.396125).  Saving model ...
Validation loss decreased (1.396125 --> 1.391329).  Saving model ...
Validation loss decreased (1.391329 --> 1.386819).  Saving model ...
Validation loss decreased (1.386819 --> 1.382487).  Saving model ...
Validation loss decreased (1.382487 --> 1.378450).  Saving model ...
Validation loss decreased (1.378450 --> 1.372369).  Saving model ...
Validation loss decreased (1.372369 --> 1.367603).  Saving model ...
Validation loss decreased (1.367603 --> 1.363273).  Saving model ...
Validation loss decreased (1.363273 --> 1.358211).  Saving model ...
Validation loss decreased (1.358211 --> 1.353595).  Saving model ...
Validation loss decreased (1.353595 --> 1.348097).  Saving model ...
Validation loss decreased (1.348097 --> 1.343430).  Saving model ...
Validation loss decreased (1.343430 --> 1.338465).  Saving model ...
Validation loss decreased (1.338465 --> 1.333271).  Saving model ...
Validation loss decreased (1.333271 --> 1.328199).  Saving model ...
Validation loss decreased (1.328199 --> 1.322945).  Saving model ...
Validation loss decreased (1.322945 --> 1.317434).  Saving model ...
Validation loss decreased (1.317434 --> 1.312108).  Saving model ...
Validation loss decreased (1.312108 --> 1.306313).  Saving model ...
Validation loss decreased (1.306313 --> 1.300197).  Saving model ...
Validation loss decreased (1.300197 --> 1.294585).  Saving model ...
Validation loss decreased (1.294585 --> 1.288456).  Saving model ...
Validation loss decreased (1.288456 --> 1.282658).  Saving model ...
Validation loss decreased (1.282658 --> 1.276951).  Saving model ...
Validation loss decreased (1.276951 --> 1.271114).  Saving model ...
Validation loss decreased (1.271114 --> 1.265066).  Saving model ...
Validation loss decreased (1.265066 --> 1.259033).  Saving model ...
Validation loss decreased (1.259033 --> 1.251654).  Saving model ...
Validation loss decreased (1.251654 --> 1.245473).  Saving model ...
Validation loss decreased (1.245473 --> 1.239376).  Saving model ...
Validation loss decreased (1.239376 --> 1.233246).  Saving model ...
Validation loss decreased (1.233246 --> 1.227097).  Saving model ...
Validation loss decreased (1.227097 --> 1.221001).  Saving model ...
Validation loss decreased (1.221001 --> 1.214902).  Saving model ...
Validation loss decreased (1.214902 --> 1.208870).  Saving model ...
Validation loss decreased (1.208870 --> 1.201491).  Saving model ...
Validation loss decreased (1.201491 --> 1.194974).  Saving model ...
Validation loss decreased (1.194974 --> 1.187746).  Saving model ...
Validation loss decreased (1.187746 --> 1.180832).  Saving model ...
Validation loss decreased (1.180832 --> 1.173886).  Saving model ...
Validation loss decreased (1.173886 --> 1.167500).  Saving model ...
Validation loss decreased (1.167500 --> 1.160842).  Saving model ...
Validation loss decreased (1.160842 --> 1.154661).  Saving model ...
Validation loss decreased (1.154661 --> 1.148318).  Saving model ...
Validation loss decreased (1.148318 --> 1.142084).  Saving model ...
Validation loss decreased (1.142084 --> 1.135895).  Saving model ...
Validation loss decreased (1.135895 --> 1.129360).  Saving model ...
Validation loss decreased (1.129360 --> 1.123606).  Saving model ...
Validation loss decreased (1.123606 --> 1.117836).  Saving model ...
Validation loss decreased (1.117836 --> 1.111764).  Saving model ...
Validation loss decreased (1.111764 --> 1.106671).  Saving model ...
Validation loss decreased (1.106671 --> 1.100731).  Saving model ...
Validation loss decreased (1.100731 --> 1.095083).  Saving model ...
Validation loss decreased (1.095083 --> 1.089516).  Saving model ...
Validation loss decreased (1.089516 --> 1.084642).  Saving model ...
Validation loss decreased (1.084642 --> 1.079584).  Saving model ...
Validation loss decreased (1.079584 --> 1.073942).  Saving model ...
Validation loss decreased (1.073942 --> 1.068979).  Saving model ...
Validation loss decreased (1.068979 --> 1.064559).  Saving model ...
Validation loss decreased (1.064559 --> 1.060668).  Saving model ...
Validation loss decreased (1.060668 --> 1.057095).  Saving model ...
Validation loss decreased (1.057095 --> 1.052220).  Saving model ...
Validation loss decreased (1.052220 --> 1.047759).  Saving model ...
Validation loss decreased (1.047759 --> 1.043987).  Saving model ...
Validation loss decreased (1.043987 --> 1.039866).  Saving model ...
Validation loss decreased (1.039866 --> 1.035841).  Saving model ...
Validation loss decreased (1.035841 --> 1.031566).  Saving model ...
Validation loss decreased (1.031566 --> 1.027797).  Saving model ...
Validation loss decreased (1.027797 --> 1.024670).  Saving model ...
Validation loss decreased (1.024670 --> 1.021004).  Saving model ...
Validation loss decreased (1.021004 --> 1.017779).  Saving model ...
Validation loss decreased (1.017779 --> 1.014071).  Saving model ...
Validation loss decreased (1.014071 --> 1.010258).  Saving model ...
Validation loss decreased (1.010258 --> 1.007445).  Saving model ...
Validation loss decreased (1.007445 --> 1.003630).  Saving model ...
Validation loss decreased (1.003630 --> 1.000746).  Saving model ...
Validation loss decreased (1.000746 --> 0.997119).  Saving model ...
Validation loss decreased (0.997119 --> 0.994996).  Saving model ...
Validation loss decreased (0.994996 --> 0.991917).  Saving model ...
Validation loss decreased (0.991917 --> 0.989126).  Saving model ...
Validation loss decreased (0.989126 --> 0.986422).  Saving model ...
Validation loss decreased (0.986422 --> 0.983906).  Saving model ...
Validation loss decreased (0.983906 --> 0.980797).  Saving model ...
Validation loss decreased (0.980797 --> 0.978681).  Saving model ...
Validation loss decreased (0.978681 --> 0.976148).  Saving model ...
Validation loss decreased (0.976148 --> 0.973518).  Saving model ...
Validation loss decreased (0.973518 --> 0.971178).  Saving model ...
Validation loss decreased (0.971178 --> 0.969053).  Saving model ...
Validation loss decreased (0.969053 --> 0.967372).  Saving model ...
Validation loss decreased (0.967372 --> 0.965555).  Saving model ...
Validation loss decreased (0.965555 --> 0.963921).  Saving model ...
Validation loss decreased (0.963921 --> 0.962135).  Saving model ...
Validation loss decreased (0.962135 --> 0.960467).  Saving model ...
Validation loss decreased (0.960467 --> 0.958200).  Saving model ...
Validation loss decreased (0.958200 --> 0.956019).  Saving model ...
Validation loss decreased (0.956019 --> 0.953205).  Saving model ...
Validation loss decreased (0.953205 --> 0.952640).  Saving model ...
Validation loss decreased (0.952640 --> 0.950796).  Saving model ...
Validation loss decreased (0.950796 --> 0.948952).  Saving model ...
Validation loss decreased (0.948952 --> 0.947598).  Saving model ...
Validation loss decreased (0.947598 --> 0.946433).  Saving model ...
Validation loss decreased (0.946433 --> 0.944586).  Saving model ...
Validation loss decreased (0.944586 --> 0.944477).  Saving model ...
Validation loss decreased (0.944477 --> 0.942760).  Saving model ...
Validation loss decreased (0.942760 --> 0.940980).  Saving model ...
Validation loss decreased (0.940980 --> 0.940843).  Saving model ...
Validation loss decreased (0.940843 --> 0.940056).  Saving model ...
Validation loss decreased (0.940056 --> 0.938540).  Saving model ...
Validation loss decreased (0.938540 --> 0.938406).  Saving model ...
Validation loss decreased (0.938406 --> 0.937900).  Saving model ...
Validation loss decreased (0.937900 --> 0.936520).  Saving model ...
Validation loss decreased (0.936520 --> 0.935513).  Saving model ...
Validation loss decreased (0.935513 --> 0.934286).  Saving model ...
EarlyStopping counter: 1 out of 10.0
Validation loss decreased (0.934286 --> 0.934186).  Saving model ...
Validation loss decreased (0.934186 --> 0.931483).  Saving model ...
Validation loss decreased (0.931483 --> 0.931029).  Saving model ...
Validation loss decreased (0.931029 --> 0.928912).  Saving model ...
Validation loss decreased (0.928912 --> 0.928721).  Saving model ...
EarlyStopping counter: 1 out of 10.0
EarlyStopping counter: 2 out of 10.0
EarlyStopping counter: 3 out of 10.0
EarlyStopping counter: 4 out of 10.0
EarlyStopping counter: 5 out of 10.0
Validation loss decreased (0.928721 --> 0.927793).  Saving model ...
Validation loss decreased (0.927793 --> 0.927704).  Saving model ...
Validation loss decreased (0.927704 --> 0.927218).  Saving model ...
Validation loss decreased (0.927218 --> 0.927153).  Saving model ...
EarlyStopping counter: 1 out of 10.0
Validation loss decreased (0.927153 --> 0.926439).  Saving model ...
EarlyStopping counter: 1 out of 10.0
Validation loss decreased (0.926439 --> 0.925216).  Saving model ...
EarlyStopping counter: 1 out of 10.0
Validation loss decreased (0.925216 --> 0.924495).  Saving model ...
Validation loss decreased (0.924495 --> 0.924170).  Saving model ...
EarlyStopping counter: 1 out of 10.0
EarlyStopping counter: 2 out of 10.0
EarlyStopping counter: 3 out of 10.0
EarlyStopping counter: 4 out of 10.0
EarlyStopping counter: 5 out of 10.0
EarlyStopping counter: 6 out of 10.0
EarlyStopping counter: 7 out of 10.0
EarlyStopping counter: 8 out of 10.0
EarlyStopping counter: 9 out of 10.0
EarlyStopping counter: 10 out of 10.0
/localscratch/yinan.29351699.0/env/lib/python3.7/site-packages/torch/nn/functional.py:1794: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.
  warnings.warn("nn.functional.tanh is deprecated. Use torch.tanh instead.")
wandb: Waiting for W&B process to finish, PID 119719... (success).
wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: \ 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: | 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: / 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: \ 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: | 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: / 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: \ 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: | 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: / 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: \ 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: | 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: / 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: \ 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb:                                                                                
wandb: Run history:
wandb:     e_F1 ▁▂▃▄▄▄▅▅▅▅▅▆▆▆▆▇▇▇▇▇▇██▇████████████████
wandb:   e_loss █▇▇▇▇▆▆▆▅▅▅▅▄▄▄▃▃▃▃▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:     t_F1 ▁▂▂▃▃▃▃▄▄▄▄▅▅▅▆▆▆▆▆▆▆▆▆▆▇▇▇▇▇▇▇▇█▇▇█████
wandb:   t_loss █▇▇▇▇▇▆▆▆▆▆▅▅▅▅▄▄▄▄▄▄▃▄▃▃▃▃▂▂▂▂▂▂▂▂▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:     e_F1 61.82289
wandb:   e_loss 0.92695
wandb:     t_F1 75.64477
wandb:   t_loss 0.70478
wandb: 
wandb: Synced 4 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Synced dry-armadillo-1: https://wandb.ai/yinanazhou/xl_512_bs_8_lr_1e06_es_10_lc_True_nr_True_sr_False_stem_False_lemma_True_repeat_1_fold_2/runs/k775otqy
wandb: Find logs at: ./wandb/run-20220325_061140-k775otqy/logs/debug.log
wandb: 

wandb: wandb version 0.12.11 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
2022-03-25 07:51:30.977209: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1
wandb: Tracking run with wandb version 0.12.5
wandb: Syncing run pretty-night-1
wandb: ⭐️ View project at https://wandb.ai/yinanazhou/xl_512_bs_8_lr_1e06_es_10_lc_True_nr_True_sr_False_stem_False_lemma_True_repeat_2_fold_1
wandb: 🚀 View run at https://wandb.ai/yinanazhou/xl_512_bs_8_lr_1e06_es_10_lc_True_nr_True_sr_False_stem_False_lemma_True_repeat_2_fold_1/runs/2gqz71ta
wandb: Run data is saved locally in /project/6002780/yinan/Thesis_MER_Lyrics/lyric-emotion/wandb/run-20220325_075128-2gqz71ta
wandb: Run `wandb offline` to turn off syncing.

Validation loss decreased (inf --> 1.385689).  Saving model ...
Validation loss decreased (1.385689 --> 1.381368).  Saving model ...
Validation loss decreased (1.381368 --> 1.377325).  Saving model ...
Validation loss decreased (1.377325 --> 1.373660).  Saving model ...
Validation loss decreased (1.373660 --> 1.370218).  Saving model ...
Validation loss decreased (1.370218 --> 1.366500).  Saving model ...
Validation loss decreased (1.366500 --> 1.363000).  Saving model ...
Validation loss decreased (1.363000 --> 1.359619).  Saving model ...
Validation loss decreased (1.359619 --> 1.355707).  Saving model ...
Validation loss decreased (1.355707 --> 1.352033).  Saving model ...
Validation loss decreased (1.352033 --> 1.348650).  Saving model ...
Validation loss decreased (1.348650 --> 1.344659).  Saving model ...
Validation loss decreased (1.344659 --> 1.340215).  Saving model ...
Validation loss decreased (1.340215 --> 1.336123).  Saving model ...
Validation loss decreased (1.336123 --> 1.331637).  Saving model ...
Validation loss decreased (1.331637 --> 1.327366).  Saving model ...
Validation loss decreased (1.327366 --> 1.322509).  Saving model ...
Validation loss decreased (1.322509 --> 1.317978).  Saving model ...
Validation loss decreased (1.317978 --> 1.313084).  Saving model ...
Validation loss decreased (1.313084 --> 1.307853).  Saving model ...
Validation loss decreased (1.307853 --> 1.303227).  Saving model ...
Validation loss decreased (1.303227 --> 1.296780).  Saving model ...
Validation loss decreased (1.296780 --> 1.290725).  Saving model ...
Validation loss decreased (1.290725 --> 1.283675).  Saving model ...
Validation loss decreased (1.283675 --> 1.277311).  Saving model ...
Validation loss decreased (1.277311 --> 1.270868).  Saving model ...
Validation loss decreased (1.270868 --> 1.263649).  Saving model ...
Validation loss decreased (1.263649 --> 1.255936).  Saving model ...
Validation loss decreased (1.255936 --> 1.249837).  Saving model ...
Validation loss decreased (1.249837 --> 1.240327).  Saving model ...
Validation loss decreased (1.240327 --> 1.232604).  Saving model ...
Validation loss decreased (1.232604 --> 1.224600).  Saving model ...
Validation loss decreased (1.224600 --> 1.217157).  Saving model ...
Validation loss decreased (1.217157 --> 1.210006).  Saving model ...
Validation loss decreased (1.210006 --> 1.202482).  Saving model ...
Validation loss decreased (1.202482 --> 1.196174).  Saving model ...
Validation loss decreased (1.196174 --> 1.186877).  Saving model ...
Validation loss decreased (1.186877 --> 1.178752).  Saving model ...
Validation loss decreased (1.178752 --> 1.173576).  Saving model ...
Validation loss decreased (1.173576 --> 1.167361).  Saving model ...
Validation loss decreased (1.167361 --> 1.160916).  Saving model ...
Validation loss decreased (1.160916 --> 1.153606).  Saving model ...
Validation loss decreased (1.153606 --> 1.149534).  Saving model ...
Validation loss decreased (1.149534 --> 1.146645).  Saving model ...
Validation loss decreased (1.146645 --> 1.140806).  Saving model ...
Validation loss decreased (1.140806 --> 1.133002).  Saving model ...
Validation loss decreased (1.133002 --> 1.126930).  Saving model ...
Validation loss decreased (1.126930 --> 1.122601).  Saving model ...
Validation loss decreased (1.122601 --> 1.119330).  Saving model ...
Validation loss decreased (1.119330 --> 1.114345).  Saving model ...
Validation loss decreased (1.114345 --> 1.109463).  Saving model ...
Validation loss decreased (1.109463 --> 1.105442).  Saving model ...
Validation loss decreased (1.105442 --> 1.102020).  Saving model ...
Validation loss decreased (1.102020 --> 1.097035).  Saving model ...
Validation loss decreased (1.097035 --> 1.093834).  Saving model ...
Validation loss decreased (1.093834 --> 1.088381).  Saving model ...
Validation loss decreased (1.088381 --> 1.083659).  Saving model ...
Validation loss decreased (1.083659 --> 1.079578).  Saving model ...
Validation loss decreased (1.079578 --> 1.073910).  Saving model ...
Validation loss decreased (1.073910 --> 1.071193).  Saving model ...
Validation loss decreased (1.071193 --> 1.066347).  Saving model ...
Validation loss decreased (1.066347 --> 1.065597).  Saving model ...
Validation loss decreased (1.065597 --> 1.061048).  Saving model ...
Validation loss decreased (1.061048 --> 1.057717).  Saving model ...
Validation loss decreased (1.057717 --> 1.055545).  Saving model ...
Validation loss decreased (1.055545 --> 1.053809).  Saving model ...
Validation loss decreased (1.053809 --> 1.050898).  Saving model ...
Validation loss decreased (1.050898 --> 1.047187).  Saving model ...
Validation loss decreased (1.047187 --> 1.043157).  Saving model ...
Validation loss decreased (1.043157 --> 1.042351).  Saving model ...
Validation loss decreased (1.042351 --> 1.038212).  Saving model ...
Validation loss decreased (1.038212 --> 1.034810).  Saving model ...
Validation loss decreased (1.034810 --> 1.031910).  Saving model ...
Validation loss decreased (1.031910 --> 1.028414).  Saving model ...
Validation loss decreased (1.028414 --> 1.028180).  Saving model ...
Validation loss decreased (1.028180 --> 1.025998).  Saving model ...
Validation loss decreased (1.025998 --> 1.022664).  Saving model ...
Validation loss decreased (1.022664 --> 1.018622).  Saving model ...
Validation loss decreased (1.018622 --> 1.016264).  Saving model ...
EarlyStopping counter: 1 out of 10.0
Validation loss decreased (1.016264 --> 1.014708).  Saving model ...
Validation loss decreased (1.014708 --> 1.014098).  Saving model ...
Validation loss decreased (1.014098 --> 1.009914).  Saving model ...
Validation loss decreased (1.009914 --> 1.008364).  Saving model ...
Validation loss decreased (1.008364 --> 1.008146).  Saving model ...
Validation loss decreased (1.008146 --> 1.005053).  Saving model ...
Validation loss decreased (1.005053 --> 1.002380).  Saving model ...
Validation loss decreased (1.002380 --> 1.001931).  Saving model ...
Validation loss decreased (1.001931 --> 1.000749).  Saving model ...
Validation loss decreased (1.000749 --> 0.998882).  Saving model ...
Validation loss decreased (0.998882 --> 0.998342).  Saving model ...
Validation loss decreased (0.998342 --> 0.996113).  Saving model ...
Validation loss decreased (0.996113 --> 0.993626).  Saving model ...
Validation loss decreased (0.993626 --> 0.992941).  Saving model ...
EarlyStopping counter: 1 out of 10.0
Validation loss decreased (0.992941 --> 0.990635).  Saving model ...
Validation loss decreased (0.990635 --> 0.988961).  Saving model ...
EarlyStopping counter: 1 out of 10.0
EarlyStopping counter: 2 out of 10.0
Validation loss decreased (0.988961 --> 0.988693).  Saving model ...
Validation loss decreased (0.988693 --> 0.986476).  Saving model ...
Validation loss decreased (0.986476 --> 0.985272).  Saving model ...
Validation loss decreased (0.985272 --> 0.983784).  Saving model ...
Validation loss decreased (0.983784 --> 0.981952).  Saving model ...
Validation loss decreased (0.981952 --> 0.981451).  Saving model ...
EarlyStopping counter: 1 out of 10.0
Validation loss decreased (0.981451 --> 0.981210).  Saving model ...
Validation loss decreased (0.981210 --> 0.978062).  Saving model ...
EarlyStopping counter: 1 out of 10.0
Validation loss decreased (0.978062 --> 0.976233).  Saving model ...
EarlyStopping counter: 1 out of 10.0
EarlyStopping counter: 2 out of 10.0
Validation loss decreased (0.976233 --> 0.973710).  Saving model ...
Validation loss decreased (0.973710 --> 0.972590).  Saving model ...
Validation loss decreased (0.972590 --> 0.971778).  Saving model ...
EarlyStopping counter: 1 out of 10.0
Validation loss decreased (0.971778 --> 0.971387).  Saving model ...
EarlyStopping counter: 1 out of 10.0
EarlyStopping counter: 2 out of 10.0
Validation loss decreased (0.971387 --> 0.970267).  Saving model ...
Validation loss decreased (0.970267 --> 0.969340).  Saving model ...
Validation loss decreased (0.969340 --> 0.969258).  Saving model ...
EarlyStopping counter: 1 out of 10.0
Validation loss decreased (0.969258 --> 0.967082).  Saving model ...
EarlyStopping counter: 1 out of 10.0
EarlyStopping counter: 2 out of 10.0
EarlyStopping counter: 3 out of 10.0
EarlyStopping counter: 4 out of 10.0
EarlyStopping counter: 5 out of 10.0
EarlyStopping counter: 6 out of 10.0
EarlyStopping counter: 7 out of 10.0
EarlyStopping counter: 8 out of 10.0
EarlyStopping counter: 9 out of 10.0
Validation loss decreased (0.967082 --> 0.966608).  Saving model ...
EarlyStopping counter: 1 out of 10.0
EarlyStopping counter: 2 out of 10.0
EarlyStopping counter: 3 out of 10.0
EarlyStopping counter: 4 out of 10.0
EarlyStopping counter: 5 out of 10.0
EarlyStopping counter: 6 out of 10.0
EarlyStopping counter: 7 out of 10.0
EarlyStopping counter: 8 out of 10.0
EarlyStopping counter: 9 out of 10.0
EarlyStopping counter: 10 out of 10.0
/localscratch/yinan.29351699.0/env/lib/python3.7/site-packages/torch/nn/functional.py:1794: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.
  warnings.warn("nn.functional.tanh is deprecated. Use torch.tanh instead.")
wandb: Waiting for W&B process to finish, PID 125013... (success).
wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: \ 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: | 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: / 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: \ 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: | 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: / 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: \ 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: | 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: / 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb:                                                                                
wandb: Run history:
wandb:     e_F1 ▁▁▃▃▄▄▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇▇▇▇▇███████████████
wandb:   e_loss ███▇▇▇▇▆▆▅▅▄▄▄▃▃▃▃▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:     t_F1 ▁▂▃▂▃▃▄▄▄▄▅▅▅▅▆▆▆▆▆▆▆▆▇▆▇▇▇▇▇▇▇▇▇▇▇▇▇███
wandb:   t_loss ████▇▇▇▇▆▆▆▅▅▅▅▅▄▄▄▄▄▃▃▃▃▃▃▃▂▂▂▂▂▂▂▂▁▁▁▁
wandb: 
wandb: Run summary:
wandb:     e_F1 60.11576
wandb:   e_loss 0.96886
wandb:     t_F1 74.71919
wandb:   t_loss 0.6903
wandb: 
wandb: Synced 4 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Synced pretty-night-1: https://wandb.ai/yinanazhou/xl_512_bs_8_lr_1e06_es_10_lc_True_nr_True_sr_False_stem_False_lemma_True_repeat_2_fold_1/runs/2gqz71ta
wandb: Find logs at: ./wandb/run-20220325_075128-2gqz71ta/logs/debug.log
wandb: 

wandb: wandb version 0.12.11 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
2022-03-25 09:26:30.750482: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1
wandb: Tracking run with wandb version 0.12.5
wandb: Syncing run fast-field-1
wandb: ⭐️ View project at https://wandb.ai/yinanazhou/xl_512_bs_8_lr_1e06_es_10_lc_True_nr_True_sr_False_stem_False_lemma_True_repeat_2_fold_2
wandb: 🚀 View run at https://wandb.ai/yinanazhou/xl_512_bs_8_lr_1e06_es_10_lc_True_nr_True_sr_False_stem_False_lemma_True_repeat_2_fold_2/runs/2k4inyic
wandb: Run data is saved locally in /project/6002780/yinan/Thesis_MER_Lyrics/lyric-emotion/wandb/run-20220325_092628-2k4inyic
wandb: Run `wandb offline` to turn off syncing.

Validation loss decreased (inf --> 1.432464).  Saving model ...
Validation loss decreased (1.432464 --> 1.416254).  Saving model ...
Validation loss decreased (1.416254 --> 1.403130).  Saving model ...
Validation loss decreased (1.403130 --> 1.392654).  Saving model ...
Validation loss decreased (1.392654 --> 1.384380).  Saving model ...
Validation loss decreased (1.384380 --> 1.377539).  Saving model ...
Validation loss decreased (1.377539 --> 1.371541).  Saving model ...
Validation loss decreased (1.371541 --> 1.366337).  Saving model ...
Validation loss decreased (1.366337 --> 1.361171).  Saving model ...
Validation loss decreased (1.361171 --> 1.356314).  Saving model ...
Validation loss decreased (1.356314 --> 1.351759).  Saving model ...
Validation loss decreased (1.351759 --> 1.346980).  Saving model ...
Validation loss decreased (1.346980 --> 1.342234).  Saving model ...
Validation loss decreased (1.342234 --> 1.337410).  Saving model ...
Validation loss decreased (1.337410 --> 1.332898).  Saving model ...
Validation loss decreased (1.332898 --> 1.327681).  Saving model ...
Validation loss decreased (1.327681 --> 1.323039).  Saving model ...
Validation loss decreased (1.323039 --> 1.317577).  Saving model ...
Validation loss decreased (1.317577 --> 1.311676).  Saving model ...
Validation loss decreased (1.311676 --> 1.306240).  Saving model ...
Validation loss decreased (1.306240 --> 1.300624).  Saving model ...
Validation loss decreased (1.300624 --> 1.295429).  Saving model ...
Validation loss decreased (1.295429 --> 1.289145).  Saving model ...
Validation loss decreased (1.289145 --> 1.282546).  Saving model ...
Validation loss decreased (1.282546 --> 1.275974).  Saving model ...
Validation loss decreased (1.275974 --> 1.268874).  Saving model ...
Validation loss decreased (1.268874 --> 1.261589).  Saving model ...
Validation loss decreased (1.261589 --> 1.253974).  Saving model ...
Validation loss decreased (1.253974 --> 1.247361).  Saving model ...
Validation loss decreased (1.247361 --> 1.241313).  Saving model ...
Validation loss decreased (1.241313 --> 1.234760).  Saving model ...
Validation loss decreased (1.234760 --> 1.228466).  Saving model ...
Validation loss decreased (1.228466 --> 1.223178).  Saving model ...
Validation loss decreased (1.223178 --> 1.214462).  Saving model ...
Validation loss decreased (1.214462 --> 1.210071).  Saving model ...
Validation loss decreased (1.210071 --> 1.202713).  Saving model ...
Validation loss decreased (1.202713 --> 1.195238).  Saving model ...
Validation loss decreased (1.195238 --> 1.188404).  Saving model ...
Validation loss decreased (1.188404 --> 1.181564).  Saving model ...
Validation loss decreased (1.181564 --> 1.175233).  Saving model ...
Validation loss decreased (1.175233 --> 1.171203).  Saving model ...
Validation loss decreased (1.171203 --> 1.166474).  Saving model ...
Validation loss decreased (1.166474 --> 1.159972).  Saving model ...
Validation loss decreased (1.159972 --> 1.153749).  Saving model ...
Validation loss decreased (1.153749 --> 1.151713).  Saving model ...
Validation loss decreased (1.151713 --> 1.146600).  Saving model ...
Validation loss decreased (1.146600 --> 1.140349).  Saving model ...
Validation loss decreased (1.140349 --> 1.134338).  Saving model ...
Validation loss decreased (1.134338 --> 1.129933).  Saving model ...
Validation loss decreased (1.129933 --> 1.125765).  Saving model ...
Validation loss decreased (1.125765 --> 1.119506).  Saving model ...
Validation loss decreased (1.119506 --> 1.117100).  Saving model ...
Validation loss decreased (1.117100 --> 1.113458).  Saving model ...
Validation loss decreased (1.113458 --> 1.110111).  Saving model ...
Validation loss decreased (1.110111 --> 1.103674).  Saving model ...
Validation loss decreased (1.103674 --> 1.100047).  Saving model ...
Validation loss decreased (1.100047 --> 1.098041).  Saving model ...
Validation loss decreased (1.098041 --> 1.097548).  Saving model ...
Validation loss decreased (1.097548 --> 1.093406).  Saving model ...
Validation loss decreased (1.093406 --> 1.090247).  Saving model ...
Validation loss decreased (1.090247 --> 1.082993).  Saving model ...
Validation loss decreased (1.082993 --> 1.078045).  Saving model ...
Validation loss decreased (1.078045 --> 1.074308).  Saving model ...
Validation loss decreased (1.074308 --> 1.069308).  Saving model ...
Validation loss decreased (1.069308 --> 1.067497).  Saving model ...
Validation loss decreased (1.067497 --> 1.064798).  Saving model ...
Validation loss decreased (1.064798 --> 1.061748).  Saving model ...
Validation loss decreased (1.061748 --> 1.056405).  Saving model ...
Validation loss decreased (1.056405 --> 1.051624).  Saving model ...
EarlyStopping counter: 1 out of 10.0
Validation loss decreased (1.051624 --> 1.047549).  Saving model ...
Validation loss decreased (1.047549 --> 1.046209).  Saving model ...
Validation loss decreased (1.046209 --> 1.045963).  Saving model ...
Validation loss decreased (1.045963 --> 1.043135).  Saving model ...
Validation loss decreased (1.043135 --> 1.039684).  Saving model ...
Validation loss decreased (1.039684 --> 1.034707).  Saving model ...
Validation loss decreased (1.034707 --> 1.034601).  Saving model ...
Validation loss decreased (1.034601 --> 1.032131).  Saving model ...
Validation loss decreased (1.032131 --> 1.027581).  Saving model ...
Validation loss decreased (1.027581 --> 1.025511).  Saving model ...
Validation loss decreased (1.025511 --> 1.023692).  Saving model ...
Validation loss decreased (1.023692 --> 1.022499).  Saving model ...
Validation loss decreased (1.022499 --> 1.020347).  Saving model ...
EarlyStopping counter: 1 out of 10.0
Validation loss decreased (1.020347 --> 1.015135).  Saving model ...
Validation loss decreased (1.015135 --> 1.013450).  Saving model ...
Validation loss decreased (1.013450 --> 1.010367).  Saving model ...
Validation loss decreased (1.010367 --> 1.005953).  Saving model ...
Validation loss decreased (1.005953 --> 1.005853).  Saving model ...
EarlyStopping counter: 1 out of 10.0
Validation loss decreased (1.005853 --> 1.003251).  Saving model ...
Validation loss decreased (1.003251 --> 1.001466).  Saving model ...
Validation loss decreased (1.001466 --> 0.997705).  Saving model ...
Validation loss decreased (0.997705 --> 0.996810).  Saving model ...
Validation loss decreased (0.996810 --> 0.992913).  Saving model ...
Validation loss decreased (0.992913 --> 0.990600).  Saving model ...
Validation loss decreased (0.990600 --> 0.990412).  Saving model ...
Validation loss decreased (0.990412 --> 0.988077).  Saving model ...
Validation loss decreased (0.988077 --> 0.984861).  Saving model ...
Validation loss decreased (0.984861 --> 0.983954).  Saving model ...
Validation loss decreased (0.983954 --> 0.983656).  Saving model ...
EarlyStopping counter: 1 out of 10.0
Validation loss decreased (0.983656 --> 0.983229).  Saving model ...
Validation loss decreased (0.983229 --> 0.979698).  Saving model ...
Validation loss decreased (0.979698 --> 0.977188).  Saving model ...
Validation loss decreased (0.977188 --> 0.976594).  Saving model ...
Validation loss decreased (0.976594 --> 0.973408).  Saving model ...
EarlyStopping counter: 1 out of 10.0
EarlyStopping counter: 2 out of 10.0
EarlyStopping counter: 3 out of 10.0
Validation loss decreased (0.973408 --> 0.970893).  Saving model ...
Validation loss decreased (0.970893 --> 0.970209).  Saving model ...
Validation loss decreased (0.970209 --> 0.966601).  Saving model ...
Validation loss decreased (0.966601 --> 0.963127).  Saving model ...
EarlyStopping counter: 1 out of 10.0
Validation loss decreased (0.963127 --> 0.961961).  Saving model ...
EarlyStopping counter: 1 out of 10.0
Validation loss decreased (0.961961 --> 0.958560).  Saving model ...
EarlyStopping counter: 1 out of 10.0
EarlyStopping counter: 2 out of 10.0
EarlyStopping counter: 3 out of 10.0
EarlyStopping counter: 4 out of 10.0
Validation loss decreased (0.958560 --> 0.957727).  Saving model ...
Validation loss decreased (0.957727 --> 0.954081).  Saving model ...
EarlyStopping counter: 1 out of 10.0
EarlyStopping counter: 2 out of 10.0
Validation loss decreased (0.954081 --> 0.953364).  Saving model ...
Validation loss decreased (0.953364 --> 0.952346).  Saving model ...
EarlyStopping counter: 1 out of 10.0
EarlyStopping counter: 2 out of 10.0
Validation loss decreased (0.952346 --> 0.950839).  Saving model ...
Validation loss decreased (0.950839 --> 0.950776).  Saving model ...
Validation loss decreased (0.950776 --> 0.947317).  Saving model ...
EarlyStopping counter: 1 out of 10.0
EarlyStopping counter: 2 out of 10.0
Validation loss decreased (0.947317 --> 0.945101).  Saving model ...
Validation loss decreased (0.945101 --> 0.944797).  Saving model ...
Validation loss decreased (0.944797 --> 0.943495).  Saving model ...
Validation loss decreased (0.943495 --> 0.942538).  Saving model ...
EarlyStopping counter: 1 out of 10.0
EarlyStopping counter: 2 out of 10.0
Validation loss decreased (0.942538 --> 0.941291).  Saving model ...
EarlyStopping counter: 1 out of 10.0
EarlyStopping counter: 2 out of 10.0
EarlyStopping counter: 3 out of 10.0
EarlyStopping counter: 4 out of 10.0
EarlyStopping counter: 5 out of 10.0
Validation loss decreased (0.941291 --> 0.939566).  Saving model ...
EarlyStopping counter: 1 out of 10.0
EarlyStopping counter: 2 out of 10.0
EarlyStopping counter: 3 out of 10.0
EarlyStopping counter: 4 out of 10.0
EarlyStopping counter: 5 out of 10.0
Validation loss decreased (0.939566 --> 0.939099).  Saving model ...
EarlyStopping counter: 1 out of 10.0
Validation loss decreased (0.939099 --> 0.938312).  Saving model ...
EarlyStopping counter: 1 out of 10.0
EarlyStopping counter: 2 out of 10.0
EarlyStopping counter: 3 out of 10.0
EarlyStopping counter: 4 out of 10.0
EarlyStopping counter: 5 out of 10.0
EarlyStopping counter: 6 out of 10.0
EarlyStopping counter: 7 out of 10.0
EarlyStopping counter: 8 out of 10.0
EarlyStopping counter: 9 out of 10.0
EarlyStopping counter: 10 out of 10.0
/localscratch/yinan.29351699.0/env/lib/python3.7/site-packages/torch/nn/functional.py:1794: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.
  warnings.warn("nn.functional.tanh is deprecated. Use torch.tanh instead.")
wandb: Waiting for W&B process to finish, PID 130101... (success).
wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: \ 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: | 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: / 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: \ 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: | 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: / 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: \ 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: | 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: / 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb:                                                                                
wandb: Run history:
wandb:     e_F1 ▁▂▃▄▅▅▅▅▅▆▆▆▆▆▆▇▇▇▇▇▇▇▇▇▇▇▇█████████████
wandb:   e_loss █▇▇▇▇▆▆▅▅▅▄▄▄▃▃▃▃▃▂▂▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:     t_F1 ▁▂▃▃▂▄▄▄▅▅▅▅▅▅▅▆▆▆▆▆▆▆▆▆▆▇▇▇▇▇▇▇█▇▇█████
wandb:   t_loss ██▇▇▇▇▇▆▆▆▆▅▅▅▅▄▄▄▄▄▄▄▃▃▃▃▃▃▂▂▂▂▂▂▂▂▂▁▂▁
wandb: 
wandb: Run summary:
wandb:     e_F1 61.04926
wandb:   e_loss 0.9441
wandb:     t_F1 73.49322
wandb:   t_loss 0.69375
wandb: 
wandb: Synced 4 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Synced fast-field-1: https://wandb.ai/yinanazhou/xl_512_bs_8_lr_1e06_es_10_lc_True_nr_True_sr_False_stem_False_lemma_True_repeat_2_fold_2/runs/2k4inyic
wandb: Find logs at: ./wandb/run-20220325_092628-2k4inyic/logs/debug.log
wandb: 

wandb: wandb version 0.12.11 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
2022-03-25 11:13:43.964374: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1
wandb: Tracking run with wandb version 0.12.5
wandb: Syncing run fearless-dawn-1
wandb: ⭐️ View project at https://wandb.ai/yinanazhou/xl_512_bs_8_lr_1e06_es_10_lc_True_nr_True_sr_False_stem_False_lemma_True_repeat_3_fold_1
wandb: 🚀 View run at https://wandb.ai/yinanazhou/xl_512_bs_8_lr_1e06_es_10_lc_True_nr_True_sr_False_stem_False_lemma_True_repeat_3_fold_1/runs/2tpi7ac7
wandb: Run data is saved locally in /project/6002780/yinan/Thesis_MER_Lyrics/lyric-emotion/wandb/run-20220325_111341-2tpi7ac7
wandb: Run `wandb offline` to turn off syncing.

Validation loss decreased (inf --> 1.423581).  Saving model ...
Validation loss decreased (1.423581 --> 1.406871).  Saving model ...
Validation loss decreased (1.406871 --> 1.394557).  Saving model ...
Validation loss decreased (1.394557 --> 1.385171).  Saving model ...
Validation loss decreased (1.385171 --> 1.378357).  Saving model ...
Validation loss decreased (1.378357 --> 1.371963).  Saving model ...
Validation loss decreased (1.371963 --> 1.366275).  Saving model ...
Validation loss decreased (1.366275 --> 1.361572).  Saving model ...
Validation loss decreased (1.361572 --> 1.357140).  Saving model ...
Validation loss decreased (1.357140 --> 1.353117).  Saving model ...
Validation loss decreased (1.353117 --> 1.349061).  Saving model ...
Validation loss decreased (1.349061 --> 1.345532).  Saving model ...
Validation loss decreased (1.345532 --> 1.341498).  Saving model ...
Validation loss decreased (1.341498 --> 1.338065).  Saving model ...
Validation loss decreased (1.338065 --> 1.334012).  Saving model ...
Validation loss decreased (1.334012 --> 1.330113).  Saving model ...
Validation loss decreased (1.330113 --> 1.325483).  Saving model ...
Validation loss decreased (1.325483 --> 1.321413).  Saving model ...
Validation loss decreased (1.321413 --> 1.317368).  Saving model ...
Validation loss decreased (1.317368 --> 1.313251).  Saving model ...
Validation loss decreased (1.313251 --> 1.308619).  Saving model ...
Validation loss decreased (1.308619 --> 1.304123).  Saving model ...
Validation loss decreased (1.304123 --> 1.298799).  Saving model ...
Validation loss decreased (1.298799 --> 1.293395).  Saving model ...
Validation loss decreased (1.293395 --> 1.289209).  Saving model ...
Validation loss decreased (1.289209 --> 1.283814).  Saving model ...
Validation loss decreased (1.283814 --> 1.277603).  Saving model ...
Validation loss decreased (1.277603 --> 1.271079).  Saving model ...
Validation loss decreased (1.271079 --> 1.265843).  Saving model ...
Validation loss decreased (1.265843 --> 1.259991).  Saving model ...
Validation loss decreased (1.259991 --> 1.253034).  Saving model ...
Validation loss decreased (1.253034 --> 1.245795).  Saving model ...
Validation loss decreased (1.245795 --> 1.239530).  Saving model ...
Validation loss decreased (1.239530 --> 1.233614).  Saving model ...
Validation loss decreased (1.233614 --> 1.229633).  Saving model ...
Validation loss decreased (1.229633 --> 1.223451).  Saving model ...
Validation loss decreased (1.223451 --> 1.218158).  Saving model ...
Validation loss decreased (1.218158 --> 1.212328).  Saving model ...
Validation loss decreased (1.212328 --> 1.205660).  Saving model ...
Validation loss decreased (1.205660 --> 1.198335).  Saving model ...
Validation loss decreased (1.198335 --> 1.195426).  Saving model ...
Validation loss decreased (1.195426 --> 1.192561).  Saving model ...
Validation loss decreased (1.192561 --> 1.187653).  Saving model ...
Validation loss decreased (1.187653 --> 1.182486).  Saving model ...
Validation loss decreased (1.182486 --> 1.181223).  Saving model ...
Validation loss decreased (1.181223 --> 1.177899).  Saving model ...
Validation loss decreased (1.177899 --> 1.172396).  Saving model ...
Validation loss decreased (1.172396 --> 1.165967).  Saving model ...
Validation loss decreased (1.165967 --> 1.161141).  Saving model ...
Validation loss decreased (1.161141 --> 1.158366).  Saving model ...
Validation loss decreased (1.158366 --> 1.152336).  Saving model ...
Validation loss decreased (1.152336 --> 1.150752).  Saving model ...
EarlyStopping counter: 1 out of 10.0
Validation loss decreased (1.150752 --> 1.146655).  Saving model ...
Validation loss decreased (1.146655 --> 1.142338).  Saving model ...
Validation loss decreased (1.142338 --> 1.139507).  Saving model ...
Validation loss decreased (1.139507 --> 1.137776).  Saving model ...
Validation loss decreased (1.137776 --> 1.134527).  Saving model ...
Validation loss decreased (1.134527 --> 1.132756).  Saving model ...
Validation loss decreased (1.132756 --> 1.130897).  Saving model ...
Validation loss decreased (1.130897 --> 1.126789).  Saving model ...
Validation loss decreased (1.126789 --> 1.126270).  Saving model ...
Validation loss decreased (1.126270 --> 1.122843).  Saving model ...
Validation loss decreased (1.122843 --> 1.115727).  Saving model ...
Validation loss decreased (1.115727 --> 1.110697).  Saving model ...
Validation loss decreased (1.110697 --> 1.108035).  Saving model ...
Validation loss decreased (1.108035 --> 1.104630).  Saving model ...
Validation loss decreased (1.104630 --> 1.102334).  Saving model ...
Validation loss decreased (1.102334 --> 1.100410).  Saving model ...
Validation loss decreased (1.100410 --> 1.097977).  Saving model ...
EarlyStopping counter: 1 out of 10.0
Validation loss decreased (1.097977 --> 1.096126).  Saving model ...
Validation loss decreased (1.096126 --> 1.093029).  Saving model ...
Validation loss decreased (1.093029 --> 1.090635).  Saving model ...
Validation loss decreased (1.090635 --> 1.088168).  Saving model ...
Validation loss decreased (1.088168 --> 1.081681).  Saving model ...
Validation loss decreased (1.081681 --> 1.080128).  Saving model ...
Validation loss decreased (1.080128 --> 1.079202).  Saving model ...
Validation loss decreased (1.079202 --> 1.077353).  Saving model ...
Validation loss decreased (1.077353 --> 1.074462).  Saving model ...
Validation loss decreased (1.074462 --> 1.070490).  Saving model ...
Validation loss decreased (1.070490 --> 1.067415).  Saving model ...
Validation loss decreased (1.067415 --> 1.062555).  Saving model ...
Validation loss decreased (1.062555 --> 1.062365).  Saving model ...
EarlyStopping counter: 1 out of 10.0
EarlyStopping counter: 2 out of 10.0
Validation loss decreased (1.062365 --> 1.059917).  Saving model ...
Validation loss decreased (1.059917 --> 1.056645).  Saving model ...
Validation loss decreased (1.056645 --> 1.053146).  Saving model ...
Validation loss decreased (1.053146 --> 1.051729).  Saving model ...
Validation loss decreased (1.051729 --> 1.047503).  Saving model ...
Validation loss decreased (1.047503 --> 1.043531).  Saving model ...
EarlyStopping counter: 1 out of 10.0
Validation loss decreased (1.043531 --> 1.042540).  Saving model ...
Validation loss decreased (1.042540 --> 1.036504).  Saving model ...
Validation loss decreased (1.036504 --> 1.035466).  Saving model ...
Validation loss decreased (1.035466 --> 1.031861).  Saving model ...
EarlyStopping counter: 1 out of 10.0
EarlyStopping counter: 2 out of 10.0
Validation loss decreased (1.031861 --> 1.030628).  Saving model ...
Validation loss decreased (1.030628 --> 1.026062).  Saving model ...
Validation loss decreased (1.026062 --> 1.025132).  Saving model ...
Validation loss decreased (1.025132 --> 1.023913).  Saving model ...
Validation loss decreased (1.023913 --> 1.022171).  Saving model ...
Validation loss decreased (1.022171 --> 1.021432).  Saving model ...
Validation loss decreased (1.021432 --> 1.020010).  Saving model ...
EarlyStopping counter: 1 out of 10.0
EarlyStopping counter: 2 out of 10.0
Validation loss decreased (1.020010 --> 1.017645).  Saving model ...
Validation loss decreased (1.017645 --> 1.016283).  Saving model ...
Validation loss decreased (1.016283 --> 1.014571).  Saving model ...
Validation loss decreased (1.014571 --> 1.008908).  Saving model ...
EarlyStopping counter: 1 out of 10.0
EarlyStopping counter: 2 out of 10.0
EarlyStopping counter: 3 out of 10.0
EarlyStopping counter: 4 out of 10.0
EarlyStopping counter: 5 out of 10.0
Validation loss decreased (1.008908 --> 1.008057).  Saving model ...
Validation loss decreased (1.008057 --> 1.003984).  Saving model ...
Validation loss decreased (1.003984 --> 1.002527).  Saving model ...
Validation loss decreased (1.002527 --> 0.999718).  Saving model ...
Validation loss decreased (0.999718 --> 0.995359).  Saving model ...
EarlyStopping counter: 1 out of 10.0
EarlyStopping counter: 2 out of 10.0
EarlyStopping counter: 3 out of 10.0
EarlyStopping counter: 4 out of 10.0
EarlyStopping counter: 5 out of 10.0
Validation loss decreased (0.995359 --> 0.994772).  Saving model ...
Validation loss decreased (0.994772 --> 0.994733).  Saving model ...
Validation loss decreased (0.994733 --> 0.993491).  Saving model ...
EarlyStopping counter: 1 out of 10.0
EarlyStopping counter: 2 out of 10.0
EarlyStopping counter: 3 out of 10.0
EarlyStopping counter: 4 out of 10.0
EarlyStopping counter: 5 out of 10.0
EarlyStopping counter: 6 out of 10.0
EarlyStopping counter: 7 out of 10.0
EarlyStopping counter: 8 out of 10.0
EarlyStopping counter: 9 out of 10.0
EarlyStopping counter: 10 out of 10.0
/localscratch/yinan.29351699.0/env/lib/python3.7/site-packages/torch/nn/functional.py:1794: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.
  warnings.warn("nn.functional.tanh is deprecated. Use torch.tanh instead.")
wandb: Waiting for W&B process to finish, PID 135817... (success).
wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: \ 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: | 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: / 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: \ 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: | 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: / 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: \ 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: | 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: / 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb:                                                                                
wandb: Run history:
wandb:     e_F1 ▁▁▃▅▅▅▅▆▆▆▆▇▇▇▇▇▇▇▇▇▇▇▇█████████████████
wandb:   e_loss ██▇▇▇▇▆▆▆▅▅▄▄▄▄▄▃▃▃▃▃▂▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁
wandb:     t_F1 ▁▁▂▂▃▃▄▄▄▄▄▅▅▅▅▅▆▆▆▆▆▇▆▆▆▇▇▇▇▇█▇▇▇██████
wandb:   t_loss ███▇▇▇▇▇▆▆▆▅▅▅▅▅▄▄▄▄▄▃▄▃▃▃▃▃▃▂▂▂▂▂▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:     e_F1 57.72852
wandb:   e_loss 0.99528
wandb:     t_F1 72.30422
wandb:   t_loss 0.75451
wandb: 
wandb: Synced 4 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Synced fearless-dawn-1: https://wandb.ai/yinanazhou/xl_512_bs_8_lr_1e06_es_10_lc_True_nr_True_sr_False_stem_False_lemma_True_repeat_3_fold_1/runs/2tpi7ac7
wandb: Find logs at: ./wandb/run-20220325_111341-2tpi7ac7/logs/debug.log
wandb: 

wandb: wandb version 0.12.11 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
2022-03-25 12:43:22.576911: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1
wandb: Tracking run with wandb version 0.12.5
wandb: Syncing run prime-plasma-1
wandb: ⭐️ View project at https://wandb.ai/yinanazhou/xl_512_bs_8_lr_1e06_es_10_lc_True_nr_True_sr_False_stem_False_lemma_True_repeat_3_fold_2
wandb: 🚀 View run at https://wandb.ai/yinanazhou/xl_512_bs_8_lr_1e06_es_10_lc_True_nr_True_sr_False_stem_False_lemma_True_repeat_3_fold_2/runs/22qxlduz
wandb: Run data is saved locally in /project/6002780/yinan/Thesis_MER_Lyrics/lyric-emotion/wandb/run-20220325_124320-22qxlduz
wandb: Run `wandb offline` to turn off syncing.

Validation loss decreased (inf --> 1.428447).  Saving model ...
Validation loss decreased (1.428447 --> 1.412835).  Saving model ...
Validation loss decreased (1.412835 --> 1.400225).  Saving model ...
Validation loss decreased (1.400225 --> 1.390961).  Saving model ...
Validation loss decreased (1.390961 --> 1.384172).  Saving model ...
Validation loss decreased (1.384172 --> 1.377949).  Saving model ...
Validation loss decreased (1.377949 --> 1.372983).  Saving model ...
Validation loss decreased (1.372983 --> 1.368580).  Saving model ...
Validation loss decreased (1.368580 --> 1.363987).  Saving model ...
Validation loss decreased (1.363987 --> 1.359596).  Saving model ...
Validation loss decreased (1.359596 --> 1.355310).  Saving model ...
Validation loss decreased (1.355310 --> 1.351523).  Saving model ...
Validation loss decreased (1.351523 --> 1.347501).  Saving model ...
Validation loss decreased (1.347501 --> 1.343116).  Saving model ...
Validation loss decreased (1.343116 --> 1.338357).  Saving model ...
Validation loss decreased (1.338357 --> 1.333718).  Saving model ...
Validation loss decreased (1.333718 --> 1.328616).  Saving model ...
Validation loss decreased (1.328616 --> 1.323701).  Saving model ...
Validation loss decreased (1.323701 --> 1.318381).  Saving model ...
Validation loss decreased (1.318381 --> 1.312817).  Saving model ...
Validation loss decreased (1.312817 --> 1.306886).  Saving model ...
Validation loss decreased (1.306886 --> 1.300756).  Saving model ...
Validation loss decreased (1.300756 --> 1.293945).  Saving model ...
Validation loss decreased (1.293945 --> 1.286723).  Saving model ...
Validation loss decreased (1.286723 --> 1.280157).  Saving model ...
Validation loss decreased (1.280157 --> 1.273155).  Saving model ...
Validation loss decreased (1.273155 --> 1.265973).  Saving model ...
Validation loss decreased (1.265973 --> 1.258770).  Saving model ...
Validation loss decreased (1.258770 --> 1.251285).  Saving model ...
Validation loss decreased (1.251285 --> 1.242133).  Saving model ...
Validation loss decreased (1.242133 --> 1.232687).  Saving model ...
Validation loss decreased (1.232687 --> 1.224575).  Saving model ...
Validation loss decreased (1.224575 --> 1.215680).  Saving model ...
Validation loss decreased (1.215680 --> 1.206995).  Saving model ...
Validation loss decreased (1.206995 --> 1.199522).  Saving model ...
Validation loss decreased (1.199522 --> 1.190698).  Saving model ...
Validation loss decreased (1.190698 --> 1.181480).  Saving model ...
Validation loss decreased (1.181480 --> 1.176312).  Saving model ...
Validation loss decreased (1.176312 --> 1.167776).  Saving model ...
Validation loss decreased (1.167776 --> 1.159919).  Saving model ...
Validation loss decreased (1.159919 --> 1.154605).  Saving model ...
Validation loss decreased (1.154605 --> 1.147785).  Saving model ...
Validation loss decreased (1.147785 --> 1.142545).  Saving model ...
Validation loss decreased (1.142545 --> 1.136869).  Saving model ...
Validation loss decreased (1.136869 --> 1.130338).  Saving model ...
Validation loss decreased (1.130338 --> 1.124290).  Saving model ...
Validation loss decreased (1.124290 --> 1.118742).  Saving model ...
Validation loss decreased (1.118742 --> 1.112922).  Saving model ...
Validation loss decreased (1.112922 --> 1.108698).  Saving model ...
Validation loss decreased (1.108698 --> 1.105288).  Saving model ...
Validation loss decreased (1.105288 --> 1.099177).  Saving model ...
Validation loss decreased (1.099177 --> 1.093427).  Saving model ...
Validation loss decreased (1.093427 --> 1.089276).  Saving model ...
Validation loss decreased (1.089276 --> 1.085820).  Saving model ...
Validation loss decreased (1.085820 --> 1.079770).  Saving model ...
Validation loss decreased (1.079770 --> 1.075598).  Saving model ...
Validation loss decreased (1.075598 --> 1.070099).  Saving model ...
Validation loss decreased (1.070099 --> 1.065877).  Saving model ...
Validation loss decreased (1.065877 --> 1.063011).  Saving model ...
Validation loss decreased (1.063011 --> 1.059567).  Saving model ...
Validation loss decreased (1.059567 --> 1.057636).  Saving model ...
Validation loss decreased (1.057636 --> 1.053509).  Saving model ...
Validation loss decreased (1.053509 --> 1.048462).  Saving model ...
Validation loss decreased (1.048462 --> 1.043852).  Saving model ...
Validation loss decreased (1.043852 --> 1.040606).  Saving model ...
Validation loss decreased (1.040606 --> 1.037609).  Saving model ...
Validation loss decreased (1.037609 --> 1.034449).  Saving model ...
Validation loss decreased (1.034449 --> 1.030525).  Saving model ...
Validation loss decreased (1.030525 --> 1.027670).  Saving model ...
Validation loss decreased (1.027670 --> 1.024248).  Saving model ...
Validation loss decreased (1.024248 --> 1.021915).  Saving model ...
Validation loss decreased (1.021915 --> 1.019829).  Saving model ...
Validation loss decreased (1.019829 --> 1.015208).  Saving model ...
Validation loss decreased (1.015208 --> 1.012128).  Saving model ...
Validation loss decreased (1.012128 --> 1.010934).  Saving model ...
Validation loss decreased (1.010934 --> 1.007645).  Saving model ...
Validation loss decreased (1.007645 --> 1.005680).  Saving model ...
Validation loss decreased (1.005680 --> 1.002055).  Saving model ...
Validation loss decreased (1.002055 --> 0.998418).  Saving model ...
Validation loss decreased (0.998418 --> 0.994859).  Saving model ...
Validation loss decreased (0.994859 --> 0.992720).  Saving model ...
Validation loss decreased (0.992720 --> 0.991247).  Saving model ...
Validation loss decreased (0.991247 --> 0.986798).  Saving model ...
Validation loss decreased (0.986798 --> 0.985384).  Saving model ...
Validation loss decreased (0.985384 --> 0.984498).  Saving model ...
Validation loss decreased (0.984498 --> 0.981612).  Saving model ...
Validation loss decreased (0.981612 --> 0.978514).  Saving model ...
Validation loss decreased (0.978514 --> 0.975840).  Saving model ...
Validation loss decreased (0.975840 --> 0.973647).  Saving model ...
Validation loss decreased (0.973647 --> 0.970866).  Saving model ...
Validation loss decreased (0.970866 --> 0.967374).  Saving model ...
Validation loss decreased (0.967374 --> 0.965791).  Saving model ...
Validation loss decreased (0.965791 --> 0.964450).  Saving model ...
Validation loss decreased (0.964450 --> 0.962427).  Saving model ...
Validation loss decreased (0.962427 --> 0.959732).  Saving model ...
Validation loss decreased (0.959732 --> 0.958087).  Saving model ...
Validation loss decreased (0.958087 --> 0.954741).  Saving model ...
Validation loss decreased (0.954741 --> 0.952780).  Saving model ...
Validation loss decreased (0.952780 --> 0.951075).  Saving model ...
Validation loss decreased (0.951075 --> 0.949931).  Saving model ...
Validation loss decreased (0.949931 --> 0.946915).  Saving model ...
Validation loss decreased (0.946915 --> 0.946073).  Saving model ...
Validation loss decreased (0.946073 --> 0.944028).  Saving model ...
Validation loss decreased (0.944028 --> 0.941139).  Saving model ...
Validation loss decreased (0.941139 --> 0.940679).  Saving model ...
Validation loss decreased (0.940679 --> 0.939148).  Saving model ...
Validation loss decreased (0.939148 --> 0.939040).  Saving model ...
Validation loss decreased (0.939040 --> 0.937001).  Saving model ...
Validation loss decreased (0.937001 --> 0.936400).  Saving model ...
Validation loss decreased (0.936400 --> 0.934533).  Saving model ...
Validation loss decreased (0.934533 --> 0.932462).  Saving model ...
Validation loss decreased (0.932462 --> 0.930434).  Saving model ...
Validation loss decreased (0.930434 --> 0.929756).  Saving model ...
Validation loss decreased (0.929756 --> 0.929052).  Saving model ...
Validation loss decreased (0.929052 --> 0.927616).  Saving model ...
Validation loss decreased (0.927616 --> 0.926407).  Saving model ...
EarlyStopping counter: 1 out of 10.0
Validation loss decreased (0.926407 --> 0.926091).  Saving model ...
Validation loss decreased (0.926091 --> 0.924546).  Saving model ...
Validation loss decreased (0.924546 --> 0.923235).  Saving model ...
Validation loss decreased (0.923235 --> 0.921576).  Saving model ...
Validation loss decreased (0.921576 --> 0.920474).  Saving model ...
Validation loss decreased (0.920474 --> 0.920202).  Saving model ...
Validation loss decreased (0.920202 --> 0.918737).  Saving model ...
Validation loss decreased (0.918737 --> 0.917711).  Saving model ...
Validation loss decreased (0.917711 --> 0.917179).  Saving model ...
Validation loss decreased (0.917179 --> 0.916782).  Saving model ...
Validation loss decreased (0.916782 --> 0.915483).  Saving model ...
Validation loss decreased (0.915483 --> 0.914978).  Saving model ...
EarlyStopping counter: 1 out of 10.0
EarlyStopping counter: 2 out of 10.0
Validation loss decreased (0.914978 --> 0.912773).  Saving model ...
Validation loss decreased (0.912773 --> 0.912631).  Saving model ...
Validation loss decreased (0.912631 --> 0.910456).  Saving model ...
Validation loss decreased (0.910456 --> 0.909552).  Saving model ...
Validation loss decreased (0.909552 --> 0.909155).  Saving model ...
Validation loss decreased (0.909155 --> 0.907760).  Saving model ...
Validation loss decreased (0.907760 --> 0.907576).  Saving model ...
Validation loss decreased (0.907576 --> 0.906410).  Saving model ...
Validation loss decreased (0.906410 --> 0.905652).  Saving model ...
EarlyStopping counter: 1 out of 10.0
Validation loss decreased (0.905652 --> 0.904565).  Saving model ...
Validation loss decreased (0.904565 --> 0.903762).  Saving model ...
EarlyStopping counter: 1 out of 10.0
EarlyStopping counter: 2 out of 10.0
EarlyStopping counter: 3 out of 10.0
EarlyStopping counter: 4 out of 10.0
EarlyStopping counter: 5 out of 10.0
EarlyStopping counter: 6 out of 10.0
EarlyStopping counter: 7 out of 10.0
EarlyStopping counter: 8 out of 10.0
EarlyStopping counter: 9 out of 10.0
EarlyStopping counter: 10 out of 10.0
/localscratch/yinan.29351699.0/env/lib/python3.7/site-packages/torch/nn/functional.py:1794: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.
  warnings.warn("nn.functional.tanh is deprecated. Use torch.tanh instead.")
wandb: Waiting for W&B process to finish, PID 140635... (success).
wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: \ 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: | 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: / 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: \ 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: | 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: / 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: \ 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: | 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: / 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: \ 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: | 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: / 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb:                                                                                
wandb: Run history:
wandb:     e_F1 ▁▁▃▄▅▅▅▆▆▆▆▆▇▇▇▇▇▇▇▇▇▇▇▇▇███████████████
wandb:   e_loss ██▇▇▇▇▆▆▅▅▅▄▄▄▄▃▃▃▃▂▂▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁
wandb:     t_F1 ▁▂▂▃▃▄▄▄▅▅▅▅▅▆▅▆▆▆▆▇▇▆▆▇▇▇▇▇▇███▇▇██████
wandb:   t_loss ███▇▇▇▇▆▆▆▆▅▅▅▅▄▄▄▄▄▃▃▃▃▃▃▂▃▂▂▂▂▂▂▂▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:     e_F1 64.75332
wandb:   e_loss 0.90405
wandb:     t_F1 71.05856
wandb:   t_loss 0.73228
wandb: 
wandb: Synced 4 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Synced prime-plasma-1: https://wandb.ai/yinanazhou/xl_512_bs_8_lr_1e06_es_10_lc_True_nr_True_sr_False_stem_False_lemma_True_repeat_3_fold_2/runs/22qxlduz
wandb: Find logs at: ./wandb/run-20220325_124320-22qxlduz/logs/debug.log
wandb: 

wandb: wandb version 0.12.11 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
2022-03-25 14:22:23.626058: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1
wandb: Tracking run with wandb version 0.12.5
wandb: Syncing run lemon-pine-1
wandb: ⭐️ View project at https://wandb.ai/yinanazhou/xl_512_bs_8_lr_1e06_es_10_lc_True_nr_True_sr_False_stem_False_lemma_True_repeat_4_fold_1
wandb: 🚀 View run at https://wandb.ai/yinanazhou/xl_512_bs_8_lr_1e06_es_10_lc_True_nr_True_sr_False_stem_False_lemma_True_repeat_4_fold_1/runs/3u7bgfk7
wandb: Run data is saved locally in /project/6002780/yinan/Thesis_MER_Lyrics/lyric-emotion/wandb/run-20220325_142221-3u7bgfk7
wandb: Run `wandb offline` to turn off syncing.

Validation loss decreased (inf --> 1.560594).  Saving model ...
Validation loss decreased (1.560594 --> 1.523379).  Saving model ...
Validation loss decreased (1.523379 --> 1.491511).  Saving model ...
Validation loss decreased (1.491511 --> 1.461946).  Saving model ...
Validation loss decreased (1.461946 --> 1.436914).  Saving model ...
Validation loss decreased (1.436914 --> 1.414346).  Saving model ...
Validation loss decreased (1.414346 --> 1.395060).  Saving model ...
Validation loss decreased (1.395060 --> 1.379960).  Saving model ...
Validation loss decreased (1.379960 --> 1.367436).  Saving model ...
Validation loss decreased (1.367436 --> 1.358641).  Saving model ...
Validation loss decreased (1.358641 --> 1.350265).  Saving model ...
Validation loss decreased (1.350265 --> 1.342672).  Saving model ...
Validation loss decreased (1.342672 --> 1.335556).  Saving model ...
Validation loss decreased (1.335556 --> 1.329200).  Saving model ...
Validation loss decreased (1.329200 --> 1.323627).  Saving model ...
Validation loss decreased (1.323627 --> 1.317522).  Saving model ...
Validation loss decreased (1.317522 --> 1.311519).  Saving model ...
Validation loss decreased (1.311519 --> 1.305792).  Saving model ...
Validation loss decreased (1.305792 --> 1.300289).  Saving model ...
Validation loss decreased (1.300289 --> 1.294605).  Saving model ...
Validation loss decreased (1.294605 --> 1.289078).  Saving model ...
Validation loss decreased (1.289078 --> 1.283039).  Saving model ...
Validation loss decreased (1.283039 --> 1.277344).  Saving model ...
Validation loss decreased (1.277344 --> 1.271969).  Saving model ...
Validation loss decreased (1.271969 --> 1.265964).  Saving model ...
Validation loss decreased (1.265964 --> 1.260180).  Saving model ...
Validation loss decreased (1.260180 --> 1.253898).  Saving model ...
Validation loss decreased (1.253898 --> 1.247951).  Saving model ...
Validation loss decreased (1.247951 --> 1.242176).  Saving model ...
Validation loss decreased (1.242176 --> 1.236621).  Saving model ...
Validation loss decreased (1.236621 --> 1.230330).  Saving model ...
Validation loss decreased (1.230330 --> 1.225238).  Saving model ...
Validation loss decreased (1.225238 --> 1.219374).  Saving model ...
Validation loss decreased (1.219374 --> 1.213785).  Saving model ...
Validation loss decreased (1.213785 --> 1.207756).  Saving model ...
Validation loss decreased (1.207756 --> 1.201936).  Saving model ...
Validation loss decreased (1.201936 --> 1.196289).  Saving model ...
Validation loss decreased (1.196289 --> 1.191021).  Saving model ...
Validation loss decreased (1.191021 --> 1.185002).  Saving model ...
Validation loss decreased (1.185002 --> 1.180274).  Saving model ...
Validation loss decreased (1.180274 --> 1.176173).  Saving model ...
Validation loss decreased (1.176173 --> 1.171487).  Saving model ...
Validation loss decreased (1.171487 --> 1.168607).  Saving model ...
Validation loss decreased (1.168607 --> 1.163453).  Saving model ...
Validation loss decreased (1.163453 --> 1.157985).  Saving model ...
Validation loss decreased (1.157985 --> 1.153292).  Saving model ...
Validation loss decreased (1.153292 --> 1.147776).  Saving model ...
Validation loss decreased (1.147776 --> 1.142921).  Saving model ...
Validation loss decreased (1.142921 --> 1.138378).  Saving model ...
Validation loss decreased (1.138378 --> 1.135611).  Saving model ...
Validation loss decreased (1.135611 --> 1.131859).  Saving model ...
Validation loss decreased (1.131859 --> 1.126183).  Saving model ...
Validation loss decreased (1.126183 --> 1.122723).  Saving model ...
Validation loss decreased (1.122723 --> 1.118700).  Saving model ...
Validation loss decreased (1.118700 --> 1.116172).  Saving model ...
Validation loss decreased (1.116172 --> 1.110744).  Saving model ...
Validation loss decreased (1.110744 --> 1.106978).  Saving model ...
Validation loss decreased (1.106978 --> 1.103250).  Saving model ...
Validation loss decreased (1.103250 --> 1.099876).  Saving model ...
Validation loss decreased (1.099876 --> 1.096001).  Saving model ...
Validation loss decreased (1.096001 --> 1.093287).  Saving model ...
Validation loss decreased (1.093287 --> 1.089582).  Saving model ...
Validation loss decreased (1.089582 --> 1.086459).  Saving model ...
Validation loss decreased (1.086459 --> 1.083310).  Saving model ...
Validation loss decreased (1.083310 --> 1.079295).  Saving model ...
Validation loss decreased (1.079295 --> 1.076821).  Saving model ...
Validation loss decreased (1.076821 --> 1.074273).  Saving model ...
Validation loss decreased (1.074273 --> 1.072365).  Saving model ...
Validation loss decreased (1.072365 --> 1.067903).  Saving model ...
Validation loss decreased (1.067903 --> 1.066448).  Saving model ...
Validation loss decreased (1.066448 --> 1.063115).  Saving model ...
Validation loss decreased (1.063115 --> 1.060518).  Saving model ...
Validation loss decreased (1.060518 --> 1.057313).  Saving model ...
Validation loss decreased (1.057313 --> 1.054719).  Saving model ...
Validation loss decreased (1.054719 --> 1.052033).  Saving model ...
Validation loss decreased (1.052033 --> 1.050070).  Saving model ...
Validation loss decreased (1.050070 --> 1.048008).  Saving model ...
Validation loss decreased (1.048008 --> 1.045645).  Saving model ...
Validation loss decreased (1.045645 --> 1.043482).  Saving model ...
Validation loss decreased (1.043482 --> 1.041884).  Saving model ...
Validation loss decreased (1.041884 --> 1.039283).  Saving model ...
Validation loss decreased (1.039283 --> 1.038720).  Saving model ...
Validation loss decreased (1.038720 --> 1.037115).  Saving model ...
Validation loss decreased (1.037115 --> 1.033894).  Saving model ...
Validation loss decreased (1.033894 --> 1.032180).  Saving model ...
Validation loss decreased (1.032180 --> 1.031401).  Saving model ...
Validation loss decreased (1.031401 --> 1.030046).  Saving model ...
Validation loss decreased (1.030046 --> 1.027156).  Saving model ...
Validation loss decreased (1.027156 --> 1.024798).  Saving model ...
Validation loss decreased (1.024798 --> 1.022300).  Saving model ...
Validation loss decreased (1.022300 --> 1.019822).  Saving model ...
Validation loss decreased (1.019822 --> 1.019007).  Saving model ...
Validation loss decreased (1.019007 --> 1.016186).  Saving model ...
Validation loss decreased (1.016186 --> 1.014408).  Saving model ...
EarlyStopping counter: 1 out of 10.0
Validation loss decreased (1.014408 --> 1.014123).  Saving model ...
Validation loss decreased (1.014123 --> 1.012939).  Saving model ...
Validation loss decreased (1.012939 --> 1.012336).  Saving model ...
Validation loss decreased (1.012336 --> 1.009351).  Saving model ...
Validation loss decreased (1.009351 --> 1.008027).  Saving model ...
Validation loss decreased (1.008027 --> 1.006428).  Saving model ...
Validation loss decreased (1.006428 --> 1.005663).  Saving model ...
Validation loss decreased (1.005663 --> 1.004211).  Saving model ...
Validation loss decreased (1.004211 --> 1.001990).  Saving model ...
Validation loss decreased (1.001990 --> 1.000658).  Saving model ...
Validation loss decreased (1.000658 --> 0.998089).  Saving model ...
Validation loss decreased (0.998089 --> 0.997239).  Saving model ...
Validation loss decreased (0.997239 --> 0.995865).  Saving model ...
Validation loss decreased (0.995865 --> 0.994721).  Saving model ...
Validation loss decreased (0.994721 --> 0.994229).  Saving model ...
Validation loss decreased (0.994229 --> 0.992446).  Saving model ...
Validation loss decreased (0.992446 --> 0.991740).  Saving model ...
Validation loss decreased (0.991740 --> 0.990613).  Saving model ...
Validation loss decreased (0.990613 --> 0.988542).  Saving model ...
Validation loss decreased (0.988542 --> 0.988201).  Saving model ...
Validation loss decreased (0.988201 --> 0.987079).  Saving model ...
Validation loss decreased (0.987079 --> 0.985900).  Saving model ...
EarlyStopping counter: 1 out of 10.0
Validation loss decreased (0.985900 --> 0.985267).  Saving model ...
Validation loss decreased (0.985267 --> 0.982607).  Saving model ...
Validation loss decreased (0.982607 --> 0.982309).  Saving model ...
Validation loss decreased (0.982309 --> 0.981926).  Saving model ...
Validation loss decreased (0.981926 --> 0.981839).  Saving model ...
Validation loss decreased (0.981839 --> 0.981719).  Saving model ...
Validation loss decreased (0.981719 --> 0.980108).  Saving model ...
Validation loss decreased (0.980108 --> 0.977025).  Saving model ...
Validation loss decreased (0.977025 --> 0.975278).  Saving model ...
Validation loss decreased (0.975278 --> 0.974429).  Saving model ...
EarlyStopping counter: 1 out of 10.0
Validation loss decreased (0.974429 --> 0.974261).  Saving model ...
Validation loss decreased (0.974261 --> 0.973837).  Saving model ...
Validation loss decreased (0.973837 --> 0.973518).  Saving model ...
Validation loss decreased (0.973518 --> 0.971898).  Saving model ...
EarlyStopping counter: 1 out of 10.0
EarlyStopping counter: 2 out of 10.0
EarlyStopping counter: 3 out of 10.0
EarlyStopping counter: 4 out of 10.0
EarlyStopping counter: 5 out of 10.0
Validation loss decreased (0.971898 --> 0.971808).  Saving model ...
Validation loss decreased (0.971808 --> 0.969607).  Saving model ...
Validation loss decreased (0.969607 --> 0.968799).  Saving model ...
EarlyStopping counter: 1 out of 10.0
Validation loss decreased (0.968799 --> 0.965614).  Saving model ...
EarlyStopping counter: 1 out of 10.0
EarlyStopping counter: 2 out of 10.0
EarlyStopping counter: 3 out of 10.0
Validation loss decreased (0.965614 --> 0.965478).  Saving model ...
Validation loss decreased (0.965478 --> 0.964977).  Saving model ...
Validation loss decreased (0.964977 --> 0.964271).  Saving model ...
Validation loss decreased (0.964271 --> 0.964101).  Saving model ...
EarlyStopping counter: 1 out of 10.0
EarlyStopping counter: 2 out of 10.0
EarlyStopping counter: 3 out of 10.0
EarlyStopping counter: 4 out of 10.0
EarlyStopping counter: 5 out of 10.0
EarlyStopping counter: 6 out of 10.0
EarlyStopping counter: 7 out of 10.0
EarlyStopping counter: 8 out of 10.0
EarlyStopping counter: 9 out of 10.0
EarlyStopping counter: 10 out of 10.0
/localscratch/yinan.29351699.0/env/lib/python3.7/site-packages/torch/nn/functional.py:1794: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.
  warnings.warn("nn.functional.tanh is deprecated. Use torch.tanh instead.")
wandb: Waiting for W&B process to finish, PID 145912... (success).
wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: \ 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: | 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: / 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: \ 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: | 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: / 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: \ 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: | 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: / 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: \ 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb:                                                                                
wandb: Run history:
wandb:     e_F1 ▁▂▃▄▅▅▆▆▆▆▆▆▆▇▇▇▇▇▇▇▇▇▇█████████████████
wandb:   e_loss █▇▆▆▅▅▅▄▄▄▄▃▃▃▃▃▂▂▂▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:     t_F1 ▁▁▁▂▃▂▃▃▄▄▅▅▅▅▅▅▅▆▆▆▆▆▇▇▆▆▇▇▇▇▇▇▇▇▇█▇███
wandb:   t_loss █▇▇▇▆▆▆▆▅▅▅▅▅▄▄▄▄▄▄▃▃▃▃▃▃▃▂▂▂▂▂▂▂▂▂▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:     e_F1 58.88756
wandb:   e_loss 0.96682
wandb:     t_F1 73.49508
wandb:   t_loss 0.70144
wandb: 
wandb: Synced 4 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Synced lemon-pine-1: https://wandb.ai/yinanazhou/xl_512_bs_8_lr_1e06_es_10_lc_True_nr_True_sr_False_stem_False_lemma_True_repeat_4_fold_1/runs/3u7bgfk7
wandb: Find logs at: ./wandb/run-20220325_142221-3u7bgfk7/logs/debug.log
wandb: 

wandb: wandb version 0.12.11 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
2022-03-25 16:02:38.314423: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1
wandb: Tracking run with wandb version 0.12.5
wandb: Syncing run neat-resonance-1
wandb: ⭐️ View project at https://wandb.ai/yinanazhou/xl_512_bs_8_lr_1e06_es_10_lc_True_nr_True_sr_False_stem_False_lemma_True_repeat_4_fold_2
wandb: 🚀 View run at https://wandb.ai/yinanazhou/xl_512_bs_8_lr_1e06_es_10_lc_True_nr_True_sr_False_stem_False_lemma_True_repeat_4_fold_2/runs/36217p3m
wandb: Run data is saved locally in /project/6002780/yinan/Thesis_MER_Lyrics/lyric-emotion/wandb/run-20220325_160235-36217p3m
wandb: Run `wandb offline` to turn off syncing.

Validation loss decreased (inf --> 1.565944).  Saving model ...
Validation loss decreased (1.565944 --> 1.514751).  Saving model ...
Validation loss decreased (1.514751 --> 1.474170).  Saving model ...
Validation loss decreased (1.474170 --> 1.442590).  Saving model ...
Validation loss decreased (1.442590 --> 1.421035).  Saving model ...
Validation loss decreased (1.421035 --> 1.403422).  Saving model ...
Validation loss decreased (1.403422 --> 1.390258).  Saving model ...
Validation loss decreased (1.390258 --> 1.380129).  Saving model ...
Validation loss decreased (1.380129 --> 1.371968).  Saving model ...
Validation loss decreased (1.371968 --> 1.365664).  Saving model ...
Validation loss decreased (1.365664 --> 1.360211).  Saving model ...
Validation loss decreased (1.360211 --> 1.354901).  Saving model ...
Validation loss decreased (1.354901 --> 1.350803).  Saving model ...
Validation loss decreased (1.350803 --> 1.346277).  Saving model ...
Validation loss decreased (1.346277 --> 1.342136).  Saving model ...
Validation loss decreased (1.342136 --> 1.338185).  Saving model ...
Validation loss decreased (1.338185 --> 1.334710).  Saving model ...
Validation loss decreased (1.334710 --> 1.330689).  Saving model ...
Validation loss decreased (1.330689 --> 1.326507).  Saving model ...
Validation loss decreased (1.326507 --> 1.321096).  Saving model ...
Validation loss decreased (1.321096 --> 1.316712).  Saving model ...
Validation loss decreased (1.316712 --> 1.311383).  Saving model ...
Validation loss decreased (1.311383 --> 1.306486).  Saving model ...
Validation loss decreased (1.306486 --> 1.300755).  Saving model ...
Validation loss decreased (1.300755 --> 1.295439).  Saving model ...
Validation loss decreased (1.295439 --> 1.290177).  Saving model ...
Validation loss decreased (1.290177 --> 1.284681).  Saving model ...
Validation loss decreased (1.284681 --> 1.278870).  Saving model ...
Validation loss decreased (1.278870 --> 1.271787).  Saving model ...
Validation loss decreased (1.271787 --> 1.264872).  Saving model ...
Validation loss decreased (1.264872 --> 1.258177).  Saving model ...
Validation loss decreased (1.258177 --> 1.252945).  Saving model ...
Validation loss decreased (1.252945 --> 1.246133).  Saving model ...
Validation loss decreased (1.246133 --> 1.240287).  Saving model ...
Validation loss decreased (1.240287 --> 1.231603).  Saving model ...
Validation loss decreased (1.231603 --> 1.223521).  Saving model ...
Validation loss decreased (1.223521 --> 1.216646).  Saving model ...
Validation loss decreased (1.216646 --> 1.209492).  Saving model ...
Validation loss decreased (1.209492 --> 1.204535).  Saving model ...
Validation loss decreased (1.204535 --> 1.199461).  Saving model ...
Validation loss decreased (1.199461 --> 1.193219).  Saving model ...
Validation loss decreased (1.193219 --> 1.186546).  Saving model ...
Validation loss decreased (1.186546 --> 1.180840).  Saving model ...
Validation loss decreased (1.180840 --> 1.171348).  Saving model ...
Validation loss decreased (1.171348 --> 1.167564).  Saving model ...
Validation loss decreased (1.167564 --> 1.161128).  Saving model ...
Validation loss decreased (1.161128 --> 1.154525).  Saving model ...
Validation loss decreased (1.154525 --> 1.148311).  Saving model ...
Validation loss decreased (1.148311 --> 1.143422).  Saving model ...
Validation loss decreased (1.143422 --> 1.138305).  Saving model ...
Validation loss decreased (1.138305 --> 1.133028).  Saving model ...
Validation loss decreased (1.133028 --> 1.126643).  Saving model ...
Validation loss decreased (1.126643 --> 1.123287).  Saving model ...
Validation loss decreased (1.123287 --> 1.119367).  Saving model ...
Validation loss decreased (1.119367 --> 1.112019).  Saving model ...
Validation loss decreased (1.112019 --> 1.105598).  Saving model ...
Validation loss decreased (1.105598 --> 1.100398).  Saving model ...
Validation loss decreased (1.100398 --> 1.096426).  Saving model ...
Validation loss decreased (1.096426 --> 1.094863).  Saving model ...
Validation loss decreased (1.094863 --> 1.088555).  Saving model ...
Validation loss decreased (1.088555 --> 1.085437).  Saving model ...
Validation loss decreased (1.085437 --> 1.082373).  Saving model ...
Validation loss decreased (1.082373 --> 1.079586).  Saving model ...
Validation loss decreased (1.079586 --> 1.075593).  Saving model ...
Validation loss decreased (1.075593 --> 1.072259).  Saving model ...
Validation loss decreased (1.072259 --> 1.066050).  Saving model ...
Validation loss decreased (1.066050 --> 1.065974).  Saving model ...
Validation loss decreased (1.065974 --> 1.063376).  Saving model ...
Validation loss decreased (1.063376 --> 1.061384).  Saving model ...
Validation loss decreased (1.061384 --> 1.055417).  Saving model ...
Validation loss decreased (1.055417 --> 1.052531).  Saving model ...
Validation loss decreased (1.052531 --> 1.050820).  Saving model ...
Validation loss decreased (1.050820 --> 1.049358).  Saving model ...
Validation loss decreased (1.049358 --> 1.045066).  Saving model ...
Validation loss decreased (1.045066 --> 1.037345).  Saving model ...
Validation loss decreased (1.037345 --> 1.032369).  Saving model ...
Validation loss decreased (1.032369 --> 1.025102).  Saving model ...
EarlyStopping counter: 1 out of 10.0
EarlyStopping counter: 2 out of 10.0
EarlyStopping counter: 3 out of 10.0
Validation loss decreased (1.025102 --> 1.021982).  Saving model ...
Validation loss decreased (1.021982 --> 1.017953).  Saving model ...
Validation loss decreased (1.017953 --> 1.017345).  Saving model ...
Validation loss decreased (1.017345 --> 1.012925).  Saving model ...
Validation loss decreased (1.012925 --> 1.005085).  Saving model ...
EarlyStopping counter: 1 out of 10.0
Validation loss decreased (1.005085 --> 1.005077).  Saving model ...
Validation loss decreased (1.005077 --> 1.003132).  Saving model ...
Validation loss decreased (1.003132 --> 0.998775).  Saving model ...
Validation loss decreased (0.998775 --> 0.996152).  Saving model ...
Validation loss decreased (0.996152 --> 0.995061).  Saving model ...
Validation loss decreased (0.995061 --> 0.993726).  Saving model ...
EarlyStopping counter: 1 out of 10.0
Validation loss decreased (0.993726 --> 0.990447).  Saving model ...
Validation loss decreased (0.990447 --> 0.987944).  Saving model ...
Validation loss decreased (0.987944 --> 0.985086).  Saving model ...
Validation loss decreased (0.985086 --> 0.983883).  Saving model ...
Validation loss decreased (0.983883 --> 0.983592).  Saving model ...
Validation loss decreased (0.983592 --> 0.982398).  Saving model ...
Validation loss decreased (0.982398 --> 0.978714).  Saving model ...
Validation loss decreased (0.978714 --> 0.977757).  Saving model ...
EarlyStopping counter: 1 out of 10.0
EarlyStopping counter: 2 out of 10.0
Validation loss decreased (0.977757 --> 0.977378).  Saving model ...
Validation loss decreased (0.977378 --> 0.974494).  Saving model ...
EarlyStopping counter: 1 out of 10.0
Validation loss decreased (0.974494 --> 0.973598).  Saving model ...
Validation loss decreased (0.973598 --> 0.971458).  Saving model ...
EarlyStopping counter: 1 out of 10.0
EarlyStopping counter: 2 out of 10.0
EarlyStopping counter: 3 out of 10.0
Validation loss decreased (0.971458 --> 0.968939).  Saving model ...
Validation loss decreased (0.968939 --> 0.966969).  Saving model ...
Validation loss decreased (0.966969 --> 0.962034).  Saving model ...
EarlyStopping counter: 1 out of 10.0
EarlyStopping counter: 2 out of 10.0
Validation loss decreased (0.962034 --> 0.959949).  Saving model ...
Validation loss decreased (0.959949 --> 0.956565).  Saving model ...
EarlyStopping counter: 1 out of 10.0
EarlyStopping counter: 2 out of 10.0
EarlyStopping counter: 3 out of 10.0
EarlyStopping counter: 4 out of 10.0
EarlyStopping counter: 5 out of 10.0
Validation loss decreased (0.956565 --> 0.952859).  Saving model ...
EarlyStopping counter: 1 out of 10.0
Validation loss decreased (0.952859 --> 0.951566).  Saving model ...
EarlyStopping counter: 1 out of 10.0
EarlyStopping counter: 2 out of 10.0
EarlyStopping counter: 3 out of 10.0
EarlyStopping counter: 4 out of 10.0
EarlyStopping counter: 5 out of 10.0
EarlyStopping counter: 6 out of 10.0
EarlyStopping counter: 7 out of 10.0
Validation loss decreased (0.951566 --> 0.949230).  Saving model ...
Validation loss decreased (0.949230 --> 0.948804).  Saving model ...
EarlyStopping counter: 1 out of 10.0
Validation loss decreased (0.948804 --> 0.943487).  Saving model ...
EarlyStopping counter: 1 out of 10.0
EarlyStopping counter: 2 out of 10.0
EarlyStopping counter: 3 out of 10.0
EarlyStopping counter: 4 out of 10.0
EarlyStopping counter: 5 out of 10.0
EarlyStopping counter: 6 out of 10.0
EarlyStopping counter: 7 out of 10.0
EarlyStopping counter: 8 out of 10.0
EarlyStopping counter: 9 out of 10.0
EarlyStopping counter: 10 out of 10.0
/localscratch/yinan.29351699.0/env/lib/python3.7/site-packages/torch/nn/functional.py:1794: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.
  warnings.warn("nn.functional.tanh is deprecated. Use torch.tanh instead.")
wandb: Waiting for W&B process to finish, PID 151223... (success).
wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: \ 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: | 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: / 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: \ 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: | 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: / 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: \ 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: | 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: / 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: \ 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb:                                                                                
wandb: Run history:
wandb:     e_F1 ▁▁▂▃▄▄▅▅▆▆▆▆▇▇▇▇▇▇▇▇▇▇██████████████████
wandb:   e_loss █▇▆▆▆▆▅▅▅▅▄▄▄▃▃▃▃▃▂▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:     t_F1 ▁▁▂▂▃▄▄▄▄▄▅▅▆▆▆▆▆▆▆▇▇▆▇▇▇▇▇▇▇▇▇▇███▇████
wandb:   t_loss █▇▇▇▆▆▆▆▆▆▅▅▅▅▄▄▄▄▄▃▃▃▃▃▃▃▂▂▂▂▂▂▂▂▂▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:     e_F1 60.19239
wandb:   e_loss 0.94895
wandb:     t_F1 72.80918
wandb:   t_loss 0.75259
wandb: 
wandb: Synced 4 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Synced neat-resonance-1: https://wandb.ai/yinanazhou/xl_512_bs_8_lr_1e06_es_10_lc_True_nr_True_sr_False_stem_False_lemma_True_repeat_4_fold_2/runs/36217p3m
wandb: Find logs at: ./wandb/run-20220325_160235-36217p3m/logs/debug.log
wandb: 

wandb: wandb version 0.12.11 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
2022-03-25 17:37:04.675181: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1
wandb: Tracking run with wandb version 0.12.5
wandb: Syncing run bright-sea-1
wandb: ⭐️ View project at https://wandb.ai/yinanazhou/xl_512_bs_8_lr_1e06_es_10_lc_True_nr_True_sr_False_stem_False_lemma_True_repeat_5_fold_1
wandb: 🚀 View run at https://wandb.ai/yinanazhou/xl_512_bs_8_lr_1e06_es_10_lc_True_nr_True_sr_False_stem_False_lemma_True_repeat_5_fold_1/runs/20710eqh
wandb: Run data is saved locally in /project/6002780/yinan/Thesis_MER_Lyrics/lyric-emotion/wandb/run-20220325_173702-20710eqh
wandb: Run `wandb offline` to turn off syncing.

Validation loss decreased (inf --> 1.407845).  Saving model ...
Validation loss decreased (1.407845 --> 1.396937).  Saving model ...
Validation loss decreased (1.396937 --> 1.388862).  Saving model ...
Validation loss decreased (1.388862 --> 1.382311).  Saving model ...
Validation loss decreased (1.382311 --> 1.377002).  Saving model ...
Validation loss decreased (1.377002 --> 1.372570).  Saving model ...
Validation loss decreased (1.372570 --> 1.368525).  Saving model ...
Validation loss decreased (1.368525 --> 1.364843).  Saving model ...
Validation loss decreased (1.364843 --> 1.361079).  Saving model ...
Validation loss decreased (1.361079 --> 1.357914).  Saving model ...
Validation loss decreased (1.357914 --> 1.354163).  Saving model ...
Validation loss decreased (1.354163 --> 1.350537).  Saving model ...
Validation loss decreased (1.350537 --> 1.347573).  Saving model ...
Validation loss decreased (1.347573 --> 1.343963).  Saving model ...
Validation loss decreased (1.343963 --> 1.340628).  Saving model ...
Validation loss decreased (1.340628 --> 1.336917).  Saving model ...
Validation loss decreased (1.336917 --> 1.332526).  Saving model ...
Validation loss decreased (1.332526 --> 1.328518).  Saving model ...
Validation loss decreased (1.328518 --> 1.324227).  Saving model ...
Validation loss decreased (1.324227 --> 1.319617).  Saving model ...
Validation loss decreased (1.319617 --> 1.314848).  Saving model ...
Validation loss decreased (1.314848 --> 1.310264).  Saving model ...
Validation loss decreased (1.310264 --> 1.304828).  Saving model ...
Validation loss decreased (1.304828 --> 1.299799).  Saving model ...
Validation loss decreased (1.299799 --> 1.294318).  Saving model ...
Validation loss decreased (1.294318 --> 1.287602).  Saving model ...
Validation loss decreased (1.287602 --> 1.281645).  Saving model ...
Validation loss decreased (1.281645 --> 1.274202).  Saving model ...
Validation loss decreased (1.274202 --> 1.267865).  Saving model ...
Validation loss decreased (1.267865 --> 1.261300).  Saving model ...
Validation loss decreased (1.261300 --> 1.254343).  Saving model ...
Validation loss decreased (1.254343 --> 1.247036).  Saving model ...
Validation loss decreased (1.247036 --> 1.239861).  Saving model ...
Validation loss decreased (1.239861 --> 1.232183).  Saving model ...
Validation loss decreased (1.232183 --> 1.224868).  Saving model ...
Validation loss decreased (1.224868 --> 1.218016).  Saving model ...
Validation loss decreased (1.218016 --> 1.213331).  Saving model ...
Validation loss decreased (1.213331 --> 1.206279).  Saving model ...
Validation loss decreased (1.206279 --> 1.197482).  Saving model ...
Validation loss decreased (1.197482 --> 1.190351).  Saving model ...
Validation loss decreased (1.190351 --> 1.183917).  Saving model ...
Validation loss decreased (1.183917 --> 1.176958).  Saving model ...
Validation loss decreased (1.176958 --> 1.170921).  Saving model ...
Validation loss decreased (1.170921 --> 1.165949).  Saving model ...
Validation loss decreased (1.165949 --> 1.160236).  Saving model ...
Validation loss decreased (1.160236 --> 1.155175).  Saving model ...
Validation loss decreased (1.155175 --> 1.149702).  Saving model ...
Validation loss decreased (1.149702 --> 1.144465).  Saving model ...
Validation loss decreased (1.144465 --> 1.139690).  Saving model ...
Validation loss decreased (1.139690 --> 1.134533).  Saving model ...
Validation loss decreased (1.134533 --> 1.130556).  Saving model ...
Validation loss decreased (1.130556 --> 1.126854).  Saving model ...
Validation loss decreased (1.126854 --> 1.121499).  Saving model ...
Validation loss decreased (1.121499 --> 1.117391).  Saving model ...
Validation loss decreased (1.117391 --> 1.114156).  Saving model ...
Validation loss decreased (1.114156 --> 1.108874).  Saving model ...
Validation loss decreased (1.108874 --> 1.104416).  Saving model ...
Validation loss decreased (1.104416 --> 1.100879).  Saving model ...
Validation loss decreased (1.100879 --> 1.098187).  Saving model ...
Validation loss decreased (1.098187 --> 1.097001).  Saving model ...
Validation loss decreased (1.097001 --> 1.094954).  Saving model ...
Validation loss decreased (1.094954 --> 1.089163).  Saving model ...
Validation loss decreased (1.089163 --> 1.083216).  Saving model ...
Validation loss decreased (1.083216 --> 1.080513).  Saving model ...
Validation loss decreased (1.080513 --> 1.075556).  Saving model ...
Validation loss decreased (1.075556 --> 1.074601).  Saving model ...
Validation loss decreased (1.074601 --> 1.068094).  Saving model ...
Validation loss decreased (1.068094 --> 1.065267).  Saving model ...
Validation loss decreased (1.065267 --> 1.062485).  Saving model ...
Validation loss decreased (1.062485 --> 1.058190).  Saving model ...
Validation loss decreased (1.058190 --> 1.056542).  Saving model ...
Validation loss decreased (1.056542 --> 1.055315).  Saving model ...
Validation loss decreased (1.055315 --> 1.050588).  Saving model ...
Validation loss decreased (1.050588 --> 1.048067).  Saving model ...
Validation loss decreased (1.048067 --> 1.045343).  Saving model ...
Validation loss decreased (1.045343 --> 1.041564).  Saving model ...
Validation loss decreased (1.041564 --> 1.038287).  Saving model ...
Validation loss decreased (1.038287 --> 1.035924).  Saving model ...
Validation loss decreased (1.035924 --> 1.032655).  Saving model ...
Validation loss decreased (1.032655 --> 1.029501).  Saving model ...
Validation loss decreased (1.029501 --> 1.026172).  Saving model ...
Validation loss decreased (1.026172 --> 1.022010).  Saving model ...
Validation loss decreased (1.022010 --> 1.021490).  Saving model ...
Validation loss decreased (1.021490 --> 1.019754).  Saving model ...
Validation loss decreased (1.019754 --> 1.017213).  Saving model ...
Validation loss decreased (1.017213 --> 1.016893).  Saving model ...
Validation loss decreased (1.016893 --> 1.013515).  Saving model ...
Validation loss decreased (1.013515 --> 1.012496).  Saving model ...
Validation loss decreased (1.012496 --> 1.009066).  Saving model ...
Validation loss decreased (1.009066 --> 1.005340).  Saving model ...
Validation loss decreased (1.005340 --> 1.004918).  Saving model ...
Validation loss decreased (1.004918 --> 1.002281).  Saving model ...
Validation loss decreased (1.002281 --> 1.000439).  Saving model ...
Validation loss decreased (1.000439 --> 0.997746).  Saving model ...
Validation loss decreased (0.997746 --> 0.995674).  Saving model ...
Validation loss decreased (0.995674 --> 0.994558).  Saving model ...
Validation loss decreased (0.994558 --> 0.993164).  Saving model ...
Validation loss decreased (0.993164 --> 0.990678).  Saving model ...
Validation loss decreased (0.990678 --> 0.988886).  Saving model ...
Validation loss decreased (0.988886 --> 0.985858).  Saving model ...
EarlyStopping counter: 1 out of 10.0
Validation loss decreased (0.985858 --> 0.983727).  Saving model ...
Validation loss decreased (0.983727 --> 0.981164).  Saving model ...
Validation loss decreased (0.981164 --> 0.980499).  Saving model ...
Validation loss decreased (0.980499 --> 0.979362).  Saving model ...
Validation loss decreased (0.979362 --> 0.978322).  Saving model ...
Validation loss decreased (0.978322 --> 0.977694).  Saving model ...
Validation loss decreased (0.977694 --> 0.976354).  Saving model ...
Validation loss decreased (0.976354 --> 0.975155).  Saving model ...
Validation loss decreased (0.975155 --> 0.972675).  Saving model ...
Validation loss decreased (0.972675 --> 0.971065).  Saving model ...
Validation loss decreased (0.971065 --> 0.970966).  Saving model ...
EarlyStopping counter: 1 out of 10.0
Validation loss decreased (0.970966 --> 0.970502).  Saving model ...
Validation loss decreased (0.970502 --> 0.967096).  Saving model ...
Validation loss decreased (0.967096 --> 0.966530).  Saving model ...
Validation loss decreased (0.966530 --> 0.965486).  Saving model ...
Validation loss decreased (0.965486 --> 0.963453).  Saving model ...
Validation loss decreased (0.963453 --> 0.962696).  Saving model ...
Validation loss decreased (0.962696 --> 0.962420).  Saving model ...
EarlyStopping counter: 1 out of 10.0
Validation loss decreased (0.962420 --> 0.961043).  Saving model ...
Validation loss decreased (0.961043 --> 0.959961).  Saving model ...
Validation loss decreased (0.959961 --> 0.959466).  Saving model ...
Validation loss decreased (0.959466 --> 0.959109).  Saving model ...
Validation loss decreased (0.959109 --> 0.959011).  Saving model ...
Validation loss decreased (0.959011 --> 0.957264).  Saving model ...
EarlyStopping counter: 1 out of 10.0
EarlyStopping counter: 2 out of 10.0
EarlyStopping counter: 3 out of 10.0
Validation loss decreased (0.957264 --> 0.956686).  Saving model ...
Validation loss decreased (0.956686 --> 0.956257).  Saving model ...
EarlyStopping counter: 1 out of 10.0
EarlyStopping counter: 2 out of 10.0
Validation loss decreased (0.956257 --> 0.956235).  Saving model ...
Validation loss decreased (0.956235 --> 0.956111).  Saving model ...
Validation loss decreased (0.956111 --> 0.954615).  Saving model ...
Validation loss decreased (0.954615 --> 0.953959).  Saving model ...
EarlyStopping counter: 1 out of 10.0
EarlyStopping counter: 2 out of 10.0
EarlyStopping counter: 3 out of 10.0
EarlyStopping counter: 4 out of 10.0
EarlyStopping counter: 5 out of 10.0
EarlyStopping counter: 6 out of 10.0
EarlyStopping counter: 7 out of 10.0
EarlyStopping counter: 8 out of 10.0
EarlyStopping counter: 9 out of 10.0
EarlyStopping counter: 10 out of 10.0
/localscratch/yinan.29351699.0/env/lib/python3.7/site-packages/torch/nn/functional.py:1794: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.
  warnings.warn("nn.functional.tanh is deprecated. Use torch.tanh instead.")
wandb: Waiting for W&B process to finish, PID 156264... (success).
wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: \ 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: | 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: / 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: \ 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: | 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: / 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: \ 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: | 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: / 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb:                                                                                
wandb: Run history:
wandb:     e_F1 ▁▁▃▅▆▆▆▆▆▆▆▆▇▇▇▇▇▇▇▇▇▇▇▇████████████████
wandb:   e_loss ██▇▇▇▇▆▆▆▅▅▅▄▄▄▃▃▃▃▃▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:     t_F1 ▁▂▂▃▃▃▄▄▄▅▆▅▆▆▅▆▆▆▇▆▇▇▆▇▇▇▇▇▇▇▇█▇██▇▇███
wandb:   t_loss █▇█▇▇▇▇▆▆▆▆▆▅▅▅▄▄▄▄▄▃▃▃▃▃▃▃▃▂▂▂▂▂▂▂▂▂▁▁▁
wandb: 
wandb: Run summary:
wandb:     e_F1 57.50232
wandb:   e_loss 0.95673
wandb:     t_F1 74.80776
wandb:   t_loss 0.71343
wandb: 
wandb: Synced 4 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Synced bright-sea-1: https://wandb.ai/yinanazhou/xl_512_bs_8_lr_1e06_es_10_lc_True_nr_True_sr_False_stem_False_lemma_True_repeat_5_fold_1/runs/20710eqh
wandb: Find logs at: ./wandb/run-20220325_173702-20710eqh/logs/debug.log
wandb: 

wandb: wandb version 0.12.11 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
2022-03-25 19:14:17.115772: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1
wandb: Tracking run with wandb version 0.12.5
wandb: Syncing run swift-sea-1
wandb: ⭐️ View project at https://wandb.ai/yinanazhou/xl_512_bs_8_lr_1e06_es_10_lc_True_nr_True_sr_False_stem_False_lemma_True_repeat_5_fold_2
wandb: 🚀 View run at https://wandb.ai/yinanazhou/xl_512_bs_8_lr_1e06_es_10_lc_True_nr_True_sr_False_stem_False_lemma_True_repeat_5_fold_2/runs/3r34y1ta
wandb: Run data is saved locally in /project/6002780/yinan/Thesis_MER_Lyrics/lyric-emotion/wandb/run-20220325_191414-3r34y1ta
wandb: Run `wandb offline` to turn off syncing.

Validation loss decreased (inf --> 1.407370).  Saving model ...
Validation loss decreased (1.407370 --> 1.398087).  Saving model ...
Validation loss decreased (1.398087 --> 1.391093).  Saving model ...
Validation loss decreased (1.391093 --> 1.385282).  Saving model ...
Validation loss decreased (1.385282 --> 1.379846).  Saving model ...
Validation loss decreased (1.379846 --> 1.374799).  Saving model ...
Validation loss decreased (1.374799 --> 1.371065).  Saving model ...
Validation loss decreased (1.371065 --> 1.366463).  Saving model ...
Validation loss decreased (1.366463 --> 1.362643).  Saving model ...
Validation loss decreased (1.362643 --> 1.358455).  Saving model ...
Validation loss decreased (1.358455 --> 1.353649).  Saving model ...
Validation loss decreased (1.353649 --> 1.349087).  Saving model ...
Validation loss decreased (1.349087 --> 1.345218).  Saving model ...
Validation loss decreased (1.345218 --> 1.341442).  Saving model ...
Validation loss decreased (1.341442 --> 1.337294).  Saving model ...
Validation loss decreased (1.337294 --> 1.332922).  Saving model ...
Validation loss decreased (1.332922 --> 1.327456).  Saving model ...
Validation loss decreased (1.327456 --> 1.322276).  Saving model ...
Validation loss decreased (1.322276 --> 1.316611).  Saving model ...
Validation loss decreased (1.316611 --> 1.310402).  Saving model ...
Validation loss decreased (1.310402 --> 1.303903).  Saving model ...
Validation loss decreased (1.303903 --> 1.297729).  Saving model ...
Validation loss decreased (1.297729 --> 1.290250).  Saving model ...
Validation loss decreased (1.290250 --> 1.284140).  Saving model ...
Validation loss decreased (1.284140 --> 1.275966).  Saving model ...
Validation loss decreased (1.275966 --> 1.267445).  Saving model ...
Validation loss decreased (1.267445 --> 1.260277).  Saving model ...
Validation loss decreased (1.260277 --> 1.253764).  Saving model ...
Validation loss decreased (1.253764 --> 1.243996).  Saving model ...
Validation loss decreased (1.243996 --> 1.235014).  Saving model ...
Validation loss decreased (1.235014 --> 1.227679).  Saving model ...
Validation loss decreased (1.227679 --> 1.220657).  Saving model ...
Validation loss decreased (1.220657 --> 1.212809).  Saving model ...
Validation loss decreased (1.212809 --> 1.205725).  Saving model ...
Validation loss decreased (1.205725 --> 1.200139).  Saving model ...
Validation loss decreased (1.200139 --> 1.191641).  Saving model ...
Validation loss decreased (1.191641 --> 1.183151).  Saving model ...
Validation loss decreased (1.183151 --> 1.176475).  Saving model ...
Validation loss decreased (1.176475 --> 1.172045).  Saving model ...
Validation loss decreased (1.172045 --> 1.165882).  Saving model ...
Validation loss decreased (1.165882 --> 1.160592).  Saving model ...
Validation loss decreased (1.160592 --> 1.153160).  Saving model ...
Validation loss decreased (1.153160 --> 1.145997).  Saving model ...
Validation loss decreased (1.145997 --> 1.143140).  Saving model ...
Validation loss decreased (1.143140 --> 1.138895).  Saving model ...
Validation loss decreased (1.138895 --> 1.134340).  Saving model ...
Validation loss decreased (1.134340 --> 1.129930).  Saving model ...
Validation loss decreased (1.129930 --> 1.125767).  Saving model ...
Validation loss decreased (1.125767 --> 1.121963).  Saving model ...
Validation loss decreased (1.121963 --> 1.117392).  Saving model ...
Validation loss decreased (1.117392 --> 1.113435).  Saving model ...
Validation loss decreased (1.113435 --> 1.109482).  Saving model ...
Validation loss decreased (1.109482 --> 1.106632).  Saving model ...
Validation loss decreased (1.106632 --> 1.100564).  Saving model ...
Validation loss decreased (1.100564 --> 1.096200).  Saving model ...
Validation loss decreased (1.096200 --> 1.091733).  Saving model ...
Validation loss decreased (1.091733 --> 1.090781).  Saving model ...
Validation loss decreased (1.090781 --> 1.086072).  Saving model ...
Validation loss decreased (1.086072 --> 1.078956).  Saving model ...
Validation loss decreased (1.078956 --> 1.077256).  Saving model ...
Validation loss decreased (1.077256 --> 1.075929).  Saving model ...
Validation loss decreased (1.075929 --> 1.068960).  Saving model ...
Validation loss decreased (1.068960 --> 1.065618).  Saving model ...
Validation loss decreased (1.065618 --> 1.064422).  Saving model ...
Validation loss decreased (1.064422 --> 1.060038).  Saving model ...
Validation loss decreased (1.060038 --> 1.056017).  Saving model ...
EarlyStopping counter: 1 out of 10.0
Validation loss decreased (1.056017 --> 1.050000).  Saving model ...
Validation loss decreased (1.050000 --> 1.045315).  Saving model ...
Validation loss decreased (1.045315 --> 1.041617).  Saving model ...
Validation loss decreased (1.041617 --> 1.038853).  Saving model ...
Validation loss decreased (1.038853 --> 1.035529).  Saving model ...
Validation loss decreased (1.035529 --> 1.033118).  Saving model ...
Validation loss decreased (1.033118 --> 1.029597).  Saving model ...
Validation loss decreased (1.029597 --> 1.027687).  Saving model ...
EarlyStopping counter: 1 out of 10.0
Validation loss decreased (1.027687 --> 1.024477).  Saving model ...
EarlyStopping counter: 1 out of 10.0
Validation loss decreased (1.024477 --> 1.022172).  Saving model ...
Validation loss decreased (1.022172 --> 1.019391).  Saving model ...
Validation loss decreased (1.019391 --> 1.017171).  Saving model ...
Validation loss decreased (1.017171 --> 1.012878).  Saving model ...
Validation loss decreased (1.012878 --> 1.008667).  Saving model ...
Validation loss decreased (1.008667 --> 1.005922).  Saving model ...
Validation loss decreased (1.005922 --> 1.004682).  Saving model ...
Validation loss decreased (1.004682 --> 1.003320).  Saving model ...
Validation loss decreased (1.003320 --> 0.999143).  Saving model ...
Validation loss decreased (0.999143 --> 0.998997).  Saving model ...
Validation loss decreased (0.998997 --> 0.998957).  Saving model ...
Validation loss decreased (0.998957 --> 0.994520).  Saving model ...
EarlyStopping counter: 1 out of 10.0
Validation loss decreased (0.994520 --> 0.991704).  Saving model ...
Validation loss decreased (0.991704 --> 0.990968).  Saving model ...
EarlyStopping counter: 1 out of 10.0
Validation loss decreased (0.990968 --> 0.988181).  Saving model ...
Validation loss decreased (0.988181 --> 0.983376).  Saving model ...
EarlyStopping counter: 1 out of 10.0
Validation loss decreased (0.983376 --> 0.981990).  Saving model ...
EarlyStopping counter: 1 out of 10.0
Validation loss decreased (0.981990 --> 0.980732).  Saving model ...
Validation loss decreased (0.980732 --> 0.979622).  Saving model ...
EarlyStopping counter: 1 out of 10.0
EarlyStopping counter: 2 out of 10.0
Validation loss decreased (0.979622 --> 0.978516).  Saving model ...
Validation loss decreased (0.978516 --> 0.976961).  Saving model ...
Validation loss decreased (0.976961 --> 0.975350).  Saving model ...
Validation loss decreased (0.975350 --> 0.970660).  Saving model ...
Validation loss decreased (0.970660 --> 0.969193).  Saving model ...
Validation loss decreased (0.969193 --> 0.965667).  Saving model ...
EarlyStopping counter: 1 out of 10.0
EarlyStopping counter: 2 out of 10.0
Validation loss decreased (0.965667 --> 0.965479).  Saving model ...
Validation loss decreased (0.965479 --> 0.962944).  Saving model ...
Validation loss decreased (0.962944 --> 0.962528).  Saving model ...
Validation loss decreased (0.962528 --> 0.960338).  Saving model ...
EarlyStopping counter: 1 out of 10.0
Validation loss decreased (0.960338 --> 0.960052).  Saving model ...
Validation loss decreased (0.960052 --> 0.958822).  Saving model ...
Validation loss decreased (0.958822 --> 0.958024).  Saving model ...
Validation loss decreased (0.958024 --> 0.957240).  Saving model ...
EarlyStopping counter: 1 out of 10.0
Validation loss decreased (0.957240 --> 0.956869).  Saving model ...
EarlyStopping counter: 1 out of 10.0
Validation loss decreased (0.956869 --> 0.954773).  Saving model ...
EarlyStopping counter: 1 out of 10.0
Validation loss decreased (0.954773 --> 0.953878).  Saving model ...
EarlyStopping counter: 1 out of 10.0
Validation loss decreased (0.953878 --> 0.953506).  Saving model ...
EarlyStopping counter: 1 out of 10.0
EarlyStopping counter: 2 out of 10.0
EarlyStopping counter: 3 out of 10.0
EarlyStopping counter: 4 out of 10.0
Validation loss decreased (0.953506 --> 0.951158).  Saving model ...
EarlyStopping counter: 1 out of 10.0
EarlyStopping counter: 2 out of 10.0
EarlyStopping counter: 3 out of 10.0
Validation loss decreased (0.951158 --> 0.950427).  Saving model ...
Validation loss decreased (0.950427 --> 0.948732).  Saving model ...
Validation loss decreased (0.948732 --> 0.946345).  Saving model ...
EarlyStopping counter: 1 out of 10.0
EarlyStopping counter: 2 out of 10.0
EarlyStopping counter: 3 out of 10.0
EarlyStopping counter: 4 out of 10.0
EarlyStopping counter: 5 out of 10.0
EarlyStopping counter: 6 out of 10.0
EarlyStopping counter: 7 out of 10.0
Validation loss decreased (0.946345 --> 0.945713).  Saving model ...
Validation loss decreased (0.945713 --> 0.944467).  Saving model ...
Validation loss decreased (0.944467 --> 0.943704).  Saving model ...
EarlyStopping counter: 1 out of 10.0
Validation loss decreased (0.943704 --> 0.942118).  Saving model ...
EarlyStopping counter: 1 out of 10.0
EarlyStopping counter: 2 out of 10.0
EarlyStopping counter: 3 out of 10.0
EarlyStopping counter: 4 out of 10.0
EarlyStopping counter: 5 out of 10.0
EarlyStopping counter: 6 out of 10.0
EarlyStopping counter: 7 out of 10.0
EarlyStopping counter: 8 out of 10.0
EarlyStopping counter: 9 out of 10.0
EarlyStopping counter: 10 out of 10.0
/localscratch/yinan.29351699.0/env/lib/python3.7/site-packages/torch/nn/functional.py:1794: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.
  warnings.warn("nn.functional.tanh is deprecated. Use torch.tanh instead.")
wandb: Waiting for W&B process to finish, PID 161433... (success).
wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: \ 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: | 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: / 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: \ 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: | 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: / 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: \ 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: | 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: / 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb:                                                                                
wandb: Run history:
wandb:     e_F1 ▁▂▃▃▄▅▅▅▆▆▇▇▇▇▇▇▇▇▇▇▇▇█▇████████████████
wandb:   e_loss ██▇▇▇▆▆▅▅▅▄▄▄▃▃▃▃▂▂▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:     t_F1 ▁▁▂▂▃▃▄▅▅▅▄▅▅▅▆▅▆▆▆▆▆▆▇▆▇▇▆▇▇▇▇▇▇▇▇▇█▇██
wandb:   t_loss ██▇▇▇▇▆▆▆▆▆▅▅▅▄▄▄▄▄▄▄▃▃▃▃▃▃▂▂▂▂▂▂▂▂▂▁▂▁▁
wandb: 
wandb: Run summary:
wandb:     e_F1 60.30283
wandb:   e_loss 0.94537
wandb:     t_F1 73.08381
wandb:   t_loss 0.71526
wandb: 
wandb: Synced 4 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Synced swift-sea-1: https://wandb.ai/yinanazhou/xl_512_bs_8_lr_1e06_es_10_lc_True_nr_True_sr_False_stem_False_lemma_True_repeat_5_fold_2/runs/3r34y1ta
wandb: Find logs at: ./wandb/run-20220325_191414-3r34y1ta/logs/debug.log
wandb: 

