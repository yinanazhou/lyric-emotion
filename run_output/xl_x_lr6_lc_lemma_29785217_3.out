Unloading StdEnv/2020

Due to MODULEPATH changes, the following have been reloaded:
  1) mii/1.1.1


The following have been reloaded with a version change:
  1) python/3.8.2 => python/3.7.4

Using base prefix '/cvmfs/soft.computecanada.ca/easybuild/software/2017/Core/python/3.7.4'
New python executable in /localscratch/yinan.29785217.0/env/bin/python
Installing setuptools, pip, wheel...
done.
Ignoring pip: markers 'python_version < "3"' don't match your environment
Looking in links: /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/nix/avx2, /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/nix/generic, /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic
Collecting pip
Installing collected packages: pip
  Found existing installation: pip 19.1.1
    Uninstalling pip-19.1.1:
      Successfully uninstalled pip-19.1.1
Successfully installed pip-21.2.3+computecanada
Looking in links: /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/nix/avx2, /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/nix/generic, /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/keras-2.8.0+computecanada-py2.py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/Keras_Preprocessing-1.1.2+computecanada-py3-none-any.whl
Requirement already satisfied: matplotlib in /cvmfs/soft.computecanada.ca/easybuild/software/2017/Core/scipy-stack/2019a/lib/python3.7/site-packages (from -r requirements.txt (line 3)) (3.0.2)
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/nltk-3.6.5+computecanada-py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/scikit_learn-0.22.1+computecanada-cp37-cp37m-linux_x86_64.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/tensorboard-2.3.0+computecanada-py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/tensorboard_plugin_wit-1.7.0+computecanada-py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/tensorflow_gpu-2.3.0+computecanada-cp37-cp37m-linux_x86_64.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/tensorflow_estimator-2.3.0+computecanada-py2.py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/tokenizers-0.5.2+computecanada-cp37-cp37m-linux_x86_64.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/nix/avx2/torch-1.4.0+computecanada-cp37-cp37m-linux_x86_64.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/torchtext-0.6.0+computecanada-py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/torchvision-0.8.2+computecanada-cp37-cp37m-linux_x86_64.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/transformers-2.5.1+computecanada-py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/urllib3-1.26.7+computecanada-py2.py3-none-any.whl
ERROR: Could not find a version that satisfies the requirement regex>=2021.8.3 (from nltk) (from versions: 2018.1.10+computecanada, 2019.11.1+computecanada, 2020.11.13+computecanada)
ERROR: No matching distribution found for regex>=2021.8.3
Looking in links: /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/nix/avx2, /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/nix/generic, /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic
ERROR: Could not find a version that satisfies the requirement numpy==1.20.0+computacanada (from versions: 1.15.0+computecanada, 1.15.2+computecanada, 1.15.4+computecanada, 1.16.0+computecanada, 1.16.2+computecanada, 1.16.3+computecanada, 1.17.4+computecanada, 1.18.1+computecanada, 1.18.4+computecanada, 1.19.1+computecanada, 1.19.2+computecanada, 1.20.2+computecanada)
ERROR: No matching distribution found for numpy==1.20.0+computacanada
Looking in links: /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/nix/avx2, /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/nix/generic, /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/wandb-0.12.5+computecanada-py2.py3-none-any.whl
Requirement already satisfied: python-dateutil>=2.6.1 in /cvmfs/soft.computecanada.ca/easybuild/software/2017/Core/scipy-stack/2019a/lib/python3.7/site-packages (from wandb) (2.7.5)
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/protobuf-3.19.4+computecanada-py2.py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/PyYAML-5.3.1+computecanada-cp37-cp37m-linux_x86_64.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/psutil-5.7.3+computecanada-cp37-cp37m-linux_x86_64.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/GitPython-3.1.24+computecanada-py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/docker_pycreds-0.4.0+computecanada-py2.py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/pathtools-0.1.2+computecanada-py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/subprocess32-3.5.4+computecanada-py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/configparser-5.0.2+computecanada-py3-none-any.whl
Requirement already satisfied: requests<3,>=2.0.0 in /cvmfs/soft.computecanada.ca/easybuild/software/2017/Core/scipy-stack/2019a/lib/python3.7/site-packages (from wandb) (2.21.0)
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/sentry_sdk-1.5.0+computecanada-py2.py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/yaspin-2.1.0+computecanada-py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/click-8.1.0+computecanada-py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/promise-2.3+computecanada-py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/six-1.16.0+computecanada-py2.py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/shortuuid-1.0.1+computecanada-py3-none-any.whl
Requirement already satisfied: importlib-metadata in /cvmfs/soft.computecanada.ca/easybuild/software/2017/Core/scipy-stack/2019a/lib/python3.7/site-packages (from Click!=8.0.0,>=7.0->wandb) (0.8)
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/typing_extensions-4.1.1+computecanada-py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/gitdb-4.0.9+computecanada-py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/smmap-5.0.0+computecanada-py3-none-any.whl
Requirement already satisfied: certifi>=2017.4.17 in /cvmfs/soft.computecanada.ca/easybuild/software/2017/Core/scipy-stack/2019a/lib/python3.7/site-packages (from requests<3,>=2.0.0->wandb) (2018.11.29)
Requirement already satisfied: idna<2.9,>=2.5 in /cvmfs/soft.computecanada.ca/easybuild/software/2017/Core/scipy-stack/2019a/lib/python3.7/site-packages (from requests<3,>=2.0.0->wandb) (2.8)
Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /cvmfs/soft.computecanada.ca/easybuild/software/2017/Core/scipy-stack/2019a/lib/python3.7/site-packages (from requests<3,>=2.0.0->wandb) (3.0.4)
Requirement already satisfied: urllib3<1.25,>=1.21.1 in /cvmfs/soft.computecanada.ca/easybuild/software/2017/Core/scipy-stack/2019a/lib/python3.7/site-packages (from requests<3,>=2.0.0->wandb) (1.24.1)
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/termcolor-1.1.0+computecanada-py3-none-any.whl
Requirement already satisfied: zipp>=0.3.2 in /cvmfs/soft.computecanada.ca/easybuild/software/2017/Core/scipy-stack/2019a/lib/python3.7/site-packages (from importlib-metadata->Click!=8.0.0,>=7.0->wandb) (0.3.3)
Installing collected packages: smmap, typing-extensions, termcolor, six, gitdb, yaspin, subprocess32, shortuuid, sentry-sdk, PyYAML, psutil, protobuf, promise, pathtools, GitPython, docker-pycreds, configparser, Click, wandb
  Attempting uninstall: six
    Found existing installation: six 1.12.0
    Not uninstalling six at /cvmfs/soft.computecanada.ca/easybuild/software/2017/Core/scipy-stack/2019a/lib/python3.7/site-packages, outside environment /localscratch/yinan.29785217.0/env
    Can't uninstall 'six'. No files were found to uninstall.
Successfully installed Click-8.1.0+computecanada GitPython-3.1.24+computecanada PyYAML-5.3.1+computecanada configparser-5.0.2+computecanada docker-pycreds-0.4.0+computecanada gitdb-4.0.9+computecanada pathtools-0.1.2+computecanada promise-2.3+computecanada protobuf-3.19.4+computecanada psutil-5.7.3+computecanada sentry-sdk-1.5.0+computecanada shortuuid-1.0.1+computecanada six-1.16.0+computecanada smmap-5.0.0+computecanada subprocess32-3.5.4+computecanada termcolor-1.1.0+computecanada typing-extensions-4.1.1+computecanada wandb-0.12.5+computecanada yaspin-2.1.0+computecanada
Looking in links: /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/nix/avx2, /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/nix/generic, /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic
ERROR: Could not find a version that satisfies the requirement sagemaker (from versions: none)
ERROR: No matching distribution found for sagemaker
Looking in links: /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/nix/avx2, /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/nix/generic, /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/torch-1.9.1+computecanada-cp37-cp37m-linux_x86_64.whl
Requirement already satisfied: typing-extensions in /localscratch/yinan.29785217.0/env/lib/python3.7/site-packages (from torch) (4.1.1+computecanada)
Installing collected packages: torch
Successfully installed torch-1.9.1+computecanada
Looking in links: /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/nix/avx2, /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/nix/generic, /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/transformers-2.5.1+computecanada-py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/boto3-1.21.14+computecanada-py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/regex-2020.11.13+computecanada-cp37-cp37m-linux_x86_64.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/filelock-3.4.2+computecanada-py3-none-any.whl
Requirement already satisfied: numpy in /cvmfs/soft.computecanada.ca/easybuild/software/2017/Core/scipy-stack/2019a/lib/python3.7/site-packages (from transformers==2.5.1+computecanada) (1.16.0)
Requirement already satisfied: requests in /cvmfs/soft.computecanada.ca/easybuild/software/2017/Core/scipy-stack/2019a/lib/python3.7/site-packages (from transformers==2.5.1+computecanada) (2.21.0)
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/tokenizers-0.5.2+computecanada-cp37-cp37m-linux_x86_64.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/sacremoses-0.0.49+computecanada-py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/tqdm-4.63.1+computecanada-py2.py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/sentencepiece-0.1.91+computecanada-cp37-cp37m-linux_x86_64.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/jmespath-0.10.0+computecanada-py2.py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/s3transfer-0.5.1+computecanada-py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/botocore-1.24.14+computecanada-py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/urllib3-1.26.9+computecanada-py2.py3-none-any.whl
Requirement already satisfied: python-dateutil<3.0.0,>=2.1 in /cvmfs/soft.computecanada.ca/easybuild/software/2017/Core/scipy-stack/2019a/lib/python3.7/site-packages (from botocore<1.25.0,>=1.24.14->boto3->transformers==2.5.1+computecanada) (2.7.5)
Requirement already satisfied: six>=1.5 in /localscratch/yinan.29785217.0/env/lib/python3.7/site-packages (from python-dateutil<3.0.0,>=2.1->botocore<1.25.0,>=1.24.14->boto3->transformers==2.5.1+computecanada) (1.16.0+computecanada)
Requirement already satisfied: idna<2.9,>=2.5 in /cvmfs/soft.computecanada.ca/easybuild/software/2017/Core/scipy-stack/2019a/lib/python3.7/site-packages (from requests->transformers==2.5.1+computecanada) (2.8)
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/requests-2.27.1+computecanada-py2.py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/charset_normalizer-2.0.12+computecanada-py3-none-any.whl
Requirement already satisfied: certifi>=2017.4.17 in /cvmfs/soft.computecanada.ca/easybuild/software/2017/Core/scipy-stack/2019a/lib/python3.7/site-packages (from requests->transformers==2.5.1+computecanada) (2018.11.29)
Requirement already satisfied: click in /localscratch/yinan.29785217.0/env/lib/python3.7/site-packages (from sacremoses->transformers==2.5.1+computecanada) (8.1.0+computecanada)
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/joblib-1.1.0+computecanada-py2.py3-none-any.whl
Requirement already satisfied: importlib-metadata in /cvmfs/soft.computecanada.ca/easybuild/software/2017/Core/scipy-stack/2019a/lib/python3.7/site-packages (from click->sacremoses->transformers==2.5.1+computecanada) (0.8)
Requirement already satisfied: zipp>=0.3.2 in /cvmfs/soft.computecanada.ca/easybuild/software/2017/Core/scipy-stack/2019a/lib/python3.7/site-packages (from importlib-metadata->click->sacremoses->transformers==2.5.1+computecanada) (0.3.3)
Installing collected packages: urllib3, jmespath, botocore, tqdm, s3transfer, regex, joblib, charset-normalizer, tokenizers, sentencepiece, sacremoses, requests, filelock, boto3, transformers
  Attempting uninstall: urllib3
    Found existing installation: urllib3 1.24.1
    Not uninstalling urllib3 at /cvmfs/soft.computecanada.ca/easybuild/software/2017/Core/scipy-stack/2019a/lib/python3.7/site-packages, outside environment /localscratch/yinan.29785217.0/env
    Can't uninstall 'urllib3'. No files were found to uninstall.
  Attempting uninstall: requests
    Found existing installation: requests 2.21.0
    Not uninstalling requests at /cvmfs/soft.computecanada.ca/easybuild/software/2017/Core/scipy-stack/2019a/lib/python3.7/site-packages, outside environment /localscratch/yinan.29785217.0/env
    Can't uninstall 'requests'. No files were found to uninstall.
Successfully installed boto3-1.21.14+computecanada botocore-1.24.14+computecanada charset-normalizer-2.0.12+computecanada filelock-3.4.2+computecanada jmespath-0.10.0+computecanada joblib-1.1.0+computecanada regex-2020.11.13+computecanada requests-2.27.1+computecanada s3transfer-0.5.1+computecanada sacremoses-0.0.49+computecanada sentencepiece-0.1.91+computecanada tokenizers-0.5.2+computecanada tqdm-4.63.1+computecanada transformers-2.5.1+computecanada urllib3-1.26.9+computecanada
Looking in links: /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/nix/avx2, /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/nix/generic, /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/tensorflow_gpu-2.3.0+computecanada-cp37-cp37m-linux_x86_64.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/astunparse-1.6.3+computecanada-py2.py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/nix/avx2/h5py-2.10.0+computecanada-cp37-cp37m-linux_x86_64.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/google_pasta-0.2.0+computecanada-py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/opt_einsum-3.3.0+computecanada-py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/grpcio-1.38.0+computecanada-cp37-cp37m-linux_x86_64.whl
Requirement already satisfied: protobuf>=3.9.2 in /localscratch/yinan.29785217.0/env/lib/python3.7/site-packages (from tensorflow_gpu==2.3.0+computecanada) (3.19.4+computecanada)
Requirement already satisfied: termcolor>=1.1.0 in /localscratch/yinan.29785217.0/env/lib/python3.7/site-packages (from tensorflow_gpu==2.3.0+computecanada) (1.1.0+computecanada)
Requirement already satisfied: wheel>=0.26 in /localscratch/yinan.29785217.0/env/lib/python3.7/site-packages (from tensorflow_gpu==2.3.0+computecanada) (0.33.4)
Requirement already satisfied: six>=1.12.0 in /localscratch/yinan.29785217.0/env/lib/python3.7/site-packages (from tensorflow_gpu==2.3.0+computecanada) (1.16.0+computecanada)
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/Keras_Preprocessing-1.1.2+computecanada-py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/tensorboard-2.8.0+computecanada-py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/tensorflow_estimator-2.3.0+computecanada-py2.py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/wrapt-1.11.2+computecanada-cp37-cp37m-linux_x86_64.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/absl_py-1.0.0+computecanada-py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/nix/generic/scipy-1.4.1+computecanada-cp37-cp37m-linux_x86_64.whl
Requirement already satisfied: numpy<1.19.0,>=1.16.0 in /cvmfs/soft.computecanada.ca/easybuild/software/2017/Core/scipy-stack/2019a/lib/python3.7/site-packages (from tensorflow_gpu==2.3.0+computecanada) (1.16.0)
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/gast-0.3.3+computecanada-py3-none-any.whl
Requirement already satisfied: requests<3,>=2.21.0 in /localscratch/yinan.29785217.0/env/lib/python3.7/site-packages (from tensorboard<3,>=2.3.0->tensorflow_gpu==2.3.0+computecanada) (2.27.1+computecanada)
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/google_auth_oauthlib-0.4.6+computecanada-py2.py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/Markdown-3.3.6+computecanada-py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/google_auth-2.3.3+computecanada-py2.py3-none-any.whl
Requirement already satisfied: setuptools>=41.0.0 in /localscratch/yinan.29785217.0/env/lib/python3.7/site-packages (from tensorboard<3,>=2.3.0->tensorflow_gpu==2.3.0+computecanada) (41.0.1)
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/Werkzeug-2.0.3+computecanada-py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/tensorboard_data_server-0.6.1+computecanada-py3-none-linux_x86_64.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/tensorboard_plugin_wit-1.8.0+computecanada-py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/rsa-4.8+computecanada-py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/pyasn1_modules-0.2.8+computecanada-py2.py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/cachetools-4.2.4+computecanada-py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/requests_oauthlib-1.3.0+computecanada-py2.py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/importlib_metadata-4.10.1+computecanada-py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/zipp-3.7.0+computecanada-py3-none-any.whl
Requirement already satisfied: typing-extensions>=3.6.4 in /localscratch/yinan.29785217.0/env/lib/python3.7/site-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard<3,>=2.3.0->tensorflow_gpu==2.3.0+computecanada) (4.1.1+computecanada)
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/pyasn1-0.4.8+computecanada-py2.py3-none-any.whl
Requirement already satisfied: idna<4,>=2.5 in /cvmfs/soft.computecanada.ca/easybuild/software/2017/Core/scipy-stack/2019a/lib/python3.7/site-packages (from requests<3,>=2.21.0->tensorboard<3,>=2.3.0->tensorflow_gpu==2.3.0+computecanada) (2.8)
Requirement already satisfied: charset-normalizer~=2.0.0 in /localscratch/yinan.29785217.0/env/lib/python3.7/site-packages (from requests<3,>=2.21.0->tensorboard<3,>=2.3.0->tensorflow_gpu==2.3.0+computecanada) (2.0.12+computecanada)
Requirement already satisfied: urllib3<1.27,>=1.21.1 in /localscratch/yinan.29785217.0/env/lib/python3.7/site-packages (from requests<3,>=2.21.0->tensorboard<3,>=2.3.0->tensorflow_gpu==2.3.0+computecanada) (1.26.9+computecanada)
Requirement already satisfied: certifi>=2017.4.17 in /cvmfs/soft.computecanada.ca/easybuild/software/2017/Core/scipy-stack/2019a/lib/python3.7/site-packages (from requests<3,>=2.21.0->tensorboard<3,>=2.3.0->tensorflow_gpu==2.3.0+computecanada) (2018.11.29)
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/oauthlib-3.1.1+computecanada-py2.py3-none-any.whl
Installing collected packages: pyasn1, zipp, rsa, pyasn1-modules, oauthlib, cachetools, requests-oauthlib, importlib-metadata, google-auth, werkzeug, tensorboard-plugin-wit, tensorboard-data-server, markdown, grpcio, google-auth-oauthlib, absl-py, wrapt, tensorflow-estimator, tensorboard, scipy, opt-einsum, keras-preprocessing, h5py, google-pasta, gast, astunparse, tensorflow-gpu
  Attempting uninstall: pyasn1
    Found existing installation: pyasn1 0.4.3
    Not uninstalling pyasn1 at /cvmfs/soft.computecanada.ca/easybuild/software/2017/Core/scipy-stack/2019a/lib/python3.7/site-packages, outside environment /localscratch/yinan.29785217.0/env
    Can't uninstall 'pyasn1'. No files were found to uninstall.
  Attempting uninstall: zipp
    Found existing installation: zipp 0.3.3
    Not uninstalling zipp at /cvmfs/soft.computecanada.ca/easybuild/software/2017/Core/scipy-stack/2019a/lib/python3.7/site-packages, outside environment /localscratch/yinan.29785217.0/env
    Can't uninstall 'zipp'. No files were found to uninstall.
  Attempting uninstall: importlib-metadata
    Found existing installation: importlib-metadata 0.8
    Not uninstalling importlib-metadata at /cvmfs/soft.computecanada.ca/easybuild/software/2017/Core/scipy-stack/2019a/lib/python3.7/site-packages, outside environment /localscratch/yinan.29785217.0/env
    Can't uninstall 'importlib-metadata'. No files were found to uninstall.
  Attempting uninstall: scipy
    Found existing installation: scipy 1.2.0
    Not uninstalling scipy at /cvmfs/soft.computecanada.ca/easybuild/software/2017/Core/scipy-stack/2019a/lib/python3.7/site-packages, outside environment /localscratch/yinan.29785217.0/env
    Can't uninstall 'scipy'. No files were found to uninstall.
Successfully installed absl-py-1.0.0+computecanada astunparse-1.6.3+computecanada cachetools-4.2.4+computecanada gast-0.3.3+computecanada google-auth-2.3.3+computecanada google-auth-oauthlib-0.4.6+computecanada google-pasta-0.2.0+computecanada grpcio-1.38.0+computecanada h5py-2.10.0+computecanada importlib-metadata-4.10.1+computecanada keras-preprocessing-1.1.2+computecanada markdown-3.3.6+computecanada oauthlib-3.1.1+computecanada opt-einsum-3.3.0+computecanada pyasn1-0.4.8+computecanada pyasn1-modules-0.2.8+computecanada requests-oauthlib-1.3.0+computecanada rsa-4.8+computecanada scipy-1.4.1+computecanada tensorboard-2.8.0+computecanada tensorboard-data-server-0.6.1+computecanada tensorboard-plugin-wit-1.8.0+computecanada tensorflow-estimator-2.3.0+computecanada tensorflow-gpu-2.3.0+computecanada werkzeug-2.0.3+computecanada wrapt-1.11.2+computecanada zipp-3.7.0+computecanada
Looking in links: /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/nix/avx2, /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/nix/generic, /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/keras-2.8.0+computecanada-py2.py3-none-any.whl
Installing collected packages: Keras
Successfully installed Keras-2.8.0+computecanada
Looking in links: /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/nix/avx2, /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/nix/generic, /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/urllib3-1.26.7+computecanada-py2.py3-none-any.whl
Installing collected packages: urllib3
  Attempting uninstall: urllib3
    Found existing installation: urllib3 1.26.9+computecanada
    Uninstalling urllib3-1.26.9+computecanada:
      Successfully uninstalled urllib3-1.26.9+computecanada
Successfully installed urllib3-1.26.7+computecanada
Looking in links: /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/nix/avx2, /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/nix/generic, /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/nltk-3.7+computecanada-py3-none-any.whl
Requirement already satisfied: joblib in /localscratch/yinan.29785217.0/env/lib/python3.7/site-packages (from nltk) (1.1.0+computecanada)
Requirement already satisfied: click in /localscratch/yinan.29785217.0/env/lib/python3.7/site-packages (from nltk) (8.1.0+computecanada)
Requirement already satisfied: tqdm in /localscratch/yinan.29785217.0/env/lib/python3.7/site-packages (from nltk) (4.63.1+computecanada)
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/nltk-3.6.5+computecanada-py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/nltk-3.6.3+computecanada-py3-none-any.whl
Requirement already satisfied: regex in /localscratch/yinan.29785217.0/env/lib/python3.7/site-packages (from nltk) (2020.11.13+computecanada)
Requirement already satisfied: importlib-metadata in /localscratch/yinan.29785217.0/env/lib/python3.7/site-packages (from click->nltk) (4.10.1+computecanada)
Requirement already satisfied: zipp>=0.5 in /localscratch/yinan.29785217.0/env/lib/python3.7/site-packages (from importlib-metadata->click->nltk) (3.7.0+computecanada)
Requirement already satisfied: typing-extensions>=3.6.4 in /localscratch/yinan.29785217.0/env/lib/python3.7/site-packages (from importlib-metadata->click->nltk) (4.1.1+computecanada)
Installing collected packages: nltk
Successfully installed nltk-3.6.3+computecanada
Looking in links: /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/nix/avx2, /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/nix/generic, /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/scikit_learn-0.22.1+computecanada-cp37-cp37m-linux_x86_64.whl
Requirement already satisfied: numpy>=1.11.0 in /cvmfs/soft.computecanada.ca/easybuild/software/2017/Core/scipy-stack/2019a/lib/python3.7/site-packages (from scikit-learn==0.22.1) (1.16.0)
Requirement already satisfied: scipy>=0.17.0 in /localscratch/yinan.29785217.0/env/lib/python3.7/site-packages (from scikit-learn==0.22.1) (1.4.1+computecanada)
Requirement already satisfied: joblib>=0.11 in /localscratch/yinan.29785217.0/env/lib/python3.7/site-packages (from scikit-learn==0.22.1) (1.1.0+computecanada)
Installing collected packages: scikit-learn
Successfully installed scikit-learn-0.22.1+computecanada
Looking in links: /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/nix/avx2, /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/nix/generic, /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic
Requirement already satisfied: tokenizers==0.5.2 in /localscratch/yinan.29785217.0/env/lib/python3.7/site-packages (0.5.2+computecanada)
wandb: Appending key for api.wandb.ai to your netrc file: /home/yinan/.netrc
Starting Task
2022-03-29 20:33:08.489840: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1
[nltk_data] Downloading package stopwords to /home/yinan/nltk_data...
[nltk_data]   Package stopwords is already up-to-date!
[nltk_data] Downloading package wordnet to /home/yinan/nltk_data...
[nltk_data]   Package wordnet is already up-to-date!
wandb: Currently logged in as: yinanazhou (use `wandb login --relogin` to force relogin)
wandb: wandb version 0.12.11 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
2022-03-29 20:33:24.146342: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1
wandb: Tracking run with wandb version 0.12.5
wandb: Syncing run lyric-mountain-2
wandb: ⭐️ View project at https://wandb.ai/yinanazhou/xl_512_bs_8_lr_1e06_es_3_lc_True_nr_False_sr_False_stem_False_lemma_True_repeat_1_fold_1
wandb: 🚀 View run at https://wandb.ai/yinanazhou/xl_512_bs_8_lr_1e06_es_3_lc_True_nr_False_sr_False_stem_False_lemma_True_repeat_1_fold_1/runs/11k1h5r4
wandb: Run data is saved locally in /project/6002780/yinan/Thesis_MER_Lyrics/lyric-emotion/wandb/run-20220329_203322-11k1h5r4
wandb: Run `wandb offline` to turn off syncing.

Validation loss decreased (inf --> 1.433387).  Saving model ...
Validation loss decreased (1.433387 --> 1.413981).  Saving model ...
Validation loss decreased (1.413981 --> 1.397822).  Saving model ...
Validation loss decreased (1.397822 --> 1.384927).  Saving model ...
Validation loss decreased (1.384927 --> 1.374721).  Saving model ...
Validation loss decreased (1.374721 --> 1.365957).  Saving model ...
Validation loss decreased (1.365957 --> 1.358616).  Saving model ...
Validation loss decreased (1.358616 --> 1.352624).  Saving model ...
Validation loss decreased (1.352624 --> 1.347371).  Saving model ...
Validation loss decreased (1.347371 --> 1.341487).  Saving model ...
Validation loss decreased (1.341487 --> 1.335491).  Saving model ...
Validation loss decreased (1.335491 --> 1.330084).  Saving model ...
Validation loss decreased (1.330084 --> 1.324555).  Saving model ...
Validation loss decreased (1.324555 --> 1.319240).  Saving model ...
Validation loss decreased (1.319240 --> 1.314237).  Saving model ...
Validation loss decreased (1.314237 --> 1.308590).  Saving model ...
Validation loss decreased (1.308590 --> 1.303107).  Saving model ...
Validation loss decreased (1.303107 --> 1.296859).  Saving model ...
Validation loss decreased (1.296859 --> 1.290189).  Saving model ...
Validation loss decreased (1.290189 --> 1.282792).  Saving model ...
Validation loss decreased (1.282792 --> 1.275819).  Saving model ...
Validation loss decreased (1.275819 --> 1.268752).  Saving model ...
Validation loss decreased (1.268752 --> 1.262562).  Saving model ...
Validation loss decreased (1.262562 --> 1.255516).  Saving model ...
Validation loss decreased (1.255516 --> 1.247164).  Saving model ...
Validation loss decreased (1.247164 --> 1.239761).  Saving model ...
Validation loss decreased (1.239761 --> 1.233390).  Saving model ...
Validation loss decreased (1.233390 --> 1.226658).  Saving model ...
Validation loss decreased (1.226658 --> 1.220915).  Saving model ...
Validation loss decreased (1.220915 --> 1.215830).  Saving model ...
Validation loss decreased (1.215830 --> 1.207669).  Saving model ...
Validation loss decreased (1.207669 --> 1.203214).  Saving model ...
Validation loss decreased (1.203214 --> 1.200058).  Saving model ...
Validation loss decreased (1.200058 --> 1.193948).  Saving model ...
Validation loss decreased (1.193948 --> 1.186832).  Saving model ...
Validation loss decreased (1.186832 --> 1.183043).  Saving model ...
Validation loss decreased (1.183043 --> 1.175233).  Saving model ...
Validation loss decreased (1.175233 --> 1.170703).  Saving model ...
Validation loss decreased (1.170703 --> 1.168870).  Saving model ...
Validation loss decreased (1.168870 --> 1.166053).  Saving model ...
Validation loss decreased (1.166053 --> 1.161387).  Saving model ...
Validation loss decreased (1.161387 --> 1.154649).  Saving model ...
Validation loss decreased (1.154649 --> 1.151328).  Saving model ...
Validation loss decreased (1.151328 --> 1.147662).  Saving model ...
Validation loss decreased (1.147662 --> 1.144545).  Saving model ...
Validation loss decreased (1.144545 --> 1.139429).  Saving model ...
Validation loss decreased (1.139429 --> 1.135583).  Saving model ...
Validation loss decreased (1.135583 --> 1.132313).  Saving model ...
Validation loss decreased (1.132313 --> 1.126347).  Saving model ...
Validation loss decreased (1.126347 --> 1.123219).  Saving model ...
Validation loss decreased (1.123219 --> 1.117370).  Saving model ...
Validation loss decreased (1.117370 --> 1.114682).  Saving model ...
Validation loss decreased (1.114682 --> 1.112565).  Saving model ...
Validation loss decreased (1.112565 --> 1.108434).  Saving model ...
EarlyStopping counter: 1 out of 3.0
Validation loss decreased (1.108434 --> 1.104441).  Saving model ...
Validation loss decreased (1.104441 --> 1.099149).  Saving model ...
Validation loss decreased (1.099149 --> 1.093575).  Saving model ...
Validation loss decreased (1.093575 --> 1.088544).  Saving model ...
EarlyStopping counter: 1 out of 3.0
Validation loss decreased (1.088544 --> 1.088525).  Saving model ...
Validation loss decreased (1.088525 --> 1.084370).  Saving model ...
Validation loss decreased (1.084370 --> 1.080092).  Saving model ...
Validation loss decreased (1.080092 --> 1.076291).  Saving model ...
Validation loss decreased (1.076291 --> 1.076033).  Saving model ...
Validation loss decreased (1.076033 --> 1.072529).  Saving model ...
Validation loss decreased (1.072529 --> 1.070793).  Saving model ...
Validation loss decreased (1.070793 --> 1.066482).  Saving model ...
Validation loss decreased (1.066482 --> 1.062048).  Saving model ...
Validation loss decreased (1.062048 --> 1.059040).  Saving model ...
Validation loss decreased (1.059040 --> 1.055943).  Saving model ...
Validation loss decreased (1.055943 --> 1.053744).  Saving model ...
Validation loss decreased (1.053744 --> 1.053065).  Saving model ...
Validation loss decreased (1.053065 --> 1.049087).  Saving model ...
Validation loss decreased (1.049087 --> 1.046876).  Saving model ...
Validation loss decreased (1.046876 --> 1.045297).  Saving model ...
Validation loss decreased (1.045297 --> 1.042906).  Saving model ...
Validation loss decreased (1.042906 --> 1.040165).  Saving model ...
Validation loss decreased (1.040165 --> 1.037659).  Saving model ...
Validation loss decreased (1.037659 --> 1.034924).  Saving model ...
EarlyStopping counter: 1 out of 3.0
EarlyStopping counter: 2 out of 3.0
EarlyStopping counter: 3 out of 3.0
/localscratch/yinan.29785217.0/env/lib/python3.7/site-packages/torch/nn/functional.py:1794: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.
  warnings.warn("nn.functional.tanh is deprecated. Use torch.tanh instead.")
/localscratch/yinan.29785217.0/env/lib/python3.7/site-packages/transformers/optimization.py:155: UserWarning: This overload of add_ is deprecated:
	add_(Number alpha, Tensor other)
Consider using one of the following signatures instead:
	add_(Tensor other, *, Number alpha) (Triggered internally at  ../torch/csrc/utils/python_arg_parser.cpp:1025.)
  exp_avg.mul_(beta1).add_(1.0 - beta1, grad)
wandb: Waiting for W&B process to finish, PID 42046... (success).
wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: \ 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: | 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: / 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: \ 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: | 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: / 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: \ 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: | 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: / 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb:                                                                                
wandb: Run history:
wandb:     e_F1 ▁▁▂▃▄▅▅▆▆▆▆▆▇▇▇▇▇▇▇▇▇▇▇▇▇▇██████████████
wandb:   e_loss █▇▇▇▆▆▆▆▆▅▅▅▅▄▄▄▄▄▃▃▃▃▃▃▂▂▂▂▂▂▂▂▂▁▁▁▁▁▁▁
wandb:     t_F1 ▁▁▂▃▂▃▃▃▃▄▅▄▅▅▅▆▆▅▆▆▆▆▆▇▆▇▆▇▇▇▇▇▇▇▇▇██▇█
wandb:   t_loss ██▇▇▇▇▇▇▇▆▆▆▅▅▅▅▅▄▄▄▄▄▄▃▃▃▃▃▂▃▂▂▂▂▂▁▂▁▂▁
wandb: 
wandb: Run summary:
wandb:     e_F1 56.25608
wandb:   e_loss 1.03523
wandb:     t_F1 66.78878
wandb:   t_loss 0.87448
wandb: 
wandb: Synced 4 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Synced lyric-mountain-2: https://wandb.ai/yinanazhou/xl_512_bs_8_lr_1e06_es_3_lc_True_nr_False_sr_False_stem_False_lemma_True_repeat_1_fold_1/runs/11k1h5r4
wandb: Find logs at: ./wandb/run-20220329_203322-11k1h5r4/logs/debug.log
wandb: 

wandb: wandb version 0.12.11 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
2022-03-29 21:28:13.810358: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1
wandb: Tracking run with wandb version 0.12.5
wandb: Syncing run autumn-paper-2
wandb: ⭐️ View project at https://wandb.ai/yinanazhou/xl_512_bs_8_lr_1e06_es_3_lc_True_nr_False_sr_False_stem_False_lemma_True_repeat_1_fold_2
wandb: 🚀 View run at https://wandb.ai/yinanazhou/xl_512_bs_8_lr_1e06_es_3_lc_True_nr_False_sr_False_stem_False_lemma_True_repeat_1_fold_2/runs/1p430xac
wandb: Run data is saved locally in /project/6002780/yinan/Thesis_MER_Lyrics/lyric-emotion/wandb/run-20220329_212811-1p430xac
wandb: Run `wandb offline` to turn off syncing.

Validation loss decreased (inf --> 1.479827).  Saving model ...
Validation loss decreased (1.479827 --> 1.446850).  Saving model ...
Validation loss decreased (1.446850 --> 1.420362).  Saving model ...
Validation loss decreased (1.420362 --> 1.401490).  Saving model ...
Validation loss decreased (1.401490 --> 1.387015).  Saving model ...
Validation loss decreased (1.387015 --> 1.376194).  Saving model ...
Validation loss decreased (1.376194 --> 1.367462).  Saving model ...
Validation loss decreased (1.367462 --> 1.359825).  Saving model ...
Validation loss decreased (1.359825 --> 1.353023).  Saving model ...
Validation loss decreased (1.353023 --> 1.347105).  Saving model ...
Validation loss decreased (1.347105 --> 1.342371).  Saving model ...
Validation loss decreased (1.342371 --> 1.337308).  Saving model ...
Validation loss decreased (1.337308 --> 1.332727).  Saving model ...
Validation loss decreased (1.332727 --> 1.327703).  Saving model ...
Validation loss decreased (1.327703 --> 1.322852).  Saving model ...
Validation loss decreased (1.322852 --> 1.317372).  Saving model ...
Validation loss decreased (1.317372 --> 1.311436).  Saving model ...
Validation loss decreased (1.311436 --> 1.305317).  Saving model ...
Validation loss decreased (1.305317 --> 1.300056).  Saving model ...
Validation loss decreased (1.300056 --> 1.294884).  Saving model ...
Validation loss decreased (1.294884 --> 1.288560).  Saving model ...
Validation loss decreased (1.288560 --> 1.281534).  Saving model ...
Validation loss decreased (1.281534 --> 1.274837).  Saving model ...
Validation loss decreased (1.274837 --> 1.268160).  Saving model ...
Validation loss decreased (1.268160 --> 1.261916).  Saving model ...
Validation loss decreased (1.261916 --> 1.255718).  Saving model ...
Validation loss decreased (1.255718 --> 1.249132).  Saving model ...
Validation loss decreased (1.249132 --> 1.243267).  Saving model ...
Validation loss decreased (1.243267 --> 1.236610).  Saving model ...
Validation loss decreased (1.236610 --> 1.230606).  Saving model ...
Validation loss decreased (1.230606 --> 1.224717).  Saving model ...
Validation loss decreased (1.224717 --> 1.218633).  Saving model ...
Validation loss decreased (1.218633 --> 1.212169).  Saving model ...
Validation loss decreased (1.212169 --> 1.205405).  Saving model ...
Validation loss decreased (1.205405 --> 1.202804).  Saving model ...
Validation loss decreased (1.202804 --> 1.196825).  Saving model ...
Validation loss decreased (1.196825 --> 1.191161).  Saving model ...
Validation loss decreased (1.191161 --> 1.183338).  Saving model ...
Validation loss decreased (1.183338 --> 1.177710).  Saving model ...
Validation loss decreased (1.177710 --> 1.172751).  Saving model ...
Validation loss decreased (1.172751 --> 1.167918).  Saving model ...
Validation loss decreased (1.167918 --> 1.161969).  Saving model ...
Validation loss decreased (1.161969 --> 1.156984).  Saving model ...
Validation loss decreased (1.156984 --> 1.147938).  Saving model ...
Validation loss decreased (1.147938 --> 1.142883).  Saving model ...
Validation loss decreased (1.142883 --> 1.138563).  Saving model ...
Validation loss decreased (1.138563 --> 1.130924).  Saving model ...
Validation loss decreased (1.130924 --> 1.125582).  Saving model ...
Validation loss decreased (1.125582 --> 1.121300).  Saving model ...
Validation loss decreased (1.121300 --> 1.115162).  Saving model ...
Validation loss decreased (1.115162 --> 1.110325).  Saving model ...
Validation loss decreased (1.110325 --> 1.104643).  Saving model ...
Validation loss decreased (1.104643 --> 1.097368).  Saving model ...
Validation loss decreased (1.097368 --> 1.093966).  Saving model ...
Validation loss decreased (1.093966 --> 1.090695).  Saving model ...
Validation loss decreased (1.090695 --> 1.086286).  Saving model ...
Validation loss decreased (1.086286 --> 1.079643).  Saving model ...
Validation loss decreased (1.079643 --> 1.072850).  Saving model ...
Validation loss decreased (1.072850 --> 1.069256).  Saving model ...
Validation loss decreased (1.069256 --> 1.064518).  Saving model ...
Validation loss decreased (1.064518 --> 1.057774).  Saving model ...
Validation loss decreased (1.057774 --> 1.053212).  Saving model ...
Validation loss decreased (1.053212 --> 1.051407).  Saving model ...
Validation loss decreased (1.051407 --> 1.045550).  Saving model ...
Validation loss decreased (1.045550 --> 1.042478).  Saving model ...
Validation loss decreased (1.042478 --> 1.037894).  Saving model ...
Validation loss decreased (1.037894 --> 1.035110).  Saving model ...
Validation loss decreased (1.035110 --> 1.032685).  Saving model ...
Validation loss decreased (1.032685 --> 1.026151).  Saving model ...
Validation loss decreased (1.026151 --> 1.021820).  Saving model ...
Validation loss decreased (1.021820 --> 1.017948).  Saving model ...
Validation loss decreased (1.017948 --> 1.015123).  Saving model ...
Validation loss decreased (1.015123 --> 1.010023).  Saving model ...
Validation loss decreased (1.010023 --> 1.005585).  Saving model ...
Validation loss decreased (1.005585 --> 1.002292).  Saving model ...
Validation loss decreased (1.002292 --> 0.999123).  Saving model ...
Validation loss decreased (0.999123 --> 0.996729).  Saving model ...
Validation loss decreased (0.996729 --> 0.991977).  Saving model ...
Validation loss decreased (0.991977 --> 0.990005).  Saving model ...
Validation loss decreased (0.990005 --> 0.988408).  Saving model ...
Validation loss decreased (0.988408 --> 0.986461).  Saving model ...
Validation loss decreased (0.986461 --> 0.982893).  Saving model ...
Validation loss decreased (0.982893 --> 0.980403).  Saving model ...
Validation loss decreased (0.980403 --> 0.978128).  Saving model ...
Validation loss decreased (0.978128 --> 0.976312).  Saving model ...
Validation loss decreased (0.976312 --> 0.971720).  Saving model ...
EarlyStopping counter: 1 out of 3.0
Validation loss decreased (0.971720 --> 0.970837).  Saving model ...
Validation loss decreased (0.970837 --> 0.966598).  Saving model ...
Validation loss decreased (0.966598 --> 0.964073).  Saving model ...
Validation loss decreased (0.964073 --> 0.963195).  Saving model ...
Validation loss decreased (0.963195 --> 0.961437).  Saving model ...
Validation loss decreased (0.961437 --> 0.958734).  Saving model ...
Validation loss decreased (0.958734 --> 0.955873).  Saving model ...
Validation loss decreased (0.955873 --> 0.953108).  Saving model ...
Validation loss decreased (0.953108 --> 0.950195).  Saving model ...
EarlyStopping counter: 1 out of 3.0
Validation loss decreased (0.950195 --> 0.947676).  Saving model ...
Validation loss decreased (0.947676 --> 0.945033).  Saving model ...
Validation loss decreased (0.945033 --> 0.942758).  Saving model ...
Validation loss decreased (0.942758 --> 0.941723).  Saving model ...
Validation loss decreased (0.941723 --> 0.940283).  Saving model ...
Validation loss decreased (0.940283 --> 0.938704).  Saving model ...
Validation loss decreased (0.938704 --> 0.936465).  Saving model ...
Validation loss decreased (0.936465 --> 0.935659).  Saving model ...
Validation loss decreased (0.935659 --> 0.934518).  Saving model ...
EarlyStopping counter: 1 out of 3.0
Validation loss decreased (0.934518 --> 0.932364).  Saving model ...
Validation loss decreased (0.932364 --> 0.931518).  Saving model ...
Validation loss decreased (0.931518 --> 0.930276).  Saving model ...
Validation loss decreased (0.930276 --> 0.929718).  Saving model ...
Validation loss decreased (0.929718 --> 0.928394).  Saving model ...
EarlyStopping counter: 1 out of 3.0
EarlyStopping counter: 2 out of 3.0
EarlyStopping counter: 3 out of 3.0
/localscratch/yinan.29785217.0/env/lib/python3.7/site-packages/torch/nn/functional.py:1794: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.
  warnings.warn("nn.functional.tanh is deprecated. Use torch.tanh instead.")
wandb: Waiting for W&B process to finish, PID 44980... (success).
wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: \ 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: | 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: / 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: \ 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: | 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: / 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: \ 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: | 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: / 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: \ 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: | 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb:                                                                                
wandb: Run history:
wandb:     e_F1 ▁▁▁▃▄▄▅▅▅▆▆▆▆▆▆▇▇▇▇▇████████████████████
wandb:   e_loss █▇▇▆▆▆▆▆▅▅▅▅▄▄▄▄▄▃▃▃▃▃▂▂▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁
wandb:     t_F1 ▁▁▂▃▃▃▄▄▅▅▅▅▆▅▆▆▆▆▆▇▇▇▇▇▇▇▇▇▇▇█▇▇█▇█████
wandb:   t_loss ██▇▇▇▇▆▆▆▆▅▅▅▅▅▅▅▄▄▄▄▄▃▃▃▃▃▃▃▂▂▂▂▂▂▁▁▁▂▁
wandb: 
wandb: Run summary:
wandb:     e_F1 60.09634
wandb:   e_loss 0.92991
wandb:     t_F1 69.29099
wandb:   t_loss 0.80752
wandb: 
wandb: Synced 4 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Synced autumn-paper-2: https://wandb.ai/yinanazhou/xl_512_bs_8_lr_1e06_es_3_lc_True_nr_False_sr_False_stem_False_lemma_True_repeat_1_fold_2/runs/1p430xac
wandb: Find logs at: ./wandb/run-20220329_212811-1p430xac/logs/debug.log
wandb: 

wandb: wandb version 0.12.11 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
2022-03-29 22:42:07.131750: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1
wandb: Tracking run with wandb version 0.12.5
wandb: Syncing run golden-spaceship-2
wandb: ⭐️ View project at https://wandb.ai/yinanazhou/xl_512_bs_8_lr_1e06_es_3_lc_True_nr_False_sr_False_stem_False_lemma_True_repeat_2_fold_1
wandb: 🚀 View run at https://wandb.ai/yinanazhou/xl_512_bs_8_lr_1e06_es_3_lc_True_nr_False_sr_False_stem_False_lemma_True_repeat_2_fold_1/runs/3n2dlbpe
wandb: Run data is saved locally in /project/6002780/yinan/Thesis_MER_Lyrics/lyric-emotion/wandb/run-20220329_224204-3n2dlbpe
wandb: Run `wandb offline` to turn off syncing.

Validation loss decreased (inf --> 1.491854).  Saving model ...
Validation loss decreased (1.491854 --> 1.456956).  Saving model ...
Validation loss decreased (1.456956 --> 1.430776).  Saving model ...
Validation loss decreased (1.430776 --> 1.409995).  Saving model ...
Validation loss decreased (1.409995 --> 1.393168).  Saving model ...
Validation loss decreased (1.393168 --> 1.379769).  Saving model ...
Validation loss decreased (1.379769 --> 1.369099).  Saving model ...
Validation loss decreased (1.369099 --> 1.360604).  Saving model ...
Validation loss decreased (1.360604 --> 1.353358).  Saving model ...
Validation loss decreased (1.353358 --> 1.346470).  Saving model ...
Validation loss decreased (1.346470 --> 1.340048).  Saving model ...
Validation loss decreased (1.340048 --> 1.334701).  Saving model ...
Validation loss decreased (1.334701 --> 1.329095).  Saving model ...
Validation loss decreased (1.329095 --> 1.323541).  Saving model ...
Validation loss decreased (1.323541 --> 1.318379).  Saving model ...
Validation loss decreased (1.318379 --> 1.313351).  Saving model ...
Validation loss decreased (1.313351 --> 1.308153).  Saving model ...
Validation loss decreased (1.308153 --> 1.303271).  Saving model ...
Validation loss decreased (1.303271 --> 1.298210).  Saving model ...
Validation loss decreased (1.298210 --> 1.292533).  Saving model ...
Validation loss decreased (1.292533 --> 1.287824).  Saving model ...
Validation loss decreased (1.287824 --> 1.281399).  Saving model ...
Validation loss decreased (1.281399 --> 1.275595).  Saving model ...
Validation loss decreased (1.275595 --> 1.268914).  Saving model ...
Validation loss decreased (1.268914 --> 1.262248).  Saving model ...
Validation loss decreased (1.262248 --> 1.255726).  Saving model ...
Validation loss decreased (1.255726 --> 1.249092).  Saving model ...
Validation loss decreased (1.249092 --> 1.241323).  Saving model ...
Validation loss decreased (1.241323 --> 1.233199).  Saving model ...
Validation loss decreased (1.233199 --> 1.226598).  Saving model ...
Validation loss decreased (1.226598 --> 1.217985).  Saving model ...
Validation loss decreased (1.217985 --> 1.211783).  Saving model ...
Validation loss decreased (1.211783 --> 1.205216).  Saving model ...
Validation loss decreased (1.205216 --> 1.197106).  Saving model ...
Validation loss decreased (1.197106 --> 1.189856).  Saving model ...
Validation loss decreased (1.189856 --> 1.183372).  Saving model ...
Validation loss decreased (1.183372 --> 1.175793).  Saving model ...
Validation loss decreased (1.175793 --> 1.169310).  Saving model ...
Validation loss decreased (1.169310 --> 1.161614).  Saving model ...
Validation loss decreased (1.161614 --> 1.154635).  Saving model ...
Validation loss decreased (1.154635 --> 1.148210).  Saving model ...
Validation loss decreased (1.148210 --> 1.140231).  Saving model ...
Validation loss decreased (1.140231 --> 1.133345).  Saving model ...
Validation loss decreased (1.133345 --> 1.125606).  Saving model ...
Validation loss decreased (1.125606 --> 1.121029).  Saving model ...
Validation loss decreased (1.121029 --> 1.115178).  Saving model ...
Validation loss decreased (1.115178 --> 1.108106).  Saving model ...
Validation loss decreased (1.108106 --> 1.102177).  Saving model ...
Validation loss decreased (1.102177 --> 1.097405).  Saving model ...
Validation loss decreased (1.097405 --> 1.092978).  Saving model ...
Validation loss decreased (1.092978 --> 1.089042).  Saving model ...
Validation loss decreased (1.089042 --> 1.083722).  Saving model ...
Validation loss decreased (1.083722 --> 1.078558).  Saving model ...
Validation loss decreased (1.078558 --> 1.072751).  Saving model ...
Validation loss decreased (1.072751 --> 1.065735).  Saving model ...
Validation loss decreased (1.065735 --> 1.063348).  Saving model ...
Validation loss decreased (1.063348 --> 1.058828).  Saving model ...
Validation loss decreased (1.058828 --> 1.054896).  Saving model ...
Validation loss decreased (1.054896 --> 1.050326).  Saving model ...
Validation loss decreased (1.050326 --> 1.046951).  Saving model ...
Validation loss decreased (1.046951 --> 1.042297).  Saving model ...
Validation loss decreased (1.042297 --> 1.038811).  Saving model ...
Validation loss decreased (1.038811 --> 1.034323).  Saving model ...
Validation loss decreased (1.034323 --> 1.031591).  Saving model ...
Validation loss decreased (1.031591 --> 1.029283).  Saving model ...
Validation loss decreased (1.029283 --> 1.026632).  Saving model ...
Validation loss decreased (1.026632 --> 1.022469).  Saving model ...
Validation loss decreased (1.022469 --> 1.018967).  Saving model ...
Validation loss decreased (1.018967 --> 1.015654).  Saving model ...
Validation loss decreased (1.015654 --> 1.012332).  Saving model ...
Validation loss decreased (1.012332 --> 1.010043).  Saving model ...
Validation loss decreased (1.010043 --> 1.007027).  Saving model ...
Validation loss decreased (1.007027 --> 1.005943).  Saving model ...
Validation loss decreased (1.005943 --> 1.001619).  Saving model ...
Validation loss decreased (1.001619 --> 0.997846).  Saving model ...
Validation loss decreased (0.997846 --> 0.996808).  Saving model ...
Validation loss decreased (0.996808 --> 0.995016).  Saving model ...
Validation loss decreased (0.995016 --> 0.992102).  Saving model ...
Validation loss decreased (0.992102 --> 0.989149).  Saving model ...
Validation loss decreased (0.989149 --> 0.987796).  Saving model ...
Validation loss decreased (0.987796 --> 0.985675).  Saving model ...
Validation loss decreased (0.985675 --> 0.983752).  Saving model ...
Validation loss decreased (0.983752 --> 0.981713).  Saving model ...
Validation loss decreased (0.981713 --> 0.980888).  Saving model ...
Validation loss decreased (0.980888 --> 0.978849).  Saving model ...
Validation loss decreased (0.978849 --> 0.976474).  Saving model ...
Validation loss decreased (0.976474 --> 0.974283).  Saving model ...
Validation loss decreased (0.974283 --> 0.973110).  Saving model ...
Validation loss decreased (0.973110 --> 0.972740).  Saving model ...
Validation loss decreased (0.972740 --> 0.970437).  Saving model ...
Validation loss decreased (0.970437 --> 0.967433).  Saving model ...
Validation loss decreased (0.967433 --> 0.965970).  Saving model ...
Validation loss decreased (0.965970 --> 0.965438).  Saving model ...
Validation loss decreased (0.965438 --> 0.965414).  Saving model ...
Validation loss decreased (0.965414 --> 0.962961).  Saving model ...
Validation loss decreased (0.962961 --> 0.962763).  Saving model ...
Validation loss decreased (0.962763 --> 0.960246).  Saving model ...
Validation loss decreased (0.960246 --> 0.958859).  Saving model ...
Validation loss decreased (0.958859 --> 0.958583).  Saving model ...
Validation loss decreased (0.958583 --> 0.958024).  Saving model ...
Validation loss decreased (0.958024 --> 0.957888).  Saving model ...
Validation loss decreased (0.957888 --> 0.956353).  Saving model ...
Validation loss decreased (0.956353 --> 0.955177).  Saving model ...
Validation loss decreased (0.955177 --> 0.954668).  Saving model ...
Validation loss decreased (0.954668 --> 0.953487).  Saving model ...
Validation loss decreased (0.953487 --> 0.952526).  Saving model ...
Validation loss decreased (0.952526 --> 0.951736).  Saving model ...
Validation loss decreased (0.951736 --> 0.950639).  Saving model ...
Validation loss decreased (0.950639 --> 0.950093).  Saving model ...
Validation loss decreased (0.950093 --> 0.949229).  Saving model ...
Validation loss decreased (0.949229 --> 0.948971).  Saving model ...
EarlyStopping counter: 1 out of 3.0
EarlyStopping counter: 2 out of 3.0
Validation loss decreased (0.948971 --> 0.948813).  Saving model ...
Validation loss decreased (0.948813 --> 0.948773).  Saving model ...
Validation loss decreased (0.948773 --> 0.948324).  Saving model ...
Validation loss decreased (0.948324 --> 0.947785).  Saving model ...
EarlyStopping counter: 1 out of 3.0
EarlyStopping counter: 2 out of 3.0
EarlyStopping counter: 3 out of 3.0
/localscratch/yinan.29785217.0/env/lib/python3.7/site-packages/torch/nn/functional.py:1794: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.
  warnings.warn("nn.functional.tanh is deprecated. Use torch.tanh instead.")
wandb: Waiting for W&B process to finish, PID 48909... (success).
wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: \ 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: | 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: / 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: \ 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: | 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: / 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: \ 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: | 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: / 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb:                                                                                
wandb: Run history:
wandb:     e_F1 ▁▂▂▄▄▅▅▅▆▆▆▆▆▇▇▇▇▇██████████████████████
wandb:   e_loss █▇▆▆▆▆▆▅▅▅▄▄▄▄▃▃▃▃▃▂▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:     t_F1 ▁▂▂▃▃▃▃▄▄▄▅▅▆▆▆▆▆▆▇▇▆▆▇▇▇▇█▇█▇▇▇▇██▇█▇██
wandb:   t_loss █▇▇▇▆▆▆▆▆▆▅▅▅▅▄▄▄▄▃▃▃▃▃▃▃▃▂▂▂▂▂▂▂▂▂▂▂▁▁▁
wandb: 
wandb: Run summary:
wandb:     e_F1 58.48191
wandb:   e_loss 0.94914
wandb:     t_F1 70.09086
wandb:   t_loss 0.76679
wandb: 
wandb: Synced 4 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Synced golden-spaceship-2: https://wandb.ai/yinanazhou/xl_512_bs_8_lr_1e06_es_3_lc_True_nr_False_sr_False_stem_False_lemma_True_repeat_2_fold_1/runs/3n2dlbpe
wandb: Find logs at: ./wandb/run-20220329_224204-3n2dlbpe/logs/debug.log
wandb: 

wandb: wandb version 0.12.11 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
2022-03-29 23:59:20.285223: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1
wandb: Tracking run with wandb version 0.12.5
wandb: Syncing run rose-energy-2
wandb: ⭐️ View project at https://wandb.ai/yinanazhou/xl_512_bs_8_lr_1e06_es_3_lc_True_nr_False_sr_False_stem_False_lemma_True_repeat_2_fold_2
wandb: 🚀 View run at https://wandb.ai/yinanazhou/xl_512_bs_8_lr_1e06_es_3_lc_True_nr_False_sr_False_stem_False_lemma_True_repeat_2_fold_2/runs/q1hrmh52
wandb: Run data is saved locally in /project/6002780/yinan/Thesis_MER_Lyrics/lyric-emotion/wandb/run-20220329_235918-q1hrmh52
wandb: Run `wandb offline` to turn off syncing.

Validation loss decreased (inf --> 1.397767).  Saving model ...
Validation loss decreased (1.397767 --> 1.389790).  Saving model ...
Validation loss decreased (1.389790 --> 1.383778).  Saving model ...
Validation loss decreased (1.383778 --> 1.378600).  Saving model ...
Validation loss decreased (1.378600 --> 1.374273).  Saving model ...
Validation loss decreased (1.374273 --> 1.370354).  Saving model ...
Validation loss decreased (1.370354 --> 1.367282).  Saving model ...
Validation loss decreased (1.367282 --> 1.363953).  Saving model ...
Validation loss decreased (1.363953 --> 1.360666).  Saving model ...
Validation loss decreased (1.360666 --> 1.357261).  Saving model ...
Validation loss decreased (1.357261 --> 1.354115).  Saving model ...
Validation loss decreased (1.354115 --> 1.351087).  Saving model ...
Validation loss decreased (1.351087 --> 1.347670).  Saving model ...
Validation loss decreased (1.347670 --> 1.344503).  Saving model ...
Validation loss decreased (1.344503 --> 1.341122).  Saving model ...
Validation loss decreased (1.341122 --> 1.337674).  Saving model ...
Validation loss decreased (1.337674 --> 1.333831).  Saving model ...
Validation loss decreased (1.333831 --> 1.329786).  Saving model ...
Validation loss decreased (1.329786 --> 1.325752).  Saving model ...
Validation loss decreased (1.325752 --> 1.321393).  Saving model ...
Validation loss decreased (1.321393 --> 1.317870).  Saving model ...
Validation loss decreased (1.317870 --> 1.313707).  Saving model ...
Validation loss decreased (1.313707 --> 1.308620).  Saving model ...
Validation loss decreased (1.308620 --> 1.303902).  Saving model ...
Validation loss decreased (1.303902 --> 1.298387).  Saving model ...
Validation loss decreased (1.298387 --> 1.292593).  Saving model ...
Validation loss decreased (1.292593 --> 1.286388).  Saving model ...
Validation loss decreased (1.286388 --> 1.280618).  Saving model ...
Validation loss decreased (1.280618 --> 1.274256).  Saving model ...
Validation loss decreased (1.274256 --> 1.267972).  Saving model ...
Validation loss decreased (1.267972 --> 1.260275).  Saving model ...
Validation loss decreased (1.260275 --> 1.253431).  Saving model ...
Validation loss decreased (1.253431 --> 1.245192).  Saving model ...
Validation loss decreased (1.245192 --> 1.237794).  Saving model ...
Validation loss decreased (1.237794 --> 1.232211).  Saving model ...
Validation loss decreased (1.232211 --> 1.223218).  Saving model ...
Validation loss decreased (1.223218 --> 1.216309).  Saving model ...
Validation loss decreased (1.216309 --> 1.210382).  Saving model ...
Validation loss decreased (1.210382 --> 1.202434).  Saving model ...
Validation loss decreased (1.202434 --> 1.195132).  Saving model ...
Validation loss decreased (1.195132 --> 1.189209).  Saving model ...
Validation loss decreased (1.189209 --> 1.181415).  Saving model ...
Validation loss decreased (1.181415 --> 1.174902).  Saving model ...
Validation loss decreased (1.174902 --> 1.170079).  Saving model ...
Validation loss decreased (1.170079 --> 1.163083).  Saving model ...
Validation loss decreased (1.163083 --> 1.157111).  Saving model ...
Validation loss decreased (1.157111 --> 1.150165).  Saving model ...
Validation loss decreased (1.150165 --> 1.145334).  Saving model ...
Validation loss decreased (1.145334 --> 1.139449).  Saving model ...
Validation loss decreased (1.139449 --> 1.132778).  Saving model ...
Validation loss decreased (1.132778 --> 1.127672).  Saving model ...
Validation loss decreased (1.127672 --> 1.122490).  Saving model ...
Validation loss decreased (1.122490 --> 1.120093).  Saving model ...
Validation loss decreased (1.120093 --> 1.116743).  Saving model ...
Validation loss decreased (1.116743 --> 1.111085).  Saving model ...
Validation loss decreased (1.111085 --> 1.104702).  Saving model ...
Validation loss decreased (1.104702 --> 1.101625).  Saving model ...
Validation loss decreased (1.101625 --> 1.096178).  Saving model ...
Validation loss decreased (1.096178 --> 1.091515).  Saving model ...
Validation loss decreased (1.091515 --> 1.086460).  Saving model ...
Validation loss decreased (1.086460 --> 1.082877).  Saving model ...
Validation loss decreased (1.082877 --> 1.080220).  Saving model ...
Validation loss decreased (1.080220 --> 1.078150).  Saving model ...
Validation loss decreased (1.078150 --> 1.072993).  Saving model ...
Validation loss decreased (1.072993 --> 1.069399).  Saving model ...
Validation loss decreased (1.069399 --> 1.064858).  Saving model ...
Validation loss decreased (1.064858 --> 1.060896).  Saving model ...
Validation loss decreased (1.060896 --> 1.057621).  Saving model ...
Validation loss decreased (1.057621 --> 1.055502).  Saving model ...
Validation loss decreased (1.055502 --> 1.051432).  Saving model ...
Validation loss decreased (1.051432 --> 1.046317).  Saving model ...
Validation loss decreased (1.046317 --> 1.041523).  Saving model ...
Validation loss decreased (1.041523 --> 1.039743).  Saving model ...
Validation loss decreased (1.039743 --> 1.037535).  Saving model ...
Validation loss decreased (1.037535 --> 1.035520).  Saving model ...
Validation loss decreased (1.035520 --> 1.034319).  Saving model ...
Validation loss decreased (1.034319 --> 1.031186).  Saving model ...
Validation loss decreased (1.031186 --> 1.027525).  Saving model ...
Validation loss decreased (1.027525 --> 1.023252).  Saving model ...
Validation loss decreased (1.023252 --> 1.020961).  Saving model ...
Validation loss decreased (1.020961 --> 1.018328).  Saving model ...
Validation loss decreased (1.018328 --> 1.014507).  Saving model ...
Validation loss decreased (1.014507 --> 1.012159).  Saving model ...
Validation loss decreased (1.012159 --> 1.010097).  Saving model ...
Validation loss decreased (1.010097 --> 1.007316).  Saving model ...
Validation loss decreased (1.007316 --> 1.006150).  Saving model ...
Validation loss decreased (1.006150 --> 1.001729).  Saving model ...
Validation loss decreased (1.001729 --> 0.998994).  Saving model ...
Validation loss decreased (0.998994 --> 0.995102).  Saving model ...
Validation loss decreased (0.995102 --> 0.992207).  Saving model ...
Validation loss decreased (0.992207 --> 0.990732).  Saving model ...
Validation loss decreased (0.990732 --> 0.989968).  Saving model ...
Validation loss decreased (0.989968 --> 0.987740).  Saving model ...
Validation loss decreased (0.987740 --> 0.985810).  Saving model ...
Validation loss decreased (0.985810 --> 0.983832).  Saving model ...
Validation loss decreased (0.983832 --> 0.982105).  Saving model ...
Validation loss decreased (0.982105 --> 0.980007).  Saving model ...
Validation loss decreased (0.980007 --> 0.976762).  Saving model ...
Validation loss decreased (0.976762 --> 0.976546).  Saving model ...
Validation loss decreased (0.976546 --> 0.973788).  Saving model ...
Validation loss decreased (0.973788 --> 0.973125).  Saving model ...
Validation loss decreased (0.973125 --> 0.970128).  Saving model ...
Validation loss decreased (0.970128 --> 0.967968).  Saving model ...
EarlyStopping counter: 1 out of 3.0
Validation loss decreased (0.967968 --> 0.967469).  Saving model ...
Validation loss decreased (0.967469 --> 0.964719).  Saving model ...
Validation loss decreased (0.964719 --> 0.964145).  Saving model ...
Validation loss decreased (0.964145 --> 0.961550).  Saving model ...
Validation loss decreased (0.961550 --> 0.960729).  Saving model ...
Validation loss decreased (0.960729 --> 0.960139).  Saving model ...
Validation loss decreased (0.960139 --> 0.958817).  Saving model ...
Validation loss decreased (0.958817 --> 0.958358).  Saving model ...
Validation loss decreased (0.958358 --> 0.956287).  Saving model ...
Validation loss decreased (0.956287 --> 0.954365).  Saving model ...
Validation loss decreased (0.954365 --> 0.953730).  Saving model ...
Validation loss decreased (0.953730 --> 0.953051).  Saving model ...
EarlyStopping counter: 1 out of 3.0
Validation loss decreased (0.953051 --> 0.951114).  Saving model ...
Validation loss decreased (0.951114 --> 0.950885).  Saving model ...
Validation loss decreased (0.950885 --> 0.949173).  Saving model ...
EarlyStopping counter: 1 out of 3.0
Validation loss decreased (0.949173 --> 0.948984).  Saving model ...
EarlyStopping counter: 1 out of 3.0
Validation loss decreased (0.948984 --> 0.947846).  Saving model ...
EarlyStopping counter: 1 out of 3.0
EarlyStopping counter: 2 out of 3.0
EarlyStopping counter: 3 out of 3.0
/localscratch/yinan.29785217.0/env/lib/python3.7/site-packages/torch/nn/functional.py:1794: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.
  warnings.warn("nn.functional.tanh is deprecated. Use torch.tanh instead.")
wandb: Waiting for W&B process to finish, PID 52989... (success).
wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: \ 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: | 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: / 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: \ 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: | 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: / 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: \ 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: | 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: / 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb:                                                                                
wandb: Run history:
wandb:     e_F1 ▁▃▄▄▄▄▄▄▄▄▅▅▅▅▆▆▆▆▇▇▇▇▇▇▇███████████████
wandb:   e_loss ███▇▇▇▇▇▆▆▆▅▅▅▄▄▄▄▃▃▃▃▂▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁
wandb:     t_F1 ▁▂▃▃▃▃▄▄▄▅▅▅▅▅▆▆▆▆▆▆▆▆▇▆▇▇▇▇▇▇▇▇▇███████
wandb:   t_loss ██▇▇▇▇▇▇▇▆▆▆▅▅▅▅▅▄▄▄▄▄▃▃▃▃▃▂▃▂▂▂▂▂▂▁▂▁▁▁
wandb: 
wandb: Run summary:
wandb:     e_F1 59.74522
wandb:   e_loss 0.94814
wandb:     t_F1 69.5549
wandb:   t_loss 0.78718
wandb: 
wandb: Synced 4 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Synced rose-energy-2: https://wandb.ai/yinanazhou/xl_512_bs_8_lr_1e06_es_3_lc_True_nr_False_sr_False_stem_False_lemma_True_repeat_2_fold_2/runs/q1hrmh52
wandb: Find logs at: ./wandb/run-20220329_235918-q1hrmh52/logs/debug.log
wandb: 

wandb: wandb version 0.12.11 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
2022-03-30 01:23:15.108556: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1
wandb: Tracking run with wandb version 0.12.5
wandb: Syncing run sweet-glitter-2
wandb: ⭐️ View project at https://wandb.ai/yinanazhou/xl_512_bs_8_lr_1e06_es_3_lc_True_nr_False_sr_False_stem_False_lemma_True_repeat_3_fold_1
wandb: 🚀 View run at https://wandb.ai/yinanazhou/xl_512_bs_8_lr_1e06_es_3_lc_True_nr_False_sr_False_stem_False_lemma_True_repeat_3_fold_1/runs/3lef1ow1
wandb: Run data is saved locally in /project/6002780/yinan/Thesis_MER_Lyrics/lyric-emotion/wandb/run-20220330_012312-3lef1ow1
wandb: Run `wandb offline` to turn off syncing.

Validation loss decreased (inf --> 1.451528).  Saving model ...
Validation loss decreased (1.451528 --> 1.430215).  Saving model ...
Validation loss decreased (1.430215 --> 1.413667).  Saving model ...
Validation loss decreased (1.413667 --> 1.401395).  Saving model ...
Validation loss decreased (1.401395 --> 1.391281).  Saving model ...
Validation loss decreased (1.391281 --> 1.382942).  Saving model ...
Validation loss decreased (1.382942 --> 1.375397).  Saving model ...
Validation loss decreased (1.375397 --> 1.369204).  Saving model ...
Validation loss decreased (1.369204 --> 1.363715).  Saving model ...
Validation loss decreased (1.363715 --> 1.358621).  Saving model ...
Validation loss decreased (1.358621 --> 1.353779).  Saving model ...
Validation loss decreased (1.353779 --> 1.349316).  Saving model ...
Validation loss decreased (1.349316 --> 1.344667).  Saving model ...
Validation loss decreased (1.344667 --> 1.339634).  Saving model ...
Validation loss decreased (1.339634 --> 1.334531).  Saving model ...
Validation loss decreased (1.334531 --> 1.329742).  Saving model ...
Validation loss decreased (1.329742 --> 1.324699).  Saving model ...
Validation loss decreased (1.324699 --> 1.318175).  Saving model ...
Validation loss decreased (1.318175 --> 1.312715).  Saving model ...
Validation loss decreased (1.312715 --> 1.305654).  Saving model ...
Validation loss decreased (1.305654 --> 1.299279).  Saving model ...
Validation loss decreased (1.299279 --> 1.292477).  Saving model ...
Validation loss decreased (1.292477 --> 1.285652).  Saving model ...
Validation loss decreased (1.285652 --> 1.277239).  Saving model ...
Validation loss decreased (1.277239 --> 1.269117).  Saving model ...
Validation loss decreased (1.269117 --> 1.261388).  Saving model ...
Validation loss decreased (1.261388 --> 1.251564).  Saving model ...
Validation loss decreased (1.251564 --> 1.243365).  Saving model ...
Validation loss decreased (1.243365 --> 1.234879).  Saving model ...
Validation loss decreased (1.234879 --> 1.226352).  Saving model ...
Validation loss decreased (1.226352 --> 1.218246).  Saving model ...
Validation loss decreased (1.218246 --> 1.209198).  Saving model ...
Validation loss decreased (1.209198 --> 1.200031).  Saving model ...
Validation loss decreased (1.200031 --> 1.191150).  Saving model ...
Validation loss decreased (1.191150 --> 1.184347).  Saving model ...
Validation loss decreased (1.184347 --> 1.176689).  Saving model ...
Validation loss decreased (1.176689 --> 1.168189).  Saving model ...
Validation loss decreased (1.168189 --> 1.161921).  Saving model ...
Validation loss decreased (1.161921 --> 1.154960).  Saving model ...
Validation loss decreased (1.154960 --> 1.148934).  Saving model ...
Validation loss decreased (1.148934 --> 1.141865).  Saving model ...
Validation loss decreased (1.141865 --> 1.132410).  Saving model ...
Validation loss decreased (1.132410 --> 1.127939).  Saving model ...
Validation loss decreased (1.127939 --> 1.120422).  Saving model ...
Validation loss decreased (1.120422 --> 1.114598).  Saving model ...
Validation loss decreased (1.114598 --> 1.109672).  Saving model ...
Validation loss decreased (1.109672 --> 1.103526).  Saving model ...
Validation loss decreased (1.103526 --> 1.097400).  Saving model ...
Validation loss decreased (1.097400 --> 1.094093).  Saving model ...
Validation loss decreased (1.094093 --> 1.088873).  Saving model ...
Validation loss decreased (1.088873 --> 1.082894).  Saving model ...
Validation loss decreased (1.082894 --> 1.077189).  Saving model ...
Validation loss decreased (1.077189 --> 1.073355).  Saving model ...
Validation loss decreased (1.073355 --> 1.068351).  Saving model ...
Validation loss decreased (1.068351 --> 1.064343).  Saving model ...
Validation loss decreased (1.064343 --> 1.060438).  Saving model ...
Validation loss decreased (1.060438 --> 1.057680).  Saving model ...
Validation loss decreased (1.057680 --> 1.053698).  Saving model ...
Validation loss decreased (1.053698 --> 1.048295).  Saving model ...
Validation loss decreased (1.048295 --> 1.044181).  Saving model ...
Validation loss decreased (1.044181 --> 1.040905).  Saving model ...
Validation loss decreased (1.040905 --> 1.037682).  Saving model ...
Validation loss decreased (1.037682 --> 1.034065).  Saving model ...
Validation loss decreased (1.034065 --> 1.031631).  Saving model ...
Validation loss decreased (1.031631 --> 1.027098).  Saving model ...
Validation loss decreased (1.027098 --> 1.023469).  Saving model ...
Validation loss decreased (1.023469 --> 1.019356).  Saving model ...
Validation loss decreased (1.019356 --> 1.014430).  Saving model ...
Validation loss decreased (1.014430 --> 1.010971).  Saving model ...
Validation loss decreased (1.010971 --> 1.008915).  Saving model ...
Validation loss decreased (1.008915 --> 1.004406).  Saving model ...
Validation loss decreased (1.004406 --> 1.001601).  Saving model ...
Validation loss decreased (1.001601 --> 0.998484).  Saving model ...
Validation loss decreased (0.998484 --> 0.996582).  Saving model ...
Validation loss decreased (0.996582 --> 0.992321).  Saving model ...
Validation loss decreased (0.992321 --> 0.990061).  Saving model ...
Validation loss decreased (0.990061 --> 0.987615).  Saving model ...
Validation loss decreased (0.987615 --> 0.985454).  Saving model ...
Validation loss decreased (0.985454 --> 0.983376).  Saving model ...
Validation loss decreased (0.983376 --> 0.980098).  Saving model ...
Validation loss decreased (0.980098 --> 0.978204).  Saving model ...
Validation loss decreased (0.978204 --> 0.976688).  Saving model ...
Validation loss decreased (0.976688 --> 0.973386).  Saving model ...
Validation loss decreased (0.973386 --> 0.971349).  Saving model ...
Validation loss decreased (0.971349 --> 0.968893).  Saving model ...
Validation loss decreased (0.968893 --> 0.967504).  Saving model ...
Validation loss decreased (0.967504 --> 0.966689).  Saving model ...
Validation loss decreased (0.966689 --> 0.964229).  Saving model ...
Validation loss decreased (0.964229 --> 0.963098).  Saving model ...
Validation loss decreased (0.963098 --> 0.960814).  Saving model ...
Validation loss decreased (0.960814 --> 0.958854).  Saving model ...
Validation loss decreased (0.958854 --> 0.958411).  Saving model ...
Validation loss decreased (0.958411 --> 0.957019).  Saving model ...
Validation loss decreased (0.957019 --> 0.955326).  Saving model ...
Validation loss decreased (0.955326 --> 0.953053).  Saving model ...
Validation loss decreased (0.953053 --> 0.951995).  Saving model ...
EarlyStopping counter: 1 out of 3.0
Validation loss decreased (0.951995 --> 0.949590).  Saving model ...
Validation loss decreased (0.949590 --> 0.948030).  Saving model ...
EarlyStopping counter: 1 out of 3.0
Validation loss decreased (0.948030 --> 0.947219).  Saving model ...
Validation loss decreased (0.947219 --> 0.945588).  Saving model ...
EarlyStopping counter: 1 out of 3.0
Validation loss decreased (0.945588 --> 0.944895).  Saving model ...
Validation loss decreased (0.944895 --> 0.942131).  Saving model ...
Validation loss decreased (0.942131 --> 0.941886).  Saving model ...
Validation loss decreased (0.941886 --> 0.940014).  Saving model ...
EarlyStopping counter: 1 out of 3.0
Validation loss decreased (0.940014 --> 0.939251).  Saving model ...
EarlyStopping counter: 1 out of 3.0
EarlyStopping counter: 2 out of 3.0
Validation loss decreased (0.939251 --> 0.938834).  Saving model ...
Validation loss decreased (0.938834 --> 0.937677).  Saving model ...
Validation loss decreased (0.937677 --> 0.936645).  Saving model ...
Validation loss decreased (0.936645 --> 0.936329).  Saving model ...
Validation loss decreased (0.936329 --> 0.936314).  Saving model ...
Validation loss decreased (0.936314 --> 0.936109).  Saving model ...
Validation loss decreased (0.936109 --> 0.936013).  Saving model ...
EarlyStopping counter: 1 out of 3.0
EarlyStopping counter: 2 out of 3.0
EarlyStopping counter: 3 out of 3.0
/localscratch/yinan.29785217.0/env/lib/python3.7/site-packages/torch/nn/functional.py:1794: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.
  warnings.warn("nn.functional.tanh is deprecated. Use torch.tanh instead.")
wandb: Waiting for W&B process to finish, PID 57520... (success).
wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: \ 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: | 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: / 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: \ 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: | 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: / 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: \ 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: | 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: / 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: \ 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb:                                                                                
wandb: Run history:
wandb:     e_F1 ▁▁▃▃▃▄▄▅▆▆▆▇▇▇▇▇▇▇▇▇█▇██████████████████
wandb:   e_loss █▇▇▇▇▆▆▆▆▅▅▄▄▄▄▃▃▃▃▃▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:     t_F1 ▁▂▂▂▃▃▃▃▄▄▅▅▅▆▆▆▆▆▆▆▆▇▆▇▇▇▇▇▇▇▇███▇██▇██
wandb:   t_loss █▇▇▇▇▇▆▆▆▆▅▅▅▅▅▄▄▄▃▃▃▃▃▃▃▂▂▂▂▂▂▂▂▁▂▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:     e_F1 59.70719
wandb:   e_loss 0.93646
wandb:     t_F1 71.64073
wandb:   t_loss 0.78791
wandb: 
wandb: Synced 4 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Synced sweet-glitter-2: https://wandb.ai/yinanazhou/xl_512_bs_8_lr_1e06_es_3_lc_True_nr_False_sr_False_stem_False_lemma_True_repeat_3_fold_1/runs/3lef1ow1
wandb: Find logs at: ./wandb/run-20220330_012312-3lef1ow1/logs/debug.log
wandb: 

wandb: wandb version 0.12.11 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
2022-03-30 02:41:50.350072: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1
wandb: Tracking run with wandb version 0.12.5
wandb: Syncing run sandy-bird-2
wandb: ⭐️ View project at https://wandb.ai/yinanazhou/xl_512_bs_8_lr_1e06_es_3_lc_True_nr_False_sr_False_stem_False_lemma_True_repeat_3_fold_2
wandb: 🚀 View run at https://wandb.ai/yinanazhou/xl_512_bs_8_lr_1e06_es_3_lc_True_nr_False_sr_False_stem_False_lemma_True_repeat_3_fold_2/runs/2b4sfrmt
wandb: Run data is saved locally in /project/6002780/yinan/Thesis_MER_Lyrics/lyric-emotion/wandb/run-20220330_024147-2b4sfrmt
wandb: Run `wandb offline` to turn off syncing.

Validation loss decreased (inf --> 1.438311).  Saving model ...
Validation loss decreased (1.438311 --> 1.420695).  Saving model ...
Validation loss decreased (1.420695 --> 1.405781).  Saving model ...
Validation loss decreased (1.405781 --> 1.393577).  Saving model ...
Validation loss decreased (1.393577 --> 1.383155).  Saving model ...
Validation loss decreased (1.383155 --> 1.374298).  Saving model ...
Validation loss decreased (1.374298 --> 1.367669).  Saving model ...
Validation loss decreased (1.367669 --> 1.361459).  Saving model ...
Validation loss decreased (1.361459 --> 1.355731).  Saving model ...
Validation loss decreased (1.355731 --> 1.350545).  Saving model ...
Validation loss decreased (1.350545 --> 1.345537).  Saving model ...
Validation loss decreased (1.345537 --> 1.339516).  Saving model ...
Validation loss decreased (1.339516 --> 1.334096).  Saving model ...
Validation loss decreased (1.334096 --> 1.328509).  Saving model ...
Validation loss decreased (1.328509 --> 1.323452).  Saving model ...
Validation loss decreased (1.323452 --> 1.317808).  Saving model ...
Validation loss decreased (1.317808 --> 1.311364).  Saving model ...
Validation loss decreased (1.311364 --> 1.304466).  Saving model ...
Validation loss decreased (1.304466 --> 1.298313).  Saving model ...
Validation loss decreased (1.298313 --> 1.291281).  Saving model ...
Validation loss decreased (1.291281 --> 1.284415).  Saving model ...
Validation loss decreased (1.284415 --> 1.276768).  Saving model ...
Validation loss decreased (1.276768 --> 1.268839).  Saving model ...
Validation loss decreased (1.268839 --> 1.261840).  Saving model ...
Validation loss decreased (1.261840 --> 1.254111).  Saving model ...
Validation loss decreased (1.254111 --> 1.247105).  Saving model ...
Validation loss decreased (1.247105 --> 1.239014).  Saving model ...
Validation loss decreased (1.239014 --> 1.231133).  Saving model ...
Validation loss decreased (1.231133 --> 1.223700).  Saving model ...
Validation loss decreased (1.223700 --> 1.215797).  Saving model ...
Validation loss decreased (1.215797 --> 1.208129).  Saving model ...
Validation loss decreased (1.208129 --> 1.200549).  Saving model ...
Validation loss decreased (1.200549 --> 1.193271).  Saving model ...
Validation loss decreased (1.193271 --> 1.185939).  Saving model ...
Validation loss decreased (1.185939 --> 1.178558).  Saving model ...
Validation loss decreased (1.178558 --> 1.170548).  Saving model ...
Validation loss decreased (1.170548 --> 1.165163).  Saving model ...
Validation loss decreased (1.165163 --> 1.158843).  Saving model ...
Validation loss decreased (1.158843 --> 1.152814).  Saving model ...
Validation loss decreased (1.152814 --> 1.146628).  Saving model ...
Validation loss decreased (1.146628 --> 1.140157).  Saving model ...
Validation loss decreased (1.140157 --> 1.134569).  Saving model ...
Validation loss decreased (1.134569 --> 1.128228).  Saving model ...
Validation loss decreased (1.128228 --> 1.122693).  Saving model ...
Validation loss decreased (1.122693 --> 1.117605).  Saving model ...
Validation loss decreased (1.117605 --> 1.113228).  Saving model ...
Validation loss decreased (1.113228 --> 1.106184).  Saving model ...
Validation loss decreased (1.106184 --> 1.101292).  Saving model ...
Validation loss decreased (1.101292 --> 1.095923).  Saving model ...
Validation loss decreased (1.095923 --> 1.090440).  Saving model ...
Validation loss decreased (1.090440 --> 1.086193).  Saving model ...
Validation loss decreased (1.086193 --> 1.081840).  Saving model ...
Validation loss decreased (1.081840 --> 1.076696).  Saving model ...
Validation loss decreased (1.076696 --> 1.071952).  Saving model ...
Validation loss decreased (1.071952 --> 1.067722).  Saving model ...
Validation loss decreased (1.067722 --> 1.063757).  Saving model ...
Validation loss decreased (1.063757 --> 1.062225).  Saving model ...
Validation loss decreased (1.062225 --> 1.057408).  Saving model ...
Validation loss decreased (1.057408 --> 1.053325).  Saving model ...
Validation loss decreased (1.053325 --> 1.049136).  Saving model ...
Validation loss decreased (1.049136 --> 1.045581).  Saving model ...
Validation loss decreased (1.045581 --> 1.040472).  Saving model ...
Validation loss decreased (1.040472 --> 1.036534).  Saving model ...
Validation loss decreased (1.036534 --> 1.031736).  Saving model ...
Validation loss decreased (1.031736 --> 1.030258).  Saving model ...
Validation loss decreased (1.030258 --> 1.027425).  Saving model ...
Validation loss decreased (1.027425 --> 1.024514).  Saving model ...
Validation loss decreased (1.024514 --> 1.022671).  Saving model ...
Validation loss decreased (1.022671 --> 1.020720).  Saving model ...
Validation loss decreased (1.020720 --> 1.016693).  Saving model ...
Validation loss decreased (1.016693 --> 1.014222).  Saving model ...
Validation loss decreased (1.014222 --> 1.011475).  Saving model ...
Validation loss decreased (1.011475 --> 1.009582).  Saving model ...
Validation loss decreased (1.009582 --> 1.006339).  Saving model ...
Validation loss decreased (1.006339 --> 1.004365).  Saving model ...
Validation loss decreased (1.004365 --> 0.999856).  Saving model ...
Validation loss decreased (0.999856 --> 0.996154).  Saving model ...
Validation loss decreased (0.996154 --> 0.994329).  Saving model ...
Validation loss decreased (0.994329 --> 0.993105).  Saving model ...
Validation loss decreased (0.993105 --> 0.990809).  Saving model ...
Validation loss decreased (0.990809 --> 0.988940).  Saving model ...
Validation loss decreased (0.988940 --> 0.987252).  Saving model ...
Validation loss decreased (0.987252 --> 0.985242).  Saving model ...
Validation loss decreased (0.985242 --> 0.982508).  Saving model ...
Validation loss decreased (0.982508 --> 0.980634).  Saving model ...
Validation loss decreased (0.980634 --> 0.978766).  Saving model ...
Validation loss decreased (0.978766 --> 0.977131).  Saving model ...
Validation loss decreased (0.977131 --> 0.977037).  Saving model ...
EarlyStopping counter: 1 out of 3.0
Validation loss decreased (0.977037 --> 0.975382).  Saving model ...
Validation loss decreased (0.975382 --> 0.971412).  Saving model ...
Validation loss decreased (0.971412 --> 0.969820).  Saving model ...
EarlyStopping counter: 1 out of 3.0
Validation loss decreased (0.969820 --> 0.966225).  Saving model ...
Validation loss decreased (0.966225 --> 0.966197).  Saving model ...
Validation loss decreased (0.966197 --> 0.964436).  Saving model ...
Validation loss decreased (0.964436 --> 0.962397).  Saving model ...
Validation loss decreased (0.962397 --> 0.961524).  Saving model ...
Validation loss decreased (0.961524 --> 0.960239).  Saving model ...
Validation loss decreased (0.960239 --> 0.959741).  Saving model ...
Validation loss decreased (0.959741 --> 0.958486).  Saving model ...
Validation loss decreased (0.958486 --> 0.957087).  Saving model ...
Validation loss decreased (0.957087 --> 0.956883).  Saving model ...
EarlyStopping counter: 1 out of 3.0
Validation loss decreased (0.956883 --> 0.956070).  Saving model ...
Validation loss decreased (0.956070 --> 0.954422).  Saving model ...
Validation loss decreased (0.954422 --> 0.952282).  Saving model ...
EarlyStopping counter: 1 out of 3.0
Validation loss decreased (0.952282 --> 0.952082).  Saving model ...
Validation loss decreased (0.952082 --> 0.951975).  Saving model ...
Validation loss decreased (0.951975 --> 0.949836).  Saving model ...
Validation loss decreased (0.949836 --> 0.949258).  Saving model ...
Validation loss decreased (0.949258 --> 0.948861).  Saving model ...
Validation loss decreased (0.948861 --> 0.947416).  Saving model ...
Validation loss decreased (0.947416 --> 0.946728).  Saving model ...
Validation loss decreased (0.946728 --> 0.945579).  Saving model ...
Validation loss decreased (0.945579 --> 0.944901).  Saving model ...
Validation loss decreased (0.944901 --> 0.943338).  Saving model ...
Validation loss decreased (0.943338 --> 0.942585).  Saving model ...
Validation loss decreased (0.942585 --> 0.941443).  Saving model ...
EarlyStopping counter: 1 out of 3.0
Validation loss decreased (0.941443 --> 0.940967).  Saving model ...
Validation loss decreased (0.940967 --> 0.940041).  Saving model ...
Validation loss decreased (0.940041 --> 0.939831).  Saving model ...
EarlyStopping counter: 1 out of 3.0
EarlyStopping counter: 2 out of 3.0
EarlyStopping counter: 3 out of 3.0
/localscratch/yinan.29785217.0/env/lib/python3.7/site-packages/torch/nn/functional.py:1794: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.
  warnings.warn("nn.functional.tanh is deprecated. Use torch.tanh instead.")
wandb: Waiting for W&B process to finish, PID 61722... (success).
wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: \ 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: | 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: / 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: \ 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: | 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: / 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: \ 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: | 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: / 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb:                                                                                
wandb: Run history:
wandb:     e_F1 ▁▁▃▄▄▄▄▅▅▆▆▆▆▆▇▇▇▇▇▇▇▇▇▇▇▇▇▇████████████
wandb:   e_loss █▇▇▇▇▆▆▆▅▅▅▄▄▄▃▃▃▃▃▂▂▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁
wandb:     t_F1 ▁▁▂▃▃▃▃▄▄▅▅▅▅▆▆▅▆▆▇▆▆▆▇▆▇▇▇█▇▇▇▇▇▇█▇████
wandb:   t_loss ██▇▇▇▇▇▆▆▆▆▅▅▅▅▅▄▄▄▄▄▃▃▃▃▃▃▃▃▂▂▂▂▂▂▂▁▁▁▁
wandb: 
wandb: Run summary:
wandb:     e_F1 62.9854
wandb:   e_loss 0.94144
wandb:     t_F1 71.78991
wandb:   t_loss 0.74479
wandb: 
wandb: Synced 4 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Synced sandy-bird-2: https://wandb.ai/yinanazhou/xl_512_bs_8_lr_1e06_es_3_lc_True_nr_False_sr_False_stem_False_lemma_True_repeat_3_fold_2/runs/2b4sfrmt
wandb: Find logs at: ./wandb/run-20220330_024147-2b4sfrmt/logs/debug.log
wandb: 

wandb: wandb version 0.12.11 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
2022-03-30 04:04:34.673067: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1
wandb: Tracking run with wandb version 0.12.5
wandb: Syncing run generous-totem-2
wandb: ⭐️ View project at https://wandb.ai/yinanazhou/xl_512_bs_8_lr_1e06_es_3_lc_True_nr_False_sr_False_stem_False_lemma_True_repeat_4_fold_1
wandb: 🚀 View run at https://wandb.ai/yinanazhou/xl_512_bs_8_lr_1e06_es_3_lc_True_nr_False_sr_False_stem_False_lemma_True_repeat_4_fold_1/runs/19vqafwn
wandb: Run data is saved locally in /project/6002780/yinan/Thesis_MER_Lyrics/lyric-emotion/wandb/run-20220330_040432-19vqafwn
wandb: Run `wandb offline` to turn off syncing.

Validation loss decreased (inf --> 1.432586).  Saving model ...
Validation loss decreased (1.432586 --> 1.415674).  Saving model ...
Validation loss decreased (1.415674 --> 1.403080).  Saving model ...
Validation loss decreased (1.403080 --> 1.394013).  Saving model ...
Validation loss decreased (1.394013 --> 1.386645).  Saving model ...
Validation loss decreased (1.386645 --> 1.379969).  Saving model ...
Validation loss decreased (1.379969 --> 1.374357).  Saving model ...
Validation loss decreased (1.374357 --> 1.369099).  Saving model ...
Validation loss decreased (1.369099 --> 1.364270).  Saving model ...
Validation loss decreased (1.364270 --> 1.359679).  Saving model ...
Validation loss decreased (1.359679 --> 1.354615).  Saving model ...
Validation loss decreased (1.354615 --> 1.349428).  Saving model ...
Validation loss decreased (1.349428 --> 1.344109).  Saving model ...
Validation loss decreased (1.344109 --> 1.339169).  Saving model ...
Validation loss decreased (1.339169 --> 1.333808).  Saving model ...
Validation loss decreased (1.333808 --> 1.329039).  Saving model ...
Validation loss decreased (1.329039 --> 1.323148).  Saving model ...
Validation loss decreased (1.323148 --> 1.317023).  Saving model ...
Validation loss decreased (1.317023 --> 1.310333).  Saving model ...
Validation loss decreased (1.310333 --> 1.303403).  Saving model ...
Validation loss decreased (1.303403 --> 1.295591).  Saving model ...
Validation loss decreased (1.295591 --> 1.288362).  Saving model ...
Validation loss decreased (1.288362 --> 1.280434).  Saving model ...
Validation loss decreased (1.280434 --> 1.273058).  Saving model ...
Validation loss decreased (1.273058 --> 1.264695).  Saving model ...
Validation loss decreased (1.264695 --> 1.256876).  Saving model ...
Validation loss decreased (1.256876 --> 1.249720).  Saving model ...
Validation loss decreased (1.249720 --> 1.240744).  Saving model ...
Validation loss decreased (1.240744 --> 1.233106).  Saving model ...
Validation loss decreased (1.233106 --> 1.225144).  Saving model ...
Validation loss decreased (1.225144 --> 1.216661).  Saving model ...
Validation loss decreased (1.216661 --> 1.208300).  Saving model ...
Validation loss decreased (1.208300 --> 1.201208).  Saving model ...
Validation loss decreased (1.201208 --> 1.193322).  Saving model ...
Validation loss decreased (1.193322 --> 1.186062).  Saving model ...
Validation loss decreased (1.186062 --> 1.178745).  Saving model ...
Validation loss decreased (1.178745 --> 1.172658).  Saving model ...
Validation loss decreased (1.172658 --> 1.166714).  Saving model ...
Validation loss decreased (1.166714 --> 1.162006).  Saving model ...
Validation loss decreased (1.162006 --> 1.156740).  Saving model ...
Validation loss decreased (1.156740 --> 1.150896).  Saving model ...
Validation loss decreased (1.150896 --> 1.145392).  Saving model ...
Validation loss decreased (1.145392 --> 1.141731).  Saving model ...
Validation loss decreased (1.141731 --> 1.137514).  Saving model ...
Validation loss decreased (1.137514 --> 1.132559).  Saving model ...
Validation loss decreased (1.132559 --> 1.127446).  Saving model ...
Validation loss decreased (1.127446 --> 1.121021).  Saving model ...
Validation loss decreased (1.121021 --> 1.113909).  Saving model ...
Validation loss decreased (1.113909 --> 1.108674).  Saving model ...
Validation loss decreased (1.108674 --> 1.103614).  Saving model ...
Validation loss decreased (1.103614 --> 1.099174).  Saving model ...
Validation loss decreased (1.099174 --> 1.094483).  Saving model ...
Validation loss decreased (1.094483 --> 1.090321).  Saving model ...
Validation loss decreased (1.090321 --> 1.085352).  Saving model ...
Validation loss decreased (1.085352 --> 1.080986).  Saving model ...
Validation loss decreased (1.080986 --> 1.077744).  Saving model ...
Validation loss decreased (1.077744 --> 1.074873).  Saving model ...
Validation loss decreased (1.074873 --> 1.071162).  Saving model ...
Validation loss decreased (1.071162 --> 1.067000).  Saving model ...
Validation loss decreased (1.067000 --> 1.062039).  Saving model ...
Validation loss decreased (1.062039 --> 1.060557).  Saving model ...
Validation loss decreased (1.060557 --> 1.056485).  Saving model ...
Validation loss decreased (1.056485 --> 1.052983).  Saving model ...
Validation loss decreased (1.052983 --> 1.048537).  Saving model ...
Validation loss decreased (1.048537 --> 1.045781).  Saving model ...
Validation loss decreased (1.045781 --> 1.041845).  Saving model ...
Validation loss decreased (1.041845 --> 1.039407).  Saving model ...
Validation loss decreased (1.039407 --> 1.034572).  Saving model ...
Validation loss decreased (1.034572 --> 1.030201).  Saving model ...
Validation loss decreased (1.030201 --> 1.027609).  Saving model ...
Validation loss decreased (1.027609 --> 1.024278).  Saving model ...
Validation loss decreased (1.024278 --> 1.021739).  Saving model ...
Validation loss decreased (1.021739 --> 1.017803).  Saving model ...
Validation loss decreased (1.017803 --> 1.015841).  Saving model ...
Validation loss decreased (1.015841 --> 1.014590).  Saving model ...
Validation loss decreased (1.014590 --> 1.011511).  Saving model ...
Validation loss decreased (1.011511 --> 1.008013).  Saving model ...
Validation loss decreased (1.008013 --> 1.006198).  Saving model ...
Validation loss decreased (1.006198 --> 1.004357).  Saving model ...
Validation loss decreased (1.004357 --> 1.000886).  Saving model ...
Validation loss decreased (1.000886 --> 0.998303).  Saving model ...
Validation loss decreased (0.998303 --> 0.996227).  Saving model ...
Validation loss decreased (0.996227 --> 0.994467).  Saving model ...
Validation loss decreased (0.994467 --> 0.993016).  Saving model ...
Validation loss decreased (0.993016 --> 0.989899).  Saving model ...
Validation loss decreased (0.989899 --> 0.989232).  Saving model ...
Validation loss decreased (0.989232 --> 0.984895).  Saving model ...
Validation loss decreased (0.984895 --> 0.982607).  Saving model ...
Validation loss decreased (0.982607 --> 0.981469).  Saving model ...
Validation loss decreased (0.981469 --> 0.980657).  Saving model ...
Validation loss decreased (0.980657 --> 0.978390).  Saving model ...
Validation loss decreased (0.978390 --> 0.975883).  Saving model ...
Validation loss decreased (0.975883 --> 0.973612).  Saving model ...
Validation loss decreased (0.973612 --> 0.971905).  Saving model ...
Validation loss decreased (0.971905 --> 0.969889).  Saving model ...
Validation loss decreased (0.969889 --> 0.968583).  Saving model ...
Validation loss decreased (0.968583 --> 0.967196).  Saving model ...
Validation loss decreased (0.967196 --> 0.966248).  Saving model ...
Validation loss decreased (0.966248 --> 0.965653).  Saving model ...
Validation loss decreased (0.965653 --> 0.964934).  Saving model ...
Validation loss decreased (0.964934 --> 0.962890).  Saving model ...
Validation loss decreased (0.962890 --> 0.960632).  Saving model ...
Validation loss decreased (0.960632 --> 0.959630).  Saving model ...
Validation loss decreased (0.959630 --> 0.958032).  Saving model ...
Validation loss decreased (0.958032 --> 0.956746).  Saving model ...
Validation loss decreased (0.956746 --> 0.955946).  Saving model ...
Validation loss decreased (0.955946 --> 0.955197).  Saving model ...
Validation loss decreased (0.955197 --> 0.954488).  Saving model ...
Validation loss decreased (0.954488 --> 0.953038).  Saving model ...
EarlyStopping counter: 1 out of 3.0
Validation loss decreased (0.953038 --> 0.952253).  Saving model ...
EarlyStopping counter: 1 out of 3.0
Validation loss decreased (0.952253 --> 0.951552).  Saving model ...
Validation loss decreased (0.951552 --> 0.949929).  Saving model ...
Validation loss decreased (0.949929 --> 0.949519).  Saving model ...
Validation loss decreased (0.949519 --> 0.949095).  Saving model ...
EarlyStopping counter: 1 out of 3.0
EarlyStopping counter: 2 out of 3.0
Validation loss decreased (0.949095 --> 0.948275).  Saving model ...
Validation loss decreased (0.948275 --> 0.947655).  Saving model ...
Validation loss decreased (0.947655 --> 0.946161).  Saving model ...
EarlyStopping counter: 1 out of 3.0
Validation loss decreased (0.946161 --> 0.945979).  Saving model ...
EarlyStopping counter: 1 out of 3.0
Validation loss decreased (0.945979 --> 0.944745).  Saving model ...
Validation loss decreased (0.944745 --> 0.943934).  Saving model ...
EarlyStopping counter: 1 out of 3.0
Validation loss decreased (0.943934 --> 0.943838).  Saving model ...
EarlyStopping counter: 1 out of 3.0
Validation loss decreased (0.943838 --> 0.942638).  Saving model ...
EarlyStopping counter: 1 out of 3.0
EarlyStopping counter: 2 out of 3.0
EarlyStopping counter: 3 out of 3.0
/localscratch/yinan.29785217.0/env/lib/python3.7/site-packages/torch/nn/functional.py:1794: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.
  warnings.warn("nn.functional.tanh is deprecated. Use torch.tanh instead.")
wandb: Waiting for W&B process to finish, PID 66162... (success).
wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: \ 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: | 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: / 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: \ 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: | 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: / 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: \ 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: | 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: / 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: \ 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: | 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: / 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: \ 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: | 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb:                                                                                
wandb: Run history:
wandb:     e_F1 ▁▁▃▄▅▅▆▆▆▆▆▇▇▇▇▇▇▇▇▇▇▇▇█▇███████████████
wandb:   e_loss ██▇▇▇▇▆▆▅▅▅▄▄▄▄▃▃▃▃▃▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:     t_F1 ▁▂▂▃▃▄▄▄▅▅▆▅▆▆▆▆▇▆▆▆▆▆▇▇▇▇▇▇▇▇██████████
wandb:   t_loss ███▇▇▇▇▇▆▆▆▅▅▅▅▄▄▄▄▄▄▃▃▃▃▃▂▃▂▂▂▂▂▂▂▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:     e_F1 59.5319
wandb:   e_loss 0.94336
wandb:     t_F1 75.02507
wandb:   t_loss 0.70702
wandb: 
wandb: Synced 4 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Synced generous-totem-2: https://wandb.ai/yinanazhou/xl_512_bs_8_lr_1e06_es_3_lc_True_nr_False_sr_False_stem_False_lemma_True_repeat_4_fold_1/runs/19vqafwn
wandb: Find logs at: ./wandb/run-20220330_040432-19vqafwn/logs/debug.log
wandb: 

wandb: wandb version 0.12.11 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
2022-03-30 05:32:16.329088: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1
wandb: Tracking run with wandb version 0.12.5
wandb: Syncing run ethereal-bush-2
wandb: ⭐️ View project at https://wandb.ai/yinanazhou/xl_512_bs_8_lr_1e06_es_3_lc_True_nr_False_sr_False_stem_False_lemma_True_repeat_4_fold_2
wandb: 🚀 View run at https://wandb.ai/yinanazhou/xl_512_bs_8_lr_1e06_es_3_lc_True_nr_False_sr_False_stem_False_lemma_True_repeat_4_fold_2/runs/11tgri9k
wandb: Run data is saved locally in /project/6002780/yinan/Thesis_MER_Lyrics/lyric-emotion/wandb/run-20220330_053213-11tgri9k
wandb: Run `wandb offline` to turn off syncing.

Validation loss decreased (inf --> 1.490025).  Saving model ...
Validation loss decreased (1.490025 --> 1.452688).  Saving model ...
Validation loss decreased (1.452688 --> 1.425319).  Saving model ...
Validation loss decreased (1.425319 --> 1.402914).  Saving model ...
Validation loss decreased (1.402914 --> 1.386130).  Saving model ...
Validation loss decreased (1.386130 --> 1.373731).  Saving model ...
Validation loss decreased (1.373731 --> 1.363861).  Saving model ...
Validation loss decreased (1.363861 --> 1.355528).  Saving model ...
Validation loss decreased (1.355528 --> 1.349496).  Saving model ...
Validation loss decreased (1.349496 --> 1.343371).  Saving model ...
Validation loss decreased (1.343371 --> 1.337154).  Saving model ...
Validation loss decreased (1.337154 --> 1.331846).  Saving model ...
Validation loss decreased (1.331846 --> 1.326414).  Saving model ...
Validation loss decreased (1.326414 --> 1.321564).  Saving model ...
Validation loss decreased (1.321564 --> 1.316964).  Saving model ...
Validation loss decreased (1.316964 --> 1.311542).  Saving model ...
Validation loss decreased (1.311542 --> 1.306039).  Saving model ...
Validation loss decreased (1.306039 --> 1.300167).  Saving model ...
Validation loss decreased (1.300167 --> 1.294004).  Saving model ...
Validation loss decreased (1.294004 --> 1.288002).  Saving model ...
Validation loss decreased (1.288002 --> 1.281128).  Saving model ...
Validation loss decreased (1.281128 --> 1.274822).  Saving model ...
Validation loss decreased (1.274822 --> 1.269038).  Saving model ...
Validation loss decreased (1.269038 --> 1.261949).  Saving model ...
Validation loss decreased (1.261949 --> 1.255150).  Saving model ...
Validation loss decreased (1.255150 --> 1.247206).  Saving model ...
Validation loss decreased (1.247206 --> 1.238884).  Saving model ...
Validation loss decreased (1.238884 --> 1.230449).  Saving model ...
Validation loss decreased (1.230449 --> 1.225415).  Saving model ...
Validation loss decreased (1.225415 --> 1.217166).  Saving model ...
Validation loss decreased (1.217166 --> 1.208054).  Saving model ...
Validation loss decreased (1.208054 --> 1.200466).  Saving model ...
Validation loss decreased (1.200466 --> 1.193097).  Saving model ...
Validation loss decreased (1.193097 --> 1.186191).  Saving model ...
Validation loss decreased (1.186191 --> 1.177126).  Saving model ...
Validation loss decreased (1.177126 --> 1.169274).  Saving model ...
Validation loss decreased (1.169274 --> 1.162085).  Saving model ...
Validation loss decreased (1.162085 --> 1.155623).  Saving model ...
Validation loss decreased (1.155623 --> 1.148362).  Saving model ...
Validation loss decreased (1.148362 --> 1.142162).  Saving model ...
Validation loss decreased (1.142162 --> 1.136028).  Saving model ...
Validation loss decreased (1.136028 --> 1.129917).  Saving model ...
Validation loss decreased (1.129917 --> 1.123537).  Saving model ...
Validation loss decreased (1.123537 --> 1.118165).  Saving model ...
Validation loss decreased (1.118165 --> 1.112342).  Saving model ...
Validation loss decreased (1.112342 --> 1.105807).  Saving model ...
Validation loss decreased (1.105807 --> 1.098951).  Saving model ...
Validation loss decreased (1.098951 --> 1.093677).  Saving model ...
Validation loss decreased (1.093677 --> 1.089041).  Saving model ...
Validation loss decreased (1.089041 --> 1.084520).  Saving model ...
Validation loss decreased (1.084520 --> 1.079759).  Saving model ...
Validation loss decreased (1.079759 --> 1.073774).  Saving model ...
Validation loss decreased (1.073774 --> 1.068936).  Saving model ...
Validation loss decreased (1.068936 --> 1.061953).  Saving model ...
Validation loss decreased (1.061953 --> 1.056203).  Saving model ...
Validation loss decreased (1.056203 --> 1.051691).  Saving model ...
Validation loss decreased (1.051691 --> 1.046474).  Saving model ...
Validation loss decreased (1.046474 --> 1.041706).  Saving model ...
Validation loss decreased (1.041706 --> 1.037555).  Saving model ...
Validation loss decreased (1.037555 --> 1.033630).  Saving model ...
Validation loss decreased (1.033630 --> 1.028882).  Saving model ...
Validation loss decreased (1.028882 --> 1.025109).  Saving model ...
Validation loss decreased (1.025109 --> 1.022382).  Saving model ...
Validation loss decreased (1.022382 --> 1.018085).  Saving model ...
Validation loss decreased (1.018085 --> 1.013750).  Saving model ...
Validation loss decreased (1.013750 --> 1.009864).  Saving model ...
Validation loss decreased (1.009864 --> 1.006636).  Saving model ...
Validation loss decreased (1.006636 --> 1.002797).  Saving model ...
Validation loss decreased (1.002797 --> 0.999692).  Saving model ...
Validation loss decreased (0.999692 --> 0.996832).  Saving model ...
Validation loss decreased (0.996832 --> 0.994632).  Saving model ...
Validation loss decreased (0.994632 --> 0.991831).  Saving model ...
Validation loss decreased (0.991831 --> 0.987377).  Saving model ...
Validation loss decreased (0.987377 --> 0.984373).  Saving model ...
Validation loss decreased (0.984373 --> 0.982345).  Saving model ...
Validation loss decreased (0.982345 --> 0.979578).  Saving model ...
Validation loss decreased (0.979578 --> 0.976878).  Saving model ...
Validation loss decreased (0.976878 --> 0.976467).  Saving model ...
Validation loss decreased (0.976467 --> 0.973693).  Saving model ...
Validation loss decreased (0.973693 --> 0.971172).  Saving model ...
Validation loss decreased (0.971172 --> 0.966734).  Saving model ...
Validation loss decreased (0.966734 --> 0.964423).  Saving model ...
Validation loss decreased (0.964423 --> 0.961983).  Saving model ...
Validation loss decreased (0.961983 --> 0.960910).  Saving model ...
Validation loss decreased (0.960910 --> 0.959234).  Saving model ...
Validation loss decreased (0.959234 --> 0.957413).  Saving model ...
Validation loss decreased (0.957413 --> 0.955551).  Saving model ...
Validation loss decreased (0.955551 --> 0.955258).  Saving model ...
Validation loss decreased (0.955258 --> 0.952609).  Saving model ...
Validation loss decreased (0.952609 --> 0.950160).  Saving model ...
Validation loss decreased (0.950160 --> 0.947985).  Saving model ...
Validation loss decreased (0.947985 --> 0.946795).  Saving model ...
Validation loss decreased (0.946795 --> 0.944544).  Saving model ...
Validation loss decreased (0.944544 --> 0.944180).  Saving model ...
Validation loss decreased (0.944180 --> 0.943795).  Saving model ...
Validation loss decreased (0.943795 --> 0.943388).  Saving model ...
Validation loss decreased (0.943388 --> 0.941533).  Saving model ...
Validation loss decreased (0.941533 --> 0.939062).  Saving model ...
Validation loss decreased (0.939062 --> 0.936177).  Saving model ...
Validation loss decreased (0.936177 --> 0.935279).  Saving model ...
EarlyStopping counter: 1 out of 3.0
Validation loss decreased (0.935279 --> 0.935004).  Saving model ...
Validation loss decreased (0.935004 --> 0.933113).  Saving model ...
Validation loss decreased (0.933113 --> 0.931831).  Saving model ...
Validation loss decreased (0.931831 --> 0.930864).  Saving model ...
Validation loss decreased (0.930864 --> 0.930065).  Saving model ...
EarlyStopping counter: 1 out of 3.0
Validation loss decreased (0.930065 --> 0.928215).  Saving model ...
EarlyStopping counter: 1 out of 3.0
EarlyStopping counter: 2 out of 3.0
Validation loss decreased (0.928215 --> 0.925468).  Saving model ...
EarlyStopping counter: 1 out of 3.0
Validation loss decreased (0.925468 --> 0.925362).  Saving model ...
Validation loss decreased (0.925362 --> 0.923264).  Saving model ...
EarlyStopping counter: 1 out of 3.0
Validation loss decreased (0.923264 --> 0.923040).  Saving model ...
EarlyStopping counter: 1 out of 3.0
EarlyStopping counter: 2 out of 3.0
Validation loss decreased (0.923040 --> 0.922059).  Saving model ...
EarlyStopping counter: 1 out of 3.0
EarlyStopping counter: 2 out of 3.0
Validation loss decreased (0.922059 --> 0.921401).  Saving model ...
Validation loss decreased (0.921401 --> 0.919926).  Saving model ...
EarlyStopping counter: 1 out of 3.0
EarlyStopping counter: 2 out of 3.0
Validation loss decreased (0.919926 --> 0.919068).  Saving model ...
Validation loss decreased (0.919068 --> 0.918809).  Saving model ...
EarlyStopping counter: 1 out of 3.0
Validation loss decreased (0.918809 --> 0.917015).  Saving model ...
EarlyStopping counter: 1 out of 3.0
EarlyStopping counter: 2 out of 3.0
EarlyStopping counter: 3 out of 3.0
/localscratch/yinan.29785217.0/env/lib/python3.7/site-packages/torch/nn/functional.py:1794: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.
  warnings.warn("nn.functional.tanh is deprecated. Use torch.tanh instead.")
wandb: Waiting for W&B process to finish, PID 70816... (success).
wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: \ 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: | 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: / 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: \ 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: | 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: / 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: \ 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: | 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: / 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb:                                                                                
wandb: Run history:
wandb:     e_F1 ▁▂▃▄▅▅▆▆▆▇▇▇▇▇▇▇▇▇▇▇██▇█████████████████
wandb:   e_loss █▇▇▆▆▆▆▆▅▅▅▄▄▄▃▃▃▃▂▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:     t_F1 ▁▁▂▃▃▃▄▄▅▄▅▅▅▆▆▆▆▆▆▇▇▇▇▇▇▇▇▇▇▇▇▇▇███████
wandb:   t_loss ██▇▇▇▆▆▆▆▆▆▅▅▅▅▄▄▄▄▄▃▃▃▃▃▃▃▂▂▂▂▂▂▂▂▁▂▁▁▁
wandb: 
wandb: Run summary:
wandb:     e_F1 62.22301
wandb:   e_loss 0.91807
wandb:     t_F1 71.18897
wandb:   t_loss 0.76734
wandb: 
wandb: Synced 4 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Synced ethereal-bush-2: https://wandb.ai/yinanazhou/xl_512_bs_8_lr_1e06_es_3_lc_True_nr_False_sr_False_stem_False_lemma_True_repeat_4_fold_2/runs/11tgri9k
wandb: Find logs at: ./wandb/run-20220330_053213-11tgri9k/logs/debug.log
wandb: 

wandb: wandb version 0.12.11 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
2022-03-30 06:59:12.117032: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1
wandb: Tracking run with wandb version 0.12.5
wandb: Syncing run wobbly-snowflake-1
wandb: ⭐️ View project at https://wandb.ai/yinanazhou/xl_512_bs_8_lr_1e06_es_3_lc_True_nr_False_sr_False_stem_False_lemma_True_repeat_5_fold_1
wandb: 🚀 View run at https://wandb.ai/yinanazhou/xl_512_bs_8_lr_1e06_es_3_lc_True_nr_False_sr_False_stem_False_lemma_True_repeat_5_fold_1/runs/2rlbli1y
wandb: Run data is saved locally in /project/6002780/yinan/Thesis_MER_Lyrics/lyric-emotion/wandb/run-20220330_065909-2rlbli1y
wandb: Run `wandb offline` to turn off syncing.

Validation loss decreased (inf --> 1.543484).  Saving model ...
Validation loss decreased (1.543484 --> 1.492058).  Saving model ...
Validation loss decreased (1.492058 --> 1.452471).  Saving model ...
Validation loss decreased (1.452471 --> 1.423402).  Saving model ...
Validation loss decreased (1.423402 --> 1.403117).  Saving model ...
Validation loss decreased (1.403117 --> 1.388599).  Saving model ...
Validation loss decreased (1.388599 --> 1.376918).  Saving model ...
Validation loss decreased (1.376918 --> 1.368720).  Saving model ...
Validation loss decreased (1.368720 --> 1.362430).  Saving model ...
Validation loss decreased (1.362430 --> 1.356792).  Saving model ...
Validation loss decreased (1.356792 --> 1.352027).  Saving model ...
Validation loss decreased (1.352027 --> 1.347308).  Saving model ...
Validation loss decreased (1.347308 --> 1.342797).  Saving model ...
Validation loss decreased (1.342797 --> 1.338134).  Saving model ...
Validation loss decreased (1.338134 --> 1.333492).  Saving model ...
Validation loss decreased (1.333492 --> 1.328843).  Saving model ...
Validation loss decreased (1.328843 --> 1.323760).  Saving model ...
Validation loss decreased (1.323760 --> 1.318569).  Saving model ...
Validation loss decreased (1.318569 --> 1.313660).  Saving model ...
Validation loss decreased (1.313660 --> 1.308050).  Saving model ...
Validation loss decreased (1.308050 --> 1.302699).  Saving model ...
Validation loss decreased (1.302699 --> 1.297153).  Saving model ...
Validation loss decreased (1.297153 --> 1.290896).  Saving model ...
Validation loss decreased (1.290896 --> 1.285149).  Saving model ...
Validation loss decreased (1.285149 --> 1.279120).  Saving model ...
Validation loss decreased (1.279120 --> 1.274172).  Saving model ...
Validation loss decreased (1.274172 --> 1.267709).  Saving model ...
Validation loss decreased (1.267709 --> 1.260755).  Saving model ...
Validation loss decreased (1.260755 --> 1.254903).  Saving model ...
Validation loss decreased (1.254903 --> 1.248935).  Saving model ...
Validation loss decreased (1.248935 --> 1.243707).  Saving model ...
Validation loss decreased (1.243707 --> 1.238021).  Saving model ...
Validation loss decreased (1.238021 --> 1.231393).  Saving model ...
Validation loss decreased (1.231393 --> 1.225445).  Saving model ...
Validation loss decreased (1.225445 --> 1.217122).  Saving model ...
Validation loss decreased (1.217122 --> 1.212073).  Saving model ...
Validation loss decreased (1.212073 --> 1.205109).  Saving model ...
Validation loss decreased (1.205109 --> 1.199722).  Saving model ...
Validation loss decreased (1.199722 --> 1.193299).  Saving model ...
Validation loss decreased (1.193299 --> 1.185782).  Saving model ...
Validation loss decreased (1.185782 --> 1.180016).  Saving model ...
Validation loss decreased (1.180016 --> 1.174125).  Saving model ...
Validation loss decreased (1.174125 --> 1.169386).  Saving model ...
Validation loss decreased (1.169386 --> 1.161328).  Saving model ...
Validation loss decreased (1.161328 --> 1.155229).  Saving model ...
Validation loss decreased (1.155229 --> 1.149488).  Saving model ...
Validation loss decreased (1.149488 --> 1.144669).  Saving model ...
Validation loss decreased (1.144669 --> 1.138847).  Saving model ...
Validation loss decreased (1.138847 --> 1.132662).  Saving model ...
Validation loss decreased (1.132662 --> 1.127840).  Saving model ...
Validation loss decreased (1.127840 --> 1.122452).  Saving model ...
Validation loss decreased (1.122452 --> 1.116444).  Saving model ...
Validation loss decreased (1.116444 --> 1.112439).  Saving model ...
Validation loss decreased (1.112439 --> 1.109885).  Saving model ...
Validation loss decreased (1.109885 --> 1.105700).  Saving model ...
Validation loss decreased (1.105700 --> 1.098318).  Saving model ...
Validation loss decreased (1.098318 --> 1.095254).  Saving model ...
Validation loss decreased (1.095254 --> 1.090990).  Saving model ...
Validation loss decreased (1.090990 --> 1.084980).  Saving model ...
Validation loss decreased (1.084980 --> 1.079516).  Saving model ...
Validation loss decreased (1.079516 --> 1.076993).  Saving model ...
Validation loss decreased (1.076993 --> 1.072226).  Saving model ...
Validation loss decreased (1.072226 --> 1.068920).  Saving model ...
Validation loss decreased (1.068920 --> 1.064343).  Saving model ...
Validation loss decreased (1.064343 --> 1.061883).  Saving model ...
Validation loss decreased (1.061883 --> 1.060366).  Saving model ...
Validation loss decreased (1.060366 --> 1.058484).  Saving model ...
Validation loss decreased (1.058484 --> 1.056069).  Saving model ...
Validation loss decreased (1.056069 --> 1.051858).  Saving model ...
Validation loss decreased (1.051858 --> 1.047114).  Saving model ...
Validation loss decreased (1.047114 --> 1.042541).  Saving model ...
Validation loss decreased (1.042541 --> 1.039161).  Saving model ...
Validation loss decreased (1.039161 --> 1.038303).  Saving model ...
Validation loss decreased (1.038303 --> 1.034922).  Saving model ...
Validation loss decreased (1.034922 --> 1.030067).  Saving model ...
Validation loss decreased (1.030067 --> 1.029820).  Saving model ...
Validation loss decreased (1.029820 --> 1.027586).  Saving model ...
Validation loss decreased (1.027586 --> 1.026748).  Saving model ...
Validation loss decreased (1.026748 --> 1.025783).  Saving model ...
Validation loss decreased (1.025783 --> 1.020734).  Saving model ...
Validation loss decreased (1.020734 --> 1.019415).  Saving model ...
Validation loss decreased (1.019415 --> 1.017736).  Saving model ...
Validation loss decreased (1.017736 --> 1.009592).  Saving model ...
Validation loss decreased (1.009592 --> 1.007071).  Saving model ...
Validation loss decreased (1.007071 --> 1.006452).  Saving model ...
EarlyStopping counter: 1 out of 3.0
EarlyStopping counter: 2 out of 3.0
Validation loss decreased (1.006452 --> 1.002390).  Saving model ...
Validation loss decreased (1.002390 --> 0.999109).  Saving model ...
Validation loss decreased (0.999109 --> 0.998982).  Saving model ...
Validation loss decreased (0.998982 --> 0.996947).  Saving model ...
EarlyStopping counter: 1 out of 3.0
Validation loss decreased (0.996947 --> 0.994123).  Saving model ...
Validation loss decreased (0.994123 --> 0.991205).  Saving model ...
Validation loss decreased (0.991205 --> 0.990266).  Saving model ...
Validation loss decreased (0.990266 --> 0.988937).  Saving model ...
EarlyStopping counter: 1 out of 3.0
Validation loss decreased (0.988937 --> 0.988431).  Saving model ...
Validation loss decreased (0.988431 --> 0.982136).  Saving model ...
EarlyStopping counter: 1 out of 3.0
EarlyStopping counter: 2 out of 3.0
Validation loss decreased (0.982136 --> 0.981405).  Saving model ...
Validation loss decreased (0.981405 --> 0.980361).  Saving model ...
Validation loss decreased (0.980361 --> 0.978404).  Saving model ...
EarlyStopping counter: 1 out of 3.0
EarlyStopping counter: 2 out of 3.0
Validation loss decreased (0.978404 --> 0.975993).  Saving model ...
EarlyStopping counter: 1 out of 3.0
Validation loss decreased (0.975993 --> 0.974143).  Saving model ...
EarlyStopping counter: 1 out of 3.0
EarlyStopping counter: 2 out of 3.0
Validation loss decreased (0.974143 --> 0.971194).  Saving model ...
EarlyStopping counter: 1 out of 3.0
Validation loss decreased (0.971194 --> 0.971114).  Saving model ...
Validation loss decreased (0.971114 --> 0.970026).  Saving model ...
Validation loss decreased (0.970026 --> 0.967042).  Saving model ...
EarlyStopping counter: 1 out of 3.0
EarlyStopping counter: 2 out of 3.0
Validation loss decreased (0.967042 --> 0.965444).  Saving model ...
EarlyStopping counter: 1 out of 3.0
Validation loss decreased (0.965444 --> 0.963798).  Saving model ...
EarlyStopping counter: 1 out of 3.0
EarlyStopping counter: 2 out of 3.0
EarlyStopping counter: 3 out of 3.0
/localscratch/yinan.29785217.0/env/lib/python3.7/site-packages/torch/nn/functional.py:1794: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.
  warnings.warn("nn.functional.tanh is deprecated. Use torch.tanh instead.")
wandb: Waiting for W&B process to finish, PID 75442... (success).
wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: \ 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: | 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: / 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: \ 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: | 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: / 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: \ 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: | 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: / 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb:                                                                                
wandb: Run history:
wandb:     e_F1 ▁▁▃▄▄▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇▇▇███▇██████████████
wandb:   e_loss █▇▆▆▆▅▅▅▅▅▄▄▄▄▃▃▃▃▃▂▂▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁
wandb:     t_F1 ▁▁▂▃▃▄▄▄▄▄▅▅▅▆▆▅▆▆▆▆▆▇▆▇▇▇▇▇▇▇▇▇▇██████▇
wandb:   t_loss █▇▇▆▆▆▆▆▆▅▅▅▅▄▄▄▄▄▄▄▃▃▃▃▃▃▂▂▂▂▂▂▂▂▂▁▁▁▁▂
wandb: 
wandb: Run summary:
wandb:     e_F1 58.67657
wandb:   e_loss 0.96635
wandb:     t_F1 67.37129
wandb:   t_loss 0.83636
wandb: 
wandb: Synced 4 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Synced wobbly-snowflake-1: https://wandb.ai/yinanazhou/xl_512_bs_8_lr_1e06_es_3_lc_True_nr_False_sr_False_stem_False_lemma_True_repeat_5_fold_1/runs/2rlbli1y
wandb: Find logs at: ./wandb/run-20220330_065909-2rlbli1y/logs/debug.log
wandb: 

wandb: wandb version 0.12.11 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
2022-03-30 08:20:16.924091: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1
wandb: Tracking run with wandb version 0.12.5
wandb: Syncing run chocolate-brook-1
wandb: ⭐️ View project at https://wandb.ai/yinanazhou/xl_512_bs_8_lr_1e06_es_3_lc_True_nr_False_sr_False_stem_False_lemma_True_repeat_5_fold_2
wandb: 🚀 View run at https://wandb.ai/yinanazhou/xl_512_bs_8_lr_1e06_es_3_lc_True_nr_False_sr_False_stem_False_lemma_True_repeat_5_fold_2/runs/3764ytjo
wandb: Run data is saved locally in /project/6002780/yinan/Thesis_MER_Lyrics/lyric-emotion/wandb/run-20220330_082014-3764ytjo
wandb: Run `wandb offline` to turn off syncing.

Validation loss decreased (inf --> 1.432204).  Saving model ...
Validation loss decreased (1.432204 --> 1.410398).  Saving model ...
Validation loss decreased (1.410398 --> 1.394325).  Saving model ...
Validation loss decreased (1.394325 --> 1.380570).  Saving model ...
Validation loss decreased (1.380570 --> 1.370299).  Saving model ...
Validation loss decreased (1.370299 --> 1.361891).  Saving model ...
Validation loss decreased (1.361891 --> 1.354554).  Saving model ...
Validation loss decreased (1.354554 --> 1.348458).  Saving model ...
Validation loss decreased (1.348458 --> 1.341833).  Saving model ...
Validation loss decreased (1.341833 --> 1.336193).  Saving model ...
Validation loss decreased (1.336193 --> 1.331068).  Saving model ...
Validation loss decreased (1.331068 --> 1.326128).  Saving model ...
Validation loss decreased (1.326128 --> 1.319863).  Saving model ...
Validation loss decreased (1.319863 --> 1.313294).  Saving model ...
Validation loss decreased (1.313294 --> 1.307311).  Saving model ...
Validation loss decreased (1.307311 --> 1.301425).  Saving model ...
Validation loss decreased (1.301425 --> 1.295592).  Saving model ...
Validation loss decreased (1.295592 --> 1.289032).  Saving model ...
Validation loss decreased (1.289032 --> 1.282432).  Saving model ...
Validation loss decreased (1.282432 --> 1.275205).  Saving model ...
Validation loss decreased (1.275205 --> 1.267532).  Saving model ...
Validation loss decreased (1.267532 --> 1.260379).  Saving model ...
Validation loss decreased (1.260379 --> 1.252004).  Saving model ...
Validation loss decreased (1.252004 --> 1.244541).  Saving model ...
Validation loss decreased (1.244541 --> 1.235805).  Saving model ...
Validation loss decreased (1.235805 --> 1.227646).  Saving model ...
Validation loss decreased (1.227646 --> 1.219038).  Saving model ...
Validation loss decreased (1.219038 --> 1.210379).  Saving model ...
Validation loss decreased (1.210379 --> 1.201192).  Saving model ...
Validation loss decreased (1.201192 --> 1.194625).  Saving model ...
Validation loss decreased (1.194625 --> 1.187645).  Saving model ...
Validation loss decreased (1.187645 --> 1.179511).  Saving model ...
Validation loss decreased (1.179511 --> 1.170138).  Saving model ...
Validation loss decreased (1.170138 --> 1.163186).  Saving model ...
Validation loss decreased (1.163186 --> 1.156623).  Saving model ...
Validation loss decreased (1.156623 --> 1.148948).  Saving model ...
Validation loss decreased (1.148948 --> 1.141438).  Saving model ...
Validation loss decreased (1.141438 --> 1.136548).  Saving model ...
Validation loss decreased (1.136548 --> 1.131348).  Saving model ...
Validation loss decreased (1.131348 --> 1.123694).  Saving model ...
Validation loss decreased (1.123694 --> 1.117732).  Saving model ...
Validation loss decreased (1.117732 --> 1.112396).  Saving model ...
Validation loss decreased (1.112396 --> 1.106826).  Saving model ...
Validation loss decreased (1.106826 --> 1.100393).  Saving model ...
Validation loss decreased (1.100393 --> 1.094675).  Saving model ...
Validation loss decreased (1.094675 --> 1.089460).  Saving model ...
Validation loss decreased (1.089460 --> 1.085384).  Saving model ...
Validation loss decreased (1.085384 --> 1.080337).  Saving model ...
Validation loss decreased (1.080337 --> 1.076546).  Saving model ...
Validation loss decreased (1.076546 --> 1.071482).  Saving model ...
Validation loss decreased (1.071482 --> 1.066974).  Saving model ...
Validation loss decreased (1.066974 --> 1.063481).  Saving model ...
Validation loss decreased (1.063481 --> 1.058746).  Saving model ...
Validation loss decreased (1.058746 --> 1.054860).  Saving model ...
Validation loss decreased (1.054860 --> 1.050622).  Saving model ...
Validation loss decreased (1.050622 --> 1.046728).  Saving model ...
Validation loss decreased (1.046728 --> 1.039564).  Saving model ...
Validation loss decreased (1.039564 --> 1.035342).  Saving model ...
Validation loss decreased (1.035342 --> 1.030965).  Saving model ...
Validation loss decreased (1.030965 --> 1.027402).  Saving model ...
Validation loss decreased (1.027402 --> 1.023627).  Saving model ...
Validation loss decreased (1.023627 --> 1.019021).  Saving model ...
Validation loss decreased (1.019021 --> 1.016622).  Saving model ...
Validation loss decreased (1.016622 --> 1.012211).  Saving model ...
Validation loss decreased (1.012211 --> 1.007657).  Saving model ...
Validation loss decreased (1.007657 --> 1.004290).  Saving model ...
Validation loss decreased (1.004290 --> 1.001296).  Saving model ...
Validation loss decreased (1.001296 --> 0.998833).  Saving model ...
Validation loss decreased (0.998833 --> 0.995334).  Saving model ...
Validation loss decreased (0.995334 --> 0.992868).  Saving model ...
Validation loss decreased (0.992868 --> 0.989533).  Saving model ...
Validation loss decreased (0.989533 --> 0.985692).  Saving model ...
Validation loss decreased (0.985692 --> 0.982807).  Saving model ...
Validation loss decreased (0.982807 --> 0.980178).  Saving model ...
Validation loss decreased (0.980178 --> 0.977025).  Saving model ...
Validation loss decreased (0.977025 --> 0.974710).  Saving model ...
Validation loss decreased (0.974710 --> 0.973111).  Saving model ...
Validation loss decreased (0.973111 --> 0.970786).  Saving model ...
Validation loss decreased (0.970786 --> 0.967375).  Saving model ...
Validation loss decreased (0.967375 --> 0.963979).  Saving model ...
Validation loss decreased (0.963979 --> 0.962360).  Saving model ...
Validation loss decreased (0.962360 --> 0.960363).  Saving model ...
Validation loss decreased (0.960363 --> 0.958352).  Saving model ...
Validation loss decreased (0.958352 --> 0.956966).  Saving model ...
Validation loss decreased (0.956966 --> 0.955300).  Saving model ...
Validation loss decreased (0.955300 --> 0.952685).  Saving model ...
Validation loss decreased (0.952685 --> 0.951705).  Saving model ...
Validation loss decreased (0.951705 --> 0.948558).  Saving model ...
Validation loss decreased (0.948558 --> 0.947364).  Saving model ...
Validation loss decreased (0.947364 --> 0.944251).  Saving model ...
Validation loss decreased (0.944251 --> 0.944045).  Saving model ...
Validation loss decreased (0.944045 --> 0.941775).  Saving model ...
Validation loss decreased (0.941775 --> 0.938152).  Saving model ...
Validation loss decreased (0.938152 --> 0.937164).  Saving model ...
Validation loss decreased (0.937164 --> 0.936567).  Saving model ...
Validation loss decreased (0.936567 --> 0.935426).  Saving model ...
Validation loss decreased (0.935426 --> 0.933770).  Saving model ...
Validation loss decreased (0.933770 --> 0.932004).  Saving model ...
Validation loss decreased (0.932004 --> 0.931772).  Saving model ...
Validation loss decreased (0.931772 --> 0.930050).  Saving model ...
Validation loss decreased (0.930050 --> 0.928915).  Saving model ...
Validation loss decreased (0.928915 --> 0.928664).  Saving model ...
Validation loss decreased (0.928664 --> 0.926799).  Saving model ...
Validation loss decreased (0.926799 --> 0.924888).  Saving model ...
EarlyStopping counter: 1 out of 3.0
EarlyStopping counter: 2 out of 3.0
EarlyStopping counter: 3 out of 3.0
/localscratch/yinan.29785217.0/env/lib/python3.7/site-packages/torch/nn/functional.py:1794: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.
  warnings.warn("nn.functional.tanh is deprecated. Use torch.tanh instead.")
wandb: Waiting for W&B process to finish, PID 79774... (success).
wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: \ 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: | 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: / 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: \ 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: | 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: / 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: \ 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: | 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: / 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb:                                                                                
wandb: Run history:
wandb:     e_F1 ▁▁▂▄▄▅▅▆▆▆▆▆▆▇▇▇▇▇▇▇▇▇▇▇▇▇██████████████
wandb:   e_loss █▇▇▇▇▆▆▆▆▅▅▅▄▄▄▄▃▃▃▃▃▃▂▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁
wandb:     t_F1 ▁▁▂▃▃▃▃▃▄▅▄▄▅▅▅▆▆▆▆▆▇▆▇▆▇▇▇▇▇▇▇█▇█▇██▇██
wandb:   t_loss ██▇▇▇▇▇▆▆▆▆▅▅▅▅▄▄▄▄▄▃▃▃▃▃▃▂▃▂▂▂▁▂▁▂▂▁▁▁▁
wandb: 
wandb: Run summary:
wandb:     e_F1 61.02213
wandb:   e_loss 0.92718
wandb:     t_F1 66.66555
wandb:   t_loss 0.82742
wandb: 
wandb: Synced 4 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Synced chocolate-brook-1: https://wandb.ai/yinanazhou/xl_512_bs_8_lr_1e06_es_3_lc_True_nr_False_sr_False_stem_False_lemma_True_repeat_5_fold_2/runs/3764ytjo
wandb: Find logs at: ./wandb/run-20220330_082014-3764ytjo/logs/debug.log
wandb: 

