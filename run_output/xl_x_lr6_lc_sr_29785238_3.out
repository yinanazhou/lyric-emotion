Unloading StdEnv/2020

Due to MODULEPATH changes, the following have been reloaded:
  1) mii/1.1.1


The following have been reloaded with a version change:
  1) python/3.8.2 => python/3.7.4

Using base prefix '/cvmfs/soft.computecanada.ca/easybuild/software/2017/Core/python/3.7.4'
New python executable in /localscratch/yinan.29785238.0/env/bin/python
Installing setuptools, pip, wheel...
done.
Ignoring pip: markers 'python_version < "3"' don't match your environment
Looking in links: /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/nix/avx2, /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/nix/generic, /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic
Collecting pip
Installing collected packages: pip
  Found existing installation: pip 19.1.1
    Uninstalling pip-19.1.1:
      Successfully uninstalled pip-19.1.1
Successfully installed pip-21.2.3+computecanada
Looking in links: /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/nix/avx2, /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/nix/generic, /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/keras-2.8.0+computecanada-py2.py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/Keras_Preprocessing-1.1.2+computecanada-py3-none-any.whl
Requirement already satisfied: matplotlib in /cvmfs/soft.computecanada.ca/easybuild/software/2017/Core/scipy-stack/2019a/lib/python3.7/site-packages (from -r requirements.txt (line 3)) (3.0.2)
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/nltk-3.6.5+computecanada-py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/scikit_learn-0.22.1+computecanada-cp37-cp37m-linux_x86_64.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/tensorboard-2.3.0+computecanada-py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/tensorboard_plugin_wit-1.7.0+computecanada-py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/tensorflow_gpu-2.3.0+computecanada-cp37-cp37m-linux_x86_64.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/tensorflow_estimator-2.3.0+computecanada-py2.py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/tokenizers-0.5.2+computecanada-cp37-cp37m-linux_x86_64.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/nix/avx2/torch-1.4.0+computecanada-cp37-cp37m-linux_x86_64.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/torchtext-0.6.0+computecanada-py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/torchvision-0.8.2+computecanada-cp37-cp37m-linux_x86_64.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/transformers-2.5.1+computecanada-py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/urllib3-1.26.7+computecanada-py2.py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/joblib-1.1.0+computecanada-py2.py3-none-any.whl
ERROR: Could not find a version that satisfies the requirement regex>=2021.8.3 (from nltk) (from versions: 2018.1.10+computecanada, 2019.11.1+computecanada, 2020.11.13+computecanada)
ERROR: No matching distribution found for regex>=2021.8.3
Looking in links: /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/nix/avx2, /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/nix/generic, /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic
ERROR: Could not find a version that satisfies the requirement numpy==1.20.0+computacanada (from versions: 1.15.0+computecanada, 1.15.2+computecanada, 1.15.4+computecanada, 1.16.0+computecanada, 1.16.2+computecanada, 1.16.3+computecanada, 1.17.4+computecanada, 1.18.1+computecanada, 1.18.4+computecanada, 1.19.1+computecanada, 1.19.2+computecanada, 1.20.2+computecanada)
ERROR: No matching distribution found for numpy==1.20.0+computacanada
Looking in links: /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/nix/avx2, /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/nix/generic, /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/wandb-0.12.5+computecanada-py2.py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/configparser-5.0.2+computecanada-py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/protobuf-3.19.4+computecanada-py2.py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/yaspin-2.1.0+computecanada-py3-none-any.whl
Requirement already satisfied: requests<3,>=2.0.0 in /cvmfs/soft.computecanada.ca/easybuild/software/2017/Core/scipy-stack/2019a/lib/python3.7/site-packages (from wandb) (2.21.0)
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/six-1.16.0+computecanada-py2.py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/GitPython-3.1.24+computecanada-py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/psutil-5.7.3+computecanada-cp37-cp37m-linux_x86_64.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/sentry_sdk-1.5.0+computecanada-py2.py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/docker_pycreds-0.4.0+computecanada-py2.py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/subprocess32-3.5.4+computecanada-py3-none-any.whl
Requirement already satisfied: python-dateutil>=2.6.1 in /cvmfs/soft.computecanada.ca/easybuild/software/2017/Core/scipy-stack/2019a/lib/python3.7/site-packages (from wandb) (2.7.5)
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/click-8.1.0+computecanada-py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/pathtools-0.1.2+computecanada-py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/promise-2.3+computecanada-py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/PyYAML-5.3.1+computecanada-cp37-cp37m-linux_x86_64.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/shortuuid-1.0.1+computecanada-py3-none-any.whl
Requirement already satisfied: importlib-metadata in /cvmfs/soft.computecanada.ca/easybuild/software/2017/Core/scipy-stack/2019a/lib/python3.7/site-packages (from Click!=8.0.0,>=7.0->wandb) (0.8)
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/typing_extensions-4.1.1+computecanada-py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/gitdb-4.0.9+computecanada-py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/smmap-5.0.0+computecanada-py3-none-any.whl
Requirement already satisfied: urllib3<1.25,>=1.21.1 in /cvmfs/soft.computecanada.ca/easybuild/software/2017/Core/scipy-stack/2019a/lib/python3.7/site-packages (from requests<3,>=2.0.0->wandb) (1.24.1)
Requirement already satisfied: certifi>=2017.4.17 in /cvmfs/soft.computecanada.ca/easybuild/software/2017/Core/scipy-stack/2019a/lib/python3.7/site-packages (from requests<3,>=2.0.0->wandb) (2018.11.29)
Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /cvmfs/soft.computecanada.ca/easybuild/software/2017/Core/scipy-stack/2019a/lib/python3.7/site-packages (from requests<3,>=2.0.0->wandb) (3.0.4)
Requirement already satisfied: idna<2.9,>=2.5 in /cvmfs/soft.computecanada.ca/easybuild/software/2017/Core/scipy-stack/2019a/lib/python3.7/site-packages (from requests<3,>=2.0.0->wandb) (2.8)
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/termcolor-1.1.0+computecanada-py3-none-any.whl
Requirement already satisfied: zipp>=0.3.2 in /cvmfs/soft.computecanada.ca/easybuild/software/2017/Core/scipy-stack/2019a/lib/python3.7/site-packages (from importlib-metadata->Click!=8.0.0,>=7.0->wandb) (0.3.3)
Installing collected packages: smmap, typing-extensions, termcolor, six, gitdb, yaspin, subprocess32, shortuuid, sentry-sdk, PyYAML, psutil, protobuf, promise, pathtools, GitPython, docker-pycreds, configparser, Click, wandb
  Attempting uninstall: six
    Found existing installation: six 1.12.0
    Not uninstalling six at /cvmfs/soft.computecanada.ca/easybuild/software/2017/Core/scipy-stack/2019a/lib/python3.7/site-packages, outside environment /localscratch/yinan.29785238.0/env
    Can't uninstall 'six'. No files were found to uninstall.
Successfully installed Click-8.1.0+computecanada GitPython-3.1.24+computecanada PyYAML-5.3.1+computecanada configparser-5.0.2+computecanada docker-pycreds-0.4.0+computecanada gitdb-4.0.9+computecanada pathtools-0.1.2+computecanada promise-2.3+computecanada protobuf-3.19.4+computecanada psutil-5.7.3+computecanada sentry-sdk-1.5.0+computecanada shortuuid-1.0.1+computecanada six-1.16.0+computecanada smmap-5.0.0+computecanada subprocess32-3.5.4+computecanada termcolor-1.1.0+computecanada typing-extensions-4.1.1+computecanada wandb-0.12.5+computecanada yaspin-2.1.0+computecanada
Looking in links: /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/nix/avx2, /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/nix/generic, /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic
ERROR: Could not find a version that satisfies the requirement sagemaker (from versions: none)
ERROR: No matching distribution found for sagemaker
Looking in links: /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/nix/avx2, /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/nix/generic, /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/torch-1.9.1+computecanada-cp37-cp37m-linux_x86_64.whl
Requirement already satisfied: typing-extensions in /localscratch/yinan.29785238.0/env/lib/python3.7/site-packages (from torch) (4.1.1+computecanada)
Installing collected packages: torch
Successfully installed torch-1.9.1+computecanada
Looking in links: /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/nix/avx2, /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/nix/generic, /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/transformers-2.5.1+computecanada-py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/filelock-3.4.2+computecanada-py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/tqdm-4.63.1+computecanada-py2.py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/sentencepiece-0.1.91+computecanada-cp37-cp37m-linux_x86_64.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/regex-2020.11.13+computecanada-cp37-cp37m-linux_x86_64.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/tokenizers-0.5.2+computecanada-cp37-cp37m-linux_x86_64.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/boto3-1.21.14+computecanada-py3-none-any.whl
Requirement already satisfied: requests in /cvmfs/soft.computecanada.ca/easybuild/software/2017/Core/scipy-stack/2019a/lib/python3.7/site-packages (from transformers==2.5.1+computecanada) (2.21.0)
Requirement already satisfied: numpy in /cvmfs/soft.computecanada.ca/easybuild/software/2017/Core/scipy-stack/2019a/lib/python3.7/site-packages (from transformers==2.5.1+computecanada) (1.16.0)
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/sacremoses-0.0.49+computecanada-py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/s3transfer-0.5.1+computecanada-py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/botocore-1.24.14+computecanada-py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/jmespath-0.10.0+computecanada-py2.py3-none-any.whl
Requirement already satisfied: python-dateutil<3.0.0,>=2.1 in /cvmfs/soft.computecanada.ca/easybuild/software/2017/Core/scipy-stack/2019a/lib/python3.7/site-packages (from botocore<1.25.0,>=1.24.14->boto3->transformers==2.5.1+computecanada) (2.7.5)
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/urllib3-1.26.9+computecanada-py2.py3-none-any.whl
Requirement already satisfied: six>=1.5 in /localscratch/yinan.29785238.0/env/lib/python3.7/site-packages (from python-dateutil<3.0.0,>=2.1->botocore<1.25.0,>=1.24.14->boto3->transformers==2.5.1+computecanada) (1.16.0+computecanada)
Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /cvmfs/soft.computecanada.ca/easybuild/software/2017/Core/scipy-stack/2019a/lib/python3.7/site-packages (from requests->transformers==2.5.1+computecanada) (3.0.4)
Requirement already satisfied: certifi>=2017.4.17 in /cvmfs/soft.computecanada.ca/easybuild/software/2017/Core/scipy-stack/2019a/lib/python3.7/site-packages (from requests->transformers==2.5.1+computecanada) (2018.11.29)
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/requests-2.27.1+computecanada-py2.py3-none-any.whl
Requirement already satisfied: idna<4,>=2.5 in /cvmfs/soft.computecanada.ca/easybuild/software/2017/Core/scipy-stack/2019a/lib/python3.7/site-packages (from requests->transformers==2.5.1+computecanada) (2.8)
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/charset_normalizer-2.0.12+computecanada-py3-none-any.whl
Requirement already satisfied: click in /localscratch/yinan.29785238.0/env/lib/python3.7/site-packages (from sacremoses->transformers==2.5.1+computecanada) (8.1.0+computecanada)
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/joblib-1.1.0+computecanada-py2.py3-none-any.whl
Requirement already satisfied: importlib-metadata in /cvmfs/soft.computecanada.ca/easybuild/software/2017/Core/scipy-stack/2019a/lib/python3.7/site-packages (from click->sacremoses->transformers==2.5.1+computecanada) (0.8)
Requirement already satisfied: zipp>=0.3.2 in /cvmfs/soft.computecanada.ca/easybuild/software/2017/Core/scipy-stack/2019a/lib/python3.7/site-packages (from importlib-metadata->click->sacremoses->transformers==2.5.1+computecanada) (0.3.3)
Installing collected packages: urllib3, jmespath, botocore, tqdm, s3transfer, regex, joblib, charset-normalizer, tokenizers, sentencepiece, sacremoses, requests, filelock, boto3, transformers
  Attempting uninstall: urllib3
    Found existing installation: urllib3 1.24.1
    Not uninstalling urllib3 at /cvmfs/soft.computecanada.ca/easybuild/software/2017/Core/scipy-stack/2019a/lib/python3.7/site-packages, outside environment /localscratch/yinan.29785238.0/env
    Can't uninstall 'urllib3'. No files were found to uninstall.
  Attempting uninstall: requests
    Found existing installation: requests 2.21.0
    Not uninstalling requests at /cvmfs/soft.computecanada.ca/easybuild/software/2017/Core/scipy-stack/2019a/lib/python3.7/site-packages, outside environment /localscratch/yinan.29785238.0/env
    Can't uninstall 'requests'. No files were found to uninstall.
Successfully installed boto3-1.21.14+computecanada botocore-1.24.14+computecanada charset-normalizer-2.0.12+computecanada filelock-3.4.2+computecanada jmespath-0.10.0+computecanada joblib-1.1.0+computecanada regex-2020.11.13+computecanada requests-2.27.1+computecanada s3transfer-0.5.1+computecanada sacremoses-0.0.49+computecanada sentencepiece-0.1.91+computecanada tokenizers-0.5.2+computecanada tqdm-4.63.1+computecanada transformers-2.5.1+computecanada urllib3-1.26.9+computecanada
Looking in links: /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/nix/avx2, /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/nix/generic, /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/tensorflow_gpu-2.3.0+computecanada-cp37-cp37m-linux_x86_64.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/google_pasta-0.2.0+computecanada-py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/nix/generic/scipy-1.4.1+computecanada-cp37-cp37m-linux_x86_64.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/astunparse-1.6.3+computecanada-py2.py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/wrapt-1.11.2+computecanada-cp37-cp37m-linux_x86_64.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/tensorflow_estimator-2.3.0+computecanada-py2.py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/opt_einsum-3.3.0+computecanada-py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/tensorboard-2.8.0+computecanada-py3-none-any.whl
Requirement already satisfied: wheel>=0.26 in /localscratch/yinan.29785238.0/env/lib/python3.7/site-packages (from tensorflow_gpu==2.3.0+computecanada) (0.33.4)
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/Keras_Preprocessing-1.1.2+computecanada-py3-none-any.whl
Requirement already satisfied: numpy<1.19.0,>=1.16.0 in /cvmfs/soft.computecanada.ca/easybuild/software/2017/Core/scipy-stack/2019a/lib/python3.7/site-packages (from tensorflow_gpu==2.3.0+computecanada) (1.16.0)
Requirement already satisfied: protobuf>=3.9.2 in /localscratch/yinan.29785238.0/env/lib/python3.7/site-packages (from tensorflow_gpu==2.3.0+computecanada) (3.19.4+computecanada)
Requirement already satisfied: six>=1.12.0 in /localscratch/yinan.29785238.0/env/lib/python3.7/site-packages (from tensorflow_gpu==2.3.0+computecanada) (1.16.0+computecanada)
Requirement already satisfied: termcolor>=1.1.0 in /localscratch/yinan.29785238.0/env/lib/python3.7/site-packages (from tensorflow_gpu==2.3.0+computecanada) (1.1.0+computecanada)
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/grpcio-1.38.0+computecanada-cp37-cp37m-linux_x86_64.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/absl_py-1.0.0+computecanada-py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/nix/avx2/h5py-2.10.0+computecanada-cp37-cp37m-linux_x86_64.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/gast-0.3.3+computecanada-py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/google_auth-2.3.3+computecanada-py2.py3-none-any.whl
Requirement already satisfied: requests<3,>=2.21.0 in /localscratch/yinan.29785238.0/env/lib/python3.7/site-packages (from tensorboard<3,>=2.3.0->tensorflow_gpu==2.3.0+computecanada) (2.27.1+computecanada)
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/Werkzeug-2.0.3+computecanada-py3-none-any.whl
Requirement already satisfied: setuptools>=41.0.0 in /localscratch/yinan.29785238.0/env/lib/python3.7/site-packages (from tensorboard<3,>=2.3.0->tensorflow_gpu==2.3.0+computecanada) (41.0.1)
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/Markdown-3.3.6+computecanada-py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/tensorboard_plugin_wit-1.8.0+computecanada-py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/tensorboard_data_server-0.6.1+computecanada-py3-none-linux_x86_64.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/google_auth_oauthlib-0.4.6+computecanada-py2.py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/cachetools-4.2.4+computecanada-py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/rsa-4.8+computecanada-py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/pyasn1_modules-0.2.8+computecanada-py2.py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/requests_oauthlib-1.3.0+computecanada-py2.py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/importlib_metadata-4.10.1+computecanada-py3-none-any.whl
Requirement already satisfied: typing-extensions>=3.6.4 in /localscratch/yinan.29785238.0/env/lib/python3.7/site-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard<3,>=2.3.0->tensorflow_gpu==2.3.0+computecanada) (4.1.1+computecanada)
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/zipp-3.7.0+computecanada-py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/pyasn1-0.4.8+computecanada-py2.py3-none-any.whl
Requirement already satisfied: charset-normalizer~=2.0.0 in /localscratch/yinan.29785238.0/env/lib/python3.7/site-packages (from requests<3,>=2.21.0->tensorboard<3,>=2.3.0->tensorflow_gpu==2.3.0+computecanada) (2.0.12+computecanada)
Requirement already satisfied: idna<4,>=2.5 in /cvmfs/soft.computecanada.ca/easybuild/software/2017/Core/scipy-stack/2019a/lib/python3.7/site-packages (from requests<3,>=2.21.0->tensorboard<3,>=2.3.0->tensorflow_gpu==2.3.0+computecanada) (2.8)
Requirement already satisfied: urllib3<1.27,>=1.21.1 in /localscratch/yinan.29785238.0/env/lib/python3.7/site-packages (from requests<3,>=2.21.0->tensorboard<3,>=2.3.0->tensorflow_gpu==2.3.0+computecanada) (1.26.9+computecanada)
Requirement already satisfied: certifi>=2017.4.17 in /cvmfs/soft.computecanada.ca/easybuild/software/2017/Core/scipy-stack/2019a/lib/python3.7/site-packages (from requests<3,>=2.21.0->tensorboard<3,>=2.3.0->tensorflow_gpu==2.3.0+computecanada) (2018.11.29)
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/oauthlib-3.1.1+computecanada-py2.py3-none-any.whl
Installing collected packages: pyasn1, zipp, rsa, pyasn1-modules, oauthlib, cachetools, requests-oauthlib, importlib-metadata, google-auth, werkzeug, tensorboard-plugin-wit, tensorboard-data-server, markdown, grpcio, google-auth-oauthlib, absl-py, wrapt, tensorflow-estimator, tensorboard, scipy, opt-einsum, keras-preprocessing, h5py, google-pasta, gast, astunparse, tensorflow-gpu
  Attempting uninstall: pyasn1
    Found existing installation: pyasn1 0.4.3
    Not uninstalling pyasn1 at /cvmfs/soft.computecanada.ca/easybuild/software/2017/Core/scipy-stack/2019a/lib/python3.7/site-packages, outside environment /localscratch/yinan.29785238.0/env
    Can't uninstall 'pyasn1'. No files were found to uninstall.
  Attempting uninstall: zipp
    Found existing installation: zipp 0.3.3
    Not uninstalling zipp at /cvmfs/soft.computecanada.ca/easybuild/software/2017/Core/scipy-stack/2019a/lib/python3.7/site-packages, outside environment /localscratch/yinan.29785238.0/env
    Can't uninstall 'zipp'. No files were found to uninstall.
  Attempting uninstall: importlib-metadata
    Found existing installation: importlib-metadata 0.8
    Not uninstalling importlib-metadata at /cvmfs/soft.computecanada.ca/easybuild/software/2017/Core/scipy-stack/2019a/lib/python3.7/site-packages, outside environment /localscratch/yinan.29785238.0/env
    Can't uninstall 'importlib-metadata'. No files were found to uninstall.
  Attempting uninstall: scipy
    Found existing installation: scipy 1.2.0
    Not uninstalling scipy at /cvmfs/soft.computecanada.ca/easybuild/software/2017/Core/scipy-stack/2019a/lib/python3.7/site-packages, outside environment /localscratch/yinan.29785238.0/env
    Can't uninstall 'scipy'. No files were found to uninstall.
Successfully installed absl-py-1.0.0+computecanada astunparse-1.6.3+computecanada cachetools-4.2.4+computecanada gast-0.3.3+computecanada google-auth-2.3.3+computecanada google-auth-oauthlib-0.4.6+computecanada google-pasta-0.2.0+computecanada grpcio-1.38.0+computecanada h5py-2.10.0+computecanada importlib-metadata-4.10.1+computecanada keras-preprocessing-1.1.2+computecanada markdown-3.3.6+computecanada oauthlib-3.1.1+computecanada opt-einsum-3.3.0+computecanada pyasn1-0.4.8+computecanada pyasn1-modules-0.2.8+computecanada requests-oauthlib-1.3.0+computecanada rsa-4.8+computecanada scipy-1.4.1+computecanada tensorboard-2.8.0+computecanada tensorboard-data-server-0.6.1+computecanada tensorboard-plugin-wit-1.8.0+computecanada tensorflow-estimator-2.3.0+computecanada tensorflow-gpu-2.3.0+computecanada werkzeug-2.0.3+computecanada wrapt-1.11.2+computecanada zipp-3.7.0+computecanada
Looking in links: /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/nix/avx2, /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/nix/generic, /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/keras-2.8.0+computecanada-py2.py3-none-any.whl
Installing collected packages: Keras
Successfully installed Keras-2.8.0+computecanada
Looking in links: /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/nix/avx2, /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/nix/generic, /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/urllib3-1.26.7+computecanada-py2.py3-none-any.whl
Installing collected packages: urllib3
  Attempting uninstall: urllib3
    Found existing installation: urllib3 1.26.9+computecanada
    Uninstalling urllib3-1.26.9+computecanada:
      Successfully uninstalled urllib3-1.26.9+computecanada
Successfully installed urllib3-1.26.7+computecanada
Looking in links: /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/nix/avx2, /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/nix/generic, /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/nltk-3.7+computecanada-py3-none-any.whl
Requirement already satisfied: joblib in /localscratch/yinan.29785238.0/env/lib/python3.7/site-packages (from nltk) (1.1.0+computecanada)
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/nltk-3.6.5+computecanada-py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/nltk-3.6.3+computecanada-py3-none-any.whl
Requirement already satisfied: regex in /localscratch/yinan.29785238.0/env/lib/python3.7/site-packages (from nltk) (2020.11.13+computecanada)
Requirement already satisfied: tqdm in /localscratch/yinan.29785238.0/env/lib/python3.7/site-packages (from nltk) (4.63.1+computecanada)
Requirement already satisfied: click in /localscratch/yinan.29785238.0/env/lib/python3.7/site-packages (from nltk) (8.1.0+computecanada)
Requirement already satisfied: importlib-metadata in /localscratch/yinan.29785238.0/env/lib/python3.7/site-packages (from click->nltk) (4.10.1+computecanada)
Requirement already satisfied: typing-extensions>=3.6.4 in /localscratch/yinan.29785238.0/env/lib/python3.7/site-packages (from importlib-metadata->click->nltk) (4.1.1+computecanada)
Requirement already satisfied: zipp>=0.5 in /localscratch/yinan.29785238.0/env/lib/python3.7/site-packages (from importlib-metadata->click->nltk) (3.7.0+computecanada)
Installing collected packages: nltk
Successfully installed nltk-3.6.3+computecanada
Looking in links: /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/nix/avx2, /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/nix/generic, /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/scikit_learn-0.22.1+computecanada-cp37-cp37m-linux_x86_64.whl
Requirement already satisfied: numpy>=1.11.0 in /cvmfs/soft.computecanada.ca/easybuild/software/2017/Core/scipy-stack/2019a/lib/python3.7/site-packages (from scikit-learn==0.22.1) (1.16.0)
Requirement already satisfied: joblib>=0.11 in /localscratch/yinan.29785238.0/env/lib/python3.7/site-packages (from scikit-learn==0.22.1) (1.1.0+computecanada)
Requirement already satisfied: scipy>=0.17.0 in /localscratch/yinan.29785238.0/env/lib/python3.7/site-packages (from scikit-learn==0.22.1) (1.4.1+computecanada)
Installing collected packages: scikit-learn
Successfully installed scikit-learn-0.22.1+computecanada
Looking in links: /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/nix/avx2, /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/nix/generic, /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic
Requirement already satisfied: tokenizers==0.5.2 in /localscratch/yinan.29785238.0/env/lib/python3.7/site-packages (0.5.2+computecanada)
wandb: Appending key for api.wandb.ai to your netrc file: /home/yinan/.netrc
Starting Task
2022-03-31 06:07:29.067190: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1
[nltk_data] Downloading package stopwords to /home/yinan/nltk_data...
[nltk_data]   Package stopwords is already up-to-date!
[nltk_data] Downloading package wordnet to /home/yinan/nltk_data...
[nltk_data]   Package wordnet is already up-to-date!
wandb: Currently logged in as: yinanazhou (use `wandb login --relogin` to force relogin)
wandb: wandb version 0.12.11 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
2022-03-31 06:07:39.408032: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1
wandb: Tracking run with wandb version 0.12.5
wandb: Syncing run sparkling-sun-2
wandb: ⭐️ View project at https://wandb.ai/yinanazhou/xl_512_bs_8_lr_1e06_es_3_lc_True_nr_False_sr_True_stem_False_lemma_False_repeat_1_fold_1
wandb: 🚀 View run at https://wandb.ai/yinanazhou/xl_512_bs_8_lr_1e06_es_3_lc_True_nr_False_sr_True_stem_False_lemma_False_repeat_1_fold_1/runs/1to75noc
wandb: Run data is saved locally in /project/6002780/yinan/Thesis_MER_Lyrics/lyric-emotion/wandb/run-20220331_060737-1to75noc
wandb: Run `wandb offline` to turn off syncing.

Validation loss decreased (inf --> 1.438751).  Saving model ...
Validation loss decreased (1.438751 --> 1.418951).  Saving model ...
Validation loss decreased (1.418951 --> 1.403289).  Saving model ...
Validation loss decreased (1.403289 --> 1.389923).  Saving model ...
Validation loss decreased (1.389923 --> 1.379769).  Saving model ...
Validation loss decreased (1.379769 --> 1.370931).  Saving model ...
Validation loss decreased (1.370931 --> 1.363271).  Saving model ...
Validation loss decreased (1.363271 --> 1.356312).  Saving model ...
Validation loss decreased (1.356312 --> 1.349979).  Saving model ...
Validation loss decreased (1.349979 --> 1.343323).  Saving model ...
Validation loss decreased (1.343323 --> 1.336362).  Saving model ...
Validation loss decreased (1.336362 --> 1.330191).  Saving model ...
Validation loss decreased (1.330191 --> 1.323821).  Saving model ...
Validation loss decreased (1.323821 --> 1.317705).  Saving model ...
Validation loss decreased (1.317705 --> 1.311222).  Saving model ...
Validation loss decreased (1.311222 --> 1.304461).  Saving model ...
Validation loss decreased (1.304461 --> 1.297779).  Saving model ...
Validation loss decreased (1.297779 --> 1.290949).  Saving model ...
Validation loss decreased (1.290949 --> 1.283989).  Saving model ...
Validation loss decreased (1.283989 --> 1.277859).  Saving model ...
Validation loss decreased (1.277859 --> 1.271250).  Saving model ...
Validation loss decreased (1.271250 --> 1.263335).  Saving model ...
Validation loss decreased (1.263335 --> 1.256937).  Saving model ...
Validation loss decreased (1.256937 --> 1.249202).  Saving model ...
Validation loss decreased (1.249202 --> 1.243923).  Saving model ...
Validation loss decreased (1.243923 --> 1.236385).  Saving model ...
Validation loss decreased (1.236385 --> 1.229786).  Saving model ...
Validation loss decreased (1.229786 --> 1.225042).  Saving model ...
Validation loss decreased (1.225042 --> 1.220232).  Saving model ...
Validation loss decreased (1.220232 --> 1.215213).  Saving model ...
Validation loss decreased (1.215213 --> 1.209694).  Saving model ...
Validation loss decreased (1.209694 --> 1.204692).  Saving model ...
Validation loss decreased (1.204692 --> 1.200113).  Saving model ...
Validation loss decreased (1.200113 --> 1.193838).  Saving model ...
Validation loss decreased (1.193838 --> 1.190156).  Saving model ...
Validation loss decreased (1.190156 --> 1.185947).  Saving model ...
Validation loss decreased (1.185947 --> 1.181116).  Saving model ...
Validation loss decreased (1.181116 --> 1.176395).  Saving model ...
Validation loss decreased (1.176395 --> 1.173479).  Saving model ...
Validation loss decreased (1.173479 --> 1.171065).  Saving model ...
Validation loss decreased (1.171065 --> 1.164059).  Saving model ...
Validation loss decreased (1.164059 --> 1.159869).  Saving model ...
Validation loss decreased (1.159869 --> 1.158189).  Saving model ...
Validation loss decreased (1.158189 --> 1.153697).  Saving model ...
Validation loss decreased (1.153697 --> 1.149670).  Saving model ...
Validation loss decreased (1.149670 --> 1.143968).  Saving model ...
Validation loss decreased (1.143968 --> 1.140727).  Saving model ...
Validation loss decreased (1.140727 --> 1.139116).  Saving model ...
Validation loss decreased (1.139116 --> 1.132226).  Saving model ...
Validation loss decreased (1.132226 --> 1.127853).  Saving model ...
Validation loss decreased (1.127853 --> 1.123505).  Saving model ...
Validation loss decreased (1.123505 --> 1.119249).  Saving model ...
Validation loss decreased (1.119249 --> 1.117118).  Saving model ...
Validation loss decreased (1.117118 --> 1.115362).  Saving model ...
Validation loss decreased (1.115362 --> 1.113534).  Saving model ...
Validation loss decreased (1.113534 --> 1.107802).  Saving model ...
Validation loss decreased (1.107802 --> 1.105366).  Saving model ...
Validation loss decreased (1.105366 --> 1.101634).  Saving model ...
Validation loss decreased (1.101634 --> 1.096751).  Saving model ...
Validation loss decreased (1.096751 --> 1.095560).  Saving model ...
Validation loss decreased (1.095560 --> 1.090876).  Saving model ...
Validation loss decreased (1.090876 --> 1.087604).  Saving model ...
Validation loss decreased (1.087604 --> 1.083187).  Saving model ...
Validation loss decreased (1.083187 --> 1.081971).  Saving model ...
Validation loss decreased (1.081971 --> 1.081882).  Saving model ...
Validation loss decreased (1.081882 --> 1.075714).  Saving model ...
EarlyStopping counter: 1 out of 3.0
Validation loss decreased (1.075714 --> 1.069536).  Saving model ...
Validation loss decreased (1.069536 --> 1.067538).  Saving model ...
Validation loss decreased (1.067538 --> 1.065469).  Saving model ...
Validation loss decreased (1.065469 --> 1.061253).  Saving model ...
Validation loss decreased (1.061253 --> 1.059912).  Saving model ...
Validation loss decreased (1.059912 --> 1.057221).  Saving model ...
Validation loss decreased (1.057221 --> 1.055016).  Saving model ...
Validation loss decreased (1.055016 --> 1.051605).  Saving model ...
Validation loss decreased (1.051605 --> 1.048695).  Saving model ...
Validation loss decreased (1.048695 --> 1.048339).  Saving model ...
Validation loss decreased (1.048339 --> 1.047874).  Saving model ...
Validation loss decreased (1.047874 --> 1.042140).  Saving model ...
Validation loss decreased (1.042140 --> 1.038831).  Saving model ...
Validation loss decreased (1.038831 --> 1.037597).  Saving model ...
EarlyStopping counter: 1 out of 3.0
Validation loss decreased (1.037597 --> 1.036116).  Saving model ...
Validation loss decreased (1.036116 --> 1.035876).  Saving model ...
Validation loss decreased (1.035876 --> 1.031280).  Saving model ...
Validation loss decreased (1.031280 --> 1.030312).  Saving model ...
Validation loss decreased (1.030312 --> 1.027784).  Saving model ...
Validation loss decreased (1.027784 --> 1.027054).  Saving model ...
Validation loss decreased (1.027054 --> 1.023174).  Saving model ...
Validation loss decreased (1.023174 --> 1.021052).  Saving model ...
Validation loss decreased (1.021052 --> 1.020149).  Saving model ...
Validation loss decreased (1.020149 --> 1.018719).  Saving model ...
Validation loss decreased (1.018719 --> 1.018044).  Saving model ...
EarlyStopping counter: 1 out of 3.0
Validation loss decreased (1.018044 --> 1.017023).  Saving model ...
Validation loss decreased (1.017023 --> 1.015802).  Saving model ...
Validation loss decreased (1.015802 --> 1.013845).  Saving model ...
Validation loss decreased (1.013845 --> 1.011273).  Saving model ...
Validation loss decreased (1.011273 --> 1.009174).  Saving model ...
Validation loss decreased (1.009174 --> 1.009171).  Saving model ...
Validation loss decreased (1.009171 --> 1.007543).  Saving model ...
EarlyStopping counter: 1 out of 3.0
Validation loss decreased (1.007543 --> 1.006352).  Saving model ...
Validation loss decreased (1.006352 --> 1.004243).  Saving model ...
Validation loss decreased (1.004243 --> 1.003232).  Saving model ...
Validation loss decreased (1.003232 --> 0.998866).  Saving model ...
Validation loss decreased (0.998866 --> 0.998735).  Saving model ...
Validation loss decreased (0.998735 --> 0.997981).  Saving model ...
Validation loss decreased (0.997981 --> 0.996418).  Saving model ...
Validation loss decreased (0.996418 --> 0.995420).  Saving model ...
EarlyStopping counter: 1 out of 3.0
EarlyStopping counter: 2 out of 3.0
EarlyStopping counter: 3 out of 3.0
/localscratch/yinan.29785238.0/env/lib/python3.7/site-packages/torch/nn/functional.py:1794: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.
  warnings.warn("nn.functional.tanh is deprecated. Use torch.tanh instead.")
/localscratch/yinan.29785238.0/env/lib/python3.7/site-packages/transformers/optimization.py:155: UserWarning: This overload of add_ is deprecated:
	add_(Number alpha, Tensor other)
Consider using one of the following signatures instead:
	add_(Tensor other, *, Number alpha) (Triggered internally at  ../torch/csrc/utils/python_arg_parser.cpp:1025.)
  exp_avg.mul_(beta1).add_(1.0 - beta1, grad)
wandb: Waiting for W&B process to finish, PID 192218... (success).
wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: \ 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: | 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: / 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: \ 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: | 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: / 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: \ 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: | 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: / 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb:                                                                                
wandb: Run history:
wandb:     e_F1 ▁▂▂▄▄▅▅▅▆▆▆▆▆▆▆▇▇▇▇▇▇▇▇▇▇███████████████
wandb:   e_loss █▇▇▇▆▆▆▅▅▅▅▄▄▄▄▃▃▃▃▃▃▃▂▂▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁
wandb:     t_F1 ▁▂▃▃▃▃▄▄▄▅▅▅▅▆▆▆▆▆▆▆▆▆▆▆▇▇▇▇▇▇▇▇██▇▇████
wandb:   t_loss ██▇▇▇▇▆▆▆▅▅▅▅▄▄▄▄▄▄▃▃▃▃▃▃▃▂▂▂▂▂▂▂▂▂▂▁▁▁▁
wandb: 
wandb: Run summary:
wandb:     e_F1 56.04753
wandb:   e_loss 0.99857
wandb:     t_F1 68.14367
wandb:   t_loss 0.80946
wandb: 
wandb: Synced 4 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Synced sparkling-sun-2: https://wandb.ai/yinanazhou/xl_512_bs_8_lr_1e06_es_3_lc_True_nr_False_sr_True_stem_False_lemma_False_repeat_1_fold_1/runs/1to75noc
wandb: Find logs at: ./wandb/run-20220331_060737-1to75noc/logs/debug.log
wandb: 

wandb: wandb version 0.12.11 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
2022-03-31 07:21:34.316230: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1
wandb: Tracking run with wandb version 0.12.5
wandb: Syncing run quiet-wave-2
wandb: ⭐️ View project at https://wandb.ai/yinanazhou/xl_512_bs_8_lr_1e06_es_3_lc_True_nr_False_sr_True_stem_False_lemma_False_repeat_1_fold_2
wandb: 🚀 View run at https://wandb.ai/yinanazhou/xl_512_bs_8_lr_1e06_es_3_lc_True_nr_False_sr_True_stem_False_lemma_False_repeat_1_fold_2/runs/2plbtix2
wandb: Run data is saved locally in /project/6002780/yinan/Thesis_MER_Lyrics/lyric-emotion/wandb/run-20220331_072131-2plbtix2
wandb: Run `wandb offline` to turn off syncing.

Validation loss decreased (inf --> 1.396162).  Saving model ...
Validation loss decreased (1.396162 --> 1.384386).  Saving model ...
Validation loss decreased (1.384386 --> 1.375269).  Saving model ...
Validation loss decreased (1.375269 --> 1.367239).  Saving model ...
Validation loss decreased (1.367239 --> 1.361112).  Saving model ...
Validation loss decreased (1.361112 --> 1.355486).  Saving model ...
Validation loss decreased (1.355486 --> 1.349890).  Saving model ...
Validation loss decreased (1.349890 --> 1.344696).  Saving model ...
Validation loss decreased (1.344696 --> 1.339455).  Saving model ...
Validation loss decreased (1.339455 --> 1.334926).  Saving model ...
Validation loss decreased (1.334926 --> 1.330212).  Saving model ...
Validation loss decreased (1.330212 --> 1.325208).  Saving model ...
Validation loss decreased (1.325208 --> 1.319826).  Saving model ...
Validation loss decreased (1.319826 --> 1.313878).  Saving model ...
Validation loss decreased (1.313878 --> 1.308290).  Saving model ...
Validation loss decreased (1.308290 --> 1.302360).  Saving model ...
Validation loss decreased (1.302360 --> 1.296931).  Saving model ...
Validation loss decreased (1.296931 --> 1.290667).  Saving model ...
Validation loss decreased (1.290667 --> 1.284446).  Saving model ...
Validation loss decreased (1.284446 --> 1.277866).  Saving model ...
Validation loss decreased (1.277866 --> 1.271403).  Saving model ...
Validation loss decreased (1.271403 --> 1.264709).  Saving model ...
Validation loss decreased (1.264709 --> 1.257441).  Saving model ...
Validation loss decreased (1.257441 --> 1.250933).  Saving model ...
Validation loss decreased (1.250933 --> 1.243486).  Saving model ...
Validation loss decreased (1.243486 --> 1.235449).  Saving model ...
Validation loss decreased (1.235449 --> 1.227299).  Saving model ...
Validation loss decreased (1.227299 --> 1.218932).  Saving model ...
Validation loss decreased (1.218932 --> 1.210861).  Saving model ...
Validation loss decreased (1.210861 --> 1.204491).  Saving model ...
Validation loss decreased (1.204491 --> 1.197856).  Saving model ...
Validation loss decreased (1.197856 --> 1.191851).  Saving model ...
Validation loss decreased (1.191851 --> 1.184351).  Saving model ...
Validation loss decreased (1.184351 --> 1.176424).  Saving model ...
Validation loss decreased (1.176424 --> 1.170231).  Saving model ...
Validation loss decreased (1.170231 --> 1.164565).  Saving model ...
Validation loss decreased (1.164565 --> 1.155905).  Saving model ...
Validation loss decreased (1.155905 --> 1.149512).  Saving model ...
Validation loss decreased (1.149512 --> 1.142735).  Saving model ...
Validation loss decreased (1.142735 --> 1.136604).  Saving model ...
Validation loss decreased (1.136604 --> 1.129037).  Saving model ...
Validation loss decreased (1.129037 --> 1.120866).  Saving model ...
Validation loss decreased (1.120866 --> 1.114537).  Saving model ...
Validation loss decreased (1.114537 --> 1.107220).  Saving model ...
Validation loss decreased (1.107220 --> 1.100338).  Saving model ...
Validation loss decreased (1.100338 --> 1.095198).  Saving model ...
Validation loss decreased (1.095198 --> 1.089752).  Saving model ...
Validation loss decreased (1.089752 --> 1.084694).  Saving model ...
Validation loss decreased (1.084694 --> 1.079821).  Saving model ...
Validation loss decreased (1.079821 --> 1.075705).  Saving model ...
Validation loss decreased (1.075705 --> 1.071005).  Saving model ...
Validation loss decreased (1.071005 --> 1.066436).  Saving model ...
Validation loss decreased (1.066436 --> 1.060451).  Saving model ...
Validation loss decreased (1.060451 --> 1.054365).  Saving model ...
Validation loss decreased (1.054365 --> 1.048500).  Saving model ...
Validation loss decreased (1.048500 --> 1.043185).  Saving model ...
Validation loss decreased (1.043185 --> 1.041207).  Saving model ...
Validation loss decreased (1.041207 --> 1.037001).  Saving model ...
Validation loss decreased (1.037001 --> 1.028929).  Saving model ...
Validation loss decreased (1.028929 --> 1.024625).  Saving model ...
Validation loss decreased (1.024625 --> 1.019554).  Saving model ...
Validation loss decreased (1.019554 --> 1.016618).  Saving model ...
Validation loss decreased (1.016618 --> 1.014457).  Saving model ...
Validation loss decreased (1.014457 --> 1.010392).  Saving model ...
Validation loss decreased (1.010392 --> 1.006233).  Saving model ...
Validation loss decreased (1.006233 --> 1.001501).  Saving model ...
Validation loss decreased (1.001501 --> 0.998134).  Saving model ...
Validation loss decreased (0.998134 --> 0.993645).  Saving model ...
Validation loss decreased (0.993645 --> 0.988954).  Saving model ...
Validation loss decreased (0.988954 --> 0.986301).  Saving model ...
Validation loss decreased (0.986301 --> 0.982018).  Saving model ...
Validation loss decreased (0.982018 --> 0.978096).  Saving model ...
Validation loss decreased (0.978096 --> 0.975025).  Saving model ...
Validation loss decreased (0.975025 --> 0.971898).  Saving model ...
Validation loss decreased (0.971898 --> 0.968708).  Saving model ...
Validation loss decreased (0.968708 --> 0.965289).  Saving model ...
Validation loss decreased (0.965289 --> 0.963061).  Saving model ...
Validation loss decreased (0.963061 --> 0.959419).  Saving model ...
Validation loss decreased (0.959419 --> 0.956264).  Saving model ...
Validation loss decreased (0.956264 --> 0.953844).  Saving model ...
Validation loss decreased (0.953844 --> 0.952169).  Saving model ...
Validation loss decreased (0.952169 --> 0.949545).  Saving model ...
Validation loss decreased (0.949545 --> 0.948333).  Saving model ...
Validation loss decreased (0.948333 --> 0.946420).  Saving model ...
Validation loss decreased (0.946420 --> 0.944224).  Saving model ...
Validation loss decreased (0.944224 --> 0.941360).  Saving model ...
Validation loss decreased (0.941360 --> 0.939652).  Saving model ...
Validation loss decreased (0.939652 --> 0.937444).  Saving model ...
Validation loss decreased (0.937444 --> 0.934545).  Saving model ...
Validation loss decreased (0.934545 --> 0.933764).  Saving model ...
Validation loss decreased (0.933764 --> 0.933611).  Saving model ...
Validation loss decreased (0.933611 --> 0.930966).  Saving model ...
EarlyStopping counter: 1 out of 3.0
Validation loss decreased (0.930966 --> 0.928578).  Saving model ...
Validation loss decreased (0.928578 --> 0.927380).  Saving model ...
Validation loss decreased (0.927380 --> 0.925544).  Saving model ...
Validation loss decreased (0.925544 --> 0.924573).  Saving model ...
EarlyStopping counter: 1 out of 3.0
Validation loss decreased (0.924573 --> 0.923630).  Saving model ...
Validation loss decreased (0.923630 --> 0.921553).  Saving model ...
Validation loss decreased (0.921553 --> 0.920565).  Saving model ...
Validation loss decreased (0.920565 --> 0.918538).  Saving model ...
Validation loss decreased (0.918538 --> 0.917413).  Saving model ...
Validation loss decreased (0.917413 --> 0.916182).  Saving model ...
Validation loss decreased (0.916182 --> 0.915030).  Saving model ...
EarlyStopping counter: 1 out of 3.0
EarlyStopping counter: 2 out of 3.0
Validation loss decreased (0.915030 --> 0.914165).  Saving model ...
Validation loss decreased (0.914165 --> 0.912961).  Saving model ...
Validation loss decreased (0.912961 --> 0.910758).  Saving model ...
Validation loss decreased (0.910758 --> 0.910444).  Saving model ...
Validation loss decreased (0.910444 --> 0.910440).  Saving model ...
EarlyStopping counter: 1 out of 3.0
EarlyStopping counter: 2 out of 3.0
EarlyStopping counter: 3 out of 3.0
/localscratch/yinan.29785238.0/env/lib/python3.7/site-packages/torch/nn/functional.py:1794: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.
  warnings.warn("nn.functional.tanh is deprecated. Use torch.tanh instead.")
wandb: Waiting for W&B process to finish, PID 196215... (success).
wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: \ 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: | 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: / 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: \ 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: | 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: / 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: \ 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: | 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: / 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb:                                                                                
wandb: Run history:
wandb:     e_F1 ▁▁▂▃▄▅▆▆▆▆▆▆▇▇▇▇▇▇▇▇▇▇▇▇▇███████████████
wandb:   e_loss ██▇▇▇▇▆▆▆▆▅▅▅▄▄▄▄▃▃▃▃▃▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁
wandb:     t_F1 ▁▁▂▂▃▃▃▃▃▄▄▅▅▅▆▅▅▆▆▆▆▆▆▇▇▆▇▇▇▇▇▇▇▇█▇▇█▇▇
wandb:   t_loss ██▇█▇▇▇▇▇▆▆▆▆▆▅▅▅▄▄▄▄▄▄▃▃▃▃▃▂▃▂▂▂▂▂▁▂▁▁▁
wandb: 
wandb: Run summary:
wandb:     e_F1 61.92242
wandb:   e_loss 0.91236
wandb:     t_F1 69.53378
wandb:   t_loss 0.79328
wandb: 
wandb: Synced 4 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Synced quiet-wave-2: https://wandb.ai/yinanazhou/xl_512_bs_8_lr_1e06_es_3_lc_True_nr_False_sr_True_stem_False_lemma_False_repeat_1_fold_2/runs/2plbtix2
wandb: Find logs at: ./wandb/run-20220331_072131-2plbtix2/logs/debug.log
wandb: 

wandb: wandb version 0.12.11 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
2022-03-31 08:37:30.715590: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1
wandb: Tracking run with wandb version 0.12.5
wandb: Syncing run effortless-elevator-2
wandb: ⭐️ View project at https://wandb.ai/yinanazhou/xl_512_bs_8_lr_1e06_es_3_lc_True_nr_False_sr_True_stem_False_lemma_False_repeat_2_fold_1
wandb: 🚀 View run at https://wandb.ai/yinanazhou/xl_512_bs_8_lr_1e06_es_3_lc_True_nr_False_sr_True_stem_False_lemma_False_repeat_2_fold_1/runs/2ecc6dtw
wandb: Run data is saved locally in /project/6002780/yinan/Thesis_MER_Lyrics/lyric-emotion/wandb/run-20220331_083728-2ecc6dtw
wandb: Run `wandb offline` to turn off syncing.

Validation loss decreased (inf --> 1.426720).  Saving model ...
Validation loss decreased (1.426720 --> 1.413777).  Saving model ...
Validation loss decreased (1.413777 --> 1.403015).  Saving model ...
Validation loss decreased (1.403015 --> 1.393760).  Saving model ...
Validation loss decreased (1.393760 --> 1.386200).  Saving model ...
Validation loss decreased (1.386200 --> 1.379980).  Saving model ...
Validation loss decreased (1.379980 --> 1.373848).  Saving model ...
Validation loss decreased (1.373848 --> 1.368604).  Saving model ...
Validation loss decreased (1.368604 --> 1.363436).  Saving model ...
Validation loss decreased (1.363436 --> 1.357997).  Saving model ...
Validation loss decreased (1.357997 --> 1.353272).  Saving model ...
Validation loss decreased (1.353272 --> 1.348820).  Saving model ...
Validation loss decreased (1.348820 --> 1.344573).  Saving model ...
Validation loss decreased (1.344573 --> 1.339947).  Saving model ...
Validation loss decreased (1.339947 --> 1.335123).  Saving model ...
Validation loss decreased (1.335123 --> 1.330519).  Saving model ...
Validation loss decreased (1.330519 --> 1.325475).  Saving model ...
Validation loss decreased (1.325475 --> 1.320605).  Saving model ...
Validation loss decreased (1.320605 --> 1.315615).  Saving model ...
Validation loss decreased (1.315615 --> 1.310380).  Saving model ...
Validation loss decreased (1.310380 --> 1.304564).  Saving model ...
Validation loss decreased (1.304564 --> 1.299141).  Saving model ...
Validation loss decreased (1.299141 --> 1.293158).  Saving model ...
Validation loss decreased (1.293158 --> 1.287267).  Saving model ...
Validation loss decreased (1.287267 --> 1.280291).  Saving model ...
Validation loss decreased (1.280291 --> 1.273545).  Saving model ...
Validation loss decreased (1.273545 --> 1.266969).  Saving model ...
Validation loss decreased (1.266969 --> 1.259087).  Saving model ...
Validation loss decreased (1.259087 --> 1.251778).  Saving model ...
Validation loss decreased (1.251778 --> 1.244355).  Saving model ...
Validation loss decreased (1.244355 --> 1.236361).  Saving model ...
Validation loss decreased (1.236361 --> 1.228895).  Saving model ...
Validation loss decreased (1.228895 --> 1.219600).  Saving model ...
Validation loss decreased (1.219600 --> 1.210854).  Saving model ...
Validation loss decreased (1.210854 --> 1.201785).  Saving model ...
Validation loss decreased (1.201785 --> 1.191872).  Saving model ...
Validation loss decreased (1.191872 --> 1.182068).  Saving model ...
Validation loss decreased (1.182068 --> 1.172400).  Saving model ...
Validation loss decreased (1.172400 --> 1.163634).  Saving model ...
Validation loss decreased (1.163634 --> 1.153068).  Saving model ...
Validation loss decreased (1.153068 --> 1.143785).  Saving model ...
Validation loss decreased (1.143785 --> 1.134522).  Saving model ...
Validation loss decreased (1.134522 --> 1.126945).  Saving model ...
Validation loss decreased (1.126945 --> 1.118816).  Saving model ...
Validation loss decreased (1.118816 --> 1.111026).  Saving model ...
Validation loss decreased (1.111026 --> 1.103719).  Saving model ...
Validation loss decreased (1.103719 --> 1.097832).  Saving model ...
Validation loss decreased (1.097832 --> 1.090729).  Saving model ...
Validation loss decreased (1.090729 --> 1.084235).  Saving model ...
Validation loss decreased (1.084235 --> 1.077493).  Saving model ...
Validation loss decreased (1.077493 --> 1.070495).  Saving model ...
Validation loss decreased (1.070495 --> 1.064526).  Saving model ...
Validation loss decreased (1.064526 --> 1.059830).  Saving model ...
Validation loss decreased (1.059830 --> 1.054641).  Saving model ...
Validation loss decreased (1.054641 --> 1.049569).  Saving model ...
Validation loss decreased (1.049569 --> 1.045567).  Saving model ...
Validation loss decreased (1.045567 --> 1.041290).  Saving model ...
Validation loss decreased (1.041290 --> 1.037422).  Saving model ...
Validation loss decreased (1.037422 --> 1.032772).  Saving model ...
Validation loss decreased (1.032772 --> 1.028933).  Saving model ...
Validation loss decreased (1.028933 --> 1.024378).  Saving model ...
Validation loss decreased (1.024378 --> 1.021097).  Saving model ...
Validation loss decreased (1.021097 --> 1.018334).  Saving model ...
Validation loss decreased (1.018334 --> 1.015122).  Saving model ...
Validation loss decreased (1.015122 --> 1.012405).  Saving model ...
Validation loss decreased (1.012405 --> 1.009290).  Saving model ...
Validation loss decreased (1.009290 --> 1.007064).  Saving model ...
Validation loss decreased (1.007064 --> 1.005321).  Saving model ...
Validation loss decreased (1.005321 --> 1.001137).  Saving model ...
Validation loss decreased (1.001137 --> 0.999039).  Saving model ...
Validation loss decreased (0.999039 --> 0.996470).  Saving model ...
Validation loss decreased (0.996470 --> 0.994172).  Saving model ...
Validation loss decreased (0.994172 --> 0.991438).  Saving model ...
Validation loss decreased (0.991438 --> 0.988286).  Saving model ...
Validation loss decreased (0.988286 --> 0.986071).  Saving model ...
EarlyStopping counter: 1 out of 3.0
Validation loss decreased (0.986071 --> 0.984078).  Saving model ...
Validation loss decreased (0.984078 --> 0.980231).  Saving model ...
Validation loss decreased (0.980231 --> 0.976856).  Saving model ...
Validation loss decreased (0.976856 --> 0.975382).  Saving model ...
Validation loss decreased (0.975382 --> 0.974829).  Saving model ...
EarlyStopping counter: 1 out of 3.0
Validation loss decreased (0.974829 --> 0.974253).  Saving model ...
Validation loss decreased (0.974253 --> 0.971603).  Saving model ...
Validation loss decreased (0.971603 --> 0.968873).  Saving model ...
Validation loss decreased (0.968873 --> 0.968391).  Saving model ...
Validation loss decreased (0.968391 --> 0.967816).  Saving model ...
Validation loss decreased (0.967816 --> 0.965343).  Saving model ...
EarlyStopping counter: 1 out of 3.0
Validation loss decreased (0.965343 --> 0.963348).  Saving model ...
Validation loss decreased (0.963348 --> 0.962341).  Saving model ...
Validation loss decreased (0.962341 --> 0.961637).  Saving model ...
EarlyStopping counter: 1 out of 3.0
Validation loss decreased (0.961637 --> 0.960073).  Saving model ...
Validation loss decreased (0.960073 --> 0.958524).  Saving model ...
EarlyStopping counter: 1 out of 3.0
Validation loss decreased (0.958524 --> 0.957293).  Saving model ...
Validation loss decreased (0.957293 --> 0.955951).  Saving model ...
Validation loss decreased (0.955951 --> 0.955178).  Saving model ...
Validation loss decreased (0.955178 --> 0.954479).  Saving model ...
Validation loss decreased (0.954479 --> 0.953737).  Saving model ...
Validation loss decreased (0.953737 --> 0.953632).  Saving model ...
EarlyStopping counter: 1 out of 3.0
Validation loss decreased (0.953632 --> 0.953183).  Saving model ...
Validation loss decreased (0.953183 --> 0.951104).  Saving model ...
Validation loss decreased (0.951104 --> 0.950691).  Saving model ...
Validation loss decreased (0.950691 --> 0.949357).  Saving model ...
EarlyStopping counter: 1 out of 3.0
EarlyStopping counter: 2 out of 3.0
EarlyStopping counter: 3 out of 3.0
/localscratch/yinan.29785238.0/env/lib/python3.7/site-packages/torch/nn/functional.py:1794: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.
  warnings.warn("nn.functional.tanh is deprecated. Use torch.tanh instead.")
wandb: Waiting for W&B process to finish, PID 200354... (success).
wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: \ 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: | 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: / 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: \ 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: | 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: / 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: \ 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: | 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: / 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb:                                                                                
wandb: Run history:
wandb:     e_F1 ▁▂▃▃▄▅▅▅▆▆▆▆▆▆▇▇▇▇▇▇███▇▇▇▇▇▇███████████
wandb:   e_loss ██▇▇▇▇▇▆▆▆▆▅▅▄▄▄▃▃▃▃▂▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁
wandb:     t_F1 ▁▁▂▂▂▂▃▃▃▃▄▄▅▅▅▅▆▆▆▆▆▆▇▇▇▇▇▇▇▇▇█▇████▇██
wandb:   t_loss ███▇▇▇▇▇▇▆▆▆▆▅▅▅▅▄▄▄▄▃▃▃▃▃▃▃▂▂▂▂▂▂▁▂▁▁▁▁
wandb: 
wandb: Run summary:
wandb:     e_F1 60.30895
wandb:   e_loss 0.95084
wandb:     t_F1 70.39877
wandb:   t_loss 0.81787
wandb: 
wandb: Synced 4 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Synced effortless-elevator-2: https://wandb.ai/yinanazhou/xl_512_bs_8_lr_1e06_es_3_lc_True_nr_False_sr_True_stem_False_lemma_False_repeat_2_fold_1/runs/2ecc6dtw
wandb: Find logs at: ./wandb/run-20220331_083728-2ecc6dtw/logs/debug.log
wandb: 

wandb: wandb version 0.12.11 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
2022-03-31 09:50:09.315943: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1
wandb: Tracking run with wandb version 0.12.5
wandb: Syncing run divine-moon-2
wandb: ⭐️ View project at https://wandb.ai/yinanazhou/xl_512_bs_8_lr_1e06_es_3_lc_True_nr_False_sr_True_stem_False_lemma_False_repeat_2_fold_2
wandb: 🚀 View run at https://wandb.ai/yinanazhou/xl_512_bs_8_lr_1e06_es_3_lc_True_nr_False_sr_True_stem_False_lemma_False_repeat_2_fold_2/runs/3jpgd4us
wandb: Run data is saved locally in /project/6002780/yinan/Thesis_MER_Lyrics/lyric-emotion/wandb/run-20220331_095006-3jpgd4us
wandb: Run `wandb offline` to turn off syncing.

Validation loss decreased (inf --> 1.420975).  Saving model ...
Validation loss decreased (1.420975 --> 1.413461).  Saving model ...
Validation loss decreased (1.413461 --> 1.406523).  Saving model ...
Validation loss decreased (1.406523 --> 1.400538).  Saving model ...
Validation loss decreased (1.400538 --> 1.395617).  Saving model ...
Validation loss decreased (1.395617 --> 1.391312).  Saving model ...
Validation loss decreased (1.391312 --> 1.387050).  Saving model ...
Validation loss decreased (1.387050 --> 1.383261).  Saving model ...
Validation loss decreased (1.383261 --> 1.379126).  Saving model ...
Validation loss decreased (1.379126 --> 1.375360).  Saving model ...
Validation loss decreased (1.375360 --> 1.371594).  Saving model ...
Validation loss decreased (1.371594 --> 1.367622).  Saving model ...
Validation loss decreased (1.367622 --> 1.364258).  Saving model ...
Validation loss decreased (1.364258 --> 1.360359).  Saving model ...
Validation loss decreased (1.360359 --> 1.356465).  Saving model ...
Validation loss decreased (1.356465 --> 1.352412).  Saving model ...
Validation loss decreased (1.352412 --> 1.348642).  Saving model ...
Validation loss decreased (1.348642 --> 1.344465).  Saving model ...
Validation loss decreased (1.344465 --> 1.340148).  Saving model ...
Validation loss decreased (1.340148 --> 1.335965).  Saving model ...
Validation loss decreased (1.335965 --> 1.331759).  Saving model ...
Validation loss decreased (1.331759 --> 1.327197).  Saving model ...
Validation loss decreased (1.327197 --> 1.321581).  Saving model ...
Validation loss decreased (1.321581 --> 1.316540).  Saving model ...
Validation loss decreased (1.316540 --> 1.311232).  Saving model ...
Validation loss decreased (1.311232 --> 1.305580).  Saving model ...
Validation loss decreased (1.305580 --> 1.300064).  Saving model ...
Validation loss decreased (1.300064 --> 1.293349).  Saving model ...
Validation loss decreased (1.293349 --> 1.286854).  Saving model ...
Validation loss decreased (1.286854 --> 1.280332).  Saving model ...
Validation loss decreased (1.280332 --> 1.272980).  Saving model ...
Validation loss decreased (1.272980 --> 1.264162).  Saving model ...
Validation loss decreased (1.264162 --> 1.256888).  Saving model ...
Validation loss decreased (1.256888 --> 1.249496).  Saving model ...
Validation loss decreased (1.249496 --> 1.239929).  Saving model ...
Validation loss decreased (1.239929 --> 1.231823).  Saving model ...
Validation loss decreased (1.231823 --> 1.224223).  Saving model ...
Validation loss decreased (1.224223 --> 1.216305).  Saving model ...
Validation loss decreased (1.216305 --> 1.209681).  Saving model ...
Validation loss decreased (1.209681 --> 1.201929).  Saving model ...
Validation loss decreased (1.201929 --> 1.194814).  Saving model ...
Validation loss decreased (1.194814 --> 1.187621).  Saving model ...
Validation loss decreased (1.187621 --> 1.181393).  Saving model ...
Validation loss decreased (1.181393 --> 1.172576).  Saving model ...
Validation loss decreased (1.172576 --> 1.166028).  Saving model ...
Validation loss decreased (1.166028 --> 1.160140).  Saving model ...
Validation loss decreased (1.160140 --> 1.153475).  Saving model ...
Validation loss decreased (1.153475 --> 1.146639).  Saving model ...
Validation loss decreased (1.146639 --> 1.139425).  Saving model ...
Validation loss decreased (1.139425 --> 1.131942).  Saving model ...
Validation loss decreased (1.131942 --> 1.125659).  Saving model ...
Validation loss decreased (1.125659 --> 1.118938).  Saving model ...
Validation loss decreased (1.118938 --> 1.112195).  Saving model ...
Validation loss decreased (1.112195 --> 1.106344).  Saving model ...
Validation loss decreased (1.106344 --> 1.099897).  Saving model ...
Validation loss decreased (1.099897 --> 1.094974).  Saving model ...
Validation loss decreased (1.094974 --> 1.092014).  Saving model ...
Validation loss decreased (1.092014 --> 1.087964).  Saving model ...
Validation loss decreased (1.087964 --> 1.084134).  Saving model ...
Validation loss decreased (1.084134 --> 1.078436).  Saving model ...
Validation loss decreased (1.078436 --> 1.072835).  Saving model ...
Validation loss decreased (1.072835 --> 1.067232).  Saving model ...
Validation loss decreased (1.067232 --> 1.064355).  Saving model ...
Validation loss decreased (1.064355 --> 1.060477).  Saving model ...
Validation loss decreased (1.060477 --> 1.057390).  Saving model ...
Validation loss decreased (1.057390 --> 1.053272).  Saving model ...
Validation loss decreased (1.053272 --> 1.048731).  Saving model ...
Validation loss decreased (1.048731 --> 1.046336).  Saving model ...
Validation loss decreased (1.046336 --> 1.040986).  Saving model ...
Validation loss decreased (1.040986 --> 1.035307).  Saving model ...
Validation loss decreased (1.035307 --> 1.032615).  Saving model ...
Validation loss decreased (1.032615 --> 1.029228).  Saving model ...
Validation loss decreased (1.029228 --> 1.025606).  Saving model ...
Validation loss decreased (1.025606 --> 1.021318).  Saving model ...
Validation loss decreased (1.021318 --> 1.015988).  Saving model ...
Validation loss decreased (1.015988 --> 1.012887).  Saving model ...
Validation loss decreased (1.012887 --> 1.011006).  Saving model ...
Validation loss decreased (1.011006 --> 1.008112).  Saving model ...
Validation loss decreased (1.008112 --> 1.005396).  Saving model ...
Validation loss decreased (1.005396 --> 1.001294).  Saving model ...
Validation loss decreased (1.001294 --> 0.999729).  Saving model ...
Validation loss decreased (0.999729 --> 0.999307).  Saving model ...
Validation loss decreased (0.999307 --> 0.996693).  Saving model ...
Validation loss decreased (0.996693 --> 0.993638).  Saving model ...
Validation loss decreased (0.993638 --> 0.991172).  Saving model ...
Validation loss decreased (0.991172 --> 0.988127).  Saving model ...
Validation loss decreased (0.988127 --> 0.985033).  Saving model ...
Validation loss decreased (0.985033 --> 0.982391).  Saving model ...
Validation loss decreased (0.982391 --> 0.980852).  Saving model ...
Validation loss decreased (0.980852 --> 0.979803).  Saving model ...
Validation loss decreased (0.979803 --> 0.978870).  Saving model ...
Validation loss decreased (0.978870 --> 0.976694).  Saving model ...
Validation loss decreased (0.976694 --> 0.973796).  Saving model ...
Validation loss decreased (0.973796 --> 0.970237).  Saving model ...
Validation loss decreased (0.970237 --> 0.967690).  Saving model ...
Validation loss decreased (0.967690 --> 0.965863).  Saving model ...
Validation loss decreased (0.965863 --> 0.965413).  Saving model ...
Validation loss decreased (0.965413 --> 0.963849).  Saving model ...
Validation loss decreased (0.963849 --> 0.961286).  Saving model ...
Validation loss decreased (0.961286 --> 0.959314).  Saving model ...
Validation loss decreased (0.959314 --> 0.957853).  Saving model ...
Validation loss decreased (0.957853 --> 0.956379).  Saving model ...
Validation loss decreased (0.956379 --> 0.955565).  Saving model ...
Validation loss decreased (0.955565 --> 0.954581).  Saving model ...
EarlyStopping counter: 1 out of 3.0
Validation loss decreased (0.954581 --> 0.953062).  Saving model ...
Validation loss decreased (0.953062 --> 0.949234).  Saving model ...
Validation loss decreased (0.949234 --> 0.948488).  Saving model ...
Validation loss decreased (0.948488 --> 0.948076).  Saving model ...
Validation loss decreased (0.948076 --> 0.947668).  Saving model ...
Validation loss decreased (0.947668 --> 0.946551).  Saving model ...
Validation loss decreased (0.946551 --> 0.944189).  Saving model ...
Validation loss decreased (0.944189 --> 0.941287).  Saving model ...
Validation loss decreased (0.941287 --> 0.940564).  Saving model ...
Validation loss decreased (0.940564 --> 0.939646).  Saving model ...
Validation loss decreased (0.939646 --> 0.936804).  Saving model ...
Validation loss decreased (0.936804 --> 0.935235).  Saving model ...
EarlyStopping counter: 1 out of 3.0
Validation loss decreased (0.935235 --> 0.934978).  Saving model ...
EarlyStopping counter: 1 out of 3.0
EarlyStopping counter: 2 out of 3.0
EarlyStopping counter: 3 out of 3.0
/localscratch/yinan.29785238.0/env/lib/python3.7/site-packages/torch/nn/functional.py:1794: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.
  warnings.warn("nn.functional.tanh is deprecated. Use torch.tanh instead.")
wandb: Waiting for W&B process to finish, PID 204247... (success).
wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: \ 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: | 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: / 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: \ 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: | 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: / 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: \ 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: | 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: / 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb:                                                                                
wandb: Run history:
wandb:     e_F1 ▁▁▂▂▂▃▄▄▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇▇▇▇▇▇▇▇██████████
wandb:   e_loss ███▇▇▇▇▇▆▆▆▅▅▅▄▄▄▄▃▃▃▃▃▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁
wandb:     t_F1 ▁▁▂▂▂▃▃▃▃▄▄▅▅▆▆▅▆▆▆▆▆▆▇▆▇▇▇▇█▇▇▇█▇█▇████
wandb:   t_loss ███▇█▇▇▇▇▇▆▆▆▅▅▅▅▅▄▄▄▄▃▃▃▃▃▃▂▂▂▂▂▂▂▂▁▁▁▁
wandb: 
wandb: Run summary:
wandb:     e_F1 62.10257
wandb:   e_loss 0.93558
wandb:     t_F1 69.79448
wandb:   t_loss 0.7787
wandb: 
wandb: Synced 4 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Synced divine-moon-2: https://wandb.ai/yinanazhou/xl_512_bs_8_lr_1e06_es_3_lc_True_nr_False_sr_True_stem_False_lemma_False_repeat_2_fold_2/runs/3jpgd4us
wandb: Find logs at: ./wandb/run-20220331_095006-3jpgd4us/logs/debug.log
wandb: 

wandb: wandb version 0.12.11 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
2022-03-31 11:08:04.567830: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1
wandb: Tracking run with wandb version 0.12.5
wandb: Syncing run effortless-morning-2
wandb: ⭐️ View project at https://wandb.ai/yinanazhou/xl_512_bs_8_lr_1e06_es_3_lc_True_nr_False_sr_True_stem_False_lemma_False_repeat_3_fold_1
wandb: 🚀 View run at https://wandb.ai/yinanazhou/xl_512_bs_8_lr_1e06_es_3_lc_True_nr_False_sr_True_stem_False_lemma_False_repeat_3_fold_1/runs/1s19vbtb
wandb: Run data is saved locally in /project/6002780/yinan/Thesis_MER_Lyrics/lyric-emotion/wandb/run-20220331_110802-1s19vbtb
wandb: Run `wandb offline` to turn off syncing.

Validation loss decreased (inf --> 1.789233).  Saving model ...
Validation loss decreased (1.789233 --> 1.645780).  Saving model ...
Validation loss decreased (1.645780 --> 1.533021).  Saving model ...
Validation loss decreased (1.533021 --> 1.456417).  Saving model ...
Validation loss decreased (1.456417 --> 1.407980).  Saving model ...
Validation loss decreased (1.407980 --> 1.378213).  Saving model ...
Validation loss decreased (1.378213 --> 1.360039).  Saving model ...
Validation loss decreased (1.360039 --> 1.348162).  Saving model ...
Validation loss decreased (1.348162 --> 1.340006).  Saving model ...
Validation loss decreased (1.340006 --> 1.333110).  Saving model ...
Validation loss decreased (1.333110 --> 1.326646).  Saving model ...
Validation loss decreased (1.326646 --> 1.320176).  Saving model ...
Validation loss decreased (1.320176 --> 1.314602).  Saving model ...
Validation loss decreased (1.314602 --> 1.308156).  Saving model ...
Validation loss decreased (1.308156 --> 1.302494).  Saving model ...
Validation loss decreased (1.302494 --> 1.296282).  Saving model ...
Validation loss decreased (1.296282 --> 1.290022).  Saving model ...
Validation loss decreased (1.290022 --> 1.284789).  Saving model ...
Validation loss decreased (1.284789 --> 1.278889).  Saving model ...
Validation loss decreased (1.278889 --> 1.271788).  Saving model ...
Validation loss decreased (1.271788 --> 1.265099).  Saving model ...
Validation loss decreased (1.265099 --> 1.259171).  Saving model ...
Validation loss decreased (1.259171 --> 1.253045).  Saving model ...
Validation loss decreased (1.253045 --> 1.246715).  Saving model ...
Validation loss decreased (1.246715 --> 1.241383).  Saving model ...
Validation loss decreased (1.241383 --> 1.235171).  Saving model ...
Validation loss decreased (1.235171 --> 1.229347).  Saving model ...
Validation loss decreased (1.229347 --> 1.223521).  Saving model ...
Validation loss decreased (1.223521 --> 1.217555).  Saving model ...
Validation loss decreased (1.217555 --> 1.211359).  Saving model ...
Validation loss decreased (1.211359 --> 1.206004).  Saving model ...
Validation loss decreased (1.206004 --> 1.199556).  Saving model ...
Validation loss decreased (1.199556 --> 1.193568).  Saving model ...
Validation loss decreased (1.193568 --> 1.187887).  Saving model ...
Validation loss decreased (1.187887 --> 1.181950).  Saving model ...
Validation loss decreased (1.181950 --> 1.176566).  Saving model ...
Validation loss decreased (1.176566 --> 1.171768).  Saving model ...
Validation loss decreased (1.171768 --> 1.163768).  Saving model ...
Validation loss decreased (1.163768 --> 1.158514).  Saving model ...
Validation loss decreased (1.158514 --> 1.153924).  Saving model ...
Validation loss decreased (1.153924 --> 1.148291).  Saving model ...
Validation loss decreased (1.148291 --> 1.143880).  Saving model ...
Validation loss decreased (1.143880 --> 1.138320).  Saving model ...
Validation loss decreased (1.138320 --> 1.134837).  Saving model ...
Validation loss decreased (1.134837 --> 1.129305).  Saving model ...
Validation loss decreased (1.129305 --> 1.124775).  Saving model ...
Validation loss decreased (1.124775 --> 1.119962).  Saving model ...
Validation loss decreased (1.119962 --> 1.115782).  Saving model ...
Validation loss decreased (1.115782 --> 1.110305).  Saving model ...
Validation loss decreased (1.110305 --> 1.105602).  Saving model ...
Validation loss decreased (1.105602 --> 1.101829).  Saving model ...
Validation loss decreased (1.101829 --> 1.096054).  Saving model ...
Validation loss decreased (1.096054 --> 1.091060).  Saving model ...
Validation loss decreased (1.091060 --> 1.087287).  Saving model ...
Validation loss decreased (1.087287 --> 1.084839).  Saving model ...
Validation loss decreased (1.084839 --> 1.079409).  Saving model ...
Validation loss decreased (1.079409 --> 1.075806).  Saving model ...
Validation loss decreased (1.075806 --> 1.072126).  Saving model ...
Validation loss decreased (1.072126 --> 1.068657).  Saving model ...
Validation loss decreased (1.068657 --> 1.063083).  Saving model ...
Validation loss decreased (1.063083 --> 1.058314).  Saving model ...
Validation loss decreased (1.058314 --> 1.054577).  Saving model ...
Validation loss decreased (1.054577 --> 1.050851).  Saving model ...
Validation loss decreased (1.050851 --> 1.048613).  Saving model ...
Validation loss decreased (1.048613 --> 1.044248).  Saving model ...
Validation loss decreased (1.044248 --> 1.041047).  Saving model ...
Validation loss decreased (1.041047 --> 1.037490).  Saving model ...
Validation loss decreased (1.037490 --> 1.033115).  Saving model ...
Validation loss decreased (1.033115 --> 1.029866).  Saving model ...
Validation loss decreased (1.029866 --> 1.027999).  Saving model ...
Validation loss decreased (1.027999 --> 1.024553).  Saving model ...
Validation loss decreased (1.024553 --> 1.023056).  Saving model ...
Validation loss decreased (1.023056 --> 1.019963).  Saving model ...
Validation loss decreased (1.019963 --> 1.016676).  Saving model ...
Validation loss decreased (1.016676 --> 1.014698).  Saving model ...
Validation loss decreased (1.014698 --> 1.011481).  Saving model ...
Validation loss decreased (1.011481 --> 1.009629).  Saving model ...
Validation loss decreased (1.009629 --> 1.006980).  Saving model ...
Validation loss decreased (1.006980 --> 1.005510).  Saving model ...
Validation loss decreased (1.005510 --> 1.002692).  Saving model ...
Validation loss decreased (1.002692 --> 1.001005).  Saving model ...
Validation loss decreased (1.001005 --> 0.999397).  Saving model ...
Validation loss decreased (0.999397 --> 0.998271).  Saving model ...
Validation loss decreased (0.998271 --> 0.995597).  Saving model ...
Validation loss decreased (0.995597 --> 0.993220).  Saving model ...
Validation loss decreased (0.993220 --> 0.991668).  Saving model ...
Validation loss decreased (0.991668 --> 0.989380).  Saving model ...
Validation loss decreased (0.989380 --> 0.987677).  Saving model ...
Validation loss decreased (0.987677 --> 0.986062).  Saving model ...
Validation loss decreased (0.986062 --> 0.983878).  Saving model ...
Validation loss decreased (0.983878 --> 0.982415).  Saving model ...
Validation loss decreased (0.982415 --> 0.980517).  Saving model ...
Validation loss decreased (0.980517 --> 0.979399).  Saving model ...
Validation loss decreased (0.979399 --> 0.979368).  Saving model ...
Validation loss decreased (0.979368 --> 0.977548).  Saving model ...
Validation loss decreased (0.977548 --> 0.976023).  Saving model ...
Validation loss decreased (0.976023 --> 0.973788).  Saving model ...
Validation loss decreased (0.973788 --> 0.973512).  Saving model ...
Validation loss decreased (0.973512 --> 0.972838).  Saving model ...
Validation loss decreased (0.972838 --> 0.972647).  Saving model ...
Validation loss decreased (0.972647 --> 0.970308).  Saving model ...
Validation loss decreased (0.970308 --> 0.968669).  Saving model ...
Validation loss decreased (0.968669 --> 0.967641).  Saving model ...
Validation loss decreased (0.967641 --> 0.967151).  Saving model ...
Validation loss decreased (0.967151 --> 0.966297).  Saving model ...
Validation loss decreased (0.966297 --> 0.965040).  Saving model ...
Validation loss decreased (0.965040 --> 0.963486).  Saving model ...
Validation loss decreased (0.963486 --> 0.962110).  Saving model ...
EarlyStopping counter: 1 out of 3.0
Validation loss decreased (0.962110 --> 0.961129).  Saving model ...
Validation loss decreased (0.961129 --> 0.960531).  Saving model ...
EarlyStopping counter: 1 out of 3.0
Validation loss decreased (0.960531 --> 0.959728).  Saving model ...
Validation loss decreased (0.959728 --> 0.958988).  Saving model ...
Validation loss decreased (0.958988 --> 0.958269).  Saving model ...
EarlyStopping counter: 1 out of 3.0
Validation loss decreased (0.958269 --> 0.958251).  Saving model ...
Validation loss decreased (0.958251 --> 0.955859).  Saving model ...
EarlyStopping counter: 1 out of 3.0
EarlyStopping counter: 2 out of 3.0
EarlyStopping counter: 3 out of 3.0
/localscratch/yinan.29785238.0/env/lib/python3.7/site-packages/torch/nn/functional.py:1794: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.
  warnings.warn("nn.functional.tanh is deprecated. Use torch.tanh instead.")
wandb: Waiting for W&B process to finish, PID 208450... (success).
wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: \ 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: | 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: / 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: \ 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: | 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: / 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: \ 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: | 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: / 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: \ 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: | 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb:                                                                                
wandb: Run history:
wandb:     e_F1 ▁▁▄▄▅▅▅▆▆▆▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇██████████
wandb:   e_loss █▅▄▄▄▄▄▄▃▃▃▃▃▃▃▂▂▂▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:     t_F1 ▁▁▂▃▃▄▄▄▄▄▅▅▅▅▆▆▆▆▆▆▆▇▇▇▇▇▇▇▇███████████
wandb:   t_loss █▆▅▅▅▅▅▅▄▄▄▄▄▄▄▃▃▃▃▃▃▃▂▂▂▂▂▂▂▂▂▁▁▂▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:     e_F1 61.19003
wandb:   e_loss 0.9562
wandb:     t_F1 69.01269
wandb:   t_loss 0.79486
wandb: 
wandb: Synced 4 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Synced effortless-morning-2: https://wandb.ai/yinanazhou/xl_512_bs_8_lr_1e06_es_3_lc_True_nr_False_sr_True_stem_False_lemma_False_repeat_3_fold_1/runs/1s19vbtb
wandb: Find logs at: ./wandb/run-20220331_110802-1s19vbtb/logs/debug.log
wandb: 

wandb: wandb version 0.12.11 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
2022-03-31 12:28:12.164572: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1
wandb: Tracking run with wandb version 0.12.5
wandb: Syncing run jumping-river-2
wandb: ⭐️ View project at https://wandb.ai/yinanazhou/xl_512_bs_8_lr_1e06_es_3_lc_True_nr_False_sr_True_stem_False_lemma_False_repeat_3_fold_2
wandb: 🚀 View run at https://wandb.ai/yinanazhou/xl_512_bs_8_lr_1e06_es_3_lc_True_nr_False_sr_True_stem_False_lemma_False_repeat_3_fold_2/runs/1cmfokmy
wandb: Run data is saved locally in /project/6002780/yinan/Thesis_MER_Lyrics/lyric-emotion/wandb/run-20220331_122809-1cmfokmy
wandb: Run `wandb offline` to turn off syncing.

Validation loss decreased (inf --> 1.421307).  Saving model ...
Validation loss decreased (1.421307 --> 1.409424).  Saving model ...
Validation loss decreased (1.409424 --> 1.400678).  Saving model ...
Validation loss decreased (1.400678 --> 1.394263).  Saving model ...
Validation loss decreased (1.394263 --> 1.388368).  Saving model ...
Validation loss decreased (1.388368 --> 1.383325).  Saving model ...
Validation loss decreased (1.383325 --> 1.378916).  Saving model ...
Validation loss decreased (1.378916 --> 1.374636).  Saving model ...
Validation loss decreased (1.374636 --> 1.370420).  Saving model ...
Validation loss decreased (1.370420 --> 1.365886).  Saving model ...
Validation loss decreased (1.365886 --> 1.361658).  Saving model ...
Validation loss decreased (1.361658 --> 1.357300).  Saving model ...
Validation loss decreased (1.357300 --> 1.352976).  Saving model ...
Validation loss decreased (1.352976 --> 1.348696).  Saving model ...
Validation loss decreased (1.348696 --> 1.344375).  Saving model ...
Validation loss decreased (1.344375 --> 1.339654).  Saving model ...
Validation loss decreased (1.339654 --> 1.334891).  Saving model ...
Validation loss decreased (1.334891 --> 1.329382).  Saving model ...
Validation loss decreased (1.329382 --> 1.324126).  Saving model ...
Validation loss decreased (1.324126 --> 1.319166).  Saving model ...
Validation loss decreased (1.319166 --> 1.312947).  Saving model ...
Validation loss decreased (1.312947 --> 1.306880).  Saving model ...
Validation loss decreased (1.306880 --> 1.300836).  Saving model ...
Validation loss decreased (1.300836 --> 1.294057).  Saving model ...
Validation loss decreased (1.294057 --> 1.286488).  Saving model ...
Validation loss decreased (1.286488 --> 1.278992).  Saving model ...
Validation loss decreased (1.278992 --> 1.270453).  Saving model ...
Validation loss decreased (1.270453 --> 1.263051).  Saving model ...
Validation loss decreased (1.263051 --> 1.254692).  Saving model ...
Validation loss decreased (1.254692 --> 1.246372).  Saving model ...
Validation loss decreased (1.246372 --> 1.237639).  Saving model ...
Validation loss decreased (1.237639 --> 1.230145).  Saving model ...
Validation loss decreased (1.230145 --> 1.221407).  Saving model ...
Validation loss decreased (1.221407 --> 1.212982).  Saving model ...
Validation loss decreased (1.212982 --> 1.204915).  Saving model ...
Validation loss decreased (1.204915 --> 1.197656).  Saving model ...
Validation loss decreased (1.197656 --> 1.189233).  Saving model ...
Validation loss decreased (1.189233 --> 1.181710).  Saving model ...
Validation loss decreased (1.181710 --> 1.174477).  Saving model ...
Validation loss decreased (1.174477 --> 1.167511).  Saving model ...
Validation loss decreased (1.167511 --> 1.160808).  Saving model ...
Validation loss decreased (1.160808 --> 1.155073).  Saving model ...
Validation loss decreased (1.155073 --> 1.148315).  Saving model ...
Validation loss decreased (1.148315 --> 1.142448).  Saving model ...
Validation loss decreased (1.142448 --> 1.135956).  Saving model ...
Validation loss decreased (1.135956 --> 1.130977).  Saving model ...
Validation loss decreased (1.130977 --> 1.125940).  Saving model ...
Validation loss decreased (1.125940 --> 1.121154).  Saving model ...
Validation loss decreased (1.121154 --> 1.115889).  Saving model ...
Validation loss decreased (1.115889 --> 1.110545).  Saving model ...
Validation loss decreased (1.110545 --> 1.105642).  Saving model ...
Validation loss decreased (1.105642 --> 1.100704).  Saving model ...
Validation loss decreased (1.100704 --> 1.096297).  Saving model ...
Validation loss decreased (1.096297 --> 1.093146).  Saving model ...
Validation loss decreased (1.093146 --> 1.090949).  Saving model ...
Validation loss decreased (1.090949 --> 1.087040).  Saving model ...
Validation loss decreased (1.087040 --> 1.082200).  Saving model ...
Validation loss decreased (1.082200 --> 1.076905).  Saving model ...
Validation loss decreased (1.076905 --> 1.072081).  Saving model ...
Validation loss decreased (1.072081 --> 1.067688).  Saving model ...
Validation loss decreased (1.067688 --> 1.063232).  Saving model ...
Validation loss decreased (1.063232 --> 1.058505).  Saving model ...
Validation loss decreased (1.058505 --> 1.054694).  Saving model ...
Validation loss decreased (1.054694 --> 1.050516).  Saving model ...
Validation loss decreased (1.050516 --> 1.046179).  Saving model ...
Validation loss decreased (1.046179 --> 1.043280).  Saving model ...
Validation loss decreased (1.043280 --> 1.040836).  Saving model ...
Validation loss decreased (1.040836 --> 1.037658).  Saving model ...
Validation loss decreased (1.037658 --> 1.035179).  Saving model ...
Validation loss decreased (1.035179 --> 1.030042).  Saving model ...
Validation loss decreased (1.030042 --> 1.027037).  Saving model ...
Validation loss decreased (1.027037 --> 1.024185).  Saving model ...
Validation loss decreased (1.024185 --> 1.020088).  Saving model ...
Validation loss decreased (1.020088 --> 1.017880).  Saving model ...
Validation loss decreased (1.017880 --> 1.013044).  Saving model ...
Validation loss decreased (1.013044 --> 1.011022).  Saving model ...
Validation loss decreased (1.011022 --> 1.008995).  Saving model ...
Validation loss decreased (1.008995 --> 1.008519).  Saving model ...
Validation loss decreased (1.008519 --> 1.004023).  Saving model ...
Validation loss decreased (1.004023 --> 0.999021).  Saving model ...
Validation loss decreased (0.999021 --> 0.997272).  Saving model ...
Validation loss decreased (0.997272 --> 0.994900).  Saving model ...
Validation loss decreased (0.994900 --> 0.993272).  Saving model ...
Validation loss decreased (0.993272 --> 0.992649).  Saving model ...
Validation loss decreased (0.992649 --> 0.991732).  Saving model ...
Validation loss decreased (0.991732 --> 0.987388).  Saving model ...
Validation loss decreased (0.987388 --> 0.981646).  Saving model ...
Validation loss decreased (0.981646 --> 0.978772).  Saving model ...
Validation loss decreased (0.978772 --> 0.978131).  Saving model ...
Validation loss decreased (0.978131 --> 0.976691).  Saving model ...
Validation loss decreased (0.976691 --> 0.975823).  Saving model ...
Validation loss decreased (0.975823 --> 0.974212).  Saving model ...
Validation loss decreased (0.974212 --> 0.970001).  Saving model ...
Validation loss decreased (0.970001 --> 0.966355).  Saving model ...
Validation loss decreased (0.966355 --> 0.965524).  Saving model ...
EarlyStopping counter: 1 out of 3.0
EarlyStopping counter: 2 out of 3.0
Validation loss decreased (0.965524 --> 0.964274).  Saving model ...
Validation loss decreased (0.964274 --> 0.960750).  Saving model ...
Validation loss decreased (0.960750 --> 0.957964).  Saving model ...
Validation loss decreased (0.957964 --> 0.956045).  Saving model ...
Validation loss decreased (0.956045 --> 0.954539).  Saving model ...
Validation loss decreased (0.954539 --> 0.954103).  Saving model ...
Validation loss decreased (0.954103 --> 0.952924).  Saving model ...
EarlyStopping counter: 1 out of 3.0
Validation loss decreased (0.952924 --> 0.952638).  Saving model ...
Validation loss decreased (0.952638 --> 0.949707).  Saving model ...
Validation loss decreased (0.949707 --> 0.947600).  Saving model ...
Validation loss decreased (0.947600 --> 0.945208).  Saving model ...
Validation loss decreased (0.945208 --> 0.943288).  Saving model ...
EarlyStopping counter: 1 out of 3.0
EarlyStopping counter: 2 out of 3.0
EarlyStopping counter: 3 out of 3.0
/localscratch/yinan.29785238.0/env/lib/python3.7/site-packages/torch/nn/functional.py:1794: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.
  warnings.warn("nn.functional.tanh is deprecated. Use torch.tanh instead.")
wandb: Waiting for W&B process to finish, PID 212745... (success).
wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: \ 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: | 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: / 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: \ 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: | 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: / 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: \ 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: | 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: / 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb:                                                                                
wandb: Run history:
wandb:     e_F1 ▁▁▃▃▄▅▅▅▅▆▆▆▆▆▆▆▇▇▇▇▇▇▇▇▇▇▇▇▇▇█▇▇███████
wandb:   e_loss ██▇▇▇▇▇▆▆▆▆▅▅▄▄▄▄▄▃▃▃▃▃▂▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁
wandb:     t_F1 ▁▁▂▂▃▃▃▄▄▄▅▅▅▅▅▆▆▆▆▆▆▆▇▆▆▇▇▇▇▇▇▇▇▇█▇▇▇██
wandb:   t_loss ██▇▇▇▇▇▇▆▆▆▆▆▅▅▅▅▅▄▄▄▄▃▃▃▃▃▃▂▂▂▂▂▂▂▁▂▂▁▁
wandb: 
wandb: Run summary:
wandb:     e_F1 59.9838
wandb:   e_loss 0.94588
wandb:     t_F1 67.33324
wandb:   t_loss 0.84793
wandb: 
wandb: Synced 4 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Synced jumping-river-2: https://wandb.ai/yinanazhou/xl_512_bs_8_lr_1e06_es_3_lc_True_nr_False_sr_True_stem_False_lemma_False_repeat_3_fold_2/runs/1cmfokmy
wandb: Find logs at: ./wandb/run-20220331_122809-1cmfokmy/logs/debug.log
wandb: 

wandb: wandb version 0.12.11 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
2022-03-31 13:42:52.000297: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1
wandb: Tracking run with wandb version 0.12.5
wandb: Syncing run elated-jazz-2
wandb: ⭐️ View project at https://wandb.ai/yinanazhou/xl_512_bs_8_lr_1e06_es_3_lc_True_nr_False_sr_True_stem_False_lemma_False_repeat_4_fold_1
wandb: 🚀 View run at https://wandb.ai/yinanazhou/xl_512_bs_8_lr_1e06_es_3_lc_True_nr_False_sr_True_stem_False_lemma_False_repeat_4_fold_1/runs/31yqrci0
wandb: Run data is saved locally in /project/6002780/yinan/Thesis_MER_Lyrics/lyric-emotion/wandb/run-20220331_134249-31yqrci0
wandb: Run `wandb offline` to turn off syncing.

Validation loss decreased (inf --> 1.535695).  Saving model ...
Validation loss decreased (1.535695 --> 1.498440).  Saving model ...
Validation loss decreased (1.498440 --> 1.469999).  Saving model ...
Validation loss decreased (1.469999 --> 1.446466).  Saving model ...
Validation loss decreased (1.446466 --> 1.427781).  Saving model ...
Validation loss decreased (1.427781 --> 1.413989).  Saving model ...
Validation loss decreased (1.413989 --> 1.402653).  Saving model ...
Validation loss decreased (1.402653 --> 1.393327).  Saving model ...
Validation loss decreased (1.393327 --> 1.385004).  Saving model ...
Validation loss decreased (1.385004 --> 1.377359).  Saving model ...
Validation loss decreased (1.377359 --> 1.369949).  Saving model ...
Validation loss decreased (1.369949 --> 1.362495).  Saving model ...
Validation loss decreased (1.362495 --> 1.355954).  Saving model ...
Validation loss decreased (1.355954 --> 1.349589).  Saving model ...
Validation loss decreased (1.349589 --> 1.342904).  Saving model ...
Validation loss decreased (1.342904 --> 1.336224).  Saving model ...
Validation loss decreased (1.336224 --> 1.328806).  Saving model ...
Validation loss decreased (1.328806 --> 1.322013).  Saving model ...
Validation loss decreased (1.322013 --> 1.314401).  Saving model ...
Validation loss decreased (1.314401 --> 1.306970).  Saving model ...
Validation loss decreased (1.306970 --> 1.298320).  Saving model ...
Validation loss decreased (1.298320 --> 1.289489).  Saving model ...
Validation loss decreased (1.289489 --> 1.281496).  Saving model ...
Validation loss decreased (1.281496 --> 1.272698).  Saving model ...
Validation loss decreased (1.272698 --> 1.264559).  Saving model ...
Validation loss decreased (1.264559 --> 1.257218).  Saving model ...
Validation loss decreased (1.257218 --> 1.249732).  Saving model ...
Validation loss decreased (1.249732 --> 1.241398).  Saving model ...
Validation loss decreased (1.241398 --> 1.233410).  Saving model ...
Validation loss decreased (1.233410 --> 1.225716).  Saving model ...
Validation loss decreased (1.225716 --> 1.218130).  Saving model ...
Validation loss decreased (1.218130 --> 1.210571).  Saving model ...
Validation loss decreased (1.210571 --> 1.203385).  Saving model ...
Validation loss decreased (1.203385 --> 1.196393).  Saving model ...
Validation loss decreased (1.196393 --> 1.190099).  Saving model ...
Validation loss decreased (1.190099 --> 1.183083).  Saving model ...
Validation loss decreased (1.183083 --> 1.176724).  Saving model ...
Validation loss decreased (1.176724 --> 1.170958).  Saving model ...
Validation loss decreased (1.170958 --> 1.165260).  Saving model ...
Validation loss decreased (1.165260 --> 1.159676).  Saving model ...
Validation loss decreased (1.159676 --> 1.153854).  Saving model ...
Validation loss decreased (1.153854 --> 1.148187).  Saving model ...
Validation loss decreased (1.148187 --> 1.142307).  Saving model ...
Validation loss decreased (1.142307 --> 1.136734).  Saving model ...
Validation loss decreased (1.136734 --> 1.130976).  Saving model ...
Validation loss decreased (1.130976 --> 1.126270).  Saving model ...
Validation loss decreased (1.126270 --> 1.120747).  Saving model ...
Validation loss decreased (1.120747 --> 1.116112).  Saving model ...
Validation loss decreased (1.116112 --> 1.110934).  Saving model ...
Validation loss decreased (1.110934 --> 1.105978).  Saving model ...
Validation loss decreased (1.105978 --> 1.101342).  Saving model ...
Validation loss decreased (1.101342 --> 1.096605).  Saving model ...
Validation loss decreased (1.096605 --> 1.091742).  Saving model ...
Validation loss decreased (1.091742 --> 1.088441).  Saving model ...
Validation loss decreased (1.088441 --> 1.084531).  Saving model ...
Validation loss decreased (1.084531 --> 1.080166).  Saving model ...
Validation loss decreased (1.080166 --> 1.074560).  Saving model ...
Validation loss decreased (1.074560 --> 1.070327).  Saving model ...
Validation loss decreased (1.070327 --> 1.066956).  Saving model ...
Validation loss decreased (1.066956 --> 1.063160).  Saving model ...
Validation loss decreased (1.063160 --> 1.059238).  Saving model ...
Validation loss decreased (1.059238 --> 1.056413).  Saving model ...
Validation loss decreased (1.056413 --> 1.052614).  Saving model ...
Validation loss decreased (1.052614 --> 1.048832).  Saving model ...
Validation loss decreased (1.048832 --> 1.044055).  Saving model ...
Validation loss decreased (1.044055 --> 1.041205).  Saving model ...
Validation loss decreased (1.041205 --> 1.037348).  Saving model ...
Validation loss decreased (1.037348 --> 1.033884).  Saving model ...
Validation loss decreased (1.033884 --> 1.031119).  Saving model ...
Validation loss decreased (1.031119 --> 1.027502).  Saving model ...
Validation loss decreased (1.027502 --> 1.025102).  Saving model ...
Validation loss decreased (1.025102 --> 1.022564).  Saving model ...
Validation loss decreased (1.022564 --> 1.020789).  Saving model ...
Validation loss decreased (1.020789 --> 1.017189).  Saving model ...
Validation loss decreased (1.017189 --> 1.014481).  Saving model ...
Validation loss decreased (1.014481 --> 1.011925).  Saving model ...
Validation loss decreased (1.011925 --> 1.009576).  Saving model ...
Validation loss decreased (1.009576 --> 1.007145).  Saving model ...
Validation loss decreased (1.007145 --> 1.004439).  Saving model ...
Validation loss decreased (1.004439 --> 1.003238).  Saving model ...
Validation loss decreased (1.003238 --> 1.000908).  Saving model ...
Validation loss decreased (1.000908 --> 0.998158).  Saving model ...
Validation loss decreased (0.998158 --> 0.995866).  Saving model ...
Validation loss decreased (0.995866 --> 0.994154).  Saving model ...
Validation loss decreased (0.994154 --> 0.991679).  Saving model ...
Validation loss decreased (0.991679 --> 0.990385).  Saving model ...
Validation loss decreased (0.990385 --> 0.987609).  Saving model ...
Validation loss decreased (0.987609 --> 0.986977).  Saving model ...
Validation loss decreased (0.986977 --> 0.985612).  Saving model ...
Validation loss decreased (0.985612 --> 0.983633).  Saving model ...
Validation loss decreased (0.983633 --> 0.981634).  Saving model ...
Validation loss decreased (0.981634 --> 0.979941).  Saving model ...
Validation loss decreased (0.979941 --> 0.977854).  Saving model ...
Validation loss decreased (0.977854 --> 0.976686).  Saving model ...
Validation loss decreased (0.976686 --> 0.975645).  Saving model ...
Validation loss decreased (0.975645 --> 0.973422).  Saving model ...
Validation loss decreased (0.973422 --> 0.972627).  Saving model ...
Validation loss decreased (0.972627 --> 0.971559).  Saving model ...
Validation loss decreased (0.971559 --> 0.970521).  Saving model ...
Validation loss decreased (0.970521 --> 0.969668).  Saving model ...
Validation loss decreased (0.969668 --> 0.968032).  Saving model ...
Validation loss decreased (0.968032 --> 0.966380).  Saving model ...
Validation loss decreased (0.966380 --> 0.963641).  Saving model ...
EarlyStopping counter: 1 out of 3.0
Validation loss decreased (0.963641 --> 0.962977).  Saving model ...
Validation loss decreased (0.962977 --> 0.961067).  Saving model ...
Validation loss decreased (0.961067 --> 0.960770).  Saving model ...
Validation loss decreased (0.960770 --> 0.958985).  Saving model ...
Validation loss decreased (0.958985 --> 0.958249).  Saving model ...
EarlyStopping counter: 1 out of 3.0
EarlyStopping counter: 2 out of 3.0
Validation loss decreased (0.958249 --> 0.957686).  Saving model ...
Validation loss decreased (0.957686 --> 0.955926).  Saving model ...
EarlyStopping counter: 1 out of 3.0
Validation loss decreased (0.955926 --> 0.955261).  Saving model ...
Validation loss decreased (0.955261 --> 0.953586).  Saving model ...
Validation loss decreased (0.953586 --> 0.953468).  Saving model ...
Validation loss decreased (0.953468 --> 0.952537).  Saving model ...
Validation loss decreased (0.952537 --> 0.952196).  Saving model ...
EarlyStopping counter: 1 out of 3.0
EarlyStopping counter: 2 out of 3.0
Validation loss decreased (0.952196 --> 0.951789).  Saving model ...
Validation loss decreased (0.951789 --> 0.951584).  Saving model ...
Validation loss decreased (0.951584 --> 0.949706).  Saving model ...
EarlyStopping counter: 1 out of 3.0
EarlyStopping counter: 2 out of 3.0
EarlyStopping counter: 3 out of 3.0
/localscratch/yinan.29785238.0/env/lib/python3.7/site-packages/torch/nn/functional.py:1794: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.
  warnings.warn("nn.functional.tanh is deprecated. Use torch.tanh instead.")
wandb: Waiting for W&B process to finish, PID 216750... (success).
wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: \ 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: | 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: / 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: \ 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: | 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: / 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: \ 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: | 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: / 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb:                                                                                
wandb: Run history:
wandb:     e_F1 ▁▁▂▃▄▅▅▆▆▆▆▆▇▇▇▇▇▇▇▇████████████████████
wandb:   e_loss █▇▆▆▆▆▅▅▅▄▄▄▄▃▃▃▃▃▂▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:     t_F1 ▁▁▂▃▃▃▄▄▅▅▅▆▆▆▆▆▆▆▇▆▆▆▇▇▇▇▇▇▇▇▇█▇█▇█████
wandb:   t_loss █▇▇▇▆▆▆▆▅▅▅▅▄▄▄▄▄▄▃▃▃▃▃▃▂▂▂▂▂▂▂▂▂▂▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:     e_F1 60.22538
wandb:   e_loss 0.95142
wandb:     t_F1 71.31318
wandb:   t_loss 0.77432
wandb: 
wandb: Synced 4 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Synced elated-jazz-2: https://wandb.ai/yinanazhou/xl_512_bs_8_lr_1e06_es_3_lc_True_nr_False_sr_True_stem_False_lemma_False_repeat_4_fold_1/runs/31yqrci0
wandb: Find logs at: ./wandb/run-20220331_134249-31yqrci0/logs/debug.log
wandb: 

wandb: wandb version 0.12.11 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
2022-03-31 15:03:57.461032: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1
wandb: Tracking run with wandb version 0.12.5
wandb: Syncing run magic-salad-1
wandb: ⭐️ View project at https://wandb.ai/yinanazhou/xl_512_bs_8_lr_1e06_es_3_lc_True_nr_False_sr_True_stem_False_lemma_False_repeat_4_fold_2
wandb: 🚀 View run at https://wandb.ai/yinanazhou/xl_512_bs_8_lr_1e06_es_3_lc_True_nr_False_sr_True_stem_False_lemma_False_repeat_4_fold_2/runs/eyptfecw
wandb: Run data is saved locally in /project/6002780/yinan/Thesis_MER_Lyrics/lyric-emotion/wandb/run-20220331_150355-eyptfecw
wandb: Run `wandb offline` to turn off syncing.

Validation loss decreased (inf --> 1.421217).  Saving model ...
Validation loss decreased (1.421217 --> 1.403299).  Saving model ...
Validation loss decreased (1.403299 --> 1.389819).  Saving model ...
Validation loss decreased (1.389819 --> 1.379425).  Saving model ...
Validation loss decreased (1.379425 --> 1.370741).  Saving model ...
Validation loss decreased (1.370741 --> 1.364019).  Saving model ...
Validation loss decreased (1.364019 --> 1.358058).  Saving model ...
Validation loss decreased (1.358058 --> 1.352780).  Saving model ...
Validation loss decreased (1.352780 --> 1.348044).  Saving model ...
Validation loss decreased (1.348044 --> 1.343443).  Saving model ...
Validation loss decreased (1.343443 --> 1.339143).  Saving model ...
Validation loss decreased (1.339143 --> 1.334658).  Saving model ...
Validation loss decreased (1.334658 --> 1.330492).  Saving model ...
Validation loss decreased (1.330492 --> 1.326916).  Saving model ...
Validation loss decreased (1.326916 --> 1.322219).  Saving model ...
Validation loss decreased (1.322219 --> 1.317504).  Saving model ...
Validation loss decreased (1.317504 --> 1.312224).  Saving model ...
Validation loss decreased (1.312224 --> 1.307545).  Saving model ...
Validation loss decreased (1.307545 --> 1.302787).  Saving model ...
Validation loss decreased (1.302787 --> 1.297153).  Saving model ...
Validation loss decreased (1.297153 --> 1.291873).  Saving model ...
Validation loss decreased (1.291873 --> 1.286430).  Saving model ...
Validation loss decreased (1.286430 --> 1.280095).  Saving model ...
Validation loss decreased (1.280095 --> 1.272670).  Saving model ...
Validation loss decreased (1.272670 --> 1.264878).  Saving model ...
Validation loss decreased (1.264878 --> 1.256779).  Saving model ...
Validation loss decreased (1.256779 --> 1.249112).  Saving model ...
Validation loss decreased (1.249112 --> 1.240890).  Saving model ...
Validation loss decreased (1.240890 --> 1.232804).  Saving model ...
Validation loss decreased (1.232804 --> 1.224762).  Saving model ...
Validation loss decreased (1.224762 --> 1.215622).  Saving model ...
Validation loss decreased (1.215622 --> 1.207078).  Saving model ...
Validation loss decreased (1.207078 --> 1.196568).  Saving model ...
Validation loss decreased (1.196568 --> 1.189076).  Saving model ...
Validation loss decreased (1.189076 --> 1.180033).  Saving model ...
Validation loss decreased (1.180033 --> 1.170366).  Saving model ...
Validation loss decreased (1.170366 --> 1.162600).  Saving model ...
Validation loss decreased (1.162600 --> 1.153791).  Saving model ...
Validation loss decreased (1.153791 --> 1.144860).  Saving model ...
Validation loss decreased (1.144860 --> 1.136957).  Saving model ...
Validation loss decreased (1.136957 --> 1.130677).  Saving model ...
Validation loss decreased (1.130677 --> 1.120361).  Saving model ...
Validation loss decreased (1.120361 --> 1.114824).  Saving model ...
Validation loss decreased (1.114824 --> 1.109272).  Saving model ...
Validation loss decreased (1.109272 --> 1.101760).  Saving model ...
Validation loss decreased (1.101760 --> 1.095633).  Saving model ...
Validation loss decreased (1.095633 --> 1.088290).  Saving model ...
Validation loss decreased (1.088290 --> 1.082793).  Saving model ...
Validation loss decreased (1.082793 --> 1.076860).  Saving model ...
Validation loss decreased (1.076860 --> 1.072094).  Saving model ...
Validation loss decreased (1.072094 --> 1.067530).  Saving model ...
Validation loss decreased (1.067530 --> 1.062317).  Saving model ...
Validation loss decreased (1.062317 --> 1.057981).  Saving model ...
Validation loss decreased (1.057981 --> 1.053182).  Saving model ...
Validation loss decreased (1.053182 --> 1.049307).  Saving model ...
Validation loss decreased (1.049307 --> 1.044585).  Saving model ...
Validation loss decreased (1.044585 --> 1.040882).  Saving model ...
Validation loss decreased (1.040882 --> 1.037052).  Saving model ...
Validation loss decreased (1.037052 --> 1.031305).  Saving model ...
Validation loss decreased (1.031305 --> 1.028202).  Saving model ...
Validation loss decreased (1.028202 --> 1.025168).  Saving model ...
Validation loss decreased (1.025168 --> 1.020784).  Saving model ...
Validation loss decreased (1.020784 --> 1.017064).  Saving model ...
Validation loss decreased (1.017064 --> 1.013689).  Saving model ...
Validation loss decreased (1.013689 --> 1.010558).  Saving model ...
Validation loss decreased (1.010558 --> 1.007408).  Saving model ...
Validation loss decreased (1.007408 --> 1.004784).  Saving model ...
Validation loss decreased (1.004784 --> 1.001097).  Saving model ...
Validation loss decreased (1.001097 --> 0.995873).  Saving model ...
Validation loss decreased (0.995873 --> 0.992531).  Saving model ...
Validation loss decreased (0.992531 --> 0.989698).  Saving model ...
Validation loss decreased (0.989698 --> 0.986853).  Saving model ...
Validation loss decreased (0.986853 --> 0.984649).  Saving model ...
Validation loss decreased (0.984649 --> 0.983620).  Saving model ...
Validation loss decreased (0.983620 --> 0.981363).  Saving model ...
Validation loss decreased (0.981363 --> 0.977958).  Saving model ...
Validation loss decreased (0.977958 --> 0.976014).  Saving model ...
Validation loss decreased (0.976014 --> 0.974744).  Saving model ...
Validation loss decreased (0.974744 --> 0.972655).  Saving model ...
Validation loss decreased (0.972655 --> 0.968716).  Saving model ...
Validation loss decreased (0.968716 --> 0.965701).  Saving model ...
Validation loss decreased (0.965701 --> 0.962282).  Saving model ...
Validation loss decreased (0.962282 --> 0.961404).  Saving model ...
Validation loss decreased (0.961404 --> 0.959999).  Saving model ...
Validation loss decreased (0.959999 --> 0.957019).  Saving model ...
Validation loss decreased (0.957019 --> 0.954849).  Saving model ...
Validation loss decreased (0.954849 --> 0.953457).  Saving model ...
EarlyStopping counter: 1 out of 3.0
Validation loss decreased (0.953457 --> 0.952064).  Saving model ...
Validation loss decreased (0.952064 --> 0.950618).  Saving model ...
Validation loss decreased (0.950618 --> 0.949116).  Saving model ...
EarlyStopping counter: 1 out of 3.0
EarlyStopping counter: 2 out of 3.0
Validation loss decreased (0.949116 --> 0.947772).  Saving model ...
Validation loss decreased (0.947772 --> 0.946115).  Saving model ...
Validation loss decreased (0.946115 --> 0.942323).  Saving model ...
Validation loss decreased (0.942323 --> 0.942240).  Saving model ...
Validation loss decreased (0.942240 --> 0.941055).  Saving model ...
Validation loss decreased (0.941055 --> 0.941015).  Saving model ...
Validation loss decreased (0.941015 --> 0.940748).  Saving model ...
Validation loss decreased (0.940748 --> 0.938604).  Saving model ...
Validation loss decreased (0.938604 --> 0.935434).  Saving model ...
Validation loss decreased (0.935434 --> 0.934577).  Saving model ...
EarlyStopping counter: 1 out of 3.0
EarlyStopping counter: 2 out of 3.0
Validation loss decreased (0.934577 --> 0.932630).  Saving model ...
Validation loss decreased (0.932630 --> 0.932459).  Saving model ...
Validation loss decreased (0.932459 --> 0.932323).  Saving model ...
Validation loss decreased (0.932323 --> 0.932150).  Saving model ...
Validation loss decreased (0.932150 --> 0.930856).  Saving model ...
Validation loss decreased (0.930856 --> 0.930649).  Saving model ...
EarlyStopping counter: 1 out of 3.0
Validation loss decreased (0.930649 --> 0.930291).  Saving model ...
Validation loss decreased (0.930291 --> 0.929738).  Saving model ...
Validation loss decreased (0.929738 --> 0.927952).  Saving model ...
EarlyStopping counter: 1 out of 3.0
EarlyStopping counter: 2 out of 3.0
Validation loss decreased (0.927952 --> 0.926420).  Saving model ...
Validation loss decreased (0.926420 --> 0.925114).  Saving model ...
Validation loss decreased (0.925114 --> 0.924992).  Saving model ...
EarlyStopping counter: 1 out of 3.0
EarlyStopping counter: 2 out of 3.0
EarlyStopping counter: 3 out of 3.0
/localscratch/yinan.29785238.0/env/lib/python3.7/site-packages/torch/nn/functional.py:1794: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.
  warnings.warn("nn.functional.tanh is deprecated. Use torch.tanh instead.")
wandb: Waiting for W&B process to finish, PID 221106... (success).
wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: \ 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: | 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: / 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: \ 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: | 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: / 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: \ 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: | 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: / 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb:                                                                                
wandb: Run history:
wandb:     e_F1 ▁▃▃▄▄▅▅▅▆▆▆▆▆▆▇▇▇▇▇▇▇▇▇▇▇███████████████
wandb:   e_loss █▇▇▇▇▇▆▆▆▅▅▅▄▄▄▃▃▃▃▂▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:     t_F1 ▁▂▂▂▃▃▃▄▄▄▅▅▅▅▆▆▆▆▆▆▆▆▆▇▇▇▇▇▇▇▇▇▇▇█▇▇███
wandb:   t_loss ██▇▇▇▇▇▇▆▆▆▆▅▅▅▄▄▄▄▄▃▃▃▃▃▃▃▂▂▂▂▂▂▂▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:     e_F1 63.64219
wandb:   e_loss 0.92769
wandb:     t_F1 67.85887
wandb:   t_loss 0.81059
wandb: 
wandb: Synced 4 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Synced magic-salad-1: https://wandb.ai/yinanazhou/xl_512_bs_8_lr_1e06_es_3_lc_True_nr_False_sr_True_stem_False_lemma_False_repeat_4_fold_2/runs/eyptfecw
wandb: Find logs at: ./wandb/run-20220331_150355-eyptfecw/logs/debug.log
wandb: 

wandb: wandb version 0.12.11 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
2022-03-31 16:25:03.103387: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1
wandb: Tracking run with wandb version 0.12.5
wandb: Syncing run light-night-1
wandb: ⭐️ View project at https://wandb.ai/yinanazhou/xl_512_bs_8_lr_1e06_es_3_lc_True_nr_False_sr_True_stem_False_lemma_False_repeat_5_fold_1
wandb: 🚀 View run at https://wandb.ai/yinanazhou/xl_512_bs_8_lr_1e06_es_3_lc_True_nr_False_sr_True_stem_False_lemma_False_repeat_5_fold_1/runs/r0v01ntu
wandb: Run data is saved locally in /project/6002780/yinan/Thesis_MER_Lyrics/lyric-emotion/wandb/run-20220331_162500-r0v01ntu
wandb: Run `wandb offline` to turn off syncing.

Validation loss decreased (inf --> 1.389886).  Saving model ...
Validation loss decreased (1.389886 --> 1.381248).  Saving model ...
Validation loss decreased (1.381248 --> 1.374844).  Saving model ...
Validation loss decreased (1.374844 --> 1.368736).  Saving model ...
Validation loss decreased (1.368736 --> 1.363644).  Saving model ...
Validation loss decreased (1.363644 --> 1.359194).  Saving model ...
Validation loss decreased (1.359194 --> 1.354849).  Saving model ...
Validation loss decreased (1.354849 --> 1.350986).  Saving model ...
Validation loss decreased (1.350986 --> 1.346763).  Saving model ...
Validation loss decreased (1.346763 --> 1.342701).  Saving model ...
Validation loss decreased (1.342701 --> 1.338382).  Saving model ...
Validation loss decreased (1.338382 --> 1.334654).  Saving model ...
Validation loss decreased (1.334654 --> 1.330037).  Saving model ...
Validation loss decreased (1.330037 --> 1.325375).  Saving model ...
Validation loss decreased (1.325375 --> 1.320474).  Saving model ...
Validation loss decreased (1.320474 --> 1.315739).  Saving model ...
Validation loss decreased (1.315739 --> 1.311106).  Saving model ...
Validation loss decreased (1.311106 --> 1.306254).  Saving model ...
Validation loss decreased (1.306254 --> 1.300981).  Saving model ...
Validation loss decreased (1.300981 --> 1.294974).  Saving model ...
Validation loss decreased (1.294974 --> 1.290239).  Saving model ...
Validation loss decreased (1.290239 --> 1.284587).  Saving model ...
Validation loss decreased (1.284587 --> 1.278577).  Saving model ...
Validation loss decreased (1.278577 --> 1.272492).  Saving model ...
Validation loss decreased (1.272492 --> 1.266491).  Saving model ...
Validation loss decreased (1.266491 --> 1.260102).  Saving model ...
Validation loss decreased (1.260102 --> 1.254402).  Saving model ...
Validation loss decreased (1.254402 --> 1.248310).  Saving model ...
Validation loss decreased (1.248310 --> 1.242263).  Saving model ...
Validation loss decreased (1.242263 --> 1.236126).  Saving model ...
Validation loss decreased (1.236126 --> 1.229805).  Saving model ...
Validation loss decreased (1.229805 --> 1.223706).  Saving model ...
Validation loss decreased (1.223706 --> 1.217401).  Saving model ...
Validation loss decreased (1.217401 --> 1.211459).  Saving model ...
Validation loss decreased (1.211459 --> 1.205312).  Saving model ...
Validation loss decreased (1.205312 --> 1.198836).  Saving model ...
Validation loss decreased (1.198836 --> 1.193021).  Saving model ...
Validation loss decreased (1.193021 --> 1.186640).  Saving model ...
Validation loss decreased (1.186640 --> 1.181455).  Saving model ...
Validation loss decreased (1.181455 --> 1.176195).  Saving model ...
Validation loss decreased (1.176195 --> 1.170906).  Saving model ...
Validation loss decreased (1.170906 --> 1.164773).  Saving model ...
Validation loss decreased (1.164773 --> 1.158935).  Saving model ...
Validation loss decreased (1.158935 --> 1.153659).  Saving model ...
Validation loss decreased (1.153659 --> 1.147912).  Saving model ...
Validation loss decreased (1.147912 --> 1.141837).  Saving model ...
Validation loss decreased (1.141837 --> 1.137872).  Saving model ...
Validation loss decreased (1.137872 --> 1.132246).  Saving model ...
Validation loss decreased (1.132246 --> 1.127051).  Saving model ...
Validation loss decreased (1.127051 --> 1.121736).  Saving model ...
Validation loss decreased (1.121736 --> 1.116339).  Saving model ...
Validation loss decreased (1.116339 --> 1.112272).  Saving model ...
Validation loss decreased (1.112272 --> 1.108572).  Saving model ...
Validation loss decreased (1.108572 --> 1.103002).  Saving model ...
Validation loss decreased (1.103002 --> 1.097347).  Saving model ...
Validation loss decreased (1.097347 --> 1.093091).  Saving model ...
Validation loss decreased (1.093091 --> 1.089083).  Saving model ...
Validation loss decreased (1.089083 --> 1.084655).  Saving model ...
Validation loss decreased (1.084655 --> 1.080304).  Saving model ...
Validation loss decreased (1.080304 --> 1.075121).  Saving model ...
Validation loss decreased (1.075121 --> 1.071219).  Saving model ...
Validation loss decreased (1.071219 --> 1.066768).  Saving model ...
Validation loss decreased (1.066768 --> 1.062757).  Saving model ...
Validation loss decreased (1.062757 --> 1.059387).  Saving model ...
Validation loss decreased (1.059387 --> 1.054986).  Saving model ...
Validation loss decreased (1.054986 --> 1.051571).  Saving model ...
Validation loss decreased (1.051571 --> 1.047577).  Saving model ...
Validation loss decreased (1.047577 --> 1.044137).  Saving model ...
Validation loss decreased (1.044137 --> 1.040632).  Saving model ...
Validation loss decreased (1.040632 --> 1.037377).  Saving model ...
Validation loss decreased (1.037377 --> 1.035173).  Saving model ...
Validation loss decreased (1.035173 --> 1.031277).  Saving model ...
Validation loss decreased (1.031277 --> 1.026771).  Saving model ...
Validation loss decreased (1.026771 --> 1.024035).  Saving model ...
Validation loss decreased (1.024035 --> 1.022157).  Saving model ...
Validation loss decreased (1.022157 --> 1.018226).  Saving model ...
Validation loss decreased (1.018226 --> 1.015261).  Saving model ...
Validation loss decreased (1.015261 --> 1.013621).  Saving model ...
Validation loss decreased (1.013621 --> 1.011070).  Saving model ...
Validation loss decreased (1.011070 --> 1.007193).  Saving model ...
Validation loss decreased (1.007193 --> 1.004444).  Saving model ...
Validation loss decreased (1.004444 --> 1.002776).  Saving model ...
Validation loss decreased (1.002776 --> 1.001127).  Saving model ...
Validation loss decreased (1.001127 --> 1.000249).  Saving model ...
Validation loss decreased (1.000249 --> 0.995715).  Saving model ...
Validation loss decreased (0.995715 --> 0.992804).  Saving model ...
Validation loss decreased (0.992804 --> 0.989999).  Saving model ...
Validation loss decreased (0.989999 --> 0.988318).  Saving model ...
Validation loss decreased (0.988318 --> 0.986196).  Saving model ...
Validation loss decreased (0.986196 --> 0.985558).  Saving model ...
Validation loss decreased (0.985558 --> 0.983569).  Saving model ...
Validation loss decreased (0.983569 --> 0.981333).  Saving model ...
Validation loss decreased (0.981333 --> 0.980946).  Saving model ...
Validation loss decreased (0.980946 --> 0.978854).  Saving model ...
Validation loss decreased (0.978854 --> 0.976822).  Saving model ...
Validation loss decreased (0.976822 --> 0.973569).  Saving model ...
Validation loss decreased (0.973569 --> 0.972037).  Saving model ...
Validation loss decreased (0.972037 --> 0.970363).  Saving model ...
EarlyStopping counter: 1 out of 3.0
Validation loss decreased (0.970363 --> 0.969757).  Saving model ...
Validation loss decreased (0.969757 --> 0.967344).  Saving model ...
Validation loss decreased (0.967344 --> 0.964969).  Saving model ...
Validation loss decreased (0.964969 --> 0.962931).  Saving model ...
Validation loss decreased (0.962931 --> 0.961431).  Saving model ...
Validation loss decreased (0.961431 --> 0.960395).  Saving model ...
Validation loss decreased (0.960395 --> 0.957313).  Saving model ...
Validation loss decreased (0.957313 --> 0.956678).  Saving model ...
Validation loss decreased (0.956678 --> 0.954053).  Saving model ...
EarlyStopping counter: 1 out of 3.0
EarlyStopping counter: 2 out of 3.0
EarlyStopping counter: 3 out of 3.0
/localscratch/yinan.29785238.0/env/lib/python3.7/site-packages/torch/nn/functional.py:1794: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.
  warnings.warn("nn.functional.tanh is deprecated. Use torch.tanh instead.")
wandb: Waiting for W&B process to finish, PID 225448... (success).
wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: \ 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: | 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: / 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: \ 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: | 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: / 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: \ 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: | 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: / 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb:                                                                                
wandb: Run history:
wandb:     e_F1 ▁▂▃▃▄▄▄▄▅▅▆▆▆▆▆▆▇▆▇▇▇▇▇▇▇▇▇▇▇███████████
wandb:   e_loss ███▇▇▇▇▆▆▆▆▅▅▅▅▄▄▄▄▃▃▃▃▃▂▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁
wandb:     t_F1 ▁▁▂▂▂▃▂▃▃▄▄▅▅▅▅▅▆▆▆▆▆▆▇▇▇▆▇▇▇▇█▇█▇██████
wandb:   t_loss ███▇▇▇▇▇▇▆▆▆▆▅▅▅▅▅▄▄▄▄▄▃▃▃▃▃▃▃▂▂▂▂▂▂▂▁▁▁
wandb: 
wandb: Run summary:
wandb:     e_F1 57.68805
wandb:   e_loss 0.95506
wandb:     t_F1 68.80738
wandb:   t_loss 0.80517
wandb: 
wandb: Synced 4 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Synced light-night-1: https://wandb.ai/yinanazhou/xl_512_bs_8_lr_1e06_es_3_lc_True_nr_False_sr_True_stem_False_lemma_False_repeat_5_fold_1/runs/r0v01ntu
wandb: Find logs at: ./wandb/run-20220331_162500-r0v01ntu/logs/debug.log
wandb: 

wandb: wandb version 0.12.11 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
2022-03-31 17:36:13.864661: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1
wandb: Tracking run with wandb version 0.12.5
wandb: Syncing run likely-fog-1
wandb: ⭐️ View project at https://wandb.ai/yinanazhou/xl_512_bs_8_lr_1e06_es_3_lc_True_nr_False_sr_True_stem_False_lemma_False_repeat_5_fold_2
wandb: 🚀 View run at https://wandb.ai/yinanazhou/xl_512_bs_8_lr_1e06_es_3_lc_True_nr_False_sr_True_stem_False_lemma_False_repeat_5_fold_2/runs/1v81w2sg
wandb: Run data is saved locally in /project/6002780/yinan/Thesis_MER_Lyrics/lyric-emotion/wandb/run-20220331_173611-1v81w2sg
wandb: Run `wandb offline` to turn off syncing.

Validation loss decreased (inf --> 1.439995).  Saving model ...
Validation loss decreased (1.439995 --> 1.417439).  Saving model ...
Validation loss decreased (1.417439 --> 1.399879).  Saving model ...
Validation loss decreased (1.399879 --> 1.387147).  Saving model ...
Validation loss decreased (1.387147 --> 1.376794).  Saving model ...
Validation loss decreased (1.376794 --> 1.368029).  Saving model ...
Validation loss decreased (1.368029 --> 1.360889).  Saving model ...
Validation loss decreased (1.360889 --> 1.354495).  Saving model ...
Validation loss decreased (1.354495 --> 1.347507).  Saving model ...
Validation loss decreased (1.347507 --> 1.342316).  Saving model ...
Validation loss decreased (1.342316 --> 1.336830).  Saving model ...
Validation loss decreased (1.336830 --> 1.331520).  Saving model ...
Validation loss decreased (1.331520 --> 1.324810).  Saving model ...
Validation loss decreased (1.324810 --> 1.319326).  Saving model ...
Validation loss decreased (1.319326 --> 1.312773).  Saving model ...
Validation loss decreased (1.312773 --> 1.306823).  Saving model ...
Validation loss decreased (1.306823 --> 1.301225).  Saving model ...
Validation loss decreased (1.301225 --> 1.295107).  Saving model ...
Validation loss decreased (1.295107 --> 1.288395).  Saving model ...
Validation loss decreased (1.288395 --> 1.280280).  Saving model ...
Validation loss decreased (1.280280 --> 1.273089).  Saving model ...
Validation loss decreased (1.273089 --> 1.264426).  Saving model ...
Validation loss decreased (1.264426 --> 1.257524).  Saving model ...
Validation loss decreased (1.257524 --> 1.248328).  Saving model ...
Validation loss decreased (1.248328 --> 1.239010).  Saving model ...
Validation loss decreased (1.239010 --> 1.229707).  Saving model ...
Validation loss decreased (1.229707 --> 1.220892).  Saving model ...
Validation loss decreased (1.220892 --> 1.212888).  Saving model ...
Validation loss decreased (1.212888 --> 1.204616).  Saving model ...
Validation loss decreased (1.204616 --> 1.195467).  Saving model ...
Validation loss decreased (1.195467 --> 1.187773).  Saving model ...
Validation loss decreased (1.187773 --> 1.180545).  Saving model ...
Validation loss decreased (1.180545 --> 1.171662).  Saving model ...
Validation loss decreased (1.171662 --> 1.164404).  Saving model ...
Validation loss decreased (1.164404 --> 1.156459).  Saving model ...
Validation loss decreased (1.156459 --> 1.147543).  Saving model ...
Validation loss decreased (1.147543 --> 1.142306).  Saving model ...
Validation loss decreased (1.142306 --> 1.136777).  Saving model ...
Validation loss decreased (1.136777 --> 1.130268).  Saving model ...
Validation loss decreased (1.130268 --> 1.124058).  Saving model ...
Validation loss decreased (1.124058 --> 1.120058).  Saving model ...
Validation loss decreased (1.120058 --> 1.113225).  Saving model ...
Validation loss decreased (1.113225 --> 1.107048).  Saving model ...
Validation loss decreased (1.107048 --> 1.101585).  Saving model ...
Validation loss decreased (1.101585 --> 1.095456).  Saving model ...
Validation loss decreased (1.095456 --> 1.090192).  Saving model ...
Validation loss decreased (1.090192 --> 1.085075).  Saving model ...
Validation loss decreased (1.085075 --> 1.081075).  Saving model ...
Validation loss decreased (1.081075 --> 1.075772).  Saving model ...
Validation loss decreased (1.075772 --> 1.071266).  Saving model ...
Validation loss decreased (1.071266 --> 1.065164).  Saving model ...
Validation loss decreased (1.065164 --> 1.061349).  Saving model ...
Validation loss decreased (1.061349 --> 1.057061).  Saving model ...
Validation loss decreased (1.057061 --> 1.054071).  Saving model ...
Validation loss decreased (1.054071 --> 1.047864).  Saving model ...
Validation loss decreased (1.047864 --> 1.041134).  Saving model ...
Validation loss decreased (1.041134 --> 1.035144).  Saving model ...
Validation loss decreased (1.035144 --> 1.031634).  Saving model ...
Validation loss decreased (1.031634 --> 1.027982).  Saving model ...
Validation loss decreased (1.027982 --> 1.022615).  Saving model ...
Validation loss decreased (1.022615 --> 1.018765).  Saving model ...
Validation loss decreased (1.018765 --> 1.014155).  Saving model ...
Validation loss decreased (1.014155 --> 1.009506).  Saving model ...
Validation loss decreased (1.009506 --> 1.006448).  Saving model ...
Validation loss decreased (1.006448 --> 1.003940).  Saving model ...
Validation loss decreased (1.003940 --> 0.999118).  Saving model ...
Validation loss decreased (0.999118 --> 0.995824).  Saving model ...
Validation loss decreased (0.995824 --> 0.991282).  Saving model ...
Validation loss decreased (0.991282 --> 0.989466).  Saving model ...
Validation loss decreased (0.989466 --> 0.986004).  Saving model ...
EarlyStopping counter: 1 out of 3.0
Validation loss decreased (0.986004 --> 0.982191).  Saving model ...
Validation loss decreased (0.982191 --> 0.979965).  Saving model ...
Validation loss decreased (0.979965 --> 0.978027).  Saving model ...
Validation loss decreased (0.978027 --> 0.975053).  Saving model ...
Validation loss decreased (0.975053 --> 0.972535).  Saving model ...
Validation loss decreased (0.972535 --> 0.967526).  Saving model ...
Validation loss decreased (0.967526 --> 0.964488).  Saving model ...
Validation loss decreased (0.964488 --> 0.962489).  Saving model ...
Validation loss decreased (0.962489 --> 0.959919).  Saving model ...
Validation loss decreased (0.959919 --> 0.959165).  Saving model ...
Validation loss decreased (0.959165 --> 0.958335).  Saving model ...
Validation loss decreased (0.958335 --> 0.956964).  Saving model ...
Validation loss decreased (0.956964 --> 0.954002).  Saving model ...
Validation loss decreased (0.954002 --> 0.951821).  Saving model ...
Validation loss decreased (0.951821 --> 0.947142).  Saving model ...
Validation loss decreased (0.947142 --> 0.945838).  Saving model ...
Validation loss decreased (0.945838 --> 0.944721).  Saving model ...
Validation loss decreased (0.944721 --> 0.943806).  Saving model ...
Validation loss decreased (0.943806 --> 0.942056).  Saving model ...
Validation loss decreased (0.942056 --> 0.939249).  Saving model ...
Validation loss decreased (0.939249 --> 0.937507).  Saving model ...
Validation loss decreased (0.937507 --> 0.936586).  Saving model ...
Validation loss decreased (0.936586 --> 0.936336).  Saving model ...
Validation loss decreased (0.936336 --> 0.935758).  Saving model ...
Validation loss decreased (0.935758 --> 0.933970).  Saving model ...
EarlyStopping counter: 1 out of 3.0
Validation loss decreased (0.933970 --> 0.931620).  Saving model ...
EarlyStopping counter: 1 out of 3.0
Validation loss decreased (0.931620 --> 0.930266).  Saving model ...
EarlyStopping counter: 1 out of 3.0
Validation loss decreased (0.930266 --> 0.928270).  Saving model ...
Validation loss decreased (0.928270 --> 0.927398).  Saving model ...
Validation loss decreased (0.927398 --> 0.926288).  Saving model ...
Validation loss decreased (0.926288 --> 0.923267).  Saving model ...
Validation loss decreased (0.923267 --> 0.923219).  Saving model ...
Validation loss decreased (0.923219 --> 0.921229).  Saving model ...
Validation loss decreased (0.921229 --> 0.920297).  Saving model ...
Validation loss decreased (0.920297 --> 0.919056).  Saving model ...
EarlyStopping counter: 1 out of 3.0
EarlyStopping counter: 2 out of 3.0
Validation loss decreased (0.919056 --> 0.918233).  Saving model ...
EarlyStopping counter: 1 out of 3.0
EarlyStopping counter: 2 out of 3.0
Validation loss decreased (0.918233 --> 0.916023).  Saving model ...
Validation loss decreased (0.916023 --> 0.915144).  Saving model ...
EarlyStopping counter: 1 out of 3.0
EarlyStopping counter: 2 out of 3.0
EarlyStopping counter: 3 out of 3.0
/localscratch/yinan.29785238.0/env/lib/python3.7/site-packages/torch/nn/functional.py:1794: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.
  warnings.warn("nn.functional.tanh is deprecated. Use torch.tanh instead.")
wandb: Waiting for W&B process to finish, PID 229318... (success).
wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: \ 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: | 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: / 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: \ 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: | 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: / 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: \ 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: | 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: / 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb:                                                                                
wandb: Run history:
wandb:     e_F1 ▁▂▃▄▄▅▅▅▅▆▆▆▇▇▇▇▇▇▇▇▇▇██████████████████
wandb:   e_loss █▇▇▇▆▆▆▆▅▅▅▄▄▄▄▃▃▃▃▃▂▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁
wandb:     t_F1 ▁▂▂▃▃▄▄▄▄▄▅▅▅▅▆▆▆▆▆▇▆▇▇▇▇▇▇▇▇▇▇█▇█████▇█
wandb:   t_loss █▇▇▇▇▇▇▆▆▆▅▅▅▅▄▄▄▄▄▃▃▃▃▃▃▃▂▂▂▂▂▂▂▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:     e_F1 62.04447
wandb:   e_loss 0.91644
wandb:     t_F1 68.53403
wandb:   t_loss 0.80114
wandb: 
wandb: Synced 4 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Synced likely-fog-1: https://wandb.ai/yinanazhou/xl_512_bs_8_lr_1e06_es_3_lc_True_nr_False_sr_True_stem_False_lemma_False_repeat_5_fold_2/runs/1v81w2sg
wandb: Find logs at: ./wandb/run-20220331_173611-1v81w2sg/logs/debug.log
wandb: 

