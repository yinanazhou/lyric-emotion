Unloading StdEnv/2020

Due to MODULEPATH changes, the following have been reloaded:
  1) mii/1.1.1


The following have been reloaded with a version change:
  1) python/3.8.2 => python/3.7.4

Using base prefix '/cvmfs/soft.computecanada.ca/easybuild/software/2017/Core/python/3.7.4'
New python executable in /localscratch/yinan.29019366.0/env/bin/python
Installing setuptools, pip, wheel...
done.
Ignoring pip: markers 'python_version < "3"' don't match your environment
Looking in links: /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/nix/avx2, /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/nix/generic, /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic
Collecting pip
Installing collected packages: pip
  Found existing installation: pip 19.1.1
    Uninstalling pip-19.1.1:
      Successfully uninstalled pip-19.1.1
Successfully installed pip-21.2.3+computecanada
Looking in links: /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/nix/avx2, /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/nix/generic, /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/keras-2.8.0+computecanada-py2.py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/Keras_Preprocessing-1.1.2+computecanada-py3-none-any.whl
Requirement already satisfied: matplotlib in /cvmfs/soft.computecanada.ca/easybuild/software/2017/Core/scipy-stack/2019a/lib/python3.7/site-packages (from -r requirements.txt (line 3)) (3.0.2)
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/nltk-3.6.5+computecanada-py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/scikit_learn-0.22.1+computecanada-cp37-cp37m-linux_x86_64.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/tensorboard-2.3.0+computecanada-py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/tensorboard_plugin_wit-1.7.0+computecanada-py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/tensorflow_gpu-2.3.0+computecanada-cp37-cp37m-linux_x86_64.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/tensorflow_estimator-2.3.0+computecanada-py2.py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/tokenizers-0.5.2+computecanada-cp37-cp37m-linux_x86_64.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/nix/avx2/torch-1.4.0+computecanada-cp37-cp37m-linux_x86_64.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/torchtext-0.6.0+computecanada-py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/torchvision-0.8.2+computecanada-cp37-cp37m-linux_x86_64.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/transformers-2.5.1+computecanada-py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/urllib3-1.26.7+computecanada-py2.py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/click-8.0.4+computecanada-py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/tqdm-4.63.0+computecanada-py2.py3-none-any.whl
ERROR: Could not find a version that satisfies the requirement regex>=2021.8.3 (from nltk) (from versions: 2018.1.10+computecanada, 2019.11.1+computecanada, 2020.11.13+computecanada)
ERROR: No matching distribution found for regex>=2021.8.3
Looking in links: /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/nix/avx2, /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/nix/generic, /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic
ERROR: Could not find a version that satisfies the requirement numpy==1.20.0+computacanada (from versions: 1.15.0+computecanada, 1.15.2+computecanada, 1.15.4+computecanada, 1.16.0+computecanada, 1.16.2+computecanada, 1.16.3+computecanada, 1.17.4+computecanada, 1.18.1+computecanada, 1.18.4+computecanada, 1.19.1+computecanada, 1.19.2+computecanada, 1.20.2+computecanada)
ERROR: No matching distribution found for numpy==1.20.0+computacanada
Looking in links: /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/nix/avx2, /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/nix/generic, /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/wandb-0.12.5+computecanada-py2.py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/six-1.16.0+computecanada-py2.py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/click-8.0.4+computecanada-py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/GitPython-3.1.24+computecanada-py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/shortuuid-1.0.1+computecanada-py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/psutil-5.7.3+computecanada-cp37-cp37m-linux_x86_64.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/pathtools-0.1.2+computecanada-py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/docker_pycreds-0.4.0+computecanada-py2.py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/promise-2.3+computecanada-py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/PyYAML-5.3.1+computecanada-cp37-cp37m-linux_x86_64.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/configparser-5.0.2+computecanada-py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/subprocess32-3.5.4+computecanada-py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/yaspin-2.1.0+computecanada-py3-none-any.whl
Requirement already satisfied: requests<3,>=2.0.0 in /cvmfs/soft.computecanada.ca/easybuild/software/2017/Core/scipy-stack/2019a/lib/python3.7/site-packages (from wandb) (2.21.0)
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/protobuf-3.19.4+computecanada-py2.py3-none-any.whl
Requirement already satisfied: python-dateutil>=2.6.1 in /cvmfs/soft.computecanada.ca/easybuild/software/2017/Core/scipy-stack/2019a/lib/python3.7/site-packages (from wandb) (2.7.5)
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/sentry_sdk-1.5.0+computecanada-py2.py3-none-any.whl
Requirement already satisfied: importlib-metadata in /cvmfs/soft.computecanada.ca/easybuild/software/2017/Core/scipy-stack/2019a/lib/python3.7/site-packages (from Click!=8.0.0,>=7.0->wandb) (0.8)
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/gitdb-4.0.9+computecanada-py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/typing_extensions-4.0.1+computecanada-py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/smmap-5.0.0+computecanada-py3-none-any.whl
Requirement already satisfied: urllib3<1.25,>=1.21.1 in /cvmfs/soft.computecanada.ca/easybuild/software/2017/Core/scipy-stack/2019a/lib/python3.7/site-packages (from requests<3,>=2.0.0->wandb) (1.24.1)
Requirement already satisfied: certifi>=2017.4.17 in /cvmfs/soft.computecanada.ca/easybuild/software/2017/Core/scipy-stack/2019a/lib/python3.7/site-packages (from requests<3,>=2.0.0->wandb) (2018.11.29)
Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /cvmfs/soft.computecanada.ca/easybuild/software/2017/Core/scipy-stack/2019a/lib/python3.7/site-packages (from requests<3,>=2.0.0->wandb) (3.0.4)
Requirement already satisfied: idna<2.9,>=2.5 in /cvmfs/soft.computecanada.ca/easybuild/software/2017/Core/scipy-stack/2019a/lib/python3.7/site-packages (from requests<3,>=2.0.0->wandb) (2.8)
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/termcolor-1.1.0+computecanada-py3-none-any.whl
Requirement already satisfied: zipp>=0.3.2 in /cvmfs/soft.computecanada.ca/easybuild/software/2017/Core/scipy-stack/2019a/lib/python3.7/site-packages (from importlib-metadata->Click!=8.0.0,>=7.0->wandb) (0.3.3)
Installing collected packages: smmap, typing-extensions, termcolor, six, gitdb, yaspin, subprocess32, shortuuid, sentry-sdk, PyYAML, psutil, protobuf, promise, pathtools, GitPython, docker-pycreds, configparser, Click, wandb
  Attempting uninstall: six
    Found existing installation: six 1.12.0
    Not uninstalling six at /cvmfs/soft.computecanada.ca/easybuild/software/2017/Core/scipy-stack/2019a/lib/python3.7/site-packages, outside environment /localscratch/yinan.29019366.0/env
    Can't uninstall 'six'. No files were found to uninstall.
Successfully installed Click-8.0.4+computecanada GitPython-3.1.24+computecanada PyYAML-5.3.1+computecanada configparser-5.0.2+computecanada docker-pycreds-0.4.0+computecanada gitdb-4.0.9+computecanada pathtools-0.1.2+computecanada promise-2.3+computecanada protobuf-3.19.4+computecanada psutil-5.7.3+computecanada sentry-sdk-1.5.0+computecanada shortuuid-1.0.1+computecanada six-1.16.0+computecanada smmap-5.0.0+computecanada subprocess32-3.5.4+computecanada termcolor-1.1.0+computecanada typing-extensions-4.0.1+computecanada wandb-0.12.5+computecanada yaspin-2.1.0+computecanada
Looking in links: /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/nix/avx2, /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/nix/generic, /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic
ERROR: Could not find a version that satisfies the requirement sagemaker (from versions: none)
ERROR: No matching distribution found for sagemaker
Looking in links: /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/nix/avx2, /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/nix/generic, /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/torch-1.9.1+computecanada-cp37-cp37m-linux_x86_64.whl
Requirement already satisfied: typing-extensions in /localscratch/yinan.29019366.0/env/lib/python3.7/site-packages (from torch) (4.0.1+computecanada)
Installing collected packages: torch
Successfully installed torch-1.9.1+computecanada
Looking in links: /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/nix/avx2, /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/nix/generic, /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/transformers-2.5.1+computecanada-py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/filelock-3.4.2+computecanada-py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/tqdm-4.63.0+computecanada-py2.py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/tokenizers-0.5.2+computecanada-cp37-cp37m-linux_x86_64.whl
Requirement already satisfied: requests in /cvmfs/soft.computecanada.ca/easybuild/software/2017/Core/scipy-stack/2019a/lib/python3.7/site-packages (from transformers==2.5.1+computecanada) (2.21.0)
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/regex-2020.11.13+computecanada-cp37-cp37m-linux_x86_64.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/boto3-1.21.14+computecanada-py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/sacremoses-0.0.46+computecanada-py3-none-any.whl
Requirement already satisfied: numpy in /cvmfs/soft.computecanada.ca/easybuild/software/2017/Core/scipy-stack/2019a/lib/python3.7/site-packages (from transformers==2.5.1+computecanada) (1.16.0)
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/sentencepiece-0.1.91+computecanada-cp37-cp37m-linux_x86_64.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/jmespath-0.10.0+computecanada-py2.py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/s3transfer-0.5.1+computecanada-py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/botocore-1.24.14+computecanada-py3-none-any.whl
Requirement already satisfied: python-dateutil<3.0.0,>=2.1 in /cvmfs/soft.computecanada.ca/easybuild/software/2017/Core/scipy-stack/2019a/lib/python3.7/site-packages (from botocore<1.25.0,>=1.24.14->boto3->transformers==2.5.1+computecanada) (2.7.5)
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/urllib3-1.26.8+computecanada-py2.py3-none-any.whl
Requirement already satisfied: six>=1.5 in /localscratch/yinan.29019366.0/env/lib/python3.7/site-packages (from python-dateutil<3.0.0,>=2.1->botocore<1.25.0,>=1.24.14->boto3->transformers==2.5.1+computecanada) (1.16.0+computecanada)
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/requests-2.27.1+computecanada-py2.py3-none-any.whl
Requirement already satisfied: certifi>=2017.4.17 in /cvmfs/soft.computecanada.ca/easybuild/software/2017/Core/scipy-stack/2019a/lib/python3.7/site-packages (from requests->transformers==2.5.1+computecanada) (2018.11.29)
Requirement already satisfied: idna<4,>=2.5 in /cvmfs/soft.computecanada.ca/easybuild/software/2017/Core/scipy-stack/2019a/lib/python3.7/site-packages (from requests->transformers==2.5.1+computecanada) (2.8)
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/charset_normalizer-2.0.12+computecanada-py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/joblib-1.1.0+computecanada-py2.py3-none-any.whl
Requirement already satisfied: click in /localscratch/yinan.29019366.0/env/lib/python3.7/site-packages (from sacremoses->transformers==2.5.1+computecanada) (8.0.4+computecanada)
Requirement already satisfied: importlib-metadata in /cvmfs/soft.computecanada.ca/easybuild/software/2017/Core/scipy-stack/2019a/lib/python3.7/site-packages (from click->sacremoses->transformers==2.5.1+computecanada) (0.8)
Requirement already satisfied: zipp>=0.3.2 in /cvmfs/soft.computecanada.ca/easybuild/software/2017/Core/scipy-stack/2019a/lib/python3.7/site-packages (from importlib-metadata->click->sacremoses->transformers==2.5.1+computecanada) (0.3.3)
Installing collected packages: urllib3, jmespath, botocore, tqdm, s3transfer, regex, joblib, charset-normalizer, tokenizers, sentencepiece, sacremoses, requests, filelock, boto3, transformers
  Attempting uninstall: urllib3
    Found existing installation: urllib3 1.24.1
    Not uninstalling urllib3 at /cvmfs/soft.computecanada.ca/easybuild/software/2017/Core/scipy-stack/2019a/lib/python3.7/site-packages, outside environment /localscratch/yinan.29019366.0/env
    Can't uninstall 'urllib3'. No files were found to uninstall.
  Attempting uninstall: requests
    Found existing installation: requests 2.21.0
    Not uninstalling requests at /cvmfs/soft.computecanada.ca/easybuild/software/2017/Core/scipy-stack/2019a/lib/python3.7/site-packages, outside environment /localscratch/yinan.29019366.0/env
    Can't uninstall 'requests'. No files were found to uninstall.
Successfully installed boto3-1.21.14+computecanada botocore-1.24.14+computecanada charset-normalizer-2.0.12+computecanada filelock-3.4.2+computecanada jmespath-0.10.0+computecanada joblib-1.1.0+computecanada regex-2020.11.13+computecanada requests-2.27.1+computecanada s3transfer-0.5.1+computecanada sacremoses-0.0.46+computecanada sentencepiece-0.1.91+computecanada tokenizers-0.5.2+computecanada tqdm-4.63.0+computecanada transformers-2.5.1+computecanada urllib3-1.26.8+computecanada
Looking in links: /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/nix/avx2, /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/nix/generic, /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/tensorflow_gpu-2.3.0+computecanada-cp37-cp37m-linux_x86_64.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/tensorboard-2.8.0+computecanada-py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/tensorflow_estimator-2.3.0+computecanada-py2.py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/opt_einsum-3.3.0+computecanada-py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/gast-0.3.3+computecanada-py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/absl_py-1.0.0+computecanada-py3-none-any.whl
Requirement already satisfied: protobuf>=3.9.2 in /localscratch/yinan.29019366.0/env/lib/python3.7/site-packages (from tensorflow_gpu==2.3.0+computecanada) (3.19.4+computecanada)
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/wrapt-1.11.2+computecanada-cp37-cp37m-linux_x86_64.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/google_pasta-0.2.0+computecanada-py3-none-any.whl
Requirement already satisfied: six>=1.12.0 in /localscratch/yinan.29019366.0/env/lib/python3.7/site-packages (from tensorflow_gpu==2.3.0+computecanada) (1.16.0+computecanada)
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/nix/generic/scipy-1.4.1+computecanada-cp37-cp37m-linux_x86_64.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/Keras_Preprocessing-1.1.2+computecanada-py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/grpcio-1.38.0+computecanada-cp37-cp37m-linux_x86_64.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/nix/avx2/h5py-2.10.0+computecanada-cp37-cp37m-linux_x86_64.whl
Requirement already satisfied: termcolor>=1.1.0 in /localscratch/yinan.29019366.0/env/lib/python3.7/site-packages (from tensorflow_gpu==2.3.0+computecanada) (1.1.0+computecanada)
Requirement already satisfied: numpy<1.19.0,>=1.16.0 in /cvmfs/soft.computecanada.ca/easybuild/software/2017/Core/scipy-stack/2019a/lib/python3.7/site-packages (from tensorflow_gpu==2.3.0+computecanada) (1.16.0)
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/astunparse-1.6.3+computecanada-py2.py3-none-any.whl
Requirement already satisfied: wheel>=0.26 in /localscratch/yinan.29019366.0/env/lib/python3.7/site-packages (from tensorflow_gpu==2.3.0+computecanada) (0.33.4)
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/tensorboard_data_server-0.6.1+computecanada-py3-none-linux_x86_64.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/Werkzeug-2.0.3+computecanada-py3-none-any.whl
Requirement already satisfied: setuptools>=41.0.0 in /localscratch/yinan.29019366.0/env/lib/python3.7/site-packages (from tensorboard<3,>=2.3.0->tensorflow_gpu==2.3.0+computecanada) (41.0.1)
Requirement already satisfied: requests<3,>=2.21.0 in /localscratch/yinan.29019366.0/env/lib/python3.7/site-packages (from tensorboard<3,>=2.3.0->tensorflow_gpu==2.3.0+computecanada) (2.27.1+computecanada)
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/tensorboard_plugin_wit-1.8.0+computecanada-py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/google_auth_oauthlib-0.4.6+computecanada-py2.py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/google_auth-2.3.3+computecanada-py2.py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/Markdown-3.3.6+computecanada-py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/rsa-4.8+computecanada-py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/cachetools-4.2.4+computecanada-py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/pyasn1_modules-0.2.8+computecanada-py2.py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/requests_oauthlib-1.3.0+computecanada-py2.py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/importlib_metadata-4.10.1+computecanada-py3-none-any.whl
Requirement already satisfied: typing-extensions>=3.6.4 in /localscratch/yinan.29019366.0/env/lib/python3.7/site-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard<3,>=2.3.0->tensorflow_gpu==2.3.0+computecanada) (4.0.1+computecanada)
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/zipp-3.7.0+computecanada-py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/pyasn1-0.4.8+computecanada-py2.py3-none-any.whl
Requirement already satisfied: urllib3<1.27,>=1.21.1 in /localscratch/yinan.29019366.0/env/lib/python3.7/site-packages (from requests<3,>=2.21.0->tensorboard<3,>=2.3.0->tensorflow_gpu==2.3.0+computecanada) (1.26.8+computecanada)
Requirement already satisfied: idna<4,>=2.5 in /cvmfs/soft.computecanada.ca/easybuild/software/2017/Core/scipy-stack/2019a/lib/python3.7/site-packages (from requests<3,>=2.21.0->tensorboard<3,>=2.3.0->tensorflow_gpu==2.3.0+computecanada) (2.8)
Requirement already satisfied: charset-normalizer~=2.0.0 in /localscratch/yinan.29019366.0/env/lib/python3.7/site-packages (from requests<3,>=2.21.0->tensorboard<3,>=2.3.0->tensorflow_gpu==2.3.0+computecanada) (2.0.12+computecanada)
Requirement already satisfied: certifi>=2017.4.17 in /cvmfs/soft.computecanada.ca/easybuild/software/2017/Core/scipy-stack/2019a/lib/python3.7/site-packages (from requests<3,>=2.21.0->tensorboard<3,>=2.3.0->tensorflow_gpu==2.3.0+computecanada) (2018.11.29)
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/oauthlib-3.1.1+computecanada-py2.py3-none-any.whl
Installing collected packages: pyasn1, zipp, rsa, pyasn1-modules, oauthlib, cachetools, requests-oauthlib, importlib-metadata, google-auth, werkzeug, tensorboard-plugin-wit, tensorboard-data-server, markdown, grpcio, google-auth-oauthlib, absl-py, wrapt, tensorflow-estimator, tensorboard, scipy, opt-einsum, keras-preprocessing, h5py, google-pasta, gast, astunparse, tensorflow-gpu
  Attempting uninstall: pyasn1
    Found existing installation: pyasn1 0.4.3
    Not uninstalling pyasn1 at /cvmfs/soft.computecanada.ca/easybuild/software/2017/Core/scipy-stack/2019a/lib/python3.7/site-packages, outside environment /localscratch/yinan.29019366.0/env
    Can't uninstall 'pyasn1'. No files were found to uninstall.
  Attempting uninstall: zipp
    Found existing installation: zipp 0.3.3
    Not uninstalling zipp at /cvmfs/soft.computecanada.ca/easybuild/software/2017/Core/scipy-stack/2019a/lib/python3.7/site-packages, outside environment /localscratch/yinan.29019366.0/env
    Can't uninstall 'zipp'. No files were found to uninstall.
  Attempting uninstall: importlib-metadata
    Found existing installation: importlib-metadata 0.8
    Not uninstalling importlib-metadata at /cvmfs/soft.computecanada.ca/easybuild/software/2017/Core/scipy-stack/2019a/lib/python3.7/site-packages, outside environment /localscratch/yinan.29019366.0/env
    Can't uninstall 'importlib-metadata'. No files were found to uninstall.
  Attempting uninstall: scipy
    Found existing installation: scipy 1.2.0
    Not uninstalling scipy at /cvmfs/soft.computecanada.ca/easybuild/software/2017/Core/scipy-stack/2019a/lib/python3.7/site-packages, outside environment /localscratch/yinan.29019366.0/env
    Can't uninstall 'scipy'. No files were found to uninstall.
Successfully installed absl-py-1.0.0+computecanada astunparse-1.6.3+computecanada cachetools-4.2.4+computecanada gast-0.3.3+computecanada google-auth-2.3.3+computecanada google-auth-oauthlib-0.4.6+computecanada google-pasta-0.2.0+computecanada grpcio-1.38.0+computecanada h5py-2.10.0+computecanada importlib-metadata-4.10.1+computecanada keras-preprocessing-1.1.2+computecanada markdown-3.3.6+computecanada oauthlib-3.1.1+computecanada opt-einsum-3.3.0+computecanada pyasn1-0.4.8+computecanada pyasn1-modules-0.2.8+computecanada requests-oauthlib-1.3.0+computecanada rsa-4.8+computecanada scipy-1.4.1+computecanada tensorboard-2.8.0+computecanada tensorboard-data-server-0.6.1+computecanada tensorboard-plugin-wit-1.8.0+computecanada tensorflow-estimator-2.3.0+computecanada tensorflow-gpu-2.3.0+computecanada werkzeug-2.0.3+computecanada wrapt-1.11.2+computecanada zipp-3.7.0+computecanada
Looking in links: /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/nix/avx2, /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/nix/generic, /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/keras-2.8.0+computecanada-py2.py3-none-any.whl
Installing collected packages: Keras
Successfully installed Keras-2.8.0+computecanada
Looking in links: /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/nix/avx2, /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/nix/generic, /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/urllib3-1.26.7+computecanada-py2.py3-none-any.whl
Installing collected packages: urllib3
  Attempting uninstall: urllib3
    Found existing installation: urllib3 1.26.8+computecanada
    Uninstalling urllib3-1.26.8+computecanada:
      Successfully uninstalled urllib3-1.26.8+computecanada
Successfully installed urllib3-1.26.7+computecanada
Looking in links: /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/nix/avx2, /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/nix/generic, /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/nltk-3.7+computecanada-py3-none-any.whl
Requirement already satisfied: joblib in /localscratch/yinan.29019366.0/env/lib/python3.7/site-packages (from nltk) (1.1.0+computecanada)
Requirement already satisfied: tqdm in /localscratch/yinan.29019366.0/env/lib/python3.7/site-packages (from nltk) (4.63.0+computecanada)
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/nltk-3.6.5+computecanada-py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/nltk-3.6.3+computecanada-py3-none-any.whl
Requirement already satisfied: regex in /localscratch/yinan.29019366.0/env/lib/python3.7/site-packages (from nltk) (2020.11.13+computecanada)
Requirement already satisfied: click in /localscratch/yinan.29019366.0/env/lib/python3.7/site-packages (from nltk) (8.0.4+computecanada)
Requirement already satisfied: importlib-metadata in /localscratch/yinan.29019366.0/env/lib/python3.7/site-packages (from click->nltk) (4.10.1+computecanada)
Requirement already satisfied: typing-extensions>=3.6.4 in /localscratch/yinan.29019366.0/env/lib/python3.7/site-packages (from importlib-metadata->click->nltk) (4.0.1+computecanada)
Requirement already satisfied: zipp>=0.5 in /localscratch/yinan.29019366.0/env/lib/python3.7/site-packages (from importlib-metadata->click->nltk) (3.7.0+computecanada)
Installing collected packages: nltk
Successfully installed nltk-3.6.3+computecanada
Looking in links: /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/nix/avx2, /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/nix/generic, /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/scikit_learn-0.22.1+computecanada-cp37-cp37m-linux_x86_64.whl
Requirement already satisfied: scipy>=0.17.0 in /localscratch/yinan.29019366.0/env/lib/python3.7/site-packages (from scikit-learn==0.22.1) (1.4.1+computecanada)
Requirement already satisfied: numpy>=1.11.0 in /cvmfs/soft.computecanada.ca/easybuild/software/2017/Core/scipy-stack/2019a/lib/python3.7/site-packages (from scikit-learn==0.22.1) (1.16.0)
Requirement already satisfied: joblib>=0.11 in /localscratch/yinan.29019366.0/env/lib/python3.7/site-packages (from scikit-learn==0.22.1) (1.1.0+computecanada)
Installing collected packages: scikit-learn
Successfully installed scikit-learn-0.22.1+computecanada
Looking in links: /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/nix/avx2, /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/nix/generic, /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic
Requirement already satisfied: tokenizers==0.5.2 in /localscratch/yinan.29019366.0/env/lib/python3.7/site-packages (0.5.2+computecanada)
wandb: Appending key for api.wandb.ai to your netrc file: /home/yinan/.netrc
Starting Task
2022-03-18 19:48:14.873214: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1
[nltk_data] Downloading package stopwords to /home/yinan/nltk_data...
[nltk_data]   Package stopwords is already up-to-date!
[nltk_data] Downloading package wordnet to /home/yinan/nltk_data...
[nltk_data]   Package wordnet is already up-to-date!
wandb: Currently logged in as: yinanazhou (use `wandb login --relogin` to force relogin)
wandb: wandb version 0.12.11 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
2022-03-18 19:48:32.277667: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1
wandb: Tracking run with wandb version 0.12.5
wandb: Syncing run faithful-oath-2
wandb: ⭐️ View project at https://wandb.ai/yinanazhou/xl_512_bs_8_lr_1e06_es_10_lc_False_nr_False_sr_True_stem_True_lemma_False_repeat_1_fold_1
wandb: 🚀 View run at https://wandb.ai/yinanazhou/xl_512_bs_8_lr_1e06_es_10_lc_False_nr_False_sr_True_stem_True_lemma_False_repeat_1_fold_1/runs/1neyypjj
wandb: Run data is saved locally in /project/6002780/yinan/Thesis_MER_Lyrics/lyric-emotion/wandb/run-20220318_194830-1neyypjj
wandb: Run `wandb offline` to turn off syncing.

Validation loss decreased (inf --> 1.428336).  Saving model ...
Validation loss decreased (1.428336 --> 1.410090).  Saving model ...
Validation loss decreased (1.410090 --> 1.394581).  Saving model ...
Validation loss decreased (1.394581 --> 1.382553).  Saving model ...
Validation loss decreased (1.382553 --> 1.373312).  Saving model ...
Validation loss decreased (1.373312 --> 1.365093).  Saving model ...
Validation loss decreased (1.365093 --> 1.357848).  Saving model ...
Validation loss decreased (1.357848 --> 1.352315).  Saving model ...
Validation loss decreased (1.352315 --> 1.347384).  Saving model ...
Validation loss decreased (1.347384 --> 1.341819).  Saving model ...
Validation loss decreased (1.341819 --> 1.335825).  Saving model ...
Validation loss decreased (1.335825 --> 1.330865).  Saving model ...
Validation loss decreased (1.330865 --> 1.324781).  Saving model ...
Validation loss decreased (1.324781 --> 1.319466).  Saving model ...
Validation loss decreased (1.319466 --> 1.313526).  Saving model ...
Validation loss decreased (1.313526 --> 1.307974).  Saving model ...
Validation loss decreased (1.307974 --> 1.301574).  Saving model ...
Validation loss decreased (1.301574 --> 1.295002).  Saving model ...
Validation loss decreased (1.295002 --> 1.287915).  Saving model ...
Validation loss decreased (1.287915 --> 1.280906).  Saving model ...
Validation loss decreased (1.280906 --> 1.274137).  Saving model ...
Validation loss decreased (1.274137 --> 1.267608).  Saving model ...
Validation loss decreased (1.267608 --> 1.260766).  Saving model ...
Validation loss decreased (1.260766 --> 1.253186).  Saving model ...
Validation loss decreased (1.253186 --> 1.246624).  Saving model ...
Validation loss decreased (1.246624 --> 1.239379).  Saving model ...
Validation loss decreased (1.239379 --> 1.233142).  Saving model ...
Validation loss decreased (1.233142 --> 1.227383).  Saving model ...
Validation loss decreased (1.227383 --> 1.222111).  Saving model ...
Validation loss decreased (1.222111 --> 1.218019).  Saving model ...
Validation loss decreased (1.218019 --> 1.210569).  Saving model ...
Validation loss decreased (1.210569 --> 1.204863).  Saving model ...
Validation loss decreased (1.204863 --> 1.203193).  Saving model ...
Validation loss decreased (1.203193 --> 1.196775).  Saving model ...
Validation loss decreased (1.196775 --> 1.192703).  Saving model ...
Validation loss decreased (1.192703 --> 1.189213).  Saving model ...
Validation loss decreased (1.189213 --> 1.184962).  Saving model ...
Validation loss decreased (1.184962 --> 1.178914).  Saving model ...
Validation loss decreased (1.178914 --> 1.176458).  Saving model ...
Validation loss decreased (1.176458 --> 1.171284).  Saving model ...
Validation loss decreased (1.171284 --> 1.166732).  Saving model ...
Validation loss decreased (1.166732 --> 1.162547).  Saving model ...
Validation loss decreased (1.162547 --> 1.159377).  Saving model ...
Validation loss decreased (1.159377 --> 1.156974).  Saving model ...
Validation loss decreased (1.156974 --> 1.152956).  Saving model ...
Validation loss decreased (1.152956 --> 1.149144).  Saving model ...
Validation loss decreased (1.149144 --> 1.145337).  Saving model ...
Validation loss decreased (1.145337 --> 1.141879).  Saving model ...
Validation loss decreased (1.141879 --> 1.136632).  Saving model ...
Validation loss decreased (1.136632 --> 1.133573).  Saving model ...
Validation loss decreased (1.133573 --> 1.130473).  Saving model ...
Validation loss decreased (1.130473 --> 1.126623).  Saving model ...
Validation loss decreased (1.126623 --> 1.122893).  Saving model ...
Validation loss decreased (1.122893 --> 1.119330).  Saving model ...
Validation loss decreased (1.119330 --> 1.118278).  Saving model ...
Validation loss decreased (1.118278 --> 1.115033).  Saving model ...
Validation loss decreased (1.115033 --> 1.113060).  Saving model ...
Validation loss decreased (1.113060 --> 1.111896).  Saving model ...
Validation loss decreased (1.111896 --> 1.108335).  Saving model ...
Validation loss decreased (1.108335 --> 1.106651).  Saving model ...
Validation loss decreased (1.106651 --> 1.103776).  Saving model ...
Validation loss decreased (1.103776 --> 1.103452).  Saving model ...
Validation loss decreased (1.103452 --> 1.097789).  Saving model ...
Validation loss decreased (1.097789 --> 1.095956).  Saving model ...
EarlyStopping counter: 1 out of 10.0
Validation loss decreased (1.095956 --> 1.094321).  Saving model ...
Validation loss decreased (1.094321 --> 1.092769).  Saving model ...
Validation loss decreased (1.092769 --> 1.091682).  Saving model ...
Validation loss decreased (1.091682 --> 1.088289).  Saving model ...
Validation loss decreased (1.088289 --> 1.084520).  Saving model ...
Validation loss decreased (1.084520 --> 1.081349).  Saving model ...
Validation loss decreased (1.081349 --> 1.080218).  Saving model ...
Validation loss decreased (1.080218 --> 1.075985).  Saving model ...
Validation loss decreased (1.075985 --> 1.074257).  Saving model ...
Validation loss decreased (1.074257 --> 1.070610).  Saving model ...
EarlyStopping counter: 1 out of 10.0
EarlyStopping counter: 2 out of 10.0
EarlyStopping counter: 3 out of 10.0
Validation loss decreased (1.070610 --> 1.067180).  Saving model ...
Validation loss decreased (1.067180 --> 1.066260).  Saving model ...
Validation loss decreased (1.066260 --> 1.065961).  Saving model ...
Validation loss decreased (1.065961 --> 1.064425).  Saving model ...
Validation loss decreased (1.064425 --> 1.063727).  Saving model ...
Validation loss decreased (1.063727 --> 1.060416).  Saving model ...
Validation loss decreased (1.060416 --> 1.057384).  Saving model ...
Validation loss decreased (1.057384 --> 1.057142).  Saving model ...
EarlyStopping counter: 1 out of 10.0
EarlyStopping counter: 2 out of 10.0
Validation loss decreased (1.057142 --> 1.056663).  Saving model ...
Validation loss decreased (1.056663 --> 1.055487).  Saving model ...
Validation loss decreased (1.055487 --> 1.053208).  Saving model ...
Validation loss decreased (1.053208 --> 1.051571).  Saving model ...
Validation loss decreased (1.051571 --> 1.049869).  Saving model ...
EarlyStopping counter: 1 out of 10.0
EarlyStopping counter: 2 out of 10.0
Validation loss decreased (1.049869 --> 1.047207).  Saving model ...
EarlyStopping counter: 1 out of 10.0
EarlyStopping counter: 2 out of 10.0
Validation loss decreased (1.047207 --> 1.045383).  Saving model ...
EarlyStopping counter: 1 out of 10.0
EarlyStopping counter: 2 out of 10.0
EarlyStopping counter: 3 out of 10.0
Validation loss decreased (1.045383 --> 1.044297).  Saving model ...
EarlyStopping counter: 1 out of 10.0
EarlyStopping counter: 2 out of 10.0
EarlyStopping counter: 3 out of 10.0
Validation loss decreased (1.044297 --> 1.043381).  Saving model ...
EarlyStopping counter: 1 out of 10.0
Validation loss decreased (1.043381 --> 1.042279).  Saving model ...
Validation loss decreased (1.042279 --> 1.040701).  Saving model ...
EarlyStopping counter: 1 out of 10.0
EarlyStopping counter: 2 out of 10.0
EarlyStopping counter: 3 out of 10.0
EarlyStopping counter: 4 out of 10.0
EarlyStopping counter: 5 out of 10.0
EarlyStopping counter: 6 out of 10.0
EarlyStopping counter: 7 out of 10.0
EarlyStopping counter: 8 out of 10.0
EarlyStopping counter: 9 out of 10.0
EarlyStopping counter: 10 out of 10.0
/localscratch/yinan.29019366.0/env/lib/python3.7/site-packages/torch/nn/functional.py:1794: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.
  warnings.warn("nn.functional.tanh is deprecated. Use torch.tanh instead.")
/localscratch/yinan.29019366.0/env/lib/python3.7/site-packages/transformers/optimization.py:155: UserWarning: This overload of add_ is deprecated:
	add_(Number alpha, Tensor other)
Consider using one of the following signatures instead:
	add_(Tensor other, *, Number alpha) (Triggered internally at  ../torch/csrc/utils/python_arg_parser.cpp:1025.)
  exp_avg.mul_(beta1).add_(1.0 - beta1, grad)
wandb: Waiting for W&B process to finish, PID 3828... (success).
wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: \ 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: | 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: / 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: \ 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: | 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: / 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: \ 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: | 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: / 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb:                                                                                
wandb: Run history:
wandb:     e_F1 ▁▂▄▅▅▅▆▆▆▆▆▆▆▇▇▇▇▇▇▇▇▇██████████████████
wandb:   e_loss █▇▇▆▆▆▅▅▅▄▄▄▄▃▃▃▃▃▂▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:     t_F1 ▁▂▃▂▃▃▄▄▄▅▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇▇▇▇▇█▇█████▇█
wandb:   t_loss ██▇▇▇▇▇▆▆▆▅▅▅▅▄▄▄▄▄▄▃▃▃▃▃▂▂▂▂▂▂▂▂▂▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:     e_F1 56.89706
wandb:   e_loss 1.04204
wandb:     t_F1 70.69812
wandb:   t_loss 0.7843
wandb: 
wandb: Synced 4 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Synced faithful-oath-2: https://wandb.ai/yinanazhou/xl_512_bs_8_lr_1e06_es_10_lc_False_nr_False_sr_True_stem_True_lemma_False_repeat_1_fold_1/runs/1neyypjj
wandb: Find logs at: ./wandb/run-20220318_194830-1neyypjj/logs/debug.log
wandb: 

wandb: wandb version 0.12.11 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
2022-03-18 21:06:18.741629: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1
wandb: Tracking run with wandb version 0.12.5
wandb: Syncing run scarlet-pond-2
wandb: ⭐️ View project at https://wandb.ai/yinanazhou/xl_512_bs_8_lr_1e06_es_10_lc_False_nr_False_sr_True_stem_True_lemma_False_repeat_1_fold_2
wandb: 🚀 View run at https://wandb.ai/yinanazhou/xl_512_bs_8_lr_1e06_es_10_lc_False_nr_False_sr_True_stem_True_lemma_False_repeat_1_fold_2/runs/1izox2yi
wandb: Run data is saved locally in /project/6002780/yinan/Thesis_MER_Lyrics/lyric-emotion/wandb/run-20220318_210616-1izox2yi
wandb: Run `wandb offline` to turn off syncing.

Validation loss decreased (inf --> 1.509431).  Saving model ...
Validation loss decreased (1.509431 --> 1.478469).  Saving model ...
Validation loss decreased (1.478469 --> 1.452591).  Saving model ...
Validation loss decreased (1.452591 --> 1.431739).  Saving model ...
Validation loss decreased (1.431739 --> 1.414678).  Saving model ...
Validation loss decreased (1.414678 --> 1.401380).  Saving model ...
Validation loss decreased (1.401380 --> 1.390693).  Saving model ...
Validation loss decreased (1.390693 --> 1.382418).  Saving model ...
Validation loss decreased (1.382418 --> 1.375162).  Saving model ...
Validation loss decreased (1.375162 --> 1.369358).  Saving model ...
Validation loss decreased (1.369358 --> 1.363812).  Saving model ...
Validation loss decreased (1.363812 --> 1.359226).  Saving model ...
Validation loss decreased (1.359226 --> 1.354645).  Saving model ...
Validation loss decreased (1.354645 --> 1.350012).  Saving model ...
Validation loss decreased (1.350012 --> 1.345617).  Saving model ...
Validation loss decreased (1.345617 --> 1.340621).  Saving model ...
Validation loss decreased (1.340621 --> 1.336258).  Saving model ...
Validation loss decreased (1.336258 --> 1.331446).  Saving model ...
Validation loss decreased (1.331446 --> 1.326576).  Saving model ...
Validation loss decreased (1.326576 --> 1.321634).  Saving model ...
Validation loss decreased (1.321634 --> 1.315761).  Saving model ...
Validation loss decreased (1.315761 --> 1.310073).  Saving model ...
Validation loss decreased (1.310073 --> 1.303639).  Saving model ...
Validation loss decreased (1.303639 --> 1.297032).  Saving model ...
Validation loss decreased (1.297032 --> 1.290827).  Saving model ...
Validation loss decreased (1.290827 --> 1.283810).  Saving model ...
Validation loss decreased (1.283810 --> 1.276926).  Saving model ...
Validation loss decreased (1.276926 --> 1.268556).  Saving model ...
Validation loss decreased (1.268556 --> 1.260354).  Saving model ...
Validation loss decreased (1.260354 --> 1.253067).  Saving model ...
Validation loss decreased (1.253067 --> 1.245479).  Saving model ...
Validation loss decreased (1.245479 --> 1.235681).  Saving model ...
Validation loss decreased (1.235681 --> 1.228331).  Saving model ...
Validation loss decreased (1.228331 --> 1.220407).  Saving model ...
Validation loss decreased (1.220407 --> 1.211535).  Saving model ...
Validation loss decreased (1.211535 --> 1.203797).  Saving model ...
Validation loss decreased (1.203797 --> 1.196881).  Saving model ...
Validation loss decreased (1.196881 --> 1.189977).  Saving model ...
Validation loss decreased (1.189977 --> 1.183585).  Saving model ...
Validation loss decreased (1.183585 --> 1.176461).  Saving model ...
Validation loss decreased (1.176461 --> 1.170019).  Saving model ...
Validation loss decreased (1.170019 --> 1.165427).  Saving model ...
Validation loss decreased (1.165427 --> 1.159204).  Saving model ...
Validation loss decreased (1.159204 --> 1.153476).  Saving model ...
Validation loss decreased (1.153476 --> 1.147753).  Saving model ...
Validation loss decreased (1.147753 --> 1.139332).  Saving model ...
Validation loss decreased (1.139332 --> 1.132951).  Saving model ...
Validation loss decreased (1.132951 --> 1.127337).  Saving model ...
Validation loss decreased (1.127337 --> 1.122552).  Saving model ...
Validation loss decreased (1.122552 --> 1.117481).  Saving model ...
Validation loss decreased (1.117481 --> 1.112021).  Saving model ...
Validation loss decreased (1.112021 --> 1.107192).  Saving model ...
Validation loss decreased (1.107192 --> 1.102140).  Saving model ...
Validation loss decreased (1.102140 --> 1.096640).  Saving model ...
Validation loss decreased (1.096640 --> 1.091497).  Saving model ...
Validation loss decreased (1.091497 --> 1.085089).  Saving model ...
Validation loss decreased (1.085089 --> 1.080526).  Saving model ...
Validation loss decreased (1.080526 --> 1.077721).  Saving model ...
Validation loss decreased (1.077721 --> 1.074041).  Saving model ...
Validation loss decreased (1.074041 --> 1.068754).  Saving model ...
Validation loss decreased (1.068754 --> 1.064144).  Saving model ...
Validation loss decreased (1.064144 --> 1.061575).  Saving model ...
Validation loss decreased (1.061575 --> 1.057185).  Saving model ...
Validation loss decreased (1.057185 --> 1.052374).  Saving model ...
Validation loss decreased (1.052374 --> 1.047838).  Saving model ...
Validation loss decreased (1.047838 --> 1.043958).  Saving model ...
Validation loss decreased (1.043958 --> 1.040797).  Saving model ...
Validation loss decreased (1.040797 --> 1.037874).  Saving model ...
Validation loss decreased (1.037874 --> 1.034161).  Saving model ...
Validation loss decreased (1.034161 --> 1.028074).  Saving model ...
Validation loss decreased (1.028074 --> 1.025564).  Saving model ...
Validation loss decreased (1.025564 --> 1.024233).  Saving model ...
Validation loss decreased (1.024233 --> 1.020279).  Saving model ...
Validation loss decreased (1.020279 --> 1.016218).  Saving model ...
Validation loss decreased (1.016218 --> 1.015288).  Saving model ...
Validation loss decreased (1.015288 --> 1.012701).  Saving model ...
Validation loss decreased (1.012701 --> 1.010480).  Saving model ...
Validation loss decreased (1.010480 --> 1.008350).  Saving model ...
Validation loss decreased (1.008350 --> 1.005249).  Saving model ...
Validation loss decreased (1.005249 --> 1.002891).  Saving model ...
Validation loss decreased (1.002891 --> 1.001594).  Saving model ...
Validation loss decreased (1.001594 --> 0.997874).  Saving model ...
Validation loss decreased (0.997874 --> 0.995495).  Saving model ...
Validation loss decreased (0.995495 --> 0.993024).  Saving model ...
Validation loss decreased (0.993024 --> 0.992114).  Saving model ...
Validation loss decreased (0.992114 --> 0.989818).  Saving model ...
Validation loss decreased (0.989818 --> 0.988497).  Saving model ...
Validation loss decreased (0.988497 --> 0.984828).  Saving model ...
Validation loss decreased (0.984828 --> 0.983659).  Saving model ...
Validation loss decreased (0.983659 --> 0.980724).  Saving model ...
Validation loss decreased (0.980724 --> 0.979471).  Saving model ...
Validation loss decreased (0.979471 --> 0.978695).  Saving model ...
Validation loss decreased (0.978695 --> 0.977578).  Saving model ...
Validation loss decreased (0.977578 --> 0.974857).  Saving model ...
Validation loss decreased (0.974857 --> 0.973300).  Saving model ...
Validation loss decreased (0.973300 --> 0.971516).  Saving model ...
Validation loss decreased (0.971516 --> 0.969356).  Saving model ...
Validation loss decreased (0.969356 --> 0.968049).  Saving model ...
Validation loss decreased (0.968049 --> 0.966063).  Saving model ...
EarlyStopping counter: 1 out of 10.0
EarlyStopping counter: 2 out of 10.0
Validation loss decreased (0.966063 --> 0.964994).  Saving model ...
Validation loss decreased (0.964994 --> 0.962040).  Saving model ...
Validation loss decreased (0.962040 --> 0.960550).  Saving model ...
Validation loss decreased (0.960550 --> 0.960278).  Saving model ...
Validation loss decreased (0.960278 --> 0.958721).  Saving model ...
Validation loss decreased (0.958721 --> 0.957783).  Saving model ...
Validation loss decreased (0.957783 --> 0.957576).  Saving model ...
Validation loss decreased (0.957576 --> 0.957355).  Saving model ...
Validation loss decreased (0.957355 --> 0.955337).  Saving model ...
EarlyStopping counter: 1 out of 10.0
Validation loss decreased (0.955337 --> 0.954641).  Saving model ...
Validation loss decreased (0.954641 --> 0.953210).  Saving model ...
EarlyStopping counter: 1 out of 10.0
EarlyStopping counter: 2 out of 10.0
Validation loss decreased (0.953210 --> 0.952003).  Saving model ...
Validation loss decreased (0.952003 --> 0.951328).  Saving model ...
Validation loss decreased (0.951328 --> 0.950621).  Saving model ...
EarlyStopping counter: 1 out of 10.0
EarlyStopping counter: 2 out of 10.0
EarlyStopping counter: 3 out of 10.0
EarlyStopping counter: 4 out of 10.0
Validation loss decreased (0.950621 --> 0.949817).  Saving model ...
EarlyStopping counter: 1 out of 10.0
EarlyStopping counter: 2 out of 10.0
EarlyStopping counter: 3 out of 10.0
EarlyStopping counter: 4 out of 10.0
EarlyStopping counter: 5 out of 10.0
EarlyStopping counter: 6 out of 10.0
Validation loss decreased (0.949817 --> 0.949424).  Saving model ...
EarlyStopping counter: 1 out of 10.0
EarlyStopping counter: 2 out of 10.0
EarlyStopping counter: 3 out of 10.0
EarlyStopping counter: 4 out of 10.0
EarlyStopping counter: 5 out of 10.0
EarlyStopping counter: 6 out of 10.0
EarlyStopping counter: 7 out of 10.0
EarlyStopping counter: 8 out of 10.0
EarlyStopping counter: 9 out of 10.0
EarlyStopping counter: 10 out of 10.0
/localscratch/yinan.29019366.0/env/lib/python3.7/site-packages/torch/nn/functional.py:1794: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.
  warnings.warn("nn.functional.tanh is deprecated. Use torch.tanh instead.")
wandb: Waiting for W&B process to finish, PID 8039... (success).
wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: \ 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: | 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: / 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: \ 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: | 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: / 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: \ 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: | 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb:                                                                                
wandb: Run history:
wandb:     e_F1 ▁▁▂▃▄▄▅▅▆▆▆▇▇▇▇▇▇▇▇▇████████████████████
wandb:   e_loss █▇▇▆▆▆▆▅▅▅▄▄▄▃▃▃▃▂▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:     t_F1 ▁▁▁▂▂▃▃▄▄▄▅▅▅▅▅▆▆▆▆▆▇▆▇▆▇▇▇▇▇▇█▇████████
wandb:   t_loss ██▇▇▇▇▆▆▆▆▅▅▅▅▅▅▄▄▄▄▃▃▃▃▃▃▃▂▃▂▂▂▂▂▁▁▂▁▁▁
wandb: 
wandb: Run summary:
wandb:     e_F1 56.84282
wandb:   e_loss 0.94995
wandb:     t_F1 70.26988
wandb:   t_loss 0.77186
wandb: 
wandb: Synced 4 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Synced scarlet-pond-2: https://wandb.ai/yinanazhou/xl_512_bs_8_lr_1e06_es_10_lc_False_nr_False_sr_True_stem_True_lemma_False_repeat_1_fold_2/runs/1izox2yi
wandb: Find logs at: ./wandb/run-20220318_210616-1izox2yi/logs/debug.log
wandb: 

wandb: wandb version 0.12.11 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
2022-03-18 22:39:13.338141: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1
wandb: Tracking run with wandb version 0.12.5
wandb: Syncing run different-puddle-2
wandb: ⭐️ View project at https://wandb.ai/yinanazhou/xl_512_bs_8_lr_1e06_es_10_lc_False_nr_False_sr_True_stem_True_lemma_False_repeat_2_fold_1
wandb: 🚀 View run at https://wandb.ai/yinanazhou/xl_512_bs_8_lr_1e06_es_10_lc_False_nr_False_sr_True_stem_True_lemma_False_repeat_2_fold_1/runs/6xu9nnr7
wandb: Run data is saved locally in /project/6002780/yinan/Thesis_MER_Lyrics/lyric-emotion/wandb/run-20220318_223910-6xu9nnr7
wandb: Run `wandb offline` to turn off syncing.

Validation loss decreased (inf --> 1.415550).  Saving model ...
Validation loss decreased (1.415550 --> 1.395595).  Saving model ...
Validation loss decreased (1.395595 --> 1.380912).  Saving model ...
Validation loss decreased (1.380912 --> 1.370314).  Saving model ...
Validation loss decreased (1.370314 --> 1.362428).  Saving model ...
Validation loss decreased (1.362428 --> 1.355783).  Saving model ...
Validation loss decreased (1.355783 --> 1.349731).  Saving model ...
Validation loss decreased (1.349731 --> 1.345291).  Saving model ...
Validation loss decreased (1.345291 --> 1.339879).  Saving model ...
Validation loss decreased (1.339879 --> 1.335028).  Saving model ...
Validation loss decreased (1.335028 --> 1.330364).  Saving model ...
Validation loss decreased (1.330364 --> 1.325590).  Saving model ...
Validation loss decreased (1.325590 --> 1.320928).  Saving model ...
Validation loss decreased (1.320928 --> 1.315111).  Saving model ...
Validation loss decreased (1.315111 --> 1.309625).  Saving model ...
Validation loss decreased (1.309625 --> 1.304812).  Saving model ...
Validation loss decreased (1.304812 --> 1.299010).  Saving model ...
Validation loss decreased (1.299010 --> 1.293290).  Saving model ...
Validation loss decreased (1.293290 --> 1.287570).  Saving model ...
Validation loss decreased (1.287570 --> 1.281446).  Saving model ...
Validation loss decreased (1.281446 --> 1.275928).  Saving model ...
Validation loss decreased (1.275928 --> 1.268577).  Saving model ...
Validation loss decreased (1.268577 --> 1.260113).  Saving model ...
Validation loss decreased (1.260113 --> 1.253729).  Saving model ...
Validation loss decreased (1.253729 --> 1.247516).  Saving model ...
Validation loss decreased (1.247516 --> 1.241301).  Saving model ...
Validation loss decreased (1.241301 --> 1.233501).  Saving model ...
Validation loss decreased (1.233501 --> 1.225596).  Saving model ...
Validation loss decreased (1.225596 --> 1.218059).  Saving model ...
Validation loss decreased (1.218059 --> 1.210636).  Saving model ...
Validation loss decreased (1.210636 --> 1.202566).  Saving model ...
Validation loss decreased (1.202566 --> 1.196448).  Saving model ...
Validation loss decreased (1.196448 --> 1.189388).  Saving model ...
Validation loss decreased (1.189388 --> 1.183368).  Saving model ...
Validation loss decreased (1.183368 --> 1.176133).  Saving model ...
Validation loss decreased (1.176133 --> 1.168845).  Saving model ...
Validation loss decreased (1.168845 --> 1.162381).  Saving model ...
Validation loss decreased (1.162381 --> 1.157326).  Saving model ...
Validation loss decreased (1.157326 --> 1.150880).  Saving model ...
Validation loss decreased (1.150880 --> 1.144210).  Saving model ...
Validation loss decreased (1.144210 --> 1.138527).  Saving model ...
Validation loss decreased (1.138527 --> 1.133439).  Saving model ...
Validation loss decreased (1.133439 --> 1.128444).  Saving model ...
Validation loss decreased (1.128444 --> 1.124112).  Saving model ...
Validation loss decreased (1.124112 --> 1.118597).  Saving model ...
Validation loss decreased (1.118597 --> 1.112691).  Saving model ...
Validation loss decreased (1.112691 --> 1.108509).  Saving model ...
Validation loss decreased (1.108509 --> 1.102772).  Saving model ...
Validation loss decreased (1.102772 --> 1.096713).  Saving model ...
Validation loss decreased (1.096713 --> 1.092242).  Saving model ...
Validation loss decreased (1.092242 --> 1.087641).  Saving model ...
Validation loss decreased (1.087641 --> 1.083891).  Saving model ...
Validation loss decreased (1.083891 --> 1.078117).  Saving model ...
Validation loss decreased (1.078117 --> 1.074567).  Saving model ...
Validation loss decreased (1.074567 --> 1.070388).  Saving model ...
Validation loss decreased (1.070388 --> 1.066162).  Saving model ...
Validation loss decreased (1.066162 --> 1.062590).  Saving model ...
Validation loss decreased (1.062590 --> 1.057741).  Saving model ...
Validation loss decreased (1.057741 --> 1.055021).  Saving model ...
Validation loss decreased (1.055021 --> 1.051049).  Saving model ...
Validation loss decreased (1.051049 --> 1.046910).  Saving model ...
Validation loss decreased (1.046910 --> 1.042432).  Saving model ...
Validation loss decreased (1.042432 --> 1.038406).  Saving model ...
Validation loss decreased (1.038406 --> 1.035392).  Saving model ...
Validation loss decreased (1.035392 --> 1.032075).  Saving model ...
Validation loss decreased (1.032075 --> 1.029754).  Saving model ...
Validation loss decreased (1.029754 --> 1.026908).  Saving model ...
Validation loss decreased (1.026908 --> 1.024406).  Saving model ...
Validation loss decreased (1.024406 --> 1.021006).  Saving model ...
Validation loss decreased (1.021006 --> 1.017877).  Saving model ...
Validation loss decreased (1.017877 --> 1.014383).  Saving model ...
Validation loss decreased (1.014383 --> 1.011730).  Saving model ...
Validation loss decreased (1.011730 --> 1.009066).  Saving model ...
Validation loss decreased (1.009066 --> 1.006777).  Saving model ...
Validation loss decreased (1.006777 --> 1.005390).  Saving model ...
Validation loss decreased (1.005390 --> 1.003712).  Saving model ...
Validation loss decreased (1.003712 --> 1.000793).  Saving model ...
Validation loss decreased (1.000793 --> 0.998361).  Saving model ...
Validation loss decreased (0.998361 --> 0.997234).  Saving model ...
Validation loss decreased (0.997234 --> 0.996233).  Saving model ...
Validation loss decreased (0.996233 --> 0.993449).  Saving model ...
Validation loss decreased (0.993449 --> 0.991999).  Saving model ...
Validation loss decreased (0.991999 --> 0.989963).  Saving model ...
Validation loss decreased (0.989963 --> 0.988507).  Saving model ...
Validation loss decreased (0.988507 --> 0.986355).  Saving model ...
Validation loss decreased (0.986355 --> 0.984432).  Saving model ...
Validation loss decreased (0.984432 --> 0.982623).  Saving model ...
Validation loss decreased (0.982623 --> 0.981303).  Saving model ...
Validation loss decreased (0.981303 --> 0.980424).  Saving model ...
Validation loss decreased (0.980424 --> 0.979335).  Saving model ...
Validation loss decreased (0.979335 --> 0.976469).  Saving model ...
Validation loss decreased (0.976469 --> 0.974325).  Saving model ...
Validation loss decreased (0.974325 --> 0.972773).  Saving model ...
Validation loss decreased (0.972773 --> 0.971646).  Saving model ...
Validation loss decreased (0.971646 --> 0.970205).  Saving model ...
Validation loss decreased (0.970205 --> 0.969048).  Saving model ...
Validation loss decreased (0.969048 --> 0.967767).  Saving model ...
Validation loss decreased (0.967767 --> 0.967376).  Saving model ...
Validation loss decreased (0.967376 --> 0.966902).  Saving model ...
Validation loss decreased (0.966902 --> 0.966666).  Saving model ...
Validation loss decreased (0.966666 --> 0.965992).  Saving model ...
Validation loss decreased (0.965992 --> 0.965334).  Saving model ...
Validation loss decreased (0.965334 --> 0.964432).  Saving model ...
Validation loss decreased (0.964432 --> 0.963261).  Saving model ...
Validation loss decreased (0.963261 --> 0.963037).  Saving model ...
Validation loss decreased (0.963037 --> 0.962844).  Saving model ...
Validation loss decreased (0.962844 --> 0.962735).  Saving model ...
Validation loss decreased (0.962735 --> 0.961642).  Saving model ...
Validation loss decreased (0.961642 --> 0.960879).  Saving model ...
Validation loss decreased (0.960879 --> 0.959038).  Saving model ...
Validation loss decreased (0.959038 --> 0.958157).  Saving model ...
EarlyStopping counter: 1 out of 10.0
Validation loss decreased (0.958157 --> 0.957816).  Saving model ...
Validation loss decreased (0.957816 --> 0.957563).  Saving model ...
Validation loss decreased (0.957563 --> 0.956758).  Saving model ...
Validation loss decreased (0.956758 --> 0.955244).  Saving model ...
Validation loss decreased (0.955244 --> 0.954732).  Saving model ...
Validation loss decreased (0.954732 --> 0.954410).  Saving model ...
EarlyStopping counter: 1 out of 10.0
EarlyStopping counter: 2 out of 10.0
Validation loss decreased (0.954410 --> 0.954391).  Saving model ...
Validation loss decreased (0.954391 --> 0.953950).  Saving model ...
EarlyStopping counter: 1 out of 10.0
EarlyStopping counter: 2 out of 10.0
EarlyStopping counter: 3 out of 10.0
EarlyStopping counter: 4 out of 10.0
EarlyStopping counter: 5 out of 10.0
EarlyStopping counter: 6 out of 10.0
EarlyStopping counter: 7 out of 10.0
EarlyStopping counter: 8 out of 10.0
EarlyStopping counter: 9 out of 10.0
EarlyStopping counter: 10 out of 10.0
/localscratch/yinan.29019366.0/env/lib/python3.7/site-packages/torch/nn/functional.py:1794: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.
  warnings.warn("nn.functional.tanh is deprecated. Use torch.tanh instead.")
wandb: Waiting for W&B process to finish, PID 13013... (success).
wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: \ 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: | 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: / 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb:                                                                                
wandb: Run history:
wandb:     e_F1 ▁▂▅▅▆▆▆▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇█████████████████
wandb:   e_loss ██▇▇▇▆▆▆▅▅▅▄▄▄▃▃▃▃▂▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:     t_F1 ▁▁▃▃▃▄▄▄▄▄▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇▇▇█▇▇█▇█▇▇████
wandb:   t_loss ███▇▇▇▇▆▆▆▆▆▅▅▅▅▄▄▄▄▃▃▃▃▃▃▂▃▂▂▂▂▂▁▂▂▁▁▁▁
wandb: 
wandb: Run summary:
wandb:     e_F1 58.44619
wandb:   e_loss 0.95459
wandb:     t_F1 71.88577
wandb:   t_loss 0.75217
wandb: 
wandb: Synced 4 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Synced different-puddle-2: https://wandb.ai/yinanazhou/xl_512_bs_8_lr_1e06_es_10_lc_False_nr_False_sr_True_stem_True_lemma_False_repeat_2_fold_1/runs/6xu9nnr7
wandb: Find logs at: ./wandb/run-20220318_223910-6xu9nnr7/logs/debug.log
wandb: 

wandb: wandb version 0.12.11 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
2022-03-19 00:06:51.758185: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1
wandb: Tracking run with wandb version 0.12.5
wandb: Syncing run smooth-butterfly-2
wandb: ⭐️ View project at https://wandb.ai/yinanazhou/xl_512_bs_8_lr_1e06_es_10_lc_False_nr_False_sr_True_stem_True_lemma_False_repeat_2_fold_2
wandb: 🚀 View run at https://wandb.ai/yinanazhou/xl_512_bs_8_lr_1e06_es_10_lc_False_nr_False_sr_True_stem_True_lemma_False_repeat_2_fold_2/runs/3us89aoq
wandb: Run data is saved locally in /project/6002780/yinan/Thesis_MER_Lyrics/lyric-emotion/wandb/run-20220319_000648-3us89aoq
wandb: Run `wandb offline` to turn off syncing.

Validation loss decreased (inf --> 1.419424).  Saving model ...
Validation loss decreased (1.419424 --> 1.400337).  Saving model ...
Validation loss decreased (1.400337 --> 1.384531).  Saving model ...
Validation loss decreased (1.384531 --> 1.372100).  Saving model ...
Validation loss decreased (1.372100 --> 1.362861).  Saving model ...
Validation loss decreased (1.362861 --> 1.355738).  Saving model ...
Validation loss decreased (1.355738 --> 1.349567).  Saving model ...
Validation loss decreased (1.349567 --> 1.344084).  Saving model ...
Validation loss decreased (1.344084 --> 1.338827).  Saving model ...
Validation loss decreased (1.338827 --> 1.334094).  Saving model ...
Validation loss decreased (1.334094 --> 1.329823).  Saving model ...
Validation loss decreased (1.329823 --> 1.325136).  Saving model ...
Validation loss decreased (1.325136 --> 1.320512).  Saving model ...
Validation loss decreased (1.320512 --> 1.315685).  Saving model ...
Validation loss decreased (1.315685 --> 1.310795).  Saving model ...
Validation loss decreased (1.310795 --> 1.305878).  Saving model ...
Validation loss decreased (1.305878 --> 1.300628).  Saving model ...
Validation loss decreased (1.300628 --> 1.295262).  Saving model ...
Validation loss decreased (1.295262 --> 1.289417).  Saving model ...
Validation loss decreased (1.289417 --> 1.283522).  Saving model ...
Validation loss decreased (1.283522 --> 1.277345).  Saving model ...
Validation loss decreased (1.277345 --> 1.271328).  Saving model ...
Validation loss decreased (1.271328 --> 1.264615).  Saving model ...
Validation loss decreased (1.264615 --> 1.258403).  Saving model ...
Validation loss decreased (1.258403 --> 1.250362).  Saving model ...
Validation loss decreased (1.250362 --> 1.243428).  Saving model ...
Validation loss decreased (1.243428 --> 1.236504).  Saving model ...
Validation loss decreased (1.236504 --> 1.229621).  Saving model ...
Validation loss decreased (1.229621 --> 1.222505).  Saving model ...
Validation loss decreased (1.222505 --> 1.215023).  Saving model ...
Validation loss decreased (1.215023 --> 1.208458).  Saving model ...
Validation loss decreased (1.208458 --> 1.201214).  Saving model ...
Validation loss decreased (1.201214 --> 1.194005).  Saving model ...
Validation loss decreased (1.194005 --> 1.186730).  Saving model ...
Validation loss decreased (1.186730 --> 1.179673).  Saving model ...
Validation loss decreased (1.179673 --> 1.172338).  Saving model ...
Validation loss decreased (1.172338 --> 1.165204).  Saving model ...
Validation loss decreased (1.165204 --> 1.160034).  Saving model ...
Validation loss decreased (1.160034 --> 1.151792).  Saving model ...
Validation loss decreased (1.151792 --> 1.145223).  Saving model ...
Validation loss decreased (1.145223 --> 1.139310).  Saving model ...
Validation loss decreased (1.139310 --> 1.132156).  Saving model ...
Validation loss decreased (1.132156 --> 1.125784).  Saving model ...
Validation loss decreased (1.125784 --> 1.119696).  Saving model ...
Validation loss decreased (1.119696 --> 1.112614).  Saving model ...
Validation loss decreased (1.112614 --> 1.107151).  Saving model ...
Validation loss decreased (1.107151 --> 1.103288).  Saving model ...
Validation loss decreased (1.103288 --> 1.097825).  Saving model ...
Validation loss decreased (1.097825 --> 1.092660).  Saving model ...
Validation loss decreased (1.092660 --> 1.088509).  Saving model ...
Validation loss decreased (1.088509 --> 1.084919).  Saving model ...
Validation loss decreased (1.084919 --> 1.082398).  Saving model ...
Validation loss decreased (1.082398 --> 1.077662).  Saving model ...
Validation loss decreased (1.077662 --> 1.074281).  Saving model ...
Validation loss decreased (1.074281 --> 1.069025).  Saving model ...
Validation loss decreased (1.069025 --> 1.066099).  Saving model ...
Validation loss decreased (1.066099 --> 1.061975).  Saving model ...
Validation loss decreased (1.061975 --> 1.057911).  Saving model ...
Validation loss decreased (1.057911 --> 1.054284).  Saving model ...
Validation loss decreased (1.054284 --> 1.050051).  Saving model ...
Validation loss decreased (1.050051 --> 1.046902).  Saving model ...
Validation loss decreased (1.046902 --> 1.042107).  Saving model ...
Validation loss decreased (1.042107 --> 1.038065).  Saving model ...
Validation loss decreased (1.038065 --> 1.036052).  Saving model ...
Validation loss decreased (1.036052 --> 1.032940).  Saving model ...
Validation loss decreased (1.032940 --> 1.030201).  Saving model ...
Validation loss decreased (1.030201 --> 1.026625).  Saving model ...
Validation loss decreased (1.026625 --> 1.023746).  Saving model ...
Validation loss decreased (1.023746 --> 1.020250).  Saving model ...
Validation loss decreased (1.020250 --> 1.017993).  Saving model ...
Validation loss decreased (1.017993 --> 1.016479).  Saving model ...
Validation loss decreased (1.016479 --> 1.013754).  Saving model ...
Validation loss decreased (1.013754 --> 1.011133).  Saving model ...
Validation loss decreased (1.011133 --> 1.009818).  Saving model ...
Validation loss decreased (1.009818 --> 1.007203).  Saving model ...
Validation loss decreased (1.007203 --> 1.004702).  Saving model ...
Validation loss decreased (1.004702 --> 1.001866).  Saving model ...
Validation loss decreased (1.001866 --> 0.998898).  Saving model ...
Validation loss decreased (0.998898 --> 0.997754).  Saving model ...
Validation loss decreased (0.997754 --> 0.995404).  Saving model ...
Validation loss decreased (0.995404 --> 0.993546).  Saving model ...
Validation loss decreased (0.993546 --> 0.991997).  Saving model ...
Validation loss decreased (0.991997 --> 0.989984).  Saving model ...
Validation loss decreased (0.989984 --> 0.988232).  Saving model ...
Validation loss decreased (0.988232 --> 0.983928).  Saving model ...
Validation loss decreased (0.983928 --> 0.982325).  Saving model ...
EarlyStopping counter: 1 out of 10.0
Validation loss decreased (0.982325 --> 0.981939).  Saving model ...
Validation loss decreased (0.981939 --> 0.980311).  Saving model ...
Validation loss decreased (0.980311 --> 0.976640).  Saving model ...
Validation loss decreased (0.976640 --> 0.975303).  Saving model ...
Validation loss decreased (0.975303 --> 0.973854).  Saving model ...
Validation loss decreased (0.973854 --> 0.971702).  Saving model ...
Validation loss decreased (0.971702 --> 0.970834).  Saving model ...
Validation loss decreased (0.970834 --> 0.970547).  Saving model ...
EarlyStopping counter: 1 out of 10.0
Validation loss decreased (0.970547 --> 0.969148).  Saving model ...
Validation loss decreased (0.969148 --> 0.968301).  Saving model ...
Validation loss decreased (0.968301 --> 0.966750).  Saving model ...
Validation loss decreased (0.966750 --> 0.964615).  Saving model ...
Validation loss decreased (0.964615 --> 0.963033).  Saving model ...
Validation loss decreased (0.963033 --> 0.961904).  Saving model ...
EarlyStopping counter: 1 out of 10.0
EarlyStopping counter: 2 out of 10.0
Validation loss decreased (0.961904 --> 0.961443).  Saving model ...
Validation loss decreased (0.961443 --> 0.961269).  Saving model ...
Validation loss decreased (0.961269 --> 0.958697).  Saving model ...
Validation loss decreased (0.958697 --> 0.956781).  Saving model ...
Validation loss decreased (0.956781 --> 0.955185).  Saving model ...
Validation loss decreased (0.955185 --> 0.955060).  Saving model ...
Validation loss decreased (0.955060 --> 0.953727).  Saving model ...
Validation loss decreased (0.953727 --> 0.953534).  Saving model ...
Validation loss decreased (0.953534 --> 0.952900).  Saving model ...
Validation loss decreased (0.952900 --> 0.952294).  Saving model ...
Validation loss decreased (0.952294 --> 0.952218).  Saving model ...
EarlyStopping counter: 1 out of 10.0
EarlyStopping counter: 2 out of 10.0
EarlyStopping counter: 3 out of 10.0
Validation loss decreased (0.952218 --> 0.951251).  Saving model ...
EarlyStopping counter: 1 out of 10.0
Validation loss decreased (0.951251 --> 0.950957).  Saving model ...
Validation loss decreased (0.950957 --> 0.949580).  Saving model ...
Validation loss decreased (0.949580 --> 0.949267).  Saving model ...
Validation loss decreased (0.949267 --> 0.949125).  Saving model ...
EarlyStopping counter: 1 out of 10.0
Validation loss decreased (0.949125 --> 0.948601).  Saving model ...
EarlyStopping counter: 1 out of 10.0
EarlyStopping counter: 2 out of 10.0
EarlyStopping counter: 3 out of 10.0
EarlyStopping counter: 4 out of 10.0
EarlyStopping counter: 5 out of 10.0
EarlyStopping counter: 6 out of 10.0
Validation loss decreased (0.948601 --> 0.947346).  Saving model ...
EarlyStopping counter: 1 out of 10.0
Validation loss decreased (0.947346 --> 0.946888).  Saving model ...
Validation loss decreased (0.946888 --> 0.946527).  Saving model ...
EarlyStopping counter: 1 out of 10.0
Validation loss decreased (0.946527 --> 0.946138).  Saving model ...
EarlyStopping counter: 1 out of 10.0
EarlyStopping counter: 2 out of 10.0
EarlyStopping counter: 3 out of 10.0
EarlyStopping counter: 4 out of 10.0
EarlyStopping counter: 5 out of 10.0
EarlyStopping counter: 6 out of 10.0
EarlyStopping counter: 7 out of 10.0
EarlyStopping counter: 8 out of 10.0
EarlyStopping counter: 9 out of 10.0
EarlyStopping counter: 10 out of 10.0
/localscratch/yinan.29019366.0/env/lib/python3.7/site-packages/torch/nn/functional.py:1794: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.
  warnings.warn("nn.functional.tanh is deprecated. Use torch.tanh instead.")
wandb: Waiting for W&B process to finish, PID 17749... (success).
wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: \ 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: | 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: / 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: \ 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: | 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: / 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: \ 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: | 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: / 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb:                                                                                
wandb: Run history:
wandb:     e_F1 ▁▂▄▅▅▅▅▆▆▆▆▆▆▆▇▇▇▇▇▇▇▇▇▇▇███████████████
wandb:   e_loss ██▇▇▇▆▆▅▅▅▄▄▃▃▃▃▃▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:     t_F1 ▁▁▂▂▃▃▄▄▄▄▄▆▆▆▅▆▆▆▇▆▆▆▆▆▆▇▇▇▇▇▇▇▇█▇▇████
wandb:   t_loss ██▇▇▇▇▇▆▆▆▆▅▅▅▅▄▄▄▃▄▃▄▃▃▃▃▃▂▂▂▂▂▂▂▂▂▂▁▁▁
wandb: 
wandb: Run summary:
wandb:     e_F1 60.8957
wandb:   e_loss 0.95086
wandb:     t_F1 72.3905
wandb:   t_loss 0.72135
wandb: 
wandb: Synced 4 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Synced smooth-butterfly-2: https://wandb.ai/yinanazhou/xl_512_bs_8_lr_1e06_es_10_lc_False_nr_False_sr_True_stem_True_lemma_False_repeat_2_fold_2/runs/3us89aoq
wandb: Find logs at: ./wandb/run-20220319_000648-3us89aoq/logs/debug.log
wandb: 

wandb: wandb version 0.12.11 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
2022-03-19 01:39:50.151462: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1
wandb: Tracking run with wandb version 0.12.5
wandb: Syncing run earthy-cosmos-2
wandb: ⭐️ View project at https://wandb.ai/yinanazhou/xl_512_bs_8_lr_1e06_es_10_lc_False_nr_False_sr_True_stem_True_lemma_False_repeat_3_fold_1
wandb: 🚀 View run at https://wandb.ai/yinanazhou/xl_512_bs_8_lr_1e06_es_10_lc_False_nr_False_sr_True_stem_True_lemma_False_repeat_3_fold_1/runs/2u9n48ad
wandb: Run data is saved locally in /project/6002780/yinan/Thesis_MER_Lyrics/lyric-emotion/wandb/run-20220319_013947-2u9n48ad
wandb: Run `wandb offline` to turn off syncing.

Validation loss decreased (inf --> 1.460372).  Saving model ...
Validation loss decreased (1.460372 --> 1.431835).  Saving model ...
Validation loss decreased (1.431835 --> 1.410858).  Saving model ...
Validation loss decreased (1.410858 --> 1.397069).  Saving model ...
Validation loss decreased (1.397069 --> 1.386647).  Saving model ...
Validation loss decreased (1.386647 --> 1.379294).  Saving model ...
Validation loss decreased (1.379294 --> 1.373169).  Saving model ...
Validation loss decreased (1.373169 --> 1.368127).  Saving model ...
Validation loss decreased (1.368127 --> 1.362705).  Saving model ...
Validation loss decreased (1.362705 --> 1.357801).  Saving model ...
Validation loss decreased (1.357801 --> 1.353109).  Saving model ...
Validation loss decreased (1.353109 --> 1.347943).  Saving model ...
Validation loss decreased (1.347943 --> 1.343344).  Saving model ...
Validation loss decreased (1.343344 --> 1.338386).  Saving model ...
Validation loss decreased (1.338386 --> 1.332136).  Saving model ...
Validation loss decreased (1.332136 --> 1.325829).  Saving model ...
Validation loss decreased (1.325829 --> 1.320868).  Saving model ...
Validation loss decreased (1.320868 --> 1.315141).  Saving model ...
Validation loss decreased (1.315141 --> 1.308361).  Saving model ...
Validation loss decreased (1.308361 --> 1.300840).  Saving model ...
Validation loss decreased (1.300840 --> 1.293661).  Saving model ...
Validation loss decreased (1.293661 --> 1.285603).  Saving model ...
Validation loss decreased (1.285603 --> 1.277856).  Saving model ...
Validation loss decreased (1.277856 --> 1.270718).  Saving model ...
Validation loss decreased (1.270718 --> 1.262483).  Saving model ...
Validation loss decreased (1.262483 --> 1.254170).  Saving model ...
Validation loss decreased (1.254170 --> 1.246005).  Saving model ...
Validation loss decreased (1.246005 --> 1.238050).  Saving model ...
Validation loss decreased (1.238050 --> 1.230818).  Saving model ...
Validation loss decreased (1.230818 --> 1.222353).  Saving model ...
Validation loss decreased (1.222353 --> 1.216439).  Saving model ...
Validation loss decreased (1.216439 --> 1.209371).  Saving model ...
Validation loss decreased (1.209371 --> 1.202155).  Saving model ...
Validation loss decreased (1.202155 --> 1.194984).  Saving model ...
Validation loss decreased (1.194984 --> 1.189384).  Saving model ...
Validation loss decreased (1.189384 --> 1.182424).  Saving model ...
Validation loss decreased (1.182424 --> 1.176106).  Saving model ...
Validation loss decreased (1.176106 --> 1.170618).  Saving model ...
Validation loss decreased (1.170618 --> 1.164099).  Saving model ...
Validation loss decreased (1.164099 --> 1.159438).  Saving model ...
Validation loss decreased (1.159438 --> 1.153355).  Saving model ...
Validation loss decreased (1.153355 --> 1.147525).  Saving model ...
Validation loss decreased (1.147525 --> 1.143151).  Saving model ...
Validation loss decreased (1.143151 --> 1.137523).  Saving model ...
Validation loss decreased (1.137523 --> 1.129863).  Saving model ...
Validation loss decreased (1.129863 --> 1.125913).  Saving model ...
Validation loss decreased (1.125913 --> 1.119959).  Saving model ...
Validation loss decreased (1.119959 --> 1.116680).  Saving model ...
Validation loss decreased (1.116680 --> 1.111622).  Saving model ...
Validation loss decreased (1.111622 --> 1.107607).  Saving model ...
Validation loss decreased (1.107607 --> 1.105851).  Saving model ...
Validation loss decreased (1.105851 --> 1.100973).  Saving model ...
Validation loss decreased (1.100973 --> 1.096726).  Saving model ...
Validation loss decreased (1.096726 --> 1.091516).  Saving model ...
Validation loss decreased (1.091516 --> 1.085658).  Saving model ...
Validation loss decreased (1.085658 --> 1.080885).  Saving model ...
Validation loss decreased (1.080885 --> 1.077133).  Saving model ...
Validation loss decreased (1.077133 --> 1.073936).  Saving model ...
Validation loss decreased (1.073936 --> 1.070101).  Saving model ...
Validation loss decreased (1.070101 --> 1.066027).  Saving model ...
Validation loss decreased (1.066027 --> 1.064824).  Saving model ...
Validation loss decreased (1.064824 --> 1.062585).  Saving model ...
Validation loss decreased (1.062585 --> 1.059554).  Saving model ...
Validation loss decreased (1.059554 --> 1.055419).  Saving model ...
Validation loss decreased (1.055419 --> 1.048281).  Saving model ...
Validation loss decreased (1.048281 --> 1.043820).  Saving model ...
Validation loss decreased (1.043820 --> 1.042647).  Saving model ...
Validation loss decreased (1.042647 --> 1.040034).  Saving model ...
Validation loss decreased (1.040034 --> 1.035729).  Saving model ...
EarlyStopping counter: 1 out of 10.0
Validation loss decreased (1.035729 --> 1.032146).  Saving model ...
Validation loss decreased (1.032146 --> 1.030884).  Saving model ...
Validation loss decreased (1.030884 --> 1.024329).  Saving model ...
Validation loss decreased (1.024329 --> 1.021464).  Saving model ...
Validation loss decreased (1.021464 --> 1.020632).  Saving model ...
Validation loss decreased (1.020632 --> 1.019267).  Saving model ...
Validation loss decreased (1.019267 --> 1.015172).  Saving model ...
Validation loss decreased (1.015172 --> 1.014967).  Saving model ...
Validation loss decreased (1.014967 --> 1.011450).  Saving model ...
Validation loss decreased (1.011450 --> 1.009310).  Saving model ...
Validation loss decreased (1.009310 --> 1.007675).  Saving model ...
EarlyStopping counter: 1 out of 10.0
Validation loss decreased (1.007675 --> 1.006905).  Saving model ...
Validation loss decreased (1.006905 --> 1.005037).  Saving model ...
Validation loss decreased (1.005037 --> 1.002728).  Saving model ...
EarlyStopping counter: 1 out of 10.0
Validation loss decreased (1.002728 --> 1.002429).  Saving model ...
Validation loss decreased (1.002429 --> 0.996741).  Saving model ...
Validation loss decreased (0.996741 --> 0.996361).  Saving model ...
Validation loss decreased (0.996361 --> 0.993988).  Saving model ...
EarlyStopping counter: 1 out of 10.0
Validation loss decreased (0.993988 --> 0.991847).  Saving model ...
Validation loss decreased (0.991847 --> 0.991165).  Saving model ...
Validation loss decreased (0.991165 --> 0.989647).  Saving model ...
Validation loss decreased (0.989647 --> 0.987990).  Saving model ...
Validation loss decreased (0.987990 --> 0.982599).  Saving model ...
Validation loss decreased (0.982599 --> 0.980222).  Saving model ...
Validation loss decreased (0.980222 --> 0.979886).  Saving model ...
EarlyStopping counter: 1 out of 10.0
Validation loss decreased (0.979886 --> 0.978528).  Saving model ...
Validation loss decreased (0.978528 --> 0.977271).  Saving model ...
Validation loss decreased (0.977271 --> 0.975891).  Saving model ...
EarlyStopping counter: 1 out of 10.0
EarlyStopping counter: 2 out of 10.0
EarlyStopping counter: 3 out of 10.0
Validation loss decreased (0.975891 --> 0.975653).  Saving model ...
Validation loss decreased (0.975653 --> 0.975152).  Saving model ...
Validation loss decreased (0.975152 --> 0.973740).  Saving model ...
Validation loss decreased (0.973740 --> 0.973417).  Saving model ...
Validation loss decreased (0.973417 --> 0.968818).  Saving model ...
EarlyStopping counter: 1 out of 10.0
EarlyStopping counter: 2 out of 10.0
Validation loss decreased (0.968818 --> 0.968660).  Saving model ...
EarlyStopping counter: 1 out of 10.0
EarlyStopping counter: 2 out of 10.0
EarlyStopping counter: 3 out of 10.0
EarlyStopping counter: 4 out of 10.0
EarlyStopping counter: 5 out of 10.0
EarlyStopping counter: 6 out of 10.0
EarlyStopping counter: 7 out of 10.0
EarlyStopping counter: 8 out of 10.0
EarlyStopping counter: 9 out of 10.0
EarlyStopping counter: 10 out of 10.0
/localscratch/yinan.29019366.0/env/lib/python3.7/site-packages/torch/nn/functional.py:1794: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.
  warnings.warn("nn.functional.tanh is deprecated. Use torch.tanh instead.")
wandb: Waiting for W&B process to finish, PID 22774... (success).
wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: \ 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: | 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: / 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: \ 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: | 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: / 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: \ 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: | 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: / 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb:                                                                                
wandb: Run history:
wandb:     e_F1 ▁▁▃▄▄▅▆▆▆▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇████████████████
wandb:   e_loss █▇▇▇▆▆▆▆▅▅▄▄▄▄▃▃▃▃▃▂▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:     t_F1 ▁▂▃▄▃▄▄▄▅▅▅▅▅▅▅▆▆▆▆▆▆▇▆▆▇▆▆▇▇▇▇▇▇▇▇▇▇█▇█
wandb:   t_loss ██▇▇▇▇▇▆▆▆▆▅▅▅▅▅▄▄▄▄▃▃▃▃▃▃▃▃▂▂▂▂▂▂▂▂▁▁▁▁
wandb: 
wandb: Run summary:
wandb:     e_F1 58.91057
wandb:   e_loss 0.96986
wandb:     t_F1 70.07459
wandb:   t_loss 0.78742
wandb: 
wandb: Synced 4 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Synced earthy-cosmos-2: https://wandb.ai/yinanazhou/xl_512_bs_8_lr_1e06_es_10_lc_False_nr_False_sr_True_stem_True_lemma_False_repeat_3_fold_1/runs/2u9n48ad
wandb: Find logs at: ./wandb/run-20220319_013947-2u9n48ad/logs/debug.log
wandb: 

wandb: wandb version 0.12.11 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
2022-03-19 02:59:09.185624: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1
wandb: Tracking run with wandb version 0.12.5
wandb: Syncing run dashing-leaf-2
wandb: ⭐️ View project at https://wandb.ai/yinanazhou/xl_512_bs_8_lr_1e06_es_10_lc_False_nr_False_sr_True_stem_True_lemma_False_repeat_3_fold_2
wandb: 🚀 View run at https://wandb.ai/yinanazhou/xl_512_bs_8_lr_1e06_es_10_lc_False_nr_False_sr_True_stem_True_lemma_False_repeat_3_fold_2/runs/2ck5abfo
wandb: Run data is saved locally in /project/6002780/yinan/Thesis_MER_Lyrics/lyric-emotion/wandb/run-20220319_025906-2ck5abfo
wandb: Run `wandb offline` to turn off syncing.

Validation loss decreased (inf --> 1.413765).  Saving model ...
Validation loss decreased (1.413765 --> 1.396184).  Saving model ...
Validation loss decreased (1.396184 --> 1.382936).  Saving model ...
Validation loss decreased (1.382936 --> 1.373413).  Saving model ...
Validation loss decreased (1.373413 --> 1.366008).  Saving model ...
Validation loss decreased (1.366008 --> 1.359979).  Saving model ...
Validation loss decreased (1.359979 --> 1.354327).  Saving model ...
Validation loss decreased (1.354327 --> 1.349167).  Saving model ...
Validation loss decreased (1.349167 --> 1.344437).  Saving model ...
Validation loss decreased (1.344437 --> 1.340015).  Saving model ...
Validation loss decreased (1.340015 --> 1.334850).  Saving model ...
Validation loss decreased (1.334850 --> 1.329881).  Saving model ...
Validation loss decreased (1.329881 --> 1.324993).  Saving model ...
Validation loss decreased (1.324993 --> 1.319787).  Saving model ...
Validation loss decreased (1.319787 --> 1.314660).  Saving model ...
Validation loss decreased (1.314660 --> 1.309595).  Saving model ...
Validation loss decreased (1.309595 --> 1.304237).  Saving model ...
Validation loss decreased (1.304237 --> 1.298921).  Saving model ...
Validation loss decreased (1.298921 --> 1.292657).  Saving model ...
Validation loss decreased (1.292657 --> 1.287168).  Saving model ...
Validation loss decreased (1.287168 --> 1.281424).  Saving model ...
Validation loss decreased (1.281424 --> 1.274373).  Saving model ...
Validation loss decreased (1.274373 --> 1.267085).  Saving model ...
Validation loss decreased (1.267085 --> 1.260129).  Saving model ...
Validation loss decreased (1.260129 --> 1.252449).  Saving model ...
Validation loss decreased (1.252449 --> 1.245791).  Saving model ...
Validation loss decreased (1.245791 --> 1.237647).  Saving model ...
Validation loss decreased (1.237647 --> 1.230805).  Saving model ...
Validation loss decreased (1.230805 --> 1.221678).  Saving model ...
Validation loss decreased (1.221678 --> 1.213288).  Saving model ...
Validation loss decreased (1.213288 --> 1.204383).  Saving model ...
Validation loss decreased (1.204383 --> 1.196686).  Saving model ...
Validation loss decreased (1.196686 --> 1.188656).  Saving model ...
Validation loss decreased (1.188656 --> 1.180699).  Saving model ...
Validation loss decreased (1.180699 --> 1.173064).  Saving model ...
Validation loss decreased (1.173064 --> 1.166918).  Saving model ...
Validation loss decreased (1.166918 --> 1.159125).  Saving model ...
Validation loss decreased (1.159125 --> 1.150411).  Saving model ...
Validation loss decreased (1.150411 --> 1.144410).  Saving model ...
Validation loss decreased (1.144410 --> 1.137198).  Saving model ...
Validation loss decreased (1.137198 --> 1.130376).  Saving model ...
Validation loss decreased (1.130376 --> 1.124144).  Saving model ...
Validation loss decreased (1.124144 --> 1.117704).  Saving model ...
Validation loss decreased (1.117704 --> 1.111836).  Saving model ...
Validation loss decreased (1.111836 --> 1.106552).  Saving model ...
Validation loss decreased (1.106552 --> 1.101658).  Saving model ...
Validation loss decreased (1.101658 --> 1.096927).  Saving model ...
Validation loss decreased (1.096927 --> 1.091127).  Saving model ...
Validation loss decreased (1.091127 --> 1.085257).  Saving model ...
Validation loss decreased (1.085257 --> 1.080416).  Saving model ...
Validation loss decreased (1.080416 --> 1.074405).  Saving model ...
Validation loss decreased (1.074405 --> 1.070337).  Saving model ...
Validation loss decreased (1.070337 --> 1.066556).  Saving model ...
Validation loss decreased (1.066556 --> 1.061991).  Saving model ...
Validation loss decreased (1.061991 --> 1.057794).  Saving model ...
Validation loss decreased (1.057794 --> 1.054314).  Saving model ...
Validation loss decreased (1.054314 --> 1.050174).  Saving model ...
Validation loss decreased (1.050174 --> 1.045420).  Saving model ...
Validation loss decreased (1.045420 --> 1.040618).  Saving model ...
Validation loss decreased (1.040618 --> 1.037610).  Saving model ...
Validation loss decreased (1.037610 --> 1.033982).  Saving model ...
Validation loss decreased (1.033982 --> 1.031374).  Saving model ...
Validation loss decreased (1.031374 --> 1.025677).  Saving model ...
Validation loss decreased (1.025677 --> 1.022822).  Saving model ...
Validation loss decreased (1.022822 --> 1.017917).  Saving model ...
Validation loss decreased (1.017917 --> 1.013254).  Saving model ...
Validation loss decreased (1.013254 --> 1.012280).  Saving model ...
Validation loss decreased (1.012280 --> 1.009450).  Saving model ...
Validation loss decreased (1.009450 --> 1.005813).  Saving model ...
Validation loss decreased (1.005813 --> 1.001322).  Saving model ...
Validation loss decreased (1.001322 --> 1.000238).  Saving model ...
Validation loss decreased (1.000238 --> 0.995104).  Saving model ...
Validation loss decreased (0.995104 --> 0.991438).  Saving model ...
Validation loss decreased (0.991438 --> 0.988446).  Saving model ...
Validation loss decreased (0.988446 --> 0.985482).  Saving model ...
Validation loss decreased (0.985482 --> 0.984081).  Saving model ...
Validation loss decreased (0.984081 --> 0.980282).  Saving model ...
Validation loss decreased (0.980282 --> 0.977749).  Saving model ...
Validation loss decreased (0.977749 --> 0.972422).  Saving model ...
Validation loss decreased (0.972422 --> 0.971329).  Saving model ...
Validation loss decreased (0.971329 --> 0.969995).  Saving model ...
Validation loss decreased (0.969995 --> 0.968854).  Saving model ...
Validation loss decreased (0.968854 --> 0.967999).  Saving model ...
Validation loss decreased (0.967999 --> 0.963352).  Saving model ...
Validation loss decreased (0.963352 --> 0.961169).  Saving model ...
Validation loss decreased (0.961169 --> 0.958949).  Saving model ...
Validation loss decreased (0.958949 --> 0.957965).  Saving model ...
Validation loss decreased (0.957965 --> 0.956855).  Saving model ...
Validation loss decreased (0.956855 --> 0.954517).  Saving model ...
Validation loss decreased (0.954517 --> 0.951769).  Saving model ...
Validation loss decreased (0.951769 --> 0.949644).  Saving model ...
Validation loss decreased (0.949644 --> 0.947928).  Saving model ...
Validation loss decreased (0.947928 --> 0.947668).  Saving model ...
Validation loss decreased (0.947668 --> 0.947411).  Saving model ...
Validation loss decreased (0.947411 --> 0.945212).  Saving model ...
Validation loss decreased (0.945212 --> 0.941910).  Saving model ...
Validation loss decreased (0.941910 --> 0.941844).  Saving model ...
Validation loss decreased (0.941844 --> 0.941167).  Saving model ...
Validation loss decreased (0.941167 --> 0.937747).  Saving model ...
Validation loss decreased (0.937747 --> 0.936376).  Saving model ...
Validation loss decreased (0.936376 --> 0.934849).  Saving model ...
Validation loss decreased (0.934849 --> 0.932408).  Saving model ...
Validation loss decreased (0.932408 --> 0.931522).  Saving model ...
Validation loss decreased (0.931522 --> 0.931429).  Saving model ...
Validation loss decreased (0.931429 --> 0.930444).  Saving model ...
EarlyStopping counter: 1 out of 10.0
Validation loss decreased (0.930444 --> 0.929815).  Saving model ...
Validation loss decreased (0.929815 --> 0.928041).  Saving model ...
Validation loss decreased (0.928041 --> 0.927656).  Saving model ...
EarlyStopping counter: 1 out of 10.0
Validation loss decreased (0.927656 --> 0.925062).  Saving model ...
Validation loss decreased (0.925062 --> 0.924731).  Saving model ...
Validation loss decreased (0.924731 --> 0.923879).  Saving model ...
Validation loss decreased (0.923879 --> 0.921305).  Saving model ...
Validation loss decreased (0.921305 --> 0.919012).  Saving model ...
EarlyStopping counter: 1 out of 10.0
EarlyStopping counter: 2 out of 10.0
EarlyStopping counter: 3 out of 10.0
EarlyStopping counter: 4 out of 10.0
EarlyStopping counter: 5 out of 10.0
Validation loss decreased (0.919012 --> 0.918354).  Saving model ...
EarlyStopping counter: 1 out of 10.0
Validation loss decreased (0.918354 --> 0.915661).  Saving model ...
EarlyStopping counter: 1 out of 10.0
EarlyStopping counter: 2 out of 10.0
Validation loss decreased (0.915661 --> 0.915309).  Saving model ...
Validation loss decreased (0.915309 --> 0.914581).  Saving model ...
EarlyStopping counter: 1 out of 10.0
Validation loss decreased (0.914581 --> 0.913959).  Saving model ...
Validation loss decreased (0.913959 --> 0.913704).  Saving model ...
EarlyStopping counter: 1 out of 10.0
EarlyStopping counter: 2 out of 10.0
Validation loss decreased (0.913704 --> 0.913258).  Saving model ...
EarlyStopping counter: 1 out of 10.0
Validation loss decreased (0.913258 --> 0.912588).  Saving model ...
Validation loss decreased (0.912588 --> 0.912316).  Saving model ...
Validation loss decreased (0.912316 --> 0.910620).  Saving model ...
Validation loss decreased (0.910620 --> 0.910244).  Saving model ...
Validation loss decreased (0.910244 --> 0.909596).  Saving model ...
EarlyStopping counter: 1 out of 10.0
EarlyStopping counter: 2 out of 10.0
Validation loss decreased (0.909596 --> 0.909348).  Saving model ...
Validation loss decreased (0.909348 --> 0.909208).  Saving model ...
Validation loss decreased (0.909208 --> 0.908735).  Saving model ...
EarlyStopping counter: 1 out of 10.0
EarlyStopping counter: 2 out of 10.0
EarlyStopping counter: 3 out of 10.0
EarlyStopping counter: 4 out of 10.0
Validation loss decreased (0.908735 --> 0.908587).  Saving model ...
Validation loss decreased (0.908587 --> 0.907776).  Saving model ...
EarlyStopping counter: 1 out of 10.0
EarlyStopping counter: 2 out of 10.0
EarlyStopping counter: 3 out of 10.0
EarlyStopping counter: 4 out of 10.0
EarlyStopping counter: 5 out of 10.0
EarlyStopping counter: 6 out of 10.0
EarlyStopping counter: 7 out of 10.0
EarlyStopping counter: 8 out of 10.0
EarlyStopping counter: 9 out of 10.0
EarlyStopping counter: 10 out of 10.0
/localscratch/yinan.29019366.0/env/lib/python3.7/site-packages/torch/nn/functional.py:1794: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.
  warnings.warn("nn.functional.tanh is deprecated. Use torch.tanh instead.")
wandb: Waiting for W&B process to finish, PID 27056... (success).
wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: \ 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: | 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: / 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: \ 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: | 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: / 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: \ 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: | 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: / 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb:                                                                                
wandb: Run history:
wandb:     e_F1 ▁▃▅▆▆▆▆▆▆▇▇▇▇▇▇▇▇███████████████████████
wandb:   e_loss █▇▇▇▇▆▆▅▅▄▄▄▃▃▃▃▃▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:     t_F1 ▁▁▂▂▃▄▃▄▅▅▄▅▅▆▆▆▆▆▇▇▆▇▆▇▆▇▇▇▇▇▇▇▇███████
wandb:   t_loss ███▇▇▇▇▇▆▆▆▆▅▅▅▄▄▄▄▄▄▃▃▃▃▃▃▃▂▂▂▂▂▂▂▂▂▁▁▁
wandb: 
wandb: Run summary:
wandb:     e_F1 61.39436
wandb:   e_loss 0.90917
wandb:     t_F1 73.60901
wandb:   t_loss 0.69073
wandb: 
wandb: Synced 4 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Synced dashing-leaf-2: https://wandb.ai/yinanazhou/xl_512_bs_8_lr_1e06_es_10_lc_False_nr_False_sr_True_stem_True_lemma_False_repeat_3_fold_2/runs/2ck5abfo
wandb: Find logs at: ./wandb/run-20220319_025906-2ck5abfo/logs/debug.log
wandb: 

wandb: wandb version 0.12.11 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
2022-03-19 04:39:31.884156: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1
wandb: Tracking run with wandb version 0.12.5
wandb: Syncing run morning-river-2
wandb: ⭐️ View project at https://wandb.ai/yinanazhou/xl_512_bs_8_lr_1e06_es_10_lc_False_nr_False_sr_True_stem_True_lemma_False_repeat_4_fold_1
wandb: 🚀 View run at https://wandb.ai/yinanazhou/xl_512_bs_8_lr_1e06_es_10_lc_False_nr_False_sr_True_stem_True_lemma_False_repeat_4_fold_1/runs/22bkj6pt
wandb: Run data is saved locally in /project/6002780/yinan/Thesis_MER_Lyrics/lyric-emotion/wandb/run-20220319_043929-22bkj6pt
wandb: Run `wandb offline` to turn off syncing.

Validation loss decreased (inf --> 1.399255).  Saving model ...
Validation loss decreased (1.399255 --> 1.393936).  Saving model ...
Validation loss decreased (1.393936 --> 1.389436).  Saving model ...
Validation loss decreased (1.389436 --> 1.385433).  Saving model ...
Validation loss decreased (1.385433 --> 1.381734).  Saving model ...
Validation loss decreased (1.381734 --> 1.378129).  Saving model ...
Validation loss decreased (1.378129 --> 1.374884).  Saving model ...
Validation loss decreased (1.374884 --> 1.371182).  Saving model ...
Validation loss decreased (1.371182 --> 1.367671).  Saving model ...
Validation loss decreased (1.367671 --> 1.364712).  Saving model ...
Validation loss decreased (1.364712 --> 1.361323).  Saving model ...
Validation loss decreased (1.361323 --> 1.357844).  Saving model ...
Validation loss decreased (1.357844 --> 1.353830).  Saving model ...
Validation loss decreased (1.353830 --> 1.350074).  Saving model ...
Validation loss decreased (1.350074 --> 1.346091).  Saving model ...
Validation loss decreased (1.346091 --> 1.342355).  Saving model ...
Validation loss decreased (1.342355 --> 1.337753).  Saving model ...
Validation loss decreased (1.337753 --> 1.333203).  Saving model ...
Validation loss decreased (1.333203 --> 1.328395).  Saving model ...
Validation loss decreased (1.328395 --> 1.323209).  Saving model ...
Validation loss decreased (1.323209 --> 1.318243).  Saving model ...
Validation loss decreased (1.318243 --> 1.313162).  Saving model ...
Validation loss decreased (1.313162 --> 1.306868).  Saving model ...
Validation loss decreased (1.306868 --> 1.299638).  Saving model ...
Validation loss decreased (1.299638 --> 1.293025).  Saving model ...
Validation loss decreased (1.293025 --> 1.286159).  Saving model ...
Validation loss decreased (1.286159 --> 1.278585).  Saving model ...
Validation loss decreased (1.278585 --> 1.271471).  Saving model ...
Validation loss decreased (1.271471 --> 1.264357).  Saving model ...
Validation loss decreased (1.264357 --> 1.256218).  Saving model ...
Validation loss decreased (1.256218 --> 1.248097).  Saving model ...
Validation loss decreased (1.248097 --> 1.239392).  Saving model ...
Validation loss decreased (1.239392 --> 1.231250).  Saving model ...
Validation loss decreased (1.231250 --> 1.223565).  Saving model ...
Validation loss decreased (1.223565 --> 1.216324).  Saving model ...
Validation loss decreased (1.216324 --> 1.209382).  Saving model ...
Validation loss decreased (1.209382 --> 1.203441).  Saving model ...
Validation loss decreased (1.203441 --> 1.196919).  Saving model ...
Validation loss decreased (1.196919 --> 1.191254).  Saving model ...
Validation loss decreased (1.191254 --> 1.184470).  Saving model ...
Validation loss decreased (1.184470 --> 1.178758).  Saving model ...
Validation loss decreased (1.178758 --> 1.172725).  Saving model ...
Validation loss decreased (1.172725 --> 1.167438).  Saving model ...
Validation loss decreased (1.167438 --> 1.162377).  Saving model ...
Validation loss decreased (1.162377 --> 1.157214).  Saving model ...
Validation loss decreased (1.157214 --> 1.151496).  Saving model ...
Validation loss decreased (1.151496 --> 1.146264).  Saving model ...
Validation loss decreased (1.146264 --> 1.142005).  Saving model ...
Validation loss decreased (1.142005 --> 1.138082).  Saving model ...
Validation loss decreased (1.138082 --> 1.134505).  Saving model ...
Validation loss decreased (1.134505 --> 1.129790).  Saving model ...
Validation loss decreased (1.129790 --> 1.125013).  Saving model ...
Validation loss decreased (1.125013 --> 1.121495).  Saving model ...
Validation loss decreased (1.121495 --> 1.116121).  Saving model ...
Validation loss decreased (1.116121 --> 1.113624).  Saving model ...
Validation loss decreased (1.113624 --> 1.109387).  Saving model ...
Validation loss decreased (1.109387 --> 1.104663).  Saving model ...
Validation loss decreased (1.104663 --> 1.101157).  Saving model ...
Validation loss decreased (1.101157 --> 1.097718).  Saving model ...
Validation loss decreased (1.097718 --> 1.094140).  Saving model ...
Validation loss decreased (1.094140 --> 1.090119).  Saving model ...
Validation loss decreased (1.090119 --> 1.086864).  Saving model ...
Validation loss decreased (1.086864 --> 1.084109).  Saving model ...
Validation loss decreased (1.084109 --> 1.081022).  Saving model ...
Validation loss decreased (1.081022 --> 1.079477).  Saving model ...
Validation loss decreased (1.079477 --> 1.076968).  Saving model ...
Validation loss decreased (1.076968 --> 1.073799).  Saving model ...
Validation loss decreased (1.073799 --> 1.071620).  Saving model ...
Validation loss decreased (1.071620 --> 1.068287).  Saving model ...
Validation loss decreased (1.068287 --> 1.065410).  Saving model ...
Validation loss decreased (1.065410 --> 1.062427).  Saving model ...
Validation loss decreased (1.062427 --> 1.061124).  Saving model ...
Validation loss decreased (1.061124 --> 1.058315).  Saving model ...
Validation loss decreased (1.058315 --> 1.056281).  Saving model ...
Validation loss decreased (1.056281 --> 1.054203).  Saving model ...
Validation loss decreased (1.054203 --> 1.051912).  Saving model ...
Validation loss decreased (1.051912 --> 1.049740).  Saving model ...
Validation loss decreased (1.049740 --> 1.046410).  Saving model ...
Validation loss decreased (1.046410 --> 1.046202).  Saving model ...
Validation loss decreased (1.046202 --> 1.045484).  Saving model ...
Validation loss decreased (1.045484 --> 1.044495).  Saving model ...
Validation loss decreased (1.044495 --> 1.040941).  Saving model ...
Validation loss decreased (1.040941 --> 1.036619).  Saving model ...
Validation loss decreased (1.036619 --> 1.035786).  Saving model ...
Validation loss decreased (1.035786 --> 1.032895).  Saving model ...
Validation loss decreased (1.032895 --> 1.031499).  Saving model ...
Validation loss decreased (1.031499 --> 1.031427).  Saving model ...
Validation loss decreased (1.031427 --> 1.028020).  Saving model ...
Validation loss decreased (1.028020 --> 1.025189).  Saving model ...
EarlyStopping counter: 1 out of 10.0
Validation loss decreased (1.025189 --> 1.024868).  Saving model ...
EarlyStopping counter: 1 out of 10.0
Validation loss decreased (1.024868 --> 1.021589).  Saving model ...
Validation loss decreased (1.021589 --> 1.019839).  Saving model ...
EarlyStopping counter: 1 out of 10.0
EarlyStopping counter: 2 out of 10.0
Validation loss decreased (1.019839 --> 1.017692).  Saving model ...
Validation loss decreased (1.017692 --> 1.015369).  Saving model ...
Validation loss decreased (1.015369 --> 1.013583).  Saving model ...
EarlyStopping counter: 1 out of 10.0
EarlyStopping counter: 2 out of 10.0
Validation loss decreased (1.013583 --> 1.012397).  Saving model ...
Validation loss decreased (1.012397 --> 1.011126).  Saving model ...
Validation loss decreased (1.011126 --> 1.011113).  Saving model ...
EarlyStopping counter: 1 out of 10.0
EarlyStopping counter: 2 out of 10.0
Validation loss decreased (1.011113 --> 1.009120).  Saving model ...
EarlyStopping counter: 1 out of 10.0
EarlyStopping counter: 2 out of 10.0
Validation loss decreased (1.009120 --> 1.007200).  Saving model ...
Validation loss decreased (1.007200 --> 1.004212).  Saving model ...
Validation loss decreased (1.004212 --> 1.003976).  Saving model ...
EarlyStopping counter: 1 out of 10.0
EarlyStopping counter: 2 out of 10.0
EarlyStopping counter: 3 out of 10.0
EarlyStopping counter: 4 out of 10.0
EarlyStopping counter: 5 out of 10.0
Validation loss decreased (1.003976 --> 1.002821).  Saving model ...
Validation loss decreased (1.002821 --> 1.002067).  Saving model ...
EarlyStopping counter: 1 out of 10.0
Validation loss decreased (1.002067 --> 1.001972).  Saving model ...
EarlyStopping counter: 1 out of 10.0
EarlyStopping counter: 2 out of 10.0
EarlyStopping counter: 3 out of 10.0
Validation loss decreased (1.001972 --> 1.001763).  Saving model ...
EarlyStopping counter: 1 out of 10.0
EarlyStopping counter: 2 out of 10.0
EarlyStopping counter: 3 out of 10.0
EarlyStopping counter: 4 out of 10.0
EarlyStopping counter: 5 out of 10.0
EarlyStopping counter: 6 out of 10.0
EarlyStopping counter: 7 out of 10.0
EarlyStopping counter: 8 out of 10.0
EarlyStopping counter: 9 out of 10.0
EarlyStopping counter: 10 out of 10.0
/localscratch/yinan.29019366.0/env/lib/python3.7/site-packages/torch/nn/functional.py:1794: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.
  warnings.warn("nn.functional.tanh is deprecated. Use torch.tanh instead.")
wandb: Waiting for W&B process to finish, PID 32684... (success).
wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: \ 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: | 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: / 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: \ 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: | 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: / 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: \ 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: | 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: / 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb:                                                                                
wandb: Run history:
wandb:     e_F1 ▁▂▂▃▃▃▄▄▅▆▆▆▆▆▆▇▇▇▇█████████████████████
wandb:   e_loss ███▇▇▇▇▆▆▅▅▄▄▄▃▃▃▃▃▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:     t_F1 ▁▂▃▂▃▃▃▃▄▅▅▅▅▆▆▆▅▆▆▆▆▆▇▇▆▇▇▇▇▇▇▇▇▇█▇████
wandb:   t_loss ██▇█▇▇▇▇▇▆▆▆▅▅▅▅▅▄▄▄▃▄▃▃▃▃▃▂▂▂▂▂▂▂▁▂▁▁▁▁
wandb: 
wandb: Run summary:
wandb:     e_F1 55.62385
wandb:   e_loss 1.00691
wandb:     t_F1 68.52416
wandb:   t_loss 0.76796
wandb: 
wandb: Synced 4 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Synced morning-river-2: https://wandb.ai/yinanazhou/xl_512_bs_8_lr_1e06_es_10_lc_False_nr_False_sr_True_stem_True_lemma_False_repeat_4_fold_1/runs/22bkj6pt
wandb: Find logs at: ./wandb/run-20220319_043929-22bkj6pt/logs/debug.log
wandb: 

wandb: wandb version 0.12.11 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
2022-03-19 06:07:16.065150: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1
wandb: Tracking run with wandb version 0.12.5
wandb: Syncing run astral-planet-2
wandb: ⭐️ View project at https://wandb.ai/yinanazhou/xl_512_bs_8_lr_1e06_es_10_lc_False_nr_False_sr_True_stem_True_lemma_False_repeat_4_fold_2
wandb: 🚀 View run at https://wandb.ai/yinanazhou/xl_512_bs_8_lr_1e06_es_10_lc_False_nr_False_sr_True_stem_True_lemma_False_repeat_4_fold_2/runs/1shxf2sq
wandb: Run data is saved locally in /project/6002780/yinan/Thesis_MER_Lyrics/lyric-emotion/wandb/run-20220319_060713-1shxf2sq
wandb: Run `wandb offline` to turn off syncing.

Validation loss decreased (inf --> 1.610247).  Saving model ...
Validation loss decreased (1.610247 --> 1.530383).  Saving model ...
Validation loss decreased (1.530383 --> 1.472783).  Saving model ...
Validation loss decreased (1.472783 --> 1.435553).  Saving model ...
Validation loss decreased (1.435553 --> 1.409932).  Saving model ...
Validation loss decreased (1.409932 --> 1.393766).  Saving model ...
Validation loss decreased (1.393766 --> 1.381844).  Saving model ...
Validation loss decreased (1.381844 --> 1.372854).  Saving model ...
Validation loss decreased (1.372854 --> 1.365613).  Saving model ...
Validation loss decreased (1.365613 --> 1.358934).  Saving model ...
Validation loss decreased (1.358934 --> 1.352316).  Saving model ...
Validation loss decreased (1.352316 --> 1.345890).  Saving model ...
Validation loss decreased (1.345890 --> 1.340113).  Saving model ...
Validation loss decreased (1.340113 --> 1.334660).  Saving model ...
Validation loss decreased (1.334660 --> 1.328925).  Saving model ...
Validation loss decreased (1.328925 --> 1.321567).  Saving model ...
Validation loss decreased (1.321567 --> 1.315314).  Saving model ...
Validation loss decreased (1.315314 --> 1.308912).  Saving model ...
Validation loss decreased (1.308912 --> 1.301887).  Saving model ...
Validation loss decreased (1.301887 --> 1.294640).  Saving model ...
Validation loss decreased (1.294640 --> 1.288310).  Saving model ...
Validation loss decreased (1.288310 --> 1.281942).  Saving model ...
Validation loss decreased (1.281942 --> 1.274095).  Saving model ...
Validation loss decreased (1.274095 --> 1.267429).  Saving model ...
Validation loss decreased (1.267429 --> 1.259537).  Saving model ...
Validation loss decreased (1.259537 --> 1.250672).  Saving model ...
Validation loss decreased (1.250672 --> 1.242701).  Saving model ...
Validation loss decreased (1.242701 --> 1.235340).  Saving model ...
Validation loss decreased (1.235340 --> 1.227835).  Saving model ...
Validation loss decreased (1.227835 --> 1.219368).  Saving model ...
Validation loss decreased (1.219368 --> 1.210768).  Saving model ...
Validation loss decreased (1.210768 --> 1.202728).  Saving model ...
Validation loss decreased (1.202728 --> 1.195124).  Saving model ...
Validation loss decreased (1.195124 --> 1.187830).  Saving model ...
Validation loss decreased (1.187830 --> 1.181274).  Saving model ...
Validation loss decreased (1.181274 --> 1.172844).  Saving model ...
Validation loss decreased (1.172844 --> 1.165880).  Saving model ...
Validation loss decreased (1.165880 --> 1.159391).  Saving model ...
Validation loss decreased (1.159391 --> 1.153264).  Saving model ...
Validation loss decreased (1.153264 --> 1.146122).  Saving model ...
Validation loss decreased (1.146122 --> 1.139798).  Saving model ...
Validation loss decreased (1.139798 --> 1.133745).  Saving model ...
Validation loss decreased (1.133745 --> 1.125953).  Saving model ...
Validation loss decreased (1.125953 --> 1.119159).  Saving model ...
Validation loss decreased (1.119159 --> 1.113060).  Saving model ...
Validation loss decreased (1.113060 --> 1.107618).  Saving model ...
Validation loss decreased (1.107618 --> 1.100664).  Saving model ...
Validation loss decreased (1.100664 --> 1.095643).  Saving model ...
Validation loss decreased (1.095643 --> 1.090329).  Saving model ...
Validation loss decreased (1.090329 --> 1.085163).  Saving model ...
Validation loss decreased (1.085163 --> 1.079909).  Saving model ...
Validation loss decreased (1.079909 --> 1.076015).  Saving model ...
Validation loss decreased (1.076015 --> 1.071435).  Saving model ...
Validation loss decreased (1.071435 --> 1.065407).  Saving model ...
Validation loss decreased (1.065407 --> 1.059934).  Saving model ...
Validation loss decreased (1.059934 --> 1.056900).  Saving model ...
Validation loss decreased (1.056900 --> 1.052186).  Saving model ...
Validation loss decreased (1.052186 --> 1.048745).  Saving model ...
Validation loss decreased (1.048745 --> 1.044814).  Saving model ...
Validation loss decreased (1.044814 --> 1.039814).  Saving model ...
Validation loss decreased (1.039814 --> 1.034346).  Saving model ...
Validation loss decreased (1.034346 --> 1.031611).  Saving model ...
Validation loss decreased (1.031611 --> 1.028625).  Saving model ...
Validation loss decreased (1.028625 --> 1.025021).  Saving model ...
Validation loss decreased (1.025021 --> 1.022057).  Saving model ...
Validation loss decreased (1.022057 --> 1.018064).  Saving model ...
Validation loss decreased (1.018064 --> 1.014546).  Saving model ...
Validation loss decreased (1.014546 --> 1.010215).  Saving model ...
Validation loss decreased (1.010215 --> 1.007698).  Saving model ...
Validation loss decreased (1.007698 --> 1.004745).  Saving model ...
Validation loss decreased (1.004745 --> 1.003133).  Saving model ...
Validation loss decreased (1.003133 --> 0.999573).  Saving model ...
Validation loss decreased (0.999573 --> 0.996735).  Saving model ...
Validation loss decreased (0.996735 --> 0.994233).  Saving model ...
Validation loss decreased (0.994233 --> 0.992349).  Saving model ...
Validation loss decreased (0.992349 --> 0.991895).  Saving model ...
Validation loss decreased (0.991895 --> 0.990724).  Saving model ...
Validation loss decreased (0.990724 --> 0.988864).  Saving model ...
Validation loss decreased (0.988864 --> 0.986855).  Saving model ...
Validation loss decreased (0.986855 --> 0.984837).  Saving model ...
Validation loss decreased (0.984837 --> 0.982207).  Saving model ...
Validation loss decreased (0.982207 --> 0.979900).  Saving model ...
EarlyStopping counter: 1 out of 10.0
Validation loss decreased (0.979900 --> 0.978899).  Saving model ...
Validation loss decreased (0.978899 --> 0.974489).  Saving model ...
Validation loss decreased (0.974489 --> 0.970910).  Saving model ...
Validation loss decreased (0.970910 --> 0.968558).  Saving model ...
Validation loss decreased (0.968558 --> 0.968220).  Saving model ...
EarlyStopping counter: 1 out of 10.0
Validation loss decreased (0.968220 --> 0.965912).  Saving model ...
Validation loss decreased (0.965912 --> 0.963428).  Saving model ...
EarlyStopping counter: 1 out of 10.0
Validation loss decreased (0.963428 --> 0.961648).  Saving model ...
Validation loss decreased (0.961648 --> 0.960612).  Saving model ...
EarlyStopping counter: 1 out of 10.0
Validation loss decreased (0.960612 --> 0.959390).  Saving model ...
Validation loss decreased (0.959390 --> 0.957339).  Saving model ...
Validation loss decreased (0.957339 --> 0.956765).  Saving model ...
Validation loss decreased (0.956765 --> 0.956106).  Saving model ...
Validation loss decreased (0.956106 --> 0.955894).  Saving model ...
Validation loss decreased (0.955894 --> 0.954059).  Saving model ...
EarlyStopping counter: 1 out of 10.0
Validation loss decreased (0.954059 --> 0.953365).  Saving model ...
EarlyStopping counter: 1 out of 10.0
Validation loss decreased (0.953365 --> 0.952445).  Saving model ...
Validation loss decreased (0.952445 --> 0.950559).  Saving model ...
Validation loss decreased (0.950559 --> 0.950142).  Saving model ...
EarlyStopping counter: 1 out of 10.0
Validation loss decreased (0.950142 --> 0.950004).  Saving model ...
EarlyStopping counter: 1 out of 10.0
EarlyStopping counter: 2 out of 10.0
Validation loss decreased (0.950004 --> 0.947061).  Saving model ...
Validation loss decreased (0.947061 --> 0.945897).  Saving model ...
EarlyStopping counter: 1 out of 10.0
EarlyStopping counter: 2 out of 10.0
EarlyStopping counter: 3 out of 10.0
EarlyStopping counter: 4 out of 10.0
Validation loss decreased (0.945897 --> 0.945788).  Saving model ...
EarlyStopping counter: 1 out of 10.0
EarlyStopping counter: 2 out of 10.0
EarlyStopping counter: 3 out of 10.0
EarlyStopping counter: 4 out of 10.0
EarlyStopping counter: 5 out of 10.0
EarlyStopping counter: 6 out of 10.0
EarlyStopping counter: 7 out of 10.0
EarlyStopping counter: 8 out of 10.0
EarlyStopping counter: 9 out of 10.0
EarlyStopping counter: 10 out of 10.0
/localscratch/yinan.29019366.0/env/lib/python3.7/site-packages/torch/nn/functional.py:1794: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.
  warnings.warn("nn.functional.tanh is deprecated. Use torch.tanh instead.")
wandb: Waiting for W&B process to finish, PID 37446... (success).
wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: \ 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: | 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: / 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: \ 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: | 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: / 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: \ 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: | 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: / 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb:                                                                                
wandb: Run history:
wandb:     e_F1 ▁▁▃▄▄▅▅▆▆▆▇▇▇▇▇▇▇███████████████████████
wandb:   e_loss █▇▆▆▆▅▅▅▅▄▄▄▃▃▃▃▃▂▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:     t_F1 ▁▁▂▃▂▄▃▄▅▄▄▅▅▆▅▆▆▆▆▆▆▆▇▇▆▇▇▇▇▇▇▇█▇██████
wandb:   t_loss █▇▇▆▆▆▆▆▅▅▅▅▅▄▄▄▄▄▃▃▃▃▃▃▃▂▂▂▂▂▂▂▂▂▂▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:     e_F1 59.84248
wandb:   e_loss 0.953
wandb:     t_F1 67.51581
wandb:   t_loss 0.78938
wandb: 
wandb: Synced 4 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Synced astral-planet-2: https://wandb.ai/yinanazhou/xl_512_bs_8_lr_1e06_es_10_lc_False_nr_False_sr_True_stem_True_lemma_False_repeat_4_fold_2/runs/1shxf2sq
wandb: Find logs at: ./wandb/run-20220319_060713-1shxf2sq/logs/debug.log
wandb: 

wandb: wandb version 0.12.11 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
2022-03-19 07:31:14.507907: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1
wandb: Tracking run with wandb version 0.12.5
wandb: Syncing run treasured-gorge-2
wandb: ⭐️ View project at https://wandb.ai/yinanazhou/xl_512_bs_8_lr_1e06_es_10_lc_False_nr_False_sr_True_stem_True_lemma_False_repeat_5_fold_1
wandb: 🚀 View run at https://wandb.ai/yinanazhou/xl_512_bs_8_lr_1e06_es_10_lc_False_nr_False_sr_True_stem_True_lemma_False_repeat_5_fold_1/runs/7dmhztku
wandb: Run data is saved locally in /project/6002780/yinan/Thesis_MER_Lyrics/lyric-emotion/wandb/run-20220319_073111-7dmhztku
wandb: Run `wandb offline` to turn off syncing.

Validation loss decreased (inf --> 1.453879).  Saving model ...
Validation loss decreased (1.453879 --> 1.431916).  Saving model ...
Validation loss decreased (1.431916 --> 1.416129).  Saving model ...
Validation loss decreased (1.416129 --> 1.404822).  Saving model ...
Validation loss decreased (1.404822 --> 1.396170).  Saving model ...
Validation loss decreased (1.396170 --> 1.389398).  Saving model ...
Validation loss decreased (1.389398 --> 1.383931).  Saving model ...
Validation loss decreased (1.383931 --> 1.379570).  Saving model ...
Validation loss decreased (1.379570 --> 1.375549).  Saving model ...
Validation loss decreased (1.375549 --> 1.371625).  Saving model ...
Validation loss decreased (1.371625 --> 1.367901).  Saving model ...
Validation loss decreased (1.367901 --> 1.364480).  Saving model ...
Validation loss decreased (1.364480 --> 1.361185).  Saving model ...
Validation loss decreased (1.361185 --> 1.357497).  Saving model ...
Validation loss decreased (1.357497 --> 1.353126).  Saving model ...
Validation loss decreased (1.353126 --> 1.349346).  Saving model ...
Validation loss decreased (1.349346 --> 1.344772).  Saving model ...
Validation loss decreased (1.344772 --> 1.340271).  Saving model ...
Validation loss decreased (1.340271 --> 1.335827).  Saving model ...
Validation loss decreased (1.335827 --> 1.331308).  Saving model ...
Validation loss decreased (1.331308 --> 1.326786).  Saving model ...
Validation loss decreased (1.326786 --> 1.321757).  Saving model ...
Validation loss decreased (1.321757 --> 1.316188).  Saving model ...
Validation loss decreased (1.316188 --> 1.311049).  Saving model ...
Validation loss decreased (1.311049 --> 1.305809).  Saving model ...
Validation loss decreased (1.305809 --> 1.300118).  Saving model ...
Validation loss decreased (1.300118 --> 1.294775).  Saving model ...
Validation loss decreased (1.294775 --> 1.288123).  Saving model ...
Validation loss decreased (1.288123 --> 1.280956).  Saving model ...
Validation loss decreased (1.280956 --> 1.273943).  Saving model ...
Validation loss decreased (1.273943 --> 1.267310).  Saving model ...
Validation loss decreased (1.267310 --> 1.260511).  Saving model ...
Validation loss decreased (1.260511 --> 1.253720).  Saving model ...
Validation loss decreased (1.253720 --> 1.247127).  Saving model ...
Validation loss decreased (1.247127 --> 1.240467).  Saving model ...
Validation loss decreased (1.240467 --> 1.234405).  Saving model ...
Validation loss decreased (1.234405 --> 1.227065).  Saving model ...
Validation loss decreased (1.227065 --> 1.220664).  Saving model ...
Validation loss decreased (1.220664 --> 1.213509).  Saving model ...
Validation loss decreased (1.213509 --> 1.207170).  Saving model ...
Validation loss decreased (1.207170 --> 1.200204).  Saving model ...
Validation loss decreased (1.200204 --> 1.193289).  Saving model ...
Validation loss decreased (1.193289 --> 1.186530).  Saving model ...
Validation loss decreased (1.186530 --> 1.181056).  Saving model ...
Validation loss decreased (1.181056 --> 1.174745).  Saving model ...
Validation loss decreased (1.174745 --> 1.170434).  Saving model ...
Validation loss decreased (1.170434 --> 1.164392).  Saving model ...
Validation loss decreased (1.164392 --> 1.158781).  Saving model ...
Validation loss decreased (1.158781 --> 1.153127).  Saving model ...
Validation loss decreased (1.153127 --> 1.147913).  Saving model ...
Validation loss decreased (1.147913 --> 1.141639).  Saving model ...
Validation loss decreased (1.141639 --> 1.135700).  Saving model ...
Validation loss decreased (1.135700 --> 1.131420).  Saving model ...
Validation loss decreased (1.131420 --> 1.125680).  Saving model ...
Validation loss decreased (1.125680 --> 1.120772).  Saving model ...
Validation loss decreased (1.120772 --> 1.116360).  Saving model ...
Validation loss decreased (1.116360 --> 1.111134).  Saving model ...
Validation loss decreased (1.111134 --> 1.107592).  Saving model ...
Validation loss decreased (1.107592 --> 1.103598).  Saving model ...
Validation loss decreased (1.103598 --> 1.098372).  Saving model ...
Validation loss decreased (1.098372 --> 1.094038).  Saving model ...
Validation loss decreased (1.094038 --> 1.089180).  Saving model ...
Validation loss decreased (1.089180 --> 1.085268).  Saving model ...
Validation loss decreased (1.085268 --> 1.079916).  Saving model ...
Validation loss decreased (1.079916 --> 1.077995).  Saving model ...
Validation loss decreased (1.077995 --> 1.073843).  Saving model ...
Validation loss decreased (1.073843 --> 1.069395).  Saving model ...
Validation loss decreased (1.069395 --> 1.066978).  Saving model ...
Validation loss decreased (1.066978 --> 1.062748).  Saving model ...
Validation loss decreased (1.062748 --> 1.056042).  Saving model ...
Validation loss decreased (1.056042 --> 1.053626).  Saving model ...
Validation loss decreased (1.053626 --> 1.050087).  Saving model ...
Validation loss decreased (1.050087 --> 1.044308).  Saving model ...
Validation loss decreased (1.044308 --> 1.040983).  Saving model ...
Validation loss decreased (1.040983 --> 1.036417).  Saving model ...
Validation loss decreased (1.036417 --> 1.034659).  Saving model ...
Validation loss decreased (1.034659 --> 1.031216).  Saving model ...
Validation loss decreased (1.031216 --> 1.027969).  Saving model ...
Validation loss decreased (1.027969 --> 1.024660).  Saving model ...
Validation loss decreased (1.024660 --> 1.021591).  Saving model ...
Validation loss decreased (1.021591 --> 1.019333).  Saving model ...
Validation loss decreased (1.019333 --> 1.017116).  Saving model ...
Validation loss decreased (1.017116 --> 1.014260).  Saving model ...
Validation loss decreased (1.014260 --> 1.011666).  Saving model ...
Validation loss decreased (1.011666 --> 1.008566).  Saving model ...
Validation loss decreased (1.008566 --> 1.007012).  Saving model ...
Validation loss decreased (1.007012 --> 1.004148).  Saving model ...
Validation loss decreased (1.004148 --> 1.001492).  Saving model ...
Validation loss decreased (1.001492 --> 0.998718).  Saving model ...
Validation loss decreased (0.998718 --> 0.997597).  Saving model ...
Validation loss decreased (0.997597 --> 0.994535).  Saving model ...
Validation loss decreased (0.994535 --> 0.992693).  Saving model ...
Validation loss decreased (0.992693 --> 0.992188).  Saving model ...
Validation loss decreased (0.992188 --> 0.991650).  Saving model ...
Validation loss decreased (0.991650 --> 0.989793).  Saving model ...
Validation loss decreased (0.989793 --> 0.987557).  Saving model ...
Validation loss decreased (0.987557 --> 0.985266).  Saving model ...
Validation loss decreased (0.985266 --> 0.984935).  Saving model ...
Validation loss decreased (0.984935 --> 0.983355).  Saving model ...
Validation loss decreased (0.983355 --> 0.981833).  Saving model ...
Validation loss decreased (0.981833 --> 0.981247).  Saving model ...
Validation loss decreased (0.981247 --> 0.980253).  Saving model ...
Validation loss decreased (0.980253 --> 0.978392).  Saving model ...
EarlyStopping counter: 1 out of 10.0
Validation loss decreased (0.978392 --> 0.976889).  Saving model ...
Validation loss decreased (0.976889 --> 0.976359).  Saving model ...
Validation loss decreased (0.976359 --> 0.975084).  Saving model ...
Validation loss decreased (0.975084 --> 0.972892).  Saving model ...
Validation loss decreased (0.972892 --> 0.970896).  Saving model ...
Validation loss decreased (0.970896 --> 0.970592).  Saving model ...
Validation loss decreased (0.970592 --> 0.968412).  Saving model ...
Validation loss decreased (0.968412 --> 0.968298).  Saving model ...
Validation loss decreased (0.968298 --> 0.967635).  Saving model ...
Validation loss decreased (0.967635 --> 0.966143).  Saving model ...
Validation loss decreased (0.966143 --> 0.964025).  Saving model ...
Validation loss decreased (0.964025 --> 0.963901).  Saving model ...
Validation loss decreased (0.963901 --> 0.963371).  Saving model ...
Validation loss decreased (0.963371 --> 0.962218).  Saving model ...
Validation loss decreased (0.962218 --> 0.961633).  Saving model ...
Validation loss decreased (0.961633 --> 0.960286).  Saving model ...
Validation loss decreased (0.960286 --> 0.958924).  Saving model ...
Validation loss decreased (0.958924 --> 0.958314).  Saving model ...
EarlyStopping counter: 1 out of 10.0
EarlyStopping counter: 2 out of 10.0
EarlyStopping counter: 3 out of 10.0
EarlyStopping counter: 4 out of 10.0
EarlyStopping counter: 5 out of 10.0
EarlyStopping counter: 6 out of 10.0
EarlyStopping counter: 7 out of 10.0
EarlyStopping counter: 8 out of 10.0
Validation loss decreased (0.958314 --> 0.957083).  Saving model ...
Validation loss decreased (0.957083 --> 0.956665).  Saving model ...
EarlyStopping counter: 1 out of 10.0
EarlyStopping counter: 2 out of 10.0
EarlyStopping counter: 3 out of 10.0
EarlyStopping counter: 4 out of 10.0
EarlyStopping counter: 5 out of 10.0
EarlyStopping counter: 6 out of 10.0
EarlyStopping counter: 7 out of 10.0
EarlyStopping counter: 8 out of 10.0
EarlyStopping counter: 9 out of 10.0
EarlyStopping counter: 10 out of 10.0
/localscratch/yinan.29019366.0/env/lib/python3.7/site-packages/torch/nn/functional.py:1794: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.
  warnings.warn("nn.functional.tanh is deprecated. Use torch.tanh instead.")
wandb: Waiting for W&B process to finish, PID 41963... (success).
wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: \ 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: | 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: / 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: \ 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: | 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: / 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: \ 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: | 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb:                                                                                
wandb: Run history:
wandb:     e_F1 ▁▂▃▄▄▄▄▄▅▅▅▆▆▆▇▇▇▇▇▇██▇█████████████████
wandb:   e_loss ██▇▇▇▇▆▆▆▅▅▅▄▄▄▃▃▃▃▂▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:     t_F1 ▁▂▂▂▂▃▃▃▄▄▅▅▅▅▅▅▆▆▆▆▆▆▆▆▆▇▆▇▇▇▇▇▇▇▇▇▇█▇█
wandb:   t_loss ███▇▇▇▇▇▆▆▆▆▆▅▅▅▅▄▄▄▄▃▃▃▃▃▃▃▂▂▂▂▂▂▂▂▂▁▂▁
wandb: 
wandb: Run summary:
wandb:     e_F1 56.14017
wandb:   e_loss 0.95788
wandb:     t_F1 76.66421
wandb:   t_loss 0.71904
wandb: 
wandb: Synced 4 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Synced treasured-gorge-2: https://wandb.ai/yinanazhou/xl_512_bs_8_lr_1e06_es_10_lc_False_nr_False_sr_True_stem_True_lemma_False_repeat_5_fold_1/runs/7dmhztku
wandb: Find logs at: ./wandb/run-20220319_073111-7dmhztku/logs/debug.log
wandb: 

wandb: wandb version 0.12.11 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
2022-03-19 09:03:32.559287: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1
wandb: Tracking run with wandb version 0.12.5
wandb: Syncing run dazzling-cherry-2
wandb: ⭐️ View project at https://wandb.ai/yinanazhou/xl_512_bs_8_lr_1e06_es_10_lc_False_nr_False_sr_True_stem_True_lemma_False_repeat_5_fold_2
wandb: 🚀 View run at https://wandb.ai/yinanazhou/xl_512_bs_8_lr_1e06_es_10_lc_False_nr_False_sr_True_stem_True_lemma_False_repeat_5_fold_2/runs/1q1t9u88
wandb: Run data is saved locally in /project/6002780/yinan/Thesis_MER_Lyrics/lyric-emotion/wandb/run-20220319_090329-1q1t9u88
wandb: Run `wandb offline` to turn off syncing.

Validation loss decreased (inf --> 1.398011).  Saving model ...
Validation loss decreased (1.398011 --> 1.391010).  Saving model ...
Validation loss decreased (1.391010 --> 1.385126).  Saving model ...
Validation loss decreased (1.385126 --> 1.379159).  Saving model ...
Validation loss decreased (1.379159 --> 1.374404).  Saving model ...
Validation loss decreased (1.374404 --> 1.370374).  Saving model ...
Validation loss decreased (1.370374 --> 1.365338).  Saving model ...
Validation loss decreased (1.365338 --> 1.360386).  Saving model ...
Validation loss decreased (1.360386 --> 1.355595).  Saving model ...
Validation loss decreased (1.355595 --> 1.350710).  Saving model ...
Validation loss decreased (1.350710 --> 1.346231).  Saving model ...
Validation loss decreased (1.346231 --> 1.341938).  Saving model ...
Validation loss decreased (1.341938 --> 1.337042).  Saving model ...
Validation loss decreased (1.337042 --> 1.332289).  Saving model ...
Validation loss decreased (1.332289 --> 1.326672).  Saving model ...
Validation loss decreased (1.326672 --> 1.321102).  Saving model ...
Validation loss decreased (1.321102 --> 1.315354).  Saving model ...
Validation loss decreased (1.315354 --> 1.309424).  Saving model ...
Validation loss decreased (1.309424 --> 1.304038).  Saving model ...
Validation loss decreased (1.304038 --> 1.297944).  Saving model ...
Validation loss decreased (1.297944 --> 1.291774).  Saving model ...
Validation loss decreased (1.291774 --> 1.285023).  Saving model ...
Validation loss decreased (1.285023 --> 1.278028).  Saving model ...
Validation loss decreased (1.278028 --> 1.270123).  Saving model ...
Validation loss decreased (1.270123 --> 1.261905).  Saving model ...
Validation loss decreased (1.261905 --> 1.253861).  Saving model ...
Validation loss decreased (1.253861 --> 1.245073).  Saving model ...
Validation loss decreased (1.245073 --> 1.238688).  Saving model ...
Validation loss decreased (1.238688 --> 1.231055).  Saving model ...
Validation loss decreased (1.231055 --> 1.222706).  Saving model ...
Validation loss decreased (1.222706 --> 1.215634).  Saving model ...
Validation loss decreased (1.215634 --> 1.208810).  Saving model ...
Validation loss decreased (1.208810 --> 1.201956).  Saving model ...
Validation loss decreased (1.201956 --> 1.194523).  Saving model ...
Validation loss decreased (1.194523 --> 1.186941).  Saving model ...
Validation loss decreased (1.186941 --> 1.178899).  Saving model ...
Validation loss decreased (1.178899 --> 1.172988).  Saving model ...
Validation loss decreased (1.172988 --> 1.166231).  Saving model ...
Validation loss decreased (1.166231 --> 1.158726).  Saving model ...
Validation loss decreased (1.158726 --> 1.152029).  Saving model ...
Validation loss decreased (1.152029 --> 1.147979).  Saving model ...
Validation loss decreased (1.147979 --> 1.143641).  Saving model ...
Validation loss decreased (1.143641 --> 1.137853).  Saving model ...
Validation loss decreased (1.137853 --> 1.131260).  Saving model ...
Validation loss decreased (1.131260 --> 1.126358).  Saving model ...
Validation loss decreased (1.126358 --> 1.120209).  Saving model ...
Validation loss decreased (1.120209 --> 1.113337).  Saving model ...
Validation loss decreased (1.113337 --> 1.108562).  Saving model ...
Validation loss decreased (1.108562 --> 1.105179).  Saving model ...
Validation loss decreased (1.105179 --> 1.102122).  Saving model ...
Validation loss decreased (1.102122 --> 1.097711).  Saving model ...
Validation loss decreased (1.097711 --> 1.092397).  Saving model ...
Validation loss decreased (1.092397 --> 1.087661).  Saving model ...
Validation loss decreased (1.087661 --> 1.081480).  Saving model ...
Validation loss decreased (1.081480 --> 1.078411).  Saving model ...
Validation loss decreased (1.078411 --> 1.075606).  Saving model ...
Validation loss decreased (1.075606 --> 1.070185).  Saving model ...
Validation loss decreased (1.070185 --> 1.065019).  Saving model ...
Validation loss decreased (1.065019 --> 1.063507).  Saving model ...
Validation loss decreased (1.063507 --> 1.061623).  Saving model ...
Validation loss decreased (1.061623 --> 1.056829).  Saving model ...
Validation loss decreased (1.056829 --> 1.054877).  Saving model ...
Validation loss decreased (1.054877 --> 1.050421).  Saving model ...
Validation loss decreased (1.050421 --> 1.045837).  Saving model ...
Validation loss decreased (1.045837 --> 1.038733).  Saving model ...
Validation loss decreased (1.038733 --> 1.036617).  Saving model ...
Validation loss decreased (1.036617 --> 1.035123).  Saving model ...
Validation loss decreased (1.035123 --> 1.033844).  Saving model ...
Validation loss decreased (1.033844 --> 1.030765).  Saving model ...
Validation loss decreased (1.030765 --> 1.028648).  Saving model ...
Validation loss decreased (1.028648 --> 1.027845).  Saving model ...
Validation loss decreased (1.027845 --> 1.023498).  Saving model ...
Validation loss decreased (1.023498 --> 1.019377).  Saving model ...
Validation loss decreased (1.019377 --> 1.016395).  Saving model ...
Validation loss decreased (1.016395 --> 1.015053).  Saving model ...
Validation loss decreased (1.015053 --> 1.014293).  Saving model ...
Validation loss decreased (1.014293 --> 1.011114).  Saving model ...
Validation loss decreased (1.011114 --> 1.008979).  Saving model ...
Validation loss decreased (1.008979 --> 1.006489).  Saving model ...
Validation loss decreased (1.006489 --> 1.005493).  Saving model ...
Validation loss decreased (1.005493 --> 1.003933).  Saving model ...
Validation loss decreased (1.003933 --> 0.999764).  Saving model ...
Validation loss decreased (0.999764 --> 0.996020).  Saving model ...
EarlyStopping counter: 1 out of 10.0
Validation loss decreased (0.996020 --> 0.995242).  Saving model ...
EarlyStopping counter: 1 out of 10.0
Validation loss decreased (0.995242 --> 0.992743).  Saving model ...
Validation loss decreased (0.992743 --> 0.989499).  Saving model ...
Validation loss decreased (0.989499 --> 0.987012).  Saving model ...
EarlyStopping counter: 1 out of 10.0
EarlyStopping counter: 2 out of 10.0
Validation loss decreased (0.987012 --> 0.986964).  Saving model ...
Validation loss decreased (0.986964 --> 0.985314).  Saving model ...
Validation loss decreased (0.985314 --> 0.980453).  Saving model ...
Validation loss decreased (0.980453 --> 0.979361).  Saving model ...
Validation loss decreased (0.979361 --> 0.978415).  Saving model ...
Validation loss decreased (0.978415 --> 0.978235).  Saving model ...
Validation loss decreased (0.978235 --> 0.976016).  Saving model ...
Validation loss decreased (0.976016 --> 0.974727).  Saving model ...
Validation loss decreased (0.974727 --> 0.972504).  Saving model ...
Validation loss decreased (0.972504 --> 0.970140).  Saving model ...
Validation loss decreased (0.970140 --> 0.967506).  Saving model ...
EarlyStopping counter: 1 out of 10.0
EarlyStopping counter: 2 out of 10.0
EarlyStopping counter: 3 out of 10.0
Validation loss decreased (0.967506 --> 0.967002).  Saving model ...
Validation loss decreased (0.967002 --> 0.965951).  Saving model ...
EarlyStopping counter: 1 out of 10.0
Validation loss decreased (0.965951 --> 0.962710).  Saving model ...
Validation loss decreased (0.962710 --> 0.962209).  Saving model ...
EarlyStopping counter: 1 out of 10.0
Validation loss decreased (0.962209 --> 0.961489).  Saving model ...
Validation loss decreased (0.961489 --> 0.958310).  Saving model ...
Validation loss decreased (0.958310 --> 0.956045).  Saving model ...
EarlyStopping counter: 1 out of 10.0
EarlyStopping counter: 2 out of 10.0
EarlyStopping counter: 3 out of 10.0
Validation loss decreased (0.956045 --> 0.954939).  Saving model ...
Validation loss decreased (0.954939 --> 0.952756).  Saving model ...
Validation loss decreased (0.952756 --> 0.951406).  Saving model ...
EarlyStopping counter: 1 out of 10.0
EarlyStopping counter: 2 out of 10.0
Validation loss decreased (0.951406 --> 0.948136).  Saving model ...
Validation loss decreased (0.948136 --> 0.945389).  Saving model ...
EarlyStopping counter: 1 out of 10.0
EarlyStopping counter: 2 out of 10.0
EarlyStopping counter: 3 out of 10.0
EarlyStopping counter: 4 out of 10.0
EarlyStopping counter: 5 out of 10.0
EarlyStopping counter: 6 out of 10.0
EarlyStopping counter: 7 out of 10.0
EarlyStopping counter: 8 out of 10.0
EarlyStopping counter: 9 out of 10.0
EarlyStopping counter: 10 out of 10.0
/localscratch/yinan.29019366.0/env/lib/python3.7/site-packages/torch/nn/functional.py:1794: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.
  warnings.warn("nn.functional.tanh is deprecated. Use torch.tanh instead.")
wandb: Waiting for W&B process to finish, PID 46938... (success).
wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: \ 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: | 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: / 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: \ 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: | 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: / 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: \ 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: | 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: / 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb:                                                                                
wandb: Run history:
wandb:     e_F1 ▁▂▃▄▄▅▅▆▆▆▆▆▇▇▆▇▇▇▇▇▇▇▇█████████████████
wandb:   e_loss ███▇▇▇▆▆▆▅▅▄▄▄▄▃▃▃▃▂▂▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁
wandb:     t_F1 ▁▁▂▂▂▃▃▄▄▄▅▅▅▆▅▆▆▆▆▆▇▆▇▇▇▇▇▇▇▇▇▇▇▇█▇▇███
wandb:   t_loss ████▇▇▇▇▆▆▅▅▅▅▅▄▄▄▄▃▃▃▃▃▃▃▂▂▂▂▂▂▂▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:     e_F1 60.88565
wandb:   e_loss 0.94769
wandb:     t_F1 68.62001
wandb:   t_loss 0.81264
wandb: 
wandb: Synced 4 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Synced dazzling-cherry-2: https://wandb.ai/yinanazhou/xl_512_bs_8_lr_1e06_es_10_lc_False_nr_False_sr_True_stem_True_lemma_False_repeat_5_fold_2/runs/1q1t9u88
wandb: Find logs at: ./wandb/run-20220319_090329-1q1t9u88/logs/debug.log
wandb: 

