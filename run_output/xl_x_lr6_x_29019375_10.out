Unloading StdEnv/2020

Due to MODULEPATH changes, the following have been reloaded:
  1) mii/1.1.1


The following have been reloaded with a version change:
  1) python/3.8.2 => python/3.7.4

Using base prefix '/cvmfs/soft.computecanada.ca/easybuild/software/2017/Core/python/3.7.4'
New python executable in /localscratch/yinan.29019375.0/env/bin/python
Installing setuptools, pip, wheel...
done.
Ignoring pip: markers 'python_version < "3"' don't match your environment
Looking in links: /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/nix/avx2, /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/nix/generic, /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic
Collecting pip
Installing collected packages: pip
  Found existing installation: pip 19.1.1
    Uninstalling pip-19.1.1:
      Successfully uninstalled pip-19.1.1
Successfully installed pip-21.2.3+computecanada
Looking in links: /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/nix/avx2, /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/nix/generic, /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/keras-2.8.0+computecanada-py2.py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/Keras_Preprocessing-1.1.2+computecanada-py3-none-any.whl
Requirement already satisfied: matplotlib in /cvmfs/soft.computecanada.ca/easybuild/software/2017/Core/scipy-stack/2019a/lib/python3.7/site-packages (from -r requirements.txt (line 3)) (3.0.2)
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/nltk-3.6.5+computecanada-py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/scikit_learn-0.22.1+computecanada-cp37-cp37m-linux_x86_64.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/tensorboard-2.3.0+computecanada-py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/tensorboard_plugin_wit-1.7.0+computecanada-py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/tensorflow_gpu-2.3.0+computecanada-cp37-cp37m-linux_x86_64.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/tensorflow_estimator-2.3.0+computecanada-py2.py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/tokenizers-0.5.2+computecanada-cp37-cp37m-linux_x86_64.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/nix/avx2/torch-1.4.0+computecanada-cp37-cp37m-linux_x86_64.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/torchtext-0.6.0+computecanada-py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/torchvision-0.8.2+computecanada-cp37-cp37m-linux_x86_64.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/transformers-2.5.1+computecanada-py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/urllib3-1.26.7+computecanada-py2.py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/tqdm-4.63.0+computecanada-py2.py3-none-any.whl
ERROR: Could not find a version that satisfies the requirement regex>=2021.8.3 (from nltk) (from versions: 2018.1.10+computecanada, 2019.11.1+computecanada, 2020.11.13+computecanada)
ERROR: No matching distribution found for regex>=2021.8.3
Looking in links: /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/nix/avx2, /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/nix/generic, /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic
ERROR: Could not find a version that satisfies the requirement numpy==1.20.0+computacanada (from versions: 1.15.0+computecanada, 1.15.2+computecanada, 1.15.4+computecanada, 1.16.0+computecanada, 1.16.2+computecanada, 1.16.3+computecanada, 1.17.4+computecanada, 1.18.1+computecanada, 1.18.4+computecanada, 1.19.1+computecanada, 1.19.2+computecanada, 1.20.2+computecanada)
ERROR: No matching distribution found for numpy==1.20.0+computacanada
Looking in links: /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/nix/avx2, /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/nix/generic, /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/wandb-0.12.5+computecanada-py2.py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/psutil-5.7.3+computecanada-cp37-cp37m-linux_x86_64.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/shortuuid-1.0.1+computecanada-py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/pathtools-0.1.2+computecanada-py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/click-8.0.4+computecanada-py3-none-any.whl
Requirement already satisfied: python-dateutil>=2.6.1 in /cvmfs/soft.computecanada.ca/easybuild/software/2017/Core/scipy-stack/2019a/lib/python3.7/site-packages (from wandb) (2.7.5)
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/promise-2.3+computecanada-py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/docker_pycreds-0.4.0+computecanada-py2.py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/subprocess32-3.5.4+computecanada-py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/PyYAML-5.3.1+computecanada-cp37-cp37m-linux_x86_64.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/protobuf-3.19.4+computecanada-py2.py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/GitPython-3.1.24+computecanada-py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/sentry_sdk-1.5.0+computecanada-py2.py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/configparser-5.0.2+computecanada-py3-none-any.whl
Requirement already satisfied: requests<3,>=2.0.0 in /cvmfs/soft.computecanada.ca/easybuild/software/2017/Core/scipy-stack/2019a/lib/python3.7/site-packages (from wandb) (2.21.0)
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/six-1.16.0+computecanada-py2.py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/yaspin-2.1.0+computecanada-py3-none-any.whl
Requirement already satisfied: importlib-metadata in /cvmfs/soft.computecanada.ca/easybuild/software/2017/Core/scipy-stack/2019a/lib/python3.7/site-packages (from Click!=8.0.0,>=7.0->wandb) (0.8)
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/typing_extensions-4.0.1+computecanada-py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/gitdb-4.0.9+computecanada-py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/smmap-5.0.0+computecanada-py3-none-any.whl
Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /cvmfs/soft.computecanada.ca/easybuild/software/2017/Core/scipy-stack/2019a/lib/python3.7/site-packages (from requests<3,>=2.0.0->wandb) (3.0.4)
Requirement already satisfied: idna<2.9,>=2.5 in /cvmfs/soft.computecanada.ca/easybuild/software/2017/Core/scipy-stack/2019a/lib/python3.7/site-packages (from requests<3,>=2.0.0->wandb) (2.8)
Requirement already satisfied: urllib3<1.25,>=1.21.1 in /cvmfs/soft.computecanada.ca/easybuild/software/2017/Core/scipy-stack/2019a/lib/python3.7/site-packages (from requests<3,>=2.0.0->wandb) (1.24.1)
Requirement already satisfied: certifi>=2017.4.17 in /cvmfs/soft.computecanada.ca/easybuild/software/2017/Core/scipy-stack/2019a/lib/python3.7/site-packages (from requests<3,>=2.0.0->wandb) (2018.11.29)
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/termcolor-1.1.0+computecanada-py3-none-any.whl
Requirement already satisfied: zipp>=0.3.2 in /cvmfs/soft.computecanada.ca/easybuild/software/2017/Core/scipy-stack/2019a/lib/python3.7/site-packages (from importlib-metadata->Click!=8.0.0,>=7.0->wandb) (0.3.3)
Installing collected packages: smmap, typing-extensions, termcolor, six, gitdb, yaspin, subprocess32, shortuuid, sentry-sdk, PyYAML, psutil, protobuf, promise, pathtools, GitPython, docker-pycreds, configparser, Click, wandb
  Attempting uninstall: six
    Found existing installation: six 1.12.0
    Not uninstalling six at /cvmfs/soft.computecanada.ca/easybuild/software/2017/Core/scipy-stack/2019a/lib/python3.7/site-packages, outside environment /localscratch/yinan.29019375.0/env
    Can't uninstall 'six'. No files were found to uninstall.
Successfully installed Click-8.0.4+computecanada GitPython-3.1.24+computecanada PyYAML-5.3.1+computecanada configparser-5.0.2+computecanada docker-pycreds-0.4.0+computecanada gitdb-4.0.9+computecanada pathtools-0.1.2+computecanada promise-2.3+computecanada protobuf-3.19.4+computecanada psutil-5.7.3+computecanada sentry-sdk-1.5.0+computecanada shortuuid-1.0.1+computecanada six-1.16.0+computecanada smmap-5.0.0+computecanada subprocess32-3.5.4+computecanada termcolor-1.1.0+computecanada typing-extensions-4.0.1+computecanada wandb-0.12.5+computecanada yaspin-2.1.0+computecanada
Looking in links: /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/nix/avx2, /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/nix/generic, /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic
ERROR: Could not find a version that satisfies the requirement sagemaker (from versions: none)
ERROR: No matching distribution found for sagemaker
Looking in links: /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/nix/avx2, /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/nix/generic, /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/torch-1.9.1+computecanada-cp37-cp37m-linux_x86_64.whl
Requirement already satisfied: typing-extensions in /localscratch/yinan.29019375.0/env/lib/python3.7/site-packages (from torch) (4.0.1+computecanada)
Installing collected packages: torch
Successfully installed torch-1.9.1+computecanada
Looking in links: /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/nix/avx2, /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/nix/generic, /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/transformers-2.5.1+computecanada-py3-none-any.whl
Requirement already satisfied: requests in /cvmfs/soft.computecanada.ca/easybuild/software/2017/Core/scipy-stack/2019a/lib/python3.7/site-packages (from transformers==2.5.1+computecanada) (2.21.0)
Requirement already satisfied: numpy in /cvmfs/soft.computecanada.ca/easybuild/software/2017/Core/scipy-stack/2019a/lib/python3.7/site-packages (from transformers==2.5.1+computecanada) (1.16.0)
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/boto3-1.21.14+computecanada-py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/filelock-3.4.2+computecanada-py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/regex-2020.11.13+computecanada-cp37-cp37m-linux_x86_64.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/tokenizers-0.5.2+computecanada-cp37-cp37m-linux_x86_64.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/sacremoses-0.0.46+computecanada-py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/sentencepiece-0.1.91+computecanada-cp37-cp37m-linux_x86_64.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/tqdm-4.63.0+computecanada-py2.py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/botocore-1.24.14+computecanada-py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/s3transfer-0.5.1+computecanada-py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/jmespath-0.10.0+computecanada-py2.py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/urllib3-1.26.8+computecanada-py2.py3-none-any.whl
Requirement already satisfied: python-dateutil<3.0.0,>=2.1 in /cvmfs/soft.computecanada.ca/easybuild/software/2017/Core/scipy-stack/2019a/lib/python3.7/site-packages (from botocore<1.25.0,>=1.24.14->boto3->transformers==2.5.1+computecanada) (2.7.5)
Requirement already satisfied: six>=1.5 in /localscratch/yinan.29019375.0/env/lib/python3.7/site-packages (from python-dateutil<3.0.0,>=2.1->botocore<1.25.0,>=1.24.14->boto3->transformers==2.5.1+computecanada) (1.16.0+computecanada)
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/requests-2.27.1+computecanada-py2.py3-none-any.whl
Requirement already satisfied: idna<4,>=2.5 in /cvmfs/soft.computecanada.ca/easybuild/software/2017/Core/scipy-stack/2019a/lib/python3.7/site-packages (from requests->transformers==2.5.1+computecanada) (2.8)
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/charset_normalizer-2.0.12+computecanada-py3-none-any.whl
Requirement already satisfied: certifi>=2017.4.17 in /cvmfs/soft.computecanada.ca/easybuild/software/2017/Core/scipy-stack/2019a/lib/python3.7/site-packages (from requests->transformers==2.5.1+computecanada) (2018.11.29)
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/joblib-1.1.0+computecanada-py2.py3-none-any.whl
Requirement already satisfied: click in /localscratch/yinan.29019375.0/env/lib/python3.7/site-packages (from sacremoses->transformers==2.5.1+computecanada) (8.0.4+computecanada)
Requirement already satisfied: importlib-metadata in /cvmfs/soft.computecanada.ca/easybuild/software/2017/Core/scipy-stack/2019a/lib/python3.7/site-packages (from click->sacremoses->transformers==2.5.1+computecanada) (0.8)
Requirement already satisfied: zipp>=0.3.2 in /cvmfs/soft.computecanada.ca/easybuild/software/2017/Core/scipy-stack/2019a/lib/python3.7/site-packages (from importlib-metadata->click->sacremoses->transformers==2.5.1+computecanada) (0.3.3)
Installing collected packages: urllib3, jmespath, botocore, tqdm, s3transfer, regex, joblib, charset-normalizer, tokenizers, sentencepiece, sacremoses, requests, filelock, boto3, transformers
  Attempting uninstall: urllib3
    Found existing installation: urllib3 1.24.1
    Not uninstalling urllib3 at /cvmfs/soft.computecanada.ca/easybuild/software/2017/Core/scipy-stack/2019a/lib/python3.7/site-packages, outside environment /localscratch/yinan.29019375.0/env
    Can't uninstall 'urllib3'. No files were found to uninstall.
  Attempting uninstall: requests
    Found existing installation: requests 2.21.0
    Not uninstalling requests at /cvmfs/soft.computecanada.ca/easybuild/software/2017/Core/scipy-stack/2019a/lib/python3.7/site-packages, outside environment /localscratch/yinan.29019375.0/env
    Can't uninstall 'requests'. No files were found to uninstall.
Successfully installed boto3-1.21.14+computecanada botocore-1.24.14+computecanada charset-normalizer-2.0.12+computecanada filelock-3.4.2+computecanada jmespath-0.10.0+computecanada joblib-1.1.0+computecanada regex-2020.11.13+computecanada requests-2.27.1+computecanada s3transfer-0.5.1+computecanada sacremoses-0.0.46+computecanada sentencepiece-0.1.91+computecanada tokenizers-0.5.2+computecanada tqdm-4.63.0+computecanada transformers-2.5.1+computecanada urllib3-1.26.8+computecanada
Looking in links: /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/nix/avx2, /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/nix/generic, /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/tensorflow_gpu-2.3.0+computecanada-cp37-cp37m-linux_x86_64.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/google_pasta-0.2.0+computecanada-py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/tensorboard-2.8.0+computecanada-py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/tensorflow_estimator-2.3.0+computecanada-py2.py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/wrapt-1.11.2+computecanada-cp37-cp37m-linux_x86_64.whl
Requirement already satisfied: numpy<1.19.0,>=1.16.0 in /cvmfs/soft.computecanada.ca/easybuild/software/2017/Core/scipy-stack/2019a/lib/python3.7/site-packages (from tensorflow_gpu==2.3.0+computecanada) (1.16.0)
Requirement already satisfied: six>=1.12.0 in /localscratch/yinan.29019375.0/env/lib/python3.7/site-packages (from tensorflow_gpu==2.3.0+computecanada) (1.16.0+computecanada)
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/nix/avx2/h5py-2.10.0+computecanada-cp37-cp37m-linux_x86_64.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/opt_einsum-3.3.0+computecanada-py3-none-any.whl
Requirement already satisfied: termcolor>=1.1.0 in /localscratch/yinan.29019375.0/env/lib/python3.7/site-packages (from tensorflow_gpu==2.3.0+computecanada) (1.1.0+computecanada)
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/grpcio-1.38.0+computecanada-cp37-cp37m-linux_x86_64.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/nix/generic/scipy-1.4.1+computecanada-cp37-cp37m-linux_x86_64.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/absl_py-1.0.0+computecanada-py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/gast-0.3.3+computecanada-py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/astunparse-1.6.3+computecanada-py2.py3-none-any.whl
Requirement already satisfied: wheel>=0.26 in /localscratch/yinan.29019375.0/env/lib/python3.7/site-packages (from tensorflow_gpu==2.3.0+computecanada) (0.33.4)
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/Keras_Preprocessing-1.1.2+computecanada-py3-none-any.whl
Requirement already satisfied: protobuf>=3.9.2 in /localscratch/yinan.29019375.0/env/lib/python3.7/site-packages (from tensorflow_gpu==2.3.0+computecanada) (3.19.4+computecanada)
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/tensorboard_plugin_wit-1.8.0+computecanada-py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/Markdown-3.3.6+computecanada-py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/google_auth-2.3.3+computecanada-py2.py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/tensorboard_data_server-0.6.1+computecanada-py3-none-linux_x86_64.whl
Requirement already satisfied: setuptools>=41.0.0 in /localscratch/yinan.29019375.0/env/lib/python3.7/site-packages (from tensorboard<3,>=2.3.0->tensorflow_gpu==2.3.0+computecanada) (41.0.1)
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/google_auth_oauthlib-0.4.6+computecanada-py2.py3-none-any.whl
Requirement already satisfied: requests<3,>=2.21.0 in /localscratch/yinan.29019375.0/env/lib/python3.7/site-packages (from tensorboard<3,>=2.3.0->tensorflow_gpu==2.3.0+computecanada) (2.27.1+computecanada)
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/Werkzeug-2.0.3+computecanada-py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/rsa-4.8+computecanada-py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/pyasn1_modules-0.2.8+computecanada-py2.py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/cachetools-4.2.4+computecanada-py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/requests_oauthlib-1.3.0+computecanada-py2.py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/importlib_metadata-4.10.1+computecanada-py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/zipp-3.7.0+computecanada-py3-none-any.whl
Requirement already satisfied: typing-extensions>=3.6.4 in /localscratch/yinan.29019375.0/env/lib/python3.7/site-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard<3,>=2.3.0->tensorflow_gpu==2.3.0+computecanada) (4.0.1+computecanada)
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/pyasn1-0.4.8+computecanada-py2.py3-none-any.whl
Requirement already satisfied: certifi>=2017.4.17 in /cvmfs/soft.computecanada.ca/easybuild/software/2017/Core/scipy-stack/2019a/lib/python3.7/site-packages (from requests<3,>=2.21.0->tensorboard<3,>=2.3.0->tensorflow_gpu==2.3.0+computecanada) (2018.11.29)
Requirement already satisfied: urllib3<1.27,>=1.21.1 in /localscratch/yinan.29019375.0/env/lib/python3.7/site-packages (from requests<3,>=2.21.0->tensorboard<3,>=2.3.0->tensorflow_gpu==2.3.0+computecanada) (1.26.8+computecanada)
Requirement already satisfied: idna<4,>=2.5 in /cvmfs/soft.computecanada.ca/easybuild/software/2017/Core/scipy-stack/2019a/lib/python3.7/site-packages (from requests<3,>=2.21.0->tensorboard<3,>=2.3.0->tensorflow_gpu==2.3.0+computecanada) (2.8)
Requirement already satisfied: charset-normalizer~=2.0.0 in /localscratch/yinan.29019375.0/env/lib/python3.7/site-packages (from requests<3,>=2.21.0->tensorboard<3,>=2.3.0->tensorflow_gpu==2.3.0+computecanada) (2.0.12+computecanada)
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/oauthlib-3.1.1+computecanada-py2.py3-none-any.whl
Installing collected packages: pyasn1, zipp, rsa, pyasn1-modules, oauthlib, cachetools, requests-oauthlib, importlib-metadata, google-auth, werkzeug, tensorboard-plugin-wit, tensorboard-data-server, markdown, grpcio, google-auth-oauthlib, absl-py, wrapt, tensorflow-estimator, tensorboard, scipy, opt-einsum, keras-preprocessing, h5py, google-pasta, gast, astunparse, tensorflow-gpu
  Attempting uninstall: pyasn1
    Found existing installation: pyasn1 0.4.3
    Not uninstalling pyasn1 at /cvmfs/soft.computecanada.ca/easybuild/software/2017/Core/scipy-stack/2019a/lib/python3.7/site-packages, outside environment /localscratch/yinan.29019375.0/env
    Can't uninstall 'pyasn1'. No files were found to uninstall.
  Attempting uninstall: zipp
    Found existing installation: zipp 0.3.3
    Not uninstalling zipp at /cvmfs/soft.computecanada.ca/easybuild/software/2017/Core/scipy-stack/2019a/lib/python3.7/site-packages, outside environment /localscratch/yinan.29019375.0/env
    Can't uninstall 'zipp'. No files were found to uninstall.
  Attempting uninstall: importlib-metadata
    Found existing installation: importlib-metadata 0.8
    Not uninstalling importlib-metadata at /cvmfs/soft.computecanada.ca/easybuild/software/2017/Core/scipy-stack/2019a/lib/python3.7/site-packages, outside environment /localscratch/yinan.29019375.0/env
    Can't uninstall 'importlib-metadata'. No files were found to uninstall.
  Attempting uninstall: scipy
    Found existing installation: scipy 1.2.0
    Not uninstalling scipy at /cvmfs/soft.computecanada.ca/easybuild/software/2017/Core/scipy-stack/2019a/lib/python3.7/site-packages, outside environment /localscratch/yinan.29019375.0/env
    Can't uninstall 'scipy'. No files were found to uninstall.
Successfully installed absl-py-1.0.0+computecanada astunparse-1.6.3+computecanada cachetools-4.2.4+computecanada gast-0.3.3+computecanada google-auth-2.3.3+computecanada google-auth-oauthlib-0.4.6+computecanada google-pasta-0.2.0+computecanada grpcio-1.38.0+computecanada h5py-2.10.0+computecanada importlib-metadata-4.10.1+computecanada keras-preprocessing-1.1.2+computecanada markdown-3.3.6+computecanada oauthlib-3.1.1+computecanada opt-einsum-3.3.0+computecanada pyasn1-0.4.8+computecanada pyasn1-modules-0.2.8+computecanada requests-oauthlib-1.3.0+computecanada rsa-4.8+computecanada scipy-1.4.1+computecanada tensorboard-2.8.0+computecanada tensorboard-data-server-0.6.1+computecanada tensorboard-plugin-wit-1.8.0+computecanada tensorflow-estimator-2.3.0+computecanada tensorflow-gpu-2.3.0+computecanada werkzeug-2.0.3+computecanada wrapt-1.11.2+computecanada zipp-3.7.0+computecanada
Looking in links: /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/nix/avx2, /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/nix/generic, /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/keras-2.8.0+computecanada-py2.py3-none-any.whl
Installing collected packages: Keras
Successfully installed Keras-2.8.0+computecanada
Looking in links: /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/nix/avx2, /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/nix/generic, /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/urllib3-1.26.7+computecanada-py2.py3-none-any.whl
Installing collected packages: urllib3
  Attempting uninstall: urllib3
    Found existing installation: urllib3 1.26.8+computecanada
    Uninstalling urllib3-1.26.8+computecanada:
      Successfully uninstalled urllib3-1.26.8+computecanada
Successfully installed urllib3-1.26.7+computecanada
Looking in links: /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/nix/avx2, /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/nix/generic, /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/nltk-3.7+computecanada-py3-none-any.whl
Requirement already satisfied: joblib in /localscratch/yinan.29019375.0/env/lib/python3.7/site-packages (from nltk) (1.1.0+computecanada)
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/nltk-3.6.5+computecanada-py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/nltk-3.6.3+computecanada-py3-none-any.whl
Requirement already satisfied: click in /localscratch/yinan.29019375.0/env/lib/python3.7/site-packages (from nltk) (8.0.4+computecanada)
Requirement already satisfied: regex in /localscratch/yinan.29019375.0/env/lib/python3.7/site-packages (from nltk) (2020.11.13+computecanada)
Requirement already satisfied: tqdm in /localscratch/yinan.29019375.0/env/lib/python3.7/site-packages (from nltk) (4.63.0+computecanada)
Requirement already satisfied: importlib-metadata in /localscratch/yinan.29019375.0/env/lib/python3.7/site-packages (from click->nltk) (4.10.1+computecanada)
Requirement already satisfied: typing-extensions>=3.6.4 in /localscratch/yinan.29019375.0/env/lib/python3.7/site-packages (from importlib-metadata->click->nltk) (4.0.1+computecanada)
Requirement already satisfied: zipp>=0.5 in /localscratch/yinan.29019375.0/env/lib/python3.7/site-packages (from importlib-metadata->click->nltk) (3.7.0+computecanada)
Installing collected packages: nltk
Successfully installed nltk-3.6.3+computecanada
Looking in links: /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/nix/avx2, /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/nix/generic, /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/scikit_learn-0.22.1+computecanada-cp37-cp37m-linux_x86_64.whl
Requirement already satisfied: numpy>=1.11.0 in /cvmfs/soft.computecanada.ca/easybuild/software/2017/Core/scipy-stack/2019a/lib/python3.7/site-packages (from scikit-learn==0.22.1) (1.16.0)
Requirement already satisfied: scipy>=0.17.0 in /localscratch/yinan.29019375.0/env/lib/python3.7/site-packages (from scikit-learn==0.22.1) (1.4.1+computecanada)
Requirement already satisfied: joblib>=0.11 in /localscratch/yinan.29019375.0/env/lib/python3.7/site-packages (from scikit-learn==0.22.1) (1.1.0+computecanada)
Installing collected packages: scikit-learn
Successfully installed scikit-learn-0.22.1+computecanada
Looking in links: /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/nix/avx2, /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/nix/generic, /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic
Requirement already satisfied: tokenizers==0.5.2 in /localscratch/yinan.29019375.0/env/lib/python3.7/site-packages (0.5.2+computecanada)
wandb: Appending key for api.wandb.ai to your netrc file: /home/yinan/.netrc
Starting Task
2022-03-18 21:23:37.771449: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1
[nltk_data] Downloading package stopwords to /home/yinan/nltk_data...
[nltk_data]   Package stopwords is already up-to-date!
[nltk_data] Downloading package wordnet to /home/yinan/nltk_data...
[nltk_data]   Package wordnet is already up-to-date!
wandb: Currently logged in as: yinanazhou (use `wandb login --relogin` to force relogin)
wandb: wandb version 0.12.11 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
2022-03-18 21:23:46.721708: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1
wandb: Tracking run with wandb version 0.12.5
wandb: Syncing run breezy-shape-2
wandb: â­ï¸ View project at https://wandb.ai/yinanazhou/xl_512_bs_8_lr_1e06_es_10_lc_False_nr_False_sr_False_stem_False_lemma_False_repeat_1_fold_1
wandb: ðŸš€ View run at https://wandb.ai/yinanazhou/xl_512_bs_8_lr_1e06_es_10_lc_False_nr_False_sr_False_stem_False_lemma_False_repeat_1_fold_1/runs/3lqwzt94
wandb: Run data is saved locally in /project/6002780/yinan/Thesis_MER_Lyrics/lyric-emotion/wandb/run-20220318_212344-3lqwzt94
wandb: Run `wandb offline` to turn off syncing.

Validation loss decreased (inf --> 1.432649).  Saving model ...
Validation loss decreased (1.432649 --> 1.413243).  Saving model ...
Validation loss decreased (1.413243 --> 1.396893).  Saving model ...
Validation loss decreased (1.396893 --> 1.383810).  Saving model ...
Validation loss decreased (1.383810 --> 1.373484).  Saving model ...
Validation loss decreased (1.373484 --> 1.365146).  Saving model ...
Validation loss decreased (1.365146 --> 1.357312).  Saving model ...
Validation loss decreased (1.357312 --> 1.350908).  Saving model ...
Validation loss decreased (1.350908 --> 1.345829).  Saving model ...
Validation loss decreased (1.345829 --> 1.339794).  Saving model ...
Validation loss decreased (1.339794 --> 1.333172).  Saving model ...
Validation loss decreased (1.333172 --> 1.327449).  Saving model ...
Validation loss decreased (1.327449 --> 1.320892).  Saving model ...
Validation loss decreased (1.320892 --> 1.315636).  Saving model ...
Validation loss decreased (1.315636 --> 1.309583).  Saving model ...
Validation loss decreased (1.309583 --> 1.302805).  Saving model ...
Validation loss decreased (1.302805 --> 1.296959).  Saving model ...
Validation loss decreased (1.296959 --> 1.291311).  Saving model ...
Validation loss decreased (1.291311 --> 1.284247).  Saving model ...
Validation loss decreased (1.284247 --> 1.275604).  Saving model ...
Validation loss decreased (1.275604 --> 1.268060).  Saving model ...
Validation loss decreased (1.268060 --> 1.260894).  Saving model ...
Validation loss decreased (1.260894 --> 1.255024).  Saving model ...
Validation loss decreased (1.255024 --> 1.245388).  Saving model ...
Validation loss decreased (1.245388 --> 1.236527).  Saving model ...
Validation loss decreased (1.236527 --> 1.228766).  Saving model ...
Validation loss decreased (1.228766 --> 1.221822).  Saving model ...
Validation loss decreased (1.221822 --> 1.215460).  Saving model ...
Validation loss decreased (1.215460 --> 1.208375).  Saving model ...
Validation loss decreased (1.208375 --> 1.202478).  Saving model ...
Validation loss decreased (1.202478 --> 1.195194).  Saving model ...
Validation loss decreased (1.195194 --> 1.190426).  Saving model ...
Validation loss decreased (1.190426 --> 1.188564).  Saving model ...
Validation loss decreased (1.188564 --> 1.181541).  Saving model ...
Validation loss decreased (1.181541 --> 1.174907).  Saving model ...
Validation loss decreased (1.174907 --> 1.169635).  Saving model ...
Validation loss decreased (1.169635 --> 1.167549).  Saving model ...
Validation loss decreased (1.167549 --> 1.159069).  Saving model ...
Validation loss decreased (1.159069 --> 1.155852).  Saving model ...
Validation loss decreased (1.155852 --> 1.150329).  Saving model ...
Validation loss decreased (1.150329 --> 1.144300).  Saving model ...
Validation loss decreased (1.144300 --> 1.139620).  Saving model ...
Validation loss decreased (1.139620 --> 1.136095).  Saving model ...
Validation loss decreased (1.136095 --> 1.131987).  Saving model ...
Validation loss decreased (1.131987 --> 1.128156).  Saving model ...
Validation loss decreased (1.128156 --> 1.122394).  Saving model ...
Validation loss decreased (1.122394 --> 1.118459).  Saving model ...
Validation loss decreased (1.118459 --> 1.114139).  Saving model ...
Validation loss decreased (1.114139 --> 1.108813).  Saving model ...
Validation loss decreased (1.108813 --> 1.106998).  Saving model ...
Validation loss decreased (1.106998 --> 1.100536).  Saving model ...
Validation loss decreased (1.100536 --> 1.097067).  Saving model ...
Validation loss decreased (1.097067 --> 1.094954).  Saving model ...
Validation loss decreased (1.094954 --> 1.090739).  Saving model ...
Validation loss decreased (1.090739 --> 1.090494).  Saving model ...
Validation loss decreased (1.090494 --> 1.086035).  Saving model ...
Validation loss decreased (1.086035 --> 1.082550).  Saving model ...
Validation loss decreased (1.082550 --> 1.079738).  Saving model ...
Validation loss decreased (1.079738 --> 1.076174).  Saving model ...
Validation loss decreased (1.076174 --> 1.071831).  Saving model ...
Validation loss decreased (1.071831 --> 1.068904).  Saving model ...
Validation loss decreased (1.068904 --> 1.066291).  Saving model ...
Validation loss decreased (1.066291 --> 1.063490).  Saving model ...
Validation loss decreased (1.063490 --> 1.061816).  Saving model ...
EarlyStopping counter: 1 out of 10.0
Validation loss decreased (1.061816 --> 1.058415).  Saving model ...
Validation loss decreased (1.058415 --> 1.054562).  Saving model ...
Validation loss decreased (1.054562 --> 1.054312).  Saving model ...
Validation loss decreased (1.054312 --> 1.051142).  Saving model ...
Validation loss decreased (1.051142 --> 1.046887).  Saving model ...
Validation loss decreased (1.046887 --> 1.045249).  Saving model ...
Validation loss decreased (1.045249 --> 1.042753).  Saving model ...
Validation loss decreased (1.042753 --> 1.042324).  Saving model ...
Validation loss decreased (1.042324 --> 1.037681).  Saving model ...
Validation loss decreased (1.037681 --> 1.037470).  Saving model ...
Validation loss decreased (1.037470 --> 1.035747).  Saving model ...
Validation loss decreased (1.035747 --> 1.035413).  Saving model ...
Validation loss decreased (1.035413 --> 1.031903).  Saving model ...
Validation loss decreased (1.031903 --> 1.030121).  Saving model ...
Validation loss decreased (1.030121 --> 1.026242).  Saving model ...
EarlyStopping counter: 1 out of 10.0
Validation loss decreased (1.026242 --> 1.023637).  Saving model ...
EarlyStopping counter: 1 out of 10.0
Validation loss decreased (1.023637 --> 1.020683).  Saving model ...
Validation loss decreased (1.020683 --> 1.020144).  Saving model ...
Validation loss decreased (1.020144 --> 1.016497).  Saving model ...
Validation loss decreased (1.016497 --> 1.016310).  Saving model ...
EarlyStopping counter: 1 out of 10.0
Validation loss decreased (1.016310 --> 1.014816).  Saving model ...
EarlyStopping counter: 1 out of 10.0
Validation loss decreased (1.014816 --> 1.012580).  Saving model ...
Validation loss decreased (1.012580 --> 1.011412).  Saving model ...
Validation loss decreased (1.011412 --> 1.008186).  Saving model ...
EarlyStopping counter: 1 out of 10.0
EarlyStopping counter: 2 out of 10.0
Validation loss decreased (1.008186 --> 1.006308).  Saving model ...
EarlyStopping counter: 1 out of 10.0
Validation loss decreased (1.006308 --> 1.006186).  Saving model ...
Validation loss decreased (1.006186 --> 1.005985).  Saving model ...
EarlyStopping counter: 1 out of 10.0
Validation loss decreased (1.005985 --> 1.004365).  Saving model ...
Validation loss decreased (1.004365 --> 1.003041).  Saving model ...
Validation loss decreased (1.003041 --> 1.002498).  Saving model ...
EarlyStopping counter: 1 out of 10.0
Validation loss decreased (1.002498 --> 1.002447).  Saving model ...
Validation loss decreased (1.002447 --> 1.001717).  Saving model ...
EarlyStopping counter: 1 out of 10.0
Validation loss decreased (1.001717 --> 1.000461).  Saving model ...
Validation loss decreased (1.000461 --> 0.996587).  Saving model ...
Validation loss decreased (0.996587 --> 0.995678).  Saving model ...
EarlyStopping counter: 1 out of 10.0
Validation loss decreased (0.995678 --> 0.995502).  Saving model ...
Validation loss decreased (0.995502 --> 0.994498).  Saving model ...
EarlyStopping counter: 1 out of 10.0
EarlyStopping counter: 2 out of 10.0
Validation loss decreased (0.994498 --> 0.993227).  Saving model ...
Validation loss decreased (0.993227 --> 0.992971).  Saving model ...
EarlyStopping counter: 1 out of 10.0
EarlyStopping counter: 2 out of 10.0
EarlyStopping counter: 3 out of 10.0
EarlyStopping counter: 4 out of 10.0
EarlyStopping counter: 5 out of 10.0
EarlyStopping counter: 6 out of 10.0
EarlyStopping counter: 7 out of 10.0
EarlyStopping counter: 8 out of 10.0
Validation loss decreased (0.992971 --> 0.992959).  Saving model ...
Validation loss decreased (0.992959 --> 0.991542).  Saving model ...
EarlyStopping counter: 1 out of 10.0
EarlyStopping counter: 2 out of 10.0
EarlyStopping counter: 3 out of 10.0
EarlyStopping counter: 4 out of 10.0
EarlyStopping counter: 5 out of 10.0
EarlyStopping counter: 6 out of 10.0
Validation loss decreased (0.991542 --> 0.990879).  Saving model ...
EarlyStopping counter: 1 out of 10.0
EarlyStopping counter: 2 out of 10.0
EarlyStopping counter: 3 out of 10.0
EarlyStopping counter: 4 out of 10.0
EarlyStopping counter: 5 out of 10.0
EarlyStopping counter: 6 out of 10.0
EarlyStopping counter: 7 out of 10.0
EarlyStopping counter: 8 out of 10.0
EarlyStopping counter: 9 out of 10.0
EarlyStopping counter: 10 out of 10.0
/localscratch/yinan.29019375.0/env/lib/python3.7/site-packages/torch/nn/functional.py:1794: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.
  warnings.warn("nn.functional.tanh is deprecated. Use torch.tanh instead.")
/localscratch/yinan.29019375.0/env/lib/python3.7/site-packages/transformers/optimization.py:155: UserWarning: This overload of add_ is deprecated:
	add_(Number alpha, Tensor other)
Consider using one of the following signatures instead:
	add_(Tensor other, *, Number alpha) (Triggered internally at  ../torch/csrc/utils/python_arg_parser.cpp:1025.)
  exp_avg.mul_(beta1).add_(1.0 - beta1, grad)
wandb: Waiting for W&B process to finish, PID 139252... (success).
wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: \ 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: | 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: / 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: \ 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: | 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: / 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: \ 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: | 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: / 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb:                                                                                
wandb: Run history:
wandb:     e_F1 â–â–‚â–ƒâ–„â–…â–…â–…â–†â–†â–†â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ
wandb:   e_loss â–ˆâ–ˆâ–‡â–‡â–†â–†â–…â–…â–„â–„â–„â–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–‚â–‚â–‚â–‚â–‚â–‚â–‚â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:     t_F1 â–â–‚â–‚â–ƒâ–ƒâ–„â–„â–…â–…â–…â–…â–…â–…â–…â–…â–†â–†â–†â–†â–†â–†â–†â–†â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ
wandb:   t_loss â–ˆâ–ˆâ–‡â–‡â–‡â–†â–†â–†â–…â–…â–…â–…â–…â–„â–„â–„â–„â–„â–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–‚â–ƒâ–‚â–‚â–‚â–‚â–‚â–‚â–‚â–â–â–â–â–
wandb: 
wandb: Run summary:
wandb:     e_F1 59.95376
wandb:   e_loss 0.99448
wandb:     t_F1 75.23264
wandb:   t_loss 0.67978
wandb: 
wandb: Synced 4 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Synced breezy-shape-2: https://wandb.ai/yinanazhou/xl_512_bs_8_lr_1e06_es_10_lc_False_nr_False_sr_False_stem_False_lemma_False_repeat_1_fold_1/runs/3lqwzt94
wandb: Find logs at: ./wandb/run-20220318_212344-3lqwzt94/logs/debug.log
wandb: 

wandb: wandb version 0.12.11 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
2022-03-18 22:58:16.180914: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1
wandb: Tracking run with wandb version 0.12.5
wandb: Syncing run pretty-deluge-2
wandb: â­ï¸ View project at https://wandb.ai/yinanazhou/xl_512_bs_8_lr_1e06_es_10_lc_False_nr_False_sr_False_stem_False_lemma_False_repeat_1_fold_2
wandb: ðŸš€ View run at https://wandb.ai/yinanazhou/xl_512_bs_8_lr_1e06_es_10_lc_False_nr_False_sr_False_stem_False_lemma_False_repeat_1_fold_2/runs/cygmy8id
wandb: Run data is saved locally in /project/6002780/yinan/Thesis_MER_Lyrics/lyric-emotion/wandb/run-20220318_225813-cygmy8id
wandb: Run `wandb offline` to turn off syncing.

Validation loss decreased (inf --> 1.613185).  Saving model ...
Validation loss decreased (1.613185 --> 1.538815).  Saving model ...
Validation loss decreased (1.538815 --> 1.485845).  Saving model ...
Validation loss decreased (1.485845 --> 1.449737).  Saving model ...
Validation loss decreased (1.449737 --> 1.420411).  Saving model ...
Validation loss decreased (1.420411 --> 1.401466).  Saving model ...
Validation loss decreased (1.401466 --> 1.387579).  Saving model ...
Validation loss decreased (1.387579 --> 1.376988).  Saving model ...
Validation loss decreased (1.376988 --> 1.369138).  Saving model ...
Validation loss decreased (1.369138 --> 1.361830).  Saving model ...
Validation loss decreased (1.361830 --> 1.354103).  Saving model ...
Validation loss decreased (1.354103 --> 1.346615).  Saving model ...
Validation loss decreased (1.346615 --> 1.339364).  Saving model ...
Validation loss decreased (1.339364 --> 1.331687).  Saving model ...
Validation loss decreased (1.331687 --> 1.322338).  Saving model ...
Validation loss decreased (1.322338 --> 1.314795).  Saving model ...
Validation loss decreased (1.314795 --> 1.307084).  Saving model ...
Validation loss decreased (1.307084 --> 1.299816).  Saving model ...
Validation loss decreased (1.299816 --> 1.293954).  Saving model ...
Validation loss decreased (1.293954 --> 1.285947).  Saving model ...
Validation loss decreased (1.285947 --> 1.276481).  Saving model ...
Validation loss decreased (1.276481 --> 1.265720).  Saving model ...
Validation loss decreased (1.265720 --> 1.255636).  Saving model ...
Validation loss decreased (1.255636 --> 1.246108).  Saving model ...
Validation loss decreased (1.246108 --> 1.236743).  Saving model ...
Validation loss decreased (1.236743 --> 1.229200).  Saving model ...
Validation loss decreased (1.229200 --> 1.221771).  Saving model ...
Validation loss decreased (1.221771 --> 1.213443).  Saving model ...
Validation loss decreased (1.213443 --> 1.205443).  Saving model ...
Validation loss decreased (1.205443 --> 1.197146).  Saving model ...
Validation loss decreased (1.197146 --> 1.189846).  Saving model ...
Validation loss decreased (1.189846 --> 1.182064).  Saving model ...
Validation loss decreased (1.182064 --> 1.176058).  Saving model ...
Validation loss decreased (1.176058 --> 1.169515).  Saving model ...
Validation loss decreased (1.169515 --> 1.161782).  Saving model ...
Validation loss decreased (1.161782 --> 1.155575).  Saving model ...
Validation loss decreased (1.155575 --> 1.150068).  Saving model ...
Validation loss decreased (1.150068 --> 1.143650).  Saving model ...
Validation loss decreased (1.143650 --> 1.137251).  Saving model ...
Validation loss decreased (1.137251 --> 1.131131).  Saving model ...
Validation loss decreased (1.131131 --> 1.123623).  Saving model ...
Validation loss decreased (1.123623 --> 1.116024).  Saving model ...
Validation loss decreased (1.116024 --> 1.109678).  Saving model ...
Validation loss decreased (1.109678 --> 1.105437).  Saving model ...
Validation loss decreased (1.105437 --> 1.100072).  Saving model ...
Validation loss decreased (1.100072 --> 1.095244).  Saving model ...
Validation loss decreased (1.095244 --> 1.090798).  Saving model ...
Validation loss decreased (1.090798 --> 1.089190).  Saving model ...
Validation loss decreased (1.089190 --> 1.082886).  Saving model ...
Validation loss decreased (1.082886 --> 1.078582).  Saving model ...
Validation loss decreased (1.078582 --> 1.071859).  Saving model ...
Validation loss decreased (1.071859 --> 1.067244).  Saving model ...
Validation loss decreased (1.067244 --> 1.060424).  Saving model ...
Validation loss decreased (1.060424 --> 1.055824).  Saving model ...
Validation loss decreased (1.055824 --> 1.052486).  Saving model ...
Validation loss decreased (1.052486 --> 1.048450).  Saving model ...
Validation loss decreased (1.048450 --> 1.042326).  Saving model ...
Validation loss decreased (1.042326 --> 1.038275).  Saving model ...
Validation loss decreased (1.038275 --> 1.037770).  Saving model ...
Validation loss decreased (1.037770 --> 1.034177).  Saving model ...
Validation loss decreased (1.034177 --> 1.032371).  Saving model ...
Validation loss decreased (1.032371 --> 1.029354).  Saving model ...
Validation loss decreased (1.029354 --> 1.023871).  Saving model ...
Validation loss decreased (1.023871 --> 1.019257).  Saving model ...
Validation loss decreased (1.019257 --> 1.013276).  Saving model ...
Validation loss decreased (1.013276 --> 1.008214).  Saving model ...
Validation loss decreased (1.008214 --> 1.006495).  Saving model ...
Validation loss decreased (1.006495 --> 1.003677).  Saving model ...
Validation loss decreased (1.003677 --> 0.998024).  Saving model ...
Validation loss decreased (0.998024 --> 0.994948).  Saving model ...
Validation loss decreased (0.994948 --> 0.990929).  Saving model ...
Validation loss decreased (0.990929 --> 0.988119).  Saving model ...
Validation loss decreased (0.988119 --> 0.986825).  Saving model ...
Validation loss decreased (0.986825 --> 0.983095).  Saving model ...
Validation loss decreased (0.983095 --> 0.981816).  Saving model ...
Validation loss decreased (0.981816 --> 0.977795).  Saving model ...
Validation loss decreased (0.977795 --> 0.975156).  Saving model ...
Validation loss decreased (0.975156 --> 0.973789).  Saving model ...
Validation loss decreased (0.973789 --> 0.970014).  Saving model ...
Validation loss decreased (0.970014 --> 0.969741).  Saving model ...
Validation loss decreased (0.969741 --> 0.967009).  Saving model ...
Validation loss decreased (0.967009 --> 0.963660).  Saving model ...
EarlyStopping counter: 1 out of 10.0
Validation loss decreased (0.963660 --> 0.963507).  Saving model ...
Validation loss decreased (0.963507 --> 0.960333).  Saving model ...
Validation loss decreased (0.960333 --> 0.959126).  Saving model ...
Validation loss decreased (0.959126 --> 0.958302).  Saving model ...
Validation loss decreased (0.958302 --> 0.957813).  Saving model ...
Validation loss decreased (0.957813 --> 0.953441).  Saving model ...
Validation loss decreased (0.953441 --> 0.952087).  Saving model ...
Validation loss decreased (0.952087 --> 0.949565).  Saving model ...
Validation loss decreased (0.949565 --> 0.948852).  Saving model ...
Validation loss decreased (0.948852 --> 0.948527).  Saving model ...
Validation loss decreased (0.948527 --> 0.943121).  Saving model ...
Validation loss decreased (0.943121 --> 0.943102).  Saving model ...
EarlyStopping counter: 1 out of 10.0
EarlyStopping counter: 2 out of 10.0
Validation loss decreased (0.943102 --> 0.941460).  Saving model ...
Validation loss decreased (0.941460 --> 0.939590).  Saving model ...
Validation loss decreased (0.939590 --> 0.938505).  Saving model ...
EarlyStopping counter: 1 out of 10.0
Validation loss decreased (0.938505 --> 0.938129).  Saving model ...
Validation loss decreased (0.938129 --> 0.937745).  Saving model ...
Validation loss decreased (0.937745 --> 0.936567).  Saving model ...
EarlyStopping counter: 1 out of 10.0
Validation loss decreased (0.936567 --> 0.934888).  Saving model ...
Validation loss decreased (0.934888 --> 0.934874).  Saving model ...
EarlyStopping counter: 1 out of 10.0
EarlyStopping counter: 2 out of 10.0
EarlyStopping counter: 3 out of 10.0
EarlyStopping counter: 4 out of 10.0
Validation loss decreased (0.934874 --> 0.933533).  Saving model ...
Validation loss decreased (0.933533 --> 0.933230).  Saving model ...
EarlyStopping counter: 1 out of 10.0
Validation loss decreased (0.933230 --> 0.932324).  Saving model ...
Validation loss decreased (0.932324 --> 0.930899).  Saving model ...
Validation loss decreased (0.930899 --> 0.930191).  Saving model ...
EarlyStopping counter: 1 out of 10.0
EarlyStopping counter: 2 out of 10.0
EarlyStopping counter: 3 out of 10.0
EarlyStopping counter: 4 out of 10.0
EarlyStopping counter: 5 out of 10.0
EarlyStopping counter: 6 out of 10.0
EarlyStopping counter: 7 out of 10.0
EarlyStopping counter: 8 out of 10.0
EarlyStopping counter: 9 out of 10.0
EarlyStopping counter: 10 out of 10.0
/localscratch/yinan.29019375.0/env/lib/python3.7/site-packages/torch/nn/functional.py:1794: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.
  warnings.warn("nn.functional.tanh is deprecated. Use torch.tanh instead.")
wandb: Waiting for W&B process to finish, PID 144313... (success).
wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: \ 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: | 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: / 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: \ 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: | 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: / 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: \ 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: | 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: / 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: \ 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb:                                                                                
wandb: Run history:
wandb:     e_F1 â–â–â–‚â–„â–…â–†â–†â–†â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ
wandb:   e_loss â–ˆâ–†â–†â–…â–…â–…â–…â–„â–„â–„â–„â–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:     t_F1 â–â–â–‚â–‚â–ƒâ–„â–„â–„â–„â–…â–…â–…â–…â–†â–†â–†â–†â–†â–†â–‡â–†â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ
wandb:   t_loss â–ˆâ–‡â–†â–†â–†â–†â–…â–…â–…â–…â–…â–…â–„â–„â–„â–„â–„â–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–‚â–ƒâ–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–â–â–â–â–
wandb: 
wandb: Run summary:
wandb:     e_F1 59.35266
wandb:   e_loss 0.93485
wandb:     t_F1 73.33621
wandb:   t_loss 0.75185
wandb: 
wandb: Synced 4 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Synced pretty-deluge-2: https://wandb.ai/yinanazhou/xl_512_bs_8_lr_1e06_es_10_lc_False_nr_False_sr_False_stem_False_lemma_False_repeat_1_fold_2/runs/cygmy8id
wandb: Find logs at: ./wandb/run-20220318_225813-cygmy8id/logs/debug.log
wandb: 

wandb: wandb version 0.12.11 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
2022-03-19 00:21:21.401849: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1
wandb: Tracking run with wandb version 0.12.5
wandb: Syncing run driven-firefly-2
wandb: â­ï¸ View project at https://wandb.ai/yinanazhou/xl_512_bs_8_lr_1e06_es_10_lc_False_nr_False_sr_False_stem_False_lemma_False_repeat_2_fold_1
wandb: ðŸš€ View run at https://wandb.ai/yinanazhou/xl_512_bs_8_lr_1e06_es_10_lc_False_nr_False_sr_False_stem_False_lemma_False_repeat_2_fold_1/runs/1yrvt17a
wandb: Run data is saved locally in /project/6002780/yinan/Thesis_MER_Lyrics/lyric-emotion/wandb/run-20220319_002118-1yrvt17a
wandb: Run `wandb offline` to turn off syncing.

Validation loss decreased (inf --> 1.430685).  Saving model ...
Validation loss decreased (1.430685 --> 1.414688).  Saving model ...
Validation loss decreased (1.414688 --> 1.401011).  Saving model ...
Validation loss decreased (1.401011 --> 1.390075).  Saving model ...
Validation loss decreased (1.390075 --> 1.381422).  Saving model ...
Validation loss decreased (1.381422 --> 1.373703).  Saving model ...
Validation loss decreased (1.373703 --> 1.365951).  Saving model ...
Validation loss decreased (1.365951 --> 1.359560).  Saving model ...
Validation loss decreased (1.359560 --> 1.353158).  Saving model ...
Validation loss decreased (1.353158 --> 1.346800).  Saving model ...
Validation loss decreased (1.346800 --> 1.340225).  Saving model ...
Validation loss decreased (1.340225 --> 1.333635).  Saving model ...
Validation loss decreased (1.333635 --> 1.326670).  Saving model ...
Validation loss decreased (1.326670 --> 1.320321).  Saving model ...
Validation loss decreased (1.320321 --> 1.313247).  Saving model ...
Validation loss decreased (1.313247 --> 1.305161).  Saving model ...
Validation loss decreased (1.305161 --> 1.297316).  Saving model ...
Validation loss decreased (1.297316 --> 1.288916).  Saving model ...
Validation loss decreased (1.288916 --> 1.281345).  Saving model ...
Validation loss decreased (1.281345 --> 1.273016).  Saving model ...
Validation loss decreased (1.273016 --> 1.265385).  Saving model ...
Validation loss decreased (1.265385 --> 1.257492).  Saving model ...
Validation loss decreased (1.257492 --> 1.250221).  Saving model ...
Validation loss decreased (1.250221 --> 1.242801).  Saving model ...
Validation loss decreased (1.242801 --> 1.235154).  Saving model ...
Validation loss decreased (1.235154 --> 1.228188).  Saving model ...
Validation loss decreased (1.228188 --> 1.221934).  Saving model ...
Validation loss decreased (1.221934 --> 1.215794).  Saving model ...
Validation loss decreased (1.215794 --> 1.208631).  Saving model ...
Validation loss decreased (1.208631 --> 1.202682).  Saving model ...
Validation loss decreased (1.202682 --> 1.195970).  Saving model ...
Validation loss decreased (1.195970 --> 1.188268).  Saving model ...
Validation loss decreased (1.188268 --> 1.181443).  Saving model ...
Validation loss decreased (1.181443 --> 1.175239).  Saving model ...
Validation loss decreased (1.175239 --> 1.169036).  Saving model ...
Validation loss decreased (1.169036 --> 1.162754).  Saving model ...
Validation loss decreased (1.162754 --> 1.155502).  Saving model ...
Validation loss decreased (1.155502 --> 1.148349).  Saving model ...
Validation loss decreased (1.148349 --> 1.142000).  Saving model ...
Validation loss decreased (1.142000 --> 1.136201).  Saving model ...
Validation loss decreased (1.136201 --> 1.128691).  Saving model ...
Validation loss decreased (1.128691 --> 1.122664).  Saving model ...
Validation loss decreased (1.122664 --> 1.116729).  Saving model ...
Validation loss decreased (1.116729 --> 1.111627).  Saving model ...
Validation loss decreased (1.111627 --> 1.105988).  Saving model ...
Validation loss decreased (1.105988 --> 1.101066).  Saving model ...
Validation loss decreased (1.101066 --> 1.096720).  Saving model ...
Validation loss decreased (1.096720 --> 1.091979).  Saving model ...
Validation loss decreased (1.091979 --> 1.087020).  Saving model ...
Validation loss decreased (1.087020 --> 1.081367).  Saving model ...
Validation loss decreased (1.081367 --> 1.075848).  Saving model ...
Validation loss decreased (1.075848 --> 1.070626).  Saving model ...
Validation loss decreased (1.070626 --> 1.067779).  Saving model ...
Validation loss decreased (1.067779 --> 1.061996).  Saving model ...
Validation loss decreased (1.061996 --> 1.057619).  Saving model ...
Validation loss decreased (1.057619 --> 1.053368).  Saving model ...
Validation loss decreased (1.053368 --> 1.049516).  Saving model ...
Validation loss decreased (1.049516 --> 1.045193).  Saving model ...
Validation loss decreased (1.045193 --> 1.041488).  Saving model ...
Validation loss decreased (1.041488 --> 1.038052).  Saving model ...
Validation loss decreased (1.038052 --> 1.034399).  Saving model ...
Validation loss decreased (1.034399 --> 1.030738).  Saving model ...
Validation loss decreased (1.030738 --> 1.027435).  Saving model ...
Validation loss decreased (1.027435 --> 1.024258).  Saving model ...
Validation loss decreased (1.024258 --> 1.021432).  Saving model ...
Validation loss decreased (1.021432 --> 1.018123).  Saving model ...
Validation loss decreased (1.018123 --> 1.014139).  Saving model ...
Validation loss decreased (1.014139 --> 1.012968).  Saving model ...
Validation loss decreased (1.012968 --> 1.009678).  Saving model ...
Validation loss decreased (1.009678 --> 1.006275).  Saving model ...
Validation loss decreased (1.006275 --> 1.002483).  Saving model ...
Validation loss decreased (1.002483 --> 0.999864).  Saving model ...
Validation loss decreased (0.999864 --> 0.997503).  Saving model ...
Validation loss decreased (0.997503 --> 0.994159).  Saving model ...
Validation loss decreased (0.994159 --> 0.992021).  Saving model ...
Validation loss decreased (0.992021 --> 0.989008).  Saving model ...
Validation loss decreased (0.989008 --> 0.986914).  Saving model ...
Validation loss decreased (0.986914 --> 0.984730).  Saving model ...
Validation loss decreased (0.984730 --> 0.981633).  Saving model ...
Validation loss decreased (0.981633 --> 0.979706).  Saving model ...
Validation loss decreased (0.979706 --> 0.977324).  Saving model ...
Validation loss decreased (0.977324 --> 0.975952).  Saving model ...
Validation loss decreased (0.975952 --> 0.973768).  Saving model ...
Validation loss decreased (0.973768 --> 0.972675).  Saving model ...
Validation loss decreased (0.972675 --> 0.970817).  Saving model ...
Validation loss decreased (0.970817 --> 0.969299).  Saving model ...
Validation loss decreased (0.969299 --> 0.967659).  Saving model ...
Validation loss decreased (0.967659 --> 0.966383).  Saving model ...
Validation loss decreased (0.966383 --> 0.965120).  Saving model ...
Validation loss decreased (0.965120 --> 0.963729).  Saving model ...
Validation loss decreased (0.963729 --> 0.962812).  Saving model ...
Validation loss decreased (0.962812 --> 0.961445).  Saving model ...
Validation loss decreased (0.961445 --> 0.960227).  Saving model ...
Validation loss decreased (0.960227 --> 0.958867).  Saving model ...
Validation loss decreased (0.958867 --> 0.957399).  Saving model ...
Validation loss decreased (0.957399 --> 0.957083).  Saving model ...
Validation loss decreased (0.957083 --> 0.956603).  Saving model ...
Validation loss decreased (0.956603 --> 0.955424).  Saving model ...
Validation loss decreased (0.955424 --> 0.953987).  Saving model ...
Validation loss decreased (0.953987 --> 0.953429).  Saving model ...
Validation loss decreased (0.953429 --> 0.953353).  Saving model ...
Validation loss decreased (0.953353 --> 0.952226).  Saving model ...
Validation loss decreased (0.952226 --> 0.951701).  Saving model ...
Validation loss decreased (0.951701 --> 0.951422).  Saving model ...
Validation loss decreased (0.951422 --> 0.950364).  Saving model ...
Validation loss decreased (0.950364 --> 0.949086).  Saving model ...
Validation loss decreased (0.949086 --> 0.948221).  Saving model ...
EarlyStopping counter: 1 out of 10.0
Validation loss decreased (0.948221 --> 0.947382).  Saving model ...
Validation loss decreased (0.947382 --> 0.946779).  Saving model ...
Validation loss decreased (0.946779 --> 0.946042).  Saving model ...
EarlyStopping counter: 1 out of 10.0
Validation loss decreased (0.946042 --> 0.945986).  Saving model ...
Validation loss decreased (0.945986 --> 0.945009).  Saving model ...
Validation loss decreased (0.945009 --> 0.944524).  Saving model ...
EarlyStopping counter: 1 out of 10.0
EarlyStopping counter: 2 out of 10.0
EarlyStopping counter: 3 out of 10.0
EarlyStopping counter: 4 out of 10.0
Validation loss decreased (0.944524 --> 0.944480).  Saving model ...
Validation loss decreased (0.944480 --> 0.944322).  Saving model ...
EarlyStopping counter: 1 out of 10.0
EarlyStopping counter: 2 out of 10.0
EarlyStopping counter: 3 out of 10.0
Validation loss decreased (0.944322 --> 0.944257).  Saving model ...
EarlyStopping counter: 1 out of 10.0
EarlyStopping counter: 2 out of 10.0
EarlyStopping counter: 3 out of 10.0
EarlyStopping counter: 4 out of 10.0
EarlyStopping counter: 5 out of 10.0
EarlyStopping counter: 6 out of 10.0
EarlyStopping counter: 7 out of 10.0
EarlyStopping counter: 8 out of 10.0
EarlyStopping counter: 9 out of 10.0
EarlyStopping counter: 10 out of 10.0
/localscratch/yinan.29019375.0/env/lib/python3.7/site-packages/torch/nn/functional.py:1794: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.
  warnings.warn("nn.functional.tanh is deprecated. Use torch.tanh instead.")
wandb: Waiting for W&B process to finish, PID 148773... (success).
wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: \ 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: | 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: / 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: \ 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: | 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: / 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: \ 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: | 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: / 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb:                                                                                
wandb: Run history:
wandb:     e_F1 â–â–‚â–ƒâ–„â–„â–…â–…â–…â–†â–†â–†â–†â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ
wandb:   e_loss â–ˆâ–ˆâ–‡â–‡â–‡â–†â–†â–…â–…â–…â–„â–„â–„â–ƒâ–ƒâ–ƒâ–ƒâ–‚â–‚â–‚â–‚â–‚â–‚â–‚â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:     t_F1 â–â–â–‚â–‚â–ƒâ–ƒâ–„â–„â–„â–„â–„â–…â–†â–…â–…â–†â–†â–†â–†â–†â–†â–†â–‡â–†â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–ˆâ–‡â–‡â–‡â–ˆâ–ˆâ–ˆâ–‡â–ˆ
wandb:   t_loss â–ˆâ–ˆâ–‡â–‡â–‡â–‡â–†â–†â–†â–†â–†â–…â–…â–„â–…â–„â–„â–„â–„â–„â–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–â–â–â–
wandb: 
wandb: Run summary:
wandb:     e_F1 61.13387
wandb:   e_loss 0.94643
wandb:     t_F1 73.38018
wandb:   t_loss 0.70317
wandb: 
wandb: Synced 4 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Synced driven-firefly-2: https://wandb.ai/yinanazhou/xl_512_bs_8_lr_1e06_es_10_lc_False_nr_False_sr_False_stem_False_lemma_False_repeat_2_fold_1/runs/1yrvt17a
wandb: Find logs at: ./wandb/run-20220319_002118-1yrvt17a/logs/debug.log
wandb: 

wandb: wandb version 0.12.11 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
2022-03-19 01:47:35.866445: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1
wandb: Tracking run with wandb version 0.12.5
wandb: Syncing run graceful-brook-2
wandb: â­ï¸ View project at https://wandb.ai/yinanazhou/xl_512_bs_8_lr_1e06_es_10_lc_False_nr_False_sr_False_stem_False_lemma_False_repeat_2_fold_2
wandb: ðŸš€ View run at https://wandb.ai/yinanazhou/xl_512_bs_8_lr_1e06_es_10_lc_False_nr_False_sr_False_stem_False_lemma_False_repeat_2_fold_2/runs/bzltems4
wandb: Run data is saved locally in /project/6002780/yinan/Thesis_MER_Lyrics/lyric-emotion/wandb/run-20220319_014733-bzltems4
wandb: Run `wandb offline` to turn off syncing.

Validation loss decreased (inf --> 1.415797).  Saving model ...
Validation loss decreased (1.415797 --> 1.401262).  Saving model ...
Validation loss decreased (1.401262 --> 1.389021).  Saving model ...
Validation loss decreased (1.389021 --> 1.379480).  Saving model ...
Validation loss decreased (1.379480 --> 1.370948).  Saving model ...
Validation loss decreased (1.370948 --> 1.364567).  Saving model ...
Validation loss decreased (1.364567 --> 1.358265).  Saving model ...
Validation loss decreased (1.358265 --> 1.352440).  Saving model ...
Validation loss decreased (1.352440 --> 1.346541).  Saving model ...
Validation loss decreased (1.346541 --> 1.341454).  Saving model ...
Validation loss decreased (1.341454 --> 1.336185).  Saving model ...
Validation loss decreased (1.336185 --> 1.331200).  Saving model ...
Validation loss decreased (1.331200 --> 1.326103).  Saving model ...
Validation loss decreased (1.326103 --> 1.320819).  Saving model ...
Validation loss decreased (1.320819 --> 1.316066).  Saving model ...
Validation loss decreased (1.316066 --> 1.311109).  Saving model ...
Validation loss decreased (1.311109 --> 1.305562).  Saving model ...
Validation loss decreased (1.305562 --> 1.299439).  Saving model ...
Validation loss decreased (1.299439 --> 1.293686).  Saving model ...
Validation loss decreased (1.293686 --> 1.287351).  Saving model ...
Validation loss decreased (1.287351 --> 1.280977).  Saving model ...
Validation loss decreased (1.280977 --> 1.275169).  Saving model ...
Validation loss decreased (1.275169 --> 1.268842).  Saving model ...
Validation loss decreased (1.268842 --> 1.261129).  Saving model ...
Validation loss decreased (1.261129 --> 1.253675).  Saving model ...
Validation loss decreased (1.253675 --> 1.246202).  Saving model ...
Validation loss decreased (1.246202 --> 1.238708).  Saving model ...
Validation loss decreased (1.238708 --> 1.230641).  Saving model ...
Validation loss decreased (1.230641 --> 1.222349).  Saving model ...
Validation loss decreased (1.222349 --> 1.214591).  Saving model ...
Validation loss decreased (1.214591 --> 1.207309).  Saving model ...
Validation loss decreased (1.207309 --> 1.200394).  Saving model ...
Validation loss decreased (1.200394 --> 1.193147).  Saving model ...
Validation loss decreased (1.193147 --> 1.184337).  Saving model ...
Validation loss decreased (1.184337 --> 1.174066).  Saving model ...
Validation loss decreased (1.174066 --> 1.166139).  Saving model ...
Validation loss decreased (1.166139 --> 1.159506).  Saving model ...
Validation loss decreased (1.159506 --> 1.154264).  Saving model ...
Validation loss decreased (1.154264 --> 1.148124).  Saving model ...
Validation loss decreased (1.148124 --> 1.140914).  Saving model ...
Validation loss decreased (1.140914 --> 1.134906).  Saving model ...
Validation loss decreased (1.134906 --> 1.128689).  Saving model ...
Validation loss decreased (1.128689 --> 1.123134).  Saving model ...
Validation loss decreased (1.123134 --> 1.117085).  Saving model ...
Validation loss decreased (1.117085 --> 1.111476).  Saving model ...
Validation loss decreased (1.111476 --> 1.106721).  Saving model ...
Validation loss decreased (1.106721 --> 1.099611).  Saving model ...
Validation loss decreased (1.099611 --> 1.095137).  Saving model ...
Validation loss decreased (1.095137 --> 1.088851).  Saving model ...
Validation loss decreased (1.088851 --> 1.085426).  Saving model ...
Validation loss decreased (1.085426 --> 1.080143).  Saving model ...
Validation loss decreased (1.080143 --> 1.075751).  Saving model ...
Validation loss decreased (1.075751 --> 1.071752).  Saving model ...
Validation loss decreased (1.071752 --> 1.065796).  Saving model ...
Validation loss decreased (1.065796 --> 1.062676).  Saving model ...
Validation loss decreased (1.062676 --> 1.058606).  Saving model ...
Validation loss decreased (1.058606 --> 1.055542).  Saving model ...
Validation loss decreased (1.055542 --> 1.050802).  Saving model ...
Validation loss decreased (1.050802 --> 1.046782).  Saving model ...
Validation loss decreased (1.046782 --> 1.042176).  Saving model ...
Validation loss decreased (1.042176 --> 1.037744).  Saving model ...
Validation loss decreased (1.037744 --> 1.034366).  Saving model ...
Validation loss decreased (1.034366 --> 1.029917).  Saving model ...
Validation loss decreased (1.029917 --> 1.026945).  Saving model ...
Validation loss decreased (1.026945 --> 1.023557).  Saving model ...
Validation loss decreased (1.023557 --> 1.019904).  Saving model ...
Validation loss decreased (1.019904 --> 1.017168).  Saving model ...
Validation loss decreased (1.017168 --> 1.013059).  Saving model ...
Validation loss decreased (1.013059 --> 1.009884).  Saving model ...
Validation loss decreased (1.009884 --> 1.007773).  Saving model ...
Validation loss decreased (1.007773 --> 1.003584).  Saving model ...
Validation loss decreased (1.003584 --> 1.001769).  Saving model ...
Validation loss decreased (1.001769 --> 0.999358).  Saving model ...
Validation loss decreased (0.999358 --> 0.995693).  Saving model ...
Validation loss decreased (0.995693 --> 0.993302).  Saving model ...
Validation loss decreased (0.993302 --> 0.991558).  Saving model ...
Validation loss decreased (0.991558 --> 0.988668).  Saving model ...
Validation loss decreased (0.988668 --> 0.986900).  Saving model ...
Validation loss decreased (0.986900 --> 0.984944).  Saving model ...
Validation loss decreased (0.984944 --> 0.982552).  Saving model ...
Validation loss decreased (0.982552 --> 0.979181).  Saving model ...
Validation loss decreased (0.979181 --> 0.977238).  Saving model ...
Validation loss decreased (0.977238 --> 0.974135).  Saving model ...
Validation loss decreased (0.974135 --> 0.973071).  Saving model ...
Validation loss decreased (0.973071 --> 0.971300).  Saving model ...
Validation loss decreased (0.971300 --> 0.968349).  Saving model ...
Validation loss decreased (0.968349 --> 0.965475).  Saving model ...
Validation loss decreased (0.965475 --> 0.963804).  Saving model ...
Validation loss decreased (0.963804 --> 0.963540).  Saving model ...
Validation loss decreased (0.963540 --> 0.961452).  Saving model ...
Validation loss decreased (0.961452 --> 0.959561).  Saving model ...
Validation loss decreased (0.959561 --> 0.957184).  Saving model ...
Validation loss decreased (0.957184 --> 0.954677).  Saving model ...
Validation loss decreased (0.954677 --> 0.953064).  Saving model ...
Validation loss decreased (0.953064 --> 0.952306).  Saving model ...
Validation loss decreased (0.952306 --> 0.949628).  Saving model ...
Validation loss decreased (0.949628 --> 0.948220).  Saving model ...
Validation loss decreased (0.948220 --> 0.947712).  Saving model ...
Validation loss decreased (0.947712 --> 0.946954).  Saving model ...
Validation loss decreased (0.946954 --> 0.945862).  Saving model ...
Validation loss decreased (0.945862 --> 0.944469).  Saving model ...
Validation loss decreased (0.944469 --> 0.943642).  Saving model ...
Validation loss decreased (0.943642 --> 0.942271).  Saving model ...
Validation loss decreased (0.942271 --> 0.941319).  Saving model ...
Validation loss decreased (0.941319 --> 0.940663).  Saving model ...
Validation loss decreased (0.940663 --> 0.939942).  Saving model ...
Validation loss decreased (0.939942 --> 0.938061).  Saving model ...
Validation loss decreased (0.938061 --> 0.936563).  Saving model ...
EarlyStopping counter: 1 out of 10.0
Validation loss decreased (0.936563 --> 0.935732).  Saving model ...
EarlyStopping counter: 1 out of 10.0
Validation loss decreased (0.935732 --> 0.935508).  Saving model ...
EarlyStopping counter: 1 out of 10.0
Validation loss decreased (0.935508 --> 0.934524).  Saving model ...
Validation loss decreased (0.934524 --> 0.933461).  Saving model ...
Validation loss decreased (0.933461 --> 0.932530).  Saving model ...
Validation loss decreased (0.932530 --> 0.931765).  Saving model ...
EarlyStopping counter: 1 out of 10.0
Validation loss decreased (0.931765 --> 0.931591).  Saving model ...
Validation loss decreased (0.931591 --> 0.931163).  Saving model ...
Validation loss decreased (0.931163 --> 0.930800).  Saving model ...
Validation loss decreased (0.930800 --> 0.930602).  Saving model ...
Validation loss decreased (0.930602 --> 0.928584).  Saving model ...
Validation loss decreased (0.928584 --> 0.927552).  Saving model ...
EarlyStopping counter: 1 out of 10.0
EarlyStopping counter: 2 out of 10.0
EarlyStopping counter: 3 out of 10.0
EarlyStopping counter: 4 out of 10.0
EarlyStopping counter: 5 out of 10.0
EarlyStopping counter: 6 out of 10.0
EarlyStopping counter: 7 out of 10.0
EarlyStopping counter: 8 out of 10.0
EarlyStopping counter: 9 out of 10.0
EarlyStopping counter: 10 out of 10.0
/localscratch/yinan.29019375.0/env/lib/python3.7/site-packages/torch/nn/functional.py:1794: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.
  warnings.warn("nn.functional.tanh is deprecated. Use torch.tanh instead.")
wandb: Waiting for W&B process to finish, PID 153439... (success).
wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: \ 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: | 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: / 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: \ 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: | 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: / 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: \ 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: | 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: / 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: \ 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb:                                                                                
wandb: Run history:
wandb:     e_F1 â–â–â–ƒâ–„â–„â–„â–…â–…â–…â–…â–†â–†â–†â–†â–†â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–ˆâ–‡â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ
wandb:   e_loss â–ˆâ–ˆâ–‡â–‡â–‡â–†â–†â–†â–…â–…â–…â–„â–„â–„â–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–‚â–‚â–‚â–‚â–‚â–‚â–‚â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:     t_F1 â–â–‚â–‚â–ƒâ–ƒâ–„â–ƒâ–…â–„â–„â–…â–…â–…â–†â–†â–†â–†â–†â–†â–†â–‡â–†â–‡â–‡â–†â–†â–‡â–‡â–‡â–ˆâ–‡â–ˆâ–‡â–‡â–‡â–ˆâ–ˆâ–ˆâ–‡â–ˆ
wandb:   t_loss â–ˆâ–ˆâ–‡â–‡â–‡â–‡â–‡â–†â–†â–†â–†â–…â–…â–…â–…â–„â–„â–„â–„â–„â–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–â–â–â–
wandb: 
wandb: Run summary:
wandb:     e_F1 62.70925
wandb:   e_loss 0.92816
wandb:     t_F1 71.09061
wandb:   t_loss 0.73282
wandb: 
wandb: Synced 4 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Synced graceful-brook-2: https://wandb.ai/yinanazhou/xl_512_bs_8_lr_1e06_es_10_lc_False_nr_False_sr_False_stem_False_lemma_False_repeat_2_fold_2/runs/bzltems4
wandb: Find logs at: ./wandb/run-20220319_014733-bzltems4/logs/debug.log
wandb: 

wandb: wandb version 0.12.11 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
2022-03-19 03:12:04.670914: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1
wandb: Tracking run with wandb version 0.12.5
wandb: Syncing run sandy-rain-2
wandb: â­ï¸ View project at https://wandb.ai/yinanazhou/xl_512_bs_8_lr_1e06_es_10_lc_False_nr_False_sr_False_stem_False_lemma_False_repeat_3_fold_1
wandb: ðŸš€ View run at https://wandb.ai/yinanazhou/xl_512_bs_8_lr_1e06_es_10_lc_False_nr_False_sr_False_stem_False_lemma_False_repeat_3_fold_1/runs/t5j8gxg0
wandb: Run data is saved locally in /project/6002780/yinan/Thesis_MER_Lyrics/lyric-emotion/wandb/run-20220319_031201-t5j8gxg0
wandb: Run `wandb offline` to turn off syncing.

Validation loss decreased (inf --> 1.463794).  Saving model ...
Validation loss decreased (1.463794 --> 1.435907).  Saving model ...
Validation loss decreased (1.435907 --> 1.416037).  Saving model ...
Validation loss decreased (1.416037 --> 1.401986).  Saving model ...
Validation loss decreased (1.401986 --> 1.391683).  Saving model ...
Validation loss decreased (1.391683 --> 1.383288).  Saving model ...
Validation loss decreased (1.383288 --> 1.376550).  Saving model ...
Validation loss decreased (1.376550 --> 1.371114).  Saving model ...
Validation loss decreased (1.371114 --> 1.365153).  Saving model ...
Validation loss decreased (1.365153 --> 1.359334).  Saving model ...
Validation loss decreased (1.359334 --> 1.353698).  Saving model ...
Validation loss decreased (1.353698 --> 1.347548).  Saving model ...
Validation loss decreased (1.347548 --> 1.341404).  Saving model ...
Validation loss decreased (1.341404 --> 1.335190).  Saving model ...
Validation loss decreased (1.335190 --> 1.327816).  Saving model ...
Validation loss decreased (1.327816 --> 1.320240).  Saving model ...
Validation loss decreased (1.320240 --> 1.312863).  Saving model ...
Validation loss decreased (1.312863 --> 1.305593).  Saving model ...
Validation loss decreased (1.305593 --> 1.296890).  Saving model ...
Validation loss decreased (1.296890 --> 1.288766).  Saving model ...
Validation loss decreased (1.288766 --> 1.280258).  Saving model ...
Validation loss decreased (1.280258 --> 1.271201).  Saving model ...
Validation loss decreased (1.271201 --> 1.263071).  Saving model ...
Validation loss decreased (1.263071 --> 1.255429).  Saving model ...
Validation loss decreased (1.255429 --> 1.247061).  Saving model ...
Validation loss decreased (1.247061 --> 1.237983).  Saving model ...
Validation loss decreased (1.237983 --> 1.229290).  Saving model ...
Validation loss decreased (1.229290 --> 1.222180).  Saving model ...
Validation loss decreased (1.222180 --> 1.215006).  Saving model ...
Validation loss decreased (1.215006 --> 1.204963).  Saving model ...
Validation loss decreased (1.204963 --> 1.198283).  Saving model ...
Validation loss decreased (1.198283 --> 1.193346).  Saving model ...
Validation loss decreased (1.193346 --> 1.184054).  Saving model ...
Validation loss decreased (1.184054 --> 1.177336).  Saving model ...
Validation loss decreased (1.177336 --> 1.170393).  Saving model ...
Validation loss decreased (1.170393 --> 1.162078).  Saving model ...
Validation loss decreased (1.162078 --> 1.154726).  Saving model ...
Validation loss decreased (1.154726 --> 1.147620).  Saving model ...
Validation loss decreased (1.147620 --> 1.141689).  Saving model ...
Validation loss decreased (1.141689 --> 1.137502).  Saving model ...
Validation loss decreased (1.137502 --> 1.131353).  Saving model ...
Validation loss decreased (1.131353 --> 1.125395).  Saving model ...
Validation loss decreased (1.125395 --> 1.120942).  Saving model ...
Validation loss decreased (1.120942 --> 1.115117).  Saving model ...
Validation loss decreased (1.115117 --> 1.107106).  Saving model ...
Validation loss decreased (1.107106 --> 1.103941).  Saving model ...
Validation loss decreased (1.103941 --> 1.097655).  Saving model ...
Validation loss decreased (1.097655 --> 1.091647).  Saving model ...
Validation loss decreased (1.091647 --> 1.083938).  Saving model ...
Validation loss decreased (1.083938 --> 1.080099).  Saving model ...
Validation loss decreased (1.080099 --> 1.076628).  Saving model ...
Validation loss decreased (1.076628 --> 1.071170).  Saving model ...
Validation loss decreased (1.071170 --> 1.065030).  Saving model ...
Validation loss decreased (1.065030 --> 1.061799).  Saving model ...
Validation loss decreased (1.061799 --> 1.053933).  Saving model ...
Validation loss decreased (1.053933 --> 1.050338).  Saving model ...
Validation loss decreased (1.050338 --> 1.045141).  Saving model ...
Validation loss decreased (1.045141 --> 1.041491).  Saving model ...
Validation loss decreased (1.041491 --> 1.038177).  Saving model ...
Validation loss decreased (1.038177 --> 1.033320).  Saving model ...
Validation loss decreased (1.033320 --> 1.030140).  Saving model ...
Validation loss decreased (1.030140 --> 1.027749).  Saving model ...
Validation loss decreased (1.027749 --> 1.024878).  Saving model ...
Validation loss decreased (1.024878 --> 1.020629).  Saving model ...
Validation loss decreased (1.020629 --> 1.015105).  Saving model ...
Validation loss decreased (1.015105 --> 1.011333).  Saving model ...
Validation loss decreased (1.011333 --> 1.008625).  Saving model ...
Validation loss decreased (1.008625 --> 1.003210).  Saving model ...
Validation loss decreased (1.003210 --> 1.001666).  Saving model ...
Validation loss decreased (1.001666 --> 1.001188).  Saving model ...
Validation loss decreased (1.001188 --> 0.998385).  Saving model ...
Validation loss decreased (0.998385 --> 0.995268).  Saving model ...
Validation loss decreased (0.995268 --> 0.991336).  Saving model ...
Validation loss decreased (0.991336 --> 0.990215).  Saving model ...
Validation loss decreased (0.990215 --> 0.988484).  Saving model ...
Validation loss decreased (0.988484 --> 0.984973).  Saving model ...
Validation loss decreased (0.984973 --> 0.981094).  Saving model ...
EarlyStopping counter: 1 out of 10.0
Validation loss decreased (0.981094 --> 0.981079).  Saving model ...
Validation loss decreased (0.981079 --> 0.977785).  Saving model ...
Validation loss decreased (0.977785 --> 0.975883).  Saving model ...
Validation loss decreased (0.975883 --> 0.973980).  Saving model ...
Validation loss decreased (0.973980 --> 0.973485).  Saving model ...
Validation loss decreased (0.973485 --> 0.970973).  Saving model ...
Validation loss decreased (0.970973 --> 0.969337).  Saving model ...
Validation loss decreased (0.969337 --> 0.967901).  Saving model ...
Validation loss decreased (0.967901 --> 0.967317).  Saving model ...
Validation loss decreased (0.967317 --> 0.962127).  Saving model ...
Validation loss decreased (0.962127 --> 0.958906).  Saving model ...
EarlyStopping counter: 1 out of 10.0
EarlyStopping counter: 2 out of 10.0
Validation loss decreased (0.958906 --> 0.958145).  Saving model ...
Validation loss decreased (0.958145 --> 0.956932).  Saving model ...
Validation loss decreased (0.956932 --> 0.955592).  Saving model ...
Validation loss decreased (0.955592 --> 0.955303).  Saving model ...
Validation loss decreased (0.955303 --> 0.952073).  Saving model ...
Validation loss decreased (0.952073 --> 0.948569).  Saving model ...
Validation loss decreased (0.948569 --> 0.948215).  Saving model ...
EarlyStopping counter: 1 out of 10.0
Validation loss decreased (0.948215 --> 0.948072).  Saving model ...
Validation loss decreased (0.948072 --> 0.946635).  Saving model ...
EarlyStopping counter: 1 out of 10.0
Validation loss decreased (0.946635 --> 0.946326).  Saving model ...
EarlyStopping counter: 1 out of 10.0
EarlyStopping counter: 2 out of 10.0
Validation loss decreased (0.946326 --> 0.945763).  Saving model ...
EarlyStopping counter: 1 out of 10.0
Validation loss decreased (0.945763 --> 0.945176).  Saving model ...
Validation loss decreased (0.945176 --> 0.943788).  Saving model ...
Validation loss decreased (0.943788 --> 0.940159).  Saving model ...
EarlyStopping counter: 1 out of 10.0
EarlyStopping counter: 2 out of 10.0
EarlyStopping counter: 3 out of 10.0
EarlyStopping counter: 4 out of 10.0
EarlyStopping counter: 5 out of 10.0
EarlyStopping counter: 6 out of 10.0
EarlyStopping counter: 7 out of 10.0
EarlyStopping counter: 8 out of 10.0
EarlyStopping counter: 9 out of 10.0
EarlyStopping counter: 10 out of 10.0
/localscratch/yinan.29019375.0/env/lib/python3.7/site-packages/torch/nn/functional.py:1794: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.
  warnings.warn("nn.functional.tanh is deprecated. Use torch.tanh instead.")
wandb: Waiting for W&B process to finish, PID 158002... (success).
wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: \ 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: | 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: / 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: \ 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: | 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: / 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: \ 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: | 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: / 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb:                                                                                
wandb: Run history:
wandb:     e_F1 â–â–â–ƒâ–„â–„â–„â–…â–†â–†â–†â–†â–†â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ
wandb:   e_loss â–ˆâ–‡â–‡â–‡â–†â–†â–†â–…â–…â–…â–„â–„â–„â–„â–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:     t_F1 â–â–â–‚â–ƒâ–ƒâ–ƒâ–„â–„â–…â–…â–…â–…â–†â–†â–†â–†â–†â–‡â–†â–†â–†â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–ˆâ–‡â–‡â–‡â–‡â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ
wandb:   t_loss â–ˆâ–ˆâ–‡â–‡â–‡â–‡â–†â–†â–†â–†â–†â–…â–…â–…â–…â–„â–„â–„â–„â–„â–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–â–â–â–â–
wandb: 
wandb: Run summary:
wandb:     e_F1 61.58132
wandb:   e_loss 0.94166
wandb:     t_F1 73.04287
wandb:   t_loss 0.74395
wandb: 
wandb: Synced 4 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Synced sandy-rain-2: https://wandb.ai/yinanazhou/xl_512_bs_8_lr_1e06_es_10_lc_False_nr_False_sr_False_stem_False_lemma_False_repeat_3_fold_1/runs/t5j8gxg0
wandb: Find logs at: ./wandb/run-20220319_031201-t5j8gxg0/logs/debug.log
wandb: 

wandb: wandb version 0.12.11 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
2022-03-19 04:25:14.892930: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1
wandb: Tracking run with wandb version 0.12.5
wandb: Syncing run sparkling-morning-2
wandb: â­ï¸ View project at https://wandb.ai/yinanazhou/xl_512_bs_8_lr_1e06_es_10_lc_False_nr_False_sr_False_stem_False_lemma_False_repeat_3_fold_2
wandb: ðŸš€ View run at https://wandb.ai/yinanazhou/xl_512_bs_8_lr_1e06_es_10_lc_False_nr_False_sr_False_stem_False_lemma_False_repeat_3_fold_2/runs/2sh9bs0e
wandb: Run data is saved locally in /project/6002780/yinan/Thesis_MER_Lyrics/lyric-emotion/wandb/run-20220319_042512-2sh9bs0e
wandb: Run `wandb offline` to turn off syncing.

Validation loss decreased (inf --> 1.400712).  Saving model ...
Validation loss decreased (1.400712 --> 1.387035).  Saving model ...
Validation loss decreased (1.387035 --> 1.377407).  Saving model ...
Validation loss decreased (1.377407 --> 1.369492).  Saving model ...
Validation loss decreased (1.369492 --> 1.362574).  Saving model ...
Validation loss decreased (1.362574 --> 1.356577).  Saving model ...
Validation loss decreased (1.356577 --> 1.351188).  Saving model ...
Validation loss decreased (1.351188 --> 1.346821).  Saving model ...
Validation loss decreased (1.346821 --> 1.341996).  Saving model ...
Validation loss decreased (1.341996 --> 1.337250).  Saving model ...
Validation loss decreased (1.337250 --> 1.332668).  Saving model ...
Validation loss decreased (1.332668 --> 1.328408).  Saving model ...
Validation loss decreased (1.328408 --> 1.323380).  Saving model ...
Validation loss decreased (1.323380 --> 1.317961).  Saving model ...
Validation loss decreased (1.317961 --> 1.312483).  Saving model ...
Validation loss decreased (1.312483 --> 1.306547).  Saving model ...
Validation loss decreased (1.306547 --> 1.300902).  Saving model ...
Validation loss decreased (1.300902 --> 1.295479).  Saving model ...
Validation loss decreased (1.295479 --> 1.289227).  Saving model ...
Validation loss decreased (1.289227 --> 1.283035).  Saving model ...
Validation loss decreased (1.283035 --> 1.276491).  Saving model ...
Validation loss decreased (1.276491 --> 1.269020).  Saving model ...
Validation loss decreased (1.269020 --> 1.261177).  Saving model ...
Validation loss decreased (1.261177 --> 1.253351).  Saving model ...
Validation loss decreased (1.253351 --> 1.244999).  Saving model ...
Validation loss decreased (1.244999 --> 1.236861).  Saving model ...
Validation loss decreased (1.236861 --> 1.229487).  Saving model ...
Validation loss decreased (1.229487 --> 1.218701).  Saving model ...
Validation loss decreased (1.218701 --> 1.209217).  Saving model ...
Validation loss decreased (1.209217 --> 1.199987).  Saving model ...
Validation loss decreased (1.199987 --> 1.191877).  Saving model ...
Validation loss decreased (1.191877 --> 1.182698).  Saving model ...
Validation loss decreased (1.182698 --> 1.174172).  Saving model ...
Validation loss decreased (1.174172 --> 1.166079).  Saving model ...
Validation loss decreased (1.166079 --> 1.156177).  Saving model ...
Validation loss decreased (1.156177 --> 1.147068).  Saving model ...
Validation loss decreased (1.147068 --> 1.138333).  Saving model ...
Validation loss decreased (1.138333 --> 1.131353).  Saving model ...
Validation loss decreased (1.131353 --> 1.122534).  Saving model ...
Validation loss decreased (1.122534 --> 1.115244).  Saving model ...
Validation loss decreased (1.115244 --> 1.107301).  Saving model ...
Validation loss decreased (1.107301 --> 1.101906).  Saving model ...
Validation loss decreased (1.101906 --> 1.096116).  Saving model ...
Validation loss decreased (1.096116 --> 1.091821).  Saving model ...
Validation loss decreased (1.091821 --> 1.084358).  Saving model ...
Validation loss decreased (1.084358 --> 1.078013).  Saving model ...
Validation loss decreased (1.078013 --> 1.071823).  Saving model ...
Validation loss decreased (1.071823 --> 1.066312).  Saving model ...
Validation loss decreased (1.066312 --> 1.061834).  Saving model ...
Validation loss decreased (1.061834 --> 1.058096).  Saving model ...
Validation loss decreased (1.058096 --> 1.052830).  Saving model ...
Validation loss decreased (1.052830 --> 1.047265).  Saving model ...
Validation loss decreased (1.047265 --> 1.043616).  Saving model ...
Validation loss decreased (1.043616 --> 1.039398).  Saving model ...
Validation loss decreased (1.039398 --> 1.036595).  Saving model ...
Validation loss decreased (1.036595 --> 1.032801).  Saving model ...
Validation loss decreased (1.032801 --> 1.029051).  Saving model ...
Validation loss decreased (1.029051 --> 1.025312).  Saving model ...
Validation loss decreased (1.025312 --> 1.022064).  Saving model ...
Validation loss decreased (1.022064 --> 1.019521).  Saving model ...
Validation loss decreased (1.019521 --> 1.013937).  Saving model ...
Validation loss decreased (1.013937 --> 1.012024).  Saving model ...
Validation loss decreased (1.012024 --> 1.008293).  Saving model ...
Validation loss decreased (1.008293 --> 1.004622).  Saving model ...
Validation loss decreased (1.004622 --> 1.002405).  Saving model ...
Validation loss decreased (1.002405 --> 0.998429).  Saving model ...
Validation loss decreased (0.998429 --> 0.997045).  Saving model ...
Validation loss decreased (0.997045 --> 0.990342).  Saving model ...
Validation loss decreased (0.990342 --> 0.988287).  Saving model ...
Validation loss decreased (0.988287 --> 0.987843).  Saving model ...
Validation loss decreased (0.987843 --> 0.985850).  Saving model ...
Validation loss decreased (0.985850 --> 0.981521).  Saving model ...
Validation loss decreased (0.981521 --> 0.978517).  Saving model ...
Validation loss decreased (0.978517 --> 0.976291).  Saving model ...
Validation loss decreased (0.976291 --> 0.971396).  Saving model ...
EarlyStopping counter: 1 out of 10.0
Validation loss decreased (0.971396 --> 0.968459).  Saving model ...
Validation loss decreased (0.968459 --> 0.965495).  Saving model ...
Validation loss decreased (0.965495 --> 0.964236).  Saving model ...
Validation loss decreased (0.964236 --> 0.963453).  Saving model ...
Validation loss decreased (0.963453 --> 0.960396).  Saving model ...
Validation loss decreased (0.960396 --> 0.955553).  Saving model ...
Validation loss decreased (0.955553 --> 0.953927).  Saving model ...
Validation loss decreased (0.953927 --> 0.952525).  Saving model ...
Validation loss decreased (0.952525 --> 0.950410).  Saving model ...
Validation loss decreased (0.950410 --> 0.947569).  Saving model ...
Validation loss decreased (0.947569 --> 0.944329).  Saving model ...
EarlyStopping counter: 1 out of 10.0
Validation loss decreased (0.944329 --> 0.943179).  Saving model ...
Validation loss decreased (0.943179 --> 0.942255).  Saving model ...
Validation loss decreased (0.942255 --> 0.941447).  Saving model ...
Validation loss decreased (0.941447 --> 0.940383).  Saving model ...
Validation loss decreased (0.940383 --> 0.940020).  Saving model ...
Validation loss decreased (0.940020 --> 0.939417).  Saving model ...
Validation loss decreased (0.939417 --> 0.937137).  Saving model ...
EarlyStopping counter: 1 out of 10.0
EarlyStopping counter: 2 out of 10.0
Validation loss decreased (0.937137 --> 0.935064).  Saving model ...
Validation loss decreased (0.935064 --> 0.932544).  Saving model ...
EarlyStopping counter: 1 out of 10.0
Validation loss decreased (0.932544 --> 0.932260).  Saving model ...
Validation loss decreased (0.932260 --> 0.932206).  Saving model ...
Validation loss decreased (0.932206 --> 0.930869).  Saving model ...
Validation loss decreased (0.930869 --> 0.926427).  Saving model ...
Validation loss decreased (0.926427 --> 0.924759).  Saving model ...
Validation loss decreased (0.924759 --> 0.923633).  Saving model ...
Validation loss decreased (0.923633 --> 0.923562).  Saving model ...
Validation loss decreased (0.923562 --> 0.922736).  Saving model ...
EarlyStopping counter: 1 out of 10.0
Validation loss decreased (0.922736 --> 0.922112).  Saving model ...
Validation loss decreased (0.922112 --> 0.919399).  Saving model ...
Validation loss decreased (0.919399 --> 0.919341).  Saving model ...
EarlyStopping counter: 1 out of 10.0
EarlyStopping counter: 2 out of 10.0
EarlyStopping counter: 3 out of 10.0
Validation loss decreased (0.919341 --> 0.916799).  Saving model ...
EarlyStopping counter: 1 out of 10.0
EarlyStopping counter: 2 out of 10.0
EarlyStopping counter: 3 out of 10.0
EarlyStopping counter: 4 out of 10.0
Validation loss decreased (0.916799 --> 0.916015).  Saving model ...
Validation loss decreased (0.916015 --> 0.915021).  Saving model ...
EarlyStopping counter: 1 out of 10.0
EarlyStopping counter: 2 out of 10.0
EarlyStopping counter: 3 out of 10.0
Validation loss decreased (0.915021 --> 0.914707).  Saving model ...
EarlyStopping counter: 1 out of 10.0
EarlyStopping counter: 2 out of 10.0
EarlyStopping counter: 3 out of 10.0
EarlyStopping counter: 4 out of 10.0
EarlyStopping counter: 5 out of 10.0
EarlyStopping counter: 6 out of 10.0
Validation loss decreased (0.914707 --> 0.913454).  Saving model ...
EarlyStopping counter: 1 out of 10.0
EarlyStopping counter: 2 out of 10.0
EarlyStopping counter: 3 out of 10.0
EarlyStopping counter: 4 out of 10.0
EarlyStopping counter: 5 out of 10.0
EarlyStopping counter: 6 out of 10.0
EarlyStopping counter: 7 out of 10.0
EarlyStopping counter: 8 out of 10.0
EarlyStopping counter: 9 out of 10.0
EarlyStopping counter: 10 out of 10.0
/localscratch/yinan.29019375.0/env/lib/python3.7/site-packages/torch/nn/functional.py:1794: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.
  warnings.warn("nn.functional.tanh is deprecated. Use torch.tanh instead.")
wandb: Waiting for W&B process to finish, PID 161951... (success).
wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: \ 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: | 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: / 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: \ 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: | 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: / 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: \ 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: | 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: / 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: \ 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: | 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb:                                                                                
wandb: Run history:
wandb:     e_F1 â–â–‚â–ƒâ–„â–„â–„â–…â–…â–†â–†â–†â–†â–†â–†â–†â–†â–‡â–‡â–‡â–‡â–‡â–‡â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ
wandb:   e_loss â–ˆâ–ˆâ–‡â–‡â–‡â–‡â–†â–†â–…â–…â–„â–„â–„â–ƒâ–ƒâ–ƒâ–ƒâ–‚â–‚â–‚â–‚â–‚â–‚â–‚â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:     t_F1 â–â–â–â–‚â–‚â–‚â–„â–„â–„â–„â–„â–…â–…â–…â–†â–†â–†â–†â–†â–†â–†â–†â–‡â–‡â–†â–‡â–‡â–‡â–‡â–‡â–‡â–ˆâ–ˆâ–ˆâ–‡â–‡â–ˆâ–ˆâ–ˆâ–ˆ
wandb:   t_loss â–ˆâ–ˆâ–ˆâ–ˆâ–‡â–‡â–‡â–†â–†â–†â–†â–…â–…â–…â–…â–„â–„â–„â–„â–„â–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–â–â–â–
wandb: 
wandb: Run summary:
wandb:     e_F1 63.65668
wandb:   e_loss 0.91637
wandb:     t_F1 70.86448
wandb:   t_loss 0.71555
wandb: 
wandb: Synced 4 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Synced sparkling-morning-2: https://wandb.ai/yinanazhou/xl_512_bs_8_lr_1e06_es_10_lc_False_nr_False_sr_False_stem_False_lemma_False_repeat_3_fold_2/runs/2sh9bs0e
wandb: Find logs at: ./wandb/run-20220319_042512-2sh9bs0e/logs/debug.log
wandb: 

wandb: wandb version 0.12.11 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
2022-03-19 05:58:42.866894: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1
wandb: Tracking run with wandb version 0.12.5
wandb: Syncing run leafy-serenity-2
wandb: â­ï¸ View project at https://wandb.ai/yinanazhou/xl_512_bs_8_lr_1e06_es_10_lc_False_nr_False_sr_False_stem_False_lemma_False_repeat_4_fold_1
wandb: ðŸš€ View run at https://wandb.ai/yinanazhou/xl_512_bs_8_lr_1e06_es_10_lc_False_nr_False_sr_False_stem_False_lemma_False_repeat_4_fold_1/runs/3qllq9ke
wandb: Run data is saved locally in /project/6002780/yinan/Thesis_MER_Lyrics/lyric-emotion/wandb/run-20220319_055838-3qllq9ke
wandb: Run `wandb offline` to turn off syncing.

Validation loss decreased (inf --> 1.458310).  Saving model ...
Validation loss decreased (1.458310 --> 1.435836).  Saving model ...
Validation loss decreased (1.435836 --> 1.419502).  Saving model ...
Validation loss decreased (1.419502 --> 1.406902).  Saving model ...
Validation loss decreased (1.406902 --> 1.397265).  Saving model ...
Validation loss decreased (1.397265 --> 1.389394).  Saving model ...
Validation loss decreased (1.389394 --> 1.383178).  Saving model ...
Validation loss decreased (1.383178 --> 1.377445).  Saving model ...
Validation loss decreased (1.377445 --> 1.372230).  Saving model ...
Validation loss decreased (1.372230 --> 1.367042).  Saving model ...
Validation loss decreased (1.367042 --> 1.362114).  Saving model ...
Validation loss decreased (1.362114 --> 1.356872).  Saving model ...
Validation loss decreased (1.356872 --> 1.352167).  Saving model ...
Validation loss decreased (1.352167 --> 1.346942).  Saving model ...
Validation loss decreased (1.346942 --> 1.341281).  Saving model ...
Validation loss decreased (1.341281 --> 1.335458).  Saving model ...
Validation loss decreased (1.335458 --> 1.329871).  Saving model ...
Validation loss decreased (1.329871 --> 1.323767).  Saving model ...
Validation loss decreased (1.323767 --> 1.316824).  Saving model ...
Validation loss decreased (1.316824 --> 1.309108).  Saving model ...
Validation loss decreased (1.309108 --> 1.301530).  Saving model ...
Validation loss decreased (1.301530 --> 1.294140).  Saving model ...
Validation loss decreased (1.294140 --> 1.286460).  Saving model ...
Validation loss decreased (1.286460 --> 1.277370).  Saving model ...
Validation loss decreased (1.277370 --> 1.267729).  Saving model ...
Validation loss decreased (1.267729 --> 1.258514).  Saving model ...
Validation loss decreased (1.258514 --> 1.248512).  Saving model ...
Validation loss decreased (1.248512 --> 1.239837).  Saving model ...
Validation loss decreased (1.239837 --> 1.230796).  Saving model ...
Validation loss decreased (1.230796 --> 1.221124).  Saving model ...
Validation loss decreased (1.221124 --> 1.213472).  Saving model ...
Validation loss decreased (1.213472 --> 1.206660).  Saving model ...
Validation loss decreased (1.206660 --> 1.199255).  Saving model ...
Validation loss decreased (1.199255 --> 1.192083).  Saving model ...
Validation loss decreased (1.192083 --> 1.185563).  Saving model ...
Validation loss decreased (1.185563 --> 1.178993).  Saving model ...
Validation loss decreased (1.178993 --> 1.173119).  Saving model ...
Validation loss decreased (1.173119 --> 1.167792).  Saving model ...
Validation loss decreased (1.167792 --> 1.161117).  Saving model ...
Validation loss decreased (1.161117 --> 1.155316).  Saving model ...
Validation loss decreased (1.155316 --> 1.150668).  Saving model ...
Validation loss decreased (1.150668 --> 1.145793).  Saving model ...
Validation loss decreased (1.145793 --> 1.138963).  Saving model ...
Validation loss decreased (1.138963 --> 1.132364).  Saving model ...
Validation loss decreased (1.132364 --> 1.126507).  Saving model ...
Validation loss decreased (1.126507 --> 1.120896).  Saving model ...
Validation loss decreased (1.120896 --> 1.115979).  Saving model ...
Validation loss decreased (1.115979 --> 1.111603).  Saving model ...
Validation loss decreased (1.111603 --> 1.107517).  Saving model ...
Validation loss decreased (1.107517 --> 1.103705).  Saving model ...
Validation loss decreased (1.103705 --> 1.097481).  Saving model ...
Validation loss decreased (1.097481 --> 1.092312).  Saving model ...
Validation loss decreased (1.092312 --> 1.086784).  Saving model ...
Validation loss decreased (1.086784 --> 1.083734).  Saving model ...
Validation loss decreased (1.083734 --> 1.078119).  Saving model ...
Validation loss decreased (1.078119 --> 1.074239).  Saving model ...
Validation loss decreased (1.074239 --> 1.071022).  Saving model ...
Validation loss decreased (1.071022 --> 1.066464).  Saving model ...
Validation loss decreased (1.066464 --> 1.062697).  Saving model ...
Validation loss decreased (1.062697 --> 1.059807).  Saving model ...
Validation loss decreased (1.059807 --> 1.054594).  Saving model ...
Validation loss decreased (1.054594 --> 1.052824).  Saving model ...
Validation loss decreased (1.052824 --> 1.050580).  Saving model ...
Validation loss decreased (1.050580 --> 1.044764).  Saving model ...
Validation loss decreased (1.044764 --> 1.043340).  Saving model ...
Validation loss decreased (1.043340 --> 1.038823).  Saving model ...
Validation loss decreased (1.038823 --> 1.034353).  Saving model ...
Validation loss decreased (1.034353 --> 1.032533).  Saving model ...
Validation loss decreased (1.032533 --> 1.030064).  Saving model ...
Validation loss decreased (1.030064 --> 1.028029).  Saving model ...
Validation loss decreased (1.028029 --> 1.023141).  Saving model ...
Validation loss decreased (1.023141 --> 1.019637).  Saving model ...
Validation loss decreased (1.019637 --> 1.016915).  Saving model ...
Validation loss decreased (1.016915 --> 1.011261).  Saving model ...
Validation loss decreased (1.011261 --> 1.010615).  Saving model ...
Validation loss decreased (1.010615 --> 1.007302).  Saving model ...
Validation loss decreased (1.007302 --> 1.005101).  Saving model ...
Validation loss decreased (1.005101 --> 1.001954).  Saving model ...
Validation loss decreased (1.001954 --> 0.997656).  Saving model ...
Validation loss decreased (0.997656 --> 0.997591).  Saving model ...
Validation loss decreased (0.997591 --> 0.995451).  Saving model ...
Validation loss decreased (0.995451 --> 0.993542).  Saving model ...
Validation loss decreased (0.993542 --> 0.990772).  Saving model ...
Validation loss decreased (0.990772 --> 0.988688).  Saving model ...
Validation loss decreased (0.988688 --> 0.986588).  Saving model ...
Validation loss decreased (0.986588 --> 0.983215).  Saving model ...
Validation loss decreased (0.983215 --> 0.982441).  Saving model ...
Validation loss decreased (0.982441 --> 0.981525).  Saving model ...
Validation loss decreased (0.981525 --> 0.979759).  Saving model ...
Validation loss decreased (0.979759 --> 0.978186).  Saving model ...
Validation loss decreased (0.978186 --> 0.976616).  Saving model ...
Validation loss decreased (0.976616 --> 0.974836).  Saving model ...
Validation loss decreased (0.974836 --> 0.972181).  Saving model ...
Validation loss decreased (0.972181 --> 0.970370).  Saving model ...
Validation loss decreased (0.970370 --> 0.969534).  Saving model ...
Validation loss decreased (0.969534 --> 0.968799).  Saving model ...
Validation loss decreased (0.968799 --> 0.967385).  Saving model ...
Validation loss decreased (0.967385 --> 0.966417).  Saving model ...
Validation loss decreased (0.966417 --> 0.965960).  Saving model ...
EarlyStopping counter: 1 out of 10.0
Validation loss decreased (0.965960 --> 0.963591).  Saving model ...
Validation loss decreased (0.963591 --> 0.962641).  Saving model ...
Validation loss decreased (0.962641 --> 0.959872).  Saving model ...
Validation loss decreased (0.959872 --> 0.959621).  Saving model ...
EarlyStopping counter: 1 out of 10.0
EarlyStopping counter: 2 out of 10.0
Validation loss decreased (0.959621 --> 0.957272).  Saving model ...
Validation loss decreased (0.957272 --> 0.954929).  Saving model ...
Validation loss decreased (0.954929 --> 0.953911).  Saving model ...
EarlyStopping counter: 1 out of 10.0
EarlyStopping counter: 2 out of 10.0
EarlyStopping counter: 3 out of 10.0
Validation loss decreased (0.953911 --> 0.952844).  Saving model ...
Validation loss decreased (0.952844 --> 0.951492).  Saving model ...
Validation loss decreased (0.951492 --> 0.949612).  Saving model ...
Validation loss decreased (0.949612 --> 0.948965).  Saving model ...
Validation loss decreased (0.948965 --> 0.948229).  Saving model ...
Validation loss decreased (0.948229 --> 0.945820).  Saving model ...
EarlyStopping counter: 1 out of 10.0
EarlyStopping counter: 2 out of 10.0
EarlyStopping counter: 3 out of 10.0
EarlyStopping counter: 4 out of 10.0
EarlyStopping counter: 5 out of 10.0
EarlyStopping counter: 6 out of 10.0
EarlyStopping counter: 7 out of 10.0
Validation loss decreased (0.945820 --> 0.945189).  Saving model ...
Validation loss decreased (0.945189 --> 0.943871).  Saving model ...
EarlyStopping counter: 1 out of 10.0
EarlyStopping counter: 2 out of 10.0
EarlyStopping counter: 3 out of 10.0
EarlyStopping counter: 4 out of 10.0
EarlyStopping counter: 5 out of 10.0
EarlyStopping counter: 6 out of 10.0
Validation loss decreased (0.943871 --> 0.941949).  Saving model ...
EarlyStopping counter: 1 out of 10.0
EarlyStopping counter: 2 out of 10.0
EarlyStopping counter: 3 out of 10.0
EarlyStopping counter: 4 out of 10.0
EarlyStopping counter: 5 out of 10.0
EarlyStopping counter: 6 out of 10.0
EarlyStopping counter: 7 out of 10.0
EarlyStopping counter: 8 out of 10.0
EarlyStopping counter: 9 out of 10.0
Validation loss decreased (0.941949 --> 0.941779).  Saving model ...
EarlyStopping counter: 1 out of 10.0
EarlyStopping counter: 2 out of 10.0
EarlyStopping counter: 3 out of 10.0
EarlyStopping counter: 4 out of 10.0
EarlyStopping counter: 5 out of 10.0
EarlyStopping counter: 6 out of 10.0
EarlyStopping counter: 7 out of 10.0
EarlyStopping counter: 8 out of 10.0
EarlyStopping counter: 9 out of 10.0
EarlyStopping counter: 10 out of 10.0
/localscratch/yinan.29019375.0/env/lib/python3.7/site-packages/torch/nn/functional.py:1794: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.
  warnings.warn("nn.functional.tanh is deprecated. Use torch.tanh instead.")
wandb: Waiting for W&B process to finish, PID 166941... (success).
wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: \ 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: | 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: / 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb:                                                                                
wandb: Run history:
wandb:     e_F1 â–â–â–ƒâ–„â–…â–…â–†â–†â–†â–†â–†â–‡â–†â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ
wandb:   e_loss â–ˆâ–ˆâ–‡â–‡â–‡â–†â–†â–…â–…â–„â–„â–„â–ƒâ–ƒâ–ƒâ–ƒâ–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:     t_F1 â–â–â–‚â–ƒâ–ƒâ–ƒâ–„â–„â–…â–…â–…â–…â–†â–†â–†â–†â–†â–†â–‡â–†â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–ˆâ–‡â–‡â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ
wandb:   t_loss â–ˆâ–ˆâ–‡â–‡â–‡â–‡â–†â–†â–†â–…â–…â–…â–…â–…â–„â–„â–„â–„â–„â–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–â–â–â–
wandb: 
wandb: Run summary:
wandb:     e_F1 58.39258
wandb:   e_loss 0.95038
wandb:     t_F1 75.00229
wandb:   t_loss 0.67854
wandb: 
wandb: Synced 4 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Synced leafy-serenity-2: https://wandb.ai/yinanazhou/xl_512_bs_8_lr_1e06_es_10_lc_False_nr_False_sr_False_stem_False_lemma_False_repeat_4_fold_1/runs/3qllq9ke
wandb: Find logs at: ./wandb/run-20220319_055838-3qllq9ke/logs/debug.log
wandb: 

wandb: wandb version 0.12.11 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
2022-03-19 07:39:11.351910: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1
wandb: Tracking run with wandb version 0.12.5
wandb: Syncing run serene-firefly-2
wandb: â­ï¸ View project at https://wandb.ai/yinanazhou/xl_512_bs_8_lr_1e06_es_10_lc_False_nr_False_sr_False_stem_False_lemma_False_repeat_4_fold_2
wandb: ðŸš€ View run at https://wandb.ai/yinanazhou/xl_512_bs_8_lr_1e06_es_10_lc_False_nr_False_sr_False_stem_False_lemma_False_repeat_4_fold_2/runs/12ftut52
wandb: Run data is saved locally in /project/6002780/yinan/Thesis_MER_Lyrics/lyric-emotion/wandb/run-20220319_073908-12ftut52
wandb: Run `wandb offline` to turn off syncing.

Validation loss decreased (inf --> 1.438659).  Saving model ...
Validation loss decreased (1.438659 --> 1.423528).  Saving model ...
Validation loss decreased (1.423528 --> 1.412083).  Saving model ...
Validation loss decreased (1.412083 --> 1.402375).  Saving model ...
Validation loss decreased (1.402375 --> 1.394353).  Saving model ...
Validation loss decreased (1.394353 --> 1.386970).  Saving model ...
Validation loss decreased (1.386970 --> 1.379952).  Saving model ...
Validation loss decreased (1.379952 --> 1.373215).  Saving model ...
Validation loss decreased (1.373215 --> 1.367033).  Saving model ...
Validation loss decreased (1.367033 --> 1.360664).  Saving model ...
Validation loss decreased (1.360664 --> 1.354182).  Saving model ...
Validation loss decreased (1.354182 --> 1.347244).  Saving model ...
Validation loss decreased (1.347244 --> 1.340763).  Saving model ...
Validation loss decreased (1.340763 --> 1.334027).  Saving model ...
Validation loss decreased (1.334027 --> 1.325865).  Saving model ...
Validation loss decreased (1.325865 --> 1.317237).  Saving model ...
Validation loss decreased (1.317237 --> 1.309099).  Saving model ...
Validation loss decreased (1.309099 --> 1.300184).  Saving model ...
Validation loss decreased (1.300184 --> 1.292354).  Saving model ...
Validation loss decreased (1.292354 --> 1.283438).  Saving model ...
Validation loss decreased (1.283438 --> 1.273660).  Saving model ...
Validation loss decreased (1.273660 --> 1.265705).  Saving model ...
Validation loss decreased (1.265705 --> 1.255216).  Saving model ...
Validation loss decreased (1.255216 --> 1.246867).  Saving model ...
Validation loss decreased (1.246867 --> 1.240122).  Saving model ...
Validation loss decreased (1.240122 --> 1.231855).  Saving model ...
Validation loss decreased (1.231855 --> 1.223014).  Saving model ...
Validation loss decreased (1.223014 --> 1.213997).  Saving model ...
Validation loss decreased (1.213997 --> 1.205552).  Saving model ...
Validation loss decreased (1.205552 --> 1.197500).  Saving model ...
Validation loss decreased (1.197500 --> 1.188686).  Saving model ...
Validation loss decreased (1.188686 --> 1.181648).  Saving model ...
Validation loss decreased (1.181648 --> 1.172231).  Saving model ...
Validation loss decreased (1.172231 --> 1.163371).  Saving model ...
Validation loss decreased (1.163371 --> 1.155755).  Saving model ...
Validation loss decreased (1.155755 --> 1.148229).  Saving model ...
Validation loss decreased (1.148229 --> 1.141132).  Saving model ...
Validation loss decreased (1.141132 --> 1.133534).  Saving model ...
Validation loss decreased (1.133534 --> 1.124860).  Saving model ...
Validation loss decreased (1.124860 --> 1.118253).  Saving model ...
Validation loss decreased (1.118253 --> 1.112360).  Saving model ...
Validation loss decreased (1.112360 --> 1.104303).  Saving model ...
Validation loss decreased (1.104303 --> 1.096127).  Saving model ...
Validation loss decreased (1.096127 --> 1.089665).  Saving model ...
Validation loss decreased (1.089665 --> 1.085518).  Saving model ...
Validation loss decreased (1.085518 --> 1.081266).  Saving model ...
Validation loss decreased (1.081266 --> 1.073932).  Saving model ...
Validation loss decreased (1.073932 --> 1.068154).  Saving model ...
Validation loss decreased (1.068154 --> 1.062227).  Saving model ...
Validation loss decreased (1.062227 --> 1.058607).  Saving model ...
Validation loss decreased (1.058607 --> 1.050776).  Saving model ...
Validation loss decreased (1.050776 --> 1.046312).  Saving model ...
Validation loss decreased (1.046312 --> 1.043117).  Saving model ...
Validation loss decreased (1.043117 --> 1.038017).  Saving model ...
Validation loss decreased (1.038017 --> 1.031793).  Saving model ...
Validation loss decreased (1.031793 --> 1.028011).  Saving model ...
Validation loss decreased (1.028011 --> 1.023128).  Saving model ...
Validation loss decreased (1.023128 --> 1.019482).  Saving model ...
Validation loss decreased (1.019482 --> 1.018339).  Saving model ...
Validation loss decreased (1.018339 --> 1.013148).  Saving model ...
Validation loss decreased (1.013148 --> 1.010202).  Saving model ...
Validation loss decreased (1.010202 --> 1.006232).  Saving model ...
Validation loss decreased (1.006232 --> 1.002629).  Saving model ...
Validation loss decreased (1.002629 --> 0.999694).  Saving model ...
Validation loss decreased (0.999694 --> 0.994964).  Saving model ...
Validation loss decreased (0.994964 --> 0.991752).  Saving model ...
Validation loss decreased (0.991752 --> 0.989562).  Saving model ...
Validation loss decreased (0.989562 --> 0.984136).  Saving model ...
Validation loss decreased (0.984136 --> 0.980384).  Saving model ...
Validation loss decreased (0.980384 --> 0.979008).  Saving model ...
Validation loss decreased (0.979008 --> 0.976494).  Saving model ...
Validation loss decreased (0.976494 --> 0.975801).  Saving model ...
Validation loss decreased (0.975801 --> 0.972567).  Saving model ...
Validation loss decreased (0.972567 --> 0.969544).  Saving model ...
Validation loss decreased (0.969544 --> 0.966281).  Saving model ...
Validation loss decreased (0.966281 --> 0.965445).  Saving model ...
Validation loss decreased (0.965445 --> 0.961704).  Saving model ...
Validation loss decreased (0.961704 --> 0.959186).  Saving model ...
Validation loss decreased (0.959186 --> 0.957996).  Saving model ...
Validation loss decreased (0.957996 --> 0.956596).  Saving model ...
Validation loss decreased (0.956596 --> 0.952435).  Saving model ...
Validation loss decreased (0.952435 --> 0.951457).  Saving model ...
Validation loss decreased (0.951457 --> 0.948914).  Saving model ...
Validation loss decreased (0.948914 --> 0.947954).  Saving model ...
EarlyStopping counter: 1 out of 10.0
Validation loss decreased (0.947954 --> 0.944797).  Saving model ...
Validation loss decreased (0.944797 --> 0.944101).  Saving model ...
Validation loss decreased (0.944101 --> 0.942514).  Saving model ...
Validation loss decreased (0.942514 --> 0.941609).  Saving model ...
Validation loss decreased (0.941609 --> 0.939862).  Saving model ...
Validation loss decreased (0.939862 --> 0.935385).  Saving model ...
Validation loss decreased (0.935385 --> 0.935376).  Saving model ...
Validation loss decreased (0.935376 --> 0.934265).  Saving model ...
EarlyStopping counter: 1 out of 10.0
EarlyStopping counter: 2 out of 10.0
Validation loss decreased (0.934265 --> 0.933070).  Saving model ...
Validation loss decreased (0.933070 --> 0.930634).  Saving model ...
Validation loss decreased (0.930634 --> 0.930348).  Saving model ...
EarlyStopping counter: 1 out of 10.0
EarlyStopping counter: 2 out of 10.0
Validation loss decreased (0.930348 --> 0.928105).  Saving model ...
Validation loss decreased (0.928105 --> 0.926269).  Saving model ...
Validation loss decreased (0.926269 --> 0.923071).  Saving model ...
EarlyStopping counter: 1 out of 10.0
EarlyStopping counter: 2 out of 10.0
EarlyStopping counter: 3 out of 10.0
EarlyStopping counter: 4 out of 10.0
EarlyStopping counter: 5 out of 10.0
EarlyStopping counter: 6 out of 10.0
Validation loss decreased (0.923071 --> 0.922724).  Saving model ...
EarlyStopping counter: 1 out of 10.0
Validation loss decreased (0.922724 --> 0.922237).  Saving model ...
EarlyStopping counter: 1 out of 10.0
Validation loss decreased (0.922237 --> 0.922068).  Saving model ...
Validation loss decreased (0.922068 --> 0.919605).  Saving model ...
Validation loss decreased (0.919605 --> 0.919518).  Saving model ...
Validation loss decreased (0.919518 --> 0.918998).  Saving model ...
EarlyStopping counter: 1 out of 10.0
EarlyStopping counter: 2 out of 10.0
EarlyStopping counter: 3 out of 10.0
EarlyStopping counter: 4 out of 10.0
EarlyStopping counter: 5 out of 10.0
EarlyStopping counter: 6 out of 10.0
EarlyStopping counter: 7 out of 10.0
EarlyStopping counter: 8 out of 10.0
EarlyStopping counter: 9 out of 10.0
EarlyStopping counter: 10 out of 10.0
/localscratch/yinan.29019375.0/env/lib/python3.7/site-packages/torch/nn/functional.py:1794: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.
  warnings.warn("nn.functional.tanh is deprecated. Use torch.tanh instead.")
wandb: Waiting for W&B process to finish, PID 172346... (success).
wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: \ 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: | 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: / 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb:                                                                                
wandb: Run history:
wandb:     e_F1 â–â–ƒâ–ƒâ–‚â–ƒâ–„â–„â–…â–…â–…â–…â–†â–†â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ
wandb:   e_loss â–ˆâ–ˆâ–‡â–‡â–‡â–†â–†â–†â–…â–…â–„â–„â–„â–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–‚â–‚â–‚â–‚â–‚â–‚â–‚â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:     t_F1 â–â–â–‚â–‚â–ƒâ–„â–ƒâ–…â–„â–…â–…â–…â–†â–†â–†â–†â–†â–†â–†â–†â–†â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ
wandb:   t_loss â–ˆâ–ˆâ–‡â–‡â–‡â–‡â–‡â–†â–†â–†â–…â–…â–…â–…â–…â–„â–„â–„â–„â–„â–„â–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–‚â–‚â–‚â–‚â–‚â–‚â–â–â–â–â–â–â–
wandb: 
wandb: Run summary:
wandb:     e_F1 62.07625
wandb:   e_loss 0.92577
wandb:     t_F1 71.47476
wandb:   t_loss 0.736
wandb: 
wandb: Synced 4 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Synced serene-firefly-2: https://wandb.ai/yinanazhou/xl_512_bs_8_lr_1e06_es_10_lc_False_nr_False_sr_False_stem_False_lemma_False_repeat_4_fold_2/runs/12ftut52
wandb: Find logs at: ./wandb/run-20220319_073908-12ftut52/logs/debug.log
wandb: 

wandb: wandb version 0.12.11 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
2022-03-19 09:02:23.471415: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1
wandb: Tracking run with wandb version 0.12.5
wandb: Syncing run glorious-thunder-2
wandb: â­ï¸ View project at https://wandb.ai/yinanazhou/xl_512_bs_8_lr_1e06_es_10_lc_False_nr_False_sr_False_stem_False_lemma_False_repeat_5_fold_1
wandb: ðŸš€ View run at https://wandb.ai/yinanazhou/xl_512_bs_8_lr_1e06_es_10_lc_False_nr_False_sr_False_stem_False_lemma_False_repeat_5_fold_1/runs/2mc0y93q
wandb: Run data is saved locally in /project/6002780/yinan/Thesis_MER_Lyrics/lyric-emotion/wandb/run-20220319_090220-2mc0y93q
wandb: Run `wandb offline` to turn off syncing.

Validation loss decreased (inf --> 1.389805).  Saving model ...
Validation loss decreased (1.389805 --> 1.382672).  Saving model ...
Validation loss decreased (1.382672 --> 1.376665).  Saving model ...
Validation loss decreased (1.376665 --> 1.371575).  Saving model ...
Validation loss decreased (1.371575 --> 1.367167).  Saving model ...
Validation loss decreased (1.367167 --> 1.362651).  Saving model ...
Validation loss decreased (1.362651 --> 1.358693).  Saving model ...
Validation loss decreased (1.358693 --> 1.354321).  Saving model ...
Validation loss decreased (1.354321 --> 1.350090).  Saving model ...
Validation loss decreased (1.350090 --> 1.345827).  Saving model ...
Validation loss decreased (1.345827 --> 1.341563).  Saving model ...
Validation loss decreased (1.341563 --> 1.336871).  Saving model ...
Validation loss decreased (1.336871 --> 1.332234).  Saving model ...
Validation loss decreased (1.332234 --> 1.327143).  Saving model ...
Validation loss decreased (1.327143 --> 1.322405).  Saving model ...
Validation loss decreased (1.322405 --> 1.317335).  Saving model ...
Validation loss decreased (1.317335 --> 1.311329).  Saving model ...
Validation loss decreased (1.311329 --> 1.306017).  Saving model ...
Validation loss decreased (1.306017 --> 1.299836).  Saving model ...
Validation loss decreased (1.299836 --> 1.293815).  Saving model ...
Validation loss decreased (1.293815 --> 1.286973).  Saving model ...
Validation loss decreased (1.286973 --> 1.279905).  Saving model ...
Validation loss decreased (1.279905 --> 1.273472).  Saving model ...
Validation loss decreased (1.273472 --> 1.265548).  Saving model ...
Validation loss decreased (1.265548 --> 1.258031).  Saving model ...
Validation loss decreased (1.258031 --> 1.251621).  Saving model ...
Validation loss decreased (1.251621 --> 1.244729).  Saving model ...
Validation loss decreased (1.244729 --> 1.237319).  Saving model ...
Validation loss decreased (1.237319 --> 1.230754).  Saving model ...
Validation loss decreased (1.230754 --> 1.223112).  Saving model ...
Validation loss decreased (1.223112 --> 1.216560).  Saving model ...
Validation loss decreased (1.216560 --> 1.210005).  Saving model ...
Validation loss decreased (1.210005 --> 1.203167).  Saving model ...
Validation loss decreased (1.203167 --> 1.195081).  Saving model ...
Validation loss decreased (1.195081 --> 1.188213).  Saving model ...
Validation loss decreased (1.188213 --> 1.181340).  Saving model ...
Validation loss decreased (1.181340 --> 1.175370).  Saving model ...
Validation loss decreased (1.175370 --> 1.169500).  Saving model ...
Validation loss decreased (1.169500 --> 1.162768).  Saving model ...
Validation loss decreased (1.162768 --> 1.157786).  Saving model ...
Validation loss decreased (1.157786 --> 1.151483).  Saving model ...
Validation loss decreased (1.151483 --> 1.147530).  Saving model ...
Validation loss decreased (1.147530 --> 1.141745).  Saving model ...
Validation loss decreased (1.141745 --> 1.134618).  Saving model ...
Validation loss decreased (1.134618 --> 1.126694).  Saving model ...
Validation loss decreased (1.126694 --> 1.123575).  Saving model ...
Validation loss decreased (1.123575 --> 1.117591).  Saving model ...
Validation loss decreased (1.117591 --> 1.113380).  Saving model ...
Validation loss decreased (1.113380 --> 1.107376).  Saving model ...
Validation loss decreased (1.107376 --> 1.102133).  Saving model ...
Validation loss decreased (1.102133 --> 1.096677).  Saving model ...
Validation loss decreased (1.096677 --> 1.091461).  Saving model ...
Validation loss decreased (1.091461 --> 1.085971).  Saving model ...
Validation loss decreased (1.085971 --> 1.080396).  Saving model ...
Validation loss decreased (1.080396 --> 1.075639).  Saving model ...
Validation loss decreased (1.075639 --> 1.070339).  Saving model ...
Validation loss decreased (1.070339 --> 1.064818).  Saving model ...
Validation loss decreased (1.064818 --> 1.059875).  Saving model ...
Validation loss decreased (1.059875 --> 1.055457).  Saving model ...
Validation loss decreased (1.055457 --> 1.052764).  Saving model ...
Validation loss decreased (1.052764 --> 1.047963).  Saving model ...
Validation loss decreased (1.047963 --> 1.044383).  Saving model ...
Validation loss decreased (1.044383 --> 1.040169).  Saving model ...
Validation loss decreased (1.040169 --> 1.034567).  Saving model ...
Validation loss decreased (1.034567 --> 1.031904).  Saving model ...
Validation loss decreased (1.031904 --> 1.027502).  Saving model ...
Validation loss decreased (1.027502 --> 1.023661).  Saving model ...
Validation loss decreased (1.023661 --> 1.020819).  Saving model ...
Validation loss decreased (1.020819 --> 1.015229).  Saving model ...
Validation loss decreased (1.015229 --> 1.012695).  Saving model ...
Validation loss decreased (1.012695 --> 1.007891).  Saving model ...
Validation loss decreased (1.007891 --> 1.003626).  Saving model ...
Validation loss decreased (1.003626 --> 0.999316).  Saving model ...
Validation loss decreased (0.999316 --> 0.996448).  Saving model ...
Validation loss decreased (0.996448 --> 0.992755).  Saving model ...
Validation loss decreased (0.992755 --> 0.989104).  Saving model ...
Validation loss decreased (0.989104 --> 0.984716).  Saving model ...
Validation loss decreased (0.984716 --> 0.981256).  Saving model ...
Validation loss decreased (0.981256 --> 0.978383).  Saving model ...
Validation loss decreased (0.978383 --> 0.974378).  Saving model ...
Validation loss decreased (0.974378 --> 0.971430).  Saving model ...
Validation loss decreased (0.971430 --> 0.968365).  Saving model ...
Validation loss decreased (0.968365 --> 0.965933).  Saving model ...
Validation loss decreased (0.965933 --> 0.963559).  Saving model ...
Validation loss decreased (0.963559 --> 0.961594).  Saving model ...
Validation loss decreased (0.961594 --> 0.958567).  Saving model ...
Validation loss decreased (0.958567 --> 0.955536).  Saving model ...
Validation loss decreased (0.955536 --> 0.955342).  Saving model ...
Validation loss decreased (0.955342 --> 0.952813).  Saving model ...
Validation loss decreased (0.952813 --> 0.949544).  Saving model ...
Validation loss decreased (0.949544 --> 0.947251).  Saving model ...
Validation loss decreased (0.947251 --> 0.945506).  Saving model ...
Validation loss decreased (0.945506 --> 0.942496).  Saving model ...
Validation loss decreased (0.942496 --> 0.940847).  Saving model ...
Validation loss decreased (0.940847 --> 0.938489).  Saving model ...
Validation loss decreased (0.938489 --> 0.937654).  Saving model ...
Validation loss decreased (0.937654 --> 0.935236).  Saving model ...
Validation loss decreased (0.935236 --> 0.933750).  Saving model ...
Validation loss decreased (0.933750 --> 0.932857).  Saving model ...
Validation loss decreased (0.932857 --> 0.932772).  Saving model ...
Validation loss decreased (0.932772 --> 0.929905).  Saving model ...
Validation loss decreased (0.929905 --> 0.929021).  Saving model ...
Validation loss decreased (0.929021 --> 0.927186).  Saving model ...
Validation loss decreased (0.927186 --> 0.924852).  Saving model ...
Validation loss decreased (0.924852 --> 0.924660).  Saving model ...
Validation loss decreased (0.924660 --> 0.922627).  Saving model ...
Validation loss decreased (0.922627 --> 0.921633).  Saving model ...
Validation loss decreased (0.921633 --> 0.921130).  Saving model ...
Validation loss decreased (0.921130 --> 0.919712).  Saving model ...
Validation loss decreased (0.919712 --> 0.917864).  Saving model ...
Validation loss decreased (0.917864 --> 0.916164).  Saving model ...
Validation loss decreased (0.916164 --> 0.915690).  Saving model ...
Validation loss decreased (0.915690 --> 0.914452).  Saving model ...
Validation loss decreased (0.914452 --> 0.914006).  Saving model ...
Validation loss decreased (0.914006 --> 0.912520).  Saving model ...
Validation loss decreased (0.912520 --> 0.911670).  Saving model ...
Validation loss decreased (0.911670 --> 0.911028).  Saving model ...
EarlyStopping counter: 1 out of 10.0
EarlyStopping counter: 2 out of 10.0
Validation loss decreased (0.911028 --> 0.910503).  Saving model ...
Validation loss decreased (0.910503 --> 0.909703).  Saving model ...
Validation loss decreased (0.909703 --> 0.908742).  Saving model ...
Validation loss decreased (0.908742 --> 0.908335).  Saving model ...
Validation loss decreased (0.908335 --> 0.907698).  Saving model ...
Validation loss decreased (0.907698 --> 0.907621).  Saving model ...
Validation loss decreased (0.907621 --> 0.907027).  Saving model ...
EarlyStopping counter: 1 out of 10.0
Validation loss decreased (0.907027 --> 0.906971).  Saving model ...
EarlyStopping counter: 1 out of 10.0
EarlyStopping counter: 2 out of 10.0
EarlyStopping counter: 3 out of 10.0
Validation loss decreased (0.906971 --> 0.906717).  Saving model ...
Validation loss decreased (0.906717 --> 0.906572).  Saving model ...
Validation loss decreased (0.906572 --> 0.906486).  Saving model ...
EarlyStopping counter: 1 out of 10.0
EarlyStopping counter: 2 out of 10.0
EarlyStopping counter: 3 out of 10.0
EarlyStopping counter: 4 out of 10.0
EarlyStopping counter: 5 out of 10.0
EarlyStopping counter: 6 out of 10.0
EarlyStopping counter: 7 out of 10.0
EarlyStopping counter: 8 out of 10.0
EarlyStopping counter: 9 out of 10.0
EarlyStopping counter: 10 out of 10.0
/localscratch/yinan.29019375.0/env/lib/python3.7/site-packages/torch/nn/functional.py:1794: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.
  warnings.warn("nn.functional.tanh is deprecated. Use torch.tanh instead.")
wandb: Waiting for W&B process to finish, PID 176829... (success).
wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: \ 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: | 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: / 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: \ 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: | 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: / 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: \ 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: | 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: / 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb:                                                                                
wandb: Run history:
wandb:     e_F1 â–â–‚â–ƒâ–„â–„â–„â–„â–…â–…â–…â–…â–†â–†â–†â–†â–†â–†â–†â–†â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ
wandb:   e_loss â–ˆâ–ˆâ–ˆâ–‡â–‡â–‡â–†â–†â–†â–…â–…â–…â–„â–„â–„â–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–‚â–‚â–‚â–‚â–‚â–‚â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:     t_F1 â–â–â–‚â–‚â–‚â–‚â–ƒâ–„â–…â–„â–„â–…â–…â–†â–…â–…â–†â–†â–†â–†â–†â–†â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–ˆâ–‡â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ
wandb:   t_loss â–ˆâ–ˆâ–ˆâ–ˆâ–‡â–‡â–‡â–‡â–†â–†â–†â–†â–…â–…â–…â–…â–„â–„â–„â–„â–„â–„â–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–â–â–
wandb: 
wandb: Run summary:
wandb:     e_F1 63.69489
wandb:   e_loss 0.90751
wandb:     t_F1 74.45136
wandb:   t_loss 0.67597
wandb: 
wandb: Synced 4 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Synced glorious-thunder-2: https://wandb.ai/yinanazhou/xl_512_bs_8_lr_1e06_es_10_lc_False_nr_False_sr_False_stem_False_lemma_False_repeat_5_fold_1/runs/2mc0y93q
wandb: Find logs at: ./wandb/run-20220319_090220-2mc0y93q/logs/debug.log
wandb: 

wandb: wandb version 0.12.11 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
2022-03-19 10:36:09.983401: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1
wandb: Tracking run with wandb version 0.12.5
wandb: Syncing run clean-pine-2
wandb: â­ï¸ View project at https://wandb.ai/yinanazhou/xl_512_bs_8_lr_1e06_es_10_lc_False_nr_False_sr_False_stem_False_lemma_False_repeat_5_fold_2
wandb: ðŸš€ View run at https://wandb.ai/yinanazhou/xl_512_bs_8_lr_1e06_es_10_lc_False_nr_False_sr_False_stem_False_lemma_False_repeat_5_fold_2/runs/2rg96xjq
wandb: Run data is saved locally in /project/6002780/yinan/Thesis_MER_Lyrics/lyric-emotion/wandb/run-20220319_103607-2rg96xjq
wandb: Run `wandb offline` to turn off syncing.

Validation loss decreased (inf --> 1.402870).  Saving model ...
Validation loss decreased (1.402870 --> 1.394393).  Saving model ...
Validation loss decreased (1.394393 --> 1.387029).  Saving model ...
Validation loss decreased (1.387029 --> 1.380359).  Saving model ...
Validation loss decreased (1.380359 --> 1.374347).  Saving model ...
Validation loss decreased (1.374347 --> 1.369407).  Saving model ...
Validation loss decreased (1.369407 --> 1.363820).  Saving model ...
Validation loss decreased (1.363820 --> 1.357952).  Saving model ...
Validation loss decreased (1.357952 --> 1.352434).  Saving model ...
Validation loss decreased (1.352434 --> 1.346565).  Saving model ...
Validation loss decreased (1.346565 --> 1.341742).  Saving model ...
Validation loss decreased (1.341742 --> 1.336452).  Saving model ...
Validation loss decreased (1.336452 --> 1.330303).  Saving model ...
Validation loss decreased (1.330303 --> 1.324367).  Saving model ...
Validation loss decreased (1.324367 --> 1.317781).  Saving model ...
Validation loss decreased (1.317781 --> 1.310962).  Saving model ...
Validation loss decreased (1.310962 --> 1.303486).  Saving model ...
Validation loss decreased (1.303486 --> 1.296265).  Saving model ...
Validation loss decreased (1.296265 --> 1.289769).  Saving model ...
Validation loss decreased (1.289769 --> 1.282481).  Saving model ...
Validation loss decreased (1.282481 --> 1.274729).  Saving model ...
Validation loss decreased (1.274729 --> 1.267291).  Saving model ...
Validation loss decreased (1.267291 --> 1.259390).  Saving model ...
Validation loss decreased (1.259390 --> 1.250854).  Saving model ...
Validation loss decreased (1.250854 --> 1.243201).  Saving model ...
Validation loss decreased (1.243201 --> 1.234717).  Saving model ...
Validation loss decreased (1.234717 --> 1.226461).  Saving model ...
Validation loss decreased (1.226461 --> 1.218573).  Saving model ...
Validation loss decreased (1.218573 --> 1.210562).  Saving model ...
Validation loss decreased (1.210562 --> 1.203020).  Saving model ...
Validation loss decreased (1.203020 --> 1.194831).  Saving model ...
Validation loss decreased (1.194831 --> 1.186170).  Saving model ...
Validation loss decreased (1.186170 --> 1.179071).  Saving model ...
Validation loss decreased (1.179071 --> 1.170324).  Saving model ...
Validation loss decreased (1.170324 --> 1.161735).  Saving model ...
Validation loss decreased (1.161735 --> 1.153321).  Saving model ...
Validation loss decreased (1.153321 --> 1.147341).  Saving model ...
Validation loss decreased (1.147341 --> 1.139609).  Saving model ...
Validation loss decreased (1.139609 --> 1.132052).  Saving model ...
Validation loss decreased (1.132052 --> 1.123658).  Saving model ...
Validation loss decreased (1.123658 --> 1.117385).  Saving model ...
Validation loss decreased (1.117385 --> 1.111827).  Saving model ...
Validation loss decreased (1.111827 --> 1.104888).  Saving model ...
Validation loss decreased (1.104888 --> 1.097095).  Saving model ...
Validation loss decreased (1.097095 --> 1.092274).  Saving model ...
Validation loss decreased (1.092274 --> 1.087412).  Saving model ...
Validation loss decreased (1.087412 --> 1.081011).  Saving model ...
Validation loss decreased (1.081011 --> 1.074213).  Saving model ...
Validation loss decreased (1.074213 --> 1.072647).  Saving model ...
Validation loss decreased (1.072647 --> 1.067075).  Saving model ...
Validation loss decreased (1.067075 --> 1.063520).  Saving model ...
Validation loss decreased (1.063520 --> 1.058271).  Saving model ...
Validation loss decreased (1.058271 --> 1.055173).  Saving model ...
Validation loss decreased (1.055173 --> 1.048539).  Saving model ...
Validation loss decreased (1.048539 --> 1.044283).  Saving model ...
Validation loss decreased (1.044283 --> 1.040505).  Saving model ...
Validation loss decreased (1.040505 --> 1.036432).  Saving model ...
Validation loss decreased (1.036432 --> 1.033579).  Saving model ...
Validation loss decreased (1.033579 --> 1.031402).  Saving model ...
Validation loss decreased (1.031402 --> 1.028643).  Saving model ...
Validation loss decreased (1.028643 --> 1.024114).  Saving model ...
Validation loss decreased (1.024114 --> 1.022430).  Saving model ...
Validation loss decreased (1.022430 --> 1.018198).  Saving model ...
Validation loss decreased (1.018198 --> 1.014584).  Saving model ...
Validation loss decreased (1.014584 --> 1.010544).  Saving model ...
Validation loss decreased (1.010544 --> 1.006664).  Saving model ...
Validation loss decreased (1.006664 --> 1.004425).  Saving model ...
Validation loss decreased (1.004425 --> 1.001927).  Saving model ...
Validation loss decreased (1.001927 --> 0.998504).  Saving model ...
Validation loss decreased (0.998504 --> 0.996219).  Saving model ...
Validation loss decreased (0.996219 --> 0.995233).  Saving model ...
Validation loss decreased (0.995233 --> 0.992649).  Saving model ...
Validation loss decreased (0.992649 --> 0.991392).  Saving model ...
Validation loss decreased (0.991392 --> 0.989242).  Saving model ...
Validation loss decreased (0.989242 --> 0.987892).  Saving model ...
Validation loss decreased (0.987892 --> 0.985427).  Saving model ...
Validation loss decreased (0.985427 --> 0.981196).  Saving model ...
Validation loss decreased (0.981196 --> 0.977175).  Saving model ...
Validation loss decreased (0.977175 --> 0.975059).  Saving model ...
EarlyStopping counter: 1 out of 10.0
Validation loss decreased (0.975059 --> 0.974127).  Saving model ...
Validation loss decreased (0.974127 --> 0.968774).  Saving model ...
Validation loss decreased (0.968774 --> 0.965767).  Saving model ...
EarlyStopping counter: 1 out of 10.0
EarlyStopping counter: 2 out of 10.0
Validation loss decreased (0.965767 --> 0.964778).  Saving model ...
Validation loss decreased (0.964778 --> 0.963648).  Saving model ...
Validation loss decreased (0.963648 --> 0.962108).  Saving model ...
Validation loss decreased (0.962108 --> 0.961192).  Saving model ...
Validation loss decreased (0.961192 --> 0.960279).  Saving model ...
Validation loss decreased (0.960279 --> 0.957568).  Saving model ...
Validation loss decreased (0.957568 --> 0.956798).  Saving model ...
Validation loss decreased (0.956798 --> 0.956017).  Saving model ...
Validation loss decreased (0.956017 --> 0.953478).  Saving model ...
Validation loss decreased (0.953478 --> 0.952088).  Saving model ...
Validation loss decreased (0.952088 --> 0.949661).  Saving model ...
Validation loss decreased (0.949661 --> 0.948329).  Saving model ...
EarlyStopping counter: 1 out of 10.0
Validation loss decreased (0.948329 --> 0.947765).  Saving model ...
Validation loss decreased (0.947765 --> 0.947081).  Saving model ...
Validation loss decreased (0.947081 --> 0.942880).  Saving model ...
EarlyStopping counter: 1 out of 10.0
EarlyStopping counter: 2 out of 10.0
EarlyStopping counter: 3 out of 10.0
EarlyStopping counter: 4 out of 10.0
EarlyStopping counter: 5 out of 10.0
EarlyStopping counter: 6 out of 10.0
EarlyStopping counter: 7 out of 10.0
Validation loss decreased (0.942880 --> 0.940177).  Saving model ...
EarlyStopping counter: 1 out of 10.0
EarlyStopping counter: 2 out of 10.0
Validation loss decreased (0.940177 --> 0.940098).  Saving model ...
Validation loss decreased (0.940098 --> 0.940061).  Saving model ...
Validation loss decreased (0.940061 --> 0.938732).  Saving model ...
EarlyStopping counter: 1 out of 10.0
Validation loss decreased (0.938732 --> 0.937623).  Saving model ...
Validation loss decreased (0.937623 --> 0.937537).  Saving model ...
Validation loss decreased (0.937537 --> 0.935675).  Saving model ...
Validation loss decreased (0.935675 --> 0.934695).  Saving model ...
Validation loss decreased (0.934695 --> 0.933158).  Saving model ...
EarlyStopping counter: 1 out of 10.0
EarlyStopping counter: 2 out of 10.0
EarlyStopping counter: 3 out of 10.0
Validation loss decreased (0.933158 --> 0.932184).  Saving model ...
EarlyStopping counter: 1 out of 10.0
EarlyStopping counter: 2 out of 10.0
EarlyStopping counter: 3 out of 10.0
EarlyStopping counter: 4 out of 10.0
EarlyStopping counter: 5 out of 10.0
EarlyStopping counter: 6 out of 10.0
EarlyStopping counter: 7 out of 10.0
EarlyStopping counter: 8 out of 10.0
EarlyStopping counter: 9 out of 10.0
EarlyStopping counter: 10 out of 10.0
/localscratch/yinan.29019375.0/env/lib/python3.7/site-packages/torch/nn/functional.py:1794: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.
  warnings.warn("nn.functional.tanh is deprecated. Use torch.tanh instead.")
wandb: Waiting for W&B process to finish, PID 181868... (success).
wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: \ 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: | 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: / 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: \ 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: | 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: / 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: \ 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: | 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: / 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: \ 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: | 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb:                                                                                
wandb: Run history:
wandb:     e_F1 â–â–‚â–ƒâ–„â–…â–…â–…â–…â–†â–†â–†â–†â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–ˆâ–‡â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ
wandb:   e_loss â–ˆâ–ˆâ–‡â–‡â–‡â–‡â–†â–†â–…â–…â–…â–„â–„â–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–‚â–‚â–‚â–‚â–‚â–‚â–‚â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:     t_F1 â–â–â–‚â–‚â–ƒâ–ƒâ–„â–„â–„â–„â–…â–†â–…â–†â–†â–†â–†â–†â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–ˆâ–ˆâ–ˆâ–ˆâ–‡â–ˆ
wandb:   t_loss â–ˆâ–ˆâ–ˆâ–‡â–‡â–‡â–‡â–†â–†â–†â–…â–…â–…â–…â–…â–„â–„â–„â–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–â–â–â–â–
wandb: 
wandb: Run summary:
wandb:     e_F1 61.04052
wandb:   e_loss 0.93535
wandb:     t_F1 73.43376
wandb:   t_loss 0.72395
wandb: 
wandb: Synced 4 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Synced clean-pine-2: https://wandb.ai/yinanazhou/xl_512_bs_8_lr_1e06_es_10_lc_False_nr_False_sr_False_stem_False_lemma_False_repeat_5_fold_2/runs/2rg96xjq
wandb: Find logs at: ./wandb/run-20220319_103607-2rg96xjq/logs/debug.log
wandb: 

