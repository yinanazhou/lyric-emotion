Unloading StdEnv/2020

Due to MODULEPATH changes, the following have been reloaded:
  1) mii/1.1.1


The following have been reloaded with a version change:
  1) python/3.8.2 => python/3.7.4

Using base prefix '/cvmfs/soft.computecanada.ca/easybuild/software/2017/Core/python/3.7.4'
New python executable in /localscratch/yinan.29201085.0/env/bin/python
Installing setuptools, pip, wheel...
done.
Ignoring pip: markers 'python_version < "3"' don't match your environment
Looking in links: /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/nix/avx2, /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/nix/generic, /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic
Collecting pip
Installing collected packages: pip
  Found existing installation: pip 19.1.1
    Uninstalling pip-19.1.1:
      Successfully uninstalled pip-19.1.1
Successfully installed pip-21.2.3+computecanada
Looking in links: /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/nix/avx2, /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/nix/generic, /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/keras-2.8.0+computecanada-py2.py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/Keras_Preprocessing-1.1.2+computecanada-py3-none-any.whl
Requirement already satisfied: matplotlib in /cvmfs/soft.computecanada.ca/easybuild/software/2017/Core/scipy-stack/2019a/lib/python3.7/site-packages (from -r requirements.txt (line 3)) (3.0.2)
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/nltk-3.6.5+computecanada-py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/scikit_learn-0.22.1+computecanada-cp37-cp37m-linux_x86_64.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/tensorboard-2.3.0+computecanada-py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/tensorboard_plugin_wit-1.7.0+computecanada-py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/tensorflow_gpu-2.3.0+computecanada-cp37-cp37m-linux_x86_64.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/tensorflow_estimator-2.3.0+computecanada-py2.py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/tokenizers-0.5.2+computecanada-cp37-cp37m-linux_x86_64.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/nix/avx2/torch-1.4.0+computecanada-cp37-cp37m-linux_x86_64.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/torchtext-0.6.0+computecanada-py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/torchvision-0.8.2+computecanada-cp37-cp37m-linux_x86_64.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/transformers-2.5.1+computecanada-py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/urllib3-1.26.7+computecanada-py2.py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/tqdm-4.63.0+computecanada-py2.py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/click-8.0.4+computecanada-py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/joblib-1.1.0+computecanada-py2.py3-none-any.whl
ERROR: Could not find a version that satisfies the requirement regex>=2021.8.3 (from nltk) (from versions: 2018.1.10+computecanada, 2019.11.1+computecanada, 2020.11.13+computecanada)
ERROR: No matching distribution found for regex>=2021.8.3
Looking in links: /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/nix/avx2, /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/nix/generic, /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic
ERROR: Could not find a version that satisfies the requirement numpy==1.20.0+computacanada (from versions: 1.15.0+computecanada, 1.15.2+computecanada, 1.15.4+computecanada, 1.16.0+computecanada, 1.16.2+computecanada, 1.16.3+computecanada, 1.17.4+computecanada, 1.18.1+computecanada, 1.18.4+computecanada, 1.19.1+computecanada, 1.19.2+computecanada, 1.20.2+computecanada)
ERROR: No matching distribution found for numpy==1.20.0+computacanada
Looking in links: /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/nix/avx2, /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/nix/generic, /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/wandb-0.12.5+computecanada-py2.py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/click-8.0.4+computecanada-py3-none-any.whl
Requirement already satisfied: python-dateutil>=2.6.1 in /cvmfs/soft.computecanada.ca/easybuild/software/2017/Core/scipy-stack/2019a/lib/python3.7/site-packages (from wandb) (2.7.5)
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/GitPython-3.1.24+computecanada-py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/sentry_sdk-1.5.0+computecanada-py2.py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/protobuf-3.19.4+computecanada-py2.py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/psutil-5.7.3+computecanada-cp37-cp37m-linux_x86_64.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/PyYAML-5.3.1+computecanada-cp37-cp37m-linux_x86_64.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/configparser-5.0.2+computecanada-py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/yaspin-2.1.0+computecanada-py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/pathtools-0.1.2+computecanada-py3-none-any.whl
Requirement already satisfied: requests<3,>=2.0.0 in /cvmfs/soft.computecanada.ca/easybuild/software/2017/Core/scipy-stack/2019a/lib/python3.7/site-packages (from wandb) (2.21.0)
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/promise-2.3+computecanada-py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/shortuuid-1.0.1+computecanada-py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/six-1.16.0+computecanada-py2.py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/subprocess32-3.5.4+computecanada-py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/docker_pycreds-0.4.0+computecanada-py2.py3-none-any.whl
Requirement already satisfied: importlib-metadata in /cvmfs/soft.computecanada.ca/easybuild/software/2017/Core/scipy-stack/2019a/lib/python3.7/site-packages (from Click!=8.0.0,>=7.0->wandb) (0.8)
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/gitdb-4.0.9+computecanada-py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/typing_extensions-4.0.1+computecanada-py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/smmap-5.0.0+computecanada-py3-none-any.whl
Requirement already satisfied: certifi>=2017.4.17 in /cvmfs/soft.computecanada.ca/easybuild/software/2017/Core/scipy-stack/2019a/lib/python3.7/site-packages (from requests<3,>=2.0.0->wandb) (2018.11.29)
Requirement already satisfied: urllib3<1.25,>=1.21.1 in /cvmfs/soft.computecanada.ca/easybuild/software/2017/Core/scipy-stack/2019a/lib/python3.7/site-packages (from requests<3,>=2.0.0->wandb) (1.24.1)
Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /cvmfs/soft.computecanada.ca/easybuild/software/2017/Core/scipy-stack/2019a/lib/python3.7/site-packages (from requests<3,>=2.0.0->wandb) (3.0.4)
Requirement already satisfied: idna<2.9,>=2.5 in /cvmfs/soft.computecanada.ca/easybuild/software/2017/Core/scipy-stack/2019a/lib/python3.7/site-packages (from requests<3,>=2.0.0->wandb) (2.8)
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/termcolor-1.1.0+computecanada-py3-none-any.whl
Requirement already satisfied: zipp>=0.3.2 in /cvmfs/soft.computecanada.ca/easybuild/software/2017/Core/scipy-stack/2019a/lib/python3.7/site-packages (from importlib-metadata->Click!=8.0.0,>=7.0->wandb) (0.3.3)
Installing collected packages: smmap, typing-extensions, termcolor, six, gitdb, yaspin, subprocess32, shortuuid, sentry-sdk, PyYAML, psutil, protobuf, promise, pathtools, GitPython, docker-pycreds, configparser, Click, wandb
  Attempting uninstall: six
    Found existing installation: six 1.12.0
    Not uninstalling six at /cvmfs/soft.computecanada.ca/easybuild/software/2017/Core/scipy-stack/2019a/lib/python3.7/site-packages, outside environment /localscratch/yinan.29201085.0/env
    Can't uninstall 'six'. No files were found to uninstall.
Successfully installed Click-8.0.4+computecanada GitPython-3.1.24+computecanada PyYAML-5.3.1+computecanada configparser-5.0.2+computecanada docker-pycreds-0.4.0+computecanada gitdb-4.0.9+computecanada pathtools-0.1.2+computecanada promise-2.3+computecanada protobuf-3.19.4+computecanada psutil-5.7.3+computecanada sentry-sdk-1.5.0+computecanada shortuuid-1.0.1+computecanada six-1.16.0+computecanada smmap-5.0.0+computecanada subprocess32-3.5.4+computecanada termcolor-1.1.0+computecanada typing-extensions-4.0.1+computecanada wandb-0.12.5+computecanada yaspin-2.1.0+computecanada
Looking in links: /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/nix/avx2, /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/nix/generic, /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic
ERROR: Could not find a version that satisfies the requirement sagemaker (from versions: none)
ERROR: No matching distribution found for sagemaker
Looking in links: /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/nix/avx2, /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/nix/generic, /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/torch-1.9.1+computecanada-cp37-cp37m-linux_x86_64.whl
Requirement already satisfied: typing-extensions in /localscratch/yinan.29201085.0/env/lib/python3.7/site-packages (from torch) (4.0.1+computecanada)
Installing collected packages: torch
Successfully installed torch-1.9.1+computecanada
Looking in links: /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/nix/avx2, /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/nix/generic, /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/transformers-2.5.1+computecanada-py3-none-any.whl
Requirement already satisfied: requests in /cvmfs/soft.computecanada.ca/easybuild/software/2017/Core/scipy-stack/2019a/lib/python3.7/site-packages (from transformers==2.5.1+computecanada) (2.21.0)
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/regex-2020.11.13+computecanada-cp37-cp37m-linux_x86_64.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/sentencepiece-0.1.91+computecanada-cp37-cp37m-linux_x86_64.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/filelock-3.4.2+computecanada-py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/sacremoses-0.0.46+computecanada-py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/tqdm-4.63.0+computecanada-py2.py3-none-any.whl
Requirement already satisfied: numpy in /cvmfs/soft.computecanada.ca/easybuild/software/2017/Core/scipy-stack/2019a/lib/python3.7/site-packages (from transformers==2.5.1+computecanada) (1.16.0)
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/boto3-1.21.14+computecanada-py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/tokenizers-0.5.2+computecanada-cp37-cp37m-linux_x86_64.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/botocore-1.24.14+computecanada-py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/jmespath-0.10.0+computecanada-py2.py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/s3transfer-0.5.1+computecanada-py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/urllib3-1.26.8+computecanada-py2.py3-none-any.whl
Requirement already satisfied: python-dateutil<3.0.0,>=2.1 in /cvmfs/soft.computecanada.ca/easybuild/software/2017/Core/scipy-stack/2019a/lib/python3.7/site-packages (from botocore<1.25.0,>=1.24.14->boto3->transformers==2.5.1+computecanada) (2.7.5)
Requirement already satisfied: six>=1.5 in /localscratch/yinan.29201085.0/env/lib/python3.7/site-packages (from python-dateutil<3.0.0,>=2.1->botocore<1.25.0,>=1.24.14->boto3->transformers==2.5.1+computecanada) (1.16.0+computecanada)
Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /cvmfs/soft.computecanada.ca/easybuild/software/2017/Core/scipy-stack/2019a/lib/python3.7/site-packages (from requests->transformers==2.5.1+computecanada) (3.0.4)
Requirement already satisfied: certifi>=2017.4.17 in /cvmfs/soft.computecanada.ca/easybuild/software/2017/Core/scipy-stack/2019a/lib/python3.7/site-packages (from requests->transformers==2.5.1+computecanada) (2018.11.29)
Requirement already satisfied: idna<2.9,>=2.5 in /cvmfs/soft.computecanada.ca/easybuild/software/2017/Core/scipy-stack/2019a/lib/python3.7/site-packages (from requests->transformers==2.5.1+computecanada) (2.8)
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/requests-2.27.1+computecanada-py2.py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/charset_normalizer-2.0.12+computecanada-py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/joblib-1.1.0+computecanada-py2.py3-none-any.whl
Requirement already satisfied: click in /localscratch/yinan.29201085.0/env/lib/python3.7/site-packages (from sacremoses->transformers==2.5.1+computecanada) (8.0.4+computecanada)
Requirement already satisfied: importlib-metadata in /cvmfs/soft.computecanada.ca/easybuild/software/2017/Core/scipy-stack/2019a/lib/python3.7/site-packages (from click->sacremoses->transformers==2.5.1+computecanada) (0.8)
Requirement already satisfied: zipp>=0.3.2 in /cvmfs/soft.computecanada.ca/easybuild/software/2017/Core/scipy-stack/2019a/lib/python3.7/site-packages (from importlib-metadata->click->sacremoses->transformers==2.5.1+computecanada) (0.3.3)
Installing collected packages: urllib3, jmespath, botocore, tqdm, s3transfer, regex, joblib, charset-normalizer, tokenizers, sentencepiece, sacremoses, requests, filelock, boto3, transformers
  Attempting uninstall: urllib3
    Found existing installation: urllib3 1.24.1
    Not uninstalling urllib3 at /cvmfs/soft.computecanada.ca/easybuild/software/2017/Core/scipy-stack/2019a/lib/python3.7/site-packages, outside environment /localscratch/yinan.29201085.0/env
    Can't uninstall 'urllib3'. No files were found to uninstall.
  Attempting uninstall: requests
    Found existing installation: requests 2.21.0
    Not uninstalling requests at /cvmfs/soft.computecanada.ca/easybuild/software/2017/Core/scipy-stack/2019a/lib/python3.7/site-packages, outside environment /localscratch/yinan.29201085.0/env
    Can't uninstall 'requests'. No files were found to uninstall.
Successfully installed boto3-1.21.14+computecanada botocore-1.24.14+computecanada charset-normalizer-2.0.12+computecanada filelock-3.4.2+computecanada jmespath-0.10.0+computecanada joblib-1.1.0+computecanada regex-2020.11.13+computecanada requests-2.27.1+computecanada s3transfer-0.5.1+computecanada sacremoses-0.0.46+computecanada sentencepiece-0.1.91+computecanada tokenizers-0.5.2+computecanada tqdm-4.63.0+computecanada transformers-2.5.1+computecanada urllib3-1.26.8+computecanada
Looking in links: /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/nix/avx2, /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/nix/generic, /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/tensorflow_gpu-2.3.0+computecanada-cp37-cp37m-linux_x86_64.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/Keras_Preprocessing-1.1.2+computecanada-py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/tensorflow_estimator-2.3.0+computecanada-py2.py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/grpcio-1.38.0+computecanada-cp37-cp37m-linux_x86_64.whl
Requirement already satisfied: protobuf>=3.9.2 in /localscratch/yinan.29201085.0/env/lib/python3.7/site-packages (from tensorflow_gpu==2.3.0+computecanada) (3.19.4+computecanada)
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/tensorboard-2.8.0+computecanada-py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/gast-0.3.3+computecanada-py3-none-any.whl
Requirement already satisfied: termcolor>=1.1.0 in /localscratch/yinan.29201085.0/env/lib/python3.7/site-packages (from tensorflow_gpu==2.3.0+computecanada) (1.1.0+computecanada)
Requirement already satisfied: six>=1.12.0 in /localscratch/yinan.29201085.0/env/lib/python3.7/site-packages (from tensorflow_gpu==2.3.0+computecanada) (1.16.0+computecanada)
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/nix/generic/scipy-1.4.1+computecanada-cp37-cp37m-linux_x86_64.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/opt_einsum-3.3.0+computecanada-py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/google_pasta-0.2.0+computecanada-py3-none-any.whl
Requirement already satisfied: numpy<1.19.0,>=1.16.0 in /cvmfs/soft.computecanada.ca/easybuild/software/2017/Core/scipy-stack/2019a/lib/python3.7/site-packages (from tensorflow_gpu==2.3.0+computecanada) (1.16.0)
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/astunparse-1.6.3+computecanada-py2.py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/absl_py-1.0.0+computecanada-py3-none-any.whl
Requirement already satisfied: wheel>=0.26 in /localscratch/yinan.29201085.0/env/lib/python3.7/site-packages (from tensorflow_gpu==2.3.0+computecanada) (0.33.4)
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/wrapt-1.11.2+computecanada-cp37-cp37m-linux_x86_64.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/nix/avx2/h5py-2.10.0+computecanada-cp37-cp37m-linux_x86_64.whl
Requirement already satisfied: requests<3,>=2.21.0 in /localscratch/yinan.29201085.0/env/lib/python3.7/site-packages (from tensorboard<3,>=2.3.0->tensorflow_gpu==2.3.0+computecanada) (2.27.1+computecanada)
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/google_auth-2.3.3+computecanada-py2.py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/Markdown-3.3.6+computecanada-py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/Werkzeug-2.0.3+computecanada-py3-none-any.whl
Requirement already satisfied: setuptools>=41.0.0 in /localscratch/yinan.29201085.0/env/lib/python3.7/site-packages (from tensorboard<3,>=2.3.0->tensorflow_gpu==2.3.0+computecanada) (41.0.1)
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/tensorboard_data_server-0.6.1+computecanada-py3-none-linux_x86_64.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/google_auth_oauthlib-0.4.6+computecanada-py2.py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/tensorboard_plugin_wit-1.8.0+computecanada-py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/rsa-4.8+computecanada-py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/cachetools-4.2.4+computecanada-py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/pyasn1_modules-0.2.8+computecanada-py2.py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/requests_oauthlib-1.3.0+computecanada-py2.py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/importlib_metadata-4.10.1+computecanada-py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/zipp-3.7.0+computecanada-py3-none-any.whl
Requirement already satisfied: typing-extensions>=3.6.4 in /localscratch/yinan.29201085.0/env/lib/python3.7/site-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard<3,>=2.3.0->tensorflow_gpu==2.3.0+computecanada) (4.0.1+computecanada)
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/pyasn1-0.4.8+computecanada-py2.py3-none-any.whl
Requirement already satisfied: certifi>=2017.4.17 in /cvmfs/soft.computecanada.ca/easybuild/software/2017/Core/scipy-stack/2019a/lib/python3.7/site-packages (from requests<3,>=2.21.0->tensorboard<3,>=2.3.0->tensorflow_gpu==2.3.0+computecanada) (2018.11.29)
Requirement already satisfied: charset-normalizer~=2.0.0 in /localscratch/yinan.29201085.0/env/lib/python3.7/site-packages (from requests<3,>=2.21.0->tensorboard<3,>=2.3.0->tensorflow_gpu==2.3.0+computecanada) (2.0.12+computecanada)
Requirement already satisfied: urllib3<1.27,>=1.21.1 in /localscratch/yinan.29201085.0/env/lib/python3.7/site-packages (from requests<3,>=2.21.0->tensorboard<3,>=2.3.0->tensorflow_gpu==2.3.0+computecanada) (1.26.8+computecanada)
Requirement already satisfied: idna<4,>=2.5 in /cvmfs/soft.computecanada.ca/easybuild/software/2017/Core/scipy-stack/2019a/lib/python3.7/site-packages (from requests<3,>=2.21.0->tensorboard<3,>=2.3.0->tensorflow_gpu==2.3.0+computecanada) (2.8)
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/oauthlib-3.1.1+computecanada-py2.py3-none-any.whl
Installing collected packages: pyasn1, zipp, rsa, pyasn1-modules, oauthlib, cachetools, requests-oauthlib, importlib-metadata, google-auth, werkzeug, tensorboard-plugin-wit, tensorboard-data-server, markdown, grpcio, google-auth-oauthlib, absl-py, wrapt, tensorflow-estimator, tensorboard, scipy, opt-einsum, keras-preprocessing, h5py, google-pasta, gast, astunparse, tensorflow-gpu
  Attempting uninstall: pyasn1
    Found existing installation: pyasn1 0.4.3
    Not uninstalling pyasn1 at /cvmfs/soft.computecanada.ca/easybuild/software/2017/Core/scipy-stack/2019a/lib/python3.7/site-packages, outside environment /localscratch/yinan.29201085.0/env
    Can't uninstall 'pyasn1'. No files were found to uninstall.
  Attempting uninstall: zipp
    Found existing installation: zipp 0.3.3
    Not uninstalling zipp at /cvmfs/soft.computecanada.ca/easybuild/software/2017/Core/scipy-stack/2019a/lib/python3.7/site-packages, outside environment /localscratch/yinan.29201085.0/env
    Can't uninstall 'zipp'. No files were found to uninstall.
  Attempting uninstall: importlib-metadata
    Found existing installation: importlib-metadata 0.8
    Not uninstalling importlib-metadata at /cvmfs/soft.computecanada.ca/easybuild/software/2017/Core/scipy-stack/2019a/lib/python3.7/site-packages, outside environment /localscratch/yinan.29201085.0/env
    Can't uninstall 'importlib-metadata'. No files were found to uninstall.
  Attempting uninstall: scipy
    Found existing installation: scipy 1.2.0
    Not uninstalling scipy at /cvmfs/soft.computecanada.ca/easybuild/software/2017/Core/scipy-stack/2019a/lib/python3.7/site-packages, outside environment /localscratch/yinan.29201085.0/env
    Can't uninstall 'scipy'. No files were found to uninstall.
Successfully installed absl-py-1.0.0+computecanada astunparse-1.6.3+computecanada cachetools-4.2.4+computecanada gast-0.3.3+computecanada google-auth-2.3.3+computecanada google-auth-oauthlib-0.4.6+computecanada google-pasta-0.2.0+computecanada grpcio-1.38.0+computecanada h5py-2.10.0+computecanada importlib-metadata-4.10.1+computecanada keras-preprocessing-1.1.2+computecanada markdown-3.3.6+computecanada oauthlib-3.1.1+computecanada opt-einsum-3.3.0+computecanada pyasn1-0.4.8+computecanada pyasn1-modules-0.2.8+computecanada requests-oauthlib-1.3.0+computecanada rsa-4.8+computecanada scipy-1.4.1+computecanada tensorboard-2.8.0+computecanada tensorboard-data-server-0.6.1+computecanada tensorboard-plugin-wit-1.8.0+computecanada tensorflow-estimator-2.3.0+computecanada tensorflow-gpu-2.3.0+computecanada werkzeug-2.0.3+computecanada wrapt-1.11.2+computecanada zipp-3.7.0+computecanada
Looking in links: /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/nix/avx2, /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/nix/generic, /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/keras-2.8.0+computecanada-py2.py3-none-any.whl
Installing collected packages: Keras
Successfully installed Keras-2.8.0+computecanada
Looking in links: /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/nix/avx2, /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/nix/generic, /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/urllib3-1.26.7+computecanada-py2.py3-none-any.whl
Installing collected packages: urllib3
  Attempting uninstall: urllib3
    Found existing installation: urllib3 1.26.8+computecanada
    Uninstalling urllib3-1.26.8+computecanada:
      Successfully uninstalled urllib3-1.26.8+computecanada
Successfully installed urllib3-1.26.7+computecanada
Looking in links: /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/nix/avx2, /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/nix/generic, /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/nltk-3.7+computecanada-py3-none-any.whl
Requirement already satisfied: tqdm in /localscratch/yinan.29201085.0/env/lib/python3.7/site-packages (from nltk) (4.63.0+computecanada)
Requirement already satisfied: click in /localscratch/yinan.29201085.0/env/lib/python3.7/site-packages (from nltk) (8.0.4+computecanada)
Requirement already satisfied: joblib in /localscratch/yinan.29201085.0/env/lib/python3.7/site-packages (from nltk) (1.1.0+computecanada)
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/nltk-3.6.5+computecanada-py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/nltk-3.6.3+computecanada-py3-none-any.whl
Requirement already satisfied: regex in /localscratch/yinan.29201085.0/env/lib/python3.7/site-packages (from nltk) (2020.11.13+computecanada)
Requirement already satisfied: importlib-metadata in /localscratch/yinan.29201085.0/env/lib/python3.7/site-packages (from click->nltk) (4.10.1+computecanada)
Requirement already satisfied: zipp>=0.5 in /localscratch/yinan.29201085.0/env/lib/python3.7/site-packages (from importlib-metadata->click->nltk) (3.7.0+computecanada)
Requirement already satisfied: typing-extensions>=3.6.4 in /localscratch/yinan.29201085.0/env/lib/python3.7/site-packages (from importlib-metadata->click->nltk) (4.0.1+computecanada)
Installing collected packages: nltk
Successfully installed nltk-3.6.3+computecanada
Looking in links: /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/nix/avx2, /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/nix/generic, /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/scikit_learn-0.22.1+computecanada-cp37-cp37m-linux_x86_64.whl
Requirement already satisfied: numpy>=1.11.0 in /cvmfs/soft.computecanada.ca/easybuild/software/2017/Core/scipy-stack/2019a/lib/python3.7/site-packages (from scikit-learn==0.22.1) (1.16.0)
Requirement already satisfied: scipy>=0.17.0 in /localscratch/yinan.29201085.0/env/lib/python3.7/site-packages (from scikit-learn==0.22.1) (1.4.1+computecanada)
Requirement already satisfied: joblib>=0.11 in /localscratch/yinan.29201085.0/env/lib/python3.7/site-packages (from scikit-learn==0.22.1) (1.1.0+computecanada)
Installing collected packages: scikit-learn
Successfully installed scikit-learn-0.22.1+computecanada
Looking in links: /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/nix/avx2, /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/nix/generic, /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic
Requirement already satisfied: tokenizers==0.5.2 in /localscratch/yinan.29201085.0/env/lib/python3.7/site-packages (0.5.2+computecanada)
wandb: Appending key for api.wandb.ai to your netrc file: /home/yinan/.netrc
Starting Task
2022-03-18 20:18:51.068584: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1
[nltk_data] Downloading package stopwords to /home/yinan/nltk_data...
[nltk_data]   Package stopwords is already up-to-date!
[nltk_data] Downloading package wordnet to /home/yinan/nltk_data...
[nltk_data]   Package wordnet is already up-to-date!
wandb: Currently logged in as: yinanazhou (use `wandb login --relogin` to force relogin)
wandb: wandb version 0.12.11 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
2022-03-18 20:19:08.029460: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1
wandb: Tracking run with wandb version 0.12.5
wandb: Syncing run happy-microwave-2
wandb: ⭐️ View project at https://wandb.ai/yinanazhou/xl_512_bs_8_lr_1e06_es_5_lc_False_nr_False_sr_False_stem_True_lemma_False_repeat_1_fold_1
wandb: 🚀 View run at https://wandb.ai/yinanazhou/xl_512_bs_8_lr_1e06_es_5_lc_False_nr_False_sr_False_stem_True_lemma_False_repeat_1_fold_1/runs/2i05lbcx
wandb: Run data is saved locally in /project/6002780/yinan/Thesis_MER_Lyrics/lyric-emotion/wandb/run-20220318_201905-2i05lbcx
wandb: Run `wandb offline` to turn off syncing.

Validation loss decreased (inf --> 1.430502).  Saving model ...
Validation loss decreased (1.430502 --> 1.411706).  Saving model ...
Validation loss decreased (1.411706 --> 1.396635).  Saving model ...
Validation loss decreased (1.396635 --> 1.384219).  Saving model ...
Validation loss decreased (1.384219 --> 1.374457).  Saving model ...
Validation loss decreased (1.374457 --> 1.365996).  Saving model ...
Validation loss decreased (1.365996 --> 1.359206).  Saving model ...
Validation loss decreased (1.359206 --> 1.353191).  Saving model ...
Validation loss decreased (1.353191 --> 1.348336).  Saving model ...
Validation loss decreased (1.348336 --> 1.342848).  Saving model ...
Validation loss decreased (1.342848 --> 1.337130).  Saving model ...
Validation loss decreased (1.337130 --> 1.331982).  Saving model ...
Validation loss decreased (1.331982 --> 1.326342).  Saving model ...
Validation loss decreased (1.326342 --> 1.321056).  Saving model ...
Validation loss decreased (1.321056 --> 1.316004).  Saving model ...
Validation loss decreased (1.316004 --> 1.310585).  Saving model ...
Validation loss decreased (1.310585 --> 1.305343).  Saving model ...
Validation loss decreased (1.305343 --> 1.300160).  Saving model ...
Validation loss decreased (1.300160 --> 1.294765).  Saving model ...
Validation loss decreased (1.294765 --> 1.287543).  Saving model ...
Validation loss decreased (1.287543 --> 1.280441).  Saving model ...
Validation loss decreased (1.280441 --> 1.274405).  Saving model ...
Validation loss decreased (1.274405 --> 1.268341).  Saving model ...
Validation loss decreased (1.268341 --> 1.260786).  Saving model ...
Validation loss decreased (1.260786 --> 1.253102).  Saving model ...
Validation loss decreased (1.253102 --> 1.245907).  Saving model ...
Validation loss decreased (1.245907 --> 1.239367).  Saving model ...
Validation loss decreased (1.239367 --> 1.234503).  Saving model ...
Validation loss decreased (1.234503 --> 1.228293).  Saving model ...
Validation loss decreased (1.228293 --> 1.222584).  Saving model ...
Validation loss decreased (1.222584 --> 1.216064).  Saving model ...
Validation loss decreased (1.216064 --> 1.210650).  Saving model ...
Validation loss decreased (1.210650 --> 1.207100).  Saving model ...
Validation loss decreased (1.207100 --> 1.200621).  Saving model ...
Validation loss decreased (1.200621 --> 1.194490).  Saving model ...
Validation loss decreased (1.194490 --> 1.189788).  Saving model ...
Validation loss decreased (1.189788 --> 1.188445).  Saving model ...
Validation loss decreased (1.188445 --> 1.182179).  Saving model ...
Validation loss decreased (1.182179 --> 1.178794).  Saving model ...
Validation loss decreased (1.178794 --> 1.173980).  Saving model ...
Validation loss decreased (1.173980 --> 1.166531).  Saving model ...
Validation loss decreased (1.166531 --> 1.162467).  Saving model ...
Validation loss decreased (1.162467 --> 1.158194).  Saving model ...
Validation loss decreased (1.158194 --> 1.155818).  Saving model ...
Validation loss decreased (1.155818 --> 1.151464).  Saving model ...
Validation loss decreased (1.151464 --> 1.147466).  Saving model ...
Validation loss decreased (1.147466 --> 1.143790).  Saving model ...
Validation loss decreased (1.143790 --> 1.141341).  Saving model ...
Validation loss decreased (1.141341 --> 1.135549).  Saving model ...
Validation loss decreased (1.135549 --> 1.134148).  Saving model ...
Validation loss decreased (1.134148 --> 1.129279).  Saving model ...
Validation loss decreased (1.129279 --> 1.125128).  Saving model ...
Validation loss decreased (1.125128 --> 1.123482).  Saving model ...
Validation loss decreased (1.123482 --> 1.120830).  Saving model ...
EarlyStopping counter: 1 out of 5.0
Validation loss decreased (1.120830 --> 1.117757).  Saving model ...
Validation loss decreased (1.117757 --> 1.113687).  Saving model ...
Validation loss decreased (1.113687 --> 1.111035).  Saving model ...
Validation loss decreased (1.111035 --> 1.108442).  Saving model ...
Validation loss decreased (1.108442 --> 1.105160).  Saving model ...
Validation loss decreased (1.105160 --> 1.103039).  Saving model ...
Validation loss decreased (1.103039 --> 1.100567).  Saving model ...
Validation loss decreased (1.100567 --> 1.099276).  Saving model ...
Validation loss decreased (1.099276 --> 1.098061).  Saving model ...
EarlyStopping counter: 1 out of 5.0
Validation loss decreased (1.098061 --> 1.095929).  Saving model ...
Validation loss decreased (1.095929 --> 1.091774).  Saving model ...
EarlyStopping counter: 1 out of 5.0
Validation loss decreased (1.091774 --> 1.089520).  Saving model ...
Validation loss decreased (1.089520 --> 1.084666).  Saving model ...
Validation loss decreased (1.084666 --> 1.083744).  Saving model ...
Validation loss decreased (1.083744 --> 1.081128).  Saving model ...
Validation loss decreased (1.081128 --> 1.080316).  Saving model ...
Validation loss decreased (1.080316 --> 1.076862).  Saving model ...
Validation loss decreased (1.076862 --> 1.074781).  Saving model ...
Validation loss decreased (1.074781 --> 1.074017).  Saving model ...
EarlyStopping counter: 1 out of 5.0
Validation loss decreased (1.074017 --> 1.071483).  Saving model ...
Validation loss decreased (1.071483 --> 1.069455).  Saving model ...
Validation loss decreased (1.069455 --> 1.065857).  Saving model ...
EarlyStopping counter: 1 out of 5.0
EarlyStopping counter: 2 out of 5.0
Validation loss decreased (1.065857 --> 1.065726).  Saving model ...
Validation loss decreased (1.065726 --> 1.061777).  Saving model ...
Validation loss decreased (1.061777 --> 1.060714).  Saving model ...
Validation loss decreased (1.060714 --> 1.060006).  Saving model ...
EarlyStopping counter: 1 out of 5.0
EarlyStopping counter: 2 out of 5.0
Validation loss decreased (1.060006 --> 1.058762).  Saving model ...
EarlyStopping counter: 1 out of 5.0
Validation loss decreased (1.058762 --> 1.057055).  Saving model ...
Validation loss decreased (1.057055 --> 1.054931).  Saving model ...
Validation loss decreased (1.054931 --> 1.054297).  Saving model ...
EarlyStopping counter: 1 out of 5.0
EarlyStopping counter: 2 out of 5.0
Validation loss decreased (1.054297 --> 1.051264).  Saving model ...
EarlyStopping counter: 1 out of 5.0
Validation loss decreased (1.051264 --> 1.051008).  Saving model ...
EarlyStopping counter: 1 out of 5.0
EarlyStopping counter: 2 out of 5.0
Validation loss decreased (1.051008 --> 1.050266).  Saving model ...
EarlyStopping counter: 1 out of 5.0
EarlyStopping counter: 2 out of 5.0
EarlyStopping counter: 3 out of 5.0
EarlyStopping counter: 4 out of 5.0
EarlyStopping counter: 5 out of 5.0
/localscratch/yinan.29201085.0/env/lib/python3.7/site-packages/torch/nn/functional.py:1794: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.
  warnings.warn("nn.functional.tanh is deprecated. Use torch.tanh instead.")
/localscratch/yinan.29201085.0/env/lib/python3.7/site-packages/transformers/optimization.py:155: UserWarning: This overload of add_ is deprecated:
	add_(Number alpha, Tensor other)
Consider using one of the following signatures instead:
	add_(Tensor other, *, Number alpha) (Triggered internally at  ../torch/csrc/utils/python_arg_parser.cpp:1025.)
  exp_avg.mul_(beta1).add_(1.0 - beta1, grad)
wandb: Waiting for W&B process to finish, PID 206270... (success).
wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: \ 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: | 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: / 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: \ 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: | 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: / 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: \ 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: | 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: / 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb:                                                                                
wandb: Run history:
wandb:     e_F1 ▁▁▃▄▄▅▅▅▆▆▆▆▆▇▇▇▇▇▇▇▇█▇▇████████████████
wandb:   e_loss █▇▇▆▆▆▆▅▅▅▄▄▄▄▃▃▃▃▃▂▂▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁
wandb:     t_F1 ▁▁▃▂▃▃▄▃▄▄▅▅▅▅▆▆▆▆▆▆▆▆▇▆▇▇▇▇▇▇▇▇▇███████
wandb:   t_loss ██▇▇▇▇▇▇▆▆▆▅▅▅▅▄▄▄▄▄▄▃▃▃▃▃▃▂▂▂▂▂▂▂▂▁▁▂▁▁
wandb: 
wandb: Run summary:
wandb:     e_F1 55.09936
wandb:   e_loss 1.05173
wandb:     t_F1 69.29149
wandb:   t_loss 0.80347
wandb: 
wandb: Synced 4 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Synced happy-microwave-2: https://wandb.ai/yinanazhou/xl_512_bs_8_lr_1e06_es_5_lc_False_nr_False_sr_False_stem_True_lemma_False_repeat_1_fold_1/runs/2i05lbcx
wandb: Find logs at: ./wandb/run-20220318_201905-2i05lbcx/logs/debug.log
wandb: 

wandb: wandb version 0.12.11 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
2022-03-18 21:29:37.834729: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1
wandb: Tracking run with wandb version 0.12.5
wandb: Syncing run dulcet-sea-2
wandb: ⭐️ View project at https://wandb.ai/yinanazhou/xl_512_bs_8_lr_1e06_es_5_lc_False_nr_False_sr_False_stem_True_lemma_False_repeat_1_fold_2
wandb: 🚀 View run at https://wandb.ai/yinanazhou/xl_512_bs_8_lr_1e06_es_5_lc_False_nr_False_sr_False_stem_True_lemma_False_repeat_1_fold_2/runs/1wxy0cka
wandb: Run data is saved locally in /project/6002780/yinan/Thesis_MER_Lyrics/lyric-emotion/wandb/run-20220318_212934-1wxy0cka
wandb: Run `wandb offline` to turn off syncing.

Validation loss decreased (inf --> 1.480582).  Saving model ...
Validation loss decreased (1.480582 --> 1.451816).  Saving model ...
Validation loss decreased (1.451816 --> 1.427669).  Saving model ...
Validation loss decreased (1.427669 --> 1.407614).  Saving model ...
Validation loss decreased (1.407614 --> 1.392228).  Saving model ...
Validation loss decreased (1.392228 --> 1.380846).  Saving model ...
Validation loss decreased (1.380846 --> 1.370812).  Saving model ...
Validation loss decreased (1.370812 --> 1.362156).  Saving model ...
Validation loss decreased (1.362156 --> 1.354825).  Saving model ...
Validation loss decreased (1.354825 --> 1.348565).  Saving model ...
Validation loss decreased (1.348565 --> 1.342249).  Saving model ...
Validation loss decreased (1.342249 --> 1.337114).  Saving model ...
Validation loss decreased (1.337114 --> 1.331809).  Saving model ...
Validation loss decreased (1.331809 --> 1.326639).  Saving model ...
Validation loss decreased (1.326639 --> 1.321893).  Saving model ...
Validation loss decreased (1.321893 --> 1.317352).  Saving model ...
Validation loss decreased (1.317352 --> 1.312353).  Saving model ...
Validation loss decreased (1.312353 --> 1.307373).  Saving model ...
Validation loss decreased (1.307373 --> 1.302153).  Saving model ...
Validation loss decreased (1.302153 --> 1.296418).  Saving model ...
Validation loss decreased (1.296418 --> 1.289932).  Saving model ...
Validation loss decreased (1.289932 --> 1.284176).  Saving model ...
Validation loss decreased (1.284176 --> 1.277621).  Saving model ...
Validation loss decreased (1.277621 --> 1.271989).  Saving model ...
Validation loss decreased (1.271989 --> 1.265790).  Saving model ...
Validation loss decreased (1.265790 --> 1.259756).  Saving model ...
Validation loss decreased (1.259756 --> 1.253240).  Saving model ...
Validation loss decreased (1.253240 --> 1.246559).  Saving model ...
Validation loss decreased (1.246559 --> 1.240504).  Saving model ...
Validation loss decreased (1.240504 --> 1.234880).  Saving model ...
Validation loss decreased (1.234880 --> 1.228637).  Saving model ...
Validation loss decreased (1.228637 --> 1.222800).  Saving model ...
Validation loss decreased (1.222800 --> 1.216363).  Saving model ...
Validation loss decreased (1.216363 --> 1.208803).  Saving model ...
Validation loss decreased (1.208803 --> 1.201621).  Saving model ...
Validation loss decreased (1.201621 --> 1.195407).  Saving model ...
Validation loss decreased (1.195407 --> 1.188903).  Saving model ...
Validation loss decreased (1.188903 --> 1.183351).  Saving model ...
Validation loss decreased (1.183351 --> 1.177095).  Saving model ...
Validation loss decreased (1.177095 --> 1.170673).  Saving model ...
Validation loss decreased (1.170673 --> 1.164494).  Saving model ...
Validation loss decreased (1.164494 --> 1.158800).  Saving model ...
Validation loss decreased (1.158800 --> 1.152329).  Saving model ...
Validation loss decreased (1.152329 --> 1.146458).  Saving model ...
Validation loss decreased (1.146458 --> 1.141642).  Saving model ...
Validation loss decreased (1.141642 --> 1.135207).  Saving model ...
Validation loss decreased (1.135207 --> 1.130143).  Saving model ...
Validation loss decreased (1.130143 --> 1.124114).  Saving model ...
Validation loss decreased (1.124114 --> 1.118459).  Saving model ...
Validation loss decreased (1.118459 --> 1.111332).  Saving model ...
Validation loss decreased (1.111332 --> 1.106285).  Saving model ...
Validation loss decreased (1.106285 --> 1.100681).  Saving model ...
Validation loss decreased (1.100681 --> 1.095458).  Saving model ...
Validation loss decreased (1.095458 --> 1.091260).  Saving model ...
Validation loss decreased (1.091260 --> 1.084899).  Saving model ...
Validation loss decreased (1.084899 --> 1.080272).  Saving model ...
Validation loss decreased (1.080272 --> 1.075492).  Saving model ...
Validation loss decreased (1.075492 --> 1.069463).  Saving model ...
Validation loss decreased (1.069463 --> 1.064993).  Saving model ...
Validation loss decreased (1.064993 --> 1.060137).  Saving model ...
Validation loss decreased (1.060137 --> 1.055028).  Saving model ...
Validation loss decreased (1.055028 --> 1.049232).  Saving model ...
Validation loss decreased (1.049232 --> 1.045083).  Saving model ...
Validation loss decreased (1.045083 --> 1.039032).  Saving model ...
Validation loss decreased (1.039032 --> 1.035692).  Saving model ...
Validation loss decreased (1.035692 --> 1.032710).  Saving model ...
Validation loss decreased (1.032710 --> 1.027545).  Saving model ...
Validation loss decreased (1.027545 --> 1.024141).  Saving model ...
Validation loss decreased (1.024141 --> 1.021160).  Saving model ...
Validation loss decreased (1.021160 --> 1.016317).  Saving model ...
Validation loss decreased (1.016317 --> 1.012002).  Saving model ...
Validation loss decreased (1.012002 --> 1.008694).  Saving model ...
Validation loss decreased (1.008694 --> 1.006528).  Saving model ...
Validation loss decreased (1.006528 --> 1.003201).  Saving model ...
Validation loss decreased (1.003201 --> 0.998676).  Saving model ...
Validation loss decreased (0.998676 --> 0.998231).  Saving model ...
Validation loss decreased (0.998231 --> 0.994169).  Saving model ...
Validation loss decreased (0.994169 --> 0.989446).  Saving model ...
Validation loss decreased (0.989446 --> 0.986626).  Saving model ...
Validation loss decreased (0.986626 --> 0.983535).  Saving model ...
Validation loss decreased (0.983535 --> 0.980211).  Saving model ...
Validation loss decreased (0.980211 --> 0.978693).  Saving model ...
Validation loss decreased (0.978693 --> 0.974696).  Saving model ...
Validation loss decreased (0.974696 --> 0.971719).  Saving model ...
Validation loss decreased (0.971719 --> 0.969040).  Saving model ...
Validation loss decreased (0.969040 --> 0.968127).  Saving model ...
Validation loss decreased (0.968127 --> 0.966461).  Saving model ...
Validation loss decreased (0.966461 --> 0.961695).  Saving model ...
Validation loss decreased (0.961695 --> 0.960563).  Saving model ...
Validation loss decreased (0.960563 --> 0.958790).  Saving model ...
Validation loss decreased (0.958790 --> 0.956390).  Saving model ...
Validation loss decreased (0.956390 --> 0.954145).  Saving model ...
Validation loss decreased (0.954145 --> 0.952878).  Saving model ...
Validation loss decreased (0.952878 --> 0.952239).  Saving model ...
Validation loss decreased (0.952239 --> 0.948420).  Saving model ...
Validation loss decreased (0.948420 --> 0.946260).  Saving model ...
Validation loss decreased (0.946260 --> 0.945442).  Saving model ...
Validation loss decreased (0.945442 --> 0.943492).  Saving model ...
Validation loss decreased (0.943492 --> 0.941555).  Saving model ...
Validation loss decreased (0.941555 --> 0.939616).  Saving model ...
Validation loss decreased (0.939616 --> 0.938362).  Saving model ...
EarlyStopping counter: 1 out of 5.0
Validation loss decreased (0.938362 --> 0.936318).  Saving model ...
Validation loss decreased (0.936318 --> 0.934227).  Saving model ...
Validation loss decreased (0.934227 --> 0.934081).  Saving model ...
Validation loss decreased (0.934081 --> 0.932316).  Saving model ...
Validation loss decreased (0.932316 --> 0.930987).  Saving model ...
EarlyStopping counter: 1 out of 5.0
Validation loss decreased (0.930987 --> 0.929463).  Saving model ...
Validation loss decreased (0.929463 --> 0.927043).  Saving model ...
Validation loss decreased (0.927043 --> 0.926521).  Saving model ...
Validation loss decreased (0.926521 --> 0.924123).  Saving model ...
EarlyStopping counter: 1 out of 5.0
EarlyStopping counter: 2 out of 5.0
EarlyStopping counter: 3 out of 5.0
Validation loss decreased (0.924123 --> 0.923498).  Saving model ...
Validation loss decreased (0.923498 --> 0.922425).  Saving model ...
EarlyStopping counter: 1 out of 5.0
Validation loss decreased (0.922425 --> 0.920624).  Saving model ...
EarlyStopping counter: 1 out of 5.0
EarlyStopping counter: 2 out of 5.0
EarlyStopping counter: 3 out of 5.0
EarlyStopping counter: 4 out of 5.0
EarlyStopping counter: 5 out of 5.0
/localscratch/yinan.29201085.0/env/lib/python3.7/site-packages/torch/nn/functional.py:1794: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.
  warnings.warn("nn.functional.tanh is deprecated. Use torch.tanh instead.")
wandb: Waiting for W&B process to finish, PID 210054... (success).
wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: \ 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: | 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: / 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: \ 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: | 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: / 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: \ 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: | 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: / 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb:                                                                                
wandb: Run history:
wandb:     e_F1 ▁▁▂▃▄▄▅▅▅▆▆▆▆▆▇▇▇▇▇▇▇▇▇▇▇███████████████
wandb:   e_loss █▇▇▆▆▆▆▅▅▅▅▅▄▄▄▄▃▃▃▃▂▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁
wandb:     t_F1 ▁▂▂▃▃▃▄▄▄▄▅▅▅▅▆▆▆▆▆▆▆▇▆▆▇▇▇▇▇█▇▇▇▇█▇▇███
wandb:   t_loss █▇▇▇▇▇▆▆▆▆▆▅▅▅▅▄▄▄▄▄▄▃▃▃▃▃▂▂▃▂▂▂▂▂▂▂▁▁▁▁
wandb: 
wandb: Run summary:
wandb:     e_F1 60.89931
wandb:   e_loss 0.92122
wandb:     t_F1 67.74199
wandb:   t_loss 0.80768
wandb: 
wandb: Synced 4 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Synced dulcet-sea-2: https://wandb.ai/yinanazhou/xl_512_bs_8_lr_1e06_es_5_lc_False_nr_False_sr_False_stem_True_lemma_False_repeat_1_fold_2/runs/1wxy0cka
wandb: Find logs at: ./wandb/run-20220318_212934-1wxy0cka/logs/debug.log
wandb: 

wandb: wandb version 0.12.11 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
2022-03-18 22:51:17.119695: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1
wandb: Tracking run with wandb version 0.12.5
wandb: Syncing run apricot-water-2
wandb: ⭐️ View project at https://wandb.ai/yinanazhou/xl_512_bs_8_lr_1e06_es_5_lc_False_nr_False_sr_False_stem_True_lemma_False_repeat_2_fold_1
wandb: 🚀 View run at https://wandb.ai/yinanazhou/xl_512_bs_8_lr_1e06_es_5_lc_False_nr_False_sr_False_stem_True_lemma_False_repeat_2_fold_1/runs/3126qe61
wandb: Run data is saved locally in /project/6002780/yinan/Thesis_MER_Lyrics/lyric-emotion/wandb/run-20220318_225114-3126qe61
wandb: Run `wandb offline` to turn off syncing.

Validation loss decreased (inf --> 1.440492).  Saving model ...
Validation loss decreased (1.440492 --> 1.411764).  Saving model ...
Validation loss decreased (1.411764 --> 1.391266).  Saving model ...
Validation loss decreased (1.391266 --> 1.377170).  Saving model ...
Validation loss decreased (1.377170 --> 1.366500).  Saving model ...
Validation loss decreased (1.366500 --> 1.358986).  Saving model ...
Validation loss decreased (1.358986 --> 1.352793).  Saving model ...
Validation loss decreased (1.352793 --> 1.347815).  Saving model ...
Validation loss decreased (1.347815 --> 1.343536).  Saving model ...
Validation loss decreased (1.343536 --> 1.339762).  Saving model ...
Validation loss decreased (1.339762 --> 1.336072).  Saving model ...
Validation loss decreased (1.336072 --> 1.331697).  Saving model ...
Validation loss decreased (1.331697 --> 1.327003).  Saving model ...
Validation loss decreased (1.327003 --> 1.321935).  Saving model ...
Validation loss decreased (1.321935 --> 1.317429).  Saving model ...
Validation loss decreased (1.317429 --> 1.312971).  Saving model ...
Validation loss decreased (1.312971 --> 1.308383).  Saving model ...
Validation loss decreased (1.308383 --> 1.303277).  Saving model ...
Validation loss decreased (1.303277 --> 1.297717).  Saving model ...
Validation loss decreased (1.297717 --> 1.292335).  Saving model ...
Validation loss decreased (1.292335 --> 1.286972).  Saving model ...
Validation loss decreased (1.286972 --> 1.281063).  Saving model ...
Validation loss decreased (1.281063 --> 1.273986).  Saving model ...
Validation loss decreased (1.273986 --> 1.267000).  Saving model ...
Validation loss decreased (1.267000 --> 1.260766).  Saving model ...
Validation loss decreased (1.260766 --> 1.254024).  Saving model ...
Validation loss decreased (1.254024 --> 1.247739).  Saving model ...
Validation loss decreased (1.247739 --> 1.240556).  Saving model ...
Validation loss decreased (1.240556 --> 1.233272).  Saving model ...
Validation loss decreased (1.233272 --> 1.225899).  Saving model ...
Validation loss decreased (1.225899 --> 1.217040).  Saving model ...
Validation loss decreased (1.217040 --> 1.210045).  Saving model ...
Validation loss decreased (1.210045 --> 1.202763).  Saving model ...
Validation loss decreased (1.202763 --> 1.194776).  Saving model ...
Validation loss decreased (1.194776 --> 1.187427).  Saving model ...
Validation loss decreased (1.187427 --> 1.178723).  Saving model ...
Validation loss decreased (1.178723 --> 1.170421).  Saving model ...
Validation loss decreased (1.170421 --> 1.163180).  Saving model ...
Validation loss decreased (1.163180 --> 1.155168).  Saving model ...
Validation loss decreased (1.155168 --> 1.146833).  Saving model ...
Validation loss decreased (1.146833 --> 1.139645).  Saving model ...
Validation loss decreased (1.139645 --> 1.130806).  Saving model ...
Validation loss decreased (1.130806 --> 1.123859).  Saving model ...
Validation loss decreased (1.123859 --> 1.117051).  Saving model ...
Validation loss decreased (1.117051 --> 1.109784).  Saving model ...
Validation loss decreased (1.109784 --> 1.104585).  Saving model ...
Validation loss decreased (1.104585 --> 1.099070).  Saving model ...
Validation loss decreased (1.099070 --> 1.093095).  Saving model ...
Validation loss decreased (1.093095 --> 1.088169).  Saving model ...
Validation loss decreased (1.088169 --> 1.082063).  Saving model ...
Validation loss decreased (1.082063 --> 1.076593).  Saving model ...
Validation loss decreased (1.076593 --> 1.072264).  Saving model ...
Validation loss decreased (1.072264 --> 1.066672).  Saving model ...
Validation loss decreased (1.066672 --> 1.061773).  Saving model ...
Validation loss decreased (1.061773 --> 1.058191).  Saving model ...
Validation loss decreased (1.058191 --> 1.053375).  Saving model ...
Validation loss decreased (1.053375 --> 1.048999).  Saving model ...
Validation loss decreased (1.048999 --> 1.044867).  Saving model ...
Validation loss decreased (1.044867 --> 1.041041).  Saving model ...
Validation loss decreased (1.041041 --> 1.037828).  Saving model ...
Validation loss decreased (1.037828 --> 1.034662).  Saving model ...
Validation loss decreased (1.034662 --> 1.030767).  Saving model ...
Validation loss decreased (1.030767 --> 1.027850).  Saving model ...
Validation loss decreased (1.027850 --> 1.024473).  Saving model ...
Validation loss decreased (1.024473 --> 1.022343).  Saving model ...
Validation loss decreased (1.022343 --> 1.018377).  Saving model ...
Validation loss decreased (1.018377 --> 1.015434).  Saving model ...
Validation loss decreased (1.015434 --> 1.013033).  Saving model ...
Validation loss decreased (1.013033 --> 1.009421).  Saving model ...
Validation loss decreased (1.009421 --> 1.006514).  Saving model ...
Validation loss decreased (1.006514 --> 1.004742).  Saving model ...
Validation loss decreased (1.004742 --> 1.003027).  Saving model ...
Validation loss decreased (1.003027 --> 1.001578).  Saving model ...
Validation loss decreased (1.001578 --> 1.000148).  Saving model ...
Validation loss decreased (1.000148 --> 0.997752).  Saving model ...
Validation loss decreased (0.997752 --> 0.995477).  Saving model ...
Validation loss decreased (0.995477 --> 0.993838).  Saving model ...
Validation loss decreased (0.993838 --> 0.991999).  Saving model ...
Validation loss decreased (0.991999 --> 0.991484).  Saving model ...
Validation loss decreased (0.991484 --> 0.989019).  Saving model ...
Validation loss decreased (0.989019 --> 0.985783).  Saving model ...
Validation loss decreased (0.985783 --> 0.983330).  Saving model ...
Validation loss decreased (0.983330 --> 0.982025).  Saving model ...
Validation loss decreased (0.982025 --> 0.981171).  Saving model ...
Validation loss decreased (0.981171 --> 0.979257).  Saving model ...
Validation loss decreased (0.979257 --> 0.977678).  Saving model ...
Validation loss decreased (0.977678 --> 0.975699).  Saving model ...
Validation loss decreased (0.975699 --> 0.974000).  Saving model ...
Validation loss decreased (0.974000 --> 0.971767).  Saving model ...
Validation loss decreased (0.971767 --> 0.970732).  Saving model ...
Validation loss decreased (0.970732 --> 0.969981).  Saving model ...
Validation loss decreased (0.969981 --> 0.968050).  Saving model ...
Validation loss decreased (0.968050 --> 0.967990).  Saving model ...
Validation loss decreased (0.967990 --> 0.966411).  Saving model ...
Validation loss decreased (0.966411 --> 0.965073).  Saving model ...
Validation loss decreased (0.965073 --> 0.964875).  Saving model ...
Validation loss decreased (0.964875 --> 0.963630).  Saving model ...
EarlyStopping counter: 1 out of 5.0
Validation loss decreased (0.963630 --> 0.960334).  Saving model ...
EarlyStopping counter: 1 out of 5.0
Validation loss decreased (0.960334 --> 0.959465).  Saving model ...
Validation loss decreased (0.959465 --> 0.957924).  Saving model ...
Validation loss decreased (0.957924 --> 0.956561).  Saving model ...
EarlyStopping counter: 1 out of 5.0
EarlyStopping counter: 2 out of 5.0
Validation loss decreased (0.956561 --> 0.956442).  Saving model ...
Validation loss decreased (0.956442 --> 0.955986).  Saving model ...
Validation loss decreased (0.955986 --> 0.953986).  Saving model ...
EarlyStopping counter: 1 out of 5.0
EarlyStopping counter: 2 out of 5.0
EarlyStopping counter: 3 out of 5.0
EarlyStopping counter: 4 out of 5.0
EarlyStopping counter: 5 out of 5.0
/localscratch/yinan.29201085.0/env/lib/python3.7/site-packages/torch/nn/functional.py:1794: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.
  warnings.warn("nn.functional.tanh is deprecated. Use torch.tanh instead.")
wandb: Waiting for W&B process to finish, PID 214445... (success).
wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: \ 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: | 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: / 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: \ 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: | 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: / 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: \ 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: | 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: / 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb:                                                                                
wandb: Run history:
wandb:     e_F1 ▁▂▃▄▄▄▄▄▅▅▆▆▆▇▇▇▇▇▇▇▇▇▇▇▇▇▇█████████████
wandb:   e_loss █▇▇▇▆▆▆▆▆▅▅▅▄▄▄▃▃▃▃▂▂▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁
wandb:     t_F1 ▁▁▂▃▃▃▄▄▄▄▅▅▅▅▅▆▆▆▆▆▆▇▇▆▇▇▇█▇▇▇█▇███████
wandb:   t_loss ██▇▇▇▆▆▆▆▆▆▅▅▅▅▄▄▄▄▄▄▃▃▃▃▃▃▂▂▂▂▂▂▂▁▂▂▁▁▁
wandb: 
wandb: Run summary:
wandb:     e_F1 57.11043
wandb:   e_loss 0.95431
wandb:     t_F1 70.56349
wandb:   t_loss 0.7949
wandb: 
wandb: Synced 4 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Synced apricot-water-2: https://wandb.ai/yinanazhou/xl_512_bs_8_lr_1e06_es_5_lc_False_nr_False_sr_False_stem_True_lemma_False_repeat_2_fold_1/runs/3126qe61
wandb: Find logs at: ./wandb/run-20220318_225114-3126qe61/logs/debug.log
wandb: 

wandb: wandb version 0.12.11 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
2022-03-19 00:05:04.512947: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1
wandb: Tracking run with wandb version 0.12.5
wandb: Syncing run hearty-water-2
wandb: ⭐️ View project at https://wandb.ai/yinanazhou/xl_512_bs_8_lr_1e06_es_5_lc_False_nr_False_sr_False_stem_True_lemma_False_repeat_2_fold_2
wandb: 🚀 View run at https://wandb.ai/yinanazhou/xl_512_bs_8_lr_1e06_es_5_lc_False_nr_False_sr_False_stem_True_lemma_False_repeat_2_fold_2/runs/34vrnkmi
wandb: Run data is saved locally in /project/6002780/yinan/Thesis_MER_Lyrics/lyric-emotion/wandb/run-20220319_000501-34vrnkmi
wandb: Run `wandb offline` to turn off syncing.

Validation loss decreased (inf --> 1.446916).  Saving model ...
Validation loss decreased (1.446916 --> 1.426207).  Saving model ...
Validation loss decreased (1.426207 --> 1.411010).  Saving model ...
Validation loss decreased (1.411010 --> 1.398416).  Saving model ...
Validation loss decreased (1.398416 --> 1.388721).  Saving model ...
Validation loss decreased (1.388721 --> 1.380101).  Saving model ...
Validation loss decreased (1.380101 --> 1.372887).  Saving model ...
Validation loss decreased (1.372887 --> 1.366606).  Saving model ...
Validation loss decreased (1.366606 --> 1.360940).  Saving model ...
Validation loss decreased (1.360940 --> 1.355841).  Saving model ...
Validation loss decreased (1.355841 --> 1.351128).  Saving model ...
Validation loss decreased (1.351128 --> 1.346486).  Saving model ...
Validation loss decreased (1.346486 --> 1.342384).  Saving model ...
Validation loss decreased (1.342384 --> 1.337832).  Saving model ...
Validation loss decreased (1.337832 --> 1.333387).  Saving model ...
Validation loss decreased (1.333387 --> 1.329249).  Saving model ...
Validation loss decreased (1.329249 --> 1.324606).  Saving model ...
Validation loss decreased (1.324606 --> 1.320098).  Saving model ...
Validation loss decreased (1.320098 --> 1.315566).  Saving model ...
Validation loss decreased (1.315566 --> 1.310968).  Saving model ...
Validation loss decreased (1.310968 --> 1.306056).  Saving model ...
Validation loss decreased (1.306056 --> 1.301245).  Saving model ...
Validation loss decreased (1.301245 --> 1.296235).  Saving model ...
Validation loss decreased (1.296235 --> 1.290351).  Saving model ...
Validation loss decreased (1.290351 --> 1.284702).  Saving model ...
Validation loss decreased (1.284702 --> 1.279483).  Saving model ...
Validation loss decreased (1.279483 --> 1.273648).  Saving model ...
Validation loss decreased (1.273648 --> 1.267201).  Saving model ...
Validation loss decreased (1.267201 --> 1.260957).  Saving model ...
Validation loss decreased (1.260957 --> 1.253747).  Saving model ...
Validation loss decreased (1.253747 --> 1.247365).  Saving model ...
Validation loss decreased (1.247365 --> 1.240502).  Saving model ...
Validation loss decreased (1.240502 --> 1.233323).  Saving model ...
Validation loss decreased (1.233323 --> 1.226853).  Saving model ...
Validation loss decreased (1.226853 --> 1.220481).  Saving model ...
Validation loss decreased (1.220481 --> 1.214704).  Saving model ...
Validation loss decreased (1.214704 --> 1.208579).  Saving model ...
Validation loss decreased (1.208579 --> 1.201987).  Saving model ...
Validation loss decreased (1.201987 --> 1.195533).  Saving model ...
Validation loss decreased (1.195533 --> 1.190214).  Saving model ...
Validation loss decreased (1.190214 --> 1.184187).  Saving model ...
Validation loss decreased (1.184187 --> 1.177683).  Saving model ...
Validation loss decreased (1.177683 --> 1.173811).  Saving model ...
Validation loss decreased (1.173811 --> 1.167745).  Saving model ...
Validation loss decreased (1.167745 --> 1.160448).  Saving model ...
Validation loss decreased (1.160448 --> 1.153640).  Saving model ...
Validation loss decreased (1.153640 --> 1.147886).  Saving model ...
Validation loss decreased (1.147886 --> 1.143278).  Saving model ...
Validation loss decreased (1.143278 --> 1.137791).  Saving model ...
Validation loss decreased (1.137791 --> 1.132434).  Saving model ...
Validation loss decreased (1.132434 --> 1.126068).  Saving model ...
Validation loss decreased (1.126068 --> 1.121678).  Saving model ...
Validation loss decreased (1.121678 --> 1.116662).  Saving model ...
Validation loss decreased (1.116662 --> 1.110982).  Saving model ...
Validation loss decreased (1.110982 --> 1.105922).  Saving model ...
Validation loss decreased (1.105922 --> 1.102925).  Saving model ...
Validation loss decreased (1.102925 --> 1.098416).  Saving model ...
Validation loss decreased (1.098416 --> 1.093523).  Saving model ...
Validation loss decreased (1.093523 --> 1.089697).  Saving model ...
Validation loss decreased (1.089697 --> 1.085601).  Saving model ...
Validation loss decreased (1.085601 --> 1.081241).  Saving model ...
Validation loss decreased (1.081241 --> 1.077483).  Saving model ...
Validation loss decreased (1.077483 --> 1.074338).  Saving model ...
Validation loss decreased (1.074338 --> 1.068999).  Saving model ...
Validation loss decreased (1.068999 --> 1.064848).  Saving model ...
Validation loss decreased (1.064848 --> 1.060960).  Saving model ...
Validation loss decreased (1.060960 --> 1.056893).  Saving model ...
Validation loss decreased (1.056893 --> 1.053585).  Saving model ...
Validation loss decreased (1.053585 --> 1.049376).  Saving model ...
Validation loss decreased (1.049376 --> 1.046745).  Saving model ...
Validation loss decreased (1.046745 --> 1.043540).  Saving model ...
Validation loss decreased (1.043540 --> 1.039437).  Saving model ...
Validation loss decreased (1.039437 --> 1.036550).  Saving model ...
Validation loss decreased (1.036550 --> 1.034518).  Saving model ...
Validation loss decreased (1.034518 --> 1.032426).  Saving model ...
Validation loss decreased (1.032426 --> 1.028657).  Saving model ...
Validation loss decreased (1.028657 --> 1.024485).  Saving model ...
Validation loss decreased (1.024485 --> 1.021886).  Saving model ...
Validation loss decreased (1.021886 --> 1.018947).  Saving model ...
Validation loss decreased (1.018947 --> 1.016935).  Saving model ...
Validation loss decreased (1.016935 --> 1.013894).  Saving model ...
Validation loss decreased (1.013894 --> 1.012446).  Saving model ...
Validation loss decreased (1.012446 --> 1.008985).  Saving model ...
Validation loss decreased (1.008985 --> 1.006296).  Saving model ...
Validation loss decreased (1.006296 --> 1.004420).  Saving model ...
Validation loss decreased (1.004420 --> 1.002694).  Saving model ...
Validation loss decreased (1.002694 --> 1.000047).  Saving model ...
Validation loss decreased (1.000047 --> 0.998149).  Saving model ...
Validation loss decreased (0.998149 --> 0.995894).  Saving model ...
Validation loss decreased (0.995894 --> 0.993159).  Saving model ...
Validation loss decreased (0.993159 --> 0.991405).  Saving model ...
Validation loss decreased (0.991405 --> 0.988704).  Saving model ...
Validation loss decreased (0.988704 --> 0.987560).  Saving model ...
Validation loss decreased (0.987560 --> 0.984555).  Saving model ...
Validation loss decreased (0.984555 --> 0.981928).  Saving model ...
Validation loss decreased (0.981928 --> 0.981347).  Saving model ...
Validation loss decreased (0.981347 --> 0.979538).  Saving model ...
Validation loss decreased (0.979538 --> 0.977016).  Saving model ...
Validation loss decreased (0.977016 --> 0.974793).  Saving model ...
EarlyStopping counter: 1 out of 5.0
Validation loss decreased (0.974793 --> 0.973287).  Saving model ...
Validation loss decreased (0.973287 --> 0.971228).  Saving model ...
Validation loss decreased (0.971228 --> 0.969640).  Saving model ...
Validation loss decreased (0.969640 --> 0.967832).  Saving model ...
Validation loss decreased (0.967832 --> 0.965716).  Saving model ...
EarlyStopping counter: 1 out of 5.0
Validation loss decreased (0.965716 --> 0.965506).  Saving model ...
Validation loss decreased (0.965506 --> 0.961364).  Saving model ...
Validation loss decreased (0.961364 --> 0.959523).  Saving model ...
Validation loss decreased (0.959523 --> 0.958705).  Saving model ...
Validation loss decreased (0.958705 --> 0.958511).  Saving model ...
Validation loss decreased (0.958511 --> 0.956062).  Saving model ...
EarlyStopping counter: 1 out of 5.0
Validation loss decreased (0.956062 --> 0.955937).  Saving model ...
Validation loss decreased (0.955937 --> 0.955372).  Saving model ...
Validation loss decreased (0.955372 --> 0.953490).  Saving model ...
Validation loss decreased (0.953490 --> 0.952509).  Saving model ...
Validation loss decreased (0.952509 --> 0.952490).  Saving model ...
Validation loss decreased (0.952490 --> 0.951204).  Saving model ...
Validation loss decreased (0.951204 --> 0.950346).  Saving model ...
Validation loss decreased (0.950346 --> 0.946275).  Saving model ...
Validation loss decreased (0.946275 --> 0.946178).  Saving model ...
Validation loss decreased (0.946178 --> 0.945037).  Saving model ...
Validation loss decreased (0.945037 --> 0.944327).  Saving model ...
Validation loss decreased (0.944327 --> 0.943769).  Saving model ...
Validation loss decreased (0.943769 --> 0.942132).  Saving model ...
Validation loss decreased (0.942132 --> 0.941422).  Saving model ...
Validation loss decreased (0.941422 --> 0.941018).  Saving model ...
EarlyStopping counter: 1 out of 5.0
EarlyStopping counter: 2 out of 5.0
EarlyStopping counter: 3 out of 5.0
EarlyStopping counter: 4 out of 5.0
EarlyStopping counter: 5 out of 5.0
/localscratch/yinan.29201085.0/env/lib/python3.7/site-packages/torch/nn/functional.py:1794: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.
  warnings.warn("nn.functional.tanh is deprecated. Use torch.tanh instead.")
wandb: Waiting for W&B process to finish, PID 218487... (success).
wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: \ 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: | 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: / 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: \ 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: | 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: / 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: \ 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: | 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: / 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb:                                                                                
wandb: Run history:
wandb:     e_F1 ▁▂▂▃▃▄▅▅▅▅▅▅▆▆▆▆▇▇▇▇▇▇▇▇▇▇▇█████████████
wandb:   e_loss ██▇▇▇▆▆▆▆▅▅▅▄▄▄▄▃▃▃▃▃▂▂▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁
wandb:     t_F1 ▁▁▂▂▃▃▄▄▄▅▄▄▅▅▅▅▆▆▆▆▆▆▆▇▇▇▇▇▇▇█▇▇▇▇▇████
wandb:   t_loss ██▇▇▇▇▆▆▆▆▆▅▅▅▅▅▄▄▄▄▄▃▃▃▃▃▃▃▂▂▂▂▂▂▂▂▁▂▁▁
wandb: 
wandb: Run summary:
wandb:     e_F1 60.47797
wandb:   e_loss 0.94117
wandb:     t_F1 70.19254
wandb:   t_loss 0.76933
wandb: 
wandb: Synced 4 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Synced hearty-water-2: https://wandb.ai/yinanazhou/xl_512_bs_8_lr_1e06_es_5_lc_False_nr_False_sr_False_stem_True_lemma_False_repeat_2_fold_2/runs/34vrnkmi
wandb: Find logs at: ./wandb/run-20220319_000501-34vrnkmi/logs/debug.log
wandb: 

wandb: wandb version 0.12.11 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
2022-03-19 01:30:33.942080: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1
wandb: Tracking run with wandb version 0.12.5
wandb: Syncing run treasured-snowball-2
wandb: ⭐️ View project at https://wandb.ai/yinanazhou/xl_512_bs_8_lr_1e06_es_5_lc_False_nr_False_sr_False_stem_True_lemma_False_repeat_3_fold_1
wandb: 🚀 View run at https://wandb.ai/yinanazhou/xl_512_bs_8_lr_1e06_es_5_lc_False_nr_False_sr_False_stem_True_lemma_False_repeat_3_fold_1/runs/28v1sbtb
wandb: Run data is saved locally in /project/6002780/yinan/Thesis_MER_Lyrics/lyric-emotion/wandb/run-20220319_013029-28v1sbtb
wandb: Run `wandb offline` to turn off syncing.

Validation loss decreased (inf --> 1.434661).  Saving model ...
Validation loss decreased (1.434661 --> 1.412044).  Saving model ...
Validation loss decreased (1.412044 --> 1.396641).  Saving model ...
Validation loss decreased (1.396641 --> 1.385102).  Saving model ...
Validation loss decreased (1.385102 --> 1.376322).  Saving model ...
Validation loss decreased (1.376322 --> 1.369382).  Saving model ...
Validation loss decreased (1.369382 --> 1.363977).  Saving model ...
Validation loss decreased (1.363977 --> 1.358739).  Saving model ...
Validation loss decreased (1.358739 --> 1.354056).  Saving model ...
Validation loss decreased (1.354056 --> 1.348913).  Saving model ...
Validation loss decreased (1.348913 --> 1.343522).  Saving model ...
Validation loss decreased (1.343522 --> 1.338403).  Saving model ...
Validation loss decreased (1.338403 --> 1.333232).  Saving model ...
Validation loss decreased (1.333232 --> 1.327013).  Saving model ...
Validation loss decreased (1.327013 --> 1.321189).  Saving model ...
Validation loss decreased (1.321189 --> 1.315344).  Saving model ...
Validation loss decreased (1.315344 --> 1.309744).  Saving model ...
Validation loss decreased (1.309744 --> 1.303682).  Saving model ...
Validation loss decreased (1.303682 --> 1.297404).  Saving model ...
Validation loss decreased (1.297404 --> 1.291100).  Saving model ...
Validation loss decreased (1.291100 --> 1.283765).  Saving model ...
Validation loss decreased (1.283765 --> 1.277846).  Saving model ...
Validation loss decreased (1.277846 --> 1.269916).  Saving model ...
Validation loss decreased (1.269916 --> 1.262763).  Saving model ...
Validation loss decreased (1.262763 --> 1.255626).  Saving model ...
Validation loss decreased (1.255626 --> 1.248137).  Saving model ...
Validation loss decreased (1.248137 --> 1.241252).  Saving model ...
Validation loss decreased (1.241252 --> 1.233394).  Saving model ...
Validation loss decreased (1.233394 --> 1.225807).  Saving model ...
Validation loss decreased (1.225807 --> 1.218750).  Saving model ...
Validation loss decreased (1.218750 --> 1.211112).  Saving model ...
Validation loss decreased (1.211112 --> 1.204415).  Saving model ...
Validation loss decreased (1.204415 --> 1.198043).  Saving model ...
Validation loss decreased (1.198043 --> 1.191899).  Saving model ...
Validation loss decreased (1.191899 --> 1.184743).  Saving model ...
Validation loss decreased (1.184743 --> 1.178144).  Saving model ...
Validation loss decreased (1.178144 --> 1.171447).  Saving model ...
Validation loss decreased (1.171447 --> 1.164805).  Saving model ...
Validation loss decreased (1.164805 --> 1.159338).  Saving model ...
Validation loss decreased (1.159338 --> 1.153515).  Saving model ...
Validation loss decreased (1.153515 --> 1.148394).  Saving model ...
Validation loss decreased (1.148394 --> 1.143003).  Saving model ...
Validation loss decreased (1.143003 --> 1.138690).  Saving model ...
Validation loss decreased (1.138690 --> 1.132666).  Saving model ...
Validation loss decreased (1.132666 --> 1.127107).  Saving model ...
Validation loss decreased (1.127107 --> 1.121279).  Saving model ...
Validation loss decreased (1.121279 --> 1.116612).  Saving model ...
Validation loss decreased (1.116612 --> 1.113041).  Saving model ...
Validation loss decreased (1.113041 --> 1.107501).  Saving model ...
Validation loss decreased (1.107501 --> 1.102960).  Saving model ...
Validation loss decreased (1.102960 --> 1.097885).  Saving model ...
Validation loss decreased (1.097885 --> 1.094016).  Saving model ...
Validation loss decreased (1.094016 --> 1.089462).  Saving model ...
Validation loss decreased (1.089462 --> 1.085759).  Saving model ...
Validation loss decreased (1.085759 --> 1.081249).  Saving model ...
Validation loss decreased (1.081249 --> 1.077198).  Saving model ...
Validation loss decreased (1.077198 --> 1.073350).  Saving model ...
Validation loss decreased (1.073350 --> 1.070256).  Saving model ...
Validation loss decreased (1.070256 --> 1.066355).  Saving model ...
Validation loss decreased (1.066355 --> 1.062599).  Saving model ...
Validation loss decreased (1.062599 --> 1.059163).  Saving model ...
Validation loss decreased (1.059163 --> 1.055295).  Saving model ...
Validation loss decreased (1.055295 --> 1.051103).  Saving model ...
Validation loss decreased (1.051103 --> 1.046676).  Saving model ...
Validation loss decreased (1.046676 --> 1.043737).  Saving model ...
Validation loss decreased (1.043737 --> 1.040990).  Saving model ...
Validation loss decreased (1.040990 --> 1.036976).  Saving model ...
Validation loss decreased (1.036976 --> 1.035576).  Saving model ...
Validation loss decreased (1.035576 --> 1.032918).  Saving model ...
Validation loss decreased (1.032918 --> 1.030228).  Saving model ...
Validation loss decreased (1.030228 --> 1.029323).  Saving model ...
Validation loss decreased (1.029323 --> 1.027181).  Saving model ...
Validation loss decreased (1.027181 --> 1.024084).  Saving model ...
Validation loss decreased (1.024084 --> 1.021808).  Saving model ...
Validation loss decreased (1.021808 --> 1.019668).  Saving model ...
Validation loss decreased (1.019668 --> 1.018035).  Saving model ...
Validation loss decreased (1.018035 --> 1.016393).  Saving model ...
Validation loss decreased (1.016393 --> 1.014566).  Saving model ...
Validation loss decreased (1.014566 --> 1.013534).  Saving model ...
Validation loss decreased (1.013534 --> 1.010125).  Saving model ...
Validation loss decreased (1.010125 --> 1.007660).  Saving model ...
Validation loss decreased (1.007660 --> 1.004876).  Saving model ...
Validation loss decreased (1.004876 --> 1.002456).  Saving model ...
Validation loss decreased (1.002456 --> 1.000504).  Saving model ...
Validation loss decreased (1.000504 --> 0.999943).  Saving model ...
Validation loss decreased (0.999943 --> 0.999141).  Saving model ...
Validation loss decreased (0.999141 --> 0.998407).  Saving model ...
Validation loss decreased (0.998407 --> 0.996666).  Saving model ...
Validation loss decreased (0.996666 --> 0.994808).  Saving model ...
Validation loss decreased (0.994808 --> 0.991571).  Saving model ...
Validation loss decreased (0.991571 --> 0.988699).  Saving model ...
Validation loss decreased (0.988699 --> 0.987215).  Saving model ...
Validation loss decreased (0.987215 --> 0.987170).  Saving model ...
Validation loss decreased (0.987170 --> 0.986101).  Saving model ...
EarlyStopping counter: 1 out of 5.0
Validation loss decreased (0.986101 --> 0.985596).  Saving model ...
Validation loss decreased (0.985596 --> 0.983633).  Saving model ...
Validation loss decreased (0.983633 --> 0.981366).  Saving model ...
Validation loss decreased (0.981366 --> 0.979638).  Saving model ...
Validation loss decreased (0.979638 --> 0.978482).  Saving model ...
EarlyStopping counter: 1 out of 5.0
Validation loss decreased (0.978482 --> 0.976404).  Saving model ...
Validation loss decreased (0.976404 --> 0.976030).  Saving model ...
Validation loss decreased (0.976030 --> 0.976002).  Saving model ...
Validation loss decreased (0.976002 --> 0.975064).  Saving model ...
Validation loss decreased (0.975064 --> 0.973291).  Saving model ...
Validation loss decreased (0.973291 --> 0.972850).  Saving model ...
Validation loss decreased (0.972850 --> 0.972088).  Saving model ...
Validation loss decreased (0.972088 --> 0.970283).  Saving model ...
EarlyStopping counter: 1 out of 5.0
Validation loss decreased (0.970283 --> 0.970182).  Saving model ...
EarlyStopping counter: 1 out of 5.0
Validation loss decreased (0.970182 --> 0.968450).  Saving model ...
EarlyStopping counter: 1 out of 5.0
EarlyStopping counter: 2 out of 5.0
EarlyStopping counter: 3 out of 5.0
Validation loss decreased (0.968450 --> 0.966814).  Saving model ...
EarlyStopping counter: 1 out of 5.0
Validation loss decreased (0.966814 --> 0.966034).  Saving model ...
Validation loss decreased (0.966034 --> 0.965448).  Saving model ...
Validation loss decreased (0.965448 --> 0.964609).  Saving model ...
EarlyStopping counter: 1 out of 5.0
EarlyStopping counter: 2 out of 5.0
EarlyStopping counter: 3 out of 5.0
EarlyStopping counter: 4 out of 5.0
EarlyStopping counter: 5 out of 5.0
/localscratch/yinan.29201085.0/env/lib/python3.7/site-packages/torch/nn/functional.py:1794: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.
  warnings.warn("nn.functional.tanh is deprecated. Use torch.tanh instead.")
wandb: Waiting for W&B process to finish, PID 223055... (success).
wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: \ 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: | 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: / 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: \ 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: | 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: / 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: \ 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: | 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: / 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: \ 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb:                                                                                
wandb: Run history:
wandb:     e_F1 ▁▃▄▄▅▅▅▆▆▇▇▇▇▇▇▇▇▇▇▇█▇██████████████████
wandb:   e_loss █▇▇▇▆▆▆▆▅▅▄▄▄▄▃▃▃▃▃▂▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:     t_F1 ▁▂▂▃▃▃▃▄▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇▇▇▇▇▇▇▇██▇█▇▇███
wandb:   t_loss █▇▇▇▇▇▆▆▆▆▅▅▅▅▅▄▄▄▃▃▃▃▃▃▃▃▂▂▃▂▂▂▂▂▁▂▁▁▁▁
wandb: 
wandb: Run summary:
wandb:     e_F1 55.99179
wandb:   e_loss 0.96592
wandb:     t_F1 71.19553
wandb:   t_loss 0.79214
wandb: 
wandb: Synced 4 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Synced treasured-snowball-2: https://wandb.ai/yinanazhou/xl_512_bs_8_lr_1e06_es_5_lc_False_nr_False_sr_False_stem_True_lemma_False_repeat_3_fold_1/runs/28v1sbtb
wandb: Find logs at: ./wandb/run-20220319_013029-28v1sbtb/logs/debug.log
wandb: 

wandb: wandb version 0.12.11 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
2022-03-19 02:51:33.149644: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1
wandb: Tracking run with wandb version 0.12.5
wandb: Syncing run laced-bee-2
wandb: ⭐️ View project at https://wandb.ai/yinanazhou/xl_512_bs_8_lr_1e06_es_5_lc_False_nr_False_sr_False_stem_True_lemma_False_repeat_3_fold_2
wandb: 🚀 View run at https://wandb.ai/yinanazhou/xl_512_bs_8_lr_1e06_es_5_lc_False_nr_False_sr_False_stem_True_lemma_False_repeat_3_fold_2/runs/3h7rojqa
wandb: Run data is saved locally in /project/6002780/yinan/Thesis_MER_Lyrics/lyric-emotion/wandb/run-20220319_025129-3h7rojqa
wandb: Run `wandb offline` to turn off syncing.

Validation loss decreased (inf --> 1.458123).  Saving model ...
Validation loss decreased (1.458123 --> 1.434770).  Saving model ...
Validation loss decreased (1.434770 --> 1.417112).  Saving model ...
Validation loss decreased (1.417112 --> 1.403258).  Saving model ...
Validation loss decreased (1.403258 --> 1.392469).  Saving model ...
Validation loss decreased (1.392469 --> 1.384035).  Saving model ...
Validation loss decreased (1.384035 --> 1.376942).  Saving model ...
Validation loss decreased (1.376942 --> 1.371134).  Saving model ...
Validation loss decreased (1.371134 --> 1.365684).  Saving model ...
Validation loss decreased (1.365684 --> 1.360708).  Saving model ...
Validation loss decreased (1.360708 --> 1.355966).  Saving model ...
Validation loss decreased (1.355966 --> 1.351330).  Saving model ...
Validation loss decreased (1.351330 --> 1.346937).  Saving model ...
Validation loss decreased (1.346937 --> 1.342206).  Saving model ...
Validation loss decreased (1.342206 --> 1.337646).  Saving model ...
Validation loss decreased (1.337646 --> 1.332354).  Saving model ...
Validation loss decreased (1.332354 --> 1.326954).  Saving model ...
Validation loss decreased (1.326954 --> 1.321251).  Saving model ...
Validation loss decreased (1.321251 --> 1.315228).  Saving model ...
Validation loss decreased (1.315228 --> 1.308415).  Saving model ...
Validation loss decreased (1.308415 --> 1.302277).  Saving model ...
Validation loss decreased (1.302277 --> 1.295307).  Saving model ...
Validation loss decreased (1.295307 --> 1.288526).  Saving model ...
Validation loss decreased (1.288526 --> 1.280946).  Saving model ...
Validation loss decreased (1.280946 --> 1.272726).  Saving model ...
Validation loss decreased (1.272726 --> 1.266954).  Saving model ...
Validation loss decreased (1.266954 --> 1.259317).  Saving model ...
Validation loss decreased (1.259317 --> 1.252298).  Saving model ...
Validation loss decreased (1.252298 --> 1.244975).  Saving model ...
Validation loss decreased (1.244975 --> 1.237424).  Saving model ...
Validation loss decreased (1.237424 --> 1.230273).  Saving model ...
Validation loss decreased (1.230273 --> 1.223478).  Saving model ...
Validation loss decreased (1.223478 --> 1.216676).  Saving model ...
Validation loss decreased (1.216676 --> 1.209770).  Saving model ...
Validation loss decreased (1.209770 --> 1.203043).  Saving model ...
Validation loss decreased (1.203043 --> 1.195549).  Saving model ...
Validation loss decreased (1.195549 --> 1.188453).  Saving model ...
Validation loss decreased (1.188453 --> 1.182836).  Saving model ...
Validation loss decreased (1.182836 --> 1.175680).  Saving model ...
Validation loss decreased (1.175680 --> 1.168861).  Saving model ...
Validation loss decreased (1.168861 --> 1.161779).  Saving model ...
Validation loss decreased (1.161779 --> 1.156044).  Saving model ...
Validation loss decreased (1.156044 --> 1.150709).  Saving model ...
Validation loss decreased (1.150709 --> 1.144969).  Saving model ...
Validation loss decreased (1.144969 --> 1.138604).  Saving model ...
Validation loss decreased (1.138604 --> 1.135119).  Saving model ...
Validation loss decreased (1.135119 --> 1.130889).  Saving model ...
Validation loss decreased (1.130889 --> 1.125054).  Saving model ...
Validation loss decreased (1.125054 --> 1.118411).  Saving model ...
Validation loss decreased (1.118411 --> 1.113589).  Saving model ...
Validation loss decreased (1.113589 --> 1.109242).  Saving model ...
Validation loss decreased (1.109242 --> 1.105076).  Saving model ...
Validation loss decreased (1.105076 --> 1.101365).  Saving model ...
Validation loss decreased (1.101365 --> 1.096412).  Saving model ...
Validation loss decreased (1.096412 --> 1.091787).  Saving model ...
Validation loss decreased (1.091787 --> 1.087458).  Saving model ...
Validation loss decreased (1.087458 --> 1.082222).  Saving model ...
Validation loss decreased (1.082222 --> 1.079207).  Saving model ...
Validation loss decreased (1.079207 --> 1.073914).  Saving model ...
Validation loss decreased (1.073914 --> 1.071753).  Saving model ...
Validation loss decreased (1.071753 --> 1.067593).  Saving model ...
Validation loss decreased (1.067593 --> 1.064220).  Saving model ...
Validation loss decreased (1.064220 --> 1.063560).  Saving model ...
Validation loss decreased (1.063560 --> 1.061654).  Saving model ...
Validation loss decreased (1.061654 --> 1.056970).  Saving model ...
Validation loss decreased (1.056970 --> 1.050376).  Saving model ...
Validation loss decreased (1.050376 --> 1.044175).  Saving model ...
Validation loss decreased (1.044175 --> 1.043110).  Saving model ...
Validation loss decreased (1.043110 --> 1.037760).  Saving model ...
Validation loss decreased (1.037760 --> 1.033434).  Saving model ...
Validation loss decreased (1.033434 --> 1.027226).  Saving model ...
Validation loss decreased (1.027226 --> 1.024222).  Saving model ...
Validation loss decreased (1.024222 --> 1.020759).  Saving model ...
Validation loss decreased (1.020759 --> 1.018418).  Saving model ...
Validation loss decreased (1.018418 --> 1.015778).  Saving model ...
Validation loss decreased (1.015778 --> 1.014658).  Saving model ...
Validation loss decreased (1.014658 --> 1.013823).  Saving model ...
Validation loss decreased (1.013823 --> 1.010242).  Saving model ...
Validation loss decreased (1.010242 --> 1.009167).  Saving model ...
Validation loss decreased (1.009167 --> 1.006260).  Saving model ...
Validation loss decreased (1.006260 --> 1.001454).  Saving model ...
Validation loss decreased (1.001454 --> 0.999227).  Saving model ...
Validation loss decreased (0.999227 --> 0.995353).  Saving model ...
Validation loss decreased (0.995353 --> 0.994898).  Saving model ...
Validation loss decreased (0.994898 --> 0.994365).  Saving model ...
Validation loss decreased (0.994365 --> 0.990709).  Saving model ...
Validation loss decreased (0.990709 --> 0.987564).  Saving model ...
Validation loss decreased (0.987564 --> 0.984817).  Saving model ...
Validation loss decreased (0.984817 --> 0.984660).  Saving model ...
Validation loss decreased (0.984660 --> 0.982449).  Saving model ...
Validation loss decreased (0.982449 --> 0.981349).  Saving model ...
Validation loss decreased (0.981349 --> 0.979161).  Saving model ...
Validation loss decreased (0.979161 --> 0.975692).  Saving model ...
Validation loss decreased (0.975692 --> 0.972835).  Saving model ...
Validation loss decreased (0.972835 --> 0.970968).  Saving model ...
Validation loss decreased (0.970968 --> 0.970607).  Saving model ...
Validation loss decreased (0.970607 --> 0.967519).  Saving model ...
Validation loss decreased (0.967519 --> 0.966675).  Saving model ...
Validation loss decreased (0.966675 --> 0.963650).  Saving model ...
Validation loss decreased (0.963650 --> 0.962737).  Saving model ...
Validation loss decreased (0.962737 --> 0.961920).  Saving model ...
EarlyStopping counter: 1 out of 5.0
Validation loss decreased (0.961920 --> 0.960340).  Saving model ...
Validation loss decreased (0.960340 --> 0.959992).  Saving model ...
Validation loss decreased (0.959992 --> 0.958197).  Saving model ...
Validation loss decreased (0.958197 --> 0.956680).  Saving model ...
EarlyStopping counter: 1 out of 5.0
Validation loss decreased (0.956680 --> 0.954564).  Saving model ...
Validation loss decreased (0.954564 --> 0.951512).  Saving model ...
EarlyStopping counter: 1 out of 5.0
EarlyStopping counter: 2 out of 5.0
EarlyStopping counter: 3 out of 5.0
EarlyStopping counter: 4 out of 5.0
Validation loss decreased (0.951512 --> 0.950963).  Saving model ...
Validation loss decreased (0.950963 --> 0.948826).  Saving model ...
EarlyStopping counter: 1 out of 5.0
Validation loss decreased (0.948826 --> 0.946295).  Saving model ...
Validation loss decreased (0.946295 --> 0.945684).  Saving model ...
Validation loss decreased (0.945684 --> 0.945078).  Saving model ...
Validation loss decreased (0.945078 --> 0.944633).  Saving model ...
Validation loss decreased (0.944633 --> 0.943451).  Saving model ...
Validation loss decreased (0.943451 --> 0.941285).  Saving model ...
EarlyStopping counter: 1 out of 5.0
EarlyStopping counter: 2 out of 5.0
EarlyStopping counter: 3 out of 5.0
Validation loss decreased (0.941285 --> 0.940224).  Saving model ...
Validation loss decreased (0.940224 --> 0.940198).  Saving model ...
EarlyStopping counter: 1 out of 5.0
EarlyStopping counter: 2 out of 5.0
EarlyStopping counter: 3 out of 5.0
Validation loss decreased (0.940198 --> 0.939026).  Saving model ...
Validation loss decreased (0.939026 --> 0.938440).  Saving model ...
Validation loss decreased (0.938440 --> 0.938424).  Saving model ...
EarlyStopping counter: 1 out of 5.0
Validation loss decreased (0.938424 --> 0.938261).  Saving model ...
EarlyStopping counter: 1 out of 5.0
EarlyStopping counter: 2 out of 5.0
EarlyStopping counter: 3 out of 5.0
EarlyStopping counter: 4 out of 5.0
Validation loss decreased (0.938261 --> 0.936945).  Saving model ...
EarlyStopping counter: 1 out of 5.0
Validation loss decreased (0.936945 --> 0.936877).  Saving model ...
EarlyStopping counter: 1 out of 5.0
EarlyStopping counter: 2 out of 5.0
Validation loss decreased (0.936877 --> 0.934135).  Saving model ...
EarlyStopping counter: 1 out of 5.0
EarlyStopping counter: 2 out of 5.0
EarlyStopping counter: 3 out of 5.0
EarlyStopping counter: 4 out of 5.0
EarlyStopping counter: 5 out of 5.0
/localscratch/yinan.29201085.0/env/lib/python3.7/site-packages/torch/nn/functional.py:1794: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.
  warnings.warn("nn.functional.tanh is deprecated. Use torch.tanh instead.")
wandb: Waiting for W&B process to finish, PID 227498... (success).
wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: \ 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: | 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: / 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: \ 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: | 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: / 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: \ 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: | 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: / 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb:                                                                                
wandb: Run history:
wandb:     e_F1 ▁▁▂▃▄▄▄▅▅▅▆▆▆▆▆▇▇▇▇▇▇▇▇█▇█▇█████████████
wandb:   e_loss ██▇▇▇▆▆▅▅▅▄▄▄▃▃▃▃▃▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:     t_F1 ▁▁▂▃▃▄▃▄▅▅▅▅▅▆▆▆▆▆▆▇▆▇▇▇▇▇▇▇▇▇▇█████████
wandb:   t_loss ███▇▇▇▇▆▆▆▆▅▅▅▄▄▄▄▄▃▃▃▃▃▃▃▃▂▂▂▂▂▂▂▁▂▁▁▁▁
wandb: 
wandb: Run summary:
wandb:     e_F1 62.07487
wandb:   e_loss 0.93717
wandb:     t_F1 74.08467
wandb:   t_loss 0.70959
wandb: 
wandb: Synced 4 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Synced laced-bee-2: https://wandb.ai/yinanazhou/xl_512_bs_8_lr_1e06_es_5_lc_False_nr_False_sr_False_stem_True_lemma_False_repeat_3_fold_2/runs/3h7rojqa
wandb: Find logs at: ./wandb/run-20220319_025129-3h7rojqa/logs/debug.log
wandb: 

wandb: wandb version 0.12.11 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
2022-03-19 04:27:45.358465: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1
wandb: Tracking run with wandb version 0.12.5
wandb: Syncing run likely-serenity-2
wandb: ⭐️ View project at https://wandb.ai/yinanazhou/xl_512_bs_8_lr_1e06_es_5_lc_False_nr_False_sr_False_stem_True_lemma_False_repeat_4_fold_1
wandb: 🚀 View run at https://wandb.ai/yinanazhou/xl_512_bs_8_lr_1e06_es_5_lc_False_nr_False_sr_False_stem_True_lemma_False_repeat_4_fold_1/runs/20dd93td
wandb: Run data is saved locally in /project/6002780/yinan/Thesis_MER_Lyrics/lyric-emotion/wandb/run-20220319_042741-20dd93td
wandb: Run `wandb offline` to turn off syncing.

Validation loss decreased (inf --> 1.492461).  Saving model ...
Validation loss decreased (1.492461 --> 1.452265).  Saving model ...
Validation loss decreased (1.452265 --> 1.425650).  Saving model ...
Validation loss decreased (1.425650 --> 1.406316).  Saving model ...
Validation loss decreased (1.406316 --> 1.392627).  Saving model ...
Validation loss decreased (1.392627 --> 1.382117).  Saving model ...
Validation loss decreased (1.382117 --> 1.374067).  Saving model ...
Validation loss decreased (1.374067 --> 1.367757).  Saving model ...
Validation loss decreased (1.367757 --> 1.362654).  Saving model ...
Validation loss decreased (1.362654 --> 1.357251).  Saving model ...
Validation loss decreased (1.357251 --> 1.352720).  Saving model ...
Validation loss decreased (1.352720 --> 1.348363).  Saving model ...
Validation loss decreased (1.348363 --> 1.344078).  Saving model ...
Validation loss decreased (1.344078 --> 1.339561).  Saving model ...
Validation loss decreased (1.339561 --> 1.334744).  Saving model ...
Validation loss decreased (1.334744 --> 1.329817).  Saving model ...
Validation loss decreased (1.329817 --> 1.324471).  Saving model ...
Validation loss decreased (1.324471 --> 1.318683).  Saving model ...
Validation loss decreased (1.318683 --> 1.312622).  Saving model ...
Validation loss decreased (1.312622 --> 1.306905).  Saving model ...
Validation loss decreased (1.306905 --> 1.300235).  Saving model ...
Validation loss decreased (1.300235 --> 1.293517).  Saving model ...
Validation loss decreased (1.293517 --> 1.286170).  Saving model ...
Validation loss decreased (1.286170 --> 1.279079).  Saving model ...
Validation loss decreased (1.279079 --> 1.271540).  Saving model ...
Validation loss decreased (1.271540 --> 1.264074).  Saving model ...
Validation loss decreased (1.264074 --> 1.256265).  Saving model ...
Validation loss decreased (1.256265 --> 1.247115).  Saving model ...
Validation loss decreased (1.247115 --> 1.239689).  Saving model ...
Validation loss decreased (1.239689 --> 1.231337).  Saving model ...
Validation loss decreased (1.231337 --> 1.223446).  Saving model ...
Validation loss decreased (1.223446 --> 1.214848).  Saving model ...
Validation loss decreased (1.214848 --> 1.209012).  Saving model ...
Validation loss decreased (1.209012 --> 1.202723).  Saving model ...
Validation loss decreased (1.202723 --> 1.195172).  Saving model ...
Validation loss decreased (1.195172 --> 1.189637).  Saving model ...
Validation loss decreased (1.189637 --> 1.182306).  Saving model ...
Validation loss decreased (1.182306 --> 1.175847).  Saving model ...
Validation loss decreased (1.175847 --> 1.168267).  Saving model ...
Validation loss decreased (1.168267 --> 1.161925).  Saving model ...
Validation loss decreased (1.161925 --> 1.156074).  Saving model ...
Validation loss decreased (1.156074 --> 1.150887).  Saving model ...
Validation loss decreased (1.150887 --> 1.145192).  Saving model ...
Validation loss decreased (1.145192 --> 1.139085).  Saving model ...
Validation loss decreased (1.139085 --> 1.134308).  Saving model ...
Validation loss decreased (1.134308 --> 1.129072).  Saving model ...
Validation loss decreased (1.129072 --> 1.123389).  Saving model ...
Validation loss decreased (1.123389 --> 1.117742).  Saving model ...
Validation loss decreased (1.117742 --> 1.112820).  Saving model ...
Validation loss decreased (1.112820 --> 1.108515).  Saving model ...
Validation loss decreased (1.108515 --> 1.104511).  Saving model ...
Validation loss decreased (1.104511 --> 1.099121).  Saving model ...
Validation loss decreased (1.099121 --> 1.094462).  Saving model ...
Validation loss decreased (1.094462 --> 1.089687).  Saving model ...
Validation loss decreased (1.089687 --> 1.085847).  Saving model ...
Validation loss decreased (1.085847 --> 1.081757).  Saving model ...
Validation loss decreased (1.081757 --> 1.078849).  Saving model ...
Validation loss decreased (1.078849 --> 1.073676).  Saving model ...
Validation loss decreased (1.073676 --> 1.069643).  Saving model ...
Validation loss decreased (1.069643 --> 1.066466).  Saving model ...
Validation loss decreased (1.066466 --> 1.063724).  Saving model ...
Validation loss decreased (1.063724 --> 1.060028).  Saving model ...
Validation loss decreased (1.060028 --> 1.055740).  Saving model ...
Validation loss decreased (1.055740 --> 1.052369).  Saving model ...
Validation loss decreased (1.052369 --> 1.048552).  Saving model ...
Validation loss decreased (1.048552 --> 1.045829).  Saving model ...
Validation loss decreased (1.045829 --> 1.042588).  Saving model ...
Validation loss decreased (1.042588 --> 1.040078).  Saving model ...
Validation loss decreased (1.040078 --> 1.036405).  Saving model ...
Validation loss decreased (1.036405 --> 1.033601).  Saving model ...
Validation loss decreased (1.033601 --> 1.030820).  Saving model ...
Validation loss decreased (1.030820 --> 1.028980).  Saving model ...
Validation loss decreased (1.028980 --> 1.026947).  Saving model ...
Validation loss decreased (1.026947 --> 1.024951).  Saving model ...
Validation loss decreased (1.024951 --> 1.022852).  Saving model ...
Validation loss decreased (1.022852 --> 1.018981).  Saving model ...
Validation loss decreased (1.018981 --> 1.016979).  Saving model ...
Validation loss decreased (1.016979 --> 1.013264).  Saving model ...
Validation loss decreased (1.013264 --> 1.010922).  Saving model ...
Validation loss decreased (1.010922 --> 1.009141).  Saving model ...
Validation loss decreased (1.009141 --> 1.006064).  Saving model ...
Validation loss decreased (1.006064 --> 1.002890).  Saving model ...
Validation loss decreased (1.002890 --> 1.001444).  Saving model ...
Validation loss decreased (1.001444 --> 0.999912).  Saving model ...
Validation loss decreased (0.999912 --> 0.998390).  Saving model ...
Validation loss decreased (0.998390 --> 0.997510).  Saving model ...
Validation loss decreased (0.997510 --> 0.995986).  Saving model ...
Validation loss decreased (0.995986 --> 0.993059).  Saving model ...
Validation loss decreased (0.993059 --> 0.991834).  Saving model ...
Validation loss decreased (0.991834 --> 0.990341).  Saving model ...
Validation loss decreased (0.990341 --> 0.988789).  Saving model ...
Validation loss decreased (0.988789 --> 0.987930).  Saving model ...
Validation loss decreased (0.987930 --> 0.986503).  Saving model ...
Validation loss decreased (0.986503 --> 0.985041).  Saving model ...
Validation loss decreased (0.985041 --> 0.984007).  Saving model ...
Validation loss decreased (0.984007 --> 0.983537).  Saving model ...
Validation loss decreased (0.983537 --> 0.981003).  Saving model ...
Validation loss decreased (0.981003 --> 0.979763).  Saving model ...
Validation loss decreased (0.979763 --> 0.978314).  Saving model ...
EarlyStopping counter: 1 out of 5.0
Validation loss decreased (0.978314 --> 0.977323).  Saving model ...
EarlyStopping counter: 1 out of 5.0
Validation loss decreased (0.977323 --> 0.974511).  Saving model ...
Validation loss decreased (0.974511 --> 0.974017).  Saving model ...
EarlyStopping counter: 1 out of 5.0
Validation loss decreased (0.974017 --> 0.972586).  Saving model ...
EarlyStopping counter: 1 out of 5.0
Validation loss decreased (0.972586 --> 0.971843).  Saving model ...
Validation loss decreased (0.971843 --> 0.970142).  Saving model ...
Validation loss decreased (0.970142 --> 0.969430).  Saving model ...
Validation loss decreased (0.969430 --> 0.969162).  Saving model ...
Validation loss decreased (0.969162 --> 0.967393).  Saving model ...
Validation loss decreased (0.967393 --> 0.967320).  Saving model ...
Validation loss decreased (0.967320 --> 0.965500).  Saving model ...
EarlyStopping counter: 1 out of 5.0
EarlyStopping counter: 2 out of 5.0
EarlyStopping counter: 3 out of 5.0
EarlyStopping counter: 4 out of 5.0
Validation loss decreased (0.965500 --> 0.964868).  Saving model ...
Validation loss decreased (0.964868 --> 0.963350).  Saving model ...
EarlyStopping counter: 1 out of 5.0
EarlyStopping counter: 2 out of 5.0
EarlyStopping counter: 3 out of 5.0
EarlyStopping counter: 4 out of 5.0
Validation loss decreased (0.963350 --> 0.963088).  Saving model ...
Validation loss decreased (0.963088 --> 0.961611).  Saving model ...
EarlyStopping counter: 1 out of 5.0
EarlyStopping counter: 2 out of 5.0
EarlyStopping counter: 3 out of 5.0
Validation loss decreased (0.961611 --> 0.960558).  Saving model ...
Validation loss decreased (0.960558 --> 0.960454).  Saving model ...
Validation loss decreased (0.960454 --> 0.960226).  Saving model ...
Validation loss decreased (0.960226 --> 0.960184).  Saving model ...
EarlyStopping counter: 1 out of 5.0
EarlyStopping counter: 2 out of 5.0
EarlyStopping counter: 3 out of 5.0
Validation loss decreased (0.960184 --> 0.959325).  Saving model ...
Validation loss decreased (0.959325 --> 0.958507).  Saving model ...
EarlyStopping counter: 1 out of 5.0
EarlyStopping counter: 2 out of 5.0
EarlyStopping counter: 3 out of 5.0
EarlyStopping counter: 4 out of 5.0
EarlyStopping counter: 5 out of 5.0
/localscratch/yinan.29201085.0/env/lib/python3.7/site-packages/torch/nn/functional.py:1794: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.
  warnings.warn("nn.functional.tanh is deprecated. Use torch.tanh instead.")
wandb: Waiting for W&B process to finish, PID 232637... (success).
wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: \ 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: | 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: / 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: \ 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: | 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: / 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: \ 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: | 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: / 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb:                                                                                
wandb: Run history:
wandb:     e_F1 ▁▁▄▄▅▅▆▆▇▇▇▇▇▇▇▇▇▇▇▇▇███████████████████
wandb:   e_loss █▇▇▇▆▆▆▅▅▄▄▄▄▃▃▃▃▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:     t_F1 ▁▁▂▃▃▃▅▄▅▅▅▅▆▆▆▆▆▆▆▆▇▆▇▇▇▇▇▇▇▇▇▇███▇████
wandb:   t_loss █▇▇▇▇▇▆▆▆▆▅▅▅▄▄▄▄▄▄▃▃▃▃▃▃▃▂▂▂▂▂▂▂▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:     e_F1 58.1138
wandb:   e_loss 0.96149
wandb:     t_F1 71.23562
wandb:   t_loss 0.75529
wandb: 
wandb: Synced 4 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Synced likely-serenity-2: https://wandb.ai/yinanazhou/xl_512_bs_8_lr_1e06_es_5_lc_False_nr_False_sr_False_stem_True_lemma_False_repeat_4_fold_1/runs/20dd93td
wandb: Find logs at: ./wandb/run-20220319_042741-20dd93td/logs/debug.log
wandb: 

wandb: wandb version 0.12.11 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
2022-03-19 06:01:12.152460: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1
wandb: Tracking run with wandb version 0.12.5
wandb: Syncing run blooming-sponge-2
wandb: ⭐️ View project at https://wandb.ai/yinanazhou/xl_512_bs_8_lr_1e06_es_5_lc_False_nr_False_sr_False_stem_True_lemma_False_repeat_4_fold_2
wandb: 🚀 View run at https://wandb.ai/yinanazhou/xl_512_bs_8_lr_1e06_es_5_lc_False_nr_False_sr_False_stem_True_lemma_False_repeat_4_fold_2/runs/37hs6kf9
wandb: Run data is saved locally in /project/6002780/yinan/Thesis_MER_Lyrics/lyric-emotion/wandb/run-20220319_060109-37hs6kf9
wandb: Run `wandb offline` to turn off syncing.

Validation loss decreased (inf --> 1.382667).  Saving model ...
Validation loss decreased (1.382667 --> 1.376905).  Saving model ...
Validation loss decreased (1.376905 --> 1.372107).  Saving model ...
Validation loss decreased (1.372107 --> 1.368123).  Saving model ...
Validation loss decreased (1.368123 --> 1.364300).  Saving model ...
Validation loss decreased (1.364300 --> 1.360678).  Saving model ...
Validation loss decreased (1.360678 --> 1.356702).  Saving model ...
Validation loss decreased (1.356702 --> 1.352733).  Saving model ...
Validation loss decreased (1.352733 --> 1.348534).  Saving model ...
Validation loss decreased (1.348534 --> 1.344551).  Saving model ...
Validation loss decreased (1.344551 --> 1.340292).  Saving model ...
Validation loss decreased (1.340292 --> 1.335463).  Saving model ...
Validation loss decreased (1.335463 --> 1.331406).  Saving model ...
Validation loss decreased (1.331406 --> 1.327016).  Saving model ...
Validation loss decreased (1.327016 --> 1.322164).  Saving model ...
Validation loss decreased (1.322164 --> 1.316597).  Saving model ...
Validation loss decreased (1.316597 --> 1.311727).  Saving model ...
Validation loss decreased (1.311727 --> 1.305719).  Saving model ...
Validation loss decreased (1.305719 --> 1.299464).  Saving model ...
Validation loss decreased (1.299464 --> 1.292769).  Saving model ...
Validation loss decreased (1.292769 --> 1.285967).  Saving model ...
Validation loss decreased (1.285967 --> 1.279593).  Saving model ...
Validation loss decreased (1.279593 --> 1.274398).  Saving model ...
Validation loss decreased (1.274398 --> 1.267740).  Saving model ...
Validation loss decreased (1.267740 --> 1.260558).  Saving model ...
Validation loss decreased (1.260558 --> 1.254492).  Saving model ...
Validation loss decreased (1.254492 --> 1.245724).  Saving model ...
Validation loss decreased (1.245724 --> 1.239692).  Saving model ...
Validation loss decreased (1.239692 --> 1.232002).  Saving model ...
Validation loss decreased (1.232002 --> 1.225899).  Saving model ...
Validation loss decreased (1.225899 --> 1.216210).  Saving model ...
Validation loss decreased (1.216210 --> 1.210584).  Saving model ...
Validation loss decreased (1.210584 --> 1.205039).  Saving model ...
Validation loss decreased (1.205039 --> 1.198281).  Saving model ...
Validation loss decreased (1.198281 --> 1.189589).  Saving model ...
Validation loss decreased (1.189589 --> 1.183010).  Saving model ...
Validation loss decreased (1.183010 --> 1.176552).  Saving model ...
Validation loss decreased (1.176552 --> 1.170243).  Saving model ...
Validation loss decreased (1.170243 --> 1.163206).  Saving model ...
Validation loss decreased (1.163206 --> 1.158633).  Saving model ...
Validation loss decreased (1.158633 --> 1.150441).  Saving model ...
Validation loss decreased (1.150441 --> 1.144342).  Saving model ...
Validation loss decreased (1.144342 --> 1.139780).  Saving model ...
Validation loss decreased (1.139780 --> 1.131691).  Saving model ...
Validation loss decreased (1.131691 --> 1.125868).  Saving model ...
Validation loss decreased (1.125868 --> 1.120376).  Saving model ...
Validation loss decreased (1.120376 --> 1.117802).  Saving model ...
Validation loss decreased (1.117802 --> 1.111878).  Saving model ...
Validation loss decreased (1.111878 --> 1.106840).  Saving model ...
Validation loss decreased (1.106840 --> 1.104855).  Saving model ...
Validation loss decreased (1.104855 --> 1.100045).  Saving model ...
Validation loss decreased (1.100045 --> 1.093832).  Saving model ...
Validation loss decreased (1.093832 --> 1.090105).  Saving model ...
Validation loss decreased (1.090105 --> 1.084900).  Saving model ...
Validation loss decreased (1.084900 --> 1.081061).  Saving model ...
Validation loss decreased (1.081061 --> 1.078625).  Saving model ...
Validation loss decreased (1.078625 --> 1.072969).  Saving model ...
Validation loss decreased (1.072969 --> 1.069041).  Saving model ...
Validation loss decreased (1.069041 --> 1.064248).  Saving model ...
Validation loss decreased (1.064248 --> 1.062251).  Saving model ...
Validation loss decreased (1.062251 --> 1.060068).  Saving model ...
Validation loss decreased (1.060068 --> 1.053263).  Saving model ...
Validation loss decreased (1.053263 --> 1.050769).  Saving model ...
Validation loss decreased (1.050769 --> 1.047977).  Saving model ...
Validation loss decreased (1.047977 --> 1.047344).  Saving model ...
Validation loss decreased (1.047344 --> 1.041656).  Saving model ...
Validation loss decreased (1.041656 --> 1.040431).  Saving model ...
Validation loss decreased (1.040431 --> 1.034383).  Saving model ...
Validation loss decreased (1.034383 --> 1.031425).  Saving model ...
Validation loss decreased (1.031425 --> 1.029648).  Saving model ...
Validation loss decreased (1.029648 --> 1.027746).  Saving model ...
Validation loss decreased (1.027746 --> 1.024625).  Saving model ...
Validation loss decreased (1.024625 --> 1.020378).  Saving model ...
Validation loss decreased (1.020378 --> 1.016378).  Saving model ...
Validation loss decreased (1.016378 --> 1.014068).  Saving model ...
Validation loss decreased (1.014068 --> 1.012571).  Saving model ...
Validation loss decreased (1.012571 --> 1.009791).  Saving model ...
Validation loss decreased (1.009791 --> 1.006806).  Saving model ...
Validation loss decreased (1.006806 --> 1.004680).  Saving model ...
Validation loss decreased (1.004680 --> 0.999717).  Saving model ...
EarlyStopping counter: 1 out of 5.0
EarlyStopping counter: 2 out of 5.0
Validation loss decreased (0.999717 --> 0.996691).  Saving model ...
Validation loss decreased (0.996691 --> 0.995565).  Saving model ...
Validation loss decreased (0.995565 --> 0.992006).  Saving model ...
EarlyStopping counter: 1 out of 5.0
Validation loss decreased (0.992006 --> 0.991309).  Saving model ...
Validation loss decreased (0.991309 --> 0.989140).  Saving model ...
EarlyStopping counter: 1 out of 5.0
Validation loss decreased (0.989140 --> 0.986654).  Saving model ...
Validation loss decreased (0.986654 --> 0.985572).  Saving model ...
Validation loss decreased (0.985572 --> 0.981889).  Saving model ...
Validation loss decreased (0.981889 --> 0.979362).  Saving model ...
Validation loss decreased (0.979362 --> 0.979119).  Saving model ...
Validation loss decreased (0.979119 --> 0.978134).  Saving model ...
EarlyStopping counter: 1 out of 5.0
Validation loss decreased (0.978134 --> 0.977954).  Saving model ...
Validation loss decreased (0.977954 --> 0.976010).  Saving model ...
EarlyStopping counter: 1 out of 5.0
Validation loss decreased (0.976010 --> 0.974072).  Saving model ...
Validation loss decreased (0.974072 --> 0.969482).  Saving model ...
EarlyStopping counter: 1 out of 5.0
EarlyStopping counter: 2 out of 5.0
Validation loss decreased (0.969482 --> 0.968288).  Saving model ...
Validation loss decreased (0.968288 --> 0.966705).  Saving model ...
EarlyStopping counter: 1 out of 5.0
Validation loss decreased (0.966705 --> 0.965860).  Saving model ...
Validation loss decreased (0.965860 --> 0.965779).  Saving model ...
Validation loss decreased (0.965779 --> 0.962475).  Saving model ...
EarlyStopping counter: 1 out of 5.0
EarlyStopping counter: 2 out of 5.0
Validation loss decreased (0.962475 --> 0.962374).  Saving model ...
Validation loss decreased (0.962374 --> 0.959944).  Saving model ...
EarlyStopping counter: 1 out of 5.0
EarlyStopping counter: 2 out of 5.0
Validation loss decreased (0.959944 --> 0.958766).  Saving model ...
EarlyStopping counter: 1 out of 5.0
EarlyStopping counter: 2 out of 5.0
EarlyStopping counter: 3 out of 5.0
EarlyStopping counter: 4 out of 5.0
EarlyStopping counter: 5 out of 5.0
/localscratch/yinan.29201085.0/env/lib/python3.7/site-packages/torch/nn/functional.py:1794: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.
  warnings.warn("nn.functional.tanh is deprecated. Use torch.tanh instead.")
wandb: Waiting for W&B process to finish, PID 237652... (success).
wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: \ 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: | 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: / 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: \ 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: | 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: / 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: \ 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: | 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb:                                                                                
wandb: Run history:
wandb:     e_F1 ▁▂▄▄▄▄▄▅▅▆▆▆▆▆▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇███████████
wandb:   e_loss ███▇▇▇▇▆▆▆▅▅▅▄▄▄▃▃▃▃▃▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁
wandb:     t_F1 ▁▂▂▂▂▃▃▄▄▄▄▄▅▅▅▆▆▅▆▆▆▆▆▆▇▆▇▇▇▇▇▇▇▇▇▇▇▇██
wandb:   t_loss ███▇▇▇▇▇▇▆▆▆▆▅▅▅▄▅▄▄▄▄▃▃▃▃▃▃▂▂▂▂▂▂▂▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:     e_F1 59.68667
wandb:   e_loss 0.96469
wandb:     t_F1 72.83643
wandb:   t_loss 0.78304
wandb: 
wandb: Synced 4 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Synced blooming-sponge-2: https://wandb.ai/yinanazhou/xl_512_bs_8_lr_1e06_es_5_lc_False_nr_False_sr_False_stem_True_lemma_False_repeat_4_fold_2/runs/37hs6kf9
wandb: Find logs at: ./wandb/run-20220319_060109-37hs6kf9/logs/debug.log
wandb: 

wandb: wandb version 0.12.11 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
2022-03-19 07:21:27.246581: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1
wandb: Tracking run with wandb version 0.12.5
wandb: Syncing run worthy-firebrand-2
wandb: ⭐️ View project at https://wandb.ai/yinanazhou/xl_512_bs_8_lr_1e06_es_5_lc_False_nr_False_sr_False_stem_True_lemma_False_repeat_5_fold_1
wandb: 🚀 View run at https://wandb.ai/yinanazhou/xl_512_bs_8_lr_1e06_es_5_lc_False_nr_False_sr_False_stem_True_lemma_False_repeat_5_fold_1/runs/26lu6psv
wandb: Run data is saved locally in /project/6002780/yinan/Thesis_MER_Lyrics/lyric-emotion/wandb/run-20220319_072124-26lu6psv
wandb: Run `wandb offline` to turn off syncing.

Validation loss decreased (inf --> 1.422408).  Saving model ...
Validation loss decreased (1.422408 --> 1.406045).  Saving model ...
Validation loss decreased (1.406045 --> 1.393141).  Saving model ...
Validation loss decreased (1.393141 --> 1.383795).  Saving model ...
Validation loss decreased (1.383795 --> 1.376060).  Saving model ...
Validation loss decreased (1.376060 --> 1.370082).  Saving model ...
Validation loss decreased (1.370082 --> 1.364839).  Saving model ...
Validation loss decreased (1.364839 --> 1.359647).  Saving model ...
Validation loss decreased (1.359647 --> 1.355534).  Saving model ...
Validation loss decreased (1.355534 --> 1.351546).  Saving model ...
Validation loss decreased (1.351546 --> 1.347607).  Saving model ...
Validation loss decreased (1.347607 --> 1.343070).  Saving model ...
Validation loss decreased (1.343070 --> 1.338502).  Saving model ...
Validation loss decreased (1.338502 --> 1.334174).  Saving model ...
Validation loss decreased (1.334174 --> 1.329264).  Saving model ...
Validation loss decreased (1.329264 --> 1.324212).  Saving model ...
Validation loss decreased (1.324212 --> 1.318949).  Saving model ...
Validation loss decreased (1.318949 --> 1.314163).  Saving model ...
Validation loss decreased (1.314163 --> 1.308631).  Saving model ...
Validation loss decreased (1.308631 --> 1.302695).  Saving model ...
Validation loss decreased (1.302695 --> 1.296769).  Saving model ...
Validation loss decreased (1.296769 --> 1.290548).  Saving model ...
Validation loss decreased (1.290548 --> 1.284244).  Saving model ...
Validation loss decreased (1.284244 --> 1.277293).  Saving model ...
Validation loss decreased (1.277293 --> 1.271017).  Saving model ...
Validation loss decreased (1.271017 --> 1.264419).  Saving model ...
Validation loss decreased (1.264419 --> 1.257215).  Saving model ...
Validation loss decreased (1.257215 --> 1.250473).  Saving model ...
Validation loss decreased (1.250473 --> 1.241875).  Saving model ...
Validation loss decreased (1.241875 --> 1.234226).  Saving model ...
Validation loss decreased (1.234226 --> 1.227049).  Saving model ...
Validation loss decreased (1.227049 --> 1.219554).  Saving model ...
Validation loss decreased (1.219554 --> 1.212312).  Saving model ...
Validation loss decreased (1.212312 --> 1.205095).  Saving model ...
Validation loss decreased (1.205095 --> 1.198431).  Saving model ...
Validation loss decreased (1.198431 --> 1.190835).  Saving model ...
Validation loss decreased (1.190835 --> 1.184911).  Saving model ...
Validation loss decreased (1.184911 --> 1.177287).  Saving model ...
Validation loss decreased (1.177287 --> 1.171528).  Saving model ...
Validation loss decreased (1.171528 --> 1.163752).  Saving model ...
Validation loss decreased (1.163752 --> 1.156980).  Saving model ...
Validation loss decreased (1.156980 --> 1.151288).  Saving model ...
Validation loss decreased (1.151288 --> 1.145741).  Saving model ...
Validation loss decreased (1.145741 --> 1.139608).  Saving model ...
Validation loss decreased (1.139608 --> 1.135736).  Saving model ...
Validation loss decreased (1.135736 --> 1.129489).  Saving model ...
Validation loss decreased (1.129489 --> 1.124163).  Saving model ...
Validation loss decreased (1.124163 --> 1.119110).  Saving model ...
Validation loss decreased (1.119110 --> 1.112791).  Saving model ...
Validation loss decreased (1.112791 --> 1.106213).  Saving model ...
Validation loss decreased (1.106213 --> 1.101528).  Saving model ...
Validation loss decreased (1.101528 --> 1.098580).  Saving model ...
Validation loss decreased (1.098580 --> 1.092860).  Saving model ...
Validation loss decreased (1.092860 --> 1.088822).  Saving model ...
Validation loss decreased (1.088822 --> 1.084696).  Saving model ...
Validation loss decreased (1.084696 --> 1.080658).  Saving model ...
Validation loss decreased (1.080658 --> 1.077032).  Saving model ...
Validation loss decreased (1.077032 --> 1.070898).  Saving model ...
Validation loss decreased (1.070898 --> 1.066994).  Saving model ...
Validation loss decreased (1.066994 --> 1.063414).  Saving model ...
Validation loss decreased (1.063414 --> 1.059215).  Saving model ...
Validation loss decreased (1.059215 --> 1.057975).  Saving model ...
Validation loss decreased (1.057975 --> 1.054865).  Saving model ...
Validation loss decreased (1.054865 --> 1.050952).  Saving model ...
Validation loss decreased (1.050952 --> 1.043867).  Saving model ...
Validation loss decreased (1.043867 --> 1.039665).  Saving model ...
Validation loss decreased (1.039665 --> 1.037996).  Saving model ...
Validation loss decreased (1.037996 --> 1.036987).  Saving model ...
Validation loss decreased (1.036987 --> 1.029945).  Saving model ...
Validation loss decreased (1.029945 --> 1.027023).  Saving model ...
Validation loss decreased (1.027023 --> 1.024798).  Saving model ...
Validation loss decreased (1.024798 --> 1.023510).  Saving model ...
Validation loss decreased (1.023510 --> 1.022055).  Saving model ...
Validation loss decreased (1.022055 --> 1.015018).  Saving model ...
Validation loss decreased (1.015018 --> 1.012539).  Saving model ...
Validation loss decreased (1.012539 --> 1.007613).  Saving model ...
Validation loss decreased (1.007613 --> 1.004781).  Saving model ...
Validation loss decreased (1.004781 --> 1.002277).  Saving model ...
Validation loss decreased (1.002277 --> 1.000928).  Saving model ...
Validation loss decreased (1.000928 --> 1.000007).  Saving model ...
Validation loss decreased (1.000007 --> 0.994739).  Saving model ...
Validation loss decreased (0.994739 --> 0.993308).  Saving model ...
Validation loss decreased (0.993308 --> 0.992368).  Saving model ...
Validation loss decreased (0.992368 --> 0.989415).  Saving model ...
Validation loss decreased (0.989415 --> 0.986002).  Saving model ...
Validation loss decreased (0.986002 --> 0.984944).  Saving model ...
Validation loss decreased (0.984944 --> 0.982958).  Saving model ...
Validation loss decreased (0.982958 --> 0.981345).  Saving model ...
Validation loss decreased (0.981345 --> 0.980739).  Saving model ...
Validation loss decreased (0.980739 --> 0.979263).  Saving model ...
Validation loss decreased (0.979263 --> 0.976445).  Saving model ...
EarlyStopping counter: 1 out of 5.0
Validation loss decreased (0.976445 --> 0.973436).  Saving model ...
Validation loss decreased (0.973436 --> 0.972570).  Saving model ...
Validation loss decreased (0.972570 --> 0.970201).  Saving model ...
Validation loss decreased (0.970201 --> 0.968052).  Saving model ...
Validation loss decreased (0.968052 --> 0.967437).  Saving model ...
Validation loss decreased (0.967437 --> 0.966626).  Saving model ...
Validation loss decreased (0.966626 --> 0.964427).  Saving model ...
Validation loss decreased (0.964427 --> 0.963725).  Saving model ...
EarlyStopping counter: 1 out of 5.0
EarlyStopping counter: 2 out of 5.0
EarlyStopping counter: 3 out of 5.0
Validation loss decreased (0.963725 --> 0.960197).  Saving model ...
EarlyStopping counter: 1 out of 5.0
EarlyStopping counter: 2 out of 5.0
Validation loss decreased (0.960197 --> 0.959430).  Saving model ...
Validation loss decreased (0.959430 --> 0.959421).  Saving model ...
Validation loss decreased (0.959421 --> 0.958331).  Saving model ...
Validation loss decreased (0.958331 --> 0.955456).  Saving model ...
Validation loss decreased (0.955456 --> 0.955415).  Saving model ...
Validation loss decreased (0.955415 --> 0.955274).  Saving model ...
Validation loss decreased (0.955274 --> 0.954165).  Saving model ...
EarlyStopping counter: 1 out of 5.0
EarlyStopping counter: 2 out of 5.0
EarlyStopping counter: 3 out of 5.0
EarlyStopping counter: 4 out of 5.0
Validation loss decreased (0.954165 --> 0.953594).  Saving model ...
EarlyStopping counter: 1 out of 5.0
EarlyStopping counter: 2 out of 5.0
Validation loss decreased (0.953594 --> 0.952461).  Saving model ...
Validation loss decreased (0.952461 --> 0.951278).  Saving model ...
EarlyStopping counter: 1 out of 5.0
Validation loss decreased (0.951278 --> 0.950501).  Saving model ...
EarlyStopping counter: 1 out of 5.0
EarlyStopping counter: 2 out of 5.0
Validation loss decreased (0.950501 --> 0.950311).  Saving model ...
EarlyStopping counter: 1 out of 5.0
EarlyStopping counter: 2 out of 5.0
EarlyStopping counter: 3 out of 5.0
EarlyStopping counter: 4 out of 5.0
EarlyStopping counter: 5 out of 5.0
/localscratch/yinan.29201085.0/env/lib/python3.7/site-packages/torch/nn/functional.py:1794: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.
  warnings.warn("nn.functional.tanh is deprecated. Use torch.tanh instead.")
wandb: Waiting for W&B process to finish, PID 241984... (success).
wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: \ 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: | 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: / 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: \ 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: | 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: / 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: \ 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: | 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: / 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb:                                                                                
wandb: Run history:
wandb:     e_F1 ▁▂▄▄▄▅▅▅▆▆▆▆▆▇▇▇▇▇▇▇████████████████████
wandb:   e_loss ██▇▇▇▇▆▆▆▅▅▄▄▄▄▃▃▃▃▃▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:     t_F1 ▁▂▂▃▃▃▃▃▄▄▄▄▄▅▅▆▆▆▆▅▆▆▆▆▆▆▇▇▇▇▇▇▇▇▇█████
wandb:   t_loss ██▇▇▇▇▇▇▇▆▆▆▅▅▅▅▅▄▄▄▄▄▄▃▃▃▃▃▃▃▂▂▂▂▂▂▂▁▁▁
wandb: 
wandb: Run summary:
wandb:     e_F1 58.98845
wandb:   e_loss 0.951
wandb:     t_F1 73.93987
wandb:   t_loss 0.73556
wandb: 
wandb: Synced 4 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Synced worthy-firebrand-2: https://wandb.ai/yinanazhou/xl_512_bs_8_lr_1e06_es_5_lc_False_nr_False_sr_False_stem_True_lemma_False_repeat_5_fold_1/runs/26lu6psv
wandb: Find logs at: ./wandb/run-20220319_072124-26lu6psv/logs/debug.log
wandb: 

wandb: wandb version 0.12.11 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
2022-03-19 08:48:58.590563: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1
wandb: Tracking run with wandb version 0.12.5
wandb: Syncing run vibrant-wind-2
wandb: ⭐️ View project at https://wandb.ai/yinanazhou/xl_512_bs_8_lr_1e06_es_5_lc_False_nr_False_sr_False_stem_True_lemma_False_repeat_5_fold_2
wandb: 🚀 View run at https://wandb.ai/yinanazhou/xl_512_bs_8_lr_1e06_es_5_lc_False_nr_False_sr_False_stem_True_lemma_False_repeat_5_fold_2/runs/37lbwyhm
wandb: Run data is saved locally in /project/6002780/yinan/Thesis_MER_Lyrics/lyric-emotion/wandb/run-20220319_084855-37lbwyhm
wandb: Run `wandb offline` to turn off syncing.

Validation loss decreased (inf --> 1.425822).  Saving model ...
Validation loss decreased (1.425822 --> 1.408741).  Saving model ...
Validation loss decreased (1.408741 --> 1.395769).  Saving model ...
Validation loss decreased (1.395769 --> 1.387713).  Saving model ...
Validation loss decreased (1.387713 --> 1.381477).  Saving model ...
Validation loss decreased (1.381477 --> 1.376671).  Saving model ...
Validation loss decreased (1.376671 --> 1.372307).  Saving model ...
Validation loss decreased (1.372307 --> 1.368122).  Saving model ...
Validation loss decreased (1.368122 --> 1.364439).  Saving model ...
Validation loss decreased (1.364439 --> 1.360395).  Saving model ...
Validation loss decreased (1.360395 --> 1.356168).  Saving model ...
Validation loss decreased (1.356168 --> 1.352010).  Saving model ...
Validation loss decreased (1.352010 --> 1.347624).  Saving model ...
Validation loss decreased (1.347624 --> 1.343202).  Saving model ...
Validation loss decreased (1.343202 --> 1.338433).  Saving model ...
Validation loss decreased (1.338433 --> 1.333215).  Saving model ...
Validation loss decreased (1.333215 --> 1.327875).  Saving model ...
Validation loss decreased (1.327875 --> 1.322176).  Saving model ...
Validation loss decreased (1.322176 --> 1.315948).  Saving model ...
Validation loss decreased (1.315948 --> 1.309366).  Saving model ...
Validation loss decreased (1.309366 --> 1.303012).  Saving model ...
Validation loss decreased (1.303012 --> 1.295619).  Saving model ...
Validation loss decreased (1.295619 --> 1.289375).  Saving model ...
Validation loss decreased (1.289375 --> 1.283689).  Saving model ...
Validation loss decreased (1.283689 --> 1.276930).  Saving model ...
Validation loss decreased (1.276930 --> 1.268185).  Saving model ...
Validation loss decreased (1.268185 --> 1.260869).  Saving model ...
Validation loss decreased (1.260869 --> 1.252296).  Saving model ...
Validation loss decreased (1.252296 --> 1.244864).  Saving model ...
Validation loss decreased (1.244864 --> 1.237150).  Saving model ...
Validation loss decreased (1.237150 --> 1.229628).  Saving model ...
Validation loss decreased (1.229628 --> 1.223753).  Saving model ...
Validation loss decreased (1.223753 --> 1.215388).  Saving model ...
Validation loss decreased (1.215388 --> 1.207010).  Saving model ...
Validation loss decreased (1.207010 --> 1.200616).  Saving model ...
Validation loss decreased (1.200616 --> 1.192396).  Saving model ...
Validation loss decreased (1.192396 --> 1.186361).  Saving model ...
Validation loss decreased (1.186361 --> 1.180508).  Saving model ...
Validation loss decreased (1.180508 --> 1.174447).  Saving model ...
Validation loss decreased (1.174447 --> 1.166961).  Saving model ...
Validation loss decreased (1.166961 --> 1.161966).  Saving model ...
Validation loss decreased (1.161966 --> 1.155097).  Saving model ...
Validation loss decreased (1.155097 --> 1.149397).  Saving model ...
Validation loss decreased (1.149397 --> 1.142914).  Saving model ...
Validation loss decreased (1.142914 --> 1.138225).  Saving model ...
Validation loss decreased (1.138225 --> 1.131874).  Saving model ...
Validation loss decreased (1.131874 --> 1.126658).  Saving model ...
Validation loss decreased (1.126658 --> 1.121440).  Saving model ...
Validation loss decreased (1.121440 --> 1.115951).  Saving model ...
Validation loss decreased (1.115951 --> 1.110104).  Saving model ...
Validation loss decreased (1.110104 --> 1.107544).  Saving model ...
Validation loss decreased (1.107544 --> 1.101606).  Saving model ...
Validation loss decreased (1.101606 --> 1.096627).  Saving model ...
Validation loss decreased (1.096627 --> 1.092385).  Saving model ...
Validation loss decreased (1.092385 --> 1.088552).  Saving model ...
Validation loss decreased (1.088552 --> 1.084359).  Saving model ...
Validation loss decreased (1.084359 --> 1.078810).  Saving model ...
Validation loss decreased (1.078810 --> 1.074744).  Saving model ...
Validation loss decreased (1.074744 --> 1.071532).  Saving model ...
Validation loss decreased (1.071532 --> 1.066745).  Saving model ...
Validation loss decreased (1.066745 --> 1.062671).  Saving model ...
Validation loss decreased (1.062671 --> 1.057975).  Saving model ...
Validation loss decreased (1.057975 --> 1.055656).  Saving model ...
Validation loss decreased (1.055656 --> 1.051657).  Saving model ...
Validation loss decreased (1.051657 --> 1.048327).  Saving model ...
Validation loss decreased (1.048327 --> 1.045185).  Saving model ...
Validation loss decreased (1.045185 --> 1.040588).  Saving model ...
Validation loss decreased (1.040588 --> 1.037591).  Saving model ...
Validation loss decreased (1.037591 --> 1.034124).  Saving model ...
Validation loss decreased (1.034124 --> 1.033476).  Saving model ...
Validation loss decreased (1.033476 --> 1.030226).  Saving model ...
Validation loss decreased (1.030226 --> 1.026740).  Saving model ...
Validation loss decreased (1.026740 --> 1.023018).  Saving model ...
Validation loss decreased (1.023018 --> 1.018537).  Saving model ...
Validation loss decreased (1.018537 --> 1.015609).  Saving model ...
Validation loss decreased (1.015609 --> 1.013796).  Saving model ...
EarlyStopping counter: 1 out of 5.0
Validation loss decreased (1.013796 --> 1.011499).  Saving model ...
Validation loss decreased (1.011499 --> 1.009665).  Saving model ...
Validation loss decreased (1.009665 --> 1.005422).  Saving model ...
Validation loss decreased (1.005422 --> 1.002879).  Saving model ...
Validation loss decreased (1.002879 --> 1.002221).  Saving model ...
EarlyStopping counter: 1 out of 5.0
Validation loss decreased (1.002221 --> 1.000682).  Saving model ...
Validation loss decreased (1.000682 --> 0.995829).  Saving model ...
Validation loss decreased (0.995829 --> 0.994750).  Saving model ...
Validation loss decreased (0.994750 --> 0.993123).  Saving model ...
Validation loss decreased (0.993123 --> 0.990487).  Saving model ...
Validation loss decreased (0.990487 --> 0.988221).  Saving model ...
EarlyStopping counter: 1 out of 5.0
EarlyStopping counter: 2 out of 5.0
Validation loss decreased (0.988221 --> 0.984899).  Saving model ...
Validation loss decreased (0.984899 --> 0.984176).  Saving model ...
Validation loss decreased (0.984176 --> 0.982946).  Saving model ...
Validation loss decreased (0.982946 --> 0.982070).  Saving model ...
Validation loss decreased (0.982070 --> 0.979394).  Saving model ...
Validation loss decreased (0.979394 --> 0.978338).  Saving model ...
Validation loss decreased (0.978338 --> 0.977331).  Saving model ...
Validation loss decreased (0.977331 --> 0.976573).  Saving model ...
EarlyStopping counter: 1 out of 5.0
Validation loss decreased (0.976573 --> 0.974649).  Saving model ...
Validation loss decreased (0.974649 --> 0.972122).  Saving model ...
Validation loss decreased (0.972122 --> 0.970949).  Saving model ...
Validation loss decreased (0.970949 --> 0.968348).  Saving model ...
EarlyStopping counter: 1 out of 5.0
EarlyStopping counter: 2 out of 5.0
Validation loss decreased (0.968348 --> 0.966246).  Saving model ...
Validation loss decreased (0.966246 --> 0.965440).  Saving model ...
EarlyStopping counter: 1 out of 5.0
EarlyStopping counter: 2 out of 5.0
EarlyStopping counter: 3 out of 5.0
Validation loss decreased (0.965440 --> 0.963329).  Saving model ...
Validation loss decreased (0.963329 --> 0.962623).  Saving model ...
Validation loss decreased (0.962623 --> 0.961757).  Saving model ...
EarlyStopping counter: 1 out of 5.0
Validation loss decreased (0.961757 --> 0.960455).  Saving model ...
Validation loss decreased (0.960455 --> 0.960420).  Saving model ...
EarlyStopping counter: 1 out of 5.0
Validation loss decreased (0.960420 --> 0.959331).  Saving model ...
EarlyStopping counter: 1 out of 5.0
EarlyStopping counter: 2 out of 5.0
EarlyStopping counter: 3 out of 5.0
Validation loss decreased (0.959331 --> 0.956846).  Saving model ...
Validation loss decreased (0.956846 --> 0.956590).  Saving model ...
Validation loss decreased (0.956590 --> 0.955834).  Saving model ...
EarlyStopping counter: 1 out of 5.0
EarlyStopping counter: 2 out of 5.0
EarlyStopping counter: 3 out of 5.0
EarlyStopping counter: 4 out of 5.0
EarlyStopping counter: 5 out of 5.0
/localscratch/yinan.29201085.0/env/lib/python3.7/site-packages/torch/nn/functional.py:1794: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.
  warnings.warn("nn.functional.tanh is deprecated. Use torch.tanh instead.")
wandb: Waiting for W&B process to finish, PID 246666... (success).
wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: \ 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: | 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: / 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: \ 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: | 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: / 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: \ 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: | 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: / 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb:                                                                                
wandb: Run history:
wandb:     e_F1 ▁▂▄▄▄▅▅▅▆▆▇▇▇▇▇▇▇▇▇▇▇▇█▇██▇▇████████████
wandb:   e_loss ██▇▇▇▇▆▆▆▅▅▄▄▄▄▃▃▃▃▂▂▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁
wandb:     t_F1 ▁▁▂▂▃▄▄▄▅▅▅▅▅▆▆▆▆▆▇▇▆▇▇▇▇▇▇█▇████▇▇█████
wandb:   t_loss ██▇▇▇▇▇▆▆▆▆▅▅▅▅▄▄▄▄▄▄▃▃▃▃▃▂▂▂▂▂▂▂▂▂▂▁▁▁▁
wandb: 
wandb: Run summary:
wandb:     e_F1 61.42877
wandb:   e_loss 0.95746
wandb:     t_F1 69.11924
wandb:   t_loss 0.77275
wandb: 
wandb: Synced 4 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Synced vibrant-wind-2: https://wandb.ai/yinanazhou/xl_512_bs_8_lr_1e06_es_5_lc_False_nr_False_sr_False_stem_True_lemma_False_repeat_5_fold_2/runs/37lbwyhm
wandb: Find logs at: ./wandb/run-20220319_084855-37lbwyhm/logs/debug.log
wandb: 

