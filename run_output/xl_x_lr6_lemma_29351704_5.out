Unloading StdEnv/2020

Due to MODULEPATH changes, the following have been reloaded:
  1) mii/1.1.1


The following have been reloaded with a version change:
  1) python/3.8.2 => python/3.7.4

Using base prefix '/cvmfs/soft.computecanada.ca/easybuild/software/2017/Core/python/3.7.4'
New python executable in /localscratch/yinan.29351704.0/env/bin/python
Installing setuptools, pip, wheel...
done.
Ignoring pip: markers 'python_version < "3"' don't match your environment
Looking in links: /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/nix/avx2, /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/nix/generic, /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic
Collecting pip
Installing collected packages: pip
  Found existing installation: pip 19.1.1
    Uninstalling pip-19.1.1:
      Successfully uninstalled pip-19.1.1
Successfully installed pip-21.2.3+computecanada
Looking in links: /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/nix/avx2, /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/nix/generic, /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/keras-2.8.0+computecanada-py2.py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/Keras_Preprocessing-1.1.2+computecanada-py3-none-any.whl
Requirement already satisfied: matplotlib in /cvmfs/soft.computecanada.ca/easybuild/software/2017/Core/scipy-stack/2019a/lib/python3.7/site-packages (from -r requirements.txt (line 3)) (3.0.2)
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/nltk-3.6.5+computecanada-py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/scikit_learn-0.22.1+computecanada-cp37-cp37m-linux_x86_64.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/tensorboard-2.3.0+computecanada-py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/tensorboard_plugin_wit-1.7.0+computecanada-py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/tensorflow_gpu-2.3.0+computecanada-cp37-cp37m-linux_x86_64.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/tensorflow_estimator-2.3.0+computecanada-py2.py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/tokenizers-0.5.2+computecanada-cp37-cp37m-linux_x86_64.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/nix/avx2/torch-1.4.0+computecanada-cp37-cp37m-linux_x86_64.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/torchtext-0.6.0+computecanada-py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/torchvision-0.8.2+computecanada-cp37-cp37m-linux_x86_64.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/transformers-2.5.1+computecanada-py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/urllib3-1.26.7+computecanada-py2.py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/joblib-1.1.0+computecanada-py2.py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/tqdm-4.63.1+computecanada-py2.py3-none-any.whl
ERROR: Could not find a version that satisfies the requirement regex>=2021.8.3 (from nltk) (from versions: 2018.1.10+computecanada, 2019.11.1+computecanada, 2020.11.13+computecanada)
ERROR: No matching distribution found for regex>=2021.8.3
Looking in links: /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/nix/avx2, /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/nix/generic, /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic
ERROR: Could not find a version that satisfies the requirement numpy==1.20.0+computacanada (from versions: 1.15.0+computecanada, 1.15.2+computecanada, 1.15.4+computecanada, 1.16.0+computecanada, 1.16.2+computecanada, 1.16.3+computecanada, 1.17.4+computecanada, 1.18.1+computecanada, 1.18.4+computecanada, 1.19.1+computecanada, 1.19.2+computecanada, 1.20.2+computecanada)
ERROR: No matching distribution found for numpy==1.20.0+computacanada
Looking in links: /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/nix/avx2, /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/nix/generic, /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/wandb-0.12.5+computecanada-py2.py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/docker_pycreds-0.4.0+computecanada-py2.py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/protobuf-3.19.4+computecanada-py2.py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/promise-2.3+computecanada-py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/subprocess32-3.5.4+computecanada-py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/configparser-5.0.2+computecanada-py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/yaspin-2.1.0+computecanada-py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/psutil-5.7.3+computecanada-cp37-cp37m-linux_x86_64.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/PyYAML-5.3.1+computecanada-cp37-cp37m-linux_x86_64.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/click-8.0.4+computecanada-py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/shortuuid-1.0.1+computecanada-py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/sentry_sdk-1.5.0+computecanada-py2.py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/GitPython-3.1.24+computecanada-py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/pathtools-0.1.2+computecanada-py3-none-any.whl
Requirement already satisfied: python-dateutil>=2.6.1 in /cvmfs/soft.computecanada.ca/easybuild/software/2017/Core/scipy-stack/2019a/lib/python3.7/site-packages (from wandb) (2.7.5)
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/six-1.16.0+computecanada-py2.py3-none-any.whl
Requirement already satisfied: requests<3,>=2.0.0 in /cvmfs/soft.computecanada.ca/easybuild/software/2017/Core/scipy-stack/2019a/lib/python3.7/site-packages (from wandb) (2.21.0)
Requirement already satisfied: importlib-metadata in /cvmfs/soft.computecanada.ca/easybuild/software/2017/Core/scipy-stack/2019a/lib/python3.7/site-packages (from Click!=8.0.0,>=7.0->wandb) (0.8)
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/typing_extensions-4.1.1+computecanada-py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/gitdb-4.0.9+computecanada-py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/smmap-5.0.0+computecanada-py3-none-any.whl
Requirement already satisfied: urllib3<1.25,>=1.21.1 in /cvmfs/soft.computecanada.ca/easybuild/software/2017/Core/scipy-stack/2019a/lib/python3.7/site-packages (from requests<3,>=2.0.0->wandb) (1.24.1)
Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /cvmfs/soft.computecanada.ca/easybuild/software/2017/Core/scipy-stack/2019a/lib/python3.7/site-packages (from requests<3,>=2.0.0->wandb) (3.0.4)
Requirement already satisfied: idna<2.9,>=2.5 in /cvmfs/soft.computecanada.ca/easybuild/software/2017/Core/scipy-stack/2019a/lib/python3.7/site-packages (from requests<3,>=2.0.0->wandb) (2.8)
Requirement already satisfied: certifi>=2017.4.17 in /cvmfs/soft.computecanada.ca/easybuild/software/2017/Core/scipy-stack/2019a/lib/python3.7/site-packages (from requests<3,>=2.0.0->wandb) (2018.11.29)
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/termcolor-1.1.0+computecanada-py3-none-any.whl
Requirement already satisfied: zipp>=0.3.2 in /cvmfs/soft.computecanada.ca/easybuild/software/2017/Core/scipy-stack/2019a/lib/python3.7/site-packages (from importlib-metadata->Click!=8.0.0,>=7.0->wandb) (0.3.3)
Installing collected packages: smmap, typing-extensions, termcolor, six, gitdb, yaspin, subprocess32, shortuuid, sentry-sdk, PyYAML, psutil, protobuf, promise, pathtools, GitPython, docker-pycreds, configparser, Click, wandb
  Attempting uninstall: six
    Found existing installation: six 1.12.0
    Not uninstalling six at /cvmfs/soft.computecanada.ca/easybuild/software/2017/Core/scipy-stack/2019a/lib/python3.7/site-packages, outside environment /localscratch/yinan.29351704.0/env
    Can't uninstall 'six'. No files were found to uninstall.
Successfully installed Click-8.0.4+computecanada GitPython-3.1.24+computecanada PyYAML-5.3.1+computecanada configparser-5.0.2+computecanada docker-pycreds-0.4.0+computecanada gitdb-4.0.9+computecanada pathtools-0.1.2+computecanada promise-2.3+computecanada protobuf-3.19.4+computecanada psutil-5.7.3+computecanada sentry-sdk-1.5.0+computecanada shortuuid-1.0.1+computecanada six-1.16.0+computecanada smmap-5.0.0+computecanada subprocess32-3.5.4+computecanada termcolor-1.1.0+computecanada typing-extensions-4.1.1+computecanada wandb-0.12.5+computecanada yaspin-2.1.0+computecanada
Looking in links: /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/nix/avx2, /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/nix/generic, /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic
ERROR: Could not find a version that satisfies the requirement sagemaker (from versions: none)
ERROR: No matching distribution found for sagemaker
Looking in links: /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/nix/avx2, /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/nix/generic, /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/torch-1.9.1+computecanada-cp37-cp37m-linux_x86_64.whl
Requirement already satisfied: typing-extensions in /localscratch/yinan.29351704.0/env/lib/python3.7/site-packages (from torch) (4.1.1+computecanada)
Installing collected packages: torch
Successfully installed torch-1.9.1+computecanada
Looking in links: /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/nix/avx2, /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/nix/generic, /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/transformers-2.5.1+computecanada-py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/sacremoses-0.0.49+computecanada-py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/tokenizers-0.5.2+computecanada-cp37-cp37m-linux_x86_64.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/sentencepiece-0.1.91+computecanada-cp37-cp37m-linux_x86_64.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/tqdm-4.63.1+computecanada-py2.py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/regex-2020.11.13+computecanada-cp37-cp37m-linux_x86_64.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/filelock-3.4.2+computecanada-py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/boto3-1.21.14+computecanada-py3-none-any.whl
Requirement already satisfied: requests in /cvmfs/soft.computecanada.ca/easybuild/software/2017/Core/scipy-stack/2019a/lib/python3.7/site-packages (from transformers==2.5.1+computecanada) (2.21.0)
Requirement already satisfied: numpy in /cvmfs/soft.computecanada.ca/easybuild/software/2017/Core/scipy-stack/2019a/lib/python3.7/site-packages (from transformers==2.5.1+computecanada) (1.16.0)
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/jmespath-0.10.0+computecanada-py2.py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/s3transfer-0.5.1+computecanada-py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/botocore-1.24.14+computecanada-py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/urllib3-1.26.8+computecanada-py2.py3-none-any.whl
Requirement already satisfied: python-dateutil<3.0.0,>=2.1 in /cvmfs/soft.computecanada.ca/easybuild/software/2017/Core/scipy-stack/2019a/lib/python3.7/site-packages (from botocore<1.25.0,>=1.24.14->boto3->transformers==2.5.1+computecanada) (2.7.5)
Requirement already satisfied: six>=1.5 in /localscratch/yinan.29351704.0/env/lib/python3.7/site-packages (from python-dateutil<3.0.0,>=2.1->botocore<1.25.0,>=1.24.14->boto3->transformers==2.5.1+computecanada) (1.16.0+computecanada)
Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /cvmfs/soft.computecanada.ca/easybuild/software/2017/Core/scipy-stack/2019a/lib/python3.7/site-packages (from requests->transformers==2.5.1+computecanada) (3.0.4)
Requirement already satisfied: certifi>=2017.4.17 in /cvmfs/soft.computecanada.ca/easybuild/software/2017/Core/scipy-stack/2019a/lib/python3.7/site-packages (from requests->transformers==2.5.1+computecanada) (2018.11.29)
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/requests-2.27.1+computecanada-py2.py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/charset_normalizer-2.0.12+computecanada-py3-none-any.whl
Requirement already satisfied: idna<4,>=2.5 in /cvmfs/soft.computecanada.ca/easybuild/software/2017/Core/scipy-stack/2019a/lib/python3.7/site-packages (from requests->transformers==2.5.1+computecanada) (2.8)
Requirement already satisfied: click in /localscratch/yinan.29351704.0/env/lib/python3.7/site-packages (from sacremoses->transformers==2.5.1+computecanada) (8.0.4+computecanada)
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/joblib-1.1.0+computecanada-py2.py3-none-any.whl
Requirement already satisfied: importlib-metadata in /cvmfs/soft.computecanada.ca/easybuild/software/2017/Core/scipy-stack/2019a/lib/python3.7/site-packages (from click->sacremoses->transformers==2.5.1+computecanada) (0.8)
Requirement already satisfied: zipp>=0.3.2 in /cvmfs/soft.computecanada.ca/easybuild/software/2017/Core/scipy-stack/2019a/lib/python3.7/site-packages (from importlib-metadata->click->sacremoses->transformers==2.5.1+computecanada) (0.3.3)
Installing collected packages: urllib3, jmespath, botocore, tqdm, s3transfer, regex, joblib, charset-normalizer, tokenizers, sentencepiece, sacremoses, requests, filelock, boto3, transformers
  Attempting uninstall: urllib3
    Found existing installation: urllib3 1.24.1
    Not uninstalling urllib3 at /cvmfs/soft.computecanada.ca/easybuild/software/2017/Core/scipy-stack/2019a/lib/python3.7/site-packages, outside environment /localscratch/yinan.29351704.0/env
    Can't uninstall 'urllib3'. No files were found to uninstall.
  Attempting uninstall: requests
    Found existing installation: requests 2.21.0
    Not uninstalling requests at /cvmfs/soft.computecanada.ca/easybuild/software/2017/Core/scipy-stack/2019a/lib/python3.7/site-packages, outside environment /localscratch/yinan.29351704.0/env
    Can't uninstall 'requests'. No files were found to uninstall.
Successfully installed boto3-1.21.14+computecanada botocore-1.24.14+computecanada charset-normalizer-2.0.12+computecanada filelock-3.4.2+computecanada jmespath-0.10.0+computecanada joblib-1.1.0+computecanada regex-2020.11.13+computecanada requests-2.27.1+computecanada s3transfer-0.5.1+computecanada sacremoses-0.0.49+computecanada sentencepiece-0.1.91+computecanada tokenizers-0.5.2+computecanada tqdm-4.63.1+computecanada transformers-2.5.1+computecanada urllib3-1.26.8+computecanada
Looking in links: /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/nix/avx2, /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/nix/generic, /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/tensorflow_gpu-2.3.0+computecanada-cp37-cp37m-linux_x86_64.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/Keras_Preprocessing-1.1.2+computecanada-py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/wrapt-1.11.2+computecanada-cp37-cp37m-linux_x86_64.whl
Requirement already satisfied: numpy<1.19.0,>=1.16.0 in /cvmfs/soft.computecanada.ca/easybuild/software/2017/Core/scipy-stack/2019a/lib/python3.7/site-packages (from tensorflow_gpu==2.3.0+computecanada) (1.16.0)
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/astunparse-1.6.3+computecanada-py2.py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/absl_py-1.0.0+computecanada-py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/grpcio-1.38.0+computecanada-cp37-cp37m-linux_x86_64.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/nix/avx2/h5py-2.10.0+computecanada-cp37-cp37m-linux_x86_64.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/tensorflow_estimator-2.3.0+computecanada-py2.py3-none-any.whl
Requirement already satisfied: termcolor>=1.1.0 in /localscratch/yinan.29351704.0/env/lib/python3.7/site-packages (from tensorflow_gpu==2.3.0+computecanada) (1.1.0+computecanada)
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/gast-0.3.3+computecanada-py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/tensorboard-2.8.0+computecanada-py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/nix/generic/scipy-1.4.1+computecanada-cp37-cp37m-linux_x86_64.whl
Requirement already satisfied: protobuf>=3.9.2 in /localscratch/yinan.29351704.0/env/lib/python3.7/site-packages (from tensorflow_gpu==2.3.0+computecanada) (3.19.4+computecanada)
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/google_pasta-0.2.0+computecanada-py3-none-any.whl
Requirement already satisfied: six>=1.12.0 in /localscratch/yinan.29351704.0/env/lib/python3.7/site-packages (from tensorflow_gpu==2.3.0+computecanada) (1.16.0+computecanada)
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/opt_einsum-3.3.0+computecanada-py3-none-any.whl
Requirement already satisfied: wheel>=0.26 in /localscratch/yinan.29351704.0/env/lib/python3.7/site-packages (from tensorflow_gpu==2.3.0+computecanada) (0.33.4)
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/google_auth_oauthlib-0.4.6+computecanada-py2.py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/tensorboard_data_server-0.6.1+computecanada-py3-none-linux_x86_64.whl
Requirement already satisfied: setuptools>=41.0.0 in /localscratch/yinan.29351704.0/env/lib/python3.7/site-packages (from tensorboard<3,>=2.3.0->tensorflow_gpu==2.3.0+computecanada) (41.0.1)
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/Markdown-3.3.6+computecanada-py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/google_auth-2.3.3+computecanada-py2.py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/Werkzeug-2.0.3+computecanada-py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/tensorboard_plugin_wit-1.8.0+computecanada-py3-none-any.whl
Requirement already satisfied: requests<3,>=2.21.0 in /localscratch/yinan.29351704.0/env/lib/python3.7/site-packages (from tensorboard<3,>=2.3.0->tensorflow_gpu==2.3.0+computecanada) (2.27.1+computecanada)
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/rsa-4.8+computecanada-py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/pyasn1_modules-0.2.8+computecanada-py2.py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/cachetools-4.2.4+computecanada-py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/requests_oauthlib-1.3.0+computecanada-py2.py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/importlib_metadata-4.10.1+computecanada-py3-none-any.whl
Requirement already satisfied: typing-extensions>=3.6.4 in /localscratch/yinan.29351704.0/env/lib/python3.7/site-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard<3,>=2.3.0->tensorflow_gpu==2.3.0+computecanada) (4.1.1+computecanada)
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/zipp-3.7.0+computecanada-py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/pyasn1-0.4.8+computecanada-py2.py3-none-any.whl
Requirement already satisfied: certifi>=2017.4.17 in /cvmfs/soft.computecanada.ca/easybuild/software/2017/Core/scipy-stack/2019a/lib/python3.7/site-packages (from requests<3,>=2.21.0->tensorboard<3,>=2.3.0->tensorflow_gpu==2.3.0+computecanada) (2018.11.29)
Requirement already satisfied: idna<4,>=2.5 in /cvmfs/soft.computecanada.ca/easybuild/software/2017/Core/scipy-stack/2019a/lib/python3.7/site-packages (from requests<3,>=2.21.0->tensorboard<3,>=2.3.0->tensorflow_gpu==2.3.0+computecanada) (2.8)
Requirement already satisfied: charset-normalizer~=2.0.0 in /localscratch/yinan.29351704.0/env/lib/python3.7/site-packages (from requests<3,>=2.21.0->tensorboard<3,>=2.3.0->tensorflow_gpu==2.3.0+computecanada) (2.0.12+computecanada)
Requirement already satisfied: urllib3<1.27,>=1.21.1 in /localscratch/yinan.29351704.0/env/lib/python3.7/site-packages (from requests<3,>=2.21.0->tensorboard<3,>=2.3.0->tensorflow_gpu==2.3.0+computecanada) (1.26.8+computecanada)
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/oauthlib-3.1.1+computecanada-py2.py3-none-any.whl
Installing collected packages: pyasn1, zipp, rsa, pyasn1-modules, oauthlib, cachetools, requests-oauthlib, importlib-metadata, google-auth, werkzeug, tensorboard-plugin-wit, tensorboard-data-server, markdown, grpcio, google-auth-oauthlib, absl-py, wrapt, tensorflow-estimator, tensorboard, scipy, opt-einsum, keras-preprocessing, h5py, google-pasta, gast, astunparse, tensorflow-gpu
  Attempting uninstall: pyasn1
    Found existing installation: pyasn1 0.4.3
    Not uninstalling pyasn1 at /cvmfs/soft.computecanada.ca/easybuild/software/2017/Core/scipy-stack/2019a/lib/python3.7/site-packages, outside environment /localscratch/yinan.29351704.0/env
    Can't uninstall 'pyasn1'. No files were found to uninstall.
  Attempting uninstall: zipp
    Found existing installation: zipp 0.3.3
    Not uninstalling zipp at /cvmfs/soft.computecanada.ca/easybuild/software/2017/Core/scipy-stack/2019a/lib/python3.7/site-packages, outside environment /localscratch/yinan.29351704.0/env
    Can't uninstall 'zipp'. No files were found to uninstall.
  Attempting uninstall: importlib-metadata
    Found existing installation: importlib-metadata 0.8
    Not uninstalling importlib-metadata at /cvmfs/soft.computecanada.ca/easybuild/software/2017/Core/scipy-stack/2019a/lib/python3.7/site-packages, outside environment /localscratch/yinan.29351704.0/env
    Can't uninstall 'importlib-metadata'. No files were found to uninstall.
  Attempting uninstall: scipy
    Found existing installation: scipy 1.2.0
    Not uninstalling scipy at /cvmfs/soft.computecanada.ca/easybuild/software/2017/Core/scipy-stack/2019a/lib/python3.7/site-packages, outside environment /localscratch/yinan.29351704.0/env
    Can't uninstall 'scipy'. No files were found to uninstall.
Successfully installed absl-py-1.0.0+computecanada astunparse-1.6.3+computecanada cachetools-4.2.4+computecanada gast-0.3.3+computecanada google-auth-2.3.3+computecanada google-auth-oauthlib-0.4.6+computecanada google-pasta-0.2.0+computecanada grpcio-1.38.0+computecanada h5py-2.10.0+computecanada importlib-metadata-4.10.1+computecanada keras-preprocessing-1.1.2+computecanada markdown-3.3.6+computecanada oauthlib-3.1.1+computecanada opt-einsum-3.3.0+computecanada pyasn1-0.4.8+computecanada pyasn1-modules-0.2.8+computecanada requests-oauthlib-1.3.0+computecanada rsa-4.8+computecanada scipy-1.4.1+computecanada tensorboard-2.8.0+computecanada tensorboard-data-server-0.6.1+computecanada tensorboard-plugin-wit-1.8.0+computecanada tensorflow-estimator-2.3.0+computecanada tensorflow-gpu-2.3.0+computecanada werkzeug-2.0.3+computecanada wrapt-1.11.2+computecanada zipp-3.7.0+computecanada
Looking in links: /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/nix/avx2, /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/nix/generic, /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/keras-2.8.0+computecanada-py2.py3-none-any.whl
Installing collected packages: Keras
Successfully installed Keras-2.8.0+computecanada
Looking in links: /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/nix/avx2, /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/nix/generic, /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/urllib3-1.26.7+computecanada-py2.py3-none-any.whl
Installing collected packages: urllib3
  Attempting uninstall: urllib3
    Found existing installation: urllib3 1.26.8+computecanada
    Uninstalling urllib3-1.26.8+computecanada:
      Successfully uninstalled urllib3-1.26.8+computecanada
Successfully installed urllib3-1.26.7+computecanada
Looking in links: /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/nix/avx2, /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/nix/generic, /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/nltk-3.7+computecanada-py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/nltk-3.6.5+computecanada-py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/nltk-3.6.3+computecanada-py3-none-any.whl
Requirement already satisfied: click in /localscratch/yinan.29351704.0/env/lib/python3.7/site-packages (from nltk) (8.0.4+computecanada)
Requirement already satisfied: joblib in /localscratch/yinan.29351704.0/env/lib/python3.7/site-packages (from nltk) (1.1.0+computecanada)
Requirement already satisfied: regex in /localscratch/yinan.29351704.0/env/lib/python3.7/site-packages (from nltk) (2020.11.13+computecanada)
Requirement already satisfied: tqdm in /localscratch/yinan.29351704.0/env/lib/python3.7/site-packages (from nltk) (4.63.1+computecanada)
Requirement already satisfied: importlib-metadata in /localscratch/yinan.29351704.0/env/lib/python3.7/site-packages (from click->nltk) (4.10.1+computecanada)
Requirement already satisfied: zipp>=0.5 in /localscratch/yinan.29351704.0/env/lib/python3.7/site-packages (from importlib-metadata->click->nltk) (3.7.0+computecanada)
Requirement already satisfied: typing-extensions>=3.6.4 in /localscratch/yinan.29351704.0/env/lib/python3.7/site-packages (from importlib-metadata->click->nltk) (4.1.1+computecanada)
Installing collected packages: nltk
Successfully installed nltk-3.6.3+computecanada
Looking in links: /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/nix/avx2, /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/nix/generic, /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/scikit_learn-0.22.1+computecanada-cp37-cp37m-linux_x86_64.whl
Requirement already satisfied: joblib>=0.11 in /localscratch/yinan.29351704.0/env/lib/python3.7/site-packages (from scikit-learn==0.22.1) (1.1.0+computecanada)
Requirement already satisfied: scipy>=0.17.0 in /localscratch/yinan.29351704.0/env/lib/python3.7/site-packages (from scikit-learn==0.22.1) (1.4.1+computecanada)
Requirement already satisfied: numpy>=1.11.0 in /cvmfs/soft.computecanada.ca/easybuild/software/2017/Core/scipy-stack/2019a/lib/python3.7/site-packages (from scikit-learn==0.22.1) (1.16.0)
Installing collected packages: scikit-learn
Successfully installed scikit-learn-0.22.1+computecanada
Looking in links: /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/nix/avx2, /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/nix/generic, /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic
Requirement already satisfied: tokenizers==0.5.2 in /localscratch/yinan.29351704.0/env/lib/python3.7/site-packages (0.5.2+computecanada)
wandb: Appending key for api.wandb.ai to your netrc file: /home/yinan/.netrc
Starting Task
2022-03-27 09:16:17.241825: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1
[nltk_data] Downloading package stopwords to /home/yinan/nltk_data...
[nltk_data]   Package stopwords is already up-to-date!
[nltk_data] Downloading package wordnet to /home/yinan/nltk_data...
[nltk_data]   Package wordnet is already up-to-date!
wandb: Currently logged in as: yinanazhou (use `wandb login --relogin` to force relogin)
wandb: wandb version 0.12.11 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
2022-03-27 09:16:30.648082: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1
wandb: Tracking run with wandb version 0.12.5
wandb: Syncing run spring-puddle-4
wandb: ⭐️ View project at https://wandb.ai/yinanazhou/xl_512_bs_8_lr_1e06_es_5_lc_False_nr_False_sr_False_stem_False_lemma_True_repeat_1_fold_1
wandb: 🚀 View run at https://wandb.ai/yinanazhou/xl_512_bs_8_lr_1e06_es_5_lc_False_nr_False_sr_False_stem_False_lemma_True_repeat_1_fold_1/runs/9mym6q25
wandb: Run data is saved locally in /project/6002780/yinan/Thesis_MER_Lyrics/lyric-emotion/wandb/run-20220327_091628-9mym6q25
wandb: Run `wandb offline` to turn off syncing.

Validation loss decreased (inf --> 1.432546).  Saving model ...
Validation loss decreased (1.432546 --> 1.413126).  Saving model ...
Validation loss decreased (1.413126 --> 1.396755).  Saving model ...
Validation loss decreased (1.396755 --> 1.383684).  Saving model ...
Validation loss decreased (1.383684 --> 1.373420).  Saving model ...
Validation loss decreased (1.373420 --> 1.365059).  Saving model ...
Validation loss decreased (1.365059 --> 1.357237).  Saving model ...
Validation loss decreased (1.357237 --> 1.350860).  Saving model ...
Validation loss decreased (1.350860 --> 1.345819).  Saving model ...
Validation loss decreased (1.345819 --> 1.339794).  Saving model ...
Validation loss decreased (1.339794 --> 1.333211).  Saving model ...
Validation loss decreased (1.333211 --> 1.327532).  Saving model ...
Validation loss decreased (1.327532 --> 1.320957).  Saving model ...
Validation loss decreased (1.320957 --> 1.315761).  Saving model ...
Validation loss decreased (1.315761 --> 1.309923).  Saving model ...
Validation loss decreased (1.309923 --> 1.303239).  Saving model ...
Validation loss decreased (1.303239 --> 1.297425).  Saving model ...
Validation loss decreased (1.297425 --> 1.291823).  Saving model ...
Validation loss decreased (1.291823 --> 1.284710).  Saving model ...
Validation loss decreased (1.284710 --> 1.276107).  Saving model ...
Validation loss decreased (1.276107 --> 1.268505).  Saving model ...
Validation loss decreased (1.268505 --> 1.261320).  Saving model ...
Validation loss decreased (1.261320 --> 1.255386).  Saving model ...
Validation loss decreased (1.255386 --> 1.245741).  Saving model ...
Validation loss decreased (1.245741 --> 1.236896).  Saving model ...
Validation loss decreased (1.236896 --> 1.229123).  Saving model ...
Validation loss decreased (1.229123 --> 1.221927).  Saving model ...
Validation loss decreased (1.221927 --> 1.215503).  Saving model ...
Validation loss decreased (1.215503 --> 1.208406).  Saving model ...
Validation loss decreased (1.208406 --> 1.202564).  Saving model ...
Validation loss decreased (1.202564 --> 1.195145).  Saving model ...
Validation loss decreased (1.195145 --> 1.190457).  Saving model ...
Validation loss decreased (1.190457 --> 1.188558).  Saving model ...
Validation loss decreased (1.188558 --> 1.181519).  Saving model ...
Validation loss decreased (1.181519 --> 1.174924).  Saving model ...
Validation loss decreased (1.174924 --> 1.169742).  Saving model ...
Validation loss decreased (1.169742 --> 1.167609).  Saving model ...
Validation loss decreased (1.167609 --> 1.159269).  Saving model ...
Validation loss decreased (1.159269 --> 1.155949).  Saving model ...
Validation loss decreased (1.155949 --> 1.150369).  Saving model ...
Validation loss decreased (1.150369 --> 1.144295).  Saving model ...
Validation loss decreased (1.144295 --> 1.139610).  Saving model ...
Validation loss decreased (1.139610 --> 1.136293).  Saving model ...
Validation loss decreased (1.136293 --> 1.132175).  Saving model ...
Validation loss decreased (1.132175 --> 1.128546).  Saving model ...
Validation loss decreased (1.128546 --> 1.122662).  Saving model ...
Validation loss decreased (1.122662 --> 1.118791).  Saving model ...
Validation loss decreased (1.118791 --> 1.114800).  Saving model ...
Validation loss decreased (1.114800 --> 1.109543).  Saving model ...
Validation loss decreased (1.109543 --> 1.107728).  Saving model ...
Validation loss decreased (1.107728 --> 1.101190).  Saving model ...
Validation loss decreased (1.101190 --> 1.097861).  Saving model ...
Validation loss decreased (1.097861 --> 1.095947).  Saving model ...
Validation loss decreased (1.095947 --> 1.091612).  Saving model ...
Validation loss decreased (1.091612 --> 1.091463).  Saving model ...
Validation loss decreased (1.091463 --> 1.087062).  Saving model ...
Validation loss decreased (1.087062 --> 1.083768).  Saving model ...
Validation loss decreased (1.083768 --> 1.080771).  Saving model ...
Validation loss decreased (1.080771 --> 1.077325).  Saving model ...
Validation loss decreased (1.077325 --> 1.072794).  Saving model ...
Validation loss decreased (1.072794 --> 1.069951).  Saving model ...
Validation loss decreased (1.069951 --> 1.067529).  Saving model ...
Validation loss decreased (1.067529 --> 1.064658).  Saving model ...
Validation loss decreased (1.064658 --> 1.063071).  Saving model ...
EarlyStopping counter: 1 out of 5.0
Validation loss decreased (1.063071 --> 1.059871).  Saving model ...
Validation loss decreased (1.059871 --> 1.055762).  Saving model ...
Validation loss decreased (1.055762 --> 1.055532).  Saving model ...
Validation loss decreased (1.055532 --> 1.052331).  Saving model ...
Validation loss decreased (1.052331 --> 1.048086).  Saving model ...
Validation loss decreased (1.048086 --> 1.046424).  Saving model ...
Validation loss decreased (1.046424 --> 1.043945).  Saving model ...
Validation loss decreased (1.043945 --> 1.043592).  Saving model ...
Validation loss decreased (1.043592 --> 1.038909).  Saving model ...
Validation loss decreased (1.038909 --> 1.038774).  Saving model ...
Validation loss decreased (1.038774 --> 1.037030).  Saving model ...
Validation loss decreased (1.037030 --> 1.036792).  Saving model ...
Validation loss decreased (1.036792 --> 1.033075).  Saving model ...
Validation loss decreased (1.033075 --> 1.031138).  Saving model ...
Validation loss decreased (1.031138 --> 1.027383).  Saving model ...
Validation loss decreased (1.027383 --> 1.027307).  Saving model ...
Validation loss decreased (1.027307 --> 1.024689).  Saving model ...
EarlyStopping counter: 1 out of 5.0
Validation loss decreased (1.024689 --> 1.021918).  Saving model ...
Validation loss decreased (1.021918 --> 1.021314).  Saving model ...
Validation loss decreased (1.021314 --> 1.017864).  Saving model ...
Validation loss decreased (1.017864 --> 1.017600).  Saving model ...
EarlyStopping counter: 1 out of 5.0
Validation loss decreased (1.017600 --> 1.015980).  Saving model ...
EarlyStopping counter: 1 out of 5.0
Validation loss decreased (1.015980 --> 1.013767).  Saving model ...
Validation loss decreased (1.013767 --> 1.012502).  Saving model ...
Validation loss decreased (1.012502 --> 1.009174).  Saving model ...
EarlyStopping counter: 1 out of 5.0
EarlyStopping counter: 2 out of 5.0
Validation loss decreased (1.009174 --> 1.007474).  Saving model ...
EarlyStopping counter: 1 out of 5.0
Validation loss decreased (1.007474 --> 1.006743).  Saving model ...
Validation loss decreased (1.006743 --> 1.006419).  Saving model ...
EarlyStopping counter: 1 out of 5.0
Validation loss decreased (1.006419 --> 1.005210).  Saving model ...
Validation loss decreased (1.005210 --> 1.004337).  Saving model ...
Validation loss decreased (1.004337 --> 1.004010).  Saving model ...
EarlyStopping counter: 1 out of 5.0
EarlyStopping counter: 2 out of 5.0
Validation loss decreased (1.004010 --> 1.003118).  Saving model ...
EarlyStopping counter: 1 out of 5.0
Validation loss decreased (1.003118 --> 1.001800).  Saving model ...
Validation loss decreased (1.001800 --> 0.997945).  Saving model ...
Validation loss decreased (0.997945 --> 0.996836).  Saving model ...
EarlyStopping counter: 1 out of 5.0
Validation loss decreased (0.996836 --> 0.996739).  Saving model ...
Validation loss decreased (0.996739 --> 0.995916).  Saving model ...
EarlyStopping counter: 1 out of 5.0
Validation loss decreased (0.995916 --> 0.995910).  Saving model ...
Validation loss decreased (0.995910 --> 0.994420).  Saving model ...
Validation loss decreased (0.994420 --> 0.994344).  Saving model ...
EarlyStopping counter: 1 out of 5.0
EarlyStopping counter: 2 out of 5.0
EarlyStopping counter: 3 out of 5.0
EarlyStopping counter: 4 out of 5.0
EarlyStopping counter: 5 out of 5.0
/localscratch/yinan.29351704.0/env/lib/python3.7/site-packages/torch/nn/functional.py:1794: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.
  warnings.warn("nn.functional.tanh is deprecated. Use torch.tanh instead.")
/localscratch/yinan.29351704.0/env/lib/python3.7/site-packages/transformers/optimization.py:155: UserWarning: This overload of add_ is deprecated:
	add_(Number alpha, Tensor other)
Consider using one of the following signatures instead:
	add_(Tensor other, *, Number alpha) (Triggered internally at  ../torch/csrc/utils/python_arg_parser.cpp:1025.)
  exp_avg.mul_(beta1).add_(1.0 - beta1, grad)
wandb: Waiting for W&B process to finish, PID 71644... (success).
wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: \ 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: | 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: / 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: \ 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: | 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: / 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: \ 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: | 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: / 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: \ 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb:                                                                                
wandb: Run history:
wandb:     e_F1 ▁▂▃▄▅▅▅▆▆▆▆▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇█▇████████████
wandb:   e_loss █▇▇▇▆▆▆▅▅▅▄▄▄▃▃▃▃▃▂▂▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:     t_F1 ▁▂▃▂▃▃▄▄▅▅▅▆▆▆▆▆▆▆▆▇▇▇▇▇▇▇▇▇▇▇▇▇▇███████
wandb:   t_loss ██▇▇▇▇▆▆▆▆▅▅▅▄▄▄▄▄▄▃▃▃▃▃▃▂▃▃▂▂▂▂▂▂▁▁▂▁▁▁
wandb: 
wandb: Run summary:
wandb:     e_F1 58.2124
wandb:   e_loss 0.99576
wandb:     t_F1 71.52368
wandb:   t_loss 0.77103
wandb: 
wandb: Synced 4 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Synced spring-puddle-4: https://wandb.ai/yinanazhou/xl_512_bs_8_lr_1e06_es_5_lc_False_nr_False_sr_False_stem_False_lemma_True_repeat_1_fold_1/runs/9mym6q25
wandb: Find logs at: ./wandb/run-20220327_091628-9mym6q25/logs/debug.log
wandb: 

wandb: wandb version 0.12.11 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
2022-03-27 10:34:30.815809: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1
wandb: Tracking run with wandb version 0.12.5
wandb: Syncing run prime-wave-4
wandb: ⭐️ View project at https://wandb.ai/yinanazhou/xl_512_bs_8_lr_1e06_es_5_lc_False_nr_False_sr_False_stem_False_lemma_True_repeat_1_fold_2
wandb: 🚀 View run at https://wandb.ai/yinanazhou/xl_512_bs_8_lr_1e06_es_5_lc_False_nr_False_sr_False_stem_False_lemma_True_repeat_1_fold_2/runs/1g85sxqc
wandb: Run data is saved locally in /project/6002780/yinan/Thesis_MER_Lyrics/lyric-emotion/wandb/run-20220327_103428-1g85sxqc
wandb: Run `wandb offline` to turn off syncing.

Validation loss decreased (inf --> 1.418272).  Saving model ...
Validation loss decreased (1.418272 --> 1.399606).  Saving model ...
Validation loss decreased (1.399606 --> 1.385583).  Saving model ...
Validation loss decreased (1.385583 --> 1.375089).  Saving model ...
Validation loss decreased (1.375089 --> 1.366658).  Saving model ...
Validation loss decreased (1.366658 --> 1.359750).  Saving model ...
Validation loss decreased (1.359750 --> 1.354003).  Saving model ...
Validation loss decreased (1.354003 --> 1.348768).  Saving model ...
Validation loss decreased (1.348768 --> 1.343230).  Saving model ...
Validation loss decreased (1.343230 --> 1.338330).  Saving model ...
Validation loss decreased (1.338330 --> 1.333645).  Saving model ...
Validation loss decreased (1.333645 --> 1.328305).  Saving model ...
Validation loss decreased (1.328305 --> 1.323384).  Saving model ...
Validation loss decreased (1.323384 --> 1.318223).  Saving model ...
Validation loss decreased (1.318223 --> 1.313591).  Saving model ...
Validation loss decreased (1.313591 --> 1.308876).  Saving model ...
Validation loss decreased (1.308876 --> 1.303419).  Saving model ...
Validation loss decreased (1.303419 --> 1.297954).  Saving model ...
Validation loss decreased (1.297954 --> 1.291938).  Saving model ...
Validation loss decreased (1.291938 --> 1.285618).  Saving model ...
Validation loss decreased (1.285618 --> 1.279576).  Saving model ...
Validation loss decreased (1.279576 --> 1.273422).  Saving model ...
Validation loss decreased (1.273422 --> 1.266987).  Saving model ...
Validation loss decreased (1.266987 --> 1.260173).  Saving model ...
Validation loss decreased (1.260173 --> 1.253532).  Saving model ...
Validation loss decreased (1.253532 --> 1.247535).  Saving model ...
Validation loss decreased (1.247535 --> 1.241033).  Saving model ...
Validation loss decreased (1.241033 --> 1.233836).  Saving model ...
Validation loss decreased (1.233836 --> 1.227064).  Saving model ...
Validation loss decreased (1.227064 --> 1.219411).  Saving model ...
Validation loss decreased (1.219411 --> 1.214059).  Saving model ...
Validation loss decreased (1.214059 --> 1.206301).  Saving model ...
Validation loss decreased (1.206301 --> 1.198245).  Saving model ...
Validation loss decreased (1.198245 --> 1.189208).  Saving model ...
Validation loss decreased (1.189208 --> 1.181231).  Saving model ...
Validation loss decreased (1.181231 --> 1.173157).  Saving model ...
Validation loss decreased (1.173157 --> 1.165037).  Saving model ...
Validation loss decreased (1.165037 --> 1.158268).  Saving model ...
Validation loss decreased (1.158268 --> 1.150999).  Saving model ...
Validation loss decreased (1.150999 --> 1.143185).  Saving model ...
Validation loss decreased (1.143185 --> 1.137502).  Saving model ...
Validation loss decreased (1.137502 --> 1.131122).  Saving model ...
Validation loss decreased (1.131122 --> 1.124333).  Saving model ...
Validation loss decreased (1.124333 --> 1.117442).  Saving model ...
Validation loss decreased (1.117442 --> 1.111110).  Saving model ...
Validation loss decreased (1.111110 --> 1.103262).  Saving model ...
Validation loss decreased (1.103262 --> 1.097044).  Saving model ...
Validation loss decreased (1.097044 --> 1.091250).  Saving model ...
Validation loss decreased (1.091250 --> 1.086405).  Saving model ...
Validation loss decreased (1.086405 --> 1.082163).  Saving model ...
Validation loss decreased (1.082163 --> 1.075082).  Saving model ...
Validation loss decreased (1.075082 --> 1.071795).  Saving model ...
Validation loss decreased (1.071795 --> 1.067986).  Saving model ...
Validation loss decreased (1.067986 --> 1.061314).  Saving model ...
Validation loss decreased (1.061314 --> 1.056092).  Saving model ...
Validation loss decreased (1.056092 --> 1.053068).  Saving model ...
Validation loss decreased (1.053068 --> 1.047517).  Saving model ...
Validation loss decreased (1.047517 --> 1.045201).  Saving model ...
Validation loss decreased (1.045201 --> 1.040217).  Saving model ...
Validation loss decreased (1.040217 --> 1.035966).  Saving model ...
Validation loss decreased (1.035966 --> 1.030802).  Saving model ...
Validation loss decreased (1.030802 --> 1.026020).  Saving model ...
Validation loss decreased (1.026020 --> 1.022836).  Saving model ...
Validation loss decreased (1.022836 --> 1.018968).  Saving model ...
Validation loss decreased (1.018968 --> 1.015879).  Saving model ...
Validation loss decreased (1.015879 --> 1.011887).  Saving model ...
Validation loss decreased (1.011887 --> 1.009057).  Saving model ...
Validation loss decreased (1.009057 --> 1.005061).  Saving model ...
Validation loss decreased (1.005061 --> 1.001671).  Saving model ...
Validation loss decreased (1.001671 --> 0.998878).  Saving model ...
Validation loss decreased (0.998878 --> 0.995817).  Saving model ...
Validation loss decreased (0.995817 --> 0.993326).  Saving model ...
Validation loss decreased (0.993326 --> 0.990583).  Saving model ...
Validation loss decreased (0.990583 --> 0.988626).  Saving model ...
Validation loss decreased (0.988626 --> 0.985835).  Saving model ...
Validation loss decreased (0.985835 --> 0.984191).  Saving model ...
Validation loss decreased (0.984191 --> 0.982203).  Saving model ...
Validation loss decreased (0.982203 --> 0.977912).  Saving model ...
Validation loss decreased (0.977912 --> 0.974463).  Saving model ...
Validation loss decreased (0.974463 --> 0.971954).  Saving model ...
EarlyStopping counter: 1 out of 5.0
EarlyStopping counter: 2 out of 5.0
Validation loss decreased (0.971954 --> 0.970456).  Saving model ...
Validation loss decreased (0.970456 --> 0.968949).  Saving model ...
Validation loss decreased (0.968949 --> 0.965085).  Saving model ...
Validation loss decreased (0.965085 --> 0.964294).  Saving model ...
Validation loss decreased (0.964294 --> 0.961201).  Saving model ...
EarlyStopping counter: 1 out of 5.0
EarlyStopping counter: 2 out of 5.0
Validation loss decreased (0.961201 --> 0.959580).  Saving model ...
Validation loss decreased (0.959580 --> 0.957026).  Saving model ...
EarlyStopping counter: 1 out of 5.0
Validation loss decreased (0.957026 --> 0.954783).  Saving model ...
Validation loss decreased (0.954783 --> 0.952384).  Saving model ...
EarlyStopping counter: 1 out of 5.0
Validation loss decreased (0.952384 --> 0.949898).  Saving model ...
EarlyStopping counter: 1 out of 5.0
EarlyStopping counter: 2 out of 5.0
EarlyStopping counter: 3 out of 5.0
Validation loss decreased (0.949898 --> 0.949702).  Saving model ...
Validation loss decreased (0.949702 --> 0.947878).  Saving model ...
EarlyStopping counter: 1 out of 5.0
Validation loss decreased (0.947878 --> 0.944893).  Saving model ...
EarlyStopping counter: 1 out of 5.0
EarlyStopping counter: 2 out of 5.0
EarlyStopping counter: 3 out of 5.0
EarlyStopping counter: 4 out of 5.0
EarlyStopping counter: 5 out of 5.0
/localscratch/yinan.29351704.0/env/lib/python3.7/site-packages/torch/nn/functional.py:1794: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.
  warnings.warn("nn.functional.tanh is deprecated. Use torch.tanh instead.")
wandb: Waiting for W&B process to finish, PID 75804... (success).
wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: \ 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: | 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: / 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: \ 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: | 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: / 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: \ 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: | 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: / 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb:                                                                                
wandb: Run history:
wandb:     e_F1 ▁▂▃▄▄▅▅▅▅▆▆▆▆▇▇▇▇▇▇▇████████████████████
wandb:   e_loss ██▇▇▇▇▆▆▆▆▅▅▅▄▄▄▄▃▃▃▃▂▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁
wandb:     t_F1 ▁▂▂▃▃▃▄▄▃▄▄▅▅▆▆▅▆▅▆▆▆▆▆▆▇▇▇▇▇▇▇▇▇███████
wandb:   t_loss ██▇▇▇▇▇▇▆▆▆▆▆▅▅▅▅▄▄▄▄▄▄▃▃▃▃▃▃▃▂▂▂▂▂▁▂▁▁▁
wandb: 
wandb: Run summary:
wandb:     e_F1 58.77922
wandb:   e_loss 0.94912
wandb:     t_F1 68.81482
wandb:   t_loss 0.82789
wandb: 
wandb: Synced 4 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Synced prime-wave-4: https://wandb.ai/yinanazhou/xl_512_bs_8_lr_1e06_es_5_lc_False_nr_False_sr_False_stem_False_lemma_True_repeat_1_fold_2/runs/1g85sxqc
wandb: Find logs at: ./wandb/run-20220327_103428-1g85sxqc/logs/debug.log
wandb: 

wandb: wandb version 0.12.11 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
2022-03-27 11:46:09.690974: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1
wandb: Tracking run with wandb version 0.12.5
wandb: Syncing run fiery-rain-4
wandb: ⭐️ View project at https://wandb.ai/yinanazhou/xl_512_bs_8_lr_1e06_es_5_lc_False_nr_False_sr_False_stem_False_lemma_True_repeat_2_fold_1
wandb: 🚀 View run at https://wandb.ai/yinanazhou/xl_512_bs_8_lr_1e06_es_5_lc_False_nr_False_sr_False_stem_False_lemma_True_repeat_2_fold_1/runs/qkewdj07
wandb: Run data is saved locally in /project/6002780/yinan/Thesis_MER_Lyrics/lyric-emotion/wandb/run-20220327_114607-qkewdj07
wandb: Run `wandb offline` to turn off syncing.

Validation loss decreased (inf --> 1.434543).  Saving model ...
Validation loss decreased (1.434543 --> 1.405259).  Saving model ...
Validation loss decreased (1.405259 --> 1.384996).  Saving model ...
Validation loss decreased (1.384996 --> 1.371358).  Saving model ...
Validation loss decreased (1.371358 --> 1.360624).  Saving model ...
Validation loss decreased (1.360624 --> 1.353032).  Saving model ...
Validation loss decreased (1.353032 --> 1.346789).  Saving model ...
Validation loss decreased (1.346789 --> 1.341149).  Saving model ...
Validation loss decreased (1.341149 --> 1.336731).  Saving model ...
Validation loss decreased (1.336731 --> 1.332831).  Saving model ...
Validation loss decreased (1.332831 --> 1.328207).  Saving model ...
Validation loss decreased (1.328207 --> 1.323082).  Saving model ...
Validation loss decreased (1.323082 --> 1.317706).  Saving model ...
Validation loss decreased (1.317706 --> 1.311959).  Saving model ...
Validation loss decreased (1.311959 --> 1.306299).  Saving model ...
Validation loss decreased (1.306299 --> 1.301071).  Saving model ...
Validation loss decreased (1.301071 --> 1.295941).  Saving model ...
Validation loss decreased (1.295941 --> 1.290729).  Saving model ...
Validation loss decreased (1.290729 --> 1.284736).  Saving model ...
Validation loss decreased (1.284736 --> 1.278948).  Saving model ...
Validation loss decreased (1.278948 --> 1.272426).  Saving model ...
Validation loss decreased (1.272426 --> 1.265836).  Saving model ...
Validation loss decreased (1.265836 --> 1.258529).  Saving model ...
Validation loss decreased (1.258529 --> 1.251151).  Saving model ...
Validation loss decreased (1.251151 --> 1.244040).  Saving model ...
Validation loss decreased (1.244040 --> 1.237169).  Saving model ...
Validation loss decreased (1.237169 --> 1.230169).  Saving model ...
Validation loss decreased (1.230169 --> 1.222844).  Saving model ...
Validation loss decreased (1.222844 --> 1.214735).  Saving model ...
Validation loss decreased (1.214735 --> 1.206618).  Saving model ...
Validation loss decreased (1.206618 --> 1.196477).  Saving model ...
Validation loss decreased (1.196477 --> 1.188762).  Saving model ...
Validation loss decreased (1.188762 --> 1.180897).  Saving model ...
Validation loss decreased (1.180897 --> 1.172267).  Saving model ...
Validation loss decreased (1.172267 --> 1.163802).  Saving model ...
Validation loss decreased (1.163802 --> 1.154519).  Saving model ...
Validation loss decreased (1.154519 --> 1.145238).  Saving model ...
Validation loss decreased (1.145238 --> 1.137099).  Saving model ...
Validation loss decreased (1.137099 --> 1.129908).  Saving model ...
Validation loss decreased (1.129908 --> 1.121484).  Saving model ...
Validation loss decreased (1.121484 --> 1.114179).  Saving model ...
Validation loss decreased (1.114179 --> 1.105993).  Saving model ...
Validation loss decreased (1.105993 --> 1.098495).  Saving model ...
Validation loss decreased (1.098495 --> 1.091555).  Saving model ...
Validation loss decreased (1.091555 --> 1.084274).  Saving model ...
Validation loss decreased (1.084274 --> 1.078537).  Saving model ...
Validation loss decreased (1.078537 --> 1.072970).  Saving model ...
Validation loss decreased (1.072970 --> 1.066387).  Saving model ...
Validation loss decreased (1.066387 --> 1.060930).  Saving model ...
Validation loss decreased (1.060930 --> 1.055578).  Saving model ...
Validation loss decreased (1.055578 --> 1.049270).  Saving model ...
Validation loss decreased (1.049270 --> 1.044638).  Saving model ...
Validation loss decreased (1.044638 --> 1.039439).  Saving model ...
Validation loss decreased (1.039439 --> 1.034268).  Saving model ...
Validation loss decreased (1.034268 --> 1.029592).  Saving model ...
Validation loss decreased (1.029592 --> 1.025062).  Saving model ...
Validation loss decreased (1.025062 --> 1.020714).  Saving model ...
Validation loss decreased (1.020714 --> 1.016371).  Saving model ...
Validation loss decreased (1.016371 --> 1.012051).  Saving model ...
Validation loss decreased (1.012051 --> 1.008309).  Saving model ...
Validation loss decreased (1.008309 --> 1.004749).  Saving model ...
Validation loss decreased (1.004749 --> 1.000748).  Saving model ...
Validation loss decreased (1.000748 --> 0.996888).  Saving model ...
Validation loss decreased (0.996888 --> 0.993510).  Saving model ...
Validation loss decreased (0.993510 --> 0.990928).  Saving model ...
Validation loss decreased (0.990928 --> 0.987572).  Saving model ...
Validation loss decreased (0.987572 --> 0.983383).  Saving model ...
Validation loss decreased (0.983383 --> 0.981245).  Saving model ...
Validation loss decreased (0.981245 --> 0.977386).  Saving model ...
Validation loss decreased (0.977386 --> 0.975106).  Saving model ...
Validation loss decreased (0.975106 --> 0.972963).  Saving model ...
Validation loss decreased (0.972963 --> 0.970890).  Saving model ...
Validation loss decreased (0.970890 --> 0.968829).  Saving model ...
Validation loss decreased (0.968829 --> 0.967269).  Saving model ...
Validation loss decreased (0.967269 --> 0.965312).  Saving model ...
Validation loss decreased (0.965312 --> 0.963837).  Saving model ...
Validation loss decreased (0.963837 --> 0.960945).  Saving model ...
Validation loss decreased (0.960945 --> 0.960363).  Saving model ...
Validation loss decreased (0.960363 --> 0.957469).  Saving model ...
Validation loss decreased (0.957469 --> 0.954491).  Saving model ...
Validation loss decreased (0.954491 --> 0.952060).  Saving model ...
Validation loss decreased (0.952060 --> 0.949851).  Saving model ...
Validation loss decreased (0.949851 --> 0.948665).  Saving model ...
Validation loss decreased (0.948665 --> 0.947726).  Saving model ...
Validation loss decreased (0.947726 --> 0.944754).  Saving model ...
Validation loss decreased (0.944754 --> 0.942363).  Saving model ...
Validation loss decreased (0.942363 --> 0.941019).  Saving model ...
Validation loss decreased (0.941019 --> 0.940022).  Saving model ...
Validation loss decreased (0.940022 --> 0.937810).  Saving model ...
Validation loss decreased (0.937810 --> 0.937062).  Saving model ...
Validation loss decreased (0.937062 --> 0.935612).  Saving model ...
Validation loss decreased (0.935612 --> 0.933933).  Saving model ...
Validation loss decreased (0.933933 --> 0.933096).  Saving model ...
Validation loss decreased (0.933096 --> 0.931286).  Saving model ...
Validation loss decreased (0.931286 --> 0.930025).  Saving model ...
Validation loss decreased (0.930025 --> 0.929407).  Saving model ...
Validation loss decreased (0.929407 --> 0.928520).  Saving model ...
EarlyStopping counter: 1 out of 5.0
Validation loss decreased (0.928520 --> 0.926358).  Saving model ...
Validation loss decreased (0.926358 --> 0.926081).  Saving model ...
Validation loss decreased (0.926081 --> 0.925554).  Saving model ...
Validation loss decreased (0.925554 --> 0.923982).  Saving model ...
Validation loss decreased (0.923982 --> 0.923442).  Saving model ...
Validation loss decreased (0.923442 --> 0.923025).  Saving model ...
Validation loss decreased (0.923025 --> 0.922377).  Saving model ...
Validation loss decreased (0.922377 --> 0.922053).  Saving model ...
Validation loss decreased (0.922053 --> 0.921964).  Saving model ...
Validation loss decreased (0.921964 --> 0.920894).  Saving model ...
Validation loss decreased (0.920894 --> 0.920380).  Saving model ...
Validation loss decreased (0.920380 --> 0.920087).  Saving model ...
EarlyStopping counter: 1 out of 5.0
EarlyStopping counter: 2 out of 5.0
EarlyStopping counter: 3 out of 5.0
Validation loss decreased (0.920087 --> 0.919768).  Saving model ...
Validation loss decreased (0.919768 --> 0.918748).  Saving model ...
EarlyStopping counter: 1 out of 5.0
EarlyStopping counter: 2 out of 5.0
Validation loss decreased (0.918748 --> 0.918489).  Saving model ...
Validation loss decreased (0.918489 --> 0.918377).  Saving model ...
EarlyStopping counter: 1 out of 5.0
EarlyStopping counter: 2 out of 5.0
EarlyStopping counter: 3 out of 5.0
EarlyStopping counter: 4 out of 5.0
EarlyStopping counter: 5 out of 5.0
/localscratch/yinan.29351704.0/env/lib/python3.7/site-packages/torch/nn/functional.py:1794: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.
  warnings.warn("nn.functional.tanh is deprecated. Use torch.tanh instead.")
wandb: Waiting for W&B process to finish, PID 79632... (success).
wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: \ 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: | 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: / 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: \ 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: | 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: / 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: \ 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: | 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: / 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb:                                                                                
wandb: Run history:
wandb:     e_F1 ▁▂▃▃▃▄▄▄▅▆▆▆▇▆▇▇▇▇▇▇▇▇▇▇▇▇▇█████████████
wandb:   e_loss █▇▇▇▆▆▆▆▅▅▅▄▄▄▃▃▃▃▂▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:     t_F1 ▁▁▂▃▃▃▄▄▄▅▅▅▅▆▆▆▆▆▆▆▆▆▇▇▇▇▇▇▇▇██▇▇█▇▇███
wandb:   t_loss ██▇▇▇▇▆▆▆▆▆▅▅▅▅▄▄▄▃▄▃▃▃▃▃▃▂▂▂▂▂▂▂▂▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:     e_F1 61.90266
wandb:   e_loss 0.91906
wandb:     t_F1 73.41578
wandb:   t_loss 0.73251
wandb: 
wandb: Synced 4 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Synced fiery-rain-4: https://wandb.ai/yinanazhou/xl_512_bs_8_lr_1e06_es_5_lc_False_nr_False_sr_False_stem_False_lemma_True_repeat_2_fold_1/runs/qkewdj07
wandb: Find logs at: ./wandb/run-20220327_114607-qkewdj07/logs/debug.log
wandb: 

wandb: wandb version 0.12.11 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
2022-03-27 13:08:19.322094: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1
wandb: Tracking run with wandb version 0.12.5
wandb: Syncing run pretty-gorge-1
wandb: ⭐️ View project at https://wandb.ai/yinanazhou/xl_512_bs_8_lr_1e06_es_5_lc_False_nr_False_sr_False_stem_False_lemma_True_repeat_2_fold_2
wandb: 🚀 View run at https://wandb.ai/yinanazhou/xl_512_bs_8_lr_1e06_es_5_lc_False_nr_False_sr_False_stem_False_lemma_True_repeat_2_fold_2/runs/23rd5v5p
wandb: Run data is saved locally in /project/6002780/yinan/Thesis_MER_Lyrics/lyric-emotion/wandb/run-20220327_130817-23rd5v5p
wandb: Run `wandb offline` to turn off syncing.

Validation loss decreased (inf --> 1.447918).  Saving model ...
Validation loss decreased (1.447918 --> 1.422175).  Saving model ...
Validation loss decreased (1.422175 --> 1.402695).  Saving model ...
Validation loss decreased (1.402695 --> 1.387851).  Saving model ...
Validation loss decreased (1.387851 --> 1.375997).  Saving model ...
Validation loss decreased (1.375997 --> 1.366910).  Saving model ...
Validation loss decreased (1.366910 --> 1.359545).  Saving model ...
Validation loss decreased (1.359545 --> 1.353230).  Saving model ...
Validation loss decreased (1.353230 --> 1.347330).  Saving model ...
Validation loss decreased (1.347330 --> 1.342199).  Saving model ...
Validation loss decreased (1.342199 --> 1.337353).  Saving model ...
Validation loss decreased (1.337353 --> 1.332524).  Saving model ...
Validation loss decreased (1.332524 --> 1.327886).  Saving model ...
Validation loss decreased (1.327886 --> 1.322920).  Saving model ...
Validation loss decreased (1.322920 --> 1.318554).  Saving model ...
Validation loss decreased (1.318554 --> 1.313720).  Saving model ...
Validation loss decreased (1.313720 --> 1.308769).  Saving model ...
Validation loss decreased (1.308769 --> 1.303805).  Saving model ...
Validation loss decreased (1.303805 --> 1.297416).  Saving model ...
Validation loss decreased (1.297416 --> 1.292125).  Saving model ...
Validation loss decreased (1.292125 --> 1.286406).  Saving model ...
Validation loss decreased (1.286406 --> 1.280910).  Saving model ...
Validation loss decreased (1.280910 --> 1.275517).  Saving model ...
Validation loss decreased (1.275517 --> 1.269193).  Saving model ...
Validation loss decreased (1.269193 --> 1.262281).  Saving model ...
Validation loss decreased (1.262281 --> 1.256108).  Saving model ...
Validation loss decreased (1.256108 --> 1.247908).  Saving model ...
Validation loss decreased (1.247908 --> 1.241142).  Saving model ...
Validation loss decreased (1.241142 --> 1.235096).  Saving model ...
Validation loss decreased (1.235096 --> 1.227674).  Saving model ...
Validation loss decreased (1.227674 --> 1.219721).  Saving model ...
Validation loss decreased (1.219721 --> 1.213436).  Saving model ...
Validation loss decreased (1.213436 --> 1.204792).  Saving model ...
Validation loss decreased (1.204792 --> 1.194584).  Saving model ...
Validation loss decreased (1.194584 --> 1.187265).  Saving model ...
Validation loss decreased (1.187265 --> 1.180221).  Saving model ...
Validation loss decreased (1.180221 --> 1.174240).  Saving model ...
Validation loss decreased (1.174240 --> 1.167900).  Saving model ...
Validation loss decreased (1.167900 --> 1.161577).  Saving model ...
Validation loss decreased (1.161577 --> 1.156176).  Saving model ...
Validation loss decreased (1.156176 --> 1.149373).  Saving model ...
Validation loss decreased (1.149373 --> 1.143699).  Saving model ...
Validation loss decreased (1.143699 --> 1.138321).  Saving model ...
Validation loss decreased (1.138321 --> 1.131609).  Saving model ...
Validation loss decreased (1.131609 --> 1.125704).  Saving model ...
Validation loss decreased (1.125704 --> 1.118725).  Saving model ...
Validation loss decreased (1.118725 --> 1.112873).  Saving model ...
Validation loss decreased (1.112873 --> 1.107992).  Saving model ...
Validation loss decreased (1.107992 --> 1.103144).  Saving model ...
Validation loss decreased (1.103144 --> 1.095433).  Saving model ...
Validation loss decreased (1.095433 --> 1.089398).  Saving model ...
EarlyStopping counter: 1 out of 5.0
Validation loss decreased (1.089398 --> 1.083958).  Saving model ...
Validation loss decreased (1.083958 --> 1.077558).  Saving model ...
Validation loss decreased (1.077558 --> 1.073455).  Saving model ...
Validation loss decreased (1.073455 --> 1.067580).  Saving model ...
Validation loss decreased (1.067580 --> 1.063641).  Saving model ...
Validation loss decreased (1.063641 --> 1.060608).  Saving model ...
Validation loss decreased (1.060608 --> 1.054331).  Saving model ...
Validation loss decreased (1.054331 --> 1.050248).  Saving model ...
Validation loss decreased (1.050248 --> 1.047036).  Saving model ...
Validation loss decreased (1.047036 --> 1.045457).  Saving model ...
Validation loss decreased (1.045457 --> 1.041651).  Saving model ...
Validation loss decreased (1.041651 --> 1.041392).  Saving model ...
Validation loss decreased (1.041392 --> 1.039145).  Saving model ...
Validation loss decreased (1.039145 --> 1.029776).  Saving model ...
Validation loss decreased (1.029776 --> 1.027268).  Saving model ...
Validation loss decreased (1.027268 --> 1.024871).  Saving model ...
EarlyStopping counter: 1 out of 5.0
Validation loss decreased (1.024871 --> 1.023695).  Saving model ...
Validation loss decreased (1.023695 --> 1.018407).  Saving model ...
Validation loss decreased (1.018407 --> 1.011778).  Saving model ...
Validation loss decreased (1.011778 --> 1.011300).  Saving model ...
Validation loss decreased (1.011300 --> 1.005769).  Saving model ...
Validation loss decreased (1.005769 --> 1.000114).  Saving model ...
Validation loss decreased (1.000114 --> 0.997079).  Saving model ...
Validation loss decreased (0.997079 --> 0.991084).  Saving model ...
Validation loss decreased (0.991084 --> 0.986685).  Saving model ...
EarlyStopping counter: 1 out of 5.0
Validation loss decreased (0.986685 --> 0.986138).  Saving model ...
Validation loss decreased (0.986138 --> 0.984031).  Saving model ...
Validation loss decreased (0.984031 --> 0.980505).  Saving model ...
Validation loss decreased (0.980505 --> 0.975594).  Saving model ...
Validation loss decreased (0.975594 --> 0.974090).  Saving model ...
Validation loss decreased (0.974090 --> 0.972236).  Saving model ...
Validation loss decreased (0.972236 --> 0.971966).  Saving model ...
Validation loss decreased (0.971966 --> 0.968277).  Saving model ...
Validation loss decreased (0.968277 --> 0.965830).  Saving model ...
Validation loss decreased (0.965830 --> 0.962283).  Saving model ...
Validation loss decreased (0.962283 --> 0.962123).  Saving model ...
Validation loss decreased (0.962123 --> 0.959570).  Saving model ...
Validation loss decreased (0.959570 --> 0.955764).  Saving model ...
EarlyStopping counter: 1 out of 5.0
EarlyStopping counter: 2 out of 5.0
Validation loss decreased (0.955764 --> 0.955133).  Saving model ...
Validation loss decreased (0.955133 --> 0.953313).  Saving model ...
Validation loss decreased (0.953313 --> 0.948810).  Saving model ...
Validation loss decreased (0.948810 --> 0.946685).  Saving model ...
Validation loss decreased (0.946685 --> 0.943990).  Saving model ...
Validation loss decreased (0.943990 --> 0.942384).  Saving model ...
Validation loss decreased (0.942384 --> 0.940542).  Saving model ...
Validation loss decreased (0.940542 --> 0.940264).  Saving model ...
EarlyStopping counter: 1 out of 5.0
Validation loss decreased (0.940264 --> 0.937681).  Saving model ...
Validation loss decreased (0.937681 --> 0.937673).  Saving model ...
Validation loss decreased (0.937673 --> 0.935612).  Saving model ...
Validation loss decreased (0.935612 --> 0.933276).  Saving model ...
EarlyStopping counter: 1 out of 5.0
EarlyStopping counter: 2 out of 5.0
EarlyStopping counter: 3 out of 5.0
Validation loss decreased (0.933276 --> 0.932597).  Saving model ...
Validation loss decreased (0.932597 --> 0.929365).  Saving model ...
Validation loss decreased (0.929365 --> 0.928218).  Saving model ...
Validation loss decreased (0.928218 --> 0.926347).  Saving model ...
Validation loss decreased (0.926347 --> 0.925809).  Saving model ...
EarlyStopping counter: 1 out of 5.0
EarlyStopping counter: 2 out of 5.0
Validation loss decreased (0.925809 --> 0.923760).  Saving model ...
EarlyStopping counter: 1 out of 5.0
EarlyStopping counter: 2 out of 5.0
EarlyStopping counter: 3 out of 5.0
EarlyStopping counter: 4 out of 5.0
Validation loss decreased (0.923760 --> 0.923080).  Saving model ...
Validation loss decreased (0.923080 --> 0.920640).  Saving model ...
EarlyStopping counter: 1 out of 5.0
EarlyStopping counter: 2 out of 5.0
Validation loss decreased (0.920640 --> 0.919864).  Saving model ...
EarlyStopping counter: 1 out of 5.0
EarlyStopping counter: 2 out of 5.0
EarlyStopping counter: 3 out of 5.0
EarlyStopping counter: 4 out of 5.0
Validation loss decreased (0.919864 --> 0.919567).  Saving model ...
Validation loss decreased (0.919567 --> 0.917901).  Saving model ...
EarlyStopping counter: 1 out of 5.0
Validation loss decreased (0.917901 --> 0.916542).  Saving model ...
EarlyStopping counter: 1 out of 5.0
EarlyStopping counter: 2 out of 5.0
EarlyStopping counter: 3 out of 5.0
Validation loss decreased (0.916542 --> 0.916403).  Saving model ...
Validation loss decreased (0.916403 --> 0.914951).  Saving model ...
EarlyStopping counter: 1 out of 5.0
EarlyStopping counter: 2 out of 5.0
EarlyStopping counter: 3 out of 5.0
EarlyStopping counter: 4 out of 5.0
EarlyStopping counter: 5 out of 5.0
/localscratch/yinan.29351704.0/env/lib/python3.7/site-packages/torch/nn/functional.py:1794: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.
  warnings.warn("nn.functional.tanh is deprecated. Use torch.tanh instead.")
wandb: Waiting for W&B process to finish, PID 84013... (success).
wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: \ 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: | 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: / 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: \ 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: | 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: / 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: \ 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: | 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb:                                                                                
wandb: Run history:
wandb:     e_F1 ▁▁▄▃▃▄▄▅▅▆▆▆▆▆▆▇▇▇▇▇▇▇▇▇████████████████
wandb:   e_loss ██▇▇▇▆▆▆▅▅▄▄▄▄▃▃▃▃▃▃▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:     t_F1 ▁▁▂▂▃▃▃▄▄▄▅▅▅▆▆▆▆▇▆▇▇▆▆▇▇▇▇▇▇▇▇▇▇█▇▇▇█▇█
wandb:   t_loss ██▇▇▇▇▇▆▆▆▆▅▅▅▅▄▄▄▄▃▄▃▃▃▃▃▂▂▂▂▂▂▂▂▂▂▁▂▂▁
wandb: 
wandb: Run summary:
wandb:     e_F1 60.86675
wandb:   e_loss 0.91719
wandb:     t_F1 70.11295
wandb:   t_loss 0.72865
wandb: 
wandb: Synced 4 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Synced pretty-gorge-1: https://wandb.ai/yinanazhou/xl_512_bs_8_lr_1e06_es_5_lc_False_nr_False_sr_False_stem_False_lemma_True_repeat_2_fold_2/runs/23rd5v5p
wandb: Find logs at: ./wandb/run-20220327_130817-23rd5v5p/logs/debug.log
wandb: 

wandb: wandb version 0.12.11 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
2022-03-27 14:42:09.848662: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1
wandb: Tracking run with wandb version 0.12.5
wandb: Syncing run twilight-breeze-1
wandb: ⭐️ View project at https://wandb.ai/yinanazhou/xl_512_bs_8_lr_1e06_es_5_lc_False_nr_False_sr_False_stem_False_lemma_True_repeat_3_fold_1
wandb: 🚀 View run at https://wandb.ai/yinanazhou/xl_512_bs_8_lr_1e06_es_5_lc_False_nr_False_sr_False_stem_False_lemma_True_repeat_3_fold_1/runs/3a53nlhm
wandb: Run data is saved locally in /project/6002780/yinan/Thesis_MER_Lyrics/lyric-emotion/wandb/run-20220327_144207-3a53nlhm
wandb: Run `wandb offline` to turn off syncing.

Validation loss decreased (inf --> 1.436422).  Saving model ...
Validation loss decreased (1.436422 --> 1.415616).  Saving model ...
Validation loss decreased (1.415616 --> 1.399268).  Saving model ...
Validation loss decreased (1.399268 --> 1.386836).  Saving model ...
Validation loss decreased (1.386836 --> 1.377625).  Saving model ...
Validation loss decreased (1.377625 --> 1.369517).  Saving model ...
Validation loss decreased (1.369517 --> 1.362481).  Saving model ...
Validation loss decreased (1.362481 --> 1.356519).  Saving model ...
Validation loss decreased (1.356519 --> 1.350676).  Saving model ...
Validation loss decreased (1.350676 --> 1.345604).  Saving model ...
Validation loss decreased (1.345604 --> 1.340935).  Saving model ...
Validation loss decreased (1.340935 --> 1.336472).  Saving model ...
Validation loss decreased (1.336472 --> 1.331478).  Saving model ...
Validation loss decreased (1.331478 --> 1.326471).  Saving model ...
Validation loss decreased (1.326471 --> 1.321334).  Saving model ...
Validation loss decreased (1.321334 --> 1.316053).  Saving model ...
Validation loss decreased (1.316053 --> 1.310721).  Saving model ...
Validation loss decreased (1.310721 --> 1.305767).  Saving model ...
Validation loss decreased (1.305767 --> 1.300633).  Saving model ...
Validation loss decreased (1.300633 --> 1.294634).  Saving model ...
Validation loss decreased (1.294634 --> 1.288266).  Saving model ...
Validation loss decreased (1.288266 --> 1.282202).  Saving model ...
Validation loss decreased (1.282202 --> 1.275648).  Saving model ...
Validation loss decreased (1.275648 --> 1.268365).  Saving model ...
Validation loss decreased (1.268365 --> 1.261700).  Saving model ...
Validation loss decreased (1.261700 --> 1.255061).  Saving model ...
Validation loss decreased (1.255061 --> 1.248707).  Saving model ...
Validation loss decreased (1.248707 --> 1.241853).  Saving model ...
Validation loss decreased (1.241853 --> 1.234385).  Saving model ...
Validation loss decreased (1.234385 --> 1.228228).  Saving model ...
Validation loss decreased (1.228228 --> 1.220554).  Saving model ...
Validation loss decreased (1.220554 --> 1.213837).  Saving model ...
Validation loss decreased (1.213837 --> 1.205690).  Saving model ...
Validation loss decreased (1.205690 --> 1.197953).  Saving model ...
Validation loss decreased (1.197953 --> 1.189662).  Saving model ...
Validation loss decreased (1.189662 --> 1.181611).  Saving model ...
Validation loss decreased (1.181611 --> 1.174828).  Saving model ...
Validation loss decreased (1.174828 --> 1.167374).  Saving model ...
Validation loss decreased (1.167374 --> 1.159036).  Saving model ...
Validation loss decreased (1.159036 --> 1.150428).  Saving model ...
Validation loss decreased (1.150428 --> 1.141820).  Saving model ...
Validation loss decreased (1.141820 --> 1.133518).  Saving model ...
Validation loss decreased (1.133518 --> 1.128290).  Saving model ...
Validation loss decreased (1.128290 --> 1.122919).  Saving model ...
Validation loss decreased (1.122919 --> 1.117055).  Saving model ...
Validation loss decreased (1.117055 --> 1.111617).  Saving model ...
Validation loss decreased (1.111617 --> 1.103924).  Saving model ...
Validation loss decreased (1.103924 --> 1.098511).  Saving model ...
Validation loss decreased (1.098511 --> 1.093511).  Saving model ...
Validation loss decreased (1.093511 --> 1.090232).  Saving model ...
Validation loss decreased (1.090232 --> 1.083154).  Saving model ...
Validation loss decreased (1.083154 --> 1.077418).  Saving model ...
Validation loss decreased (1.077418 --> 1.076078).  Saving model ...
Validation loss decreased (1.076078 --> 1.072570).  Saving model ...
Validation loss decreased (1.072570 --> 1.068769).  Saving model ...
Validation loss decreased (1.068769 --> 1.062932).  Saving model ...
Validation loss decreased (1.062932 --> 1.058403).  Saving model ...
Validation loss decreased (1.058403 --> 1.050402).  Saving model ...
Validation loss decreased (1.050402 --> 1.044693).  Saving model ...
Validation loss decreased (1.044693 --> 1.040381).  Saving model ...
Validation loss decreased (1.040381 --> 1.037283).  Saving model ...
Validation loss decreased (1.037283 --> 1.036822).  Saving model ...
Validation loss decreased (1.036822 --> 1.035549).  Saving model ...
Validation loss decreased (1.035549 --> 1.032338).  Saving model ...
EarlyStopping counter: 1 out of 5.0
Validation loss decreased (1.032338 --> 1.028214).  Saving model ...
Validation loss decreased (1.028214 --> 1.021695).  Saving model ...
Validation loss decreased (1.021695 --> 1.017211).  Saving model ...
Validation loss decreased (1.017211 --> 1.015078).  Saving model ...
Validation loss decreased (1.015078 --> 1.012921).  Saving model ...
Validation loss decreased (1.012921 --> 1.007639).  Saving model ...
Validation loss decreased (1.007639 --> 1.004793).  Saving model ...
Validation loss decreased (1.004793 --> 1.001259).  Saving model ...
Validation loss decreased (1.001259 --> 0.998626).  Saving model ...
Validation loss decreased (0.998626 --> 0.996525).  Saving model ...
Validation loss decreased (0.996525 --> 0.991218).  Saving model ...
Validation loss decreased (0.991218 --> 0.986490).  Saving model ...
Validation loss decreased (0.986490 --> 0.983624).  Saving model ...
Validation loss decreased (0.983624 --> 0.980919).  Saving model ...
Validation loss decreased (0.980919 --> 0.979672).  Saving model ...
Validation loss decreased (0.979672 --> 0.977505).  Saving model ...
EarlyStopping counter: 1 out of 5.0
Validation loss decreased (0.977505 --> 0.974529).  Saving model ...
Validation loss decreased (0.974529 --> 0.973448).  Saving model ...
Validation loss decreased (0.973448 --> 0.971551).  Saving model ...
Validation loss decreased (0.971551 --> 0.967433).  Saving model ...
Validation loss decreased (0.967433 --> 0.966734).  Saving model ...
Validation loss decreased (0.966734 --> 0.964895).  Saving model ...
Validation loss decreased (0.964895 --> 0.963661).  Saving model ...
Validation loss decreased (0.963661 --> 0.961014).  Saving model ...
Validation loss decreased (0.961014 --> 0.958742).  Saving model ...
EarlyStopping counter: 1 out of 5.0
Validation loss decreased (0.958742 --> 0.957852).  Saving model ...
Validation loss decreased (0.957852 --> 0.956969).  Saving model ...
EarlyStopping counter: 1 out of 5.0
Validation loss decreased (0.956969 --> 0.953816).  Saving model ...
Validation loss decreased (0.953816 --> 0.951796).  Saving model ...
EarlyStopping counter: 1 out of 5.0
EarlyStopping counter: 2 out of 5.0
EarlyStopping counter: 3 out of 5.0
Validation loss decreased (0.951796 --> 0.951250).  Saving model ...
Validation loss decreased (0.951250 --> 0.948295).  Saving model ...
Validation loss decreased (0.948295 --> 0.947388).  Saving model ...
Validation loss decreased (0.947388 --> 0.945255).  Saving model ...
EarlyStopping counter: 1 out of 5.0
Validation loss decreased (0.945255 --> 0.941062).  Saving model ...
EarlyStopping counter: 1 out of 5.0
EarlyStopping counter: 2 out of 5.0
EarlyStopping counter: 3 out of 5.0
EarlyStopping counter: 4 out of 5.0
EarlyStopping counter: 5 out of 5.0
/localscratch/yinan.29351704.0/env/lib/python3.7/site-packages/torch/nn/functional.py:1794: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.
  warnings.warn("nn.functional.tanh is deprecated. Use torch.tanh instead.")
wandb: Waiting for W&B process to finish, PID 88995... (success).
wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: \ 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: | 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: / 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: \ 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: | 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: / 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: \ 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: | 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: / 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: \ 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: | 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb:                                                                                
wandb: Run history:
wandb:     e_F1 ▁▁▂▄▅▅▅▅▆▆▆▆▇▆▇▇▇▇▇▇▇▇▇▇████████████████
wandb:   e_loss █▇▇▇▇▆▆▆▆▅▅▅▅▄▄▄▃▃▃▃▃▂▂▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁
wandb:     t_F1 ▁▁▂▃▃▃▃▃▄▄▅▅▅▆▆▅▆▆▆▆▇▇▇▇▇▇▇▇▇▇█▇█████▇██
wandb:   t_loss ██▇▇▇▇▇▇▆▆▆▆▅▅▅▅▄▄▄▄▃▃▃▃▃▃▃▃▂▂▂▂▂▁▂▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:     e_F1 59.90093
wandb:   e_loss 0.94235
wandb:     t_F1 68.60832
wandb:   t_loss 0.78304
wandb: 
wandb: Synced 4 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Synced twilight-breeze-1: https://wandb.ai/yinanazhou/xl_512_bs_8_lr_1e06_es_5_lc_False_nr_False_sr_False_stem_False_lemma_True_repeat_3_fold_1/runs/3a53nlhm
wandb: Find logs at: ./wandb/run-20220327_144207-3a53nlhm/logs/debug.log
wandb: 

wandb: wandb version 0.12.11 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
2022-03-27 15:53:34.244502: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1
wandb: Tracking run with wandb version 0.12.5
wandb: Syncing run clear-forest-1
wandb: ⭐️ View project at https://wandb.ai/yinanazhou/xl_512_bs_8_lr_1e06_es_5_lc_False_nr_False_sr_False_stem_False_lemma_True_repeat_3_fold_2
wandb: 🚀 View run at https://wandb.ai/yinanazhou/xl_512_bs_8_lr_1e06_es_5_lc_False_nr_False_sr_False_stem_False_lemma_True_repeat_3_fold_2/runs/3ikvwest
wandb: Run data is saved locally in /project/6002780/yinan/Thesis_MER_Lyrics/lyric-emotion/wandb/run-20220327_155331-3ikvwest
wandb: Run `wandb offline` to turn off syncing.

Validation loss decreased (inf --> 1.400003).  Saving model ...
Validation loss decreased (1.400003 --> 1.375919).  Saving model ...
Validation loss decreased (1.375919 --> 1.359139).  Saving model ...
Validation loss decreased (1.359139 --> 1.347077).  Saving model ...
Validation loss decreased (1.347077 --> 1.338730).  Saving model ...
Validation loss decreased (1.338730 --> 1.331860).  Saving model ...
Validation loss decreased (1.331860 --> 1.325256).  Saving model ...
Validation loss decreased (1.325256 --> 1.319836).  Saving model ...
Validation loss decreased (1.319836 --> 1.314466).  Saving model ...
Validation loss decreased (1.314466 --> 1.309005).  Saving model ...
Validation loss decreased (1.309005 --> 1.303312).  Saving model ...
Validation loss decreased (1.303312 --> 1.297711).  Saving model ...
Validation loss decreased (1.297711 --> 1.292332).  Saving model ...
Validation loss decreased (1.292332 --> 1.286078).  Saving model ...
Validation loss decreased (1.286078 --> 1.279948).  Saving model ...
Validation loss decreased (1.279948 --> 1.273560).  Saving model ...
Validation loss decreased (1.273560 --> 1.267138).  Saving model ...
Validation loss decreased (1.267138 --> 1.261486).  Saving model ...
Validation loss decreased (1.261486 --> 1.255466).  Saving model ...
Validation loss decreased (1.255466 --> 1.248101).  Saving model ...
Validation loss decreased (1.248101 --> 1.241271).  Saving model ...
Validation loss decreased (1.241271 --> 1.235117).  Saving model ...
Validation loss decreased (1.235117 --> 1.229204).  Saving model ...
Validation loss decreased (1.229204 --> 1.223003).  Saving model ...
Validation loss decreased (1.223003 --> 1.217153).  Saving model ...
Validation loss decreased (1.217153 --> 1.210965).  Saving model ...
Validation loss decreased (1.210965 --> 1.205210).  Saving model ...
Validation loss decreased (1.205210 --> 1.196989).  Saving model ...
Validation loss decreased (1.196989 --> 1.190116).  Saving model ...
Validation loss decreased (1.190116 --> 1.185735).  Saving model ...
Validation loss decreased (1.185735 --> 1.177320).  Saving model ...
Validation loss decreased (1.177320 --> 1.171088).  Saving model ...
Validation loss decreased (1.171088 --> 1.165124).  Saving model ...
Validation loss decreased (1.165124 --> 1.159713).  Saving model ...
Validation loss decreased (1.159713 --> 1.153657).  Saving model ...
Validation loss decreased (1.153657 --> 1.148218).  Saving model ...
Validation loss decreased (1.148218 --> 1.143058).  Saving model ...
Validation loss decreased (1.143058 --> 1.136797).  Saving model ...
Validation loss decreased (1.136797 --> 1.132787).  Saving model ...
Validation loss decreased (1.132787 --> 1.127499).  Saving model ...
Validation loss decreased (1.127499 --> 1.121359).  Saving model ...
Validation loss decreased (1.121359 --> 1.115905).  Saving model ...
Validation loss decreased (1.115905 --> 1.110891).  Saving model ...
Validation loss decreased (1.110891 --> 1.104805).  Saving model ...
Validation loss decreased (1.104805 --> 1.099815).  Saving model ...
Validation loss decreased (1.099815 --> 1.093822).  Saving model ...
Validation loss decreased (1.093822 --> 1.088066).  Saving model ...
Validation loss decreased (1.088066 --> 1.085031).  Saving model ...
Validation loss decreased (1.085031 --> 1.080326).  Saving model ...
Validation loss decreased (1.080326 --> 1.074048).  Saving model ...
Validation loss decreased (1.074048 --> 1.070092).  Saving model ...
Validation loss decreased (1.070092 --> 1.063647).  Saving model ...
Validation loss decreased (1.063647 --> 1.061154).  Saving model ...
Validation loss decreased (1.061154 --> 1.058007).  Saving model ...
Validation loss decreased (1.058007 --> 1.053294).  Saving model ...
Validation loss decreased (1.053294 --> 1.048909).  Saving model ...
Validation loss decreased (1.048909 --> 1.045820).  Saving model ...
Validation loss decreased (1.045820 --> 1.042863).  Saving model ...
Validation loss decreased (1.042863 --> 1.038819).  Saving model ...
Validation loss decreased (1.038819 --> 1.035495).  Saving model ...
Validation loss decreased (1.035495 --> 1.030604).  Saving model ...
Validation loss decreased (1.030604 --> 1.024247).  Saving model ...
Validation loss decreased (1.024247 --> 1.021856).  Saving model ...
Validation loss decreased (1.021856 --> 1.020069).  Saving model ...
Validation loss decreased (1.020069 --> 1.016038).  Saving model ...
Validation loss decreased (1.016038 --> 1.015304).  Saving model ...
Validation loss decreased (1.015304 --> 1.012839).  Saving model ...
Validation loss decreased (1.012839 --> 1.009524).  Saving model ...
Validation loss decreased (1.009524 --> 1.005893).  Saving model ...
Validation loss decreased (1.005893 --> 1.002050).  Saving model ...
Validation loss decreased (1.002050 --> 0.998489).  Saving model ...
Validation loss decreased (0.998489 --> 0.996183).  Saving model ...
Validation loss decreased (0.996183 --> 0.990428).  Saving model ...
Validation loss decreased (0.990428 --> 0.986690).  Saving model ...
Validation loss decreased (0.986690 --> 0.983896).  Saving model ...
Validation loss decreased (0.983896 --> 0.981584).  Saving model ...
Validation loss decreased (0.981584 --> 0.978985).  Saving model ...
Validation loss decreased (0.978985 --> 0.975447).  Saving model ...
Validation loss decreased (0.975447 --> 0.971784).  Saving model ...
Validation loss decreased (0.971784 --> 0.968028).  Saving model ...
Validation loss decreased (0.968028 --> 0.965219).  Saving model ...
Validation loss decreased (0.965219 --> 0.964557).  Saving model ...
Validation loss decreased (0.964557 --> 0.963467).  Saving model ...
Validation loss decreased (0.963467 --> 0.960152).  Saving model ...
Validation loss decreased (0.960152 --> 0.958446).  Saving model ...
Validation loss decreased (0.958446 --> 0.956406).  Saving model ...
Validation loss decreased (0.956406 --> 0.951811).  Saving model ...
Validation loss decreased (0.951811 --> 0.950935).  Saving model ...
Validation loss decreased (0.950935 --> 0.947465).  Saving model ...
Validation loss decreased (0.947465 --> 0.946212).  Saving model ...
Validation loss decreased (0.946212 --> 0.944134).  Saving model ...
Validation loss decreased (0.944134 --> 0.940802).  Saving model ...
Validation loss decreased (0.940802 --> 0.939160).  Saving model ...
Validation loss decreased (0.939160 --> 0.937346).  Saving model ...
Validation loss decreased (0.937346 --> 0.936655).  Saving model ...
Validation loss decreased (0.936655 --> 0.935107).  Saving model ...
EarlyStopping counter: 1 out of 5.0
Validation loss decreased (0.935107 --> 0.932330).  Saving model ...
Validation loss decreased (0.932330 --> 0.930527).  Saving model ...
EarlyStopping counter: 1 out of 5.0
Validation loss decreased (0.930527 --> 0.930461).  Saving model ...
Validation loss decreased (0.930461 --> 0.928159).  Saving model ...
Validation loss decreased (0.928159 --> 0.927531).  Saving model ...
Validation loss decreased (0.927531 --> 0.925658).  Saving model ...
Validation loss decreased (0.925658 --> 0.924919).  Saving model ...
Validation loss decreased (0.924919 --> 0.922950).  Saving model ...
EarlyStopping counter: 1 out of 5.0
Validation loss decreased (0.922950 --> 0.922624).  Saving model ...
Validation loss decreased (0.922624 --> 0.922123).  Saving model ...
Validation loss decreased (0.922123 --> 0.921606).  Saving model ...
Validation loss decreased (0.921606 --> 0.920917).  Saving model ...
EarlyStopping counter: 1 out of 5.0
Validation loss decreased (0.920917 --> 0.920694).  Saving model ...
Validation loss decreased (0.920694 --> 0.919404).  Saving model ...
Validation loss decreased (0.919404 --> 0.918208).  Saving model ...
EarlyStopping counter: 1 out of 5.0
Validation loss decreased (0.918208 --> 0.917998).  Saving model ...
Validation loss decreased (0.917998 --> 0.916048).  Saving model ...
Validation loss decreased (0.916048 --> 0.915135).  Saving model ...
EarlyStopping counter: 1 out of 5.0
EarlyStopping counter: 2 out of 5.0
EarlyStopping counter: 3 out of 5.0
EarlyStopping counter: 4 out of 5.0
Validation loss decreased (0.915135 --> 0.914758).  Saving model ...
Validation loss decreased (0.914758 --> 0.913003).  Saving model ...
Validation loss decreased (0.913003 --> 0.912421).  Saving model ...
Validation loss decreased (0.912421 --> 0.911943).  Saving model ...
EarlyStopping counter: 1 out of 5.0
EarlyStopping counter: 2 out of 5.0
EarlyStopping counter: 3 out of 5.0
EarlyStopping counter: 4 out of 5.0
Validation loss decreased (0.911943 --> 0.911207).  Saving model ...
Validation loss decreased (0.911207 --> 0.911181).  Saving model ...
EarlyStopping counter: 1 out of 5.0
EarlyStopping counter: 2 out of 5.0
EarlyStopping counter: 3 out of 5.0
EarlyStopping counter: 4 out of 5.0
EarlyStopping counter: 5 out of 5.0
/localscratch/yinan.29351704.0/env/lib/python3.7/site-packages/torch/nn/functional.py:1794: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.
  warnings.warn("nn.functional.tanh is deprecated. Use torch.tanh instead.")
wandb: Waiting for W&B process to finish, PID 92821... (success).
wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: \ 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: | 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: / 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: \ 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: | 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: / 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: \ 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: | 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: / 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: \ 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb:                                                                                
wandb: Run history:
wandb:     e_F1 ▁▃▅▅▅▅▆▆▆▆▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇███████████████
wandb:   e_loss ██▇▇▇▆▆▆▅▅▅▄▄▄▃▃▃▃▃▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:     t_F1 ▁▂▃▃▃▄▄▄▅▅▅▆▆▆▅▆▆▆▆▆▆▆▇▇▇▇▇█▇▇█▇██▇█████
wandb:   t_loss ██▇▇▇▇▇▆▆▆▅▅▅▅▅▄▄▄▄▄▄▃▃▃▃▂▃▂▂▂▂▂▂▁▂▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:     e_F1 62.37854
wandb:   e_loss 0.91168
wandb:     t_F1 69.32788
wandb:   t_loss 0.75234
wandb: 
wandb: Synced 4 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Synced clear-forest-1: https://wandb.ai/yinanazhou/xl_512_bs_8_lr_1e06_es_5_lc_False_nr_False_sr_False_stem_False_lemma_True_repeat_3_fold_2/runs/3ikvwest
wandb: Find logs at: ./wandb/run-20220327_155331-3ikvwest/logs/debug.log
wandb: 

wandb: wandb version 0.12.11 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
2022-03-27 17:22:54.801608: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1
wandb: Tracking run with wandb version 0.12.5
wandb: Syncing run sparkling-firefly-1
wandb: ⭐️ View project at https://wandb.ai/yinanazhou/xl_512_bs_8_lr_1e06_es_5_lc_False_nr_False_sr_False_stem_False_lemma_True_repeat_4_fold_1
wandb: 🚀 View run at https://wandb.ai/yinanazhou/xl_512_bs_8_lr_1e06_es_5_lc_False_nr_False_sr_False_stem_False_lemma_True_repeat_4_fold_1/runs/1dd6446e
wandb: Run data is saved locally in /project/6002780/yinan/Thesis_MER_Lyrics/lyric-emotion/wandb/run-20220327_172252-1dd6446e
wandb: Run `wandb offline` to turn off syncing.

Validation loss decreased (inf --> 1.391654).  Saving model ...
Validation loss decreased (1.391654 --> 1.380146).  Saving model ...
Validation loss decreased (1.380146 --> 1.371156).  Saving model ...
Validation loss decreased (1.371156 --> 1.364060).  Saving model ...
Validation loss decreased (1.364060 --> 1.357725).  Saving model ...
Validation loss decreased (1.357725 --> 1.352231).  Saving model ...
Validation loss decreased (1.352231 --> 1.347100).  Saving model ...
Validation loss decreased (1.347100 --> 1.341999).  Saving model ...
Validation loss decreased (1.341999 --> 1.337024).  Saving model ...
Validation loss decreased (1.337024 --> 1.332035).  Saving model ...
Validation loss decreased (1.332035 --> 1.326741).  Saving model ...
Validation loss decreased (1.326741 --> 1.321113).  Saving model ...
Validation loss decreased (1.321113 --> 1.315527).  Saving model ...
Validation loss decreased (1.315527 --> 1.309321).  Saving model ...
Validation loss decreased (1.309321 --> 1.303936).  Saving model ...
Validation loss decreased (1.303936 --> 1.297755).  Saving model ...
Validation loss decreased (1.297755 --> 1.290996).  Saving model ...
Validation loss decreased (1.290996 --> 1.284206).  Saving model ...
Validation loss decreased (1.284206 --> 1.277053).  Saving model ...
Validation loss decreased (1.277053 --> 1.269377).  Saving model ...
Validation loss decreased (1.269377 --> 1.262131).  Saving model ...
Validation loss decreased (1.262131 --> 1.254863).  Saving model ...
Validation loss decreased (1.254863 --> 1.247355).  Saving model ...
Validation loss decreased (1.247355 --> 1.239238).  Saving model ...
Validation loss decreased (1.239238 --> 1.231439).  Saving model ...
Validation loss decreased (1.231439 --> 1.222891).  Saving model ...
Validation loss decreased (1.222891 --> 1.214499).  Saving model ...
Validation loss decreased (1.214499 --> 1.207014).  Saving model ...
Validation loss decreased (1.207014 --> 1.200039).  Saving model ...
Validation loss decreased (1.200039 --> 1.192309).  Saving model ...
Validation loss decreased (1.192309 --> 1.183980).  Saving model ...
Validation loss decreased (1.183980 --> 1.175737).  Saving model ...
Validation loss decreased (1.175737 --> 1.167809).  Saving model ...
Validation loss decreased (1.167809 --> 1.161278).  Saving model ...
Validation loss decreased (1.161278 --> 1.154080).  Saving model ...
Validation loss decreased (1.154080 --> 1.146830).  Saving model ...
Validation loss decreased (1.146830 --> 1.140031).  Saving model ...
Validation loss decreased (1.140031 --> 1.133568).  Saving model ...
Validation loss decreased (1.133568 --> 1.127626).  Saving model ...
Validation loss decreased (1.127626 --> 1.121865).  Saving model ...
Validation loss decreased (1.121865 --> 1.115667).  Saving model ...
Validation loss decreased (1.115667 --> 1.109619).  Saving model ...
Validation loss decreased (1.109619 --> 1.103668).  Saving model ...
Validation loss decreased (1.103668 --> 1.099299).  Saving model ...
Validation loss decreased (1.099299 --> 1.094898).  Saving model ...
Validation loss decreased (1.094898 --> 1.090511).  Saving model ...
Validation loss decreased (1.090511 --> 1.085010).  Saving model ...
Validation loss decreased (1.085010 --> 1.080630).  Saving model ...
Validation loss decreased (1.080630 --> 1.075442).  Saving model ...
Validation loss decreased (1.075442 --> 1.072551).  Saving model ...
Validation loss decreased (1.072551 --> 1.066711).  Saving model ...
Validation loss decreased (1.066711 --> 1.062096).  Saving model ...
Validation loss decreased (1.062096 --> 1.056983).  Saving model ...
Validation loss decreased (1.056983 --> 1.053866).  Saving model ...
Validation loss decreased (1.053866 --> 1.049106).  Saving model ...
Validation loss decreased (1.049106 --> 1.044358).  Saving model ...
Validation loss decreased (1.044358 --> 1.039529).  Saving model ...
Validation loss decreased (1.039529 --> 1.034951).  Saving model ...
Validation loss decreased (1.034951 --> 1.031333).  Saving model ...
Validation loss decreased (1.031333 --> 1.027131).  Saving model ...
Validation loss decreased (1.027131 --> 1.024638).  Saving model ...
Validation loss decreased (1.024638 --> 1.021019).  Saving model ...
Validation loss decreased (1.021019 --> 1.018854).  Saving model ...
Validation loss decreased (1.018854 --> 1.014358).  Saving model ...
Validation loss decreased (1.014358 --> 1.010107).  Saving model ...
Validation loss decreased (1.010107 --> 1.006107).  Saving model ...
Validation loss decreased (1.006107 --> 1.001954).  Saving model ...
Validation loss decreased (1.001954 --> 0.998759).  Saving model ...
Validation loss decreased (0.998759 --> 0.996291).  Saving model ...
Validation loss decreased (0.996291 --> 0.992697).  Saving model ...
Validation loss decreased (0.992697 --> 0.990507).  Saving model ...
Validation loss decreased (0.990507 --> 0.987858).  Saving model ...
Validation loss decreased (0.987858 --> 0.984424).  Saving model ...
Validation loss decreased (0.984424 --> 0.981428).  Saving model ...
Validation loss decreased (0.981428 --> 0.978690).  Saving model ...
Validation loss decreased (0.978690 --> 0.977754).  Saving model ...
Validation loss decreased (0.977754 --> 0.975322).  Saving model ...
Validation loss decreased (0.975322 --> 0.973692).  Saving model ...
Validation loss decreased (0.973692 --> 0.970487).  Saving model ...
Validation loss decreased (0.970487 --> 0.967769).  Saving model ...
Validation loss decreased (0.967769 --> 0.965104).  Saving model ...
Validation loss decreased (0.965104 --> 0.962847).  Saving model ...
Validation loss decreased (0.962847 --> 0.962412).  Saving model ...
Validation loss decreased (0.962412 --> 0.960710).  Saving model ...
Validation loss decreased (0.960710 --> 0.956109).  Saving model ...
Validation loss decreased (0.956109 --> 0.953773).  Saving model ...
Validation loss decreased (0.953773 --> 0.950671).  Saving model ...
Validation loss decreased (0.950671 --> 0.948952).  Saving model ...
Validation loss decreased (0.948952 --> 0.948711).  Saving model ...
EarlyStopping counter: 1 out of 5.0
Validation loss decreased (0.948711 --> 0.945320).  Saving model ...
Validation loss decreased (0.945320 --> 0.943794).  Saving model ...
Validation loss decreased (0.943794 --> 0.941834).  Saving model ...
Validation loss decreased (0.941834 --> 0.938207).  Saving model ...
Validation loss decreased (0.938207 --> 0.936590).  Saving model ...
Validation loss decreased (0.936590 --> 0.936535).  Saving model ...
Validation loss decreased (0.936535 --> 0.935243).  Saving model ...
EarlyStopping counter: 1 out of 5.0
Validation loss decreased (0.935243 --> 0.933345).  Saving model ...
EarlyStopping counter: 1 out of 5.0
Validation loss decreased (0.933345 --> 0.932343).  Saving model ...
Validation loss decreased (0.932343 --> 0.929188).  Saving model ...
Validation loss decreased (0.929188 --> 0.927408).  Saving model ...
Validation loss decreased (0.927408 --> 0.927298).  Saving model ...
EarlyStopping counter: 1 out of 5.0
Validation loss decreased (0.927298 --> 0.927103).  Saving model ...
Validation loss decreased (0.927103 --> 0.924372).  Saving model ...
Validation loss decreased (0.924372 --> 0.924141).  Saving model ...
Validation loss decreased (0.924141 --> 0.923953).  Saving model ...
Validation loss decreased (0.923953 --> 0.922084).  Saving model ...
EarlyStopping counter: 1 out of 5.0
Validation loss decreased (0.922084 --> 0.921279).  Saving model ...
Validation loss decreased (0.921279 --> 0.920694).  Saving model ...
Validation loss decreased (0.920694 --> 0.919727).  Saving model ...
Validation loss decreased (0.919727 --> 0.919416).  Saving model ...
Validation loss decreased (0.919416 --> 0.918769).  Saving model ...
EarlyStopping counter: 1 out of 5.0
EarlyStopping counter: 2 out of 5.0
Validation loss decreased (0.918769 --> 0.916915).  Saving model ...
EarlyStopping counter: 1 out of 5.0
Validation loss decreased (0.916915 --> 0.916662).  Saving model ...
Validation loss decreased (0.916662 --> 0.916013).  Saving model ...
Validation loss decreased (0.916013 --> 0.915070).  Saving model ...
Validation loss decreased (0.915070 --> 0.914080).  Saving model ...
EarlyStopping counter: 1 out of 5.0
Validation loss decreased (0.914080 --> 0.911724).  Saving model ...
Validation loss decreased (0.911724 --> 0.911441).  Saving model ...
Validation loss decreased (0.911441 --> 0.909671).  Saving model ...
EarlyStopping counter: 1 out of 5.0
EarlyStopping counter: 2 out of 5.0
EarlyStopping counter: 3 out of 5.0
EarlyStopping counter: 4 out of 5.0
EarlyStopping counter: 5 out of 5.0
/localscratch/yinan.29351704.0/env/lib/python3.7/site-packages/torch/nn/functional.py:1794: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.
  warnings.warn("nn.functional.tanh is deprecated. Use torch.tanh instead.")
wandb: Waiting for W&B process to finish, PID 97630... (success).
wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: \ 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: | 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: / 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb:                                                                                
wandb: Run history:
wandb:     e_F1 ▁▂▄▅▅▆▆▆▆▆▆▆▇▇▇▇▇▇▇▇▇▇▇▇▇▇██████████████
wandb:   e_loss ██▇▇▇▇▆▆▅▅▅▄▄▄▄▃▃▃▃▃▂▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁
wandb:     t_F1 ▁▂▂▂▃▃▄▄▅▅▅▆▅▆▅▆▆▆▆▇▆▇▇▇▇▇▇▇▇▇▇▇██▇▇▇███
wandb:   t_loss ████▇▇▇▇▆▆▆▅▅▅▅▅▄▄▄▄▄▃▃▃▃▃▃▂▃▂▂▂▂▂▂▂▁▁▁▁
wandb: 
wandb: Run summary:
wandb:     e_F1 62.21557
wandb:   e_loss 0.91285
wandb:     t_F1 73.23213
wandb:   t_loss 0.73384
wandb: 
wandb: Synced 4 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Synced sparkling-firefly-1: https://wandb.ai/yinanazhou/xl_512_bs_8_lr_1e06_es_5_lc_False_nr_False_sr_False_stem_False_lemma_True_repeat_4_fold_1/runs/1dd6446e
wandb: Find logs at: ./wandb/run-20220327_172252-1dd6446e/logs/debug.log
wandb: 

wandb: wandb version 0.12.11 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
2022-03-27 18:46:18.689473: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1
wandb: Tracking run with wandb version 0.12.5
wandb: Syncing run fancy-totem-1
wandb: ⭐️ View project at https://wandb.ai/yinanazhou/xl_512_bs_8_lr_1e06_es_5_lc_False_nr_False_sr_False_stem_False_lemma_True_repeat_4_fold_2
wandb: 🚀 View run at https://wandb.ai/yinanazhou/xl_512_bs_8_lr_1e06_es_5_lc_False_nr_False_sr_False_stem_False_lemma_True_repeat_4_fold_2/runs/1az1tlsy
wandb: Run data is saved locally in /project/6002780/yinan/Thesis_MER_Lyrics/lyric-emotion/wandb/run-20220327_184616-1az1tlsy
wandb: Run `wandb offline` to turn off syncing.

Validation loss decreased (inf --> 1.432681).  Saving model ...
Validation loss decreased (1.432681 --> 1.418552).  Saving model ...
Validation loss decreased (1.418552 --> 1.407902).  Saving model ...
Validation loss decreased (1.407902 --> 1.399214).  Saving model ...
Validation loss decreased (1.399214 --> 1.390971).  Saving model ...
Validation loss decreased (1.390971 --> 1.383718).  Saving model ...
Validation loss decreased (1.383718 --> 1.377441).  Saving model ...
Validation loss decreased (1.377441 --> 1.370957).  Saving model ...
Validation loss decreased (1.370957 --> 1.364807).  Saving model ...
Validation loss decreased (1.364807 --> 1.359879).  Saving model ...
Validation loss decreased (1.359879 --> 1.353822).  Saving model ...
Validation loss decreased (1.353822 --> 1.347580).  Saving model ...
Validation loss decreased (1.347580 --> 1.342359).  Saving model ...
Validation loss decreased (1.342359 --> 1.336931).  Saving model ...
Validation loss decreased (1.336931 --> 1.330633).  Saving model ...
Validation loss decreased (1.330633 --> 1.323948).  Saving model ...
Validation loss decreased (1.323948 --> 1.317310).  Saving model ...
Validation loss decreased (1.317310 --> 1.310019).  Saving model ...
Validation loss decreased (1.310019 --> 1.303406).  Saving model ...
Validation loss decreased (1.303406 --> 1.296472).  Saving model ...
Validation loss decreased (1.296472 --> 1.289172).  Saving model ...
Validation loss decreased (1.289172 --> 1.282395).  Saving model ...
Validation loss decreased (1.282395 --> 1.275416).  Saving model ...
Validation loss decreased (1.275416 --> 1.268417).  Saving model ...
Validation loss decreased (1.268417 --> 1.260700).  Saving model ...
Validation loss decreased (1.260700 --> 1.252420).  Saving model ...
Validation loss decreased (1.252420 --> 1.245058).  Saving model ...
Validation loss decreased (1.245058 --> 1.237927).  Saving model ...
Validation loss decreased (1.237927 --> 1.229967).  Saving model ...
Validation loss decreased (1.229967 --> 1.222081).  Saving model ...
Validation loss decreased (1.222081 --> 1.213279).  Saving model ...
Validation loss decreased (1.213279 --> 1.204293).  Saving model ...
Validation loss decreased (1.204293 --> 1.196257).  Saving model ...
Validation loss decreased (1.196257 --> 1.187650).  Saving model ...
Validation loss decreased (1.187650 --> 1.178386).  Saving model ...
Validation loss decreased (1.178386 --> 1.169055).  Saving model ...
Validation loss decreased (1.169055 --> 1.161970).  Saving model ...
Validation loss decreased (1.161970 --> 1.152731).  Saving model ...
Validation loss decreased (1.152731 --> 1.145436).  Saving model ...
Validation loss decreased (1.145436 --> 1.137117).  Saving model ...
Validation loss decreased (1.137117 --> 1.128160).  Saving model ...
Validation loss decreased (1.128160 --> 1.120161).  Saving model ...
Validation loss decreased (1.120161 --> 1.111640).  Saving model ...
Validation loss decreased (1.111640 --> 1.104951).  Saving model ...
Validation loss decreased (1.104951 --> 1.097279).  Saving model ...
Validation loss decreased (1.097279 --> 1.090881).  Saving model ...
Validation loss decreased (1.090881 --> 1.084005).  Saving model ...
Validation loss decreased (1.084005 --> 1.078746).  Saving model ...
Validation loss decreased (1.078746 --> 1.073059).  Saving model ...
Validation loss decreased (1.073059 --> 1.066166).  Saving model ...
Validation loss decreased (1.066166 --> 1.061826).  Saving model ...
Validation loss decreased (1.061826 --> 1.056978).  Saving model ...
Validation loss decreased (1.056978 --> 1.051958).  Saving model ...
Validation loss decreased (1.051958 --> 1.047052).  Saving model ...
Validation loss decreased (1.047052 --> 1.042101).  Saving model ...
Validation loss decreased (1.042101 --> 1.036430).  Saving model ...
Validation loss decreased (1.036430 --> 1.032634).  Saving model ...
Validation loss decreased (1.032634 --> 1.027651).  Saving model ...
Validation loss decreased (1.027651 --> 1.022474).  Saving model ...
Validation loss decreased (1.022474 --> 1.017521).  Saving model ...
Validation loss decreased (1.017521 --> 1.013701).  Saving model ...
Validation loss decreased (1.013701 --> 1.010464).  Saving model ...
Validation loss decreased (1.010464 --> 1.008495).  Saving model ...
Validation loss decreased (1.008495 --> 1.003568).  Saving model ...
Validation loss decreased (1.003568 --> 0.999690).  Saving model ...
Validation loss decreased (0.999690 --> 0.995833).  Saving model ...
Validation loss decreased (0.995833 --> 0.992035).  Saving model ...
Validation loss decreased (0.992035 --> 0.989763).  Saving model ...
Validation loss decreased (0.989763 --> 0.986718).  Saving model ...
Validation loss decreased (0.986718 --> 0.983394).  Saving model ...
Validation loss decreased (0.983394 --> 0.979594).  Saving model ...
Validation loss decreased (0.979594 --> 0.976648).  Saving model ...
Validation loss decreased (0.976648 --> 0.976170).  Saving model ...
Validation loss decreased (0.976170 --> 0.972679).  Saving model ...
Validation loss decreased (0.972679 --> 0.970784).  Saving model ...
Validation loss decreased (0.970784 --> 0.967699).  Saving model ...
Validation loss decreased (0.967699 --> 0.965750).  Saving model ...
Validation loss decreased (0.965750 --> 0.964206).  Saving model ...
Validation loss decreased (0.964206 --> 0.962022).  Saving model ...
Validation loss decreased (0.962022 --> 0.958819).  Saving model ...
Validation loss decreased (0.958819 --> 0.955850).  Saving model ...
Validation loss decreased (0.955850 --> 0.953120).  Saving model ...
Validation loss decreased (0.953120 --> 0.951797).  Saving model ...
Validation loss decreased (0.951797 --> 0.948278).  Saving model ...
Validation loss decreased (0.948278 --> 0.946985).  Saving model ...
Validation loss decreased (0.946985 --> 0.945115).  Saving model ...
Validation loss decreased (0.945115 --> 0.943429).  Saving model ...
EarlyStopping counter: 1 out of 5.0
Validation loss decreased (0.943429 --> 0.940596).  Saving model ...
EarlyStopping counter: 1 out of 5.0
Validation loss decreased (0.940596 --> 0.940100).  Saving model ...
Validation loss decreased (0.940100 --> 0.939155).  Saving model ...
Validation loss decreased (0.939155 --> 0.937982).  Saving model ...
Validation loss decreased (0.937982 --> 0.934727).  Saving model ...
EarlyStopping counter: 1 out of 5.0
Validation loss decreased (0.934727 --> 0.934064).  Saving model ...
Validation loss decreased (0.934064 --> 0.932547).  Saving model ...
EarlyStopping counter: 1 out of 5.0
Validation loss decreased (0.932547 --> 0.931660).  Saving model ...
Validation loss decreased (0.931660 --> 0.931589).  Saving model ...
EarlyStopping counter: 1 out of 5.0
Validation loss decreased (0.931589 --> 0.929196).  Saving model ...
Validation loss decreased (0.929196 --> 0.929161).  Saving model ...
Validation loss decreased (0.929161 --> 0.928054).  Saving model ...
Validation loss decreased (0.928054 --> 0.927837).  Saving model ...
Validation loss decreased (0.927837 --> 0.927745).  Saving model ...
Validation loss decreased (0.927745 --> 0.927424).  Saving model ...
Validation loss decreased (0.927424 --> 0.927133).  Saving model ...
EarlyStopping counter: 1 out of 5.0
Validation loss decreased (0.927133 --> 0.926833).  Saving model ...
EarlyStopping counter: 1 out of 5.0
EarlyStopping counter: 2 out of 5.0
EarlyStopping counter: 3 out of 5.0
EarlyStopping counter: 4 out of 5.0
Validation loss decreased (0.926833 --> 0.926389).  Saving model ...
EarlyStopping counter: 1 out of 5.0
EarlyStopping counter: 2 out of 5.0
EarlyStopping counter: 3 out of 5.0
EarlyStopping counter: 4 out of 5.0
EarlyStopping counter: 5 out of 5.0
/localscratch/yinan.29351704.0/env/lib/python3.7/site-packages/torch/nn/functional.py:1794: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.
  warnings.warn("nn.functional.tanh is deprecated. Use torch.tanh instead.")
wandb: Waiting for W&B process to finish, PID 102071... (success).
wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: \ 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: | 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: / 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: \ 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: | 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: / 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: \ 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: | 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: / 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb:                                                                                
wandb: Run history:
wandb:     e_F1 ▁▂▃▄▅▅▆▆▆▆▆▇▇▇▇▇▇█▇█████████████████████
wandb:   e_loss ██▇▇▇▆▆▆▆▅▅▅▄▄▄▃▃▃▃▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:     t_F1 ▁▂▂▂▃▃▃▄▄▅▅▅▅▆▅▅▆▆▆▆▆▇▆▆▇▇▇▇▇▇▇▇██▇▇▇▇██
wandb:   t_loss █▇▇▇▇▇▇▇▆▆▆▆▆▅▅▅▄▄▄▄▄▃▃▃▃▃▃▂▂▂▂▂▂▂▂▂▂▂▁▁
wandb: 
wandb: Run summary:
wandb:     e_F1 61.63956
wandb:   e_loss 0.93065
wandb:     t_F1 72.798
wandb:   t_loss 0.75019
wandb: 
wandb: Synced 4 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Synced fancy-totem-1: https://wandb.ai/yinanazhou/xl_512_bs_8_lr_1e06_es_5_lc_False_nr_False_sr_False_stem_False_lemma_True_repeat_4_fold_2/runs/1az1tlsy
wandb: Find logs at: ./wandb/run-20220327_184616-1az1tlsy/logs/debug.log
wandb: 

wandb: wandb version 0.12.11 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
2022-03-27 20:03:39.863541: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1
wandb: Tracking run with wandb version 0.12.5
wandb: Syncing run mild-puddle-1
wandb: ⭐️ View project at https://wandb.ai/yinanazhou/xl_512_bs_8_lr_1e06_es_5_lc_False_nr_False_sr_False_stem_False_lemma_True_repeat_5_fold_1
wandb: 🚀 View run at https://wandb.ai/yinanazhou/xl_512_bs_8_lr_1e06_es_5_lc_False_nr_False_sr_False_stem_False_lemma_True_repeat_5_fold_1/runs/1zjxcdaa
wandb: Run data is saved locally in /project/6002780/yinan/Thesis_MER_Lyrics/lyric-emotion/wandb/run-20220327_200337-1zjxcdaa
wandb: Run `wandb offline` to turn off syncing.

Validation loss decreased (inf --> 1.400685).  Saving model ...
Validation loss decreased (1.400685 --> 1.388993).  Saving model ...
Validation loss decreased (1.388993 --> 1.380338).  Saving model ...
Validation loss decreased (1.380338 --> 1.372652).  Saving model ...
Validation loss decreased (1.372652 --> 1.366743).  Saving model ...
Validation loss decreased (1.366743 --> 1.361510).  Saving model ...
Validation loss decreased (1.361510 --> 1.356254).  Saving model ...
Validation loss decreased (1.356254 --> 1.351399).  Saving model ...
Validation loss decreased (1.351399 --> 1.346064).  Saving model ...
Validation loss decreased (1.346064 --> 1.340999).  Saving model ...
Validation loss decreased (1.340999 --> 1.335991).  Saving model ...
Validation loss decreased (1.335991 --> 1.331026).  Saving model ...
Validation loss decreased (1.331026 --> 1.326089).  Saving model ...
Validation loss decreased (1.326089 --> 1.320401).  Saving model ...
Validation loss decreased (1.320401 --> 1.314401).  Saving model ...
Validation loss decreased (1.314401 --> 1.308811).  Saving model ...
Validation loss decreased (1.308811 --> 1.302398).  Saving model ...
Validation loss decreased (1.302398 --> 1.295620).  Saving model ...
Validation loss decreased (1.295620 --> 1.289108).  Saving model ...
Validation loss decreased (1.289108 --> 1.281176).  Saving model ...
Validation loss decreased (1.281176 --> 1.273295).  Saving model ...
Validation loss decreased (1.273295 --> 1.265628).  Saving model ...
Validation loss decreased (1.265628 --> 1.257025).  Saving model ...
Validation loss decreased (1.257025 --> 1.248490).  Saving model ...
Validation loss decreased (1.248490 --> 1.239615).  Saving model ...
Validation loss decreased (1.239615 --> 1.230538).  Saving model ...
Validation loss decreased (1.230538 --> 1.220746).  Saving model ...
Validation loss decreased (1.220746 --> 1.210997).  Saving model ...
Validation loss decreased (1.210997 --> 1.202320).  Saving model ...
Validation loss decreased (1.202320 --> 1.194311).  Saving model ...
Validation loss decreased (1.194311 --> 1.187198).  Saving model ...
Validation loss decreased (1.187198 --> 1.178600).  Saving model ...
Validation loss decreased (1.178600 --> 1.171423).  Saving model ...
Validation loss decreased (1.171423 --> 1.162328).  Saving model ...
Validation loss decreased (1.162328 --> 1.155460).  Saving model ...
Validation loss decreased (1.155460 --> 1.148591).  Saving model ...
Validation loss decreased (1.148591 --> 1.141503).  Saving model ...
Validation loss decreased (1.141503 --> 1.133622).  Saving model ...
Validation loss decreased (1.133622 --> 1.125952).  Saving model ...
Validation loss decreased (1.125952 --> 1.120775).  Saving model ...
Validation loss decreased (1.120775 --> 1.115545).  Saving model ...
Validation loss decreased (1.115545 --> 1.110283).  Saving model ...
Validation loss decreased (1.110283 --> 1.103474).  Saving model ...
Validation loss decreased (1.103474 --> 1.099346).  Saving model ...
Validation loss decreased (1.099346 --> 1.092375).  Saving model ...
Validation loss decreased (1.092375 --> 1.086048).  Saving model ...
Validation loss decreased (1.086048 --> 1.079895).  Saving model ...
Validation loss decreased (1.079895 --> 1.075717).  Saving model ...
Validation loss decreased (1.075717 --> 1.071120).  Saving model ...
Validation loss decreased (1.071120 --> 1.065408).  Saving model ...
Validation loss decreased (1.065408 --> 1.062064).  Saving model ...
Validation loss decreased (1.062064 --> 1.059121).  Saving model ...
Validation loss decreased (1.059121 --> 1.053837).  Saving model ...
Validation loss decreased (1.053837 --> 1.047909).  Saving model ...
Validation loss decreased (1.047909 --> 1.042395).  Saving model ...
Validation loss decreased (1.042395 --> 1.038179).  Saving model ...
Validation loss decreased (1.038179 --> 1.035973).  Saving model ...
Validation loss decreased (1.035973 --> 1.032330).  Saving model ...
Validation loss decreased (1.032330 --> 1.028504).  Saving model ...
Validation loss decreased (1.028504 --> 1.025762).  Saving model ...
Validation loss decreased (1.025762 --> 1.019661).  Saving model ...
Validation loss decreased (1.019661 --> 1.015176).  Saving model ...
Validation loss decreased (1.015176 --> 1.011100).  Saving model ...
Validation loss decreased (1.011100 --> 1.006967).  Saving model ...
Validation loss decreased (1.006967 --> 1.001938).  Saving model ...
Validation loss decreased (1.001938 --> 0.999086).  Saving model ...
Validation loss decreased (0.999086 --> 0.996946).  Saving model ...
Validation loss decreased (0.996946 --> 0.993753).  Saving model ...
Validation loss decreased (0.993753 --> 0.990924).  Saving model ...
Validation loss decreased (0.990924 --> 0.987438).  Saving model ...
Validation loss decreased (0.987438 --> 0.983474).  Saving model ...
Validation loss decreased (0.983474 --> 0.979879).  Saving model ...
Validation loss decreased (0.979879 --> 0.977486).  Saving model ...
Validation loss decreased (0.977486 --> 0.977017).  Saving model ...
Validation loss decreased (0.977017 --> 0.971391).  Saving model ...
Validation loss decreased (0.971391 --> 0.969393).  Saving model ...
Validation loss decreased (0.969393 --> 0.968027).  Saving model ...
Validation loss decreased (0.968027 --> 0.964773).  Saving model ...
EarlyStopping counter: 1 out of 5.0
Validation loss decreased (0.964773 --> 0.960489).  Saving model ...
Validation loss decreased (0.960489 --> 0.958856).  Saving model ...
Validation loss decreased (0.958856 --> 0.956499).  Saving model ...
Validation loss decreased (0.956499 --> 0.954773).  Saving model ...
Validation loss decreased (0.954773 --> 0.950964).  Saving model ...
Validation loss decreased (0.950964 --> 0.949155).  Saving model ...
Validation loss decreased (0.949155 --> 0.946994).  Saving model ...
EarlyStopping counter: 1 out of 5.0
Validation loss decreased (0.946994 --> 0.946177).  Saving model ...
Validation loss decreased (0.946177 --> 0.943398).  Saving model ...
Validation loss decreased (0.943398 --> 0.942395).  Saving model ...
Validation loss decreased (0.942395 --> 0.940395).  Saving model ...
Validation loss decreased (0.940395 --> 0.938268).  Saving model ...
Validation loss decreased (0.938268 --> 0.936334).  Saving model ...
Validation loss decreased (0.936334 --> 0.935683).  Saving model ...
Validation loss decreased (0.935683 --> 0.933409).  Saving model ...
Validation loss decreased (0.933409 --> 0.930548).  Saving model ...
Validation loss decreased (0.930548 --> 0.930071).  Saving model ...
EarlyStopping counter: 1 out of 5.0
EarlyStopping counter: 2 out of 5.0
Validation loss decreased (0.930071 --> 0.928686).  Saving model ...
Validation loss decreased (0.928686 --> 0.926354).  Saving model ...
Validation loss decreased (0.926354 --> 0.923347).  Saving model ...
Validation loss decreased (0.923347 --> 0.922381).  Saving model ...
EarlyStopping counter: 1 out of 5.0
EarlyStopping counter: 2 out of 5.0
Validation loss decreased (0.922381 --> 0.921208).  Saving model ...
Validation loss decreased (0.921208 --> 0.920059).  Saving model ...
EarlyStopping counter: 1 out of 5.0
EarlyStopping counter: 2 out of 5.0
Validation loss decreased (0.920059 --> 0.919417).  Saving model ...
Validation loss decreased (0.919417 --> 0.918017).  Saving model ...
Validation loss decreased (0.918017 --> 0.917748).  Saving model ...
EarlyStopping counter: 1 out of 5.0
Validation loss decreased (0.917748 --> 0.917560).  Saving model ...
Validation loss decreased (0.917560 --> 0.917244).  Saving model ...
EarlyStopping counter: 1 out of 5.0
Validation loss decreased (0.917244 --> 0.916529).  Saving model ...
Validation loss decreased (0.916529 --> 0.916142).  Saving model ...
Validation loss decreased (0.916142 --> 0.915649).  Saving model ...
EarlyStopping counter: 1 out of 5.0
Validation loss decreased (0.915649 --> 0.915387).  Saving model ...
Validation loss decreased (0.915387 --> 0.915181).  Saving model ...
Validation loss decreased (0.915181 --> 0.913413).  Saving model ...
EarlyStopping counter: 1 out of 5.0
EarlyStopping counter: 2 out of 5.0
EarlyStopping counter: 3 out of 5.0
EarlyStopping counter: 4 out of 5.0
EarlyStopping counter: 5 out of 5.0
/localscratch/yinan.29351704.0/env/lib/python3.7/site-packages/torch/nn/functional.py:1794: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.
  warnings.warn("nn.functional.tanh is deprecated. Use torch.tanh instead.")
wandb: Waiting for W&B process to finish, PID 106208... (success).
wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: \ 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: | 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: / 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: \ 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: | 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: / 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: \ 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: | 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: / 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb:                                                                                
wandb: Run history:
wandb:     e_F1 ▁▂▃▄▄▅▅▅▆▆▆▆▆▇▆▇▇▇▇▇▇▇▇▇▇▇██████████████
wandb:   e_loss ██▇▇▇▇▆▆▆▅▅▄▄▄▄▃▃▃▃▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:     t_F1 ▁▁▃▃▃▄▄▄▄▄▅▅▆▆▆▆▆▆▇▇▆▆▇▇▇▇▇▇▇▇▇▇▇▇▇█████
wandb:   t_loss ███▇▇▇▇▇▆▆▆▅▅▅▅▅▄▄▄▄▄▄▃▃▃▃▂▃▂▂▂▂▂▂▂▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:     e_F1 64.0114
wandb:   e_loss 0.91557
wandb:     t_F1 72.49924
wandb:   t_loss 0.73464
wandb: 
wandb: Synced 4 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Synced mild-puddle-1: https://wandb.ai/yinanazhou/xl_512_bs_8_lr_1e06_es_5_lc_False_nr_False_sr_False_stem_False_lemma_True_repeat_5_fold_1/runs/1zjxcdaa
wandb: Find logs at: ./wandb/run-20220327_200337-1zjxcdaa/logs/debug.log
wandb: 

wandb: wandb version 0.12.11 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
2022-03-27 21:28:08.403786: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1
wandb: Tracking run with wandb version 0.12.5
wandb: Syncing run electric-water-1
wandb: ⭐️ View project at https://wandb.ai/yinanazhou/xl_512_bs_8_lr_1e06_es_5_lc_False_nr_False_sr_False_stem_False_lemma_True_repeat_5_fold_2
wandb: 🚀 View run at https://wandb.ai/yinanazhou/xl_512_bs_8_lr_1e06_es_5_lc_False_nr_False_sr_False_stem_False_lemma_True_repeat_5_fold_2/runs/30s3u1kg
wandb: Run data is saved locally in /project/6002780/yinan/Thesis_MER_Lyrics/lyric-emotion/wandb/run-20220327_212806-30s3u1kg
wandb: Run `wandb offline` to turn off syncing.

Validation loss decreased (inf --> 1.395132).  Saving model ...
Validation loss decreased (1.395132 --> 1.390295).  Saving model ...
Validation loss decreased (1.390295 --> 1.385466).  Saving model ...
Validation loss decreased (1.385466 --> 1.381003).  Saving model ...
Validation loss decreased (1.381003 --> 1.376685).  Saving model ...
Validation loss decreased (1.376685 --> 1.372677).  Saving model ...
Validation loss decreased (1.372677 --> 1.368552).  Saving model ...
Validation loss decreased (1.368552 --> 1.364422).  Saving model ...
Validation loss decreased (1.364422 --> 1.360412).  Saving model ...
Validation loss decreased (1.360412 --> 1.356103).  Saving model ...
Validation loss decreased (1.356103 --> 1.351606).  Saving model ...
Validation loss decreased (1.351606 --> 1.346939).  Saving model ...
Validation loss decreased (1.346939 --> 1.342703).  Saving model ...
Validation loss decreased (1.342703 --> 1.338000).  Saving model ...
Validation loss decreased (1.338000 --> 1.332952).  Saving model ...
Validation loss decreased (1.332952 --> 1.327782).  Saving model ...
Validation loss decreased (1.327782 --> 1.322700).  Saving model ...
Validation loss decreased (1.322700 --> 1.317383).  Saving model ...
Validation loss decreased (1.317383 --> 1.311448).  Saving model ...
Validation loss decreased (1.311448 --> 1.304437).  Saving model ...
Validation loss decreased (1.304437 --> 1.297288).  Saving model ...
Validation loss decreased (1.297288 --> 1.290844).  Saving model ...
Validation loss decreased (1.290844 --> 1.284356).  Saving model ...
Validation loss decreased (1.284356 --> 1.277528).  Saving model ...
Validation loss decreased (1.277528 --> 1.270408).  Saving model ...
Validation loss decreased (1.270408 --> 1.263148).  Saving model ...
Validation loss decreased (1.263148 --> 1.256066).  Saving model ...
Validation loss decreased (1.256066 --> 1.248796).  Saving model ...
Validation loss decreased (1.248796 --> 1.240918).  Saving model ...
Validation loss decreased (1.240918 --> 1.232565).  Saving model ...
Validation loss decreased (1.232565 --> 1.224180).  Saving model ...
Validation loss decreased (1.224180 --> 1.215714).  Saving model ...
Validation loss decreased (1.215714 --> 1.206998).  Saving model ...
Validation loss decreased (1.206998 --> 1.198169).  Saving model ...
Validation loss decreased (1.198169 --> 1.188584).  Saving model ...
Validation loss decreased (1.188584 --> 1.179612).  Saving model ...
Validation loss decreased (1.179612 --> 1.171588).  Saving model ...
Validation loss decreased (1.171588 --> 1.163815).  Saving model ...
Validation loss decreased (1.163815 --> 1.155460).  Saving model ...
Validation loss decreased (1.155460 --> 1.148117).  Saving model ...
Validation loss decreased (1.148117 --> 1.140436).  Saving model ...
Validation loss decreased (1.140436 --> 1.132887).  Saving model ...
Validation loss decreased (1.132887 --> 1.126300).  Saving model ...
Validation loss decreased (1.126300 --> 1.118941).  Saving model ...
Validation loss decreased (1.118941 --> 1.113340).  Saving model ...
Validation loss decreased (1.113340 --> 1.107076).  Saving model ...
Validation loss decreased (1.107076 --> 1.100626).  Saving model ...
Validation loss decreased (1.100626 --> 1.095018).  Saving model ...
Validation loss decreased (1.095018 --> 1.088249).  Saving model ...
Validation loss decreased (1.088249 --> 1.082227).  Saving model ...
Validation loss decreased (1.082227 --> 1.076892).  Saving model ...
Validation loss decreased (1.076892 --> 1.072616).  Saving model ...
Validation loss decreased (1.072616 --> 1.068948).  Saving model ...
Validation loss decreased (1.068948 --> 1.063414).  Saving model ...
Validation loss decreased (1.063414 --> 1.059457).  Saving model ...
Validation loss decreased (1.059457 --> 1.055090).  Saving model ...
Validation loss decreased (1.055090 --> 1.051474).  Saving model ...
Validation loss decreased (1.051474 --> 1.046875).  Saving model ...
Validation loss decreased (1.046875 --> 1.041512).  Saving model ...
Validation loss decreased (1.041512 --> 1.037802).  Saving model ...
Validation loss decreased (1.037802 --> 1.033936).  Saving model ...
Validation loss decreased (1.033936 --> 1.029782).  Saving model ...
Validation loss decreased (1.029782 --> 1.027334).  Saving model ...
Validation loss decreased (1.027334 --> 1.023898).  Saving model ...
Validation loss decreased (1.023898 --> 1.020425).  Saving model ...
Validation loss decreased (1.020425 --> 1.016720).  Saving model ...
Validation loss decreased (1.016720 --> 1.013791).  Saving model ...
Validation loss decreased (1.013791 --> 1.011397).  Saving model ...
Validation loss decreased (1.011397 --> 1.007624).  Saving model ...
Validation loss decreased (1.007624 --> 1.004667).  Saving model ...
Validation loss decreased (1.004667 --> 1.002760).  Saving model ...
Validation loss decreased (1.002760 --> 0.999652).  Saving model ...
Validation loss decreased (0.999652 --> 0.997459).  Saving model ...
Validation loss decreased (0.997459 --> 0.995202).  Saving model ...
Validation loss decreased (0.995202 --> 0.992607).  Saving model ...
Validation loss decreased (0.992607 --> 0.990353).  Saving model ...
Validation loss decreased (0.990353 --> 0.987219).  Saving model ...
Validation loss decreased (0.987219 --> 0.984672).  Saving model ...
Validation loss decreased (0.984672 --> 0.982762).  Saving model ...
Validation loss decreased (0.982762 --> 0.980501).  Saving model ...
Validation loss decreased (0.980501 --> 0.978687).  Saving model ...
Validation loss decreased (0.978687 --> 0.975213).  Saving model ...
Validation loss decreased (0.975213 --> 0.972546).  Saving model ...
Validation loss decreased (0.972546 --> 0.971977).  Saving model ...
Validation loss decreased (0.971977 --> 0.970269).  Saving model ...
Validation loss decreased (0.970269 --> 0.967533).  Saving model ...
Validation loss decreased (0.967533 --> 0.966026).  Saving model ...
Validation loss decreased (0.966026 --> 0.965624).  Saving model ...
Validation loss decreased (0.965624 --> 0.965334).  Saving model ...
Validation loss decreased (0.965334 --> 0.964064).  Saving model ...
Validation loss decreased (0.964064 --> 0.961584).  Saving model ...
Validation loss decreased (0.961584 --> 0.960690).  Saving model ...
Validation loss decreased (0.960690 --> 0.958765).  Saving model ...
Validation loss decreased (0.958765 --> 0.958695).  Saving model ...
Validation loss decreased (0.958695 --> 0.956444).  Saving model ...
Validation loss decreased (0.956444 --> 0.954946).  Saving model ...
Validation loss decreased (0.954946 --> 0.954547).  Saving model ...
Validation loss decreased (0.954547 --> 0.953366).  Saving model ...
Validation loss decreased (0.953366 --> 0.950928).  Saving model ...
EarlyStopping counter: 1 out of 5.0
EarlyStopping counter: 2 out of 5.0
EarlyStopping counter: 3 out of 5.0
EarlyStopping counter: 4 out of 5.0
Validation loss decreased (0.950928 --> 0.950657).  Saving model ...
Validation loss decreased (0.950657 --> 0.948471).  Saving model ...
EarlyStopping counter: 1 out of 5.0
Validation loss decreased (0.948471 --> 0.948075).  Saving model ...
Validation loss decreased (0.948075 --> 0.947320).  Saving model ...
EarlyStopping counter: 1 out of 5.0
Validation loss decreased (0.947320 --> 0.945256).  Saving model ...
EarlyStopping counter: 1 out of 5.0
EarlyStopping counter: 2 out of 5.0
EarlyStopping counter: 3 out of 5.0
EarlyStopping counter: 4 out of 5.0
Validation loss decreased (0.945256 --> 0.945029).  Saving model ...
Validation loss decreased (0.945029 --> 0.942917).  Saving model ...
EarlyStopping counter: 1 out of 5.0
EarlyStopping counter: 2 out of 5.0
EarlyStopping counter: 3 out of 5.0
Validation loss decreased (0.942917 --> 0.942000).  Saving model ...
Validation loss decreased (0.942000 --> 0.941830).  Saving model ...
EarlyStopping counter: 1 out of 5.0
EarlyStopping counter: 2 out of 5.0
EarlyStopping counter: 3 out of 5.0
EarlyStopping counter: 4 out of 5.0
EarlyStopping counter: 5 out of 5.0
/localscratch/yinan.29351704.0/env/lib/python3.7/site-packages/torch/nn/functional.py:1794: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.
  warnings.warn("nn.functional.tanh is deprecated. Use torch.tanh instead.")
wandb: Waiting for W&B process to finish, PID 110706... (success).
wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: \ 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: | 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: / 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: \ 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: | 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: / 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: \ 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: | 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: / 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb:                                                                                
wandb: Run history:
wandb:     e_F1 ▁▂▃▃▄▅▅▅▆▆▆▆▆▇▇▇▇▇▇▇▇▇██▇▇██████████████
wandb:   e_loss ███▇▇▇▇▆▆▆▅▅▄▄▄▃▃▃▃▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:     t_F1 ▁▁▂▂▂▃▃▃▄▄▅▅▅▅▅▆▆▆▆▆▆▇▆▇▇▇▇▇▇▇▇▇▇███▇███
wandb:   t_loss ████▇▇▇▇▇▆▆▅▅▅▅▅▄▄▄▄▄▃▃▃▃▂▂▂▂▂▂▂▂▂▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:     e_F1 60.26514
wandb:   e_loss 0.94402
wandb:     t_F1 71.35158
wandb:   t_loss 0.75007
wandb: 
wandb: Synced 4 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Synced electric-water-1: https://wandb.ai/yinanazhou/xl_512_bs_8_lr_1e06_es_5_lc_False_nr_False_sr_False_stem_False_lemma_True_repeat_5_fold_2/runs/30s3u1kg
wandb: Find logs at: ./wandb/run-20220327_212806-30s3u1kg/logs/debug.log
wandb: 

