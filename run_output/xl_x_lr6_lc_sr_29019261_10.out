Unloading StdEnv/2020

Due to MODULEPATH changes, the following have been reloaded:
  1) mii/1.1.1


The following have been reloaded with a version change:
  1) python/3.8.2 => python/3.7.4

Using base prefix '/cvmfs/soft.computecanada.ca/easybuild/software/2017/Core/python/3.7.4'
New python executable in /localscratch/yinan.29019261.0/env/bin/python
Installing setuptools, pip, wheel...
done.
Ignoring pip: markers 'python_version < "3"' don't match your environment
Looking in links: /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/nix/avx2, /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/nix/generic, /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic
Collecting pip
Installing collected packages: pip
  Found existing installation: pip 19.1.1
    Uninstalling pip-19.1.1:
      Successfully uninstalled pip-19.1.1
Successfully installed pip-21.2.3+computecanada
Looking in links: /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/nix/avx2, /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/nix/generic, /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/keras-2.8.0+computecanada-py2.py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/Keras_Preprocessing-1.1.2+computecanada-py3-none-any.whl
Requirement already satisfied: matplotlib in /cvmfs/soft.computecanada.ca/easybuild/software/2017/Core/scipy-stack/2019a/lib/python3.7/site-packages (from -r requirements.txt (line 3)) (3.0.2)
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/nltk-3.6.5+computecanada-py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/scikit_learn-0.22.1+computecanada-cp37-cp37m-linux_x86_64.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/tensorboard-2.3.0+computecanada-py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/tensorboard_plugin_wit-1.7.0+computecanada-py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/tensorflow_gpu-2.3.0+computecanada-cp37-cp37m-linux_x86_64.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/tensorflow_estimator-2.3.0+computecanada-py2.py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/tokenizers-0.5.2+computecanada-cp37-cp37m-linux_x86_64.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/nix/avx2/torch-1.4.0+computecanada-cp37-cp37m-linux_x86_64.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/torchtext-0.6.0+computecanada-py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/torchvision-0.8.2+computecanada-cp37-cp37m-linux_x86_64.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/transformers-2.5.1+computecanada-py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/urllib3-1.26.7+computecanada-py2.py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/tqdm-4.63.0+computecanada-py2.py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/joblib-1.1.0+computecanada-py2.py3-none-any.whl
ERROR: Could not find a version that satisfies the requirement regex>=2021.8.3 (from nltk) (from versions: 2018.1.10+computecanada, 2019.11.1+computecanada, 2020.11.13+computecanada)
ERROR: No matching distribution found for regex>=2021.8.3
Looking in links: /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/nix/avx2, /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/nix/generic, /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic
ERROR: Could not find a version that satisfies the requirement numpy==1.20.0+computacanada (from versions: 1.15.0+computecanada, 1.15.2+computecanada, 1.15.4+computecanada, 1.16.0+computecanada, 1.16.2+computecanada, 1.16.3+computecanada, 1.17.4+computecanada, 1.18.1+computecanada, 1.18.4+computecanada, 1.19.1+computecanada, 1.19.2+computecanada, 1.20.2+computecanada)
ERROR: No matching distribution found for numpy==1.20.0+computacanada
Looking in links: /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/nix/avx2, /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/nix/generic, /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/wandb-0.12.5+computecanada-py2.py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/yaspin-2.1.0+computecanada-py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/configparser-5.0.2+computecanada-py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/protobuf-3.19.4+computecanada-py2.py3-none-any.whl
Requirement already satisfied: requests<3,>=2.0.0 in /cvmfs/soft.computecanada.ca/easybuild/software/2017/Core/scipy-stack/2019a/lib/python3.7/site-packages (from wandb) (2.21.0)
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/click-8.0.4+computecanada-py3-none-any.whl
Requirement already satisfied: python-dateutil>=2.6.1 in /cvmfs/soft.computecanada.ca/easybuild/software/2017/Core/scipy-stack/2019a/lib/python3.7/site-packages (from wandb) (2.7.5)
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/psutil-5.7.3+computecanada-cp37-cp37m-linux_x86_64.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/subprocess32-3.5.4+computecanada-py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/six-1.16.0+computecanada-py2.py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/docker_pycreds-0.4.0+computecanada-py2.py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/GitPython-3.1.24+computecanada-py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/shortuuid-1.0.1+computecanada-py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/sentry_sdk-1.5.0+computecanada-py2.py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/promise-2.3+computecanada-py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/PyYAML-5.3.1+computecanada-cp37-cp37m-linux_x86_64.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/pathtools-0.1.2+computecanada-py3-none-any.whl
Requirement already satisfied: importlib-metadata in /cvmfs/soft.computecanada.ca/easybuild/software/2017/Core/scipy-stack/2019a/lib/python3.7/site-packages (from Click!=8.0.0,>=7.0->wandb) (0.8)
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/gitdb-4.0.9+computecanada-py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/typing_extensions-4.0.1+computecanada-py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/smmap-5.0.0+computecanada-py3-none-any.whl
Requirement already satisfied: certifi>=2017.4.17 in /cvmfs/soft.computecanada.ca/easybuild/software/2017/Core/scipy-stack/2019a/lib/python3.7/site-packages (from requests<3,>=2.0.0->wandb) (2018.11.29)
Requirement already satisfied: idna<2.9,>=2.5 in /cvmfs/soft.computecanada.ca/easybuild/software/2017/Core/scipy-stack/2019a/lib/python3.7/site-packages (from requests<3,>=2.0.0->wandb) (2.8)
Requirement already satisfied: urllib3<1.25,>=1.21.1 in /cvmfs/soft.computecanada.ca/easybuild/software/2017/Core/scipy-stack/2019a/lib/python3.7/site-packages (from requests<3,>=2.0.0->wandb) (1.24.1)
Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /cvmfs/soft.computecanada.ca/easybuild/software/2017/Core/scipy-stack/2019a/lib/python3.7/site-packages (from requests<3,>=2.0.0->wandb) (3.0.4)
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/termcolor-1.1.0+computecanada-py3-none-any.whl
Requirement already satisfied: zipp>=0.3.2 in /cvmfs/soft.computecanada.ca/easybuild/software/2017/Core/scipy-stack/2019a/lib/python3.7/site-packages (from importlib-metadata->Click!=8.0.0,>=7.0->wandb) (0.3.3)
Installing collected packages: smmap, typing-extensions, termcolor, six, gitdb, yaspin, subprocess32, shortuuid, sentry-sdk, PyYAML, psutil, protobuf, promise, pathtools, GitPython, docker-pycreds, configparser, Click, wandb
  Attempting uninstall: six
    Found existing installation: six 1.12.0
    Not uninstalling six at /cvmfs/soft.computecanada.ca/easybuild/software/2017/Core/scipy-stack/2019a/lib/python3.7/site-packages, outside environment /localscratch/yinan.29019261.0/env
    Can't uninstall 'six'. No files were found to uninstall.
Successfully installed Click-8.0.4+computecanada GitPython-3.1.24+computecanada PyYAML-5.3.1+computecanada configparser-5.0.2+computecanada docker-pycreds-0.4.0+computecanada gitdb-4.0.9+computecanada pathtools-0.1.2+computecanada promise-2.3+computecanada protobuf-3.19.4+computecanada psutil-5.7.3+computecanada sentry-sdk-1.5.0+computecanada shortuuid-1.0.1+computecanada six-1.16.0+computecanada smmap-5.0.0+computecanada subprocess32-3.5.4+computecanada termcolor-1.1.0+computecanada typing-extensions-4.0.1+computecanada wandb-0.12.5+computecanada yaspin-2.1.0+computecanada
Looking in links: /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/nix/avx2, /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/nix/generic, /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic
ERROR: Could not find a version that satisfies the requirement sagemaker (from versions: none)
ERROR: No matching distribution found for sagemaker
Looking in links: /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/nix/avx2, /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/nix/generic, /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/torch-1.9.1+computecanada-cp37-cp37m-linux_x86_64.whl
Requirement already satisfied: typing-extensions in /localscratch/yinan.29019261.0/env/lib/python3.7/site-packages (from torch) (4.0.1+computecanada)
Installing collected packages: torch
Successfully installed torch-1.9.1+computecanada
Looking in links: /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/nix/avx2, /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/nix/generic, /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/transformers-2.5.1+computecanada-py3-none-any.whl
Requirement already satisfied: numpy in /cvmfs/soft.computecanada.ca/easybuild/software/2017/Core/scipy-stack/2019a/lib/python3.7/site-packages (from transformers==2.5.1+computecanada) (1.16.0)
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/sacremoses-0.0.46+computecanada-py3-none-any.whl
Requirement already satisfied: requests in /cvmfs/soft.computecanada.ca/easybuild/software/2017/Core/scipy-stack/2019a/lib/python3.7/site-packages (from transformers==2.5.1+computecanada) (2.21.0)
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/regex-2020.11.13+computecanada-cp37-cp37m-linux_x86_64.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/boto3-1.21.14+computecanada-py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/filelock-3.4.2+computecanada-py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/tqdm-4.63.0+computecanada-py2.py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/sentencepiece-0.1.91+computecanada-cp37-cp37m-linux_x86_64.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/tokenizers-0.5.2+computecanada-cp37-cp37m-linux_x86_64.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/botocore-1.24.14+computecanada-py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/s3transfer-0.5.1+computecanada-py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/jmespath-0.10.0+computecanada-py2.py3-none-any.whl
Requirement already satisfied: python-dateutil<3.0.0,>=2.1 in /cvmfs/soft.computecanada.ca/easybuild/software/2017/Core/scipy-stack/2019a/lib/python3.7/site-packages (from botocore<1.25.0,>=1.24.14->boto3->transformers==2.5.1+computecanada) (2.7.5)
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/urllib3-1.26.8+computecanada-py2.py3-none-any.whl
Requirement already satisfied: six>=1.5 in /localscratch/yinan.29019261.0/env/lib/python3.7/site-packages (from python-dateutil<3.0.0,>=2.1->botocore<1.25.0,>=1.24.14->boto3->transformers==2.5.1+computecanada) (1.16.0+computecanada)
Requirement already satisfied: idna<2.9,>=2.5 in /cvmfs/soft.computecanada.ca/easybuild/software/2017/Core/scipy-stack/2019a/lib/python3.7/site-packages (from requests->transformers==2.5.1+computecanada) (2.8)
Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /cvmfs/soft.computecanada.ca/easybuild/software/2017/Core/scipy-stack/2019a/lib/python3.7/site-packages (from requests->transformers==2.5.1+computecanada) (3.0.4)
Requirement already satisfied: certifi>=2017.4.17 in /cvmfs/soft.computecanada.ca/easybuild/software/2017/Core/scipy-stack/2019a/lib/python3.7/site-packages (from requests->transformers==2.5.1+computecanada) (2018.11.29)
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/requests-2.27.1+computecanada-py2.py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/charset_normalizer-2.0.12+computecanada-py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/joblib-1.1.0+computecanada-py2.py3-none-any.whl
Requirement already satisfied: click in /localscratch/yinan.29019261.0/env/lib/python3.7/site-packages (from sacremoses->transformers==2.5.1+computecanada) (8.0.4+computecanada)
Requirement already satisfied: importlib-metadata in /cvmfs/soft.computecanada.ca/easybuild/software/2017/Core/scipy-stack/2019a/lib/python3.7/site-packages (from click->sacremoses->transformers==2.5.1+computecanada) (0.8)
Requirement already satisfied: zipp>=0.3.2 in /cvmfs/soft.computecanada.ca/easybuild/software/2017/Core/scipy-stack/2019a/lib/python3.7/site-packages (from importlib-metadata->click->sacremoses->transformers==2.5.1+computecanada) (0.3.3)
Installing collected packages: urllib3, jmespath, botocore, tqdm, s3transfer, regex, joblib, charset-normalizer, tokenizers, sentencepiece, sacremoses, requests, filelock, boto3, transformers
  Attempting uninstall: urllib3
    Found existing installation: urllib3 1.24.1
    Not uninstalling urllib3 at /cvmfs/soft.computecanada.ca/easybuild/software/2017/Core/scipy-stack/2019a/lib/python3.7/site-packages, outside environment /localscratch/yinan.29019261.0/env
    Can't uninstall 'urllib3'. No files were found to uninstall.
  Attempting uninstall: requests
    Found existing installation: requests 2.21.0
    Not uninstalling requests at /cvmfs/soft.computecanada.ca/easybuild/software/2017/Core/scipy-stack/2019a/lib/python3.7/site-packages, outside environment /localscratch/yinan.29019261.0/env
    Can't uninstall 'requests'. No files were found to uninstall.
Successfully installed boto3-1.21.14+computecanada botocore-1.24.14+computecanada charset-normalizer-2.0.12+computecanada filelock-3.4.2+computecanada jmespath-0.10.0+computecanada joblib-1.1.0+computecanada regex-2020.11.13+computecanada requests-2.27.1+computecanada s3transfer-0.5.1+computecanada sacremoses-0.0.46+computecanada sentencepiece-0.1.91+computecanada tokenizers-0.5.2+computecanada tqdm-4.63.0+computecanada transformers-2.5.1+computecanada urllib3-1.26.8+computecanada
Looking in links: /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/nix/avx2, /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/nix/generic, /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/tensorflow_gpu-2.3.0+computecanada-cp37-cp37m-linux_x86_64.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/nix/avx2/h5py-2.10.0+computecanada-cp37-cp37m-linux_x86_64.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/Keras_Preprocessing-1.1.2+computecanada-py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/google_pasta-0.2.0+computecanada-py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/gast-0.3.3+computecanada-py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/opt_einsum-3.3.0+computecanada-py3-none-any.whl
Requirement already satisfied: termcolor>=1.1.0 in /localscratch/yinan.29019261.0/env/lib/python3.7/site-packages (from tensorflow_gpu==2.3.0+computecanada) (1.1.0+computecanada)
Requirement already satisfied: numpy<1.19.0,>=1.16.0 in /cvmfs/soft.computecanada.ca/easybuild/software/2017/Core/scipy-stack/2019a/lib/python3.7/site-packages (from tensorflow_gpu==2.3.0+computecanada) (1.16.0)
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/tensorboard-2.8.0+computecanada-py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/nix/generic/scipy-1.4.1+computecanada-cp37-cp37m-linux_x86_64.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/grpcio-1.38.0+computecanada-cp37-cp37m-linux_x86_64.whl
Requirement already satisfied: six>=1.12.0 in /localscratch/yinan.29019261.0/env/lib/python3.7/site-packages (from tensorflow_gpu==2.3.0+computecanada) (1.16.0+computecanada)
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/wrapt-1.11.2+computecanada-cp37-cp37m-linux_x86_64.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/absl_py-1.0.0+computecanada-py3-none-any.whl
Requirement already satisfied: wheel>=0.26 in /localscratch/yinan.29019261.0/env/lib/python3.7/site-packages (from tensorflow_gpu==2.3.0+computecanada) (0.33.4)
Requirement already satisfied: protobuf>=3.9.2 in /localscratch/yinan.29019261.0/env/lib/python3.7/site-packages (from tensorflow_gpu==2.3.0+computecanada) (3.19.4+computecanada)
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/tensorflow_estimator-2.3.0+computecanada-py2.py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/astunparse-1.6.3+computecanada-py2.py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/tensorboard_data_server-0.6.1+computecanada-py3-none-linux_x86_64.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/tensorboard_plugin_wit-1.8.0+computecanada-py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/Werkzeug-2.0.3+computecanada-py3-none-any.whl
Requirement already satisfied: setuptools>=41.0.0 in /localscratch/yinan.29019261.0/env/lib/python3.7/site-packages (from tensorboard<3,>=2.3.0->tensorflow_gpu==2.3.0+computecanada) (41.0.1)
Requirement already satisfied: requests<3,>=2.21.0 in /localscratch/yinan.29019261.0/env/lib/python3.7/site-packages (from tensorboard<3,>=2.3.0->tensorflow_gpu==2.3.0+computecanada) (2.27.1+computecanada)
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/google_auth_oauthlib-0.4.6+computecanada-py2.py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/Markdown-3.3.6+computecanada-py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/google_auth-2.3.3+computecanada-py2.py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/pyasn1_modules-0.2.8+computecanada-py2.py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/cachetools-4.2.4+computecanada-py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/rsa-4.8+computecanada-py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/requests_oauthlib-1.3.0+computecanada-py2.py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/importlib_metadata-4.10.1+computecanada-py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/zipp-3.7.0+computecanada-py3-none-any.whl
Requirement already satisfied: typing-extensions>=3.6.4 in /localscratch/yinan.29019261.0/env/lib/python3.7/site-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard<3,>=2.3.0->tensorflow_gpu==2.3.0+computecanada) (4.0.1+computecanada)
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/pyasn1-0.4.8+computecanada-py2.py3-none-any.whl
Requirement already satisfied: certifi>=2017.4.17 in /cvmfs/soft.computecanada.ca/easybuild/software/2017/Core/scipy-stack/2019a/lib/python3.7/site-packages (from requests<3,>=2.21.0->tensorboard<3,>=2.3.0->tensorflow_gpu==2.3.0+computecanada) (2018.11.29)
Requirement already satisfied: charset-normalizer~=2.0.0 in /localscratch/yinan.29019261.0/env/lib/python3.7/site-packages (from requests<3,>=2.21.0->tensorboard<3,>=2.3.0->tensorflow_gpu==2.3.0+computecanada) (2.0.12+computecanada)
Requirement already satisfied: urllib3<1.27,>=1.21.1 in /localscratch/yinan.29019261.0/env/lib/python3.7/site-packages (from requests<3,>=2.21.0->tensorboard<3,>=2.3.0->tensorflow_gpu==2.3.0+computecanada) (1.26.8+computecanada)
Requirement already satisfied: idna<4,>=2.5 in /cvmfs/soft.computecanada.ca/easybuild/software/2017/Core/scipy-stack/2019a/lib/python3.7/site-packages (from requests<3,>=2.21.0->tensorboard<3,>=2.3.0->tensorflow_gpu==2.3.0+computecanada) (2.8)
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/oauthlib-3.1.1+computecanada-py2.py3-none-any.whl
Installing collected packages: pyasn1, zipp, rsa, pyasn1-modules, oauthlib, cachetools, requests-oauthlib, importlib-metadata, google-auth, werkzeug, tensorboard-plugin-wit, tensorboard-data-server, markdown, grpcio, google-auth-oauthlib, absl-py, wrapt, tensorflow-estimator, tensorboard, scipy, opt-einsum, keras-preprocessing, h5py, google-pasta, gast, astunparse, tensorflow-gpu
  Attempting uninstall: pyasn1
    Found existing installation: pyasn1 0.4.3
    Not uninstalling pyasn1 at /cvmfs/soft.computecanada.ca/easybuild/software/2017/Core/scipy-stack/2019a/lib/python3.7/site-packages, outside environment /localscratch/yinan.29019261.0/env
    Can't uninstall 'pyasn1'. No files were found to uninstall.
  Attempting uninstall: zipp
    Found existing installation: zipp 0.3.3
    Not uninstalling zipp at /cvmfs/soft.computecanada.ca/easybuild/software/2017/Core/scipy-stack/2019a/lib/python3.7/site-packages, outside environment /localscratch/yinan.29019261.0/env
    Can't uninstall 'zipp'. No files were found to uninstall.
  Attempting uninstall: importlib-metadata
    Found existing installation: importlib-metadata 0.8
    Not uninstalling importlib-metadata at /cvmfs/soft.computecanada.ca/easybuild/software/2017/Core/scipy-stack/2019a/lib/python3.7/site-packages, outside environment /localscratch/yinan.29019261.0/env
    Can't uninstall 'importlib-metadata'. No files were found to uninstall.
  Attempting uninstall: scipy
    Found existing installation: scipy 1.2.0
    Not uninstalling scipy at /cvmfs/soft.computecanada.ca/easybuild/software/2017/Core/scipy-stack/2019a/lib/python3.7/site-packages, outside environment /localscratch/yinan.29019261.0/env
    Can't uninstall 'scipy'. No files were found to uninstall.
Successfully installed absl-py-1.0.0+computecanada astunparse-1.6.3+computecanada cachetools-4.2.4+computecanada gast-0.3.3+computecanada google-auth-2.3.3+computecanada google-auth-oauthlib-0.4.6+computecanada google-pasta-0.2.0+computecanada grpcio-1.38.0+computecanada h5py-2.10.0+computecanada importlib-metadata-4.10.1+computecanada keras-preprocessing-1.1.2+computecanada markdown-3.3.6+computecanada oauthlib-3.1.1+computecanada opt-einsum-3.3.0+computecanada pyasn1-0.4.8+computecanada pyasn1-modules-0.2.8+computecanada requests-oauthlib-1.3.0+computecanada rsa-4.8+computecanada scipy-1.4.1+computecanada tensorboard-2.8.0+computecanada tensorboard-data-server-0.6.1+computecanada tensorboard-plugin-wit-1.8.0+computecanada tensorflow-estimator-2.3.0+computecanada tensorflow-gpu-2.3.0+computecanada werkzeug-2.0.3+computecanada wrapt-1.11.2+computecanada zipp-3.7.0+computecanada
Looking in links: /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/nix/avx2, /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/nix/generic, /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/keras-2.8.0+computecanada-py2.py3-none-any.whl
Installing collected packages: Keras
Successfully installed Keras-2.8.0+computecanada
Looking in links: /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/nix/avx2, /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/nix/generic, /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/urllib3-1.26.7+computecanada-py2.py3-none-any.whl
Installing collected packages: urllib3
  Attempting uninstall: urllib3
    Found existing installation: urllib3 1.26.8+computecanada
    Uninstalling urllib3-1.26.8+computecanada:
      Successfully uninstalled urllib3-1.26.8+computecanada
Successfully installed urllib3-1.26.7+computecanada
Looking in links: /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/nix/avx2, /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/nix/generic, /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/nltk-3.7+computecanada-py3-none-any.whl
Requirement already satisfied: tqdm in /localscratch/yinan.29019261.0/env/lib/python3.7/site-packages (from nltk) (4.63.0+computecanada)
Requirement already satisfied: click in /localscratch/yinan.29019261.0/env/lib/python3.7/site-packages (from nltk) (8.0.4+computecanada)
Requirement already satisfied: joblib in /localscratch/yinan.29019261.0/env/lib/python3.7/site-packages (from nltk) (1.1.0+computecanada)
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/nltk-3.6.5+computecanada-py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/nltk-3.6.3+computecanada-py3-none-any.whl
Requirement already satisfied: regex in /localscratch/yinan.29019261.0/env/lib/python3.7/site-packages (from nltk) (2020.11.13+computecanada)
Requirement already satisfied: importlib-metadata in /localscratch/yinan.29019261.0/env/lib/python3.7/site-packages (from click->nltk) (4.10.1+computecanada)
Requirement already satisfied: zipp>=0.5 in /localscratch/yinan.29019261.0/env/lib/python3.7/site-packages (from importlib-metadata->click->nltk) (3.7.0+computecanada)
Requirement already satisfied: typing-extensions>=3.6.4 in /localscratch/yinan.29019261.0/env/lib/python3.7/site-packages (from importlib-metadata->click->nltk) (4.0.1+computecanada)
Installing collected packages: nltk
Successfully installed nltk-3.6.3+computecanada
Looking in links: /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/nix/avx2, /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/nix/generic, /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/scikit_learn-0.22.1+computecanada-cp37-cp37m-linux_x86_64.whl
Requirement already satisfied: joblib>=0.11 in /localscratch/yinan.29019261.0/env/lib/python3.7/site-packages (from scikit-learn==0.22.1) (1.1.0+computecanada)
Requirement already satisfied: scipy>=0.17.0 in /localscratch/yinan.29019261.0/env/lib/python3.7/site-packages (from scikit-learn==0.22.1) (1.4.1+computecanada)
Requirement already satisfied: numpy>=1.11.0 in /cvmfs/soft.computecanada.ca/easybuild/software/2017/Core/scipy-stack/2019a/lib/python3.7/site-packages (from scikit-learn==0.22.1) (1.16.0)
Installing collected packages: scikit-learn
Successfully installed scikit-learn-0.22.1+computecanada
Looking in links: /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/nix/avx2, /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/nix/generic, /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic
Requirement already satisfied: tokenizers==0.5.2 in /localscratch/yinan.29019261.0/env/lib/python3.7/site-packages (0.5.2+computecanada)
wandb: Appending key for api.wandb.ai to your netrc file: /home/yinan/.netrc
Starting Task
2022-03-17 05:35:51.014756: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1
[nltk_data] Downloading package stopwords to /home/yinan/nltk_data...
[nltk_data]   Package stopwords is already up-to-date!
[nltk_data] Downloading package wordnet to /home/yinan/nltk_data...
[nltk_data]   Package wordnet is already up-to-date!
wandb: Currently logged in as: yinanazhou (use `wandb login --relogin` to force relogin)
wandb: wandb version 0.12.11 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
2022-03-17 05:36:01.887672: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1
wandb: Tracking run with wandb version 0.12.5
wandb: Syncing run dashing-wind-2
wandb: ⭐️ View project at https://wandb.ai/yinanazhou/xl_512_bs_8_lr_1e06_es_10_lc_True_nr_False_sr_True_stem_False_lemma_False_repeat_1_fold_1
wandb: 🚀 View run at https://wandb.ai/yinanazhou/xl_512_bs_8_lr_1e06_es_10_lc_True_nr_False_sr_True_stem_False_lemma_False_repeat_1_fold_1/runs/1343j7le
wandb: Run data is saved locally in /project/6002780/yinan/Thesis_MER_Lyrics/lyric-emotion/wandb/run-20220317_053600-1343j7le
wandb: Run `wandb offline` to turn off syncing.

Validation loss decreased (inf --> 1.438751).  Saving model ...
Validation loss decreased (1.438751 --> 1.418951).  Saving model ...
Validation loss decreased (1.418951 --> 1.403289).  Saving model ...
Validation loss decreased (1.403289 --> 1.389923).  Saving model ...
Validation loss decreased (1.389923 --> 1.379769).  Saving model ...
Validation loss decreased (1.379769 --> 1.370931).  Saving model ...
Validation loss decreased (1.370931 --> 1.363271).  Saving model ...
Validation loss decreased (1.363271 --> 1.356312).  Saving model ...
Validation loss decreased (1.356312 --> 1.349979).  Saving model ...
Validation loss decreased (1.349979 --> 1.343323).  Saving model ...
Validation loss decreased (1.343323 --> 1.336362).  Saving model ...
Validation loss decreased (1.336362 --> 1.330191).  Saving model ...
Validation loss decreased (1.330191 --> 1.323821).  Saving model ...
Validation loss decreased (1.323821 --> 1.317705).  Saving model ...
Validation loss decreased (1.317705 --> 1.311222).  Saving model ...
Validation loss decreased (1.311222 --> 1.304461).  Saving model ...
Validation loss decreased (1.304461 --> 1.297779).  Saving model ...
Validation loss decreased (1.297779 --> 1.290949).  Saving model ...
Validation loss decreased (1.290949 --> 1.283989).  Saving model ...
Validation loss decreased (1.283989 --> 1.277859).  Saving model ...
Validation loss decreased (1.277859 --> 1.271250).  Saving model ...
Validation loss decreased (1.271250 --> 1.263335).  Saving model ...
Validation loss decreased (1.263335 --> 1.256937).  Saving model ...
Validation loss decreased (1.256937 --> 1.249202).  Saving model ...
Validation loss decreased (1.249202 --> 1.243923).  Saving model ...
Validation loss decreased (1.243923 --> 1.236385).  Saving model ...
Validation loss decreased (1.236385 --> 1.229786).  Saving model ...
Validation loss decreased (1.229786 --> 1.225042).  Saving model ...
Validation loss decreased (1.225042 --> 1.220232).  Saving model ...
Validation loss decreased (1.220232 --> 1.215213).  Saving model ...
Validation loss decreased (1.215213 --> 1.209694).  Saving model ...
Validation loss decreased (1.209694 --> 1.204692).  Saving model ...
Validation loss decreased (1.204692 --> 1.200113).  Saving model ...
Validation loss decreased (1.200113 --> 1.193838).  Saving model ...
Validation loss decreased (1.193838 --> 1.190156).  Saving model ...
Validation loss decreased (1.190156 --> 1.185947).  Saving model ...
Validation loss decreased (1.185947 --> 1.181116).  Saving model ...
Validation loss decreased (1.181116 --> 1.176395).  Saving model ...
Validation loss decreased (1.176395 --> 1.173479).  Saving model ...
Validation loss decreased (1.173479 --> 1.171065).  Saving model ...
Validation loss decreased (1.171065 --> 1.164059).  Saving model ...
Validation loss decreased (1.164059 --> 1.159869).  Saving model ...
Validation loss decreased (1.159869 --> 1.158189).  Saving model ...
Validation loss decreased (1.158189 --> 1.153697).  Saving model ...
Validation loss decreased (1.153697 --> 1.149670).  Saving model ...
Validation loss decreased (1.149670 --> 1.143968).  Saving model ...
Validation loss decreased (1.143968 --> 1.140727).  Saving model ...
Validation loss decreased (1.140727 --> 1.139116).  Saving model ...
Validation loss decreased (1.139116 --> 1.132226).  Saving model ...
Validation loss decreased (1.132226 --> 1.127853).  Saving model ...
Validation loss decreased (1.127853 --> 1.123505).  Saving model ...
Validation loss decreased (1.123505 --> 1.119249).  Saving model ...
Validation loss decreased (1.119249 --> 1.117118).  Saving model ...
Validation loss decreased (1.117118 --> 1.115362).  Saving model ...
Validation loss decreased (1.115362 --> 1.113534).  Saving model ...
Validation loss decreased (1.113534 --> 1.107802).  Saving model ...
Validation loss decreased (1.107802 --> 1.105366).  Saving model ...
Validation loss decreased (1.105366 --> 1.101634).  Saving model ...
Validation loss decreased (1.101634 --> 1.096751).  Saving model ...
Validation loss decreased (1.096751 --> 1.095560).  Saving model ...
Validation loss decreased (1.095560 --> 1.090876).  Saving model ...
Validation loss decreased (1.090876 --> 1.087604).  Saving model ...
Validation loss decreased (1.087604 --> 1.083187).  Saving model ...
Validation loss decreased (1.083187 --> 1.081971).  Saving model ...
Validation loss decreased (1.081971 --> 1.081882).  Saving model ...
Validation loss decreased (1.081882 --> 1.075714).  Saving model ...
EarlyStopping counter: 1 out of 10.0
Validation loss decreased (1.075714 --> 1.069536).  Saving model ...
Validation loss decreased (1.069536 --> 1.067538).  Saving model ...
Validation loss decreased (1.067538 --> 1.065469).  Saving model ...
Validation loss decreased (1.065469 --> 1.061253).  Saving model ...
Validation loss decreased (1.061253 --> 1.059912).  Saving model ...
Validation loss decreased (1.059912 --> 1.057221).  Saving model ...
Validation loss decreased (1.057221 --> 1.055016).  Saving model ...
Validation loss decreased (1.055016 --> 1.051605).  Saving model ...
Validation loss decreased (1.051605 --> 1.048695).  Saving model ...
Validation loss decreased (1.048695 --> 1.048339).  Saving model ...
Validation loss decreased (1.048339 --> 1.047874).  Saving model ...
Validation loss decreased (1.047874 --> 1.042140).  Saving model ...
Validation loss decreased (1.042140 --> 1.038831).  Saving model ...
Validation loss decreased (1.038831 --> 1.037597).  Saving model ...
EarlyStopping counter: 1 out of 10.0
Validation loss decreased (1.037597 --> 1.036116).  Saving model ...
Validation loss decreased (1.036116 --> 1.035876).  Saving model ...
Validation loss decreased (1.035876 --> 1.031280).  Saving model ...
Validation loss decreased (1.031280 --> 1.030312).  Saving model ...
Validation loss decreased (1.030312 --> 1.027784).  Saving model ...
Validation loss decreased (1.027784 --> 1.027054).  Saving model ...
Validation loss decreased (1.027054 --> 1.023174).  Saving model ...
Validation loss decreased (1.023174 --> 1.021052).  Saving model ...
Validation loss decreased (1.021052 --> 1.020149).  Saving model ...
Validation loss decreased (1.020149 --> 1.018719).  Saving model ...
Validation loss decreased (1.018719 --> 1.018044).  Saving model ...
EarlyStopping counter: 1 out of 10.0
Validation loss decreased (1.018044 --> 1.017023).  Saving model ...
Validation loss decreased (1.017023 --> 1.015802).  Saving model ...
Validation loss decreased (1.015802 --> 1.013845).  Saving model ...
Validation loss decreased (1.013845 --> 1.011273).  Saving model ...
Validation loss decreased (1.011273 --> 1.009174).  Saving model ...
Validation loss decreased (1.009174 --> 1.009171).  Saving model ...
Validation loss decreased (1.009171 --> 1.007543).  Saving model ...
EarlyStopping counter: 1 out of 10.0
Validation loss decreased (1.007543 --> 1.006352).  Saving model ...
Validation loss decreased (1.006352 --> 1.004243).  Saving model ...
Validation loss decreased (1.004243 --> 1.003232).  Saving model ...
Validation loss decreased (1.003232 --> 0.998866).  Saving model ...
Validation loss decreased (0.998866 --> 0.998735).  Saving model ...
Validation loss decreased (0.998735 --> 0.997981).  Saving model ...
Validation loss decreased (0.997981 --> 0.996418).  Saving model ...
Validation loss decreased (0.996418 --> 0.995420).  Saving model ...
EarlyStopping counter: 1 out of 10.0
EarlyStopping counter: 2 out of 10.0
EarlyStopping counter: 3 out of 10.0
Validation loss decreased (0.995420 --> 0.994424).  Saving model ...
EarlyStopping counter: 1 out of 10.0
Validation loss decreased (0.994424 --> 0.992114).  Saving model ...
Validation loss decreased (0.992114 --> 0.989436).  Saving model ...
Validation loss decreased (0.989436 --> 0.989183).  Saving model ...
EarlyStopping counter: 1 out of 10.0
Validation loss decreased (0.989183 --> 0.987726).  Saving model ...
Validation loss decreased (0.987726 --> 0.987347).  Saving model ...
EarlyStopping counter: 1 out of 10.0
Validation loss decreased (0.987347 --> 0.983901).  Saving model ...
EarlyStopping counter: 1 out of 10.0
Validation loss decreased (0.983901 --> 0.983594).  Saving model ...
EarlyStopping counter: 1 out of 10.0
EarlyStopping counter: 2 out of 10.0
Validation loss decreased (0.983594 --> 0.983022).  Saving model ...
EarlyStopping counter: 1 out of 10.0
EarlyStopping counter: 2 out of 10.0
EarlyStopping counter: 3 out of 10.0
EarlyStopping counter: 4 out of 10.0
EarlyStopping counter: 5 out of 10.0
EarlyStopping counter: 6 out of 10.0
EarlyStopping counter: 7 out of 10.0
EarlyStopping counter: 8 out of 10.0
Validation loss decreased (0.983022 --> 0.982539).  Saving model ...
Validation loss decreased (0.982539 --> 0.979610).  Saving model ...
EarlyStopping counter: 1 out of 10.0
Validation loss decreased (0.979610 --> 0.978536).  Saving model ...
EarlyStopping counter: 1 out of 10.0
EarlyStopping counter: 2 out of 10.0
EarlyStopping counter: 3 out of 10.0
EarlyStopping counter: 4 out of 10.0
EarlyStopping counter: 5 out of 10.0
EarlyStopping counter: 6 out of 10.0
EarlyStopping counter: 7 out of 10.0
EarlyStopping counter: 8 out of 10.0
EarlyStopping counter: 9 out of 10.0
EarlyStopping counter: 10 out of 10.0
/localscratch/yinan.29019261.0/env/lib/python3.7/site-packages/torch/nn/functional.py:1794: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.
  warnings.warn("nn.functional.tanh is deprecated. Use torch.tanh instead.")
/localscratch/yinan.29019261.0/env/lib/python3.7/site-packages/transformers/optimization.py:155: UserWarning: This overload of add_ is deprecated:
	add_(Number alpha, Tensor other)
Consider using one of the following signatures instead:
	add_(Tensor other, *, Number alpha) (Triggered internally at  ../torch/csrc/utils/python_arg_parser.cpp:1025.)
  exp_avg.mul_(beta1).add_(1.0 - beta1, grad)
wandb: Waiting for W&B process to finish, PID 134861... (success).
wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: \ 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: | 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: / 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: \ 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: | 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: / 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: \ 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: | 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: / 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: \ 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb:                                                                                
wandb: Run history:
wandb:     e_F1 ▁▂▃▄▅▅▅▅▆▆▆▆▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇████████████
wandb:   e_loss ██▇▇▆▆▅▅▅▄▄▄▄▃▃▃▃▃▂▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:     t_F1 ▁▁▂▃▃▃▄▄▄▅▅▅▅▆▅▆▆▆▆▆▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇███
wandb:   t_loss ██▇▇▇▆▆▆▅▅▅▅▅▄▄▄▄▄▃▃▃▃▃▃▃▂▂▂▂▂▂▂▂▂▂▂▁▁▁▁
wandb: 
wandb: Run summary:
wandb:     e_F1 58.24615
wandb:   e_loss 0.9809
wandb:     t_F1 74.7411
wandb:   t_loss 0.68313
wandb: 
wandb: Synced 4 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Synced dashing-wind-2: https://wandb.ai/yinanazhou/xl_512_bs_8_lr_1e06_es_10_lc_True_nr_False_sr_True_stem_False_lemma_False_repeat_1_fold_1/runs/1343j7le
wandb: Find logs at: ./wandb/run-20220317_053600-1343j7le/logs/debug.log
wandb: 

wandb: wandb version 0.12.11 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
2022-03-17 07:09:39.406528: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1
wandb: Tracking run with wandb version 0.12.5
wandb: Syncing run neat-lake-2
wandb: ⭐️ View project at https://wandb.ai/yinanazhou/xl_512_bs_8_lr_1e06_es_10_lc_True_nr_False_sr_True_stem_False_lemma_False_repeat_1_fold_2
wandb: 🚀 View run at https://wandb.ai/yinanazhou/xl_512_bs_8_lr_1e06_es_10_lc_True_nr_False_sr_True_stem_False_lemma_False_repeat_1_fold_2/runs/l3fsyvre
wandb: Run data is saved locally in /project/6002780/yinan/Thesis_MER_Lyrics/lyric-emotion/wandb/run-20220317_070937-l3fsyvre
wandb: Run `wandb offline` to turn off syncing.

Validation loss decreased (inf --> 1.416643).  Saving model ...
Validation loss decreased (1.416643 --> 1.393208).  Saving model ...
Validation loss decreased (1.393208 --> 1.376939).  Saving model ...
Validation loss decreased (1.376939 --> 1.366044).  Saving model ...
Validation loss decreased (1.366044 --> 1.357591).  Saving model ...
Validation loss decreased (1.357591 --> 1.350631).  Saving model ...
Validation loss decreased (1.350631 --> 1.344783).  Saving model ...
Validation loss decreased (1.344783 --> 1.339144).  Saving model ...
Validation loss decreased (1.339144 --> 1.333933).  Saving model ...
Validation loss decreased (1.333933 --> 1.329259).  Saving model ...
Validation loss decreased (1.329259 --> 1.324781).  Saving model ...
Validation loss decreased (1.324781 --> 1.320417).  Saving model ...
Validation loss decreased (1.320417 --> 1.315703).  Saving model ...
Validation loss decreased (1.315703 --> 1.310809).  Saving model ...
Validation loss decreased (1.310809 --> 1.305547).  Saving model ...
Validation loss decreased (1.305547 --> 1.299404).  Saving model ...
Validation loss decreased (1.299404 --> 1.293282).  Saving model ...
Validation loss decreased (1.293282 --> 1.287382).  Saving model ...
Validation loss decreased (1.287382 --> 1.280687).  Saving model ...
Validation loss decreased (1.280687 --> 1.274780).  Saving model ...
Validation loss decreased (1.274780 --> 1.268538).  Saving model ...
Validation loss decreased (1.268538 --> 1.261344).  Saving model ...
Validation loss decreased (1.261344 --> 1.253642).  Saving model ...
Validation loss decreased (1.253642 --> 1.245788).  Saving model ...
Validation loss decreased (1.245788 --> 1.238236).  Saving model ...
Validation loss decreased (1.238236 --> 1.230493).  Saving model ...
Validation loss decreased (1.230493 --> 1.223674).  Saving model ...
Validation loss decreased (1.223674 --> 1.214869).  Saving model ...
Validation loss decreased (1.214869 --> 1.206469).  Saving model ...
Validation loss decreased (1.206469 --> 1.198884).  Saving model ...
Validation loss decreased (1.198884 --> 1.191113).  Saving model ...
Validation loss decreased (1.191113 --> 1.181452).  Saving model ...
Validation loss decreased (1.181452 --> 1.173524).  Saving model ...
Validation loss decreased (1.173524 --> 1.165353).  Saving model ...
Validation loss decreased (1.165353 --> 1.156356).  Saving model ...
Validation loss decreased (1.156356 --> 1.147151).  Saving model ...
Validation loss decreased (1.147151 --> 1.139457).  Saving model ...
Validation loss decreased (1.139457 --> 1.131810).  Saving model ...
Validation loss decreased (1.131810 --> 1.125042).  Saving model ...
Validation loss decreased (1.125042 --> 1.119123).  Saving model ...
Validation loss decreased (1.119123 --> 1.111724).  Saving model ...
Validation loss decreased (1.111724 --> 1.104366).  Saving model ...
Validation loss decreased (1.104366 --> 1.098713).  Saving model ...
Validation loss decreased (1.098713 --> 1.092562).  Saving model ...
Validation loss decreased (1.092562 --> 1.085826).  Saving model ...
Validation loss decreased (1.085826 --> 1.080750).  Saving model ...
Validation loss decreased (1.080750 --> 1.073958).  Saving model ...
Validation loss decreased (1.073958 --> 1.069518).  Saving model ...
Validation loss decreased (1.069518 --> 1.064786).  Saving model ...
Validation loss decreased (1.064786 --> 1.058728).  Saving model ...
Validation loss decreased (1.058728 --> 1.053049).  Saving model ...
Validation loss decreased (1.053049 --> 1.046595).  Saving model ...
Validation loss decreased (1.046595 --> 1.042859).  Saving model ...
Validation loss decreased (1.042859 --> 1.038840).  Saving model ...
Validation loss decreased (1.038840 --> 1.033700).  Saving model ...
Validation loss decreased (1.033700 --> 1.031394).  Saving model ...
Validation loss decreased (1.031394 --> 1.026525).  Saving model ...
Validation loss decreased (1.026525 --> 1.022505).  Saving model ...
Validation loss decreased (1.022505 --> 1.014988).  Saving model ...
Validation loss decreased (1.014988 --> 1.010014).  Saving model ...
Validation loss decreased (1.010014 --> 1.007121).  Saving model ...
Validation loss decreased (1.007121 --> 1.004913).  Saving model ...
Validation loss decreased (1.004913 --> 1.000285).  Saving model ...
Validation loss decreased (1.000285 --> 0.998335).  Saving model ...
Validation loss decreased (0.998335 --> 0.991480).  Saving model ...
Validation loss decreased (0.991480 --> 0.989599).  Saving model ...
Validation loss decreased (0.989599 --> 0.984139).  Saving model ...
Validation loss decreased (0.984139 --> 0.979571).  Saving model ...
Validation loss decreased (0.979571 --> 0.976869).  Saving model ...
Validation loss decreased (0.976869 --> 0.974865).  Saving model ...
Validation loss decreased (0.974865 --> 0.971647).  Saving model ...
Validation loss decreased (0.971647 --> 0.969845).  Saving model ...
Validation loss decreased (0.969845 --> 0.968005).  Saving model ...
Validation loss decreased (0.968005 --> 0.963497).  Saving model ...
Validation loss decreased (0.963497 --> 0.958310).  Saving model ...
Validation loss decreased (0.958310 --> 0.957348).  Saving model ...
Validation loss decreased (0.957348 --> 0.954202).  Saving model ...
Validation loss decreased (0.954202 --> 0.952756).  Saving model ...
Validation loss decreased (0.952756 --> 0.949230).  Saving model ...
Validation loss decreased (0.949230 --> 0.948217).  Saving model ...
Validation loss decreased (0.948217 --> 0.944722).  Saving model ...
Validation loss decreased (0.944722 --> 0.941893).  Saving model ...
Validation loss decreased (0.941893 --> 0.940037).  Saving model ...
Validation loss decreased (0.940037 --> 0.935278).  Saving model ...
EarlyStopping counter: 1 out of 10.0
Validation loss decreased (0.935278 --> 0.934562).  Saving model ...
EarlyStopping counter: 1 out of 10.0
Validation loss decreased (0.934562 --> 0.931925).  Saving model ...
Validation loss decreased (0.931925 --> 0.930269).  Saving model ...
Validation loss decreased (0.930269 --> 0.927804).  Saving model ...
Validation loss decreased (0.927804 --> 0.923836).  Saving model ...
EarlyStopping counter: 1 out of 10.0
Validation loss decreased (0.923836 --> 0.921445).  Saving model ...
Validation loss decreased (0.921445 --> 0.917827).  Saving model ...
Validation loss decreased (0.917827 --> 0.917077).  Saving model ...
Validation loss decreased (0.917077 --> 0.915680).  Saving model ...
EarlyStopping counter: 1 out of 10.0
EarlyStopping counter: 2 out of 10.0
Validation loss decreased (0.915680 --> 0.912114).  Saving model ...
EarlyStopping counter: 1 out of 10.0
Validation loss decreased (0.912114 --> 0.911593).  Saving model ...
EarlyStopping counter: 1 out of 10.0
Validation loss decreased (0.911593 --> 0.910149).  Saving model ...
Validation loss decreased (0.910149 --> 0.909162).  Saving model ...
EarlyStopping counter: 1 out of 10.0
EarlyStopping counter: 2 out of 10.0
EarlyStopping counter: 3 out of 10.0
Validation loss decreased (0.909162 --> 0.907486).  Saving model ...
Validation loss decreased (0.907486 --> 0.905281).  Saving model ...
Validation loss decreased (0.905281 --> 0.904983).  Saving model ...
Validation loss decreased (0.904983 --> 0.902852).  Saving model ...
EarlyStopping counter: 1 out of 10.0
EarlyStopping counter: 2 out of 10.0
EarlyStopping counter: 3 out of 10.0
EarlyStopping counter: 4 out of 10.0
EarlyStopping counter: 5 out of 10.0
EarlyStopping counter: 6 out of 10.0
EarlyStopping counter: 7 out of 10.0
EarlyStopping counter: 8 out of 10.0
EarlyStopping counter: 9 out of 10.0
Validation loss decreased (0.902852 --> 0.902245).  Saving model ...
EarlyStopping counter: 1 out of 10.0
Validation loss decreased (0.902245 --> 0.901836).  Saving model ...
EarlyStopping counter: 1 out of 10.0
EarlyStopping counter: 2 out of 10.0
EarlyStopping counter: 3 out of 10.0
EarlyStopping counter: 4 out of 10.0
EarlyStopping counter: 5 out of 10.0
EarlyStopping counter: 6 out of 10.0
EarlyStopping counter: 7 out of 10.0
Validation loss decreased (0.901836 --> 0.901050).  Saving model ...
EarlyStopping counter: 1 out of 10.0
EarlyStopping counter: 2 out of 10.0
EarlyStopping counter: 3 out of 10.0
Validation loss decreased (0.901050 --> 0.900701).  Saving model ...
EarlyStopping counter: 1 out of 10.0
EarlyStopping counter: 2 out of 10.0
EarlyStopping counter: 3 out of 10.0
EarlyStopping counter: 4 out of 10.0
EarlyStopping counter: 5 out of 10.0
EarlyStopping counter: 6 out of 10.0
EarlyStopping counter: 7 out of 10.0
EarlyStopping counter: 8 out of 10.0
EarlyStopping counter: 9 out of 10.0
EarlyStopping counter: 10 out of 10.0
/localscratch/yinan.29019261.0/env/lib/python3.7/site-packages/torch/nn/functional.py:1794: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.
  warnings.warn("nn.functional.tanh is deprecated. Use torch.tanh instead.")
wandb: Waiting for W&B process to finish, PID 139887... (success).
wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: \ 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: | 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: / 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: \ 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: | 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: / 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: \ 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: | 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: / 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: \ 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb:                                                                                
wandb: Run history:
wandb:     e_F1 ▁▃▄▅▅▅▆▆▆▇▇▇▇▇▇▇▇▇▇█▇▇██████████████████
wandb:   e_loss ██▇▇▇▆▆▆▅▅▄▄▄▃▃▃▃▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:     t_F1 ▁▂▃▂▃▃▃▄▄▄▅▅▅▆▆▆▆▆▆▆▇▇▇▇▇▇▇▇▇▇▇▇▇▇██▇███
wandb:   t_loss ███▇▇▇▇▇▆▆▆▆▅▅▅▅▄▄▄▄▄▄▃▃▃▃▃▃▂▂▂▂▂▂▂▂▁▁▁▁
wandb: 
wandb: Run summary:
wandb:     e_F1 63.8273
wandb:   e_loss 0.90944
wandb:     t_F1 74.82795
wandb:   t_loss 0.69695
wandb: 
wandb: Synced 4 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Synced neat-lake-2: https://wandb.ai/yinanazhou/xl_512_bs_8_lr_1e06_es_10_lc_True_nr_False_sr_True_stem_False_lemma_False_repeat_1_fold_2/runs/l3fsyvre
wandb: Find logs at: ./wandb/run-20220317_070937-l3fsyvre/logs/debug.log
wandb: 

wandb: wandb version 0.12.11 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
2022-03-17 08:43:10.192887: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1
wandb: Tracking run with wandb version 0.12.5
wandb: Syncing run firm-rain-2
wandb: ⭐️ View project at https://wandb.ai/yinanazhou/xl_512_bs_8_lr_1e06_es_10_lc_True_nr_False_sr_True_stem_False_lemma_False_repeat_2_fold_1
wandb: 🚀 View run at https://wandb.ai/yinanazhou/xl_512_bs_8_lr_1e06_es_10_lc_True_nr_False_sr_True_stem_False_lemma_False_repeat_2_fold_1/runs/7bq7hyth
wandb: Run data is saved locally in /project/6002780/yinan/Thesis_MER_Lyrics/lyric-emotion/wandb/run-20220317_084308-7bq7hyth
wandb: Run `wandb offline` to turn off syncing.
wandb: ERROR Error while calling W&B API: Error 1040: Too many connections (<Response [500]>)

Validation loss decreased (inf --> 1.424891).  Saving model ...
Validation loss decreased (1.424891 --> 1.409353).  Saving model ...
Validation loss decreased (1.409353 --> 1.398075).  Saving model ...
Validation loss decreased (1.398075 --> 1.388704).  Saving model ...
Validation loss decreased (1.388704 --> 1.381033).  Saving model ...
Validation loss decreased (1.381033 --> 1.374646).  Saving model ...
Validation loss decreased (1.374646 --> 1.368551).  Saving model ...
Validation loss decreased (1.368551 --> 1.362821).  Saving model ...
Validation loss decreased (1.362821 --> 1.357554).  Saving model ...
Validation loss decreased (1.357554 --> 1.352487).  Saving model ...
Validation loss decreased (1.352487 --> 1.347144).  Saving model ...
Validation loss decreased (1.347144 --> 1.341342).  Saving model ...
Validation loss decreased (1.341342 --> 1.335883).  Saving model ...
Validation loss decreased (1.335883 --> 1.329778).  Saving model ...
Validation loss decreased (1.329778 --> 1.323560).  Saving model ...
Validation loss decreased (1.323560 --> 1.317149).  Saving model ...
Validation loss decreased (1.317149 --> 1.310040).  Saving model ...
Validation loss decreased (1.310040 --> 1.302504).  Saving model ...
Validation loss decreased (1.302504 --> 1.295639).  Saving model ...
Validation loss decreased (1.295639 --> 1.288103).  Saving model ...
Validation loss decreased (1.288103 --> 1.279757).  Saving model ...
Validation loss decreased (1.279757 --> 1.270220).  Saving model ...
Validation loss decreased (1.270220 --> 1.262175).  Saving model ...
Validation loss decreased (1.262175 --> 1.254301).  Saving model ...
Validation loss decreased (1.254301 --> 1.244735).  Saving model ...
Validation loss decreased (1.244735 --> 1.235795).  Saving model ...
Validation loss decreased (1.235795 --> 1.227026).  Saving model ...
Validation loss decreased (1.227026 --> 1.216901).  Saving model ...
Validation loss decreased (1.216901 --> 1.207429).  Saving model ...
Validation loss decreased (1.207429 --> 1.199004).  Saving model ...
Validation loss decreased (1.199004 --> 1.191102).  Saving model ...
Validation loss decreased (1.191102 --> 1.181632).  Saving model ...
Validation loss decreased (1.181632 --> 1.174609).  Saving model ...
Validation loss decreased (1.174609 --> 1.164628).  Saving model ...
Validation loss decreased (1.164628 --> 1.157187).  Saving model ...
Validation loss decreased (1.157187 --> 1.149709).  Saving model ...
Validation loss decreased (1.149709 --> 1.142798).  Saving model ...
Validation loss decreased (1.142798 --> 1.137552).  Saving model ...
Validation loss decreased (1.137552 --> 1.129818).  Saving model ...
Validation loss decreased (1.129818 --> 1.122756).  Saving model ...
Validation loss decreased (1.122756 --> 1.116573).  Saving model ...
Validation loss decreased (1.116573 --> 1.109892).  Saving model ...
Validation loss decreased (1.109892 --> 1.103755).  Saving model ...
Validation loss decreased (1.103755 --> 1.097879).  Saving model ...
Validation loss decreased (1.097879 --> 1.091642).  Saving model ...
Validation loss decreased (1.091642 --> 1.085776).  Saving model ...
Validation loss decreased (1.085776 --> 1.080103).  Saving model ...
Validation loss decreased (1.080103 --> 1.075346).  Saving model ...
Validation loss decreased (1.075346 --> 1.071202).  Saving model ...
Validation loss decreased (1.071202 --> 1.065504).  Saving model ...
Validation loss decreased (1.065504 --> 1.060312).  Saving model ...
Validation loss decreased (1.060312 --> 1.055454).  Saving model ...
Validation loss decreased (1.055454 --> 1.050941).  Saving model ...
Validation loss decreased (1.050941 --> 1.046643).  Saving model ...
Validation loss decreased (1.046643 --> 1.041792).  Saving model ...
Validation loss decreased (1.041792 --> 1.037250).  Saving model ...
Validation loss decreased (1.037250 --> 1.033496).  Saving model ...
Validation loss decreased (1.033496 --> 1.029228).  Saving model ...
Validation loss decreased (1.029228 --> 1.025402).  Saving model ...
Validation loss decreased (1.025402 --> 1.023235).  Saving model ...
Validation loss decreased (1.023235 --> 1.019675).  Saving model ...
Validation loss decreased (1.019675 --> 1.016296).  Saving model ...
Validation loss decreased (1.016296 --> 1.013825).  Saving model ...
Validation loss decreased (1.013825 --> 1.010169).  Saving model ...
Validation loss decreased (1.010169 --> 1.009515).  Saving model ...
Validation loss decreased (1.009515 --> 1.005557).  Saving model ...
Validation loss decreased (1.005557 --> 1.001355).  Saving model ...
Validation loss decreased (1.001355 --> 0.998290).  Saving model ...
Validation loss decreased (0.998290 --> 0.995998).  Saving model ...
Validation loss decreased (0.995998 --> 0.993776).  Saving model ...
Validation loss decreased (0.993776 --> 0.990978).  Saving model ...
Validation loss decreased (0.990978 --> 0.990130).  Saving model ...
Validation loss decreased (0.990130 --> 0.988215).  Saving model ...
Validation loss decreased (0.988215 --> 0.986246).  Saving model ...
Validation loss decreased (0.986246 --> 0.983152).  Saving model ...
Validation loss decreased (0.983152 --> 0.980680).  Saving model ...
Validation loss decreased (0.980680 --> 0.978197).  Saving model ...
Validation loss decreased (0.978197 --> 0.975634).  Saving model ...
Validation loss decreased (0.975634 --> 0.974200).  Saving model ...
Validation loss decreased (0.974200 --> 0.972834).  Saving model ...
Validation loss decreased (0.972834 --> 0.970956).  Saving model ...
Validation loss decreased (0.970956 --> 0.969820).  Saving model ...
Validation loss decreased (0.969820 --> 0.967451).  Saving model ...
Validation loss decreased (0.967451 --> 0.966787).  Saving model ...
Validation loss decreased (0.966787 --> 0.965119).  Saving model ...
Validation loss decreased (0.965119 --> 0.963354).  Saving model ...
Validation loss decreased (0.963354 --> 0.961667).  Saving model ...
Validation loss decreased (0.961667 --> 0.960822).  Saving model ...
Validation loss decreased (0.960822 --> 0.959636).  Saving model ...
Validation loss decreased (0.959636 --> 0.957450).  Saving model ...
Validation loss decreased (0.957450 --> 0.956033).  Saving model ...
Validation loss decreased (0.956033 --> 0.955249).  Saving model ...
Validation loss decreased (0.955249 --> 0.954495).  Saving model ...
Validation loss decreased (0.954495 --> 0.953363).  Saving model ...
Validation loss decreased (0.953363 --> 0.952821).  Saving model ...
Validation loss decreased (0.952821 --> 0.952237).  Saving model ...
Validation loss decreased (0.952237 --> 0.951421).  Saving model ...
Validation loss decreased (0.951421 --> 0.949901).  Saving model ...
Validation loss decreased (0.949901 --> 0.948699).  Saving model ...
Validation loss decreased (0.948699 --> 0.947392).  Saving model ...
Validation loss decreased (0.947392 --> 0.946217).  Saving model ...
Validation loss decreased (0.946217 --> 0.944771).  Saving model ...
Validation loss decreased (0.944771 --> 0.944541).  Saving model ...
Validation loss decreased (0.944541 --> 0.944454).  Saving model ...
Validation loss decreased (0.944454 --> 0.944033).  Saving model ...
Validation loss decreased (0.944033 --> 0.943103).  Saving model ...
Validation loss decreased (0.943103 --> 0.942402).  Saving model ...
Validation loss decreased (0.942402 --> 0.941591).  Saving model ...
EarlyStopping counter: 1 out of 10.0
Validation loss decreased (0.941591 --> 0.940668).  Saving model ...
Validation loss decreased (0.940668 --> 0.939867).  Saving model ...
Validation loss decreased (0.939867 --> 0.939282).  Saving model ...
EarlyStopping counter: 1 out of 10.0
EarlyStopping counter: 2 out of 10.0
EarlyStopping counter: 3 out of 10.0
EarlyStopping counter: 4 out of 10.0
Validation loss decreased (0.939282 --> 0.938134).  Saving model ...
Validation loss decreased (0.938134 --> 0.937905).  Saving model ...
Validation loss decreased (0.937905 --> 0.937610).  Saving model ...
EarlyStopping counter: 1 out of 10.0
EarlyStopping counter: 2 out of 10.0
EarlyStopping counter: 3 out of 10.0
EarlyStopping counter: 4 out of 10.0
EarlyStopping counter: 5 out of 10.0
EarlyStopping counter: 6 out of 10.0
EarlyStopping counter: 7 out of 10.0
EarlyStopping counter: 8 out of 10.0
EarlyStopping counter: 9 out of 10.0
Validation loss decreased (0.937610 --> 0.937592).  Saving model ...
EarlyStopping counter: 1 out of 10.0
Validation loss decreased (0.937592 --> 0.936911).  Saving model ...
EarlyStopping counter: 1 out of 10.0
EarlyStopping counter: 2 out of 10.0
EarlyStopping counter: 3 out of 10.0
EarlyStopping counter: 4 out of 10.0
EarlyStopping counter: 5 out of 10.0
EarlyStopping counter: 6 out of 10.0
Validation loss decreased (0.936911 --> 0.936617).  Saving model ...
EarlyStopping counter: 1 out of 10.0
EarlyStopping counter: 2 out of 10.0
EarlyStopping counter: 3 out of 10.0
EarlyStopping counter: 4 out of 10.0
EarlyStopping counter: 5 out of 10.0
EarlyStopping counter: 6 out of 10.0
EarlyStopping counter: 7 out of 10.0
EarlyStopping counter: 8 out of 10.0
EarlyStopping counter: 9 out of 10.0
EarlyStopping counter: 10 out of 10.0
/localscratch/yinan.29019261.0/env/lib/python3.7/site-packages/torch/nn/functional.py:1794: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.
  warnings.warn("nn.functional.tanh is deprecated. Use torch.tanh instead.")
wandb: Waiting for W&B process to finish, PID 144922... (success).
wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: \ 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: | 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: / 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: \ 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: | 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: / 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: \ 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: | 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: / 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: \ 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb:                                                                                
wandb: Run history:
wandb:     e_F1 ▁▂▃▄▅▆▆▆▆▇▇▇▇▇▇▇▇▇█▇████████████████████
wandb:   e_loss ██▇▇▇▆▆▅▅▄▄▄▃▃▃▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:     t_F1 ▁▂▃▃▃▃▄▅▄▅▆▆▆▆▆▆▆▇▇▇▇▆▆▇▇▇▇▇▇▇▇▇▇███████
wandb:   t_loss ██▇▇▇▇▇▆▆▆▅▅▅▅▄▄▄▄▃▃▃▃▃▃▃▃▂▂▂▂▂▂▂▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:     e_F1 60.96971
wandb:   e_loss 0.94013
wandb:     t_F1 73.82669
wandb:   t_loss 0.70709
wandb: 
wandb: Synced 4 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Synced firm-rain-2: https://wandb.ai/yinanazhou/xl_512_bs_8_lr_1e06_es_10_lc_True_nr_False_sr_True_stem_False_lemma_False_repeat_2_fold_1/runs/7bq7hyth
wandb: Find logs at: ./wandb/run-20220317_084308-7bq7hyth/logs/debug.log
wandb: 

wandb: wandb version 0.12.11 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
2022-03-17 10:18:57.976955: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1
wandb: Tracking run with wandb version 0.12.5
wandb: Syncing run vivid-wood-2
wandb: ⭐️ View project at https://wandb.ai/yinanazhou/xl_512_bs_8_lr_1e06_es_10_lc_True_nr_False_sr_True_stem_False_lemma_False_repeat_2_fold_2
wandb: 🚀 View run at https://wandb.ai/yinanazhou/xl_512_bs_8_lr_1e06_es_10_lc_True_nr_False_sr_True_stem_False_lemma_False_repeat_2_fold_2/runs/1hd90tqn
wandb: Run data is saved locally in /project/6002780/yinan/Thesis_MER_Lyrics/lyric-emotion/wandb/run-20220317_101854-1hd90tqn
wandb: Run `wandb offline` to turn off syncing.

Validation loss decreased (inf --> 1.376781).  Saving model ...
Validation loss decreased (1.376781 --> 1.372092).  Saving model ...
Validation loss decreased (1.372092 --> 1.367541).  Saving model ...
Validation loss decreased (1.367541 --> 1.363236).  Saving model ...
Validation loss decreased (1.363236 --> 1.359243).  Saving model ...
Validation loss decreased (1.359243 --> 1.355351).  Saving model ...
Validation loss decreased (1.355351 --> 1.351426).  Saving model ...
Validation loss decreased (1.351426 --> 1.347784).  Saving model ...
Validation loss decreased (1.347784 --> 1.344070).  Saving model ...
Validation loss decreased (1.344070 --> 1.339439).  Saving model ...
Validation loss decreased (1.339439 --> 1.335247).  Saving model ...
Validation loss decreased (1.335247 --> 1.331073).  Saving model ...
Validation loss decreased (1.331073 --> 1.327157).  Saving model ...
Validation loss decreased (1.327157 --> 1.322570).  Saving model ...
Validation loss decreased (1.322570 --> 1.317943).  Saving model ...
Validation loss decreased (1.317943 --> 1.312898).  Saving model ...
Validation loss decreased (1.312898 --> 1.307248).  Saving model ...
Validation loss decreased (1.307248 --> 1.302231).  Saving model ...
Validation loss decreased (1.302231 --> 1.296494).  Saving model ...
Validation loss decreased (1.296494 --> 1.291118).  Saving model ...
Validation loss decreased (1.291118 --> 1.284551).  Saving model ...
Validation loss decreased (1.284551 --> 1.278434).  Saving model ...
Validation loss decreased (1.278434 --> 1.271048).  Saving model ...
Validation loss decreased (1.271048 --> 1.263671).  Saving model ...
Validation loss decreased (1.263671 --> 1.255667).  Saving model ...
Validation loss decreased (1.255667 --> 1.248539).  Saving model ...
Validation loss decreased (1.248539 --> 1.241550).  Saving model ...
Validation loss decreased (1.241550 --> 1.233626).  Saving model ...
Validation loss decreased (1.233626 --> 1.225201).  Saving model ...
Validation loss decreased (1.225201 --> 1.218097).  Saving model ...
Validation loss decreased (1.218097 --> 1.211173).  Saving model ...
Validation loss decreased (1.211173 --> 1.204137).  Saving model ...
Validation loss decreased (1.204137 --> 1.196049).  Saving model ...
Validation loss decreased (1.196049 --> 1.189370).  Saving model ...
Validation loss decreased (1.189370 --> 1.182312).  Saving model ...
Validation loss decreased (1.182312 --> 1.173447).  Saving model ...
Validation loss decreased (1.173447 --> 1.165538).  Saving model ...
Validation loss decreased (1.165538 --> 1.158650).  Saving model ...
Validation loss decreased (1.158650 --> 1.151463).  Saving model ...
Validation loss decreased (1.151463 --> 1.143942).  Saving model ...
Validation loss decreased (1.143942 --> 1.137142).  Saving model ...
Validation loss decreased (1.137142 --> 1.131471).  Saving model ...
Validation loss decreased (1.131471 --> 1.127074).  Saving model ...
Validation loss decreased (1.127074 --> 1.121161).  Saving model ...
Validation loss decreased (1.121161 --> 1.115231).  Saving model ...
Validation loss decreased (1.115231 --> 1.107073).  Saving model ...
Validation loss decreased (1.107073 --> 1.101541).  Saving model ...
Validation loss decreased (1.101541 --> 1.095048).  Saving model ...
Validation loss decreased (1.095048 --> 1.089210).  Saving model ...
Validation loss decreased (1.089210 --> 1.083822).  Saving model ...
Validation loss decreased (1.083822 --> 1.078829).  Saving model ...
Validation loss decreased (1.078829 --> 1.074354).  Saving model ...
Validation loss decreased (1.074354 --> 1.070458).  Saving model ...
Validation loss decreased (1.070458 --> 1.065603).  Saving model ...
Validation loss decreased (1.065603 --> 1.061746).  Saving model ...
Validation loss decreased (1.061746 --> 1.057395).  Saving model ...
Validation loss decreased (1.057395 --> 1.051314).  Saving model ...
Validation loss decreased (1.051314 --> 1.047546).  Saving model ...
Validation loss decreased (1.047546 --> 1.043320).  Saving model ...
Validation loss decreased (1.043320 --> 1.039910).  Saving model ...
Validation loss decreased (1.039910 --> 1.036674).  Saving model ...
Validation loss decreased (1.036674 --> 1.033738).  Saving model ...
Validation loss decreased (1.033738 --> 1.029689).  Saving model ...
Validation loss decreased (1.029689 --> 1.025150).  Saving model ...
Validation loss decreased (1.025150 --> 1.022692).  Saving model ...
Validation loss decreased (1.022692 --> 1.018120).  Saving model ...
Validation loss decreased (1.018120 --> 1.013993).  Saving model ...
Validation loss decreased (1.013993 --> 1.011167).  Saving model ...
Validation loss decreased (1.011167 --> 1.007573).  Saving model ...
Validation loss decreased (1.007573 --> 1.004504).  Saving model ...
Validation loss decreased (1.004504 --> 1.001538).  Saving model ...
Validation loss decreased (1.001538 --> 0.998569).  Saving model ...
Validation loss decreased (0.998569 --> 0.995184).  Saving model ...
Validation loss decreased (0.995184 --> 0.992946).  Saving model ...
Validation loss decreased (0.992946 --> 0.990816).  Saving model ...
Validation loss decreased (0.990816 --> 0.987607).  Saving model ...
Validation loss decreased (0.987607 --> 0.983514).  Saving model ...
Validation loss decreased (0.983514 --> 0.980899).  Saving model ...
Validation loss decreased (0.980899 --> 0.977101).  Saving model ...
Validation loss decreased (0.977101 --> 0.974144).  Saving model ...
Validation loss decreased (0.974144 --> 0.973356).  Saving model ...
Validation loss decreased (0.973356 --> 0.970104).  Saving model ...
Validation loss decreased (0.970104 --> 0.967835).  Saving model ...
Validation loss decreased (0.967835 --> 0.965525).  Saving model ...
Validation loss decreased (0.965525 --> 0.963383).  Saving model ...
Validation loss decreased (0.963383 --> 0.961766).  Saving model ...
Validation loss decreased (0.961766 --> 0.958923).  Saving model ...
Validation loss decreased (0.958923 --> 0.958261).  Saving model ...
Validation loss decreased (0.958261 --> 0.956594).  Saving model ...
Validation loss decreased (0.956594 --> 0.954454).  Saving model ...
Validation loss decreased (0.954454 --> 0.951402).  Saving model ...
Validation loss decreased (0.951402 --> 0.950601).  Saving model ...
Validation loss decreased (0.950601 --> 0.949019).  Saving model ...
Validation loss decreased (0.949019 --> 0.947575).  Saving model ...
Validation loss decreased (0.947575 --> 0.944669).  Saving model ...
Validation loss decreased (0.944669 --> 0.942587).  Saving model ...
Validation loss decreased (0.942587 --> 0.940681).  Saving model ...
Validation loss decreased (0.940681 --> 0.939149).  Saving model ...
Validation loss decreased (0.939149 --> 0.936445).  Saving model ...
Validation loss decreased (0.936445 --> 0.935851).  Saving model ...
Validation loss decreased (0.935851 --> 0.934774).  Saving model ...
Validation loss decreased (0.934774 --> 0.934191).  Saving model ...
Validation loss decreased (0.934191 --> 0.931586).  Saving model ...
Validation loss decreased (0.931586 --> 0.930302).  Saving model ...
Validation loss decreased (0.930302 --> 0.928310).  Saving model ...
Validation loss decreased (0.928310 --> 0.927220).  Saving model ...
Validation loss decreased (0.927220 --> 0.925439).  Saving model ...
Validation loss decreased (0.925439 --> 0.923775).  Saving model ...
Validation loss decreased (0.923775 --> 0.922898).  Saving model ...
EarlyStopping counter: 1 out of 10.0
Validation loss decreased (0.922898 --> 0.921949).  Saving model ...
Validation loss decreased (0.921949 --> 0.920913).  Saving model ...
Validation loss decreased (0.920913 --> 0.920051).  Saving model ...
EarlyStopping counter: 1 out of 10.0
Validation loss decreased (0.920051 --> 0.919000).  Saving model ...
Validation loss decreased (0.919000 --> 0.917019).  Saving model ...
Validation loss decreased (0.917019 --> 0.915325).  Saving model ...
Validation loss decreased (0.915325 --> 0.914441).  Saving model ...
EarlyStopping counter: 1 out of 10.0
EarlyStopping counter: 2 out of 10.0
Validation loss decreased (0.914441 --> 0.913800).  Saving model ...
Validation loss decreased (0.913800 --> 0.912555).  Saving model ...
Validation loss decreased (0.912555 --> 0.911210).  Saving model ...
Validation loss decreased (0.911210 --> 0.911182).  Saving model ...
Validation loss decreased (0.911182 --> 0.910036).  Saving model ...
Validation loss decreased (0.910036 --> 0.908723).  Saving model ...
Validation loss decreased (0.908723 --> 0.908538).  Saving model ...
EarlyStopping counter: 1 out of 10.0
EarlyStopping counter: 2 out of 10.0
EarlyStopping counter: 3 out of 10.0
EarlyStopping counter: 4 out of 10.0
EarlyStopping counter: 5 out of 10.0
EarlyStopping counter: 6 out of 10.0
EarlyStopping counter: 7 out of 10.0
Validation loss decreased (0.908538 --> 0.908217).  Saving model ...
EarlyStopping counter: 1 out of 10.0
Validation loss decreased (0.908217 --> 0.907923).  Saving model ...
Validation loss decreased (0.907923 --> 0.907598).  Saving model ...
Validation loss decreased (0.907598 --> 0.907220).  Saving model ...
Validation loss decreased (0.907220 --> 0.906347).  Saving model ...
Validation loss decreased (0.906347 --> 0.905381).  Saving model ...
Validation loss decreased (0.905381 --> 0.905152).  Saving model ...
EarlyStopping counter: 1 out of 10.0
EarlyStopping counter: 2 out of 10.0
EarlyStopping counter: 3 out of 10.0
EarlyStopping counter: 4 out of 10.0
EarlyStopping counter: 5 out of 10.0
EarlyStopping counter: 6 out of 10.0
EarlyStopping counter: 7 out of 10.0
EarlyStopping counter: 8 out of 10.0
EarlyStopping counter: 9 out of 10.0
EarlyStopping counter: 10 out of 10.0
/localscratch/yinan.29019261.0/env/lib/python3.7/site-packages/torch/nn/functional.py:1794: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.
  warnings.warn("nn.functional.tanh is deprecated. Use torch.tanh instead.")
wandb: Waiting for W&B process to finish, PID 150045... (success).
wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: \ 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: | 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: / 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: \ 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: | 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: / 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: \ 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: | 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: / 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb:                                                                                
wandb: Run history:
wandb:     e_F1 ▁▂▂▃▃▃▄▄▄▅▆▆▆▆▇▇▇▇▇▇▇▇▇▇▇▇██████████████
wandb:   e_loss ███▇▇▇▆▆▅▅▅▄▄▄▃▃▃▃▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:     t_F1 ▁▂▂▂▂▃▃▄▄▄▄▅▆▅▆▅▆▆▆▆▇▇▇▇▇▇▇▇▇▇▇▇▇▇██████
wandb:   t_loss ████▇▇▇▇▆▆▆▆▅▅▅▅▄▄▄▄▃▃▃▃▃▃▂▃▂▂▂▂▂▂▂▂▁▁▁▁
wandb: 
wandb: Run summary:
wandb:     e_F1 62.31264
wandb:   e_loss 0.91026
wandb:     t_F1 74.42369
wandb:   t_loss 0.68152
wandb: 
wandb: Synced 4 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Synced vivid-wood-2: https://wandb.ai/yinanazhou/xl_512_bs_8_lr_1e06_es_10_lc_True_nr_False_sr_True_stem_False_lemma_False_repeat_2_fold_2/runs/1hd90tqn
wandb: Find logs at: ./wandb/run-20220317_101854-1hd90tqn/logs/debug.log
wandb: 

wandb: wandb version 0.12.11 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
2022-03-17 11:58:23.142187: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1
wandb: Tracking run with wandb version 0.12.5
wandb: Syncing run colorful-fire-2
wandb: ⭐️ View project at https://wandb.ai/yinanazhou/xl_512_bs_8_lr_1e06_es_10_lc_True_nr_False_sr_True_stem_False_lemma_False_repeat_3_fold_1
wandb: 🚀 View run at https://wandb.ai/yinanazhou/xl_512_bs_8_lr_1e06_es_10_lc_True_nr_False_sr_True_stem_False_lemma_False_repeat_3_fold_1/runs/143w1xs8
wandb: Run data is saved locally in /project/6002780/yinan/Thesis_MER_Lyrics/lyric-emotion/wandb/run-20220317_115820-143w1xs8
wandb: Run `wandb offline` to turn off syncing.

Validation loss decreased (inf --> 1.400151).  Saving model ...
Validation loss decreased (1.400151 --> 1.390126).  Saving model ...
Validation loss decreased (1.390126 --> 1.382432).  Saving model ...
Validation loss decreased (1.382432 --> 1.375847).  Saving model ...
Validation loss decreased (1.375847 --> 1.370692).  Saving model ...
Validation loss decreased (1.370692 --> 1.366411).  Saving model ...
Validation loss decreased (1.366411 --> 1.362075).  Saving model ...
Validation loss decreased (1.362075 --> 1.358033).  Saving model ...
Validation loss decreased (1.358033 --> 1.353975).  Saving model ...
Validation loss decreased (1.353975 --> 1.349755).  Saving model ...
Validation loss decreased (1.349755 --> 1.345450).  Saving model ...
Validation loss decreased (1.345450 --> 1.341577).  Saving model ...
Validation loss decreased (1.341577 --> 1.337504).  Saving model ...
Validation loss decreased (1.337504 --> 1.333322).  Saving model ...
Validation loss decreased (1.333322 --> 1.328784).  Saving model ...
Validation loss decreased (1.328784 --> 1.323714).  Saving model ...
Validation loss decreased (1.323714 --> 1.318747).  Saving model ...
Validation loss decreased (1.318747 --> 1.313884).  Saving model ...
Validation loss decreased (1.313884 --> 1.308934).  Saving model ...
Validation loss decreased (1.308934 --> 1.303852).  Saving model ...
Validation loss decreased (1.303852 --> 1.298925).  Saving model ...
Validation loss decreased (1.298925 --> 1.293080).  Saving model ...
Validation loss decreased (1.293080 --> 1.286827).  Saving model ...
Validation loss decreased (1.286827 --> 1.280357).  Saving model ...
Validation loss decreased (1.280357 --> 1.274034).  Saving model ...
Validation loss decreased (1.274034 --> 1.266894).  Saving model ...
Validation loss decreased (1.266894 --> 1.260484).  Saving model ...
Validation loss decreased (1.260484 --> 1.253749).  Saving model ...
Validation loss decreased (1.253749 --> 1.245599).  Saving model ...
Validation loss decreased (1.245599 --> 1.238446).  Saving model ...
Validation loss decreased (1.238446 --> 1.230430).  Saving model ...
Validation loss decreased (1.230430 --> 1.221830).  Saving model ...
Validation loss decreased (1.221830 --> 1.214712).  Saving model ...
Validation loss decreased (1.214712 --> 1.207550).  Saving model ...
Validation loss decreased (1.207550 --> 1.198921).  Saving model ...
Validation loss decreased (1.198921 --> 1.192514).  Saving model ...
Validation loss decreased (1.192514 --> 1.185068).  Saving model ...
Validation loss decreased (1.185068 --> 1.177748).  Saving model ...
Validation loss decreased (1.177748 --> 1.170291).  Saving model ...
Validation loss decreased (1.170291 --> 1.163504).  Saving model ...
Validation loss decreased (1.163504 --> 1.156083).  Saving model ...
Validation loss decreased (1.156083 --> 1.149292).  Saving model ...
Validation loss decreased (1.149292 --> 1.142921).  Saving model ...
Validation loss decreased (1.142921 --> 1.136840).  Saving model ...
Validation loss decreased (1.136840 --> 1.130845).  Saving model ...
Validation loss decreased (1.130845 --> 1.125667).  Saving model ...
Validation loss decreased (1.125667 --> 1.118899).  Saving model ...
Validation loss decreased (1.118899 --> 1.114659).  Saving model ...
Validation loss decreased (1.114659 --> 1.109929).  Saving model ...
Validation loss decreased (1.109929 --> 1.104266).  Saving model ...
Validation loss decreased (1.104266 --> 1.098657).  Saving model ...
Validation loss decreased (1.098657 --> 1.093609).  Saving model ...
Validation loss decreased (1.093609 --> 1.087021).  Saving model ...
Validation loss decreased (1.087021 --> 1.082712).  Saving model ...
Validation loss decreased (1.082712 --> 1.077847).  Saving model ...
Validation loss decreased (1.077847 --> 1.073279).  Saving model ...
Validation loss decreased (1.073279 --> 1.069297).  Saving model ...
Validation loss decreased (1.069297 --> 1.063787).  Saving model ...
Validation loss decreased (1.063787 --> 1.058292).  Saving model ...
Validation loss decreased (1.058292 --> 1.055554).  Saving model ...
Validation loss decreased (1.055554 --> 1.053417).  Saving model ...
Validation loss decreased (1.053417 --> 1.047617).  Saving model ...
Validation loss decreased (1.047617 --> 1.042879).  Saving model ...
Validation loss decreased (1.042879 --> 1.038665).  Saving model ...
Validation loss decreased (1.038665 --> 1.033760).  Saving model ...
Validation loss decreased (1.033760 --> 1.030480).  Saving model ...
Validation loss decreased (1.030480 --> 1.028277).  Saving model ...
Validation loss decreased (1.028277 --> 1.025394).  Saving model ...
Validation loss decreased (1.025394 --> 1.021603).  Saving model ...
Validation loss decreased (1.021603 --> 1.017540).  Saving model ...
Validation loss decreased (1.017540 --> 1.014260).  Saving model ...
Validation loss decreased (1.014260 --> 1.012129).  Saving model ...
Validation loss decreased (1.012129 --> 1.009135).  Saving model ...
Validation loss decreased (1.009135 --> 1.007000).  Saving model ...
Validation loss decreased (1.007000 --> 1.002238).  Saving model ...
Validation loss decreased (1.002238 --> 1.000230).  Saving model ...
Validation loss decreased (1.000230 --> 0.998038).  Saving model ...
Validation loss decreased (0.998038 --> 0.996434).  Saving model ...
Validation loss decreased (0.996434 --> 0.994164).  Saving model ...
Validation loss decreased (0.994164 --> 0.990564).  Saving model ...
Validation loss decreased (0.990564 --> 0.989883).  Saving model ...
Validation loss decreased (0.989883 --> 0.988643).  Saving model ...
Validation loss decreased (0.988643 --> 0.984943).  Saving model ...
Validation loss decreased (0.984943 --> 0.982293).  Saving model ...
Validation loss decreased (0.982293 --> 0.980492).  Saving model ...
EarlyStopping counter: 1 out of 10.0
Validation loss decreased (0.980492 --> 0.977516).  Saving model ...
Validation loss decreased (0.977516 --> 0.974721).  Saving model ...
Validation loss decreased (0.974721 --> 0.972340).  Saving model ...
Validation loss decreased (0.972340 --> 0.971854).  Saving model ...
Validation loss decreased (0.971854 --> 0.969333).  Saving model ...
EarlyStopping counter: 1 out of 10.0
Validation loss decreased (0.969333 --> 0.966878).  Saving model ...
Validation loss decreased (0.966878 --> 0.964750).  Saving model ...
Validation loss decreased (0.964750 --> 0.963861).  Saving model ...
Validation loss decreased (0.963861 --> 0.962193).  Saving model ...
Validation loss decreased (0.962193 --> 0.960845).  Saving model ...
Validation loss decreased (0.960845 --> 0.960061).  Saving model ...
Validation loss decreased (0.960061 --> 0.959179).  Saving model ...
Validation loss decreased (0.959179 --> 0.958232).  Saving model ...
Validation loss decreased (0.958232 --> 0.956890).  Saving model ...
Validation loss decreased (0.956890 --> 0.956614).  Saving model ...
Validation loss decreased (0.956614 --> 0.956237).  Saving model ...
Validation loss decreased (0.956237 --> 0.955192).  Saving model ...
EarlyStopping counter: 1 out of 10.0
Validation loss decreased (0.955192 --> 0.953592).  Saving model ...
Validation loss decreased (0.953592 --> 0.952298).  Saving model ...
Validation loss decreased (0.952298 --> 0.951918).  Saving model ...
Validation loss decreased (0.951918 --> 0.951188).  Saving model ...
Validation loss decreased (0.951188 --> 0.950011).  Saving model ...
Validation loss decreased (0.950011 --> 0.949732).  Saving model ...
EarlyStopping counter: 1 out of 10.0
Validation loss decreased (0.949732 --> 0.947884).  Saving model ...
Validation loss decreased (0.947884 --> 0.946506).  Saving model ...
EarlyStopping counter: 1 out of 10.0
Validation loss decreased (0.946506 --> 0.945597).  Saving model ...
Validation loss decreased (0.945597 --> 0.944709).  Saving model ...
EarlyStopping counter: 1 out of 10.0
EarlyStopping counter: 2 out of 10.0
Validation loss decreased (0.944709 --> 0.944014).  Saving model ...
Validation loss decreased (0.944014 --> 0.942454).  Saving model ...
EarlyStopping counter: 1 out of 10.0
EarlyStopping counter: 2 out of 10.0
EarlyStopping counter: 3 out of 10.0
EarlyStopping counter: 4 out of 10.0
EarlyStopping counter: 5 out of 10.0
EarlyStopping counter: 6 out of 10.0
EarlyStopping counter: 7 out of 10.0
Validation loss decreased (0.942454 --> 0.940579).  Saving model ...
Validation loss decreased (0.940579 --> 0.939685).  Saving model ...
EarlyStopping counter: 1 out of 10.0
Validation loss decreased (0.939685 --> 0.939446).  Saving model ...
EarlyStopping counter: 1 out of 10.0
EarlyStopping counter: 2 out of 10.0
EarlyStopping counter: 3 out of 10.0
EarlyStopping counter: 4 out of 10.0
EarlyStopping counter: 5 out of 10.0
EarlyStopping counter: 6 out of 10.0
EarlyStopping counter: 7 out of 10.0
EarlyStopping counter: 8 out of 10.0
EarlyStopping counter: 9 out of 10.0
EarlyStopping counter: 10 out of 10.0
/localscratch/yinan.29019261.0/env/lib/python3.7/site-packages/torch/nn/functional.py:1794: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.
  warnings.warn("nn.functional.tanh is deprecated. Use torch.tanh instead.")
wandb: Waiting for W&B process to finish, PID 155389... (success).
wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: \ 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: | 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: / 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: \ 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: | 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: / 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: \ 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: | 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: / 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: \ 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: | 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: / 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: \ 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: | 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb:                                                                                
wandb: Run history:
wandb:     e_F1 ▁▂▃▄▄▄▅▅▅▆▆▆▇▇▇▇▇▇▇▇▇▇▇▇▇███████████████
wandb:   e_loss ███▇▇▇▆▆▆▅▅▄▄▄▃▃▃▃▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:     t_F1 ▁▂▂▂▃▃▄▄▄▅▄▅▅▆▆▆▆▆▆▇▆▇▇▇▇▇▇▇▇▇▇▇▇▇██████
wandb:   t_loss ██▇▇▇▇▇▇▆▆▆▅▅▅▅▅▄▄▄▃▃▃▃▃▃▃▂▂▂▂▂▂▂▂▂▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:     e_F1 61.44119
wandb:   e_loss 0.94307
wandb:     t_F1 73.55666
wandb:   t_loss 0.71676
wandb: 
wandb: Synced 4 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Synced colorful-fire-2: https://wandb.ai/yinanazhou/xl_512_bs_8_lr_1e06_es_10_lc_True_nr_False_sr_True_stem_False_lemma_False_repeat_3_fold_1/runs/143w1xs8
wandb: Find logs at: ./wandb/run-20220317_115820-143w1xs8/logs/debug.log
wandb: 

wandb: wandb version 0.12.11 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
2022-03-17 13:31:17.593681: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1
wandb: Tracking run with wandb version 0.12.5
wandb: Syncing run helpful-flower-2
wandb: ⭐️ View project at https://wandb.ai/yinanazhou/xl_512_bs_8_lr_1e06_es_10_lc_True_nr_False_sr_True_stem_False_lemma_False_repeat_3_fold_2
wandb: 🚀 View run at https://wandb.ai/yinanazhou/xl_512_bs_8_lr_1e06_es_10_lc_True_nr_False_sr_True_stem_False_lemma_False_repeat_3_fold_2/runs/2n86jugc
wandb: Run data is saved locally in /project/6002780/yinan/Thesis_MER_Lyrics/lyric-emotion/wandb/run-20220317_133114-2n86jugc
wandb: Run `wandb offline` to turn off syncing.

Validation loss decreased (inf --> 1.413320).  Saving model ...
Validation loss decreased (1.413320 --> 1.401630).  Saving model ...
Validation loss decreased (1.401630 --> 1.392094).  Saving model ...
Validation loss decreased (1.392094 --> 1.384475).  Saving model ...
Validation loss decreased (1.384475 --> 1.378052).  Saving model ...
Validation loss decreased (1.378052 --> 1.372478).  Saving model ...
Validation loss decreased (1.372478 --> 1.367641).  Saving model ...
Validation loss decreased (1.367641 --> 1.363255).  Saving model ...
Validation loss decreased (1.363255 --> 1.358861).  Saving model ...
Validation loss decreased (1.358861 --> 1.354857).  Saving model ...
Validation loss decreased (1.354857 --> 1.350685).  Saving model ...
Validation loss decreased (1.350685 --> 1.346496).  Saving model ...
Validation loss decreased (1.346496 --> 1.341858).  Saving model ...
Validation loss decreased (1.341858 --> 1.337475).  Saving model ...
Validation loss decreased (1.337475 --> 1.332927).  Saving model ...
Validation loss decreased (1.332927 --> 1.328387).  Saving model ...
Validation loss decreased (1.328387 --> 1.323689).  Saving model ...
Validation loss decreased (1.323689 --> 1.318407).  Saving model ...
Validation loss decreased (1.318407 --> 1.313014).  Saving model ...
Validation loss decreased (1.313014 --> 1.307134).  Saving model ...
Validation loss decreased (1.307134 --> 1.300690).  Saving model ...
Validation loss decreased (1.300690 --> 1.294206).  Saving model ...
Validation loss decreased (1.294206 --> 1.289078).  Saving model ...
Validation loss decreased (1.289078 --> 1.282682).  Saving model ...
Validation loss decreased (1.282682 --> 1.276286).  Saving model ...
Validation loss decreased (1.276286 --> 1.269008).  Saving model ...
Validation loss decreased (1.269008 --> 1.262219).  Saving model ...
Validation loss decreased (1.262219 --> 1.254092).  Saving model ...
Validation loss decreased (1.254092 --> 1.246713).  Saving model ...
Validation loss decreased (1.246713 --> 1.240562).  Saving model ...
Validation loss decreased (1.240562 --> 1.232317).  Saving model ...
Validation loss decreased (1.232317 --> 1.224805).  Saving model ...
Validation loss decreased (1.224805 --> 1.218308).  Saving model ...
Validation loss decreased (1.218308 --> 1.210696).  Saving model ...
Validation loss decreased (1.210696 --> 1.204220).  Saving model ...
Validation loss decreased (1.204220 --> 1.198283).  Saving model ...
Validation loss decreased (1.198283 --> 1.190382).  Saving model ...
Validation loss decreased (1.190382 --> 1.183152).  Saving model ...
Validation loss decreased (1.183152 --> 1.174771).  Saving model ...
Validation loss decreased (1.174771 --> 1.168064).  Saving model ...
Validation loss decreased (1.168064 --> 1.160796).  Saving model ...
Validation loss decreased (1.160796 --> 1.155147).  Saving model ...
Validation loss decreased (1.155147 --> 1.149281).  Saving model ...
Validation loss decreased (1.149281 --> 1.143685).  Saving model ...
Validation loss decreased (1.143685 --> 1.137543).  Saving model ...
Validation loss decreased (1.137543 --> 1.132358).  Saving model ...
Validation loss decreased (1.132358 --> 1.127025).  Saving model ...
Validation loss decreased (1.127025 --> 1.120429).  Saving model ...
Validation loss decreased (1.120429 --> 1.116349).  Saving model ...
Validation loss decreased (1.116349 --> 1.113209).  Saving model ...
Validation loss decreased (1.113209 --> 1.106676).  Saving model ...
Validation loss decreased (1.106676 --> 1.101103).  Saving model ...
Validation loss decreased (1.101103 --> 1.095799).  Saving model ...
Validation loss decreased (1.095799 --> 1.091017).  Saving model ...
Validation loss decreased (1.091017 --> 1.086756).  Saving model ...
Validation loss decreased (1.086756 --> 1.082580).  Saving model ...
Validation loss decreased (1.082580 --> 1.079329).  Saving model ...
Validation loss decreased (1.079329 --> 1.073354).  Saving model ...
Validation loss decreased (1.073354 --> 1.068530).  Saving model ...
Validation loss decreased (1.068530 --> 1.064941).  Saving model ...
Validation loss decreased (1.064941 --> 1.058990).  Saving model ...
Validation loss decreased (1.058990 --> 1.054394).  Saving model ...
Validation loss decreased (1.054394 --> 1.048467).  Saving model ...
Validation loss decreased (1.048467 --> 1.046228).  Saving model ...
Validation loss decreased (1.046228 --> 1.044947).  Saving model ...
Validation loss decreased (1.044947 --> 1.042231).  Saving model ...
Validation loss decreased (1.042231 --> 1.037207).  Saving model ...
Validation loss decreased (1.037207 --> 1.032005).  Saving model ...
Validation loss decreased (1.032005 --> 1.027833).  Saving model ...
Validation loss decreased (1.027833 --> 1.023645).  Saving model ...
Validation loss decreased (1.023645 --> 1.021549).  Saving model ...
Validation loss decreased (1.021549 --> 1.017460).  Saving model ...
Validation loss decreased (1.017460 --> 1.015127).  Saving model ...
Validation loss decreased (1.015127 --> 1.013851).  Saving model ...
Validation loss decreased (1.013851 --> 1.012089).  Saving model ...
Validation loss decreased (1.012089 --> 1.005597).  Saving model ...
Validation loss decreased (1.005597 --> 1.002360).  Saving model ...
Validation loss decreased (1.002360 --> 1.000101).  Saving model ...
Validation loss decreased (1.000101 --> 0.998596).  Saving model ...
Validation loss decreased (0.998596 --> 0.997563).  Saving model ...
EarlyStopping counter: 1 out of 10.0
Validation loss decreased (0.997563 --> 0.991848).  Saving model ...
Validation loss decreased (0.991848 --> 0.990479).  Saving model ...
Validation loss decreased (0.990479 --> 0.989318).  Saving model ...
Validation loss decreased (0.989318 --> 0.987788).  Saving model ...
Validation loss decreased (0.987788 --> 0.981907).  Saving model ...
Validation loss decreased (0.981907 --> 0.981695).  Saving model ...
Validation loss decreased (0.981695 --> 0.979629).  Saving model ...
Validation loss decreased (0.979629 --> 0.978168).  Saving model ...
Validation loss decreased (0.978168 --> 0.978069).  Saving model ...
Validation loss decreased (0.978069 --> 0.974797).  Saving model ...
Validation loss decreased (0.974797 --> 0.972833).  Saving model ...
Validation loss decreased (0.972833 --> 0.972097).  Saving model ...
Validation loss decreased (0.972097 --> 0.969005).  Saving model ...
Validation loss decreased (0.969005 --> 0.966956).  Saving model ...
Validation loss decreased (0.966956 --> 0.965003).  Saving model ...
EarlyStopping counter: 1 out of 10.0
Validation loss decreased (0.965003 --> 0.962389).  Saving model ...
Validation loss decreased (0.962389 --> 0.960642).  Saving model ...
Validation loss decreased (0.960642 --> 0.958047).  Saving model ...
Validation loss decreased (0.958047 --> 0.956368).  Saving model ...
Validation loss decreased (0.956368 --> 0.956116).  Saving model ...
Validation loss decreased (0.956116 --> 0.955943).  Saving model ...
Validation loss decreased (0.955943 --> 0.952258).  Saving model ...
Validation loss decreased (0.952258 --> 0.950429).  Saving model ...
Validation loss decreased (0.950429 --> 0.949987).  Saving model ...
EarlyStopping counter: 1 out of 10.0
EarlyStopping counter: 2 out of 10.0
Validation loss decreased (0.949987 --> 0.948174).  Saving model ...
Validation loss decreased (0.948174 --> 0.944586).  Saving model ...
Validation loss decreased (0.944586 --> 0.942984).  Saving model ...
EarlyStopping counter: 1 out of 10.0
Validation loss decreased (0.942984 --> 0.942735).  Saving model ...
Validation loss decreased (0.942735 --> 0.940835).  Saving model ...
Validation loss decreased (0.940835 --> 0.939482).  Saving model ...
Validation loss decreased (0.939482 --> 0.939254).  Saving model ...
Validation loss decreased (0.939254 --> 0.936258).  Saving model ...
EarlyStopping counter: 1 out of 10.0
EarlyStopping counter: 2 out of 10.0
EarlyStopping counter: 3 out of 10.0
Validation loss decreased (0.936258 --> 0.936034).  Saving model ...
Validation loss decreased (0.936034 --> 0.933749).  Saving model ...
EarlyStopping counter: 1 out of 10.0
Validation loss decreased (0.933749 --> 0.933582).  Saving model ...
Validation loss decreased (0.933582 --> 0.931436).  Saving model ...
Validation loss decreased (0.931436 --> 0.930921).  Saving model ...
Validation loss decreased (0.930921 --> 0.929884).  Saving model ...
Validation loss decreased (0.929884 --> 0.929560).  Saving model ...
Validation loss decreased (0.929560 --> 0.928238).  Saving model ...
EarlyStopping counter: 1 out of 10.0
Validation loss decreased (0.928238 --> 0.927348).  Saving model ...
EarlyStopping counter: 1 out of 10.0
Validation loss decreased (0.927348 --> 0.926697).  Saving model ...
EarlyStopping counter: 1 out of 10.0
Validation loss decreased (0.926697 --> 0.926590).  Saving model ...
Validation loss decreased (0.926590 --> 0.923270).  Saving model ...
EarlyStopping counter: 1 out of 10.0
EarlyStopping counter: 2 out of 10.0
EarlyStopping counter: 3 out of 10.0
EarlyStopping counter: 4 out of 10.0
EarlyStopping counter: 5 out of 10.0
EarlyStopping counter: 6 out of 10.0
EarlyStopping counter: 7 out of 10.0
EarlyStopping counter: 8 out of 10.0
Validation loss decreased (0.923270 --> 0.923079).  Saving model ...
EarlyStopping counter: 1 out of 10.0
EarlyStopping counter: 2 out of 10.0
Validation loss decreased (0.923079 --> 0.922254).  Saving model ...
EarlyStopping counter: 1 out of 10.0
EarlyStopping counter: 2 out of 10.0
EarlyStopping counter: 3 out of 10.0
EarlyStopping counter: 4 out of 10.0
Validation loss decreased (0.922254 --> 0.921521).  Saving model ...
EarlyStopping counter: 1 out of 10.0
Validation loss decreased (0.921521 --> 0.920846).  Saving model ...
EarlyStopping counter: 1 out of 10.0
EarlyStopping counter: 2 out of 10.0
Validation loss decreased (0.920846 --> 0.920466).  Saving model ...
EarlyStopping counter: 1 out of 10.0
EarlyStopping counter: 2 out of 10.0
EarlyStopping counter: 3 out of 10.0
EarlyStopping counter: 4 out of 10.0
EarlyStopping counter: 5 out of 10.0
EarlyStopping counter: 6 out of 10.0
EarlyStopping counter: 7 out of 10.0
EarlyStopping counter: 8 out of 10.0
EarlyStopping counter: 9 out of 10.0
EarlyStopping counter: 10 out of 10.0
/localscratch/yinan.29019261.0/env/lib/python3.7/site-packages/torch/nn/functional.py:1794: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.
  warnings.warn("nn.functional.tanh is deprecated. Use torch.tanh instead.")
wandb: Waiting for W&B process to finish, PID 160394... (success).
wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: \ 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: | 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: / 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: \ 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb:                                                                                
wandb: Run history:
wandb:     e_F1 ▁▂▄▄▅▄▅▅▆▆▆▆▆▇▇▇▇▇▇▇▇▇▇▇▇▇██████████████
wandb:   e_loss ██▇▇▇▆▆▆▅▅▄▄▄▃▃▃▃▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:     t_F1 ▁▁▂▂▂▃▃▄▄▅▅▅▅▅▆▆▆▆▆▇▇▆▆▇▇▇▇▇▇▇▇▇████████
wandb:   t_loss ████▇▇▇▇▆▆▆▅▅▅▄▅▄▄▄▃▃▃▃▃▃▃▂▃▂▂▂▂▂▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:     e_F1 62.5817
wandb:   e_loss 0.92196
wandb:     t_F1 72.02928
wandb:   t_loss 0.71213
wandb: 
wandb: Synced 4 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Synced helpful-flower-2: https://wandb.ai/yinanazhou/xl_512_bs_8_lr_1e06_es_10_lc_True_nr_False_sr_True_stem_False_lemma_False_repeat_3_fold_2/runs/2n86jugc
wandb: Find logs at: ./wandb/run-20220317_133114-2n86jugc/logs/debug.log
wandb: 

wandb: wandb version 0.12.11 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
2022-03-17 15:21:15.859282: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1
wandb: Tracking run with wandb version 0.12.5
wandb: Syncing run fiery-field-2
wandb: ⭐️ View project at https://wandb.ai/yinanazhou/xl_512_bs_8_lr_1e06_es_10_lc_True_nr_False_sr_True_stem_False_lemma_False_repeat_4_fold_1
wandb: 🚀 View run at https://wandb.ai/yinanazhou/xl_512_bs_8_lr_1e06_es_10_lc_True_nr_False_sr_True_stem_False_lemma_False_repeat_4_fold_1/runs/hd7dxw7j
wandb: Run data is saved locally in /project/6002780/yinan/Thesis_MER_Lyrics/lyric-emotion/wandb/run-20220317_152113-hd7dxw7j
wandb: Run `wandb offline` to turn off syncing.

Validation loss decreased (inf --> 1.442474).  Saving model ...
Validation loss decreased (1.442474 --> 1.426988).  Saving model ...
Validation loss decreased (1.426988 --> 1.413834).  Saving model ...
Validation loss decreased (1.413834 --> 1.403722).  Saving model ...
Validation loss decreased (1.403722 --> 1.395037).  Saving model ...
Validation loss decreased (1.395037 --> 1.387951).  Saving model ...
Validation loss decreased (1.387951 --> 1.381362).  Saving model ...
Validation loss decreased (1.381362 --> 1.375390).  Saving model ...
Validation loss decreased (1.375390 --> 1.369702).  Saving model ...
Validation loss decreased (1.369702 --> 1.364431).  Saving model ...
Validation loss decreased (1.364431 --> 1.359258).  Saving model ...
Validation loss decreased (1.359258 --> 1.354027).  Saving model ...
Validation loss decreased (1.354027 --> 1.348766).  Saving model ...
Validation loss decreased (1.348766 --> 1.343428).  Saving model ...
Validation loss decreased (1.343428 --> 1.338324).  Saving model ...
Validation loss decreased (1.338324 --> 1.332868).  Saving model ...
Validation loss decreased (1.332868 --> 1.327295).  Saving model ...
Validation loss decreased (1.327295 --> 1.321550).  Saving model ...
Validation loss decreased (1.321550 --> 1.315373).  Saving model ...
Validation loss decreased (1.315373 --> 1.309229).  Saving model ...
Validation loss decreased (1.309229 --> 1.301650).  Saving model ...
Validation loss decreased (1.301650 --> 1.295143).  Saving model ...
Validation loss decreased (1.295143 --> 1.287551).  Saving model ...
Validation loss decreased (1.287551 --> 1.278895).  Saving model ...
Validation loss decreased (1.278895 --> 1.271749).  Saving model ...
Validation loss decreased (1.271749 --> 1.263713).  Saving model ...
Validation loss decreased (1.263713 --> 1.256550).  Saving model ...
Validation loss decreased (1.256550 --> 1.247727).  Saving model ...
Validation loss decreased (1.247727 --> 1.238900).  Saving model ...
Validation loss decreased (1.238900 --> 1.230637).  Saving model ...
Validation loss decreased (1.230637 --> 1.222170).  Saving model ...
Validation loss decreased (1.222170 --> 1.215148).  Saving model ...
Validation loss decreased (1.215148 --> 1.207614).  Saving model ...
Validation loss decreased (1.207614 --> 1.200113).  Saving model ...
Validation loss decreased (1.200113 --> 1.192880).  Saving model ...
Validation loss decreased (1.192880 --> 1.186607).  Saving model ...
Validation loss decreased (1.186607 --> 1.180428).  Saving model ...
Validation loss decreased (1.180428 --> 1.174048).  Saving model ...
Validation loss decreased (1.174048 --> 1.167047).  Saving model ...
Validation loss decreased (1.167047 --> 1.161021).  Saving model ...
Validation loss decreased (1.161021 --> 1.154751).  Saving model ...
Validation loss decreased (1.154751 --> 1.148410).  Saving model ...
Validation loss decreased (1.148410 --> 1.142421).  Saving model ...
Validation loss decreased (1.142421 --> 1.139313).  Saving model ...
Validation loss decreased (1.139313 --> 1.133986).  Saving model ...
Validation loss decreased (1.133986 --> 1.127308).  Saving model ...
Validation loss decreased (1.127308 --> 1.122788).  Saving model ...
Validation loss decreased (1.122788 --> 1.120025).  Saving model ...
Validation loss decreased (1.120025 --> 1.116093).  Saving model ...
Validation loss decreased (1.116093 --> 1.110999).  Saving model ...
Validation loss decreased (1.110999 --> 1.106907).  Saving model ...
Validation loss decreased (1.106907 --> 1.100396).  Saving model ...
Validation loss decreased (1.100396 --> 1.095795).  Saving model ...
Validation loss decreased (1.095795 --> 1.092469).  Saving model ...
Validation loss decreased (1.092469 --> 1.088867).  Saving model ...
Validation loss decreased (1.088867 --> 1.086480).  Saving model ...
Validation loss decreased (1.086480 --> 1.082384).  Saving model ...
Validation loss decreased (1.082384 --> 1.080236).  Saving model ...
Validation loss decreased (1.080236 --> 1.074744).  Saving model ...
Validation loss decreased (1.074744 --> 1.070919).  Saving model ...
Validation loss decreased (1.070919 --> 1.069089).  Saving model ...
Validation loss decreased (1.069089 --> 1.064818).  Saving model ...
Validation loss decreased (1.064818 --> 1.062174).  Saving model ...
Validation loss decreased (1.062174 --> 1.058195).  Saving model ...
Validation loss decreased (1.058195 --> 1.053967).  Saving model ...
Validation loss decreased (1.053967 --> 1.049755).  Saving model ...
Validation loss decreased (1.049755 --> 1.046518).  Saving model ...
Validation loss decreased (1.046518 --> 1.043519).  Saving model ...
Validation loss decreased (1.043519 --> 1.041028).  Saving model ...
Validation loss decreased (1.041028 --> 1.040312).  Saving model ...
Validation loss decreased (1.040312 --> 1.035836).  Saving model ...
Validation loss decreased (1.035836 --> 1.032437).  Saving model ...
Validation loss decreased (1.032437 --> 1.030162).  Saving model ...
Validation loss decreased (1.030162 --> 1.026450).  Saving model ...
Validation loss decreased (1.026450 --> 1.025356).  Saving model ...
Validation loss decreased (1.025356 --> 1.020708).  Saving model ...
Validation loss decreased (1.020708 --> 1.019275).  Saving model ...
Validation loss decreased (1.019275 --> 1.016906).  Saving model ...
Validation loss decreased (1.016906 --> 1.014470).  Saving model ...
EarlyStopping counter: 1 out of 10.0
Validation loss decreased (1.014470 --> 1.012228).  Saving model ...
Validation loss decreased (1.012228 --> 1.010356).  Saving model ...
Validation loss decreased (1.010356 --> 1.008619).  Saving model ...
Validation loss decreased (1.008619 --> 1.005648).  Saving model ...
Validation loss decreased (1.005648 --> 1.002516).  Saving model ...
Validation loss decreased (1.002516 --> 1.001571).  Saving model ...
Validation loss decreased (1.001571 --> 1.000303).  Saving model ...
Validation loss decreased (1.000303 --> 0.997698).  Saving model ...
Validation loss decreased (0.997698 --> 0.995087).  Saving model ...
Validation loss decreased (0.995087 --> 0.993098).  Saving model ...
Validation loss decreased (0.993098 --> 0.990181).  Saving model ...
Validation loss decreased (0.990181 --> 0.987876).  Saving model ...
EarlyStopping counter: 1 out of 10.0
Validation loss decreased (0.987876 --> 0.986594).  Saving model ...
Validation loss decreased (0.986594 --> 0.984204).  Saving model ...
Validation loss decreased (0.984204 --> 0.983390).  Saving model ...
Validation loss decreased (0.983390 --> 0.982667).  Saving model ...
Validation loss decreased (0.982667 --> 0.980371).  Saving model ...
Validation loss decreased (0.980371 --> 0.978057).  Saving model ...
EarlyStopping counter: 1 out of 10.0
Validation loss decreased (0.978057 --> 0.977562).  Saving model ...
Validation loss decreased (0.977562 --> 0.976485).  Saving model ...
EarlyStopping counter: 1 out of 10.0
Validation loss decreased (0.976485 --> 0.975432).  Saving model ...
EarlyStopping counter: 1 out of 10.0
Validation loss decreased (0.975432 --> 0.974593).  Saving model ...
Validation loss decreased (0.974593 --> 0.974144).  Saving model ...
Validation loss decreased (0.974144 --> 0.972950).  Saving model ...
Validation loss decreased (0.972950 --> 0.972277).  Saving model ...
EarlyStopping counter: 1 out of 10.0
Validation loss decreased (0.972277 --> 0.970655).  Saving model ...
Validation loss decreased (0.970655 --> 0.969231).  Saving model ...
Validation loss decreased (0.969231 --> 0.968059).  Saving model ...
EarlyStopping counter: 1 out of 10.0
Validation loss decreased (0.968059 --> 0.965981).  Saving model ...
Validation loss decreased (0.965981 --> 0.964419).  Saving model ...
EarlyStopping counter: 1 out of 10.0
Validation loss decreased (0.964419 --> 0.963809).  Saving model ...
EarlyStopping counter: 1 out of 10.0
EarlyStopping counter: 2 out of 10.0
EarlyStopping counter: 3 out of 10.0
EarlyStopping counter: 4 out of 10.0
EarlyStopping counter: 5 out of 10.0
Validation loss decreased (0.963809 --> 0.962348).  Saving model ...
Validation loss decreased (0.962348 --> 0.962197).  Saving model ...
EarlyStopping counter: 1 out of 10.0
Validation loss decreased (0.962197 --> 0.960916).  Saving model ...
EarlyStopping counter: 1 out of 10.0
EarlyStopping counter: 2 out of 10.0
EarlyStopping counter: 3 out of 10.0
EarlyStopping counter: 4 out of 10.0
EarlyStopping counter: 5 out of 10.0
EarlyStopping counter: 6 out of 10.0
EarlyStopping counter: 7 out of 10.0
EarlyStopping counter: 8 out of 10.0
Validation loss decreased (0.960916 --> 0.958523).  Saving model ...
EarlyStopping counter: 1 out of 10.0
EarlyStopping counter: 2 out of 10.0
EarlyStopping counter: 3 out of 10.0
EarlyStopping counter: 4 out of 10.0
EarlyStopping counter: 5 out of 10.0
EarlyStopping counter: 6 out of 10.0
EarlyStopping counter: 7 out of 10.0
EarlyStopping counter: 8 out of 10.0
EarlyStopping counter: 9 out of 10.0
EarlyStopping counter: 10 out of 10.0
/localscratch/yinan.29019261.0/env/lib/python3.7/site-packages/torch/nn/functional.py:1794: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.
  warnings.warn("nn.functional.tanh is deprecated. Use torch.tanh instead.")
wandb: Waiting for W&B process to finish, PID 166315... (success).
wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: \ 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: | 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: / 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: \ 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: | 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: / 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: \ 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: | 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: / 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb:                                                                                
wandb: Run history:
wandb:     e_F1 ▁▁▂▃▄▄▅▅▆▆▆▆▇▇▇▇▇▇██████████████████████
wandb:   e_loss ██▇▇▇▆▆▆▅▅▄▄▄▃▃▃▃▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:     t_F1 ▁▁▂▃▃▃▄▄▄▅▅▅▅▆▆▆▆▆▇▆▇▇▇▇▇▇▇▇▇▇▇█▇█▇█████
wandb:   t_loss ███▇▇▇▆▆▆▆▆▅▅▅▄▄▄▄▄▄▄▃▃▃▃▃▃▂▂▂▂▂▂▂▂▂▁▁▁▁
wandb: 
wandb: Run summary:
wandb:     e_F1 58.92057
wandb:   e_loss 0.96267
wandb:     t_F1 74.59132
wandb:   t_loss 0.69307
wandb: 
wandb: Synced 4 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Synced fiery-field-2: https://wandb.ai/yinanazhou/xl_512_bs_8_lr_1e06_es_10_lc_True_nr_False_sr_True_stem_False_lemma_False_repeat_4_fold_1/runs/hd7dxw7j
wandb: Find logs at: ./wandb/run-20220317_152113-hd7dxw7j/logs/debug.log
wandb: 

wandb: wandb version 0.12.11 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
2022-03-17 16:56:52.818492: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1
wandb: Tracking run with wandb version 0.12.5
wandb: Syncing run tough-bird-2
wandb: ⭐️ View project at https://wandb.ai/yinanazhou/xl_512_bs_8_lr_1e06_es_10_lc_True_nr_False_sr_True_stem_False_lemma_False_repeat_4_fold_2
wandb: 🚀 View run at https://wandb.ai/yinanazhou/xl_512_bs_8_lr_1e06_es_10_lc_True_nr_False_sr_True_stem_False_lemma_False_repeat_4_fold_2/runs/1loqlp9o
wandb: Run data is saved locally in /project/6002780/yinan/Thesis_MER_Lyrics/lyric-emotion/wandb/run-20220317_165650-1loqlp9o
wandb: Run `wandb offline` to turn off syncing.

Validation loss decreased (inf --> 1.416992).  Saving model ...
Validation loss decreased (1.416992 --> 1.399444).  Saving model ...
Validation loss decreased (1.399444 --> 1.385660).  Saving model ...
Validation loss decreased (1.385660 --> 1.375938).  Saving model ...
Validation loss decreased (1.375938 --> 1.368226).  Saving model ...
Validation loss decreased (1.368226 --> 1.361922).  Saving model ...
Validation loss decreased (1.361922 --> 1.356008).  Saving model ...
Validation loss decreased (1.356008 --> 1.350408).  Saving model ...
Validation loss decreased (1.350408 --> 1.345455).  Saving model ...
Validation loss decreased (1.345455 --> 1.340582).  Saving model ...
Validation loss decreased (1.340582 --> 1.335898).  Saving model ...
Validation loss decreased (1.335898 --> 1.330362).  Saving model ...
Validation loss decreased (1.330362 --> 1.324187).  Saving model ...
Validation loss decreased (1.324187 --> 1.318710).  Saving model ...
Validation loss decreased (1.318710 --> 1.313376).  Saving model ...
Validation loss decreased (1.313376 --> 1.308094).  Saving model ...
Validation loss decreased (1.308094 --> 1.301613).  Saving model ...
Validation loss decreased (1.301613 --> 1.293365).  Saving model ...
Validation loss decreased (1.293365 --> 1.286157).  Saving model ...
Validation loss decreased (1.286157 --> 1.278059).  Saving model ...
Validation loss decreased (1.278059 --> 1.271314).  Saving model ...
Validation loss decreased (1.271314 --> 1.262820).  Saving model ...
Validation loss decreased (1.262820 --> 1.253976).  Saving model ...
Validation loss decreased (1.253976 --> 1.246422).  Saving model ...
Validation loss decreased (1.246422 --> 1.238746).  Saving model ...
Validation loss decreased (1.238746 --> 1.229551).  Saving model ...
Validation loss decreased (1.229551 --> 1.221998).  Saving model ...
Validation loss decreased (1.221998 --> 1.213872).  Saving model ...
Validation loss decreased (1.213872 --> 1.207658).  Saving model ...
Validation loss decreased (1.207658 --> 1.199056).  Saving model ...
Validation loss decreased (1.199056 --> 1.190534).  Saving model ...
Validation loss decreased (1.190534 --> 1.183099).  Saving model ...
Validation loss decreased (1.183099 --> 1.175202).  Saving model ...
Validation loss decreased (1.175202 --> 1.166037).  Saving model ...
Validation loss decreased (1.166037 --> 1.158767).  Saving model ...
Validation loss decreased (1.158767 --> 1.153307).  Saving model ...
Validation loss decreased (1.153307 --> 1.146663).  Saving model ...
Validation loss decreased (1.146663 --> 1.134992).  Saving model ...
Validation loss decreased (1.134992 --> 1.126970).  Saving model ...
Validation loss decreased (1.126970 --> 1.121022).  Saving model ...
Validation loss decreased (1.121022 --> 1.113313).  Saving model ...
Validation loss decreased (1.113313 --> 1.106877).  Saving model ...
Validation loss decreased (1.106877 --> 1.102618).  Saving model ...
Validation loss decreased (1.102618 --> 1.096772).  Saving model ...
Validation loss decreased (1.096772 --> 1.088020).  Saving model ...
Validation loss decreased (1.088020 --> 1.083167).  Saving model ...
Validation loss decreased (1.083167 --> 1.081500).  Saving model ...
Validation loss decreased (1.081500 --> 1.074742).  Saving model ...
Validation loss decreased (1.074742 --> 1.066567).  Saving model ...
Validation loss decreased (1.066567 --> 1.061982).  Saving model ...
Validation loss decreased (1.061982 --> 1.055234).  Saving model ...
Validation loss decreased (1.055234 --> 1.051560).  Saving model ...
Validation loss decreased (1.051560 --> 1.046256).  Saving model ...
Validation loss decreased (1.046256 --> 1.041363).  Saving model ...
Validation loss decreased (1.041363 --> 1.038652).  Saving model ...
Validation loss decreased (1.038652 --> 1.034391).  Saving model ...
Validation loss decreased (1.034391 --> 1.029916).  Saving model ...
Validation loss decreased (1.029916 --> 1.024625).  Saving model ...
Validation loss decreased (1.024625 --> 1.019487).  Saving model ...
Validation loss decreased (1.019487 --> 1.016793).  Saving model ...
Validation loss decreased (1.016793 --> 1.013368).  Saving model ...
Validation loss decreased (1.013368 --> 1.011235).  Saving model ...
Validation loss decreased (1.011235 --> 1.006845).  Saving model ...
Validation loss decreased (1.006845 --> 1.002603).  Saving model ...
Validation loss decreased (1.002603 --> 0.998851).  Saving model ...
Validation loss decreased (0.998851 --> 0.995206).  Saving model ...
Validation loss decreased (0.995206 --> 0.990496).  Saving model ...
Validation loss decreased (0.990496 --> 0.987311).  Saving model ...
Validation loss decreased (0.987311 --> 0.985150).  Saving model ...
Validation loss decreased (0.985150 --> 0.983136).  Saving model ...
Validation loss decreased (0.983136 --> 0.980645).  Saving model ...
Validation loss decreased (0.980645 --> 0.978706).  Saving model ...
Validation loss decreased (0.978706 --> 0.975500).  Saving model ...
Validation loss decreased (0.975500 --> 0.973113).  Saving model ...
Validation loss decreased (0.973113 --> 0.969326).  Saving model ...
Validation loss decreased (0.969326 --> 0.966367).  Saving model ...
Validation loss decreased (0.966367 --> 0.962675).  Saving model ...
Validation loss decreased (0.962675 --> 0.960847).  Saving model ...
Validation loss decreased (0.960847 --> 0.958599).  Saving model ...
Validation loss decreased (0.958599 --> 0.955939).  Saving model ...
Validation loss decreased (0.955939 --> 0.954630).  Saving model ...
Validation loss decreased (0.954630 --> 0.952489).  Saving model ...
Validation loss decreased (0.952489 --> 0.950708).  Saving model ...
Validation loss decreased (0.950708 --> 0.947374).  Saving model ...
Validation loss decreased (0.947374 --> 0.945291).  Saving model ...
Validation loss decreased (0.945291 --> 0.943093).  Saving model ...
Validation loss decreased (0.943093 --> 0.941349).  Saving model ...
Validation loss decreased (0.941349 --> 0.938791).  Saving model ...
Validation loss decreased (0.938791 --> 0.937350).  Saving model ...
Validation loss decreased (0.937350 --> 0.936387).  Saving model ...
Validation loss decreased (0.936387 --> 0.935082).  Saving model ...
Validation loss decreased (0.935082 --> 0.934161).  Saving model ...
Validation loss decreased (0.934161 --> 0.932801).  Saving model ...
Validation loss decreased (0.932801 --> 0.931423).  Saving model ...
Validation loss decreased (0.931423 --> 0.929190).  Saving model ...
Validation loss decreased (0.929190 --> 0.927615).  Saving model ...
Validation loss decreased (0.927615 --> 0.925558).  Saving model ...
Validation loss decreased (0.925558 --> 0.924434).  Saving model ...
Validation loss decreased (0.924434 --> 0.923764).  Saving model ...
Validation loss decreased (0.923764 --> 0.922092).  Saving model ...
Validation loss decreased (0.922092 --> 0.920139).  Saving model ...
Validation loss decreased (0.920139 --> 0.919726).  Saving model ...
Validation loss decreased (0.919726 --> 0.917303).  Saving model ...
Validation loss decreased (0.917303 --> 0.915866).  Saving model ...
Validation loss decreased (0.915866 --> 0.915035).  Saving model ...
Validation loss decreased (0.915035 --> 0.914530).  Saving model ...
Validation loss decreased (0.914530 --> 0.914301).  Saving model ...
Validation loss decreased (0.914301 --> 0.913356).  Saving model ...
Validation loss decreased (0.913356 --> 0.912031).  Saving model ...
Validation loss decreased (0.912031 --> 0.910805).  Saving model ...
Validation loss decreased (0.910805 --> 0.910389).  Saving model ...
Validation loss decreased (0.910389 --> 0.909774).  Saving model ...
Validation loss decreased (0.909774 --> 0.909069).  Saving model ...
Validation loss decreased (0.909069 --> 0.908594).  Saving model ...
EarlyStopping counter: 1 out of 10.0
Validation loss decreased (0.908594 --> 0.907090).  Saving model ...
Validation loss decreased (0.907090 --> 0.906981).  Saving model ...
Validation loss decreased (0.906981 --> 0.906929).  Saving model ...
Validation loss decreased (0.906929 --> 0.905971).  Saving model ...
Validation loss decreased (0.905971 --> 0.905795).  Saving model ...
Validation loss decreased (0.905795 --> 0.905630).  Saving model ...
Validation loss decreased (0.905630 --> 0.905278).  Saving model ...
EarlyStopping counter: 1 out of 10.0
Validation loss decreased (0.905278 --> 0.904772).  Saving model ...
Validation loss decreased (0.904772 --> 0.904134).  Saving model ...
Validation loss decreased (0.904134 --> 0.903729).  Saving model ...
Validation loss decreased (0.903729 --> 0.903436).  Saving model ...
EarlyStopping counter: 1 out of 10.0
EarlyStopping counter: 2 out of 10.0
Validation loss decreased (0.903436 --> 0.902560).  Saving model ...
EarlyStopping counter: 1 out of 10.0
EarlyStopping counter: 2 out of 10.0
EarlyStopping counter: 3 out of 10.0
EarlyStopping counter: 4 out of 10.0
EarlyStopping counter: 5 out of 10.0
EarlyStopping counter: 6 out of 10.0
EarlyStopping counter: 7 out of 10.0
EarlyStopping counter: 8 out of 10.0
EarlyStopping counter: 9 out of 10.0
EarlyStopping counter: 10 out of 10.0
/localscratch/yinan.29019261.0/env/lib/python3.7/site-packages/torch/nn/functional.py:1794: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.
  warnings.warn("nn.functional.tanh is deprecated. Use torch.tanh instead.")
wandb: Waiting for W&B process to finish, PID 171414... (success).
wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: \ 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: | 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: / 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: \ 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: | 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: / 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: \ 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: | 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: / 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb:                                                                                
wandb: Run history:
wandb:     e_F1 ▁▂▄▅▅▅▆▆▆▆▆▆▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇█████████████
wandb:   e_loss ██▇▇▇▇▆▆▅▅▅▄▄▃▃▃▃▃▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:     t_F1 ▁▂▂▃▄▄▄▅▅▅▅▆▆▆▆▆▆▆▇▆▇▆▇▇▇▇▇▇▇▇█▇▇▇█▇████
wandb:   t_loss ███▇▇▇▇▆▆▆▆▅▅▅▅▅▄▄▄▄▄▃▃▃▃▃▃▃▂▂▂▂▂▂▂▂▂▁▁▁
wandb: 
wandb: Run summary:
wandb:     e_F1 63.86217
wandb:   e_loss 0.90367
wandb:     t_F1 73.87463
wandb:   t_loss 0.70945
wandb: 
wandb: Synced 4 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Synced tough-bird-2: https://wandb.ai/yinanazhou/xl_512_bs_8_lr_1e06_es_10_lc_True_nr_False_sr_True_stem_False_lemma_False_repeat_4_fold_2/runs/1loqlp9o
wandb: Find logs at: ./wandb/run-20220317_165650-1loqlp9o/logs/debug.log
wandb: 

wandb: wandb version 0.12.11 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
2022-03-17 18:28:38.910993: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1
wandb: Tracking run with wandb version 0.12.5
wandb: Syncing run exalted-rain-2
wandb: ⭐️ View project at https://wandb.ai/yinanazhou/xl_512_bs_8_lr_1e06_es_10_lc_True_nr_False_sr_True_stem_False_lemma_False_repeat_5_fold_1
wandb: 🚀 View run at https://wandb.ai/yinanazhou/xl_512_bs_8_lr_1e06_es_10_lc_True_nr_False_sr_True_stem_False_lemma_False_repeat_5_fold_1/runs/2w4igjq7
wandb: Run data is saved locally in /project/6002780/yinan/Thesis_MER_Lyrics/lyric-emotion/wandb/run-20220317_182836-2w4igjq7
wandb: Run `wandb offline` to turn off syncing.
wandb: Network error (ReadTimeout), entering retry loop.

Validation loss decreased (inf --> 1.460973).  Saving model ...
Validation loss decreased (1.460973 --> 1.436653).  Saving model ...
Validation loss decreased (1.436653 --> 1.418141).  Saving model ...
Validation loss decreased (1.418141 --> 1.405017).  Saving model ...
Validation loss decreased (1.405017 --> 1.394255).  Saving model ...
Validation loss decreased (1.394255 --> 1.385952).  Saving model ...
Validation loss decreased (1.385952 --> 1.379461).  Saving model ...
Validation loss decreased (1.379461 --> 1.373476).  Saving model ...
Validation loss decreased (1.373476 --> 1.368159).  Saving model ...
Validation loss decreased (1.368159 --> 1.363558).  Saving model ...
Validation loss decreased (1.363558 --> 1.358565).  Saving model ...
Validation loss decreased (1.358565 --> 1.354072).  Saving model ...
Validation loss decreased (1.354072 --> 1.349060).  Saving model ...
Validation loss decreased (1.349060 --> 1.343932).  Saving model ...
Validation loss decreased (1.343932 --> 1.339655).  Saving model ...
Validation loss decreased (1.339655 --> 1.334309).  Saving model ...
Validation loss decreased (1.334309 --> 1.329107).  Saving model ...
Validation loss decreased (1.329107 --> 1.323197).  Saving model ...
Validation loss decreased (1.323197 --> 1.317092).  Saving model ...
Validation loss decreased (1.317092 --> 1.311021).  Saving model ...
Validation loss decreased (1.311021 --> 1.304420).  Saving model ...
Validation loss decreased (1.304420 --> 1.297676).  Saving model ...
Validation loss decreased (1.297676 --> 1.291400).  Saving model ...
Validation loss decreased (1.291400 --> 1.284460).  Saving model ...
Validation loss decreased (1.284460 --> 1.276988).  Saving model ...
Validation loss decreased (1.276988 --> 1.269500).  Saving model ...
Validation loss decreased (1.269500 --> 1.262059).  Saving model ...
Validation loss decreased (1.262059 --> 1.255191).  Saving model ...
Validation loss decreased (1.255191 --> 1.248916).  Saving model ...
Validation loss decreased (1.248916 --> 1.242206).  Saving model ...
Validation loss decreased (1.242206 --> 1.235585).  Saving model ...
Validation loss decreased (1.235585 --> 1.228476).  Saving model ...
Validation loss decreased (1.228476 --> 1.221969).  Saving model ...
Validation loss decreased (1.221969 --> 1.215536).  Saving model ...
Validation loss decreased (1.215536 --> 1.208923).  Saving model ...
Validation loss decreased (1.208923 --> 1.202918).  Saving model ...
Validation loss decreased (1.202918 --> 1.196752).  Saving model ...
Validation loss decreased (1.196752 --> 1.190750).  Saving model ...
Validation loss decreased (1.190750 --> 1.184792).  Saving model ...
Validation loss decreased (1.184792 --> 1.179495).  Saving model ...
Validation loss decreased (1.179495 --> 1.173575).  Saving model ...
Validation loss decreased (1.173575 --> 1.166844).  Saving model ...
Validation loss decreased (1.166844 --> 1.160420).  Saving model ...
Validation loss decreased (1.160420 --> 1.155731).  Saving model ...
Validation loss decreased (1.155731 --> 1.150066).  Saving model ...
Validation loss decreased (1.150066 --> 1.145625).  Saving model ...
Validation loss decreased (1.145625 --> 1.141803).  Saving model ...
Validation loss decreased (1.141803 --> 1.137319).  Saving model ...
Validation loss decreased (1.137319 --> 1.131908).  Saving model ...
Validation loss decreased (1.131908 --> 1.127426).  Saving model ...
Validation loss decreased (1.127426 --> 1.123568).  Saving model ...
Validation loss decreased (1.123568 --> 1.118231).  Saving model ...
Validation loss decreased (1.118231 --> 1.113265).  Saving model ...
Validation loss decreased (1.113265 --> 1.109116).  Saving model ...
Validation loss decreased (1.109116 --> 1.102682).  Saving model ...
Validation loss decreased (1.102682 --> 1.096705).  Saving model ...
Validation loss decreased (1.096705 --> 1.094197).  Saving model ...
Validation loss decreased (1.094197 --> 1.088525).  Saving model ...
Validation loss decreased (1.088525 --> 1.083993).  Saving model ...
Validation loss decreased (1.083993 --> 1.080602).  Saving model ...
Validation loss decreased (1.080602 --> 1.076776).  Saving model ...
Validation loss decreased (1.076776 --> 1.073256).  Saving model ...
Validation loss decreased (1.073256 --> 1.067254).  Saving model ...
Validation loss decreased (1.067254 --> 1.065085).  Saving model ...
Validation loss decreased (1.065085 --> 1.060475).  Saving model ...
Validation loss decreased (1.060475 --> 1.056046).  Saving model ...
Validation loss decreased (1.056046 --> 1.053339).  Saving model ...
Validation loss decreased (1.053339 --> 1.049008).  Saving model ...
Validation loss decreased (1.049008 --> 1.045662).  Saving model ...
Validation loss decreased (1.045662 --> 1.041975).  Saving model ...
Validation loss decreased (1.041975 --> 1.039191).  Saving model ...
Validation loss decreased (1.039191 --> 1.035037).  Saving model ...
Validation loss decreased (1.035037 --> 1.033092).  Saving model ...
Validation loss decreased (1.033092 --> 1.029387).  Saving model ...
Validation loss decreased (1.029387 --> 1.024594).  Saving model ...
Validation loss decreased (1.024594 --> 1.021514).  Saving model ...
Validation loss decreased (1.021514 --> 1.017109).  Saving model ...
Validation loss decreased (1.017109 --> 1.015300).  Saving model ...
Validation loss decreased (1.015300 --> 1.011688).  Saving model ...
Validation loss decreased (1.011688 --> 1.009795).  Saving model ...
Validation loss decreased (1.009795 --> 1.006330).  Saving model ...
Validation loss decreased (1.006330 --> 1.002970).  Saving model ...
Validation loss decreased (1.002970 --> 1.000030).  Saving model ...
Validation loss decreased (1.000030 --> 0.997386).  Saving model ...
Validation loss decreased (0.997386 --> 0.995681).  Saving model ...
Validation loss decreased (0.995681 --> 0.994659).  Saving model ...
Validation loss decreased (0.994659 --> 0.991829).  Saving model ...
Validation loss decreased (0.991829 --> 0.990245).  Saving model ...
Validation loss decreased (0.990245 --> 0.987089).  Saving model ...
Validation loss decreased (0.987089 --> 0.986094).  Saving model ...
Validation loss decreased (0.986094 --> 0.984238).  Saving model ...
Validation loss decreased (0.984238 --> 0.980954).  Saving model ...
Validation loss decreased (0.980954 --> 0.978968).  Saving model ...
Validation loss decreased (0.978968 --> 0.978308).  Saving model ...
Validation loss decreased (0.978308 --> 0.976417).  Saving model ...
Validation loss decreased (0.976417 --> 0.974307).  Saving model ...
Validation loss decreased (0.974307 --> 0.972789).  Saving model ...
Validation loss decreased (0.972789 --> 0.969586).  Saving model ...
Validation loss decreased (0.969586 --> 0.968304).  Saving model ...
Validation loss decreased (0.968304 --> 0.967377).  Saving model ...
Validation loss decreased (0.967377 --> 0.965280).  Saving model ...
Validation loss decreased (0.965280 --> 0.963566).  Saving model ...
Validation loss decreased (0.963566 --> 0.963177).  Saving model ...
Validation loss decreased (0.963177 --> 0.960406).  Saving model ...
Validation loss decreased (0.960406 --> 0.959273).  Saving model ...
Validation loss decreased (0.959273 --> 0.958658).  Saving model ...
Validation loss decreased (0.958658 --> 0.958093).  Saving model ...
Validation loss decreased (0.958093 --> 0.955898).  Saving model ...
Validation loss decreased (0.955898 --> 0.955053).  Saving model ...
Validation loss decreased (0.955053 --> 0.953465).  Saving model ...
EarlyStopping counter: 1 out of 10.0
Validation loss decreased (0.953465 --> 0.951446).  Saving model ...
Validation loss decreased (0.951446 --> 0.950942).  Saving model ...
Validation loss decreased (0.950942 --> 0.949491).  Saving model ...
Validation loss decreased (0.949491 --> 0.948845).  Saving model ...
EarlyStopping counter: 1 out of 10.0
Validation loss decreased (0.948845 --> 0.947544).  Saving model ...
EarlyStopping counter: 1 out of 10.0
EarlyStopping counter: 2 out of 10.0
Validation loss decreased (0.947544 --> 0.945978).  Saving model ...
Validation loss decreased (0.945978 --> 0.944344).  Saving model ...
Validation loss decreased (0.944344 --> 0.943598).  Saving model ...
Validation loss decreased (0.943598 --> 0.942042).  Saving model ...
Validation loss decreased (0.942042 --> 0.940421).  Saving model ...
EarlyStopping counter: 1 out of 10.0
EarlyStopping counter: 2 out of 10.0
Validation loss decreased (0.940421 --> 0.940023).  Saving model ...
Validation loss decreased (0.940023 --> 0.939506).  Saving model ...
EarlyStopping counter: 1 out of 10.0
Validation loss decreased (0.939506 --> 0.938837).  Saving model ...
EarlyStopping counter: 1 out of 10.0
Validation loss decreased (0.938837 --> 0.938794).  Saving model ...
EarlyStopping counter: 1 out of 10.0
EarlyStopping counter: 2 out of 10.0
EarlyStopping counter: 3 out of 10.0
Validation loss decreased (0.938794 --> 0.937833).  Saving model ...
EarlyStopping counter: 1 out of 10.0
Validation loss decreased (0.937833 --> 0.936547).  Saving model ...
Validation loss decreased (0.936547 --> 0.935291).  Saving model ...
EarlyStopping counter: 1 out of 10.0
EarlyStopping counter: 2 out of 10.0
EarlyStopping counter: 3 out of 10.0
EarlyStopping counter: 4 out of 10.0
EarlyStopping counter: 5 out of 10.0
EarlyStopping counter: 6 out of 10.0
EarlyStopping counter: 7 out of 10.0
EarlyStopping counter: 8 out of 10.0
EarlyStopping counter: 9 out of 10.0
EarlyStopping counter: 10 out of 10.0
/localscratch/yinan.29019261.0/env/lib/python3.7/site-packages/torch/nn/functional.py:1794: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.
  warnings.warn("nn.functional.tanh is deprecated. Use torch.tanh instead.")
wandb: Waiting for W&B process to finish, PID 176353... (success).
wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: \ 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: | 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: / 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: \ 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: | 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: / 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: \ 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: | 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: / 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb:                                                                                
wandb: Run history:
wandb:     e_F1 ▁▁▃▄▅▅▅▆▅▆▆▆▆▇▇▇▇▇▇▇████████████████████
wandb:   e_loss ██▇▇▇▆▆▅▅▅▅▄▄▄▃▃▃▃▃▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:     t_F1 ▁▁▂▃▃▄▄▄▅▄▅▅▅▆▆▆▆▆▆▆▇▇▇▇▇▇▇▇▇███▇█▇█████
wandb:   t_loss ██▇▇▇▇▇▆▆▆▅▅▅▅▄▄▄▄▄▃▃▃▃▃▃▃▃▂▂▂▂▂▂▂▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:     e_F1 59.30442
wandb:   e_loss 0.93824
wandb:     t_F1 75.27873
wandb:   t_loss 0.68864
wandb: 
wandb: Synced 4 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Synced exalted-rain-2: https://wandb.ai/yinanazhou/xl_512_bs_8_lr_1e06_es_10_lc_True_nr_False_sr_True_stem_False_lemma_False_repeat_5_fold_1/runs/2w4igjq7
wandb: Find logs at: ./wandb/run-20220317_182836-2w4igjq7/logs/debug.log
wandb: 

wandb: wandb version 0.12.11 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
2022-03-17 20:06:04.700491: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1
wandb: Tracking run with wandb version 0.12.5
wandb: Syncing run glorious-resonance-2
wandb: ⭐️ View project at https://wandb.ai/yinanazhou/xl_512_bs_8_lr_1e06_es_10_lc_True_nr_False_sr_True_stem_False_lemma_False_repeat_5_fold_2
wandb: 🚀 View run at https://wandb.ai/yinanazhou/xl_512_bs_8_lr_1e06_es_10_lc_True_nr_False_sr_True_stem_False_lemma_False_repeat_5_fold_2/runs/26h4ly3w
wandb: Run data is saved locally in /project/6002780/yinan/Thesis_MER_Lyrics/lyric-emotion/wandb/run-20220317_200602-26h4ly3w
wandb: Run `wandb offline` to turn off syncing.

Validation loss decreased (inf --> 1.434581).  Saving model ...
Validation loss decreased (1.434581 --> 1.414710).  Saving model ...
Validation loss decreased (1.414710 --> 1.399870).  Saving model ...
Validation loss decreased (1.399870 --> 1.387515).  Saving model ...
Validation loss decreased (1.387515 --> 1.378183).  Saving model ...
Validation loss decreased (1.378183 --> 1.371045).  Saving model ...
Validation loss decreased (1.371045 --> 1.364955).  Saving model ...
Validation loss decreased (1.364955 --> 1.358598).  Saving model ...
Validation loss decreased (1.358598 --> 1.352615).  Saving model ...
Validation loss decreased (1.352615 --> 1.346585).  Saving model ...
Validation loss decreased (1.346585 --> 1.341032).  Saving model ...
Validation loss decreased (1.341032 --> 1.335596).  Saving model ...
Validation loss decreased (1.335596 --> 1.330528).  Saving model ...
Validation loss decreased (1.330528 --> 1.324458).  Saving model ...
Validation loss decreased (1.324458 --> 1.318678).  Saving model ...
Validation loss decreased (1.318678 --> 1.313016).  Saving model ...
Validation loss decreased (1.313016 --> 1.307438).  Saving model ...
Validation loss decreased (1.307438 --> 1.300430).  Saving model ...
Validation loss decreased (1.300430 --> 1.294091).  Saving model ...
Validation loss decreased (1.294091 --> 1.286787).  Saving model ...
Validation loss decreased (1.286787 --> 1.281018).  Saving model ...
Validation loss decreased (1.281018 --> 1.274301).  Saving model ...
Validation loss decreased (1.274301 --> 1.267172).  Saving model ...
Validation loss decreased (1.267172 --> 1.259405).  Saving model ...
Validation loss decreased (1.259405 --> 1.250852).  Saving model ...
Validation loss decreased (1.250852 --> 1.243057).  Saving model ...
Validation loss decreased (1.243057 --> 1.233880).  Saving model ...
Validation loss decreased (1.233880 --> 1.223816).  Saving model ...
Validation loss decreased (1.223816 --> 1.214667).  Saving model ...
Validation loss decreased (1.214667 --> 1.205530).  Saving model ...
Validation loss decreased (1.205530 --> 1.195710).  Saving model ...
Validation loss decreased (1.195710 --> 1.187091).  Saving model ...
Validation loss decreased (1.187091 --> 1.176414).  Saving model ...
Validation loss decreased (1.176414 --> 1.167987).  Saving model ...
Validation loss decreased (1.167987 --> 1.159645).  Saving model ...
Validation loss decreased (1.159645 --> 1.149373).  Saving model ...
Validation loss decreased (1.149373 --> 1.141241).  Saving model ...
Validation loss decreased (1.141241 --> 1.134776).  Saving model ...
Validation loss decreased (1.134776 --> 1.128678).  Saving model ...
Validation loss decreased (1.128678 --> 1.119058).  Saving model ...
Validation loss decreased (1.119058 --> 1.112575).  Saving model ...
Validation loss decreased (1.112575 --> 1.107754).  Saving model ...
Validation loss decreased (1.107754 --> 1.102907).  Saving model ...
Validation loss decreased (1.102907 --> 1.096347).  Saving model ...
Validation loss decreased (1.096347 --> 1.088122).  Saving model ...
Validation loss decreased (1.088122 --> 1.078528).  Saving model ...
Validation loss decreased (1.078528 --> 1.072260).  Saving model ...
Validation loss decreased (1.072260 --> 1.068355).  Saving model ...
Validation loss decreased (1.068355 --> 1.063271).  Saving model ...
Validation loss decreased (1.063271 --> 1.057926).  Saving model ...
Validation loss decreased (1.057926 --> 1.052816).  Saving model ...
Validation loss decreased (1.052816 --> 1.047489).  Saving model ...
Validation loss decreased (1.047489 --> 1.043616).  Saving model ...
Validation loss decreased (1.043616 --> 1.038778).  Saving model ...
Validation loss decreased (1.038778 --> 1.034335).  Saving model ...
Validation loss decreased (1.034335 --> 1.028482).  Saving model ...
Validation loss decreased (1.028482 --> 1.023633).  Saving model ...
Validation loss decreased (1.023633 --> 1.019401).  Saving model ...
Validation loss decreased (1.019401 --> 1.016052).  Saving model ...
Validation loss decreased (1.016052 --> 1.012528).  Saving model ...
Validation loss decreased (1.012528 --> 1.008836).  Saving model ...
Validation loss decreased (1.008836 --> 1.004079).  Saving model ...
Validation loss decreased (1.004079 --> 0.999802).  Saving model ...
Validation loss decreased (0.999802 --> 0.996282).  Saving model ...
Validation loss decreased (0.996282 --> 0.993949).  Saving model ...
Validation loss decreased (0.993949 --> 0.991172).  Saving model ...
Validation loss decreased (0.991172 --> 0.988630).  Saving model ...
Validation loss decreased (0.988630 --> 0.986091).  Saving model ...
Validation loss decreased (0.986091 --> 0.983069).  Saving model ...
Validation loss decreased (0.983069 --> 0.978661).  Saving model ...
Validation loss decreased (0.978661 --> 0.975654).  Saving model ...
Validation loss decreased (0.975654 --> 0.972239).  Saving model ...
Validation loss decreased (0.972239 --> 0.969034).  Saving model ...
Validation loss decreased (0.969034 --> 0.966177).  Saving model ...
Validation loss decreased (0.966177 --> 0.963564).  Saving model ...
Validation loss decreased (0.963564 --> 0.961019).  Saving model ...
Validation loss decreased (0.961019 --> 0.960341).  Saving model ...
Validation loss decreased (0.960341 --> 0.957139).  Saving model ...
Validation loss decreased (0.957139 --> 0.955558).  Saving model ...
Validation loss decreased (0.955558 --> 0.954308).  Saving model ...
Validation loss decreased (0.954308 --> 0.952268).  Saving model ...
Validation loss decreased (0.952268 --> 0.950445).  Saving model ...
Validation loss decreased (0.950445 --> 0.947914).  Saving model ...
Validation loss decreased (0.947914 --> 0.944854).  Saving model ...
Validation loss decreased (0.944854 --> 0.942857).  Saving model ...
Validation loss decreased (0.942857 --> 0.940506).  Saving model ...
Validation loss decreased (0.940506 --> 0.937622).  Saving model ...
Validation loss decreased (0.937622 --> 0.935722).  Saving model ...
Validation loss decreased (0.935722 --> 0.933256).  Saving model ...
Validation loss decreased (0.933256 --> 0.931826).  Saving model ...
Validation loss decreased (0.931826 --> 0.930959).  Saving model ...
Validation loss decreased (0.930959 --> 0.929848).  Saving model ...
Validation loss decreased (0.929848 --> 0.928329).  Saving model ...
Validation loss decreased (0.928329 --> 0.927030).  Saving model ...
Validation loss decreased (0.927030 --> 0.925386).  Saving model ...
Validation loss decreased (0.925386 --> 0.923482).  Saving model ...
Validation loss decreased (0.923482 --> 0.921344).  Saving model ...
Validation loss decreased (0.921344 --> 0.920914).  Saving model ...
Validation loss decreased (0.920914 --> 0.920212).  Saving model ...
Validation loss decreased (0.920212 --> 0.918821).  Saving model ...
Validation loss decreased (0.918821 --> 0.916467).  Saving model ...
EarlyStopping counter: 1 out of 10.0
Validation loss decreased (0.916467 --> 0.915009).  Saving model ...
Validation loss decreased (0.915009 --> 0.912720).  Saving model ...
Validation loss decreased (0.912720 --> 0.910692).  Saving model ...
Validation loss decreased (0.910692 --> 0.910210).  Saving model ...
Validation loss decreased (0.910210 --> 0.910046).  Saving model ...
Validation loss decreased (0.910046 --> 0.908582).  Saving model ...
EarlyStopping counter: 1 out of 10.0
Validation loss decreased (0.908582 --> 0.908403).  Saving model ...
Validation loss decreased (0.908403 --> 0.908257).  Saving model ...
Validation loss decreased (0.908257 --> 0.907444).  Saving model ...
Validation loss decreased (0.907444 --> 0.905655).  Saving model ...
EarlyStopping counter: 1 out of 10.0
Validation loss decreased (0.905655 --> 0.903278).  Saving model ...
Validation loss decreased (0.903278 --> 0.902578).  Saving model ...
Validation loss decreased (0.902578 --> 0.901294).  Saving model ...
Validation loss decreased (0.901294 --> 0.901121).  Saving model ...
EarlyStopping counter: 1 out of 10.0
EarlyStopping counter: 2 out of 10.0
Validation loss decreased (0.901121 --> 0.899968).  Saving model ...
Validation loss decreased (0.899968 --> 0.899065).  Saving model ...
Validation loss decreased (0.899065 --> 0.898392).  Saving model ...
EarlyStopping counter: 1 out of 10.0
Validation loss decreased (0.898392 --> 0.897763).  Saving model ...
Validation loss decreased (0.897763 --> 0.897579).  Saving model ...
Validation loss decreased (0.897579 --> 0.897255).  Saving model ...
Validation loss decreased (0.897255 --> 0.897156).  Saving model ...
EarlyStopping counter: 1 out of 10.0
Validation loss decreased (0.897156 --> 0.896562).  Saving model ...
Validation loss decreased (0.896562 --> 0.895495).  Saving model ...
Validation loss decreased (0.895495 --> 0.895001).  Saving model ...
Validation loss decreased (0.895001 --> 0.894256).  Saving model ...
EarlyStopping counter: 1 out of 10.0
EarlyStopping counter: 2 out of 10.0
EarlyStopping counter: 3 out of 10.0
EarlyStopping counter: 4 out of 10.0
Validation loss decreased (0.894256 --> 0.893726).  Saving model ...
Validation loss decreased (0.893726 --> 0.892565).  Saving model ...
Validation loss decreased (0.892565 --> 0.892084).  Saving model ...
EarlyStopping counter: 1 out of 10.0
EarlyStopping counter: 2 out of 10.0
Validation loss decreased (0.892084 --> 0.891639).  Saving model ...
Validation loss decreased (0.891639 --> 0.891436).  Saving model ...
EarlyStopping counter: 1 out of 10.0
EarlyStopping counter: 2 out of 10.0
EarlyStopping counter: 3 out of 10.0
EarlyStopping counter: 4 out of 10.0
EarlyStopping counter: 5 out of 10.0
Validation loss decreased (0.891436 --> 0.891084).  Saving model ...
EarlyStopping counter: 1 out of 10.0
EarlyStopping counter: 2 out of 10.0
EarlyStopping counter: 3 out of 10.0
EarlyStopping counter: 4 out of 10.0
EarlyStopping counter: 5 out of 10.0
EarlyStopping counter: 6 out of 10.0
EarlyStopping counter: 7 out of 10.0
EarlyStopping counter: 8 out of 10.0
EarlyStopping counter: 9 out of 10.0
EarlyStopping counter: 10 out of 10.0
/localscratch/yinan.29019261.0/env/lib/python3.7/site-packages/torch/nn/functional.py:1794: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.
  warnings.warn("nn.functional.tanh is deprecated. Use torch.tanh instead.")
wandb: Waiting for W&B process to finish, PID 181587... (success).
wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: \ 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: | 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: / 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: \ 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: | 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: / 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: \ 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: | 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: / 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb:                                                                                
wandb: Run history:
wandb:     e_F1 ▁▃▄▅▅▆▆▆▆▇▇▇▇▇▇▇████████████████████████
wandb:   e_loss █▇▇▇▆▆▆▅▅▄▄▄▃▃▃▃▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:     t_F1 ▁▂▃▃▄▄▄▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇▇▇▇▇▇▇▇██████▇███
wandb:   t_loss ██▇▇▇▇▆▆▆▆▅▅▅▅▄▄▄▄▄▃▃▃▃▃▃▃▂▃▂▂▂▂▂▂▂▂▂▁▂▁
wandb: 
wandb: Run summary:
wandb:     e_F1 63.19708
wandb:   e_loss 0.89443
wandb:     t_F1 72.4215
wandb:   t_loss 0.68862
wandb: 
wandb: Synced 4 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Synced glorious-resonance-2: https://wandb.ai/yinanazhou/xl_512_bs_8_lr_1e06_es_10_lc_True_nr_False_sr_True_stem_False_lemma_False_repeat_5_fold_2/runs/26h4ly3w
wandb: Find logs at: ./wandb/run-20220317_200602-26h4ly3w/logs/debug.log
wandb: 

