Unloading StdEnv/2020

Due to MODULEPATH changes, the following have been reloaded:
  1) mii/1.1.1


The following have been reloaded with a version change:
  1) python/3.8.2 => python/3.7.4

Using base prefix '/cvmfs/soft.computecanada.ca/easybuild/software/2017/Core/python/3.7.4'
New python executable in /localscratch/yinan.28327867.0/env/bin/python
Installing setuptools, pip, wheel...
done.
Ignoring pip: markers 'python_version < "3"' don't match your environment
Looking in links: /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/nix/avx2, /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/nix/generic, /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic
Collecting pip
Installing collected packages: pip
  Found existing installation: pip 19.1.1
    Uninstalling pip-19.1.1:
      Successfully uninstalled pip-19.1.1
Successfully installed pip-21.2.3+computecanada
Looking in links: /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/nix/avx2, /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/nix/generic, /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/keras-2.8.0+computecanada-py2.py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/Keras_Preprocessing-1.1.2+computecanada-py3-none-any.whl
Requirement already satisfied: matplotlib in /cvmfs/soft.computecanada.ca/easybuild/software/2017/Core/scipy-stack/2019a/lib/python3.7/site-packages (from -r requirements.txt (line 3)) (3.0.2)
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/nltk-3.6.5+computecanada-py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/scikit_learn-0.22.1+computecanada-cp37-cp37m-linux_x86_64.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/tensorboard-2.3.0+computecanada-py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/tensorboard_plugin_wit-1.7.0+computecanada-py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/tensorflow_gpu-2.3.0+computecanada-cp37-cp37m-linux_x86_64.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/tensorflow_estimator-2.3.0+computecanada-py2.py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/tokenizers-0.5.2+computecanada-cp37-cp37m-linux_x86_64.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/nix/avx2/torch-1.4.0+computecanada-cp37-cp37m-linux_x86_64.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/torchtext-0.6.0+computecanada-py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/torchvision-0.8.2+computecanada-cp37-cp37m-linux_x86_64.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/transformers-2.5.1+computecanada-py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/urllib3-1.26.7+computecanada-py2.py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/joblib-1.1.0+computecanada-py2.py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/tqdm-4.63.0+computecanada-py2.py3-none-any.whl
ERROR: Could not find a version that satisfies the requirement regex>=2021.8.3 (from nltk) (from versions: 2018.1.10+computecanada, 2019.11.1+computecanada, 2020.11.13+computecanada)
ERROR: No matching distribution found for regex>=2021.8.3
Looking in links: /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/nix/avx2, /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/nix/generic, /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic
ERROR: Could not find a version that satisfies the requirement numpy==1.20.0+computacanada (from versions: 1.15.0+computecanada, 1.15.2+computecanada, 1.15.4+computecanada, 1.16.0+computecanada, 1.16.2+computecanada, 1.16.3+computecanada, 1.17.4+computecanada, 1.18.1+computecanada, 1.18.4+computecanada, 1.19.1+computecanada, 1.19.2+computecanada, 1.20.2+computecanada)
ERROR: No matching distribution found for numpy==1.20.0+computacanada
Looking in links: /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/nix/avx2, /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/nix/generic, /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/wandb-0.12.5+computecanada-py2.py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/docker_pycreds-0.4.0+computecanada-py2.py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/shortuuid-1.0.1+computecanada-py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/promise-2.3+computecanada-py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/configparser-5.0.2+computecanada-py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/protobuf-3.19.3+computecanada-py2.py3-none-any.whl
Requirement already satisfied: python-dateutil>=2.6.1 in /cvmfs/soft.computecanada.ca/easybuild/software/2017/Core/scipy-stack/2019a/lib/python3.7/site-packages (from wandb) (2.7.5)
Requirement already satisfied: requests<3,>=2.0.0 in /cvmfs/soft.computecanada.ca/easybuild/software/2017/Core/scipy-stack/2019a/lib/python3.7/site-packages (from wandb) (2.21.0)
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/six-1.16.0+computecanada-py2.py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/pathtools-0.1.2+computecanada-py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/psutil-5.7.3+computecanada-cp37-cp37m-linux_x86_64.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/PyYAML-5.3.1+computecanada-cp37-cp37m-linux_x86_64.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/click-8.0.3+computecanada-py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/subprocess32-3.5.4+computecanada-py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/yaspin-2.1.0+computecanada-py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/sentry_sdk-1.5.0+computecanada-py2.py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/GitPython-3.1.24+computecanada-py3-none-any.whl
Requirement already satisfied: importlib-metadata in /cvmfs/soft.computecanada.ca/easybuild/software/2017/Core/scipy-stack/2019a/lib/python3.7/site-packages (from Click!=8.0.0,>=7.0->wandb) (0.8)
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/typing_extensions-4.0.1+computecanada-py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/gitdb-4.0.9+computecanada-py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/smmap-5.0.0+computecanada-py3-none-any.whl
Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /cvmfs/soft.computecanada.ca/easybuild/software/2017/Core/scipy-stack/2019a/lib/python3.7/site-packages (from requests<3,>=2.0.0->wandb) (3.0.4)
Requirement already satisfied: idna<2.9,>=2.5 in /cvmfs/soft.computecanada.ca/easybuild/software/2017/Core/scipy-stack/2019a/lib/python3.7/site-packages (from requests<3,>=2.0.0->wandb) (2.8)
Requirement already satisfied: certifi>=2017.4.17 in /cvmfs/soft.computecanada.ca/easybuild/software/2017/Core/scipy-stack/2019a/lib/python3.7/site-packages (from requests<3,>=2.0.0->wandb) (2018.11.29)
Requirement already satisfied: urllib3<1.25,>=1.21.1 in /cvmfs/soft.computecanada.ca/easybuild/software/2017/Core/scipy-stack/2019a/lib/python3.7/site-packages (from requests<3,>=2.0.0->wandb) (1.24.1)
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/termcolor-1.1.0+computecanada-py3-none-any.whl
Requirement already satisfied: zipp>=0.3.2 in /cvmfs/soft.computecanada.ca/easybuild/software/2017/Core/scipy-stack/2019a/lib/python3.7/site-packages (from importlib-metadata->Click!=8.0.0,>=7.0->wandb) (0.3.3)
Installing collected packages: smmap, typing-extensions, termcolor, six, gitdb, yaspin, subprocess32, shortuuid, sentry-sdk, PyYAML, psutil, protobuf, promise, pathtools, GitPython, docker-pycreds, configparser, Click, wandb
  Attempting uninstall: six
    Found existing installation: six 1.12.0
    Not uninstalling six at /cvmfs/soft.computecanada.ca/easybuild/software/2017/Core/scipy-stack/2019a/lib/python3.7/site-packages, outside environment /localscratch/yinan.28327867.0/env
    Can't uninstall 'six'. No files were found to uninstall.
Successfully installed Click-8.0.3+computecanada GitPython-3.1.24+computecanada PyYAML-5.3.1+computecanada configparser-5.0.2+computecanada docker-pycreds-0.4.0+computecanada gitdb-4.0.9+computecanada pathtools-0.1.2+computecanada promise-2.3+computecanada protobuf-3.19.3+computecanada psutil-5.7.3+computecanada sentry-sdk-1.5.0+computecanada shortuuid-1.0.1+computecanada six-1.16.0+computecanada smmap-5.0.0+computecanada subprocess32-3.5.4+computecanada termcolor-1.1.0+computecanada typing-extensions-4.0.1+computecanada wandb-0.12.5+computecanada yaspin-2.1.0+computecanada
Looking in links: /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/nix/avx2, /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/nix/generic, /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic
ERROR: Could not find a version that satisfies the requirement sagemaker (from versions: none)
ERROR: No matching distribution found for sagemaker
Looking in links: /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/nix/avx2, /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/nix/generic, /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/torch-1.9.1+computecanada-cp37-cp37m-linux_x86_64.whl
Requirement already satisfied: typing-extensions in /localscratch/yinan.28327867.0/env/lib/python3.7/site-packages (from torch) (4.0.1+computecanada)
Installing collected packages: torch
Successfully installed torch-1.9.1+computecanada
Looking in links: /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/nix/avx2, /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/nix/generic, /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/transformers-2.5.1+computecanada-py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/boto3-1.20.52+computecanada-py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/tokenizers-0.5.2+computecanada-cp37-cp37m-linux_x86_64.whl
Requirement already satisfied: requests in /cvmfs/soft.computecanada.ca/easybuild/software/2017/Core/scipy-stack/2019a/lib/python3.7/site-packages (from transformers==2.5.1+computecanada) (2.21.0)
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/filelock-3.4.2+computecanada-py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/regex-2020.11.13+computecanada-cp37-cp37m-linux_x86_64.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/sacremoses-0.0.46+computecanada-py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/sentencepiece-0.1.91+computecanada-cp37-cp37m-linux_x86_64.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/tqdm-4.63.0+computecanada-py2.py3-none-any.whl
Requirement already satisfied: numpy in /cvmfs/soft.computecanada.ca/easybuild/software/2017/Core/scipy-stack/2019a/lib/python3.7/site-packages (from transformers==2.5.1+computecanada) (1.16.0)
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/s3transfer-0.5.1+computecanada-py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/botocore-1.23.52+computecanada-py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/jmespath-0.10.0+computecanada-py2.py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/urllib3-1.26.8+computecanada-py2.py3-none-any.whl
Requirement already satisfied: python-dateutil<3.0.0,>=2.1 in /cvmfs/soft.computecanada.ca/easybuild/software/2017/Core/scipy-stack/2019a/lib/python3.7/site-packages (from botocore<1.24.0,>=1.23.52->boto3->transformers==2.5.1+computecanada) (2.7.5)
Requirement already satisfied: six>=1.5 in /localscratch/yinan.28327867.0/env/lib/python3.7/site-packages (from python-dateutil<3.0.0,>=2.1->botocore<1.24.0,>=1.23.52->boto3->transformers==2.5.1+computecanada) (1.16.0+computecanada)
Requirement already satisfied: idna<2.9,>=2.5 in /cvmfs/soft.computecanada.ca/easybuild/software/2017/Core/scipy-stack/2019a/lib/python3.7/site-packages (from requests->transformers==2.5.1+computecanada) (2.8)
Requirement already satisfied: certifi>=2017.4.17 in /cvmfs/soft.computecanada.ca/easybuild/software/2017/Core/scipy-stack/2019a/lib/python3.7/site-packages (from requests->transformers==2.5.1+computecanada) (2018.11.29)
Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /cvmfs/soft.computecanada.ca/easybuild/software/2017/Core/scipy-stack/2019a/lib/python3.7/site-packages (from requests->transformers==2.5.1+computecanada) (3.0.4)
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/requests-2.27.1+computecanada-py2.py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/charset_normalizer-2.0.11+computecanada-py3-none-any.whl
Requirement already satisfied: click in /localscratch/yinan.28327867.0/env/lib/python3.7/site-packages (from sacremoses->transformers==2.5.1+computecanada) (8.0.3+computecanada)
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/joblib-1.1.0+computecanada-py2.py3-none-any.whl
Requirement already satisfied: importlib-metadata in /cvmfs/soft.computecanada.ca/easybuild/software/2017/Core/scipy-stack/2019a/lib/python3.7/site-packages (from click->sacremoses->transformers==2.5.1+computecanada) (0.8)
Requirement already satisfied: zipp>=0.3.2 in /cvmfs/soft.computecanada.ca/easybuild/software/2017/Core/scipy-stack/2019a/lib/python3.7/site-packages (from importlib-metadata->click->sacremoses->transformers==2.5.1+computecanada) (0.3.3)
Installing collected packages: urllib3, jmespath, botocore, tqdm, s3transfer, regex, joblib, charset-normalizer, tokenizers, sentencepiece, sacremoses, requests, filelock, boto3, transformers
  Attempting uninstall: urllib3
    Found existing installation: urllib3 1.24.1
    Not uninstalling urllib3 at /cvmfs/soft.computecanada.ca/easybuild/software/2017/Core/scipy-stack/2019a/lib/python3.7/site-packages, outside environment /localscratch/yinan.28327867.0/env
    Can't uninstall 'urllib3'. No files were found to uninstall.
  Attempting uninstall: requests
    Found existing installation: requests 2.21.0
    Not uninstalling requests at /cvmfs/soft.computecanada.ca/easybuild/software/2017/Core/scipy-stack/2019a/lib/python3.7/site-packages, outside environment /localscratch/yinan.28327867.0/env
    Can't uninstall 'requests'. No files were found to uninstall.
Successfully installed boto3-1.20.52+computecanada botocore-1.23.52+computecanada charset-normalizer-2.0.11+computecanada filelock-3.4.2+computecanada jmespath-0.10.0+computecanada joblib-1.1.0+computecanada regex-2020.11.13+computecanada requests-2.27.1+computecanada s3transfer-0.5.1+computecanada sacremoses-0.0.46+computecanada sentencepiece-0.1.91+computecanada tokenizers-0.5.2+computecanada tqdm-4.63.0+computecanada transformers-2.5.1+computecanada urllib3-1.26.8+computecanada
Looking in links: /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/nix/avx2, /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/nix/generic, /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/tensorflow_gpu-2.3.0+computecanada-cp37-cp37m-linux_x86_64.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/grpcio-1.38.0+computecanada-cp37-cp37m-linux_x86_64.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/astunparse-1.6.3+computecanada-py2.py3-none-any.whl
Requirement already satisfied: numpy<1.19.0,>=1.16.0 in /cvmfs/soft.computecanada.ca/easybuild/software/2017/Core/scipy-stack/2019a/lib/python3.7/site-packages (from tensorflow_gpu==2.3.0+computecanada) (1.16.0)
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/wrapt-1.11.2+computecanada-cp37-cp37m-linux_x86_64.whl
Requirement already satisfied: six>=1.12.0 in /localscratch/yinan.28327867.0/env/lib/python3.7/site-packages (from tensorflow_gpu==2.3.0+computecanada) (1.16.0+computecanada)
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/gast-0.3.3+computecanada-py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/Keras_Preprocessing-1.1.2+computecanada-py3-none-any.whl
Requirement already satisfied: termcolor>=1.1.0 in /localscratch/yinan.28327867.0/env/lib/python3.7/site-packages (from tensorflow_gpu==2.3.0+computecanada) (1.1.0+computecanada)
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/absl_py-1.0.0+computecanada-py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/nix/generic/scipy-1.4.1+computecanada-cp37-cp37m-linux_x86_64.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/tensorboard-2.8.0+computecanada-py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/opt_einsum-3.3.0+computecanada-py3-none-any.whl
Requirement already satisfied: protobuf>=3.9.2 in /localscratch/yinan.28327867.0/env/lib/python3.7/site-packages (from tensorflow_gpu==2.3.0+computecanada) (3.19.3+computecanada)
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/google_pasta-0.2.0+computecanada-py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/tensorflow_estimator-2.3.0+computecanada-py2.py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/nix/avx2/h5py-2.10.0+computecanada-cp37-cp37m-linux_x86_64.whl
Requirement already satisfied: wheel>=0.26 in /localscratch/yinan.28327867.0/env/lib/python3.7/site-packages (from tensorflow_gpu==2.3.0+computecanada) (0.33.4)
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/tensorboard_data_server-0.6.1+computecanada-py3-none-linux_x86_64.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/Werkzeug-2.0.3+computecanada-py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/tensorboard_plugin_wit-1.8.0+computecanada-py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/Markdown-3.3.6+computecanada-py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/google_auth_oauthlib-0.4.6+computecanada-py2.py3-none-any.whl
Requirement already satisfied: requests<3,>=2.21.0 in /localscratch/yinan.28327867.0/env/lib/python3.7/site-packages (from tensorboard<3,>=2.3.0->tensorflow_gpu==2.3.0+computecanada) (2.27.1+computecanada)
Requirement already satisfied: setuptools>=41.0.0 in /localscratch/yinan.28327867.0/env/lib/python3.7/site-packages (from tensorboard<3,>=2.3.0->tensorflow_gpu==2.3.0+computecanada) (41.0.1)
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/google_auth-2.3.3+computecanada-py2.py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/cachetools-4.2.4+computecanada-py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/rsa-4.8+computecanada-py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/pyasn1_modules-0.2.8+computecanada-py2.py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/requests_oauthlib-1.3.0+computecanada-py2.py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/importlib_metadata-4.10.1+computecanada-py3-none-any.whl
Requirement already satisfied: typing-extensions>=3.6.4 in /localscratch/yinan.28327867.0/env/lib/python3.7/site-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard<3,>=2.3.0->tensorflow_gpu==2.3.0+computecanada) (4.0.1+computecanada)
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/zipp-3.7.0+computecanada-py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/pyasn1-0.4.8+computecanada-py2.py3-none-any.whl
Requirement already satisfied: certifi>=2017.4.17 in /cvmfs/soft.computecanada.ca/easybuild/software/2017/Core/scipy-stack/2019a/lib/python3.7/site-packages (from requests<3,>=2.21.0->tensorboard<3,>=2.3.0->tensorflow_gpu==2.3.0+computecanada) (2018.11.29)
Requirement already satisfied: idna<4,>=2.5 in /cvmfs/soft.computecanada.ca/easybuild/software/2017/Core/scipy-stack/2019a/lib/python3.7/site-packages (from requests<3,>=2.21.0->tensorboard<3,>=2.3.0->tensorflow_gpu==2.3.0+computecanada) (2.8)
Requirement already satisfied: charset-normalizer~=2.0.0 in /localscratch/yinan.28327867.0/env/lib/python3.7/site-packages (from requests<3,>=2.21.0->tensorboard<3,>=2.3.0->tensorflow_gpu==2.3.0+computecanada) (2.0.11+computecanada)
Requirement already satisfied: urllib3<1.27,>=1.21.1 in /localscratch/yinan.28327867.0/env/lib/python3.7/site-packages (from requests<3,>=2.21.0->tensorboard<3,>=2.3.0->tensorflow_gpu==2.3.0+computecanada) (1.26.8+computecanada)
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/oauthlib-3.1.1+computecanada-py2.py3-none-any.whl
Installing collected packages: pyasn1, zipp, rsa, pyasn1-modules, oauthlib, cachetools, requests-oauthlib, importlib-metadata, google-auth, werkzeug, tensorboard-plugin-wit, tensorboard-data-server, markdown, grpcio, google-auth-oauthlib, absl-py, wrapt, tensorflow-estimator, tensorboard, scipy, opt-einsum, keras-preprocessing, h5py, google-pasta, gast, astunparse, tensorflow-gpu
  Attempting uninstall: pyasn1
    Found existing installation: pyasn1 0.4.3
    Not uninstalling pyasn1 at /cvmfs/soft.computecanada.ca/easybuild/software/2017/Core/scipy-stack/2019a/lib/python3.7/site-packages, outside environment /localscratch/yinan.28327867.0/env
    Can't uninstall 'pyasn1'. No files were found to uninstall.
  Attempting uninstall: zipp
    Found existing installation: zipp 0.3.3
    Not uninstalling zipp at /cvmfs/soft.computecanada.ca/easybuild/software/2017/Core/scipy-stack/2019a/lib/python3.7/site-packages, outside environment /localscratch/yinan.28327867.0/env
    Can't uninstall 'zipp'. No files were found to uninstall.
  Attempting uninstall: importlib-metadata
    Found existing installation: importlib-metadata 0.8
    Not uninstalling importlib-metadata at /cvmfs/soft.computecanada.ca/easybuild/software/2017/Core/scipy-stack/2019a/lib/python3.7/site-packages, outside environment /localscratch/yinan.28327867.0/env
    Can't uninstall 'importlib-metadata'. No files were found to uninstall.
  Attempting uninstall: scipy
    Found existing installation: scipy 1.2.0
    Not uninstalling scipy at /cvmfs/soft.computecanada.ca/easybuild/software/2017/Core/scipy-stack/2019a/lib/python3.7/site-packages, outside environment /localscratch/yinan.28327867.0/env
    Can't uninstall 'scipy'. No files were found to uninstall.
Successfully installed absl-py-1.0.0+computecanada astunparse-1.6.3+computecanada cachetools-4.2.4+computecanada gast-0.3.3+computecanada google-auth-2.3.3+computecanada google-auth-oauthlib-0.4.6+computecanada google-pasta-0.2.0+computecanada grpcio-1.38.0+computecanada h5py-2.10.0+computecanada importlib-metadata-4.10.1+computecanada keras-preprocessing-1.1.2+computecanada markdown-3.3.6+computecanada oauthlib-3.1.1+computecanada opt-einsum-3.3.0+computecanada pyasn1-0.4.8+computecanada pyasn1-modules-0.2.8+computecanada requests-oauthlib-1.3.0+computecanada rsa-4.8+computecanada scipy-1.4.1+computecanada tensorboard-2.8.0+computecanada tensorboard-data-server-0.6.1+computecanada tensorboard-plugin-wit-1.8.0+computecanada tensorflow-estimator-2.3.0+computecanada tensorflow-gpu-2.3.0+computecanada werkzeug-2.0.3+computecanada wrapt-1.11.2+computecanada zipp-3.7.0+computecanada
Looking in links: /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/nix/avx2, /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/nix/generic, /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/keras-2.8.0+computecanada-py2.py3-none-any.whl
Installing collected packages: Keras
Successfully installed Keras-2.8.0+computecanada
Looking in links: /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/nix/avx2, /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/nix/generic, /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/urllib3-1.26.7+computecanada-py2.py3-none-any.whl
Installing collected packages: urllib3
  Attempting uninstall: urllib3
    Found existing installation: urllib3 1.26.8+computecanada
    Uninstalling urllib3-1.26.8+computecanada:
      Successfully uninstalled urllib3-1.26.8+computecanada
Successfully installed urllib3-1.26.7+computecanada
Looking in links: /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/nix/avx2, /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/nix/generic, /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/nltk-3.7+computecanada-py3-none-any.whl
Requirement already satisfied: joblib in /localscratch/yinan.28327867.0/env/lib/python3.7/site-packages (from nltk) (1.1.0+computecanada)
Requirement already satisfied: tqdm in /localscratch/yinan.28327867.0/env/lib/python3.7/site-packages (from nltk) (4.63.0+computecanada)
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/nltk-3.6.5+computecanada-py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/nltk-3.6.3+computecanada-py3-none-any.whl
Requirement already satisfied: regex in /localscratch/yinan.28327867.0/env/lib/python3.7/site-packages (from nltk) (2020.11.13+computecanada)
Requirement already satisfied: click in /localscratch/yinan.28327867.0/env/lib/python3.7/site-packages (from nltk) (8.0.3+computecanada)
Requirement already satisfied: importlib-metadata in /localscratch/yinan.28327867.0/env/lib/python3.7/site-packages (from click->nltk) (4.10.1+computecanada)
Requirement already satisfied: zipp>=0.5 in /localscratch/yinan.28327867.0/env/lib/python3.7/site-packages (from importlib-metadata->click->nltk) (3.7.0+computecanada)
Requirement already satisfied: typing-extensions>=3.6.4 in /localscratch/yinan.28327867.0/env/lib/python3.7/site-packages (from importlib-metadata->click->nltk) (4.0.1+computecanada)
Installing collected packages: nltk
Successfully installed nltk-3.6.3+computecanada
Looking in links: /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/nix/avx2, /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/nix/generic, /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/scikit_learn-0.22.1+computecanada-cp37-cp37m-linux_x86_64.whl
Requirement already satisfied: joblib>=0.11 in /localscratch/yinan.28327867.0/env/lib/python3.7/site-packages (from scikit-learn==0.22.1) (1.1.0+computecanada)
Requirement already satisfied: scipy>=0.17.0 in /localscratch/yinan.28327867.0/env/lib/python3.7/site-packages (from scikit-learn==0.22.1) (1.4.1+computecanada)
Requirement already satisfied: numpy>=1.11.0 in /cvmfs/soft.computecanada.ca/easybuild/software/2017/Core/scipy-stack/2019a/lib/python3.7/site-packages (from scikit-learn==0.22.1) (1.16.0)
Installing collected packages: scikit-learn
Successfully installed scikit-learn-0.22.1+computecanada
Looking in links: /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/nix/avx2, /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/nix/generic, /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic
Requirement already satisfied: tokenizers==0.5.2 in /localscratch/yinan.28327867.0/env/lib/python3.7/site-packages (0.5.2+computecanada)
wandb: Appending key for api.wandb.ai to your netrc file: /home/yinan/.netrc
Starting Task
2022-03-06 01:32:55.232861: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1
[nltk_data] Downloading package stopwords to /home/yinan/nltk_data...
[nltk_data]   Package stopwords is already up-to-date!
[nltk_data] Downloading package wordnet to /home/yinan/nltk_data...
[nltk_data]   Package wordnet is already up-to-date!
wandb: Currently logged in as: yinanazhou (use `wandb login --relogin` to force relogin)
wandb: wandb version 0.12.11 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
2022-03-06 01:33:03.561752: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1
wandb: Tracking run with wandb version 0.12.5
wandb: Syncing run playful-snowball-2
wandb: ⭐️ View project at https://wandb.ai/yinanazhou/xl_512_bs_8_lr_1e06_es_25_lc_True_nr_True_stem_False_lemma_False_repeat_1_fold_1
wandb: 🚀 View run at https://wandb.ai/yinanazhou/xl_512_bs_8_lr_1e06_es_25_lc_True_nr_True_stem_False_lemma_False_repeat_1_fold_1/runs/1uuhxycr
wandb: Run data is saved locally in /project/6002780/yinan/Thesis_MER_Lyrics/lyric-emotion/wandb/run-20220306_013301-1uuhxycr
wandb: Run `wandb offline` to turn off syncing.

Validation loss decreased (inf --> 1.383586).  Saving model ...
Validation loss decreased (1.383586 --> 1.343331).  Saving model ...
Validation loss decreased (1.343331 --> 1.324520).  Saving model ...
Validation loss decreased (1.324520 --> 1.300737).  Saving model ...
Validation loss decreased (1.300737 --> 1.279243).  Saving model ...
Validation loss decreased (1.279243 --> 1.260654).  Saving model ...
Validation loss decreased (1.260654 --> 1.243697).  Saving model ...
EarlyStopping counter: 1 out of 25.0
Validation loss decreased (1.243697 --> 1.212058).  Saving model ...
Validation loss decreased (1.212058 --> 1.188203).  Saving model ...
Validation loss decreased (1.188203 --> 1.166604).  Saving model ...
Validation loss decreased (1.166604 --> 1.137374).  Saving model ...
Validation loss decreased (1.137374 --> 1.118331).  Saving model ...
Validation loss decreased (1.118331 --> 1.094287).  Saving model ...
Validation loss decreased (1.094287 --> 1.075554).  Saving model ...
Validation loss decreased (1.075554 --> 1.074469).  Saving model ...
Validation loss decreased (1.074469 --> 1.063259).  Saving model ...
Validation loss decreased (1.063259 --> 1.048414).  Saving model ...
Validation loss decreased (1.048414 --> 1.035492).  Saving model ...
Validation loss decreased (1.035492 --> 1.029556).  Saving model ...
EarlyStopping counter: 1 out of 25.0
Validation loss decreased (1.029556 --> 1.023290).  Saving model ...
Validation loss decreased (1.023290 --> 1.020398).  Saving model ...
EarlyStopping counter: 1 out of 25.0
EarlyStopping counter: 2 out of 25.0
EarlyStopping counter: 3 out of 25.0
EarlyStopping counter: 4 out of 25.0
Validation loss decreased (1.020398 --> 1.020373).  Saving model ...
EarlyStopping counter: 1 out of 25.0
EarlyStopping counter: 2 out of 25.0
Validation loss decreased (1.020373 --> 1.014273).  Saving model ...
EarlyStopping counter: 1 out of 25.0
EarlyStopping counter: 2 out of 25.0
EarlyStopping counter: 3 out of 25.0
EarlyStopping counter: 4 out of 25.0
EarlyStopping counter: 5 out of 25.0
EarlyStopping counter: 6 out of 25.0
EarlyStopping counter: 7 out of 25.0
EarlyStopping counter: 8 out of 25.0
EarlyStopping counter: 9 out of 25.0
EarlyStopping counter: 10 out of 25.0
EarlyStopping counter: 11 out of 25.0
EarlyStopping counter: 12 out of 25.0
EarlyStopping counter: 13 out of 25.0
EarlyStopping counter: 14 out of 25.0
EarlyStopping counter: 15 out of 25.0
EarlyStopping counter: 16 out of 25.0
EarlyStopping counter: 17 out of 25.0
EarlyStopping counter: 18 out of 25.0
EarlyStopping counter: 19 out of 25.0
EarlyStopping counter: 20 out of 25.0
EarlyStopping counter: 21 out of 25.0
EarlyStopping counter: 22 out of 25.0
EarlyStopping counter: 23 out of 25.0
EarlyStopping counter: 24 out of 25.0
EarlyStopping counter: 25 out of 25.0
/localscratch/yinan.28327867.0/env/lib/python3.7/site-packages/torch/nn/functional.py:1794: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.
  warnings.warn("nn.functional.tanh is deprecated. Use torch.tanh instead.")
/localscratch/yinan.28327867.0/env/lib/python3.7/site-packages/transformers/optimization.py:155: UserWarning: This overload of add_ is deprecated:
	add_(Number alpha, Tensor other)
Consider using one of the following signatures instead:
	add_(Tensor other, *, Number alpha) (Triggered internally at  ../torch/csrc/utils/python_arg_parser.cpp:1025.)
  exp_avg.mul_(beta1).add_(1.0 - beta1, grad)
wandb: Waiting for W&B process to finish, PID 144091... (success).
wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: \ 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: | 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: / 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb:                                                                                
wandb: Run history:
wandb:     e_F1 ▁▃▄▄▅▅▅▅▆▆▇▇▇▇▇▇▇▇▇▇█▇█▇████████████████
wandb:   e_loss █▇▇▆▆▅▅▄▃▃▂▂▂▁▁▁▁▁▂▁▁▁▁▁▁▁▁▂▁▂▂▂▃▃▃▃▃▄▄▄
wandb:     t_F1 ▁▂▂▃▃▃▄▄▅▄▅▅▅▅▅▆▆▆▆▆▆▆▇▇▇▇▇▇▇▇▇▇████████
wandb:   t_loss ██▇▇▇▇▆▆▆▆▅▅▅▅▄▄▄▄▄▄▃▃▃▃▃▃▂▂▂▂▂▂▂▂▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:     e_F1 58.24255
wandb:   e_loss 1.19854
wandb:     t_F1 97.47125
wandb:   t_loss 0.17486
wandb: 
wandb: Synced 4 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Synced playful-snowball-2: https://wandb.ai/yinanazhou/xl_512_bs_8_lr_1e06_es_25_lc_True_nr_True_stem_False_lemma_False_repeat_1_fold_1/runs/1uuhxycr
wandb: Find logs at: ./wandb/run-20220306_013301-1uuhxycr/logs/debug.log
wandb: 

wandb: wandb version 0.12.11 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
2022-03-06 02:24:59.447211: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1
wandb: Tracking run with wandb version 0.12.5
wandb: Syncing run dauntless-sea-2
wandb: ⭐️ View project at https://wandb.ai/yinanazhou/xl_512_bs_8_lr_1e06_es_25_lc_True_nr_True_stem_False_lemma_False_repeat_1_fold_2
wandb: 🚀 View run at https://wandb.ai/yinanazhou/xl_512_bs_8_lr_1e06_es_25_lc_True_nr_True_stem_False_lemma_False_repeat_1_fold_2/runs/31utrynt
wandb: Run data is saved locally in /project/6002780/yinan/Thesis_MER_Lyrics/lyric-emotion/wandb/run-20220306_022456-31utrynt
wandb: Run `wandb offline` to turn off syncing.

Validation loss decreased (inf --> 1.387621).  Saving model ...
Validation loss decreased (1.387621 --> 1.344768).  Saving model ...
Validation loss decreased (1.344768 --> 1.321430).  Saving model ...
Validation loss decreased (1.321430 --> 1.309338).  Saving model ...
Validation loss decreased (1.309338 --> 1.300780).  Saving model ...
Validation loss decreased (1.300780 --> 1.289137).  Saving model ...
Validation loss decreased (1.289137 --> 1.273013).  Saving model ...
Validation loss decreased (1.273013 --> 1.253627).  Saving model ...
Validation loss decreased (1.253627 --> 1.241252).  Saving model ...
Validation loss decreased (1.241252 --> 1.210674).  Saving model ...
Validation loss decreased (1.210674 --> 1.192665).  Saving model ...
Validation loss decreased (1.192665 --> 1.157598).  Saving model ...
Validation loss decreased (1.157598 --> 1.144191).  Saving model ...
Validation loss decreased (1.144191 --> 1.113285).  Saving model ...
Validation loss decreased (1.113285 --> 1.089393).  Saving model ...
Validation loss decreased (1.089393 --> 1.067508).  Saving model ...
Validation loss decreased (1.067508 --> 1.056885).  Saving model ...
Validation loss decreased (1.056885 --> 1.033913).  Saving model ...
Validation loss decreased (1.033913 --> 1.017137).  Saving model ...
Validation loss decreased (1.017137 --> 1.001539).  Saving model ...
Validation loss decreased (1.001539 --> 0.987135).  Saving model ...
Validation loss decreased (0.987135 --> 0.972954).  Saving model ...
Validation loss decreased (0.972954 --> 0.970622).  Saving model ...
Validation loss decreased (0.970622 --> 0.953864).  Saving model ...
EarlyStopping counter: 1 out of 25.0
Validation loss decreased (0.953864 --> 0.952942).  Saving model ...
Validation loss decreased (0.952942 --> 0.948644).  Saving model ...
EarlyStopping counter: 1 out of 25.0
EarlyStopping counter: 2 out of 25.0
EarlyStopping counter: 3 out of 25.0
EarlyStopping counter: 4 out of 25.0
EarlyStopping counter: 5 out of 25.0
EarlyStopping counter: 6 out of 25.0
EarlyStopping counter: 7 out of 25.0
EarlyStopping counter: 8 out of 25.0
EarlyStopping counter: 9 out of 25.0
EarlyStopping counter: 10 out of 25.0
EarlyStopping counter: 11 out of 25.0
EarlyStopping counter: 12 out of 25.0
EarlyStopping counter: 13 out of 25.0
EarlyStopping counter: 14 out of 25.0
EarlyStopping counter: 15 out of 25.0
EarlyStopping counter: 16 out of 25.0
EarlyStopping counter: 17 out of 25.0
EarlyStopping counter: 18 out of 25.0
EarlyStopping counter: 19 out of 25.0
EarlyStopping counter: 20 out of 25.0
EarlyStopping counter: 21 out of 25.0
EarlyStopping counter: 22 out of 25.0
EarlyStopping counter: 23 out of 25.0
EarlyStopping counter: 24 out of 25.0
EarlyStopping counter: 25 out of 25.0
/localscratch/yinan.28327867.0/env/lib/python3.7/site-packages/torch/nn/functional.py:1794: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.
  warnings.warn("nn.functional.tanh is deprecated. Use torch.tanh instead.")
wandb: Waiting for W&B process to finish, PID 147012... (success).
wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: \ 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: | 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: / 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: \ 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: | 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: / 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: \ 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: | 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: / 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb:                                                                                
wandb: Run history:
wandb:     e_F1 ▁▃▄▄▃▄▅▅▅▆▆▇▇▇▇████▇█████▇███▇█▇█▇▇█████
wandb:   e_loss █▇▇▇▆▆▆▅▅▄▄▃▃▂▂▂▂▁▁▁▁▁▁▁▁▁▂▂▂▂▃▃▃▃▄▄▄▅▅▅
wandb:     t_F1 ▁▁▂▂▂▂▃▃▃▄▄▄▄▅▅▅▅▆▅▆▆▆▆▆▆▆▇▇▇▇▇▇▇███████
wandb:   t_loss ████▇▇▇▇▇▇▆▆▆▅▅▅▅▅▄▄▄▄▄▃▃▃▃▃▃▂▂▂▂▂▂▂▁▁▁▁
wandb: 
wandb: Run summary:
wandb:     e_F1 57.98287
wandb:   e_loss 1.21029
wandb:     t_F1 97.0411
wandb:   t_loss 0.18098
wandb: 
wandb: Synced 4 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Synced dauntless-sea-2: https://wandb.ai/yinanazhou/xl_512_bs_8_lr_1e06_es_25_lc_True_nr_True_stem_False_lemma_False_repeat_1_fold_2/runs/31utrynt
wandb: Find logs at: ./wandb/run-20220306_022456-31utrynt/logs/debug.log
wandb: 

wandb: wandb version 0.12.11 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
2022-03-06 03:12:55.483773: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1
wandb: Tracking run with wandb version 0.12.5
wandb: Syncing run stilted-dragon-2
wandb: ⭐️ View project at https://wandb.ai/yinanazhou/xl_512_bs_8_lr_1e06_es_25_lc_True_nr_True_stem_False_lemma_False_repeat_2_fold_1
wandb: 🚀 View run at https://wandb.ai/yinanazhou/xl_512_bs_8_lr_1e06_es_25_lc_True_nr_True_stem_False_lemma_False_repeat_2_fold_1/runs/54yhe34s
wandb: Run data is saved locally in /project/6002780/yinan/Thesis_MER_Lyrics/lyric-emotion/wandb/run-20220306_031251-54yhe34s
wandb: Run `wandb offline` to turn off syncing.

Validation loss decreased (inf --> 1.392726).  Saving model ...
Validation loss decreased (1.392726 --> 1.376467).  Saving model ...
Validation loss decreased (1.376467 --> 1.354362).  Saving model ...
Validation loss decreased (1.354362 --> 1.317834).  Saving model ...
Validation loss decreased (1.317834 --> 1.278950).  Saving model ...
Validation loss decreased (1.278950 --> 1.241979).  Saving model ...
Validation loss decreased (1.241979 --> 1.208591).  Saving model ...
Validation loss decreased (1.208591 --> 1.170390).  Saving model ...
Validation loss decreased (1.170390 --> 1.145288).  Saving model ...
Validation loss decreased (1.145288 --> 1.121126).  Saving model ...
Validation loss decreased (1.121126 --> 1.089766).  Saving model ...
Validation loss decreased (1.089766 --> 1.058585).  Saving model ...
Validation loss decreased (1.058585 --> 1.044134).  Saving model ...
Validation loss decreased (1.044134 --> 1.030960).  Saving model ...
Validation loss decreased (1.030960 --> 1.002867).  Saving model ...
Validation loss decreased (1.002867 --> 0.997523).  Saving model ...
Validation loss decreased (0.997523 --> 0.985072).  Saving model ...
Validation loss decreased (0.985072 --> 0.979002).  Saving model ...
EarlyStopping counter: 1 out of 25.0
EarlyStopping counter: 2 out of 25.0
EarlyStopping counter: 3 out of 25.0
Validation loss decreased (0.979002 --> 0.968563).  Saving model ...
EarlyStopping counter: 1 out of 25.0
EarlyStopping counter: 2 out of 25.0
EarlyStopping counter: 3 out of 25.0
EarlyStopping counter: 4 out of 25.0
EarlyStopping counter: 5 out of 25.0
EarlyStopping counter: 6 out of 25.0
EarlyStopping counter: 7 out of 25.0
EarlyStopping counter: 8 out of 25.0
EarlyStopping counter: 9 out of 25.0
EarlyStopping counter: 10 out of 25.0
EarlyStopping counter: 11 out of 25.0
EarlyStopping counter: 12 out of 25.0
EarlyStopping counter: 13 out of 25.0
EarlyStopping counter: 14 out of 25.0
EarlyStopping counter: 15 out of 25.0
EarlyStopping counter: 16 out of 25.0
EarlyStopping counter: 17 out of 25.0
EarlyStopping counter: 18 out of 25.0
EarlyStopping counter: 19 out of 25.0
EarlyStopping counter: 20 out of 25.0
EarlyStopping counter: 21 out of 25.0
EarlyStopping counter: 22 out of 25.0
EarlyStopping counter: 23 out of 25.0
EarlyStopping counter: 24 out of 25.0
EarlyStopping counter: 25 out of 25.0
/localscratch/yinan.28327867.0/env/lib/python3.7/site-packages/torch/nn/functional.py:1794: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.
  warnings.warn("nn.functional.tanh is deprecated. Use torch.tanh instead.")
wandb: Waiting for W&B process to finish, PID 149626... (success).
wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: \ 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: | 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: / 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: \ 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: | 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: / 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: \ 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: | 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: / 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb:                                                                                
wandb: Run history:
wandb:     e_F1 ▁▃▃▄▄▅▆▆▆▇▇▇█▇██▇█████████████▇▇▇█▇██▇▇▇
wandb:   e_loss ██▇▇▆▆▄▄▄▃▂▂▂▁▁▁▁▁▁▁▁▁▁▂▂▂▂▂▃▃▃▄▄▄▅▄▅▅▆▆
wandb:     t_F1 ▁▂▂▃▃▃▄▄▄▅▅▅▅▆▅▆▆▆▆▆▆▆▇▇▇▇▇▇▇▇▇█████████
wandb:   t_loss ███▇▇▇▇▆▆▆▆▅▅▅▅▄▄▄▄▄▃▃▃▃▃▃▂▂▂▂▂▂▂▂▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:     e_F1 55.94036
wandb:   e_loss 1.26688
wandb:     t_F1 99.14892
wandb:   t_loss 0.12943
wandb: 
wandb: Synced 4 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Synced stilted-dragon-2: https://wandb.ai/yinanazhou/xl_512_bs_8_lr_1e06_es_25_lc_True_nr_True_stem_False_lemma_False_repeat_2_fold_1/runs/54yhe34s
wandb: Find logs at: ./wandb/run-20220306_031251-54yhe34s/logs/debug.log
wandb: 

wandb: wandb version 0.12.11 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
2022-03-06 03:56:16.748290: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1
wandb: Tracking run with wandb version 0.12.5
wandb: Syncing run magic-morning-2
wandb: ⭐️ View project at https://wandb.ai/yinanazhou/xl_512_bs_8_lr_1e06_es_25_lc_True_nr_True_stem_False_lemma_False_repeat_2_fold_2
wandb: 🚀 View run at https://wandb.ai/yinanazhou/xl_512_bs_8_lr_1e06_es_25_lc_True_nr_True_stem_False_lemma_False_repeat_2_fold_2/runs/23tj283k
wandb: Run data is saved locally in /project/6002780/yinan/Thesis_MER_Lyrics/lyric-emotion/wandb/run-20220306_035613-23tj283k
wandb: Run `wandb offline` to turn off syncing.

Validation loss decreased (inf --> 1.394961).  Saving model ...
Validation loss decreased (1.394961 --> 1.358680).  Saving model ...
Validation loss decreased (1.358680 --> 1.338489).  Saving model ...
Validation loss decreased (1.338489 --> 1.318098).  Saving model ...
Validation loss decreased (1.318098 --> 1.293797).  Saving model ...
Validation loss decreased (1.293797 --> 1.266126).  Saving model ...
Validation loss decreased (1.266126 --> 1.240562).  Saving model ...
Validation loss decreased (1.240562 --> 1.220927).  Saving model ...
Validation loss decreased (1.220927 --> 1.182259).  Saving model ...
Validation loss decreased (1.182259 --> 1.150769).  Saving model ...
Validation loss decreased (1.150769 --> 1.126671).  Saving model ...
Validation loss decreased (1.126671 --> 1.101764).  Saving model ...
Validation loss decreased (1.101764 --> 1.078286).  Saving model ...
Validation loss decreased (1.078286 --> 1.053692).  Saving model ...
EarlyStopping counter: 1 out of 25.0
Validation loss decreased (1.053692 --> 1.019406).  Saving model ...
Validation loss decreased (1.019406 --> 1.016342).  Saving model ...
Validation loss decreased (1.016342 --> 0.986151).  Saving model ...
Validation loss decreased (0.986151 --> 0.985772).  Saving model ...
Validation loss decreased (0.985772 --> 0.963254).  Saving model ...
EarlyStopping counter: 1 out of 25.0
Validation loss decreased (0.963254 --> 0.953946).  Saving model ...
Validation loss decreased (0.953946 --> 0.952156).  Saving model ...
Validation loss decreased (0.952156 --> 0.950266).  Saving model ...
EarlyStopping counter: 1 out of 25.0
EarlyStopping counter: 2 out of 25.0
EarlyStopping counter: 3 out of 25.0
EarlyStopping counter: 4 out of 25.0
EarlyStopping counter: 5 out of 25.0
EarlyStopping counter: 6 out of 25.0
EarlyStopping counter: 7 out of 25.0
EarlyStopping counter: 8 out of 25.0
EarlyStopping counter: 9 out of 25.0
EarlyStopping counter: 10 out of 25.0
EarlyStopping counter: 11 out of 25.0
EarlyStopping counter: 12 out of 25.0
EarlyStopping counter: 13 out of 25.0
EarlyStopping counter: 14 out of 25.0
EarlyStopping counter: 15 out of 25.0
EarlyStopping counter: 16 out of 25.0
EarlyStopping counter: 17 out of 25.0
EarlyStopping counter: 18 out of 25.0
EarlyStopping counter: 19 out of 25.0
EarlyStopping counter: 20 out of 25.0
EarlyStopping counter: 21 out of 25.0
EarlyStopping counter: 22 out of 25.0
EarlyStopping counter: 23 out of 25.0
EarlyStopping counter: 24 out of 25.0
EarlyStopping counter: 25 out of 25.0
/localscratch/yinan.28327867.0/env/lib/python3.7/site-packages/torch/nn/functional.py:1794: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.
  warnings.warn("nn.functional.tanh is deprecated. Use torch.tanh instead.")
wandb: Waiting for W&B process to finish, PID 151967... (success).
wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: \ 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: | 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: / 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: \ 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: | 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: / 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: \ 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: | 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: / 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: \ 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: | 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: / 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: \ 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: | 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: / 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: \ 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: | 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: / 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: \ 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: | 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: / 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: \ 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: | 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: / 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: \ 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: | 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: / 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: \ 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: | 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: / 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: \ 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: | 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: / 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: \ 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: | 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: / 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: \ 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: | 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: / 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: \ 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: | 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: / 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: \ 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: | 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: / 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: \ 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: | 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: / 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: \ 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: | 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: / 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: \ 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: | 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: / 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: \ 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: | 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: / 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: \ 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: | 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: / 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: \ 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: | 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: / 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: \ 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: | 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb:                                                                                
wandb: Run history:
wandb:     e_F1 ▁▂▃▃▄▅▆▆▇▇▇▇▇███████████████████████████
wandb:   e_loss █▇▇▇▆▆▅▅▄▃▃▃▃▂▂▂▁▁▁▁▁▁▁▁▁▁▁▂▂▂▂▂▂▃▃▃▄▄▄▅
wandb:     t_F1 ▁▁▁▂▃▃▃▃▃▄▄▅▅▅▅▅▅▆▆▆▆▆▆▆▆▇▇▇▇▇▇█████████
wandb:   t_loss ███▇▇▇▇▇▆▆▆▆▅▅▅▅▄▄▄▄▄▄▃▃▃▃▃▂▂▂▂▂▂▂▂▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:     e_F1 59.96774
wandb:   e_loss 1.18011
wandb:     t_F1 97.89645
wandb:   t_loss 0.16979
wandb: 
wandb: Synced 4 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Synced magic-morning-2: https://wandb.ai/yinanazhou/xl_512_bs_8_lr_1e06_es_25_lc_True_nr_True_stem_False_lemma_False_repeat_2_fold_2/runs/23tj283k
wandb: Find logs at: ./wandb/run-20220306_035613-23tj283k/logs/debug.log
wandb: 

wandb: wandb version 0.12.11 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
2022-03-06 04:41:26.746099: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1
wandb: Tracking run with wandb version 0.12.5
wandb: Syncing run clean-breeze-2
wandb: ⭐️ View project at https://wandb.ai/yinanazhou/xl_512_bs_8_lr_1e06_es_25_lc_True_nr_True_stem_False_lemma_False_repeat_3_fold_1
wandb: 🚀 View run at https://wandb.ai/yinanazhou/xl_512_bs_8_lr_1e06_es_25_lc_True_nr_True_stem_False_lemma_False_repeat_3_fold_1/runs/14nvsa8q
wandb: Run data is saved locally in /project/6002780/yinan/Thesis_MER_Lyrics/lyric-emotion/wandb/run-20220306_044123-14nvsa8q
wandb: Run `wandb offline` to turn off syncing.

Validation loss decreased (inf --> 1.386430).  Saving model ...
Validation loss decreased (1.386430 --> 1.370087).  Saving model ...
Validation loss decreased (1.370087 --> 1.349161).  Saving model ...
Validation loss decreased (1.349161 --> 1.327192).  Saving model ...
Validation loss decreased (1.327192 --> 1.306633).  Saving model ...
Validation loss decreased (1.306633 --> 1.284384).  Saving model ...
Validation loss decreased (1.284384 --> 1.265369).  Saving model ...
EarlyStopping counter: 1 out of 25.0
Validation loss decreased (1.265369 --> 1.235329).  Saving model ...
Validation loss decreased (1.235329 --> 1.221863).  Saving model ...
Validation loss decreased (1.221863 --> 1.199474).  Saving model ...
Validation loss decreased (1.199474 --> 1.182209).  Saving model ...
Validation loss decreased (1.182209 --> 1.157022).  Saving model ...
Validation loss decreased (1.157022 --> 1.141790).  Saving model ...
Validation loss decreased (1.141790 --> 1.119675).  Saving model ...
Validation loss decreased (1.119675 --> 1.104026).  Saving model ...
Validation loss decreased (1.104026 --> 1.089889).  Saving model ...
Validation loss decreased (1.089889 --> 1.079921).  Saving model ...
Validation loss decreased (1.079921 --> 1.067075).  Saving model ...
Validation loss decreased (1.067075 --> 1.050950).  Saving model ...
Validation loss decreased (1.050950 --> 1.039294).  Saving model ...
Validation loss decreased (1.039294 --> 1.010834).  Saving model ...
EarlyStopping counter: 1 out of 25.0
EarlyStopping counter: 2 out of 25.0
EarlyStopping counter: 3 out of 25.0
EarlyStopping counter: 4 out of 25.0
EarlyStopping counter: 5 out of 25.0
EarlyStopping counter: 6 out of 25.0
EarlyStopping counter: 7 out of 25.0
EarlyStopping counter: 8 out of 25.0
EarlyStopping counter: 9 out of 25.0
EarlyStopping counter: 10 out of 25.0
EarlyStopping counter: 11 out of 25.0
EarlyStopping counter: 12 out of 25.0
EarlyStopping counter: 13 out of 25.0
EarlyStopping counter: 14 out of 25.0
EarlyStopping counter: 15 out of 25.0
EarlyStopping counter: 16 out of 25.0
EarlyStopping counter: 17 out of 25.0
EarlyStopping counter: 18 out of 25.0
EarlyStopping counter: 19 out of 25.0
EarlyStopping counter: 20 out of 25.0
EarlyStopping counter: 21 out of 25.0
EarlyStopping counter: 22 out of 25.0
EarlyStopping counter: 23 out of 25.0
EarlyStopping counter: 24 out of 25.0
EarlyStopping counter: 25 out of 25.0
/localscratch/yinan.28327867.0/env/lib/python3.7/site-packages/torch/nn/functional.py:1794: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.
  warnings.warn("nn.functional.tanh is deprecated. Use torch.tanh instead.")
wandb: Waiting for W&B process to finish, PID 154425... (success).
wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: \ 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: | 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: / 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: \ 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: | 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: / 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: \ 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: | 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: / 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb:                                                                                
wandb: Run history:
wandb:     e_F1 ▁▃▃▄▄▄▄▅▅▅▅▆▆▇▇▇▇██▇██▇▇██▇▇████████████
wandb:   e_loss ██▇▇▇▆▆▅▅▅▄▄▃▃▂▂▂▂▁▁▁▁▂▁▁▁▁▁▁▁▂▁▂▂▂▂▂▃▃▃
wandb:     t_F1 ▁▂▂▂▂▃▃▄▃▄▄▄▄▅▅▅▆▆▆▆▆▆▆▇▇▇▇▇▇▇▇▇▇███████
wandb:   t_loss ████▇▇▇▇▆▆▆▆▅▅▅▅▄▄▄▄▄▄▄▃▃▃▃▃▃▂▂▂▂▂▂▂▁▁▁▁
wandb: 
wandb: Run summary:
wandb:     e_F1 59.63919
wandb:   e_loss 1.10827
wandb:     t_F1 95.53055
wandb:   t_loss 0.23113
wandb: 
wandb: Synced 4 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Synced clean-breeze-2: https://wandb.ai/yinanazhou/xl_512_bs_8_lr_1e06_es_25_lc_True_nr_True_stem_False_lemma_False_repeat_3_fold_1/runs/14nvsa8q
wandb: Find logs at: ./wandb/run-20220306_044123-14nvsa8q/logs/debug.log
wandb: 

wandb: wandb version 0.12.11 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
2022-03-06 05:24:57.900995: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1
wandb: Tracking run with wandb version 0.12.5
wandb: Syncing run skilled-butterfly-2
wandb: ⭐️ View project at https://wandb.ai/yinanazhou/xl_512_bs_8_lr_1e06_es_25_lc_True_nr_True_stem_False_lemma_False_repeat_3_fold_2
wandb: 🚀 View run at https://wandb.ai/yinanazhou/xl_512_bs_8_lr_1e06_es_25_lc_True_nr_True_stem_False_lemma_False_repeat_3_fold_2/runs/f9ib6853
wandb: Run data is saved locally in /project/6002780/yinan/Thesis_MER_Lyrics/lyric-emotion/wandb/run-20220306_052455-f9ib6853
wandb: Run `wandb offline` to turn off syncing.

Validation loss decreased (inf --> 1.371643).  Saving model ...
Validation loss decreased (1.371643 --> 1.360049).  Saving model ...
Validation loss decreased (1.360049 --> 1.342520).  Saving model ...
Validation loss decreased (1.342520 --> 1.323162).  Saving model ...
Validation loss decreased (1.323162 --> 1.297059).  Saving model ...
Validation loss decreased (1.297059 --> 1.275471).  Saving model ...
Validation loss decreased (1.275471 --> 1.243250).  Saving model ...
Validation loss decreased (1.243250 --> 1.210700).  Saving model ...
Validation loss decreased (1.210700 --> 1.188629).  Saving model ...
Validation loss decreased (1.188629 --> 1.151148).  Saving model ...
Validation loss decreased (1.151148 --> 1.114723).  Saving model ...
Validation loss decreased (1.114723 --> 1.085235).  Saving model ...
Validation loss decreased (1.085235 --> 1.063676).  Saving model ...
Validation loss decreased (1.063676 --> 1.036615).  Saving model ...
Validation loss decreased (1.036615 --> 1.019125).  Saving model ...
Validation loss decreased (1.019125 --> 1.005577).  Saving model ...
Validation loss decreased (1.005577 --> 0.985613).  Saving model ...
Validation loss decreased (0.985613 --> 0.975384).  Saving model ...
Validation loss decreased (0.975384 --> 0.963049).  Saving model ...
Validation loss decreased (0.963049 --> 0.961714).  Saving model ...
Validation loss decreased (0.961714 --> 0.948978).  Saving model ...
Validation loss decreased (0.948978 --> 0.943518).  Saving model ...
Validation loss decreased (0.943518 --> 0.937923).  Saving model ...
EarlyStopping counter: 1 out of 25.0
EarlyStopping counter: 2 out of 25.0
EarlyStopping counter: 3 out of 25.0
EarlyStopping counter: 4 out of 25.0
EarlyStopping counter: 5 out of 25.0
EarlyStopping counter: 6 out of 25.0
EarlyStopping counter: 7 out of 25.0
EarlyStopping counter: 8 out of 25.0
EarlyStopping counter: 9 out of 25.0
EarlyStopping counter: 10 out of 25.0
EarlyStopping counter: 11 out of 25.0
EarlyStopping counter: 12 out of 25.0
EarlyStopping counter: 13 out of 25.0
EarlyStopping counter: 14 out of 25.0
EarlyStopping counter: 15 out of 25.0
EarlyStopping counter: 16 out of 25.0
EarlyStopping counter: 17 out of 25.0
EarlyStopping counter: 18 out of 25.0
EarlyStopping counter: 19 out of 25.0
EarlyStopping counter: 20 out of 25.0
EarlyStopping counter: 21 out of 25.0
EarlyStopping counter: 22 out of 25.0
EarlyStopping counter: 23 out of 25.0
EarlyStopping counter: 24 out of 25.0
EarlyStopping counter: 25 out of 25.0
/localscratch/yinan.28327867.0/env/lib/python3.7/site-packages/torch/nn/functional.py:1794: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.
  warnings.warn("nn.functional.tanh is deprecated. Use torch.tanh instead.")
wandb: Waiting for W&B process to finish, PID 156765... (success).
wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: \ 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: | 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: / 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: \ 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: | 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: / 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: \ 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: | 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: / 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: \ 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb:                                                                                
wandb: Run history:
wandb:     e_F1 ▁▂▃▃▃▅▅▅▆▆▇▇▇▇▇█▇███████▇███████████████
wandb:   e_loss ███▇▇▆▅▅▄▄▃▃▂▂▂▁▁▁▁▁▁▁▁▁▁▂▂▂▂▂▂▂▃▂▃▃▃▃▄▄
wandb:     t_F1 ▁▂▂▂▃▃▃▄▄▄▅▅▅▅▅▆▆▆▆▆▆▆▆▆▇▇▇▇▇▇▇▇▇▇▇█████
wandb:   t_loss ████▇▇▇▇▆▆▆▆▅▅▅▄▄▄▄▄▃▃▃▃▃▃▃▃▂▂▂▂▂▂▂▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:     e_F1 60.47125
wandb:   e_loss 1.10659
wandb:     t_F1 93.8727
wandb:   t_loss 0.25647
wandb: 
wandb: Synced 4 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Synced skilled-butterfly-2: https://wandb.ai/yinanazhou/xl_512_bs_8_lr_1e06_es_25_lc_True_nr_True_stem_False_lemma_False_repeat_3_fold_2/runs/f9ib6853
wandb: Find logs at: ./wandb/run-20220306_052455-f9ib6853/logs/debug.log
wandb: 

wandb: wandb version 0.12.11 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
2022-03-06 06:09:27.019914: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1
wandb: Tracking run with wandb version 0.12.5
wandb: Syncing run gentle-flower-2
wandb: ⭐️ View project at https://wandb.ai/yinanazhou/xl_512_bs_8_lr_1e06_es_25_lc_True_nr_True_stem_False_lemma_False_repeat_4_fold_1
wandb: 🚀 View run at https://wandb.ai/yinanazhou/xl_512_bs_8_lr_1e06_es_25_lc_True_nr_True_stem_False_lemma_False_repeat_4_fold_1/runs/9qbj2poc
wandb: Run data is saved locally in /project/6002780/yinan/Thesis_MER_Lyrics/lyric-emotion/wandb/run-20220306_060924-9qbj2poc
wandb: Run `wandb offline` to turn off syncing.

Validation loss decreased (inf --> 1.383646).  Saving model ...
Validation loss decreased (1.383646 --> 1.360119).  Saving model ...
Validation loss decreased (1.360119 --> 1.345297).  Saving model ...
Validation loss decreased (1.345297 --> 1.327066).  Saving model ...
Validation loss decreased (1.327066 --> 1.304599).  Saving model ...
Validation loss decreased (1.304599 --> 1.281428).  Saving model ...
Validation loss decreased (1.281428 --> 1.259898).  Saving model ...
Validation loss decreased (1.259898 --> 1.228339).  Saving model ...
Validation loss decreased (1.228339 --> 1.202260).  Saving model ...
Validation loss decreased (1.202260 --> 1.199431).  Saving model ...
Validation loss decreased (1.199431 --> 1.155200).  Saving model ...
Validation loss decreased (1.155200 --> 1.141024).  Saving model ...
Validation loss decreased (1.141024 --> 1.112252).  Saving model ...
Validation loss decreased (1.112252 --> 1.102907).  Saving model ...
Validation loss decreased (1.102907 --> 1.090893).  Saving model ...
Validation loss decreased (1.090893 --> 1.063685).  Saving model ...
Validation loss decreased (1.063685 --> 1.048790).  Saving model ...
Validation loss decreased (1.048790 --> 1.027502).  Saving model ...
Validation loss decreased (1.027502 --> 1.014965).  Saving model ...
Validation loss decreased (1.014965 --> 1.004175).  Saving model ...
Validation loss decreased (1.004175 --> 0.992970).  Saving model ...
Validation loss decreased (0.992970 --> 0.975332).  Saving model ...
Validation loss decreased (0.975332 --> 0.971740).  Saving model ...
Validation loss decreased (0.971740 --> 0.963878).  Saving model ...
Validation loss decreased (0.963878 --> 0.951475).  Saving model ...
EarlyStopping counter: 1 out of 25.0
Validation loss decreased (0.951475 --> 0.949322).  Saving model ...
EarlyStopping counter: 1 out of 25.0
EarlyStopping counter: 2 out of 25.0
Validation loss decreased (0.949322 --> 0.936913).  Saving model ...
EarlyStopping counter: 1 out of 25.0
EarlyStopping counter: 2 out of 25.0
EarlyStopping counter: 3 out of 25.0
EarlyStopping counter: 4 out of 25.0
EarlyStopping counter: 5 out of 25.0
EarlyStopping counter: 6 out of 25.0
EarlyStopping counter: 7 out of 25.0
EarlyStopping counter: 8 out of 25.0
EarlyStopping counter: 9 out of 25.0
EarlyStopping counter: 10 out of 25.0
EarlyStopping counter: 11 out of 25.0
EarlyStopping counter: 12 out of 25.0
EarlyStopping counter: 13 out of 25.0
EarlyStopping counter: 14 out of 25.0
EarlyStopping counter: 15 out of 25.0
EarlyStopping counter: 16 out of 25.0
EarlyStopping counter: 17 out of 25.0
EarlyStopping counter: 18 out of 25.0
EarlyStopping counter: 19 out of 25.0
EarlyStopping counter: 20 out of 25.0
EarlyStopping counter: 21 out of 25.0
EarlyStopping counter: 22 out of 25.0
EarlyStopping counter: 23 out of 25.0
EarlyStopping counter: 24 out of 25.0
EarlyStopping counter: 25 out of 25.0
/localscratch/yinan.28327867.0/env/lib/python3.7/site-packages/torch/nn/functional.py:1794: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.
  warnings.warn("nn.functional.tanh is deprecated. Use torch.tanh instead.")
wandb: Waiting for W&B process to finish, PID 159167... (success).
wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: \ 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: | 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: / 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: \ 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: | 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: / 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: \ 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: | 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: / 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb:                                                                                
wandb: Run history:
wandb:     e_F1 ▁▂▃▄▅▅▆▆▆▇▆▆▇▇▇▇████████████████████████
wandb:   e_loss ██▇▇▆▆▅▅▄▄▄▃▃▂▂▂▂▁▁▁▁▁▁▁▁▂▁▂▂▂▂▂▂▃▃▄▄▄▄▅
wandb:     t_F1 ▁▁▂▂▂▃▃▄▄▄▄▅▅▅▅▅▆▆▆▆▆▆▆▇▇▇▇▇▇▇▇▇████████
wandb:   t_loss ███▇▇▇▇▇▆▆▆▆▅▅▅▅▅▄▄▄▄▄▃▃▃▃▃▃▂▂▂▂▂▂▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:     e_F1 60.52322
wandb:   e_loss 1.17699
wandb:     t_F1 97.27047
wandb:   t_loss 0.14875
wandb: 
wandb: Synced 4 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Synced gentle-flower-2: https://wandb.ai/yinanazhou/xl_512_bs_8_lr_1e06_es_25_lc_True_nr_True_stem_False_lemma_False_repeat_4_fold_1/runs/9qbj2poc
wandb: Find logs at: ./wandb/run-20220306_060924-9qbj2poc/logs/debug.log
wandb: 

wandb: wandb version 0.12.11 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
2022-03-06 07:00:30.791155: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1
wandb: Tracking run with wandb version 0.12.5
wandb: Syncing run fiery-disco-2
wandb: ⭐️ View project at https://wandb.ai/yinanazhou/xl_512_bs_8_lr_1e06_es_25_lc_True_nr_True_stem_False_lemma_False_repeat_4_fold_2
wandb: 🚀 View run at https://wandb.ai/yinanazhou/xl_512_bs_8_lr_1e06_es_25_lc_True_nr_True_stem_False_lemma_False_repeat_4_fold_2/runs/3238pijn
wandb: Run data is saved locally in /project/6002780/yinan/Thesis_MER_Lyrics/lyric-emotion/wandb/run-20220306_070027-3238pijn
wandb: Run `wandb offline` to turn off syncing.

Validation loss decreased (inf --> 1.371169).  Saving model ...
Validation loss decreased (1.371169 --> 1.349220).  Saving model ...
Validation loss decreased (1.349220 --> 1.333900).  Saving model ...
Validation loss decreased (1.333900 --> 1.320257).  Saving model ...
Validation loss decreased (1.320257 --> 1.309602).  Saving model ...
Validation loss decreased (1.309602 --> 1.283655).  Saving model ...
Validation loss decreased (1.283655 --> 1.242139).  Saving model ...
Validation loss decreased (1.242139 --> 1.209231).  Saving model ...
Validation loss decreased (1.209231 --> 1.180927).  Saving model ...
Validation loss decreased (1.180927 --> 1.146589).  Saving model ...
Validation loss decreased (1.146589 --> 1.118918).  Saving model ...
Validation loss decreased (1.118918 --> 1.089446).  Saving model ...
Validation loss decreased (1.089446 --> 1.070233).  Saving model ...
Validation loss decreased (1.070233 --> 1.048647).  Saving model ...
Validation loss decreased (1.048647 --> 1.046311).  Saving model ...
Validation loss decreased (1.046311 --> 1.024380).  Saving model ...
Validation loss decreased (1.024380 --> 1.009044).  Saving model ...
Validation loss decreased (1.009044 --> 1.006418).  Saving model ...
Validation loss decreased (1.006418 --> 0.995486).  Saving model ...
Validation loss decreased (0.995486 --> 0.993210).  Saving model ...
EarlyStopping counter: 1 out of 25.0
Validation loss decreased (0.993210 --> 0.968671).  Saving model ...
EarlyStopping counter: 1 out of 25.0
EarlyStopping counter: 2 out of 25.0
EarlyStopping counter: 3 out of 25.0
EarlyStopping counter: 4 out of 25.0
EarlyStopping counter: 5 out of 25.0
EarlyStopping counter: 6 out of 25.0
EarlyStopping counter: 7 out of 25.0
EarlyStopping counter: 8 out of 25.0
EarlyStopping counter: 9 out of 25.0
EarlyStopping counter: 10 out of 25.0
EarlyStopping counter: 11 out of 25.0
EarlyStopping counter: 12 out of 25.0
EarlyStopping counter: 13 out of 25.0
EarlyStopping counter: 14 out of 25.0
EarlyStopping counter: 15 out of 25.0
EarlyStopping counter: 16 out of 25.0
EarlyStopping counter: 17 out of 25.0
EarlyStopping counter: 18 out of 25.0
EarlyStopping counter: 19 out of 25.0
EarlyStopping counter: 20 out of 25.0
EarlyStopping counter: 21 out of 25.0
EarlyStopping counter: 22 out of 25.0
EarlyStopping counter: 23 out of 25.0
EarlyStopping counter: 24 out of 25.0
EarlyStopping counter: 25 out of 25.0
/localscratch/yinan.28327867.0/env/lib/python3.7/site-packages/torch/nn/functional.py:1794: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.
  warnings.warn("nn.functional.tanh is deprecated. Use torch.tanh instead.")
wandb: Waiting for W&B process to finish, PID 161936... (success).
wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: \ 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: | 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: / 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: \ 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: | 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: / 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: \ 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: | 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb:                                                                                
wandb: Run history:
wandb:     e_F1 ▁▂▃▃▄▄▄▅▆▆▆▇▇▇▇█████████████████████████
wandb:   e_loss ██▇▇▇▆▅▅▄▄▃▃▂▂▂▂▁▁▁▁▁▁▁▂▂▂▂▂▂▂▂▃▃▃▃▄▄▄▄▄
wandb:     t_F1 ▁▁▂▂▂▂▃▃▄▄▄▄▅▅▅▆▅▆▆▆▆▆▆▇▇▇▇▇▇▇▇▇█▇██████
wandb:   t_loss █████▇▇▇▇▆▆▆▅▅▅▅▅▄▄▄▄▄▃▃▃▃▃▃▂▂▂▂▂▂▂▂▁▁▁▁
wandb: 
wandb: Run summary:
wandb:     e_F1 62.23694
wandb:   e_loss 1.13709
wandb:     t_F1 97.03802
wandb:   t_loss 0.16444
wandb: 
wandb: Synced 4 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Synced fiery-disco-2: https://wandb.ai/yinanazhou/xl_512_bs_8_lr_1e06_es_25_lc_True_nr_True_stem_False_lemma_False_repeat_4_fold_2/runs/3238pijn
wandb: Find logs at: ./wandb/run-20220306_070027-3238pijn/logs/debug.log
wandb: 

wandb: wandb version 0.12.11 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
2022-03-06 07:44:05.968405: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1
wandb: Tracking run with wandb version 0.12.5
wandb: Syncing run youthful-dawn-2
wandb: ⭐️ View project at https://wandb.ai/yinanazhou/xl_512_bs_8_lr_1e06_es_25_lc_True_nr_True_stem_False_lemma_False_repeat_5_fold_1
wandb: 🚀 View run at https://wandb.ai/yinanazhou/xl_512_bs_8_lr_1e06_es_25_lc_True_nr_True_stem_False_lemma_False_repeat_5_fold_1/runs/3v3klswq
wandb: Run data is saved locally in /project/6002780/yinan/Thesis_MER_Lyrics/lyric-emotion/wandb/run-20220306_074403-3v3klswq
wandb: Run `wandb offline` to turn off syncing.

Validation loss decreased (inf --> 1.370389).  Saving model ...
Validation loss decreased (1.370389 --> 1.345048).  Saving model ...
Validation loss decreased (1.345048 --> 1.328846).  Saving model ...
Validation loss decreased (1.328846 --> 1.305775).  Saving model ...
Validation loss decreased (1.305775 --> 1.278599).  Saving model ...
Validation loss decreased (1.278599 --> 1.249365).  Saving model ...
Validation loss decreased (1.249365 --> 1.216243).  Saving model ...
Validation loss decreased (1.216243 --> 1.183075).  Saving model ...
Validation loss decreased (1.183075 --> 1.152986).  Saving model ...
Validation loss decreased (1.152986 --> 1.124209).  Saving model ...
Validation loss decreased (1.124209 --> 1.093524).  Saving model ...
Validation loss decreased (1.093524 --> 1.063675).  Saving model ...
Validation loss decreased (1.063675 --> 1.034119).  Saving model ...
Validation loss decreased (1.034119 --> 1.013780).  Saving model ...
Validation loss decreased (1.013780 --> 0.992547).  Saving model ...
Validation loss decreased (0.992547 --> 0.980687).  Saving model ...
Validation loss decreased (0.980687 --> 0.968859).  Saving model ...
Validation loss decreased (0.968859 --> 0.957734).  Saving model ...
Validation loss decreased (0.957734 --> 0.947864).  Saving model ...
Validation loss decreased (0.947864 --> 0.938852).  Saving model ...
Validation loss decreased (0.938852 --> 0.934192).  Saving model ...
Validation loss decreased (0.934192 --> 0.926663).  Saving model ...
Validation loss decreased (0.926663 --> 0.921613).  Saving model ...
EarlyStopping counter: 1 out of 25.0
EarlyStopping counter: 2 out of 25.0
Validation loss decreased (0.921613 --> 0.918537).  Saving model ...
EarlyStopping counter: 1 out of 25.0
EarlyStopping counter: 2 out of 25.0
EarlyStopping counter: 3 out of 25.0
EarlyStopping counter: 4 out of 25.0
EarlyStopping counter: 5 out of 25.0
EarlyStopping counter: 6 out of 25.0
EarlyStopping counter: 7 out of 25.0
EarlyStopping counter: 8 out of 25.0
EarlyStopping counter: 9 out of 25.0
EarlyStopping counter: 10 out of 25.0
EarlyStopping counter: 11 out of 25.0
EarlyStopping counter: 12 out of 25.0
EarlyStopping counter: 13 out of 25.0
EarlyStopping counter: 14 out of 25.0
EarlyStopping counter: 15 out of 25.0
EarlyStopping counter: 16 out of 25.0
EarlyStopping counter: 17 out of 25.0
EarlyStopping counter: 18 out of 25.0
EarlyStopping counter: 19 out of 25.0
EarlyStopping counter: 20 out of 25.0
EarlyStopping counter: 21 out of 25.0
EarlyStopping counter: 22 out of 25.0
EarlyStopping counter: 23 out of 25.0
EarlyStopping counter: 24 out of 25.0
EarlyStopping counter: 25 out of 25.0
/localscratch/yinan.28327867.0/env/lib/python3.7/site-packages/torch/nn/functional.py:1794: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.
  warnings.warn("nn.functional.tanh is deprecated. Use torch.tanh instead.")
wandb: Waiting for W&B process to finish, PID 164290... (success).
wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: \ 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: | 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: / 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: \ 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: | 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: / 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: \ 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: | 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: / 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb:                                                                                
wandb: Run history:
wandb:     e_F1 ▁▂▂▄▅▆▆▆▇▇▇█████████████████████████▇█▇▇
wandb:   e_loss ██▇▇▆▆▅▅▄▃▃▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▂▂▂▂▂▂▂▂▃▃▃▃▄▄
wandb:     t_F1 ▁▂▂▂▃▃▃▄▄▅▅▅▅▅▅▆▆▆▆▆▆▇▇▇▇▇▇▇▇▇▇█████████
wandb:   t_loss ████▇▇▇▆▆▆▆▅▅▅▅▄▄▄▄▄▄▃▃▃▃▃▂▂▂▂▂▂▂▂▂▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:     e_F1 58.16606
wandb:   e_loss 1.10498
wandb:     t_F1 97.89494
wandb:   t_loss 0.1534
wandb: 
wandb: Synced 4 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Synced youthful-dawn-2: https://wandb.ai/yinanazhou/xl_512_bs_8_lr_1e06_es_25_lc_True_nr_True_stem_False_lemma_False_repeat_5_fold_1/runs/3v3klswq
wandb: Find logs at: ./wandb/run-20220306_074403-3v3klswq/logs/debug.log
wandb: 

wandb: wandb version 0.12.11 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
2022-03-06 08:31:30.397490: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1
wandb: Tracking run with wandb version 0.12.5
wandb: Syncing run unique-brook-2
wandb: ⭐️ View project at https://wandb.ai/yinanazhou/xl_512_bs_8_lr_1e06_es_25_lc_True_nr_True_stem_False_lemma_False_repeat_5_fold_2
wandb: 🚀 View run at https://wandb.ai/yinanazhou/xl_512_bs_8_lr_1e06_es_25_lc_True_nr_True_stem_False_lemma_False_repeat_5_fold_2/runs/3mlw0gdc
wandb: Run data is saved locally in /project/6002780/yinan/Thesis_MER_Lyrics/lyric-emotion/wandb/run-20220306_083127-3mlw0gdc
wandb: Run `wandb offline` to turn off syncing.

Validation loss decreased (inf --> 1.379000).  Saving model ...
Validation loss decreased (1.379000 --> 1.361377).  Saving model ...
Validation loss decreased (1.361377 --> 1.348308).  Saving model ...
Validation loss decreased (1.348308 --> 1.333213).  Saving model ...
Validation loss decreased (1.333213 --> 1.313059).  Saving model ...
Validation loss decreased (1.313059 --> 1.286244).  Saving model ...
Validation loss decreased (1.286244 --> 1.260887).  Saving model ...
Validation loss decreased (1.260887 --> 1.233450).  Saving model ...
Validation loss decreased (1.233450 --> 1.206871).  Saving model ...
Validation loss decreased (1.206871 --> 1.192354).  Saving model ...
Validation loss decreased (1.192354 --> 1.170919).  Saving model ...
Validation loss decreased (1.170919 --> 1.138526).  Saving model ...
Validation loss decreased (1.138526 --> 1.120241).  Saving model ...
Validation loss decreased (1.120241 --> 1.086798).  Saving model ...
Validation loss decreased (1.086798 --> 1.076780).  Saving model ...
Validation loss decreased (1.076780 --> 1.070815).  Saving model ...
Validation loss decreased (1.070815 --> 1.053125).  Saving model ...
EarlyStopping counter: 1 out of 25.0
Validation loss decreased (1.053125 --> 1.031168).  Saving model ...
EarlyStopping counter: 1 out of 25.0
Validation loss decreased (1.031168 --> 1.002860).  Saving model ...
EarlyStopping counter: 1 out of 25.0
Validation loss decreased (1.002860 --> 0.984506).  Saving model ...
EarlyStopping counter: 1 out of 25.0
Validation loss decreased (0.984506 --> 0.966847).  Saving model ...
Validation loss decreased (0.966847 --> 0.959194).  Saving model ...
EarlyStopping counter: 1 out of 25.0
Validation loss decreased (0.959194 --> 0.956502).  Saving model ...
Validation loss decreased (0.956502 --> 0.951678).  Saving model ...
EarlyStopping counter: 1 out of 25.0
Validation loss decreased (0.951678 --> 0.947806).  Saving model ...
EarlyStopping counter: 1 out of 25.0
EarlyStopping counter: 2 out of 25.0
EarlyStopping counter: 3 out of 25.0
EarlyStopping counter: 4 out of 25.0
EarlyStopping counter: 5 out of 25.0
EarlyStopping counter: 6 out of 25.0
EarlyStopping counter: 7 out of 25.0
EarlyStopping counter: 8 out of 25.0
EarlyStopping counter: 9 out of 25.0
EarlyStopping counter: 10 out of 25.0
EarlyStopping counter: 11 out of 25.0
EarlyStopping counter: 12 out of 25.0
EarlyStopping counter: 13 out of 25.0
EarlyStopping counter: 14 out of 25.0
EarlyStopping counter: 15 out of 25.0
EarlyStopping counter: 16 out of 25.0
EarlyStopping counter: 17 out of 25.0
EarlyStopping counter: 18 out of 25.0
EarlyStopping counter: 19 out of 25.0
EarlyStopping counter: 20 out of 25.0
EarlyStopping counter: 21 out of 25.0
EarlyStopping counter: 22 out of 25.0
EarlyStopping counter: 23 out of 25.0
EarlyStopping counter: 24 out of 25.0
EarlyStopping counter: 25 out of 25.0
/localscratch/yinan.28327867.0/env/lib/python3.7/site-packages/torch/nn/functional.py:1794: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.
  warnings.warn("nn.functional.tanh is deprecated. Use torch.tanh instead.")
wandb: Waiting for W&B process to finish, PID 166870... (success).
wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: \ 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: | 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: / 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: \ 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: | 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: / 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: \ 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: | 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: / 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb:                                                                                
wandb: Run history:
wandb:     e_F1 ▁▂▄▅▅▅▆▆▆▆▇▇▇▇▆▇▇██████▇████████████████
wandb:   e_loss ██▇▇▆▆▅▅▄▄▃▃▃▂▂▂▂▂▁▁▁▁▁▁▁▂▁▁▂▂▂▂▃▃▃▃▅▄▅▅
wandb:     t_F1 ▁▁▁▂▂▃▃▃▄▄▅▅▅▅▅▅▅▆▆▆▆▆▆▆▇▇▇▇▇▇▇▇████████
wandb:   t_loss █████▇▇▇▆▆▆▆▅▅▅▅▅▄▄▄▄▄▃▃▃▃▃▃▂▂▂▂▂▂▂▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:     e_F1 58.97895
wandb:   e_loss 1.21352
wandb:     t_F1 98.51217
wandb:   t_loss 0.14158
wandb: 
wandb: Synced 4 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Synced unique-brook-2: https://wandb.ai/yinanazhou/xl_512_bs_8_lr_1e06_es_25_lc_True_nr_True_stem_False_lemma_False_repeat_5_fold_2/runs/3mlw0gdc
wandb: Find logs at: ./wandb/run-20220306_083127-3mlw0gdc/logs/debug.log
wandb: 

