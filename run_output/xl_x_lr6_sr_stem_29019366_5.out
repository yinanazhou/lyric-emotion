Unloading StdEnv/2020

Due to MODULEPATH changes, the following have been reloaded:
  1) mii/1.1.1


The following have been reloaded with a version change:
  1) python/3.8.2 => python/3.7.4

Using base prefix '/cvmfs/soft.computecanada.ca/easybuild/software/2017/Core/python/3.7.4'
New python executable in /localscratch/yinan.29200513.0/env/bin/python
Installing setuptools, pip, wheel...
done.
Ignoring pip: markers 'python_version < "3"' don't match your environment
Looking in links: /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/nix/avx2, /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/nix/generic, /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic
Collecting pip
Installing collected packages: pip
  Found existing installation: pip 19.1.1
    Uninstalling pip-19.1.1:
      Successfully uninstalled pip-19.1.1
Successfully installed pip-21.2.3+computecanada
Looking in links: /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/nix/avx2, /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/nix/generic, /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/keras-2.8.0+computecanada-py2.py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/Keras_Preprocessing-1.1.2+computecanada-py3-none-any.whl
Requirement already satisfied: matplotlib in /cvmfs/soft.computecanada.ca/easybuild/software/2017/Core/scipy-stack/2019a/lib/python3.7/site-packages (from -r requirements.txt (line 3)) (3.0.2)
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/nltk-3.6.5+computecanada-py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/scikit_learn-0.22.1+computecanada-cp37-cp37m-linux_x86_64.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/tensorboard-2.3.0+computecanada-py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/tensorboard_plugin_wit-1.7.0+computecanada-py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/tensorflow_gpu-2.3.0+computecanada-cp37-cp37m-linux_x86_64.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/tensorflow_estimator-2.3.0+computecanada-py2.py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/tokenizers-0.5.2+computecanada-cp37-cp37m-linux_x86_64.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/nix/avx2/torch-1.4.0+computecanada-cp37-cp37m-linux_x86_64.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/torchtext-0.6.0+computecanada-py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/torchvision-0.8.2+computecanada-cp37-cp37m-linux_x86_64.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/transformers-2.5.1+computecanada-py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/urllib3-1.26.7+computecanada-py2.py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/click-8.0.4+computecanada-py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/tqdm-4.63.0+computecanada-py2.py3-none-any.whl
ERROR: Could not find a version that satisfies the requirement regex>=2021.8.3 (from nltk) (from versions: 2018.1.10+computecanada, 2019.11.1+computecanada, 2020.11.13+computecanada)
ERROR: No matching distribution found for regex>=2021.8.3
Looking in links: /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/nix/avx2, /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/nix/generic, /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic
ERROR: Could not find a version that satisfies the requirement numpy==1.20.0+computacanada (from versions: 1.15.0+computecanada, 1.15.2+computecanada, 1.15.4+computecanada, 1.16.0+computecanada, 1.16.2+computecanada, 1.16.3+computecanada, 1.17.4+computecanada, 1.18.1+computecanada, 1.18.4+computecanada, 1.19.1+computecanada, 1.19.2+computecanada, 1.20.2+computecanada)
ERROR: No matching distribution found for numpy==1.20.0+computacanada
Looking in links: /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/nix/avx2, /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/nix/generic, /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/wandb-0.12.5+computecanada-py2.py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/PyYAML-5.3.1+computecanada-cp37-cp37m-linux_x86_64.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/pathtools-0.1.2+computecanada-py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/configparser-5.0.2+computecanada-py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/GitPython-3.1.24+computecanada-py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/docker_pycreds-0.4.0+computecanada-py2.py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/click-8.0.4+computecanada-py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/protobuf-3.19.4+computecanada-py2.py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/six-1.16.0+computecanada-py2.py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/subprocess32-3.5.4+computecanada-py3-none-any.whl
Requirement already satisfied: python-dateutil>=2.6.1 in /cvmfs/soft.computecanada.ca/easybuild/software/2017/Core/scipy-stack/2019a/lib/python3.7/site-packages (from wandb) (2.7.5)
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/shortuuid-1.0.1+computecanada-py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/sentry_sdk-1.5.0+computecanada-py2.py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/yaspin-2.1.0+computecanada-py3-none-any.whl
Requirement already satisfied: requests<3,>=2.0.0 in /cvmfs/soft.computecanada.ca/easybuild/software/2017/Core/scipy-stack/2019a/lib/python3.7/site-packages (from wandb) (2.21.0)
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/psutil-5.7.3+computecanada-cp37-cp37m-linux_x86_64.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/promise-2.3+computecanada-py3-none-any.whl
Requirement already satisfied: importlib-metadata in /cvmfs/soft.computecanada.ca/easybuild/software/2017/Core/scipy-stack/2019a/lib/python3.7/site-packages (from Click!=8.0.0,>=7.0->wandb) (0.8)
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/gitdb-4.0.9+computecanada-py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/typing_extensions-4.0.1+computecanada-py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/smmap-5.0.0+computecanada-py3-none-any.whl
Requirement already satisfied: certifi>=2017.4.17 in /cvmfs/soft.computecanada.ca/easybuild/software/2017/Core/scipy-stack/2019a/lib/python3.7/site-packages (from requests<3,>=2.0.0->wandb) (2018.11.29)
Requirement already satisfied: urllib3<1.25,>=1.21.1 in /cvmfs/soft.computecanada.ca/easybuild/software/2017/Core/scipy-stack/2019a/lib/python3.7/site-packages (from requests<3,>=2.0.0->wandb) (1.24.1)
Requirement already satisfied: idna<2.9,>=2.5 in /cvmfs/soft.computecanada.ca/easybuild/software/2017/Core/scipy-stack/2019a/lib/python3.7/site-packages (from requests<3,>=2.0.0->wandb) (2.8)
Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /cvmfs/soft.computecanada.ca/easybuild/software/2017/Core/scipy-stack/2019a/lib/python3.7/site-packages (from requests<3,>=2.0.0->wandb) (3.0.4)
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/termcolor-1.1.0+computecanada-py3-none-any.whl
Requirement already satisfied: zipp>=0.3.2 in /cvmfs/soft.computecanada.ca/easybuild/software/2017/Core/scipy-stack/2019a/lib/python3.7/site-packages (from importlib-metadata->Click!=8.0.0,>=7.0->wandb) (0.3.3)
Installing collected packages: smmap, typing-extensions, termcolor, six, gitdb, yaspin, subprocess32, shortuuid, sentry-sdk, PyYAML, psutil, protobuf, promise, pathtools, GitPython, docker-pycreds, configparser, Click, wandb
  Attempting uninstall: six
    Found existing installation: six 1.12.0
    Not uninstalling six at /cvmfs/soft.computecanada.ca/easybuild/software/2017/Core/scipy-stack/2019a/lib/python3.7/site-packages, outside environment /localscratch/yinan.29200513.0/env
    Can't uninstall 'six'. No files were found to uninstall.
Successfully installed Click-8.0.4+computecanada GitPython-3.1.24+computecanada PyYAML-5.3.1+computecanada configparser-5.0.2+computecanada docker-pycreds-0.4.0+computecanada gitdb-4.0.9+computecanada pathtools-0.1.2+computecanada promise-2.3+computecanada protobuf-3.19.4+computecanada psutil-5.7.3+computecanada sentry-sdk-1.5.0+computecanada shortuuid-1.0.1+computecanada six-1.16.0+computecanada smmap-5.0.0+computecanada subprocess32-3.5.4+computecanada termcolor-1.1.0+computecanada typing-extensions-4.0.1+computecanada wandb-0.12.5+computecanada yaspin-2.1.0+computecanada
Looking in links: /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/nix/avx2, /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/nix/generic, /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic
ERROR: Could not find a version that satisfies the requirement sagemaker (from versions: none)
ERROR: No matching distribution found for sagemaker
Looking in links: /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/nix/avx2, /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/nix/generic, /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/torch-1.9.1+computecanada-cp37-cp37m-linux_x86_64.whl
Requirement already satisfied: typing-extensions in /localscratch/yinan.29200513.0/env/lib/python3.7/site-packages (from torch) (4.0.1+computecanada)
Installing collected packages: torch
Successfully installed torch-1.9.1+computecanada
Looking in links: /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/nix/avx2, /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/nix/generic, /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/transformers-2.5.1+computecanada-py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/sacremoses-0.0.46+computecanada-py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/filelock-3.4.2+computecanada-py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/sentencepiece-0.1.91+computecanada-cp37-cp37m-linux_x86_64.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/tqdm-4.63.0+computecanada-py2.py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/regex-2020.11.13+computecanada-cp37-cp37m-linux_x86_64.whl
Requirement already satisfied: numpy in /cvmfs/soft.computecanada.ca/easybuild/software/2017/Core/scipy-stack/2019a/lib/python3.7/site-packages (from transformers==2.5.1+computecanada) (1.16.0)
Requirement already satisfied: requests in /cvmfs/soft.computecanada.ca/easybuild/software/2017/Core/scipy-stack/2019a/lib/python3.7/site-packages (from transformers==2.5.1+computecanada) (2.21.0)
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/tokenizers-0.5.2+computecanada-cp37-cp37m-linux_x86_64.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/boto3-1.21.14+computecanada-py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/s3transfer-0.5.1+computecanada-py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/jmespath-0.10.0+computecanada-py2.py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/botocore-1.24.14+computecanada-py3-none-any.whl
Requirement already satisfied: python-dateutil<3.0.0,>=2.1 in /cvmfs/soft.computecanada.ca/easybuild/software/2017/Core/scipy-stack/2019a/lib/python3.7/site-packages (from botocore<1.25.0,>=1.24.14->boto3->transformers==2.5.1+computecanada) (2.7.5)
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/urllib3-1.26.8+computecanada-py2.py3-none-any.whl
Requirement already satisfied: six>=1.5 in /localscratch/yinan.29200513.0/env/lib/python3.7/site-packages (from python-dateutil<3.0.0,>=2.1->botocore<1.25.0,>=1.24.14->boto3->transformers==2.5.1+computecanada) (1.16.0+computecanada)
Requirement already satisfied: certifi>=2017.4.17 in /cvmfs/soft.computecanada.ca/easybuild/software/2017/Core/scipy-stack/2019a/lib/python3.7/site-packages (from requests->transformers==2.5.1+computecanada) (2018.11.29)
Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /cvmfs/soft.computecanada.ca/easybuild/software/2017/Core/scipy-stack/2019a/lib/python3.7/site-packages (from requests->transformers==2.5.1+computecanada) (3.0.4)
Requirement already satisfied: idna<2.9,>=2.5 in /cvmfs/soft.computecanada.ca/easybuild/software/2017/Core/scipy-stack/2019a/lib/python3.7/site-packages (from requests->transformers==2.5.1+computecanada) (2.8)
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/requests-2.27.1+computecanada-py2.py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/charset_normalizer-2.0.12+computecanada-py3-none-any.whl
Requirement already satisfied: click in /localscratch/yinan.29200513.0/env/lib/python3.7/site-packages (from sacremoses->transformers==2.5.1+computecanada) (8.0.4+computecanada)
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/joblib-1.1.0+computecanada-py2.py3-none-any.whl
Requirement already satisfied: importlib-metadata in /cvmfs/soft.computecanada.ca/easybuild/software/2017/Core/scipy-stack/2019a/lib/python3.7/site-packages (from click->sacremoses->transformers==2.5.1+computecanada) (0.8)
Requirement already satisfied: zipp>=0.3.2 in /cvmfs/soft.computecanada.ca/easybuild/software/2017/Core/scipy-stack/2019a/lib/python3.7/site-packages (from importlib-metadata->click->sacremoses->transformers==2.5.1+computecanada) (0.3.3)
Installing collected packages: urllib3, jmespath, botocore, tqdm, s3transfer, regex, joblib, charset-normalizer, tokenizers, sentencepiece, sacremoses, requests, filelock, boto3, transformers
  Attempting uninstall: urllib3
    Found existing installation: urllib3 1.24.1
    Not uninstalling urllib3 at /cvmfs/soft.computecanada.ca/easybuild/software/2017/Core/scipy-stack/2019a/lib/python3.7/site-packages, outside environment /localscratch/yinan.29200513.0/env
    Can't uninstall 'urllib3'. No files were found to uninstall.
  Attempting uninstall: requests
    Found existing installation: requests 2.21.0
    Not uninstalling requests at /cvmfs/soft.computecanada.ca/easybuild/software/2017/Core/scipy-stack/2019a/lib/python3.7/site-packages, outside environment /localscratch/yinan.29200513.0/env
    Can't uninstall 'requests'. No files were found to uninstall.
Successfully installed boto3-1.21.14+computecanada botocore-1.24.14+computecanada charset-normalizer-2.0.12+computecanada filelock-3.4.2+computecanada jmespath-0.10.0+computecanada joblib-1.1.0+computecanada regex-2020.11.13+computecanada requests-2.27.1+computecanada s3transfer-0.5.1+computecanada sacremoses-0.0.46+computecanada sentencepiece-0.1.91+computecanada tokenizers-0.5.2+computecanada tqdm-4.63.0+computecanada transformers-2.5.1+computecanada urllib3-1.26.8+computecanada
Looking in links: /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/nix/avx2, /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/nix/generic, /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/tensorflow_gpu-2.3.0+computecanada-cp37-cp37m-linux_x86_64.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/absl_py-1.0.0+computecanada-py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/google_pasta-0.2.0+computecanada-py3-none-any.whl
Requirement already satisfied: protobuf>=3.9.2 in /localscratch/yinan.29200513.0/env/lib/python3.7/site-packages (from tensorflow_gpu==2.3.0+computecanada) (3.19.4+computecanada)
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/tensorboard-2.8.0+computecanada-py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/wrapt-1.11.2+computecanada-cp37-cp37m-linux_x86_64.whl
Requirement already satisfied: numpy<1.19.0,>=1.16.0 in /cvmfs/soft.computecanada.ca/easybuild/software/2017/Core/scipy-stack/2019a/lib/python3.7/site-packages (from tensorflow_gpu==2.3.0+computecanada) (1.16.0)
Requirement already satisfied: wheel>=0.26 in /localscratch/yinan.29200513.0/env/lib/python3.7/site-packages (from tensorflow_gpu==2.3.0+computecanada) (0.33.4)
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/tensorflow_estimator-2.3.0+computecanada-py2.py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/nix/avx2/h5py-2.10.0+computecanada-cp37-cp37m-linux_x86_64.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/nix/generic/scipy-1.4.1+computecanada-cp37-cp37m-linux_x86_64.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/Keras_Preprocessing-1.1.2+computecanada-py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/opt_einsum-3.3.0+computecanada-py3-none-any.whl
Requirement already satisfied: six>=1.12.0 in /localscratch/yinan.29200513.0/env/lib/python3.7/site-packages (from tensorflow_gpu==2.3.0+computecanada) (1.16.0+computecanada)
Requirement already satisfied: termcolor>=1.1.0 in /localscratch/yinan.29200513.0/env/lib/python3.7/site-packages (from tensorflow_gpu==2.3.0+computecanada) (1.1.0+computecanada)
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/gast-0.3.3+computecanada-py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/grpcio-1.38.0+computecanada-cp37-cp37m-linux_x86_64.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/astunparse-1.6.3+computecanada-py2.py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/google_auth_oauthlib-0.4.6+computecanada-py2.py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/google_auth-2.3.3+computecanada-py2.py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/tensorboard_plugin_wit-1.8.0+computecanada-py3-none-any.whl
Requirement already satisfied: setuptools>=41.0.0 in /localscratch/yinan.29200513.0/env/lib/python3.7/site-packages (from tensorboard<3,>=2.3.0->tensorflow_gpu==2.3.0+computecanada) (41.0.1)
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/Werkzeug-2.0.3+computecanada-py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/tensorboard_data_server-0.6.1+computecanada-py3-none-linux_x86_64.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/Markdown-3.3.6+computecanada-py3-none-any.whl
Requirement already satisfied: requests<3,>=2.21.0 in /localscratch/yinan.29200513.0/env/lib/python3.7/site-packages (from tensorboard<3,>=2.3.0->tensorflow_gpu==2.3.0+computecanada) (2.27.1+computecanada)
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/rsa-4.8+computecanada-py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/pyasn1_modules-0.2.8+computecanada-py2.py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/cachetools-4.2.4+computecanada-py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/requests_oauthlib-1.3.0+computecanada-py2.py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/importlib_metadata-4.10.1+computecanada-py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/zipp-3.7.0+computecanada-py3-none-any.whl
Requirement already satisfied: typing-extensions>=3.6.4 in /localscratch/yinan.29200513.0/env/lib/python3.7/site-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard<3,>=2.3.0->tensorflow_gpu==2.3.0+computecanada) (4.0.1+computecanada)
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/pyasn1-0.4.8+computecanada-py2.py3-none-any.whl
Requirement already satisfied: urllib3<1.27,>=1.21.1 in /localscratch/yinan.29200513.0/env/lib/python3.7/site-packages (from requests<3,>=2.21.0->tensorboard<3,>=2.3.0->tensorflow_gpu==2.3.0+computecanada) (1.26.8+computecanada)
Requirement already satisfied: idna<4,>=2.5 in /cvmfs/soft.computecanada.ca/easybuild/software/2017/Core/scipy-stack/2019a/lib/python3.7/site-packages (from requests<3,>=2.21.0->tensorboard<3,>=2.3.0->tensorflow_gpu==2.3.0+computecanada) (2.8)
Requirement already satisfied: certifi>=2017.4.17 in /cvmfs/soft.computecanada.ca/easybuild/software/2017/Core/scipy-stack/2019a/lib/python3.7/site-packages (from requests<3,>=2.21.0->tensorboard<3,>=2.3.0->tensorflow_gpu==2.3.0+computecanada) (2018.11.29)
Requirement already satisfied: charset-normalizer~=2.0.0 in /localscratch/yinan.29200513.0/env/lib/python3.7/site-packages (from requests<3,>=2.21.0->tensorboard<3,>=2.3.0->tensorflow_gpu==2.3.0+computecanada) (2.0.12+computecanada)
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/oauthlib-3.1.1+computecanada-py2.py3-none-any.whl
Installing collected packages: pyasn1, zipp, rsa, pyasn1-modules, oauthlib, cachetools, requests-oauthlib, importlib-metadata, google-auth, werkzeug, tensorboard-plugin-wit, tensorboard-data-server, markdown, grpcio, google-auth-oauthlib, absl-py, wrapt, tensorflow-estimator, tensorboard, scipy, opt-einsum, keras-preprocessing, h5py, google-pasta, gast, astunparse, tensorflow-gpu
  Attempting uninstall: pyasn1
    Found existing installation: pyasn1 0.4.3
    Not uninstalling pyasn1 at /cvmfs/soft.computecanada.ca/easybuild/software/2017/Core/scipy-stack/2019a/lib/python3.7/site-packages, outside environment /localscratch/yinan.29200513.0/env
    Can't uninstall 'pyasn1'. No files were found to uninstall.
  Attempting uninstall: zipp
    Found existing installation: zipp 0.3.3
    Not uninstalling zipp at /cvmfs/soft.computecanada.ca/easybuild/software/2017/Core/scipy-stack/2019a/lib/python3.7/site-packages, outside environment /localscratch/yinan.29200513.0/env
    Can't uninstall 'zipp'. No files were found to uninstall.
  Attempting uninstall: importlib-metadata
    Found existing installation: importlib-metadata 0.8
    Not uninstalling importlib-metadata at /cvmfs/soft.computecanada.ca/easybuild/software/2017/Core/scipy-stack/2019a/lib/python3.7/site-packages, outside environment /localscratch/yinan.29200513.0/env
    Can't uninstall 'importlib-metadata'. No files were found to uninstall.
  Attempting uninstall: scipy
    Found existing installation: scipy 1.2.0
    Not uninstalling scipy at /cvmfs/soft.computecanada.ca/easybuild/software/2017/Core/scipy-stack/2019a/lib/python3.7/site-packages, outside environment /localscratch/yinan.29200513.0/env
    Can't uninstall 'scipy'. No files were found to uninstall.
Successfully installed absl-py-1.0.0+computecanada astunparse-1.6.3+computecanada cachetools-4.2.4+computecanada gast-0.3.3+computecanada google-auth-2.3.3+computecanada google-auth-oauthlib-0.4.6+computecanada google-pasta-0.2.0+computecanada grpcio-1.38.0+computecanada h5py-2.10.0+computecanada importlib-metadata-4.10.1+computecanada keras-preprocessing-1.1.2+computecanada markdown-3.3.6+computecanada oauthlib-3.1.1+computecanada opt-einsum-3.3.0+computecanada pyasn1-0.4.8+computecanada pyasn1-modules-0.2.8+computecanada requests-oauthlib-1.3.0+computecanada rsa-4.8+computecanada scipy-1.4.1+computecanada tensorboard-2.8.0+computecanada tensorboard-data-server-0.6.1+computecanada tensorboard-plugin-wit-1.8.0+computecanada tensorflow-estimator-2.3.0+computecanada tensorflow-gpu-2.3.0+computecanada werkzeug-2.0.3+computecanada wrapt-1.11.2+computecanada zipp-3.7.0+computecanada
Looking in links: /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/nix/avx2, /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/nix/generic, /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/keras-2.8.0+computecanada-py2.py3-none-any.whl
Installing collected packages: Keras
Successfully installed Keras-2.8.0+computecanada
Looking in links: /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/nix/avx2, /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/nix/generic, /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/urllib3-1.26.7+computecanada-py2.py3-none-any.whl
Installing collected packages: urllib3
  Attempting uninstall: urllib3
    Found existing installation: urllib3 1.26.8+computecanada
    Uninstalling urllib3-1.26.8+computecanada:
      Successfully uninstalled urllib3-1.26.8+computecanada
Successfully installed urllib3-1.26.7+computecanada
Looking in links: /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/nix/avx2, /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/nix/generic, /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/nltk-3.7+computecanada-py3-none-any.whl
Requirement already satisfied: click in /localscratch/yinan.29200513.0/env/lib/python3.7/site-packages (from nltk) (8.0.4+computecanada)
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/nltk-3.6.5+computecanada-py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/nltk-3.6.3+computecanada-py3-none-any.whl
Requirement already satisfied: tqdm in /localscratch/yinan.29200513.0/env/lib/python3.7/site-packages (from nltk) (4.63.0+computecanada)
Requirement already satisfied: joblib in /localscratch/yinan.29200513.0/env/lib/python3.7/site-packages (from nltk) (1.1.0+computecanada)
Requirement already satisfied: regex in /localscratch/yinan.29200513.0/env/lib/python3.7/site-packages (from nltk) (2020.11.13+computecanada)
Requirement already satisfied: importlib-metadata in /localscratch/yinan.29200513.0/env/lib/python3.7/site-packages (from click->nltk) (4.10.1+computecanada)
Requirement already satisfied: typing-extensions>=3.6.4 in /localscratch/yinan.29200513.0/env/lib/python3.7/site-packages (from importlib-metadata->click->nltk) (4.0.1+computecanada)
Requirement already satisfied: zipp>=0.5 in /localscratch/yinan.29200513.0/env/lib/python3.7/site-packages (from importlib-metadata->click->nltk) (3.7.0+computecanada)
Installing collected packages: nltk
Successfully installed nltk-3.6.3+computecanada
Looking in links: /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/nix/avx2, /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/nix/generic, /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/scikit_learn-0.22.1+computecanada-cp37-cp37m-linux_x86_64.whl
Requirement already satisfied: numpy>=1.11.0 in /cvmfs/soft.computecanada.ca/easybuild/software/2017/Core/scipy-stack/2019a/lib/python3.7/site-packages (from scikit-learn==0.22.1) (1.16.0)
Requirement already satisfied: scipy>=0.17.0 in /localscratch/yinan.29200513.0/env/lib/python3.7/site-packages (from scikit-learn==0.22.1) (1.4.1+computecanada)
Requirement already satisfied: joblib>=0.11 in /localscratch/yinan.29200513.0/env/lib/python3.7/site-packages (from scikit-learn==0.22.1) (1.1.0+computecanada)
Installing collected packages: scikit-learn
Successfully installed scikit-learn-0.22.1+computecanada
Looking in links: /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/nix/avx2, /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/nix/generic, /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic
Requirement already satisfied: tokenizers==0.5.2 in /localscratch/yinan.29200513.0/env/lib/python3.7/site-packages (0.5.2+computecanada)
wandb: Appending key for api.wandb.ai to your netrc file: /home/yinan/.netrc
Starting Task
2022-03-18 19:48:12.339618: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1
[nltk_data] Downloading package stopwords to /home/yinan/nltk_data...
[nltk_data]   Package stopwords is already up-to-date!
[nltk_data] Downloading package wordnet to /home/yinan/nltk_data...
[nltk_data]   Package wordnet is already up-to-date!
wandb: Currently logged in as: yinanazhou (use `wandb login --relogin` to force relogin)
wandb: wandb version 0.12.11 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
2022-03-18 19:48:29.256953: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1
wandb: Tracking run with wandb version 0.12.5
wandb: Syncing run lively-plasma-2
wandb: ⭐️ View project at https://wandb.ai/yinanazhou/xl_512_bs_8_lr_1e06_es_5_lc_False_nr_False_sr_True_stem_True_lemma_False_repeat_1_fold_1
wandb: 🚀 View run at https://wandb.ai/yinanazhou/xl_512_bs_8_lr_1e06_es_5_lc_False_nr_False_sr_True_stem_True_lemma_False_repeat_1_fold_1/runs/u68u7o3l
wandb: Run data is saved locally in /project/6002780/yinan/Thesis_MER_Lyrics/lyric-emotion/wandb/run-20220318_194827-u68u7o3l
wandb: Run `wandb offline` to turn off syncing.

Validation loss decreased (inf --> 1.428336).  Saving model ...
Validation loss decreased (1.428336 --> 1.410090).  Saving model ...
Validation loss decreased (1.410090 --> 1.394581).  Saving model ...
Validation loss decreased (1.394581 --> 1.382553).  Saving model ...
Validation loss decreased (1.382553 --> 1.373312).  Saving model ...
Validation loss decreased (1.373312 --> 1.365093).  Saving model ...
Validation loss decreased (1.365093 --> 1.357848).  Saving model ...
Validation loss decreased (1.357848 --> 1.352315).  Saving model ...
Validation loss decreased (1.352315 --> 1.347384).  Saving model ...
Validation loss decreased (1.347384 --> 1.341819).  Saving model ...
Validation loss decreased (1.341819 --> 1.335825).  Saving model ...
Validation loss decreased (1.335825 --> 1.330865).  Saving model ...
Validation loss decreased (1.330865 --> 1.324781).  Saving model ...
Validation loss decreased (1.324781 --> 1.319466).  Saving model ...
Validation loss decreased (1.319466 --> 1.313526).  Saving model ...
Validation loss decreased (1.313526 --> 1.307974).  Saving model ...
Validation loss decreased (1.307974 --> 1.301574).  Saving model ...
Validation loss decreased (1.301574 --> 1.295002).  Saving model ...
Validation loss decreased (1.295002 --> 1.287915).  Saving model ...
Validation loss decreased (1.287915 --> 1.280906).  Saving model ...
Validation loss decreased (1.280906 --> 1.274137).  Saving model ...
Validation loss decreased (1.274137 --> 1.267608).  Saving model ...
Validation loss decreased (1.267608 --> 1.260766).  Saving model ...
Validation loss decreased (1.260766 --> 1.253186).  Saving model ...
Validation loss decreased (1.253186 --> 1.246624).  Saving model ...
Validation loss decreased (1.246624 --> 1.239379).  Saving model ...
Validation loss decreased (1.239379 --> 1.233142).  Saving model ...
Validation loss decreased (1.233142 --> 1.227383).  Saving model ...
Validation loss decreased (1.227383 --> 1.222111).  Saving model ...
Validation loss decreased (1.222111 --> 1.218019).  Saving model ...
Validation loss decreased (1.218019 --> 1.210569).  Saving model ...
Validation loss decreased (1.210569 --> 1.204863).  Saving model ...
Validation loss decreased (1.204863 --> 1.203193).  Saving model ...
Validation loss decreased (1.203193 --> 1.196775).  Saving model ...
Validation loss decreased (1.196775 --> 1.192703).  Saving model ...
Validation loss decreased (1.192703 --> 1.189213).  Saving model ...
Validation loss decreased (1.189213 --> 1.184962).  Saving model ...
Validation loss decreased (1.184962 --> 1.178914).  Saving model ...
Validation loss decreased (1.178914 --> 1.176458).  Saving model ...
Validation loss decreased (1.176458 --> 1.171284).  Saving model ...
Validation loss decreased (1.171284 --> 1.166732).  Saving model ...
Validation loss decreased (1.166732 --> 1.162547).  Saving model ...
Validation loss decreased (1.162547 --> 1.159377).  Saving model ...
Validation loss decreased (1.159377 --> 1.156974).  Saving model ...
Validation loss decreased (1.156974 --> 1.152956).  Saving model ...
Validation loss decreased (1.152956 --> 1.149144).  Saving model ...
Validation loss decreased (1.149144 --> 1.145337).  Saving model ...
Validation loss decreased (1.145337 --> 1.141879).  Saving model ...
Validation loss decreased (1.141879 --> 1.136632).  Saving model ...
Validation loss decreased (1.136632 --> 1.133573).  Saving model ...
Validation loss decreased (1.133573 --> 1.130473).  Saving model ...
Validation loss decreased (1.130473 --> 1.126623).  Saving model ...
Validation loss decreased (1.126623 --> 1.122893).  Saving model ...
Validation loss decreased (1.122893 --> 1.119330).  Saving model ...
Validation loss decreased (1.119330 --> 1.118278).  Saving model ...
Validation loss decreased (1.118278 --> 1.115033).  Saving model ...
Validation loss decreased (1.115033 --> 1.113060).  Saving model ...
Validation loss decreased (1.113060 --> 1.111896).  Saving model ...
Validation loss decreased (1.111896 --> 1.108335).  Saving model ...
Validation loss decreased (1.108335 --> 1.106651).  Saving model ...
Validation loss decreased (1.106651 --> 1.103776).  Saving model ...
Validation loss decreased (1.103776 --> 1.103452).  Saving model ...
Validation loss decreased (1.103452 --> 1.097789).  Saving model ...
Validation loss decreased (1.097789 --> 1.095956).  Saving model ...
EarlyStopping counter: 1 out of 5.0
Validation loss decreased (1.095956 --> 1.094321).  Saving model ...
Validation loss decreased (1.094321 --> 1.092769).  Saving model ...
Validation loss decreased (1.092769 --> 1.091682).  Saving model ...
Validation loss decreased (1.091682 --> 1.088289).  Saving model ...
Validation loss decreased (1.088289 --> 1.084520).  Saving model ...
Validation loss decreased (1.084520 --> 1.081349).  Saving model ...
Validation loss decreased (1.081349 --> 1.080218).  Saving model ...
Validation loss decreased (1.080218 --> 1.075985).  Saving model ...
Validation loss decreased (1.075985 --> 1.074257).  Saving model ...
Validation loss decreased (1.074257 --> 1.070610).  Saving model ...
EarlyStopping counter: 1 out of 5.0
EarlyStopping counter: 2 out of 5.0
EarlyStopping counter: 3 out of 5.0
Validation loss decreased (1.070610 --> 1.067180).  Saving model ...
Validation loss decreased (1.067180 --> 1.066260).  Saving model ...
Validation loss decreased (1.066260 --> 1.065961).  Saving model ...
Validation loss decreased (1.065961 --> 1.064425).  Saving model ...
Validation loss decreased (1.064425 --> 1.063727).  Saving model ...
Validation loss decreased (1.063727 --> 1.060416).  Saving model ...
Validation loss decreased (1.060416 --> 1.057384).  Saving model ...
Validation loss decreased (1.057384 --> 1.057142).  Saving model ...
EarlyStopping counter: 1 out of 5.0
EarlyStopping counter: 2 out of 5.0
Validation loss decreased (1.057142 --> 1.056663).  Saving model ...
Validation loss decreased (1.056663 --> 1.055487).  Saving model ...
Validation loss decreased (1.055487 --> 1.053208).  Saving model ...
Validation loss decreased (1.053208 --> 1.051571).  Saving model ...
Validation loss decreased (1.051571 --> 1.049869).  Saving model ...
EarlyStopping counter: 1 out of 5.0
EarlyStopping counter: 2 out of 5.0
Validation loss decreased (1.049869 --> 1.047207).  Saving model ...
EarlyStopping counter: 1 out of 5.0
EarlyStopping counter: 2 out of 5.0
Validation loss decreased (1.047207 --> 1.045383).  Saving model ...
EarlyStopping counter: 1 out of 5.0
EarlyStopping counter: 2 out of 5.0
EarlyStopping counter: 3 out of 5.0
Validation loss decreased (1.045383 --> 1.044297).  Saving model ...
EarlyStopping counter: 1 out of 5.0
EarlyStopping counter: 2 out of 5.0
EarlyStopping counter: 3 out of 5.0
Validation loss decreased (1.044297 --> 1.043381).  Saving model ...
EarlyStopping counter: 1 out of 5.0
Validation loss decreased (1.043381 --> 1.042279).  Saving model ...
Validation loss decreased (1.042279 --> 1.040701).  Saving model ...
EarlyStopping counter: 1 out of 5.0
EarlyStopping counter: 2 out of 5.0
EarlyStopping counter: 3 out of 5.0
EarlyStopping counter: 4 out of 5.0
EarlyStopping counter: 5 out of 5.0
/localscratch/yinan.29200513.0/env/lib/python3.7/site-packages/torch/nn/functional.py:1794: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.
  warnings.warn("nn.functional.tanh is deprecated. Use torch.tanh instead.")
/localscratch/yinan.29200513.0/env/lib/python3.7/site-packages/transformers/optimization.py:155: UserWarning: This overload of add_ is deprecated:
	add_(Number alpha, Tensor other)
Consider using one of the following signatures instead:
	add_(Tensor other, *, Number alpha) (Triggered internally at  ../torch/csrc/utils/python_arg_parser.cpp:1025.)
  exp_avg.mul_(beta1).add_(1.0 - beta1, grad)
wandb: Waiting for W&B process to finish, PID 141505... (success).
wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: \ 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: | 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: / 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: \ 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: | 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: / 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: \ 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: | 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb:                                                                                
wandb: Run history:
wandb:     e_F1 ▁▁▃▄▅▅▆▆▆▆▆▆▆▆▇▇▇▇▇▇▇▇▇█████████████████
wandb:   e_loss █▇▇▇▆▆▆▅▅▄▄▄▄▃▃▃▃▃▂▂▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:     t_F1 ▁▁▂▂▃▃▄▄▄▅▅▅▅▅▆▆▆▆▇▆▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇███
wandb:   t_loss ██▇▇▇▇▆▆▆▆▅▅▅▅▄▄▄▄▃▄▃▃▃▃▃▂▂▃▂▂▂▂▂▂▂▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:     e_F1 57.19331
wandb:   e_loss 1.0505
wandb:     t_F1 66.70888
wandb:   t_loss 0.80822
wandb: 
wandb: Synced 4 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Synced lively-plasma-2: https://wandb.ai/yinanazhou/xl_512_bs_8_lr_1e06_es_5_lc_False_nr_False_sr_True_stem_True_lemma_False_repeat_1_fold_1/runs/u68u7o3l
wandb: Find logs at: ./wandb/run-20220318_194827-u68u7o3l/logs/debug.log
wandb: 

wandb: wandb version 0.12.11 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
2022-03-18 21:02:49.677193: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1
wandb: Tracking run with wandb version 0.12.5
wandb: Syncing run toasty-morning-2
wandb: ⭐️ View project at https://wandb.ai/yinanazhou/xl_512_bs_8_lr_1e06_es_5_lc_False_nr_False_sr_True_stem_True_lemma_False_repeat_1_fold_2
wandb: 🚀 View run at https://wandb.ai/yinanazhou/xl_512_bs_8_lr_1e06_es_5_lc_False_nr_False_sr_True_stem_True_lemma_False_repeat_1_fold_2/runs/3d59w1ua
wandb: Run data is saved locally in /project/6002780/yinan/Thesis_MER_Lyrics/lyric-emotion/wandb/run-20220318_210247-3d59w1ua
wandb: Run `wandb offline` to turn off syncing.

Validation loss decreased (inf --> 1.413313).  Saving model ...
Validation loss decreased (1.413313 --> 1.401693).  Saving model ...
Validation loss decreased (1.401693 --> 1.393451).  Saving model ...
Validation loss decreased (1.393451 --> 1.387100).  Saving model ...
Validation loss decreased (1.387100 --> 1.381204).  Saving model ...
Validation loss decreased (1.381204 --> 1.376505).  Saving model ...
Validation loss decreased (1.376505 --> 1.372410).  Saving model ...
Validation loss decreased (1.372410 --> 1.367993).  Saving model ...
Validation loss decreased (1.367993 --> 1.364125).  Saving model ...
Validation loss decreased (1.364125 --> 1.360458).  Saving model ...
Validation loss decreased (1.360458 --> 1.356989).  Saving model ...
Validation loss decreased (1.356989 --> 1.353271).  Saving model ...
Validation loss decreased (1.353271 --> 1.349473).  Saving model ...
Validation loss decreased (1.349473 --> 1.345782).  Saving model ...
Validation loss decreased (1.345782 --> 1.342336).  Saving model ...
Validation loss decreased (1.342336 --> 1.338574).  Saving model ...
Validation loss decreased (1.338574 --> 1.334745).  Saving model ...
Validation loss decreased (1.334745 --> 1.330593).  Saving model ...
Validation loss decreased (1.330593 --> 1.325783).  Saving model ...
Validation loss decreased (1.325783 --> 1.321162).  Saving model ...
Validation loss decreased (1.321162 --> 1.316217).  Saving model ...
Validation loss decreased (1.316217 --> 1.311799).  Saving model ...
Validation loss decreased (1.311799 --> 1.306590).  Saving model ...
Validation loss decreased (1.306590 --> 1.301309).  Saving model ...
Validation loss decreased (1.301309 --> 1.296484).  Saving model ...
Validation loss decreased (1.296484 --> 1.290053).  Saving model ...
Validation loss decreased (1.290053 --> 1.284624).  Saving model ...
Validation loss decreased (1.284624 --> 1.278158).  Saving model ...
Validation loss decreased (1.278158 --> 1.272227).  Saving model ...
Validation loss decreased (1.272227 --> 1.266335).  Saving model ...
Validation loss decreased (1.266335 --> 1.258757).  Saving model ...
Validation loss decreased (1.258757 --> 1.251253).  Saving model ...
Validation loss decreased (1.251253 --> 1.244255).  Saving model ...
Validation loss decreased (1.244255 --> 1.236745).  Saving model ...
Validation loss decreased (1.236745 --> 1.229375).  Saving model ...
Validation loss decreased (1.229375 --> 1.221854).  Saving model ...
Validation loss decreased (1.221854 --> 1.213993).  Saving model ...
Validation loss decreased (1.213993 --> 1.206536).  Saving model ...
Validation loss decreased (1.206536 --> 1.198409).  Saving model ...
Validation loss decreased (1.198409 --> 1.190245).  Saving model ...
Validation loss decreased (1.190245 --> 1.182944).  Saving model ...
Validation loss decreased (1.182944 --> 1.177326).  Saving model ...
Validation loss decreased (1.177326 --> 1.170781).  Saving model ...
Validation loss decreased (1.170781 --> 1.164428).  Saving model ...
Validation loss decreased (1.164428 --> 1.158417).  Saving model ...
Validation loss decreased (1.158417 --> 1.152484).  Saving model ...
Validation loss decreased (1.152484 --> 1.148074).  Saving model ...
Validation loss decreased (1.148074 --> 1.142300).  Saving model ...
Validation loss decreased (1.142300 --> 1.137336).  Saving model ...
Validation loss decreased (1.137336 --> 1.131961).  Saving model ...
Validation loss decreased (1.131961 --> 1.125158).  Saving model ...
Validation loss decreased (1.125158 --> 1.119859).  Saving model ...
Validation loss decreased (1.119859 --> 1.114057).  Saving model ...
Validation loss decreased (1.114057 --> 1.110510).  Saving model ...
Validation loss decreased (1.110510 --> 1.105580).  Saving model ...
Validation loss decreased (1.105580 --> 1.100237).  Saving model ...
Validation loss decreased (1.100237 --> 1.094731).  Saving model ...
Validation loss decreased (1.094731 --> 1.089826).  Saving model ...
Validation loss decreased (1.089826 --> 1.084616).  Saving model ...
Validation loss decreased (1.084616 --> 1.080483).  Saving model ...
Validation loss decreased (1.080483 --> 1.074355).  Saving model ...
Validation loss decreased (1.074355 --> 1.070392).  Saving model ...
Validation loss decreased (1.070392 --> 1.065769).  Saving model ...
Validation loss decreased (1.065769 --> 1.062429).  Saving model ...
Validation loss decreased (1.062429 --> 1.059086).  Saving model ...
Validation loss decreased (1.059086 --> 1.052493).  Saving model ...
Validation loss decreased (1.052493 --> 1.049772).  Saving model ...
Validation loss decreased (1.049772 --> 1.045540).  Saving model ...
Validation loss decreased (1.045540 --> 1.043169).  Saving model ...
Validation loss decreased (1.043169 --> 1.039985).  Saving model ...
Validation loss decreased (1.039985 --> 1.036654).  Saving model ...
Validation loss decreased (1.036654 --> 1.034011).  Saving model ...
Validation loss decreased (1.034011 --> 1.030722).  Saving model ...
Validation loss decreased (1.030722 --> 1.028200).  Saving model ...
Validation loss decreased (1.028200 --> 1.023817).  Saving model ...
Validation loss decreased (1.023817 --> 1.020741).  Saving model ...
Validation loss decreased (1.020741 --> 1.019026).  Saving model ...
Validation loss decreased (1.019026 --> 1.016440).  Saving model ...
Validation loss decreased (1.016440 --> 1.013589).  Saving model ...
Validation loss decreased (1.013589 --> 1.010083).  Saving model ...
Validation loss decreased (1.010083 --> 1.007578).  Saving model ...
Validation loss decreased (1.007578 --> 1.004659).  Saving model ...
Validation loss decreased (1.004659 --> 1.003258).  Saving model ...
Validation loss decreased (1.003258 --> 1.000248).  Saving model ...
Validation loss decreased (1.000248 --> 0.998248).  Saving model ...
Validation loss decreased (0.998248 --> 0.996078).  Saving model ...
Validation loss decreased (0.996078 --> 0.992682).  Saving model ...
Validation loss decreased (0.992682 --> 0.990995).  Saving model ...
Validation loss decreased (0.990995 --> 0.989310).  Saving model ...
Validation loss decreased (0.989310 --> 0.987485).  Saving model ...
Validation loss decreased (0.987485 --> 0.986416).  Saving model ...
Validation loss decreased (0.986416 --> 0.985191).  Saving model ...
Validation loss decreased (0.985191 --> 0.982846).  Saving model ...
Validation loss decreased (0.982846 --> 0.981160).  Saving model ...
Validation loss decreased (0.981160 --> 0.979297).  Saving model ...
EarlyStopping counter: 1 out of 5.0
Validation loss decreased (0.979297 --> 0.978099).  Saving model ...
Validation loss decreased (0.978099 --> 0.976384).  Saving model ...
Validation loss decreased (0.976384 --> 0.975025).  Saving model ...
Validation loss decreased (0.975025 --> 0.973403).  Saving model ...
Validation loss decreased (0.973403 --> 0.971118).  Saving model ...
Validation loss decreased (0.971118 --> 0.968843).  Saving model ...
Validation loss decreased (0.968843 --> 0.967367).  Saving model ...
Validation loss decreased (0.967367 --> 0.967249).  Saving model ...
Validation loss decreased (0.967249 --> 0.967102).  Saving model ...
Validation loss decreased (0.967102 --> 0.966682).  Saving model ...
Validation loss decreased (0.966682 --> 0.964941).  Saving model ...
Validation loss decreased (0.964941 --> 0.962737).  Saving model ...
EarlyStopping counter: 1 out of 5.0
EarlyStopping counter: 2 out of 5.0
Validation loss decreased (0.962737 --> 0.961342).  Saving model ...
Validation loss decreased (0.961342 --> 0.961164).  Saving model ...
Validation loss decreased (0.961164 --> 0.960817).  Saving model ...
Validation loss decreased (0.960817 --> 0.958812).  Saving model ...
Validation loss decreased (0.958812 --> 0.958754).  Saving model ...
EarlyStopping counter: 1 out of 5.0
EarlyStopping counter: 2 out of 5.0
Validation loss decreased (0.958754 --> 0.956965).  Saving model ...
Validation loss decreased (0.956965 --> 0.956178).  Saving model ...
EarlyStopping counter: 1 out of 5.0
EarlyStopping counter: 2 out of 5.0
Validation loss decreased (0.956178 --> 0.955964).  Saving model ...
EarlyStopping counter: 1 out of 5.0
EarlyStopping counter: 2 out of 5.0
EarlyStopping counter: 3 out of 5.0
EarlyStopping counter: 4 out of 5.0
EarlyStopping counter: 5 out of 5.0
/localscratch/yinan.29200513.0/env/lib/python3.7/site-packages/torch/nn/functional.py:1794: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.
  warnings.warn("nn.functional.tanh is deprecated. Use torch.tanh instead.")
wandb: Waiting for W&B process to finish, PID 145528... (success).
wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: \ 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: | 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: / 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: \ 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: | 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: / 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: \ 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: | 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: / 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb:                                                                                
wandb: Run history:
wandb:     e_F1 ▁▂▃▃▄▅▆▆▆▆▆▆▇▇▇▇▇▇▇▇▇█▇▇▇███████████████
wandb:   e_loss ██▇▇▇▇▇▆▆▆▅▅▅▄▄▄▄▃▃▃▃▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁
wandb:     t_F1 ▁▁▂▂▂▃▃▃▄▃▄▄▅▅▅▅▅▅▆▆▆▆▆▆▇▇▇▇▇▇▇██▇██▇███
wandb:   t_loss ██▇▇▇▇▇▇▇▇▆▆▆▅▅▅▅▅▄▄▄▄▄▃▃▃▃▃▃▂▃▂▂▂▂▁▂▁▁▁
wandb: 
wandb: Run summary:
wandb:     e_F1 58.63678
wandb:   e_loss 0.95695
wandb:     t_F1 70.75579
wandb:   t_loss 0.82436
wandb: 
wandb: Synced 4 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Synced toasty-morning-2: https://wandb.ai/yinanazhou/xl_512_bs_8_lr_1e06_es_5_lc_False_nr_False_sr_True_stem_True_lemma_False_repeat_1_fold_2/runs/3d59w1ua
wandb: Find logs at: ./wandb/run-20220318_210247-3d59w1ua/logs/debug.log
wandb: 

wandb: wandb version 0.12.11 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
2022-03-18 22:26:53.240140: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1
wandb: Tracking run with wandb version 0.12.5
wandb: Syncing run breezy-fog-2
wandb: ⭐️ View project at https://wandb.ai/yinanazhou/xl_512_bs_8_lr_1e06_es_5_lc_False_nr_False_sr_True_stem_True_lemma_False_repeat_2_fold_1
wandb: 🚀 View run at https://wandb.ai/yinanazhou/xl_512_bs_8_lr_1e06_es_5_lc_False_nr_False_sr_True_stem_True_lemma_False_repeat_2_fold_1/runs/3awh7hzp
wandb: Run data is saved locally in /project/6002780/yinan/Thesis_MER_Lyrics/lyric-emotion/wandb/run-20220318_222650-3awh7hzp
wandb: Run `wandb offline` to turn off syncing.

Validation loss decreased (inf --> 1.438771).  Saving model ...
Validation loss decreased (1.438771 --> 1.415155).  Saving model ...
Validation loss decreased (1.415155 --> 1.397623).  Saving model ...
Validation loss decreased (1.397623 --> 1.385303).  Saving model ...
Validation loss decreased (1.385303 --> 1.375559).  Saving model ...
Validation loss decreased (1.375559 --> 1.368208).  Saving model ...
Validation loss decreased (1.368208 --> 1.362465).  Saving model ...
Validation loss decreased (1.362465 --> 1.357502).  Saving model ...
Validation loss decreased (1.357502 --> 1.353157).  Saving model ...
Validation loss decreased (1.353157 --> 1.349079).  Saving model ...
Validation loss decreased (1.349079 --> 1.344577).  Saving model ...
Validation loss decreased (1.344577 --> 1.340314).  Saving model ...
Validation loss decreased (1.340314 --> 1.336469).  Saving model ...
Validation loss decreased (1.336469 --> 1.332477).  Saving model ...
Validation loss decreased (1.332477 --> 1.328593).  Saving model ...
Validation loss decreased (1.328593 --> 1.324650).  Saving model ...
Validation loss decreased (1.324650 --> 1.320029).  Saving model ...
Validation loss decreased (1.320029 --> 1.315385).  Saving model ...
Validation loss decreased (1.315385 --> 1.309221).  Saving model ...
Validation loss decreased (1.309221 --> 1.304072).  Saving model ...
Validation loss decreased (1.304072 --> 1.298823).  Saving model ...
Validation loss decreased (1.298823 --> 1.293297).  Saving model ...
Validation loss decreased (1.293297 --> 1.286355).  Saving model ...
Validation loss decreased (1.286355 --> 1.277689).  Saving model ...
Validation loss decreased (1.277689 --> 1.269617).  Saving model ...
Validation loss decreased (1.269617 --> 1.263158).  Saving model ...
Validation loss decreased (1.263158 --> 1.254993).  Saving model ...
Validation loss decreased (1.254993 --> 1.247558).  Saving model ...
Validation loss decreased (1.247558 --> 1.239694).  Saving model ...
Validation loss decreased (1.239694 --> 1.230842).  Saving model ...
Validation loss decreased (1.230842 --> 1.223486).  Saving model ...
Validation loss decreased (1.223486 --> 1.213979).  Saving model ...
Validation loss decreased (1.213979 --> 1.206505).  Saving model ...
Validation loss decreased (1.206505 --> 1.200011).  Saving model ...
Validation loss decreased (1.200011 --> 1.192064).  Saving model ...
Validation loss decreased (1.192064 --> 1.184472).  Saving model ...
Validation loss decreased (1.184472 --> 1.176870).  Saving model ...
Validation loss decreased (1.176870 --> 1.169926).  Saving model ...
Validation loss decreased (1.169926 --> 1.163140).  Saving model ...
Validation loss decreased (1.163140 --> 1.157456).  Saving model ...
Validation loss decreased (1.157456 --> 1.150284).  Saving model ...
Validation loss decreased (1.150284 --> 1.144293).  Saving model ...
Validation loss decreased (1.144293 --> 1.138894).  Saving model ...
Validation loss decreased (1.138894 --> 1.133732).  Saving model ...
Validation loss decreased (1.133732 --> 1.128796).  Saving model ...
Validation loss decreased (1.128796 --> 1.123382).  Saving model ...
Validation loss decreased (1.123382 --> 1.119328).  Saving model ...
Validation loss decreased (1.119328 --> 1.113345).  Saving model ...
Validation loss decreased (1.113345 --> 1.112023).  Saving model ...
Validation loss decreased (1.112023 --> 1.109260).  Saving model ...
Validation loss decreased (1.109260 --> 1.104726).  Saving model ...
Validation loss decreased (1.104726 --> 1.100482).  Saving model ...
Validation loss decreased (1.100482 --> 1.097666).  Saving model ...
Validation loss decreased (1.097666 --> 1.092875).  Saving model ...
Validation loss decreased (1.092875 --> 1.088739).  Saving model ...
Validation loss decreased (1.088739 --> 1.083621).  Saving model ...
Validation loss decreased (1.083621 --> 1.078984).  Saving model ...
Validation loss decreased (1.078984 --> 1.073852).  Saving model ...
Validation loss decreased (1.073852 --> 1.069902).  Saving model ...
Validation loss decreased (1.069902 --> 1.066146).  Saving model ...
Validation loss decreased (1.066146 --> 1.064738).  Saving model ...
Validation loss decreased (1.064738 --> 1.063023).  Saving model ...
Validation loss decreased (1.063023 --> 1.059326).  Saving model ...
Validation loss decreased (1.059326 --> 1.057014).  Saving model ...
Validation loss decreased (1.057014 --> 1.052803).  Saving model ...
Validation loss decreased (1.052803 --> 1.047397).  Saving model ...
Validation loss decreased (1.047397 --> 1.043935).  Saving model ...
Validation loss decreased (1.043935 --> 1.043671).  Saving model ...
Validation loss decreased (1.043671 --> 1.041622).  Saving model ...
Validation loss decreased (1.041622 --> 1.037134).  Saving model ...
Validation loss decreased (1.037134 --> 1.033057).  Saving model ...
Validation loss decreased (1.033057 --> 1.029874).  Saving model ...
Validation loss decreased (1.029874 --> 1.025133).  Saving model ...
Validation loss decreased (1.025133 --> 1.023406).  Saving model ...
Validation loss decreased (1.023406 --> 1.022653).  Saving model ...
Validation loss decreased (1.022653 --> 1.020077).  Saving model ...
Validation loss decreased (1.020077 --> 1.017672).  Saving model ...
Validation loss decreased (1.017672 --> 1.015586).  Saving model ...
Validation loss decreased (1.015586 --> 1.012975).  Saving model ...
Validation loss decreased (1.012975 --> 1.009261).  Saving model ...
Validation loss decreased (1.009261 --> 1.006128).  Saving model ...
Validation loss decreased (1.006128 --> 1.003910).  Saving model ...
Validation loss decreased (1.003910 --> 1.002111).  Saving model ...
Validation loss decreased (1.002111 --> 1.000216).  Saving model ...
Validation loss decreased (1.000216 --> 0.999415).  Saving model ...
Validation loss decreased (0.999415 --> 0.997938).  Saving model ...
Validation loss decreased (0.997938 --> 0.996049).  Saving model ...
Validation loss decreased (0.996049 --> 0.994050).  Saving model ...
Validation loss decreased (0.994050 --> 0.992718).  Saving model ...
Validation loss decreased (0.992718 --> 0.990216).  Saving model ...
Validation loss decreased (0.990216 --> 0.988546).  Saving model ...
Validation loss decreased (0.988546 --> 0.987417).  Saving model ...
Validation loss decreased (0.987417 --> 0.986317).  Saving model ...
Validation loss decreased (0.986317 --> 0.984289).  Saving model ...
Validation loss decreased (0.984289 --> 0.982785).  Saving model ...
Validation loss decreased (0.982785 --> 0.981820).  Saving model ...
Validation loss decreased (0.981820 --> 0.981375).  Saving model ...
Validation loss decreased (0.981375 --> 0.980247).  Saving model ...
Validation loss decreased (0.980247 --> 0.978563).  Saving model ...
Validation loss decreased (0.978563 --> 0.977014).  Saving model ...
Validation loss decreased (0.977014 --> 0.976913).  Saving model ...
Validation loss decreased (0.976913 --> 0.976352).  Saving model ...
Validation loss decreased (0.976352 --> 0.974232).  Saving model ...
EarlyStopping counter: 1 out of 5.0
EarlyStopping counter: 2 out of 5.0
Validation loss decreased (0.974232 --> 0.973065).  Saving model ...
Validation loss decreased (0.973065 --> 0.972112).  Saving model ...
EarlyStopping counter: 1 out of 5.0
Validation loss decreased (0.972112 --> 0.971025).  Saving model ...
Validation loss decreased (0.971025 --> 0.970343).  Saving model ...
Validation loss decreased (0.970343 --> 0.969710).  Saving model ...
Validation loss decreased (0.969710 --> 0.968663).  Saving model ...
Validation loss decreased (0.968663 --> 0.968349).  Saving model ...
EarlyStopping counter: 1 out of 5.0
Validation loss decreased (0.968349 --> 0.968042).  Saving model ...
EarlyStopping counter: 1 out of 5.0
Validation loss decreased (0.968042 --> 0.967928).  Saving model ...
EarlyStopping counter: 1 out of 5.0
EarlyStopping counter: 2 out of 5.0
EarlyStopping counter: 3 out of 5.0
EarlyStopping counter: 4 out of 5.0
EarlyStopping counter: 5 out of 5.0
/localscratch/yinan.29200513.0/env/lib/python3.7/site-packages/torch/nn/functional.py:1794: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.
  warnings.warn("nn.functional.tanh is deprecated. Use torch.tanh instead.")
wandb: Waiting for W&B process to finish, PID 150059... (success).
wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: \ 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: | 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: / 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: \ 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: | 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: / 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: \ 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: | 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: / 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb:                                                                                
wandb: Run history:
wandb:     e_F1 ▁▁▃▄▄▄▄▅▅▆▆▇▇▇▇▇▇▇▇▇██▇█████████████████
wandb:   e_loss █▇▇▇▆▆▆▆▅▅▅▄▄▄▃▃▃▃▃▃▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:     t_F1 ▁▂▂▂▃▃▃▄▄▄▅▅▅▅▆▅▆▆▆▆▆▆▆▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇█
wandb:   t_loss █▇▇▇▇▇▇▆▆▆▆▅▅▅▅▄▄▄▄▄▄▄▃▃▃▃▃▃▃▂▂▂▂▂▂▂▂▁▁▁
wandb: 
wandb: Run summary:
wandb:     e_F1 57.92561
wandb:   e_loss 0.96883
wandb:     t_F1 73.79789
wandb:   t_loss 0.7603
wandb: 
wandb: Synced 4 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Synced breezy-fog-2: https://wandb.ai/yinanazhou/xl_512_bs_8_lr_1e06_es_5_lc_False_nr_False_sr_True_stem_True_lemma_False_repeat_2_fold_1/runs/3awh7hzp
wandb: Find logs at: ./wandb/run-20220318_222650-3awh7hzp/logs/debug.log
wandb: 

wandb: wandb version 0.12.11 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
2022-03-18 23:47:40.159126: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1
wandb: Tracking run with wandb version 0.12.5
wandb: Syncing run swept-oath-2
wandb: ⭐️ View project at https://wandb.ai/yinanazhou/xl_512_bs_8_lr_1e06_es_5_lc_False_nr_False_sr_True_stem_True_lemma_False_repeat_2_fold_2
wandb: 🚀 View run at https://wandb.ai/yinanazhou/xl_512_bs_8_lr_1e06_es_5_lc_False_nr_False_sr_True_stem_True_lemma_False_repeat_2_fold_2/runs/115imb3i
wandb: Run data is saved locally in /project/6002780/yinan/Thesis_MER_Lyrics/lyric-emotion/wandb/run-20220318_234737-115imb3i
wandb: Run `wandb offline` to turn off syncing.

Validation loss decreased (inf --> 1.425836).  Saving model ...
Validation loss decreased (1.425836 --> 1.412196).  Saving model ...
Validation loss decreased (1.412196 --> 1.401973).  Saving model ...
Validation loss decreased (1.401973 --> 1.394004).  Saving model ...
Validation loss decreased (1.394004 --> 1.387550).  Saving model ...
Validation loss decreased (1.387550 --> 1.382068).  Saving model ...
Validation loss decreased (1.382068 --> 1.376904).  Saving model ...
Validation loss decreased (1.376904 --> 1.372195).  Saving model ...
Validation loss decreased (1.372195 --> 1.367355).  Saving model ...
Validation loss decreased (1.367355 --> 1.363164).  Saving model ...
Validation loss decreased (1.363164 --> 1.359022).  Saving model ...
Validation loss decreased (1.359022 --> 1.354574).  Saving model ...
Validation loss decreased (1.354574 --> 1.350819).  Saving model ...
Validation loss decreased (1.350819 --> 1.346526).  Saving model ...
Validation loss decreased (1.346526 --> 1.342223).  Saving model ...
Validation loss decreased (1.342223 --> 1.338019).  Saving model ...
Validation loss decreased (1.338019 --> 1.333309).  Saving model ...
Validation loss decreased (1.333309 --> 1.327982).  Saving model ...
Validation loss decreased (1.327982 --> 1.323052).  Saving model ...
Validation loss decreased (1.323052 --> 1.318454).  Saving model ...
Validation loss decreased (1.318454 --> 1.312351).  Saving model ...
Validation loss decreased (1.312351 --> 1.306178).  Saving model ...
Validation loss decreased (1.306178 --> 1.300390).  Saving model ...
Validation loss decreased (1.300390 --> 1.293491).  Saving model ...
Validation loss decreased (1.293491 --> 1.287378).  Saving model ...
Validation loss decreased (1.287378 --> 1.280804).  Saving model ...
Validation loss decreased (1.280804 --> 1.273762).  Saving model ...
Validation loss decreased (1.273762 --> 1.267446).  Saving model ...
Validation loss decreased (1.267446 --> 1.259381).  Saving model ...
Validation loss decreased (1.259381 --> 1.252991).  Saving model ...
Validation loss decreased (1.252991 --> 1.245212).  Saving model ...
Validation loss decreased (1.245212 --> 1.237135).  Saving model ...
Validation loss decreased (1.237135 --> 1.230614).  Saving model ...
Validation loss decreased (1.230614 --> 1.223601).  Saving model ...
Validation loss decreased (1.223601 --> 1.217083).  Saving model ...
Validation loss decreased (1.217083 --> 1.210069).  Saving model ...
Validation loss decreased (1.210069 --> 1.203638).  Saving model ...
Validation loss decreased (1.203638 --> 1.196342).  Saving model ...
Validation loss decreased (1.196342 --> 1.189099).  Saving model ...
Validation loss decreased (1.189099 --> 1.181790).  Saving model ...
Validation loss decreased (1.181790 --> 1.174557).  Saving model ...
Validation loss decreased (1.174557 --> 1.168403).  Saving model ...
Validation loss decreased (1.168403 --> 1.162774).  Saving model ...
Validation loss decreased (1.162774 --> 1.158133).  Saving model ...
Validation loss decreased (1.158133 --> 1.152005).  Saving model ...
Validation loss decreased (1.152005 --> 1.145404).  Saving model ...
Validation loss decreased (1.145404 --> 1.139884).  Saving model ...
Validation loss decreased (1.139884 --> 1.134587).  Saving model ...
Validation loss decreased (1.134587 --> 1.129778).  Saving model ...
Validation loss decreased (1.129778 --> 1.125759).  Saving model ...
Validation loss decreased (1.125759 --> 1.120792).  Saving model ...
Validation loss decreased (1.120792 --> 1.115266).  Saving model ...
Validation loss decreased (1.115266 --> 1.110424).  Saving model ...
Validation loss decreased (1.110424 --> 1.106663).  Saving model ...
Validation loss decreased (1.106663 --> 1.103768).  Saving model ...
Validation loss decreased (1.103768 --> 1.100271).  Saving model ...
Validation loss decreased (1.100271 --> 1.094443).  Saving model ...
Validation loss decreased (1.094443 --> 1.090536).  Saving model ...
Validation loss decreased (1.090536 --> 1.087002).  Saving model ...
Validation loss decreased (1.087002 --> 1.082957).  Saving model ...
Validation loss decreased (1.082957 --> 1.079185).  Saving model ...
Validation loss decreased (1.079185 --> 1.073726).  Saving model ...
Validation loss decreased (1.073726 --> 1.070326).  Saving model ...
Validation loss decreased (1.070326 --> 1.067320).  Saving model ...
Validation loss decreased (1.067320 --> 1.063875).  Saving model ...
Validation loss decreased (1.063875 --> 1.061209).  Saving model ...
Validation loss decreased (1.061209 --> 1.056508).  Saving model ...
Validation loss decreased (1.056508 --> 1.053309).  Saving model ...
Validation loss decreased (1.053309 --> 1.050270).  Saving model ...
Validation loss decreased (1.050270 --> 1.045884).  Saving model ...
Validation loss decreased (1.045884 --> 1.043426).  Saving model ...
Validation loss decreased (1.043426 --> 1.040887).  Saving model ...
Validation loss decreased (1.040887 --> 1.036606).  Saving model ...
Validation loss decreased (1.036606 --> 1.033449).  Saving model ...
Validation loss decreased (1.033449 --> 1.032138).  Saving model ...
Validation loss decreased (1.032138 --> 1.029163).  Saving model ...
Validation loss decreased (1.029163 --> 1.024852).  Saving model ...
Validation loss decreased (1.024852 --> 1.023073).  Saving model ...
Validation loss decreased (1.023073 --> 1.019822).  Saving model ...
Validation loss decreased (1.019822 --> 1.018686).  Saving model ...
Validation loss decreased (1.018686 --> 1.015389).  Saving model ...
Validation loss decreased (1.015389 --> 1.014964).  Saving model ...
Validation loss decreased (1.014964 --> 1.012186).  Saving model ...
Validation loss decreased (1.012186 --> 1.010026).  Saving model ...
Validation loss decreased (1.010026 --> 1.008029).  Saving model ...
Validation loss decreased (1.008029 --> 1.006671).  Saving model ...
Validation loss decreased (1.006671 --> 1.002760).  Saving model ...
Validation loss decreased (1.002760 --> 1.000146).  Saving model ...
Validation loss decreased (1.000146 --> 0.999248).  Saving model ...
Validation loss decreased (0.999248 --> 0.997318).  Saving model ...
Validation loss decreased (0.997318 --> 0.994698).  Saving model ...
Validation loss decreased (0.994698 --> 0.993834).  Saving model ...
Validation loss decreased (0.993834 --> 0.992042).  Saving model ...
Validation loss decreased (0.992042 --> 0.990848).  Saving model ...
Validation loss decreased (0.990848 --> 0.987856).  Saving model ...
Validation loss decreased (0.987856 --> 0.986923).  Saving model ...
Validation loss decreased (0.986923 --> 0.984931).  Saving model ...
Validation loss decreased (0.984931 --> 0.984621).  Saving model ...
Validation loss decreased (0.984621 --> 0.984033).  Saving model ...
Validation loss decreased (0.984033 --> 0.980863).  Saving model ...
Validation loss decreased (0.980863 --> 0.977894).  Saving model ...
EarlyStopping counter: 1 out of 5.0
Validation loss decreased (0.977894 --> 0.977332).  Saving model ...
Validation loss decreased (0.977332 --> 0.976602).  Saving model ...
Validation loss decreased (0.976602 --> 0.975879).  Saving model ...
Validation loss decreased (0.975879 --> 0.974142).  Saving model ...
Validation loss decreased (0.974142 --> 0.971862).  Saving model ...
Validation loss decreased (0.971862 --> 0.969236).  Saving model ...
Validation loss decreased (0.969236 --> 0.968448).  Saving model ...
EarlyStopping counter: 1 out of 5.0
Validation loss decreased (0.968448 --> 0.967896).  Saving model ...
Validation loss decreased (0.967896 --> 0.967020).  Saving model ...
Validation loss decreased (0.967020 --> 0.964771).  Saving model ...
EarlyStopping counter: 1 out of 5.0
EarlyStopping counter: 2 out of 5.0
EarlyStopping counter: 3 out of 5.0
EarlyStopping counter: 4 out of 5.0
Validation loss decreased (0.964771 --> 0.964284).  Saving model ...
Validation loss decreased (0.964284 --> 0.963431).  Saving model ...
Validation loss decreased (0.963431 --> 0.962277).  Saving model ...
Validation loss decreased (0.962277 --> 0.961726).  Saving model ...
Validation loss decreased (0.961726 --> 0.960680).  Saving model ...
Validation loss decreased (0.960680 --> 0.959256).  Saving model ...
EarlyStopping counter: 1 out of 5.0
EarlyStopping counter: 2 out of 5.0
EarlyStopping counter: 3 out of 5.0
Validation loss decreased (0.959256 --> 0.957928).  Saving model ...
Validation loss decreased (0.957928 --> 0.956736).  Saving model ...
EarlyStopping counter: 1 out of 5.0
EarlyStopping counter: 2 out of 5.0
EarlyStopping counter: 3 out of 5.0
EarlyStopping counter: 4 out of 5.0
EarlyStopping counter: 5 out of 5.0
/localscratch/yinan.29200513.0/env/lib/python3.7/site-packages/torch/nn/functional.py:1794: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.
  warnings.warn("nn.functional.tanh is deprecated. Use torch.tanh instead.")
wandb: Waiting for W&B process to finish, PID 154403... (success).
wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: \ 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: | 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: / 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: \ 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: | 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: / 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: \ 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: | 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: / 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb:                                                                                
wandb: Run history:
wandb:     e_F1 ▁▁▃▄▄▅▅▅▅▆▅▆▇▇▇▇▇▇▇▇▇▇▇▇▇███████████████
wandb:   e_loss ██▇▇▇▇▆▆▆▅▅▅▄▄▄▃▃▃▃▃▂▂▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁
wandb:     t_F1 ▁▂▂▃▃▃▄▄▅▅▄▅▆▅▅▆▆▆▆▆▆▆▇▇▇▇▇▇▇▇█▇▇▇▇█████
wandb:   t_loss ███▇▇▇▇▆▆▆▆▅▅▅▅▅▄▄▄▄▃▃▃▃▃▃▃▂▂▂▂▂▂▂▂▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:     e_F1 59.09759
wandb:   e_loss 0.95919
wandb:     t_F1 69.51746
wandb:   t_loss 0.76396
wandb: 
wandb: Synced 4 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Synced swept-oath-2: https://wandb.ai/yinanazhou/xl_512_bs_8_lr_1e06_es_5_lc_False_nr_False_sr_True_stem_True_lemma_False_repeat_2_fold_2/runs/115imb3i
wandb: Find logs at: ./wandb/run-20220318_234737-115imb3i/logs/debug.log
wandb: 

wandb: wandb version 0.12.11 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
2022-03-19 01:14:09.054356: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1
wandb: Tracking run with wandb version 0.12.5
wandb: Syncing run cool-moon-2
wandb: ⭐️ View project at https://wandb.ai/yinanazhou/xl_512_bs_8_lr_1e06_es_5_lc_False_nr_False_sr_True_stem_True_lemma_False_repeat_3_fold_1
wandb: 🚀 View run at https://wandb.ai/yinanazhou/xl_512_bs_8_lr_1e06_es_5_lc_False_nr_False_sr_True_stem_True_lemma_False_repeat_3_fold_1/runs/1hxy60nb
wandb: Run data is saved locally in /project/6002780/yinan/Thesis_MER_Lyrics/lyric-emotion/wandb/run-20220319_011406-1hxy60nb
wandb: Run `wandb offline` to turn off syncing.

Validation loss decreased (inf --> 1.408812).  Saving model ...
Validation loss decreased (1.408812 --> 1.394686).  Saving model ...
Validation loss decreased (1.394686 --> 1.384994).  Saving model ...
Validation loss decreased (1.384994 --> 1.377110).  Saving model ...
Validation loss decreased (1.377110 --> 1.370499).  Saving model ...
Validation loss decreased (1.370499 --> 1.364998).  Saving model ...
Validation loss decreased (1.364998 --> 1.360068).  Saving model ...
Validation loss decreased (1.360068 --> 1.355637).  Saving model ...
Validation loss decreased (1.355637 --> 1.351282).  Saving model ...
Validation loss decreased (1.351282 --> 1.347419).  Saving model ...
Validation loss decreased (1.347419 --> 1.343356).  Saving model ...
Validation loss decreased (1.343356 --> 1.339355).  Saving model ...
Validation loss decreased (1.339355 --> 1.334946).  Saving model ...
Validation loss decreased (1.334946 --> 1.330692).  Saving model ...
Validation loss decreased (1.330692 --> 1.326368).  Saving model ...
Validation loss decreased (1.326368 --> 1.321706).  Saving model ...
Validation loss decreased (1.321706 --> 1.316931).  Saving model ...
Validation loss decreased (1.316931 --> 1.312404).  Saving model ...
Validation loss decreased (1.312404 --> 1.307163).  Saving model ...
Validation loss decreased (1.307163 --> 1.302136).  Saving model ...
Validation loss decreased (1.302136 --> 1.296407).  Saving model ...
Validation loss decreased (1.296407 --> 1.290983).  Saving model ...
Validation loss decreased (1.290983 --> 1.284833).  Saving model ...
Validation loss decreased (1.284833 --> 1.278724).  Saving model ...
Validation loss decreased (1.278724 --> 1.272342).  Saving model ...
Validation loss decreased (1.272342 --> 1.265828).  Saving model ...
Validation loss decreased (1.265828 --> 1.259551).  Saving model ...
Validation loss decreased (1.259551 --> 1.252642).  Saving model ...
Validation loss decreased (1.252642 --> 1.245753).  Saving model ...
Validation loss decreased (1.245753 --> 1.238600).  Saving model ...
Validation loss decreased (1.238600 --> 1.232325).  Saving model ...
Validation loss decreased (1.232325 --> 1.226549).  Saving model ...
Validation loss decreased (1.226549 --> 1.218950).  Saving model ...
Validation loss decreased (1.218950 --> 1.211273).  Saving model ...
Validation loss decreased (1.211273 --> 1.204714).  Saving model ...
Validation loss decreased (1.204714 --> 1.198726).  Saving model ...
Validation loss decreased (1.198726 --> 1.192729).  Saving model ...
Validation loss decreased (1.192729 --> 1.186129).  Saving model ...
Validation loss decreased (1.186129 --> 1.180330).  Saving model ...
Validation loss decreased (1.180330 --> 1.174820).  Saving model ...
Validation loss decreased (1.174820 --> 1.168313).  Saving model ...
Validation loss decreased (1.168313 --> 1.161580).  Saving model ...
Validation loss decreased (1.161580 --> 1.156758).  Saving model ...
Validation loss decreased (1.156758 --> 1.150037).  Saving model ...
Validation loss decreased (1.150037 --> 1.144626).  Saving model ...
Validation loss decreased (1.144626 --> 1.138956).  Saving model ...
Validation loss decreased (1.138956 --> 1.132221).  Saving model ...
Validation loss decreased (1.132221 --> 1.126465).  Saving model ...
Validation loss decreased (1.126465 --> 1.121867).  Saving model ...
Validation loss decreased (1.121867 --> 1.117137).  Saving model ...
Validation loss decreased (1.117137 --> 1.113337).  Saving model ...
Validation loss decreased (1.113337 --> 1.107285).  Saving model ...
Validation loss decreased (1.107285 --> 1.101811).  Saving model ...
Validation loss decreased (1.101811 --> 1.095502).  Saving model ...
Validation loss decreased (1.095502 --> 1.091879).  Saving model ...
Validation loss decreased (1.091879 --> 1.087918).  Saving model ...
Validation loss decreased (1.087918 --> 1.084340).  Saving model ...
Validation loss decreased (1.084340 --> 1.079172).  Saving model ...
Validation loss decreased (1.079172 --> 1.074139).  Saving model ...
Validation loss decreased (1.074139 --> 1.068535).  Saving model ...
Validation loss decreased (1.068535 --> 1.064931).  Saving model ...
Validation loss decreased (1.064931 --> 1.059409).  Saving model ...
Validation loss decreased (1.059409 --> 1.056403).  Saving model ...
Validation loss decreased (1.056403 --> 1.055459).  Saving model ...
Validation loss decreased (1.055459 --> 1.050807).  Saving model ...
Validation loss decreased (1.050807 --> 1.046847).  Saving model ...
Validation loss decreased (1.046847 --> 1.043210).  Saving model ...
Validation loss decreased (1.043210 --> 1.042784).  Saving model ...
Validation loss decreased (1.042784 --> 1.039230).  Saving model ...
Validation loss decreased (1.039230 --> 1.034473).  Saving model ...
Validation loss decreased (1.034473 --> 1.031608).  Saving model ...
Validation loss decreased (1.031608 --> 1.031133).  Saving model ...
Validation loss decreased (1.031133 --> 1.027138).  Saving model ...
Validation loss decreased (1.027138 --> 1.023723).  Saving model ...
Validation loss decreased (1.023723 --> 1.021952).  Saving model ...
Validation loss decreased (1.021952 --> 1.018768).  Saving model ...
Validation loss decreased (1.018768 --> 1.015518).  Saving model ...
Validation loss decreased (1.015518 --> 1.015176).  Saving model ...
Validation loss decreased (1.015176 --> 1.009978).  Saving model ...
Validation loss decreased (1.009978 --> 1.008864).  Saving model ...
Validation loss decreased (1.008864 --> 1.007120).  Saving model ...
Validation loss decreased (1.007120 --> 1.006380).  Saving model ...
Validation loss decreased (1.006380 --> 1.003301).  Saving model ...
Validation loss decreased (1.003301 --> 1.001902).  Saving model ...
EarlyStopping counter: 1 out of 5.0
Validation loss decreased (1.001902 --> 1.000224).  Saving model ...
Validation loss decreased (1.000224 --> 0.999075).  Saving model ...
Validation loss decreased (0.999075 --> 0.995519).  Saving model ...
Validation loss decreased (0.995519 --> 0.995133).  Saving model ...
Validation loss decreased (0.995133 --> 0.992038).  Saving model ...
Validation loss decreased (0.992038 --> 0.991640).  Saving model ...
Validation loss decreased (0.991640 --> 0.989211).  Saving model ...
Validation loss decreased (0.989211 --> 0.989053).  Saving model ...
EarlyStopping counter: 1 out of 5.0
Validation loss decreased (0.989053 --> 0.988408).  Saving model ...
Validation loss decreased (0.988408 --> 0.986399).  Saving model ...
Validation loss decreased (0.986399 --> 0.986238).  Saving model ...
Validation loss decreased (0.986238 --> 0.983821).  Saving model ...
Validation loss decreased (0.983821 --> 0.982069).  Saving model ...
Validation loss decreased (0.982069 --> 0.980638).  Saving model ...
Validation loss decreased (0.980638 --> 0.979653).  Saving model ...
Validation loss decreased (0.979653 --> 0.977744).  Saving model ...
EarlyStopping counter: 1 out of 5.0
EarlyStopping counter: 2 out of 5.0
EarlyStopping counter: 3 out of 5.0
EarlyStopping counter: 4 out of 5.0
EarlyStopping counter: 5 out of 5.0
/localscratch/yinan.29200513.0/env/lib/python3.7/site-packages/torch/nn/functional.py:1794: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.
  warnings.warn("nn.functional.tanh is deprecated. Use torch.tanh instead.")
wandb: Waiting for W&B process to finish, PID 159116... (success).
wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: \ 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: | 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: / 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: \ 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: | 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: / 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: \ 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: | 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: / 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb:                                                                                
wandb: Run history:
wandb:     e_F1 ▁▁▄▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇▇▇▇▇██▇▇██████████████
wandb:   e_loss ██▇▇▇▇▇▆▆▆▅▅▅▅▄▄▄▄▃▃▃▃▂▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁
wandb:     t_F1 ▁▁▂▃▂▃▃▄▄▄▄▄▅▅▆▆▅▆▆▆▆▆▆▇▇▇▆▇▇▇█▇▇▇▇▇▇▇█▇
wandb:   t_loss ██▇▇▇▇▇▇▆▆▆▆▅▅▅▅▅▄▄▄▄▃▄▃▃▃▃▂▂▂▂▂▂▂▂▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:     e_F1 58.03993
wandb:   e_loss 0.97827
wandb:     t_F1 66.42323
wandb:   t_loss 0.87142
wandb: 
wandb: Synced 4 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Synced cool-moon-2: https://wandb.ai/yinanazhou/xl_512_bs_8_lr_1e06_es_5_lc_False_nr_False_sr_True_stem_True_lemma_False_repeat_3_fold_1/runs/1hxy60nb
wandb: Find logs at: ./wandb/run-20220319_011406-1hxy60nb/logs/debug.log
wandb: 

wandb: wandb version 0.12.11 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
2022-03-19 02:24:03.245323: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1
wandb: Tracking run with wandb version 0.12.5
wandb: Syncing run summer-sunset-2
wandb: ⭐️ View project at https://wandb.ai/yinanazhou/xl_512_bs_8_lr_1e06_es_5_lc_False_nr_False_sr_True_stem_True_lemma_False_repeat_3_fold_2
wandb: 🚀 View run at https://wandb.ai/yinanazhou/xl_512_bs_8_lr_1e06_es_5_lc_False_nr_False_sr_True_stem_True_lemma_False_repeat_3_fold_2/runs/21nvj83q
wandb: Run data is saved locally in /project/6002780/yinan/Thesis_MER_Lyrics/lyric-emotion/wandb/run-20220319_022400-21nvj83q
wandb: Run `wandb offline` to turn off syncing.

Validation loss decreased (inf --> 1.501036).  Saving model ...
Validation loss decreased (1.501036 --> 1.464922).  Saving model ...
Validation loss decreased (1.464922 --> 1.437977).  Saving model ...
Validation loss decreased (1.437977 --> 1.418193).  Saving model ...
Validation loss decreased (1.418193 --> 1.403053).  Saving model ...
Validation loss decreased (1.403053 --> 1.392047).  Saving model ...
Validation loss decreased (1.392047 --> 1.383499).  Saving model ...
Validation loss decreased (1.383499 --> 1.376342).  Saving model ...
Validation loss decreased (1.376342 --> 1.369936).  Saving model ...
Validation loss decreased (1.369936 --> 1.364365).  Saving model ...
Validation loss decreased (1.364365 --> 1.359015).  Saving model ...
Validation loss decreased (1.359015 --> 1.353405).  Saving model ...
Validation loss decreased (1.353405 --> 1.348363).  Saving model ...
Validation loss decreased (1.348363 --> 1.343286).  Saving model ...
Validation loss decreased (1.343286 --> 1.337550).  Saving model ...
Validation loss decreased (1.337550 --> 1.331406).  Saving model ...
Validation loss decreased (1.331406 --> 1.325801).  Saving model ...
Validation loss decreased (1.325801 --> 1.319570).  Saving model ...
Validation loss decreased (1.319570 --> 1.313148).  Saving model ...
Validation loss decreased (1.313148 --> 1.306792).  Saving model ...
Validation loss decreased (1.306792 --> 1.300140).  Saving model ...
Validation loss decreased (1.300140 --> 1.293044).  Saving model ...
Validation loss decreased (1.293044 --> 1.285543).  Saving model ...
Validation loss decreased (1.285543 --> 1.279558).  Saving model ...
Validation loss decreased (1.279558 --> 1.272847).  Saving model ...
Validation loss decreased (1.272847 --> 1.264909).  Saving model ...
Validation loss decreased (1.264909 --> 1.258266).  Saving model ...
Validation loss decreased (1.258266 --> 1.251138).  Saving model ...
Validation loss decreased (1.251138 --> 1.243049).  Saving model ...
Validation loss decreased (1.243049 --> 1.236028).  Saving model ...
Validation loss decreased (1.236028 --> 1.229348).  Saving model ...
Validation loss decreased (1.229348 --> 1.223266).  Saving model ...
Validation loss decreased (1.223266 --> 1.216794).  Saving model ...
Validation loss decreased (1.216794 --> 1.209204).  Saving model ...
Validation loss decreased (1.209204 --> 1.202792).  Saving model ...
Validation loss decreased (1.202792 --> 1.196440).  Saving model ...
Validation loss decreased (1.196440 --> 1.187782).  Saving model ...
Validation loss decreased (1.187782 --> 1.182078).  Saving model ...
Validation loss decreased (1.182078 --> 1.175363).  Saving model ...
Validation loss decreased (1.175363 --> 1.168985).  Saving model ...
Validation loss decreased (1.168985 --> 1.162291).  Saving model ...
Validation loss decreased (1.162291 --> 1.156108).  Saving model ...
Validation loss decreased (1.156108 --> 1.151360).  Saving model ...
Validation loss decreased (1.151360 --> 1.144086).  Saving model ...
Validation loss decreased (1.144086 --> 1.139377).  Saving model ...
Validation loss decreased (1.139377 --> 1.135301).  Saving model ...
Validation loss decreased (1.135301 --> 1.128253).  Saving model ...
Validation loss decreased (1.128253 --> 1.121945).  Saving model ...
Validation loss decreased (1.121945 --> 1.116560).  Saving model ...
Validation loss decreased (1.116560 --> 1.110779).  Saving model ...
Validation loss decreased (1.110779 --> 1.106149).  Saving model ...
Validation loss decreased (1.106149 --> 1.100268).  Saving model ...
Validation loss decreased (1.100268 --> 1.093839).  Saving model ...
Validation loss decreased (1.093839 --> 1.087850).  Saving model ...
Validation loss decreased (1.087850 --> 1.081812).  Saving model ...
Validation loss decreased (1.081812 --> 1.077776).  Saving model ...
Validation loss decreased (1.077776 --> 1.074292).  Saving model ...
Validation loss decreased (1.074292 --> 1.070785).  Saving model ...
Validation loss decreased (1.070785 --> 1.064270).  Saving model ...
Validation loss decreased (1.064270 --> 1.059092).  Saving model ...
Validation loss decreased (1.059092 --> 1.056159).  Saving model ...
Validation loss decreased (1.056159 --> 1.053226).  Saving model ...
Validation loss decreased (1.053226 --> 1.050288).  Saving model ...
Validation loss decreased (1.050288 --> 1.044918).  Saving model ...
Validation loss decreased (1.044918 --> 1.041027).  Saving model ...
Validation loss decreased (1.041027 --> 1.038375).  Saving model ...
Validation loss decreased (1.038375 --> 1.034732).  Saving model ...
Validation loss decreased (1.034732 --> 1.031595).  Saving model ...
Validation loss decreased (1.031595 --> 1.023802).  Saving model ...
Validation loss decreased (1.023802 --> 1.020632).  Saving model ...
Validation loss decreased (1.020632 --> 1.016600).  Saving model ...
Validation loss decreased (1.016600 --> 1.015458).  Saving model ...
Validation loss decreased (1.015458 --> 1.013540).  Saving model ...
Validation loss decreased (1.013540 --> 1.011914).  Saving model ...
Validation loss decreased (1.011914 --> 1.008146).  Saving model ...
Validation loss decreased (1.008146 --> 1.005574).  Saving model ...
Validation loss decreased (1.005574 --> 1.003854).  Saving model ...
Validation loss decreased (1.003854 --> 0.999655).  Saving model ...
Validation loss decreased (0.999655 --> 0.995423).  Saving model ...
Validation loss decreased (0.995423 --> 0.992456).  Saving model ...
Validation loss decreased (0.992456 --> 0.991970).  Saving model ...
Validation loss decreased (0.991970 --> 0.989243).  Saving model ...
Validation loss decreased (0.989243 --> 0.987679).  Saving model ...
Validation loss decreased (0.987679 --> 0.985757).  Saving model ...
Validation loss decreased (0.985757 --> 0.983367).  Saving model ...
Validation loss decreased (0.983367 --> 0.980046).  Saving model ...
Validation loss decreased (0.980046 --> 0.978850).  Saving model ...
Validation loss decreased (0.978850 --> 0.976803).  Saving model ...
Validation loss decreased (0.976803 --> 0.975608).  Saving model ...
Validation loss decreased (0.975608 --> 0.971571).  Saving model ...
Validation loss decreased (0.971571 --> 0.970183).  Saving model ...
Validation loss decreased (0.970183 --> 0.966859).  Saving model ...
EarlyStopping counter: 1 out of 5.0
Validation loss decreased (0.966859 --> 0.966075).  Saving model ...
Validation loss decreased (0.966075 --> 0.963859).  Saving model ...
Validation loss decreased (0.963859 --> 0.961451).  Saving model ...
Validation loss decreased (0.961451 --> 0.959863).  Saving model ...
EarlyStopping counter: 1 out of 5.0
Validation loss decreased (0.959863 --> 0.959844).  Saving model ...
Validation loss decreased (0.959844 --> 0.959464).  Saving model ...
Validation loss decreased (0.959464 --> 0.958916).  Saving model ...
Validation loss decreased (0.958916 --> 0.953989).  Saving model ...
EarlyStopping counter: 1 out of 5.0
Validation loss decreased (0.953989 --> 0.952958).  Saving model ...
EarlyStopping counter: 1 out of 5.0
Validation loss decreased (0.952958 --> 0.950883).  Saving model ...
Validation loss decreased (0.950883 --> 0.948740).  Saving model ...
Validation loss decreased (0.948740 --> 0.947237).  Saving model ...
Validation loss decreased (0.947237 --> 0.946966).  Saving model ...
Validation loss decreased (0.946966 --> 0.943505).  Saving model ...
EarlyStopping counter: 1 out of 5.0
EarlyStopping counter: 2 out of 5.0
EarlyStopping counter: 3 out of 5.0
EarlyStopping counter: 4 out of 5.0
EarlyStopping counter: 5 out of 5.0
/localscratch/yinan.29200513.0/env/lib/python3.7/site-packages/torch/nn/functional.py:1794: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.
  warnings.warn("nn.functional.tanh is deprecated. Use torch.tanh instead.")
wandb: Waiting for W&B process to finish, PID 162881... (success).
wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: \ 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: | 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: / 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: \ 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: | 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: / 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: \ 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: | 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: / 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb:                                                                                
wandb: Run history:
wandb:     e_F1 ▁▂▂▃▄▄▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇▇▇▇▇▇▇▇▇███████████
wandb:   e_loss █▇▇▆▆▆▆▅▅▅▅▄▄▄▄▄▃▃▃▃▃▂▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁
wandb:     t_F1 ▁▁▂▂▃▃▄▄▅▅▅▅▅▅▆▇▆▇▇▇▇▇▇▇▇▇▇▇▇▇████▇█████
wandb:   t_loss █▇▇▇▇▆▆▆▆▆▆▅▅▅▅▄▄▄▄▃▃▃▃▃▃▃▃▂▂▂▂▂▂▂▂▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:     e_F1 59.43216
wandb:   e_loss 0.94801
wandb:     t_F1 67.69206
wandb:   t_loss 0.81394
wandb: 
wandb: Synced 4 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Synced summer-sunset-2: https://wandb.ai/yinanazhou/xl_512_bs_8_lr_1e06_es_5_lc_False_nr_False_sr_True_stem_True_lemma_False_repeat_3_fold_2/runs/21nvj83q
wandb: Find logs at: ./wandb/run-20220319_022400-21nvj83q/logs/debug.log
wandb: 

wandb: wandb version 0.12.11 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
2022-03-19 03:38:51.916564: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1
wandb: Tracking run with wandb version 0.12.5
wandb: Syncing run mild-sunset-2
wandb: ⭐️ View project at https://wandb.ai/yinanazhou/xl_512_bs_8_lr_1e06_es_5_lc_False_nr_False_sr_True_stem_True_lemma_False_repeat_4_fold_1
wandb: 🚀 View run at https://wandb.ai/yinanazhou/xl_512_bs_8_lr_1e06_es_5_lc_False_nr_False_sr_True_stem_True_lemma_False_repeat_4_fold_1/runs/2ejxogp5
wandb: Run data is saved locally in /project/6002780/yinan/Thesis_MER_Lyrics/lyric-emotion/wandb/run-20220319_033849-2ejxogp5
wandb: Run `wandb offline` to turn off syncing.

Validation loss decreased (inf --> 1.464807).  Saving model ...
Validation loss decreased (1.464807 --> 1.435046).  Saving model ...
Validation loss decreased (1.435046 --> 1.415498).  Saving model ...
Validation loss decreased (1.415498 --> 1.401776).  Saving model ...
Validation loss decreased (1.401776 --> 1.392722).  Saving model ...
Validation loss decreased (1.392722 --> 1.385840).  Saving model ...
Validation loss decreased (1.385840 --> 1.380249).  Saving model ...
Validation loss decreased (1.380249 --> 1.375164).  Saving model ...
Validation loss decreased (1.375164 --> 1.370497).  Saving model ...
Validation loss decreased (1.370497 --> 1.365863).  Saving model ...
Validation loss decreased (1.365863 --> 1.361284).  Saving model ...
Validation loss decreased (1.361284 --> 1.356923).  Saving model ...
Validation loss decreased (1.356923 --> 1.352318).  Saving model ...
Validation loss decreased (1.352318 --> 1.347110).  Saving model ...
Validation loss decreased (1.347110 --> 1.342060).  Saving model ...
Validation loss decreased (1.342060 --> 1.337095).  Saving model ...
Validation loss decreased (1.337095 --> 1.331852).  Saving model ...
Validation loss decreased (1.331852 --> 1.326186).  Saving model ...
Validation loss decreased (1.326186 --> 1.320606).  Saving model ...
Validation loss decreased (1.320606 --> 1.314668).  Saving model ...
Validation loss decreased (1.314668 --> 1.309062).  Saving model ...
Validation loss decreased (1.309062 --> 1.303086).  Saving model ...
Validation loss decreased (1.303086 --> 1.297015).  Saving model ...
Validation loss decreased (1.297015 --> 1.290151).  Saving model ...
Validation loss decreased (1.290151 --> 1.284540).  Saving model ...
Validation loss decreased (1.284540 --> 1.278510).  Saving model ...
Validation loss decreased (1.278510 --> 1.271377).  Saving model ...
Validation loss decreased (1.271377 --> 1.264913).  Saving model ...
Validation loss decreased (1.264913 --> 1.257409).  Saving model ...
Validation loss decreased (1.257409 --> 1.250677).  Saving model ...
Validation loss decreased (1.250677 --> 1.245146).  Saving model ...
Validation loss decreased (1.245146 --> 1.238953).  Saving model ...
Validation loss decreased (1.238953 --> 1.232073).  Saving model ...
Validation loss decreased (1.232073 --> 1.226282).  Saving model ...
Validation loss decreased (1.226282 --> 1.219699).  Saving model ...
Validation loss decreased (1.219699 --> 1.213336).  Saving model ...
Validation loss decreased (1.213336 --> 1.207381).  Saving model ...
Validation loss decreased (1.207381 --> 1.201007).  Saving model ...
Validation loss decreased (1.201007 --> 1.195251).  Saving model ...
Validation loss decreased (1.195251 --> 1.189128).  Saving model ...
Validation loss decreased (1.189128 --> 1.184105).  Saving model ...
Validation loss decreased (1.184105 --> 1.178649).  Saving model ...
Validation loss decreased (1.178649 --> 1.173166).  Saving model ...
Validation loss decreased (1.173166 --> 1.168368).  Saving model ...
Validation loss decreased (1.168368 --> 1.163605).  Saving model ...
Validation loss decreased (1.163605 --> 1.158572).  Saving model ...
Validation loss decreased (1.158572 --> 1.153816).  Saving model ...
Validation loss decreased (1.153816 --> 1.148900).  Saving model ...
Validation loss decreased (1.148900 --> 1.143521).  Saving model ...
Validation loss decreased (1.143521 --> 1.138673).  Saving model ...
Validation loss decreased (1.138673 --> 1.134299).  Saving model ...
Validation loss decreased (1.134299 --> 1.130487).  Saving model ...
Validation loss decreased (1.130487 --> 1.126352).  Saving model ...
Validation loss decreased (1.126352 --> 1.121943).  Saving model ...
Validation loss decreased (1.121943 --> 1.117694).  Saving model ...
Validation loss decreased (1.117694 --> 1.114662).  Saving model ...
Validation loss decreased (1.114662 --> 1.111596).  Saving model ...
Validation loss decreased (1.111596 --> 1.109017).  Saving model ...
Validation loss decreased (1.109017 --> 1.104920).  Saving model ...
Validation loss decreased (1.104920 --> 1.102047).  Saving model ...
Validation loss decreased (1.102047 --> 1.098772).  Saving model ...
Validation loss decreased (1.098772 --> 1.095053).  Saving model ...
Validation loss decreased (1.095053 --> 1.091425).  Saving model ...
Validation loss decreased (1.091425 --> 1.088505).  Saving model ...
Validation loss decreased (1.088505 --> 1.086333).  Saving model ...
Validation loss decreased (1.086333 --> 1.083732).  Saving model ...
Validation loss decreased (1.083732 --> 1.079498).  Saving model ...
Validation loss decreased (1.079498 --> 1.075915).  Saving model ...
Validation loss decreased (1.075915 --> 1.072419).  Saving model ...
Validation loss decreased (1.072419 --> 1.070104).  Saving model ...
Validation loss decreased (1.070104 --> 1.068636).  Saving model ...
Validation loss decreased (1.068636 --> 1.064933).  Saving model ...
Validation loss decreased (1.064933 --> 1.061555).  Saving model ...
Validation loss decreased (1.061555 --> 1.058843).  Saving model ...
Validation loss decreased (1.058843 --> 1.057303).  Saving model ...
Validation loss decreased (1.057303 --> 1.055804).  Saving model ...
Validation loss decreased (1.055804 --> 1.053628).  Saving model ...
Validation loss decreased (1.053628 --> 1.052597).  Saving model ...
Validation loss decreased (1.052597 --> 1.051837).  Saving model ...
Validation loss decreased (1.051837 --> 1.047481).  Saving model ...
Validation loss decreased (1.047481 --> 1.045844).  Saving model ...
Validation loss decreased (1.045844 --> 1.044304).  Saving model ...
Validation loss decreased (1.044304 --> 1.041566).  Saving model ...
Validation loss decreased (1.041566 --> 1.039692).  Saving model ...
Validation loss decreased (1.039692 --> 1.038357).  Saving model ...
Validation loss decreased (1.038357 --> 1.035806).  Saving model ...
Validation loss decreased (1.035806 --> 1.033176).  Saving model ...
Validation loss decreased (1.033176 --> 1.031804).  Saving model ...
Validation loss decreased (1.031804 --> 1.031439).  Saving model ...
EarlyStopping counter: 1 out of 5.0
Validation loss decreased (1.031439 --> 1.029799).  Saving model ...
Validation loss decreased (1.029799 --> 1.028098).  Saving model ...
Validation loss decreased (1.028098 --> 1.027147).  Saving model ...
Validation loss decreased (1.027147 --> 1.024841).  Saving model ...
Validation loss decreased (1.024841 --> 1.023951).  Saving model ...
EarlyStopping counter: 1 out of 5.0
Validation loss decreased (1.023951 --> 1.020947).  Saving model ...
Validation loss decreased (1.020947 --> 1.020356).  Saving model ...
Validation loss decreased (1.020356 --> 1.017550).  Saving model ...
EarlyStopping counter: 1 out of 5.0
Validation loss decreased (1.017550 --> 1.017474).  Saving model ...
Validation loss decreased (1.017474 --> 1.015217).  Saving model ...
Validation loss decreased (1.015217 --> 1.014840).  Saving model ...
Validation loss decreased (1.014840 --> 1.012818).  Saving model ...
Validation loss decreased (1.012818 --> 1.012184).  Saving model ...
EarlyStopping counter: 1 out of 5.0
EarlyStopping counter: 2 out of 5.0
EarlyStopping counter: 3 out of 5.0
Validation loss decreased (1.012184 --> 1.010846).  Saving model ...
Validation loss decreased (1.010846 --> 1.008117).  Saving model ...
Validation loss decreased (1.008117 --> 1.006566).  Saving model ...
EarlyStopping counter: 1 out of 5.0
EarlyStopping counter: 2 out of 5.0
Validation loss decreased (1.006566 --> 1.004279).  Saving model ...
Validation loss decreased (1.004279 --> 1.003278).  Saving model ...
Validation loss decreased (1.003278 --> 1.002432).  Saving model ...
Validation loss decreased (1.002432 --> 1.001411).  Saving model ...
EarlyStopping counter: 1 out of 5.0
EarlyStopping counter: 2 out of 5.0
EarlyStopping counter: 3 out of 5.0
EarlyStopping counter: 4 out of 5.0
EarlyStopping counter: 5 out of 5.0
/localscratch/yinan.29200513.0/env/lib/python3.7/site-packages/torch/nn/functional.py:1794: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.
  warnings.warn("nn.functional.tanh is deprecated. Use torch.tanh instead.")
wandb: Waiting for W&B process to finish, PID 166920... (success).
wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: \ 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: | 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: / 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: \ 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: | 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: / 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: \ 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: | 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: / 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb:                                                                                
wandb: Run history:
wandb:     e_F1 ▁▂▃▄▄▅▅▅▆▆▆▆▆▆▆▆▇▇▇▇▇▇▇▇▇▇▇▇▇▇██████████
wandb:   e_loss █▇▇▇▆▆▆▆▅▅▅▄▄▄▄▃▃▃▃▃▂▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁
wandb:     t_F1 ▁▂▂▃▃▃▄▄▄▅▅▅▅▅▆▆▆▆▇▆▇▇▆▇▇▇▇▇▇▇█▇████████
wandb:   t_loss █▇▇▇▇▇▆▆▆▆▅▅▅▅▅▄▄▄▄▄▃▃▃▃▃▂▃▂▃▂▂▂▂▂▂▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:     e_F1 56.30865
wandb:   e_loss 1.00181
wandb:     t_F1 67.83887
wandb:   t_loss 0.79627
wandb: 
wandb: Synced 4 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Synced mild-sunset-2: https://wandb.ai/yinanazhou/xl_512_bs_8_lr_1e06_es_5_lc_False_nr_False_sr_True_stem_True_lemma_False_repeat_4_fold_1/runs/2ejxogp5
wandb: Find logs at: ./wandb/run-20220319_033849-2ejxogp5/logs/debug.log
wandb: 

wandb: wandb version 0.12.11 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
2022-03-19 04:58:20.782301: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1
wandb: Tracking run with wandb version 0.12.5
wandb: Syncing run eager-durian-2
wandb: ⭐️ View project at https://wandb.ai/yinanazhou/xl_512_bs_8_lr_1e06_es_5_lc_False_nr_False_sr_True_stem_True_lemma_False_repeat_4_fold_2
wandb: 🚀 View run at https://wandb.ai/yinanazhou/xl_512_bs_8_lr_1e06_es_5_lc_False_nr_False_sr_True_stem_True_lemma_False_repeat_4_fold_2/runs/26x6qe0r
wandb: Run data is saved locally in /project/6002780/yinan/Thesis_MER_Lyrics/lyric-emotion/wandb/run-20220319_045817-26x6qe0r
wandb: Run `wandb offline` to turn off syncing.

Validation loss decreased (inf --> 1.432880).  Saving model ...
Validation loss decreased (1.432880 --> 1.414018).  Saving model ...
Validation loss decreased (1.414018 --> 1.400640).  Saving model ...
Validation loss decreased (1.400640 --> 1.389916).  Saving model ...
Validation loss decreased (1.389916 --> 1.381901).  Saving model ...
Validation loss decreased (1.381901 --> 1.373578).  Saving model ...
Validation loss decreased (1.373578 --> 1.366865).  Saving model ...
Validation loss decreased (1.366865 --> 1.361698).  Saving model ...
Validation loss decreased (1.361698 --> 1.356612).  Saving model ...
Validation loss decreased (1.356612 --> 1.352121).  Saving model ...
Validation loss decreased (1.352121 --> 1.347108).  Saving model ...
Validation loss decreased (1.347108 --> 1.342549).  Saving model ...
Validation loss decreased (1.342549 --> 1.337045).  Saving model ...
Validation loss decreased (1.337045 --> 1.332045).  Saving model ...
Validation loss decreased (1.332045 --> 1.327020).  Saving model ...
Validation loss decreased (1.327020 --> 1.321866).  Saving model ...
Validation loss decreased (1.321866 --> 1.316708).  Saving model ...
Validation loss decreased (1.316708 --> 1.311690).  Saving model ...
Validation loss decreased (1.311690 --> 1.306723).  Saving model ...
Validation loss decreased (1.306723 --> 1.301076).  Saving model ...
Validation loss decreased (1.301076 --> 1.295829).  Saving model ...
Validation loss decreased (1.295829 --> 1.289327).  Saving model ...
Validation loss decreased (1.289327 --> 1.283192).  Saving model ...
Validation loss decreased (1.283192 --> 1.277038).  Saving model ...
Validation loss decreased (1.277038 --> 1.269035).  Saving model ...
Validation loss decreased (1.269035 --> 1.263144).  Saving model ...
Validation loss decreased (1.263144 --> 1.255890).  Saving model ...
Validation loss decreased (1.255890 --> 1.248197).  Saving model ...
Validation loss decreased (1.248197 --> 1.240074).  Saving model ...
Validation loss decreased (1.240074 --> 1.231907).  Saving model ...
Validation loss decreased (1.231907 --> 1.225276).  Saving model ...
Validation loss decreased (1.225276 --> 1.217988).  Saving model ...
Validation loss decreased (1.217988 --> 1.210367).  Saving model ...
Validation loss decreased (1.210367 --> 1.201286).  Saving model ...
Validation loss decreased (1.201286 --> 1.194785).  Saving model ...
Validation loss decreased (1.194785 --> 1.187523).  Saving model ...
Validation loss decreased (1.187523 --> 1.178652).  Saving model ...
Validation loss decreased (1.178652 --> 1.171524).  Saving model ...
Validation loss decreased (1.171524 --> 1.163815).  Saving model ...
Validation loss decreased (1.163815 --> 1.155748).  Saving model ...
Validation loss decreased (1.155748 --> 1.149226).  Saving model ...
Validation loss decreased (1.149226 --> 1.141815).  Saving model ...
Validation loss decreased (1.141815 --> 1.134740).  Saving model ...
Validation loss decreased (1.134740 --> 1.127183).  Saving model ...
Validation loss decreased (1.127183 --> 1.120582).  Saving model ...
Validation loss decreased (1.120582 --> 1.113613).  Saving model ...
Validation loss decreased (1.113613 --> 1.109139).  Saving model ...
Validation loss decreased (1.109139 --> 1.103910).  Saving model ...
Validation loss decreased (1.103910 --> 1.098840).  Saving model ...
Validation loss decreased (1.098840 --> 1.093763).  Saving model ...
Validation loss decreased (1.093763 --> 1.089271).  Saving model ...
Validation loss decreased (1.089271 --> 1.083407).  Saving model ...
Validation loss decreased (1.083407 --> 1.078985).  Saving model ...
Validation loss decreased (1.078985 --> 1.075442).  Saving model ...
Validation loss decreased (1.075442 --> 1.068637).  Saving model ...
Validation loss decreased (1.068637 --> 1.064348).  Saving model ...
Validation loss decreased (1.064348 --> 1.060906).  Saving model ...
Validation loss decreased (1.060906 --> 1.057112).  Saving model ...
Validation loss decreased (1.057112 --> 1.052592).  Saving model ...
Validation loss decreased (1.052592 --> 1.049629).  Saving model ...
Validation loss decreased (1.049629 --> 1.045718).  Saving model ...
Validation loss decreased (1.045718 --> 1.041920).  Saving model ...
Validation loss decreased (1.041920 --> 1.037987).  Saving model ...
Validation loss decreased (1.037987 --> 1.034854).  Saving model ...
Validation loss decreased (1.034854 --> 1.030476).  Saving model ...
Validation loss decreased (1.030476 --> 1.026349).  Saving model ...
Validation loss decreased (1.026349 --> 1.021694).  Saving model ...
Validation loss decreased (1.021694 --> 1.018958).  Saving model ...
Validation loss decreased (1.018958 --> 1.017704).  Saving model ...
Validation loss decreased (1.017704 --> 1.015588).  Saving model ...
Validation loss decreased (1.015588 --> 1.012908).  Saving model ...
Validation loss decreased (1.012908 --> 1.009597).  Saving model ...
Validation loss decreased (1.009597 --> 1.005539).  Saving model ...
Validation loss decreased (1.005539 --> 1.001256).  Saving model ...
Validation loss decreased (1.001256 --> 0.999255).  Saving model ...
Validation loss decreased (0.999255 --> 0.998403).  Saving model ...
Validation loss decreased (0.998403 --> 0.995687).  Saving model ...
Validation loss decreased (0.995687 --> 0.992729).  Saving model ...
Validation loss decreased (0.992729 --> 0.991614).  Saving model ...
Validation loss decreased (0.991614 --> 0.989290).  Saving model ...
Validation loss decreased (0.989290 --> 0.986342).  Saving model ...
Validation loss decreased (0.986342 --> 0.985010).  Saving model ...
Validation loss decreased (0.985010 --> 0.983983).  Saving model ...
Validation loss decreased (0.983983 --> 0.980522).  Saving model ...
Validation loss decreased (0.980522 --> 0.978767).  Saving model ...
Validation loss decreased (0.978767 --> 0.977932).  Saving model ...
Validation loss decreased (0.977932 --> 0.974252).  Saving model ...
Validation loss decreased (0.974252 --> 0.972047).  Saving model ...
Validation loss decreased (0.972047 --> 0.970518).  Saving model ...
EarlyStopping counter: 1 out of 5.0
Validation loss decreased (0.970518 --> 0.968196).  Saving model ...
Validation loss decreased (0.968196 --> 0.965590).  Saving model ...
Validation loss decreased (0.965590 --> 0.964431).  Saving model ...
Validation loss decreased (0.964431 --> 0.963606).  Saving model ...
EarlyStopping counter: 1 out of 5.0
Validation loss decreased (0.963606 --> 0.960947).  Saving model ...
Validation loss decreased (0.960947 --> 0.959424).  Saving model ...
Validation loss decreased (0.959424 --> 0.959056).  Saving model ...
EarlyStopping counter: 1 out of 5.0
Validation loss decreased (0.959056 --> 0.958732).  Saving model ...
Validation loss decreased (0.958732 --> 0.958046).  Saving model ...
Validation loss decreased (0.958046 --> 0.957057).  Saving model ...
Validation loss decreased (0.957057 --> 0.955182).  Saving model ...
Validation loss decreased (0.955182 --> 0.951150).  Saving model ...
Validation loss decreased (0.951150 --> 0.949585).  Saving model ...
EarlyStopping counter: 1 out of 5.0
Validation loss decreased (0.949585 --> 0.949070).  Saving model ...
EarlyStopping counter: 1 out of 5.0
Validation loss decreased (0.949070 --> 0.948903).  Saving model ...
EarlyStopping counter: 1 out of 5.0
Validation loss decreased (0.948903 --> 0.948392).  Saving model ...
Validation loss decreased (0.948392 --> 0.946612).  Saving model ...
Validation loss decreased (0.946612 --> 0.945617).  Saving model ...
Validation loss decreased (0.945617 --> 0.944408).  Saving model ...
EarlyStopping counter: 1 out of 5.0
Validation loss decreased (0.944408 --> 0.942694).  Saving model ...
EarlyStopping counter: 1 out of 5.0
EarlyStopping counter: 2 out of 5.0
EarlyStopping counter: 3 out of 5.0
EarlyStopping counter: 4 out of 5.0
EarlyStopping counter: 5 out of 5.0
/localscratch/yinan.29200513.0/env/lib/python3.7/site-packages/torch/nn/functional.py:1794: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.
  warnings.warn("nn.functional.tanh is deprecated. Use torch.tanh instead.")
wandb: Waiting for W&B process to finish, PID 171200... (success).
wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: \ 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: | 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: / 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: \ 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: | 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: / 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: \ 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: | 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: / 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb:                                                                                
wandb: Run history:
wandb:     e_F1 ▁▁▃▄▅▆▆▆▆▆▇▇▆▇▇▇▇▇▇▇▇▇██████████████████
wandb:   e_loss █▇▇▇▇▆▆▆▆▅▅▅▄▄▄▃▃▃▃▃▂▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁
wandb:     t_F1 ▁▂▂▃▃▃▃▄▅▅▄▅▅▅▆▅▆▆▇▆▇▇▇▇▇▇▇▇██▇▇█▇██████
wandb:   t_loss █▇▇▇▇▇▇▇▆▆▆▆▆▅▅▅▄▄▄▄▄▃▄▃▃▃▃▃▂▂▂▂▂▂▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:     e_F1 59.90296
wandb:   e_loss 0.94337
wandb:     t_F1 66.99812
wandb:   t_loss 0.80071
wandb: 
wandb: Synced 4 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Synced eager-durian-2: https://wandb.ai/yinanazhou/xl_512_bs_8_lr_1e06_es_5_lc_False_nr_False_sr_True_stem_True_lemma_False_repeat_4_fold_2/runs/26x6qe0r
wandb: Find logs at: ./wandb/run-20220319_045817-26x6qe0r/logs/debug.log
wandb: 

wandb: wandb version 0.12.11 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
2022-03-19 06:15:24.774149: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1
wandb: Tracking run with wandb version 0.12.5
wandb: Syncing run whole-totem-2
wandb: ⭐️ View project at https://wandb.ai/yinanazhou/xl_512_bs_8_lr_1e06_es_5_lc_False_nr_False_sr_True_stem_True_lemma_False_repeat_5_fold_1
wandb: 🚀 View run at https://wandb.ai/yinanazhou/xl_512_bs_8_lr_1e06_es_5_lc_False_nr_False_sr_True_stem_True_lemma_False_repeat_5_fold_1/runs/33jusb93
wandb: Run data is saved locally in /project/6002780/yinan/Thesis_MER_Lyrics/lyric-emotion/wandb/run-20220319_061522-33jusb93
wandb: Run `wandb offline` to turn off syncing.

Validation loss decreased (inf --> 1.530662).  Saving model ...
Validation loss decreased (1.530662 --> 1.475950).  Saving model ...
Validation loss decreased (1.475950 --> 1.433591).  Saving model ...
Validation loss decreased (1.433591 --> 1.401624).  Saving model ...
Validation loss decreased (1.401624 --> 1.377775).  Saving model ...
Validation loss decreased (1.377775 --> 1.359877).  Saving model ...
Validation loss decreased (1.359877 --> 1.348281).  Saving model ...
Validation loss decreased (1.348281 --> 1.339824).  Saving model ...
Validation loss decreased (1.339824 --> 1.333992).  Saving model ...
Validation loss decreased (1.333992 --> 1.329552).  Saving model ...
Validation loss decreased (1.329552 --> 1.324759).  Saving model ...
Validation loss decreased (1.324759 --> 1.320255).  Saving model ...
Validation loss decreased (1.320255 --> 1.315022).  Saving model ...
Validation loss decreased (1.315022 --> 1.311007).  Saving model ...
Validation loss decreased (1.311007 --> 1.306034).  Saving model ...
Validation loss decreased (1.306034 --> 1.300979).  Saving model ...
Validation loss decreased (1.300979 --> 1.295780).  Saving model ...
Validation loss decreased (1.295780 --> 1.289931).  Saving model ...
Validation loss decreased (1.289931 --> 1.284425).  Saving model ...
Validation loss decreased (1.284425 --> 1.278783).  Saving model ...
Validation loss decreased (1.278783 --> 1.273912).  Saving model ...
Validation loss decreased (1.273912 --> 1.269189).  Saving model ...
Validation loss decreased (1.269189 --> 1.263802).  Saving model ...
Validation loss decreased (1.263802 --> 1.258652).  Saving model ...
Validation loss decreased (1.258652 --> 1.251600).  Saving model ...
Validation loss decreased (1.251600 --> 1.247587).  Saving model ...
Validation loss decreased (1.247587 --> 1.241048).  Saving model ...
Validation loss decreased (1.241048 --> 1.235460).  Saving model ...
Validation loss decreased (1.235460 --> 1.231387).  Saving model ...
Validation loss decreased (1.231387 --> 1.226038).  Saving model ...
Validation loss decreased (1.226038 --> 1.219415).  Saving model ...
Validation loss decreased (1.219415 --> 1.215242).  Saving model ...
Validation loss decreased (1.215242 --> 1.207132).  Saving model ...
Validation loss decreased (1.207132 --> 1.203117).  Saving model ...
Validation loss decreased (1.203117 --> 1.198870).  Saving model ...
Validation loss decreased (1.198870 --> 1.191941).  Saving model ...
Validation loss decreased (1.191941 --> 1.184075).  Saving model ...
Validation loss decreased (1.184075 --> 1.179834).  Saving model ...
Validation loss decreased (1.179834 --> 1.175142).  Saving model ...
Validation loss decreased (1.175142 --> 1.169735).  Saving model ...
Validation loss decreased (1.169735 --> 1.163356).  Saving model ...
Validation loss decreased (1.163356 --> 1.159231).  Saving model ...
Validation loss decreased (1.159231 --> 1.154330).  Saving model ...
Validation loss decreased (1.154330 --> 1.150021).  Saving model ...
Validation loss decreased (1.150021 --> 1.143380).  Saving model ...
Validation loss decreased (1.143380 --> 1.141036).  Saving model ...
Validation loss decreased (1.141036 --> 1.136375).  Saving model ...
Validation loss decreased (1.136375 --> 1.132543).  Saving model ...
Validation loss decreased (1.132543 --> 1.131306).  Saving model ...
Validation loss decreased (1.131306 --> 1.126714).  Saving model ...
Validation loss decreased (1.126714 --> 1.121317).  Saving model ...
Validation loss decreased (1.121317 --> 1.116765).  Saving model ...
Validation loss decreased (1.116765 --> 1.110869).  Saving model ...
Validation loss decreased (1.110869 --> 1.104703).  Saving model ...
Validation loss decreased (1.104703 --> 1.104473).  Saving model ...
Validation loss decreased (1.104473 --> 1.098431).  Saving model ...
Validation loss decreased (1.098431 --> 1.093447).  Saving model ...
Validation loss decreased (1.093447 --> 1.089817).  Saving model ...
Validation loss decreased (1.089817 --> 1.084050).  Saving model ...
Validation loss decreased (1.084050 --> 1.081097).  Saving model ...
Validation loss decreased (1.081097 --> 1.076288).  Saving model ...
Validation loss decreased (1.076288 --> 1.074418).  Saving model ...
Validation loss decreased (1.074418 --> 1.071755).  Saving model ...
Validation loss decreased (1.071755 --> 1.069535).  Saving model ...
Validation loss decreased (1.069535 --> 1.066350).  Saving model ...
Validation loss decreased (1.066350 --> 1.063546).  Saving model ...
Validation loss decreased (1.063546 --> 1.059456).  Saving model ...
Validation loss decreased (1.059456 --> 1.057204).  Saving model ...
Validation loss decreased (1.057204 --> 1.054631).  Saving model ...
Validation loss decreased (1.054631 --> 1.049092).  Saving model ...
Validation loss decreased (1.049092 --> 1.047792).  Saving model ...
Validation loss decreased (1.047792 --> 1.045273).  Saving model ...
Validation loss decreased (1.045273 --> 1.043833).  Saving model ...
Validation loss decreased (1.043833 --> 1.042275).  Saving model ...
Validation loss decreased (1.042275 --> 1.039500).  Saving model ...
Validation loss decreased (1.039500 --> 1.038502).  Saving model ...
Validation loss decreased (1.038502 --> 1.033850).  Saving model ...
Validation loss decreased (1.033850 --> 1.031749).  Saving model ...
Validation loss decreased (1.031749 --> 1.027521).  Saving model ...
Validation loss decreased (1.027521 --> 1.025585).  Saving model ...
Validation loss decreased (1.025585 --> 1.025035).  Saving model ...
Validation loss decreased (1.025035 --> 1.020707).  Saving model ...
EarlyStopping counter: 1 out of 5.0
Validation loss decreased (1.020707 --> 1.017210).  Saving model ...
Validation loss decreased (1.017210 --> 1.016054).  Saving model ...
Validation loss decreased (1.016054 --> 1.015719).  Saving model ...
Validation loss decreased (1.015719 --> 1.013187).  Saving model ...
Validation loss decreased (1.013187 --> 1.009263).  Saving model ...
EarlyStopping counter: 1 out of 5.0
EarlyStopping counter: 2 out of 5.0
EarlyStopping counter: 3 out of 5.0
Validation loss decreased (1.009263 --> 1.006283).  Saving model ...
Validation loss decreased (1.006283 --> 1.005110).  Saving model ...
EarlyStopping counter: 1 out of 5.0
Validation loss decreased (1.005110 --> 0.999607).  Saving model ...
EarlyStopping counter: 1 out of 5.0
Validation loss decreased (0.999607 --> 0.997642).  Saving model ...
Validation loss decreased (0.997642 --> 0.994729).  Saving model ...
Validation loss decreased (0.994729 --> 0.993246).  Saving model ...
Validation loss decreased (0.993246 --> 0.992310).  Saving model ...
EarlyStopping counter: 1 out of 5.0
EarlyStopping counter: 2 out of 5.0
Validation loss decreased (0.992310 --> 0.989672).  Saving model ...
Validation loss decreased (0.989672 --> 0.989107).  Saving model ...
EarlyStopping counter: 1 out of 5.0
EarlyStopping counter: 2 out of 5.0
Validation loss decreased (0.989107 --> 0.985170).  Saving model ...
Validation loss decreased (0.985170 --> 0.983741).  Saving model ...
EarlyStopping counter: 1 out of 5.0
EarlyStopping counter: 2 out of 5.0
EarlyStopping counter: 3 out of 5.0
EarlyStopping counter: 4 out of 5.0
EarlyStopping counter: 5 out of 5.0
/localscratch/yinan.29200513.0/env/lib/python3.7/site-packages/torch/nn/functional.py:1794: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.
  warnings.warn("nn.functional.tanh is deprecated. Use torch.tanh instead.")
wandb: Waiting for W&B process to finish, PID 175374... (success).
wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: \ 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: | 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: / 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: \ 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: | 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: / 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: \ 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: | 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: / 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: \ 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: | 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: / 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb:                                                                                
wandb: Run history:
wandb:     e_F1 ▁▂▃▅▅▅▅▅▅▆▆▆▆▇▇▇▇▇▇▇▇▇▇▇█▇▇█████████████
wandb:   e_loss █▇▆▅▅▅▅▅▅▄▄▄▄▃▃▃▃▃▃▃▂▂▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁
wandb:     t_F1 ▁▁▂▃▄▄▄▅▅▅▅▅▅▆▆▆▆▇▆▇▆▆▇▇▇▇▇▇▇▇██▇▇██████
wandb:   t_loss ██▇▆▆▆▆▅▅▅▅▅▅▄▄▄▄▄▄▃▃▃▃▃▃▂▂▂▂▂▂▂▂▂▂▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:     e_F1 55.46961
wandb:   e_loss 0.98813
wandb:     t_F1 67.4778
wandb:   t_loss 0.82978
wandb: 
wandb: Synced 4 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Synced whole-totem-2: https://wandb.ai/yinanazhou/xl_512_bs_8_lr_1e06_es_5_lc_False_nr_False_sr_True_stem_True_lemma_False_repeat_5_fold_1/runs/33jusb93
wandb: Find logs at: ./wandb/run-20220319_061522-33jusb93/logs/debug.log
wandb: 

wandb: wandb version 0.12.11 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
2022-03-19 07:30:09.405827: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1
wandb: Tracking run with wandb version 0.12.5
wandb: Syncing run breezy-mountain-2
wandb: ⭐️ View project at https://wandb.ai/yinanazhou/xl_512_bs_8_lr_1e06_es_5_lc_False_nr_False_sr_True_stem_True_lemma_False_repeat_5_fold_2
wandb: 🚀 View run at https://wandb.ai/yinanazhou/xl_512_bs_8_lr_1e06_es_5_lc_False_nr_False_sr_True_stem_True_lemma_False_repeat_5_fold_2/runs/1wosows4
wandb: Run data is saved locally in /project/6002780/yinan/Thesis_MER_Lyrics/lyric-emotion/wandb/run-20220319_073005-1wosows4
wandb: Run `wandb offline` to turn off syncing.

Validation loss decreased (inf --> 1.397698).  Saving model ...
Validation loss decreased (1.397698 --> 1.386594).  Saving model ...
Validation loss decreased (1.386594 --> 1.377663).  Saving model ...
Validation loss decreased (1.377663 --> 1.370719).  Saving model ...
Validation loss decreased (1.370719 --> 1.364493).  Saving model ...
Validation loss decreased (1.364493 --> 1.359218).  Saving model ...
Validation loss decreased (1.359218 --> 1.354335).  Saving model ...
Validation loss decreased (1.354335 --> 1.349338).  Saving model ...
Validation loss decreased (1.349338 --> 1.345261).  Saving model ...
Validation loss decreased (1.345261 --> 1.340897).  Saving model ...
Validation loss decreased (1.340897 --> 1.336141).  Saving model ...
Validation loss decreased (1.336141 --> 1.331973).  Saving model ...
Validation loss decreased (1.331973 --> 1.327467).  Saving model ...
Validation loss decreased (1.327467 --> 1.322477).  Saving model ...
Validation loss decreased (1.322477 --> 1.317193).  Saving model ...
Validation loss decreased (1.317193 --> 1.312003).  Saving model ...
Validation loss decreased (1.312003 --> 1.306857).  Saving model ...
Validation loss decreased (1.306857 --> 1.301634).  Saving model ...
Validation loss decreased (1.301634 --> 1.296752).  Saving model ...
Validation loss decreased (1.296752 --> 1.290789).  Saving model ...
Validation loss decreased (1.290789 --> 1.285376).  Saving model ...
Validation loss decreased (1.285376 --> 1.279495).  Saving model ...
Validation loss decreased (1.279495 --> 1.272880).  Saving model ...
Validation loss decreased (1.272880 --> 1.266088).  Saving model ...
Validation loss decreased (1.266088 --> 1.258473).  Saving model ...
Validation loss decreased (1.258473 --> 1.252317).  Saving model ...
Validation loss decreased (1.252317 --> 1.245614).  Saving model ...
Validation loss decreased (1.245614 --> 1.237860).  Saving model ...
Validation loss decreased (1.237860 --> 1.231838).  Saving model ...
Validation loss decreased (1.231838 --> 1.225296).  Saving model ...
Validation loss decreased (1.225296 --> 1.217844).  Saving model ...
Validation loss decreased (1.217844 --> 1.211211).  Saving model ...
Validation loss decreased (1.211211 --> 1.204986).  Saving model ...
Validation loss decreased (1.204986 --> 1.197627).  Saving model ...
Validation loss decreased (1.197627 --> 1.190525).  Saving model ...
Validation loss decreased (1.190525 --> 1.184812).  Saving model ...
Validation loss decreased (1.184812 --> 1.180317).  Saving model ...
Validation loss decreased (1.180317 --> 1.174123).  Saving model ...
Validation loss decreased (1.174123 --> 1.167137).  Saving model ...
Validation loss decreased (1.167137 --> 1.160895).  Saving model ...
Validation loss decreased (1.160895 --> 1.155947).  Saving model ...
Validation loss decreased (1.155947 --> 1.153005).  Saving model ...
Validation loss decreased (1.153005 --> 1.148508).  Saving model ...
Validation loss decreased (1.148508 --> 1.141677).  Saving model ...
Validation loss decreased (1.141677 --> 1.136641).  Saving model ...
Validation loss decreased (1.136641 --> 1.131593).  Saving model ...
Validation loss decreased (1.131593 --> 1.127308).  Saving model ...
Validation loss decreased (1.127308 --> 1.122104).  Saving model ...
Validation loss decreased (1.122104 --> 1.116167).  Saving model ...
Validation loss decreased (1.116167 --> 1.108797).  Saving model ...
Validation loss decreased (1.108797 --> 1.106141).  Saving model ...
Validation loss decreased (1.106141 --> 1.101989).  Saving model ...
Validation loss decreased (1.101989 --> 1.097866).  Saving model ...
Validation loss decreased (1.097866 --> 1.093387).  Saving model ...
Validation loss decreased (1.093387 --> 1.089675).  Saving model ...
Validation loss decreased (1.089675 --> 1.086584).  Saving model ...
Validation loss decreased (1.086584 --> 1.081320).  Saving model ...
Validation loss decreased (1.081320 --> 1.077606).  Saving model ...
Validation loss decreased (1.077606 --> 1.073595).  Saving model ...
Validation loss decreased (1.073595 --> 1.070555).  Saving model ...
Validation loss decreased (1.070555 --> 1.067907).  Saving model ...
Validation loss decreased (1.067907 --> 1.064006).  Saving model ...
Validation loss decreased (1.064006 --> 1.059099).  Saving model ...
Validation loss decreased (1.059099 --> 1.052910).  Saving model ...
Validation loss decreased (1.052910 --> 1.048722).  Saving model ...
Validation loss decreased (1.048722 --> 1.045337).  Saving model ...
Validation loss decreased (1.045337 --> 1.040975).  Saving model ...
Validation loss decreased (1.040975 --> 1.038235).  Saving model ...
Validation loss decreased (1.038235 --> 1.034811).  Saving model ...
Validation loss decreased (1.034811 --> 1.034199).  Saving model ...
Validation loss decreased (1.034199 --> 1.031520).  Saving model ...
Validation loss decreased (1.031520 --> 1.027414).  Saving model ...
Validation loss decreased (1.027414 --> 1.024464).  Saving model ...
Validation loss decreased (1.024464 --> 1.020794).  Saving model ...
Validation loss decreased (1.020794 --> 1.017855).  Saving model ...
Validation loss decreased (1.017855 --> 1.015401).  Saving model ...
Validation loss decreased (1.015401 --> 1.013467).  Saving model ...
Validation loss decreased (1.013467 --> 1.010834).  Saving model ...
Validation loss decreased (1.010834 --> 1.010347).  Saving model ...
Validation loss decreased (1.010347 --> 1.007959).  Saving model ...
Validation loss decreased (1.007959 --> 1.005026).  Saving model ...
Validation loss decreased (1.005026 --> 1.001166).  Saving model ...
Validation loss decreased (1.001166 --> 0.998411).  Saving model ...
Validation loss decreased (0.998411 --> 0.998222).  Saving model ...
Validation loss decreased (0.998222 --> 0.995526).  Saving model ...
Validation loss decreased (0.995526 --> 0.992625).  Saving model ...
Validation loss decreased (0.992625 --> 0.989317).  Saving model ...
Validation loss decreased (0.989317 --> 0.988729).  Saving model ...
Validation loss decreased (0.988729 --> 0.987544).  Saving model ...
Validation loss decreased (0.987544 --> 0.986803).  Saving model ...
Validation loss decreased (0.986803 --> 0.985408).  Saving model ...
Validation loss decreased (0.985408 --> 0.985256).  Saving model ...
Validation loss decreased (0.985256 --> 0.980143).  Saving model ...
EarlyStopping counter: 1 out of 5.0
Validation loss decreased (0.980143 --> 0.976673).  Saving model ...
Validation loss decreased (0.976673 --> 0.974480).  Saving model ...
Validation loss decreased (0.974480 --> 0.973129).  Saving model ...
Validation loss decreased (0.973129 --> 0.972083).  Saving model ...
Validation loss decreased (0.972083 --> 0.970801).  Saving model ...
EarlyStopping counter: 1 out of 5.0
Validation loss decreased (0.970801 --> 0.968718).  Saving model ...
Validation loss decreased (0.968718 --> 0.967691).  Saving model ...
Validation loss decreased (0.967691 --> 0.965458).  Saving model ...
EarlyStopping counter: 1 out of 5.0
EarlyStopping counter: 2 out of 5.0
Validation loss decreased (0.965458 --> 0.963755).  Saving model ...
Validation loss decreased (0.963755 --> 0.961355).  Saving model ...
Validation loss decreased (0.961355 --> 0.957817).  Saving model ...
Validation loss decreased (0.957817 --> 0.957493).  Saving model ...
Validation loss decreased (0.957493 --> 0.956828).  Saving model ...
Validation loss decreased (0.956828 --> 0.955781).  Saving model ...
Validation loss decreased (0.955781 --> 0.955781).  Saving model ...
Validation loss decreased (0.955781 --> 0.954179).  Saving model ...
EarlyStopping counter: 1 out of 5.0
Validation loss decreased (0.954179 --> 0.953770).  Saving model ...
Validation loss decreased (0.953770 --> 0.952743).  Saving model ...
Validation loss decreased (0.952743 --> 0.951957).  Saving model ...
Validation loss decreased (0.951957 --> 0.951707).  Saving model ...
Validation loss decreased (0.951707 --> 0.949788).  Saving model ...
Validation loss decreased (0.949788 --> 0.948317).  Saving model ...
EarlyStopping counter: 1 out of 5.0
Validation loss decreased (0.948317 --> 0.947173).  Saving model ...
Validation loss decreased (0.947173 --> 0.947026).  Saving model ...
Validation loss decreased (0.947026 --> 0.946019).  Saving model ...
Validation loss decreased (0.946019 --> 0.945790).  Saving model ...
EarlyStopping counter: 1 out of 5.0
Validation loss decreased (0.945790 --> 0.942900).  Saving model ...
Validation loss decreased (0.942900 --> 0.942286).  Saving model ...
Validation loss decreased (0.942286 --> 0.942263).  Saving model ...
Validation loss decreased (0.942263 --> 0.941956).  Saving model ...
Validation loss decreased (0.941956 --> 0.940276).  Saving model ...
Validation loss decreased (0.940276 --> 0.939410).  Saving model ...
EarlyStopping counter: 1 out of 5.0
Validation loss decreased (0.939410 --> 0.938273).  Saving model ...
EarlyStopping counter: 1 out of 5.0
EarlyStopping counter: 2 out of 5.0
EarlyStopping counter: 3 out of 5.0
EarlyStopping counter: 4 out of 5.0
EarlyStopping counter: 5 out of 5.0
/localscratch/yinan.29200513.0/env/lib/python3.7/site-packages/torch/nn/functional.py:1794: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.
  warnings.warn("nn.functional.tanh is deprecated. Use torch.tanh instead.")
wandb: Waiting for W&B process to finish, PID 179411... (success).
wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: \ 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: | 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: / 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: \ 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: | 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: / 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: \ 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: | 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: / 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb:                                                                                
wandb: Run history:
wandb:     e_F1 ▁▁▃▄▄▅▆▆▆▆▆▆▆▇▇▇▇▇▇▇▇▇█▇▇███████████████
wandb:   e_loss ██▇▇▇▇▆▆▆▅▅▄▄▄▄▃▃▃▃▃▂▂▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁
wandb:     t_F1 ▁▂▂▃▃▃▃▄▄▅▅▅▅▅▆▅▆▆▆▆▅▆▆▆▆▇▇▇▇▇▇▇▇▇▇▇▇▇██
wandb:   t_loss ███▇▇▇▇▇▆▆▆▆▅▅▄▅▄▄▄▃▄▄▃▃▃▃▃▂▂▂▂▂▂▁▂▂▁▂▁▁
wandb: 
wandb: Run summary:
wandb:     e_F1 62.58119
wandb:   e_loss 0.93911
wandb:     t_F1 70.38015
wandb:   t_loss 0.78052
wandb: 
wandb: Synced 4 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Synced breezy-mountain-2: https://wandb.ai/yinanazhou/xl_512_bs_8_lr_1e06_es_5_lc_False_nr_False_sr_True_stem_True_lemma_False_repeat_5_fold_2/runs/1wosows4
wandb: Find logs at: ./wandb/run-20220319_073005-1wosows4/logs/debug.log
wandb: 

