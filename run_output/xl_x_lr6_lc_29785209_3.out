Unloading StdEnv/2020

Due to MODULEPATH changes, the following have been reloaded:
  1) mii/1.1.1


The following have been reloaded with a version change:
  1) python/3.8.2 => python/3.7.4

Using base prefix '/cvmfs/soft.computecanada.ca/easybuild/software/2017/Core/python/3.7.4'
New python executable in /localscratch/yinan.29785209.0/env/bin/python
Installing setuptools, pip, wheel...
done.
Ignoring pip: markers 'python_version < "3"' don't match your environment
Looking in links: /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/nix/avx2, /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/nix/generic, /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic
Collecting pip
Installing collected packages: pip
  Found existing installation: pip 19.1.1
    Uninstalling pip-19.1.1:
      Successfully uninstalled pip-19.1.1
Successfully installed pip-21.2.3+computecanada
Looking in links: /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/nix/avx2, /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/nix/generic, /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/keras-2.8.0+computecanada-py2.py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/Keras_Preprocessing-1.1.2+computecanada-py3-none-any.whl
Requirement already satisfied: matplotlib in /cvmfs/soft.computecanada.ca/easybuild/software/2017/Core/scipy-stack/2019a/lib/python3.7/site-packages (from -r requirements.txt (line 3)) (3.0.2)
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/nltk-3.6.5+computecanada-py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/scikit_learn-0.22.1+computecanada-cp37-cp37m-linux_x86_64.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/tensorboard-2.3.0+computecanada-py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/tensorboard_plugin_wit-1.7.0+computecanada-py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/tensorflow_gpu-2.3.0+computecanada-cp37-cp37m-linux_x86_64.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/tensorflow_estimator-2.3.0+computecanada-py2.py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/tokenizers-0.5.2+computecanada-cp37-cp37m-linux_x86_64.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/nix/avx2/torch-1.4.0+computecanada-cp37-cp37m-linux_x86_64.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/torchtext-0.6.0+computecanada-py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/torchvision-0.8.2+computecanada-cp37-cp37m-linux_x86_64.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/transformers-2.5.1+computecanada-py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/urllib3-1.26.7+computecanada-py2.py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/joblib-1.1.0+computecanada-py2.py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/tqdm-4.63.1+computecanada-py2.py3-none-any.whl
ERROR: Could not find a version that satisfies the requirement regex>=2021.8.3 (from nltk) (from versions: 2018.1.10+computecanada, 2019.11.1+computecanada, 2020.11.13+computecanada)
ERROR: No matching distribution found for regex>=2021.8.3
Looking in links: /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/nix/avx2, /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/nix/generic, /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic
ERROR: Could not find a version that satisfies the requirement numpy==1.20.0+computacanada (from versions: 1.15.0+computecanada, 1.15.2+computecanada, 1.15.4+computecanada, 1.16.0+computecanada, 1.16.2+computecanada, 1.16.3+computecanada, 1.17.4+computecanada, 1.18.1+computecanada, 1.18.4+computecanada, 1.19.1+computecanada, 1.19.2+computecanada, 1.20.2+computecanada)
ERROR: No matching distribution found for numpy==1.20.0+computacanada
Looking in links: /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/nix/avx2, /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/nix/generic, /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/wandb-0.12.5+computecanada-py2.py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/GitPython-3.1.24+computecanada-py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/promise-2.3+computecanada-py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/docker_pycreds-0.4.0+computecanada-py2.py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/configparser-5.0.2+computecanada-py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/psutil-5.7.3+computecanada-cp37-cp37m-linux_x86_64.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/protobuf-3.19.4+computecanada-py2.py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/PyYAML-5.3.1+computecanada-cp37-cp37m-linux_x86_64.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/pathtools-0.1.2+computecanada-py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/shortuuid-1.0.1+computecanada-py3-none-any.whl
Requirement already satisfied: python-dateutil>=2.6.1 in /cvmfs/soft.computecanada.ca/easybuild/software/2017/Core/scipy-stack/2019a/lib/python3.7/site-packages (from wandb) (2.7.5)
Requirement already satisfied: requests<3,>=2.0.0 in /cvmfs/soft.computecanada.ca/easybuild/software/2017/Core/scipy-stack/2019a/lib/python3.7/site-packages (from wandb) (2.21.0)
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/subprocess32-3.5.4+computecanada-py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/sentry_sdk-1.5.0+computecanada-py2.py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/yaspin-2.1.0+computecanada-py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/click-8.1.0+computecanada-py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/six-1.16.0+computecanada-py2.py3-none-any.whl
Requirement already satisfied: importlib-metadata in /cvmfs/soft.computecanada.ca/easybuild/software/2017/Core/scipy-stack/2019a/lib/python3.7/site-packages (from Click!=8.0.0,>=7.0->wandb) (0.8)
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/typing_extensions-4.1.1+computecanada-py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/gitdb-4.0.9+computecanada-py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/smmap-5.0.0+computecanada-py3-none-any.whl
Requirement already satisfied: certifi>=2017.4.17 in /cvmfs/soft.computecanada.ca/easybuild/software/2017/Core/scipy-stack/2019a/lib/python3.7/site-packages (from requests<3,>=2.0.0->wandb) (2018.11.29)
Requirement already satisfied: urllib3<1.25,>=1.21.1 in /cvmfs/soft.computecanada.ca/easybuild/software/2017/Core/scipy-stack/2019a/lib/python3.7/site-packages (from requests<3,>=2.0.0->wandb) (1.24.1)
Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /cvmfs/soft.computecanada.ca/easybuild/software/2017/Core/scipy-stack/2019a/lib/python3.7/site-packages (from requests<3,>=2.0.0->wandb) (3.0.4)
Requirement already satisfied: idna<2.9,>=2.5 in /cvmfs/soft.computecanada.ca/easybuild/software/2017/Core/scipy-stack/2019a/lib/python3.7/site-packages (from requests<3,>=2.0.0->wandb) (2.8)
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/termcolor-1.1.0+computecanada-py3-none-any.whl
Requirement already satisfied: zipp>=0.3.2 in /cvmfs/soft.computecanada.ca/easybuild/software/2017/Core/scipy-stack/2019a/lib/python3.7/site-packages (from importlib-metadata->Click!=8.0.0,>=7.0->wandb) (0.3.3)
Installing collected packages: smmap, typing-extensions, termcolor, six, gitdb, yaspin, subprocess32, shortuuid, sentry-sdk, PyYAML, psutil, protobuf, promise, pathtools, GitPython, docker-pycreds, configparser, Click, wandb
  Attempting uninstall: six
    Found existing installation: six 1.12.0
    Not uninstalling six at /cvmfs/soft.computecanada.ca/easybuild/software/2017/Core/scipy-stack/2019a/lib/python3.7/site-packages, outside environment /localscratch/yinan.29785209.0/env
    Can't uninstall 'six'. No files were found to uninstall.
Successfully installed Click-8.1.0+computecanada GitPython-3.1.24+computecanada PyYAML-5.3.1+computecanada configparser-5.0.2+computecanada docker-pycreds-0.4.0+computecanada gitdb-4.0.9+computecanada pathtools-0.1.2+computecanada promise-2.3+computecanada protobuf-3.19.4+computecanada psutil-5.7.3+computecanada sentry-sdk-1.5.0+computecanada shortuuid-1.0.1+computecanada six-1.16.0+computecanada smmap-5.0.0+computecanada subprocess32-3.5.4+computecanada termcolor-1.1.0+computecanada typing-extensions-4.1.1+computecanada wandb-0.12.5+computecanada yaspin-2.1.0+computecanada
Looking in links: /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/nix/avx2, /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/nix/generic, /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic
ERROR: Could not find a version that satisfies the requirement sagemaker (from versions: none)
ERROR: No matching distribution found for sagemaker
Looking in links: /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/nix/avx2, /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/nix/generic, /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/torch-1.9.1+computecanada-cp37-cp37m-linux_x86_64.whl
Requirement already satisfied: typing-extensions in /localscratch/yinan.29785209.0/env/lib/python3.7/site-packages (from torch) (4.1.1+computecanada)
Installing collected packages: torch
Successfully installed torch-1.9.1+computecanada
Looking in links: /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/nix/avx2, /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/nix/generic, /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/transformers-2.5.1+computecanada-py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/filelock-3.4.2+computecanada-py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/tqdm-4.63.1+computecanada-py2.py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/sentencepiece-0.1.91+computecanada-cp37-cp37m-linux_x86_64.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/tokenizers-0.5.2+computecanada-cp37-cp37m-linux_x86_64.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/regex-2020.11.13+computecanada-cp37-cp37m-linux_x86_64.whl
Requirement already satisfied: numpy in /cvmfs/soft.computecanada.ca/easybuild/software/2017/Core/scipy-stack/2019a/lib/python3.7/site-packages (from transformers==2.5.1+computecanada) (1.16.0)
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/sacremoses-0.0.49+computecanada-py3-none-any.whl
Requirement already satisfied: requests in /cvmfs/soft.computecanada.ca/easybuild/software/2017/Core/scipy-stack/2019a/lib/python3.7/site-packages (from transformers==2.5.1+computecanada) (2.21.0)
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/boto3-1.21.14+computecanada-py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/s3transfer-0.5.1+computecanada-py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/jmespath-0.10.0+computecanada-py2.py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/botocore-1.24.14+computecanada-py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/urllib3-1.26.9+computecanada-py2.py3-none-any.whl
Requirement already satisfied: python-dateutil<3.0.0,>=2.1 in /cvmfs/soft.computecanada.ca/easybuild/software/2017/Core/scipy-stack/2019a/lib/python3.7/site-packages (from botocore<1.25.0,>=1.24.14->boto3->transformers==2.5.1+computecanada) (2.7.5)
Requirement already satisfied: six>=1.5 in /localscratch/yinan.29785209.0/env/lib/python3.7/site-packages (from python-dateutil<3.0.0,>=2.1->botocore<1.25.0,>=1.24.14->boto3->transformers==2.5.1+computecanada) (1.16.0+computecanada)
Requirement already satisfied: idna<2.9,>=2.5 in /cvmfs/soft.computecanada.ca/easybuild/software/2017/Core/scipy-stack/2019a/lib/python3.7/site-packages (from requests->transformers==2.5.1+computecanada) (2.8)
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/requests-2.27.1+computecanada-py2.py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/charset_normalizer-2.0.12+computecanada-py3-none-any.whl
Requirement already satisfied: certifi>=2017.4.17 in /cvmfs/soft.computecanada.ca/easybuild/software/2017/Core/scipy-stack/2019a/lib/python3.7/site-packages (from requests->transformers==2.5.1+computecanada) (2018.11.29)
Requirement already satisfied: click in /localscratch/yinan.29785209.0/env/lib/python3.7/site-packages (from sacremoses->transformers==2.5.1+computecanada) (8.1.0+computecanada)
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/joblib-1.1.0+computecanada-py2.py3-none-any.whl
Requirement already satisfied: importlib-metadata in /cvmfs/soft.computecanada.ca/easybuild/software/2017/Core/scipy-stack/2019a/lib/python3.7/site-packages (from click->sacremoses->transformers==2.5.1+computecanada) (0.8)
Requirement already satisfied: zipp>=0.3.2 in /cvmfs/soft.computecanada.ca/easybuild/software/2017/Core/scipy-stack/2019a/lib/python3.7/site-packages (from importlib-metadata->click->sacremoses->transformers==2.5.1+computecanada) (0.3.3)
Installing collected packages: urllib3, jmespath, botocore, tqdm, s3transfer, regex, joblib, charset-normalizer, tokenizers, sentencepiece, sacremoses, requests, filelock, boto3, transformers
  Attempting uninstall: urllib3
    Found existing installation: urllib3 1.24.1
    Not uninstalling urllib3 at /cvmfs/soft.computecanada.ca/easybuild/software/2017/Core/scipy-stack/2019a/lib/python3.7/site-packages, outside environment /localscratch/yinan.29785209.0/env
    Can't uninstall 'urllib3'. No files were found to uninstall.
  Attempting uninstall: requests
    Found existing installation: requests 2.21.0
    Not uninstalling requests at /cvmfs/soft.computecanada.ca/easybuild/software/2017/Core/scipy-stack/2019a/lib/python3.7/site-packages, outside environment /localscratch/yinan.29785209.0/env
    Can't uninstall 'requests'. No files were found to uninstall.
Successfully installed boto3-1.21.14+computecanada botocore-1.24.14+computecanada charset-normalizer-2.0.12+computecanada filelock-3.4.2+computecanada jmespath-0.10.0+computecanada joblib-1.1.0+computecanada regex-2020.11.13+computecanada requests-2.27.1+computecanada s3transfer-0.5.1+computecanada sacremoses-0.0.49+computecanada sentencepiece-0.1.91+computecanada tokenizers-0.5.2+computecanada tqdm-4.63.1+computecanada transformers-2.5.1+computecanada urllib3-1.26.9+computecanada
Looking in links: /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/nix/avx2, /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/nix/generic, /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/tensorflow_gpu-2.3.0+computecanada-cp37-cp37m-linux_x86_64.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/nix/generic/scipy-1.4.1+computecanada-cp37-cp37m-linux_x86_64.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/tensorboard-2.8.0+computecanada-py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/nix/avx2/h5py-2.10.0+computecanada-cp37-cp37m-linux_x86_64.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/grpcio-1.38.0+computecanada-cp37-cp37m-linux_x86_64.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/tensorflow_estimator-2.3.0+computecanada-py2.py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/absl_py-1.0.0+computecanada-py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/gast-0.3.3+computecanada-py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/opt_einsum-3.3.0+computecanada-py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/Keras_Preprocessing-1.1.2+computecanada-py3-none-any.whl
Requirement already satisfied: six>=1.12.0 in /localscratch/yinan.29785209.0/env/lib/python3.7/site-packages (from tensorflow_gpu==2.3.0+computecanada) (1.16.0+computecanada)
Requirement already satisfied: numpy<1.19.0,>=1.16.0 in /cvmfs/soft.computecanada.ca/easybuild/software/2017/Core/scipy-stack/2019a/lib/python3.7/site-packages (from tensorflow_gpu==2.3.0+computecanada) (1.16.0)
Requirement already satisfied: wheel>=0.26 in /localscratch/yinan.29785209.0/env/lib/python3.7/site-packages (from tensorflow_gpu==2.3.0+computecanada) (0.33.4)
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/astunparse-1.6.3+computecanada-py2.py3-none-any.whl
Requirement already satisfied: protobuf>=3.9.2 in /localscratch/yinan.29785209.0/env/lib/python3.7/site-packages (from tensorflow_gpu==2.3.0+computecanada) (3.19.4+computecanada)
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/wrapt-1.11.2+computecanada-cp37-cp37m-linux_x86_64.whl
Requirement already satisfied: termcolor>=1.1.0 in /localscratch/yinan.29785209.0/env/lib/python3.7/site-packages (from tensorflow_gpu==2.3.0+computecanada) (1.1.0+computecanada)
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/google_pasta-0.2.0+computecanada-py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/tensorboard_data_server-0.6.1+computecanada-py3-none-linux_x86_64.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/tensorboard_plugin_wit-1.8.0+computecanada-py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/Werkzeug-2.0.3+computecanada-py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/Markdown-3.3.6+computecanada-py3-none-any.whl
Requirement already satisfied: requests<3,>=2.21.0 in /localscratch/yinan.29785209.0/env/lib/python3.7/site-packages (from tensorboard<3,>=2.3.0->tensorflow_gpu==2.3.0+computecanada) (2.27.1+computecanada)
Requirement already satisfied: setuptools>=41.0.0 in /localscratch/yinan.29785209.0/env/lib/python3.7/site-packages (from tensorboard<3,>=2.3.0->tensorflow_gpu==2.3.0+computecanada) (41.0.1)
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/google_auth-2.3.3+computecanada-py2.py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/google_auth_oauthlib-0.4.6+computecanada-py2.py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/cachetools-4.2.4+computecanada-py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/pyasn1_modules-0.2.8+computecanada-py2.py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/rsa-4.8+computecanada-py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/requests_oauthlib-1.3.0+computecanada-py2.py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/importlib_metadata-4.10.1+computecanada-py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/zipp-3.7.0+computecanada-py3-none-any.whl
Requirement already satisfied: typing-extensions>=3.6.4 in /localscratch/yinan.29785209.0/env/lib/python3.7/site-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard<3,>=2.3.0->tensorflow_gpu==2.3.0+computecanada) (4.1.1+computecanada)
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/pyasn1-0.4.8+computecanada-py2.py3-none-any.whl
Requirement already satisfied: urllib3<1.27,>=1.21.1 in /localscratch/yinan.29785209.0/env/lib/python3.7/site-packages (from requests<3,>=2.21.0->tensorboard<3,>=2.3.0->tensorflow_gpu==2.3.0+computecanada) (1.26.9+computecanada)
Requirement already satisfied: certifi>=2017.4.17 in /cvmfs/soft.computecanada.ca/easybuild/software/2017/Core/scipy-stack/2019a/lib/python3.7/site-packages (from requests<3,>=2.21.0->tensorboard<3,>=2.3.0->tensorflow_gpu==2.3.0+computecanada) (2018.11.29)
Requirement already satisfied: charset-normalizer~=2.0.0 in /localscratch/yinan.29785209.0/env/lib/python3.7/site-packages (from requests<3,>=2.21.0->tensorboard<3,>=2.3.0->tensorflow_gpu==2.3.0+computecanada) (2.0.12+computecanada)
Requirement already satisfied: idna<4,>=2.5 in /cvmfs/soft.computecanada.ca/easybuild/software/2017/Core/scipy-stack/2019a/lib/python3.7/site-packages (from requests<3,>=2.21.0->tensorboard<3,>=2.3.0->tensorflow_gpu==2.3.0+computecanada) (2.8)
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/oauthlib-3.1.1+computecanada-py2.py3-none-any.whl
Installing collected packages: pyasn1, zipp, rsa, pyasn1-modules, oauthlib, cachetools, requests-oauthlib, importlib-metadata, google-auth, werkzeug, tensorboard-plugin-wit, tensorboard-data-server, markdown, grpcio, google-auth-oauthlib, absl-py, wrapt, tensorflow-estimator, tensorboard, scipy, opt-einsum, keras-preprocessing, h5py, google-pasta, gast, astunparse, tensorflow-gpu
  Attempting uninstall: pyasn1
    Found existing installation: pyasn1 0.4.3
    Not uninstalling pyasn1 at /cvmfs/soft.computecanada.ca/easybuild/software/2017/Core/scipy-stack/2019a/lib/python3.7/site-packages, outside environment /localscratch/yinan.29785209.0/env
    Can't uninstall 'pyasn1'. No files were found to uninstall.
  Attempting uninstall: zipp
    Found existing installation: zipp 0.3.3
    Not uninstalling zipp at /cvmfs/soft.computecanada.ca/easybuild/software/2017/Core/scipy-stack/2019a/lib/python3.7/site-packages, outside environment /localscratch/yinan.29785209.0/env
    Can't uninstall 'zipp'. No files were found to uninstall.
  Attempting uninstall: importlib-metadata
    Found existing installation: importlib-metadata 0.8
    Not uninstalling importlib-metadata at /cvmfs/soft.computecanada.ca/easybuild/software/2017/Core/scipy-stack/2019a/lib/python3.7/site-packages, outside environment /localscratch/yinan.29785209.0/env
    Can't uninstall 'importlib-metadata'. No files were found to uninstall.
  Attempting uninstall: scipy
    Found existing installation: scipy 1.2.0
    Not uninstalling scipy at /cvmfs/soft.computecanada.ca/easybuild/software/2017/Core/scipy-stack/2019a/lib/python3.7/site-packages, outside environment /localscratch/yinan.29785209.0/env
    Can't uninstall 'scipy'. No files were found to uninstall.
Successfully installed absl-py-1.0.0+computecanada astunparse-1.6.3+computecanada cachetools-4.2.4+computecanada gast-0.3.3+computecanada google-auth-2.3.3+computecanada google-auth-oauthlib-0.4.6+computecanada google-pasta-0.2.0+computecanada grpcio-1.38.0+computecanada h5py-2.10.0+computecanada importlib-metadata-4.10.1+computecanada keras-preprocessing-1.1.2+computecanada markdown-3.3.6+computecanada oauthlib-3.1.1+computecanada opt-einsum-3.3.0+computecanada pyasn1-0.4.8+computecanada pyasn1-modules-0.2.8+computecanada requests-oauthlib-1.3.0+computecanada rsa-4.8+computecanada scipy-1.4.1+computecanada tensorboard-2.8.0+computecanada tensorboard-data-server-0.6.1+computecanada tensorboard-plugin-wit-1.8.0+computecanada tensorflow-estimator-2.3.0+computecanada tensorflow-gpu-2.3.0+computecanada werkzeug-2.0.3+computecanada wrapt-1.11.2+computecanada zipp-3.7.0+computecanada
Looking in links: /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/nix/avx2, /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/nix/generic, /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/keras-2.8.0+computecanada-py2.py3-none-any.whl
Installing collected packages: Keras
Successfully installed Keras-2.8.0+computecanada
Looking in links: /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/nix/avx2, /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/nix/generic, /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/urllib3-1.26.7+computecanada-py2.py3-none-any.whl
Installing collected packages: urllib3
  Attempting uninstall: urllib3
    Found existing installation: urllib3 1.26.9+computecanada
    Uninstalling urllib3-1.26.9+computecanada:
      Successfully uninstalled urllib3-1.26.9+computecanada
Successfully installed urllib3-1.26.7+computecanada
Looking in links: /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/nix/avx2, /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/nix/generic, /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/nltk-3.7+computecanada-py3-none-any.whl
Requirement already satisfied: click in /localscratch/yinan.29785209.0/env/lib/python3.7/site-packages (from nltk) (8.1.0+computecanada)
Requirement already satisfied: tqdm in /localscratch/yinan.29785209.0/env/lib/python3.7/site-packages (from nltk) (4.63.1+computecanada)
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/nltk-3.6.5+computecanada-py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/nltk-3.6.3+computecanada-py3-none-any.whl
Requirement already satisfied: regex in /localscratch/yinan.29785209.0/env/lib/python3.7/site-packages (from nltk) (2020.11.13+computecanada)
Requirement already satisfied: joblib in /localscratch/yinan.29785209.0/env/lib/python3.7/site-packages (from nltk) (1.1.0+computecanada)
Requirement already satisfied: importlib-metadata in /localscratch/yinan.29785209.0/env/lib/python3.7/site-packages (from click->nltk) (4.10.1+computecanada)
Requirement already satisfied: typing-extensions>=3.6.4 in /localscratch/yinan.29785209.0/env/lib/python3.7/site-packages (from importlib-metadata->click->nltk) (4.1.1+computecanada)
Requirement already satisfied: zipp>=0.5 in /localscratch/yinan.29785209.0/env/lib/python3.7/site-packages (from importlib-metadata->click->nltk) (3.7.0+computecanada)
Installing collected packages: nltk
Successfully installed nltk-3.6.3+computecanada
Looking in links: /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/nix/avx2, /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/nix/generic, /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/scikit_learn-0.22.1+computecanada-cp37-cp37m-linux_x86_64.whl
Requirement already satisfied: joblib>=0.11 in /localscratch/yinan.29785209.0/env/lib/python3.7/site-packages (from scikit-learn==0.22.1) (1.1.0+computecanada)
Requirement already satisfied: numpy>=1.11.0 in /cvmfs/soft.computecanada.ca/easybuild/software/2017/Core/scipy-stack/2019a/lib/python3.7/site-packages (from scikit-learn==0.22.1) (1.16.0)
Requirement already satisfied: scipy>=0.17.0 in /localscratch/yinan.29785209.0/env/lib/python3.7/site-packages (from scikit-learn==0.22.1) (1.4.1+computecanada)
Installing collected packages: scikit-learn
Successfully installed scikit-learn-0.22.1+computecanada
Looking in links: /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/nix/avx2, /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/nix/generic, /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic
Requirement already satisfied: tokenizers==0.5.2 in /localscratch/yinan.29785209.0/env/lib/python3.7/site-packages (0.5.2+computecanada)
wandb: Appending key for api.wandb.ai to your netrc file: /home/yinan/.netrc
Starting Task
2022-03-29 20:33:19.454821: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1
[nltk_data] Downloading package stopwords to /home/yinan/nltk_data...
[nltk_data]   Package stopwords is already up-to-date!
[nltk_data] Downloading package wordnet to /home/yinan/nltk_data...
[nltk_data]   Package wordnet is already up-to-date!
wandb: Currently logged in as: yinanazhou (use `wandb login --relogin` to force relogin)
wandb: wandb version 0.12.11 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
2022-03-29 20:33:31.023316: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1
wandb: Tracking run with wandb version 0.12.5
wandb: Syncing run still-durian-2
wandb: ⭐️ View project at https://wandb.ai/yinanazhou/xl_512_bs_8_lr_1e06_es_3_lc_True_nr_False_sr_False_stem_False_lemma_False_repeat_1_fold_1
wandb: 🚀 View run at https://wandb.ai/yinanazhou/xl_512_bs_8_lr_1e06_es_3_lc_True_nr_False_sr_False_stem_False_lemma_False_repeat_1_fold_1/runs/3o1caixm
wandb: Run data is saved locally in /project/6002780/yinan/Thesis_MER_Lyrics/lyric-emotion/wandb/run-20220329_203328-3o1caixm
wandb: Run `wandb offline` to turn off syncing.

Validation loss decreased (inf --> 1.433313).  Saving model ...
Validation loss decreased (1.433313 --> 1.413823).  Saving model ...
Validation loss decreased (1.413823 --> 1.397634).  Saving model ...
Validation loss decreased (1.397634 --> 1.384729).  Saving model ...
Validation loss decreased (1.384729 --> 1.374505).  Saving model ...
Validation loss decreased (1.374505 --> 1.365789).  Saving model ...
Validation loss decreased (1.365789 --> 1.358431).  Saving model ...
Validation loss decreased (1.358431 --> 1.352422).  Saving model ...
Validation loss decreased (1.352422 --> 1.347176).  Saving model ...
Validation loss decreased (1.347176 --> 1.341239).  Saving model ...
Validation loss decreased (1.341239 --> 1.335240).  Saving model ...
Validation loss decreased (1.335240 --> 1.329805).  Saving model ...
Validation loss decreased (1.329805 --> 1.324280).  Saving model ...
Validation loss decreased (1.324280 --> 1.319049).  Saving model ...
Validation loss decreased (1.319049 --> 1.314033).  Saving model ...
Validation loss decreased (1.314033 --> 1.308356).  Saving model ...
Validation loss decreased (1.308356 --> 1.302842).  Saving model ...
Validation loss decreased (1.302842 --> 1.296422).  Saving model ...
Validation loss decreased (1.296422 --> 1.289807).  Saving model ...
Validation loss decreased (1.289807 --> 1.282416).  Saving model ...
Validation loss decreased (1.282416 --> 1.275527).  Saving model ...
Validation loss decreased (1.275527 --> 1.268434).  Saving model ...
Validation loss decreased (1.268434 --> 1.262217).  Saving model ...
Validation loss decreased (1.262217 --> 1.255003).  Saving model ...
Validation loss decreased (1.255003 --> 1.246530).  Saving model ...
Validation loss decreased (1.246530 --> 1.239448).  Saving model ...
Validation loss decreased (1.239448 --> 1.233109).  Saving model ...
Validation loss decreased (1.233109 --> 1.226549).  Saving model ...
Validation loss decreased (1.226549 --> 1.220859).  Saving model ...
Validation loss decreased (1.220859 --> 1.215898).  Saving model ...
Validation loss decreased (1.215898 --> 1.207550).  Saving model ...
Validation loss decreased (1.207550 --> 1.203158).  Saving model ...
Validation loss decreased (1.203158 --> 1.199874).  Saving model ...
Validation loss decreased (1.199874 --> 1.194043).  Saving model ...
Validation loss decreased (1.194043 --> 1.186784).  Saving model ...
Validation loss decreased (1.186784 --> 1.182782).  Saving model ...
Validation loss decreased (1.182782 --> 1.174996).  Saving model ...
Validation loss decreased (1.174996 --> 1.170641).  Saving model ...
Validation loss decreased (1.170641 --> 1.168795).  Saving model ...
Validation loss decreased (1.168795 --> 1.166190).  Saving model ...
Validation loss decreased (1.166190 --> 1.161606).  Saving model ...
Validation loss decreased (1.161606 --> 1.154363).  Saving model ...
Validation loss decreased (1.154363 --> 1.150958).  Saving model ...
Validation loss decreased (1.150958 --> 1.147520).  Saving model ...
Validation loss decreased (1.147520 --> 1.144593).  Saving model ...
Validation loss decreased (1.144593 --> 1.139181).  Saving model ...
Validation loss decreased (1.139181 --> 1.135060).  Saving model ...
Validation loss decreased (1.135060 --> 1.131736).  Saving model ...
Validation loss decreased (1.131736 --> 1.125831).  Saving model ...
Validation loss decreased (1.125831 --> 1.122838).  Saving model ...
Validation loss decreased (1.122838 --> 1.116849).  Saving model ...
Validation loss decreased (1.116849 --> 1.114160).  Saving model ...
Validation loss decreased (1.114160 --> 1.112123).  Saving model ...
Validation loss decreased (1.112123 --> 1.107845).  Saving model ...
EarlyStopping counter: 1 out of 3.0
Validation loss decreased (1.107845 --> 1.104358).  Saving model ...
Validation loss decreased (1.104358 --> 1.099308).  Saving model ...
Validation loss decreased (1.099308 --> 1.093686).  Saving model ...
Validation loss decreased (1.093686 --> 1.088410).  Saving model ...
EarlyStopping counter: 1 out of 3.0
EarlyStopping counter: 2 out of 3.0
Validation loss decreased (1.088410 --> 1.084482).  Saving model ...
Validation loss decreased (1.084482 --> 1.080187).  Saving model ...
Validation loss decreased (1.080187 --> 1.076264).  Saving model ...
Validation loss decreased (1.076264 --> 1.075939).  Saving model ...
Validation loss decreased (1.075939 --> 1.072168).  Saving model ...
Validation loss decreased (1.072168 --> 1.070593).  Saving model ...
Validation loss decreased (1.070593 --> 1.066321).  Saving model ...
Validation loss decreased (1.066321 --> 1.061729).  Saving model ...
Validation loss decreased (1.061729 --> 1.058850).  Saving model ...
Validation loss decreased (1.058850 --> 1.056024).  Saving model ...
Validation loss decreased (1.056024 --> 1.053853).  Saving model ...
Validation loss decreased (1.053853 --> 1.053145).  Saving model ...
Validation loss decreased (1.053145 --> 1.049757).  Saving model ...
Validation loss decreased (1.049757 --> 1.047381).  Saving model ...
Validation loss decreased (1.047381 --> 1.045632).  Saving model ...
Validation loss decreased (1.045632 --> 1.043149).  Saving model ...
Validation loss decreased (1.043149 --> 1.040299).  Saving model ...
Validation loss decreased (1.040299 --> 1.038331).  Saving model ...
Validation loss decreased (1.038331 --> 1.035407).  Saving model ...
EarlyStopping counter: 1 out of 3.0
EarlyStopping counter: 2 out of 3.0
EarlyStopping counter: 3 out of 3.0
/localscratch/yinan.29785209.0/env/lib/python3.7/site-packages/torch/nn/functional.py:1794: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.
  warnings.warn("nn.functional.tanh is deprecated. Use torch.tanh instead.")
/localscratch/yinan.29785209.0/env/lib/python3.7/site-packages/transformers/optimization.py:155: UserWarning: This overload of add_ is deprecated:
	add_(Number alpha, Tensor other)
Consider using one of the following signatures instead:
	add_(Tensor other, *, Number alpha) (Triggered internally at  ../torch/csrc/utils/python_arg_parser.cpp:1025.)
  exp_avg.mul_(beta1).add_(1.0 - beta1, grad)
wandb: Waiting for W&B process to finish, PID 2244... (success).
wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: \ 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: | 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: / 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: \ 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: | 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: / 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: \ 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: | 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: / 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb:                                                                                
wandb: Run history:
wandb:     e_F1 ▁▁▂▃▄▅▅▆▆▆▆▆▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇████████████
wandb:   e_loss █▇▇▇▆▆▆▆▆▅▅▅▅▄▄▄▄▄▃▃▃▃▃▃▂▂▂▂▂▂▂▂▂▁▁▁▁▁▁▁
wandb:     t_F1 ▁▁▁▃▂▃▃▃▃▄▄▄▅▅▅▆▆▅▆▆▆▆▆▇▆▇▆▇▇▇▇▇▇▇▇▇▇█▇█
wandb:   t_loss ██▇▇▇▇▇▇▇▆▆▆▅▅▅▅▅▄▄▄▄▄▄▃▃▃▃▃▂▃▂▂▂▂▂▁▂▁▁▁
wandb: 
wandb: Run summary:
wandb:     e_F1 56.25608
wandb:   e_loss 1.03583
wandb:     t_F1 66.7826
wandb:   t_loss 0.87546
wandb: 
wandb: Synced 4 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Synced still-durian-2: https://wandb.ai/yinanazhou/xl_512_bs_8_lr_1e06_es_3_lc_True_nr_False_sr_False_stem_False_lemma_False_repeat_1_fold_1/runs/3o1caixm
wandb: Find logs at: ./wandb/run-20220329_203328-3o1caixm/logs/debug.log
wandb: 

wandb: wandb version 0.12.11 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
2022-03-29 21:26:39.853135: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1
wandb: Tracking run with wandb version 0.12.5
wandb: Syncing run super-armadillo-2
wandb: ⭐️ View project at https://wandb.ai/yinanazhou/xl_512_bs_8_lr_1e06_es_3_lc_True_nr_False_sr_False_stem_False_lemma_False_repeat_1_fold_2
wandb: 🚀 View run at https://wandb.ai/yinanazhou/xl_512_bs_8_lr_1e06_es_3_lc_True_nr_False_sr_False_stem_False_lemma_False_repeat_1_fold_2/runs/20dh34fh
wandb: Run data is saved locally in /project/6002780/yinan/Thesis_MER_Lyrics/lyric-emotion/wandb/run-20220329_212637-20dh34fh
wandb: Run `wandb offline` to turn off syncing.

Validation loss decreased (inf --> 1.479745).  Saving model ...
Validation loss decreased (1.479745 --> 1.446771).  Saving model ...
Validation loss decreased (1.446771 --> 1.420332).  Saving model ...
Validation loss decreased (1.420332 --> 1.401502).  Saving model ...
Validation loss decreased (1.401502 --> 1.386879).  Saving model ...
Validation loss decreased (1.386879 --> 1.376087).  Saving model ...
Validation loss decreased (1.376087 --> 1.367420).  Saving model ...
Validation loss decreased (1.367420 --> 1.359757).  Saving model ...
Validation loss decreased (1.359757 --> 1.353003).  Saving model ...
Validation loss decreased (1.353003 --> 1.347084).  Saving model ...
Validation loss decreased (1.347084 --> 1.342397).  Saving model ...
Validation loss decreased (1.342397 --> 1.337323).  Saving model ...
Validation loss decreased (1.337323 --> 1.332740).  Saving model ...
Validation loss decreased (1.332740 --> 1.327721).  Saving model ...
Validation loss decreased (1.327721 --> 1.322857).  Saving model ...
Validation loss decreased (1.322857 --> 1.317298).  Saving model ...
Validation loss decreased (1.317298 --> 1.311413).  Saving model ...
Validation loss decreased (1.311413 --> 1.305246).  Saving model ...
Validation loss decreased (1.305246 --> 1.300067).  Saving model ...
Validation loss decreased (1.300067 --> 1.294788).  Saving model ...
Validation loss decreased (1.294788 --> 1.288403).  Saving model ...
Validation loss decreased (1.288403 --> 1.281341).  Saving model ...
Validation loss decreased (1.281341 --> 1.274647).  Saving model ...
Validation loss decreased (1.274647 --> 1.267915).  Saving model ...
Validation loss decreased (1.267915 --> 1.261663).  Saving model ...
Validation loss decreased (1.261663 --> 1.255526).  Saving model ...
Validation loss decreased (1.255526 --> 1.248975).  Saving model ...
Validation loss decreased (1.248975 --> 1.243251).  Saving model ...
Validation loss decreased (1.243251 --> 1.236638).  Saving model ...
Validation loss decreased (1.236638 --> 1.230774).  Saving model ...
Validation loss decreased (1.230774 --> 1.225021).  Saving model ...
Validation loss decreased (1.225021 --> 1.219147).  Saving model ...
Validation loss decreased (1.219147 --> 1.212667).  Saving model ...
Validation loss decreased (1.212667 --> 1.205817).  Saving model ...
Validation loss decreased (1.205817 --> 1.203497).  Saving model ...
Validation loss decreased (1.203497 --> 1.197550).  Saving model ...
Validation loss decreased (1.197550 --> 1.191756).  Saving model ...
Validation loss decreased (1.191756 --> 1.183790).  Saving model ...
Validation loss decreased (1.183790 --> 1.178257).  Saving model ...
Validation loss decreased (1.178257 --> 1.173274).  Saving model ...
Validation loss decreased (1.173274 --> 1.168306).  Saving model ...
Validation loss decreased (1.168306 --> 1.162175).  Saving model ...
Validation loss decreased (1.162175 --> 1.157341).  Saving model ...
Validation loss decreased (1.157341 --> 1.148206).  Saving model ...
Validation loss decreased (1.148206 --> 1.142663).  Saving model ...
Validation loss decreased (1.142663 --> 1.138800).  Saving model ...
Validation loss decreased (1.138800 --> 1.130909).  Saving model ...
Validation loss decreased (1.130909 --> 1.125379).  Saving model ...
Validation loss decreased (1.125379 --> 1.121749).  Saving model ...
Validation loss decreased (1.121749 --> 1.115509).  Saving model ...
Validation loss decreased (1.115509 --> 1.110611).  Saving model ...
Validation loss decreased (1.110611 --> 1.105127).  Saving model ...
Validation loss decreased (1.105127 --> 1.097586).  Saving model ...
Validation loss decreased (1.097586 --> 1.094574).  Saving model ...
Validation loss decreased (1.094574 --> 1.090889).  Saving model ...
Validation loss decreased (1.090889 --> 1.086281).  Saving model ...
Validation loss decreased (1.086281 --> 1.079740).  Saving model ...
Validation loss decreased (1.079740 --> 1.072971).  Saving model ...
Validation loss decreased (1.072971 --> 1.069272).  Saving model ...
Validation loss decreased (1.069272 --> 1.064613).  Saving model ...
Validation loss decreased (1.064613 --> 1.057842).  Saving model ...
Validation loss decreased (1.057842 --> 1.053327).  Saving model ...
Validation loss decreased (1.053327 --> 1.051439).  Saving model ...
Validation loss decreased (1.051439 --> 1.045904).  Saving model ...
Validation loss decreased (1.045904 --> 1.042504).  Saving model ...
Validation loss decreased (1.042504 --> 1.037631).  Saving model ...
Validation loss decreased (1.037631 --> 1.034594).  Saving model ...
Validation loss decreased (1.034594 --> 1.032282).  Saving model ...
Validation loss decreased (1.032282 --> 1.025865).  Saving model ...
Validation loss decreased (1.025865 --> 1.021685).  Saving model ...
Validation loss decreased (1.021685 --> 1.017799).  Saving model ...
Validation loss decreased (1.017799 --> 1.014898).  Saving model ...
Validation loss decreased (1.014898 --> 1.009973).  Saving model ...
Validation loss decreased (1.009973 --> 1.005751).  Saving model ...
Validation loss decreased (1.005751 --> 1.002581).  Saving model ...
Validation loss decreased (1.002581 --> 0.999283).  Saving model ...
Validation loss decreased (0.999283 --> 0.996894).  Saving model ...
Validation loss decreased (0.996894 --> 0.991915).  Saving model ...
Validation loss decreased (0.991915 --> 0.989841).  Saving model ...
Validation loss decreased (0.989841 --> 0.988363).  Saving model ...
Validation loss decreased (0.988363 --> 0.986531).  Saving model ...
Validation loss decreased (0.986531 --> 0.982850).  Saving model ...
Validation loss decreased (0.982850 --> 0.980479).  Saving model ...
Validation loss decreased (0.980479 --> 0.978375).  Saving model ...
Validation loss decreased (0.978375 --> 0.976428).  Saving model ...
Validation loss decreased (0.976428 --> 0.971721).  Saving model ...
EarlyStopping counter: 1 out of 3.0
Validation loss decreased (0.971721 --> 0.970926).  Saving model ...
Validation loss decreased (0.970926 --> 0.966944).  Saving model ...
Validation loss decreased (0.966944 --> 0.964253).  Saving model ...
Validation loss decreased (0.964253 --> 0.963275).  Saving model ...
Validation loss decreased (0.963275 --> 0.961756).  Saving model ...
Validation loss decreased (0.961756 --> 0.959037).  Saving model ...
Validation loss decreased (0.959037 --> 0.955767).  Saving model ...
Validation loss decreased (0.955767 --> 0.953109).  Saving model ...
Validation loss decreased (0.953109 --> 0.950506).  Saving model ...
EarlyStopping counter: 1 out of 3.0
Validation loss decreased (0.950506 --> 0.948049).  Saving model ...
Validation loss decreased (0.948049 --> 0.945583).  Saving model ...
Validation loss decreased (0.945583 --> 0.943323).  Saving model ...
Validation loss decreased (0.943323 --> 0.942492).  Saving model ...
Validation loss decreased (0.942492 --> 0.940998).  Saving model ...
Validation loss decreased (0.940998 --> 0.939553).  Saving model ...
Validation loss decreased (0.939553 --> 0.937239).  Saving model ...
Validation loss decreased (0.937239 --> 0.936316).  Saving model ...
Validation loss decreased (0.936316 --> 0.935197).  Saving model ...
EarlyStopping counter: 1 out of 3.0
Validation loss decreased (0.935197 --> 0.933158).  Saving model ...
Validation loss decreased (0.933158 --> 0.932226).  Saving model ...
Validation loss decreased (0.932226 --> 0.930900).  Saving model ...
Validation loss decreased (0.930900 --> 0.930432).  Saving model ...
Validation loss decreased (0.930432 --> 0.929197).  Saving model ...
EarlyStopping counter: 1 out of 3.0
EarlyStopping counter: 2 out of 3.0
EarlyStopping counter: 3 out of 3.0
/localscratch/yinan.29785209.0/env/lib/python3.7/site-packages/torch/nn/functional.py:1794: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.
  warnings.warn("nn.functional.tanh is deprecated. Use torch.tanh instead.")
wandb: Waiting for W&B process to finish, PID 5105... (success).
wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: \ 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: | 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: / 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: \ 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: | 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: / 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: \ 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: | 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: / 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: \ 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: | 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: / 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb:                                                                                
wandb: Run history:
wandb:     e_F1 ▁▁▁▃▄▄▅▅▆▆▆▆▆▆▆▇▇▇▇▇▇███████████████████
wandb:   e_loss █▇▇▆▆▆▆▆▅▅▅▅▄▄▄▄▄▃▃▃▃▃▂▂▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁
wandb:     t_F1 ▁▁▂▂▃▃▄▄▄▅▅▅▆▅▆▆▆▆▆▇▇▇▇▇▇▇▇▇▇▇█▇▇█▇█████
wandb:   t_loss ██▇▇▇▇▆▆▆▆▅▅▅▅▅▅▅▄▄▄▄▄▃▃▃▃▃▃▃▂▂▂▂▂▂▁▁▁▂▁
wandb: 
wandb: Run summary:
wandb:     e_F1 59.4428
wandb:   e_loss 0.93009
wandb:     t_F1 69.11127
wandb:   t_loss 0.80351
wandb: 
wandb: Synced 4 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Synced super-armadillo-2: https://wandb.ai/yinanazhou/xl_512_bs_8_lr_1e06_es_3_lc_True_nr_False_sr_False_stem_False_lemma_False_repeat_1_fold_2/runs/20dh34fh
wandb: Find logs at: ./wandb/run-20220329_212637-20dh34fh/logs/debug.log
wandb: 

wandb: wandb version 0.12.11 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
2022-03-29 22:42:48.335334: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1
wandb: Tracking run with wandb version 0.12.5
wandb: Syncing run autumn-lion-2
wandb: ⭐️ View project at https://wandb.ai/yinanazhou/xl_512_bs_8_lr_1e06_es_3_lc_True_nr_False_sr_False_stem_False_lemma_False_repeat_2_fold_1
wandb: 🚀 View run at https://wandb.ai/yinanazhou/xl_512_bs_8_lr_1e06_es_3_lc_True_nr_False_sr_False_stem_False_lemma_False_repeat_2_fold_1/runs/2vqkgp8s
wandb: Run data is saved locally in /project/6002780/yinan/Thesis_MER_Lyrics/lyric-emotion/wandb/run-20220329_224246-2vqkgp8s
wandb: Run `wandb offline` to turn off syncing.

Validation loss decreased (inf --> 1.491888).  Saving model ...
Validation loss decreased (1.491888 --> 1.457082).  Saving model ...
Validation loss decreased (1.457082 --> 1.430883).  Saving model ...
Validation loss decreased (1.430883 --> 1.410011).  Saving model ...
Validation loss decreased (1.410011 --> 1.393218).  Saving model ...
Validation loss decreased (1.393218 --> 1.379855).  Saving model ...
Validation loss decreased (1.379855 --> 1.369125).  Saving model ...
Validation loss decreased (1.369125 --> 1.360607).  Saving model ...
Validation loss decreased (1.360607 --> 1.353339).  Saving model ...
Validation loss decreased (1.353339 --> 1.346458).  Saving model ...
Validation loss decreased (1.346458 --> 1.340015).  Saving model ...
Validation loss decreased (1.340015 --> 1.334587).  Saving model ...
Validation loss decreased (1.334587 --> 1.328976).  Saving model ...
Validation loss decreased (1.328976 --> 1.323323).  Saving model ...
Validation loss decreased (1.323323 --> 1.318112).  Saving model ...
Validation loss decreased (1.318112 --> 1.313016).  Saving model ...
Validation loss decreased (1.313016 --> 1.307829).  Saving model ...
Validation loss decreased (1.307829 --> 1.302928).  Saving model ...
Validation loss decreased (1.302928 --> 1.297796).  Saving model ...
Validation loss decreased (1.297796 --> 1.292037).  Saving model ...
Validation loss decreased (1.292037 --> 1.287259).  Saving model ...
Validation loss decreased (1.287259 --> 1.280737).  Saving model ...
Validation loss decreased (1.280737 --> 1.274943).  Saving model ...
Validation loss decreased (1.274943 --> 1.268207).  Saving model ...
Validation loss decreased (1.268207 --> 1.261657).  Saving model ...
Validation loss decreased (1.261657 --> 1.255049).  Saving model ...
Validation loss decreased (1.255049 --> 1.248412).  Saving model ...
Validation loss decreased (1.248412 --> 1.240490).  Saving model ...
Validation loss decreased (1.240490 --> 1.232437).  Saving model ...
Validation loss decreased (1.232437 --> 1.225788).  Saving model ...
Validation loss decreased (1.225788 --> 1.217251).  Saving model ...
Validation loss decreased (1.217251 --> 1.210963).  Saving model ...
Validation loss decreased (1.210963 --> 1.204602).  Saving model ...
Validation loss decreased (1.204602 --> 1.196349).  Saving model ...
Validation loss decreased (1.196349 --> 1.188917).  Saving model ...
Validation loss decreased (1.188917 --> 1.182214).  Saving model ...
Validation loss decreased (1.182214 --> 1.174632).  Saving model ...
Validation loss decreased (1.174632 --> 1.168197).  Saving model ...
Validation loss decreased (1.168197 --> 1.160593).  Saving model ...
Validation loss decreased (1.160593 --> 1.153541).  Saving model ...
Validation loss decreased (1.153541 --> 1.147090).  Saving model ...
Validation loss decreased (1.147090 --> 1.139117).  Saving model ...
Validation loss decreased (1.139117 --> 1.132229).  Saving model ...
Validation loss decreased (1.132229 --> 1.124537).  Saving model ...
Validation loss decreased (1.124537 --> 1.119781).  Saving model ...
Validation loss decreased (1.119781 --> 1.114034).  Saving model ...
Validation loss decreased (1.114034 --> 1.107038).  Saving model ...
Validation loss decreased (1.107038 --> 1.101236).  Saving model ...
Validation loss decreased (1.101236 --> 1.096360).  Saving model ...
Validation loss decreased (1.096360 --> 1.091667).  Saving model ...
Validation loss decreased (1.091667 --> 1.087788).  Saving model ...
Validation loss decreased (1.087788 --> 1.082678).  Saving model ...
Validation loss decreased (1.082678 --> 1.077606).  Saving model ...
Validation loss decreased (1.077606 --> 1.071676).  Saving model ...
Validation loss decreased (1.071676 --> 1.064709).  Saving model ...
Validation loss decreased (1.064709 --> 1.062300).  Saving model ...
Validation loss decreased (1.062300 --> 1.057794).  Saving model ...
Validation loss decreased (1.057794 --> 1.053944).  Saving model ...
Validation loss decreased (1.053944 --> 1.049351).  Saving model ...
Validation loss decreased (1.049351 --> 1.045904).  Saving model ...
Validation loss decreased (1.045904 --> 1.041212).  Saving model ...
Validation loss decreased (1.041212 --> 1.037843).  Saving model ...
Validation loss decreased (1.037843 --> 1.033305).  Saving model ...
Validation loss decreased (1.033305 --> 1.030533).  Saving model ...
Validation loss decreased (1.030533 --> 1.028201).  Saving model ...
Validation loss decreased (1.028201 --> 1.025612).  Saving model ...
Validation loss decreased (1.025612 --> 1.021522).  Saving model ...
Validation loss decreased (1.021522 --> 1.017894).  Saving model ...
Validation loss decreased (1.017894 --> 1.014453).  Saving model ...
Validation loss decreased (1.014453 --> 1.011254).  Saving model ...
Validation loss decreased (1.011254 --> 1.009062).  Saving model ...
Validation loss decreased (1.009062 --> 1.006027).  Saving model ...
Validation loss decreased (1.006027 --> 1.004825).  Saving model ...
Validation loss decreased (1.004825 --> 1.000465).  Saving model ...
Validation loss decreased (1.000465 --> 0.996782).  Saving model ...
Validation loss decreased (0.996782 --> 0.995705).  Saving model ...
Validation loss decreased (0.995705 --> 0.993981).  Saving model ...
Validation loss decreased (0.993981 --> 0.991033).  Saving model ...
Validation loss decreased (0.991033 --> 0.988064).  Saving model ...
Validation loss decreased (0.988064 --> 0.986881).  Saving model ...
Validation loss decreased (0.986881 --> 0.984829).  Saving model ...
Validation loss decreased (0.984829 --> 0.982783).  Saving model ...
Validation loss decreased (0.982783 --> 0.980588).  Saving model ...
Validation loss decreased (0.980588 --> 0.979613).  Saving model ...
Validation loss decreased (0.979613 --> 0.977558).  Saving model ...
Validation loss decreased (0.977558 --> 0.975290).  Saving model ...
Validation loss decreased (0.975290 --> 0.973216).  Saving model ...
Validation loss decreased (0.973216 --> 0.971978).  Saving model ...
Validation loss decreased (0.971978 --> 0.971518).  Saving model ...
Validation loss decreased (0.971518 --> 0.969251).  Saving model ...
Validation loss decreased (0.969251 --> 0.966068).  Saving model ...
Validation loss decreased (0.966068 --> 0.964668).  Saving model ...
Validation loss decreased (0.964668 --> 0.964190).  Saving model ...
Validation loss decreased (0.964190 --> 0.964129).  Saving model ...
Validation loss decreased (0.964129 --> 0.961648).  Saving model ...
Validation loss decreased (0.961648 --> 0.961441).  Saving model ...
Validation loss decreased (0.961441 --> 0.958917).  Saving model ...
Validation loss decreased (0.958917 --> 0.957481).  Saving model ...
Validation loss decreased (0.957481 --> 0.957247).  Saving model ...
Validation loss decreased (0.957247 --> 0.956714).  Saving model ...
Validation loss decreased (0.956714 --> 0.956599).  Saving model ...
Validation loss decreased (0.956599 --> 0.955063).  Saving model ...
Validation loss decreased (0.955063 --> 0.953838).  Saving model ...
Validation loss decreased (0.953838 --> 0.953208).  Saving model ...
Validation loss decreased (0.953208 --> 0.952184).  Saving model ...
Validation loss decreased (0.952184 --> 0.951112).  Saving model ...
Validation loss decreased (0.951112 --> 0.950304).  Saving model ...
Validation loss decreased (0.950304 --> 0.949156).  Saving model ...
Validation loss decreased (0.949156 --> 0.948685).  Saving model ...
Validation loss decreased (0.948685 --> 0.947746).  Saving model ...
Validation loss decreased (0.947746 --> 0.947488).  Saving model ...
EarlyStopping counter: 1 out of 3.0
EarlyStopping counter: 2 out of 3.0
Validation loss decreased (0.947488 --> 0.947415).  Saving model ...
Validation loss decreased (0.947415 --> 0.947252).  Saving model ...
Validation loss decreased (0.947252 --> 0.946732).  Saving model ...
Validation loss decreased (0.946732 --> 0.946228).  Saving model ...
EarlyStopping counter: 1 out of 3.0
EarlyStopping counter: 2 out of 3.0
EarlyStopping counter: 3 out of 3.0
/localscratch/yinan.29785209.0/env/lib/python3.7/site-packages/torch/nn/functional.py:1794: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.
  warnings.warn("nn.functional.tanh is deprecated. Use torch.tanh instead.")
wandb: Waiting for W&B process to finish, PID 9194... (success).
wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: \ 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: | 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: / 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: \ 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: | 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: / 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: \ 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: | 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: / 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: \ 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: | 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: / 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: \ 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: | 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: / 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: \ 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: | 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: / 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: \ 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: | 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: / 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: \ 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: | 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: / 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: \ 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: | 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: / 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: \ 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: | 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb:                                                                                
wandb: Run history:
wandb:     e_F1 ▁▂▂▃▄▅▅▅▆▆▆▆▇▇▇▇▇███████████████████████
wandb:   e_loss █▇▆▆▆▆▆▅▅▅▄▄▄▄▃▃▃▃▃▂▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:     t_F1 ▁▂▂▃▃▃▃▄▅▄▅▅▆▆▆▆▆▆▆▇▆▆▇▇▇▇█▇█▇▇▇▇██▇█▇██
wandb:   t_loss █▇▇▇▆▆▆▆▆▆▅▅▅▅▄▄▄▄▃▃▃▃▃▃▃▃▂▂▂▂▂▂▂▂▂▁▂▁▁▁
wandb: 
wandb: Run summary:
wandb:     e_F1 58.04778
wandb:   e_loss 0.94737
wandb:     t_F1 69.66631
wandb:   t_loss 0.76735
wandb: 
wandb: Synced 4 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Synced autumn-lion-2: https://wandb.ai/yinanazhou/xl_512_bs_8_lr_1e06_es_3_lc_True_nr_False_sr_False_stem_False_lemma_False_repeat_2_fold_1/runs/2vqkgp8s
wandb: Find logs at: ./wandb/run-20220329_224246-2vqkgp8s/logs/debug.log
wandb: 

wandb: wandb version 0.12.11 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
2022-03-30 00:02:12.554296: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1
wandb: Tracking run with wandb version 0.12.5
wandb: Syncing run clean-salad-2
wandb: ⭐️ View project at https://wandb.ai/yinanazhou/xl_512_bs_8_lr_1e06_es_3_lc_True_nr_False_sr_False_stem_False_lemma_False_repeat_2_fold_2
wandb: 🚀 View run at https://wandb.ai/yinanazhou/xl_512_bs_8_lr_1e06_es_3_lc_True_nr_False_sr_False_stem_False_lemma_False_repeat_2_fold_2/runs/1uj9qgt2
wandb: Run data is saved locally in /project/6002780/yinan/Thesis_MER_Lyrics/lyric-emotion/wandb/run-20220330_000210-1uj9qgt2
wandb: Run `wandb offline` to turn off syncing.

Validation loss decreased (inf --> 1.397529).  Saving model ...
Validation loss decreased (1.397529 --> 1.389558).  Saving model ...
Validation loss decreased (1.389558 --> 1.383537).  Saving model ...
Validation loss decreased (1.383537 --> 1.378335).  Saving model ...
Validation loss decreased (1.378335 --> 1.373991).  Saving model ...
Validation loss decreased (1.373991 --> 1.370083).  Saving model ...
Validation loss decreased (1.370083 --> 1.367000).  Saving model ...
Validation loss decreased (1.367000 --> 1.363664).  Saving model ...
Validation loss decreased (1.363664 --> 1.360364).  Saving model ...
Validation loss decreased (1.360364 --> 1.356920).  Saving model ...
Validation loss decreased (1.356920 --> 1.353763).  Saving model ...
Validation loss decreased (1.353763 --> 1.350705).  Saving model ...
Validation loss decreased (1.350705 --> 1.347240).  Saving model ...
Validation loss decreased (1.347240 --> 1.344044).  Saving model ...
Validation loss decreased (1.344044 --> 1.340617).  Saving model ...
Validation loss decreased (1.340617 --> 1.337124).  Saving model ...
Validation loss decreased (1.337124 --> 1.333216).  Saving model ...
Validation loss decreased (1.333216 --> 1.329128).  Saving model ...
Validation loss decreased (1.329128 --> 1.325028).  Saving model ...
Validation loss decreased (1.325028 --> 1.320626).  Saving model ...
Validation loss decreased (1.320626 --> 1.317123).  Saving model ...
Validation loss decreased (1.317123 --> 1.312932).  Saving model ...
Validation loss decreased (1.312932 --> 1.307795).  Saving model ...
Validation loss decreased (1.307795 --> 1.303025).  Saving model ...
Validation loss decreased (1.303025 --> 1.297441).  Saving model ...
Validation loss decreased (1.297441 --> 1.291536).  Saving model ...
Validation loss decreased (1.291536 --> 1.285257).  Saving model ...
Validation loss decreased (1.285257 --> 1.279421).  Saving model ...
Validation loss decreased (1.279421 --> 1.272976).  Saving model ...
Validation loss decreased (1.272976 --> 1.266462).  Saving model ...
Validation loss decreased (1.266462 --> 1.258691).  Saving model ...
Validation loss decreased (1.258691 --> 1.251687).  Saving model ...
Validation loss decreased (1.251687 --> 1.243361).  Saving model ...
Validation loss decreased (1.243361 --> 1.235995).  Saving model ...
Validation loss decreased (1.235995 --> 1.230460).  Saving model ...
Validation loss decreased (1.230460 --> 1.221287).  Saving model ...
Validation loss decreased (1.221287 --> 1.214430).  Saving model ...
Validation loss decreased (1.214430 --> 1.208557).  Saving model ...
Validation loss decreased (1.208557 --> 1.200616).  Saving model ...
Validation loss decreased (1.200616 --> 1.193292).  Saving model ...
Validation loss decreased (1.193292 --> 1.187263).  Saving model ...
Validation loss decreased (1.187263 --> 1.179593).  Saving model ...
Validation loss decreased (1.179593 --> 1.173145).  Saving model ...
Validation loss decreased (1.173145 --> 1.168130).  Saving model ...
Validation loss decreased (1.168130 --> 1.160999).  Saving model ...
Validation loss decreased (1.160999 --> 1.155110).  Saving model ...
Validation loss decreased (1.155110 --> 1.148156).  Saving model ...
Validation loss decreased (1.148156 --> 1.143287).  Saving model ...
Validation loss decreased (1.143287 --> 1.137519).  Saving model ...
Validation loss decreased (1.137519 --> 1.130844).  Saving model ...
Validation loss decreased (1.130844 --> 1.125479).  Saving model ...
Validation loss decreased (1.125479 --> 1.120486).  Saving model ...
Validation loss decreased (1.120486 --> 1.117893).  Saving model ...
Validation loss decreased (1.117893 --> 1.114608).  Saving model ...
Validation loss decreased (1.114608 --> 1.108705).  Saving model ...
Validation loss decreased (1.108705 --> 1.102547).  Saving model ...
Validation loss decreased (1.102547 --> 1.099548).  Saving model ...
Validation loss decreased (1.099548 --> 1.094246).  Saving model ...
Validation loss decreased (1.094246 --> 1.089578).  Saving model ...
Validation loss decreased (1.089578 --> 1.084497).  Saving model ...
Validation loss decreased (1.084497 --> 1.081109).  Saving model ...
Validation loss decreased (1.081109 --> 1.078385).  Saving model ...
Validation loss decreased (1.078385 --> 1.076187).  Saving model ...
Validation loss decreased (1.076187 --> 1.071090).  Saving model ...
Validation loss decreased (1.071090 --> 1.067537).  Saving model ...
Validation loss decreased (1.067537 --> 1.063009).  Saving model ...
Validation loss decreased (1.063009 --> 1.058998).  Saving model ...
Validation loss decreased (1.058998 --> 1.055856).  Saving model ...
Validation loss decreased (1.055856 --> 1.053596).  Saving model ...
Validation loss decreased (1.053596 --> 1.049374).  Saving model ...
Validation loss decreased (1.049374 --> 1.044323).  Saving model ...
Validation loss decreased (1.044323 --> 1.039803).  Saving model ...
Validation loss decreased (1.039803 --> 1.038100).  Saving model ...
Validation loss decreased (1.038100 --> 1.035895).  Saving model ...
Validation loss decreased (1.035895 --> 1.033902).  Saving model ...
Validation loss decreased (1.033902 --> 1.032611).  Saving model ...
Validation loss decreased (1.032611 --> 1.029694).  Saving model ...
Validation loss decreased (1.029694 --> 1.025895).  Saving model ...
Validation loss decreased (1.025895 --> 1.021525).  Saving model ...
Validation loss decreased (1.021525 --> 1.019237).  Saving model ...
Validation loss decreased (1.019237 --> 1.016304).  Saving model ...
Validation loss decreased (1.016304 --> 1.012643).  Saving model ...
Validation loss decreased (1.012643 --> 1.010198).  Saving model ...
Validation loss decreased (1.010198 --> 1.008311).  Saving model ...
Validation loss decreased (1.008311 --> 1.005575).  Saving model ...
Validation loss decreased (1.005575 --> 1.004508).  Saving model ...
Validation loss decreased (1.004508 --> 1.000095).  Saving model ...
Validation loss decreased (1.000095 --> 0.997337).  Saving model ...
Validation loss decreased (0.997337 --> 0.993524).  Saving model ...
Validation loss decreased (0.993524 --> 0.990732).  Saving model ...
Validation loss decreased (0.990732 --> 0.988920).  Saving model ...
Validation loss decreased (0.988920 --> 0.988437).  Saving model ...
Validation loss decreased (0.988437 --> 0.986318).  Saving model ...
Validation loss decreased (0.986318 --> 0.984210).  Saving model ...
Validation loss decreased (0.984210 --> 0.981939).  Saving model ...
Validation loss decreased (0.981939 --> 0.980206).  Saving model ...
Validation loss decreased (0.980206 --> 0.978325).  Saving model ...
Validation loss decreased (0.978325 --> 0.974990).  Saving model ...
Validation loss decreased (0.974990 --> 0.974468).  Saving model ...
Validation loss decreased (0.974468 --> 0.971982).  Saving model ...
Validation loss decreased (0.971982 --> 0.971502).  Saving model ...
Validation loss decreased (0.971502 --> 0.968348).  Saving model ...
Validation loss decreased (0.968348 --> 0.966109).  Saving model ...
EarlyStopping counter: 1 out of 3.0
Validation loss decreased (0.966109 --> 0.965896).  Saving model ...
Validation loss decreased (0.965896 --> 0.963353).  Saving model ...
Validation loss decreased (0.963353 --> 0.962888).  Saving model ...
Validation loss decreased (0.962888 --> 0.960070).  Saving model ...
Validation loss decreased (0.960070 --> 0.959364).  Saving model ...
Validation loss decreased (0.959364 --> 0.958968).  Saving model ...
Validation loss decreased (0.958968 --> 0.957460).  Saving model ...
Validation loss decreased (0.957460 --> 0.957004).  Saving model ...
Validation loss decreased (0.957004 --> 0.955057).  Saving model ...
Validation loss decreased (0.955057 --> 0.953260).  Saving model ...
Validation loss decreased (0.953260 --> 0.952709).  Saving model ...
Validation loss decreased (0.952709 --> 0.951992).  Saving model ...
EarlyStopping counter: 1 out of 3.0
Validation loss decreased (0.951992 --> 0.950091).  Saving model ...
Validation loss decreased (0.950091 --> 0.949819).  Saving model ...
Validation loss decreased (0.949819 --> 0.947903).  Saving model ...
EarlyStopping counter: 1 out of 3.0
EarlyStopping counter: 2 out of 3.0
EarlyStopping counter: 3 out of 3.0
/localscratch/yinan.29785209.0/env/lib/python3.7/site-packages/torch/nn/functional.py:1794: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.
  warnings.warn("nn.functional.tanh is deprecated. Use torch.tanh instead.")
wandb: Waiting for W&B process to finish, PID 13499... (success).
wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: \ 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: | 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: / 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: \ 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: | 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: / 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: \ 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: | 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: / 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: \ 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: | 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: / 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: \ 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb:                                                                                
wandb: Run history:
wandb:     e_F1 ▁▃▄▄▄▄▄▄▅▄▅▅▅▆▆▆▆▆▆▇▇▇▇▇▇▇██████████████
wandb:   e_loss ███▇▇▇▇▇▆▆▆▅▅▅▄▄▄▄▃▃▃▃▃▂▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁
wandb:     t_F1 ▁▂▃▃▃▃▄▄▄▄▅▅▅▅▅▅▆▆▆▆▇▆▆▇▇▇▇▇▇▇▇█▇▇██████
wandb:   t_loss ██▇▇▇▇▇▇▆▆▆▆▅▅▅▅▄▄▄▄▄▃▃▃▃▃▃▃▂▃▂▂▂▂▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:     e_F1 60.19955
wandb:   e_loss 0.9486
wandb:     t_F1 67.73792
wandb:   t_loss 0.81645
wandb: 
wandb: Synced 4 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Synced clean-salad-2: https://wandb.ai/yinanazhou/xl_512_bs_8_lr_1e06_es_3_lc_True_nr_False_sr_False_stem_False_lemma_False_repeat_2_fold_2/runs/1uj9qgt2
wandb: Find logs at: ./wandb/run-20220330_000210-1uj9qgt2/logs/debug.log
wandb: 

wandb: wandb version 0.12.11 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
2022-03-30 01:22:22.455270: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1
wandb: Tracking run with wandb version 0.12.5
wandb: Syncing run splendid-bush-2
wandb: ⭐️ View project at https://wandb.ai/yinanazhou/xl_512_bs_8_lr_1e06_es_3_lc_True_nr_False_sr_False_stem_False_lemma_False_repeat_3_fold_1
wandb: 🚀 View run at https://wandb.ai/yinanazhou/xl_512_bs_8_lr_1e06_es_3_lc_True_nr_False_sr_False_stem_False_lemma_False_repeat_3_fold_1/runs/1r1j6kwa
wandb: Run data is saved locally in /project/6002780/yinan/Thesis_MER_Lyrics/lyric-emotion/wandb/run-20220330_012219-1r1j6kwa
wandb: Run `wandb offline` to turn off syncing.
wandb: Network error (ReadTimeout), entering retry loop.

Validation loss decreased (inf --> 1.410753).  Saving model ...
Validation loss decreased (1.410753 --> 1.401413).  Saving model ...
Validation loss decreased (1.401413 --> 1.393087).  Saving model ...
Validation loss decreased (1.393087 --> 1.386656).  Saving model ...
Validation loss decreased (1.386656 --> 1.381035).  Saving model ...
Validation loss decreased (1.381035 --> 1.376340).  Saving model ...
Validation loss decreased (1.376340 --> 1.371775).  Saving model ...
Validation loss decreased (1.371775 --> 1.367497).  Saving model ...
Validation loss decreased (1.367497 --> 1.363020).  Saving model ...
Validation loss decreased (1.363020 --> 1.358733).  Saving model ...
Validation loss decreased (1.358733 --> 1.354335).  Saving model ...
Validation loss decreased (1.354335 --> 1.349931).  Saving model ...
Validation loss decreased (1.349931 --> 1.345640).  Saving model ...
Validation loss decreased (1.345640 --> 1.340963).  Saving model ...
Validation loss decreased (1.340963 --> 1.336396).  Saving model ...
Validation loss decreased (1.336396 --> 1.332186).  Saving model ...
Validation loss decreased (1.332186 --> 1.327808).  Saving model ...
Validation loss decreased (1.327808 --> 1.322819).  Saving model ...
Validation loss decreased (1.322819 --> 1.318035).  Saving model ...
Validation loss decreased (1.318035 --> 1.312996).  Saving model ...
Validation loss decreased (1.312996 --> 1.307726).  Saving model ...
Validation loss decreased (1.307726 --> 1.301778).  Saving model ...
Validation loss decreased (1.301778 --> 1.296651).  Saving model ...
Validation loss decreased (1.296651 --> 1.290787).  Saving model ...
Validation loss decreased (1.290787 --> 1.284800).  Saving model ...
Validation loss decreased (1.284800 --> 1.278941).  Saving model ...
Validation loss decreased (1.278941 --> 1.272354).  Saving model ...
Validation loss decreased (1.272354 --> 1.265430).  Saving model ...
Validation loss decreased (1.265430 --> 1.258332).  Saving model ...
Validation loss decreased (1.258332 --> 1.251770).  Saving model ...
Validation loss decreased (1.251770 --> 1.243666).  Saving model ...
Validation loss decreased (1.243666 --> 1.237079).  Saving model ...
Validation loss decreased (1.237079 --> 1.231112).  Saving model ...
Validation loss decreased (1.231112 --> 1.224202).  Saving model ...
Validation loss decreased (1.224202 --> 1.216980).  Saving model ...
Validation loss decreased (1.216980 --> 1.209232).  Saving model ...
Validation loss decreased (1.209232 --> 1.202363).  Saving model ...
Validation loss decreased (1.202363 --> 1.195469).  Saving model ...
Validation loss decreased (1.195469 --> 1.189071).  Saving model ...
Validation loss decreased (1.189071 --> 1.183253).  Saving model ...
Validation loss decreased (1.183253 --> 1.176324).  Saving model ...
Validation loss decreased (1.176324 --> 1.168944).  Saving model ...
Validation loss decreased (1.168944 --> 1.161578).  Saving model ...
Validation loss decreased (1.161578 --> 1.157367).  Saving model ...
Validation loss decreased (1.157367 --> 1.151166).  Saving model ...
Validation loss decreased (1.151166 --> 1.143683).  Saving model ...
Validation loss decreased (1.143683 --> 1.139349).  Saving model ...
Validation loss decreased (1.139349 --> 1.132678).  Saving model ...
Validation loss decreased (1.132678 --> 1.126626).  Saving model ...
Validation loss decreased (1.126626 --> 1.122528).  Saving model ...
Validation loss decreased (1.122528 --> 1.117350).  Saving model ...
Validation loss decreased (1.117350 --> 1.112378).  Saving model ...
Validation loss decreased (1.112378 --> 1.107763).  Saving model ...
Validation loss decreased (1.107763 --> 1.103520).  Saving model ...
Validation loss decreased (1.103520 --> 1.097453).  Saving model ...
Validation loss decreased (1.097453 --> 1.092096).  Saving model ...
Validation loss decreased (1.092096 --> 1.088061).  Saving model ...
Validation loss decreased (1.088061 --> 1.083743).  Saving model ...
Validation loss decreased (1.083743 --> 1.079638).  Saving model ...
Validation loss decreased (1.079638 --> 1.075945).  Saving model ...
Validation loss decreased (1.075945 --> 1.072614).  Saving model ...
Validation loss decreased (1.072614 --> 1.069202).  Saving model ...
Validation loss decreased (1.069202 --> 1.063833).  Saving model ...
Validation loss decreased (1.063833 --> 1.059686).  Saving model ...
Validation loss decreased (1.059686 --> 1.057170).  Saving model ...
Validation loss decreased (1.057170 --> 1.054182).  Saving model ...
Validation loss decreased (1.054182 --> 1.050176).  Saving model ...
Validation loss decreased (1.050176 --> 1.048099).  Saving model ...
Validation loss decreased (1.048099 --> 1.045376).  Saving model ...
Validation loss decreased (1.045376 --> 1.042941).  Saving model ...
Validation loss decreased (1.042941 --> 1.037966).  Saving model ...
Validation loss decreased (1.037966 --> 1.034948).  Saving model ...
Validation loss decreased (1.034948 --> 1.032267).  Saving model ...
Validation loss decreased (1.032267 --> 1.030468).  Saving model ...
Validation loss decreased (1.030468 --> 1.024154).  Saving model ...
Validation loss decreased (1.024154 --> 1.023878).  Saving model ...
Validation loss decreased (1.023878 --> 1.019443).  Saving model ...
Validation loss decreased (1.019443 --> 1.016330).  Saving model ...
Validation loss decreased (1.016330 --> 1.013028).  Saving model ...
Validation loss decreased (1.013028 --> 1.010667).  Saving model ...
Validation loss decreased (1.010667 --> 1.008179).  Saving model ...
Validation loss decreased (1.008179 --> 1.006470).  Saving model ...
EarlyStopping counter: 1 out of 3.0
Validation loss decreased (1.006470 --> 1.002073).  Saving model ...
Validation loss decreased (1.002073 --> 0.999051).  Saving model ...
Validation loss decreased (0.999051 --> 0.996674).  Saving model ...
Validation loss decreased (0.996674 --> 0.993545).  Saving model ...
EarlyStopping counter: 1 out of 3.0
Validation loss decreased (0.993545 --> 0.991458).  Saving model ...
Validation loss decreased (0.991458 --> 0.990141).  Saving model ...
EarlyStopping counter: 1 out of 3.0
Validation loss decreased (0.990141 --> 0.988091).  Saving model ...
Validation loss decreased (0.988091 --> 0.986260).  Saving model ...
Validation loss decreased (0.986260 --> 0.984576).  Saving model ...
Validation loss decreased (0.984576 --> 0.981280).  Saving model ...
EarlyStopping counter: 1 out of 3.0
Validation loss decreased (0.981280 --> 0.979567).  Saving model ...
Validation loss decreased (0.979567 --> 0.977782).  Saving model ...
Validation loss decreased (0.977782 --> 0.975439).  Saving model ...
EarlyStopping counter: 1 out of 3.0
EarlyStopping counter: 2 out of 3.0
Validation loss decreased (0.975439 --> 0.973366).  Saving model ...
Validation loss decreased (0.973366 --> 0.971265).  Saving model ...
EarlyStopping counter: 1 out of 3.0
Validation loss decreased (0.971265 --> 0.970890).  Saving model ...
Validation loss decreased (0.970890 --> 0.969464).  Saving model ...
Validation loss decreased (0.969464 --> 0.969167).  Saving model ...
EarlyStopping counter: 1 out of 3.0
Validation loss decreased (0.969167 --> 0.966696).  Saving model ...
Validation loss decreased (0.966696 --> 0.965785).  Saving model ...
Validation loss decreased (0.965785 --> 0.965217).  Saving model ...
Validation loss decreased (0.965217 --> 0.964444).  Saving model ...
Validation loss decreased (0.964444 --> 0.963068).  Saving model ...
Validation loss decreased (0.963068 --> 0.962628).  Saving model ...
EarlyStopping counter: 1 out of 3.0
EarlyStopping counter: 2 out of 3.0
Validation loss decreased (0.962628 --> 0.962074).  Saving model ...
Validation loss decreased (0.962074 --> 0.961803).  Saving model ...
EarlyStopping counter: 1 out of 3.0
Validation loss decreased (0.961803 --> 0.961295).  Saving model ...
Validation loss decreased (0.961295 --> 0.960715).  Saving model ...
Validation loss decreased (0.960715 --> 0.960570).  Saving model ...
Validation loss decreased (0.960570 --> 0.959841).  Saving model ...
EarlyStopping counter: 1 out of 3.0
Validation loss decreased (0.959841 --> 0.959379).  Saving model ...
Validation loss decreased (0.959379 --> 0.956781).  Saving model ...
EarlyStopping counter: 1 out of 3.0
Validation loss decreased (0.956781 --> 0.955834).  Saving model ...
Validation loss decreased (0.955834 --> 0.954365).  Saving model ...
EarlyStopping counter: 1 out of 3.0
EarlyStopping counter: 2 out of 3.0
EarlyStopping counter: 3 out of 3.0
/localscratch/yinan.29785209.0/env/lib/python3.7/site-packages/torch/nn/functional.py:1794: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.
  warnings.warn("nn.functional.tanh is deprecated. Use torch.tanh instead.")
wandb: Waiting for W&B process to finish, PID 17830... (success).
wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: \ 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: | 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: / 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: \ 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: | 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: / 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: \ 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: | 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: / 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb:                                                                                
wandb: Run history:
wandb:     e_F1 ▁▂▃▄▄▄▅▅▅▅▅▆▆▆▆▆▇▇▇▆▇▇▇▇▇▇▇▇████████████
wandb:   e_loss ██▇▇▇▇▆▆▆▅▅▅▄▄▄▃▃▃▃▃▂▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁
wandb:     t_F1 ▁▁▂▂▃▃▃▄▄▄▄▅▅▅▅▆▆▅▆▆▆▆▇▇▇▇▇▇▇▇▇▇▇▇█▇▇███
wandb:   t_loss ███▇▇▇▇▇▇▆▆▅▅▅▅▅▄▄▄▄▄▃▃▃▃▃▃▂▃▂▂▂▂▂▂▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:     e_F1 59.9974
wandb:   e_loss 0.95811
wandb:     t_F1 74.38816
wandb:   t_loss 0.74078
wandb: 
wandb: Synced 4 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Synced splendid-bush-2: https://wandb.ai/yinanazhou/xl_512_bs_8_lr_1e06_es_3_lc_True_nr_False_sr_False_stem_False_lemma_False_repeat_3_fold_1/runs/1r1j6kwa
wandb: Find logs at: ./wandb/run-20220330_012219-1r1j6kwa/logs/debug.log
wandb: 

wandb: wandb version 0.12.11 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
2022-03-30 02:49:38.457855: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1
wandb: Tracking run with wandb version 0.12.5
wandb: Syncing run bumbling-thunder-2
wandb: ⭐️ View project at https://wandb.ai/yinanazhou/xl_512_bs_8_lr_1e06_es_3_lc_True_nr_False_sr_False_stem_False_lemma_False_repeat_3_fold_2
wandb: 🚀 View run at https://wandb.ai/yinanazhou/xl_512_bs_8_lr_1e06_es_3_lc_True_nr_False_sr_False_stem_False_lemma_False_repeat_3_fold_2/runs/1hxmqqks
wandb: Run data is saved locally in /project/6002780/yinan/Thesis_MER_Lyrics/lyric-emotion/wandb/run-20220330_024935-1hxmqqks
wandb: Run `wandb offline` to turn off syncing.

Validation loss decreased (inf --> 1.386555).  Saving model ...
Validation loss decreased (1.386555 --> 1.380229).  Saving model ...
Validation loss decreased (1.380229 --> 1.375482).  Saving model ...
Validation loss decreased (1.375482 --> 1.371239).  Saving model ...
Validation loss decreased (1.371239 --> 1.366770).  Saving model ...
Validation loss decreased (1.366770 --> 1.362761).  Saving model ...
Validation loss decreased (1.362761 --> 1.358749).  Saving model ...
Validation loss decreased (1.358749 --> 1.355246).  Saving model ...
Validation loss decreased (1.355246 --> 1.351727).  Saving model ...
Validation loss decreased (1.351727 --> 1.347893).  Saving model ...
Validation loss decreased (1.347893 --> 1.343981).  Saving model ...
Validation loss decreased (1.343981 --> 1.340397).  Saving model ...
Validation loss decreased (1.340397 --> 1.336330).  Saving model ...
Validation loss decreased (1.336330 --> 1.332317).  Saving model ...
Validation loss decreased (1.332317 --> 1.327978).  Saving model ...
Validation loss decreased (1.327978 --> 1.322818).  Saving model ...
Validation loss decreased (1.322818 --> 1.317625).  Saving model ...
Validation loss decreased (1.317625 --> 1.312629).  Saving model ...
Validation loss decreased (1.312629 --> 1.307573).  Saving model ...
Validation loss decreased (1.307573 --> 1.301483).  Saving model ...
Validation loss decreased (1.301483 --> 1.295897).  Saving model ...
Validation loss decreased (1.295897 --> 1.290786).  Saving model ...
Validation loss decreased (1.290786 --> 1.285279).  Saving model ...
Validation loss decreased (1.285279 --> 1.277768).  Saving model ...
Validation loss decreased (1.277768 --> 1.271281).  Saving model ...
Validation loss decreased (1.271281 --> 1.264296).  Saving model ...
Validation loss decreased (1.264296 --> 1.256657).  Saving model ...
Validation loss decreased (1.256657 --> 1.249463).  Saving model ...
Validation loss decreased (1.249463 --> 1.241818).  Saving model ...
Validation loss decreased (1.241818 --> 1.233728).  Saving model ...
Validation loss decreased (1.233728 --> 1.226252).  Saving model ...
Validation loss decreased (1.226252 --> 1.219072).  Saving model ...
Validation loss decreased (1.219072 --> 1.210560).  Saving model ...
Validation loss decreased (1.210560 --> 1.202267).  Saving model ...
Validation loss decreased (1.202267 --> 1.196041).  Saving model ...
Validation loss decreased (1.196041 --> 1.188131).  Saving model ...
Validation loss decreased (1.188131 --> 1.182187).  Saving model ...
Validation loss decreased (1.182187 --> 1.176572).  Saving model ...
Validation loss decreased (1.176572 --> 1.171158).  Saving model ...
Validation loss decreased (1.171158 --> 1.164387).  Saving model ...
Validation loss decreased (1.164387 --> 1.158791).  Saving model ...
Validation loss decreased (1.158791 --> 1.153106).  Saving model ...
Validation loss decreased (1.153106 --> 1.147202).  Saving model ...
Validation loss decreased (1.147202 --> 1.142475).  Saving model ...
Validation loss decreased (1.142475 --> 1.135789).  Saving model ...
Validation loss decreased (1.135789 --> 1.130291).  Saving model ...
Validation loss decreased (1.130291 --> 1.124092).  Saving model ...
Validation loss decreased (1.124092 --> 1.119048).  Saving model ...
Validation loss decreased (1.119048 --> 1.114901).  Saving model ...
Validation loss decreased (1.114901 --> 1.112876).  Saving model ...
Validation loss decreased (1.112876 --> 1.107150).  Saving model ...
Validation loss decreased (1.107150 --> 1.101188).  Saving model ...
Validation loss decreased (1.101188 --> 1.096101).  Saving model ...
Validation loss decreased (1.096101 --> 1.092973).  Saving model ...
Validation loss decreased (1.092973 --> 1.087151).  Saving model ...
Validation loss decreased (1.087151 --> 1.082188).  Saving model ...
Validation loss decreased (1.082188 --> 1.076594).  Saving model ...
Validation loss decreased (1.076594 --> 1.072726).  Saving model ...
Validation loss decreased (1.072726 --> 1.068161).  Saving model ...
Validation loss decreased (1.068161 --> 1.064697).  Saving model ...
Validation loss decreased (1.064697 --> 1.060977).  Saving model ...
Validation loss decreased (1.060977 --> 1.058955).  Saving model ...
Validation loss decreased (1.058955 --> 1.054093).  Saving model ...
Validation loss decreased (1.054093 --> 1.051508).  Saving model ...
Validation loss decreased (1.051508 --> 1.048253).  Saving model ...
Validation loss decreased (1.048253 --> 1.045101).  Saving model ...
Validation loss decreased (1.045101 --> 1.042708).  Saving model ...
Validation loss decreased (1.042708 --> 1.039684).  Saving model ...
Validation loss decreased (1.039684 --> 1.032763).  Saving model ...
Validation loss decreased (1.032763 --> 1.028574).  Saving model ...
Validation loss decreased (1.028574 --> 1.026978).  Saving model ...
Validation loss decreased (1.026978 --> 1.023078).  Saving model ...
Validation loss decreased (1.023078 --> 1.019465).  Saving model ...
Validation loss decreased (1.019465 --> 1.017193).  Saving model ...
Validation loss decreased (1.017193 --> 1.014359).  Saving model ...
EarlyStopping counter: 1 out of 3.0
Validation loss decreased (1.014359 --> 1.011034).  Saving model ...
Validation loss decreased (1.011034 --> 1.006548).  Saving model ...
Validation loss decreased (1.006548 --> 1.004366).  Saving model ...
Validation loss decreased (1.004366 --> 1.003356).  Saving model ...
Validation loss decreased (1.003356 --> 1.002642).  Saving model ...
Validation loss decreased (1.002642 --> 1.002479).  Saving model ...
Validation loss decreased (1.002479 --> 0.999157).  Saving model ...
Validation loss decreased (0.999157 --> 0.993637).  Saving model ...
Validation loss decreased (0.993637 --> 0.990124).  Saving model ...
EarlyStopping counter: 1 out of 3.0
Validation loss decreased (0.990124 --> 0.987196).  Saving model ...
Validation loss decreased (0.987196 --> 0.984392).  Saving model ...
Validation loss decreased (0.984392 --> 0.984318).  Saving model ...
Validation loss decreased (0.984318 --> 0.981007).  Saving model ...
Validation loss decreased (0.981007 --> 0.980294).  Saving model ...
Validation loss decreased (0.980294 --> 0.974865).  Saving model ...
Validation loss decreased (0.974865 --> 0.973423).  Saving model ...
Validation loss decreased (0.973423 --> 0.972445).  Saving model ...
Validation loss decreased (0.972445 --> 0.970556).  Saving model ...
Validation loss decreased (0.970556 --> 0.969386).  Saving model ...
Validation loss decreased (0.969386 --> 0.969187).  Saving model ...
Validation loss decreased (0.969187 --> 0.967628).  Saving model ...
Validation loss decreased (0.967628 --> 0.965536).  Saving model ...
Validation loss decreased (0.965536 --> 0.961759).  Saving model ...
EarlyStopping counter: 1 out of 3.0
EarlyStopping counter: 2 out of 3.0
EarlyStopping counter: 3 out of 3.0
/localscratch/yinan.29785209.0/env/lib/python3.7/site-packages/torch/nn/functional.py:1794: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.
  warnings.warn("nn.functional.tanh is deprecated. Use torch.tanh instead.")
wandb: Waiting for W&B process to finish, PID 22574... (success).
wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: \ 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: | 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: / 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: \ 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: | 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: / 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: \ 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: | 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: / 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb:                                                                                
wandb: Run history:
wandb:     e_F1 ▁▂▃▄▄▅▅▅▅▆▆▆▆▆▆▆▆▇▇▇▇▇▇▇▇▇▇▇▇▇██████████
wandb:   e_loss ███▇▇▇▇▇▇▆▆▆▅▅▅▄▄▄▄▃▃▃▃▃▃▂▂▂▂▂▂▂▂▁▁▁▁▁▁▁
wandb:     t_F1 ▁▁▂▂▃▃▃▄▃▄▄▅▅▅▅▆▆▆▆▇▇▇▇▇▇▇▇█▇▇▇▇▇███▇███
wandb:   t_loss ██▇█▇▇▇▇▇▆▆▆▆▆▅▅▅▅▄▄▄▄▃▃▃▃▃▂▃▂▃▂▂▂▁▂▁▁▁▁
wandb: 
wandb: Run summary:
wandb:     e_F1 60.63782
wandb:   e_loss 0.96184
wandb:     t_F1 65.76979
wandb:   t_loss 0.86212
wandb: 
wandb: Synced 4 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Synced bumbling-thunder-2: https://wandb.ai/yinanazhou/xl_512_bs_8_lr_1e06_es_3_lc_True_nr_False_sr_False_stem_False_lemma_False_repeat_3_fold_2/runs/1hxmqqks
wandb: Find logs at: ./wandb/run-20220330_024935-1hxmqqks/logs/debug.log
wandb: 

wandb: wandb version 0.12.11 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
2022-03-30 03:56:40.042657: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1
wandb: Tracking run with wandb version 0.12.5
wandb: Syncing run kind-deluge-2
wandb: ⭐️ View project at https://wandb.ai/yinanazhou/xl_512_bs_8_lr_1e06_es_3_lc_True_nr_False_sr_False_stem_False_lemma_False_repeat_4_fold_1
wandb: 🚀 View run at https://wandb.ai/yinanazhou/xl_512_bs_8_lr_1e06_es_3_lc_True_nr_False_sr_False_stem_False_lemma_False_repeat_4_fold_1/runs/228fw22h
wandb: Run data is saved locally in /project/6002780/yinan/Thesis_MER_Lyrics/lyric-emotion/wandb/run-20220330_035637-228fw22h
wandb: Run `wandb offline` to turn off syncing.

Validation loss decreased (inf --> 1.431707).  Saving model ...
Validation loss decreased (1.431707 --> 1.411220).  Saving model ...
Validation loss decreased (1.411220 --> 1.395784).  Saving model ...
Validation loss decreased (1.395784 --> 1.383102).  Saving model ...
Validation loss decreased (1.383102 --> 1.372743).  Saving model ...
Validation loss decreased (1.372743 --> 1.365130).  Saving model ...
Validation loss decreased (1.365130 --> 1.358527).  Saving model ...
Validation loss decreased (1.358527 --> 1.353058).  Saving model ...
Validation loss decreased (1.353058 --> 1.348205).  Saving model ...
Validation loss decreased (1.348205 --> 1.343445).  Saving model ...
Validation loss decreased (1.343445 --> 1.339358).  Saving model ...
Validation loss decreased (1.339358 --> 1.335027).  Saving model ...
Validation loss decreased (1.335027 --> 1.330924).  Saving model ...
Validation loss decreased (1.330924 --> 1.326691).  Saving model ...
Validation loss decreased (1.326691 --> 1.322227).  Saving model ...
Validation loss decreased (1.322227 --> 1.317972).  Saving model ...
Validation loss decreased (1.317972 --> 1.313581).  Saving model ...
Validation loss decreased (1.313581 --> 1.309406).  Saving model ...
Validation loss decreased (1.309406 --> 1.303985).  Saving model ...
Validation loss decreased (1.303985 --> 1.299116).  Saving model ...
Validation loss decreased (1.299116 --> 1.293721).  Saving model ...
Validation loss decreased (1.293721 --> 1.288256).  Saving model ...
Validation loss decreased (1.288256 --> 1.282046).  Saving model ...
Validation loss decreased (1.282046 --> 1.276185).  Saving model ...
Validation loss decreased (1.276185 --> 1.270587).  Saving model ...
Validation loss decreased (1.270587 --> 1.264849).  Saving model ...
Validation loss decreased (1.264849 --> 1.259052).  Saving model ...
Validation loss decreased (1.259052 --> 1.251949).  Saving model ...
Validation loss decreased (1.251949 --> 1.244852).  Saving model ...
Validation loss decreased (1.244852 --> 1.236137).  Saving model ...
Validation loss decreased (1.236137 --> 1.229122).  Saving model ...
Validation loss decreased (1.229122 --> 1.219892).  Saving model ...
Validation loss decreased (1.219892 --> 1.213315).  Saving model ...
Validation loss decreased (1.213315 --> 1.204372).  Saving model ...
Validation loss decreased (1.204372 --> 1.197338).  Saving model ...
Validation loss decreased (1.197338 --> 1.188876).  Saving model ...
Validation loss decreased (1.188876 --> 1.181575).  Saving model ...
Validation loss decreased (1.181575 --> 1.174259).  Saving model ...
Validation loss decreased (1.174259 --> 1.166749).  Saving model ...
Validation loss decreased (1.166749 --> 1.158727).  Saving model ...
Validation loss decreased (1.158727 --> 1.152273).  Saving model ...
Validation loss decreased (1.152273 --> 1.146268).  Saving model ...
Validation loss decreased (1.146268 --> 1.140419).  Saving model ...
Validation loss decreased (1.140419 --> 1.134812).  Saving model ...
Validation loss decreased (1.134812 --> 1.129750).  Saving model ...
Validation loss decreased (1.129750 --> 1.124411).  Saving model ...
Validation loss decreased (1.124411 --> 1.119111).  Saving model ...
Validation loss decreased (1.119111 --> 1.113018).  Saving model ...
Validation loss decreased (1.113018 --> 1.109975).  Saving model ...
Validation loss decreased (1.109975 --> 1.105043).  Saving model ...
Validation loss decreased (1.105043 --> 1.099918).  Saving model ...
Validation loss decreased (1.099918 --> 1.096402).  Saving model ...
Validation loss decreased (1.096402 --> 1.092115).  Saving model ...
Validation loss decreased (1.092115 --> 1.088740).  Saving model ...
Validation loss decreased (1.088740 --> 1.085169).  Saving model ...
Validation loss decreased (1.085169 --> 1.081014).  Saving model ...
Validation loss decreased (1.081014 --> 1.077634).  Saving model ...
Validation loss decreased (1.077634 --> 1.073933).  Saving model ...
Validation loss decreased (1.073933 --> 1.071008).  Saving model ...
Validation loss decreased (1.071008 --> 1.070431).  Saving model ...
Validation loss decreased (1.070431 --> 1.067388).  Saving model ...
Validation loss decreased (1.067388 --> 1.062179).  Saving model ...
Validation loss decreased (1.062179 --> 1.059117).  Saving model ...
Validation loss decreased (1.059117 --> 1.054066).  Saving model ...
Validation loss decreased (1.054066 --> 1.051747).  Saving model ...
Validation loss decreased (1.051747 --> 1.047326).  Saving model ...
Validation loss decreased (1.047326 --> 1.044336).  Saving model ...
Validation loss decreased (1.044336 --> 1.041405).  Saving model ...
Validation loss decreased (1.041405 --> 1.038479).  Saving model ...
Validation loss decreased (1.038479 --> 1.035658).  Saving model ...
Validation loss decreased (1.035658 --> 1.032960).  Saving model ...
Validation loss decreased (1.032960 --> 1.029891).  Saving model ...
Validation loss decreased (1.029891 --> 1.027668).  Saving model ...
Validation loss decreased (1.027668 --> 1.025942).  Saving model ...
Validation loss decreased (1.025942 --> 1.023960).  Saving model ...
Validation loss decreased (1.023960 --> 1.019491).  Saving model ...
Validation loss decreased (1.019491 --> 1.016958).  Saving model ...
Validation loss decreased (1.016958 --> 1.015677).  Saving model ...
Validation loss decreased (1.015677 --> 1.012825).  Saving model ...
Validation loss decreased (1.012825 --> 1.010418).  Saving model ...
Validation loss decreased (1.010418 --> 1.007262).  Saving model ...
Validation loss decreased (1.007262 --> 1.005132).  Saving model ...
Validation loss decreased (1.005132 --> 1.002547).  Saving model ...
Validation loss decreased (1.002547 --> 1.001024).  Saving model ...
Validation loss decreased (1.001024 --> 0.998403).  Saving model ...
Validation loss decreased (0.998403 --> 0.996331).  Saving model ...
Validation loss decreased (0.996331 --> 0.995082).  Saving model ...
Validation loss decreased (0.995082 --> 0.992726).  Saving model ...
Validation loss decreased (0.992726 --> 0.991677).  Saving model ...
Validation loss decreased (0.991677 --> 0.990045).  Saving model ...
Validation loss decreased (0.990045 --> 0.988885).  Saving model ...
Validation loss decreased (0.988885 --> 0.987616).  Saving model ...
Validation loss decreased (0.987616 --> 0.985752).  Saving model ...
Validation loss decreased (0.985752 --> 0.984442).  Saving model ...
Validation loss decreased (0.984442 --> 0.983115).  Saving model ...
Validation loss decreased (0.983115 --> 0.981955).  Saving model ...
Validation loss decreased (0.981955 --> 0.980624).  Saving model ...
Validation loss decreased (0.980624 --> 0.978802).  Saving model ...
Validation loss decreased (0.978802 --> 0.976965).  Saving model ...
Validation loss decreased (0.976965 --> 0.975429).  Saving model ...
Validation loss decreased (0.975429 --> 0.974668).  Saving model ...
Validation loss decreased (0.974668 --> 0.972146).  Saving model ...
EarlyStopping counter: 1 out of 3.0
Validation loss decreased (0.972146 --> 0.970634).  Saving model ...
Validation loss decreased (0.970634 --> 0.969824).  Saving model ...
Validation loss decreased (0.969824 --> 0.968613).  Saving model ...
Validation loss decreased (0.968613 --> 0.967337).  Saving model ...
Validation loss decreased (0.967337 --> 0.965683).  Saving model ...
Validation loss decreased (0.965683 --> 0.964223).  Saving model ...
Validation loss decreased (0.964223 --> 0.963349).  Saving model ...
Validation loss decreased (0.963349 --> 0.962566).  Saving model ...
Validation loss decreased (0.962566 --> 0.961148).  Saving model ...
Validation loss decreased (0.961148 --> 0.959883).  Saving model ...
Validation loss decreased (0.959883 --> 0.959698).  Saving model ...
Validation loss decreased (0.959698 --> 0.959191).  Saving model ...
Validation loss decreased (0.959191 --> 0.959128).  Saving model ...
Validation loss decreased (0.959128 --> 0.958979).  Saving model ...
Validation loss decreased (0.958979 --> 0.957653).  Saving model ...
Validation loss decreased (0.957653 --> 0.956494).  Saving model ...
EarlyStopping counter: 1 out of 3.0
EarlyStopping counter: 2 out of 3.0
Validation loss decreased (0.956494 --> 0.955976).  Saving model ...
EarlyStopping counter: 1 out of 3.0
Validation loss decreased (0.955976 --> 0.955828).  Saving model ...
EarlyStopping counter: 1 out of 3.0
Validation loss decreased (0.955828 --> 0.954826).  Saving model ...
EarlyStopping counter: 1 out of 3.0
Validation loss decreased (0.954826 --> 0.954345).  Saving model ...
Validation loss decreased (0.954345 --> 0.952657).  Saving model ...
EarlyStopping counter: 1 out of 3.0
Validation loss decreased (0.952657 --> 0.951859).  Saving model ...
Validation loss decreased (0.951859 --> 0.951714).  Saving model ...
Validation loss decreased (0.951714 --> 0.951353).  Saving model ...
EarlyStopping counter: 1 out of 3.0
EarlyStopping counter: 2 out of 3.0
Validation loss decreased (0.951353 --> 0.951232).  Saving model ...
EarlyStopping counter: 1 out of 3.0
Validation loss decreased (0.951232 --> 0.950936).  Saving model ...
Validation loss decreased (0.950936 --> 0.950185).  Saving model ...
EarlyStopping counter: 1 out of 3.0
EarlyStopping counter: 2 out of 3.0
EarlyStopping counter: 3 out of 3.0
/localscratch/yinan.29785209.0/env/lib/python3.7/site-packages/torch/nn/functional.py:1794: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.
  warnings.warn("nn.functional.tanh is deprecated. Use torch.tanh instead.")
wandb: Waiting for W&B process to finish, PID 26217... (success).
wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: \ 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: | 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: / 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: \ 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: | 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: / 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: \ 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: | 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: / 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb:                                                                                
wandb: Run history:
wandb:     e_F1 ▁▂▃▃▄▄▄▄▅▅▅▆▆▆▆▆▆▆▇▇▇▇▇▇▇▇▇▇▇▇▇█████████
wandb:   e_loss ██▇▇▇▆▆▆▅▅▅▄▄▃▃▃▃▃▂▂▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:     t_F1 ▁▁▂▂▃▃▃▃▄▄▅▄▅▅▅▅▅▆▆▆▆▆▆▆▇▇▇▇▇▇▇▇▇█▇▇█▇██
wandb:   t_loss ██▇▇▇▇▇▆▆▆▅▅▅▅▄▄▄▄▄▃▃▃▃▃▃▃▃▂▂▂▂▂▂▂▂▂▁▁▁▁
wandb: 
wandb: Run summary:
wandb:     e_F1 61.34237
wandb:   e_loss 0.95284
wandb:     t_F1 75.56068
wandb:   t_loss 0.70125
wandb: 
wandb: Synced 4 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Synced kind-deluge-2: https://wandb.ai/yinanazhou/xl_512_bs_8_lr_1e06_es_3_lc_True_nr_False_sr_False_stem_False_lemma_False_repeat_4_fold_1/runs/228fw22h
wandb: Find logs at: ./wandb/run-20220330_035637-228fw22h/logs/debug.log
wandb: 

wandb: wandb version 0.12.11 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
2022-03-30 05:30:24.703109: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1
wandb: Tracking run with wandb version 0.12.5
wandb: Syncing run leafy-wind-2
wandb: ⭐️ View project at https://wandb.ai/yinanazhou/xl_512_bs_8_lr_1e06_es_3_lc_True_nr_False_sr_False_stem_False_lemma_False_repeat_4_fold_2
wandb: 🚀 View run at https://wandb.ai/yinanazhou/xl_512_bs_8_lr_1e06_es_3_lc_True_nr_False_sr_False_stem_False_lemma_False_repeat_4_fold_2/runs/2xt2jic4
wandb: Run data is saved locally in /project/6002780/yinan/Thesis_MER_Lyrics/lyric-emotion/wandb/run-20220330_053022-2xt2jic4
wandb: Run `wandb offline` to turn off syncing.

Validation loss decreased (inf --> 1.386385).  Saving model ...
Validation loss decreased (1.386385 --> 1.379813).  Saving model ...
Validation loss decreased (1.379813 --> 1.373698).  Saving model ...
Validation loss decreased (1.373698 --> 1.368335).  Saving model ...
Validation loss decreased (1.368335 --> 1.363836).  Saving model ...
Validation loss decreased (1.363836 --> 1.359514).  Saving model ...
Validation loss decreased (1.359514 --> 1.355167).  Saving model ...
Validation loss decreased (1.355167 --> 1.350870).  Saving model ...
Validation loss decreased (1.350870 --> 1.346717).  Saving model ...
Validation loss decreased (1.346717 --> 1.342575).  Saving model ...
Validation loss decreased (1.342575 --> 1.338377).  Saving model ...
Validation loss decreased (1.338377 --> 1.333419).  Saving model ...
Validation loss decreased (1.333419 --> 1.328695).  Saving model ...
Validation loss decreased (1.328695 --> 1.323449).  Saving model ...
Validation loss decreased (1.323449 --> 1.318522).  Saving model ...
Validation loss decreased (1.318522 --> 1.313579).  Saving model ...
Validation loss decreased (1.313579 --> 1.308541).  Saving model ...
Validation loss decreased (1.308541 --> 1.302979).  Saving model ...
Validation loss decreased (1.302979 --> 1.297141).  Saving model ...
Validation loss decreased (1.297141 --> 1.291089).  Saving model ...
Validation loss decreased (1.291089 --> 1.284697).  Saving model ...
Validation loss decreased (1.284697 --> 1.278995).  Saving model ...
Validation loss decreased (1.278995 --> 1.272948).  Saving model ...
Validation loss decreased (1.272948 --> 1.265830).  Saving model ...
Validation loss decreased (1.265830 --> 1.258717).  Saving model ...
Validation loss decreased (1.258717 --> 1.250705).  Saving model ...
Validation loss decreased (1.250705 --> 1.242980).  Saving model ...
Validation loss decreased (1.242980 --> 1.234933).  Saving model ...
Validation loss decreased (1.234933 --> 1.227885).  Saving model ...
Validation loss decreased (1.227885 --> 1.220308).  Saving model ...
Validation loss decreased (1.220308 --> 1.213223).  Saving model ...
Validation loss decreased (1.213223 --> 1.205361).  Saving model ...
Validation loss decreased (1.205361 --> 1.196712).  Saving model ...
Validation loss decreased (1.196712 --> 1.188055).  Saving model ...
Validation loss decreased (1.188055 --> 1.178703).  Saving model ...
Validation loss decreased (1.178703 --> 1.170834).  Saving model ...
Validation loss decreased (1.170834 --> 1.164134).  Saving model ...
Validation loss decreased (1.164134 --> 1.154953).  Saving model ...
Validation loss decreased (1.154953 --> 1.146544).  Saving model ...
Validation loss decreased (1.146544 --> 1.138486).  Saving model ...
Validation loss decreased (1.138486 --> 1.129644).  Saving model ...
Validation loss decreased (1.129644 --> 1.122410).  Saving model ...
Validation loss decreased (1.122410 --> 1.115467).  Saving model ...
Validation loss decreased (1.115467 --> 1.108351).  Saving model ...
Validation loss decreased (1.108351 --> 1.100822).  Saving model ...
Validation loss decreased (1.100822 --> 1.093449).  Saving model ...
Validation loss decreased (1.093449 --> 1.086795).  Saving model ...
Validation loss decreased (1.086795 --> 1.082042).  Saving model ...
Validation loss decreased (1.082042 --> 1.075458).  Saving model ...
Validation loss decreased (1.075458 --> 1.071054).  Saving model ...
Validation loss decreased (1.071054 --> 1.065025).  Saving model ...
Validation loss decreased (1.065025 --> 1.058126).  Saving model ...
Validation loss decreased (1.058126 --> 1.053393).  Saving model ...
Validation loss decreased (1.053393 --> 1.048087).  Saving model ...
Validation loss decreased (1.048087 --> 1.042724).  Saving model ...
Validation loss decreased (1.042724 --> 1.038249).  Saving model ...
Validation loss decreased (1.038249 --> 1.033758).  Saving model ...
Validation loss decreased (1.033758 --> 1.031338).  Saving model ...
Validation loss decreased (1.031338 --> 1.028367).  Saving model ...
Validation loss decreased (1.028367 --> 1.023423).  Saving model ...
Validation loss decreased (1.023423 --> 1.018551).  Saving model ...
Validation loss decreased (1.018551 --> 1.012392).  Saving model ...
Validation loss decreased (1.012392 --> 1.008346).  Saving model ...
Validation loss decreased (1.008346 --> 1.005233).  Saving model ...
Validation loss decreased (1.005233 --> 0.999582).  Saving model ...
Validation loss decreased (0.999582 --> 0.995139).  Saving model ...
Validation loss decreased (0.995139 --> 0.993053).  Saving model ...
Validation loss decreased (0.993053 --> 0.991016).  Saving model ...
Validation loss decreased (0.991016 --> 0.986839).  Saving model ...
Validation loss decreased (0.986839 --> 0.982518).  Saving model ...
Validation loss decreased (0.982518 --> 0.981239).  Saving model ...
Validation loss decreased (0.981239 --> 0.977226).  Saving model ...
Validation loss decreased (0.977226 --> 0.973855).  Saving model ...
Validation loss decreased (0.973855 --> 0.971146).  Saving model ...
Validation loss decreased (0.971146 --> 0.968377).  Saving model ...
Validation loss decreased (0.968377 --> 0.964724).  Saving model ...
Validation loss decreased (0.964724 --> 0.962372).  Saving model ...
Validation loss decreased (0.962372 --> 0.961834).  Saving model ...
Validation loss decreased (0.961834 --> 0.959619).  Saving model ...
EarlyStopping counter: 1 out of 3.0
Validation loss decreased (0.959619 --> 0.956318).  Saving model ...
Validation loss decreased (0.956318 --> 0.953503).  Saving model ...
Validation loss decreased (0.953503 --> 0.951306).  Saving model ...
Validation loss decreased (0.951306 --> 0.948103).  Saving model ...
Validation loss decreased (0.948103 --> 0.944636).  Saving model ...
Validation loss decreased (0.944636 --> 0.944375).  Saving model ...
Validation loss decreased (0.944375 --> 0.944352).  Saving model ...
Validation loss decreased (0.944352 --> 0.943883).  Saving model ...
Validation loss decreased (0.943883 --> 0.941305).  Saving model ...
Validation loss decreased (0.941305 --> 0.939788).  Saving model ...
Validation loss decreased (0.939788 --> 0.939633).  Saving model ...
Validation loss decreased (0.939633 --> 0.937659).  Saving model ...
Validation loss decreased (0.937659 --> 0.936219).  Saving model ...
EarlyStopping counter: 1 out of 3.0
Validation loss decreased (0.936219 --> 0.934695).  Saving model ...
Validation loss decreased (0.934695 --> 0.933428).  Saving model ...
Validation loss decreased (0.933428 --> 0.930917).  Saving model ...
EarlyStopping counter: 1 out of 3.0
Validation loss decreased (0.930917 --> 0.930183).  Saving model ...
EarlyStopping counter: 1 out of 3.0
Validation loss decreased (0.930183 --> 0.928338).  Saving model ...
Validation loss decreased (0.928338 --> 0.927669).  Saving model ...
EarlyStopping counter: 1 out of 3.0
Validation loss decreased (0.927669 --> 0.926397).  Saving model ...
EarlyStopping counter: 1 out of 3.0
Validation loss decreased (0.926397 --> 0.924524).  Saving model ...
Validation loss decreased (0.924524 --> 0.922979).  Saving model ...
Validation loss decreased (0.922979 --> 0.922729).  Saving model ...
EarlyStopping counter: 1 out of 3.0
EarlyStopping counter: 2 out of 3.0
EarlyStopping counter: 3 out of 3.0
/localscratch/yinan.29785209.0/env/lib/python3.7/site-packages/torch/nn/functional.py:1794: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.
  warnings.warn("nn.functional.tanh is deprecated. Use torch.tanh instead.")
wandb: Waiting for W&B process to finish, PID 31212... (success).
wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: \ 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: | 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: / 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: \ 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: | 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: / 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: \ 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: | 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: / 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb:                                                                                
wandb: Run history:
wandb:     e_F1 ▁▂▃▃▄▄▅▅▅▅▆▆▆▆▇▇▇▇▇▇▇▇█▇████████████████
wandb:   e_loss ███▇▇▇▇▇▆▆▆▅▅▅▄▄▄▃▃▃▃▃▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁
wandb:     t_F1 ▁▁▁▂▂▂▂▃▄▃▃▄▄▄▅▅▅▅▆▆▆▆▆▆▆▆▆▇▇▆▇▇▇▇▇▇▇███
wandb:   t_loss ████▇▇▇▇▇▇▆▆▆▆▅▅▅▄▄▄▄▄▃▃▃▃▃▂▃▂▂▂▂▂▂▂▁▁▁▁
wandb: 
wandb: Run summary:
wandb:     e_F1 61.76928
wandb:   e_loss 0.92429
wandb:     t_F1 71.9788
wandb:   t_loss 0.80732
wandb: 
wandb: Synced 4 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Synced leafy-wind-2: https://wandb.ai/yinanazhou/xl_512_bs_8_lr_1e06_es_3_lc_True_nr_False_sr_False_stem_False_lemma_False_repeat_4_fold_2/runs/2xt2jic4
wandb: Find logs at: ./wandb/run-20220330_053022-2xt2jic4/logs/debug.log
wandb: 

wandb: wandb version 0.12.11 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
2022-03-30 06:43:29.386929: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1
wandb: Tracking run with wandb version 0.12.5
wandb: Syncing run cool-shape-1
wandb: ⭐️ View project at https://wandb.ai/yinanazhou/xl_512_bs_8_lr_1e06_es_3_lc_True_nr_False_sr_False_stem_False_lemma_False_repeat_5_fold_1
wandb: 🚀 View run at https://wandb.ai/yinanazhou/xl_512_bs_8_lr_1e06_es_3_lc_True_nr_False_sr_False_stem_False_lemma_False_repeat_5_fold_1/runs/c8harpcb
wandb: Run data is saved locally in /project/6002780/yinan/Thesis_MER_Lyrics/lyric-emotion/wandb/run-20220330_064327-c8harpcb
wandb: Run `wandb offline` to turn off syncing.

Validation loss decreased (inf --> 1.430362).  Saving model ...
Validation loss decreased (1.430362 --> 1.416827).  Saving model ...
Validation loss decreased (1.416827 --> 1.406509).  Saving model ...
Validation loss decreased (1.406509 --> 1.397840).  Saving model ...
Validation loss decreased (1.397840 --> 1.389828).  Saving model ...
Validation loss decreased (1.389828 --> 1.383330).  Saving model ...
Validation loss decreased (1.383330 --> 1.377583).  Saving model ...
Validation loss decreased (1.377583 --> 1.372362).  Saving model ...
Validation loss decreased (1.372362 --> 1.367878).  Saving model ...
Validation loss decreased (1.367878 --> 1.363738).  Saving model ...
Validation loss decreased (1.363738 --> 1.359198).  Saving model ...
Validation loss decreased (1.359198 --> 1.355277).  Saving model ...
Validation loss decreased (1.355277 --> 1.351320).  Saving model ...
Validation loss decreased (1.351320 --> 1.346824).  Saving model ...
Validation loss decreased (1.346824 --> 1.342220).  Saving model ...
Validation loss decreased (1.342220 --> 1.337754).  Saving model ...
Validation loss decreased (1.337754 --> 1.333648).  Saving model ...
Validation loss decreased (1.333648 --> 1.329534).  Saving model ...
Validation loss decreased (1.329534 --> 1.324866).  Saving model ...
Validation loss decreased (1.324866 --> 1.319913).  Saving model ...
Validation loss decreased (1.319913 --> 1.314525).  Saving model ...
Validation loss decreased (1.314525 --> 1.309075).  Saving model ...
Validation loss decreased (1.309075 --> 1.303710).  Saving model ...
Validation loss decreased (1.303710 --> 1.297982).  Saving model ...
Validation loss decreased (1.297982 --> 1.291881).  Saving model ...
Validation loss decreased (1.291881 --> 1.285628).  Saving model ...
Validation loss decreased (1.285628 --> 1.279647).  Saving model ...
Validation loss decreased (1.279647 --> 1.273263).  Saving model ...
Validation loss decreased (1.273263 --> 1.266418).  Saving model ...
Validation loss decreased (1.266418 --> 1.260460).  Saving model ...
Validation loss decreased (1.260460 --> 1.253318).  Saving model ...
Validation loss decreased (1.253318 --> 1.245509).  Saving model ...
Validation loss decreased (1.245509 --> 1.238338).  Saving model ...
Validation loss decreased (1.238338 --> 1.229903).  Saving model ...
Validation loss decreased (1.229903 --> 1.223303).  Saving model ...
Validation loss decreased (1.223303 --> 1.215271).  Saving model ...
Validation loss decreased (1.215271 --> 1.209111).  Saving model ...
Validation loss decreased (1.209111 --> 1.202630).  Saving model ...
Validation loss decreased (1.202630 --> 1.195565).  Saving model ...
Validation loss decreased (1.195565 --> 1.189982).  Saving model ...
Validation loss decreased (1.189982 --> 1.183465).  Saving model ...
Validation loss decreased (1.183465 --> 1.177129).  Saving model ...
Validation loss decreased (1.177129 --> 1.170914).  Saving model ...
Validation loss decreased (1.170914 --> 1.166090).  Saving model ...
Validation loss decreased (1.166090 --> 1.160707).  Saving model ...
Validation loss decreased (1.160707 --> 1.154236).  Saving model ...
Validation loss decreased (1.154236 --> 1.149121).  Saving model ...
Validation loss decreased (1.149121 --> 1.145483).  Saving model ...
Validation loss decreased (1.145483 --> 1.140205).  Saving model ...
Validation loss decreased (1.140205 --> 1.135127).  Saving model ...
Validation loss decreased (1.135127 --> 1.130017).  Saving model ...
Validation loss decreased (1.130017 --> 1.125844).  Saving model ...
Validation loss decreased (1.125844 --> 1.121333).  Saving model ...
Validation loss decreased (1.121333 --> 1.116001).  Saving model ...
Validation loss decreased (1.116001 --> 1.111647).  Saving model ...
Validation loss decreased (1.111647 --> 1.107412).  Saving model ...
Validation loss decreased (1.107412 --> 1.103171).  Saving model ...
Validation loss decreased (1.103171 --> 1.099892).  Saving model ...
Validation loss decreased (1.099892 --> 1.095704).  Saving model ...
Validation loss decreased (1.095704 --> 1.092316).  Saving model ...
Validation loss decreased (1.092316 --> 1.089312).  Saving model ...
Validation loss decreased (1.089312 --> 1.085348).  Saving model ...
Validation loss decreased (1.085348 --> 1.080990).  Saving model ...
Validation loss decreased (1.080990 --> 1.076877).  Saving model ...
Validation loss decreased (1.076877 --> 1.073520).  Saving model ...
Validation loss decreased (1.073520 --> 1.069109).  Saving model ...
Validation loss decreased (1.069109 --> 1.067097).  Saving model ...
Validation loss decreased (1.067097 --> 1.063322).  Saving model ...
Validation loss decreased (1.063322 --> 1.058794).  Saving model ...
Validation loss decreased (1.058794 --> 1.055579).  Saving model ...
Validation loss decreased (1.055579 --> 1.053226).  Saving model ...
Validation loss decreased (1.053226 --> 1.050380).  Saving model ...
Validation loss decreased (1.050380 --> 1.047491).  Saving model ...
Validation loss decreased (1.047491 --> 1.044110).  Saving model ...
Validation loss decreased (1.044110 --> 1.041426).  Saving model ...
Validation loss decreased (1.041426 --> 1.038178).  Saving model ...
Validation loss decreased (1.038178 --> 1.035973).  Saving model ...
Validation loss decreased (1.035973 --> 1.032452).  Saving model ...
Validation loss decreased (1.032452 --> 1.031430).  Saving model ...
Validation loss decreased (1.031430 --> 1.029295).  Saving model ...
Validation loss decreased (1.029295 --> 1.025836).  Saving model ...
Validation loss decreased (1.025836 --> 1.022373).  Saving model ...
Validation loss decreased (1.022373 --> 1.019160).  Saving model ...
Validation loss decreased (1.019160 --> 1.017884).  Saving model ...
Validation loss decreased (1.017884 --> 1.014798).  Saving model ...
Validation loss decreased (1.014798 --> 1.010987).  Saving model ...
Validation loss decreased (1.010987 --> 1.007393).  Saving model ...
Validation loss decreased (1.007393 --> 1.004922).  Saving model ...
Validation loss decreased (1.004922 --> 1.001973).  Saving model ...
Validation loss decreased (1.001973 --> 1.000274).  Saving model ...
Validation loss decreased (1.000274 --> 0.999985).  Saving model ...
Validation loss decreased (0.999985 --> 0.997969).  Saving model ...
Validation loss decreased (0.997969 --> 0.995354).  Saving model ...
Validation loss decreased (0.995354 --> 0.993107).  Saving model ...
EarlyStopping counter: 1 out of 3.0
Validation loss decreased (0.993107 --> 0.991588).  Saving model ...
Validation loss decreased (0.991588 --> 0.990824).  Saving model ...
Validation loss decreased (0.990824 --> 0.987730).  Saving model ...
Validation loss decreased (0.987730 --> 0.986631).  Saving model ...
Validation loss decreased (0.986631 --> 0.985879).  Saving model ...
Validation loss decreased (0.985879 --> 0.983415).  Saving model ...
Validation loss decreased (0.983415 --> 0.983304).  Saving model ...
Validation loss decreased (0.983304 --> 0.981209).  Saving model ...
Validation loss decreased (0.981209 --> 0.978407).  Saving model ...
Validation loss decreased (0.978407 --> 0.977837).  Saving model ...
Validation loss decreased (0.977837 --> 0.977519).  Saving model ...
EarlyStopping counter: 1 out of 3.0
Validation loss decreased (0.977519 --> 0.975813).  Saving model ...
Validation loss decreased (0.975813 --> 0.975638).  Saving model ...
Validation loss decreased (0.975638 --> 0.973251).  Saving model ...
Validation loss decreased (0.973251 --> 0.971144).  Saving model ...
Validation loss decreased (0.971144 --> 0.968099).  Saving model ...
Validation loss decreased (0.968099 --> 0.967018).  Saving model ...
Validation loss decreased (0.967018 --> 0.966976).  Saving model ...
EarlyStopping counter: 1 out of 3.0
EarlyStopping counter: 2 out of 3.0
EarlyStopping counter: 3 out of 3.0
/localscratch/yinan.29785209.0/env/lib/python3.7/site-packages/torch/nn/functional.py:1794: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.
  warnings.warn("nn.functional.tanh is deprecated. Use torch.tanh instead.")
wandb: Waiting for W&B process to finish, PID 35130... (success).
wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: \ 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: | 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: / 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: \ 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: | 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: / 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: \ 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: | 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: / 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: \ 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb:                                                                                
wandb: Run history:
wandb:     e_F1 ▁▁▂▃▃▄▄▅▅▅▆▆▆▆▇▇▇▇▇▇▇▇▇▇▇▇▇▇████████████
wandb:   e_loss ██▇▇▇▇▆▆▆▆▅▅▅▄▄▄▄▃▃▃▃▃▃▂▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁
wandb:     t_F1 ▁▁▂▁▂▃▃▃▄▄▄▅▅▅▅▆▅▅▆▆▆▆▆▇▇▇▆▇▇▇▇▇█▇█▇████
wandb:   t_loss ██▇▇▇▇▇▇▆▆▆▆▅▅▅▅▄▄▄▄▄▃▃▃▃▃▃▂▂▂▂▂▂▂▁▂▁▁▁▁
wandb: 
wandb: Run summary:
wandb:     e_F1 57.41487
wandb:   e_loss 0.96776
wandb:     t_F1 66.98069
wandb:   t_loss 0.83716
wandb: 
wandb: Synced 4 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Synced cool-shape-1: https://wandb.ai/yinanazhou/xl_512_bs_8_lr_1e06_es_3_lc_True_nr_False_sr_False_stem_False_lemma_False_repeat_5_fold_1/runs/c8harpcb
wandb: Find logs at: ./wandb/run-20220330_064327-c8harpcb/logs/debug.log
wandb: 

wandb: wandb version 0.12.11 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
2022-03-30 08:00:56.431515: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1
wandb: Tracking run with wandb version 0.12.5
wandb: Syncing run northern-feather-1
wandb: ⭐️ View project at https://wandb.ai/yinanazhou/xl_512_bs_8_lr_1e06_es_3_lc_True_nr_False_sr_False_stem_False_lemma_False_repeat_5_fold_2
wandb: 🚀 View run at https://wandb.ai/yinanazhou/xl_512_bs_8_lr_1e06_es_3_lc_True_nr_False_sr_False_stem_False_lemma_False_repeat_5_fold_2/runs/3k1c5pfz
wandb: Run data is saved locally in /project/6002780/yinan/Thesis_MER_Lyrics/lyric-emotion/wandb/run-20220330_080053-3k1c5pfz
wandb: Run `wandb offline` to turn off syncing.

Validation loss decreased (inf --> 1.485274).  Saving model ...
Validation loss decreased (1.485274 --> 1.449610).  Saving model ...
Validation loss decreased (1.449610 --> 1.422322).  Saving model ...
Validation loss decreased (1.422322 --> 1.401172).  Saving model ...
Validation loss decreased (1.401172 --> 1.386075).  Saving model ...
Validation loss decreased (1.386075 --> 1.373957).  Saving model ...
Validation loss decreased (1.373957 --> 1.364534).  Saving model ...
Validation loss decreased (1.364534 --> 1.355806).  Saving model ...
Validation loss decreased (1.355806 --> 1.348336).  Saving model ...
Validation loss decreased (1.348336 --> 1.342421).  Saving model ...
Validation loss decreased (1.342421 --> 1.336604).  Saving model ...
Validation loss decreased (1.336604 --> 1.331071).  Saving model ...
Validation loss decreased (1.331071 --> 1.325690).  Saving model ...
Validation loss decreased (1.325690 --> 1.320237).  Saving model ...
Validation loss decreased (1.320237 --> 1.315039).  Saving model ...
Validation loss decreased (1.315039 --> 1.308997).  Saving model ...
Validation loss decreased (1.308997 --> 1.303229).  Saving model ...
Validation loss decreased (1.303229 --> 1.297129).  Saving model ...
Validation loss decreased (1.297129 --> 1.290757).  Saving model ...
Validation loss decreased (1.290757 --> 1.285074).  Saving model ...
Validation loss decreased (1.285074 --> 1.279385).  Saving model ...
Validation loss decreased (1.279385 --> 1.272716).  Saving model ...
Validation loss decreased (1.272716 --> 1.266391).  Saving model ...
Validation loss decreased (1.266391 --> 1.259379).  Saving model ...
Validation loss decreased (1.259379 --> 1.252597).  Saving model ...
Validation loss decreased (1.252597 --> 1.245939).  Saving model ...
Validation loss decreased (1.245939 --> 1.238874).  Saving model ...
Validation loss decreased (1.238874 --> 1.231464).  Saving model ...
Validation loss decreased (1.231464 --> 1.223198).  Saving model ...
Validation loss decreased (1.223198 --> 1.215894).  Saving model ...
Validation loss decreased (1.215894 --> 1.207590).  Saving model ...
Validation loss decreased (1.207590 --> 1.200024).  Saving model ...
Validation loss decreased (1.200024 --> 1.192053).  Saving model ...
Validation loss decreased (1.192053 --> 1.184074).  Saving model ...
Validation loss decreased (1.184074 --> 1.177220).  Saving model ...
Validation loss decreased (1.177220 --> 1.170944).  Saving model ...
Validation loss decreased (1.170944 --> 1.162624).  Saving model ...
Validation loss decreased (1.162624 --> 1.155849).  Saving model ...
Validation loss decreased (1.155849 --> 1.149966).  Saving model ...
Validation loss decreased (1.149966 --> 1.142793).  Saving model ...
Validation loss decreased (1.142793 --> 1.135263).  Saving model ...
Validation loss decreased (1.135263 --> 1.127803).  Saving model ...
Validation loss decreased (1.127803 --> 1.121965).  Saving model ...
Validation loss decreased (1.121965 --> 1.116309).  Saving model ...
Validation loss decreased (1.116309 --> 1.109363).  Saving model ...
Validation loss decreased (1.109363 --> 1.104626).  Saving model ...
Validation loss decreased (1.104626 --> 1.097956).  Saving model ...
Validation loss decreased (1.097956 --> 1.093466).  Saving model ...
Validation loss decreased (1.093466 --> 1.088044).  Saving model ...
Validation loss decreased (1.088044 --> 1.083480).  Saving model ...
Validation loss decreased (1.083480 --> 1.078080).  Saving model ...
Validation loss decreased (1.078080 --> 1.073428).  Saving model ...
Validation loss decreased (1.073428 --> 1.068154).  Saving model ...
Validation loss decreased (1.068154 --> 1.062976).  Saving model ...
Validation loss decreased (1.062976 --> 1.056881).  Saving model ...
Validation loss decreased (1.056881 --> 1.052746).  Saving model ...
Validation loss decreased (1.052746 --> 1.048902).  Saving model ...
Validation loss decreased (1.048902 --> 1.045722).  Saving model ...
Validation loss decreased (1.045722 --> 1.040503).  Saving model ...
Validation loss decreased (1.040503 --> 1.036645).  Saving model ...
Validation loss decreased (1.036645 --> 1.032141).  Saving model ...
Validation loss decreased (1.032141 --> 1.029329).  Saving model ...
Validation loss decreased (1.029329 --> 1.027335).  Saving model ...
Validation loss decreased (1.027335 --> 1.021701).  Saving model ...
Validation loss decreased (1.021701 --> 1.016730).  Saving model ...
Validation loss decreased (1.016730 --> 1.013386).  Saving model ...
Validation loss decreased (1.013386 --> 1.010912).  Saving model ...
Validation loss decreased (1.010912 --> 1.008087).  Saving model ...
Validation loss decreased (1.008087 --> 1.004193).  Saving model ...
Validation loss decreased (1.004193 --> 1.001786).  Saving model ...
Validation loss decreased (1.001786 --> 0.999430).  Saving model ...
Validation loss decreased (0.999430 --> 0.996520).  Saving model ...
Validation loss decreased (0.996520 --> 0.993063).  Saving model ...
Validation loss decreased (0.993063 --> 0.991137).  Saving model ...
Validation loss decreased (0.991137 --> 0.988639).  Saving model ...
Validation loss decreased (0.988639 --> 0.984064).  Saving model ...
Validation loss decreased (0.984064 --> 0.981276).  Saving model ...
Validation loss decreased (0.981276 --> 0.979870).  Saving model ...
Validation loss decreased (0.979870 --> 0.977132).  Saving model ...
Validation loss decreased (0.977132 --> 0.976079).  Saving model ...
Validation loss decreased (0.976079 --> 0.973371).  Saving model ...
Validation loss decreased (0.973371 --> 0.971062).  Saving model ...
Validation loss decreased (0.971062 --> 0.969688).  Saving model ...
Validation loss decreased (0.969688 --> 0.968040).  Saving model ...
Validation loss decreased (0.968040 --> 0.967987).  Saving model ...
Validation loss decreased (0.967987 --> 0.964615).  Saving model ...
Validation loss decreased (0.964615 --> 0.962602).  Saving model ...
Validation loss decreased (0.962602 --> 0.961110).  Saving model ...
Validation loss decreased (0.961110 --> 0.959121).  Saving model ...
Validation loss decreased (0.959121 --> 0.958350).  Saving model ...
Validation loss decreased (0.958350 --> 0.956231).  Saving model ...
Validation loss decreased (0.956231 --> 0.953748).  Saving model ...
Validation loss decreased (0.953748 --> 0.951051).  Saving model ...
Validation loss decreased (0.951051 --> 0.949929).  Saving model ...
Validation loss decreased (0.949929 --> 0.947382).  Saving model ...
EarlyStopping counter: 1 out of 3.0
Validation loss decreased (0.947382 --> 0.946909).  Saving model ...
Validation loss decreased (0.946909 --> 0.944885).  Saving model ...
Validation loss decreased (0.944885 --> 0.944014).  Saving model ...
Validation loss decreased (0.944014 --> 0.943295).  Saving model ...
Validation loss decreased (0.943295 --> 0.941895).  Saving model ...
Validation loss decreased (0.941895 --> 0.939674).  Saving model ...
Validation loss decreased (0.939674 --> 0.939065).  Saving model ...
Validation loss decreased (0.939065 --> 0.937159).  Saving model ...
Validation loss decreased (0.937159 --> 0.934911).  Saving model ...
EarlyStopping counter: 1 out of 3.0
EarlyStopping counter: 2 out of 3.0
EarlyStopping counter: 3 out of 3.0
/localscratch/yinan.29785209.0/env/lib/python3.7/site-packages/torch/nn/functional.py:1794: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.
  warnings.warn("nn.functional.tanh is deprecated. Use torch.tanh instead.")
wandb: Waiting for W&B process to finish, PID 39266... (success).
wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: \ 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: | 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: / 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: \ 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: | 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: / 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: \ 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: | 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: / 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb:                                                                                
wandb: Run history:
wandb:     e_F1 ▁▂▃▄▄▅▅▅▆▆▆▆▇▇▇▇▇▇▇▇████████████████████
wandb:   e_loss █▇▇▆▆▆▆▅▅▅▅▄▄▄▄▃▃▃▃▃▃▂▂▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁
wandb:     t_F1 ▁▁▂▃▃▃▄▄▄▅▅▅▅▅▅▆▆▆▆▇▇▇▇▇▇▇▇▇▇█▇▇█▇██▇███
wandb:   t_loss █▇▇▇▇▇▆▆▆▆▅▅▅▅▄▄▄▄▄▄▃▃▃▃▃▂▂▂▂▂▂▂▂▂▁▂▁▁▁▁
wandb: 
wandb: Run summary:
wandb:     e_F1 61.80294
wandb:   e_loss 0.93586
wandb:     t_F1 66.54756
wandb:   t_loss 0.85171
wandb: 
wandb: Synced 4 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Synced northern-feather-1: https://wandb.ai/yinanazhou/xl_512_bs_8_lr_1e06_es_3_lc_True_nr_False_sr_False_stem_False_lemma_False_repeat_5_fold_2/runs/3k1c5pfz
wandb: Find logs at: ./wandb/run-20220330_080053-3k1c5pfz/logs/debug.log
wandb: 

