Unloading StdEnv/2020

Due to MODULEPATH changes, the following have been reloaded:
  1) mii/1.1.1


The following have been reloaded with a version change:
  1) python/3.8.2 => python/3.7.4

Using base prefix '/cvmfs/soft.computecanada.ca/easybuild/software/2017/Core/python/3.7.4'
New python executable in /localscratch/yinan.29785236.0/env/bin/python
Installing setuptools, pip, wheel...
done.
Ignoring pip: markers 'python_version < "3"' don't match your environment
Looking in links: /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/nix/avx2, /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/nix/generic, /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic
Collecting pip
Installing collected packages: pip
  Found existing installation: pip 19.1.1
    Uninstalling pip-19.1.1:
      Successfully uninstalled pip-19.1.1
Successfully installed pip-21.2.3+computecanada
Looking in links: /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/nix/avx2, /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/nix/generic, /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/keras-2.8.0+computecanada-py2.py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/Keras_Preprocessing-1.1.2+computecanada-py3-none-any.whl
Requirement already satisfied: matplotlib in /cvmfs/soft.computecanada.ca/easybuild/software/2017/Core/scipy-stack/2019a/lib/python3.7/site-packages (from -r requirements.txt (line 3)) (3.0.2)
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/nltk-3.6.5+computecanada-py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/scikit_learn-0.22.1+computecanada-cp37-cp37m-linux_x86_64.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/tensorboard-2.3.0+computecanada-py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/tensorboard_plugin_wit-1.7.0+computecanada-py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/tensorflow_gpu-2.3.0+computecanada-cp37-cp37m-linux_x86_64.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/tensorflow_estimator-2.3.0+computecanada-py2.py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/tokenizers-0.5.2+computecanada-cp37-cp37m-linux_x86_64.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/nix/avx2/torch-1.4.0+computecanada-cp37-cp37m-linux_x86_64.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/torchtext-0.6.0+computecanada-py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/torchvision-0.8.2+computecanada-cp37-cp37m-linux_x86_64.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/transformers-2.5.1+computecanada-py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/urllib3-1.26.7+computecanada-py2.py3-none-any.whl
ERROR: Could not find a version that satisfies the requirement regex>=2021.8.3 (from nltk) (from versions: 2018.1.10+computecanada, 2019.11.1+computecanada, 2020.11.13+computecanada)
ERROR: No matching distribution found for regex>=2021.8.3
Looking in links: /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/nix/avx2, /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/nix/generic, /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic
ERROR: Could not find a version that satisfies the requirement numpy==1.20.0+computacanada (from versions: 1.15.0+computecanada, 1.15.2+computecanada, 1.15.4+computecanada, 1.16.0+computecanada, 1.16.2+computecanada, 1.16.3+computecanada, 1.17.4+computecanada, 1.18.1+computecanada, 1.18.4+computecanada, 1.19.1+computecanada, 1.19.2+computecanada, 1.20.2+computecanada)
ERROR: No matching distribution found for numpy==1.20.0+computacanada
Looking in links: /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/nix/avx2, /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/nix/generic, /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/wandb-0.12.5+computecanada-py2.py3-none-any.whl
Requirement already satisfied: requests<3,>=2.0.0 in /cvmfs/soft.computecanada.ca/easybuild/software/2017/Core/scipy-stack/2019a/lib/python3.7/site-packages (from wandb) (2.21.0)
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/PyYAML-5.3.1+computecanada-cp37-cp37m-linux_x86_64.whl
Requirement already satisfied: python-dateutil>=2.6.1 in /cvmfs/soft.computecanada.ca/easybuild/software/2017/Core/scipy-stack/2019a/lib/python3.7/site-packages (from wandb) (2.7.5)
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/protobuf-3.19.4+computecanada-py2.py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/six-1.16.0+computecanada-py2.py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/promise-2.3+computecanada-py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/yaspin-2.1.0+computecanada-py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/pathtools-0.1.2+computecanada-py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/subprocess32-3.5.4+computecanada-py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/GitPython-3.1.24+computecanada-py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/shortuuid-1.0.1+computecanada-py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/configparser-5.0.2+computecanada-py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/docker_pycreds-0.4.0+computecanada-py2.py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/psutil-5.7.3+computecanada-cp37-cp37m-linux_x86_64.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/sentry_sdk-1.5.0+computecanada-py2.py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/click-8.1.0+computecanada-py3-none-any.whl
Requirement already satisfied: importlib-metadata in /cvmfs/soft.computecanada.ca/easybuild/software/2017/Core/scipy-stack/2019a/lib/python3.7/site-packages (from Click!=8.0.0,>=7.0->wandb) (0.8)
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/typing_extensions-4.1.1+computecanada-py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/gitdb-4.0.9+computecanada-py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/smmap-5.0.0+computecanada-py3-none-any.whl
Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /cvmfs/soft.computecanada.ca/easybuild/software/2017/Core/scipy-stack/2019a/lib/python3.7/site-packages (from requests<3,>=2.0.0->wandb) (3.0.4)
Requirement already satisfied: certifi>=2017.4.17 in /cvmfs/soft.computecanada.ca/easybuild/software/2017/Core/scipy-stack/2019a/lib/python3.7/site-packages (from requests<3,>=2.0.0->wandb) (2018.11.29)
Requirement already satisfied: idna<2.9,>=2.5 in /cvmfs/soft.computecanada.ca/easybuild/software/2017/Core/scipy-stack/2019a/lib/python3.7/site-packages (from requests<3,>=2.0.0->wandb) (2.8)
Requirement already satisfied: urllib3<1.25,>=1.21.1 in /cvmfs/soft.computecanada.ca/easybuild/software/2017/Core/scipy-stack/2019a/lib/python3.7/site-packages (from requests<3,>=2.0.0->wandb) (1.24.1)
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/termcolor-1.1.0+computecanada-py3-none-any.whl
Requirement already satisfied: zipp>=0.3.2 in /cvmfs/soft.computecanada.ca/easybuild/software/2017/Core/scipy-stack/2019a/lib/python3.7/site-packages (from importlib-metadata->Click!=8.0.0,>=7.0->wandb) (0.3.3)
Installing collected packages: smmap, typing-extensions, termcolor, six, gitdb, yaspin, subprocess32, shortuuid, sentry-sdk, PyYAML, psutil, protobuf, promise, pathtools, GitPython, docker-pycreds, configparser, Click, wandb
  Attempting uninstall: six
    Found existing installation: six 1.12.0
    Not uninstalling six at /cvmfs/soft.computecanada.ca/easybuild/software/2017/Core/scipy-stack/2019a/lib/python3.7/site-packages, outside environment /localscratch/yinan.29785236.0/env
    Can't uninstall 'six'. No files were found to uninstall.
Successfully installed Click-8.1.0+computecanada GitPython-3.1.24+computecanada PyYAML-5.3.1+computecanada configparser-5.0.2+computecanada docker-pycreds-0.4.0+computecanada gitdb-4.0.9+computecanada pathtools-0.1.2+computecanada promise-2.3+computecanada protobuf-3.19.4+computecanada psutil-5.7.3+computecanada sentry-sdk-1.5.0+computecanada shortuuid-1.0.1+computecanada six-1.16.0+computecanada smmap-5.0.0+computecanada subprocess32-3.5.4+computecanada termcolor-1.1.0+computecanada typing-extensions-4.1.1+computecanada wandb-0.12.5+computecanada yaspin-2.1.0+computecanada
Looking in links: /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/nix/avx2, /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/nix/generic, /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic
ERROR: Could not find a version that satisfies the requirement sagemaker (from versions: none)
ERROR: No matching distribution found for sagemaker
Looking in links: /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/nix/avx2, /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/nix/generic, /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/torch-1.9.1+computecanada-cp37-cp37m-linux_x86_64.whl
Requirement already satisfied: typing-extensions in /localscratch/yinan.29785236.0/env/lib/python3.7/site-packages (from torch) (4.1.1+computecanada)
Installing collected packages: torch
Successfully installed torch-1.9.1+computecanada
Looking in links: /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/nix/avx2, /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/nix/generic, /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/transformers-2.5.1+computecanada-py3-none-any.whl
Requirement already satisfied: requests in /cvmfs/soft.computecanada.ca/easybuild/software/2017/Core/scipy-stack/2019a/lib/python3.7/site-packages (from transformers==2.5.1+computecanada) (2.21.0)
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/sacremoses-0.0.49+computecanada-py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/regex-2020.11.13+computecanada-cp37-cp37m-linux_x86_64.whl
Requirement already satisfied: numpy in /cvmfs/soft.computecanada.ca/easybuild/software/2017/Core/scipy-stack/2019a/lib/python3.7/site-packages (from transformers==2.5.1+computecanada) (1.16.0)
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/filelock-3.4.2+computecanada-py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/sentencepiece-0.1.91+computecanada-cp37-cp37m-linux_x86_64.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/tqdm-4.63.1+computecanada-py2.py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/tokenizers-0.5.2+computecanada-cp37-cp37m-linux_x86_64.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/boto3-1.21.14+computecanada-py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/s3transfer-0.5.1+computecanada-py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/botocore-1.24.14+computecanada-py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/jmespath-0.10.0+computecanada-py2.py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/urllib3-1.26.9+computecanada-py2.py3-none-any.whl
Requirement already satisfied: python-dateutil<3.0.0,>=2.1 in /cvmfs/soft.computecanada.ca/easybuild/software/2017/Core/scipy-stack/2019a/lib/python3.7/site-packages (from botocore<1.25.0,>=1.24.14->boto3->transformers==2.5.1+computecanada) (2.7.5)
Requirement already satisfied: six>=1.5 in /localscratch/yinan.29785236.0/env/lib/python3.7/site-packages (from python-dateutil<3.0.0,>=2.1->botocore<1.25.0,>=1.24.14->boto3->transformers==2.5.1+computecanada) (1.16.0+computecanada)
Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /cvmfs/soft.computecanada.ca/easybuild/software/2017/Core/scipy-stack/2019a/lib/python3.7/site-packages (from requests->transformers==2.5.1+computecanada) (3.0.4)
Requirement already satisfied: certifi>=2017.4.17 in /cvmfs/soft.computecanada.ca/easybuild/software/2017/Core/scipy-stack/2019a/lib/python3.7/site-packages (from requests->transformers==2.5.1+computecanada) (2018.11.29)
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/requests-2.27.1+computecanada-py2.py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/charset_normalizer-2.0.12+computecanada-py3-none-any.whl
Requirement already satisfied: idna<4,>=2.5 in /cvmfs/soft.computecanada.ca/easybuild/software/2017/Core/scipy-stack/2019a/lib/python3.7/site-packages (from requests->transformers==2.5.1+computecanada) (2.8)
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/joblib-1.1.0+computecanada-py2.py3-none-any.whl
Requirement already satisfied: click in /localscratch/yinan.29785236.0/env/lib/python3.7/site-packages (from sacremoses->transformers==2.5.1+computecanada) (8.1.0+computecanada)
Requirement already satisfied: importlib-metadata in /cvmfs/soft.computecanada.ca/easybuild/software/2017/Core/scipy-stack/2019a/lib/python3.7/site-packages (from click->sacremoses->transformers==2.5.1+computecanada) (0.8)
Requirement already satisfied: zipp>=0.3.2 in /cvmfs/soft.computecanada.ca/easybuild/software/2017/Core/scipy-stack/2019a/lib/python3.7/site-packages (from importlib-metadata->click->sacremoses->transformers==2.5.1+computecanada) (0.3.3)
Installing collected packages: urllib3, jmespath, botocore, tqdm, s3transfer, regex, joblib, charset-normalizer, tokenizers, sentencepiece, sacremoses, requests, filelock, boto3, transformers
  Attempting uninstall: urllib3
    Found existing installation: urllib3 1.24.1
    Not uninstalling urllib3 at /cvmfs/soft.computecanada.ca/easybuild/software/2017/Core/scipy-stack/2019a/lib/python3.7/site-packages, outside environment /localscratch/yinan.29785236.0/env
    Can't uninstall 'urllib3'. No files were found to uninstall.
  Attempting uninstall: requests
    Found existing installation: requests 2.21.0
    Not uninstalling requests at /cvmfs/soft.computecanada.ca/easybuild/software/2017/Core/scipy-stack/2019a/lib/python3.7/site-packages, outside environment /localscratch/yinan.29785236.0/env
    Can't uninstall 'requests'. No files were found to uninstall.
Successfully installed boto3-1.21.14+computecanada botocore-1.24.14+computecanada charset-normalizer-2.0.12+computecanada filelock-3.4.2+computecanada jmespath-0.10.0+computecanada joblib-1.1.0+computecanada regex-2020.11.13+computecanada requests-2.27.1+computecanada s3transfer-0.5.1+computecanada sacremoses-0.0.49+computecanada sentencepiece-0.1.91+computecanada tokenizers-0.5.2+computecanada tqdm-4.63.1+computecanada transformers-2.5.1+computecanada urllib3-1.26.9+computecanada
Looking in links: /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/nix/avx2, /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/nix/generic, /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/tensorflow_gpu-2.3.0+computecanada-cp37-cp37m-linux_x86_64.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/google_pasta-0.2.0+computecanada-py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/absl_py-1.0.0+computecanada-py3-none-any.whl
Requirement already satisfied: six>=1.12.0 in /localscratch/yinan.29785236.0/env/lib/python3.7/site-packages (from tensorflow_gpu==2.3.0+computecanada) (1.16.0+computecanada)
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/nix/avx2/h5py-2.10.0+computecanada-cp37-cp37m-linux_x86_64.whl
Requirement already satisfied: termcolor>=1.1.0 in /localscratch/yinan.29785236.0/env/lib/python3.7/site-packages (from tensorflow_gpu==2.3.0+computecanada) (1.1.0+computecanada)
Requirement already satisfied: wheel>=0.26 in /localscratch/yinan.29785236.0/env/lib/python3.7/site-packages (from tensorflow_gpu==2.3.0+computecanada) (0.33.4)
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/grpcio-1.38.0+computecanada-cp37-cp37m-linux_x86_64.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/astunparse-1.6.3+computecanada-py2.py3-none-any.whl
Requirement already satisfied: numpy<1.19.0,>=1.16.0 in /cvmfs/soft.computecanada.ca/easybuild/software/2017/Core/scipy-stack/2019a/lib/python3.7/site-packages (from tensorflow_gpu==2.3.0+computecanada) (1.16.0)
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/opt_einsum-3.3.0+computecanada-py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/Keras_Preprocessing-1.1.2+computecanada-py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/wrapt-1.11.2+computecanada-cp37-cp37m-linux_x86_64.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/tensorboard-2.8.0+computecanada-py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/nix/generic/scipy-1.4.1+computecanada-cp37-cp37m-linux_x86_64.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/gast-0.3.3+computecanada-py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/tensorflow_estimator-2.3.0+computecanada-py2.py3-none-any.whl
Requirement already satisfied: protobuf>=3.9.2 in /localscratch/yinan.29785236.0/env/lib/python3.7/site-packages (from tensorflow_gpu==2.3.0+computecanada) (3.19.4+computecanada)
Requirement already satisfied: requests<3,>=2.21.0 in /localscratch/yinan.29785236.0/env/lib/python3.7/site-packages (from tensorboard<3,>=2.3.0->tensorflow_gpu==2.3.0+computecanada) (2.27.1+computecanada)
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/tensorboard_plugin_wit-1.8.0+computecanada-py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/google_auth-2.3.3+computecanada-py2.py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/tensorboard_data_server-0.6.1+computecanada-py3-none-linux_x86_64.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/Werkzeug-2.0.3+computecanada-py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/Markdown-3.3.6+computecanada-py3-none-any.whl
Requirement already satisfied: setuptools>=41.0.0 in /localscratch/yinan.29785236.0/env/lib/python3.7/site-packages (from tensorboard<3,>=2.3.0->tensorflow_gpu==2.3.0+computecanada) (41.0.1)
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/google_auth_oauthlib-0.4.6+computecanada-py2.py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/cachetools-4.2.4+computecanada-py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/rsa-4.8+computecanada-py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/pyasn1_modules-0.2.8+computecanada-py2.py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/requests_oauthlib-1.3.0+computecanada-py2.py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/importlib_metadata-4.10.1+computecanada-py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/zipp-3.7.0+computecanada-py3-none-any.whl
Requirement already satisfied: typing-extensions>=3.6.4 in /localscratch/yinan.29785236.0/env/lib/python3.7/site-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard<3,>=2.3.0->tensorflow_gpu==2.3.0+computecanada) (4.1.1+computecanada)
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/pyasn1-0.4.8+computecanada-py2.py3-none-any.whl
Requirement already satisfied: idna<4,>=2.5 in /cvmfs/soft.computecanada.ca/easybuild/software/2017/Core/scipy-stack/2019a/lib/python3.7/site-packages (from requests<3,>=2.21.0->tensorboard<3,>=2.3.0->tensorflow_gpu==2.3.0+computecanada) (2.8)
Requirement already satisfied: urllib3<1.27,>=1.21.1 in /localscratch/yinan.29785236.0/env/lib/python3.7/site-packages (from requests<3,>=2.21.0->tensorboard<3,>=2.3.0->tensorflow_gpu==2.3.0+computecanada) (1.26.9+computecanada)
Requirement already satisfied: charset-normalizer~=2.0.0 in /localscratch/yinan.29785236.0/env/lib/python3.7/site-packages (from requests<3,>=2.21.0->tensorboard<3,>=2.3.0->tensorflow_gpu==2.3.0+computecanada) (2.0.12+computecanada)
Requirement already satisfied: certifi>=2017.4.17 in /cvmfs/soft.computecanada.ca/easybuild/software/2017/Core/scipy-stack/2019a/lib/python3.7/site-packages (from requests<3,>=2.21.0->tensorboard<3,>=2.3.0->tensorflow_gpu==2.3.0+computecanada) (2018.11.29)
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/oauthlib-3.1.1+computecanada-py2.py3-none-any.whl
Installing collected packages: pyasn1, zipp, rsa, pyasn1-modules, oauthlib, cachetools, requests-oauthlib, importlib-metadata, google-auth, werkzeug, tensorboard-plugin-wit, tensorboard-data-server, markdown, grpcio, google-auth-oauthlib, absl-py, wrapt, tensorflow-estimator, tensorboard, scipy, opt-einsum, keras-preprocessing, h5py, google-pasta, gast, astunparse, tensorflow-gpu
  Attempting uninstall: pyasn1
    Found existing installation: pyasn1 0.4.3
    Not uninstalling pyasn1 at /cvmfs/soft.computecanada.ca/easybuild/software/2017/Core/scipy-stack/2019a/lib/python3.7/site-packages, outside environment /localscratch/yinan.29785236.0/env
    Can't uninstall 'pyasn1'. No files were found to uninstall.
  Attempting uninstall: zipp
    Found existing installation: zipp 0.3.3
    Not uninstalling zipp at /cvmfs/soft.computecanada.ca/easybuild/software/2017/Core/scipy-stack/2019a/lib/python3.7/site-packages, outside environment /localscratch/yinan.29785236.0/env
    Can't uninstall 'zipp'. No files were found to uninstall.
  Attempting uninstall: importlib-metadata
    Found existing installation: importlib-metadata 0.8
    Not uninstalling importlib-metadata at /cvmfs/soft.computecanada.ca/easybuild/software/2017/Core/scipy-stack/2019a/lib/python3.7/site-packages, outside environment /localscratch/yinan.29785236.0/env
    Can't uninstall 'importlib-metadata'. No files were found to uninstall.
  Attempting uninstall: scipy
    Found existing installation: scipy 1.2.0
    Not uninstalling scipy at /cvmfs/soft.computecanada.ca/easybuild/software/2017/Core/scipy-stack/2019a/lib/python3.7/site-packages, outside environment /localscratch/yinan.29785236.0/env
    Can't uninstall 'scipy'. No files were found to uninstall.
Successfully installed absl-py-1.0.0+computecanada astunparse-1.6.3+computecanada cachetools-4.2.4+computecanada gast-0.3.3+computecanada google-auth-2.3.3+computecanada google-auth-oauthlib-0.4.6+computecanada google-pasta-0.2.0+computecanada grpcio-1.38.0+computecanada h5py-2.10.0+computecanada importlib-metadata-4.10.1+computecanada keras-preprocessing-1.1.2+computecanada markdown-3.3.6+computecanada oauthlib-3.1.1+computecanada opt-einsum-3.3.0+computecanada pyasn1-0.4.8+computecanada pyasn1-modules-0.2.8+computecanada requests-oauthlib-1.3.0+computecanada rsa-4.8+computecanada scipy-1.4.1+computecanada tensorboard-2.8.0+computecanada tensorboard-data-server-0.6.1+computecanada tensorboard-plugin-wit-1.8.0+computecanada tensorflow-estimator-2.3.0+computecanada tensorflow-gpu-2.3.0+computecanada werkzeug-2.0.3+computecanada wrapt-1.11.2+computecanada zipp-3.7.0+computecanada
Looking in links: /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/nix/avx2, /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/nix/generic, /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/keras-2.8.0+computecanada-py2.py3-none-any.whl
Installing collected packages: Keras
Successfully installed Keras-2.8.0+computecanada
Looking in links: /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/nix/avx2, /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/nix/generic, /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/urllib3-1.26.7+computecanada-py2.py3-none-any.whl
Installing collected packages: urllib3
  Attempting uninstall: urllib3
    Found existing installation: urllib3 1.26.9+computecanada
    Uninstalling urllib3-1.26.9+computecanada:
      Successfully uninstalled urllib3-1.26.9+computecanada
Successfully installed urllib3-1.26.7+computecanada
Looking in links: /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/nix/avx2, /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/nix/generic, /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/nltk-3.7+computecanada-py3-none-any.whl
Requirement already satisfied: joblib in /localscratch/yinan.29785236.0/env/lib/python3.7/site-packages (from nltk) (1.1.0+computecanada)
Requirement already satisfied: tqdm in /localscratch/yinan.29785236.0/env/lib/python3.7/site-packages (from nltk) (4.63.1+computecanada)
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/nltk-3.6.5+computecanada-py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/nltk-3.6.3+computecanada-py3-none-any.whl
Requirement already satisfied: regex in /localscratch/yinan.29785236.0/env/lib/python3.7/site-packages (from nltk) (2020.11.13+computecanada)
Requirement already satisfied: click in /localscratch/yinan.29785236.0/env/lib/python3.7/site-packages (from nltk) (8.1.0+computecanada)
Requirement already satisfied: importlib-metadata in /localscratch/yinan.29785236.0/env/lib/python3.7/site-packages (from click->nltk) (4.10.1+computecanada)
Requirement already satisfied: typing-extensions>=3.6.4 in /localscratch/yinan.29785236.0/env/lib/python3.7/site-packages (from importlib-metadata->click->nltk) (4.1.1+computecanada)
Requirement already satisfied: zipp>=0.5 in /localscratch/yinan.29785236.0/env/lib/python3.7/site-packages (from importlib-metadata->click->nltk) (3.7.0+computecanada)
Installing collected packages: nltk
Successfully installed nltk-3.6.3+computecanada
Looking in links: /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/nix/avx2, /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/nix/generic, /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/scikit_learn-0.22.1+computecanada-cp37-cp37m-linux_x86_64.whl
Requirement already satisfied: numpy>=1.11.0 in /cvmfs/soft.computecanada.ca/easybuild/software/2017/Core/scipy-stack/2019a/lib/python3.7/site-packages (from scikit-learn==0.22.1) (1.16.0)
Requirement already satisfied: joblib>=0.11 in /localscratch/yinan.29785236.0/env/lib/python3.7/site-packages (from scikit-learn==0.22.1) (1.1.0+computecanada)
Requirement already satisfied: scipy>=0.17.0 in /localscratch/yinan.29785236.0/env/lib/python3.7/site-packages (from scikit-learn==0.22.1) (1.4.1+computecanada)
Installing collected packages: scikit-learn
Successfully installed scikit-learn-0.22.1+computecanada
Looking in links: /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/nix/avx2, /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/nix/generic, /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic
Requirement already satisfied: tokenizers==0.5.2 in /localscratch/yinan.29785236.0/env/lib/python3.7/site-packages (0.5.2+computecanada)
wandb: Appending key for api.wandb.ai to your netrc file: /home/yinan/.netrc
Starting Task
2022-03-31 06:02:32.478236: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1
[nltk_data] Downloading package stopwords to /home/yinan/nltk_data...
[nltk_data]   Package stopwords is already up-to-date!
[nltk_data] Downloading package wordnet to /home/yinan/nltk_data...
[nltk_data]   Package wordnet is already up-to-date!
wandb: Currently logged in as: yinanazhou (use `wandb login --relogin` to force relogin)
wandb: wandb version 0.12.11 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
2022-03-31 06:02:51.358066: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1
wandb: Tracking run with wandb version 0.12.5
wandb: Syncing run magic-sun-2
wandb: ⭐️ View project at https://wandb.ai/yinanazhou/xl_512_bs_8_lr_1e06_es_3_lc_True_nr_True_sr_True_stem_True_lemma_False_repeat_1_fold_1
wandb: 🚀 View run at https://wandb.ai/yinanazhou/xl_512_bs_8_lr_1e06_es_3_lc_True_nr_True_sr_True_stem_True_lemma_False_repeat_1_fold_1/runs/38q9o5e8
wandb: Run data is saved locally in /project/6002780/yinan/Thesis_MER_Lyrics/lyric-emotion/wandb/run-20220331_060249-38q9o5e8
wandb: Run `wandb offline` to turn off syncing.

Validation loss decreased (inf --> 1.430802).  Saving model ...
Validation loss decreased (1.430802 --> 1.412844).  Saving model ...
Validation loss decreased (1.412844 --> 1.397584).  Saving model ...
Validation loss decreased (1.397584 --> 1.386169).  Saving model ...
Validation loss decreased (1.386169 --> 1.377412).  Saving model ...
Validation loss decreased (1.377412 --> 1.369765).  Saving model ...
Validation loss decreased (1.369765 --> 1.364451).  Saving model ...
Validation loss decreased (1.364451 --> 1.359499).  Saving model ...
Validation loss decreased (1.359499 --> 1.355043).  Saving model ...
Validation loss decreased (1.355043 --> 1.350380).  Saving model ...
Validation loss decreased (1.350380 --> 1.346062).  Saving model ...
Validation loss decreased (1.346062 --> 1.342096).  Saving model ...
Validation loss decreased (1.342096 --> 1.338372).  Saving model ...
Validation loss decreased (1.338372 --> 1.334480).  Saving model ...
Validation loss decreased (1.334480 --> 1.330222).  Saving model ...
Validation loss decreased (1.330222 --> 1.326268).  Saving model ...
Validation loss decreased (1.326268 --> 1.322305).  Saving model ...
Validation loss decreased (1.322305 --> 1.318177).  Saving model ...
Validation loss decreased (1.318177 --> 1.313915).  Saving model ...
Validation loss decreased (1.313915 --> 1.308910).  Saving model ...
Validation loss decreased (1.308910 --> 1.304758).  Saving model ...
Validation loss decreased (1.304758 --> 1.300695).  Saving model ...
Validation loss decreased (1.300695 --> 1.296857).  Saving model ...
Validation loss decreased (1.296857 --> 1.292195).  Saving model ...
Validation loss decreased (1.292195 --> 1.287799).  Saving model ...
Validation loss decreased (1.287799 --> 1.283709).  Saving model ...
Validation loss decreased (1.283709 --> 1.279681).  Saving model ...
Validation loss decreased (1.279681 --> 1.276568).  Saving model ...
Validation loss decreased (1.276568 --> 1.274172).  Saving model ...
Validation loss decreased (1.274172 --> 1.271892).  Saving model ...
Validation loss decreased (1.271892 --> 1.269055).  Saving model ...
Validation loss decreased (1.269055 --> 1.264359).  Saving model ...
Validation loss decreased (1.264359 --> 1.263599).  Saving model ...
Validation loss decreased (1.263599 --> 1.258447).  Saving model ...
Validation loss decreased (1.258447 --> 1.258193).  Saving model ...
Validation loss decreased (1.258193 --> 1.254563).  Saving model ...
Validation loss decreased (1.254563 --> 1.252902).  Saving model ...
Validation loss decreased (1.252902 --> 1.249198).  Saving model ...
Validation loss decreased (1.249198 --> 1.247007).  Saving model ...
Validation loss decreased (1.247007 --> 1.244498).  Saving model ...
Validation loss decreased (1.244498 --> 1.240359).  Saving model ...
Validation loss decreased (1.240359 --> 1.235253).  Saving model ...
Validation loss decreased (1.235253 --> 1.232360).  Saving model ...
EarlyStopping counter: 1 out of 3.0
Validation loss decreased (1.232360 --> 1.229351).  Saving model ...
Validation loss decreased (1.229351 --> 1.226187).  Saving model ...
Validation loss decreased (1.226187 --> 1.225632).  Saving model ...
Validation loss decreased (1.225632 --> 1.222413).  Saving model ...
Validation loss decreased (1.222413 --> 1.221576).  Saving model ...
Validation loss decreased (1.221576 --> 1.217515).  Saving model ...
Validation loss decreased (1.217515 --> 1.217336).  Saving model ...
Validation loss decreased (1.217336 --> 1.213143).  Saving model ...
Validation loss decreased (1.213143 --> 1.211339).  Saving model ...
Validation loss decreased (1.211339 --> 1.209193).  Saving model ...
Validation loss decreased (1.209193 --> 1.207602).  Saving model ...
Validation loss decreased (1.207602 --> 1.202671).  Saving model ...
Validation loss decreased (1.202671 --> 1.198777).  Saving model ...
Validation loss decreased (1.198777 --> 1.195545).  Saving model ...
EarlyStopping counter: 1 out of 3.0
EarlyStopping counter: 2 out of 3.0
Validation loss decreased (1.195545 --> 1.188393).  Saving model ...
EarlyStopping counter: 1 out of 3.0
Validation loss decreased (1.188393 --> 1.181933).  Saving model ...
Validation loss decreased (1.181933 --> 1.181053).  Saving model ...
Validation loss decreased (1.181053 --> 1.180043).  Saving model ...
Validation loss decreased (1.180043 --> 1.174617).  Saving model ...
Validation loss decreased (1.174617 --> 1.173421).  Saving model ...
Validation loss decreased (1.173421 --> 1.170380).  Saving model ...
Validation loss decreased (1.170380 --> 1.168580).  Saving model ...
EarlyStopping counter: 1 out of 3.0
Validation loss decreased (1.168580 --> 1.166111).  Saving model ...
Validation loss decreased (1.166111 --> 1.165434).  Saving model ...
Validation loss decreased (1.165434 --> 1.162438).  Saving model ...
Validation loss decreased (1.162438 --> 1.155211).  Saving model ...
Validation loss decreased (1.155211 --> 1.152384).  Saving model ...
EarlyStopping counter: 1 out of 3.0
EarlyStopping counter: 2 out of 3.0
Validation loss decreased (1.152384 --> 1.148845).  Saving model ...
Validation loss decreased (1.148845 --> 1.145520).  Saving model ...
Validation loss decreased (1.145520 --> 1.142184).  Saving model ...
Validation loss decreased (1.142184 --> 1.141996).  Saving model ...
Validation loss decreased (1.141996 --> 1.141032).  Saving model ...
Validation loss decreased (1.141032 --> 1.139475).  Saving model ...
Validation loss decreased (1.139475 --> 1.138199).  Saving model ...
Validation loss decreased (1.138199 --> 1.132230).  Saving model ...
Validation loss decreased (1.132230 --> 1.126876).  Saving model ...
Validation loss decreased (1.126876 --> 1.126766).  Saving model ...
EarlyStopping counter: 1 out of 3.0
Validation loss decreased (1.126766 --> 1.125239).  Saving model ...
Validation loss decreased (1.125239 --> 1.123873).  Saving model ...
Validation loss decreased (1.123873 --> 1.120806).  Saving model ...
EarlyStopping counter: 1 out of 3.0
Validation loss decreased (1.120806 --> 1.120740).  Saving model ...
Validation loss decreased (1.120740 --> 1.119868).  Saving model ...
EarlyStopping counter: 1 out of 3.0
Validation loss decreased (1.119868 --> 1.116751).  Saving model ...
EarlyStopping counter: 1 out of 3.0
Validation loss decreased (1.116751 --> 1.114840).  Saving model ...
Validation loss decreased (1.114840 --> 1.111464).  Saving model ...
Validation loss decreased (1.111464 --> 1.111410).  Saving model ...
Validation loss decreased (1.111410 --> 1.111180).  Saving model ...
Validation loss decreased (1.111180 --> 1.109421).  Saving model ...
Validation loss decreased (1.109421 --> 1.103078).  Saving model ...
EarlyStopping counter: 1 out of 3.0
Validation loss decreased (1.103078 --> 1.102789).  Saving model ...
Validation loss decreased (1.102789 --> 1.098237).  Saving model ...
Validation loss decreased (1.098237 --> 1.095197).  Saving model ...
EarlyStopping counter: 1 out of 3.0
Validation loss decreased (1.095197 --> 1.094284).  Saving model ...
Validation loss decreased (1.094284 --> 1.087418).  Saving model ...
EarlyStopping counter: 1 out of 3.0
EarlyStopping counter: 2 out of 3.0
EarlyStopping counter: 3 out of 3.0
/localscratch/yinan.29785236.0/env/lib/python3.7/site-packages/torch/nn/functional.py:1794: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.
  warnings.warn("nn.functional.tanh is deprecated. Use torch.tanh instead.")
/localscratch/yinan.29785236.0/env/lib/python3.7/site-packages/transformers/optimization.py:155: UserWarning: This overload of add_ is deprecated:
	add_(Number alpha, Tensor other)
Consider using one of the following signatures instead:
	add_(Tensor other, *, Number alpha) (Triggered internally at  ../torch/csrc/utils/python_arg_parser.cpp:1025.)
  exp_avg.mul_(beta1).add_(1.0 - beta1, grad)
wandb: Waiting for W&B process to finish, PID 15089... (success).
wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: \ 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: | 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: / 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: \ 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: | 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: / 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: \ 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: | 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: / 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: \ 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: | 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb:                                                                                
wandb: Run history:
wandb:     e_F1 ▁▂▃▄▅▅▅▅▅▅▅▆▆▆▆▆▆▆▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇██▇███
wandb:   e_loss █▇▇▆▆▆▆▅▅▅▅▅▄▄▄▄▄▄▄▃▃▃▃▃▃▃▂▂▂▂▂▂▂▂▂▁▁▁▁▁
wandb:     t_F1 ▁▂▃▃▃▃▄▄▄▅▅▅▅▆▆▅▆▅▆▆▆▇▇▆▇▇▇▆▇▆▇▇▇███████
wandb:   t_loss ██▇▇▇▇▇▆▆▆▅▅▅▅▄▄▄▄▄▄▄▃▃▃▃▃▂▃▂▃▂▂▂▁▂▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:     e_F1 50.22718
wandb:   e_loss 1.09643
wandb:     t_F1 64.3207
wandb:   t_loss 0.86923
wandb: 
wandb: Synced 4 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Synced magic-sun-2: https://wandb.ai/yinanazhou/xl_512_bs_8_lr_1e06_es_3_lc_True_nr_True_sr_True_stem_True_lemma_False_repeat_1_fold_1/runs/38q9o5e8
wandb: Find logs at: ./wandb/run-20220331_060249-38q9o5e8/logs/debug.log
wandb: 

wandb: wandb version 0.12.11 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
2022-03-31 07:17:37.658361: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1
wandb: Tracking run with wandb version 0.12.5
wandb: Syncing run dry-waterfall-2
wandb: ⭐️ View project at https://wandb.ai/yinanazhou/xl_512_bs_8_lr_1e06_es_3_lc_True_nr_True_sr_True_stem_True_lemma_False_repeat_1_fold_2
wandb: 🚀 View run at https://wandb.ai/yinanazhou/xl_512_bs_8_lr_1e06_es_3_lc_True_nr_True_sr_True_stem_True_lemma_False_repeat_1_fold_2/runs/2rdq68z4
wandb: Run data is saved locally in /project/6002780/yinan/Thesis_MER_Lyrics/lyric-emotion/wandb/run-20220331_071734-2rdq68z4
wandb: Run `wandb offline` to turn off syncing.

Validation loss decreased (inf --> 1.393310).  Saving model ...
Validation loss decreased (1.393310 --> 1.382266).  Saving model ...
Validation loss decreased (1.382266 --> 1.374291).  Saving model ...
Validation loss decreased (1.374291 --> 1.367354).  Saving model ...
Validation loss decreased (1.367354 --> 1.361801).  Saving model ...
Validation loss decreased (1.361801 --> 1.356818).  Saving model ...
Validation loss decreased (1.356818 --> 1.351926).  Saving model ...
Validation loss decreased (1.351926 --> 1.347589).  Saving model ...
Validation loss decreased (1.347589 --> 1.343854).  Saving model ...
Validation loss decreased (1.343854 --> 1.340207).  Saving model ...
Validation loss decreased (1.340207 --> 1.336320).  Saving model ...
Validation loss decreased (1.336320 --> 1.332222).  Saving model ...
Validation loss decreased (1.332222 --> 1.328515).  Saving model ...
Validation loss decreased (1.328515 --> 1.324090).  Saving model ...
Validation loss decreased (1.324090 --> 1.320306).  Saving model ...
Validation loss decreased (1.320306 --> 1.316639).  Saving model ...
Validation loss decreased (1.316639 --> 1.312636).  Saving model ...
Validation loss decreased (1.312636 --> 1.308384).  Saving model ...
Validation loss decreased (1.308384 --> 1.304742).  Saving model ...
Validation loss decreased (1.304742 --> 1.300631).  Saving model ...
Validation loss decreased (1.300631 --> 1.296289).  Saving model ...
Validation loss decreased (1.296289 --> 1.291542).  Saving model ...
Validation loss decreased (1.291542 --> 1.287225).  Saving model ...
Validation loss decreased (1.287225 --> 1.282631).  Saving model ...
Validation loss decreased (1.282631 --> 1.277694).  Saving model ...
Validation loss decreased (1.277694 --> 1.272665).  Saving model ...
Validation loss decreased (1.272665 --> 1.267495).  Saving model ...
Validation loss decreased (1.267495 --> 1.261118).  Saving model ...
Validation loss decreased (1.261118 --> 1.255624).  Saving model ...
Validation loss decreased (1.255624 --> 1.250233).  Saving model ...
Validation loss decreased (1.250233 --> 1.244783).  Saving model ...
Validation loss decreased (1.244783 --> 1.238990).  Saving model ...
Validation loss decreased (1.238990 --> 1.233437).  Saving model ...
Validation loss decreased (1.233437 --> 1.227430).  Saving model ...
Validation loss decreased (1.227430 --> 1.222277).  Saving model ...
Validation loss decreased (1.222277 --> 1.216787).  Saving model ...
Validation loss decreased (1.216787 --> 1.210838).  Saving model ...
Validation loss decreased (1.210838 --> 1.205186).  Saving model ...
Validation loss decreased (1.205186 --> 1.199586).  Saving model ...
Validation loss decreased (1.199586 --> 1.193941).  Saving model ...
Validation loss decreased (1.193941 --> 1.187882).  Saving model ...
Validation loss decreased (1.187882 --> 1.182115).  Saving model ...
Validation loss decreased (1.182115 --> 1.176454).  Saving model ...
Validation loss decreased (1.176454 --> 1.170556).  Saving model ...
Validation loss decreased (1.170556 --> 1.165160).  Saving model ...
Validation loss decreased (1.165160 --> 1.159417).  Saving model ...
Validation loss decreased (1.159417 --> 1.153758).  Saving model ...
Validation loss decreased (1.153758 --> 1.148296).  Saving model ...
Validation loss decreased (1.148296 --> 1.142689).  Saving model ...
Validation loss decreased (1.142689 --> 1.136714).  Saving model ...
Validation loss decreased (1.136714 --> 1.131165).  Saving model ...
Validation loss decreased (1.131165 --> 1.126467).  Saving model ...
Validation loss decreased (1.126467 --> 1.121116).  Saving model ...
Validation loss decreased (1.121116 --> 1.115967).  Saving model ...
Validation loss decreased (1.115967 --> 1.111845).  Saving model ...
Validation loss decreased (1.111845 --> 1.106501).  Saving model ...
Validation loss decreased (1.106501 --> 1.102146).  Saving model ...
Validation loss decreased (1.102146 --> 1.097885).  Saving model ...
Validation loss decreased (1.097885 --> 1.093531).  Saving model ...
Validation loss decreased (1.093531 --> 1.089254).  Saving model ...
Validation loss decreased (1.089254 --> 1.084718).  Saving model ...
Validation loss decreased (1.084718 --> 1.080579).  Saving model ...
Validation loss decreased (1.080579 --> 1.076687).  Saving model ...
Validation loss decreased (1.076687 --> 1.073037).  Saving model ...
Validation loss decreased (1.073037 --> 1.068375).  Saving model ...
Validation loss decreased (1.068375 --> 1.064459).  Saving model ...
Validation loss decreased (1.064459 --> 1.061247).  Saving model ...
Validation loss decreased (1.061247 --> 1.057612).  Saving model ...
Validation loss decreased (1.057612 --> 1.053930).  Saving model ...
Validation loss decreased (1.053930 --> 1.050865).  Saving model ...
Validation loss decreased (1.050865 --> 1.048518).  Saving model ...
Validation loss decreased (1.048518 --> 1.044489).  Saving model ...
Validation loss decreased (1.044489 --> 1.041093).  Saving model ...
Validation loss decreased (1.041093 --> 1.038414).  Saving model ...
Validation loss decreased (1.038414 --> 1.035784).  Saving model ...
Validation loss decreased (1.035784 --> 1.032100).  Saving model ...
Validation loss decreased (1.032100 --> 1.028558).  Saving model ...
Validation loss decreased (1.028558 --> 1.025869).  Saving model ...
Validation loss decreased (1.025869 --> 1.023090).  Saving model ...
Validation loss decreased (1.023090 --> 1.019818).  Saving model ...
Validation loss decreased (1.019818 --> 1.017602).  Saving model ...
Validation loss decreased (1.017602 --> 1.015489).  Saving model ...
Validation loss decreased (1.015489 --> 1.012727).  Saving model ...
Validation loss decreased (1.012727 --> 1.010698).  Saving model ...
Validation loss decreased (1.010698 --> 1.009312).  Saving model ...
Validation loss decreased (1.009312 --> 1.006819).  Saving model ...
Validation loss decreased (1.006819 --> 1.004509).  Saving model ...
Validation loss decreased (1.004509 --> 1.002773).  Saving model ...
Validation loss decreased (1.002773 --> 1.000182).  Saving model ...
Validation loss decreased (1.000182 --> 0.997130).  Saving model ...
Validation loss decreased (0.997130 --> 0.994070).  Saving model ...
Validation loss decreased (0.994070 --> 0.992434).  Saving model ...
Validation loss decreased (0.992434 --> 0.990243).  Saving model ...
Validation loss decreased (0.990243 --> 0.987813).  Saving model ...
Validation loss decreased (0.987813 --> 0.986106).  Saving model ...
Validation loss decreased (0.986106 --> 0.983870).  Saving model ...
Validation loss decreased (0.983870 --> 0.981602).  Saving model ...
Validation loss decreased (0.981602 --> 0.980098).  Saving model ...
Validation loss decreased (0.980098 --> 0.978513).  Saving model ...
Validation loss decreased (0.978513 --> 0.975828).  Saving model ...
Validation loss decreased (0.975828 --> 0.975267).  Saving model ...
Validation loss decreased (0.975267 --> 0.973756).  Saving model ...
Validation loss decreased (0.973756 --> 0.972229).  Saving model ...
Validation loss decreased (0.972229 --> 0.970042).  Saving model ...
Validation loss decreased (0.970042 --> 0.968414).  Saving model ...
Validation loss decreased (0.968414 --> 0.966503).  Saving model ...
Validation loss decreased (0.966503 --> 0.965629).  Saving model ...
Validation loss decreased (0.965629 --> 0.964414).  Saving model ...
Validation loss decreased (0.964414 --> 0.963911).  Saving model ...
Validation loss decreased (0.963911 --> 0.962570).  Saving model ...
Validation loss decreased (0.962570 --> 0.961136).  Saving model ...
Validation loss decreased (0.961136 --> 0.959784).  Saving model ...
Validation loss decreased (0.959784 --> 0.958628).  Saving model ...
Validation loss decreased (0.958628 --> 0.957848).  Saving model ...
Validation loss decreased (0.957848 --> 0.957097).  Saving model ...
Validation loss decreased (0.957097 --> 0.956710).  Saving model ...
Validation loss decreased (0.956710 --> 0.955946).  Saving model ...
Validation loss decreased (0.955946 --> 0.955222).  Saving model ...
Validation loss decreased (0.955222 --> 0.955021).  Saving model ...
EarlyStopping counter: 1 out of 3.0
Validation loss decreased (0.955021 --> 0.953853).  Saving model ...
Validation loss decreased (0.953853 --> 0.953343).  Saving model ...
Validation loss decreased (0.953343 --> 0.953113).  Saving model ...
Validation loss decreased (0.953113 --> 0.952106).  Saving model ...
Validation loss decreased (0.952106 --> 0.951725).  Saving model ...
EarlyStopping counter: 1 out of 3.0
Validation loss decreased (0.951725 --> 0.951207).  Saving model ...
Validation loss decreased (0.951207 --> 0.950705).  Saving model ...
EarlyStopping counter: 1 out of 3.0
EarlyStopping counter: 2 out of 3.0
EarlyStopping counter: 3 out of 3.0
/localscratch/yinan.29785236.0/env/lib/python3.7/site-packages/torch/nn/functional.py:1794: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.
  warnings.warn("nn.functional.tanh is deprecated. Use torch.tanh instead.")
wandb: Waiting for W&B process to finish, PID 19092... (success).
wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: \ 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: | 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: / 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: \ 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: | 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: / 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: \ 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: | 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: / 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb:                                                                                
wandb: Run history:
wandb:     e_F1 ▁▂▃▃▄▄▅▅▆▆▆▆▆▆▆▇▇▇▇▇▇▇▇▇▇███████████████
wandb:   e_loss ██▇▇▇▇▇▆▆▆▅▅▅▅▄▄▄▄▃▃▃▃▂▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁
wandb:     t_F1 ▁▁▂▃▃▂▃▃▄▄▄▅▅▅▅▅▆▆▅▆▆▆▇▆▆▆▇▇▇▇▇█▇▇████▇█
wandb:   t_loss ███▇▇▇▇▇▇▆▆▆▆▆▅▅▅▅▅▄▄▄▄▄▃▃▃▃▃▃▂▂▂▂▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:     e_F1 59.50274
wandb:   e_loss 0.951
wandb:     t_F1 68.37206
wandb:   t_loss 0.83295
wandb: 
wandb: Synced 4 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Synced dry-waterfall-2: https://wandb.ai/yinanazhou/xl_512_bs_8_lr_1e06_es_3_lc_True_nr_True_sr_True_stem_True_lemma_False_repeat_1_fold_2/runs/2rdq68z4
wandb: Find logs at: ./wandb/run-20220331_071734-2rdq68z4/logs/debug.log
wandb: 

wandb: wandb version 0.12.11 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
2022-03-31 08:42:04.713918: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1
wandb: Tracking run with wandb version 0.12.5
wandb: Syncing run iconic-totem-2
wandb: ⭐️ View project at https://wandb.ai/yinanazhou/xl_512_bs_8_lr_1e06_es_3_lc_True_nr_True_sr_True_stem_True_lemma_False_repeat_2_fold_1
wandb: 🚀 View run at https://wandb.ai/yinanazhou/xl_512_bs_8_lr_1e06_es_3_lc_True_nr_True_sr_True_stem_True_lemma_False_repeat_2_fold_1/runs/29onrhig
wandb: Run data is saved locally in /project/6002780/yinan/Thesis_MER_Lyrics/lyric-emotion/wandb/run-20220331_084202-29onrhig
wandb: Run `wandb offline` to turn off syncing.

Validation loss decreased (inf --> 1.400215).  Saving model ...
Validation loss decreased (1.400215 --> 1.390996).  Saving model ...
Validation loss decreased (1.390996 --> 1.383582).  Saving model ...
Validation loss decreased (1.383582 --> 1.377383).  Saving model ...
Validation loss decreased (1.377383 --> 1.372068).  Saving model ...
Validation loss decreased (1.372068 --> 1.367533).  Saving model ...
Validation loss decreased (1.367533 --> 1.363602).  Saving model ...
Validation loss decreased (1.363602 --> 1.359601).  Saving model ...
Validation loss decreased (1.359601 --> 1.355675).  Saving model ...
Validation loss decreased (1.355675 --> 1.351913).  Saving model ...
Validation loss decreased (1.351913 --> 1.348122).  Saving model ...
Validation loss decreased (1.348122 --> 1.344449).  Saving model ...
Validation loss decreased (1.344449 --> 1.340561).  Saving model ...
Validation loss decreased (1.340561 --> 1.336894).  Saving model ...
Validation loss decreased (1.336894 --> 1.333000).  Saving model ...
Validation loss decreased (1.333000 --> 1.329132).  Saving model ...
Validation loss decreased (1.329132 --> 1.325336).  Saving model ...
Validation loss decreased (1.325336 --> 1.321295).  Saving model ...
Validation loss decreased (1.321295 --> 1.317320).  Saving model ...
Validation loss decreased (1.317320 --> 1.313667).  Saving model ...
Validation loss decreased (1.313667 --> 1.308882).  Saving model ...
Validation loss decreased (1.308882 --> 1.304462).  Saving model ...
Validation loss decreased (1.304462 --> 1.299622).  Saving model ...
Validation loss decreased (1.299622 --> 1.294147).  Saving model ...
Validation loss decreased (1.294147 --> 1.289834).  Saving model ...
Validation loss decreased (1.289834 --> 1.284761).  Saving model ...
Validation loss decreased (1.284761 --> 1.279294).  Saving model ...
Validation loss decreased (1.279294 --> 1.274227).  Saving model ...
Validation loss decreased (1.274227 --> 1.269322).  Saving model ...
Validation loss decreased (1.269322 --> 1.263551).  Saving model ...
Validation loss decreased (1.263551 --> 1.257980).  Saving model ...
Validation loss decreased (1.257980 --> 1.251421).  Saving model ...
Validation loss decreased (1.251421 --> 1.243582).  Saving model ...
Validation loss decreased (1.243582 --> 1.238256).  Saving model ...
Validation loss decreased (1.238256 --> 1.232362).  Saving model ...
Validation loss decreased (1.232362 --> 1.226961).  Saving model ...
Validation loss decreased (1.226961 --> 1.221850).  Saving model ...
Validation loss decreased (1.221850 --> 1.216000).  Saving model ...
Validation loss decreased (1.216000 --> 1.209870).  Saving model ...
Validation loss decreased (1.209870 --> 1.204257).  Saving model ...
Validation loss decreased (1.204257 --> 1.199355).  Saving model ...
Validation loss decreased (1.199355 --> 1.193679).  Saving model ...
Validation loss decreased (1.193679 --> 1.188473).  Saving model ...
Validation loss decreased (1.188473 --> 1.183509).  Saving model ...
Validation loss decreased (1.183509 --> 1.176053).  Saving model ...
Validation loss decreased (1.176053 --> 1.171845).  Saving model ...
Validation loss decreased (1.171845 --> 1.168323).  Saving model ...
Validation loss decreased (1.168323 --> 1.163686).  Saving model ...
Validation loss decreased (1.163686 --> 1.158695).  Saving model ...
EarlyStopping counter: 1 out of 3.0
Validation loss decreased (1.158695 --> 1.154981).  Saving model ...
Validation loss decreased (1.154981 --> 1.151561).  Saving model ...
Validation loss decreased (1.151561 --> 1.147710).  Saving model ...
Validation loss decreased (1.147710 --> 1.143350).  Saving model ...
Validation loss decreased (1.143350 --> 1.140050).  Saving model ...
Validation loss decreased (1.140050 --> 1.137229).  Saving model ...
Validation loss decreased (1.137229 --> 1.130859).  Saving model ...
Validation loss decreased (1.130859 --> 1.127855).  Saving model ...
Validation loss decreased (1.127855 --> 1.125542).  Saving model ...
Validation loss decreased (1.125542 --> 1.122387).  Saving model ...
Validation loss decreased (1.122387 --> 1.118881).  Saving model ...
Validation loss decreased (1.118881 --> 1.115844).  Saving model ...
Validation loss decreased (1.115844 --> 1.113704).  Saving model ...
Validation loss decreased (1.113704 --> 1.110285).  Saving model ...
Validation loss decreased (1.110285 --> 1.106315).  Saving model ...
Validation loss decreased (1.106315 --> 1.103831).  Saving model ...
Validation loss decreased (1.103831 --> 1.103546).  Saving model ...
Validation loss decreased (1.103546 --> 1.100833).  Saving model ...
Validation loss decreased (1.100833 --> 1.095920).  Saving model ...
Validation loss decreased (1.095920 --> 1.093945).  Saving model ...
EarlyStopping counter: 1 out of 3.0
Validation loss decreased (1.093945 --> 1.091759).  Saving model ...
Validation loss decreased (1.091759 --> 1.090247).  Saving model ...
Validation loss decreased (1.090247 --> 1.087986).  Saving model ...
Validation loss decreased (1.087986 --> 1.084506).  Saving model ...
Validation loss decreased (1.084506 --> 1.081004).  Saving model ...
EarlyStopping counter: 1 out of 3.0
Validation loss decreased (1.081004 --> 1.080391).  Saving model ...
Validation loss decreased (1.080391 --> 1.076996).  Saving model ...
EarlyStopping counter: 1 out of 3.0
Validation loss decreased (1.076996 --> 1.073734).  Saving model ...
Validation loss decreased (1.073734 --> 1.071072).  Saving model ...
EarlyStopping counter: 1 out of 3.0
EarlyStopping counter: 2 out of 3.0
Validation loss decreased (1.071072 --> 1.069900).  Saving model ...
Validation loss decreased (1.069900 --> 1.067807).  Saving model ...
Validation loss decreased (1.067807 --> 1.065710).  Saving model ...
Validation loss decreased (1.065710 --> 1.064116).  Saving model ...
Validation loss decreased (1.064116 --> 1.062760).  Saving model ...
Validation loss decreased (1.062760 --> 1.060126).  Saving model ...
Validation loss decreased (1.060126 --> 1.058760).  Saving model ...
Validation loss decreased (1.058760 --> 1.057506).  Saving model ...
Validation loss decreased (1.057506 --> 1.055928).  Saving model ...
EarlyStopping counter: 1 out of 3.0
EarlyStopping counter: 2 out of 3.0
Validation loss decreased (1.055928 --> 1.052975).  Saving model ...
Validation loss decreased (1.052975 --> 1.051634).  Saving model ...
Validation loss decreased (1.051634 --> 1.048982).  Saving model ...
Validation loss decreased (1.048982 --> 1.047061).  Saving model ...
EarlyStopping counter: 1 out of 3.0
EarlyStopping counter: 2 out of 3.0
Validation loss decreased (1.047061 --> 1.045410).  Saving model ...
Validation loss decreased (1.045410 --> 1.042996).  Saving model ...
EarlyStopping counter: 1 out of 3.0
EarlyStopping counter: 2 out of 3.0
Validation loss decreased (1.042996 --> 1.041302).  Saving model ...
Validation loss decreased (1.041302 --> 1.038085).  Saving model ...
EarlyStopping counter: 1 out of 3.0
Validation loss decreased (1.038085 --> 1.037419).  Saving model ...
Validation loss decreased (1.037419 --> 1.036616).  Saving model ...
EarlyStopping counter: 1 out of 3.0
Validation loss decreased (1.036616 --> 1.036284).  Saving model ...
EarlyStopping counter: 1 out of 3.0
Validation loss decreased (1.036284 --> 1.036207).  Saving model ...
Validation loss decreased (1.036207 --> 1.034620).  Saving model ...
EarlyStopping counter: 1 out of 3.0
EarlyStopping counter: 2 out of 3.0
Validation loss decreased (1.034620 --> 1.034605).  Saving model ...
Validation loss decreased (1.034605 --> 1.034480).  Saving model ...
Validation loss decreased (1.034480 --> 1.034168).  Saving model ...
Validation loss decreased (1.034168 --> 1.034013).  Saving model ...
Validation loss decreased (1.034013 --> 1.033199).  Saving model ...
Validation loss decreased (1.033199 --> 1.031356).  Saving model ...
EarlyStopping counter: 1 out of 3.0
EarlyStopping counter: 2 out of 3.0
EarlyStopping counter: 3 out of 3.0
/localscratch/yinan.29785236.0/env/lib/python3.7/site-packages/torch/nn/functional.py:1794: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.
  warnings.warn("nn.functional.tanh is deprecated. Use torch.tanh instead.")
wandb: Waiting for W&B process to finish, PID 23703... (success).
wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: \ 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: | 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: / 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: \ 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: | 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: / 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: \ 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: | 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: / 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb:                                                                                
wandb: Run history:
wandb:     e_F1 ▁▁▂▃▄▅▅▅▆▆▆▆▆▆▆▇▇▇▇▇▇▇██████████████████
wandb:   e_loss ██▇▇▇▇▆▆▆▆▅▅▄▄▄▃▃▃▃▃▂▂▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁
wandb:     t_F1 ▁▁▂▃▃▄▄▃▄▄▅▅▅▅▆▆▅▆▆▆▆▆▇▆▆▇▇▇▇▇█▇▇█▇▇███▇
wandb:   t_loss ██▇▇▇▇▇▇▇▆▆▆▆▅▅▅▅▄▄▄▄▄▃▃▃▃▂▃▂▂▂▂▂▂▂▂▁▁▁▁
wandb: 
wandb: Run summary:
wandb:     e_F1 56.02367
wandb:   e_loss 1.03365
wandb:     t_F1 65.88918
wandb:   t_loss 0.79529
wandb: 
wandb: Synced 4 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Synced iconic-totem-2: https://wandb.ai/yinanazhou/xl_512_bs_8_lr_1e06_es_3_lc_True_nr_True_sr_True_stem_True_lemma_False_repeat_2_fold_1/runs/29onrhig
wandb: Find logs at: ./wandb/run-20220331_084202-29onrhig/logs/debug.log
wandb: 

wandb: wandb version 0.12.11 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
2022-03-31 10:00:56.239392: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1
wandb: Tracking run with wandb version 0.12.5
wandb: Syncing run rose-paper-2
wandb: ⭐️ View project at https://wandb.ai/yinanazhou/xl_512_bs_8_lr_1e06_es_3_lc_True_nr_True_sr_True_stem_True_lemma_False_repeat_2_fold_2
wandb: 🚀 View run at https://wandb.ai/yinanazhou/xl_512_bs_8_lr_1e06_es_3_lc_True_nr_True_sr_True_stem_True_lemma_False_repeat_2_fold_2/runs/2oo5710d
wandb: Run data is saved locally in /project/6002780/yinan/Thesis_MER_Lyrics/lyric-emotion/wandb/run-20220331_100053-2oo5710d
wandb: Run `wandb offline` to turn off syncing.

Validation loss decreased (inf --> 1.518088).  Saving model ...
Validation loss decreased (1.518088 --> 1.480231).  Saving model ...
Validation loss decreased (1.480231 --> 1.449397).  Saving model ...
Validation loss decreased (1.449397 --> 1.425615).  Saving model ...
Validation loss decreased (1.425615 --> 1.407829).  Saving model ...
Validation loss decreased (1.407829 --> 1.395644).  Saving model ...
Validation loss decreased (1.395644 --> 1.386300).  Saving model ...
Validation loss decreased (1.386300 --> 1.378793).  Saving model ...
Validation loss decreased (1.378793 --> 1.373642).  Saving model ...
Validation loss decreased (1.373642 --> 1.369637).  Saving model ...
Validation loss decreased (1.369637 --> 1.365007).  Saving model ...
Validation loss decreased (1.365007 --> 1.361043).  Saving model ...
Validation loss decreased (1.361043 --> 1.357349).  Saving model ...
Validation loss decreased (1.357349 --> 1.353650).  Saving model ...
Validation loss decreased (1.353650 --> 1.349950).  Saving model ...
Validation loss decreased (1.349950 --> 1.346055).  Saving model ...
Validation loss decreased (1.346055 --> 1.342012).  Saving model ...
Validation loss decreased (1.342012 --> 1.338636).  Saving model ...
Validation loss decreased (1.338636 --> 1.335115).  Saving model ...
Validation loss decreased (1.335115 --> 1.331374).  Saving model ...
Validation loss decreased (1.331374 --> 1.327423).  Saving model ...
Validation loss decreased (1.327423 --> 1.323045).  Saving model ...
Validation loss decreased (1.323045 --> 1.318631).  Saving model ...
Validation loss decreased (1.318631 --> 1.315440).  Saving model ...
Validation loss decreased (1.315440 --> 1.311754).  Saving model ...
Validation loss decreased (1.311754 --> 1.306712).  Saving model ...
Validation loss decreased (1.306712 --> 1.302780).  Saving model ...
Validation loss decreased (1.302780 --> 1.299407).  Saving model ...
Validation loss decreased (1.299407 --> 1.296099).  Saving model ...
Validation loss decreased (1.296099 --> 1.292178).  Saving model ...
Validation loss decreased (1.292178 --> 1.288188).  Saving model ...
Validation loss decreased (1.288188 --> 1.283331).  Saving model ...
Validation loss decreased (1.283331 --> 1.278816).  Saving model ...
Validation loss decreased (1.278816 --> 1.274778).  Saving model ...
Validation loss decreased (1.274778 --> 1.269791).  Saving model ...
Validation loss decreased (1.269791 --> 1.267031).  Saving model ...
Validation loss decreased (1.267031 --> 1.263947).  Saving model ...
Validation loss decreased (1.263947 --> 1.260627).  Saving model ...
Validation loss decreased (1.260627 --> 1.256878).  Saving model ...
Validation loss decreased (1.256878 --> 1.251986).  Saving model ...
Validation loss decreased (1.251986 --> 1.248130).  Saving model ...
Validation loss decreased (1.248130 --> 1.245790).  Saving model ...
Validation loss decreased (1.245790 --> 1.240301).  Saving model ...
Validation loss decreased (1.240301 --> 1.236821).  Saving model ...
Validation loss decreased (1.236821 --> 1.233500).  Saving model ...
Validation loss decreased (1.233500 --> 1.229926).  Saving model ...
Validation loss decreased (1.229926 --> 1.226261).  Saving model ...
Validation loss decreased (1.226261 --> 1.221691).  Saving model ...
Validation loss decreased (1.221691 --> 1.217104).  Saving model ...
Validation loss decreased (1.217104 --> 1.213555).  Saving model ...
Validation loss decreased (1.213555 --> 1.210579).  Saving model ...
Validation loss decreased (1.210579 --> 1.206383).  Saving model ...
Validation loss decreased (1.206383 --> 1.202091).  Saving model ...
Validation loss decreased (1.202091 --> 1.197799).  Saving model ...
Validation loss decreased (1.197799 --> 1.196288).  Saving model ...
Validation loss decreased (1.196288 --> 1.193248).  Saving model ...
Validation loss decreased (1.193248 --> 1.189659).  Saving model ...
Validation loss decreased (1.189659 --> 1.187644).  Saving model ...
Validation loss decreased (1.187644 --> 1.182703).  Saving model ...
Validation loss decreased (1.182703 --> 1.178316).  Saving model ...
Validation loss decreased (1.178316 --> 1.171898).  Saving model ...
Validation loss decreased (1.171898 --> 1.169009).  Saving model ...
Validation loss decreased (1.169009 --> 1.165977).  Saving model ...
Validation loss decreased (1.165977 --> 1.161789).  Saving model ...
Validation loss decreased (1.161789 --> 1.159242).  Saving model ...
Validation loss decreased (1.159242 --> 1.158627).  Saving model ...
Validation loss decreased (1.158627 --> 1.155815).  Saving model ...
Validation loss decreased (1.155815 --> 1.150795).  Saving model ...
Validation loss decreased (1.150795 --> 1.149335).  Saving model ...
Validation loss decreased (1.149335 --> 1.146731).  Saving model ...
Validation loss decreased (1.146731 --> 1.141739).  Saving model ...
Validation loss decreased (1.141739 --> 1.140811).  Saving model ...
Validation loss decreased (1.140811 --> 1.135991).  Saving model ...
Validation loss decreased (1.135991 --> 1.135900).  Saving model ...
Validation loss decreased (1.135900 --> 1.129583).  Saving model ...
Validation loss decreased (1.129583 --> 1.126734).  Saving model ...
Validation loss decreased (1.126734 --> 1.125943).  Saving model ...
Validation loss decreased (1.125943 --> 1.124915).  Saving model ...
Validation loss decreased (1.124915 --> 1.123444).  Saving model ...
Validation loss decreased (1.123444 --> 1.117854).  Saving model ...
Validation loss decreased (1.117854 --> 1.113011).  Saving model ...
Validation loss decreased (1.113011 --> 1.107322).  Saving model ...
Validation loss decreased (1.107322 --> 1.104073).  Saving model ...
Validation loss decreased (1.104073 --> 1.099922).  Saving model ...
Validation loss decreased (1.099922 --> 1.099123).  Saving model ...
Validation loss decreased (1.099123 --> 1.096717).  Saving model ...
Validation loss decreased (1.096717 --> 1.094367).  Saving model ...
Validation loss decreased (1.094367 --> 1.092297).  Saving model ...
Validation loss decreased (1.092297 --> 1.088697).  Saving model ...
Validation loss decreased (1.088697 --> 1.085124).  Saving model ...
Validation loss decreased (1.085124 --> 1.078538).  Saving model ...
EarlyStopping counter: 1 out of 3.0
EarlyStopping counter: 2 out of 3.0
Validation loss decreased (1.078538 --> 1.074273).  Saving model ...
EarlyStopping counter: 1 out of 3.0
EarlyStopping counter: 2 out of 3.0
Validation loss decreased (1.074273 --> 1.070847).  Saving model ...
Validation loss decreased (1.070847 --> 1.067660).  Saving model ...
Validation loss decreased (1.067660 --> 1.063525).  Saving model ...
Validation loss decreased (1.063525 --> 1.060576).  Saving model ...
Validation loss decreased (1.060576 --> 1.057876).  Saving model ...
Validation loss decreased (1.057876 --> 1.057384).  Saving model ...
Validation loss decreased (1.057384 --> 1.056210).  Saving model ...
Validation loss decreased (1.056210 --> 1.054282).  Saving model ...
Validation loss decreased (1.054282 --> 1.052390).  Saving model ...
Validation loss decreased (1.052390 --> 1.051046).  Saving model ...
Validation loss decreased (1.051046 --> 1.049604).  Saving model ...
Validation loss decreased (1.049604 --> 1.047195).  Saving model ...
EarlyStopping counter: 1 out of 3.0
Validation loss decreased (1.047195 --> 1.045685).  Saving model ...
Validation loss decreased (1.045685 --> 1.043822).  Saving model ...
Validation loss decreased (1.043822 --> 1.042688).  Saving model ...
Validation loss decreased (1.042688 --> 1.040834).  Saving model ...
Validation loss decreased (1.040834 --> 1.036330).  Saving model ...
Validation loss decreased (1.036330 --> 1.033106).  Saving model ...
Validation loss decreased (1.033106 --> 1.031276).  Saving model ...
Validation loss decreased (1.031276 --> 1.030562).  Saving model ...
EarlyStopping counter: 1 out of 3.0
Validation loss decreased (1.030562 --> 1.026973).  Saving model ...
EarlyStopping counter: 1 out of 3.0
Validation loss decreased (1.026973 --> 1.022443).  Saving model ...
EarlyStopping counter: 1 out of 3.0
Validation loss decreased (1.022443 --> 1.020354).  Saving model ...
Validation loss decreased (1.020354 --> 1.020067).  Saving model ...
Validation loss decreased (1.020067 --> 1.019289).  Saving model ...
Validation loss decreased (1.019289 --> 1.019134).  Saving model ...
Validation loss decreased (1.019134 --> 1.018293).  Saving model ...
Validation loss decreased (1.018293 --> 1.017535).  Saving model ...
Validation loss decreased (1.017535 --> 1.016911).  Saving model ...
Validation loss decreased (1.016911 --> 1.013738).  Saving model ...
Validation loss decreased (1.013738 --> 1.013735).  Saving model ...
Validation loss decreased (1.013735 --> 1.011478).  Saving model ...
Validation loss decreased (1.011478 --> 1.010620).  Saving model ...
EarlyStopping counter: 1 out of 3.0
Validation loss decreased (1.010620 --> 1.010162).  Saving model ...
Validation loss decreased (1.010162 --> 1.009239).  Saving model ...
Validation loss decreased (1.009239 --> 1.004954).  Saving model ...
Validation loss decreased (1.004954 --> 1.000526).  Saving model ...
Validation loss decreased (1.000526 --> 0.999718).  Saving model ...
EarlyStopping counter: 1 out of 3.0
EarlyStopping counter: 2 out of 3.0
Validation loss decreased (0.999718 --> 0.999680).  Saving model ...
Validation loss decreased (0.999680 --> 0.998005).  Saving model ...
EarlyStopping counter: 1 out of 3.0
Validation loss decreased (0.998005 --> 0.997308).  Saving model ...
EarlyStopping counter: 1 out of 3.0
EarlyStopping counter: 2 out of 3.0
Validation loss decreased (0.997308 --> 0.996232).  Saving model ...
EarlyStopping counter: 1 out of 3.0
Validation loss decreased (0.996232 --> 0.995562).  Saving model ...
Validation loss decreased (0.995562 --> 0.995249).  Saving model ...
Validation loss decreased (0.995249 --> 0.992176).  Saving model ...
EarlyStopping counter: 1 out of 3.0
EarlyStopping counter: 2 out of 3.0
EarlyStopping counter: 3 out of 3.0
/localscratch/yinan.29785236.0/env/lib/python3.7/site-packages/torch/nn/functional.py:1794: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.
  warnings.warn("nn.functional.tanh is deprecated. Use torch.tanh instead.")
wandb: Waiting for W&B process to finish, PID 27901... (success).
wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: \ 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: | 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: / 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: \ 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: | 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: / 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: \ 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: | 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: / 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb:                                                                                
wandb: Run history:
wandb:     e_F1 ▁▁▃▃▄▄▄▄▅▅▅▅▅▆▆▆▆▇▇▇▇▇▇▇▇▇▇▇▇███████████
wandb:   e_loss █▇▇▆▆▆▆▅▅▅▅▄▄▄▄▄▃▃▃▃▃▃▂▂▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁
wandb:     t_F1 ▁▁▂▂▂▄▃▄▄▄▄▅▅▅▆▆▆▅▅▇▆▆▇▆▇▆▇▇▇▇▇▇▇▇█▇▇███
wandb:   t_loss ██▇▇▇▇▆▆▆▆▆▅▅▅▅▅▄▄▄▄▃▄▃▃▃▃▃▃▂▂▂▂▂▂▂▁▂▂▁▁
wandb: 
wandb: Run summary:
wandb:     e_F1 54.03707
wandb:   e_loss 0.9972
wandb:     t_F1 68.84436
wandb:   t_loss 0.80818
wandb: 
wandb: Synced 4 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Synced rose-paper-2: https://wandb.ai/yinanazhou/xl_512_bs_8_lr_1e06_es_3_lc_True_nr_True_sr_True_stem_True_lemma_False_repeat_2_fold_2/runs/2oo5710d
wandb: Find logs at: ./wandb/run-20220331_100053-2oo5710d/logs/debug.log
wandb: 

wandb: wandb version 0.12.11 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
2022-03-31 11:41:51.434341: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1
wandb: Tracking run with wandb version 0.12.5
wandb: Syncing run usual-snowball-2
wandb: ⭐️ View project at https://wandb.ai/yinanazhou/xl_512_bs_8_lr_1e06_es_3_lc_True_nr_True_sr_True_stem_True_lemma_False_repeat_3_fold_1
wandb: 🚀 View run at https://wandb.ai/yinanazhou/xl_512_bs_8_lr_1e06_es_3_lc_True_nr_True_sr_True_stem_True_lemma_False_repeat_3_fold_1/runs/1pdiw525
wandb: Run data is saved locally in /project/6002780/yinan/Thesis_MER_Lyrics/lyric-emotion/wandb/run-20220331_114148-1pdiw525
wandb: Run `wandb offline` to turn off syncing.

Validation loss decreased (inf --> 1.404913).  Saving model ...
Validation loss decreased (1.404913 --> 1.401393).  Saving model ...
Validation loss decreased (1.401393 --> 1.398225).  Saving model ...
Validation loss decreased (1.398225 --> 1.395306).  Saving model ...
Validation loss decreased (1.395306 --> 1.392314).  Saving model ...
Validation loss decreased (1.392314 --> 1.389701).  Saving model ...
Validation loss decreased (1.389701 --> 1.387225).  Saving model ...
Validation loss decreased (1.387225 --> 1.384956).  Saving model ...
Validation loss decreased (1.384956 --> 1.382381).  Saving model ...
Validation loss decreased (1.382381 --> 1.379855).  Saving model ...
Validation loss decreased (1.379855 --> 1.377487).  Saving model ...
Validation loss decreased (1.377487 --> 1.375000).  Saving model ...
Validation loss decreased (1.375000 --> 1.372327).  Saving model ...
Validation loss decreased (1.372327 --> 1.369566).  Saving model ...
Validation loss decreased (1.369566 --> 1.366872).  Saving model ...
Validation loss decreased (1.366872 --> 1.364062).  Saving model ...
Validation loss decreased (1.364062 --> 1.361308).  Saving model ...
Validation loss decreased (1.361308 --> 1.358700).  Saving model ...
Validation loss decreased (1.358700 --> 1.355721).  Saving model ...
Validation loss decreased (1.355721 --> 1.352737).  Saving model ...
Validation loss decreased (1.352737 --> 1.349788).  Saving model ...
Validation loss decreased (1.349788 --> 1.346838).  Saving model ...
Validation loss decreased (1.346838 --> 1.343880).  Saving model ...
Validation loss decreased (1.343880 --> 1.340290).  Saving model ...
Validation loss decreased (1.340290 --> 1.337223).  Saving model ...
Validation loss decreased (1.337223 --> 1.333801).  Saving model ...
Validation loss decreased (1.333801 --> 1.330407).  Saving model ...
Validation loss decreased (1.330407 --> 1.326709).  Saving model ...
Validation loss decreased (1.326709 --> 1.323095).  Saving model ...
Validation loss decreased (1.323095 --> 1.318514).  Saving model ...
Validation loss decreased (1.318514 --> 1.314561).  Saving model ...
Validation loss decreased (1.314561 --> 1.310684).  Saving model ...
Validation loss decreased (1.310684 --> 1.306928).  Saving model ...
Validation loss decreased (1.306928 --> 1.302478).  Saving model ...
Validation loss decreased (1.302478 --> 1.298175).  Saving model ...
Validation loss decreased (1.298175 --> 1.294630).  Saving model ...
Validation loss decreased (1.294630 --> 1.289579).  Saving model ...
Validation loss decreased (1.289579 --> 1.285325).  Saving model ...
Validation loss decreased (1.285325 --> 1.282483).  Saving model ...
Validation loss decreased (1.282483 --> 1.276074).  Saving model ...
Validation loss decreased (1.276074 --> 1.269750).  Saving model ...
Validation loss decreased (1.269750 --> 1.265462).  Saving model ...
Validation loss decreased (1.265462 --> 1.259809).  Saving model ...
Validation loss decreased (1.259809 --> 1.254614).  Saving model ...
Validation loss decreased (1.254614 --> 1.250254).  Saving model ...
Validation loss decreased (1.250254 --> 1.247013).  Saving model ...
Validation loss decreased (1.247013 --> 1.239467).  Saving model ...
Validation loss decreased (1.239467 --> 1.237398).  Saving model ...
Validation loss decreased (1.237398 --> 1.231365).  Saving model ...
Validation loss decreased (1.231365 --> 1.225401).  Saving model ...
Validation loss decreased (1.225401 --> 1.221180).  Saving model ...
Validation loss decreased (1.221180 --> 1.214951).  Saving model ...
Validation loss decreased (1.214951 --> 1.210086).  Saving model ...
Validation loss decreased (1.210086 --> 1.205142).  Saving model ...
Validation loss decreased (1.205142 --> 1.200857).  Saving model ...
Validation loss decreased (1.200857 --> 1.194860).  Saving model ...
Validation loss decreased (1.194860 --> 1.188199).  Saving model ...
Validation loss decreased (1.188199 --> 1.183594).  Saving model ...
Validation loss decreased (1.183594 --> 1.180243).  Saving model ...
EarlyStopping counter: 1 out of 3.0
Validation loss decreased (1.180243 --> 1.175323).  Saving model ...
Validation loss decreased (1.175323 --> 1.172798).  Saving model ...
Validation loss decreased (1.172798 --> 1.168337).  Saving model ...
Validation loss decreased (1.168337 --> 1.163081).  Saving model ...
Validation loss decreased (1.163081 --> 1.158274).  Saving model ...
EarlyStopping counter: 1 out of 3.0
Validation loss decreased (1.158274 --> 1.153910).  Saving model ...
Validation loss decreased (1.153910 --> 1.148272).  Saving model ...
Validation loss decreased (1.148272 --> 1.142167).  Saving model ...
Validation loss decreased (1.142167 --> 1.140294).  Saving model ...
Validation loss decreased (1.140294 --> 1.139354).  Saving model ...
Validation loss decreased (1.139354 --> 1.135033).  Saving model ...
Validation loss decreased (1.135033 --> 1.134627).  Saving model ...
Validation loss decreased (1.134627 --> 1.127850).  Saving model ...
Validation loss decreased (1.127850 --> 1.127376).  Saving model ...
Validation loss decreased (1.127376 --> 1.125105).  Saving model ...
Validation loss decreased (1.125105 --> 1.121540).  Saving model ...
Validation loss decreased (1.121540 --> 1.119008).  Saving model ...
EarlyStopping counter: 1 out of 3.0
Validation loss decreased (1.119008 --> 1.115891).  Saving model ...
Validation loss decreased (1.115891 --> 1.113510).  Saving model ...
Validation loss decreased (1.113510 --> 1.111041).  Saving model ...
Validation loss decreased (1.111041 --> 1.107714).  Saving model ...
Validation loss decreased (1.107714 --> 1.104447).  Saving model ...
EarlyStopping counter: 1 out of 3.0
Validation loss decreased (1.104447 --> 1.104049).  Saving model ...
Validation loss decreased (1.104049 --> 1.100669).  Saving model ...
Validation loss decreased (1.100669 --> 1.098998).  Saving model ...
Validation loss decreased (1.098998 --> 1.096287).  Saving model ...
Validation loss decreased (1.096287 --> 1.094191).  Saving model ...
Validation loss decreased (1.094191 --> 1.092230).  Saving model ...
Validation loss decreased (1.092230 --> 1.090440).  Saving model ...
Validation loss decreased (1.090440 --> 1.089058).  Saving model ...
Validation loss decreased (1.089058 --> 1.088849).  Saving model ...
EarlyStopping counter: 1 out of 3.0
Validation loss decreased (1.088849 --> 1.085299).  Saving model ...
Validation loss decreased (1.085299 --> 1.082655).  Saving model ...
Validation loss decreased (1.082655 --> 1.081900).  Saving model ...
EarlyStopping counter: 1 out of 3.0
Validation loss decreased (1.081900 --> 1.079924).  Saving model ...
Validation loss decreased (1.079924 --> 1.076286).  Saving model ...
Validation loss decreased (1.076286 --> 1.074740).  Saving model ...
Validation loss decreased (1.074740 --> 1.069681).  Saving model ...
Validation loss decreased (1.069681 --> 1.066385).  Saving model ...
EarlyStopping counter: 1 out of 3.0
EarlyStopping counter: 2 out of 3.0
Validation loss decreased (1.066385 --> 1.065944).  Saving model ...
EarlyStopping counter: 1 out of 3.0
EarlyStopping counter: 2 out of 3.0
EarlyStopping counter: 3 out of 3.0
/localscratch/yinan.29785236.0/env/lib/python3.7/site-packages/torch/nn/functional.py:1794: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.
  warnings.warn("nn.functional.tanh is deprecated. Use torch.tanh instead.")
wandb: Waiting for W&B process to finish, PID 33321... (success).
wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: \ 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: | 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: / 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: \ 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: | 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: / 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: \ 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: | 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: / 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb:                                                                                
wandb: Run history:
wandb:     e_F1 ▁▂▂▃▃▃▄▄▄▄▄▅▅▅▅▆▆▆▆▇▇▇▇▇▇▇██████████████
wandb:   e_loss ████▇▇▇▇▇▇▆▆▆▆▅▅▅▅▄▄▄▃▃▃▃▃▂▂▂▂▂▂▂▁▁▁▁▁▁▁
wandb:     t_F1 ▁▁▁▁▂▂▂▂▃▃▃▄▄▃▅▄▄▅▅▆▅▆▆▅▆▇▇▆▆▇▆▇▆▇▇█▇▇▇▇
wandb:   t_loss █████▇█▇▇▇▇▇▆▆▆▆▆▅▅▅▅▄▄▄▄▃▃▃▃▃▂▂▂▁▂▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:     e_F1 52.54808
wandb:   e_loss 1.06918
wandb:     t_F1 64.23159
wandb:   t_loss 0.8979
wandb: 
wandb: Synced 4 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Synced usual-snowball-2: https://wandb.ai/yinanazhou/xl_512_bs_8_lr_1e06_es_3_lc_True_nr_True_sr_True_stem_True_lemma_False_repeat_3_fold_1/runs/1pdiw525
wandb: Find logs at: ./wandb/run-20220331_114148-1pdiw525/logs/debug.log
wandb: 

wandb: wandb version 0.12.11 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
2022-03-31 12:53:29.672905: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1
wandb: Tracking run with wandb version 0.12.5
wandb: Syncing run scarlet-rain-2
wandb: ⭐️ View project at https://wandb.ai/yinanazhou/xl_512_bs_8_lr_1e06_es_3_lc_True_nr_True_sr_True_stem_True_lemma_False_repeat_3_fold_2
wandb: 🚀 View run at https://wandb.ai/yinanazhou/xl_512_bs_8_lr_1e06_es_3_lc_True_nr_True_sr_True_stem_True_lemma_False_repeat_3_fold_2/runs/32qob5v7
wandb: Run data is saved locally in /project/6002780/yinan/Thesis_MER_Lyrics/lyric-emotion/wandb/run-20220331_125327-32qob5v7
wandb: Run `wandb offline` to turn off syncing.

Validation loss decreased (inf --> 1.424052).  Saving model ...
Validation loss decreased (1.424052 --> 1.405204).  Saving model ...
Validation loss decreased (1.405204 --> 1.392053).  Saving model ...
Validation loss decreased (1.392053 --> 1.382083).  Saving model ...
Validation loss decreased (1.382083 --> 1.374016).  Saving model ...
Validation loss decreased (1.374016 --> 1.368566).  Saving model ...
Validation loss decreased (1.368566 --> 1.363927).  Saving model ...
Validation loss decreased (1.363927 --> 1.359480).  Saving model ...
Validation loss decreased (1.359480 --> 1.355508).  Saving model ...
Validation loss decreased (1.355508 --> 1.352322).  Saving model ...
Validation loss decreased (1.352322 --> 1.348676).  Saving model ...
Validation loss decreased (1.348676 --> 1.344700).  Saving model ...
Validation loss decreased (1.344700 --> 1.340945).  Saving model ...
Validation loss decreased (1.340945 --> 1.337826).  Saving model ...
Validation loss decreased (1.337826 --> 1.334034).  Saving model ...
Validation loss decreased (1.334034 --> 1.330186).  Saving model ...
Validation loss decreased (1.330186 --> 1.325660).  Saving model ...
Validation loss decreased (1.325660 --> 1.321624).  Saving model ...
Validation loss decreased (1.321624 --> 1.317310).  Saving model ...
Validation loss decreased (1.317310 --> 1.313083).  Saving model ...
Validation loss decreased (1.313083 --> 1.309030).  Saving model ...
Validation loss decreased (1.309030 --> 1.303920).  Saving model ...
Validation loss decreased (1.303920 --> 1.299300).  Saving model ...
Validation loss decreased (1.299300 --> 1.294347).  Saving model ...
Validation loss decreased (1.294347 --> 1.289094).  Saving model ...
Validation loss decreased (1.289094 --> 1.283404).  Saving model ...
Validation loss decreased (1.283404 --> 1.277137).  Saving model ...
Validation loss decreased (1.277137 --> 1.271933).  Saving model ...
Validation loss decreased (1.271933 --> 1.265818).  Saving model ...
Validation loss decreased (1.265818 --> 1.259680).  Saving model ...
Validation loss decreased (1.259680 --> 1.253783).  Saving model ...
Validation loss decreased (1.253783 --> 1.247803).  Saving model ...
Validation loss decreased (1.247803 --> 1.242193).  Saving model ...
Validation loss decreased (1.242193 --> 1.236569).  Saving model ...
Validation loss decreased (1.236569 --> 1.231252).  Saving model ...
Validation loss decreased (1.231252 --> 1.225757).  Saving model ...
Validation loss decreased (1.225757 --> 1.219854).  Saving model ...
Validation loss decreased (1.219854 --> 1.215257).  Saving model ...
Validation loss decreased (1.215257 --> 1.209785).  Saving model ...
Validation loss decreased (1.209785 --> 1.203895).  Saving model ...
Validation loss decreased (1.203895 --> 1.197356).  Saving model ...
Validation loss decreased (1.197356 --> 1.193078).  Saving model ...
Validation loss decreased (1.193078 --> 1.188192).  Saving model ...
Validation loss decreased (1.188192 --> 1.182893).  Saving model ...
Validation loss decreased (1.182893 --> 1.178471).  Saving model ...
Validation loss decreased (1.178471 --> 1.174691).  Saving model ...
Validation loss decreased (1.174691 --> 1.168671).  Saving model ...
Validation loss decreased (1.168671 --> 1.162530).  Saving model ...
Validation loss decreased (1.162530 --> 1.159001).  Saving model ...
Validation loss decreased (1.159001 --> 1.155521).  Saving model ...
Validation loss decreased (1.155521 --> 1.151655).  Saving model ...
Validation loss decreased (1.151655 --> 1.148105).  Saving model ...
Validation loss decreased (1.148105 --> 1.143850).  Saving model ...
Validation loss decreased (1.143850 --> 1.140283).  Saving model ...
Validation loss decreased (1.140283 --> 1.135707).  Saving model ...
Validation loss decreased (1.135707 --> 1.131776).  Saving model ...
Validation loss decreased (1.131776 --> 1.128052).  Saving model ...
Validation loss decreased (1.128052 --> 1.124111).  Saving model ...
Validation loss decreased (1.124111 --> 1.119285).  Saving model ...
Validation loss decreased (1.119285 --> 1.116355).  Saving model ...
Validation loss decreased (1.116355 --> 1.114176).  Saving model ...
Validation loss decreased (1.114176 --> 1.111490).  Saving model ...
Validation loss decreased (1.111490 --> 1.107690).  Saving model ...
Validation loss decreased (1.107690 --> 1.104093).  Saving model ...
Validation loss decreased (1.104093 --> 1.100285).  Saving model ...
Validation loss decreased (1.100285 --> 1.096934).  Saving model ...
Validation loss decreased (1.096934 --> 1.095644).  Saving model ...
Validation loss decreased (1.095644 --> 1.093194).  Saving model ...
Validation loss decreased (1.093194 --> 1.088882).  Saving model ...
Validation loss decreased (1.088882 --> 1.084716).  Saving model ...
Validation loss decreased (1.084716 --> 1.080274).  Saving model ...
Validation loss decreased (1.080274 --> 1.078112).  Saving model ...
Validation loss decreased (1.078112 --> 1.075405).  Saving model ...
Validation loss decreased (1.075405 --> 1.072544).  Saving model ...
Validation loss decreased (1.072544 --> 1.069461).  Saving model ...
Validation loss decreased (1.069461 --> 1.066811).  Saving model ...
Validation loss decreased (1.066811 --> 1.064441).  Saving model ...
Validation loss decreased (1.064441 --> 1.061036).  Saving model ...
Validation loss decreased (1.061036 --> 1.058656).  Saving model ...
Validation loss decreased (1.058656 --> 1.056790).  Saving model ...
Validation loss decreased (1.056790 --> 1.053908).  Saving model ...
Validation loss decreased (1.053908 --> 1.051314).  Saving model ...
Validation loss decreased (1.051314 --> 1.047326).  Saving model ...
Validation loss decreased (1.047326 --> 1.045679).  Saving model ...
Validation loss decreased (1.045679 --> 1.043985).  Saving model ...
Validation loss decreased (1.043985 --> 1.041442).  Saving model ...
Validation loss decreased (1.041442 --> 1.039037).  Saving model ...
Validation loss decreased (1.039037 --> 1.038338).  Saving model ...
Validation loss decreased (1.038338 --> 1.035557).  Saving model ...
Validation loss decreased (1.035557 --> 1.032639).  Saving model ...
Validation loss decreased (1.032639 --> 1.030836).  Saving model ...
Validation loss decreased (1.030836 --> 1.028763).  Saving model ...
Validation loss decreased (1.028763 --> 1.026725).  Saving model ...
Validation loss decreased (1.026725 --> 1.026496).  Saving model ...
Validation loss decreased (1.026496 --> 1.023841).  Saving model ...
Validation loss decreased (1.023841 --> 1.021251).  Saving model ...
Validation loss decreased (1.021251 --> 1.018468).  Saving model ...
Validation loss decreased (1.018468 --> 1.016071).  Saving model ...
Validation loss decreased (1.016071 --> 1.015165).  Saving model ...
Validation loss decreased (1.015165 --> 1.013146).  Saving model ...
Validation loss decreased (1.013146 --> 1.011456).  Saving model ...
Validation loss decreased (1.011456 --> 1.010773).  Saving model ...
Validation loss decreased (1.010773 --> 1.009395).  Saving model ...
Validation loss decreased (1.009395 --> 1.006332).  Saving model ...
Validation loss decreased (1.006332 --> 1.005846).  Saving model ...
Validation loss decreased (1.005846 --> 1.003652).  Saving model ...
Validation loss decreased (1.003652 --> 1.000599).  Saving model ...
Validation loss decreased (1.000599 --> 1.000104).  Saving model ...
Validation loss decreased (1.000104 --> 0.998544).  Saving model ...
Validation loss decreased (0.998544 --> 0.997234).  Saving model ...
Validation loss decreased (0.997234 --> 0.997120).  Saving model ...
Validation loss decreased (0.997120 --> 0.994220).  Saving model ...
Validation loss decreased (0.994220 --> 0.993567).  Saving model ...
Validation loss decreased (0.993567 --> 0.992037).  Saving model ...
Validation loss decreased (0.992037 --> 0.991263).  Saving model ...
Validation loss decreased (0.991263 --> 0.988965).  Saving model ...
Validation loss decreased (0.988965 --> 0.987258).  Saving model ...
Validation loss decreased (0.987258 --> 0.984913).  Saving model ...
Validation loss decreased (0.984913 --> 0.983238).  Saving model ...
Validation loss decreased (0.983238 --> 0.982778).  Saving model ...
Validation loss decreased (0.982778 --> 0.982252).  Saving model ...
Validation loss decreased (0.982252 --> 0.980865).  Saving model ...
EarlyStopping counter: 1 out of 3.0
Validation loss decreased (0.980865 --> 0.979534).  Saving model ...
EarlyStopping counter: 1 out of 3.0
Validation loss decreased (0.979534 --> 0.977826).  Saving model ...
Validation loss decreased (0.977826 --> 0.976958).  Saving model ...
Validation loss decreased (0.976958 --> 0.976079).  Saving model ...
Validation loss decreased (0.976079 --> 0.975534).  Saving model ...
Validation loss decreased (0.975534 --> 0.974730).  Saving model ...
EarlyStopping counter: 1 out of 3.0
Validation loss decreased (0.974730 --> 0.974503).  Saving model ...
Validation loss decreased (0.974503 --> 0.973578).  Saving model ...
EarlyStopping counter: 1 out of 3.0
Validation loss decreased (0.973578 --> 0.973145).  Saving model ...
Validation loss decreased (0.973145 --> 0.972312).  Saving model ...
Validation loss decreased (0.972312 --> 0.972228).  Saving model ...
EarlyStopping counter: 1 out of 3.0
EarlyStopping counter: 2 out of 3.0
Validation loss decreased (0.972228 --> 0.971061).  Saving model ...
Validation loss decreased (0.971061 --> 0.968823).  Saving model ...
EarlyStopping counter: 1 out of 3.0
EarlyStopping counter: 2 out of 3.0
EarlyStopping counter: 3 out of 3.0
/localscratch/yinan.29785236.0/env/lib/python3.7/site-packages/torch/nn/functional.py:1794: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.
  warnings.warn("nn.functional.tanh is deprecated. Use torch.tanh instead.")
wandb: Waiting for W&B process to finish, PID 37172... (success).
wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: \ 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: | 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: / 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: \ 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: | 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: / 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: \ 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: | 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: / 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb:                                                                                
wandb: Run history:
wandb:     e_F1 ▁▂▄▄▄▅▅▅▆▆▆▆▆▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇████████████
wandb:   e_loss ██▇▇▇▇▆▆▆▅▅▅▄▄▄▄▃▃▃▃▃▂▂▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁
wandb:     t_F1 ▁▂▂▃▃▃▃▄▄▅▅▅▆▆▆▆▅▆▆▆▆▇▇▇▇▇▇▇▇▇▇██▇█▇▇███
wandb:   t_loss ███▇▇▇▇▇▆▆▆▆▅▅▅▅▅▄▄▄▄▃▃▃▃▃▃▃▃▃▂▂▂▂▂▂▂▁▁▁
wandb: 
wandb: Run summary:
wandb:     e_F1 58.23496
wandb:   e_loss 0.97029
wandb:     t_F1 69.34836
wandb:   t_loss 0.78782
wandb: 
wandb: Synced 4 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Synced scarlet-rain-2: https://wandb.ai/yinanazhou/xl_512_bs_8_lr_1e06_es_3_lc_True_nr_True_sr_True_stem_True_lemma_False_repeat_3_fold_2/runs/32qob5v7
wandb: Find logs at: ./wandb/run-20220331_125327-32qob5v7/logs/debug.log
wandb: 

wandb: wandb version 0.12.11 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
2022-03-31 14:27:20.686489: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1
wandb: Tracking run with wandb version 0.12.5
wandb: Syncing run unique-lion-2
wandb: ⭐️ View project at https://wandb.ai/yinanazhou/xl_512_bs_8_lr_1e06_es_3_lc_True_nr_True_sr_True_stem_True_lemma_False_repeat_4_fold_1
wandb: 🚀 View run at https://wandb.ai/yinanazhou/xl_512_bs_8_lr_1e06_es_3_lc_True_nr_True_sr_True_stem_True_lemma_False_repeat_4_fold_1/runs/11x3ck44
wandb: Run data is saved locally in /project/6002780/yinan/Thesis_MER_Lyrics/lyric-emotion/wandb/run-20220331_142717-11x3ck44
wandb: Run `wandb offline` to turn off syncing.

Validation loss decreased (inf --> 1.379137).  Saving model ...
Validation loss decreased (1.379137 --> 1.374472).  Saving model ...
Validation loss decreased (1.374472 --> 1.370218).  Saving model ...
Validation loss decreased (1.370218 --> 1.366398).  Saving model ...
Validation loss decreased (1.366398 --> 1.362751).  Saving model ...
Validation loss decreased (1.362751 --> 1.359571).  Saving model ...
Validation loss decreased (1.359571 --> 1.356450).  Saving model ...
Validation loss decreased (1.356450 --> 1.353129).  Saving model ...
Validation loss decreased (1.353129 --> 1.349860).  Saving model ...
Validation loss decreased (1.349860 --> 1.346775).  Saving model ...
Validation loss decreased (1.346775 --> 1.343436).  Saving model ...
Validation loss decreased (1.343436 --> 1.340021).  Saving model ...
Validation loss decreased (1.340021 --> 1.336275).  Saving model ...
Validation loss decreased (1.336275 --> 1.332919).  Saving model ...
Validation loss decreased (1.332919 --> 1.329513).  Saving model ...
Validation loss decreased (1.329513 --> 1.325700).  Saving model ...
Validation loss decreased (1.325700 --> 1.322010).  Saving model ...
Validation loss decreased (1.322010 --> 1.317969).  Saving model ...
Validation loss decreased (1.317969 --> 1.313616).  Saving model ...
Validation loss decreased (1.313616 --> 1.308941).  Saving model ...
Validation loss decreased (1.308941 --> 1.304286).  Saving model ...
Validation loss decreased (1.304286 --> 1.299445).  Saving model ...
Validation loss decreased (1.299445 --> 1.294805).  Saving model ...
Validation loss decreased (1.294805 --> 1.290337).  Saving model ...
Validation loss decreased (1.290337 --> 1.285120).  Saving model ...
Validation loss decreased (1.285120 --> 1.279837).  Saving model ...
Validation loss decreased (1.279837 --> 1.274311).  Saving model ...
Validation loss decreased (1.274311 --> 1.268686).  Saving model ...
Validation loss decreased (1.268686 --> 1.263028).  Saving model ...
Validation loss decreased (1.263028 --> 1.257187).  Saving model ...
Validation loss decreased (1.257187 --> 1.251942).  Saving model ...
Validation loss decreased (1.251942 --> 1.245793).  Saving model ...
Validation loss decreased (1.245793 --> 1.239784).  Saving model ...
Validation loss decreased (1.239784 --> 1.233967).  Saving model ...
Validation loss decreased (1.233967 --> 1.229298).  Saving model ...
Validation loss decreased (1.229298 --> 1.224396).  Saving model ...
Validation loss decreased (1.224396 --> 1.219540).  Saving model ...
Validation loss decreased (1.219540 --> 1.214938).  Saving model ...
Validation loss decreased (1.214938 --> 1.210245).  Saving model ...
Validation loss decreased (1.210245 --> 1.205951).  Saving model ...
Validation loss decreased (1.205951 --> 1.201595).  Saving model ...
Validation loss decreased (1.201595 --> 1.196704).  Saving model ...
Validation loss decreased (1.196704 --> 1.193097).  Saving model ...
Validation loss decreased (1.193097 --> 1.188129).  Saving model ...
Validation loss decreased (1.188129 --> 1.183503).  Saving model ...
Validation loss decreased (1.183503 --> 1.179810).  Saving model ...
Validation loss decreased (1.179810 --> 1.176351).  Saving model ...
Validation loss decreased (1.176351 --> 1.173098).  Saving model ...
Validation loss decreased (1.173098 --> 1.168849).  Saving model ...
Validation loss decreased (1.168849 --> 1.164348).  Saving model ...
Validation loss decreased (1.164348 --> 1.160433).  Saving model ...
Validation loss decreased (1.160433 --> 1.157020).  Saving model ...
Validation loss decreased (1.157020 --> 1.154007).  Saving model ...
Validation loss decreased (1.154007 --> 1.149990).  Saving model ...
Validation loss decreased (1.149990 --> 1.146514).  Saving model ...
Validation loss decreased (1.146514 --> 1.142569).  Saving model ...
Validation loss decreased (1.142569 --> 1.138902).  Saving model ...
Validation loss decreased (1.138902 --> 1.135303).  Saving model ...
Validation loss decreased (1.135303 --> 1.131493).  Saving model ...
Validation loss decreased (1.131493 --> 1.127782).  Saving model ...
Validation loss decreased (1.127782 --> 1.124885).  Saving model ...
Validation loss decreased (1.124885 --> 1.121756).  Saving model ...
Validation loss decreased (1.121756 --> 1.119511).  Saving model ...
Validation loss decreased (1.119511 --> 1.116250).  Saving model ...
Validation loss decreased (1.116250 --> 1.113560).  Saving model ...
Validation loss decreased (1.113560 --> 1.110425).  Saving model ...
Validation loss decreased (1.110425 --> 1.107414).  Saving model ...
Validation loss decreased (1.107414 --> 1.105524).  Saving model ...
Validation loss decreased (1.105524 --> 1.102551).  Saving model ...
Validation loss decreased (1.102551 --> 1.100822).  Saving model ...
Validation loss decreased (1.100822 --> 1.098830).  Saving model ...
Validation loss decreased (1.098830 --> 1.094754).  Saving model ...
Validation loss decreased (1.094754 --> 1.092729).  Saving model ...
Validation loss decreased (1.092729 --> 1.090670).  Saving model ...
Validation loss decreased (1.090670 --> 1.088137).  Saving model ...
Validation loss decreased (1.088137 --> 1.085700).  Saving model ...
Validation loss decreased (1.085700 --> 1.083770).  Saving model ...
Validation loss decreased (1.083770 --> 1.081253).  Saving model ...
Validation loss decreased (1.081253 --> 1.078078).  Saving model ...
Validation loss decreased (1.078078 --> 1.076002).  Saving model ...
Validation loss decreased (1.076002 --> 1.073395).  Saving model ...
Validation loss decreased (1.073395 --> 1.070741).  Saving model ...
Validation loss decreased (1.070741 --> 1.069795).  Saving model ...
Validation loss decreased (1.069795 --> 1.067883).  Saving model ...
Validation loss decreased (1.067883 --> 1.065899).  Saving model ...
Validation loss decreased (1.065899 --> 1.063966).  Saving model ...
Validation loss decreased (1.063966 --> 1.061749).  Saving model ...
Validation loss decreased (1.061749 --> 1.059849).  Saving model ...
Validation loss decreased (1.059849 --> 1.058173).  Saving model ...
Validation loss decreased (1.058173 --> 1.057153).  Saving model ...
Validation loss decreased (1.057153 --> 1.054621).  Saving model ...
Validation loss decreased (1.054621 --> 1.053089).  Saving model ...
Validation loss decreased (1.053089 --> 1.051359).  Saving model ...
Validation loss decreased (1.051359 --> 1.049877).  Saving model ...
Validation loss decreased (1.049877 --> 1.047940).  Saving model ...
Validation loss decreased (1.047940 --> 1.046506).  Saving model ...
Validation loss decreased (1.046506 --> 1.045371).  Saving model ...
Validation loss decreased (1.045371 --> 1.043729).  Saving model ...
Validation loss decreased (1.043729 --> 1.042055).  Saving model ...
Validation loss decreased (1.042055 --> 1.040966).  Saving model ...
Validation loss decreased (1.040966 --> 1.039886).  Saving model ...
Validation loss decreased (1.039886 --> 1.038258).  Saving model ...
Validation loss decreased (1.038258 --> 1.037570).  Saving model ...
Validation loss decreased (1.037570 --> 1.035982).  Saving model ...
Validation loss decreased (1.035982 --> 1.034736).  Saving model ...
EarlyStopping counter: 1 out of 3.0
Validation loss decreased (1.034736 --> 1.034294).  Saving model ...
EarlyStopping counter: 1 out of 3.0
Validation loss decreased (1.034294 --> 1.034209).  Saving model ...
Validation loss decreased (1.034209 --> 1.033960).  Saving model ...
Validation loss decreased (1.033960 --> 1.033566).  Saving model ...
Validation loss decreased (1.033566 --> 1.033109).  Saving model ...
EarlyStopping counter: 1 out of 3.0
Validation loss decreased (1.033109 --> 1.031576).  Saving model ...
Validation loss decreased (1.031576 --> 1.029917).  Saving model ...
Validation loss decreased (1.029917 --> 1.028164).  Saving model ...
Validation loss decreased (1.028164 --> 1.027243).  Saving model ...
EarlyStopping counter: 1 out of 3.0
Validation loss decreased (1.027243 --> 1.026934).  Saving model ...
Validation loss decreased (1.026934 --> 1.025857).  Saving model ...
Validation loss decreased (1.025857 --> 1.024402).  Saving model ...
Validation loss decreased (1.024402 --> 1.023592).  Saving model ...
EarlyStopping counter: 1 out of 3.0
EarlyStopping counter: 2 out of 3.0
Validation loss decreased (1.023592 --> 1.023339).  Saving model ...
Validation loss decreased (1.023339 --> 1.022266).  Saving model ...
Validation loss decreased (1.022266 --> 1.021747).  Saving model ...
Validation loss decreased (1.021747 --> 1.021027).  Saving model ...
Validation loss decreased (1.021027 --> 1.020342).  Saving model ...
Validation loss decreased (1.020342 --> 1.019125).  Saving model ...
EarlyStopping counter: 1 out of 3.0
EarlyStopping counter: 2 out of 3.0
Validation loss decreased (1.019125 --> 1.018681).  Saving model ...
EarlyStopping counter: 1 out of 3.0
EarlyStopping counter: 2 out of 3.0
Validation loss decreased (1.018681 --> 1.018351).  Saving model ...
EarlyStopping counter: 1 out of 3.0
Validation loss decreased (1.018351 --> 1.017189).  Saving model ...
Validation loss decreased (1.017189 --> 1.016285).  Saving model ...
Validation loss decreased (1.016285 --> 1.015492).  Saving model ...
EarlyStopping counter: 1 out of 3.0
Validation loss decreased (1.015492 --> 1.015430).  Saving model ...
EarlyStopping counter: 1 out of 3.0
EarlyStopping counter: 2 out of 3.0
Validation loss decreased (1.015430 --> 1.015309).  Saving model ...
EarlyStopping counter: 1 out of 3.0
EarlyStopping counter: 2 out of 3.0
EarlyStopping counter: 3 out of 3.0
/localscratch/yinan.29785236.0/env/lib/python3.7/site-packages/torch/nn/functional.py:1794: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.
  warnings.warn("nn.functional.tanh is deprecated. Use torch.tanh instead.")
wandb: Waiting for W&B process to finish, PID 42222... (success).
wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: \ 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: | 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: / 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: \ 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: | 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: / 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: \ 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: | 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: / 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb:                                                                                
wandb: Run history:
wandb:     e_F1 ▁▂▄▄▄▅▅▅▅▅▅▆▆▆▆▆▆▆▇▇▇▇▇▇▇▇██████████████
wandb:   e_loss ███▇▇▇▆▆▆▅▅▅▄▄▄▃▃▃▃▃▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:     t_F1 ▁▂▂▃▃▃▄▄▅▄▄▅▆▆▅▆▆▅▆▆▆▆▇▇▇▇▇▇▇▇▇█████████
wandb:   t_loss ███▇▇▇▇▇▆▆▆▆▅▅▅▅▅▅▄▄▄▃▃▃▃▃▃▃▃▃▂▂▂▂▂▁▂▂▁▁
wandb: 
wandb: Run summary:
wandb:     e_F1 57.28504
wandb:   e_loss 1.01882
wandb:     t_F1 69.95274
wandb:   t_loss 0.75755
wandb: 
wandb: Synced 4 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Synced unique-lion-2: https://wandb.ai/yinanazhou/xl_512_bs_8_lr_1e06_es_3_lc_True_nr_True_sr_True_stem_True_lemma_False_repeat_4_fold_1/runs/11x3ck44
wandb: Find logs at: ./wandb/run-20220331_142717-11x3ck44/logs/debug.log
wandb: 

wandb: wandb version 0.12.11 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
2022-03-31 16:05:12.562737: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1
wandb: Tracking run with wandb version 0.12.5
wandb: Syncing run ancient-leaf-1
wandb: ⭐️ View project at https://wandb.ai/yinanazhou/xl_512_bs_8_lr_1e06_es_3_lc_True_nr_True_sr_True_stem_True_lemma_False_repeat_4_fold_2
wandb: 🚀 View run at https://wandb.ai/yinanazhou/xl_512_bs_8_lr_1e06_es_3_lc_True_nr_True_sr_True_stem_True_lemma_False_repeat_4_fold_2/runs/3n9je7m1
wandb: Run data is saved locally in /project/6002780/yinan/Thesis_MER_Lyrics/lyric-emotion/wandb/run-20220331_160510-3n9je7m1
wandb: Run `wandb offline` to turn off syncing.

Validation loss decreased (inf --> 1.428284).  Saving model ...
Validation loss decreased (1.428284 --> 1.414282).  Saving model ...
Validation loss decreased (1.414282 --> 1.403724).  Saving model ...
Validation loss decreased (1.403724 --> 1.395670).  Saving model ...
Validation loss decreased (1.395670 --> 1.389318).  Saving model ...
Validation loss decreased (1.389318 --> 1.383996).  Saving model ...
Validation loss decreased (1.383996 --> 1.379431).  Saving model ...
Validation loss decreased (1.379431 --> 1.375567).  Saving model ...
Validation loss decreased (1.375567 --> 1.371882).  Saving model ...
Validation loss decreased (1.371882 --> 1.368206).  Saving model ...
Validation loss decreased (1.368206 --> 1.364705).  Saving model ...
Validation loss decreased (1.364705 --> 1.360736).  Saving model ...
Validation loss decreased (1.360736 --> 1.357399).  Saving model ...
Validation loss decreased (1.357399 --> 1.353648).  Saving model ...
Validation loss decreased (1.353648 --> 1.349977).  Saving model ...
Validation loss decreased (1.349977 --> 1.346341).  Saving model ...
Validation loss decreased (1.346341 --> 1.342747).  Saving model ...
Validation loss decreased (1.342747 --> 1.338889).  Saving model ...
Validation loss decreased (1.338889 --> 1.334875).  Saving model ...
Validation loss decreased (1.334875 --> 1.330890).  Saving model ...
Validation loss decreased (1.330890 --> 1.326598).  Saving model ...
Validation loss decreased (1.326598 --> 1.321548).  Saving model ...
Validation loss decreased (1.321548 --> 1.318249).  Saving model ...
Validation loss decreased (1.318249 --> 1.313972).  Saving model ...
Validation loss decreased (1.313972 --> 1.307493).  Saving model ...
Validation loss decreased (1.307493 --> 1.302831).  Saving model ...
Validation loss decreased (1.302831 --> 1.297990).  Saving model ...
Validation loss decreased (1.297990 --> 1.291696).  Saving model ...
Validation loss decreased (1.291696 --> 1.287387).  Saving model ...
Validation loss decreased (1.287387 --> 1.281864).  Saving model ...
Validation loss decreased (1.281864 --> 1.276290).  Saving model ...
Validation loss decreased (1.276290 --> 1.271133).  Saving model ...
Validation loss decreased (1.271133 --> 1.267573).  Saving model ...
Validation loss decreased (1.267573 --> 1.261505).  Saving model ...
Validation loss decreased (1.261505 --> 1.255485).  Saving model ...
Validation loss decreased (1.255485 --> 1.250771).  Saving model ...
Validation loss decreased (1.250771 --> 1.245262).  Saving model ...
Validation loss decreased (1.245262 --> 1.241072).  Saving model ...
Validation loss decreased (1.241072 --> 1.235806).  Saving model ...
Validation loss decreased (1.235806 --> 1.231880).  Saving model ...
Validation loss decreased (1.231880 --> 1.227979).  Saving model ...
Validation loss decreased (1.227979 --> 1.222837).  Saving model ...
Validation loss decreased (1.222837 --> 1.218936).  Saving model ...
Validation loss decreased (1.218936 --> 1.213783).  Saving model ...
Validation loss decreased (1.213783 --> 1.207961).  Saving model ...
Validation loss decreased (1.207961 --> 1.203267).  Saving model ...
Validation loss decreased (1.203267 --> 1.196813).  Saving model ...
Validation loss decreased (1.196813 --> 1.193779).  Saving model ...
Validation loss decreased (1.193779 --> 1.192131).  Saving model ...
Validation loss decreased (1.192131 --> 1.187373).  Saving model ...
Validation loss decreased (1.187373 --> 1.180576).  Saving model ...
Validation loss decreased (1.180576 --> 1.178013).  Saving model ...
Validation loss decreased (1.178013 --> 1.176152).  Saving model ...
Validation loss decreased (1.176152 --> 1.172263).  Saving model ...
Validation loss decreased (1.172263 --> 1.168739).  Saving model ...
Validation loss decreased (1.168739 --> 1.162003).  Saving model ...
Validation loss decreased (1.162003 --> 1.161639).  Saving model ...
Validation loss decreased (1.161639 --> 1.155807).  Saving model ...
Validation loss decreased (1.155807 --> 1.150424).  Saving model ...
Validation loss decreased (1.150424 --> 1.146541).  Saving model ...
Validation loss decreased (1.146541 --> 1.140572).  Saving model ...
Validation loss decreased (1.140572 --> 1.137527).  Saving model ...
EarlyStopping counter: 1 out of 3.0
Validation loss decreased (1.137527 --> 1.134246).  Saving model ...
Validation loss decreased (1.134246 --> 1.130858).  Saving model ...
Validation loss decreased (1.130858 --> 1.129988).  Saving model ...
Validation loss decreased (1.129988 --> 1.125960).  Saving model ...
Validation loss decreased (1.125960 --> 1.120863).  Saving model ...
Validation loss decreased (1.120863 --> 1.116494).  Saving model ...
Validation loss decreased (1.116494 --> 1.115623).  Saving model ...
Validation loss decreased (1.115623 --> 1.111985).  Saving model ...
Validation loss decreased (1.111985 --> 1.104446).  Saving model ...
EarlyStopping counter: 1 out of 3.0
Validation loss decreased (1.104446 --> 1.102117).  Saving model ...
Validation loss decreased (1.102117 --> 1.098017).  Saving model ...
EarlyStopping counter: 1 out of 3.0
EarlyStopping counter: 2 out of 3.0
Validation loss decreased (1.098017 --> 1.097521).  Saving model ...
Validation loss decreased (1.097521 --> 1.093561).  Saving model ...
Validation loss decreased (1.093561 --> 1.091507).  Saving model ...
Validation loss decreased (1.091507 --> 1.089365).  Saving model ...
Validation loss decreased (1.089365 --> 1.084460).  Saving model ...
Validation loss decreased (1.084460 --> 1.082244).  Saving model ...
Validation loss decreased (1.082244 --> 1.076594).  Saving model ...
EarlyStopping counter: 1 out of 3.0
EarlyStopping counter: 2 out of 3.0
Validation loss decreased (1.076594 --> 1.076299).  Saving model ...
Validation loss decreased (1.076299 --> 1.067950).  Saving model ...
EarlyStopping counter: 1 out of 3.0
EarlyStopping counter: 2 out of 3.0
EarlyStopping counter: 3 out of 3.0
/localscratch/yinan.29785236.0/env/lib/python3.7/site-packages/torch/nn/functional.py:1794: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.
  warnings.warn("nn.functional.tanh is deprecated. Use torch.tanh instead.")
wandb: Waiting for W&B process to finish, PID 47450... (success).
wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: \ 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: | 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: / 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: \ 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: | 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: / 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: \ 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: | 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: / 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb:                                                                                
wandb: Run history:
wandb:     e_F1 ▁▁▂▃▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▆▇▇▇▇▇▇▇▇▇███████████
wandb:   e_loss ██▇▇▇▇▇▆▆▆▆▆▅▅▅▅▄▄▄▄▄▃▃▃▃▃▃▂▂▂▂▂▂▂▁▁▁▁▁▁
wandb:     t_F1 ▁▁▂▂▃▃▃▃▃▄▄▄▅▅▅▅▅▆▅▅▆▆▆▆▇▇▆▇▇▇▇▇██▇██▇██
wandb:   t_loss █▇▇▇▇▇▇▇▇▆▆▆▆▆▆▅▅▅▅▅▄▄▄▄▃▃▃▃▃▃▃▂▂▂▂▂▁▂▁▁
wandb: 
wandb: Run summary:
wandb:     e_F1 50.85243
wandb:   e_loss 1.06861
wandb:     t_F1 64.96678
wandb:   t_loss 0.9363
wandb: 
wandb: Synced 4 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Synced ancient-leaf-1: https://wandb.ai/yinanazhou/xl_512_bs_8_lr_1e06_es_3_lc_True_nr_True_sr_True_stem_True_lemma_False_repeat_4_fold_2/runs/3n9je7m1
wandb: Find logs at: ./wandb/run-20220331_160510-3n9je7m1/logs/debug.log
wandb: 

wandb: wandb version 0.12.11 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
2022-03-31 17:05:09.761576: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1
wandb: Tracking run with wandb version 0.12.5
wandb: Syncing run logical-jazz-1
wandb: ⭐️ View project at https://wandb.ai/yinanazhou/xl_512_bs_8_lr_1e06_es_3_lc_True_nr_True_sr_True_stem_True_lemma_False_repeat_5_fold_1
wandb: 🚀 View run at https://wandb.ai/yinanazhou/xl_512_bs_8_lr_1e06_es_3_lc_True_nr_True_sr_True_stem_True_lemma_False_repeat_5_fold_1/runs/1yolzqrf
wandb: Run data is saved locally in /project/6002780/yinan/Thesis_MER_Lyrics/lyric-emotion/wandb/run-20220331_170507-1yolzqrf
wandb: Run `wandb offline` to turn off syncing.

Validation loss decreased (inf --> 1.410955).  Saving model ...
Validation loss decreased (1.410955 --> 1.396536).  Saving model ...
Validation loss decreased (1.396536 --> 1.385734).  Saving model ...
Validation loss decreased (1.385734 --> 1.377449).  Saving model ...
Validation loss decreased (1.377449 --> 1.371590).  Saving model ...
Validation loss decreased (1.371590 --> 1.366640).  Saving model ...
Validation loss decreased (1.366640 --> 1.362288).  Saving model ...
Validation loss decreased (1.362288 --> 1.358443).  Saving model ...
Validation loss decreased (1.358443 --> 1.354669).  Saving model ...
Validation loss decreased (1.354669 --> 1.351067).  Saving model ...
Validation loss decreased (1.351067 --> 1.347354).  Saving model ...
Validation loss decreased (1.347354 --> 1.343945).  Saving model ...
Validation loss decreased (1.343945 --> 1.340211).  Saving model ...
Validation loss decreased (1.340211 --> 1.336479).  Saving model ...
Validation loss decreased (1.336479 --> 1.332780).  Saving model ...
Validation loss decreased (1.332780 --> 1.329081).  Saving model ...
Validation loss decreased (1.329081 --> 1.325250).  Saving model ...
Validation loss decreased (1.325250 --> 1.320777).  Saving model ...
Validation loss decreased (1.320777 --> 1.316244).  Saving model ...
Validation loss decreased (1.316244 --> 1.311526).  Saving model ...
Validation loss decreased (1.311526 --> 1.306549).  Saving model ...
Validation loss decreased (1.306549 --> 1.301121).  Saving model ...
Validation loss decreased (1.301121 --> 1.295588).  Saving model ...
Validation loss decreased (1.295588 --> 1.291133).  Saving model ...
Validation loss decreased (1.291133 --> 1.285852).  Saving model ...
Validation loss decreased (1.285852 --> 1.280273).  Saving model ...
Validation loss decreased (1.280273 --> 1.274256).  Saving model ...
Validation loss decreased (1.274256 --> 1.268620).  Saving model ...
Validation loss decreased (1.268620 --> 1.261919).  Saving model ...
Validation loss decreased (1.261919 --> 1.256035).  Saving model ...
Validation loss decreased (1.256035 --> 1.249957).  Saving model ...
Validation loss decreased (1.249957 --> 1.244545).  Saving model ...
Validation loss decreased (1.244545 --> 1.238194).  Saving model ...
Validation loss decreased (1.238194 --> 1.233067).  Saving model ...
Validation loss decreased (1.233067 --> 1.227313).  Saving model ...
Validation loss decreased (1.227313 --> 1.222021).  Saving model ...
Validation loss decreased (1.222021 --> 1.217489).  Saving model ...
Validation loss decreased (1.217489 --> 1.214025).  Saving model ...
Validation loss decreased (1.214025 --> 1.208438).  Saving model ...
Validation loss decreased (1.208438 --> 1.203858).  Saving model ...
Validation loss decreased (1.203858 --> 1.199947).  Saving model ...
Validation loss decreased (1.199947 --> 1.195723).  Saving model ...
Validation loss decreased (1.195723 --> 1.192536).  Saving model ...
Validation loss decreased (1.192536 --> 1.187299).  Saving model ...
Validation loss decreased (1.187299 --> 1.182998).  Saving model ...
Validation loss decreased (1.182998 --> 1.177577).  Saving model ...
Validation loss decreased (1.177577 --> 1.173909).  Saving model ...
Validation loss decreased (1.173909 --> 1.170749).  Saving model ...
Validation loss decreased (1.170749 --> 1.165441).  Saving model ...
Validation loss decreased (1.165441 --> 1.160759).  Saving model ...
Validation loss decreased (1.160759 --> 1.157014).  Saving model ...
Validation loss decreased (1.157014 --> 1.154122).  Saving model ...
Validation loss decreased (1.154122 --> 1.150287).  Saving model ...
Validation loss decreased (1.150287 --> 1.147108).  Saving model ...
Validation loss decreased (1.147108 --> 1.142979).  Saving model ...
Validation loss decreased (1.142979 --> 1.138827).  Saving model ...
Validation loss decreased (1.138827 --> 1.135148).  Saving model ...
Validation loss decreased (1.135148 --> 1.131528).  Saving model ...
Validation loss decreased (1.131528 --> 1.128141).  Saving model ...
Validation loss decreased (1.128141 --> 1.124354).  Saving model ...
Validation loss decreased (1.124354 --> 1.119288).  Saving model ...
Validation loss decreased (1.119288 --> 1.115666).  Saving model ...
Validation loss decreased (1.115666 --> 1.112152).  Saving model ...
Validation loss decreased (1.112152 --> 1.109202).  Saving model ...
Validation loss decreased (1.109202 --> 1.106029).  Saving model ...
Validation loss decreased (1.106029 --> 1.102573).  Saving model ...
Validation loss decreased (1.102573 --> 1.101015).  Saving model ...
Validation loss decreased (1.101015 --> 1.098060).  Saving model ...
Validation loss decreased (1.098060 --> 1.093941).  Saving model ...
Validation loss decreased (1.093941 --> 1.089079).  Saving model ...
Validation loss decreased (1.089079 --> 1.087584).  Saving model ...
Validation loss decreased (1.087584 --> 1.086226).  Saving model ...
Validation loss decreased (1.086226 --> 1.082409).  Saving model ...
Validation loss decreased (1.082409 --> 1.080164).  Saving model ...
Validation loss decreased (1.080164 --> 1.076272).  Saving model ...
Validation loss decreased (1.076272 --> 1.072493).  Saving model ...
Validation loss decreased (1.072493 --> 1.070063).  Saving model ...
Validation loss decreased (1.070063 --> 1.067040).  Saving model ...
Validation loss decreased (1.067040 --> 1.063088).  Saving model ...
Validation loss decreased (1.063088 --> 1.062768).  Saving model ...
Validation loss decreased (1.062768 --> 1.062575).  Saving model ...
Validation loss decreased (1.062575 --> 1.060006).  Saving model ...
Validation loss decreased (1.060006 --> 1.056932).  Saving model ...
Validation loss decreased (1.056932 --> 1.054417).  Saving model ...
Validation loss decreased (1.054417 --> 1.050373).  Saving model ...
Validation loss decreased (1.050373 --> 1.046003).  Saving model ...
Validation loss decreased (1.046003 --> 1.045221).  Saving model ...
Validation loss decreased (1.045221 --> 1.044771).  Saving model ...
Validation loss decreased (1.044771 --> 1.041122).  Saving model ...
Validation loss decreased (1.041122 --> 1.037558).  Saving model ...
Validation loss decreased (1.037558 --> 1.036815).  Saving model ...
Validation loss decreased (1.036815 --> 1.034208).  Saving model ...
Validation loss decreased (1.034208 --> 1.031991).  Saving model ...
Validation loss decreased (1.031991 --> 1.029061).  Saving model ...
Validation loss decreased (1.029061 --> 1.028307).  Saving model ...
Validation loss decreased (1.028307 --> 1.024577).  Saving model ...
Validation loss decreased (1.024577 --> 1.023113).  Saving model ...
Validation loss decreased (1.023113 --> 1.021062).  Saving model ...
Validation loss decreased (1.021062 --> 1.020052).  Saving model ...
Validation loss decreased (1.020052 --> 1.018505).  Saving model ...
Validation loss decreased (1.018505 --> 1.016387).  Saving model ...
Validation loss decreased (1.016387 --> 1.015381).  Saving model ...
EarlyStopping counter: 1 out of 3.0
Validation loss decreased (1.015381 --> 1.013789).  Saving model ...
Validation loss decreased (1.013789 --> 1.011049).  Saving model ...
EarlyStopping counter: 1 out of 3.0
Validation loss decreased (1.011049 --> 1.008841).  Saving model ...
Validation loss decreased (1.008841 --> 1.006701).  Saving model ...
Validation loss decreased (1.006701 --> 1.004918).  Saving model ...
EarlyStopping counter: 1 out of 3.0
EarlyStopping counter: 2 out of 3.0
Validation loss decreased (1.004918 --> 1.002886).  Saving model ...
Validation loss decreased (1.002886 --> 1.001945).  Saving model ...
Validation loss decreased (1.001945 --> 0.999714).  Saving model ...
Validation loss decreased (0.999714 --> 0.997901).  Saving model ...
Validation loss decreased (0.997901 --> 0.996271).  Saving model ...
Validation loss decreased (0.996271 --> 0.995905).  Saving model ...
Validation loss decreased (0.995905 --> 0.994973).  Saving model ...
EarlyStopping counter: 1 out of 3.0
EarlyStopping counter: 2 out of 3.0
Validation loss decreased (0.994973 --> 0.994313).  Saving model ...
EarlyStopping counter: 1 out of 3.0
EarlyStopping counter: 2 out of 3.0
Validation loss decreased (0.994313 --> 0.992573).  Saving model ...
Validation loss decreased (0.992573 --> 0.991352).  Saving model ...
Validation loss decreased (0.991352 --> 0.990469).  Saving model ...
EarlyStopping counter: 1 out of 3.0
EarlyStopping counter: 2 out of 3.0
EarlyStopping counter: 3 out of 3.0
/localscratch/yinan.29785236.0/env/lib/python3.7/site-packages/torch/nn/functional.py:1794: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.
  warnings.warn("nn.functional.tanh is deprecated. Use torch.tanh instead.")
wandb: Waiting for W&B process to finish, PID 50687... (success).
wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: \ 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: | 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: / 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: \ 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: | 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: / 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: \ 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: | 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: / 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: \ 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: | 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb:                                                                                
wandb: Run history:
wandb:     e_F1 ▁▁▂▃▄▅▅▅▆▆▅▅▆▆▆▆▆▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇███████
wandb:   e_loss ██▇▇▇▇▇▆▆▆▅▅▅▄▄▄▄▄▃▃▃▃▃▂▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁
wandb:     t_F1 ▁▁▂▃▃▃▃▄▄▄▅▅▆▅▅▅▆▆▆▆▇▆▆▇▇▇▇▇▇▇▇███████▇█
wandb:   t_loss ████▇▇▇▇▆▆▆▆▅▅▅▅▅▄▄▄▄▃▃▃▃▃▃▂▃▂▂▂▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:     e_F1 56.82932
wandb:   e_loss 0.99119
wandb:     t_F1 68.41084
wandb:   t_loss 0.82082
wandb: 
wandb: Synced 4 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Synced logical-jazz-1: https://wandb.ai/yinanazhou/xl_512_bs_8_lr_1e06_es_3_lc_True_nr_True_sr_True_stem_True_lemma_False_repeat_5_fold_1/runs/1yolzqrf
wandb: Find logs at: ./wandb/run-20220331_170507-1yolzqrf/logs/debug.log
wandb: 

wandb: wandb version 0.12.11 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
2022-03-31 18:28:37.622271: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1
wandb: Tracking run with wandb version 0.12.5
wandb: Syncing run balmy-surf-1
wandb: ⭐️ View project at https://wandb.ai/yinanazhou/xl_512_bs_8_lr_1e06_es_3_lc_True_nr_True_sr_True_stem_True_lemma_False_repeat_5_fold_2
wandb: 🚀 View run at https://wandb.ai/yinanazhou/xl_512_bs_8_lr_1e06_es_3_lc_True_nr_True_sr_True_stem_True_lemma_False_repeat_5_fold_2/runs/1493l7ht
wandb: Run data is saved locally in /project/6002780/yinan/Thesis_MER_Lyrics/lyric-emotion/wandb/run-20220331_182835-1493l7ht
wandb: Run `wandb offline` to turn off syncing.
slurmstepd: error: *** JOB 29785236 ON cdr2642 CANCELLED AT 2022-03-31T19:26:43 ***
