Unloading StdEnv/2020

Due to MODULEPATH changes, the following have been reloaded:
  1) mii/1.1.1


The following have been reloaded with a version change:
  1) python/3.8.2 => python/3.7.4

Using base prefix '/cvmfs/soft.computecanada.ca/easybuild/software/2017/Core/python/3.7.4'
New python executable in /localscratch/yinan.29785229.0/env/bin/python
Installing setuptools, pip, wheel...
done.
Ignoring pip: markers 'python_version < "3"' don't match your environment
Looking in links: /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/nix/avx2, /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/nix/generic, /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic
Collecting pip
Installing collected packages: pip
  Found existing installation: pip 19.1.1
    Uninstalling pip-19.1.1:
      Successfully uninstalled pip-19.1.1
Successfully installed pip-21.2.3+computecanada
Looking in links: /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/nix/avx2, /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/nix/generic, /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/keras-2.8.0+computecanada-py2.py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/Keras_Preprocessing-1.1.2+computecanada-py3-none-any.whl
Requirement already satisfied: matplotlib in /cvmfs/soft.computecanada.ca/easybuild/software/2017/Core/scipy-stack/2019a/lib/python3.7/site-packages (from -r requirements.txt (line 3)) (3.0.2)
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/nltk-3.6.5+computecanada-py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/scikit_learn-0.22.1+computecanada-cp37-cp37m-linux_x86_64.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/tensorboard-2.3.0+computecanada-py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/tensorboard_plugin_wit-1.7.0+computecanada-py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/tensorflow_gpu-2.3.0+computecanada-cp37-cp37m-linux_x86_64.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/tensorflow_estimator-2.3.0+computecanada-py2.py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/tokenizers-0.5.2+computecanada-cp37-cp37m-linux_x86_64.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/nix/avx2/torch-1.4.0+computecanada-cp37-cp37m-linux_x86_64.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/torchtext-0.6.0+computecanada-py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/torchvision-0.8.2+computecanada-cp37-cp37m-linux_x86_64.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/transformers-2.5.1+computecanada-py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/urllib3-1.26.7+computecanada-py2.py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/joblib-1.1.0+computecanada-py2.py3-none-any.whl
ERROR: Could not find a version that satisfies the requirement regex>=2021.8.3 (from nltk) (from versions: 2018.1.10+computecanada, 2019.11.1+computecanada, 2020.11.13+computecanada)
ERROR: No matching distribution found for regex>=2021.8.3
Looking in links: /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/nix/avx2, /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/nix/generic, /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic
ERROR: Could not find a version that satisfies the requirement numpy==1.20.0+computacanada (from versions: 1.15.0+computecanada, 1.15.2+computecanada, 1.15.4+computecanada, 1.16.0+computecanada, 1.16.2+computecanada, 1.16.3+computecanada, 1.17.4+computecanada, 1.18.1+computecanada, 1.18.4+computecanada, 1.19.1+computecanada, 1.19.2+computecanada, 1.20.2+computecanada)
ERROR: No matching distribution found for numpy==1.20.0+computacanada
Looking in links: /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/nix/avx2, /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/nix/generic, /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/wandb-0.12.5+computecanada-py2.py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/six-1.16.0+computecanada-py2.py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/yaspin-2.1.0+computecanada-py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/GitPython-3.1.24+computecanada-py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/protobuf-3.19.4+computecanada-py2.py3-none-any.whl
Requirement already satisfied: python-dateutil>=2.6.1 in /cvmfs/soft.computecanada.ca/easybuild/software/2017/Core/scipy-stack/2019a/lib/python3.7/site-packages (from wandb) (2.7.5)
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/sentry_sdk-1.5.0+computecanada-py2.py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/docker_pycreds-0.4.0+computecanada-py2.py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/shortuuid-1.0.1+computecanada-py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/subprocess32-3.5.4+computecanada-py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/promise-2.3+computecanada-py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/psutil-5.7.3+computecanada-cp37-cp37m-linux_x86_64.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/configparser-5.0.2+computecanada-py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/PyYAML-5.3.1+computecanada-cp37-cp37m-linux_x86_64.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/click-8.1.0+computecanada-py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/pathtools-0.1.2+computecanada-py3-none-any.whl
Requirement already satisfied: requests<3,>=2.0.0 in /cvmfs/soft.computecanada.ca/easybuild/software/2017/Core/scipy-stack/2019a/lib/python3.7/site-packages (from wandb) (2.21.0)
Requirement already satisfied: importlib-metadata in /cvmfs/soft.computecanada.ca/easybuild/software/2017/Core/scipy-stack/2019a/lib/python3.7/site-packages (from Click!=8.0.0,>=7.0->wandb) (0.8)
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/gitdb-4.0.9+computecanada-py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/typing_extensions-4.1.1+computecanada-py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/smmap-5.0.0+computecanada-py3-none-any.whl
Requirement already satisfied: idna<2.9,>=2.5 in /cvmfs/soft.computecanada.ca/easybuild/software/2017/Core/scipy-stack/2019a/lib/python3.7/site-packages (from requests<3,>=2.0.0->wandb) (2.8)
Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /cvmfs/soft.computecanada.ca/easybuild/software/2017/Core/scipy-stack/2019a/lib/python3.7/site-packages (from requests<3,>=2.0.0->wandb) (3.0.4)
Requirement already satisfied: certifi>=2017.4.17 in /cvmfs/soft.computecanada.ca/easybuild/software/2017/Core/scipy-stack/2019a/lib/python3.7/site-packages (from requests<3,>=2.0.0->wandb) (2018.11.29)
Requirement already satisfied: urllib3<1.25,>=1.21.1 in /cvmfs/soft.computecanada.ca/easybuild/software/2017/Core/scipy-stack/2019a/lib/python3.7/site-packages (from requests<3,>=2.0.0->wandb) (1.24.1)
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/termcolor-1.1.0+computecanada-py3-none-any.whl
Requirement already satisfied: zipp>=0.3.2 in /cvmfs/soft.computecanada.ca/easybuild/software/2017/Core/scipy-stack/2019a/lib/python3.7/site-packages (from importlib-metadata->Click!=8.0.0,>=7.0->wandb) (0.3.3)
Installing collected packages: smmap, typing-extensions, termcolor, six, gitdb, yaspin, subprocess32, shortuuid, sentry-sdk, PyYAML, psutil, protobuf, promise, pathtools, GitPython, docker-pycreds, configparser, Click, wandb
  Attempting uninstall: six
    Found existing installation: six 1.12.0
    Not uninstalling six at /cvmfs/soft.computecanada.ca/easybuild/software/2017/Core/scipy-stack/2019a/lib/python3.7/site-packages, outside environment /localscratch/yinan.29785229.0/env
    Can't uninstall 'six'. No files were found to uninstall.
Successfully installed Click-8.1.0+computecanada GitPython-3.1.24+computecanada PyYAML-5.3.1+computecanada configparser-5.0.2+computecanada docker-pycreds-0.4.0+computecanada gitdb-4.0.9+computecanada pathtools-0.1.2+computecanada promise-2.3+computecanada protobuf-3.19.4+computecanada psutil-5.7.3+computecanada sentry-sdk-1.5.0+computecanada shortuuid-1.0.1+computecanada six-1.16.0+computecanada smmap-5.0.0+computecanada subprocess32-3.5.4+computecanada termcolor-1.1.0+computecanada typing-extensions-4.1.1+computecanada wandb-0.12.5+computecanada yaspin-2.1.0+computecanada
Looking in links: /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/nix/avx2, /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/nix/generic, /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic
ERROR: Could not find a version that satisfies the requirement sagemaker (from versions: none)
ERROR: No matching distribution found for sagemaker
Looking in links: /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/nix/avx2, /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/nix/generic, /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/torch-1.9.1+computecanada-cp37-cp37m-linux_x86_64.whl
Requirement already satisfied: typing-extensions in /localscratch/yinan.29785229.0/env/lib/python3.7/site-packages (from torch) (4.1.1+computecanada)
Installing collected packages: torch
Successfully installed torch-1.9.1+computecanada
Looking in links: /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/nix/avx2, /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/nix/generic, /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/transformers-2.5.1+computecanada-py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/regex-2020.11.13+computecanada-cp37-cp37m-linux_x86_64.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/sacremoses-0.0.49+computecanada-py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/tokenizers-0.5.2+computecanada-cp37-cp37m-linux_x86_64.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/boto3-1.21.14+computecanada-py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/filelock-3.4.2+computecanada-py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/tqdm-4.63.1+computecanada-py2.py3-none-any.whl
Requirement already satisfied: numpy in /cvmfs/soft.computecanada.ca/easybuild/software/2017/Core/scipy-stack/2019a/lib/python3.7/site-packages (from transformers==2.5.1+computecanada) (1.16.0)
Requirement already satisfied: requests in /cvmfs/soft.computecanada.ca/easybuild/software/2017/Core/scipy-stack/2019a/lib/python3.7/site-packages (from transformers==2.5.1+computecanada) (2.21.0)
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/sentencepiece-0.1.91+computecanada-cp37-cp37m-linux_x86_64.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/botocore-1.24.14+computecanada-py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/s3transfer-0.5.1+computecanada-py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/jmespath-0.10.0+computecanada-py2.py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/urllib3-1.26.9+computecanada-py2.py3-none-any.whl
Requirement already satisfied: python-dateutil<3.0.0,>=2.1 in /cvmfs/soft.computecanada.ca/easybuild/software/2017/Core/scipy-stack/2019a/lib/python3.7/site-packages (from botocore<1.25.0,>=1.24.14->boto3->transformers==2.5.1+computecanada) (2.7.5)
Requirement already satisfied: six>=1.5 in /localscratch/yinan.29785229.0/env/lib/python3.7/site-packages (from python-dateutil<3.0.0,>=2.1->botocore<1.25.0,>=1.24.14->boto3->transformers==2.5.1+computecanada) (1.16.0+computecanada)
Requirement already satisfied: idna<2.9,>=2.5 in /cvmfs/soft.computecanada.ca/easybuild/software/2017/Core/scipy-stack/2019a/lib/python3.7/site-packages (from requests->transformers==2.5.1+computecanada) (2.8)
Requirement already satisfied: certifi>=2017.4.17 in /cvmfs/soft.computecanada.ca/easybuild/software/2017/Core/scipy-stack/2019a/lib/python3.7/site-packages (from requests->transformers==2.5.1+computecanada) (2018.11.29)
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/requests-2.27.1+computecanada-py2.py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/charset_normalizer-2.0.12+computecanada-py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/joblib-1.1.0+computecanada-py2.py3-none-any.whl
Requirement already satisfied: click in /localscratch/yinan.29785229.0/env/lib/python3.7/site-packages (from sacremoses->transformers==2.5.1+computecanada) (8.1.0+computecanada)
Requirement already satisfied: importlib-metadata in /cvmfs/soft.computecanada.ca/easybuild/software/2017/Core/scipy-stack/2019a/lib/python3.7/site-packages (from click->sacremoses->transformers==2.5.1+computecanada) (0.8)
Requirement already satisfied: zipp>=0.3.2 in /cvmfs/soft.computecanada.ca/easybuild/software/2017/Core/scipy-stack/2019a/lib/python3.7/site-packages (from importlib-metadata->click->sacremoses->transformers==2.5.1+computecanada) (0.3.3)
Installing collected packages: urllib3, jmespath, botocore, tqdm, s3transfer, regex, joblib, charset-normalizer, tokenizers, sentencepiece, sacremoses, requests, filelock, boto3, transformers
  Attempting uninstall: urllib3
    Found existing installation: urllib3 1.24.1
    Not uninstalling urllib3 at /cvmfs/soft.computecanada.ca/easybuild/software/2017/Core/scipy-stack/2019a/lib/python3.7/site-packages, outside environment /localscratch/yinan.29785229.0/env
    Can't uninstall 'urllib3'. No files were found to uninstall.
  Attempting uninstall: requests
    Found existing installation: requests 2.21.0
    Not uninstalling requests at /cvmfs/soft.computecanada.ca/easybuild/software/2017/Core/scipy-stack/2019a/lib/python3.7/site-packages, outside environment /localscratch/yinan.29785229.0/env
    Can't uninstall 'requests'. No files were found to uninstall.
Successfully installed boto3-1.21.14+computecanada botocore-1.24.14+computecanada charset-normalizer-2.0.12+computecanada filelock-3.4.2+computecanada jmespath-0.10.0+computecanada joblib-1.1.0+computecanada regex-2020.11.13+computecanada requests-2.27.1+computecanada s3transfer-0.5.1+computecanada sacremoses-0.0.49+computecanada sentencepiece-0.1.91+computecanada tokenizers-0.5.2+computecanada tqdm-4.63.1+computecanada transformers-2.5.1+computecanada urllib3-1.26.9+computecanada
Looking in links: /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/nix/avx2, /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/nix/generic, /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/tensorflow_gpu-2.3.0+computecanada-cp37-cp37m-linux_x86_64.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/Keras_Preprocessing-1.1.2+computecanada-py3-none-any.whl
Requirement already satisfied: protobuf>=3.9.2 in /localscratch/yinan.29785229.0/env/lib/python3.7/site-packages (from tensorflow_gpu==2.3.0+computecanada) (3.19.4+computecanada)
Requirement already satisfied: six>=1.12.0 in /localscratch/yinan.29785229.0/env/lib/python3.7/site-packages (from tensorflow_gpu==2.3.0+computecanada) (1.16.0+computecanada)
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/wrapt-1.11.2+computecanada-cp37-cp37m-linux_x86_64.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/google_pasta-0.2.0+computecanada-py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/tensorflow_estimator-2.3.0+computecanada-py2.py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/astunparse-1.6.3+computecanada-py2.py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/grpcio-1.38.0+computecanada-cp37-cp37m-linux_x86_64.whl
Requirement already satisfied: numpy<1.19.0,>=1.16.0 in /cvmfs/soft.computecanada.ca/easybuild/software/2017/Core/scipy-stack/2019a/lib/python3.7/site-packages (from tensorflow_gpu==2.3.0+computecanada) (1.16.0)
Requirement already satisfied: termcolor>=1.1.0 in /localscratch/yinan.29785229.0/env/lib/python3.7/site-packages (from tensorflow_gpu==2.3.0+computecanada) (1.1.0+computecanada)
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/nix/generic/scipy-1.4.1+computecanada-cp37-cp37m-linux_x86_64.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/absl_py-1.0.0+computecanada-py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/opt_einsum-3.3.0+computecanada-py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/gast-0.3.3+computecanada-py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/nix/avx2/h5py-2.10.0+computecanada-cp37-cp37m-linux_x86_64.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/tensorboard-2.8.0+computecanada-py3-none-any.whl
Requirement already satisfied: wheel>=0.26 in /localscratch/yinan.29785229.0/env/lib/python3.7/site-packages (from tensorflow_gpu==2.3.0+computecanada) (0.33.4)
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/google_auth-2.3.3+computecanada-py2.py3-none-any.whl
Requirement already satisfied: requests<3,>=2.21.0 in /localscratch/yinan.29785229.0/env/lib/python3.7/site-packages (from tensorboard<3,>=2.3.0->tensorflow_gpu==2.3.0+computecanada) (2.27.1+computecanada)
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/tensorboard_plugin_wit-1.8.0+computecanada-py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/google_auth_oauthlib-0.4.6+computecanada-py2.py3-none-any.whl
Requirement already satisfied: setuptools>=41.0.0 in /localscratch/yinan.29785229.0/env/lib/python3.7/site-packages (from tensorboard<3,>=2.3.0->tensorflow_gpu==2.3.0+computecanada) (41.0.1)
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/tensorboard_data_server-0.6.1+computecanada-py3-none-linux_x86_64.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/Markdown-3.3.6+computecanada-py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/Werkzeug-2.0.3+computecanada-py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/rsa-4.8+computecanada-py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/pyasn1_modules-0.2.8+computecanada-py2.py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/cachetools-4.2.4+computecanada-py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/requests_oauthlib-1.3.0+computecanada-py2.py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/importlib_metadata-4.10.1+computecanada-py3-none-any.whl
Requirement already satisfied: typing-extensions>=3.6.4 in /localscratch/yinan.29785229.0/env/lib/python3.7/site-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard<3,>=2.3.0->tensorflow_gpu==2.3.0+computecanada) (4.1.1+computecanada)
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/zipp-3.7.0+computecanada-py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/pyasn1-0.4.8+computecanada-py2.py3-none-any.whl
Requirement already satisfied: certifi>=2017.4.17 in /cvmfs/soft.computecanada.ca/easybuild/software/2017/Core/scipy-stack/2019a/lib/python3.7/site-packages (from requests<3,>=2.21.0->tensorboard<3,>=2.3.0->tensorflow_gpu==2.3.0+computecanada) (2018.11.29)
Requirement already satisfied: urllib3<1.27,>=1.21.1 in /localscratch/yinan.29785229.0/env/lib/python3.7/site-packages (from requests<3,>=2.21.0->tensorboard<3,>=2.3.0->tensorflow_gpu==2.3.0+computecanada) (1.26.9+computecanada)
Requirement already satisfied: idna<4,>=2.5 in /cvmfs/soft.computecanada.ca/easybuild/software/2017/Core/scipy-stack/2019a/lib/python3.7/site-packages (from requests<3,>=2.21.0->tensorboard<3,>=2.3.0->tensorflow_gpu==2.3.0+computecanada) (2.8)
Requirement already satisfied: charset-normalizer~=2.0.0 in /localscratch/yinan.29785229.0/env/lib/python3.7/site-packages (from requests<3,>=2.21.0->tensorboard<3,>=2.3.0->tensorflow_gpu==2.3.0+computecanada) (2.0.12+computecanada)
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/oauthlib-3.1.1+computecanada-py2.py3-none-any.whl
Installing collected packages: pyasn1, zipp, rsa, pyasn1-modules, oauthlib, cachetools, requests-oauthlib, importlib-metadata, google-auth, werkzeug, tensorboard-plugin-wit, tensorboard-data-server, markdown, grpcio, google-auth-oauthlib, absl-py, wrapt, tensorflow-estimator, tensorboard, scipy, opt-einsum, keras-preprocessing, h5py, google-pasta, gast, astunparse, tensorflow-gpu
  Attempting uninstall: pyasn1
    Found existing installation: pyasn1 0.4.3
    Not uninstalling pyasn1 at /cvmfs/soft.computecanada.ca/easybuild/software/2017/Core/scipy-stack/2019a/lib/python3.7/site-packages, outside environment /localscratch/yinan.29785229.0/env
    Can't uninstall 'pyasn1'. No files were found to uninstall.
  Attempting uninstall: zipp
    Found existing installation: zipp 0.3.3
    Not uninstalling zipp at /cvmfs/soft.computecanada.ca/easybuild/software/2017/Core/scipy-stack/2019a/lib/python3.7/site-packages, outside environment /localscratch/yinan.29785229.0/env
    Can't uninstall 'zipp'. No files were found to uninstall.
  Attempting uninstall: importlib-metadata
    Found existing installation: importlib-metadata 0.8
    Not uninstalling importlib-metadata at /cvmfs/soft.computecanada.ca/easybuild/software/2017/Core/scipy-stack/2019a/lib/python3.7/site-packages, outside environment /localscratch/yinan.29785229.0/env
    Can't uninstall 'importlib-metadata'. No files were found to uninstall.
  Attempting uninstall: scipy
    Found existing installation: scipy 1.2.0
    Not uninstalling scipy at /cvmfs/soft.computecanada.ca/easybuild/software/2017/Core/scipy-stack/2019a/lib/python3.7/site-packages, outside environment /localscratch/yinan.29785229.0/env
    Can't uninstall 'scipy'. No files were found to uninstall.
Successfully installed absl-py-1.0.0+computecanada astunparse-1.6.3+computecanada cachetools-4.2.4+computecanada gast-0.3.3+computecanada google-auth-2.3.3+computecanada google-auth-oauthlib-0.4.6+computecanada google-pasta-0.2.0+computecanada grpcio-1.38.0+computecanada h5py-2.10.0+computecanada importlib-metadata-4.10.1+computecanada keras-preprocessing-1.1.2+computecanada markdown-3.3.6+computecanada oauthlib-3.1.1+computecanada opt-einsum-3.3.0+computecanada pyasn1-0.4.8+computecanada pyasn1-modules-0.2.8+computecanada requests-oauthlib-1.3.0+computecanada rsa-4.8+computecanada scipy-1.4.1+computecanada tensorboard-2.8.0+computecanada tensorboard-data-server-0.6.1+computecanada tensorboard-plugin-wit-1.8.0+computecanada tensorflow-estimator-2.3.0+computecanada tensorflow-gpu-2.3.0+computecanada werkzeug-2.0.3+computecanada wrapt-1.11.2+computecanada zipp-3.7.0+computecanada
Looking in links: /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/nix/avx2, /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/nix/generic, /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/keras-2.8.0+computecanada-py2.py3-none-any.whl
Installing collected packages: Keras
Successfully installed Keras-2.8.0+computecanada
Looking in links: /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/nix/avx2, /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/nix/generic, /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/urllib3-1.26.7+computecanada-py2.py3-none-any.whl
Installing collected packages: urllib3
  Attempting uninstall: urllib3
    Found existing installation: urllib3 1.26.9+computecanada
    Uninstalling urllib3-1.26.9+computecanada:
      Successfully uninstalled urllib3-1.26.9+computecanada
Successfully installed urllib3-1.26.7+computecanada
Looking in links: /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/nix/avx2, /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/nix/generic, /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/nltk-3.7+computecanada-py3-none-any.whl
Requirement already satisfied: tqdm in /localscratch/yinan.29785229.0/env/lib/python3.7/site-packages (from nltk) (4.63.1+computecanada)
Requirement already satisfied: joblib in /localscratch/yinan.29785229.0/env/lib/python3.7/site-packages (from nltk) (1.1.0+computecanada)
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/nltk-3.6.5+computecanada-py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/nltk-3.6.3+computecanada-py3-none-any.whl
Requirement already satisfied: regex in /localscratch/yinan.29785229.0/env/lib/python3.7/site-packages (from nltk) (2020.11.13+computecanada)
Requirement already satisfied: click in /localscratch/yinan.29785229.0/env/lib/python3.7/site-packages (from nltk) (8.1.0+computecanada)
Requirement already satisfied: importlib-metadata in /localscratch/yinan.29785229.0/env/lib/python3.7/site-packages (from click->nltk) (4.10.1+computecanada)
Requirement already satisfied: zipp>=0.5 in /localscratch/yinan.29785229.0/env/lib/python3.7/site-packages (from importlib-metadata->click->nltk) (3.7.0+computecanada)
Requirement already satisfied: typing-extensions>=3.6.4 in /localscratch/yinan.29785229.0/env/lib/python3.7/site-packages (from importlib-metadata->click->nltk) (4.1.1+computecanada)
Installing collected packages: nltk
Successfully installed nltk-3.6.3+computecanada
Looking in links: /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/nix/avx2, /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/nix/generic, /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/scikit_learn-0.22.1+computecanada-cp37-cp37m-linux_x86_64.whl
Requirement already satisfied: scipy>=0.17.0 in /localscratch/yinan.29785229.0/env/lib/python3.7/site-packages (from scikit-learn==0.22.1) (1.4.1+computecanada)
Requirement already satisfied: joblib>=0.11 in /localscratch/yinan.29785229.0/env/lib/python3.7/site-packages (from scikit-learn==0.22.1) (1.1.0+computecanada)
Requirement already satisfied: numpy>=1.11.0 in /cvmfs/soft.computecanada.ca/easybuild/software/2017/Core/scipy-stack/2019a/lib/python3.7/site-packages (from scikit-learn==0.22.1) (1.16.0)
Installing collected packages: scikit-learn
Successfully installed scikit-learn-0.22.1+computecanada
Looking in links: /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/nix/avx2, /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/nix/generic, /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic
Requirement already satisfied: tokenizers==0.5.2 in /localscratch/yinan.29785229.0/env/lib/python3.7/site-packages (0.5.2+computecanada)
wandb: Appending key for api.wandb.ai to your netrc file: /home/yinan/.netrc
Starting Task
2022-03-31 05:09:45.792367: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1
[nltk_data] Downloading package stopwords to /home/yinan/nltk_data...
[nltk_data]   Package stopwords is already up-to-date!
[nltk_data] Downloading package wordnet to /home/yinan/nltk_data...
[nltk_data]   Package wordnet is already up-to-date!
wandb: Currently logged in as: yinanazhou (use `wandb login --relogin` to force relogin)
wandb: wandb version 0.12.11 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
2022-03-31 05:09:56.251372: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1
wandb: Tracking run with wandb version 0.12.5
wandb: Syncing run zesty-gorge-2
wandb: ⭐️ View project at https://wandb.ai/yinanazhou/xl_512_bs_8_lr_1e06_es_3_lc_True_nr_True_sr_True_stem_False_lemma_False_repeat_1_fold_1
wandb: 🚀 View run at https://wandb.ai/yinanazhou/xl_512_bs_8_lr_1e06_es_3_lc_True_nr_True_sr_True_stem_False_lemma_False_repeat_1_fold_1/runs/39upwgl2
wandb: Run data is saved locally in /project/6002780/yinan/Thesis_MER_Lyrics/lyric-emotion/wandb/run-20220331_050954-39upwgl2
wandb: Run `wandb offline` to turn off syncing.

Validation loss decreased (inf --> 1.441675).  Saving model ...
Validation loss decreased (1.441675 --> 1.423186).  Saving model ...
Validation loss decreased (1.423186 --> 1.407739).  Saving model ...
Validation loss decreased (1.407739 --> 1.395278).  Saving model ...
Validation loss decreased (1.395278 --> 1.385952).  Saving model ...
Validation loss decreased (1.385952 --> 1.378015).  Saving model ...
Validation loss decreased (1.378015 --> 1.372319).  Saving model ...
Validation loss decreased (1.372319 --> 1.367101).  Saving model ...
Validation loss decreased (1.367101 --> 1.362449).  Saving model ...
Validation loss decreased (1.362449 --> 1.357497).  Saving model ...
Validation loss decreased (1.357497 --> 1.352490).  Saving model ...
Validation loss decreased (1.352490 --> 1.347691).  Saving model ...
Validation loss decreased (1.347691 --> 1.342970).  Saving model ...
Validation loss decreased (1.342970 --> 1.338242).  Saving model ...
Validation loss decreased (1.338242 --> 1.333882).  Saving model ...
Validation loss decreased (1.333882 --> 1.329833).  Saving model ...
Validation loss decreased (1.329833 --> 1.325409).  Saving model ...
Validation loss decreased (1.325409 --> 1.320543).  Saving model ...
Validation loss decreased (1.320543 --> 1.315317).  Saving model ...
Validation loss decreased (1.315317 --> 1.310341).  Saving model ...
Validation loss decreased (1.310341 --> 1.305684).  Saving model ...
Validation loss decreased (1.305684 --> 1.300396).  Saving model ...
Validation loss decreased (1.300396 --> 1.296148).  Saving model ...
Validation loss decreased (1.296148 --> 1.290671).  Saving model ...
Validation loss decreased (1.290671 --> 1.285830).  Saving model ...
Validation loss decreased (1.285830 --> 1.281224).  Saving model ...
Validation loss decreased (1.281224 --> 1.277315).  Saving model ...
Validation loss decreased (1.277315 --> 1.275066).  Saving model ...
Validation loss decreased (1.275066 --> 1.273085).  Saving model ...
Validation loss decreased (1.273085 --> 1.270585).  Saving model ...
Validation loss decreased (1.270585 --> 1.266308).  Saving model ...
Validation loss decreased (1.266308 --> 1.261046).  Saving model ...
Validation loss decreased (1.261046 --> 1.259798).  Saving model ...
Validation loss decreased (1.259798 --> 1.253288).  Saving model ...
Validation loss decreased (1.253288 --> 1.252226).  Saving model ...
Validation loss decreased (1.252226 --> 1.247537).  Saving model ...
Validation loss decreased (1.247537 --> 1.244679).  Saving model ...
Validation loss decreased (1.244679 --> 1.239517).  Saving model ...
Validation loss decreased (1.239517 --> 1.237540).  Saving model ...
Validation loss decreased (1.237540 --> 1.237170).  Saving model ...
Validation loss decreased (1.237170 --> 1.230621).  Saving model ...
Validation loss decreased (1.230621 --> 1.227196).  Saving model ...
Validation loss decreased (1.227196 --> 1.226575).  Saving model ...
Validation loss decreased (1.226575 --> 1.221086).  Saving model ...
Validation loss decreased (1.221086 --> 1.220941).  Saving model ...
Validation loss decreased (1.220941 --> 1.218210).  Saving model ...
Validation loss decreased (1.218210 --> 1.216324).  Saving model ...
Validation loss decreased (1.216324 --> 1.214311).  Saving model ...
Validation loss decreased (1.214311 --> 1.210619).  Saving model ...
Validation loss decreased (1.210619 --> 1.205541).  Saving model ...
Validation loss decreased (1.205541 --> 1.201404).  Saving model ...
Validation loss decreased (1.201404 --> 1.197768).  Saving model ...
Validation loss decreased (1.197768 --> 1.195982).  Saving model ...
Validation loss decreased (1.195982 --> 1.191534).  Saving model ...
EarlyStopping counter: 1 out of 3.0
Validation loss decreased (1.191534 --> 1.189415).  Saving model ...
Validation loss decreased (1.189415 --> 1.188133).  Saving model ...
Validation loss decreased (1.188133 --> 1.184564).  Saving model ...
Validation loss decreased (1.184564 --> 1.178266).  Saving model ...
Validation loss decreased (1.178266 --> 1.178206).  Saving model ...
Validation loss decreased (1.178206 --> 1.173006).  Saving model ...
EarlyStopping counter: 1 out of 3.0
Validation loss decreased (1.173006 --> 1.170363).  Saving model ...
Validation loss decreased (1.170363 --> 1.168316).  Saving model ...
Validation loss decreased (1.168316 --> 1.166168).  Saving model ...
Validation loss decreased (1.166168 --> 1.161845).  Saving model ...
Validation loss decreased (1.161845 --> 1.159450).  Saving model ...
Validation loss decreased (1.159450 --> 1.155724).  Saving model ...
Validation loss decreased (1.155724 --> 1.154208).  Saving model ...
Validation loss decreased (1.154208 --> 1.152667).  Saving model ...
Validation loss decreased (1.152667 --> 1.149243).  Saving model ...
Validation loss decreased (1.149243 --> 1.147071).  Saving model ...
Validation loss decreased (1.147071 --> 1.145694).  Saving model ...
Validation loss decreased (1.145694 --> 1.140263).  Saving model ...
Validation loss decreased (1.140263 --> 1.134228).  Saving model ...
Validation loss decreased (1.134228 --> 1.133849).  Saving model ...
EarlyStopping counter: 1 out of 3.0
Validation loss decreased (1.133849 --> 1.133062).  Saving model ...
Validation loss decreased (1.133062 --> 1.128384).  Saving model ...
Validation loss decreased (1.128384 --> 1.120717).  Saving model ...
EarlyStopping counter: 1 out of 3.0
EarlyStopping counter: 2 out of 3.0
EarlyStopping counter: 3 out of 3.0
/localscratch/yinan.29785229.0/env/lib/python3.7/site-packages/torch/nn/functional.py:1794: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.
  warnings.warn("nn.functional.tanh is deprecated. Use torch.tanh instead.")
/localscratch/yinan.29785229.0/env/lib/python3.7/site-packages/transformers/optimization.py:155: UserWarning: This overload of add_ is deprecated:
	add_(Number alpha, Tensor other)
Consider using one of the following signatures instead:
	add_(Tensor other, *, Number alpha) (Triggered internally at  ../torch/csrc/utils/python_arg_parser.cpp:1025.)
  exp_avg.mul_(beta1).add_(1.0 - beta1, grad)
wandb: Waiting for W&B process to finish, PID 143494... (success).
wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: \ 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: | 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: / 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: \ 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: | 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: / 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: \ 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: | 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: / 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: \ 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: | 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: / 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: \ 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: | 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb:                                                                                
wandb: Run history:
wandb:     e_F1 ▁▂▃▃▄▄▄▅▅▅▅▅▅▅▆▆▆▆▆▆▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇████
wandb:   e_loss █▇▇▆▆▆▆▆▅▅▅▅▅▄▄▄▄▄▄▄▃▃▃▃▃▃▃▂▂▂▂▂▂▂▂▁▁▁▁▁
wandb:     t_F1 ▁▂▂▃▃▃▃▃▄▄▅▅▅▅▅▅▆▆▆▆▆▆▇▇▇▇▇▇▇▇▇█▇▇▇█▇███
wandb:   t_loss ██▇▇▇▇▇▇▆▆▆▅▅▅▅▄▄▄▄▄▄▃▃▃▃▃▂▃▂▂▂▂▂▂▂▁▂▁▁▁
wandb: 
wandb: Run summary:
wandb:     e_F1 49.0674
wandb:   e_loss 1.12212
wandb:     t_F1 61.90194
wandb:   t_loss 0.93146
wandb: 
wandb: Synced 4 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Synced zesty-gorge-2: https://wandb.ai/yinanazhou/xl_512_bs_8_lr_1e06_es_3_lc_True_nr_True_sr_True_stem_False_lemma_False_repeat_1_fold_1/runs/39upwgl2
wandb: Find logs at: ./wandb/run-20220331_050954-39upwgl2/logs/debug.log
wandb: 

wandb: wandb version 0.12.11 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
2022-03-31 06:05:07.802865: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1
wandb: Tracking run with wandb version 0.12.5
wandb: Syncing run usual-pond-2
wandb: ⭐️ View project at https://wandb.ai/yinanazhou/xl_512_bs_8_lr_1e06_es_3_lc_True_nr_True_sr_True_stem_False_lemma_False_repeat_1_fold_2
wandb: 🚀 View run at https://wandb.ai/yinanazhou/xl_512_bs_8_lr_1e06_es_3_lc_True_nr_True_sr_True_stem_False_lemma_False_repeat_1_fold_2/runs/vedft6a0
wandb: Run data is saved locally in /project/6002780/yinan/Thesis_MER_Lyrics/lyric-emotion/wandb/run-20220331_060505-vedft6a0
wandb: Run `wandb offline` to turn off syncing.

Validation loss decreased (inf --> 1.478515).  Saving model ...
Validation loss decreased (1.478515 --> 1.447532).  Saving model ...
Validation loss decreased (1.447532 --> 1.423084).  Saving model ...
Validation loss decreased (1.423084 --> 1.405793).  Saving model ...
Validation loss decreased (1.405793 --> 1.394162).  Saving model ...
Validation loss decreased (1.394162 --> 1.385212).  Saving model ...
Validation loss decreased (1.385212 --> 1.377852).  Saving model ...
Validation loss decreased (1.377852 --> 1.371233).  Saving model ...
Validation loss decreased (1.371233 --> 1.365350).  Saving model ...
Validation loss decreased (1.365350 --> 1.360361).  Saving model ...
Validation loss decreased (1.360361 --> 1.356131).  Saving model ...
Validation loss decreased (1.356131 --> 1.351330).  Saving model ...
Validation loss decreased (1.351330 --> 1.347120).  Saving model ...
Validation loss decreased (1.347120 --> 1.342436).  Saving model ...
Validation loss decreased (1.342436 --> 1.338277).  Saving model ...
Validation loss decreased (1.338277 --> 1.333564).  Saving model ...
Validation loss decreased (1.333564 --> 1.328860).  Saving model ...
Validation loss decreased (1.328860 --> 1.323723).  Saving model ...
Validation loss decreased (1.323723 --> 1.319268).  Saving model ...
Validation loss decreased (1.319268 --> 1.314398).  Saving model ...
Validation loss decreased (1.314398 --> 1.309014).  Saving model ...
Validation loss decreased (1.309014 --> 1.303844).  Saving model ...
Validation loss decreased (1.303844 --> 1.298000).  Saving model ...
Validation loss decreased (1.298000 --> 1.291377).  Saving model ...
Validation loss decreased (1.291377 --> 1.286441).  Saving model ...
Validation loss decreased (1.286441 --> 1.281733).  Saving model ...
Validation loss decreased (1.281733 --> 1.275646).  Saving model ...
Validation loss decreased (1.275646 --> 1.269128).  Saving model ...
Validation loss decreased (1.269128 --> 1.262462).  Saving model ...
Validation loss decreased (1.262462 --> 1.255001).  Saving model ...
Validation loss decreased (1.255001 --> 1.248986).  Saving model ...
Validation loss decreased (1.248986 --> 1.242479).  Saving model ...
Validation loss decreased (1.242479 --> 1.234984).  Saving model ...
Validation loss decreased (1.234984 --> 1.228794).  Saving model ...
Validation loss decreased (1.228794 --> 1.222577).  Saving model ...
Validation loss decreased (1.222577 --> 1.216465).  Saving model ...
Validation loss decreased (1.216465 --> 1.210011).  Saving model ...
Validation loss decreased (1.210011 --> 1.203715).  Saving model ...
Validation loss decreased (1.203715 --> 1.197003).  Saving model ...
Validation loss decreased (1.197003 --> 1.190656).  Saving model ...
Validation loss decreased (1.190656 --> 1.184903).  Saving model ...
Validation loss decreased (1.184903 --> 1.178307).  Saving model ...
Validation loss decreased (1.178307 --> 1.172254).  Saving model ...
Validation loss decreased (1.172254 --> 1.165808).  Saving model ...
Validation loss decreased (1.165808 --> 1.160383).  Saving model ...
Validation loss decreased (1.160383 --> 1.154787).  Saving model ...
Validation loss decreased (1.154787 --> 1.148587).  Saving model ...
Validation loss decreased (1.148587 --> 1.143804).  Saving model ...
Validation loss decreased (1.143804 --> 1.137265).  Saving model ...
Validation loss decreased (1.137265 --> 1.131047).  Saving model ...
Validation loss decreased (1.131047 --> 1.124901).  Saving model ...
Validation loss decreased (1.124901 --> 1.118825).  Saving model ...
Validation loss decreased (1.118825 --> 1.112788).  Saving model ...
Validation loss decreased (1.112788 --> 1.107817).  Saving model ...
Validation loss decreased (1.107817 --> 1.102290).  Saving model ...
Validation loss decreased (1.102290 --> 1.096836).  Saving model ...
Validation loss decreased (1.096836 --> 1.093061).  Saving model ...
Validation loss decreased (1.093061 --> 1.087481).  Saving model ...
Validation loss decreased (1.087481 --> 1.081823).  Saving model ...
Validation loss decreased (1.081823 --> 1.076672).  Saving model ...
Validation loss decreased (1.076672 --> 1.073323).  Saving model ...
Validation loss decreased (1.073323 --> 1.069869).  Saving model ...
Validation loss decreased (1.069869 --> 1.065823).  Saving model ...
Validation loss decreased (1.065823 --> 1.064184).  Saving model ...
Validation loss decreased (1.064184 --> 1.056781).  Saving model ...
Validation loss decreased (1.056781 --> 1.052839).  Saving model ...
Validation loss decreased (1.052839 --> 1.048210).  Saving model ...
Validation loss decreased (1.048210 --> 1.043651).  Saving model ...
Validation loss decreased (1.043651 --> 1.039201).  Saving model ...
Validation loss decreased (1.039201 --> 1.036477).  Saving model ...
Validation loss decreased (1.036477 --> 1.030956).  Saving model ...
Validation loss decreased (1.030956 --> 1.027494).  Saving model ...
Validation loss decreased (1.027494 --> 1.020911).  Saving model ...
Validation loss decreased (1.020911 --> 1.017791).  Saving model ...
Validation loss decreased (1.017791 --> 1.015497).  Saving model ...
Validation loss decreased (1.015497 --> 1.010895).  Saving model ...
Validation loss decreased (1.010895 --> 1.007746).  Saving model ...
Validation loss decreased (1.007746 --> 1.003485).  Saving model ...
Validation loss decreased (1.003485 --> 1.000571).  Saving model ...
Validation loss decreased (1.000571 --> 0.997584).  Saving model ...
Validation loss decreased (0.997584 --> 0.994525).  Saving model ...
Validation loss decreased (0.994525 --> 0.990859).  Saving model ...
Validation loss decreased (0.990859 --> 0.988482).  Saving model ...
Validation loss decreased (0.988482 --> 0.986231).  Saving model ...
Validation loss decreased (0.986231 --> 0.985452).  Saving model ...
Validation loss decreased (0.985452 --> 0.983171).  Saving model ...
Validation loss decreased (0.983171 --> 0.979861).  Saving model ...
Validation loss decreased (0.979861 --> 0.977412).  Saving model ...
Validation loss decreased (0.977412 --> 0.973454).  Saving model ...
Validation loss decreased (0.973454 --> 0.970807).  Saving model ...
Validation loss decreased (0.970807 --> 0.968122).  Saving model ...
Validation loss decreased (0.968122 --> 0.965399).  Saving model ...
Validation loss decreased (0.965399 --> 0.963348).  Saving model ...
Validation loss decreased (0.963348 --> 0.960398).  Saving model ...
Validation loss decreased (0.960398 --> 0.958072).  Saving model ...
Validation loss decreased (0.958072 --> 0.955645).  Saving model ...
Validation loss decreased (0.955645 --> 0.954850).  Saving model ...
Validation loss decreased (0.954850 --> 0.952907).  Saving model ...
Validation loss decreased (0.952907 --> 0.950490).  Saving model ...
Validation loss decreased (0.950490 --> 0.949214).  Saving model ...
Validation loss decreased (0.949214 --> 0.947417).  Saving model ...
Validation loss decreased (0.947417 --> 0.943593).  Saving model ...
Validation loss decreased (0.943593 --> 0.942041).  Saving model ...
Validation loss decreased (0.942041 --> 0.941158).  Saving model ...
Validation loss decreased (0.941158 --> 0.940652).  Saving model ...
Validation loss decreased (0.940652 --> 0.939230).  Saving model ...
Validation loss decreased (0.939230 --> 0.937350).  Saving model ...
Validation loss decreased (0.937350 --> 0.936871).  Saving model ...
Validation loss decreased (0.936871 --> 0.934878).  Saving model ...
Validation loss decreased (0.934878 --> 0.934428).  Saving model ...
Validation loss decreased (0.934428 --> 0.932266).  Saving model ...
Validation loss decreased (0.932266 --> 0.931679).  Saving model ...
Validation loss decreased (0.931679 --> 0.929327).  Saving model ...
Validation loss decreased (0.929327 --> 0.928064).  Saving model ...
Validation loss decreased (0.928064 --> 0.926477).  Saving model ...
Validation loss decreased (0.926477 --> 0.925345).  Saving model ...
Validation loss decreased (0.925345 --> 0.924792).  Saving model ...
Validation loss decreased (0.924792 --> 0.924448).  Saving model ...
EarlyStopping counter: 1 out of 3.0
Validation loss decreased (0.924448 --> 0.923201).  Saving model ...
EarlyStopping counter: 1 out of 3.0
EarlyStopping counter: 2 out of 3.0
Validation loss decreased (0.923201 --> 0.921036).  Saving model ...
EarlyStopping counter: 1 out of 3.0
EarlyStopping counter: 2 out of 3.0
EarlyStopping counter: 3 out of 3.0
/localscratch/yinan.29785229.0/env/lib/python3.7/site-packages/torch/nn/functional.py:1794: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.
  warnings.warn("nn.functional.tanh is deprecated. Use torch.tanh instead.")
wandb: Waiting for W&B process to finish, PID 146485... (success).
wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: \ 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: | 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: / 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: \ 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: | 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: / 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: \ 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: | 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: / 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb:                                                                                
wandb: Run history:
wandb:     e_F1 ▁▁▂▄▄▄▅▅▆▆▆▆▇▇▇▇▇▇▇▇▇▇▇█████████████████
wandb:   e_loss █▇▇▇▆▆▆▆▆▅▅▅▄▄▄▄▃▃▃▃▃▃▂▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁
wandb:     t_F1 ▁▁▂▃▃▃▄▃▄▄▄▅▅▅▆▅▆▆▆▆▆▆▇▇▆▇▇▆█▇▇▇██▇█████
wandb:   t_loss █▇▇▇▇▆▆▆▆▆▆▅▅▅▅▅▄▄▄▄▄▄▃▃▃▃▃▃▂▂▂▂▂▂▂▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:     e_F1 59.94121
wandb:   e_loss 0.92155
wandb:     t_F1 70.59113
wandb:   t_loss 0.83256
wandb: 
wandb: Synced 4 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Synced usual-pond-2: https://wandb.ai/yinanazhou/xl_512_bs_8_lr_1e06_es_3_lc_True_nr_True_sr_True_stem_False_lemma_False_repeat_1_fold_2/runs/vedft6a0
wandb: Find logs at: ./wandb/run-20220331_060505-vedft6a0/logs/debug.log
wandb: 

wandb: wandb version 0.12.11 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
2022-03-31 07:26:29.710204: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1
wandb: Tracking run with wandb version 0.12.5
wandb: Syncing run sage-voice-2
wandb: ⭐️ View project at https://wandb.ai/yinanazhou/xl_512_bs_8_lr_1e06_es_3_lc_True_nr_True_sr_True_stem_False_lemma_False_repeat_2_fold_1
wandb: 🚀 View run at https://wandb.ai/yinanazhou/xl_512_bs_8_lr_1e06_es_3_lc_True_nr_True_sr_True_stem_False_lemma_False_repeat_2_fold_1/runs/2q6lz0mn
wandb: Run data is saved locally in /project/6002780/yinan/Thesis_MER_Lyrics/lyric-emotion/wandb/run-20220331_072626-2q6lz0mn
wandb: Run `wandb offline` to turn off syncing.

Validation loss decreased (inf --> 1.415362).  Saving model ...
Validation loss decreased (1.415362 --> 1.403217).  Saving model ...
Validation loss decreased (1.403217 --> 1.393162).  Saving model ...
Validation loss decreased (1.393162 --> 1.385286).  Saving model ...
Validation loss decreased (1.385286 --> 1.378459).  Saving model ...
Validation loss decreased (1.378459 --> 1.373258).  Saving model ...
Validation loss decreased (1.373258 --> 1.368226).  Saving model ...
Validation loss decreased (1.368226 --> 1.363237).  Saving model ...
Validation loss decreased (1.363237 --> 1.358489).  Saving model ...
Validation loss decreased (1.358489 --> 1.354290).  Saving model ...
Validation loss decreased (1.354290 --> 1.349815).  Saving model ...
Validation loss decreased (1.349815 --> 1.345872).  Saving model ...
Validation loss decreased (1.345872 --> 1.341164).  Saving model ...
Validation loss decreased (1.341164 --> 1.336652).  Saving model ...
Validation loss decreased (1.336652 --> 1.331954).  Saving model ...
Validation loss decreased (1.331954 --> 1.327671).  Saving model ...
Validation loss decreased (1.327671 --> 1.323110).  Saving model ...
Validation loss decreased (1.323110 --> 1.318010).  Saving model ...
Validation loss decreased (1.318010 --> 1.312797).  Saving model ...
Validation loss decreased (1.312797 --> 1.307111).  Saving model ...
Validation loss decreased (1.307111 --> 1.301216).  Saving model ...
Validation loss decreased (1.301216 --> 1.295674).  Saving model ...
Validation loss decreased (1.295674 --> 1.289642).  Saving model ...
Validation loss decreased (1.289642 --> 1.283734).  Saving model ...
Validation loss decreased (1.283734 --> 1.277189).  Saving model ...
Validation loss decreased (1.277189 --> 1.269737).  Saving model ...
Validation loss decreased (1.269737 --> 1.262991).  Saving model ...
Validation loss decreased (1.262991 --> 1.254647).  Saving model ...
Validation loss decreased (1.254647 --> 1.246531).  Saving model ...
Validation loss decreased (1.246531 --> 1.238644).  Saving model ...
Validation loss decreased (1.238644 --> 1.231907).  Saving model ...
Validation loss decreased (1.231907 --> 1.224839).  Saving model ...
Validation loss decreased (1.224839 --> 1.218464).  Saving model ...
Validation loss decreased (1.218464 --> 1.211974).  Saving model ...
Validation loss decreased (1.211974 --> 1.206077).  Saving model ...
Validation loss decreased (1.206077 --> 1.199162).  Saving model ...
Validation loss decreased (1.199162 --> 1.193572).  Saving model ...
Validation loss decreased (1.193572 --> 1.186744).  Saving model ...
Validation loss decreased (1.186744 --> 1.180196).  Saving model ...
Validation loss decreased (1.180196 --> 1.173586).  Saving model ...
Validation loss decreased (1.173586 --> 1.169037).  Saving model ...
Validation loss decreased (1.169037 --> 1.164760).  Saving model ...
Validation loss decreased (1.164760 --> 1.160612).  Saving model ...
Validation loss decreased (1.160612 --> 1.156031).  Saving model ...
Validation loss decreased (1.156031 --> 1.150850).  Saving model ...
Validation loss decreased (1.150850 --> 1.147279).  Saving model ...
Validation loss decreased (1.147279 --> 1.143512).  Saving model ...
Validation loss decreased (1.143512 --> 1.137709).  Saving model ...
Validation loss decreased (1.137709 --> 1.132174).  Saving model ...
Validation loss decreased (1.132174 --> 1.129550).  Saving model ...
Validation loss decreased (1.129550 --> 1.125230).  Saving model ...
Validation loss decreased (1.125230 --> 1.120975).  Saving model ...
Validation loss decreased (1.120975 --> 1.115871).  Saving model ...
Validation loss decreased (1.115871 --> 1.112234).  Saving model ...
Validation loss decreased (1.112234 --> 1.110375).  Saving model ...
Validation loss decreased (1.110375 --> 1.105201).  Saving model ...
Validation loss decreased (1.105201 --> 1.101545).  Saving model ...
Validation loss decreased (1.101545 --> 1.097944).  Saving model ...
Validation loss decreased (1.097944 --> 1.092584).  Saving model ...
Validation loss decreased (1.092584 --> 1.090122).  Saving model ...
Validation loss decreased (1.090122 --> 1.086675).  Saving model ...
Validation loss decreased (1.086675 --> 1.084025).  Saving model ...
Validation loss decreased (1.084025 --> 1.079482).  Saving model ...
Validation loss decreased (1.079482 --> 1.075622).  Saving model ...
Validation loss decreased (1.075622 --> 1.071558).  Saving model ...
Validation loss decreased (1.071558 --> 1.066659).  Saving model ...
Validation loss decreased (1.066659 --> 1.065387).  Saving model ...
Validation loss decreased (1.065387 --> 1.060920).  Saving model ...
Validation loss decreased (1.060920 --> 1.059622).  Saving model ...
Validation loss decreased (1.059622 --> 1.054379).  Saving model ...
Validation loss decreased (1.054379 --> 1.052295).  Saving model ...
Validation loss decreased (1.052295 --> 1.049020).  Saving model ...
Validation loss decreased (1.049020 --> 1.046222).  Saving model ...
Validation loss decreased (1.046222 --> 1.044151).  Saving model ...
Validation loss decreased (1.044151 --> 1.042389).  Saving model ...
Validation loss decreased (1.042389 --> 1.040853).  Saving model ...
Validation loss decreased (1.040853 --> 1.037194).  Saving model ...
Validation loss decreased (1.037194 --> 1.035484).  Saving model ...
Validation loss decreased (1.035484 --> 1.031059).  Saving model ...
Validation loss decreased (1.031059 --> 1.028867).  Saving model ...
Validation loss decreased (1.028867 --> 1.028415).  Saving model ...
Validation loss decreased (1.028415 --> 1.027134).  Saving model ...
Validation loss decreased (1.027134 --> 1.024872).  Saving model ...
Validation loss decreased (1.024872 --> 1.020578).  Saving model ...
EarlyStopping counter: 1 out of 3.0
Validation loss decreased (1.020578 --> 1.017644).  Saving model ...
Validation loss decreased (1.017644 --> 1.016853).  Saving model ...
Validation loss decreased (1.016853 --> 1.014491).  Saving model ...
Validation loss decreased (1.014491 --> 1.012402).  Saving model ...
Validation loss decreased (1.012402 --> 1.011992).  Saving model ...
EarlyStopping counter: 1 out of 3.0
Validation loss decreased (1.011992 --> 1.006924).  Saving model ...
EarlyStopping counter: 1 out of 3.0
EarlyStopping counter: 2 out of 3.0
EarlyStopping counter: 3 out of 3.0
/localscratch/yinan.29785229.0/env/lib/python3.7/site-packages/torch/nn/functional.py:1794: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.
  warnings.warn("nn.functional.tanh is deprecated. Use torch.tanh instead.")
wandb: Waiting for W&B process to finish, PID 150854... (success).
wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: \ 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: | 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: / 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: \ 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: | 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: / 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: \ 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: | 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: / 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: \ 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: | 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: / 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb:                                                                                
wandb: Run history:
wandb:     e_F1 ▁▂▃▄▅▅▅▅▆▆▆▆▆▆▆▆▆▆▆▆▇▇▇▇▇▇▇▇▇▇██████████
wandb:   e_loss ██▇▇▇▇▇▆▆▆▆▅▅▅▅▄▄▄▄▃▃▃▃▃▃▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁
wandb:     t_F1 ▁▁▂▂▂▂▃▃▃▃▄▄▅▅▅▅▅▅▅▅▆▆▆▆▆▆▆▇▇▇▇▇▇▇▇▇▇███
wandb:   t_loss ████▇▇▇▇▇▇▆▆▆▅▅▅▅▅▅▄▄▄▃▄▃▃▃▃▂▂▂▂▂▂▂▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:     e_F1 57.58597
wandb:   e_loss 1.00724
wandb:     t_F1 65.57687
wandb:   t_loss 0.87595
wandb: 
wandb: Synced 4 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Synced sage-voice-2: https://wandb.ai/yinanazhou/xl_512_bs_8_lr_1e06_es_3_lc_True_nr_True_sr_True_stem_False_lemma_False_repeat_2_fold_1/runs/2q6lz0mn
wandb: Find logs at: ./wandb/run-20220331_072626-2q6lz0mn/logs/debug.log
wandb: 

wandb: wandb version 0.12.11 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
2022-03-31 08:27:58.984981: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1
wandb: Tracking run with wandb version 0.12.5
wandb: Syncing run floral-bee-2
wandb: ⭐️ View project at https://wandb.ai/yinanazhou/xl_512_bs_8_lr_1e06_es_3_lc_True_nr_True_sr_True_stem_False_lemma_False_repeat_2_fold_2
wandb: 🚀 View run at https://wandb.ai/yinanazhou/xl_512_bs_8_lr_1e06_es_3_lc_True_nr_True_sr_True_stem_False_lemma_False_repeat_2_fold_2/runs/268ip9fl
wandb: Run data is saved locally in /project/6002780/yinan/Thesis_MER_Lyrics/lyric-emotion/wandb/run-20220331_082756-268ip9fl
wandb: Run `wandb offline` to turn off syncing.

Validation loss decreased (inf --> 1.434657).  Saving model ...
Validation loss decreased (1.434657 --> 1.419427).  Saving model ...
Validation loss decreased (1.419427 --> 1.406349).  Saving model ...
Validation loss decreased (1.406349 --> 1.396073).  Saving model ...
Validation loss decreased (1.396073 --> 1.386773).  Saving model ...
Validation loss decreased (1.386773 --> 1.379395).  Saving model ...
Validation loss decreased (1.379395 --> 1.373160).  Saving model ...
Validation loss decreased (1.373160 --> 1.367648).  Saving model ...
Validation loss decreased (1.367648 --> 1.362334).  Saving model ...
Validation loss decreased (1.362334 --> 1.357039).  Saving model ...
Validation loss decreased (1.357039 --> 1.352589).  Saving model ...
Validation loss decreased (1.352589 --> 1.347840).  Saving model ...
Validation loss decreased (1.347840 --> 1.343408).  Saving model ...
Validation loss decreased (1.343408 --> 1.338960).  Saving model ...
Validation loss decreased (1.338960 --> 1.334228).  Saving model ...
Validation loss decreased (1.334228 --> 1.329577).  Saving model ...
Validation loss decreased (1.329577 --> 1.324592).  Saving model ...
Validation loss decreased (1.324592 --> 1.319503).  Saving model ...
Validation loss decreased (1.319503 --> 1.314602).  Saving model ...
Validation loss decreased (1.314602 --> 1.310025).  Saving model ...
Validation loss decreased (1.310025 --> 1.305237).  Saving model ...
Validation loss decreased (1.305237 --> 1.299890).  Saving model ...
Validation loss decreased (1.299890 --> 1.293730).  Saving model ...
Validation loss decreased (1.293730 --> 1.287549).  Saving model ...
Validation loss decreased (1.287549 --> 1.281263).  Saving model ...
Validation loss decreased (1.281263 --> 1.275124).  Saving model ...
Validation loss decreased (1.275124 --> 1.267276).  Saving model ...
Validation loss decreased (1.267276 --> 1.260828).  Saving model ...
Validation loss decreased (1.260828 --> 1.254951).  Saving model ...
Validation loss decreased (1.254951 --> 1.248584).  Saving model ...
Validation loss decreased (1.248584 --> 1.242290).  Saving model ...
Validation loss decreased (1.242290 --> 1.235593).  Saving model ...
Validation loss decreased (1.235593 --> 1.229878).  Saving model ...
Validation loss decreased (1.229878 --> 1.223331).  Saving model ...
Validation loss decreased (1.223331 --> 1.218346).  Saving model ...
Validation loss decreased (1.218346 --> 1.211667).  Saving model ...
Validation loss decreased (1.211667 --> 1.204907).  Saving model ...
Validation loss decreased (1.204907 --> 1.198219).  Saving model ...
Validation loss decreased (1.198219 --> 1.191413).  Saving model ...
Validation loss decreased (1.191413 --> 1.184808).  Saving model ...
Validation loss decreased (1.184808 --> 1.178979).  Saving model ...
Validation loss decreased (1.178979 --> 1.173746).  Saving model ...
Validation loss decreased (1.173746 --> 1.168885).  Saving model ...
Validation loss decreased (1.168885 --> 1.162559).  Saving model ...
Validation loss decreased (1.162559 --> 1.157553).  Saving model ...
Validation loss decreased (1.157553 --> 1.152192).  Saving model ...
Validation loss decreased (1.152192 --> 1.146501).  Saving model ...
Validation loss decreased (1.146501 --> 1.140633).  Saving model ...
Validation loss decreased (1.140633 --> 1.136571).  Saving model ...
Validation loss decreased (1.136571 --> 1.130138).  Saving model ...
Validation loss decreased (1.130138 --> 1.125244).  Saving model ...
Validation loss decreased (1.125244 --> 1.122907).  Saving model ...
Validation loss decreased (1.122907 --> 1.118668).  Saving model ...
Validation loss decreased (1.118668 --> 1.113575).  Saving model ...
Validation loss decreased (1.113575 --> 1.107459).  Saving model ...
Validation loss decreased (1.107459 --> 1.105094).  Saving model ...
Validation loss decreased (1.105094 --> 1.099806).  Saving model ...
Validation loss decreased (1.099806 --> 1.096964).  Saving model ...
Validation loss decreased (1.096964 --> 1.092196).  Saving model ...
Validation loss decreased (1.092196 --> 1.088079).  Saving model ...
Validation loss decreased (1.088079 --> 1.083746).  Saving model ...
Validation loss decreased (1.083746 --> 1.079579).  Saving model ...
Validation loss decreased (1.079579 --> 1.074085).  Saving model ...
Validation loss decreased (1.074085 --> 1.070056).  Saving model ...
Validation loss decreased (1.070056 --> 1.067136).  Saving model ...
Validation loss decreased (1.067136 --> 1.063047).  Saving model ...
Validation loss decreased (1.063047 --> 1.059187).  Saving model ...
Validation loss decreased (1.059187 --> 1.057303).  Saving model ...
Validation loss decreased (1.057303 --> 1.052947).  Saving model ...
Validation loss decreased (1.052947 --> 1.050276).  Saving model ...
Validation loss decreased (1.050276 --> 1.047252).  Saving model ...
Validation loss decreased (1.047252 --> 1.043865).  Saving model ...
Validation loss decreased (1.043865 --> 1.042729).  Saving model ...
Validation loss decreased (1.042729 --> 1.038422).  Saving model ...
Validation loss decreased (1.038422 --> 1.034819).  Saving model ...
Validation loss decreased (1.034819 --> 1.029317).  Saving model ...
Validation loss decreased (1.029317 --> 1.026990).  Saving model ...
Validation loss decreased (1.026990 --> 1.026016).  Saving model ...
EarlyStopping counter: 1 out of 3.0
Validation loss decreased (1.026016 --> 1.020962).  Saving model ...
Validation loss decreased (1.020962 --> 1.016360).  Saving model ...
Validation loss decreased (1.016360 --> 1.013862).  Saving model ...
Validation loss decreased (1.013862 --> 1.011658).  Saving model ...
Validation loss decreased (1.011658 --> 1.007738).  Saving model ...
Validation loss decreased (1.007738 --> 1.004618).  Saving model ...
Validation loss decreased (1.004618 --> 1.001221).  Saving model ...
Validation loss decreased (1.001221 --> 0.996955).  Saving model ...
Validation loss decreased (0.996955 --> 0.995430).  Saving model ...
Validation loss decreased (0.995430 --> 0.992371).  Saving model ...
Validation loss decreased (0.992371 --> 0.991273).  Saving model ...
EarlyStopping counter: 1 out of 3.0
Validation loss decreased (0.991273 --> 0.989091).  Saving model ...
Validation loss decreased (0.989091 --> 0.985585).  Saving model ...
Validation loss decreased (0.985585 --> 0.982960).  Saving model ...
Validation loss decreased (0.982960 --> 0.980300).  Saving model ...
Validation loss decreased (0.980300 --> 0.977945).  Saving model ...
Validation loss decreased (0.977945 --> 0.974315).  Saving model ...
Validation loss decreased (0.974315 --> 0.970658).  Saving model ...
Validation loss decreased (0.970658 --> 0.967823).  Saving model ...
Validation loss decreased (0.967823 --> 0.967724).  Saving model ...
Validation loss decreased (0.967724 --> 0.965071).  Saving model ...
Validation loss decreased (0.965071 --> 0.964136).  Saving model ...
Validation loss decreased (0.964136 --> 0.963161).  Saving model ...
Validation loss decreased (0.963161 --> 0.962901).  Saving model ...
Validation loss decreased (0.962901 --> 0.960928).  Saving model ...
Validation loss decreased (0.960928 --> 0.959182).  Saving model ...
Validation loss decreased (0.959182 --> 0.957716).  Saving model ...
Validation loss decreased (0.957716 --> 0.955987).  Saving model ...
Validation loss decreased (0.955987 --> 0.952764).  Saving model ...
Validation loss decreased (0.952764 --> 0.952127).  Saving model ...
Validation loss decreased (0.952127 --> 0.950366).  Saving model ...
Validation loss decreased (0.950366 --> 0.947474).  Saving model ...
Validation loss decreased (0.947474 --> 0.946183).  Saving model ...
Validation loss decreased (0.946183 --> 0.944804).  Saving model ...
Validation loss decreased (0.944804 --> 0.942920).  Saving model ...
Validation loss decreased (0.942920 --> 0.940382).  Saving model ...
Validation loss decreased (0.940382 --> 0.937661).  Saving model ...
Validation loss decreased (0.937661 --> 0.935819).  Saving model ...
EarlyStopping counter: 1 out of 3.0
Validation loss decreased (0.935819 --> 0.934656).  Saving model ...
EarlyStopping counter: 1 out of 3.0
Validation loss decreased (0.934656 --> 0.934156).  Saving model ...
Validation loss decreased (0.934156 --> 0.931656).  Saving model ...
EarlyStopping counter: 1 out of 3.0
Validation loss decreased (0.931656 --> 0.930153).  Saving model ...
EarlyStopping counter: 1 out of 3.0
Validation loss decreased (0.930153 --> 0.924953).  Saving model ...
EarlyStopping counter: 1 out of 3.0
EarlyStopping counter: 2 out of 3.0
Validation loss decreased (0.924953 --> 0.923319).  Saving model ...
Validation loss decreased (0.923319 --> 0.923052).  Saving model ...
EarlyStopping counter: 1 out of 3.0
EarlyStopping counter: 2 out of 3.0
Validation loss decreased (0.923052 --> 0.922122).  Saving model ...
EarlyStopping counter: 1 out of 3.0
EarlyStopping counter: 2 out of 3.0
Validation loss decreased (0.922122 --> 0.920326).  Saving model ...
Validation loss decreased (0.920326 --> 0.919657).  Saving model ...
EarlyStopping counter: 1 out of 3.0
EarlyStopping counter: 2 out of 3.0
Validation loss decreased (0.919657 --> 0.916392).  Saving model ...
Validation loss decreased (0.916392 --> 0.915450).  Saving model ...
Validation loss decreased (0.915450 --> 0.914896).  Saving model ...
EarlyStopping counter: 1 out of 3.0
EarlyStopping counter: 2 out of 3.0
EarlyStopping counter: 3 out of 3.0
/localscratch/yinan.29785229.0/env/lib/python3.7/site-packages/torch/nn/functional.py:1794: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.
  warnings.warn("nn.functional.tanh is deprecated. Use torch.tanh instead.")
wandb: Waiting for W&B process to finish, PID 154152... (success).
wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: \ 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: | 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: / 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: \ 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: | 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: / 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: \ 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: | 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: / 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb:                                                                                
wandb: Run history:
wandb:     e_F1 ▁▁▂▃▅▅▅▅▅▆▆▆▆▆▆▆▆▇▇▇▇▇▇▇▇▇▇▇▇▇██████████
wandb:   e_loss ██▇▇▇▆▆▆▆▅▅▅▄▄▄▄▃▃▃▃▃▃▂▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁
wandb:     t_F1 ▁▁▂▃▃▃▄▄▄▄▄▅▆▆▆▆▆▆▇▆▆▆▇▇▇▇▇▇▇▇████▇█████
wandb:   t_loss ██▇▇▇▇▇▆▆▆▆▅▅▅▅▄▄▄▄▃▄▃▃▃▃▃▃▂▂▂▂▂▁▂▂▂▁▁▁▁
wandb: 
wandb: Run summary:
wandb:     e_F1 62.4296
wandb:   e_loss 0.91765
wandb:     t_F1 69.47112
wandb:   t_loss 0.79212
wandb: 
wandb: Synced 4 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Synced floral-bee-2: https://wandb.ai/yinanazhou/xl_512_bs_8_lr_1e06_es_3_lc_True_nr_True_sr_True_stem_False_lemma_False_repeat_2_fold_2/runs/268ip9fl
wandb: Find logs at: ./wandb/run-20220331_082756-268ip9fl/logs/debug.log
wandb: 

wandb: wandb version 0.12.11 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
2022-03-31 10:04:51.270668: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1
wandb: Tracking run with wandb version 0.12.5
wandb: Syncing run balmy-sun-2
wandb: ⭐️ View project at https://wandb.ai/yinanazhou/xl_512_bs_8_lr_1e06_es_3_lc_True_nr_True_sr_True_stem_False_lemma_False_repeat_3_fold_1
wandb: 🚀 View run at https://wandb.ai/yinanazhou/xl_512_bs_8_lr_1e06_es_3_lc_True_nr_True_sr_True_stem_False_lemma_False_repeat_3_fold_1/runs/b2e68pi5
wandb: Run data is saved locally in /project/6002780/yinan/Thesis_MER_Lyrics/lyric-emotion/wandb/run-20220331_100448-b2e68pi5
wandb: Run `wandb offline` to turn off syncing.

Validation loss decreased (inf --> 1.404749).  Saving model ...
Validation loss decreased (1.404749 --> 1.396883).  Saving model ...
Validation loss decreased (1.396883 --> 1.390262).  Saving model ...
Validation loss decreased (1.390262 --> 1.384616).  Saving model ...
Validation loss decreased (1.384616 --> 1.380085).  Saving model ...
Validation loss decreased (1.380085 --> 1.375571).  Saving model ...
Validation loss decreased (1.375571 --> 1.371412).  Saving model ...
Validation loss decreased (1.371412 --> 1.367121).  Saving model ...
Validation loss decreased (1.367121 --> 1.363316).  Saving model ...
Validation loss decreased (1.363316 --> 1.359809).  Saving model ...
Validation loss decreased (1.359809 --> 1.356263).  Saving model ...
Validation loss decreased (1.356263 --> 1.352460).  Saving model ...
Validation loss decreased (1.352460 --> 1.347852).  Saving model ...
Validation loss decreased (1.347852 --> 1.343077).  Saving model ...
Validation loss decreased (1.343077 --> 1.338598).  Saving model ...
Validation loss decreased (1.338598 --> 1.334282).  Saving model ...
Validation loss decreased (1.334282 --> 1.329838).  Saving model ...
Validation loss decreased (1.329838 --> 1.325377).  Saving model ...
Validation loss decreased (1.325377 --> 1.319080).  Saving model ...
Validation loss decreased (1.319080 --> 1.313812).  Saving model ...
Validation loss decreased (1.313812 --> 1.308488).  Saving model ...
Validation loss decreased (1.308488 --> 1.302239).  Saving model ...
Validation loss decreased (1.302239 --> 1.295934).  Saving model ...
Validation loss decreased (1.295934 --> 1.290331).  Saving model ...
Validation loss decreased (1.290331 --> 1.285236).  Saving model ...
Validation loss decreased (1.285236 --> 1.277497).  Saving model ...
Validation loss decreased (1.277497 --> 1.270002).  Saving model ...
Validation loss decreased (1.270002 --> 1.263620).  Saving model ...
Validation loss decreased (1.263620 --> 1.257964).  Saving model ...
Validation loss decreased (1.257964 --> 1.250650).  Saving model ...
Validation loss decreased (1.250650 --> 1.243072).  Saving model ...
Validation loss decreased (1.243072 --> 1.236524).  Saving model ...
Validation loss decreased (1.236524 --> 1.230376).  Saving model ...
Validation loss decreased (1.230376 --> 1.223419).  Saving model ...
Validation loss decreased (1.223419 --> 1.217231).  Saving model ...
Validation loss decreased (1.217231 --> 1.211806).  Saving model ...
Validation loss decreased (1.211806 --> 1.205884).  Saving model ...
Validation loss decreased (1.205884 --> 1.201865).  Saving model ...
Validation loss decreased (1.201865 --> 1.195571).  Saving model ...
Validation loss decreased (1.195571 --> 1.192651).  Saving model ...
Validation loss decreased (1.192651 --> 1.187169).  Saving model ...
Validation loss decreased (1.187169 --> 1.181615).  Saving model ...
Validation loss decreased (1.181615 --> 1.176519).  Saving model ...
Validation loss decreased (1.176519 --> 1.170060).  Saving model ...
Validation loss decreased (1.170060 --> 1.164666).  Saving model ...
Validation loss decreased (1.164666 --> 1.160233).  Saving model ...
Validation loss decreased (1.160233 --> 1.155147).  Saving model ...
Validation loss decreased (1.155147 --> 1.150938).  Saving model ...
Validation loss decreased (1.150938 --> 1.148101).  Saving model ...
Validation loss decreased (1.148101 --> 1.142888).  Saving model ...
Validation loss decreased (1.142888 --> 1.142844).  Saving model ...
Validation loss decreased (1.142844 --> 1.136823).  Saving model ...
Validation loss decreased (1.136823 --> 1.131229).  Saving model ...
Validation loss decreased (1.131229 --> 1.125525).  Saving model ...
Validation loss decreased (1.125525 --> 1.122179).  Saving model ...
Validation loss decreased (1.122179 --> 1.118124).  Saving model ...
Validation loss decreased (1.118124 --> 1.114420).  Saving model ...
Validation loss decreased (1.114420 --> 1.111803).  Saving model ...
Validation loss decreased (1.111803 --> 1.109661).  Saving model ...
Validation loss decreased (1.109661 --> 1.106551).  Saving model ...
Validation loss decreased (1.106551 --> 1.101393).  Saving model ...
Validation loss decreased (1.101393 --> 1.099946).  Saving model ...
Validation loss decreased (1.099946 --> 1.096348).  Saving model ...
Validation loss decreased (1.096348 --> 1.091299).  Saving model ...
Validation loss decreased (1.091299 --> 1.086519).  Saving model ...
Validation loss decreased (1.086519 --> 1.082655).  Saving model ...
Validation loss decreased (1.082655 --> 1.079053).  Saving model ...
Validation loss decreased (1.079053 --> 1.077867).  Saving model ...
Validation loss decreased (1.077867 --> 1.075665).  Saving model ...
Validation loss decreased (1.075665 --> 1.072192).  Saving model ...
Validation loss decreased (1.072192 --> 1.069939).  Saving model ...
Validation loss decreased (1.069939 --> 1.068020).  Saving model ...
Validation loss decreased (1.068020 --> 1.064793).  Saving model ...
Validation loss decreased (1.064793 --> 1.060469).  Saving model ...
Validation loss decreased (1.060469 --> 1.058050).  Saving model ...
Validation loss decreased (1.058050 --> 1.053501).  Saving model ...
Validation loss decreased (1.053501 --> 1.051791).  Saving model ...
Validation loss decreased (1.051791 --> 1.048837).  Saving model ...
EarlyStopping counter: 1 out of 3.0
Validation loss decreased (1.048837 --> 1.044870).  Saving model ...
Validation loss decreased (1.044870 --> 1.041957).  Saving model ...
Validation loss decreased (1.041957 --> 1.041334).  Saving model ...
Validation loss decreased (1.041334 --> 1.040612).  Saving model ...
Validation loss decreased (1.040612 --> 1.038877).  Saving model ...
Validation loss decreased (1.038877 --> 1.037113).  Saving model ...
Validation loss decreased (1.037113 --> 1.036290).  Saving model ...
EarlyStopping counter: 1 out of 3.0
Validation loss decreased (1.036290 --> 1.033300).  Saving model ...
Validation loss decreased (1.033300 --> 1.031755).  Saving model ...
Validation loss decreased (1.031755 --> 1.026508).  Saving model ...
Validation loss decreased (1.026508 --> 1.025552).  Saving model ...
Validation loss decreased (1.025552 --> 1.022946).  Saving model ...
Validation loss decreased (1.022946 --> 1.020558).  Saving model ...
Validation loss decreased (1.020558 --> 1.017251).  Saving model ...
EarlyStopping counter: 1 out of 3.0
Validation loss decreased (1.017251 --> 1.015920).  Saving model ...
Validation loss decreased (1.015920 --> 1.011339).  Saving model ...
Validation loss decreased (1.011339 --> 1.009574).  Saving model ...
EarlyStopping counter: 1 out of 3.0
EarlyStopping counter: 2 out of 3.0
EarlyStopping counter: 3 out of 3.0
/localscratch/yinan.29785229.0/env/lib/python3.7/site-packages/torch/nn/functional.py:1794: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.
  warnings.warn("nn.functional.tanh is deprecated. Use torch.tanh instead.")
wandb: Waiting for W&B process to finish, PID 159345... (success).
wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: \ 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: | 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: / 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: \ 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: | 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: / 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: \ 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: | 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: / 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb:                                                                                
wandb: Run history:
wandb:     e_F1 ▁▂▂▃▃▄▄▄▅▅▅▆▆▆▆▆▆▆▆▆▆▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇████
wandb:   e_loss ██▇▇▇▇▇▇▆▆▆▅▅▅▅▄▄▄▄▃▃▃▃▃▃▂▂▂▂▂▂▂▂▁▁▁▁▁▁▁
wandb:     t_F1 ▁▂▂▃▂▂▃▃▄▃▄▄▅▄▆▅▆▅▆▆▆▅▆▆▇▇▇▇▇▇▇▇▇▇█▇████
wandb:   t_loss ██▇▇▇▇▇▇▇▇▆▆▅▆▅▅▅▅▄▄▄▄▄▄▃▃▃▃▂▂▃▂▂▂▂▂▂▁▂▁
wandb: 
wandb: Run summary:
wandb:     e_F1 57.20962
wandb:   e_loss 1.01013
wandb:     t_F1 67.20245
wandb:   t_loss 0.86195
wandb: 
wandb: Synced 4 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Synced balmy-sun-2: https://wandb.ai/yinanazhou/xl_512_bs_8_lr_1e06_es_3_lc_True_nr_True_sr_True_stem_False_lemma_False_repeat_3_fold_1/runs/b2e68pi5
wandb: Find logs at: ./wandb/run-20220331_100448-b2e68pi5/logs/debug.log
wandb: 

wandb: wandb version 0.12.11 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
2022-03-31 11:10:52.845125: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1
wandb: Tracking run with wandb version 0.12.5
wandb: Syncing run radiant-snowflake-2
wandb: ⭐️ View project at https://wandb.ai/yinanazhou/xl_512_bs_8_lr_1e06_es_3_lc_True_nr_True_sr_True_stem_False_lemma_False_repeat_3_fold_2
wandb: 🚀 View run at https://wandb.ai/yinanazhou/xl_512_bs_8_lr_1e06_es_3_lc_True_nr_True_sr_True_stem_False_lemma_False_repeat_3_fold_2/runs/1t3c04zq
wandb: Run data is saved locally in /project/6002780/yinan/Thesis_MER_Lyrics/lyric-emotion/wandb/run-20220331_111050-1t3c04zq
wandb: Run `wandb offline` to turn off syncing.

Validation loss decreased (inf --> 1.478335).  Saving model ...
Validation loss decreased (1.478335 --> 1.440205).  Saving model ...
Validation loss decreased (1.440205 --> 1.413947).  Saving model ...
Validation loss decreased (1.413947 --> 1.392624).  Saving model ...
Validation loss decreased (1.392624 --> 1.379458).  Saving model ...
Validation loss decreased (1.379458 --> 1.369562).  Saving model ...
Validation loss decreased (1.369562 --> 1.361962).  Saving model ...
Validation loss decreased (1.361962 --> 1.356146).  Saving model ...
Validation loss decreased (1.356146 --> 1.350513).  Saving model ...
Validation loss decreased (1.350513 --> 1.345413).  Saving model ...
Validation loss decreased (1.345413 --> 1.340592).  Saving model ...
Validation loss decreased (1.340592 --> 1.334939).  Saving model ...
Validation loss decreased (1.334939 --> 1.330333).  Saving model ...
Validation loss decreased (1.330333 --> 1.325425).  Saving model ...
Validation loss decreased (1.325425 --> 1.320417).  Saving model ...
Validation loss decreased (1.320417 --> 1.314677).  Saving model ...
Validation loss decreased (1.314677 --> 1.309654).  Saving model ...
Validation loss decreased (1.309654 --> 1.303543).  Saving model ...
Validation loss decreased (1.303543 --> 1.296965).  Saving model ...
Validation loss decreased (1.296965 --> 1.290844).  Saving model ...
Validation loss decreased (1.290844 --> 1.285278).  Saving model ...
Validation loss decreased (1.285278 --> 1.279237).  Saving model ...
Validation loss decreased (1.279237 --> 1.272194).  Saving model ...
Validation loss decreased (1.272194 --> 1.265350).  Saving model ...
Validation loss decreased (1.265350 --> 1.259329).  Saving model ...
Validation loss decreased (1.259329 --> 1.252915).  Saving model ...
Validation loss decreased (1.252915 --> 1.246433).  Saving model ...
Validation loss decreased (1.246433 --> 1.239986).  Saving model ...
Validation loss decreased (1.239986 --> 1.232795).  Saving model ...
Validation loss decreased (1.232795 --> 1.225854).  Saving model ...
Validation loss decreased (1.225854 --> 1.219358).  Saving model ...
Validation loss decreased (1.219358 --> 1.212837).  Saving model ...
Validation loss decreased (1.212837 --> 1.206832).  Saving model ...
Validation loss decreased (1.206832 --> 1.201073).  Saving model ...
Validation loss decreased (1.201073 --> 1.195136).  Saving model ...
Validation loss decreased (1.195136 --> 1.188296).  Saving model ...
Validation loss decreased (1.188296 --> 1.181633).  Saving model ...
Validation loss decreased (1.181633 --> 1.176263).  Saving model ...
Validation loss decreased (1.176263 --> 1.170948).  Saving model ...
Validation loss decreased (1.170948 --> 1.166196).  Saving model ...
Validation loss decreased (1.166196 --> 1.159282).  Saving model ...
Validation loss decreased (1.159282 --> 1.154085).  Saving model ...
Validation loss decreased (1.154085 --> 1.149483).  Saving model ...
Validation loss decreased (1.149483 --> 1.144391).  Saving model ...
Validation loss decreased (1.144391 --> 1.138190).  Saving model ...
Validation loss decreased (1.138190 --> 1.133400).  Saving model ...
Validation loss decreased (1.133400 --> 1.128886).  Saving model ...
Validation loss decreased (1.128886 --> 1.124926).  Saving model ...
Validation loss decreased (1.124926 --> 1.120492).  Saving model ...
Validation loss decreased (1.120492 --> 1.115640).  Saving model ...
Validation loss decreased (1.115640 --> 1.111482).  Saving model ...
Validation loss decreased (1.111482 --> 1.107813).  Saving model ...
Validation loss decreased (1.107813 --> 1.104112).  Saving model ...
Validation loss decreased (1.104112 --> 1.100074).  Saving model ...
Validation loss decreased (1.100074 --> 1.095391).  Saving model ...
Validation loss decreased (1.095391 --> 1.090751).  Saving model ...
Validation loss decreased (1.090751 --> 1.086968).  Saving model ...
Validation loss decreased (1.086968 --> 1.083365).  Saving model ...
Validation loss decreased (1.083365 --> 1.080300).  Saving model ...
Validation loss decreased (1.080300 --> 1.077101).  Saving model ...
Validation loss decreased (1.077101 --> 1.072820).  Saving model ...
Validation loss decreased (1.072820 --> 1.069179).  Saving model ...
Validation loss decreased (1.069179 --> 1.066634).  Saving model ...
Validation loss decreased (1.066634 --> 1.063320).  Saving model ...
Validation loss decreased (1.063320 --> 1.059255).  Saving model ...
Validation loss decreased (1.059255 --> 1.056115).  Saving model ...
Validation loss decreased (1.056115 --> 1.052132).  Saving model ...
Validation loss decreased (1.052132 --> 1.049452).  Saving model ...
Validation loss decreased (1.049452 --> 1.046276).  Saving model ...
Validation loss decreased (1.046276 --> 1.043718).  Saving model ...
Validation loss decreased (1.043718 --> 1.039890).  Saving model ...
Validation loss decreased (1.039890 --> 1.036959).  Saving model ...
Validation loss decreased (1.036959 --> 1.035695).  Saving model ...
Validation loss decreased (1.035695 --> 1.033245).  Saving model ...
Validation loss decreased (1.033245 --> 1.030338).  Saving model ...
Validation loss decreased (1.030338 --> 1.026171).  Saving model ...
Validation loss decreased (1.026171 --> 1.023234).  Saving model ...
Validation loss decreased (1.023234 --> 1.020427).  Saving model ...
Validation loss decreased (1.020427 --> 1.017133).  Saving model ...
Validation loss decreased (1.017133 --> 1.015439).  Saving model ...
Validation loss decreased (1.015439 --> 1.013242).  Saving model ...
Validation loss decreased (1.013242 --> 1.009670).  Saving model ...
Validation loss decreased (1.009670 --> 1.008516).  Saving model ...
Validation loss decreased (1.008516 --> 1.006590).  Saving model ...
Validation loss decreased (1.006590 --> 1.004469).  Saving model ...
Validation loss decreased (1.004469 --> 1.001908).  Saving model ...
Validation loss decreased (1.001908 --> 1.000364).  Saving model ...
Validation loss decreased (1.000364 --> 0.997749).  Saving model ...
Validation loss decreased (0.997749 --> 0.995449).  Saving model ...
Validation loss decreased (0.995449 --> 0.993769).  Saving model ...
Validation loss decreased (0.993769 --> 0.992256).  Saving model ...
Validation loss decreased (0.992256 --> 0.990342).  Saving model ...
Validation loss decreased (0.990342 --> 0.988397).  Saving model ...
Validation loss decreased (0.988397 --> 0.986807).  Saving model ...
Validation loss decreased (0.986807 --> 0.984218).  Saving model ...
Validation loss decreased (0.984218 --> 0.981837).  Saving model ...
Validation loss decreased (0.981837 --> 0.981092).  Saving model ...
Validation loss decreased (0.981092 --> 0.979224).  Saving model ...
Validation loss decreased (0.979224 --> 0.976722).  Saving model ...
Validation loss decreased (0.976722 --> 0.975377).  Saving model ...
Validation loss decreased (0.975377 --> 0.974079).  Saving model ...
Validation loss decreased (0.974079 --> 0.973534).  Saving model ...
Validation loss decreased (0.973534 --> 0.972662).  Saving model ...
Validation loss decreased (0.972662 --> 0.970586).  Saving model ...
Validation loss decreased (0.970586 --> 0.969304).  Saving model ...
Validation loss decreased (0.969304 --> 0.967571).  Saving model ...
Validation loss decreased (0.967571 --> 0.967047).  Saving model ...
Validation loss decreased (0.967047 --> 0.965464).  Saving model ...
Validation loss decreased (0.965464 --> 0.963901).  Saving model ...
Validation loss decreased (0.963901 --> 0.962736).  Saving model ...
Validation loss decreased (0.962736 --> 0.961285).  Saving model ...
Validation loss decreased (0.961285 --> 0.960581).  Saving model ...
Validation loss decreased (0.960581 --> 0.959179).  Saving model ...
Validation loss decreased (0.959179 --> 0.958035).  Saving model ...
Validation loss decreased (0.958035 --> 0.956999).  Saving model ...
Validation loss decreased (0.956999 --> 0.955835).  Saving model ...
Validation loss decreased (0.955835 --> 0.954780).  Saving model ...
EarlyStopping counter: 1 out of 3.0
Validation loss decreased (0.954780 --> 0.954541).  Saving model ...
Validation loss decreased (0.954541 --> 0.953455).  Saving model ...
Validation loss decreased (0.953455 --> 0.953127).  Saving model ...
Validation loss decreased (0.953127 --> 0.951997).  Saving model ...
Validation loss decreased (0.951997 --> 0.949928).  Saving model ...
Validation loss decreased (0.949928 --> 0.949294).  Saving model ...
Validation loss decreased (0.949294 --> 0.949160).  Saving model ...
Validation loss decreased (0.949160 --> 0.948582).  Saving model ...
EarlyStopping counter: 1 out of 3.0
Validation loss decreased (0.948582 --> 0.948215).  Saving model ...
Validation loss decreased (0.948215 --> 0.947413).  Saving model ...
Validation loss decreased (0.947413 --> 0.947310).  Saving model ...
Validation loss decreased (0.947310 --> 0.946104).  Saving model ...
Validation loss decreased (0.946104 --> 0.944449).  Saving model ...
Validation loss decreased (0.944449 --> 0.943719).  Saving model ...
Validation loss decreased (0.943719 --> 0.943605).  Saving model ...
Validation loss decreased (0.943605 --> 0.942123).  Saving model ...
Validation loss decreased (0.942123 --> 0.941656).  Saving model ...
EarlyStopping counter: 1 out of 3.0
Validation loss decreased (0.941656 --> 0.941095).  Saving model ...
Validation loss decreased (0.941095 --> 0.940269).  Saving model ...
EarlyStopping counter: 1 out of 3.0
EarlyStopping counter: 2 out of 3.0
Validation loss decreased (0.940269 --> 0.940129).  Saving model ...
Validation loss decreased (0.940129 --> 0.939515).  Saving model ...
EarlyStopping counter: 1 out of 3.0
EarlyStopping counter: 2 out of 3.0
Validation loss decreased (0.939515 --> 0.939462).  Saving model ...
Validation loss decreased (0.939462 --> 0.938777).  Saving model ...
EarlyStopping counter: 1 out of 3.0
EarlyStopping counter: 2 out of 3.0
EarlyStopping counter: 3 out of 3.0
/localscratch/yinan.29785229.0/env/lib/python3.7/site-packages/torch/nn/functional.py:1794: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.
  warnings.warn("nn.functional.tanh is deprecated. Use torch.tanh instead.")
wandb: Waiting for W&B process to finish, PID 162884... (success).
wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: \ 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: | 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: / 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: \ 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: | 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: / 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: \ 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: | 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: / 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb:                                                                                
wandb: Run history:
wandb:     e_F1 ▁▂▄▄▅▅▅▆▆▆▆▆▆▆▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇██████████
wandb:   e_loss █▇▇▇▆▆▆▅▅▄▄▄▄▃▃▃▃▃▂▂▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:     t_F1 ▁▁▂▂▃▃▃▃▄▄▅▅▅▅▆▆▆▆▅▆▇▆▆▇▇▇▇▇▇▇▇▇▇██▇▇███
wandb:   t_loss ██▇▇▇▇▇▆▆▆▅▅▅▅▅▄▄▄▄▄▃▄▃▃▃▃▃▃▃▂▂▂▂▂▂▂▁▁▁▁
wandb: 
wandb: Run summary:
wandb:     e_F1 62.55414
wandb:   e_loss 0.93938
wandb:     t_F1 71.95038
wandb:   t_loss 0.75261
wandb: 
wandb: Synced 4 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Synced radiant-snowflake-2: https://wandb.ai/yinanazhou/xl_512_bs_8_lr_1e06_es_3_lc_True_nr_True_sr_True_stem_False_lemma_False_repeat_3_fold_2/runs/1t3c04zq
wandb: Find logs at: ./wandb/run-20220331_111050-1t3c04zq/logs/debug.log
wandb: 

wandb: wandb version 0.12.11 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
2022-03-31 12:48:54.869889: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1
wandb: Tracking run with wandb version 0.12.5
wandb: Syncing run amber-snowflake-2
wandb: ⭐️ View project at https://wandb.ai/yinanazhou/xl_512_bs_8_lr_1e06_es_3_lc_True_nr_True_sr_True_stem_False_lemma_False_repeat_4_fold_1
wandb: 🚀 View run at https://wandb.ai/yinanazhou/xl_512_bs_8_lr_1e06_es_3_lc_True_nr_True_sr_True_stem_False_lemma_False_repeat_4_fold_1/runs/96a0vz8p
wandb: Run data is saved locally in /project/6002780/yinan/Thesis_MER_Lyrics/lyric-emotion/wandb/run-20220331_124851-96a0vz8p
wandb: Run `wandb offline` to turn off syncing.

Validation loss decreased (inf --> 1.460856).  Saving model ...
Validation loss decreased (1.460856 --> 1.438536).  Saving model ...
Validation loss decreased (1.438536 --> 1.422655).  Saving model ...
Validation loss decreased (1.422655 --> 1.409281).  Saving model ...
Validation loss decreased (1.409281 --> 1.398800).  Saving model ...
Validation loss decreased (1.398800 --> 1.390645).  Saving model ...
Validation loss decreased (1.390645 --> 1.384404).  Saving model ...
Validation loss decreased (1.384404 --> 1.378878).  Saving model ...
Validation loss decreased (1.378878 --> 1.373448).  Saving model ...
Validation loss decreased (1.373448 --> 1.368627).  Saving model ...
Validation loss decreased (1.368627 --> 1.364126).  Saving model ...
Validation loss decreased (1.364126 --> 1.359745).  Saving model ...
Validation loss decreased (1.359745 --> 1.355955).  Saving model ...
Validation loss decreased (1.355955 --> 1.352268).  Saving model ...
Validation loss decreased (1.352268 --> 1.348129).  Saving model ...
Validation loss decreased (1.348129 --> 1.344269).  Saving model ...
Validation loss decreased (1.344269 --> 1.340419).  Saving model ...
Validation loss decreased (1.340419 --> 1.336824).  Saving model ...
Validation loss decreased (1.336824 --> 1.332961).  Saving model ...
Validation loss decreased (1.332961 --> 1.329072).  Saving model ...
Validation loss decreased (1.329072 --> 1.325040).  Saving model ...
Validation loss decreased (1.325040 --> 1.320763).  Saving model ...
Validation loss decreased (1.320763 --> 1.316568).  Saving model ...
Validation loss decreased (1.316568 --> 1.311869).  Saving model ...
Validation loss decreased (1.311869 --> 1.307526).  Saving model ...
Validation loss decreased (1.307526 --> 1.302859).  Saving model ...
Validation loss decreased (1.302859 --> 1.298311).  Saving model ...
Validation loss decreased (1.298311 --> 1.293218).  Saving model ...
Validation loss decreased (1.293218 --> 1.288403).  Saving model ...
Validation loss decreased (1.288403 --> 1.283385).  Saving model ...
Validation loss decreased (1.283385 --> 1.278396).  Saving model ...
Validation loss decreased (1.278396 --> 1.273542).  Saving model ...
Validation loss decreased (1.273542 --> 1.267987).  Saving model ...
Validation loss decreased (1.267987 --> 1.262415).  Saving model ...
Validation loss decreased (1.262415 --> 1.256949).  Saving model ...
Validation loss decreased (1.256949 --> 1.251202).  Saving model ...
Validation loss decreased (1.251202 --> 1.245471).  Saving model ...
Validation loss decreased (1.245471 --> 1.239946).  Saving model ...
Validation loss decreased (1.239946 --> 1.234815).  Saving model ...
Validation loss decreased (1.234815 --> 1.229622).  Saving model ...
Validation loss decreased (1.229622 --> 1.224116).  Saving model ...
Validation loss decreased (1.224116 --> 1.218727).  Saving model ...
Validation loss decreased (1.218727 --> 1.213453).  Saving model ...
Validation loss decreased (1.213453 --> 1.208490).  Saving model ...
Validation loss decreased (1.208490 --> 1.203297).  Saving model ...
Validation loss decreased (1.203297 --> 1.198958).  Saving model ...
Validation loss decreased (1.198958 --> 1.194985).  Saving model ...
Validation loss decreased (1.194985 --> 1.190990).  Saving model ...
Validation loss decreased (1.190990 --> 1.187241).  Saving model ...
Validation loss decreased (1.187241 --> 1.183838).  Saving model ...
Validation loss decreased (1.183838 --> 1.180088).  Saving model ...
Validation loss decreased (1.180088 --> 1.176764).  Saving model ...
Validation loss decreased (1.176764 --> 1.173190).  Saving model ...
Validation loss decreased (1.173190 --> 1.169329).  Saving model ...
Validation loss decreased (1.169329 --> 1.166216).  Saving model ...
Validation loss decreased (1.166216 --> 1.161891).  Saving model ...
Validation loss decreased (1.161891 --> 1.158477).  Saving model ...
Validation loss decreased (1.158477 --> 1.154425).  Saving model ...
Validation loss decreased (1.154425 --> 1.151077).  Saving model ...
Validation loss decreased (1.151077 --> 1.147177).  Saving model ...
Validation loss decreased (1.147177 --> 1.143720).  Saving model ...
Validation loss decreased (1.143720 --> 1.140516).  Saving model ...
Validation loss decreased (1.140516 --> 1.137583).  Saving model ...
Validation loss decreased (1.137583 --> 1.134292).  Saving model ...
Validation loss decreased (1.134292 --> 1.130438).  Saving model ...
Validation loss decreased (1.130438 --> 1.127314).  Saving model ...
Validation loss decreased (1.127314 --> 1.124302).  Saving model ...
Validation loss decreased (1.124302 --> 1.121386).  Saving model ...
Validation loss decreased (1.121386 --> 1.118695).  Saving model ...
Validation loss decreased (1.118695 --> 1.116581).  Saving model ...
Validation loss decreased (1.116581 --> 1.114895).  Saving model ...
Validation loss decreased (1.114895 --> 1.111939).  Saving model ...
Validation loss decreased (1.111939 --> 1.109006).  Saving model ...
Validation loss decreased (1.109006 --> 1.106210).  Saving model ...
Validation loss decreased (1.106210 --> 1.102854).  Saving model ...
Validation loss decreased (1.102854 --> 1.100643).  Saving model ...
Validation loss decreased (1.100643 --> 1.098468).  Saving model ...
Validation loss decreased (1.098468 --> 1.094625).  Saving model ...
Validation loss decreased (1.094625 --> 1.092833).  Saving model ...
Validation loss decreased (1.092833 --> 1.090225).  Saving model ...
Validation loss decreased (1.090225 --> 1.089036).  Saving model ...
Validation loss decreased (1.089036 --> 1.087233).  Saving model ...
Validation loss decreased (1.087233 --> 1.084724).  Saving model ...
Validation loss decreased (1.084724 --> 1.082449).  Saving model ...
Validation loss decreased (1.082449 --> 1.079976).  Saving model ...
Validation loss decreased (1.079976 --> 1.077361).  Saving model ...
Validation loss decreased (1.077361 --> 1.076214).  Saving model ...
Validation loss decreased (1.076214 --> 1.073798).  Saving model ...
Validation loss decreased (1.073798 --> 1.071549).  Saving model ...
Validation loss decreased (1.071549 --> 1.068201).  Saving model ...
Validation loss decreased (1.068201 --> 1.066742).  Saving model ...
Validation loss decreased (1.066742 --> 1.064546).  Saving model ...
Validation loss decreased (1.064546 --> 1.061280).  Saving model ...
Validation loss decreased (1.061280 --> 1.059690).  Saving model ...
Validation loss decreased (1.059690 --> 1.056913).  Saving model ...
Validation loss decreased (1.056913 --> 1.055351).  Saving model ...
Validation loss decreased (1.055351 --> 1.054586).  Saving model ...
Validation loss decreased (1.054586 --> 1.054221).  Saving model ...
Validation loss decreased (1.054221 --> 1.052017).  Saving model ...
Validation loss decreased (1.052017 --> 1.050456).  Saving model ...
Validation loss decreased (1.050456 --> 1.049654).  Saving model ...
Validation loss decreased (1.049654 --> 1.048605).  Saving model ...
Validation loss decreased (1.048605 --> 1.047065).  Saving model ...
Validation loss decreased (1.047065 --> 1.044572).  Saving model ...
Validation loss decreased (1.044572 --> 1.044355).  Saving model ...
Validation loss decreased (1.044355 --> 1.042518).  Saving model ...
Validation loss decreased (1.042518 --> 1.042120).  Saving model ...
Validation loss decreased (1.042120 --> 1.041085).  Saving model ...
Validation loss decreased (1.041085 --> 1.038207).  Saving model ...
Validation loss decreased (1.038207 --> 1.035760).  Saving model ...
Validation loss decreased (1.035760 --> 1.035547).  Saving model ...
EarlyStopping counter: 1 out of 3.0
Validation loss decreased (1.035547 --> 1.033507).  Saving model ...
Validation loss decreased (1.033507 --> 1.031957).  Saving model ...
Validation loss decreased (1.031957 --> 1.030372).  Saving model ...
Validation loss decreased (1.030372 --> 1.028617).  Saving model ...
Validation loss decreased (1.028617 --> 1.028364).  Saving model ...
Validation loss decreased (1.028364 --> 1.027443).  Saving model ...
Validation loss decreased (1.027443 --> 1.027137).  Saving model ...
Validation loss decreased (1.027137 --> 1.026322).  Saving model ...
Validation loss decreased (1.026322 --> 1.024183).  Saving model ...
Validation loss decreased (1.024183 --> 1.023113).  Saving model ...
Validation loss decreased (1.023113 --> 1.021886).  Saving model ...
Validation loss decreased (1.021886 --> 1.021551).  Saving model ...
Validation loss decreased (1.021551 --> 1.021152).  Saving model ...
EarlyStopping counter: 1 out of 3.0
EarlyStopping counter: 2 out of 3.0
Validation loss decreased (1.021152 --> 1.020363).  Saving model ...
EarlyStopping counter: 1 out of 3.0
EarlyStopping counter: 2 out of 3.0
EarlyStopping counter: 3 out of 3.0
/localscratch/yinan.29785229.0/env/lib/python3.7/site-packages/torch/nn/functional.py:1794: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.
  warnings.warn("nn.functional.tanh is deprecated. Use torch.tanh instead.")
wandb: Waiting for W&B process to finish, PID 168136... (success).
wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: \ 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: | 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: / 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: \ 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: | 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: / 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: \ 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: | 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: / 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: \ 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: | 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: / 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb:                                                                                
wandb: Run history:
wandb:     e_F1 ▁▁▂▃▄▅▅▅▅▅▆▆▆▆▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇██████████
wandb:   e_loss ██▇▇▇▆▆▆▆▅▅▅▄▄▄▄▃▃▃▃▃▃▂▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁
wandb:     t_F1 ▁▁▂▂▂▃▃▃▄▄▄▅▅▅▅▅▆▅▆▆▆▆▆▆▆▆▆▇▇▇▇▇▇▇▇█▇▇▇█
wandb:   t_loss ██▇▇▇▇▇▇▆▆▆▆▆▅▆▅▅▅▄▄▄▄▄▄▃▃▃▃▃▃▃▂▂▂▂▂▂▂▂▁
wandb: 
wandb: Run summary:
wandb:     e_F1 55.98636
wandb:   e_loss 1.02188
wandb:     t_F1 68.61162
wandb:   t_loss 0.78782
wandb: 
wandb: Synced 4 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Synced amber-snowflake-2: https://wandb.ai/yinanazhou/xl_512_bs_8_lr_1e06_es_3_lc_True_nr_True_sr_True_stem_False_lemma_False_repeat_4_fold_1/runs/96a0vz8p
wandb: Find logs at: ./wandb/run-20220331_124851-96a0vz8p/logs/debug.log
wandb: 

wandb: wandb version 0.12.11 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
2022-03-31 14:15:58.805655: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1
wandb: Tracking run with wandb version 0.12.5
wandb: Syncing run sweet-vortex-2
wandb: ⭐️ View project at https://wandb.ai/yinanazhou/xl_512_bs_8_lr_1e06_es_3_lc_True_nr_True_sr_True_stem_False_lemma_False_repeat_4_fold_2
wandb: 🚀 View run at https://wandb.ai/yinanazhou/xl_512_bs_8_lr_1e06_es_3_lc_True_nr_True_sr_True_stem_False_lemma_False_repeat_4_fold_2/runs/2hx1mzad
wandb: Run data is saved locally in /project/6002780/yinan/Thesis_MER_Lyrics/lyric-emotion/wandb/run-20220331_141555-2hx1mzad
wandb: Run `wandb offline` to turn off syncing.

Validation loss decreased (inf --> 1.392954).  Saving model ...
Validation loss decreased (1.392954 --> 1.384191).  Saving model ...
Validation loss decreased (1.384191 --> 1.378398).  Saving model ...
Validation loss decreased (1.378398 --> 1.373411).  Saving model ...
Validation loss decreased (1.373411 --> 1.369016).  Saving model ...
Validation loss decreased (1.369016 --> 1.364942).  Saving model ...
Validation loss decreased (1.364942 --> 1.361072).  Saving model ...
Validation loss decreased (1.361072 --> 1.357987).  Saving model ...
Validation loss decreased (1.357987 --> 1.354588).  Saving model ...
Validation loss decreased (1.354588 --> 1.350700).  Saving model ...
Validation loss decreased (1.350700 --> 1.346946).  Saving model ...
Validation loss decreased (1.346946 --> 1.342968).  Saving model ...
Validation loss decreased (1.342968 --> 1.338031).  Saving model ...
Validation loss decreased (1.338031 --> 1.333703).  Saving model ...
Validation loss decreased (1.333703 --> 1.329398).  Saving model ...
Validation loss decreased (1.329398 --> 1.324354).  Saving model ...
Validation loss decreased (1.324354 --> 1.319932).  Saving model ...
Validation loss decreased (1.319932 --> 1.314933).  Saving model ...
Validation loss decreased (1.314933 --> 1.308960).  Saving model ...
Validation loss decreased (1.308960 --> 1.303162).  Saving model ...
Validation loss decreased (1.303162 --> 1.297359).  Saving model ...
Validation loss decreased (1.297359 --> 1.290187).  Saving model ...
Validation loss decreased (1.290187 --> 1.284308).  Saving model ...
Validation loss decreased (1.284308 --> 1.276541).  Saving model ...
Validation loss decreased (1.276541 --> 1.269461).  Saving model ...
Validation loss decreased (1.269461 --> 1.264175).  Saving model ...
Validation loss decreased (1.264175 --> 1.255200).  Saving model ...
Validation loss decreased (1.255200 --> 1.248489).  Saving model ...
Validation loss decreased (1.248489 --> 1.240397).  Saving model ...
Validation loss decreased (1.240397 --> 1.233557).  Saving model ...
Validation loss decreased (1.233557 --> 1.226000).  Saving model ...
Validation loss decreased (1.226000 --> 1.218577).  Saving model ...
Validation loss decreased (1.218577 --> 1.210874).  Saving model ...
Validation loss decreased (1.210874 --> 1.203656).  Saving model ...
Validation loss decreased (1.203656 --> 1.197433).  Saving model ...
Validation loss decreased (1.197433 --> 1.189854).  Saving model ...
Validation loss decreased (1.189854 --> 1.184183).  Saving model ...
Validation loss decreased (1.184183 --> 1.179948).  Saving model ...
Validation loss decreased (1.179948 --> 1.173442).  Saving model ...
Validation loss decreased (1.173442 --> 1.166880).  Saving model ...
Validation loss decreased (1.166880 --> 1.159969).  Saving model ...
Validation loss decreased (1.159969 --> 1.154413).  Saving model ...
Validation loss decreased (1.154413 --> 1.148673).  Saving model ...
Validation loss decreased (1.148673 --> 1.145260).  Saving model ...
Validation loss decreased (1.145260 --> 1.139273).  Saving model ...
Validation loss decreased (1.139273 --> 1.134505).  Saving model ...
Validation loss decreased (1.134505 --> 1.129796).  Saving model ...
Validation loss decreased (1.129796 --> 1.125881).  Saving model ...
Validation loss decreased (1.125881 --> 1.121241).  Saving model ...
Validation loss decreased (1.121241 --> 1.117864).  Saving model ...
Validation loss decreased (1.117864 --> 1.112833).  Saving model ...
Validation loss decreased (1.112833 --> 1.107700).  Saving model ...
Validation loss decreased (1.107700 --> 1.104476).  Saving model ...
Validation loss decreased (1.104476 --> 1.100579).  Saving model ...
Validation loss decreased (1.100579 --> 1.095703).  Saving model ...
Validation loss decreased (1.095703 --> 1.092656).  Saving model ...
Validation loss decreased (1.092656 --> 1.088268).  Saving model ...
Validation loss decreased (1.088268 --> 1.081791).  Saving model ...
Validation loss decreased (1.081791 --> 1.078557).  Saving model ...
Validation loss decreased (1.078557 --> 1.072108).  Saving model ...
Validation loss decreased (1.072108 --> 1.070592).  Saving model ...
Validation loss decreased (1.070592 --> 1.064974).  Saving model ...
EarlyStopping counter: 1 out of 3.0
Validation loss decreased (1.064974 --> 1.061729).  Saving model ...
Validation loss decreased (1.061729 --> 1.057139).  Saving model ...
Validation loss decreased (1.057139 --> 1.054205).  Saving model ...
Validation loss decreased (1.054205 --> 1.052385).  Saving model ...
Validation loss decreased (1.052385 --> 1.047549).  Saving model ...
Validation loss decreased (1.047549 --> 1.045802).  Saving model ...
Validation loss decreased (1.045802 --> 1.041372).  Saving model ...
Validation loss decreased (1.041372 --> 1.039490).  Saving model ...
EarlyStopping counter: 1 out of 3.0
Validation loss decreased (1.039490 --> 1.034608).  Saving model ...
Validation loss decreased (1.034608 --> 1.031246).  Saving model ...
Validation loss decreased (1.031246 --> 1.025349).  Saving model ...
Validation loss decreased (1.025349 --> 1.023566).  Saving model ...
EarlyStopping counter: 1 out of 3.0
Validation loss decreased (1.023566 --> 1.021900).  Saving model ...
Validation loss decreased (1.021900 --> 1.018393).  Saving model ...
Validation loss decreased (1.018393 --> 1.017833).  Saving model ...
Validation loss decreased (1.017833 --> 1.015780).  Saving model ...
Validation loss decreased (1.015780 --> 1.014975).  Saving model ...
Validation loss decreased (1.014975 --> 1.014368).  Saving model ...
Validation loss decreased (1.014368 --> 1.006718).  Saving model ...
Validation loss decreased (1.006718 --> 1.004273).  Saving model ...
Validation loss decreased (1.004273 --> 1.002231).  Saving model ...
Validation loss decreased (1.002231 --> 1.001563).  Saving model ...
Validation loss decreased (1.001563 --> 0.998084).  Saving model ...
Validation loss decreased (0.998084 --> 0.998049).  Saving model ...
EarlyStopping counter: 1 out of 3.0
Validation loss decreased (0.998049 --> 0.996793).  Saving model ...
Validation loss decreased (0.996793 --> 0.994935).  Saving model ...
Validation loss decreased (0.994935 --> 0.994340).  Saving model ...
Validation loss decreased (0.994340 --> 0.992783).  Saving model ...
EarlyStopping counter: 1 out of 3.0
Validation loss decreased (0.992783 --> 0.988545).  Saving model ...
Validation loss decreased (0.988545 --> 0.986470).  Saving model ...
Validation loss decreased (0.986470 --> 0.986327).  Saving model ...
Validation loss decreased (0.986327 --> 0.983650).  Saving model ...
Validation loss decreased (0.983650 --> 0.981324).  Saving model ...
Validation loss decreased (0.981324 --> 0.979173).  Saving model ...
Validation loss decreased (0.979173 --> 0.977377).  Saving model ...
Validation loss decreased (0.977377 --> 0.976702).  Saving model ...
Validation loss decreased (0.976702 --> 0.976162).  Saving model ...
Validation loss decreased (0.976162 --> 0.974304).  Saving model ...
EarlyStopping counter: 1 out of 3.0
EarlyStopping counter: 2 out of 3.0
Validation loss decreased (0.974304 --> 0.972262).  Saving model ...
EarlyStopping counter: 1 out of 3.0
EarlyStopping counter: 2 out of 3.0
EarlyStopping counter: 3 out of 3.0
/localscratch/yinan.29785229.0/env/lib/python3.7/site-packages/torch/nn/functional.py:1794: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.
  warnings.warn("nn.functional.tanh is deprecated. Use torch.tanh instead.")
wandb: Waiting for W&B process to finish, PID 172832... (success).
wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: \ 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: | 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: / 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: \ 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: | 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: / 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: \ 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: | 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: / 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb:                                                                                
wandb: Run history:
wandb:     e_F1 ▁▂▄▄▄▄▅▅▅▅▆▆▆▆▇▇▇▇▇▇▇▇▇█████████████████
wandb:   e_loss ███▇▇▇▇▇▆▆▅▅▅▅▄▄▄▄▃▃▃▃▃▂▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁
wandb:     t_F1 ▁▁▂▂▂▃▃▄▄▅▅▅▄▅▆▆▅▆▆▆▆▆▇▇▇▇▇▇▇▇▇▇█▇▇█████
wandb:   t_loss █████▇▇▇▇▆▆▆▆▅▅▅▅▄▄▄▄▄▃▃▃▃▃▃▂▃▂▂▂▂▂▂▁▁▁▁
wandb: 
wandb: Run summary:
wandb:     e_F1 57.76589
wandb:   e_loss 0.97252
wandb:     t_F1 70.36708
wandb:   t_loss 0.81153
wandb: 
wandb: Synced 4 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Synced sweet-vortex-2: https://wandb.ai/yinanazhou/xl_512_bs_8_lr_1e06_es_3_lc_True_nr_True_sr_True_stem_False_lemma_False_repeat_4_fold_2/runs/2hx1mzad
wandb: Find logs at: ./wandb/run-20220331_141555-2hx1mzad/logs/debug.log
wandb: 

wandb: wandb version 0.12.11 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
2022-03-31 15:29:33.826466: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1
wandb: Tracking run with wandb version 0.12.5
wandb: Syncing run glamorous-cosmos-1
wandb: ⭐️ View project at https://wandb.ai/yinanazhou/xl_512_bs_8_lr_1e06_es_3_lc_True_nr_True_sr_True_stem_False_lemma_False_repeat_5_fold_1
wandb: 🚀 View run at https://wandb.ai/yinanazhou/xl_512_bs_8_lr_1e06_es_3_lc_True_nr_True_sr_True_stem_False_lemma_False_repeat_5_fold_1/runs/2qf0qpyq
wandb: Run data is saved locally in /project/6002780/yinan/Thesis_MER_Lyrics/lyric-emotion/wandb/run-20220331_152931-2qf0qpyq
wandb: Run `wandb offline` to turn off syncing.

Validation loss decreased (inf --> 1.428575).  Saving model ...
Validation loss decreased (1.428575 --> 1.411348).  Saving model ...
Validation loss decreased (1.411348 --> 1.398597).  Saving model ...
Validation loss decreased (1.398597 --> 1.389108).  Saving model ...
Validation loss decreased (1.389108 --> 1.380746).  Saving model ...
Validation loss decreased (1.380746 --> 1.374687).  Saving model ...
Validation loss decreased (1.374687 --> 1.369137).  Saving model ...
Validation loss decreased (1.369137 --> 1.364600).  Saving model ...
Validation loss decreased (1.364600 --> 1.360504).  Saving model ...
Validation loss decreased (1.360504 --> 1.356202).  Saving model ...
Validation loss decreased (1.356202 --> 1.352108).  Saving model ...
Validation loss decreased (1.352108 --> 1.348131).  Saving model ...
Validation loss decreased (1.348131 --> 1.344179).  Saving model ...
Validation loss decreased (1.344179 --> 1.340199).  Saving model ...
Validation loss decreased (1.340199 --> 1.335880).  Saving model ...
Validation loss decreased (1.335880 --> 1.331876).  Saving model ...
Validation loss decreased (1.331876 --> 1.327495).  Saving model ...
Validation loss decreased (1.327495 --> 1.322919).  Saving model ...
Validation loss decreased (1.322919 --> 1.317378).  Saving model ...
Validation loss decreased (1.317378 --> 1.311817).  Saving model ...
Validation loss decreased (1.311817 --> 1.305980).  Saving model ...
Validation loss decreased (1.305980 --> 1.300809).  Saving model ...
Validation loss decreased (1.300809 --> 1.294660).  Saving model ...
Validation loss decreased (1.294660 --> 1.288986).  Saving model ...
Validation loss decreased (1.288986 --> 1.282355).  Saving model ...
Validation loss decreased (1.282355 --> 1.275277).  Saving model ...
Validation loss decreased (1.275277 --> 1.267157).  Saving model ...
Validation loss decreased (1.267157 --> 1.259756).  Saving model ...
Validation loss decreased (1.259756 --> 1.253395).  Saving model ...
Validation loss decreased (1.253395 --> 1.246688).  Saving model ...
Validation loss decreased (1.246688 --> 1.239569).  Saving model ...
Validation loss decreased (1.239569 --> 1.231942).  Saving model ...
Validation loss decreased (1.231942 --> 1.225220).  Saving model ...
Validation loss decreased (1.225220 --> 1.219771).  Saving model ...
Validation loss decreased (1.219771 --> 1.212551).  Saving model ...
Validation loss decreased (1.212551 --> 1.206869).  Saving model ...
Validation loss decreased (1.206869 --> 1.200570).  Saving model ...
Validation loss decreased (1.200570 --> 1.196776).  Saving model ...
Validation loss decreased (1.196776 --> 1.190862).  Saving model ...
Validation loss decreased (1.190862 --> 1.184227).  Saving model ...
Validation loss decreased (1.184227 --> 1.178883).  Saving model ...
Validation loss decreased (1.178883 --> 1.173692).  Saving model ...
Validation loss decreased (1.173692 --> 1.168277).  Saving model ...
Validation loss decreased (1.168277 --> 1.164971).  Saving model ...
Validation loss decreased (1.164971 --> 1.160938).  Saving model ...
Validation loss decreased (1.160938 --> 1.157613).  Saving model ...
Validation loss decreased (1.157613 --> 1.151915).  Saving model ...
Validation loss decreased (1.151915 --> 1.146535).  Saving model ...
Validation loss decreased (1.146535 --> 1.140924).  Saving model ...
Validation loss decreased (1.140924 --> 1.136255).  Saving model ...
Validation loss decreased (1.136255 --> 1.132017).  Saving model ...
Validation loss decreased (1.132017 --> 1.128447).  Saving model ...
Validation loss decreased (1.128447 --> 1.123688).  Saving model ...
Validation loss decreased (1.123688 --> 1.120701).  Saving model ...
Validation loss decreased (1.120701 --> 1.115680).  Saving model ...
Validation loss decreased (1.115680 --> 1.110561).  Saving model ...
Validation loss decreased (1.110561 --> 1.106500).  Saving model ...
Validation loss decreased (1.106500 --> 1.103146).  Saving model ...
Validation loss decreased (1.103146 --> 1.099757).  Saving model ...
Validation loss decreased (1.099757 --> 1.095136).  Saving model ...
Validation loss decreased (1.095136 --> 1.092753).  Saving model ...
Validation loss decreased (1.092753 --> 1.089866).  Saving model ...
Validation loss decreased (1.089866 --> 1.085771).  Saving model ...
Validation loss decreased (1.085771 --> 1.080090).  Saving model ...
Validation loss decreased (1.080090 --> 1.076373).  Saving model ...
Validation loss decreased (1.076373 --> 1.074255).  Saving model ...
Validation loss decreased (1.074255 --> 1.070169).  Saving model ...
Validation loss decreased (1.070169 --> 1.064440).  Saving model ...
Validation loss decreased (1.064440 --> 1.060548).  Saving model ...
Validation loss decreased (1.060548 --> 1.058447).  Saving model ...
Validation loss decreased (1.058447 --> 1.055251).  Saving model ...
Validation loss decreased (1.055251 --> 1.052246).  Saving model ...
Validation loss decreased (1.052246 --> 1.048329).  Saving model ...
Validation loss decreased (1.048329 --> 1.044920).  Saving model ...
Validation loss decreased (1.044920 --> 1.043019).  Saving model ...
Validation loss decreased (1.043019 --> 1.040114).  Saving model ...
Validation loss decreased (1.040114 --> 1.038923).  Saving model ...
Validation loss decreased (1.038923 --> 1.035628).  Saving model ...
Validation loss decreased (1.035628 --> 1.032608).  Saving model ...
Validation loss decreased (1.032608 --> 1.028747).  Saving model ...
Validation loss decreased (1.028747 --> 1.027836).  Saving model ...
Validation loss decreased (1.027836 --> 1.025766).  Saving model ...
Validation loss decreased (1.025766 --> 1.023777).  Saving model ...
Validation loss decreased (1.023777 --> 1.019724).  Saving model ...
Validation loss decreased (1.019724 --> 1.016665).  Saving model ...
Validation loss decreased (1.016665 --> 1.014864).  Saving model ...
Validation loss decreased (1.014864 --> 1.011834).  Saving model ...
Validation loss decreased (1.011834 --> 1.011229).  Saving model ...
Validation loss decreased (1.011229 --> 1.009286).  Saving model ...
Validation loss decreased (1.009286 --> 1.005177).  Saving model ...
Validation loss decreased (1.005177 --> 1.003254).  Saving model ...
Validation loss decreased (1.003254 --> 0.999852).  Saving model ...
Validation loss decreased (0.999852 --> 0.997514).  Saving model ...
Validation loss decreased (0.997514 --> 0.996091).  Saving model ...
Validation loss decreased (0.996091 --> 0.995707).  Saving model ...
Validation loss decreased (0.995707 --> 0.995421).  Saving model ...
Validation loss decreased (0.995421 --> 0.993617).  Saving model ...
Validation loss decreased (0.993617 --> 0.992177).  Saving model ...
Validation loss decreased (0.992177 --> 0.991323).  Saving model ...
Validation loss decreased (0.991323 --> 0.987903).  Saving model ...
Validation loss decreased (0.987903 --> 0.986663).  Saving model ...
EarlyStopping counter: 1 out of 3.0
Validation loss decreased (0.986663 --> 0.983769).  Saving model ...
Validation loss decreased (0.983769 --> 0.982012).  Saving model ...
Validation loss decreased (0.982012 --> 0.979185).  Saving model ...
Validation loss decreased (0.979185 --> 0.978244).  Saving model ...
Validation loss decreased (0.978244 --> 0.974983).  Saving model ...
Validation loss decreased (0.974983 --> 0.972561).  Saving model ...
EarlyStopping counter: 1 out of 3.0
Validation loss decreased (0.972561 --> 0.972016).  Saving model ...
Validation loss decreased (0.972016 --> 0.970676).  Saving model ...
Validation loss decreased (0.970676 --> 0.969131).  Saving model ...
Validation loss decreased (0.969131 --> 0.968662).  Saving model ...
Validation loss decreased (0.968662 --> 0.966283).  Saving model ...
Validation loss decreased (0.966283 --> 0.964286).  Saving model ...
EarlyStopping counter: 1 out of 3.0
Validation loss decreased (0.964286 --> 0.963899).  Saving model ...
EarlyStopping counter: 1 out of 3.0
EarlyStopping counter: 2 out of 3.0
Validation loss decreased (0.963899 --> 0.961574).  Saving model ...
Validation loss decreased (0.961574 --> 0.959140).  Saving model ...
Validation loss decreased (0.959140 --> 0.957474).  Saving model ...
EarlyStopping counter: 1 out of 3.0
EarlyStopping counter: 2 out of 3.0
Validation loss decreased (0.957474 --> 0.956899).  Saving model ...
Validation loss decreased (0.956899 --> 0.955688).  Saving model ...
EarlyStopping counter: 1 out of 3.0
EarlyStopping counter: 2 out of 3.0
Validation loss decreased (0.955688 --> 0.954398).  Saving model ...
Validation loss decreased (0.954398 --> 0.952334).  Saving model ...
Validation loss decreased (0.952334 --> 0.951922).  Saving model ...
EarlyStopping counter: 1 out of 3.0
Validation loss decreased (0.951922 --> 0.951706).  Saving model ...
EarlyStopping counter: 1 out of 3.0
Validation loss decreased (0.951706 --> 0.950920).  Saving model ...
Validation loss decreased (0.950920 --> 0.948507).  Saving model ...
EarlyStopping counter: 1 out of 3.0
EarlyStopping counter: 2 out of 3.0
Validation loss decreased (0.948507 --> 0.946916).  Saving model ...
Validation loss decreased (0.946916 --> 0.945249).  Saving model ...
Validation loss decreased (0.945249 --> 0.944624).  Saving model ...
EarlyStopping counter: 1 out of 3.0
EarlyStopping counter: 2 out of 3.0
EarlyStopping counter: 3 out of 3.0
/localscratch/yinan.29785229.0/env/lib/python3.7/site-packages/torch/nn/functional.py:1794: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.
  warnings.warn("nn.functional.tanh is deprecated. Use torch.tanh instead.")
wandb: Waiting for W&B process to finish, PID 176769... (success).
wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: \ 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: | 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: / 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: \ 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: | 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: / 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: \ 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: | 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: / 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb:                                                                                
wandb: Run history:
wandb:     e_F1 ▁▂▃▄▄▅▅▅▅▅▆▆▆▆▆▆▆▇▇▇▇▇▇▇▇▇▇▇▇███████████
wandb:   e_loss ██▇▇▇▇▆▆▆▅▅▄▄▄▄▃▃▃▃▃▂▂▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁
wandb:     t_F1 ▁▁▂▃▃▃▃▄▄▅▅▅▅▆▆▆▆▆▆▇▆▆▆▇▇▇▇▇▇▇▇▇█▇▇▇█▇██
wandb:   t_loss ███▇▇▇▇▆▆▆▆▅▅▅▅▄▄▄▄▃▃▃▃▃▃▃▃▃▂▂▂▂▂▂▂▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:     e_F1 58.34654
wandb:   e_loss 0.94612
wandb:     t_F1 73.54778
wandb:   t_loss 0.74001
wandb: 
wandb: Synced 4 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Synced glamorous-cosmos-1: https://wandb.ai/yinanazhou/xl_512_bs_8_lr_1e06_es_3_lc_True_nr_True_sr_True_stem_False_lemma_False_repeat_5_fold_1/runs/2qf0qpyq
wandb: Find logs at: ./wandb/run-20220331_152931-2qf0qpyq/logs/debug.log
wandb: 

wandb: wandb version 0.12.11 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
2022-03-31 17:04:16.248387: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1
wandb: Tracking run with wandb version 0.12.5
wandb: Syncing run pleasant-cherry-1
wandb: ⭐️ View project at https://wandb.ai/yinanazhou/xl_512_bs_8_lr_1e06_es_3_lc_True_nr_True_sr_True_stem_False_lemma_False_repeat_5_fold_2
wandb: 🚀 View run at https://wandb.ai/yinanazhou/xl_512_bs_8_lr_1e06_es_3_lc_True_nr_True_sr_True_stem_False_lemma_False_repeat_5_fold_2/runs/28zhd9rg
wandb: Run data is saved locally in /project/6002780/yinan/Thesis_MER_Lyrics/lyric-emotion/wandb/run-20220331_170413-28zhd9rg
wandb: Run `wandb offline` to turn off syncing.

Validation loss decreased (inf --> 1.411378).  Saving model ...
Validation loss decreased (1.411378 --> 1.400241).  Saving model ...
Validation loss decreased (1.400241 --> 1.391482).  Saving model ...
Validation loss decreased (1.391482 --> 1.384124).  Saving model ...
Validation loss decreased (1.384124 --> 1.378571).  Saving model ...
Validation loss decreased (1.378571 --> 1.373527).  Saving model ...
Validation loss decreased (1.373527 --> 1.369459).  Saving model ...
Validation loss decreased (1.369459 --> 1.365594).  Saving model ...
Validation loss decreased (1.365594 --> 1.361803).  Saving model ...
Validation loss decreased (1.361803 --> 1.358242).  Saving model ...
Validation loss decreased (1.358242 --> 1.354497).  Saving model ...
Validation loss decreased (1.354497 --> 1.351214).  Saving model ...
Validation loss decreased (1.351214 --> 1.347753).  Saving model ...
Validation loss decreased (1.347753 --> 1.344356).  Saving model ...
Validation loss decreased (1.344356 --> 1.340865).  Saving model ...
Validation loss decreased (1.340865 --> 1.337091).  Saving model ...
Validation loss decreased (1.337091 --> 1.333437).  Saving model ...
Validation loss decreased (1.333437 --> 1.329667).  Saving model ...
Validation loss decreased (1.329667 --> 1.325712).  Saving model ...
Validation loss decreased (1.325712 --> 1.321682).  Saving model ...
Validation loss decreased (1.321682 --> 1.316549).  Saving model ...
Validation loss decreased (1.316549 --> 1.311845).  Saving model ...
Validation loss decreased (1.311845 --> 1.307010).  Saving model ...
Validation loss decreased (1.307010 --> 1.300600).  Saving model ...
Validation loss decreased (1.300600 --> 1.295005).  Saving model ...
Validation loss decreased (1.295005 --> 1.289217).  Saving model ...
Validation loss decreased (1.289217 --> 1.283532).  Saving model ...
Validation loss decreased (1.283532 --> 1.277860).  Saving model ...
Validation loss decreased (1.277860 --> 1.272666).  Saving model ...
Validation loss decreased (1.272666 --> 1.267872).  Saving model ...
Validation loss decreased (1.267872 --> 1.261453).  Saving model ...
Validation loss decreased (1.261453 --> 1.255453).  Saving model ...
Validation loss decreased (1.255453 --> 1.249445).  Saving model ...
Validation loss decreased (1.249445 --> 1.243975).  Saving model ...
Validation loss decreased (1.243975 --> 1.235732).  Saving model ...
Validation loss decreased (1.235732 --> 1.231479).  Saving model ...
Validation loss decreased (1.231479 --> 1.226187).  Saving model ...
Validation loss decreased (1.226187 --> 1.219741).  Saving model ...
Validation loss decreased (1.219741 --> 1.214589).  Saving model ...
Validation loss decreased (1.214589 --> 1.209822).  Saving model ...
Validation loss decreased (1.209822 --> 1.203616).  Saving model ...
Validation loss decreased (1.203616 --> 1.198196).  Saving model ...
Validation loss decreased (1.198196 --> 1.193293).  Saving model ...
Validation loss decreased (1.193293 --> 1.186929).  Saving model ...
Validation loss decreased (1.186929 --> 1.181947).  Saving model ...
Validation loss decreased (1.181947 --> 1.177484).  Saving model ...
Validation loss decreased (1.177484 --> 1.172189).  Saving model ...
Validation loss decreased (1.172189 --> 1.166021).  Saving model ...
Validation loss decreased (1.166021 --> 1.163588).  Saving model ...
Validation loss decreased (1.163588 --> 1.158927).  Saving model ...
Validation loss decreased (1.158927 --> 1.154942).  Saving model ...
Validation loss decreased (1.154942 --> 1.149039).  Saving model ...
Validation loss decreased (1.149039 --> 1.142999).  Saving model ...
Validation loss decreased (1.142999 --> 1.136369).  Saving model ...
Validation loss decreased (1.136369 --> 1.133837).  Saving model ...
Validation loss decreased (1.133837 --> 1.128694).  Saving model ...
Validation loss decreased (1.128694 --> 1.124611).  Saving model ...
Validation loss decreased (1.124611 --> 1.122007).  Saving model ...
Validation loss decreased (1.122007 --> 1.117342).  Saving model ...
Validation loss decreased (1.117342 --> 1.111692).  Saving model ...
Validation loss decreased (1.111692 --> 1.109974).  Saving model ...
Validation loss decreased (1.109974 --> 1.106740).  Saving model ...
Validation loss decreased (1.106740 --> 1.102484).  Saving model ...
Validation loss decreased (1.102484 --> 1.098760).  Saving model ...
Validation loss decreased (1.098760 --> 1.096950).  Saving model ...
Validation loss decreased (1.096950 --> 1.093683).  Saving model ...
Validation loss decreased (1.093683 --> 1.091329).  Saving model ...
Validation loss decreased (1.091329 --> 1.087801).  Saving model ...
Validation loss decreased (1.087801 --> 1.085129).  Saving model ...
Validation loss decreased (1.085129 --> 1.081639).  Saving model ...
Validation loss decreased (1.081639 --> 1.079018).  Saving model ...
Validation loss decreased (1.079018 --> 1.078359).  Saving model ...
Validation loss decreased (1.078359 --> 1.075748).  Saving model ...
Validation loss decreased (1.075748 --> 1.071712).  Saving model ...
Validation loss decreased (1.071712 --> 1.066989).  Saving model ...
Validation loss decreased (1.066989 --> 1.063923).  Saving model ...
Validation loss decreased (1.063923 --> 1.062360).  Saving model ...
Validation loss decreased (1.062360 --> 1.058650).  Saving model ...
Validation loss decreased (1.058650 --> 1.056704).  Saving model ...
Validation loss decreased (1.056704 --> 1.052223).  Saving model ...
Validation loss decreased (1.052223 --> 1.048979).  Saving model ...
Validation loss decreased (1.048979 --> 1.045575).  Saving model ...
Validation loss decreased (1.045575 --> 1.043864).  Saving model ...
Validation loss decreased (1.043864 --> 1.041647).  Saving model ...
Validation loss decreased (1.041647 --> 1.038764).  Saving model ...
Validation loss decreased (1.038764 --> 1.035269).  Saving model ...
Validation loss decreased (1.035269 --> 1.033667).  Saving model ...
EarlyStopping counter: 1 out of 3.0
Validation loss decreased (1.033667 --> 1.029270).  Saving model ...
Validation loss decreased (1.029270 --> 1.024332).  Saving model ...
Validation loss decreased (1.024332 --> 1.023200).  Saving model ...
Validation loss decreased (1.023200 --> 1.021034).  Saving model ...
Validation loss decreased (1.021034 --> 1.020698).  Saving model ...
Validation loss decreased (1.020698 --> 1.018614).  Saving model ...
Validation loss decreased (1.018614 --> 1.015328).  Saving model ...
Validation loss decreased (1.015328 --> 1.013956).  Saving model ...
Validation loss decreased (1.013956 --> 1.012663).  Saving model ...
Validation loss decreased (1.012663 --> 1.012246).  Saving model ...
EarlyStopping counter: 1 out of 3.0
EarlyStopping counter: 2 out of 3.0
Validation loss decreased (1.012246 --> 1.011887).  Saving model ...
Validation loss decreased (1.011887 --> 1.007012).  Saving model ...
Validation loss decreased (1.007012 --> 1.001656).  Saving model ...
Validation loss decreased (1.001656 --> 1.000207).  Saving model ...
Validation loss decreased (1.000207 --> 0.998698).  Saving model ...
Validation loss decreased (0.998698 --> 0.997410).  Saving model ...
Validation loss decreased (0.997410 --> 0.996773).  Saving model ...
Validation loss decreased (0.996773 --> 0.995859).  Saving model ...
EarlyStopping counter: 1 out of 3.0
Validation loss decreased (0.995859 --> 0.992455).  Saving model ...
Validation loss decreased (0.992455 --> 0.990369).  Saving model ...
Validation loss decreased (0.990369 --> 0.988663).  Saving model ...
Validation loss decreased (0.988663 --> 0.985542).  Saving model ...
EarlyStopping counter: 1 out of 3.0
EarlyStopping counter: 2 out of 3.0
Validation loss decreased (0.985542 --> 0.985396).  Saving model ...
Validation loss decreased (0.985396 --> 0.985260).  Saving model ...
Validation loss decreased (0.985260 --> 0.985049).  Saving model ...
Validation loss decreased (0.985049 --> 0.983467).  Saving model ...
Validation loss decreased (0.983467 --> 0.981397).  Saving model ...
Validation loss decreased (0.981397 --> 0.978973).  Saving model ...
Validation loss decreased (0.978973 --> 0.978576).  Saving model ...
Validation loss decreased (0.978576 --> 0.975499).  Saving model ...
EarlyStopping counter: 1 out of 3.0
EarlyStopping counter: 2 out of 3.0
EarlyStopping counter: 3 out of 3.0
/localscratch/yinan.29785229.0/env/lib/python3.7/site-packages/torch/nn/functional.py:1794: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.
  warnings.warn("nn.functional.tanh is deprecated. Use torch.tanh instead.")
wandb: Waiting for W&B process to finish, PID 181843... (success).
wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: \ 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: | 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: / 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: \ 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: | 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: / 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: \ 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: | 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: / 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: \ 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: | 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: / 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb:                                                                                
wandb: Run history:
wandb:     e_F1 ▁▂▃▄▄▅▅▅▅▅▅▆▆▆▆▆▆▇▇▇▇▇▇▇▇▇▇█████████████
wandb:   e_loss ██▇▇▇▇▇▆▆▆▅▅▅▅▄▄▄▄▃▃▃▃▃▃▂▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁
wandb:     t_F1 ▁▁▂▂▃▃▃▄▄▄▄▄▅▅▅▅▆▆▆▆▆▆▇▆▇▇▇▇▇▇▇▇▇▇▇▇██▇█
wandb:   t_loss ██▇▇▇▇▇▇▆▆▆▆▅▅▅▅▄▄▄▄▄▄▃▄▃▃▃▃▂▂▂▂▂▂▂▂▁▁▁▁
wandb: 
wandb: Run summary:
wandb:     e_F1 56.65541
wandb:   e_loss 0.97684
wandb:     t_F1 72.17517
wandb:   t_loss 0.78278
wandb: 
wandb: Synced 4 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Synced pleasant-cherry-1: https://wandb.ai/yinanazhou/xl_512_bs_8_lr_1e06_es_3_lc_True_nr_True_sr_True_stem_False_lemma_False_repeat_5_fold_2/runs/28zhd9rg
wandb: Find logs at: ./wandb/run-20220331_170413-28zhd9rg/logs/debug.log
wandb: 

