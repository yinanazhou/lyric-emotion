Unloading StdEnv/2020

Due to MODULEPATH changes, the following have been reloaded:
  1) mii/1.1.1


The following have been reloaded with a version change:
  1) python/3.8.2 => python/3.7.4

Using base prefix '/cvmfs/soft.computecanada.ca/easybuild/software/2017/Core/python/3.7.4'
New python executable in /localscratch/yinan.29113217.0/env/bin/python
Installing setuptools, pip, wheel...
done.
Ignoring pip: markers 'python_version < "3"' don't match your environment
Looking in links: /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/nix/avx2, /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/nix/generic, /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic
Collecting pip
Installing collected packages: pip
  Found existing installation: pip 19.1.1
    Uninstalling pip-19.1.1:
      Successfully uninstalled pip-19.1.1
Successfully installed pip-21.2.3+computecanada
Looking in links: /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/nix/avx2, /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/nix/generic, /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/keras-2.8.0+computecanada-py2.py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/Keras_Preprocessing-1.1.2+computecanada-py3-none-any.whl
Requirement already satisfied: matplotlib in /cvmfs/soft.computecanada.ca/easybuild/software/2017/Core/scipy-stack/2019a/lib/python3.7/site-packages (from -r requirements.txt (line 3)) (3.0.2)
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/nltk-3.6.5+computecanada-py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/scikit_learn-0.22.1+computecanada-cp37-cp37m-linux_x86_64.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/tensorboard-2.3.0+computecanada-py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/tensorboard_plugin_wit-1.7.0+computecanada-py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/tensorflow_gpu-2.3.0+computecanada-cp37-cp37m-linux_x86_64.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/tensorflow_estimator-2.3.0+computecanada-py2.py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/tokenizers-0.5.2+computecanada-cp37-cp37m-linux_x86_64.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/nix/avx2/torch-1.4.0+computecanada-cp37-cp37m-linux_x86_64.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/torchtext-0.6.0+computecanada-py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/torchvision-0.8.2+computecanada-cp37-cp37m-linux_x86_64.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/transformers-2.5.1+computecanada-py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/urllib3-1.26.7+computecanada-py2.py3-none-any.whl
ERROR: Could not find a version that satisfies the requirement regex>=2021.8.3 (from nltk) (from versions: 2018.1.10+computecanada, 2019.11.1+computecanada, 2020.11.13+computecanada)
ERROR: No matching distribution found for regex>=2021.8.3
Looking in links: /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/nix/avx2, /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/nix/generic, /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic
ERROR: Could not find a version that satisfies the requirement numpy==1.20.0+computacanada (from versions: 1.15.0+computecanada, 1.15.2+computecanada, 1.15.4+computecanada, 1.16.0+computecanada, 1.16.2+computecanada, 1.16.3+computecanada, 1.17.4+computecanada, 1.18.1+computecanada, 1.18.4+computecanada, 1.19.1+computecanada, 1.19.2+computecanada, 1.20.2+computecanada)
ERROR: No matching distribution found for numpy==1.20.0+computacanada
Looking in links: /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/nix/avx2, /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/nix/generic, /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/wandb-0.12.5+computecanada-py2.py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/protobuf-3.19.4+computecanada-py2.py3-none-any.whl
Requirement already satisfied: python-dateutil>=2.6.1 in /cvmfs/soft.computecanada.ca/easybuild/software/2017/Core/scipy-stack/2019a/lib/python3.7/site-packages (from wandb) (2.7.5)
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/docker_pycreds-0.4.0+computecanada-py2.py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/click-8.0.4+computecanada-py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/six-1.16.0+computecanada-py2.py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/PyYAML-5.3.1+computecanada-cp37-cp37m-linux_x86_64.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/sentry_sdk-1.5.0+computecanada-py2.py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/subprocess32-3.5.4+computecanada-py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/promise-2.3+computecanada-py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/shortuuid-1.0.1+computecanada-py3-none-any.whl
Requirement already satisfied: requests<3,>=2.0.0 in /cvmfs/soft.computecanada.ca/easybuild/software/2017/Core/scipy-stack/2019a/lib/python3.7/site-packages (from wandb) (2.21.0)
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/yaspin-2.1.0+computecanada-py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/GitPython-3.1.24+computecanada-py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/configparser-5.0.2+computecanada-py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/pathtools-0.1.2+computecanada-py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/psutil-5.7.3+computecanada-cp37-cp37m-linux_x86_64.whl
Requirement already satisfied: importlib-metadata in /cvmfs/soft.computecanada.ca/easybuild/software/2017/Core/scipy-stack/2019a/lib/python3.7/site-packages (from Click!=8.0.0,>=7.0->wandb) (0.8)
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/typing_extensions-4.0.1+computecanada-py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/gitdb-4.0.9+computecanada-py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/smmap-5.0.0+computecanada-py3-none-any.whl
Requirement already satisfied: certifi>=2017.4.17 in /cvmfs/soft.computecanada.ca/easybuild/software/2017/Core/scipy-stack/2019a/lib/python3.7/site-packages (from requests<3,>=2.0.0->wandb) (2018.11.29)
Requirement already satisfied: urllib3<1.25,>=1.21.1 in /cvmfs/soft.computecanada.ca/easybuild/software/2017/Core/scipy-stack/2019a/lib/python3.7/site-packages (from requests<3,>=2.0.0->wandb) (1.24.1)
Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /cvmfs/soft.computecanada.ca/easybuild/software/2017/Core/scipy-stack/2019a/lib/python3.7/site-packages (from requests<3,>=2.0.0->wandb) (3.0.4)
Requirement already satisfied: idna<2.9,>=2.5 in /cvmfs/soft.computecanada.ca/easybuild/software/2017/Core/scipy-stack/2019a/lib/python3.7/site-packages (from requests<3,>=2.0.0->wandb) (2.8)
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/termcolor-1.1.0+computecanada-py3-none-any.whl
Requirement already satisfied: zipp>=0.3.2 in /cvmfs/soft.computecanada.ca/easybuild/software/2017/Core/scipy-stack/2019a/lib/python3.7/site-packages (from importlib-metadata->Click!=8.0.0,>=7.0->wandb) (0.3.3)
Installing collected packages: smmap, typing-extensions, termcolor, six, gitdb, yaspin, subprocess32, shortuuid, sentry-sdk, PyYAML, psutil, protobuf, promise, pathtools, GitPython, docker-pycreds, configparser, Click, wandb
  Attempting uninstall: six
    Found existing installation: six 1.12.0
    Not uninstalling six at /cvmfs/soft.computecanada.ca/easybuild/software/2017/Core/scipy-stack/2019a/lib/python3.7/site-packages, outside environment /localscratch/yinan.29113217.0/env
    Can't uninstall 'six'. No files were found to uninstall.
Successfully installed Click-8.0.4+computecanada GitPython-3.1.24+computecanada PyYAML-5.3.1+computecanada configparser-5.0.2+computecanada docker-pycreds-0.4.0+computecanada gitdb-4.0.9+computecanada pathtools-0.1.2+computecanada promise-2.3+computecanada protobuf-3.19.4+computecanada psutil-5.7.3+computecanada sentry-sdk-1.5.0+computecanada shortuuid-1.0.1+computecanada six-1.16.0+computecanada smmap-5.0.0+computecanada subprocess32-3.5.4+computecanada termcolor-1.1.0+computecanada typing-extensions-4.0.1+computecanada wandb-0.12.5+computecanada yaspin-2.1.0+computecanada
Looking in links: /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/nix/avx2, /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/nix/generic, /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic
ERROR: Could not find a version that satisfies the requirement sagemaker (from versions: none)
ERROR: No matching distribution found for sagemaker
Looking in links: /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/nix/avx2, /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/nix/generic, /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/torch-1.9.1+computecanada-cp37-cp37m-linux_x86_64.whl
Requirement already satisfied: typing-extensions in /localscratch/yinan.29113217.0/env/lib/python3.7/site-packages (from torch) (4.0.1+computecanada)
Installing collected packages: torch
Successfully installed torch-1.9.1+computecanada
Looking in links: /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/nix/avx2, /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/nix/generic, /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/transformers-2.5.1+computecanada-py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/sacremoses-0.0.46+computecanada-py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/tqdm-4.63.0+computecanada-py2.py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/boto3-1.21.14+computecanada-py3-none-any.whl
Requirement already satisfied: requests in /cvmfs/soft.computecanada.ca/easybuild/software/2017/Core/scipy-stack/2019a/lib/python3.7/site-packages (from transformers==2.5.1+computecanada) (2.21.0)
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/tokenizers-0.5.2+computecanada-cp37-cp37m-linux_x86_64.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/filelock-3.4.2+computecanada-py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/regex-2020.11.13+computecanada-cp37-cp37m-linux_x86_64.whl
Requirement already satisfied: numpy in /cvmfs/soft.computecanada.ca/easybuild/software/2017/Core/scipy-stack/2019a/lib/python3.7/site-packages (from transformers==2.5.1+computecanada) (1.16.0)
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/sentencepiece-0.1.91+computecanada-cp37-cp37m-linux_x86_64.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/botocore-1.24.14+computecanada-py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/jmespath-0.10.0+computecanada-py2.py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/s3transfer-0.5.1+computecanada-py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/urllib3-1.26.8+computecanada-py2.py3-none-any.whl
Requirement already satisfied: python-dateutil<3.0.0,>=2.1 in /cvmfs/soft.computecanada.ca/easybuild/software/2017/Core/scipy-stack/2019a/lib/python3.7/site-packages (from botocore<1.25.0,>=1.24.14->boto3->transformers==2.5.1+computecanada) (2.7.5)
Requirement already satisfied: six>=1.5 in /localscratch/yinan.29113217.0/env/lib/python3.7/site-packages (from python-dateutil<3.0.0,>=2.1->botocore<1.25.0,>=1.24.14->boto3->transformers==2.5.1+computecanada) (1.16.0+computecanada)
Requirement already satisfied: certifi>=2017.4.17 in /cvmfs/soft.computecanada.ca/easybuild/software/2017/Core/scipy-stack/2019a/lib/python3.7/site-packages (from requests->transformers==2.5.1+computecanada) (2018.11.29)
Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /cvmfs/soft.computecanada.ca/easybuild/software/2017/Core/scipy-stack/2019a/lib/python3.7/site-packages (from requests->transformers==2.5.1+computecanada) (3.0.4)
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/requests-2.27.1+computecanada-py2.py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/charset_normalizer-2.0.12+computecanada-py3-none-any.whl
Requirement already satisfied: idna<4,>=2.5 in /cvmfs/soft.computecanada.ca/easybuild/software/2017/Core/scipy-stack/2019a/lib/python3.7/site-packages (from requests->transformers==2.5.1+computecanada) (2.8)
Requirement already satisfied: click in /localscratch/yinan.29113217.0/env/lib/python3.7/site-packages (from sacremoses->transformers==2.5.1+computecanada) (8.0.4+computecanada)
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/joblib-1.1.0+computecanada-py2.py3-none-any.whl
Requirement already satisfied: importlib-metadata in /cvmfs/soft.computecanada.ca/easybuild/software/2017/Core/scipy-stack/2019a/lib/python3.7/site-packages (from click->sacremoses->transformers==2.5.1+computecanada) (0.8)
Requirement already satisfied: zipp>=0.3.2 in /cvmfs/soft.computecanada.ca/easybuild/software/2017/Core/scipy-stack/2019a/lib/python3.7/site-packages (from importlib-metadata->click->sacremoses->transformers==2.5.1+computecanada) (0.3.3)
Installing collected packages: urllib3, jmespath, botocore, tqdm, s3transfer, regex, joblib, charset-normalizer, tokenizers, sentencepiece, sacremoses, requests, filelock, boto3, transformers
  Attempting uninstall: urllib3
    Found existing installation: urllib3 1.24.1
    Not uninstalling urllib3 at /cvmfs/soft.computecanada.ca/easybuild/software/2017/Core/scipy-stack/2019a/lib/python3.7/site-packages, outside environment /localscratch/yinan.29113217.0/env
    Can't uninstall 'urllib3'. No files were found to uninstall.
  Attempting uninstall: requests
    Found existing installation: requests 2.21.0
    Not uninstalling requests at /cvmfs/soft.computecanada.ca/easybuild/software/2017/Core/scipy-stack/2019a/lib/python3.7/site-packages, outside environment /localscratch/yinan.29113217.0/env
    Can't uninstall 'requests'. No files were found to uninstall.
Successfully installed boto3-1.21.14+computecanada botocore-1.24.14+computecanada charset-normalizer-2.0.12+computecanada filelock-3.4.2+computecanada jmespath-0.10.0+computecanada joblib-1.1.0+computecanada regex-2020.11.13+computecanada requests-2.27.1+computecanada s3transfer-0.5.1+computecanada sacremoses-0.0.46+computecanada sentencepiece-0.1.91+computecanada tokenizers-0.5.2+computecanada tqdm-4.63.0+computecanada transformers-2.5.1+computecanada urllib3-1.26.8+computecanada
Looking in links: /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/nix/avx2, /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/nix/generic, /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/tensorflow_gpu-2.3.0+computecanada-cp37-cp37m-linux_x86_64.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/grpcio-1.38.0+computecanada-cp37-cp37m-linux_x86_64.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/absl_py-1.0.0+computecanada-py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/astunparse-1.6.3+computecanada-py2.py3-none-any.whl
Requirement already satisfied: protobuf>=3.9.2 in /localscratch/yinan.29113217.0/env/lib/python3.7/site-packages (from tensorflow_gpu==2.3.0+computecanada) (3.19.4+computecanada)
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/tensorboard-2.8.0+computecanada-py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/wrapt-1.11.2+computecanada-cp37-cp37m-linux_x86_64.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/gast-0.3.3+computecanada-py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/nix/generic/scipy-1.4.1+computecanada-cp37-cp37m-linux_x86_64.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/tensorflow_estimator-2.3.0+computecanada-py2.py3-none-any.whl
Requirement already satisfied: termcolor>=1.1.0 in /localscratch/yinan.29113217.0/env/lib/python3.7/site-packages (from tensorflow_gpu==2.3.0+computecanada) (1.1.0+computecanada)
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/opt_einsum-3.3.0+computecanada-py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/google_pasta-0.2.0+computecanada-py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/Keras_Preprocessing-1.1.2+computecanada-py3-none-any.whl
Requirement already satisfied: numpy<1.19.0,>=1.16.0 in /cvmfs/soft.computecanada.ca/easybuild/software/2017/Core/scipy-stack/2019a/lib/python3.7/site-packages (from tensorflow_gpu==2.3.0+computecanada) (1.16.0)
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/nix/avx2/h5py-2.10.0+computecanada-cp37-cp37m-linux_x86_64.whl
Requirement already satisfied: six>=1.12.0 in /localscratch/yinan.29113217.0/env/lib/python3.7/site-packages (from tensorflow_gpu==2.3.0+computecanada) (1.16.0+computecanada)
Requirement already satisfied: wheel>=0.26 in /localscratch/yinan.29113217.0/env/lib/python3.7/site-packages (from tensorflow_gpu==2.3.0+computecanada) (0.33.4)
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/google_auth_oauthlib-0.4.6+computecanada-py2.py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/Werkzeug-2.0.3+computecanada-py3-none-any.whl
Requirement already satisfied: setuptools>=41.0.0 in /localscratch/yinan.29113217.0/env/lib/python3.7/site-packages (from tensorboard<3,>=2.3.0->tensorflow_gpu==2.3.0+computecanada) (41.0.1)
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/tensorboard_data_server-0.6.1+computecanada-py3-none-linux_x86_64.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/tensorboard_plugin_wit-1.8.0+computecanada-py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/Markdown-3.3.6+computecanada-py3-none-any.whl
Requirement already satisfied: requests<3,>=2.21.0 in /localscratch/yinan.29113217.0/env/lib/python3.7/site-packages (from tensorboard<3,>=2.3.0->tensorflow_gpu==2.3.0+computecanada) (2.27.1+computecanada)
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/google_auth-2.3.3+computecanada-py2.py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/cachetools-4.2.4+computecanada-py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/pyasn1_modules-0.2.8+computecanada-py2.py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/rsa-4.8+computecanada-py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/requests_oauthlib-1.3.0+computecanada-py2.py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/importlib_metadata-4.10.1+computecanada-py3-none-any.whl
Requirement already satisfied: typing-extensions>=3.6.4 in /localscratch/yinan.29113217.0/env/lib/python3.7/site-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard<3,>=2.3.0->tensorflow_gpu==2.3.0+computecanada) (4.0.1+computecanada)
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/zipp-3.7.0+computecanada-py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/pyasn1-0.4.8+computecanada-py2.py3-none-any.whl
Requirement already satisfied: certifi>=2017.4.17 in /cvmfs/soft.computecanada.ca/easybuild/software/2017/Core/scipy-stack/2019a/lib/python3.7/site-packages (from requests<3,>=2.21.0->tensorboard<3,>=2.3.0->tensorflow_gpu==2.3.0+computecanada) (2018.11.29)
Requirement already satisfied: urllib3<1.27,>=1.21.1 in /localscratch/yinan.29113217.0/env/lib/python3.7/site-packages (from requests<3,>=2.21.0->tensorboard<3,>=2.3.0->tensorflow_gpu==2.3.0+computecanada) (1.26.8+computecanada)
Requirement already satisfied: idna<4,>=2.5 in /cvmfs/soft.computecanada.ca/easybuild/software/2017/Core/scipy-stack/2019a/lib/python3.7/site-packages (from requests<3,>=2.21.0->tensorboard<3,>=2.3.0->tensorflow_gpu==2.3.0+computecanada) (2.8)
Requirement already satisfied: charset-normalizer~=2.0.0 in /localscratch/yinan.29113217.0/env/lib/python3.7/site-packages (from requests<3,>=2.21.0->tensorboard<3,>=2.3.0->tensorflow_gpu==2.3.0+computecanada) (2.0.12+computecanada)
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/oauthlib-3.1.1+computecanada-py2.py3-none-any.whl
Installing collected packages: pyasn1, zipp, rsa, pyasn1-modules, oauthlib, cachetools, requests-oauthlib, importlib-metadata, google-auth, werkzeug, tensorboard-plugin-wit, tensorboard-data-server, markdown, grpcio, google-auth-oauthlib, absl-py, wrapt, tensorflow-estimator, tensorboard, scipy, opt-einsum, keras-preprocessing, h5py, google-pasta, gast, astunparse, tensorflow-gpu
  Attempting uninstall: pyasn1
    Found existing installation: pyasn1 0.4.3
    Not uninstalling pyasn1 at /cvmfs/soft.computecanada.ca/easybuild/software/2017/Core/scipy-stack/2019a/lib/python3.7/site-packages, outside environment /localscratch/yinan.29113217.0/env
    Can't uninstall 'pyasn1'. No files were found to uninstall.
  Attempting uninstall: zipp
    Found existing installation: zipp 0.3.3
    Not uninstalling zipp at /cvmfs/soft.computecanada.ca/easybuild/software/2017/Core/scipy-stack/2019a/lib/python3.7/site-packages, outside environment /localscratch/yinan.29113217.0/env
    Can't uninstall 'zipp'. No files were found to uninstall.
  Attempting uninstall: importlib-metadata
    Found existing installation: importlib-metadata 0.8
    Not uninstalling importlib-metadata at /cvmfs/soft.computecanada.ca/easybuild/software/2017/Core/scipy-stack/2019a/lib/python3.7/site-packages, outside environment /localscratch/yinan.29113217.0/env
    Can't uninstall 'importlib-metadata'. No files were found to uninstall.
  Attempting uninstall: scipy
    Found existing installation: scipy 1.2.0
    Not uninstalling scipy at /cvmfs/soft.computecanada.ca/easybuild/software/2017/Core/scipy-stack/2019a/lib/python3.7/site-packages, outside environment /localscratch/yinan.29113217.0/env
    Can't uninstall 'scipy'. No files were found to uninstall.
Successfully installed absl-py-1.0.0+computecanada astunparse-1.6.3+computecanada cachetools-4.2.4+computecanada gast-0.3.3+computecanada google-auth-2.3.3+computecanada google-auth-oauthlib-0.4.6+computecanada google-pasta-0.2.0+computecanada grpcio-1.38.0+computecanada h5py-2.10.0+computecanada importlib-metadata-4.10.1+computecanada keras-preprocessing-1.1.2+computecanada markdown-3.3.6+computecanada oauthlib-3.1.1+computecanada opt-einsum-3.3.0+computecanada pyasn1-0.4.8+computecanada pyasn1-modules-0.2.8+computecanada requests-oauthlib-1.3.0+computecanada rsa-4.8+computecanada scipy-1.4.1+computecanada tensorboard-2.8.0+computecanada tensorboard-data-server-0.6.1+computecanada tensorboard-plugin-wit-1.8.0+computecanada tensorflow-estimator-2.3.0+computecanada tensorflow-gpu-2.3.0+computecanada werkzeug-2.0.3+computecanada wrapt-1.11.2+computecanada zipp-3.7.0+computecanada
Looking in links: /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/nix/avx2, /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/nix/generic, /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/keras-2.8.0+computecanada-py2.py3-none-any.whl
Installing collected packages: Keras
Successfully installed Keras-2.8.0+computecanada
Looking in links: /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/nix/avx2, /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/nix/generic, /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/urllib3-1.26.7+computecanada-py2.py3-none-any.whl
Installing collected packages: urllib3
  Attempting uninstall: urllib3
    Found existing installation: urllib3 1.26.8+computecanada
    Uninstalling urllib3-1.26.8+computecanada:
      Successfully uninstalled urllib3-1.26.8+computecanada
Successfully installed urllib3-1.26.7+computecanada
Looking in links: /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/nix/avx2, /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/nix/generic, /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/nltk-3.7+computecanada-py3-none-any.whl
Requirement already satisfied: tqdm in /localscratch/yinan.29113217.0/env/lib/python3.7/site-packages (from nltk) (4.63.0+computecanada)
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/nltk-3.6.5+computecanada-py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/nltk-3.6.3+computecanada-py3-none-any.whl
Requirement already satisfied: regex in /localscratch/yinan.29113217.0/env/lib/python3.7/site-packages (from nltk) (2020.11.13+computecanada)
Requirement already satisfied: joblib in /localscratch/yinan.29113217.0/env/lib/python3.7/site-packages (from nltk) (1.1.0+computecanada)
Requirement already satisfied: click in /localscratch/yinan.29113217.0/env/lib/python3.7/site-packages (from nltk) (8.0.4+computecanada)
Requirement already satisfied: importlib-metadata in /localscratch/yinan.29113217.0/env/lib/python3.7/site-packages (from click->nltk) (4.10.1+computecanada)
Requirement already satisfied: typing-extensions>=3.6.4 in /localscratch/yinan.29113217.0/env/lib/python3.7/site-packages (from importlib-metadata->click->nltk) (4.0.1+computecanada)
Requirement already satisfied: zipp>=0.5 in /localscratch/yinan.29113217.0/env/lib/python3.7/site-packages (from importlib-metadata->click->nltk) (3.7.0+computecanada)
Installing collected packages: nltk
Successfully installed nltk-3.6.3+computecanada
Looking in links: /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/nix/avx2, /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/nix/generic, /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/scikit_learn-0.22.1+computecanada-cp37-cp37m-linux_x86_64.whl
Requirement already satisfied: joblib>=0.11 in /localscratch/yinan.29113217.0/env/lib/python3.7/site-packages (from scikit-learn==0.22.1) (1.1.0+computecanada)
Requirement already satisfied: scipy>=0.17.0 in /localscratch/yinan.29113217.0/env/lib/python3.7/site-packages (from scikit-learn==0.22.1) (1.4.1+computecanada)
Requirement already satisfied: numpy>=1.11.0 in /cvmfs/soft.computecanada.ca/easybuild/software/2017/Core/scipy-stack/2019a/lib/python3.7/site-packages (from scikit-learn==0.22.1) (1.16.0)
Installing collected packages: scikit-learn
Successfully installed scikit-learn-0.22.1+computecanada
Looking in links: /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/nix/avx2, /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/nix/generic, /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic
Requirement already satisfied: tokenizers==0.5.2 in /localscratch/yinan.29113217.0/env/lib/python3.7/site-packages (0.5.2+computecanada)
wandb: Appending key for api.wandb.ai to your netrc file: /home/yinan/.netrc
Starting Task
2022-03-17 06:43:41.978822: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1
[nltk_data] Downloading package stopwords to /home/yinan/nltk_data...
[nltk_data]   Package stopwords is already up-to-date!
[nltk_data] Downloading package wordnet to /home/yinan/nltk_data...
[nltk_data]   Package wordnet is already up-to-date!
wandb: Currently logged in as: yinanazhou (use `wandb login --relogin` to force relogin)
wandb: wandb version 0.12.11 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
2022-03-17 06:43:56.880342: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1
wandb: Tracking run with wandb version 0.12.5
wandb: Syncing run expert-river-1
wandb: ⭐️ View project at https://wandb.ai/yinanazhou/xl_512_bs_8_lr_1e06_es_5_lc_True_nr_False_sr_True_stem_True_lemma_False_repeat_1_fold_1
wandb: 🚀 View run at https://wandb.ai/yinanazhou/xl_512_bs_8_lr_1e06_es_5_lc_True_nr_False_sr_True_stem_True_lemma_False_repeat_1_fold_1/runs/1enqzhjy
wandb: Run data is saved locally in /project/6002780/yinan/Thesis_MER_Lyrics/lyric-emotion/wandb/run-20220317_064354-1enqzhjy
wandb: Run `wandb offline` to turn off syncing.

Validation loss decreased (inf --> 1.430210).  Saving model ...
Validation loss decreased (1.430210 --> 1.412249).  Saving model ...
Validation loss decreased (1.412249 --> 1.397505).  Saving model ...
Validation loss decreased (1.397505 --> 1.384806).  Saving model ...
Validation loss decreased (1.384806 --> 1.375036).  Saving model ...
Validation loss decreased (1.375036 --> 1.366992).  Saving model ...
Validation loss decreased (1.366992 --> 1.360318).  Saving model ...
Validation loss decreased (1.360318 --> 1.354317).  Saving model ...
Validation loss decreased (1.354317 --> 1.349033).  Saving model ...
Validation loss decreased (1.349033 --> 1.343130).  Saving model ...
Validation loss decreased (1.343130 --> 1.337345).  Saving model ...
Validation loss decreased (1.337345 --> 1.332209).  Saving model ...
Validation loss decreased (1.332209 --> 1.326985).  Saving model ...
Validation loss decreased (1.326985 --> 1.322089).  Saving model ...
Validation loss decreased (1.322089 --> 1.316468).  Saving model ...
Validation loss decreased (1.316468 --> 1.311502).  Saving model ...
Validation loss decreased (1.311502 --> 1.306029).  Saving model ...
Validation loss decreased (1.306029 --> 1.300590).  Saving model ...
Validation loss decreased (1.300590 --> 1.295294).  Saving model ...
Validation loss decreased (1.295294 --> 1.289089).  Saving model ...
Validation loss decreased (1.289089 --> 1.283232).  Saving model ...
Validation loss decreased (1.283232 --> 1.277649).  Saving model ...
Validation loss decreased (1.277649 --> 1.271788).  Saving model ...
Validation loss decreased (1.271788 --> 1.266046).  Saving model ...
Validation loss decreased (1.266046 --> 1.260479).  Saving model ...
Validation loss decreased (1.260479 --> 1.255159).  Saving model ...
Validation loss decreased (1.255159 --> 1.249375).  Saving model ...
Validation loss decreased (1.249375 --> 1.244089).  Saving model ...
Validation loss decreased (1.244089 --> 1.239751).  Saving model ...
Validation loss decreased (1.239751 --> 1.234297).  Saving model ...
Validation loss decreased (1.234297 --> 1.229342).  Saving model ...
Validation loss decreased (1.229342 --> 1.224513).  Saving model ...
Validation loss decreased (1.224513 --> 1.219727).  Saving model ...
Validation loss decreased (1.219727 --> 1.214424).  Saving model ...
Validation loss decreased (1.214424 --> 1.210924).  Saving model ...
Validation loss decreased (1.210924 --> 1.206348).  Saving model ...
Validation loss decreased (1.206348 --> 1.201905).  Saving model ...
Validation loss decreased (1.201905 --> 1.197582).  Saving model ...
Validation loss decreased (1.197582 --> 1.194820).  Saving model ...
Validation loss decreased (1.194820 --> 1.190910).  Saving model ...
Validation loss decreased (1.190910 --> 1.184925).  Saving model ...
Validation loss decreased (1.184925 --> 1.182018).  Saving model ...
Validation loss decreased (1.182018 --> 1.179328).  Saving model ...
Validation loss decreased (1.179328 --> 1.175264).  Saving model ...
Validation loss decreased (1.175264 --> 1.172412).  Saving model ...
Validation loss decreased (1.172412 --> 1.167712).  Saving model ...
Validation loss decreased (1.167712 --> 1.163357).  Saving model ...
Validation loss decreased (1.163357 --> 1.162127).  Saving model ...
Validation loss decreased (1.162127 --> 1.156737).  Saving model ...
Validation loss decreased (1.156737 --> 1.151515).  Saving model ...
Validation loss decreased (1.151515 --> 1.148340).  Saving model ...
Validation loss decreased (1.148340 --> 1.145097).  Saving model ...
Validation loss decreased (1.145097 --> 1.142837).  Saving model ...
Validation loss decreased (1.142837 --> 1.141051).  Saving model ...
Validation loss decreased (1.141051 --> 1.138547).  Saving model ...
Validation loss decreased (1.138547 --> 1.131931).  Saving model ...
Validation loss decreased (1.131931 --> 1.129908).  Saving model ...
Validation loss decreased (1.129908 --> 1.126883).  Saving model ...
Validation loss decreased (1.126883 --> 1.121798).  Saving model ...
Validation loss decreased (1.121798 --> 1.120669).  Saving model ...
Validation loss decreased (1.120669 --> 1.118011).  Saving model ...
Validation loss decreased (1.118011 --> 1.116920).  Saving model ...
Validation loss decreased (1.116920 --> 1.112071).  Saving model ...
Validation loss decreased (1.112071 --> 1.109591).  Saving model ...
EarlyStopping counter: 1 out of 5.0
Validation loss decreased (1.109591 --> 1.106922).  Saving model ...
Validation loss decreased (1.106922 --> 1.103593).  Saving model ...
Validation loss decreased (1.103593 --> 1.098547).  Saving model ...
Validation loss decreased (1.098547 --> 1.095867).  Saving model ...
Validation loss decreased (1.095867 --> 1.092458).  Saving model ...
Validation loss decreased (1.092458 --> 1.088707).  Saving model ...
EarlyStopping counter: 1 out of 5.0
Validation loss decreased (1.088707 --> 1.085272).  Saving model ...
Validation loss decreased (1.085272 --> 1.082917).  Saving model ...
Validation loss decreased (1.082917 --> 1.080597).  Saving model ...
Validation loss decreased (1.080597 --> 1.079706).  Saving model ...
Validation loss decreased (1.079706 --> 1.079162).  Saving model ...
Validation loss decreased (1.079162 --> 1.076865).  Saving model ...
Validation loss decreased (1.076865 --> 1.071596).  Saving model ...
Validation loss decreased (1.071596 --> 1.068601).  Saving model ...
Validation loss decreased (1.068601 --> 1.068073).  Saving model ...
Validation loss decreased (1.068073 --> 1.066345).  Saving model ...
Validation loss decreased (1.066345 --> 1.064647).  Saving model ...
EarlyStopping counter: 1 out of 5.0
Validation loss decreased (1.064647 --> 1.060166).  Saving model ...
Validation loss decreased (1.060166 --> 1.059190).  Saving model ...
Validation loss decreased (1.059190 --> 1.056568).  Saving model ...
EarlyStopping counter: 1 out of 5.0
Validation loss decreased (1.056568 --> 1.054544).  Saving model ...
Validation loss decreased (1.054544 --> 1.050973).  Saving model ...
EarlyStopping counter: 1 out of 5.0
Validation loss decreased (1.050973 --> 1.050481).  Saving model ...
Validation loss decreased (1.050481 --> 1.048481).  Saving model ...
EarlyStopping counter: 1 out of 5.0
EarlyStopping counter: 2 out of 5.0
Validation loss decreased (1.048481 --> 1.047805).  Saving model ...
Validation loss decreased (1.047805 --> 1.044778).  Saving model ...
Validation loss decreased (1.044778 --> 1.040265).  Saving model ...
Validation loss decreased (1.040265 --> 1.038755).  Saving model ...
EarlyStopping counter: 1 out of 5.0
Validation loss decreased (1.038755 --> 1.037378).  Saving model ...
Validation loss decreased (1.037378 --> 1.036332).  Saving model ...
EarlyStopping counter: 1 out of 5.0
EarlyStopping counter: 2 out of 5.0
EarlyStopping counter: 3 out of 5.0
Validation loss decreased (1.036332 --> 1.033114).  Saving model ...
Validation loss decreased (1.033114 --> 1.032515).  Saving model ...
EarlyStopping counter: 1 out of 5.0
Validation loss decreased (1.032515 --> 1.029543).  Saving model ...
Validation loss decreased (1.029543 --> 1.026258).  Saving model ...
EarlyStopping counter: 1 out of 5.0
EarlyStopping counter: 2 out of 5.0
EarlyStopping counter: 3 out of 5.0
EarlyStopping counter: 4 out of 5.0
EarlyStopping counter: 5 out of 5.0
/localscratch/yinan.29113217.0/env/lib/python3.7/site-packages/torch/nn/functional.py:1794: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.
  warnings.warn("nn.functional.tanh is deprecated. Use torch.tanh instead.")
/localscratch/yinan.29113217.0/env/lib/python3.7/site-packages/transformers/optimization.py:155: UserWarning: This overload of add_ is deprecated:
	add_(Number alpha, Tensor other)
Consider using one of the following signatures instead:
	add_(Tensor other, *, Number alpha) (Triggered internally at  ../torch/csrc/utils/python_arg_parser.cpp:1025.)
  exp_avg.mul_(beta1).add_(1.0 - beta1, grad)
wandb: Waiting for W&B process to finish, PID 154222... (success).
wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: \ 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: | 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: / 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: \ 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: | 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: / 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: \ 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: | 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: / 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb:                                                                                
wandb: Run history:
wandb:     e_F1 ▁▂▃▄▅▅▅▆▆▆▆▆▆▆▇▆▇▇▇▇▇▇▇▇▇▇▇▇▇▇██████████
wandb:   e_loss █▇▇▇▆▆▆▅▅▅▅▄▄▄▄▄▃▃▃▃▃▃▂▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁
wandb:     t_F1 ▁▂▂▃▃▃▃▅▄▅▅▅▆▅▆▆▆▆▇▆▇▇▇▇▇▇▇▇▇▇▇▇▇▇██████
wandb:   t_loss ██▇▇▇▇▆▆▆▆▅▅▅▅▄▄▄▄▃▄▃▃▃▃▃▂▂▃▂▂▂▂▂▂▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:     e_F1 55.2089
wandb:   e_loss 1.02846
wandb:     t_F1 68.13061
wandb:   t_loss 0.82274
wandb: 
wandb: Synced 4 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Synced expert-river-1: https://wandb.ai/yinanazhou/xl_512_bs_8_lr_1e06_es_5_lc_True_nr_False_sr_True_stem_True_lemma_False_repeat_1_fold_1/runs/1enqzhjy
wandb: Find logs at: ./wandb/run-20220317_064354-1enqzhjy/logs/debug.log
wandb: 

wandb: wandb version 0.12.11 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
2022-03-17 07:59:33.301187: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1
wandb: Tracking run with wandb version 0.12.5
wandb: Syncing run firm-waterfall-1
wandb: ⭐️ View project at https://wandb.ai/yinanazhou/xl_512_bs_8_lr_1e06_es_5_lc_True_nr_False_sr_True_stem_True_lemma_False_repeat_1_fold_2
wandb: 🚀 View run at https://wandb.ai/yinanazhou/xl_512_bs_8_lr_1e06_es_5_lc_True_nr_False_sr_True_stem_True_lemma_False_repeat_1_fold_2/runs/t4pfg2a7
wandb: Run data is saved locally in /project/6002780/yinan/Thesis_MER_Lyrics/lyric-emotion/wandb/run-20220317_075931-t4pfg2a7
wandb: Run `wandb offline` to turn off syncing.

Validation loss decreased (inf --> 1.424899).  Saving model ...
Validation loss decreased (1.424899 --> 1.412645).  Saving model ...
Validation loss decreased (1.412645 --> 1.404388).  Saving model ...
Validation loss decreased (1.404388 --> 1.397536).  Saving model ...
Validation loss decreased (1.397536 --> 1.391308).  Saving model ...
Validation loss decreased (1.391308 --> 1.386314).  Saving model ...
Validation loss decreased (1.386314 --> 1.381865).  Saving model ...
Validation loss decreased (1.381865 --> 1.377948).  Saving model ...
Validation loss decreased (1.377948 --> 1.374083).  Saving model ...
Validation loss decreased (1.374083 --> 1.370301).  Saving model ...
Validation loss decreased (1.370301 --> 1.366430).  Saving model ...
Validation loss decreased (1.366430 --> 1.362205).  Saving model ...
Validation loss decreased (1.362205 --> 1.358616).  Saving model ...
Validation loss decreased (1.358616 --> 1.354907).  Saving model ...
Validation loss decreased (1.354907 --> 1.351550).  Saving model ...
Validation loss decreased (1.351550 --> 1.347756).  Saving model ...
Validation loss decreased (1.347756 --> 1.343836).  Saving model ...
Validation loss decreased (1.343836 --> 1.339589).  Saving model ...
Validation loss decreased (1.339589 --> 1.334959).  Saving model ...
Validation loss decreased (1.334959 --> 1.330337).  Saving model ...
Validation loss decreased (1.330337 --> 1.325332).  Saving model ...
Validation loss decreased (1.325332 --> 1.320676).  Saving model ...
Validation loss decreased (1.320676 --> 1.315705).  Saving model ...
Validation loss decreased (1.315705 --> 1.310749).  Saving model ...
Validation loss decreased (1.310749 --> 1.305425).  Saving model ...
Validation loss decreased (1.305425 --> 1.299349).  Saving model ...
Validation loss decreased (1.299349 --> 1.293728).  Saving model ...
Validation loss decreased (1.293728 --> 1.287795).  Saving model ...
Validation loss decreased (1.287795 --> 1.281873).  Saving model ...
Validation loss decreased (1.281873 --> 1.275982).  Saving model ...
Validation loss decreased (1.275982 --> 1.269941).  Saving model ...
Validation loss decreased (1.269941 --> 1.263132).  Saving model ...
Validation loss decreased (1.263132 --> 1.256503).  Saving model ...
Validation loss decreased (1.256503 --> 1.250249).  Saving model ...
Validation loss decreased (1.250249 --> 1.242708).  Saving model ...
Validation loss decreased (1.242708 --> 1.234643).  Saving model ...
Validation loss decreased (1.234643 --> 1.227487).  Saving model ...
Validation loss decreased (1.227487 --> 1.220780).  Saving model ...
Validation loss decreased (1.220780 --> 1.213664).  Saving model ...
Validation loss decreased (1.213664 --> 1.206414).  Saving model ...
Validation loss decreased (1.206414 --> 1.199263).  Saving model ...
Validation loss decreased (1.199263 --> 1.192513).  Saving model ...
Validation loss decreased (1.192513 --> 1.185575).  Saving model ...
Validation loss decreased (1.185575 --> 1.177506).  Saving model ...
Validation loss decreased (1.177506 --> 1.172077).  Saving model ...
Validation loss decreased (1.172077 --> 1.166814).  Saving model ...
Validation loss decreased (1.166814 --> 1.158657).  Saving model ...
Validation loss decreased (1.158657 --> 1.153026).  Saving model ...
Validation loss decreased (1.153026 --> 1.148694).  Saving model ...
Validation loss decreased (1.148694 --> 1.142896).  Saving model ...
Validation loss decreased (1.142896 --> 1.136482).  Saving model ...
Validation loss decreased (1.136482 --> 1.130661).  Saving model ...
Validation loss decreased (1.130661 --> 1.123841).  Saving model ...
Validation loss decreased (1.123841 --> 1.119618).  Saving model ...
Validation loss decreased (1.119618 --> 1.114559).  Saving model ...
Validation loss decreased (1.114559 --> 1.109805).  Saving model ...
Validation loss decreased (1.109805 --> 1.102549).  Saving model ...
Validation loss decreased (1.102549 --> 1.097280).  Saving model ...
Validation loss decreased (1.097280 --> 1.091677).  Saving model ...
Validation loss decreased (1.091677 --> 1.088383).  Saving model ...
Validation loss decreased (1.088383 --> 1.083826).  Saving model ...
Validation loss decreased (1.083826 --> 1.080256).  Saving model ...
Validation loss decreased (1.080256 --> 1.074270).  Saving model ...
Validation loss decreased (1.074270 --> 1.070467).  Saving model ...
Validation loss decreased (1.070467 --> 1.067159).  Saving model ...
Validation loss decreased (1.067159 --> 1.060483).  Saving model ...
Validation loss decreased (1.060483 --> 1.056085).  Saving model ...
Validation loss decreased (1.056085 --> 1.054257).  Saving model ...
Validation loss decreased (1.054257 --> 1.050616).  Saving model ...
Validation loss decreased (1.050616 --> 1.045709).  Saving model ...
Validation loss decreased (1.045709 --> 1.044221).  Saving model ...
Validation loss decreased (1.044221 --> 1.039205).  Saving model ...
Validation loss decreased (1.039205 --> 1.034931).  Saving model ...
Validation loss decreased (1.034931 --> 1.032584).  Saving model ...
Validation loss decreased (1.032584 --> 1.029242).  Saving model ...
Validation loss decreased (1.029242 --> 1.026816).  Saving model ...
Validation loss decreased (1.026816 --> 1.025242).  Saving model ...
Validation loss decreased (1.025242 --> 1.022660).  Saving model ...
Validation loss decreased (1.022660 --> 1.020558).  Saving model ...
Validation loss decreased (1.020558 --> 1.017036).  Saving model ...
Validation loss decreased (1.017036 --> 1.016039).  Saving model ...
Validation loss decreased (1.016039 --> 1.011752).  Saving model ...
Validation loss decreased (1.011752 --> 1.009273).  Saving model ...
Validation loss decreased (1.009273 --> 1.005026).  Saving model ...
Validation loss decreased (1.005026 --> 1.003100).  Saving model ...
Validation loss decreased (1.003100 --> 1.000594).  Saving model ...
Validation loss decreased (1.000594 --> 0.997433).  Saving model ...
Validation loss decreased (0.997433 --> 0.996225).  Saving model ...
Validation loss decreased (0.996225 --> 0.994128).  Saving model ...
Validation loss decreased (0.994128 --> 0.990937).  Saving model ...
EarlyStopping counter: 1 out of 5.0
Validation loss decreased (0.990937 --> 0.986648).  Saving model ...
Validation loss decreased (0.986648 --> 0.985274).  Saving model ...
Validation loss decreased (0.985274 --> 0.983598).  Saving model ...
EarlyStopping counter: 1 out of 5.0
Validation loss decreased (0.983598 --> 0.981975).  Saving model ...
Validation loss decreased (0.981975 --> 0.976968).  Saving model ...
Validation loss decreased (0.976968 --> 0.973873).  Saving model ...
EarlyStopping counter: 1 out of 5.0
Validation loss decreased (0.973873 --> 0.972460).  Saving model ...
EarlyStopping counter: 1 out of 5.0
Validation loss decreased (0.972460 --> 0.972034).  Saving model ...
Validation loss decreased (0.972034 --> 0.971295).  Saving model ...
Validation loss decreased (0.971295 --> 0.968873).  Saving model ...
Validation loss decreased (0.968873 --> 0.967209).  Saving model ...
EarlyStopping counter: 1 out of 5.0
Validation loss decreased (0.967209 --> 0.966009).  Saving model ...
Validation loss decreased (0.966009 --> 0.962368).  Saving model ...
EarlyStopping counter: 1 out of 5.0
Validation loss decreased (0.962368 --> 0.961204).  Saving model ...
EarlyStopping counter: 1 out of 5.0
EarlyStopping counter: 2 out of 5.0
Validation loss decreased (0.961204 --> 0.959424).  Saving model ...
Validation loss decreased (0.959424 --> 0.958024).  Saving model ...
EarlyStopping counter: 1 out of 5.0
EarlyStopping counter: 2 out of 5.0
Validation loss decreased (0.958024 --> 0.957401).  Saving model ...
Validation loss decreased (0.957401 --> 0.956998).  Saving model ...
Validation loss decreased (0.956998 --> 0.954524).  Saving model ...
Validation loss decreased (0.954524 --> 0.954109).  Saving model ...
Validation loss decreased (0.954109 --> 0.952278).  Saving model ...
EarlyStopping counter: 1 out of 5.0
Validation loss decreased (0.952278 --> 0.951449).  Saving model ...
Validation loss decreased (0.951449 --> 0.950285).  Saving model ...
EarlyStopping counter: 1 out of 5.0
EarlyStopping counter: 2 out of 5.0
Validation loss decreased (0.950285 --> 0.949642).  Saving model ...
Validation loss decreased (0.949642 --> 0.946941).  Saving model ...
Validation loss decreased (0.946941 --> 0.944576).  Saving model ...
EarlyStopping counter: 1 out of 5.0
EarlyStopping counter: 2 out of 5.0
EarlyStopping counter: 3 out of 5.0
EarlyStopping counter: 4 out of 5.0
EarlyStopping counter: 5 out of 5.0
/localscratch/yinan.29113217.0/env/lib/python3.7/site-packages/torch/nn/functional.py:1794: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.
  warnings.warn("nn.functional.tanh is deprecated. Use torch.tanh instead.")
wandb: Waiting for W&B process to finish, PID 158287... (success).
wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: \ 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: | 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: / 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: \ 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: | 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: / 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: \ 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: | 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: / 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb:                                                                                
wandb: Run history:
wandb:     e_F1 ▁▁▃▃▄▄▅▅▅▆▆▆▆▆▆▇▇▇▇▇▇▇▇▇▇▇██████████████
wandb:   e_loss ██▇▇▇▇▇▆▆▆▆▅▅▄▄▄▃▃▃▃▃▂▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁
wandb:     t_F1 ▁▂▂▂▂▃▃▄▄▄▄▅▄▅▆▆▅▆▆▆▆▆▇▇▇▇▇▇▇▇█▇█▇▇████▇
wandb:   t_loss ██▇▇▇▇▇▇▆▆▆▆▅▅▅▅▅▄▄▄▄▄▃▃▃▃▃▃▂▂▂▂▂▂▂▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:     e_F1 59.3998
wandb:   e_loss 0.94599
wandb:     t_F1 66.89705
wandb:   t_loss 0.81599
wandb: 
wandb: Synced 4 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Synced firm-waterfall-1: https://wandb.ai/yinanazhou/xl_512_bs_8_lr_1e06_es_5_lc_True_nr_False_sr_True_stem_True_lemma_False_repeat_1_fold_2/runs/t4pfg2a7
wandb: Find logs at: ./wandb/run-20220317_075931-t4pfg2a7/logs/debug.log
wandb: 

wandb: wandb version 0.12.11 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
2022-03-17 09:26:30.125957: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1
wandb: Tracking run with wandb version 0.12.5
wandb: Syncing run smooth-fog-1
wandb: ⭐️ View project at https://wandb.ai/yinanazhou/xl_512_bs_8_lr_1e06_es_5_lc_True_nr_False_sr_True_stem_True_lemma_False_repeat_2_fold_1
wandb: 🚀 View run at https://wandb.ai/yinanazhou/xl_512_bs_8_lr_1e06_es_5_lc_True_nr_False_sr_True_stem_True_lemma_False_repeat_2_fold_1/runs/d5za2204
wandb: Run data is saved locally in /project/6002780/yinan/Thesis_MER_Lyrics/lyric-emotion/wandb/run-20220317_092627-d5za2204
wandb: Run `wandb offline` to turn off syncing.

Validation loss decreased (inf --> 1.531731).  Saving model ...
Validation loss decreased (1.531731 --> 1.498250).  Saving model ...
Validation loss decreased (1.498250 --> 1.470547).  Saving model ...
Validation loss decreased (1.470547 --> 1.448558).  Saving model ...
Validation loss decreased (1.448558 --> 1.431460).  Saving model ...
Validation loss decreased (1.431460 --> 1.417882).  Saving model ...
Validation loss decreased (1.417882 --> 1.406814).  Saving model ...
Validation loss decreased (1.406814 --> 1.398453).  Saving model ...
Validation loss decreased (1.398453 --> 1.391712).  Saving model ...
Validation loss decreased (1.391712 --> 1.385684).  Saving model ...
Validation loss decreased (1.385684 --> 1.380135).  Saving model ...
Validation loss decreased (1.380135 --> 1.374754).  Saving model ...
Validation loss decreased (1.374754 --> 1.369749).  Saving model ...
Validation loss decreased (1.369749 --> 1.364651).  Saving model ...
Validation loss decreased (1.364651 --> 1.360104).  Saving model ...
Validation loss decreased (1.360104 --> 1.355309).  Saving model ...
Validation loss decreased (1.355309 --> 1.350079).  Saving model ...
Validation loss decreased (1.350079 --> 1.345045).  Saving model ...
Validation loss decreased (1.345045 --> 1.339617).  Saving model ...
Validation loss decreased (1.339617 --> 1.334372).  Saving model ...
Validation loss decreased (1.334372 --> 1.328600).  Saving model ...
Validation loss decreased (1.328600 --> 1.322675).  Saving model ...
Validation loss decreased (1.322675 --> 1.316415).  Saving model ...
Validation loss decreased (1.316415 --> 1.310861).  Saving model ...
Validation loss decreased (1.310861 --> 1.303765).  Saving model ...
Validation loss decreased (1.303765 --> 1.297080).  Saving model ...
Validation loss decreased (1.297080 --> 1.290321).  Saving model ...
Validation loss decreased (1.290321 --> 1.284158).  Saving model ...
Validation loss decreased (1.284158 --> 1.276854).  Saving model ...
Validation loss decreased (1.276854 --> 1.269997).  Saving model ...
Validation loss decreased (1.269997 --> 1.263290).  Saving model ...
Validation loss decreased (1.263290 --> 1.256484).  Saving model ...
Validation loss decreased (1.256484 --> 1.249860).  Saving model ...
Validation loss decreased (1.249860 --> 1.242763).  Saving model ...
Validation loss decreased (1.242763 --> 1.236230).  Saving model ...
Validation loss decreased (1.236230 --> 1.229337).  Saving model ...
Validation loss decreased (1.229337 --> 1.222224).  Saving model ...
Validation loss decreased (1.222224 --> 1.214785).  Saving model ...
Validation loss decreased (1.214785 --> 1.207595).  Saving model ...
Validation loss decreased (1.207595 --> 1.201804).  Saving model ...
Validation loss decreased (1.201804 --> 1.195534).  Saving model ...
Validation loss decreased (1.195534 --> 1.189867).  Saving model ...
Validation loss decreased (1.189867 --> 1.184301).  Saving model ...
Validation loss decreased (1.184301 --> 1.178989).  Saving model ...
Validation loss decreased (1.178989 --> 1.172117).  Saving model ...
Validation loss decreased (1.172117 --> 1.166551).  Saving model ...
Validation loss decreased (1.166551 --> 1.160779).  Saving model ...
Validation loss decreased (1.160779 --> 1.156225).  Saving model ...
Validation loss decreased (1.156225 --> 1.152075).  Saving model ...
Validation loss decreased (1.152075 --> 1.147342).  Saving model ...
Validation loss decreased (1.147342 --> 1.140659).  Saving model ...
Validation loss decreased (1.140659 --> 1.136032).  Saving model ...
Validation loss decreased (1.136032 --> 1.131661).  Saving model ...
Validation loss decreased (1.131661 --> 1.126391).  Saving model ...
Validation loss decreased (1.126391 --> 1.120645).  Saving model ...
Validation loss decreased (1.120645 --> 1.115353).  Saving model ...
Validation loss decreased (1.115353 --> 1.111310).  Saving model ...
Validation loss decreased (1.111310 --> 1.105635).  Saving model ...
Validation loss decreased (1.105635 --> 1.099248).  Saving model ...
Validation loss decreased (1.099248 --> 1.095332).  Saving model ...
Validation loss decreased (1.095332 --> 1.092467).  Saving model ...
Validation loss decreased (1.092467 --> 1.087163).  Saving model ...
Validation loss decreased (1.087163 --> 1.083274).  Saving model ...
Validation loss decreased (1.083274 --> 1.079044).  Saving model ...
Validation loss decreased (1.079044 --> 1.074866).  Saving model ...
Validation loss decreased (1.074866 --> 1.071148).  Saving model ...
Validation loss decreased (1.071148 --> 1.066386).  Saving model ...
Validation loss decreased (1.066386 --> 1.064069).  Saving model ...
Validation loss decreased (1.064069 --> 1.060707).  Saving model ...
Validation loss decreased (1.060707 --> 1.058645).  Saving model ...
Validation loss decreased (1.058645 --> 1.054864).  Saving model ...
Validation loss decreased (1.054864 --> 1.052601).  Saving model ...
Validation loss decreased (1.052601 --> 1.049273).  Saving model ...
Validation loss decreased (1.049273 --> 1.044288).  Saving model ...
Validation loss decreased (1.044288 --> 1.043216).  Saving model ...
Validation loss decreased (1.043216 --> 1.039664).  Saving model ...
Validation loss decreased (1.039664 --> 1.037080).  Saving model ...
Validation loss decreased (1.037080 --> 1.035481).  Saving model ...
Validation loss decreased (1.035481 --> 1.032573).  Saving model ...
Validation loss decreased (1.032573 --> 1.029712).  Saving model ...
Validation loss decreased (1.029712 --> 1.027360).  Saving model ...
Validation loss decreased (1.027360 --> 1.026883).  Saving model ...
Validation loss decreased (1.026883 --> 1.023781).  Saving model ...
Validation loss decreased (1.023781 --> 1.018534).  Saving model ...
EarlyStopping counter: 1 out of 5.0
Validation loss decreased (1.018534 --> 1.015662).  Saving model ...
Validation loss decreased (1.015662 --> 1.014595).  Saving model ...
Validation loss decreased (1.014595 --> 1.012670).  Saving model ...
Validation loss decreased (1.012670 --> 1.009546).  Saving model ...
EarlyStopping counter: 1 out of 5.0
Validation loss decreased (1.009546 --> 1.009432).  Saving model ...
Validation loss decreased (1.009432 --> 1.006908).  Saving model ...
Validation loss decreased (1.006908 --> 1.003492).  Saving model ...
Validation loss decreased (1.003492 --> 1.001101).  Saving model ...
Validation loss decreased (1.001101 --> 1.000415).  Saving model ...
Validation loss decreased (1.000415 --> 0.999299).  Saving model ...
Validation loss decreased (0.999299 --> 0.998195).  Saving model ...
Validation loss decreased (0.998195 --> 0.996368).  Saving model ...
Validation loss decreased (0.996368 --> 0.993830).  Saving model ...
Validation loss decreased (0.993830 --> 0.991255).  Saving model ...
EarlyStopping counter: 1 out of 5.0
EarlyStopping counter: 2 out of 5.0
EarlyStopping counter: 3 out of 5.0
Validation loss decreased (0.991255 --> 0.990174).  Saving model ...
Validation loss decreased (0.990174 --> 0.989180).  Saving model ...
EarlyStopping counter: 1 out of 5.0
Validation loss decreased (0.989180 --> 0.988331).  Saving model ...
Validation loss decreased (0.988331 --> 0.988155).  Saving model ...
Validation loss decreased (0.988155 --> 0.988055).  Saving model ...
EarlyStopping counter: 1 out of 5.0
Validation loss decreased (0.988055 --> 0.986729).  Saving model ...
Validation loss decreased (0.986729 --> 0.985544).  Saving model ...
Validation loss decreased (0.985544 --> 0.984231).  Saving model ...
Validation loss decreased (0.984231 --> 0.983221).  Saving model ...
Validation loss decreased (0.983221 --> 0.982659).  Saving model ...
EarlyStopping counter: 1 out of 5.0
EarlyStopping counter: 2 out of 5.0
EarlyStopping counter: 3 out of 5.0
Validation loss decreased (0.982659 --> 0.981450).  Saving model ...
Validation loss decreased (0.981450 --> 0.980543).  Saving model ...
Validation loss decreased (0.980543 --> 0.979671).  Saving model ...
Validation loss decreased (0.979671 --> 0.979541).  Saving model ...
EarlyStopping counter: 1 out of 5.0
Validation loss decreased (0.979541 --> 0.978497).  Saving model ...
Validation loss decreased (0.978497 --> 0.978009).  Saving model ...
EarlyStopping counter: 1 out of 5.0
EarlyStopping counter: 2 out of 5.0
EarlyStopping counter: 3 out of 5.0
EarlyStopping counter: 4 out of 5.0
EarlyStopping counter: 5 out of 5.0
/localscratch/yinan.29113217.0/env/lib/python3.7/site-packages/torch/nn/functional.py:1794: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.
  warnings.warn("nn.functional.tanh is deprecated. Use torch.tanh instead.")
wandb: Waiting for W&B process to finish, PID 162961... (success).
wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: \ 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: | 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: / 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: \ 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: | 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: / 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: \ 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: | 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: / 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: \ 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: | 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: / 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: \ 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: | 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb:                                                                                
wandb: Run history:
wandb:     e_F1 ▁▁▂▃▅▅▅▅▆▆▆▆▆▆▇▇▇▇▇▇▇▇██████████████████
wandb:   e_loss █▇▇▆▆▆▆▅▅▅▅▄▄▄▄▃▃▃▃▂▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:     t_F1 ▁▁▂▂▃▃▃▄▄▅▅▅▅▆▆▆▆▆▆▇▇▇▇▇▇▇▇▇██▇█▇████▇██
wandb:   t_loss ██▇▇▇▇▆▆▆▆▆▅▅▅▅▄▄▄▄▄▄▃▃▃▃▃▂▂▂▂▂▂▂▂▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:     e_F1 58.04728
wandb:   e_loss 0.98067
wandb:     t_F1 69.48772
wandb:   t_loss 0.7785
wandb: 
wandb: Synced 4 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Synced smooth-fog-1: https://wandb.ai/yinanazhou/xl_512_bs_8_lr_1e06_es_5_lc_True_nr_False_sr_True_stem_True_lemma_False_repeat_2_fold_1/runs/d5za2204
wandb: Find logs at: ./wandb/run-20220317_092627-d5za2204/logs/debug.log
wandb: 

wandb: wandb version 0.12.11 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
2022-03-17 10:50:26.834299: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1
wandb: Tracking run with wandb version 0.12.5
wandb: Syncing run devout-river-1
wandb: ⭐️ View project at https://wandb.ai/yinanazhou/xl_512_bs_8_lr_1e06_es_5_lc_True_nr_False_sr_True_stem_True_lemma_False_repeat_2_fold_2
wandb: 🚀 View run at https://wandb.ai/yinanazhou/xl_512_bs_8_lr_1e06_es_5_lc_True_nr_False_sr_True_stem_True_lemma_False_repeat_2_fold_2/runs/175oqg99
wandb: Run data is saved locally in /project/6002780/yinan/Thesis_MER_Lyrics/lyric-emotion/wandb/run-20220317_105023-175oqg99
wandb: Run `wandb offline` to turn off syncing.

Validation loss decreased (inf --> 1.423722).  Saving model ...
Validation loss decreased (1.423722 --> 1.408859).  Saving model ...
Validation loss decreased (1.408859 --> 1.396492).  Saving model ...
Validation loss decreased (1.396492 --> 1.386977).  Saving model ...
Validation loss decreased (1.386977 --> 1.379065).  Saving model ...
Validation loss decreased (1.379065 --> 1.371618).  Saving model ...
Validation loss decreased (1.371618 --> 1.365249).  Saving model ...
Validation loss decreased (1.365249 --> 1.360381).  Saving model ...
Validation loss decreased (1.360381 --> 1.355420).  Saving model ...
Validation loss decreased (1.355420 --> 1.351495).  Saving model ...
Validation loss decreased (1.351495 --> 1.347099).  Saving model ...
Validation loss decreased (1.347099 --> 1.342944).  Saving model ...
Validation loss decreased (1.342944 --> 1.338513).  Saving model ...
Validation loss decreased (1.338513 --> 1.333727).  Saving model ...
Validation loss decreased (1.333727 --> 1.329393).  Saving model ...
Validation loss decreased (1.329393 --> 1.324748).  Saving model ...
Validation loss decreased (1.324748 --> 1.320541).  Saving model ...
Validation loss decreased (1.320541 --> 1.316153).  Saving model ...
Validation loss decreased (1.316153 --> 1.311506).  Saving model ...
Validation loss decreased (1.311506 --> 1.306815).  Saving model ...
Validation loss decreased (1.306815 --> 1.301421).  Saving model ...
Validation loss decreased (1.301421 --> 1.296445).  Saving model ...
Validation loss decreased (1.296445 --> 1.291252).  Saving model ...
Validation loss decreased (1.291252 --> 1.286338).  Saving model ...
Validation loss decreased (1.286338 --> 1.280957).  Saving model ...
Validation loss decreased (1.280957 --> 1.275420).  Saving model ...
Validation loss decreased (1.275420 --> 1.269878).  Saving model ...
Validation loss decreased (1.269878 --> 1.263611).  Saving model ...
Validation loss decreased (1.263611 --> 1.257738).  Saving model ...
Validation loss decreased (1.257738 --> 1.251483).  Saving model ...
Validation loss decreased (1.251483 --> 1.245785).  Saving model ...
Validation loss decreased (1.245785 --> 1.239502).  Saving model ...
Validation loss decreased (1.239502 --> 1.234115).  Saving model ...
Validation loss decreased (1.234115 --> 1.226426).  Saving model ...
Validation loss decreased (1.226426 --> 1.220437).  Saving model ...
Validation loss decreased (1.220437 --> 1.215141).  Saving model ...
Validation loss decreased (1.215141 --> 1.209450).  Saving model ...
Validation loss decreased (1.209450 --> 1.204281).  Saving model ...
Validation loss decreased (1.204281 --> 1.198700).  Saving model ...
Validation loss decreased (1.198700 --> 1.194398).  Saving model ...
Validation loss decreased (1.194398 --> 1.189426).  Saving model ...
Validation loss decreased (1.189426 --> 1.183459).  Saving model ...
Validation loss decreased (1.183459 --> 1.178347).  Saving model ...
Validation loss decreased (1.178347 --> 1.172608).  Saving model ...
Validation loss decreased (1.172608 --> 1.168673).  Saving model ...
Validation loss decreased (1.168673 --> 1.164296).  Saving model ...
Validation loss decreased (1.164296 --> 1.160613).  Saving model ...
Validation loss decreased (1.160613 --> 1.154691).  Saving model ...
Validation loss decreased (1.154691 --> 1.149798).  Saving model ...
Validation loss decreased (1.149798 --> 1.143906).  Saving model ...
Validation loss decreased (1.143906 --> 1.140504).  Saving model ...
Validation loss decreased (1.140504 --> 1.135290).  Saving model ...
Validation loss decreased (1.135290 --> 1.132153).  Saving model ...
Validation loss decreased (1.132153 --> 1.127068).  Saving model ...
Validation loss decreased (1.127068 --> 1.124144).  Saving model ...
Validation loss decreased (1.124144 --> 1.120207).  Saving model ...
Validation loss decreased (1.120207 --> 1.116464).  Saving model ...
Validation loss decreased (1.116464 --> 1.112467).  Saving model ...
Validation loss decreased (1.112467 --> 1.108634).  Saving model ...
Validation loss decreased (1.108634 --> 1.106323).  Saving model ...
Validation loss decreased (1.106323 --> 1.101913).  Saving model ...
Validation loss decreased (1.101913 --> 1.097399).  Saving model ...
Validation loss decreased (1.097399 --> 1.094246).  Saving model ...
Validation loss decreased (1.094246 --> 1.091786).  Saving model ...
Validation loss decreased (1.091786 --> 1.088957).  Saving model ...
Validation loss decreased (1.088957 --> 1.084363).  Saving model ...
Validation loss decreased (1.084363 --> 1.081499).  Saving model ...
Validation loss decreased (1.081499 --> 1.079116).  Saving model ...
Validation loss decreased (1.079116 --> 1.076517).  Saving model ...
Validation loss decreased (1.076517 --> 1.074753).  Saving model ...
Validation loss decreased (1.074753 --> 1.070408).  Saving model ...
Validation loss decreased (1.070408 --> 1.068079).  Saving model ...
Validation loss decreased (1.068079 --> 1.067004).  Saving model ...
Validation loss decreased (1.067004 --> 1.062285).  Saving model ...
Validation loss decreased (1.062285 --> 1.057367).  Saving model ...
Validation loss decreased (1.057367 --> 1.054916).  Saving model ...
Validation loss decreased (1.054916 --> 1.053910).  Saving model ...
Validation loss decreased (1.053910 --> 1.049698).  Saving model ...
Validation loss decreased (1.049698 --> 1.046526).  Saving model ...
Validation loss decreased (1.046526 --> 1.044106).  Saving model ...
Validation loss decreased (1.044106 --> 1.041528).  Saving model ...
Validation loss decreased (1.041528 --> 1.038638).  Saving model ...
Validation loss decreased (1.038638 --> 1.035883).  Saving model ...
Validation loss decreased (1.035883 --> 1.033970).  Saving model ...
Validation loss decreased (1.033970 --> 1.032322).  Saving model ...
Validation loss decreased (1.032322 --> 1.029149).  Saving model ...
Validation loss decreased (1.029149 --> 1.027297).  Saving model ...
Validation loss decreased (1.027297 --> 1.024287).  Saving model ...
Validation loss decreased (1.024287 --> 1.022076).  Saving model ...
Validation loss decreased (1.022076 --> 1.020883).  Saving model ...
Validation loss decreased (1.020883 --> 1.016979).  Saving model ...
Validation loss decreased (1.016979 --> 1.013766).  Saving model ...
Validation loss decreased (1.013766 --> 1.010867).  Saving model ...
Validation loss decreased (1.010867 --> 1.010502).  Saving model ...
Validation loss decreased (1.010502 --> 1.007709).  Saving model ...
EarlyStopping counter: 1 out of 5.0
Validation loss decreased (1.007709 --> 1.006854).  Saving model ...
Validation loss decreased (1.006854 --> 1.004143).  Saving model ...
Validation loss decreased (1.004143 --> 1.003739).  Saving model ...
Validation loss decreased (1.003739 --> 1.001782).  Saving model ...
Validation loss decreased (1.001782 --> 1.000861).  Saving model ...
Validation loss decreased (1.000861 --> 0.999977).  Saving model ...
Validation loss decreased (0.999977 --> 0.997856).  Saving model ...
Validation loss decreased (0.997856 --> 0.995796).  Saving model ...
Validation loss decreased (0.995796 --> 0.992449).  Saving model ...
Validation loss decreased (0.992449 --> 0.990518).  Saving model ...
Validation loss decreased (0.990518 --> 0.988313).  Saving model ...
Validation loss decreased (0.988313 --> 0.986942).  Saving model ...
EarlyStopping counter: 1 out of 5.0
Validation loss decreased (0.986942 --> 0.985477).  Saving model ...
Validation loss decreased (0.985477 --> 0.983157).  Saving model ...
Validation loss decreased (0.983157 --> 0.981398).  Saving model ...
Validation loss decreased (0.981398 --> 0.978656).  Saving model ...
Validation loss decreased (0.978656 --> 0.975745).  Saving model ...
Validation loss decreased (0.975745 --> 0.974608).  Saving model ...
EarlyStopping counter: 1 out of 5.0
Validation loss decreased (0.974608 --> 0.974122).  Saving model ...
Validation loss decreased (0.974122 --> 0.971796).  Saving model ...
Validation loss decreased (0.971796 --> 0.969918).  Saving model ...
Validation loss decreased (0.969918 --> 0.967303).  Saving model ...
Validation loss decreased (0.967303 --> 0.966110).  Saving model ...
EarlyStopping counter: 1 out of 5.0
Validation loss decreased (0.966110 --> 0.964236).  Saving model ...
Validation loss decreased (0.964236 --> 0.963513).  Saving model ...
Validation loss decreased (0.963513 --> 0.963346).  Saving model ...
EarlyStopping counter: 1 out of 5.0
EarlyStopping counter: 2 out of 5.0
Validation loss decreased (0.963346 --> 0.962035).  Saving model ...
EarlyStopping counter: 1 out of 5.0
Validation loss decreased (0.962035 --> 0.958565).  Saving model ...
Validation loss decreased (0.958565 --> 0.956161).  Saving model ...
EarlyStopping counter: 1 out of 5.0
Validation loss decreased (0.956161 --> 0.955178).  Saving model ...
EarlyStopping counter: 1 out of 5.0
EarlyStopping counter: 2 out of 5.0
EarlyStopping counter: 3 out of 5.0
Validation loss decreased (0.955178 --> 0.954901).  Saving model ...
EarlyStopping counter: 1 out of 5.0
Validation loss decreased (0.954901 --> 0.954757).  Saving model ...
EarlyStopping counter: 1 out of 5.0
Validation loss decreased (0.954757 --> 0.954366).  Saving model ...
EarlyStopping counter: 1 out of 5.0
EarlyStopping counter: 2 out of 5.0
Validation loss decreased (0.954366 --> 0.953349).  Saving model ...
EarlyStopping counter: 1 out of 5.0
Validation loss decreased (0.953349 --> 0.952851).  Saving model ...
EarlyStopping counter: 1 out of 5.0
EarlyStopping counter: 2 out of 5.0
Validation loss decreased (0.952851 --> 0.952451).  Saving model ...
Validation loss decreased (0.952451 --> 0.950654).  Saving model ...
EarlyStopping counter: 1 out of 5.0
EarlyStopping counter: 2 out of 5.0
EarlyStopping counter: 3 out of 5.0
EarlyStopping counter: 4 out of 5.0
EarlyStopping counter: 5 out of 5.0
/localscratch/yinan.29113217.0/env/lib/python3.7/site-packages/torch/nn/functional.py:1794: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.
  warnings.warn("nn.functional.tanh is deprecated. Use torch.tanh instead.")
wandb: Waiting for W&B process to finish, PID 167473... (success).
wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: \ 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: | 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: / 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: \ 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: | 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: / 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: \ 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: | 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: / 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb:                                                                                
wandb: Run history:
wandb:     e_F1 ▁▂▄▅▅▅▅▆▆▆▆▆▇▆▇▇▇▇▇▇▇▇▇▇▇▇██▇███████████
wandb:   e_loss ██▇▇▇▆▆▆▅▅▅▄▄▄▄▃▃▃▃▃▃▂▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁
wandb:     t_F1 ▁▂▂▃▃▃▄▅▅▅▅▅▅▅▅▅▆▆▆▆▆▆▇▆▆▇▇▇▇▇█▇█▇██████
wandb:   t_loss ███▇▇▇▇▇▆▆▅▅▅▅▅▅▄▄▄▄▄▄▃▃▃▃▃▃▂▂▂▂▂▂▂▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:     e_F1 59.48141
wandb:   e_loss 0.95238
wandb:     t_F1 71.22989
wandb:   t_loss 0.76417
wandb: 
wandb: Synced 4 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Synced devout-river-1: https://wandb.ai/yinanazhou/xl_512_bs_8_lr_1e06_es_5_lc_True_nr_False_sr_True_stem_True_lemma_False_repeat_2_fold_2/runs/175oqg99
wandb: Find logs at: ./wandb/run-20220317_105023-175oqg99/logs/debug.log
wandb: 

wandb: wandb version 0.12.11 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
2022-03-17 12:28:44.742225: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1
wandb: Tracking run with wandb version 0.12.5
wandb: Syncing run stellar-valley-1
wandb: ⭐️ View project at https://wandb.ai/yinanazhou/xl_512_bs_8_lr_1e06_es_5_lc_True_nr_False_sr_True_stem_True_lemma_False_repeat_3_fold_1
wandb: 🚀 View run at https://wandb.ai/yinanazhou/xl_512_bs_8_lr_1e06_es_5_lc_True_nr_False_sr_True_stem_True_lemma_False_repeat_3_fold_1/runs/1pam2j15
wandb: Run data is saved locally in /project/6002780/yinan/Thesis_MER_Lyrics/lyric-emotion/wandb/run-20220317_122841-1pam2j15
wandb: Run `wandb offline` to turn off syncing.

Validation loss decreased (inf --> 1.446395).  Saving model ...
Validation loss decreased (1.446395 --> 1.427757).  Saving model ...
Validation loss decreased (1.427757 --> 1.412891).  Saving model ...
Validation loss decreased (1.412891 --> 1.400568).  Saving model ...
Validation loss decreased (1.400568 --> 1.391064).  Saving model ...
Validation loss decreased (1.391064 --> 1.383308).  Saving model ...
Validation loss decreased (1.383308 --> 1.376294).  Saving model ...
Validation loss decreased (1.376294 --> 1.370507).  Saving model ...
Validation loss decreased (1.370507 --> 1.365014).  Saving model ...
Validation loss decreased (1.365014 --> 1.359913).  Saving model ...
Validation loss decreased (1.359913 --> 1.355009).  Saving model ...
Validation loss decreased (1.355009 --> 1.350530).  Saving model ...
Validation loss decreased (1.350530 --> 1.346421).  Saving model ...
Validation loss decreased (1.346421 --> 1.342326).  Saving model ...
Validation loss decreased (1.342326 --> 1.338058).  Saving model ...
Validation loss decreased (1.338058 --> 1.334014).  Saving model ...
Validation loss decreased (1.334014 --> 1.329577).  Saving model ...
Validation loss decreased (1.329577 --> 1.324881).  Saving model ...
Validation loss decreased (1.324881 --> 1.320764).  Saving model ...
Validation loss decreased (1.320764 --> 1.316311).  Saving model ...
Validation loss decreased (1.316311 --> 1.311397).  Saving model ...
Validation loss decreased (1.311397 --> 1.305802).  Saving model ...
Validation loss decreased (1.305802 --> 1.300971).  Saving model ...
Validation loss decreased (1.300971 --> 1.295952).  Saving model ...
Validation loss decreased (1.295952 --> 1.290465).  Saving model ...
Validation loss decreased (1.290465 --> 1.285500).  Saving model ...
Validation loss decreased (1.285500 --> 1.280141).  Saving model ...
Validation loss decreased (1.280141 --> 1.273726).  Saving model ...
Validation loss decreased (1.273726 --> 1.267682).  Saving model ...
Validation loss decreased (1.267682 --> 1.262052).  Saving model ...
Validation loss decreased (1.262052 --> 1.255660).  Saving model ...
Validation loss decreased (1.255660 --> 1.249110).  Saving model ...
Validation loss decreased (1.249110 --> 1.242336).  Saving model ...
Validation loss decreased (1.242336 --> 1.236359).  Saving model ...
Validation loss decreased (1.236359 --> 1.230505).  Saving model ...
Validation loss decreased (1.230505 --> 1.224181).  Saving model ...
Validation loss decreased (1.224181 --> 1.218917).  Saving model ...
Validation loss decreased (1.218917 --> 1.212530).  Saving model ...
Validation loss decreased (1.212530 --> 1.206565).  Saving model ...
Validation loss decreased (1.206565 --> 1.200607).  Saving model ...
Validation loss decreased (1.200607 --> 1.195506).  Saving model ...
Validation loss decreased (1.195506 --> 1.190179).  Saving model ...
Validation loss decreased (1.190179 --> 1.185243).  Saving model ...
Validation loss decreased (1.185243 --> 1.179722).  Saving model ...
Validation loss decreased (1.179722 --> 1.172839).  Saving model ...
Validation loss decreased (1.172839 --> 1.168991).  Saving model ...
Validation loss decreased (1.168991 --> 1.165605).  Saving model ...
Validation loss decreased (1.165605 --> 1.161419).  Saving model ...
Validation loss decreased (1.161419 --> 1.154059).  Saving model ...
Validation loss decreased (1.154059 --> 1.149503).  Saving model ...
Validation loss decreased (1.149503 --> 1.144183).  Saving model ...
Validation loss decreased (1.144183 --> 1.139948).  Saving model ...
Validation loss decreased (1.139948 --> 1.135646).  Saving model ...
Validation loss decreased (1.135646 --> 1.130353).  Saving model ...
Validation loss decreased (1.130353 --> 1.124724).  Saving model ...
Validation loss decreased (1.124724 --> 1.120070).  Saving model ...
Validation loss decreased (1.120070 --> 1.116176).  Saving model ...
Validation loss decreased (1.116176 --> 1.111200).  Saving model ...
Validation loss decreased (1.111200 --> 1.107186).  Saving model ...
Validation loss decreased (1.107186 --> 1.102169).  Saving model ...
Validation loss decreased (1.102169 --> 1.098738).  Saving model ...
Validation loss decreased (1.098738 --> 1.094633).  Saving model ...
Validation loss decreased (1.094633 --> 1.089955).  Saving model ...
Validation loss decreased (1.089955 --> 1.088264).  Saving model ...
Validation loss decreased (1.088264 --> 1.083323).  Saving model ...
Validation loss decreased (1.083323 --> 1.080016).  Saving model ...
Validation loss decreased (1.080016 --> 1.075352).  Saving model ...
Validation loss decreased (1.075352 --> 1.073428).  Saving model ...
Validation loss decreased (1.073428 --> 1.070704).  Saving model ...
Validation loss decreased (1.070704 --> 1.066344).  Saving model ...
Validation loss decreased (1.066344 --> 1.064548).  Saving model ...
Validation loss decreased (1.064548 --> 1.059136).  Saving model ...
Validation loss decreased (1.059136 --> 1.055420).  Saving model ...
Validation loss decreased (1.055420 --> 1.051776).  Saving model ...
Validation loss decreased (1.051776 --> 1.049841).  Saving model ...
Validation loss decreased (1.049841 --> 1.047083).  Saving model ...
Validation loss decreased (1.047083 --> 1.042960).  Saving model ...
Validation loss decreased (1.042960 --> 1.041143).  Saving model ...
Validation loss decreased (1.041143 --> 1.037760).  Saving model ...
Validation loss decreased (1.037760 --> 1.037273).  Saving model ...
Validation loss decreased (1.037273 --> 1.035522).  Saving model ...
Validation loss decreased (1.035522 --> 1.033021).  Saving model ...
Validation loss decreased (1.033021 --> 1.030851).  Saving model ...
Validation loss decreased (1.030851 --> 1.026973).  Saving model ...
Validation loss decreased (1.026973 --> 1.022545).  Saving model ...
Validation loss decreased (1.022545 --> 1.021297).  Saving model ...
Validation loss decreased (1.021297 --> 1.018598).  Saving model ...
Validation loss decreased (1.018598 --> 1.015305).  Saving model ...
Validation loss decreased (1.015305 --> 1.013041).  Saving model ...
Validation loss decreased (1.013041 --> 1.011779).  Saving model ...
Validation loss decreased (1.011779 --> 1.010892).  Saving model ...
Validation loss decreased (1.010892 --> 1.008593).  Saving model ...
Validation loss decreased (1.008593 --> 1.005640).  Saving model ...
Validation loss decreased (1.005640 --> 1.002927).  Saving model ...
Validation loss decreased (1.002927 --> 1.001297).  Saving model ...
Validation loss decreased (1.001297 --> 0.998069).  Saving model ...
EarlyStopping counter: 1 out of 5.0
Validation loss decreased (0.998069 --> 0.995678).  Saving model ...
Validation loss decreased (0.995678 --> 0.992302).  Saving model ...
Validation loss decreased (0.992302 --> 0.990871).  Saving model ...
Validation loss decreased (0.990871 --> 0.989784).  Saving model ...
Validation loss decreased (0.989784 --> 0.986443).  Saving model ...
Validation loss decreased (0.986443 --> 0.985511).  Saving model ...
Validation loss decreased (0.985511 --> 0.981851).  Saving model ...
Validation loss decreased (0.981851 --> 0.981251).  Saving model ...
Validation loss decreased (0.981251 --> 0.979739).  Saving model ...
Validation loss decreased (0.979739 --> 0.979302).  Saving model ...
Validation loss decreased (0.979302 --> 0.976666).  Saving model ...
Validation loss decreased (0.976666 --> 0.975164).  Saving model ...
Validation loss decreased (0.975164 --> 0.974918).  Saving model ...
Validation loss decreased (0.974918 --> 0.974209).  Saving model ...
Validation loss decreased (0.974209 --> 0.972634).  Saving model ...
Validation loss decreased (0.972634 --> 0.971787).  Saving model ...
Validation loss decreased (0.971787 --> 0.969535).  Saving model ...
Validation loss decreased (0.969535 --> 0.967017).  Saving model ...
EarlyStopping counter: 1 out of 5.0
EarlyStopping counter: 2 out of 5.0
Validation loss decreased (0.967017 --> 0.963490).  Saving model ...
Validation loss decreased (0.963490 --> 0.963231).  Saving model ...
Validation loss decreased (0.963231 --> 0.962487).  Saving model ...
EarlyStopping counter: 1 out of 5.0
EarlyStopping counter: 2 out of 5.0
Validation loss decreased (0.962487 --> 0.962383).  Saving model ...
Validation loss decreased (0.962383 --> 0.960814).  Saving model ...
Validation loss decreased (0.960814 --> 0.959413).  Saving model ...
EarlyStopping counter: 1 out of 5.0
EarlyStopping counter: 2 out of 5.0
EarlyStopping counter: 3 out of 5.0
EarlyStopping counter: 4 out of 5.0
EarlyStopping counter: 5 out of 5.0
/localscratch/yinan.29113217.0/env/lib/python3.7/site-packages/torch/nn/functional.py:1794: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.
  warnings.warn("nn.functional.tanh is deprecated. Use torch.tanh instead.")
wandb: Waiting for W&B process to finish, PID 172726... (success).
wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: \ 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: | 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: / 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: \ 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: | 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: / 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: \ 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: | 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: / 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb:                                                                                
wandb: Run history:
wandb:     e_F1 ▁▂▃▃▅▅▅▆▆▆▆▇▇▇▇▇▇▇▇▇▇▇▇▇▇███████████████
wandb:   e_loss ██▇▇▇▆▆▆▆▆▅▅▅▄▄▄▄▃▃▃▃▃▂▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁
wandb:     t_F1 ▁▁▁▂▃▃▃▄▄▄▄▄▅▅▅▅▆▅▆▆▆▆▇▇▇▇▇▇▇▇█▇▇██▇████
wandb:   t_loss ███▇▇▇▇▇▆▆▆▆▆▅▅▅▄▅▄▄▄▄▃▃▃▃▃▂▂▂▂▂▂▂▂▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:     e_F1 59.33933
wandb:   e_loss 0.96133
wandb:     t_F1 70.97194
wandb:   t_loss 0.78691
wandb: 
wandb: Synced 4 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Synced stellar-valley-1: https://wandb.ai/yinanazhou/xl_512_bs_8_lr_1e06_es_5_lc_True_nr_False_sr_True_stem_True_lemma_False_repeat_3_fold_1/runs/1pam2j15
wandb: Find logs at: ./wandb/run-20220317_122841-1pam2j15/logs/debug.log
wandb: 

wandb: wandb version 0.12.11 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
2022-03-17 13:54:02.468467: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1
wandb: Tracking run with wandb version 0.12.5
wandb: Syncing run lemon-darkness-1
wandb: ⭐️ View project at https://wandb.ai/yinanazhou/xl_512_bs_8_lr_1e06_es_5_lc_True_nr_False_sr_True_stem_True_lemma_False_repeat_3_fold_2
wandb: 🚀 View run at https://wandb.ai/yinanazhou/xl_512_bs_8_lr_1e06_es_5_lc_True_nr_False_sr_True_stem_True_lemma_False_repeat_3_fold_2/runs/3kk2ooy8
wandb: Run data is saved locally in /project/6002780/yinan/Thesis_MER_Lyrics/lyric-emotion/wandb/run-20220317_135358-3kk2ooy8
wandb: Run `wandb offline` to turn off syncing.

Validation loss decreased (inf --> 1.417331).  Saving model ...
Validation loss decreased (1.417331 --> 1.407386).  Saving model ...
Validation loss decreased (1.407386 --> 1.398878).  Saving model ...
Validation loss decreased (1.398878 --> 1.392902).  Saving model ...
Validation loss decreased (1.392902 --> 1.387111).  Saving model ...
Validation loss decreased (1.387111 --> 1.382043).  Saving model ...
Validation loss decreased (1.382043 --> 1.377284).  Saving model ...
Validation loss decreased (1.377284 --> 1.372935).  Saving model ...
Validation loss decreased (1.372935 --> 1.369110).  Saving model ...
Validation loss decreased (1.369110 --> 1.364790).  Saving model ...
Validation loss decreased (1.364790 --> 1.360321).  Saving model ...
Validation loss decreased (1.360321 --> 1.355875).  Saving model ...
Validation loss decreased (1.355875 --> 1.351688).  Saving model ...
Validation loss decreased (1.351688 --> 1.347894).  Saving model ...
Validation loss decreased (1.347894 --> 1.344011).  Saving model ...
Validation loss decreased (1.344011 --> 1.340144).  Saving model ...
Validation loss decreased (1.340144 --> 1.336004).  Saving model ...
Validation loss decreased (1.336004 --> 1.331367).  Saving model ...
Validation loss decreased (1.331367 --> 1.326298).  Saving model ...
Validation loss decreased (1.326298 --> 1.321616).  Saving model ...
Validation loss decreased (1.321616 --> 1.316964).  Saving model ...
Validation loss decreased (1.316964 --> 1.312191).  Saving model ...
Validation loss decreased (1.312191 --> 1.307268).  Saving model ...
Validation loss decreased (1.307268 --> 1.301528).  Saving model ...
Validation loss decreased (1.301528 --> 1.295359).  Saving model ...
Validation loss decreased (1.295359 --> 1.288193).  Saving model ...
Validation loss decreased (1.288193 --> 1.281475).  Saving model ...
Validation loss decreased (1.281475 --> 1.275221).  Saving model ...
Validation loss decreased (1.275221 --> 1.268444).  Saving model ...
Validation loss decreased (1.268444 --> 1.261113).  Saving model ...
Validation loss decreased (1.261113 --> 1.253310).  Saving model ...
Validation loss decreased (1.253310 --> 1.245793).  Saving model ...
Validation loss decreased (1.245793 --> 1.237869).  Saving model ...
Validation loss decreased (1.237869 --> 1.229873).  Saving model ...
Validation loss decreased (1.229873 --> 1.220679).  Saving model ...
Validation loss decreased (1.220679 --> 1.212056).  Saving model ...
Validation loss decreased (1.212056 --> 1.204459).  Saving model ...
Validation loss decreased (1.204459 --> 1.197933).  Saving model ...
Validation loss decreased (1.197933 --> 1.190457).  Saving model ...
Validation loss decreased (1.190457 --> 1.183352).  Saving model ...
Validation loss decreased (1.183352 --> 1.176382).  Saving model ...
Validation loss decreased (1.176382 --> 1.169806).  Saving model ...
Validation loss decreased (1.169806 --> 1.165537).  Saving model ...
Validation loss decreased (1.165537 --> 1.160671).  Saving model ...
Validation loss decreased (1.160671 --> 1.156910).  Saving model ...
Validation loss decreased (1.156910 --> 1.151345).  Saving model ...
Validation loss decreased (1.151345 --> 1.146834).  Saving model ...
Validation loss decreased (1.146834 --> 1.142005).  Saving model ...
Validation loss decreased (1.142005 --> 1.137417).  Saving model ...
Validation loss decreased (1.137417 --> 1.131916).  Saving model ...
Validation loss decreased (1.131916 --> 1.128046).  Saving model ...
Validation loss decreased (1.128046 --> 1.125681).  Saving model ...
Validation loss decreased (1.125681 --> 1.121764).  Saving model ...
Validation loss decreased (1.121764 --> 1.116278).  Saving model ...
Validation loss decreased (1.116278 --> 1.113651).  Saving model ...
Validation loss decreased (1.113651 --> 1.109924).  Saving model ...
Validation loss decreased (1.109924 --> 1.104630).  Saving model ...
Validation loss decreased (1.104630 --> 1.101449).  Saving model ...
Validation loss decreased (1.101449 --> 1.098300).  Saving model ...
Validation loss decreased (1.098300 --> 1.096134).  Saving model ...
Validation loss decreased (1.096134 --> 1.091978).  Saving model ...
Validation loss decreased (1.091978 --> 1.087155).  Saving model ...
Validation loss decreased (1.087155 --> 1.083168).  Saving model ...
Validation loss decreased (1.083168 --> 1.078883).  Saving model ...
Validation loss decreased (1.078883 --> 1.075869).  Saving model ...
Validation loss decreased (1.075869 --> 1.071107).  Saving model ...
Validation loss decreased (1.071107 --> 1.068378).  Saving model ...
Validation loss decreased (1.068378 --> 1.065158).  Saving model ...
Validation loss decreased (1.065158 --> 1.059913).  Saving model ...
Validation loss decreased (1.059913 --> 1.057199).  Saving model ...
Validation loss decreased (1.057199 --> 1.054096).  Saving model ...
Validation loss decreased (1.054096 --> 1.051772).  Saving model ...
Validation loss decreased (1.051772 --> 1.048594).  Saving model ...
Validation loss decreased (1.048594 --> 1.044374).  Saving model ...
Validation loss decreased (1.044374 --> 1.040786).  Saving model ...
Validation loss decreased (1.040786 --> 1.037637).  Saving model ...
Validation loss decreased (1.037637 --> 1.033827).  Saving model ...
Validation loss decreased (1.033827 --> 1.030073).  Saving model ...
Validation loss decreased (1.030073 --> 1.026929).  Saving model ...
Validation loss decreased (1.026929 --> 1.024636).  Saving model ...
Validation loss decreased (1.024636 --> 1.021015).  Saving model ...
Validation loss decreased (1.021015 --> 1.019938).  Saving model ...
Validation loss decreased (1.019938 --> 1.017756).  Saving model ...
Validation loss decreased (1.017756 --> 1.015697).  Saving model ...
Validation loss decreased (1.015697 --> 1.014379).  Saving model ...
Validation loss decreased (1.014379 --> 1.014275).  Saving model ...
Validation loss decreased (1.014275 --> 1.012902).  Saving model ...
Validation loss decreased (1.012902 --> 1.009537).  Saving model ...
Validation loss decreased (1.009537 --> 1.007310).  Saving model ...
Validation loss decreased (1.007310 --> 1.006172).  Saving model ...
Validation loss decreased (1.006172 --> 1.004768).  Saving model ...
Validation loss decreased (1.004768 --> 1.001098).  Saving model ...
Validation loss decreased (1.001098 --> 0.999416).  Saving model ...
Validation loss decreased (0.999416 --> 0.998481).  Saving model ...
Validation loss decreased (0.998481 --> 0.997596).  Saving model ...
EarlyStopping counter: 1 out of 5.0
Validation loss decreased (0.997596 --> 0.996632).  Saving model ...
Validation loss decreased (0.996632 --> 0.995310).  Saving model ...
Validation loss decreased (0.995310 --> 0.992824).  Saving model ...
EarlyStopping counter: 1 out of 5.0
Validation loss decreased (0.992824 --> 0.990600).  Saving model ...
Validation loss decreased (0.990600 --> 0.987829).  Saving model ...
EarlyStopping counter: 1 out of 5.0
Validation loss decreased (0.987829 --> 0.985101).  Saving model ...
Validation loss decreased (0.985101 --> 0.984639).  Saving model ...
Validation loss decreased (0.984639 --> 0.983735).  Saving model ...
Validation loss decreased (0.983735 --> 0.981817).  Saving model ...
Validation loss decreased (0.981817 --> 0.981389).  Saving model ...
EarlyStopping counter: 1 out of 5.0
Validation loss decreased (0.981389 --> 0.981249).  Saving model ...
Validation loss decreased (0.981249 --> 0.981139).  Saving model ...
Validation loss decreased (0.981139 --> 0.977245).  Saving model ...
Validation loss decreased (0.977245 --> 0.975194).  Saving model ...
EarlyStopping counter: 1 out of 5.0
EarlyStopping counter: 2 out of 5.0
Validation loss decreased (0.975194 --> 0.975043).  Saving model ...
EarlyStopping counter: 1 out of 5.0
Validation loss decreased (0.975043 --> 0.975015).  Saving model ...
EarlyStopping counter: 1 out of 5.0
EarlyStopping counter: 2 out of 5.0
Validation loss decreased (0.975015 --> 0.973928).  Saving model ...
EarlyStopping counter: 1 out of 5.0
EarlyStopping counter: 2 out of 5.0
Validation loss decreased (0.973928 --> 0.972229).  Saving model ...
Validation loss decreased (0.972229 --> 0.969216).  Saving model ...
Validation loss decreased (0.969216 --> 0.967696).  Saving model ...
EarlyStopping counter: 1 out of 5.0
EarlyStopping counter: 2 out of 5.0
Validation loss decreased (0.967696 --> 0.967158).  Saving model ...
EarlyStopping counter: 1 out of 5.0
EarlyStopping counter: 2 out of 5.0
EarlyStopping counter: 3 out of 5.0
EarlyStopping counter: 4 out of 5.0
Validation loss decreased (0.967158 --> 0.967109).  Saving model ...
EarlyStopping counter: 1 out of 5.0
Validation loss decreased (0.967109 --> 0.965732).  Saving model ...
EarlyStopping counter: 1 out of 5.0
Validation loss decreased (0.965732 --> 0.965400).  Saving model ...
EarlyStopping counter: 1 out of 5.0
EarlyStopping counter: 2 out of 5.0
EarlyStopping counter: 3 out of 5.0
Validation loss decreased (0.965400 --> 0.965382).  Saving model ...
Validation loss decreased (0.965382 --> 0.962777).  Saving model ...
EarlyStopping counter: 1 out of 5.0
Validation loss decreased (0.962777 --> 0.961574).  Saving model ...
EarlyStopping counter: 1 out of 5.0
EarlyStopping counter: 2 out of 5.0
EarlyStopping counter: 3 out of 5.0
EarlyStopping counter: 4 out of 5.0
EarlyStopping counter: 5 out of 5.0
/localscratch/yinan.29113217.0/env/lib/python3.7/site-packages/torch/nn/functional.py:1794: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.
  warnings.warn("nn.functional.tanh is deprecated. Use torch.tanh instead.")
wandb: Waiting for W&B process to finish, PID 177333... (success).
wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: \ 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: | 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: / 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: \ 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: | 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: / 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: \ 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: | 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: / 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb:                                                                                
wandb: Run history:
wandb:     e_F1 ▁▁▂▄▄▅▅▅▆▆▆▆▆▆▆▆▇▇▇▇▇▇▇▇▇▇▇█████████████
wandb:   e_loss ██▇▇▇▇▆▆▅▅▅▄▄▄▃▃▃▃▂▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:     t_F1 ▁▁▂▂▂▃▃▄▅▅▅▅▅▆▅▆▇▇▆▆▇▇▇▆▇▇▇▇▇█▇▇█▇██████
wandb:   t_loss ███▇▇▇▇▇▆▆▆▅▅▅▅▅▄▄▄▄▃▃▃▃▃▃▂▂▂▂▂▂▂▂▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:     e_F1 61.45292
wandb:   e_loss 0.96252
wandb:     t_F1 72.52153
wandb:   t_loss 0.74766
wandb: 
wandb: Synced 4 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Synced lemon-darkness-1: https://wandb.ai/yinanazhou/xl_512_bs_8_lr_1e06_es_5_lc_True_nr_False_sr_True_stem_True_lemma_False_repeat_3_fold_2/runs/3kk2ooy8
wandb: Find logs at: ./wandb/run-20220317_135358-3kk2ooy8/logs/debug.log
wandb: 

wandb: wandb version 0.12.11 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
2022-03-17 15:28:05.158633: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1
wandb: Tracking run with wandb version 0.12.5
wandb: Syncing run brisk-hill-1
wandb: ⭐️ View project at https://wandb.ai/yinanazhou/xl_512_bs_8_lr_1e06_es_5_lc_True_nr_False_sr_True_stem_True_lemma_False_repeat_4_fold_1
wandb: 🚀 View run at https://wandb.ai/yinanazhou/xl_512_bs_8_lr_1e06_es_5_lc_True_nr_False_sr_True_stem_True_lemma_False_repeat_4_fold_1/runs/2ylue1bq
wandb: Run data is saved locally in /project/6002780/yinan/Thesis_MER_Lyrics/lyric-emotion/wandb/run-20220317_152801-2ylue1bq
wandb: Run `wandb offline` to turn off syncing.

Validation loss decreased (inf --> 1.394233).  Saving model ...
Validation loss decreased (1.394233 --> 1.386867).  Saving model ...
Validation loss decreased (1.386867 --> 1.380181).  Saving model ...
Validation loss decreased (1.380181 --> 1.374843).  Saving model ...
Validation loss decreased (1.374843 --> 1.369767).  Saving model ...
Validation loss decreased (1.369767 --> 1.365293).  Saving model ...
Validation loss decreased (1.365293 --> 1.361167).  Saving model ...
Validation loss decreased (1.361167 --> 1.356992).  Saving model ...
Validation loss decreased (1.356992 --> 1.352768).  Saving model ...
Validation loss decreased (1.352768 --> 1.348535).  Saving model ...
Validation loss decreased (1.348535 --> 1.344526).  Saving model ...
Validation loss decreased (1.344526 --> 1.340273).  Saving model ...
Validation loss decreased (1.340273 --> 1.335795).  Saving model ...
Validation loss decreased (1.335795 --> 1.331299).  Saving model ...
Validation loss decreased (1.331299 --> 1.326781).  Saving model ...
Validation loss decreased (1.326781 --> 1.322033).  Saving model ...
Validation loss decreased (1.322033 --> 1.316531).  Saving model ...
Validation loss decreased (1.316531 --> 1.310267).  Saving model ...
Validation loss decreased (1.310267 --> 1.304430).  Saving model ...
Validation loss decreased (1.304430 --> 1.298200).  Saving model ...
Validation loss decreased (1.298200 --> 1.291417).  Saving model ...
Validation loss decreased (1.291417 --> 1.284509).  Saving model ...
Validation loss decreased (1.284509 --> 1.277338).  Saving model ...
Validation loss decreased (1.277338 --> 1.270130).  Saving model ...
Validation loss decreased (1.270130 --> 1.262425).  Saving model ...
Validation loss decreased (1.262425 --> 1.255110).  Saving model ...
Validation loss decreased (1.255110 --> 1.247940).  Saving model ...
Validation loss decreased (1.247940 --> 1.240918).  Saving model ...
Validation loss decreased (1.240918 --> 1.234198).  Saving model ...
Validation loss decreased (1.234198 --> 1.227597).  Saving model ...
Validation loss decreased (1.227597 --> 1.220364).  Saving model ...
Validation loss decreased (1.220364 --> 1.213932).  Saving model ...
Validation loss decreased (1.213932 --> 1.208049).  Saving model ...
Validation loss decreased (1.208049 --> 1.202116).  Saving model ...
Validation loss decreased (1.202116 --> 1.197626).  Saving model ...
Validation loss decreased (1.197626 --> 1.192119).  Saving model ...
Validation loss decreased (1.192119 --> 1.186396).  Saving model ...
Validation loss decreased (1.186396 --> 1.180552).  Saving model ...
Validation loss decreased (1.180552 --> 1.175803).  Saving model ...
Validation loss decreased (1.175803 --> 1.170188).  Saving model ...
Validation loss decreased (1.170188 --> 1.164894).  Saving model ...
Validation loss decreased (1.164894 --> 1.160189).  Saving model ...
Validation loss decreased (1.160189 --> 1.155190).  Saving model ...
Validation loss decreased (1.155190 --> 1.150960).  Saving model ...
Validation loss decreased (1.150960 --> 1.145304).  Saving model ...
Validation loss decreased (1.145304 --> 1.140880).  Saving model ...
Validation loss decreased (1.140880 --> 1.137659).  Saving model ...
Validation loss decreased (1.137659 --> 1.133271).  Saving model ...
Validation loss decreased (1.133271 --> 1.129172).  Saving model ...
Validation loss decreased (1.129172 --> 1.124405).  Saving model ...
Validation loss decreased (1.124405 --> 1.120513).  Saving model ...
Validation loss decreased (1.120513 --> 1.116290).  Saving model ...
Validation loss decreased (1.116290 --> 1.114446).  Saving model ...
Validation loss decreased (1.114446 --> 1.112321).  Saving model ...
Validation loss decreased (1.112321 --> 1.107478).  Saving model ...
Validation loss decreased (1.107478 --> 1.103218).  Saving model ...
Validation loss decreased (1.103218 --> 1.099770).  Saving model ...
Validation loss decreased (1.099770 --> 1.096505).  Saving model ...
Validation loss decreased (1.096505 --> 1.092640).  Saving model ...
Validation loss decreased (1.092640 --> 1.089844).  Saving model ...
Validation loss decreased (1.089844 --> 1.085655).  Saving model ...
Validation loss decreased (1.085655 --> 1.083706).  Saving model ...
Validation loss decreased (1.083706 --> 1.079761).  Saving model ...
Validation loss decreased (1.079761 --> 1.076587).  Saving model ...
Validation loss decreased (1.076587 --> 1.074309).  Saving model ...
Validation loss decreased (1.074309 --> 1.068782).  Saving model ...
Validation loss decreased (1.068782 --> 1.067119).  Saving model ...
Validation loss decreased (1.067119 --> 1.063853).  Saving model ...
Validation loss decreased (1.063853 --> 1.061463).  Saving model ...
Validation loss decreased (1.061463 --> 1.059588).  Saving model ...
Validation loss decreased (1.059588 --> 1.055544).  Saving model ...
Validation loss decreased (1.055544 --> 1.052021).  Saving model ...
Validation loss decreased (1.052021 --> 1.049243).  Saving model ...
Validation loss decreased (1.049243 --> 1.047351).  Saving model ...
Validation loss decreased (1.047351 --> 1.042398).  Saving model ...
Validation loss decreased (1.042398 --> 1.041197).  Saving model ...
Validation loss decreased (1.041197 --> 1.040449).  Saving model ...
Validation loss decreased (1.040449 --> 1.037484).  Saving model ...
Validation loss decreased (1.037484 --> 1.035447).  Saving model ...
Validation loss decreased (1.035447 --> 1.033789).  Saving model ...
Validation loss decreased (1.033789 --> 1.032776).  Saving model ...
Validation loss decreased (1.032776 --> 1.031417).  Saving model ...
Validation loss decreased (1.031417 --> 1.029170).  Saving model ...
Validation loss decreased (1.029170 --> 1.027385).  Saving model ...
Validation loss decreased (1.027385 --> 1.024425).  Saving model ...
Validation loss decreased (1.024425 --> 1.021139).  Saving model ...
Validation loss decreased (1.021139 --> 1.019238).  Saving model ...
Validation loss decreased (1.019238 --> 1.018105).  Saving model ...
EarlyStopping counter: 1 out of 5.0
EarlyStopping counter: 2 out of 5.0
Validation loss decreased (1.018105 --> 1.016597).  Saving model ...
Validation loss decreased (1.016597 --> 1.016381).  Saving model ...
Validation loss decreased (1.016381 --> 1.015082).  Saving model ...
Validation loss decreased (1.015082 --> 1.012118).  Saving model ...
Validation loss decreased (1.012118 --> 1.009154).  Saving model ...
Validation loss decreased (1.009154 --> 1.009122).  Saving model ...
Validation loss decreased (1.009122 --> 1.008359).  Saving model ...
Validation loss decreased (1.008359 --> 1.006248).  Saving model ...
EarlyStopping counter: 1 out of 5.0
EarlyStopping counter: 2 out of 5.0
EarlyStopping counter: 3 out of 5.0
Validation loss decreased (1.006248 --> 1.002473).  Saving model ...
EarlyStopping counter: 1 out of 5.0
Validation loss decreased (1.002473 --> 1.000787).  Saving model ...
Validation loss decreased (1.000787 --> 0.999936).  Saving model ...
Validation loss decreased (0.999936 --> 0.997805).  Saving model ...
EarlyStopping counter: 1 out of 5.0
EarlyStopping counter: 2 out of 5.0
Validation loss decreased (0.997805 --> 0.996438).  Saving model ...
Validation loss decreased (0.996438 --> 0.994857).  Saving model ...
Validation loss decreased (0.994857 --> 0.992768).  Saving model ...
EarlyStopping counter: 1 out of 5.0
EarlyStopping counter: 2 out of 5.0
EarlyStopping counter: 3 out of 5.0
EarlyStopping counter: 4 out of 5.0
Validation loss decreased (0.992768 --> 0.989129).  Saving model ...
EarlyStopping counter: 1 out of 5.0
Validation loss decreased (0.989129 --> 0.989060).  Saving model ...
EarlyStopping counter: 1 out of 5.0
Validation loss decreased (0.989060 --> 0.988288).  Saving model ...
Validation loss decreased (0.988288 --> 0.986150).  Saving model ...
EarlyStopping counter: 1 out of 5.0
EarlyStopping counter: 2 out of 5.0
EarlyStopping counter: 3 out of 5.0
Validation loss decreased (0.986150 --> 0.985802).  Saving model ...
Validation loss decreased (0.985802 --> 0.985075).  Saving model ...
Validation loss decreased (0.985075 --> 0.984820).  Saving model ...
EarlyStopping counter: 1 out of 5.0
EarlyStopping counter: 2 out of 5.0
EarlyStopping counter: 3 out of 5.0
EarlyStopping counter: 4 out of 5.0
EarlyStopping counter: 5 out of 5.0
/localscratch/yinan.29113217.0/env/lib/python3.7/site-packages/torch/nn/functional.py:1794: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.
  warnings.warn("nn.functional.tanh is deprecated. Use torch.tanh instead.")
wandb: Waiting for W&B process to finish, PID 182384... (success).
wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: \ 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: | 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: / 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: \ 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb:                                                                                
wandb: Run history:
wandb:     e_F1 ▁▂▄▄▅▅▅▆▆▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇██████████████
wandb:   e_loss ██▇▇▇▇▆▆▅▅▅▄▄▄▄▃▃▃▃▃▂▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁
wandb:     t_F1 ▁▁▃▂▂▃▄▄▄▅▅▅▅▅▅▆▆▆▇▆▆▆▆▆▇▇▇▇▇▇▇▇▇█▇▇▇███
wandb:   t_loss █████▇▇▇▆▆▆▅▅▅▅▅▅▄▄▄▄▃▃▃▃▃▃▃▂▂▂▂▂▂▂▂▂▁▁▁
wandb: 
wandb: Run summary:
wandb:     e_F1 55.73538
wandb:   e_loss 0.98621
wandb:     t_F1 69.50448
wandb:   t_loss 0.75712
wandb: 
wandb: Synced 4 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Synced brisk-hill-1: https://wandb.ai/yinanazhou/xl_512_bs_8_lr_1e06_es_5_lc_True_nr_False_sr_True_stem_True_lemma_False_repeat_4_fold_1/runs/2ylue1bq
wandb: Find logs at: ./wandb/run-20220317_152801-2ylue1bq/logs/debug.log
wandb: 

wandb: wandb version 0.12.11 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
2022-03-17 16:54:30.598213: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1
wandb: Tracking run with wandb version 0.12.5
wandb: Syncing run young-feather-1
wandb: ⭐️ View project at https://wandb.ai/yinanazhou/xl_512_bs_8_lr_1e06_es_5_lc_True_nr_False_sr_True_stem_True_lemma_False_repeat_4_fold_2
wandb: 🚀 View run at https://wandb.ai/yinanazhou/xl_512_bs_8_lr_1e06_es_5_lc_True_nr_False_sr_True_stem_True_lemma_False_repeat_4_fold_2/runs/2t2hj1vr
wandb: Run data is saved locally in /project/6002780/yinan/Thesis_MER_Lyrics/lyric-emotion/wandb/run-20220317_165427-2t2hj1vr
wandb: Run `wandb offline` to turn off syncing.

Validation loss decreased (inf --> 1.396043).  Saving model ...
Validation loss decreased (1.396043 --> 1.386606).  Saving model ...
Validation loss decreased (1.386606 --> 1.378967).  Saving model ...
Validation loss decreased (1.378967 --> 1.373077).  Saving model ...
Validation loss decreased (1.373077 --> 1.367722).  Saving model ...
Validation loss decreased (1.367722 --> 1.362640).  Saving model ...
Validation loss decreased (1.362640 --> 1.358037).  Saving model ...
Validation loss decreased (1.358037 --> 1.353602).  Saving model ...
Validation loss decreased (1.353602 --> 1.349391).  Saving model ...
Validation loss decreased (1.349391 --> 1.345526).  Saving model ...
Validation loss decreased (1.345526 --> 1.341056).  Saving model ...
Validation loss decreased (1.341056 --> 1.337084).  Saving model ...
Validation loss decreased (1.337084 --> 1.332745).  Saving model ...
Validation loss decreased (1.332745 --> 1.327596).  Saving model ...
Validation loss decreased (1.327596 --> 1.322292).  Saving model ...
Validation loss decreased (1.322292 --> 1.317219).  Saving model ...
Validation loss decreased (1.317219 --> 1.312061).  Saving model ...
Validation loss decreased (1.312061 --> 1.306169).  Saving model ...
Validation loss decreased (1.306169 --> 1.300188).  Saving model ...
Validation loss decreased (1.300188 --> 1.294971).  Saving model ...
Validation loss decreased (1.294971 --> 1.289169).  Saving model ...
Validation loss decreased (1.289169 --> 1.283161).  Saving model ...
Validation loss decreased (1.283161 --> 1.276058).  Saving model ...
Validation loss decreased (1.276058 --> 1.269487).  Saving model ...
Validation loss decreased (1.269487 --> 1.263674).  Saving model ...
Validation loss decreased (1.263674 --> 1.256714).  Saving model ...
Validation loss decreased (1.256714 --> 1.250285).  Saving model ...
Validation loss decreased (1.250285 --> 1.241947).  Saving model ...
Validation loss decreased (1.241947 --> 1.234868).  Saving model ...
Validation loss decreased (1.234868 --> 1.229503).  Saving model ...
Validation loss decreased (1.229503 --> 1.224107).  Saving model ...
Validation loss decreased (1.224107 --> 1.217405).  Saving model ...
Validation loss decreased (1.217405 --> 1.212749).  Saving model ...
Validation loss decreased (1.212749 --> 1.206227).  Saving model ...
Validation loss decreased (1.206227 --> 1.201398).  Saving model ...
Validation loss decreased (1.201398 --> 1.196213).  Saving model ...
Validation loss decreased (1.196213 --> 1.189562).  Saving model ...
Validation loss decreased (1.189562 --> 1.183758).  Saving model ...
Validation loss decreased (1.183758 --> 1.178942).  Saving model ...
Validation loss decreased (1.178942 --> 1.171950).  Saving model ...
Validation loss decreased (1.171950 --> 1.165004).  Saving model ...
Validation loss decreased (1.165004 --> 1.159732).  Saving model ...
Validation loss decreased (1.159732 --> 1.158166).  Saving model ...
Validation loss decreased (1.158166 --> 1.152297).  Saving model ...
Validation loss decreased (1.152297 --> 1.145734).  Saving model ...
Validation loss decreased (1.145734 --> 1.140147).  Saving model ...
Validation loss decreased (1.140147 --> 1.135163).  Saving model ...
Validation loss decreased (1.135163 --> 1.128089).  Saving model ...
Validation loss decreased (1.128089 --> 1.124219).  Saving model ...
Validation loss decreased (1.124219 --> 1.119989).  Saving model ...
Validation loss decreased (1.119989 --> 1.115907).  Saving model ...
Validation loss decreased (1.115907 --> 1.112965).  Saving model ...
Validation loss decreased (1.112965 --> 1.107674).  Saving model ...
Validation loss decreased (1.107674 --> 1.101378).  Saving model ...
Validation loss decreased (1.101378 --> 1.099646).  Saving model ...
Validation loss decreased (1.099646 --> 1.095229).  Saving model ...
EarlyStopping counter: 1 out of 5.0
Validation loss decreased (1.095229 --> 1.092748).  Saving model ...
Validation loss decreased (1.092748 --> 1.088442).  Saving model ...
Validation loss decreased (1.088442 --> 1.083713).  Saving model ...
Validation loss decreased (1.083713 --> 1.079227).  Saving model ...
Validation loss decreased (1.079227 --> 1.073260).  Saving model ...
Validation loss decreased (1.073260 --> 1.071288).  Saving model ...
EarlyStopping counter: 1 out of 5.0
Validation loss decreased (1.071288 --> 1.068244).  Saving model ...
Validation loss decreased (1.068244 --> 1.061187).  Saving model ...
Validation loss decreased (1.061187 --> 1.059036).  Saving model ...
EarlyStopping counter: 1 out of 5.0
Validation loss decreased (1.059036 --> 1.053315).  Saving model ...
Validation loss decreased (1.053315 --> 1.051549).  Saving model ...
Validation loss decreased (1.051549 --> 1.049630).  Saving model ...
Validation loss decreased (1.049630 --> 1.045726).  Saving model ...
Validation loss decreased (1.045726 --> 1.042368).  Saving model ...
EarlyStopping counter: 1 out of 5.0
Validation loss decreased (1.042368 --> 1.040468).  Saving model ...
Validation loss decreased (1.040468 --> 1.034961).  Saving model ...
Validation loss decreased (1.034961 --> 1.034756).  Saving model ...
Validation loss decreased (1.034756 --> 1.033356).  Saving model ...
Validation loss decreased (1.033356 --> 1.027894).  Saving model ...
Validation loss decreased (1.027894 --> 1.024111).  Saving model ...
Validation loss decreased (1.024111 --> 1.022971).  Saving model ...
Validation loss decreased (1.022971 --> 1.020424).  Saving model ...
Validation loss decreased (1.020424 --> 1.019441).  Saving model ...
Validation loss decreased (1.019441 --> 1.019148).  Saving model ...
Validation loss decreased (1.019148 --> 1.016617).  Saving model ...
Validation loss decreased (1.016617 --> 1.014062).  Saving model ...
Validation loss decreased (1.014062 --> 1.012860).  Saving model ...
Validation loss decreased (1.012860 --> 1.011419).  Saving model ...
Validation loss decreased (1.011419 --> 1.009277).  Saving model ...
Validation loss decreased (1.009277 --> 1.005684).  Saving model ...
EarlyStopping counter: 1 out of 5.0
Validation loss decreased (1.005684 --> 1.003707).  Saving model ...
Validation loss decreased (1.003707 --> 1.001586).  Saving model ...
Validation loss decreased (1.001586 --> 1.001417).  Saving model ...
EarlyStopping counter: 1 out of 5.0
Validation loss decreased (1.001417 --> 1.000373).  Saving model ...
Validation loss decreased (1.000373 --> 0.998212).  Saving model ...
Validation loss decreased (0.998212 --> 0.995790).  Saving model ...
Validation loss decreased (0.995790 --> 0.992855).  Saving model ...
Validation loss decreased (0.992855 --> 0.990520).  Saving model ...
EarlyStopping counter: 1 out of 5.0
Validation loss decreased (0.990520 --> 0.988118).  Saving model ...
Validation loss decreased (0.988118 --> 0.987012).  Saving model ...
EarlyStopping counter: 1 out of 5.0
Validation loss decreased (0.987012 --> 0.986593).  Saving model ...
Validation loss decreased (0.986593 --> 0.985409).  Saving model ...
Validation loss decreased (0.985409 --> 0.982866).  Saving model ...
Validation loss decreased (0.982866 --> 0.982331).  Saving model ...
Validation loss decreased (0.982331 --> 0.982291).  Saving model ...
EarlyStopping counter: 1 out of 5.0
EarlyStopping counter: 2 out of 5.0
Validation loss decreased (0.982291 --> 0.980318).  Saving model ...
EarlyStopping counter: 1 out of 5.0
EarlyStopping counter: 2 out of 5.0
EarlyStopping counter: 3 out of 5.0
Validation loss decreased (0.980318 --> 0.979775).  Saving model ...
Validation loss decreased (0.979775 --> 0.978049).  Saving model ...
Validation loss decreased (0.978049 --> 0.976616).  Saving model ...
EarlyStopping counter: 1 out of 5.0
Validation loss decreased (0.976616 --> 0.975889).  Saving model ...
EarlyStopping counter: 1 out of 5.0
EarlyStopping counter: 2 out of 5.0
Validation loss decreased (0.975889 --> 0.974920).  Saving model ...
Validation loss decreased (0.974920 --> 0.972571).  Saving model ...
EarlyStopping counter: 1 out of 5.0
EarlyStopping counter: 2 out of 5.0
EarlyStopping counter: 3 out of 5.0
EarlyStopping counter: 4 out of 5.0
Validation loss decreased (0.972571 --> 0.970859).  Saving model ...
EarlyStopping counter: 1 out of 5.0
EarlyStopping counter: 2 out of 5.0
EarlyStopping counter: 3 out of 5.0
EarlyStopping counter: 4 out of 5.0
EarlyStopping counter: 5 out of 5.0
/localscratch/yinan.29113217.0/env/lib/python3.7/site-packages/torch/nn/functional.py:1794: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.
  warnings.warn("nn.functional.tanh is deprecated. Use torch.tanh instead.")
wandb: Waiting for W&B process to finish, PID 186977... (success).
wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: \ 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: | 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: / 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: \ 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: | 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: / 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: \ 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: | 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: / 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb:                                                                                
wandb: Run history:
wandb:     e_F1 ▁▂▃▄▄▅▅▅▅▆▆▆▆▇▇▇▇▇▇▇▇▇██████████████████
wandb:   e_loss ██▇▇▇▇▆▆▆▅▅▅▄▄▄▃▃▃▃▂▂▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁
wandb:     t_F1 ▁▂▂▂▃▃▄▃▄▄▄▅▅▆▆▅▆▆▅▆▆▇▆▇▇▇▆▇▇▇▇▇▇▇▇▇████
wandb:   t_loss ███▇▇▇▇▆▆▆▆▆▅▅▅▅▄▄▄▄▄▄▃▃▃▃▃▃▂▂▂▂▂▂▂▂▁▁▁▁
wandb: 
wandb: Run summary:
wandb:     e_F1 60.47382
wandb:   e_loss 0.97699
wandb:     t_F1 69.23436
wandb:   t_loss 0.78828
wandb: 
wandb: Synced 4 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Synced young-feather-1: https://wandb.ai/yinanazhou/xl_512_bs_8_lr_1e06_es_5_lc_True_nr_False_sr_True_stem_True_lemma_False_repeat_4_fold_2/runs/2t2hj1vr
wandb: Find logs at: ./wandb/run-20220317_165427-2t2hj1vr/logs/debug.log
wandb: 

wandb: wandb version 0.12.11 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
2022-03-17 18:22:17.210398: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1
wandb: Tracking run with wandb version 0.12.5
wandb: Syncing run confused-breeze-1
wandb: ⭐️ View project at https://wandb.ai/yinanazhou/xl_512_bs_8_lr_1e06_es_5_lc_True_nr_False_sr_True_stem_True_lemma_False_repeat_5_fold_1
wandb: 🚀 View run at https://wandb.ai/yinanazhou/xl_512_bs_8_lr_1e06_es_5_lc_True_nr_False_sr_True_stem_True_lemma_False_repeat_5_fold_1/runs/1ozm7tnb
wandb: Run data is saved locally in /project/6002780/yinan/Thesis_MER_Lyrics/lyric-emotion/wandb/run-20220317_182214-1ozm7tnb
wandb: Run `wandb offline` to turn off syncing.

Validation loss decreased (inf --> 1.435290).  Saving model ...
Validation loss decreased (1.435290 --> 1.416971).  Saving model ...
Validation loss decreased (1.416971 --> 1.401943).  Saving model ...
Validation loss decreased (1.401943 --> 1.390203).  Saving model ...
Validation loss decreased (1.390203 --> 1.381830).  Saving model ...
Validation loss decreased (1.381830 --> 1.374861).  Saving model ...
Validation loss decreased (1.374861 --> 1.369257).  Saving model ...
Validation loss decreased (1.369257 --> 1.364551).  Saving model ...
Validation loss decreased (1.364551 --> 1.360754).  Saving model ...
Validation loss decreased (1.360754 --> 1.357181).  Saving model ...
Validation loss decreased (1.357181 --> 1.354193).  Saving model ...
Validation loss decreased (1.354193 --> 1.350963).  Saving model ...
Validation loss decreased (1.350963 --> 1.347883).  Saving model ...
Validation loss decreased (1.347883 --> 1.344854).  Saving model ...
Validation loss decreased (1.344854 --> 1.341492).  Saving model ...
Validation loss decreased (1.341492 --> 1.337886).  Saving model ...
Validation loss decreased (1.337886 --> 1.334196).  Saving model ...
Validation loss decreased (1.334196 --> 1.330157).  Saving model ...
Validation loss decreased (1.330157 --> 1.326615).  Saving model ...
Validation loss decreased (1.326615 --> 1.322393).  Saving model ...
Validation loss decreased (1.322393 --> 1.317738).  Saving model ...
Validation loss decreased (1.317738 --> 1.313983).  Saving model ...
Validation loss decreased (1.313983 --> 1.309077).  Saving model ...
Validation loss decreased (1.309077 --> 1.304306).  Saving model ...
Validation loss decreased (1.304306 --> 1.298580).  Saving model ...
Validation loss decreased (1.298580 --> 1.293274).  Saving model ...
Validation loss decreased (1.293274 --> 1.287884).  Saving model ...
Validation loss decreased (1.287884 --> 1.282001).  Saving model ...
Validation loss decreased (1.282001 --> 1.276038).  Saving model ...
Validation loss decreased (1.276038 --> 1.269509).  Saving model ...
Validation loss decreased (1.269509 --> 1.263198).  Saving model ...
Validation loss decreased (1.263198 --> 1.257332).  Saving model ...
Validation loss decreased (1.257332 --> 1.251990).  Saving model ...
Validation loss decreased (1.251990 --> 1.245349).  Saving model ...
Validation loss decreased (1.245349 --> 1.239238).  Saving model ...
Validation loss decreased (1.239238 --> 1.233282).  Saving model ...
Validation loss decreased (1.233282 --> 1.227577).  Saving model ...
Validation loss decreased (1.227577 --> 1.221661).  Saving model ...
Validation loss decreased (1.221661 --> 1.216125).  Saving model ...
Validation loss decreased (1.216125 --> 1.209802).  Saving model ...
Validation loss decreased (1.209802 --> 1.204206).  Saving model ...
Validation loss decreased (1.204206 --> 1.198940).  Saving model ...
Validation loss decreased (1.198940 --> 1.194091).  Saving model ...
Validation loss decreased (1.194091 --> 1.189515).  Saving model ...
Validation loss decreased (1.189515 --> 1.184838).  Saving model ...
Validation loss decreased (1.184838 --> 1.180788).  Saving model ...
Validation loss decreased (1.180788 --> 1.175622).  Saving model ...
Validation loss decreased (1.175622 --> 1.170617).  Saving model ...
Validation loss decreased (1.170617 --> 1.166413).  Saving model ...
Validation loss decreased (1.166413 --> 1.162317).  Saving model ...
Validation loss decreased (1.162317 --> 1.158581).  Saving model ...
Validation loss decreased (1.158581 --> 1.154088).  Saving model ...
Validation loss decreased (1.154088 --> 1.150030).  Saving model ...
Validation loss decreased (1.150030 --> 1.146017).  Saving model ...
Validation loss decreased (1.146017 --> 1.140787).  Saving model ...
Validation loss decreased (1.140787 --> 1.136801).  Saving model ...
Validation loss decreased (1.136801 --> 1.132866).  Saving model ...
Validation loss decreased (1.132866 --> 1.128677).  Saving model ...
Validation loss decreased (1.128677 --> 1.125199).  Saving model ...
Validation loss decreased (1.125199 --> 1.121080).  Saving model ...
Validation loss decreased (1.121080 --> 1.116983).  Saving model ...
Validation loss decreased (1.116983 --> 1.112761).  Saving model ...
Validation loss decreased (1.112761 --> 1.109149).  Saving model ...
Validation loss decreased (1.109149 --> 1.106156).  Saving model ...
Validation loss decreased (1.106156 --> 1.102587).  Saving model ...
Validation loss decreased (1.102587 --> 1.099379).  Saving model ...
Validation loss decreased (1.099379 --> 1.096547).  Saving model ...
Validation loss decreased (1.096547 --> 1.092432).  Saving model ...
Validation loss decreased (1.092432 --> 1.088375).  Saving model ...
Validation loss decreased (1.088375 --> 1.085002).  Saving model ...
Validation loss decreased (1.085002 --> 1.080634).  Saving model ...
Validation loss decreased (1.080634 --> 1.078714).  Saving model ...
Validation loss decreased (1.078714 --> 1.075553).  Saving model ...
Validation loss decreased (1.075553 --> 1.071806).  Saving model ...
Validation loss decreased (1.071806 --> 1.068691).  Saving model ...
Validation loss decreased (1.068691 --> 1.065625).  Saving model ...
Validation loss decreased (1.065625 --> 1.062745).  Saving model ...
Validation loss decreased (1.062745 --> 1.060238).  Saving model ...
Validation loss decreased (1.060238 --> 1.057310).  Saving model ...
Validation loss decreased (1.057310 --> 1.055186).  Saving model ...
Validation loss decreased (1.055186 --> 1.052768).  Saving model ...
Validation loss decreased (1.052768 --> 1.050685).  Saving model ...
Validation loss decreased (1.050685 --> 1.047777).  Saving model ...
Validation loss decreased (1.047777 --> 1.045476).  Saving model ...
Validation loss decreased (1.045476 --> 1.043342).  Saving model ...
Validation loss decreased (1.043342 --> 1.040609).  Saving model ...
Validation loss decreased (1.040609 --> 1.038380).  Saving model ...
Validation loss decreased (1.038380 --> 1.035972).  Saving model ...
Validation loss decreased (1.035972 --> 1.033809).  Saving model ...
Validation loss decreased (1.033809 --> 1.031293).  Saving model ...
Validation loss decreased (1.031293 --> 1.029486).  Saving model ...
Validation loss decreased (1.029486 --> 1.027177).  Saving model ...
Validation loss decreased (1.027177 --> 1.023762).  Saving model ...
Validation loss decreased (1.023762 --> 1.022274).  Saving model ...
Validation loss decreased (1.022274 --> 1.019621).  Saving model ...
Validation loss decreased (1.019621 --> 1.018124).  Saving model ...
Validation loss decreased (1.018124 --> 1.017520).  Saving model ...
Validation loss decreased (1.017520 --> 1.016430).  Saving model ...
Validation loss decreased (1.016430 --> 1.012174).  Saving model ...
Validation loss decreased (1.012174 --> 1.010130).  Saving model ...
Validation loss decreased (1.010130 --> 1.008668).  Saving model ...
Validation loss decreased (1.008668 --> 1.006845).  Saving model ...
Validation loss decreased (1.006845 --> 1.005563).  Saving model ...
Validation loss decreased (1.005563 --> 1.003765).  Saving model ...
Validation loss decreased (1.003765 --> 1.000656).  Saving model ...
Validation loss decreased (1.000656 --> 0.999698).  Saving model ...
Validation loss decreased (0.999698 --> 0.998523).  Saving model ...
Validation loss decreased (0.998523 --> 0.997549).  Saving model ...
Validation loss decreased (0.997549 --> 0.995475).  Saving model ...
Validation loss decreased (0.995475 --> 0.994205).  Saving model ...
EarlyStopping counter: 1 out of 5.0
Validation loss decreased (0.994205 --> 0.991952).  Saving model ...
Validation loss decreased (0.991952 --> 0.989259).  Saving model ...
EarlyStopping counter: 1 out of 5.0
Validation loss decreased (0.989259 --> 0.988785).  Saving model ...
Validation loss decreased (0.988785 --> 0.987100).  Saving model ...
Validation loss decreased (0.987100 --> 0.985966).  Saving model ...
Validation loss decreased (0.985966 --> 0.984790).  Saving model ...
Validation loss decreased (0.984790 --> 0.983463).  Saving model ...
Validation loss decreased (0.983463 --> 0.981395).  Saving model ...
Validation loss decreased (0.981395 --> 0.981221).  Saving model ...
Validation loss decreased (0.981221 --> 0.980613).  Saving model ...
Validation loss decreased (0.980613 --> 0.980591).  Saving model ...
EarlyStopping counter: 1 out of 5.0
Validation loss decreased (0.980591 --> 0.979452).  Saving model ...
Validation loss decreased (0.979452 --> 0.979244).  Saving model ...
Validation loss decreased (0.979244 --> 0.977468).  Saving model ...
Validation loss decreased (0.977468 --> 0.977423).  Saving model ...
Validation loss decreased (0.977423 --> 0.977406).  Saving model ...
Validation loss decreased (0.977406 --> 0.977254).  Saving model ...
Validation loss decreased (0.977254 --> 0.975980).  Saving model ...
Validation loss decreased (0.975980 --> 0.975929).  Saving model ...
EarlyStopping counter: 1 out of 5.0
Validation loss decreased (0.975929 --> 0.975199).  Saving model ...
EarlyStopping counter: 1 out of 5.0
EarlyStopping counter: 2 out of 5.0
Validation loss decreased (0.975199 --> 0.974503).  Saving model ...
Validation loss decreased (0.974503 --> 0.972757).  Saving model ...
EarlyStopping counter: 1 out of 5.0
EarlyStopping counter: 2 out of 5.0
EarlyStopping counter: 3 out of 5.0
EarlyStopping counter: 4 out of 5.0
Validation loss decreased (0.972757 --> 0.971884).  Saving model ...
Validation loss decreased (0.971884 --> 0.970620).  Saving model ...
EarlyStopping counter: 1 out of 5.0
Validation loss decreased (0.970620 --> 0.970604).  Saving model ...
Validation loss decreased (0.970604 --> 0.970466).  Saving model ...
EarlyStopping counter: 1 out of 5.0
EarlyStopping counter: 2 out of 5.0
EarlyStopping counter: 3 out of 5.0
Validation loss decreased (0.970466 --> 0.970413).  Saving model ...
EarlyStopping counter: 1 out of 5.0
Validation loss decreased (0.970413 --> 0.970382).  Saving model ...
EarlyStopping counter: 1 out of 5.0
EarlyStopping counter: 2 out of 5.0
EarlyStopping counter: 3 out of 5.0
EarlyStopping counter: 4 out of 5.0
EarlyStopping counter: 5 out of 5.0
/localscratch/yinan.29113217.0/env/lib/python3.7/site-packages/torch/nn/functional.py:1794: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.
  warnings.warn("nn.functional.tanh is deprecated. Use torch.tanh instead.")
wandb: Waiting for W&B process to finish, PID 191710... (success).
wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: \ 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: | 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: / 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: \ 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: | 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: / 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: \ 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: | 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: / 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb:                                                                                
wandb: Run history:
wandb:     e_F1 ▁▂▃▄▄▄▅▅▆▆▆▆▆▆▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇████████
wandb:   e_loss █▇▇▇▇▆▆▆▅▅▅▄▄▄▃▃▃▃▃▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:     t_F1 ▁▁▂▂▃▃▃▄▄▅▄▅▅▅▆▆▆▆▆▇▆▆▆▆▇▇▇▇█▇▇▇▇█▇█████
wandb:   t_loss ██▇▇▇▇▇▆▆▆▆▅▅▅▄▄▄▄▄▃▃▃▃▃▃▃▃▂▂▂▂▂▂▂▂▁▂▁▁▁
wandb: 
wandb: Run summary:
wandb:     e_F1 57.80036
wandb:   e_loss 0.97203
wandb:     t_F1 71.64081
wandb:   t_loss 0.72575
wandb: 
wandb: Synced 4 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Synced confused-breeze-1: https://wandb.ai/yinanazhou/xl_512_bs_8_lr_1e06_es_5_lc_True_nr_False_sr_True_stem_True_lemma_False_repeat_5_fold_1/runs/1ozm7tnb
wandb: Find logs at: ./wandb/run-20220317_182214-1ozm7tnb/logs/debug.log
wandb: 

wandb: wandb version 0.12.11 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
2022-03-17 20:02:35.214496: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1
wandb: Tracking run with wandb version 0.12.5
wandb: Syncing run trim-blaze-1
wandb: ⭐️ View project at https://wandb.ai/yinanazhou/xl_512_bs_8_lr_1e06_es_5_lc_True_nr_False_sr_True_stem_True_lemma_False_repeat_5_fold_2
wandb: 🚀 View run at https://wandb.ai/yinanazhou/xl_512_bs_8_lr_1e06_es_5_lc_True_nr_False_sr_True_stem_True_lemma_False_repeat_5_fold_2/runs/26qsx8mw
wandb: Run data is saved locally in /project/6002780/yinan/Thesis_MER_Lyrics/lyric-emotion/wandb/run-20220317_200232-26qsx8mw
wandb: Run `wandb offline` to turn off syncing.

Validation loss decreased (inf --> 1.475100).  Saving model ...
Validation loss decreased (1.475100 --> 1.447612).  Saving model ...
Validation loss decreased (1.447612 --> 1.425657).  Saving model ...
Validation loss decreased (1.425657 --> 1.409427).  Saving model ...
Validation loss decreased (1.409427 --> 1.396019).  Saving model ...
Validation loss decreased (1.396019 --> 1.385552).  Saving model ...
Validation loss decreased (1.385552 --> 1.377082).  Saving model ...
Validation loss decreased (1.377082 --> 1.370256).  Saving model ...
Validation loss decreased (1.370256 --> 1.363814).  Saving model ...
Validation loss decreased (1.363814 --> 1.358255).  Saving model ...
Validation loss decreased (1.358255 --> 1.353385).  Saving model ...
Validation loss decreased (1.353385 --> 1.347800).  Saving model ...
Validation loss decreased (1.347800 --> 1.343482).  Saving model ...
Validation loss decreased (1.343482 --> 1.339546).  Saving model ...
Validation loss decreased (1.339546 --> 1.334717).  Saving model ...
Validation loss decreased (1.334717 --> 1.329853).  Saving model ...
Validation loss decreased (1.329853 --> 1.324738).  Saving model ...
Validation loss decreased (1.324738 --> 1.321367).  Saving model ...
Validation loss decreased (1.321367 --> 1.315994).  Saving model ...
Validation loss decreased (1.315994 --> 1.310766).  Saving model ...
Validation loss decreased (1.310766 --> 1.304879).  Saving model ...
Validation loss decreased (1.304879 --> 1.299487).  Saving model ...
Validation loss decreased (1.299487 --> 1.294342).  Saving model ...
Validation loss decreased (1.294342 --> 1.287831).  Saving model ...
Validation loss decreased (1.287831 --> 1.281501).  Saving model ...
Validation loss decreased (1.281501 --> 1.275273).  Saving model ...
Validation loss decreased (1.275273 --> 1.269931).  Saving model ...
Validation loss decreased (1.269931 --> 1.263741).  Saving model ...
Validation loss decreased (1.263741 --> 1.257169).  Saving model ...
Validation loss decreased (1.257169 --> 1.248517).  Saving model ...
Validation loss decreased (1.248517 --> 1.241235).  Saving model ...
Validation loss decreased (1.241235 --> 1.234889).  Saving model ...
Validation loss decreased (1.234889 --> 1.229670).  Saving model ...
Validation loss decreased (1.229670 --> 1.224686).  Saving model ...
Validation loss decreased (1.224686 --> 1.218375).  Saving model ...
Validation loss decreased (1.218375 --> 1.209466).  Saving model ...
Validation loss decreased (1.209466 --> 1.203567).  Saving model ...
Validation loss decreased (1.203567 --> 1.195815).  Saving model ...
Validation loss decreased (1.195815 --> 1.190039).  Saving model ...
Validation loss decreased (1.190039 --> 1.187080).  Saving model ...
Validation loss decreased (1.187080 --> 1.178284).  Saving model ...
Validation loss decreased (1.178284 --> 1.168430).  Saving model ...
Validation loss decreased (1.168430 --> 1.163962).  Saving model ...
Validation loss decreased (1.163962 --> 1.157413).  Saving model ...
Validation loss decreased (1.157413 --> 1.151357).  Saving model ...
Validation loss decreased (1.151357 --> 1.144685).  Saving model ...
Validation loss decreased (1.144685 --> 1.141776).  Saving model ...
Validation loss decreased (1.141776 --> 1.134872).  Saving model ...
Validation loss decreased (1.134872 --> 1.129409).  Saving model ...
Validation loss decreased (1.129409 --> 1.125835).  Saving model ...
Validation loss decreased (1.125835 --> 1.118774).  Saving model ...
Validation loss decreased (1.118774 --> 1.113517).  Saving model ...
Validation loss decreased (1.113517 --> 1.105237).  Saving model ...
Validation loss decreased (1.105237 --> 1.100290).  Saving model ...
Validation loss decreased (1.100290 --> 1.096187).  Saving model ...
Validation loss decreased (1.096187 --> 1.093474).  Saving model ...
Validation loss decreased (1.093474 --> 1.085554).  Saving model ...
Validation loss decreased (1.085554 --> 1.079077).  Saving model ...
Validation loss decreased (1.079077 --> 1.074183).  Saving model ...
Validation loss decreased (1.074183 --> 1.070386).  Saving model ...
Validation loss decreased (1.070386 --> 1.067449).  Saving model ...
Validation loss decreased (1.067449 --> 1.062448).  Saving model ...
Validation loss decreased (1.062448 --> 1.057793).  Saving model ...
Validation loss decreased (1.057793 --> 1.052551).  Saving model ...
Validation loss decreased (1.052551 --> 1.047846).  Saving model ...
Validation loss decreased (1.047846 --> 1.043795).  Saving model ...
Validation loss decreased (1.043795 --> 1.039801).  Saving model ...
Validation loss decreased (1.039801 --> 1.035197).  Saving model ...
Validation loss decreased (1.035197 --> 1.031824).  Saving model ...
Validation loss decreased (1.031824 --> 1.028916).  Saving model ...
Validation loss decreased (1.028916 --> 1.025946).  Saving model ...
Validation loss decreased (1.025946 --> 1.020541).  Saving model ...
Validation loss decreased (1.020541 --> 1.018489).  Saving model ...
Validation loss decreased (1.018489 --> 1.014006).  Saving model ...
Validation loss decreased (1.014006 --> 1.010694).  Saving model ...
Validation loss decreased (1.010694 --> 1.006904).  Saving model ...
Validation loss decreased (1.006904 --> 1.003828).  Saving model ...
Validation loss decreased (1.003828 --> 1.000709).  Saving model ...
Validation loss decreased (1.000709 --> 0.996921).  Saving model ...
Validation loss decreased (0.996921 --> 0.994102).  Saving model ...
Validation loss decreased (0.994102 --> 0.990804).  Saving model ...
Validation loss decreased (0.990804 --> 0.989602).  Saving model ...
Validation loss decreased (0.989602 --> 0.987931).  Saving model ...
Validation loss decreased (0.987931 --> 0.984276).  Saving model ...
Validation loss decreased (0.984276 --> 0.982589).  Saving model ...
Validation loss decreased (0.982589 --> 0.979591).  Saving model ...
Validation loss decreased (0.979591 --> 0.977507).  Saving model ...
Validation loss decreased (0.977507 --> 0.974019).  Saving model ...
Validation loss decreased (0.974019 --> 0.970710).  Saving model ...
Validation loss decreased (0.970710 --> 0.968138).  Saving model ...
Validation loss decreased (0.968138 --> 0.966523).  Saving model ...
Validation loss decreased (0.966523 --> 0.964939).  Saving model ...
Validation loss decreased (0.964939 --> 0.962585).  Saving model ...
Validation loss decreased (0.962585 --> 0.960318).  Saving model ...
Validation loss decreased (0.960318 --> 0.957217).  Saving model ...
Validation loss decreased (0.957217 --> 0.955666).  Saving model ...
Validation loss decreased (0.955666 --> 0.952285).  Saving model ...
Validation loss decreased (0.952285 --> 0.950626).  Saving model ...
Validation loss decreased (0.950626 --> 0.949647).  Saving model ...
Validation loss decreased (0.949647 --> 0.949320).  Saving model ...
Validation loss decreased (0.949320 --> 0.948184).  Saving model ...
Validation loss decreased (0.948184 --> 0.945611).  Saving model ...
Validation loss decreased (0.945611 --> 0.943681).  Saving model ...
Validation loss decreased (0.943681 --> 0.943340).  Saving model ...
Validation loss decreased (0.943340 --> 0.942711).  Saving model ...
Validation loss decreased (0.942711 --> 0.940404).  Saving model ...
Validation loss decreased (0.940404 --> 0.939875).  Saving model ...
Validation loss decreased (0.939875 --> 0.937343).  Saving model ...
Validation loss decreased (0.937343 --> 0.935943).  Saving model ...
Validation loss decreased (0.935943 --> 0.935543).  Saving model ...
Validation loss decreased (0.935543 --> 0.935284).  Saving model ...
EarlyStopping counter: 1 out of 5.0
Validation loss decreased (0.935284 --> 0.932957).  Saving model ...
Validation loss decreased (0.932957 --> 0.931058).  Saving model ...
EarlyStopping counter: 1 out of 5.0
Validation loss decreased (0.931058 --> 0.928913).  Saving model ...
Validation loss decreased (0.928913 --> 0.928747).  Saving model ...
EarlyStopping counter: 1 out of 5.0
Validation loss decreased (0.928747 --> 0.926351).  Saving model ...
Validation loss decreased (0.926351 --> 0.924694).  Saving model ...
EarlyStopping counter: 1 out of 5.0
EarlyStopping counter: 2 out of 5.0
Validation loss decreased (0.924694 --> 0.923082).  Saving model ...
Validation loss decreased (0.923082 --> 0.921171).  Saving model ...
EarlyStopping counter: 1 out of 5.0
Validation loss decreased (0.921171 --> 0.919626).  Saving model ...
Validation loss decreased (0.919626 --> 0.917915).  Saving model ...
EarlyStopping counter: 1 out of 5.0
Validation loss decreased (0.917915 --> 0.916580).  Saving model ...
EarlyStopping counter: 1 out of 5.0
Validation loss decreased (0.916580 --> 0.915392).  Saving model ...
EarlyStopping counter: 1 out of 5.0
EarlyStopping counter: 2 out of 5.0
Validation loss decreased (0.915392 --> 0.914503).  Saving model ...
Validation loss decreased (0.914503 --> 0.913142).  Saving model ...
Validation loss decreased (0.913142 --> 0.911770).  Saving model ...
EarlyStopping counter: 1 out of 5.0
EarlyStopping counter: 2 out of 5.0
Validation loss decreased (0.911770 --> 0.911042).  Saving model ...
EarlyStopping counter: 1 out of 5.0
Validation loss decreased (0.911042 --> 0.910819).  Saving model ...
Validation loss decreased (0.910819 --> 0.908754).  Saving model ...
EarlyStopping counter: 1 out of 5.0
EarlyStopping counter: 2 out of 5.0
Validation loss decreased (0.908754 --> 0.908563).  Saving model ...
Validation loss decreased (0.908563 --> 0.908485).  Saving model ...
Validation loss decreased (0.908485 --> 0.908408).  Saving model ...
EarlyStopping counter: 1 out of 5.0
Validation loss decreased (0.908408 --> 0.907448).  Saving model ...
Validation loss decreased (0.907448 --> 0.906647).  Saving model ...
Validation loss decreased (0.906647 --> 0.905843).  Saving model ...
EarlyStopping counter: 1 out of 5.0
EarlyStopping counter: 2 out of 5.0
EarlyStopping counter: 3 out of 5.0
EarlyStopping counter: 4 out of 5.0
Validation loss decreased (0.905843 --> 0.905630).  Saving model ...
Validation loss decreased (0.905630 --> 0.903708).  Saving model ...
EarlyStopping counter: 1 out of 5.0
EarlyStopping counter: 2 out of 5.0
EarlyStopping counter: 3 out of 5.0
EarlyStopping counter: 4 out of 5.0
EarlyStopping counter: 5 out of 5.0
/localscratch/yinan.29113217.0/env/lib/python3.7/site-packages/torch/nn/functional.py:1794: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.
  warnings.warn("nn.functional.tanh is deprecated. Use torch.tanh instead.")
wandb: Waiting for W&B process to finish, PID 197080... (success).
wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: \ 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: | 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: / 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: \ 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: | 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: / 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: \ 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: | 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: / 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb:                                                                                
wandb: Run history:
wandb:     e_F1 ▁▃▄▄▅▅▅▆▆▆▆▇▇▇▇▇▇█▇█▇███████████████████
wandb:   e_loss █▇▇▇▆▆▆▅▅▅▄▄▄▄▃▃▃▃▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:     t_F1 ▁▂▃▃▃▄▄▄▅▅▆▅▅▅▆▅▆▆▇▆▇▆▇▇▇▇▇▇▇▇▇█▇▇██████
wandb:   t_loss █▇▇▇▇▇▆▆▆▆▅▅▅▅▅▄▄▄▄▄▃▃▃▃▃▃▂▂▂▂▂▂▂▂▂▂▁▂▁▁
wandb: 
wandb: Run summary:
wandb:     e_F1 64.62089
wandb:   e_loss 0.90489
wandb:     t_F1 69.44725
wandb:   t_loss 0.73501
wandb: 
wandb: Synced 4 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Synced trim-blaze-1: https://wandb.ai/yinanazhou/xl_512_bs_8_lr_1e06_es_5_lc_True_nr_False_sr_True_stem_True_lemma_False_repeat_5_fold_2/runs/26qsx8mw
wandb: Find logs at: ./wandb/run-20220317_200232-26qsx8mw/logs/debug.log
wandb: 

