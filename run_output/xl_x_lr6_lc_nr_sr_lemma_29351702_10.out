Unloading StdEnv/2020

Due to MODULEPATH changes, the following have been reloaded:
  1) mii/1.1.1


The following have been reloaded with a version change:
  1) python/3.8.2 => python/3.7.4

Using base prefix '/cvmfs/soft.computecanada.ca/easybuild/software/2017/Core/python/3.7.4'
New python executable in /localscratch/yinan.29544078.0/env/bin/python
Installing setuptools, pip, wheel...
done.
Ignoring pip: markers 'python_version < "3"' don't match your environment
Looking in links: /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/nix/avx2, /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/nix/generic, /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic
Collecting pip
Installing collected packages: pip
  Found existing installation: pip 19.1.1
    Uninstalling pip-19.1.1:
      Successfully uninstalled pip-19.1.1
Successfully installed pip-21.2.3+computecanada
Looking in links: /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/nix/avx2, /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/nix/generic, /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/keras-2.8.0+computecanada-py2.py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/Keras_Preprocessing-1.1.2+computecanada-py3-none-any.whl
Requirement already satisfied: matplotlib in /cvmfs/soft.computecanada.ca/easybuild/software/2017/Core/scipy-stack/2019a/lib/python3.7/site-packages (from -r requirements.txt (line 3)) (3.0.2)
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/nltk-3.6.5+computecanada-py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/scikit_learn-0.22.1+computecanada-cp37-cp37m-linux_x86_64.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/tensorboard-2.3.0+computecanada-py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/tensorboard_plugin_wit-1.7.0+computecanada-py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/tensorflow_gpu-2.3.0+computecanada-cp37-cp37m-linux_x86_64.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/tensorflow_estimator-2.3.0+computecanada-py2.py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/tokenizers-0.5.2+computecanada-cp37-cp37m-linux_x86_64.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/nix/avx2/torch-1.4.0+computecanada-cp37-cp37m-linux_x86_64.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/torchtext-0.6.0+computecanada-py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/torchvision-0.8.2+computecanada-cp37-cp37m-linux_x86_64.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/transformers-2.5.1+computecanada-py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/urllib3-1.26.7+computecanada-py2.py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/click-8.0.4+computecanada-py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/joblib-1.1.0+computecanada-py2.py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/tqdm-4.63.1+computecanada-py2.py3-none-any.whl
ERROR: Could not find a version that satisfies the requirement regex>=2021.8.3 (from nltk) (from versions: 2018.1.10+computecanada, 2019.11.1+computecanada, 2020.11.13+computecanada)
ERROR: No matching distribution found for regex>=2021.8.3
Looking in links: /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/nix/avx2, /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/nix/generic, /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic
ERROR: Could not find a version that satisfies the requirement numpy==1.20.0+computacanada (from versions: 1.15.0+computecanada, 1.15.2+computecanada, 1.15.4+computecanada, 1.16.0+computecanada, 1.16.2+computecanada, 1.16.3+computecanada, 1.17.4+computecanada, 1.18.1+computecanada, 1.18.4+computecanada, 1.19.1+computecanada, 1.19.2+computecanada, 1.20.2+computecanada)
ERROR: No matching distribution found for numpy==1.20.0+computacanada
Looking in links: /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/nix/avx2, /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/nix/generic, /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/wandb-0.12.5+computecanada-py2.py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/configparser-5.0.2+computecanada-py3-none-any.whl
Requirement already satisfied: python-dateutil>=2.6.1 in /cvmfs/soft.computecanada.ca/easybuild/software/2017/Core/scipy-stack/2019a/lib/python3.7/site-packages (from wandb) (2.7.5)
Requirement already satisfied: requests<3,>=2.0.0 in /cvmfs/soft.computecanada.ca/easybuild/software/2017/Core/scipy-stack/2019a/lib/python3.7/site-packages (from wandb) (2.21.0)
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/shortuuid-1.0.1+computecanada-py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/psutil-5.7.3+computecanada-cp37-cp37m-linux_x86_64.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/GitPython-3.1.24+computecanada-py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/sentry_sdk-1.5.0+computecanada-py2.py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/subprocess32-3.5.4+computecanada-py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/click-8.0.4+computecanada-py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/promise-2.3+computecanada-py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/protobuf-3.19.4+computecanada-py2.py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/docker_pycreds-0.4.0+computecanada-py2.py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/PyYAML-5.3.1+computecanada-cp37-cp37m-linux_x86_64.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/pathtools-0.1.2+computecanada-py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/yaspin-2.1.0+computecanada-py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/six-1.16.0+computecanada-py2.py3-none-any.whl
Requirement already satisfied: importlib-metadata in /cvmfs/soft.computecanada.ca/easybuild/software/2017/Core/scipy-stack/2019a/lib/python3.7/site-packages (from Click!=8.0.0,>=7.0->wandb) (0.8)
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/gitdb-4.0.9+computecanada-py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/typing_extensions-4.1.1+computecanada-py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/smmap-5.0.0+computecanada-py3-none-any.whl
Requirement already satisfied: idna<2.9,>=2.5 in /cvmfs/soft.computecanada.ca/easybuild/software/2017/Core/scipy-stack/2019a/lib/python3.7/site-packages (from requests<3,>=2.0.0->wandb) (2.8)
Requirement already satisfied: urllib3<1.25,>=1.21.1 in /cvmfs/soft.computecanada.ca/easybuild/software/2017/Core/scipy-stack/2019a/lib/python3.7/site-packages (from requests<3,>=2.0.0->wandb) (1.24.1)
Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /cvmfs/soft.computecanada.ca/easybuild/software/2017/Core/scipy-stack/2019a/lib/python3.7/site-packages (from requests<3,>=2.0.0->wandb) (3.0.4)
Requirement already satisfied: certifi>=2017.4.17 in /cvmfs/soft.computecanada.ca/easybuild/software/2017/Core/scipy-stack/2019a/lib/python3.7/site-packages (from requests<3,>=2.0.0->wandb) (2018.11.29)
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/termcolor-1.1.0+computecanada-py3-none-any.whl
Requirement already satisfied: zipp>=0.3.2 in /cvmfs/soft.computecanada.ca/easybuild/software/2017/Core/scipy-stack/2019a/lib/python3.7/site-packages (from importlib-metadata->Click!=8.0.0,>=7.0->wandb) (0.3.3)
Installing collected packages: smmap, typing-extensions, termcolor, six, gitdb, yaspin, subprocess32, shortuuid, sentry-sdk, PyYAML, psutil, protobuf, promise, pathtools, GitPython, docker-pycreds, configparser, Click, wandb
  Attempting uninstall: six
    Found existing installation: six 1.12.0
    Not uninstalling six at /cvmfs/soft.computecanada.ca/easybuild/software/2017/Core/scipy-stack/2019a/lib/python3.7/site-packages, outside environment /localscratch/yinan.29544078.0/env
    Can't uninstall 'six'. No files were found to uninstall.
Successfully installed Click-8.0.4+computecanada GitPython-3.1.24+computecanada PyYAML-5.3.1+computecanada configparser-5.0.2+computecanada docker-pycreds-0.4.0+computecanada gitdb-4.0.9+computecanada pathtools-0.1.2+computecanada promise-2.3+computecanada protobuf-3.19.4+computecanada psutil-5.7.3+computecanada sentry-sdk-1.5.0+computecanada shortuuid-1.0.1+computecanada six-1.16.0+computecanada smmap-5.0.0+computecanada subprocess32-3.5.4+computecanada termcolor-1.1.0+computecanada typing-extensions-4.1.1+computecanada wandb-0.12.5+computecanada yaspin-2.1.0+computecanada
Looking in links: /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/nix/avx2, /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/nix/generic, /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic
ERROR: Could not find a version that satisfies the requirement sagemaker (from versions: none)
ERROR: No matching distribution found for sagemaker
Looking in links: /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/nix/avx2, /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/nix/generic, /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/torch-1.9.1+computecanada-cp37-cp37m-linux_x86_64.whl
Requirement already satisfied: typing-extensions in /localscratch/yinan.29544078.0/env/lib/python3.7/site-packages (from torch) (4.1.1+computecanada)
Installing collected packages: torch
Successfully installed torch-1.9.1+computecanada
Looking in links: /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/nix/avx2, /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/nix/generic, /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/transformers-2.5.1+computecanada-py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/tokenizers-0.5.2+computecanada-cp37-cp37m-linux_x86_64.whl
Requirement already satisfied: numpy in /cvmfs/soft.computecanada.ca/easybuild/software/2017/Core/scipy-stack/2019a/lib/python3.7/site-packages (from transformers==2.5.1+computecanada) (1.16.0)
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/filelock-3.4.2+computecanada-py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/regex-2020.11.13+computecanada-cp37-cp37m-linux_x86_64.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/sacremoses-0.0.49+computecanada-py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/tqdm-4.63.1+computecanada-py2.py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/sentencepiece-0.1.91+computecanada-cp37-cp37m-linux_x86_64.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/boto3-1.21.14+computecanada-py3-none-any.whl
Requirement already satisfied: requests in /cvmfs/soft.computecanada.ca/easybuild/software/2017/Core/scipy-stack/2019a/lib/python3.7/site-packages (from transformers==2.5.1+computecanada) (2.21.0)
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/jmespath-0.10.0+computecanada-py2.py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/botocore-1.24.14+computecanada-py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/s3transfer-0.5.1+computecanada-py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/urllib3-1.26.8+computecanada-py2.py3-none-any.whl
Requirement already satisfied: python-dateutil<3.0.0,>=2.1 in /cvmfs/soft.computecanada.ca/easybuild/software/2017/Core/scipy-stack/2019a/lib/python3.7/site-packages (from botocore<1.25.0,>=1.24.14->boto3->transformers==2.5.1+computecanada) (2.7.5)
Requirement already satisfied: six>=1.5 in /localscratch/yinan.29544078.0/env/lib/python3.7/site-packages (from python-dateutil<3.0.0,>=2.1->botocore<1.25.0,>=1.24.14->boto3->transformers==2.5.1+computecanada) (1.16.0+computecanada)
Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /cvmfs/soft.computecanada.ca/easybuild/software/2017/Core/scipy-stack/2019a/lib/python3.7/site-packages (from requests->transformers==2.5.1+computecanada) (3.0.4)
Requirement already satisfied: certifi>=2017.4.17 in /cvmfs/soft.computecanada.ca/easybuild/software/2017/Core/scipy-stack/2019a/lib/python3.7/site-packages (from requests->transformers==2.5.1+computecanada) (2018.11.29)
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/requests-2.27.1+computecanada-py2.py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/charset_normalizer-2.0.12+computecanada-py3-none-any.whl
Requirement already satisfied: idna<4,>=2.5 in /cvmfs/soft.computecanada.ca/easybuild/software/2017/Core/scipy-stack/2019a/lib/python3.7/site-packages (from requests->transformers==2.5.1+computecanada) (2.8)
Requirement already satisfied: click in /localscratch/yinan.29544078.0/env/lib/python3.7/site-packages (from sacremoses->transformers==2.5.1+computecanada) (8.0.4+computecanada)
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/joblib-1.1.0+computecanada-py2.py3-none-any.whl
Requirement already satisfied: importlib-metadata in /cvmfs/soft.computecanada.ca/easybuild/software/2017/Core/scipy-stack/2019a/lib/python3.7/site-packages (from click->sacremoses->transformers==2.5.1+computecanada) (0.8)
Requirement already satisfied: zipp>=0.3.2 in /cvmfs/soft.computecanada.ca/easybuild/software/2017/Core/scipy-stack/2019a/lib/python3.7/site-packages (from importlib-metadata->click->sacremoses->transformers==2.5.1+computecanada) (0.3.3)
Installing collected packages: urllib3, jmespath, botocore, tqdm, s3transfer, regex, joblib, charset-normalizer, tokenizers, sentencepiece, sacremoses, requests, filelock, boto3, transformers
  Attempting uninstall: urllib3
    Found existing installation: urllib3 1.24.1
    Not uninstalling urllib3 at /cvmfs/soft.computecanada.ca/easybuild/software/2017/Core/scipy-stack/2019a/lib/python3.7/site-packages, outside environment /localscratch/yinan.29544078.0/env
    Can't uninstall 'urllib3'. No files were found to uninstall.
  Attempting uninstall: requests
    Found existing installation: requests 2.21.0
    Not uninstalling requests at /cvmfs/soft.computecanada.ca/easybuild/software/2017/Core/scipy-stack/2019a/lib/python3.7/site-packages, outside environment /localscratch/yinan.29544078.0/env
    Can't uninstall 'requests'. No files were found to uninstall.
Successfully installed boto3-1.21.14+computecanada botocore-1.24.14+computecanada charset-normalizer-2.0.12+computecanada filelock-3.4.2+computecanada jmespath-0.10.0+computecanada joblib-1.1.0+computecanada regex-2020.11.13+computecanada requests-2.27.1+computecanada s3transfer-0.5.1+computecanada sacremoses-0.0.49+computecanada sentencepiece-0.1.91+computecanada tokenizers-0.5.2+computecanada tqdm-4.63.1+computecanada transformers-2.5.1+computecanada urllib3-1.26.8+computecanada
Looking in links: /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/nix/avx2, /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/nix/generic, /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/tensorflow_gpu-2.3.0+computecanada-cp37-cp37m-linux_x86_64.whl
Requirement already satisfied: protobuf>=3.9.2 in /localscratch/yinan.29544078.0/env/lib/python3.7/site-packages (from tensorflow_gpu==2.3.0+computecanada) (3.19.4+computecanada)
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/tensorboard-2.8.0+computecanada-py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/google_pasta-0.2.0+computecanada-py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/nix/avx2/h5py-2.10.0+computecanada-cp37-cp37m-linux_x86_64.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/opt_einsum-3.3.0+computecanada-py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/grpcio-1.38.0+computecanada-cp37-cp37m-linux_x86_64.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/astunparse-1.6.3+computecanada-py2.py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/Keras_Preprocessing-1.1.2+computecanada-py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/wrapt-1.11.2+computecanada-cp37-cp37m-linux_x86_64.whl
Requirement already satisfied: wheel>=0.26 in /localscratch/yinan.29544078.0/env/lib/python3.7/site-packages (from tensorflow_gpu==2.3.0+computecanada) (0.33.4)
Requirement already satisfied: termcolor>=1.1.0 in /localscratch/yinan.29544078.0/env/lib/python3.7/site-packages (from tensorflow_gpu==2.3.0+computecanada) (1.1.0+computecanada)
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/nix/generic/scipy-1.4.1+computecanada-cp37-cp37m-linux_x86_64.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/gast-0.3.3+computecanada-py3-none-any.whl
Requirement already satisfied: six>=1.12.0 in /localscratch/yinan.29544078.0/env/lib/python3.7/site-packages (from tensorflow_gpu==2.3.0+computecanada) (1.16.0+computecanada)
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/tensorflow_estimator-2.3.0+computecanada-py2.py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/absl_py-1.0.0+computecanada-py3-none-any.whl
Requirement already satisfied: numpy<1.19.0,>=1.16.0 in /cvmfs/soft.computecanada.ca/easybuild/software/2017/Core/scipy-stack/2019a/lib/python3.7/site-packages (from tensorflow_gpu==2.3.0+computecanada) (1.16.0)
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/Werkzeug-2.0.3+computecanada-py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/tensorboard_plugin_wit-1.8.0+computecanada-py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/google_auth_oauthlib-0.4.6+computecanada-py2.py3-none-any.whl
Requirement already satisfied: setuptools>=41.0.0 in /localscratch/yinan.29544078.0/env/lib/python3.7/site-packages (from tensorboard<3,>=2.3.0->tensorflow_gpu==2.3.0+computecanada) (41.0.1)
Requirement already satisfied: requests<3,>=2.21.0 in /localscratch/yinan.29544078.0/env/lib/python3.7/site-packages (from tensorboard<3,>=2.3.0->tensorflow_gpu==2.3.0+computecanada) (2.27.1+computecanada)
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/Markdown-3.3.6+computecanada-py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/tensorboard_data_server-0.6.1+computecanada-py3-none-linux_x86_64.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/google_auth-2.3.3+computecanada-py2.py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/pyasn1_modules-0.2.8+computecanada-py2.py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/cachetools-4.2.4+computecanada-py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/rsa-4.8+computecanada-py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/requests_oauthlib-1.3.0+computecanada-py2.py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/importlib_metadata-4.10.1+computecanada-py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/zipp-3.7.0+computecanada-py3-none-any.whl
Requirement already satisfied: typing-extensions>=3.6.4 in /localscratch/yinan.29544078.0/env/lib/python3.7/site-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard<3,>=2.3.0->tensorflow_gpu==2.3.0+computecanada) (4.1.1+computecanada)
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/pyasn1-0.4.8+computecanada-py2.py3-none-any.whl
Requirement already satisfied: idna<4,>=2.5 in /cvmfs/soft.computecanada.ca/easybuild/software/2017/Core/scipy-stack/2019a/lib/python3.7/site-packages (from requests<3,>=2.21.0->tensorboard<3,>=2.3.0->tensorflow_gpu==2.3.0+computecanada) (2.8)
Requirement already satisfied: urllib3<1.27,>=1.21.1 in /localscratch/yinan.29544078.0/env/lib/python3.7/site-packages (from requests<3,>=2.21.0->tensorboard<3,>=2.3.0->tensorflow_gpu==2.3.0+computecanada) (1.26.8+computecanada)
Requirement already satisfied: charset-normalizer~=2.0.0 in /localscratch/yinan.29544078.0/env/lib/python3.7/site-packages (from requests<3,>=2.21.0->tensorboard<3,>=2.3.0->tensorflow_gpu==2.3.0+computecanada) (2.0.12+computecanada)
Requirement already satisfied: certifi>=2017.4.17 in /cvmfs/soft.computecanada.ca/easybuild/software/2017/Core/scipy-stack/2019a/lib/python3.7/site-packages (from requests<3,>=2.21.0->tensorboard<3,>=2.3.0->tensorflow_gpu==2.3.0+computecanada) (2018.11.29)
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/oauthlib-3.1.1+computecanada-py2.py3-none-any.whl
Installing collected packages: pyasn1, zipp, rsa, pyasn1-modules, oauthlib, cachetools, requests-oauthlib, importlib-metadata, google-auth, werkzeug, tensorboard-plugin-wit, tensorboard-data-server, markdown, grpcio, google-auth-oauthlib, absl-py, wrapt, tensorflow-estimator, tensorboard, scipy, opt-einsum, keras-preprocessing, h5py, google-pasta, gast, astunparse, tensorflow-gpu
  Attempting uninstall: pyasn1
    Found existing installation: pyasn1 0.4.3
    Not uninstalling pyasn1 at /cvmfs/soft.computecanada.ca/easybuild/software/2017/Core/scipy-stack/2019a/lib/python3.7/site-packages, outside environment /localscratch/yinan.29544078.0/env
    Can't uninstall 'pyasn1'. No files were found to uninstall.
  Attempting uninstall: zipp
    Found existing installation: zipp 0.3.3
    Not uninstalling zipp at /cvmfs/soft.computecanada.ca/easybuild/software/2017/Core/scipy-stack/2019a/lib/python3.7/site-packages, outside environment /localscratch/yinan.29544078.0/env
    Can't uninstall 'zipp'. No files were found to uninstall.
  Attempting uninstall: importlib-metadata
    Found existing installation: importlib-metadata 0.8
    Not uninstalling importlib-metadata at /cvmfs/soft.computecanada.ca/easybuild/software/2017/Core/scipy-stack/2019a/lib/python3.7/site-packages, outside environment /localscratch/yinan.29544078.0/env
    Can't uninstall 'importlib-metadata'. No files were found to uninstall.
  Attempting uninstall: scipy
    Found existing installation: scipy 1.2.0
    Not uninstalling scipy at /cvmfs/soft.computecanada.ca/easybuild/software/2017/Core/scipy-stack/2019a/lib/python3.7/site-packages, outside environment /localscratch/yinan.29544078.0/env
    Can't uninstall 'scipy'. No files were found to uninstall.
Successfully installed absl-py-1.0.0+computecanada astunparse-1.6.3+computecanada cachetools-4.2.4+computecanada gast-0.3.3+computecanada google-auth-2.3.3+computecanada google-auth-oauthlib-0.4.6+computecanada google-pasta-0.2.0+computecanada grpcio-1.38.0+computecanada h5py-2.10.0+computecanada importlib-metadata-4.10.1+computecanada keras-preprocessing-1.1.2+computecanada markdown-3.3.6+computecanada oauthlib-3.1.1+computecanada opt-einsum-3.3.0+computecanada pyasn1-0.4.8+computecanada pyasn1-modules-0.2.8+computecanada requests-oauthlib-1.3.0+computecanada rsa-4.8+computecanada scipy-1.4.1+computecanada tensorboard-2.8.0+computecanada tensorboard-data-server-0.6.1+computecanada tensorboard-plugin-wit-1.8.0+computecanada tensorflow-estimator-2.3.0+computecanada tensorflow-gpu-2.3.0+computecanada werkzeug-2.0.3+computecanada wrapt-1.11.2+computecanada zipp-3.7.0+computecanada
Looking in links: /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/nix/avx2, /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/nix/generic, /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/keras-2.8.0+computecanada-py2.py3-none-any.whl
Installing collected packages: Keras
Successfully installed Keras-2.8.0+computecanada
Looking in links: /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/nix/avx2, /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/nix/generic, /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/urllib3-1.26.7+computecanada-py2.py3-none-any.whl
Installing collected packages: urllib3
  Attempting uninstall: urllib3
    Found existing installation: urllib3 1.26.8+computecanada
    Uninstalling urllib3-1.26.8+computecanada:
      Successfully uninstalled urllib3-1.26.8+computecanada
Successfully installed urllib3-1.26.7+computecanada
Looking in links: /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/nix/avx2, /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/nix/generic, /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/nltk-3.7+computecanada-py3-none-any.whl
Requirement already satisfied: tqdm in /localscratch/yinan.29544078.0/env/lib/python3.7/site-packages (from nltk) (4.63.1+computecanada)
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/nltk-3.6.5+computecanada-py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/nltk-3.6.3+computecanada-py3-none-any.whl
Requirement already satisfied: regex in /localscratch/yinan.29544078.0/env/lib/python3.7/site-packages (from nltk) (2020.11.13+computecanada)
Requirement already satisfied: joblib in /localscratch/yinan.29544078.0/env/lib/python3.7/site-packages (from nltk) (1.1.0+computecanada)
Requirement already satisfied: click in /localscratch/yinan.29544078.0/env/lib/python3.7/site-packages (from nltk) (8.0.4+computecanada)
Requirement already satisfied: importlib-metadata in /localscratch/yinan.29544078.0/env/lib/python3.7/site-packages (from click->nltk) (4.10.1+computecanada)
Requirement already satisfied: zipp>=0.5 in /localscratch/yinan.29544078.0/env/lib/python3.7/site-packages (from importlib-metadata->click->nltk) (3.7.0+computecanada)
Requirement already satisfied: typing-extensions>=3.6.4 in /localscratch/yinan.29544078.0/env/lib/python3.7/site-packages (from importlib-metadata->click->nltk) (4.1.1+computecanada)
Installing collected packages: nltk
Successfully installed nltk-3.6.3+computecanada
Looking in links: /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/nix/avx2, /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/nix/generic, /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/scikit_learn-0.22.1+computecanada-cp37-cp37m-linux_x86_64.whl
Requirement already satisfied: joblib>=0.11 in /localscratch/yinan.29544078.0/env/lib/python3.7/site-packages (from scikit-learn==0.22.1) (1.1.0+computecanada)
Requirement already satisfied: scipy>=0.17.0 in /localscratch/yinan.29544078.0/env/lib/python3.7/site-packages (from scikit-learn==0.22.1) (1.4.1+computecanada)
Requirement already satisfied: numpy>=1.11.0 in /cvmfs/soft.computecanada.ca/easybuild/software/2017/Core/scipy-stack/2019a/lib/python3.7/site-packages (from scikit-learn==0.22.1) (1.16.0)
Installing collected packages: scikit-learn
Successfully installed scikit-learn-0.22.1+computecanada
Looking in links: /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/nix/avx2, /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/nix/generic, /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic
Requirement already satisfied: tokenizers==0.5.2 in /localscratch/yinan.29544078.0/env/lib/python3.7/site-packages (0.5.2+computecanada)
wandb: Appending key for api.wandb.ai to your netrc file: /home/yinan/.netrc
Starting Task
2022-03-26 00:14:06.485577: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1
[nltk_data] Downloading package stopwords to /home/yinan/nltk_data...
[nltk_data]   Package stopwords is already up-to-date!
[nltk_data] Downloading package wordnet to /home/yinan/nltk_data...
[nltk_data]   Package wordnet is already up-to-date!
wandb: Currently logged in as: yinanazhou (use `wandb login --relogin` to force relogin)
wandb: wandb version 0.12.11 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
2022-03-26 00:14:22.471523: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1
wandb: Tracking run with wandb version 0.12.5
wandb: Syncing run crisp-waterfall-3
wandb: ⭐️ View project at https://wandb.ai/yinanazhou/xl_512_bs_8_lr_1e06_es_10_lc_True_nr_True_sr_True_stem_False_lemma_True_repeat_1_fold_1
wandb: 🚀 View run at https://wandb.ai/yinanazhou/xl_512_bs_8_lr_1e06_es_10_lc_True_nr_True_sr_True_stem_False_lemma_True_repeat_1_fold_1/runs/2ritkfk6
wandb: Run data is saved locally in /project/6002780/yinan/Thesis_MER_Lyrics/lyric-emotion/wandb/run-20220326_001420-2ritkfk6
wandb: Run `wandb offline` to turn off syncing.

Validation loss decreased (inf --> 1.441050).  Saving model ...
Validation loss decreased (1.441050 --> 1.422546).  Saving model ...
Validation loss decreased (1.422546 --> 1.406987).  Saving model ...
Validation loss decreased (1.406987 --> 1.394437).  Saving model ...
Validation loss decreased (1.394437 --> 1.385030).  Saving model ...
Validation loss decreased (1.385030 --> 1.377016).  Saving model ...
Validation loss decreased (1.377016 --> 1.371314).  Saving model ...
Validation loss decreased (1.371314 --> 1.366144).  Saving model ...
Validation loss decreased (1.366144 --> 1.361522).  Saving model ...
Validation loss decreased (1.361522 --> 1.356556).  Saving model ...
Validation loss decreased (1.356556 --> 1.351467).  Saving model ...
Validation loss decreased (1.351467 --> 1.346667).  Saving model ...
Validation loss decreased (1.346667 --> 1.341938).  Saving model ...
Validation loss decreased (1.341938 --> 1.337148).  Saving model ...
Validation loss decreased (1.337148 --> 1.332648).  Saving model ...
Validation loss decreased (1.332648 --> 1.328454).  Saving model ...
Validation loss decreased (1.328454 --> 1.323934).  Saving model ...
Validation loss decreased (1.323934 --> 1.318981).  Saving model ...
Validation loss decreased (1.318981 --> 1.313722).  Saving model ...
Validation loss decreased (1.313722 --> 1.308605).  Saving model ...
Validation loss decreased (1.308605 --> 1.303833).  Saving model ...
Validation loss decreased (1.303833 --> 1.298572).  Saving model ...
Validation loss decreased (1.298572 --> 1.294304).  Saving model ...
Validation loss decreased (1.294304 --> 1.289001).  Saving model ...
Validation loss decreased (1.289001 --> 1.283986).  Saving model ...
Validation loss decreased (1.283986 --> 1.279423).  Saving model ...
Validation loss decreased (1.279423 --> 1.275605).  Saving model ...
Validation loss decreased (1.275605 --> 1.273295).  Saving model ...
Validation loss decreased (1.273295 --> 1.271246).  Saving model ...
Validation loss decreased (1.271246 --> 1.268588).  Saving model ...
Validation loss decreased (1.268588 --> 1.264408).  Saving model ...
Validation loss decreased (1.264408 --> 1.259131).  Saving model ...
Validation loss decreased (1.259131 --> 1.257839).  Saving model ...
Validation loss decreased (1.257839 --> 1.251614).  Saving model ...
Validation loss decreased (1.251614 --> 1.250597).  Saving model ...
Validation loss decreased (1.250597 --> 1.245848).  Saving model ...
Validation loss decreased (1.245848 --> 1.242941).  Saving model ...
Validation loss decreased (1.242941 --> 1.237915).  Saving model ...
Validation loss decreased (1.237915 --> 1.235737).  Saving model ...
Validation loss decreased (1.235737 --> 1.235414).  Saving model ...
Validation loss decreased (1.235414 --> 1.229424).  Saving model ...
Validation loss decreased (1.229424 --> 1.225860).  Saving model ...
Validation loss decreased (1.225860 --> 1.224981).  Saving model ...
Validation loss decreased (1.224981 --> 1.219308).  Saving model ...
Validation loss decreased (1.219308 --> 1.218950).  Saving model ...
Validation loss decreased (1.218950 --> 1.216117).  Saving model ...
Validation loss decreased (1.216117 --> 1.214318).  Saving model ...
Validation loss decreased (1.214318 --> 1.212653).  Saving model ...
Validation loss decreased (1.212653 --> 1.209030).  Saving model ...
Validation loss decreased (1.209030 --> 1.203927).  Saving model ...
Validation loss decreased (1.203927 --> 1.199859).  Saving model ...
Validation loss decreased (1.199859 --> 1.196007).  Saving model ...
Validation loss decreased (1.196007 --> 1.193905).  Saving model ...
Validation loss decreased (1.193905 --> 1.189473).  Saving model ...
EarlyStopping counter: 1 out of 10.0
Validation loss decreased (1.189473 --> 1.187035).  Saving model ...
Validation loss decreased (1.187035 --> 1.185654).  Saving model ...
Validation loss decreased (1.185654 --> 1.182188).  Saving model ...
Validation loss decreased (1.182188 --> 1.176013).  Saving model ...
EarlyStopping counter: 1 out of 10.0
Validation loss decreased (1.176013 --> 1.171099).  Saving model ...
EarlyStopping counter: 1 out of 10.0
Validation loss decreased (1.171099 --> 1.168495).  Saving model ...
Validation loss decreased (1.168495 --> 1.166129).  Saving model ...
Validation loss decreased (1.166129 --> 1.164369).  Saving model ...
Validation loss decreased (1.164369 --> 1.160331).  Saving model ...
Validation loss decreased (1.160331 --> 1.158230).  Saving model ...
Validation loss decreased (1.158230 --> 1.154337).  Saving model ...
Validation loss decreased (1.154337 --> 1.152773).  Saving model ...
Validation loss decreased (1.152773 --> 1.151421).  Saving model ...
Validation loss decreased (1.151421 --> 1.147668).  Saving model ...
Validation loss decreased (1.147668 --> 1.145653).  Saving model ...
Validation loss decreased (1.145653 --> 1.144194).  Saving model ...
Validation loss decreased (1.144194 --> 1.138765).  Saving model ...
Validation loss decreased (1.138765 --> 1.132761).  Saving model ...
Validation loss decreased (1.132761 --> 1.132460).  Saving model ...
EarlyStopping counter: 1 out of 10.0
Validation loss decreased (1.132460 --> 1.132265).  Saving model ...
Validation loss decreased (1.132265 --> 1.126817).  Saving model ...
Validation loss decreased (1.126817 --> 1.119659).  Saving model ...
EarlyStopping counter: 1 out of 10.0
EarlyStopping counter: 2 out of 10.0
EarlyStopping counter: 3 out of 10.0
EarlyStopping counter: 4 out of 10.0
Validation loss decreased (1.119659 --> 1.116509).  Saving model ...
Validation loss decreased (1.116509 --> 1.107057).  Saving model ...
Validation loss decreased (1.107057 --> 1.103257).  Saving model ...
EarlyStopping counter: 1 out of 10.0
EarlyStopping counter: 2 out of 10.0
EarlyStopping counter: 3 out of 10.0
Validation loss decreased (1.103257 --> 1.099335).  Saving model ...
Validation loss decreased (1.099335 --> 1.096625).  Saving model ...
EarlyStopping counter: 1 out of 10.0
EarlyStopping counter: 2 out of 10.0
EarlyStopping counter: 3 out of 10.0
EarlyStopping counter: 4 out of 10.0
EarlyStopping counter: 5 out of 10.0
Validation loss decreased (1.096625 --> 1.093952).  Saving model ...
Validation loss decreased (1.093952 --> 1.092028).  Saving model ...
EarlyStopping counter: 1 out of 10.0
Validation loss decreased (1.092028 --> 1.090102).  Saving model ...
Validation loss decreased (1.090102 --> 1.088411).  Saving model ...
Validation loss decreased (1.088411 --> 1.082982).  Saving model ...
EarlyStopping counter: 1 out of 10.0
EarlyStopping counter: 2 out of 10.0
Validation loss decreased (1.082982 --> 1.080259).  Saving model ...
Validation loss decreased (1.080259 --> 1.076832).  Saving model ...
Validation loss decreased (1.076832 --> 1.075624).  Saving model ...
Validation loss decreased (1.075624 --> 1.073223).  Saving model ...
Validation loss decreased (1.073223 --> 1.070194).  Saving model ...
EarlyStopping counter: 1 out of 10.0
EarlyStopping counter: 2 out of 10.0
EarlyStopping counter: 3 out of 10.0
EarlyStopping counter: 4 out of 10.0
EarlyStopping counter: 5 out of 10.0
EarlyStopping counter: 6 out of 10.0
EarlyStopping counter: 7 out of 10.0
Validation loss decreased (1.070194 --> 1.067802).  Saving model ...
Validation loss decreased (1.067802 --> 1.065894).  Saving model ...
Validation loss decreased (1.065894 --> 1.063728).  Saving model ...
Validation loss decreased (1.063728 --> 1.061552).  Saving model ...
Validation loss decreased (1.061552 --> 1.061049).  Saving model ...
Validation loss decreased (1.061049 --> 1.056545).  Saving model ...
EarlyStopping counter: 1 out of 10.0
EarlyStopping counter: 2 out of 10.0
EarlyStopping counter: 3 out of 10.0
EarlyStopping counter: 4 out of 10.0
EarlyStopping counter: 5 out of 10.0
EarlyStopping counter: 6 out of 10.0
EarlyStopping counter: 7 out of 10.0
EarlyStopping counter: 8 out of 10.0
EarlyStopping counter: 9 out of 10.0
Validation loss decreased (1.056545 --> 1.052720).  Saving model ...
Validation loss decreased (1.052720 --> 1.051903).  Saving model ...
EarlyStopping counter: 1 out of 10.0
EarlyStopping counter: 2 out of 10.0
Validation loss decreased (1.051903 --> 1.049215).  Saving model ...
EarlyStopping counter: 1 out of 10.0
EarlyStopping counter: 2 out of 10.0
EarlyStopping counter: 3 out of 10.0
EarlyStopping counter: 4 out of 10.0
EarlyStopping counter: 5 out of 10.0
EarlyStopping counter: 6 out of 10.0
EarlyStopping counter: 7 out of 10.0
Validation loss decreased (1.049215 --> 1.048539).  Saving model ...
EarlyStopping counter: 1 out of 10.0
EarlyStopping counter: 2 out of 10.0
EarlyStopping counter: 3 out of 10.0
EarlyStopping counter: 4 out of 10.0
Validation loss decreased (1.048539 --> 1.047189).  Saving model ...
EarlyStopping counter: 1 out of 10.0
EarlyStopping counter: 2 out of 10.0
EarlyStopping counter: 3 out of 10.0
EarlyStopping counter: 4 out of 10.0
Validation loss decreased (1.047189 --> 1.046477).  Saving model ...
Validation loss decreased (1.046477 --> 1.042871).  Saving model ...
Validation loss decreased (1.042871 --> 1.042222).  Saving model ...
EarlyStopping counter: 1 out of 10.0
EarlyStopping counter: 2 out of 10.0
EarlyStopping counter: 3 out of 10.0
EarlyStopping counter: 4 out of 10.0
EarlyStopping counter: 5 out of 10.0
EarlyStopping counter: 6 out of 10.0
Validation loss decreased (1.042222 --> 1.040247).  Saving model ...
EarlyStopping counter: 1 out of 10.0
EarlyStopping counter: 2 out of 10.0
EarlyStopping counter: 3 out of 10.0
EarlyStopping counter: 4 out of 10.0
EarlyStopping counter: 5 out of 10.0
EarlyStopping counter: 6 out of 10.0
EarlyStopping counter: 7 out of 10.0
EarlyStopping counter: 8 out of 10.0
EarlyStopping counter: 9 out of 10.0
EarlyStopping counter: 10 out of 10.0
/localscratch/yinan.29544078.0/env/lib/python3.7/site-packages/torch/nn/functional.py:1794: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.
  warnings.warn("nn.functional.tanh is deprecated. Use torch.tanh instead.")
/localscratch/yinan.29544078.0/env/lib/python3.7/site-packages/transformers/optimization.py:155: UserWarning: This overload of add_ is deprecated:
	add_(Number alpha, Tensor other)
Consider using one of the following signatures instead:
	add_(Tensor other, *, Number alpha) (Triggered internally at  ../torch/csrc/utils/python_arg_parser.cpp:1025.)
  exp_avg.mul_(beta1).add_(1.0 - beta1, grad)
wandb: Waiting for W&B process to finish, PID 1705... (success).
wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: \ 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: | 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: / 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: \ 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: | 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: / 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: \ 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: | 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: / 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb:                                                                                
wandb: Run history:
wandb:     e_F1 ▁▃▄▄▄▅▅▅▅▆▆▆▆▆▆▆▆▇▇▇▇▇▇▇████████████████
wandb:   e_loss █▇▇▆▆▆▅▅▅▅▄▄▄▄▃▃▃▃▂▂▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:     t_F1 ▁▂▂▃▃▄▄▄▅▅▅▅▅▅▆▆▆▆▆▆▇▇▇▇▇▇▇▇▇▇▇▇█▇▇▇▇███
wandb:   t_loss █▇█▇▇▆▆▆▅▅▅▅▅▄▄▄▄▄▄▄▃▃▃▃▃▃▃▂▂▂▂▂▂▂▂▂▂▂▁▁
wandb: 
wandb: Run summary:
wandb:     e_F1 55.30391
wandb:   e_loss 1.04944
wandb:     t_F1 76.45419
wandb:   t_loss 0.63781
wandb: 
wandb: Synced 4 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Synced crisp-waterfall-3: https://wandb.ai/yinanazhou/xl_512_bs_8_lr_1e06_es_10_lc_True_nr_True_sr_True_stem_False_lemma_True_repeat_1_fold_1/runs/2ritkfk6
wandb: Find logs at: ./wandb/run-20220326_001420-2ritkfk6/logs/debug.log
wandb: 

wandb: wandb version 0.12.11 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
2022-03-26 02:08:18.485148: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1
wandb: Tracking run with wandb version 0.12.5
wandb: Syncing run desert-firefly-3
wandb: ⭐️ View project at https://wandb.ai/yinanazhou/xl_512_bs_8_lr_1e06_es_10_lc_True_nr_True_sr_True_stem_False_lemma_True_repeat_1_fold_2
wandb: 🚀 View run at https://wandb.ai/yinanazhou/xl_512_bs_8_lr_1e06_es_10_lc_True_nr_True_sr_True_stem_False_lemma_True_repeat_1_fold_2/runs/3bvhn2eh
wandb: Run data is saved locally in /project/6002780/yinan/Thesis_MER_Lyrics/lyric-emotion/wandb/run-20220326_020816-3bvhn2eh
wandb: Run `wandb offline` to turn off syncing.

Validation loss decreased (inf --> 1.415457).  Saving model ...
Validation loss decreased (1.415457 --> 1.399544).  Saving model ...
Validation loss decreased (1.399544 --> 1.387885).  Saving model ...
Validation loss decreased (1.387885 --> 1.379488).  Saving model ...
Validation loss decreased (1.379488 --> 1.372240).  Saving model ...
Validation loss decreased (1.372240 --> 1.367018).  Saving model ...
Validation loss decreased (1.367018 --> 1.361894).  Saving model ...
Validation loss decreased (1.361894 --> 1.357347).  Saving model ...
Validation loss decreased (1.357347 --> 1.353985).  Saving model ...
Validation loss decreased (1.353985 --> 1.350849).  Saving model ...
Validation loss decreased (1.350849 --> 1.347567).  Saving model ...
Validation loss decreased (1.347567 --> 1.344629).  Saving model ...
Validation loss decreased (1.344629 --> 1.341075).  Saving model ...
Validation loss decreased (1.341075 --> 1.337809).  Saving model ...
Validation loss decreased (1.337809 --> 1.334399).  Saving model ...
Validation loss decreased (1.334399 --> 1.331611).  Saving model ...
Validation loss decreased (1.331611 --> 1.328199).  Saving model ...
Validation loss decreased (1.328199 --> 1.324396).  Saving model ...
Validation loss decreased (1.324396 --> 1.320804).  Saving model ...
Validation loss decreased (1.320804 --> 1.317009).  Saving model ...
Validation loss decreased (1.317009 --> 1.312728).  Saving model ...
Validation loss decreased (1.312728 --> 1.308869).  Saving model ...
Validation loss decreased (1.308869 --> 1.305100).  Saving model ...
Validation loss decreased (1.305100 --> 1.300208).  Saving model ...
Validation loss decreased (1.300208 --> 1.296030).  Saving model ...
Validation loss decreased (1.296030 --> 1.290526).  Saving model ...
Validation loss decreased (1.290526 --> 1.285540).  Saving model ...
Validation loss decreased (1.285540 --> 1.279420).  Saving model ...
Validation loss decreased (1.279420 --> 1.274724).  Saving model ...
Validation loss decreased (1.274724 --> 1.268465).  Saving model ...
Validation loss decreased (1.268465 --> 1.263273).  Saving model ...
Validation loss decreased (1.263273 --> 1.255931).  Saving model ...
Validation loss decreased (1.255931 --> 1.249158).  Saving model ...
Validation loss decreased (1.249158 --> 1.242498).  Saving model ...
Validation loss decreased (1.242498 --> 1.234709).  Saving model ...
Validation loss decreased (1.234709 --> 1.228218).  Saving model ...
Validation loss decreased (1.228218 --> 1.219393).  Saving model ...
Validation loss decreased (1.219393 --> 1.212815).  Saving model ...
Validation loss decreased (1.212815 --> 1.206469).  Saving model ...
Validation loss decreased (1.206469 --> 1.199522).  Saving model ...
Validation loss decreased (1.199522 --> 1.191795).  Saving model ...
Validation loss decreased (1.191795 --> 1.185775).  Saving model ...
Validation loss decreased (1.185775 --> 1.179633).  Saving model ...
Validation loss decreased (1.179633 --> 1.172359).  Saving model ...
Validation loss decreased (1.172359 --> 1.166560).  Saving model ...
Validation loss decreased (1.166560 --> 1.161484).  Saving model ...
Validation loss decreased (1.161484 --> 1.156871).  Saving model ...
Validation loss decreased (1.156871 --> 1.150350).  Saving model ...
Validation loss decreased (1.150350 --> 1.146268).  Saving model ...
Validation loss decreased (1.146268 --> 1.140402).  Saving model ...
Validation loss decreased (1.140402 --> 1.134895).  Saving model ...
Validation loss decreased (1.134895 --> 1.130475).  Saving model ...
Validation loss decreased (1.130475 --> 1.124782).  Saving model ...
Validation loss decreased (1.124782 --> 1.120181).  Saving model ...
Validation loss decreased (1.120181 --> 1.114783).  Saving model ...
Validation loss decreased (1.114783 --> 1.108699).  Saving model ...
Validation loss decreased (1.108699 --> 1.103961).  Saving model ...
Validation loss decreased (1.103961 --> 1.099885).  Saving model ...
Validation loss decreased (1.099885 --> 1.095995).  Saving model ...
Validation loss decreased (1.095995 --> 1.091939).  Saving model ...
Validation loss decreased (1.091939 --> 1.087168).  Saving model ...
Validation loss decreased (1.087168 --> 1.081121).  Saving model ...
Validation loss decreased (1.081121 --> 1.076808).  Saving model ...
Validation loss decreased (1.076808 --> 1.072605).  Saving model ...
Validation loss decreased (1.072605 --> 1.069857).  Saving model ...
Validation loss decreased (1.069857 --> 1.065590).  Saving model ...
Validation loss decreased (1.065590 --> 1.061096).  Saving model ...
Validation loss decreased (1.061096 --> 1.058605).  Saving model ...
Validation loss decreased (1.058605 --> 1.055472).  Saving model ...
Validation loss decreased (1.055472 --> 1.051382).  Saving model ...
Validation loss decreased (1.051382 --> 1.047366).  Saving model ...
Validation loss decreased (1.047366 --> 1.044003).  Saving model ...
Validation loss decreased (1.044003 --> 1.039726).  Saving model ...
Validation loss decreased (1.039726 --> 1.036965).  Saving model ...
Validation loss decreased (1.036965 --> 1.031812).  Saving model ...
Validation loss decreased (1.031812 --> 1.028862).  Saving model ...
Validation loss decreased (1.028862 --> 1.025932).  Saving model ...
Validation loss decreased (1.025932 --> 1.023433).  Saving model ...
Validation loss decreased (1.023433 --> 1.018935).  Saving model ...
Validation loss decreased (1.018935 --> 1.015734).  Saving model ...
Validation loss decreased (1.015734 --> 1.013911).  Saving model ...
Validation loss decreased (1.013911 --> 1.011173).  Saving model ...
Validation loss decreased (1.011173 --> 1.007377).  Saving model ...
Validation loss decreased (1.007377 --> 1.004476).  Saving model ...
Validation loss decreased (1.004476 --> 1.002397).  Saving model ...
Validation loss decreased (1.002397 --> 1.000205).  Saving model ...
Validation loss decreased (1.000205 --> 0.996853).  Saving model ...
Validation loss decreased (0.996853 --> 0.995296).  Saving model ...
Validation loss decreased (0.995296 --> 0.991799).  Saving model ...
Validation loss decreased (0.991799 --> 0.989414).  Saving model ...
Validation loss decreased (0.989414 --> 0.986244).  Saving model ...
Validation loss decreased (0.986244 --> 0.985094).  Saving model ...
Validation loss decreased (0.985094 --> 0.983447).  Saving model ...
Validation loss decreased (0.983447 --> 0.980384).  Saving model ...
Validation loss decreased (0.980384 --> 0.980253).  Saving model ...
Validation loss decreased (0.980253 --> 0.977555).  Saving model ...
Validation loss decreased (0.977555 --> 0.976122).  Saving model ...
Validation loss decreased (0.976122 --> 0.974546).  Saving model ...
Validation loss decreased (0.974546 --> 0.971667).  Saving model ...
Validation loss decreased (0.971667 --> 0.969011).  Saving model ...
Validation loss decreased (0.969011 --> 0.968396).  Saving model ...
Validation loss decreased (0.968396 --> 0.967936).  Saving model ...
Validation loss decreased (0.967936 --> 0.967752).  Saving model ...
Validation loss decreased (0.967752 --> 0.964547).  Saving model ...
Validation loss decreased (0.964547 --> 0.962408).  Saving model ...
EarlyStopping counter: 1 out of 10.0
Validation loss decreased (0.962408 --> 0.961851).  Saving model ...
Validation loss decreased (0.961851 --> 0.958614).  Saving model ...
Validation loss decreased (0.958614 --> 0.958558).  Saving model ...
Validation loss decreased (0.958558 --> 0.956008).  Saving model ...
Validation loss decreased (0.956008 --> 0.955709).  Saving model ...
Validation loss decreased (0.955709 --> 0.955570).  Saving model ...
Validation loss decreased (0.955570 --> 0.953095).  Saving model ...
Validation loss decreased (0.953095 --> 0.952028).  Saving model ...
Validation loss decreased (0.952028 --> 0.951590).  Saving model ...
Validation loss decreased (0.951590 --> 0.949306).  Saving model ...
EarlyStopping counter: 1 out of 10.0
EarlyStopping counter: 2 out of 10.0
Validation loss decreased (0.949306 --> 0.948233).  Saving model ...
EarlyStopping counter: 1 out of 10.0
Validation loss decreased (0.948233 --> 0.946820).  Saving model ...
Validation loss decreased (0.946820 --> 0.946267).  Saving model ...
Validation loss decreased (0.946267 --> 0.945477).  Saving model ...
Validation loss decreased (0.945477 --> 0.944731).  Saving model ...
Validation loss decreased (0.944731 --> 0.944593).  Saving model ...
EarlyStopping counter: 1 out of 10.0
Validation loss decreased (0.944593 --> 0.943330).  Saving model ...
Validation loss decreased (0.943330 --> 0.943170).  Saving model ...
Validation loss decreased (0.943170 --> 0.942400).  Saving model ...
Validation loss decreased (0.942400 --> 0.941265).  Saving model ...
Validation loss decreased (0.941265 --> 0.940862).  Saving model ...
Validation loss decreased (0.940862 --> 0.940010).  Saving model ...
Validation loss decreased (0.940010 --> 0.938752).  Saving model ...
EarlyStopping counter: 1 out of 10.0
EarlyStopping counter: 2 out of 10.0
EarlyStopping counter: 3 out of 10.0
Validation loss decreased (0.938752 --> 0.938108).  Saving model ...
EarlyStopping counter: 1 out of 10.0
EarlyStopping counter: 2 out of 10.0
EarlyStopping counter: 3 out of 10.0
EarlyStopping counter: 4 out of 10.0
EarlyStopping counter: 5 out of 10.0
EarlyStopping counter: 6 out of 10.0
EarlyStopping counter: 7 out of 10.0
EarlyStopping counter: 8 out of 10.0
EarlyStopping counter: 9 out of 10.0
EarlyStopping counter: 10 out of 10.0
/localscratch/yinan.29544078.0/env/lib/python3.7/site-packages/torch/nn/functional.py:1794: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.
  warnings.warn("nn.functional.tanh is deprecated. Use torch.tanh instead.")
wandb: Waiting for W&B process to finish, PID 7813... (success).
wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: \ 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: | 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: / 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: \ 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: | 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: / 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: \ 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: | 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: / 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb:                                                                                
wandb: Run history:
wandb:     e_F1 ▁▂▄▅▅▅▆▆▆▆▆▆▆▆▇▇▇▇▇▇▇█▇▇████████████████
wandb:   e_loss ██▇▇▇▇▆▆▆▆▅▅▄▄▄▄▃▃▃▃▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:     t_F1 ▁▂▂▂▃▃▄▄▄▄▅▅▅▅▆▅▆▆▆▆▆▇▆▆▇▇▇▇▇▇▇▇████▇███
wandb:   t_loss ███▇▇▇▇▇▇▇▆▆▆▅▅▅▅▄▅▄▄▄▄▃▃▃▃▂▃▃▂▂▂▂▂▂▁▁▁▁
wandb: 
wandb: Run summary:
wandb:     e_F1 58.86679
wandb:   e_loss 0.94082
wandb:     t_F1 75.2302
wandb:   t_loss 0.76418
wandb: 
wandb: Synced 4 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Synced desert-firefly-3: https://wandb.ai/yinanazhou/xl_512_bs_8_lr_1e06_es_10_lc_True_nr_True_sr_True_stem_False_lemma_True_repeat_1_fold_2/runs/3bvhn2eh
wandb: Find logs at: ./wandb/run-20220326_020816-3bvhn2eh/logs/debug.log
wandb: 

wandb: wandb version 0.12.11 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
2022-03-26 03:42:46.594786: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1
wandb: Tracking run with wandb version 0.12.5
wandb: Syncing run winter-blaze-3
wandb: ⭐️ View project at https://wandb.ai/yinanazhou/xl_512_bs_8_lr_1e06_es_10_lc_True_nr_True_sr_True_stem_False_lemma_True_repeat_2_fold_1
wandb: 🚀 View run at https://wandb.ai/yinanazhou/xl_512_bs_8_lr_1e06_es_10_lc_True_nr_True_sr_True_stem_False_lemma_True_repeat_2_fold_1/runs/2cmi9dii
wandb: Run data is saved locally in /project/6002780/yinan/Thesis_MER_Lyrics/lyric-emotion/wandb/run-20220326_034244-2cmi9dii
wandb: Run `wandb offline` to turn off syncing.

Validation loss decreased (inf --> 1.428130).  Saving model ...
Validation loss decreased (1.428130 --> 1.412421).  Saving model ...
Validation loss decreased (1.412421 --> 1.399631).  Saving model ...
Validation loss decreased (1.399631 --> 1.389426).  Saving model ...
Validation loss decreased (1.389426 --> 1.381474).  Saving model ...
Validation loss decreased (1.381474 --> 1.375090).  Saving model ...
Validation loss decreased (1.375090 --> 1.369488).  Saving model ...
Validation loss decreased (1.369488 --> 1.364023).  Saving model ...
Validation loss decreased (1.364023 --> 1.359050).  Saving model ...
Validation loss decreased (1.359050 --> 1.353897).  Saving model ...
Validation loss decreased (1.353897 --> 1.349504).  Saving model ...
Validation loss decreased (1.349504 --> 1.344173).  Saving model ...
Validation loss decreased (1.344173 --> 1.338998).  Saving model ...
Validation loss decreased (1.338998 --> 1.334009).  Saving model ...
Validation loss decreased (1.334009 --> 1.328871).  Saving model ...
Validation loss decreased (1.328871 --> 1.323724).  Saving model ...
Validation loss decreased (1.323724 --> 1.318260).  Saving model ...
Validation loss decreased (1.318260 --> 1.312590).  Saving model ...
Validation loss decreased (1.312590 --> 1.306474).  Saving model ...
Validation loss decreased (1.306474 --> 1.299035).  Saving model ...
Validation loss decreased (1.299035 --> 1.292107).  Saving model ...
Validation loss decreased (1.292107 --> 1.284808).  Saving model ...
Validation loss decreased (1.284808 --> 1.277968).  Saving model ...
Validation loss decreased (1.277968 --> 1.270489).  Saving model ...
Validation loss decreased (1.270489 --> 1.264744).  Saving model ...
Validation loss decreased (1.264744 --> 1.258497).  Saving model ...
Validation loss decreased (1.258497 --> 1.251270).  Saving model ...
Validation loss decreased (1.251270 --> 1.243701).  Saving model ...
Validation loss decreased (1.243701 --> 1.233057).  Saving model ...
Validation loss decreased (1.233057 --> 1.225425).  Saving model ...
Validation loss decreased (1.225425 --> 1.216821).  Saving model ...
Validation loss decreased (1.216821 --> 1.210236).  Saving model ...
Validation loss decreased (1.210236 --> 1.203600).  Saving model ...
Validation loss decreased (1.203600 --> 1.196091).  Saving model ...
Validation loss decreased (1.196091 --> 1.189753).  Saving model ...
Validation loss decreased (1.189753 --> 1.184406).  Saving model ...
Validation loss decreased (1.184406 --> 1.177882).  Saving model ...
Validation loss decreased (1.177882 --> 1.171889).  Saving model ...
Validation loss decreased (1.171889 --> 1.166743).  Saving model ...
Validation loss decreased (1.166743 --> 1.162587).  Saving model ...
Validation loss decreased (1.162587 --> 1.157238).  Saving model ...
Validation loss decreased (1.157238 --> 1.152705).  Saving model ...
Validation loss decreased (1.152705 --> 1.147543).  Saving model ...
Validation loss decreased (1.147543 --> 1.143203).  Saving model ...
Validation loss decreased (1.143203 --> 1.140311).  Saving model ...
Validation loss decreased (1.140311 --> 1.134251).  Saving model ...
Validation loss decreased (1.134251 --> 1.128942).  Saving model ...
Validation loss decreased (1.128942 --> 1.128834).  Saving model ...
Validation loss decreased (1.128834 --> 1.120350).  Saving model ...
Validation loss decreased (1.120350 --> 1.117247).  Saving model ...
Validation loss decreased (1.117247 --> 1.112764).  Saving model ...
Validation loss decreased (1.112764 --> 1.107586).  Saving model ...
Validation loss decreased (1.107586 --> 1.103584).  Saving model ...
Validation loss decreased (1.103584 --> 1.100091).  Saving model ...
Validation loss decreased (1.100091 --> 1.095519).  Saving model ...
Validation loss decreased (1.095519 --> 1.092369).  Saving model ...
Validation loss decreased (1.092369 --> 1.088273).  Saving model ...
Validation loss decreased (1.088273 --> 1.086081).  Saving model ...
Validation loss decreased (1.086081 --> 1.081888).  Saving model ...
Validation loss decreased (1.081888 --> 1.079619).  Saving model ...
Validation loss decreased (1.079619 --> 1.076623).  Saving model ...
Validation loss decreased (1.076623 --> 1.074144).  Saving model ...
Validation loss decreased (1.074144 --> 1.070093).  Saving model ...
Validation loss decreased (1.070093 --> 1.067367).  Saving model ...
Validation loss decreased (1.067367 --> 1.064318).  Saving model ...
Validation loss decreased (1.064318 --> 1.061270).  Saving model ...
Validation loss decreased (1.061270 --> 1.059203).  Saving model ...
Validation loss decreased (1.059203 --> 1.056006).  Saving model ...
Validation loss decreased (1.056006 --> 1.053465).  Saving model ...
Validation loss decreased (1.053465 --> 1.048241).  Saving model ...
Validation loss decreased (1.048241 --> 1.047503).  Saving model ...
EarlyStopping counter: 1 out of 10.0
Validation loss decreased (1.047503 --> 1.044064).  Saving model ...
Validation loss decreased (1.044064 --> 1.038185).  Saving model ...
Validation loss decreased (1.038185 --> 1.036564).  Saving model ...
Validation loss decreased (1.036564 --> 1.035796).  Saving model ...
Validation loss decreased (1.035796 --> 1.033489).  Saving model ...
Validation loss decreased (1.033489 --> 1.030540).  Saving model ...
Validation loss decreased (1.030540 --> 1.027950).  Saving model ...
Validation loss decreased (1.027950 --> 1.026686).  Saving model ...
EarlyStopping counter: 1 out of 10.0
Validation loss decreased (1.026686 --> 1.022257).  Saving model ...
Validation loss decreased (1.022257 --> 1.018800).  Saving model ...
Validation loss decreased (1.018800 --> 1.017366).  Saving model ...
Validation loss decreased (1.017366 --> 1.016956).  Saving model ...
Validation loss decreased (1.016956 --> 1.014091).  Saving model ...
EarlyStopping counter: 1 out of 10.0
EarlyStopping counter: 2 out of 10.0
Validation loss decreased (1.014091 --> 1.008982).  Saving model ...
EarlyStopping counter: 1 out of 10.0
Validation loss decreased (1.008982 --> 1.007956).  Saving model ...
Validation loss decreased (1.007956 --> 1.007568).  Saving model ...
Validation loss decreased (1.007568 --> 1.007189).  Saving model ...
Validation loss decreased (1.007189 --> 1.005805).  Saving model ...
Validation loss decreased (1.005805 --> 1.003471).  Saving model ...
Validation loss decreased (1.003471 --> 1.003389).  Saving model ...
Validation loss decreased (1.003389 --> 1.002230).  Saving model ...
Validation loss decreased (1.002230 --> 1.000788).  Saving model ...
Validation loss decreased (1.000788 --> 0.999847).  Saving model ...
Validation loss decreased (0.999847 --> 0.997332).  Saving model ...
Validation loss decreased (0.997332 --> 0.994861).  Saving model ...
Validation loss decreased (0.994861 --> 0.994491).  Saving model ...
EarlyStopping counter: 1 out of 10.0
Validation loss decreased (0.994491 --> 0.993256).  Saving model ...
Validation loss decreased (0.993256 --> 0.991946).  Saving model ...
EarlyStopping counter: 1 out of 10.0
EarlyStopping counter: 2 out of 10.0
Validation loss decreased (0.991946 --> 0.990344).  Saving model ...
Validation loss decreased (0.990344 --> 0.988701).  Saving model ...
Validation loss decreased (0.988701 --> 0.986287).  Saving model ...
EarlyStopping counter: 1 out of 10.0
EarlyStopping counter: 2 out of 10.0
EarlyStopping counter: 3 out of 10.0
Validation loss decreased (0.986287 --> 0.985757).  Saving model ...
Validation loss decreased (0.985757 --> 0.985683).  Saving model ...
EarlyStopping counter: 1 out of 10.0
Validation loss decreased (0.985683 --> 0.984749).  Saving model ...
Validation loss decreased (0.984749 --> 0.983521).  Saving model ...
Validation loss decreased (0.983521 --> 0.983119).  Saving model ...
Validation loss decreased (0.983119 --> 0.982028).  Saving model ...
Validation loss decreased (0.982028 --> 0.981660).  Saving model ...
EarlyStopping counter: 1 out of 10.0
EarlyStopping counter: 2 out of 10.0
EarlyStopping counter: 3 out of 10.0
EarlyStopping counter: 4 out of 10.0
EarlyStopping counter: 5 out of 10.0
EarlyStopping counter: 6 out of 10.0
EarlyStopping counter: 7 out of 10.0
EarlyStopping counter: 8 out of 10.0
EarlyStopping counter: 9 out of 10.0
Validation loss decreased (0.981660 --> 0.981463).  Saving model ...
EarlyStopping counter: 1 out of 10.0
EarlyStopping counter: 2 out of 10.0
EarlyStopping counter: 3 out of 10.0
Validation loss decreased (0.981463 --> 0.981153).  Saving model ...
EarlyStopping counter: 1 out of 10.0
EarlyStopping counter: 2 out of 10.0
EarlyStopping counter: 3 out of 10.0
EarlyStopping counter: 4 out of 10.0
EarlyStopping counter: 5 out of 10.0
EarlyStopping counter: 6 out of 10.0
EarlyStopping counter: 7 out of 10.0
EarlyStopping counter: 8 out of 10.0
EarlyStopping counter: 9 out of 10.0
EarlyStopping counter: 10 out of 10.0
/localscratch/yinan.29544078.0/env/lib/python3.7/site-packages/torch/nn/functional.py:1794: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.
  warnings.warn("nn.functional.tanh is deprecated. Use torch.tanh instead.")
wandb: Waiting for W&B process to finish, PID 12975... (success).
wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: \ 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: | 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: / 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: \ 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: | 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: / 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: \ 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: | 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: / 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb:                                                                                
wandb: Run history:
wandb:     e_F1 ▁▂▃▄▄▅▅▅▆▆▆▆▆▆▇▇▇▇▇▇▇▇▇▇████████████████
wandb:   e_loss ██▇▇▇▆▆▅▅▄▄▄▄▃▃▃▃▂▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:     t_F1 ▁▁▂▃▃▄▃▄▄▅▅▅▅▆▆▆▆▆▆▆▇▆▆▇▇▇▇▇▇▇▇█▇▇█▇███▇
wandb:   t_loss ██▇▇▇▇▇▆▆▆▅▅▅▅▅▄▄▄▄▄▃▃▃▃▃▃▃▂▂▂▂▂▂▂▂▂▁▁▁▁
wandb: 
wandb: Run summary:
wandb:     e_F1 59.02022
wandb:   e_loss 0.98406
wandb:     t_F1 74.61573
wandb:   t_loss 0.68655
wandb: 
wandb: Synced 4 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Synced winter-blaze-3: https://wandb.ai/yinanazhou/xl_512_bs_8_lr_1e06_es_10_lc_True_nr_True_sr_True_stem_False_lemma_True_repeat_2_fold_1/runs/2cmi9dii
wandb: Find logs at: ./wandb/run-20220326_034244-2cmi9dii/logs/debug.log
wandb: 

wandb: wandb version 0.12.11 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
2022-03-26 05:15:42.405299: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1
wandb: Tracking run with wandb version 0.12.5
wandb: Syncing run denim-oath-1
wandb: ⭐️ View project at https://wandb.ai/yinanazhou/xl_512_bs_8_lr_1e06_es_10_lc_True_nr_True_sr_True_stem_False_lemma_True_repeat_2_fold_2
wandb: 🚀 View run at https://wandb.ai/yinanazhou/xl_512_bs_8_lr_1e06_es_10_lc_True_nr_True_sr_True_stem_False_lemma_True_repeat_2_fold_2/runs/24oi4s2i
wandb: Run data is saved locally in /project/6002780/yinan/Thesis_MER_Lyrics/lyric-emotion/wandb/run-20220326_051540-24oi4s2i
wandb: Run `wandb offline` to turn off syncing.

Validation loss decreased (inf --> 1.435235).  Saving model ...
Validation loss decreased (1.435235 --> 1.414938).  Saving model ...
Validation loss decreased (1.414938 --> 1.401142).  Saving model ...
Validation loss decreased (1.401142 --> 1.390150).  Saving model ...
Validation loss decreased (1.390150 --> 1.382554).  Saving model ...
Validation loss decreased (1.382554 --> 1.376871).  Saving model ...
Validation loss decreased (1.376871 --> 1.371993).  Saving model ...
Validation loss decreased (1.371993 --> 1.367664).  Saving model ...
Validation loss decreased (1.367664 --> 1.363341).  Saving model ...
Validation loss decreased (1.363341 --> 1.359739).  Saving model ...
Validation loss decreased (1.359739 --> 1.356291).  Saving model ...
Validation loss decreased (1.356291 --> 1.352562).  Saving model ...
Validation loss decreased (1.352562 --> 1.348879).  Saving model ...
Validation loss decreased (1.348879 --> 1.345272).  Saving model ...
Validation loss decreased (1.345272 --> 1.341889).  Saving model ...
Validation loss decreased (1.341889 --> 1.338503).  Saving model ...
Validation loss decreased (1.338503 --> 1.334708).  Saving model ...
Validation loss decreased (1.334708 --> 1.330838).  Saving model ...
Validation loss decreased (1.330838 --> 1.326755).  Saving model ...
Validation loss decreased (1.326755 --> 1.322791).  Saving model ...
Validation loss decreased (1.322791 --> 1.318526).  Saving model ...
Validation loss decreased (1.318526 --> 1.313691).  Saving model ...
Validation loss decreased (1.313691 --> 1.308827).  Saving model ...
Validation loss decreased (1.308827 --> 1.304424).  Saving model ...
Validation loss decreased (1.304424 --> 1.299109).  Saving model ...
Validation loss decreased (1.299109 --> 1.294163).  Saving model ...
Validation loss decreased (1.294163 --> 1.289770).  Saving model ...
Validation loss decreased (1.289770 --> 1.284046).  Saving model ...
Validation loss decreased (1.284046 --> 1.278493).  Saving model ...
Validation loss decreased (1.278493 --> 1.274315).  Saving model ...
Validation loss decreased (1.274315 --> 1.268821).  Saving model ...
Validation loss decreased (1.268821 --> 1.263602).  Saving model ...
Validation loss decreased (1.263602 --> 1.257276).  Saving model ...
Validation loss decreased (1.257276 --> 1.249557).  Saving model ...
Validation loss decreased (1.249557 --> 1.244053).  Saving model ...
Validation loss decreased (1.244053 --> 1.237864).  Saving model ...
Validation loss decreased (1.237864 --> 1.232929).  Saving model ...
Validation loss decreased (1.232929 --> 1.225222).  Saving model ...
Validation loss decreased (1.225222 --> 1.218305).  Saving model ...
Validation loss decreased (1.218305 --> 1.213442).  Saving model ...
Validation loss decreased (1.213442 --> 1.207073).  Saving model ...
Validation loss decreased (1.207073 --> 1.200650).  Saving model ...
Validation loss decreased (1.200650 --> 1.195968).  Saving model ...
Validation loss decreased (1.195968 --> 1.192947).  Saving model ...
Validation loss decreased (1.192947 --> 1.186929).  Saving model ...
Validation loss decreased (1.186929 --> 1.181347).  Saving model ...
Validation loss decreased (1.181347 --> 1.177613).  Saving model ...
Validation loss decreased (1.177613 --> 1.171779).  Saving model ...
Validation loss decreased (1.171779 --> 1.169447).  Saving model ...
Validation loss decreased (1.169447 --> 1.166171).  Saving model ...
Validation loss decreased (1.166171 --> 1.163481).  Saving model ...
Validation loss decreased (1.163481 --> 1.156517).  Saving model ...
Validation loss decreased (1.156517 --> 1.153484).  Saving model ...
Validation loss decreased (1.153484 --> 1.150427).  Saving model ...
Validation loss decreased (1.150427 --> 1.146741).  Saving model ...
Validation loss decreased (1.146741 --> 1.139758).  Saving model ...
Validation loss decreased (1.139758 --> 1.137422).  Saving model ...
Validation loss decreased (1.137422 --> 1.135058).  Saving model ...
Validation loss decreased (1.135058 --> 1.128927).  Saving model ...
Validation loss decreased (1.128927 --> 1.125517).  Saving model ...
Validation loss decreased (1.125517 --> 1.121659).  Saving model ...
Validation loss decreased (1.121659 --> 1.116490).  Saving model ...
Validation loss decreased (1.116490 --> 1.112507).  Saving model ...
Validation loss decreased (1.112507 --> 1.108974).  Saving model ...
Validation loss decreased (1.108974 --> 1.105332).  Saving model ...
Validation loss decreased (1.105332 --> 1.102526).  Saving model ...
Validation loss decreased (1.102526 --> 1.099719).  Saving model ...
Validation loss decreased (1.099719 --> 1.093866).  Saving model ...
EarlyStopping counter: 1 out of 10.0
Validation loss decreased (1.093866 --> 1.091557).  Saving model ...
Validation loss decreased (1.091557 --> 1.085279).  Saving model ...
Validation loss decreased (1.085279 --> 1.082688).  Saving model ...
Validation loss decreased (1.082688 --> 1.079941).  Saving model ...
Validation loss decreased (1.079941 --> 1.075573).  Saving model ...
Validation loss decreased (1.075573 --> 1.070033).  Saving model ...
Validation loss decreased (1.070033 --> 1.066789).  Saving model ...
Validation loss decreased (1.066789 --> 1.066381).  Saving model ...
Validation loss decreased (1.066381 --> 1.063809).  Saving model ...
Validation loss decreased (1.063809 --> 1.061264).  Saving model ...
Validation loss decreased (1.061264 --> 1.057775).  Saving model ...
Validation loss decreased (1.057775 --> 1.055866).  Saving model ...
Validation loss decreased (1.055866 --> 1.051801).  Saving model ...
Validation loss decreased (1.051801 --> 1.047412).  Saving model ...
Validation loss decreased (1.047412 --> 1.045226).  Saving model ...
Validation loss decreased (1.045226 --> 1.039902).  Saving model ...
Validation loss decreased (1.039902 --> 1.038516).  Saving model ...
Validation loss decreased (1.038516 --> 1.036716).  Saving model ...
Validation loss decreased (1.036716 --> 1.035180).  Saving model ...
Validation loss decreased (1.035180 --> 1.031394).  Saving model ...
Validation loss decreased (1.031394 --> 1.029130).  Saving model ...
Validation loss decreased (1.029130 --> 1.026422).  Saving model ...
Validation loss decreased (1.026422 --> 1.023583).  Saving model ...
Validation loss decreased (1.023583 --> 1.019635).  Saving model ...
Validation loss decreased (1.019635 --> 1.017636).  Saving model ...
Validation loss decreased (1.017636 --> 1.015097).  Saving model ...
Validation loss decreased (1.015097 --> 1.014777).  Saving model ...
Validation loss decreased (1.014777 --> 1.010712).  Saving model ...
Validation loss decreased (1.010712 --> 1.008336).  Saving model ...
Validation loss decreased (1.008336 --> 1.006296).  Saving model ...
Validation loss decreased (1.006296 --> 1.002806).  Saving model ...
Validation loss decreased (1.002806 --> 1.000270).  Saving model ...
Validation loss decreased (1.000270 --> 0.995743).  Saving model ...
Validation loss decreased (0.995743 --> 0.993264).  Saving model ...
Validation loss decreased (0.993264 --> 0.991869).  Saving model ...
EarlyStopping counter: 1 out of 10.0
EarlyStopping counter: 2 out of 10.0
EarlyStopping counter: 3 out of 10.0
Validation loss decreased (0.991869 --> 0.990627).  Saving model ...
Validation loss decreased (0.990627 --> 0.990356).  Saving model ...
Validation loss decreased (0.990356 --> 0.985935).  Saving model ...
Validation loss decreased (0.985935 --> 0.985073).  Saving model ...
Validation loss decreased (0.985073 --> 0.981478).  Saving model ...
Validation loss decreased (0.981478 --> 0.980555).  Saving model ...
Validation loss decreased (0.980555 --> 0.979022).  Saving model ...
EarlyStopping counter: 1 out of 10.0
Validation loss decreased (0.979022 --> 0.975920).  Saving model ...
Validation loss decreased (0.975920 --> 0.974391).  Saving model ...
Validation loss decreased (0.974391 --> 0.973887).  Saving model ...
Validation loss decreased (0.973887 --> 0.972045).  Saving model ...
EarlyStopping counter: 1 out of 10.0
Validation loss decreased (0.972045 --> 0.969263).  Saving model ...
Validation loss decreased (0.969263 --> 0.969218).  Saving model ...
Validation loss decreased (0.969218 --> 0.966358).  Saving model ...
Validation loss decreased (0.966358 --> 0.964469).  Saving model ...
Validation loss decreased (0.964469 --> 0.963718).  Saving model ...
Validation loss decreased (0.963718 --> 0.962048).  Saving model ...
EarlyStopping counter: 1 out of 10.0
Validation loss decreased (0.962048 --> 0.960160).  Saving model ...
Validation loss decreased (0.960160 --> 0.957738).  Saving model ...
EarlyStopping counter: 1 out of 10.0
Validation loss decreased (0.957738 --> 0.957105).  Saving model ...
Validation loss decreased (0.957105 --> 0.953403).  Saving model ...
Validation loss decreased (0.953403 --> 0.953266).  Saving model ...
Validation loss decreased (0.953266 --> 0.953065).  Saving model ...
Validation loss decreased (0.953065 --> 0.952946).  Saving model ...
Validation loss decreased (0.952946 --> 0.951873).  Saving model ...
Validation loss decreased (0.951873 --> 0.950579).  Saving model ...
EarlyStopping counter: 1 out of 10.0
Validation loss decreased (0.950579 --> 0.950479).  Saving model ...
Validation loss decreased (0.950479 --> 0.946798).  Saving model ...
Validation loss decreased (0.946798 --> 0.946374).  Saving model ...
EarlyStopping counter: 1 out of 10.0
Validation loss decreased (0.946374 --> 0.945436).  Saving model ...
EarlyStopping counter: 1 out of 10.0
Validation loss decreased (0.945436 --> 0.942861).  Saving model ...
EarlyStopping counter: 1 out of 10.0
Validation loss decreased (0.942861 --> 0.941450).  Saving model ...
Validation loss decreased (0.941450 --> 0.940488).  Saving model ...
EarlyStopping counter: 1 out of 10.0
EarlyStopping counter: 2 out of 10.0
Validation loss decreased (0.940488 --> 0.940037).  Saving model ...
EarlyStopping counter: 1 out of 10.0
EarlyStopping counter: 2 out of 10.0
EarlyStopping counter: 3 out of 10.0
Validation loss decreased (0.940037 --> 0.938750).  Saving model ...
EarlyStopping counter: 1 out of 10.0
EarlyStopping counter: 2 out of 10.0
EarlyStopping counter: 3 out of 10.0
Validation loss decreased (0.938750 --> 0.937634).  Saving model ...
EarlyStopping counter: 1 out of 10.0
EarlyStopping counter: 2 out of 10.0
EarlyStopping counter: 3 out of 10.0
Validation loss decreased (0.937634 --> 0.935681).  Saving model ...
EarlyStopping counter: 1 out of 10.0
Validation loss decreased (0.935681 --> 0.934335).  Saving model ...
EarlyStopping counter: 1 out of 10.0
Validation loss decreased (0.934335 --> 0.933461).  Saving model ...
EarlyStopping counter: 1 out of 10.0
EarlyStopping counter: 2 out of 10.0
EarlyStopping counter: 3 out of 10.0
EarlyStopping counter: 4 out of 10.0
EarlyStopping counter: 5 out of 10.0
EarlyStopping counter: 6 out of 10.0
EarlyStopping counter: 7 out of 10.0
EarlyStopping counter: 8 out of 10.0
EarlyStopping counter: 9 out of 10.0
EarlyStopping counter: 10 out of 10.0
/localscratch/yinan.29544078.0/env/lib/python3.7/site-packages/torch/nn/functional.py:1794: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.
  warnings.warn("nn.functional.tanh is deprecated. Use torch.tanh instead.")
wandb: Waiting for W&B process to finish, PID 17942... (success).
wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: \ 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: | 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: / 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: \ 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: | 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: / 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: \ 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: | 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: / 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: \ 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: | 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb:                                                                                
wandb: Run history:
wandb:     e_F1 ▁▂▃▄▅▆▆▆▆▆▆▆▆▇▇▇▇▇▇▇▇▇▇▇▇███████████████
wandb:   e_loss █▇▇▇▇▆▆▆▅▅▅▄▄▄▄▃▃▃▃▃▂▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁
wandb:     t_F1 ▁▂▃▃▃▄▄▄▄▅▅▅▅▆▅▆▆▆▆▆▆▆▆▆▇▇▇▇▇▇▇▇██▇█▇███
wandb:   t_loss ██▇▇▇▇▇▆▆▆▆▅▅▅▅▅▄▄▄▄▄▃▃▃▃▃▃▃▃▃▂▂▂▂▂▂▂▁▁▁
wandb: 
wandb: Run summary:
wandb:     e_F1 59.22783
wandb:   e_loss 0.93655
wandb:     t_F1 75.33976
wandb:   t_loss 0.71261
wandb: 
wandb: Synced 4 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Synced denim-oath-1: https://wandb.ai/yinanazhou/xl_512_bs_8_lr_1e06_es_10_lc_True_nr_True_sr_True_stem_False_lemma_True_repeat_2_fold_2/runs/24oi4s2i
wandb: Find logs at: ./wandb/run-20220326_051540-24oi4s2i/logs/debug.log
wandb: 

wandb: wandb version 0.12.11 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
2022-03-26 07:12:10.419780: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1
wandb: Tracking run with wandb version 0.12.5
wandb: Syncing run vibrant-cloud-1
wandb: ⭐️ View project at https://wandb.ai/yinanazhou/xl_512_bs_8_lr_1e06_es_10_lc_True_nr_True_sr_True_stem_False_lemma_True_repeat_3_fold_1
wandb: 🚀 View run at https://wandb.ai/yinanazhou/xl_512_bs_8_lr_1e06_es_10_lc_True_nr_True_sr_True_stem_False_lemma_True_repeat_3_fold_1/runs/2js8xxsm
wandb: Run data is saved locally in /project/6002780/yinan/Thesis_MER_Lyrics/lyric-emotion/wandb/run-20220326_071208-2js8xxsm
wandb: Run `wandb offline` to turn off syncing.

Validation loss decreased (inf --> 1.398867).  Saving model ...
Validation loss decreased (1.398867 --> 1.393571).  Saving model ...
Validation loss decreased (1.393571 --> 1.388843).  Saving model ...
Validation loss decreased (1.388843 --> 1.384546).  Saving model ...
Validation loss decreased (1.384546 --> 1.380762).  Saving model ...
Validation loss decreased (1.380762 --> 1.377221).  Saving model ...
Validation loss decreased (1.377221 --> 1.373783).  Saving model ...
Validation loss decreased (1.373783 --> 1.370425).  Saving model ...
Validation loss decreased (1.370425 --> 1.367066).  Saving model ...
Validation loss decreased (1.367066 --> 1.363619).  Saving model ...
Validation loss decreased (1.363619 --> 1.360263).  Saving model ...
Validation loss decreased (1.360263 --> 1.356860).  Saving model ...
Validation loss decreased (1.356860 --> 1.353597).  Saving model ...
Validation loss decreased (1.353597 --> 1.349985).  Saving model ...
Validation loss decreased (1.349985 --> 1.346234).  Saving model ...
Validation loss decreased (1.346234 --> 1.342009).  Saving model ...
Validation loss decreased (1.342009 --> 1.337525).  Saving model ...
Validation loss decreased (1.337525 --> 1.333286).  Saving model ...
Validation loss decreased (1.333286 --> 1.328552).  Saving model ...
Validation loss decreased (1.328552 --> 1.323027).  Saving model ...
Validation loss decreased (1.323027 --> 1.317464).  Saving model ...
Validation loss decreased (1.317464 --> 1.311902).  Saving model ...
Validation loss decreased (1.311902 --> 1.305382).  Saving model ...
Validation loss decreased (1.305382 --> 1.298532).  Saving model ...
Validation loss decreased (1.298532 --> 1.291216).  Saving model ...
Validation loss decreased (1.291216 --> 1.283493).  Saving model ...
Validation loss decreased (1.283493 --> 1.276566).  Saving model ...
Validation loss decreased (1.276566 --> 1.269394).  Saving model ...
Validation loss decreased (1.269394 --> 1.262052).  Saving model ...
Validation loss decreased (1.262052 --> 1.255065).  Saving model ...
Validation loss decreased (1.255065 --> 1.247633).  Saving model ...
Validation loss decreased (1.247633 --> 1.240991).  Saving model ...
Validation loss decreased (1.240991 --> 1.235353).  Saving model ...
Validation loss decreased (1.235353 --> 1.231148).  Saving model ...
Validation loss decreased (1.231148 --> 1.223872).  Saving model ...
Validation loss decreased (1.223872 --> 1.218774).  Saving model ...
Validation loss decreased (1.218774 --> 1.212294).  Saving model ...
Validation loss decreased (1.212294 --> 1.207237).  Saving model ...
Validation loss decreased (1.207237 --> 1.201428).  Saving model ...
Validation loss decreased (1.201428 --> 1.197159).  Saving model ...
Validation loss decreased (1.197159 --> 1.191539).  Saving model ...
Validation loss decreased (1.191539 --> 1.188821).  Saving model ...
Validation loss decreased (1.188821 --> 1.185146).  Saving model ...
Validation loss decreased (1.185146 --> 1.181138).  Saving model ...
Validation loss decreased (1.181138 --> 1.176365).  Saving model ...
Validation loss decreased (1.176365 --> 1.171533).  Saving model ...
Validation loss decreased (1.171533 --> 1.167621).  Saving model ...
Validation loss decreased (1.167621 --> 1.162906).  Saving model ...
Validation loss decreased (1.162906 --> 1.156860).  Saving model ...
Validation loss decreased (1.156860 --> 1.155132).  Saving model ...
Validation loss decreased (1.155132 --> 1.150022).  Saving model ...
Validation loss decreased (1.150022 --> 1.145838).  Saving model ...
Validation loss decreased (1.145838 --> 1.140835).  Saving model ...
Validation loss decreased (1.140835 --> 1.135494).  Saving model ...
Validation loss decreased (1.135494 --> 1.129032).  Saving model ...
Validation loss decreased (1.129032 --> 1.128419).  Saving model ...
Validation loss decreased (1.128419 --> 1.123613).  Saving model ...
Validation loss decreased (1.123613 --> 1.120897).  Saving model ...
Validation loss decreased (1.120897 --> 1.118485).  Saving model ...
Validation loss decreased (1.118485 --> 1.113134).  Saving model ...
Validation loss decreased (1.113134 --> 1.110910).  Saving model ...
Validation loss decreased (1.110910 --> 1.102768).  Saving model ...
Validation loss decreased (1.102768 --> 1.100702).  Saving model ...
Validation loss decreased (1.100702 --> 1.097428).  Saving model ...
Validation loss decreased (1.097428 --> 1.096996).  Saving model ...
Validation loss decreased (1.096996 --> 1.090537).  Saving model ...
Validation loss decreased (1.090537 --> 1.089376).  Saving model ...
Validation loss decreased (1.089376 --> 1.081113).  Saving model ...
Validation loss decreased (1.081113 --> 1.075754).  Saving model ...
Validation loss decreased (1.075754 --> 1.075698).  Saving model ...
Validation loss decreased (1.075698 --> 1.072273).  Saving model ...
Validation loss decreased (1.072273 --> 1.069679).  Saving model ...
Validation loss decreased (1.069679 --> 1.066668).  Saving model ...
Validation loss decreased (1.066668 --> 1.064854).  Saving model ...
Validation loss decreased (1.064854 --> 1.060961).  Saving model ...
Validation loss decreased (1.060961 --> 1.055997).  Saving model ...
Validation loss decreased (1.055997 --> 1.054791).  Saving model ...
EarlyStopping counter: 1 out of 10.0
Validation loss decreased (1.054791 --> 1.053393).  Saving model ...
Validation loss decreased (1.053393 --> 1.050740).  Saving model ...
Validation loss decreased (1.050740 --> 1.048428).  Saving model ...
Validation loss decreased (1.048428 --> 1.045688).  Saving model ...
Validation loss decreased (1.045688 --> 1.041145).  Saving model ...
Validation loss decreased (1.041145 --> 1.039815).  Saving model ...
Validation loss decreased (1.039815 --> 1.038417).  Saving model ...
EarlyStopping counter: 1 out of 10.0
Validation loss decreased (1.038417 --> 1.037483).  Saving model ...
Validation loss decreased (1.037483 --> 1.033923).  Saving model ...
Validation loss decreased (1.033923 --> 1.028124).  Saving model ...
EarlyStopping counter: 1 out of 10.0
Validation loss decreased (1.028124 --> 1.026791).  Saving model ...
Validation loss decreased (1.026791 --> 1.026293).  Saving model ...
Validation loss decreased (1.026293 --> 1.025905).  Saving model ...
Validation loss decreased (1.025905 --> 1.023185).  Saving model ...
Validation loss decreased (1.023185 --> 1.017086).  Saving model ...
EarlyStopping counter: 1 out of 10.0
EarlyStopping counter: 2 out of 10.0
EarlyStopping counter: 3 out of 10.0
Validation loss decreased (1.017086 --> 1.016616).  Saving model ...
Validation loss decreased (1.016616 --> 1.013630).  Saving model ...
Validation loss decreased (1.013630 --> 1.013041).  Saving model ...
Validation loss decreased (1.013041 --> 1.009296).  Saving model ...
EarlyStopping counter: 1 out of 10.0
EarlyStopping counter: 2 out of 10.0
Validation loss decreased (1.009296 --> 1.006682).  Saving model ...
EarlyStopping counter: 1 out of 10.0
EarlyStopping counter: 2 out of 10.0
Validation loss decreased (1.006682 --> 1.003348).  Saving model ...
EarlyStopping counter: 1 out of 10.0
EarlyStopping counter: 2 out of 10.0
EarlyStopping counter: 3 out of 10.0
Validation loss decreased (1.003348 --> 1.001467).  Saving model ...
EarlyStopping counter: 1 out of 10.0
Validation loss decreased (1.001467 --> 0.999998).  Saving model ...
EarlyStopping counter: 1 out of 10.0
EarlyStopping counter: 2 out of 10.0
Validation loss decreased (0.999998 --> 0.999769).  Saving model ...
EarlyStopping counter: 1 out of 10.0
Validation loss decreased (0.999769 --> 0.996725).  Saving model ...
EarlyStopping counter: 1 out of 10.0
Validation loss decreased (0.996725 --> 0.995964).  Saving model ...
EarlyStopping counter: 1 out of 10.0
EarlyStopping counter: 2 out of 10.0
Validation loss decreased (0.995964 --> 0.993177).  Saving model ...
EarlyStopping counter: 1 out of 10.0
EarlyStopping counter: 2 out of 10.0
EarlyStopping counter: 3 out of 10.0
Validation loss decreased (0.993177 --> 0.987901).  Saving model ...
EarlyStopping counter: 1 out of 10.0
EarlyStopping counter: 2 out of 10.0
EarlyStopping counter: 3 out of 10.0
EarlyStopping counter: 4 out of 10.0
EarlyStopping counter: 5 out of 10.0
EarlyStopping counter: 6 out of 10.0
EarlyStopping counter: 7 out of 10.0
EarlyStopping counter: 8 out of 10.0
EarlyStopping counter: 9 out of 10.0
EarlyStopping counter: 10 out of 10.0
/localscratch/yinan.29544078.0/env/lib/python3.7/site-packages/torch/nn/functional.py:1794: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.
  warnings.warn("nn.functional.tanh is deprecated. Use torch.tanh instead.")
wandb: Waiting for W&B process to finish, PID 24244... (success).
wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: \ 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: | 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: / 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: \ 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: | 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: / 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: \ 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: | 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: / 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb:                                                                                
wandb: Run history:
wandb:     e_F1 ▁▁▂▃▃▄▅▅▆▅▆▆▆▆▆▆▆▇▇▇▇▇▇▇▇▇▇▇▇███████████
wandb:   e_loss ███▇▇▇▇▆▆▅▅▅▄▄▄▃▃▃▃▃▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:     t_F1 ▁▁▂▃▂▃▃▃▃▄▅▄▅▅▅▆▅▆▆▆▆▆▇▇▇▆▇▇▇▇▇▇▇▇██▇▇▇█
wandb:   t_loss ████▇▇▇▇▇▆▆▆▅▅▅▅▅▄▄▄▄▃▃▃▃▃▃▃▃▃▂▂▂▂▂▂▂▂▂▁
wandb: 
wandb: Run summary:
wandb:     e_F1 57.84209
wandb:   e_loss 0.99411
wandb:     t_F1 74.26964
wandb:   t_loss 0.7146
wandb: 
wandb: Synced 4 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Synced vibrant-cloud-1: https://wandb.ai/yinanazhou/xl_512_bs_8_lr_1e06_es_10_lc_True_nr_True_sr_True_stem_False_lemma_True_repeat_3_fold_1/runs/2js8xxsm
wandb: Find logs at: ./wandb/run-20220326_071208-2js8xxsm/logs/debug.log
wandb: 

wandb: wandb version 0.12.11 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
2022-03-26 08:42:53.556623: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1
wandb: Tracking run with wandb version 0.12.5
wandb: Syncing run effortless-vortex-1
wandb: ⭐️ View project at https://wandb.ai/yinanazhou/xl_512_bs_8_lr_1e06_es_10_lc_True_nr_True_sr_True_stem_False_lemma_True_repeat_3_fold_2
wandb: 🚀 View run at https://wandb.ai/yinanazhou/xl_512_bs_8_lr_1e06_es_10_lc_True_nr_True_sr_True_stem_False_lemma_True_repeat_3_fold_2/runs/2glh471x
wandb: Run data is saved locally in /project/6002780/yinan/Thesis_MER_Lyrics/lyric-emotion/wandb/run-20220326_084251-2glh471x
wandb: Run `wandb offline` to turn off syncing.

Validation loss decreased (inf --> 1.413298).  Saving model ...
Validation loss decreased (1.413298 --> 1.398129).  Saving model ...
Validation loss decreased (1.398129 --> 1.385835).  Saving model ...
Validation loss decreased (1.385835 --> 1.376945).  Saving model ...
Validation loss decreased (1.376945 --> 1.369437).  Saving model ...
Validation loss decreased (1.369437 --> 1.363552).  Saving model ...
Validation loss decreased (1.363552 --> 1.358594).  Saving model ...
Validation loss decreased (1.358594 --> 1.353999).  Saving model ...
Validation loss decreased (1.353999 --> 1.349115).  Saving model ...
Validation loss decreased (1.349115 --> 1.344429).  Saving model ...
Validation loss decreased (1.344429 --> 1.340334).  Saving model ...
Validation loss decreased (1.340334 --> 1.336174).  Saving model ...
Validation loss decreased (1.336174 --> 1.331277).  Saving model ...
Validation loss decreased (1.331277 --> 1.327381).  Saving model ...
Validation loss decreased (1.327381 --> 1.322905).  Saving model ...
Validation loss decreased (1.322905 --> 1.318031).  Saving model ...
Validation loss decreased (1.318031 --> 1.313358).  Saving model ...
Validation loss decreased (1.313358 --> 1.309047).  Saving model ...
Validation loss decreased (1.309047 --> 1.304477).  Saving model ...
Validation loss decreased (1.304477 --> 1.299763).  Saving model ...
Validation loss decreased (1.299763 --> 1.294799).  Saving model ...
Validation loss decreased (1.294799 --> 1.290109).  Saving model ...
Validation loss decreased (1.290109 --> 1.284437).  Saving model ...
Validation loss decreased (1.284437 --> 1.278488).  Saving model ...
Validation loss decreased (1.278488 --> 1.272766).  Saving model ...
Validation loss decreased (1.272766 --> 1.266594).  Saving model ...
Validation loss decreased (1.266594 --> 1.260153).  Saving model ...
Validation loss decreased (1.260153 --> 1.253416).  Saving model ...
Validation loss decreased (1.253416 --> 1.247341).  Saving model ...
Validation loss decreased (1.247341 --> 1.240208).  Saving model ...
Validation loss decreased (1.240208 --> 1.232795).  Saving model ...
Validation loss decreased (1.232795 --> 1.224992).  Saving model ...
Validation loss decreased (1.224992 --> 1.219388).  Saving model ...
Validation loss decreased (1.219388 --> 1.213078).  Saving model ...
Validation loss decreased (1.213078 --> 1.207133).  Saving model ...
Validation loss decreased (1.207133 --> 1.200656).  Saving model ...
Validation loss decreased (1.200656 --> 1.193641).  Saving model ...
Validation loss decreased (1.193641 --> 1.186660).  Saving model ...
Validation loss decreased (1.186660 --> 1.180542).  Saving model ...
Validation loss decreased (1.180542 --> 1.174340).  Saving model ...
Validation loss decreased (1.174340 --> 1.168006).  Saving model ...
Validation loss decreased (1.168006 --> 1.162009).  Saving model ...
Validation loss decreased (1.162009 --> 1.156521).  Saving model ...
Validation loss decreased (1.156521 --> 1.151551).  Saving model ...
Validation loss decreased (1.151551 --> 1.144982).  Saving model ...
Validation loss decreased (1.144982 --> 1.139760).  Saving model ...
Validation loss decreased (1.139760 --> 1.134884).  Saving model ...
Validation loss decreased (1.134884 --> 1.129718).  Saving model ...
Validation loss decreased (1.129718 --> 1.125026).  Saving model ...
Validation loss decreased (1.125026 --> 1.120223).  Saving model ...
Validation loss decreased (1.120223 --> 1.115110).  Saving model ...
Validation loss decreased (1.115110 --> 1.110454).  Saving model ...
Validation loss decreased (1.110454 --> 1.106703).  Saving model ...
Validation loss decreased (1.106703 --> 1.101664).  Saving model ...
Validation loss decreased (1.101664 --> 1.100083).  Saving model ...
Validation loss decreased (1.100083 --> 1.095127).  Saving model ...
Validation loss decreased (1.095127 --> 1.089850).  Saving model ...
Validation loss decreased (1.089850 --> 1.085065).  Saving model ...
Validation loss decreased (1.085065 --> 1.081931).  Saving model ...
Validation loss decreased (1.081931 --> 1.079323).  Saving model ...
Validation loss decreased (1.079323 --> 1.075618).  Saving model ...
Validation loss decreased (1.075618 --> 1.072260).  Saving model ...
Validation loss decreased (1.072260 --> 1.068893).  Saving model ...
Validation loss decreased (1.068893 --> 1.065049).  Saving model ...
Validation loss decreased (1.065049 --> 1.061887).  Saving model ...
Validation loss decreased (1.061887 --> 1.058182).  Saving model ...
Validation loss decreased (1.058182 --> 1.054591).  Saving model ...
Validation loss decreased (1.054591 --> 1.051100).  Saving model ...
Validation loss decreased (1.051100 --> 1.047163).  Saving model ...
Validation loss decreased (1.047163 --> 1.045122).  Saving model ...
Validation loss decreased (1.045122 --> 1.041540).  Saving model ...
Validation loss decreased (1.041540 --> 1.037492).  Saving model ...
Validation loss decreased (1.037492 --> 1.034460).  Saving model ...
Validation loss decreased (1.034460 --> 1.030877).  Saving model ...
Validation loss decreased (1.030877 --> 1.028851).  Saving model ...
Validation loss decreased (1.028851 --> 1.026162).  Saving model ...
Validation loss decreased (1.026162 --> 1.023097).  Saving model ...
Validation loss decreased (1.023097 --> 1.019953).  Saving model ...
Validation loss decreased (1.019953 --> 1.017116).  Saving model ...
Validation loss decreased (1.017116 --> 1.014643).  Saving model ...
Validation loss decreased (1.014643 --> 1.011313).  Saving model ...
Validation loss decreased (1.011313 --> 1.010028).  Saving model ...
Validation loss decreased (1.010028 --> 1.007925).  Saving model ...
Validation loss decreased (1.007925 --> 1.006180).  Saving model ...
Validation loss decreased (1.006180 --> 1.004839).  Saving model ...
Validation loss decreased (1.004839 --> 1.001752).  Saving model ...
Validation loss decreased (1.001752 --> 0.999517).  Saving model ...
Validation loss decreased (0.999517 --> 0.997550).  Saving model ...
Validation loss decreased (0.997550 --> 0.994385).  Saving model ...
Validation loss decreased (0.994385 --> 0.992777).  Saving model ...
Validation loss decreased (0.992777 --> 0.990192).  Saving model ...
Validation loss decreased (0.990192 --> 0.988275).  Saving model ...
Validation loss decreased (0.988275 --> 0.987812).  Saving model ...
Validation loss decreased (0.987812 --> 0.986458).  Saving model ...
Validation loss decreased (0.986458 --> 0.983882).  Saving model ...
Validation loss decreased (0.983882 --> 0.980616).  Saving model ...
Validation loss decreased (0.980616 --> 0.979853).  Saving model ...
Validation loss decreased (0.979853 --> 0.977885).  Saving model ...
Validation loss decreased (0.977885 --> 0.975716).  Saving model ...
Validation loss decreased (0.975716 --> 0.972932).  Saving model ...
Validation loss decreased (0.972932 --> 0.971605).  Saving model ...
Validation loss decreased (0.971605 --> 0.969913).  Saving model ...
Validation loss decreased (0.969913 --> 0.967648).  Saving model ...
Validation loss decreased (0.967648 --> 0.966297).  Saving model ...
Validation loss decreased (0.966297 --> 0.965574).  Saving model ...
Validation loss decreased (0.965574 --> 0.963563).  Saving model ...
Validation loss decreased (0.963563 --> 0.962015).  Saving model ...
Validation loss decreased (0.962015 --> 0.961844).  Saving model ...
Validation loss decreased (0.961844 --> 0.960119).  Saving model ...
Validation loss decreased (0.960119 --> 0.957940).  Saving model ...
Validation loss decreased (0.957940 --> 0.956736).  Saving model ...
Validation loss decreased (0.956736 --> 0.955965).  Saving model ...
Validation loss decreased (0.955965 --> 0.954969).  Saving model ...
Validation loss decreased (0.954969 --> 0.952946).  Saving model ...
Validation loss decreased (0.952946 --> 0.950530).  Saving model ...
Validation loss decreased (0.950530 --> 0.948331).  Saving model ...
EarlyStopping counter: 1 out of 10.0
Validation loss decreased (0.948331 --> 0.948291).  Saving model ...
Validation loss decreased (0.948291 --> 0.948024).  Saving model ...
EarlyStopping counter: 1 out of 10.0
Validation loss decreased (0.948024 --> 0.946992).  Saving model ...
Validation loss decreased (0.946992 --> 0.945489).  Saving model ...
Validation loss decreased (0.945489 --> 0.943085).  Saving model ...
Validation loss decreased (0.943085 --> 0.942248).  Saving model ...
Validation loss decreased (0.942248 --> 0.941192).  Saving model ...
Validation loss decreased (0.941192 --> 0.940171).  Saving model ...
Validation loss decreased (0.940171 --> 0.939874).  Saving model ...
Validation loss decreased (0.939874 --> 0.939310).  Saving model ...
Validation loss decreased (0.939310 --> 0.938865).  Saving model ...
Validation loss decreased (0.938865 --> 0.938335).  Saving model ...
Validation loss decreased (0.938335 --> 0.937011).  Saving model ...
Validation loss decreased (0.937011 --> 0.935493).  Saving model ...
Validation loss decreased (0.935493 --> 0.935158).  Saving model ...
Validation loss decreased (0.935158 --> 0.934822).  Saving model ...
Validation loss decreased (0.934822 --> 0.933600).  Saving model ...
Validation loss decreased (0.933600 --> 0.933337).  Saving model ...
EarlyStopping counter: 1 out of 10.0
Validation loss decreased (0.933337 --> 0.933334).  Saving model ...
Validation loss decreased (0.933334 --> 0.932975).  Saving model ...
Validation loss decreased (0.932975 --> 0.932766).  Saving model ...
Validation loss decreased (0.932766 --> 0.932626).  Saving model ...
Validation loss decreased (0.932626 --> 0.932264).  Saving model ...
Validation loss decreased (0.932264 --> 0.931605).  Saving model ...
Validation loss decreased (0.931605 --> 0.930897).  Saving model ...
Validation loss decreased (0.930897 --> 0.930619).  Saving model ...
EarlyStopping counter: 1 out of 10.0
Validation loss decreased (0.930619 --> 0.930589).  Saving model ...
Validation loss decreased (0.930589 --> 0.930144).  Saving model ...
Validation loss decreased (0.930144 --> 0.929572).  Saving model ...
EarlyStopping counter: 1 out of 10.0
Validation loss decreased (0.929572 --> 0.929137).  Saving model ...
EarlyStopping counter: 1 out of 10.0
EarlyStopping counter: 2 out of 10.0
EarlyStopping counter: 3 out of 10.0
Validation loss decreased (0.929137 --> 0.929032).  Saving model ...
EarlyStopping counter: 1 out of 10.0
Validation loss decreased (0.929032 --> 0.928527).  Saving model ...
Validation loss decreased (0.928527 --> 0.927865).  Saving model ...
Validation loss decreased (0.927865 --> 0.927813).  Saving model ...
EarlyStopping counter: 1 out of 10.0
EarlyStopping counter: 2 out of 10.0
EarlyStopping counter: 3 out of 10.0
EarlyStopping counter: 4 out of 10.0
EarlyStopping counter: 5 out of 10.0
Validation loss decreased (0.927813 --> 0.927590).  Saving model ...
Validation loss decreased (0.927590 --> 0.927561).  Saving model ...
EarlyStopping counter: 1 out of 10.0
EarlyStopping counter: 2 out of 10.0
EarlyStopping counter: 3 out of 10.0
EarlyStopping counter: 4 out of 10.0
EarlyStopping counter: 5 out of 10.0
EarlyStopping counter: 6 out of 10.0
EarlyStopping counter: 7 out of 10.0
EarlyStopping counter: 8 out of 10.0
EarlyStopping counter: 9 out of 10.0
EarlyStopping counter: 10 out of 10.0
/localscratch/yinan.29544078.0/env/lib/python3.7/site-packages/torch/nn/functional.py:1794: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.
  warnings.warn("nn.functional.tanh is deprecated. Use torch.tanh instead.")
wandb: Waiting for W&B process to finish, PID 29112... (success).
wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: \ 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: | 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: / 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: \ 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: | 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: / 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: \ 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: | 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: / 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb:                                                                                
wandb: Run history:
wandb:     e_F1 ▁▃▃▄▅▅▅▆▆▆▆▆▆▇▇▇▇▇▇▇▇▇▇█▇▇██████████████
wandb:   e_loss █▇▇▇▇▆▆▅▅▄▄▄▄▃▃▃▃▂▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:     t_F1 ▁▁▃▂▂▃▃▄▅▅▅▅▅▅▅▆▆▆▆▆▇▆▇▆▇▇▇▇▇▇▇▇▇▇▇▇██▇█
wandb:   t_loss ██▇▇▇▇▇▆▆▆▅▅▅▅▅▄▄▄▄▄▃▃▃▃▃▃▂▂▃▂▂▂▂▂▂▂▁▁▁▁
wandb: 
wandb: Run summary:
wandb:     e_F1 62.66997
wandb:   e_loss 0.92843
wandb:     t_F1 75.86304
wandb:   t_loss 0.69025
wandb: 
wandb: Synced 4 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Synced effortless-vortex-1: https://wandb.ai/yinanazhou/xl_512_bs_8_lr_1e06_es_10_lc_True_nr_True_sr_True_stem_False_lemma_True_repeat_3_fold_2/runs/2glh471x
wandb: Find logs at: ./wandb/run-20220326_084251-2glh471x/logs/debug.log
wandb: 

wandb: wandb version 0.12.11 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
2022-03-26 10:38:59.091333: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1
wandb: Tracking run with wandb version 0.12.5
wandb: Syncing run crisp-bee-1
wandb: ⭐️ View project at https://wandb.ai/yinanazhou/xl_512_bs_8_lr_1e06_es_10_lc_True_nr_True_sr_True_stem_False_lemma_True_repeat_4_fold_1
wandb: 🚀 View run at https://wandb.ai/yinanazhou/xl_512_bs_8_lr_1e06_es_10_lc_True_nr_True_sr_True_stem_False_lemma_True_repeat_4_fold_1/runs/1e7azryh
wandb: Run data is saved locally in /project/6002780/yinan/Thesis_MER_Lyrics/lyric-emotion/wandb/run-20220326_103856-1e7azryh
wandb: Run `wandb offline` to turn off syncing.

Validation loss decreased (inf --> 1.418548).  Saving model ...
Validation loss decreased (1.418548 --> 1.402844).  Saving model ...
Validation loss decreased (1.402844 --> 1.391186).  Saving model ...
Validation loss decreased (1.391186 --> 1.382331).  Saving model ...
Validation loss decreased (1.382331 --> 1.375272).  Saving model ...
Validation loss decreased (1.375272 --> 1.369821).  Saving model ...
Validation loss decreased (1.369821 --> 1.364546).  Saving model ...
Validation loss decreased (1.364546 --> 1.359990).  Saving model ...
Validation loss decreased (1.359990 --> 1.355145).  Saving model ...
Validation loss decreased (1.355145 --> 1.350403).  Saving model ...
Validation loss decreased (1.350403 --> 1.346052).  Saving model ...
Validation loss decreased (1.346052 --> 1.341534).  Saving model ...
Validation loss decreased (1.341534 --> 1.337274).  Saving model ...
Validation loss decreased (1.337274 --> 1.332501).  Saving model ...
Validation loss decreased (1.332501 --> 1.327397).  Saving model ...
Validation loss decreased (1.327397 --> 1.322428).  Saving model ...
Validation loss decreased (1.322428 --> 1.316992).  Saving model ...
Validation loss decreased (1.316992 --> 1.311842).  Saving model ...
Validation loss decreased (1.311842 --> 1.306756).  Saving model ...
Validation loss decreased (1.306756 --> 1.301494).  Saving model ...
Validation loss decreased (1.301494 --> 1.295497).  Saving model ...
Validation loss decreased (1.295497 --> 1.289662).  Saving model ...
Validation loss decreased (1.289662 --> 1.283881).  Saving model ...
Validation loss decreased (1.283881 --> 1.278015).  Saving model ...
Validation loss decreased (1.278015 --> 1.271841).  Saving model ...
Validation loss decreased (1.271841 --> 1.265910).  Saving model ...
Validation loss decreased (1.265910 --> 1.260592).  Saving model ...
Validation loss decreased (1.260592 --> 1.254208).  Saving model ...
Validation loss decreased (1.254208 --> 1.248627).  Saving model ...
Validation loss decreased (1.248627 --> 1.242590).  Saving model ...
Validation loss decreased (1.242590 --> 1.237055).  Saving model ...
Validation loss decreased (1.237055 --> 1.231569).  Saving model ...
Validation loss decreased (1.231569 --> 1.226440).  Saving model ...
Validation loss decreased (1.226440 --> 1.221136).  Saving model ...
Validation loss decreased (1.221136 --> 1.215542).  Saving model ...
Validation loss decreased (1.215542 --> 1.210249).  Saving model ...
Validation loss decreased (1.210249 --> 1.205262).  Saving model ...
Validation loss decreased (1.205262 --> 1.200789).  Saving model ...
Validation loss decreased (1.200789 --> 1.196407).  Saving model ...
Validation loss decreased (1.196407 --> 1.191384).  Saving model ...
Validation loss decreased (1.191384 --> 1.186150).  Saving model ...
Validation loss decreased (1.186150 --> 1.180429).  Saving model ...
Validation loss decreased (1.180429 --> 1.176198).  Saving model ...
Validation loss decreased (1.176198 --> 1.171542).  Saving model ...
Validation loss decreased (1.171542 --> 1.167416).  Saving model ...
Validation loss decreased (1.167416 --> 1.163232).  Saving model ...
Validation loss decreased (1.163232 --> 1.159183).  Saving model ...
Validation loss decreased (1.159183 --> 1.156493).  Saving model ...
Validation loss decreased (1.156493 --> 1.152730).  Saving model ...
Validation loss decreased (1.152730 --> 1.148446).  Saving model ...
Validation loss decreased (1.148446 --> 1.143809).  Saving model ...
Validation loss decreased (1.143809 --> 1.139155).  Saving model ...
Validation loss decreased (1.139155 --> 1.135160).  Saving model ...
Validation loss decreased (1.135160 --> 1.131052).  Saving model ...
Validation loss decreased (1.131052 --> 1.127841).  Saving model ...
Validation loss decreased (1.127841 --> 1.123334).  Saving model ...
Validation loss decreased (1.123334 --> 1.119686).  Saving model ...
Validation loss decreased (1.119686 --> 1.116116).  Saving model ...
Validation loss decreased (1.116116 --> 1.112499).  Saving model ...
Validation loss decreased (1.112499 --> 1.109161).  Saving model ...
Validation loss decreased (1.109161 --> 1.106276).  Saving model ...
Validation loss decreased (1.106276 --> 1.102379).  Saving model ...
Validation loss decreased (1.102379 --> 1.099277).  Saving model ...
Validation loss decreased (1.099277 --> 1.095983).  Saving model ...
Validation loss decreased (1.095983 --> 1.093149).  Saving model ...
Validation loss decreased (1.093149 --> 1.089613).  Saving model ...
Validation loss decreased (1.089613 --> 1.086294).  Saving model ...
Validation loss decreased (1.086294 --> 1.083043).  Saving model ...
Validation loss decreased (1.083043 --> 1.079254).  Saving model ...
Validation loss decreased (1.079254 --> 1.077311).  Saving model ...
Validation loss decreased (1.077311 --> 1.074075).  Saving model ...
Validation loss decreased (1.074075 --> 1.072124).  Saving model ...
Validation loss decreased (1.072124 --> 1.069261).  Saving model ...
Validation loss decreased (1.069261 --> 1.065830).  Saving model ...
Validation loss decreased (1.065830 --> 1.063344).  Saving model ...
Validation loss decreased (1.063344 --> 1.060702).  Saving model ...
Validation loss decreased (1.060702 --> 1.058641).  Saving model ...
Validation loss decreased (1.058641 --> 1.055831).  Saving model ...
Validation loss decreased (1.055831 --> 1.052985).  Saving model ...
Validation loss decreased (1.052985 --> 1.050208).  Saving model ...
Validation loss decreased (1.050208 --> 1.047420).  Saving model ...
Validation loss decreased (1.047420 --> 1.046052).  Saving model ...
Validation loss decreased (1.046052 --> 1.043249).  Saving model ...
Validation loss decreased (1.043249 --> 1.040334).  Saving model ...
Validation loss decreased (1.040334 --> 1.038593).  Saving model ...
Validation loss decreased (1.038593 --> 1.036707).  Saving model ...
Validation loss decreased (1.036707 --> 1.034691).  Saving model ...
Validation loss decreased (1.034691 --> 1.033115).  Saving model ...
Validation loss decreased (1.033115 --> 1.030736).  Saving model ...
Validation loss decreased (1.030736 --> 1.028384).  Saving model ...
Validation loss decreased (1.028384 --> 1.027683).  Saving model ...
Validation loss decreased (1.027683 --> 1.026738).  Saving model ...
Validation loss decreased (1.026738 --> 1.024329).  Saving model ...
Validation loss decreased (1.024329 --> 1.021528).  Saving model ...
Validation loss decreased (1.021528 --> 1.020366).  Saving model ...
Validation loss decreased (1.020366 --> 1.019411).  Saving model ...
Validation loss decreased (1.019411 --> 1.017690).  Saving model ...
Validation loss decreased (1.017690 --> 1.015975).  Saving model ...
Validation loss decreased (1.015975 --> 1.015293).  Saving model ...
Validation loss decreased (1.015293 --> 1.014007).  Saving model ...
Validation loss decreased (1.014007 --> 1.012476).  Saving model ...
Validation loss decreased (1.012476 --> 1.011796).  Saving model ...
Validation loss decreased (1.011796 --> 1.010350).  Saving model ...
Validation loss decreased (1.010350 --> 1.009084).  Saving model ...
Validation loss decreased (1.009084 --> 1.008662).  Saving model ...
Validation loss decreased (1.008662 --> 1.007555).  Saving model ...
Validation loss decreased (1.007555 --> 1.006562).  Saving model ...
Validation loss decreased (1.006562 --> 1.006491).  Saving model ...
Validation loss decreased (1.006491 --> 1.005257).  Saving model ...
Validation loss decreased (1.005257 --> 1.003622).  Saving model ...
Validation loss decreased (1.003622 --> 1.003181).  Saving model ...
Validation loss decreased (1.003181 --> 1.002160).  Saving model ...
Validation loss decreased (1.002160 --> 1.000641).  Saving model ...
Validation loss decreased (1.000641 --> 0.999909).  Saving model ...
Validation loss decreased (0.999909 --> 0.999694).  Saving model ...
Validation loss decreased (0.999694 --> 0.998178).  Saving model ...
Validation loss decreased (0.998178 --> 0.998006).  Saving model ...
EarlyStopping counter: 1 out of 10.0
Validation loss decreased (0.998006 --> 0.996932).  Saving model ...
Validation loss decreased (0.996932 --> 0.995905).  Saving model ...
Validation loss decreased (0.995905 --> 0.995431).  Saving model ...
Validation loss decreased (0.995431 --> 0.994280).  Saving model ...
Validation loss decreased (0.994280 --> 0.993792).  Saving model ...
Validation loss decreased (0.993792 --> 0.992461).  Saving model ...
Validation loss decreased (0.992461 --> 0.992130).  Saving model ...
Validation loss decreased (0.992130 --> 0.991092).  Saving model ...
Validation loss decreased (0.991092 --> 0.991024).  Saving model ...
Validation loss decreased (0.991024 --> 0.991013).  Saving model ...
EarlyStopping counter: 1 out of 10.0
EarlyStopping counter: 2 out of 10.0
Validation loss decreased (0.991013 --> 0.990948).  Saving model ...
EarlyStopping counter: 1 out of 10.0
Validation loss decreased (0.990948 --> 0.989628).  Saving model ...
EarlyStopping counter: 1 out of 10.0
Validation loss decreased (0.989628 --> 0.988873).  Saving model ...
Validation loss decreased (0.988873 --> 0.987208).  Saving model ...
Validation loss decreased (0.987208 --> 0.986515).  Saving model ...
EarlyStopping counter: 1 out of 10.0
EarlyStopping counter: 2 out of 10.0
EarlyStopping counter: 3 out of 10.0
EarlyStopping counter: 4 out of 10.0
Validation loss decreased (0.986515 --> 0.986203).  Saving model ...
EarlyStopping counter: 1 out of 10.0
EarlyStopping counter: 2 out of 10.0
EarlyStopping counter: 3 out of 10.0
EarlyStopping counter: 4 out of 10.0
EarlyStopping counter: 5 out of 10.0
EarlyStopping counter: 6 out of 10.0
EarlyStopping counter: 7 out of 10.0
EarlyStopping counter: 8 out of 10.0
EarlyStopping counter: 9 out of 10.0
EarlyStopping counter: 10 out of 10.0
/localscratch/yinan.29544078.0/env/lib/python3.7/site-packages/torch/nn/functional.py:1794: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.
  warnings.warn("nn.functional.tanh is deprecated. Use torch.tanh instead.")
wandb: Waiting for W&B process to finish, PID 35303... (success).
wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: \ 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: | 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: / 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: \ 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: | 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: / 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: \ 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: | 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: / 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb:                                                                                
wandb: Run history:
wandb:     e_F1 ▁▁▃▄▄▅▅▅▆▆▆▆▆▆▆▇▇▇▇▇▇▇▇█████████████████
wandb:   e_loss ██▇▇▇▆▆▅▅▅▄▄▄▄▃▃▃▃▃▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:     t_F1 ▁▁▂▃▃▃▄▄▄▅▅▅▅▆▆▆▅▆▆▆▆▆▆▇▇▇▇▇▇▇▇█▇██▇████
wandb:   t_loss ██▇▇▇▇▇▆▆▆▆▅▅▅▅▅▄▄▄▄▃▃▃▃▃▃▃▂▂▂▂▂▂▂▂▂▁▁▁▁
wandb: 
wandb: Run summary:
wandb:     e_F1 57.71227
wandb:   e_loss 0.98822
wandb:     t_F1 71.96685
wandb:   t_loss 0.73698
wandb: 
wandb: Synced 4 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Synced crisp-bee-1: https://wandb.ai/yinanazhou/xl_512_bs_8_lr_1e06_es_10_lc_True_nr_True_sr_True_stem_False_lemma_True_repeat_4_fold_1/runs/1e7azryh
wandb: Find logs at: ./wandb/run-20220326_103856-1e7azryh/logs/debug.log
wandb: 

wandb: wandb version 0.12.11 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
2022-03-26 12:19:19.594119: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1
wandb: Tracking run with wandb version 0.12.5
wandb: Syncing run lunar-elevator-1
wandb: ⭐️ View project at https://wandb.ai/yinanazhou/xl_512_bs_8_lr_1e06_es_10_lc_True_nr_True_sr_True_stem_False_lemma_True_repeat_4_fold_2
wandb: 🚀 View run at https://wandb.ai/yinanazhou/xl_512_bs_8_lr_1e06_es_10_lc_True_nr_True_sr_True_stem_False_lemma_True_repeat_4_fold_2/runs/11qe56dh
wandb: Run data is saved locally in /project/6002780/yinan/Thesis_MER_Lyrics/lyric-emotion/wandb/run-20220326_121917-11qe56dh
wandb: Run `wandb offline` to turn off syncing.

Validation loss decreased (inf --> 1.461783).  Saving model ...
Validation loss decreased (1.461783 --> 1.428231).  Saving model ...
Validation loss decreased (1.428231 --> 1.405985).  Saving model ...
Validation loss decreased (1.405985 --> 1.391167).  Saving model ...
Validation loss decreased (1.391167 --> 1.381549).  Saving model ...
Validation loss decreased (1.381549 --> 1.374595).  Saving model ...
Validation loss decreased (1.374595 --> 1.369121).  Saving model ...
Validation loss decreased (1.369121 --> 1.364739).  Saving model ...
Validation loss decreased (1.364739 --> 1.360582).  Saving model ...
Validation loss decreased (1.360582 --> 1.356346).  Saving model ...
Validation loss decreased (1.356346 --> 1.352049).  Saving model ...
Validation loss decreased (1.352049 --> 1.348290).  Saving model ...
Validation loss decreased (1.348290 --> 1.343880).  Saving model ...
Validation loss decreased (1.343880 --> 1.339483).  Saving model ...
Validation loss decreased (1.339483 --> 1.334844).  Saving model ...
Validation loss decreased (1.334844 --> 1.330152).  Saving model ...
Validation loss decreased (1.330152 --> 1.324453).  Saving model ...
Validation loss decreased (1.324453 --> 1.317813).  Saving model ...
Validation loss decreased (1.317813 --> 1.312211).  Saving model ...
Validation loss decreased (1.312211 --> 1.306787).  Saving model ...
Validation loss decreased (1.306787 --> 1.300589).  Saving model ...
Validation loss decreased (1.300589 --> 1.293406).  Saving model ...
Validation loss decreased (1.293406 --> 1.288363).  Saving model ...
Validation loss decreased (1.288363 --> 1.281477).  Saving model ...
Validation loss decreased (1.281477 --> 1.273231).  Saving model ...
Validation loss decreased (1.273231 --> 1.265776).  Saving model ...
Validation loss decreased (1.265776 --> 1.259411).  Saving model ...
Validation loss decreased (1.259411 --> 1.252519).  Saving model ...
Validation loss decreased (1.252519 --> 1.245349).  Saving model ...
Validation loss decreased (1.245349 --> 1.239066).  Saving model ...
Validation loss decreased (1.239066 --> 1.234484).  Saving model ...
Validation loss decreased (1.234484 --> 1.231771).  Saving model ...
Validation loss decreased (1.231771 --> 1.225620).  Saving model ...
Validation loss decreased (1.225620 --> 1.222018).  Saving model ...
Validation loss decreased (1.222018 --> 1.216628).  Saving model ...
Validation loss decreased (1.216628 --> 1.212484).  Saving model ...
Validation loss decreased (1.212484 --> 1.204495).  Saving model ...
Validation loss decreased (1.204495 --> 1.200922).  Saving model ...
Validation loss decreased (1.200922 --> 1.196778).  Saving model ...
Validation loss decreased (1.196778 --> 1.194381).  Saving model ...
Validation loss decreased (1.194381 --> 1.188937).  Saving model ...
Validation loss decreased (1.188937 --> 1.181080).  Saving model ...
Validation loss decreased (1.181080 --> 1.176024).  Saving model ...
Validation loss decreased (1.176024 --> 1.170818).  Saving model ...
Validation loss decreased (1.170818 --> 1.167867).  Saving model ...
Validation loss decreased (1.167867 --> 1.162678).  Saving model ...
Validation loss decreased (1.162678 --> 1.159720).  Saving model ...
Validation loss decreased (1.159720 --> 1.154053).  Saving model ...
Validation loss decreased (1.154053 --> 1.149247).  Saving model ...
Validation loss decreased (1.149247 --> 1.148039).  Saving model ...
Validation loss decreased (1.148039 --> 1.142692).  Saving model ...
Validation loss decreased (1.142692 --> 1.135176).  Saving model ...
Validation loss decreased (1.135176 --> 1.131669).  Saving model ...
Validation loss decreased (1.131669 --> 1.127741).  Saving model ...
Validation loss decreased (1.127741 --> 1.123479).  Saving model ...
Validation loss decreased (1.123479 --> 1.118282).  Saving model ...
EarlyStopping counter: 1 out of 10.0
Validation loss decreased (1.118282 --> 1.117956).  Saving model ...
Validation loss decreased (1.117956 --> 1.114243).  Saving model ...
Validation loss decreased (1.114243 --> 1.109590).  Saving model ...
Validation loss decreased (1.109590 --> 1.104697).  Saving model ...
Validation loss decreased (1.104697 --> 1.101386).  Saving model ...
Validation loss decreased (1.101386 --> 1.097785).  Saving model ...
Validation loss decreased (1.097785 --> 1.093689).  Saving model ...
Validation loss decreased (1.093689 --> 1.091419).  Saving model ...
Validation loss decreased (1.091419 --> 1.088041).  Saving model ...
Validation loss decreased (1.088041 --> 1.082907).  Saving model ...
Validation loss decreased (1.082907 --> 1.076719).  Saving model ...
Validation loss decreased (1.076719 --> 1.075549).  Saving model ...
Validation loss decreased (1.075549 --> 1.073792).  Saving model ...
Validation loss decreased (1.073792 --> 1.072028).  Saving model ...
Validation loss decreased (1.072028 --> 1.069485).  Saving model ...
Validation loss decreased (1.069485 --> 1.068715).  Saving model ...
Validation loss decreased (1.068715 --> 1.064416).  Saving model ...
Validation loss decreased (1.064416 --> 1.061690).  Saving model ...
Validation loss decreased (1.061690 --> 1.058483).  Saving model ...
Validation loss decreased (1.058483 --> 1.055209).  Saving model ...
Validation loss decreased (1.055209 --> 1.053859).  Saving model ...
Validation loss decreased (1.053859 --> 1.052197).  Saving model ...
Validation loss decreased (1.052197 --> 1.049085).  Saving model ...
EarlyStopping counter: 1 out of 10.0
Validation loss decreased (1.049085 --> 1.046284).  Saving model ...
Validation loss decreased (1.046284 --> 1.044900).  Saving model ...
EarlyStopping counter: 1 out of 10.0
Validation loss decreased (1.044900 --> 1.041984).  Saving model ...
EarlyStopping counter: 1 out of 10.0
Validation loss decreased (1.041984 --> 1.038770).  Saving model ...
Validation loss decreased (1.038770 --> 1.036565).  Saving model ...
Validation loss decreased (1.036565 --> 1.033303).  Saving model ...
Validation loss decreased (1.033303 --> 1.032021).  Saving model ...
Validation loss decreased (1.032021 --> 1.031246).  Saving model ...
Validation loss decreased (1.031246 --> 1.030773).  Saving model ...
Validation loss decreased (1.030773 --> 1.029085).  Saving model ...
Validation loss decreased (1.029085 --> 1.025892).  Saving model ...
Validation loss decreased (1.025892 --> 1.021483).  Saving model ...
EarlyStopping counter: 1 out of 10.0
EarlyStopping counter: 2 out of 10.0
EarlyStopping counter: 3 out of 10.0
EarlyStopping counter: 4 out of 10.0
EarlyStopping counter: 5 out of 10.0
Validation loss decreased (1.021483 --> 1.019784).  Saving model ...
Validation loss decreased (1.019784 --> 1.017513).  Saving model ...
EarlyStopping counter: 1 out of 10.0
EarlyStopping counter: 2 out of 10.0
EarlyStopping counter: 3 out of 10.0
Validation loss decreased (1.017513 --> 1.013997).  Saving model ...
EarlyStopping counter: 1 out of 10.0
Validation loss decreased (1.013997 --> 1.012807).  Saving model ...
EarlyStopping counter: 1 out of 10.0
EarlyStopping counter: 2 out of 10.0
Validation loss decreased (1.012807 --> 1.011662).  Saving model ...
EarlyStopping counter: 1 out of 10.0
Validation loss decreased (1.011662 --> 1.009892).  Saving model ...
EarlyStopping counter: 1 out of 10.0
EarlyStopping counter: 2 out of 10.0
Validation loss decreased (1.009892 --> 1.007924).  Saving model ...
EarlyStopping counter: 1 out of 10.0
EarlyStopping counter: 2 out of 10.0
Validation loss decreased (1.007924 --> 1.006252).  Saving model ...
EarlyStopping counter: 1 out of 10.0
EarlyStopping counter: 2 out of 10.0
EarlyStopping counter: 3 out of 10.0
EarlyStopping counter: 4 out of 10.0
EarlyStopping counter: 5 out of 10.0
EarlyStopping counter: 6 out of 10.0
Validation loss decreased (1.006252 --> 1.006071).  Saving model ...
EarlyStopping counter: 1 out of 10.0
EarlyStopping counter: 2 out of 10.0
Validation loss decreased (1.006071 --> 1.005482).  Saving model ...
EarlyStopping counter: 1 out of 10.0
EarlyStopping counter: 2 out of 10.0
Validation loss decreased (1.005482 --> 1.004382).  Saving model ...
Validation loss decreased (1.004382 --> 1.003801).  Saving model ...
EarlyStopping counter: 1 out of 10.0
Validation loss decreased (1.003801 --> 1.000913).  Saving model ...
Validation loss decreased (1.000913 --> 0.998895).  Saving model ...
EarlyStopping counter: 1 out of 10.0
EarlyStopping counter: 2 out of 10.0
EarlyStopping counter: 3 out of 10.0
Validation loss decreased (0.998895 --> 0.997236).  Saving model ...
EarlyStopping counter: 1 out of 10.0
EarlyStopping counter: 2 out of 10.0
EarlyStopping counter: 3 out of 10.0
Validation loss decreased (0.997236 --> 0.996387).  Saving model ...
EarlyStopping counter: 1 out of 10.0
EarlyStopping counter: 2 out of 10.0
EarlyStopping counter: 3 out of 10.0
EarlyStopping counter: 4 out of 10.0
EarlyStopping counter: 5 out of 10.0
EarlyStopping counter: 6 out of 10.0
EarlyStopping counter: 7 out of 10.0
EarlyStopping counter: 8 out of 10.0
EarlyStopping counter: 9 out of 10.0
EarlyStopping counter: 10 out of 10.0
/localscratch/yinan.29544078.0/env/lib/python3.7/site-packages/torch/nn/functional.py:1794: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.
  warnings.warn("nn.functional.tanh is deprecated. Use torch.tanh instead.")
wandb: Waiting for W&B process to finish, PID 40712... (success).
wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: \ 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: | 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: / 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: \ 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: | 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: / 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: \ 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: | 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: / 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: \ 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: | 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb:                                                                                
wandb: Run history:
wandb:     e_F1 ▁▂▄▄▄▅▅▅▆▆▆▆▇▇▇▇▇▇▇▇▇▇▇▇▇▇██████████████
wandb:   e_loss █▇▇▇▆▆▆▅▅▄▄▄▄▃▃▃▃▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:     t_F1 ▁▁▂▂▃▃▄▄▅▅▅▅▆▅▅▆▆▆▆▆▆▇▇▆▇▇▇▇▇▇▇██▇▇███▇█
wandb:   t_loss ██▇▇▇▇▆▆▆▆▅▅▅▅▅▄▄▄▄▄▄▃▃▃▃▃▂▃▂▂▂▂▂▂▂▂▁▁▁▁
wandb: 
wandb: Run summary:
wandb:     e_F1 57.02716
wandb:   e_loss 1.00925
wandb:     t_F1 75.38347
wandb:   t_loss 0.69119
wandb: 
wandb: Synced 4 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Synced lunar-elevator-1: https://wandb.ai/yinanazhou/xl_512_bs_8_lr_1e06_es_10_lc_True_nr_True_sr_True_stem_False_lemma_True_repeat_4_fold_2/runs/11qe56dh
wandb: Find logs at: ./wandb/run-20220326_121917-11qe56dh/logs/debug.log
wandb: 

wandb: wandb version 0.12.11 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
2022-03-26 14:00:02.504832: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1
wandb: Tracking run with wandb version 0.12.5
wandb: Syncing run pleasant-galaxy-1
wandb: ⭐️ View project at https://wandb.ai/yinanazhou/xl_512_bs_8_lr_1e06_es_10_lc_True_nr_True_sr_True_stem_False_lemma_True_repeat_5_fold_1
wandb: 🚀 View run at https://wandb.ai/yinanazhou/xl_512_bs_8_lr_1e06_es_10_lc_True_nr_True_sr_True_stem_False_lemma_True_repeat_5_fold_1/runs/1xxhb6fu
wandb: Run data is saved locally in /project/6002780/yinan/Thesis_MER_Lyrics/lyric-emotion/wandb/run-20220326_140000-1xxhb6fu
wandb: Run `wandb offline` to turn off syncing.

Validation loss decreased (inf --> 1.455520).  Saving model ...
Validation loss decreased (1.455520 --> 1.433891).  Saving model ...
Validation loss decreased (1.433891 --> 1.415391).  Saving model ...
Validation loss decreased (1.415391 --> 1.400609).  Saving model ...
Validation loss decreased (1.400609 --> 1.389478).  Saving model ...
Validation loss decreased (1.389478 --> 1.380928).  Saving model ...
Validation loss decreased (1.380928 --> 1.372549).  Saving model ...
Validation loss decreased (1.372549 --> 1.365883).  Saving model ...
Validation loss decreased (1.365883 --> 1.360494).  Saving model ...
Validation loss decreased (1.360494 --> 1.354968).  Saving model ...
Validation loss decreased (1.354968 --> 1.350429).  Saving model ...
Validation loss decreased (1.350429 --> 1.346072).  Saving model ...
Validation loss decreased (1.346072 --> 1.341829).  Saving model ...
Validation loss decreased (1.341829 --> 1.337135).  Saving model ...
Validation loss decreased (1.337135 --> 1.332307).  Saving model ...
Validation loss decreased (1.332307 --> 1.326954).  Saving model ...
Validation loss decreased (1.326954 --> 1.321720).  Saving model ...
Validation loss decreased (1.321720 --> 1.316477).  Saving model ...
Validation loss decreased (1.316477 --> 1.311128).  Saving model ...
Validation loss decreased (1.311128 --> 1.305820).  Saving model ...
Validation loss decreased (1.305820 --> 1.300713).  Saving model ...
Validation loss decreased (1.300713 --> 1.294967).  Saving model ...
Validation loss decreased (1.294967 --> 1.289763).  Saving model ...
Validation loss decreased (1.289763 --> 1.284286).  Saving model ...
Validation loss decreased (1.284286 --> 1.279145).  Saving model ...
Validation loss decreased (1.279145 --> 1.273160).  Saving model ...
Validation loss decreased (1.273160 --> 1.265245).  Saving model ...
Validation loss decreased (1.265245 --> 1.260326).  Saving model ...
Validation loss decreased (1.260326 --> 1.255064).  Saving model ...
Validation loss decreased (1.255064 --> 1.249321).  Saving model ...
Validation loss decreased (1.249321 --> 1.241989).  Saving model ...
Validation loss decreased (1.241989 --> 1.236144).  Saving model ...
Validation loss decreased (1.236144 --> 1.230445).  Saving model ...
Validation loss decreased (1.230445 --> 1.223338).  Saving model ...
Validation loss decreased (1.223338 --> 1.217783).  Saving model ...
Validation loss decreased (1.217783 --> 1.212917).  Saving model ...
Validation loss decreased (1.212917 --> 1.206746).  Saving model ...
Validation loss decreased (1.206746 --> 1.202081).  Saving model ...
Validation loss decreased (1.202081 --> 1.196227).  Saving model ...
Validation loss decreased (1.196227 --> 1.189746).  Saving model ...
Validation loss decreased (1.189746 --> 1.185755).  Saving model ...
Validation loss decreased (1.185755 --> 1.180366).  Saving model ...
Validation loss decreased (1.180366 --> 1.174066).  Saving model ...
Validation loss decreased (1.174066 --> 1.170537).  Saving model ...
Validation loss decreased (1.170537 --> 1.165182).  Saving model ...
Validation loss decreased (1.165182 --> 1.160070).  Saving model ...
Validation loss decreased (1.160070 --> 1.154790).  Saving model ...
Validation loss decreased (1.154790 --> 1.150345).  Saving model ...
Validation loss decreased (1.150345 --> 1.147170).  Saving model ...
Validation loss decreased (1.147170 --> 1.144829).  Saving model ...
Validation loss decreased (1.144829 --> 1.140287).  Saving model ...
Validation loss decreased (1.140287 --> 1.136078).  Saving model ...
Validation loss decreased (1.136078 --> 1.131245).  Saving model ...
Validation loss decreased (1.131245 --> 1.127281).  Saving model ...
Validation loss decreased (1.127281 --> 1.124267).  Saving model ...
Validation loss decreased (1.124267 --> 1.119084).  Saving model ...
Validation loss decreased (1.119084 --> 1.114191).  Saving model ...
Validation loss decreased (1.114191 --> 1.112471).  Saving model ...
Validation loss decreased (1.112471 --> 1.108534).  Saving model ...
Validation loss decreased (1.108534 --> 1.104610).  Saving model ...
Validation loss decreased (1.104610 --> 1.101676).  Saving model ...
Validation loss decreased (1.101676 --> 1.098591).  Saving model ...
Validation loss decreased (1.098591 --> 1.095439).  Saving model ...
Validation loss decreased (1.095439 --> 1.090974).  Saving model ...
Validation loss decreased (1.090974 --> 1.088623).  Saving model ...
Validation loss decreased (1.088623 --> 1.085080).  Saving model ...
Validation loss decreased (1.085080 --> 1.082143).  Saving model ...
Validation loss decreased (1.082143 --> 1.078398).  Saving model ...
Validation loss decreased (1.078398 --> 1.075896).  Saving model ...
Validation loss decreased (1.075896 --> 1.072850).  Saving model ...
Validation loss decreased (1.072850 --> 1.072076).  Saving model ...
Validation loss decreased (1.072076 --> 1.068467).  Saving model ...
Validation loss decreased (1.068467 --> 1.064929).  Saving model ...
Validation loss decreased (1.064929 --> 1.061332).  Saving model ...
Validation loss decreased (1.061332 --> 1.058740).  Saving model ...
Validation loss decreased (1.058740 --> 1.058198).  Saving model ...
Validation loss decreased (1.058198 --> 1.056756).  Saving model ...
Validation loss decreased (1.056756 --> 1.052666).  Saving model ...
Validation loss decreased (1.052666 --> 1.050187).  Saving model ...
Validation loss decreased (1.050187 --> 1.048525).  Saving model ...
Validation loss decreased (1.048525 --> 1.046355).  Saving model ...
Validation loss decreased (1.046355 --> 1.044411).  Saving model ...
Validation loss decreased (1.044411 --> 1.042334).  Saving model ...
Validation loss decreased (1.042334 --> 1.040727).  Saving model ...
Validation loss decreased (1.040727 --> 1.038353).  Saving model ...
Validation loss decreased (1.038353 --> 1.035092).  Saving model ...
Validation loss decreased (1.035092 --> 1.032543).  Saving model ...
Validation loss decreased (1.032543 --> 1.031302).  Saving model ...
Validation loss decreased (1.031302 --> 1.030102).  Saving model ...
Validation loss decreased (1.030102 --> 1.028888).  Saving model ...
Validation loss decreased (1.028888 --> 1.024595).  Saving model ...
Validation loss decreased (1.024595 --> 1.023646).  Saving model ...
EarlyStopping counter: 1 out of 10.0
Validation loss decreased (1.023646 --> 1.023481).  Saving model ...
Validation loss decreased (1.023481 --> 1.021725).  Saving model ...
Validation loss decreased (1.021725 --> 1.018426).  Saving model ...
Validation loss decreased (1.018426 --> 1.017251).  Saving model ...
Validation loss decreased (1.017251 --> 1.016623).  Saving model ...
Validation loss decreased (1.016623 --> 1.014917).  Saving model ...
Validation loss decreased (1.014917 --> 1.012902).  Saving model ...
Validation loss decreased (1.012902 --> 1.010798).  Saving model ...
Validation loss decreased (1.010798 --> 1.010116).  Saving model ...
Validation loss decreased (1.010116 --> 1.009779).  Saving model ...
Validation loss decreased (1.009779 --> 1.007770).  Saving model ...
Validation loss decreased (1.007770 --> 1.006898).  Saving model ...
Validation loss decreased (1.006898 --> 1.003838).  Saving model ...
EarlyStopping counter: 1 out of 10.0
Validation loss decreased (1.003838 --> 1.002059).  Saving model ...
Validation loss decreased (1.002059 --> 1.001410).  Saving model ...
Validation loss decreased (1.001410 --> 1.000537).  Saving model ...
EarlyStopping counter: 1 out of 10.0
Validation loss decreased (1.000537 --> 0.998709).  Saving model ...
Validation loss decreased (0.998709 --> 0.996549).  Saving model ...
Validation loss decreased (0.996549 --> 0.994870).  Saving model ...
EarlyStopping counter: 1 out of 10.0
Validation loss decreased (0.994870 --> 0.994332).  Saving model ...
Validation loss decreased (0.994332 --> 0.992767).  Saving model ...
Validation loss decreased (0.992767 --> 0.992056).  Saving model ...
Validation loss decreased (0.992056 --> 0.991365).  Saving model ...
Validation loss decreased (0.991365 --> 0.988497).  Saving model ...
Validation loss decreased (0.988497 --> 0.987061).  Saving model ...
EarlyStopping counter: 1 out of 10.0
Validation loss decreased (0.987061 --> 0.986980).  Saving model ...
Validation loss decreased (0.986980 --> 0.986708).  Saving model ...
EarlyStopping counter: 1 out of 10.0
EarlyStopping counter: 2 out of 10.0
Validation loss decreased (0.986708 --> 0.986305).  Saving model ...
Validation loss decreased (0.986305 --> 0.986294).  Saving model ...
Validation loss decreased (0.986294 --> 0.985767).  Saving model ...
Validation loss decreased (0.985767 --> 0.983328).  Saving model ...
Validation loss decreased (0.983328 --> 0.982828).  Saving model ...
Validation loss decreased (0.982828 --> 0.982106).  Saving model ...
Validation loss decreased (0.982106 --> 0.980966).  Saving model ...
Validation loss decreased (0.980966 --> 0.980125).  Saving model ...
EarlyStopping counter: 1 out of 10.0
EarlyStopping counter: 2 out of 10.0
EarlyStopping counter: 3 out of 10.0
Validation loss decreased (0.980125 --> 0.979356).  Saving model ...
EarlyStopping counter: 1 out of 10.0
Validation loss decreased (0.979356 --> 0.978976).  Saving model ...
EarlyStopping counter: 1 out of 10.0
EarlyStopping counter: 2 out of 10.0
EarlyStopping counter: 3 out of 10.0
EarlyStopping counter: 4 out of 10.0
EarlyStopping counter: 5 out of 10.0
EarlyStopping counter: 6 out of 10.0
Validation loss decreased (0.978976 --> 0.978154).  Saving model ...
EarlyStopping counter: 1 out of 10.0
EarlyStopping counter: 2 out of 10.0
EarlyStopping counter: 3 out of 10.0
Validation loss decreased (0.978154 --> 0.977986).  Saving model ...
EarlyStopping counter: 1 out of 10.0
EarlyStopping counter: 2 out of 10.0
EarlyStopping counter: 3 out of 10.0
EarlyStopping counter: 4 out of 10.0
EarlyStopping counter: 5 out of 10.0
EarlyStopping counter: 6 out of 10.0
EarlyStopping counter: 7 out of 10.0
EarlyStopping counter: 8 out of 10.0
EarlyStopping counter: 9 out of 10.0
EarlyStopping counter: 10 out of 10.0
/localscratch/yinan.29544078.0/env/lib/python3.7/site-packages/torch/nn/functional.py:1794: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.
  warnings.warn("nn.functional.tanh is deprecated. Use torch.tanh instead.")
wandb: Waiting for W&B process to finish, PID 46043... (success).
wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: \ 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: | 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: / 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: \ 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: | 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: / 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: \ 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: | 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: / 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: \ 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb:                                                                                
wandb: Run history:
wandb:     e_F1 ▁▂▄▄▄▄▅▅▅▅▆▆▆▆▆▆▇▇▇▇▇███████████████████
wandb:   e_loss █▇▇▇▆▆▆▅▅▄▄▄▄▃▃▃▃▂▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:     t_F1 ▁▂▂▃▄▄▄▄▄▅▅▅▅▅▆▆▆▇▇▆▆▆▇▇▇▇▆▇▇▇█▇▇██▇▇███
wandb:   t_loss ██▇▇▇▇▆▆▆▅▅▅▅▅▅▄▄▄▄▄▄▃▃▃▃▃▃▂▂▂▂▂▂▂▂▂▂▂▁▁
wandb: 
wandb: Run summary:
wandb:     e_F1 58.78713
wandb:   e_loss 0.978
wandb:     t_F1 74.89144
wandb:   t_loss 0.69035
wandb: 
wandb: Synced 4 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Synced pleasant-galaxy-1: https://wandb.ai/yinanazhou/xl_512_bs_8_lr_1e06_es_10_lc_True_nr_True_sr_True_stem_False_lemma_True_repeat_5_fold_1/runs/1xxhb6fu
wandb: Find logs at: ./wandb/run-20220326_140000-1xxhb6fu/logs/debug.log
wandb: 

wandb: wandb version 0.12.11 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
2022-03-26 15:45:26.591371: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1
wandb: Tracking run with wandb version 0.12.5
wandb: Syncing run soft-glade-1
wandb: ⭐️ View project at https://wandb.ai/yinanazhou/xl_512_bs_8_lr_1e06_es_10_lc_True_nr_True_sr_True_stem_False_lemma_True_repeat_5_fold_2
wandb: 🚀 View run at https://wandb.ai/yinanazhou/xl_512_bs_8_lr_1e06_es_10_lc_True_nr_True_sr_True_stem_False_lemma_True_repeat_5_fold_2/runs/3pbcfuar
wandb: Run data is saved locally in /project/6002780/yinan/Thesis_MER_Lyrics/lyric-emotion/wandb/run-20220326_154524-3pbcfuar
wandb: Run `wandb offline` to turn off syncing.

Validation loss decreased (inf --> 1.415863).  Saving model ...
Validation loss decreased (1.415863 --> 1.402677).  Saving model ...
Validation loss decreased (1.402677 --> 1.393040).  Saving model ...
Validation loss decreased (1.393040 --> 1.386269).  Saving model ...
Validation loss decreased (1.386269 --> 1.381064).  Saving model ...
Validation loss decreased (1.381064 --> 1.376432).  Saving model ...
Validation loss decreased (1.376432 --> 1.372006).  Saving model ...
Validation loss decreased (1.372006 --> 1.368201).  Saving model ...
Validation loss decreased (1.368201 --> 1.364284).  Saving model ...
Validation loss decreased (1.364284 --> 1.359984).  Saving model ...
Validation loss decreased (1.359984 --> 1.355912).  Saving model ...
Validation loss decreased (1.355912 --> 1.351907).  Saving model ...
Validation loss decreased (1.351907 --> 1.347670).  Saving model ...
Validation loss decreased (1.347670 --> 1.343320).  Saving model ...
Validation loss decreased (1.343320 --> 1.338837).  Saving model ...
Validation loss decreased (1.338837 --> 1.334873).  Saving model ...
Validation loss decreased (1.334873 --> 1.330197).  Saving model ...
Validation loss decreased (1.330197 --> 1.326326).  Saving model ...
Validation loss decreased (1.326326 --> 1.321406).  Saving model ...
Validation loss decreased (1.321406 --> 1.315661).  Saving model ...
Validation loss decreased (1.315661 --> 1.309578).  Saving model ...
Validation loss decreased (1.309578 --> 1.302598).  Saving model ...
Validation loss decreased (1.302598 --> 1.296817).  Saving model ...
Validation loss decreased (1.296817 --> 1.291650).  Saving model ...
Validation loss decreased (1.291650 --> 1.284501).  Saving model ...
Validation loss decreased (1.284501 --> 1.277786).  Saving model ...
Validation loss decreased (1.277786 --> 1.271150).  Saving model ...
Validation loss decreased (1.271150 --> 1.264351).  Saving model ...
Validation loss decreased (1.264351 --> 1.257813).  Saving model ...
Validation loss decreased (1.257813 --> 1.250963).  Saving model ...
Validation loss decreased (1.250963 --> 1.244642).  Saving model ...
Validation loss decreased (1.244642 --> 1.238012).  Saving model ...
Validation loss decreased (1.238012 --> 1.233187).  Saving model ...
Validation loss decreased (1.233187 --> 1.227219).  Saving model ...
Validation loss decreased (1.227219 --> 1.221534).  Saving model ...
Validation loss decreased (1.221534 --> 1.215133).  Saving model ...
Validation loss decreased (1.215133 --> 1.210046).  Saving model ...
Validation loss decreased (1.210046 --> 1.204435).  Saving model ...
Validation loss decreased (1.204435 --> 1.200960).  Saving model ...
Validation loss decreased (1.200960 --> 1.195171).  Saving model ...
Validation loss decreased (1.195171 --> 1.189295).  Saving model ...
Validation loss decreased (1.189295 --> 1.186582).  Saving model ...
Validation loss decreased (1.186582 --> 1.180207).  Saving model ...
Validation loss decreased (1.180207 --> 1.175719).  Saving model ...
Validation loss decreased (1.175719 --> 1.172213).  Saving model ...
Validation loss decreased (1.172213 --> 1.167567).  Saving model ...
Validation loss decreased (1.167567 --> 1.162149).  Saving model ...
Validation loss decreased (1.162149 --> 1.159232).  Saving model ...
Validation loss decreased (1.159232 --> 1.154871).  Saving model ...
Validation loss decreased (1.154871 --> 1.151834).  Saving model ...
Validation loss decreased (1.151834 --> 1.144668).  Saving model ...
Validation loss decreased (1.144668 --> 1.141771).  Saving model ...
Validation loss decreased (1.141771 --> 1.137044).  Saving model ...
Validation loss decreased (1.137044 --> 1.135967).  Saving model ...
Validation loss decreased (1.135967 --> 1.133933).  Saving model ...
Validation loss decreased (1.133933 --> 1.127942).  Saving model ...
Validation loss decreased (1.127942 --> 1.122886).  Saving model ...
Validation loss decreased (1.122886 --> 1.119356).  Saving model ...
Validation loss decreased (1.119356 --> 1.117501).  Saving model ...
Validation loss decreased (1.117501 --> 1.112833).  Saving model ...
Validation loss decreased (1.112833 --> 1.112122).  Saving model ...
Validation loss decreased (1.112122 --> 1.108167).  Saving model ...
Validation loss decreased (1.108167 --> 1.103590).  Saving model ...
Validation loss decreased (1.103590 --> 1.098634).  Saving model ...
Validation loss decreased (1.098634 --> 1.092371).  Saving model ...
Validation loss decreased (1.092371 --> 1.086891).  Saving model ...
Validation loss decreased (1.086891 --> 1.085859).  Saving model ...
Validation loss decreased (1.085859 --> 1.085612).  Saving model ...
Validation loss decreased (1.085612 --> 1.081347).  Saving model ...
Validation loss decreased (1.081347 --> 1.078018).  Saving model ...
Validation loss decreased (1.078018 --> 1.077012).  Saving model ...
Validation loss decreased (1.077012 --> 1.074373).  Saving model ...
Validation loss decreased (1.074373 --> 1.073297).  Saving model ...
Validation loss decreased (1.073297 --> 1.068103).  Saving model ...
Validation loss decreased (1.068103 --> 1.065860).  Saving model ...
Validation loss decreased (1.065860 --> 1.062809).  Saving model ...
Validation loss decreased (1.062809 --> 1.060989).  Saving model ...
Validation loss decreased (1.060989 --> 1.058770).  Saving model ...
Validation loss decreased (1.058770 --> 1.055343).  Saving model ...
Validation loss decreased (1.055343 --> 1.054046).  Saving model ...
Validation loss decreased (1.054046 --> 1.052400).  Saving model ...
Validation loss decreased (1.052400 --> 1.049664).  Saving model ...
Validation loss decreased (1.049664 --> 1.047023).  Saving model ...
Validation loss decreased (1.047023 --> 1.043030).  Saving model ...
Validation loss decreased (1.043030 --> 1.041032).  Saving model ...
EarlyStopping counter: 1 out of 10.0
Validation loss decreased (1.041032 --> 1.037496).  Saving model ...
EarlyStopping counter: 1 out of 10.0
Validation loss decreased (1.037496 --> 1.037032).  Saving model ...
Validation loss decreased (1.037032 --> 1.034931).  Saving model ...
Validation loss decreased (1.034931 --> 1.033404).  Saving model ...
Validation loss decreased (1.033404 --> 1.030014).  Saving model ...
Validation loss decreased (1.030014 --> 1.027040).  Saving model ...
Validation loss decreased (1.027040 --> 1.025879).  Saving model ...
Validation loss decreased (1.025879 --> 1.021774).  Saving model ...
Validation loss decreased (1.021774 --> 1.021589).  Saving model ...
Validation loss decreased (1.021589 --> 1.018126).  Saving model ...
Validation loss decreased (1.018126 --> 1.018062).  Saving model ...
Validation loss decreased (1.018062 --> 1.015701).  Saving model ...
Validation loss decreased (1.015701 --> 1.014636).  Saving model ...
EarlyStopping counter: 1 out of 10.0
EarlyStopping counter: 2 out of 10.0
Validation loss decreased (1.014636 --> 1.014368).  Saving model ...
Validation loss decreased (1.014368 --> 1.009569).  Saving model ...
EarlyStopping counter: 1 out of 10.0
EarlyStopping counter: 2 out of 10.0
Validation loss decreased (1.009569 --> 1.005571).  Saving model ...
Validation loss decreased (1.005571 --> 1.002940).  Saving model ...
EarlyStopping counter: 1 out of 10.0
Validation loss decreased (1.002940 --> 0.998933).  Saving model ...
EarlyStopping counter: 1 out of 10.0
Validation loss decreased (0.998933 --> 0.998874).  Saving model ...
EarlyStopping counter: 1 out of 10.0
EarlyStopping counter: 2 out of 10.0
Validation loss decreased (0.998874 --> 0.997742).  Saving model ...
EarlyStopping counter: 1 out of 10.0
Validation loss decreased (0.997742 --> 0.994919).  Saving model ...
Validation loss decreased (0.994919 --> 0.994077).  Saving model ...
EarlyStopping counter: 1 out of 10.0
EarlyStopping counter: 2 out of 10.0
EarlyStopping counter: 3 out of 10.0
Validation loss decreased (0.994077 --> 0.987909).  Saving model ...
Validation loss decreased (0.987909 --> 0.986510).  Saving model ...
EarlyStopping counter: 1 out of 10.0
EarlyStopping counter: 2 out of 10.0
Validation loss decreased (0.986510 --> 0.984817).  Saving model ...
EarlyStopping counter: 1 out of 10.0
Validation loss decreased (0.984817 --> 0.982954).  Saving model ...
EarlyStopping counter: 1 out of 10.0
EarlyStopping counter: 2 out of 10.0
EarlyStopping counter: 3 out of 10.0
Validation loss decreased (0.982954 --> 0.980775).  Saving model ...
Validation loss decreased (0.980775 --> 0.978526).  Saving model ...
EarlyStopping counter: 1 out of 10.0
EarlyStopping counter: 2 out of 10.0
EarlyStopping counter: 3 out of 10.0
EarlyStopping counter: 4 out of 10.0
EarlyStopping counter: 5 out of 10.0
EarlyStopping counter: 6 out of 10.0
EarlyStopping counter: 7 out of 10.0
EarlyStopping counter: 8 out of 10.0
EarlyStopping counter: 9 out of 10.0
EarlyStopping counter: 10 out of 10.0
/localscratch/yinan.29544078.0/env/lib/python3.7/site-packages/torch/nn/functional.py:1794: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.
  warnings.warn("nn.functional.tanh is deprecated. Use torch.tanh instead.")
wandb: Waiting for W&B process to finish, PID 51654... (success).
wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: \ 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: | 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: / 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: \ 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: | 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: / 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: \ 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: | 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: / 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb:                                                                                
wandb: Run history:
wandb:     e_F1 ▁▂▄▅▅▅▅▅▆▆▆▆▆▆▆▆▆▆▇▇▇▇▇▇▇▇▇█████████████
wandb:   e_loss ██▇▇▇▇▆▆▅▅▅▅▄▄▄▄▃▃▃▃▃▂▂▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁
wandb:     t_F1 ▁▁▂▂▃▃▄▄▄▄▄▅▅▅▆▅▆▆▆▆▆▆▆▇▇▇▇▇▇▇▇▇████████
wandb:   t_loss ███▇▇▇▇▇▆▆▆▅▅▅▅▅▄▄▄▄▃▃▃▃▃▃▃▃▂▂▂▂▂▂▁▂▂▁▁▁
wandb: 
wandb: Run summary:
wandb:     e_F1 57.49926
wandb:   e_loss 0.97926
wandb:     t_F1 69.30182
wandb:   t_loss 0.77884
wandb: 
wandb: Synced 4 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Synced soft-glade-1: https://wandb.ai/yinanazhou/xl_512_bs_8_lr_1e06_es_10_lc_True_nr_True_sr_True_stem_False_lemma_True_repeat_5_fold_2/runs/3pbcfuar
wandb: Find logs at: ./wandb/run-20220326_154524-3pbcfuar/logs/debug.log
wandb: 

