Unloading StdEnv/2020

Due to MODULEPATH changes, the following have been reloaded:
  1) mii/1.1.1


The following have been reloaded with a version change:
  1) python/3.8.2 => python/3.7.4

Using base prefix '/cvmfs/soft.computecanada.ca/easybuild/software/2017/Core/python/3.7.4'
New python executable in /localscratch/yinan.29019358.0/env/bin/python
Installing setuptools, pip, wheel...
done.
Ignoring pip: markers 'python_version < "3"' don't match your environment
Looking in links: /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/nix/avx2, /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/nix/generic, /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic
Collecting pip
Installing collected packages: pip
  Found existing installation: pip 19.1.1
    Uninstalling pip-19.1.1:
      Successfully uninstalled pip-19.1.1
Successfully installed pip-21.2.3+computecanada
Looking in links: /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/nix/avx2, /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/nix/generic, /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/keras-2.8.0+computecanada-py2.py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/Keras_Preprocessing-1.1.2+computecanada-py3-none-any.whl
Requirement already satisfied: matplotlib in /cvmfs/soft.computecanada.ca/easybuild/software/2017/Core/scipy-stack/2019a/lib/python3.7/site-packages (from -r requirements.txt (line 3)) (3.0.2)
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/nltk-3.6.5+computecanada-py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/scikit_learn-0.22.1+computecanada-cp37-cp37m-linux_x86_64.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/tensorboard-2.3.0+computecanada-py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/tensorboard_plugin_wit-1.7.0+computecanada-py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/tensorflow_gpu-2.3.0+computecanada-cp37-cp37m-linux_x86_64.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/tensorflow_estimator-2.3.0+computecanada-py2.py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/tokenizers-0.5.2+computecanada-cp37-cp37m-linux_x86_64.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/nix/avx2/torch-1.4.0+computecanada-cp37-cp37m-linux_x86_64.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/torchtext-0.6.0+computecanada-py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/torchvision-0.8.2+computecanada-cp37-cp37m-linux_x86_64.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/transformers-2.5.1+computecanada-py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/urllib3-1.26.7+computecanada-py2.py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/joblib-1.1.0+computecanada-py2.py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/click-8.0.4+computecanada-py3-none-any.whl
ERROR: Could not find a version that satisfies the requirement regex>=2021.8.3 (from nltk) (from versions: 2018.1.10+computecanada, 2019.11.1+computecanada, 2020.11.13+computecanada)
ERROR: No matching distribution found for regex>=2021.8.3
Looking in links: /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/nix/avx2, /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/nix/generic, /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic
ERROR: Could not find a version that satisfies the requirement numpy==1.20.0+computacanada (from versions: 1.15.0+computecanada, 1.15.2+computecanada, 1.15.4+computecanada, 1.16.0+computecanada, 1.16.2+computecanada, 1.16.3+computecanada, 1.17.4+computecanada, 1.18.1+computecanada, 1.18.4+computecanada, 1.19.1+computecanada, 1.19.2+computecanada, 1.20.2+computecanada)
ERROR: No matching distribution found for numpy==1.20.0+computacanada
Looking in links: /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/nix/avx2, /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/nix/generic, /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/wandb-0.12.5+computecanada-py2.py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/docker_pycreds-0.4.0+computecanada-py2.py3-none-any.whl
Requirement already satisfied: requests<3,>=2.0.0 in /cvmfs/soft.computecanada.ca/easybuild/software/2017/Core/scipy-stack/2019a/lib/python3.7/site-packages (from wandb) (2.21.0)
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/click-8.0.4+computecanada-py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/yaspin-2.1.0+computecanada-py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/six-1.16.0+computecanada-py2.py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/promise-2.3+computecanada-py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/sentry_sdk-1.5.0+computecanada-py2.py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/GitPython-3.1.24+computecanada-py3-none-any.whl
Requirement already satisfied: python-dateutil>=2.6.1 in /cvmfs/soft.computecanada.ca/easybuild/software/2017/Core/scipy-stack/2019a/lib/python3.7/site-packages (from wandb) (2.7.5)
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/psutil-5.7.3+computecanada-cp37-cp37m-linux_x86_64.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/protobuf-3.19.4+computecanada-py2.py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/pathtools-0.1.2+computecanada-py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/subprocess32-3.5.4+computecanada-py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/shortuuid-1.0.1+computecanada-py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/configparser-5.0.2+computecanada-py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/PyYAML-5.3.1+computecanada-cp37-cp37m-linux_x86_64.whl
Requirement already satisfied: importlib-metadata in /cvmfs/soft.computecanada.ca/easybuild/software/2017/Core/scipy-stack/2019a/lib/python3.7/site-packages (from Click!=8.0.0,>=7.0->wandb) (0.8)
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/gitdb-4.0.9+computecanada-py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/typing_extensions-4.0.1+computecanada-py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/smmap-5.0.0+computecanada-py3-none-any.whl
Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /cvmfs/soft.computecanada.ca/easybuild/software/2017/Core/scipy-stack/2019a/lib/python3.7/site-packages (from requests<3,>=2.0.0->wandb) (3.0.4)
Requirement already satisfied: idna<2.9,>=2.5 in /cvmfs/soft.computecanada.ca/easybuild/software/2017/Core/scipy-stack/2019a/lib/python3.7/site-packages (from requests<3,>=2.0.0->wandb) (2.8)
Requirement already satisfied: urllib3<1.25,>=1.21.1 in /cvmfs/soft.computecanada.ca/easybuild/software/2017/Core/scipy-stack/2019a/lib/python3.7/site-packages (from requests<3,>=2.0.0->wandb) (1.24.1)
Requirement already satisfied: certifi>=2017.4.17 in /cvmfs/soft.computecanada.ca/easybuild/software/2017/Core/scipy-stack/2019a/lib/python3.7/site-packages (from requests<3,>=2.0.0->wandb) (2018.11.29)
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/termcolor-1.1.0+computecanada-py3-none-any.whl
Requirement already satisfied: zipp>=0.3.2 in /cvmfs/soft.computecanada.ca/easybuild/software/2017/Core/scipy-stack/2019a/lib/python3.7/site-packages (from importlib-metadata->Click!=8.0.0,>=7.0->wandb) (0.3.3)
Installing collected packages: smmap, typing-extensions, termcolor, six, gitdb, yaspin, subprocess32, shortuuid, sentry-sdk, PyYAML, psutil, protobuf, promise, pathtools, GitPython, docker-pycreds, configparser, Click, wandb
  Attempting uninstall: six
    Found existing installation: six 1.12.0
    Not uninstalling six at /cvmfs/soft.computecanada.ca/easybuild/software/2017/Core/scipy-stack/2019a/lib/python3.7/site-packages, outside environment /localscratch/yinan.29019358.0/env
    Can't uninstall 'six'. No files were found to uninstall.
Successfully installed Click-8.0.4+computecanada GitPython-3.1.24+computecanada PyYAML-5.3.1+computecanada configparser-5.0.2+computecanada docker-pycreds-0.4.0+computecanada gitdb-4.0.9+computecanada pathtools-0.1.2+computecanada promise-2.3+computecanada protobuf-3.19.4+computecanada psutil-5.7.3+computecanada sentry-sdk-1.5.0+computecanada shortuuid-1.0.1+computecanada six-1.16.0+computecanada smmap-5.0.0+computecanada subprocess32-3.5.4+computecanada termcolor-1.1.0+computecanada typing-extensions-4.0.1+computecanada wandb-0.12.5+computecanada yaspin-2.1.0+computecanada
Looking in links: /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/nix/avx2, /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/nix/generic, /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic
ERROR: Could not find a version that satisfies the requirement sagemaker (from versions: none)
ERROR: No matching distribution found for sagemaker
Looking in links: /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/nix/avx2, /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/nix/generic, /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/torch-1.9.1+computecanada-cp37-cp37m-linux_x86_64.whl
Requirement already satisfied: typing-extensions in /localscratch/yinan.29019358.0/env/lib/python3.7/site-packages (from torch) (4.0.1+computecanada)
Installing collected packages: torch
Successfully installed torch-1.9.1+computecanada
Looking in links: /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/nix/avx2, /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/nix/generic, /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/transformers-2.5.1+computecanada-py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/boto3-1.21.14+computecanada-py3-none-any.whl
Requirement already satisfied: numpy in /cvmfs/soft.computecanada.ca/easybuild/software/2017/Core/scipy-stack/2019a/lib/python3.7/site-packages (from transformers==2.5.1+computecanada) (1.16.0)
Requirement already satisfied: requests in /cvmfs/soft.computecanada.ca/easybuild/software/2017/Core/scipy-stack/2019a/lib/python3.7/site-packages (from transformers==2.5.1+computecanada) (2.21.0)
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/filelock-3.4.2+computecanada-py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/sacremoses-0.0.46+computecanada-py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/regex-2020.11.13+computecanada-cp37-cp37m-linux_x86_64.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/tokenizers-0.5.2+computecanada-cp37-cp37m-linux_x86_64.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/sentencepiece-0.1.91+computecanada-cp37-cp37m-linux_x86_64.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/tqdm-4.63.0+computecanada-py2.py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/botocore-1.24.14+computecanada-py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/s3transfer-0.5.1+computecanada-py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/jmespath-0.10.0+computecanada-py2.py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/urllib3-1.26.8+computecanada-py2.py3-none-any.whl
Requirement already satisfied: python-dateutil<3.0.0,>=2.1 in /cvmfs/soft.computecanada.ca/easybuild/software/2017/Core/scipy-stack/2019a/lib/python3.7/site-packages (from botocore<1.25.0,>=1.24.14->boto3->transformers==2.5.1+computecanada) (2.7.5)
Requirement already satisfied: six>=1.5 in /localscratch/yinan.29019358.0/env/lib/python3.7/site-packages (from python-dateutil<3.0.0,>=2.1->botocore<1.25.0,>=1.24.14->boto3->transformers==2.5.1+computecanada) (1.16.0+computecanada)
Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /cvmfs/soft.computecanada.ca/easybuild/software/2017/Core/scipy-stack/2019a/lib/python3.7/site-packages (from requests->transformers==2.5.1+computecanada) (3.0.4)
Requirement already satisfied: certifi>=2017.4.17 in /cvmfs/soft.computecanada.ca/easybuild/software/2017/Core/scipy-stack/2019a/lib/python3.7/site-packages (from requests->transformers==2.5.1+computecanada) (2018.11.29)
Requirement already satisfied: idna<2.9,>=2.5 in /cvmfs/soft.computecanada.ca/easybuild/software/2017/Core/scipy-stack/2019a/lib/python3.7/site-packages (from requests->transformers==2.5.1+computecanada) (2.8)
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/requests-2.27.1+computecanada-py2.py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/charset_normalizer-2.0.12+computecanada-py3-none-any.whl
Requirement already satisfied: click in /localscratch/yinan.29019358.0/env/lib/python3.7/site-packages (from sacremoses->transformers==2.5.1+computecanada) (8.0.4+computecanada)
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/joblib-1.1.0+computecanada-py2.py3-none-any.whl
Requirement already satisfied: importlib-metadata in /cvmfs/soft.computecanada.ca/easybuild/software/2017/Core/scipy-stack/2019a/lib/python3.7/site-packages (from click->sacremoses->transformers==2.5.1+computecanada) (0.8)
Requirement already satisfied: zipp>=0.3.2 in /cvmfs/soft.computecanada.ca/easybuild/software/2017/Core/scipy-stack/2019a/lib/python3.7/site-packages (from importlib-metadata->click->sacremoses->transformers==2.5.1+computecanada) (0.3.3)
Installing collected packages: urllib3, jmespath, botocore, tqdm, s3transfer, regex, joblib, charset-normalizer, tokenizers, sentencepiece, sacremoses, requests, filelock, boto3, transformers
  Attempting uninstall: urllib3
    Found existing installation: urllib3 1.24.1
    Not uninstalling urllib3 at /cvmfs/soft.computecanada.ca/easybuild/software/2017/Core/scipy-stack/2019a/lib/python3.7/site-packages, outside environment /localscratch/yinan.29019358.0/env
    Can't uninstall 'urllib3'. No files were found to uninstall.
  Attempting uninstall: requests
    Found existing installation: requests 2.21.0
    Not uninstalling requests at /cvmfs/soft.computecanada.ca/easybuild/software/2017/Core/scipy-stack/2019a/lib/python3.7/site-packages, outside environment /localscratch/yinan.29019358.0/env
    Can't uninstall 'requests'. No files were found to uninstall.
Successfully installed boto3-1.21.14+computecanada botocore-1.24.14+computecanada charset-normalizer-2.0.12+computecanada filelock-3.4.2+computecanada jmespath-0.10.0+computecanada joblib-1.1.0+computecanada regex-2020.11.13+computecanada requests-2.27.1+computecanada s3transfer-0.5.1+computecanada sacremoses-0.0.46+computecanada sentencepiece-0.1.91+computecanada tokenizers-0.5.2+computecanada tqdm-4.63.0+computecanada transformers-2.5.1+computecanada urllib3-1.26.8+computecanada
Looking in links: /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/nix/avx2, /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/nix/generic, /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/tensorflow_gpu-2.3.0+computecanada-cp37-cp37m-linux_x86_64.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/nix/avx2/h5py-2.10.0+computecanada-cp37-cp37m-linux_x86_64.whl
Requirement already satisfied: protobuf>=3.9.2 in /localscratch/yinan.29019358.0/env/lib/python3.7/site-packages (from tensorflow_gpu==2.3.0+computecanada) (3.19.4+computecanada)
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/astunparse-1.6.3+computecanada-py2.py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/wrapt-1.11.2+computecanada-cp37-cp37m-linux_x86_64.whl
Requirement already satisfied: six>=1.12.0 in /localscratch/yinan.29019358.0/env/lib/python3.7/site-packages (from tensorflow_gpu==2.3.0+computecanada) (1.16.0+computecanada)
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/gast-0.3.3+computecanada-py3-none-any.whl
Requirement already satisfied: termcolor>=1.1.0 in /localscratch/yinan.29019358.0/env/lib/python3.7/site-packages (from tensorflow_gpu==2.3.0+computecanada) (1.1.0+computecanada)
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/nix/generic/scipy-1.4.1+computecanada-cp37-cp37m-linux_x86_64.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/Keras_Preprocessing-1.1.2+computecanada-py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/opt_einsum-3.3.0+computecanada-py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/tensorflow_estimator-2.3.0+computecanada-py2.py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/absl_py-1.0.0+computecanada-py3-none-any.whl
Requirement already satisfied: wheel>=0.26 in /localscratch/yinan.29019358.0/env/lib/python3.7/site-packages (from tensorflow_gpu==2.3.0+computecanada) (0.33.4)
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/grpcio-1.38.0+computecanada-cp37-cp37m-linux_x86_64.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/google_pasta-0.2.0+computecanada-py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/tensorboard-2.8.0+computecanada-py3-none-any.whl
Requirement already satisfied: numpy<1.19.0,>=1.16.0 in /cvmfs/soft.computecanada.ca/easybuild/software/2017/Core/scipy-stack/2019a/lib/python3.7/site-packages (from tensorflow_gpu==2.3.0+computecanada) (1.16.0)
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/google_auth-2.3.3+computecanada-py2.py3-none-any.whl
Requirement already satisfied: requests<3,>=2.21.0 in /localscratch/yinan.29019358.0/env/lib/python3.7/site-packages (from tensorboard<3,>=2.3.0->tensorflow_gpu==2.3.0+computecanada) (2.27.1+computecanada)
Requirement already satisfied: setuptools>=41.0.0 in /localscratch/yinan.29019358.0/env/lib/python3.7/site-packages (from tensorboard<3,>=2.3.0->tensorflow_gpu==2.3.0+computecanada) (41.0.1)
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/tensorboard_data_server-0.6.1+computecanada-py3-none-linux_x86_64.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/tensorboard_plugin_wit-1.8.0+computecanada-py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/Werkzeug-2.0.3+computecanada-py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/Markdown-3.3.6+computecanada-py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/google_auth_oauthlib-0.4.6+computecanada-py2.py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/pyasn1_modules-0.2.8+computecanada-py2.py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/rsa-4.8+computecanada-py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/cachetools-4.2.4+computecanada-py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/requests_oauthlib-1.3.0+computecanada-py2.py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/importlib_metadata-4.10.1+computecanada-py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/zipp-3.7.0+computecanada-py3-none-any.whl
Requirement already satisfied: typing-extensions>=3.6.4 in /localscratch/yinan.29019358.0/env/lib/python3.7/site-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard<3,>=2.3.0->tensorflow_gpu==2.3.0+computecanada) (4.0.1+computecanada)
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/pyasn1-0.4.8+computecanada-py2.py3-none-any.whl
Requirement already satisfied: charset-normalizer~=2.0.0 in /localscratch/yinan.29019358.0/env/lib/python3.7/site-packages (from requests<3,>=2.21.0->tensorboard<3,>=2.3.0->tensorflow_gpu==2.3.0+computecanada) (2.0.12+computecanada)
Requirement already satisfied: idna<4,>=2.5 in /cvmfs/soft.computecanada.ca/easybuild/software/2017/Core/scipy-stack/2019a/lib/python3.7/site-packages (from requests<3,>=2.21.0->tensorboard<3,>=2.3.0->tensorflow_gpu==2.3.0+computecanada) (2.8)
Requirement already satisfied: urllib3<1.27,>=1.21.1 in /localscratch/yinan.29019358.0/env/lib/python3.7/site-packages (from requests<3,>=2.21.0->tensorboard<3,>=2.3.0->tensorflow_gpu==2.3.0+computecanada) (1.26.8+computecanada)
Requirement already satisfied: certifi>=2017.4.17 in /cvmfs/soft.computecanada.ca/easybuild/software/2017/Core/scipy-stack/2019a/lib/python3.7/site-packages (from requests<3,>=2.21.0->tensorboard<3,>=2.3.0->tensorflow_gpu==2.3.0+computecanada) (2018.11.29)
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/oauthlib-3.1.1+computecanada-py2.py3-none-any.whl
Installing collected packages: pyasn1, zipp, rsa, pyasn1-modules, oauthlib, cachetools, requests-oauthlib, importlib-metadata, google-auth, werkzeug, tensorboard-plugin-wit, tensorboard-data-server, markdown, grpcio, google-auth-oauthlib, absl-py, wrapt, tensorflow-estimator, tensorboard, scipy, opt-einsum, keras-preprocessing, h5py, google-pasta, gast, astunparse, tensorflow-gpu
  Attempting uninstall: pyasn1
    Found existing installation: pyasn1 0.4.3
    Not uninstalling pyasn1 at /cvmfs/soft.computecanada.ca/easybuild/software/2017/Core/scipy-stack/2019a/lib/python3.7/site-packages, outside environment /localscratch/yinan.29019358.0/env
    Can't uninstall 'pyasn1'. No files were found to uninstall.
  Attempting uninstall: zipp
    Found existing installation: zipp 0.3.3
    Not uninstalling zipp at /cvmfs/soft.computecanada.ca/easybuild/software/2017/Core/scipy-stack/2019a/lib/python3.7/site-packages, outside environment /localscratch/yinan.29019358.0/env
    Can't uninstall 'zipp'. No files were found to uninstall.
  Attempting uninstall: importlib-metadata
    Found existing installation: importlib-metadata 0.8
    Not uninstalling importlib-metadata at /cvmfs/soft.computecanada.ca/easybuild/software/2017/Core/scipy-stack/2019a/lib/python3.7/site-packages, outside environment /localscratch/yinan.29019358.0/env
    Can't uninstall 'importlib-metadata'. No files were found to uninstall.
  Attempting uninstall: scipy
    Found existing installation: scipy 1.2.0
    Not uninstalling scipy at /cvmfs/soft.computecanada.ca/easybuild/software/2017/Core/scipy-stack/2019a/lib/python3.7/site-packages, outside environment /localscratch/yinan.29019358.0/env
    Can't uninstall 'scipy'. No files were found to uninstall.
Successfully installed absl-py-1.0.0+computecanada astunparse-1.6.3+computecanada cachetools-4.2.4+computecanada gast-0.3.3+computecanada google-auth-2.3.3+computecanada google-auth-oauthlib-0.4.6+computecanada google-pasta-0.2.0+computecanada grpcio-1.38.0+computecanada h5py-2.10.0+computecanada importlib-metadata-4.10.1+computecanada keras-preprocessing-1.1.2+computecanada markdown-3.3.6+computecanada oauthlib-3.1.1+computecanada opt-einsum-3.3.0+computecanada pyasn1-0.4.8+computecanada pyasn1-modules-0.2.8+computecanada requests-oauthlib-1.3.0+computecanada rsa-4.8+computecanada scipy-1.4.1+computecanada tensorboard-2.8.0+computecanada tensorboard-data-server-0.6.1+computecanada tensorboard-plugin-wit-1.8.0+computecanada tensorflow-estimator-2.3.0+computecanada tensorflow-gpu-2.3.0+computecanada werkzeug-2.0.3+computecanada wrapt-1.11.2+computecanada zipp-3.7.0+computecanada
Looking in links: /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/nix/avx2, /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/nix/generic, /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/keras-2.8.0+computecanada-py2.py3-none-any.whl
Installing collected packages: Keras
Successfully installed Keras-2.8.0+computecanada
Looking in links: /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/nix/avx2, /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/nix/generic, /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/urllib3-1.26.7+computecanada-py2.py3-none-any.whl
Installing collected packages: urllib3
  Attempting uninstall: urllib3
    Found existing installation: urllib3 1.26.8+computecanada
    Uninstalling urllib3-1.26.8+computecanada:
      Successfully uninstalled urllib3-1.26.8+computecanada
Successfully installed urllib3-1.26.7+computecanada
Looking in links: /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/nix/avx2, /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/nix/generic, /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/nltk-3.7+computecanada-py3-none-any.whl
Requirement already satisfied: joblib in /localscratch/yinan.29019358.0/env/lib/python3.7/site-packages (from nltk) (1.1.0+computecanada)
Requirement already satisfied: click in /localscratch/yinan.29019358.0/env/lib/python3.7/site-packages (from nltk) (8.0.4+computecanada)
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/nltk-3.6.5+computecanada-py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/nltk-3.6.3+computecanada-py3-none-any.whl
Requirement already satisfied: tqdm in /localscratch/yinan.29019358.0/env/lib/python3.7/site-packages (from nltk) (4.63.0+computecanada)
Requirement already satisfied: regex in /localscratch/yinan.29019358.0/env/lib/python3.7/site-packages (from nltk) (2020.11.13+computecanada)
Requirement already satisfied: importlib-metadata in /localscratch/yinan.29019358.0/env/lib/python3.7/site-packages (from click->nltk) (4.10.1+computecanada)
Requirement already satisfied: typing-extensions>=3.6.4 in /localscratch/yinan.29019358.0/env/lib/python3.7/site-packages (from importlib-metadata->click->nltk) (4.0.1+computecanada)
Requirement already satisfied: zipp>=0.5 in /localscratch/yinan.29019358.0/env/lib/python3.7/site-packages (from importlib-metadata->click->nltk) (3.7.0+computecanada)
Installing collected packages: nltk
Successfully installed nltk-3.6.3+computecanada
Looking in links: /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/nix/avx2, /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/nix/generic, /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/scikit_learn-0.22.1+computecanada-cp37-cp37m-linux_x86_64.whl
Requirement already satisfied: numpy>=1.11.0 in /cvmfs/soft.computecanada.ca/easybuild/software/2017/Core/scipy-stack/2019a/lib/python3.7/site-packages (from scikit-learn==0.22.1) (1.16.0)
Requirement already satisfied: joblib>=0.11 in /localscratch/yinan.29019358.0/env/lib/python3.7/site-packages (from scikit-learn==0.22.1) (1.1.0+computecanada)
Requirement already satisfied: scipy>=0.17.0 in /localscratch/yinan.29019358.0/env/lib/python3.7/site-packages (from scikit-learn==0.22.1) (1.4.1+computecanada)
Installing collected packages: scikit-learn
Successfully installed scikit-learn-0.22.1+computecanada
Looking in links: /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/nix/avx2, /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/nix/generic, /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic
Requirement already satisfied: tokenizers==0.5.2 in /localscratch/yinan.29019358.0/env/lib/python3.7/site-packages (0.5.2+computecanada)
wandb: Appending key for api.wandb.ai to your netrc file: /home/yinan/.netrc
Starting Task
2022-03-17 22:13:32.411546: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1
[nltk_data] Downloading package stopwords to /home/yinan/nltk_data...
[nltk_data]   Package stopwords is already up-to-date!
[nltk_data] Downloading package wordnet to /home/yinan/nltk_data...
[nltk_data]   Package wordnet is already up-to-date!
wandb: Currently logged in as: yinanazhou (use `wandb login --relogin` to force relogin)
wandb: wandb version 0.12.11 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
2022-03-17 22:13:40.200976: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1
wandb: Tracking run with wandb version 0.12.5
wandb: Syncing run super-wood-2
wandb: ⭐️ View project at https://wandb.ai/yinanazhou/xl_512_bs_8_lr_1e06_es_10_lc_False_nr_False_sr_True_stem_False_lemma_False_repeat_1_fold_1
wandb: 🚀 View run at https://wandb.ai/yinanazhou/xl_512_bs_8_lr_1e06_es_10_lc_False_nr_False_sr_True_stem_False_lemma_False_repeat_1_fold_1/runs/vth02792
wandb: Run data is saved locally in /project/6002780/yinan/Thesis_MER_Lyrics/lyric-emotion/wandb/run-20220317_221338-vth02792
wandb: Run `wandb offline` to turn off syncing.

Validation loss decreased (inf --> 1.427634).  Saving model ...
Validation loss decreased (1.427634 --> 1.407890).  Saving model ...
Validation loss decreased (1.407890 --> 1.391092).  Saving model ...
Validation loss decreased (1.391092 --> 1.378354).  Saving model ...
Validation loss decreased (1.378354 --> 1.368354).  Saving model ...
Validation loss decreased (1.368354 --> 1.358864).  Saving model ...
Validation loss decreased (1.358864 --> 1.351233).  Saving model ...
Validation loss decreased (1.351233 --> 1.344785).  Saving model ...
Validation loss decreased (1.344785 --> 1.339057).  Saving model ...
Validation loss decreased (1.339057 --> 1.332830).  Saving model ...
Validation loss decreased (1.332830 --> 1.325896).  Saving model ...
Validation loss decreased (1.325896 --> 1.320483).  Saving model ...
Validation loss decreased (1.320483 --> 1.313196).  Saving model ...
Validation loss decreased (1.313196 --> 1.306760).  Saving model ...
Validation loss decreased (1.306760 --> 1.299403).  Saving model ...
Validation loss decreased (1.299403 --> 1.291941).  Saving model ...
Validation loss decreased (1.291941 --> 1.284379).  Saving model ...
Validation loss decreased (1.284379 --> 1.277515).  Saving model ...
Validation loss decreased (1.277515 --> 1.269098).  Saving model ...
Validation loss decreased (1.269098 --> 1.261555).  Saving model ...
Validation loss decreased (1.261555 --> 1.254810).  Saving model ...
Validation loss decreased (1.254810 --> 1.247065).  Saving model ...
Validation loss decreased (1.247065 --> 1.240767).  Saving model ...
Validation loss decreased (1.240767 --> 1.232513).  Saving model ...
Validation loss decreased (1.232513 --> 1.225693).  Saving model ...
Validation loss decreased (1.225693 --> 1.218072).  Saving model ...
Validation loss decreased (1.218072 --> 1.214171).  Saving model ...
Validation loss decreased (1.214171 --> 1.207632).  Saving model ...
Validation loss decreased (1.207632 --> 1.199322).  Saving model ...
Validation loss decreased (1.199322 --> 1.195482).  Saving model ...
Validation loss decreased (1.195482 --> 1.187913).  Saving model ...
Validation loss decreased (1.187913 --> 1.181648).  Saving model ...
Validation loss decreased (1.181648 --> 1.180704).  Saving model ...
Validation loss decreased (1.180704 --> 1.173219).  Saving model ...
Validation loss decreased (1.173219 --> 1.169318).  Saving model ...
Validation loss decreased (1.169318 --> 1.165172).  Saving model ...
Validation loss decreased (1.165172 --> 1.160725).  Saving model ...
Validation loss decreased (1.160725 --> 1.154045).  Saving model ...
Validation loss decreased (1.154045 --> 1.151521).  Saving model ...
Validation loss decreased (1.151521 --> 1.147711).  Saving model ...
Validation loss decreased (1.147711 --> 1.142857).  Saving model ...
Validation loss decreased (1.142857 --> 1.137463).  Saving model ...
Validation loss decreased (1.137463 --> 1.134584).  Saving model ...
Validation loss decreased (1.134584 --> 1.130979).  Saving model ...
Validation loss decreased (1.130979 --> 1.125704).  Saving model ...
Validation loss decreased (1.125704 --> 1.120424).  Saving model ...
Validation loss decreased (1.120424 --> 1.117576).  Saving model ...
Validation loss decreased (1.117576 --> 1.113193).  Saving model ...
Validation loss decreased (1.113193 --> 1.109162).  Saving model ...
Validation loss decreased (1.109162 --> 1.105871).  Saving model ...
Validation loss decreased (1.105871 --> 1.100484).  Saving model ...
Validation loss decreased (1.100484 --> 1.095978).  Saving model ...
Validation loss decreased (1.095978 --> 1.090830).  Saving model ...
Validation loss decreased (1.090830 --> 1.087201).  Saving model ...
Validation loss decreased (1.087201 --> 1.086079).  Saving model ...
Validation loss decreased (1.086079 --> 1.082679).  Saving model ...
Validation loss decreased (1.082679 --> 1.080545).  Saving model ...
Validation loss decreased (1.080545 --> 1.077914).  Saving model ...
Validation loss decreased (1.077914 --> 1.073281).  Saving model ...
Validation loss decreased (1.073281 --> 1.072754).  Saving model ...
Validation loss decreased (1.072754 --> 1.071195).  Saving model ...
Validation loss decreased (1.071195 --> 1.068948).  Saving model ...
Validation loss decreased (1.068948 --> 1.063747).  Saving model ...
Validation loss decreased (1.063747 --> 1.062170).  Saving model ...
Validation loss decreased (1.062170 --> 1.060296).  Saving model ...
Validation loss decreased (1.060296 --> 1.055550).  Saving model ...
Validation loss decreased (1.055550 --> 1.054609).  Saving model ...
Validation loss decreased (1.054609 --> 1.054045).  Saving model ...
Validation loss decreased (1.054045 --> 1.050805).  Saving model ...
Validation loss decreased (1.050805 --> 1.045988).  Saving model ...
Validation loss decreased (1.045988 --> 1.044792).  Saving model ...
Validation loss decreased (1.044792 --> 1.041103).  Saving model ...
Validation loss decreased (1.041103 --> 1.038043).  Saving model ...
Validation loss decreased (1.038043 --> 1.034067).  Saving model ...
Validation loss decreased (1.034067 --> 1.032766).  Saving model ...
Validation loss decreased (1.032766 --> 1.030950).  Saving model ...
EarlyStopping counter: 1 out of 10.0
Validation loss decreased (1.030950 --> 1.030262).  Saving model ...
Validation loss decreased (1.030262 --> 1.024752).  Saving model ...
EarlyStopping counter: 1 out of 10.0
Validation loss decreased (1.024752 --> 1.023614).  Saving model ...
Validation loss decreased (1.023614 --> 1.020147).  Saving model ...
Validation loss decreased (1.020147 --> 1.018712).  Saving model ...
Validation loss decreased (1.018712 --> 1.017526).  Saving model ...
Validation loss decreased (1.017526 --> 1.012715).  Saving model ...
Validation loss decreased (1.012715 --> 1.009871).  Saving model ...
Validation loss decreased (1.009871 --> 1.009408).  Saving model ...
EarlyStopping counter: 1 out of 10.0
EarlyStopping counter: 2 out of 10.0
Validation loss decreased (1.009408 --> 1.007126).  Saving model ...
Validation loss decreased (1.007126 --> 1.007018).  Saving model ...
Validation loss decreased (1.007018 --> 1.005920).  Saving model ...
Validation loss decreased (1.005920 --> 1.003522).  Saving model ...
EarlyStopping counter: 1 out of 10.0
EarlyStopping counter: 2 out of 10.0
Validation loss decreased (1.003522 --> 1.000777).  Saving model ...
Validation loss decreased (1.000777 --> 1.000668).  Saving model ...
Validation loss decreased (1.000668 --> 0.999832).  Saving model ...
Validation loss decreased (0.999832 --> 0.998146).  Saving model ...
EarlyStopping counter: 1 out of 10.0
Validation loss decreased (0.998146 --> 0.997942).  Saving model ...
EarlyStopping counter: 1 out of 10.0
Validation loss decreased (0.997942 --> 0.995829).  Saving model ...
EarlyStopping counter: 1 out of 10.0
EarlyStopping counter: 2 out of 10.0
Validation loss decreased (0.995829 --> 0.995735).  Saving model ...
Validation loss decreased (0.995735 --> 0.995070).  Saving model ...
Validation loss decreased (0.995070 --> 0.995024).  Saving model ...
Validation loss decreased (0.995024 --> 0.992044).  Saving model ...
Validation loss decreased (0.992044 --> 0.990643).  Saving model ...
EarlyStopping counter: 1 out of 10.0
EarlyStopping counter: 2 out of 10.0
EarlyStopping counter: 3 out of 10.0
EarlyStopping counter: 4 out of 10.0
EarlyStopping counter: 5 out of 10.0
Validation loss decreased (0.990643 --> 0.990496).  Saving model ...
Validation loss decreased (0.990496 --> 0.987455).  Saving model ...
Validation loss decreased (0.987455 --> 0.985767).  Saving model ...
Validation loss decreased (0.985767 --> 0.985737).  Saving model ...
Validation loss decreased (0.985737 --> 0.982931).  Saving model ...
EarlyStopping counter: 1 out of 10.0
EarlyStopping counter: 2 out of 10.0
EarlyStopping counter: 3 out of 10.0
EarlyStopping counter: 4 out of 10.0
EarlyStopping counter: 5 out of 10.0
EarlyStopping counter: 6 out of 10.0
EarlyStopping counter: 7 out of 10.0
EarlyStopping counter: 8 out of 10.0
EarlyStopping counter: 9 out of 10.0
EarlyStopping counter: 10 out of 10.0
/localscratch/yinan.29019358.0/env/lib/python3.7/site-packages/torch/nn/functional.py:1794: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.
  warnings.warn("nn.functional.tanh is deprecated. Use torch.tanh instead.")
/localscratch/yinan.29019358.0/env/lib/python3.7/site-packages/transformers/optimization.py:155: UserWarning: This overload of add_ is deprecated:
	add_(Number alpha, Tensor other)
Consider using one of the following signatures instead:
	add_(Tensor other, *, Number alpha) (Triggered internally at  ../torch/csrc/utils/python_arg_parser.cpp:1025.)
  exp_avg.mul_(beta1).add_(1.0 - beta1, grad)
wandb: Waiting for W&B process to finish, PID 188902... (success).
wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: \ 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: | 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: / 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: \ 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: | 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: / 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: \ 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: | 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: / 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb:                                                                                
wandb: Run history:
wandb:     e_F1 ▁▂▄▄▄▅▅▅▅▆▆▆▇▇▇▇▇▇▇▇▇▇▇▇▇▇█▇█▇██████████
wandb:   e_loss ██▇▇▆▆▆▅▅▅▄▄▄▃▃▃▃▃▂▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:     t_F1 ▁▁▂▂▃▄▄▄▄▅▅▆▅▅▅▆▆▆▆▇▆▆▇▆▇▇▇▇▇▇▇▇▇█▇█████
wandb:   t_loss ██▇▇▇▆▆▆▆▅▅▅▅▄▅▄▄▄▄▃▃▃▃▃▃▃▂▃▂▂▂▂▂▂▂▂▂▁▁▁
wandb: 
wandb: Run summary:
wandb:     e_F1 59.32306
wandb:   e_loss 0.98368
wandb:     t_F1 73.33824
wandb:   t_loss 0.71181
wandb: 
wandb: Synced 4 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Synced super-wood-2: https://wandb.ai/yinanazhou/xl_512_bs_8_lr_1e06_es_10_lc_False_nr_False_sr_True_stem_False_lemma_False_repeat_1_fold_1/runs/vth02792
wandb: Find logs at: ./wandb/run-20220317_221338-vth02792/logs/debug.log
wandb: 

wandb: wandb version 0.12.11 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
2022-03-17 23:39:16.274319: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1
wandb: Tracking run with wandb version 0.12.5
wandb: Syncing run absurd-galaxy-2
wandb: ⭐️ View project at https://wandb.ai/yinanazhou/xl_512_bs_8_lr_1e06_es_10_lc_False_nr_False_sr_True_stem_False_lemma_False_repeat_1_fold_2
wandb: 🚀 View run at https://wandb.ai/yinanazhou/xl_512_bs_8_lr_1e06_es_10_lc_False_nr_False_sr_True_stem_False_lemma_False_repeat_1_fold_2/runs/1pp9k96x
wandb: Run data is saved locally in /project/6002780/yinan/Thesis_MER_Lyrics/lyric-emotion/wandb/run-20220317_233914-1pp9k96x
wandb: Run `wandb offline` to turn off syncing.

Validation loss decreased (inf --> 1.413569).  Saving model ...
Validation loss decreased (1.413569 --> 1.401833).  Saving model ...
Validation loss decreased (1.401833 --> 1.393255).  Saving model ...
Validation loss decreased (1.393255 --> 1.386119).  Saving model ...
Validation loss decreased (1.386119 --> 1.381055).  Saving model ...
Validation loss decreased (1.381055 --> 1.376286).  Saving model ...
Validation loss decreased (1.376286 --> 1.372276).  Saving model ...
Validation loss decreased (1.372276 --> 1.367627).  Saving model ...
Validation loss decreased (1.367627 --> 1.363190).  Saving model ...
Validation loss decreased (1.363190 --> 1.359044).  Saving model ...
Validation loss decreased (1.359044 --> 1.353205).  Saving model ...
Validation loss decreased (1.353205 --> 1.347777).  Saving model ...
Validation loss decreased (1.347777 --> 1.342258).  Saving model ...
Validation loss decreased (1.342258 --> 1.337005).  Saving model ...
Validation loss decreased (1.337005 --> 1.331848).  Saving model ...
Validation loss decreased (1.331848 --> 1.324397).  Saving model ...
Validation loss decreased (1.324397 --> 1.317677).  Saving model ...
Validation loss decreased (1.317677 --> 1.311526).  Saving model ...
Validation loss decreased (1.311526 --> 1.304321).  Saving model ...
Validation loss decreased (1.304321 --> 1.297517).  Saving model ...
Validation loss decreased (1.297517 --> 1.290466).  Saving model ...
Validation loss decreased (1.290466 --> 1.281654).  Saving model ...
Validation loss decreased (1.281654 --> 1.275551).  Saving model ...
Validation loss decreased (1.275551 --> 1.269301).  Saving model ...
Validation loss decreased (1.269301 --> 1.261062).  Saving model ...
Validation loss decreased (1.261062 --> 1.252226).  Saving model ...
Validation loss decreased (1.252226 --> 1.245254).  Saving model ...
Validation loss decreased (1.245254 --> 1.237441).  Saving model ...
Validation loss decreased (1.237441 --> 1.228831).  Saving model ...
Validation loss decreased (1.228831 --> 1.220506).  Saving model ...
Validation loss decreased (1.220506 --> 1.212838).  Saving model ...
Validation loss decreased (1.212838 --> 1.205117).  Saving model ...
Validation loss decreased (1.205117 --> 1.198723).  Saving model ...
Validation loss decreased (1.198723 --> 1.190834).  Saving model ...
Validation loss decreased (1.190834 --> 1.183661).  Saving model ...
Validation loss decreased (1.183661 --> 1.174209).  Saving model ...
Validation loss decreased (1.174209 --> 1.165268).  Saving model ...
Validation loss decreased (1.165268 --> 1.157500).  Saving model ...
Validation loss decreased (1.157500 --> 1.150317).  Saving model ...
Validation loss decreased (1.150317 --> 1.144636).  Saving model ...
Validation loss decreased (1.144636 --> 1.139559).  Saving model ...
Validation loss decreased (1.139559 --> 1.133514).  Saving model ...
Validation loss decreased (1.133514 --> 1.126295).  Saving model ...
Validation loss decreased (1.126295 --> 1.119150).  Saving model ...
Validation loss decreased (1.119150 --> 1.113801).  Saving model ...
Validation loss decreased (1.113801 --> 1.107004).  Saving model ...
Validation loss decreased (1.107004 --> 1.100417).  Saving model ...
Validation loss decreased (1.100417 --> 1.094390).  Saving model ...
Validation loss decreased (1.094390 --> 1.089218).  Saving model ...
Validation loss decreased (1.089218 --> 1.084567).  Saving model ...
Validation loss decreased (1.084567 --> 1.078332).  Saving model ...
Validation loss decreased (1.078332 --> 1.072767).  Saving model ...
Validation loss decreased (1.072767 --> 1.066411).  Saving model ...
Validation loss decreased (1.066411 --> 1.061098).  Saving model ...
Validation loss decreased (1.061098 --> 1.055683).  Saving model ...
Validation loss decreased (1.055683 --> 1.052453).  Saving model ...
Validation loss decreased (1.052453 --> 1.047147).  Saving model ...
Validation loss decreased (1.047147 --> 1.043430).  Saving model ...
Validation loss decreased (1.043430 --> 1.040157).  Saving model ...
Validation loss decreased (1.040157 --> 1.033751).  Saving model ...
Validation loss decreased (1.033751 --> 1.029164).  Saving model ...
Validation loss decreased (1.029164 --> 1.026772).  Saving model ...
Validation loss decreased (1.026772 --> 1.023167).  Saving model ...
Validation loss decreased (1.023167 --> 1.019507).  Saving model ...
Validation loss decreased (1.019507 --> 1.014215).  Saving model ...
Validation loss decreased (1.014215 --> 1.011369).  Saving model ...
Validation loss decreased (1.011369 --> 1.007301).  Saving model ...
Validation loss decreased (1.007301 --> 1.003620).  Saving model ...
Validation loss decreased (1.003620 --> 0.999439).  Saving model ...
Validation loss decreased (0.999439 --> 0.995955).  Saving model ...
Validation loss decreased (0.995955 --> 0.992556).  Saving model ...
Validation loss decreased (0.992556 --> 0.988730).  Saving model ...
Validation loss decreased (0.988730 --> 0.987663).  Saving model ...
Validation loss decreased (0.987663 --> 0.984013).  Saving model ...
Validation loss decreased (0.984013 --> 0.981496).  Saving model ...
Validation loss decreased (0.981496 --> 0.979532).  Saving model ...
Validation loss decreased (0.979532 --> 0.976739).  Saving model ...
Validation loss decreased (0.976739 --> 0.973867).  Saving model ...
Validation loss decreased (0.973867 --> 0.972690).  Saving model ...
Validation loss decreased (0.972690 --> 0.970310).  Saving model ...
Validation loss decreased (0.970310 --> 0.968929).  Saving model ...
Validation loss decreased (0.968929 --> 0.966440).  Saving model ...
Validation loss decreased (0.966440 --> 0.964542).  Saving model ...
Validation loss decreased (0.964542 --> 0.962242).  Saving model ...
Validation loss decreased (0.962242 --> 0.960703).  Saving model ...
Validation loss decreased (0.960703 --> 0.957210).  Saving model ...
Validation loss decreased (0.957210 --> 0.956191).  Saving model ...
Validation loss decreased (0.956191 --> 0.953543).  Saving model ...
Validation loss decreased (0.953543 --> 0.952634).  Saving model ...
Validation loss decreased (0.952634 --> 0.951927).  Saving model ...
Validation loss decreased (0.951927 --> 0.951636).  Saving model ...
Validation loss decreased (0.951636 --> 0.950008).  Saving model ...
Validation loss decreased (0.950008 --> 0.948060).  Saving model ...
EarlyStopping counter: 1 out of 10.0
Validation loss decreased (0.948060 --> 0.948001).  Saving model ...
Validation loss decreased (0.948001 --> 0.944827).  Saving model ...
Validation loss decreased (0.944827 --> 0.944807).  Saving model ...
Validation loss decreased (0.944807 --> 0.944379).  Saving model ...
Validation loss decreased (0.944379 --> 0.942886).  Saving model ...
Validation loss decreased (0.942886 --> 0.942059).  Saving model ...
Validation loss decreased (0.942059 --> 0.941491).  Saving model ...
Validation loss decreased (0.941491 --> 0.939666).  Saving model ...
Validation loss decreased (0.939666 --> 0.936874).  Saving model ...
EarlyStopping counter: 1 out of 10.0
EarlyStopping counter: 2 out of 10.0
EarlyStopping counter: 3 out of 10.0
EarlyStopping counter: 4 out of 10.0
Validation loss decreased (0.936874 --> 0.934550).  Saving model ...
EarlyStopping counter: 1 out of 10.0
Validation loss decreased (0.934550 --> 0.932735).  Saving model ...
EarlyStopping counter: 1 out of 10.0
EarlyStopping counter: 2 out of 10.0
EarlyStopping counter: 3 out of 10.0
EarlyStopping counter: 4 out of 10.0
EarlyStopping counter: 5 out of 10.0
EarlyStopping counter: 6 out of 10.0
EarlyStopping counter: 7 out of 10.0
EarlyStopping counter: 8 out of 10.0
EarlyStopping counter: 9 out of 10.0
EarlyStopping counter: 10 out of 10.0
/localscratch/yinan.29019358.0/env/lib/python3.7/site-packages/torch/nn/functional.py:1794: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.
  warnings.warn("nn.functional.tanh is deprecated. Use torch.tanh instead.")
wandb: Waiting for W&B process to finish, PID 193520... (success).
wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: \ 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: | 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: / 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: \ 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: | 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: / 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: \ 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: | 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: / 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: \ 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: | 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: / 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: \ 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: | 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: / 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb:                                                                                
wandb: Run history:
wandb:     e_F1 ▁▂▂▃▄▄▄▅▅▅▆▆▆▆▇▇▇▇▇▇▇███████████████████
wandb:   e_loss ██▇▇▇▇▆▆▆▅▅▅▄▄▄▄▃▃▃▃▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:     t_F1 ▁▂▂▂▃▃▃▄▄▄▅▅▅▅▅▆▆▆▆▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇██████
wandb:   t_loss ██▇▇▇▇▇▇▆▆▆▆▅▅▅▅▅▄▄▄▄▃▃▃▃▃▃▃▃▂▂▂▂▂▂▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:     e_F1 60.79309
wandb:   e_loss 0.93495
wandb:     t_F1 72.13743
wandb:   t_loss 0.76656
wandb: 
wandb: Synced 4 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Synced absurd-galaxy-2: https://wandb.ai/yinanazhou/xl_512_bs_8_lr_1e06_es_10_lc_False_nr_False_sr_True_stem_False_lemma_False_repeat_1_fold_2/runs/1pp9k96x
wandb: Find logs at: ./wandb/run-20220317_233914-1pp9k96x/logs/debug.log
wandb: 

wandb: wandb version 0.12.11 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
2022-03-18 00:58:10.614485: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1
wandb: Tracking run with wandb version 0.12.5
wandb: Syncing run lyric-moon-2
wandb: ⭐️ View project at https://wandb.ai/yinanazhou/xl_512_bs_8_lr_1e06_es_10_lc_False_nr_False_sr_True_stem_False_lemma_False_repeat_2_fold_1
wandb: 🚀 View run at https://wandb.ai/yinanazhou/xl_512_bs_8_lr_1e06_es_10_lc_False_nr_False_sr_True_stem_False_lemma_False_repeat_2_fold_1/runs/da7phrfs
wandb: Run data is saved locally in /project/6002780/yinan/Thesis_MER_Lyrics/lyric-emotion/wandb/run-20220318_005808-da7phrfs
wandb: Run `wandb offline` to turn off syncing.

Validation loss decreased (inf --> 1.408283).  Saving model ...
Validation loss decreased (1.408283 --> 1.402041).  Saving model ...
Validation loss decreased (1.402041 --> 1.396152).  Saving model ...
Validation loss decreased (1.396152 --> 1.390954).  Saving model ...
Validation loss decreased (1.390954 --> 1.386283).  Saving model ...
Validation loss decreased (1.386283 --> 1.382077).  Saving model ...
Validation loss decreased (1.382077 --> 1.377954).  Saving model ...
Validation loss decreased (1.377954 --> 1.373883).  Saving model ...
Validation loss decreased (1.373883 --> 1.369580).  Saving model ...
Validation loss decreased (1.369580 --> 1.365212).  Saving model ...
Validation loss decreased (1.365212 --> 1.360481).  Saving model ...
Validation loss decreased (1.360481 --> 1.356747).  Saving model ...
Validation loss decreased (1.356747 --> 1.352388).  Saving model ...
Validation loss decreased (1.352388 --> 1.348042).  Saving model ...
Validation loss decreased (1.348042 --> 1.343342).  Saving model ...
Validation loss decreased (1.343342 --> 1.338602).  Saving model ...
Validation loss decreased (1.338602 --> 1.334051).  Saving model ...
Validation loss decreased (1.334051 --> 1.328901).  Saving model ...
Validation loss decreased (1.328901 --> 1.323298).  Saving model ...
Validation loss decreased (1.323298 --> 1.317808).  Saving model ...
Validation loss decreased (1.317808 --> 1.312200).  Saving model ...
Validation loss decreased (1.312200 --> 1.306157).  Saving model ...
Validation loss decreased (1.306157 --> 1.299751).  Saving model ...
Validation loss decreased (1.299751 --> 1.291750).  Saving model ...
Validation loss decreased (1.291750 --> 1.283583).  Saving model ...
Validation loss decreased (1.283583 --> 1.276229).  Saving model ...
Validation loss decreased (1.276229 --> 1.266326).  Saving model ...
Validation loss decreased (1.266326 --> 1.257795).  Saving model ...
Validation loss decreased (1.257795 --> 1.248378).  Saving model ...
Validation loss decreased (1.248378 --> 1.240353).  Saving model ...
Validation loss decreased (1.240353 --> 1.232378).  Saving model ...
Validation loss decreased (1.232378 --> 1.223408).  Saving model ...
Validation loss decreased (1.223408 --> 1.215322).  Saving model ...
Validation loss decreased (1.215322 --> 1.207225).  Saving model ...
Validation loss decreased (1.207225 --> 1.200888).  Saving model ...
Validation loss decreased (1.200888 --> 1.193912).  Saving model ...
Validation loss decreased (1.193912 --> 1.186299).  Saving model ...
Validation loss decreased (1.186299 --> 1.179595).  Saving model ...
Validation loss decreased (1.179595 --> 1.172463).  Saving model ...
Validation loss decreased (1.172463 --> 1.165826).  Saving model ...
Validation loss decreased (1.165826 --> 1.159700).  Saving model ...
Validation loss decreased (1.159700 --> 1.152453).  Saving model ...
Validation loss decreased (1.152453 --> 1.146115).  Saving model ...
Validation loss decreased (1.146115 --> 1.140151).  Saving model ...
Validation loss decreased (1.140151 --> 1.134836).  Saving model ...
Validation loss decreased (1.134836 --> 1.128820).  Saving model ...
Validation loss decreased (1.128820 --> 1.122806).  Saving model ...
Validation loss decreased (1.122806 --> 1.117790).  Saving model ...
Validation loss decreased (1.117790 --> 1.113088).  Saving model ...
Validation loss decreased (1.113088 --> 1.106931).  Saving model ...
Validation loss decreased (1.106931 --> 1.100363).  Saving model ...
Validation loss decreased (1.100363 --> 1.096898).  Saving model ...
Validation loss decreased (1.096898 --> 1.090212).  Saving model ...
Validation loss decreased (1.090212 --> 1.085327).  Saving model ...
Validation loss decreased (1.085327 --> 1.080344).  Saving model ...
Validation loss decreased (1.080344 --> 1.075560).  Saving model ...
Validation loss decreased (1.075560 --> 1.071238).  Saving model ...
Validation loss decreased (1.071238 --> 1.064740).  Saving model ...
Validation loss decreased (1.064740 --> 1.060083).  Saving model ...
Validation loss decreased (1.060083 --> 1.055154).  Saving model ...
Validation loss decreased (1.055154 --> 1.050266).  Saving model ...
Validation loss decreased (1.050266 --> 1.045173).  Saving model ...
Validation loss decreased (1.045173 --> 1.040305).  Saving model ...
Validation loss decreased (1.040305 --> 1.036807).  Saving model ...
Validation loss decreased (1.036807 --> 1.032361).  Saving model ...
Validation loss decreased (1.032361 --> 1.027276).  Saving model ...
Validation loss decreased (1.027276 --> 1.023887).  Saving model ...
Validation loss decreased (1.023887 --> 1.021313).  Saving model ...
Validation loss decreased (1.021313 --> 1.017892).  Saving model ...
Validation loss decreased (1.017892 --> 1.014446).  Saving model ...
Validation loss decreased (1.014446 --> 1.012195).  Saving model ...
Validation loss decreased (1.012195 --> 1.007821).  Saving model ...
Validation loss decreased (1.007821 --> 1.004187).  Saving model ...
Validation loss decreased (1.004187 --> 1.001999).  Saving model ...
Validation loss decreased (1.001999 --> 0.999217).  Saving model ...
Validation loss decreased (0.999217 --> 0.996382).  Saving model ...
Validation loss decreased (0.996382 --> 0.994205).  Saving model ...
Validation loss decreased (0.994205 --> 0.991081).  Saving model ...
Validation loss decreased (0.991081 --> 0.987389).  Saving model ...
Validation loss decreased (0.987389 --> 0.983998).  Saving model ...
Validation loss decreased (0.983998 --> 0.980828).  Saving model ...
Validation loss decreased (0.980828 --> 0.977886).  Saving model ...
Validation loss decreased (0.977886 --> 0.976315).  Saving model ...
Validation loss decreased (0.976315 --> 0.974053).  Saving model ...
Validation loss decreased (0.974053 --> 0.971577).  Saving model ...
Validation loss decreased (0.971577 --> 0.969369).  Saving model ...
Validation loss decreased (0.969369 --> 0.966682).  Saving model ...
Validation loss decreased (0.966682 --> 0.963428).  Saving model ...
Validation loss decreased (0.963428 --> 0.963099).  Saving model ...
Validation loss decreased (0.963099 --> 0.960898).  Saving model ...
Validation loss decreased (0.960898 --> 0.957291).  Saving model ...
Validation loss decreased (0.957291 --> 0.955549).  Saving model ...
Validation loss decreased (0.955549 --> 0.954331).  Saving model ...
Validation loss decreased (0.954331 --> 0.953352).  Saving model ...
Validation loss decreased (0.953352 --> 0.951497).  Saving model ...
Validation loss decreased (0.951497 --> 0.948727).  Saving model ...
Validation loss decreased (0.948727 --> 0.947691).  Saving model ...
Validation loss decreased (0.947691 --> 0.947368).  Saving model ...
Validation loss decreased (0.947368 --> 0.946785).  Saving model ...
Validation loss decreased (0.946785 --> 0.946167).  Saving model ...
Validation loss decreased (0.946167 --> 0.944591).  Saving model ...
Validation loss decreased (0.944591 --> 0.942869).  Saving model ...
Validation loss decreased (0.942869 --> 0.941374).  Saving model ...
Validation loss decreased (0.941374 --> 0.940099).  Saving model ...
Validation loss decreased (0.940099 --> 0.938907).  Saving model ...
Validation loss decreased (0.938907 --> 0.938751).  Saving model ...
Validation loss decreased (0.938751 --> 0.938616).  Saving model ...
Validation loss decreased (0.938616 --> 0.937481).  Saving model ...
Validation loss decreased (0.937481 --> 0.936303).  Saving model ...
Validation loss decreased (0.936303 --> 0.935659).  Saving model ...
Validation loss decreased (0.935659 --> 0.934685).  Saving model ...
Validation loss decreased (0.934685 --> 0.934247).  Saving model ...
Validation loss decreased (0.934247 --> 0.933126).  Saving model ...
EarlyStopping counter: 1 out of 10.0
EarlyStopping counter: 2 out of 10.0
Validation loss decreased (0.933126 --> 0.932747).  Saving model ...
EarlyStopping counter: 1 out of 10.0
EarlyStopping counter: 2 out of 10.0
EarlyStopping counter: 3 out of 10.0
EarlyStopping counter: 4 out of 10.0
Validation loss decreased (0.932747 --> 0.932717).  Saving model ...
EarlyStopping counter: 1 out of 10.0
EarlyStopping counter: 2 out of 10.0
Validation loss decreased (0.932717 --> 0.931578).  Saving model ...
Validation loss decreased (0.931578 --> 0.930853).  Saving model ...
Validation loss decreased (0.930853 --> 0.930149).  Saving model ...
Validation loss decreased (0.930149 --> 0.928578).  Saving model ...
EarlyStopping counter: 1 out of 10.0
EarlyStopping counter: 2 out of 10.0
EarlyStopping counter: 3 out of 10.0
EarlyStopping counter: 4 out of 10.0
EarlyStopping counter: 5 out of 10.0
EarlyStopping counter: 6 out of 10.0
EarlyStopping counter: 7 out of 10.0
EarlyStopping counter: 8 out of 10.0
EarlyStopping counter: 9 out of 10.0
EarlyStopping counter: 10 out of 10.0
/localscratch/yinan.29019358.0/env/lib/python3.7/site-packages/torch/nn/functional.py:1794: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.
  warnings.warn("nn.functional.tanh is deprecated. Use torch.tanh instead.")
wandb: Waiting for W&B process to finish, PID 197784... (success).
wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: \ 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: | 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: / 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: \ 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: | 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: / 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: \ 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: | 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: / 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb:                                                                                
wandb: Run history:
wandb:     e_F1 ▁▂▃▄▄▄▅▅▅▆▆▆▆▆▆▆▇▇▇▇▇▇▇▇▇███████████████
wandb:   e_loss ███▇▇▇▇▆▆▅▅▅▄▄▄▃▃▃▃▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:     t_F1 ▁▁▁▂▂▂▂▃▄▄▄▄▅▅▅▆▅▆▆▆▆▆▇▇▆▇▇▇▇▇▇▇████▇███
wandb:   t_loss ████▇▇▇▇▇▆▆▆▆▅▅▅▅▄▄▄▄▃▃▃▃▃▂▃▂▂▂▂▂▁▂▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:     e_F1 59.54388
wandb:   e_loss 0.93192
wandb:     t_F1 72.50461
wandb:   t_loss 0.72859
wandb: 
wandb: Synced 4 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Synced lyric-moon-2: https://wandb.ai/yinanazhou/xl_512_bs_8_lr_1e06_es_10_lc_False_nr_False_sr_True_stem_False_lemma_False_repeat_2_fold_1/runs/da7phrfs
wandb: Find logs at: ./wandb/run-20220318_005808-da7phrfs/logs/debug.log
wandb: 

wandb: wandb version 0.12.11 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
2022-03-18 02:28:20.946746: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1
wandb: Tracking run with wandb version 0.12.5
wandb: Syncing run fanciful-universe-2
wandb: ⭐️ View project at https://wandb.ai/yinanazhou/xl_512_bs_8_lr_1e06_es_10_lc_False_nr_False_sr_True_stem_False_lemma_False_repeat_2_fold_2
wandb: 🚀 View run at https://wandb.ai/yinanazhou/xl_512_bs_8_lr_1e06_es_10_lc_False_nr_False_sr_True_stem_False_lemma_False_repeat_2_fold_2/runs/1b4goxqo
wandb: Run data is saved locally in /project/6002780/yinan/Thesis_MER_Lyrics/lyric-emotion/wandb/run-20220318_022818-1b4goxqo
wandb: Run `wandb offline` to turn off syncing.

Validation loss decreased (inf --> 1.375726).  Saving model ...
Validation loss decreased (1.375726 --> 1.369907).  Saving model ...
Validation loss decreased (1.369907 --> 1.364314).  Saving model ...
Validation loss decreased (1.364314 --> 1.359036).  Saving model ...
Validation loss decreased (1.359036 --> 1.354068).  Saving model ...
Validation loss decreased (1.354068 --> 1.348815).  Saving model ...
Validation loss decreased (1.348815 --> 1.344475).  Saving model ...
Validation loss decreased (1.344475 --> 1.340139).  Saving model ...
Validation loss decreased (1.340139 --> 1.335787).  Saving model ...
Validation loss decreased (1.335787 --> 1.330867).  Saving model ...
Validation loss decreased (1.330867 --> 1.325435).  Saving model ...
Validation loss decreased (1.325435 --> 1.319828).  Saving model ...
Validation loss decreased (1.319828 --> 1.314639).  Saving model ...
Validation loss decreased (1.314639 --> 1.309243).  Saving model ...
Validation loss decreased (1.309243 --> 1.302646).  Saving model ...
Validation loss decreased (1.302646 --> 1.296028).  Saving model ...
Validation loss decreased (1.296028 --> 1.289293).  Saving model ...
Validation loss decreased (1.289293 --> 1.282077).  Saving model ...
Validation loss decreased (1.282077 --> 1.275119).  Saving model ...
Validation loss decreased (1.275119 --> 1.268165).  Saving model ...
Validation loss decreased (1.268165 --> 1.259967).  Saving model ...
Validation loss decreased (1.259967 --> 1.251447).  Saving model ...
Validation loss decreased (1.251447 --> 1.242933).  Saving model ...
Validation loss decreased (1.242933 --> 1.233722).  Saving model ...
Validation loss decreased (1.233722 --> 1.224184).  Saving model ...
Validation loss decreased (1.224184 --> 1.214719).  Saving model ...
Validation loss decreased (1.214719 --> 1.204941).  Saving model ...
Validation loss decreased (1.204941 --> 1.194191).  Saving model ...
Validation loss decreased (1.194191 --> 1.187068).  Saving model ...
Validation loss decreased (1.187068 --> 1.177680).  Saving model ...
Validation loss decreased (1.177680 --> 1.169743).  Saving model ...
Validation loss decreased (1.169743 --> 1.161265).  Saving model ...
Validation loss decreased (1.161265 --> 1.154099).  Saving model ...
Validation loss decreased (1.154099 --> 1.148583).  Saving model ...
Validation loss decreased (1.148583 --> 1.142985).  Saving model ...
Validation loss decreased (1.142985 --> 1.138416).  Saving model ...
Validation loss decreased (1.138416 --> 1.132340).  Saving model ...
Validation loss decreased (1.132340 --> 1.126392).  Saving model ...
Validation loss decreased (1.126392 --> 1.119597).  Saving model ...
Validation loss decreased (1.119597 --> 1.112506).  Saving model ...
Validation loss decreased (1.112506 --> 1.106613).  Saving model ...
Validation loss decreased (1.106613 --> 1.103053).  Saving model ...
Validation loss decreased (1.103053 --> 1.097845).  Saving model ...
Validation loss decreased (1.097845 --> 1.091216).  Saving model ...
Validation loss decreased (1.091216 --> 1.086562).  Saving model ...
Validation loss decreased (1.086562 --> 1.083317).  Saving model ...
Validation loss decreased (1.083317 --> 1.077292).  Saving model ...
Validation loss decreased (1.077292 --> 1.072981).  Saving model ...
Validation loss decreased (1.072981 --> 1.068396).  Saving model ...
Validation loss decreased (1.068396 --> 1.062108).  Saving model ...
Validation loss decreased (1.062108 --> 1.057683).  Saving model ...
Validation loss decreased (1.057683 --> 1.054986).  Saving model ...
Validation loss decreased (1.054986 --> 1.051121).  Saving model ...
Validation loss decreased (1.051121 --> 1.046286).  Saving model ...
Validation loss decreased (1.046286 --> 1.043704).  Saving model ...
Validation loss decreased (1.043704 --> 1.039199).  Saving model ...
Validation loss decreased (1.039199 --> 1.038631).  Saving model ...
Validation loss decreased (1.038631 --> 1.033468).  Saving model ...
Validation loss decreased (1.033468 --> 1.029284).  Saving model ...
Validation loss decreased (1.029284 --> 1.023606).  Saving model ...
Validation loss decreased (1.023606 --> 1.019564).  Saving model ...
Validation loss decreased (1.019564 --> 1.018270).  Saving model ...
Validation loss decreased (1.018270 --> 1.016344).  Saving model ...
Validation loss decreased (1.016344 --> 1.014734).  Saving model ...
Validation loss decreased (1.014734 --> 1.007892).  Saving model ...
Validation loss decreased (1.007892 --> 1.005417).  Saving model ...
Validation loss decreased (1.005417 --> 1.001288).  Saving model ...
Validation loss decreased (1.001288 --> 0.994571).  Saving model ...
Validation loss decreased (0.994571 --> 0.992162).  Saving model ...
Validation loss decreased (0.992162 --> 0.989063).  Saving model ...
Validation loss decreased (0.989063 --> 0.988586).  Saving model ...
Validation loss decreased (0.988586 --> 0.985208).  Saving model ...
EarlyStopping counter: 1 out of 10.0
Validation loss decreased (0.985208 --> 0.982021).  Saving model ...
Validation loss decreased (0.982021 --> 0.978359).  Saving model ...
Validation loss decreased (0.978359 --> 0.975753).  Saving model ...
Validation loss decreased (0.975753 --> 0.974649).  Saving model ...
Validation loss decreased (0.974649 --> 0.970550).  Saving model ...
Validation loss decreased (0.970550 --> 0.968155).  Saving model ...
Validation loss decreased (0.968155 --> 0.966638).  Saving model ...
Validation loss decreased (0.966638 --> 0.963453).  Saving model ...
Validation loss decreased (0.963453 --> 0.960710).  Saving model ...
Validation loss decreased (0.960710 --> 0.955903).  Saving model ...
Validation loss decreased (0.955903 --> 0.953958).  Saving model ...
Validation loss decreased (0.953958 --> 0.953021).  Saving model ...
Validation loss decreased (0.953021 --> 0.952416).  Saving model ...
Validation loss decreased (0.952416 --> 0.949774).  Saving model ...
Validation loss decreased (0.949774 --> 0.948766).  Saving model ...
Validation loss decreased (0.948766 --> 0.947516).  Saving model ...
Validation loss decreased (0.947516 --> 0.944048).  Saving model ...
Validation loss decreased (0.944048 --> 0.942173).  Saving model ...
Validation loss decreased (0.942173 --> 0.941440).  Saving model ...
Validation loss decreased (0.941440 --> 0.939686).  Saving model ...
Validation loss decreased (0.939686 --> 0.938306).  Saving model ...
Validation loss decreased (0.938306 --> 0.936092).  Saving model ...
Validation loss decreased (0.936092 --> 0.934405).  Saving model ...
Validation loss decreased (0.934405 --> 0.933504).  Saving model ...
Validation loss decreased (0.933504 --> 0.933012).  Saving model ...
EarlyStopping counter: 1 out of 10.0
Validation loss decreased (0.933012 --> 0.931091).  Saving model ...
Validation loss decreased (0.931091 --> 0.930488).  Saving model ...
EarlyStopping counter: 1 out of 10.0
Validation loss decreased (0.930488 --> 0.929115).  Saving model ...
Validation loss decreased (0.929115 --> 0.927300).  Saving model ...
Validation loss decreased (0.927300 --> 0.922959).  Saving model ...
Validation loss decreased (0.922959 --> 0.921981).  Saving model ...
Validation loss decreased (0.921981 --> 0.921555).  Saving model ...
Validation loss decreased (0.921555 --> 0.921027).  Saving model ...
Validation loss decreased (0.921027 --> 0.919206).  Saving model ...
Validation loss decreased (0.919206 --> 0.919076).  Saving model ...
EarlyStopping counter: 1 out of 10.0
EarlyStopping counter: 2 out of 10.0
Validation loss decreased (0.919076 --> 0.917245).  Saving model ...
Validation loss decreased (0.917245 --> 0.916583).  Saving model ...
Validation loss decreased (0.916583 --> 0.915274).  Saving model ...
EarlyStopping counter: 1 out of 10.0
Validation loss decreased (0.915274 --> 0.914866).  Saving model ...
EarlyStopping counter: 1 out of 10.0
Validation loss decreased (0.914866 --> 0.914545).  Saving model ...
Validation loss decreased (0.914545 --> 0.914469).  Saving model ...
EarlyStopping counter: 1 out of 10.0
Validation loss decreased (0.914469 --> 0.912975).  Saving model ...
Validation loss decreased (0.912975 --> 0.912129).  Saving model ...
Validation loss decreased (0.912129 --> 0.911739).  Saving model ...
Validation loss decreased (0.911739 --> 0.911204).  Saving model ...
Validation loss decreased (0.911204 --> 0.910491).  Saving model ...
EarlyStopping counter: 1 out of 10.0
Validation loss decreased (0.910491 --> 0.910469).  Saving model ...
EarlyStopping counter: 1 out of 10.0
EarlyStopping counter: 2 out of 10.0
EarlyStopping counter: 3 out of 10.0
EarlyStopping counter: 4 out of 10.0
EarlyStopping counter: 5 out of 10.0
EarlyStopping counter: 6 out of 10.0
EarlyStopping counter: 7 out of 10.0
EarlyStopping counter: 8 out of 10.0
EarlyStopping counter: 9 out of 10.0
Validation loss decreased (0.910469 --> 0.909884).  Saving model ...
Validation loss decreased (0.909884 --> 0.909823).  Saving model ...
EarlyStopping counter: 1 out of 10.0
EarlyStopping counter: 2 out of 10.0
EarlyStopping counter: 3 out of 10.0
Validation loss decreased (0.909823 --> 0.909626).  Saving model ...
EarlyStopping counter: 1 out of 10.0
EarlyStopping counter: 2 out of 10.0
EarlyStopping counter: 3 out of 10.0
EarlyStopping counter: 4 out of 10.0
EarlyStopping counter: 5 out of 10.0
EarlyStopping counter: 6 out of 10.0
EarlyStopping counter: 7 out of 10.0
EarlyStopping counter: 8 out of 10.0
EarlyStopping counter: 9 out of 10.0
EarlyStopping counter: 10 out of 10.0
/localscratch/yinan.29019358.0/env/lib/python3.7/site-packages/torch/nn/functional.py:1794: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.
  warnings.warn("nn.functional.tanh is deprecated. Use torch.tanh instead.")
wandb: Waiting for W&B process to finish, PID 202735... (success).
wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: \ 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: | 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: / 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: \ 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: | 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: / 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: \ 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: | 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: / 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb:                                                                                
wandb: Run history:
wandb:     e_F1 ▁▃▃▃▄▄▄▅▆▆▆▆▆▆▆▆▇▇▇▇▇▇▇▇▇▇▇▇████████████
wandb:   e_loss ███▇▇▆▆▅▅▄▄▄▃▃▃▃▃▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:     t_F1 ▁▁▂▃▃▄▄▄▄▅▅▅▅▆▅▆▆▆▆▆▆▆▆▇▇▇▇▇▇▇█▇▇████▇██
wandb:   t_loss ███▇▇▇▇▆▆▆▅▅▅▅▅▄▄▄▄▄▃▃▃▃▃▃▂▂▂▂▂▂▂▂▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:     e_F1 63.24082
wandb:   e_loss 0.91348
wandb:     t_F1 72.66688
wandb:   t_loss 0.68902
wandb: 
wandb: Synced 4 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Synced fanciful-universe-2: https://wandb.ai/yinanazhou/xl_512_bs_8_lr_1e06_es_10_lc_False_nr_False_sr_True_stem_False_lemma_False_repeat_2_fold_2/runs/1b4goxqo
wandb: Find logs at: ./wandb/run-20220318_022818-1b4goxqo/logs/debug.log
wandb: 

wandb: wandb version 0.12.11 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
2022-03-18 04:05:01.259620: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1
wandb: Tracking run with wandb version 0.12.5
wandb: Syncing run fiery-elevator-2
wandb: ⭐️ View project at https://wandb.ai/yinanazhou/xl_512_bs_8_lr_1e06_es_10_lc_False_nr_False_sr_True_stem_False_lemma_False_repeat_3_fold_1
wandb: 🚀 View run at https://wandb.ai/yinanazhou/xl_512_bs_8_lr_1e06_es_10_lc_False_nr_False_sr_True_stem_False_lemma_False_repeat_3_fold_1/runs/2ei9dces
wandb: Run data is saved locally in /project/6002780/yinan/Thesis_MER_Lyrics/lyric-emotion/wandb/run-20220318_040458-2ei9dces
wandb: Run `wandb offline` to turn off syncing.

Validation loss decreased (inf --> 1.462394).  Saving model ...
Validation loss decreased (1.462394 --> 1.433594).  Saving model ...
Validation loss decreased (1.433594 --> 1.413144).  Saving model ...
Validation loss decreased (1.413144 --> 1.398980).  Saving model ...
Validation loss decreased (1.398980 --> 1.388625).  Saving model ...
Validation loss decreased (1.388625 --> 1.380696).  Saving model ...
Validation loss decreased (1.380696 --> 1.374106).  Saving model ...
Validation loss decreased (1.374106 --> 1.368290).  Saving model ...
Validation loss decreased (1.368290 --> 1.362086).  Saving model ...
Validation loss decreased (1.362086 --> 1.355777).  Saving model ...
Validation loss decreased (1.355777 --> 1.349739).  Saving model ...
Validation loss decreased (1.349739 --> 1.343518).  Saving model ...
Validation loss decreased (1.343518 --> 1.337547).  Saving model ...
Validation loss decreased (1.337547 --> 1.330561).  Saving model ...
Validation loss decreased (1.330561 --> 1.322266).  Saving model ...
Validation loss decreased (1.322266 --> 1.313466).  Saving model ...
Validation loss decreased (1.313466 --> 1.305342).  Saving model ...
Validation loss decreased (1.305342 --> 1.297527).  Saving model ...
Validation loss decreased (1.297527 --> 1.288995).  Saving model ...
Validation loss decreased (1.288995 --> 1.279695).  Saving model ...
Validation loss decreased (1.279695 --> 1.271971).  Saving model ...
Validation loss decreased (1.271971 --> 1.263337).  Saving model ...
Validation loss decreased (1.263337 --> 1.255688).  Saving model ...
Validation loss decreased (1.255688 --> 1.247268).  Saving model ...
Validation loss decreased (1.247268 --> 1.239871).  Saving model ...
Validation loss decreased (1.239871 --> 1.231063).  Saving model ...
Validation loss decreased (1.231063 --> 1.223081).  Saving model ...
Validation loss decreased (1.223081 --> 1.215902).  Saving model ...
Validation loss decreased (1.215902 --> 1.209862).  Saving model ...
Validation loss decreased (1.209862 --> 1.201395).  Saving model ...
Validation loss decreased (1.201395 --> 1.195415).  Saving model ...
Validation loss decreased (1.195415 --> 1.188481).  Saving model ...
Validation loss decreased (1.188481 --> 1.181599).  Saving model ...
Validation loss decreased (1.181599 --> 1.175935).  Saving model ...
Validation loss decreased (1.175935 --> 1.170795).  Saving model ...
Validation loss decreased (1.170795 --> 1.163486).  Saving model ...
Validation loss decreased (1.163486 --> 1.157314).  Saving model ...
Validation loss decreased (1.157314 --> 1.150282).  Saving model ...
Validation loss decreased (1.150282 --> 1.142738).  Saving model ...
Validation loss decreased (1.142738 --> 1.138453).  Saving model ...
Validation loss decreased (1.138453 --> 1.131407).  Saving model ...
Validation loss decreased (1.131407 --> 1.126190).  Saving model ...
Validation loss decreased (1.126190 --> 1.122124).  Saving model ...
Validation loss decreased (1.122124 --> 1.115998).  Saving model ...
Validation loss decreased (1.115998 --> 1.109041).  Saving model ...
Validation loss decreased (1.109041 --> 1.104922).  Saving model ...
Validation loss decreased (1.104922 --> 1.099269).  Saving model ...
Validation loss decreased (1.099269 --> 1.095444).  Saving model ...
Validation loss decreased (1.095444 --> 1.087746).  Saving model ...
Validation loss decreased (1.087746 --> 1.082995).  Saving model ...
Validation loss decreased (1.082995 --> 1.081852).  Saving model ...
Validation loss decreased (1.081852 --> 1.077668).  Saving model ...
Validation loss decreased (1.077668 --> 1.070661).  Saving model ...
Validation loss decreased (1.070661 --> 1.065104).  Saving model ...
Validation loss decreased (1.065104 --> 1.057578).  Saving model ...
Validation loss decreased (1.057578 --> 1.053869).  Saving model ...
Validation loss decreased (1.053869 --> 1.050717).  Saving model ...
Validation loss decreased (1.050717 --> 1.047942).  Saving model ...
Validation loss decreased (1.047942 --> 1.043705).  Saving model ...
Validation loss decreased (1.043705 --> 1.037454).  Saving model ...
Validation loss decreased (1.037454 --> 1.035722).  Saving model ...
Validation loss decreased (1.035722 --> 1.032754).  Saving model ...
Validation loss decreased (1.032754 --> 1.029007).  Saving model ...
Validation loss decreased (1.029007 --> 1.026182).  Saving model ...
Validation loss decreased (1.026182 --> 1.019373).  Saving model ...
Validation loss decreased (1.019373 --> 1.016657).  Saving model ...
Validation loss decreased (1.016657 --> 1.014403).  Saving model ...
Validation loss decreased (1.014403 --> 1.010854).  Saving model ...
Validation loss decreased (1.010854 --> 1.007423).  Saving model ...
EarlyStopping counter: 1 out of 10.0
Validation loss decreased (1.007423 --> 1.004122).  Saving model ...
Validation loss decreased (1.004122 --> 1.003749).  Saving model ...
Validation loss decreased (1.003749 --> 0.998780).  Saving model ...
Validation loss decreased (0.998780 --> 0.995604).  Saving model ...
Validation loss decreased (0.995604 --> 0.994643).  Saving model ...
Validation loss decreased (0.994643 --> 0.990297).  Saving model ...
Validation loss decreased (0.990297 --> 0.987036).  Saving model ...
Validation loss decreased (0.987036 --> 0.985424).  Saving model ...
Validation loss decreased (0.985424 --> 0.982934).  Saving model ...
Validation loss decreased (0.982934 --> 0.981082).  Saving model ...
Validation loss decreased (0.981082 --> 0.979351).  Saving model ...
EarlyStopping counter: 1 out of 10.0
Validation loss decreased (0.979351 --> 0.978325).  Saving model ...
Validation loss decreased (0.978325 --> 0.977238).  Saving model ...
Validation loss decreased (0.977238 --> 0.973652).  Saving model ...
EarlyStopping counter: 1 out of 10.0
EarlyStopping counter: 2 out of 10.0
Validation loss decreased (0.973652 --> 0.967988).  Saving model ...
Validation loss decreased (0.967988 --> 0.967579).  Saving model ...
Validation loss decreased (0.967579 --> 0.966916).  Saving model ...
EarlyStopping counter: 1 out of 10.0
Validation loss decreased (0.966916 --> 0.966860).  Saving model ...
Validation loss decreased (0.966860 --> 0.963278).  Saving model ...
Validation loss decreased (0.963278 --> 0.962391).  Saving model ...
Validation loss decreased (0.962391 --> 0.961200).  Saving model ...
Validation loss decreased (0.961200 --> 0.956707).  Saving model ...
Validation loss decreased (0.956707 --> 0.955944).  Saving model ...
Validation loss decreased (0.955944 --> 0.955552).  Saving model ...
Validation loss decreased (0.955552 --> 0.954332).  Saving model ...
Validation loss decreased (0.954332 --> 0.953326).  Saving model ...
Validation loss decreased (0.953326 --> 0.951861).  Saving model ...
EarlyStopping counter: 1 out of 10.0
EarlyStopping counter: 2 out of 10.0
EarlyStopping counter: 3 out of 10.0
EarlyStopping counter: 4 out of 10.0
EarlyStopping counter: 5 out of 10.0
Validation loss decreased (0.951861 --> 0.950244).  Saving model ...
Validation loss decreased (0.950244 --> 0.950065).  Saving model ...
EarlyStopping counter: 1 out of 10.0
Validation loss decreased (0.950065 --> 0.945264).  Saving model ...
EarlyStopping counter: 1 out of 10.0
EarlyStopping counter: 2 out of 10.0
EarlyStopping counter: 3 out of 10.0
EarlyStopping counter: 4 out of 10.0
EarlyStopping counter: 5 out of 10.0
EarlyStopping counter: 6 out of 10.0
EarlyStopping counter: 7 out of 10.0
EarlyStopping counter: 8 out of 10.0
EarlyStopping counter: 9 out of 10.0
EarlyStopping counter: 10 out of 10.0
/localscratch/yinan.29019358.0/env/lib/python3.7/site-packages/torch/nn/functional.py:1794: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.
  warnings.warn("nn.functional.tanh is deprecated. Use torch.tanh instead.")
wandb: Waiting for W&B process to finish, PID 207948... (success).
wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: \ 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: | 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: / 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: \ 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb:                                                                                
wandb: Run history:
wandb:     e_F1 ▁▁▃▄▅▆▆▆▆▆▇▆▇▇▇▇▇▇█▇████████████████████
wandb:   e_loss █▇▇▇▆▆▆▅▅▅▄▄▄▄▃▃▃▃▃▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:     t_F1 ▁▂▂▄▄▄▄▄▅▅▅▅▆▆▆▆▆▆▆▇▇▇▇▇▇▇▇▇▇█▇█▇███▇███
wandb:   t_loss ██▇▇▇▇▆▆▆▆▅▅▅▅▅▄▄▄▄▄▃▃▃▃▃▃▃▂▂▂▂▂▂▂▂▂▁▁▁▁
wandb: 
wandb: Run summary:
wandb:     e_F1 60.77222
wandb:   e_loss 0.95015
wandb:     t_F1 71.75039
wandb:   t_loss 0.74608
wandb: 
wandb: Synced 4 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Synced fiery-elevator-2: https://wandb.ai/yinanazhou/xl_512_bs_8_lr_1e06_es_10_lc_False_nr_False_sr_True_stem_False_lemma_False_repeat_3_fold_1/runs/2ei9dces
wandb: Find logs at: ./wandb/run-20220318_040458-2ei9dces/logs/debug.log
wandb: 

wandb: wandb version 0.12.11 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
2022-03-18 05:22:02.337777: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1
wandb: Tracking run with wandb version 0.12.5
wandb: Syncing run fast-field-2
wandb: ⭐️ View project at https://wandb.ai/yinanazhou/xl_512_bs_8_lr_1e06_es_10_lc_False_nr_False_sr_True_stem_False_lemma_False_repeat_3_fold_2
wandb: 🚀 View run at https://wandb.ai/yinanazhou/xl_512_bs_8_lr_1e06_es_10_lc_False_nr_False_sr_True_stem_False_lemma_False_repeat_3_fold_2/runs/tiq5cocx
wandb: Run data is saved locally in /project/6002780/yinan/Thesis_MER_Lyrics/lyric-emotion/wandb/run-20220318_052158-tiq5cocx
wandb: Run `wandb offline` to turn off syncing.

Validation loss decreased (inf --> 1.399638).  Saving model ...
Validation loss decreased (1.399638 --> 1.385872).  Saving model ...
Validation loss decreased (1.385872 --> 1.375393).  Saving model ...
Validation loss decreased (1.375393 --> 1.367402).  Saving model ...
Validation loss decreased (1.367402 --> 1.360705).  Saving model ...
Validation loss decreased (1.360705 --> 1.354742).  Saving model ...
Validation loss decreased (1.354742 --> 1.348897).  Saving model ...
Validation loss decreased (1.348897 --> 1.344328).  Saving model ...
Validation loss decreased (1.344328 --> 1.339648).  Saving model ...
Validation loss decreased (1.339648 --> 1.335005).  Saving model ...
Validation loss decreased (1.335005 --> 1.330236).  Saving model ...
Validation loss decreased (1.330236 --> 1.326182).  Saving model ...
Validation loss decreased (1.326182 --> 1.321030).  Saving model ...
Validation loss decreased (1.321030 --> 1.315546).  Saving model ...
Validation loss decreased (1.315546 --> 1.309679).  Saving model ...
Validation loss decreased (1.309679 --> 1.303469).  Saving model ...
Validation loss decreased (1.303469 --> 1.297817).  Saving model ...
Validation loss decreased (1.297817 --> 1.292049).  Saving model ...
Validation loss decreased (1.292049 --> 1.285956).  Saving model ...
Validation loss decreased (1.285956 --> 1.279349).  Saving model ...
Validation loss decreased (1.279349 --> 1.272780).  Saving model ...
Validation loss decreased (1.272780 --> 1.264787).  Saving model ...
Validation loss decreased (1.264787 --> 1.256420).  Saving model ...
Validation loss decreased (1.256420 --> 1.247819).  Saving model ...
Validation loss decreased (1.247819 --> 1.239913).  Saving model ...
Validation loss decreased (1.239913 --> 1.231690).  Saving model ...
Validation loss decreased (1.231690 --> 1.223535).  Saving model ...
Validation loss decreased (1.223535 --> 1.212907).  Saving model ...
Validation loss decreased (1.212907 --> 1.204549).  Saving model ...
Validation loss decreased (1.204549 --> 1.195206).  Saving model ...
Validation loss decreased (1.195206 --> 1.186229).  Saving model ...
Validation loss decreased (1.186229 --> 1.176091).  Saving model ...
Validation loss decreased (1.176091 --> 1.167423).  Saving model ...
Validation loss decreased (1.167423 --> 1.158831).  Saving model ...
Validation loss decreased (1.158831 --> 1.147895).  Saving model ...
Validation loss decreased (1.147895 --> 1.138336).  Saving model ...
Validation loss decreased (1.138336 --> 1.130197).  Saving model ...
Validation loss decreased (1.130197 --> 1.122599).  Saving model ...
Validation loss decreased (1.122599 --> 1.114609).  Saving model ...
Validation loss decreased (1.114609 --> 1.104943).  Saving model ...
Validation loss decreased (1.104943 --> 1.097699).  Saving model ...
Validation loss decreased (1.097699 --> 1.089987).  Saving model ...
Validation loss decreased (1.089987 --> 1.084873).  Saving model ...
Validation loss decreased (1.084873 --> 1.079234).  Saving model ...
Validation loss decreased (1.079234 --> 1.072916).  Saving model ...
Validation loss decreased (1.072916 --> 1.066477).  Saving model ...
Validation loss decreased (1.066477 --> 1.060829).  Saving model ...
Validation loss decreased (1.060829 --> 1.055176).  Saving model ...
Validation loss decreased (1.055176 --> 1.049762).  Saving model ...
Validation loss decreased (1.049762 --> 1.046765).  Saving model ...
Validation loss decreased (1.046765 --> 1.039352).  Saving model ...
Validation loss decreased (1.039352 --> 1.032764).  Saving model ...
Validation loss decreased (1.032764 --> 1.027202).  Saving model ...
Validation loss decreased (1.027202 --> 1.022135).  Saving model ...
Validation loss decreased (1.022135 --> 1.019014).  Saving model ...
Validation loss decreased (1.019014 --> 1.015288).  Saving model ...
Validation loss decreased (1.015288 --> 1.011554).  Saving model ...
Validation loss decreased (1.011554 --> 1.007166).  Saving model ...
Validation loss decreased (1.007166 --> 1.004703).  Saving model ...
Validation loss decreased (1.004703 --> 1.000861).  Saving model ...
Validation loss decreased (1.000861 --> 0.995558).  Saving model ...
Validation loss decreased (0.995558 --> 0.990118).  Saving model ...
Validation loss decreased (0.990118 --> 0.988055).  Saving model ...
Validation loss decreased (0.988055 --> 0.983659).  Saving model ...
Validation loss decreased (0.983659 --> 0.980858).  Saving model ...
Validation loss decreased (0.980858 --> 0.975306).  Saving model ...
Validation loss decreased (0.975306 --> 0.973035).  Saving model ...
Validation loss decreased (0.973035 --> 0.967805).  Saving model ...
Validation loss decreased (0.967805 --> 0.964217).  Saving model ...
Validation loss decreased (0.964217 --> 0.963005).  Saving model ...
Validation loss decreased (0.963005 --> 0.961051).  Saving model ...
Validation loss decreased (0.961051 --> 0.958908).  Saving model ...
Validation loss decreased (0.958908 --> 0.956177).  Saving model ...
Validation loss decreased (0.956177 --> 0.951223).  Saving model ...
Validation loss decreased (0.951223 --> 0.946463).  Saving model ...
Validation loss decreased (0.946463 --> 0.945959).  Saving model ...
Validation loss decreased (0.945959 --> 0.943530).  Saving model ...
Validation loss decreased (0.943530 --> 0.940002).  Saving model ...
Validation loss decreased (0.940002 --> 0.937733).  Saving model ...
Validation loss decreased (0.937733 --> 0.935181).  Saving model ...
Validation loss decreased (0.935181 --> 0.931151).  Saving model ...
Validation loss decreased (0.931151 --> 0.927022).  Saving model ...
Validation loss decreased (0.927022 --> 0.925463).  Saving model ...
Validation loss decreased (0.925463 --> 0.922052).  Saving model ...
Validation loss decreased (0.922052 --> 0.918846).  Saving model ...
Validation loss decreased (0.918846 --> 0.917184).  Saving model ...
Validation loss decreased (0.917184 --> 0.915585).  Saving model ...
Validation loss decreased (0.915585 --> 0.915322).  Saving model ...
Validation loss decreased (0.915322 --> 0.911982).  Saving model ...
Validation loss decreased (0.911982 --> 0.911187).  Saving model ...
Validation loss decreased (0.911187 --> 0.909048).  Saving model ...
Validation loss decreased (0.909048 --> 0.907920).  Saving model ...
Validation loss decreased (0.907920 --> 0.906192).  Saving model ...
Validation loss decreased (0.906192 --> 0.904483).  Saving model ...
Validation loss decreased (0.904483 --> 0.902595).  Saving model ...
EarlyStopping counter: 1 out of 10.0
Validation loss decreased (0.902595 --> 0.902593).  Saving model ...
Validation loss decreased (0.902593 --> 0.899457).  Saving model ...
Validation loss decreased (0.899457 --> 0.897189).  Saving model ...
EarlyStopping counter: 1 out of 10.0
Validation loss decreased (0.897189 --> 0.895556).  Saving model ...
Validation loss decreased (0.895556 --> 0.894180).  Saving model ...
Validation loss decreased (0.894180 --> 0.893030).  Saving model ...
Validation loss decreased (0.893030 --> 0.891131).  Saving model ...
Validation loss decreased (0.891131 --> 0.889145).  Saving model ...
Validation loss decreased (0.889145 --> 0.888173).  Saving model ...
EarlyStopping counter: 1 out of 10.0
Validation loss decreased (0.888173 --> 0.886021).  Saving model ...
EarlyStopping counter: 1 out of 10.0
Validation loss decreased (0.886021 --> 0.884703).  Saving model ...
Validation loss decreased (0.884703 --> 0.883211).  Saving model ...
EarlyStopping counter: 1 out of 10.0
EarlyStopping counter: 2 out of 10.0
Validation loss decreased (0.883211 --> 0.882464).  Saving model ...
Validation loss decreased (0.882464 --> 0.882192).  Saving model ...
Validation loss decreased (0.882192 --> 0.879696).  Saving model ...
Validation loss decreased (0.879696 --> 0.878950).  Saving model ...
Validation loss decreased (0.878950 --> 0.878266).  Saving model ...
EarlyStopping counter: 1 out of 10.0
EarlyStopping counter: 2 out of 10.0
Validation loss decreased (0.878266 --> 0.876996).  Saving model ...
EarlyStopping counter: 1 out of 10.0
EarlyStopping counter: 2 out of 10.0
EarlyStopping counter: 3 out of 10.0
Validation loss decreased (0.876996 --> 0.876454).  Saving model ...
Validation loss decreased (0.876454 --> 0.874756).  Saving model ...
EarlyStopping counter: 1 out of 10.0
EarlyStopping counter: 2 out of 10.0
Validation loss decreased (0.874756 --> 0.874499).  Saving model ...
Validation loss decreased (0.874499 --> 0.874296).  Saving model ...
EarlyStopping counter: 1 out of 10.0
EarlyStopping counter: 2 out of 10.0
EarlyStopping counter: 3 out of 10.0
EarlyStopping counter: 4 out of 10.0
Validation loss decreased (0.874296 --> 0.874216).  Saving model ...
Validation loss decreased (0.874216 --> 0.873329).  Saving model ...
EarlyStopping counter: 1 out of 10.0
EarlyStopping counter: 2 out of 10.0
EarlyStopping counter: 3 out of 10.0
EarlyStopping counter: 4 out of 10.0
EarlyStopping counter: 5 out of 10.0
EarlyStopping counter: 6 out of 10.0
EarlyStopping counter: 7 out of 10.0
EarlyStopping counter: 8 out of 10.0
EarlyStopping counter: 9 out of 10.0
EarlyStopping counter: 10 out of 10.0
/localscratch/yinan.29019358.0/env/lib/python3.7/site-packages/torch/nn/functional.py:1794: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.
  warnings.warn("nn.functional.tanh is deprecated. Use torch.tanh instead.")
wandb: Waiting for W&B process to finish, PID 212097... (success).
wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: \ 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: | 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: / 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: \ 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: | 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: / 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: \ 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: | 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: / 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb:                                                                                
wandb: Run history:
wandb:     e_F1 ▁▂▄▃▄▄▅▅▅▆▆▆▆▆▆▆▇▇▇▇▇▇▇▇▇███████████████
wandb:   e_loss ██▇▇▇▇▆▆▅▅▄▄▄▃▃▃▃▂▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:     t_F1 ▁▁▁▂▃▃▄▄▄▅▅▅▆▆▅▆▆▆▆▆▆▆▇▆▇▇▇▇▇▇▇▇▇▇▇▇██▇█
wandb:   t_loss ████▇▇▇▆▆▆▅▅▅▅▅▄▄▄▄▄▃▃▃▃▃▃▃▃▃▂▂▂▂▂▂▂▁▁▂▁
wandb: 
wandb: Run summary:
wandb:     e_F1 65.6407
wandb:   e_loss 0.87516
wandb:     t_F1 73.89557
wandb:   t_loss 0.70268
wandb: 
wandb: Synced 4 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Synced fast-field-2: https://wandb.ai/yinanazhou/xl_512_bs_8_lr_1e06_es_10_lc_False_nr_False_sr_True_stem_False_lemma_False_repeat_3_fold_2/runs/tiq5cocx
wandb: Find logs at: ./wandb/run-20220318_052158-tiq5cocx/logs/debug.log
wandb: 

wandb: wandb version 0.12.11 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
2022-03-18 06:55:40.627550: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1
wandb: Tracking run with wandb version 0.12.5
wandb: Syncing run wandering-disco-2
wandb: ⭐️ View project at https://wandb.ai/yinanazhou/xl_512_bs_8_lr_1e06_es_10_lc_False_nr_False_sr_True_stem_False_lemma_False_repeat_4_fold_1
wandb: 🚀 View run at https://wandb.ai/yinanazhou/xl_512_bs_8_lr_1e06_es_10_lc_False_nr_False_sr_True_stem_False_lemma_False_repeat_4_fold_1/runs/2tvw9el1
wandb: Run data is saved locally in /project/6002780/yinan/Thesis_MER_Lyrics/lyric-emotion/wandb/run-20220318_065538-2tvw9el1
wandb: Run `wandb offline` to turn off syncing.

Validation loss decreased (inf --> 1.404615).  Saving model ...
Validation loss decreased (1.404615 --> 1.394869).  Saving model ...
Validation loss decreased (1.394869 --> 1.386422).  Saving model ...
Validation loss decreased (1.386422 --> 1.379592).  Saving model ...
Validation loss decreased (1.379592 --> 1.373220).  Saving model ...
Validation loss decreased (1.373220 --> 1.367351).  Saving model ...
Validation loss decreased (1.367351 --> 1.362029).  Saving model ...
Validation loss decreased (1.362029 --> 1.356834).  Saving model ...
Validation loss decreased (1.356834 --> 1.351627).  Saving model ...
Validation loss decreased (1.351627 --> 1.346862).  Saving model ...
Validation loss decreased (1.346862 --> 1.341661).  Saving model ...
Validation loss decreased (1.341661 --> 1.336611).  Saving model ...
Validation loss decreased (1.336611 --> 1.330759).  Saving model ...
Validation loss decreased (1.330759 --> 1.325041).  Saving model ...
Validation loss decreased (1.325041 --> 1.319072).  Saving model ...
Validation loss decreased (1.319072 --> 1.311985).  Saving model ...
Validation loss decreased (1.311985 --> 1.305184).  Saving model ...
Validation loss decreased (1.305184 --> 1.298569).  Saving model ...
Validation loss decreased (1.298569 --> 1.291478).  Saving model ...
Validation loss decreased (1.291478 --> 1.283673).  Saving model ...
Validation loss decreased (1.283673 --> 1.276336).  Saving model ...
Validation loss decreased (1.276336 --> 1.268604).  Saving model ...
Validation loss decreased (1.268604 --> 1.260539).  Saving model ...
Validation loss decreased (1.260539 --> 1.252450).  Saving model ...
Validation loss decreased (1.252450 --> 1.245113).  Saving model ...
Validation loss decreased (1.245113 --> 1.237002).  Saving model ...
Validation loss decreased (1.237002 --> 1.229360).  Saving model ...
Validation loss decreased (1.229360 --> 1.221396).  Saving model ...
Validation loss decreased (1.221396 --> 1.213300).  Saving model ...
Validation loss decreased (1.213300 --> 1.206172).  Saving model ...
Validation loss decreased (1.206172 --> 1.198406).  Saving model ...
Validation loss decreased (1.198406 --> 1.191338).  Saving model ...
Validation loss decreased (1.191338 --> 1.184167).  Saving model ...
Validation loss decreased (1.184167 --> 1.178387).  Saving model ...
Validation loss decreased (1.178387 --> 1.171997).  Saving model ...
Validation loss decreased (1.171997 --> 1.165738).  Saving model ...
Validation loss decreased (1.165738 --> 1.161435).  Saving model ...
Validation loss decreased (1.161435 --> 1.155157).  Saving model ...
Validation loss decreased (1.155157 --> 1.151110).  Saving model ...
Validation loss decreased (1.151110 --> 1.145737).  Saving model ...
Validation loss decreased (1.145737 --> 1.139272).  Saving model ...
Validation loss decreased (1.139272 --> 1.135132).  Saving model ...
Validation loss decreased (1.135132 --> 1.130787).  Saving model ...
Validation loss decreased (1.130787 --> 1.123776).  Saving model ...
Validation loss decreased (1.123776 --> 1.117990).  Saving model ...
Validation loss decreased (1.117990 --> 1.113563).  Saving model ...
Validation loss decreased (1.113563 --> 1.110598).  Saving model ...
Validation loss decreased (1.110598 --> 1.105523).  Saving model ...
Validation loss decreased (1.105523 --> 1.101522).  Saving model ...
Validation loss decreased (1.101522 --> 1.095600).  Saving model ...
Validation loss decreased (1.095600 --> 1.091279).  Saving model ...
Validation loss decreased (1.091279 --> 1.086476).  Saving model ...
Validation loss decreased (1.086476 --> 1.083400).  Saving model ...
Validation loss decreased (1.083400 --> 1.079909).  Saving model ...
Validation loss decreased (1.079909 --> 1.077372).  Saving model ...
Validation loss decreased (1.077372 --> 1.075270).  Saving model ...
Validation loss decreased (1.075270 --> 1.070491).  Saving model ...
Validation loss decreased (1.070491 --> 1.067419).  Saving model ...
Validation loss decreased (1.067419 --> 1.063954).  Saving model ...
Validation loss decreased (1.063954 --> 1.060508).  Saving model ...
Validation loss decreased (1.060508 --> 1.055791).  Saving model ...
Validation loss decreased (1.055791 --> 1.051495).  Saving model ...
Validation loss decreased (1.051495 --> 1.047923).  Saving model ...
Validation loss decreased (1.047923 --> 1.044405).  Saving model ...
Validation loss decreased (1.044405 --> 1.042039).  Saving model ...
Validation loss decreased (1.042039 --> 1.040226).  Saving model ...
Validation loss decreased (1.040226 --> 1.037398).  Saving model ...
Validation loss decreased (1.037398 --> 1.035465).  Saving model ...
Validation loss decreased (1.035465 --> 1.032112).  Saving model ...
Validation loss decreased (1.032112 --> 1.028931).  Saving model ...
Validation loss decreased (1.028931 --> 1.026595).  Saving model ...
Validation loss decreased (1.026595 --> 1.025726).  Saving model ...
Validation loss decreased (1.025726 --> 1.020488).  Saving model ...
Validation loss decreased (1.020488 --> 1.017260).  Saving model ...
Validation loss decreased (1.017260 --> 1.014819).  Saving model ...
Validation loss decreased (1.014819 --> 1.013495).  Saving model ...
Validation loss decreased (1.013495 --> 1.009660).  Saving model ...
Validation loss decreased (1.009660 --> 1.007288).  Saving model ...
Validation loss decreased (1.007288 --> 1.005639).  Saving model ...
Validation loss decreased (1.005639 --> 1.003438).  Saving model ...
Validation loss decreased (1.003438 --> 1.002051).  Saving model ...
Validation loss decreased (1.002051 --> 0.999915).  Saving model ...
Validation loss decreased (0.999915 --> 0.997699).  Saving model ...
Validation loss decreased (0.997699 --> 0.995527).  Saving model ...
EarlyStopping counter: 1 out of 10.0
Validation loss decreased (0.995527 --> 0.994038).  Saving model ...
Validation loss decreased (0.994038 --> 0.991356).  Saving model ...
Validation loss decreased (0.991356 --> 0.988782).  Saving model ...
EarlyStopping counter: 1 out of 10.0
Validation loss decreased (0.988782 --> 0.986467).  Saving model ...
Validation loss decreased (0.986467 --> 0.986087).  Saving model ...
Validation loss decreased (0.986087 --> 0.984392).  Saving model ...
Validation loss decreased (0.984392 --> 0.982596).  Saving model ...
Validation loss decreased (0.982596 --> 0.979776).  Saving model ...
Validation loss decreased (0.979776 --> 0.977793).  Saving model ...
Validation loss decreased (0.977793 --> 0.977051).  Saving model ...
EarlyStopping counter: 1 out of 10.0
EarlyStopping counter: 2 out of 10.0
Validation loss decreased (0.977051 --> 0.973237).  Saving model ...
Validation loss decreased (0.973237 --> 0.972834).  Saving model ...
Validation loss decreased (0.972834 --> 0.971840).  Saving model ...
EarlyStopping counter: 1 out of 10.0
Validation loss decreased (0.971840 --> 0.970292).  Saving model ...
Validation loss decreased (0.970292 --> 0.967829).  Saving model ...
Validation loss decreased (0.967829 --> 0.966193).  Saving model ...
Validation loss decreased (0.966193 --> 0.964348).  Saving model ...
EarlyStopping counter: 1 out of 10.0
EarlyStopping counter: 2 out of 10.0
Validation loss decreased (0.964348 --> 0.964311).  Saving model ...
Validation loss decreased (0.964311 --> 0.960832).  Saving model ...
EarlyStopping counter: 1 out of 10.0
Validation loss decreased (0.960832 --> 0.960309).  Saving model ...
Validation loss decreased (0.960309 --> 0.957827).  Saving model ...
EarlyStopping counter: 1 out of 10.0
Validation loss decreased (0.957827 --> 0.956344).  Saving model ...
EarlyStopping counter: 1 out of 10.0
EarlyStopping counter: 2 out of 10.0
EarlyStopping counter: 3 out of 10.0
Validation loss decreased (0.956344 --> 0.955475).  Saving model ...
Validation loss decreased (0.955475 --> 0.954965).  Saving model ...
Validation loss decreased (0.954965 --> 0.954215).  Saving model ...
Validation loss decreased (0.954215 --> 0.953628).  Saving model ...
EarlyStopping counter: 1 out of 10.0
Validation loss decreased (0.953628 --> 0.951752).  Saving model ...
EarlyStopping counter: 1 out of 10.0
Validation loss decreased (0.951752 --> 0.951469).  Saving model ...
EarlyStopping counter: 1 out of 10.0
EarlyStopping counter: 2 out of 10.0
EarlyStopping counter: 3 out of 10.0
Validation loss decreased (0.951469 --> 0.951059).  Saving model ...
Validation loss decreased (0.951059 --> 0.949256).  Saving model ...
EarlyStopping counter: 1 out of 10.0
EarlyStopping counter: 2 out of 10.0
EarlyStopping counter: 3 out of 10.0
EarlyStopping counter: 4 out of 10.0
EarlyStopping counter: 5 out of 10.0
EarlyStopping counter: 6 out of 10.0
EarlyStopping counter: 7 out of 10.0
EarlyStopping counter: 8 out of 10.0
EarlyStopping counter: 9 out of 10.0
EarlyStopping counter: 10 out of 10.0
/localscratch/yinan.29019358.0/env/lib/python3.7/site-packages/torch/nn/functional.py:1794: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.
  warnings.warn("nn.functional.tanh is deprecated. Use torch.tanh instead.")
wandb: Waiting for W&B process to finish, PID 217101... (success).
wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: \ 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: | 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: / 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: \ 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: | 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: / 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: \ 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: | 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: / 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb:                                                                                
wandb: Run history:
wandb:     e_F1 ▁▁▁▂▃▃▄▅▅▆▆▆▆▆▆▆▆▆▆▇▇▇▇▇▇▇▇▇▇▇██████████
wandb:   e_loss ██▇▇▇▆▆▆▅▅▄▄▄▃▃▃▃▃▂▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:     t_F1 ▁▁▂▂▂▃▄▄▅▅▅▅▅▆▆▆▆▆▆▆▆▆▇▇▇▇▇▇▇▇▇▇▇▇█▇████
wandb:   t_loss ███▇▇▇▇▇▆▆▆▅▅▅▅▅▄▄▄▄▄▃▃▃▃▃▃▃▃▂▂▂▂▂▂▂▂▁▁▁
wandb: 
wandb: Run summary:
wandb:     e_F1 61.14731
wandb:   e_loss 0.95421
wandb:     t_F1 72.49215
wandb:   t_loss 0.73959
wandb: 
wandb: Synced 4 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Synced wandering-disco-2: https://wandb.ai/yinanazhou/xl_512_bs_8_lr_1e06_es_10_lc_False_nr_False_sr_True_stem_False_lemma_False_repeat_4_fold_1/runs/2tvw9el1
wandb: Find logs at: ./wandb/run-20220318_065538-2tvw9el1/logs/debug.log
wandb: 

wandb: wandb version 0.12.11 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
2022-03-18 08:26:16.490900: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1
wandb: Tracking run with wandb version 0.12.5
wandb: Syncing run deft-bee-2
wandb: ⭐️ View project at https://wandb.ai/yinanazhou/xl_512_bs_8_lr_1e06_es_10_lc_False_nr_False_sr_True_stem_False_lemma_False_repeat_4_fold_2
wandb: 🚀 View run at https://wandb.ai/yinanazhou/xl_512_bs_8_lr_1e06_es_10_lc_False_nr_False_sr_True_stem_False_lemma_False_repeat_4_fold_2/runs/3iv5930s
wandb: Run data is saved locally in /project/6002780/yinan/Thesis_MER_Lyrics/lyric-emotion/wandb/run-20220318_082613-3iv5930s
wandb: Run `wandb offline` to turn off syncing.

Validation loss decreased (inf --> 1.414468).  Saving model ...
Validation loss decreased (1.414468 --> 1.396026).  Saving model ...
Validation loss decreased (1.396026 --> 1.382197).  Saving model ...
Validation loss decreased (1.382197 --> 1.371824).  Saving model ...
Validation loss decreased (1.371824 --> 1.363153).  Saving model ...
Validation loss decreased (1.363153 --> 1.355177).  Saving model ...
Validation loss decreased (1.355177 --> 1.348327).  Saving model ...
Validation loss decreased (1.348327 --> 1.341812).  Saving model ...
Validation loss decreased (1.341812 --> 1.336250).  Saving model ...
Validation loss decreased (1.336250 --> 1.330412).  Saving model ...
Validation loss decreased (1.330412 --> 1.324437).  Saving model ...
Validation loss decreased (1.324437 --> 1.318687).  Saving model ...
Validation loss decreased (1.318687 --> 1.311782).  Saving model ...
Validation loss decreased (1.311782 --> 1.304742).  Saving model ...
Validation loss decreased (1.304742 --> 1.298046).  Saving model ...
Validation loss decreased (1.298046 --> 1.290010).  Saving model ...
Validation loss decreased (1.290010 --> 1.281198).  Saving model ...
Validation loss decreased (1.281198 --> 1.272990).  Saving model ...
Validation loss decreased (1.272990 --> 1.264936).  Saving model ...
Validation loss decreased (1.264936 --> 1.256472).  Saving model ...
Validation loss decreased (1.256472 --> 1.247640).  Saving model ...
Validation loss decreased (1.247640 --> 1.239250).  Saving model ...
Validation loss decreased (1.239250 --> 1.230292).  Saving model ...
Validation loss decreased (1.230292 --> 1.223171).  Saving model ...
Validation loss decreased (1.223171 --> 1.212923).  Saving model ...
Validation loss decreased (1.212923 --> 1.204609).  Saving model ...
Validation loss decreased (1.204609 --> 1.195625).  Saving model ...
Validation loss decreased (1.195625 --> 1.187499).  Saving model ...
Validation loss decreased (1.187499 --> 1.179070).  Saving model ...
Validation loss decreased (1.179070 --> 1.170511).  Saving model ...
Validation loss decreased (1.170511 --> 1.161132).  Saving model ...
Validation loss decreased (1.161132 --> 1.154741).  Saving model ...
Validation loss decreased (1.154741 --> 1.147796).  Saving model ...
Validation loss decreased (1.147796 --> 1.138989).  Saving model ...
Validation loss decreased (1.138989 --> 1.130799).  Saving model ...
Validation loss decreased (1.130799 --> 1.123635).  Saving model ...
Validation loss decreased (1.123635 --> 1.115813).  Saving model ...
Validation loss decreased (1.115813 --> 1.107330).  Saving model ...
Validation loss decreased (1.107330 --> 1.101488).  Saving model ...
Validation loss decreased (1.101488 --> 1.095074).  Saving model ...
Validation loss decreased (1.095074 --> 1.088663).  Saving model ...
Validation loss decreased (1.088663 --> 1.082777).  Saving model ...
Validation loss decreased (1.082777 --> 1.078438).  Saving model ...
Validation loss decreased (1.078438 --> 1.072016).  Saving model ...
Validation loss decreased (1.072016 --> 1.066746).  Saving model ...
Validation loss decreased (1.066746 --> 1.062071).  Saving model ...
Validation loss decreased (1.062071 --> 1.056091).  Saving model ...
Validation loss decreased (1.056091 --> 1.051225).  Saving model ...
Validation loss decreased (1.051225 --> 1.046447).  Saving model ...
Validation loss decreased (1.046447 --> 1.043661).  Saving model ...
Validation loss decreased (1.043661 --> 1.039037).  Saving model ...
Validation loss decreased (1.039037 --> 1.034031).  Saving model ...
Validation loss decreased (1.034031 --> 1.029071).  Saving model ...
Validation loss decreased (1.029071 --> 1.024761).  Saving model ...
Validation loss decreased (1.024761 --> 1.022634).  Saving model ...
Validation loss decreased (1.022634 --> 1.018284).  Saving model ...
Validation loss decreased (1.018284 --> 1.013886).  Saving model ...
Validation loss decreased (1.013886 --> 1.009503).  Saving model ...
Validation loss decreased (1.009503 --> 1.005427).  Saving model ...
Validation loss decreased (1.005427 --> 1.002303).  Saving model ...
Validation loss decreased (1.002303 --> 0.998001).  Saving model ...
Validation loss decreased (0.998001 --> 0.996873).  Saving model ...
Validation loss decreased (0.996873 --> 0.994747).  Saving model ...
Validation loss decreased (0.994747 --> 0.991570).  Saving model ...
Validation loss decreased (0.991570 --> 0.987066).  Saving model ...
Validation loss decreased (0.987066 --> 0.983402).  Saving model ...
Validation loss decreased (0.983402 --> 0.978498).  Saving model ...
Validation loss decreased (0.978498 --> 0.976625).  Saving model ...
Validation loss decreased (0.976625 --> 0.974732).  Saving model ...
Validation loss decreased (0.974732 --> 0.970972).  Saving model ...
Validation loss decreased (0.970972 --> 0.969335).  Saving model ...
Validation loss decreased (0.969335 --> 0.967201).  Saving model ...
Validation loss decreased (0.967201 --> 0.965242).  Saving model ...
Validation loss decreased (0.965242 --> 0.961706).  Saving model ...
Validation loss decreased (0.961706 --> 0.959165).  Saving model ...
Validation loss decreased (0.959165 --> 0.957801).  Saving model ...
Validation loss decreased (0.957801 --> 0.955166).  Saving model ...
Validation loss decreased (0.955166 --> 0.952542).  Saving model ...
Validation loss decreased (0.952542 --> 0.949658).  Saving model ...
Validation loss decreased (0.949658 --> 0.948570).  Saving model ...
Validation loss decreased (0.948570 --> 0.945794).  Saving model ...
Validation loss decreased (0.945794 --> 0.945284).  Saving model ...
Validation loss decreased (0.945284 --> 0.942931).  Saving model ...
Validation loss decreased (0.942931 --> 0.939584).  Saving model ...
Validation loss decreased (0.939584 --> 0.936997).  Saving model ...
EarlyStopping counter: 1 out of 10.0
Validation loss decreased (0.936997 --> 0.935659).  Saving model ...
Validation loss decreased (0.935659 --> 0.933167).  Saving model ...
Validation loss decreased (0.933167 --> 0.932579).  Saving model ...
Validation loss decreased (0.932579 --> 0.929787).  Saving model ...
Validation loss decreased (0.929787 --> 0.928685).  Saving model ...
Validation loss decreased (0.928685 --> 0.928203).  Saving model ...
Validation loss decreased (0.928203 --> 0.927505).  Saving model ...
EarlyStopping counter: 1 out of 10.0
EarlyStopping counter: 2 out of 10.0
EarlyStopping counter: 3 out of 10.0
EarlyStopping counter: 4 out of 10.0
Validation loss decreased (0.927505 --> 0.926711).  Saving model ...
Validation loss decreased (0.926711 --> 0.926239).  Saving model ...
Validation loss decreased (0.926239 --> 0.922997).  Saving model ...
Validation loss decreased (0.922997 --> 0.921173).  Saving model ...
EarlyStopping counter: 1 out of 10.0
Validation loss decreased (0.921173 --> 0.920299).  Saving model ...
EarlyStopping counter: 1 out of 10.0
EarlyStopping counter: 2 out of 10.0
Validation loss decreased (0.920299 --> 0.920008).  Saving model ...
Validation loss decreased (0.920008 --> 0.918264).  Saving model ...
Validation loss decreased (0.918264 --> 0.916719).  Saving model ...
EarlyStopping counter: 1 out of 10.0
EarlyStopping counter: 2 out of 10.0
EarlyStopping counter: 3 out of 10.0
EarlyStopping counter: 4 out of 10.0
Validation loss decreased (0.916719 --> 0.916446).  Saving model ...
EarlyStopping counter: 1 out of 10.0
EarlyStopping counter: 2 out of 10.0
EarlyStopping counter: 3 out of 10.0
EarlyStopping counter: 4 out of 10.0
EarlyStopping counter: 5 out of 10.0
EarlyStopping counter: 6 out of 10.0
EarlyStopping counter: 7 out of 10.0
EarlyStopping counter: 8 out of 10.0
EarlyStopping counter: 9 out of 10.0
EarlyStopping counter: 10 out of 10.0
/localscratch/yinan.29019358.0/env/lib/python3.7/site-packages/torch/nn/functional.py:1794: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.
  warnings.warn("nn.functional.tanh is deprecated. Use torch.tanh instead.")
wandb: Waiting for W&B process to finish, PID 221988... (success).
wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: \ 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: | 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: / 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: \ 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: | 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: / 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: \ 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: | 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: / 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: \ 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: | 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: / 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb:                                                                                
wandb: Run history:
wandb:     e_F1 ▁▃▄▄▄▅▆▆▆▇▆▇▇▇▇▇████████████████████████
wandb:   e_loss █▇▇▇▇▆▆▆▅▅▄▄▄▃▃▃▃▃▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:     t_F1 ▁▂▂▃▃▃▄▄▅▄▅▅▅▆▆▆▆▆▆▆▇▇▆▆▇▇▇▇▇▇▇▇██▇█████
wandb:   t_loss ██▇▇▇▇▇▆▆▆▅▅▅▅▅▄▄▄▄▄▃▃▃▃▃▃▂▂▂▂▂▂▂▂▂▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:     e_F1 61.54837
wandb:   e_loss 0.91699
wandb:     t_F1 72.45148
wandb:   t_loss 0.75994
wandb: 
wandb: Synced 4 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Synced deft-bee-2: https://wandb.ai/yinanazhou/xl_512_bs_8_lr_1e06_es_10_lc_False_nr_False_sr_True_stem_False_lemma_False_repeat_4_fold_2/runs/3iv5930s
wandb: Find logs at: ./wandb/run-20220318_082613-3iv5930s/logs/debug.log
wandb: 

wandb: wandb version 0.12.11 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
2022-03-18 09:43:42.955367: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1
wandb: Tracking run with wandb version 0.12.5
wandb: Syncing run neat-shadow-2
wandb: ⭐️ View project at https://wandb.ai/yinanazhou/xl_512_bs_8_lr_1e06_es_10_lc_False_nr_False_sr_True_stem_False_lemma_False_repeat_5_fold_1
wandb: 🚀 View run at https://wandb.ai/yinanazhou/xl_512_bs_8_lr_1e06_es_10_lc_False_nr_False_sr_True_stem_False_lemma_False_repeat_5_fold_1/runs/1707vo4u
wandb: Run data is saved locally in /project/6002780/yinan/Thesis_MER_Lyrics/lyric-emotion/wandb/run-20220318_094338-1707vo4u
wandb: Run `wandb offline` to turn off syncing.

Validation loss decreased (inf --> 1.414096).  Saving model ...
Validation loss decreased (1.414096 --> 1.404396).  Saving model ...
Validation loss decreased (1.404396 --> 1.396782).  Saving model ...
Validation loss decreased (1.396782 --> 1.390347).  Saving model ...
Validation loss decreased (1.390347 --> 1.384944).  Saving model ...
Validation loss decreased (1.384944 --> 1.380101).  Saving model ...
Validation loss decreased (1.380101 --> 1.375568).  Saving model ...
Validation loss decreased (1.375568 --> 1.371161).  Saving model ...
Validation loss decreased (1.371161 --> 1.366991).  Saving model ...
Validation loss decreased (1.366991 --> 1.363111).  Saving model ...
Validation loss decreased (1.363111 --> 1.359115).  Saving model ...
Validation loss decreased (1.359115 --> 1.354951).  Saving model ...
Validation loss decreased (1.354951 --> 1.350938).  Saving model ...
Validation loss decreased (1.350938 --> 1.346481).  Saving model ...
Validation loss decreased (1.346481 --> 1.342276).  Saving model ...
Validation loss decreased (1.342276 --> 1.338184).  Saving model ...
Validation loss decreased (1.338184 --> 1.333506).  Saving model ...
Validation loss decreased (1.333506 --> 1.329278).  Saving model ...
Validation loss decreased (1.329278 --> 1.324025).  Saving model ...
Validation loss decreased (1.324025 --> 1.318174).  Saving model ...
Validation loss decreased (1.318174 --> 1.312772).  Saving model ...
Validation loss decreased (1.312772 --> 1.307499).  Saving model ...
Validation loss decreased (1.307499 --> 1.301578).  Saving model ...
Validation loss decreased (1.301578 --> 1.295557).  Saving model ...
Validation loss decreased (1.295557 --> 1.289199).  Saving model ...
Validation loss decreased (1.289199 --> 1.282204).  Saving model ...
Validation loss decreased (1.282204 --> 1.274866).  Saving model ...
Validation loss decreased (1.274866 --> 1.267349).  Saving model ...
Validation loss decreased (1.267349 --> 1.260304).  Saving model ...
Validation loss decreased (1.260304 --> 1.252347).  Saving model ...
Validation loss decreased (1.252347 --> 1.243826).  Saving model ...
Validation loss decreased (1.243826 --> 1.236049).  Saving model ...
Validation loss decreased (1.236049 --> 1.227533).  Saving model ...
Validation loss decreased (1.227533 --> 1.219024).  Saving model ...
Validation loss decreased (1.219024 --> 1.210916).  Saving model ...
Validation loss decreased (1.210916 --> 1.202916).  Saving model ...
Validation loss decreased (1.202916 --> 1.195360).  Saving model ...
Validation loss decreased (1.195360 --> 1.188075).  Saving model ...
Validation loss decreased (1.188075 --> 1.181016).  Saving model ...
Validation loss decreased (1.181016 --> 1.174722).  Saving model ...
Validation loss decreased (1.174722 --> 1.169476).  Saving model ...
Validation loss decreased (1.169476 --> 1.162153).  Saving model ...
Validation loss decreased (1.162153 --> 1.156841).  Saving model ...
Validation loss decreased (1.156841 --> 1.151171).  Saving model ...
Validation loss decreased (1.151171 --> 1.144373).  Saving model ...
Validation loss decreased (1.144373 --> 1.138703).  Saving model ...
Validation loss decreased (1.138703 --> 1.133432).  Saving model ...
Validation loss decreased (1.133432 --> 1.127055).  Saving model ...
Validation loss decreased (1.127055 --> 1.120421).  Saving model ...
Validation loss decreased (1.120421 --> 1.113739).  Saving model ...
Validation loss decreased (1.113739 --> 1.109112).  Saving model ...
Validation loss decreased (1.109112 --> 1.104461).  Saving model ...
Validation loss decreased (1.104461 --> 1.097525).  Saving model ...
Validation loss decreased (1.097525 --> 1.093093).  Saving model ...
Validation loss decreased (1.093093 --> 1.088690).  Saving model ...
Validation loss decreased (1.088690 --> 1.085416).  Saving model ...
Validation loss decreased (1.085416 --> 1.080659).  Saving model ...
Validation loss decreased (1.080659 --> 1.075254).  Saving model ...
Validation loss decreased (1.075254 --> 1.069687).  Saving model ...
Validation loss decreased (1.069687 --> 1.065980).  Saving model ...
Validation loss decreased (1.065980 --> 1.061078).  Saving model ...
Validation loss decreased (1.061078 --> 1.057717).  Saving model ...
Validation loss decreased (1.057717 --> 1.053014).  Saving model ...
Validation loss decreased (1.053014 --> 1.047946).  Saving model ...
Validation loss decreased (1.047946 --> 1.041983).  Saving model ...
Validation loss decreased (1.041983 --> 1.038010).  Saving model ...
Validation loss decreased (1.038010 --> 1.033303).  Saving model ...
Validation loss decreased (1.033303 --> 1.029079).  Saving model ...
Validation loss decreased (1.029079 --> 1.024430).  Saving model ...
Validation loss decreased (1.024430 --> 1.020030).  Saving model ...
Validation loss decreased (1.020030 --> 1.015745).  Saving model ...
Validation loss decreased (1.015745 --> 1.012519).  Saving model ...
Validation loss decreased (1.012519 --> 1.007259).  Saving model ...
Validation loss decreased (1.007259 --> 1.004726).  Saving model ...
Validation loss decreased (1.004726 --> 1.002283).  Saving model ...
Validation loss decreased (1.002283 --> 0.998408).  Saving model ...
Validation loss decreased (0.998408 --> 0.995254).  Saving model ...
Validation loss decreased (0.995254 --> 0.990507).  Saving model ...
Validation loss decreased (0.990507 --> 0.987541).  Saving model ...
Validation loss decreased (0.987541 --> 0.983608).  Saving model ...
Validation loss decreased (0.983608 --> 0.980462).  Saving model ...
Validation loss decreased (0.980462 --> 0.977790).  Saving model ...
Validation loss decreased (0.977790 --> 0.975725).  Saving model ...
Validation loss decreased (0.975725 --> 0.972080).  Saving model ...
Validation loss decreased (0.972080 --> 0.969309).  Saving model ...
Validation loss decreased (0.969309 --> 0.966362).  Saving model ...
Validation loss decreased (0.966362 --> 0.963736).  Saving model ...
Validation loss decreased (0.963736 --> 0.960290).  Saving model ...
Validation loss decreased (0.960290 --> 0.957217).  Saving model ...
Validation loss decreased (0.957217 --> 0.955523).  Saving model ...
Validation loss decreased (0.955523 --> 0.952079).  Saving model ...
Validation loss decreased (0.952079 --> 0.949465).  Saving model ...
Validation loss decreased (0.949465 --> 0.947174).  Saving model ...
Validation loss decreased (0.947174 --> 0.945360).  Saving model ...
Validation loss decreased (0.945360 --> 0.943487).  Saving model ...
Validation loss decreased (0.943487 --> 0.941161).  Saving model ...
Validation loss decreased (0.941161 --> 0.939406).  Saving model ...
Validation loss decreased (0.939406 --> 0.938573).  Saving model ...
Validation loss decreased (0.938573 --> 0.937065).  Saving model ...
Validation loss decreased (0.937065 --> 0.934508).  Saving model ...
Validation loss decreased (0.934508 --> 0.932779).  Saving model ...
Validation loss decreased (0.932779 --> 0.931064).  Saving model ...
Validation loss decreased (0.931064 --> 0.929478).  Saving model ...
Validation loss decreased (0.929478 --> 0.927842).  Saving model ...
Validation loss decreased (0.927842 --> 0.926000).  Saving model ...
Validation loss decreased (0.926000 --> 0.924429).  Saving model ...
Validation loss decreased (0.924429 --> 0.923286).  Saving model ...
Validation loss decreased (0.923286 --> 0.921806).  Saving model ...
Validation loss decreased (0.921806 --> 0.920256).  Saving model ...
Validation loss decreased (0.920256 --> 0.919476).  Saving model ...
Validation loss decreased (0.919476 --> 0.918142).  Saving model ...
Validation loss decreased (0.918142 --> 0.917390).  Saving model ...
Validation loss decreased (0.917390 --> 0.916923).  Saving model ...
Validation loss decreased (0.916923 --> 0.915856).  Saving model ...
Validation loss decreased (0.915856 --> 0.914839).  Saving model ...
Validation loss decreased (0.914839 --> 0.914167).  Saving model ...
Validation loss decreased (0.914167 --> 0.912639).  Saving model ...
Validation loss decreased (0.912639 --> 0.912267).  Saving model ...
Validation loss decreased (0.912267 --> 0.912007).  Saving model ...
Validation loss decreased (0.912007 --> 0.910942).  Saving model ...
Validation loss decreased (0.910942 --> 0.909833).  Saving model ...
Validation loss decreased (0.909833 --> 0.908882).  Saving model ...
Validation loss decreased (0.908882 --> 0.907759).  Saving model ...
EarlyStopping counter: 1 out of 10.0
Validation loss decreased (0.907759 --> 0.906940).  Saving model ...
Validation loss decreased (0.906940 --> 0.906478).  Saving model ...
Validation loss decreased (0.906478 --> 0.905544).  Saving model ...
Validation loss decreased (0.905544 --> 0.905159).  Saving model ...
Validation loss decreased (0.905159 --> 0.905083).  Saving model ...
Validation loss decreased (0.905083 --> 0.904560).  Saving model ...
Validation loss decreased (0.904560 --> 0.903760).  Saving model ...
Validation loss decreased (0.903760 --> 0.903572).  Saving model ...
Validation loss decreased (0.903572 --> 0.903108).  Saving model ...
Validation loss decreased (0.903108 --> 0.902313).  Saving model ...
Validation loss decreased (0.902313 --> 0.901742).  Saving model ...
Validation loss decreased (0.901742 --> 0.901708).  Saving model ...
EarlyStopping counter: 1 out of 10.0
Validation loss decreased (0.901708 --> 0.901252).  Saving model ...
EarlyStopping counter: 1 out of 10.0
EarlyStopping counter: 2 out of 10.0
EarlyStopping counter: 3 out of 10.0
EarlyStopping counter: 4 out of 10.0
EarlyStopping counter: 5 out of 10.0
EarlyStopping counter: 6 out of 10.0
EarlyStopping counter: 7 out of 10.0
EarlyStopping counter: 8 out of 10.0
EarlyStopping counter: 9 out of 10.0
EarlyStopping counter: 10 out of 10.0
/localscratch/yinan.29019358.0/env/lib/python3.7/site-packages/torch/nn/functional.py:1794: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.
  warnings.warn("nn.functional.tanh is deprecated. Use torch.tanh instead.")
wandb: Waiting for W&B process to finish, PID 226122... (success).
wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: \ 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: | 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: / 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: \ 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: | 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: / 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: \ 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: | 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: / 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb:                                                                                
wandb: Run history:
wandb:     e_F1 ▁▂▂▃▄▅▅▅▅▅▆▆▆▆▇▇▇▇▇▇▇▇▇▇▇███████████████
wandb:   e_loss ███▇▇▇▆▆▆▅▅▅▄▄▄▃▃▃▃▃▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:     t_F1 ▁▁▂▂▃▃▄▄▄▄▅▅▅▅▆▆▆▆▆▆▆▆▇▇▇▇▇▇▇▇█▇▇█▇█████
wandb:   t_loss ████▇▇▇▇▇▆▆▆▅▅▅▅▅▄▄▄▄▄▃▃▃▃▃▃▂▂▂▂▂▂▂▂▁▁▁▁
wandb: 
wandb: Run summary:
wandb:     e_F1 62.49599
wandb:   e_loss 0.90353
wandb:     t_F1 74.83479
wandb:   t_loss 0.68433
wandb: 
wandb: Synced 4 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Synced neat-shadow-2: https://wandb.ai/yinanazhou/xl_512_bs_8_lr_1e06_es_10_lc_False_nr_False_sr_True_stem_False_lemma_False_repeat_5_fold_1/runs/1707vo4u
wandb: Find logs at: ./wandb/run-20220318_094338-1707vo4u/logs/debug.log
wandb: 

wandb: wandb version 0.12.11 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
2022-03-18 11:19:15.553463: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1
wandb: Tracking run with wandb version 0.12.5
wandb: Syncing run driven-shape-2
wandb: ⭐️ View project at https://wandb.ai/yinanazhou/xl_512_bs_8_lr_1e06_es_10_lc_False_nr_False_sr_True_stem_False_lemma_False_repeat_5_fold_2
wandb: 🚀 View run at https://wandb.ai/yinanazhou/xl_512_bs_8_lr_1e06_es_10_lc_False_nr_False_sr_True_stem_False_lemma_False_repeat_5_fold_2/runs/3uxgu8vu
wandb: Run data is saved locally in /project/6002780/yinan/Thesis_MER_Lyrics/lyric-emotion/wandb/run-20220318_111913-3uxgu8vu
wandb: Run `wandb offline` to turn off syncing.

Validation loss decreased (inf --> 1.379905).  Saving model ...
Validation loss decreased (1.379905 --> 1.374093).  Saving model ...
Validation loss decreased (1.374093 --> 1.368179).  Saving model ...
Validation loss decreased (1.368179 --> 1.363211).  Saving model ...
Validation loss decreased (1.363211 --> 1.358355).  Saving model ...
Validation loss decreased (1.358355 --> 1.353916).  Saving model ...
Validation loss decreased (1.353916 --> 1.349773).  Saving model ...
Validation loss decreased (1.349773 --> 1.344932).  Saving model ...
Validation loss decreased (1.344932 --> 1.340624).  Saving model ...
Validation loss decreased (1.340624 --> 1.336470).  Saving model ...
Validation loss decreased (1.336470 --> 1.332190).  Saving model ...
Validation loss decreased (1.332190 --> 1.326833).  Saving model ...
Validation loss decreased (1.326833 --> 1.321852).  Saving model ...
Validation loss decreased (1.321852 --> 1.317066).  Saving model ...
Validation loss decreased (1.317066 --> 1.311875).  Saving model ...
Validation loss decreased (1.311875 --> 1.306293).  Saving model ...
Validation loss decreased (1.306293 --> 1.300088).  Saving model ...
Validation loss decreased (1.300088 --> 1.294419).  Saving model ...
Validation loss decreased (1.294419 --> 1.288960).  Saving model ...
Validation loss decreased (1.288960 --> 1.282843).  Saving model ...
Validation loss decreased (1.282843 --> 1.276810).  Saving model ...
Validation loss decreased (1.276810 --> 1.269583).  Saving model ...
Validation loss decreased (1.269583 --> 1.261423).  Saving model ...
Validation loss decreased (1.261423 --> 1.254641).  Saving model ...
Validation loss decreased (1.254641 --> 1.246709).  Saving model ...
Validation loss decreased (1.246709 --> 1.238788).  Saving model ...
Validation loss decreased (1.238788 --> 1.231512).  Saving model ...
Validation loss decreased (1.231512 --> 1.224986).  Saving model ...
Validation loss decreased (1.224986 --> 1.217188).  Saving model ...
Validation loss decreased (1.217188 --> 1.210461).  Saving model ...
Validation loss decreased (1.210461 --> 1.201458).  Saving model ...
Validation loss decreased (1.201458 --> 1.194023).  Saving model ...
Validation loss decreased (1.194023 --> 1.187058).  Saving model ...
Validation loss decreased (1.187058 --> 1.180338).  Saving model ...
Validation loss decreased (1.180338 --> 1.173257).  Saving model ...
Validation loss decreased (1.173257 --> 1.165646).  Saving model ...
Validation loss decreased (1.165646 --> 1.159269).  Saving model ...
Validation loss decreased (1.159269 --> 1.153497).  Saving model ...
Validation loss decreased (1.153497 --> 1.146561).  Saving model ...
Validation loss decreased (1.146561 --> 1.140579).  Saving model ...
Validation loss decreased (1.140579 --> 1.134984).  Saving model ...
Validation loss decreased (1.134984 --> 1.128344).  Saving model ...
Validation loss decreased (1.128344 --> 1.122537).  Saving model ...
Validation loss decreased (1.122537 --> 1.115987).  Saving model ...
Validation loss decreased (1.115987 --> 1.110809).  Saving model ...
Validation loss decreased (1.110809 --> 1.103923).  Saving model ...
Validation loss decreased (1.103923 --> 1.097739).  Saving model ...
Validation loss decreased (1.097739 --> 1.093379).  Saving model ...
Validation loss decreased (1.093379 --> 1.088871).  Saving model ...
Validation loss decreased (1.088871 --> 1.083237).  Saving model ...
Validation loss decreased (1.083237 --> 1.078903).  Saving model ...
Validation loss decreased (1.078903 --> 1.074065).  Saving model ...
Validation loss decreased (1.074065 --> 1.070440).  Saving model ...
Validation loss decreased (1.070440 --> 1.065193).  Saving model ...
Validation loss decreased (1.065193 --> 1.060230).  Saving model ...
Validation loss decreased (1.060230 --> 1.056168).  Saving model ...
Validation loss decreased (1.056168 --> 1.051237).  Saving model ...
Validation loss decreased (1.051237 --> 1.046041).  Saving model ...
Validation loss decreased (1.046041 --> 1.042890).  Saving model ...
Validation loss decreased (1.042890 --> 1.037700).  Saving model ...
Validation loss decreased (1.037700 --> 1.035910).  Saving model ...
Validation loss decreased (1.035910 --> 1.033495).  Saving model ...
Validation loss decreased (1.033495 --> 1.030075).  Saving model ...
Validation loss decreased (1.030075 --> 1.026206).  Saving model ...
Validation loss decreased (1.026206 --> 1.022009).  Saving model ...
Validation loss decreased (1.022009 --> 1.018532).  Saving model ...
Validation loss decreased (1.018532 --> 1.015622).  Saving model ...
Validation loss decreased (1.015622 --> 1.013393).  Saving model ...
Validation loss decreased (1.013393 --> 1.010921).  Saving model ...
Validation loss decreased (1.010921 --> 1.006677).  Saving model ...
Validation loss decreased (1.006677 --> 1.004270).  Saving model ...
Validation loss decreased (1.004270 --> 1.002393).  Saving model ...
Validation loss decreased (1.002393 --> 0.998007).  Saving model ...
Validation loss decreased (0.998007 --> 0.992703).  Saving model ...
Validation loss decreased (0.992703 --> 0.989962).  Saving model ...
Validation loss decreased (0.989962 --> 0.987478).  Saving model ...
Validation loss decreased (0.987478 --> 0.986358).  Saving model ...
Validation loss decreased (0.986358 --> 0.984208).  Saving model ...
Validation loss decreased (0.984208 --> 0.981257).  Saving model ...
Validation loss decreased (0.981257 --> 0.978719).  Saving model ...
Validation loss decreased (0.978719 --> 0.975966).  Saving model ...
Validation loss decreased (0.975966 --> 0.973256).  Saving model ...
Validation loss decreased (0.973256 --> 0.970170).  Saving model ...
Validation loss decreased (0.970170 --> 0.969709).  Saving model ...
Validation loss decreased (0.969709 --> 0.968159).  Saving model ...
Validation loss decreased (0.968159 --> 0.966744).  Saving model ...
Validation loss decreased (0.966744 --> 0.964453).  Saving model ...
Validation loss decreased (0.964453 --> 0.961697).  Saving model ...
Validation loss decreased (0.961697 --> 0.959820).  Saving model ...
Validation loss decreased (0.959820 --> 0.958200).  Saving model ...
Validation loss decreased (0.958200 --> 0.955156).  Saving model ...
Validation loss decreased (0.955156 --> 0.953742).  Saving model ...
Validation loss decreased (0.953742 --> 0.949881).  Saving model ...
Validation loss decreased (0.949881 --> 0.948894).  Saving model ...
Validation loss decreased (0.948894 --> 0.946547).  Saving model ...
Validation loss decreased (0.946547 --> 0.946049).  Saving model ...
Validation loss decreased (0.946049 --> 0.944861).  Saving model ...
EarlyStopping counter: 1 out of 10.0
Validation loss decreased (0.944861 --> 0.941682).  Saving model ...
Validation loss decreased (0.941682 --> 0.939784).  Saving model ...
EarlyStopping counter: 1 out of 10.0
Validation loss decreased (0.939784 --> 0.936267).  Saving model ...
Validation loss decreased (0.936267 --> 0.935616).  Saving model ...
EarlyStopping counter: 1 out of 10.0
Validation loss decreased (0.935616 --> 0.933150).  Saving model ...
Validation loss decreased (0.933150 --> 0.932318).  Saving model ...
Validation loss decreased (0.932318 --> 0.931282).  Saving model ...
EarlyStopping counter: 1 out of 10.0
Validation loss decreased (0.931282 --> 0.930663).  Saving model ...
Validation loss decreased (0.930663 --> 0.930543).  Saving model ...
Validation loss decreased (0.930543 --> 0.926806).  Saving model ...
Validation loss decreased (0.926806 --> 0.925200).  Saving model ...
Validation loss decreased (0.925200 --> 0.924287).  Saving model ...
EarlyStopping counter: 1 out of 10.0
EarlyStopping counter: 2 out of 10.0
EarlyStopping counter: 3 out of 10.0
EarlyStopping counter: 4 out of 10.0
EarlyStopping counter: 5 out of 10.0
Validation loss decreased (0.924287 --> 0.922452).  Saving model ...
EarlyStopping counter: 1 out of 10.0
EarlyStopping counter: 2 out of 10.0
Validation loss decreased (0.922452 --> 0.920064).  Saving model ...
Validation loss decreased (0.920064 --> 0.918669).  Saving model ...
Validation loss decreased (0.918669 --> 0.916794).  Saving model ...
EarlyStopping counter: 1 out of 10.0
Validation loss decreased (0.916794 --> 0.916106).  Saving model ...
EarlyStopping counter: 1 out of 10.0
EarlyStopping counter: 2 out of 10.0
Validation loss decreased (0.916106 --> 0.914468).  Saving model ...
Validation loss decreased (0.914468 --> 0.913720).  Saving model ...
Validation loss decreased (0.913720 --> 0.912851).  Saving model ...
Validation loss decreased (0.912851 --> 0.912457).  Saving model ...
EarlyStopping counter: 1 out of 10.0
EarlyStopping counter: 2 out of 10.0
EarlyStopping counter: 3 out of 10.0
Validation loss decreased (0.912457 --> 0.911850).  Saving model ...
EarlyStopping counter: 1 out of 10.0
EarlyStopping counter: 2 out of 10.0
EarlyStopping counter: 3 out of 10.0
Validation loss decreased (0.911850 --> 0.911008).  Saving model ...
EarlyStopping counter: 1 out of 10.0
Validation loss decreased (0.911008 --> 0.910399).  Saving model ...
EarlyStopping counter: 1 out of 10.0
EarlyStopping counter: 2 out of 10.0
EarlyStopping counter: 3 out of 10.0
EarlyStopping counter: 4 out of 10.0
EarlyStopping counter: 5 out of 10.0
EarlyStopping counter: 6 out of 10.0
Validation loss decreased (0.910399 --> 0.910006).  Saving model ...
Validation loss decreased (0.910006 --> 0.909719).  Saving model ...
Validation loss decreased (0.909719 --> 0.909536).  Saving model ...
EarlyStopping counter: 1 out of 10.0
Validation loss decreased (0.909536 --> 0.909047).  Saving model ...
EarlyStopping counter: 1 out of 10.0
EarlyStopping counter: 2 out of 10.0
EarlyStopping counter: 3 out of 10.0
EarlyStopping counter: 4 out of 10.0
EarlyStopping counter: 5 out of 10.0
Validation loss decreased (0.909047 --> 0.908818).  Saving model ...
Validation loss decreased (0.908818 --> 0.908512).  Saving model ...
Validation loss decreased (0.908512 --> 0.907163).  Saving model ...
EarlyStopping counter: 1 out of 10.0
EarlyStopping counter: 2 out of 10.0
EarlyStopping counter: 3 out of 10.0
EarlyStopping counter: 4 out of 10.0
EarlyStopping counter: 5 out of 10.0
EarlyStopping counter: 6 out of 10.0
EarlyStopping counter: 7 out of 10.0
EarlyStopping counter: 8 out of 10.0
EarlyStopping counter: 9 out of 10.0
EarlyStopping counter: 10 out of 10.0
/localscratch/yinan.29019358.0/env/lib/python3.7/site-packages/torch/nn/functional.py:1794: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.
  warnings.warn("nn.functional.tanh is deprecated. Use torch.tanh instead.")
wandb: Waiting for W&B process to finish, PID 231295... (success).
wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: \ 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: | 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: / 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: \ 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: | 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: / 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: \ 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: | 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: / 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb:                                                                                
wandb: Run history:
wandb:     e_F1 ▁▂▃▄▄▄▄▅▅▆▆▆▆▆▆▇▇▇▇▇▇▇██████████████████
wandb:   e_loss ██▇▇▇▆▆▅▅▄▄▄▃▃▃▃▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:     t_F1 ▁▂▂▃▃▃▄▄▅▅▅▅▅▆▅▆▆▆▆▆▆▇▇▇▇▇▇▇▇▇▇▇▇▇█▇██▇█
wandb:   t_loss ████▇▇▇▆▆▆▅▅▅▅▅▄▄▄▄▃▃▃▃▃▃▃▂▂▂▂▂▂▂▂▂▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:     e_F1 62.31026
wandb:   e_loss 0.91524
wandb:     t_F1 77.97221
wandb:   t_loss 0.64826
wandb: 
wandb: Synced 4 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Synced driven-shape-2: https://wandb.ai/yinanazhou/xl_512_bs_8_lr_1e06_es_10_lc_False_nr_False_sr_True_stem_False_lemma_False_repeat_5_fold_2/runs/3uxgu8vu
wandb: Find logs at: ./wandb/run-20220318_111913-3uxgu8vu/logs/debug.log
wandb: 

