Unloading StdEnv/2020

Due to MODULEPATH changes, the following have been reloaded:
  1) mii/1.1.1


The following have been reloaded with a version change:
  1) python/3.8.2 => python/3.7.4

Using base prefix '/cvmfs/soft.computecanada.ca/easybuild/software/2017/Core/python/3.7.4'
New python executable in /localscratch/yinan.29031137.0/env/bin/python
Installing setuptools, pip, wheel...
done.
Ignoring pip: markers 'python_version < "3"' don't match your environment
Looking in links: /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/nix/avx2, /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/nix/generic, /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic
Collecting pip
Installing collected packages: pip
  Found existing installation: pip 19.1.1
    Uninstalling pip-19.1.1:
      Successfully uninstalled pip-19.1.1
Successfully installed pip-21.2.3+computecanada
Looking in links: /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/nix/avx2, /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/nix/generic, /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/keras-2.8.0+computecanada-py2.py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/Keras_Preprocessing-1.1.2+computecanada-py3-none-any.whl
Requirement already satisfied: matplotlib in /cvmfs/soft.computecanada.ca/easybuild/software/2017/Core/scipy-stack/2019a/lib/python3.7/site-packages (from -r requirements.txt (line 3)) (3.0.2)
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/nltk-3.6.5+computecanada-py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/scikit_learn-0.22.1+computecanada-cp37-cp37m-linux_x86_64.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/tensorboard-2.3.0+computecanada-py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/tensorboard_plugin_wit-1.7.0+computecanada-py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/tensorflow_gpu-2.3.0+computecanada-cp37-cp37m-linux_x86_64.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/tensorflow_estimator-2.3.0+computecanada-py2.py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/tokenizers-0.5.2+computecanada-cp37-cp37m-linux_x86_64.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/nix/avx2/torch-1.4.0+computecanada-cp37-cp37m-linux_x86_64.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/torchtext-0.6.0+computecanada-py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/torchvision-0.8.2+computecanada-cp37-cp37m-linux_x86_64.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/transformers-2.5.1+computecanada-py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/urllib3-1.26.7+computecanada-py2.py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/joblib-1.1.0+computecanada-py2.py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/click-8.0.3+computecanada-py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/tqdm-4.63.0+computecanada-py2.py3-none-any.whl
ERROR: Could not find a version that satisfies the requirement regex>=2021.8.3 (from nltk) (from versions: 2018.1.10+computecanada, 2019.11.1+computecanada, 2020.11.13+computecanada)
ERROR: No matching distribution found for regex>=2021.8.3
Looking in links: /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/nix/avx2, /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/nix/generic, /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic
ERROR: Could not find a version that satisfies the requirement numpy==1.20.0+computacanada (from versions: 1.15.0+computecanada, 1.15.2+computecanada, 1.15.4+computecanada, 1.16.0+computecanada, 1.16.2+computecanada, 1.16.3+computecanada, 1.17.4+computecanada, 1.18.1+computecanada, 1.18.4+computecanada, 1.19.1+computecanada, 1.19.2+computecanada, 1.20.2+computecanada)
ERROR: No matching distribution found for numpy==1.20.0+computacanada
Looking in links: /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/nix/avx2, /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/nix/generic, /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/wandb-0.12.5+computecanada-py2.py3-none-any.whl
Requirement already satisfied: python-dateutil>=2.6.1 in /cvmfs/soft.computecanada.ca/easybuild/software/2017/Core/scipy-stack/2019a/lib/python3.7/site-packages (from wandb) (2.7.5)
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/docker_pycreds-0.4.0+computecanada-py2.py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/psutil-5.7.3+computecanada-cp37-cp37m-linux_x86_64.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/GitPython-3.1.24+computecanada-py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/six-1.16.0+computecanada-py2.py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/PyYAML-5.3.1+computecanada-cp37-cp37m-linux_x86_64.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/yaspin-2.1.0+computecanada-py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/sentry_sdk-1.5.0+computecanada-py2.py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/protobuf-3.19.4+computecanada-py2.py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/pathtools-0.1.2+computecanada-py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/configparser-5.0.2+computecanada-py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/subprocess32-3.5.4+computecanada-py3-none-any.whl
Requirement already satisfied: requests<3,>=2.0.0 in /cvmfs/soft.computecanada.ca/easybuild/software/2017/Core/scipy-stack/2019a/lib/python3.7/site-packages (from wandb) (2.21.0)
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/click-8.0.3+computecanada-py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/promise-2.3+computecanada-py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/shortuuid-1.0.1+computecanada-py3-none-any.whl
Requirement already satisfied: importlib-metadata in /cvmfs/soft.computecanada.ca/easybuild/software/2017/Core/scipy-stack/2019a/lib/python3.7/site-packages (from Click!=8.0.0,>=7.0->wandb) (0.8)
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/typing_extensions-4.0.1+computecanada-py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/gitdb-4.0.9+computecanada-py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/smmap-5.0.0+computecanada-py3-none-any.whl
Requirement already satisfied: idna<2.9,>=2.5 in /cvmfs/soft.computecanada.ca/easybuild/software/2017/Core/scipy-stack/2019a/lib/python3.7/site-packages (from requests<3,>=2.0.0->wandb) (2.8)
Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /cvmfs/soft.computecanada.ca/easybuild/software/2017/Core/scipy-stack/2019a/lib/python3.7/site-packages (from requests<3,>=2.0.0->wandb) (3.0.4)
Requirement already satisfied: certifi>=2017.4.17 in /cvmfs/soft.computecanada.ca/easybuild/software/2017/Core/scipy-stack/2019a/lib/python3.7/site-packages (from requests<3,>=2.0.0->wandb) (2018.11.29)
Requirement already satisfied: urllib3<1.25,>=1.21.1 in /cvmfs/soft.computecanada.ca/easybuild/software/2017/Core/scipy-stack/2019a/lib/python3.7/site-packages (from requests<3,>=2.0.0->wandb) (1.24.1)
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/termcolor-1.1.0+computecanada-py3-none-any.whl
Requirement already satisfied: zipp>=0.3.2 in /cvmfs/soft.computecanada.ca/easybuild/software/2017/Core/scipy-stack/2019a/lib/python3.7/site-packages (from importlib-metadata->Click!=8.0.0,>=7.0->wandb) (0.3.3)
Installing collected packages: smmap, typing-extensions, termcolor, six, gitdb, yaspin, subprocess32, shortuuid, sentry-sdk, PyYAML, psutil, protobuf, promise, pathtools, GitPython, docker-pycreds, configparser, Click, wandb
  Attempting uninstall: six
    Found existing installation: six 1.12.0
    Not uninstalling six at /cvmfs/soft.computecanada.ca/easybuild/software/2017/Core/scipy-stack/2019a/lib/python3.7/site-packages, outside environment /localscratch/yinan.29031137.0/env
    Can't uninstall 'six'. No files were found to uninstall.
Successfully installed Click-8.0.3+computecanada GitPython-3.1.24+computecanada PyYAML-5.3.1+computecanada configparser-5.0.2+computecanada docker-pycreds-0.4.0+computecanada gitdb-4.0.9+computecanada pathtools-0.1.2+computecanada promise-2.3+computecanada protobuf-3.19.4+computecanada psutil-5.7.3+computecanada sentry-sdk-1.5.0+computecanada shortuuid-1.0.1+computecanada six-1.16.0+computecanada smmap-5.0.0+computecanada subprocess32-3.5.4+computecanada termcolor-1.1.0+computecanada typing-extensions-4.0.1+computecanada wandb-0.12.5+computecanada yaspin-2.1.0+computecanada
Looking in links: /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/nix/avx2, /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/nix/generic, /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic
ERROR: Could not find a version that satisfies the requirement sagemaker (from versions: none)
ERROR: No matching distribution found for sagemaker
Looking in links: /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/nix/avx2, /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/nix/generic, /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/torch-1.9.1+computecanada-cp37-cp37m-linux_x86_64.whl
Requirement already satisfied: typing-extensions in /localscratch/yinan.29031137.0/env/lib/python3.7/site-packages (from torch) (4.0.1+computecanada)
Installing collected packages: torch
Successfully installed torch-1.9.1+computecanada
Looking in links: /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/nix/avx2, /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/nix/generic, /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/transformers-2.5.1+computecanada-py3-none-any.whl
Requirement already satisfied: numpy in /cvmfs/soft.computecanada.ca/easybuild/software/2017/Core/scipy-stack/2019a/lib/python3.7/site-packages (from transformers==2.5.1+computecanada) (1.16.0)
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/sentencepiece-0.1.91+computecanada-cp37-cp37m-linux_x86_64.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/tokenizers-0.5.2+computecanada-cp37-cp37m-linux_x86_64.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/sacremoses-0.0.46+computecanada-py3-none-any.whl
Requirement already satisfied: requests in /cvmfs/soft.computecanada.ca/easybuild/software/2017/Core/scipy-stack/2019a/lib/python3.7/site-packages (from transformers==2.5.1+computecanada) (2.21.0)
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/filelock-3.4.2+computecanada-py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/boto3-1.20.52+computecanada-py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/regex-2020.11.13+computecanada-cp37-cp37m-linux_x86_64.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/tqdm-4.63.0+computecanada-py2.py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/s3transfer-0.5.1+computecanada-py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/jmespath-0.10.0+computecanada-py2.py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/botocore-1.23.52+computecanada-py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/urllib3-1.26.8+computecanada-py2.py3-none-any.whl
Requirement already satisfied: python-dateutil<3.0.0,>=2.1 in /cvmfs/soft.computecanada.ca/easybuild/software/2017/Core/scipy-stack/2019a/lib/python3.7/site-packages (from botocore<1.24.0,>=1.23.52->boto3->transformers==2.5.1+computecanada) (2.7.5)
Requirement already satisfied: six>=1.5 in /localscratch/yinan.29031137.0/env/lib/python3.7/site-packages (from python-dateutil<3.0.0,>=2.1->botocore<1.24.0,>=1.23.52->boto3->transformers==2.5.1+computecanada) (1.16.0+computecanada)
Requirement already satisfied: certifi>=2017.4.17 in /cvmfs/soft.computecanada.ca/easybuild/software/2017/Core/scipy-stack/2019a/lib/python3.7/site-packages (from requests->transformers==2.5.1+computecanada) (2018.11.29)
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/requests-2.27.1+computecanada-py2.py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/charset_normalizer-2.0.11+computecanada-py3-none-any.whl
Requirement already satisfied: idna<4,>=2.5 in /cvmfs/soft.computecanada.ca/easybuild/software/2017/Core/scipy-stack/2019a/lib/python3.7/site-packages (from requests->transformers==2.5.1+computecanada) (2.8)
Requirement already satisfied: click in /localscratch/yinan.29031137.0/env/lib/python3.7/site-packages (from sacremoses->transformers==2.5.1+computecanada) (8.0.3+computecanada)
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/joblib-1.1.0+computecanada-py2.py3-none-any.whl
Requirement already satisfied: importlib-metadata in /cvmfs/soft.computecanada.ca/easybuild/software/2017/Core/scipy-stack/2019a/lib/python3.7/site-packages (from click->sacremoses->transformers==2.5.1+computecanada) (0.8)
Requirement already satisfied: zipp>=0.3.2 in /cvmfs/soft.computecanada.ca/easybuild/software/2017/Core/scipy-stack/2019a/lib/python3.7/site-packages (from importlib-metadata->click->sacremoses->transformers==2.5.1+computecanada) (0.3.3)
Installing collected packages: urllib3, jmespath, botocore, tqdm, s3transfer, regex, joblib, charset-normalizer, tokenizers, sentencepiece, sacremoses, requests, filelock, boto3, transformers
  Attempting uninstall: urllib3
    Found existing installation: urllib3 1.24.1
    Not uninstalling urllib3 at /cvmfs/soft.computecanada.ca/easybuild/software/2017/Core/scipy-stack/2019a/lib/python3.7/site-packages, outside environment /localscratch/yinan.29031137.0/env
    Can't uninstall 'urllib3'. No files were found to uninstall.
  Attempting uninstall: requests
    Found existing installation: requests 2.21.0
    Not uninstalling requests at /cvmfs/soft.computecanada.ca/easybuild/software/2017/Core/scipy-stack/2019a/lib/python3.7/site-packages, outside environment /localscratch/yinan.29031137.0/env
    Can't uninstall 'requests'. No files were found to uninstall.
Successfully installed boto3-1.20.52+computecanada botocore-1.23.52+computecanada charset-normalizer-2.0.11+computecanada filelock-3.4.2+computecanada jmespath-0.10.0+computecanada joblib-1.1.0+computecanada regex-2020.11.13+computecanada requests-2.27.1+computecanada s3transfer-0.5.1+computecanada sacremoses-0.0.46+computecanada sentencepiece-0.1.91+computecanada tokenizers-0.5.2+computecanada tqdm-4.63.0+computecanada transformers-2.5.1+computecanada urllib3-1.26.8+computecanada
Looking in links: /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/nix/avx2, /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/nix/generic, /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/tensorflow_gpu-2.3.0+computecanada-cp37-cp37m-linux_x86_64.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/tensorboard-2.8.0+computecanada-py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/gast-0.3.3+computecanada-py3-none-any.whl
Requirement already satisfied: six>=1.12.0 in /localscratch/yinan.29031137.0/env/lib/python3.7/site-packages (from tensorflow_gpu==2.3.0+computecanada) (1.16.0+computecanada)
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/wrapt-1.11.2+computecanada-cp37-cp37m-linux_x86_64.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/nix/generic/scipy-1.4.1+computecanada-cp37-cp37m-linux_x86_64.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/nix/avx2/h5py-2.10.0+computecanada-cp37-cp37m-linux_x86_64.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/absl_py-1.0.0+computecanada-py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/astunparse-1.6.3+computecanada-py2.py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/google_pasta-0.2.0+computecanada-py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/Keras_Preprocessing-1.1.2+computecanada-py3-none-any.whl
Requirement already satisfied: protobuf>=3.9.2 in /localscratch/yinan.29031137.0/env/lib/python3.7/site-packages (from tensorflow_gpu==2.3.0+computecanada) (3.19.4+computecanada)
Requirement already satisfied: numpy<1.19.0,>=1.16.0 in /cvmfs/soft.computecanada.ca/easybuild/software/2017/Core/scipy-stack/2019a/lib/python3.7/site-packages (from tensorflow_gpu==2.3.0+computecanada) (1.16.0)
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/opt_einsum-3.3.0+computecanada-py3-none-any.whl
Requirement already satisfied: termcolor>=1.1.0 in /localscratch/yinan.29031137.0/env/lib/python3.7/site-packages (from tensorflow_gpu==2.3.0+computecanada) (1.1.0+computecanada)
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/grpcio-1.38.0+computecanada-cp37-cp37m-linux_x86_64.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/tensorflow_estimator-2.3.0+computecanada-py2.py3-none-any.whl
Requirement already satisfied: wheel>=0.26 in /localscratch/yinan.29031137.0/env/lib/python3.7/site-packages (from tensorflow_gpu==2.3.0+computecanada) (0.33.4)
Requirement already satisfied: setuptools>=41.0.0 in /localscratch/yinan.29031137.0/env/lib/python3.7/site-packages (from tensorboard<3,>=2.3.0->tensorflow_gpu==2.3.0+computecanada) (41.0.1)
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/Markdown-3.3.6+computecanada-py3-none-any.whl
Requirement already satisfied: requests<3,>=2.21.0 in /localscratch/yinan.29031137.0/env/lib/python3.7/site-packages (from tensorboard<3,>=2.3.0->tensorflow_gpu==2.3.0+computecanada) (2.27.1+computecanada)
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/Werkzeug-2.0.3+computecanada-py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/tensorboard_plugin_wit-1.8.0+computecanada-py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/google_auth-2.3.3+computecanada-py2.py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/tensorboard_data_server-0.6.1+computecanada-py3-none-linux_x86_64.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/google_auth_oauthlib-0.4.6+computecanada-py2.py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/rsa-4.8+computecanada-py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/cachetools-4.2.4+computecanada-py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/pyasn1_modules-0.2.8+computecanada-py2.py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/requests_oauthlib-1.3.0+computecanada-py2.py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/importlib_metadata-4.10.1+computecanada-py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/zipp-3.7.0+computecanada-py3-none-any.whl
Requirement already satisfied: typing-extensions>=3.6.4 in /localscratch/yinan.29031137.0/env/lib/python3.7/site-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard<3,>=2.3.0->tensorflow_gpu==2.3.0+computecanada) (4.0.1+computecanada)
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/pyasn1-0.4.8+computecanada-py2.py3-none-any.whl
Requirement already satisfied: idna<4,>=2.5 in /cvmfs/soft.computecanada.ca/easybuild/software/2017/Core/scipy-stack/2019a/lib/python3.7/site-packages (from requests<3,>=2.21.0->tensorboard<3,>=2.3.0->tensorflow_gpu==2.3.0+computecanada) (2.8)
Requirement already satisfied: certifi>=2017.4.17 in /cvmfs/soft.computecanada.ca/easybuild/software/2017/Core/scipy-stack/2019a/lib/python3.7/site-packages (from requests<3,>=2.21.0->tensorboard<3,>=2.3.0->tensorflow_gpu==2.3.0+computecanada) (2018.11.29)
Requirement already satisfied: urllib3<1.27,>=1.21.1 in /localscratch/yinan.29031137.0/env/lib/python3.7/site-packages (from requests<3,>=2.21.0->tensorboard<3,>=2.3.0->tensorflow_gpu==2.3.0+computecanada) (1.26.8+computecanada)
Requirement already satisfied: charset-normalizer~=2.0.0 in /localscratch/yinan.29031137.0/env/lib/python3.7/site-packages (from requests<3,>=2.21.0->tensorboard<3,>=2.3.0->tensorflow_gpu==2.3.0+computecanada) (2.0.11+computecanada)
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/oauthlib-3.1.1+computecanada-py2.py3-none-any.whl
Installing collected packages: pyasn1, zipp, rsa, pyasn1-modules, oauthlib, cachetools, requests-oauthlib, importlib-metadata, google-auth, werkzeug, tensorboard-plugin-wit, tensorboard-data-server, markdown, grpcio, google-auth-oauthlib, absl-py, wrapt, tensorflow-estimator, tensorboard, scipy, opt-einsum, keras-preprocessing, h5py, google-pasta, gast, astunparse, tensorflow-gpu
  Attempting uninstall: pyasn1
    Found existing installation: pyasn1 0.4.3
    Not uninstalling pyasn1 at /cvmfs/soft.computecanada.ca/easybuild/software/2017/Core/scipy-stack/2019a/lib/python3.7/site-packages, outside environment /localscratch/yinan.29031137.0/env
    Can't uninstall 'pyasn1'. No files were found to uninstall.
  Attempting uninstall: zipp
    Found existing installation: zipp 0.3.3
    Not uninstalling zipp at /cvmfs/soft.computecanada.ca/easybuild/software/2017/Core/scipy-stack/2019a/lib/python3.7/site-packages, outside environment /localscratch/yinan.29031137.0/env
    Can't uninstall 'zipp'. No files were found to uninstall.
  Attempting uninstall: importlib-metadata
    Found existing installation: importlib-metadata 0.8
    Not uninstalling importlib-metadata at /cvmfs/soft.computecanada.ca/easybuild/software/2017/Core/scipy-stack/2019a/lib/python3.7/site-packages, outside environment /localscratch/yinan.29031137.0/env
    Can't uninstall 'importlib-metadata'. No files were found to uninstall.
  Attempting uninstall: scipy
    Found existing installation: scipy 1.2.0
    Not uninstalling scipy at /cvmfs/soft.computecanada.ca/easybuild/software/2017/Core/scipy-stack/2019a/lib/python3.7/site-packages, outside environment /localscratch/yinan.29031137.0/env
    Can't uninstall 'scipy'. No files were found to uninstall.
Successfully installed absl-py-1.0.0+computecanada astunparse-1.6.3+computecanada cachetools-4.2.4+computecanada gast-0.3.3+computecanada google-auth-2.3.3+computecanada google-auth-oauthlib-0.4.6+computecanada google-pasta-0.2.0+computecanada grpcio-1.38.0+computecanada h5py-2.10.0+computecanada importlib-metadata-4.10.1+computecanada keras-preprocessing-1.1.2+computecanada markdown-3.3.6+computecanada oauthlib-3.1.1+computecanada opt-einsum-3.3.0+computecanada pyasn1-0.4.8+computecanada pyasn1-modules-0.2.8+computecanada requests-oauthlib-1.3.0+computecanada rsa-4.8+computecanada scipy-1.4.1+computecanada tensorboard-2.8.0+computecanada tensorboard-data-server-0.6.1+computecanada tensorboard-plugin-wit-1.8.0+computecanada tensorflow-estimator-2.3.0+computecanada tensorflow-gpu-2.3.0+computecanada werkzeug-2.0.3+computecanada wrapt-1.11.2+computecanada zipp-3.7.0+computecanada
Looking in links: /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/nix/avx2, /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/nix/generic, /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/keras-2.8.0+computecanada-py2.py3-none-any.whl
Installing collected packages: Keras
Successfully installed Keras-2.8.0+computecanada
Looking in links: /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/nix/avx2, /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/nix/generic, /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/urllib3-1.26.7+computecanada-py2.py3-none-any.whl
Installing collected packages: urllib3
  Attempting uninstall: urllib3
    Found existing installation: urllib3 1.26.8+computecanada
    Uninstalling urllib3-1.26.8+computecanada:
      Successfully uninstalled urllib3-1.26.8+computecanada
Successfully installed urllib3-1.26.7+computecanada
Looking in links: /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/nix/avx2, /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/nix/generic, /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/nltk-3.7+computecanada-py3-none-any.whl
Requirement already satisfied: joblib in /localscratch/yinan.29031137.0/env/lib/python3.7/site-packages (from nltk) (1.1.0+computecanada)
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/nltk-3.6.5+computecanada-py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/nltk-3.6.3+computecanada-py3-none-any.whl
Requirement already satisfied: regex in /localscratch/yinan.29031137.0/env/lib/python3.7/site-packages (from nltk) (2020.11.13+computecanada)
Requirement already satisfied: click in /localscratch/yinan.29031137.0/env/lib/python3.7/site-packages (from nltk) (8.0.3+computecanada)
Requirement already satisfied: tqdm in /localscratch/yinan.29031137.0/env/lib/python3.7/site-packages (from nltk) (4.63.0+computecanada)
Requirement already satisfied: importlib-metadata in /localscratch/yinan.29031137.0/env/lib/python3.7/site-packages (from click->nltk) (4.10.1+computecanada)
Requirement already satisfied: typing-extensions>=3.6.4 in /localscratch/yinan.29031137.0/env/lib/python3.7/site-packages (from importlib-metadata->click->nltk) (4.0.1+computecanada)
Requirement already satisfied: zipp>=0.5 in /localscratch/yinan.29031137.0/env/lib/python3.7/site-packages (from importlib-metadata->click->nltk) (3.7.0+computecanada)
Installing collected packages: nltk
Successfully installed nltk-3.6.3+computecanada
Looking in links: /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/nix/avx2, /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/nix/generic, /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/scikit_learn-0.22.1+computecanada-cp37-cp37m-linux_x86_64.whl
Requirement already satisfied: joblib>=0.11 in /localscratch/yinan.29031137.0/env/lib/python3.7/site-packages (from scikit-learn==0.22.1) (1.1.0+computecanada)
Requirement already satisfied: scipy>=0.17.0 in /localscratch/yinan.29031137.0/env/lib/python3.7/site-packages (from scikit-learn==0.22.1) (1.4.1+computecanada)
Requirement already satisfied: numpy>=1.11.0 in /cvmfs/soft.computecanada.ca/easybuild/software/2017/Core/scipy-stack/2019a/lib/python3.7/site-packages (from scikit-learn==0.22.1) (1.16.0)
Installing collected packages: scikit-learn
Successfully installed scikit-learn-0.22.1+computecanada
Looking in links: /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/nix/avx2, /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/nix/generic, /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic
Requirement already satisfied: tokenizers==0.5.2 in /localscratch/yinan.29031137.0/env/lib/python3.7/site-packages (0.5.2+computecanada)
wandb: Appending key for api.wandb.ai to your netrc file: /home/yinan/.netrc
Starting Task
2022-03-16 04:53:28.720250: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1
[nltk_data] Downloading package stopwords to /home/yinan/nltk_data...
[nltk_data]   Package stopwords is already up-to-date!
[nltk_data] Downloading package wordnet to /home/yinan/nltk_data...
[nltk_data]   Package wordnet is already up-to-date!
wandb: Currently logged in as: yinanazhou (use `wandb login --relogin` to force relogin)
wandb: wandb version 0.12.11 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
2022-03-16 04:53:39.768218: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1
wandb: Tracking run with wandb version 0.12.5
wandb: Syncing run proud-snow-3
wandb: ⭐️ View project at https://wandb.ai/yinanazhou/xl_512_bs_8_lr_1e06_es_5_lc_True_nr_False_sr_True_stem_False_lemma_False_repeat_1_fold_1
wandb: 🚀 View run at https://wandb.ai/yinanazhou/xl_512_bs_8_lr_1e06_es_5_lc_True_nr_False_sr_True_stem_False_lemma_False_repeat_1_fold_1/runs/28w8c0g9
wandb: Run data is saved locally in /project/6002780/yinan/Thesis_MER_Lyrics/lyric-emotion/wandb/run-20220316_045337-28w8c0g9
wandb: Run `wandb offline` to turn off syncing.

Validation loss decreased (inf --> 1.438751).  Saving model ...
Validation loss decreased (1.438751 --> 1.418951).  Saving model ...
Validation loss decreased (1.418951 --> 1.403289).  Saving model ...
Validation loss decreased (1.403289 --> 1.389923).  Saving model ...
Validation loss decreased (1.389923 --> 1.379769).  Saving model ...
Validation loss decreased (1.379769 --> 1.370931).  Saving model ...
Validation loss decreased (1.370931 --> 1.363271).  Saving model ...
Validation loss decreased (1.363271 --> 1.356312).  Saving model ...
Validation loss decreased (1.356312 --> 1.349979).  Saving model ...
Validation loss decreased (1.349979 --> 1.343323).  Saving model ...
Validation loss decreased (1.343323 --> 1.336362).  Saving model ...
Validation loss decreased (1.336362 --> 1.330191).  Saving model ...
Validation loss decreased (1.330191 --> 1.323821).  Saving model ...
Validation loss decreased (1.323821 --> 1.317705).  Saving model ...
Validation loss decreased (1.317705 --> 1.311222).  Saving model ...
Validation loss decreased (1.311222 --> 1.304461).  Saving model ...
Validation loss decreased (1.304461 --> 1.297779).  Saving model ...
Validation loss decreased (1.297779 --> 1.290949).  Saving model ...
Validation loss decreased (1.290949 --> 1.283989).  Saving model ...
Validation loss decreased (1.283989 --> 1.277859).  Saving model ...
Validation loss decreased (1.277859 --> 1.271250).  Saving model ...
Validation loss decreased (1.271250 --> 1.263335).  Saving model ...
Validation loss decreased (1.263335 --> 1.256937).  Saving model ...
Validation loss decreased (1.256937 --> 1.249202).  Saving model ...
Validation loss decreased (1.249202 --> 1.243923).  Saving model ...
Validation loss decreased (1.243923 --> 1.236385).  Saving model ...
Validation loss decreased (1.236385 --> 1.229786).  Saving model ...
Validation loss decreased (1.229786 --> 1.225042).  Saving model ...
Validation loss decreased (1.225042 --> 1.220232).  Saving model ...
Validation loss decreased (1.220232 --> 1.215213).  Saving model ...
Validation loss decreased (1.215213 --> 1.209694).  Saving model ...
Validation loss decreased (1.209694 --> 1.204692).  Saving model ...
Validation loss decreased (1.204692 --> 1.200113).  Saving model ...
Validation loss decreased (1.200113 --> 1.193838).  Saving model ...
Validation loss decreased (1.193838 --> 1.190156).  Saving model ...
Validation loss decreased (1.190156 --> 1.185947).  Saving model ...
Validation loss decreased (1.185947 --> 1.181116).  Saving model ...
Validation loss decreased (1.181116 --> 1.176395).  Saving model ...
Validation loss decreased (1.176395 --> 1.173479).  Saving model ...
Validation loss decreased (1.173479 --> 1.171065).  Saving model ...
Validation loss decreased (1.171065 --> 1.164059).  Saving model ...
Validation loss decreased (1.164059 --> 1.159869).  Saving model ...
Validation loss decreased (1.159869 --> 1.158189).  Saving model ...
Validation loss decreased (1.158189 --> 1.153697).  Saving model ...
Validation loss decreased (1.153697 --> 1.149670).  Saving model ...
Validation loss decreased (1.149670 --> 1.143968).  Saving model ...
Validation loss decreased (1.143968 --> 1.140727).  Saving model ...
Validation loss decreased (1.140727 --> 1.139116).  Saving model ...
Validation loss decreased (1.139116 --> 1.132226).  Saving model ...
Validation loss decreased (1.132226 --> 1.127853).  Saving model ...
Validation loss decreased (1.127853 --> 1.123505).  Saving model ...
Validation loss decreased (1.123505 --> 1.119249).  Saving model ...
Validation loss decreased (1.119249 --> 1.117118).  Saving model ...
Validation loss decreased (1.117118 --> 1.115362).  Saving model ...
Validation loss decreased (1.115362 --> 1.113534).  Saving model ...
Validation loss decreased (1.113534 --> 1.107802).  Saving model ...
Validation loss decreased (1.107802 --> 1.105366).  Saving model ...
Validation loss decreased (1.105366 --> 1.101634).  Saving model ...
Validation loss decreased (1.101634 --> 1.096751).  Saving model ...
Validation loss decreased (1.096751 --> 1.095560).  Saving model ...
Validation loss decreased (1.095560 --> 1.090876).  Saving model ...
Validation loss decreased (1.090876 --> 1.087604).  Saving model ...
Validation loss decreased (1.087604 --> 1.083187).  Saving model ...
Validation loss decreased (1.083187 --> 1.081971).  Saving model ...
Validation loss decreased (1.081971 --> 1.081882).  Saving model ...
Validation loss decreased (1.081882 --> 1.075714).  Saving model ...
EarlyStopping counter: 1 out of 5.0
Validation loss decreased (1.075714 --> 1.069536).  Saving model ...
Validation loss decreased (1.069536 --> 1.067538).  Saving model ...
Validation loss decreased (1.067538 --> 1.065469).  Saving model ...
Validation loss decreased (1.065469 --> 1.061253).  Saving model ...
Validation loss decreased (1.061253 --> 1.059912).  Saving model ...
Validation loss decreased (1.059912 --> 1.057221).  Saving model ...
Validation loss decreased (1.057221 --> 1.055016).  Saving model ...
Validation loss decreased (1.055016 --> 1.051605).  Saving model ...
Validation loss decreased (1.051605 --> 1.048695).  Saving model ...
Validation loss decreased (1.048695 --> 1.048339).  Saving model ...
Validation loss decreased (1.048339 --> 1.047874).  Saving model ...
Validation loss decreased (1.047874 --> 1.042140).  Saving model ...
Validation loss decreased (1.042140 --> 1.038831).  Saving model ...
Validation loss decreased (1.038831 --> 1.037597).  Saving model ...
EarlyStopping counter: 1 out of 5.0
Validation loss decreased (1.037597 --> 1.036116).  Saving model ...
Validation loss decreased (1.036116 --> 1.035876).  Saving model ...
Validation loss decreased (1.035876 --> 1.031280).  Saving model ...
Validation loss decreased (1.031280 --> 1.030312).  Saving model ...
Validation loss decreased (1.030312 --> 1.027784).  Saving model ...
Validation loss decreased (1.027784 --> 1.027054).  Saving model ...
Validation loss decreased (1.027054 --> 1.023174).  Saving model ...
Validation loss decreased (1.023174 --> 1.021052).  Saving model ...
Validation loss decreased (1.021052 --> 1.020149).  Saving model ...
Validation loss decreased (1.020149 --> 1.018719).  Saving model ...
Validation loss decreased (1.018719 --> 1.018044).  Saving model ...
EarlyStopping counter: 1 out of 5.0
Validation loss decreased (1.018044 --> 1.017023).  Saving model ...
Validation loss decreased (1.017023 --> 1.015802).  Saving model ...
Validation loss decreased (1.015802 --> 1.013845).  Saving model ...
Validation loss decreased (1.013845 --> 1.011273).  Saving model ...
Validation loss decreased (1.011273 --> 1.009174).  Saving model ...
Validation loss decreased (1.009174 --> 1.009171).  Saving model ...
Validation loss decreased (1.009171 --> 1.007543).  Saving model ...
EarlyStopping counter: 1 out of 5.0
Validation loss decreased (1.007543 --> 1.006352).  Saving model ...
Validation loss decreased (1.006352 --> 1.004243).  Saving model ...
Validation loss decreased (1.004243 --> 1.003232).  Saving model ...
Validation loss decreased (1.003232 --> 0.998866).  Saving model ...
Validation loss decreased (0.998866 --> 0.998735).  Saving model ...
Validation loss decreased (0.998735 --> 0.997981).  Saving model ...
Validation loss decreased (0.997981 --> 0.996418).  Saving model ...
Validation loss decreased (0.996418 --> 0.995420).  Saving model ...
EarlyStopping counter: 1 out of 5.0
EarlyStopping counter: 2 out of 5.0
EarlyStopping counter: 3 out of 5.0
Validation loss decreased (0.995420 --> 0.994424).  Saving model ...
EarlyStopping counter: 1 out of 5.0
Validation loss decreased (0.994424 --> 0.992114).  Saving model ...
Validation loss decreased (0.992114 --> 0.989436).  Saving model ...
Validation loss decreased (0.989436 --> 0.989183).  Saving model ...
EarlyStopping counter: 1 out of 5.0
Validation loss decreased (0.989183 --> 0.987726).  Saving model ...
Validation loss decreased (0.987726 --> 0.987347).  Saving model ...
EarlyStopping counter: 1 out of 5.0
Validation loss decreased (0.987347 --> 0.983901).  Saving model ...
EarlyStopping counter: 1 out of 5.0
Validation loss decreased (0.983901 --> 0.983594).  Saving model ...
EarlyStopping counter: 1 out of 5.0
EarlyStopping counter: 2 out of 5.0
Validation loss decreased (0.983594 --> 0.983022).  Saving model ...
EarlyStopping counter: 1 out of 5.0
EarlyStopping counter: 2 out of 5.0
EarlyStopping counter: 3 out of 5.0
EarlyStopping counter: 4 out of 5.0
EarlyStopping counter: 5 out of 5.0
/localscratch/yinan.29031137.0/env/lib/python3.7/site-packages/torch/nn/functional.py:1794: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.
  warnings.warn("nn.functional.tanh is deprecated. Use torch.tanh instead.")
/localscratch/yinan.29031137.0/env/lib/python3.7/site-packages/transformers/optimization.py:155: UserWarning: This overload of add_ is deprecated:
	add_(Number alpha, Tensor other)
Consider using one of the following signatures instead:
	add_(Tensor other, *, Number alpha) (Triggered internally at  ../torch/csrc/utils/python_arg_parser.cpp:1025.)
  exp_avg.mul_(beta1).add_(1.0 - beta1, grad)
wandb: Waiting for W&B process to finish, PID 65913... (success).
wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: \ 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: | 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: / 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: \ 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: | 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: / 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: \ 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: | 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb:                                                                                
wandb: Run history:
wandb:     e_F1 ▁▂▃▄▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇██▇████████
wandb:   e_loss ██▇▇▆▆▆▅▅▅▄▄▄▄▄▃▃▃▃▃▂▂▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁
wandb:     t_F1 ▁▁▂▃▃▃▄▄▄▅▅▅▆▆▆▆▆▆▇▆▆▇▇▇▇▇▇▇▇▇▇█████████
wandb:   t_loss ██▇▇▇▇▆▆▆▅▅▅▅▄▄▄▄▄▃▃▃▃▃▃▃▃▂▂▂▂▂▂▂▂▂▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:     e_F1 57.64728
wandb:   e_loss 0.98475
wandb:     t_F1 70.47087
wandb:   t_loss 0.75332
wandb: 
wandb: Synced 4 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Synced proud-snow-3: https://wandb.ai/yinanazhou/xl_512_bs_8_lr_1e06_es_5_lc_True_nr_False_sr_True_stem_False_lemma_False_repeat_1_fold_1/runs/28w8c0g9
wandb: Find logs at: ./wandb/run-20220316_045337-28w8c0g9/logs/debug.log
wandb: 

wandb: wandb version 0.12.11 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
2022-03-16 06:19:07.028669: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1
wandb: Tracking run with wandb version 0.12.5
wandb: Syncing run faithful-energy-3
wandb: ⭐️ View project at https://wandb.ai/yinanazhou/xl_512_bs_8_lr_1e06_es_5_lc_True_nr_False_sr_True_stem_False_lemma_False_repeat_1_fold_2
wandb: 🚀 View run at https://wandb.ai/yinanazhou/xl_512_bs_8_lr_1e06_es_5_lc_True_nr_False_sr_True_stem_False_lemma_False_repeat_1_fold_2/runs/1dyy4x1c
wandb: Run data is saved locally in /project/6002780/yinan/Thesis_MER_Lyrics/lyric-emotion/wandb/run-20220316_061904-1dyy4x1c
wandb: Run `wandb offline` to turn off syncing.

Validation loss decreased (inf --> 1.453819).  Saving model ...
Validation loss decreased (1.453819 --> 1.430368).  Saving model ...
Validation loss decreased (1.430368 --> 1.412101).  Saving model ...
Validation loss decreased (1.412101 --> 1.397362).  Saving model ...
Validation loss decreased (1.397362 --> 1.386510).  Saving model ...
Validation loss decreased (1.386510 --> 1.377620).  Saving model ...
Validation loss decreased (1.377620 --> 1.370103).  Saving model ...
Validation loss decreased (1.370103 --> 1.363401).  Saving model ...
Validation loss decreased (1.363401 --> 1.356783).  Saving model ...
Validation loss decreased (1.356783 --> 1.351308).  Saving model ...
Validation loss decreased (1.351308 --> 1.345903).  Saving model ...
Validation loss decreased (1.345903 --> 1.340751).  Saving model ...
Validation loss decreased (1.340751 --> 1.334688).  Saving model ...
Validation loss decreased (1.334688 --> 1.327972).  Saving model ...
Validation loss decreased (1.327972 --> 1.321900).  Saving model ...
Validation loss decreased (1.321900 --> 1.315908).  Saving model ...
Validation loss decreased (1.315908 --> 1.308926).  Saving model ...
Validation loss decreased (1.308926 --> 1.302182).  Saving model ...
Validation loss decreased (1.302182 --> 1.295028).  Saving model ...
Validation loss decreased (1.295028 --> 1.288894).  Saving model ...
Validation loss decreased (1.288894 --> 1.282365).  Saving model ...
Validation loss decreased (1.282365 --> 1.274913).  Saving model ...
Validation loss decreased (1.274913 --> 1.266453).  Saving model ...
Validation loss decreased (1.266453 --> 1.258539).  Saving model ...
Validation loss decreased (1.258539 --> 1.251040).  Saving model ...
Validation loss decreased (1.251040 --> 1.243854).  Saving model ...
Validation loss decreased (1.243854 --> 1.236720).  Saving model ...
Validation loss decreased (1.236720 --> 1.229597).  Saving model ...
Validation loss decreased (1.229597 --> 1.221566).  Saving model ...
Validation loss decreased (1.221566 --> 1.213911).  Saving model ...
Validation loss decreased (1.213911 --> 1.205739).  Saving model ...
Validation loss decreased (1.205739 --> 1.197864).  Saving model ...
Validation loss decreased (1.197864 --> 1.190487).  Saving model ...
Validation loss decreased (1.190487 --> 1.181948).  Saving model ...
Validation loss decreased (1.181948 --> 1.175170).  Saving model ...
Validation loss decreased (1.175170 --> 1.167090).  Saving model ...
Validation loss decreased (1.167090 --> 1.160747).  Saving model ...
Validation loss decreased (1.160747 --> 1.153890).  Saving model ...
Validation loss decreased (1.153890 --> 1.145147).  Saving model ...
Validation loss decreased (1.145147 --> 1.136183).  Saving model ...
Validation loss decreased (1.136183 --> 1.128154).  Saving model ...
Validation loss decreased (1.128154 --> 1.121968).  Saving model ...
Validation loss decreased (1.121968 --> 1.116187).  Saving model ...
Validation loss decreased (1.116187 --> 1.110816).  Saving model ...
Validation loss decreased (1.110816 --> 1.104362).  Saving model ...
Validation loss decreased (1.104362 --> 1.098450).  Saving model ...
Validation loss decreased (1.098450 --> 1.093248).  Saving model ...
Validation loss decreased (1.093248 --> 1.087163).  Saving model ...
Validation loss decreased (1.087163 --> 1.078162).  Saving model ...
Validation loss decreased (1.078162 --> 1.073030).  Saving model ...
Validation loss decreased (1.073030 --> 1.067003).  Saving model ...
Validation loss decreased (1.067003 --> 1.062056).  Saving model ...
Validation loss decreased (1.062056 --> 1.055734).  Saving model ...
Validation loss decreased (1.055734 --> 1.050984).  Saving model ...
Validation loss decreased (1.050984 --> 1.045201).  Saving model ...
Validation loss decreased (1.045201 --> 1.041059).  Saving model ...
Validation loss decreased (1.041059 --> 1.038494).  Saving model ...
Validation loss decreased (1.038494 --> 1.033589).  Saving model ...
Validation loss decreased (1.033589 --> 1.027829).  Saving model ...
Validation loss decreased (1.027829 --> 1.024018).  Saving model ...
Validation loss decreased (1.024018 --> 1.020140).  Saving model ...
Validation loss decreased (1.020140 --> 1.015812).  Saving model ...
Validation loss decreased (1.015812 --> 1.012296).  Saving model ...
Validation loss decreased (1.012296 --> 1.008689).  Saving model ...
Validation loss decreased (1.008689 --> 1.005202).  Saving model ...
Validation loss decreased (1.005202 --> 1.001642).  Saving model ...
Validation loss decreased (1.001642 --> 0.996843).  Saving model ...
Validation loss decreased (0.996843 --> 0.993712).  Saving model ...
Validation loss decreased (0.993712 --> 0.989794).  Saving model ...
Validation loss decreased (0.989794 --> 0.986912).  Saving model ...
Validation loss decreased (0.986912 --> 0.984191).  Saving model ...
Validation loss decreased (0.984191 --> 0.981663).  Saving model ...
Validation loss decreased (0.981663 --> 0.979642).  Saving model ...
Validation loss decreased (0.979642 --> 0.976880).  Saving model ...
Validation loss decreased (0.976880 --> 0.975990).  Saving model ...
Validation loss decreased (0.975990 --> 0.969007).  Saving model ...
Validation loss decreased (0.969007 --> 0.965606).  Saving model ...
Validation loss decreased (0.965606 --> 0.964377).  Saving model ...
Validation loss decreased (0.964377 --> 0.960464).  Saving model ...
Validation loss decreased (0.960464 --> 0.957299).  Saving model ...
EarlyStopping counter: 1 out of 5.0
Validation loss decreased (0.957299 --> 0.953846).  Saving model ...
Validation loss decreased (0.953846 --> 0.953221).  Saving model ...
Validation loss decreased (0.953221 --> 0.951009).  Saving model ...
Validation loss decreased (0.951009 --> 0.947675).  Saving model ...
Validation loss decreased (0.947675 --> 0.944982).  Saving model ...
Validation loss decreased (0.944982 --> 0.943317).  Saving model ...
Validation loss decreased (0.943317 --> 0.940190).  Saving model ...
EarlyStopping counter: 1 out of 5.0
Validation loss decreased (0.940190 --> 0.939063).  Saving model ...
Validation loss decreased (0.939063 --> 0.936679).  Saving model ...
Validation loss decreased (0.936679 --> 0.933326).  Saving model ...
Validation loss decreased (0.933326 --> 0.931811).  Saving model ...
EarlyStopping counter: 1 out of 5.0
Validation loss decreased (0.931811 --> 0.929058).  Saving model ...
Validation loss decreased (0.929058 --> 0.928642).  Saving model ...
EarlyStopping counter: 1 out of 5.0
Validation loss decreased (0.928642 --> 0.926883).  Saving model ...
Validation loss decreased (0.926883 --> 0.925993).  Saving model ...
Validation loss decreased (0.925993 --> 0.923557).  Saving model ...
Validation loss decreased (0.923557 --> 0.922258).  Saving model ...
EarlyStopping counter: 1 out of 5.0
EarlyStopping counter: 2 out of 5.0
EarlyStopping counter: 3 out of 5.0
Validation loss decreased (0.922258 --> 0.920400).  Saving model ...
Validation loss decreased (0.920400 --> 0.919656).  Saving model ...
Validation loss decreased (0.919656 --> 0.917938).  Saving model ...
Validation loss decreased (0.917938 --> 0.917299).  Saving model ...
EarlyStopping counter: 1 out of 5.0
Validation loss decreased (0.917299 --> 0.914874).  Saving model ...
Validation loss decreased (0.914874 --> 0.913980).  Saving model ...
EarlyStopping counter: 1 out of 5.0
EarlyStopping counter: 2 out of 5.0
EarlyStopping counter: 3 out of 5.0
Validation loss decreased (0.913980 --> 0.912913).  Saving model ...
Validation loss decreased (0.912913 --> 0.911233).  Saving model ...
EarlyStopping counter: 1 out of 5.0
EarlyStopping counter: 2 out of 5.0
EarlyStopping counter: 3 out of 5.0
EarlyStopping counter: 4 out of 5.0
EarlyStopping counter: 5 out of 5.0
/localscratch/yinan.29031137.0/env/lib/python3.7/site-packages/torch/nn/functional.py:1794: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.
  warnings.warn("nn.functional.tanh is deprecated. Use torch.tanh instead.")
wandb: Waiting for W&B process to finish, PID 70526... (success).
wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: \ 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: | 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: / 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: \ 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: | 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: / 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: \ 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: | 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb:                                                                                
wandb: Run history:
wandb:     e_F1 ▁▃▃▄▄▅▅▅▅▅▆▆▆▇▇▇▇▇▇▇████████████████████
wandb:   e_loss █▇▇▇▆▆▆▆▅▅▅▄▄▄▄▃▃▃▃▃▂▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁
wandb:     t_F1 ▁▁▂▂▃▃▃▄▄▄▄▅▅▅▅▅▆▆▆▆▆▆▇▇▇▇▇▇▇█▇█▇█▇█▇███
wandb:   t_loss ██▇▇▇▇▇▆▆▆▆▆▅▅▅▄▄▄▄▄▄▄▃▃▃▃▃▃▂▂▂▂▂▂▂▂▁▁▁▁
wandb: 
wandb: Run summary:
wandb:     e_F1 59.96294
wandb:   e_loss 0.9116
wandb:     t_F1 71.01148
wandb:   t_loss 0.77814
wandb: 
wandb: Synced 4 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Synced faithful-energy-3: https://wandb.ai/yinanazhou/xl_512_bs_8_lr_1e06_es_5_lc_True_nr_False_sr_True_stem_False_lemma_False_repeat_1_fold_2/runs/1dyy4x1c
wandb: Find logs at: ./wandb/run-20220316_061904-1dyy4x1c/logs/debug.log
wandb: 

wandb: wandb version 0.12.11 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
2022-03-16 07:36:15.514090: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1
wandb: Tracking run with wandb version 0.12.5
wandb: Syncing run lucky-sunset-2
wandb: ⭐️ View project at https://wandb.ai/yinanazhou/xl_512_bs_8_lr_1e06_es_5_lc_True_nr_False_sr_True_stem_False_lemma_False_repeat_2_fold_1
wandb: 🚀 View run at https://wandb.ai/yinanazhou/xl_512_bs_8_lr_1e06_es_5_lc_True_nr_False_sr_True_stem_False_lemma_False_repeat_2_fold_1/runs/1tw5rjry
wandb: Run data is saved locally in /project/6002780/yinan/Thesis_MER_Lyrics/lyric-emotion/wandb/run-20220316_073611-1tw5rjry
wandb: Run `wandb offline` to turn off syncing.

Validation loss decreased (inf --> 1.421273).  Saving model ...
Validation loss decreased (1.421273 --> 1.408959).  Saving model ...
Validation loss decreased (1.408959 --> 1.399722).  Saving model ...
Validation loss decreased (1.399722 --> 1.392076).  Saving model ...
Validation loss decreased (1.392076 --> 1.385553).  Saving model ...
Validation loss decreased (1.385553 --> 1.379879).  Saving model ...
Validation loss decreased (1.379879 --> 1.374075).  Saving model ...
Validation loss decreased (1.374075 --> 1.369141).  Saving model ...
Validation loss decreased (1.369141 --> 1.364324).  Saving model ...
Validation loss decreased (1.364324 --> 1.359946).  Saving model ...
Validation loss decreased (1.359946 --> 1.354568).  Saving model ...
Validation loss decreased (1.354568 --> 1.349547).  Saving model ...
Validation loss decreased (1.349547 --> 1.344657).  Saving model ...
Validation loss decreased (1.344657 --> 1.339351).  Saving model ...
Validation loss decreased (1.339351 --> 1.333954).  Saving model ...
Validation loss decreased (1.333954 --> 1.328216).  Saving model ...
Validation loss decreased (1.328216 --> 1.322111).  Saving model ...
Validation loss decreased (1.322111 --> 1.315774).  Saving model ...
Validation loss decreased (1.315774 --> 1.309266).  Saving model ...
Validation loss decreased (1.309266 --> 1.301588).  Saving model ...
Validation loss decreased (1.301588 --> 1.294790).  Saving model ...
Validation loss decreased (1.294790 --> 1.286923).  Saving model ...
Validation loss decreased (1.286923 --> 1.278108).  Saving model ...
Validation loss decreased (1.278108 --> 1.269661).  Saving model ...
Validation loss decreased (1.269661 --> 1.261219).  Saving model ...
Validation loss decreased (1.261219 --> 1.252625).  Saving model ...
Validation loss decreased (1.252625 --> 1.245952).  Saving model ...
Validation loss decreased (1.245952 --> 1.237777).  Saving model ...
Validation loss decreased (1.237777 --> 1.227681).  Saving model ...
Validation loss decreased (1.227681 --> 1.220126).  Saving model ...
Validation loss decreased (1.220126 --> 1.212620).  Saving model ...
Validation loss decreased (1.212620 --> 1.204368).  Saving model ...
Validation loss decreased (1.204368 --> 1.195375).  Saving model ...
Validation loss decreased (1.195375 --> 1.186661).  Saving model ...
Validation loss decreased (1.186661 --> 1.178633).  Saving model ...
Validation loss decreased (1.178633 --> 1.171451).  Saving model ...
Validation loss decreased (1.171451 --> 1.163279).  Saving model ...
Validation loss decreased (1.163279 --> 1.155633).  Saving model ...
Validation loss decreased (1.155633 --> 1.148289).  Saving model ...
Validation loss decreased (1.148289 --> 1.142385).  Saving model ...
Validation loss decreased (1.142385 --> 1.135855).  Saving model ...
Validation loss decreased (1.135855 --> 1.128830).  Saving model ...
Validation loss decreased (1.128830 --> 1.122180).  Saving model ...
Validation loss decreased (1.122180 --> 1.116329).  Saving model ...
Validation loss decreased (1.116329 --> 1.110188).  Saving model ...
Validation loss decreased (1.110188 --> 1.104379).  Saving model ...
Validation loss decreased (1.104379 --> 1.099039).  Saving model ...
Validation loss decreased (1.099039 --> 1.093945).  Saving model ...
Validation loss decreased (1.093945 --> 1.088097).  Saving model ...
Validation loss decreased (1.088097 --> 1.082232).  Saving model ...
Validation loss decreased (1.082232 --> 1.078290).  Saving model ...
Validation loss decreased (1.078290 --> 1.073362).  Saving model ...
Validation loss decreased (1.073362 --> 1.069333).  Saving model ...
Validation loss decreased (1.069333 --> 1.064969).  Saving model ...
Validation loss decreased (1.064969 --> 1.061785).  Saving model ...
Validation loss decreased (1.061785 --> 1.056866).  Saving model ...
Validation loss decreased (1.056866 --> 1.052082).  Saving model ...
Validation loss decreased (1.052082 --> 1.047625).  Saving model ...
Validation loss decreased (1.047625 --> 1.042843).  Saving model ...
Validation loss decreased (1.042843 --> 1.040815).  Saving model ...
Validation loss decreased (1.040815 --> 1.038836).  Saving model ...
Validation loss decreased (1.038836 --> 1.034933).  Saving model ...
Validation loss decreased (1.034933 --> 1.033290).  Saving model ...
Validation loss decreased (1.033290 --> 1.029789).  Saving model ...
Validation loss decreased (1.029789 --> 1.027159).  Saving model ...
Validation loss decreased (1.027159 --> 1.023393).  Saving model ...
Validation loss decreased (1.023393 --> 1.020101).  Saving model ...
Validation loss decreased (1.020101 --> 1.016814).  Saving model ...
Validation loss decreased (1.016814 --> 1.013296).  Saving model ...
Validation loss decreased (1.013296 --> 1.012070).  Saving model ...
Validation loss decreased (1.012070 --> 1.007764).  Saving model ...
Validation loss decreased (1.007764 --> 1.005533).  Saving model ...
Validation loss decreased (1.005533 --> 1.003764).  Saving model ...
Validation loss decreased (1.003764 --> 1.002057).  Saving model ...
Validation loss decreased (1.002057 --> 0.999366).  Saving model ...
Validation loss decreased (0.999366 --> 0.995887).  Saving model ...
Validation loss decreased (0.995887 --> 0.994280).  Saving model ...
Validation loss decreased (0.994280 --> 0.991607).  Saving model ...
Validation loss decreased (0.991607 --> 0.990902).  Saving model ...
Validation loss decreased (0.990902 --> 0.989108).  Saving model ...
Validation loss decreased (0.989108 --> 0.986886).  Saving model ...
Validation loss decreased (0.986886 --> 0.986321).  Saving model ...
Validation loss decreased (0.986321 --> 0.984620).  Saving model ...
Validation loss decreased (0.984620 --> 0.983629).  Saving model ...
Validation loss decreased (0.983629 --> 0.983556).  Saving model ...
Validation loss decreased (0.983556 --> 0.980746).  Saving model ...
Validation loss decreased (0.980746 --> 0.978682).  Saving model ...
Validation loss decreased (0.978682 --> 0.976515).  Saving model ...
Validation loss decreased (0.976515 --> 0.974320).  Saving model ...
Validation loss decreased (0.974320 --> 0.973442).  Saving model ...
Validation loss decreased (0.973442 --> 0.971582).  Saving model ...
Validation loss decreased (0.971582 --> 0.970355).  Saving model ...
Validation loss decreased (0.970355 --> 0.969509).  Saving model ...
Validation loss decreased (0.969509 --> 0.967743).  Saving model ...
Validation loss decreased (0.967743 --> 0.965099).  Saving model ...
EarlyStopping counter: 1 out of 5.0
EarlyStopping counter: 2 out of 5.0
EarlyStopping counter: 3 out of 5.0
Validation loss decreased (0.965099 --> 0.963785).  Saving model ...
Validation loss decreased (0.963785 --> 0.961781).  Saving model ...
EarlyStopping counter: 1 out of 5.0
Validation loss decreased (0.961781 --> 0.960832).  Saving model ...
EarlyStopping counter: 1 out of 5.0
EarlyStopping counter: 2 out of 5.0
Validation loss decreased (0.960832 --> 0.960343).  Saving model ...
EarlyStopping counter: 1 out of 5.0
Validation loss decreased (0.960343 --> 0.959872).  Saving model ...
Validation loss decreased (0.959872 --> 0.959785).  Saving model ...
Validation loss decreased (0.959785 --> 0.959545).  Saving model ...
EarlyStopping counter: 1 out of 5.0
Validation loss decreased (0.959545 --> 0.959038).  Saving model ...
Validation loss decreased (0.959038 --> 0.958303).  Saving model ...
EarlyStopping counter: 1 out of 5.0
EarlyStopping counter: 2 out of 5.0
Validation loss decreased (0.958303 --> 0.957350).  Saving model ...
EarlyStopping counter: 1 out of 5.0
Validation loss decreased (0.957350 --> 0.957285).  Saving model ...
Validation loss decreased (0.957285 --> 0.956472).  Saving model ...
Validation loss decreased (0.956472 --> 0.955352).  Saving model ...
EarlyStopping counter: 1 out of 5.0
EarlyStopping counter: 2 out of 5.0
EarlyStopping counter: 3 out of 5.0
EarlyStopping counter: 4 out of 5.0
EarlyStopping counter: 5 out of 5.0
/localscratch/yinan.29031137.0/env/lib/python3.7/site-packages/torch/nn/functional.py:1794: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.
  warnings.warn("nn.functional.tanh is deprecated. Use torch.tanh instead.")
wandb: Waiting for W&B process to finish, PID 74672... (success).
wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: \ 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: | 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: / 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: \ 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: | 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: / 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: \ 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: | 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: / 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb:                                                                                
wandb: Run history:
wandb:     e_F1 ▁▂▃▄▅▆▆▆▆▆▇▇▇▇▇▇▇▇▇▇▇███████████████████
wandb:   e_loss ██▇▇▇▇▆▆▅▅▅▄▄▄▃▃▃▃▂▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:     t_F1 ▁▁▂▃▃▃▃▄▄▄▅▅▅▅▅▆▆▆▇▇▇▆▇▇▆▇▇▇▇▇█▇██▇█████
wandb:   t_loss ███▇▇▇▇▇▇▆▆▆▆▅▅▅▄▄▄▄▃▃▃▃▃▃▂▂▂▂▂▂▂▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:     e_F1 59.72996
wandb:   e_loss 0.95571
wandb:     t_F1 71.47904
wandb:   t_loss 0.78494
wandb: 
wandb: Synced 4 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Synced lucky-sunset-2: https://wandb.ai/yinanazhou/xl_512_bs_8_lr_1e06_es_5_lc_True_nr_False_sr_True_stem_False_lemma_False_repeat_2_fold_1/runs/1tw5rjry
wandb: Find logs at: ./wandb/run-20220316_073611-1tw5rjry/logs/debug.log
wandb: 

wandb: wandb version 0.12.11 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
2022-03-16 08:58:48.415821: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1
wandb: Tracking run with wandb version 0.12.5
wandb: Syncing run vital-eon-2
wandb: ⭐️ View project at https://wandb.ai/yinanazhou/xl_512_bs_8_lr_1e06_es_5_lc_True_nr_False_sr_True_stem_False_lemma_False_repeat_2_fold_2
wandb: 🚀 View run at https://wandb.ai/yinanazhou/xl_512_bs_8_lr_1e06_es_5_lc_True_nr_False_sr_True_stem_False_lemma_False_repeat_2_fold_2/runs/7wy7o8b8
wandb: Run data is saved locally in /project/6002780/yinan/Thesis_MER_Lyrics/lyric-emotion/wandb/run-20220316_085845-7wy7o8b8
wandb: Run `wandb offline` to turn off syncing.

Validation loss decreased (inf --> 1.390218).  Saving model ...
Validation loss decreased (1.390218 --> 1.383805).  Saving model ...
Validation loss decreased (1.383805 --> 1.378142).  Saving model ...
Validation loss decreased (1.378142 --> 1.373035).  Saving model ...
Validation loss decreased (1.373035 --> 1.368545).  Saving model ...
Validation loss decreased (1.368545 --> 1.364454).  Saving model ...
Validation loss decreased (1.364454 --> 1.360554).  Saving model ...
Validation loss decreased (1.360554 --> 1.356347).  Saving model ...
Validation loss decreased (1.356347 --> 1.351988).  Saving model ...
Validation loss decreased (1.351988 --> 1.347808).  Saving model ...
Validation loss decreased (1.347808 --> 1.343598).  Saving model ...
Validation loss decreased (1.343598 --> 1.339056).  Saving model ...
Validation loss decreased (1.339056 --> 1.334552).  Saving model ...
Validation loss decreased (1.334552 --> 1.329938).  Saving model ...
Validation loss decreased (1.329938 --> 1.325221).  Saving model ...
Validation loss decreased (1.325221 --> 1.320280).  Saving model ...
Validation loss decreased (1.320280 --> 1.314695).  Saving model ...
Validation loss decreased (1.314695 --> 1.308458).  Saving model ...
Validation loss decreased (1.308458 --> 1.302732).  Saving model ...
Validation loss decreased (1.302732 --> 1.296191).  Saving model ...
Validation loss decreased (1.296191 --> 1.287993).  Saving model ...
Validation loss decreased (1.287993 --> 1.280670).  Saving model ...
Validation loss decreased (1.280670 --> 1.273281).  Saving model ...
Validation loss decreased (1.273281 --> 1.264231).  Saving model ...
Validation loss decreased (1.264231 --> 1.254484).  Saving model ...
Validation loss decreased (1.254484 --> 1.245392).  Saving model ...
Validation loss decreased (1.245392 --> 1.236118).  Saving model ...
Validation loss decreased (1.236118 --> 1.226579).  Saving model ...
Validation loss decreased (1.226579 --> 1.217751).  Saving model ...
Validation loss decreased (1.217751 --> 1.209762).  Saving model ...
Validation loss decreased (1.209762 --> 1.203146).  Saving model ...
Validation loss decreased (1.203146 --> 1.194446).  Saving model ...
Validation loss decreased (1.194446 --> 1.185901).  Saving model ...
Validation loss decreased (1.185901 --> 1.180157).  Saving model ...
Validation loss decreased (1.180157 --> 1.172206).  Saving model ...
Validation loss decreased (1.172206 --> 1.165657).  Saving model ...
Validation loss decreased (1.165657 --> 1.159199).  Saving model ...
Validation loss decreased (1.159199 --> 1.155745).  Saving model ...
Validation loss decreased (1.155745 --> 1.149535).  Saving model ...
Validation loss decreased (1.149535 --> 1.144539).  Saving model ...
Validation loss decreased (1.144539 --> 1.137815).  Saving model ...
Validation loss decreased (1.137815 --> 1.130985).  Saving model ...
Validation loss decreased (1.130985 --> 1.125658).  Saving model ...
Validation loss decreased (1.125658 --> 1.120005).  Saving model ...
Validation loss decreased (1.120005 --> 1.113708).  Saving model ...
Validation loss decreased (1.113708 --> 1.107130).  Saving model ...
Validation loss decreased (1.107130 --> 1.104160).  Saving model ...
Validation loss decreased (1.104160 --> 1.097962).  Saving model ...
Validation loss decreased (1.097962 --> 1.091549).  Saving model ...
Validation loss decreased (1.091549 --> 1.087971).  Saving model ...
Validation loss decreased (1.087971 --> 1.083518).  Saving model ...
Validation loss decreased (1.083518 --> 1.078815).  Saving model ...
Validation loss decreased (1.078815 --> 1.072218).  Saving model ...
Validation loss decreased (1.072218 --> 1.066847).  Saving model ...
Validation loss decreased (1.066847 --> 1.061217).  Saving model ...
Validation loss decreased (1.061217 --> 1.057488).  Saving model ...
Validation loss decreased (1.057488 --> 1.052240).  Saving model ...
Validation loss decreased (1.052240 --> 1.047099).  Saving model ...
Validation loss decreased (1.047099 --> 1.042262).  Saving model ...
Validation loss decreased (1.042262 --> 1.038844).  Saving model ...
Validation loss decreased (1.038844 --> 1.036810).  Saving model ...
Validation loss decreased (1.036810 --> 1.031356).  Saving model ...
Validation loss decreased (1.031356 --> 1.027307).  Saving model ...
Validation loss decreased (1.027307 --> 1.024152).  Saving model ...
Validation loss decreased (1.024152 --> 1.023213).  Saving model ...
Validation loss decreased (1.023213 --> 1.021448).  Saving model ...
Validation loss decreased (1.021448 --> 1.016407).  Saving model ...
Validation loss decreased (1.016407 --> 1.010478).  Saving model ...
Validation loss decreased (1.010478 --> 1.007832).  Saving model ...
Validation loss decreased (1.007832 --> 1.004343).  Saving model ...
Validation loss decreased (1.004343 --> 1.002521).  Saving model ...
Validation loss decreased (1.002521 --> 0.997963).  Saving model ...
Validation loss decreased (0.997963 --> 0.993275).  Saving model ...
Validation loss decreased (0.993275 --> 0.991659).  Saving model ...
Validation loss decreased (0.991659 --> 0.988499).  Saving model ...
Validation loss decreased (0.988499 --> 0.985263).  Saving model ...
Validation loss decreased (0.985263 --> 0.981587).  Saving model ...
Validation loss decreased (0.981587 --> 0.980494).  Saving model ...
Validation loss decreased (0.980494 --> 0.976938).  Saving model ...
Validation loss decreased (0.976938 --> 0.975113).  Saving model ...
Validation loss decreased (0.975113 --> 0.971705).  Saving model ...
Validation loss decreased (0.971705 --> 0.969336).  Saving model ...
Validation loss decreased (0.969336 --> 0.966695).  Saving model ...
Validation loss decreased (0.966695 --> 0.965129).  Saving model ...
Validation loss decreased (0.965129 --> 0.963820).  Saving model ...
Validation loss decreased (0.963820 --> 0.960787).  Saving model ...
Validation loss decreased (0.960787 --> 0.958242).  Saving model ...
EarlyStopping counter: 1 out of 5.0
Validation loss decreased (0.958242 --> 0.955652).  Saving model ...
Validation loss decreased (0.955652 --> 0.953476).  Saving model ...
Validation loss decreased (0.953476 --> 0.948980).  Saving model ...
Validation loss decreased (0.948980 --> 0.946791).  Saving model ...
Validation loss decreased (0.946791 --> 0.944983).  Saving model ...
Validation loss decreased (0.944983 --> 0.943630).  Saving model ...
Validation loss decreased (0.943630 --> 0.942011).  Saving model ...
Validation loss decreased (0.942011 --> 0.939924).  Saving model ...
EarlyStopping counter: 1 out of 5.0
Validation loss decreased (0.939924 --> 0.939320).  Saving model ...
Validation loss decreased (0.939320 --> 0.937452).  Saving model ...
Validation loss decreased (0.937452 --> 0.936591).  Saving model ...
Validation loss decreased (0.936591 --> 0.934831).  Saving model ...
Validation loss decreased (0.934831 --> 0.933664).  Saving model ...
Validation loss decreased (0.933664 --> 0.932825).  Saving model ...
Validation loss decreased (0.932825 --> 0.931601).  Saving model ...
Validation loss decreased (0.931601 --> 0.929773).  Saving model ...
Validation loss decreased (0.929773 --> 0.927879).  Saving model ...
Validation loss decreased (0.927879 --> 0.927729).  Saving model ...
Validation loss decreased (0.927729 --> 0.927117).  Saving model ...
Validation loss decreased (0.927117 --> 0.925711).  Saving model ...
Validation loss decreased (0.925711 --> 0.924837).  Saving model ...
Validation loss decreased (0.924837 --> 0.923104).  Saving model ...
EarlyStopping counter: 1 out of 5.0
Validation loss decreased (0.923104 --> 0.920721).  Saving model ...
Validation loss decreased (0.920721 --> 0.919410).  Saving model ...
Validation loss decreased (0.919410 --> 0.919037).  Saving model ...
Validation loss decreased (0.919037 --> 0.916487).  Saving model ...
Validation loss decreased (0.916487 --> 0.915425).  Saving model ...
EarlyStopping counter: 1 out of 5.0
EarlyStopping counter: 2 out of 5.0
Validation loss decreased (0.915425 --> 0.915108).  Saving model ...
Validation loss decreased (0.915108 --> 0.914477).  Saving model ...
Validation loss decreased (0.914477 --> 0.911913).  Saving model ...
Validation loss decreased (0.911913 --> 0.911465).  Saving model ...
Validation loss decreased (0.911465 --> 0.910968).  Saving model ...
EarlyStopping counter: 1 out of 5.0
EarlyStopping counter: 2 out of 5.0
EarlyStopping counter: 3 out of 5.0
EarlyStopping counter: 4 out of 5.0
EarlyStopping counter: 5 out of 5.0
/localscratch/yinan.29031137.0/env/lib/python3.7/site-packages/torch/nn/functional.py:1794: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.
  warnings.warn("nn.functional.tanh is deprecated. Use torch.tanh instead.")
wandb: Waiting for W&B process to finish, PID 79103... (success).
wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: \ 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: | 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: / 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: \ 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: | 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: / 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: \ 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: | 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb:                                                                                
wandb: Run history:
wandb:     e_F1 ▁▂▃▃▃▄▄▅▅▅▆▆▆▆▆▇▇▇▇▇▇▇▇▇▇▇█▇████████████
wandb:   e_loss ███▇▇▇▇▆▆▅▅▅▄▄▄▄▃▃▃▃▃▂▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁
wandb:     t_F1 ▁▁▂▃▂▃▃▄▄▄▅▅▅▅▆▅▆▆▆▇▆▆▇▆▇▇▆▆▇▇█▇▇▇█▇▇▇██
wandb:   t_loss ███▇▇▇▇▇▇▆▆▆▅▅▅▅▄▄▄▄▄▃▃▃▃▃▃▃▂▃▂▂▂▂▂▂▂▁▁▁
wandb: 
wandb: Run summary:
wandb:     e_F1 62.26546
wandb:   e_loss 0.91235
wandb:     t_F1 73.47435
wandb:   t_loss 0.75145
wandb: 
wandb: Synced 4 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Synced vital-eon-2: https://wandb.ai/yinanazhou/xl_512_bs_8_lr_1e06_es_5_lc_True_nr_False_sr_True_stem_False_lemma_False_repeat_2_fold_2/runs/7wy7o8b8
wandb: Find logs at: ./wandb/run-20220316_085845-7wy7o8b8/logs/debug.log
wandb: 

wandb: wandb version 0.12.11 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
2022-03-16 10:21:44.541085: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1
wandb: Tracking run with wandb version 0.12.5
wandb: Syncing run ethereal-wildflower-2
wandb: ⭐️ View project at https://wandb.ai/yinanazhou/xl_512_bs_8_lr_1e06_es_5_lc_True_nr_False_sr_True_stem_False_lemma_False_repeat_3_fold_1
wandb: 🚀 View run at https://wandb.ai/yinanazhou/xl_512_bs_8_lr_1e06_es_5_lc_True_nr_False_sr_True_stem_False_lemma_False_repeat_3_fold_1/runs/141mdyno
wandb: Run data is saved locally in /project/6002780/yinan/Thesis_MER_Lyrics/lyric-emotion/wandb/run-20220316_102141-141mdyno
wandb: Run `wandb offline` to turn off syncing.

Validation loss decreased (inf --> 1.415898).  Saving model ...
Validation loss decreased (1.415898 --> 1.405640).  Saving model ...
Validation loss decreased (1.405640 --> 1.397045).  Saving model ...
Validation loss decreased (1.397045 --> 1.390066).  Saving model ...
Validation loss decreased (1.390066 --> 1.383660).  Saving model ...
Validation loss decreased (1.383660 --> 1.377834).  Saving model ...
Validation loss decreased (1.377834 --> 1.372497).  Saving model ...
Validation loss decreased (1.372497 --> 1.367352).  Saving model ...
Validation loss decreased (1.367352 --> 1.362390).  Saving model ...
Validation loss decreased (1.362390 --> 1.357729).  Saving model ...
Validation loss decreased (1.357729 --> 1.352439).  Saving model ...
Validation loss decreased (1.352439 --> 1.347383).  Saving model ...
Validation loss decreased (1.347383 --> 1.342029).  Saving model ...
Validation loss decreased (1.342029 --> 1.336803).  Saving model ...
Validation loss decreased (1.336803 --> 1.331405).  Saving model ...
Validation loss decreased (1.331405 --> 1.324873).  Saving model ...
Validation loss decreased (1.324873 --> 1.319173).  Saving model ...
Validation loss decreased (1.319173 --> 1.313273).  Saving model ...
Validation loss decreased (1.313273 --> 1.308163).  Saving model ...
Validation loss decreased (1.308163 --> 1.301813).  Saving model ...
Validation loss decreased (1.301813 --> 1.293610).  Saving model ...
Validation loss decreased (1.293610 --> 1.285999).  Saving model ...
Validation loss decreased (1.285999 --> 1.277727).  Saving model ...
Validation loss decreased (1.277727 --> 1.268476).  Saving model ...
Validation loss decreased (1.268476 --> 1.260275).  Saving model ...
Validation loss decreased (1.260275 --> 1.251476).  Saving model ...
Validation loss decreased (1.251476 --> 1.242829).  Saving model ...
Validation loss decreased (1.242829 --> 1.235205).  Saving model ...
Validation loss decreased (1.235205 --> 1.226070).  Saving model ...
Validation loss decreased (1.226070 --> 1.218011).  Saving model ...
Validation loss decreased (1.218011 --> 1.210278).  Saving model ...
Validation loss decreased (1.210278 --> 1.203315).  Saving model ...
Validation loss decreased (1.203315 --> 1.196301).  Saving model ...
Validation loss decreased (1.196301 --> 1.189519).  Saving model ...
Validation loss decreased (1.189519 --> 1.183336).  Saving model ...
Validation loss decreased (1.183336 --> 1.177547).  Saving model ...
Validation loss decreased (1.177547 --> 1.170628).  Saving model ...
Validation loss decreased (1.170628 --> 1.164812).  Saving model ...
Validation loss decreased (1.164812 --> 1.159598).  Saving model ...
Validation loss decreased (1.159598 --> 1.153009).  Saving model ...
Validation loss decreased (1.153009 --> 1.147712).  Saving model ...
Validation loss decreased (1.147712 --> 1.140889).  Saving model ...
Validation loss decreased (1.140889 --> 1.135474).  Saving model ...
Validation loss decreased (1.135474 --> 1.130025).  Saving model ...
Validation loss decreased (1.130025 --> 1.124462).  Saving model ...
Validation loss decreased (1.124462 --> 1.119717).  Saving model ...
Validation loss decreased (1.119717 --> 1.115712).  Saving model ...
Validation loss decreased (1.115712 --> 1.110380).  Saving model ...
Validation loss decreased (1.110380 --> 1.104450).  Saving model ...
Validation loss decreased (1.104450 --> 1.099936).  Saving model ...
Validation loss decreased (1.099936 --> 1.095022).  Saving model ...
Validation loss decreased (1.095022 --> 1.089524).  Saving model ...
Validation loss decreased (1.089524 --> 1.086137).  Saving model ...
Validation loss decreased (1.086137 --> 1.082799).  Saving model ...
Validation loss decreased (1.082799 --> 1.078065).  Saving model ...
Validation loss decreased (1.078065 --> 1.075068).  Saving model ...
Validation loss decreased (1.075068 --> 1.071202).  Saving model ...
Validation loss decreased (1.071202 --> 1.065839).  Saving model ...
Validation loss decreased (1.065839 --> 1.061599).  Saving model ...
Validation loss decreased (1.061599 --> 1.056965).  Saving model ...
Validation loss decreased (1.056965 --> 1.052792).  Saving model ...
Validation loss decreased (1.052792 --> 1.050497).  Saving model ...
Validation loss decreased (1.050497 --> 1.046953).  Saving model ...
Validation loss decreased (1.046953 --> 1.044498).  Saving model ...
Validation loss decreased (1.044498 --> 1.042062).  Saving model ...
Validation loss decreased (1.042062 --> 1.038308).  Saving model ...
Validation loss decreased (1.038308 --> 1.034331).  Saving model ...
Validation loss decreased (1.034331 --> 1.030871).  Saving model ...
Validation loss decreased (1.030871 --> 1.028125).  Saving model ...
Validation loss decreased (1.028125 --> 1.025942).  Saving model ...
Validation loss decreased (1.025942 --> 1.021721).  Saving model ...
Validation loss decreased (1.021721 --> 1.019669).  Saving model ...
Validation loss decreased (1.019669 --> 1.018304).  Saving model ...
Validation loss decreased (1.018304 --> 1.014954).  Saving model ...
Validation loss decreased (1.014954 --> 1.013220).  Saving model ...
Validation loss decreased (1.013220 --> 1.008415).  Saving model ...
Validation loss decreased (1.008415 --> 1.006756).  Saving model ...
Validation loss decreased (1.006756 --> 1.004146).  Saving model ...
Validation loss decreased (1.004146 --> 1.002619).  Saving model ...
Validation loss decreased (1.002619 --> 1.000307).  Saving model ...
Validation loss decreased (1.000307 --> 0.997943).  Saving model ...
Validation loss decreased (0.997943 --> 0.995673).  Saving model ...
Validation loss decreased (0.995673 --> 0.992723).  Saving model ...
Validation loss decreased (0.992723 --> 0.991529).  Saving model ...
Validation loss decreased (0.991529 --> 0.989667).  Saving model ...
Validation loss decreased (0.989667 --> 0.987650).  Saving model ...
Validation loss decreased (0.987650 --> 0.985840).  Saving model ...
Validation loss decreased (0.985840 --> 0.984370).  Saving model ...
EarlyStopping counter: 1 out of 5.0
Validation loss decreased (0.984370 --> 0.982733).  Saving model ...
Validation loss decreased (0.982733 --> 0.982653).  Saving model ...
Validation loss decreased (0.982653 --> 0.979129).  Saving model ...
Validation loss decreased (0.979129 --> 0.978004).  Saving model ...
Validation loss decreased (0.978004 --> 0.977314).  Saving model ...
EarlyStopping counter: 1 out of 5.0
Validation loss decreased (0.977314 --> 0.976689).  Saving model ...
Validation loss decreased (0.976689 --> 0.974672).  Saving model ...
Validation loss decreased (0.974672 --> 0.973225).  Saving model ...
Validation loss decreased (0.973225 --> 0.971810).  Saving model ...
Validation loss decreased (0.971810 --> 0.970398).  Saving model ...
Validation loss decreased (0.970398 --> 0.969694).  Saving model ...
Validation loss decreased (0.969694 --> 0.969119).  Saving model ...
Validation loss decreased (0.969119 --> 0.968784).  Saving model ...
Validation loss decreased (0.968784 --> 0.967515).  Saving model ...
Validation loss decreased (0.967515 --> 0.966848).  Saving model ...
Validation loss decreased (0.966848 --> 0.964748).  Saving model ...
Validation loss decreased (0.964748 --> 0.964157).  Saving model ...
EarlyStopping counter: 1 out of 5.0
Validation loss decreased (0.964157 --> 0.962541).  Saving model ...
Validation loss decreased (0.962541 --> 0.961978).  Saving model ...
Validation loss decreased (0.961978 --> 0.961230).  Saving model ...
Validation loss decreased (0.961230 --> 0.960028).  Saving model ...
Validation loss decreased (0.960028 --> 0.959427).  Saving model ...
EarlyStopping counter: 1 out of 5.0
EarlyStopping counter: 2 out of 5.0
EarlyStopping counter: 3 out of 5.0
EarlyStopping counter: 4 out of 5.0
Validation loss decreased (0.959427 --> 0.958667).  Saving model ...
EarlyStopping counter: 1 out of 5.0
EarlyStopping counter: 2 out of 5.0
Validation loss decreased (0.958667 --> 0.957276).  Saving model ...
Validation loss decreased (0.957276 --> 0.955736).  Saving model ...
Validation loss decreased (0.955736 --> 0.955241).  Saving model ...
EarlyStopping counter: 1 out of 5.0
EarlyStopping counter: 2 out of 5.0
Validation loss decreased (0.955241 --> 0.955116).  Saving model ...
EarlyStopping counter: 1 out of 5.0
EarlyStopping counter: 2 out of 5.0
Validation loss decreased (0.955116 --> 0.954326).  Saving model ...
Validation loss decreased (0.954326 --> 0.953262).  Saving model ...
EarlyStopping counter: 1 out of 5.0
EarlyStopping counter: 2 out of 5.0
Validation loss decreased (0.953262 --> 0.953202).  Saving model ...
EarlyStopping counter: 1 out of 5.0
EarlyStopping counter: 2 out of 5.0
EarlyStopping counter: 3 out of 5.0
Validation loss decreased (0.953202 --> 0.952590).  Saving model ...
EarlyStopping counter: 1 out of 5.0
EarlyStopping counter: 2 out of 5.0
EarlyStopping counter: 3 out of 5.0
EarlyStopping counter: 4 out of 5.0
Validation loss decreased (0.952590 --> 0.951521).  Saving model ...
EarlyStopping counter: 1 out of 5.0
EarlyStopping counter: 2 out of 5.0
EarlyStopping counter: 3 out of 5.0
EarlyStopping counter: 4 out of 5.0
EarlyStopping counter: 5 out of 5.0
/localscratch/yinan.29031137.0/env/lib/python3.7/site-packages/torch/nn/functional.py:1794: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.
  warnings.warn("nn.functional.tanh is deprecated. Use torch.tanh instead.")
wandb: Waiting for W&B process to finish, PID 83538... (success).
wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: \ 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: | 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: / 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: \ 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: | 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: / 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: \ 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: | 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb:                                                                                
wandb: Run history:
wandb:     e_F1 ▁▂▃▄▅▆▆▆▆▆▆▆▆▆▇▇▇▇▇▇▇▇▇▇███▇████████████
wandb:   e_loss ██▇▇▇▆▆▆▅▅▄▄▄▃▃▃▃▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:     t_F1 ▁▁▂▂▃▃▄▄▅▅▅▆▆▅▆▆▆▆▆▇▆▇▇▇▇▇▇█▇▇▇█▇███▇███
wandb:   t_loss ███▇▇▇▇▇▆▆▆▅▅▅▅▄▄▄▄▄▄▃▃▃▃▃▃▃▂▂▂▂▂▂▁▂▂▂▁▁
wandb: 
wandb: Run summary:
wandb:     e_F1 62.25286
wandb:   e_loss 0.95411
wandb:     t_F1 77.46948
wandb:   t_loss 0.6785
wandb: 
wandb: Synced 4 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Synced ethereal-wildflower-2: https://wandb.ai/yinanazhou/xl_512_bs_8_lr_1e06_es_5_lc_True_nr_False_sr_True_stem_False_lemma_False_repeat_3_fold_1/runs/141mdyno
wandb: Find logs at: ./wandb/run-20220316_102141-141mdyno/logs/debug.log
wandb: 

wandb: wandb version 0.12.11 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
2022-03-16 11:59:01.821910: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1
wandb: Tracking run with wandb version 0.12.5
wandb: Syncing run decent-snowball-2
wandb: ⭐️ View project at https://wandb.ai/yinanazhou/xl_512_bs_8_lr_1e06_es_5_lc_True_nr_False_sr_True_stem_False_lemma_False_repeat_3_fold_2
wandb: 🚀 View run at https://wandb.ai/yinanazhou/xl_512_bs_8_lr_1e06_es_5_lc_True_nr_False_sr_True_stem_False_lemma_False_repeat_3_fold_2/runs/3b28bkbk
wandb: Run data is saved locally in /project/6002780/yinan/Thesis_MER_Lyrics/lyric-emotion/wandb/run-20220316_115858-3b28bkbk
wandb: Run `wandb offline` to turn off syncing.

Validation loss decreased (inf --> 1.404547).  Saving model ...
Validation loss decreased (1.404547 --> 1.395363).  Saving model ...
Validation loss decreased (1.395363 --> 1.388307).  Saving model ...
Validation loss decreased (1.388307 --> 1.381651).  Saving model ...
Validation loss decreased (1.381651 --> 1.376372).  Saving model ...
Validation loss decreased (1.376372 --> 1.371274).  Saving model ...
Validation loss decreased (1.371274 --> 1.366690).  Saving model ...
Validation loss decreased (1.366690 --> 1.361339).  Saving model ...
Validation loss decreased (1.361339 --> 1.357100).  Saving model ...
Validation loss decreased (1.357100 --> 1.352894).  Saving model ...
Validation loss decreased (1.352894 --> 1.348036).  Saving model ...
Validation loss decreased (1.348036 --> 1.342943).  Saving model ...
Validation loss decreased (1.342943 --> 1.338149).  Saving model ...
Validation loss decreased (1.338149 --> 1.333272).  Saving model ...
Validation loss decreased (1.333272 --> 1.328323).  Saving model ...
Validation loss decreased (1.328323 --> 1.322957).  Saving model ...
Validation loss decreased (1.322957 --> 1.316789).  Saving model ...
Validation loss decreased (1.316789 --> 1.310626).  Saving model ...
Validation loss decreased (1.310626 --> 1.303698).  Saving model ...
Validation loss decreased (1.303698 --> 1.296315).  Saving model ...
Validation loss decreased (1.296315 --> 1.288540).  Saving model ...
Validation loss decreased (1.288540 --> 1.279743).  Saving model ...
Validation loss decreased (1.279743 --> 1.271703).  Saving model ...
Validation loss decreased (1.271703 --> 1.263062).  Saving model ...
Validation loss decreased (1.263062 --> 1.254542).  Saving model ...
Validation loss decreased (1.254542 --> 1.245675).  Saving model ...
Validation loss decreased (1.245675 --> 1.237442).  Saving model ...
Validation loss decreased (1.237442 --> 1.227565).  Saving model ...
Validation loss decreased (1.227565 --> 1.218402).  Saving model ...
Validation loss decreased (1.218402 --> 1.209917).  Saving model ...
Validation loss decreased (1.209917 --> 1.202452).  Saving model ...
Validation loss decreased (1.202452 --> 1.195695).  Saving model ...
Validation loss decreased (1.195695 --> 1.186443).  Saving model ...
Validation loss decreased (1.186443 --> 1.178495).  Saving model ...
Validation loss decreased (1.178495 --> 1.169930).  Saving model ...
Validation loss decreased (1.169930 --> 1.161681).  Saving model ...
Validation loss decreased (1.161681 --> 1.154150).  Saving model ...
Validation loss decreased (1.154150 --> 1.147714).  Saving model ...
Validation loss decreased (1.147714 --> 1.141467).  Saving model ...
Validation loss decreased (1.141467 --> 1.134721).  Saving model ...
Validation loss decreased (1.134721 --> 1.128523).  Saving model ...
Validation loss decreased (1.128523 --> 1.121654).  Saving model ...
Validation loss decreased (1.121654 --> 1.115323).  Saving model ...
Validation loss decreased (1.115323 --> 1.109764).  Saving model ...
Validation loss decreased (1.109764 --> 1.104713).  Saving model ...
Validation loss decreased (1.104713 --> 1.098886).  Saving model ...
Validation loss decreased (1.098886 --> 1.093529).  Saving model ...
Validation loss decreased (1.093529 --> 1.088472).  Saving model ...
Validation loss decreased (1.088472 --> 1.082689).  Saving model ...
Validation loss decreased (1.082689 --> 1.078864).  Saving model ...
Validation loss decreased (1.078864 --> 1.073937).  Saving model ...
Validation loss decreased (1.073937 --> 1.068142).  Saving model ...
Validation loss decreased (1.068142 --> 1.063385).  Saving model ...
Validation loss decreased (1.063385 --> 1.059398).  Saving model ...
Validation loss decreased (1.059398 --> 1.055281).  Saving model ...
Validation loss decreased (1.055281 --> 1.051639).  Saving model ...
Validation loss decreased (1.051639 --> 1.048025).  Saving model ...
Validation loss decreased (1.048025 --> 1.043294).  Saving model ...
Validation loss decreased (1.043294 --> 1.037866).  Saving model ...
Validation loss decreased (1.037866 --> 1.033257).  Saving model ...
Validation loss decreased (1.033257 --> 1.030486).  Saving model ...
Validation loss decreased (1.030486 --> 1.027157).  Saving model ...
Validation loss decreased (1.027157 --> 1.024019).  Saving model ...
Validation loss decreased (1.024019 --> 1.020543).  Saving model ...
Validation loss decreased (1.020543 --> 1.017299).  Saving model ...
Validation loss decreased (1.017299 --> 1.013038).  Saving model ...
Validation loss decreased (1.013038 --> 1.009230).  Saving model ...
Validation loss decreased (1.009230 --> 1.006312).  Saving model ...
Validation loss decreased (1.006312 --> 1.003972).  Saving model ...
Validation loss decreased (1.003972 --> 1.000764).  Saving model ...
Validation loss decreased (1.000764 --> 0.997496).  Saving model ...
Validation loss decreased (0.997496 --> 0.994131).  Saving model ...
Validation loss decreased (0.994131 --> 0.992591).  Saving model ...
Validation loss decreased (0.992591 --> 0.989091).  Saving model ...
Validation loss decreased (0.989091 --> 0.986018).  Saving model ...
Validation loss decreased (0.986018 --> 0.983297).  Saving model ...
Validation loss decreased (0.983297 --> 0.981541).  Saving model ...
Validation loss decreased (0.981541 --> 0.978111).  Saving model ...
Validation loss decreased (0.978111 --> 0.974431).  Saving model ...
Validation loss decreased (0.974431 --> 0.973758).  Saving model ...
Validation loss decreased (0.973758 --> 0.971370).  Saving model ...
Validation loss decreased (0.971370 --> 0.970121).  Saving model ...
Validation loss decreased (0.970121 --> 0.968213).  Saving model ...
Validation loss decreased (0.968213 --> 0.964812).  Saving model ...
Validation loss decreased (0.964812 --> 0.963385).  Saving model ...
Validation loss decreased (0.963385 --> 0.960025).  Saving model ...
Validation loss decreased (0.960025 --> 0.956273).  Saving model ...
Validation loss decreased (0.956273 --> 0.952822).  Saving model ...
Validation loss decreased (0.952822 --> 0.951508).  Saving model ...
Validation loss decreased (0.951508 --> 0.950337).  Saving model ...
Validation loss decreased (0.950337 --> 0.949974).  Saving model ...
Validation loss decreased (0.949974 --> 0.948691).  Saving model ...
Validation loss decreased (0.948691 --> 0.945776).  Saving model ...
Validation loss decreased (0.945776 --> 0.943157).  Saving model ...
Validation loss decreased (0.943157 --> 0.941810).  Saving model ...
Validation loss decreased (0.941810 --> 0.941488).  Saving model ...
Validation loss decreased (0.941488 --> 0.940847).  Saving model ...
Validation loss decreased (0.940847 --> 0.938804).  Saving model ...
Validation loss decreased (0.938804 --> 0.937735).  Saving model ...
Validation loss decreased (0.937735 --> 0.936190).  Saving model ...
Validation loss decreased (0.936190 --> 0.936039).  Saving model ...
Validation loss decreased (0.936039 --> 0.934200).  Saving model ...
Validation loss decreased (0.934200 --> 0.932803).  Saving model ...
Validation loss decreased (0.932803 --> 0.932592).  Saving model ...
Validation loss decreased (0.932592 --> 0.930139).  Saving model ...
EarlyStopping counter: 1 out of 5.0
EarlyStopping counter: 2 out of 5.0
EarlyStopping counter: 3 out of 5.0
Validation loss decreased (0.930139 --> 0.928783).  Saving model ...
Validation loss decreased (0.928783 --> 0.925987).  Saving model ...
Validation loss decreased (0.925987 --> 0.925484).  Saving model ...
EarlyStopping counter: 1 out of 5.0
EarlyStopping counter: 2 out of 5.0
Validation loss decreased (0.925484 --> 0.923132).  Saving model ...
Validation loss decreased (0.923132 --> 0.922503).  Saving model ...
EarlyStopping counter: 1 out of 5.0
EarlyStopping counter: 2 out of 5.0
EarlyStopping counter: 3 out of 5.0
Validation loss decreased (0.922503 --> 0.922158).  Saving model ...
Validation loss decreased (0.922158 --> 0.920408).  Saving model ...
EarlyStopping counter: 1 out of 5.0
Validation loss decreased (0.920408 --> 0.918366).  Saving model ...
Validation loss decreased (0.918366 --> 0.917940).  Saving model ...
Validation loss decreased (0.917940 --> 0.917783).  Saving model ...
EarlyStopping counter: 1 out of 5.0
EarlyStopping counter: 2 out of 5.0
EarlyStopping counter: 3 out of 5.0
EarlyStopping counter: 4 out of 5.0
EarlyStopping counter: 5 out of 5.0
/localscratch/yinan.29031137.0/env/lib/python3.7/site-packages/torch/nn/functional.py:1794: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.
  warnings.warn("nn.functional.tanh is deprecated. Use torch.tanh instead.")
wandb: Waiting for W&B process to finish, PID 88726... (success).
wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: \ 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: | 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: / 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: \ 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: | 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: / 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: \ 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: | 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: / 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: \ 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb:                                                                                
wandb: Run history:
wandb:     e_F1 ▁▂▃▄▄▅▅▆▅▆▆▆▆▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇███████████
wandb:   e_loss ███▇▇▇▇▆▆▅▅▅▄▄▄▃▃▃▃▃▂▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁
wandb:     t_F1 ▁▂▂▂▂▃▄▄▄▄▅▅▅▅▅▆▅▆▆▇▆▆▇▇▇▇▇▇▇█▇████▇████
wandb:   t_loss ████▇▇▇▇▇▆▆▅▅▅▅▅▄▄▄▄▄▃▃▃▃▃▃▂▂▂▂▂▂▁▁▂▁▁▁▁
wandb: 
wandb: Run summary:
wandb:     e_F1 62.801
wandb:   e_loss 0.9192
wandb:     t_F1 74.17902
wandb:   t_loss 0.72761
wandb: 
wandb: Synced 4 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Synced decent-snowball-2: https://wandb.ai/yinanazhou/xl_512_bs_8_lr_1e06_es_5_lc_True_nr_False_sr_True_stem_False_lemma_False_repeat_3_fold_2/runs/3b28bkbk
wandb: Find logs at: ./wandb/run-20220316_115858-3b28bkbk/logs/debug.log
wandb: 

wandb: wandb version 0.12.11 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
2022-03-16 13:24:43.365490: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1
wandb: Tracking run with wandb version 0.12.5
wandb: Syncing run glowing-river-2
wandb: ⭐️ View project at https://wandb.ai/yinanazhou/xl_512_bs_8_lr_1e06_es_5_lc_True_nr_False_sr_True_stem_False_lemma_False_repeat_4_fold_1
wandb: 🚀 View run at https://wandb.ai/yinanazhou/xl_512_bs_8_lr_1e06_es_5_lc_True_nr_False_sr_True_stem_False_lemma_False_repeat_4_fold_1/runs/2gyosi7p
wandb: Run data is saved locally in /project/6002780/yinan/Thesis_MER_Lyrics/lyric-emotion/wandb/run-20220316_132439-2gyosi7p
wandb: Run `wandb offline` to turn off syncing.

Validation loss decreased (inf --> 1.489330).  Saving model ...
Validation loss decreased (1.489330 --> 1.459326).  Saving model ...
Validation loss decreased (1.459326 --> 1.437188).  Saving model ...
Validation loss decreased (1.437188 --> 1.420195).  Saving model ...
Validation loss decreased (1.420195 --> 1.406490).  Saving model ...
Validation loss decreased (1.406490 --> 1.395641).  Saving model ...
Validation loss decreased (1.395641 --> 1.386764).  Saving model ...
Validation loss decreased (1.386764 --> 1.378722).  Saving model ...
Validation loss decreased (1.378722 --> 1.372304).  Saving model ...
Validation loss decreased (1.372304 --> 1.366050).  Saving model ...
Validation loss decreased (1.366050 --> 1.360019).  Saving model ...
Validation loss decreased (1.360019 --> 1.354127).  Saving model ...
Validation loss decreased (1.354127 --> 1.348610).  Saving model ...
Validation loss decreased (1.348610 --> 1.342868).  Saving model ...
Validation loss decreased (1.342868 --> 1.337270).  Saving model ...
Validation loss decreased (1.337270 --> 1.331579).  Saving model ...
Validation loss decreased (1.331579 --> 1.325444).  Saving model ...
Validation loss decreased (1.325444 --> 1.319522).  Saving model ...
Validation loss decreased (1.319522 --> 1.312838).  Saving model ...
Validation loss decreased (1.312838 --> 1.305993).  Saving model ...
Validation loss decreased (1.305993 --> 1.298720).  Saving model ...
Validation loss decreased (1.298720 --> 1.290852).  Saving model ...
Validation loss decreased (1.290852 --> 1.282705).  Saving model ...
Validation loss decreased (1.282705 --> 1.275270).  Saving model ...
Validation loss decreased (1.275270 --> 1.266708).  Saving model ...
Validation loss decreased (1.266708 --> 1.258758).  Saving model ...
Validation loss decreased (1.258758 --> 1.250412).  Saving model ...
Validation loss decreased (1.250412 --> 1.242043).  Saving model ...
Validation loss decreased (1.242043 --> 1.232567).  Saving model ...
Validation loss decreased (1.232567 --> 1.224964).  Saving model ...
Validation loss decreased (1.224964 --> 1.217596).  Saving model ...
Validation loss decreased (1.217596 --> 1.209949).  Saving model ...
Validation loss decreased (1.209949 --> 1.203166).  Saving model ...
Validation loss decreased (1.203166 --> 1.197048).  Saving model ...
Validation loss decreased (1.197048 --> 1.190902).  Saving model ...
Validation loss decreased (1.190902 --> 1.184503).  Saving model ...
Validation loss decreased (1.184503 --> 1.177532).  Saving model ...
Validation loss decreased (1.177532 --> 1.170724).  Saving model ...
Validation loss decreased (1.170724 --> 1.164362).  Saving model ...
Validation loss decreased (1.164362 --> 1.157919).  Saving model ...
Validation loss decreased (1.157919 --> 1.152643).  Saving model ...
Validation loss decreased (1.152643 --> 1.146742).  Saving model ...
Validation loss decreased (1.146742 --> 1.140535).  Saving model ...
Validation loss decreased (1.140535 --> 1.134759).  Saving model ...
Validation loss decreased (1.134759 --> 1.128684).  Saving model ...
Validation loss decreased (1.128684 --> 1.123946).  Saving model ...
Validation loss decreased (1.123946 --> 1.118506).  Saving model ...
Validation loss decreased (1.118506 --> 1.113521).  Saving model ...
Validation loss decreased (1.113521 --> 1.107921).  Saving model ...
Validation loss decreased (1.107921 --> 1.102703).  Saving model ...
Validation loss decreased (1.102703 --> 1.097779).  Saving model ...
Validation loss decreased (1.097779 --> 1.093202).  Saving model ...
Validation loss decreased (1.093202 --> 1.088545).  Saving model ...
Validation loss decreased (1.088545 --> 1.084751).  Saving model ...
Validation loss decreased (1.084751 --> 1.080620).  Saving model ...
Validation loss decreased (1.080620 --> 1.075559).  Saving model ...
Validation loss decreased (1.075559 --> 1.071634).  Saving model ...
Validation loss decreased (1.071634 --> 1.068633).  Saving model ...
Validation loss decreased (1.068633 --> 1.063409).  Saving model ...
Validation loss decreased (1.063409 --> 1.060087).  Saving model ...
Validation loss decreased (1.060087 --> 1.057162).  Saving model ...
Validation loss decreased (1.057162 --> 1.053054).  Saving model ...
Validation loss decreased (1.053054 --> 1.050330).  Saving model ...
Validation loss decreased (1.050330 --> 1.046392).  Saving model ...
Validation loss decreased (1.046392 --> 1.043304).  Saving model ...
Validation loss decreased (1.043304 --> 1.041864).  Saving model ...
Validation loss decreased (1.041864 --> 1.035989).  Saving model ...
Validation loss decreased (1.035989 --> 1.032570).  Saving model ...
Validation loss decreased (1.032570 --> 1.031407).  Saving model ...
Validation loss decreased (1.031407 --> 1.027753).  Saving model ...
Validation loss decreased (1.027753 --> 1.025229).  Saving model ...
Validation loss decreased (1.025229 --> 1.022396).  Saving model ...
Validation loss decreased (1.022396 --> 1.020268).  Saving model ...
Validation loss decreased (1.020268 --> 1.016875).  Saving model ...
Validation loss decreased (1.016875 --> 1.014247).  Saving model ...
Validation loss decreased (1.014247 --> 1.010692).  Saving model ...
Validation loss decreased (1.010692 --> 1.006870).  Saving model ...
Validation loss decreased (1.006870 --> 1.004814).  Saving model ...
Validation loss decreased (1.004814 --> 1.002130).  Saving model ...
Validation loss decreased (1.002130 --> 0.999281).  Saving model ...
Validation loss decreased (0.999281 --> 0.998174).  Saving model ...
Validation loss decreased (0.998174 --> 0.997426).  Saving model ...
Validation loss decreased (0.997426 --> 0.994259).  Saving model ...
Validation loss decreased (0.994259 --> 0.993028).  Saving model ...
Validation loss decreased (0.993028 --> 0.990390).  Saving model ...
Validation loss decreased (0.990390 --> 0.988157).  Saving model ...
Validation loss decreased (0.988157 --> 0.986559).  Saving model ...
Validation loss decreased (0.986559 --> 0.985440).  Saving model ...
Validation loss decreased (0.985440 --> 0.984104).  Saving model ...
Validation loss decreased (0.984104 --> 0.981437).  Saving model ...
Validation loss decreased (0.981437 --> 0.978133).  Saving model ...
Validation loss decreased (0.978133 --> 0.976860).  Saving model ...
Validation loss decreased (0.976860 --> 0.975274).  Saving model ...
Validation loss decreased (0.975274 --> 0.972317).  Saving model ...
Validation loss decreased (0.972317 --> 0.969868).  Saving model ...
Validation loss decreased (0.969868 --> 0.969251).  Saving model ...
Validation loss decreased (0.969251 --> 0.968418).  Saving model ...
Validation loss decreased (0.968418 --> 0.967788).  Saving model ...
Validation loss decreased (0.967788 --> 0.966302).  Saving model ...
EarlyStopping counter: 1 out of 5.0
Validation loss decreased (0.966302 --> 0.965154).  Saving model ...
Validation loss decreased (0.965154 --> 0.964006).  Saving model ...
Validation loss decreased (0.964006 --> 0.962008).  Saving model ...
Validation loss decreased (0.962008 --> 0.962003).  Saving model ...
Validation loss decreased (0.962003 --> 0.961236).  Saving model ...
Validation loss decreased (0.961236 --> 0.957655).  Saving model ...
Validation loss decreased (0.957655 --> 0.957221).  Saving model ...
Validation loss decreased (0.957221 --> 0.957144).  Saving model ...
Validation loss decreased (0.957144 --> 0.956530).  Saving model ...
Validation loss decreased (0.956530 --> 0.954915).  Saving model ...
Validation loss decreased (0.954915 --> 0.953293).  Saving model ...
Validation loss decreased (0.953293 --> 0.951731).  Saving model ...
Validation loss decreased (0.951731 --> 0.950851).  Saving model ...
EarlyStopping counter: 1 out of 5.0
Validation loss decreased (0.950851 --> 0.950359).  Saving model ...
Validation loss decreased (0.950359 --> 0.949483).  Saving model ...
Validation loss decreased (0.949483 --> 0.949326).  Saving model ...
Validation loss decreased (0.949326 --> 0.946382).  Saving model ...
Validation loss decreased (0.946382 --> 0.945761).  Saving model ...
EarlyStopping counter: 1 out of 5.0
EarlyStopping counter: 2 out of 5.0
EarlyStopping counter: 3 out of 5.0
Validation loss decreased (0.945761 --> 0.944554).  Saving model ...
EarlyStopping counter: 1 out of 5.0
EarlyStopping counter: 2 out of 5.0
Validation loss decreased (0.944554 --> 0.944537).  Saving model ...
EarlyStopping counter: 1 out of 5.0
Validation loss decreased (0.944537 --> 0.944140).  Saving model ...
Validation loss decreased (0.944140 --> 0.942176).  Saving model ...
EarlyStopping counter: 1 out of 5.0
EarlyStopping counter: 2 out of 5.0
EarlyStopping counter: 3 out of 5.0
EarlyStopping counter: 4 out of 5.0
Validation loss decreased (0.942176 --> 0.941822).  Saving model ...
EarlyStopping counter: 1 out of 5.0
EarlyStopping counter: 2 out of 5.0
EarlyStopping counter: 3 out of 5.0
Validation loss decreased (0.941822 --> 0.940954).  Saving model ...
Validation loss decreased (0.940954 --> 0.939627).  Saving model ...
EarlyStopping counter: 1 out of 5.0
EarlyStopping counter: 2 out of 5.0
EarlyStopping counter: 3 out of 5.0
EarlyStopping counter: 4 out of 5.0
EarlyStopping counter: 5 out of 5.0
/localscratch/yinan.29031137.0/env/lib/python3.7/site-packages/torch/nn/functional.py:1794: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.
  warnings.warn("nn.functional.tanh is deprecated. Use torch.tanh instead.")
wandb: Waiting for W&B process to finish, PID 93382... (success).
wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: \ 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: | 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: / 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: \ 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: | 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: / 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: \ 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb:                                                                                
wandb: Run history:
wandb:     e_F1 ▁▂▃▄▅▆▆▆▆▆▆▇▇▇▇▇▇▇▇▇████████████████████
wandb:   e_loss █▇▇▇▆▆▆▅▅▄▄▄▄▃▃▃▃▃▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:     t_F1 ▁▁▂▂▃▃▄▄▄▅▅▅▅▅▆▆▆▆▆▆▇▇▆▇▇▇▇▇▇▇▇█▇▇██████
wandb:   t_loss ██▇▇▇▇▆▆▆▅▅▅▅▄▄▄▄▄▄▃▃▃▃▃▃▃▃▃▂▂▂▂▂▂▂▁▂▁▁▁
wandb: 
wandb: Run summary:
wandb:     e_F1 58.89819
wandb:   e_loss 0.94407
wandb:     t_F1 73.41813
wandb:   t_loss 0.71067
wandb: 
wandb: Synced 4 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Synced glowing-river-2: https://wandb.ai/yinanazhou/xl_512_bs_8_lr_1e06_es_5_lc_True_nr_False_sr_True_stem_False_lemma_False_repeat_4_fold_1/runs/2gyosi7p
wandb: Find logs at: ./wandb/run-20220316_132439-2gyosi7p/logs/debug.log
wandb: 

wandb: wandb version 0.12.11 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
2022-03-16 15:00:17.869071: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1
wandb: Tracking run with wandb version 0.12.5
wandb: Syncing run sunny-deluge-2
wandb: ⭐️ View project at https://wandb.ai/yinanazhou/xl_512_bs_8_lr_1e06_es_5_lc_True_nr_False_sr_True_stem_False_lemma_False_repeat_4_fold_2
wandb: 🚀 View run at https://wandb.ai/yinanazhou/xl_512_bs_8_lr_1e06_es_5_lc_True_nr_False_sr_True_stem_False_lemma_False_repeat_4_fold_2/runs/2hf7axho
wandb: Run data is saved locally in /project/6002780/yinan/Thesis_MER_Lyrics/lyric-emotion/wandb/run-20220316_150015-2hf7axho
wandb: Run `wandb offline` to turn off syncing.

Validation loss decreased (inf --> 1.417438).  Saving model ...
Validation loss decreased (1.417438 --> 1.402919).  Saving model ...
Validation loss decreased (1.402919 --> 1.391782).  Saving model ...
Validation loss decreased (1.391782 --> 1.383042).  Saving model ...
Validation loss decreased (1.383042 --> 1.375568).  Saving model ...
Validation loss decreased (1.375568 --> 1.369629).  Saving model ...
Validation loss decreased (1.369629 --> 1.364347).  Saving model ...
Validation loss decreased (1.364347 --> 1.359509).  Saving model ...
Validation loss decreased (1.359509 --> 1.354765).  Saving model ...
Validation loss decreased (1.354765 --> 1.350094).  Saving model ...
Validation loss decreased (1.350094 --> 1.345322).  Saving model ...
Validation loss decreased (1.345322 --> 1.339843).  Saving model ...
Validation loss decreased (1.339843 --> 1.335206).  Saving model ...
Validation loss decreased (1.335206 --> 1.330016).  Saving model ...
Validation loss decreased (1.330016 --> 1.324068).  Saving model ...
Validation loss decreased (1.324068 --> 1.317995).  Saving model ...
Validation loss decreased (1.317995 --> 1.311939).  Saving model ...
Validation loss decreased (1.311939 --> 1.305786).  Saving model ...
Validation loss decreased (1.305786 --> 1.298383).  Saving model ...
Validation loss decreased (1.298383 --> 1.290009).  Saving model ...
Validation loss decreased (1.290009 --> 1.282619).  Saving model ...
Validation loss decreased (1.282619 --> 1.274273).  Saving model ...
Validation loss decreased (1.274273 --> 1.266091).  Saving model ...
Validation loss decreased (1.266091 --> 1.256519).  Saving model ...
Validation loss decreased (1.256519 --> 1.245036).  Saving model ...
Validation loss decreased (1.245036 --> 1.234041).  Saving model ...
Validation loss decreased (1.234041 --> 1.225970).  Saving model ...
Validation loss decreased (1.225970 --> 1.216100).  Saving model ...
Validation loss decreased (1.216100 --> 1.207166).  Saving model ...
Validation loss decreased (1.207166 --> 1.196822).  Saving model ...
Validation loss decreased (1.196822 --> 1.187449).  Saving model ...
Validation loss decreased (1.187449 --> 1.180235).  Saving model ...
Validation loss decreased (1.180235 --> 1.171243).  Saving model ...
Validation loss decreased (1.171243 --> 1.162180).  Saving model ...
Validation loss decreased (1.162180 --> 1.156311).  Saving model ...
Validation loss decreased (1.156311 --> 1.147634).  Saving model ...
Validation loss decreased (1.147634 --> 1.140299).  Saving model ...
Validation loss decreased (1.140299 --> 1.133204).  Saving model ...
Validation loss decreased (1.133204 --> 1.125565).  Saving model ...
Validation loss decreased (1.125565 --> 1.117906).  Saving model ...
Validation loss decreased (1.117906 --> 1.111192).  Saving model ...
Validation loss decreased (1.111192 --> 1.105886).  Saving model ...
Validation loss decreased (1.105886 --> 1.100779).  Saving model ...
Validation loss decreased (1.100779 --> 1.093706).  Saving model ...
Validation loss decreased (1.093706 --> 1.085591).  Saving model ...
Validation loss decreased (1.085591 --> 1.079446).  Saving model ...
Validation loss decreased (1.079446 --> 1.071466).  Saving model ...
Validation loss decreased (1.071466 --> 1.065294).  Saving model ...
Validation loss decreased (1.065294 --> 1.061331).  Saving model ...
Validation loss decreased (1.061331 --> 1.056501).  Saving model ...
Validation loss decreased (1.056501 --> 1.050923).  Saving model ...
Validation loss decreased (1.050923 --> 1.047341).  Saving model ...
Validation loss decreased (1.047341 --> 1.043011).  Saving model ...
Validation loss decreased (1.043011 --> 1.037512).  Saving model ...
Validation loss decreased (1.037512 --> 1.033282).  Saving model ...
Validation loss decreased (1.033282 --> 1.030165).  Saving model ...
Validation loss decreased (1.030165 --> 1.025901).  Saving model ...
Validation loss decreased (1.025901 --> 1.019685).  Saving model ...
Validation loss decreased (1.019685 --> 1.015074).  Saving model ...
Validation loss decreased (1.015074 --> 1.011438).  Saving model ...
Validation loss decreased (1.011438 --> 1.007097).  Saving model ...
Validation loss decreased (1.007097 --> 1.002735).  Saving model ...
Validation loss decreased (1.002735 --> 1.000322).  Saving model ...
Validation loss decreased (1.000322 --> 0.995396).  Saving model ...
Validation loss decreased (0.995396 --> 0.991571).  Saving model ...
Validation loss decreased (0.991571 --> 0.987544).  Saving model ...
Validation loss decreased (0.987544 --> 0.984865).  Saving model ...
Validation loss decreased (0.984865 --> 0.981246).  Saving model ...
Validation loss decreased (0.981246 --> 0.979627).  Saving model ...
Validation loss decreased (0.979627 --> 0.977305).  Saving model ...
Validation loss decreased (0.977305 --> 0.974724).  Saving model ...
Validation loss decreased (0.974724 --> 0.972723).  Saving model ...
Validation loss decreased (0.972723 --> 0.969760).  Saving model ...
Validation loss decreased (0.969760 --> 0.966939).  Saving model ...
Validation loss decreased (0.966939 --> 0.963738).  Saving model ...
Validation loss decreased (0.963738 --> 0.962758).  Saving model ...
Validation loss decreased (0.962758 --> 0.960430).  Saving model ...
Validation loss decreased (0.960430 --> 0.958483).  Saving model ...
Validation loss decreased (0.958483 --> 0.956171).  Saving model ...
Validation loss decreased (0.956171 --> 0.953853).  Saving model ...
Validation loss decreased (0.953853 --> 0.952105).  Saving model ...
Validation loss decreased (0.952105 --> 0.949661).  Saving model ...
Validation loss decreased (0.949661 --> 0.947626).  Saving model ...
Validation loss decreased (0.947626 --> 0.945764).  Saving model ...
Validation loss decreased (0.945764 --> 0.943485).  Saving model ...
Validation loss decreased (0.943485 --> 0.941710).  Saving model ...
Validation loss decreased (0.941710 --> 0.940438).  Saving model ...
Validation loss decreased (0.940438 --> 0.938790).  Saving model ...
Validation loss decreased (0.938790 --> 0.937305).  Saving model ...
Validation loss decreased (0.937305 --> 0.935937).  Saving model ...
Validation loss decreased (0.935937 --> 0.934735).  Saving model ...
Validation loss decreased (0.934735 --> 0.933054).  Saving model ...
Validation loss decreased (0.933054 --> 0.931608).  Saving model ...
Validation loss decreased (0.931608 --> 0.930430).  Saving model ...
Validation loss decreased (0.930430 --> 0.928465).  Saving model ...
Validation loss decreased (0.928465 --> 0.927970).  Saving model ...
Validation loss decreased (0.927970 --> 0.926453).  Saving model ...
Validation loss decreased (0.926453 --> 0.924213).  Saving model ...
Validation loss decreased (0.924213 --> 0.923932).  Saving model ...
Validation loss decreased (0.923932 --> 0.923343).  Saving model ...
Validation loss decreased (0.923343 --> 0.922872).  Saving model ...
Validation loss decreased (0.922872 --> 0.922692).  Saving model ...
Validation loss decreased (0.922692 --> 0.921821).  Saving model ...
Validation loss decreased (0.921821 --> 0.919535).  Saving model ...
Validation loss decreased (0.919535 --> 0.919014).  Saving model ...
Validation loss decreased (0.919014 --> 0.917624).  Saving model ...
Validation loss decreased (0.917624 --> 0.916545).  Saving model ...
Validation loss decreased (0.916545 --> 0.916419).  Saving model ...
Validation loss decreased (0.916419 --> 0.915426).  Saving model ...
Validation loss decreased (0.915426 --> 0.915152).  Saving model ...
Validation loss decreased (0.915152 --> 0.914491).  Saving model ...
Validation loss decreased (0.914491 --> 0.912662).  Saving model ...
Validation loss decreased (0.912662 --> 0.912214).  Saving model ...
EarlyStopping counter: 1 out of 5.0
Validation loss decreased (0.912214 --> 0.911992).  Saving model ...
Validation loss decreased (0.911992 --> 0.910875).  Saving model ...
Validation loss decreased (0.910875 --> 0.910262).  Saving model ...
Validation loss decreased (0.910262 --> 0.909358).  Saving model ...
EarlyStopping counter: 1 out of 5.0
EarlyStopping counter: 2 out of 5.0
Validation loss decreased (0.909358 --> 0.908187).  Saving model ...
Validation loss decreased (0.908187 --> 0.906964).  Saving model ...
Validation loss decreased (0.906964 --> 0.906682).  Saving model ...
Validation loss decreased (0.906682 --> 0.905856).  Saving model ...
EarlyStopping counter: 1 out of 5.0
EarlyStopping counter: 2 out of 5.0
EarlyStopping counter: 3 out of 5.0
EarlyStopping counter: 4 out of 5.0
EarlyStopping counter: 5 out of 5.0
/localscratch/yinan.29031137.0/env/lib/python3.7/site-packages/torch/nn/functional.py:1794: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.
  warnings.warn("nn.functional.tanh is deprecated. Use torch.tanh instead.")
wandb: Waiting for W&B process to finish, PID 98508... (success).
wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: \ 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: | 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: / 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: \ 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: | 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: / 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: \ 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: | 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: / 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb:                                                                                
wandb: Run history:
wandb:     e_F1 ▁▁▄▄▅▆▆▆▆▆▇▇▇▇▇▇▇▇▇█████████████████████
wandb:   e_loss ██▇▇▇▇▆▆▆▅▅▄▄▄▃▃▃▃▂▂▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:     t_F1 ▁▁▂▂▂▃▄▄▄▄▅▅▅▅▆▆▆▆▆▆▇▇▆▇▇▇▇▇▇▇▇▇▇██▇█▇██
wandb:   t_loss ██▇▇▇▇▇▆▆▆▆▆▅▅▅▄▄▄▄▄▃▃▃▃▃▃▃▂▂▂▂▂▂▂▂▂▁▁▁▁
wandb: 
wandb: Run summary:
wandb:     e_F1 63.84389
wandb:   e_loss 0.90702
wandb:     t_F1 69.32053
wandb:   t_loss 0.77376
wandb: 
wandb: Synced 4 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Synced sunny-deluge-2: https://wandb.ai/yinanazhou/xl_512_bs_8_lr_1e06_es_5_lc_True_nr_False_sr_True_stem_False_lemma_False_repeat_4_fold_2/runs/2hf7axho
wandb: Find logs at: ./wandb/run-20220316_150015-2hf7axho/logs/debug.log
wandb: 

wandb: wandb version 0.12.11 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
2022-03-16 16:23:57.450897: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1
wandb: Tracking run with wandb version 0.12.5
wandb: Syncing run glamorous-dew-2
wandb: ⭐️ View project at https://wandb.ai/yinanazhou/xl_512_bs_8_lr_1e06_es_5_lc_True_nr_False_sr_True_stem_False_lemma_False_repeat_5_fold_1
wandb: 🚀 View run at https://wandb.ai/yinanazhou/xl_512_bs_8_lr_1e06_es_5_lc_True_nr_False_sr_True_stem_False_lemma_False_repeat_5_fold_1/runs/11s1tulj
wandb: Run data is saved locally in /project/6002780/yinan/Thesis_MER_Lyrics/lyric-emotion/wandb/run-20220316_162354-11s1tulj
wandb: Run `wandb offline` to turn off syncing.

Validation loss decreased (inf --> 1.417852).  Saving model ...
Validation loss decreased (1.417852 --> 1.397056).  Saving model ...
Validation loss decreased (1.397056 --> 1.383518).  Saving model ...
Validation loss decreased (1.383518 --> 1.373993).  Saving model ...
Validation loss decreased (1.373993 --> 1.366759).  Saving model ...
Validation loss decreased (1.366759 --> 1.359990).  Saving model ...
Validation loss decreased (1.359990 --> 1.354509).  Saving model ...
Validation loss decreased (1.354509 --> 1.349230).  Saving model ...
Validation loss decreased (1.349230 --> 1.344011).  Saving model ...
Validation loss decreased (1.344011 --> 1.339545).  Saving model ...
Validation loss decreased (1.339545 --> 1.333983).  Saving model ...
Validation loss decreased (1.333983 --> 1.329469).  Saving model ...
Validation loss decreased (1.329469 --> 1.324419).  Saving model ...
Validation loss decreased (1.324419 --> 1.318884).  Saving model ...
Validation loss decreased (1.318884 --> 1.313688).  Saving model ...
Validation loss decreased (1.313688 --> 1.308419).  Saving model ...
Validation loss decreased (1.308419 --> 1.302577).  Saving model ...
Validation loss decreased (1.302577 --> 1.297275).  Saving model ...
Validation loss decreased (1.297275 --> 1.291651).  Saving model ...
Validation loss decreased (1.291651 --> 1.285650).  Saving model ...
Validation loss decreased (1.285650 --> 1.279706).  Saving model ...
Validation loss decreased (1.279706 --> 1.273844).  Saving model ...
Validation loss decreased (1.273844 --> 1.267793).  Saving model ...
Validation loss decreased (1.267793 --> 1.262296).  Saving model ...
Validation loss decreased (1.262296 --> 1.256549).  Saving model ...
Validation loss decreased (1.256549 --> 1.250942).  Saving model ...
Validation loss decreased (1.250942 --> 1.244995).  Saving model ...
Validation loss decreased (1.244995 --> 1.239056).  Saving model ...
Validation loss decreased (1.239056 --> 1.232123).  Saving model ...
Validation loss decreased (1.232123 --> 1.225730).  Saving model ...
Validation loss decreased (1.225730 --> 1.218958).  Saving model ...
Validation loss decreased (1.218958 --> 1.213111).  Saving model ...
Validation loss decreased (1.213111 --> 1.206834).  Saving model ...
Validation loss decreased (1.206834 --> 1.200668).  Saving model ...
Validation loss decreased (1.200668 --> 1.194784).  Saving model ...
Validation loss decreased (1.194784 --> 1.189057).  Saving model ...
Validation loss decreased (1.189057 --> 1.184212).  Saving model ...
Validation loss decreased (1.184212 --> 1.178525).  Saving model ...
Validation loss decreased (1.178525 --> 1.172904).  Saving model ...
Validation loss decreased (1.172904 --> 1.168512).  Saving model ...
Validation loss decreased (1.168512 --> 1.162113).  Saving model ...
Validation loss decreased (1.162113 --> 1.157454).  Saving model ...
Validation loss decreased (1.157454 --> 1.151230).  Saving model ...
Validation loss decreased (1.151230 --> 1.145506).  Saving model ...
Validation loss decreased (1.145506 --> 1.139348).  Saving model ...
Validation loss decreased (1.139348 --> 1.133952).  Saving model ...
Validation loss decreased (1.133952 --> 1.130027).  Saving model ...
Validation loss decreased (1.130027 --> 1.126187).  Saving model ...
Validation loss decreased (1.126187 --> 1.120564).  Saving model ...
Validation loss decreased (1.120564 --> 1.115585).  Saving model ...
Validation loss decreased (1.115585 --> 1.113144).  Saving model ...
Validation loss decreased (1.113144 --> 1.110061).  Saving model ...
Validation loss decreased (1.110061 --> 1.103325).  Saving model ...
Validation loss decreased (1.103325 --> 1.098824).  Saving model ...
Validation loss decreased (1.098824 --> 1.092694).  Saving model ...
Validation loss decreased (1.092694 --> 1.088470).  Saving model ...
Validation loss decreased (1.088470 --> 1.084077).  Saving model ...
Validation loss decreased (1.084077 --> 1.078681).  Saving model ...
Validation loss decreased (1.078681 --> 1.074400).  Saving model ...
Validation loss decreased (1.074400 --> 1.071901).  Saving model ...
Validation loss decreased (1.071901 --> 1.067123).  Saving model ...
Validation loss decreased (1.067123 --> 1.064402).  Saving model ...
Validation loss decreased (1.064402 --> 1.060350).  Saving model ...
Validation loss decreased (1.060350 --> 1.054285).  Saving model ...
Validation loss decreased (1.054285 --> 1.052405).  Saving model ...
Validation loss decreased (1.052405 --> 1.049963).  Saving model ...
Validation loss decreased (1.049963 --> 1.046113).  Saving model ...
Validation loss decreased (1.046113 --> 1.044076).  Saving model ...
Validation loss decreased (1.044076 --> 1.040160).  Saving model ...
Validation loss decreased (1.040160 --> 1.037332).  Saving model ...
Validation loss decreased (1.037332 --> 1.036271).  Saving model ...
Validation loss decreased (1.036271 --> 1.032263).  Saving model ...
Validation loss decreased (1.032263 --> 1.028031).  Saving model ...
Validation loss decreased (1.028031 --> 1.021746).  Saving model ...
Validation loss decreased (1.021746 --> 1.019704).  Saving model ...
Validation loss decreased (1.019704 --> 1.016242).  Saving model ...
Validation loss decreased (1.016242 --> 1.014621).  Saving model ...
Validation loss decreased (1.014621 --> 1.013539).  Saving model ...
Validation loss decreased (1.013539 --> 1.009478).  Saving model ...
Validation loss decreased (1.009478 --> 1.007870).  Saving model ...
Validation loss decreased (1.007870 --> 1.003666).  Saving model ...
Validation loss decreased (1.003666 --> 1.002525).  Saving model ...
Validation loss decreased (1.002525 --> 0.999959).  Saving model ...
Validation loss decreased (0.999959 --> 0.998219).  Saving model ...
Validation loss decreased (0.998219 --> 0.995481).  Saving model ...
Validation loss decreased (0.995481 --> 0.993149).  Saving model ...
Validation loss decreased (0.993149 --> 0.991956).  Saving model ...
EarlyStopping counter: 1 out of 5.0
Validation loss decreased (0.991956 --> 0.991270).  Saving model ...
Validation loss decreased (0.991270 --> 0.989340).  Saving model ...
Validation loss decreased (0.989340 --> 0.987032).  Saving model ...
Validation loss decreased (0.987032 --> 0.983500).  Saving model ...
Validation loss decreased (0.983500 --> 0.982382).  Saving model ...
Validation loss decreased (0.982382 --> 0.980087).  Saving model ...
Validation loss decreased (0.980087 --> 0.976479).  Saving model ...
Validation loss decreased (0.976479 --> 0.976294).  Saving model ...
Validation loss decreased (0.976294 --> 0.973319).  Saving model ...
Validation loss decreased (0.973319 --> 0.970187).  Saving model ...
Validation loss decreased (0.970187 --> 0.968289).  Saving model ...
EarlyStopping counter: 1 out of 5.0
Validation loss decreased (0.968289 --> 0.965250).  Saving model ...
Validation loss decreased (0.965250 --> 0.964526).  Saving model ...
Validation loss decreased (0.964526 --> 0.962552).  Saving model ...
Validation loss decreased (0.962552 --> 0.961891).  Saving model ...
Validation loss decreased (0.961891 --> 0.960927).  Saving model ...
Validation loss decreased (0.960927 --> 0.960670).  Saving model ...
Validation loss decreased (0.960670 --> 0.958643).  Saving model ...
Validation loss decreased (0.958643 --> 0.956725).  Saving model ...
Validation loss decreased (0.956725 --> 0.955868).  Saving model ...
EarlyStopping counter: 1 out of 5.0
Validation loss decreased (0.955868 --> 0.955470).  Saving model ...
Validation loss decreased (0.955470 --> 0.953924).  Saving model ...
Validation loss decreased (0.953924 --> 0.953908).  Saving model ...
Validation loss decreased (0.953908 --> 0.949948).  Saving model ...
EarlyStopping counter: 1 out of 5.0
EarlyStopping counter: 2 out of 5.0
Validation loss decreased (0.949948 --> 0.949042).  Saving model ...
Validation loss decreased (0.949042 --> 0.947750).  Saving model ...
Validation loss decreased (0.947750 --> 0.946525).  Saving model ...
EarlyStopping counter: 1 out of 5.0
EarlyStopping counter: 2 out of 5.0
EarlyStopping counter: 3 out of 5.0
Validation loss decreased (0.946525 --> 0.945071).  Saving model ...
Validation loss decreased (0.945071 --> 0.944555).  Saving model ...
Validation loss decreased (0.944555 --> 0.942833).  Saving model ...
Validation loss decreased (0.942833 --> 0.941164).  Saving model ...
EarlyStopping counter: 1 out of 5.0
EarlyStopping counter: 2 out of 5.0
Validation loss decreased (0.941164 --> 0.940241).  Saving model ...
Validation loss decreased (0.940241 --> 0.939463).  Saving model ...
Validation loss decreased (0.939463 --> 0.938269).  Saving model ...
EarlyStopping counter: 1 out of 5.0
EarlyStopping counter: 2 out of 5.0
EarlyStopping counter: 3 out of 5.0
EarlyStopping counter: 4 out of 5.0
EarlyStopping counter: 5 out of 5.0
/localscratch/yinan.29031137.0/env/lib/python3.7/site-packages/torch/nn/functional.py:1794: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.
  warnings.warn("nn.functional.tanh is deprecated. Use torch.tanh instead.")
wandb: Waiting for W&B process to finish, PID 102996... (success).
wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: \ 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: | 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: / 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: \ 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: | 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: / 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: \ 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: | 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb:                                                                                
wandb: Run history:
wandb:     e_F1 ▁▂▄▄▄▅▅▆▆▆▆▆▇▇▇▆▇▇▇▇▇▇▇▇▇▇▇█████████████
wandb:   e_loss ██▇▇▇▆▆▆▆▅▅▅▄▄▄▄▃▃▃▃▂▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁
wandb:     t_F1 ▁▂▃▃▃▃▄▄▅▅▅▅▆▅▆▆▆▆▆▆▇▇▇▇▇▇▇▇▇▇█▇▇▇██████
wandb:   t_loss ██▇▇▇▇▇▆▆▆▆▆▅▅▅▄▄▄▄▄▄▃▃▃▃▃▂▃▂▂▂▂▂▂▂▁▂▁▁▁
wandb: 
wandb: Run summary:
wandb:     e_F1 58.74195
wandb:   e_loss 0.94098
wandb:     t_F1 71.61537
wandb:   t_loss 0.7538
wandb: 
wandb: Synced 4 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Synced glamorous-dew-2: https://wandb.ai/yinanazhou/xl_512_bs_8_lr_1e06_es_5_lc_True_nr_False_sr_True_stem_False_lemma_False_repeat_5_fold_1/runs/11s1tulj
wandb: Find logs at: ./wandb/run-20220316_162354-11s1tulj/logs/debug.log
wandb: 

wandb: wandb version 0.12.11 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
2022-03-16 17:54:21.659248: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1
wandb: Tracking run with wandb version 0.12.5
wandb: Syncing run cool-blaze-2
wandb: ⭐️ View project at https://wandb.ai/yinanazhou/xl_512_bs_8_lr_1e06_es_5_lc_True_nr_False_sr_True_stem_False_lemma_False_repeat_5_fold_2
wandb: 🚀 View run at https://wandb.ai/yinanazhou/xl_512_bs_8_lr_1e06_es_5_lc_True_nr_False_sr_True_stem_False_lemma_False_repeat_5_fold_2/runs/37skyone
wandb: Run data is saved locally in /project/6002780/yinan/Thesis_MER_Lyrics/lyric-emotion/wandb/run-20220316_175418-37skyone
wandb: Run `wandb offline` to turn off syncing.

Validation loss decreased (inf --> 1.522456).  Saving model ...
Validation loss decreased (1.522456 --> 1.481266).  Saving model ...
Validation loss decreased (1.481266 --> 1.451149).  Saving model ...
Validation loss decreased (1.451149 --> 1.429767).  Saving model ...
Validation loss decreased (1.429767 --> 1.413981).  Saving model ...
Validation loss decreased (1.413981 --> 1.402630).  Saving model ...
Validation loss decreased (1.402630 --> 1.394070).  Saving model ...
Validation loss decreased (1.394070 --> 1.386739).  Saving model ...
Validation loss decreased (1.386739 --> 1.380820).  Saving model ...
Validation loss decreased (1.380820 --> 1.375009).  Saving model ...
Validation loss decreased (1.375009 --> 1.370234).  Saving model ...
Validation loss decreased (1.370234 --> 1.365386).  Saving model ...
Validation loss decreased (1.365386 --> 1.359648).  Saving model ...
Validation loss decreased (1.359648 --> 1.354462).  Saving model ...
Validation loss decreased (1.354462 --> 1.349192).  Saving model ...
Validation loss decreased (1.349192 --> 1.342957).  Saving model ...
Validation loss decreased (1.342957 --> 1.336395).  Saving model ...
Validation loss decreased (1.336395 --> 1.328148).  Saving model ...
Validation loss decreased (1.328148 --> 1.320774).  Saving model ...
Validation loss decreased (1.320774 --> 1.313568).  Saving model ...
Validation loss decreased (1.313568 --> 1.305319).  Saving model ...
Validation loss decreased (1.305319 --> 1.296741).  Saving model ...
Validation loss decreased (1.296741 --> 1.288862).  Saving model ...
Validation loss decreased (1.288862 --> 1.280661).  Saving model ...
Validation loss decreased (1.280661 --> 1.272982).  Saving model ...
Validation loss decreased (1.272982 --> 1.264298).  Saving model ...
Validation loss decreased (1.264298 --> 1.254039).  Saving model ...
Validation loss decreased (1.254039 --> 1.245760).  Saving model ...
Validation loss decreased (1.245760 --> 1.237918).  Saving model ...
Validation loss decreased (1.237918 --> 1.227913).  Saving model ...
Validation loss decreased (1.227913 --> 1.220050).  Saving model ...
Validation loss decreased (1.220050 --> 1.211824).  Saving model ...
Validation loss decreased (1.211824 --> 1.202859).  Saving model ...
Validation loss decreased (1.202859 --> 1.194321).  Saving model ...
Validation loss decreased (1.194321 --> 1.187630).  Saving model ...
Validation loss decreased (1.187630 --> 1.180601).  Saving model ...
Validation loss decreased (1.180601 --> 1.173774).  Saving model ...
Validation loss decreased (1.173774 --> 1.165781).  Saving model ...
Validation loss decreased (1.165781 --> 1.157275).  Saving model ...
Validation loss decreased (1.157275 --> 1.151194).  Saving model ...
Validation loss decreased (1.151194 --> 1.144484).  Saving model ...
Validation loss decreased (1.144484 --> 1.138439).  Saving model ...
Validation loss decreased (1.138439 --> 1.131070).  Saving model ...
Validation loss decreased (1.131070 --> 1.124549).  Saving model ...
Validation loss decreased (1.124549 --> 1.117916).  Saving model ...
Validation loss decreased (1.117916 --> 1.109455).  Saving model ...
Validation loss decreased (1.109455 --> 1.104145).  Saving model ...
Validation loss decreased (1.104145 --> 1.100201).  Saving model ...
Validation loss decreased (1.100201 --> 1.093976).  Saving model ...
Validation loss decreased (1.093976 --> 1.088658).  Saving model ...
Validation loss decreased (1.088658 --> 1.082296).  Saving model ...
Validation loss decreased (1.082296 --> 1.075411).  Saving model ...
Validation loss decreased (1.075411 --> 1.071451).  Saving model ...
Validation loss decreased (1.071451 --> 1.065842).  Saving model ...
Validation loss decreased (1.065842 --> 1.063402).  Saving model ...
Validation loss decreased (1.063402 --> 1.057749).  Saving model ...
Validation loss decreased (1.057749 --> 1.051481).  Saving model ...
Validation loss decreased (1.051481 --> 1.047371).  Saving model ...
Validation loss decreased (1.047371 --> 1.044266).  Saving model ...
Validation loss decreased (1.044266 --> 1.041457).  Saving model ...
Validation loss decreased (1.041457 --> 1.038319).  Saving model ...
Validation loss decreased (1.038319 --> 1.031649).  Saving model ...
Validation loss decreased (1.031649 --> 1.027204).  Saving model ...
Validation loss decreased (1.027204 --> 1.023858).  Saving model ...
Validation loss decreased (1.023858 --> 1.019479).  Saving model ...
Validation loss decreased (1.019479 --> 1.015870).  Saving model ...
Validation loss decreased (1.015870 --> 1.012314).  Saving model ...
Validation loss decreased (1.012314 --> 1.010203).  Saving model ...
Validation loss decreased (1.010203 --> 1.007997).  Saving model ...
Validation loss decreased (1.007997 --> 1.003802).  Saving model ...
Validation loss decreased (1.003802 --> 1.000182).  Saving model ...
Validation loss decreased (1.000182 --> 0.997677).  Saving model ...
Validation loss decreased (0.997677 --> 0.994506).  Saving model ...
Validation loss decreased (0.994506 --> 0.992698).  Saving model ...
Validation loss decreased (0.992698 --> 0.991511).  Saving model ...
Validation loss decreased (0.991511 --> 0.987690).  Saving model ...
Validation loss decreased (0.987690 --> 0.983970).  Saving model ...
Validation loss decreased (0.983970 --> 0.979740).  Saving model ...
Validation loss decreased (0.979740 --> 0.977629).  Saving model ...
Validation loss decreased (0.977629 --> 0.973217).  Saving model ...
Validation loss decreased (0.973217 --> 0.971273).  Saving model ...
Validation loss decreased (0.971273 --> 0.969075).  Saving model ...
Validation loss decreased (0.969075 --> 0.966611).  Saving model ...
Validation loss decreased (0.966611 --> 0.964742).  Saving model ...
Validation loss decreased (0.964742 --> 0.962818).  Saving model ...
Validation loss decreased (0.962818 --> 0.962169).  Saving model ...
Validation loss decreased (0.962169 --> 0.960745).  Saving model ...
Validation loss decreased (0.960745 --> 0.959467).  Saving model ...
Validation loss decreased (0.959467 --> 0.957203).  Saving model ...
Validation loss decreased (0.957203 --> 0.955479).  Saving model ...
Validation loss decreased (0.955479 --> 0.952914).  Saving model ...
Validation loss decreased (0.952914 --> 0.949141).  Saving model ...
Validation loss decreased (0.949141 --> 0.947202).  Saving model ...
EarlyStopping counter: 1 out of 5.0
Validation loss decreased (0.947202 --> 0.946415).  Saving model ...
Validation loss decreased (0.946415 --> 0.942778).  Saving model ...
Validation loss decreased (0.942778 --> 0.940545).  Saving model ...
Validation loss decreased (0.940545 --> 0.940279).  Saving model ...
Validation loss decreased (0.940279 --> 0.938272).  Saving model ...
Validation loss decreased (0.938272 --> 0.936269).  Saving model ...
Validation loss decreased (0.936269 --> 0.933850).  Saving model ...
Validation loss decreased (0.933850 --> 0.933338).  Saving model ...
Validation loss decreased (0.933338 --> 0.930252).  Saving model ...
Validation loss decreased (0.930252 --> 0.929596).  Saving model ...
Validation loss decreased (0.929596 --> 0.928310).  Saving model ...
Validation loss decreased (0.928310 --> 0.927063).  Saving model ...
EarlyStopping counter: 1 out of 5.0
EarlyStopping counter: 2 out of 5.0
Validation loss decreased (0.927063 --> 0.924643).  Saving model ...
Validation loss decreased (0.924643 --> 0.923373).  Saving model ...
Validation loss decreased (0.923373 --> 0.922428).  Saving model ...
EarlyStopping counter: 1 out of 5.0
EarlyStopping counter: 2 out of 5.0
Validation loss decreased (0.922428 --> 0.920136).  Saving model ...
Validation loss decreased (0.920136 --> 0.919510).  Saving model ...
Validation loss decreased (0.919510 --> 0.919004).  Saving model ...
Validation loss decreased (0.919004 --> 0.918924).  Saving model ...
Validation loss decreased (0.918924 --> 0.917152).  Saving model ...
Validation loss decreased (0.917152 --> 0.916411).  Saving model ...
Validation loss decreased (0.916411 --> 0.916184).  Saving model ...
Validation loss decreased (0.916184 --> 0.915594).  Saving model ...
EarlyStopping counter: 1 out of 5.0
Validation loss decreased (0.915594 --> 0.914423).  Saving model ...
Validation loss decreased (0.914423 --> 0.914368).  Saving model ...
EarlyStopping counter: 1 out of 5.0
Validation loss decreased (0.914368 --> 0.913731).  Saving model ...
Validation loss decreased (0.913731 --> 0.913571).  Saving model ...
EarlyStopping counter: 1 out of 5.0
Validation loss decreased (0.913571 --> 0.912070).  Saving model ...
EarlyStopping counter: 1 out of 5.0
EarlyStopping counter: 2 out of 5.0
Validation loss decreased (0.912070 --> 0.911325).  Saving model ...
EarlyStopping counter: 1 out of 5.0
EarlyStopping counter: 2 out of 5.0
EarlyStopping counter: 3 out of 5.0
EarlyStopping counter: 4 out of 5.0
EarlyStopping counter: 5 out of 5.0
/localscratch/yinan.29031137.0/env/lib/python3.7/site-packages/torch/nn/functional.py:1794: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.
  warnings.warn("nn.functional.tanh is deprecated. Use torch.tanh instead.")
wandb: Waiting for W&B process to finish, PID 107835... (success).
wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: \ 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: | 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: / 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: \ 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: | 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: / 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: \ 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: | 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: / 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb:                                                                                
wandb: Run history:
wandb:     e_F1 ▁▁▃▄▄▅▅▅▆▆▆▆▆▇▇▇▇▇▇▇▇▇▇█████████████████
wandb:   e_loss █▇▇▇▆▆▆▅▅▅▄▄▄▃▃▃▃▃▂▂▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:     t_F1 ▁▁▁▃▃▄▄▅▅▅▅▅▅▆▆▆▆▆▆▇▇▆▇▇▇▇▇▇▇▇▇▇▇▇▇▇████
wandb:   t_loss ██▇▇▇▆▆▆▆▆▅▅▅▅▄▄▄▄▄▃▃▃▃▃▃▃▃▂▂▂▂▂▂▂▂▂▁▂▁▁
wandb: 
wandb: Run summary:
wandb:     e_F1 62.57458
wandb:   e_loss 0.91438
wandb:     t_F1 73.68017
wandb:   t_loss 0.75163
wandb: 
wandb: Synced 4 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Synced cool-blaze-2: https://wandb.ai/yinanazhou/xl_512_bs_8_lr_1e06_es_5_lc_True_nr_False_sr_True_stem_False_lemma_False_repeat_5_fold_2/runs/37skyone
wandb: Find logs at: ./wandb/run-20220316_175418-37skyone/logs/debug.log
wandb: 

