Unloading StdEnv/2020

Due to MODULEPATH changes, the following have been reloaded:
  1) mii/1.1.1


The following have been reloaded with a version change:
  1) python/3.8.2 => python/3.7.4

Using base prefix '/cvmfs/soft.computecanada.ca/easybuild/software/2017/Core/python/3.7.4'
New python executable in /localscratch/yinan.29019368.0/env/bin/python
Installing setuptools, pip, wheel...
done.
Ignoring pip: markers 'python_version < "3"' don't match your environment
Looking in links: /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/nix/avx2, /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/nix/generic, /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic
Collecting pip
Installing collected packages: pip
  Found existing installation: pip 19.1.1
    Uninstalling pip-19.1.1:
      Successfully uninstalled pip-19.1.1
Successfully installed pip-21.2.3+computecanada
Looking in links: /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/nix/avx2, /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/nix/generic, /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/keras-2.8.0+computecanada-py2.py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/Keras_Preprocessing-1.1.2+computecanada-py3-none-any.whl
Requirement already satisfied: matplotlib in /cvmfs/soft.computecanada.ca/easybuild/software/2017/Core/scipy-stack/2019a/lib/python3.7/site-packages (from -r requirements.txt (line 3)) (3.0.2)
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/nltk-3.6.5+computecanada-py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/scikit_learn-0.22.1+computecanada-cp37-cp37m-linux_x86_64.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/tensorboard-2.3.0+computecanada-py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/tensorboard_plugin_wit-1.7.0+computecanada-py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/tensorflow_gpu-2.3.0+computecanada-cp37-cp37m-linux_x86_64.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/tensorflow_estimator-2.3.0+computecanada-py2.py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/tokenizers-0.5.2+computecanada-cp37-cp37m-linux_x86_64.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/nix/avx2/torch-1.4.0+computecanada-cp37-cp37m-linux_x86_64.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/torchtext-0.6.0+computecanada-py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/torchvision-0.8.2+computecanada-cp37-cp37m-linux_x86_64.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/transformers-2.5.1+computecanada-py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/urllib3-1.26.7+computecanada-py2.py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/click-8.0.4+computecanada-py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/tqdm-4.63.0+computecanada-py2.py3-none-any.whl
ERROR: Could not find a version that satisfies the requirement regex>=2021.8.3 (from nltk) (from versions: 2018.1.10+computecanada, 2019.11.1+computecanada, 2020.11.13+computecanada)
ERROR: No matching distribution found for regex>=2021.8.3
Looking in links: /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/nix/avx2, /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/nix/generic, /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic
ERROR: Could not find a version that satisfies the requirement numpy==1.20.0+computacanada (from versions: 1.15.0+computecanada, 1.15.2+computecanada, 1.15.4+computecanada, 1.16.0+computecanada, 1.16.2+computecanada, 1.16.3+computecanada, 1.17.4+computecanada, 1.18.1+computecanada, 1.18.4+computecanada, 1.19.1+computecanada, 1.19.2+computecanada, 1.20.2+computecanada)
ERROR: No matching distribution found for numpy==1.20.0+computacanada
Looking in links: /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/nix/avx2, /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/nix/generic, /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/wandb-0.12.5+computecanada-py2.py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/click-8.0.4+computecanada-py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/promise-2.3+computecanada-py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/subprocess32-3.5.4+computecanada-py3-none-any.whl
Requirement already satisfied: requests<3,>=2.0.0 in /cvmfs/soft.computecanada.ca/easybuild/software/2017/Core/scipy-stack/2019a/lib/python3.7/site-packages (from wandb) (2.21.0)
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/psutil-5.7.3+computecanada-cp37-cp37m-linux_x86_64.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/sentry_sdk-1.5.0+computecanada-py2.py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/yaspin-2.1.0+computecanada-py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/PyYAML-5.3.1+computecanada-cp37-cp37m-linux_x86_64.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/shortuuid-1.0.1+computecanada-py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/protobuf-3.19.4+computecanada-py2.py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/configparser-5.0.2+computecanada-py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/six-1.16.0+computecanada-py2.py3-none-any.whl
Requirement already satisfied: python-dateutil>=2.6.1 in /cvmfs/soft.computecanada.ca/easybuild/software/2017/Core/scipy-stack/2019a/lib/python3.7/site-packages (from wandb) (2.7.5)
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/pathtools-0.1.2+computecanada-py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/docker_pycreds-0.4.0+computecanada-py2.py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/GitPython-3.1.24+computecanada-py3-none-any.whl
Requirement already satisfied: importlib-metadata in /cvmfs/soft.computecanada.ca/easybuild/software/2017/Core/scipy-stack/2019a/lib/python3.7/site-packages (from Click!=8.0.0,>=7.0->wandb) (0.8)
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/gitdb-4.0.9+computecanada-py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/typing_extensions-4.0.1+computecanada-py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/smmap-5.0.0+computecanada-py3-none-any.whl
Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /cvmfs/soft.computecanada.ca/easybuild/software/2017/Core/scipy-stack/2019a/lib/python3.7/site-packages (from requests<3,>=2.0.0->wandb) (3.0.4)
Requirement already satisfied: certifi>=2017.4.17 in /cvmfs/soft.computecanada.ca/easybuild/software/2017/Core/scipy-stack/2019a/lib/python3.7/site-packages (from requests<3,>=2.0.0->wandb) (2018.11.29)
Requirement already satisfied: urllib3<1.25,>=1.21.1 in /cvmfs/soft.computecanada.ca/easybuild/software/2017/Core/scipy-stack/2019a/lib/python3.7/site-packages (from requests<3,>=2.0.0->wandb) (1.24.1)
Requirement already satisfied: idna<2.9,>=2.5 in /cvmfs/soft.computecanada.ca/easybuild/software/2017/Core/scipy-stack/2019a/lib/python3.7/site-packages (from requests<3,>=2.0.0->wandb) (2.8)
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/termcolor-1.1.0+computecanada-py3-none-any.whl
Requirement already satisfied: zipp>=0.3.2 in /cvmfs/soft.computecanada.ca/easybuild/software/2017/Core/scipy-stack/2019a/lib/python3.7/site-packages (from importlib-metadata->Click!=8.0.0,>=7.0->wandb) (0.3.3)
Installing collected packages: smmap, typing-extensions, termcolor, six, gitdb, yaspin, subprocess32, shortuuid, sentry-sdk, PyYAML, psutil, protobuf, promise, pathtools, GitPython, docker-pycreds, configparser, Click, wandb
  Attempting uninstall: six
    Found existing installation: six 1.12.0
    Not uninstalling six at /cvmfs/soft.computecanada.ca/easybuild/software/2017/Core/scipy-stack/2019a/lib/python3.7/site-packages, outside environment /localscratch/yinan.29019368.0/env
    Can't uninstall 'six'. No files were found to uninstall.
Successfully installed Click-8.0.4+computecanada GitPython-3.1.24+computecanada PyYAML-5.3.1+computecanada configparser-5.0.2+computecanada docker-pycreds-0.4.0+computecanada gitdb-4.0.9+computecanada pathtools-0.1.2+computecanada promise-2.3+computecanada protobuf-3.19.4+computecanada psutil-5.7.3+computecanada sentry-sdk-1.5.0+computecanada shortuuid-1.0.1+computecanada six-1.16.0+computecanada smmap-5.0.0+computecanada subprocess32-3.5.4+computecanada termcolor-1.1.0+computecanada typing-extensions-4.0.1+computecanada wandb-0.12.5+computecanada yaspin-2.1.0+computecanada
Looking in links: /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/nix/avx2, /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/nix/generic, /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic
ERROR: Could not find a version that satisfies the requirement sagemaker (from versions: none)
ERROR: No matching distribution found for sagemaker
Looking in links: /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/nix/avx2, /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/nix/generic, /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/torch-1.9.1+computecanada-cp37-cp37m-linux_x86_64.whl
Requirement already satisfied: typing-extensions in /localscratch/yinan.29019368.0/env/lib/python3.7/site-packages (from torch) (4.0.1+computecanada)
Installing collected packages: torch
Successfully installed torch-1.9.1+computecanada
Looking in links: /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/nix/avx2, /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/nix/generic, /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/transformers-2.5.1+computecanada-py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/sentencepiece-0.1.91+computecanada-cp37-cp37m-linux_x86_64.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/sacremoses-0.0.46+computecanada-py3-none-any.whl
Requirement already satisfied: numpy in /cvmfs/soft.computecanada.ca/easybuild/software/2017/Core/scipy-stack/2019a/lib/python3.7/site-packages (from transformers==2.5.1+computecanada) (1.16.0)
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/tqdm-4.63.0+computecanada-py2.py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/tokenizers-0.5.2+computecanada-cp37-cp37m-linux_x86_64.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/regex-2020.11.13+computecanada-cp37-cp37m-linux_x86_64.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/boto3-1.21.14+computecanada-py3-none-any.whl
Requirement already satisfied: requests in /cvmfs/soft.computecanada.ca/easybuild/software/2017/Core/scipy-stack/2019a/lib/python3.7/site-packages (from transformers==2.5.1+computecanada) (2.21.0)
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/filelock-3.4.2+computecanada-py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/botocore-1.24.14+computecanada-py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/s3transfer-0.5.1+computecanada-py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/jmespath-0.10.0+computecanada-py2.py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/urllib3-1.26.8+computecanada-py2.py3-none-any.whl
Requirement already satisfied: python-dateutil<3.0.0,>=2.1 in /cvmfs/soft.computecanada.ca/easybuild/software/2017/Core/scipy-stack/2019a/lib/python3.7/site-packages (from botocore<1.25.0,>=1.24.14->boto3->transformers==2.5.1+computecanada) (2.7.5)
Requirement already satisfied: six>=1.5 in /localscratch/yinan.29019368.0/env/lib/python3.7/site-packages (from python-dateutil<3.0.0,>=2.1->botocore<1.25.0,>=1.24.14->boto3->transformers==2.5.1+computecanada) (1.16.0+computecanada)
Requirement already satisfied: certifi>=2017.4.17 in /cvmfs/soft.computecanada.ca/easybuild/software/2017/Core/scipy-stack/2019a/lib/python3.7/site-packages (from requests->transformers==2.5.1+computecanada) (2018.11.29)
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/requests-2.27.1+computecanada-py2.py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/charset_normalizer-2.0.12+computecanada-py3-none-any.whl
Requirement already satisfied: idna<4,>=2.5 in /cvmfs/soft.computecanada.ca/easybuild/software/2017/Core/scipy-stack/2019a/lib/python3.7/site-packages (from requests->transformers==2.5.1+computecanada) (2.8)
Requirement already satisfied: click in /localscratch/yinan.29019368.0/env/lib/python3.7/site-packages (from sacremoses->transformers==2.5.1+computecanada) (8.0.4+computecanada)
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/joblib-1.1.0+computecanada-py2.py3-none-any.whl
Requirement already satisfied: importlib-metadata in /cvmfs/soft.computecanada.ca/easybuild/software/2017/Core/scipy-stack/2019a/lib/python3.7/site-packages (from click->sacremoses->transformers==2.5.1+computecanada) (0.8)
Requirement already satisfied: zipp>=0.3.2 in /cvmfs/soft.computecanada.ca/easybuild/software/2017/Core/scipy-stack/2019a/lib/python3.7/site-packages (from importlib-metadata->click->sacremoses->transformers==2.5.1+computecanada) (0.3.3)
Installing collected packages: urllib3, jmespath, botocore, tqdm, s3transfer, regex, joblib, charset-normalizer, tokenizers, sentencepiece, sacremoses, requests, filelock, boto3, transformers
  Attempting uninstall: urllib3
    Found existing installation: urllib3 1.24.1
    Not uninstalling urllib3 at /cvmfs/soft.computecanada.ca/easybuild/software/2017/Core/scipy-stack/2019a/lib/python3.7/site-packages, outside environment /localscratch/yinan.29019368.0/env
    Can't uninstall 'urllib3'. No files were found to uninstall.
  Attempting uninstall: requests
    Found existing installation: requests 2.21.0
    Not uninstalling requests at /cvmfs/soft.computecanada.ca/easybuild/software/2017/Core/scipy-stack/2019a/lib/python3.7/site-packages, outside environment /localscratch/yinan.29019368.0/env
    Can't uninstall 'requests'. No files were found to uninstall.
Successfully installed boto3-1.21.14+computecanada botocore-1.24.14+computecanada charset-normalizer-2.0.12+computecanada filelock-3.4.2+computecanada jmespath-0.10.0+computecanada joblib-1.1.0+computecanada regex-2020.11.13+computecanada requests-2.27.1+computecanada s3transfer-0.5.1+computecanada sacremoses-0.0.46+computecanada sentencepiece-0.1.91+computecanada tokenizers-0.5.2+computecanada tqdm-4.63.0+computecanada transformers-2.5.1+computecanada urllib3-1.26.8+computecanada
Looking in links: /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/nix/avx2, /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/nix/generic, /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/tensorflow_gpu-2.3.0+computecanada-cp37-cp37m-linux_x86_64.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/google_pasta-0.2.0+computecanada-py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/opt_einsum-3.3.0+computecanada-py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/wrapt-1.11.2+computecanada-cp37-cp37m-linux_x86_64.whl
Requirement already satisfied: protobuf>=3.9.2 in /localscratch/yinan.29019368.0/env/lib/python3.7/site-packages (from tensorflow_gpu==2.3.0+computecanada) (3.19.4+computecanada)
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/gast-0.3.3+computecanada-py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/tensorboard-2.8.0+computecanada-py3-none-any.whl
Requirement already satisfied: wheel>=0.26 in /localscratch/yinan.29019368.0/env/lib/python3.7/site-packages (from tensorflow_gpu==2.3.0+computecanada) (0.33.4)
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/nix/generic/scipy-1.4.1+computecanada-cp37-cp37m-linux_x86_64.whl
Requirement already satisfied: six>=1.12.0 in /localscratch/yinan.29019368.0/env/lib/python3.7/site-packages (from tensorflow_gpu==2.3.0+computecanada) (1.16.0+computecanada)
Requirement already satisfied: numpy<1.19.0,>=1.16.0 in /cvmfs/soft.computecanada.ca/easybuild/software/2017/Core/scipy-stack/2019a/lib/python3.7/site-packages (from tensorflow_gpu==2.3.0+computecanada) (1.16.0)
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/nix/avx2/h5py-2.10.0+computecanada-cp37-cp37m-linux_x86_64.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/absl_py-1.0.0+computecanada-py3-none-any.whl
Requirement already satisfied: termcolor>=1.1.0 in /localscratch/yinan.29019368.0/env/lib/python3.7/site-packages (from tensorflow_gpu==2.3.0+computecanada) (1.1.0+computecanada)
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/Keras_Preprocessing-1.1.2+computecanada-py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/tensorflow_estimator-2.3.0+computecanada-py2.py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/astunparse-1.6.3+computecanada-py2.py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/grpcio-1.38.0+computecanada-cp37-cp37m-linux_x86_64.whl
Requirement already satisfied: requests<3,>=2.21.0 in /localscratch/yinan.29019368.0/env/lib/python3.7/site-packages (from tensorboard<3,>=2.3.0->tensorflow_gpu==2.3.0+computecanada) (2.27.1+computecanada)
Requirement already satisfied: setuptools>=41.0.0 in /localscratch/yinan.29019368.0/env/lib/python3.7/site-packages (from tensorboard<3,>=2.3.0->tensorflow_gpu==2.3.0+computecanada) (41.0.1)
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/Markdown-3.3.6+computecanada-py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/Werkzeug-2.0.3+computecanada-py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/google_auth-2.3.3+computecanada-py2.py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/tensorboard_plugin_wit-1.8.0+computecanada-py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/google_auth_oauthlib-0.4.6+computecanada-py2.py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/tensorboard_data_server-0.6.1+computecanada-py3-none-linux_x86_64.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/cachetools-4.2.4+computecanada-py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/pyasn1_modules-0.2.8+computecanada-py2.py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/rsa-4.8+computecanada-py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/requests_oauthlib-1.3.0+computecanada-py2.py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/importlib_metadata-4.10.1+computecanada-py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/zipp-3.7.0+computecanada-py3-none-any.whl
Requirement already satisfied: typing-extensions>=3.6.4 in /localscratch/yinan.29019368.0/env/lib/python3.7/site-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard<3,>=2.3.0->tensorflow_gpu==2.3.0+computecanada) (4.0.1+computecanada)
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/pyasn1-0.4.8+computecanada-py2.py3-none-any.whl
Requirement already satisfied: certifi>=2017.4.17 in /cvmfs/soft.computecanada.ca/easybuild/software/2017/Core/scipy-stack/2019a/lib/python3.7/site-packages (from requests<3,>=2.21.0->tensorboard<3,>=2.3.0->tensorflow_gpu==2.3.0+computecanada) (2018.11.29)
Requirement already satisfied: urllib3<1.27,>=1.21.1 in /localscratch/yinan.29019368.0/env/lib/python3.7/site-packages (from requests<3,>=2.21.0->tensorboard<3,>=2.3.0->tensorflow_gpu==2.3.0+computecanada) (1.26.8+computecanada)
Requirement already satisfied: charset-normalizer~=2.0.0 in /localscratch/yinan.29019368.0/env/lib/python3.7/site-packages (from requests<3,>=2.21.0->tensorboard<3,>=2.3.0->tensorflow_gpu==2.3.0+computecanada) (2.0.12+computecanada)
Requirement already satisfied: idna<4,>=2.5 in /cvmfs/soft.computecanada.ca/easybuild/software/2017/Core/scipy-stack/2019a/lib/python3.7/site-packages (from requests<3,>=2.21.0->tensorboard<3,>=2.3.0->tensorflow_gpu==2.3.0+computecanada) (2.8)
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/oauthlib-3.1.1+computecanada-py2.py3-none-any.whl
Installing collected packages: pyasn1, zipp, rsa, pyasn1-modules, oauthlib, cachetools, requests-oauthlib, importlib-metadata, google-auth, werkzeug, tensorboard-plugin-wit, tensorboard-data-server, markdown, grpcio, google-auth-oauthlib, absl-py, wrapt, tensorflow-estimator, tensorboard, scipy, opt-einsum, keras-preprocessing, h5py, google-pasta, gast, astunparse, tensorflow-gpu
  Attempting uninstall: pyasn1
    Found existing installation: pyasn1 0.4.3
    Not uninstalling pyasn1 at /cvmfs/soft.computecanada.ca/easybuild/software/2017/Core/scipy-stack/2019a/lib/python3.7/site-packages, outside environment /localscratch/yinan.29019368.0/env
    Can't uninstall 'pyasn1'. No files were found to uninstall.
  Attempting uninstall: zipp
    Found existing installation: zipp 0.3.3
    Not uninstalling zipp at /cvmfs/soft.computecanada.ca/easybuild/software/2017/Core/scipy-stack/2019a/lib/python3.7/site-packages, outside environment /localscratch/yinan.29019368.0/env
    Can't uninstall 'zipp'. No files were found to uninstall.
  Attempting uninstall: importlib-metadata
    Found existing installation: importlib-metadata 0.8
    Not uninstalling importlib-metadata at /cvmfs/soft.computecanada.ca/easybuild/software/2017/Core/scipy-stack/2019a/lib/python3.7/site-packages, outside environment /localscratch/yinan.29019368.0/env
    Can't uninstall 'importlib-metadata'. No files were found to uninstall.
  Attempting uninstall: scipy
    Found existing installation: scipy 1.2.0
    Not uninstalling scipy at /cvmfs/soft.computecanada.ca/easybuild/software/2017/Core/scipy-stack/2019a/lib/python3.7/site-packages, outside environment /localscratch/yinan.29019368.0/env
    Can't uninstall 'scipy'. No files were found to uninstall.
Successfully installed absl-py-1.0.0+computecanada astunparse-1.6.3+computecanada cachetools-4.2.4+computecanada gast-0.3.3+computecanada google-auth-2.3.3+computecanada google-auth-oauthlib-0.4.6+computecanada google-pasta-0.2.0+computecanada grpcio-1.38.0+computecanada h5py-2.10.0+computecanada importlib-metadata-4.10.1+computecanada keras-preprocessing-1.1.2+computecanada markdown-3.3.6+computecanada oauthlib-3.1.1+computecanada opt-einsum-3.3.0+computecanada pyasn1-0.4.8+computecanada pyasn1-modules-0.2.8+computecanada requests-oauthlib-1.3.0+computecanada rsa-4.8+computecanada scipy-1.4.1+computecanada tensorboard-2.8.0+computecanada tensorboard-data-server-0.6.1+computecanada tensorboard-plugin-wit-1.8.0+computecanada tensorflow-estimator-2.3.0+computecanada tensorflow-gpu-2.3.0+computecanada werkzeug-2.0.3+computecanada wrapt-1.11.2+computecanada zipp-3.7.0+computecanada
Looking in links: /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/nix/avx2, /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/nix/generic, /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/keras-2.8.0+computecanada-py2.py3-none-any.whl
Installing collected packages: Keras
Successfully installed Keras-2.8.0+computecanada
Looking in links: /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/nix/avx2, /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/nix/generic, /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/urllib3-1.26.7+computecanada-py2.py3-none-any.whl
Installing collected packages: urllib3
  Attempting uninstall: urllib3
    Found existing installation: urllib3 1.26.8+computecanada
    Uninstalling urllib3-1.26.8+computecanada:
      Successfully uninstalled urllib3-1.26.8+computecanada
Successfully installed urllib3-1.26.7+computecanada
Looking in links: /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/nix/avx2, /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/nix/generic, /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/nltk-3.7+computecanada-py3-none-any.whl
Requirement already satisfied: click in /localscratch/yinan.29019368.0/env/lib/python3.7/site-packages (from nltk) (8.0.4+computecanada)
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/nltk-3.6.5+computecanada-py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/nltk-3.6.3+computecanada-py3-none-any.whl
Requirement already satisfied: tqdm in /localscratch/yinan.29019368.0/env/lib/python3.7/site-packages (from nltk) (4.63.0+computecanada)
Requirement already satisfied: joblib in /localscratch/yinan.29019368.0/env/lib/python3.7/site-packages (from nltk) (1.1.0+computecanada)
Requirement already satisfied: regex in /localscratch/yinan.29019368.0/env/lib/python3.7/site-packages (from nltk) (2020.11.13+computecanada)
Requirement already satisfied: importlib-metadata in /localscratch/yinan.29019368.0/env/lib/python3.7/site-packages (from click->nltk) (4.10.1+computecanada)
Requirement already satisfied: zipp>=0.5 in /localscratch/yinan.29019368.0/env/lib/python3.7/site-packages (from importlib-metadata->click->nltk) (3.7.0+computecanada)
Requirement already satisfied: typing-extensions>=3.6.4 in /localscratch/yinan.29019368.0/env/lib/python3.7/site-packages (from importlib-metadata->click->nltk) (4.0.1+computecanada)
Installing collected packages: nltk
Successfully installed nltk-3.6.3+computecanada
Looking in links: /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/nix/avx2, /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/nix/generic, /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/scikit_learn-0.22.1+computecanada-cp37-cp37m-linux_x86_64.whl
Requirement already satisfied: scipy>=0.17.0 in /localscratch/yinan.29019368.0/env/lib/python3.7/site-packages (from scikit-learn==0.22.1) (1.4.1+computecanada)
Requirement already satisfied: joblib>=0.11 in /localscratch/yinan.29019368.0/env/lib/python3.7/site-packages (from scikit-learn==0.22.1) (1.1.0+computecanada)
Requirement already satisfied: numpy>=1.11.0 in /cvmfs/soft.computecanada.ca/easybuild/software/2017/Core/scipy-stack/2019a/lib/python3.7/site-packages (from scikit-learn==0.22.1) (1.16.0)
Installing collected packages: scikit-learn
Successfully installed scikit-learn-0.22.1+computecanada
Looking in links: /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/nix/avx2, /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/nix/generic, /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic
Requirement already satisfied: tokenizers==0.5.2 in /localscratch/yinan.29019368.0/env/lib/python3.7/site-packages (0.5.2+computecanada)
wandb: Appending key for api.wandb.ai to your netrc file: /home/yinan/.netrc
Starting Task
2022-03-18 20:19:36.012834: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1
[nltk_data] Downloading package stopwords to /home/yinan/nltk_data...
[nltk_data]   Package stopwords is already up-to-date!
[nltk_data] Downloading package wordnet to /home/yinan/nltk_data...
[nltk_data]   Package wordnet is already up-to-date!
wandb: Currently logged in as: yinanazhou (use `wandb login --relogin` to force relogin)
wandb: wandb version 0.12.11 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
2022-03-18 20:19:54.586007: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1
wandb: Tracking run with wandb version 0.12.5
wandb: Syncing run balmy-music-2
wandb: ⭐️ View project at https://wandb.ai/yinanazhou/xl_512_bs_8_lr_1e06_es_10_lc_False_nr_False_sr_False_stem_True_lemma_False_repeat_1_fold_1
wandb: 🚀 View run at https://wandb.ai/yinanazhou/xl_512_bs_8_lr_1e06_es_10_lc_False_nr_False_sr_False_stem_True_lemma_False_repeat_1_fold_1/runs/1h3z6n4j
wandb: Run data is saved locally in /project/6002780/yinan/Thesis_MER_Lyrics/lyric-emotion/wandb/run-20220318_201952-1h3z6n4j
wandb: Run `wandb offline` to turn off syncing.

Validation loss decreased (inf --> 1.430502).  Saving model ...
Validation loss decreased (1.430502 --> 1.411706).  Saving model ...
Validation loss decreased (1.411706 --> 1.396635).  Saving model ...
Validation loss decreased (1.396635 --> 1.384219).  Saving model ...
Validation loss decreased (1.384219 --> 1.374457).  Saving model ...
Validation loss decreased (1.374457 --> 1.365996).  Saving model ...
Validation loss decreased (1.365996 --> 1.359206).  Saving model ...
Validation loss decreased (1.359206 --> 1.353191).  Saving model ...
Validation loss decreased (1.353191 --> 1.348336).  Saving model ...
Validation loss decreased (1.348336 --> 1.342848).  Saving model ...
Validation loss decreased (1.342848 --> 1.337130).  Saving model ...
Validation loss decreased (1.337130 --> 1.331982).  Saving model ...
Validation loss decreased (1.331982 --> 1.326342).  Saving model ...
Validation loss decreased (1.326342 --> 1.321056).  Saving model ...
Validation loss decreased (1.321056 --> 1.316004).  Saving model ...
Validation loss decreased (1.316004 --> 1.310585).  Saving model ...
Validation loss decreased (1.310585 --> 1.305343).  Saving model ...
Validation loss decreased (1.305343 --> 1.300160).  Saving model ...
Validation loss decreased (1.300160 --> 1.294765).  Saving model ...
Validation loss decreased (1.294765 --> 1.287543).  Saving model ...
Validation loss decreased (1.287543 --> 1.280441).  Saving model ...
Validation loss decreased (1.280441 --> 1.274405).  Saving model ...
Validation loss decreased (1.274405 --> 1.268341).  Saving model ...
Validation loss decreased (1.268341 --> 1.260786).  Saving model ...
Validation loss decreased (1.260786 --> 1.253102).  Saving model ...
Validation loss decreased (1.253102 --> 1.245907).  Saving model ...
Validation loss decreased (1.245907 --> 1.239367).  Saving model ...
Validation loss decreased (1.239367 --> 1.234503).  Saving model ...
Validation loss decreased (1.234503 --> 1.228293).  Saving model ...
Validation loss decreased (1.228293 --> 1.222584).  Saving model ...
Validation loss decreased (1.222584 --> 1.216064).  Saving model ...
Validation loss decreased (1.216064 --> 1.210650).  Saving model ...
Validation loss decreased (1.210650 --> 1.207100).  Saving model ...
Validation loss decreased (1.207100 --> 1.200621).  Saving model ...
Validation loss decreased (1.200621 --> 1.194490).  Saving model ...
Validation loss decreased (1.194490 --> 1.189788).  Saving model ...
Validation loss decreased (1.189788 --> 1.188445).  Saving model ...
Validation loss decreased (1.188445 --> 1.182179).  Saving model ...
Validation loss decreased (1.182179 --> 1.178794).  Saving model ...
Validation loss decreased (1.178794 --> 1.173980).  Saving model ...
Validation loss decreased (1.173980 --> 1.166531).  Saving model ...
Validation loss decreased (1.166531 --> 1.162467).  Saving model ...
Validation loss decreased (1.162467 --> 1.158194).  Saving model ...
Validation loss decreased (1.158194 --> 1.155818).  Saving model ...
Validation loss decreased (1.155818 --> 1.151464).  Saving model ...
Validation loss decreased (1.151464 --> 1.147466).  Saving model ...
Validation loss decreased (1.147466 --> 1.143790).  Saving model ...
Validation loss decreased (1.143790 --> 1.141341).  Saving model ...
Validation loss decreased (1.141341 --> 1.135549).  Saving model ...
Validation loss decreased (1.135549 --> 1.134148).  Saving model ...
Validation loss decreased (1.134148 --> 1.129279).  Saving model ...
Validation loss decreased (1.129279 --> 1.125128).  Saving model ...
Validation loss decreased (1.125128 --> 1.123482).  Saving model ...
Validation loss decreased (1.123482 --> 1.120830).  Saving model ...
EarlyStopping counter: 1 out of 10.0
Validation loss decreased (1.120830 --> 1.117757).  Saving model ...
Validation loss decreased (1.117757 --> 1.113687).  Saving model ...
Validation loss decreased (1.113687 --> 1.111035).  Saving model ...
Validation loss decreased (1.111035 --> 1.108442).  Saving model ...
Validation loss decreased (1.108442 --> 1.105160).  Saving model ...
Validation loss decreased (1.105160 --> 1.103039).  Saving model ...
Validation loss decreased (1.103039 --> 1.100567).  Saving model ...
Validation loss decreased (1.100567 --> 1.099276).  Saving model ...
Validation loss decreased (1.099276 --> 1.098061).  Saving model ...
EarlyStopping counter: 1 out of 10.0
Validation loss decreased (1.098061 --> 1.095929).  Saving model ...
Validation loss decreased (1.095929 --> 1.091774).  Saving model ...
EarlyStopping counter: 1 out of 10.0
Validation loss decreased (1.091774 --> 1.089520).  Saving model ...
Validation loss decreased (1.089520 --> 1.084666).  Saving model ...
Validation loss decreased (1.084666 --> 1.083744).  Saving model ...
Validation loss decreased (1.083744 --> 1.081128).  Saving model ...
Validation loss decreased (1.081128 --> 1.080316).  Saving model ...
Validation loss decreased (1.080316 --> 1.076862).  Saving model ...
Validation loss decreased (1.076862 --> 1.074781).  Saving model ...
Validation loss decreased (1.074781 --> 1.074017).  Saving model ...
EarlyStopping counter: 1 out of 10.0
Validation loss decreased (1.074017 --> 1.071483).  Saving model ...
Validation loss decreased (1.071483 --> 1.069455).  Saving model ...
Validation loss decreased (1.069455 --> 1.065857).  Saving model ...
EarlyStopping counter: 1 out of 10.0
EarlyStopping counter: 2 out of 10.0
Validation loss decreased (1.065857 --> 1.065726).  Saving model ...
Validation loss decreased (1.065726 --> 1.061777).  Saving model ...
Validation loss decreased (1.061777 --> 1.060714).  Saving model ...
Validation loss decreased (1.060714 --> 1.060006).  Saving model ...
EarlyStopping counter: 1 out of 10.0
EarlyStopping counter: 2 out of 10.0
Validation loss decreased (1.060006 --> 1.058762).  Saving model ...
EarlyStopping counter: 1 out of 10.0
Validation loss decreased (1.058762 --> 1.057055).  Saving model ...
Validation loss decreased (1.057055 --> 1.054931).  Saving model ...
Validation loss decreased (1.054931 --> 1.054297).  Saving model ...
EarlyStopping counter: 1 out of 10.0
EarlyStopping counter: 2 out of 10.0
Validation loss decreased (1.054297 --> 1.051264).  Saving model ...
EarlyStopping counter: 1 out of 10.0
Validation loss decreased (1.051264 --> 1.051008).  Saving model ...
EarlyStopping counter: 1 out of 10.0
EarlyStopping counter: 2 out of 10.0
Validation loss decreased (1.051008 --> 1.050266).  Saving model ...
EarlyStopping counter: 1 out of 10.0
EarlyStopping counter: 2 out of 10.0
EarlyStopping counter: 3 out of 10.0
EarlyStopping counter: 4 out of 10.0
EarlyStopping counter: 5 out of 10.0
Validation loss decreased (1.050266 --> 1.049473).  Saving model ...
Validation loss decreased (1.049473 --> 1.046309).  Saving model ...
EarlyStopping counter: 1 out of 10.0
Validation loss decreased (1.046309 --> 1.044319).  Saving model ...
EarlyStopping counter: 1 out of 10.0
EarlyStopping counter: 2 out of 10.0
EarlyStopping counter: 3 out of 10.0
EarlyStopping counter: 4 out of 10.0
EarlyStopping counter: 5 out of 10.0
EarlyStopping counter: 6 out of 10.0
EarlyStopping counter: 7 out of 10.0
EarlyStopping counter: 8 out of 10.0
EarlyStopping counter: 9 out of 10.0
EarlyStopping counter: 10 out of 10.0
/localscratch/yinan.29019368.0/env/lib/python3.7/site-packages/torch/nn/functional.py:1794: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.
  warnings.warn("nn.functional.tanh is deprecated. Use torch.tanh instead.")
/localscratch/yinan.29019368.0/env/lib/python3.7/site-packages/transformers/optimization.py:155: UserWarning: This overload of add_ is deprecated:
	add_(Number alpha, Tensor other)
Consider using one of the following signatures instead:
	add_(Tensor other, *, Number alpha) (Triggered internally at  ../torch/csrc/utils/python_arg_parser.cpp:1025.)
  exp_avg.mul_(beta1).add_(1.0 - beta1, grad)
wandb: Waiting for W&B process to finish, PID 76271... (success).
wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: \ 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: | 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: / 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: \ 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: | 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: / 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: \ 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: | 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: / 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: \ 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb:                                                                                
wandb: Run history:
wandb:     e_F1 ▁▂▃▄▅▅▅▆▆▆▆▆▇▇▇▇▇▇▇█▇███████████████████
wandb:   e_loss █▇▇▆▆▆▆▅▅▄▄▄▄▃▃▃▃▂▂▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:     t_F1 ▁▁▃▂▃▃▃▄▄▄▅▅▅▆▅▆▆▆▇▇▆▇▇▇▇▇▇▇██▇█▇███████
wandb:   t_loss ██▇▇▇▇▇▆▆▆▅▅▅▅▄▄▄▄▃▃▃▃▃▃▃▂▃▂▂▂▂▂▂▂▁▂▁▁▁▁
wandb: 
wandb: Run summary:
wandb:     e_F1 55.46878
wandb:   e_loss 1.04834
wandb:     t_F1 70.60848
wandb:   t_loss 0.7736
wandb: 
wandb: Synced 4 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Synced balmy-music-2: https://wandb.ai/yinanazhou/xl_512_bs_8_lr_1e06_es_10_lc_False_nr_False_sr_False_stem_True_lemma_False_repeat_1_fold_1/runs/1h3z6n4j
wandb: Find logs at: ./wandb/run-20220318_201952-1h3z6n4j/logs/debug.log
wandb: 

wandb: wandb version 0.12.11 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
2022-03-18 21:37:25.328840: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1
wandb: Tracking run with wandb version 0.12.5
wandb: Syncing run devout-durian-2
wandb: ⭐️ View project at https://wandb.ai/yinanazhou/xl_512_bs_8_lr_1e06_es_10_lc_False_nr_False_sr_False_stem_True_lemma_False_repeat_1_fold_2
wandb: 🚀 View run at https://wandb.ai/yinanazhou/xl_512_bs_8_lr_1e06_es_10_lc_False_nr_False_sr_False_stem_True_lemma_False_repeat_1_fold_2/runs/1k13a6eq
wandb: Run data is saved locally in /project/6002780/yinan/Thesis_MER_Lyrics/lyric-emotion/wandb/run-20220318_213722-1k13a6eq
wandb: Run `wandb offline` to turn off syncing.

Validation loss decreased (inf --> 1.507683).  Saving model ...
Validation loss decreased (1.507683 --> 1.476795).  Saving model ...
Validation loss decreased (1.476795 --> 1.451368).  Saving model ...
Validation loss decreased (1.451368 --> 1.429280).  Saving model ...
Validation loss decreased (1.429280 --> 1.411248).  Saving model ...
Validation loss decreased (1.411248 --> 1.397046).  Saving model ...
Validation loss decreased (1.397046 --> 1.384824).  Saving model ...
Validation loss decreased (1.384824 --> 1.375214).  Saving model ...
Validation loss decreased (1.375214 --> 1.367056).  Saving model ...
Validation loss decreased (1.367056 --> 1.360705).  Saving model ...
Validation loss decreased (1.360705 --> 1.354485).  Saving model ...
Validation loss decreased (1.354485 --> 1.349235).  Saving model ...
Validation loss decreased (1.349235 --> 1.344084).  Saving model ...
Validation loss decreased (1.344084 --> 1.338718).  Saving model ...
Validation loss decreased (1.338718 --> 1.334000).  Saving model ...
Validation loss decreased (1.334000 --> 1.329169).  Saving model ...
Validation loss decreased (1.329169 --> 1.324654).  Saving model ...
Validation loss decreased (1.324654 --> 1.319908).  Saving model ...
Validation loss decreased (1.319908 --> 1.315257).  Saving model ...
Validation loss decreased (1.315257 --> 1.309876).  Saving model ...
Validation loss decreased (1.309876 --> 1.304306).  Saving model ...
Validation loss decreased (1.304306 --> 1.298501).  Saving model ...
Validation loss decreased (1.298501 --> 1.292893).  Saving model ...
Validation loss decreased (1.292893 --> 1.287249).  Saving model ...
Validation loss decreased (1.287249 --> 1.281457).  Saving model ...
Validation loss decreased (1.281457 --> 1.274537).  Saving model ...
Validation loss decreased (1.274537 --> 1.267319).  Saving model ...
Validation loss decreased (1.267319 --> 1.260590).  Saving model ...
Validation loss decreased (1.260590 --> 1.252160).  Saving model ...
Validation loss decreased (1.252160 --> 1.243550).  Saving model ...
Validation loss decreased (1.243550 --> 1.235525).  Saving model ...
Validation loss decreased (1.235525 --> 1.226998).  Saving model ...
Validation loss decreased (1.226998 --> 1.220983).  Saving model ...
Validation loss decreased (1.220983 --> 1.212498).  Saving model ...
Validation loss decreased (1.212498 --> 1.203541).  Saving model ...
Validation loss decreased (1.203541 --> 1.193425).  Saving model ...
Validation loss decreased (1.193425 --> 1.185429).  Saving model ...
Validation loss decreased (1.185429 --> 1.178226).  Saving model ...
Validation loss decreased (1.178226 --> 1.171261).  Saving model ...
Validation loss decreased (1.171261 --> 1.164845).  Saving model ...
Validation loss decreased (1.164845 --> 1.158219).  Saving model ...
Validation loss decreased (1.158219 --> 1.150747).  Saving model ...
Validation loss decreased (1.150747 --> 1.144073).  Saving model ...
Validation loss decreased (1.144073 --> 1.136762).  Saving model ...
Validation loss decreased (1.136762 --> 1.130145).  Saving model ...
Validation loss decreased (1.130145 --> 1.123299).  Saving model ...
Validation loss decreased (1.123299 --> 1.116794).  Saving model ...
Validation loss decreased (1.116794 --> 1.110478).  Saving model ...
Validation loss decreased (1.110478 --> 1.104778).  Saving model ...
Validation loss decreased (1.104778 --> 1.098118).  Saving model ...
Validation loss decreased (1.098118 --> 1.093164).  Saving model ...
Validation loss decreased (1.093164 --> 1.089149).  Saving model ...
Validation loss decreased (1.089149 --> 1.082076).  Saving model ...
Validation loss decreased (1.082076 --> 1.076918).  Saving model ...
Validation loss decreased (1.076918 --> 1.071988).  Saving model ...
Validation loss decreased (1.071988 --> 1.066808).  Saving model ...
Validation loss decreased (1.066808 --> 1.062494).  Saving model ...
Validation loss decreased (1.062494 --> 1.058335).  Saving model ...
Validation loss decreased (1.058335 --> 1.052526).  Saving model ...
Validation loss decreased (1.052526 --> 1.049203).  Saving model ...
Validation loss decreased (1.049203 --> 1.044413).  Saving model ...
Validation loss decreased (1.044413 --> 1.043951).  Saving model ...
Validation loss decreased (1.043951 --> 1.037878).  Saving model ...
Validation loss decreased (1.037878 --> 1.033759).  Saving model ...
Validation loss decreased (1.033759 --> 1.029991).  Saving model ...
Validation loss decreased (1.029991 --> 1.025357).  Saving model ...
Validation loss decreased (1.025357 --> 1.022098).  Saving model ...
Validation loss decreased (1.022098 --> 1.018735).  Saving model ...
Validation loss decreased (1.018735 --> 1.014266).  Saving model ...
Validation loss decreased (1.014266 --> 1.009197).  Saving model ...
Validation loss decreased (1.009197 --> 1.006556).  Saving model ...
Validation loss decreased (1.006556 --> 1.005526).  Saving model ...
Validation loss decreased (1.005526 --> 1.002875).  Saving model ...
Validation loss decreased (1.002875 --> 0.996810).  Saving model ...
Validation loss decreased (0.996810 --> 0.996632).  Saving model ...
Validation loss decreased (0.996632 --> 0.994439).  Saving model ...
Validation loss decreased (0.994439 --> 0.991517).  Saving model ...
Validation loss decreased (0.991517 --> 0.988653).  Saving model ...
Validation loss decreased (0.988653 --> 0.986998).  Saving model ...
Validation loss decreased (0.986998 --> 0.985269).  Saving model ...
Validation loss decreased (0.985269 --> 0.982336).  Saving model ...
Validation loss decreased (0.982336 --> 0.980751).  Saving model ...
EarlyStopping counter: 1 out of 10.0
Validation loss decreased (0.980751 --> 0.979640).  Saving model ...
Validation loss decreased (0.979640 --> 0.976129).  Saving model ...
Validation loss decreased (0.976129 --> 0.973030).  Saving model ...
Validation loss decreased (0.973030 --> 0.971012).  Saving model ...
Validation loss decreased (0.971012 --> 0.967614).  Saving model ...
Validation loss decreased (0.967614 --> 0.963012).  Saving model ...
Validation loss decreased (0.963012 --> 0.958621).  Saving model ...
EarlyStopping counter: 1 out of 10.0
EarlyStopping counter: 2 out of 10.0
Validation loss decreased (0.958621 --> 0.957338).  Saving model ...
EarlyStopping counter: 1 out of 10.0
Validation loss decreased (0.957338 --> 0.954576).  Saving model ...
Validation loss decreased (0.954576 --> 0.952398).  Saving model ...
Validation loss decreased (0.952398 --> 0.951420).  Saving model ...
Validation loss decreased (0.951420 --> 0.947582).  Saving model ...
Validation loss decreased (0.947582 --> 0.946109).  Saving model ...
EarlyStopping counter: 1 out of 10.0
EarlyStopping counter: 2 out of 10.0
EarlyStopping counter: 3 out of 10.0
Validation loss decreased (0.946109 --> 0.944240).  Saving model ...
EarlyStopping counter: 1 out of 10.0
Validation loss decreased (0.944240 --> 0.941790).  Saving model ...
EarlyStopping counter: 1 out of 10.0
Validation loss decreased (0.941790 --> 0.940879).  Saving model ...
Validation loss decreased (0.940879 --> 0.938673).  Saving model ...
Validation loss decreased (0.938673 --> 0.937917).  Saving model ...
EarlyStopping counter: 1 out of 10.0
EarlyStopping counter: 2 out of 10.0
EarlyStopping counter: 3 out of 10.0
Validation loss decreased (0.937917 --> 0.935205).  Saving model ...
EarlyStopping counter: 1 out of 10.0
EarlyStopping counter: 2 out of 10.0
Validation loss decreased (0.935205 --> 0.933791).  Saving model ...
Validation loss decreased (0.933791 --> 0.933599).  Saving model ...
Validation loss decreased (0.933599 --> 0.932969).  Saving model ...
Validation loss decreased (0.932969 --> 0.932523).  Saving model ...
EarlyStopping counter: 1 out of 10.0
EarlyStopping counter: 2 out of 10.0
Validation loss decreased (0.932523 --> 0.931986).  Saving model ...
Validation loss decreased (0.931986 --> 0.930900).  Saving model ...
Validation loss decreased (0.930900 --> 0.930409).  Saving model ...
EarlyStopping counter: 1 out of 10.0
EarlyStopping counter: 2 out of 10.0
EarlyStopping counter: 3 out of 10.0
Validation loss decreased (0.930409 --> 0.929831).  Saving model ...
EarlyStopping counter: 1 out of 10.0
Validation loss decreased (0.929831 --> 0.929439).  Saving model ...
Validation loss decreased (0.929439 --> 0.928760).  Saving model ...
EarlyStopping counter: 1 out of 10.0
EarlyStopping counter: 2 out of 10.0
EarlyStopping counter: 3 out of 10.0
EarlyStopping counter: 4 out of 10.0
EarlyStopping counter: 5 out of 10.0
EarlyStopping counter: 6 out of 10.0
EarlyStopping counter: 7 out of 10.0
EarlyStopping counter: 8 out of 10.0
Validation loss decreased (0.928760 --> 0.928691).  Saving model ...
Validation loss decreased (0.928691 --> 0.927037).  Saving model ...
EarlyStopping counter: 1 out of 10.0
EarlyStopping counter: 2 out of 10.0
EarlyStopping counter: 3 out of 10.0
EarlyStopping counter: 4 out of 10.0
EarlyStopping counter: 5 out of 10.0
EarlyStopping counter: 6 out of 10.0
EarlyStopping counter: 7 out of 10.0
EarlyStopping counter: 8 out of 10.0
EarlyStopping counter: 9 out of 10.0
EarlyStopping counter: 10 out of 10.0
/localscratch/yinan.29019368.0/env/lib/python3.7/site-packages/torch/nn/functional.py:1794: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.
  warnings.warn("nn.functional.tanh is deprecated. Use torch.tanh instead.")
wandb: Waiting for W&B process to finish, PID 80458... (success).
wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: \ 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: | 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: / 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: \ 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: | 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: / 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: \ 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: | 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: / 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb:                                                                                
wandb: Run history:
wandb:     e_F1 ▁▁▂▃▄▅▅▅▆▆▆▇▇▇▇▇▇▇██████████████████████
wandb:   e_loss █▇▇▆▆▆▆▅▅▄▄▄▃▃▃▃▂▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:     t_F1 ▁▁▁▂▂▃▃▄▄▅▄▅▅▅▅▆▆▆▆▆▆▆▆▇▆▇▇▇▇▇▇▇▇▇▇▇▇███
wandb:   t_loss ██▇▇▇▇▆▆▆▅▅▅▅▅▅▄▄▄▄▄▄▃▃▃▃▃▃▂▂▂▂▂▂▂▂▂▁▁▁▁
wandb: 
wandb: Run summary:
wandb:     e_F1 59.65522
wandb:   e_loss 0.93396
wandb:     t_F1 74.30137
wandb:   t_loss 0.72059
wandb: 
wandb: Synced 4 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Synced devout-durian-2: https://wandb.ai/yinanazhou/xl_512_bs_8_lr_1e06_es_10_lc_False_nr_False_sr_False_stem_True_lemma_False_repeat_1_fold_2/runs/1k13a6eq
wandb: Find logs at: ./wandb/run-20220318_213722-1k13a6eq/logs/debug.log
wandb: 

wandb: wandb version 0.12.11 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
2022-03-18 23:16:59.194854: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1
wandb: Tracking run with wandb version 0.12.5
wandb: Syncing run dry-wave-2
wandb: ⭐️ View project at https://wandb.ai/yinanazhou/xl_512_bs_8_lr_1e06_es_10_lc_False_nr_False_sr_False_stem_True_lemma_False_repeat_2_fold_1
wandb: 🚀 View run at https://wandb.ai/yinanazhou/xl_512_bs_8_lr_1e06_es_10_lc_False_nr_False_sr_False_stem_True_lemma_False_repeat_2_fold_1/runs/2hz0nqwj
wandb: Run data is saved locally in /project/6002780/yinan/Thesis_MER_Lyrics/lyric-emotion/wandb/run-20220318_231656-2hz0nqwj
wandb: Run `wandb offline` to turn off syncing.

Validation loss decreased (inf --> 1.435318).  Saving model ...
Validation loss decreased (1.435318 --> 1.420400).  Saving model ...
Validation loss decreased (1.420400 --> 1.406734).  Saving model ...
Validation loss decreased (1.406734 --> 1.396117).  Saving model ...
Validation loss decreased (1.396117 --> 1.387789).  Saving model ...
Validation loss decreased (1.387789 --> 1.380135).  Saving model ...
Validation loss decreased (1.380135 --> 1.372981).  Saving model ...
Validation loss decreased (1.372981 --> 1.366950).  Saving model ...
Validation loss decreased (1.366950 --> 1.361185).  Saving model ...
Validation loss decreased (1.361185 --> 1.355871).  Saving model ...
Validation loss decreased (1.355871 --> 1.350088).  Saving model ...
Validation loss decreased (1.350088 --> 1.344305).  Saving model ...
Validation loss decreased (1.344305 --> 1.338120).  Saving model ...
Validation loss decreased (1.338120 --> 1.332769).  Saving model ...
Validation loss decreased (1.332769 --> 1.326840).  Saving model ...
Validation loss decreased (1.326840 --> 1.319901).  Saving model ...
Validation loss decreased (1.319901 --> 1.312928).  Saving model ...
Validation loss decreased (1.312928 --> 1.305719).  Saving model ...
Validation loss decreased (1.305719 --> 1.298996).  Saving model ...
Validation loss decreased (1.298996 --> 1.291549).  Saving model ...
Validation loss decreased (1.291549 --> 1.284982).  Saving model ...
Validation loss decreased (1.284982 --> 1.276936).  Saving model ...
Validation loss decreased (1.276936 --> 1.268819).  Saving model ...
Validation loss decreased (1.268819 --> 1.261563).  Saving model ...
Validation loss decreased (1.261563 --> 1.254484).  Saving model ...
Validation loss decreased (1.254484 --> 1.247527).  Saving model ...
Validation loss decreased (1.247527 --> 1.241710).  Saving model ...
Validation loss decreased (1.241710 --> 1.235185).  Saving model ...
Validation loss decreased (1.235185 --> 1.227946).  Saving model ...
Validation loss decreased (1.227946 --> 1.221140).  Saving model ...
Validation loss decreased (1.221140 --> 1.215530).  Saving model ...
Validation loss decreased (1.215530 --> 1.208748).  Saving model ...
Validation loss decreased (1.208748 --> 1.203068).  Saving model ...
Validation loss decreased (1.203068 --> 1.196991).  Saving model ...
Validation loss decreased (1.196991 --> 1.190573).  Saving model ...
Validation loss decreased (1.190573 --> 1.185116).  Saving model ...
Validation loss decreased (1.185116 --> 1.179098).  Saving model ...
Validation loss decreased (1.179098 --> 1.172644).  Saving model ...
Validation loss decreased (1.172644 --> 1.166230).  Saving model ...
Validation loss decreased (1.166230 --> 1.160492).  Saving model ...
Validation loss decreased (1.160492 --> 1.154776).  Saving model ...
Validation loss decreased (1.154776 --> 1.149265).  Saving model ...
Validation loss decreased (1.149265 --> 1.143122).  Saving model ...
Validation loss decreased (1.143122 --> 1.138160).  Saving model ...
Validation loss decreased (1.138160 --> 1.132916).  Saving model ...
Validation loss decreased (1.132916 --> 1.127956).  Saving model ...
Validation loss decreased (1.127956 --> 1.123816).  Saving model ...
Validation loss decreased (1.123816 --> 1.119807).  Saving model ...
Validation loss decreased (1.119807 --> 1.113819).  Saving model ...
Validation loss decreased (1.113819 --> 1.108252).  Saving model ...
Validation loss decreased (1.108252 --> 1.103623).  Saving model ...
Validation loss decreased (1.103623 --> 1.099771).  Saving model ...
Validation loss decreased (1.099771 --> 1.096447).  Saving model ...
Validation loss decreased (1.096447 --> 1.091676).  Saving model ...
Validation loss decreased (1.091676 --> 1.086884).  Saving model ...
Validation loss decreased (1.086884 --> 1.082570).  Saving model ...
Validation loss decreased (1.082570 --> 1.078787).  Saving model ...
Validation loss decreased (1.078787 --> 1.074135).  Saving model ...
Validation loss decreased (1.074135 --> 1.070402).  Saving model ...
Validation loss decreased (1.070402 --> 1.066906).  Saving model ...
Validation loss decreased (1.066906 --> 1.063541).  Saving model ...
Validation loss decreased (1.063541 --> 1.060524).  Saving model ...
Validation loss decreased (1.060524 --> 1.057434).  Saving model ...
Validation loss decreased (1.057434 --> 1.054073).  Saving model ...
Validation loss decreased (1.054073 --> 1.051500).  Saving model ...
Validation loss decreased (1.051500 --> 1.048262).  Saving model ...
Validation loss decreased (1.048262 --> 1.045436).  Saving model ...
Validation loss decreased (1.045436 --> 1.043579).  Saving model ...
Validation loss decreased (1.043579 --> 1.041260).  Saving model ...
Validation loss decreased (1.041260 --> 1.038002).  Saving model ...
Validation loss decreased (1.038002 --> 1.034701).  Saving model ...
Validation loss decreased (1.034701 --> 1.032511).  Saving model ...
Validation loss decreased (1.032511 --> 1.030165).  Saving model ...
Validation loss decreased (1.030165 --> 1.027463).  Saving model ...
Validation loss decreased (1.027463 --> 1.024795).  Saving model ...
Validation loss decreased (1.024795 --> 1.022107).  Saving model ...
Validation loss decreased (1.022107 --> 1.020467).  Saving model ...
Validation loss decreased (1.020467 --> 1.017757).  Saving model ...
Validation loss decreased (1.017757 --> 1.015988).  Saving model ...
Validation loss decreased (1.015988 --> 1.013828).  Saving model ...
Validation loss decreased (1.013828 --> 1.011229).  Saving model ...
Validation loss decreased (1.011229 --> 1.009452).  Saving model ...
Validation loss decreased (1.009452 --> 1.008094).  Saving model ...
Validation loss decreased (1.008094 --> 1.006789).  Saving model ...
Validation loss decreased (1.006789 --> 1.004729).  Saving model ...
Validation loss decreased (1.004729 --> 1.004167).  Saving model ...
Validation loss decreased (1.004167 --> 1.002314).  Saving model ...
Validation loss decreased (1.002314 --> 1.001528).  Saving model ...
Validation loss decreased (1.001528 --> 0.999614).  Saving model ...
Validation loss decreased (0.999614 --> 0.997589).  Saving model ...
Validation loss decreased (0.997589 --> 0.996894).  Saving model ...
Validation loss decreased (0.996894 --> 0.996153).  Saving model ...
Validation loss decreased (0.996153 --> 0.995083).  Saving model ...
Validation loss decreased (0.995083 --> 0.994365).  Saving model ...
Validation loss decreased (0.994365 --> 0.992946).  Saving model ...
Validation loss decreased (0.992946 --> 0.992576).  Saving model ...
Validation loss decreased (0.992576 --> 0.992438).  Saving model ...
Validation loss decreased (0.992438 --> 0.990625).  Saving model ...
Validation loss decreased (0.990625 --> 0.988976).  Saving model ...
Validation loss decreased (0.988976 --> 0.988470).  Saving model ...
EarlyStopping counter: 1 out of 10.0
Validation loss decreased (0.988470 --> 0.987881).  Saving model ...
EarlyStopping counter: 1 out of 10.0
EarlyStopping counter: 2 out of 10.0
EarlyStopping counter: 3 out of 10.0
Validation loss decreased (0.987881 --> 0.986524).  Saving model ...
Validation loss decreased (0.986524 --> 0.985767).  Saving model ...
Validation loss decreased (0.985767 --> 0.984804).  Saving model ...
Validation loss decreased (0.984804 --> 0.983604).  Saving model ...
Validation loss decreased (0.983604 --> 0.983506).  Saving model ...
EarlyStopping counter: 1 out of 10.0
EarlyStopping counter: 2 out of 10.0
Validation loss decreased (0.983506 --> 0.983277).  Saving model ...
Validation loss decreased (0.983277 --> 0.982708).  Saving model ...
Validation loss decreased (0.982708 --> 0.981440).  Saving model ...
Validation loss decreased (0.981440 --> 0.981338).  Saving model ...
EarlyStopping counter: 1 out of 10.0
EarlyStopping counter: 2 out of 10.0
EarlyStopping counter: 3 out of 10.0
Validation loss decreased (0.981338 --> 0.980913).  Saving model ...
Validation loss decreased (0.980913 --> 0.980109).  Saving model ...
Validation loss decreased (0.980109 --> 0.980098).  Saving model ...
Validation loss decreased (0.980098 --> 0.979714).  Saving model ...
EarlyStopping counter: 1 out of 10.0
EarlyStopping counter: 2 out of 10.0
EarlyStopping counter: 3 out of 10.0
EarlyStopping counter: 4 out of 10.0
EarlyStopping counter: 5 out of 10.0
EarlyStopping counter: 6 out of 10.0
EarlyStopping counter: 7 out of 10.0
EarlyStopping counter: 8 out of 10.0
EarlyStopping counter: 9 out of 10.0
EarlyStopping counter: 10 out of 10.0
/localscratch/yinan.29019368.0/env/lib/python3.7/site-packages/torch/nn/functional.py:1794: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.
  warnings.warn("nn.functional.tanh is deprecated. Use torch.tanh instead.")
wandb: Waiting for W&B process to finish, PID 85841... (success).
wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: \ 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: | 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: / 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: \ 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: | 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: / 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: \ 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: | 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: / 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb:                                                                                
wandb: Run history:
wandb:     e_F1 ▁▁▄▄▄▅▅▆▆▆▆▇▇▇▇█▇███████████████████████
wandb:   e_loss ██▇▇▇▆▆▅▅▅▄▄▄▄▃▃▃▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:     t_F1 ▁▁▂▂▃▃▄▄▄▅▄▅▆▆▆▆▆▇▇▆▆▆▆▆▇▇▇▇▇▇▇█▇▇▇█████
wandb:   t_loss ██▇▇▇▇▆▆▆▆▆▅▅▅▅▄▄▄▄▄▃▃▃▃▃▃▃▂▂▂▂▂▂▂▂▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:     e_F1 57.30616
wandb:   e_loss 0.97995
wandb:     t_F1 74.55809
wandb:   t_loss 0.73677
wandb: 
wandb: Synced 4 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Synced dry-wave-2: https://wandb.ai/yinanazhou/xl_512_bs_8_lr_1e06_es_10_lc_False_nr_False_sr_False_stem_True_lemma_False_repeat_2_fold_1/runs/2hz0nqwj
wandb: Find logs at: ./wandb/run-20220318_231656-2hz0nqwj/logs/debug.log
wandb: 

wandb: wandb version 0.12.11 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
2022-03-19 00:44:59.920752: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1
wandb: Tracking run with wandb version 0.12.5
wandb: Syncing run winter-leaf-2
wandb: ⭐️ View project at https://wandb.ai/yinanazhou/xl_512_bs_8_lr_1e06_es_10_lc_False_nr_False_sr_False_stem_True_lemma_False_repeat_2_fold_2
wandb: 🚀 View run at https://wandb.ai/yinanazhou/xl_512_bs_8_lr_1e06_es_10_lc_False_nr_False_sr_False_stem_True_lemma_False_repeat_2_fold_2/runs/2dj33pdj
wandb: Run data is saved locally in /project/6002780/yinan/Thesis_MER_Lyrics/lyric-emotion/wandb/run-20220319_004456-2dj33pdj
wandb: Run `wandb offline` to turn off syncing.

Validation loss decreased (inf --> 1.394884).  Saving model ...
Validation loss decreased (1.394884 --> 1.387948).  Saving model ...
Validation loss decreased (1.387948 --> 1.382096).  Saving model ...
Validation loss decreased (1.382096 --> 1.377298).  Saving model ...
Validation loss decreased (1.377298 --> 1.372878).  Saving model ...
Validation loss decreased (1.372878 --> 1.368600).  Saving model ...
Validation loss decreased (1.368600 --> 1.364582).  Saving model ...
Validation loss decreased (1.364582 --> 1.360638).  Saving model ...
Validation loss decreased (1.360638 --> 1.356733).  Saving model ...
Validation loss decreased (1.356733 --> 1.352660).  Saving model ...
Validation loss decreased (1.352660 --> 1.348325).  Saving model ...
Validation loss decreased (1.348325 --> 1.344074).  Saving model ...
Validation loss decreased (1.344074 --> 1.339516).  Saving model ...
Validation loss decreased (1.339516 --> 1.335359).  Saving model ...
Validation loss decreased (1.335359 --> 1.330346).  Saving model ...
Validation loss decreased (1.330346 --> 1.324873).  Saving model ...
Validation loss decreased (1.324873 --> 1.319849).  Saving model ...
Validation loss decreased (1.319849 --> 1.314638).  Saving model ...
Validation loss decreased (1.314638 --> 1.309085).  Saving model ...
Validation loss decreased (1.309085 --> 1.303842).  Saving model ...
Validation loss decreased (1.303842 --> 1.297888).  Saving model ...
Validation loss decreased (1.297888 --> 1.291096).  Saving model ...
Validation loss decreased (1.291096 --> 1.284438).  Saving model ...
Validation loss decreased (1.284438 --> 1.277583).  Saving model ...
Validation loss decreased (1.277583 --> 1.270029).  Saving model ...
Validation loss decreased (1.270029 --> 1.262637).  Saving model ...
Validation loss decreased (1.262637 --> 1.255664).  Saving model ...
Validation loss decreased (1.255664 --> 1.247556).  Saving model ...
Validation loss decreased (1.247556 --> 1.239816).  Saving model ...
Validation loss decreased (1.239816 --> 1.232411).  Saving model ...
Validation loss decreased (1.232411 --> 1.225419).  Saving model ...
Validation loss decreased (1.225419 --> 1.219271).  Saving model ...
Validation loss decreased (1.219271 --> 1.211495).  Saving model ...
Validation loss decreased (1.211495 --> 1.203882).  Saving model ...
Validation loss decreased (1.203882 --> 1.196021).  Saving model ...
Validation loss decreased (1.196021 --> 1.188736).  Saving model ...
Validation loss decreased (1.188736 --> 1.182107).  Saving model ...
Validation loss decreased (1.182107 --> 1.175341).  Saving model ...
Validation loss decreased (1.175341 --> 1.169179).  Saving model ...
Validation loss decreased (1.169179 --> 1.164084).  Saving model ...
Validation loss decreased (1.164084 --> 1.157359).  Saving model ...
Validation loss decreased (1.157359 --> 1.150746).  Saving model ...
Validation loss decreased (1.150746 --> 1.144409).  Saving model ...
Validation loss decreased (1.144409 --> 1.138914).  Saving model ...
Validation loss decreased (1.138914 --> 1.132953).  Saving model ...
Validation loss decreased (1.132953 --> 1.127694).  Saving model ...
Validation loss decreased (1.127694 --> 1.121244).  Saving model ...
Validation loss decreased (1.121244 --> 1.115050).  Saving model ...
Validation loss decreased (1.115050 --> 1.109323).  Saving model ...
Validation loss decreased (1.109323 --> 1.103387).  Saving model ...
Validation loss decreased (1.103387 --> 1.097849).  Saving model ...
Validation loss decreased (1.097849 --> 1.093842).  Saving model ...
Validation loss decreased (1.093842 --> 1.089508).  Saving model ...
Validation loss decreased (1.089508 --> 1.085597).  Saving model ...
Validation loss decreased (1.085597 --> 1.080010).  Saving model ...
Validation loss decreased (1.080010 --> 1.073644).  Saving model ...
Validation loss decreased (1.073644 --> 1.069929).  Saving model ...
Validation loss decreased (1.069929 --> 1.066153).  Saving model ...
Validation loss decreased (1.066153 --> 1.062431).  Saving model ...
Validation loss decreased (1.062431 --> 1.059028).  Saving model ...
Validation loss decreased (1.059028 --> 1.054666).  Saving model ...
Validation loss decreased (1.054666 --> 1.050743).  Saving model ...
Validation loss decreased (1.050743 --> 1.045825).  Saving model ...
Validation loss decreased (1.045825 --> 1.042478).  Saving model ...
Validation loss decreased (1.042478 --> 1.038677).  Saving model ...
Validation loss decreased (1.038677 --> 1.034664).  Saving model ...
Validation loss decreased (1.034664 --> 1.032128).  Saving model ...
Validation loss decreased (1.032128 --> 1.029617).  Saving model ...
Validation loss decreased (1.029617 --> 1.027505).  Saving model ...
Validation loss decreased (1.027505 --> 1.024446).  Saving model ...
Validation loss decreased (1.024446 --> 1.019470).  Saving model ...
Validation loss decreased (1.019470 --> 1.017183).  Saving model ...
Validation loss decreased (1.017183 --> 1.013426).  Saving model ...
Validation loss decreased (1.013426 --> 1.010912).  Saving model ...
Validation loss decreased (1.010912 --> 1.008711).  Saving model ...
Validation loss decreased (1.008711 --> 1.005644).  Saving model ...
Validation loss decreased (1.005644 --> 1.002345).  Saving model ...
Validation loss decreased (1.002345 --> 1.000426).  Saving model ...
Validation loss decreased (1.000426 --> 0.998880).  Saving model ...
Validation loss decreased (0.998880 --> 0.997012).  Saving model ...
Validation loss decreased (0.997012 --> 0.994587).  Saving model ...
Validation loss decreased (0.994587 --> 0.991223).  Saving model ...
Validation loss decreased (0.991223 --> 0.987950).  Saving model ...
Validation loss decreased (0.987950 --> 0.986452).  Saving model ...
Validation loss decreased (0.986452 --> 0.984609).  Saving model ...
Validation loss decreased (0.984609 --> 0.982373).  Saving model ...
Validation loss decreased (0.982373 --> 0.980915).  Saving model ...
Validation loss decreased (0.980915 --> 0.979260).  Saving model ...
Validation loss decreased (0.979260 --> 0.977200).  Saving model ...
Validation loss decreased (0.977200 --> 0.975321).  Saving model ...
Validation loss decreased (0.975321 --> 0.973941).  Saving model ...
Validation loss decreased (0.973941 --> 0.971400).  Saving model ...
Validation loss decreased (0.971400 --> 0.969212).  Saving model ...
Validation loss decreased (0.969212 --> 0.967257).  Saving model ...
Validation loss decreased (0.967257 --> 0.965636).  Saving model ...
Validation loss decreased (0.965636 --> 0.963066).  Saving model ...
Validation loss decreased (0.963066 --> 0.961679).  Saving model ...
Validation loss decreased (0.961679 --> 0.960825).  Saving model ...
Validation loss decreased (0.960825 --> 0.960628).  Saving model ...
Validation loss decreased (0.960628 --> 0.959755).  Saving model ...
Validation loss decreased (0.959755 --> 0.957975).  Saving model ...
Validation loss decreased (0.957975 --> 0.956838).  Saving model ...
Validation loss decreased (0.956838 --> 0.954773).  Saving model ...
Validation loss decreased (0.954773 --> 0.954678).  Saving model ...
Validation loss decreased (0.954678 --> 0.953821).  Saving model ...
Validation loss decreased (0.953821 --> 0.952579).  Saving model ...
Validation loss decreased (0.952579 --> 0.952095).  Saving model ...
Validation loss decreased (0.952095 --> 0.951115).  Saving model ...
Validation loss decreased (0.951115 --> 0.950258).  Saving model ...
Validation loss decreased (0.950258 --> 0.949994).  Saving model ...
Validation loss decreased (0.949994 --> 0.949001).  Saving model ...
Validation loss decreased (0.949001 --> 0.947847).  Saving model ...
Validation loss decreased (0.947847 --> 0.947106).  Saving model ...
Validation loss decreased (0.947106 --> 0.945947).  Saving model ...
EarlyStopping counter: 1 out of 10.0
Validation loss decreased (0.945947 --> 0.945361).  Saving model ...
Validation loss decreased (0.945361 --> 0.945268).  Saving model ...
Validation loss decreased (0.945268 --> 0.943844).  Saving model ...
EarlyStopping counter: 1 out of 10.0
Validation loss decreased (0.943844 --> 0.942907).  Saving model ...
Validation loss decreased (0.942907 --> 0.942530).  Saving model ...
Validation loss decreased (0.942530 --> 0.941417).  Saving model ...
Validation loss decreased (0.941417 --> 0.940395).  Saving model ...
Validation loss decreased (0.940395 --> 0.939204).  Saving model ...
Validation loss decreased (0.939204 --> 0.939007).  Saving model ...
Validation loss decreased (0.939007 --> 0.937893).  Saving model ...
EarlyStopping counter: 1 out of 10.0
EarlyStopping counter: 2 out of 10.0
EarlyStopping counter: 3 out of 10.0
EarlyStopping counter: 4 out of 10.0
Validation loss decreased (0.937893 --> 0.937244).  Saving model ...
EarlyStopping counter: 1 out of 10.0
EarlyStopping counter: 2 out of 10.0
EarlyStopping counter: 3 out of 10.0
EarlyStopping counter: 4 out of 10.0
EarlyStopping counter: 5 out of 10.0
Validation loss decreased (0.937244 --> 0.936603).  Saving model ...
EarlyStopping counter: 1 out of 10.0
Validation loss decreased (0.936603 --> 0.936457).  Saving model ...
Validation loss decreased (0.936457 --> 0.935664).  Saving model ...
EarlyStopping counter: 1 out of 10.0
EarlyStopping counter: 2 out of 10.0
EarlyStopping counter: 3 out of 10.0
EarlyStopping counter: 4 out of 10.0
EarlyStopping counter: 5 out of 10.0
EarlyStopping counter: 6 out of 10.0
EarlyStopping counter: 7 out of 10.0
EarlyStopping counter: 8 out of 10.0
EarlyStopping counter: 9 out of 10.0
EarlyStopping counter: 10 out of 10.0
/localscratch/yinan.29019368.0/env/lib/python3.7/site-packages/torch/nn/functional.py:1794: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.
  warnings.warn("nn.functional.tanh is deprecated. Use torch.tanh instead.")
wandb: Waiting for W&B process to finish, PID 90550... (success).
wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: \ 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: | 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: / 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: \ 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: | 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: / 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: \ 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: | 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: / 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb:                                                                                
wandb: Run history:
wandb:     e_F1 ▁▁▂▃▄▄▅▅▅▅▅▆▆▆▇▇▇▇▇▇▇▇▇▇▇▇██████████████
wandb:   e_loss ███▇▇▇▆▆▅▅▅▄▄▄▃▃▃▃▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:     t_F1 ▁▁▂▂▃▃▃▄▄▅▅▅▅▅▅▆▅▆▆▆▆▇▇▆▆▇▇▇▇▇▇▇▇▇▇█▇███
wandb:   t_loss ████▇▇▇▇▆▆▆▅▅▅▅▄▄▄▄▄▄▃▃▃▃▃▃▂▂▂▂▂▂▂▂▁▁▂▁▁
wandb: 
wandb: Run summary:
wandb:     e_F1 61.9253
wandb:   e_loss 0.93833
wandb:     t_F1 73.04355
wandb:   t_loss 0.70534
wandb: 
wandb: Synced 4 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Synced winter-leaf-2: https://wandb.ai/yinanazhou/xl_512_bs_8_lr_1e06_es_10_lc_False_nr_False_sr_False_stem_True_lemma_False_repeat_2_fold_2/runs/2dj33pdj
wandb: Find logs at: ./wandb/run-20220319_004456-2dj33pdj/logs/debug.log
wandb: 

wandb: wandb version 0.12.11 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
2022-03-19 02:19:01.891832: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1
wandb: Tracking run with wandb version 0.12.5
wandb: Syncing run confused-snow-2
wandb: ⭐️ View project at https://wandb.ai/yinanazhou/xl_512_bs_8_lr_1e06_es_10_lc_False_nr_False_sr_False_stem_True_lemma_False_repeat_3_fold_1
wandb: 🚀 View run at https://wandb.ai/yinanazhou/xl_512_bs_8_lr_1e06_es_10_lc_False_nr_False_sr_False_stem_True_lemma_False_repeat_3_fold_1/runs/17x0s3vl
wandb: Run data is saved locally in /project/6002780/yinan/Thesis_MER_Lyrics/lyric-emotion/wandb/run-20220319_021857-17x0s3vl
wandb: Run `wandb offline` to turn off syncing.

Validation loss decreased (inf --> 1.450892).  Saving model ...
Validation loss decreased (1.450892 --> 1.424001).  Saving model ...
Validation loss decreased (1.424001 --> 1.406777).  Saving model ...
Validation loss decreased (1.406777 --> 1.393743).  Saving model ...
Validation loss decreased (1.393743 --> 1.383884).  Saving model ...
Validation loss decreased (1.383884 --> 1.375565).  Saving model ...
Validation loss decreased (1.375565 --> 1.368334).  Saving model ...
Validation loss decreased (1.368334 --> 1.362774).  Saving model ...
Validation loss decreased (1.362774 --> 1.357844).  Saving model ...
Validation loss decreased (1.357844 --> 1.352717).  Saving model ...
Validation loss decreased (1.352717 --> 1.348044).  Saving model ...
Validation loss decreased (1.348044 --> 1.343749).  Saving model ...
Validation loss decreased (1.343749 --> 1.339208).  Saving model ...
Validation loss decreased (1.339208 --> 1.334376).  Saving model ...
Validation loss decreased (1.334376 --> 1.329380).  Saving model ...
Validation loss decreased (1.329380 --> 1.324522).  Saving model ...
Validation loss decreased (1.324522 --> 1.319568).  Saving model ...
Validation loss decreased (1.319568 --> 1.314586).  Saving model ...
Validation loss decreased (1.314586 --> 1.309470).  Saving model ...
Validation loss decreased (1.309470 --> 1.304635).  Saving model ...
Validation loss decreased (1.304635 --> 1.299111).  Saving model ...
Validation loss decreased (1.299111 --> 1.293609).  Saving model ...
Validation loss decreased (1.293609 --> 1.286965).  Saving model ...
Validation loss decreased (1.286965 --> 1.280623).  Saving model ...
Validation loss decreased (1.280623 --> 1.273341).  Saving model ...
Validation loss decreased (1.273341 --> 1.267371).  Saving model ...
Validation loss decreased (1.267371 --> 1.261702).  Saving model ...
Validation loss decreased (1.261702 --> 1.254314).  Saving model ...
Validation loss decreased (1.254314 --> 1.246255).  Saving model ...
Validation loss decreased (1.246255 --> 1.238762).  Saving model ...
Validation loss decreased (1.238762 --> 1.231475).  Saving model ...
Validation loss decreased (1.231475 --> 1.225587).  Saving model ...
Validation loss decreased (1.225587 --> 1.219971).  Saving model ...
Validation loss decreased (1.219971 --> 1.214119).  Saving model ...
Validation loss decreased (1.214119 --> 1.206960).  Saving model ...
Validation loss decreased (1.206960 --> 1.201865).  Saving model ...
Validation loss decreased (1.201865 --> 1.196184).  Saving model ...
Validation loss decreased (1.196184 --> 1.190461).  Saving model ...
Validation loss decreased (1.190461 --> 1.183552).  Saving model ...
Validation loss decreased (1.183552 --> 1.178810).  Saving model ...
Validation loss decreased (1.178810 --> 1.172230).  Saving model ...
Validation loss decreased (1.172230 --> 1.166090).  Saving model ...
Validation loss decreased (1.166090 --> 1.159957).  Saving model ...
Validation loss decreased (1.159957 --> 1.155944).  Saving model ...
Validation loss decreased (1.155944 --> 1.149909).  Saving model ...
Validation loss decreased (1.149909 --> 1.146309).  Saving model ...
Validation loss decreased (1.146309 --> 1.140202).  Saving model ...
Validation loss decreased (1.140202 --> 1.136199).  Saving model ...
Validation loss decreased (1.136199 --> 1.132840).  Saving model ...
Validation loss decreased (1.132840 --> 1.128478).  Saving model ...
Validation loss decreased (1.128478 --> 1.121421).  Saving model ...
Validation loss decreased (1.121421 --> 1.117526).  Saving model ...
Validation loss decreased (1.117526 --> 1.112208).  Saving model ...
Validation loss decreased (1.112208 --> 1.107231).  Saving model ...
Validation loss decreased (1.107231 --> 1.103651).  Saving model ...
Validation loss decreased (1.103651 --> 1.099315).  Saving model ...
Validation loss decreased (1.099315 --> 1.095656).  Saving model ...
Validation loss decreased (1.095656 --> 1.091223).  Saving model ...
Validation loss decreased (1.091223 --> 1.088599).  Saving model ...
Validation loss decreased (1.088599 --> 1.085089).  Saving model ...
Validation loss decreased (1.085089 --> 1.081931).  Saving model ...
Validation loss decreased (1.081931 --> 1.077011).  Saving model ...
Validation loss decreased (1.077011 --> 1.072183).  Saving model ...
Validation loss decreased (1.072183 --> 1.069870).  Saving model ...
Validation loss decreased (1.069870 --> 1.067269).  Saving model ...
Validation loss decreased (1.067269 --> 1.062831).  Saving model ...
Validation loss decreased (1.062831 --> 1.059588).  Saving model ...
Validation loss decreased (1.059588 --> 1.056584).  Saving model ...
Validation loss decreased (1.056584 --> 1.052486).  Saving model ...
EarlyStopping counter: 1 out of 10.0
Validation loss decreased (1.052486 --> 1.049061).  Saving model ...
Validation loss decreased (1.049061 --> 1.046371).  Saving model ...
Validation loss decreased (1.046371 --> 1.042568).  Saving model ...
Validation loss decreased (1.042568 --> 1.039857).  Saving model ...
Validation loss decreased (1.039857 --> 1.036973).  Saving model ...
Validation loss decreased (1.036973 --> 1.036705).  Saving model ...
Validation loss decreased (1.036705 --> 1.034075).  Saving model ...
Validation loss decreased (1.034075 --> 1.032282).  Saving model ...
Validation loss decreased (1.032282 --> 1.031332).  Saving model ...
Validation loss decreased (1.031332 --> 1.027112).  Saving model ...
Validation loss decreased (1.027112 --> 1.025863).  Saving model ...
Validation loss decreased (1.025863 --> 1.022616).  Saving model ...
Validation loss decreased (1.022616 --> 1.020102).  Saving model ...
Validation loss decreased (1.020102 --> 1.017733).  Saving model ...
Validation loss decreased (1.017733 --> 1.016581).  Saving model ...
Validation loss decreased (1.016581 --> 1.014604).  Saving model ...
Validation loss decreased (1.014604 --> 1.013199).  Saving model ...
Validation loss decreased (1.013199 --> 1.011209).  Saving model ...
EarlyStopping counter: 1 out of 10.0
Validation loss decreased (1.011209 --> 1.010219).  Saving model ...
Validation loss decreased (1.010219 --> 1.008058).  Saving model ...
Validation loss decreased (1.008058 --> 1.005825).  Saving model ...
Validation loss decreased (1.005825 --> 1.004697).  Saving model ...
Validation loss decreased (1.004697 --> 1.002007).  Saving model ...
EarlyStopping counter: 1 out of 10.0
Validation loss decreased (1.002007 --> 1.000434).  Saving model ...
Validation loss decreased (1.000434 --> 0.999290).  Saving model ...
Validation loss decreased (0.999290 --> 0.997025).  Saving model ...
Validation loss decreased (0.997025 --> 0.995297).  Saving model ...
EarlyStopping counter: 1 out of 10.0
EarlyStopping counter: 2 out of 10.0
Validation loss decreased (0.995297 --> 0.994961).  Saving model ...
Validation loss decreased (0.994961 --> 0.993255).  Saving model ...
EarlyStopping counter: 1 out of 10.0
EarlyStopping counter: 2 out of 10.0
Validation loss decreased (0.993255 --> 0.990314).  Saving model ...
Validation loss decreased (0.990314 --> 0.990251).  Saving model ...
Validation loss decreased (0.990251 --> 0.989508).  Saving model ...
Validation loss decreased (0.989508 --> 0.988701).  Saving model ...
Validation loss decreased (0.988701 --> 0.987952).  Saving model ...
EarlyStopping counter: 1 out of 10.0
EarlyStopping counter: 2 out of 10.0
Validation loss decreased (0.987952 --> 0.986903).  Saving model ...
Validation loss decreased (0.986903 --> 0.985211).  Saving model ...
Validation loss decreased (0.985211 --> 0.983882).  Saving model ...
EarlyStopping counter: 1 out of 10.0
EarlyStopping counter: 2 out of 10.0
Validation loss decreased (0.983882 --> 0.982870).  Saving model ...
EarlyStopping counter: 1 out of 10.0
EarlyStopping counter: 2 out of 10.0
Validation loss decreased (0.982870 --> 0.981969).  Saving model ...
EarlyStopping counter: 1 out of 10.0
Validation loss decreased (0.981969 --> 0.981125).  Saving model ...
Validation loss decreased (0.981125 --> 0.981051).  Saving model ...
Validation loss decreased (0.981051 --> 0.979851).  Saving model ...
Validation loss decreased (0.979851 --> 0.979479).  Saving model ...
EarlyStopping counter: 1 out of 10.0
EarlyStopping counter: 2 out of 10.0
Validation loss decreased (0.979479 --> 0.979271).  Saving model ...
EarlyStopping counter: 1 out of 10.0
EarlyStopping counter: 2 out of 10.0
EarlyStopping counter: 3 out of 10.0
EarlyStopping counter: 4 out of 10.0
EarlyStopping counter: 5 out of 10.0
EarlyStopping counter: 6 out of 10.0
EarlyStopping counter: 7 out of 10.0
EarlyStopping counter: 8 out of 10.0
EarlyStopping counter: 9 out of 10.0
EarlyStopping counter: 10 out of 10.0
/localscratch/yinan.29019368.0/env/lib/python3.7/site-packages/torch/nn/functional.py:1794: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.
  warnings.warn("nn.functional.tanh is deprecated. Use torch.tanh instead.")
wandb: Waiting for W&B process to finish, PID 95612... (success).
wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: \ 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: | 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: / 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: \ 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: | 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: / 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: \ 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: | 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: / 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb:                                                                                
wandb: Run history:
wandb:     e_F1 ▁▂▄▅▅▆▆▆▆▆▇▇▇▇▇▇▇▇▇█████████████████████
wandb:   e_loss ██▇▇▇▆▆▆▅▅▅▄▄▄▃▃▃▃▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:     t_F1 ▁▂▃▃▃▄▅▅▄▅▅▆▆▆▅▆▆▆▆▆▇▇▇▇▇▇▇▇█████▇██████
wandb:   t_loss ██▇▇▇▇▆▆▆▆▆▅▅▅▅▄▄▄▄▄▃▃▃▃▃▃▃▂▂▂▂▂▂▂▂▁▂▁▁▁
wandb: 
wandb: Run summary:
wandb:     e_F1 56.23681
wandb:   e_loss 0.98166
wandb:     t_F1 72.02949
wandb:   t_loss 0.72347
wandb: 
wandb: Synced 4 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Synced confused-snow-2: https://wandb.ai/yinanazhou/xl_512_bs_8_lr_1e06_es_10_lc_False_nr_False_sr_False_stem_True_lemma_False_repeat_3_fold_1/runs/17x0s3vl
wandb: Find logs at: ./wandb/run-20220319_021857-17x0s3vl/logs/debug.log
wandb: 

wandb: wandb version 0.12.11 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
2022-03-19 03:48:20.821884: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1
wandb: Tracking run with wandb version 0.12.5
wandb: Syncing run azure-shadow-2
wandb: ⭐️ View project at https://wandb.ai/yinanazhou/xl_512_bs_8_lr_1e06_es_10_lc_False_nr_False_sr_False_stem_True_lemma_False_repeat_3_fold_2
wandb: 🚀 View run at https://wandb.ai/yinanazhou/xl_512_bs_8_lr_1e06_es_10_lc_False_nr_False_sr_False_stem_True_lemma_False_repeat_3_fold_2/runs/322rfjol
wandb: Run data is saved locally in /project/6002780/yinan/Thesis_MER_Lyrics/lyric-emotion/wandb/run-20220319_034814-322rfjol
wandb: Run `wandb offline` to turn off syncing.

Validation loss decreased (inf --> 1.398455).  Saving model ...
Validation loss decreased (1.398455 --> 1.390505).  Saving model ...
Validation loss decreased (1.390505 --> 1.384086).  Saving model ...
Validation loss decreased (1.384086 --> 1.378186).  Saving model ...
Validation loss decreased (1.378186 --> 1.372834).  Saving model ...
Validation loss decreased (1.372834 --> 1.367875).  Saving model ...
Validation loss decreased (1.367875 --> 1.362944).  Saving model ...
Validation loss decreased (1.362944 --> 1.358182).  Saving model ...
Validation loss decreased (1.358182 --> 1.354127).  Saving model ...
Validation loss decreased (1.354127 --> 1.350038).  Saving model ...
Validation loss decreased (1.350038 --> 1.345754).  Saving model ...
Validation loss decreased (1.345754 --> 1.341434).  Saving model ...
Validation loss decreased (1.341434 --> 1.337374).  Saving model ...
Validation loss decreased (1.337374 --> 1.332762).  Saving model ...
Validation loss decreased (1.332762 --> 1.328114).  Saving model ...
Validation loss decreased (1.328114 --> 1.323719).  Saving model ...
Validation loss decreased (1.323719 --> 1.319032).  Saving model ...
Validation loss decreased (1.319032 --> 1.314182).  Saving model ...
Validation loss decreased (1.314182 --> 1.309554).  Saving model ...
Validation loss decreased (1.309554 --> 1.304573).  Saving model ...
Validation loss decreased (1.304573 --> 1.299415).  Saving model ...
Validation loss decreased (1.299415 --> 1.293686).  Saving model ...
Validation loss decreased (1.293686 --> 1.288162).  Saving model ...
Validation loss decreased (1.288162 --> 1.282732).  Saving model ...
Validation loss decreased (1.282732 --> 1.277189).  Saving model ...
Validation loss decreased (1.277189 --> 1.271230).  Saving model ...
Validation loss decreased (1.271230 --> 1.265448).  Saving model ...
Validation loss decreased (1.265448 --> 1.258739).  Saving model ...
Validation loss decreased (1.258739 --> 1.252861).  Saving model ...
Validation loss decreased (1.252861 --> 1.247079).  Saving model ...
Validation loss decreased (1.247079 --> 1.239732).  Saving model ...
Validation loss decreased (1.239732 --> 1.234347).  Saving model ...
Validation loss decreased (1.234347 --> 1.227484).  Saving model ...
Validation loss decreased (1.227484 --> 1.220686).  Saving model ...
Validation loss decreased (1.220686 --> 1.212929).  Saving model ...
Validation loss decreased (1.212929 --> 1.207213).  Saving model ...
Validation loss decreased (1.207213 --> 1.201855).  Saving model ...
Validation loss decreased (1.201855 --> 1.195899).  Saving model ...
Validation loss decreased (1.195899 --> 1.189565).  Saving model ...
Validation loss decreased (1.189565 --> 1.183123).  Saving model ...
Validation loss decreased (1.183123 --> 1.177562).  Saving model ...
Validation loss decreased (1.177562 --> 1.171285).  Saving model ...
Validation loss decreased (1.171285 --> 1.167001).  Saving model ...
Validation loss decreased (1.167001 --> 1.160068).  Saving model ...
Validation loss decreased (1.160068 --> 1.153084).  Saving model ...
Validation loss decreased (1.153084 --> 1.147040).  Saving model ...
Validation loss decreased (1.147040 --> 1.140558).  Saving model ...
Validation loss decreased (1.140558 --> 1.134803).  Saving model ...
Validation loss decreased (1.134803 --> 1.127081).  Saving model ...
Validation loss decreased (1.127081 --> 1.122224).  Saving model ...
Validation loss decreased (1.122224 --> 1.116006).  Saving model ...
Validation loss decreased (1.116006 --> 1.112738).  Saving model ...
Validation loss decreased (1.112738 --> 1.107111).  Saving model ...
Validation loss decreased (1.107111 --> 1.101869).  Saving model ...
Validation loss decreased (1.101869 --> 1.097973).  Saving model ...
Validation loss decreased (1.097973 --> 1.095701).  Saving model ...
Validation loss decreased (1.095701 --> 1.091271).  Saving model ...
Validation loss decreased (1.091271 --> 1.088632).  Saving model ...
Validation loss decreased (1.088632 --> 1.082466).  Saving model ...
Validation loss decreased (1.082466 --> 1.078370).  Saving model ...
Validation loss decreased (1.078370 --> 1.073213).  Saving model ...
Validation loss decreased (1.073213 --> 1.069908).  Saving model ...
Validation loss decreased (1.069908 --> 1.064444).  Saving model ...
Validation loss decreased (1.064444 --> 1.059885).  Saving model ...
Validation loss decreased (1.059885 --> 1.056163).  Saving model ...
Validation loss decreased (1.056163 --> 1.052614).  Saving model ...
Validation loss decreased (1.052614 --> 1.051468).  Saving model ...
Validation loss decreased (1.051468 --> 1.049749).  Saving model ...
Validation loss decreased (1.049749 --> 1.045602).  Saving model ...
Validation loss decreased (1.045602 --> 1.040203).  Saving model ...
Validation loss decreased (1.040203 --> 1.035429).  Saving model ...
Validation loss decreased (1.035429 --> 1.031720).  Saving model ...
Validation loss decreased (1.031720 --> 1.025937).  Saving model ...
Validation loss decreased (1.025937 --> 1.023406).  Saving model ...
Validation loss decreased (1.023406 --> 1.019298).  Saving model ...
Validation loss decreased (1.019298 --> 1.016617).  Saving model ...
Validation loss decreased (1.016617 --> 1.016040).  Saving model ...
Validation loss decreased (1.016040 --> 1.012692).  Saving model ...
Validation loss decreased (1.012692 --> 1.009886).  Saving model ...
Validation loss decreased (1.009886 --> 1.008577).  Saving model ...
Validation loss decreased (1.008577 --> 1.007653).  Saving model ...
Validation loss decreased (1.007653 --> 1.005510).  Saving model ...
Validation loss decreased (1.005510 --> 1.000921).  Saving model ...
Validation loss decreased (1.000921 --> 0.999910).  Saving model ...
Validation loss decreased (0.999910 --> 0.997442).  Saving model ...
EarlyStopping counter: 1 out of 10.0
Validation loss decreased (0.997442 --> 0.994873).  Saving model ...
Validation loss decreased (0.994873 --> 0.989674).  Saving model ...
Validation loss decreased (0.989674 --> 0.986384).  Saving model ...
Validation loss decreased (0.986384 --> 0.985245).  Saving model ...
Validation loss decreased (0.985245 --> 0.984782).  Saving model ...
Validation loss decreased (0.984782 --> 0.981178).  Saving model ...
Validation loss decreased (0.981178 --> 0.977840).  Saving model ...
Validation loss decreased (0.977840 --> 0.977574).  Saving model ...
Validation loss decreased (0.977574 --> 0.975695).  Saving model ...
Validation loss decreased (0.975695 --> 0.975207).  Saving model ...
Validation loss decreased (0.975207 --> 0.971964).  Saving model ...
Validation loss decreased (0.971964 --> 0.971099).  Saving model ...
Validation loss decreased (0.971099 --> 0.969462).  Saving model ...
Validation loss decreased (0.969462 --> 0.967470).  Saving model ...
EarlyStopping counter: 1 out of 10.0
Validation loss decreased (0.967470 --> 0.967051).  Saving model ...
Validation loss decreased (0.967051 --> 0.965185).  Saving model ...
Validation loss decreased (0.965185 --> 0.963768).  Saving model ...
Validation loss decreased (0.963768 --> 0.963146).  Saving model ...
Validation loss decreased (0.963146 --> 0.962050).  Saving model ...
Validation loss decreased (0.962050 --> 0.961150).  Saving model ...
Validation loss decreased (0.961150 --> 0.960551).  Saving model ...
Validation loss decreased (0.960551 --> 0.956720).  Saving model ...
Validation loss decreased (0.956720 --> 0.955900).  Saving model ...
EarlyStopping counter: 1 out of 10.0
Validation loss decreased (0.955900 --> 0.953070).  Saving model ...
Validation loss decreased (0.953070 --> 0.952207).  Saving model ...
EarlyStopping counter: 1 out of 10.0
Validation loss decreased (0.952207 --> 0.951596).  Saving model ...
Validation loss decreased (0.951596 --> 0.950645).  Saving model ...
Validation loss decreased (0.950645 --> 0.949593).  Saving model ...
EarlyStopping counter: 1 out of 10.0
EarlyStopping counter: 2 out of 10.0
EarlyStopping counter: 3 out of 10.0
Validation loss decreased (0.949593 --> 0.948807).  Saving model ...
Validation loss decreased (0.948807 --> 0.946522).  Saving model ...
Validation loss decreased (0.946522 --> 0.945740).  Saving model ...
Validation loss decreased (0.945740 --> 0.944884).  Saving model ...
EarlyStopping counter: 1 out of 10.0
EarlyStopping counter: 2 out of 10.0
Validation loss decreased (0.944884 --> 0.944849).  Saving model ...
Validation loss decreased (0.944849 --> 0.943294).  Saving model ...
Validation loss decreased (0.943294 --> 0.942460).  Saving model ...
Validation loss decreased (0.942460 --> 0.941309).  Saving model ...
EarlyStopping counter: 1 out of 10.0
EarlyStopping counter: 2 out of 10.0
EarlyStopping counter: 3 out of 10.0
EarlyStopping counter: 4 out of 10.0
EarlyStopping counter: 5 out of 10.0
EarlyStopping counter: 6 out of 10.0
EarlyStopping counter: 7 out of 10.0
EarlyStopping counter: 8 out of 10.0
EarlyStopping counter: 9 out of 10.0
EarlyStopping counter: 10 out of 10.0
/localscratch/yinan.29019368.0/env/lib/python3.7/site-packages/torch/nn/functional.py:1794: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.
  warnings.warn("nn.functional.tanh is deprecated. Use torch.tanh instead.")
wandb: Waiting for W&B process to finish, PID 100414... (success).
wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: \ 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: | 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: / 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: \ 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: | 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: / 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: \ 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: | 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: / 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb:                                                                                
wandb: Run history:
wandb:     e_F1 ▁▂▄▅▅▅▆▅▆▆▆▆▆▆▆▆▇▇▇▇▇▇▇▇▇███████████████
wandb:   e_loss ██▇▇▇▇▆▆▆▆▅▅▄▄▄▃▃▃▃▃▂▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁
wandb:     t_F1 ▁▂▃▃▃▃▄▄▄▅▅▅▆▆▆▆▆▇▆▆▆▇▆▇▇▇▇▇▇▇▇▇█▇█▇████
wandb:   t_loss ███▇▇▇▇▇▆▆▆▆▅▅▅▅▄▄▄▄▄▃▄▃▃▃▃▃▂▂▂▂▂▂▂▂▁▁▁▁
wandb: 
wandb: Run summary:
wandb:     e_F1 60.95419
wandb:   e_loss 0.946
wandb:     t_F1 72.25743
wandb:   t_loss 0.75312
wandb: 
wandb: Synced 4 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Synced azure-shadow-2: https://wandb.ai/yinanazhou/xl_512_bs_8_lr_1e06_es_10_lc_False_nr_False_sr_False_stem_True_lemma_False_repeat_3_fold_2/runs/322rfjol
wandb: Find logs at: ./wandb/run-20220319_034814-322rfjol/logs/debug.log
wandb: 

wandb: wandb version 0.12.11 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
2022-03-19 05:15:51.324151: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1
wandb: Tracking run with wandb version 0.12.5
wandb: Syncing run decent-lake-2
wandb: ⭐️ View project at https://wandb.ai/yinanazhou/xl_512_bs_8_lr_1e06_es_10_lc_False_nr_False_sr_False_stem_True_lemma_False_repeat_4_fold_1
wandb: 🚀 View run at https://wandb.ai/yinanazhou/xl_512_bs_8_lr_1e06_es_10_lc_False_nr_False_sr_False_stem_True_lemma_False_repeat_4_fold_1/runs/2djsv3fa
wandb: Run data is saved locally in /project/6002780/yinan/Thesis_MER_Lyrics/lyric-emotion/wandb/run-20220319_051548-2djsv3fa
wandb: Run `wandb offline` to turn off syncing.

Validation loss decreased (inf --> 1.611766).  Saving model ...
Validation loss decreased (1.611766 --> 1.522285).  Saving model ...
Validation loss decreased (1.522285 --> 1.460434).  Saving model ...
Validation loss decreased (1.460434 --> 1.424516).  Saving model ...
Validation loss decreased (1.424516 --> 1.404189).  Saving model ...
Validation loss decreased (1.404189 --> 1.393646).  Saving model ...
Validation loss decreased (1.393646 --> 1.387264).  Saving model ...
Validation loss decreased (1.387264 --> 1.382450).  Saving model ...
Validation loss decreased (1.382450 --> 1.376318).  Saving model ...
Validation loss decreased (1.376318 --> 1.370495).  Saving model ...
Validation loss decreased (1.370495 --> 1.365575).  Saving model ...
Validation loss decreased (1.365575 --> 1.359555).  Saving model ...
Validation loss decreased (1.359555 --> 1.353807).  Saving model ...
Validation loss decreased (1.353807 --> 1.346539).  Saving model ...
Validation loss decreased (1.346539 --> 1.341014).  Saving model ...
Validation loss decreased (1.341014 --> 1.334833).  Saving model ...
Validation loss decreased (1.334833 --> 1.328257).  Saving model ...
Validation loss decreased (1.328257 --> 1.321723).  Saving model ...
Validation loss decreased (1.321723 --> 1.315770).  Saving model ...
Validation loss decreased (1.315770 --> 1.308959).  Saving model ...
Validation loss decreased (1.308959 --> 1.302681).  Saving model ...
Validation loss decreased (1.302681 --> 1.295190).  Saving model ...
Validation loss decreased (1.295190 --> 1.288717).  Saving model ...
Validation loss decreased (1.288717 --> 1.282086).  Saving model ...
Validation loss decreased (1.282086 --> 1.274570).  Saving model ...
Validation loss decreased (1.274570 --> 1.269017).  Saving model ...
Validation loss decreased (1.269017 --> 1.262084).  Saving model ...
Validation loss decreased (1.262084 --> 1.255345).  Saving model ...
Validation loss decreased (1.255345 --> 1.247996).  Saving model ...
Validation loss decreased (1.247996 --> 1.241081).  Saving model ...
Validation loss decreased (1.241081 --> 1.234786).  Saving model ...
Validation loss decreased (1.234786 --> 1.228458).  Saving model ...
Validation loss decreased (1.228458 --> 1.222529).  Saving model ...
Validation loss decreased (1.222529 --> 1.216243).  Saving model ...
Validation loss decreased (1.216243 --> 1.211248).  Saving model ...
Validation loss decreased (1.211248 --> 1.204805).  Saving model ...
Validation loss decreased (1.204805 --> 1.196985).  Saving model ...
Validation loss decreased (1.196985 --> 1.191211).  Saving model ...
Validation loss decreased (1.191211 --> 1.186473).  Saving model ...
Validation loss decreased (1.186473 --> 1.180998).  Saving model ...
Validation loss decreased (1.180998 --> 1.173304).  Saving model ...
Validation loss decreased (1.173304 --> 1.166646).  Saving model ...
Validation loss decreased (1.166646 --> 1.160260).  Saving model ...
Validation loss decreased (1.160260 --> 1.153609).  Saving model ...
Validation loss decreased (1.153609 --> 1.149136).  Saving model ...
Validation loss decreased (1.149136 --> 1.143543).  Saving model ...
Validation loss decreased (1.143543 --> 1.137148).  Saving model ...
Validation loss decreased (1.137148 --> 1.131359).  Saving model ...
Validation loss decreased (1.131359 --> 1.127772).  Saving model ...
Validation loss decreased (1.127772 --> 1.123543).  Saving model ...
Validation loss decreased (1.123543 --> 1.117413).  Saving model ...
Validation loss decreased (1.117413 --> 1.109560).  Saving model ...
Validation loss decreased (1.109560 --> 1.103792).  Saving model ...
Validation loss decreased (1.103792 --> 1.100589).  Saving model ...
Validation loss decreased (1.100589 --> 1.096291).  Saving model ...
Validation loss decreased (1.096291 --> 1.090701).  Saving model ...
Validation loss decreased (1.090701 --> 1.087204).  Saving model ...
Validation loss decreased (1.087204 --> 1.084275).  Saving model ...
Validation loss decreased (1.084275 --> 1.080230).  Saving model ...
Validation loss decreased (1.080230 --> 1.076040).  Saving model ...
Validation loss decreased (1.076040 --> 1.072846).  Saving model ...
Validation loss decreased (1.072846 --> 1.068541).  Saving model ...
Validation loss decreased (1.068541 --> 1.064765).  Saving model ...
Validation loss decreased (1.064765 --> 1.059523).  Saving model ...
Validation loss decreased (1.059523 --> 1.055022).  Saving model ...
Validation loss decreased (1.055022 --> 1.052844).  Saving model ...
Validation loss decreased (1.052844 --> 1.051071).  Saving model ...
Validation loss decreased (1.051071 --> 1.046761).  Saving model ...
Validation loss decreased (1.046761 --> 1.044364).  Saving model ...
Validation loss decreased (1.044364 --> 1.043052).  Saving model ...
Validation loss decreased (1.043052 --> 1.038463).  Saving model ...
Validation loss decreased (1.038463 --> 1.036551).  Saving model ...
Validation loss decreased (1.036551 --> 1.031416).  Saving model ...
Validation loss decreased (1.031416 --> 1.029154).  Saving model ...
Validation loss decreased (1.029154 --> 1.027403).  Saving model ...
Validation loss decreased (1.027403 --> 1.024237).  Saving model ...
Validation loss decreased (1.024237 --> 1.022590).  Saving model ...
Validation loss decreased (1.022590 --> 1.018082).  Saving model ...
Validation loss decreased (1.018082 --> 1.014800).  Saving model ...
Validation loss decreased (1.014800 --> 1.014140).  Saving model ...
Validation loss decreased (1.014140 --> 1.013441).  Saving model ...
Validation loss decreased (1.013441 --> 1.009510).  Saving model ...
Validation loss decreased (1.009510 --> 1.006898).  Saving model ...
Validation loss decreased (1.006898 --> 1.006882).  Saving model ...
Validation loss decreased (1.006882 --> 1.004819).  Saving model ...
Validation loss decreased (1.004819 --> 1.002148).  Saving model ...
Validation loss decreased (1.002148 --> 0.999175).  Saving model ...
Validation loss decreased (0.999175 --> 0.996794).  Saving model ...
Validation loss decreased (0.996794 --> 0.994703).  Saving model ...
EarlyStopping counter: 1 out of 10.0
Validation loss decreased (0.994703 --> 0.992810).  Saving model ...
Validation loss decreased (0.992810 --> 0.990674).  Saving model ...
Validation loss decreased (0.990674 --> 0.990445).  Saving model ...
Validation loss decreased (0.990445 --> 0.989426).  Saving model ...
EarlyStopping counter: 1 out of 10.0
Validation loss decreased (0.989426 --> 0.988279).  Saving model ...
Validation loss decreased (0.988279 --> 0.983791).  Saving model ...
Validation loss decreased (0.983791 --> 0.982001).  Saving model ...
EarlyStopping counter: 1 out of 10.0
Validation loss decreased (0.982001 --> 0.980571).  Saving model ...
Validation loss decreased (0.980571 --> 0.978551).  Saving model ...
Validation loss decreased (0.978551 --> 0.978419).  Saving model ...
EarlyStopping counter: 1 out of 10.0
Validation loss decreased (0.978419 --> 0.976390).  Saving model ...
EarlyStopping counter: 1 out of 10.0
Validation loss decreased (0.976390 --> 0.976383).  Saving model ...
Validation loss decreased (0.976383 --> 0.974877).  Saving model ...
Validation loss decreased (0.974877 --> 0.972865).  Saving model ...
EarlyStopping counter: 1 out of 10.0
Validation loss decreased (0.972865 --> 0.970159).  Saving model ...
EarlyStopping counter: 1 out of 10.0
EarlyStopping counter: 2 out of 10.0
Validation loss decreased (0.970159 --> 0.969814).  Saving model ...
Validation loss decreased (0.969814 --> 0.969278).  Saving model ...
Validation loss decreased (0.969278 --> 0.965746).  Saving model ...
EarlyStopping counter: 1 out of 10.0
EarlyStopping counter: 2 out of 10.0
Validation loss decreased (0.965746 --> 0.965010).  Saving model ...
EarlyStopping counter: 1 out of 10.0
Validation loss decreased (0.965010 --> 0.963411).  Saving model ...
EarlyStopping counter: 1 out of 10.0
EarlyStopping counter: 2 out of 10.0
EarlyStopping counter: 3 out of 10.0
EarlyStopping counter: 4 out of 10.0
EarlyStopping counter: 5 out of 10.0
EarlyStopping counter: 6 out of 10.0
EarlyStopping counter: 7 out of 10.0
EarlyStopping counter: 8 out of 10.0
EarlyStopping counter: 9 out of 10.0
Validation loss decreased (0.963411 --> 0.961848).  Saving model ...
EarlyStopping counter: 1 out of 10.0
EarlyStopping counter: 2 out of 10.0
EarlyStopping counter: 3 out of 10.0
EarlyStopping counter: 4 out of 10.0
EarlyStopping counter: 5 out of 10.0
EarlyStopping counter: 6 out of 10.0
EarlyStopping counter: 7 out of 10.0
EarlyStopping counter: 8 out of 10.0
Validation loss decreased (0.961848 --> 0.960936).  Saving model ...
Validation loss decreased (0.960936 --> 0.960283).  Saving model ...
EarlyStopping counter: 1 out of 10.0
EarlyStopping counter: 2 out of 10.0
EarlyStopping counter: 3 out of 10.0
EarlyStopping counter: 4 out of 10.0
EarlyStopping counter: 5 out of 10.0
EarlyStopping counter: 6 out of 10.0
EarlyStopping counter: 7 out of 10.0
EarlyStopping counter: 8 out of 10.0
EarlyStopping counter: 9 out of 10.0
EarlyStopping counter: 10 out of 10.0
/localscratch/yinan.29019368.0/env/lib/python3.7/site-packages/torch/nn/functional.py:1794: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.
  warnings.warn("nn.functional.tanh is deprecated. Use torch.tanh instead.")
wandb: Waiting for W&B process to finish, PID 105142... (success).
wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: \ 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: | 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: / 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: \ 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: | 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: / 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: \ 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: | 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: / 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb:                                                                                
wandb: Run history:
wandb:     e_F1 ▁▂▄▄▄▅▅▅▆▆▆▆▇▇▇▇▇▇▇▇████████████████████
wandb:   e_loss █▇▆▆▆▅▅▅▄▄▄▄▃▃▃▃▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:     t_F1 ▁▁▂▃▃▄▄▄▅▅▅▅▆▆▅▆▆▆▆▆▆▇▆▇▇▇▇▇▇█▇▇████████
wandb:   t_loss █▇▇▆▆▆▆▅▅▅▅▅▄▄▄▃▄▃▃▃▃▃▃▃▂▂▂▂▂▂▂▂▂▂▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:     e_F1 58.23565
wandb:   e_loss 0.9708
wandb:     t_F1 72.54008
wandb:   t_loss 0.72306
wandb: 
wandb: Synced 4 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Synced decent-lake-2: https://wandb.ai/yinanazhou/xl_512_bs_8_lr_1e06_es_10_lc_False_nr_False_sr_False_stem_True_lemma_False_repeat_4_fold_1/runs/2djsv3fa
wandb: Find logs at: ./wandb/run-20220319_051548-2djsv3fa/logs/debug.log
wandb: 

wandb: wandb version 0.12.11 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
2022-03-19 06:53:01.526276: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1
wandb: Tracking run with wandb version 0.12.5
wandb: Syncing run absurd-sound-2
wandb: ⭐️ View project at https://wandb.ai/yinanazhou/xl_512_bs_8_lr_1e06_es_10_lc_False_nr_False_sr_False_stem_True_lemma_False_repeat_4_fold_2
wandb: 🚀 View run at https://wandb.ai/yinanazhou/xl_512_bs_8_lr_1e06_es_10_lc_False_nr_False_sr_False_stem_True_lemma_False_repeat_4_fold_2/runs/ax27ynhs
wandb: Run data is saved locally in /project/6002780/yinan/Thesis_MER_Lyrics/lyric-emotion/wandb/run-20220319_065258-ax27ynhs
wandb: Run `wandb offline` to turn off syncing.

Validation loss decreased (inf --> 1.434498).  Saving model ...
Validation loss decreased (1.434498 --> 1.414426).  Saving model ...
Validation loss decreased (1.414426 --> 1.399807).  Saving model ...
Validation loss decreased (1.399807 --> 1.387827).  Saving model ...
Validation loss decreased (1.387827 --> 1.379160).  Saving model ...
Validation loss decreased (1.379160 --> 1.371753).  Saving model ...
Validation loss decreased (1.371753 --> 1.365244).  Saving model ...
Validation loss decreased (1.365244 --> 1.359546).  Saving model ...
Validation loss decreased (1.359546 --> 1.354195).  Saving model ...
Validation loss decreased (1.354195 --> 1.349044).  Saving model ...
Validation loss decreased (1.349044 --> 1.344010).  Saving model ...
Validation loss decreased (1.344010 --> 1.339050).  Saving model ...
Validation loss decreased (1.339050 --> 1.334602).  Saving model ...
Validation loss decreased (1.334602 --> 1.329970).  Saving model ...
Validation loss decreased (1.329970 --> 1.325330).  Saving model ...
Validation loss decreased (1.325330 --> 1.320348).  Saving model ...
Validation loss decreased (1.320348 --> 1.314889).  Saving model ...
Validation loss decreased (1.314889 --> 1.309391).  Saving model ...
Validation loss decreased (1.309391 --> 1.303811).  Saving model ...
Validation loss decreased (1.303811 --> 1.297849).  Saving model ...
Validation loss decreased (1.297849 --> 1.290579).  Saving model ...
Validation loss decreased (1.290579 --> 1.282339).  Saving model ...
Validation loss decreased (1.282339 --> 1.274371).  Saving model ...
Validation loss decreased (1.274371 --> 1.266849).  Saving model ...
Validation loss decreased (1.266849 --> 1.256890).  Saving model ...
Validation loss decreased (1.256890 --> 1.247640).  Saving model ...
Validation loss decreased (1.247640 --> 1.237544).  Saving model ...
Validation loss decreased (1.237544 --> 1.229294).  Saving model ...
Validation loss decreased (1.229294 --> 1.219050).  Saving model ...
Validation loss decreased (1.219050 --> 1.209418).  Saving model ...
Validation loss decreased (1.209418 --> 1.198734).  Saving model ...
Validation loss decreased (1.198734 --> 1.189624).  Saving model ...
Validation loss decreased (1.189624 --> 1.180797).  Saving model ...
Validation loss decreased (1.180797 --> 1.172052).  Saving model ...
Validation loss decreased (1.172052 --> 1.162447).  Saving model ...
Validation loss decreased (1.162447 --> 1.155802).  Saving model ...
Validation loss decreased (1.155802 --> 1.149475).  Saving model ...
Validation loss decreased (1.149475 --> 1.142354).  Saving model ...
Validation loss decreased (1.142354 --> 1.135316).  Saving model ...
Validation loss decreased (1.135316 --> 1.127439).  Saving model ...
Validation loss decreased (1.127439 --> 1.121012).  Saving model ...
Validation loss decreased (1.121012 --> 1.113318).  Saving model ...
Validation loss decreased (1.113318 --> 1.107206).  Saving model ...
Validation loss decreased (1.107206 --> 1.101856).  Saving model ...
Validation loss decreased (1.101856 --> 1.097638).  Saving model ...
Validation loss decreased (1.097638 --> 1.092482).  Saving model ...
Validation loss decreased (1.092482 --> 1.086750).  Saving model ...
Validation loss decreased (1.086750 --> 1.082092).  Saving model ...
Validation loss decreased (1.082092 --> 1.076043).  Saving model ...
Validation loss decreased (1.076043 --> 1.070340).  Saving model ...
Validation loss decreased (1.070340 --> 1.064975).  Saving model ...
Validation loss decreased (1.064975 --> 1.060161).  Saving model ...
Validation loss decreased (1.060161 --> 1.055825).  Saving model ...
Validation loss decreased (1.055825 --> 1.049787).  Saving model ...
Validation loss decreased (1.049787 --> 1.045161).  Saving model ...
Validation loss decreased (1.045161 --> 1.040538).  Saving model ...
Validation loss decreased (1.040538 --> 1.035569).  Saving model ...
Validation loss decreased (1.035569 --> 1.032587).  Saving model ...
Validation loss decreased (1.032587 --> 1.030187).  Saving model ...
Validation loss decreased (1.030187 --> 1.026090).  Saving model ...
Validation loss decreased (1.026090 --> 1.021709).  Saving model ...
Validation loss decreased (1.021709 --> 1.017712).  Saving model ...
Validation loss decreased (1.017712 --> 1.014010).  Saving model ...
Validation loss decreased (1.014010 --> 1.011128).  Saving model ...
Validation loss decreased (1.011128 --> 1.008007).  Saving model ...
Validation loss decreased (1.008007 --> 1.004029).  Saving model ...
Validation loss decreased (1.004029 --> 1.000981).  Saving model ...
Validation loss decreased (1.000981 --> 0.999043).  Saving model ...
Validation loss decreased (0.999043 --> 0.995602).  Saving model ...
Validation loss decreased (0.995602 --> 0.992236).  Saving model ...
Validation loss decreased (0.992236 --> 0.989641).  Saving model ...
Validation loss decreased (0.989641 --> 0.985666).  Saving model ...
Validation loss decreased (0.985666 --> 0.983540).  Saving model ...
Validation loss decreased (0.983540 --> 0.980760).  Saving model ...
Validation loss decreased (0.980760 --> 0.978550).  Saving model ...
Validation loss decreased (0.978550 --> 0.975959).  Saving model ...
Validation loss decreased (0.975959 --> 0.972713).  Saving model ...
Validation loss decreased (0.972713 --> 0.971250).  Saving model ...
Validation loss decreased (0.971250 --> 0.969225).  Saving model ...
Validation loss decreased (0.969225 --> 0.967427).  Saving model ...
Validation loss decreased (0.967427 --> 0.966041).  Saving model ...
Validation loss decreased (0.966041 --> 0.965158).  Saving model ...
Validation loss decreased (0.965158 --> 0.963589).  Saving model ...
Validation loss decreased (0.963589 --> 0.960535).  Saving model ...
EarlyStopping counter: 1 out of 10.0
Validation loss decreased (0.960535 --> 0.957708).  Saving model ...
Validation loss decreased (0.957708 --> 0.954397).  Saving model ...
Validation loss decreased (0.954397 --> 0.951877).  Saving model ...
Validation loss decreased (0.951877 --> 0.951156).  Saving model ...
Validation loss decreased (0.951156 --> 0.949455).  Saving model ...
Validation loss decreased (0.949455 --> 0.949002).  Saving model ...
Validation loss decreased (0.949002 --> 0.946962).  Saving model ...
Validation loss decreased (0.946962 --> 0.946244).  Saving model ...
Validation loss decreased (0.946244 --> 0.944882).  Saving model ...
Validation loss decreased (0.944882 --> 0.943967).  Saving model ...
Validation loss decreased (0.943967 --> 0.943789).  Saving model ...
Validation loss decreased (0.943789 --> 0.943041).  Saving model ...
EarlyStopping counter: 1 out of 10.0
Validation loss decreased (0.943041 --> 0.942592).  Saving model ...
Validation loss decreased (0.942592 --> 0.941308).  Saving model ...
EarlyStopping counter: 1 out of 10.0
Validation loss decreased (0.941308 --> 0.940597).  Saving model ...
Validation loss decreased (0.940597 --> 0.940253).  Saving model ...
Validation loss decreased (0.940253 --> 0.939183).  Saving model ...
Validation loss decreased (0.939183 --> 0.936221).  Saving model ...
Validation loss decreased (0.936221 --> 0.934622).  Saving model ...
Validation loss decreased (0.934622 --> 0.934568).  Saving model ...
EarlyStopping counter: 1 out of 10.0
Validation loss decreased (0.934568 --> 0.933933).  Saving model ...
EarlyStopping counter: 1 out of 10.0
EarlyStopping counter: 2 out of 10.0
Validation loss decreased (0.933933 --> 0.931986).  Saving model ...
EarlyStopping counter: 1 out of 10.0
Validation loss decreased (0.931986 --> 0.931907).  Saving model ...
EarlyStopping counter: 1 out of 10.0
EarlyStopping counter: 2 out of 10.0
Validation loss decreased (0.931907 --> 0.931401).  Saving model ...
Validation loss decreased (0.931401 --> 0.930441).  Saving model ...
Validation loss decreased (0.930441 --> 0.930109).  Saving model ...
EarlyStopping counter: 1 out of 10.0
Validation loss decreased (0.930109 --> 0.929156).  Saving model ...
EarlyStopping counter: 1 out of 10.0
Validation loss decreased (0.929156 --> 0.928022).  Saving model ...
EarlyStopping counter: 1 out of 10.0
EarlyStopping counter: 2 out of 10.0
EarlyStopping counter: 3 out of 10.0
EarlyStopping counter: 4 out of 10.0
EarlyStopping counter: 5 out of 10.0
EarlyStopping counter: 6 out of 10.0
EarlyStopping counter: 7 out of 10.0
EarlyStopping counter: 8 out of 10.0
EarlyStopping counter: 9 out of 10.0
EarlyStopping counter: 10 out of 10.0
/localscratch/yinan.29019368.0/env/lib/python3.7/site-packages/torch/nn/functional.py:1794: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.
  warnings.warn("nn.functional.tanh is deprecated. Use torch.tanh instead.")
wandb: Waiting for W&B process to finish, PID 110361... (success).
wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: \ 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: | 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: / 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: \ 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: | 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: / 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: \ 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: | 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: / 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb:                                                                                
wandb: Run history:
wandb:     e_F1 ▁▁▄▅▅▆▆▆▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇███████████
wandb:   e_loss ██▇▇▇▆▆▆▅▅▅▄▄▃▃▃▃▂▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:     t_F1 ▁▁▂▃▃▄▃▄▄▅▅▅▅▅▆▅▆▆▆▆▆▆▆▆▇▇▇▆▇▇▇▇▇▇▇▇▇▇▇█
wandb:   t_loss ██▇▇▇▇▇▇▆▆▆▆▅▅▅▅▄▄▄▄▄▃▄▃▃▃▃▃▃▂▂▂▂▂▂▂▁▂▂▁
wandb: 
wandb: Run summary:
wandb:     e_F1 60.99576
wandb:   e_loss 0.93117
wandb:     t_F1 72.51095
wandb:   t_loss 0.75919
wandb: 
wandb: Synced 4 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Synced absurd-sound-2: https://wandb.ai/yinanazhou/xl_512_bs_8_lr_1e06_es_10_lc_False_nr_False_sr_False_stem_True_lemma_False_repeat_4_fold_2/runs/ax27ynhs
wandb: Find logs at: ./wandb/run-20220319_065258-ax27ynhs/logs/debug.log
wandb: 

wandb: wandb version 0.12.11 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
2022-03-19 08:20:03.989674: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1
wandb: Tracking run with wandb version 0.12.5
wandb: Syncing run dainty-violet-2
wandb: ⭐️ View project at https://wandb.ai/yinanazhou/xl_512_bs_8_lr_1e06_es_10_lc_False_nr_False_sr_False_stem_True_lemma_False_repeat_5_fold_1
wandb: 🚀 View run at https://wandb.ai/yinanazhou/xl_512_bs_8_lr_1e06_es_10_lc_False_nr_False_sr_False_stem_True_lemma_False_repeat_5_fold_1/runs/2quvullm
wandb: Run data is saved locally in /project/6002780/yinan/Thesis_MER_Lyrics/lyric-emotion/wandb/run-20220319_082000-2quvullm
wandb: Run `wandb offline` to turn off syncing.

Validation loss decreased (inf --> 1.416767).  Saving model ...
Validation loss decreased (1.416767 --> 1.402735).  Saving model ...
Validation loss decreased (1.402735 --> 1.391476).  Saving model ...
Validation loss decreased (1.391476 --> 1.382471).  Saving model ...
Validation loss decreased (1.382471 --> 1.375505).  Saving model ...
Validation loss decreased (1.375505 --> 1.370264).  Saving model ...
Validation loss decreased (1.370264 --> 1.365089).  Saving model ...
Validation loss decreased (1.365089 --> 1.360638).  Saving model ...
Validation loss decreased (1.360638 --> 1.356967).  Saving model ...
Validation loss decreased (1.356967 --> 1.353301).  Saving model ...
Validation loss decreased (1.353301 --> 1.349042).  Saving model ...
Validation loss decreased (1.349042 --> 1.345362).  Saving model ...
Validation loss decreased (1.345362 --> 1.341594).  Saving model ...
Validation loss decreased (1.341594 --> 1.337634).  Saving model ...
Validation loss decreased (1.337634 --> 1.333205).  Saving model ...
Validation loss decreased (1.333205 --> 1.328730).  Saving model ...
Validation loss decreased (1.328730 --> 1.323497).  Saving model ...
Validation loss decreased (1.323497 --> 1.318377).  Saving model ...
Validation loss decreased (1.318377 --> 1.312894).  Saving model ...
Validation loss decreased (1.312894 --> 1.307451).  Saving model ...
Validation loss decreased (1.307451 --> 1.301546).  Saving model ...
Validation loss decreased (1.301546 --> 1.295517).  Saving model ...
Validation loss decreased (1.295517 --> 1.289482).  Saving model ...
Validation loss decreased (1.289482 --> 1.281786).  Saving model ...
Validation loss decreased (1.281786 --> 1.274957).  Saving model ...
Validation loss decreased (1.274957 --> 1.268593).  Saving model ...
Validation loss decreased (1.268593 --> 1.261116).  Saving model ...
Validation loss decreased (1.261116 --> 1.254993).  Saving model ...
Validation loss decreased (1.254993 --> 1.248670).  Saving model ...
Validation loss decreased (1.248670 --> 1.243062).  Saving model ...
Validation loss decreased (1.243062 --> 1.236590).  Saving model ...
Validation loss decreased (1.236590 --> 1.229226).  Saving model ...
Validation loss decreased (1.229226 --> 1.222667).  Saving model ...
Validation loss decreased (1.222667 --> 1.215302).  Saving model ...
Validation loss decreased (1.215302 --> 1.208069).  Saving model ...
Validation loss decreased (1.208069 --> 1.202285).  Saving model ...
Validation loss decreased (1.202285 --> 1.195224).  Saving model ...
Validation loss decreased (1.195224 --> 1.189909).  Saving model ...
Validation loss decreased (1.189909 --> 1.183817).  Saving model ...
Validation loss decreased (1.183817 --> 1.176705).  Saving model ...
Validation loss decreased (1.176705 --> 1.172866).  Saving model ...
Validation loss decreased (1.172866 --> 1.166598).  Saving model ...
Validation loss decreased (1.166598 --> 1.162005).  Saving model ...
Validation loss decreased (1.162005 --> 1.155553).  Saving model ...
Validation loss decreased (1.155553 --> 1.149649).  Saving model ...
Validation loss decreased (1.149649 --> 1.144431).  Saving model ...
Validation loss decreased (1.144431 --> 1.139518).  Saving model ...
Validation loss decreased (1.139518 --> 1.134015).  Saving model ...
Validation loss decreased (1.134015 --> 1.129675).  Saving model ...
Validation loss decreased (1.129675 --> 1.124615).  Saving model ...
Validation loss decreased (1.124615 --> 1.121339).  Saving model ...
Validation loss decreased (1.121339 --> 1.117238).  Saving model ...
Validation loss decreased (1.117238 --> 1.113547).  Saving model ...
Validation loss decreased (1.113547 --> 1.109329).  Saving model ...
Validation loss decreased (1.109329 --> 1.103377).  Saving model ...
Validation loss decreased (1.103377 --> 1.099308).  Saving model ...
Validation loss decreased (1.099308 --> 1.095358).  Saving model ...
Validation loss decreased (1.095358 --> 1.092810).  Saving model ...
Validation loss decreased (1.092810 --> 1.089321).  Saving model ...
Validation loss decreased (1.089321 --> 1.083267).  Saving model ...
Validation loss decreased (1.083267 --> 1.077722).  Saving model ...
Validation loss decreased (1.077722 --> 1.073005).  Saving model ...
Validation loss decreased (1.073005 --> 1.071620).  Saving model ...
Validation loss decreased (1.071620 --> 1.069932).  Saving model ...
Validation loss decreased (1.069932 --> 1.065019).  Saving model ...
Validation loss decreased (1.065019 --> 1.060761).  Saving model ...
Validation loss decreased (1.060761 --> 1.057893).  Saving model ...
Validation loss decreased (1.057893 --> 1.055635).  Saving model ...
Validation loss decreased (1.055635 --> 1.052073).  Saving model ...
Validation loss decreased (1.052073 --> 1.049663).  Saving model ...
Validation loss decreased (1.049663 --> 1.044590).  Saving model ...
Validation loss decreased (1.044590 --> 1.040328).  Saving model ...
Validation loss decreased (1.040328 --> 1.037191).  Saving model ...
Validation loss decreased (1.037191 --> 1.035441).  Saving model ...
Validation loss decreased (1.035441 --> 1.033239).  Saving model ...
Validation loss decreased (1.033239 --> 1.032131).  Saving model ...
Validation loss decreased (1.032131 --> 1.028308).  Saving model ...
Validation loss decreased (1.028308 --> 1.025361).  Saving model ...
Validation loss decreased (1.025361 --> 1.021939).  Saving model ...
Validation loss decreased (1.021939 --> 1.018661).  Saving model ...
Validation loss decreased (1.018661 --> 1.015857).  Saving model ...
Validation loss decreased (1.015857 --> 1.015696).  Saving model ...
Validation loss decreased (1.015696 --> 1.009990).  Saving model ...
Validation loss decreased (1.009990 --> 1.006671).  Saving model ...
Validation loss decreased (1.006671 --> 1.001021).  Saving model ...
Validation loss decreased (1.001021 --> 1.000783).  Saving model ...
Validation loss decreased (1.000783 --> 0.998632).  Saving model ...
Validation loss decreased (0.998632 --> 0.997332).  Saving model ...
Validation loss decreased (0.997332 --> 0.994694).  Saving model ...
Validation loss decreased (0.994694 --> 0.991555).  Saving model ...
Validation loss decreased (0.991555 --> 0.989159).  Saving model ...
Validation loss decreased (0.989159 --> 0.987987).  Saving model ...
Validation loss decreased (0.987987 --> 0.987002).  Saving model ...
Validation loss decreased (0.987002 --> 0.984259).  Saving model ...
Validation loss decreased (0.984259 --> 0.983681).  Saving model ...
Validation loss decreased (0.983681 --> 0.980946).  Saving model ...
EarlyStopping counter: 1 out of 10.0
Validation loss decreased (0.980946 --> 0.979992).  Saving model ...
Validation loss decreased (0.979992 --> 0.978204).  Saving model ...
Validation loss decreased (0.978204 --> 0.977567).  Saving model ...
Validation loss decreased (0.977567 --> 0.974617).  Saving model ...
Validation loss decreased (0.974617 --> 0.973642).  Saving model ...
Validation loss decreased (0.973642 --> 0.973313).  Saving model ...
Validation loss decreased (0.973313 --> 0.972275).  Saving model ...
Validation loss decreased (0.972275 --> 0.969263).  Saving model ...
Validation loss decreased (0.969263 --> 0.968827).  Saving model ...
Validation loss decreased (0.968827 --> 0.967630).  Saving model ...
EarlyStopping counter: 1 out of 10.0
Validation loss decreased (0.967630 --> 0.967319).  Saving model ...
Validation loss decreased (0.967319 --> 0.964605).  Saving model ...
Validation loss decreased (0.964605 --> 0.964581).  Saving model ...
Validation loss decreased (0.964581 --> 0.962911).  Saving model ...
EarlyStopping counter: 1 out of 10.0
Validation loss decreased (0.962911 --> 0.960974).  Saving model ...
Validation loss decreased (0.960974 --> 0.960579).  Saving model ...
Validation loss decreased (0.960579 --> 0.960344).  Saving model ...
Validation loss decreased (0.960344 --> 0.959071).  Saving model ...
Validation loss decreased (0.959071 --> 0.958268).  Saving model ...
EarlyStopping counter: 1 out of 10.0
EarlyStopping counter: 2 out of 10.0
EarlyStopping counter: 3 out of 10.0
Validation loss decreased (0.958268 --> 0.957613).  Saving model ...
Validation loss decreased (0.957613 --> 0.956667).  Saving model ...
Validation loss decreased (0.956667 --> 0.955512).  Saving model ...
EarlyStopping counter: 1 out of 10.0
EarlyStopping counter: 2 out of 10.0
EarlyStopping counter: 3 out of 10.0
EarlyStopping counter: 4 out of 10.0
EarlyStopping counter: 5 out of 10.0
Validation loss decreased (0.955512 --> 0.954289).  Saving model ...
EarlyStopping counter: 1 out of 10.0
EarlyStopping counter: 2 out of 10.0
EarlyStopping counter: 3 out of 10.0
EarlyStopping counter: 4 out of 10.0
EarlyStopping counter: 5 out of 10.0
EarlyStopping counter: 6 out of 10.0
EarlyStopping counter: 7 out of 10.0
EarlyStopping counter: 8 out of 10.0
EarlyStopping counter: 9 out of 10.0
EarlyStopping counter: 10 out of 10.0
/localscratch/yinan.29019368.0/env/lib/python3.7/site-packages/torch/nn/functional.py:1794: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.
  warnings.warn("nn.functional.tanh is deprecated. Use torch.tanh instead.")
wandb: Waiting for W&B process to finish, PID 115043... (success).
wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: \ 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: | 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: / 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: \ 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: | 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: / 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: \ 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: | 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: / 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb:                                                                                
wandb: Run history:
wandb:     e_F1 ▁▂▃▄▄▄▄▅▅▅▅▆▆▆▆▆▆▆▆▇▇▇▇▇▇▇█▇████████████
wandb:   e_loss ██▇▇▇▇▆▆▆▅▅▄▄▄▄▃▃▃▃▃▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:     t_F1 ▁▁▂▂▃▃▃▄▄▅▅▄▅▅▅▅▅▆▆▆▆▇▆▆▆▇▇▇▇▇▇▇▇▇█▇████
wandb:   t_loss ███▇▇▇▇▆▆▆▆▆▅▅▅▅▄▄▄▄▄▃▄▃▃▃▃▃▂▂▂▂▂▂▁▂▁▁▁▁
wandb: 
wandb: Run summary:
wandb:     e_F1 59.01629
wandb:   e_loss 0.95582
wandb:     t_F1 72.86125
wandb:   t_loss 0.74007
wandb: 
wandb: Synced 4 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Synced dainty-violet-2: https://wandb.ai/yinanazhou/xl_512_bs_8_lr_1e06_es_10_lc_False_nr_False_sr_False_stem_True_lemma_False_repeat_5_fold_1/runs/2quvullm
wandb: Find logs at: ./wandb/run-20220319_082000-2quvullm/logs/debug.log
wandb: 

wandb: wandb version 0.12.11 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
2022-03-19 09:50:41.887007: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1
wandb: Tracking run with wandb version 0.12.5
wandb: Syncing run lunar-firebrand-1
wandb: ⭐️ View project at https://wandb.ai/yinanazhou/xl_512_bs_8_lr_1e06_es_10_lc_False_nr_False_sr_False_stem_True_lemma_False_repeat_5_fold_2
wandb: 🚀 View run at https://wandb.ai/yinanazhou/xl_512_bs_8_lr_1e06_es_10_lc_False_nr_False_sr_False_stem_True_lemma_False_repeat_5_fold_2/runs/34069cp3
wandb: Run data is saved locally in /project/6002780/yinan/Thesis_MER_Lyrics/lyric-emotion/wandb/run-20220319_095038-34069cp3
wandb: Run `wandb offline` to turn off syncing.

Validation loss decreased (inf --> 1.406782).  Saving model ...
Validation loss decreased (1.406782 --> 1.397706).  Saving model ...
Validation loss decreased (1.397706 --> 1.390811).  Saving model ...
Validation loss decreased (1.390811 --> 1.385566).  Saving model ...
Validation loss decreased (1.385566 --> 1.380577).  Saving model ...
Validation loss decreased (1.380577 --> 1.376244).  Saving model ...
Validation loss decreased (1.376244 --> 1.371871).  Saving model ...
Validation loss decreased (1.371871 --> 1.368087).  Saving model ...
Validation loss decreased (1.368087 --> 1.364294).  Saving model ...
Validation loss decreased (1.364294 --> 1.360373).  Saving model ...
Validation loss decreased (1.360373 --> 1.356237).  Saving model ...
Validation loss decreased (1.356237 --> 1.351994).  Saving model ...
Validation loss decreased (1.351994 --> 1.347748).  Saving model ...
Validation loss decreased (1.347748 --> 1.343376).  Saving model ...
Validation loss decreased (1.343376 --> 1.338780).  Saving model ...
Validation loss decreased (1.338780 --> 1.334073).  Saving model ...
Validation loss decreased (1.334073 --> 1.329771).  Saving model ...
Validation loss decreased (1.329771 --> 1.325275).  Saving model ...
Validation loss decreased (1.325275 --> 1.320242).  Saving model ...
Validation loss decreased (1.320242 --> 1.315079).  Saving model ...
Validation loss decreased (1.315079 --> 1.309995).  Saving model ...
Validation loss decreased (1.309995 --> 1.304329).  Saving model ...
Validation loss decreased (1.304329 --> 1.298629).  Saving model ...
Validation loss decreased (1.298629 --> 1.293270).  Saving model ...
Validation loss decreased (1.293270 --> 1.287129).  Saving model ...
Validation loss decreased (1.287129 --> 1.280147).  Saving model ...
Validation loss decreased (1.280147 --> 1.274420).  Saving model ...
Validation loss decreased (1.274420 --> 1.268287).  Saving model ...
Validation loss decreased (1.268287 --> 1.261896).  Saving model ...
Validation loss decreased (1.261896 --> 1.255563).  Saving model ...
Validation loss decreased (1.255563 --> 1.248097).  Saving model ...
Validation loss decreased (1.248097 --> 1.241392).  Saving model ...
Validation loss decreased (1.241392 --> 1.235237).  Saving model ...
Validation loss decreased (1.235237 --> 1.227727).  Saving model ...
Validation loss decreased (1.227727 --> 1.219502).  Saving model ...
Validation loss decreased (1.219502 --> 1.211713).  Saving model ...
Validation loss decreased (1.211713 --> 1.204367).  Saving model ...
Validation loss decreased (1.204367 --> 1.197589).  Saving model ...
Validation loss decreased (1.197589 --> 1.189546).  Saving model ...
Validation loss decreased (1.189546 --> 1.182802).  Saving model ...
Validation loss decreased (1.182802 --> 1.173619).  Saving model ...
Validation loss decreased (1.173619 --> 1.166199).  Saving model ...
Validation loss decreased (1.166199 --> 1.158429).  Saving model ...
Validation loss decreased (1.158429 --> 1.152457).  Saving model ...
Validation loss decreased (1.152457 --> 1.146060).  Saving model ...
Validation loss decreased (1.146060 --> 1.140892).  Saving model ...
Validation loss decreased (1.140892 --> 1.133583).  Saving model ...
Validation loss decreased (1.133583 --> 1.128735).  Saving model ...
Validation loss decreased (1.128735 --> 1.121944).  Saving model ...
Validation loss decreased (1.121944 --> 1.115228).  Saving model ...
Validation loss decreased (1.115228 --> 1.110933).  Saving model ...
Validation loss decreased (1.110933 --> 1.105256).  Saving model ...
Validation loss decreased (1.105256 --> 1.098445).  Saving model ...
Validation loss decreased (1.098445 --> 1.094998).  Saving model ...
Validation loss decreased (1.094998 --> 1.088889).  Saving model ...
Validation loss decreased (1.088889 --> 1.084974).  Saving model ...
Validation loss decreased (1.084974 --> 1.078644).  Saving model ...
Validation loss decreased (1.078644 --> 1.074422).  Saving model ...
Validation loss decreased (1.074422 --> 1.069242).  Saving model ...
Validation loss decreased (1.069242 --> 1.064479).  Saving model ...
Validation loss decreased (1.064479 --> 1.059468).  Saving model ...
Validation loss decreased (1.059468 --> 1.055800).  Saving model ...
Validation loss decreased (1.055800 --> 1.051748).  Saving model ...
Validation loss decreased (1.051748 --> 1.049245).  Saving model ...
Validation loss decreased (1.049245 --> 1.044744).  Saving model ...
Validation loss decreased (1.044744 --> 1.040865).  Saving model ...
Validation loss decreased (1.040865 --> 1.038289).  Saving model ...
Validation loss decreased (1.038289 --> 1.035624).  Saving model ...
Validation loss decreased (1.035624 --> 1.033017).  Saving model ...
Validation loss decreased (1.033017 --> 1.028073).  Saving model ...
Validation loss decreased (1.028073 --> 1.024107).  Saving model ...
Validation loss decreased (1.024107 --> 1.021095).  Saving model ...
Validation loss decreased (1.021095 --> 1.016801).  Saving model ...
Validation loss decreased (1.016801 --> 1.013954).  Saving model ...
Validation loss decreased (1.013954 --> 1.012119).  Saving model ...
EarlyStopping counter: 1 out of 10.0
Validation loss decreased (1.012119 --> 1.010243).  Saving model ...
Validation loss decreased (1.010243 --> 1.005656).  Saving model ...
Validation loss decreased (1.005656 --> 1.002731).  Saving model ...
Validation loss decreased (1.002731 --> 1.002464).  Saving model ...
Validation loss decreased (1.002464 --> 0.999316).  Saving model ...
Validation loss decreased (0.999316 --> 0.999068).  Saving model ...
Validation loss decreased (0.999068 --> 0.996657).  Saving model ...
Validation loss decreased (0.996657 --> 0.995073).  Saving model ...
Validation loss decreased (0.995073 --> 0.992846).  Saving model ...
Validation loss decreased (0.992846 --> 0.989704).  Saving model ...
Validation loss decreased (0.989704 --> 0.989082).  Saving model ...
Validation loss decreased (0.989082 --> 0.985902).  Saving model ...
Validation loss decreased (0.985902 --> 0.983202).  Saving model ...
Validation loss decreased (0.983202 --> 0.982664).  Saving model ...
Validation loss decreased (0.982664 --> 0.980634).  Saving model ...
Validation loss decreased (0.980634 --> 0.979851).  Saving model ...
Validation loss decreased (0.979851 --> 0.977698).  Saving model ...
Validation loss decreased (0.977698 --> 0.976937).  Saving model ...
Validation loss decreased (0.976937 --> 0.973554).  Saving model ...
Validation loss decreased (0.973554 --> 0.969693).  Saving model ...
EarlyStopping counter: 1 out of 10.0
Validation loss decreased (0.969693 --> 0.968197).  Saving model ...
Validation loss decreased (0.968197 --> 0.967778).  Saving model ...
Validation loss decreased (0.967778 --> 0.964557).  Saving model ...
Validation loss decreased (0.964557 --> 0.963874).  Saving model ...
Validation loss decreased (0.963874 --> 0.962054).  Saving model ...
EarlyStopping counter: 1 out of 10.0
EarlyStopping counter: 2 out of 10.0
Validation loss decreased (0.962054 --> 0.961435).  Saving model ...
Validation loss decreased (0.961435 --> 0.960019).  Saving model ...
Validation loss decreased (0.960019 --> 0.957650).  Saving model ...
Validation loss decreased (0.957650 --> 0.957593).  Saving model ...
Validation loss decreased (0.957593 --> 0.955066).  Saving model ...
EarlyStopping counter: 1 out of 10.0
Validation loss decreased (0.955066 --> 0.953518).  Saving model ...
EarlyStopping counter: 1 out of 10.0
Validation loss decreased (0.953518 --> 0.951722).  Saving model ...
EarlyStopping counter: 1 out of 10.0
Validation loss decreased (0.951722 --> 0.951349).  Saving model ...
EarlyStopping counter: 1 out of 10.0
EarlyStopping counter: 2 out of 10.0
EarlyStopping counter: 3 out of 10.0
EarlyStopping counter: 4 out of 10.0
Validation loss decreased (0.951349 --> 0.948670).  Saving model ...
Validation loss decreased (0.948670 --> 0.947393).  Saving model ...
EarlyStopping counter: 1 out of 10.0
Validation loss decreased (0.947393 --> 0.946883).  Saving model ...
EarlyStopping counter: 1 out of 10.0
Validation loss decreased (0.946883 --> 0.945629).  Saving model ...
Validation loss decreased (0.945629 --> 0.944783).  Saving model ...
EarlyStopping counter: 1 out of 10.0
EarlyStopping counter: 2 out of 10.0
EarlyStopping counter: 3 out of 10.0
Validation loss decreased (0.944783 --> 0.944596).  Saving model ...
EarlyStopping counter: 1 out of 10.0
EarlyStopping counter: 2 out of 10.0
EarlyStopping counter: 3 out of 10.0
Validation loss decreased (0.944596 --> 0.943959).  Saving model ...
EarlyStopping counter: 1 out of 10.0
Validation loss decreased (0.943959 --> 0.943005).  Saving model ...
EarlyStopping counter: 1 out of 10.0
EarlyStopping counter: 2 out of 10.0
Validation loss decreased (0.943005 --> 0.942944).  Saving model ...
EarlyStopping counter: 1 out of 10.0
EarlyStopping counter: 2 out of 10.0
Validation loss decreased (0.942944 --> 0.942275).  Saving model ...
EarlyStopping counter: 1 out of 10.0
EarlyStopping counter: 2 out of 10.0
Validation loss decreased (0.942275 --> 0.941991).  Saving model ...
Validation loss decreased (0.941991 --> 0.941439).  Saving model ...
EarlyStopping counter: 1 out of 10.0
EarlyStopping counter: 2 out of 10.0
EarlyStopping counter: 3 out of 10.0
EarlyStopping counter: 4 out of 10.0
EarlyStopping counter: 5 out of 10.0
EarlyStopping counter: 6 out of 10.0
EarlyStopping counter: 7 out of 10.0
EarlyStopping counter: 8 out of 10.0
EarlyStopping counter: 9 out of 10.0
EarlyStopping counter: 10 out of 10.0
/localscratch/yinan.29019368.0/env/lib/python3.7/site-packages/torch/nn/functional.py:1794: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.
  warnings.warn("nn.functional.tanh is deprecated. Use torch.tanh instead.")
wandb: Waiting for W&B process to finish, PID 119930... (success).
wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: \ 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: | 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: / 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: \ 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: | 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: / 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: \ 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: | 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: / 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb:                                                                                
wandb: Run history:
wandb:     e_F1 ▁▃▃▄▄▅▅▆▆▆▆▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇█████████████
wandb:   e_loss ███▇▇▇▆▆▆▅▅▄▄▃▃▃▃▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:     t_F1 ▁▁▂▂▃▄▄▄▄▅▅▆▆▆▆▆▆▆▇▆▇▇▇▇▇▇▇▇▇▇▇▇▇███████
wandb:   t_loss ███▇▇▇▇▇▆▆▆▅▅▅▅▄▄▄▄▃▃▃▃▃▃▂▃▂▂▂▂▂▂▂▁▂▁▁▁▁
wandb: 
wandb: Run summary:
wandb:     e_F1 61.60326
wandb:   e_loss 0.9447
wandb:     t_F1 69.24999
wandb:   t_loss 0.73235
wandb: 
wandb: Synced 4 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Synced lunar-firebrand-1: https://wandb.ai/yinanazhou/xl_512_bs_8_lr_1e06_es_10_lc_False_nr_False_sr_False_stem_True_lemma_False_repeat_5_fold_2/runs/34069cp3
wandb: Find logs at: ./wandb/run-20220319_095038-34069cp3/logs/debug.log
wandb: 

