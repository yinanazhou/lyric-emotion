Unloading StdEnv/2020

Due to MODULEPATH changes, the following have been reloaded:
  1) mii/1.1.1


The following have been reloaded with a version change:
  1) python/3.8.2 => python/3.7.4

Using base prefix '/cvmfs/soft.computecanada.ca/easybuild/software/2017/Core/python/3.7.4'
New python executable in /localscratch/yinan.29019300.0/env/bin/python
Installing setuptools, pip, wheel...
done.
Ignoring pip: markers 'python_version < "3"' don't match your environment
Looking in links: /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/nix/avx2, /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/nix/generic, /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic
Collecting pip
Installing collected packages: pip
  Found existing installation: pip 19.1.1
    Uninstalling pip-19.1.1:
      Successfully uninstalled pip-19.1.1
Successfully installed pip-21.2.3+computecanada
Looking in links: /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/nix/avx2, /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/nix/generic, /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/keras-2.8.0+computecanada-py2.py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/Keras_Preprocessing-1.1.2+computecanada-py3-none-any.whl
Requirement already satisfied: matplotlib in /cvmfs/soft.computecanada.ca/easybuild/software/2017/Core/scipy-stack/2019a/lib/python3.7/site-packages (from -r requirements.txt (line 3)) (3.0.2)
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/nltk-3.6.5+computecanada-py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/scikit_learn-0.22.1+computecanada-cp37-cp37m-linux_x86_64.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/tensorboard-2.3.0+computecanada-py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/tensorboard_plugin_wit-1.7.0+computecanada-py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/tensorflow_gpu-2.3.0+computecanada-cp37-cp37m-linux_x86_64.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/tensorflow_estimator-2.3.0+computecanada-py2.py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/tokenizers-0.5.2+computecanada-cp37-cp37m-linux_x86_64.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/nix/avx2/torch-1.4.0+computecanada-cp37-cp37m-linux_x86_64.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/torchtext-0.6.0+computecanada-py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/torchvision-0.8.2+computecanada-cp37-cp37m-linux_x86_64.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/transformers-2.5.1+computecanada-py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/urllib3-1.26.7+computecanada-py2.py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/joblib-1.1.0+computecanada-py2.py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/tqdm-4.63.0+computecanada-py2.py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/click-8.0.4+computecanada-py3-none-any.whl
ERROR: Could not find a version that satisfies the requirement regex>=2021.8.3 (from nltk) (from versions: 2018.1.10+computecanada, 2019.11.1+computecanada, 2020.11.13+computecanada)
ERROR: No matching distribution found for regex>=2021.8.3
Looking in links: /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/nix/avx2, /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/nix/generic, /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic
ERROR: Could not find a version that satisfies the requirement numpy==1.20.0+computacanada (from versions: 1.15.0+computecanada, 1.15.2+computecanada, 1.15.4+computecanada, 1.16.0+computecanada, 1.16.2+computecanada, 1.16.3+computecanada, 1.17.4+computecanada, 1.18.1+computecanada, 1.18.4+computecanada, 1.19.1+computecanada, 1.19.2+computecanada, 1.20.2+computecanada)
ERROR: No matching distribution found for numpy==1.20.0+computacanada
Looking in links: /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/nix/avx2, /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/nix/generic, /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/wandb-0.12.5+computecanada-py2.py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/protobuf-3.19.4+computecanada-py2.py3-none-any.whl
Requirement already satisfied: python-dateutil>=2.6.1 in /cvmfs/soft.computecanada.ca/easybuild/software/2017/Core/scipy-stack/2019a/lib/python3.7/site-packages (from wandb) (2.7.5)
Requirement already satisfied: requests<3,>=2.0.0 in /cvmfs/soft.computecanada.ca/easybuild/software/2017/Core/scipy-stack/2019a/lib/python3.7/site-packages (from wandb) (2.21.0)
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/yaspin-2.1.0+computecanada-py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/PyYAML-5.3.1+computecanada-cp37-cp37m-linux_x86_64.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/configparser-5.0.2+computecanada-py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/subprocess32-3.5.4+computecanada-py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/GitPython-3.1.24+computecanada-py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/shortuuid-1.0.1+computecanada-py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/sentry_sdk-1.5.0+computecanada-py2.py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/docker_pycreds-0.4.0+computecanada-py2.py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/promise-2.3+computecanada-py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/pathtools-0.1.2+computecanada-py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/six-1.16.0+computecanada-py2.py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/psutil-5.7.3+computecanada-cp37-cp37m-linux_x86_64.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/click-8.0.4+computecanada-py3-none-any.whl
Requirement already satisfied: importlib-metadata in /cvmfs/soft.computecanada.ca/easybuild/software/2017/Core/scipy-stack/2019a/lib/python3.7/site-packages (from Click!=8.0.0,>=7.0->wandb) (0.8)
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/typing_extensions-4.0.1+computecanada-py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/gitdb-4.0.9+computecanada-py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/smmap-5.0.0+computecanada-py3-none-any.whl
Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /cvmfs/soft.computecanada.ca/easybuild/software/2017/Core/scipy-stack/2019a/lib/python3.7/site-packages (from requests<3,>=2.0.0->wandb) (3.0.4)
Requirement already satisfied: certifi>=2017.4.17 in /cvmfs/soft.computecanada.ca/easybuild/software/2017/Core/scipy-stack/2019a/lib/python3.7/site-packages (from requests<3,>=2.0.0->wandb) (2018.11.29)
Requirement already satisfied: idna<2.9,>=2.5 in /cvmfs/soft.computecanada.ca/easybuild/software/2017/Core/scipy-stack/2019a/lib/python3.7/site-packages (from requests<3,>=2.0.0->wandb) (2.8)
Requirement already satisfied: urllib3<1.25,>=1.21.1 in /cvmfs/soft.computecanada.ca/easybuild/software/2017/Core/scipy-stack/2019a/lib/python3.7/site-packages (from requests<3,>=2.0.0->wandb) (1.24.1)
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/termcolor-1.1.0+computecanada-py3-none-any.whl
Requirement already satisfied: zipp>=0.3.2 in /cvmfs/soft.computecanada.ca/easybuild/software/2017/Core/scipy-stack/2019a/lib/python3.7/site-packages (from importlib-metadata->Click!=8.0.0,>=7.0->wandb) (0.3.3)
Installing collected packages: smmap, typing-extensions, termcolor, six, gitdb, yaspin, subprocess32, shortuuid, sentry-sdk, PyYAML, psutil, protobuf, promise, pathtools, GitPython, docker-pycreds, configparser, Click, wandb
  Attempting uninstall: six
    Found existing installation: six 1.12.0
    Not uninstalling six at /cvmfs/soft.computecanada.ca/easybuild/software/2017/Core/scipy-stack/2019a/lib/python3.7/site-packages, outside environment /localscratch/yinan.29019300.0/env
    Can't uninstall 'six'. No files were found to uninstall.
Successfully installed Click-8.0.4+computecanada GitPython-3.1.24+computecanada PyYAML-5.3.1+computecanada configparser-5.0.2+computecanada docker-pycreds-0.4.0+computecanada gitdb-4.0.9+computecanada pathtools-0.1.2+computecanada promise-2.3+computecanada protobuf-3.19.4+computecanada psutil-5.7.3+computecanada sentry-sdk-1.5.0+computecanada shortuuid-1.0.1+computecanada six-1.16.0+computecanada smmap-5.0.0+computecanada subprocess32-3.5.4+computecanada termcolor-1.1.0+computecanada typing-extensions-4.0.1+computecanada wandb-0.12.5+computecanada yaspin-2.1.0+computecanada
Looking in links: /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/nix/avx2, /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/nix/generic, /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic
ERROR: Could not find a version that satisfies the requirement sagemaker (from versions: none)
ERROR: No matching distribution found for sagemaker
Looking in links: /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/nix/avx2, /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/nix/generic, /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/torch-1.9.1+computecanada-cp37-cp37m-linux_x86_64.whl
Requirement already satisfied: typing-extensions in /localscratch/yinan.29019300.0/env/lib/python3.7/site-packages (from torch) (4.0.1+computecanada)
Installing collected packages: torch
Successfully installed torch-1.9.1+computecanada
Looking in links: /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/nix/avx2, /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/nix/generic, /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/transformers-2.5.1+computecanada-py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/sacremoses-0.0.46+computecanada-py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/tokenizers-0.5.2+computecanada-cp37-cp37m-linux_x86_64.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/tqdm-4.63.0+computecanada-py2.py3-none-any.whl
Requirement already satisfied: requests in /cvmfs/soft.computecanada.ca/easybuild/software/2017/Core/scipy-stack/2019a/lib/python3.7/site-packages (from transformers==2.5.1+computecanada) (2.21.0)
Requirement already satisfied: numpy in /cvmfs/soft.computecanada.ca/easybuild/software/2017/Core/scipy-stack/2019a/lib/python3.7/site-packages (from transformers==2.5.1+computecanada) (1.16.0)
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/regex-2020.11.13+computecanada-cp37-cp37m-linux_x86_64.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/boto3-1.21.14+computecanada-py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/filelock-3.4.2+computecanada-py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/sentencepiece-0.1.91+computecanada-cp37-cp37m-linux_x86_64.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/s3transfer-0.5.1+computecanada-py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/botocore-1.24.14+computecanada-py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/jmespath-0.10.0+computecanada-py2.py3-none-any.whl
Requirement already satisfied: python-dateutil<3.0.0,>=2.1 in /cvmfs/soft.computecanada.ca/easybuild/software/2017/Core/scipy-stack/2019a/lib/python3.7/site-packages (from botocore<1.25.0,>=1.24.14->boto3->transformers==2.5.1+computecanada) (2.7.5)
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/urllib3-1.26.8+computecanada-py2.py3-none-any.whl
Requirement already satisfied: six>=1.5 in /localscratch/yinan.29019300.0/env/lib/python3.7/site-packages (from python-dateutil<3.0.0,>=2.1->botocore<1.25.0,>=1.24.14->boto3->transformers==2.5.1+computecanada) (1.16.0+computecanada)
Requirement already satisfied: idna<2.9,>=2.5 in /cvmfs/soft.computecanada.ca/easybuild/software/2017/Core/scipy-stack/2019a/lib/python3.7/site-packages (from requests->transformers==2.5.1+computecanada) (2.8)
Requirement already satisfied: certifi>=2017.4.17 in /cvmfs/soft.computecanada.ca/easybuild/software/2017/Core/scipy-stack/2019a/lib/python3.7/site-packages (from requests->transformers==2.5.1+computecanada) (2018.11.29)
Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /cvmfs/soft.computecanada.ca/easybuild/software/2017/Core/scipy-stack/2019a/lib/python3.7/site-packages (from requests->transformers==2.5.1+computecanada) (3.0.4)
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/requests-2.27.1+computecanada-py2.py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/charset_normalizer-2.0.12+computecanada-py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/joblib-1.1.0+computecanada-py2.py3-none-any.whl
Requirement already satisfied: click in /localscratch/yinan.29019300.0/env/lib/python3.7/site-packages (from sacremoses->transformers==2.5.1+computecanada) (8.0.4+computecanada)
Requirement already satisfied: importlib-metadata in /cvmfs/soft.computecanada.ca/easybuild/software/2017/Core/scipy-stack/2019a/lib/python3.7/site-packages (from click->sacremoses->transformers==2.5.1+computecanada) (0.8)
Requirement already satisfied: zipp>=0.3.2 in /cvmfs/soft.computecanada.ca/easybuild/software/2017/Core/scipy-stack/2019a/lib/python3.7/site-packages (from importlib-metadata->click->sacremoses->transformers==2.5.1+computecanada) (0.3.3)
Installing collected packages: urllib3, jmespath, botocore, tqdm, s3transfer, regex, joblib, charset-normalizer, tokenizers, sentencepiece, sacremoses, requests, filelock, boto3, transformers
  Attempting uninstall: urllib3
    Found existing installation: urllib3 1.24.1
    Not uninstalling urllib3 at /cvmfs/soft.computecanada.ca/easybuild/software/2017/Core/scipy-stack/2019a/lib/python3.7/site-packages, outside environment /localscratch/yinan.29019300.0/env
    Can't uninstall 'urllib3'. No files were found to uninstall.
  Attempting uninstall: requests
    Found existing installation: requests 2.21.0
    Not uninstalling requests at /cvmfs/soft.computecanada.ca/easybuild/software/2017/Core/scipy-stack/2019a/lib/python3.7/site-packages, outside environment /localscratch/yinan.29019300.0/env
    Can't uninstall 'requests'. No files were found to uninstall.
Successfully installed boto3-1.21.14+computecanada botocore-1.24.14+computecanada charset-normalizer-2.0.12+computecanada filelock-3.4.2+computecanada jmespath-0.10.0+computecanada joblib-1.1.0+computecanada regex-2020.11.13+computecanada requests-2.27.1+computecanada s3transfer-0.5.1+computecanada sacremoses-0.0.46+computecanada sentencepiece-0.1.91+computecanada tokenizers-0.5.2+computecanada tqdm-4.63.0+computecanada transformers-2.5.1+computecanada urllib3-1.26.8+computecanada
Looking in links: /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/nix/avx2, /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/nix/generic, /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/tensorflow_gpu-2.3.0+computecanada-cp37-cp37m-linux_x86_64.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/Keras_Preprocessing-1.1.2+computecanada-py3-none-any.whl
Requirement already satisfied: wheel>=0.26 in /localscratch/yinan.29019300.0/env/lib/python3.7/site-packages (from tensorflow_gpu==2.3.0+computecanada) (0.33.4)
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/opt_einsum-3.3.0+computecanada-py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/nix/generic/scipy-1.4.1+computecanada-cp37-cp37m-linux_x86_64.whl
Requirement already satisfied: numpy<1.19.0,>=1.16.0 in /cvmfs/soft.computecanada.ca/easybuild/software/2017/Core/scipy-stack/2019a/lib/python3.7/site-packages (from tensorflow_gpu==2.3.0+computecanada) (1.16.0)
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/wrapt-1.11.2+computecanada-cp37-cp37m-linux_x86_64.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/astunparse-1.6.3+computecanada-py2.py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/tensorflow_estimator-2.3.0+computecanada-py2.py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/nix/avx2/h5py-2.10.0+computecanada-cp37-cp37m-linux_x86_64.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/absl_py-1.0.0+computecanada-py3-none-any.whl
Requirement already satisfied: protobuf>=3.9.2 in /localscratch/yinan.29019300.0/env/lib/python3.7/site-packages (from tensorflow_gpu==2.3.0+computecanada) (3.19.4+computecanada)
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/tensorboard-2.8.0+computecanada-py3-none-any.whl
Requirement already satisfied: six>=1.12.0 in /localscratch/yinan.29019300.0/env/lib/python3.7/site-packages (from tensorflow_gpu==2.3.0+computecanada) (1.16.0+computecanada)
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/grpcio-1.38.0+computecanada-cp37-cp37m-linux_x86_64.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/google_pasta-0.2.0+computecanada-py3-none-any.whl
Requirement already satisfied: termcolor>=1.1.0 in /localscratch/yinan.29019300.0/env/lib/python3.7/site-packages (from tensorflow_gpu==2.3.0+computecanada) (1.1.0+computecanada)
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/gast-0.3.3+computecanada-py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/google_auth_oauthlib-0.4.6+computecanada-py2.py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/tensorboard_data_server-0.6.1+computecanada-py3-none-linux_x86_64.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/google_auth-2.3.3+computecanada-py2.py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/Markdown-3.3.6+computecanada-py3-none-any.whl
Requirement already satisfied: requests<3,>=2.21.0 in /localscratch/yinan.29019300.0/env/lib/python3.7/site-packages (from tensorboard<3,>=2.3.0->tensorflow_gpu==2.3.0+computecanada) (2.27.1+computecanada)
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/Werkzeug-2.0.3+computecanada-py3-none-any.whl
Requirement already satisfied: setuptools>=41.0.0 in /localscratch/yinan.29019300.0/env/lib/python3.7/site-packages (from tensorboard<3,>=2.3.0->tensorflow_gpu==2.3.0+computecanada) (41.0.1)
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/tensorboard_plugin_wit-1.8.0+computecanada-py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/cachetools-4.2.4+computecanada-py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/rsa-4.8+computecanada-py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/pyasn1_modules-0.2.8+computecanada-py2.py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/requests_oauthlib-1.3.0+computecanada-py2.py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/importlib_metadata-4.10.1+computecanada-py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/zipp-3.7.0+computecanada-py3-none-any.whl
Requirement already satisfied: typing-extensions>=3.6.4 in /localscratch/yinan.29019300.0/env/lib/python3.7/site-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard<3,>=2.3.0->tensorflow_gpu==2.3.0+computecanada) (4.0.1+computecanada)
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/pyasn1-0.4.8+computecanada-py2.py3-none-any.whl
Requirement already satisfied: idna<4,>=2.5 in /cvmfs/soft.computecanada.ca/easybuild/software/2017/Core/scipy-stack/2019a/lib/python3.7/site-packages (from requests<3,>=2.21.0->tensorboard<3,>=2.3.0->tensorflow_gpu==2.3.0+computecanada) (2.8)
Requirement already satisfied: certifi>=2017.4.17 in /cvmfs/soft.computecanada.ca/easybuild/software/2017/Core/scipy-stack/2019a/lib/python3.7/site-packages (from requests<3,>=2.21.0->tensorboard<3,>=2.3.0->tensorflow_gpu==2.3.0+computecanada) (2018.11.29)
Requirement already satisfied: urllib3<1.27,>=1.21.1 in /localscratch/yinan.29019300.0/env/lib/python3.7/site-packages (from requests<3,>=2.21.0->tensorboard<3,>=2.3.0->tensorflow_gpu==2.3.0+computecanada) (1.26.8+computecanada)
Requirement already satisfied: charset-normalizer~=2.0.0 in /localscratch/yinan.29019300.0/env/lib/python3.7/site-packages (from requests<3,>=2.21.0->tensorboard<3,>=2.3.0->tensorflow_gpu==2.3.0+computecanada) (2.0.12+computecanada)
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/oauthlib-3.1.1+computecanada-py2.py3-none-any.whl
Installing collected packages: pyasn1, zipp, rsa, pyasn1-modules, oauthlib, cachetools, requests-oauthlib, importlib-metadata, google-auth, werkzeug, tensorboard-plugin-wit, tensorboard-data-server, markdown, grpcio, google-auth-oauthlib, absl-py, wrapt, tensorflow-estimator, tensorboard, scipy, opt-einsum, keras-preprocessing, h5py, google-pasta, gast, astunparse, tensorflow-gpu
  Attempting uninstall: pyasn1
    Found existing installation: pyasn1 0.4.3
    Not uninstalling pyasn1 at /cvmfs/soft.computecanada.ca/easybuild/software/2017/Core/scipy-stack/2019a/lib/python3.7/site-packages, outside environment /localscratch/yinan.29019300.0/env
    Can't uninstall 'pyasn1'. No files were found to uninstall.
  Attempting uninstall: zipp
    Found existing installation: zipp 0.3.3
    Not uninstalling zipp at /cvmfs/soft.computecanada.ca/easybuild/software/2017/Core/scipy-stack/2019a/lib/python3.7/site-packages, outside environment /localscratch/yinan.29019300.0/env
    Can't uninstall 'zipp'. No files were found to uninstall.
  Attempting uninstall: importlib-metadata
    Found existing installation: importlib-metadata 0.8
    Not uninstalling importlib-metadata at /cvmfs/soft.computecanada.ca/easybuild/software/2017/Core/scipy-stack/2019a/lib/python3.7/site-packages, outside environment /localscratch/yinan.29019300.0/env
    Can't uninstall 'importlib-metadata'. No files were found to uninstall.
  Attempting uninstall: scipy
    Found existing installation: scipy 1.2.0
    Not uninstalling scipy at /cvmfs/soft.computecanada.ca/easybuild/software/2017/Core/scipy-stack/2019a/lib/python3.7/site-packages, outside environment /localscratch/yinan.29019300.0/env
    Can't uninstall 'scipy'. No files were found to uninstall.
Successfully installed absl-py-1.0.0+computecanada astunparse-1.6.3+computecanada cachetools-4.2.4+computecanada gast-0.3.3+computecanada google-auth-2.3.3+computecanada google-auth-oauthlib-0.4.6+computecanada google-pasta-0.2.0+computecanada grpcio-1.38.0+computecanada h5py-2.10.0+computecanada importlib-metadata-4.10.1+computecanada keras-preprocessing-1.1.2+computecanada markdown-3.3.6+computecanada oauthlib-3.1.1+computecanada opt-einsum-3.3.0+computecanada pyasn1-0.4.8+computecanada pyasn1-modules-0.2.8+computecanada requests-oauthlib-1.3.0+computecanada rsa-4.8+computecanada scipy-1.4.1+computecanada tensorboard-2.8.0+computecanada tensorboard-data-server-0.6.1+computecanada tensorboard-plugin-wit-1.8.0+computecanada tensorflow-estimator-2.3.0+computecanada tensorflow-gpu-2.3.0+computecanada werkzeug-2.0.3+computecanada wrapt-1.11.2+computecanada zipp-3.7.0+computecanada
Looking in links: /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/nix/avx2, /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/nix/generic, /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/keras-2.8.0+computecanada-py2.py3-none-any.whl
Installing collected packages: Keras
Successfully installed Keras-2.8.0+computecanada
Looking in links: /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/nix/avx2, /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/nix/generic, /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/urllib3-1.26.7+computecanada-py2.py3-none-any.whl
Installing collected packages: urllib3
  Attempting uninstall: urllib3
    Found existing installation: urllib3 1.26.8+computecanada
    Uninstalling urllib3-1.26.8+computecanada:
      Successfully uninstalled urllib3-1.26.8+computecanada
Successfully installed urllib3-1.26.7+computecanada
Looking in links: /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/nix/avx2, /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/nix/generic, /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/nltk-3.7+computecanada-py3-none-any.whl
Requirement already satisfied: click in /localscratch/yinan.29019300.0/env/lib/python3.7/site-packages (from nltk) (8.0.4+computecanada)
Requirement already satisfied: tqdm in /localscratch/yinan.29019300.0/env/lib/python3.7/site-packages (from nltk) (4.63.0+computecanada)
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/nltk-3.6.5+computecanada-py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/nltk-3.6.3+computecanada-py3-none-any.whl
Requirement already satisfied: regex in /localscratch/yinan.29019300.0/env/lib/python3.7/site-packages (from nltk) (2020.11.13+computecanada)
Requirement already satisfied: joblib in /localscratch/yinan.29019300.0/env/lib/python3.7/site-packages (from nltk) (1.1.0+computecanada)
Requirement already satisfied: importlib-metadata in /localscratch/yinan.29019300.0/env/lib/python3.7/site-packages (from click->nltk) (4.10.1+computecanada)
Requirement already satisfied: zipp>=0.5 in /localscratch/yinan.29019300.0/env/lib/python3.7/site-packages (from importlib-metadata->click->nltk) (3.7.0+computecanada)
Requirement already satisfied: typing-extensions>=3.6.4 in /localscratch/yinan.29019300.0/env/lib/python3.7/site-packages (from importlib-metadata->click->nltk) (4.0.1+computecanada)
Installing collected packages: nltk
Successfully installed nltk-3.6.3+computecanada
Looking in links: /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/nix/avx2, /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/nix/generic, /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/scikit_learn-0.22.1+computecanada-cp37-cp37m-linux_x86_64.whl
Requirement already satisfied: numpy>=1.11.0 in /cvmfs/soft.computecanada.ca/easybuild/software/2017/Core/scipy-stack/2019a/lib/python3.7/site-packages (from scikit-learn==0.22.1) (1.16.0)
Requirement already satisfied: joblib>=0.11 in /localscratch/yinan.29019300.0/env/lib/python3.7/site-packages (from scikit-learn==0.22.1) (1.1.0+computecanada)
Requirement already satisfied: scipy>=0.17.0 in /localscratch/yinan.29019300.0/env/lib/python3.7/site-packages (from scikit-learn==0.22.1) (1.4.1+computecanada)
Installing collected packages: scikit-learn
Successfully installed scikit-learn-0.22.1+computecanada
Looking in links: /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/nix/avx2, /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/nix/generic, /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic
Requirement already satisfied: tokenizers==0.5.2 in /localscratch/yinan.29019300.0/env/lib/python3.7/site-packages (0.5.2+computecanada)
wandb: Appending key for api.wandb.ai to your netrc file: /home/yinan/.netrc
Starting Task
2022-03-18 18:52:22.342083: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1
[nltk_data] Downloading package stopwords to /home/yinan/nltk_data...
[nltk_data]   Package stopwords is already up-to-date!
[nltk_data] Downloading package wordnet to /home/yinan/nltk_data...
[nltk_data]   Package wordnet is already up-to-date!
wandb: Currently logged in as: yinanazhou (use `wandb login --relogin` to force relogin)
wandb: wandb version 0.12.11 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
2022-03-18 18:52:33.417132: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1
wandb: Tracking run with wandb version 0.12.5
wandb: Syncing run lilac-feather-2
wandb: â­ï¸ View project at https://wandb.ai/yinanazhou/xl_512_bs_8_lr_1e06_es_10_lc_False_nr_True_sr_False_stem_False_lemma_False_repeat_1_fold_1
wandb: ðŸš€ View run at https://wandb.ai/yinanazhou/xl_512_bs_8_lr_1e06_es_10_lc_False_nr_True_sr_False_stem_False_lemma_False_repeat_1_fold_1/runs/31b9nuzq
wandb: Run data is saved locally in /project/6002780/yinan/Thesis_MER_Lyrics/lyric-emotion/wandb/run-20220318_185231-31b9nuzq
wandb: Run `wandb offline` to turn off syncing.

Validation loss decreased (inf --> 1.433229).  Saving model ...
Validation loss decreased (1.433229 --> 1.413110).  Saving model ...
Validation loss decreased (1.413110 --> 1.396176).  Saving model ...
Validation loss decreased (1.396176 --> 1.382279).  Saving model ...
Validation loss decreased (1.382279 --> 1.371598).  Saving model ...
Validation loss decreased (1.371598 --> 1.362808).  Saving model ...
Validation loss decreased (1.362808 --> 1.355502).  Saving model ...
Validation loss decreased (1.355502 --> 1.348385).  Saving model ...
Validation loss decreased (1.348385 --> 1.342372).  Saving model ...
Validation loss decreased (1.342372 --> 1.335795).  Saving model ...
Validation loss decreased (1.335795 --> 1.329027).  Saving model ...
Validation loss decreased (1.329027 --> 1.322893).  Saving model ...
Validation loss decreased (1.322893 --> 1.315562).  Saving model ...
Validation loss decreased (1.315562 --> 1.308531).  Saving model ...
Validation loss decreased (1.308531 --> 1.300847).  Saving model ...
Validation loss decreased (1.300847 --> 1.293341).  Saving model ...
Validation loss decreased (1.293341 --> 1.286067).  Saving model ...
Validation loss decreased (1.286067 --> 1.280456).  Saving model ...
Validation loss decreased (1.280456 --> 1.272807).  Saving model ...
Validation loss decreased (1.272807 --> 1.265423).  Saving model ...
Validation loss decreased (1.265423 --> 1.258489).  Saving model ...
Validation loss decreased (1.258489 --> 1.252704).  Saving model ...
Validation loss decreased (1.252704 --> 1.248509).  Saving model ...
Validation loss decreased (1.248509 --> 1.243048).  Saving model ...
Validation loss decreased (1.243048 --> 1.237602).  Saving model ...
Validation loss decreased (1.237602 --> 1.232497).  Saving model ...
Validation loss decreased (1.232497 --> 1.228624).  Saving model ...
Validation loss decreased (1.228624 --> 1.222904).  Saving model ...
Validation loss decreased (1.222904 --> 1.217716).  Saving model ...
Validation loss decreased (1.217716 --> 1.213962).  Saving model ...
Validation loss decreased (1.213962 --> 1.208696).  Saving model ...
Validation loss decreased (1.208696 --> 1.204166).  Saving model ...
Validation loss decreased (1.204166 --> 1.201181).  Saving model ...
Validation loss decreased (1.201181 --> 1.196231).  Saving model ...
Validation loss decreased (1.196231 --> 1.192928).  Saving model ...
Validation loss decreased (1.192928 --> 1.188185).  Saving model ...
Validation loss decreased (1.188185 --> 1.186707).  Saving model ...
Validation loss decreased (1.186707 --> 1.180769).  Saving model ...
Validation loss decreased (1.180769 --> 1.176273).  Saving model ...
Validation loss decreased (1.176273 --> 1.174058).  Saving model ...
Validation loss decreased (1.174058 --> 1.169737).  Saving model ...
Validation loss decreased (1.169737 --> 1.164110).  Saving model ...
Validation loss decreased (1.164110 --> 1.161612).  Saving model ...
Validation loss decreased (1.161612 --> 1.159056).  Saving model ...
Validation loss decreased (1.159056 --> 1.154592).  Saving model ...
Validation loss decreased (1.154592 --> 1.151696).  Saving model ...
Validation loss decreased (1.151696 --> 1.149983).  Saving model ...
Validation loss decreased (1.149983 --> 1.144778).  Saving model ...
Validation loss decreased (1.144778 --> 1.138887).  Saving model ...
Validation loss decreased (1.138887 --> 1.135738).  Saving model ...
Validation loss decreased (1.135738 --> 1.130622).  Saving model ...
Validation loss decreased (1.130622 --> 1.128961).  Saving model ...
Validation loss decreased (1.128961 --> 1.126676).  Saving model ...
Validation loss decreased (1.126676 --> 1.123249).  Saving model ...
Validation loss decreased (1.123249 --> 1.122328).  Saving model ...
Validation loss decreased (1.122328 --> 1.118860).  Saving model ...
Validation loss decreased (1.118860 --> 1.116236).  Saving model ...
Validation loss decreased (1.116236 --> 1.112946).  Saving model ...
Validation loss decreased (1.112946 --> 1.108449).  Saving model ...
Validation loss decreased (1.108449 --> 1.106706).  Saving model ...
Validation loss decreased (1.106706 --> 1.106023).  Saving model ...
Validation loss decreased (1.106023 --> 1.102541).  Saving model ...
Validation loss decreased (1.102541 --> 1.099072).  Saving model ...
Validation loss decreased (1.099072 --> 1.096845).  Saving model ...
Validation loss decreased (1.096845 --> 1.096474).  Saving model ...
Validation loss decreased (1.096474 --> 1.091677).  Saving model ...
Validation loss decreased (1.091677 --> 1.089817).  Saving model ...
Validation loss decreased (1.089817 --> 1.089247).  Saving model ...
Validation loss decreased (1.089247 --> 1.086168).  Saving model ...
EarlyStopping counter: 1 out of 10.0
Validation loss decreased (1.086168 --> 1.083329).  Saving model ...
Validation loss decreased (1.083329 --> 1.076753).  Saving model ...
Validation loss decreased (1.076753 --> 1.075939).  Saving model ...
Validation loss decreased (1.075939 --> 1.073958).  Saving model ...
Validation loss decreased (1.073958 --> 1.072206).  Saving model ...
Validation loss decreased (1.072206 --> 1.071090).  Saving model ...
Validation loss decreased (1.071090 --> 1.066725).  Saving model ...
Validation loss decreased (1.066725 --> 1.065381).  Saving model ...
EarlyStopping counter: 1 out of 10.0
Validation loss decreased (1.065381 --> 1.061086).  Saving model ...
EarlyStopping counter: 1 out of 10.0
EarlyStopping counter: 2 out of 10.0
Validation loss decreased (1.061086 --> 1.060310).  Saving model ...
Validation loss decreased (1.060310 --> 1.058683).  Saving model ...
Validation loss decreased (1.058683 --> 1.051627).  Saving model ...
Validation loss decreased (1.051627 --> 1.050971).  Saving model ...
Validation loss decreased (1.050971 --> 1.050159).  Saving model ...
EarlyStopping counter: 1 out of 10.0
EarlyStopping counter: 2 out of 10.0
EarlyStopping counter: 3 out of 10.0
Validation loss decreased (1.050159 --> 1.049028).  Saving model ...
Validation loss decreased (1.049028 --> 1.047804).  Saving model ...
Validation loss decreased (1.047804 --> 1.043642).  Saving model ...
EarlyStopping counter: 1 out of 10.0
EarlyStopping counter: 2 out of 10.0
Validation loss decreased (1.043642 --> 1.043066).  Saving model ...
EarlyStopping counter: 1 out of 10.0
Validation loss decreased (1.043066 --> 1.040295).  Saving model ...
EarlyStopping counter: 1 out of 10.0
EarlyStopping counter: 2 out of 10.0
Validation loss decreased (1.040295 --> 1.039640).  Saving model ...
Validation loss decreased (1.039640 --> 1.039431).  Saving model ...
Validation loss decreased (1.039431 --> 1.036350).  Saving model ...
Validation loss decreased (1.036350 --> 1.034026).  Saving model ...
EarlyStopping counter: 1 out of 10.0
EarlyStopping counter: 2 out of 10.0
Validation loss decreased (1.034026 --> 1.032194).  Saving model ...
Validation loss decreased (1.032194 --> 1.031806).  Saving model ...
Validation loss decreased (1.031806 --> 1.030418).  Saving model ...
Validation loss decreased (1.030418 --> 1.028683).  Saving model ...
EarlyStopping counter: 1 out of 10.0
EarlyStopping counter: 2 out of 10.0
EarlyStopping counter: 3 out of 10.0
EarlyStopping counter: 4 out of 10.0
EarlyStopping counter: 5 out of 10.0
Validation loss decreased (1.028683 --> 1.028360).  Saving model ...
Validation loss decreased (1.028360 --> 1.027044).  Saving model ...
Validation loss decreased (1.027044 --> 1.025678).  Saving model ...
EarlyStopping counter: 1 out of 10.0
Validation loss decreased (1.025678 --> 1.023353).  Saving model ...
Validation loss decreased (1.023353 --> 1.023192).  Saving model ...
EarlyStopping counter: 1 out of 10.0
Validation loss decreased (1.023192 --> 1.022712).  Saving model ...
EarlyStopping counter: 1 out of 10.0
Validation loss decreased (1.022712 --> 1.021552).  Saving model ...
EarlyStopping counter: 1 out of 10.0
EarlyStopping counter: 2 out of 10.0
EarlyStopping counter: 3 out of 10.0
EarlyStopping counter: 4 out of 10.0
Validation loss decreased (1.021552 --> 1.017918).  Saving model ...
EarlyStopping counter: 1 out of 10.0
EarlyStopping counter: 2 out of 10.0
EarlyStopping counter: 3 out of 10.0
EarlyStopping counter: 4 out of 10.0
EarlyStopping counter: 5 out of 10.0
EarlyStopping counter: 6 out of 10.0
EarlyStopping counter: 7 out of 10.0
EarlyStopping counter: 8 out of 10.0
EarlyStopping counter: 9 out of 10.0
EarlyStopping counter: 10 out of 10.0
/localscratch/yinan.29019300.0/env/lib/python3.7/site-packages/torch/nn/functional.py:1794: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.
  warnings.warn("nn.functional.tanh is deprecated. Use torch.tanh instead.")
/localscratch/yinan.29019300.0/env/lib/python3.7/site-packages/transformers/optimization.py:155: UserWarning: This overload of add_ is deprecated:
	add_(Number alpha, Tensor other)
Consider using one of the following signatures instead:
	add_(Tensor other, *, Number alpha) (Triggered internally at  ../torch/csrc/utils/python_arg_parser.cpp:1025.)
  exp_avg.mul_(beta1).add_(1.0 - beta1, grad)
wandb: Waiting for W&B process to finish, PID 26553... (success).
wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: \ 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: | 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: / 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: \ 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: | 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: / 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: \ 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: | 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: / 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb:                                                                                
wandb: Run history:
wandb:     e_F1 â–â–‚â–ƒâ–„â–…â–…â–…â–…â–†â–†â–†â–†â–†â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ
wandb:   e_loss â–ˆâ–‡â–‡â–†â–†â–†â–…â–…â–„â–„â–„â–„â–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:     t_F1 â–â–â–‚â–ƒâ–„â–ƒâ–„â–„â–…â–…â–…â–…â–…â–…â–†â–†â–†â–†â–†â–†â–†â–†â–‡â–†â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–ˆâ–ˆâ–‡â–ˆâ–‡â–ˆâ–ˆâ–ˆâ–ˆ
wandb:   t_loss â–ˆâ–ˆâ–‡â–‡â–‡â–†â–†â–†â–…â–…â–…â–…â–„â–„â–„â–„â–„â–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–‚â–ƒâ–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–â–â–â–â–
wandb: 
wandb: Run summary:
wandb:     e_F1 56.88515
wandb:   e_loss 1.01868
wandb:     t_F1 72.08359
wandb:   t_loss 0.7407
wandb: 
wandb: Synced 4 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Synced lilac-feather-2: https://wandb.ai/yinanazhou/xl_512_bs_8_lr_1e06_es_10_lc_False_nr_True_sr_False_stem_False_lemma_False_repeat_1_fold_1/runs/31b9nuzq
wandb: Find logs at: ./wandb/run-20220318_185231-31b9nuzq/logs/debug.log
wandb: 

wandb: wandb version 0.12.11 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
2022-03-18 20:24:44.462179: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1
wandb: Tracking run with wandb version 0.12.5
wandb: Syncing run fallen-armadillo-2
wandb: â­ï¸ View project at https://wandb.ai/yinanazhou/xl_512_bs_8_lr_1e06_es_10_lc_False_nr_True_sr_False_stem_False_lemma_False_repeat_1_fold_2
wandb: ðŸš€ View run at https://wandb.ai/yinanazhou/xl_512_bs_8_lr_1e06_es_10_lc_False_nr_True_sr_False_stem_False_lemma_False_repeat_1_fold_2/runs/25f1t9r8
wandb: Run data is saved locally in /project/6002780/yinan/Thesis_MER_Lyrics/lyric-emotion/wandb/run-20220318_202441-25f1t9r8
wandb: Run `wandb offline` to turn off syncing.

Validation loss decreased (inf --> 1.407338).  Saving model ...
Validation loss decreased (1.407338 --> 1.395401).  Saving model ...
Validation loss decreased (1.395401 --> 1.386598).  Saving model ...
Validation loss decreased (1.386598 --> 1.380233).  Saving model ...
Validation loss decreased (1.380233 --> 1.374625).  Saving model ...
Validation loss decreased (1.374625 --> 1.369726).  Saving model ...
Validation loss decreased (1.369726 --> 1.364674).  Saving model ...
Validation loss decreased (1.364674 --> 1.360196).  Saving model ...
Validation loss decreased (1.360196 --> 1.355692).  Saving model ...
Validation loss decreased (1.355692 --> 1.351383).  Saving model ...
Validation loss decreased (1.351383 --> 1.346939).  Saving model ...
Validation loss decreased (1.346939 --> 1.342263).  Saving model ...
Validation loss decreased (1.342263 --> 1.337563).  Saving model ...
Validation loss decreased (1.337563 --> 1.333506).  Saving model ...
Validation loss decreased (1.333506 --> 1.328452).  Saving model ...
Validation loss decreased (1.328452 --> 1.323720).  Saving model ...
Validation loss decreased (1.323720 --> 1.318751).  Saving model ...
Validation loss decreased (1.318751 --> 1.313282).  Saving model ...
Validation loss decreased (1.313282 --> 1.307495).  Saving model ...
Validation loss decreased (1.307495 --> 1.301797).  Saving model ...
Validation loss decreased (1.301797 --> 1.296393).  Saving model ...
Validation loss decreased (1.296393 --> 1.291182).  Saving model ...
Validation loss decreased (1.291182 --> 1.285158).  Saving model ...
Validation loss decreased (1.285158 --> 1.278866).  Saving model ...
Validation loss decreased (1.278866 --> 1.271365).  Saving model ...
Validation loss decreased (1.271365 --> 1.264019).  Saving model ...
Validation loss decreased (1.264019 --> 1.256478).  Saving model ...
Validation loss decreased (1.256478 --> 1.249580).  Saving model ...
Validation loss decreased (1.249580 --> 1.241365).  Saving model ...
Validation loss decreased (1.241365 --> 1.234286).  Saving model ...
Validation loss decreased (1.234286 --> 1.225493).  Saving model ...
Validation loss decreased (1.225493 --> 1.216656).  Saving model ...
Validation loss decreased (1.216656 --> 1.208108).  Saving model ...
Validation loss decreased (1.208108 --> 1.198590).  Saving model ...
Validation loss decreased (1.198590 --> 1.190418).  Saving model ...
Validation loss decreased (1.190418 --> 1.181347).  Saving model ...
Validation loss decreased (1.181347 --> 1.172739).  Saving model ...
Validation loss decreased (1.172739 --> 1.164046).  Saving model ...
Validation loss decreased (1.164046 --> 1.155968).  Saving model ...
Validation loss decreased (1.155968 --> 1.149236).  Saving model ...
Validation loss decreased (1.149236 --> 1.142624).  Saving model ...
Validation loss decreased (1.142624 --> 1.135528).  Saving model ...
Validation loss decreased (1.135528 --> 1.129763).  Saving model ...
Validation loss decreased (1.129763 --> 1.124146).  Saving model ...
Validation loss decreased (1.124146 --> 1.117712).  Saving model ...
Validation loss decreased (1.117712 --> 1.111196).  Saving model ...
Validation loss decreased (1.111196 --> 1.105195).  Saving model ...
Validation loss decreased (1.105195 --> 1.099835).  Saving model ...
Validation loss decreased (1.099835 --> 1.094342).  Saving model ...
Validation loss decreased (1.094342 --> 1.089264).  Saving model ...
Validation loss decreased (1.089264 --> 1.083865).  Saving model ...
Validation loss decreased (1.083865 --> 1.079100).  Saving model ...
Validation loss decreased (1.079100 --> 1.074934).  Saving model ...
Validation loss decreased (1.074934 --> 1.071155).  Saving model ...
Validation loss decreased (1.071155 --> 1.064823).  Saving model ...
Validation loss decreased (1.064823 --> 1.060189).  Saving model ...
Validation loss decreased (1.060189 --> 1.055097).  Saving model ...
Validation loss decreased (1.055097 --> 1.051576).  Saving model ...
Validation loss decreased (1.051576 --> 1.047997).  Saving model ...
Validation loss decreased (1.047997 --> 1.044064).  Saving model ...
Validation loss decreased (1.044064 --> 1.040705).  Saving model ...
Validation loss decreased (1.040705 --> 1.037124).  Saving model ...
Validation loss decreased (1.037124 --> 1.033180).  Saving model ...
Validation loss decreased (1.033180 --> 1.028150).  Saving model ...
Validation loss decreased (1.028150 --> 1.024402).  Saving model ...
Validation loss decreased (1.024402 --> 1.020630).  Saving model ...
Validation loss decreased (1.020630 --> 1.017249).  Saving model ...
Validation loss decreased (1.017249 --> 1.013398).  Saving model ...
Validation loss decreased (1.013398 --> 1.007677).  Saving model ...
Validation loss decreased (1.007677 --> 1.004367).  Saving model ...
Validation loss decreased (1.004367 --> 1.000390).  Saving model ...
Validation loss decreased (1.000390 --> 0.997452).  Saving model ...
Validation loss decreased (0.997452 --> 0.993381).  Saving model ...
Validation loss decreased (0.993381 --> 0.990515).  Saving model ...
Validation loss decreased (0.990515 --> 0.988236).  Saving model ...
Validation loss decreased (0.988236 --> 0.985068).  Saving model ...
Validation loss decreased (0.985068 --> 0.982032).  Saving model ...
Validation loss decreased (0.982032 --> 0.980201).  Saving model ...
Validation loss decreased (0.980201 --> 0.978832).  Saving model ...
Validation loss decreased (0.978832 --> 0.975978).  Saving model ...
Validation loss decreased (0.975978 --> 0.973258).  Saving model ...
Validation loss decreased (0.973258 --> 0.972005).  Saving model ...
Validation loss decreased (0.972005 --> 0.968843).  Saving model ...
Validation loss decreased (0.968843 --> 0.966828).  Saving model ...
Validation loss decreased (0.966828 --> 0.965475).  Saving model ...
Validation loss decreased (0.965475 --> 0.962209).  Saving model ...
Validation loss decreased (0.962209 --> 0.959684).  Saving model ...
Validation loss decreased (0.959684 --> 0.956972).  Saving model ...
Validation loss decreased (0.956972 --> 0.955239).  Saving model ...
Validation loss decreased (0.955239 --> 0.954040).  Saving model ...
Validation loss decreased (0.954040 --> 0.952312).  Saving model ...
Validation loss decreased (0.952312 --> 0.950520).  Saving model ...
Validation loss decreased (0.950520 --> 0.948635).  Saving model ...
Validation loss decreased (0.948635 --> 0.946427).  Saving model ...
Validation loss decreased (0.946427 --> 0.945848).  Saving model ...
Validation loss decreased (0.945848 --> 0.945302).  Saving model ...
Validation loss decreased (0.945302 --> 0.943863).  Saving model ...
Validation loss decreased (0.943863 --> 0.941031).  Saving model ...
Validation loss decreased (0.941031 --> 0.940459).  Saving model ...
Validation loss decreased (0.940459 --> 0.940109).  Saving model ...
Validation loss decreased (0.940109 --> 0.940018).  Saving model ...
Validation loss decreased (0.940018 --> 0.938485).  Saving model ...
Validation loss decreased (0.938485 --> 0.936806).  Saving model ...
Validation loss decreased (0.936806 --> 0.936797).  Saving model ...
Validation loss decreased (0.936797 --> 0.936439).  Saving model ...
Validation loss decreased (0.936439 --> 0.935220).  Saving model ...
Validation loss decreased (0.935220 --> 0.933981).  Saving model ...
Validation loss decreased (0.933981 --> 0.933099).  Saving model ...
Validation loss decreased (0.933099 --> 0.932788).  Saving model ...
Validation loss decreased (0.932788 --> 0.932369).  Saving model ...
Validation loss decreased (0.932369 --> 0.931727).  Saving model ...
Validation loss decreased (0.931727 --> 0.931104).  Saving model ...
Validation loss decreased (0.931104 --> 0.930759).  Saving model ...
Validation loss decreased (0.930759 --> 0.929950).  Saving model ...
Validation loss decreased (0.929950 --> 0.929721).  Saving model ...
EarlyStopping counter: 1 out of 10.0
Validation loss decreased (0.929721 --> 0.929141).  Saving model ...
Validation loss decreased (0.929141 --> 0.929075).  Saving model ...
Validation loss decreased (0.929075 --> 0.928876).  Saving model ...
Validation loss decreased (0.928876 --> 0.928363).  Saving model ...
Validation loss decreased (0.928363 --> 0.928255).  Saving model ...
Validation loss decreased (0.928255 --> 0.928108).  Saving model ...
EarlyStopping counter: 1 out of 10.0
Validation loss decreased (0.928108 --> 0.927890).  Saving model ...
EarlyStopping counter: 1 out of 10.0
Validation loss decreased (0.927890 --> 0.927460).  Saving model ...
Validation loss decreased (0.927460 --> 0.927096).  Saving model ...
EarlyStopping counter: 1 out of 10.0
Validation loss decreased (0.927096 --> 0.926765).  Saving model ...
EarlyStopping counter: 1 out of 10.0
EarlyStopping counter: 2 out of 10.0
EarlyStopping counter: 3 out of 10.0
EarlyStopping counter: 4 out of 10.0
EarlyStopping counter: 5 out of 10.0
EarlyStopping counter: 6 out of 10.0
EarlyStopping counter: 7 out of 10.0
EarlyStopping counter: 8 out of 10.0
EarlyStopping counter: 9 out of 10.0
EarlyStopping counter: 10 out of 10.0
/localscratch/yinan.29019300.0/env/lib/python3.7/site-packages/torch/nn/functional.py:1794: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.
  warnings.warn("nn.functional.tanh is deprecated. Use torch.tanh instead.")
wandb: Waiting for W&B process to finish, PID 31577... (success).
wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: \ 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: | 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: / 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: \ 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: | 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: / 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: \ 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: | 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: / 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: \ 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: | 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: / 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: \ 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: | 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: / 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: \ 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb:                                                                                
wandb: Run history:
wandb:     e_F1 â–â–‚â–ƒâ–„â–„â–„â–…â–…â–…â–†â–†â–†â–†â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ
wandb:   e_loss â–ˆâ–ˆâ–‡â–‡â–‡â–‡â–†â–†â–†â–…â–…â–„â–„â–„â–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–‚â–‚â–‚â–‚â–‚â–‚â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:     t_F1 â–â–‚â–‚â–‚â–ƒâ–ƒâ–ƒâ–„â–„â–…â–…â–…â–…â–†â–…â–†â–†â–†â–†â–†â–†â–†â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–ˆâ–‡â–‡â–‡â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ
wandb:   t_loss â–ˆâ–ˆâ–ˆâ–‡â–‡â–‡â–‡â–‡â–‡â–†â–†â–†â–†â–…â–…â–…â–…â–„â–„â–„â–„â–„â–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–‚â–‚â–‚â–‚â–‚â–‚â–‚â–â–â–â–
wandb: 
wandb: Run summary:
wandb:     e_F1 59.48097
wandb:   e_loss 0.93006
wandb:     t_F1 74.19608
wandb:   t_loss 0.72544
wandb: 
wandb: Synced 4 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Synced fallen-armadillo-2: https://wandb.ai/yinanazhou/xl_512_bs_8_lr_1e06_es_10_lc_False_nr_True_sr_False_stem_False_lemma_False_repeat_1_fold_2/runs/25f1t9r8
wandb: Find logs at: ./wandb/run-20220318_202441-25f1t9r8/logs/debug.log
wandb: 

wandb: wandb version 0.12.11 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
2022-03-18 21:55:19.264983: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1
wandb: Tracking run with wandb version 0.12.5
wandb: Syncing run playful-sunset-2
wandb: â­ï¸ View project at https://wandb.ai/yinanazhou/xl_512_bs_8_lr_1e06_es_10_lc_False_nr_True_sr_False_stem_False_lemma_False_repeat_2_fold_1
wandb: ðŸš€ View run at https://wandb.ai/yinanazhou/xl_512_bs_8_lr_1e06_es_10_lc_False_nr_True_sr_False_stem_False_lemma_False_repeat_2_fold_1/runs/1tt9ck90
wandb: Run data is saved locally in /project/6002780/yinan/Thesis_MER_Lyrics/lyric-emotion/wandb/run-20220318_215516-1tt9ck90
wandb: Run `wandb offline` to turn off syncing.

Validation loss decreased (inf --> 1.459622).  Saving model ...
Validation loss decreased (1.459622 --> 1.427451).  Saving model ...
Validation loss decreased (1.427451 --> 1.405301).  Saving model ...
Validation loss decreased (1.405301 --> 1.390688).  Saving model ...
Validation loss decreased (1.390688 --> 1.380782).  Saving model ...
Validation loss decreased (1.380782 --> 1.373843).  Saving model ...
Validation loss decreased (1.373843 --> 1.368188).  Saving model ...
Validation loss decreased (1.368188 --> 1.362491).  Saving model ...
Validation loss decreased (1.362491 --> 1.357228).  Saving model ...
Validation loss decreased (1.357228 --> 1.352396).  Saving model ...
Validation loss decreased (1.352396 --> 1.347296).  Saving model ...
Validation loss decreased (1.347296 --> 1.341988).  Saving model ...
Validation loss decreased (1.341988 --> 1.337727).  Saving model ...
Validation loss decreased (1.337727 --> 1.331973).  Saving model ...
Validation loss decreased (1.331973 --> 1.325651).  Saving model ...
Validation loss decreased (1.325651 --> 1.318282).  Saving model ...
Validation loss decreased (1.318282 --> 1.310853).  Saving model ...
Validation loss decreased (1.310853 --> 1.302458).  Saving model ...
Validation loss decreased (1.302458 --> 1.294875).  Saving model ...
Validation loss decreased (1.294875 --> 1.286212).  Saving model ...
Validation loss decreased (1.286212 --> 1.278301).  Saving model ...
Validation loss decreased (1.278301 --> 1.269625).  Saving model ...
Validation loss decreased (1.269625 --> 1.260515).  Saving model ...
Validation loss decreased (1.260515 --> 1.251863).  Saving model ...
Validation loss decreased (1.251863 --> 1.244471).  Saving model ...
Validation loss decreased (1.244471 --> 1.236335).  Saving model ...
Validation loss decreased (1.236335 --> 1.229084).  Saving model ...
Validation loss decreased (1.229084 --> 1.222719).  Saving model ...
Validation loss decreased (1.222719 --> 1.214460).  Saving model ...
Validation loss decreased (1.214460 --> 1.206556).  Saving model ...
Validation loss decreased (1.206556 --> 1.198632).  Saving model ...
Validation loss decreased (1.198632 --> 1.191984).  Saving model ...
Validation loss decreased (1.191984 --> 1.185478).  Saving model ...
Validation loss decreased (1.185478 --> 1.177964).  Saving model ...
Validation loss decreased (1.177964 --> 1.172190).  Saving model ...
Validation loss decreased (1.172190 --> 1.164843).  Saving model ...
Validation loss decreased (1.164843 --> 1.158980).  Saving model ...
Validation loss decreased (1.158980 --> 1.152901).  Saving model ...
Validation loss decreased (1.152901 --> 1.147091).  Saving model ...
Validation loss decreased (1.147091 --> 1.142105).  Saving model ...
Validation loss decreased (1.142105 --> 1.136406).  Saving model ...
Validation loss decreased (1.136406 --> 1.131735).  Saving model ...
Validation loss decreased (1.131735 --> 1.125911).  Saving model ...
Validation loss decreased (1.125911 --> 1.119300).  Saving model ...
Validation loss decreased (1.119300 --> 1.115545).  Saving model ...
Validation loss decreased (1.115545 --> 1.109829).  Saving model ...
Validation loss decreased (1.109829 --> 1.104747).  Saving model ...
Validation loss decreased (1.104747 --> 1.100250).  Saving model ...
Validation loss decreased (1.100250 --> 1.095565).  Saving model ...
Validation loss decreased (1.095565 --> 1.090542).  Saving model ...
Validation loss decreased (1.090542 --> 1.086160).  Saving model ...
Validation loss decreased (1.086160 --> 1.081621).  Saving model ...
Validation loss decreased (1.081621 --> 1.076028).  Saving model ...
Validation loss decreased (1.076028 --> 1.071449).  Saving model ...
Validation loss decreased (1.071449 --> 1.067518).  Saving model ...
Validation loss decreased (1.067518 --> 1.063950).  Saving model ...
Validation loss decreased (1.063950 --> 1.061466).  Saving model ...
Validation loss decreased (1.061466 --> 1.057437).  Saving model ...
Validation loss decreased (1.057437 --> 1.053477).  Saving model ...
Validation loss decreased (1.053477 --> 1.051066).  Saving model ...
Validation loss decreased (1.051066 --> 1.047161).  Saving model ...
Validation loss decreased (1.047161 --> 1.044212).  Saving model ...
Validation loss decreased (1.044212 --> 1.039689).  Saving model ...
Validation loss decreased (1.039689 --> 1.036671).  Saving model ...
Validation loss decreased (1.036671 --> 1.032987).  Saving model ...
Validation loss decreased (1.032987 --> 1.029082).  Saving model ...
Validation loss decreased (1.029082 --> 1.026293).  Saving model ...
Validation loss decreased (1.026293 --> 1.023640).  Saving model ...
Validation loss decreased (1.023640 --> 1.020346).  Saving model ...
Validation loss decreased (1.020346 --> 1.017053).  Saving model ...
Validation loss decreased (1.017053 --> 1.014404).  Saving model ...
Validation loss decreased (1.014404 --> 1.011390).  Saving model ...
Validation loss decreased (1.011390 --> 1.009187).  Saving model ...
Validation loss decreased (1.009187 --> 1.007427).  Saving model ...
Validation loss decreased (1.007427 --> 1.004978).  Saving model ...
Validation loss decreased (1.004978 --> 1.002813).  Saving model ...
Validation loss decreased (1.002813 --> 1.001306).  Saving model ...
Validation loss decreased (1.001306 --> 0.998735).  Saving model ...
Validation loss decreased (0.998735 --> 0.998086).  Saving model ...
Validation loss decreased (0.998086 --> 0.996105).  Saving model ...
Validation loss decreased (0.996105 --> 0.993496).  Saving model ...
Validation loss decreased (0.993496 --> 0.990794).  Saving model ...
Validation loss decreased (0.990794 --> 0.987653).  Saving model ...
Validation loss decreased (0.987653 --> 0.985057).  Saving model ...
Validation loss decreased (0.985057 --> 0.983282).  Saving model ...
Validation loss decreased (0.983282 --> 0.981768).  Saving model ...
Validation loss decreased (0.981768 --> 0.980560).  Saving model ...
Validation loss decreased (0.980560 --> 0.980177).  Saving model ...
Validation loss decreased (0.980177 --> 0.978584).  Saving model ...
Validation loss decreased (0.978584 --> 0.977462).  Saving model ...
Validation loss decreased (0.977462 --> 0.975394).  Saving model ...
EarlyStopping counter: 1 out of 10.0
Validation loss decreased (0.975394 --> 0.974626).  Saving model ...
Validation loss decreased (0.974626 --> 0.970589).  Saving model ...
Validation loss decreased (0.970589 --> 0.968036).  Saving model ...
Validation loss decreased (0.968036 --> 0.967989).  Saving model ...
EarlyStopping counter: 1 out of 10.0
Validation loss decreased (0.967989 --> 0.965871).  Saving model ...
Validation loss decreased (0.965871 --> 0.964980).  Saving model ...
Validation loss decreased (0.964980 --> 0.963766).  Saving model ...
Validation loss decreased (0.963766 --> 0.962807).  Saving model ...
Validation loss decreased (0.962807 --> 0.961884).  Saving model ...
Validation loss decreased (0.961884 --> 0.961354).  Saving model ...
EarlyStopping counter: 1 out of 10.0
Validation loss decreased (0.961354 --> 0.960645).  Saving model ...
Validation loss decreased (0.960645 --> 0.958827).  Saving model ...
Validation loss decreased (0.958827 --> 0.958018).  Saving model ...
Validation loss decreased (0.958018 --> 0.956344).  Saving model ...
EarlyStopping counter: 1 out of 10.0
Validation loss decreased (0.956344 --> 0.956337).  Saving model ...
EarlyStopping counter: 1 out of 10.0
EarlyStopping counter: 2 out of 10.0
EarlyStopping counter: 3 out of 10.0
Validation loss decreased (0.956337 --> 0.955914).  Saving model ...
Validation loss decreased (0.955914 --> 0.954686).  Saving model ...
Validation loss decreased (0.954686 --> 0.952146).  Saving model ...
EarlyStopping counter: 1 out of 10.0
EarlyStopping counter: 2 out of 10.0
Validation loss decreased (0.952146 --> 0.951446).  Saving model ...
EarlyStopping counter: 1 out of 10.0
EarlyStopping counter: 2 out of 10.0
Validation loss decreased (0.951446 --> 0.950910).  Saving model ...
EarlyStopping counter: 1 out of 10.0
EarlyStopping counter: 2 out of 10.0
EarlyStopping counter: 3 out of 10.0
EarlyStopping counter: 4 out of 10.0
EarlyStopping counter: 5 out of 10.0
EarlyStopping counter: 6 out of 10.0
EarlyStopping counter: 7 out of 10.0
EarlyStopping counter: 8 out of 10.0
EarlyStopping counter: 9 out of 10.0
EarlyStopping counter: 10 out of 10.0
/localscratch/yinan.29019300.0/env/lib/python3.7/site-packages/torch/nn/functional.py:1794: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.
  warnings.warn("nn.functional.tanh is deprecated. Use torch.tanh instead.")
wandb: Waiting for W&B process to finish, PID 36511... (success).
wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: \ 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: | 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: / 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: \ 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: | 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: / 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: \ 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: | 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: / 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: \ 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb:                                                                                
wandb: Run history:
wandb:     e_F1 â–â–‚â–„â–…â–…â–…â–…â–†â–†â–†â–†â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ
wandb:   e_loss â–ˆâ–‡â–‡â–‡â–‡â–†â–†â–…â–…â–…â–„â–„â–„â–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:     t_F1 â–â–â–ƒâ–ƒâ–ƒâ–„â–„â–…â–„â–…â–…â–†â–†â–†â–…â–†â–†â–†â–‡â–‡â–†â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–ˆâ–‡â–‡â–ˆâ–‡â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ
wandb:   t_loss â–ˆâ–ˆâ–‡â–‡â–‡â–‡â–†â–†â–†â–†â–…â–…â–…â–…â–„â–„â–„â–„â–„â–„â–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–â–â–â–â–â–
wandb: 
wandb: Run summary:
wandb:     e_F1 58.60172
wandb:   e_loss 0.95319
wandb:     t_F1 69.90658
wandb:   t_loss 0.74349
wandb: 
wandb: Synced 4 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Synced playful-sunset-2: https://wandb.ai/yinanazhou/xl_512_bs_8_lr_1e06_es_10_lc_False_nr_True_sr_False_stem_False_lemma_False_repeat_2_fold_1/runs/1tt9ck90
wandb: Find logs at: ./wandb/run-20220318_215516-1tt9ck90/logs/debug.log
wandb: 

wandb: wandb version 0.12.11 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
2022-03-18 23:18:54.160139: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1
wandb: Tracking run with wandb version 0.12.5
wandb: Syncing run peachy-valley-2
wandb: â­ï¸ View project at https://wandb.ai/yinanazhou/xl_512_bs_8_lr_1e06_es_10_lc_False_nr_True_sr_False_stem_False_lemma_False_repeat_2_fold_2
wandb: ðŸš€ View run at https://wandb.ai/yinanazhou/xl_512_bs_8_lr_1e06_es_10_lc_False_nr_True_sr_False_stem_False_lemma_False_repeat_2_fold_2/runs/3ahbfjue
wandb: Run data is saved locally in /project/6002780/yinan/Thesis_MER_Lyrics/lyric-emotion/wandb/run-20220318_231851-3ahbfjue
wandb: Run `wandb offline` to turn off syncing.

Validation loss decreased (inf --> 1.436928).  Saving model ...
Validation loss decreased (1.436928 --> 1.425451).  Saving model ...
Validation loss decreased (1.425451 --> 1.415642).  Saving model ...
Validation loss decreased (1.415642 --> 1.407355).  Saving model ...
Validation loss decreased (1.407355 --> 1.400506).  Saving model ...
Validation loss decreased (1.400506 --> 1.394025).  Saving model ...
Validation loss decreased (1.394025 --> 1.388346).  Saving model ...
Validation loss decreased (1.388346 --> 1.383148).  Saving model ...
Validation loss decreased (1.383148 --> 1.377891).  Saving model ...
Validation loss decreased (1.377891 --> 1.373074).  Saving model ...
Validation loss decreased (1.373074 --> 1.368241).  Saving model ...
Validation loss decreased (1.368241 --> 1.363694).  Saving model ...
Validation loss decreased (1.363694 --> 1.358617).  Saving model ...
Validation loss decreased (1.358617 --> 1.353449).  Saving model ...
Validation loss decreased (1.353449 --> 1.348136).  Saving model ...
Validation loss decreased (1.348136 --> 1.343253).  Saving model ...
Validation loss decreased (1.343253 --> 1.337874).  Saving model ...
Validation loss decreased (1.337874 --> 1.331899).  Saving model ...
Validation loss decreased (1.331899 --> 1.325059).  Saving model ...
Validation loss decreased (1.325059 --> 1.317999).  Saving model ...
Validation loss decreased (1.317999 --> 1.310459).  Saving model ...
Validation loss decreased (1.310459 --> 1.302442).  Saving model ...
Validation loss decreased (1.302442 --> 1.294373).  Saving model ...
Validation loss decreased (1.294373 --> 1.285461).  Saving model ...
Validation loss decreased (1.285461 --> 1.277293).  Saving model ...
Validation loss decreased (1.277293 --> 1.266901).  Saving model ...
Validation loss decreased (1.266901 --> 1.257441).  Saving model ...
Validation loss decreased (1.257441 --> 1.250514).  Saving model ...
Validation loss decreased (1.250514 --> 1.242229).  Saving model ...
Validation loss decreased (1.242229 --> 1.232104).  Saving model ...
Validation loss decreased (1.232104 --> 1.223091).  Saving model ...
Validation loss decreased (1.223091 --> 1.215567).  Saving model ...
Validation loss decreased (1.215567 --> 1.208992).  Saving model ...
Validation loss decreased (1.208992 --> 1.201851).  Saving model ...
Validation loss decreased (1.201851 --> 1.192200).  Saving model ...
Validation loss decreased (1.192200 --> 1.184216).  Saving model ...
Validation loss decreased (1.184216 --> 1.175332).  Saving model ...
Validation loss decreased (1.175332 --> 1.168540).  Saving model ...
Validation loss decreased (1.168540 --> 1.162888).  Saving model ...
Validation loss decreased (1.162888 --> 1.156570).  Saving model ...
Validation loss decreased (1.156570 --> 1.148233).  Saving model ...
Validation loss decreased (1.148233 --> 1.141254).  Saving model ...
Validation loss decreased (1.141254 --> 1.133039).  Saving model ...
Validation loss decreased (1.133039 --> 1.127591).  Saving model ...
Validation loss decreased (1.127591 --> 1.121866).  Saving model ...
Validation loss decreased (1.121866 --> 1.117694).  Saving model ...
Validation loss decreased (1.117694 --> 1.110774).  Saving model ...
Validation loss decreased (1.110774 --> 1.105856).  Saving model ...
Validation loss decreased (1.105856 --> 1.100435).  Saving model ...
Validation loss decreased (1.100435 --> 1.095650).  Saving model ...
Validation loss decreased (1.095650 --> 1.089410).  Saving model ...
Validation loss decreased (1.089410 --> 1.086757).  Saving model ...
Validation loss decreased (1.086757 --> 1.081794).  Saving model ...
Validation loss decreased (1.081794 --> 1.075073).  Saving model ...
Validation loss decreased (1.075073 --> 1.071181).  Saving model ...
Validation loss decreased (1.071181 --> 1.068435).  Saving model ...
Validation loss decreased (1.068435 --> 1.064965).  Saving model ...
Validation loss decreased (1.064965 --> 1.058188).  Saving model ...
Validation loss decreased (1.058188 --> 1.053186).  Saving model ...
Validation loss decreased (1.053186 --> 1.047067).  Saving model ...
Validation loss decreased (1.047067 --> 1.042205).  Saving model ...
Validation loss decreased (1.042205 --> 1.041389).  Saving model ...
Validation loss decreased (1.041389 --> 1.035993).  Saving model ...
Validation loss decreased (1.035993 --> 1.033678).  Saving model ...
Validation loss decreased (1.033678 --> 1.029331).  Saving model ...
Validation loss decreased (1.029331 --> 1.027458).  Saving model ...
Validation loss decreased (1.027458 --> 1.023057).  Saving model ...
Validation loss decreased (1.023057 --> 1.020478).  Saving model ...
Validation loss decreased (1.020478 --> 1.016343).  Saving model ...
Validation loss decreased (1.016343 --> 1.012714).  Saving model ...
Validation loss decreased (1.012714 --> 1.007863).  Saving model ...
Validation loss decreased (1.007863 --> 1.006382).  Saving model ...
Validation loss decreased (1.006382 --> 1.004071).  Saving model ...
Validation loss decreased (1.004071 --> 1.003449).  Saving model ...
Validation loss decreased (1.003449 --> 1.001006).  Saving model ...
Validation loss decreased (1.001006 --> 0.997851).  Saving model ...
Validation loss decreased (0.997851 --> 0.996847).  Saving model ...
Validation loss decreased (0.996847 --> 0.991950).  Saving model ...
Validation loss decreased (0.991950 --> 0.989162).  Saving model ...
Validation loss decreased (0.989162 --> 0.987240).  Saving model ...
Validation loss decreased (0.987240 --> 0.985025).  Saving model ...
Validation loss decreased (0.985025 --> 0.982014).  Saving model ...
Validation loss decreased (0.982014 --> 0.978820).  Saving model ...
Validation loss decreased (0.978820 --> 0.974583).  Saving model ...
Validation loss decreased (0.974583 --> 0.974480).  Saving model ...
Validation loss decreased (0.974480 --> 0.973036).  Saving model ...
Validation loss decreased (0.973036 --> 0.970150).  Saving model ...
EarlyStopping counter: 1 out of 10.0
Validation loss decreased (0.970150 --> 0.967898).  Saving model ...
Validation loss decreased (0.967898 --> 0.967182).  Saving model ...
Validation loss decreased (0.967182 --> 0.965857).  Saving model ...
Validation loss decreased (0.965857 --> 0.963273).  Saving model ...
Validation loss decreased (0.963273 --> 0.961684).  Saving model ...
Validation loss decreased (0.961684 --> 0.961082).  Saving model ...
Validation loss decreased (0.961082 --> 0.959095).  Saving model ...
Validation loss decreased (0.959095 --> 0.957031).  Saving model ...
Validation loss decreased (0.957031 --> 0.955714).  Saving model ...
Validation loss decreased (0.955714 --> 0.951096).  Saving model ...
EarlyStopping counter: 1 out of 10.0
EarlyStopping counter: 2 out of 10.0
EarlyStopping counter: 3 out of 10.0
Validation loss decreased (0.951096 --> 0.949079).  Saving model ...
Validation loss decreased (0.949079 --> 0.948308).  Saving model ...
EarlyStopping counter: 1 out of 10.0
Validation loss decreased (0.948308 --> 0.945960).  Saving model ...
EarlyStopping counter: 1 out of 10.0
Validation loss decreased (0.945960 --> 0.945848).  Saving model ...
EarlyStopping counter: 1 out of 10.0
Validation loss decreased (0.945848 --> 0.943919).  Saving model ...
EarlyStopping counter: 1 out of 10.0
Validation loss decreased (0.943919 --> 0.942607).  Saving model ...
Validation loss decreased (0.942607 --> 0.942470).  Saving model ...
Validation loss decreased (0.942470 --> 0.941838).  Saving model ...
Validation loss decreased (0.941838 --> 0.938882).  Saving model ...
Validation loss decreased (0.938882 --> 0.937899).  Saving model ...
Validation loss decreased (0.937899 --> 0.935835).  Saving model ...
Validation loss decreased (0.935835 --> 0.934242).  Saving model ...
EarlyStopping counter: 1 out of 10.0
EarlyStopping counter: 2 out of 10.0
EarlyStopping counter: 3 out of 10.0
EarlyStopping counter: 4 out of 10.0
EarlyStopping counter: 5 out of 10.0
Validation loss decreased (0.934242 --> 0.933778).  Saving model ...
EarlyStopping counter: 1 out of 10.0
EarlyStopping counter: 2 out of 10.0
Validation loss decreased (0.933778 --> 0.933208).  Saving model ...
EarlyStopping counter: 1 out of 10.0
Validation loss decreased (0.933208 --> 0.932893).  Saving model ...
Validation loss decreased (0.932893 --> 0.932494).  Saving model ...
Validation loss decreased (0.932494 --> 0.931624).  Saving model ...
EarlyStopping counter: 1 out of 10.0
EarlyStopping counter: 2 out of 10.0
Validation loss decreased (0.931624 --> 0.930594).  Saving model ...
EarlyStopping counter: 1 out of 10.0
EarlyStopping counter: 2 out of 10.0
EarlyStopping counter: 3 out of 10.0
EarlyStopping counter: 4 out of 10.0
Validation loss decreased (0.930594 --> 0.930140).  Saving model ...
EarlyStopping counter: 1 out of 10.0
EarlyStopping counter: 2 out of 10.0
EarlyStopping counter: 3 out of 10.0
EarlyStopping counter: 4 out of 10.0
EarlyStopping counter: 5 out of 10.0
EarlyStopping counter: 6 out of 10.0
EarlyStopping counter: 7 out of 10.0
EarlyStopping counter: 8 out of 10.0
EarlyStopping counter: 9 out of 10.0
EarlyStopping counter: 10 out of 10.0
/localscratch/yinan.29019300.0/env/lib/python3.7/site-packages/torch/nn/functional.py:1794: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.
  warnings.warn("nn.functional.tanh is deprecated. Use torch.tanh instead.")
wandb: Waiting for W&B process to finish, PID 41104... (success).
wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: \ 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: | 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: / 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: \ 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: | 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: / 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: \ 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: | 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: / 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb:                                                                                
wandb: Run history:
wandb:     e_F1 â–â–â–‚â–„â–„â–…â–…â–…â–…â–†â–†â–†â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–ˆâ–‡â–‡â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ
wandb:   e_loss â–ˆâ–ˆâ–‡â–‡â–‡â–†â–†â–†â–…â–…â–„â–„â–„â–ƒâ–ƒâ–ƒâ–ƒâ–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:     t_F1 â–â–â–‚â–‚â–‚â–ƒâ–ƒâ–„â–„â–„â–…â–…â–…â–…â–†â–†â–†â–†â–†â–†â–†â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–ˆâ–ˆâ–‡â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ
wandb:   t_loss â–ˆâ–ˆâ–ˆâ–‡â–‡â–‡â–‡â–†â–†â–†â–…â–…â–…â–…â–„â–„â–„â–„â–„â–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–â–â–â–â–â–
wandb: 
wandb: Run summary:
wandb:     e_F1 64.33429
wandb:   e_loss 0.93685
wandb:     t_F1 71.5848
wandb:   t_loss 0.74544
wandb: 
wandb: Synced 4 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Synced peachy-valley-2: https://wandb.ai/yinanazhou/xl_512_bs_8_lr_1e06_es_10_lc_False_nr_True_sr_False_stem_False_lemma_False_repeat_2_fold_2/runs/3ahbfjue
wandb: Find logs at: ./wandb/run-20220318_231851-3ahbfjue/logs/debug.log
wandb: 

wandb: wandb version 0.12.11 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
2022-03-19 00:56:33.986057: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1
wandb: Tracking run with wandb version 0.12.5
wandb: Syncing run unique-valley-2
wandb: â­ï¸ View project at https://wandb.ai/yinanazhou/xl_512_bs_8_lr_1e06_es_10_lc_False_nr_True_sr_False_stem_False_lemma_False_repeat_3_fold_1
wandb: ðŸš€ View run at https://wandb.ai/yinanazhou/xl_512_bs_8_lr_1e06_es_10_lc_False_nr_True_sr_False_stem_False_lemma_False_repeat_3_fold_1/runs/34hebi6f
wandb: Run data is saved locally in /project/6002780/yinan/Thesis_MER_Lyrics/lyric-emotion/wandb/run-20220319_005631-34hebi6f
wandb: Run `wandb offline` to turn off syncing.

Validation loss decreased (inf --> 1.406500).  Saving model ...
Validation loss decreased (1.406500 --> 1.395255).  Saving model ...
Validation loss decreased (1.395255 --> 1.386341).  Saving model ...
Validation loss decreased (1.386341 --> 1.379574).  Saving model ...
Validation loss decreased (1.379574 --> 1.374057).  Saving model ...
Validation loss decreased (1.374057 --> 1.369154).  Saving model ...
Validation loss decreased (1.369154 --> 1.364300).  Saving model ...
Validation loss decreased (1.364300 --> 1.359312).  Saving model ...
Validation loss decreased (1.359312 --> 1.354636).  Saving model ...
Validation loss decreased (1.354636 --> 1.350581).  Saving model ...
Validation loss decreased (1.350581 --> 1.345444).  Saving model ...
Validation loss decreased (1.345444 --> 1.340176).  Saving model ...
Validation loss decreased (1.340176 --> 1.335146).  Saving model ...
Validation loss decreased (1.335146 --> 1.329262).  Saving model ...
Validation loss decreased (1.329262 --> 1.324175).  Saving model ...
Validation loss decreased (1.324175 --> 1.319132).  Saving model ...
Validation loss decreased (1.319132 --> 1.312168).  Saving model ...
Validation loss decreased (1.312168 --> 1.304135).  Saving model ...
Validation loss decreased (1.304135 --> 1.297269).  Saving model ...
Validation loss decreased (1.297269 --> 1.289784).  Saving model ...
Validation loss decreased (1.289784 --> 1.284034).  Saving model ...
Validation loss decreased (1.284034 --> 1.277643).  Saving model ...
Validation loss decreased (1.277643 --> 1.271222).  Saving model ...
Validation loss decreased (1.271222 --> 1.264419).  Saving model ...
Validation loss decreased (1.264419 --> 1.258092).  Saving model ...
Validation loss decreased (1.258092 --> 1.252523).  Saving model ...
Validation loss decreased (1.252523 --> 1.246434).  Saving model ...
Validation loss decreased (1.246434 --> 1.240560).  Saving model ...
Validation loss decreased (1.240560 --> 1.236141).  Saving model ...
Validation loss decreased (1.236141 --> 1.230084).  Saving model ...
Validation loss decreased (1.230084 --> 1.223632).  Saving model ...
Validation loss decreased (1.223632 --> 1.220440).  Saving model ...
Validation loss decreased (1.220440 --> 1.215602).  Saving model ...
Validation loss decreased (1.215602 --> 1.209488).  Saving model ...
Validation loss decreased (1.209488 --> 1.203933).  Saving model ...
Validation loss decreased (1.203933 --> 1.198105).  Saving model ...
Validation loss decreased (1.198105 --> 1.191914).  Saving model ...
Validation loss decreased (1.191914 --> 1.185604).  Saving model ...
Validation loss decreased (1.185604 --> 1.183196).  Saving model ...
Validation loss decreased (1.183196 --> 1.177341).  Saving model ...
Validation loss decreased (1.177341 --> 1.170626).  Saving model ...
Validation loss decreased (1.170626 --> 1.165213).  Saving model ...
Validation loss decreased (1.165213 --> 1.162503).  Saving model ...
Validation loss decreased (1.162503 --> 1.160667).  Saving model ...
Validation loss decreased (1.160667 --> 1.153880).  Saving model ...
Validation loss decreased (1.153880 --> 1.146665).  Saving model ...
Validation loss decreased (1.146665 --> 1.143103).  Saving model ...
Validation loss decreased (1.143103 --> 1.139687).  Saving model ...
Validation loss decreased (1.139687 --> 1.134032).  Saving model ...
Validation loss decreased (1.134032 --> 1.130786).  Saving model ...
Validation loss decreased (1.130786 --> 1.130731).  Saving model ...
Validation loss decreased (1.130731 --> 1.123032).  Saving model ...
Validation loss decreased (1.123032 --> 1.117105).  Saving model ...
Validation loss decreased (1.117105 --> 1.116853).  Saving model ...
Validation loss decreased (1.116853 --> 1.112379).  Saving model ...
Validation loss decreased (1.112379 --> 1.110165).  Saving model ...
Validation loss decreased (1.110165 --> 1.104509).  Saving model ...
Validation loss decreased (1.104509 --> 1.100787).  Saving model ...
Validation loss decreased (1.100787 --> 1.097848).  Saving model ...
EarlyStopping counter: 1 out of 10.0
Validation loss decreased (1.097848 --> 1.094026).  Saving model ...
Validation loss decreased (1.094026 --> 1.092436).  Saving model ...
Validation loss decreased (1.092436 --> 1.087707).  Saving model ...
Validation loss decreased (1.087707 --> 1.084081).  Saving model ...
Validation loss decreased (1.084081 --> 1.079907).  Saving model ...
Validation loss decreased (1.079907 --> 1.076177).  Saving model ...
Validation loss decreased (1.076177 --> 1.075885).  Saving model ...
Validation loss decreased (1.075885 --> 1.067412).  Saving model ...
EarlyStopping counter: 1 out of 10.0
Validation loss decreased (1.067412 --> 1.064002).  Saving model ...
Validation loss decreased (1.064002 --> 1.063173).  Saving model ...
Validation loss decreased (1.063173 --> 1.061797).  Saving model ...
EarlyStopping counter: 1 out of 10.0
Validation loss decreased (1.061797 --> 1.058172).  Saving model ...
Validation loss decreased (1.058172 --> 1.054887).  Saving model ...
Validation loss decreased (1.054887 --> 1.052991).  Saving model ...
Validation loss decreased (1.052991 --> 1.048975).  Saving model ...
Validation loss decreased (1.048975 --> 1.043741).  Saving model ...
Validation loss decreased (1.043741 --> 1.040448).  Saving model ...
EarlyStopping counter: 1 out of 10.0
Validation loss decreased (1.040448 --> 1.038223).  Saving model ...
Validation loss decreased (1.038223 --> 1.037421).  Saving model ...
Validation loss decreased (1.037421 --> 1.034047).  Saving model ...
Validation loss decreased (1.034047 --> 1.031823).  Saving model ...
EarlyStopping counter: 1 out of 10.0
EarlyStopping counter: 2 out of 10.0
Validation loss decreased (1.031823 --> 1.030319).  Saving model ...
Validation loss decreased (1.030319 --> 1.028129).  Saving model ...
Validation loss decreased (1.028129 --> 1.026422).  Saving model ...
Validation loss decreased (1.026422 --> 1.021528).  Saving model ...
Validation loss decreased (1.021528 --> 1.020923).  Saving model ...
EarlyStopping counter: 1 out of 10.0
EarlyStopping counter: 2 out of 10.0
Validation loss decreased (1.020923 --> 1.016148).  Saving model ...
EarlyStopping counter: 1 out of 10.0
EarlyStopping counter: 2 out of 10.0
EarlyStopping counter: 3 out of 10.0
EarlyStopping counter: 4 out of 10.0
EarlyStopping counter: 5 out of 10.0
EarlyStopping counter: 6 out of 10.0
Validation loss decreased (1.016148 --> 1.013530).  Saving model ...
Validation loss decreased (1.013530 --> 1.011439).  Saving model ...
Validation loss decreased (1.011439 --> 1.008277).  Saving model ...
EarlyStopping counter: 1 out of 10.0
EarlyStopping counter: 2 out of 10.0
EarlyStopping counter: 3 out of 10.0
EarlyStopping counter: 4 out of 10.0
EarlyStopping counter: 5 out of 10.0
EarlyStopping counter: 6 out of 10.0
EarlyStopping counter: 7 out of 10.0
EarlyStopping counter: 8 out of 10.0
EarlyStopping counter: 9 out of 10.0
Validation loss decreased (1.008277 --> 1.005523).  Saving model ...
EarlyStopping counter: 1 out of 10.0
EarlyStopping counter: 2 out of 10.0
EarlyStopping counter: 3 out of 10.0
EarlyStopping counter: 4 out of 10.0
EarlyStopping counter: 5 out of 10.0
Validation loss decreased (1.005523 --> 1.001834).  Saving model ...
Validation loss decreased (1.001834 --> 1.000447).  Saving model ...
EarlyStopping counter: 1 out of 10.0
EarlyStopping counter: 2 out of 10.0
EarlyStopping counter: 3 out of 10.0
EarlyStopping counter: 4 out of 10.0
EarlyStopping counter: 5 out of 10.0
EarlyStopping counter: 6 out of 10.0
EarlyStopping counter: 7 out of 10.0
EarlyStopping counter: 8 out of 10.0
EarlyStopping counter: 9 out of 10.0
EarlyStopping counter: 10 out of 10.0
/localscratch/yinan.29019300.0/env/lib/python3.7/site-packages/torch/nn/functional.py:1794: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.
  warnings.warn("nn.functional.tanh is deprecated. Use torch.tanh instead.")
wandb: Waiting for W&B process to finish, PID 46406... (success).
wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: \ 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: | 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: / 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: \ 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: | 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: / 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: \ 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: | 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: / 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb:                                                                                
wandb: Run history:
wandb:     e_F1 â–â–‚â–„â–ƒâ–„â–…â–…â–†â–†â–…â–†â–†â–†â–†â–†â–†â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ
wandb:   e_loss â–ˆâ–ˆâ–‡â–‡â–‡â–†â–†â–†â–…â–…â–…â–„â–„â–„â–„â–ƒâ–ƒâ–ƒâ–ƒâ–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:     t_F1 â–â–â–‚â–‚â–ƒâ–ƒâ–„â–„â–„â–…â–„â–…â–…â–…â–…â–…â–†â–†â–†â–†â–†â–†â–‡â–†â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–ˆâ–‡â–‡â–‡â–‡â–ˆâ–ˆâ–ˆâ–ˆ
wandb:   t_loss â–ˆâ–ˆâ–ˆâ–ˆâ–‡â–‡â–‡â–‡â–†â–†â–†â–…â–…â–…â–…â–…â–„â–„â–„â–„â–„â–„â–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–‚â–‚â–‚â–‚â–‚â–‚â–‚â–â–â–â–
wandb: 
wandb: Run summary:
wandb:     e_F1 58.81698
wandb:   e_loss 1.00725
wandb:     t_F1 75.76811
wandb:   t_loss 0.7463
wandb: 
wandb: Synced 4 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Synced unique-valley-2: https://wandb.ai/yinanazhou/xl_512_bs_8_lr_1e06_es_10_lc_False_nr_True_sr_False_stem_False_lemma_False_repeat_3_fold_1/runs/34hebi6f
wandb: Find logs at: ./wandb/run-20220319_005631-34hebi6f/logs/debug.log
wandb: 

wandb: wandb version 0.12.11 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
2022-03-19 02:22:08.457649: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1
wandb: Tracking run with wandb version 0.12.5
wandb: Syncing run rich-firefly-2
wandb: â­ï¸ View project at https://wandb.ai/yinanazhou/xl_512_bs_8_lr_1e06_es_10_lc_False_nr_True_sr_False_stem_False_lemma_False_repeat_3_fold_2
wandb: ðŸš€ View run at https://wandb.ai/yinanazhou/xl_512_bs_8_lr_1e06_es_10_lc_False_nr_True_sr_False_stem_False_lemma_False_repeat_3_fold_2/runs/2csjp828
wandb: Run data is saved locally in /project/6002780/yinan/Thesis_MER_Lyrics/lyric-emotion/wandb/run-20220319_022205-2csjp828
wandb: Run `wandb offline` to turn off syncing.

Validation loss decreased (inf --> 1.421724).  Saving model ...
Validation loss decreased (1.421724 --> 1.408165).  Saving model ...
Validation loss decreased (1.408165 --> 1.397053).  Saving model ...
Validation loss decreased (1.397053 --> 1.388973).  Saving model ...
Validation loss decreased (1.388973 --> 1.381470).  Saving model ...
Validation loss decreased (1.381470 --> 1.374853).  Saving model ...
Validation loss decreased (1.374853 --> 1.368910).  Saving model ...
Validation loss decreased (1.368910 --> 1.363151).  Saving model ...
Validation loss decreased (1.363151 --> 1.357711).  Saving model ...
Validation loss decreased (1.357711 --> 1.352065).  Saving model ...
Validation loss decreased (1.352065 --> 1.346069).  Saving model ...
Validation loss decreased (1.346069 --> 1.339930).  Saving model ...
Validation loss decreased (1.339930 --> 1.334593).  Saving model ...
Validation loss decreased (1.334593 --> 1.329153).  Saving model ...
Validation loss decreased (1.329153 --> 1.322835).  Saving model ...
Validation loss decreased (1.322835 --> 1.316748).  Saving model ...
Validation loss decreased (1.316748 --> 1.310292).  Saving model ...
Validation loss decreased (1.310292 --> 1.303287).  Saving model ...
Validation loss decreased (1.303287 --> 1.296110).  Saving model ...
Validation loss decreased (1.296110 --> 1.289379).  Saving model ...
Validation loss decreased (1.289379 --> 1.283076).  Saving model ...
Validation loss decreased (1.283076 --> 1.276194).  Saving model ...
Validation loss decreased (1.276194 --> 1.268922).  Saving model ...
Validation loss decreased (1.268922 --> 1.261356).  Saving model ...
Validation loss decreased (1.261356 --> 1.253722).  Saving model ...
Validation loss decreased (1.253722 --> 1.246587).  Saving model ...
Validation loss decreased (1.246587 --> 1.239202).  Saving model ...
Validation loss decreased (1.239202 --> 1.232175).  Saving model ...
Validation loss decreased (1.232175 --> 1.224839).  Saving model ...
Validation loss decreased (1.224839 --> 1.218876).  Saving model ...
Validation loss decreased (1.218876 --> 1.212798).  Saving model ...
Validation loss decreased (1.212798 --> 1.206636).  Saving model ...
Validation loss decreased (1.206636 --> 1.201429).  Saving model ...
Validation loss decreased (1.201429 --> 1.195981).  Saving model ...
Validation loss decreased (1.195981 --> 1.189667).  Saving model ...
Validation loss decreased (1.189667 --> 1.183544).  Saving model ...
Validation loss decreased (1.183544 --> 1.176789).  Saving model ...
Validation loss decreased (1.176789 --> 1.171171).  Saving model ...
Validation loss decreased (1.171171 --> 1.166900).  Saving model ...
Validation loss decreased (1.166900 --> 1.161670).  Saving model ...
Validation loss decreased (1.161670 --> 1.157647).  Saving model ...
Validation loss decreased (1.157647 --> 1.150087).  Saving model ...
Validation loss decreased (1.150087 --> 1.144795).  Saving model ...
Validation loss decreased (1.144795 --> 1.138867).  Saving model ...
Validation loss decreased (1.138867 --> 1.134145).  Saving model ...
Validation loss decreased (1.134145 --> 1.128398).  Saving model ...
Validation loss decreased (1.128398 --> 1.123039).  Saving model ...
Validation loss decreased (1.123039 --> 1.118061).  Saving model ...
Validation loss decreased (1.118061 --> 1.112437).  Saving model ...
Validation loss decreased (1.112437 --> 1.107766).  Saving model ...
Validation loss decreased (1.107766 --> 1.102548).  Saving model ...
Validation loss decreased (1.102548 --> 1.097675).  Saving model ...
Validation loss decreased (1.097675 --> 1.092998).  Saving model ...
Validation loss decreased (1.092998 --> 1.087520).  Saving model ...
Validation loss decreased (1.087520 --> 1.081161).  Saving model ...
Validation loss decreased (1.081161 --> 1.076553).  Saving model ...
Validation loss decreased (1.076553 --> 1.072721).  Saving model ...
Validation loss decreased (1.072721 --> 1.068181).  Saving model ...
Validation loss decreased (1.068181 --> 1.066002).  Saving model ...
Validation loss decreased (1.066002 --> 1.061836).  Saving model ...
Validation loss decreased (1.061836 --> 1.058660).  Saving model ...
Validation loss decreased (1.058660 --> 1.054384).  Saving model ...
Validation loss decreased (1.054384 --> 1.049145).  Saving model ...
Validation loss decreased (1.049145 --> 1.044923).  Saving model ...
Validation loss decreased (1.044923 --> 1.041060).  Saving model ...
Validation loss decreased (1.041060 --> 1.037856).  Saving model ...
Validation loss decreased (1.037856 --> 1.034318).  Saving model ...
Validation loss decreased (1.034318 --> 1.030804).  Saving model ...
Validation loss decreased (1.030804 --> 1.027530).  Saving model ...
Validation loss decreased (1.027530 --> 1.024994).  Saving model ...
Validation loss decreased (1.024994 --> 1.024064).  Saving model ...
Validation loss decreased (1.024064 --> 1.019453).  Saving model ...
Validation loss decreased (1.019453 --> 1.016038).  Saving model ...
Validation loss decreased (1.016038 --> 1.012727).  Saving model ...
Validation loss decreased (1.012727 --> 1.009923).  Saving model ...
Validation loss decreased (1.009923 --> 1.006113).  Saving model ...
Validation loss decreased (1.006113 --> 1.003415).  Saving model ...
Validation loss decreased (1.003415 --> 1.001312).  Saving model ...
Validation loss decreased (1.001312 --> 0.997351).  Saving model ...
Validation loss decreased (0.997351 --> 0.994220).  Saving model ...
Validation loss decreased (0.994220 --> 0.991737).  Saving model ...
Validation loss decreased (0.991737 --> 0.990239).  Saving model ...
Validation loss decreased (0.990239 --> 0.987786).  Saving model ...
Validation loss decreased (0.987786 --> 0.985092).  Saving model ...
Validation loss decreased (0.985092 --> 0.982554).  Saving model ...
Validation loss decreased (0.982554 --> 0.979573).  Saving model ...
Validation loss decreased (0.979573 --> 0.977624).  Saving model ...
Validation loss decreased (0.977624 --> 0.974919).  Saving model ...
Validation loss decreased (0.974919 --> 0.972604).  Saving model ...
Validation loss decreased (0.972604 --> 0.970596).  Saving model ...
Validation loss decreased (0.970596 --> 0.968347).  Saving model ...
Validation loss decreased (0.968347 --> 0.966976).  Saving model ...
Validation loss decreased (0.966976 --> 0.965153).  Saving model ...
Validation loss decreased (0.965153 --> 0.964078).  Saving model ...
Validation loss decreased (0.964078 --> 0.962121).  Saving model ...
Validation loss decreased (0.962121 --> 0.959986).  Saving model ...
Validation loss decreased (0.959986 --> 0.957970).  Saving model ...
Validation loss decreased (0.957970 --> 0.956301).  Saving model ...
Validation loss decreased (0.956301 --> 0.955101).  Saving model ...
Validation loss decreased (0.955101 --> 0.953771).  Saving model ...
Validation loss decreased (0.953771 --> 0.951756).  Saving model ...
Validation loss decreased (0.951756 --> 0.950270).  Saving model ...
Validation loss decreased (0.950270 --> 0.949099).  Saving model ...
Validation loss decreased (0.949099 --> 0.947737).  Saving model ...
Validation loss decreased (0.947737 --> 0.945578).  Saving model ...
Validation loss decreased (0.945578 --> 0.944412).  Saving model ...
Validation loss decreased (0.944412 --> 0.943311).  Saving model ...
Validation loss decreased (0.943311 --> 0.942956).  Saving model ...
Validation loss decreased (0.942956 --> 0.941798).  Saving model ...
Validation loss decreased (0.941798 --> 0.940633).  Saving model ...
Validation loss decreased (0.940633 --> 0.939812).  Saving model ...
Validation loss decreased (0.939812 --> 0.939246).  Saving model ...
Validation loss decreased (0.939246 --> 0.937820).  Saving model ...
Validation loss decreased (0.937820 --> 0.936683).  Saving model ...
Validation loss decreased (0.936683 --> 0.936073).  Saving model ...
Validation loss decreased (0.936073 --> 0.935223).  Saving model ...
Validation loss decreased (0.935223 --> 0.934030).  Saving model ...
Validation loss decreased (0.934030 --> 0.933447).  Saving model ...
Validation loss decreased (0.933447 --> 0.932940).  Saving model ...
Validation loss decreased (0.932940 --> 0.932035).  Saving model ...
Validation loss decreased (0.932035 --> 0.931180).  Saving model ...
Validation loss decreased (0.931180 --> 0.930895).  Saving model ...
Validation loss decreased (0.930895 --> 0.930596).  Saving model ...
Validation loss decreased (0.930596 --> 0.929290).  Saving model ...
Validation loss decreased (0.929290 --> 0.928963).  Saving model ...
EarlyStopping counter: 1 out of 10.0
Validation loss decreased (0.928963 --> 0.927878).  Saving model ...
Validation loss decreased (0.927878 --> 0.927348).  Saving model ...
Validation loss decreased (0.927348 --> 0.926972).  Saving model ...
EarlyStopping counter: 1 out of 10.0
EarlyStopping counter: 2 out of 10.0
Validation loss decreased (0.926972 --> 0.926698).  Saving model ...
Validation loss decreased (0.926698 --> 0.925598).  Saving model ...
Validation loss decreased (0.925598 --> 0.925591).  Saving model ...
Validation loss decreased (0.925591 --> 0.924721).  Saving model ...
EarlyStopping counter: 1 out of 10.0
EarlyStopping counter: 2 out of 10.0
EarlyStopping counter: 3 out of 10.0
EarlyStopping counter: 4 out of 10.0
EarlyStopping counter: 5 out of 10.0
EarlyStopping counter: 6 out of 10.0
EarlyStopping counter: 7 out of 10.0
EarlyStopping counter: 8 out of 10.0
EarlyStopping counter: 9 out of 10.0
EarlyStopping counter: 10 out of 10.0
/localscratch/yinan.29019300.0/env/lib/python3.7/site-packages/torch/nn/functional.py:1794: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.
  warnings.warn("nn.functional.tanh is deprecated. Use torch.tanh instead.")
wandb: Waiting for W&B process to finish, PID 51094... (success).
wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: \ 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: | 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: / 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb:                                                                                
wandb: Run history:
wandb:     e_F1 â–â–â–ƒâ–„â–…â–…â–…â–…â–†â–†â–†â–†â–†â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ
wandb:   e_loss â–ˆâ–ˆâ–‡â–‡â–‡â–†â–†â–†â–…â–…â–…â–„â–„â–„â–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:     t_F1 â–â–‚â–‚â–ƒâ–ƒâ–ƒâ–„â–„â–…â–…â–…â–†â–…â–†â–†â–†â–†â–†â–†â–‡â–†â–‡â–‡â–‡â–‡â–‡â–†â–‡â–‡â–‡â–ˆâ–‡â–‡â–‡â–‡â–ˆâ–ˆâ–ˆâ–‡â–ˆ
wandb:   t_loss â–ˆâ–‡â–‡â–‡â–‡â–‡â–‡â–†â–†â–†â–…â–…â–…â–…â–…â–„â–„â–„â–„â–ƒâ–„â–ƒâ–ƒâ–ƒâ–ƒâ–‚â–ƒâ–‚â–‚â–‚â–‚â–‚â–‚â–‚â–â–â–â–â–â–
wandb: 
wandb: Run summary:
wandb:     e_F1 62.43093
wandb:   e_loss 0.92908
wandb:     t_F1 73.21078
wandb:   t_loss 0.74419
wandb: 
wandb: Synced 4 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Synced rich-firefly-2: https://wandb.ai/yinanazhou/xl_512_bs_8_lr_1e06_es_10_lc_False_nr_True_sr_False_stem_False_lemma_False_repeat_3_fold_2/runs/2csjp828
wandb: Find logs at: ./wandb/run-20220319_022205-2csjp828/logs/debug.log
wandb: 

wandb: wandb version 0.12.11 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
2022-03-19 03:58:00.630217: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1
wandb: Tracking run with wandb version 0.12.5
wandb: Syncing run feasible-cosmos-2
wandb: â­ï¸ View project at https://wandb.ai/yinanazhou/xl_512_bs_8_lr_1e06_es_10_lc_False_nr_True_sr_False_stem_False_lemma_False_repeat_4_fold_1
wandb: ðŸš€ View run at https://wandb.ai/yinanazhou/xl_512_bs_8_lr_1e06_es_10_lc_False_nr_True_sr_False_stem_False_lemma_False_repeat_4_fold_1/runs/2c7hdsdl
wandb: Run data is saved locally in /project/6002780/yinan/Thesis_MER_Lyrics/lyric-emotion/wandb/run-20220319_035756-2c7hdsdl
wandb: Run `wandb offline` to turn off syncing.

Validation loss decreased (inf --> 1.426866).  Saving model ...
Validation loss decreased (1.426866 --> 1.412118).  Saving model ...
Validation loss decreased (1.412118 --> 1.401480).  Saving model ...
Validation loss decreased (1.401480 --> 1.392779).  Saving model ...
Validation loss decreased (1.392779 --> 1.385601).  Saving model ...
Validation loss decreased (1.385601 --> 1.379160).  Saving model ...
Validation loss decreased (1.379160 --> 1.373559).  Saving model ...
Validation loss decreased (1.373559 --> 1.368362).  Saving model ...
Validation loss decreased (1.368362 --> 1.363529).  Saving model ...
Validation loss decreased (1.363529 --> 1.358827).  Saving model ...
Validation loss decreased (1.358827 --> 1.353681).  Saving model ...
Validation loss decreased (1.353681 --> 1.348634).  Saving model ...
Validation loss decreased (1.348634 --> 1.343826).  Saving model ...
Validation loss decreased (1.343826 --> 1.338572).  Saving model ...
Validation loss decreased (1.338572 --> 1.332889).  Saving model ...
Validation loss decreased (1.332889 --> 1.327091).  Saving model ...
Validation loss decreased (1.327091 --> 1.321022).  Saving model ...
Validation loss decreased (1.321022 --> 1.315104).  Saving model ...
Validation loss decreased (1.315104 --> 1.309042).  Saving model ...
Validation loss decreased (1.309042 --> 1.301803).  Saving model ...
Validation loss decreased (1.301803 --> 1.295294).  Saving model ...
Validation loss decreased (1.295294 --> 1.287457).  Saving model ...
Validation loss decreased (1.287457 --> 1.280426).  Saving model ...
Validation loss decreased (1.280426 --> 1.274093).  Saving model ...
Validation loss decreased (1.274093 --> 1.267553).  Saving model ...
Validation loss decreased (1.267553 --> 1.260872).  Saving model ...
Validation loss decreased (1.260872 --> 1.253907).  Saving model ...
Validation loss decreased (1.253907 --> 1.247347).  Saving model ...
Validation loss decreased (1.247347 --> 1.240299).  Saving model ...
Validation loss decreased (1.240299 --> 1.233852).  Saving model ...
Validation loss decreased (1.233852 --> 1.227137).  Saving model ...
Validation loss decreased (1.227137 --> 1.221417).  Saving model ...
Validation loss decreased (1.221417 --> 1.216228).  Saving model ...
Validation loss decreased (1.216228 --> 1.210934).  Saving model ...
Validation loss decreased (1.210934 --> 1.205380).  Saving model ...
Validation loss decreased (1.205380 --> 1.199058).  Saving model ...
Validation loss decreased (1.199058 --> 1.194242).  Saving model ...
Validation loss decreased (1.194242 --> 1.188918).  Saving model ...
Validation loss decreased (1.188918 --> 1.183870).  Saving model ...
Validation loss decreased (1.183870 --> 1.179082).  Saving model ...
Validation loss decreased (1.179082 --> 1.174628).  Saving model ...
Validation loss decreased (1.174628 --> 1.170309).  Saving model ...
Validation loss decreased (1.170309 --> 1.164358).  Saving model ...
Validation loss decreased (1.164358 --> 1.159486).  Saving model ...
Validation loss decreased (1.159486 --> 1.156186).  Saving model ...
Validation loss decreased (1.156186 --> 1.151931).  Saving model ...
Validation loss decreased (1.151931 --> 1.147018).  Saving model ...
Validation loss decreased (1.147018 --> 1.142245).  Saving model ...
Validation loss decreased (1.142245 --> 1.138654).  Saving model ...
Validation loss decreased (1.138654 --> 1.134482).  Saving model ...
Validation loss decreased (1.134482 --> 1.131267).  Saving model ...
Validation loss decreased (1.131267 --> 1.126703).  Saving model ...
Validation loss decreased (1.126703 --> 1.121714).  Saving model ...
Validation loss decreased (1.121714 --> 1.117843).  Saving model ...
Validation loss decreased (1.117843 --> 1.113666).  Saving model ...
Validation loss decreased (1.113666 --> 1.110383).  Saving model ...
Validation loss decreased (1.110383 --> 1.107551).  Saving model ...
Validation loss decreased (1.107551 --> 1.104290).  Saving model ...
Validation loss decreased (1.104290 --> 1.100173).  Saving model ...
Validation loss decreased (1.100173 --> 1.096758).  Saving model ...
Validation loss decreased (1.096758 --> 1.093215).  Saving model ...
Validation loss decreased (1.093215 --> 1.088959).  Saving model ...
Validation loss decreased (1.088959 --> 1.085641).  Saving model ...
Validation loss decreased (1.085641 --> 1.082836).  Saving model ...
Validation loss decreased (1.082836 --> 1.080031).  Saving model ...
Validation loss decreased (1.080031 --> 1.076923).  Saving model ...
Validation loss decreased (1.076923 --> 1.073746).  Saving model ...
Validation loss decreased (1.073746 --> 1.070904).  Saving model ...
Validation loss decreased (1.070904 --> 1.068521).  Saving model ...
Validation loss decreased (1.068521 --> 1.066673).  Saving model ...
Validation loss decreased (1.066673 --> 1.064895).  Saving model ...
Validation loss decreased (1.064895 --> 1.062514).  Saving model ...
Validation loss decreased (1.062514 --> 1.059119).  Saving model ...
Validation loss decreased (1.059119 --> 1.057251).  Saving model ...
Validation loss decreased (1.057251 --> 1.053964).  Saving model ...
Validation loss decreased (1.053964 --> 1.050980).  Saving model ...
Validation loss decreased (1.050980 --> 1.048971).  Saving model ...
Validation loss decreased (1.048971 --> 1.046820).  Saving model ...
Validation loss decreased (1.046820 --> 1.045278).  Saving model ...
Validation loss decreased (1.045278 --> 1.044255).  Saving model ...
Validation loss decreased (1.044255 --> 1.042100).  Saving model ...
Validation loss decreased (1.042100 --> 1.039713).  Saving model ...
Validation loss decreased (1.039713 --> 1.037472).  Saving model ...
Validation loss decreased (1.037472 --> 1.035178).  Saving model ...
Validation loss decreased (1.035178 --> 1.033591).  Saving model ...
Validation loss decreased (1.033591 --> 1.032248).  Saving model ...
Validation loss decreased (1.032248 --> 1.029764).  Saving model ...
Validation loss decreased (1.029764 --> 1.028191).  Saving model ...
Validation loss decreased (1.028191 --> 1.026748).  Saving model ...
Validation loss decreased (1.026748 --> 1.024074).  Saving model ...
Validation loss decreased (1.024074 --> 1.022888).  Saving model ...
Validation loss decreased (1.022888 --> 1.021664).  Saving model ...
Validation loss decreased (1.021664 --> 1.020978).  Saving model ...
Validation loss decreased (1.020978 --> 1.020057).  Saving model ...
EarlyStopping counter: 1 out of 10.0
Validation loss decreased (1.020057 --> 1.017845).  Saving model ...
Validation loss decreased (1.017845 --> 1.016634).  Saving model ...
Validation loss decreased (1.016634 --> 1.016613).  Saving model ...
Validation loss decreased (1.016613 --> 1.013828).  Saving model ...
Validation loss decreased (1.013828 --> 1.012384).  Saving model ...
Validation loss decreased (1.012384 --> 1.011650).  Saving model ...
Validation loss decreased (1.011650 --> 1.010018).  Saving model ...
Validation loss decreased (1.010018 --> 1.009776).  Saving model ...
Validation loss decreased (1.009776 --> 1.009085).  Saving model ...
EarlyStopping counter: 1 out of 10.0
Validation loss decreased (1.009085 --> 1.007580).  Saving model ...
Validation loss decreased (1.007580 --> 1.006154).  Saving model ...
Validation loss decreased (1.006154 --> 1.004617).  Saving model ...
Validation loss decreased (1.004617 --> 1.003895).  Saving model ...
EarlyStopping counter: 1 out of 10.0
Validation loss decreased (1.003895 --> 1.003590).  Saving model ...
EarlyStopping counter: 1 out of 10.0
Validation loss decreased (1.003590 --> 1.002174).  Saving model ...
EarlyStopping counter: 1 out of 10.0
EarlyStopping counter: 2 out of 10.0
Validation loss decreased (1.002174 --> 1.000531).  Saving model ...
Validation loss decreased (1.000531 --> 0.999106).  Saving model ...
Validation loss decreased (0.999106 --> 0.997720).  Saving model ...
EarlyStopping counter: 1 out of 10.0
EarlyStopping counter: 2 out of 10.0
EarlyStopping counter: 3 out of 10.0
EarlyStopping counter: 4 out of 10.0
EarlyStopping counter: 5 out of 10.0
Validation loss decreased (0.997720 --> 0.996448).  Saving model ...
Validation loss decreased (0.996448 --> 0.996151).  Saving model ...
Validation loss decreased (0.996151 --> 0.995411).  Saving model ...
EarlyStopping counter: 1 out of 10.0
EarlyStopping counter: 2 out of 10.0
Validation loss decreased (0.995411 --> 0.993897).  Saving model ...
EarlyStopping counter: 1 out of 10.0
EarlyStopping counter: 2 out of 10.0
Validation loss decreased (0.993897 --> 0.993814).  Saving model ...
EarlyStopping counter: 1 out of 10.0
Validation loss decreased (0.993814 --> 0.993778).  Saving model ...
EarlyStopping counter: 1 out of 10.0
EarlyStopping counter: 2 out of 10.0
Validation loss decreased (0.993778 --> 0.992958).  Saving model ...
Validation loss decreased (0.992958 --> 0.990773).  Saving model ...
EarlyStopping counter: 1 out of 10.0
EarlyStopping counter: 2 out of 10.0
EarlyStopping counter: 3 out of 10.0
EarlyStopping counter: 4 out of 10.0
EarlyStopping counter: 5 out of 10.0
EarlyStopping counter: 6 out of 10.0
EarlyStopping counter: 7 out of 10.0
EarlyStopping counter: 8 out of 10.0
EarlyStopping counter: 9 out of 10.0
EarlyStopping counter: 10 out of 10.0
/localscratch/yinan.29019300.0/env/lib/python3.7/site-packages/torch/nn/functional.py:1794: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.
  warnings.warn("nn.functional.tanh is deprecated. Use torch.tanh instead.")
wandb: Waiting for W&B process to finish, PID 56320... (success).
wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: \ 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: | 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: / 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: \ 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: | 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: / 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: \ 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: | 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: / 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb:                                                                                
wandb: Run history:
wandb:     e_F1 â–â–‚â–ƒâ–„â–…â–…â–…â–†â–†â–†â–†â–†â–†â–†â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ
wandb:   e_loss â–ˆâ–ˆâ–‡â–‡â–‡â–†â–†â–…â–…â–…â–„â–„â–„â–ƒâ–ƒâ–ƒâ–ƒâ–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:     t_F1 â–â–â–‚â–‚â–ƒâ–ƒâ–„â–„â–…â–…â–„â–…â–…â–…â–…â–†â–†â–†â–†â–†â–†â–‡â–†â–†â–†â–†â–‡â–‡â–‡â–‡â–‡â–‡â–ˆâ–‡â–ˆâ–ˆâ–‡â–ˆâ–ˆâ–‡
wandb:   t_loss â–ˆâ–ˆâ–ˆâ–‡â–‡â–‡â–‡â–†â–†â–†â–†â–…â–…â–…â–…â–„â–„â–„â–„â–„â–„â–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–â–â–â–â–â–
wandb: 
wandb: Run summary:
wandb:     e_F1 57.06999
wandb:   e_loss 0.99885
wandb:     t_F1 69.72273
wandb:   t_loss 0.73242
wandb: 
wandb: Synced 4 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Synced feasible-cosmos-2: https://wandb.ai/yinanazhou/xl_512_bs_8_lr_1e06_es_10_lc_False_nr_True_sr_False_stem_False_lemma_False_repeat_4_fold_1/runs/2c7hdsdl
wandb: Find logs at: ./wandb/run-20220319_035756-2c7hdsdl/logs/debug.log
wandb: 

wandb: wandb version 0.12.11 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
2022-03-19 05:35:35.907623: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1
wandb: Tracking run with wandb version 0.12.5
wandb: Syncing run stellar-snowball-2
wandb: â­ï¸ View project at https://wandb.ai/yinanazhou/xl_512_bs_8_lr_1e06_es_10_lc_False_nr_True_sr_False_stem_False_lemma_False_repeat_4_fold_2
wandb: ðŸš€ View run at https://wandb.ai/yinanazhou/xl_512_bs_8_lr_1e06_es_10_lc_False_nr_True_sr_False_stem_False_lemma_False_repeat_4_fold_2/runs/grdv0q5w
wandb: Run data is saved locally in /project/6002780/yinan/Thesis_MER_Lyrics/lyric-emotion/wandb/run-20220319_053532-grdv0q5w
wandb: Run `wandb offline` to turn off syncing.

Validation loss decreased (inf --> 1.421824).  Saving model ...
Validation loss decreased (1.421824 --> 1.399367).  Saving model ...
Validation loss decreased (1.399367 --> 1.384267).  Saving model ...
Validation loss decreased (1.384267 --> 1.373715).  Saving model ...
Validation loss decreased (1.373715 --> 1.364930).  Saving model ...
Validation loss decreased (1.364930 --> 1.358191).  Saving model ...
Validation loss decreased (1.358191 --> 1.352431).  Saving model ...
Validation loss decreased (1.352431 --> 1.347460).  Saving model ...
Validation loss decreased (1.347460 --> 1.341976).  Saving model ...
Validation loss decreased (1.341976 --> 1.336278).  Saving model ...
Validation loss decreased (1.336278 --> 1.331288).  Saving model ...
Validation loss decreased (1.331288 --> 1.325468).  Saving model ...
Validation loss decreased (1.325468 --> 1.320014).  Saving model ...
Validation loss decreased (1.320014 --> 1.314812).  Saving model ...
Validation loss decreased (1.314812 --> 1.310189).  Saving model ...
Validation loss decreased (1.310189 --> 1.303515).  Saving model ...
Validation loss decreased (1.303515 --> 1.298482).  Saving model ...
Validation loss decreased (1.298482 --> 1.292040).  Saving model ...
Validation loss decreased (1.292040 --> 1.284261).  Saving model ...
Validation loss decreased (1.284261 --> 1.277707).  Saving model ...
Validation loss decreased (1.277707 --> 1.270599).  Saving model ...
Validation loss decreased (1.270599 --> 1.262456).  Saving model ...
Validation loss decreased (1.262456 --> 1.254631).  Saving model ...
Validation loss decreased (1.254631 --> 1.246498).  Saving model ...
Validation loss decreased (1.246498 --> 1.238387).  Saving model ...
Validation loss decreased (1.238387 --> 1.229829).  Saving model ...
Validation loss decreased (1.229829 --> 1.224635).  Saving model ...
Validation loss decreased (1.224635 --> 1.215028).  Saving model ...
Validation loss decreased (1.215028 --> 1.208590).  Saving model ...
Validation loss decreased (1.208590 --> 1.200781).  Saving model ...
Validation loss decreased (1.200781 --> 1.192039).  Saving model ...
Validation loss decreased (1.192039 --> 1.183935).  Saving model ...
Validation loss decreased (1.183935 --> 1.176349).  Saving model ...
Validation loss decreased (1.176349 --> 1.169493).  Saving model ...
Validation loss decreased (1.169493 --> 1.163544).  Saving model ...
Validation loss decreased (1.163544 --> 1.157340).  Saving model ...
Validation loss decreased (1.157340 --> 1.151702).  Saving model ...
Validation loss decreased (1.151702 --> 1.146562).  Saving model ...
Validation loss decreased (1.146562 --> 1.140633).  Saving model ...
Validation loss decreased (1.140633 --> 1.136392).  Saving model ...
Validation loss decreased (1.136392 --> 1.134263).  Saving model ...
Validation loss decreased (1.134263 --> 1.126818).  Saving model ...
Validation loss decreased (1.126818 --> 1.119031).  Saving model ...
Validation loss decreased (1.119031 --> 1.113179).  Saving model ...
Validation loss decreased (1.113179 --> 1.108805).  Saving model ...
Validation loss decreased (1.108805 --> 1.106824).  Saving model ...
Validation loss decreased (1.106824 --> 1.103505).  Saving model ...
Validation loss decreased (1.103505 --> 1.098015).  Saving model ...
Validation loss decreased (1.098015 --> 1.092608).  Saving model ...
Validation loss decreased (1.092608 --> 1.089140).  Saving model ...
Validation loss decreased (1.089140 --> 1.086956).  Saving model ...
Validation loss decreased (1.086956 --> 1.079988).  Saving model ...
Validation loss decreased (1.079988 --> 1.075231).  Saving model ...
Validation loss decreased (1.075231 --> 1.074140).  Saving model ...
Validation loss decreased (1.074140 --> 1.067927).  Saving model ...
Validation loss decreased (1.067927 --> 1.061494).  Saving model ...
Validation loss decreased (1.061494 --> 1.058642).  Saving model ...
Validation loss decreased (1.058642 --> 1.054840).  Saving model ...
Validation loss decreased (1.054840 --> 1.050956).  Saving model ...
Validation loss decreased (1.050956 --> 1.048895).  Saving model ...
Validation loss decreased (1.048895 --> 1.045343).  Saving model ...
Validation loss decreased (1.045343 --> 1.042053).  Saving model ...
Validation loss decreased (1.042053 --> 1.041783).  Saving model ...
Validation loss decreased (1.041783 --> 1.036936).  Saving model ...
Validation loss decreased (1.036936 --> 1.034704).  Saving model ...
Validation loss decreased (1.034704 --> 1.031589).  Saving model ...
Validation loss decreased (1.031589 --> 1.027983).  Saving model ...
Validation loss decreased (1.027983 --> 1.026988).  Saving model ...
Validation loss decreased (1.026988 --> 1.025440).  Saving model ...
Validation loss decreased (1.025440 --> 1.021522).  Saving model ...
Validation loss decreased (1.021522 --> 1.020453).  Saving model ...
Validation loss decreased (1.020453 --> 1.018086).  Saving model ...
Validation loss decreased (1.018086 --> 1.014558).  Saving model ...
Validation loss decreased (1.014558 --> 1.014400).  Saving model ...
Validation loss decreased (1.014400 --> 1.009538).  Saving model ...
Validation loss decreased (1.009538 --> 1.005998).  Saving model ...
Validation loss decreased (1.005998 --> 1.005560).  Saving model ...
EarlyStopping counter: 1 out of 10.0
Validation loss decreased (1.005560 --> 1.004740).  Saving model ...
Validation loss decreased (1.004740 --> 1.002331).  Saving model ...
Validation loss decreased (1.002331 --> 0.999342).  Saving model ...
EarlyStopping counter: 1 out of 10.0
EarlyStopping counter: 2 out of 10.0
Validation loss decreased (0.999342 --> 0.997468).  Saving model ...
EarlyStopping counter: 1 out of 10.0
EarlyStopping counter: 2 out of 10.0
Validation loss decreased (0.997468 --> 0.993343).  Saving model ...
Validation loss decreased (0.993343 --> 0.989324).  Saving model ...
Validation loss decreased (0.989324 --> 0.988004).  Saving model ...
EarlyStopping counter: 1 out of 10.0
EarlyStopping counter: 2 out of 10.0
EarlyStopping counter: 3 out of 10.0
EarlyStopping counter: 4 out of 10.0
Validation loss decreased (0.988004 --> 0.987614).  Saving model ...
Validation loss decreased (0.987614 --> 0.986629).  Saving model ...
EarlyStopping counter: 1 out of 10.0
EarlyStopping counter: 2 out of 10.0
EarlyStopping counter: 3 out of 10.0
EarlyStopping counter: 4 out of 10.0
EarlyStopping counter: 5 out of 10.0
EarlyStopping counter: 6 out of 10.0
Validation loss decreased (0.986629 --> 0.986349).  Saving model ...
Validation loss decreased (0.986349 --> 0.985505).  Saving model ...
EarlyStopping counter: 1 out of 10.0
EarlyStopping counter: 2 out of 10.0
Validation loss decreased (0.985505 --> 0.984140).  Saving model ...
EarlyStopping counter: 1 out of 10.0
Validation loss decreased (0.984140 --> 0.982179).  Saving model ...
EarlyStopping counter: 1 out of 10.0
EarlyStopping counter: 2 out of 10.0
Validation loss decreased (0.982179 --> 0.981532).  Saving model ...
EarlyStopping counter: 1 out of 10.0
Validation loss decreased (0.981532 --> 0.981511).  Saving model ...
EarlyStopping counter: 1 out of 10.0
EarlyStopping counter: 2 out of 10.0
Validation loss decreased (0.981511 --> 0.978155).  Saving model ...
EarlyStopping counter: 1 out of 10.0
EarlyStopping counter: 2 out of 10.0
EarlyStopping counter: 3 out of 10.0
EarlyStopping counter: 4 out of 10.0
EarlyStopping counter: 5 out of 10.0
EarlyStopping counter: 6 out of 10.0
EarlyStopping counter: 7 out of 10.0
EarlyStopping counter: 8 out of 10.0
EarlyStopping counter: 9 out of 10.0
EarlyStopping counter: 10 out of 10.0
/localscratch/yinan.29019300.0/env/lib/python3.7/site-packages/torch/nn/functional.py:1794: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.
  warnings.warn("nn.functional.tanh is deprecated. Use torch.tanh instead.")
wandb: Waiting for W&B process to finish, PID 61660... (success).
wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: \ 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: | 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: / 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: \ 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: | 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: / 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: \ 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: | 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: / 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb:                                                                                
wandb: Run history:
wandb:     e_F1 â–â–ƒâ–…â–…â–†â–†â–†â–†â–†â–†â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–ˆâ–‡â–‡â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ
wandb:   e_loss â–ˆâ–‡â–‡â–‡â–†â–†â–†â–…â–…â–…â–„â–„â–„â–ƒâ–ƒâ–ƒâ–ƒâ–‚â–‚â–‚â–‚â–‚â–‚â–‚â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:     t_F1 â–â–‚â–ƒâ–ƒâ–ƒâ–„â–„â–„â–„â–„â–…â–…â–…â–†â–…â–†â–†â–†â–‡â–†â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–ˆâ–‡â–‡â–‡â–‡â–ˆâ–ˆâ–ˆâ–ˆ
wandb:   t_loss â–ˆâ–ˆâ–‡â–‡â–‡â–‡â–†â–†â–†â–†â–…â–…â–…â–…â–…â–„â–„â–„â–„â–„â–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–â–â–â–â–
wandb: 
wandb: Run summary:
wandb:     e_F1 60.01219
wandb:   e_loss 0.98072
wandb:     t_F1 71.30676
wandb:   t_loss 0.7535
wandb: 
wandb: Synced 4 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Synced stellar-snowball-2: https://wandb.ai/yinanazhou/xl_512_bs_8_lr_1e06_es_10_lc_False_nr_True_sr_False_stem_False_lemma_False_repeat_4_fold_2/runs/grdv0q5w
wandb: Find logs at: ./wandb/run-20220319_053532-grdv0q5w/logs/debug.log
wandb: 

wandb: wandb version 0.12.11 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
2022-03-19 06:58:36.067486: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1
wandb: Tracking run with wandb version 0.12.5
wandb: Syncing run hardy-dust-2
wandb: â­ï¸ View project at https://wandb.ai/yinanazhou/xl_512_bs_8_lr_1e06_es_10_lc_False_nr_True_sr_False_stem_False_lemma_False_repeat_5_fold_1
wandb: ðŸš€ View run at https://wandb.ai/yinanazhou/xl_512_bs_8_lr_1e06_es_10_lc_False_nr_True_sr_False_stem_False_lemma_False_repeat_5_fold_1/runs/34kljjis
wandb: Run data is saved locally in /project/6002780/yinan/Thesis_MER_Lyrics/lyric-emotion/wandb/run-20220319_065830-34kljjis
wandb: Run `wandb offline` to turn off syncing.

Validation loss decreased (inf --> 1.446660).  Saving model ...
Validation loss decreased (1.446660 --> 1.420528).  Saving model ...
Validation loss decreased (1.420528 --> 1.402301).  Saving model ...
Validation loss decreased (1.402301 --> 1.387703).  Saving model ...
Validation loss decreased (1.387703 --> 1.377899).  Saving model ...
Validation loss decreased (1.377899 --> 1.369897).  Saving model ...
Validation loss decreased (1.369897 --> 1.362575).  Saving model ...
Validation loss decreased (1.362575 --> 1.356564).  Saving model ...
Validation loss decreased (1.356564 --> 1.351546).  Saving model ...
Validation loss decreased (1.351546 --> 1.346442).  Saving model ...
Validation loss decreased (1.346442 --> 1.341714).  Saving model ...
Validation loss decreased (1.341714 --> 1.336984).  Saving model ...
Validation loss decreased (1.336984 --> 1.332289).  Saving model ...
Validation loss decreased (1.332289 --> 1.327510).  Saving model ...
Validation loss decreased (1.327510 --> 1.322486).  Saving model ...
Validation loss decreased (1.322486 --> 1.317282).  Saving model ...
Validation loss decreased (1.317282 --> 1.312171).  Saving model ...
Validation loss decreased (1.312171 --> 1.306724).  Saving model ...
Validation loss decreased (1.306724 --> 1.300888).  Saving model ...
Validation loss decreased (1.300888 --> 1.294897).  Saving model ...
Validation loss decreased (1.294897 --> 1.288487).  Saving model ...
Validation loss decreased (1.288487 --> 1.282516).  Saving model ...
Validation loss decreased (1.282516 --> 1.275862).  Saving model ...
Validation loss decreased (1.275862 --> 1.268785).  Saving model ...
Validation loss decreased (1.268785 --> 1.261676).  Saving model ...
Validation loss decreased (1.261676 --> 1.254948).  Saving model ...
Validation loss decreased (1.254948 --> 1.246990).  Saving model ...
Validation loss decreased (1.246990 --> 1.239410).  Saving model ...
Validation loss decreased (1.239410 --> 1.232005).  Saving model ...
Validation loss decreased (1.232005 --> 1.224242).  Saving model ...
Validation loss decreased (1.224242 --> 1.217871).  Saving model ...
Validation loss decreased (1.217871 --> 1.210536).  Saving model ...
Validation loss decreased (1.210536 --> 1.202468).  Saving model ...
Validation loss decreased (1.202468 --> 1.195093).  Saving model ...
Validation loss decreased (1.195093 --> 1.187379).  Saving model ...
Validation loss decreased (1.187379 --> 1.179173).  Saving model ...
Validation loss decreased (1.179173 --> 1.172494).  Saving model ...
Validation loss decreased (1.172494 --> 1.166402).  Saving model ...
Validation loss decreased (1.166402 --> 1.159095).  Saving model ...
Validation loss decreased (1.159095 --> 1.151674).  Saving model ...
Validation loss decreased (1.151674 --> 1.146246).  Saving model ...
Validation loss decreased (1.146246 --> 1.139995).  Saving model ...
Validation loss decreased (1.139995 --> 1.133781).  Saving model ...
Validation loss decreased (1.133781 --> 1.128681).  Saving model ...
Validation loss decreased (1.128681 --> 1.123426).  Saving model ...
Validation loss decreased (1.123426 --> 1.118089).  Saving model ...
Validation loss decreased (1.118089 --> 1.112606).  Saving model ...
Validation loss decreased (1.112606 --> 1.107047).  Saving model ...
Validation loss decreased (1.107047 --> 1.103127).  Saving model ...
Validation loss decreased (1.103127 --> 1.097519).  Saving model ...
Validation loss decreased (1.097519 --> 1.091364).  Saving model ...
Validation loss decreased (1.091364 --> 1.086793).  Saving model ...
Validation loss decreased (1.086793 --> 1.081614).  Saving model ...
Validation loss decreased (1.081614 --> 1.078190).  Saving model ...
Validation loss decreased (1.078190 --> 1.074189).  Saving model ...
Validation loss decreased (1.074189 --> 1.069557).  Saving model ...
Validation loss decreased (1.069557 --> 1.066617).  Saving model ...
Validation loss decreased (1.066617 --> 1.063551).  Saving model ...
Validation loss decreased (1.063551 --> 1.060122).  Saving model ...
Validation loss decreased (1.060122 --> 1.056000).  Saving model ...
Validation loss decreased (1.056000 --> 1.052777).  Saving model ...
Validation loss decreased (1.052777 --> 1.049838).  Saving model ...
Validation loss decreased (1.049838 --> 1.045733).  Saving model ...
Validation loss decreased (1.045733 --> 1.044072).  Saving model ...
Validation loss decreased (1.044072 --> 1.040816).  Saving model ...
Validation loss decreased (1.040816 --> 1.037441).  Saving model ...
Validation loss decreased (1.037441 --> 1.033265).  Saving model ...
Validation loss decreased (1.033265 --> 1.030476).  Saving model ...
Validation loss decreased (1.030476 --> 1.025079).  Saving model ...
Validation loss decreased (1.025079 --> 1.021626).  Saving model ...
Validation loss decreased (1.021626 --> 1.018824).  Saving model ...
Validation loss decreased (1.018824 --> 1.014100).  Saving model ...
Validation loss decreased (1.014100 --> 1.010735).  Saving model ...
Validation loss decreased (1.010735 --> 1.008953).  Saving model ...
Validation loss decreased (1.008953 --> 1.005399).  Saving model ...
Validation loss decreased (1.005399 --> 1.002322).  Saving model ...
Validation loss decreased (1.002322 --> 0.999934).  Saving model ...
Validation loss decreased (0.999934 --> 0.997710).  Saving model ...
Validation loss decreased (0.997710 --> 0.995144).  Saving model ...
Validation loss decreased (0.995144 --> 0.991493).  Saving model ...
Validation loss decreased (0.991493 --> 0.988530).  Saving model ...
Validation loss decreased (0.988530 --> 0.986220).  Saving model ...
Validation loss decreased (0.986220 --> 0.984715).  Saving model ...
Validation loss decreased (0.984715 --> 0.982674).  Saving model ...
Validation loss decreased (0.982674 --> 0.979101).  Saving model ...
Validation loss decreased (0.979101 --> 0.977064).  Saving model ...
Validation loss decreased (0.977064 --> 0.974612).  Saving model ...
Validation loss decreased (0.974612 --> 0.971863).  Saving model ...
Validation loss decreased (0.971863 --> 0.970984).  Saving model ...
Validation loss decreased (0.970984 --> 0.968693).  Saving model ...
Validation loss decreased (0.968693 --> 0.964840).  Saving model ...
Validation loss decreased (0.964840 --> 0.961966).  Saving model ...
Validation loss decreased (0.961966 --> 0.960461).  Saving model ...
Validation loss decreased (0.960461 --> 0.959994).  Saving model ...
Validation loss decreased (0.959994 --> 0.959505).  Saving model ...
Validation loss decreased (0.959505 --> 0.956919).  Saving model ...
Validation loss decreased (0.956919 --> 0.955834).  Saving model ...
Validation loss decreased (0.955834 --> 0.954384).  Saving model ...
Validation loss decreased (0.954384 --> 0.951828).  Saving model ...
Validation loss decreased (0.951828 --> 0.948909).  Saving model ...
Validation loss decreased (0.948909 --> 0.947245).  Saving model ...
Validation loss decreased (0.947245 --> 0.947174).  Saving model ...
Validation loss decreased (0.947174 --> 0.946284).  Saving model ...
Validation loss decreased (0.946284 --> 0.944694).  Saving model ...
Validation loss decreased (0.944694 --> 0.943673).  Saving model ...
Validation loss decreased (0.943673 --> 0.941790).  Saving model ...
Validation loss decreased (0.941790 --> 0.941010).  Saving model ...
Validation loss decreased (0.941010 --> 0.939816).  Saving model ...
Validation loss decreased (0.939816 --> 0.937929).  Saving model ...
Validation loss decreased (0.937929 --> 0.937687).  Saving model ...
Validation loss decreased (0.937687 --> 0.935201).  Saving model ...
Validation loss decreased (0.935201 --> 0.933605).  Saving model ...
Validation loss decreased (0.933605 --> 0.933120).  Saving model ...
Validation loss decreased (0.933120 --> 0.932095).  Saving model ...
Validation loss decreased (0.932095 --> 0.931222).  Saving model ...
Validation loss decreased (0.931222 --> 0.930441).  Saving model ...
Validation loss decreased (0.930441 --> 0.929016).  Saving model ...
Validation loss decreased (0.929016 --> 0.928495).  Saving model ...
Validation loss decreased (0.928495 --> 0.927659).  Saving model ...
Validation loss decreased (0.927659 --> 0.926899).  Saving model ...
Validation loss decreased (0.926899 --> 0.925864).  Saving model ...
Validation loss decreased (0.925864 --> 0.925064).  Saving model ...
Validation loss decreased (0.925064 --> 0.924182).  Saving model ...
Validation loss decreased (0.924182 --> 0.924038).  Saving model ...
Validation loss decreased (0.924038 --> 0.923405).  Saving model ...
Validation loss decreased (0.923405 --> 0.922668).  Saving model ...
Validation loss decreased (0.922668 --> 0.921985).  Saving model ...
Validation loss decreased (0.921985 --> 0.921396).  Saving model ...
Validation loss decreased (0.921396 --> 0.921060).  Saving model ...
Validation loss decreased (0.921060 --> 0.920910).  Saving model ...
Validation loss decreased (0.920910 --> 0.920708).  Saving model ...
EarlyStopping counter: 1 out of 10.0
EarlyStopping counter: 2 out of 10.0
Validation loss decreased (0.920708 --> 0.920390).  Saving model ...
Validation loss decreased (0.920390 --> 0.920006).  Saving model ...
EarlyStopping counter: 1 out of 10.0
EarlyStopping counter: 2 out of 10.0
Validation loss decreased (0.920006 --> 0.919743).  Saving model ...
EarlyStopping counter: 1 out of 10.0
EarlyStopping counter: 2 out of 10.0
EarlyStopping counter: 3 out of 10.0
EarlyStopping counter: 4 out of 10.0
EarlyStopping counter: 5 out of 10.0
EarlyStopping counter: 6 out of 10.0
EarlyStopping counter: 7 out of 10.0
EarlyStopping counter: 8 out of 10.0
EarlyStopping counter: 9 out of 10.0
EarlyStopping counter: 10 out of 10.0
/localscratch/yinan.29019300.0/env/lib/python3.7/site-packages/torch/nn/functional.py:1794: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.
  warnings.warn("nn.functional.tanh is deprecated. Use torch.tanh instead.")
wandb: Waiting for W&B process to finish, PID 66177... (success).
wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: \ 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: | 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: / 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: \ 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: | 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: / 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: \ 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: | 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: / 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb:                                                                                
wandb: Run history:
wandb:     e_F1 â–â–‚â–„â–„â–…â–…â–…â–†â–†â–†â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ
wandb:   e_loss â–ˆâ–ˆâ–‡â–‡â–‡â–†â–†â–…â–…â–…â–„â–„â–„â–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–‚â–‚â–‚â–‚â–‚â–‚â–‚â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:     t_F1 â–â–â–‚â–ƒâ–ƒâ–ƒâ–„â–„â–„â–„â–…â–†â–…â–†â–…â–†â–†â–†â–†â–†â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–ˆâ–‡â–ˆâ–‡â–ˆâ–‡â–ˆâ–ˆâ–ˆâ–ˆ
wandb:   t_loss â–ˆâ–ˆâ–‡â–‡â–‡â–‡â–‡â–†â–†â–†â–†â–…â–…â–…â–…â–„â–„â–„â–„â–„â–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–â–â–â–
wandb: 
wandb: Run summary:
wandb:     e_F1 61.49326
wandb:   e_loss 0.92174
wandb:     t_F1 72.12737
wandb:   t_loss 0.74504
wandb: 
wandb: Synced 4 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Synced hardy-dust-2: https://wandb.ai/yinanazhou/xl_512_bs_8_lr_1e06_es_10_lc_False_nr_True_sr_False_stem_False_lemma_False_repeat_5_fold_1/runs/34kljjis
wandb: Find logs at: ./wandb/run-20220319_065830-34kljjis/logs/debug.log
wandb: 

wandb: wandb version 0.12.11 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
2022-03-19 08:36:31.267503: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1
wandb: Tracking run with wandb version 0.12.5
wandb: Syncing run faithful-terrain-2
wandb: â­ï¸ View project at https://wandb.ai/yinanazhou/xl_512_bs_8_lr_1e06_es_10_lc_False_nr_True_sr_False_stem_False_lemma_False_repeat_5_fold_2
wandb: ðŸš€ View run at https://wandb.ai/yinanazhou/xl_512_bs_8_lr_1e06_es_10_lc_False_nr_True_sr_False_stem_False_lemma_False_repeat_5_fold_2/runs/yrfmwcn9
wandb: Run data is saved locally in /project/6002780/yinan/Thesis_MER_Lyrics/lyric-emotion/wandb/run-20220319_083628-yrfmwcn9
wandb: Run `wandb offline` to turn off syncing.

Validation loss decreased (inf --> 1.405569).  Saving model ...
Validation loss decreased (1.405569 --> 1.395980).  Saving model ...
Validation loss decreased (1.395980 --> 1.388729).  Saving model ...
Validation loss decreased (1.388729 --> 1.383271).  Saving model ...
Validation loss decreased (1.383271 --> 1.377795).  Saving model ...
Validation loss decreased (1.377795 --> 1.373362).  Saving model ...
Validation loss decreased (1.373362 --> 1.368722).  Saving model ...
Validation loss decreased (1.368722 --> 1.364557).  Saving model ...
Validation loss decreased (1.364557 --> 1.360372).  Saving model ...
Validation loss decreased (1.360372 --> 1.356265).  Saving model ...
Validation loss decreased (1.356265 --> 1.351968).  Saving model ...
Validation loss decreased (1.351968 --> 1.347342).  Saving model ...
Validation loss decreased (1.347342 --> 1.343035).  Saving model ...
Validation loss decreased (1.343035 --> 1.338148).  Saving model ...
Validation loss decreased (1.338148 --> 1.333220).  Saving model ...
Validation loss decreased (1.333220 --> 1.328028).  Saving model ...
Validation loss decreased (1.328028 --> 1.322183).  Saving model ...
Validation loss decreased (1.322183 --> 1.317173).  Saving model ...
Validation loss decreased (1.317173 --> 1.310531).  Saving model ...
Validation loss decreased (1.310531 --> 1.304106).  Saving model ...
Validation loss decreased (1.304106 --> 1.297538).  Saving model ...
Validation loss decreased (1.297538 --> 1.291088).  Saving model ...
Validation loss decreased (1.291088 --> 1.284123).  Saving model ...
Validation loss decreased (1.284123 --> 1.278191).  Saving model ...
Validation loss decreased (1.278191 --> 1.270804).  Saving model ...
Validation loss decreased (1.270804 --> 1.263367).  Saving model ...
Validation loss decreased (1.263367 --> 1.256314).  Saving model ...
Validation loss decreased (1.256314 --> 1.248100).  Saving model ...
Validation loss decreased (1.248100 --> 1.240673).  Saving model ...
Validation loss decreased (1.240673 --> 1.234212).  Saving model ...
Validation loss decreased (1.234212 --> 1.226619).  Saving model ...
Validation loss decreased (1.226619 --> 1.220662).  Saving model ...
Validation loss decreased (1.220662 --> 1.214775).  Saving model ...
Validation loss decreased (1.214775 --> 1.207574).  Saving model ...
Validation loss decreased (1.207574 --> 1.200118).  Saving model ...
Validation loss decreased (1.200118 --> 1.192439).  Saving model ...
Validation loss decreased (1.192439 --> 1.186081).  Saving model ...
Validation loss decreased (1.186081 --> 1.180132).  Saving model ...
Validation loss decreased (1.180132 --> 1.174767).  Saving model ...
Validation loss decreased (1.174767 --> 1.167874).  Saving model ...
Validation loss decreased (1.167874 --> 1.163314).  Saving model ...
Validation loss decreased (1.163314 --> 1.158921).  Saving model ...
Validation loss decreased (1.158921 --> 1.153253).  Saving model ...
Validation loss decreased (1.153253 --> 1.148000).  Saving model ...
Validation loss decreased (1.148000 --> 1.141923).  Saving model ...
Validation loss decreased (1.141923 --> 1.138648).  Saving model ...
Validation loss decreased (1.138648 --> 1.136555).  Saving model ...
Validation loss decreased (1.136555 --> 1.131502).  Saving model ...
Validation loss decreased (1.131502 --> 1.125473).  Saving model ...
Validation loss decreased (1.125473 --> 1.121004).  Saving model ...
Validation loss decreased (1.121004 --> 1.117296).  Saving model ...
Validation loss decreased (1.117296 --> 1.113279).  Saving model ...
Validation loss decreased (1.113279 --> 1.106959).  Saving model ...
Validation loss decreased (1.106959 --> 1.101711).  Saving model ...
Validation loss decreased (1.101711 --> 1.096490).  Saving model ...
Validation loss decreased (1.096490 --> 1.091422).  Saving model ...
Validation loss decreased (1.091422 --> 1.087687).  Saving model ...
Validation loss decreased (1.087687 --> 1.086896).  Saving model ...
Validation loss decreased (1.086896 --> 1.080865).  Saving model ...
Validation loss decreased (1.080865 --> 1.078604).  Saving model ...
Validation loss decreased (1.078604 --> 1.073807).  Saving model ...
Validation loss decreased (1.073807 --> 1.071912).  Saving model ...
Validation loss decreased (1.071912 --> 1.068179).  Saving model ...
Validation loss decreased (1.068179 --> 1.064182).  Saving model ...
Validation loss decreased (1.064182 --> 1.060020).  Saving model ...
Validation loss decreased (1.060020 --> 1.056191).  Saving model ...
Validation loss decreased (1.056191 --> 1.055372).  Saving model ...
Validation loss decreased (1.055372 --> 1.052512).  Saving model ...
Validation loss decreased (1.052512 --> 1.050260).  Saving model ...
Validation loss decreased (1.050260 --> 1.047115).  Saving model ...
Validation loss decreased (1.047115 --> 1.045280).  Saving model ...
Validation loss decreased (1.045280 --> 1.040714).  Saving model ...
Validation loss decreased (1.040714 --> 1.033884).  Saving model ...
Validation loss decreased (1.033884 --> 1.031873).  Saving model ...
Validation loss decreased (1.031873 --> 1.030003).  Saving model ...
Validation loss decreased (1.030003 --> 1.027992).  Saving model ...
Validation loss decreased (1.027992 --> 1.027130).  Saving model ...
Validation loss decreased (1.027130 --> 1.024772).  Saving model ...
Validation loss decreased (1.024772 --> 1.024138).  Saving model ...
Validation loss decreased (1.024138 --> 1.023703).  Saving model ...
Validation loss decreased (1.023703 --> 1.020619).  Saving model ...
Validation loss decreased (1.020619 --> 1.018200).  Saving model ...
EarlyStopping counter: 1 out of 10.0
Validation loss decreased (1.018200 --> 1.015670).  Saving model ...
Validation loss decreased (1.015670 --> 1.012806).  Saving model ...
Validation loss decreased (1.012806 --> 1.007746).  Saving model ...
EarlyStopping counter: 1 out of 10.0
Validation loss decreased (1.007746 --> 1.005137).  Saving model ...
Validation loss decreased (1.005137 --> 1.003830).  Saving model ...
Validation loss decreased (1.003830 --> 1.003113).  Saving model ...
Validation loss decreased (1.003113 --> 0.999809).  Saving model ...
Validation loss decreased (0.999809 --> 0.999143).  Saving model ...
Validation loss decreased (0.999143 --> 0.997224).  Saving model ...
Validation loss decreased (0.997224 --> 0.995370).  Saving model ...
Validation loss decreased (0.995370 --> 0.993884).  Saving model ...
Validation loss decreased (0.993884 --> 0.992516).  Saving model ...
Validation loss decreased (0.992516 --> 0.991601).  Saving model ...
Validation loss decreased (0.991601 --> 0.989640).  Saving model ...
Validation loss decreased (0.989640 --> 0.989231).  Saving model ...
EarlyStopping counter: 1 out of 10.0
Validation loss decreased (0.989231 --> 0.988481).  Saving model ...
EarlyStopping counter: 1 out of 10.0
Validation loss decreased (0.988481 --> 0.986194).  Saving model ...
Validation loss decreased (0.986194 --> 0.982324).  Saving model ...
Validation loss decreased (0.982324 --> 0.981127).  Saving model ...
Validation loss decreased (0.981127 --> 0.979469).  Saving model ...
Validation loss decreased (0.979469 --> 0.979171).  Saving model ...
EarlyStopping counter: 1 out of 10.0
Validation loss decreased (0.979171 --> 0.977470).  Saving model ...
EarlyStopping counter: 1 out of 10.0
Validation loss decreased (0.977470 --> 0.975480).  Saving model ...
EarlyStopping counter: 1 out of 10.0
Validation loss decreased (0.975480 --> 0.974620).  Saving model ...
EarlyStopping counter: 1 out of 10.0
EarlyStopping counter: 2 out of 10.0
EarlyStopping counter: 3 out of 10.0
Validation loss decreased (0.974620 --> 0.974503).  Saving model ...
Validation loss decreased (0.974503 --> 0.973935).  Saving model ...
Validation loss decreased (0.973935 --> 0.971321).  Saving model ...
Validation loss decreased (0.971321 --> 0.970198).  Saving model ...
Validation loss decreased (0.970198 --> 0.967314).  Saving model ...
Validation loss decreased (0.967314 --> 0.966779).  Saving model ...
EarlyStopping counter: 1 out of 10.0
EarlyStopping counter: 2 out of 10.0
EarlyStopping counter: 3 out of 10.0
EarlyStopping counter: 4 out of 10.0
EarlyStopping counter: 5 out of 10.0
EarlyStopping counter: 6 out of 10.0
EarlyStopping counter: 7 out of 10.0
EarlyStopping counter: 8 out of 10.0
EarlyStopping counter: 9 out of 10.0
EarlyStopping counter: 10 out of 10.0
/localscratch/yinan.29019300.0/env/lib/python3.7/site-packages/torch/nn/functional.py:1794: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.
  warnings.warn("nn.functional.tanh is deprecated. Use torch.tanh instead.")
wandb: Waiting for W&B process to finish, PID 71552... (success).
wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: \ 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: | 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: / 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: \ 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: | 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: / 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: \ 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: | 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: / 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb:                                                                                
wandb: Run history:
wandb:     e_F1 â–â–ƒâ–„â–„â–…â–…â–…â–†â–†â–†â–†â–†â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ
wandb:   e_loss â–ˆâ–ˆâ–‡â–‡â–‡â–‡â–†â–†â–†â–…â–…â–„â–„â–„â–„â–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–â–â–â–â–â–â–â–â–â–â–â–
wandb:     t_F1 â–â–â–‚â–‚â–ƒâ–ƒâ–„â–„â–…â–…â–…â–…â–†â–†â–†â–†â–†â–†â–†â–†â–†â–‡â–†â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ
wandb:   t_loss â–ˆâ–ˆâ–ˆâ–‡â–‡â–‡â–‡â–‡â–†â–†â–†â–…â–…â–…â–…â–„â–„â–„â–„â–„â–„â–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–â–â–‚â–â–â–
wandb: 
wandb: Run summary:
wandb:     e_F1 58.81446
wandb:   e_loss 0.97075
wandb:     t_F1 71.1677
wandb:   t_loss 0.76437
wandb: 
wandb: Synced 4 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Synced faithful-terrain-2: https://wandb.ai/yinanazhou/xl_512_bs_8_lr_1e06_es_10_lc_False_nr_True_sr_False_stem_False_lemma_False_repeat_5_fold_2/runs/yrfmwcn9
wandb: Find logs at: ./wandb/run-20220319_083628-yrfmwcn9/logs/debug.log
wandb: 

