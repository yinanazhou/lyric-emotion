Unloading StdEnv/2020

Due to MODULEPATH changes, the following have been reloaded:
  1) mii/1.1.1


The following have been reloaded with a version change:
  1) python/3.8.2 => python/3.7.4

Using base prefix '/cvmfs/soft.computecanada.ca/easybuild/software/2017/Core/python/3.7.4'
New python executable in /localscratch/yinan.29027971.0/env/bin/python
Installing setuptools, pip, wheel...
done.
Ignoring pip: markers 'python_version < "3"' don't match your environment
Looking in links: /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/nix/avx2, /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/nix/generic, /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic
Collecting pip
Installing collected packages: pip
  Found existing installation: pip 19.1.1
    Uninstalling pip-19.1.1:
      Successfully uninstalled pip-19.1.1
Successfully installed pip-21.2.3+computecanada
Looking in links: /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/nix/avx2, /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/nix/generic, /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/keras-2.8.0+computecanada-py2.py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/Keras_Preprocessing-1.1.2+computecanada-py3-none-any.whl
Requirement already satisfied: matplotlib in /cvmfs/soft.computecanada.ca/easybuild/software/2017/Core/scipy-stack/2019a/lib/python3.7/site-packages (from -r requirements.txt (line 3)) (3.0.2)
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/nltk-3.6.5+computecanada-py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/scikit_learn-0.22.1+computecanada-cp37-cp37m-linux_x86_64.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/tensorboard-2.3.0+computecanada-py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/tensorboard_plugin_wit-1.7.0+computecanada-py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/tensorflow_gpu-2.3.0+computecanada-cp37-cp37m-linux_x86_64.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/tensorflow_estimator-2.3.0+computecanada-py2.py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/tokenizers-0.5.2+computecanada-cp37-cp37m-linux_x86_64.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/nix/avx2/torch-1.4.0+computecanada-cp37-cp37m-linux_x86_64.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/torchtext-0.6.0+computecanada-py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/torchvision-0.8.2+computecanada-cp37-cp37m-linux_x86_64.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/transformers-2.5.1+computecanada-py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/urllib3-1.26.7+computecanada-py2.py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/click-8.0.3+computecanada-py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/joblib-1.1.0+computecanada-py2.py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/tqdm-4.63.0+computecanada-py2.py3-none-any.whl
ERROR: Could not find a version that satisfies the requirement regex>=2021.8.3 (from nltk) (from versions: 2018.1.10+computecanada, 2019.11.1+computecanada, 2020.11.13+computecanada)
ERROR: No matching distribution found for regex>=2021.8.3
Looking in links: /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/nix/avx2, /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/nix/generic, /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic
ERROR: Could not find a version that satisfies the requirement numpy==1.20.0+computacanada (from versions: 1.15.0+computecanada, 1.15.2+computecanada, 1.15.4+computecanada, 1.16.0+computecanada, 1.16.2+computecanada, 1.16.3+computecanada, 1.17.4+computecanada, 1.18.1+computecanada, 1.18.4+computecanada, 1.19.1+computecanada, 1.19.2+computecanada, 1.20.2+computecanada)
ERROR: No matching distribution found for numpy==1.20.0+computacanada
Looking in links: /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/nix/avx2, /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/nix/generic, /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/wandb-0.12.5+computecanada-py2.py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/yaspin-2.1.0+computecanada-py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/shortuuid-1.0.1+computecanada-py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/six-1.16.0+computecanada-py2.py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/GitPython-3.1.24+computecanada-py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/promise-2.3+computecanada-py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/PyYAML-5.3.1+computecanada-cp37-cp37m-linux_x86_64.whl
Requirement already satisfied: python-dateutil>=2.6.1 in /cvmfs/soft.computecanada.ca/easybuild/software/2017/Core/scipy-stack/2019a/lib/python3.7/site-packages (from wandb) (2.7.5)
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/docker_pycreds-0.4.0+computecanada-py2.py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/subprocess32-3.5.4+computecanada-py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/pathtools-0.1.2+computecanada-py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/configparser-5.0.2+computecanada-py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/sentry_sdk-1.5.0+computecanada-py2.py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/protobuf-3.19.4+computecanada-py2.py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/click-8.0.3+computecanada-py3-none-any.whl
Requirement already satisfied: requests<3,>=2.0.0 in /cvmfs/soft.computecanada.ca/easybuild/software/2017/Core/scipy-stack/2019a/lib/python3.7/site-packages (from wandb) (2.21.0)
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/psutil-5.7.3+computecanada-cp37-cp37m-linux_x86_64.whl
Requirement already satisfied: importlib-metadata in /cvmfs/soft.computecanada.ca/easybuild/software/2017/Core/scipy-stack/2019a/lib/python3.7/site-packages (from Click!=8.0.0,>=7.0->wandb) (0.8)
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/gitdb-4.0.9+computecanada-py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/typing_extensions-4.0.1+computecanada-py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/smmap-5.0.0+computecanada-py3-none-any.whl
Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /cvmfs/soft.computecanada.ca/easybuild/software/2017/Core/scipy-stack/2019a/lib/python3.7/site-packages (from requests<3,>=2.0.0->wandb) (3.0.4)
Requirement already satisfied: urllib3<1.25,>=1.21.1 in /cvmfs/soft.computecanada.ca/easybuild/software/2017/Core/scipy-stack/2019a/lib/python3.7/site-packages (from requests<3,>=2.0.0->wandb) (1.24.1)
Requirement already satisfied: idna<2.9,>=2.5 in /cvmfs/soft.computecanada.ca/easybuild/software/2017/Core/scipy-stack/2019a/lib/python3.7/site-packages (from requests<3,>=2.0.0->wandb) (2.8)
Requirement already satisfied: certifi>=2017.4.17 in /cvmfs/soft.computecanada.ca/easybuild/software/2017/Core/scipy-stack/2019a/lib/python3.7/site-packages (from requests<3,>=2.0.0->wandb) (2018.11.29)
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/termcolor-1.1.0+computecanada-py3-none-any.whl
Requirement already satisfied: zipp>=0.3.2 in /cvmfs/soft.computecanada.ca/easybuild/software/2017/Core/scipy-stack/2019a/lib/python3.7/site-packages (from importlib-metadata->Click!=8.0.0,>=7.0->wandb) (0.3.3)
Installing collected packages: smmap, typing-extensions, termcolor, six, gitdb, yaspin, subprocess32, shortuuid, sentry-sdk, PyYAML, psutil, protobuf, promise, pathtools, GitPython, docker-pycreds, configparser, Click, wandb
  Attempting uninstall: six
    Found existing installation: six 1.12.0
    Not uninstalling six at /cvmfs/soft.computecanada.ca/easybuild/software/2017/Core/scipy-stack/2019a/lib/python3.7/site-packages, outside environment /localscratch/yinan.29027971.0/env
    Can't uninstall 'six'. No files were found to uninstall.
Successfully installed Click-8.0.3+computecanada GitPython-3.1.24+computecanada PyYAML-5.3.1+computecanada configparser-5.0.2+computecanada docker-pycreds-0.4.0+computecanada gitdb-4.0.9+computecanada pathtools-0.1.2+computecanada promise-2.3+computecanada protobuf-3.19.4+computecanada psutil-5.7.3+computecanada sentry-sdk-1.5.0+computecanada shortuuid-1.0.1+computecanada six-1.16.0+computecanada smmap-5.0.0+computecanada subprocess32-3.5.4+computecanada termcolor-1.1.0+computecanada typing-extensions-4.0.1+computecanada wandb-0.12.5+computecanada yaspin-2.1.0+computecanada
Looking in links: /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/nix/avx2, /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/nix/generic, /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic
ERROR: Could not find a version that satisfies the requirement sagemaker (from versions: none)
ERROR: No matching distribution found for sagemaker
Looking in links: /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/nix/avx2, /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/nix/generic, /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/torch-1.9.1+computecanada-cp37-cp37m-linux_x86_64.whl
Requirement already satisfied: typing-extensions in /localscratch/yinan.29027971.0/env/lib/python3.7/site-packages (from torch) (4.0.1+computecanada)
Installing collected packages: torch
Successfully installed torch-1.9.1+computecanada
Looking in links: /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/nix/avx2, /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/nix/generic, /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/transformers-2.5.1+computecanada-py3-none-any.whl
Requirement already satisfied: requests in /cvmfs/soft.computecanada.ca/easybuild/software/2017/Core/scipy-stack/2019a/lib/python3.7/site-packages (from transformers==2.5.1+computecanada) (2.21.0)
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/tqdm-4.63.0+computecanada-py2.py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/filelock-3.4.2+computecanada-py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/sentencepiece-0.1.91+computecanada-cp37-cp37m-linux_x86_64.whl
Requirement already satisfied: numpy in /cvmfs/soft.computecanada.ca/easybuild/software/2017/Core/scipy-stack/2019a/lib/python3.7/site-packages (from transformers==2.5.1+computecanada) (1.16.0)
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/sacremoses-0.0.46+computecanada-py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/regex-2020.11.13+computecanada-cp37-cp37m-linux_x86_64.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/boto3-1.20.52+computecanada-py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/tokenizers-0.5.2+computecanada-cp37-cp37m-linux_x86_64.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/jmespath-0.10.0+computecanada-py2.py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/botocore-1.23.52+computecanada-py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/s3transfer-0.5.1+computecanada-py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/urllib3-1.26.8+computecanada-py2.py3-none-any.whl
Requirement already satisfied: python-dateutil<3.0.0,>=2.1 in /cvmfs/soft.computecanada.ca/easybuild/software/2017/Core/scipy-stack/2019a/lib/python3.7/site-packages (from botocore<1.24.0,>=1.23.52->boto3->transformers==2.5.1+computecanada) (2.7.5)
Requirement already satisfied: six>=1.5 in /localscratch/yinan.29027971.0/env/lib/python3.7/site-packages (from python-dateutil<3.0.0,>=2.1->botocore<1.24.0,>=1.23.52->boto3->transformers==2.5.1+computecanada) (1.16.0+computecanada)
Requirement already satisfied: idna<2.9,>=2.5 in /cvmfs/soft.computecanada.ca/easybuild/software/2017/Core/scipy-stack/2019a/lib/python3.7/site-packages (from requests->transformers==2.5.1+computecanada) (2.8)
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/requests-2.27.1+computecanada-py2.py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/charset_normalizer-2.0.11+computecanada-py3-none-any.whl
Requirement already satisfied: certifi>=2017.4.17 in /cvmfs/soft.computecanada.ca/easybuild/software/2017/Core/scipy-stack/2019a/lib/python3.7/site-packages (from requests->transformers==2.5.1+computecanada) (2018.11.29)
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/joblib-1.1.0+computecanada-py2.py3-none-any.whl
Requirement already satisfied: click in /localscratch/yinan.29027971.0/env/lib/python3.7/site-packages (from sacremoses->transformers==2.5.1+computecanada) (8.0.3+computecanada)
Requirement already satisfied: importlib-metadata in /cvmfs/soft.computecanada.ca/easybuild/software/2017/Core/scipy-stack/2019a/lib/python3.7/site-packages (from click->sacremoses->transformers==2.5.1+computecanada) (0.8)
Requirement already satisfied: zipp>=0.3.2 in /cvmfs/soft.computecanada.ca/easybuild/software/2017/Core/scipy-stack/2019a/lib/python3.7/site-packages (from importlib-metadata->click->sacremoses->transformers==2.5.1+computecanada) (0.3.3)
Installing collected packages: urllib3, jmespath, botocore, tqdm, s3transfer, regex, joblib, charset-normalizer, tokenizers, sentencepiece, sacremoses, requests, filelock, boto3, transformers
  Attempting uninstall: urllib3
    Found existing installation: urllib3 1.24.1
    Not uninstalling urllib3 at /cvmfs/soft.computecanada.ca/easybuild/software/2017/Core/scipy-stack/2019a/lib/python3.7/site-packages, outside environment /localscratch/yinan.29027971.0/env
    Can't uninstall 'urllib3'. No files were found to uninstall.
  Attempting uninstall: requests
    Found existing installation: requests 2.21.0
    Not uninstalling requests at /cvmfs/soft.computecanada.ca/easybuild/software/2017/Core/scipy-stack/2019a/lib/python3.7/site-packages, outside environment /localscratch/yinan.29027971.0/env
    Can't uninstall 'requests'. No files were found to uninstall.
Successfully installed boto3-1.20.52+computecanada botocore-1.23.52+computecanada charset-normalizer-2.0.11+computecanada filelock-3.4.2+computecanada jmespath-0.10.0+computecanada joblib-1.1.0+computecanada regex-2020.11.13+computecanada requests-2.27.1+computecanada s3transfer-0.5.1+computecanada sacremoses-0.0.46+computecanada sentencepiece-0.1.91+computecanada tokenizers-0.5.2+computecanada tqdm-4.63.0+computecanada transformers-2.5.1+computecanada urllib3-1.26.8+computecanada
Looking in links: /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/nix/avx2, /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/nix/generic, /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/tensorflow_gpu-2.3.0+computecanada-cp37-cp37m-linux_x86_64.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/astunparse-1.6.3+computecanada-py2.py3-none-any.whl
Requirement already satisfied: termcolor>=1.1.0 in /localscratch/yinan.29027971.0/env/lib/python3.7/site-packages (from tensorflow_gpu==2.3.0+computecanada) (1.1.0+computecanada)
Requirement already satisfied: six>=1.12.0 in /localscratch/yinan.29027971.0/env/lib/python3.7/site-packages (from tensorflow_gpu==2.3.0+computecanada) (1.16.0+computecanada)
Requirement already satisfied: numpy<1.19.0,>=1.16.0 in /cvmfs/soft.computecanada.ca/easybuild/software/2017/Core/scipy-stack/2019a/lib/python3.7/site-packages (from tensorflow_gpu==2.3.0+computecanada) (1.16.0)
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/nix/generic/scipy-1.4.1+computecanada-cp37-cp37m-linux_x86_64.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/wrapt-1.11.2+computecanada-cp37-cp37m-linux_x86_64.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/gast-0.3.3+computecanada-py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/opt_einsum-3.3.0+computecanada-py3-none-any.whl
Requirement already satisfied: protobuf>=3.9.2 in /localscratch/yinan.29027971.0/env/lib/python3.7/site-packages (from tensorflow_gpu==2.3.0+computecanada) (3.19.4+computecanada)
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/nix/avx2/h5py-2.10.0+computecanada-cp37-cp37m-linux_x86_64.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/tensorflow_estimator-2.3.0+computecanada-py2.py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/grpcio-1.38.0+computecanada-cp37-cp37m-linux_x86_64.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/Keras_Preprocessing-1.1.2+computecanada-py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/tensorboard-2.8.0+computecanada-py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/absl_py-1.0.0+computecanada-py3-none-any.whl
Requirement already satisfied: wheel>=0.26 in /localscratch/yinan.29027971.0/env/lib/python3.7/site-packages (from tensorflow_gpu==2.3.0+computecanada) (0.33.4)
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/google_pasta-0.2.0+computecanada-py3-none-any.whl
Requirement already satisfied: requests<3,>=2.21.0 in /localscratch/yinan.29027971.0/env/lib/python3.7/site-packages (from tensorboard<3,>=2.3.0->tensorflow_gpu==2.3.0+computecanada) (2.27.1+computecanada)
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/google_auth-2.3.3+computecanada-py2.py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/tensorboard_plugin_wit-1.8.0+computecanada-py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/tensorboard_data_server-0.6.1+computecanada-py3-none-linux_x86_64.whl
Requirement already satisfied: setuptools>=41.0.0 in /localscratch/yinan.29027971.0/env/lib/python3.7/site-packages (from tensorboard<3,>=2.3.0->tensorflow_gpu==2.3.0+computecanada) (41.0.1)
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/google_auth_oauthlib-0.4.6+computecanada-py2.py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/Markdown-3.3.6+computecanada-py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/Werkzeug-2.0.3+computecanada-py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/cachetools-4.2.4+computecanada-py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/pyasn1_modules-0.2.8+computecanada-py2.py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/rsa-4.8+computecanada-py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/requests_oauthlib-1.3.0+computecanada-py2.py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/importlib_metadata-4.10.1+computecanada-py3-none-any.whl
Requirement already satisfied: typing-extensions>=3.6.4 in /localscratch/yinan.29027971.0/env/lib/python3.7/site-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard<3,>=2.3.0->tensorflow_gpu==2.3.0+computecanada) (4.0.1+computecanada)
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/zipp-3.7.0+computecanada-py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/pyasn1-0.4.8+computecanada-py2.py3-none-any.whl
Requirement already satisfied: certifi>=2017.4.17 in /cvmfs/soft.computecanada.ca/easybuild/software/2017/Core/scipy-stack/2019a/lib/python3.7/site-packages (from requests<3,>=2.21.0->tensorboard<3,>=2.3.0->tensorflow_gpu==2.3.0+computecanada) (2018.11.29)
Requirement already satisfied: charset-normalizer~=2.0.0 in /localscratch/yinan.29027971.0/env/lib/python3.7/site-packages (from requests<3,>=2.21.0->tensorboard<3,>=2.3.0->tensorflow_gpu==2.3.0+computecanada) (2.0.11+computecanada)
Requirement already satisfied: urllib3<1.27,>=1.21.1 in /localscratch/yinan.29027971.0/env/lib/python3.7/site-packages (from requests<3,>=2.21.0->tensorboard<3,>=2.3.0->tensorflow_gpu==2.3.0+computecanada) (1.26.8+computecanada)
Requirement already satisfied: idna<4,>=2.5 in /cvmfs/soft.computecanada.ca/easybuild/software/2017/Core/scipy-stack/2019a/lib/python3.7/site-packages (from requests<3,>=2.21.0->tensorboard<3,>=2.3.0->tensorflow_gpu==2.3.0+computecanada) (2.8)
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/oauthlib-3.1.1+computecanada-py2.py3-none-any.whl
Installing collected packages: pyasn1, zipp, rsa, pyasn1-modules, oauthlib, cachetools, requests-oauthlib, importlib-metadata, google-auth, werkzeug, tensorboard-plugin-wit, tensorboard-data-server, markdown, grpcio, google-auth-oauthlib, absl-py, wrapt, tensorflow-estimator, tensorboard, scipy, opt-einsum, keras-preprocessing, h5py, google-pasta, gast, astunparse, tensorflow-gpu
  Attempting uninstall: pyasn1
    Found existing installation: pyasn1 0.4.3
    Not uninstalling pyasn1 at /cvmfs/soft.computecanada.ca/easybuild/software/2017/Core/scipy-stack/2019a/lib/python3.7/site-packages, outside environment /localscratch/yinan.29027971.0/env
    Can't uninstall 'pyasn1'. No files were found to uninstall.
  Attempting uninstall: zipp
    Found existing installation: zipp 0.3.3
    Not uninstalling zipp at /cvmfs/soft.computecanada.ca/easybuild/software/2017/Core/scipy-stack/2019a/lib/python3.7/site-packages, outside environment /localscratch/yinan.29027971.0/env
    Can't uninstall 'zipp'. No files were found to uninstall.
  Attempting uninstall: importlib-metadata
    Found existing installation: importlib-metadata 0.8
    Not uninstalling importlib-metadata at /cvmfs/soft.computecanada.ca/easybuild/software/2017/Core/scipy-stack/2019a/lib/python3.7/site-packages, outside environment /localscratch/yinan.29027971.0/env
    Can't uninstall 'importlib-metadata'. No files were found to uninstall.
  Attempting uninstall: scipy
    Found existing installation: scipy 1.2.0
    Not uninstalling scipy at /cvmfs/soft.computecanada.ca/easybuild/software/2017/Core/scipy-stack/2019a/lib/python3.7/site-packages, outside environment /localscratch/yinan.29027971.0/env
    Can't uninstall 'scipy'. No files were found to uninstall.
Successfully installed absl-py-1.0.0+computecanada astunparse-1.6.3+computecanada cachetools-4.2.4+computecanada gast-0.3.3+computecanada google-auth-2.3.3+computecanada google-auth-oauthlib-0.4.6+computecanada google-pasta-0.2.0+computecanada grpcio-1.38.0+computecanada h5py-2.10.0+computecanada importlib-metadata-4.10.1+computecanada keras-preprocessing-1.1.2+computecanada markdown-3.3.6+computecanada oauthlib-3.1.1+computecanada opt-einsum-3.3.0+computecanada pyasn1-0.4.8+computecanada pyasn1-modules-0.2.8+computecanada requests-oauthlib-1.3.0+computecanada rsa-4.8+computecanada scipy-1.4.1+computecanada tensorboard-2.8.0+computecanada tensorboard-data-server-0.6.1+computecanada tensorboard-plugin-wit-1.8.0+computecanada tensorflow-estimator-2.3.0+computecanada tensorflow-gpu-2.3.0+computecanada werkzeug-2.0.3+computecanada wrapt-1.11.2+computecanada zipp-3.7.0+computecanada
Looking in links: /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/nix/avx2, /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/nix/generic, /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/keras-2.8.0+computecanada-py2.py3-none-any.whl
Installing collected packages: Keras
Successfully installed Keras-2.8.0+computecanada
Looking in links: /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/nix/avx2, /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/nix/generic, /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/urllib3-1.26.7+computecanada-py2.py3-none-any.whl
Installing collected packages: urllib3
  Attempting uninstall: urllib3
    Found existing installation: urllib3 1.26.8+computecanada
    Uninstalling urllib3-1.26.8+computecanada:
      Successfully uninstalled urllib3-1.26.8+computecanada
Successfully installed urllib3-1.26.7+computecanada
Looking in links: /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/nix/avx2, /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/nix/generic, /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/nltk-3.7+computecanada-py3-none-any.whl
Requirement already satisfied: tqdm in /localscratch/yinan.29027971.0/env/lib/python3.7/site-packages (from nltk) (4.63.0+computecanada)
Requirement already satisfied: joblib in /localscratch/yinan.29027971.0/env/lib/python3.7/site-packages (from nltk) (1.1.0+computecanada)
Requirement already satisfied: click in /localscratch/yinan.29027971.0/env/lib/python3.7/site-packages (from nltk) (8.0.3+computecanada)
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/nltk-3.6.5+computecanada-py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/nltk-3.6.3+computecanada-py3-none-any.whl
Requirement already satisfied: regex in /localscratch/yinan.29027971.0/env/lib/python3.7/site-packages (from nltk) (2020.11.13+computecanada)
Requirement already satisfied: importlib-metadata in /localscratch/yinan.29027971.0/env/lib/python3.7/site-packages (from click->nltk) (4.10.1+computecanada)
Requirement already satisfied: zipp>=0.5 in /localscratch/yinan.29027971.0/env/lib/python3.7/site-packages (from importlib-metadata->click->nltk) (3.7.0+computecanada)
Requirement already satisfied: typing-extensions>=3.6.4 in /localscratch/yinan.29027971.0/env/lib/python3.7/site-packages (from importlib-metadata->click->nltk) (4.0.1+computecanada)
Installing collected packages: nltk
Successfully installed nltk-3.6.3+computecanada
Looking in links: /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/nix/avx2, /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/nix/generic, /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/scikit_learn-0.22.1+computecanada-cp37-cp37m-linux_x86_64.whl
Requirement already satisfied: joblib>=0.11 in /localscratch/yinan.29027971.0/env/lib/python3.7/site-packages (from scikit-learn==0.22.1) (1.1.0+computecanada)
Requirement already satisfied: numpy>=1.11.0 in /cvmfs/soft.computecanada.ca/easybuild/software/2017/Core/scipy-stack/2019a/lib/python3.7/site-packages (from scikit-learn==0.22.1) (1.16.0)
Requirement already satisfied: scipy>=0.17.0 in /localscratch/yinan.29027971.0/env/lib/python3.7/site-packages (from scikit-learn==0.22.1) (1.4.1+computecanada)
Installing collected packages: scikit-learn
Successfully installed scikit-learn-0.22.1+computecanada
Looking in links: /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/nix/avx2, /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/nix/generic, /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic
Requirement already satisfied: tokenizers==0.5.2 in /localscratch/yinan.29027971.0/env/lib/python3.7/site-packages (0.5.2+computecanada)
wandb: Appending key for api.wandb.ai to your netrc file: /home/yinan/.netrc
Starting Task
2022-03-16 02:45:35.143943: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1
[nltk_data] Downloading package stopwords to /home/yinan/nltk_data...
[nltk_data]   Package stopwords is already up-to-date!
[nltk_data] Downloading package wordnet to /home/yinan/nltk_data...
[nltk_data]   Package wordnet is already up-to-date!
wandb: Currently logged in as: yinanazhou (use `wandb login --relogin` to force relogin)
wandb: wandb version 0.12.11 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
2022-03-16 02:45:45.025087: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1
wandb: Tracking run with wandb version 0.12.5
wandb: Syncing run solar-dust-3
wandb: ⭐️ View project at https://wandb.ai/yinanazhou/xl_512_bs_8_lr_1e06_es_10_lc_True_nr_True_sr_True_stem_False_lemma_False_repeat_1_fold_1
wandb: 🚀 View run at https://wandb.ai/yinanazhou/xl_512_bs_8_lr_1e06_es_10_lc_True_nr_True_sr_True_stem_False_lemma_False_repeat_1_fold_1/runs/1vkjzsoi
wandb: Run data is saved locally in /project/6002780/yinan/Thesis_MER_Lyrics/lyric-emotion/wandb/run-20220316_024542-1vkjzsoi
wandb: Run `wandb offline` to turn off syncing.

Validation loss decreased (inf --> 1.441675).  Saving model ...
Validation loss decreased (1.441675 --> 1.423186).  Saving model ...
Validation loss decreased (1.423186 --> 1.407739).  Saving model ...
Validation loss decreased (1.407739 --> 1.395278).  Saving model ...
Validation loss decreased (1.395278 --> 1.385952).  Saving model ...
Validation loss decreased (1.385952 --> 1.378015).  Saving model ...
Validation loss decreased (1.378015 --> 1.372319).  Saving model ...
Validation loss decreased (1.372319 --> 1.367101).  Saving model ...
Validation loss decreased (1.367101 --> 1.362449).  Saving model ...
Validation loss decreased (1.362449 --> 1.357497).  Saving model ...
Validation loss decreased (1.357497 --> 1.352490).  Saving model ...
Validation loss decreased (1.352490 --> 1.347691).  Saving model ...
Validation loss decreased (1.347691 --> 1.342970).  Saving model ...
Validation loss decreased (1.342970 --> 1.338242).  Saving model ...
Validation loss decreased (1.338242 --> 1.333882).  Saving model ...
Validation loss decreased (1.333882 --> 1.329833).  Saving model ...
Validation loss decreased (1.329833 --> 1.325409).  Saving model ...
Validation loss decreased (1.325409 --> 1.320543).  Saving model ...
Validation loss decreased (1.320543 --> 1.315317).  Saving model ...
Validation loss decreased (1.315317 --> 1.310341).  Saving model ...
Validation loss decreased (1.310341 --> 1.305684).  Saving model ...
Validation loss decreased (1.305684 --> 1.300396).  Saving model ...
Validation loss decreased (1.300396 --> 1.296148).  Saving model ...
Validation loss decreased (1.296148 --> 1.290671).  Saving model ...
Validation loss decreased (1.290671 --> 1.285830).  Saving model ...
Validation loss decreased (1.285830 --> 1.281224).  Saving model ...
Validation loss decreased (1.281224 --> 1.277315).  Saving model ...
Validation loss decreased (1.277315 --> 1.275066).  Saving model ...
Validation loss decreased (1.275066 --> 1.273085).  Saving model ...
Validation loss decreased (1.273085 --> 1.270585).  Saving model ...
Validation loss decreased (1.270585 --> 1.266308).  Saving model ...
Validation loss decreased (1.266308 --> 1.261046).  Saving model ...
Validation loss decreased (1.261046 --> 1.259798).  Saving model ...
Validation loss decreased (1.259798 --> 1.253288).  Saving model ...
Validation loss decreased (1.253288 --> 1.252226).  Saving model ...
Validation loss decreased (1.252226 --> 1.247537).  Saving model ...
Validation loss decreased (1.247537 --> 1.244679).  Saving model ...
Validation loss decreased (1.244679 --> 1.239517).  Saving model ...
Validation loss decreased (1.239517 --> 1.237540).  Saving model ...
Validation loss decreased (1.237540 --> 1.237170).  Saving model ...
Validation loss decreased (1.237170 --> 1.230621).  Saving model ...
Validation loss decreased (1.230621 --> 1.227196).  Saving model ...
Validation loss decreased (1.227196 --> 1.226575).  Saving model ...
Validation loss decreased (1.226575 --> 1.221086).  Saving model ...
Validation loss decreased (1.221086 --> 1.220941).  Saving model ...
Validation loss decreased (1.220941 --> 1.218210).  Saving model ...
Validation loss decreased (1.218210 --> 1.216324).  Saving model ...
Validation loss decreased (1.216324 --> 1.214311).  Saving model ...
Validation loss decreased (1.214311 --> 1.210619).  Saving model ...
Validation loss decreased (1.210619 --> 1.205541).  Saving model ...
Validation loss decreased (1.205541 --> 1.201404).  Saving model ...
Validation loss decreased (1.201404 --> 1.197768).  Saving model ...
Validation loss decreased (1.197768 --> 1.195982).  Saving model ...
Validation loss decreased (1.195982 --> 1.191534).  Saving model ...
EarlyStopping counter: 1 out of 10.0
Validation loss decreased (1.191534 --> 1.189415).  Saving model ...
Validation loss decreased (1.189415 --> 1.188133).  Saving model ...
Validation loss decreased (1.188133 --> 1.184564).  Saving model ...
Validation loss decreased (1.184564 --> 1.178266).  Saving model ...
Validation loss decreased (1.178266 --> 1.178206).  Saving model ...
Validation loss decreased (1.178206 --> 1.173006).  Saving model ...
EarlyStopping counter: 1 out of 10.0
Validation loss decreased (1.173006 --> 1.170363).  Saving model ...
Validation loss decreased (1.170363 --> 1.168316).  Saving model ...
Validation loss decreased (1.168316 --> 1.166168).  Saving model ...
Validation loss decreased (1.166168 --> 1.161845).  Saving model ...
Validation loss decreased (1.161845 --> 1.159450).  Saving model ...
Validation loss decreased (1.159450 --> 1.155724).  Saving model ...
Validation loss decreased (1.155724 --> 1.154208).  Saving model ...
Validation loss decreased (1.154208 --> 1.152667).  Saving model ...
Validation loss decreased (1.152667 --> 1.149243).  Saving model ...
Validation loss decreased (1.149243 --> 1.147071).  Saving model ...
Validation loss decreased (1.147071 --> 1.145694).  Saving model ...
Validation loss decreased (1.145694 --> 1.140263).  Saving model ...
Validation loss decreased (1.140263 --> 1.134228).  Saving model ...
Validation loss decreased (1.134228 --> 1.133849).  Saving model ...
EarlyStopping counter: 1 out of 10.0
Validation loss decreased (1.133849 --> 1.133062).  Saving model ...
Validation loss decreased (1.133062 --> 1.128384).  Saving model ...
Validation loss decreased (1.128384 --> 1.120717).  Saving model ...
EarlyStopping counter: 1 out of 10.0
EarlyStopping counter: 2 out of 10.0
EarlyStopping counter: 3 out of 10.0
EarlyStopping counter: 4 out of 10.0
Validation loss decreased (1.120717 --> 1.117917).  Saving model ...
Validation loss decreased (1.117917 --> 1.108810).  Saving model ...
Validation loss decreased (1.108810 --> 1.104728).  Saving model ...
EarlyStopping counter: 1 out of 10.0
EarlyStopping counter: 2 out of 10.0
EarlyStopping counter: 3 out of 10.0
Validation loss decreased (1.104728 --> 1.100717).  Saving model ...
Validation loss decreased (1.100717 --> 1.098361).  Saving model ...
EarlyStopping counter: 1 out of 10.0
EarlyStopping counter: 2 out of 10.0
EarlyStopping counter: 3 out of 10.0
EarlyStopping counter: 4 out of 10.0
EarlyStopping counter: 5 out of 10.0
Validation loss decreased (1.098361 --> 1.096441).  Saving model ...
Validation loss decreased (1.096441 --> 1.094552).  Saving model ...
EarlyStopping counter: 1 out of 10.0
Validation loss decreased (1.094552 --> 1.092270).  Saving model ...
Validation loss decreased (1.092270 --> 1.090155).  Saving model ...
Validation loss decreased (1.090155 --> 1.084891).  Saving model ...
EarlyStopping counter: 1 out of 10.0
Validation loss decreased (1.084891 --> 1.084865).  Saving model ...
Validation loss decreased (1.084865 --> 1.081225).  Saving model ...
Validation loss decreased (1.081225 --> 1.078288).  Saving model ...
Validation loss decreased (1.078288 --> 1.077156).  Saving model ...
Validation loss decreased (1.077156 --> 1.075131).  Saving model ...
Validation loss decreased (1.075131 --> 1.071867).  Saving model ...
EarlyStopping counter: 1 out of 10.0
EarlyStopping counter: 2 out of 10.0
EarlyStopping counter: 3 out of 10.0
EarlyStopping counter: 4 out of 10.0
EarlyStopping counter: 5 out of 10.0
Validation loss decreased (1.071867 --> 1.071482).  Saving model ...
EarlyStopping counter: 1 out of 10.0
Validation loss decreased (1.071482 --> 1.068983).  Saving model ...
Validation loss decreased (1.068983 --> 1.067395).  Saving model ...
Validation loss decreased (1.067395 --> 1.065161).  Saving model ...
Validation loss decreased (1.065161 --> 1.063052).  Saving model ...
Validation loss decreased (1.063052 --> 1.062935).  Saving model ...
Validation loss decreased (1.062935 --> 1.058124).  Saving model ...
EarlyStopping counter: 1 out of 10.0
EarlyStopping counter: 2 out of 10.0
EarlyStopping counter: 3 out of 10.0
EarlyStopping counter: 4 out of 10.0
EarlyStopping counter: 5 out of 10.0
EarlyStopping counter: 6 out of 10.0
EarlyStopping counter: 7 out of 10.0
EarlyStopping counter: 8 out of 10.0
EarlyStopping counter: 9 out of 10.0
Validation loss decreased (1.058124 --> 1.054475).  Saving model ...
Validation loss decreased (1.054475 --> 1.053281).  Saving model ...
EarlyStopping counter: 1 out of 10.0
EarlyStopping counter: 2 out of 10.0
Validation loss decreased (1.053281 --> 1.050996).  Saving model ...
EarlyStopping counter: 1 out of 10.0
EarlyStopping counter: 2 out of 10.0
EarlyStopping counter: 3 out of 10.0
EarlyStopping counter: 4 out of 10.0
EarlyStopping counter: 5 out of 10.0
EarlyStopping counter: 6 out of 10.0
EarlyStopping counter: 7 out of 10.0
Validation loss decreased (1.050996 --> 1.050884).  Saving model ...
EarlyStopping counter: 1 out of 10.0
EarlyStopping counter: 2 out of 10.0
EarlyStopping counter: 3 out of 10.0
EarlyStopping counter: 4 out of 10.0
Validation loss decreased (1.050884 --> 1.049476).  Saving model ...
EarlyStopping counter: 1 out of 10.0
EarlyStopping counter: 2 out of 10.0
EarlyStopping counter: 3 out of 10.0
EarlyStopping counter: 4 out of 10.0
Validation loss decreased (1.049476 --> 1.048471).  Saving model ...
Validation loss decreased (1.048471 --> 1.045348).  Saving model ...
Validation loss decreased (1.045348 --> 1.044734).  Saving model ...
EarlyStopping counter: 1 out of 10.0
EarlyStopping counter: 2 out of 10.0
EarlyStopping counter: 3 out of 10.0
EarlyStopping counter: 4 out of 10.0
EarlyStopping counter: 5 out of 10.0
EarlyStopping counter: 6 out of 10.0
Validation loss decreased (1.044734 --> 1.042540).  Saving model ...
EarlyStopping counter: 1 out of 10.0
EarlyStopping counter: 2 out of 10.0
EarlyStopping counter: 3 out of 10.0
EarlyStopping counter: 4 out of 10.0
EarlyStopping counter: 5 out of 10.0
EarlyStopping counter: 6 out of 10.0
EarlyStopping counter: 7 out of 10.0
EarlyStopping counter: 8 out of 10.0
EarlyStopping counter: 9 out of 10.0
EarlyStopping counter: 10 out of 10.0
/localscratch/yinan.29027971.0/env/lib/python3.7/site-packages/torch/nn/functional.py:1794: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.
  warnings.warn("nn.functional.tanh is deprecated. Use torch.tanh instead.")
/localscratch/yinan.29027971.0/env/lib/python3.7/site-packages/transformers/optimization.py:155: UserWarning: This overload of add_ is deprecated:
	add_(Number alpha, Tensor other)
Consider using one of the following signatures instead:
	add_(Tensor other, *, Number alpha) (Triggered internally at  ../torch/csrc/utils/python_arg_parser.cpp:1025.)
  exp_avg.mul_(beta1).add_(1.0 - beta1, grad)
wandb: Waiting for W&B process to finish, PID 140995... (success).
wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: \ 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: | 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: / 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: \ 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: | 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: / 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: \ 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: | 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: / 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb:                                                                                
wandb: Run history:
wandb:     e_F1 ▁▂▃▄▄▅▅▅▅▅▆▆▆▆▆▆▆▇▇▇▇▇▇▇████████████████
wandb:   e_loss █▇▇▆▆▆▅▅▅▅▄▄▄▄▃▃▃▃▂▂▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:     t_F1 ▁▂▂▃▃▄▄▄▅▅▅▅▅▆▆▆▆▆▆▆▇▇▇▇▇▇▇▇▇▇▇▇█▇▇▇▇███
wandb:   t_loss █▇▇▇▇▆▆▆▅▅▅▅▅▄▄▄▄▄▄▄▃▃▃▃▃▃▃▂▃▂▂▂▂▂▂▂▂▂▁▁
wandb: 
wandb: Run summary:
wandb:     e_F1 55.03386
wandb:   e_loss 1.05241
wandb:     t_F1 76.01299
wandb:   t_loss 0.63794
wandb: 
wandb: Synced 4 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Synced solar-dust-3: https://wandb.ai/yinanazhou/xl_512_bs_8_lr_1e06_es_10_lc_True_nr_True_sr_True_stem_False_lemma_False_repeat_1_fold_1/runs/1vkjzsoi
wandb: Find logs at: ./wandb/run-20220316_024542-1vkjzsoi/logs/debug.log
wandb: 

wandb: wandb version 0.12.11 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
2022-03-16 04:39:48.369359: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1
wandb: Tracking run with wandb version 0.12.5
wandb: Syncing run fearless-capybara-3
wandb: ⭐️ View project at https://wandb.ai/yinanazhou/xl_512_bs_8_lr_1e06_es_10_lc_True_nr_True_sr_True_stem_False_lemma_False_repeat_1_fold_2
wandb: 🚀 View run at https://wandb.ai/yinanazhou/xl_512_bs_8_lr_1e06_es_10_lc_True_nr_True_sr_True_stem_False_lemma_False_repeat_1_fold_2/runs/3u25qdx1
wandb: Run data is saved locally in /project/6002780/yinan/Thesis_MER_Lyrics/lyric-emotion/wandb/run-20220316_043945-3u25qdx1
wandb: Run `wandb offline` to turn off syncing.

Validation loss decreased (inf --> 1.414901).  Saving model ...
Validation loss decreased (1.414901 --> 1.399010).  Saving model ...
Validation loss decreased (1.399010 --> 1.387372).  Saving model ...
Validation loss decreased (1.387372 --> 1.378949).  Saving model ...
Validation loss decreased (1.378949 --> 1.371676).  Saving model ...
Validation loss decreased (1.371676 --> 1.366442).  Saving model ...
Validation loss decreased (1.366442 --> 1.361314).  Saving model ...
Validation loss decreased (1.361314 --> 1.356775).  Saving model ...
Validation loss decreased (1.356775 --> 1.353402).  Saving model ...
Validation loss decreased (1.353402 --> 1.350231).  Saving model ...
Validation loss decreased (1.350231 --> 1.346940).  Saving model ...
Validation loss decreased (1.346940 --> 1.343945).  Saving model ...
Validation loss decreased (1.343945 --> 1.340372).  Saving model ...
Validation loss decreased (1.340372 --> 1.337090).  Saving model ...
Validation loss decreased (1.337090 --> 1.333648).  Saving model ...
Validation loss decreased (1.333648 --> 1.330808).  Saving model ...
Validation loss decreased (1.330808 --> 1.327376).  Saving model ...
Validation loss decreased (1.327376 --> 1.323531).  Saving model ...
Validation loss decreased (1.323531 --> 1.319916).  Saving model ...
Validation loss decreased (1.319916 --> 1.316087).  Saving model ...
Validation loss decreased (1.316087 --> 1.311784).  Saving model ...
Validation loss decreased (1.311784 --> 1.307919).  Saving model ...
Validation loss decreased (1.307919 --> 1.304179).  Saving model ...
Validation loss decreased (1.304179 --> 1.299242).  Saving model ...
Validation loss decreased (1.299242 --> 1.295034).  Saving model ...
Validation loss decreased (1.295034 --> 1.289498).  Saving model ...
Validation loss decreased (1.289498 --> 1.284530).  Saving model ...
Validation loss decreased (1.284530 --> 1.278286).  Saving model ...
Validation loss decreased (1.278286 --> 1.273423).  Saving model ...
Validation loss decreased (1.273423 --> 1.267087).  Saving model ...
Validation loss decreased (1.267087 --> 1.261828).  Saving model ...
Validation loss decreased (1.261828 --> 1.254302).  Saving model ...
Validation loss decreased (1.254302 --> 1.247567).  Saving model ...
Validation loss decreased (1.247567 --> 1.240897).  Saving model ...
Validation loss decreased (1.240897 --> 1.233160).  Saving model ...
Validation loss decreased (1.233160 --> 1.226667).  Saving model ...
Validation loss decreased (1.226667 --> 1.218164).  Saving model ...
Validation loss decreased (1.218164 --> 1.211594).  Saving model ...
Validation loss decreased (1.211594 --> 1.205297).  Saving model ...
Validation loss decreased (1.205297 --> 1.198413).  Saving model ...
Validation loss decreased (1.198413 --> 1.190715).  Saving model ...
Validation loss decreased (1.190715 --> 1.184607).  Saving model ...
Validation loss decreased (1.184607 --> 1.178485).  Saving model ...
Validation loss decreased (1.178485 --> 1.171256).  Saving model ...
Validation loss decreased (1.171256 --> 1.165585).  Saving model ...
Validation loss decreased (1.165585 --> 1.160377).  Saving model ...
Validation loss decreased (1.160377 --> 1.155893).  Saving model ...
Validation loss decreased (1.155893 --> 1.149533).  Saving model ...
Validation loss decreased (1.149533 --> 1.145487).  Saving model ...
Validation loss decreased (1.145487 --> 1.139899).  Saving model ...
Validation loss decreased (1.139899 --> 1.134154).  Saving model ...
Validation loss decreased (1.134154 --> 1.129719).  Saving model ...
Validation loss decreased (1.129719 --> 1.123975).  Saving model ...
Validation loss decreased (1.123975 --> 1.119167).  Saving model ...
Validation loss decreased (1.119167 --> 1.113989).  Saving model ...
Validation loss decreased (1.113989 --> 1.107941).  Saving model ...
Validation loss decreased (1.107941 --> 1.103103).  Saving model ...
Validation loss decreased (1.103103 --> 1.099089).  Saving model ...
Validation loss decreased (1.099089 --> 1.095125).  Saving model ...
Validation loss decreased (1.095125 --> 1.090995).  Saving model ...
Validation loss decreased (1.090995 --> 1.086389).  Saving model ...
Validation loss decreased (1.086389 --> 1.080349).  Saving model ...
Validation loss decreased (1.080349 --> 1.076073).  Saving model ...
Validation loss decreased (1.076073 --> 1.071877).  Saving model ...
Validation loss decreased (1.071877 --> 1.068951).  Saving model ...
Validation loss decreased (1.068951 --> 1.064805).  Saving model ...
Validation loss decreased (1.064805 --> 1.060321).  Saving model ...
Validation loss decreased (1.060321 --> 1.057794).  Saving model ...
Validation loss decreased (1.057794 --> 1.054782).  Saving model ...
Validation loss decreased (1.054782 --> 1.050722).  Saving model ...
Validation loss decreased (1.050722 --> 1.046665).  Saving model ...
Validation loss decreased (1.046665 --> 1.043211).  Saving model ...
Validation loss decreased (1.043211 --> 1.038870).  Saving model ...
Validation loss decreased (1.038870 --> 1.036316).  Saving model ...
Validation loss decreased (1.036316 --> 1.031107).  Saving model ...
Validation loss decreased (1.031107 --> 1.028195).  Saving model ...
Validation loss decreased (1.028195 --> 1.025172).  Saving model ...
Validation loss decreased (1.025172 --> 1.022545).  Saving model ...
Validation loss decreased (1.022545 --> 1.017998).  Saving model ...
Validation loss decreased (1.017998 --> 1.014778).  Saving model ...
Validation loss decreased (1.014778 --> 1.012807).  Saving model ...
Validation loss decreased (1.012807 --> 1.010121).  Saving model ...
Validation loss decreased (1.010121 --> 1.006340).  Saving model ...
Validation loss decreased (1.006340 --> 1.003594).  Saving model ...
Validation loss decreased (1.003594 --> 1.001574).  Saving model ...
Validation loss decreased (1.001574 --> 0.999272).  Saving model ...
Validation loss decreased (0.999272 --> 0.996025).  Saving model ...
Validation loss decreased (0.996025 --> 0.994413).  Saving model ...
Validation loss decreased (0.994413 --> 0.991057).  Saving model ...
Validation loss decreased (0.991057 --> 0.988904).  Saving model ...
Validation loss decreased (0.988904 --> 0.985796).  Saving model ...
Validation loss decreased (0.985796 --> 0.984519).  Saving model ...
Validation loss decreased (0.984519 --> 0.982854).  Saving model ...
Validation loss decreased (0.982854 --> 0.979618).  Saving model ...
EarlyStopping counter: 1 out of 10.0
Validation loss decreased (0.979618 --> 0.977137).  Saving model ...
Validation loss decreased (0.977137 --> 0.975747).  Saving model ...
Validation loss decreased (0.975747 --> 0.974212).  Saving model ...
Validation loss decreased (0.974212 --> 0.971285).  Saving model ...
Validation loss decreased (0.971285 --> 0.968607).  Saving model ...
Validation loss decreased (0.968607 --> 0.968068).  Saving model ...
Validation loss decreased (0.968068 --> 0.967624).  Saving model ...
Validation loss decreased (0.967624 --> 0.967349).  Saving model ...
Validation loss decreased (0.967349 --> 0.964117).  Saving model ...
Validation loss decreased (0.964117 --> 0.961983).  Saving model ...
EarlyStopping counter: 1 out of 10.0
Validation loss decreased (0.961983 --> 0.961392).  Saving model ...
Validation loss decreased (0.961392 --> 0.958120).  Saving model ...
EarlyStopping counter: 1 out of 10.0
Validation loss decreased (0.958120 --> 0.955752).  Saving model ...
Validation loss decreased (0.955752 --> 0.955588).  Saving model ...
Validation loss decreased (0.955588 --> 0.955443).  Saving model ...
Validation loss decreased (0.955443 --> 0.952960).  Saving model ...
Validation loss decreased (0.952960 --> 0.952033).  Saving model ...
Validation loss decreased (0.952033 --> 0.951535).  Saving model ...
Validation loss decreased (0.951535 --> 0.949222).  Saving model ...
Validation loss decreased (0.949222 --> 0.949216).  Saving model ...
EarlyStopping counter: 1 out of 10.0
Validation loss decreased (0.949216 --> 0.948016).  Saving model ...
EarlyStopping counter: 1 out of 10.0
Validation loss decreased (0.948016 --> 0.946665).  Saving model ...
Validation loss decreased (0.946665 --> 0.945879).  Saving model ...
Validation loss decreased (0.945879 --> 0.945116).  Saving model ...
Validation loss decreased (0.945116 --> 0.944515).  Saving model ...
EarlyStopping counter: 1 out of 10.0
EarlyStopping counter: 2 out of 10.0
Validation loss decreased (0.944515 --> 0.943264).  Saving model ...
Validation loss decreased (0.943264 --> 0.943205).  Saving model ...
Validation loss decreased (0.943205 --> 0.942154).  Saving model ...
Validation loss decreased (0.942154 --> 0.941209).  Saving model ...
Validation loss decreased (0.941209 --> 0.940668).  Saving model ...
Validation loss decreased (0.940668 --> 0.939975).  Saving model ...
Validation loss decreased (0.939975 --> 0.938877).  Saving model ...
EarlyStopping counter: 1 out of 10.0
EarlyStopping counter: 2 out of 10.0
EarlyStopping counter: 3 out of 10.0
Validation loss decreased (0.938877 --> 0.938561).  Saving model ...
EarlyStopping counter: 1 out of 10.0
EarlyStopping counter: 2 out of 10.0
EarlyStopping counter: 3 out of 10.0
EarlyStopping counter: 4 out of 10.0
EarlyStopping counter: 5 out of 10.0
EarlyStopping counter: 6 out of 10.0
EarlyStopping counter: 7 out of 10.0
EarlyStopping counter: 8 out of 10.0
EarlyStopping counter: 9 out of 10.0
EarlyStopping counter: 10 out of 10.0
/localscratch/yinan.29027971.0/env/lib/python3.7/site-packages/torch/nn/functional.py:1794: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.
  warnings.warn("nn.functional.tanh is deprecated. Use torch.tanh instead.")
wandb: Waiting for W&B process to finish, PID 147109... (success).
wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: \ 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: | 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: / 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: \ 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: | 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: / 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: \ 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: | 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: / 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb:                                                                                
wandb: Run history:
wandb:     e_F1 ▁▁▃▅▅▅▅▆▆▆▆▆▆▆▇▇▇▇▇▇▇███████████████████
wandb:   e_loss ██▇▇▇▇▆▆▆▆▅▅▄▄▄▄▃▃▃▃▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:     t_F1 ▁▂▂▂▃▃▄▄▄▄▅▅▅▅▆▅▆▆▆▆▆▇▆▆▇▇▇▇▇▇▇▇████▇███
wandb:   t_loss ███▇▇▇▇▇▇▇▆▆▆▅▅▅▅▄▅▄▄▄▄▃▃▃▃▂▃▃▂▂▂▂▂▂▁▁▁▁
wandb: 
wandb: Run summary:
wandb:     e_F1 58.90867
wandb:   e_loss 0.9407
wandb:     t_F1 74.60422
wandb:   t_loss 0.76527
wandb: 
wandb: Synced 4 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Synced fearless-capybara-3: https://wandb.ai/yinanazhou/xl_512_bs_8_lr_1e06_es_10_lc_True_nr_True_sr_True_stem_False_lemma_False_repeat_1_fold_2/runs/3u25qdx1
wandb: Find logs at: ./wandb/run-20220316_043945-3u25qdx1/logs/debug.log
wandb: 

wandb: wandb version 0.12.11 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
2022-03-16 06:17:04.887499: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1
wandb: Tracking run with wandb version 0.12.5
wandb: Syncing run absurd-serenity-3
wandb: ⭐️ View project at https://wandb.ai/yinanazhou/xl_512_bs_8_lr_1e06_es_10_lc_True_nr_True_sr_True_stem_False_lemma_False_repeat_2_fold_1
wandb: 🚀 View run at https://wandb.ai/yinanazhou/xl_512_bs_8_lr_1e06_es_10_lc_True_nr_True_sr_True_stem_False_lemma_False_repeat_2_fold_1/runs/1ls1le4f
wandb: Run data is saved locally in /project/6002780/yinan/Thesis_MER_Lyrics/lyric-emotion/wandb/run-20220316_061701-1ls1le4f
wandb: Run `wandb offline` to turn off syncing.

Validation loss decreased (inf --> 1.427653).  Saving model ...
Validation loss decreased (1.427653 --> 1.411986).  Saving model ...
Validation loss decreased (1.411986 --> 1.399241).  Saving model ...
Validation loss decreased (1.399241 --> 1.389047).  Saving model ...
Validation loss decreased (1.389047 --> 1.381122).  Saving model ...
Validation loss decreased (1.381122 --> 1.374702).  Saving model ...
Validation loss decreased (1.374702 --> 1.369079).  Saving model ...
Validation loss decreased (1.369079 --> 1.363604).  Saving model ...
Validation loss decreased (1.363604 --> 1.358634).  Saving model ...
Validation loss decreased (1.358634 --> 1.353483).  Saving model ...
Validation loss decreased (1.353483 --> 1.349052).  Saving model ...
Validation loss decreased (1.349052 --> 1.343721).  Saving model ...
Validation loss decreased (1.343721 --> 1.338606).  Saving model ...
Validation loss decreased (1.338606 --> 1.333613).  Saving model ...
Validation loss decreased (1.333613 --> 1.328476).  Saving model ...
Validation loss decreased (1.328476 --> 1.323265).  Saving model ...
Validation loss decreased (1.323265 --> 1.317837).  Saving model ...
Validation loss decreased (1.317837 --> 1.312223).  Saving model ...
Validation loss decreased (1.312223 --> 1.306073).  Saving model ...
Validation loss decreased (1.306073 --> 1.298621).  Saving model ...
Validation loss decreased (1.298621 --> 1.291724).  Saving model ...
Validation loss decreased (1.291724 --> 1.284530).  Saving model ...
Validation loss decreased (1.284530 --> 1.277781).  Saving model ...
Validation loss decreased (1.277781 --> 1.270363).  Saving model ...
Validation loss decreased (1.270363 --> 1.264604).  Saving model ...
Validation loss decreased (1.264604 --> 1.258196).  Saving model ...
Validation loss decreased (1.258196 --> 1.250929).  Saving model ...
Validation loss decreased (1.250929 --> 1.243426).  Saving model ...
Validation loss decreased (1.243426 --> 1.232710).  Saving model ...
Validation loss decreased (1.232710 --> 1.224928).  Saving model ...
Validation loss decreased (1.224928 --> 1.216416).  Saving model ...
Validation loss decreased (1.216416 --> 1.209920).  Saving model ...
Validation loss decreased (1.209920 --> 1.203386).  Saving model ...
Validation loss decreased (1.203386 --> 1.195921).  Saving model ...
Validation loss decreased (1.195921 --> 1.189485).  Saving model ...
Validation loss decreased (1.189485 --> 1.184236).  Saving model ...
Validation loss decreased (1.184236 --> 1.177796).  Saving model ...
Validation loss decreased (1.177796 --> 1.171661).  Saving model ...
Validation loss decreased (1.171661 --> 1.166400).  Saving model ...
Validation loss decreased (1.166400 --> 1.162046).  Saving model ...
Validation loss decreased (1.162046 --> 1.156628).  Saving model ...
Validation loss decreased (1.156628 --> 1.152007).  Saving model ...
Validation loss decreased (1.152007 --> 1.146695).  Saving model ...
Validation loss decreased (1.146695 --> 1.142295).  Saving model ...
Validation loss decreased (1.142295 --> 1.139537).  Saving model ...
Validation loss decreased (1.139537 --> 1.133363).  Saving model ...
Validation loss decreased (1.133363 --> 1.127999).  Saving model ...
EarlyStopping counter: 1 out of 10.0
Validation loss decreased (1.127999 --> 1.119291).  Saving model ...
Validation loss decreased (1.119291 --> 1.116246).  Saving model ...
Validation loss decreased (1.116246 --> 1.111663).  Saving model ...
Validation loss decreased (1.111663 --> 1.106664).  Saving model ...
Validation loss decreased (1.106664 --> 1.102594).  Saving model ...
Validation loss decreased (1.102594 --> 1.098960).  Saving model ...
Validation loss decreased (1.098960 --> 1.094178).  Saving model ...
Validation loss decreased (1.094178 --> 1.091026).  Saving model ...
Validation loss decreased (1.091026 --> 1.086961).  Saving model ...
Validation loss decreased (1.086961 --> 1.084773).  Saving model ...
Validation loss decreased (1.084773 --> 1.080409).  Saving model ...
Validation loss decreased (1.080409 --> 1.078050).  Saving model ...
Validation loss decreased (1.078050 --> 1.075127).  Saving model ...
Validation loss decreased (1.075127 --> 1.072707).  Saving model ...
Validation loss decreased (1.072707 --> 1.068766).  Saving model ...
Validation loss decreased (1.068766 --> 1.065951).  Saving model ...
Validation loss decreased (1.065951 --> 1.062915).  Saving model ...
Validation loss decreased (1.062915 --> 1.059898).  Saving model ...
Validation loss decreased (1.059898 --> 1.057675).  Saving model ...
Validation loss decreased (1.057675 --> 1.054395).  Saving model ...
Validation loss decreased (1.054395 --> 1.051902).  Saving model ...
Validation loss decreased (1.051902 --> 1.046662).  Saving model ...
Validation loss decreased (1.046662 --> 1.046030).  Saving model ...
EarlyStopping counter: 1 out of 10.0
Validation loss decreased (1.046030 --> 1.042420).  Saving model ...
Validation loss decreased (1.042420 --> 1.036781).  Saving model ...
Validation loss decreased (1.036781 --> 1.035117).  Saving model ...
Validation loss decreased (1.035117 --> 1.034487).  Saving model ...
Validation loss decreased (1.034487 --> 1.032168).  Saving model ...
Validation loss decreased (1.032168 --> 1.029051).  Saving model ...
Validation loss decreased (1.029051 --> 1.026369).  Saving model ...
Validation loss decreased (1.026369 --> 1.025238).  Saving model ...
EarlyStopping counter: 1 out of 10.0
Validation loss decreased (1.025238 --> 1.021143).  Saving model ...
Validation loss decreased (1.021143 --> 1.017369).  Saving model ...
Validation loss decreased (1.017369 --> 1.015911).  Saving model ...
Validation loss decreased (1.015911 --> 1.015602).  Saving model ...
Validation loss decreased (1.015602 --> 1.012723).  Saving model ...
EarlyStopping counter: 1 out of 10.0
EarlyStopping counter: 2 out of 10.0
Validation loss decreased (1.012723 --> 1.007473).  Saving model ...
EarlyStopping counter: 1 out of 10.0
Validation loss decreased (1.007473 --> 1.006467).  Saving model ...
Validation loss decreased (1.006467 --> 1.006077).  Saving model ...
Validation loss decreased (1.006077 --> 1.005533).  Saving model ...
Validation loss decreased (1.005533 --> 1.004232).  Saving model ...
Validation loss decreased (1.004232 --> 1.002195).  Saving model ...
Validation loss decreased (1.002195 --> 1.002068).  Saving model ...
Validation loss decreased (1.002068 --> 1.000749).  Saving model ...
Validation loss decreased (1.000749 --> 0.999541).  Saving model ...
Validation loss decreased (0.999541 --> 0.998609).  Saving model ...
Validation loss decreased (0.998609 --> 0.996270).  Saving model ...
Validation loss decreased (0.996270 --> 0.993532).  Saving model ...
Validation loss decreased (0.993532 --> 0.993154).  Saving model ...
EarlyStopping counter: 1 out of 10.0
Validation loss decreased (0.993154 --> 0.991892).  Saving model ...
Validation loss decreased (0.991892 --> 0.990672).  Saving model ...
EarlyStopping counter: 1 out of 10.0
EarlyStopping counter: 2 out of 10.0
Validation loss decreased (0.990672 --> 0.989016).  Saving model ...
Validation loss decreased (0.989016 --> 0.987293).  Saving model ...
Validation loss decreased (0.987293 --> 0.984672).  Saving model ...
EarlyStopping counter: 1 out of 10.0
EarlyStopping counter: 2 out of 10.0
EarlyStopping counter: 3 out of 10.0
Validation loss decreased (0.984672 --> 0.984405).  Saving model ...
Validation loss decreased (0.984405 --> 0.984217).  Saving model ...
EarlyStopping counter: 1 out of 10.0
Validation loss decreased (0.984217 --> 0.983099).  Saving model ...
Validation loss decreased (0.983099 --> 0.981876).  Saving model ...
Validation loss decreased (0.981876 --> 0.981500).  Saving model ...
Validation loss decreased (0.981500 --> 0.980508).  Saving model ...
Validation loss decreased (0.980508 --> 0.979957).  Saving model ...
EarlyStopping counter: 1 out of 10.0
EarlyStopping counter: 2 out of 10.0
EarlyStopping counter: 3 out of 10.0
EarlyStopping counter: 4 out of 10.0
EarlyStopping counter: 5 out of 10.0
EarlyStopping counter: 6 out of 10.0
EarlyStopping counter: 7 out of 10.0
EarlyStopping counter: 8 out of 10.0
EarlyStopping counter: 9 out of 10.0
Validation loss decreased (0.979957 --> 0.979591).  Saving model ...
EarlyStopping counter: 1 out of 10.0
EarlyStopping counter: 2 out of 10.0
EarlyStopping counter: 3 out of 10.0
Validation loss decreased (0.979591 --> 0.979295).  Saving model ...
EarlyStopping counter: 1 out of 10.0
EarlyStopping counter: 2 out of 10.0
EarlyStopping counter: 3 out of 10.0
EarlyStopping counter: 4 out of 10.0
EarlyStopping counter: 5 out of 10.0
EarlyStopping counter: 6 out of 10.0
EarlyStopping counter: 7 out of 10.0
EarlyStopping counter: 8 out of 10.0
EarlyStopping counter: 9 out of 10.0
EarlyStopping counter: 10 out of 10.0
/localscratch/yinan.29027971.0/env/lib/python3.7/site-packages/torch/nn/functional.py:1794: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.
  warnings.warn("nn.functional.tanh is deprecated. Use torch.tanh instead.")
wandb: Waiting for W&B process to finish, PID 152350... (success).
wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: \ 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: | 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: / 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: \ 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: | 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: / 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: \ 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: | 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: / 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb:                                                                                
wandb: Run history:
wandb:     e_F1 ▁▂▃▄▅▅▅▅▆▆▆▆▆▆▇▇▇▇▇▇▇▇▇▇████████████████
wandb:   e_loss ██▇▇▇▆▆▆▅▄▄▄▄▃▃▃▃▂▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:     t_F1 ▁▁▂▃▃▄▄▄▄▅▅▅▅▅▆▆▆▆▆▆▇▆▆▇▇▇▇▇▇▇▇▇▇▇▇▇███▇
wandb:   t_loss ██▇▇▇▇▇▆▆▆▅▅▅▅▅▄▄▄▄▄▃▃▃▃▃▃▃▂▂▂▂▂▂▂▂▂▁▁▁▁
wandb: 
wandb: Run summary:
wandb:     e_F1 58.80302
wandb:   e_loss 0.982
wandb:     t_F1 74.6402
wandb:   t_loss 0.68945
wandb: 
wandb: Synced 4 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Synced absurd-serenity-3: https://wandb.ai/yinanazhou/xl_512_bs_8_lr_1e06_es_10_lc_True_nr_True_sr_True_stem_False_lemma_False_repeat_2_fold_1/runs/1ls1le4f
wandb: Find logs at: ./wandb/run-20220316_061701-1ls1le4f/logs/debug.log
wandb: 

wandb: wandb version 0.12.11 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
2022-03-16 07:52:54.366555: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1
wandb: Tracking run with wandb version 0.12.5
wandb: Syncing run youthful-planet-3
wandb: ⭐️ View project at https://wandb.ai/yinanazhou/xl_512_bs_8_lr_1e06_es_10_lc_True_nr_True_sr_True_stem_False_lemma_False_repeat_2_fold_2
wandb: 🚀 View run at https://wandb.ai/yinanazhou/xl_512_bs_8_lr_1e06_es_10_lc_True_nr_True_sr_True_stem_False_lemma_False_repeat_2_fold_2/runs/1juzab9l
wandb: Run data is saved locally in /project/6002780/yinan/Thesis_MER_Lyrics/lyric-emotion/wandb/run-20220316_075250-1juzab9l
wandb: Run `wandb offline` to turn off syncing.

Validation loss decreased (inf --> 1.435304).  Saving model ...
Validation loss decreased (1.435304 --> 1.414969).  Saving model ...
Validation loss decreased (1.414969 --> 1.401179).  Saving model ...
Validation loss decreased (1.401179 --> 1.390258).  Saving model ...
Validation loss decreased (1.390258 --> 1.382705).  Saving model ...
Validation loss decreased (1.382705 --> 1.377029).  Saving model ...
Validation loss decreased (1.377029 --> 1.372139).  Saving model ...
Validation loss decreased (1.372139 --> 1.367805).  Saving model ...
Validation loss decreased (1.367805 --> 1.363482).  Saving model ...
Validation loss decreased (1.363482 --> 1.359862).  Saving model ...
Validation loss decreased (1.359862 --> 1.356362).  Saving model ...
Validation loss decreased (1.356362 --> 1.352619).  Saving model ...
Validation loss decreased (1.352619 --> 1.348932).  Saving model ...
Validation loss decreased (1.348932 --> 1.345315).  Saving model ...
Validation loss decreased (1.345315 --> 1.341916).  Saving model ...
Validation loss decreased (1.341916 --> 1.338500).  Saving model ...
Validation loss decreased (1.338500 --> 1.334724).  Saving model ...
Validation loss decreased (1.334724 --> 1.330859).  Saving model ...
Validation loss decreased (1.330859 --> 1.326775).  Saving model ...
Validation loss decreased (1.326775 --> 1.322790).  Saving model ...
Validation loss decreased (1.322790 --> 1.318540).  Saving model ...
Validation loss decreased (1.318540 --> 1.313674).  Saving model ...
Validation loss decreased (1.313674 --> 1.308744).  Saving model ...
Validation loss decreased (1.308744 --> 1.304240).  Saving model ...
Validation loss decreased (1.304240 --> 1.298934).  Saving model ...
Validation loss decreased (1.298934 --> 1.293980).  Saving model ...
Validation loss decreased (1.293980 --> 1.289588).  Saving model ...
Validation loss decreased (1.289588 --> 1.283821).  Saving model ...
Validation loss decreased (1.283821 --> 1.278269).  Saving model ...
Validation loss decreased (1.278269 --> 1.273964).  Saving model ...
Validation loss decreased (1.273964 --> 1.268389).  Saving model ...
Validation loss decreased (1.268389 --> 1.263141).  Saving model ...
Validation loss decreased (1.263141 --> 1.256837).  Saving model ...
Validation loss decreased (1.256837 --> 1.249204).  Saving model ...
Validation loss decreased (1.249204 --> 1.243787).  Saving model ...
Validation loss decreased (1.243787 --> 1.237523).  Saving model ...
Validation loss decreased (1.237523 --> 1.232549).  Saving model ...
Validation loss decreased (1.232549 --> 1.224874).  Saving model ...
Validation loss decreased (1.224874 --> 1.218023).  Saving model ...
Validation loss decreased (1.218023 --> 1.213067).  Saving model ...
Validation loss decreased (1.213067 --> 1.206734).  Saving model ...
Validation loss decreased (1.206734 --> 1.200325).  Saving model ...
Validation loss decreased (1.200325 --> 1.195536).  Saving model ...
Validation loss decreased (1.195536 --> 1.192135).  Saving model ...
Validation loss decreased (1.192135 --> 1.186089).  Saving model ...
Validation loss decreased (1.186089 --> 1.180468).  Saving model ...
Validation loss decreased (1.180468 --> 1.176528).  Saving model ...
Validation loss decreased (1.176528 --> 1.170689).  Saving model ...
Validation loss decreased (1.170689 --> 1.168160).  Saving model ...
Validation loss decreased (1.168160 --> 1.164616).  Saving model ...
Validation loss decreased (1.164616 --> 1.161656).  Saving model ...
Validation loss decreased (1.161656 --> 1.154705).  Saving model ...
Validation loss decreased (1.154705 --> 1.151650).  Saving model ...
Validation loss decreased (1.151650 --> 1.148429).  Saving model ...
Validation loss decreased (1.148429 --> 1.145145).  Saving model ...
Validation loss decreased (1.145145 --> 1.137947).  Saving model ...
Validation loss decreased (1.137947 --> 1.135284).  Saving model ...
Validation loss decreased (1.135284 --> 1.132773).  Saving model ...
Validation loss decreased (1.132773 --> 1.127152).  Saving model ...
Validation loss decreased (1.127152 --> 1.123527).  Saving model ...
Validation loss decreased (1.123527 --> 1.119549).  Saving model ...
Validation loss decreased (1.119549 --> 1.114477).  Saving model ...
Validation loss decreased (1.114477 --> 1.110592).  Saving model ...
Validation loss decreased (1.110592 --> 1.106836).  Saving model ...
Validation loss decreased (1.106836 --> 1.103015).  Saving model ...
Validation loss decreased (1.103015 --> 1.100449).  Saving model ...
Validation loss decreased (1.100449 --> 1.097754).  Saving model ...
Validation loss decreased (1.097754 --> 1.092077).  Saving model ...
EarlyStopping counter: 1 out of 10.0
Validation loss decreased (1.092077 --> 1.089997).  Saving model ...
Validation loss decreased (1.089997 --> 1.083590).  Saving model ...
Validation loss decreased (1.083590 --> 1.080948).  Saving model ...
Validation loss decreased (1.080948 --> 1.078084).  Saving model ...
Validation loss decreased (1.078084 --> 1.073848).  Saving model ...
Validation loss decreased (1.073848 --> 1.068160).  Saving model ...
Validation loss decreased (1.068160 --> 1.064953).  Saving model ...
Validation loss decreased (1.064953 --> 1.064649).  Saving model ...
Validation loss decreased (1.064649 --> 1.061992).  Saving model ...
Validation loss decreased (1.061992 --> 1.059716).  Saving model ...
Validation loss decreased (1.059716 --> 1.056109).  Saving model ...
Validation loss decreased (1.056109 --> 1.054531).  Saving model ...
Validation loss decreased (1.054531 --> 1.050190).  Saving model ...
Validation loss decreased (1.050190 --> 1.045909).  Saving model ...
Validation loss decreased (1.045909 --> 1.043912).  Saving model ...
Validation loss decreased (1.043912 --> 1.038480).  Saving model ...
Validation loss decreased (1.038480 --> 1.036974).  Saving model ...
Validation loss decreased (1.036974 --> 1.035351).  Saving model ...
Validation loss decreased (1.035351 --> 1.034001).  Saving model ...
Validation loss decreased (1.034001 --> 1.030427).  Saving model ...
Validation loss decreased (1.030427 --> 1.028175).  Saving model ...
Validation loss decreased (1.028175 --> 1.025382).  Saving model ...
Validation loss decreased (1.025382 --> 1.022415).  Saving model ...
Validation loss decreased (1.022415 --> 1.018602).  Saving model ...
Validation loss decreased (1.018602 --> 1.016407).  Saving model ...
Validation loss decreased (1.016407 --> 1.014163).  Saving model ...
Validation loss decreased (1.014163 --> 1.014112).  Saving model ...
Validation loss decreased (1.014112 --> 1.010248).  Saving model ...
Validation loss decreased (1.010248 --> 1.007697).  Saving model ...
Validation loss decreased (1.007697 --> 1.005853).  Saving model ...
Validation loss decreased (1.005853 --> 1.002276).  Saving model ...
Validation loss decreased (1.002276 --> 0.999743).  Saving model ...
Validation loss decreased (0.999743 --> 0.995365).  Saving model ...
Validation loss decreased (0.995365 --> 0.993122).  Saving model ...
Validation loss decreased (0.993122 --> 0.991884).  Saving model ...
EarlyStopping counter: 1 out of 10.0
EarlyStopping counter: 2 out of 10.0
EarlyStopping counter: 3 out of 10.0
Validation loss decreased (0.991884 --> 0.990606).  Saving model ...
Validation loss decreased (0.990606 --> 0.990240).  Saving model ...
Validation loss decreased (0.990240 --> 0.985715).  Saving model ...
Validation loss decreased (0.985715 --> 0.984887).  Saving model ...
Validation loss decreased (0.984887 --> 0.981213).  Saving model ...
Validation loss decreased (0.981213 --> 0.980376).  Saving model ...
Validation loss decreased (0.980376 --> 0.979075).  Saving model ...
EarlyStopping counter: 1 out of 10.0
Validation loss decreased (0.979075 --> 0.975494).  Saving model ...
Validation loss decreased (0.975494 --> 0.973812).  Saving model ...
Validation loss decreased (0.973812 --> 0.973496).  Saving model ...
Validation loss decreased (0.973496 --> 0.971893).  Saving model ...
EarlyStopping counter: 1 out of 10.0
Validation loss decreased (0.971893 --> 0.969192).  Saving model ...
Validation loss decreased (0.969192 --> 0.968890).  Saving model ...
Validation loss decreased (0.968890 --> 0.966099).  Saving model ...
Validation loss decreased (0.966099 --> 0.964371).  Saving model ...
Validation loss decreased (0.964371 --> 0.963814).  Saving model ...
Validation loss decreased (0.963814 --> 0.961851).  Saving model ...
EarlyStopping counter: 1 out of 10.0
Validation loss decreased (0.961851 --> 0.960331).  Saving model ...
Validation loss decreased (0.960331 --> 0.958202).  Saving model ...
EarlyStopping counter: 1 out of 10.0
Validation loss decreased (0.958202 --> 0.957513).  Saving model ...
Validation loss decreased (0.957513 --> 0.953946).  Saving model ...
EarlyStopping counter: 1 out of 10.0
Validation loss decreased (0.953946 --> 0.953619).  Saving model ...
Validation loss decreased (0.953619 --> 0.953258).  Saving model ...
Validation loss decreased (0.953258 --> 0.952856).  Saving model ...
Validation loss decreased (0.952856 --> 0.951710).  Saving model ...
EarlyStopping counter: 1 out of 10.0
Validation loss decreased (0.951710 --> 0.950945).  Saving model ...
Validation loss decreased (0.950945 --> 0.947351).  Saving model ...
Validation loss decreased (0.947351 --> 0.947028).  Saving model ...
EarlyStopping counter: 1 out of 10.0
Validation loss decreased (0.947028 --> 0.946037).  Saving model ...
EarlyStopping counter: 1 out of 10.0
Validation loss decreased (0.946037 --> 0.943717).  Saving model ...
EarlyStopping counter: 1 out of 10.0
Validation loss decreased (0.943717 --> 0.942745).  Saving model ...
Validation loss decreased (0.942745 --> 0.941345).  Saving model ...
EarlyStopping counter: 1 out of 10.0
EarlyStopping counter: 2 out of 10.0
Validation loss decreased (0.941345 --> 0.940666).  Saving model ...
EarlyStopping counter: 1 out of 10.0
EarlyStopping counter: 2 out of 10.0
EarlyStopping counter: 3 out of 10.0
Validation loss decreased (0.940666 --> 0.939534).  Saving model ...
EarlyStopping counter: 1 out of 10.0
EarlyStopping counter: 2 out of 10.0
EarlyStopping counter: 3 out of 10.0
Validation loss decreased (0.939534 --> 0.938933).  Saving model ...
EarlyStopping counter: 1 out of 10.0
EarlyStopping counter: 2 out of 10.0
EarlyStopping counter: 3 out of 10.0
Validation loss decreased (0.938933 --> 0.937028).  Saving model ...
Validation loss decreased (0.937028 --> 0.936973).  Saving model ...
Validation loss decreased (0.936973 --> 0.935686).  Saving model ...
EarlyStopping counter: 1 out of 10.0
Validation loss decreased (0.935686 --> 0.934729).  Saving model ...
EarlyStopping counter: 1 out of 10.0
EarlyStopping counter: 2 out of 10.0
EarlyStopping counter: 3 out of 10.0
EarlyStopping counter: 4 out of 10.0
EarlyStopping counter: 5 out of 10.0
EarlyStopping counter: 6 out of 10.0
EarlyStopping counter: 7 out of 10.0
EarlyStopping counter: 8 out of 10.0
EarlyStopping counter: 9 out of 10.0
EarlyStopping counter: 10 out of 10.0
/localscratch/yinan.29027971.0/env/lib/python3.7/site-packages/torch/nn/functional.py:1794: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.
  warnings.warn("nn.functional.tanh is deprecated. Use torch.tanh instead.")
wandb: Waiting for W&B process to finish, PID 157479... (success).
wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: \ 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: | 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: / 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb:                                                                                
wandb: Run history:
wandb:     e_F1 ▁▂▃▄▅▆▆▆▆▆▆▆▆▇▇▇▇▇▇▇█▇▇▇▇██▇████████████
wandb:   e_loss █▇▇▇▇▆▆▆▅▅▅▄▄▄▃▃▃▃▃▂▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:     t_F1 ▁▂▃▃▃▃▄▄▄▅▅▅▅▆▅▆▆▆▆▆▆▆▆▆▆▇▇▇▇▇▇▇██▇█▇▇██
wandb:   t_loss ██▇▇▇▇▇▆▆▆▆▅▅▅▅▅▄▄▄▄▄▃▃▃▃▃▃▃▃▃▂▂▂▂▂▂▂▁▁▁
wandb: 
wandb: Run summary:
wandb:     e_F1 59.2421
wandb:   e_loss 0.93823
wandb:     t_F1 75.13099
wandb:   t_loss 0.70915
wandb: 
wandb: Synced 4 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Synced youthful-planet-3: https://wandb.ai/yinanazhou/xl_512_bs_8_lr_1e06_es_10_lc_True_nr_True_sr_True_stem_False_lemma_False_repeat_2_fold_2/runs/1juzab9l
wandb: Find logs at: ./wandb/run-20220316_075250-1juzab9l/logs/debug.log
wandb: 

wandb: wandb version 0.12.11 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
2022-03-16 09:50:07.427559: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1
wandb: Tracking run with wandb version 0.12.5
wandb: Syncing run different-mountain-3
wandb: ⭐️ View project at https://wandb.ai/yinanazhou/xl_512_bs_8_lr_1e06_es_10_lc_True_nr_True_sr_True_stem_False_lemma_False_repeat_3_fold_1
wandb: 🚀 View run at https://wandb.ai/yinanazhou/xl_512_bs_8_lr_1e06_es_10_lc_True_nr_True_sr_True_stem_False_lemma_False_repeat_3_fold_1/runs/26x8rqvp
wandb: Run data is saved locally in /project/6002780/yinan/Thesis_MER_Lyrics/lyric-emotion/wandb/run-20220316_095004-26x8rqvp
wandb: Run `wandb offline` to turn off syncing.

Validation loss decreased (inf --> 1.398402).  Saving model ...
Validation loss decreased (1.398402 --> 1.393077).  Saving model ...
Validation loss decreased (1.393077 --> 1.388340).  Saving model ...
Validation loss decreased (1.388340 --> 1.384082).  Saving model ...
Validation loss decreased (1.384082 --> 1.380269).  Saving model ...
Validation loss decreased (1.380269 --> 1.376717).  Saving model ...
Validation loss decreased (1.376717 --> 1.373262).  Saving model ...
Validation loss decreased (1.373262 --> 1.369900).  Saving model ...
Validation loss decreased (1.369900 --> 1.366494).  Saving model ...
Validation loss decreased (1.366494 --> 1.363028).  Saving model ...
Validation loss decreased (1.363028 --> 1.359643).  Saving model ...
Validation loss decreased (1.359643 --> 1.356210).  Saving model ...
Validation loss decreased (1.356210 --> 1.352977).  Saving model ...
Validation loss decreased (1.352977 --> 1.349360).  Saving model ...
Validation loss decreased (1.349360 --> 1.345548).  Saving model ...
Validation loss decreased (1.345548 --> 1.341274).  Saving model ...
Validation loss decreased (1.341274 --> 1.336744).  Saving model ...
Validation loss decreased (1.336744 --> 1.332449).  Saving model ...
Validation loss decreased (1.332449 --> 1.327708).  Saving model ...
Validation loss decreased (1.327708 --> 1.322156).  Saving model ...
Validation loss decreased (1.322156 --> 1.316591).  Saving model ...
Validation loss decreased (1.316591 --> 1.310893).  Saving model ...
Validation loss decreased (1.310893 --> 1.304443).  Saving model ...
Validation loss decreased (1.304443 --> 1.297631).  Saving model ...
Validation loss decreased (1.297631 --> 1.290284).  Saving model ...
Validation loss decreased (1.290284 --> 1.282537).  Saving model ...
Validation loss decreased (1.282537 --> 1.275665).  Saving model ...
Validation loss decreased (1.275665 --> 1.268590).  Saving model ...
Validation loss decreased (1.268590 --> 1.261084).  Saving model ...
Validation loss decreased (1.261084 --> 1.253976).  Saving model ...
Validation loss decreased (1.253976 --> 1.246576).  Saving model ...
Validation loss decreased (1.246576 --> 1.239871).  Saving model ...
Validation loss decreased (1.239871 --> 1.234362).  Saving model ...
Validation loss decreased (1.234362 --> 1.229952).  Saving model ...
Validation loss decreased (1.229952 --> 1.222908).  Saving model ...
Validation loss decreased (1.222908 --> 1.217454).  Saving model ...
Validation loss decreased (1.217454 --> 1.210675).  Saving model ...
Validation loss decreased (1.210675 --> 1.205558).  Saving model ...
Validation loss decreased (1.205558 --> 1.199748).  Saving model ...
Validation loss decreased (1.199748 --> 1.195568).  Saving model ...
Validation loss decreased (1.195568 --> 1.190020).  Saving model ...
Validation loss decreased (1.190020 --> 1.186909).  Saving model ...
Validation loss decreased (1.186909 --> 1.182934).  Saving model ...
Validation loss decreased (1.182934 --> 1.179184).  Saving model ...
Validation loss decreased (1.179184 --> 1.174496).  Saving model ...
Validation loss decreased (1.174496 --> 1.169567).  Saving model ...
Validation loss decreased (1.169567 --> 1.165776).  Saving model ...
Validation loss decreased (1.165776 --> 1.161005).  Saving model ...
Validation loss decreased (1.161005 --> 1.154977).  Saving model ...
Validation loss decreased (1.154977 --> 1.153337).  Saving model ...
Validation loss decreased (1.153337 --> 1.148172).  Saving model ...
Validation loss decreased (1.148172 --> 1.144202).  Saving model ...
Validation loss decreased (1.144202 --> 1.138662).  Saving model ...
Validation loss decreased (1.138662 --> 1.133667).  Saving model ...
Validation loss decreased (1.133667 --> 1.127155).  Saving model ...
Validation loss decreased (1.127155 --> 1.126538).  Saving model ...
Validation loss decreased (1.126538 --> 1.121701).  Saving model ...
Validation loss decreased (1.121701 --> 1.118935).  Saving model ...
Validation loss decreased (1.118935 --> 1.116541).  Saving model ...
Validation loss decreased (1.116541 --> 1.111464).  Saving model ...
Validation loss decreased (1.111464 --> 1.109039).  Saving model ...
Validation loss decreased (1.109039 --> 1.101144).  Saving model ...
Validation loss decreased (1.101144 --> 1.099080).  Saving model ...
Validation loss decreased (1.099080 --> 1.095982).  Saving model ...
Validation loss decreased (1.095982 --> 1.095586).  Saving model ...
Validation loss decreased (1.095586 --> 1.089267).  Saving model ...
Validation loss decreased (1.089267 --> 1.087532).  Saving model ...
Validation loss decreased (1.087532 --> 1.079669).  Saving model ...
Validation loss decreased (1.079669 --> 1.074007).  Saving model ...
Validation loss decreased (1.074007 --> 1.073793).  Saving model ...
Validation loss decreased (1.073793 --> 1.070696).  Saving model ...
Validation loss decreased (1.070696 --> 1.068331).  Saving model ...
Validation loss decreased (1.068331 --> 1.065276).  Saving model ...
Validation loss decreased (1.065276 --> 1.063041).  Saving model ...
Validation loss decreased (1.063041 --> 1.059916).  Saving model ...
Validation loss decreased (1.059916 --> 1.054639).  Saving model ...
Validation loss decreased (1.054639 --> 1.053671).  Saving model ...
EarlyStopping counter: 1 out of 10.0
Validation loss decreased (1.053671 --> 1.051569).  Saving model ...
Validation loss decreased (1.051569 --> 1.048903).  Saving model ...
Validation loss decreased (1.048903 --> 1.046679).  Saving model ...
Validation loss decreased (1.046679 --> 1.043692).  Saving model ...
Validation loss decreased (1.043692 --> 1.039375).  Saving model ...
Validation loss decreased (1.039375 --> 1.038153).  Saving model ...
Validation loss decreased (1.038153 --> 1.037003).  Saving model ...
EarlyStopping counter: 1 out of 10.0
Validation loss decreased (1.037003 --> 1.036426).  Saving model ...
Validation loss decreased (1.036426 --> 1.032334).  Saving model ...
Validation loss decreased (1.032334 --> 1.026533).  Saving model ...
EarlyStopping counter: 1 out of 10.0
Validation loss decreased (1.026533 --> 1.025054).  Saving model ...
Validation loss decreased (1.025054 --> 1.024432).  Saving model ...
Validation loss decreased (1.024432 --> 1.024207).  Saving model ...
Validation loss decreased (1.024207 --> 1.021210).  Saving model ...
Validation loss decreased (1.021210 --> 1.015432).  Saving model ...
EarlyStopping counter: 1 out of 10.0
EarlyStopping counter: 2 out of 10.0
EarlyStopping counter: 3 out of 10.0
Validation loss decreased (1.015432 --> 1.014470).  Saving model ...
Validation loss decreased (1.014470 --> 1.012029).  Saving model ...
Validation loss decreased (1.012029 --> 1.011294).  Saving model ...
Validation loss decreased (1.011294 --> 1.008052).  Saving model ...
EarlyStopping counter: 1 out of 10.0
EarlyStopping counter: 2 out of 10.0
Validation loss decreased (1.008052 --> 1.005620).  Saving model ...
EarlyStopping counter: 1 out of 10.0
EarlyStopping counter: 2 out of 10.0
Validation loss decreased (1.005620 --> 1.002545).  Saving model ...
Validation loss decreased (1.002545 --> 1.002161).  Saving model ...
EarlyStopping counter: 1 out of 10.0
EarlyStopping counter: 2 out of 10.0
Validation loss decreased (1.002161 --> 0.999781).  Saving model ...
EarlyStopping counter: 1 out of 10.0
Validation loss decreased (0.999781 --> 0.998947).  Saving model ...
EarlyStopping counter: 1 out of 10.0
EarlyStopping counter: 2 out of 10.0
Validation loss decreased (0.998947 --> 0.998725).  Saving model ...
EarlyStopping counter: 1 out of 10.0
Validation loss decreased (0.998725 --> 0.995324).  Saving model ...
EarlyStopping counter: 1 out of 10.0
Validation loss decreased (0.995324 --> 0.994996).  Saving model ...
EarlyStopping counter: 1 out of 10.0
EarlyStopping counter: 2 out of 10.0
Validation loss decreased (0.994996 --> 0.991891).  Saving model ...
EarlyStopping counter: 1 out of 10.0
EarlyStopping counter: 2 out of 10.0
EarlyStopping counter: 3 out of 10.0
Validation loss decreased (0.991891 --> 0.986580).  Saving model ...
EarlyStopping counter: 1 out of 10.0
EarlyStopping counter: 2 out of 10.0
EarlyStopping counter: 3 out of 10.0
EarlyStopping counter: 4 out of 10.0
EarlyStopping counter: 5 out of 10.0
EarlyStopping counter: 6 out of 10.0
EarlyStopping counter: 7 out of 10.0
EarlyStopping counter: 8 out of 10.0
EarlyStopping counter: 9 out of 10.0
EarlyStopping counter: 10 out of 10.0
/localscratch/yinan.29027971.0/env/lib/python3.7/site-packages/torch/nn/functional.py:1794: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.
  warnings.warn("nn.functional.tanh is deprecated. Use torch.tanh instead.")
wandb: Waiting for W&B process to finish, PID 163782... (success).
wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: \ 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: | 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: / 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: \ 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: | 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: / 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: \ 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: | 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: / 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb:                                                                                
wandb: Run history:
wandb:     e_F1 ▁▁▂▃▃▄▅▆▆▅▆▆▆▆▆▆▇▇▇▇▇▇▇▇▇▇▇▇▇███████████
wandb:   e_loss ███▇▇▇▇▆▆▅▅▅▄▄▄▃▃▃▃▃▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:     t_F1 ▁▁▂▃▂▃▃▃▃▄▅▄▅▅▅▆▅▆▆▆▆▆▇▆▇▆▇▇▇▇▇▇▇▇▇█▇▇██
wandb:   t_loss ████▇▇▇▇▇▆▆▆▅▅▅▅▅▅▄▄▄▄▃▃▃▃▃▃▃▃▂▂▂▂▂▂▂▂▂▁
wandb: 
wandb: Run summary:
wandb:     e_F1 57.65896
wandb:   e_loss 0.99242
wandb:     t_F1 73.90576
wandb:   t_loss 0.71272
wandb: 
wandb: Synced 4 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Synced different-mountain-3: https://wandb.ai/yinanazhou/xl_512_bs_8_lr_1e06_es_10_lc_True_nr_True_sr_True_stem_False_lemma_False_repeat_3_fold_1/runs/26x8rqvp
wandb: Find logs at: ./wandb/run-20220316_095004-26x8rqvp/logs/debug.log
wandb: 

wandb: wandb version 0.12.11 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
2022-03-16 11:21:38.715698: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1
wandb: Tracking run with wandb version 0.12.5
wandb: Syncing run dry-glade-3
wandb: ⭐️ View project at https://wandb.ai/yinanazhou/xl_512_bs_8_lr_1e06_es_10_lc_True_nr_True_sr_True_stem_False_lemma_False_repeat_3_fold_2
wandb: 🚀 View run at https://wandb.ai/yinanazhou/xl_512_bs_8_lr_1e06_es_10_lc_True_nr_True_sr_True_stem_False_lemma_False_repeat_3_fold_2/runs/3dk1m6y9
wandb: Run data is saved locally in /project/6002780/yinan/Thesis_MER_Lyrics/lyric-emotion/wandb/run-20220316_112135-3dk1m6y9
wandb: Run `wandb offline` to turn off syncing.

Validation loss decreased (inf --> 1.413669).  Saving model ...
Validation loss decreased (1.413669 --> 1.398497).  Saving model ...
Validation loss decreased (1.398497 --> 1.386175).  Saving model ...
Validation loss decreased (1.386175 --> 1.377285).  Saving model ...
Validation loss decreased (1.377285 --> 1.369856).  Saving model ...
Validation loss decreased (1.369856 --> 1.364014).  Saving model ...
Validation loss decreased (1.364014 --> 1.359117).  Saving model ...
Validation loss decreased (1.359117 --> 1.354555).  Saving model ...
Validation loss decreased (1.354555 --> 1.349707).  Saving model ...
Validation loss decreased (1.349707 --> 1.345020).  Saving model ...
Validation loss decreased (1.345020 --> 1.340905).  Saving model ...
Validation loss decreased (1.340905 --> 1.336742).  Saving model ...
Validation loss decreased (1.336742 --> 1.331858).  Saving model ...
Validation loss decreased (1.331858 --> 1.327971).  Saving model ...
Validation loss decreased (1.327971 --> 1.323497).  Saving model ...
Validation loss decreased (1.323497 --> 1.318620).  Saving model ...
Validation loss decreased (1.318620 --> 1.313939).  Saving model ...
Validation loss decreased (1.313939 --> 1.309595).  Saving model ...
Validation loss decreased (1.309595 --> 1.304992).  Saving model ...
Validation loss decreased (1.304992 --> 1.300230).  Saving model ...
Validation loss decreased (1.300230 --> 1.295221).  Saving model ...
Validation loss decreased (1.295221 --> 1.290476).  Saving model ...
Validation loss decreased (1.290476 --> 1.284831).  Saving model ...
Validation loss decreased (1.284831 --> 1.278867).  Saving model ...
Validation loss decreased (1.278867 --> 1.273126).  Saving model ...
Validation loss decreased (1.273126 --> 1.266877).  Saving model ...
Validation loss decreased (1.266877 --> 1.260364).  Saving model ...
Validation loss decreased (1.260364 --> 1.253543).  Saving model ...
Validation loss decreased (1.253543 --> 1.247309).  Saving model ...
Validation loss decreased (1.247309 --> 1.239973).  Saving model ...
Validation loss decreased (1.239973 --> 1.232573).  Saving model ...
Validation loss decreased (1.232573 --> 1.224707).  Saving model ...
Validation loss decreased (1.224707 --> 1.218989).  Saving model ...
Validation loss decreased (1.218989 --> 1.212673).  Saving model ...
Validation loss decreased (1.212673 --> 1.206831).  Saving model ...
Validation loss decreased (1.206831 --> 1.200229).  Saving model ...
Validation loss decreased (1.200229 --> 1.193162).  Saving model ...
Validation loss decreased (1.193162 --> 1.186174).  Saving model ...
Validation loss decreased (1.186174 --> 1.180032).  Saving model ...
Validation loss decreased (1.180032 --> 1.173784).  Saving model ...
Validation loss decreased (1.173784 --> 1.167398).  Saving model ...
Validation loss decreased (1.167398 --> 1.161374).  Saving model ...
Validation loss decreased (1.161374 --> 1.155835).  Saving model ...
Validation loss decreased (1.155835 --> 1.150977).  Saving model ...
Validation loss decreased (1.150977 --> 1.144496).  Saving model ...
Validation loss decreased (1.144496 --> 1.139304).  Saving model ...
Validation loss decreased (1.139304 --> 1.134350).  Saving model ...
Validation loss decreased (1.134350 --> 1.129283).  Saving model ...
Validation loss decreased (1.129283 --> 1.124686).  Saving model ...
Validation loss decreased (1.124686 --> 1.119923).  Saving model ...
Validation loss decreased (1.119923 --> 1.115015).  Saving model ...
Validation loss decreased (1.115015 --> 1.110426).  Saving model ...
Validation loss decreased (1.110426 --> 1.106735).  Saving model ...
Validation loss decreased (1.106735 --> 1.101751).  Saving model ...
Validation loss decreased (1.101751 --> 1.100302).  Saving model ...
Validation loss decreased (1.100302 --> 1.095434).  Saving model ...
Validation loss decreased (1.095434 --> 1.090026).  Saving model ...
Validation loss decreased (1.090026 --> 1.085131).  Saving model ...
Validation loss decreased (1.085131 --> 1.082273).  Saving model ...
Validation loss decreased (1.082273 --> 1.079867).  Saving model ...
Validation loss decreased (1.079867 --> 1.076188).  Saving model ...
Validation loss decreased (1.076188 --> 1.072912).  Saving model ...
Validation loss decreased (1.072912 --> 1.069573).  Saving model ...
Validation loss decreased (1.069573 --> 1.065886).  Saving model ...
Validation loss decreased (1.065886 --> 1.062779).  Saving model ...
Validation loss decreased (1.062779 --> 1.058799).  Saving model ...
Validation loss decreased (1.058799 --> 1.055249).  Saving model ...
Validation loss decreased (1.055249 --> 1.051816).  Saving model ...
Validation loss decreased (1.051816 --> 1.048124).  Saving model ...
Validation loss decreased (1.048124 --> 1.046094).  Saving model ...
Validation loss decreased (1.046094 --> 1.042628).  Saving model ...
Validation loss decreased (1.042628 --> 1.038364).  Saving model ...
Validation loss decreased (1.038364 --> 1.035409).  Saving model ...
Validation loss decreased (1.035409 --> 1.031954).  Saving model ...
Validation loss decreased (1.031954 --> 1.029857).  Saving model ...
Validation loss decreased (1.029857 --> 1.026956).  Saving model ...
Validation loss decreased (1.026956 --> 1.024058).  Saving model ...
Validation loss decreased (1.024058 --> 1.020938).  Saving model ...
Validation loss decreased (1.020938 --> 1.018260).  Saving model ...
Validation loss decreased (1.018260 --> 1.015644).  Saving model ...
Validation loss decreased (1.015644 --> 1.012153).  Saving model ...
Validation loss decreased (1.012153 --> 1.010988).  Saving model ...
Validation loss decreased (1.010988 --> 1.008896).  Saving model ...
Validation loss decreased (1.008896 --> 1.007332).  Saving model ...
Validation loss decreased (1.007332 --> 1.005951).  Saving model ...
Validation loss decreased (1.005951 --> 1.002687).  Saving model ...
Validation loss decreased (1.002687 --> 1.000477).  Saving model ...
Validation loss decreased (1.000477 --> 0.998407).  Saving model ...
Validation loss decreased (0.998407 --> 0.995291).  Saving model ...
Validation loss decreased (0.995291 --> 0.993697).  Saving model ...
Validation loss decreased (0.993697 --> 0.991028).  Saving model ...
Validation loss decreased (0.991028 --> 0.989078).  Saving model ...
Validation loss decreased (0.989078 --> 0.988792).  Saving model ...
Validation loss decreased (0.988792 --> 0.987414).  Saving model ...
Validation loss decreased (0.987414 --> 0.984908).  Saving model ...
Validation loss decreased (0.984908 --> 0.981825).  Saving model ...
Validation loss decreased (0.981825 --> 0.981349).  Saving model ...
Validation loss decreased (0.981349 --> 0.979174).  Saving model ...
Validation loss decreased (0.979174 --> 0.976996).  Saving model ...
Validation loss decreased (0.976996 --> 0.974086).  Saving model ...
Validation loss decreased (0.974086 --> 0.972828).  Saving model ...
Validation loss decreased (0.972828 --> 0.971171).  Saving model ...
Validation loss decreased (0.971171 --> 0.968965).  Saving model ...
Validation loss decreased (0.968965 --> 0.967648).  Saving model ...
Validation loss decreased (0.967648 --> 0.966926).  Saving model ...
Validation loss decreased (0.966926 --> 0.964959).  Saving model ...
Validation loss decreased (0.964959 --> 0.963276).  Saving model ...
Validation loss decreased (0.963276 --> 0.962938).  Saving model ...
Validation loss decreased (0.962938 --> 0.961461).  Saving model ...
Validation loss decreased (0.961461 --> 0.959416).  Saving model ...
Validation loss decreased (0.959416 --> 0.958240).  Saving model ...
Validation loss decreased (0.958240 --> 0.957524).  Saving model ...
Validation loss decreased (0.957524 --> 0.956588).  Saving model ...
Validation loss decreased (0.956588 --> 0.954435).  Saving model ...
Validation loss decreased (0.954435 --> 0.951829).  Saving model ...
Validation loss decreased (0.951829 --> 0.949696).  Saving model ...
EarlyStopping counter: 1 out of 10.0
Validation loss decreased (0.949696 --> 0.949692).  Saving model ...
Validation loss decreased (0.949692 --> 0.949539).  Saving model ...
EarlyStopping counter: 1 out of 10.0
Validation loss decreased (0.949539 --> 0.948313).  Saving model ...
Validation loss decreased (0.948313 --> 0.946838).  Saving model ...
Validation loss decreased (0.946838 --> 0.944424).  Saving model ...
Validation loss decreased (0.944424 --> 0.943441).  Saving model ...
Validation loss decreased (0.943441 --> 0.942537).  Saving model ...
Validation loss decreased (0.942537 --> 0.941455).  Saving model ...
Validation loss decreased (0.941455 --> 0.941196).  Saving model ...
Validation loss decreased (0.941196 --> 0.940853).  Saving model ...
Validation loss decreased (0.940853 --> 0.940509).  Saving model ...
Validation loss decreased (0.940509 --> 0.939882).  Saving model ...
Validation loss decreased (0.939882 --> 0.938534).  Saving model ...
Validation loss decreased (0.938534 --> 0.937087).  Saving model ...
Validation loss decreased (0.937087 --> 0.936769).  Saving model ...
Validation loss decreased (0.936769 --> 0.936284).  Saving model ...
Validation loss decreased (0.936284 --> 0.935114).  Saving model ...
Validation loss decreased (0.935114 --> 0.934892).  Saving model ...
EarlyStopping counter: 1 out of 10.0
Validation loss decreased (0.934892 --> 0.934747).  Saving model ...
Validation loss decreased (0.934747 --> 0.934306).  Saving model ...
Validation loss decreased (0.934306 --> 0.934173).  Saving model ...
Validation loss decreased (0.934173 --> 0.934107).  Saving model ...
Validation loss decreased (0.934107 --> 0.933750).  Saving model ...
Validation loss decreased (0.933750 --> 0.933122).  Saving model ...
Validation loss decreased (0.933122 --> 0.932506).  Saving model ...
Validation loss decreased (0.932506 --> 0.932271).  Saving model ...
EarlyStopping counter: 1 out of 10.0
Validation loss decreased (0.932271 --> 0.932135).  Saving model ...
Validation loss decreased (0.932135 --> 0.931707).  Saving model ...
Validation loss decreased (0.931707 --> 0.931195).  Saving model ...
EarlyStopping counter: 1 out of 10.0
Validation loss decreased (0.931195 --> 0.930713).  Saving model ...
EarlyStopping counter: 1 out of 10.0
EarlyStopping counter: 2 out of 10.0
EarlyStopping counter: 3 out of 10.0
Validation loss decreased (0.930713 --> 0.930659).  Saving model ...
EarlyStopping counter: 1 out of 10.0
Validation loss decreased (0.930659 --> 0.930298).  Saving model ...
Validation loss decreased (0.930298 --> 0.929655).  Saving model ...
Validation loss decreased (0.929655 --> 0.929524).  Saving model ...
Validation loss decreased (0.929524 --> 0.929475).  Saving model ...
EarlyStopping counter: 1 out of 10.0
EarlyStopping counter: 2 out of 10.0
Validation loss decreased (0.929475 --> 0.929432).  Saving model ...
EarlyStopping counter: 1 out of 10.0
Validation loss decreased (0.929432 --> 0.929152).  Saving model ...
Validation loss decreased (0.929152 --> 0.929116).  Saving model ...
EarlyStopping counter: 1 out of 10.0
EarlyStopping counter: 2 out of 10.0
EarlyStopping counter: 3 out of 10.0
EarlyStopping counter: 4 out of 10.0
EarlyStopping counter: 5 out of 10.0
EarlyStopping counter: 6 out of 10.0
EarlyStopping counter: 7 out of 10.0
EarlyStopping counter: 8 out of 10.0
EarlyStopping counter: 9 out of 10.0
EarlyStopping counter: 10 out of 10.0
/localscratch/yinan.29027971.0/env/lib/python3.7/site-packages/torch/nn/functional.py:1794: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.
  warnings.warn("nn.functional.tanh is deprecated. Use torch.tanh instead.")
wandb: Waiting for W&B process to finish, PID 168727... (success).
wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: \ 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: | 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: / 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: \ 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: | 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: / 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: \ 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: | 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: / 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: \ 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb:                                                                                
wandb: Run history:
wandb:     e_F1 ▁▃▄▄▅▅▆▆▆▆▆▇▆▇▇▇▇▇▇▇▇▇██████████████████
wandb:   e_loss █▇▇▇▇▆▆▅▅▄▄▄▄▃▃▃▃▂▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:     t_F1 ▁▁▂▂▂▃▃▄▅▅▅▅▆▅▅▆▆▆▆▆▆▆▆▆▇▇▇▇▇▇▇▇▇▇▇▇████
wandb:   t_loss ██▇▇▇▇▇▆▆▆▅▅▅▅▅▄▄▄▄▃▃▃▃▃▃▃▂▂▂▂▂▂▂▂▂▂▁▁▁▁
wandb: 
wandb: Run summary:
wandb:     e_F1 61.81063
wandb:   e_loss 0.93021
wandb:     t_F1 76.13223
wandb:   t_loss 0.68841
wandb: 
wandb: Synced 4 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Synced dry-glade-3: https://wandb.ai/yinanazhou/xl_512_bs_8_lr_1e06_es_10_lc_True_nr_True_sr_True_stem_False_lemma_False_repeat_3_fold_2/runs/3dk1m6y9
wandb: Find logs at: ./wandb/run-20220316_112135-3dk1m6y9/logs/debug.log
wandb: 

wandb: wandb version 0.12.11 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
2022-03-16 13:15:22.351587: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1
wandb: Tracking run with wandb version 0.12.5
wandb: Syncing run fearless-water-2
wandb: ⭐️ View project at https://wandb.ai/yinanazhou/xl_512_bs_8_lr_1e06_es_10_lc_True_nr_True_sr_True_stem_False_lemma_False_repeat_4_fold_1
wandb: 🚀 View run at https://wandb.ai/yinanazhou/xl_512_bs_8_lr_1e06_es_10_lc_True_nr_True_sr_True_stem_False_lemma_False_repeat_4_fold_1/runs/2wnpn0b5
wandb: Run data is saved locally in /project/6002780/yinan/Thesis_MER_Lyrics/lyric-emotion/wandb/run-20220316_131518-2wnpn0b5
wandb: Run `wandb offline` to turn off syncing.

Validation loss decreased (inf --> 1.418316).  Saving model ...
Validation loss decreased (1.418316 --> 1.402551).  Saving model ...
Validation loss decreased (1.402551 --> 1.390866).  Saving model ...
Validation loss decreased (1.390866 --> 1.382011).  Saving model ...
Validation loss decreased (1.382011 --> 1.374970).  Saving model ...
Validation loss decreased (1.374970 --> 1.369514).  Saving model ...
Validation loss decreased (1.369514 --> 1.364204).  Saving model ...
Validation loss decreased (1.364204 --> 1.359647).  Saving model ...
Validation loss decreased (1.359647 --> 1.354810).  Saving model ...
Validation loss decreased (1.354810 --> 1.350070).  Saving model ...
Validation loss decreased (1.350070 --> 1.345742).  Saving model ...
Validation loss decreased (1.345742 --> 1.341212).  Saving model ...
Validation loss decreased (1.341212 --> 1.336909).  Saving model ...
Validation loss decreased (1.336909 --> 1.332109).  Saving model ...
Validation loss decreased (1.332109 --> 1.327032).  Saving model ...
Validation loss decreased (1.327032 --> 1.322071).  Saving model ...
Validation loss decreased (1.322071 --> 1.316676).  Saving model ...
Validation loss decreased (1.316676 --> 1.311517).  Saving model ...
Validation loss decreased (1.311517 --> 1.306479).  Saving model ...
Validation loss decreased (1.306479 --> 1.301254).  Saving model ...
Validation loss decreased (1.301254 --> 1.295316).  Saving model ...
Validation loss decreased (1.295316 --> 1.289552).  Saving model ...
Validation loss decreased (1.289552 --> 1.283809).  Saving model ...
Validation loss decreased (1.283809 --> 1.278043).  Saving model ...
Validation loss decreased (1.278043 --> 1.271931).  Saving model ...
Validation loss decreased (1.271931 --> 1.266043).  Saving model ...
Validation loss decreased (1.266043 --> 1.260716).  Saving model ...
Validation loss decreased (1.260716 --> 1.254457).  Saving model ...
Validation loss decreased (1.254457 --> 1.248954).  Saving model ...
Validation loss decreased (1.248954 --> 1.242941).  Saving model ...
Validation loss decreased (1.242941 --> 1.237451).  Saving model ...
Validation loss decreased (1.237451 --> 1.231998).  Saving model ...
Validation loss decreased (1.231998 --> 1.226782).  Saving model ...
Validation loss decreased (1.226782 --> 1.221464).  Saving model ...
Validation loss decreased (1.221464 --> 1.215880).  Saving model ...
Validation loss decreased (1.215880 --> 1.210496).  Saving model ...
Validation loss decreased (1.210496 --> 1.205570).  Saving model ...
Validation loss decreased (1.205570 --> 1.201051).  Saving model ...
Validation loss decreased (1.201051 --> 1.196599).  Saving model ...
Validation loss decreased (1.196599 --> 1.191442).  Saving model ...
Validation loss decreased (1.191442 --> 1.186212).  Saving model ...
Validation loss decreased (1.186212 --> 1.180625).  Saving model ...
Validation loss decreased (1.180625 --> 1.176422).  Saving model ...
Validation loss decreased (1.176422 --> 1.171844).  Saving model ...
Validation loss decreased (1.171844 --> 1.167741).  Saving model ...
Validation loss decreased (1.167741 --> 1.163549).  Saving model ...
Validation loss decreased (1.163549 --> 1.159560).  Saving model ...
Validation loss decreased (1.159560 --> 1.156797).  Saving model ...
Validation loss decreased (1.156797 --> 1.152967).  Saving model ...
Validation loss decreased (1.152967 --> 1.148696).  Saving model ...
Validation loss decreased (1.148696 --> 1.144093).  Saving model ...
Validation loss decreased (1.144093 --> 1.139498).  Saving model ...
Validation loss decreased (1.139498 --> 1.135467).  Saving model ...
Validation loss decreased (1.135467 --> 1.131149).  Saving model ...
Validation loss decreased (1.131149 --> 1.128027).  Saving model ...
Validation loss decreased (1.128027 --> 1.123416).  Saving model ...
Validation loss decreased (1.123416 --> 1.119640).  Saving model ...
Validation loss decreased (1.119640 --> 1.116039).  Saving model ...
Validation loss decreased (1.116039 --> 1.112303).  Saving model ...
Validation loss decreased (1.112303 --> 1.108930).  Saving model ...
Validation loss decreased (1.108930 --> 1.105996).  Saving model ...
Validation loss decreased (1.105996 --> 1.102213).  Saving model ...
Validation loss decreased (1.102213 --> 1.099094).  Saving model ...
Validation loss decreased (1.099094 --> 1.095571).  Saving model ...
Validation loss decreased (1.095571 --> 1.092654).  Saving model ...
Validation loss decreased (1.092654 --> 1.089081).  Saving model ...
Validation loss decreased (1.089081 --> 1.085793).  Saving model ...
Validation loss decreased (1.085793 --> 1.082654).  Saving model ...
Validation loss decreased (1.082654 --> 1.078854).  Saving model ...
Validation loss decreased (1.078854 --> 1.076748).  Saving model ...
Validation loss decreased (1.076748 --> 1.073595).  Saving model ...
Validation loss decreased (1.073595 --> 1.071575).  Saving model ...
Validation loss decreased (1.071575 --> 1.068775).  Saving model ...
Validation loss decreased (1.068775 --> 1.065338).  Saving model ...
Validation loss decreased (1.065338 --> 1.062662).  Saving model ...
Validation loss decreased (1.062662 --> 1.060165).  Saving model ...
Validation loss decreased (1.060165 --> 1.058256).  Saving model ...
Validation loss decreased (1.058256 --> 1.055218).  Saving model ...
Validation loss decreased (1.055218 --> 1.052285).  Saving model ...
Validation loss decreased (1.052285 --> 1.049589).  Saving model ...
Validation loss decreased (1.049589 --> 1.046606).  Saving model ...
Validation loss decreased (1.046606 --> 1.045247).  Saving model ...
Validation loss decreased (1.045247 --> 1.042375).  Saving model ...
Validation loss decreased (1.042375 --> 1.039634).  Saving model ...
Validation loss decreased (1.039634 --> 1.037808).  Saving model ...
Validation loss decreased (1.037808 --> 1.035762).  Saving model ...
Validation loss decreased (1.035762 --> 1.033724).  Saving model ...
Validation loss decreased (1.033724 --> 1.032115).  Saving model ...
Validation loss decreased (1.032115 --> 1.029363).  Saving model ...
Validation loss decreased (1.029363 --> 1.026959).  Saving model ...
Validation loss decreased (1.026959 --> 1.026309).  Saving model ...
Validation loss decreased (1.026309 --> 1.025328).  Saving model ...
Validation loss decreased (1.025328 --> 1.022791).  Saving model ...
Validation loss decreased (1.022791 --> 1.020053).  Saving model ...
Validation loss decreased (1.020053 --> 1.018952).  Saving model ...
Validation loss decreased (1.018952 --> 1.017985).  Saving model ...
Validation loss decreased (1.017985 --> 1.016146).  Saving model ...
Validation loss decreased (1.016146 --> 1.014398).  Saving model ...
Validation loss decreased (1.014398 --> 1.013592).  Saving model ...
Validation loss decreased (1.013592 --> 1.012372).  Saving model ...
Validation loss decreased (1.012372 --> 1.011051).  Saving model ...
Validation loss decreased (1.011051 --> 1.010349).  Saving model ...
Validation loss decreased (1.010349 --> 1.009013).  Saving model ...
Validation loss decreased (1.009013 --> 1.007589).  Saving model ...
Validation loss decreased (1.007589 --> 1.007131).  Saving model ...
Validation loss decreased (1.007131 --> 1.005969).  Saving model ...
Validation loss decreased (1.005969 --> 1.005165).  Saving model ...
Validation loss decreased (1.005165 --> 1.005127).  Saving model ...
Validation loss decreased (1.005127 --> 1.003967).  Saving model ...
Validation loss decreased (1.003967 --> 1.002198).  Saving model ...
Validation loss decreased (1.002198 --> 1.001679).  Saving model ...
Validation loss decreased (1.001679 --> 1.000624).  Saving model ...
Validation loss decreased (1.000624 --> 0.999007).  Saving model ...
Validation loss decreased (0.999007 --> 0.998290).  Saving model ...
Validation loss decreased (0.998290 --> 0.998004).  Saving model ...
Validation loss decreased (0.998004 --> 0.996436).  Saving model ...
Validation loss decreased (0.996436 --> 0.996209).  Saving model ...
EarlyStopping counter: 1 out of 10.0
Validation loss decreased (0.996209 --> 0.995119).  Saving model ...
Validation loss decreased (0.995119 --> 0.994013).  Saving model ...
Validation loss decreased (0.994013 --> 0.993372).  Saving model ...
Validation loss decreased (0.993372 --> 0.992150).  Saving model ...
Validation loss decreased (0.992150 --> 0.991680).  Saving model ...
Validation loss decreased (0.991680 --> 0.990399).  Saving model ...
Validation loss decreased (0.990399 --> 0.990008).  Saving model ...
Validation loss decreased (0.990008 --> 0.989003).  Saving model ...
Validation loss decreased (0.989003 --> 0.988907).  Saving model ...
Validation loss decreased (0.988907 --> 0.988846).  Saving model ...
EarlyStopping counter: 1 out of 10.0
EarlyStopping counter: 2 out of 10.0
Validation loss decreased (0.988846 --> 0.988730).  Saving model ...
EarlyStopping counter: 1 out of 10.0
Validation loss decreased (0.988730 --> 0.987351).  Saving model ...
EarlyStopping counter: 1 out of 10.0
Validation loss decreased (0.987351 --> 0.986702).  Saving model ...
Validation loss decreased (0.986702 --> 0.985001).  Saving model ...
Validation loss decreased (0.985001 --> 0.984345).  Saving model ...
EarlyStopping counter: 1 out of 10.0
EarlyStopping counter: 2 out of 10.0
EarlyStopping counter: 3 out of 10.0
Validation loss decreased (0.984345 --> 0.984300).  Saving model ...
Validation loss decreased (0.984300 --> 0.983755).  Saving model ...
EarlyStopping counter: 1 out of 10.0
EarlyStopping counter: 2 out of 10.0
EarlyStopping counter: 3 out of 10.0
EarlyStopping counter: 4 out of 10.0
EarlyStopping counter: 5 out of 10.0
EarlyStopping counter: 6 out of 10.0
EarlyStopping counter: 7 out of 10.0
EarlyStopping counter: 8 out of 10.0
EarlyStopping counter: 9 out of 10.0
EarlyStopping counter: 10 out of 10.0
/localscratch/yinan.29027971.0/env/lib/python3.7/site-packages/torch/nn/functional.py:1794: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.
  warnings.warn("nn.functional.tanh is deprecated. Use torch.tanh instead.")
wandb: Waiting for W&B process to finish, PID 174820... (success).
wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: \ 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: | 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: / 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb:                                                                                
wandb: Run history:
wandb:     e_F1 ▁▂▃▄▄▅▅▅▆▆▆▆▆▆▆▇▇▇▇▇▇▇██████████████████
wandb:   e_loss ██▇▇▇▆▆▆▅▅▄▄▄▄▃▃▃▃▃▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:     t_F1 ▁▁▂▃▃▃▄▄▄▅▅▅▅▅▆▆▅▆▆▆▆▆▆▆▆▇▇▇▇▇▇▇▇██▇████
wandb:   t_loss ██▇▇▇▇▇▆▆▆▅▅▅▅▅▅▄▄▄▄▃▃▃▃▃▃▃▂▂▂▂▂▂▂▂▂▁▁▁▁
wandb: 
wandb: Run summary:
wandb:     e_F1 57.76147
wandb:   e_loss 0.98583
wandb:     t_F1 72.00261
wandb:   t_loss 0.73832
wandb: 
wandb: Synced 4 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Synced fearless-water-2: https://wandb.ai/yinanazhou/xl_512_bs_8_lr_1e06_es_10_lc_True_nr_True_sr_True_stem_False_lemma_False_repeat_4_fold_1/runs/2wnpn0b5
wandb: Find logs at: ./wandb/run-20220316_131518-2wnpn0b5/logs/debug.log
wandb: 

wandb: wandb version 0.12.11 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
2022-03-16 14:56:16.166859: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1
wandb: Tracking run with wandb version 0.12.5
wandb: Syncing run copper-dawn-2
wandb: ⭐️ View project at https://wandb.ai/yinanazhou/xl_512_bs_8_lr_1e06_es_10_lc_True_nr_True_sr_True_stem_False_lemma_False_repeat_4_fold_2
wandb: 🚀 View run at https://wandb.ai/yinanazhou/xl_512_bs_8_lr_1e06_es_10_lc_True_nr_True_sr_True_stem_False_lemma_False_repeat_4_fold_2/runs/3gb497r4
wandb: Run data is saved locally in /project/6002780/yinan/Thesis_MER_Lyrics/lyric-emotion/wandb/run-20220316_145612-3gb497r4
wandb: Run `wandb offline` to turn off syncing.

Validation loss decreased (inf --> 1.461491).  Saving model ...
Validation loss decreased (1.461491 --> 1.427808).  Saving model ...
Validation loss decreased (1.427808 --> 1.405507).  Saving model ...
Validation loss decreased (1.405507 --> 1.390636).  Saving model ...
Validation loss decreased (1.390636 --> 1.380944).  Saving model ...
Validation loss decreased (1.380944 --> 1.373955).  Saving model ...
Validation loss decreased (1.373955 --> 1.368486).  Saving model ...
Validation loss decreased (1.368486 --> 1.364093).  Saving model ...
Validation loss decreased (1.364093 --> 1.359905).  Saving model ...
Validation loss decreased (1.359905 --> 1.355665).  Saving model ...
Validation loss decreased (1.355665 --> 1.351350).  Saving model ...
Validation loss decreased (1.351350 --> 1.347490).  Saving model ...
Validation loss decreased (1.347490 --> 1.342986).  Saving model ...
Validation loss decreased (1.342986 --> 1.338480).  Saving model ...
Validation loss decreased (1.338480 --> 1.333870).  Saving model ...
Validation loss decreased (1.333870 --> 1.329180).  Saving model ...
Validation loss decreased (1.329180 --> 1.323395).  Saving model ...
Validation loss decreased (1.323395 --> 1.316731).  Saving model ...
Validation loss decreased (1.316731 --> 1.311029).  Saving model ...
Validation loss decreased (1.311029 --> 1.305428).  Saving model ...
Validation loss decreased (1.305428 --> 1.299253).  Saving model ...
Validation loss decreased (1.299253 --> 1.292071).  Saving model ...
Validation loss decreased (1.292071 --> 1.286991).  Saving model ...
Validation loss decreased (1.286991 --> 1.279905).  Saving model ...
Validation loss decreased (1.279905 --> 1.271597).  Saving model ...
Validation loss decreased (1.271597 --> 1.264156).  Saving model ...
Validation loss decreased (1.264156 --> 1.257965).  Saving model ...
Validation loss decreased (1.257965 --> 1.251326).  Saving model ...
Validation loss decreased (1.251326 --> 1.244032).  Saving model ...
Validation loss decreased (1.244032 --> 1.237868).  Saving model ...
Validation loss decreased (1.237868 --> 1.233367).  Saving model ...
Validation loss decreased (1.233367 --> 1.230793).  Saving model ...
Validation loss decreased (1.230793 --> 1.224511).  Saving model ...
Validation loss decreased (1.224511 --> 1.220948).  Saving model ...
Validation loss decreased (1.220948 --> 1.215348).  Saving model ...
Validation loss decreased (1.215348 --> 1.211229).  Saving model ...
Validation loss decreased (1.211229 --> 1.203351).  Saving model ...
Validation loss decreased (1.203351 --> 1.199608).  Saving model ...
Validation loss decreased (1.199608 --> 1.195337).  Saving model ...
Validation loss decreased (1.195337 --> 1.192755).  Saving model ...
Validation loss decreased (1.192755 --> 1.187294).  Saving model ...
Validation loss decreased (1.187294 --> 1.179500).  Saving model ...
Validation loss decreased (1.179500 --> 1.174355).  Saving model ...
Validation loss decreased (1.174355 --> 1.169115).  Saving model ...
Validation loss decreased (1.169115 --> 1.166098).  Saving model ...
Validation loss decreased (1.166098 --> 1.160791).  Saving model ...
Validation loss decreased (1.160791 --> 1.157635).  Saving model ...
Validation loss decreased (1.157635 --> 1.152250).  Saving model ...
Validation loss decreased (1.152250 --> 1.147649).  Saving model ...
Validation loss decreased (1.147649 --> 1.146419).  Saving model ...
Validation loss decreased (1.146419 --> 1.140907).  Saving model ...
Validation loss decreased (1.140907 --> 1.133252).  Saving model ...
Validation loss decreased (1.133252 --> 1.129769).  Saving model ...
Validation loss decreased (1.129769 --> 1.125718).  Saving model ...
Validation loss decreased (1.125718 --> 1.121213).  Saving model ...
Validation loss decreased (1.121213 --> 1.115827).  Saving model ...
EarlyStopping counter: 1 out of 10.0
Validation loss decreased (1.115827 --> 1.115459).  Saving model ...
Validation loss decreased (1.115459 --> 1.111420).  Saving model ...
Validation loss decreased (1.111420 --> 1.106922).  Saving model ...
Validation loss decreased (1.106922 --> 1.102194).  Saving model ...
Validation loss decreased (1.102194 --> 1.098991).  Saving model ...
Validation loss decreased (1.098991 --> 1.095318).  Saving model ...
Validation loss decreased (1.095318 --> 1.091375).  Saving model ...
Validation loss decreased (1.091375 --> 1.088861).  Saving model ...
Validation loss decreased (1.088861 --> 1.085485).  Saving model ...
Validation loss decreased (1.085485 --> 1.080271).  Saving model ...
Validation loss decreased (1.080271 --> 1.074142).  Saving model ...
Validation loss decreased (1.074142 --> 1.072851).  Saving model ...
Validation loss decreased (1.072851 --> 1.070922).  Saving model ...
Validation loss decreased (1.070922 --> 1.069065).  Saving model ...
Validation loss decreased (1.069065 --> 1.066943).  Saving model ...
Validation loss decreased (1.066943 --> 1.066043).  Saving model ...
Validation loss decreased (1.066043 --> 1.061776).  Saving model ...
Validation loss decreased (1.061776 --> 1.059327).  Saving model ...
Validation loss decreased (1.059327 --> 1.055817).  Saving model ...
Validation loss decreased (1.055817 --> 1.052243).  Saving model ...
Validation loss decreased (1.052243 --> 1.051415).  Saving model ...
Validation loss decreased (1.051415 --> 1.049496).  Saving model ...
Validation loss decreased (1.049496 --> 1.046314).  Saving model ...
EarlyStopping counter: 1 out of 10.0
Validation loss decreased (1.046314 --> 1.043369).  Saving model ...
Validation loss decreased (1.043369 --> 1.042033).  Saving model ...
EarlyStopping counter: 1 out of 10.0
Validation loss decreased (1.042033 --> 1.038955).  Saving model ...
EarlyStopping counter: 1 out of 10.0
Validation loss decreased (1.038955 --> 1.036206).  Saving model ...
Validation loss decreased (1.036206 --> 1.033715).  Saving model ...
Validation loss decreased (1.033715 --> 1.030265).  Saving model ...
Validation loss decreased (1.030265 --> 1.029329).  Saving model ...
Validation loss decreased (1.029329 --> 1.028351).  Saving model ...
Validation loss decreased (1.028351 --> 1.027640).  Saving model ...
Validation loss decreased (1.027640 --> 1.025708).  Saving model ...
Validation loss decreased (1.025708 --> 1.022592).  Saving model ...
Validation loss decreased (1.022592 --> 1.018617).  Saving model ...
EarlyStopping counter: 1 out of 10.0
EarlyStopping counter: 2 out of 10.0
EarlyStopping counter: 3 out of 10.0
EarlyStopping counter: 4 out of 10.0
EarlyStopping counter: 5 out of 10.0
Validation loss decreased (1.018617 --> 1.016797).  Saving model ...
Validation loss decreased (1.016797 --> 1.015230).  Saving model ...
EarlyStopping counter: 1 out of 10.0
EarlyStopping counter: 2 out of 10.0
EarlyStopping counter: 3 out of 10.0
Validation loss decreased (1.015230 --> 1.011320).  Saving model ...
EarlyStopping counter: 1 out of 10.0
Validation loss decreased (1.011320 --> 1.010063).  Saving model ...
EarlyStopping counter: 1 out of 10.0
EarlyStopping counter: 2 out of 10.0
Validation loss decreased (1.010063 --> 1.009092).  Saving model ...
EarlyStopping counter: 1 out of 10.0
Validation loss decreased (1.009092 --> 1.007678).  Saving model ...
EarlyStopping counter: 1 out of 10.0
EarlyStopping counter: 2 out of 10.0
Validation loss decreased (1.007678 --> 1.005408).  Saving model ...
EarlyStopping counter: 1 out of 10.0
EarlyStopping counter: 2 out of 10.0
Validation loss decreased (1.005408 --> 1.004209).  Saving model ...
EarlyStopping counter: 1 out of 10.0
EarlyStopping counter: 2 out of 10.0
EarlyStopping counter: 3 out of 10.0
EarlyStopping counter: 4 out of 10.0
EarlyStopping counter: 5 out of 10.0
EarlyStopping counter: 6 out of 10.0
Validation loss decreased (1.004209 --> 1.003966).  Saving model ...
EarlyStopping counter: 1 out of 10.0
EarlyStopping counter: 2 out of 10.0
Validation loss decreased (1.003966 --> 1.003932).  Saving model ...
EarlyStopping counter: 1 out of 10.0
EarlyStopping counter: 2 out of 10.0
Validation loss decreased (1.003932 --> 1.002449).  Saving model ...
Validation loss decreased (1.002449 --> 1.001839).  Saving model ...
EarlyStopping counter: 1 out of 10.0
Validation loss decreased (1.001839 --> 0.999230).  Saving model ...
Validation loss decreased (0.999230 --> 0.997311).  Saving model ...
EarlyStopping counter: 1 out of 10.0
EarlyStopping counter: 2 out of 10.0
EarlyStopping counter: 3 out of 10.0
Validation loss decreased (0.997311 --> 0.995707).  Saving model ...
EarlyStopping counter: 1 out of 10.0
EarlyStopping counter: 2 out of 10.0
EarlyStopping counter: 3 out of 10.0
Validation loss decreased (0.995707 --> 0.994833).  Saving model ...
EarlyStopping counter: 1 out of 10.0
EarlyStopping counter: 2 out of 10.0
EarlyStopping counter: 3 out of 10.0
EarlyStopping counter: 4 out of 10.0
EarlyStopping counter: 5 out of 10.0
EarlyStopping counter: 6 out of 10.0
EarlyStopping counter: 7 out of 10.0
EarlyStopping counter: 8 out of 10.0
EarlyStopping counter: 9 out of 10.0
EarlyStopping counter: 10 out of 10.0
/localscratch/yinan.29027971.0/env/lib/python3.7/site-packages/torch/nn/functional.py:1794: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.
  warnings.warn("nn.functional.tanh is deprecated. Use torch.tanh instead.")
wandb: Waiting for W&B process to finish, PID 180226... (success).
wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: \ 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: | 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: / 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: \ 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: | 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: / 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: \ 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: | 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: / 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: \ 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb:                                                                                
wandb: Run history:
wandb:     e_F1 ▁▂▄▄▄▅▅▆▆▆▆▇▇▇▇▇▇▇▇▇▇▇▇▇████████████████
wandb:   e_loss █▇▇▇▆▆▆▅▅▄▄▄▃▃▃▃▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:     t_F1 ▁▁▂▂▃▃▄▄▅▅▅▅▅▅▅▆▆▆▆▆▆▆▇▆▇▇▇▇▇▇▇██▇█▇████
wandb:   t_loss ██▇▇▇▇▆▆▆▆▅▅▅▅▅▄▄▄▄▄▄▃▃▃▃▃▂▃▂▂▂▂▂▂▂▂▁▁▁▁
wandb: 
wandb: Run summary:
wandb:     e_F1 56.32993
wandb:   e_loss 1.00822
wandb:     t_F1 74.75809
wandb:   t_loss 0.68782
wandb: 
wandb: Synced 4 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Synced copper-dawn-2: https://wandb.ai/yinanazhou/xl_512_bs_8_lr_1e06_es_10_lc_True_nr_True_sr_True_stem_False_lemma_False_repeat_4_fold_2/runs/3gb497r4
wandb: Find logs at: ./wandb/run-20220316_145612-3gb497r4/logs/debug.log
wandb: 

wandb: wandb version 0.12.11 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
2022-03-16 16:37:05.675030: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1
wandb: Tracking run with wandb version 0.12.5
wandb: Syncing run sleek-voice-2
wandb: ⭐️ View project at https://wandb.ai/yinanazhou/xl_512_bs_8_lr_1e06_es_10_lc_True_nr_True_sr_True_stem_False_lemma_False_repeat_5_fold_1
wandb: 🚀 View run at https://wandb.ai/yinanazhou/xl_512_bs_8_lr_1e06_es_10_lc_True_nr_True_sr_True_stem_False_lemma_False_repeat_5_fold_1/runs/1o6ibk3k
wandb: Run data is saved locally in /project/6002780/yinan/Thesis_MER_Lyrics/lyric-emotion/wandb/run-20220316_163702-1o6ibk3k
wandb: Run `wandb offline` to turn off syncing.
