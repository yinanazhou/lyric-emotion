Unloading StdEnv/2020

Due to MODULEPATH changes, the following have been reloaded:
  1) mii/1.1.1


The following have been reloaded with a version change:
  1) python/3.8.2 => python/3.7.4

Using base prefix '/cvmfs/soft.computecanada.ca/easybuild/software/2017/Core/python/3.7.4'
New python executable in /localscratch/yinan.29161744.0/env/bin/python
Installing setuptools, pip, wheel...
done.
Ignoring pip: markers 'python_version < "3"' don't match your environment
Looking in links: /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/nix/avx2, /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/nix/generic, /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic
Collecting pip
Installing collected packages: pip
  Found existing installation: pip 19.1.1
    Uninstalling pip-19.1.1:
      Successfully uninstalled pip-19.1.1
Successfully installed pip-21.2.3+computecanada
Looking in links: /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/nix/avx2, /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/nix/generic, /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/keras-2.8.0+computecanada-py2.py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/Keras_Preprocessing-1.1.2+computecanada-py3-none-any.whl
Requirement already satisfied: matplotlib in /cvmfs/soft.computecanada.ca/easybuild/software/2017/Core/scipy-stack/2019a/lib/python3.7/site-packages (from -r requirements.txt (line 3)) (3.0.2)
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/nltk-3.6.5+computecanada-py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/scikit_learn-0.22.1+computecanada-cp37-cp37m-linux_x86_64.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/tensorboard-2.3.0+computecanada-py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/tensorboard_plugin_wit-1.7.0+computecanada-py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/tensorflow_gpu-2.3.0+computecanada-cp37-cp37m-linux_x86_64.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/tensorflow_estimator-2.3.0+computecanada-py2.py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/tokenizers-0.5.2+computecanada-cp37-cp37m-linux_x86_64.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/nix/avx2/torch-1.4.0+computecanada-cp37-cp37m-linux_x86_64.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/torchtext-0.6.0+computecanada-py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/torchvision-0.8.2+computecanada-cp37-cp37m-linux_x86_64.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/transformers-2.5.1+computecanada-py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/urllib3-1.26.7+computecanada-py2.py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/tqdm-4.63.0+computecanada-py2.py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/click-8.0.4+computecanada-py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/joblib-1.1.0+computecanada-py2.py3-none-any.whl
ERROR: Could not find a version that satisfies the requirement regex>=2021.8.3 (from nltk) (from versions: 2018.1.10+computecanada, 2019.11.1+computecanada, 2020.11.13+computecanada)
ERROR: No matching distribution found for regex>=2021.8.3
Looking in links: /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/nix/avx2, /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/nix/generic, /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic
ERROR: Could not find a version that satisfies the requirement numpy==1.20.0+computacanada (from versions: 1.15.0+computecanada, 1.15.2+computecanada, 1.15.4+computecanada, 1.16.0+computecanada, 1.16.2+computecanada, 1.16.3+computecanada, 1.17.4+computecanada, 1.18.1+computecanada, 1.18.4+computecanada, 1.19.1+computecanada, 1.19.2+computecanada, 1.20.2+computecanada)
ERROR: No matching distribution found for numpy==1.20.0+computacanada
Looking in links: /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/nix/avx2, /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/nix/generic, /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/wandb-0.12.5+computecanada-py2.py3-none-any.whl
Requirement already satisfied: requests<3,>=2.0.0 in /cvmfs/soft.computecanada.ca/easybuild/software/2017/Core/scipy-stack/2019a/lib/python3.7/site-packages (from wandb) (2.21.0)
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/configparser-5.0.2+computecanada-py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/GitPython-3.1.24+computecanada-py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/psutil-5.7.3+computecanada-cp37-cp37m-linux_x86_64.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/shortuuid-1.0.1+computecanada-py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/sentry_sdk-1.5.0+computecanada-py2.py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/docker_pycreds-0.4.0+computecanada-py2.py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/protobuf-3.19.4+computecanada-py2.py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/subprocess32-3.5.4+computecanada-py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/click-8.0.4+computecanada-py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/pathtools-0.1.2+computecanada-py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/yaspin-2.1.0+computecanada-py3-none-any.whl
Requirement already satisfied: python-dateutil>=2.6.1 in /cvmfs/soft.computecanada.ca/easybuild/software/2017/Core/scipy-stack/2019a/lib/python3.7/site-packages (from wandb) (2.7.5)
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/PyYAML-5.3.1+computecanada-cp37-cp37m-linux_x86_64.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/six-1.16.0+computecanada-py2.py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/promise-2.3+computecanada-py3-none-any.whl
Requirement already satisfied: importlib-metadata in /cvmfs/soft.computecanada.ca/easybuild/software/2017/Core/scipy-stack/2019a/lib/python3.7/site-packages (from Click!=8.0.0,>=7.0->wandb) (0.8)
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/gitdb-4.0.9+computecanada-py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/typing_extensions-4.0.1+computecanada-py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/smmap-5.0.0+computecanada-py3-none-any.whl
Requirement already satisfied: idna<2.9,>=2.5 in /cvmfs/soft.computecanada.ca/easybuild/software/2017/Core/scipy-stack/2019a/lib/python3.7/site-packages (from requests<3,>=2.0.0->wandb) (2.8)
Requirement already satisfied: urllib3<1.25,>=1.21.1 in /cvmfs/soft.computecanada.ca/easybuild/software/2017/Core/scipy-stack/2019a/lib/python3.7/site-packages (from requests<3,>=2.0.0->wandb) (1.24.1)
Requirement already satisfied: certifi>=2017.4.17 in /cvmfs/soft.computecanada.ca/easybuild/software/2017/Core/scipy-stack/2019a/lib/python3.7/site-packages (from requests<3,>=2.0.0->wandb) (2018.11.29)
Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /cvmfs/soft.computecanada.ca/easybuild/software/2017/Core/scipy-stack/2019a/lib/python3.7/site-packages (from requests<3,>=2.0.0->wandb) (3.0.4)
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/termcolor-1.1.0+computecanada-py3-none-any.whl
Requirement already satisfied: zipp>=0.3.2 in /cvmfs/soft.computecanada.ca/easybuild/software/2017/Core/scipy-stack/2019a/lib/python3.7/site-packages (from importlib-metadata->Click!=8.0.0,>=7.0->wandb) (0.3.3)
Installing collected packages: smmap, typing-extensions, termcolor, six, gitdb, yaspin, subprocess32, shortuuid, sentry-sdk, PyYAML, psutil, protobuf, promise, pathtools, GitPython, docker-pycreds, configparser, Click, wandb
  Attempting uninstall: six
    Found existing installation: six 1.12.0
    Not uninstalling six at /cvmfs/soft.computecanada.ca/easybuild/software/2017/Core/scipy-stack/2019a/lib/python3.7/site-packages, outside environment /localscratch/yinan.29161744.0/env
    Can't uninstall 'six'. No files were found to uninstall.
Successfully installed Click-8.0.4+computecanada GitPython-3.1.24+computecanada PyYAML-5.3.1+computecanada configparser-5.0.2+computecanada docker-pycreds-0.4.0+computecanada gitdb-4.0.9+computecanada pathtools-0.1.2+computecanada promise-2.3+computecanada protobuf-3.19.4+computecanada psutil-5.7.3+computecanada sentry-sdk-1.5.0+computecanada shortuuid-1.0.1+computecanada six-1.16.0+computecanada smmap-5.0.0+computecanada subprocess32-3.5.4+computecanada termcolor-1.1.0+computecanada typing-extensions-4.0.1+computecanada wandb-0.12.5+computecanada yaspin-2.1.0+computecanada
Looking in links: /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/nix/avx2, /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/nix/generic, /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic
ERROR: Could not find a version that satisfies the requirement sagemaker (from versions: none)
ERROR: No matching distribution found for sagemaker
Looking in links: /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/nix/avx2, /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/nix/generic, /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/torch-1.9.1+computecanada-cp37-cp37m-linux_x86_64.whl
Requirement already satisfied: typing-extensions in /localscratch/yinan.29161744.0/env/lib/python3.7/site-packages (from torch) (4.0.1+computecanada)
Installing collected packages: torch
Successfully installed torch-1.9.1+computecanada
Looking in links: /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/nix/avx2, /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/nix/generic, /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/transformers-2.5.1+computecanada-py3-none-any.whl
Requirement already satisfied: numpy in /cvmfs/soft.computecanada.ca/easybuild/software/2017/Core/scipy-stack/2019a/lib/python3.7/site-packages (from transformers==2.5.1+computecanada) (1.16.0)
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/tqdm-4.63.0+computecanada-py2.py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/tokenizers-0.5.2+computecanada-cp37-cp37m-linux_x86_64.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/regex-2020.11.13+computecanada-cp37-cp37m-linux_x86_64.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/filelock-3.4.2+computecanada-py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/boto3-1.21.14+computecanada-py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/sacremoses-0.0.46+computecanada-py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/sentencepiece-0.1.91+computecanada-cp37-cp37m-linux_x86_64.whl
Requirement already satisfied: requests in /cvmfs/soft.computecanada.ca/easybuild/software/2017/Core/scipy-stack/2019a/lib/python3.7/site-packages (from transformers==2.5.1+computecanada) (2.21.0)
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/jmespath-0.10.0+computecanada-py2.py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/s3transfer-0.5.1+computecanada-py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/botocore-1.24.14+computecanada-py3-none-any.whl
Requirement already satisfied: python-dateutil<3.0.0,>=2.1 in /cvmfs/soft.computecanada.ca/easybuild/software/2017/Core/scipy-stack/2019a/lib/python3.7/site-packages (from botocore<1.25.0,>=1.24.14->boto3->transformers==2.5.1+computecanada) (2.7.5)
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/urllib3-1.26.8+computecanada-py2.py3-none-any.whl
Requirement already satisfied: six>=1.5 in /localscratch/yinan.29161744.0/env/lib/python3.7/site-packages (from python-dateutil<3.0.0,>=2.1->botocore<1.25.0,>=1.24.14->boto3->transformers==2.5.1+computecanada) (1.16.0+computecanada)
Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /cvmfs/soft.computecanada.ca/easybuild/software/2017/Core/scipy-stack/2019a/lib/python3.7/site-packages (from requests->transformers==2.5.1+computecanada) (3.0.4)
Requirement already satisfied: certifi>=2017.4.17 in /cvmfs/soft.computecanada.ca/easybuild/software/2017/Core/scipy-stack/2019a/lib/python3.7/site-packages (from requests->transformers==2.5.1+computecanada) (2018.11.29)
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/requests-2.27.1+computecanada-py2.py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/charset_normalizer-2.0.12+computecanada-py3-none-any.whl
Requirement already satisfied: idna<4,>=2.5 in /cvmfs/soft.computecanada.ca/easybuild/software/2017/Core/scipy-stack/2019a/lib/python3.7/site-packages (from requests->transformers==2.5.1+computecanada) (2.8)
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/joblib-1.1.0+computecanada-py2.py3-none-any.whl
Requirement already satisfied: click in /localscratch/yinan.29161744.0/env/lib/python3.7/site-packages (from sacremoses->transformers==2.5.1+computecanada) (8.0.4+computecanada)
Requirement already satisfied: importlib-metadata in /cvmfs/soft.computecanada.ca/easybuild/software/2017/Core/scipy-stack/2019a/lib/python3.7/site-packages (from click->sacremoses->transformers==2.5.1+computecanada) (0.8)
Requirement already satisfied: zipp>=0.3.2 in /cvmfs/soft.computecanada.ca/easybuild/software/2017/Core/scipy-stack/2019a/lib/python3.7/site-packages (from importlib-metadata->click->sacremoses->transformers==2.5.1+computecanada) (0.3.3)
Installing collected packages: urllib3, jmespath, botocore, tqdm, s3transfer, regex, joblib, charset-normalizer, tokenizers, sentencepiece, sacremoses, requests, filelock, boto3, transformers
  Attempting uninstall: urllib3
    Found existing installation: urllib3 1.24.1
    Not uninstalling urllib3 at /cvmfs/soft.computecanada.ca/easybuild/software/2017/Core/scipy-stack/2019a/lib/python3.7/site-packages, outside environment /localscratch/yinan.29161744.0/env
    Can't uninstall 'urllib3'. No files were found to uninstall.
  Attempting uninstall: requests
    Found existing installation: requests 2.21.0
    Not uninstalling requests at /cvmfs/soft.computecanada.ca/easybuild/software/2017/Core/scipy-stack/2019a/lib/python3.7/site-packages, outside environment /localscratch/yinan.29161744.0/env
    Can't uninstall 'requests'. No files were found to uninstall.
Successfully installed boto3-1.21.14+computecanada botocore-1.24.14+computecanada charset-normalizer-2.0.12+computecanada filelock-3.4.2+computecanada jmespath-0.10.0+computecanada joblib-1.1.0+computecanada regex-2020.11.13+computecanada requests-2.27.1+computecanada s3transfer-0.5.1+computecanada sacremoses-0.0.46+computecanada sentencepiece-0.1.91+computecanada tokenizers-0.5.2+computecanada tqdm-4.63.0+computecanada transformers-2.5.1+computecanada urllib3-1.26.8+computecanada
Looking in links: /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/nix/avx2, /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/nix/generic, /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/tensorflow_gpu-2.3.0+computecanada-cp37-cp37m-linux_x86_64.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/google_pasta-0.2.0+computecanada-py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/astunparse-1.6.3+computecanada-py2.py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/gast-0.3.3+computecanada-py3-none-any.whl
Requirement already satisfied: wheel>=0.26 in /localscratch/yinan.29161744.0/env/lib/python3.7/site-packages (from tensorflow_gpu==2.3.0+computecanada) (0.33.4)
Requirement already satisfied: six>=1.12.0 in /localscratch/yinan.29161744.0/env/lib/python3.7/site-packages (from tensorflow_gpu==2.3.0+computecanada) (1.16.0+computecanada)
Requirement already satisfied: protobuf>=3.9.2 in /localscratch/yinan.29161744.0/env/lib/python3.7/site-packages (from tensorflow_gpu==2.3.0+computecanada) (3.19.4+computecanada)
Requirement already satisfied: termcolor>=1.1.0 in /localscratch/yinan.29161744.0/env/lib/python3.7/site-packages (from tensorflow_gpu==2.3.0+computecanada) (1.1.0+computecanada)
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/wrapt-1.11.2+computecanada-cp37-cp37m-linux_x86_64.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/nix/avx2/h5py-2.10.0+computecanada-cp37-cp37m-linux_x86_64.whl
Requirement already satisfied: numpy<1.19.0,>=1.16.0 in /cvmfs/soft.computecanada.ca/easybuild/software/2017/Core/scipy-stack/2019a/lib/python3.7/site-packages (from tensorflow_gpu==2.3.0+computecanada) (1.16.0)
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/nix/generic/scipy-1.4.1+computecanada-cp37-cp37m-linux_x86_64.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/opt_einsum-3.3.0+computecanada-py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/grpcio-1.38.0+computecanada-cp37-cp37m-linux_x86_64.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/absl_py-1.0.0+computecanada-py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/Keras_Preprocessing-1.1.2+computecanada-py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/tensorflow_estimator-2.3.0+computecanada-py2.py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/tensorboard-2.8.0+computecanada-py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/Werkzeug-2.0.3+computecanada-py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/tensorboard_data_server-0.6.1+computecanada-py3-none-linux_x86_64.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/google_auth-2.3.3+computecanada-py2.py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/google_auth_oauthlib-0.4.6+computecanada-py2.py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/tensorboard_plugin_wit-1.8.0+computecanada-py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/Markdown-3.3.6+computecanada-py3-none-any.whl
Requirement already satisfied: requests<3,>=2.21.0 in /localscratch/yinan.29161744.0/env/lib/python3.7/site-packages (from tensorboard<3,>=2.3.0->tensorflow_gpu==2.3.0+computecanada) (2.27.1+computecanada)
Requirement already satisfied: setuptools>=41.0.0 in /localscratch/yinan.29161744.0/env/lib/python3.7/site-packages (from tensorboard<3,>=2.3.0->tensorflow_gpu==2.3.0+computecanada) (41.0.1)
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/pyasn1_modules-0.2.8+computecanada-py2.py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/cachetools-4.2.4+computecanada-py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/rsa-4.8+computecanada-py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/requests_oauthlib-1.3.0+computecanada-py2.py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/importlib_metadata-4.10.1+computecanada-py3-none-any.whl
Requirement already satisfied: typing-extensions>=3.6.4 in /localscratch/yinan.29161744.0/env/lib/python3.7/site-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard<3,>=2.3.0->tensorflow_gpu==2.3.0+computecanada) (4.0.1+computecanada)
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/zipp-3.7.0+computecanada-py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/pyasn1-0.4.8+computecanada-py2.py3-none-any.whl
Requirement already satisfied: charset-normalizer~=2.0.0 in /localscratch/yinan.29161744.0/env/lib/python3.7/site-packages (from requests<3,>=2.21.0->tensorboard<3,>=2.3.0->tensorflow_gpu==2.3.0+computecanada) (2.0.12+computecanada)
Requirement already satisfied: urllib3<1.27,>=1.21.1 in /localscratch/yinan.29161744.0/env/lib/python3.7/site-packages (from requests<3,>=2.21.0->tensorboard<3,>=2.3.0->tensorflow_gpu==2.3.0+computecanada) (1.26.8+computecanada)
Requirement already satisfied: certifi>=2017.4.17 in /cvmfs/soft.computecanada.ca/easybuild/software/2017/Core/scipy-stack/2019a/lib/python3.7/site-packages (from requests<3,>=2.21.0->tensorboard<3,>=2.3.0->tensorflow_gpu==2.3.0+computecanada) (2018.11.29)
Requirement already satisfied: idna<4,>=2.5 in /cvmfs/soft.computecanada.ca/easybuild/software/2017/Core/scipy-stack/2019a/lib/python3.7/site-packages (from requests<3,>=2.21.0->tensorboard<3,>=2.3.0->tensorflow_gpu==2.3.0+computecanada) (2.8)
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/oauthlib-3.1.1+computecanada-py2.py3-none-any.whl
Installing collected packages: pyasn1, zipp, rsa, pyasn1-modules, oauthlib, cachetools, requests-oauthlib, importlib-metadata, google-auth, werkzeug, tensorboard-plugin-wit, tensorboard-data-server, markdown, grpcio, google-auth-oauthlib, absl-py, wrapt, tensorflow-estimator, tensorboard, scipy, opt-einsum, keras-preprocessing, h5py, google-pasta, gast, astunparse, tensorflow-gpu
  Attempting uninstall: pyasn1
    Found existing installation: pyasn1 0.4.3
    Not uninstalling pyasn1 at /cvmfs/soft.computecanada.ca/easybuild/software/2017/Core/scipy-stack/2019a/lib/python3.7/site-packages, outside environment /localscratch/yinan.29161744.0/env
    Can't uninstall 'pyasn1'. No files were found to uninstall.
  Attempting uninstall: zipp
    Found existing installation: zipp 0.3.3
    Not uninstalling zipp at /cvmfs/soft.computecanada.ca/easybuild/software/2017/Core/scipy-stack/2019a/lib/python3.7/site-packages, outside environment /localscratch/yinan.29161744.0/env
    Can't uninstall 'zipp'. No files were found to uninstall.
  Attempting uninstall: importlib-metadata
    Found existing installation: importlib-metadata 0.8
    Not uninstalling importlib-metadata at /cvmfs/soft.computecanada.ca/easybuild/software/2017/Core/scipy-stack/2019a/lib/python3.7/site-packages, outside environment /localscratch/yinan.29161744.0/env
    Can't uninstall 'importlib-metadata'. No files were found to uninstall.
  Attempting uninstall: scipy
    Found existing installation: scipy 1.2.0
    Not uninstalling scipy at /cvmfs/soft.computecanada.ca/easybuild/software/2017/Core/scipy-stack/2019a/lib/python3.7/site-packages, outside environment /localscratch/yinan.29161744.0/env
    Can't uninstall 'scipy'. No files were found to uninstall.
Successfully installed absl-py-1.0.0+computecanada astunparse-1.6.3+computecanada cachetools-4.2.4+computecanada gast-0.3.3+computecanada google-auth-2.3.3+computecanada google-auth-oauthlib-0.4.6+computecanada google-pasta-0.2.0+computecanada grpcio-1.38.0+computecanada h5py-2.10.0+computecanada importlib-metadata-4.10.1+computecanada keras-preprocessing-1.1.2+computecanada markdown-3.3.6+computecanada oauthlib-3.1.1+computecanada opt-einsum-3.3.0+computecanada pyasn1-0.4.8+computecanada pyasn1-modules-0.2.8+computecanada requests-oauthlib-1.3.0+computecanada rsa-4.8+computecanada scipy-1.4.1+computecanada tensorboard-2.8.0+computecanada tensorboard-data-server-0.6.1+computecanada tensorboard-plugin-wit-1.8.0+computecanada tensorflow-estimator-2.3.0+computecanada tensorflow-gpu-2.3.0+computecanada werkzeug-2.0.3+computecanada wrapt-1.11.2+computecanada zipp-3.7.0+computecanada
Looking in links: /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/nix/avx2, /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/nix/generic, /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/keras-2.8.0+computecanada-py2.py3-none-any.whl
Installing collected packages: Keras
Successfully installed Keras-2.8.0+computecanada
Looking in links: /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/nix/avx2, /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/nix/generic, /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/urllib3-1.26.7+computecanada-py2.py3-none-any.whl
Installing collected packages: urllib3
  Attempting uninstall: urllib3
    Found existing installation: urllib3 1.26.8+computecanada
    Uninstalling urllib3-1.26.8+computecanada:
      Successfully uninstalled urllib3-1.26.8+computecanada
Successfully installed urllib3-1.26.7+computecanada
Looking in links: /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/nix/avx2, /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/nix/generic, /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/nltk-3.7+computecanada-py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/nltk-3.6.5+computecanada-py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/nltk-3.6.3+computecanada-py3-none-any.whl
Requirement already satisfied: click in /localscratch/yinan.29161744.0/env/lib/python3.7/site-packages (from nltk) (8.0.4+computecanada)
Requirement already satisfied: tqdm in /localscratch/yinan.29161744.0/env/lib/python3.7/site-packages (from nltk) (4.63.0+computecanada)
Requirement already satisfied: regex in /localscratch/yinan.29161744.0/env/lib/python3.7/site-packages (from nltk) (2020.11.13+computecanada)
Requirement already satisfied: joblib in /localscratch/yinan.29161744.0/env/lib/python3.7/site-packages (from nltk) (1.1.0+computecanada)
Requirement already satisfied: importlib-metadata in /localscratch/yinan.29161744.0/env/lib/python3.7/site-packages (from click->nltk) (4.10.1+computecanada)
Requirement already satisfied: typing-extensions>=3.6.4 in /localscratch/yinan.29161744.0/env/lib/python3.7/site-packages (from importlib-metadata->click->nltk) (4.0.1+computecanada)
Requirement already satisfied: zipp>=0.5 in /localscratch/yinan.29161744.0/env/lib/python3.7/site-packages (from importlib-metadata->click->nltk) (3.7.0+computecanada)
Installing collected packages: nltk
Successfully installed nltk-3.6.3+computecanada
Looking in links: /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/nix/avx2, /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/nix/generic, /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/scikit_learn-0.22.1+computecanada-cp37-cp37m-linux_x86_64.whl
Requirement already satisfied: joblib>=0.11 in /localscratch/yinan.29161744.0/env/lib/python3.7/site-packages (from scikit-learn==0.22.1) (1.1.0+computecanada)
Requirement already satisfied: numpy>=1.11.0 in /cvmfs/soft.computecanada.ca/easybuild/software/2017/Core/scipy-stack/2019a/lib/python3.7/site-packages (from scikit-learn==0.22.1) (1.16.0)
Requirement already satisfied: scipy>=0.17.0 in /localscratch/yinan.29161744.0/env/lib/python3.7/site-packages (from scikit-learn==0.22.1) (1.4.1+computecanada)
Installing collected packages: scikit-learn
Successfully installed scikit-learn-0.22.1+computecanada
Looking in links: /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/nix/avx2, /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/nix/generic, /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic
Requirement already satisfied: tokenizers==0.5.2 in /localscratch/yinan.29161744.0/env/lib/python3.7/site-packages (0.5.2+computecanada)
wandb: Appending key for api.wandb.ai to your netrc file: /home/yinan/.netrc
Starting Task
2022-03-17 21:20:39.502862: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1
[nltk_data] Downloading package stopwords to /home/yinan/nltk_data...
[nltk_data]   Package stopwords is already up-to-date!
[nltk_data] Downloading package wordnet to /home/yinan/nltk_data...
[nltk_data]   Package wordnet is already up-to-date!
wandb: Currently logged in as: yinanazhou (use `wandb login --relogin` to force relogin)
wandb: wandb version 0.12.11 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
2022-03-17 21:20:57.269596: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1
wandb: Tracking run with wandb version 0.12.5
wandb: Syncing run giddy-dawn-1
wandb: ⭐️ View project at https://wandb.ai/yinanazhou/xl_512_bs_8_lr_1e06_es_5_lc_False_nr_True_sr_True_stem_True_lemma_False_repeat_1_fold_1
wandb: 🚀 View run at https://wandb.ai/yinanazhou/xl_512_bs_8_lr_1e06_es_5_lc_False_nr_True_sr_True_stem_True_lemma_False_repeat_1_fold_1/runs/20526l20
wandb: Run data is saved locally in /project/6002780/yinan/Thesis_MER_Lyrics/lyric-emotion/wandb/run-20220317_212055-20526l20
wandb: Run `wandb offline` to turn off syncing.
wandb: Network error (ReadTimeout), entering retry loop.

Validation loss decreased (inf --> 1.429061).  Saving model ...
Validation loss decreased (1.429061 --> 1.410923).  Saving model ...
Validation loss decreased (1.410923 --> 1.396220).  Saving model ...
Validation loss decreased (1.396220 --> 1.383883).  Saving model ...
Validation loss decreased (1.383883 --> 1.374713).  Saving model ...
Validation loss decreased (1.374713 --> 1.366893).  Saving model ...
Validation loss decreased (1.366893 --> 1.360546).  Saving model ...
Validation loss decreased (1.360546 --> 1.354942).  Saving model ...
Validation loss decreased (1.354942 --> 1.350245).  Saving model ...
Validation loss decreased (1.350245 --> 1.345299).  Saving model ...
Validation loss decreased (1.345299 --> 1.339772).  Saving model ...
Validation loss decreased (1.339772 --> 1.334600).  Saving model ...
Validation loss decreased (1.334600 --> 1.329052).  Saving model ...
Validation loss decreased (1.329052 --> 1.324025).  Saving model ...
Validation loss decreased (1.324025 --> 1.318539).  Saving model ...
Validation loss decreased (1.318539 --> 1.313376).  Saving model ...
Validation loss decreased (1.313376 --> 1.307915).  Saving model ...
Validation loss decreased (1.307915 --> 1.303603).  Saving model ...
Validation loss decreased (1.303603 --> 1.298103).  Saving model ...
Validation loss decreased (1.298103 --> 1.292292).  Saving model ...
Validation loss decreased (1.292292 --> 1.286369).  Saving model ...
Validation loss decreased (1.286369 --> 1.281732).  Saving model ...
Validation loss decreased (1.281732 --> 1.278885).  Saving model ...
Validation loss decreased (1.278885 --> 1.273838).  Saving model ...
Validation loss decreased (1.273838 --> 1.268387).  Saving model ...
Validation loss decreased (1.268387 --> 1.264261).  Saving model ...
Validation loss decreased (1.264261 --> 1.261322).  Saving model ...
Validation loss decreased (1.261322 --> 1.258291).  Saving model ...
Validation loss decreased (1.258291 --> 1.254029).  Saving model ...
Validation loss decreased (1.254029 --> 1.251087).  Saving model ...
Validation loss decreased (1.251087 --> 1.245624).  Saving model ...
Validation loss decreased (1.245624 --> 1.242570).  Saving model ...
Validation loss decreased (1.242570 --> 1.240108).  Saving model ...
Validation loss decreased (1.240108 --> 1.235452).  Saving model ...
Validation loss decreased (1.235452 --> 1.233233).  Saving model ...
Validation loss decreased (1.233233 --> 1.229595).  Saving model ...
Validation loss decreased (1.229595 --> 1.226534).  Saving model ...
Validation loss decreased (1.226534 --> 1.221837).  Saving model ...
Validation loss decreased (1.221837 --> 1.218539).  Saving model ...
Validation loss decreased (1.218539 --> 1.215724).  Saving model ...
Validation loss decreased (1.215724 --> 1.212595).  Saving model ...
Validation loss decreased (1.212595 --> 1.207227).  Saving model ...
Validation loss decreased (1.207227 --> 1.203041).  Saving model ...
Validation loss decreased (1.203041 --> 1.200651).  Saving model ...
Validation loss decreased (1.200651 --> 1.196784).  Saving model ...
Validation loss decreased (1.196784 --> 1.193964).  Saving model ...
Validation loss decreased (1.193964 --> 1.191866).  Saving model ...
Validation loss decreased (1.191866 --> 1.188688).  Saving model ...
Validation loss decreased (1.188688 --> 1.184022).  Saving model ...
Validation loss decreased (1.184022 --> 1.179865).  Saving model ...
Validation loss decreased (1.179865 --> 1.175976).  Saving model ...
Validation loss decreased (1.175976 --> 1.172030).  Saving model ...
Validation loss decreased (1.172030 --> 1.169250).  Saving model ...
Validation loss decreased (1.169250 --> 1.168267).  Saving model ...
Validation loss decreased (1.168267 --> 1.167782).  Saving model ...
Validation loss decreased (1.167782 --> 1.162960).  Saving model ...
Validation loss decreased (1.162960 --> 1.159201).  Saving model ...
Validation loss decreased (1.159201 --> 1.156651).  Saving model ...
Validation loss decreased (1.156651 --> 1.155339).  Saving model ...
Validation loss decreased (1.155339 --> 1.153246).  Saving model ...
Validation loss decreased (1.153246 --> 1.151432).  Saving model ...
Validation loss decreased (1.151432 --> 1.147739).  Saving model ...
Validation loss decreased (1.147739 --> 1.143710).  Saving model ...
Validation loss decreased (1.143710 --> 1.140227).  Saving model ...
Validation loss decreased (1.140227 --> 1.138478).  Saving model ...
Validation loss decreased (1.138478 --> 1.133107).  Saving model ...
Validation loss decreased (1.133107 --> 1.131906).  Saving model ...
Validation loss decreased (1.131906 --> 1.131143).  Saving model ...
Validation loss decreased (1.131143 --> 1.128610).  Saving model ...
Validation loss decreased (1.128610 --> 1.127989).  Saving model ...
Validation loss decreased (1.127989 --> 1.126004).  Saving model ...
Validation loss decreased (1.126004 --> 1.121198).  Saving model ...
Validation loss decreased (1.121198 --> 1.120449).  Saving model ...
Validation loss decreased (1.120449 --> 1.115201).  Saving model ...
Validation loss decreased (1.115201 --> 1.112670).  Saving model ...
EarlyStopping counter: 1 out of 5.0
EarlyStopping counter: 2 out of 5.0
Validation loss decreased (1.112670 --> 1.112454).  Saving model ...
Validation loss decreased (1.112454 --> 1.111873).  Saving model ...
Validation loss decreased (1.111873 --> 1.106969).  Saving model ...
EarlyStopping counter: 1 out of 5.0
EarlyStopping counter: 2 out of 5.0
EarlyStopping counter: 3 out of 5.0
Validation loss decreased (1.106969 --> 1.103559).  Saving model ...
Validation loss decreased (1.103559 --> 1.099419).  Saving model ...
Validation loss decreased (1.099419 --> 1.099383).  Saving model ...
EarlyStopping counter: 1 out of 5.0
EarlyStopping counter: 2 out of 5.0
Validation loss decreased (1.099383 --> 1.097020).  Saving model ...
EarlyStopping counter: 1 out of 5.0
EarlyStopping counter: 2 out of 5.0
Validation loss decreased (1.097020 --> 1.094156).  Saving model ...
EarlyStopping counter: 1 out of 5.0
EarlyStopping counter: 2 out of 5.0
EarlyStopping counter: 3 out of 5.0
Validation loss decreased (1.094156 --> 1.094063).  Saving model ...
Validation loss decreased (1.094063 --> 1.090555).  Saving model ...
Validation loss decreased (1.090555 --> 1.087529).  Saving model ...
EarlyStopping counter: 1 out of 5.0
EarlyStopping counter: 2 out of 5.0
EarlyStopping counter: 3 out of 5.0
EarlyStopping counter: 4 out of 5.0
Validation loss decreased (1.087529 --> 1.084960).  Saving model ...
Validation loss decreased (1.084960 --> 1.083698).  Saving model ...
Validation loss decreased (1.083698 --> 1.082476).  Saving model ...
EarlyStopping counter: 1 out of 5.0
EarlyStopping counter: 2 out of 5.0
EarlyStopping counter: 3 out of 5.0
EarlyStopping counter: 4 out of 5.0
Validation loss decreased (1.082476 --> 1.079855).  Saving model ...
EarlyStopping counter: 1 out of 5.0
Validation loss decreased (1.079855 --> 1.079202).  Saving model ...
EarlyStopping counter: 1 out of 5.0
EarlyStopping counter: 2 out of 5.0
EarlyStopping counter: 3 out of 5.0
Validation loss decreased (1.079202 --> 1.076885).  Saving model ...
Validation loss decreased (1.076885 --> 1.076844).  Saving model ...
Validation loss decreased (1.076844 --> 1.075484).  Saving model ...
EarlyStopping counter: 1 out of 5.0
EarlyStopping counter: 2 out of 5.0
Validation loss decreased (1.075484 --> 1.073581).  Saving model ...
EarlyStopping counter: 1 out of 5.0
Validation loss decreased (1.073581 --> 1.073247).  Saving model ...
EarlyStopping counter: 1 out of 5.0
Validation loss decreased (1.073247 --> 1.071363).  Saving model ...
EarlyStopping counter: 1 out of 5.0
Validation loss decreased (1.071363 --> 1.070693).  Saving model ...
EarlyStopping counter: 1 out of 5.0
EarlyStopping counter: 2 out of 5.0
EarlyStopping counter: 3 out of 5.0
EarlyStopping counter: 4 out of 5.0
EarlyStopping counter: 5 out of 5.0
/localscratch/yinan.29161744.0/env/lib/python3.7/site-packages/torch/nn/functional.py:1794: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.
  warnings.warn("nn.functional.tanh is deprecated. Use torch.tanh instead.")
/localscratch/yinan.29161744.0/env/lib/python3.7/site-packages/transformers/optimization.py:155: UserWarning: This overload of add_ is deprecated:
	add_(Number alpha, Tensor other)
Consider using one of the following signatures instead:
	add_(Tensor other, *, Number alpha) (Triggered internally at  ../torch/csrc/utils/python_arg_parser.cpp:1025.)
  exp_avg.mul_(beta1).add_(1.0 - beta1, grad)
wandb: Waiting for W&B process to finish, PID 185984... (success).
wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: \ 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: | 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: / 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: \ 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: | 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: / 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: \ 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: | 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: / 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb:                                                                                
wandb: Run history:
wandb:     e_F1 ▁▂▄▄▅▅▆▅▅▆▆▆▆▆▇▇▇▇▇▇▇▇▇█▇███████████████
wandb:   e_loss █▇▇▆▆▆▅▅▅▅▄▄▄▄▃▃▃▃▃▂▂▂▂▂▂▂▂▁▂▁▁▁▁▁▁▁▁▁▁▁
wandb:     t_F1 ▁▂▃▄▄▄▄▅▅▅▅▆▅▆▆▆▆▆▇▆▇▇▇▇▇▇▇▇▇█▇█▇███████
wandb:   t_loss ██▇▇▇▇▆▆▆▆▅▅▅▅▄▄▄▄▄▄▃▃▃▃▃▃▂▂▂▂▂▂▂▂▂▁▂▁▁▁
wandb: 
wandb: Run summary:
wandb:     e_F1 54.96551
wandb:   e_loss 1.07511
wandb:     t_F1 68.8822
wandb:   t_loss 0.75191
wandb: 
wandb: Synced 4 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Synced giddy-dawn-1: https://wandb.ai/yinanazhou/xl_512_bs_8_lr_1e06_es_5_lc_False_nr_True_sr_True_stem_True_lemma_False_repeat_1_fold_1/runs/20526l20
wandb: Find logs at: ./wandb/run-20220317_212055-20526l20/logs/debug.log
wandb: 

wandb: wandb version 0.12.11 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
2022-03-17 22:46:22.844260: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1
wandb: Tracking run with wandb version 0.12.5
wandb: Syncing run ethereal-waterfall-1
wandb: ⭐️ View project at https://wandb.ai/yinanazhou/xl_512_bs_8_lr_1e06_es_5_lc_False_nr_True_sr_True_stem_True_lemma_False_repeat_1_fold_2
wandb: 🚀 View run at https://wandb.ai/yinanazhou/xl_512_bs_8_lr_1e06_es_5_lc_False_nr_True_sr_True_stem_True_lemma_False_repeat_1_fold_2/runs/2k8ukpnj
wandb: Run data is saved locally in /project/6002780/yinan/Thesis_MER_Lyrics/lyric-emotion/wandb/run-20220317_224620-2k8ukpnj
wandb: Run `wandb offline` to turn off syncing.

Validation loss decreased (inf --> 1.425217).  Saving model ...
Validation loss decreased (1.425217 --> 1.409655).  Saving model ...
Validation loss decreased (1.409655 --> 1.398317).  Saving model ...
Validation loss decreased (1.398317 --> 1.389867).  Saving model ...
Validation loss decreased (1.389867 --> 1.382719).  Saving model ...
Validation loss decreased (1.382719 --> 1.377094).  Saving model ...
Validation loss decreased (1.377094 --> 1.372022).  Saving model ...
Validation loss decreased (1.372022 --> 1.367849).  Saving model ...
Validation loss decreased (1.367849 --> 1.363201).  Saving model ...
Validation loss decreased (1.363201 --> 1.358778).  Saving model ...
Validation loss decreased (1.358778 --> 1.354936).  Saving model ...
Validation loss decreased (1.354936 --> 1.350697).  Saving model ...
Validation loss decreased (1.350697 --> 1.346474).  Saving model ...
Validation loss decreased (1.346474 --> 1.342086).  Saving model ...
Validation loss decreased (1.342086 --> 1.337530).  Saving model ...
Validation loss decreased (1.337530 --> 1.333016).  Saving model ...
Validation loss decreased (1.333016 --> 1.328325).  Saving model ...
Validation loss decreased (1.328325 --> 1.323206).  Saving model ...
Validation loss decreased (1.323206 --> 1.317813).  Saving model ...
Validation loss decreased (1.317813 --> 1.312142).  Saving model ...
Validation loss decreased (1.312142 --> 1.306434).  Saving model ...
Validation loss decreased (1.306434 --> 1.300940).  Saving model ...
Validation loss decreased (1.300940 --> 1.294500).  Saving model ...
Validation loss decreased (1.294500 --> 1.288321).  Saving model ...
Validation loss decreased (1.288321 --> 1.281966).  Saving model ...
Validation loss decreased (1.281966 --> 1.273640).  Saving model ...
Validation loss decreased (1.273640 --> 1.265195).  Saving model ...
Validation loss decreased (1.265195 --> 1.258076).  Saving model ...
Validation loss decreased (1.258076 --> 1.251686).  Saving model ...
Validation loss decreased (1.251686 --> 1.245451).  Saving model ...
Validation loss decreased (1.245451 --> 1.236384).  Saving model ...
Validation loss decreased (1.236384 --> 1.228668).  Saving model ...
Validation loss decreased (1.228668 --> 1.222371).  Saving model ...
Validation loss decreased (1.222371 --> 1.214920).  Saving model ...
Validation loss decreased (1.214920 --> 1.207769).  Saving model ...
Validation loss decreased (1.207769 --> 1.200939).  Saving model ...
Validation loss decreased (1.200939 --> 1.193169).  Saving model ...
Validation loss decreased (1.193169 --> 1.185505).  Saving model ...
Validation loss decreased (1.185505 --> 1.178344).  Saving model ...
Validation loss decreased (1.178344 --> 1.170860).  Saving model ...
Validation loss decreased (1.170860 --> 1.165378).  Saving model ...
Validation loss decreased (1.165378 --> 1.158162).  Saving model ...
Validation loss decreased (1.158162 --> 1.152682).  Saving model ...
Validation loss decreased (1.152682 --> 1.144563).  Saving model ...
Validation loss decreased (1.144563 --> 1.137760).  Saving model ...
Validation loss decreased (1.137760 --> 1.131614).  Saving model ...
Validation loss decreased (1.131614 --> 1.124289).  Saving model ...
Validation loss decreased (1.124289 --> 1.118323).  Saving model ...
Validation loss decreased (1.118323 --> 1.114033).  Saving model ...
Validation loss decreased (1.114033 --> 1.108639).  Saving model ...
Validation loss decreased (1.108639 --> 1.104769).  Saving model ...
Validation loss decreased (1.104769 --> 1.099966).  Saving model ...
Validation loss decreased (1.099966 --> 1.094548).  Saving model ...
Validation loss decreased (1.094548 --> 1.090623).  Saving model ...
Validation loss decreased (1.090623 --> 1.086356).  Saving model ...
Validation loss decreased (1.086356 --> 1.082981).  Saving model ...
Validation loss decreased (1.082981 --> 1.077095).  Saving model ...
Validation loss decreased (1.077095 --> 1.073216).  Saving model ...
Validation loss decreased (1.073216 --> 1.070021).  Saving model ...
Validation loss decreased (1.070021 --> 1.066468).  Saving model ...
Validation loss decreased (1.066468 --> 1.060043).  Saving model ...
Validation loss decreased (1.060043 --> 1.053543).  Saving model ...
Validation loss decreased (1.053543 --> 1.049468).  Saving model ...
Validation loss decreased (1.049468 --> 1.047221).  Saving model ...
Validation loss decreased (1.047221 --> 1.043565).  Saving model ...
Validation loss decreased (1.043565 --> 1.040466).  Saving model ...
Validation loss decreased (1.040466 --> 1.037205).  Saving model ...
Validation loss decreased (1.037205 --> 1.034063).  Saving model ...
Validation loss decreased (1.034063 --> 1.032340).  Saving model ...
Validation loss decreased (1.032340 --> 1.029633).  Saving model ...
Validation loss decreased (1.029633 --> 1.028384).  Saving model ...
Validation loss decreased (1.028384 --> 1.023896).  Saving model ...
Validation loss decreased (1.023896 --> 1.020746).  Saving model ...
Validation loss decreased (1.020746 --> 1.017751).  Saving model ...
Validation loss decreased (1.017751 --> 1.014984).  Saving model ...
Validation loss decreased (1.014984 --> 1.011075).  Saving model ...
Validation loss decreased (1.011075 --> 1.010566).  Saving model ...
Validation loss decreased (1.010566 --> 1.009525).  Saving model ...
Validation loss decreased (1.009525 --> 1.006442).  Saving model ...
Validation loss decreased (1.006442 --> 1.002813).  Saving model ...
Validation loss decreased (1.002813 --> 0.998623).  Saving model ...
Validation loss decreased (0.998623 --> 0.995399).  Saving model ...
Validation loss decreased (0.995399 --> 0.991136).  Saving model ...
Validation loss decreased (0.991136 --> 0.989794).  Saving model ...
Validation loss decreased (0.989794 --> 0.987385).  Saving model ...
Validation loss decreased (0.987385 --> 0.984280).  Saving model ...
Validation loss decreased (0.984280 --> 0.981368).  Saving model ...
Validation loss decreased (0.981368 --> 0.979160).  Saving model ...
Validation loss decreased (0.979160 --> 0.977814).  Saving model ...
Validation loss decreased (0.977814 --> 0.975707).  Saving model ...
Validation loss decreased (0.975707 --> 0.974574).  Saving model ...
Validation loss decreased (0.974574 --> 0.972255).  Saving model ...
Validation loss decreased (0.972255 --> 0.969814).  Saving model ...
Validation loss decreased (0.969814 --> 0.968748).  Saving model ...
Validation loss decreased (0.968748 --> 0.966855).  Saving model ...
Validation loss decreased (0.966855 --> 0.964631).  Saving model ...
EarlyStopping counter: 1 out of 5.0
Validation loss decreased (0.964631 --> 0.963903).  Saving model ...
EarlyStopping counter: 1 out of 5.0
Validation loss decreased (0.963903 --> 0.963350).  Saving model ...
Validation loss decreased (0.963350 --> 0.960880).  Saving model ...
Validation loss decreased (0.960880 --> 0.959803).  Saving model ...
Validation loss decreased (0.959803 --> 0.959275).  Saving model ...
Validation loss decreased (0.959275 --> 0.957176).  Saving model ...
Validation loss decreased (0.957176 --> 0.956780).  Saving model ...
Validation loss decreased (0.956780 --> 0.956347).  Saving model ...
Validation loss decreased (0.956347 --> 0.953481).  Saving model ...
EarlyStopping counter: 1 out of 5.0
EarlyStopping counter: 2 out of 5.0
EarlyStopping counter: 3 out of 5.0
Validation loss decreased (0.953481 --> 0.951889).  Saving model ...
Validation loss decreased (0.951889 --> 0.951780).  Saving model ...
Validation loss decreased (0.951780 --> 0.951307).  Saving model ...
Validation loss decreased (0.951307 --> 0.951031).  Saving model ...
Validation loss decreased (0.951031 --> 0.949004).  Saving model ...
EarlyStopping counter: 1 out of 5.0
EarlyStopping counter: 2 out of 5.0
Validation loss decreased (0.949004 --> 0.948841).  Saving model ...
Validation loss decreased (0.948841 --> 0.948134).  Saving model ...
Validation loss decreased (0.948134 --> 0.946362).  Saving model ...
Validation loss decreased (0.946362 --> 0.944125).  Saving model ...
Validation loss decreased (0.944125 --> 0.943508).  Saving model ...
EarlyStopping counter: 1 out of 5.0
Validation loss decreased (0.943508 --> 0.942902).  Saving model ...
Validation loss decreased (0.942902 --> 0.942318).  Saving model ...
EarlyStopping counter: 1 out of 5.0
EarlyStopping counter: 2 out of 5.0
Validation loss decreased (0.942318 --> 0.942131).  Saving model ...
EarlyStopping counter: 1 out of 5.0
Validation loss decreased (0.942131 --> 0.941972).  Saving model ...
Validation loss decreased (0.941972 --> 0.941745).  Saving model ...
EarlyStopping counter: 1 out of 5.0
Validation loss decreased (0.941745 --> 0.941455).  Saving model ...
EarlyStopping counter: 1 out of 5.0
EarlyStopping counter: 2 out of 5.0
EarlyStopping counter: 3 out of 5.0
EarlyStopping counter: 4 out of 5.0
EarlyStopping counter: 5 out of 5.0
/localscratch/yinan.29161744.0/env/lib/python3.7/site-packages/torch/nn/functional.py:1794: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.
  warnings.warn("nn.functional.tanh is deprecated. Use torch.tanh instead.")
wandb: Waiting for W&B process to finish, PID 190556... (success).
wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: \ 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: | 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: / 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: \ 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: | 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: / 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: \ 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: | 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: / 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb:                                                                                
wandb: Run history:
wandb:     e_F1 ▁▁▂▄▄▅▅▆▆▆▇▇▇▇██▇▇██████████████████████
wandb:   e_loss ██▇▇▇▇▆▆▆▅▅▄▄▄▃▃▃▃▃▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:     t_F1 ▁▁▂▃▃▃▃▄▃▄▅▅▅▅▆▅▆▆▆▆▆▆▆▆▆▆▆▇▇▇▇▇▇▇▇█▇▇██
wandb:   t_loss ██▇▇▇▇▇▇▇▆▆▆▅▅▅▅▅▄▅▄▄▄▃▃▃▃▃▃▃▂▂▂▂▂▂▁▂▂▁▁
wandb: 
wandb: Run summary:
wandb:     e_F1 57.57332
wandb:   e_loss 0.94157
wandb:     t_F1 72.91109
wandb:   t_loss 0.76987
wandb: 
wandb: Synced 4 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Synced ethereal-waterfall-1: https://wandb.ai/yinanazhou/xl_512_bs_8_lr_1e06_es_5_lc_False_nr_True_sr_True_stem_True_lemma_False_repeat_1_fold_2/runs/2k8ukpnj
wandb: Find logs at: ./wandb/run-20220317_224620-2k8ukpnj/logs/debug.log
wandb: 

wandb: wandb version 0.12.11 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
2022-03-18 00:18:03.318720: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1
wandb: Tracking run with wandb version 0.12.5
wandb: Syncing run hardy-music-1
wandb: ⭐️ View project at https://wandb.ai/yinanazhou/xl_512_bs_8_lr_1e06_es_5_lc_False_nr_True_sr_True_stem_True_lemma_False_repeat_2_fold_1
wandb: 🚀 View run at https://wandb.ai/yinanazhou/xl_512_bs_8_lr_1e06_es_5_lc_False_nr_True_sr_True_stem_True_lemma_False_repeat_2_fold_1/runs/29q206nc
wandb: Run data is saved locally in /project/6002780/yinan/Thesis_MER_Lyrics/lyric-emotion/wandb/run-20220318_001801-29q206nc
wandb: Run `wandb offline` to turn off syncing.

Validation loss decreased (inf --> 1.396159).  Saving model ...
Validation loss decreased (1.396159 --> 1.386523).  Saving model ...
Validation loss decreased (1.386523 --> 1.378599).  Saving model ...
Validation loss decreased (1.378599 --> 1.372183).  Saving model ...
Validation loss decreased (1.372183 --> 1.367247).  Saving model ...
Validation loss decreased (1.367247 --> 1.362778).  Saving model ...
Validation loss decreased (1.362778 --> 1.358399).  Saving model ...
Validation loss decreased (1.358399 --> 1.354313).  Saving model ...
Validation loss decreased (1.354313 --> 1.350383).  Saving model ...
Validation loss decreased (1.350383 --> 1.346593).  Saving model ...
Validation loss decreased (1.346593 --> 1.342965).  Saving model ...
Validation loss decreased (1.342965 --> 1.338974).  Saving model ...
Validation loss decreased (1.338974 --> 1.335041).  Saving model ...
Validation loss decreased (1.335041 --> 1.330975).  Saving model ...
Validation loss decreased (1.330975 --> 1.327347).  Saving model ...
Validation loss decreased (1.327347 --> 1.323300).  Saving model ...
Validation loss decreased (1.323300 --> 1.319164).  Saving model ...
Validation loss decreased (1.319164 --> 1.314621).  Saving model ...
Validation loss decreased (1.314621 --> 1.310135).  Saving model ...
Validation loss decreased (1.310135 --> 1.305172).  Saving model ...
Validation loss decreased (1.305172 --> 1.300688).  Saving model ...
Validation loss decreased (1.300688 --> 1.296057).  Saving model ...
Validation loss decreased (1.296057 --> 1.290851).  Saving model ...
Validation loss decreased (1.290851 --> 1.285861).  Saving model ...
Validation loss decreased (1.285861 --> 1.280869).  Saving model ...
Validation loss decreased (1.280869 --> 1.275750).  Saving model ...
Validation loss decreased (1.275750 --> 1.270844).  Saving model ...
Validation loss decreased (1.270844 --> 1.265043).  Saving model ...
Validation loss decreased (1.265043 --> 1.259116).  Saving model ...
Validation loss decreased (1.259116 --> 1.253730).  Saving model ...
Validation loss decreased (1.253730 --> 1.247683).  Saving model ...
Validation loss decreased (1.247683 --> 1.241705).  Saving model ...
Validation loss decreased (1.241705 --> 1.235443).  Saving model ...
Validation loss decreased (1.235443 --> 1.229614).  Saving model ...
Validation loss decreased (1.229614 --> 1.224099).  Saving model ...
Validation loss decreased (1.224099 --> 1.217866).  Saving model ...
Validation loss decreased (1.217866 --> 1.210842).  Saving model ...
Validation loss decreased (1.210842 --> 1.204567).  Saving model ...
Validation loss decreased (1.204567 --> 1.197956).  Saving model ...
Validation loss decreased (1.197956 --> 1.190936).  Saving model ...
Validation loss decreased (1.190936 --> 1.184927).  Saving model ...
Validation loss decreased (1.184927 --> 1.179058).  Saving model ...
Validation loss decreased (1.179058 --> 1.173550).  Saving model ...
Validation loss decreased (1.173550 --> 1.167626).  Saving model ...
Validation loss decreased (1.167626 --> 1.161240).  Saving model ...
Validation loss decreased (1.161240 --> 1.156199).  Saving model ...
Validation loss decreased (1.156199 --> 1.151840).  Saving model ...
Validation loss decreased (1.151840 --> 1.145821).  Saving model ...
Validation loss decreased (1.145821 --> 1.140034).  Saving model ...
Validation loss decreased (1.140034 --> 1.133870).  Saving model ...
Validation loss decreased (1.133870 --> 1.126795).  Saving model ...
Validation loss decreased (1.126795 --> 1.122109).  Saving model ...
Validation loss decreased (1.122109 --> 1.117250).  Saving model ...
Validation loss decreased (1.117250 --> 1.114396).  Saving model ...
Validation loss decreased (1.114396 --> 1.108611).  Saving model ...
Validation loss decreased (1.108611 --> 1.106133).  Saving model ...
Validation loss decreased (1.106133 --> 1.101356).  Saving model ...
Validation loss decreased (1.101356 --> 1.097991).  Saving model ...
Validation loss decreased (1.097991 --> 1.096103).  Saving model ...
Validation loss decreased (1.096103 --> 1.092740).  Saving model ...
Validation loss decreased (1.092740 --> 1.087915).  Saving model ...
Validation loss decreased (1.087915 --> 1.084122).  Saving model ...
Validation loss decreased (1.084122 --> 1.081073).  Saving model ...
Validation loss decreased (1.081073 --> 1.078445).  Saving model ...
Validation loss decreased (1.078445 --> 1.074801).  Saving model ...
Validation loss decreased (1.074801 --> 1.071027).  Saving model ...
Validation loss decreased (1.071027 --> 1.068699).  Saving model ...
Validation loss decreased (1.068699 --> 1.066441).  Saving model ...
Validation loss decreased (1.066441 --> 1.064094).  Saving model ...
Validation loss decreased (1.064094 --> 1.061040).  Saving model ...
Validation loss decreased (1.061040 --> 1.059418).  Saving model ...
Validation loss decreased (1.059418 --> 1.057218).  Saving model ...
Validation loss decreased (1.057218 --> 1.056233).  Saving model ...
Validation loss decreased (1.056233 --> 1.054895).  Saving model ...
Validation loss decreased (1.054895 --> 1.052183).  Saving model ...
Validation loss decreased (1.052183 --> 1.049033).  Saving model ...
Validation loss decreased (1.049033 --> 1.046138).  Saving model ...
Validation loss decreased (1.046138 --> 1.043658).  Saving model ...
Validation loss decreased (1.043658 --> 1.043580).  Saving model ...
Validation loss decreased (1.043580 --> 1.042706).  Saving model ...
Validation loss decreased (1.042706 --> 1.039200).  Saving model ...
Validation loss decreased (1.039200 --> 1.036521).  Saving model ...
Validation loss decreased (1.036521 --> 1.034865).  Saving model ...
Validation loss decreased (1.034865 --> 1.032355).  Saving model ...
Validation loss decreased (1.032355 --> 1.030241).  Saving model ...
Validation loss decreased (1.030241 --> 1.029631).  Saving model ...
Validation loss decreased (1.029631 --> 1.027841).  Saving model ...
Validation loss decreased (1.027841 --> 1.027646).  Saving model ...
Validation loss decreased (1.027646 --> 1.026739).  Saving model ...
Validation loss decreased (1.026739 --> 1.025556).  Saving model ...
EarlyStopping counter: 1 out of 5.0
Validation loss decreased (1.025556 --> 1.025090).  Saving model ...
Validation loss decreased (1.025090 --> 1.023281).  Saving model ...
Validation loss decreased (1.023281 --> 1.023164).  Saving model ...
Validation loss decreased (1.023164 --> 1.020850).  Saving model ...
Validation loss decreased (1.020850 --> 1.020017).  Saving model ...
EarlyStopping counter: 1 out of 5.0
Validation loss decreased (1.020017 --> 1.019793).  Saving model ...
EarlyStopping counter: 1 out of 5.0
Validation loss decreased (1.019793 --> 1.015556).  Saving model ...
EarlyStopping counter: 1 out of 5.0
EarlyStopping counter: 2 out of 5.0
Validation loss decreased (1.015556 --> 1.015426).  Saving model ...
Validation loss decreased (1.015426 --> 1.014857).  Saving model ...
Validation loss decreased (1.014857 --> 1.013974).  Saving model ...
Validation loss decreased (1.013974 --> 1.013450).  Saving model ...
Validation loss decreased (1.013450 --> 1.011982).  Saving model ...
EarlyStopping counter: 1 out of 5.0
Validation loss decreased (1.011982 --> 1.011127).  Saving model ...
EarlyStopping counter: 1 out of 5.0
EarlyStopping counter: 2 out of 5.0
Validation loss decreased (1.011127 --> 1.010422).  Saving model ...
EarlyStopping counter: 1 out of 5.0
EarlyStopping counter: 2 out of 5.0
Validation loss decreased (1.010422 --> 1.009741).  Saving model ...
Validation loss decreased (1.009741 --> 1.008712).  Saving model ...
EarlyStopping counter: 1 out of 5.0
EarlyStopping counter: 2 out of 5.0
EarlyStopping counter: 3 out of 5.0
EarlyStopping counter: 4 out of 5.0
EarlyStopping counter: 5 out of 5.0
/localscratch/yinan.29161744.0/env/lib/python3.7/site-packages/torch/nn/functional.py:1794: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.
  warnings.warn("nn.functional.tanh is deprecated. Use torch.tanh instead.")
wandb: Waiting for W&B process to finish, PID 195537... (success).
wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: \ 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: | 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: / 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: \ 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: | 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: / 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: \ 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: | 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: / 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: \ 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb:                                                                                
wandb: Run history:
wandb:     e_F1 ▁▂▃▄▄▅▅▅▅▅▆▆▇▇▇▇▇██▇████████████████████
wandb:   e_loss ██▇▇▇▇▆▆▆▆▅▅▅▄▄▄▃▃▃▃▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:     t_F1 ▁▂▃▃▃▃▄▄▄▄▅▄▅▅▆▆▆▆▆▆▆▇▇▇▇▇▇▇▇▇▇▇▇█▇▇████
wandb:   t_loss ██▇▇▇▇▇▇▇▆▆▆▆▅▅▅▅▄▄▄▄▃▃▃▃▃▃▂▂▂▂▂▂▁▂▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:     e_F1 54.33266
wandb:   e_loss 1.01027
wandb:     t_F1 69.40158
wandb:   t_loss 0.81967
wandb: 
wandb: Synced 4 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Synced hardy-music-1: https://wandb.ai/yinanazhou/xl_512_bs_8_lr_1e06_es_5_lc_False_nr_True_sr_True_stem_True_lemma_False_repeat_2_fold_1/runs/29q206nc
wandb: Find logs at: ./wandb/run-20220318_001801-29q206nc/logs/debug.log
wandb: 

wandb: wandb version 0.12.11 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
2022-03-18 01:38:28.115078: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1
wandb: Tracking run with wandb version 0.12.5
wandb: Syncing run different-morning-1
wandb: ⭐️ View project at https://wandb.ai/yinanazhou/xl_512_bs_8_lr_1e06_es_5_lc_False_nr_True_sr_True_stem_True_lemma_False_repeat_2_fold_2
wandb: 🚀 View run at https://wandb.ai/yinanazhou/xl_512_bs_8_lr_1e06_es_5_lc_False_nr_True_sr_True_stem_True_lemma_False_repeat_2_fold_2/runs/o3mopgbq
wandb: Run data is saved locally in /project/6002780/yinan/Thesis_MER_Lyrics/lyric-emotion/wandb/run-20220318_013825-o3mopgbq
wandb: Run `wandb offline` to turn off syncing.

Validation loss decreased (inf --> 1.394469).  Saving model ...
Validation loss decreased (1.394469 --> 1.382274).  Saving model ...
Validation loss decreased (1.382274 --> 1.373776).  Saving model ...
Validation loss decreased (1.373776 --> 1.367109).  Saving model ...
Validation loss decreased (1.367109 --> 1.361777).  Saving model ...
Validation loss decreased (1.361777 --> 1.356789).  Saving model ...
Validation loss decreased (1.356789 --> 1.352542).  Saving model ...
Validation loss decreased (1.352542 --> 1.348402).  Saving model ...
Validation loss decreased (1.348402 --> 1.343704).  Saving model ...
Validation loss decreased (1.343704 --> 1.338999).  Saving model ...
Validation loss decreased (1.338999 --> 1.334005).  Saving model ...
Validation loss decreased (1.334005 --> 1.329248).  Saving model ...
Validation loss decreased (1.329248 --> 1.324467).  Saving model ...
Validation loss decreased (1.324467 --> 1.319199).  Saving model ...
Validation loss decreased (1.319199 --> 1.314451).  Saving model ...
Validation loss decreased (1.314451 --> 1.309141).  Saving model ...
Validation loss decreased (1.309141 --> 1.303606).  Saving model ...
Validation loss decreased (1.303606 --> 1.297801).  Saving model ...
Validation loss decreased (1.297801 --> 1.292419).  Saving model ...
Validation loss decreased (1.292419 --> 1.286284).  Saving model ...
Validation loss decreased (1.286284 --> 1.280501).  Saving model ...
Validation loss decreased (1.280501 --> 1.273784).  Saving model ...
Validation loss decreased (1.273784 --> 1.268511).  Saving model ...
Validation loss decreased (1.268511 --> 1.262421).  Saving model ...
Validation loss decreased (1.262421 --> 1.256812).  Saving model ...
Validation loss decreased (1.256812 --> 1.251325).  Saving model ...
Validation loss decreased (1.251325 --> 1.246771).  Saving model ...
Validation loss decreased (1.246771 --> 1.241291).  Saving model ...
Validation loss decreased (1.241291 --> 1.236113).  Saving model ...
Validation loss decreased (1.236113 --> 1.230417).  Saving model ...
Validation loss decreased (1.230417 --> 1.225471).  Saving model ...
Validation loss decreased (1.225471 --> 1.220139).  Saving model ...
Validation loss decreased (1.220139 --> 1.215380).  Saving model ...
Validation loss decreased (1.215380 --> 1.209598).  Saving model ...
Validation loss decreased (1.209598 --> 1.205426).  Saving model ...
Validation loss decreased (1.205426 --> 1.201086).  Saving model ...
Validation loss decreased (1.201086 --> 1.195246).  Saving model ...
Validation loss decreased (1.195246 --> 1.190246).  Saving model ...
Validation loss decreased (1.190246 --> 1.186226).  Saving model ...
Validation loss decreased (1.186226 --> 1.180910).  Saving model ...
Validation loss decreased (1.180910 --> 1.176717).  Saving model ...
Validation loss decreased (1.176717 --> 1.173169).  Saving model ...
Validation loss decreased (1.173169 --> 1.169198).  Saving model ...
Validation loss decreased (1.169198 --> 1.165001).  Saving model ...
Validation loss decreased (1.165001 --> 1.160335).  Saving model ...
Validation loss decreased (1.160335 --> 1.154140).  Saving model ...
Validation loss decreased (1.154140 --> 1.148980).  Saving model ...
Validation loss decreased (1.148980 --> 1.145666).  Saving model ...
Validation loss decreased (1.145666 --> 1.142240).  Saving model ...
Validation loss decreased (1.142240 --> 1.137167).  Saving model ...
Validation loss decreased (1.137167 --> 1.135191).  Saving model ...
Validation loss decreased (1.135191 --> 1.132296).  Saving model ...
Validation loss decreased (1.132296 --> 1.128600).  Saving model ...
Validation loss decreased (1.128600 --> 1.125314).  Saving model ...
Validation loss decreased (1.125314 --> 1.119997).  Saving model ...
Validation loss decreased (1.119997 --> 1.116395).  Saving model ...
Validation loss decreased (1.116395 --> 1.112700).  Saving model ...
Validation loss decreased (1.112700 --> 1.108796).  Saving model ...
Validation loss decreased (1.108796 --> 1.105575).  Saving model ...
Validation loss decreased (1.105575 --> 1.100969).  Saving model ...
Validation loss decreased (1.100969 --> 1.096931).  Saving model ...
Validation loss decreased (1.096931 --> 1.091915).  Saving model ...
Validation loss decreased (1.091915 --> 1.089516).  Saving model ...
Validation loss decreased (1.089516 --> 1.085536).  Saving model ...
Validation loss decreased (1.085536 --> 1.081097).  Saving model ...
Validation loss decreased (1.081097 --> 1.077972).  Saving model ...
Validation loss decreased (1.077972 --> 1.075410).  Saving model ...
Validation loss decreased (1.075410 --> 1.073119).  Saving model ...
Validation loss decreased (1.073119 --> 1.069422).  Saving model ...
Validation loss decreased (1.069422 --> 1.067454).  Saving model ...
Validation loss decreased (1.067454 --> 1.065657).  Saving model ...
Validation loss decreased (1.065657 --> 1.062878).  Saving model ...
Validation loss decreased (1.062878 --> 1.059371).  Saving model ...
Validation loss decreased (1.059371 --> 1.056485).  Saving model ...
EarlyStopping counter: 1 out of 5.0
Validation loss decreased (1.056485 --> 1.052083).  Saving model ...
Validation loss decreased (1.052083 --> 1.048684).  Saving model ...
Validation loss decreased (1.048684 --> 1.046284).  Saving model ...
Validation loss decreased (1.046284 --> 1.041271).  Saving model ...
Validation loss decreased (1.041271 --> 1.038646).  Saving model ...
Validation loss decreased (1.038646 --> 1.037430).  Saving model ...
Validation loss decreased (1.037430 --> 1.035695).  Saving model ...
Validation loss decreased (1.035695 --> 1.035468).  Saving model ...
Validation loss decreased (1.035468 --> 1.033254).  Saving model ...
Validation loss decreased (1.033254 --> 1.030272).  Saving model ...
Validation loss decreased (1.030272 --> 1.029559).  Saving model ...
Validation loss decreased (1.029559 --> 1.026207).  Saving model ...
Validation loss decreased (1.026207 --> 1.025280).  Saving model ...
Validation loss decreased (1.025280 --> 1.024968).  Saving model ...
Validation loss decreased (1.024968 --> 1.023419).  Saving model ...
Validation loss decreased (1.023419 --> 1.020915).  Saving model ...
Validation loss decreased (1.020915 --> 1.018260).  Saving model ...
Validation loss decreased (1.018260 --> 1.017922).  Saving model ...
Validation loss decreased (1.017922 --> 1.015976).  Saving model ...
Validation loss decreased (1.015976 --> 1.014599).  Saving model ...
Validation loss decreased (1.014599 --> 1.010777).  Saving model ...
Validation loss decreased (1.010777 --> 1.009594).  Saving model ...
Validation loss decreased (1.009594 --> 1.007603).  Saving model ...
Validation loss decreased (1.007603 --> 1.005402).  Saving model ...
Validation loss decreased (1.005402 --> 1.005134).  Saving model ...
Validation loss decreased (1.005134 --> 1.003601).  Saving model ...
Validation loss decreased (1.003601 --> 1.000949).  Saving model ...
Validation loss decreased (1.000949 --> 0.999331).  Saving model ...
Validation loss decreased (0.999331 --> 0.997337).  Saving model ...
Validation loss decreased (0.997337 --> 0.996441).  Saving model ...
EarlyStopping counter: 1 out of 5.0
Validation loss decreased (0.996441 --> 0.996318).  Saving model ...
Validation loss decreased (0.996318 --> 0.995522).  Saving model ...
Validation loss decreased (0.995522 --> 0.992972).  Saving model ...
Validation loss decreased (0.992972 --> 0.991650).  Saving model ...
Validation loss decreased (0.991650 --> 0.989939).  Saving model ...
EarlyStopping counter: 1 out of 5.0
EarlyStopping counter: 2 out of 5.0
EarlyStopping counter: 3 out of 5.0
EarlyStopping counter: 4 out of 5.0
Validation loss decreased (0.989939 --> 0.988585).  Saving model ...
Validation loss decreased (0.988585 --> 0.988271).  Saving model ...
EarlyStopping counter: 1 out of 5.0
Validation loss decreased (0.988271 --> 0.987435).  Saving model ...
Validation loss decreased (0.987435 --> 0.985882).  Saving model ...
Validation loss decreased (0.985882 --> 0.984988).  Saving model ...
Validation loss decreased (0.984988 --> 0.983754).  Saving model ...
EarlyStopping counter: 1 out of 5.0
EarlyStopping counter: 2 out of 5.0
EarlyStopping counter: 3 out of 5.0
EarlyStopping counter: 4 out of 5.0
EarlyStopping counter: 5 out of 5.0
/localscratch/yinan.29161744.0/env/lib/python3.7/site-packages/torch/nn/functional.py:1794: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.
  warnings.warn("nn.functional.tanh is deprecated. Use torch.tanh instead.")
wandb: Waiting for W&B process to finish, PID 199860... (success).
wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: \ 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: | 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: / 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: \ 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: | 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: / 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: \ 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: | 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: / 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb:                                                                                
wandb: Run history:
wandb:     e_F1 ▁▄▄▄▅▅▅▆▆▆▆▆▆▆▇▇▇▇▇▇▇▇▇▇▇▇▇█████████████
wandb:   e_loss ██▇▇▇▆▆▆▆▅▅▅▄▄▄▄▄▃▃▃▃▃▂▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁
wandb:     t_F1 ▁▂▃▃▃▃▄▄▄▅▅▅▅▆▆▆▆▆▇▆▆▇▇▆▇▇▇▇▇▇▇▇▇█▇▇▇█▇█
wandb:   t_loss ██▇▇▇▇▇▇▆▆▆▆▅▅▅▅▅▅▄▄▄▄▃▃▃▃▃▃▃▃▂▂▂▂▂▂▂▁▂▁
wandb: 
wandb: Run summary:
wandb:     e_F1 57.68861
wandb:   e_loss 0.9853
wandb:     t_F1 70.25321
wandb:   t_loss 0.78193
wandb: 
wandb: Synced 4 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Synced different-morning-1: https://wandb.ai/yinanazhou/xl_512_bs_8_lr_1e06_es_5_lc_False_nr_True_sr_True_stem_True_lemma_False_repeat_2_fold_2/runs/o3mopgbq
wandb: Find logs at: ./wandb/run-20220318_013825-o3mopgbq/logs/debug.log
wandb: 

wandb: wandb version 0.12.11 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
2022-03-18 02:58:27.832644: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1
wandb: Tracking run with wandb version 0.12.5
wandb: Syncing run zesty-hill-1
wandb: ⭐️ View project at https://wandb.ai/yinanazhou/xl_512_bs_8_lr_1e06_es_5_lc_False_nr_True_sr_True_stem_True_lemma_False_repeat_3_fold_1
wandb: 🚀 View run at https://wandb.ai/yinanazhou/xl_512_bs_8_lr_1e06_es_5_lc_False_nr_True_sr_True_stem_True_lemma_False_repeat_3_fold_1/runs/9taf61v1
wandb: Run data is saved locally in /project/6002780/yinan/Thesis_MER_Lyrics/lyric-emotion/wandb/run-20220318_025825-9taf61v1
wandb: Run `wandb offline` to turn off syncing.

Validation loss decreased (inf --> 1.416950).  Saving model ...
Validation loss decreased (1.416950 --> 1.402842).  Saving model ...
Validation loss decreased (1.402842 --> 1.392334).  Saving model ...
Validation loss decreased (1.392334 --> 1.384060).  Saving model ...
Validation loss decreased (1.384060 --> 1.377720).  Saving model ...
Validation loss decreased (1.377720 --> 1.372645).  Saving model ...
Validation loss decreased (1.372645 --> 1.367951).  Saving model ...
Validation loss decreased (1.367951 --> 1.363756).  Saving model ...
Validation loss decreased (1.363756 --> 1.359258).  Saving model ...
Validation loss decreased (1.359258 --> 1.355206).  Saving model ...
Validation loss decreased (1.355206 --> 1.351467).  Saving model ...
Validation loss decreased (1.351467 --> 1.347614).  Saving model ...
Validation loss decreased (1.347614 --> 1.343822).  Saving model ...
Validation loss decreased (1.343822 --> 1.339622).  Saving model ...
Validation loss decreased (1.339622 --> 1.335551).  Saving model ...
Validation loss decreased (1.335551 --> 1.331590).  Saving model ...
Validation loss decreased (1.331590 --> 1.327610).  Saving model ...
Validation loss decreased (1.327610 --> 1.323612).  Saving model ...
Validation loss decreased (1.323612 --> 1.319626).  Saving model ...
Validation loss decreased (1.319626 --> 1.314734).  Saving model ...
Validation loss decreased (1.314734 --> 1.310371).  Saving model ...
Validation loss decreased (1.310371 --> 1.305562).  Saving model ...
Validation loss decreased (1.305562 --> 1.300496).  Saving model ...
Validation loss decreased (1.300496 --> 1.295653).  Saving model ...
Validation loss decreased (1.295653 --> 1.291234).  Saving model ...
Validation loss decreased (1.291234 --> 1.285290).  Saving model ...
Validation loss decreased (1.285290 --> 1.279782).  Saving model ...
Validation loss decreased (1.279782 --> 1.275295).  Saving model ...
Validation loss decreased (1.275295 --> 1.270178).  Saving model ...
Validation loss decreased (1.270178 --> 1.264435).  Saving model ...
Validation loss decreased (1.264435 --> 1.259231).  Saving model ...
Validation loss decreased (1.259231 --> 1.253644).  Saving model ...
Validation loss decreased (1.253644 --> 1.247371).  Saving model ...
Validation loss decreased (1.247371 --> 1.242653).  Saving model ...
Validation loss decreased (1.242653 --> 1.238491).  Saving model ...
Validation loss decreased (1.238491 --> 1.233543).  Saving model ...
Validation loss decreased (1.233543 --> 1.226500).  Saving model ...
Validation loss decreased (1.226500 --> 1.221230).  Saving model ...
Validation loss decreased (1.221230 --> 1.214673).  Saving model ...
Validation loss decreased (1.214673 --> 1.210650).  Saving model ...
Validation loss decreased (1.210650 --> 1.206280).  Saving model ...
Validation loss decreased (1.206280 --> 1.200642).  Saving model ...
Validation loss decreased (1.200642 --> 1.196982).  Saving model ...
Validation loss decreased (1.196982 --> 1.192327).  Saving model ...
Validation loss decreased (1.192327 --> 1.187820).  Saving model ...
Validation loss decreased (1.187820 --> 1.182710).  Saving model ...
Validation loss decreased (1.182710 --> 1.177761).  Saving model ...
Validation loss decreased (1.177761 --> 1.173593).  Saving model ...
Validation loss decreased (1.173593 --> 1.168677).  Saving model ...
Validation loss decreased (1.168677 --> 1.163677).  Saving model ...
Validation loss decreased (1.163677 --> 1.161317).  Saving model ...
Validation loss decreased (1.161317 --> 1.154871).  Saving model ...
Validation loss decreased (1.154871 --> 1.152331).  Saving model ...
Validation loss decreased (1.152331 --> 1.148463).  Saving model ...
Validation loss decreased (1.148463 --> 1.144162).  Saving model ...
Validation loss decreased (1.144162 --> 1.139849).  Saving model ...
Validation loss decreased (1.139849 --> 1.139054).  Saving model ...
Validation loss decreased (1.139054 --> 1.133404).  Saving model ...
Validation loss decreased (1.133404 --> 1.130846).  Saving model ...
Validation loss decreased (1.130846 --> 1.126213).  Saving model ...
Validation loss decreased (1.126213 --> 1.121540).  Saving model ...
Validation loss decreased (1.121540 --> 1.116565).  Saving model ...
Validation loss decreased (1.116565 --> 1.113374).  Saving model ...
Validation loss decreased (1.113374 --> 1.108962).  Saving model ...
Validation loss decreased (1.108962 --> 1.106166).  Saving model ...
Validation loss decreased (1.106166 --> 1.101915).  Saving model ...
Validation loss decreased (1.101915 --> 1.099856).  Saving model ...
Validation loss decreased (1.099856 --> 1.099200).  Saving model ...
Validation loss decreased (1.099200 --> 1.094862).  Saving model ...
Validation loss decreased (1.094862 --> 1.091707).  Saving model ...
Validation loss decreased (1.091707 --> 1.086533).  Saving model ...
Validation loss decreased (1.086533 --> 1.086042).  Saving model ...
Validation loss decreased (1.086042 --> 1.084908).  Saving model ...
Validation loss decreased (1.084908 --> 1.081474).  Saving model ...
Validation loss decreased (1.081474 --> 1.077093).  Saving model ...
Validation loss decreased (1.077093 --> 1.073850).  Saving model ...
Validation loss decreased (1.073850 --> 1.071478).  Saving model ...
Validation loss decreased (1.071478 --> 1.068742).  Saving model ...
Validation loss decreased (1.068742 --> 1.068600).  Saving model ...
EarlyStopping counter: 1 out of 5.0
Validation loss decreased (1.068600 --> 1.066287).  Saving model ...
Validation loss decreased (1.066287 --> 1.065215).  Saving model ...
Validation loss decreased (1.065215 --> 1.060612).  Saving model ...
Validation loss decreased (1.060612 --> 1.059677).  Saving model ...
EarlyStopping counter: 1 out of 5.0
Validation loss decreased (1.059677 --> 1.057980).  Saving model ...
Validation loss decreased (1.057980 --> 1.055367).  Saving model ...
Validation loss decreased (1.055367 --> 1.052324).  Saving model ...
Validation loss decreased (1.052324 --> 1.050028).  Saving model ...
Validation loss decreased (1.050028 --> 1.048164).  Saving model ...
EarlyStopping counter: 1 out of 5.0
EarlyStopping counter: 2 out of 5.0
EarlyStopping counter: 3 out of 5.0
EarlyStopping counter: 4 out of 5.0
Validation loss decreased (1.048164 --> 1.044170).  Saving model ...
Validation loss decreased (1.044170 --> 1.040666).  Saving model ...
Validation loss decreased (1.040666 --> 1.040041).  Saving model ...
Validation loss decreased (1.040041 --> 1.038757).  Saving model ...
Validation loss decreased (1.038757 --> 1.036818).  Saving model ...
Validation loss decreased (1.036818 --> 1.036554).  Saving model ...
Validation loss decreased (1.036554 --> 1.034099).  Saving model ...
EarlyStopping counter: 1 out of 5.0
Validation loss decreased (1.034099 --> 1.031543).  Saving model ...
EarlyStopping counter: 1 out of 5.0
Validation loss decreased (1.031543 --> 1.029442).  Saving model ...
EarlyStopping counter: 1 out of 5.0
EarlyStopping counter: 2 out of 5.0
EarlyStopping counter: 3 out of 5.0
Validation loss decreased (1.029442 --> 1.028560).  Saving model ...
Validation loss decreased (1.028560 --> 1.024490).  Saving model ...
Validation loss decreased (1.024490 --> 1.023035).  Saving model ...
EarlyStopping counter: 1 out of 5.0
EarlyStopping counter: 2 out of 5.0
EarlyStopping counter: 3 out of 5.0
EarlyStopping counter: 4 out of 5.0
EarlyStopping counter: 5 out of 5.0
/localscratch/yinan.29161744.0/env/lib/python3.7/site-packages/torch/nn/functional.py:1794: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.
  warnings.warn("nn.functional.tanh is deprecated. Use torch.tanh instead.")
wandb: Waiting for W&B process to finish, PID 204160... (success).
wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: \ 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: | 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: / 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: \ 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: | 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: / 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: \ 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: | 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: / 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb:                                                                                
wandb: Run history:
wandb:     e_F1 ▁▁▃▄▅▅▅▆▆▆▆▆▆▇▇▇▇▇▇▇▇██▇████████████████
wandb:   e_loss ██▇▇▇▇▆▆▆▆▅▅▅▄▄▄▄▃▃▃▃▃▂▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁
wandb:     t_F1 ▁▂▃▂▃▃▄▄▄▄▄▅▅▅▅▆▆▆▆▆▆▇▆▇▇▇▇▇█▆▇▇▇▇▇▇████
wandb:   t_loss ██▇▇▇▇▇▇▆▆▆▆▅▅▅▅▄▄▄▄▄▄▄▃▃▃▃▃▂▃▂▂▂▂▂▂▁▁▁▁
wandb: 
wandb: Run summary:
wandb:     e_F1 54.14556
wandb:   e_loss 1.02388
wandb:     t_F1 66.99678
wandb:   t_loss 0.84578
wandb: 
wandb: Synced 4 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Synced zesty-hill-1: https://wandb.ai/yinanazhou/xl_512_bs_8_lr_1e06_es_5_lc_False_nr_True_sr_True_stem_True_lemma_False_repeat_3_fold_1/runs/9taf61v1
wandb: Find logs at: ./wandb/run-20220318_025825-9taf61v1/logs/debug.log
wandb: 

wandb: wandb version 0.12.11 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
2022-03-18 04:13:20.148636: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1
wandb: Tracking run with wandb version 0.12.5
wandb: Syncing run classic-plasma-1
wandb: ⭐️ View project at https://wandb.ai/yinanazhou/xl_512_bs_8_lr_1e06_es_5_lc_False_nr_True_sr_True_stem_True_lemma_False_repeat_3_fold_2
wandb: 🚀 View run at https://wandb.ai/yinanazhou/xl_512_bs_8_lr_1e06_es_5_lc_False_nr_True_sr_True_stem_True_lemma_False_repeat_3_fold_2/runs/3vnepa0x
wandb: Run data is saved locally in /project/6002780/yinan/Thesis_MER_Lyrics/lyric-emotion/wandb/run-20220318_041317-3vnepa0x
wandb: Run `wandb offline` to turn off syncing.

Validation loss decreased (inf --> 1.406666).  Saving model ...
Validation loss decreased (1.406666 --> 1.396601).  Saving model ...
Validation loss decreased (1.396601 --> 1.388534).  Saving model ...
Validation loss decreased (1.388534 --> 1.382198).  Saving model ...
Validation loss decreased (1.382198 --> 1.376351).  Saving model ...
Validation loss decreased (1.376351 --> 1.371974).  Saving model ...
Validation loss decreased (1.371974 --> 1.367568).  Saving model ...
Validation loss decreased (1.367568 --> 1.363388).  Saving model ...
Validation loss decreased (1.363388 --> 1.358875).  Saving model ...
Validation loss decreased (1.358875 --> 1.355024).  Saving model ...
Validation loss decreased (1.355024 --> 1.351181).  Saving model ...
Validation loss decreased (1.351181 --> 1.346851).  Saving model ...
Validation loss decreased (1.346851 --> 1.342965).  Saving model ...
Validation loss decreased (1.342965 --> 1.338916).  Saving model ...
Validation loss decreased (1.338916 --> 1.334734).  Saving model ...
Validation loss decreased (1.334734 --> 1.330247).  Saving model ...
Validation loss decreased (1.330247 --> 1.325589).  Saving model ...
Validation loss decreased (1.325589 --> 1.320659).  Saving model ...
Validation loss decreased (1.320659 --> 1.315082).  Saving model ...
Validation loss decreased (1.315082 --> 1.310023).  Saving model ...
Validation loss decreased (1.310023 --> 1.303777).  Saving model ...
Validation loss decreased (1.303777 --> 1.297335).  Saving model ...
Validation loss decreased (1.297335 --> 1.291419).  Saving model ...
Validation loss decreased (1.291419 --> 1.284918).  Saving model ...
Validation loss decreased (1.284918 --> 1.278459).  Saving model ...
Validation loss decreased (1.278459 --> 1.272035).  Saving model ...
Validation loss decreased (1.272035 --> 1.265844).  Saving model ...
Validation loss decreased (1.265844 --> 1.259144).  Saving model ...
Validation loss decreased (1.259144 --> 1.252926).  Saving model ...
Validation loss decreased (1.252926 --> 1.247363).  Saving model ...
Validation loss decreased (1.247363 --> 1.240515).  Saving model ...
Validation loss decreased (1.240515 --> 1.233849).  Saving model ...
Validation loss decreased (1.233849 --> 1.228034).  Saving model ...
Validation loss decreased (1.228034 --> 1.222666).  Saving model ...
Validation loss decreased (1.222666 --> 1.216588).  Saving model ...
Validation loss decreased (1.216588 --> 1.210893).  Saving model ...
Validation loss decreased (1.210893 --> 1.204626).  Saving model ...
Validation loss decreased (1.204626 --> 1.199026).  Saving model ...
Validation loss decreased (1.199026 --> 1.193794).  Saving model ...
Validation loss decreased (1.193794 --> 1.188475).  Saving model ...
Validation loss decreased (1.188475 --> 1.182334).  Saving model ...
Validation loss decreased (1.182334 --> 1.177235).  Saving model ...
Validation loss decreased (1.177235 --> 1.171814).  Saving model ...
Validation loss decreased (1.171814 --> 1.168246).  Saving model ...
Validation loss decreased (1.168246 --> 1.163432).  Saving model ...
Validation loss decreased (1.163432 --> 1.158276).  Saving model ...
Validation loss decreased (1.158276 --> 1.153737).  Saving model ...
Validation loss decreased (1.153737 --> 1.147616).  Saving model ...
Validation loss decreased (1.147616 --> 1.141908).  Saving model ...
Validation loss decreased (1.141908 --> 1.136096).  Saving model ...
Validation loss decreased (1.136096 --> 1.132112).  Saving model ...
Validation loss decreased (1.132112 --> 1.128229).  Saving model ...
Validation loss decreased (1.128229 --> 1.124499).  Saving model ...
Validation loss decreased (1.124499 --> 1.119120).  Saving model ...
Validation loss decreased (1.119120 --> 1.113591).  Saving model ...
Validation loss decreased (1.113591 --> 1.105908).  Saving model ...
Validation loss decreased (1.105908 --> 1.101797).  Saving model ...
Validation loss decreased (1.101797 --> 1.098219).  Saving model ...
Validation loss decreased (1.098219 --> 1.094270).  Saving model ...
Validation loss decreased (1.094270 --> 1.090708).  Saving model ...
Validation loss decreased (1.090708 --> 1.086402).  Saving model ...
EarlyStopping counter: 1 out of 5.0
Validation loss decreased (1.086402 --> 1.082983).  Saving model ...
Validation loss decreased (1.082983 --> 1.077928).  Saving model ...
Validation loss decreased (1.077928 --> 1.072284).  Saving model ...
Validation loss decreased (1.072284 --> 1.069837).  Saving model ...
Validation loss decreased (1.069837 --> 1.065066).  Saving model ...
Validation loss decreased (1.065066 --> 1.061350).  Saving model ...
Validation loss decreased (1.061350 --> 1.058080).  Saving model ...
Validation loss decreased (1.058080 --> 1.056070).  Saving model ...
Validation loss decreased (1.056070 --> 1.054117).  Saving model ...
Validation loss decreased (1.054117 --> 1.052020).  Saving model ...
Validation loss decreased (1.052020 --> 1.048624).  Saving model ...
Validation loss decreased (1.048624 --> 1.045374).  Saving model ...
Validation loss decreased (1.045374 --> 1.043374).  Saving model ...
Validation loss decreased (1.043374 --> 1.042350).  Saving model ...
Validation loss decreased (1.042350 --> 1.038723).  Saving model ...
Validation loss decreased (1.038723 --> 1.034209).  Saving model ...
Validation loss decreased (1.034209 --> 1.033035).  Saving model ...
Validation loss decreased (1.033035 --> 1.032000).  Saving model ...
Validation loss decreased (1.032000 --> 1.030155).  Saving model ...
Validation loss decreased (1.030155 --> 1.025504).  Saving model ...
Validation loss decreased (1.025504 --> 1.024373).  Saving model ...
EarlyStopping counter: 1 out of 5.0
Validation loss decreased (1.024373 --> 1.021972).  Saving model ...
Validation loss decreased (1.021972 --> 1.019377).  Saving model ...
Validation loss decreased (1.019377 --> 1.017352).  Saving model ...
Validation loss decreased (1.017352 --> 1.013496).  Saving model ...
Validation loss decreased (1.013496 --> 1.011012).  Saving model ...
Validation loss decreased (1.011012 --> 1.008765).  Saving model ...
Validation loss decreased (1.008765 --> 1.005838).  Saving model ...
Validation loss decreased (1.005838 --> 1.002951).  Saving model ...
Validation loss decreased (1.002951 --> 1.002257).  Saving model ...
Validation loss decreased (1.002257 --> 0.998722).  Saving model ...
Validation loss decreased (0.998722 --> 0.996104).  Saving model ...
EarlyStopping counter: 1 out of 5.0
Validation loss decreased (0.996104 --> 0.994214).  Saving model ...
Validation loss decreased (0.994214 --> 0.992002).  Saving model ...
Validation loss decreased (0.992002 --> 0.989213).  Saving model ...
Validation loss decreased (0.989213 --> 0.986388).  Saving model ...
Validation loss decreased (0.986388 --> 0.983848).  Saving model ...
Validation loss decreased (0.983848 --> 0.981173).  Saving model ...
Validation loss decreased (0.981173 --> 0.980471).  Saving model ...
EarlyStopping counter: 1 out of 5.0
EarlyStopping counter: 2 out of 5.0
Validation loss decreased (0.980471 --> 0.979308).  Saving model ...
Validation loss decreased (0.979308 --> 0.977836).  Saving model ...
Validation loss decreased (0.977836 --> 0.974661).  Saving model ...
Validation loss decreased (0.974661 --> 0.973647).  Saving model ...
Validation loss decreased (0.973647 --> 0.973620).  Saving model ...
Validation loss decreased (0.973620 --> 0.972157).  Saving model ...
EarlyStopping counter: 1 out of 5.0
Validation loss decreased (0.972157 --> 0.969749).  Saving model ...
Validation loss decreased (0.969749 --> 0.967786).  Saving model ...
Validation loss decreased (0.967786 --> 0.967744).  Saving model ...
EarlyStopping counter: 1 out of 5.0
Validation loss decreased (0.967744 --> 0.967640).  Saving model ...
Validation loss decreased (0.967640 --> 0.964717).  Saving model ...
Validation loss decreased (0.964717 --> 0.964433).  Saving model ...
Validation loss decreased (0.964433 --> 0.964244).  Saving model ...
EarlyStopping counter: 1 out of 5.0
EarlyStopping counter: 2 out of 5.0
Validation loss decreased (0.964244 --> 0.962918).  Saving model ...
Validation loss decreased (0.962918 --> 0.962485).  Saving model ...
Validation loss decreased (0.962485 --> 0.962278).  Saving model ...
Validation loss decreased (0.962278 --> 0.960762).  Saving model ...
Validation loss decreased (0.960762 --> 0.958911).  Saving model ...
Validation loss decreased (0.958911 --> 0.956576).  Saving model ...
EarlyStopping counter: 1 out of 5.0
EarlyStopping counter: 2 out of 5.0
EarlyStopping counter: 3 out of 5.0
EarlyStopping counter: 4 out of 5.0
EarlyStopping counter: 5 out of 5.0
/localscratch/yinan.29161744.0/env/lib/python3.7/site-packages/torch/nn/functional.py:1794: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.
  warnings.warn("nn.functional.tanh is deprecated. Use torch.tanh instead.")
wandb: Waiting for W&B process to finish, PID 208209... (success).
wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: \ 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: | 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: / 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: \ 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: | 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: / 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: \ 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: | 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb:                                                                                
wandb: Run history:
wandb:     e_F1 ▁▂▃▄▄▅▅▅▆▆▆▆▆▇▇▇▇▇▇▇▇▇▇██▇██████████████
wandb:   e_loss ██▇▇▇▇▆▆▆▅▅▅▅▄▄▄▄▃▃▃▃▃▂▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁
wandb:     t_F1 ▁▂▃▃▃▃▄▄▅▅▅▅▅▆▆▆▆▆▆▆▆▇▇▇▇▇▇██▇▇▇██▇█████
wandb:   t_loss ██▇▇▇▇▇▇▆▆▆▆▅▅▅▅▄▄▄▄▄▃▃▃▃▃▃▂▂▂▂▂▂▂▂▁▁▂▁▁
wandb: 
wandb: Run summary:
wandb:     e_F1 58.22159
wandb:   e_loss 0.95799
wandb:     t_F1 69.16235
wandb:   t_loss 0.8214
wandb: 
wandb: Synced 4 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Synced classic-plasma-1: https://wandb.ai/yinanazhou/xl_512_bs_8_lr_1e06_es_5_lc_False_nr_True_sr_True_stem_True_lemma_False_repeat_3_fold_2/runs/3vnepa0x
wandb: Find logs at: ./wandb/run-20220318_041317-3vnepa0x/logs/debug.log
wandb: 

wandb: wandb version 0.12.11 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
2022-03-18 05:36:54.696640: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1
wandb: Tracking run with wandb version 0.12.5
wandb: Syncing run skilled-sponge-1
wandb: ⭐️ View project at https://wandb.ai/yinanazhou/xl_512_bs_8_lr_1e06_es_5_lc_False_nr_True_sr_True_stem_True_lemma_False_repeat_4_fold_1
wandb: 🚀 View run at https://wandb.ai/yinanazhou/xl_512_bs_8_lr_1e06_es_5_lc_False_nr_True_sr_True_stem_True_lemma_False_repeat_4_fold_1/runs/2wikt128
wandb: Run data is saved locally in /project/6002780/yinan/Thesis_MER_Lyrics/lyric-emotion/wandb/run-20220318_053651-2wikt128
wandb: Run `wandb offline` to turn off syncing.

Validation loss decreased (inf --> 1.419324).  Saving model ...
Validation loss decreased (1.419324 --> 1.402559).  Saving model ...
Validation loss decreased (1.402559 --> 1.390311).  Saving model ...
Validation loss decreased (1.390311 --> 1.381316).  Saving model ...
Validation loss decreased (1.381316 --> 1.373569).  Saving model ...
Validation loss decreased (1.373569 --> 1.367621).  Saving model ...
Validation loss decreased (1.367621 --> 1.362561).  Saving model ...
Validation loss decreased (1.362561 --> 1.357878).  Saving model ...
Validation loss decreased (1.357878 --> 1.353519).  Saving model ...
Validation loss decreased (1.353519 --> 1.349800).  Saving model ...
Validation loss decreased (1.349800 --> 1.346036).  Saving model ...
Validation loss decreased (1.346036 --> 1.342394).  Saving model ...
Validation loss decreased (1.342394 --> 1.338895).  Saving model ...
Validation loss decreased (1.338895 --> 1.335357).  Saving model ...
Validation loss decreased (1.335357 --> 1.331794).  Saving model ...
Validation loss decreased (1.331794 --> 1.328123).  Saving model ...
Validation loss decreased (1.328123 --> 1.324546).  Saving model ...
Validation loss decreased (1.324546 --> 1.320695).  Saving model ...
Validation loss decreased (1.320695 --> 1.316809).  Saving model ...
Validation loss decreased (1.316809 --> 1.312561).  Saving model ...
Validation loss decreased (1.312561 --> 1.308363).  Saving model ...
Validation loss decreased (1.308363 --> 1.304308).  Saving model ...
Validation loss decreased (1.304308 --> 1.300055).  Saving model ...
Validation loss decreased (1.300055 --> 1.295777).  Saving model ...
Validation loss decreased (1.295777 --> 1.291196).  Saving model ...
Validation loss decreased (1.291196 --> 1.286901).  Saving model ...
Validation loss decreased (1.286901 --> 1.282857).  Saving model ...
Validation loss decreased (1.282857 --> 1.278093).  Saving model ...
Validation loss decreased (1.278093 --> 1.273356).  Saving model ...
Validation loss decreased (1.273356 --> 1.268597).  Saving model ...
Validation loss decreased (1.268597 --> 1.263217).  Saving model ...
Validation loss decreased (1.263217 --> 1.258246).  Saving model ...
Validation loss decreased (1.258246 --> 1.253918).  Saving model ...
Validation loss decreased (1.253918 --> 1.248763).  Saving model ...
Validation loss decreased (1.248763 --> 1.244262).  Saving model ...
Validation loss decreased (1.244262 --> 1.239019).  Saving model ...
Validation loss decreased (1.239019 --> 1.234577).  Saving model ...
Validation loss decreased (1.234577 --> 1.228628).  Saving model ...
Validation loss decreased (1.228628 --> 1.223303).  Saving model ...
Validation loss decreased (1.223303 --> 1.218894).  Saving model ...
Validation loss decreased (1.218894 --> 1.213313).  Saving model ...
Validation loss decreased (1.213313 --> 1.208334).  Saving model ...
Validation loss decreased (1.208334 --> 1.203328).  Saving model ...
Validation loss decreased (1.203328 --> 1.197837).  Saving model ...
Validation loss decreased (1.197837 --> 1.192288).  Saving model ...
Validation loss decreased (1.192288 --> 1.187006).  Saving model ...
Validation loss decreased (1.187006 --> 1.182290).  Saving model ...
Validation loss decreased (1.182290 --> 1.177405).  Saving model ...
Validation loss decreased (1.177405 --> 1.172558).  Saving model ...
Validation loss decreased (1.172558 --> 1.166939).  Saving model ...
Validation loss decreased (1.166939 --> 1.161809).  Saving model ...
Validation loss decreased (1.161809 --> 1.157222).  Saving model ...
Validation loss decreased (1.157222 --> 1.152303).  Saving model ...
Validation loss decreased (1.152303 --> 1.147786).  Saving model ...
Validation loss decreased (1.147786 --> 1.143017).  Saving model ...
Validation loss decreased (1.143017 --> 1.138541).  Saving model ...
Validation loss decreased (1.138541 --> 1.133948).  Saving model ...
Validation loss decreased (1.133948 --> 1.130084).  Saving model ...
Validation loss decreased (1.130084 --> 1.126566).  Saving model ...
Validation loss decreased (1.126566 --> 1.121895).  Saving model ...
Validation loss decreased (1.121895 --> 1.117602).  Saving model ...
Validation loss decreased (1.117602 --> 1.113271).  Saving model ...
Validation loss decreased (1.113271 --> 1.109779).  Saving model ...
Validation loss decreased (1.109779 --> 1.106204).  Saving model ...
Validation loss decreased (1.106204 --> 1.102222).  Saving model ...
Validation loss decreased (1.102222 --> 1.097974).  Saving model ...
Validation loss decreased (1.097974 --> 1.093596).  Saving model ...
Validation loss decreased (1.093596 --> 1.090618).  Saving model ...
Validation loss decreased (1.090618 --> 1.087308).  Saving model ...
Validation loss decreased (1.087308 --> 1.083800).  Saving model ...
Validation loss decreased (1.083800 --> 1.080951).  Saving model ...
Validation loss decreased (1.080951 --> 1.077616).  Saving model ...
Validation loss decreased (1.077616 --> 1.075139).  Saving model ...
Validation loss decreased (1.075139 --> 1.071311).  Saving model ...
Validation loss decreased (1.071311 --> 1.069253).  Saving model ...
Validation loss decreased (1.069253 --> 1.066889).  Saving model ...
Validation loss decreased (1.066889 --> 1.063677).  Saving model ...
Validation loss decreased (1.063677 --> 1.061461).  Saving model ...
Validation loss decreased (1.061461 --> 1.058888).  Saving model ...
Validation loss decreased (1.058888 --> 1.057273).  Saving model ...
Validation loss decreased (1.057273 --> 1.054239).  Saving model ...
Validation loss decreased (1.054239 --> 1.051932).  Saving model ...
Validation loss decreased (1.051932 --> 1.049533).  Saving model ...
Validation loss decreased (1.049533 --> 1.047133).  Saving model ...
Validation loss decreased (1.047133 --> 1.045373).  Saving model ...
Validation loss decreased (1.045373 --> 1.043445).  Saving model ...
Validation loss decreased (1.043445 --> 1.041799).  Saving model ...
Validation loss decreased (1.041799 --> 1.039715).  Saving model ...
Validation loss decreased (1.039715 --> 1.038589).  Saving model ...
Validation loss decreased (1.038589 --> 1.036702).  Saving model ...
Validation loss decreased (1.036702 --> 1.035730).  Saving model ...
Validation loss decreased (1.035730 --> 1.032803).  Saving model ...
Validation loss decreased (1.032803 --> 1.031079).  Saving model ...
Validation loss decreased (1.031079 --> 1.029346).  Saving model ...
Validation loss decreased (1.029346 --> 1.028350).  Saving model ...
Validation loss decreased (1.028350 --> 1.026824).  Saving model ...
Validation loss decreased (1.026824 --> 1.024664).  Saving model ...
Validation loss decreased (1.024664 --> 1.023681).  Saving model ...
Validation loss decreased (1.023681 --> 1.021794).  Saving model ...
Validation loss decreased (1.021794 --> 1.020842).  Saving model ...
Validation loss decreased (1.020842 --> 1.019334).  Saving model ...
Validation loss decreased (1.019334 --> 1.017635).  Saving model ...
Validation loss decreased (1.017635 --> 1.015753).  Saving model ...
Validation loss decreased (1.015753 --> 1.015111).  Saving model ...
Validation loss decreased (1.015111 --> 1.013704).  Saving model ...
Validation loss decreased (1.013704 --> 1.011787).  Saving model ...
Validation loss decreased (1.011787 --> 1.011212).  Saving model ...
Validation loss decreased (1.011212 --> 1.009618).  Saving model ...
Validation loss decreased (1.009618 --> 1.009346).  Saving model ...
Validation loss decreased (1.009346 --> 1.008570).  Saving model ...
Validation loss decreased (1.008570 --> 1.006740).  Saving model ...
Validation loss decreased (1.006740 --> 1.004423).  Saving model ...
Validation loss decreased (1.004423 --> 1.003416).  Saving model ...
Validation loss decreased (1.003416 --> 1.002657).  Saving model ...
Validation loss decreased (1.002657 --> 1.001865).  Saving model ...
Validation loss decreased (1.001865 --> 1.000998).  Saving model ...
Validation loss decreased (1.000998 --> 1.000238).  Saving model ...
Validation loss decreased (1.000238 --> 1.000001).  Saving model ...
Validation loss decreased (1.000001 --> 0.999015).  Saving model ...
EarlyStopping counter: 1 out of 5.0
EarlyStopping counter: 2 out of 5.0
EarlyStopping counter: 3 out of 5.0
Validation loss decreased (0.999015 --> 0.998908).  Saving model ...
EarlyStopping counter: 1 out of 5.0
Validation loss decreased (0.998908 --> 0.998619).  Saving model ...
Validation loss decreased (0.998619 --> 0.997893).  Saving model ...
Validation loss decreased (0.997893 --> 0.996642).  Saving model ...
Validation loss decreased (0.996642 --> 0.996189).  Saving model ...
Validation loss decreased (0.996189 --> 0.995730).  Saving model ...
Validation loss decreased (0.995730 --> 0.994964).  Saving model ...
EarlyStopping counter: 1 out of 5.0
EarlyStopping counter: 2 out of 5.0
EarlyStopping counter: 3 out of 5.0
Validation loss decreased (0.994964 --> 0.992608).  Saving model ...
EarlyStopping counter: 1 out of 5.0
EarlyStopping counter: 2 out of 5.0
EarlyStopping counter: 3 out of 5.0
EarlyStopping counter: 4 out of 5.0
EarlyStopping counter: 5 out of 5.0
/localscratch/yinan.29161744.0/env/lib/python3.7/site-packages/torch/nn/functional.py:1794: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.
  warnings.warn("nn.functional.tanh is deprecated. Use torch.tanh instead.")
wandb: Waiting for W&B process to finish, PID 212697... (success).
wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: \ 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: | 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: / 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: \ 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: | 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: / 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: \ 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: | 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb:                                                                                
wandb: Run history:
wandb:     e_F1 ▁▂▃▄▄▄▅▅▅▅▅▅▆▆▆▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇██████████
wandb:   e_loss ██▇▇▇▇▆▆▆▆▅▅▅▄▄▄▃▃▃▃▃▂▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁
wandb:     t_F1 ▁▂▂▃▃▃▃▃▄▅▄▅▆▅▆▆▆▆▇▇▇▇▇▇▇▇▇▇▇▇▇▇█▇▇█████
wandb:   t_loss ██▇▇▇▇▇▇▆▆▆▆▅▅▅▅▄▄▄▄▃▃▃▃▃▃▃▂▂▂▂▂▂▂▂▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:     e_F1 56.0524
wandb:   e_loss 0.99455
wandb:     t_F1 67.70188
wandb:   t_loss 0.8024
wandb: 
wandb: Synced 4 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Synced skilled-sponge-1: https://wandb.ai/yinanazhou/xl_512_bs_8_lr_1e06_es_5_lc_False_nr_True_sr_True_stem_True_lemma_False_repeat_4_fold_1/runs/2wikt128
wandb: Find logs at: ./wandb/run-20220318_053651-2wikt128/logs/debug.log
wandb: 

wandb: wandb version 0.12.11 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
2022-03-18 07:07:29.329231: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1
wandb: Tracking run with wandb version 0.12.5
wandb: Syncing run amber-sponge-1
wandb: ⭐️ View project at https://wandb.ai/yinanazhou/xl_512_bs_8_lr_1e06_es_5_lc_False_nr_True_sr_True_stem_True_lemma_False_repeat_4_fold_2
wandb: 🚀 View run at https://wandb.ai/yinanazhou/xl_512_bs_8_lr_1e06_es_5_lc_False_nr_True_sr_True_stem_True_lemma_False_repeat_4_fold_2/runs/1mibs86a
wandb: Run data is saved locally in /project/6002780/yinan/Thesis_MER_Lyrics/lyric-emotion/wandb/run-20220318_070726-1mibs86a
wandb: Run `wandb offline` to turn off syncing.

Validation loss decreased (inf --> 1.399606).  Saving model ...
Validation loss decreased (1.399606 --> 1.394015).  Saving model ...
Validation loss decreased (1.394015 --> 1.389058).  Saving model ...
Validation loss decreased (1.389058 --> 1.384658).  Saving model ...
Validation loss decreased (1.384658 --> 1.380381).  Saving model ...
Validation loss decreased (1.380381 --> 1.376255).  Saving model ...
Validation loss decreased (1.376255 --> 1.372343).  Saving model ...
Validation loss decreased (1.372343 --> 1.368621).  Saving model ...
Validation loss decreased (1.368621 --> 1.364512).  Saving model ...
Validation loss decreased (1.364512 --> 1.360888).  Saving model ...
Validation loss decreased (1.360888 --> 1.357018).  Saving model ...
Validation loss decreased (1.357018 --> 1.353397).  Saving model ...
Validation loss decreased (1.353397 --> 1.349647).  Saving model ...
Validation loss decreased (1.349647 --> 1.345846).  Saving model ...
Validation loss decreased (1.345846 --> 1.342002).  Saving model ...
Validation loss decreased (1.342002 --> 1.338571).  Saving model ...
Validation loss decreased (1.338571 --> 1.333859).  Saving model ...
Validation loss decreased (1.333859 --> 1.328759).  Saving model ...
Validation loss decreased (1.328759 --> 1.324958).  Saving model ...
Validation loss decreased (1.324958 --> 1.320111).  Saving model ...
Validation loss decreased (1.320111 --> 1.313825).  Saving model ...
Validation loss decreased (1.313825 --> 1.309008).  Saving model ...
Validation loss decreased (1.309008 --> 1.305183).  Saving model ...
Validation loss decreased (1.305183 --> 1.299079).  Saving model ...
Validation loss decreased (1.299079 --> 1.292850).  Saving model ...
Validation loss decreased (1.292850 --> 1.286502).  Saving model ...
Validation loss decreased (1.286502 --> 1.279817).  Saving model ...
Validation loss decreased (1.279817 --> 1.273905).  Saving model ...
Validation loss decreased (1.273905 --> 1.266054).  Saving model ...
Validation loss decreased (1.266054 --> 1.261176).  Saving model ...
Validation loss decreased (1.261176 --> 1.254575).  Saving model ...
Validation loss decreased (1.254575 --> 1.248606).  Saving model ...
Validation loss decreased (1.248606 --> 1.239860).  Saving model ...
Validation loss decreased (1.239860 --> 1.231543).  Saving model ...
Validation loss decreased (1.231543 --> 1.226830).  Saving model ...
Validation loss decreased (1.226830 --> 1.219799).  Saving model ...
Validation loss decreased (1.219799 --> 1.211831).  Saving model ...
Validation loss decreased (1.211831 --> 1.205662).  Saving model ...
Validation loss decreased (1.205662 --> 1.202177).  Saving model ...
Validation loss decreased (1.202177 --> 1.196840).  Saving model ...
Validation loss decreased (1.196840 --> 1.191633).  Saving model ...
Validation loss decreased (1.191633 --> 1.186187).  Saving model ...
Validation loss decreased (1.186187 --> 1.179444).  Saving model ...
Validation loss decreased (1.179444 --> 1.175305).  Saving model ...
Validation loss decreased (1.175305 --> 1.168577).  Saving model ...
Validation loss decreased (1.168577 --> 1.163206).  Saving model ...
Validation loss decreased (1.163206 --> 1.158102).  Saving model ...
Validation loss decreased (1.158102 --> 1.153799).  Saving model ...
Validation loss decreased (1.153799 --> 1.149818).  Saving model ...
Validation loss decreased (1.149818 --> 1.147298).  Saving model ...
Validation loss decreased (1.147298 --> 1.136036).  Saving model ...
Validation loss decreased (1.136036 --> 1.132649).  Saving model ...
Validation loss decreased (1.132649 --> 1.129120).  Saving model ...
Validation loss decreased (1.129120 --> 1.125187).  Saving model ...
Validation loss decreased (1.125187 --> 1.120702).  Saving model ...
Validation loss decreased (1.120702 --> 1.117117).  Saving model ...
Validation loss decreased (1.117117 --> 1.114285).  Saving model ...
Validation loss decreased (1.114285 --> 1.111142).  Saving model ...
Validation loss decreased (1.111142 --> 1.107596).  Saving model ...
Validation loss decreased (1.107596 --> 1.103297).  Saving model ...
Validation loss decreased (1.103297 --> 1.096797).  Saving model ...
Validation loss decreased (1.096797 --> 1.094843).  Saving model ...
Validation loss decreased (1.094843 --> 1.091724).  Saving model ...
Validation loss decreased (1.091724 --> 1.088177).  Saving model ...
Validation loss decreased (1.088177 --> 1.087163).  Saving model ...
Validation loss decreased (1.087163 --> 1.081176).  Saving model ...
Validation loss decreased (1.081176 --> 1.079512).  Saving model ...
EarlyStopping counter: 1 out of 5.0
Validation loss decreased (1.079512 --> 1.076861).  Saving model ...
Validation loss decreased (1.076861 --> 1.072539).  Saving model ...
Validation loss decreased (1.072539 --> 1.069500).  Saving model ...
Validation loss decreased (1.069500 --> 1.063501).  Saving model ...
EarlyStopping counter: 1 out of 5.0
Validation loss decreased (1.063501 --> 1.057666).  Saving model ...
Validation loss decreased (1.057666 --> 1.056132).  Saving model ...
Validation loss decreased (1.056132 --> 1.054984).  Saving model ...
Validation loss decreased (1.054984 --> 1.053204).  Saving model ...
Validation loss decreased (1.053204 --> 1.050126).  Saving model ...
Validation loss decreased (1.050126 --> 1.046050).  Saving model ...
Validation loss decreased (1.046050 --> 1.043757).  Saving model ...
EarlyStopping counter: 1 out of 5.0
Validation loss decreased (1.043757 --> 1.040518).  Saving model ...
Validation loss decreased (1.040518 --> 1.038681).  Saving model ...
Validation loss decreased (1.038681 --> 1.038621).  Saving model ...
Validation loss decreased (1.038621 --> 1.032580).  Saving model ...
Validation loss decreased (1.032580 --> 1.031847).  Saving model ...
EarlyStopping counter: 1 out of 5.0
Validation loss decreased (1.031847 --> 1.031279).  Saving model ...
Validation loss decreased (1.031279 --> 1.030668).  Saving model ...
Validation loss decreased (1.030668 --> 1.027898).  Saving model ...
EarlyStopping counter: 1 out of 5.0
EarlyStopping counter: 2 out of 5.0
Validation loss decreased (1.027898 --> 1.021798).  Saving model ...
EarlyStopping counter: 1 out of 5.0
Validation loss decreased (1.021798 --> 1.020955).  Saving model ...
Validation loss decreased (1.020955 --> 1.017144).  Saving model ...
EarlyStopping counter: 1 out of 5.0
EarlyStopping counter: 2 out of 5.0
Validation loss decreased (1.017144 --> 1.016538).  Saving model ...
Validation loss decreased (1.016538 --> 1.015734).  Saving model ...
Validation loss decreased (1.015734 --> 1.015155).  Saving model ...
Validation loss decreased (1.015155 --> 1.013326).  Saving model ...
EarlyStopping counter: 1 out of 5.0
EarlyStopping counter: 2 out of 5.0
EarlyStopping counter: 3 out of 5.0
EarlyStopping counter: 4 out of 5.0
Validation loss decreased (1.013326 --> 1.013111).  Saving model ...
Validation loss decreased (1.013111 --> 1.012341).  Saving model ...
Validation loss decreased (1.012341 --> 1.009898).  Saving model ...
Validation loss decreased (1.009898 --> 1.007580).  Saving model ...
Validation loss decreased (1.007580 --> 1.005920).  Saving model ...
EarlyStopping counter: 1 out of 5.0
EarlyStopping counter: 2 out of 5.0
EarlyStopping counter: 3 out of 5.0
Validation loss decreased (1.005920 --> 1.003611).  Saving model ...
Validation loss decreased (1.003611 --> 1.001976).  Saving model ...
EarlyStopping counter: 1 out of 5.0
EarlyStopping counter: 2 out of 5.0
EarlyStopping counter: 3 out of 5.0
Validation loss decreased (1.001976 --> 0.998200).  Saving model ...
EarlyStopping counter: 1 out of 5.0
EarlyStopping counter: 2 out of 5.0
EarlyStopping counter: 3 out of 5.0
EarlyStopping counter: 4 out of 5.0
EarlyStopping counter: 5 out of 5.0
/localscratch/yinan.29161744.0/env/lib/python3.7/site-packages/torch/nn/functional.py:1794: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.
  warnings.warn("nn.functional.tanh is deprecated. Use torch.tanh instead.")
wandb: Waiting for W&B process to finish, PID 217569... (success).
wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: \ 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: | 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: / 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: \ 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: | 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: / 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: \ 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: | 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: / 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb:                                                                                
wandb: Run history:
wandb:     e_F1 ▁▂▃▄▄▄▅▅▅▅▆▆▆▇▇▇▇▇▇█████████████████████
wandb:   e_loss ███▇▇▇▇▆▆▆▅▅▅▄▄▄▃▃▃▃▃▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁
wandb:     t_F1 ▁▁▂▂▂▃▃▃▃▄▅▅▅▅▆▅▆▆▆▅▆▅▆▆▇▇▆▇▇▇▇▇▇▇▇▇█▇██
wandb:   t_loss ████▇▇▇▇▇▇▆▆▆▅▅▅▅▅▄▄▄▄▄▃▃▃▃▃▂▂▂▂▂▂▂▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:     e_F1 59.20776
wandb:   e_loss 1.00707
wandb:     t_F1 68.8411
wandb:   t_loss 0.80675
wandb: 
wandb: Synced 4 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Synced amber-sponge-1: https://wandb.ai/yinanazhou/xl_512_bs_8_lr_1e06_es_5_lc_False_nr_True_sr_True_stem_True_lemma_False_repeat_4_fold_2/runs/1mibs86a
wandb: Find logs at: ./wandb/run-20220318_070726-1mibs86a/logs/debug.log
wandb: 

wandb: wandb version 0.12.11 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
2022-03-18 08:29:37.551704: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1
wandb: Tracking run with wandb version 0.12.5
wandb: Syncing run brisk-music-1
wandb: ⭐️ View project at https://wandb.ai/yinanazhou/xl_512_bs_8_lr_1e06_es_5_lc_False_nr_True_sr_True_stem_True_lemma_False_repeat_5_fold_1
wandb: 🚀 View run at https://wandb.ai/yinanazhou/xl_512_bs_8_lr_1e06_es_5_lc_False_nr_True_sr_True_stem_True_lemma_False_repeat_5_fold_1/runs/1krmzg23
wandb: Run data is saved locally in /project/6002780/yinan/Thesis_MER_Lyrics/lyric-emotion/wandb/run-20220318_082934-1krmzg23
wandb: Run `wandb offline` to turn off syncing.

Validation loss decreased (inf --> 1.437815).  Saving model ...
Validation loss decreased (1.437815 --> 1.415515).  Saving model ...
Validation loss decreased (1.415515 --> 1.398800).  Saving model ...
Validation loss decreased (1.398800 --> 1.385349).  Saving model ...
Validation loss decreased (1.385349 --> 1.373978).  Saving model ...
Validation loss decreased (1.373978 --> 1.365048).  Saving model ...
Validation loss decreased (1.365048 --> 1.357860).  Saving model ...
Validation loss decreased (1.357860 --> 1.351760).  Saving model ...
Validation loss decreased (1.351760 --> 1.346338).  Saving model ...
Validation loss decreased (1.346338 --> 1.341234).  Saving model ...
Validation loss decreased (1.341234 --> 1.337319).  Saving model ...
Validation loss decreased (1.337319 --> 1.333098).  Saving model ...
Validation loss decreased (1.333098 --> 1.328189).  Saving model ...
Validation loss decreased (1.328189 --> 1.323393).  Saving model ...
Validation loss decreased (1.323393 --> 1.318628).  Saving model ...
Validation loss decreased (1.318628 --> 1.314315).  Saving model ...
Validation loss decreased (1.314315 --> 1.309299).  Saving model ...
Validation loss decreased (1.309299 --> 1.303318).  Saving model ...
Validation loss decreased (1.303318 --> 1.297511).  Saving model ...
Validation loss decreased (1.297511 --> 1.292293).  Saving model ...
Validation loss decreased (1.292293 --> 1.286937).  Saving model ...
Validation loss decreased (1.286937 --> 1.281301).  Saving model ...
Validation loss decreased (1.281301 --> 1.275541).  Saving model ...
Validation loss decreased (1.275541 --> 1.268738).  Saving model ...
Validation loss decreased (1.268738 --> 1.261992).  Saving model ...
Validation loss decreased (1.261992 --> 1.255084).  Saving model ...
Validation loss decreased (1.255084 --> 1.248549).  Saving model ...
Validation loss decreased (1.248549 --> 1.240854).  Saving model ...
Validation loss decreased (1.240854 --> 1.232902).  Saving model ...
Validation loss decreased (1.232902 --> 1.225877).  Saving model ...
Validation loss decreased (1.225877 --> 1.219690).  Saving model ...
Validation loss decreased (1.219690 --> 1.212334).  Saving model ...
Validation loss decreased (1.212334 --> 1.206160).  Saving model ...
Validation loss decreased (1.206160 --> 1.199622).  Saving model ...
Validation loss decreased (1.199622 --> 1.192500).  Saving model ...
Validation loss decreased (1.192500 --> 1.186099).  Saving model ...
Validation loss decreased (1.186099 --> 1.180385).  Saving model ...
Validation loss decreased (1.180385 --> 1.174533).  Saving model ...
Validation loss decreased (1.174533 --> 1.168535).  Saving model ...
Validation loss decreased (1.168535 --> 1.162581).  Saving model ...
Validation loss decreased (1.162581 --> 1.156661).  Saving model ...
Validation loss decreased (1.156661 --> 1.151102).  Saving model ...
Validation loss decreased (1.151102 --> 1.146546).  Saving model ...
Validation loss decreased (1.146546 --> 1.139922).  Saving model ...
Validation loss decreased (1.139922 --> 1.134718).  Saving model ...
Validation loss decreased (1.134718 --> 1.130225).  Saving model ...
Validation loss decreased (1.130225 --> 1.125347).  Saving model ...
Validation loss decreased (1.125347 --> 1.120334).  Saving model ...
Validation loss decreased (1.120334 --> 1.115691).  Saving model ...
Validation loss decreased (1.115691 --> 1.110772).  Saving model ...
Validation loss decreased (1.110772 --> 1.106482).  Saving model ...
Validation loss decreased (1.106482 --> 1.101724).  Saving model ...
Validation loss decreased (1.101724 --> 1.097431).  Saving model ...
Validation loss decreased (1.097431 --> 1.093953).  Saving model ...
Validation loss decreased (1.093953 --> 1.089455).  Saving model ...
Validation loss decreased (1.089455 --> 1.084369).  Saving model ...
Validation loss decreased (1.084369 --> 1.080817).  Saving model ...
Validation loss decreased (1.080817 --> 1.077238).  Saving model ...
Validation loss decreased (1.077238 --> 1.073887).  Saving model ...
Validation loss decreased (1.073887 --> 1.070444).  Saving model ...
Validation loss decreased (1.070444 --> 1.066494).  Saving model ...
Validation loss decreased (1.066494 --> 1.063147).  Saving model ...
Validation loss decreased (1.063147 --> 1.059619).  Saving model ...
Validation loss decreased (1.059619 --> 1.055528).  Saving model ...
Validation loss decreased (1.055528 --> 1.051880).  Saving model ...
Validation loss decreased (1.051880 --> 1.048669).  Saving model ...
Validation loss decreased (1.048669 --> 1.045768).  Saving model ...
Validation loss decreased (1.045768 --> 1.042745).  Saving model ...
Validation loss decreased (1.042745 --> 1.040143).  Saving model ...
Validation loss decreased (1.040143 --> 1.036301).  Saving model ...
Validation loss decreased (1.036301 --> 1.033444).  Saving model ...
Validation loss decreased (1.033444 --> 1.030750).  Saving model ...
Validation loss decreased (1.030750 --> 1.028539).  Saving model ...
Validation loss decreased (1.028539 --> 1.026043).  Saving model ...
Validation loss decreased (1.026043 --> 1.023149).  Saving model ...
Validation loss decreased (1.023149 --> 1.020511).  Saving model ...
Validation loss decreased (1.020511 --> 1.017393).  Saving model ...
Validation loss decreased (1.017393 --> 1.015085).  Saving model ...
Validation loss decreased (1.015085 --> 1.013417).  Saving model ...
Validation loss decreased (1.013417 --> 1.010665).  Saving model ...
Validation loss decreased (1.010665 --> 1.009224).  Saving model ...
Validation loss decreased (1.009224 --> 1.007852).  Saving model ...
Validation loss decreased (1.007852 --> 1.005523).  Saving model ...
Validation loss decreased (1.005523 --> 1.003615).  Saving model ...
Validation loss decreased (1.003615 --> 1.000646).  Saving model ...
Validation loss decreased (1.000646 --> 0.999252).  Saving model ...
Validation loss decreased (0.999252 --> 0.997957).  Saving model ...
Validation loss decreased (0.997957 --> 0.995539).  Saving model ...
Validation loss decreased (0.995539 --> 0.993093).  Saving model ...
Validation loss decreased (0.993093 --> 0.991770).  Saving model ...
Validation loss decreased (0.991770 --> 0.990345).  Saving model ...
Validation loss decreased (0.990345 --> 0.988884).  Saving model ...
Validation loss decreased (0.988884 --> 0.987200).  Saving model ...
Validation loss decreased (0.987200 --> 0.985371).  Saving model ...
Validation loss decreased (0.985371 --> 0.983399).  Saving model ...
Validation loss decreased (0.983399 --> 0.982592).  Saving model ...
Validation loss decreased (0.982592 --> 0.980253).  Saving model ...
Validation loss decreased (0.980253 --> 0.978257).  Saving model ...
Validation loss decreased (0.978257 --> 0.977548).  Saving model ...
Validation loss decreased (0.977548 --> 0.977170).  Saving model ...
Validation loss decreased (0.977170 --> 0.975537).  Saving model ...
Validation loss decreased (0.975537 --> 0.974683).  Saving model ...
Validation loss decreased (0.974683 --> 0.974081).  Saving model ...
Validation loss decreased (0.974081 --> 0.972058).  Saving model ...
Validation loss decreased (0.972058 --> 0.970653).  Saving model ...
Validation loss decreased (0.970653 --> 0.970047).  Saving model ...
Validation loss decreased (0.970047 --> 0.968546).  Saving model ...
Validation loss decreased (0.968546 --> 0.968013).  Saving model ...
Validation loss decreased (0.968013 --> 0.966961).  Saving model ...
Validation loss decreased (0.966961 --> 0.965709).  Saving model ...
Validation loss decreased (0.965709 --> 0.965173).  Saving model ...
Validation loss decreased (0.965173 --> 0.964404).  Saving model ...
Validation loss decreased (0.964404 --> 0.964046).  Saving model ...
Validation loss decreased (0.964046 --> 0.963750).  Saving model ...
Validation loss decreased (0.963750 --> 0.963164).  Saving model ...
Validation loss decreased (0.963164 --> 0.962931).  Saving model ...
Validation loss decreased (0.962931 --> 0.962601).  Saving model ...
Validation loss decreased (0.962601 --> 0.961131).  Saving model ...
Validation loss decreased (0.961131 --> 0.960245).  Saving model ...
Validation loss decreased (0.960245 --> 0.959595).  Saving model ...
EarlyStopping counter: 1 out of 5.0
Validation loss decreased (0.959595 --> 0.958663).  Saving model ...
EarlyStopping counter: 1 out of 5.0
EarlyStopping counter: 2 out of 5.0
Validation loss decreased (0.958663 --> 0.958490).  Saving model ...
EarlyStopping counter: 1 out of 5.0
EarlyStopping counter: 2 out of 5.0
Validation loss decreased (0.958490 --> 0.957946).  Saving model ...
EarlyStopping counter: 1 out of 5.0
EarlyStopping counter: 2 out of 5.0
EarlyStopping counter: 3 out of 5.0
EarlyStopping counter: 4 out of 5.0
EarlyStopping counter: 5 out of 5.0
/localscratch/yinan.29161744.0/env/lib/python3.7/site-packages/torch/nn/functional.py:1794: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.
  warnings.warn("nn.functional.tanh is deprecated. Use torch.tanh instead.")
wandb: Waiting for W&B process to finish, PID 221977... (success).
wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: \ 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: | 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: / 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: \ 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: | 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: / 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: \ 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: | 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: / 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: \ 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: | 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb:                                                                                
wandb: Run history:
wandb:     e_F1 ▁▁▃▄▅▅▅▅▆▆▆▇▇▇▇▇▇▇██████████████████████
wandb:   e_loss ██▇▇▇▆▆▆▅▅▅▄▄▄▃▃▃▃▃▂▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:     t_F1 ▁▂▂▃▃▃▄▄▅▅▅▅▅▅▆▆▆▆▇▆▆▇▇▇▇▇▇▇▇▇▇▇█▇██████
wandb:   t_loss ██▇▇▇▇▇▆▆▆▆▆▅▅▅▅▄▄▄▄▄▃▃▃▃▃▃▃▃▂▂▂▂▂▂▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:     e_F1 55.99997
wandb:   e_loss 0.95861
wandb:     t_F1 68.7909
wandb:   t_loss 0.77887
wandb: 
wandb: Synced 4 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Synced brisk-music-1: https://wandb.ai/yinanazhou/xl_512_bs_8_lr_1e06_es_5_lc_False_nr_True_sr_True_stem_True_lemma_False_repeat_5_fold_1/runs/1krmzg23
wandb: Find logs at: ./wandb/run-20220318_082934-1krmzg23/logs/debug.log
wandb: 

wandb: wandb version 0.12.11 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
2022-03-18 09:56:15.408005: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1
wandb: Tracking run with wandb version 0.12.5
wandb: Syncing run effortless-butterfly-1
wandb: ⭐️ View project at https://wandb.ai/yinanazhou/xl_512_bs_8_lr_1e06_es_5_lc_False_nr_True_sr_True_stem_True_lemma_False_repeat_5_fold_2
wandb: 🚀 View run at https://wandb.ai/yinanazhou/xl_512_bs_8_lr_1e06_es_5_lc_False_nr_True_sr_True_stem_True_lemma_False_repeat_5_fold_2/runs/1li2tyr6
wandb: Run data is saved locally in /project/6002780/yinan/Thesis_MER_Lyrics/lyric-emotion/wandb/run-20220318_095612-1li2tyr6
wandb: Run `wandb offline` to turn off syncing.

Validation loss decreased (inf --> 1.447771).  Saving model ...
Validation loss decreased (1.447771 --> 1.422070).  Saving model ...
Validation loss decreased (1.422070 --> 1.402163).  Saving model ...
Validation loss decreased (1.402163 --> 1.385758).  Saving model ...
Validation loss decreased (1.385758 --> 1.372474).  Saving model ...
Validation loss decreased (1.372474 --> 1.362697).  Saving model ...
Validation loss decreased (1.362697 --> 1.355308).  Saving model ...
Validation loss decreased (1.355308 --> 1.349220).  Saving model ...
Validation loss decreased (1.349220 --> 1.343291).  Saving model ...
Validation loss decreased (1.343291 --> 1.337248).  Saving model ...
Validation loss decreased (1.337248 --> 1.332600).  Saving model ...
Validation loss decreased (1.332600 --> 1.327274).  Saving model ...
Validation loss decreased (1.327274 --> 1.322484).  Saving model ...
Validation loss decreased (1.322484 --> 1.317688).  Saving model ...
Validation loss decreased (1.317688 --> 1.313124).  Saving model ...
Validation loss decreased (1.313124 --> 1.308905).  Saving model ...
Validation loss decreased (1.308905 --> 1.303542).  Saving model ...
Validation loss decreased (1.303542 --> 1.297756).  Saving model ...
Validation loss decreased (1.297756 --> 1.292445).  Saving model ...
Validation loss decreased (1.292445 --> 1.287113).  Saving model ...
Validation loss decreased (1.287113 --> 1.281468).  Saving model ...
Validation loss decreased (1.281468 --> 1.275219).  Saving model ...
Validation loss decreased (1.275219 --> 1.269436).  Saving model ...
Validation loss decreased (1.269436 --> 1.263568).  Saving model ...
Validation loss decreased (1.263568 --> 1.257967).  Saving model ...
Validation loss decreased (1.257967 --> 1.252134).  Saving model ...
Validation loss decreased (1.252134 --> 1.244829).  Saving model ...
Validation loss decreased (1.244829 --> 1.238383).  Saving model ...
Validation loss decreased (1.238383 --> 1.231428).  Saving model ...
Validation loss decreased (1.231428 --> 1.226276).  Saving model ...
Validation loss decreased (1.226276 --> 1.220924).  Saving model ...
Validation loss decreased (1.220924 --> 1.215663).  Saving model ...
Validation loss decreased (1.215663 --> 1.208404).  Saving model ...
Validation loss decreased (1.208404 --> 1.201420).  Saving model ...
Validation loss decreased (1.201420 --> 1.197243).  Saving model ...
Validation loss decreased (1.197243 --> 1.190546).  Saving model ...
Validation loss decreased (1.190546 --> 1.184876).  Saving model ...
Validation loss decreased (1.184876 --> 1.180079).  Saving model ...
Validation loss decreased (1.180079 --> 1.173246).  Saving model ...
Validation loss decreased (1.173246 --> 1.168110).  Saving model ...
Validation loss decreased (1.168110 --> 1.163178).  Saving model ...
Validation loss decreased (1.163178 --> 1.157924).  Saving model ...
Validation loss decreased (1.157924 --> 1.154079).  Saving model ...
Validation loss decreased (1.154079 --> 1.151463).  Saving model ...
Validation loss decreased (1.151463 --> 1.146646).  Saving model ...
Validation loss decreased (1.146646 --> 1.137918).  Saving model ...
Validation loss decreased (1.137918 --> 1.133916).  Saving model ...
Validation loss decreased (1.133916 --> 1.130234).  Saving model ...
Validation loss decreased (1.130234 --> 1.124905).  Saving model ...
Validation loss decreased (1.124905 --> 1.122059).  Saving model ...
Validation loss decreased (1.122059 --> 1.117253).  Saving model ...
Validation loss decreased (1.117253 --> 1.114315).  Saving model ...
Validation loss decreased (1.114315 --> 1.110493).  Saving model ...
Validation loss decreased (1.110493 --> 1.107050).  Saving model ...
Validation loss decreased (1.107050 --> 1.103338).  Saving model ...
Validation loss decreased (1.103338 --> 1.101131).  Saving model ...
Validation loss decreased (1.101131 --> 1.096120).  Saving model ...
Validation loss decreased (1.096120 --> 1.090179).  Saving model ...
Validation loss decreased (1.090179 --> 1.086408).  Saving model ...
Validation loss decreased (1.086408 --> 1.085926).  Saving model ...
Validation loss decreased (1.085926 --> 1.083042).  Saving model ...
Validation loss decreased (1.083042 --> 1.079113).  Saving model ...
Validation loss decreased (1.079113 --> 1.076235).  Saving model ...
Validation loss decreased (1.076235 --> 1.072953).  Saving model ...
Validation loss decreased (1.072953 --> 1.069959).  Saving model ...
Validation loss decreased (1.069959 --> 1.066022).  Saving model ...
EarlyStopping counter: 1 out of 5.0
Validation loss decreased (1.066022 --> 1.064486).  Saving model ...
Validation loss decreased (1.064486 --> 1.062001).  Saving model ...
Validation loss decreased (1.062001 --> 1.060212).  Saving model ...
Validation loss decreased (1.060212 --> 1.057748).  Saving model ...
Validation loss decreased (1.057748 --> 1.053070).  Saving model ...
Validation loss decreased (1.053070 --> 1.047813).  Saving model ...
Validation loss decreased (1.047813 --> 1.046697).  Saving model ...
Validation loss decreased (1.046697 --> 1.044993).  Saving model ...
Validation loss decreased (1.044993 --> 1.042570).  Saving model ...
Validation loss decreased (1.042570 --> 1.038644).  Saving model ...
Validation loss decreased (1.038644 --> 1.038194).  Saving model ...
Validation loss decreased (1.038194 --> 1.036019).  Saving model ...
Validation loss decreased (1.036019 --> 1.032354).  Saving model ...
Validation loss decreased (1.032354 --> 1.030534).  Saving model ...
Validation loss decreased (1.030534 --> 1.028928).  Saving model ...
Validation loss decreased (1.028928 --> 1.027911).  Saving model ...
Validation loss decreased (1.027911 --> 1.027580).  Saving model ...
Validation loss decreased (1.027580 --> 1.022795).  Saving model ...
Validation loss decreased (1.022795 --> 1.022746).  Saving model ...
EarlyStopping counter: 1 out of 5.0
Validation loss decreased (1.022746 --> 1.020557).  Saving model ...
Validation loss decreased (1.020557 --> 1.018574).  Saving model ...
Validation loss decreased (1.018574 --> 1.017919).  Saving model ...
Validation loss decreased (1.017919 --> 1.015400).  Saving model ...
Validation loss decreased (1.015400 --> 1.014752).  Saving model ...
Validation loss decreased (1.014752 --> 1.012934).  Saving model ...
Validation loss decreased (1.012934 --> 1.012473).  Saving model ...
Validation loss decreased (1.012473 --> 1.011776).  Saving model ...
Validation loss decreased (1.011776 --> 1.008616).  Saving model ...
EarlyStopping counter: 1 out of 5.0
Validation loss decreased (1.008616 --> 1.008611).  Saving model ...
Validation loss decreased (1.008611 --> 1.005590).  Saving model ...
Validation loss decreased (1.005590 --> 1.002794).  Saving model ...
EarlyStopping counter: 1 out of 5.0
EarlyStopping counter: 2 out of 5.0
EarlyStopping counter: 3 out of 5.0
EarlyStopping counter: 4 out of 5.0
Validation loss decreased (1.002794 --> 1.000970).  Saving model ...
EarlyStopping counter: 1 out of 5.0
Validation loss decreased (1.000970 --> 0.997450).  Saving model ...
EarlyStopping counter: 1 out of 5.0
EarlyStopping counter: 2 out of 5.0
Validation loss decreased (0.997450 --> 0.996395).  Saving model ...
EarlyStopping counter: 1 out of 5.0
EarlyStopping counter: 2 out of 5.0
Validation loss decreased (0.996395 --> 0.995306).  Saving model ...
Validation loss decreased (0.995306 --> 0.990373).  Saving model ...
EarlyStopping counter: 1 out of 5.0
EarlyStopping counter: 2 out of 5.0
EarlyStopping counter: 3 out of 5.0
EarlyStopping counter: 4 out of 5.0
Validation loss decreased (0.990373 --> 0.988704).  Saving model ...
EarlyStopping counter: 1 out of 5.0
EarlyStopping counter: 2 out of 5.0
EarlyStopping counter: 3 out of 5.0
EarlyStopping counter: 4 out of 5.0
EarlyStopping counter: 5 out of 5.0
/localscratch/yinan.29161744.0/env/lib/python3.7/site-packages/torch/nn/functional.py:1794: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.
  warnings.warn("nn.functional.tanh is deprecated. Use torch.tanh instead.")
wandb: Waiting for W&B process to finish, PID 226621... (success).
wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: \ 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: | 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: / 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: \ 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: | 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: / 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: \ 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: | 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: / 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: \ 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb:                                                                                
wandb: Run history:
wandb:     e_F1 ▁▁▃▄▄▅▅▅▆▆▆▆▆▆▆▆▇▇▇▇▇▇▇▇▇▇██▇███████████
wandb:   e_loss █▇▇▆▆▆▆▅▅▅▄▄▄▄▃▃▃▃▃▂▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:     t_F1 ▁▂▁▂▃▃▃▄▄▄▄▅▅▅▆▅▆▆▆▆▆▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇█▇██
wandb:   t_loss █▇▇▇▇▇▆▆▆▆▅▅▅▅▄▄▄▄▄▄▃▃▃▃▃▃▃▂▂▂▂▂▂▂▂▂▁▂▁▁
wandb: 
wandb: Run summary:
wandb:     e_F1 56.38883
wandb:   e_loss 0.99496
wandb:     t_F1 66.01421
wandb:   t_loss 0.82647
wandb: 
wandb: Synced 4 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Synced effortless-butterfly-1: https://wandb.ai/yinanazhou/xl_512_bs_8_lr_1e06_es_5_lc_False_nr_True_sr_True_stem_True_lemma_False_repeat_5_fold_2/runs/1li2tyr6
wandb: Find logs at: ./wandb/run-20220318_095612-1li2tyr6/logs/debug.log
wandb: 

