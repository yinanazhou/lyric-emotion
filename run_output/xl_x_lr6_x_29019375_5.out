Unloading StdEnv/2020

Due to MODULEPATH changes, the following have been reloaded:
  1) mii/1.1.1


The following have been reloaded with a version change:
  1) python/3.8.2 => python/3.7.4

Using base prefix '/cvmfs/soft.computecanada.ca/easybuild/software/2017/Core/python/3.7.4'
New python executable in /localscratch/yinan.29201086.0/env/bin/python
Installing setuptools, pip, wheel...
done.
Ignoring pip: markers 'python_version < "3"' don't match your environment
Looking in links: /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/nix/avx2, /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/nix/generic, /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic
Collecting pip
Installing collected packages: pip
  Found existing installation: pip 19.1.1
    Uninstalling pip-19.1.1:
      Successfully uninstalled pip-19.1.1
Successfully installed pip-21.2.3+computecanada
Looking in links: /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/nix/avx2, /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/nix/generic, /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/keras-2.8.0+computecanada-py2.py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/Keras_Preprocessing-1.1.2+computecanada-py3-none-any.whl
Requirement already satisfied: matplotlib in /cvmfs/soft.computecanada.ca/easybuild/software/2017/Core/scipy-stack/2019a/lib/python3.7/site-packages (from -r requirements.txt (line 3)) (3.0.2)
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/nltk-3.6.5+computecanada-py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/scikit_learn-0.22.1+computecanada-cp37-cp37m-linux_x86_64.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/tensorboard-2.3.0+computecanada-py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/tensorboard_plugin_wit-1.7.0+computecanada-py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/tensorflow_gpu-2.3.0+computecanada-cp37-cp37m-linux_x86_64.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/tensorflow_estimator-2.3.0+computecanada-py2.py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/tokenizers-0.5.2+computecanada-cp37-cp37m-linux_x86_64.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/nix/avx2/torch-1.4.0+computecanada-cp37-cp37m-linux_x86_64.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/torchtext-0.6.0+computecanada-py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/torchvision-0.8.2+computecanada-cp37-cp37m-linux_x86_64.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/transformers-2.5.1+computecanada-py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/urllib3-1.26.7+computecanada-py2.py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/joblib-1.1.0+computecanada-py2.py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/click-8.0.4+computecanada-py3-none-any.whl
ERROR: Could not find a version that satisfies the requirement regex>=2021.8.3 (from nltk) (from versions: 2018.1.10+computecanada, 2019.11.1+computecanada, 2020.11.13+computecanada)
ERROR: No matching distribution found for regex>=2021.8.3
Looking in links: /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/nix/avx2, /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/nix/generic, /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic
ERROR: Could not find a version that satisfies the requirement numpy==1.20.0+computacanada (from versions: 1.15.0+computecanada, 1.15.2+computecanada, 1.15.4+computecanada, 1.16.0+computecanada, 1.16.2+computecanada, 1.16.3+computecanada, 1.17.4+computecanada, 1.18.1+computecanada, 1.18.4+computecanada, 1.19.1+computecanada, 1.19.2+computecanada, 1.20.2+computecanada)
ERROR: No matching distribution found for numpy==1.20.0+computacanada
Looking in links: /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/nix/avx2, /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/nix/generic, /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/wandb-0.12.5+computecanada-py2.py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/PyYAML-5.3.1+computecanada-cp37-cp37m-linux_x86_64.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/six-1.16.0+computecanada-py2.py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/yaspin-2.1.0+computecanada-py3-none-any.whl
Requirement already satisfied: requests<3,>=2.0.0 in /cvmfs/soft.computecanada.ca/easybuild/software/2017/Core/scipy-stack/2019a/lib/python3.7/site-packages (from wandb) (2.21.0)
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/psutil-5.7.3+computecanada-cp37-cp37m-linux_x86_64.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/docker_pycreds-0.4.0+computecanada-py2.py3-none-any.whl
Requirement already satisfied: python-dateutil>=2.6.1 in /cvmfs/soft.computecanada.ca/easybuild/software/2017/Core/scipy-stack/2019a/lib/python3.7/site-packages (from wandb) (2.7.5)
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/click-8.0.4+computecanada-py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/protobuf-3.19.4+computecanada-py2.py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/configparser-5.0.2+computecanada-py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/shortuuid-1.0.1+computecanada-py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/pathtools-0.1.2+computecanada-py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/subprocess32-3.5.4+computecanada-py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/sentry_sdk-1.5.0+computecanada-py2.py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/GitPython-3.1.24+computecanada-py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/promise-2.3+computecanada-py3-none-any.whl
Requirement already satisfied: importlib-metadata in /cvmfs/soft.computecanada.ca/easybuild/software/2017/Core/scipy-stack/2019a/lib/python3.7/site-packages (from Click!=8.0.0,>=7.0->wandb) (0.8)
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/gitdb-4.0.9+computecanada-py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/typing_extensions-4.0.1+computecanada-py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/smmap-5.0.0+computecanada-py3-none-any.whl
Requirement already satisfied: idna<2.9,>=2.5 in /cvmfs/soft.computecanada.ca/easybuild/software/2017/Core/scipy-stack/2019a/lib/python3.7/site-packages (from requests<3,>=2.0.0->wandb) (2.8)
Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /cvmfs/soft.computecanada.ca/easybuild/software/2017/Core/scipy-stack/2019a/lib/python3.7/site-packages (from requests<3,>=2.0.0->wandb) (3.0.4)
Requirement already satisfied: urllib3<1.25,>=1.21.1 in /cvmfs/soft.computecanada.ca/easybuild/software/2017/Core/scipy-stack/2019a/lib/python3.7/site-packages (from requests<3,>=2.0.0->wandb) (1.24.1)
Requirement already satisfied: certifi>=2017.4.17 in /cvmfs/soft.computecanada.ca/easybuild/software/2017/Core/scipy-stack/2019a/lib/python3.7/site-packages (from requests<3,>=2.0.0->wandb) (2018.11.29)
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/termcolor-1.1.0+computecanada-py3-none-any.whl
Requirement already satisfied: zipp>=0.3.2 in /cvmfs/soft.computecanada.ca/easybuild/software/2017/Core/scipy-stack/2019a/lib/python3.7/site-packages (from importlib-metadata->Click!=8.0.0,>=7.0->wandb) (0.3.3)
Installing collected packages: smmap, typing-extensions, termcolor, six, gitdb, yaspin, subprocess32, shortuuid, sentry-sdk, PyYAML, psutil, protobuf, promise, pathtools, GitPython, docker-pycreds, configparser, Click, wandb
  Attempting uninstall: six
    Found existing installation: six 1.12.0
    Not uninstalling six at /cvmfs/soft.computecanada.ca/easybuild/software/2017/Core/scipy-stack/2019a/lib/python3.7/site-packages, outside environment /localscratch/yinan.29201086.0/env
    Can't uninstall 'six'. No files were found to uninstall.
Successfully installed Click-8.0.4+computecanada GitPython-3.1.24+computecanada PyYAML-5.3.1+computecanada configparser-5.0.2+computecanada docker-pycreds-0.4.0+computecanada gitdb-4.0.9+computecanada pathtools-0.1.2+computecanada promise-2.3+computecanada protobuf-3.19.4+computecanada psutil-5.7.3+computecanada sentry-sdk-1.5.0+computecanada shortuuid-1.0.1+computecanada six-1.16.0+computecanada smmap-5.0.0+computecanada subprocess32-3.5.4+computecanada termcolor-1.1.0+computecanada typing-extensions-4.0.1+computecanada wandb-0.12.5+computecanada yaspin-2.1.0+computecanada
Looking in links: /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/nix/avx2, /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/nix/generic, /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic
ERROR: Could not find a version that satisfies the requirement sagemaker (from versions: none)
ERROR: No matching distribution found for sagemaker
Looking in links: /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/nix/avx2, /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/nix/generic, /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/torch-1.9.1+computecanada-cp37-cp37m-linux_x86_64.whl
Requirement already satisfied: typing-extensions in /localscratch/yinan.29201086.0/env/lib/python3.7/site-packages (from torch) (4.0.1+computecanada)
Installing collected packages: torch
Successfully installed torch-1.9.1+computecanada
Looking in links: /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/nix/avx2, /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/nix/generic, /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/transformers-2.5.1+computecanada-py3-none-any.whl
Requirement already satisfied: requests in /cvmfs/soft.computecanada.ca/easybuild/software/2017/Core/scipy-stack/2019a/lib/python3.7/site-packages (from transformers==2.5.1+computecanada) (2.21.0)
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/boto3-1.21.14+computecanada-py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/filelock-3.4.2+computecanada-py3-none-any.whl
Requirement already satisfied: numpy in /cvmfs/soft.computecanada.ca/easybuild/software/2017/Core/scipy-stack/2019a/lib/python3.7/site-packages (from transformers==2.5.1+computecanada) (1.16.0)
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/tqdm-4.63.0+computecanada-py2.py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/sacremoses-0.0.46+computecanada-py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/sentencepiece-0.1.91+computecanada-cp37-cp37m-linux_x86_64.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/regex-2020.11.13+computecanada-cp37-cp37m-linux_x86_64.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/tokenizers-0.5.2+computecanada-cp37-cp37m-linux_x86_64.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/s3transfer-0.5.1+computecanada-py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/botocore-1.24.14+computecanada-py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/jmespath-0.10.0+computecanada-py2.py3-none-any.whl
Requirement already satisfied: python-dateutil<3.0.0,>=2.1 in /cvmfs/soft.computecanada.ca/easybuild/software/2017/Core/scipy-stack/2019a/lib/python3.7/site-packages (from botocore<1.25.0,>=1.24.14->boto3->transformers==2.5.1+computecanada) (2.7.5)
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/urllib3-1.26.8+computecanada-py2.py3-none-any.whl
Requirement already satisfied: six>=1.5 in /localscratch/yinan.29201086.0/env/lib/python3.7/site-packages (from python-dateutil<3.0.0,>=2.1->botocore<1.25.0,>=1.24.14->boto3->transformers==2.5.1+computecanada) (1.16.0+computecanada)
Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /cvmfs/soft.computecanada.ca/easybuild/software/2017/Core/scipy-stack/2019a/lib/python3.7/site-packages (from requests->transformers==2.5.1+computecanada) (3.0.4)
Requirement already satisfied: certifi>=2017.4.17 in /cvmfs/soft.computecanada.ca/easybuild/software/2017/Core/scipy-stack/2019a/lib/python3.7/site-packages (from requests->transformers==2.5.1+computecanada) (2018.11.29)
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/requests-2.27.1+computecanada-py2.py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/charset_normalizer-2.0.12+computecanada-py3-none-any.whl
Requirement already satisfied: idna<4,>=2.5 in /cvmfs/soft.computecanada.ca/easybuild/software/2017/Core/scipy-stack/2019a/lib/python3.7/site-packages (from requests->transformers==2.5.1+computecanada) (2.8)
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/joblib-1.1.0+computecanada-py2.py3-none-any.whl
Requirement already satisfied: click in /localscratch/yinan.29201086.0/env/lib/python3.7/site-packages (from sacremoses->transformers==2.5.1+computecanada) (8.0.4+computecanada)
Requirement already satisfied: importlib-metadata in /cvmfs/soft.computecanada.ca/easybuild/software/2017/Core/scipy-stack/2019a/lib/python3.7/site-packages (from click->sacremoses->transformers==2.5.1+computecanada) (0.8)
Requirement already satisfied: zipp>=0.3.2 in /cvmfs/soft.computecanada.ca/easybuild/software/2017/Core/scipy-stack/2019a/lib/python3.7/site-packages (from importlib-metadata->click->sacremoses->transformers==2.5.1+computecanada) (0.3.3)
Installing collected packages: urllib3, jmespath, botocore, tqdm, s3transfer, regex, joblib, charset-normalizer, tokenizers, sentencepiece, sacremoses, requests, filelock, boto3, transformers
  Attempting uninstall: urllib3
    Found existing installation: urllib3 1.24.1
    Not uninstalling urllib3 at /cvmfs/soft.computecanada.ca/easybuild/software/2017/Core/scipy-stack/2019a/lib/python3.7/site-packages, outside environment /localscratch/yinan.29201086.0/env
    Can't uninstall 'urllib3'. No files were found to uninstall.
  Attempting uninstall: requests
    Found existing installation: requests 2.21.0
    Not uninstalling requests at /cvmfs/soft.computecanada.ca/easybuild/software/2017/Core/scipy-stack/2019a/lib/python3.7/site-packages, outside environment /localscratch/yinan.29201086.0/env
    Can't uninstall 'requests'. No files were found to uninstall.
Successfully installed boto3-1.21.14+computecanada botocore-1.24.14+computecanada charset-normalizer-2.0.12+computecanada filelock-3.4.2+computecanada jmespath-0.10.0+computecanada joblib-1.1.0+computecanada regex-2020.11.13+computecanada requests-2.27.1+computecanada s3transfer-0.5.1+computecanada sacremoses-0.0.46+computecanada sentencepiece-0.1.91+computecanada tokenizers-0.5.2+computecanada tqdm-4.63.0+computecanada transformers-2.5.1+computecanada urllib3-1.26.8+computecanada
Looking in links: /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/nix/avx2, /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/nix/generic, /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/tensorflow_gpu-2.3.0+computecanada-cp37-cp37m-linux_x86_64.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/nix/generic/scipy-1.4.1+computecanada-cp37-cp37m-linux_x86_64.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/Keras_Preprocessing-1.1.2+computecanada-py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/astunparse-1.6.3+computecanada-py2.py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/grpcio-1.38.0+computecanada-cp37-cp37m-linux_x86_64.whl
Requirement already satisfied: wheel>=0.26 in /localscratch/yinan.29201086.0/env/lib/python3.7/site-packages (from tensorflow_gpu==2.3.0+computecanada) (0.33.4)
Requirement already satisfied: six>=1.12.0 in /localscratch/yinan.29201086.0/env/lib/python3.7/site-packages (from tensorflow_gpu==2.3.0+computecanada) (1.16.0+computecanada)
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/tensorflow_estimator-2.3.0+computecanada-py2.py3-none-any.whl
Requirement already satisfied: termcolor>=1.1.0 in /localscratch/yinan.29201086.0/env/lib/python3.7/site-packages (from tensorflow_gpu==2.3.0+computecanada) (1.1.0+computecanada)
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/tensorboard-2.8.0+computecanada-py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/nix/avx2/h5py-2.10.0+computecanada-cp37-cp37m-linux_x86_64.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/absl_py-1.0.0+computecanada-py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/gast-0.3.3+computecanada-py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/google_pasta-0.2.0+computecanada-py3-none-any.whl
Requirement already satisfied: numpy<1.19.0,>=1.16.0 in /cvmfs/soft.computecanada.ca/easybuild/software/2017/Core/scipy-stack/2019a/lib/python3.7/site-packages (from tensorflow_gpu==2.3.0+computecanada) (1.16.0)
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/opt_einsum-3.3.0+computecanada-py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/wrapt-1.11.2+computecanada-cp37-cp37m-linux_x86_64.whl
Requirement already satisfied: protobuf>=3.9.2 in /localscratch/yinan.29201086.0/env/lib/python3.7/site-packages (from tensorflow_gpu==2.3.0+computecanada) (3.19.4+computecanada)
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/google_auth_oauthlib-0.4.6+computecanada-py2.py3-none-any.whl
Requirement already satisfied: setuptools>=41.0.0 in /localscratch/yinan.29201086.0/env/lib/python3.7/site-packages (from tensorboard<3,>=2.3.0->tensorflow_gpu==2.3.0+computecanada) (41.0.1)
Requirement already satisfied: requests<3,>=2.21.0 in /localscratch/yinan.29201086.0/env/lib/python3.7/site-packages (from tensorboard<3,>=2.3.0->tensorflow_gpu==2.3.0+computecanada) (2.27.1+computecanada)
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/Werkzeug-2.0.3+computecanada-py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/tensorboard_plugin_wit-1.8.0+computecanada-py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/tensorboard_data_server-0.6.1+computecanada-py3-none-linux_x86_64.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/google_auth-2.3.3+computecanada-py2.py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/Markdown-3.3.6+computecanada-py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/rsa-4.8+computecanada-py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/cachetools-4.2.4+computecanada-py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/pyasn1_modules-0.2.8+computecanada-py2.py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/requests_oauthlib-1.3.0+computecanada-py2.py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/importlib_metadata-4.10.1+computecanada-py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/zipp-3.7.0+computecanada-py3-none-any.whl
Requirement already satisfied: typing-extensions>=3.6.4 in /localscratch/yinan.29201086.0/env/lib/python3.7/site-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard<3,>=2.3.0->tensorflow_gpu==2.3.0+computecanada) (4.0.1+computecanada)
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/pyasn1-0.4.8+computecanada-py2.py3-none-any.whl
Requirement already satisfied: urllib3<1.27,>=1.21.1 in /localscratch/yinan.29201086.0/env/lib/python3.7/site-packages (from requests<3,>=2.21.0->tensorboard<3,>=2.3.0->tensorflow_gpu==2.3.0+computecanada) (1.26.8+computecanada)
Requirement already satisfied: charset-normalizer~=2.0.0 in /localscratch/yinan.29201086.0/env/lib/python3.7/site-packages (from requests<3,>=2.21.0->tensorboard<3,>=2.3.0->tensorflow_gpu==2.3.0+computecanada) (2.0.12+computecanada)
Requirement already satisfied: certifi>=2017.4.17 in /cvmfs/soft.computecanada.ca/easybuild/software/2017/Core/scipy-stack/2019a/lib/python3.7/site-packages (from requests<3,>=2.21.0->tensorboard<3,>=2.3.0->tensorflow_gpu==2.3.0+computecanada) (2018.11.29)
Requirement already satisfied: idna<4,>=2.5 in /cvmfs/soft.computecanada.ca/easybuild/software/2017/Core/scipy-stack/2019a/lib/python3.7/site-packages (from requests<3,>=2.21.0->tensorboard<3,>=2.3.0->tensorflow_gpu==2.3.0+computecanada) (2.8)
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/oauthlib-3.1.1+computecanada-py2.py3-none-any.whl
Installing collected packages: pyasn1, zipp, rsa, pyasn1-modules, oauthlib, cachetools, requests-oauthlib, importlib-metadata, google-auth, werkzeug, tensorboard-plugin-wit, tensorboard-data-server, markdown, grpcio, google-auth-oauthlib, absl-py, wrapt, tensorflow-estimator, tensorboard, scipy, opt-einsum, keras-preprocessing, h5py, google-pasta, gast, astunparse, tensorflow-gpu
  Attempting uninstall: pyasn1
    Found existing installation: pyasn1 0.4.3
    Not uninstalling pyasn1 at /cvmfs/soft.computecanada.ca/easybuild/software/2017/Core/scipy-stack/2019a/lib/python3.7/site-packages, outside environment /localscratch/yinan.29201086.0/env
    Can't uninstall 'pyasn1'. No files were found to uninstall.
  Attempting uninstall: zipp
    Found existing installation: zipp 0.3.3
    Not uninstalling zipp at /cvmfs/soft.computecanada.ca/easybuild/software/2017/Core/scipy-stack/2019a/lib/python3.7/site-packages, outside environment /localscratch/yinan.29201086.0/env
    Can't uninstall 'zipp'. No files were found to uninstall.
  Attempting uninstall: importlib-metadata
    Found existing installation: importlib-metadata 0.8
    Not uninstalling importlib-metadata at /cvmfs/soft.computecanada.ca/easybuild/software/2017/Core/scipy-stack/2019a/lib/python3.7/site-packages, outside environment /localscratch/yinan.29201086.0/env
    Can't uninstall 'importlib-metadata'. No files were found to uninstall.
  Attempting uninstall: scipy
    Found existing installation: scipy 1.2.0
    Not uninstalling scipy at /cvmfs/soft.computecanada.ca/easybuild/software/2017/Core/scipy-stack/2019a/lib/python3.7/site-packages, outside environment /localscratch/yinan.29201086.0/env
    Can't uninstall 'scipy'. No files were found to uninstall.
Successfully installed absl-py-1.0.0+computecanada astunparse-1.6.3+computecanada cachetools-4.2.4+computecanada gast-0.3.3+computecanada google-auth-2.3.3+computecanada google-auth-oauthlib-0.4.6+computecanada google-pasta-0.2.0+computecanada grpcio-1.38.0+computecanada h5py-2.10.0+computecanada importlib-metadata-4.10.1+computecanada keras-preprocessing-1.1.2+computecanada markdown-3.3.6+computecanada oauthlib-3.1.1+computecanada opt-einsum-3.3.0+computecanada pyasn1-0.4.8+computecanada pyasn1-modules-0.2.8+computecanada requests-oauthlib-1.3.0+computecanada rsa-4.8+computecanada scipy-1.4.1+computecanada tensorboard-2.8.0+computecanada tensorboard-data-server-0.6.1+computecanada tensorboard-plugin-wit-1.8.0+computecanada tensorflow-estimator-2.3.0+computecanada tensorflow-gpu-2.3.0+computecanada werkzeug-2.0.3+computecanada wrapt-1.11.2+computecanada zipp-3.7.0+computecanada
Looking in links: /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/nix/avx2, /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/nix/generic, /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/keras-2.8.0+computecanada-py2.py3-none-any.whl
Installing collected packages: Keras
Successfully installed Keras-2.8.0+computecanada
Looking in links: /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/nix/avx2, /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/nix/generic, /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/urllib3-1.26.7+computecanada-py2.py3-none-any.whl
Installing collected packages: urllib3
  Attempting uninstall: urllib3
    Found existing installation: urllib3 1.26.8+computecanada
    Uninstalling urllib3-1.26.8+computecanada:
      Successfully uninstalled urllib3-1.26.8+computecanada
Successfully installed urllib3-1.26.7+computecanada
Looking in links: /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/nix/avx2, /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/nix/generic, /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/nltk-3.7+computecanada-py3-none-any.whl
Requirement already satisfied: tqdm in /localscratch/yinan.29201086.0/env/lib/python3.7/site-packages (from nltk) (4.63.0+computecanada)
Requirement already satisfied: click in /localscratch/yinan.29201086.0/env/lib/python3.7/site-packages (from nltk) (8.0.4+computecanada)
Requirement already satisfied: joblib in /localscratch/yinan.29201086.0/env/lib/python3.7/site-packages (from nltk) (1.1.0+computecanada)
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/nltk-3.6.5+computecanada-py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/nltk-3.6.3+computecanada-py3-none-any.whl
Requirement already satisfied: regex in /localscratch/yinan.29201086.0/env/lib/python3.7/site-packages (from nltk) (2020.11.13+computecanada)
Requirement already satisfied: importlib-metadata in /localscratch/yinan.29201086.0/env/lib/python3.7/site-packages (from click->nltk) (4.10.1+computecanada)
Requirement already satisfied: zipp>=0.5 in /localscratch/yinan.29201086.0/env/lib/python3.7/site-packages (from importlib-metadata->click->nltk) (3.7.0+computecanada)
Requirement already satisfied: typing-extensions>=3.6.4 in /localscratch/yinan.29201086.0/env/lib/python3.7/site-packages (from importlib-metadata->click->nltk) (4.0.1+computecanada)
Installing collected packages: nltk
Successfully installed nltk-3.6.3+computecanada
Looking in links: /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/nix/avx2, /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/nix/generic, /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/scikit_learn-0.22.1+computecanada-cp37-cp37m-linux_x86_64.whl
Requirement already satisfied: joblib>=0.11 in /localscratch/yinan.29201086.0/env/lib/python3.7/site-packages (from scikit-learn==0.22.1) (1.1.0+computecanada)
Requirement already satisfied: scipy>=0.17.0 in /localscratch/yinan.29201086.0/env/lib/python3.7/site-packages (from scikit-learn==0.22.1) (1.4.1+computecanada)
Requirement already satisfied: numpy>=1.11.0 in /cvmfs/soft.computecanada.ca/easybuild/software/2017/Core/scipy-stack/2019a/lib/python3.7/site-packages (from scikit-learn==0.22.1) (1.16.0)
Installing collected packages: scikit-learn
Successfully installed scikit-learn-0.22.1+computecanada
Looking in links: /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/nix/avx2, /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/nix/generic, /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic
Requirement already satisfied: tokenizers==0.5.2 in /localscratch/yinan.29201086.0/env/lib/python3.7/site-packages (0.5.2+computecanada)
wandb: Appending key for api.wandb.ai to your netrc file: /home/yinan/.netrc
Starting Task
2022-03-18 20:18:41.671718: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1
[nltk_data] Downloading package stopwords to /home/yinan/nltk_data...
[nltk_data]   Package stopwords is already up-to-date!
[nltk_data] Downloading package wordnet to /home/yinan/nltk_data...
[nltk_data]   Package wordnet is already up-to-date!
wandb: Currently logged in as: yinanazhou (use `wandb login --relogin` to force relogin)
wandb: wandb version 0.12.11 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
2022-03-18 20:18:51.271016: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1
wandb: Tracking run with wandb version 0.12.5
wandb: Syncing run youthful-wildflower-2
wandb: ⭐️ View project at https://wandb.ai/yinanazhou/xl_512_bs_8_lr_1e06_es_5_lc_False_nr_False_sr_False_stem_False_lemma_False_repeat_1_fold_1
wandb: 🚀 View run at https://wandb.ai/yinanazhou/xl_512_bs_8_lr_1e06_es_5_lc_False_nr_False_sr_False_stem_False_lemma_False_repeat_1_fold_1/runs/1z2k8cod
wandb: Run data is saved locally in /project/6002780/yinan/Thesis_MER_Lyrics/lyric-emotion/wandb/run-20220318_201849-1z2k8cod
wandb: Run `wandb offline` to turn off syncing.

Validation loss decreased (inf --> 1.432649).  Saving model ...
Validation loss decreased (1.432649 --> 1.413243).  Saving model ...
Validation loss decreased (1.413243 --> 1.396893).  Saving model ...
Validation loss decreased (1.396893 --> 1.383810).  Saving model ...
Validation loss decreased (1.383810 --> 1.373484).  Saving model ...
Validation loss decreased (1.373484 --> 1.365146).  Saving model ...
Validation loss decreased (1.365146 --> 1.357312).  Saving model ...
Validation loss decreased (1.357312 --> 1.350908).  Saving model ...
Validation loss decreased (1.350908 --> 1.345829).  Saving model ...
Validation loss decreased (1.345829 --> 1.339794).  Saving model ...
Validation loss decreased (1.339794 --> 1.333172).  Saving model ...
Validation loss decreased (1.333172 --> 1.327449).  Saving model ...
Validation loss decreased (1.327449 --> 1.320892).  Saving model ...
Validation loss decreased (1.320892 --> 1.315636).  Saving model ...
Validation loss decreased (1.315636 --> 1.309583).  Saving model ...
Validation loss decreased (1.309583 --> 1.302805).  Saving model ...
Validation loss decreased (1.302805 --> 1.296959).  Saving model ...
Validation loss decreased (1.296959 --> 1.291311).  Saving model ...
Validation loss decreased (1.291311 --> 1.284247).  Saving model ...
Validation loss decreased (1.284247 --> 1.275604).  Saving model ...
Validation loss decreased (1.275604 --> 1.268060).  Saving model ...
Validation loss decreased (1.268060 --> 1.260894).  Saving model ...
Validation loss decreased (1.260894 --> 1.255024).  Saving model ...
Validation loss decreased (1.255024 --> 1.245388).  Saving model ...
Validation loss decreased (1.245388 --> 1.236527).  Saving model ...
Validation loss decreased (1.236527 --> 1.228766).  Saving model ...
Validation loss decreased (1.228766 --> 1.221822).  Saving model ...
Validation loss decreased (1.221822 --> 1.215460).  Saving model ...
Validation loss decreased (1.215460 --> 1.208375).  Saving model ...
Validation loss decreased (1.208375 --> 1.202478).  Saving model ...
Validation loss decreased (1.202478 --> 1.195194).  Saving model ...
Validation loss decreased (1.195194 --> 1.190426).  Saving model ...
Validation loss decreased (1.190426 --> 1.188564).  Saving model ...
Validation loss decreased (1.188564 --> 1.181541).  Saving model ...
Validation loss decreased (1.181541 --> 1.174907).  Saving model ...
Validation loss decreased (1.174907 --> 1.169635).  Saving model ...
Validation loss decreased (1.169635 --> 1.167549).  Saving model ...
Validation loss decreased (1.167549 --> 1.159069).  Saving model ...
Validation loss decreased (1.159069 --> 1.155852).  Saving model ...
Validation loss decreased (1.155852 --> 1.150329).  Saving model ...
Validation loss decreased (1.150329 --> 1.144300).  Saving model ...
Validation loss decreased (1.144300 --> 1.139620).  Saving model ...
Validation loss decreased (1.139620 --> 1.136095).  Saving model ...
Validation loss decreased (1.136095 --> 1.131987).  Saving model ...
Validation loss decreased (1.131987 --> 1.128156).  Saving model ...
Validation loss decreased (1.128156 --> 1.122394).  Saving model ...
Validation loss decreased (1.122394 --> 1.118459).  Saving model ...
Validation loss decreased (1.118459 --> 1.114139).  Saving model ...
Validation loss decreased (1.114139 --> 1.108813).  Saving model ...
Validation loss decreased (1.108813 --> 1.106998).  Saving model ...
Validation loss decreased (1.106998 --> 1.100536).  Saving model ...
Validation loss decreased (1.100536 --> 1.097067).  Saving model ...
Validation loss decreased (1.097067 --> 1.094954).  Saving model ...
Validation loss decreased (1.094954 --> 1.090739).  Saving model ...
Validation loss decreased (1.090739 --> 1.090494).  Saving model ...
Validation loss decreased (1.090494 --> 1.086035).  Saving model ...
Validation loss decreased (1.086035 --> 1.082550).  Saving model ...
Validation loss decreased (1.082550 --> 1.079738).  Saving model ...
Validation loss decreased (1.079738 --> 1.076174).  Saving model ...
Validation loss decreased (1.076174 --> 1.071831).  Saving model ...
Validation loss decreased (1.071831 --> 1.068904).  Saving model ...
Validation loss decreased (1.068904 --> 1.066291).  Saving model ...
Validation loss decreased (1.066291 --> 1.063490).  Saving model ...
Validation loss decreased (1.063490 --> 1.061816).  Saving model ...
EarlyStopping counter: 1 out of 5.0
Validation loss decreased (1.061816 --> 1.058415).  Saving model ...
Validation loss decreased (1.058415 --> 1.054562).  Saving model ...
Validation loss decreased (1.054562 --> 1.054312).  Saving model ...
Validation loss decreased (1.054312 --> 1.051142).  Saving model ...
Validation loss decreased (1.051142 --> 1.046887).  Saving model ...
Validation loss decreased (1.046887 --> 1.045249).  Saving model ...
Validation loss decreased (1.045249 --> 1.042753).  Saving model ...
Validation loss decreased (1.042753 --> 1.042324).  Saving model ...
Validation loss decreased (1.042324 --> 1.037681).  Saving model ...
Validation loss decreased (1.037681 --> 1.037470).  Saving model ...
Validation loss decreased (1.037470 --> 1.035747).  Saving model ...
Validation loss decreased (1.035747 --> 1.035413).  Saving model ...
Validation loss decreased (1.035413 --> 1.031903).  Saving model ...
Validation loss decreased (1.031903 --> 1.030121).  Saving model ...
Validation loss decreased (1.030121 --> 1.026242).  Saving model ...
EarlyStopping counter: 1 out of 5.0
Validation loss decreased (1.026242 --> 1.023637).  Saving model ...
EarlyStopping counter: 1 out of 5.0
Validation loss decreased (1.023637 --> 1.020683).  Saving model ...
Validation loss decreased (1.020683 --> 1.020144).  Saving model ...
Validation loss decreased (1.020144 --> 1.016497).  Saving model ...
Validation loss decreased (1.016497 --> 1.016310).  Saving model ...
EarlyStopping counter: 1 out of 5.0
Validation loss decreased (1.016310 --> 1.014816).  Saving model ...
EarlyStopping counter: 1 out of 5.0
Validation loss decreased (1.014816 --> 1.012580).  Saving model ...
Validation loss decreased (1.012580 --> 1.011412).  Saving model ...
Validation loss decreased (1.011412 --> 1.008186).  Saving model ...
EarlyStopping counter: 1 out of 5.0
EarlyStopping counter: 2 out of 5.0
Validation loss decreased (1.008186 --> 1.006308).  Saving model ...
EarlyStopping counter: 1 out of 5.0
Validation loss decreased (1.006308 --> 1.006186).  Saving model ...
Validation loss decreased (1.006186 --> 1.005985).  Saving model ...
EarlyStopping counter: 1 out of 5.0
Validation loss decreased (1.005985 --> 1.004365).  Saving model ...
Validation loss decreased (1.004365 --> 1.003041).  Saving model ...
Validation loss decreased (1.003041 --> 1.002498).  Saving model ...
EarlyStopping counter: 1 out of 5.0
Validation loss decreased (1.002498 --> 1.002447).  Saving model ...
Validation loss decreased (1.002447 --> 1.001717).  Saving model ...
EarlyStopping counter: 1 out of 5.0
Validation loss decreased (1.001717 --> 1.000461).  Saving model ...
Validation loss decreased (1.000461 --> 0.996587).  Saving model ...
Validation loss decreased (0.996587 --> 0.995678).  Saving model ...
EarlyStopping counter: 1 out of 5.0
Validation loss decreased (0.995678 --> 0.995502).  Saving model ...
Validation loss decreased (0.995502 --> 0.994498).  Saving model ...
EarlyStopping counter: 1 out of 5.0
EarlyStopping counter: 2 out of 5.0
Validation loss decreased (0.994498 --> 0.993227).  Saving model ...
Validation loss decreased (0.993227 --> 0.992971).  Saving model ...
EarlyStopping counter: 1 out of 5.0
EarlyStopping counter: 2 out of 5.0
EarlyStopping counter: 3 out of 5.0
EarlyStopping counter: 4 out of 5.0
EarlyStopping counter: 5 out of 5.0
/localscratch/yinan.29201086.0/env/lib/python3.7/site-packages/torch/nn/functional.py:1794: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.
  warnings.warn("nn.functional.tanh is deprecated. Use torch.tanh instead.")
/localscratch/yinan.29201086.0/env/lib/python3.7/site-packages/transformers/optimization.py:155: UserWarning: This overload of add_ is deprecated:
	add_(Number alpha, Tensor other)
Consider using one of the following signatures instead:
	add_(Tensor other, *, Number alpha) (Triggered internally at  ../torch/csrc/utils/python_arg_parser.cpp:1025.)
  exp_avg.mul_(beta1).add_(1.0 - beta1, grad)
wandb: Waiting for W&B process to finish, PID 151665... (success).
wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: \ 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: | 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: / 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: \ 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: | 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: / 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: \ 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: | 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: / 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: \ 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb:                                                                                
wandb: Run history:
wandb:     e_F1 ▁▂▃▄▅▅▅▅▆▆▆▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇██████████████
wandb:   e_loss █▇▇▇▆▆▆▅▅▅▄▄▄▃▃▃▃▃▂▂▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:     t_F1 ▁▂▃▂▃▃▄▄▅▅▅▆▆▆▆▆▆▆▆▇▇▇▇▇▇▇▇▇▇▇▇█▇███▇███
wandb:   t_loss █▇▇▇▇▇▆▆▆▆▅▅▅▄▄▄▄▄▄▃▃▃▃▃▃▂▃▃▂▂▂▂▂▂▁▁▂▁▁▁
wandb: 
wandb: Run summary:
wandb:     e_F1 58.40983
wandb:   e_loss 0.99397
wandb:     t_F1 70.90172
wandb:   t_loss 0.7724
wandb: 
wandb: Synced 4 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Synced youthful-wildflower-2: https://wandb.ai/yinanazhou/xl_512_bs_8_lr_1e06_es_5_lc_False_nr_False_sr_False_stem_False_lemma_False_repeat_1_fold_1/runs/1z2k8cod
wandb: Find logs at: ./wandb/run-20220318_201849-1z2k8cod/logs/debug.log
wandb: 

wandb: wandb version 0.12.11 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
2022-03-18 21:37:22.648460: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1
wandb: Tracking run with wandb version 0.12.5
wandb: Syncing run swept-spaceship-2
wandb: ⭐️ View project at https://wandb.ai/yinanazhou/xl_512_bs_8_lr_1e06_es_5_lc_False_nr_False_sr_False_stem_False_lemma_False_repeat_1_fold_2
wandb: 🚀 View run at https://wandb.ai/yinanazhou/xl_512_bs_8_lr_1e06_es_5_lc_False_nr_False_sr_False_stem_False_lemma_False_repeat_1_fold_2/runs/1y6f41pv
wandb: Run data is saved locally in /project/6002780/yinan/Thesis_MER_Lyrics/lyric-emotion/wandb/run-20220318_213720-1y6f41pv
wandb: Run `wandb offline` to turn off syncing.

Validation loss decreased (inf --> 1.418162).  Saving model ...
Validation loss decreased (1.418162 --> 1.399481).  Saving model ...
Validation loss decreased (1.399481 --> 1.385487).  Saving model ...
Validation loss decreased (1.385487 --> 1.374983).  Saving model ...
Validation loss decreased (1.374983 --> 1.366554).  Saving model ...
Validation loss decreased (1.366554 --> 1.359715).  Saving model ...
Validation loss decreased (1.359715 --> 1.354030).  Saving model ...
Validation loss decreased (1.354030 --> 1.348799).  Saving model ...
Validation loss decreased (1.348799 --> 1.343297).  Saving model ...
Validation loss decreased (1.343297 --> 1.338438).  Saving model ...
Validation loss decreased (1.338438 --> 1.333782).  Saving model ...
Validation loss decreased (1.333782 --> 1.328496).  Saving model ...
Validation loss decreased (1.328496 --> 1.323619).  Saving model ...
Validation loss decreased (1.323619 --> 1.318510).  Saving model ...
Validation loss decreased (1.318510 --> 1.313876).  Saving model ...
Validation loss decreased (1.313876 --> 1.309214).  Saving model ...
Validation loss decreased (1.309214 --> 1.303848).  Saving model ...
Validation loss decreased (1.303848 --> 1.298445).  Saving model ...
Validation loss decreased (1.298445 --> 1.292462).  Saving model ...
Validation loss decreased (1.292462 --> 1.286210).  Saving model ...
Validation loss decreased (1.286210 --> 1.280264).  Saving model ...
Validation loss decreased (1.280264 --> 1.274149).  Saving model ...
Validation loss decreased (1.274149 --> 1.267784).  Saving model ...
Validation loss decreased (1.267784 --> 1.261019).  Saving model ...
Validation loss decreased (1.261019 --> 1.254394).  Saving model ...
Validation loss decreased (1.254394 --> 1.248315).  Saving model ...
Validation loss decreased (1.248315 --> 1.241825).  Saving model ...
Validation loss decreased (1.241825 --> 1.234582).  Saving model ...
Validation loss decreased (1.234582 --> 1.227797).  Saving model ...
Validation loss decreased (1.227797 --> 1.220173).  Saving model ...
Validation loss decreased (1.220173 --> 1.214833).  Saving model ...
Validation loss decreased (1.214833 --> 1.207186).  Saving model ...
Validation loss decreased (1.207186 --> 1.199112).  Saving model ...
Validation loss decreased (1.199112 --> 1.189993).  Saving model ...
Validation loss decreased (1.189993 --> 1.181882).  Saving model ...
Validation loss decreased (1.181882 --> 1.173786).  Saving model ...
Validation loss decreased (1.173786 --> 1.165610).  Saving model ...
Validation loss decreased (1.165610 --> 1.158787).  Saving model ...
Validation loss decreased (1.158787 --> 1.151317).  Saving model ...
Validation loss decreased (1.151317 --> 1.143381).  Saving model ...
Validation loss decreased (1.143381 --> 1.137685).  Saving model ...
Validation loss decreased (1.137685 --> 1.131328).  Saving model ...
Validation loss decreased (1.131328 --> 1.124434).  Saving model ...
Validation loss decreased (1.124434 --> 1.117550).  Saving model ...
Validation loss decreased (1.117550 --> 1.111403).  Saving model ...
Validation loss decreased (1.111403 --> 1.103404).  Saving model ...
Validation loss decreased (1.103404 --> 1.097187).  Saving model ...
Validation loss decreased (1.097187 --> 1.091354).  Saving model ...
Validation loss decreased (1.091354 --> 1.086421).  Saving model ...
Validation loss decreased (1.086421 --> 1.082297).  Saving model ...
Validation loss decreased (1.082297 --> 1.075303).  Saving model ...
Validation loss decreased (1.075303 --> 1.072224).  Saving model ...
Validation loss decreased (1.072224 --> 1.068357).  Saving model ...
Validation loss decreased (1.068357 --> 1.061508).  Saving model ...
Validation loss decreased (1.061508 --> 1.056303).  Saving model ...
Validation loss decreased (1.056303 --> 1.053358).  Saving model ...
Validation loss decreased (1.053358 --> 1.047860).  Saving model ...
Validation loss decreased (1.047860 --> 1.045350).  Saving model ...
Validation loss decreased (1.045350 --> 1.040423).  Saving model ...
Validation loss decreased (1.040423 --> 1.035950).  Saving model ...
Validation loss decreased (1.035950 --> 1.030786).  Saving model ...
Validation loss decreased (1.030786 --> 1.026056).  Saving model ...
Validation loss decreased (1.026056 --> 1.022958).  Saving model ...
Validation loss decreased (1.022958 --> 1.018788).  Saving model ...
Validation loss decreased (1.018788 --> 1.015647).  Saving model ...
Validation loss decreased (1.015647 --> 1.011837).  Saving model ...
Validation loss decreased (1.011837 --> 1.009012).  Saving model ...
Validation loss decreased (1.009012 --> 1.004930).  Saving model ...
Validation loss decreased (1.004930 --> 1.001586).  Saving model ...
Validation loss decreased (1.001586 --> 0.998829).  Saving model ...
Validation loss decreased (0.998829 --> 0.995958).  Saving model ...
Validation loss decreased (0.995958 --> 0.993248).  Saving model ...
Validation loss decreased (0.993248 --> 0.990483).  Saving model ...
Validation loss decreased (0.990483 --> 0.988729).  Saving model ...
Validation loss decreased (0.988729 --> 0.985817).  Saving model ...
Validation loss decreased (0.985817 --> 0.984356).  Saving model ...
Validation loss decreased (0.984356 --> 0.982136).  Saving model ...
Validation loss decreased (0.982136 --> 0.977677).  Saving model ...
Validation loss decreased (0.977677 --> 0.974524).  Saving model ...
Validation loss decreased (0.974524 --> 0.972057).  Saving model ...
EarlyStopping counter: 1 out of 5.0
EarlyStopping counter: 2 out of 5.0
Validation loss decreased (0.972057 --> 0.970505).  Saving model ...
Validation loss decreased (0.970505 --> 0.969073).  Saving model ...
Validation loss decreased (0.969073 --> 0.965520).  Saving model ...
Validation loss decreased (0.965520 --> 0.964407).  Saving model ...
Validation loss decreased (0.964407 --> 0.961338).  Saving model ...
EarlyStopping counter: 1 out of 5.0
EarlyStopping counter: 2 out of 5.0
Validation loss decreased (0.961338 --> 0.960059).  Saving model ...
Validation loss decreased (0.960059 --> 0.957234).  Saving model ...
EarlyStopping counter: 1 out of 5.0
Validation loss decreased (0.957234 --> 0.954865).  Saving model ...
Validation loss decreased (0.954865 --> 0.952536).  Saving model ...
EarlyStopping counter: 1 out of 5.0
Validation loss decreased (0.952536 --> 0.950070).  Saving model ...
EarlyStopping counter: 1 out of 5.0
Validation loss decreased (0.950070 --> 0.950049).  Saving model ...
EarlyStopping counter: 1 out of 5.0
Validation loss decreased (0.950049 --> 0.950033).  Saving model ...
Validation loss decreased (0.950033 --> 0.948463).  Saving model ...
EarlyStopping counter: 1 out of 5.0
Validation loss decreased (0.948463 --> 0.945029).  Saving model ...
EarlyStopping counter: 1 out of 5.0
EarlyStopping counter: 2 out of 5.0
EarlyStopping counter: 3 out of 5.0
EarlyStopping counter: 4 out of 5.0
EarlyStopping counter: 5 out of 5.0
/localscratch/yinan.29201086.0/env/lib/python3.7/site-packages/torch/nn/functional.py:1794: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.
  warnings.warn("nn.functional.tanh is deprecated. Use torch.tanh instead.")
wandb: Waiting for W&B process to finish, PID 155909... (success).
wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: \ 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: | 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: / 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: \ 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: | 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: / 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: \ 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: | 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: / 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb:                                                                                
wandb: Run history:
wandb:     e_F1 ▁▂▃▄▄▅▅▅▅▅▅▆▆▇▇▇▇▇▇▇████████████████████
wandb:   e_loss ██▇▇▇▇▆▆▆▆▅▅▅▄▄▄▄▃▃▃▃▂▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁
wandb:     t_F1 ▁▂▂▃▃▃▄▄▄▄▄▅▅▅▆▆▆▅▆▆▆▆▆▆▇▇▇▇▇▇▇▇▇███████
wandb:   t_loss ██▇▇▇▇▇▆▆▆▆▆▆▅▅▅▅▄▄▄▄▄▄▃▃▃▃▃▃▃▂▂▂▂▂▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:     e_F1 59.16389
wandb:   e_loss 0.94904
wandb:     t_F1 68.59614
wandb:   t_loss 0.82729
wandb: 
wandb: Synced 4 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Synced swept-spaceship-2: https://wandb.ai/yinanazhou/xl_512_bs_8_lr_1e06_es_5_lc_False_nr_False_sr_False_stem_False_lemma_False_repeat_1_fold_2/runs/1y6f41pv
wandb: Find logs at: ./wandb/run-20220318_213720-1y6f41pv/logs/debug.log
wandb: 

wandb: wandb version 0.12.11 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
2022-03-18 22:48:25.902581: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1
wandb: Tracking run with wandb version 0.12.5
wandb: Syncing run sunny-darkness-2
wandb: ⭐️ View project at https://wandb.ai/yinanazhou/xl_512_bs_8_lr_1e06_es_5_lc_False_nr_False_sr_False_stem_False_lemma_False_repeat_2_fold_1
wandb: 🚀 View run at https://wandb.ai/yinanazhou/xl_512_bs_8_lr_1e06_es_5_lc_False_nr_False_sr_False_stem_False_lemma_False_repeat_2_fold_1/runs/1hsa6rwn
wandb: Run data is saved locally in /project/6002780/yinan/Thesis_MER_Lyrics/lyric-emotion/wandb/run-20220318_224822-1hsa6rwn
wandb: Run `wandb offline` to turn off syncing.

Validation loss decreased (inf --> 1.434807).  Saving model ...
Validation loss decreased (1.434807 --> 1.405562).  Saving model ...
Validation loss decreased (1.405562 --> 1.385260).  Saving model ...
Validation loss decreased (1.385260 --> 1.371519).  Saving model ...
Validation loss decreased (1.371519 --> 1.360808).  Saving model ...
Validation loss decreased (1.360808 --> 1.353252).  Saving model ...
Validation loss decreased (1.353252 --> 1.347077).  Saving model ...
Validation loss decreased (1.347077 --> 1.341461).  Saving model ...
Validation loss decreased (1.341461 --> 1.337026).  Saving model ...
Validation loss decreased (1.337026 --> 1.333119).  Saving model ...
Validation loss decreased (1.333119 --> 1.328504).  Saving model ...
Validation loss decreased (1.328504 --> 1.323387).  Saving model ...
Validation loss decreased (1.323387 --> 1.317976).  Saving model ...
Validation loss decreased (1.317976 --> 1.312242).  Saving model ...
Validation loss decreased (1.312242 --> 1.306563).  Saving model ...
Validation loss decreased (1.306563 --> 1.301390).  Saving model ...
Validation loss decreased (1.301390 --> 1.296197).  Saving model ...
Validation loss decreased (1.296197 --> 1.290960).  Saving model ...
Validation loss decreased (1.290960 --> 1.284991).  Saving model ...
Validation loss decreased (1.284991 --> 1.279176).  Saving model ...
Validation loss decreased (1.279176 --> 1.272624).  Saving model ...
Validation loss decreased (1.272624 --> 1.265961).  Saving model ...
Validation loss decreased (1.265961 --> 1.258660).  Saving model ...
Validation loss decreased (1.258660 --> 1.251305).  Saving model ...
Validation loss decreased (1.251305 --> 1.244235).  Saving model ...
Validation loss decreased (1.244235 --> 1.237350).  Saving model ...
Validation loss decreased (1.237350 --> 1.230385).  Saving model ...
Validation loss decreased (1.230385 --> 1.223073).  Saving model ...
Validation loss decreased (1.223073 --> 1.214972).  Saving model ...
Validation loss decreased (1.214972 --> 1.206906).  Saving model ...
Validation loss decreased (1.206906 --> 1.196879).  Saving model ...
Validation loss decreased (1.196879 --> 1.189183).  Saving model ...
Validation loss decreased (1.189183 --> 1.181261).  Saving model ...
Validation loss decreased (1.181261 --> 1.172648).  Saving model ...
Validation loss decreased (1.172648 --> 1.164315).  Saving model ...
Validation loss decreased (1.164315 --> 1.155110).  Saving model ...
Validation loss decreased (1.155110 --> 1.145824).  Saving model ...
Validation loss decreased (1.145824 --> 1.137697).  Saving model ...
Validation loss decreased (1.137697 --> 1.130614).  Saving model ...
Validation loss decreased (1.130614 --> 1.122330).  Saving model ...
Validation loss decreased (1.122330 --> 1.114945).  Saving model ...
Validation loss decreased (1.114945 --> 1.106753).  Saving model ...
Validation loss decreased (1.106753 --> 1.099172).  Saving model ...
Validation loss decreased (1.099172 --> 1.092217).  Saving model ...
Validation loss decreased (1.092217 --> 1.084876).  Saving model ...
Validation loss decreased (1.084876 --> 1.079094).  Saving model ...
Validation loss decreased (1.079094 --> 1.073454).  Saving model ...
Validation loss decreased (1.073454 --> 1.066871).  Saving model ...
Validation loss decreased (1.066871 --> 1.061337).  Saving model ...
Validation loss decreased (1.061337 --> 1.055798).  Saving model ...
Validation loss decreased (1.055798 --> 1.049492).  Saving model ...
Validation loss decreased (1.049492 --> 1.044837).  Saving model ...
Validation loss decreased (1.044837 --> 1.039636).  Saving model ...
Validation loss decreased (1.039636 --> 1.034382).  Saving model ...
Validation loss decreased (1.034382 --> 1.029812).  Saving model ...
Validation loss decreased (1.029812 --> 1.025305).  Saving model ...
Validation loss decreased (1.025305 --> 1.020968).  Saving model ...
Validation loss decreased (1.020968 --> 1.016725).  Saving model ...
Validation loss decreased (1.016725 --> 1.012424).  Saving model ...
Validation loss decreased (1.012424 --> 1.008610).  Saving model ...
Validation loss decreased (1.008610 --> 1.004949).  Saving model ...
Validation loss decreased (1.004949 --> 1.000830).  Saving model ...
Validation loss decreased (1.000830 --> 0.996991).  Saving model ...
Validation loss decreased (0.996991 --> 0.993637).  Saving model ...
Validation loss decreased (0.993637 --> 0.990955).  Saving model ...
Validation loss decreased (0.990955 --> 0.987553).  Saving model ...
Validation loss decreased (0.987553 --> 0.983390).  Saving model ...
Validation loss decreased (0.983390 --> 0.981196).  Saving model ...
Validation loss decreased (0.981196 --> 0.977213).  Saving model ...
Validation loss decreased (0.977213 --> 0.974829).  Saving model ...
Validation loss decreased (0.974829 --> 0.972779).  Saving model ...
Validation loss decreased (0.972779 --> 0.970816).  Saving model ...
Validation loss decreased (0.970816 --> 0.968756).  Saving model ...
Validation loss decreased (0.968756 --> 0.967173).  Saving model ...
Validation loss decreased (0.967173 --> 0.965186).  Saving model ...
Validation loss decreased (0.965186 --> 0.963689).  Saving model ...
Validation loss decreased (0.963689 --> 0.960858).  Saving model ...
Validation loss decreased (0.960858 --> 0.960274).  Saving model ...
Validation loss decreased (0.960274 --> 0.957579).  Saving model ...
Validation loss decreased (0.957579 --> 0.954565).  Saving model ...
Validation loss decreased (0.954565 --> 0.952128).  Saving model ...
Validation loss decreased (0.952128 --> 0.949869).  Saving model ...
Validation loss decreased (0.949869 --> 0.948678).  Saving model ...
Validation loss decreased (0.948678 --> 0.947805).  Saving model ...
Validation loss decreased (0.947805 --> 0.944691).  Saving model ...
Validation loss decreased (0.944691 --> 0.942308).  Saving model ...
Validation loss decreased (0.942308 --> 0.940981).  Saving model ...
Validation loss decreased (0.940981 --> 0.939963).  Saving model ...
Validation loss decreased (0.939963 --> 0.937807).  Saving model ...
Validation loss decreased (0.937807 --> 0.937134).  Saving model ...
Validation loss decreased (0.937134 --> 0.935587).  Saving model ...
Validation loss decreased (0.935587 --> 0.933704).  Saving model ...
Validation loss decreased (0.933704 --> 0.932825).  Saving model ...
Validation loss decreased (0.932825 --> 0.931102).  Saving model ...
Validation loss decreased (0.931102 --> 0.929840).  Saving model ...
Validation loss decreased (0.929840 --> 0.929120).  Saving model ...
Validation loss decreased (0.929120 --> 0.928331).  Saving model ...
EarlyStopping counter: 1 out of 5.0
Validation loss decreased (0.928331 --> 0.926152).  Saving model ...
Validation loss decreased (0.926152 --> 0.925877).  Saving model ...
Validation loss decreased (0.925877 --> 0.925286).  Saving model ...
Validation loss decreased (0.925286 --> 0.923757).  Saving model ...
Validation loss decreased (0.923757 --> 0.923175).  Saving model ...
Validation loss decreased (0.923175 --> 0.922698).  Saving model ...
Validation loss decreased (0.922698 --> 0.922210).  Saving model ...
Validation loss decreased (0.922210 --> 0.921880).  Saving model ...
Validation loss decreased (0.921880 --> 0.921662).  Saving model ...
Validation loss decreased (0.921662 --> 0.920524).  Saving model ...
Validation loss decreased (0.920524 --> 0.919987).  Saving model ...
Validation loss decreased (0.919987 --> 0.919616).  Saving model ...
EarlyStopping counter: 1 out of 5.0
Validation loss decreased (0.919616 --> 0.919547).  Saving model ...
EarlyStopping counter: 1 out of 5.0
Validation loss decreased (0.919547 --> 0.919249).  Saving model ...
Validation loss decreased (0.919249 --> 0.918052).  Saving model ...
EarlyStopping counter: 1 out of 5.0
EarlyStopping counter: 2 out of 5.0
Validation loss decreased (0.918052 --> 0.917842).  Saving model ...
Validation loss decreased (0.917842 --> 0.917631).  Saving model ...
EarlyStopping counter: 1 out of 5.0
EarlyStopping counter: 2 out of 5.0
Validation loss decreased (0.917631 --> 0.917503).  Saving model ...
EarlyStopping counter: 1 out of 5.0
EarlyStopping counter: 2 out of 5.0
EarlyStopping counter: 3 out of 5.0
EarlyStopping counter: 4 out of 5.0
EarlyStopping counter: 5 out of 5.0
/localscratch/yinan.29201086.0/env/lib/python3.7/site-packages/torch/nn/functional.py:1794: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.
  warnings.warn("nn.functional.tanh is deprecated. Use torch.tanh instead.")
wandb: Waiting for W&B process to finish, PID 159726... (success).
wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: \ 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: | 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: / 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: \ 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: | 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: / 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: \ 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: | 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: / 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb:                                                                                
wandb: Run history:
wandb:     e_F1 ▁▂▃▃▃▄▄▅▅▆▆▇▇▇▇▇▇▇▇▇▇▇▇▇▇█▇█████████████
wandb:   e_loss █▇▇▇▆▆▆▆▅▅▅▄▄▃▃▃▃▃▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:     t_F1 ▁▁▂▃▃▃▃▄▄▅▅▅▆▆▆▆▆▆▆▇▆▆▇▇▇▇▇▇▇▇▇▇▇███████
wandb:   t_loss ██▇▇▇▇▆▆▆▅▆▅▅▅▄▄▄▄▃▃▃▃▃▃▃▂▂▂▂▂▂▂▂▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:     e_F1 61.4467
wandb:   e_loss 0.91907
wandb:     t_F1 73.08515
wandb:   t_loss 0.73028
wandb: 
wandb: Synced 4 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Synced sunny-darkness-2: https://wandb.ai/yinanazhou/xl_512_bs_8_lr_1e06_es_5_lc_False_nr_False_sr_False_stem_False_lemma_False_repeat_2_fold_1/runs/1hsa6rwn
wandb: Find logs at: ./wandb/run-20220318_224822-1hsa6rwn/logs/debug.log
wandb: 

wandb: wandb version 0.12.11 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
2022-03-19 00:12:01.655925: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1
wandb: Tracking run with wandb version 0.12.5
wandb: Syncing run noble-totem-2
wandb: ⭐️ View project at https://wandb.ai/yinanazhou/xl_512_bs_8_lr_1e06_es_5_lc_False_nr_False_sr_False_stem_False_lemma_False_repeat_2_fold_2
wandb: 🚀 View run at https://wandb.ai/yinanazhou/xl_512_bs_8_lr_1e06_es_5_lc_False_nr_False_sr_False_stem_False_lemma_False_repeat_2_fold_2/runs/2it470vb
wandb: Run data is saved locally in /project/6002780/yinan/Thesis_MER_Lyrics/lyric-emotion/wandb/run-20220319_001158-2it470vb
wandb: Run `wandb offline` to turn off syncing.

Validation loss decreased (inf --> 1.447251).  Saving model ...
Validation loss decreased (1.447251 --> 1.422503).  Saving model ...
Validation loss decreased (1.422503 --> 1.405081).  Saving model ...
Validation loss decreased (1.405081 --> 1.392362).  Saving model ...
Validation loss decreased (1.392362 --> 1.383338).  Saving model ...
Validation loss decreased (1.383338 --> 1.375611).  Saving model ...
Validation loss decreased (1.375611 --> 1.369174).  Saving model ...
Validation loss decreased (1.369174 --> 1.363601).  Saving model ...
Validation loss decreased (1.363601 --> 1.358558).  Saving model ...
Validation loss decreased (1.358558 --> 1.353804).  Saving model ...
Validation loss decreased (1.353804 --> 1.348885).  Saving model ...
Validation loss decreased (1.348885 --> 1.344357).  Saving model ...
Validation loss decreased (1.344357 --> 1.339781).  Saving model ...
Validation loss decreased (1.339781 --> 1.335142).  Saving model ...
Validation loss decreased (1.335142 --> 1.329956).  Saving model ...
Validation loss decreased (1.329956 --> 1.324070).  Saving model ...
Validation loss decreased (1.324070 --> 1.318339).  Saving model ...
Validation loss decreased (1.318339 --> 1.312123).  Saving model ...
Validation loss decreased (1.312123 --> 1.305546).  Saving model ...
Validation loss decreased (1.305546 --> 1.299011).  Saving model ...
Validation loss decreased (1.299011 --> 1.290944).  Saving model ...
Validation loss decreased (1.290944 --> 1.282120).  Saving model ...
Validation loss decreased (1.282120 --> 1.273987).  Saving model ...
Validation loss decreased (1.273987 --> 1.264487).  Saving model ...
Validation loss decreased (1.264487 --> 1.254193).  Saving model ...
Validation loss decreased (1.254193 --> 1.246151).  Saving model ...
Validation loss decreased (1.246151 --> 1.236767).  Saving model ...
Validation loss decreased (1.236767 --> 1.228079).  Saving model ...
Validation loss decreased (1.228079 --> 1.221123).  Saving model ...
Validation loss decreased (1.221123 --> 1.212566).  Saving model ...
Validation loss decreased (1.212566 --> 1.203222).  Saving model ...
Validation loss decreased (1.203222 --> 1.196702).  Saving model ...
Validation loss decreased (1.196702 --> 1.190212).  Saving model ...
Validation loss decreased (1.190212 --> 1.185632).  Saving model ...
Validation loss decreased (1.185632 --> 1.180197).  Saving model ...
Validation loss decreased (1.180197 --> 1.174075).  Saving model ...
Validation loss decreased (1.174075 --> 1.168406).  Saving model ...
Validation loss decreased (1.168406 --> 1.163570).  Saving model ...
Validation loss decreased (1.163570 --> 1.157583).  Saving model ...
Validation loss decreased (1.157583 --> 1.150202).  Saving model ...
Validation loss decreased (1.150202 --> 1.145837).  Saving model ...
Validation loss decreased (1.145837 --> 1.139749).  Saving model ...
Validation loss decreased (1.139749 --> 1.133154).  Saving model ...
Validation loss decreased (1.133154 --> 1.127635).  Saving model ...
Validation loss decreased (1.127635 --> 1.121530).  Saving model ...
Validation loss decreased (1.121530 --> 1.117635).  Saving model ...
Validation loss decreased (1.117635 --> 1.112457).  Saving model ...
Validation loss decreased (1.112457 --> 1.106591).  Saving model ...
Validation loss decreased (1.106591 --> 1.104150).  Saving model ...
Validation loss decreased (1.104150 --> 1.097916).  Saving model ...
Validation loss decreased (1.097916 --> 1.092684).  Saving model ...
Validation loss decreased (1.092684 --> 1.087778).  Saving model ...
Validation loss decreased (1.087778 --> 1.083896).  Saving model ...
Validation loss decreased (1.083896 --> 1.078759).  Saving model ...
Validation loss decreased (1.078759 --> 1.074831).  Saving model ...
Validation loss decreased (1.074831 --> 1.068663).  Saving model ...
Validation loss decreased (1.068663 --> 1.064711).  Saving model ...
Validation loss decreased (1.064711 --> 1.060879).  Saving model ...
Validation loss decreased (1.060879 --> 1.058320).  Saving model ...
Validation loss decreased (1.058320 --> 1.052965).  Saving model ...
Validation loss decreased (1.052965 --> 1.050629).  Saving model ...
Validation loss decreased (1.050629 --> 1.046801).  Saving model ...
Validation loss decreased (1.046801 --> 1.042825).  Saving model ...
Validation loss decreased (1.042825 --> 1.041350).  Saving model ...
Validation loss decreased (1.041350 --> 1.036374).  Saving model ...
Validation loss decreased (1.036374 --> 1.035077).  Saving model ...
Validation loss decreased (1.035077 --> 1.031897).  Saving model ...
Validation loss decreased (1.031897 --> 1.026732).  Saving model ...
Validation loss decreased (1.026732 --> 1.022738).  Saving model ...
Validation loss decreased (1.022738 --> 1.018246).  Saving model ...
Validation loss decreased (1.018246 --> 1.015917).  Saving model ...
Validation loss decreased (1.015917 --> 1.013549).  Saving model ...
Validation loss decreased (1.013549 --> 1.010481).  Saving model ...
Validation loss decreased (1.010481 --> 1.004679).  Saving model ...
Validation loss decreased (1.004679 --> 1.003026).  Saving model ...
Validation loss decreased (1.003026 --> 1.001424).  Saving model ...
Validation loss decreased (1.001424 --> 0.997964).  Saving model ...
Validation loss decreased (0.997964 --> 0.995257).  Saving model ...
Validation loss decreased (0.995257 --> 0.991731).  Saving model ...
Validation loss decreased (0.991731 --> 0.988783).  Saving model ...
Validation loss decreased (0.988783 --> 0.985465).  Saving model ...
Validation loss decreased (0.985465 --> 0.984423).  Saving model ...
Validation loss decreased (0.984423 --> 0.982978).  Saving model ...
Validation loss decreased (0.982978 --> 0.979651).  Saving model ...
Validation loss decreased (0.979651 --> 0.977072).  Saving model ...
Validation loss decreased (0.977072 --> 0.976048).  Saving model ...
Validation loss decreased (0.976048 --> 0.973863).  Saving model ...
Validation loss decreased (0.973863 --> 0.970942).  Saving model ...
Validation loss decreased (0.970942 --> 0.967355).  Saving model ...
Validation loss decreased (0.967355 --> 0.967011).  Saving model ...
Validation loss decreased (0.967011 --> 0.964565).  Saving model ...
Validation loss decreased (0.964565 --> 0.963428).  Saving model ...
Validation loss decreased (0.963428 --> 0.962029).  Saving model ...
Validation loss decreased (0.962029 --> 0.959805).  Saving model ...
Validation loss decreased (0.959805 --> 0.958458).  Saving model ...
Validation loss decreased (0.958458 --> 0.958274).  Saving model ...
Validation loss decreased (0.958274 --> 0.955925).  Saving model ...
Validation loss decreased (0.955925 --> 0.953548).  Saving model ...
Validation loss decreased (0.953548 --> 0.951100).  Saving model ...
Validation loss decreased (0.951100 --> 0.950825).  Saving model ...
Validation loss decreased (0.950825 --> 0.948680).  Saving model ...
Validation loss decreased (0.948680 --> 0.946575).  Saving model ...
Validation loss decreased (0.946575 --> 0.944847).  Saving model ...
Validation loss decreased (0.944847 --> 0.942931).  Saving model ...
Validation loss decreased (0.942931 --> 0.941980).  Saving model ...
EarlyStopping counter: 1 out of 5.0
Validation loss decreased (0.941980 --> 0.939458).  Saving model ...
Validation loss decreased (0.939458 --> 0.938242).  Saving model ...
Validation loss decreased (0.938242 --> 0.935152).  Saving model ...
EarlyStopping counter: 1 out of 5.0
Validation loss decreased (0.935152 --> 0.933679).  Saving model ...
Validation loss decreased (0.933679 --> 0.931531).  Saving model ...
Validation loss decreased (0.931531 --> 0.931499).  Saving model ...
Validation loss decreased (0.931499 --> 0.930234).  Saving model ...
Validation loss decreased (0.930234 --> 0.929707).  Saving model ...
Validation loss decreased (0.929707 --> 0.929340).  Saving model ...
Validation loss decreased (0.929340 --> 0.927939).  Saving model ...
Validation loss decreased (0.927939 --> 0.927886).  Saving model ...
Validation loss decreased (0.927886 --> 0.926381).  Saving model ...
Validation loss decreased (0.926381 --> 0.924528).  Saving model ...
EarlyStopping counter: 1 out of 5.0
EarlyStopping counter: 2 out of 5.0
EarlyStopping counter: 3 out of 5.0
Validation loss decreased (0.924528 --> 0.924252).  Saving model ...
Validation loss decreased (0.924252 --> 0.924002).  Saving model ...
Validation loss decreased (0.924002 --> 0.922399).  Saving model ...
Validation loss decreased (0.922399 --> 0.921939).  Saving model ...
EarlyStopping counter: 1 out of 5.0
EarlyStopping counter: 2 out of 5.0
Validation loss decreased (0.921939 --> 0.919569).  Saving model ...
Validation loss decreased (0.919569 --> 0.919508).  Saving model ...
Validation loss decreased (0.919508 --> 0.918129).  Saving model ...
EarlyStopping counter: 1 out of 5.0
EarlyStopping counter: 2 out of 5.0
Validation loss decreased (0.918129 --> 0.917723).  Saving model ...
Validation loss decreased (0.917723 --> 0.915173).  Saving model ...
Validation loss decreased (0.915173 --> 0.914784).  Saving model ...
EarlyStopping counter: 1 out of 5.0
Validation loss decreased (0.914784 --> 0.914703).  Saving model ...
EarlyStopping counter: 1 out of 5.0
Validation loss decreased (0.914703 --> 0.914636).  Saving model ...
EarlyStopping counter: 1 out of 5.0
EarlyStopping counter: 2 out of 5.0
EarlyStopping counter: 3 out of 5.0
EarlyStopping counter: 4 out of 5.0
EarlyStopping counter: 5 out of 5.0
/localscratch/yinan.29201086.0/env/lib/python3.7/site-packages/torch/nn/functional.py:1794: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.
  warnings.warn("nn.functional.tanh is deprecated. Use torch.tanh instead.")
wandb: Waiting for W&B process to finish, PID 164253... (success).
wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: \ 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: | 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: / 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: \ 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: | 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: / 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: \ 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: | 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: / 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb:                                                                                
wandb: Run history:
wandb:     e_F1 ▁▁▃▄▄▅▅▅▆▆▆▆▆▆▇▇▇▇▇▇▇▇▇▇▇▇▇▇████████████
wandb:   e_loss ██▇▇▇▆▆▆▅▅▄▄▄▄▃▃▃▃▃▂▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:     t_F1 ▁▁▂▃▃▄▄▄▅▅▅▆▆▆▆▆▆▆▇▇▆▇▇▇▇▇▇▇▇▇██████████
wandb:   t_loss ██▇▇▇▇▆▆▆▆▅▅▅▅▅▅▄▄▄▃▄▃▃▃▃▃▂▂▂▂▂▂▂▂▂▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:     e_F1 62.36666
wandb:   e_loss 0.91507
wandb:     t_F1 72.52118
wandb:   t_loss 0.70791
wandb: 
wandb: Synced 4 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Synced noble-totem-2: https://wandb.ai/yinanazhou/xl_512_bs_8_lr_1e06_es_5_lc_False_nr_False_sr_False_stem_False_lemma_False_repeat_2_fold_2/runs/2it470vb
wandb: Find logs at: ./wandb/run-20220319_001158-2it470vb/logs/debug.log
wandb: 

wandb: wandb version 0.12.11 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
2022-03-19 01:42:45.866467: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1
wandb: Tracking run with wandb version 0.12.5
wandb: Syncing run crimson-forest-2
wandb: ⭐️ View project at https://wandb.ai/yinanazhou/xl_512_bs_8_lr_1e06_es_5_lc_False_nr_False_sr_False_stem_False_lemma_False_repeat_3_fold_1
wandb: 🚀 View run at https://wandb.ai/yinanazhou/xl_512_bs_8_lr_1e06_es_5_lc_False_nr_False_sr_False_stem_False_lemma_False_repeat_3_fold_1/runs/a5svozwv
wandb: Run data is saved locally in /project/6002780/yinan/Thesis_MER_Lyrics/lyric-emotion/wandb/run-20220319_014243-a5svozwv
wandb: Run `wandb offline` to turn off syncing.

Validation loss decreased (inf --> 1.397985).  Saving model ...
Validation loss decreased (1.397985 --> 1.376541).  Saving model ...
Validation loss decreased (1.376541 --> 1.360446).  Saving model ...
Validation loss decreased (1.360446 --> 1.349618).  Saving model ...
Validation loss decreased (1.349618 --> 1.341098).  Saving model ...
Validation loss decreased (1.341098 --> 1.333992).  Saving model ...
Validation loss decreased (1.333992 --> 1.328079).  Saving model ...
Validation loss decreased (1.328079 --> 1.322733).  Saving model ...
Validation loss decreased (1.322733 --> 1.317869).  Saving model ...
Validation loss decreased (1.317869 --> 1.313302).  Saving model ...
Validation loss decreased (1.313302 --> 1.308271).  Saving model ...
Validation loss decreased (1.308271 --> 1.303479).  Saving model ...
Validation loss decreased (1.303479 --> 1.298372).  Saving model ...
Validation loss decreased (1.298372 --> 1.293440).  Saving model ...
Validation loss decreased (1.293440 --> 1.288411).  Saving model ...
Validation loss decreased (1.288411 --> 1.282992).  Saving model ...
Validation loss decreased (1.282992 --> 1.277459).  Saving model ...
Validation loss decreased (1.277459 --> 1.271850).  Saving model ...
Validation loss decreased (1.271850 --> 1.265685).  Saving model ...
Validation loss decreased (1.265685 --> 1.259462).  Saving model ...
Validation loss decreased (1.259462 --> 1.253789).  Saving model ...
Validation loss decreased (1.253789 --> 1.247872).  Saving model ...
Validation loss decreased (1.247872 --> 1.242781).  Saving model ...
Validation loss decreased (1.242781 --> 1.236046).  Saving model ...
Validation loss decreased (1.236046 --> 1.229049).  Saving model ...
Validation loss decreased (1.229049 --> 1.223356).  Saving model ...
Validation loss decreased (1.223356 --> 1.217388).  Saving model ...
Validation loss decreased (1.217388 --> 1.210924).  Saving model ...
Validation loss decreased (1.210924 --> 1.203624).  Saving model ...
Validation loss decreased (1.203624 --> 1.198261).  Saving model ...
Validation loss decreased (1.198261 --> 1.193515).  Saving model ...
Validation loss decreased (1.193515 --> 1.186903).  Saving model ...
Validation loss decreased (1.186903 --> 1.180823).  Saving model ...
Validation loss decreased (1.180823 --> 1.175257).  Saving model ...
Validation loss decreased (1.175257 --> 1.167734).  Saving model ...
Validation loss decreased (1.167734 --> 1.158653).  Saving model ...
Validation loss decreased (1.158653 --> 1.152908).  Saving model ...
Validation loss decreased (1.152908 --> 1.147675).  Saving model ...
Validation loss decreased (1.147675 --> 1.142779).  Saving model ...
Validation loss decreased (1.142779 --> 1.136978).  Saving model ...
Validation loss decreased (1.136978 --> 1.131572).  Saving model ...
Validation loss decreased (1.131572 --> 1.125993).  Saving model ...
Validation loss decreased (1.125993 --> 1.118853).  Saving model ...
Validation loss decreased (1.118853 --> 1.113155).  Saving model ...
Validation loss decreased (1.113155 --> 1.109807).  Saving model ...
Validation loss decreased (1.109807 --> 1.104420).  Saving model ...
Validation loss decreased (1.104420 --> 1.099182).  Saving model ...
Validation loss decreased (1.099182 --> 1.091849).  Saving model ...
Validation loss decreased (1.091849 --> 1.089097).  Saving model ...
Validation loss decreased (1.089097 --> 1.088578).  Saving model ...
Validation loss decreased (1.088578 --> 1.084249).  Saving model ...
Validation loss decreased (1.084249 --> 1.078295).  Saving model ...
Validation loss decreased (1.078295 --> 1.070930).  Saving model ...
Validation loss decreased (1.070930 --> 1.060545).  Saving model ...
Validation loss decreased (1.060545 --> 1.055760).  Saving model ...
Validation loss decreased (1.055760 --> 1.049754).  Saving model ...
Validation loss decreased (1.049754 --> 1.046429).  Saving model ...
Validation loss decreased (1.046429 --> 1.043938).  Saving model ...
Validation loss decreased (1.043938 --> 1.043608).  Saving model ...
Validation loss decreased (1.043608 --> 1.038684).  Saving model ...
Validation loss decreased (1.038684 --> 1.034390).  Saving model ...
Validation loss decreased (1.034390 --> 1.030126).  Saving model ...
Validation loss decreased (1.030126 --> 1.025274).  Saving model ...
Validation loss decreased (1.025274 --> 1.022373).  Saving model ...
Validation loss decreased (1.022373 --> 1.019058).  Saving model ...
Validation loss decreased (1.019058 --> 1.017212).  Saving model ...
Validation loss decreased (1.017212 --> 1.012194).  Saving model ...
Validation loss decreased (1.012194 --> 1.012013).  Saving model ...
Validation loss decreased (1.012013 --> 1.010275).  Saving model ...
Validation loss decreased (1.010275 --> 1.005997).  Saving model ...
Validation loss decreased (1.005997 --> 1.002610).  Saving model ...
Validation loss decreased (1.002610 --> 0.999317).  Saving model ...
Validation loss decreased (0.999317 --> 0.994471).  Saving model ...
Validation loss decreased (0.994471 --> 0.992273).  Saving model ...
Validation loss decreased (0.992273 --> 0.990258).  Saving model ...
Validation loss decreased (0.990258 --> 0.987728).  Saving model ...
Validation loss decreased (0.987728 --> 0.984017).  Saving model ...
Validation loss decreased (0.984017 --> 0.983572).  Saving model ...
Validation loss decreased (0.983572 --> 0.979656).  Saving model ...
EarlyStopping counter: 1 out of 5.0
Validation loss decreased (0.979656 --> 0.978441).  Saving model ...
Validation loss decreased (0.978441 --> 0.972213).  Saving model ...
EarlyStopping counter: 1 out of 5.0
Validation loss decreased (0.972213 --> 0.970362).  Saving model ...
Validation loss decreased (0.970362 --> 0.968019).  Saving model ...
Validation loss decreased (0.968019 --> 0.966305).  Saving model ...
Validation loss decreased (0.966305 --> 0.964789).  Saving model ...
EarlyStopping counter: 1 out of 5.0
Validation loss decreased (0.964789 --> 0.963060).  Saving model ...
Validation loss decreased (0.963060 --> 0.958989).  Saving model ...
EarlyStopping counter: 1 out of 5.0
Validation loss decreased (0.958989 --> 0.958488).  Saving model ...
Validation loss decreased (0.958488 --> 0.955813).  Saving model ...
Validation loss decreased (0.955813 --> 0.953920).  Saving model ...
EarlyStopping counter: 1 out of 5.0
Validation loss decreased (0.953920 --> 0.951905).  Saving model ...
EarlyStopping counter: 1 out of 5.0
Validation loss decreased (0.951905 --> 0.951219).  Saving model ...
Validation loss decreased (0.951219 --> 0.948976).  Saving model ...
Validation loss decreased (0.948976 --> 0.948505).  Saving model ...
EarlyStopping counter: 1 out of 5.0
Validation loss decreased (0.948505 --> 0.946663).  Saving model ...
EarlyStopping counter: 1 out of 5.0
Validation loss decreased (0.946663 --> 0.946630).  Saving model ...
Validation loss decreased (0.946630 --> 0.943290).  Saving model ...
EarlyStopping counter: 1 out of 5.0
EarlyStopping counter: 2 out of 5.0
EarlyStopping counter: 3 out of 5.0
EarlyStopping counter: 4 out of 5.0
Validation loss decreased (0.943290 --> 0.942335).  Saving model ...
Validation loss decreased (0.942335 --> 0.942283).  Saving model ...
Validation loss decreased (0.942283 --> 0.940526).  Saving model ...
EarlyStopping counter: 1 out of 5.0
Validation loss decreased (0.940526 --> 0.939714).  Saving model ...
EarlyStopping counter: 1 out of 5.0
EarlyStopping counter: 2 out of 5.0
EarlyStopping counter: 3 out of 5.0
EarlyStopping counter: 4 out of 5.0
EarlyStopping counter: 5 out of 5.0
/localscratch/yinan.29201086.0/env/lib/python3.7/site-packages/torch/nn/functional.py:1794: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.
  warnings.warn("nn.functional.tanh is deprecated. Use torch.tanh instead.")
wandb: Waiting for W&B process to finish, PID 169153... (success).
wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: \ 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: | 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: / 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: \ 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: | 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: / 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: \ 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: | 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: / 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb:                                                                                
wandb: Run history:
wandb:     e_F1 ▁▃▅▅▅▆▆▆▆▆▆▆▆▇▇▇▇▇▇▇▇▇▇█████████████████
wandb:   e_loss █▇▇▇▆▆▆▆▅▅▅▅▄▄▄▄▃▃▃▃▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:     t_F1 ▁▂▃▄▄▃▄▄▅▅▅▅▅▆▆▆▆▆▆▆▇▇▇▇▇▇▇▇▇▇▇▇▇▇██████
wandb:   t_loss █▇▇▇▇▇▆▆▆▆▆▅▅▅▅▄▄▄▄▄▃▃▃▃▃▃▂▂▂▂▂▂▂▂▂▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:     e_F1 62.78393
wandb:   e_loss 0.94319
wandb:     t_F1 69.94727
wandb:   t_loss 0.75799
wandb: 
wandb: Synced 4 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Synced crimson-forest-2: https://wandb.ai/yinanazhou/xl_512_bs_8_lr_1e06_es_5_lc_False_nr_False_sr_False_stem_False_lemma_False_repeat_3_fold_1/runs/a5svozwv
wandb: Find logs at: ./wandb/run-20220319_014243-a5svozwv/logs/debug.log
wandb: 

wandb: wandb version 0.12.11 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
2022-03-19 02:58:39.432926: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1
wandb: Tracking run with wandb version 0.12.5
wandb: Syncing run silvery-darkness-2
wandb: ⭐️ View project at https://wandb.ai/yinanazhou/xl_512_bs_8_lr_1e06_es_5_lc_False_nr_False_sr_False_stem_False_lemma_False_repeat_3_fold_2
wandb: 🚀 View run at https://wandb.ai/yinanazhou/xl_512_bs_8_lr_1e06_es_5_lc_False_nr_False_sr_False_stem_False_lemma_False_repeat_3_fold_2/runs/fviljc0k
wandb: Run data is saved locally in /project/6002780/yinan/Thesis_MER_Lyrics/lyric-emotion/wandb/run-20220319_025836-fviljc0k
wandb: Run `wandb offline` to turn off syncing.

Validation loss decreased (inf --> 1.436023).  Saving model ...
Validation loss decreased (1.436023 --> 1.422935).  Saving model ...
Validation loss decreased (1.422935 --> 1.412360).  Saving model ...
Validation loss decreased (1.412360 --> 1.403257).  Saving model ...
Validation loss decreased (1.403257 --> 1.394494).  Saving model ...
Validation loss decreased (1.394494 --> 1.387793).  Saving model ...
Validation loss decreased (1.387793 --> 1.381364).  Saving model ...
Validation loss decreased (1.381364 --> 1.375196).  Saving model ...
Validation loss decreased (1.375196 --> 1.369175).  Saving model ...
Validation loss decreased (1.369175 --> 1.363856).  Saving model ...
Validation loss decreased (1.363856 --> 1.358362).  Saving model ...
Validation loss decreased (1.358362 --> 1.352912).  Saving model ...
Validation loss decreased (1.352912 --> 1.347527).  Saving model ...
Validation loss decreased (1.347527 --> 1.341754).  Saving model ...
Validation loss decreased (1.341754 --> 1.336210).  Saving model ...
Validation loss decreased (1.336210 --> 1.330246).  Saving model ...
Validation loss decreased (1.330246 --> 1.324072).  Saving model ...
Validation loss decreased (1.324072 --> 1.317992).  Saving model ...
Validation loss decreased (1.317992 --> 1.311456).  Saving model ...
Validation loss decreased (1.311456 --> 1.305677).  Saving model ...
Validation loss decreased (1.305677 --> 1.298589).  Saving model ...
Validation loss decreased (1.298589 --> 1.291667).  Saving model ...
Validation loss decreased (1.291667 --> 1.285087).  Saving model ...
Validation loss decreased (1.285087 --> 1.277549).  Saving model ...
Validation loss decreased (1.277549 --> 1.270273).  Saving model ...
Validation loss decreased (1.270273 --> 1.263533).  Saving model ...
Validation loss decreased (1.263533 --> 1.257200).  Saving model ...
Validation loss decreased (1.257200 --> 1.248561).  Saving model ...
Validation loss decreased (1.248561 --> 1.240400).  Saving model ...
Validation loss decreased (1.240400 --> 1.231827).  Saving model ...
Validation loss decreased (1.231827 --> 1.224168).  Saving model ...
Validation loss decreased (1.224168 --> 1.216189).  Saving model ...
Validation loss decreased (1.216189 --> 1.206699).  Saving model ...
Validation loss decreased (1.206699 --> 1.197587).  Saving model ...
Validation loss decreased (1.197587 --> 1.188192).  Saving model ...
Validation loss decreased (1.188192 --> 1.179932).  Saving model ...
Validation loss decreased (1.179932 --> 1.171804).  Saving model ...
Validation loss decreased (1.171804 --> 1.163814).  Saving model ...
Validation loss decreased (1.163814 --> 1.156839).  Saving model ...
Validation loss decreased (1.156839 --> 1.150074).  Saving model ...
Validation loss decreased (1.150074 --> 1.145162).  Saving model ...
Validation loss decreased (1.145162 --> 1.139169).  Saving model ...
Validation loss decreased (1.139169 --> 1.130504).  Saving model ...
Validation loss decreased (1.130504 --> 1.125460).  Saving model ...
Validation loss decreased (1.125460 --> 1.119956).  Saving model ...
Validation loss decreased (1.119956 --> 1.114743).  Saving model ...
Validation loss decreased (1.114743 --> 1.109499).  Saving model ...
Validation loss decreased (1.109499 --> 1.104626).  Saving model ...
Validation loss decreased (1.104626 --> 1.097819).  Saving model ...
Validation loss decreased (1.097819 --> 1.092170).  Saving model ...
Validation loss decreased (1.092170 --> 1.085858).  Saving model ...
Validation loss decreased (1.085858 --> 1.081157).  Saving model ...
Validation loss decreased (1.081157 --> 1.076258).  Saving model ...
Validation loss decreased (1.076258 --> 1.073778).  Saving model ...
Validation loss decreased (1.073778 --> 1.068343).  Saving model ...
Validation loss decreased (1.068343 --> 1.065019).  Saving model ...
Validation loss decreased (1.065019 --> 1.062473).  Saving model ...
Validation loss decreased (1.062473 --> 1.058036).  Saving model ...
Validation loss decreased (1.058036 --> 1.052284).  Saving model ...
Validation loss decreased (1.052284 --> 1.047229).  Saving model ...
Validation loss decreased (1.047229 --> 1.042730).  Saving model ...
Validation loss decreased (1.042730 --> 1.038874).  Saving model ...
Validation loss decreased (1.038874 --> 1.033330).  Saving model ...
Validation loss decreased (1.033330 --> 1.031419).  Saving model ...
EarlyStopping counter: 1 out of 5.0
Validation loss decreased (1.031419 --> 1.025498).  Saving model ...
Validation loss decreased (1.025498 --> 1.022970).  Saving model ...
Validation loss decreased (1.022970 --> 1.017427).  Saving model ...
Validation loss decreased (1.017427 --> 1.014274).  Saving model ...
Validation loss decreased (1.014274 --> 1.013572).  Saving model ...
Validation loss decreased (1.013572 --> 1.011346).  Saving model ...
Validation loss decreased (1.011346 --> 1.009410).  Saving model ...
Validation loss decreased (1.009410 --> 1.001664).  Saving model ...
Validation loss decreased (1.001664 --> 0.997455).  Saving model ...
Validation loss decreased (0.997455 --> 0.992847).  Saving model ...
Validation loss decreased (0.992847 --> 0.990257).  Saving model ...
Validation loss decreased (0.990257 --> 0.987021).  Saving model ...
Validation loss decreased (0.987021 --> 0.984571).  Saving model ...
Validation loss decreased (0.984571 --> 0.982898).  Saving model ...
Validation loss decreased (0.982898 --> 0.982058).  Saving model ...
Validation loss decreased (0.982058 --> 0.978382).  Saving model ...
EarlyStopping counter: 1 out of 5.0
Validation loss decreased (0.978382 --> 0.976659).  Saving model ...
Validation loss decreased (0.976659 --> 0.976169).  Saving model ...
Validation loss decreased (0.976169 --> 0.973795).  Saving model ...
Validation loss decreased (0.973795 --> 0.969624).  Saving model ...
Validation loss decreased (0.969624 --> 0.968018).  Saving model ...
Validation loss decreased (0.968018 --> 0.967512).  Saving model ...
Validation loss decreased (0.967512 --> 0.964013).  Saving model ...
Validation loss decreased (0.964013 --> 0.963364).  Saving model ...
Validation loss decreased (0.963364 --> 0.960999).  Saving model ...
Validation loss decreased (0.960999 --> 0.959826).  Saving model ...
EarlyStopping counter: 1 out of 5.0
Validation loss decreased (0.959826 --> 0.957412).  Saving model ...
Validation loss decreased (0.957412 --> 0.956480).  Saving model ...
Validation loss decreased (0.956480 --> 0.955576).  Saving model ...
Validation loss decreased (0.955576 --> 0.952918).  Saving model ...
Validation loss decreased (0.952918 --> 0.952187).  Saving model ...
Validation loss decreased (0.952187 --> 0.950589).  Saving model ...
Validation loss decreased (0.950589 --> 0.949892).  Saving model ...
Validation loss decreased (0.949892 --> 0.948785).  Saving model ...
Validation loss decreased (0.948785 --> 0.947633).  Saving model ...
Validation loss decreased (0.947633 --> 0.947304).  Saving model ...
Validation loss decreased (0.947304 --> 0.946511).  Saving model ...
EarlyStopping counter: 1 out of 5.0
Validation loss decreased (0.946511 --> 0.943432).  Saving model ...
Validation loss decreased (0.943432 --> 0.942668).  Saving model ...
EarlyStopping counter: 1 out of 5.0
Validation loss decreased (0.942668 --> 0.942002).  Saving model ...
Validation loss decreased (0.942002 --> 0.940965).  Saving model ...
Validation loss decreased (0.940965 --> 0.939241).  Saving model ...
Validation loss decreased (0.939241 --> 0.938572).  Saving model ...
Validation loss decreased (0.938572 --> 0.936801).  Saving model ...
EarlyStopping counter: 1 out of 5.0
Validation loss decreased (0.936801 --> 0.936066).  Saving model ...
Validation loss decreased (0.936066 --> 0.934511).  Saving model ...
EarlyStopping counter: 1 out of 5.0
EarlyStopping counter: 2 out of 5.0
EarlyStopping counter: 3 out of 5.0
Validation loss decreased (0.934511 --> 0.932190).  Saving model ...
EarlyStopping counter: 1 out of 5.0
EarlyStopping counter: 2 out of 5.0
EarlyStopping counter: 3 out of 5.0
EarlyStopping counter: 4 out of 5.0
Validation loss decreased (0.932190 --> 0.931423).  Saving model ...
EarlyStopping counter: 1 out of 5.0
EarlyStopping counter: 2 out of 5.0
EarlyStopping counter: 3 out of 5.0
EarlyStopping counter: 4 out of 5.0
EarlyStopping counter: 5 out of 5.0
/localscratch/yinan.29201086.0/env/lib/python3.7/site-packages/torch/nn/functional.py:1794: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.
  warnings.warn("nn.functional.tanh is deprecated. Use torch.tanh instead.")
wandb: Waiting for W&B process to finish, PID 173238... (success).
wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: \ 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: | 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: / 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: \ 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: | 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: / 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: \ 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: | 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: / 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb:                                                                                
wandb: Run history:
wandb:     e_F1 ▁▂▃▃▄▄▄▅▅▅▆▆▆▆▇▇▇▇▇▇▇▇▇▇▇▇██████████████
wandb:   e_loss ██▇▇▇▇▆▆▆▅▅▄▄▄▄▃▃▃▃▂▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:     t_F1 ▁▁▂▂▂▃▃▃▅▄▅▅▆▆▆▆▆▆▆▇▆▆▆▇▇▇▇▇▇▇█▇████████
wandb:   t_loss ██▇▇▇▇▇▇▆▆▅▅▅▅▅▄▄▄▄▄▃▃▃▃▃▃▃▃▂▂▂▂▂▂▂▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:     e_F1 61.74977
wandb:   e_loss 0.93302
wandb:     t_F1 69.36108
wandb:   t_loss 0.74876
wandb: 
wandb: Synced 4 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Synced silvery-darkness-2: https://wandb.ai/yinanazhou/xl_512_bs_8_lr_1e06_es_5_lc_False_nr_False_sr_False_stem_False_lemma_False_repeat_3_fold_2/runs/fviljc0k
wandb: Find logs at: ./wandb/run-20220319_025836-fviljc0k/logs/debug.log
wandb: 

wandb: wandb version 0.12.11 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
2022-03-19 04:19:19.766559: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1
wandb: Tracking run with wandb version 0.12.5
wandb: Syncing run major-sea-2
wandb: ⭐️ View project at https://wandb.ai/yinanazhou/xl_512_bs_8_lr_1e06_es_5_lc_False_nr_False_sr_False_stem_False_lemma_False_repeat_4_fold_1
wandb: 🚀 View run at https://wandb.ai/yinanazhou/xl_512_bs_8_lr_1e06_es_5_lc_False_nr_False_sr_False_stem_False_lemma_False_repeat_4_fold_1/runs/3sbuuxmp
wandb: Run data is saved locally in /project/6002780/yinan/Thesis_MER_Lyrics/lyric-emotion/wandb/run-20220319_041916-3sbuuxmp
wandb: Run `wandb offline` to turn off syncing.

Validation loss decreased (inf --> 1.501665).  Saving model ...
Validation loss decreased (1.501665 --> 1.460376).  Saving model ...
Validation loss decreased (1.460376 --> 1.433319).  Saving model ...
Validation loss decreased (1.433319 --> 1.413648).  Saving model ...
Validation loss decreased (1.413648 --> 1.399427).  Saving model ...
Validation loss decreased (1.399427 --> 1.388504).  Saving model ...
Validation loss decreased (1.388504 --> 1.380321).  Saving model ...
Validation loss decreased (1.380321 --> 1.373523).  Saving model ...
Validation loss decreased (1.373523 --> 1.367850).  Saving model ...
Validation loss decreased (1.367850 --> 1.361941).  Saving model ...
Validation loss decreased (1.361941 --> 1.356845).  Saving model ...
Validation loss decreased (1.356845 --> 1.351980).  Saving model ...
Validation loss decreased (1.351980 --> 1.346777).  Saving model ...
Validation loss decreased (1.346777 --> 1.341329).  Saving model ...
Validation loss decreased (1.341329 --> 1.335420).  Saving model ...
Validation loss decreased (1.335420 --> 1.329533).  Saving model ...
Validation loss decreased (1.329533 --> 1.322926).  Saving model ...
Validation loss decreased (1.322926 --> 1.316011).  Saving model ...
Validation loss decreased (1.316011 --> 1.308108).  Saving model ...
Validation loss decreased (1.308108 --> 1.300840).  Saving model ...
Validation loss decreased (1.300840 --> 1.292603).  Saving model ...
Validation loss decreased (1.292603 --> 1.283379).  Saving model ...
Validation loss decreased (1.283379 --> 1.273852).  Saving model ...
Validation loss decreased (1.273852 --> 1.264663).  Saving model ...
Validation loss decreased (1.264663 --> 1.254905).  Saving model ...
Validation loss decreased (1.254905 --> 1.245878).  Saving model ...
Validation loss decreased (1.245878 --> 1.236555).  Saving model ...
Validation loss decreased (1.236555 --> 1.225163).  Saving model ...
Validation loss decreased (1.225163 --> 1.217364).  Saving model ...
Validation loss decreased (1.217364 --> 1.208918).  Saving model ...
Validation loss decreased (1.208918 --> 1.200720).  Saving model ...
Validation loss decreased (1.200720 --> 1.191766).  Saving model ...
Validation loss decreased (1.191766 --> 1.185618).  Saving model ...
Validation loss decreased (1.185618 --> 1.178980).  Saving model ...
Validation loss decreased (1.178980 --> 1.171979).  Saving model ...
Validation loss decreased (1.171979 --> 1.165765).  Saving model ...
Validation loss decreased (1.165765 --> 1.157447).  Saving model ...
Validation loss decreased (1.157447 --> 1.150266).  Saving model ...
Validation loss decreased (1.150266 --> 1.142787).  Saving model ...
Validation loss decreased (1.142787 --> 1.136301).  Saving model ...
Validation loss decreased (1.136301 --> 1.131027).  Saving model ...
Validation loss decreased (1.131027 --> 1.126302).  Saving model ...
Validation loss decreased (1.126302 --> 1.121823).  Saving model ...
Validation loss decreased (1.121823 --> 1.116339).  Saving model ...
Validation loss decreased (1.116339 --> 1.110793).  Saving model ...
Validation loss decreased (1.110793 --> 1.105960).  Saving model ...
Validation loss decreased (1.105960 --> 1.098712).  Saving model ...
Validation loss decreased (1.098712 --> 1.094067).  Saving model ...
Validation loss decreased (1.094067 --> 1.088332).  Saving model ...
Validation loss decreased (1.088332 --> 1.083157).  Saving model ...
Validation loss decreased (1.083157 --> 1.078896).  Saving model ...
Validation loss decreased (1.078896 --> 1.074383).  Saving model ...
Validation loss decreased (1.074383 --> 1.069453).  Saving model ...
Validation loss decreased (1.069453 --> 1.065016).  Saving model ...
Validation loss decreased (1.065016 --> 1.061856).  Saving model ...
Validation loss decreased (1.061856 --> 1.058450).  Saving model ...
Validation loss decreased (1.058450 --> 1.055937).  Saving model ...
Validation loss decreased (1.055937 --> 1.050285).  Saving model ...
Validation loss decreased (1.050285 --> 1.046394).  Saving model ...
Validation loss decreased (1.046394 --> 1.042077).  Saving model ...
Validation loss decreased (1.042077 --> 1.038768).  Saving model ...
Validation loss decreased (1.038768 --> 1.035431).  Saving model ...
Validation loss decreased (1.035431 --> 1.031664).  Saving model ...
Validation loss decreased (1.031664 --> 1.028220).  Saving model ...
Validation loss decreased (1.028220 --> 1.022827).  Saving model ...
Validation loss decreased (1.022827 --> 1.019486).  Saving model ...
Validation loss decreased (1.019486 --> 1.017423).  Saving model ...
Validation loss decreased (1.017423 --> 1.015945).  Saving model ...
Validation loss decreased (1.015945 --> 1.010585).  Saving model ...
Validation loss decreased (1.010585 --> 1.007860).  Saving model ...
Validation loss decreased (1.007860 --> 1.004726).  Saving model ...
Validation loss decreased (1.004726 --> 1.002346).  Saving model ...
Validation loss decreased (1.002346 --> 1.000905).  Saving model ...
Validation loss decreased (1.000905 --> 0.998596).  Saving model ...
Validation loss decreased (0.998596 --> 0.994655).  Saving model ...
Validation loss decreased (0.994655 --> 0.991642).  Saving model ...
Validation loss decreased (0.991642 --> 0.988610).  Saving model ...
Validation loss decreased (0.988610 --> 0.984906).  Saving model ...
Validation loss decreased (0.984906 --> 0.982878).  Saving model ...
Validation loss decreased (0.982878 --> 0.982350).  Saving model ...
Validation loss decreased (0.982350 --> 0.978355).  Saving model ...
Validation loss decreased (0.978355 --> 0.976015).  Saving model ...
Validation loss decreased (0.976015 --> 0.974319).  Saving model ...
Validation loss decreased (0.974319 --> 0.973390).  Saving model ...
EarlyStopping counter: 1 out of 5.0
Validation loss decreased (0.973390 --> 0.971173).  Saving model ...
Validation loss decreased (0.971173 --> 0.968548).  Saving model ...
Validation loss decreased (0.968548 --> 0.964137).  Saving model ...
Validation loss decreased (0.964137 --> 0.962892).  Saving model ...
Validation loss decreased (0.962892 --> 0.961868).  Saving model ...
Validation loss decreased (0.961868 --> 0.959718).  Saving model ...
Validation loss decreased (0.959718 --> 0.959427).  Saving model ...
Validation loss decreased (0.959427 --> 0.958120).  Saving model ...
EarlyStopping counter: 1 out of 5.0
Validation loss decreased (0.958120 --> 0.955446).  Saving model ...
Validation loss decreased (0.955446 --> 0.953246).  Saving model ...
Validation loss decreased (0.953246 --> 0.952722).  Saving model ...
Validation loss decreased (0.952722 --> 0.950076).  Saving model ...
EarlyStopping counter: 1 out of 5.0
EarlyStopping counter: 2 out of 5.0
Validation loss decreased (0.950076 --> 0.948383).  Saving model ...
Validation loss decreased (0.948383 --> 0.947189).  Saving model ...
Validation loss decreased (0.947189 --> 0.942351).  Saving model ...
EarlyStopping counter: 1 out of 5.0
EarlyStopping counter: 2 out of 5.0
Validation loss decreased (0.942351 --> 0.941171).  Saving model ...
EarlyStopping counter: 1 out of 5.0
Validation loss decreased (0.941171 --> 0.940503).  Saving model ...
Validation loss decreased (0.940503 --> 0.939588).  Saving model ...
Validation loss decreased (0.939588 --> 0.938323).  Saving model ...
EarlyStopping counter: 1 out of 5.0
EarlyStopping counter: 2 out of 5.0
EarlyStopping counter: 3 out of 5.0
Validation loss decreased (0.938323 --> 0.937711).  Saving model ...
Validation loss decreased (0.937711 --> 0.936280).  Saving model ...
EarlyStopping counter: 1 out of 5.0
EarlyStopping counter: 2 out of 5.0
Validation loss decreased (0.936280 --> 0.935146).  Saving model ...
Validation loss decreased (0.935146 --> 0.934144).  Saving model ...
EarlyStopping counter: 1 out of 5.0
Validation loss decreased (0.934144 --> 0.933526).  Saving model ...
EarlyStopping counter: 1 out of 5.0
Validation loss decreased (0.933526 --> 0.932696).  Saving model ...
Validation loss decreased (0.932696 --> 0.931042).  Saving model ...
Validation loss decreased (0.931042 --> 0.927682).  Saving model ...
EarlyStopping counter: 1 out of 5.0
EarlyStopping counter: 2 out of 5.0
EarlyStopping counter: 3 out of 5.0
EarlyStopping counter: 4 out of 5.0
EarlyStopping counter: 5 out of 5.0
/localscratch/yinan.29201086.0/env/lib/python3.7/site-packages/torch/nn/functional.py:1794: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.
  warnings.warn("nn.functional.tanh is deprecated. Use torch.tanh instead.")
wandb: Waiting for W&B process to finish, PID 177618... (success).
wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: \ 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: | 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: / 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: \ 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: | 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: / 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: \ 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: | 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: / 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb:                                                                                
wandb: Run history:
wandb:     e_F1 ▁▁▃▃▄▅▅▆▆▆▇▇▇▇▇▇▇▇██████████████████████
wandb:   e_loss █▇▇▇▆▆▆▅▅▅▄▄▄▃▃▃▃▃▃▂▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:     t_F1 ▁▁▂▃▃▄▅▄▅▅▅▆▆▆▆▆▆▆▇▆▇▇▇▇▇▇▇▇▇▇▇▇▇███████
wandb:   t_loss █▇▇▇▇▇▆▆▅▅▅▅▅▄▄▄▄▄▃▃▃▃▃▃▃▃▂▂▂▂▂▂▂▂▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:     e_F1 60.87468
wandb:   e_loss 0.92787
wandb:     t_F1 70.15979
wandb:   t_loss 0.76458
wandb: 
wandb: Synced 4 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Synced major-sea-2: https://wandb.ai/yinanazhou/xl_512_bs_8_lr_1e06_es_5_lc_False_nr_False_sr_False_stem_False_lemma_False_repeat_4_fold_1/runs/3sbuuxmp
wandb: Find logs at: ./wandb/run-20220319_041916-3sbuuxmp/logs/debug.log
wandb: 

wandb: wandb version 0.12.11 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
2022-03-19 05:42:57.288730: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1
wandb: Tracking run with wandb version 0.12.5
wandb: Syncing run iconic-cosmos-2
wandb: ⭐️ View project at https://wandb.ai/yinanazhou/xl_512_bs_8_lr_1e06_es_5_lc_False_nr_False_sr_False_stem_False_lemma_False_repeat_4_fold_2
wandb: 🚀 View run at https://wandb.ai/yinanazhou/xl_512_bs_8_lr_1e06_es_5_lc_False_nr_False_sr_False_stem_False_lemma_False_repeat_4_fold_2/runs/1ampqrbn
wandb: Run data is saved locally in /project/6002780/yinan/Thesis_MER_Lyrics/lyric-emotion/wandb/run-20220319_054254-1ampqrbn
wandb: Run `wandb offline` to turn off syncing.

Validation loss decreased (inf --> 1.387468).  Saving model ...
Validation loss decreased (1.387468 --> 1.377247).  Saving model ...
Validation loss decreased (1.377247 --> 1.368698).  Saving model ...
Validation loss decreased (1.368698 --> 1.361567).  Saving model ...
Validation loss decreased (1.361567 --> 1.355026).  Saving model ...
Validation loss decreased (1.355026 --> 1.349440).  Saving model ...
Validation loss decreased (1.349440 --> 1.343749).  Saving model ...
Validation loss decreased (1.343749 --> 1.338620).  Saving model ...
Validation loss decreased (1.338620 --> 1.333421).  Saving model ...
Validation loss decreased (1.333421 --> 1.328338).  Saving model ...
Validation loss decreased (1.328338 --> 1.323344).  Saving model ...
Validation loss decreased (1.323344 --> 1.318898).  Saving model ...
Validation loss decreased (1.318898 --> 1.314282).  Saving model ...
Validation loss decreased (1.314282 --> 1.309205).  Saving model ...
Validation loss decreased (1.309205 --> 1.304070).  Saving model ...
Validation loss decreased (1.304070 --> 1.298413).  Saving model ...
Validation loss decreased (1.298413 --> 1.292844).  Saving model ...
Validation loss decreased (1.292844 --> 1.286837).  Saving model ...
Validation loss decreased (1.286837 --> 1.281083).  Saving model ...
Validation loss decreased (1.281083 --> 1.274442).  Saving model ...
Validation loss decreased (1.274442 --> 1.268860).  Saving model ...
Validation loss decreased (1.268860 --> 1.262500).  Saving model ...
Validation loss decreased (1.262500 --> 1.255962).  Saving model ...
Validation loss decreased (1.255962 --> 1.248840).  Saving model ...
Validation loss decreased (1.248840 --> 1.241284).  Saving model ...
Validation loss decreased (1.241284 --> 1.233682).  Saving model ...
Validation loss decreased (1.233682 --> 1.226948).  Saving model ...
Validation loss decreased (1.226948 --> 1.219427).  Saving model ...
Validation loss decreased (1.219427 --> 1.211404).  Saving model ...
Validation loss decreased (1.211404 --> 1.204190).  Saving model ...
Validation loss decreased (1.204190 --> 1.195890).  Saving model ...
Validation loss decreased (1.195890 --> 1.188276).  Saving model ...
Validation loss decreased (1.188276 --> 1.180642).  Saving model ...
Validation loss decreased (1.180642 --> 1.172939).  Saving model ...
Validation loss decreased (1.172939 --> 1.165163).  Saving model ...
Validation loss decreased (1.165163 --> 1.159853).  Saving model ...
Validation loss decreased (1.159853 --> 1.152345).  Saving model ...
Validation loss decreased (1.152345 --> 1.145339).  Saving model ...
Validation loss decreased (1.145339 --> 1.140546).  Saving model ...
Validation loss decreased (1.140546 --> 1.133537).  Saving model ...
Validation loss decreased (1.133537 --> 1.126604).  Saving model ...
Validation loss decreased (1.126604 --> 1.120443).  Saving model ...
Validation loss decreased (1.120443 --> 1.115577).  Saving model ...
Validation loss decreased (1.115577 --> 1.107945).  Saving model ...
Validation loss decreased (1.107945 --> 1.101666).  Saving model ...
Validation loss decreased (1.101666 --> 1.096390).  Saving model ...
Validation loss decreased (1.096390 --> 1.090681).  Saving model ...
Validation loss decreased (1.090681 --> 1.085161).  Saving model ...
Validation loss decreased (1.085161 --> 1.079240).  Saving model ...
Validation loss decreased (1.079240 --> 1.074275).  Saving model ...
Validation loss decreased (1.074275 --> 1.068062).  Saving model ...
Validation loss decreased (1.068062 --> 1.063113).  Saving model ...
Validation loss decreased (1.063113 --> 1.057232).  Saving model ...
Validation loss decreased (1.057232 --> 1.051336).  Saving model ...
Validation loss decreased (1.051336 --> 1.046483).  Saving model ...
Validation loss decreased (1.046483 --> 1.040820).  Saving model ...
Validation loss decreased (1.040820 --> 1.035598).  Saving model ...
Validation loss decreased (1.035598 --> 1.030912).  Saving model ...
Validation loss decreased (1.030912 --> 1.026178).  Saving model ...
Validation loss decreased (1.026178 --> 1.023209).  Saving model ...
Validation loss decreased (1.023209 --> 1.020072).  Saving model ...
Validation loss decreased (1.020072 --> 1.015775).  Saving model ...
Validation loss decreased (1.015775 --> 1.012367).  Saving model ...
Validation loss decreased (1.012367 --> 1.006425).  Saving model ...
Validation loss decreased (1.006425 --> 1.003688).  Saving model ...
Validation loss decreased (1.003688 --> 1.000876).  Saving model ...
Validation loss decreased (1.000876 --> 0.995890).  Saving model ...
Validation loss decreased (0.995890 --> 0.992259).  Saving model ...
Validation loss decreased (0.992259 --> 0.988808).  Saving model ...
Validation loss decreased (0.988808 --> 0.986355).  Saving model ...
Validation loss decreased (0.986355 --> 0.983854).  Saving model ...
Validation loss decreased (0.983854 --> 0.982316).  Saving model ...
Validation loss decreased (0.982316 --> 0.976645).  Saving model ...
Validation loss decreased (0.976645 --> 0.973994).  Saving model ...
Validation loss decreased (0.973994 --> 0.969291).  Saving model ...
Validation loss decreased (0.969291 --> 0.968786).  Saving model ...
Validation loss decreased (0.968786 --> 0.965637).  Saving model ...
Validation loss decreased (0.965637 --> 0.965350).  Saving model ...
Validation loss decreased (0.965350 --> 0.961925).  Saving model ...
Validation loss decreased (0.961925 --> 0.959496).  Saving model ...
Validation loss decreased (0.959496 --> 0.955789).  Saving model ...
Validation loss decreased (0.955789 --> 0.953674).  Saving model ...
EarlyStopping counter: 1 out of 5.0
Validation loss decreased (0.953674 --> 0.951822).  Saving model ...
Validation loss decreased (0.951822 --> 0.948875).  Saving model ...
Validation loss decreased (0.948875 --> 0.946088).  Saving model ...
EarlyStopping counter: 1 out of 5.0
Validation loss decreased (0.946088 --> 0.943422).  Saving model ...
Validation loss decreased (0.943422 --> 0.942529).  Saving model ...
Validation loss decreased (0.942529 --> 0.941025).  Saving model ...
Validation loss decreased (0.941025 --> 0.936598).  Saving model ...
Validation loss decreased (0.936598 --> 0.934771).  Saving model ...
Validation loss decreased (0.934771 --> 0.933189).  Saving model ...
Validation loss decreased (0.933189 --> 0.932571).  Saving model ...
EarlyStopping counter: 1 out of 5.0
EarlyStopping counter: 2 out of 5.0
EarlyStopping counter: 3 out of 5.0
Validation loss decreased (0.932571 --> 0.930423).  Saving model ...
Validation loss decreased (0.930423 --> 0.929064).  Saving model ...
EarlyStopping counter: 1 out of 5.0
Validation loss decreased (0.929064 --> 0.927605).  Saving model ...
Validation loss decreased (0.927605 --> 0.926289).  Saving model ...
Validation loss decreased (0.926289 --> 0.922945).  Saving model ...
EarlyStopping counter: 1 out of 5.0
Validation loss decreased (0.922945 --> 0.921395).  Saving model ...
Validation loss decreased (0.921395 --> 0.919359).  Saving model ...
EarlyStopping counter: 1 out of 5.0
EarlyStopping counter: 2 out of 5.0
Validation loss decreased (0.919359 --> 0.919243).  Saving model ...
EarlyStopping counter: 1 out of 5.0
EarlyStopping counter: 2 out of 5.0
Validation loss decreased (0.919243 --> 0.919166).  Saving model ...
Validation loss decreased (0.919166 --> 0.918519).  Saving model ...
Validation loss decreased (0.918519 --> 0.915922).  Saving model ...
Validation loss decreased (0.915922 --> 0.915769).  Saving model ...
EarlyStopping counter: 1 out of 5.0
EarlyStopping counter: 2 out of 5.0
EarlyStopping counter: 3 out of 5.0
EarlyStopping counter: 4 out of 5.0
Validation loss decreased (0.915769 --> 0.913330).  Saving model ...
EarlyStopping counter: 1 out of 5.0
Validation loss decreased (0.913330 --> 0.911419).  Saving model ...
EarlyStopping counter: 1 out of 5.0
EarlyStopping counter: 2 out of 5.0
EarlyStopping counter: 3 out of 5.0
Validation loss decreased (0.911419 --> 0.911385).  Saving model ...
EarlyStopping counter: 1 out of 5.0
EarlyStopping counter: 2 out of 5.0
EarlyStopping counter: 3 out of 5.0
EarlyStopping counter: 4 out of 5.0
EarlyStopping counter: 5 out of 5.0
/localscratch/yinan.29201086.0/env/lib/python3.7/site-packages/torch/nn/functional.py:1794: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.
  warnings.warn("nn.functional.tanh is deprecated. Use torch.tanh instead.")
wandb: Waiting for W&B process to finish, PID 182122... (success).
wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: \ 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: | 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: / 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: \ 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: | 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: / 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: \ 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb:                                                                                
wandb: Run history:
wandb:     e_F1 ▁▂▃▄▄▄▄▅▅▅▆▆▆▇▇▇▇▇▇▇████████████████████
wandb:   e_loss ██▇▇▇▇▆▆▆▅▅▅▄▄▄▃▃▃▃▂▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:     t_F1 ▁▁▂▂▂▂▃▄▄▄▄▅▅▅▅▅▆▆▆▆▆▆▇▆▇▇▇▇▇▇▇▇▇▇▇▇████
wandb:   t_loss ███▇▇▇▇▇▇▆▆▆▆▅▅▅▄▄▄▄▄▄▃▃▃▃▃▂▂▂▂▂▂▂▂▂▁▁▁▁
wandb: 
wandb: Run summary:
wandb:     e_F1 61.91861
wandb:   e_loss 0.91708
wandb:     t_F1 70.41009
wandb:   t_loss 0.74439
wandb: 
wandb: Synced 4 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Synced iconic-cosmos-2: https://wandb.ai/yinanazhou/xl_512_bs_8_lr_1e06_es_5_lc_False_nr_False_sr_False_stem_False_lemma_False_repeat_4_fold_2/runs/1ampqrbn
wandb: Find logs at: ./wandb/run-20220319_054254-1ampqrbn/logs/debug.log
wandb: 

wandb: wandb version 0.12.11 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
2022-03-19 07:07:55.265395: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1
wandb: Tracking run with wandb version 0.12.5
wandb: Syncing run exalted-serenity-2
wandb: ⭐️ View project at https://wandb.ai/yinanazhou/xl_512_bs_8_lr_1e06_es_5_lc_False_nr_False_sr_False_stem_False_lemma_False_repeat_5_fold_1
wandb: 🚀 View run at https://wandb.ai/yinanazhou/xl_512_bs_8_lr_1e06_es_5_lc_False_nr_False_sr_False_stem_False_lemma_False_repeat_5_fold_1/runs/13ezqj1z
wandb: Run data is saved locally in /project/6002780/yinan/Thesis_MER_Lyrics/lyric-emotion/wandb/run-20220319_070750-13ezqj1z
wandb: Run `wandb offline` to turn off syncing.

Validation loss decreased (inf --> 1.400796).  Saving model ...
Validation loss decreased (1.400796 --> 1.390877).  Saving model ...
Validation loss decreased (1.390877 --> 1.383235).  Saving model ...
Validation loss decreased (1.383235 --> 1.377352).  Saving model ...
Validation loss decreased (1.377352 --> 1.371644).  Saving model ...
Validation loss decreased (1.371644 --> 1.366383).  Saving model ...
Validation loss decreased (1.366383 --> 1.361582).  Saving model ...
Validation loss decreased (1.361582 --> 1.356476).  Saving model ...
Validation loss decreased (1.356476 --> 1.351294).  Saving model ...
Validation loss decreased (1.351294 --> 1.346707).  Saving model ...
Validation loss decreased (1.346707 --> 1.341882).  Saving model ...
Validation loss decreased (1.341882 --> 1.336908).  Saving model ...
Validation loss decreased (1.336908 --> 1.332089).  Saving model ...
Validation loss decreased (1.332089 --> 1.326923).  Saving model ...
Validation loss decreased (1.326923 --> 1.321209).  Saving model ...
Validation loss decreased (1.321209 --> 1.315274).  Saving model ...
Validation loss decreased (1.315274 --> 1.309705).  Saving model ...
Validation loss decreased (1.309705 --> 1.303705).  Saving model ...
Validation loss decreased (1.303705 --> 1.297054).  Saving model ...
Validation loss decreased (1.297054 --> 1.289480).  Saving model ...
Validation loss decreased (1.289480 --> 1.282099).  Saving model ...
Validation loss decreased (1.282099 --> 1.274160).  Saving model ...
Validation loss decreased (1.274160 --> 1.265905).  Saving model ...
Validation loss decreased (1.265905 --> 1.257251).  Saving model ...
Validation loss decreased (1.257251 --> 1.250074).  Saving model ...
Validation loss decreased (1.250074 --> 1.241190).  Saving model ...
Validation loss decreased (1.241190 --> 1.232444).  Saving model ...
Validation loss decreased (1.232444 --> 1.223620).  Saving model ...
Validation loss decreased (1.223620 --> 1.215228).  Saving model ...
Validation loss decreased (1.215228 --> 1.207339).  Saving model ...
Validation loss decreased (1.207339 --> 1.199080).  Saving model ...
Validation loss decreased (1.199080 --> 1.191206).  Saving model ...
Validation loss decreased (1.191206 --> 1.182461).  Saving model ...
Validation loss decreased (1.182461 --> 1.174985).  Saving model ...
Validation loss decreased (1.174985 --> 1.167905).  Saving model ...
Validation loss decreased (1.167905 --> 1.161437).  Saving model ...
Validation loss decreased (1.161437 --> 1.154795).  Saving model ...
Validation loss decreased (1.154795 --> 1.148725).  Saving model ...
Validation loss decreased (1.148725 --> 1.142290).  Saving model ...
Validation loss decreased (1.142290 --> 1.136258).  Saving model ...
Validation loss decreased (1.136258 --> 1.129980).  Saving model ...
Validation loss decreased (1.129980 --> 1.125934).  Saving model ...
Validation loss decreased (1.125934 --> 1.120658).  Saving model ...
Validation loss decreased (1.120658 --> 1.114204).  Saving model ...
Validation loss decreased (1.114204 --> 1.110691).  Saving model ...
Validation loss decreased (1.110691 --> 1.105690).  Saving model ...
Validation loss decreased (1.105690 --> 1.101538).  Saving model ...
Validation loss decreased (1.101538 --> 1.098521).  Saving model ...
Validation loss decreased (1.098521 --> 1.090306).  Saving model ...
Validation loss decreased (1.090306 --> 1.086568).  Saving model ...
Validation loss decreased (1.086568 --> 1.082832).  Saving model ...
Validation loss decreased (1.082832 --> 1.078422).  Saving model ...
Validation loss decreased (1.078422 --> 1.072462).  Saving model ...
Validation loss decreased (1.072462 --> 1.068046).  Saving model ...
Validation loss decreased (1.068046 --> 1.064962).  Saving model ...
Validation loss decreased (1.064962 --> 1.060740).  Saving model ...
Validation loss decreased (1.060740 --> 1.055200).  Saving model ...
Validation loss decreased (1.055200 --> 1.050107).  Saving model ...
Validation loss decreased (1.050107 --> 1.046006).  Saving model ...
Validation loss decreased (1.046006 --> 1.041598).  Saving model ...
Validation loss decreased (1.041598 --> 1.038214).  Saving model ...
Validation loss decreased (1.038214 --> 1.036028).  Saving model ...
Validation loss decreased (1.036028 --> 1.032398).  Saving model ...
Validation loss decreased (1.032398 --> 1.029235).  Saving model ...
Validation loss decreased (1.029235 --> 1.024080).  Saving model ...
Validation loss decreased (1.024080 --> 1.020822).  Saving model ...
Validation loss decreased (1.020822 --> 1.016151).  Saving model ...
Validation loss decreased (1.016151 --> 1.011442).  Saving model ...
Validation loss decreased (1.011442 --> 1.009597).  Saving model ...
Validation loss decreased (1.009597 --> 1.007925).  Saving model ...
Validation loss decreased (1.007925 --> 1.004501).  Saving model ...
Validation loss decreased (1.004501 --> 0.998893).  Saving model ...
Validation loss decreased (0.998893 --> 0.996148).  Saving model ...
Validation loss decreased (0.996148 --> 0.992079).  Saving model ...
Validation loss decreased (0.992079 --> 0.990378).  Saving model ...
Validation loss decreased (0.990378 --> 0.988676).  Saving model ...
Validation loss decreased (0.988676 --> 0.988487).  Saving model ...
Validation loss decreased (0.988487 --> 0.983299).  Saving model ...
Validation loss decreased (0.983299 --> 0.978345).  Saving model ...
Validation loss decreased (0.978345 --> 0.973126).  Saving model ...
Validation loss decreased (0.973126 --> 0.972746).  Saving model ...
Validation loss decreased (0.972746 --> 0.972113).  Saving model ...
Validation loss decreased (0.972113 --> 0.969060).  Saving model ...
Validation loss decreased (0.969060 --> 0.966839).  Saving model ...
Validation loss decreased (0.966839 --> 0.965471).  Saving model ...
Validation loss decreased (0.965471 --> 0.963258).  Saving model ...
Validation loss decreased (0.963258 --> 0.960701).  Saving model ...
Validation loss decreased (0.960701 --> 0.956741).  Saving model ...
Validation loss decreased (0.956741 --> 0.954170).  Saving model ...
Validation loss decreased (0.954170 --> 0.952037).  Saving model ...
Validation loss decreased (0.952037 --> 0.951075).  Saving model ...
Validation loss decreased (0.951075 --> 0.950034).  Saving model ...
EarlyStopping counter: 1 out of 5.0
Validation loss decreased (0.950034 --> 0.947784).  Saving model ...
Validation loss decreased (0.947784 --> 0.946086).  Saving model ...
Validation loss decreased (0.946086 --> 0.943333).  Saving model ...
Validation loss decreased (0.943333 --> 0.941950).  Saving model ...
Validation loss decreased (0.941950 --> 0.939922).  Saving model ...
Validation loss decreased (0.939922 --> 0.937453).  Saving model ...
Validation loss decreased (0.937453 --> 0.937212).  Saving model ...
EarlyStopping counter: 1 out of 5.0
Validation loss decreased (0.937212 --> 0.936216).  Saving model ...
Validation loss decreased (0.936216 --> 0.934761).  Saving model ...
Validation loss decreased (0.934761 --> 0.934315).  Saving model ...
Validation loss decreased (0.934315 --> 0.933617).  Saving model ...
Validation loss decreased (0.933617 --> 0.932530).  Saving model ...
Validation loss decreased (0.932530 --> 0.928976).  Saving model ...
EarlyStopping counter: 1 out of 5.0
Validation loss decreased (0.928976 --> 0.927718).  Saving model ...
Validation loss decreased (0.927718 --> 0.927018).  Saving model ...
EarlyStopping counter: 1 out of 5.0
EarlyStopping counter: 2 out of 5.0
Validation loss decreased (0.927018 --> 0.925219).  Saving model ...
EarlyStopping counter: 1 out of 5.0
EarlyStopping counter: 2 out of 5.0
Validation loss decreased (0.925219 --> 0.922717).  Saving model ...
Validation loss decreased (0.922717 --> 0.922713).  Saving model ...
Validation loss decreased (0.922713 --> 0.922585).  Saving model ...
Validation loss decreased (0.922585 --> 0.922139).  Saving model ...
EarlyStopping counter: 1 out of 5.0
EarlyStopping counter: 2 out of 5.0
EarlyStopping counter: 3 out of 5.0
Validation loss decreased (0.922139 --> 0.920467).  Saving model ...
Validation loss decreased (0.920467 --> 0.919423).  Saving model ...
Validation loss decreased (0.919423 --> 0.918879).  Saving model ...
Validation loss decreased (0.918879 --> 0.917650).  Saving model ...
Validation loss decreased (0.917650 --> 0.917082).  Saving model ...
EarlyStopping counter: 1 out of 5.0
EarlyStopping counter: 2 out of 5.0
EarlyStopping counter: 3 out of 5.0
EarlyStopping counter: 4 out of 5.0
EarlyStopping counter: 5 out of 5.0
/localscratch/yinan.29201086.0/env/lib/python3.7/site-packages/torch/nn/functional.py:1794: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.
  warnings.warn("nn.functional.tanh is deprecated. Use torch.tanh instead.")
wandb: Waiting for W&B process to finish, PID 186701... (success).
wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: \ 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: | 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: / 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: \ 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: | 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: / 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: \ 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: | 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: / 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: \ 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb:                                                                                
wandb: Run history:
wandb:     e_F1 ▁▃▄▄▄▅▅▅▆▆▆▆▆▇▇▇▇▇▇▇████████████████████
wandb:   e_loss ██▇▇▇▇▆▆▆▅▅▄▄▄▄▃▃▃▃▃▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:     t_F1 ▁▂▂▄▃▃▄▄▅▅▅▅▆▆▆▆▆▆▆▆▆▆▆▇▇▇▇▇▇▇▇▇▇▇▇█████
wandb:   t_loss ███▇▇▇▇▇▆▆▆▆▅▅▅▄▄▄▄▄▄▄▃▃▃▃▂▂▂▂▂▂▂▂▂▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:     e_F1 58.39933
wandb:   e_loss 0.92118
wandb:     t_F1 70.59296
wandb:   t_loss 0.75449
wandb: 
wandb: Synced 4 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Synced exalted-serenity-2: https://wandb.ai/yinanazhou/xl_512_bs_8_lr_1e06_es_5_lc_False_nr_False_sr_False_stem_False_lemma_False_repeat_5_fold_1/runs/13ezqj1z
wandb: Find logs at: ./wandb/run-20220319_070750-13ezqj1z/logs/debug.log
wandb: 

wandb: wandb version 0.12.11 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
2022-03-19 08:32:39.549360: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1
wandb: Tracking run with wandb version 0.12.5
wandb: Syncing run volcanic-valley-2
wandb: ⭐️ View project at https://wandb.ai/yinanazhou/xl_512_bs_8_lr_1e06_es_5_lc_False_nr_False_sr_False_stem_False_lemma_False_repeat_5_fold_2
wandb: 🚀 View run at https://wandb.ai/yinanazhou/xl_512_bs_8_lr_1e06_es_5_lc_False_nr_False_sr_False_stem_False_lemma_False_repeat_5_fold_2/runs/q65esq2b
wandb: Run data is saved locally in /project/6002780/yinan/Thesis_MER_Lyrics/lyric-emotion/wandb/run-20220319_083237-q65esq2b
wandb: Run `wandb offline` to turn off syncing.

Validation loss decreased (inf --> 1.467059).  Saving model ...
Validation loss decreased (1.467059 --> 1.445182).  Saving model ...
Validation loss decreased (1.445182 --> 1.428115).  Saving model ...
Validation loss decreased (1.428115 --> 1.415960).  Saving model ...
Validation loss decreased (1.415960 --> 1.405656).  Saving model ...
Validation loss decreased (1.405656 --> 1.396948).  Saving model ...
Validation loss decreased (1.396948 --> 1.390071).  Saving model ...
Validation loss decreased (1.390071 --> 1.383910).  Saving model ...
Validation loss decreased (1.383910 --> 1.378527).  Saving model ...
Validation loss decreased (1.378527 --> 1.373339).  Saving model ...
Validation loss decreased (1.373339 --> 1.368656).  Saving model ...
Validation loss decreased (1.368656 --> 1.364546).  Saving model ...
Validation loss decreased (1.364546 --> 1.360182).  Saving model ...
Validation loss decreased (1.360182 --> 1.355624).  Saving model ...
Validation loss decreased (1.355624 --> 1.351422).  Saving model ...
Validation loss decreased (1.351422 --> 1.346928).  Saving model ...
Validation loss decreased (1.346928 --> 1.342411).  Saving model ...
Validation loss decreased (1.342411 --> 1.337779).  Saving model ...
Validation loss decreased (1.337779 --> 1.333339).  Saving model ...
Validation loss decreased (1.333339 --> 1.328436).  Saving model ...
Validation loss decreased (1.328436 --> 1.322965).  Saving model ...
Validation loss decreased (1.322965 --> 1.317229).  Saving model ...
Validation loss decreased (1.317229 --> 1.311391).  Saving model ...
Validation loss decreased (1.311391 --> 1.305209).  Saving model ...
Validation loss decreased (1.305209 --> 1.299221).  Saving model ...
Validation loss decreased (1.299221 --> 1.292449).  Saving model ...
Validation loss decreased (1.292449 --> 1.285349).  Saving model ...
Validation loss decreased (1.285349 --> 1.278059).  Saving model ...
Validation loss decreased (1.278059 --> 1.270610).  Saving model ...
Validation loss decreased (1.270610 --> 1.264145).  Saving model ...
Validation loss decreased (1.264145 --> 1.256670).  Saving model ...
Validation loss decreased (1.256670 --> 1.249502).  Saving model ...
Validation loss decreased (1.249502 --> 1.242371).  Saving model ...
Validation loss decreased (1.242371 --> 1.235332).  Saving model ...
Validation loss decreased (1.235332 --> 1.227651).  Saving model ...
Validation loss decreased (1.227651 --> 1.219935).  Saving model ...
Validation loss decreased (1.219935 --> 1.213205).  Saving model ...
Validation loss decreased (1.213205 --> 1.204326).  Saving model ...
Validation loss decreased (1.204326 --> 1.196325).  Saving model ...
Validation loss decreased (1.196325 --> 1.189738).  Saving model ...
Validation loss decreased (1.189738 --> 1.183893).  Saving model ...
Validation loss decreased (1.183893 --> 1.176638).  Saving model ...
Validation loss decreased (1.176638 --> 1.167819).  Saving model ...
Validation loss decreased (1.167819 --> 1.161358).  Saving model ...
Validation loss decreased (1.161358 --> 1.154340).  Saving model ...
Validation loss decreased (1.154340 --> 1.147638).  Saving model ...
Validation loss decreased (1.147638 --> 1.142323).  Saving model ...
Validation loss decreased (1.142323 --> 1.136547).  Saving model ...
Validation loss decreased (1.136547 --> 1.130473).  Saving model ...
Validation loss decreased (1.130473 --> 1.125332).  Saving model ...
Validation loss decreased (1.125332 --> 1.119377).  Saving model ...
Validation loss decreased (1.119377 --> 1.113414).  Saving model ...
Validation loss decreased (1.113414 --> 1.107557).  Saving model ...
Validation loss decreased (1.107557 --> 1.103171).  Saving model ...
Validation loss decreased (1.103171 --> 1.098172).  Saving model ...
Validation loss decreased (1.098172 --> 1.092730).  Saving model ...
Validation loss decreased (1.092730 --> 1.087435).  Saving model ...
Validation loss decreased (1.087435 --> 1.083637).  Saving model ...
Validation loss decreased (1.083637 --> 1.079294).  Saving model ...
Validation loss decreased (1.079294 --> 1.072435).  Saving model ...
Validation loss decreased (1.072435 --> 1.067338).  Saving model ...
Validation loss decreased (1.067338 --> 1.063742).  Saving model ...
Validation loss decreased (1.063742 --> 1.058015).  Saving model ...
Validation loss decreased (1.058015 --> 1.054680).  Saving model ...
Validation loss decreased (1.054680 --> 1.049973).  Saving model ...
Validation loss decreased (1.049973 --> 1.045203).  Saving model ...
Validation loss decreased (1.045203 --> 1.041150).  Saving model ...
Validation loss decreased (1.041150 --> 1.039429).  Saving model ...
Validation loss decreased (1.039429 --> 1.034746).  Saving model ...
Validation loss decreased (1.034746 --> 1.028050).  Saving model ...
Validation loss decreased (1.028050 --> 1.024224).  Saving model ...
Validation loss decreased (1.024224 --> 1.021180).  Saving model ...
Validation loss decreased (1.021180 --> 1.018646).  Saving model ...
Validation loss decreased (1.018646 --> 1.016013).  Saving model ...
Validation loss decreased (1.016013 --> 1.012535).  Saving model ...
Validation loss decreased (1.012535 --> 1.011439).  Saving model ...
Validation loss decreased (1.011439 --> 1.006781).  Saving model ...
Validation loss decreased (1.006781 --> 1.003957).  Saving model ...
Validation loss decreased (1.003957 --> 1.002672).  Saving model ...
Validation loss decreased (1.002672 --> 1.000098).  Saving model ...
Validation loss decreased (1.000098 --> 0.997533).  Saving model ...
Validation loss decreased (0.997533 --> 0.994337).  Saving model ...
Validation loss decreased (0.994337 --> 0.993651).  Saving model ...
Validation loss decreased (0.993651 --> 0.991943).  Saving model ...
Validation loss decreased (0.991943 --> 0.988269).  Saving model ...
EarlyStopping counter: 1 out of 5.0
Validation loss decreased (0.988269 --> 0.987486).  Saving model ...
Validation loss decreased (0.987486 --> 0.983089).  Saving model ...
Validation loss decreased (0.983089 --> 0.978542).  Saving model ...
Validation loss decreased (0.978542 --> 0.976995).  Saving model ...
Validation loss decreased (0.976995 --> 0.976287).  Saving model ...
Validation loss decreased (0.976287 --> 0.974566).  Saving model ...
Validation loss decreased (0.974566 --> 0.971854).  Saving model ...
Validation loss decreased (0.971854 --> 0.970274).  Saving model ...
EarlyStopping counter: 1 out of 5.0
Validation loss decreased (0.970274 --> 0.969908).  Saving model ...
Validation loss decreased (0.969908 --> 0.967156).  Saving model ...
EarlyStopping counter: 1 out of 5.0
Validation loss decreased (0.967156 --> 0.966143).  Saving model ...
Validation loss decreased (0.966143 --> 0.962933).  Saving model ...
Validation loss decreased (0.962933 --> 0.962264).  Saving model ...
Validation loss decreased (0.962264 --> 0.961391).  Saving model ...
Validation loss decreased (0.961391 --> 0.959952).  Saving model ...
Validation loss decreased (0.959952 --> 0.957553).  Saving model ...
Validation loss decreased (0.957553 --> 0.956734).  Saving model ...
Validation loss decreased (0.956734 --> 0.955774).  Saving model ...
EarlyStopping counter: 1 out of 5.0
EarlyStopping counter: 2 out of 5.0
Validation loss decreased (0.955774 --> 0.955199).  Saving model ...
Validation loss decreased (0.955199 --> 0.954697).  Saving model ...
Validation loss decreased (0.954697 --> 0.951915).  Saving model ...
EarlyStopping counter: 1 out of 5.0
Validation loss decreased (0.951915 --> 0.949667).  Saving model ...
Validation loss decreased (0.949667 --> 0.949404).  Saving model ...
EarlyStopping counter: 1 out of 5.0
EarlyStopping counter: 2 out of 5.0
Validation loss decreased (0.949404 --> 0.949053).  Saving model ...
Validation loss decreased (0.949053 --> 0.947100).  Saving model ...
EarlyStopping counter: 1 out of 5.0
EarlyStopping counter: 2 out of 5.0
EarlyStopping counter: 3 out of 5.0
Validation loss decreased (0.947100 --> 0.945367).  Saving model ...
EarlyStopping counter: 1 out of 5.0
EarlyStopping counter: 2 out of 5.0
EarlyStopping counter: 3 out of 5.0
EarlyStopping counter: 4 out of 5.0
Validation loss decreased (0.945367 --> 0.943038).  Saving model ...
Validation loss decreased (0.943038 --> 0.943000).  Saving model ...
Validation loss decreased (0.943000 --> 0.942813).  Saving model ...
EarlyStopping counter: 1 out of 5.0
EarlyStopping counter: 2 out of 5.0
EarlyStopping counter: 3 out of 5.0
Validation loss decreased (0.942813 --> 0.940216).  Saving model ...
Validation loss decreased (0.940216 --> 0.940189).  Saving model ...
Validation loss decreased (0.940189 --> 0.939644).  Saving model ...
EarlyStopping counter: 1 out of 5.0
Validation loss decreased (0.939644 --> 0.939423).  Saving model ...
EarlyStopping counter: 1 out of 5.0
EarlyStopping counter: 2 out of 5.0
EarlyStopping counter: 3 out of 5.0
EarlyStopping counter: 4 out of 5.0
EarlyStopping counter: 5 out of 5.0
/localscratch/yinan.29201086.0/env/lib/python3.7/site-packages/torch/nn/functional.py:1794: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.
  warnings.warn("nn.functional.tanh is deprecated. Use torch.tanh instead.")
wandb: Waiting for W&B process to finish, PID 191271... (success).
wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: \ 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: | 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: / 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: \ 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: | 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: / 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: \ 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: | 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: / 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb:                                                                                
wandb: Run history:
wandb:     e_F1 ▁▁▂▃▄▄▅▅▆▆▆▆▆▇▇▇▇█▇█████████████████████
wandb:   e_loss ██▇▇▇▇▆▆▅▅▅▄▄▄▃▃▃▃▂▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:     t_F1 ▁▁▂▂▂▃▃▄▄▅▅▅▅▆▆▆▆▆▆▆▆▇▇▇▇▇▇▇▇█▇█████████
wandb:   t_loss ███▇▇▇▇▇▆▆▆▆▅▅▅▄▄▄▄▄▃▃▃▃▃▂▂▂▂▂▂▂▁▂▁▂▁▁▁▁
wandb: 
wandb: Run summary:
wandb:     e_F1 59.57856
wandb:   e_loss 0.93959
wandb:     t_F1 70.04947
wandb:   t_loss 0.75376
wandb: 
wandb: Synced 4 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Synced volcanic-valley-2: https://wandb.ai/yinanazhou/xl_512_bs_8_lr_1e06_es_5_lc_False_nr_False_sr_False_stem_False_lemma_False_repeat_5_fold_2/runs/q65esq2b
wandb: Find logs at: ./wandb/run-20220319_083237-q65esq2b/logs/debug.log
wandb: 

