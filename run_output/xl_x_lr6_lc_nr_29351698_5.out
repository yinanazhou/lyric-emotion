Unloading StdEnv/2020

Due to MODULEPATH changes, the following have been reloaded:
  1) mii/1.1.1


The following have been reloaded with a version change:
  1) python/3.8.2 => python/3.7.4

Using base prefix '/cvmfs/soft.computecanada.ca/easybuild/software/2017/Core/python/3.7.4'
New python executable in /localscratch/yinan.29351867.0/env/bin/python
Installing setuptools, pip, wheel...
done.
Ignoring pip: markers 'python_version < "3"' don't match your environment
Looking in links: /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/nix/avx2, /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/nix/generic, /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic
Collecting pip
Installing collected packages: pip
  Found existing installation: pip 19.1.1
    Uninstalling pip-19.1.1:
      Successfully uninstalled pip-19.1.1
Successfully installed pip-21.2.3+computecanada
Looking in links: /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/nix/avx2, /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/nix/generic, /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/keras-2.8.0+computecanada-py2.py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/Keras_Preprocessing-1.1.2+computecanada-py3-none-any.whl
Requirement already satisfied: matplotlib in /cvmfs/soft.computecanada.ca/easybuild/software/2017/Core/scipy-stack/2019a/lib/python3.7/site-packages (from -r requirements.txt (line 3)) (3.0.2)
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/nltk-3.6.5+computecanada-py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/scikit_learn-0.22.1+computecanada-cp37-cp37m-linux_x86_64.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/tensorboard-2.3.0+computecanada-py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/tensorboard_plugin_wit-1.7.0+computecanada-py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/tensorflow_gpu-2.3.0+computecanada-cp37-cp37m-linux_x86_64.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/tensorflow_estimator-2.3.0+computecanada-py2.py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/tokenizers-0.5.2+computecanada-cp37-cp37m-linux_x86_64.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/nix/avx2/torch-1.4.0+computecanada-cp37-cp37m-linux_x86_64.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/torchtext-0.6.0+computecanada-py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/torchvision-0.8.2+computecanada-cp37-cp37m-linux_x86_64.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/transformers-2.5.1+computecanada-py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/urllib3-1.26.7+computecanada-py2.py3-none-any.whl
ERROR: Could not find a version that satisfies the requirement regex>=2021.8.3 (from nltk) (from versions: 2018.1.10+computecanada, 2019.11.1+computecanada, 2020.11.13+computecanada)
ERROR: No matching distribution found for regex>=2021.8.3
Looking in links: /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/nix/avx2, /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/nix/generic, /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic
ERROR: Could not find a version that satisfies the requirement numpy==1.20.0+computacanada (from versions: 1.15.0+computecanada, 1.15.2+computecanada, 1.15.4+computecanada, 1.16.0+computecanada, 1.16.2+computecanada, 1.16.3+computecanada, 1.17.4+computecanada, 1.18.1+computecanada, 1.18.4+computecanada, 1.19.1+computecanada, 1.19.2+computecanada, 1.20.2+computecanada)
ERROR: No matching distribution found for numpy==1.20.0+computacanada
Looking in links: /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/nix/avx2, /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/nix/generic, /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/wandb-0.12.5+computecanada-py2.py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/docker_pycreds-0.4.0+computecanada-py2.py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/psutil-5.7.3+computecanada-cp37-cp37m-linux_x86_64.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/configparser-5.0.2+computecanada-py3-none-any.whl
Requirement already satisfied: python-dateutil>=2.6.1 in /cvmfs/soft.computecanada.ca/easybuild/software/2017/Core/scipy-stack/2019a/lib/python3.7/site-packages (from wandb) (2.7.5)
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/protobuf-3.19.4+computecanada-py2.py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/pathtools-0.1.2+computecanada-py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/sentry_sdk-1.5.0+computecanada-py2.py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/promise-2.3+computecanada-py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/six-1.16.0+computecanada-py2.py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/PyYAML-5.3.1+computecanada-cp37-cp37m-linux_x86_64.whl
Requirement already satisfied: requests<3,>=2.0.0 in /cvmfs/soft.computecanada.ca/easybuild/software/2017/Core/scipy-stack/2019a/lib/python3.7/site-packages (from wandb) (2.21.0)
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/shortuuid-1.0.1+computecanada-py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/GitPython-3.1.24+computecanada-py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/click-8.0.4+computecanada-py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/yaspin-2.1.0+computecanada-py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/subprocess32-3.5.4+computecanada-py3-none-any.whl
Requirement already satisfied: importlib-metadata in /cvmfs/soft.computecanada.ca/easybuild/software/2017/Core/scipy-stack/2019a/lib/python3.7/site-packages (from Click!=8.0.0,>=7.0->wandb) (0.8)
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/gitdb-4.0.9+computecanada-py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/typing_extensions-4.0.1+computecanada-py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/smmap-5.0.0+computecanada-py3-none-any.whl
Requirement already satisfied: idna<2.9,>=2.5 in /cvmfs/soft.computecanada.ca/easybuild/software/2017/Core/scipy-stack/2019a/lib/python3.7/site-packages (from requests<3,>=2.0.0->wandb) (2.8)
Requirement already satisfied: certifi>=2017.4.17 in /cvmfs/soft.computecanada.ca/easybuild/software/2017/Core/scipy-stack/2019a/lib/python3.7/site-packages (from requests<3,>=2.0.0->wandb) (2018.11.29)
Requirement already satisfied: urllib3<1.25,>=1.21.1 in /cvmfs/soft.computecanada.ca/easybuild/software/2017/Core/scipy-stack/2019a/lib/python3.7/site-packages (from requests<3,>=2.0.0->wandb) (1.24.1)
Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /cvmfs/soft.computecanada.ca/easybuild/software/2017/Core/scipy-stack/2019a/lib/python3.7/site-packages (from requests<3,>=2.0.0->wandb) (3.0.4)
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/termcolor-1.1.0+computecanada-py3-none-any.whl
Requirement already satisfied: zipp>=0.3.2 in /cvmfs/soft.computecanada.ca/easybuild/software/2017/Core/scipy-stack/2019a/lib/python3.7/site-packages (from importlib-metadata->Click!=8.0.0,>=7.0->wandb) (0.3.3)
Installing collected packages: smmap, typing-extensions, termcolor, six, gitdb, yaspin, subprocess32, shortuuid, sentry-sdk, PyYAML, psutil, protobuf, promise, pathtools, GitPython, docker-pycreds, configparser, Click, wandb
  Attempting uninstall: six
    Found existing installation: six 1.12.0
    Not uninstalling six at /cvmfs/soft.computecanada.ca/easybuild/software/2017/Core/scipy-stack/2019a/lib/python3.7/site-packages, outside environment /localscratch/yinan.29351867.0/env
    Can't uninstall 'six'. No files were found to uninstall.
Successfully installed Click-8.0.4+computecanada GitPython-3.1.24+computecanada PyYAML-5.3.1+computecanada configparser-5.0.2+computecanada docker-pycreds-0.4.0+computecanada gitdb-4.0.9+computecanada pathtools-0.1.2+computecanada promise-2.3+computecanada protobuf-3.19.4+computecanada psutil-5.7.3+computecanada sentry-sdk-1.5.0+computecanada shortuuid-1.0.1+computecanada six-1.16.0+computecanada smmap-5.0.0+computecanada subprocess32-3.5.4+computecanada termcolor-1.1.0+computecanada typing-extensions-4.0.1+computecanada wandb-0.12.5+computecanada yaspin-2.1.0+computecanada
Looking in links: /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/nix/avx2, /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/nix/generic, /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic
ERROR: Could not find a version that satisfies the requirement sagemaker (from versions: none)
ERROR: No matching distribution found for sagemaker
Looking in links: /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/nix/avx2, /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/nix/generic, /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/torch-1.9.1+computecanada-cp37-cp37m-linux_x86_64.whl
Requirement already satisfied: typing-extensions in /localscratch/yinan.29351867.0/env/lib/python3.7/site-packages (from torch) (4.0.1+computecanada)
Installing collected packages: torch
Successfully installed torch-1.9.1+computecanada
Looking in links: /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/nix/avx2, /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/nix/generic, /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/transformers-2.5.1+computecanada-py3-none-any.whl
Requirement already satisfied: requests in /cvmfs/soft.computecanada.ca/easybuild/software/2017/Core/scipy-stack/2019a/lib/python3.7/site-packages (from transformers==2.5.1+computecanada) (2.21.0)
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/boto3-1.21.14+computecanada-py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/tqdm-4.63.0+computecanada-py2.py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/regex-2020.11.13+computecanada-cp37-cp37m-linux_x86_64.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/sentencepiece-0.1.91+computecanada-cp37-cp37m-linux_x86_64.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/filelock-3.4.2+computecanada-py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/sacremoses-0.0.46+computecanada-py3-none-any.whl
Requirement already satisfied: numpy in /cvmfs/soft.computecanada.ca/easybuild/software/2017/Core/scipy-stack/2019a/lib/python3.7/site-packages (from transformers==2.5.1+computecanada) (1.16.0)
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/tokenizers-0.5.2+computecanada-cp37-cp37m-linux_x86_64.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/jmespath-0.10.0+computecanada-py2.py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/botocore-1.24.14+computecanada-py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/s3transfer-0.5.1+computecanada-py3-none-any.whl
Requirement already satisfied: python-dateutil<3.0.0,>=2.1 in /cvmfs/soft.computecanada.ca/easybuild/software/2017/Core/scipy-stack/2019a/lib/python3.7/site-packages (from botocore<1.25.0,>=1.24.14->boto3->transformers==2.5.1+computecanada) (2.7.5)
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/urllib3-1.26.8+computecanada-py2.py3-none-any.whl
Requirement already satisfied: six>=1.5 in /localscratch/yinan.29351867.0/env/lib/python3.7/site-packages (from python-dateutil<3.0.0,>=2.1->botocore<1.25.0,>=1.24.14->boto3->transformers==2.5.1+computecanada) (1.16.0+computecanada)
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/requests-2.27.1+computecanada-py2.py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/charset_normalizer-2.0.12+computecanada-py3-none-any.whl
Requirement already satisfied: certifi>=2017.4.17 in /cvmfs/soft.computecanada.ca/easybuild/software/2017/Core/scipy-stack/2019a/lib/python3.7/site-packages (from requests->transformers==2.5.1+computecanada) (2018.11.29)
Requirement already satisfied: idna<4,>=2.5 in /cvmfs/soft.computecanada.ca/easybuild/software/2017/Core/scipy-stack/2019a/lib/python3.7/site-packages (from requests->transformers==2.5.1+computecanada) (2.8)
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/joblib-1.1.0+computecanada-py2.py3-none-any.whl
Requirement already satisfied: click in /localscratch/yinan.29351867.0/env/lib/python3.7/site-packages (from sacremoses->transformers==2.5.1+computecanada) (8.0.4+computecanada)
Requirement already satisfied: importlib-metadata in /cvmfs/soft.computecanada.ca/easybuild/software/2017/Core/scipy-stack/2019a/lib/python3.7/site-packages (from click->sacremoses->transformers==2.5.1+computecanada) (0.8)
Requirement already satisfied: zipp>=0.3.2 in /cvmfs/soft.computecanada.ca/easybuild/software/2017/Core/scipy-stack/2019a/lib/python3.7/site-packages (from importlib-metadata->click->sacremoses->transformers==2.5.1+computecanada) (0.3.3)
Installing collected packages: urllib3, jmespath, botocore, tqdm, s3transfer, regex, joblib, charset-normalizer, tokenizers, sentencepiece, sacremoses, requests, filelock, boto3, transformers
  Attempting uninstall: urllib3
    Found existing installation: urllib3 1.24.1
    Not uninstalling urllib3 at /cvmfs/soft.computecanada.ca/easybuild/software/2017/Core/scipy-stack/2019a/lib/python3.7/site-packages, outside environment /localscratch/yinan.29351867.0/env
    Can't uninstall 'urllib3'. No files were found to uninstall.
  Attempting uninstall: requests
    Found existing installation: requests 2.21.0
    Not uninstalling requests at /cvmfs/soft.computecanada.ca/easybuild/software/2017/Core/scipy-stack/2019a/lib/python3.7/site-packages, outside environment /localscratch/yinan.29351867.0/env
    Can't uninstall 'requests'. No files were found to uninstall.
Successfully installed boto3-1.21.14+computecanada botocore-1.24.14+computecanada charset-normalizer-2.0.12+computecanada filelock-3.4.2+computecanada jmespath-0.10.0+computecanada joblib-1.1.0+computecanada regex-2020.11.13+computecanada requests-2.27.1+computecanada s3transfer-0.5.1+computecanada sacremoses-0.0.46+computecanada sentencepiece-0.1.91+computecanada tokenizers-0.5.2+computecanada tqdm-4.63.0+computecanada transformers-2.5.1+computecanada urllib3-1.26.8+computecanada
Looking in links: /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/nix/avx2, /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/nix/generic, /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/tensorflow_gpu-2.3.0+computecanada-cp37-cp37m-linux_x86_64.whl
Requirement already satisfied: wheel>=0.26 in /localscratch/yinan.29351867.0/env/lib/python3.7/site-packages (from tensorflow_gpu==2.3.0+computecanada) (0.33.4)
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/google_pasta-0.2.0+computecanada-py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/astunparse-1.6.3+computecanada-py2.py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/tensorflow_estimator-2.3.0+computecanada-py2.py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/nix/avx2/h5py-2.10.0+computecanada-cp37-cp37m-linux_x86_64.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/grpcio-1.38.0+computecanada-cp37-cp37m-linux_x86_64.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/gast-0.3.3+computecanada-py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/opt_einsum-3.3.0+computecanada-py3-none-any.whl
Requirement already satisfied: termcolor>=1.1.0 in /localscratch/yinan.29351867.0/env/lib/python3.7/site-packages (from tensorflow_gpu==2.3.0+computecanada) (1.1.0+computecanada)
Requirement already satisfied: six>=1.12.0 in /localscratch/yinan.29351867.0/env/lib/python3.7/site-packages (from tensorflow_gpu==2.3.0+computecanada) (1.16.0+computecanada)
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/absl_py-1.0.0+computecanada-py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/Keras_Preprocessing-1.1.2+computecanada-py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/nix/generic/scipy-1.4.1+computecanada-cp37-cp37m-linux_x86_64.whl
Requirement already satisfied: numpy<1.19.0,>=1.16.0 in /cvmfs/soft.computecanada.ca/easybuild/software/2017/Core/scipy-stack/2019a/lib/python3.7/site-packages (from tensorflow_gpu==2.3.0+computecanada) (1.16.0)
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/tensorboard-2.8.0+computecanada-py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/wrapt-1.11.2+computecanada-cp37-cp37m-linux_x86_64.whl
Requirement already satisfied: protobuf>=3.9.2 in /localscratch/yinan.29351867.0/env/lib/python3.7/site-packages (from tensorflow_gpu==2.3.0+computecanada) (3.19.4+computecanada)
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/google_auth-2.3.3+computecanada-py2.py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/google_auth_oauthlib-0.4.6+computecanada-py2.py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/tensorboard_plugin_wit-1.8.0+computecanada-py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/tensorboard_data_server-0.6.1+computecanada-py3-none-linux_x86_64.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/Markdown-3.3.6+computecanada-py3-none-any.whl
Requirement already satisfied: requests<3,>=2.21.0 in /localscratch/yinan.29351867.0/env/lib/python3.7/site-packages (from tensorboard<3,>=2.3.0->tensorflow_gpu==2.3.0+computecanada) (2.27.1+computecanada)
Requirement already satisfied: setuptools>=41.0.0 in /localscratch/yinan.29351867.0/env/lib/python3.7/site-packages (from tensorboard<3,>=2.3.0->tensorflow_gpu==2.3.0+computecanada) (41.0.1)
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/Werkzeug-2.0.3+computecanada-py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/cachetools-4.2.4+computecanada-py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/pyasn1_modules-0.2.8+computecanada-py2.py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/rsa-4.8+computecanada-py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/requests_oauthlib-1.3.0+computecanada-py2.py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/importlib_metadata-4.10.1+computecanada-py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/zipp-3.7.0+computecanada-py3-none-any.whl
Requirement already satisfied: typing-extensions>=3.6.4 in /localscratch/yinan.29351867.0/env/lib/python3.7/site-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard<3,>=2.3.0->tensorflow_gpu==2.3.0+computecanada) (4.0.1+computecanada)
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/pyasn1-0.4.8+computecanada-py2.py3-none-any.whl
Requirement already satisfied: idna<4,>=2.5 in /cvmfs/soft.computecanada.ca/easybuild/software/2017/Core/scipy-stack/2019a/lib/python3.7/site-packages (from requests<3,>=2.21.0->tensorboard<3,>=2.3.0->tensorflow_gpu==2.3.0+computecanada) (2.8)
Requirement already satisfied: urllib3<1.27,>=1.21.1 in /localscratch/yinan.29351867.0/env/lib/python3.7/site-packages (from requests<3,>=2.21.0->tensorboard<3,>=2.3.0->tensorflow_gpu==2.3.0+computecanada) (1.26.8+computecanada)
Requirement already satisfied: charset-normalizer~=2.0.0 in /localscratch/yinan.29351867.0/env/lib/python3.7/site-packages (from requests<3,>=2.21.0->tensorboard<3,>=2.3.0->tensorflow_gpu==2.3.0+computecanada) (2.0.12+computecanada)
Requirement already satisfied: certifi>=2017.4.17 in /cvmfs/soft.computecanada.ca/easybuild/software/2017/Core/scipy-stack/2019a/lib/python3.7/site-packages (from requests<3,>=2.21.0->tensorboard<3,>=2.3.0->tensorflow_gpu==2.3.0+computecanada) (2018.11.29)
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/oauthlib-3.1.1+computecanada-py2.py3-none-any.whl
Installing collected packages: pyasn1, zipp, rsa, pyasn1-modules, oauthlib, cachetools, requests-oauthlib, importlib-metadata, google-auth, werkzeug, tensorboard-plugin-wit, tensorboard-data-server, markdown, grpcio, google-auth-oauthlib, absl-py, wrapt, tensorflow-estimator, tensorboard, scipy, opt-einsum, keras-preprocessing, h5py, google-pasta, gast, astunparse, tensorflow-gpu
  Attempting uninstall: pyasn1
    Found existing installation: pyasn1 0.4.3
    Not uninstalling pyasn1 at /cvmfs/soft.computecanada.ca/easybuild/software/2017/Core/scipy-stack/2019a/lib/python3.7/site-packages, outside environment /localscratch/yinan.29351867.0/env
    Can't uninstall 'pyasn1'. No files were found to uninstall.
  Attempting uninstall: zipp
    Found existing installation: zipp 0.3.3
    Not uninstalling zipp at /cvmfs/soft.computecanada.ca/easybuild/software/2017/Core/scipy-stack/2019a/lib/python3.7/site-packages, outside environment /localscratch/yinan.29351867.0/env
    Can't uninstall 'zipp'. No files were found to uninstall.
  Attempting uninstall: importlib-metadata
    Found existing installation: importlib-metadata 0.8
    Not uninstalling importlib-metadata at /cvmfs/soft.computecanada.ca/easybuild/software/2017/Core/scipy-stack/2019a/lib/python3.7/site-packages, outside environment /localscratch/yinan.29351867.0/env
    Can't uninstall 'importlib-metadata'. No files were found to uninstall.
  Attempting uninstall: scipy
    Found existing installation: scipy 1.2.0
    Not uninstalling scipy at /cvmfs/soft.computecanada.ca/easybuild/software/2017/Core/scipy-stack/2019a/lib/python3.7/site-packages, outside environment /localscratch/yinan.29351867.0/env
    Can't uninstall 'scipy'. No files were found to uninstall.
Successfully installed absl-py-1.0.0+computecanada astunparse-1.6.3+computecanada cachetools-4.2.4+computecanada gast-0.3.3+computecanada google-auth-2.3.3+computecanada google-auth-oauthlib-0.4.6+computecanada google-pasta-0.2.0+computecanada grpcio-1.38.0+computecanada h5py-2.10.0+computecanada importlib-metadata-4.10.1+computecanada keras-preprocessing-1.1.2+computecanada markdown-3.3.6+computecanada oauthlib-3.1.1+computecanada opt-einsum-3.3.0+computecanada pyasn1-0.4.8+computecanada pyasn1-modules-0.2.8+computecanada requests-oauthlib-1.3.0+computecanada rsa-4.8+computecanada scipy-1.4.1+computecanada tensorboard-2.8.0+computecanada tensorboard-data-server-0.6.1+computecanada tensorboard-plugin-wit-1.8.0+computecanada tensorflow-estimator-2.3.0+computecanada tensorflow-gpu-2.3.0+computecanada werkzeug-2.0.3+computecanada wrapt-1.11.2+computecanada zipp-3.7.0+computecanada
Looking in links: /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/nix/avx2, /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/nix/generic, /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/keras-2.8.0+computecanada-py2.py3-none-any.whl
Installing collected packages: Keras
Successfully installed Keras-2.8.0+computecanada
Looking in links: /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/nix/avx2, /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/nix/generic, /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/urllib3-1.26.7+computecanada-py2.py3-none-any.whl
Installing collected packages: urllib3
  Attempting uninstall: urllib3
    Found existing installation: urllib3 1.26.8+computecanada
    Uninstalling urllib3-1.26.8+computecanada:
      Successfully uninstalled urllib3-1.26.8+computecanada
Successfully installed urllib3-1.26.7+computecanada
Looking in links: /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/nix/avx2, /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/nix/generic, /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/nltk-3.7+computecanada-py3-none-any.whl
Requirement already satisfied: joblib in /localscratch/yinan.29351867.0/env/lib/python3.7/site-packages (from nltk) (1.1.0+computecanada)
Requirement already satisfied: click in /localscratch/yinan.29351867.0/env/lib/python3.7/site-packages (from nltk) (8.0.4+computecanada)
Requirement already satisfied: tqdm in /localscratch/yinan.29351867.0/env/lib/python3.7/site-packages (from nltk) (4.63.0+computecanada)
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/nltk-3.6.5+computecanada-py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/nltk-3.6.3+computecanada-py3-none-any.whl
Requirement already satisfied: regex in /localscratch/yinan.29351867.0/env/lib/python3.7/site-packages (from nltk) (2020.11.13+computecanada)
Requirement already satisfied: importlib-metadata in /localscratch/yinan.29351867.0/env/lib/python3.7/site-packages (from click->nltk) (4.10.1+computecanada)
Requirement already satisfied: zipp>=0.5 in /localscratch/yinan.29351867.0/env/lib/python3.7/site-packages (from importlib-metadata->click->nltk) (3.7.0+computecanada)
Requirement already satisfied: typing-extensions>=3.6.4 in /localscratch/yinan.29351867.0/env/lib/python3.7/site-packages (from importlib-metadata->click->nltk) (4.0.1+computecanada)
Installing collected packages: nltk
Successfully installed nltk-3.6.3+computecanada
Looking in links: /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/nix/avx2, /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/nix/generic, /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/scikit_learn-0.22.1+computecanada-cp37-cp37m-linux_x86_64.whl
Requirement already satisfied: scipy>=0.17.0 in /localscratch/yinan.29351867.0/env/lib/python3.7/site-packages (from scikit-learn==0.22.1) (1.4.1+computecanada)
Requirement already satisfied: numpy>=1.11.0 in /cvmfs/soft.computecanada.ca/easybuild/software/2017/Core/scipy-stack/2019a/lib/python3.7/site-packages (from scikit-learn==0.22.1) (1.16.0)
Requirement already satisfied: joblib>=0.11 in /localscratch/yinan.29351867.0/env/lib/python3.7/site-packages (from scikit-learn==0.22.1) (1.1.0+computecanada)
Installing collected packages: scikit-learn
Successfully installed scikit-learn-0.22.1+computecanada
Looking in links: /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/nix/avx2, /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/nix/generic, /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic
Requirement already satisfied: tokenizers==0.5.2 in /localscratch/yinan.29351867.0/env/lib/python3.7/site-packages (0.5.2+computecanada)
wandb: Appending key for api.wandb.ai to your netrc file: /home/yinan/.netrc
Starting Task
2022-03-24 06:45:24.562946: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1
[nltk_data] Downloading package stopwords to /home/yinan/nltk_data...
[nltk_data]   Package stopwords is already up-to-date!
[nltk_data] Downloading package wordnet to /home/yinan/nltk_data...
[nltk_data]   Package wordnet is already up-to-date!
wandb: Currently logged in as: yinanazhou (use `wandb login --relogin` to force relogin)
wandb: wandb version 0.12.11 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
2022-03-24 06:45:34.641661: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1
wandb: Tracking run with wandb version 0.12.5
wandb: Syncing run deft-mountain-2
wandb: ⭐️ View project at https://wandb.ai/yinanazhou/xl_512_bs_8_lr_1e06_es_5_lc_True_nr_True_sr_False_stem_False_lemma_False_repeat_1_fold_1
wandb: 🚀 View run at https://wandb.ai/yinanazhou/xl_512_bs_8_lr_1e06_es_5_lc_True_nr_True_sr_False_stem_False_lemma_False_repeat_1_fold_1/runs/2btbxyo7
wandb: Run data is saved locally in /project/6002780/yinan/Thesis_MER_Lyrics/lyric-emotion/wandb/run-20220324_064532-2btbxyo7
wandb: Run `wandb offline` to turn off syncing.

Validation loss decreased (inf --> 1.439705).  Saving model ...
Validation loss decreased (1.439705 --> 1.419512).  Saving model ...
Validation loss decreased (1.419512 --> 1.402896).  Saving model ...
Validation loss decreased (1.402896 --> 1.389535).  Saving model ...
Validation loss decreased (1.389535 --> 1.379558).  Saving model ...
Validation loss decreased (1.379558 --> 1.370725).  Saving model ...
Validation loss decreased (1.370725 --> 1.364060).  Saving model ...
Validation loss decreased (1.364060 --> 1.358288).  Saving model ...
Validation loss decreased (1.358288 --> 1.352618).  Saving model ...
Validation loss decreased (1.352618 --> 1.347247).  Saving model ...
Validation loss decreased (1.347247 --> 1.341469).  Saving model ...
Validation loss decreased (1.341469 --> 1.336687).  Saving model ...
Validation loss decreased (1.336687 --> 1.331722).  Saving model ...
Validation loss decreased (1.331722 --> 1.326793).  Saving model ...
Validation loss decreased (1.326793 --> 1.321442).  Saving model ...
Validation loss decreased (1.321442 --> 1.317452).  Saving model ...
Validation loss decreased (1.317452 --> 1.311851).  Saving model ...
Validation loss decreased (1.311851 --> 1.305910).  Saving model ...
Validation loss decreased (1.305910 --> 1.300498).  Saving model ...
Validation loss decreased (1.300498 --> 1.294612).  Saving model ...
Validation loss decreased (1.294612 --> 1.289088).  Saving model ...
Validation loss decreased (1.289088 --> 1.282033).  Saving model ...
Validation loss decreased (1.282033 --> 1.278490).  Saving model ...
Validation loss decreased (1.278490 --> 1.271101).  Saving model ...
Validation loss decreased (1.271101 --> 1.265703).  Saving model ...
Validation loss decreased (1.265703 --> 1.261029).  Saving model ...
Validation loss decreased (1.261029 --> 1.254424).  Saving model ...
Validation loss decreased (1.254424 --> 1.250263).  Saving model ...
Validation loss decreased (1.250263 --> 1.247004).  Saving model ...
Validation loss decreased (1.247004 --> 1.245395).  Saving model ...
Validation loss decreased (1.245395 --> 1.242729).  Saving model ...
Validation loss decreased (1.242729 --> 1.237397).  Saving model ...
Validation loss decreased (1.237397 --> 1.235904).  Saving model ...
Validation loss decreased (1.235904 --> 1.230276).  Saving model ...
Validation loss decreased (1.230276 --> 1.227219).  Saving model ...
Validation loss decreased (1.227219 --> 1.220999).  Saving model ...
Validation loss decreased (1.220999 --> 1.215459).  Saving model ...
Validation loss decreased (1.215459 --> 1.214406).  Saving model ...
Validation loss decreased (1.214406 --> 1.209761).  Saving model ...
Validation loss decreased (1.209761 --> 1.208001).  Saving model ...
Validation loss decreased (1.208001 --> 1.201319).  Saving model ...
Validation loss decreased (1.201319 --> 1.197031).  Saving model ...
Validation loss decreased (1.197031 --> 1.194019).  Saving model ...
Validation loss decreased (1.194019 --> 1.193997).  Saving model ...
Validation loss decreased (1.193997 --> 1.189291).  Saving model ...
Validation loss decreased (1.189291 --> 1.186797).  Saving model ...
Validation loss decreased (1.186797 --> 1.185167).  Saving model ...
EarlyStopping counter: 1 out of 5.0
Validation loss decreased (1.185167 --> 1.179282).  Saving model ...
Validation loss decreased (1.179282 --> 1.179126).  Saving model ...
Validation loss decreased (1.179126 --> 1.172249).  Saving model ...
Validation loss decreased (1.172249 --> 1.169561).  Saving model ...
Validation loss decreased (1.169561 --> 1.168631).  Saving model ...
Validation loss decreased (1.168631 --> 1.165754).  Saving model ...
Validation loss decreased (1.165754 --> 1.165563).  Saving model ...
Validation loss decreased (1.165563 --> 1.159924).  Saving model ...
Validation loss decreased (1.159924 --> 1.154075).  Saving model ...
Validation loss decreased (1.154075 --> 1.149934).  Saving model ...
Validation loss decreased (1.149934 --> 1.144026).  Saving model ...
EarlyStopping counter: 1 out of 5.0
Validation loss decreased (1.144026 --> 1.141895).  Saving model ...
Validation loss decreased (1.141895 --> 1.139391).  Saving model ...
Validation loss decreased (1.139391 --> 1.134637).  Saving model ...
EarlyStopping counter: 1 out of 5.0
EarlyStopping counter: 2 out of 5.0
Validation loss decreased (1.134637 --> 1.130837).  Saving model ...
Validation loss decreased (1.130837 --> 1.128263).  Saving model ...
Validation loss decreased (1.128263 --> 1.122229).  Saving model ...
Validation loss decreased (1.122229 --> 1.121355).  Saving model ...
Validation loss decreased (1.121355 --> 1.119745).  Saving model ...
Validation loss decreased (1.119745 --> 1.113369).  Saving model ...
Validation loss decreased (1.113369 --> 1.111985).  Saving model ...
Validation loss decreased (1.111985 --> 1.111388).  Saving model ...
Validation loss decreased (1.111388 --> 1.108078).  Saving model ...
Validation loss decreased (1.108078 --> 1.104047).  Saving model ...
Validation loss decreased (1.104047 --> 1.103267).  Saving model ...
Validation loss decreased (1.103267 --> 1.102833).  Saving model ...
Validation loss decreased (1.102833 --> 1.098015).  Saving model ...
Validation loss decreased (1.098015 --> 1.092954).  Saving model ...
Validation loss decreased (1.092954 --> 1.091071).  Saving model ...
EarlyStopping counter: 1 out of 5.0
EarlyStopping counter: 2 out of 5.0
EarlyStopping counter: 3 out of 5.0
Validation loss decreased (1.091071 --> 1.088426).  Saving model ...
Validation loss decreased (1.088426 --> 1.086415).  Saving model ...
Validation loss decreased (1.086415 --> 1.081795).  Saving model ...
Validation loss decreased (1.081795 --> 1.076227).  Saving model ...
EarlyStopping counter: 1 out of 5.0
EarlyStopping counter: 2 out of 5.0
EarlyStopping counter: 3 out of 5.0
Validation loss decreased (1.076227 --> 1.076158).  Saving model ...
Validation loss decreased (1.076158 --> 1.075998).  Saving model ...
Validation loss decreased (1.075998 --> 1.073468).  Saving model ...
EarlyStopping counter: 1 out of 5.0
EarlyStopping counter: 2 out of 5.0
Validation loss decreased (1.073468 --> 1.071521).  Saving model ...
Validation loss decreased (1.071521 --> 1.070522).  Saving model ...
Validation loss decreased (1.070522 --> 1.063458).  Saving model ...
Validation loss decreased (1.063458 --> 1.062997).  Saving model ...
EarlyStopping counter: 1 out of 5.0
EarlyStopping counter: 2 out of 5.0
Validation loss decreased (1.062997 --> 1.058527).  Saving model ...
Validation loss decreased (1.058527 --> 1.057909).  Saving model ...
Validation loss decreased (1.057909 --> 1.056703).  Saving model ...
Validation loss decreased (1.056703 --> 1.055632).  Saving model ...
Validation loss decreased (1.055632 --> 1.052692).  Saving model ...
Validation loss decreased (1.052692 --> 1.052595).  Saving model ...
Validation loss decreased (1.052595 --> 1.049691).  Saving model ...
Validation loss decreased (1.049691 --> 1.047494).  Saving model ...
Validation loss decreased (1.047494 --> 1.044458).  Saving model ...
EarlyStopping counter: 1 out of 5.0
EarlyStopping counter: 2 out of 5.0
EarlyStopping counter: 3 out of 5.0
EarlyStopping counter: 4 out of 5.0
EarlyStopping counter: 5 out of 5.0
/localscratch/yinan.29351867.0/env/lib/python3.7/site-packages/torch/nn/functional.py:1794: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.
  warnings.warn("nn.functional.tanh is deprecated. Use torch.tanh instead.")
/localscratch/yinan.29351867.0/env/lib/python3.7/site-packages/transformers/optimization.py:155: UserWarning: This overload of add_ is deprecated:
	add_(Number alpha, Tensor other)
Consider using one of the following signatures instead:
	add_(Tensor other, *, Number alpha) (Triggered internally at  ../torch/csrc/utils/python_arg_parser.cpp:1025.)
  exp_avg.mul_(beta1).add_(1.0 - beta1, grad)
wandb: Waiting for W&B process to finish, PID 45488... (success).
wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: \ 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: | 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: / 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: \ 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: | 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: / 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: \ 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: | 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: / 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb:                                                                                
wandb: Run history:
wandb:     e_F1 ▁▂▃▄▅▅▅▅▅▆▆▆▆▆▆▆▆▆▆▆▇▇▇▇▇▇▇▇▇▇▇▇▇▇██████
wandb:   e_loss █▇▇▆▆▆▆▅▅▅▅▄▄▄▄▄▃▃▃▃▃▃▃▂▂▂▂▂▂▂▂▂▂▁▁▁▁▁▁▁
wandb:     t_F1 ▁▁▂▃▃▃▃▄▄▅▅▅▆▅▆▆▇▆▆▆▇▇▆▆▇▇▇▇▇▇▇▇█▇▇█████
wandb:   t_loss ██▇▇▇▇▇▆▆▆▅▅▅▅▄▄▄▄▄▄▃▃▃▃▃▃▃▃▂▂▂▂▂▂▂▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:     e_F1 55.35941
wandb:   e_loss 1.04531
wandb:     t_F1 68.50396
wandb:   t_loss 0.8105
wandb: 
wandb: Synced 4 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Synced deft-mountain-2: https://wandb.ai/yinanazhou/xl_512_bs_8_lr_1e06_es_5_lc_True_nr_True_sr_False_stem_False_lemma_False_repeat_1_fold_1/runs/2btbxyo7
wandb: Find logs at: ./wandb/run-20220324_064532-2btbxyo7/logs/debug.log
wandb: 

wandb: wandb version 0.12.11 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
2022-03-24 08:01:22.255741: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1
wandb: Tracking run with wandb version 0.12.5
wandb: Syncing run silver-valley-2
wandb: ⭐️ View project at https://wandb.ai/yinanazhou/xl_512_bs_8_lr_1e06_es_5_lc_True_nr_True_sr_False_stem_False_lemma_False_repeat_1_fold_2
wandb: 🚀 View run at https://wandb.ai/yinanazhou/xl_512_bs_8_lr_1e06_es_5_lc_True_nr_True_sr_False_stem_False_lemma_False_repeat_1_fold_2/runs/2595oqu9
wandb: Run data is saved locally in /project/6002780/yinan/Thesis_MER_Lyrics/lyric-emotion/wandb/run-20220324_080119-2595oqu9
wandb: Run `wandb offline` to turn off syncing.

Validation loss decreased (inf --> 1.435001).  Saving model ...
Validation loss decreased (1.435001 --> 1.418763).  Saving model ...
Validation loss decreased (1.418763 --> 1.408335).  Saving model ...
Validation loss decreased (1.408335 --> 1.400220).  Saving model ...
Validation loss decreased (1.400220 --> 1.393591).  Saving model ...
Validation loss decreased (1.393591 --> 1.387882).  Saving model ...
Validation loss decreased (1.387882 --> 1.383205).  Saving model ...
Validation loss decreased (1.383205 --> 1.378950).  Saving model ...
Validation loss decreased (1.378950 --> 1.374832).  Saving model ...
Validation loss decreased (1.374832 --> 1.370932).  Saving model ...
Validation loss decreased (1.370932 --> 1.367122).  Saving model ...
Validation loss decreased (1.367122 --> 1.363422).  Saving model ...
Validation loss decreased (1.363422 --> 1.359813).  Saving model ...
Validation loss decreased (1.359813 --> 1.355920).  Saving model ...
Validation loss decreased (1.355920 --> 1.352425).  Saving model ...
Validation loss decreased (1.352425 --> 1.348827).  Saving model ...
Validation loss decreased (1.348827 --> 1.345163).  Saving model ...
Validation loss decreased (1.345163 --> 1.341188).  Saving model ...
Validation loss decreased (1.341188 --> 1.336919).  Saving model ...
Validation loss decreased (1.336919 --> 1.332396).  Saving model ...
Validation loss decreased (1.332396 --> 1.327821).  Saving model ...
Validation loss decreased (1.327821 --> 1.323125).  Saving model ...
Validation loss decreased (1.323125 --> 1.317889).  Saving model ...
Validation loss decreased (1.317889 --> 1.312892).  Saving model ...
Validation loss decreased (1.312892 --> 1.307540).  Saving model ...
Validation loss decreased (1.307540 --> 1.301050).  Saving model ...
Validation loss decreased (1.301050 --> 1.294891).  Saving model ...
Validation loss decreased (1.294891 --> 1.288332).  Saving model ...
Validation loss decreased (1.288332 --> 1.281812).  Saving model ...
Validation loss decreased (1.281812 --> 1.275418).  Saving model ...
Validation loss decreased (1.275418 --> 1.268253).  Saving model ...
Validation loss decreased (1.268253 --> 1.260781).  Saving model ...
Validation loss decreased (1.260781 --> 1.253849).  Saving model ...
Validation loss decreased (1.253849 --> 1.247136).  Saving model ...
Validation loss decreased (1.247136 --> 1.238668).  Saving model ...
Validation loss decreased (1.238668 --> 1.230571).  Saving model ...
Validation loss decreased (1.230571 --> 1.223175).  Saving model ...
Validation loss decreased (1.223175 --> 1.215619).  Saving model ...
Validation loss decreased (1.215619 --> 1.207706).  Saving model ...
Validation loss decreased (1.207706 --> 1.200363).  Saving model ...
Validation loss decreased (1.200363 --> 1.192562).  Saving model ...
Validation loss decreased (1.192562 --> 1.185530).  Saving model ...
Validation loss decreased (1.185530 --> 1.178891).  Saving model ...
Validation loss decreased (1.178891 --> 1.171389).  Saving model ...
Validation loss decreased (1.171389 --> 1.165513).  Saving model ...
Validation loss decreased (1.165513 --> 1.159452).  Saving model ...
Validation loss decreased (1.159452 --> 1.152918).  Saving model ...
Validation loss decreased (1.152918 --> 1.146308).  Saving model ...
Validation loss decreased (1.146308 --> 1.139954).  Saving model ...
Validation loss decreased (1.139954 --> 1.133992).  Saving model ...
Validation loss decreased (1.133992 --> 1.127479).  Saving model ...
Validation loss decreased (1.127479 --> 1.121267).  Saving model ...
Validation loss decreased (1.121267 --> 1.115498).  Saving model ...
Validation loss decreased (1.115498 --> 1.110310).  Saving model ...
Validation loss decreased (1.110310 --> 1.103991).  Saving model ...
Validation loss decreased (1.103991 --> 1.098997).  Saving model ...
Validation loss decreased (1.098997 --> 1.093121).  Saving model ...
Validation loss decreased (1.093121 --> 1.088137).  Saving model ...
Validation loss decreased (1.088137 --> 1.083331).  Saving model ...
Validation loss decreased (1.083331 --> 1.078039).  Saving model ...
Validation loss decreased (1.078039 --> 1.072474).  Saving model ...
Validation loss decreased (1.072474 --> 1.068984).  Saving model ...
Validation loss decreased (1.068984 --> 1.065263).  Saving model ...
Validation loss decreased (1.065263 --> 1.060492).  Saving model ...
Validation loss decreased (1.060492 --> 1.054920).  Saving model ...
Validation loss decreased (1.054920 --> 1.052353).  Saving model ...
Validation loss decreased (1.052353 --> 1.046293).  Saving model ...
Validation loss decreased (1.046293 --> 1.041604).  Saving model ...
Validation loss decreased (1.041604 --> 1.038351).  Saving model ...
Validation loss decreased (1.038351 --> 1.034586).  Saving model ...
Validation loss decreased (1.034586 --> 1.029735).  Saving model ...
Validation loss decreased (1.029735 --> 1.026122).  Saving model ...
Validation loss decreased (1.026122 --> 1.022654).  Saving model ...
Validation loss decreased (1.022654 --> 1.018326).  Saving model ...
Validation loss decreased (1.018326 --> 1.016013).  Saving model ...
Validation loss decreased (1.016013 --> 1.014422).  Saving model ...
Validation loss decreased (1.014422 --> 1.009932).  Saving model ...
Validation loss decreased (1.009932 --> 1.007549).  Saving model ...
Validation loss decreased (1.007549 --> 1.004533).  Saving model ...
Validation loss decreased (1.004533 --> 1.000941).  Saving model ...
Validation loss decreased (1.000941 --> 0.998339).  Saving model ...
Validation loss decreased (0.998339 --> 0.994133).  Saving model ...
Validation loss decreased (0.994133 --> 0.990858).  Saving model ...
Validation loss decreased (0.990858 --> 0.988968).  Saving model ...
Validation loss decreased (0.988968 --> 0.985696).  Saving model ...
Validation loss decreased (0.985696 --> 0.983559).  Saving model ...
Validation loss decreased (0.983559 --> 0.982592).  Saving model ...
Validation loss decreased (0.982592 --> 0.979237).  Saving model ...
Validation loss decreased (0.979237 --> 0.976732).  Saving model ...
Validation loss decreased (0.976732 --> 0.974419).  Saving model ...
Validation loss decreased (0.974419 --> 0.973042).  Saving model ...
Validation loss decreased (0.973042 --> 0.972902).  Saving model ...
Validation loss decreased (0.972902 --> 0.969500).  Saving model ...
Validation loss decreased (0.969500 --> 0.967386).  Saving model ...
Validation loss decreased (0.967386 --> 0.964876).  Saving model ...
Validation loss decreased (0.964876 --> 0.964149).  Saving model ...
Validation loss decreased (0.964149 --> 0.961388).  Saving model ...
Validation loss decreased (0.961388 --> 0.959534).  Saving model ...
Validation loss decreased (0.959534 --> 0.957714).  Saving model ...
Validation loss decreased (0.957714 --> 0.956379).  Saving model ...
Validation loss decreased (0.956379 --> 0.955508).  Saving model ...
Validation loss decreased (0.955508 --> 0.953449).  Saving model ...
Validation loss decreased (0.953449 --> 0.951154).  Saving model ...
Validation loss decreased (0.951154 --> 0.949147).  Saving model ...
Validation loss decreased (0.949147 --> 0.947953).  Saving model ...
Validation loss decreased (0.947953 --> 0.947190).  Saving model ...
Validation loss decreased (0.947190 --> 0.945339).  Saving model ...
Validation loss decreased (0.945339 --> 0.944032).  Saving model ...
Validation loss decreased (0.944032 --> 0.942753).  Saving model ...
Validation loss decreased (0.942753 --> 0.940639).  Saving model ...
Validation loss decreased (0.940639 --> 0.939471).  Saving model ...
Validation loss decreased (0.939471 --> 0.938355).  Saving model ...
Validation loss decreased (0.938355 --> 0.936318).  Saving model ...
Validation loss decreased (0.936318 --> 0.934813).  Saving model ...
Validation loss decreased (0.934813 --> 0.933663).  Saving model ...
Validation loss decreased (0.933663 --> 0.933278).  Saving model ...
Validation loss decreased (0.933278 --> 0.931980).  Saving model ...
EarlyStopping counter: 1 out of 5.0
Validation loss decreased (0.931980 --> 0.930921).  Saving model ...
EarlyStopping counter: 1 out of 5.0
Validation loss decreased (0.930921 --> 0.930909).  Saving model ...
Validation loss decreased (0.930909 --> 0.930675).  Saving model ...
Validation loss decreased (0.930675 --> 0.930435).  Saving model ...
Validation loss decreased (0.930435 --> 0.929080).  Saving model ...
Validation loss decreased (0.929080 --> 0.928394).  Saving model ...
EarlyStopping counter: 1 out of 5.0
Validation loss decreased (0.928394 --> 0.927803).  Saving model ...
Validation loss decreased (0.927803 --> 0.927076).  Saving model ...
Validation loss decreased (0.927076 --> 0.926402).  Saving model ...
EarlyStopping counter: 1 out of 5.0
Validation loss decreased (0.926402 --> 0.925928).  Saving model ...
Validation loss decreased (0.925928 --> 0.924720).  Saving model ...
EarlyStopping counter: 1 out of 5.0
EarlyStopping counter: 2 out of 5.0
EarlyStopping counter: 3 out of 5.0
EarlyStopping counter: 4 out of 5.0
EarlyStopping counter: 5 out of 5.0
/localscratch/yinan.29351867.0/env/lib/python3.7/site-packages/torch/nn/functional.py:1794: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.
  warnings.warn("nn.functional.tanh is deprecated. Use torch.tanh instead.")
wandb: Waiting for W&B process to finish, PID 49571... (success).
wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: \ 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: | 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: / 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: \ 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: | 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: / 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: \ 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: | 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb:                                                                                
wandb: Run history:
wandb:     e_F1 ▁▁▃▄▄▅▅▅▅▅▆▆▆▆▇▇▇▇▇▇▇▇▇▇▇▇▇█████████████
wandb:   e_loss ██▇▇▇▇▇▆▆▆▅▅▅▄▄▄▃▃▃▃▃▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁
wandb:     t_F1 ▁▂▂▂▂▃▃▄▄▄▄▅▅▅▅▅▆▆▅▆▆▆▆▇▇▆▇▆▇▇▇▇▇▇███▇██
wandb:   t_loss ██▇▇▇▇▇▇▆▆▆▆▆▅▅▅▅▅▅▄▄▄▃▃▃▃▃▃▂▃▂▂▂▂▂▁▂▂▁▁
wandb: 
wandb: Run summary:
wandb:     e_F1 61.2515
wandb:   e_loss 0.92578
wandb:     t_F1 72.47963
wandb:   t_loss 0.76391
wandb: 
wandb: Synced 4 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Synced silver-valley-2: https://wandb.ai/yinanazhou/xl_512_bs_8_lr_1e06_es_5_lc_True_nr_True_sr_False_stem_False_lemma_False_repeat_1_fold_2/runs/2595oqu9
wandb: Find logs at: ./wandb/run-20220324_080119-2595oqu9/logs/debug.log
wandb: 

wandb: wandb version 0.12.11 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
2022-03-24 09:31:59.790190: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1
wandb: Tracking run with wandb version 0.12.5
wandb: Syncing run wild-silence-2
wandb: ⭐️ View project at https://wandb.ai/yinanazhou/xl_512_bs_8_lr_1e06_es_5_lc_True_nr_True_sr_False_stem_False_lemma_False_repeat_2_fold_1
wandb: 🚀 View run at https://wandb.ai/yinanazhou/xl_512_bs_8_lr_1e06_es_5_lc_True_nr_True_sr_False_stem_False_lemma_False_repeat_2_fold_1/runs/62k3o6eg
wandb: Run data is saved locally in /project/6002780/yinan/Thesis_MER_Lyrics/lyric-emotion/wandb/run-20220324_093156-62k3o6eg
wandb: Run `wandb offline` to turn off syncing.

Validation loss decreased (inf --> 1.412877).  Saving model ...
Validation loss decreased (1.412877 --> 1.400013).  Saving model ...
Validation loss decreased (1.400013 --> 1.390166).  Saving model ...
Validation loss decreased (1.390166 --> 1.382783).  Saving model ...
Validation loss decreased (1.382783 --> 1.376945).  Saving model ...
Validation loss decreased (1.376945 --> 1.371683).  Saving model ...
Validation loss decreased (1.371683 --> 1.367451).  Saving model ...
Validation loss decreased (1.367451 --> 1.363655).  Saving model ...
Validation loss decreased (1.363655 --> 1.359831).  Saving model ...
Validation loss decreased (1.359831 --> 1.356018).  Saving model ...
Validation loss decreased (1.356018 --> 1.351955).  Saving model ...
Validation loss decreased (1.351955 --> 1.348474).  Saving model ...
Validation loss decreased (1.348474 --> 1.344508).  Saving model ...
Validation loss decreased (1.344508 --> 1.340514).  Saving model ...
Validation loss decreased (1.340514 --> 1.336176).  Saving model ...
Validation loss decreased (1.336176 --> 1.331854).  Saving model ...
Validation loss decreased (1.331854 --> 1.327405).  Saving model ...
Validation loss decreased (1.327405 --> 1.323228).  Saving model ...
Validation loss decreased (1.323228 --> 1.318394).  Saving model ...
Validation loss decreased (1.318394 --> 1.312604).  Saving model ...
Validation loss decreased (1.312604 --> 1.306844).  Saving model ...
Validation loss decreased (1.306844 --> 1.299513).  Saving model ...
Validation loss decreased (1.299513 --> 1.292060).  Saving model ...
Validation loss decreased (1.292060 --> 1.285228).  Saving model ...
Validation loss decreased (1.285228 --> 1.277172).  Saving model ...
Validation loss decreased (1.277172 --> 1.267661).  Saving model ...
Validation loss decreased (1.267661 --> 1.260593).  Saving model ...
Validation loss decreased (1.260593 --> 1.252283).  Saving model ...
Validation loss decreased (1.252283 --> 1.243345).  Saving model ...
Validation loss decreased (1.243345 --> 1.234840).  Saving model ...
Validation loss decreased (1.234840 --> 1.226778).  Saving model ...
Validation loss decreased (1.226778 --> 1.218171).  Saving model ...
Validation loss decreased (1.218171 --> 1.211000).  Saving model ...
Validation loss decreased (1.211000 --> 1.204563).  Saving model ...
Validation loss decreased (1.204563 --> 1.198035).  Saving model ...
Validation loss decreased (1.198035 --> 1.190574).  Saving model ...
Validation loss decreased (1.190574 --> 1.183306).  Saving model ...
Validation loss decreased (1.183306 --> 1.177914).  Saving model ...
Validation loss decreased (1.177914 --> 1.172179).  Saving model ...
Validation loss decreased (1.172179 --> 1.165797).  Saving model ...
Validation loss decreased (1.165797 --> 1.159331).  Saving model ...
Validation loss decreased (1.159331 --> 1.156069).  Saving model ...
Validation loss decreased (1.156069 --> 1.150928).  Saving model ...
Validation loss decreased (1.150928 --> 1.146484).  Saving model ...
Validation loss decreased (1.146484 --> 1.141912).  Saving model ...
Validation loss decreased (1.141912 --> 1.135235).  Saving model ...
Validation loss decreased (1.135235 --> 1.131355).  Saving model ...
Validation loss decreased (1.131355 --> 1.128911).  Saving model ...
Validation loss decreased (1.128911 --> 1.122244).  Saving model ...
Validation loss decreased (1.122244 --> 1.118294).  Saving model ...
Validation loss decreased (1.118294 --> 1.114013).  Saving model ...
Validation loss decreased (1.114013 --> 1.111073).  Saving model ...
Validation loss decreased (1.111073 --> 1.105022).  Saving model ...
Validation loss decreased (1.105022 --> 1.099951).  Saving model ...
Validation loss decreased (1.099951 --> 1.095759).  Saving model ...
Validation loss decreased (1.095759 --> 1.091301).  Saving model ...
Validation loss decreased (1.091301 --> 1.086920).  Saving model ...
Validation loss decreased (1.086920 --> 1.083041).  Saving model ...
Validation loss decreased (1.083041 --> 1.082966).  Saving model ...
Validation loss decreased (1.082966 --> 1.077367).  Saving model ...
Validation loss decreased (1.077367 --> 1.071924).  Saving model ...
Validation loss decreased (1.071924 --> 1.068577).  Saving model ...
Validation loss decreased (1.068577 --> 1.066085).  Saving model ...
Validation loss decreased (1.066085 --> 1.064899).  Saving model ...
Validation loss decreased (1.064899 --> 1.061647).  Saving model ...
Validation loss decreased (1.061647 --> 1.059885).  Saving model ...
Validation loss decreased (1.059885 --> 1.056160).  Saving model ...
Validation loss decreased (1.056160 --> 1.049354).  Saving model ...
Validation loss decreased (1.049354 --> 1.046229).  Saving model ...
Validation loss decreased (1.046229 --> 1.044137).  Saving model ...
Validation loss decreased (1.044137 --> 1.042099).  Saving model ...
Validation loss decreased (1.042099 --> 1.040135).  Saving model ...
Validation loss decreased (1.040135 --> 1.037899).  Saving model ...
Validation loss decreased (1.037899 --> 1.035547).  Saving model ...
Validation loss decreased (1.035547 --> 1.031529).  Saving model ...
EarlyStopping counter: 1 out of 5.0
Validation loss decreased (1.031529 --> 1.029523).  Saving model ...
Validation loss decreased (1.029523 --> 1.025516).  Saving model ...
Validation loss decreased (1.025516 --> 1.022100).  Saving model ...
EarlyStopping counter: 1 out of 5.0
Validation loss decreased (1.022100 --> 1.020296).  Saving model ...
Validation loss decreased (1.020296 --> 1.015967).  Saving model ...
Validation loss decreased (1.015967 --> 1.013026).  Saving model ...
Validation loss decreased (1.013026 --> 1.012778).  Saving model ...
Validation loss decreased (1.012778 --> 1.009978).  Saving model ...
Validation loss decreased (1.009978 --> 1.007810).  Saving model ...
Validation loss decreased (1.007810 --> 1.006413).  Saving model ...
EarlyStopping counter: 1 out of 5.0
Validation loss decreased (1.006413 --> 1.002592).  Saving model ...
Validation loss decreased (1.002592 --> 1.000581).  Saving model ...
Validation loss decreased (1.000581 --> 1.000118).  Saving model ...
Validation loss decreased (1.000118 --> 0.999447).  Saving model ...
Validation loss decreased (0.999447 --> 0.996057).  Saving model ...
Validation loss decreased (0.996057 --> 0.994536).  Saving model ...
Validation loss decreased (0.994536 --> 0.991762).  Saving model ...
EarlyStopping counter: 1 out of 5.0
Validation loss decreased (0.991762 --> 0.990005).  Saving model ...
Validation loss decreased (0.990005 --> 0.986993).  Saving model ...
Validation loss decreased (0.986993 --> 0.985028).  Saving model ...
Validation loss decreased (0.985028 --> 0.981478).  Saving model ...
Validation loss decreased (0.981478 --> 0.979914).  Saving model ...
Validation loss decreased (0.979914 --> 0.977594).  Saving model ...
EarlyStopping counter: 1 out of 5.0
EarlyStopping counter: 2 out of 5.0
Validation loss decreased (0.977594 --> 0.976956).  Saving model ...
Validation loss decreased (0.976956 --> 0.974953).  Saving model ...
Validation loss decreased (0.974953 --> 0.974247).  Saving model ...
EarlyStopping counter: 1 out of 5.0
EarlyStopping counter: 2 out of 5.0
Validation loss decreased (0.974247 --> 0.974108).  Saving model ...
Validation loss decreased (0.974108 --> 0.969532).  Saving model ...
EarlyStopping counter: 1 out of 5.0
EarlyStopping counter: 2 out of 5.0
Validation loss decreased (0.969532 --> 0.969154).  Saving model ...
EarlyStopping counter: 1 out of 5.0
EarlyStopping counter: 2 out of 5.0
EarlyStopping counter: 3 out of 5.0
Validation loss decreased (0.969154 --> 0.967390).  Saving model ...
Validation loss decreased (0.967390 --> 0.965689).  Saving model ...
EarlyStopping counter: 1 out of 5.0
Validation loss decreased (0.965689 --> 0.963680).  Saving model ...
Validation loss decreased (0.963680 --> 0.962468).  Saving model ...
Validation loss decreased (0.962468 --> 0.961535).  Saving model ...
EarlyStopping counter: 1 out of 5.0
EarlyStopping counter: 2 out of 5.0
Validation loss decreased (0.961535 --> 0.961201).  Saving model ...
EarlyStopping counter: 1 out of 5.0
Validation loss decreased (0.961201 --> 0.959644).  Saving model ...
Validation loss decreased (0.959644 --> 0.958501).  Saving model ...
EarlyStopping counter: 1 out of 5.0
EarlyStopping counter: 2 out of 5.0
EarlyStopping counter: 3 out of 5.0
EarlyStopping counter: 4 out of 5.0
EarlyStopping counter: 5 out of 5.0
/localscratch/yinan.29351867.0/env/lib/python3.7/site-packages/torch/nn/functional.py:1794: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.
  warnings.warn("nn.functional.tanh is deprecated. Use torch.tanh instead.")
wandb: Waiting for W&B process to finish, PID 54428... (success).
wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: \ 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: | 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: / 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: \ 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: | 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: / 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: \ 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: | 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: / 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb:                                                                                
wandb: Run history:
wandb:     e_F1 ▁▂▅▅▆▆▆▆▇▆▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇█▇▇███████████
wandb:   e_loss ██▇▇▇▇▆▆▆▅▅▄▄▄▄▃▃▃▃▃▂▂▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁
wandb:     t_F1 ▁▁▂▃▃▃▄▄▄▄▅▅▅▅▅▆▆▆▆▆▇▆▇▇▆▇▇▇▇▇█▇▇███████
wandb:   t_loss ███▇▇▇▇▇▇▆▆▆▅▅▅▅▄▄▄▄▄▄▃▃▃▃▃▂▂▂▂▂▂▂▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:     e_F1 59.79758
wandb:   e_loss 0.95911
wandb:     t_F1 70.67201
wandb:   t_loss 0.76442
wandb: 
wandb: Synced 4 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Synced wild-silence-2: https://wandb.ai/yinanazhou/xl_512_bs_8_lr_1e06_es_5_lc_True_nr_True_sr_False_stem_False_lemma_False_repeat_2_fold_1/runs/62k3o6eg
wandb: Find logs at: ./wandb/run-20220324_093156-62k3o6eg/logs/debug.log
wandb: 

wandb: wandb version 0.12.11 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
2022-03-24 10:57:02.563695: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1
wandb: Tracking run with wandb version 0.12.5
wandb: Syncing run earthy-forest-2
wandb: ⭐️ View project at https://wandb.ai/yinanazhou/xl_512_bs_8_lr_1e06_es_5_lc_True_nr_True_sr_False_stem_False_lemma_False_repeat_2_fold_2
wandb: 🚀 View run at https://wandb.ai/yinanazhou/xl_512_bs_8_lr_1e06_es_5_lc_True_nr_True_sr_False_stem_False_lemma_False_repeat_2_fold_2/runs/2n8z2zgl
wandb: Run data is saved locally in /project/6002780/yinan/Thesis_MER_Lyrics/lyric-emotion/wandb/run-20220324_105700-2n8z2zgl
wandb: Run `wandb offline` to turn off syncing.

Validation loss decreased (inf --> 1.457296).  Saving model ...
Validation loss decreased (1.457296 --> 1.433166).  Saving model ...
Validation loss decreased (1.433166 --> 1.415774).  Saving model ...
Validation loss decreased (1.415774 --> 1.402045).  Saving model ...
Validation loss decreased (1.402045 --> 1.390698).  Saving model ...
Validation loss decreased (1.390698 --> 1.381973).  Saving model ...
Validation loss decreased (1.381973 --> 1.375023).  Saving model ...
Validation loss decreased (1.375023 --> 1.369770).  Saving model ...
Validation loss decreased (1.369770 --> 1.365167).  Saving model ...
Validation loss decreased (1.365167 --> 1.360934).  Saving model ...
Validation loss decreased (1.360934 --> 1.356860).  Saving model ...
Validation loss decreased (1.356860 --> 1.352833).  Saving model ...
Validation loss decreased (1.352833 --> 1.348912).  Saving model ...
Validation loss decreased (1.348912 --> 1.345096).  Saving model ...
Validation loss decreased (1.345096 --> 1.341164).  Saving model ...
Validation loss decreased (1.341164 --> 1.336860).  Saving model ...
Validation loss decreased (1.336860 --> 1.332858).  Saving model ...
Validation loss decreased (1.332858 --> 1.329047).  Saving model ...
Validation loss decreased (1.329047 --> 1.324230).  Saving model ...
Validation loss decreased (1.324230 --> 1.320062).  Saving model ...
Validation loss decreased (1.320062 --> 1.315918).  Saving model ...
Validation loss decreased (1.315918 --> 1.310731).  Saving model ...
Validation loss decreased (1.310731 --> 1.306024).  Saving model ...
Validation loss decreased (1.306024 --> 1.301381).  Saving model ...
Validation loss decreased (1.301381 --> 1.296158).  Saving model ...
Validation loss decreased (1.296158 --> 1.291017).  Saving model ...
Validation loss decreased (1.291017 --> 1.284751).  Saving model ...
Validation loss decreased (1.284751 --> 1.279970).  Saving model ...
Validation loss decreased (1.279970 --> 1.274425).  Saving model ...
Validation loss decreased (1.274425 --> 1.269602).  Saving model ...
Validation loss decreased (1.269602 --> 1.265019).  Saving model ...
Validation loss decreased (1.265019 --> 1.260044).  Saving model ...
Validation loss decreased (1.260044 --> 1.254136).  Saving model ...
Validation loss decreased (1.254136 --> 1.247949).  Saving model ...
Validation loss decreased (1.247949 --> 1.242851).  Saving model ...
Validation loss decreased (1.242851 --> 1.237111).  Saving model ...
Validation loss decreased (1.237111 --> 1.233334).  Saving model ...
Validation loss decreased (1.233334 --> 1.228235).  Saving model ...
Validation loss decreased (1.228235 --> 1.222880).  Saving model ...
Validation loss decreased (1.222880 --> 1.217684).  Saving model ...
Validation loss decreased (1.217684 --> 1.210849).  Saving model ...
Validation loss decreased (1.210849 --> 1.205672).  Saving model ...
Validation loss decreased (1.205672 --> 1.202324).  Saving model ...
Validation loss decreased (1.202324 --> 1.195998).  Saving model ...
Validation loss decreased (1.195998 --> 1.189971).  Saving model ...
Validation loss decreased (1.189971 --> 1.185309).  Saving model ...
Validation loss decreased (1.185309 --> 1.180667).  Saving model ...
Validation loss decreased (1.180667 --> 1.175697).  Saving model ...
Validation loss decreased (1.175697 --> 1.170737).  Saving model ...
Validation loss decreased (1.170737 --> 1.164799).  Saving model ...
Validation loss decreased (1.164799 --> 1.160656).  Saving model ...
Validation loss decreased (1.160656 --> 1.154732).  Saving model ...
Validation loss decreased (1.154732 --> 1.150442).  Saving model ...
Validation loss decreased (1.150442 --> 1.146330).  Saving model ...
Validation loss decreased (1.146330 --> 1.138376).  Saving model ...
Validation loss decreased (1.138376 --> 1.133693).  Saving model ...
Validation loss decreased (1.133693 --> 1.130330).  Saving model ...
Validation loss decreased (1.130330 --> 1.126950).  Saving model ...
Validation loss decreased (1.126950 --> 1.126593).  Saving model ...
Validation loss decreased (1.126593 --> 1.122444).  Saving model ...
Validation loss decreased (1.122444 --> 1.118365).  Saving model ...
Validation loss decreased (1.118365 --> 1.115879).  Saving model ...
Validation loss decreased (1.115879 --> 1.110116).  Saving model ...
Validation loss decreased (1.110116 --> 1.106137).  Saving model ...
Validation loss decreased (1.106137 --> 1.099260).  Saving model ...
Validation loss decreased (1.099260 --> 1.096131).  Saving model ...
Validation loss decreased (1.096131 --> 1.091829).  Saving model ...
Validation loss decreased (1.091829 --> 1.091043).  Saving model ...
Validation loss decreased (1.091043 --> 1.086709).  Saving model ...
Validation loss decreased (1.086709 --> 1.082882).  Saving model ...
Validation loss decreased (1.082882 --> 1.080242).  Saving model ...
Validation loss decreased (1.080242 --> 1.074515).  Saving model ...
Validation loss decreased (1.074515 --> 1.070411).  Saving model ...
Validation loss decreased (1.070411 --> 1.066048).  Saving model ...
Validation loss decreased (1.066048 --> 1.061931).  Saving model ...
Validation loss decreased (1.061931 --> 1.058629).  Saving model ...
Validation loss decreased (1.058629 --> 1.055404).  Saving model ...
Validation loss decreased (1.055404 --> 1.051383).  Saving model ...
Validation loss decreased (1.051383 --> 1.050575).  Saving model ...
Validation loss decreased (1.050575 --> 1.045863).  Saving model ...
Validation loss decreased (1.045863 --> 1.040095).  Saving model ...
Validation loss decreased (1.040095 --> 1.037075).  Saving model ...
Validation loss decreased (1.037075 --> 1.033573).  Saving model ...
Validation loss decreased (1.033573 --> 1.030722).  Saving model ...
Validation loss decreased (1.030722 --> 1.028921).  Saving model ...
Validation loss decreased (1.028921 --> 1.025961).  Saving model ...
Validation loss decreased (1.025961 --> 1.024974).  Saving model ...
Validation loss decreased (1.024974 --> 1.023459).  Saving model ...
Validation loss decreased (1.023459 --> 1.022754).  Saving model ...
Validation loss decreased (1.022754 --> 1.018346).  Saving model ...
Validation loss decreased (1.018346 --> 1.017387).  Saving model ...
Validation loss decreased (1.017387 --> 1.015537).  Saving model ...
EarlyStopping counter: 1 out of 5.0
Validation loss decreased (1.015537 --> 1.012718).  Saving model ...
Validation loss decreased (1.012718 --> 1.010649).  Saving model ...
Validation loss decreased (1.010649 --> 1.007254).  Saving model ...
Validation loss decreased (1.007254 --> 1.003216).  Saving model ...
Validation loss decreased (1.003216 --> 1.002776).  Saving model ...
Validation loss decreased (1.002776 --> 1.002204).  Saving model ...
Validation loss decreased (1.002204 --> 1.000374).  Saving model ...
Validation loss decreased (1.000374 --> 0.999356).  Saving model ...
Validation loss decreased (0.999356 --> 0.995372).  Saving model ...
Validation loss decreased (0.995372 --> 0.992574).  Saving model ...
Validation loss decreased (0.992574 --> 0.990080).  Saving model ...
Validation loss decreased (0.990080 --> 0.987291).  Saving model ...
Validation loss decreased (0.987291 --> 0.983829).  Saving model ...
Validation loss decreased (0.983829 --> 0.982041).  Saving model ...
Validation loss decreased (0.982041 --> 0.981034).  Saving model ...
Validation loss decreased (0.981034 --> 0.979902).  Saving model ...
EarlyStopping counter: 1 out of 5.0
Validation loss decreased (0.979902 --> 0.976245).  Saving model ...
Validation loss decreased (0.976245 --> 0.973946).  Saving model ...
Validation loss decreased (0.973946 --> 0.973272).  Saving model ...
EarlyStopping counter: 1 out of 5.0
Validation loss decreased (0.973272 --> 0.969311).  Saving model ...
Validation loss decreased (0.969311 --> 0.968965).  Saving model ...
Validation loss decreased (0.968965 --> 0.968640).  Saving model ...
Validation loss decreased (0.968640 --> 0.965346).  Saving model ...
EarlyStopping counter: 1 out of 5.0
Validation loss decreased (0.965346 --> 0.964179).  Saving model ...
Validation loss decreased (0.964179 --> 0.962340).  Saving model ...
Validation loss decreased (0.962340 --> 0.960315).  Saving model ...
Validation loss decreased (0.960315 --> 0.958525).  Saving model ...
EarlyStopping counter: 1 out of 5.0
EarlyStopping counter: 2 out of 5.0
Validation loss decreased (0.958525 --> 0.956221).  Saving model ...
EarlyStopping counter: 1 out of 5.0
EarlyStopping counter: 2 out of 5.0
Validation loss decreased (0.956221 --> 0.953512).  Saving model ...
EarlyStopping counter: 1 out of 5.0
EarlyStopping counter: 2 out of 5.0
Validation loss decreased (0.953512 --> 0.951232).  Saving model ...
Validation loss decreased (0.951232 --> 0.950483).  Saving model ...
EarlyStopping counter: 1 out of 5.0
EarlyStopping counter: 2 out of 5.0
Validation loss decreased (0.950483 --> 0.946936).  Saving model ...
EarlyStopping counter: 1 out of 5.0
EarlyStopping counter: 2 out of 5.0
EarlyStopping counter: 3 out of 5.0
EarlyStopping counter: 4 out of 5.0
Validation loss decreased (0.946936 --> 0.944891).  Saving model ...
EarlyStopping counter: 1 out of 5.0
Validation loss decreased (0.944891 --> 0.943048).  Saving model ...
Validation loss decreased (0.943048 --> 0.938431).  Saving model ...
EarlyStopping counter: 1 out of 5.0
EarlyStopping counter: 2 out of 5.0
EarlyStopping counter: 3 out of 5.0
EarlyStopping counter: 4 out of 5.0
EarlyStopping counter: 5 out of 5.0
/localscratch/yinan.29351867.0/env/lib/python3.7/site-packages/torch/nn/functional.py:1794: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.
  warnings.warn("nn.functional.tanh is deprecated. Use torch.tanh instead.")
wandb: Waiting for W&B process to finish, PID 58983... (success).
wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: \ 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: | 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: / 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: \ 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: | 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: / 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: \ 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: | 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: / 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb:                                                                                
wandb: Run history:
wandb:     e_F1 ▁▁▃▃▄▄▄▅▅▅▅▆▆▆▆▇▇▇▇▇▇▇▇▇▇▇▇▇▇███████████
wandb:   e_loss ██▇▇▇▆▆▆▆▅▅▅▄▄▄▄▄▃▃▃▃▃▂▂▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁
wandb:     t_F1 ▁▁▁▂▂▃▃▃▄▄▄▅▅▄▅▅▅▆▅▆▆▆▆▆▆▆▆▇▆▇▇▇▇▇▇█▇███
wandb:   t_loss ███▇▇▇▇▇▆▆▆▆▅▅▅▅▄▄▄▄▄▄▃▃▃▃▃▃▃▂▂▂▂▁▂▁▂▁▁▁
wandb: 
wandb: Run summary:
wandb:     e_F1 60.60203
wandb:   e_loss 0.94204
wandb:     t_F1 69.29495
wandb:   t_loss 0.78586
wandb: 
wandb: Synced 4 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Synced earthy-forest-2: https://wandb.ai/yinanazhou/xl_512_bs_8_lr_1e06_es_5_lc_True_nr_True_sr_False_stem_False_lemma_False_repeat_2_fold_2/runs/2n8z2zgl
wandb: Find logs at: ./wandb/run-20220324_105700-2n8z2zgl/logs/debug.log
wandb: 

wandb: wandb version 0.12.11 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
2022-03-24 12:32:03.891506: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1
wandb: Tracking run with wandb version 0.12.5
wandb: Syncing run worthy-flower-1
wandb: ⭐️ View project at https://wandb.ai/yinanazhou/xl_512_bs_8_lr_1e06_es_5_lc_True_nr_True_sr_False_stem_False_lemma_False_repeat_3_fold_1
wandb: 🚀 View run at https://wandb.ai/yinanazhou/xl_512_bs_8_lr_1e06_es_5_lc_True_nr_True_sr_False_stem_False_lemma_False_repeat_3_fold_1/runs/2kl0tapg
wandb: Run data is saved locally in /project/6002780/yinan/Thesis_MER_Lyrics/lyric-emotion/wandb/run-20220324_123200-2kl0tapg
wandb: Run `wandb offline` to turn off syncing.

Validation loss decreased (inf --> 1.404067).  Saving model ...
Validation loss decreased (1.404067 --> 1.396671).  Saving model ...
Validation loss decreased (1.396671 --> 1.390401).  Saving model ...
Validation loss decreased (1.390401 --> 1.385298).  Saving model ...
Validation loss decreased (1.385298 --> 1.380789).  Saving model ...
Validation loss decreased (1.380789 --> 1.376481).  Saving model ...
Validation loss decreased (1.376481 --> 1.372654).  Saving model ...
Validation loss decreased (1.372654 --> 1.368683).  Saving model ...
Validation loss decreased (1.368683 --> 1.364510).  Saving model ...
Validation loss decreased (1.364510 --> 1.360500).  Saving model ...
Validation loss decreased (1.360500 --> 1.356606).  Saving model ...
Validation loss decreased (1.356606 --> 1.352760).  Saving model ...
Validation loss decreased (1.352760 --> 1.348887).  Saving model ...
Validation loss decreased (1.348887 --> 1.344599).  Saving model ...
Validation loss decreased (1.344599 --> 1.340180).  Saving model ...
Validation loss decreased (1.340180 --> 1.335676).  Saving model ...
Validation loss decreased (1.335676 --> 1.331480).  Saving model ...
Validation loss decreased (1.331480 --> 1.326621).  Saving model ...
Validation loss decreased (1.326621 --> 1.321665).  Saving model ...
Validation loss decreased (1.321665 --> 1.316338).  Saving model ...
Validation loss decreased (1.316338 --> 1.310430).  Saving model ...
Validation loss decreased (1.310430 --> 1.304358).  Saving model ...
Validation loss decreased (1.304358 --> 1.298281).  Saving model ...
Validation loss decreased (1.298281 --> 1.292615).  Saving model ...
Validation loss decreased (1.292615 --> 1.285587).  Saving model ...
Validation loss decreased (1.285587 --> 1.278164).  Saving model ...
Validation loss decreased (1.278164 --> 1.271500).  Saving model ...
Validation loss decreased (1.271500 --> 1.265500).  Saving model ...
Validation loss decreased (1.265500 --> 1.259843).  Saving model ...
Validation loss decreased (1.259843 --> 1.252234).  Saving model ...
Validation loss decreased (1.252234 --> 1.244957).  Saving model ...
Validation loss decreased (1.244957 --> 1.238156).  Saving model ...
Validation loss decreased (1.238156 --> 1.229948).  Saving model ...
Validation loss decreased (1.229948 --> 1.224203).  Saving model ...
Validation loss decreased (1.224203 --> 1.218234).  Saving model ...
Validation loss decreased (1.218234 --> 1.211847).  Saving model ...
Validation loss decreased (1.211847 --> 1.204438).  Saving model ...
Validation loss decreased (1.204438 --> 1.197951).  Saving model ...
Validation loss decreased (1.197951 --> 1.191742).  Saving model ...
Validation loss decreased (1.191742 --> 1.186740).  Saving model ...
Validation loss decreased (1.186740 --> 1.181525).  Saving model ...
Validation loss decreased (1.181525 --> 1.177060).  Saving model ...
Validation loss decreased (1.177060 --> 1.170531).  Saving model ...
Validation loss decreased (1.170531 --> 1.164349).  Saving model ...
Validation loss decreased (1.164349 --> 1.161217).  Saving model ...
Validation loss decreased (1.161217 --> 1.157171).  Saving model ...
Validation loss decreased (1.157171 --> 1.151334).  Saving model ...
Validation loss decreased (1.151334 --> 1.144895).  Saving model ...
Validation loss decreased (1.144895 --> 1.141487).  Saving model ...
Validation loss decreased (1.141487 --> 1.140098).  Saving model ...
Validation loss decreased (1.140098 --> 1.133501).  Saving model ...
Validation loss decreased (1.133501 --> 1.128866).  Saving model ...
Validation loss decreased (1.128866 --> 1.124134).  Saving model ...
Validation loss decreased (1.124134 --> 1.120057).  Saving model ...
Validation loss decreased (1.120057 --> 1.118506).  Saving model ...
Validation loss decreased (1.118506 --> 1.117443).  Saving model ...
Validation loss decreased (1.117443 --> 1.113129).  Saving model ...
Validation loss decreased (1.113129 --> 1.109919).  Saving model ...
Validation loss decreased (1.109919 --> 1.102546).  Saving model ...
Validation loss decreased (1.102546 --> 1.099330).  Saving model ...
Validation loss decreased (1.099330 --> 1.096012).  Saving model ...
Validation loss decreased (1.096012 --> 1.091821).  Saving model ...
Validation loss decreased (1.091821 --> 1.090756).  Saving model ...
Validation loss decreased (1.090756 --> 1.085586).  Saving model ...
Validation loss decreased (1.085586 --> 1.082885).  Saving model ...
Validation loss decreased (1.082885 --> 1.079332).  Saving model ...
Validation loss decreased (1.079332 --> 1.076815).  Saving model ...
Validation loss decreased (1.076815 --> 1.075100).  Saving model ...
Validation loss decreased (1.075100 --> 1.074645).  Saving model ...
Validation loss decreased (1.074645 --> 1.070033).  Saving model ...
Validation loss decreased (1.070033 --> 1.065937).  Saving model ...
Validation loss decreased (1.065937 --> 1.063153).  Saving model ...
Validation loss decreased (1.063153 --> 1.061424).  Saving model ...
Validation loss decreased (1.061424 --> 1.060589).  Saving model ...
EarlyStopping counter: 1 out of 5.0
Validation loss decreased (1.060589 --> 1.060023).  Saving model ...
Validation loss decreased (1.060023 --> 1.056182).  Saving model ...
Validation loss decreased (1.056182 --> 1.055026).  Saving model ...
Validation loss decreased (1.055026 --> 1.051840).  Saving model ...
Validation loss decreased (1.051840 --> 1.049973).  Saving model ...
Validation loss decreased (1.049973 --> 1.048270).  Saving model ...
Validation loss decreased (1.048270 --> 1.040812).  Saving model ...
Validation loss decreased (1.040812 --> 1.037279).  Saving model ...
Validation loss decreased (1.037279 --> 1.034599).  Saving model ...
EarlyStopping counter: 1 out of 5.0
EarlyStopping counter: 2 out of 5.0
Validation loss decreased (1.034599 --> 1.031469).  Saving model ...
Validation loss decreased (1.031469 --> 1.027926).  Saving model ...
Validation loss decreased (1.027926 --> 1.027902).  Saving model ...
EarlyStopping counter: 1 out of 5.0
EarlyStopping counter: 2 out of 5.0
Validation loss decreased (1.027902 --> 1.022332).  Saving model ...
Validation loss decreased (1.022332 --> 1.018200).  Saving model ...
Validation loss decreased (1.018200 --> 1.017060).  Saving model ...
Validation loss decreased (1.017060 --> 1.016841).  Saving model ...
EarlyStopping counter: 1 out of 5.0
Validation loss decreased (1.016841 --> 1.014466).  Saving model ...
Validation loss decreased (1.014466 --> 1.013740).  Saving model ...
Validation loss decreased (1.013740 --> 1.011599).  Saving model ...
EarlyStopping counter: 1 out of 5.0
Validation loss decreased (1.011599 --> 1.009521).  Saving model ...
Validation loss decreased (1.009521 --> 1.007675).  Saving model ...
Validation loss decreased (1.007675 --> 1.006482).  Saving model ...
Validation loss decreased (1.006482 --> 1.005409).  Saving model ...
Validation loss decreased (1.005409 --> 1.005060).  Saving model ...
EarlyStopping counter: 1 out of 5.0
Validation loss decreased (1.005060 --> 1.003186).  Saving model ...
EarlyStopping counter: 1 out of 5.0
EarlyStopping counter: 2 out of 5.0
EarlyStopping counter: 3 out of 5.0
Validation loss decreased (1.003186 --> 1.002056).  Saving model ...
Validation loss decreased (1.002056 --> 1.000918).  Saving model ...
Validation loss decreased (1.000918 --> 0.996405).  Saving model ...
EarlyStopping counter: 1 out of 5.0
Validation loss decreased (0.996405 --> 0.996290).  Saving model ...
Validation loss decreased (0.996290 --> 0.995945).  Saving model ...
Validation loss decreased (0.995945 --> 0.995648).  Saving model ...
Validation loss decreased (0.995648 --> 0.993948).  Saving model ...
Validation loss decreased (0.993948 --> 0.993472).  Saving model ...
Validation loss decreased (0.993472 --> 0.991270).  Saving model ...
EarlyStopping counter: 1 out of 5.0
EarlyStopping counter: 2 out of 5.0
EarlyStopping counter: 3 out of 5.0
EarlyStopping counter: 4 out of 5.0
EarlyStopping counter: 5 out of 5.0
/localscratch/yinan.29351867.0/env/lib/python3.7/site-packages/torch/nn/functional.py:1794: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.
  warnings.warn("nn.functional.tanh is deprecated. Use torch.tanh instead.")
wandb: Waiting for W&B process to finish, PID 64115... (success).
wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: \ 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: | 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: / 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: \ 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: | 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: / 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: \ 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: | 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: / 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: \ 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: | 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: / 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb:                                                                                
wandb: Run history:
wandb:     e_F1 ▁▂▃▃▄▅▅▅▆▆▆▆▇▇▆▇▇▇▇▇▇▇▇▇▇▇██████████████
wandb:   e_loss ██▇▇▇▇▇▆▆▆▅▅▄▄▄▄▃▃▃▃▃▂▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁
wandb:     t_F1 ▁▁▂▃▃▃▃▄▄▄▅▅▄▆▅▆▆▆▆▆▆▆▇▆▇▇▇▇▇▇▇▇▇▇██████
wandb:   t_loss ███▇▇▇▇▇▆▆▆▆▆▅▅▅▄▄▄▄▄▄▃▃▃▃▃▃▂▂▂▂▂▂▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:     e_F1 55.51023
wandb:   e_loss 0.99338
wandb:     t_F1 72.94258
wandb:   t_loss 0.77689
wandb: 
wandb: Synced 4 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Synced worthy-flower-1: https://wandb.ai/yinanazhou/xl_512_bs_8_lr_1e06_es_5_lc_True_nr_True_sr_False_stem_False_lemma_False_repeat_3_fold_1/runs/2kl0tapg
wandb: Find logs at: ./wandb/run-20220324_123200-2kl0tapg/logs/debug.log
wandb: 

wandb: wandb version 0.12.11 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
2022-03-24 13:51:49.604984: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1
wandb: Tracking run with wandb version 0.12.5
wandb: Syncing run splendid-durian-1
wandb: ⭐️ View project at https://wandb.ai/yinanazhou/xl_512_bs_8_lr_1e06_es_5_lc_True_nr_True_sr_False_stem_False_lemma_False_repeat_3_fold_2
wandb: 🚀 View run at https://wandb.ai/yinanazhou/xl_512_bs_8_lr_1e06_es_5_lc_True_nr_True_sr_False_stem_False_lemma_False_repeat_3_fold_2/runs/3pbx0bth
wandb: Run data is saved locally in /project/6002780/yinan/Thesis_MER_Lyrics/lyric-emotion/wandb/run-20220324_135146-3pbx0bth
wandb: Run `wandb offline` to turn off syncing.

Validation loss decreased (inf --> 1.407028).  Saving model ...
Validation loss decreased (1.407028 --> 1.393011).  Saving model ...
Validation loss decreased (1.393011 --> 1.382564).  Saving model ...
Validation loss decreased (1.382564 --> 1.374736).  Saving model ...
Validation loss decreased (1.374736 --> 1.368155).  Saving model ...
Validation loss decreased (1.368155 --> 1.362476).  Saving model ...
Validation loss decreased (1.362476 --> 1.357174).  Saving model ...
Validation loss decreased (1.357174 --> 1.352662).  Saving model ...
Validation loss decreased (1.352662 --> 1.348461).  Saving model ...
Validation loss decreased (1.348461 --> 1.344192).  Saving model ...
Validation loss decreased (1.344192 --> 1.339946).  Saving model ...
Validation loss decreased (1.339946 --> 1.335764).  Saving model ...
Validation loss decreased (1.335764 --> 1.331664).  Saving model ...
Validation loss decreased (1.331664 --> 1.327012).  Saving model ...
Validation loss decreased (1.327012 --> 1.322086).  Saving model ...
Validation loss decreased (1.322086 --> 1.316942).  Saving model ...
Validation loss decreased (1.316942 --> 1.312168).  Saving model ...
Validation loss decreased (1.312168 --> 1.307273).  Saving model ...
Validation loss decreased (1.307273 --> 1.302466).  Saving model ...
Validation loss decreased (1.302466 --> 1.296995).  Saving model ...
Validation loss decreased (1.296995 --> 1.291817).  Saving model ...
Validation loss decreased (1.291817 --> 1.285817).  Saving model ...
Validation loss decreased (1.285817 --> 1.279266).  Saving model ...
Validation loss decreased (1.279266 --> 1.272199).  Saving model ...
Validation loss decreased (1.272199 --> 1.266489).  Saving model ...
Validation loss decreased (1.266489 --> 1.259522).  Saving model ...
Validation loss decreased (1.259522 --> 1.253497).  Saving model ...
Validation loss decreased (1.253497 --> 1.246086).  Saving model ...
Validation loss decreased (1.246086 --> 1.238201).  Saving model ...
Validation loss decreased (1.238201 --> 1.231033).  Saving model ...
Validation loss decreased (1.231033 --> 1.224022).  Saving model ...
Validation loss decreased (1.224022 --> 1.216754).  Saving model ...
Validation loss decreased (1.216754 --> 1.210011).  Saving model ...
Validation loss decreased (1.210011 --> 1.201426).  Saving model ...
Validation loss decreased (1.201426 --> 1.192568).  Saving model ...
Validation loss decreased (1.192568 --> 1.185029).  Saving model ...
Validation loss decreased (1.185029 --> 1.177941).  Saving model ...
Validation loss decreased (1.177941 --> 1.170007).  Saving model ...
Validation loss decreased (1.170007 --> 1.163587).  Saving model ...
Validation loss decreased (1.163587 --> 1.156316).  Saving model ...
Validation loss decreased (1.156316 --> 1.148679).  Saving model ...
Validation loss decreased (1.148679 --> 1.144387).  Saving model ...
Validation loss decreased (1.144387 --> 1.139441).  Saving model ...
Validation loss decreased (1.139441 --> 1.132694).  Saving model ...
Validation loss decreased (1.132694 --> 1.127432).  Saving model ...
Validation loss decreased (1.127432 --> 1.120780).  Saving model ...
Validation loss decreased (1.120780 --> 1.114975).  Saving model ...
Validation loss decreased (1.114975 --> 1.111041).  Saving model ...
Validation loss decreased (1.111041 --> 1.103961).  Saving model ...
Validation loss decreased (1.103961 --> 1.096875).  Saving model ...
Validation loss decreased (1.096875 --> 1.092173).  Saving model ...
Validation loss decreased (1.092173 --> 1.088831).  Saving model ...
Validation loss decreased (1.088831 --> 1.084827).  Saving model ...
Validation loss decreased (1.084827 --> 1.079559).  Saving model ...
Validation loss decreased (1.079559 --> 1.075466).  Saving model ...
Validation loss decreased (1.075466 --> 1.071822).  Saving model ...
Validation loss decreased (1.071822 --> 1.066683).  Saving model ...
Validation loss decreased (1.066683 --> 1.062254).  Saving model ...
Validation loss decreased (1.062254 --> 1.057644).  Saving model ...
Validation loss decreased (1.057644 --> 1.053355).  Saving model ...
Validation loss decreased (1.053355 --> 1.048883).  Saving model ...
Validation loss decreased (1.048883 --> 1.046288).  Saving model ...
Validation loss decreased (1.046288 --> 1.042439).  Saving model ...
Validation loss decreased (1.042439 --> 1.038599).  Saving model ...
Validation loss decreased (1.038599 --> 1.035720).  Saving model ...
Validation loss decreased (1.035720 --> 1.031881).  Saving model ...
Validation loss decreased (1.031881 --> 1.026905).  Saving model ...
Validation loss decreased (1.026905 --> 1.022886).  Saving model ...
Validation loss decreased (1.022886 --> 1.019560).  Saving model ...
Validation loss decreased (1.019560 --> 1.016112).  Saving model ...
Validation loss decreased (1.016112 --> 1.013382).  Saving model ...
Validation loss decreased (1.013382 --> 1.010309).  Saving model ...
Validation loss decreased (1.010309 --> 1.006143).  Saving model ...
Validation loss decreased (1.006143 --> 1.003835).  Saving model ...
Validation loss decreased (1.003835 --> 1.000560).  Saving model ...
Validation loss decreased (1.000560 --> 0.998014).  Saving model ...
Validation loss decreased (0.998014 --> 0.994165).  Saving model ...
Validation loss decreased (0.994165 --> 0.990475).  Saving model ...
Validation loss decreased (0.990475 --> 0.987448).  Saving model ...
Validation loss decreased (0.987448 --> 0.984006).  Saving model ...
Validation loss decreased (0.984006 --> 0.982000).  Saving model ...
Validation loss decreased (0.982000 --> 0.978668).  Saving model ...
Validation loss decreased (0.978668 --> 0.977482).  Saving model ...
Validation loss decreased (0.977482 --> 0.973795).  Saving model ...
Validation loss decreased (0.973795 --> 0.971461).  Saving model ...
Validation loss decreased (0.971461 --> 0.968971).  Saving model ...
Validation loss decreased (0.968971 --> 0.967913).  Saving model ...
Validation loss decreased (0.967913 --> 0.965884).  Saving model ...
Validation loss decreased (0.965884 --> 0.963359).  Saving model ...
Validation loss decreased (0.963359 --> 0.961170).  Saving model ...
Validation loss decreased (0.961170 --> 0.959647).  Saving model ...
Validation loss decreased (0.959647 --> 0.957448).  Saving model ...
Validation loss decreased (0.957448 --> 0.956000).  Saving model ...
Validation loss decreased (0.956000 --> 0.953954).  Saving model ...
Validation loss decreased (0.953954 --> 0.951338).  Saving model ...
Validation loss decreased (0.951338 --> 0.949636).  Saving model ...
Validation loss decreased (0.949636 --> 0.948383).  Saving model ...
Validation loss decreased (0.948383 --> 0.945831).  Saving model ...
Validation loss decreased (0.945831 --> 0.945287).  Saving model ...
Validation loss decreased (0.945287 --> 0.944955).  Saving model ...
EarlyStopping counter: 1 out of 5.0
Validation loss decreased (0.944955 --> 0.943712).  Saving model ...
Validation loss decreased (0.943712 --> 0.942767).  Saving model ...
Validation loss decreased (0.942767 --> 0.938417).  Saving model ...
Validation loss decreased (0.938417 --> 0.937781).  Saving model ...
Validation loss decreased (0.937781 --> 0.936386).  Saving model ...
Validation loss decreased (0.936386 --> 0.934477).  Saving model ...
Validation loss decreased (0.934477 --> 0.931958).  Saving model ...
Validation loss decreased (0.931958 --> 0.929608).  Saving model ...
Validation loss decreased (0.929608 --> 0.927977).  Saving model ...
Validation loss decreased (0.927977 --> 0.926473).  Saving model ...
Validation loss decreased (0.926473 --> 0.925605).  Saving model ...
EarlyStopping counter: 1 out of 5.0
Validation loss decreased (0.925605 --> 0.925408).  Saving model ...
Validation loss decreased (0.925408 --> 0.924587).  Saving model ...
Validation loss decreased (0.924587 --> 0.922887).  Saving model ...
EarlyStopping counter: 1 out of 5.0
Validation loss decreased (0.922887 --> 0.920842).  Saving model ...
Validation loss decreased (0.920842 --> 0.919994).  Saving model ...
Validation loss decreased (0.919994 --> 0.919528).  Saving model ...
Validation loss decreased (0.919528 --> 0.918872).  Saving model ...
Validation loss decreased (0.918872 --> 0.916910).  Saving model ...
Validation loss decreased (0.916910 --> 0.916804).  Saving model ...
Validation loss decreased (0.916804 --> 0.916427).  Saving model ...
Validation loss decreased (0.916427 --> 0.915329).  Saving model ...
Validation loss decreased (0.915329 --> 0.914113).  Saving model ...
EarlyStopping counter: 1 out of 5.0
EarlyStopping counter: 2 out of 5.0
Validation loss decreased (0.914113 --> 0.912991).  Saving model ...
EarlyStopping counter: 1 out of 5.0
EarlyStopping counter: 2 out of 5.0
EarlyStopping counter: 3 out of 5.0
Validation loss decreased (0.912991 --> 0.912953).  Saving model ...
Validation loss decreased (0.912953 --> 0.911974).  Saving model ...
Validation loss decreased (0.911974 --> 0.910565).  Saving model ...
EarlyStopping counter: 1 out of 5.0
EarlyStopping counter: 2 out of 5.0
EarlyStopping counter: 3 out of 5.0
EarlyStopping counter: 4 out of 5.0
Validation loss decreased (0.910565 --> 0.910358).  Saving model ...
Validation loss decreased (0.910358 --> 0.909157).  Saving model ...
EarlyStopping counter: 1 out of 5.0
EarlyStopping counter: 2 out of 5.0
EarlyStopping counter: 3 out of 5.0
Validation loss decreased (0.909157 --> 0.908608).  Saving model ...
EarlyStopping counter: 1 out of 5.0
EarlyStopping counter: 2 out of 5.0
Validation loss decreased (0.908608 --> 0.908345).  Saving model ...
Validation loss decreased (0.908345 --> 0.906532).  Saving model ...
EarlyStopping counter: 1 out of 5.0
EarlyStopping counter: 2 out of 5.0
EarlyStopping counter: 3 out of 5.0
EarlyStopping counter: 4 out of 5.0
EarlyStopping counter: 5 out of 5.0
/localscratch/yinan.29351867.0/env/lib/python3.7/site-packages/torch/nn/functional.py:1794: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.
  warnings.warn("nn.functional.tanh is deprecated. Use torch.tanh instead.")
wandb: Waiting for W&B process to finish, PID 68562... (success).
wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: \ 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: | 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: / 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: \ 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: | 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: / 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: \ 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: | 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: / 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: \ 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: | 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb:                                                                                
wandb: Run history:
wandb:     e_F1 ▁▁▃▄▄▄▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇▇▇▇▇▇▇▇▇█▇█████████
wandb:   e_loss ██▇▇▇▇▆▆▅▅▅▄▄▄▃▃▃▃▂▂▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:     t_F1 ▁▁▂▂▃▃▃▄▄▄▅▅▅▅▅▆▆▆▇▆▆▆▆▇▇▇▇▇▇▇▇▇▇▇██████
wandb:   t_loss ███▇▇▇▇▇▆▆▆▅▅▅▅▅▄▄▄▄▃▃▃▃▃▂▂▂▂▂▂▂▂▂▂▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:     e_F1 63.43529
wandb:   e_loss 0.90701
wandb:     t_F1 71.11905
wandb:   t_loss 0.72413
wandb: 
wandb: Synced 4 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Synced splendid-durian-1: https://wandb.ai/yinanazhou/xl_512_bs_8_lr_1e06_es_5_lc_True_nr_True_sr_False_stem_False_lemma_False_repeat_3_fold_2/runs/3pbx0bth
wandb: Find logs at: ./wandb/run-20220324_135146-3pbx0bth/logs/debug.log
wandb: 

wandb: wandb version 0.12.11 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
2022-03-24 15:31:52.336564: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1
wandb: Tracking run with wandb version 0.12.5
wandb: Syncing run northern-pond-1
wandb: ⭐️ View project at https://wandb.ai/yinanazhou/xl_512_bs_8_lr_1e06_es_5_lc_True_nr_True_sr_False_stem_False_lemma_False_repeat_4_fold_1
wandb: 🚀 View run at https://wandb.ai/yinanazhou/xl_512_bs_8_lr_1e06_es_5_lc_True_nr_True_sr_False_stem_False_lemma_False_repeat_4_fold_1/runs/2k5rea2e
wandb: Run data is saved locally in /project/6002780/yinan/Thesis_MER_Lyrics/lyric-emotion/wandb/run-20220324_153150-2k5rea2e
wandb: Run `wandb offline` to turn off syncing.

Validation loss decreased (inf --> 1.399406).  Saving model ...
Validation loss decreased (1.399406 --> 1.390303).  Saving model ...
Validation loss decreased (1.390303 --> 1.382001).  Saving model ...
Validation loss decreased (1.382001 --> 1.375543).  Saving model ...
Validation loss decreased (1.375543 --> 1.369980).  Saving model ...
Validation loss decreased (1.369980 --> 1.365005).  Saving model ...
Validation loss decreased (1.365005 --> 1.360353).  Saving model ...
Validation loss decreased (1.360353 --> 1.355653).  Saving model ...
Validation loss decreased (1.355653 --> 1.351532).  Saving model ...
Validation loss decreased (1.351532 --> 1.346827).  Saving model ...
Validation loss decreased (1.346827 --> 1.342499).  Saving model ...
Validation loss decreased (1.342499 --> 1.337631).  Saving model ...
Validation loss decreased (1.337631 --> 1.332711).  Saving model ...
Validation loss decreased (1.332711 --> 1.327785).  Saving model ...
Validation loss decreased (1.327785 --> 1.322828).  Saving model ...
Validation loss decreased (1.322828 --> 1.318066).  Saving model ...
Validation loss decreased (1.318066 --> 1.312649).  Saving model ...
Validation loss decreased (1.312649 --> 1.306281).  Saving model ...
Validation loss decreased (1.306281 --> 1.300535).  Saving model ...
Validation loss decreased (1.300535 --> 1.293755).  Saving model ...
Validation loss decreased (1.293755 --> 1.287293).  Saving model ...
Validation loss decreased (1.287293 --> 1.280458).  Saving model ...
Validation loss decreased (1.280458 --> 1.273072).  Saving model ...
Validation loss decreased (1.273072 --> 1.265822).  Saving model ...
Validation loss decreased (1.265822 --> 1.258806).  Saving model ...
Validation loss decreased (1.258806 --> 1.252104).  Saving model ...
Validation loss decreased (1.252104 --> 1.245615).  Saving model ...
Validation loss decreased (1.245615 --> 1.239091).  Saving model ...
Validation loss decreased (1.239091 --> 1.233894).  Saving model ...
Validation loss decreased (1.233894 --> 1.227757).  Saving model ...
Validation loss decreased (1.227757 --> 1.221979).  Saving model ...
Validation loss decreased (1.221979 --> 1.216416).  Saving model ...
Validation loss decreased (1.216416 --> 1.210229).  Saving model ...
Validation loss decreased (1.210229 --> 1.204845).  Saving model ...
Validation loss decreased (1.204845 --> 1.200378).  Saving model ...
Validation loss decreased (1.200378 --> 1.194956).  Saving model ...
Validation loss decreased (1.194956 --> 1.189297).  Saving model ...
Validation loss decreased (1.189297 --> 1.184813).  Saving model ...
Validation loss decreased (1.184813 --> 1.179823).  Saving model ...
Validation loss decreased (1.179823 --> 1.176041).  Saving model ...
Validation loss decreased (1.176041 --> 1.171113).  Saving model ...
Validation loss decreased (1.171113 --> 1.167638).  Saving model ...
Validation loss decreased (1.167638 --> 1.162465).  Saving model ...
Validation loss decreased (1.162465 --> 1.158050).  Saving model ...
Validation loss decreased (1.158050 --> 1.152808).  Saving model ...
Validation loss decreased (1.152808 --> 1.147054).  Saving model ...
Validation loss decreased (1.147054 --> 1.142209).  Saving model ...
Validation loss decreased (1.142209 --> 1.138919).  Saving model ...
Validation loss decreased (1.138919 --> 1.135317).  Saving model ...
Validation loss decreased (1.135317 --> 1.131720).  Saving model ...
Validation loss decreased (1.131720 --> 1.127506).  Saving model ...
Validation loss decreased (1.127506 --> 1.123422).  Saving model ...
Validation loss decreased (1.123422 --> 1.119149).  Saving model ...
Validation loss decreased (1.119149 --> 1.114760).  Saving model ...
Validation loss decreased (1.114760 --> 1.111786).  Saving model ...
Validation loss decreased (1.111786 --> 1.109775).  Saving model ...
Validation loss decreased (1.109775 --> 1.106078).  Saving model ...
Validation loss decreased (1.106078 --> 1.102877).  Saving model ...
Validation loss decreased (1.102877 --> 1.099128).  Saving model ...
Validation loss decreased (1.099128 --> 1.095875).  Saving model ...
Validation loss decreased (1.095875 --> 1.092423).  Saving model ...
Validation loss decreased (1.092423 --> 1.089250).  Saving model ...
Validation loss decreased (1.089250 --> 1.086776).  Saving model ...
Validation loss decreased (1.086776 --> 1.083411).  Saving model ...
Validation loss decreased (1.083411 --> 1.081112).  Saving model ...
Validation loss decreased (1.081112 --> 1.077206).  Saving model ...
Validation loss decreased (1.077206 --> 1.076163).  Saving model ...
Validation loss decreased (1.076163 --> 1.073353).  Saving model ...
Validation loss decreased (1.073353 --> 1.069703).  Saving model ...
Validation loss decreased (1.069703 --> 1.066261).  Saving model ...
Validation loss decreased (1.066261 --> 1.063519).  Saving model ...
Validation loss decreased (1.063519 --> 1.060082).  Saving model ...
Validation loss decreased (1.060082 --> 1.058541).  Saving model ...
Validation loss decreased (1.058541 --> 1.057676).  Saving model ...
Validation loss decreased (1.057676 --> 1.056022).  Saving model ...
Validation loss decreased (1.056022 --> 1.052681).  Saving model ...
Validation loss decreased (1.052681 --> 1.049585).  Saving model ...
Validation loss decreased (1.049585 --> 1.046958).  Saving model ...
Validation loss decreased (1.046958 --> 1.044338).  Saving model ...
Validation loss decreased (1.044338 --> 1.043938).  Saving model ...
Validation loss decreased (1.043938 --> 1.041538).  Saving model ...
Validation loss decreased (1.041538 --> 1.039257).  Saving model ...
Validation loss decreased (1.039257 --> 1.036562).  Saving model ...
Validation loss decreased (1.036562 --> 1.034686).  Saving model ...
Validation loss decreased (1.034686 --> 1.033613).  Saving model ...
Validation loss decreased (1.033613 --> 1.031420).  Saving model ...
Validation loss decreased (1.031420 --> 1.030246).  Saving model ...
Validation loss decreased (1.030246 --> 1.028535).  Saving model ...
Validation loss decreased (1.028535 --> 1.025423).  Saving model ...
Validation loss decreased (1.025423 --> 1.022288).  Saving model ...
Validation loss decreased (1.022288 --> 1.019396).  Saving model ...
Validation loss decreased (1.019396 --> 1.019031).  Saving model ...
Validation loss decreased (1.019031 --> 1.016620).  Saving model ...
Validation loss decreased (1.016620 --> 1.015723).  Saving model ...
EarlyStopping counter: 1 out of 5.0
Validation loss decreased (1.015723 --> 1.015241).  Saving model ...
Validation loss decreased (1.015241 --> 1.012257).  Saving model ...
Validation loss decreased (1.012257 --> 1.011261).  Saving model ...
Validation loss decreased (1.011261 --> 1.009160).  Saving model ...
EarlyStopping counter: 1 out of 5.0
Validation loss decreased (1.009160 --> 1.009109).  Saving model ...
Validation loss decreased (1.009109 --> 1.006097).  Saving model ...
Validation loss decreased (1.006097 --> 1.005086).  Saving model ...
Validation loss decreased (1.005086 --> 1.004387).  Saving model ...
Validation loss decreased (1.004387 --> 1.000946).  Saving model ...
Validation loss decreased (1.000946 --> 1.000938).  Saving model ...
EarlyStopping counter: 1 out of 5.0
Validation loss decreased (1.000938 --> 0.998941).  Saving model ...
Validation loss decreased (0.998941 --> 0.996339).  Saving model ...
Validation loss decreased (0.996339 --> 0.995484).  Saving model ...
EarlyStopping counter: 1 out of 5.0
Validation loss decreased (0.995484 --> 0.992713).  Saving model ...
Validation loss decreased (0.992713 --> 0.992544).  Saving model ...
Validation loss decreased (0.992544 --> 0.990057).  Saving model ...
Validation loss decreased (0.990057 --> 0.989116).  Saving model ...
EarlyStopping counter: 1 out of 5.0
EarlyStopping counter: 2 out of 5.0
Validation loss decreased (0.989116 --> 0.988041).  Saving model ...
Validation loss decreased (0.988041 --> 0.985284).  Saving model ...
EarlyStopping counter: 1 out of 5.0
EarlyStopping counter: 2 out of 5.0
Validation loss decreased (0.985284 --> 0.984320).  Saving model ...
EarlyStopping counter: 1 out of 5.0
Validation loss decreased (0.984320 --> 0.983854).  Saving model ...
EarlyStopping counter: 1 out of 5.0
EarlyStopping counter: 2 out of 5.0
Validation loss decreased (0.983854 --> 0.982317).  Saving model ...
Validation loss decreased (0.982317 --> 0.981847).  Saving model ...
Validation loss decreased (0.981847 --> 0.980460).  Saving model ...
EarlyStopping counter: 1 out of 5.0
EarlyStopping counter: 2 out of 5.0
Validation loss decreased (0.980460 --> 0.979964).  Saving model ...
Validation loss decreased (0.979964 --> 0.977757).  Saving model ...
EarlyStopping counter: 1 out of 5.0
EarlyStopping counter: 2 out of 5.0
EarlyStopping counter: 3 out of 5.0
EarlyStopping counter: 4 out of 5.0
Validation loss decreased (0.977757 --> 0.976766).  Saving model ...
EarlyStopping counter: 1 out of 5.0
EarlyStopping counter: 2 out of 5.0
Validation loss decreased (0.976766 --> 0.976535).  Saving model ...
EarlyStopping counter: 1 out of 5.0
EarlyStopping counter: 2 out of 5.0
Validation loss decreased (0.976535 --> 0.975327).  Saving model ...
EarlyStopping counter: 1 out of 5.0
EarlyStopping counter: 2 out of 5.0
EarlyStopping counter: 3 out of 5.0
EarlyStopping counter: 4 out of 5.0
EarlyStopping counter: 5 out of 5.0
/localscratch/yinan.29351867.0/env/lib/python3.7/site-packages/torch/nn/functional.py:1794: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.
  warnings.warn("nn.functional.tanh is deprecated. Use torch.tanh instead.")
wandb: Waiting for W&B process to finish, PID 73904... (success).
wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: \ 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: | 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: / 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: \ 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: | 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: / 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: \ 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: | 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: / 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb:                                                                                
wandb: Run history:
wandb:     e_F1 ▁▂▄▄▅▅▅▅▆▆▆▆▆▆▇▇▇▇▇▇▇▇▇▇▇▇██████████████
wandb:   e_loss ██▇▇▇▆▆▅▅▅▅▄▄▄▃▃▃▃▃▂▂▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁
wandb:     t_F1 ▁▁▂▂▂▃▄▄▄▄▅▅▅▅▆▆▅▅▆▆▆▆▆▆▆▇▇▆▇▇▇▇█▇██▇███
wandb:   t_loss ████▇▇▇▆▆▆▅▅▅▅▅▄▅▄▄▄▃▃▃▃▃▃▃▃▂▂▂▂▂▂▂▂▂▁▁▁
wandb: 
wandb: Run summary:
wandb:     e_F1 57.99285
wandb:   e_loss 0.97608
wandb:     t_F1 71.43649
wandb:   t_loss 0.7373
wandb: 
wandb: Synced 4 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Synced northern-pond-1: https://wandb.ai/yinanazhou/xl_512_bs_8_lr_1e06_es_5_lc_True_nr_True_sr_False_stem_False_lemma_False_repeat_4_fold_1/runs/2k5rea2e
wandb: Find logs at: ./wandb/run-20220324_153150-2k5rea2e/logs/debug.log
wandb: 

wandb: wandb version 0.12.11 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
2022-03-24 17:08:38.687089: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1
wandb: Tracking run with wandb version 0.12.5
wandb: Syncing run astral-snow-1
wandb: ⭐️ View project at https://wandb.ai/yinanazhou/xl_512_bs_8_lr_1e06_es_5_lc_True_nr_True_sr_False_stem_False_lemma_False_repeat_4_fold_2
wandb: 🚀 View run at https://wandb.ai/yinanazhou/xl_512_bs_8_lr_1e06_es_5_lc_True_nr_True_sr_False_stem_False_lemma_False_repeat_4_fold_2/runs/28wnzd2p
wandb: Run data is saved locally in /project/6002780/yinan/Thesis_MER_Lyrics/lyric-emotion/wandb/run-20220324_170836-28wnzd2p
wandb: Run `wandb offline` to turn off syncing.

Validation loss decreased (inf --> 1.426760).  Saving model ...
Validation loss decreased (1.426760 --> 1.403508).  Saving model ...
Validation loss decreased (1.403508 --> 1.385309).  Saving model ...
Validation loss decreased (1.385309 --> 1.372038).  Saving model ...
Validation loss decreased (1.372038 --> 1.361351).  Saving model ...
Validation loss decreased (1.361351 --> 1.352289).  Saving model ...
Validation loss decreased (1.352289 --> 1.345908).  Saving model ...
Validation loss decreased (1.345908 --> 1.339488).  Saving model ...
Validation loss decreased (1.339488 --> 1.334437).  Saving model ...
Validation loss decreased (1.334437 --> 1.329054).  Saving model ...
Validation loss decreased (1.329054 --> 1.324436).  Saving model ...
Validation loss decreased (1.324436 --> 1.319505).  Saving model ...
Validation loss decreased (1.319505 --> 1.314391).  Saving model ...
Validation loss decreased (1.314391 --> 1.309563).  Saving model ...
Validation loss decreased (1.309563 --> 1.304633).  Saving model ...
Validation loss decreased (1.304633 --> 1.299750).  Saving model ...
Validation loss decreased (1.299750 --> 1.294755).  Saving model ...
Validation loss decreased (1.294755 --> 1.289997).  Saving model ...
Validation loss decreased (1.289997 --> 1.285387).  Saving model ...
Validation loss decreased (1.285387 --> 1.278580).  Saving model ...
Validation loss decreased (1.278580 --> 1.272666).  Saving model ...
Validation loss decreased (1.272666 --> 1.266344).  Saving model ...
Validation loss decreased (1.266344 --> 1.259926).  Saving model ...
Validation loss decreased (1.259926 --> 1.254487).  Saving model ...
Validation loss decreased (1.254487 --> 1.247715).  Saving model ...
Validation loss decreased (1.247715 --> 1.241217).  Saving model ...
Validation loss decreased (1.241217 --> 1.234638).  Saving model ...
Validation loss decreased (1.234638 --> 1.227750).  Saving model ...
Validation loss decreased (1.227750 --> 1.221288).  Saving model ...
Validation loss decreased (1.221288 --> 1.213441).  Saving model ...
Validation loss decreased (1.213441 --> 1.206708).  Saving model ...
Validation loss decreased (1.206708 --> 1.200827).  Saving model ...
Validation loss decreased (1.200827 --> 1.193457).  Saving model ...
Validation loss decreased (1.193457 --> 1.188451).  Saving model ...
Validation loss decreased (1.188451 --> 1.182273).  Saving model ...
Validation loss decreased (1.182273 --> 1.176743).  Saving model ...
Validation loss decreased (1.176743 --> 1.171910).  Saving model ...
Validation loss decreased (1.171910 --> 1.164703).  Saving model ...
Validation loss decreased (1.164703 --> 1.158988).  Saving model ...
Validation loss decreased (1.158988 --> 1.154549).  Saving model ...
Validation loss decreased (1.154549 --> 1.148404).  Saving model ...
Validation loss decreased (1.148404 --> 1.142568).  Saving model ...
Validation loss decreased (1.142568 --> 1.134754).  Saving model ...
Validation loss decreased (1.134754 --> 1.132946).  Saving model ...
Validation loss decreased (1.132946 --> 1.127349).  Saving model ...
Validation loss decreased (1.127349 --> 1.123880).  Saving model ...
Validation loss decreased (1.123880 --> 1.118426).  Saving model ...
Validation loss decreased (1.118426 --> 1.114131).  Saving model ...
Validation loss decreased (1.114131 --> 1.105746).  Saving model ...
Validation loss decreased (1.105746 --> 1.100206).  Saving model ...
EarlyStopping counter: 1 out of 5.0
Validation loss decreased (1.100206 --> 1.092937).  Saving model ...
Validation loss decreased (1.092937 --> 1.088788).  Saving model ...
Validation loss decreased (1.088788 --> 1.086410).  Saving model ...
Validation loss decreased (1.086410 --> 1.079626).  Saving model ...
Validation loss decreased (1.079626 --> 1.076933).  Saving model ...
Validation loss decreased (1.076933 --> 1.074314).  Saving model ...
Validation loss decreased (1.074314 --> 1.069069).  Saving model ...
Validation loss decreased (1.069069 --> 1.062224).  Saving model ...
EarlyStopping counter: 1 out of 5.0
Validation loss decreased (1.062224 --> 1.059610).  Saving model ...
Validation loss decreased (1.059610 --> 1.053099).  Saving model ...
EarlyStopping counter: 1 out of 5.0
EarlyStopping counter: 2 out of 5.0
Validation loss decreased (1.053099 --> 1.050679).  Saving model ...
Validation loss decreased (1.050679 --> 1.050180).  Saving model ...
Validation loss decreased (1.050180 --> 1.044563).  Saving model ...
Validation loss decreased (1.044563 --> 1.040190).  Saving model ...
Validation loss decreased (1.040190 --> 1.032576).  Saving model ...
EarlyStopping counter: 1 out of 5.0
Validation loss decreased (1.032576 --> 1.027357).  Saving model ...
Validation loss decreased (1.027357 --> 1.023695).  Saving model ...
EarlyStopping counter: 1 out of 5.0
Validation loss decreased (1.023695 --> 1.020394).  Saving model ...
Validation loss decreased (1.020394 --> 1.015977).  Saving model ...
EarlyStopping counter: 1 out of 5.0
Validation loss decreased (1.015977 --> 1.015395).  Saving model ...
EarlyStopping counter: 1 out of 5.0
Validation loss decreased (1.015395 --> 1.011534).  Saving model ...
Validation loss decreased (1.011534 --> 1.007657).  Saving model ...
EarlyStopping counter: 1 out of 5.0
Validation loss decreased (1.007657 --> 1.003734).  Saving model ...
Validation loss decreased (1.003734 --> 1.001318).  Saving model ...
EarlyStopping counter: 1 out of 5.0
Validation loss decreased (1.001318 --> 0.996295).  Saving model ...
Validation loss decreased (0.996295 --> 0.991925).  Saving model ...
EarlyStopping counter: 1 out of 5.0
Validation loss decreased (0.991925 --> 0.989452).  Saving model ...
Validation loss decreased (0.989452 --> 0.989411).  Saving model ...
Validation loss decreased (0.989411 --> 0.988758).  Saving model ...
Validation loss decreased (0.988758 --> 0.985052).  Saving model ...
Validation loss decreased (0.985052 --> 0.981481).  Saving model ...
EarlyStopping counter: 1 out of 5.0
Validation loss decreased (0.981481 --> 0.981404).  Saving model ...
Validation loss decreased (0.981404 --> 0.979341).  Saving model ...
Validation loss decreased (0.979341 --> 0.979181).  Saving model ...
Validation loss decreased (0.979181 --> 0.977909).  Saving model ...
Validation loss decreased (0.977909 --> 0.975088).  Saving model ...
EarlyStopping counter: 1 out of 5.0
EarlyStopping counter: 2 out of 5.0
EarlyStopping counter: 3 out of 5.0
Validation loss decreased (0.975088 --> 0.974275).  Saving model ...
EarlyStopping counter: 1 out of 5.0
Validation loss decreased (0.974275 --> 0.971173).  Saving model ...
Validation loss decreased (0.971173 --> 0.970605).  Saving model ...
Validation loss decreased (0.970605 --> 0.968043).  Saving model ...
EarlyStopping counter: 1 out of 5.0
Validation loss decreased (0.968043 --> 0.967571).  Saving model ...
Validation loss decreased (0.967571 --> 0.966677).  Saving model ...
Validation loss decreased (0.966677 --> 0.965040).  Saving model ...
Validation loss decreased (0.965040 --> 0.963444).  Saving model ...
Validation loss decreased (0.963444 --> 0.963245).  Saving model ...
Validation loss decreased (0.963245 --> 0.960613).  Saving model ...
EarlyStopping counter: 1 out of 5.0
Validation loss decreased (0.960613 --> 0.958408).  Saving model ...
EarlyStopping counter: 1 out of 5.0
EarlyStopping counter: 2 out of 5.0
EarlyStopping counter: 3 out of 5.0
EarlyStopping counter: 4 out of 5.0
EarlyStopping counter: 5 out of 5.0
/localscratch/yinan.29351867.0/env/lib/python3.7/site-packages/torch/nn/functional.py:1794: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.
  warnings.warn("nn.functional.tanh is deprecated. Use torch.tanh instead.")
wandb: Waiting for W&B process to finish, PID 79095... (success).
wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: \ 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: | 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: / 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: \ 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: | 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: / 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: \ 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: | 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: / 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb:                                                                                
wandb: Run history:
wandb:     e_F1 ▁▂▄▅▅▆▆▆▆▆▇▇▇▇▇▇▇▇▇▇▇▇▇███▇█████████████
wandb:   e_loss █▇▇▇▆▆▆▆▅▅▅▄▄▄▄▃▃▃▃▃▂▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁
wandb:     t_F1 ▁▂▃▃▄▃▄▄▄▅▅▅▅▆▆▆▆▇▆▆▇▇▇▇▇▇▇▇▇▇▇██▇██████
wandb:   t_loss █▇▇▇▇▇▇▆▆▆▆▅▅▅▅▄▄▄▄▄▃▃▃▃▃▃▃▃▂▂▂▂▂▂▂▂▂▂▁▁
wandb: 
wandb: Run summary:
wandb:     e_F1 57.62825
wandb:   e_loss 0.9652
wandb:     t_F1 68.87215
wandb:   t_loss 0.77874
wandb: 
wandb: Synced 4 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Synced astral-snow-1: https://wandb.ai/yinanazhou/xl_512_bs_8_lr_1e06_es_5_lc_True_nr_True_sr_False_stem_False_lemma_False_repeat_4_fold_2/runs/28wnzd2p
wandb: Find logs at: ./wandb/run-20220324_170836-28wnzd2p/logs/debug.log
wandb: 

wandb: wandb version 0.12.11 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
2022-03-24 18:24:32.155951: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1
wandb: Tracking run with wandb version 0.12.5
wandb: Syncing run visionary-resonance-1
wandb: ⭐️ View project at https://wandb.ai/yinanazhou/xl_512_bs_8_lr_1e06_es_5_lc_True_nr_True_sr_False_stem_False_lemma_False_repeat_5_fold_1
wandb: 🚀 View run at https://wandb.ai/yinanazhou/xl_512_bs_8_lr_1e06_es_5_lc_True_nr_True_sr_False_stem_False_lemma_False_repeat_5_fold_1/runs/itxfszeh
wandb: Run data is saved locally in /project/6002780/yinan/Thesis_MER_Lyrics/lyric-emotion/wandb/run-20220324_182429-itxfszeh
wandb: Run `wandb offline` to turn off syncing.

Validation loss decreased (inf --> 1.411764).  Saving model ...
Validation loss decreased (1.411764 --> 1.402195).  Saving model ...
Validation loss decreased (1.402195 --> 1.394456).  Saving model ...
Validation loss decreased (1.394456 --> 1.388287).  Saving model ...
Validation loss decreased (1.388287 --> 1.383711).  Saving model ...
Validation loss decreased (1.383711 --> 1.379885).  Saving model ...
Validation loss decreased (1.379885 --> 1.376316).  Saving model ...
Validation loss decreased (1.376316 --> 1.373236).  Saving model ...
Validation loss decreased (1.373236 --> 1.370227).  Saving model ...
Validation loss decreased (1.370227 --> 1.367143).  Saving model ...
Validation loss decreased (1.367143 --> 1.364126).  Saving model ...
Validation loss decreased (1.364126 --> 1.361271).  Saving model ...
Validation loss decreased (1.361271 --> 1.358017).  Saving model ...
Validation loss decreased (1.358017 --> 1.354870).  Saving model ...
Validation loss decreased (1.354870 --> 1.351495).  Saving model ...
Validation loss decreased (1.351495 --> 1.348057).  Saving model ...
Validation loss decreased (1.348057 --> 1.344565).  Saving model ...
Validation loss decreased (1.344565 --> 1.340773).  Saving model ...
Validation loss decreased (1.340773 --> 1.337208).  Saving model ...
Validation loss decreased (1.337208 --> 1.332563).  Saving model ...
Validation loss decreased (1.332563 --> 1.327895).  Saving model ...
Validation loss decreased (1.327895 --> 1.322961).  Saving model ...
Validation loss decreased (1.322961 --> 1.318313).  Saving model ...
Validation loss decreased (1.318313 --> 1.313043).  Saving model ...
Validation loss decreased (1.313043 --> 1.307755).  Saving model ...
Validation loss decreased (1.307755 --> 1.301947).  Saving model ...
Validation loss decreased (1.301947 --> 1.294734).  Saving model ...
Validation loss decreased (1.294734 --> 1.288910).  Saving model ...
Validation loss decreased (1.288910 --> 1.281963).  Saving model ...
Validation loss decreased (1.281963 --> 1.276395).  Saving model ...
Validation loss decreased (1.276395 --> 1.269432).  Saving model ...
Validation loss decreased (1.269432 --> 1.263521).  Saving model ...
Validation loss decreased (1.263521 --> 1.256415).  Saving model ...
Validation loss decreased (1.256415 --> 1.250378).  Saving model ...
Validation loss decreased (1.250378 --> 1.243797).  Saving model ...
Validation loss decreased (1.243797 --> 1.237737).  Saving model ...
Validation loss decreased (1.237737 --> 1.232556).  Saving model ...
Validation loss decreased (1.232556 --> 1.227044).  Saving model ...
Validation loss decreased (1.227044 --> 1.222522).  Saving model ...
Validation loss decreased (1.222522 --> 1.217053).  Saving model ...
Validation loss decreased (1.217053 --> 1.211824).  Saving model ...
Validation loss decreased (1.211824 --> 1.206640).  Saving model ...
Validation loss decreased (1.206640 --> 1.201914).  Saving model ...
Validation loss decreased (1.201914 --> 1.196364).  Saving model ...
Validation loss decreased (1.196364 --> 1.190567).  Saving model ...
Validation loss decreased (1.190567 --> 1.184381).  Saving model ...
Validation loss decreased (1.184381 --> 1.179169).  Saving model ...
Validation loss decreased (1.179169 --> 1.174872).  Saving model ...
Validation loss decreased (1.174872 --> 1.170663).  Saving model ...
Validation loss decreased (1.170663 --> 1.165026).  Saving model ...
Validation loss decreased (1.165026 --> 1.160100).  Saving model ...
Validation loss decreased (1.160100 --> 1.155200).  Saving model ...
Validation loss decreased (1.155200 --> 1.151915).  Saving model ...
Validation loss decreased (1.151915 --> 1.147450).  Saving model ...
Validation loss decreased (1.147450 --> 1.143720).  Saving model ...
Validation loss decreased (1.143720 --> 1.141756).  Saving model ...
Validation loss decreased (1.141756 --> 1.138120).  Saving model ...
Validation loss decreased (1.138120 --> 1.134525).  Saving model ...
Validation loss decreased (1.134525 --> 1.129628).  Saving model ...
Validation loss decreased (1.129628 --> 1.124515).  Saving model ...
Validation loss decreased (1.124515 --> 1.121703).  Saving model ...
Validation loss decreased (1.121703 --> 1.117930).  Saving model ...
Validation loss decreased (1.117930 --> 1.114225).  Saving model ...
Validation loss decreased (1.114225 --> 1.110753).  Saving model ...
Validation loss decreased (1.110753 --> 1.104945).  Saving model ...
Validation loss decreased (1.104945 --> 1.101396).  Saving model ...
Validation loss decreased (1.101396 --> 1.096685).  Saving model ...
Validation loss decreased (1.096685 --> 1.093761).  Saving model ...
Validation loss decreased (1.093761 --> 1.089892).  Saving model ...
Validation loss decreased (1.089892 --> 1.087797).  Saving model ...
Validation loss decreased (1.087797 --> 1.085753).  Saving model ...
Validation loss decreased (1.085753 --> 1.081622).  Saving model ...
Validation loss decreased (1.081622 --> 1.078869).  Saving model ...
Validation loss decreased (1.078869 --> 1.076666).  Saving model ...
Validation loss decreased (1.076666 --> 1.072168).  Saving model ...
Validation loss decreased (1.072168 --> 1.067972).  Saving model ...
Validation loss decreased (1.067972 --> 1.065345).  Saving model ...
Validation loss decreased (1.065345 --> 1.061517).  Saving model ...
Validation loss decreased (1.061517 --> 1.058294).  Saving model ...
Validation loss decreased (1.058294 --> 1.055992).  Saving model ...
Validation loss decreased (1.055992 --> 1.053767).  Saving model ...
Validation loss decreased (1.053767 --> 1.051548).  Saving model ...
Validation loss decreased (1.051548 --> 1.048000).  Saving model ...
Validation loss decreased (1.048000 --> 1.045433).  Saving model ...
Validation loss decreased (1.045433 --> 1.044288).  Saving model ...
Validation loss decreased (1.044288 --> 1.042716).  Saving model ...
Validation loss decreased (1.042716 --> 1.038989).  Saving model ...
Validation loss decreased (1.038989 --> 1.036977).  Saving model ...
Validation loss decreased (1.036977 --> 1.036261).  Saving model ...
Validation loss decreased (1.036261 --> 1.034999).  Saving model ...
Validation loss decreased (1.034999 --> 1.032464).  Saving model ...
Validation loss decreased (1.032464 --> 1.029139).  Saving model ...
Validation loss decreased (1.029139 --> 1.026022).  Saving model ...
Validation loss decreased (1.026022 --> 1.024669).  Saving model ...
Validation loss decreased (1.024669 --> 1.023456).  Saving model ...
Validation loss decreased (1.023456 --> 1.020355).  Saving model ...
Validation loss decreased (1.020355 --> 1.019746).  Saving model ...
Validation loss decreased (1.019746 --> 1.017877).  Saving model ...
Validation loss decreased (1.017877 --> 1.014909).  Saving model ...
Validation loss decreased (1.014909 --> 1.013480).  Saving model ...
Validation loss decreased (1.013480 --> 1.012225).  Saving model ...
Validation loss decreased (1.012225 --> 1.010653).  Saving model ...
Validation loss decreased (1.010653 --> 1.010241).  Saving model ...
Validation loss decreased (1.010241 --> 1.007456).  Saving model ...
Validation loss decreased (1.007456 --> 1.005889).  Saving model ...
Validation loss decreased (1.005889 --> 1.004746).  Saving model ...
Validation loss decreased (1.004746 --> 1.003860).  Saving model ...
Validation loss decreased (1.003860 --> 1.001504).  Saving model ...
Validation loss decreased (1.001504 --> 1.000857).  Saving model ...
Validation loss decreased (1.000857 --> 1.000340).  Saving model ...
Validation loss decreased (1.000340 --> 0.996970).  Saving model ...
Validation loss decreased (0.996970 --> 0.996289).  Saving model ...
EarlyStopping counter: 1 out of 5.0
Validation loss decreased (0.996289 --> 0.995022).  Saving model ...
Validation loss decreased (0.995022 --> 0.993284).  Saving model ...
EarlyStopping counter: 1 out of 5.0
Validation loss decreased (0.993284 --> 0.992958).  Saving model ...
Validation loss decreased (0.992958 --> 0.991315).  Saving model ...
Validation loss decreased (0.991315 --> 0.991205).  Saving model ...
Validation loss decreased (0.991205 --> 0.990134).  Saving model ...
Validation loss decreased (0.990134 --> 0.989588).  Saving model ...
Validation loss decreased (0.989588 --> 0.988118).  Saving model ...
Validation loss decreased (0.988118 --> 0.987370).  Saving model ...
Validation loss decreased (0.987370 --> 0.985836).  Saving model ...
EarlyStopping counter: 1 out of 5.0
Validation loss decreased (0.985836 --> 0.985780).  Saving model ...
EarlyStopping counter: 1 out of 5.0
EarlyStopping counter: 2 out of 5.0
EarlyStopping counter: 3 out of 5.0
EarlyStopping counter: 4 out of 5.0
Validation loss decreased (0.985780 --> 0.985564).  Saving model ...
Validation loss decreased (0.985564 --> 0.984680).  Saving model ...
Validation loss decreased (0.984680 --> 0.982797).  Saving model ...
Validation loss decreased (0.982797 --> 0.982603).  Saving model ...
EarlyStopping counter: 1 out of 5.0
EarlyStopping counter: 2 out of 5.0
EarlyStopping counter: 3 out of 5.0
EarlyStopping counter: 4 out of 5.0
EarlyStopping counter: 5 out of 5.0
/localscratch/yinan.29351867.0/env/lib/python3.7/site-packages/torch/nn/functional.py:1794: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.
  warnings.warn("nn.functional.tanh is deprecated. Use torch.tanh instead.")
wandb: Waiting for W&B process to finish, PID 83139... (success).
wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: \ 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: | 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: / 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: \ 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: | 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: / 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: \ 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: | 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: / 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb:                                                                                
wandb: Run history:
wandb:     e_F1 ▁▁▂▃▄▄▄▅▅▆▆▆▆▆▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇███████████
wandb:   e_loss ███▇▇▇▇▆▆▆▅▅▅▄▄▄▄▃▃▃▃▃▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁
wandb:     t_F1 ▁▁▂▂▃▃▃▃▄▄▄▅▅▅▆▆▅▅▆▆▆▆▇▇▇▇▇▇▇▇▇▇▇▇█▇▇███
wandb:   t_loss ████▇▇▇▇▇▆▆▆▆▅▅▅▅▅▄▄▄▄▃▃▃▃▃▃▃▃▂▂▂▂▂▂▂▁▁▁
wandb: 
wandb: Run summary:
wandb:     e_F1 56.24079
wandb:   e_loss 0.98434
wandb:     t_F1 73.92747
wandb:   t_loss 0.77277
wandb: 
wandb: Synced 4 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Synced visionary-resonance-1: https://wandb.ai/yinanazhou/xl_512_bs_8_lr_1e06_es_5_lc_True_nr_True_sr_False_stem_False_lemma_False_repeat_5_fold_1/runs/itxfszeh
wandb: Find logs at: ./wandb/run-20220324_182429-itxfszeh/logs/debug.log
wandb: 

wandb: wandb version 0.12.11 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
2022-03-24 19:53:18.926064: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1
wandb: Tracking run with wandb version 0.12.5
wandb: Syncing run likely-salad-1
wandb: ⭐️ View project at https://wandb.ai/yinanazhou/xl_512_bs_8_lr_1e06_es_5_lc_True_nr_True_sr_False_stem_False_lemma_False_repeat_5_fold_2
wandb: 🚀 View run at https://wandb.ai/yinanazhou/xl_512_bs_8_lr_1e06_es_5_lc_True_nr_True_sr_False_stem_False_lemma_False_repeat_5_fold_2/runs/3u4l3fxf
wandb: Run data is saved locally in /project/6002780/yinan/Thesis_MER_Lyrics/lyric-emotion/wandb/run-20220324_195316-3u4l3fxf
wandb: Run `wandb offline` to turn off syncing.

Validation loss decreased (inf --> 1.487095).  Saving model ...
Validation loss decreased (1.487095 --> 1.454053).  Saving model ...
Validation loss decreased (1.454053 --> 1.427731).  Saving model ...
Validation loss decreased (1.427731 --> 1.404930).  Saving model ...
Validation loss decreased (1.404930 --> 1.387046).  Saving model ...
Validation loss decreased (1.387046 --> 1.372486).  Saving model ...
Validation loss decreased (1.372486 --> 1.360365).  Saving model ...
Validation loss decreased (1.360365 --> 1.351230).  Saving model ...
Validation loss decreased (1.351230 --> 1.343469).  Saving model ...
Validation loss decreased (1.343469 --> 1.336161).  Saving model ...
Validation loss decreased (1.336161 --> 1.331116).  Saving model ...
Validation loss decreased (1.331116 --> 1.326451).  Saving model ...
Validation loss decreased (1.326451 --> 1.320600).  Saving model ...
Validation loss decreased (1.320600 --> 1.314996).  Saving model ...
Validation loss decreased (1.314996 --> 1.309263).  Saving model ...
Validation loss decreased (1.309263 --> 1.302990).  Saving model ...
Validation loss decreased (1.302990 --> 1.297527).  Saving model ...
Validation loss decreased (1.297527 --> 1.292145).  Saving model ...
Validation loss decreased (1.292145 --> 1.286893).  Saving model ...
Validation loss decreased (1.286893 --> 1.280474).  Saving model ...
Validation loss decreased (1.280474 --> 1.274850).  Saving model ...
Validation loss decreased (1.274850 --> 1.269084).  Saving model ...
Validation loss decreased (1.269084 --> 1.261859).  Saving model ...
Validation loss decreased (1.261859 --> 1.254711).  Saving model ...
Validation loss decreased (1.254711 --> 1.249009).  Saving model ...
Validation loss decreased (1.249009 --> 1.245265).  Saving model ...
Validation loss decreased (1.245265 --> 1.237057).  Saving model ...
Validation loss decreased (1.237057 --> 1.231294).  Saving model ...
Validation loss decreased (1.231294 --> 1.226104).  Saving model ...
Validation loss decreased (1.226104 --> 1.219471).  Saving model ...
Validation loss decreased (1.219471 --> 1.213003).  Saving model ...
Validation loss decreased (1.213003 --> 1.205917).  Saving model ...
Validation loss decreased (1.205917 --> 1.200708).  Saving model ...
Validation loss decreased (1.200708 --> 1.194072).  Saving model ...
Validation loss decreased (1.194072 --> 1.186633).  Saving model ...
Validation loss decreased (1.186633 --> 1.179790).  Saving model ...
Validation loss decreased (1.179790 --> 1.175640).  Saving model ...
Validation loss decreased (1.175640 --> 1.173871).  Saving model ...
Validation loss decreased (1.173871 --> 1.172183).  Saving model ...
Validation loss decreased (1.172183 --> 1.168795).  Saving model ...
Validation loss decreased (1.168795 --> 1.163171).  Saving model ...
Validation loss decreased (1.163171 --> 1.158795).  Saving model ...
Validation loss decreased (1.158795 --> 1.151147).  Saving model ...
Validation loss decreased (1.151147 --> 1.146434).  Saving model ...
Validation loss decreased (1.146434 --> 1.141097).  Saving model ...
Validation loss decreased (1.141097 --> 1.135698).  Saving model ...
Validation loss decreased (1.135698 --> 1.133433).  Saving model ...
Validation loss decreased (1.133433 --> 1.132283).  Saving model ...
Validation loss decreased (1.132283 --> 1.120657).  Saving model ...
Validation loss decreased (1.120657 --> 1.118944).  Saving model ...
Validation loss decreased (1.118944 --> 1.115714).  Saving model ...
Validation loss decreased (1.115714 --> 1.106752).  Saving model ...
Validation loss decreased (1.106752 --> 1.100322).  Saving model ...
Validation loss decreased (1.100322 --> 1.097279).  Saving model ...
Validation loss decreased (1.097279 --> 1.092661).  Saving model ...
Validation loss decreased (1.092661 --> 1.088771).  Saving model ...
Validation loss decreased (1.088771 --> 1.086779).  Saving model ...
Validation loss decreased (1.086779 --> 1.078931).  Saving model ...
Validation loss decreased (1.078931 --> 1.078430).  Saving model ...
Validation loss decreased (1.078430 --> 1.070910).  Saving model ...
Validation loss decreased (1.070910 --> 1.069177).  Saving model ...
Validation loss decreased (1.069177 --> 1.069043).  Saving model ...
Validation loss decreased (1.069043 --> 1.066511).  Saving model ...
Validation loss decreased (1.066511 --> 1.061583).  Saving model ...
Validation loss decreased (1.061583 --> 1.054460).  Saving model ...
Validation loss decreased (1.054460 --> 1.053118).  Saving model ...
Validation loss decreased (1.053118 --> 1.049967).  Saving model ...
Validation loss decreased (1.049967 --> 1.047378).  Saving model ...
Validation loss decreased (1.047378 --> 1.038815).  Saving model ...
Validation loss decreased (1.038815 --> 1.038569).  Saving model ...
Validation loss decreased (1.038569 --> 1.034726).  Saving model ...
Validation loss decreased (1.034726 --> 1.030876).  Saving model ...
Validation loss decreased (1.030876 --> 1.029013).  Saving model ...
Validation loss decreased (1.029013 --> 1.025896).  Saving model ...
Validation loss decreased (1.025896 --> 1.022585).  Saving model ...
Validation loss decreased (1.022585 --> 1.021417).  Saving model ...
Validation loss decreased (1.021417 --> 1.020740).  Saving model ...
Validation loss decreased (1.020740 --> 1.013168).  Saving model ...
EarlyStopping counter: 1 out of 5.0
EarlyStopping counter: 2 out of 5.0
Validation loss decreased (1.013168 --> 1.011947).  Saving model ...
Validation loss decreased (1.011947 --> 1.010027).  Saving model ...
Validation loss decreased (1.010027 --> 1.005129).  Saving model ...
Validation loss decreased (1.005129 --> 1.001898).  Saving model ...
EarlyStopping counter: 1 out of 5.0
EarlyStopping counter: 2 out of 5.0
Validation loss decreased (1.001898 --> 1.000365).  Saving model ...
Validation loss decreased (1.000365 --> 0.993165).  Saving model ...
EarlyStopping counter: 1 out of 5.0
EarlyStopping counter: 2 out of 5.0
Validation loss decreased (0.993165 --> 0.991513).  Saving model ...
Validation loss decreased (0.991513 --> 0.989294).  Saving model ...
Validation loss decreased (0.989294 --> 0.984049).  Saving model ...
Validation loss decreased (0.984049 --> 0.982812).  Saving model ...
Validation loss decreased (0.982812 --> 0.978651).  Saving model ...
EarlyStopping counter: 1 out of 5.0
EarlyStopping counter: 2 out of 5.0
Validation loss decreased (0.978651 --> 0.977111).  Saving model ...
Validation loss decreased (0.977111 --> 0.975760).  Saving model ...
Validation loss decreased (0.975760 --> 0.971861).  Saving model ...
EarlyStopping counter: 1 out of 5.0
Validation loss decreased (0.971861 --> 0.971843).  Saving model ...
Validation loss decreased (0.971843 --> 0.968557).  Saving model ...
Validation loss decreased (0.968557 --> 0.963257).  Saving model ...
EarlyStopping counter: 1 out of 5.0
EarlyStopping counter: 2 out of 5.0
Validation loss decreased (0.963257 --> 0.963166).  Saving model ...
Validation loss decreased (0.963166 --> 0.959335).  Saving model ...
EarlyStopping counter: 1 out of 5.0
EarlyStopping counter: 2 out of 5.0
Validation loss decreased (0.959335 --> 0.959158).  Saving model ...
Validation loss decreased (0.959158 --> 0.956569).  Saving model ...
EarlyStopping counter: 1 out of 5.0
Validation loss decreased (0.956569 --> 0.956538).  Saving model ...
EarlyStopping counter: 1 out of 5.0
EarlyStopping counter: 2 out of 5.0
Validation loss decreased (0.956538 --> 0.955961).  Saving model ...
Validation loss decreased (0.955961 --> 0.953461).  Saving model ...
EarlyStopping counter: 1 out of 5.0
EarlyStopping counter: 2 out of 5.0
Validation loss decreased (0.953461 --> 0.951025).  Saving model ...
EarlyStopping counter: 1 out of 5.0
EarlyStopping counter: 2 out of 5.0
EarlyStopping counter: 3 out of 5.0
Validation loss decreased (0.951025 --> 0.949663).  Saving model ...
Validation loss decreased (0.949663 --> 0.947528).  Saving model ...
EarlyStopping counter: 1 out of 5.0
Validation loss decreased (0.947528 --> 0.945813).  Saving model ...
EarlyStopping counter: 1 out of 5.0
Validation loss decreased (0.945813 --> 0.941789).  Saving model ...
EarlyStopping counter: 1 out of 5.0
EarlyStopping counter: 2 out of 5.0
EarlyStopping counter: 3 out of 5.0
EarlyStopping counter: 4 out of 5.0
EarlyStopping counter: 5 out of 5.0
/localscratch/yinan.29351867.0/env/lib/python3.7/site-packages/torch/nn/functional.py:1794: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.
  warnings.warn("nn.functional.tanh is deprecated. Use torch.tanh instead.")
wandb: Waiting for W&B process to finish, PID 87879... (success).
wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: \ 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: | 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: / 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: \ 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: | 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: / 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: \ 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: | 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: / 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb:                                                                                
wandb: Run history:
wandb:     e_F1 ▁▂▄▄▅▅▆▆▆▆▆▆▆▆▇▇▇▇▇▇▇▇▇▇▇▇▇█████████████
wandb:   e_loss █▇▇▆▆▆▅▅▅▅▄▄▄▄▄▃▃▃▃▃▂▂▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁
wandb:     t_F1 ▁▁▂▃▃▃▄▄▅▅▄▅▆▆▆▆▇▆▇▆▇▆▇▇▇▇▇▇▇▇▇█▇▇██▇███
wandb:   t_loss ██▇▇▇▆▆▆▆▅▅▅▅▅▄▄▄▄▄▃▃▃▃▃▃▂▂▂▂▂▂▂▂▂▂▂▂▁▁▁
wandb: 
wandb: Run summary:
wandb:     e_F1 61.31055
wandb:   e_loss 0.94181
wandb:     t_F1 68.07912
wandb:   t_loss 0.78472
wandb: 
wandb: Synced 4 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Synced likely-salad-1: https://wandb.ai/yinanazhou/xl_512_bs_8_lr_1e06_es_5_lc_True_nr_True_sr_False_stem_False_lemma_False_repeat_5_fold_2/runs/3u4l3fxf
wandb: Find logs at: ./wandb/run-20220324_195316-3u4l3fxf/logs/debug.log
wandb: 

