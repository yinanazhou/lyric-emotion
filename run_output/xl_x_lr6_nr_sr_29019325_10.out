Unloading StdEnv/2020

Due to MODULEPATH changes, the following have been reloaded:
  1) mii/1.1.1


The following have been reloaded with a version change:
  1) python/3.8.2 => python/3.7.4

Using base prefix '/cvmfs/soft.computecanada.ca/easybuild/software/2017/Core/python/3.7.4'
New python executable in /localscratch/yinan.29019325.0/env/bin/python
Installing setuptools, pip, wheel...
done.
Ignoring pip: markers 'python_version < "3"' don't match your environment
Looking in links: /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/nix/avx2, /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/nix/generic, /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic
Collecting pip
Installing collected packages: pip
  Found existing installation: pip 19.1.1
    Uninstalling pip-19.1.1:
      Successfully uninstalled pip-19.1.1
Successfully installed pip-21.2.3+computecanada
Looking in links: /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/nix/avx2, /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/nix/generic, /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/keras-2.8.0+computecanada-py2.py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/Keras_Preprocessing-1.1.2+computecanada-py3-none-any.whl
Requirement already satisfied: matplotlib in /cvmfs/soft.computecanada.ca/easybuild/software/2017/Core/scipy-stack/2019a/lib/python3.7/site-packages (from -r requirements.txt (line 3)) (3.0.2)
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/nltk-3.6.5+computecanada-py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/scikit_learn-0.22.1+computecanada-cp37-cp37m-linux_x86_64.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/tensorboard-2.3.0+computecanada-py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/tensorboard_plugin_wit-1.7.0+computecanada-py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/tensorflow_gpu-2.3.0+computecanada-cp37-cp37m-linux_x86_64.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/tensorflow_estimator-2.3.0+computecanada-py2.py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/tokenizers-0.5.2+computecanada-cp37-cp37m-linux_x86_64.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/nix/avx2/torch-1.4.0+computecanada-cp37-cp37m-linux_x86_64.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/torchtext-0.6.0+computecanada-py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/torchvision-0.8.2+computecanada-cp37-cp37m-linux_x86_64.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/transformers-2.5.1+computecanada-py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/urllib3-1.26.7+computecanada-py2.py3-none-any.whl
ERROR: Could not find a version that satisfies the requirement regex>=2021.8.3 (from nltk) (from versions: 2018.1.10+computecanada, 2019.11.1+computecanada, 2020.11.13+computecanada)
ERROR: No matching distribution found for regex>=2021.8.3
Looking in links: /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/nix/avx2, /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/nix/generic, /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic
ERROR: Could not find a version that satisfies the requirement numpy==1.20.0+computacanada (from versions: 1.15.0+computecanada, 1.15.2+computecanada, 1.15.4+computecanada, 1.16.0+computecanada, 1.16.2+computecanada, 1.16.3+computecanada, 1.17.4+computecanada, 1.18.1+computecanada, 1.18.4+computecanada, 1.19.1+computecanada, 1.19.2+computecanada, 1.20.2+computecanada)
ERROR: No matching distribution found for numpy==1.20.0+computacanada
Looking in links: /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/nix/avx2, /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/nix/generic, /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/wandb-0.12.5+computecanada-py2.py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/promise-2.3+computecanada-py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/pathtools-0.1.2+computecanada-py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/configparser-5.0.2+computecanada-py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/PyYAML-5.3.1+computecanada-cp37-cp37m-linux_x86_64.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/six-1.16.0+computecanada-py2.py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/click-8.0.4+computecanada-py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/shortuuid-1.0.1+computecanada-py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/subprocess32-3.5.4+computecanada-py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/GitPython-3.1.24+computecanada-py3-none-any.whl
Requirement already satisfied: requests<3,>=2.0.0 in /cvmfs/soft.computecanada.ca/easybuild/software/2017/Core/scipy-stack/2019a/lib/python3.7/site-packages (from wandb) (2.21.0)
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/protobuf-3.19.4+computecanada-py2.py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/sentry_sdk-1.5.0+computecanada-py2.py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/psutil-5.7.3+computecanada-cp37-cp37m-linux_x86_64.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/yaspin-2.1.0+computecanada-py3-none-any.whl
Requirement already satisfied: python-dateutil>=2.6.1 in /cvmfs/soft.computecanada.ca/easybuild/software/2017/Core/scipy-stack/2019a/lib/python3.7/site-packages (from wandb) (2.7.5)
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/docker_pycreds-0.4.0+computecanada-py2.py3-none-any.whl
Requirement already satisfied: importlib-metadata in /cvmfs/soft.computecanada.ca/easybuild/software/2017/Core/scipy-stack/2019a/lib/python3.7/site-packages (from Click!=8.0.0,>=7.0->wandb) (0.8)
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/typing_extensions-4.0.1+computecanada-py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/gitdb-4.0.9+computecanada-py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/smmap-5.0.0+computecanada-py3-none-any.whl
Requirement already satisfied: urllib3<1.25,>=1.21.1 in /cvmfs/soft.computecanada.ca/easybuild/software/2017/Core/scipy-stack/2019a/lib/python3.7/site-packages (from requests<3,>=2.0.0->wandb) (1.24.1)
Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /cvmfs/soft.computecanada.ca/easybuild/software/2017/Core/scipy-stack/2019a/lib/python3.7/site-packages (from requests<3,>=2.0.0->wandb) (3.0.4)
Requirement already satisfied: idna<2.9,>=2.5 in /cvmfs/soft.computecanada.ca/easybuild/software/2017/Core/scipy-stack/2019a/lib/python3.7/site-packages (from requests<3,>=2.0.0->wandb) (2.8)
Requirement already satisfied: certifi>=2017.4.17 in /cvmfs/soft.computecanada.ca/easybuild/software/2017/Core/scipy-stack/2019a/lib/python3.7/site-packages (from requests<3,>=2.0.0->wandb) (2018.11.29)
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/termcolor-1.1.0+computecanada-py3-none-any.whl
Requirement already satisfied: zipp>=0.3.2 in /cvmfs/soft.computecanada.ca/easybuild/software/2017/Core/scipy-stack/2019a/lib/python3.7/site-packages (from importlib-metadata->Click!=8.0.0,>=7.0->wandb) (0.3.3)
Installing collected packages: smmap, typing-extensions, termcolor, six, gitdb, yaspin, subprocess32, shortuuid, sentry-sdk, PyYAML, psutil, protobuf, promise, pathtools, GitPython, docker-pycreds, configparser, Click, wandb
  Attempting uninstall: six
    Found existing installation: six 1.12.0
    Not uninstalling six at /cvmfs/soft.computecanada.ca/easybuild/software/2017/Core/scipy-stack/2019a/lib/python3.7/site-packages, outside environment /localscratch/yinan.29019325.0/env
    Can't uninstall 'six'. No files were found to uninstall.
Successfully installed Click-8.0.4+computecanada GitPython-3.1.24+computecanada PyYAML-5.3.1+computecanada configparser-5.0.2+computecanada docker-pycreds-0.4.0+computecanada gitdb-4.0.9+computecanada pathtools-0.1.2+computecanada promise-2.3+computecanada protobuf-3.19.4+computecanada psutil-5.7.3+computecanada sentry-sdk-1.5.0+computecanada shortuuid-1.0.1+computecanada six-1.16.0+computecanada smmap-5.0.0+computecanada subprocess32-3.5.4+computecanada termcolor-1.1.0+computecanada typing-extensions-4.0.1+computecanada wandb-0.12.5+computecanada yaspin-2.1.0+computecanada
Looking in links: /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/nix/avx2, /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/nix/generic, /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic
ERROR: Could not find a version that satisfies the requirement sagemaker (from versions: none)
ERROR: No matching distribution found for sagemaker
Looking in links: /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/nix/avx2, /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/nix/generic, /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/torch-1.9.1+computecanada-cp37-cp37m-linux_x86_64.whl
Requirement already satisfied: typing-extensions in /localscratch/yinan.29019325.0/env/lib/python3.7/site-packages (from torch) (4.0.1+computecanada)
Installing collected packages: torch
Successfully installed torch-1.9.1+computecanada
Looking in links: /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/nix/avx2, /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/nix/generic, /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/transformers-2.5.1+computecanada-py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/boto3-1.21.14+computecanada-py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/sacremoses-0.0.46+computecanada-py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/filelock-3.4.2+computecanada-py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/regex-2020.11.13+computecanada-cp37-cp37m-linux_x86_64.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/tqdm-4.63.0+computecanada-py2.py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/sentencepiece-0.1.91+computecanada-cp37-cp37m-linux_x86_64.whl
Requirement already satisfied: numpy in /cvmfs/soft.computecanada.ca/easybuild/software/2017/Core/scipy-stack/2019a/lib/python3.7/site-packages (from transformers==2.5.1+computecanada) (1.16.0)
Requirement already satisfied: requests in /cvmfs/soft.computecanada.ca/easybuild/software/2017/Core/scipy-stack/2019a/lib/python3.7/site-packages (from transformers==2.5.1+computecanada) (2.21.0)
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/tokenizers-0.5.2+computecanada-cp37-cp37m-linux_x86_64.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/jmespath-0.10.0+computecanada-py2.py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/s3transfer-0.5.1+computecanada-py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/botocore-1.24.14+computecanada-py3-none-any.whl
Requirement already satisfied: python-dateutil<3.0.0,>=2.1 in /cvmfs/soft.computecanada.ca/easybuild/software/2017/Core/scipy-stack/2019a/lib/python3.7/site-packages (from botocore<1.25.0,>=1.24.14->boto3->transformers==2.5.1+computecanada) (2.7.5)
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/urllib3-1.26.8+computecanada-py2.py3-none-any.whl
Requirement already satisfied: six>=1.5 in /localscratch/yinan.29019325.0/env/lib/python3.7/site-packages (from python-dateutil<3.0.0,>=2.1->botocore<1.25.0,>=1.24.14->boto3->transformers==2.5.1+computecanada) (1.16.0+computecanada)
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/requests-2.27.1+computecanada-py2.py3-none-any.whl
Requirement already satisfied: certifi>=2017.4.17 in /cvmfs/soft.computecanada.ca/easybuild/software/2017/Core/scipy-stack/2019a/lib/python3.7/site-packages (from requests->transformers==2.5.1+computecanada) (2018.11.29)
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/charset_normalizer-2.0.12+computecanada-py3-none-any.whl
Requirement already satisfied: idna<4,>=2.5 in /cvmfs/soft.computecanada.ca/easybuild/software/2017/Core/scipy-stack/2019a/lib/python3.7/site-packages (from requests->transformers==2.5.1+computecanada) (2.8)
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/joblib-1.1.0+computecanada-py2.py3-none-any.whl
Requirement already satisfied: click in /localscratch/yinan.29019325.0/env/lib/python3.7/site-packages (from sacremoses->transformers==2.5.1+computecanada) (8.0.4+computecanada)
Requirement already satisfied: importlib-metadata in /cvmfs/soft.computecanada.ca/easybuild/software/2017/Core/scipy-stack/2019a/lib/python3.7/site-packages (from click->sacremoses->transformers==2.5.1+computecanada) (0.8)
Requirement already satisfied: zipp>=0.3.2 in /cvmfs/soft.computecanada.ca/easybuild/software/2017/Core/scipy-stack/2019a/lib/python3.7/site-packages (from importlib-metadata->click->sacremoses->transformers==2.5.1+computecanada) (0.3.3)
Installing collected packages: urllib3, jmespath, botocore, tqdm, s3transfer, regex, joblib, charset-normalizer, tokenizers, sentencepiece, sacremoses, requests, filelock, boto3, transformers
  Attempting uninstall: urllib3
    Found existing installation: urllib3 1.24.1
    Not uninstalling urllib3 at /cvmfs/soft.computecanada.ca/easybuild/software/2017/Core/scipy-stack/2019a/lib/python3.7/site-packages, outside environment /localscratch/yinan.29019325.0/env
    Can't uninstall 'urllib3'. No files were found to uninstall.
  Attempting uninstall: requests
    Found existing installation: requests 2.21.0
    Not uninstalling requests at /cvmfs/soft.computecanada.ca/easybuild/software/2017/Core/scipy-stack/2019a/lib/python3.7/site-packages, outside environment /localscratch/yinan.29019325.0/env
    Can't uninstall 'requests'. No files were found to uninstall.
Successfully installed boto3-1.21.14+computecanada botocore-1.24.14+computecanada charset-normalizer-2.0.12+computecanada filelock-3.4.2+computecanada jmespath-0.10.0+computecanada joblib-1.1.0+computecanada regex-2020.11.13+computecanada requests-2.27.1+computecanada s3transfer-0.5.1+computecanada sacremoses-0.0.46+computecanada sentencepiece-0.1.91+computecanada tokenizers-0.5.2+computecanada tqdm-4.63.0+computecanada transformers-2.5.1+computecanada urllib3-1.26.8+computecanada
Looking in links: /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/nix/avx2, /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/nix/generic, /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/tensorflow_gpu-2.3.0+computecanada-cp37-cp37m-linux_x86_64.whl
Requirement already satisfied: wheel>=0.26 in /localscratch/yinan.29019325.0/env/lib/python3.7/site-packages (from tensorflow_gpu==2.3.0+computecanada) (0.33.4)
Requirement already satisfied: termcolor>=1.1.0 in /localscratch/yinan.29019325.0/env/lib/python3.7/site-packages (from tensorflow_gpu==2.3.0+computecanada) (1.1.0+computecanada)
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/tensorboard-2.8.0+computecanada-py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/wrapt-1.11.2+computecanada-cp37-cp37m-linux_x86_64.whl
Requirement already satisfied: protobuf>=3.9.2 in /localscratch/yinan.29019325.0/env/lib/python3.7/site-packages (from tensorflow_gpu==2.3.0+computecanada) (3.19.4+computecanada)
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/nix/avx2/h5py-2.10.0+computecanada-cp37-cp37m-linux_x86_64.whl
Requirement already satisfied: numpy<1.19.0,>=1.16.0 in /cvmfs/soft.computecanada.ca/easybuild/software/2017/Core/scipy-stack/2019a/lib/python3.7/site-packages (from tensorflow_gpu==2.3.0+computecanada) (1.16.0)
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/nix/generic/scipy-1.4.1+computecanada-cp37-cp37m-linux_x86_64.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/gast-0.3.3+computecanada-py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/google_pasta-0.2.0+computecanada-py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/grpcio-1.38.0+computecanada-cp37-cp37m-linux_x86_64.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/tensorflow_estimator-2.3.0+computecanada-py2.py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/absl_py-1.0.0+computecanada-py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/astunparse-1.6.3+computecanada-py2.py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/opt_einsum-3.3.0+computecanada-py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/Keras_Preprocessing-1.1.2+computecanada-py3-none-any.whl
Requirement already satisfied: six>=1.12.0 in /localscratch/yinan.29019325.0/env/lib/python3.7/site-packages (from tensorflow_gpu==2.3.0+computecanada) (1.16.0+computecanada)
Requirement already satisfied: setuptools>=41.0.0 in /localscratch/yinan.29019325.0/env/lib/python3.7/site-packages (from tensorboard<3,>=2.3.0->tensorflow_gpu==2.3.0+computecanada) (41.0.1)
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/tensorboard_plugin_wit-1.8.0+computecanada-py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/google_auth_oauthlib-0.4.6+computecanada-py2.py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/Markdown-3.3.6+computecanada-py3-none-any.whl
Requirement already satisfied: requests<3,>=2.21.0 in /localscratch/yinan.29019325.0/env/lib/python3.7/site-packages (from tensorboard<3,>=2.3.0->tensorflow_gpu==2.3.0+computecanada) (2.27.1+computecanada)
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/tensorboard_data_server-0.6.1+computecanada-py3-none-linux_x86_64.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/google_auth-2.3.3+computecanada-py2.py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/Werkzeug-2.0.3+computecanada-py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/pyasn1_modules-0.2.8+computecanada-py2.py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/cachetools-4.2.4+computecanada-py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/rsa-4.8+computecanada-py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/requests_oauthlib-1.3.0+computecanada-py2.py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/importlib_metadata-4.10.1+computecanada-py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/zipp-3.7.0+computecanada-py3-none-any.whl
Requirement already satisfied: typing-extensions>=3.6.4 in /localscratch/yinan.29019325.0/env/lib/python3.7/site-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard<3,>=2.3.0->tensorflow_gpu==2.3.0+computecanada) (4.0.1+computecanada)
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/pyasn1-0.4.8+computecanada-py2.py3-none-any.whl
Requirement already satisfied: charset-normalizer~=2.0.0 in /localscratch/yinan.29019325.0/env/lib/python3.7/site-packages (from requests<3,>=2.21.0->tensorboard<3,>=2.3.0->tensorflow_gpu==2.3.0+computecanada) (2.0.12+computecanada)
Requirement already satisfied: idna<4,>=2.5 in /cvmfs/soft.computecanada.ca/easybuild/software/2017/Core/scipy-stack/2019a/lib/python3.7/site-packages (from requests<3,>=2.21.0->tensorboard<3,>=2.3.0->tensorflow_gpu==2.3.0+computecanada) (2.8)
Requirement already satisfied: urllib3<1.27,>=1.21.1 in /localscratch/yinan.29019325.0/env/lib/python3.7/site-packages (from requests<3,>=2.21.0->tensorboard<3,>=2.3.0->tensorflow_gpu==2.3.0+computecanada) (1.26.8+computecanada)
Requirement already satisfied: certifi>=2017.4.17 in /cvmfs/soft.computecanada.ca/easybuild/software/2017/Core/scipy-stack/2019a/lib/python3.7/site-packages (from requests<3,>=2.21.0->tensorboard<3,>=2.3.0->tensorflow_gpu==2.3.0+computecanada) (2018.11.29)
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/oauthlib-3.1.1+computecanada-py2.py3-none-any.whl
Installing collected packages: pyasn1, zipp, rsa, pyasn1-modules, oauthlib, cachetools, requests-oauthlib, importlib-metadata, google-auth, werkzeug, tensorboard-plugin-wit, tensorboard-data-server, markdown, grpcio, google-auth-oauthlib, absl-py, wrapt, tensorflow-estimator, tensorboard, scipy, opt-einsum, keras-preprocessing, h5py, google-pasta, gast, astunparse, tensorflow-gpu
  Attempting uninstall: pyasn1
    Found existing installation: pyasn1 0.4.3
    Not uninstalling pyasn1 at /cvmfs/soft.computecanada.ca/easybuild/software/2017/Core/scipy-stack/2019a/lib/python3.7/site-packages, outside environment /localscratch/yinan.29019325.0/env
    Can't uninstall 'pyasn1'. No files were found to uninstall.
  Attempting uninstall: zipp
    Found existing installation: zipp 0.3.3
    Not uninstalling zipp at /cvmfs/soft.computecanada.ca/easybuild/software/2017/Core/scipy-stack/2019a/lib/python3.7/site-packages, outside environment /localscratch/yinan.29019325.0/env
    Can't uninstall 'zipp'. No files were found to uninstall.
  Attempting uninstall: importlib-metadata
    Found existing installation: importlib-metadata 0.8
    Not uninstalling importlib-metadata at /cvmfs/soft.computecanada.ca/easybuild/software/2017/Core/scipy-stack/2019a/lib/python3.7/site-packages, outside environment /localscratch/yinan.29019325.0/env
    Can't uninstall 'importlib-metadata'. No files were found to uninstall.
  Attempting uninstall: scipy
    Found existing installation: scipy 1.2.0
    Not uninstalling scipy at /cvmfs/soft.computecanada.ca/easybuild/software/2017/Core/scipy-stack/2019a/lib/python3.7/site-packages, outside environment /localscratch/yinan.29019325.0/env
    Can't uninstall 'scipy'. No files were found to uninstall.
Successfully installed absl-py-1.0.0+computecanada astunparse-1.6.3+computecanada cachetools-4.2.4+computecanada gast-0.3.3+computecanada google-auth-2.3.3+computecanada google-auth-oauthlib-0.4.6+computecanada google-pasta-0.2.0+computecanada grpcio-1.38.0+computecanada h5py-2.10.0+computecanada importlib-metadata-4.10.1+computecanada keras-preprocessing-1.1.2+computecanada markdown-3.3.6+computecanada oauthlib-3.1.1+computecanada opt-einsum-3.3.0+computecanada pyasn1-0.4.8+computecanada pyasn1-modules-0.2.8+computecanada requests-oauthlib-1.3.0+computecanada rsa-4.8+computecanada scipy-1.4.1+computecanada tensorboard-2.8.0+computecanada tensorboard-data-server-0.6.1+computecanada tensorboard-plugin-wit-1.8.0+computecanada tensorflow-estimator-2.3.0+computecanada tensorflow-gpu-2.3.0+computecanada werkzeug-2.0.3+computecanada wrapt-1.11.2+computecanada zipp-3.7.0+computecanada
Looking in links: /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/nix/avx2, /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/nix/generic, /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/keras-2.8.0+computecanada-py2.py3-none-any.whl
Installing collected packages: Keras
Successfully installed Keras-2.8.0+computecanada
Looking in links: /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/nix/avx2, /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/nix/generic, /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/urllib3-1.26.7+computecanada-py2.py3-none-any.whl
Installing collected packages: urllib3
  Attempting uninstall: urllib3
    Found existing installation: urllib3 1.26.8+computecanada
    Uninstalling urllib3-1.26.8+computecanada:
      Successfully uninstalled urllib3-1.26.8+computecanada
Successfully installed urllib3-1.26.7+computecanada
Looking in links: /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/nix/avx2, /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/nix/generic, /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/nltk-3.7+computecanada-py3-none-any.whl
Requirement already satisfied: joblib in /localscratch/yinan.29019325.0/env/lib/python3.7/site-packages (from nltk) (1.1.0+computecanada)
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/nltk-3.6.5+computecanada-py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/nltk-3.6.3+computecanada-py3-none-any.whl
Requirement already satisfied: click in /localscratch/yinan.29019325.0/env/lib/python3.7/site-packages (from nltk) (8.0.4+computecanada)
Requirement already satisfied: regex in /localscratch/yinan.29019325.0/env/lib/python3.7/site-packages (from nltk) (2020.11.13+computecanada)
Requirement already satisfied: tqdm in /localscratch/yinan.29019325.0/env/lib/python3.7/site-packages (from nltk) (4.63.0+computecanada)
Requirement already satisfied: importlib-metadata in /localscratch/yinan.29019325.0/env/lib/python3.7/site-packages (from click->nltk) (4.10.1+computecanada)
Requirement already satisfied: zipp>=0.5 in /localscratch/yinan.29019325.0/env/lib/python3.7/site-packages (from importlib-metadata->click->nltk) (3.7.0+computecanada)
Requirement already satisfied: typing-extensions>=3.6.4 in /localscratch/yinan.29019325.0/env/lib/python3.7/site-packages (from importlib-metadata->click->nltk) (4.0.1+computecanada)
Installing collected packages: nltk
Successfully installed nltk-3.6.3+computecanada
Looking in links: /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/nix/avx2, /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/nix/generic, /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/scikit_learn-0.22.1+computecanada-cp37-cp37m-linux_x86_64.whl
Requirement already satisfied: scipy>=0.17.0 in /localscratch/yinan.29019325.0/env/lib/python3.7/site-packages (from scikit-learn==0.22.1) (1.4.1+computecanada)
Requirement already satisfied: numpy>=1.11.0 in /cvmfs/soft.computecanada.ca/easybuild/software/2017/Core/scipy-stack/2019a/lib/python3.7/site-packages (from scikit-learn==0.22.1) (1.16.0)
Requirement already satisfied: joblib>=0.11 in /localscratch/yinan.29019325.0/env/lib/python3.7/site-packages (from scikit-learn==0.22.1) (1.1.0+computecanada)
Installing collected packages: scikit-learn
Successfully installed scikit-learn-0.22.1+computecanada
Looking in links: /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/nix/avx2, /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/nix/generic, /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic
Requirement already satisfied: tokenizers==0.5.2 in /localscratch/yinan.29019325.0/env/lib/python3.7/site-packages (0.5.2+computecanada)
wandb: Appending key for api.wandb.ai to your netrc file: /home/yinan/.netrc
Starting Task
2022-03-18 19:30:26.575809: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1
[nltk_data] Downloading package stopwords to /home/yinan/nltk_data...
[nltk_data]   Package stopwords is already up-to-date!
[nltk_data] Downloading package wordnet to /home/yinan/nltk_data...
[nltk_data]   Package wordnet is already up-to-date!
wandb: Currently logged in as: yinanazhou (use `wandb login --relogin` to force relogin)
wandb: wandb version 0.12.11 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
2022-03-18 19:30:34.424122: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1
wandb: Tracking run with wandb version 0.12.5
wandb: Syncing run hardy-universe-2
wandb: ⭐️ View project at https://wandb.ai/yinanazhou/xl_512_bs_8_lr_1e06_es_10_lc_False_nr_True_sr_True_stem_False_lemma_False_repeat_1_fold_1
wandb: 🚀 View run at https://wandb.ai/yinanazhou/xl_512_bs_8_lr_1e06_es_10_lc_False_nr_True_sr_True_stem_False_lemma_False_repeat_1_fold_1/runs/ght8sq1h
wandb: Run data is saved locally in /project/6002780/yinan/Thesis_MER_Lyrics/lyric-emotion/wandb/run-20220318_193032-ght8sq1h
wandb: Run `wandb offline` to turn off syncing.

Validation loss decreased (inf --> 1.429600).  Saving model ...
Validation loss decreased (1.429600 --> 1.410385).  Saving model ...
Validation loss decreased (1.410385 --> 1.394080).  Saving model ...
Validation loss decreased (1.394080 --> 1.380662).  Saving model ...
Validation loss decreased (1.380662 --> 1.370896).  Saving model ...
Validation loss decreased (1.370896 --> 1.362502).  Saving model ...
Validation loss decreased (1.362502 --> 1.355436).  Saving model ...
Validation loss decreased (1.355436 --> 1.349156).  Saving model ...
Validation loss decreased (1.349156 --> 1.343793).  Saving model ...
Validation loss decreased (1.343793 --> 1.337508).  Saving model ...
Validation loss decreased (1.337508 --> 1.330770).  Saving model ...
Validation loss decreased (1.330770 --> 1.324264).  Saving model ...
Validation loss decreased (1.324264 --> 1.316877).  Saving model ...
Validation loss decreased (1.316877 --> 1.310369).  Saving model ...
Validation loss decreased (1.310369 --> 1.302884).  Saving model ...
Validation loss decreased (1.302884 --> 1.296671).  Saving model ...
Validation loss decreased (1.296671 --> 1.290373).  Saving model ...
Validation loss decreased (1.290373 --> 1.284573).  Saving model ...
Validation loss decreased (1.284573 --> 1.277657).  Saving model ...
Validation loss decreased (1.277657 --> 1.271099).  Saving model ...
Validation loss decreased (1.271099 --> 1.265859).  Saving model ...
Validation loss decreased (1.265859 --> 1.259554).  Saving model ...
Validation loss decreased (1.259554 --> 1.255607).  Saving model ...
Validation loss decreased (1.255607 --> 1.250319).  Saving model ...
Validation loss decreased (1.250319 --> 1.244931).  Saving model ...
Validation loss decreased (1.244931 --> 1.238956).  Saving model ...
Validation loss decreased (1.238956 --> 1.235755).  Saving model ...
Validation loss decreased (1.235755 --> 1.231985).  Saving model ...
Validation loss decreased (1.231985 --> 1.227440).  Saving model ...
Validation loss decreased (1.227440 --> 1.222980).  Saving model ...
Validation loss decreased (1.222980 --> 1.216412).  Saving model ...
Validation loss decreased (1.216412 --> 1.213069).  Saving model ...
Validation loss decreased (1.213069 --> 1.209403).  Saving model ...
Validation loss decreased (1.209403 --> 1.205208).  Saving model ...
Validation loss decreased (1.205208 --> 1.202612).  Saving model ...
Validation loss decreased (1.202612 --> 1.196992).  Saving model ...
Validation loss decreased (1.196992 --> 1.193183).  Saving model ...
Validation loss decreased (1.193183 --> 1.188724).  Saving model ...
Validation loss decreased (1.188724 --> 1.186015).  Saving model ...
Validation loss decreased (1.186015 --> 1.183379).  Saving model ...
Validation loss decreased (1.183379 --> 1.178362).  Saving model ...
Validation loss decreased (1.178362 --> 1.171461).  Saving model ...
Validation loss decreased (1.171461 --> 1.167169).  Saving model ...
Validation loss decreased (1.167169 --> 1.162174).  Saving model ...
Validation loss decreased (1.162174 --> 1.159629).  Saving model ...
Validation loss decreased (1.159629 --> 1.154833).  Saving model ...
Validation loss decreased (1.154833 --> 1.152685).  Saving model ...
Validation loss decreased (1.152685 --> 1.147362).  Saving model ...
Validation loss decreased (1.147362 --> 1.143553).  Saving model ...
Validation loss decreased (1.143553 --> 1.139954).  Saving model ...
Validation loss decreased (1.139954 --> 1.136704).  Saving model ...
Validation loss decreased (1.136704 --> 1.131663).  Saving model ...
Validation loss decreased (1.131663 --> 1.129135).  Saving model ...
Validation loss decreased (1.129135 --> 1.128595).  Saving model ...
Validation loss decreased (1.128595 --> 1.127817).  Saving model ...
Validation loss decreased (1.127817 --> 1.122117).  Saving model ...
Validation loss decreased (1.122117 --> 1.119037).  Saving model ...
Validation loss decreased (1.119037 --> 1.118276).  Saving model ...
Validation loss decreased (1.118276 --> 1.114950).  Saving model ...
Validation loss decreased (1.114950 --> 1.113175).  Saving model ...
Validation loss decreased (1.113175 --> 1.110189).  Saving model ...
Validation loss decreased (1.110189 --> 1.107169).  Saving model ...
Validation loss decreased (1.107169 --> 1.101274).  Saving model ...
EarlyStopping counter: 1 out of 10.0
Validation loss decreased (1.101274 --> 1.098784).  Saving model ...
Validation loss decreased (1.098784 --> 1.093759).  Saving model ...
Validation loss decreased (1.093759 --> 1.093277).  Saving model ...
Validation loss decreased (1.093277 --> 1.092787).  Saving model ...
Validation loss decreased (1.092787 --> 1.090120).  Saving model ...
Validation loss decreased (1.090120 --> 1.089025).  Saving model ...
Validation loss decreased (1.089025 --> 1.086281).  Saving model ...
Validation loss decreased (1.086281 --> 1.082353).  Saving model ...
Validation loss decreased (1.082353 --> 1.080264).  Saving model ...
Validation loss decreased (1.080264 --> 1.076957).  Saving model ...
Validation loss decreased (1.076957 --> 1.075534).  Saving model ...
Validation loss decreased (1.075534 --> 1.075454).  Saving model ...
Validation loss decreased (1.075454 --> 1.074792).  Saving model ...
Validation loss decreased (1.074792 --> 1.073175).  Saving model ...
Validation loss decreased (1.073175 --> 1.071405).  Saving model ...
Validation loss decreased (1.071405 --> 1.067513).  Saving model ...
EarlyStopping counter: 1 out of 10.0
EarlyStopping counter: 2 out of 10.0
Validation loss decreased (1.067513 --> 1.067188).  Saving model ...
Validation loss decreased (1.067188 --> 1.062826).  Saving model ...
Validation loss decreased (1.062826 --> 1.059094).  Saving model ...
Validation loss decreased (1.059094 --> 1.056950).  Saving model ...
Validation loss decreased (1.056950 --> 1.056275).  Saving model ...
EarlyStopping counter: 1 out of 10.0
Validation loss decreased (1.056275 --> 1.056256).  Saving model ...
Validation loss decreased (1.056256 --> 1.054491).  Saving model ...
Validation loss decreased (1.054491 --> 1.053576).  Saving model ...
Validation loss decreased (1.053576 --> 1.050760).  Saving model ...
EarlyStopping counter: 1 out of 10.0
EarlyStopping counter: 2 out of 10.0
EarlyStopping counter: 3 out of 10.0
Validation loss decreased (1.050760 --> 1.049001).  Saving model ...
EarlyStopping counter: 1 out of 10.0
Validation loss decreased (1.049001 --> 1.043201).  Saving model ...
EarlyStopping counter: 1 out of 10.0
EarlyStopping counter: 2 out of 10.0
EarlyStopping counter: 3 out of 10.0
EarlyStopping counter: 4 out of 10.0
Validation loss decreased (1.043201 --> 1.041728).  Saving model ...
Validation loss decreased (1.041728 --> 1.039628).  Saving model ...
EarlyStopping counter: 1 out of 10.0
EarlyStopping counter: 2 out of 10.0
Validation loss decreased (1.039628 --> 1.038793).  Saving model ...
Validation loss decreased (1.038793 --> 1.038250).  Saving model ...
Validation loss decreased (1.038250 --> 1.036819).  Saving model ...
EarlyStopping counter: 1 out of 10.0
EarlyStopping counter: 2 out of 10.0
EarlyStopping counter: 3 out of 10.0
EarlyStopping counter: 4 out of 10.0
EarlyStopping counter: 5 out of 10.0
Validation loss decreased (1.036819 --> 1.036669).  Saving model ...
Validation loss decreased (1.036669 --> 1.036198).  Saving model ...
Validation loss decreased (1.036198 --> 1.035761).  Saving model ...
Validation loss decreased (1.035761 --> 1.030252).  Saving model ...
EarlyStopping counter: 1 out of 10.0
EarlyStopping counter: 2 out of 10.0
EarlyStopping counter: 3 out of 10.0
EarlyStopping counter: 4 out of 10.0
EarlyStopping counter: 5 out of 10.0
Validation loss decreased (1.030252 --> 1.029590).  Saving model ...
Validation loss decreased (1.029590 --> 1.027783).  Saving model ...
EarlyStopping counter: 1 out of 10.0
EarlyStopping counter: 2 out of 10.0
EarlyStopping counter: 3 out of 10.0
EarlyStopping counter: 4 out of 10.0
EarlyStopping counter: 5 out of 10.0
EarlyStopping counter: 6 out of 10.0
EarlyStopping counter: 7 out of 10.0
EarlyStopping counter: 8 out of 10.0
Validation loss decreased (1.027783 --> 1.026676).  Saving model ...
EarlyStopping counter: 1 out of 10.0
EarlyStopping counter: 2 out of 10.0
EarlyStopping counter: 3 out of 10.0
EarlyStopping counter: 4 out of 10.0
EarlyStopping counter: 5 out of 10.0
EarlyStopping counter: 6 out of 10.0
EarlyStopping counter: 7 out of 10.0
EarlyStopping counter: 8 out of 10.0
EarlyStopping counter: 9 out of 10.0
EarlyStopping counter: 10 out of 10.0
/localscratch/yinan.29019325.0/env/lib/python3.7/site-packages/torch/nn/functional.py:1794: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.
  warnings.warn("nn.functional.tanh is deprecated. Use torch.tanh instead.")
/localscratch/yinan.29019325.0/env/lib/python3.7/site-packages/transformers/optimization.py:155: UserWarning: This overload of add_ is deprecated:
	add_(Number alpha, Tensor other)
Consider using one of the following signatures instead:
	add_(Tensor other, *, Number alpha) (Triggered internally at  ../torch/csrc/utils/python_arg_parser.cpp:1025.)
  exp_avg.mul_(beta1).add_(1.0 - beta1, grad)
wandb: Waiting for W&B process to finish, PID 246995... (success).
wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: \ 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: | 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: / 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: \ 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: | 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: / 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: \ 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: | 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: / 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb:                                                                                
wandb: Run history:
wandb:     e_F1 ▁▂▃▄▄▅▅▆▆▆▆▆▆▆▇▇▇▇▇▇▇▇▇█████████████████
wandb:   e_loss █▇▇▆▆▅▅▅▅▄▄▄▃▃▃▃▃▂▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:     t_F1 ▁▂▃▃▃▄▄▅▅▅▆▅▆▆▆▅▆▇▇▆▆▇▇▇▇▇▇▇▇█▇█████████
wandb:   t_loss ██▇▇▇▆▆▆▅▅▅▅▄▄▄▄▄▄▃▃▃▃▃▃▂▂▂▂▂▂▂▂▂▂▂▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:     e_F1 57.09748
wandb:   e_loss 1.03368
wandb:     t_F1 71.59153
wandb:   t_loss 0.70488
wandb: 
wandb: Synced 4 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Synced hardy-universe-2: https://wandb.ai/yinanazhou/xl_512_bs_8_lr_1e06_es_10_lc_False_nr_True_sr_True_stem_False_lemma_False_repeat_1_fold_1/runs/ght8sq1h
wandb: Find logs at: ./wandb/run-20220318_193032-ght8sq1h/logs/debug.log
wandb: 

wandb: wandb version 0.12.11 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
2022-03-18 21:04:53.129084: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1
wandb: Tracking run with wandb version 0.12.5
wandb: Syncing run tough-puddle-2
wandb: ⭐️ View project at https://wandb.ai/yinanazhou/xl_512_bs_8_lr_1e06_es_10_lc_False_nr_True_sr_True_stem_False_lemma_False_repeat_1_fold_2
wandb: 🚀 View run at https://wandb.ai/yinanazhou/xl_512_bs_8_lr_1e06_es_10_lc_False_nr_True_sr_True_stem_False_lemma_False_repeat_1_fold_2/runs/3tez0oyr
wandb: Run data is saved locally in /project/6002780/yinan/Thesis_MER_Lyrics/lyric-emotion/wandb/run-20220318_210450-3tez0oyr
wandb: Run `wandb offline` to turn off syncing.

Validation loss decreased (inf --> 1.602744).  Saving model ...
Validation loss decreased (1.602744 --> 1.525295).  Saving model ...
Validation loss decreased (1.525295 --> 1.471161).  Saving model ...
Validation loss decreased (1.471161 --> 1.434435).  Saving model ...
Validation loss decreased (1.434435 --> 1.407491).  Saving model ...
Validation loss decreased (1.407491 --> 1.390646).  Saving model ...
Validation loss decreased (1.390646 --> 1.378747).  Saving model ...
Validation loss decreased (1.378747 --> 1.369523).  Saving model ...
Validation loss decreased (1.369523 --> 1.362026).  Saving model ...
Validation loss decreased (1.362026 --> 1.355445).  Saving model ...
Validation loss decreased (1.355445 --> 1.348767).  Saving model ...
Validation loss decreased (1.348767 --> 1.341722).  Saving model ...
Validation loss decreased (1.341722 --> 1.334683).  Saving model ...
Validation loss decreased (1.334683 --> 1.326647).  Saving model ...
Validation loss decreased (1.326647 --> 1.316934).  Saving model ...
Validation loss decreased (1.316934 --> 1.309397).  Saving model ...
Validation loss decreased (1.309397 --> 1.301203).  Saving model ...
Validation loss decreased (1.301203 --> 1.294438).  Saving model ...
Validation loss decreased (1.294438 --> 1.287807).  Saving model ...
Validation loss decreased (1.287807 --> 1.279948).  Saving model ...
Validation loss decreased (1.279948 --> 1.271769).  Saving model ...
Validation loss decreased (1.271769 --> 1.262286).  Saving model ...
Validation loss decreased (1.262286 --> 1.254451).  Saving model ...
Validation loss decreased (1.254451 --> 1.247401).  Saving model ...
Validation loss decreased (1.247401 --> 1.240400).  Saving model ...
Validation loss decreased (1.240400 --> 1.233594).  Saving model ...
Validation loss decreased (1.233594 --> 1.225934).  Saving model ...
Validation loss decreased (1.225934 --> 1.219162).  Saving model ...
Validation loss decreased (1.219162 --> 1.212633).  Saving model ...
Validation loss decreased (1.212633 --> 1.204736).  Saving model ...
Validation loss decreased (1.204736 --> 1.198945).  Saving model ...
Validation loss decreased (1.198945 --> 1.191083).  Saving model ...
Validation loss decreased (1.191083 --> 1.184724).  Saving model ...
Validation loss decreased (1.184724 --> 1.179537).  Saving model ...
Validation loss decreased (1.179537 --> 1.172689).  Saving model ...
Validation loss decreased (1.172689 --> 1.166541).  Saving model ...
Validation loss decreased (1.166541 --> 1.161841).  Saving model ...
Validation loss decreased (1.161841 --> 1.155689).  Saving model ...
Validation loss decreased (1.155689 --> 1.150087).  Saving model ...
Validation loss decreased (1.150087 --> 1.143933).  Saving model ...
Validation loss decreased (1.143933 --> 1.138462).  Saving model ...
Validation loss decreased (1.138462 --> 1.132459).  Saving model ...
Validation loss decreased (1.132459 --> 1.127887).  Saving model ...
Validation loss decreased (1.127887 --> 1.122557).  Saving model ...
Validation loss decreased (1.122557 --> 1.115919).  Saving model ...
Validation loss decreased (1.115919 --> 1.111540).  Saving model ...
Validation loss decreased (1.111540 --> 1.106981).  Saving model ...
Validation loss decreased (1.106981 --> 1.104218).  Saving model ...
Validation loss decreased (1.104218 --> 1.097636).  Saving model ...
Validation loss decreased (1.097636 --> 1.093625).  Saving model ...
Validation loss decreased (1.093625 --> 1.087193).  Saving model ...
Validation loss decreased (1.087193 --> 1.082455).  Saving model ...
Validation loss decreased (1.082455 --> 1.077454).  Saving model ...
Validation loss decreased (1.077454 --> 1.071368).  Saving model ...
Validation loss decreased (1.071368 --> 1.067498).  Saving model ...
Validation loss decreased (1.067498 --> 1.062800).  Saving model ...
Validation loss decreased (1.062800 --> 1.060386).  Saving model ...
Validation loss decreased (1.060386 --> 1.057178).  Saving model ...
Validation loss decreased (1.057178 --> 1.054229).  Saving model ...
Validation loss decreased (1.054229 --> 1.052060).  Saving model ...
Validation loss decreased (1.052060 --> 1.046380).  Saving model ...
Validation loss decreased (1.046380 --> 1.043749).  Saving model ...
Validation loss decreased (1.043749 --> 1.039107).  Saving model ...
Validation loss decreased (1.039107 --> 1.033437).  Saving model ...
Validation loss decreased (1.033437 --> 1.030790).  Saving model ...
Validation loss decreased (1.030790 --> 1.028039).  Saving model ...
Validation loss decreased (1.028039 --> 1.023731).  Saving model ...
Validation loss decreased (1.023731 --> 1.017866).  Saving model ...
Validation loss decreased (1.017866 --> 1.014511).  Saving model ...
Validation loss decreased (1.014511 --> 1.012333).  Saving model ...
Validation loss decreased (1.012333 --> 1.009831).  Saving model ...
Validation loss decreased (1.009831 --> 1.007793).  Saving model ...
Validation loss decreased (1.007793 --> 1.005016).  Saving model ...
Validation loss decreased (1.005016 --> 1.003666).  Saving model ...
Validation loss decreased (1.003666 --> 0.998668).  Saving model ...
Validation loss decreased (0.998668 --> 0.994864).  Saving model ...
Validation loss decreased (0.994864 --> 0.993202).  Saving model ...
Validation loss decreased (0.993202 --> 0.990385).  Saving model ...
Validation loss decreased (0.990385 --> 0.988512).  Saving model ...
Validation loss decreased (0.988512 --> 0.985834).  Saving model ...
Validation loss decreased (0.985834 --> 0.984101).  Saving model ...
Validation loss decreased (0.984101 --> 0.980935).  Saving model ...
Validation loss decreased (0.980935 --> 0.977429).  Saving model ...
Validation loss decreased (0.977429 --> 0.975263).  Saving model ...
Validation loss decreased (0.975263 --> 0.975168).  Saving model ...
Validation loss decreased (0.975168 --> 0.973624).  Saving model ...
Validation loss decreased (0.973624 --> 0.971445).  Saving model ...
Validation loss decreased (0.971445 --> 0.970806).  Saving model ...
Validation loss decreased (0.970806 --> 0.969775).  Saving model ...
Validation loss decreased (0.969775 --> 0.967078).  Saving model ...
Validation loss decreased (0.967078 --> 0.966904).  Saving model ...
Validation loss decreased (0.966904 --> 0.963887).  Saving model ...
Validation loss decreased (0.963887 --> 0.962243).  Saving model ...
Validation loss decreased (0.962243 --> 0.960268).  Saving model ...
Validation loss decreased (0.960268 --> 0.958522).  Saving model ...
Validation loss decreased (0.958522 --> 0.957703).  Saving model ...
EarlyStopping counter: 1 out of 10.0
Validation loss decreased (0.957703 --> 0.955219).  Saving model ...
Validation loss decreased (0.955219 --> 0.954060).  Saving model ...
Validation loss decreased (0.954060 --> 0.951937).  Saving model ...
EarlyStopping counter: 1 out of 10.0
Validation loss decreased (0.951937 --> 0.951572).  Saving model ...
Validation loss decreased (0.951572 --> 0.949897).  Saving model ...
EarlyStopping counter: 1 out of 10.0
EarlyStopping counter: 2 out of 10.0
Validation loss decreased (0.949897 --> 0.948401).  Saving model ...
Validation loss decreased (0.948401 --> 0.947616).  Saving model ...
Validation loss decreased (0.947616 --> 0.945473).  Saving model ...
Validation loss decreased (0.945473 --> 0.943818).  Saving model ...
Validation loss decreased (0.943818 --> 0.943472).  Saving model ...
EarlyStopping counter: 1 out of 10.0
Validation loss decreased (0.943472 --> 0.943392).  Saving model ...
Validation loss decreased (0.943392 --> 0.942419).  Saving model ...
EarlyStopping counter: 1 out of 10.0
Validation loss decreased (0.942419 --> 0.941863).  Saving model ...
Validation loss decreased (0.941863 --> 0.941488).  Saving model ...
Validation loss decreased (0.941488 --> 0.939983).  Saving model ...
Validation loss decreased (0.939983 --> 0.939326).  Saving model ...
Validation loss decreased (0.939326 --> 0.938526).  Saving model ...
Validation loss decreased (0.938526 --> 0.938026).  Saving model ...
Validation loss decreased (0.938026 --> 0.937456).  Saving model ...
Validation loss decreased (0.937456 --> 0.936727).  Saving model ...
EarlyStopping counter: 1 out of 10.0
EarlyStopping counter: 2 out of 10.0
Validation loss decreased (0.936727 --> 0.935736).  Saving model ...
EarlyStopping counter: 1 out of 10.0
EarlyStopping counter: 2 out of 10.0
EarlyStopping counter: 3 out of 10.0
EarlyStopping counter: 4 out of 10.0
EarlyStopping counter: 5 out of 10.0
EarlyStopping counter: 6 out of 10.0
EarlyStopping counter: 7 out of 10.0
EarlyStopping counter: 8 out of 10.0
EarlyStopping counter: 9 out of 10.0
EarlyStopping counter: 10 out of 10.0
/localscratch/yinan.29019325.0/env/lib/python3.7/site-packages/torch/nn/functional.py:1794: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.
  warnings.warn("nn.functional.tanh is deprecated. Use torch.tanh instead.")
wandb: Waiting for W&B process to finish, PID 252125... (success).
wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: \ 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: | 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: / 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: \ 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: | 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: / 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: \ 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: | 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: / 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb:                                                                                
wandb: Run history:
wandb:     e_F1 ▁▁▄▅▄▅▅▆▆▆▆▆▇▇▇▇▇▇▇▇▇▇▇▇▇▇██████████████
wandb:   e_loss █▇▆▆▆▅▅▅▄▄▄▄▃▃▃▃▂▂▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:     t_F1 ▁▂▂▃▃▄▄▄▅▅▅▅▅▆▆▆▆▆▆▆▇▇▇▇▇▇▇▇▇▇▇▇▇▇██▇███
wandb:   t_loss █▇▇▆▆▆▆▆▅▅▅▅▅▄▄▄▄▄▄▃▃▃▃▃▃▃▂▂▂▂▂▂▂▂▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:     e_F1 61.53337
wandb:   e_loss 0.93907
wandb:     t_F1 71.48294
wandb:   t_loss 0.76842
wandb: 
wandb: Synced 4 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Synced tough-puddle-2: https://wandb.ai/yinanazhou/xl_512_bs_8_lr_1e06_es_10_lc_False_nr_True_sr_True_stem_False_lemma_False_repeat_1_fold_2/runs/3tez0oyr
wandb: Find logs at: ./wandb/run-20220318_210450-3tez0oyr/logs/debug.log
wandb: 

wandb: wandb version 0.12.11 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
2022-03-18 22:33:36.188590: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1
wandb: Tracking run with wandb version 0.12.5
wandb: Syncing run logical-totem-2
wandb: ⭐️ View project at https://wandb.ai/yinanazhou/xl_512_bs_8_lr_1e06_es_10_lc_False_nr_True_sr_True_stem_False_lemma_False_repeat_2_fold_1
wandb: 🚀 View run at https://wandb.ai/yinanazhou/xl_512_bs_8_lr_1e06_es_10_lc_False_nr_True_sr_True_stem_False_lemma_False_repeat_2_fold_1/runs/1nqjxlhh
wandb: Run data is saved locally in /project/6002780/yinan/Thesis_MER_Lyrics/lyric-emotion/wandb/run-20220318_223333-1nqjxlhh
wandb: Run `wandb offline` to turn off syncing.

Validation loss decreased (inf --> 1.451773).  Saving model ...
Validation loss decreased (1.451773 --> 1.420784).  Saving model ...
Validation loss decreased (1.420784 --> 1.399451).  Saving model ...
Validation loss decreased (1.399451 --> 1.385210).  Saving model ...
Validation loss decreased (1.385210 --> 1.375624).  Saving model ...
Validation loss decreased (1.375624 --> 1.368980).  Saving model ...
Validation loss decreased (1.368980 --> 1.363110).  Saving model ...
Validation loss decreased (1.363110 --> 1.357738).  Saving model ...
Validation loss decreased (1.357738 --> 1.352911).  Saving model ...
Validation loss decreased (1.352911 --> 1.348085).  Saving model ...
Validation loss decreased (1.348085 --> 1.342860).  Saving model ...
Validation loss decreased (1.342860 --> 1.337640).  Saving model ...
Validation loss decreased (1.337640 --> 1.333429).  Saving model ...
Validation loss decreased (1.333429 --> 1.328112).  Saving model ...
Validation loss decreased (1.328112 --> 1.322162).  Saving model ...
Validation loss decreased (1.322162 --> 1.315606).  Saving model ...
Validation loss decreased (1.315606 --> 1.308388).  Saving model ...
Validation loss decreased (1.308388 --> 1.300797).  Saving model ...
Validation loss decreased (1.300797 --> 1.294086).  Saving model ...
Validation loss decreased (1.294086 --> 1.286129).  Saving model ...
Validation loss decreased (1.286129 --> 1.278213).  Saving model ...
Validation loss decreased (1.278213 --> 1.270428).  Saving model ...
Validation loss decreased (1.270428 --> 1.261585).  Saving model ...
Validation loss decreased (1.261585 --> 1.252933).  Saving model ...
Validation loss decreased (1.252933 --> 1.245395).  Saving model ...
Validation loss decreased (1.245395 --> 1.236942).  Saving model ...
Validation loss decreased (1.236942 --> 1.228558).  Saving model ...
Validation loss decreased (1.228558 --> 1.221838).  Saving model ...
Validation loss decreased (1.221838 --> 1.213945).  Saving model ...
Validation loss decreased (1.213945 --> 1.206521).  Saving model ...
Validation loss decreased (1.206521 --> 1.197011).  Saving model ...
Validation loss decreased (1.197011 --> 1.190418).  Saving model ...
Validation loss decreased (1.190418 --> 1.183098).  Saving model ...
Validation loss decreased (1.183098 --> 1.175079).  Saving model ...
Validation loss decreased (1.175079 --> 1.168488).  Saving model ...
Validation loss decreased (1.168488 --> 1.161485).  Saving model ...
Validation loss decreased (1.161485 --> 1.154972).  Saving model ...
Validation loss decreased (1.154972 --> 1.149174).  Saving model ...
Validation loss decreased (1.149174 --> 1.143204).  Saving model ...
Validation loss decreased (1.143204 --> 1.136597).  Saving model ...
Validation loss decreased (1.136597 --> 1.130186).  Saving model ...
Validation loss decreased (1.130186 --> 1.124575).  Saving model ...
Validation loss decreased (1.124575 --> 1.118647).  Saving model ...
Validation loss decreased (1.118647 --> 1.112621).  Saving model ...
Validation loss decreased (1.112621 --> 1.108859).  Saving model ...
Validation loss decreased (1.108859 --> 1.102768).  Saving model ...
Validation loss decreased (1.102768 --> 1.098107).  Saving model ...
Validation loss decreased (1.098107 --> 1.094005).  Saving model ...
Validation loss decreased (1.094005 --> 1.088303).  Saving model ...
Validation loss decreased (1.088303 --> 1.083289).  Saving model ...
Validation loss decreased (1.083289 --> 1.079149).  Saving model ...
Validation loss decreased (1.079149 --> 1.074330).  Saving model ...
Validation loss decreased (1.074330 --> 1.069705).  Saving model ...
Validation loss decreased (1.069705 --> 1.065193).  Saving model ...
Validation loss decreased (1.065193 --> 1.061381).  Saving model ...
Validation loss decreased (1.061381 --> 1.057027).  Saving model ...
Validation loss decreased (1.057027 --> 1.053372).  Saving model ...
Validation loss decreased (1.053372 --> 1.050156).  Saving model ...
Validation loss decreased (1.050156 --> 1.046258).  Saving model ...
Validation loss decreased (1.046258 --> 1.043385).  Saving model ...
Validation loss decreased (1.043385 --> 1.041741).  Saving model ...
Validation loss decreased (1.041741 --> 1.038954).  Saving model ...
Validation loss decreased (1.038954 --> 1.034620).  Saving model ...
Validation loss decreased (1.034620 --> 1.030994).  Saving model ...
Validation loss decreased (1.030994 --> 1.027545).  Saving model ...
Validation loss decreased (1.027545 --> 1.023465).  Saving model ...
Validation loss decreased (1.023465 --> 1.020964).  Saving model ...
Validation loss decreased (1.020964 --> 1.017400).  Saving model ...
Validation loss decreased (1.017400 --> 1.014550).  Saving model ...
Validation loss decreased (1.014550 --> 1.011426).  Saving model ...
Validation loss decreased (1.011426 --> 1.007167).  Saving model ...
Validation loss decreased (1.007167 --> 1.004022).  Saving model ...
Validation loss decreased (1.004022 --> 1.001408).  Saving model ...
Validation loss decreased (1.001408 --> 0.999520).  Saving model ...
Validation loss decreased (0.999520 --> 0.996452).  Saving model ...
Validation loss decreased (0.996452 --> 0.993784).  Saving model ...
Validation loss decreased (0.993784 --> 0.992728).  Saving model ...
Validation loss decreased (0.992728 --> 0.990253).  Saving model ...
Validation loss decreased (0.990253 --> 0.989668).  Saving model ...
Validation loss decreased (0.989668 --> 0.988803).  Saving model ...
Validation loss decreased (0.988803 --> 0.987694).  Saving model ...
Validation loss decreased (0.987694 --> 0.985262).  Saving model ...
Validation loss decreased (0.985262 --> 0.981676).  Saving model ...
Validation loss decreased (0.981676 --> 0.980545).  Saving model ...
Validation loss decreased (0.980545 --> 0.978078).  Saving model ...
Validation loss decreased (0.978078 --> 0.976103).  Saving model ...
Validation loss decreased (0.976103 --> 0.973457).  Saving model ...
Validation loss decreased (0.973457 --> 0.972503).  Saving model ...
Validation loss decreased (0.972503 --> 0.971521).  Saving model ...
Validation loss decreased (0.971521 --> 0.969691).  Saving model ...
Validation loss decreased (0.969691 --> 0.968622).  Saving model ...
Validation loss decreased (0.968622 --> 0.968134).  Saving model ...
Validation loss decreased (0.968134 --> 0.967373).  Saving model ...
Validation loss decreased (0.967373 --> 0.965435).  Saving model ...
Validation loss decreased (0.965435 --> 0.963330).  Saving model ...
Validation loss decreased (0.963330 --> 0.961804).  Saving model ...
Validation loss decreased (0.961804 --> 0.960383).  Saving model ...
Validation loss decreased (0.960383 --> 0.958708).  Saving model ...
Validation loss decreased (0.958708 --> 0.957549).  Saving model ...
EarlyStopping counter: 1 out of 10.0
Validation loss decreased (0.957549 --> 0.956595).  Saving model ...
Validation loss decreased (0.956595 --> 0.955458).  Saving model ...
Validation loss decreased (0.955458 --> 0.953711).  Saving model ...
EarlyStopping counter: 1 out of 10.0
Validation loss decreased (0.953711 --> 0.952588).  Saving model ...
Validation loss decreased (0.952588 --> 0.952180).  Saving model ...
Validation loss decreased (0.952180 --> 0.951424).  Saving model ...
Validation loss decreased (0.951424 --> 0.950889).  Saving model ...
Validation loss decreased (0.950889 --> 0.949992).  Saving model ...
Validation loss decreased (0.949992 --> 0.949514).  Saving model ...
Validation loss decreased (0.949514 --> 0.949366).  Saving model ...
Validation loss decreased (0.949366 --> 0.948533).  Saving model ...
Validation loss decreased (0.948533 --> 0.947346).  Saving model ...
Validation loss decreased (0.947346 --> 0.946390).  Saving model ...
EarlyStopping counter: 1 out of 10.0
EarlyStopping counter: 2 out of 10.0
EarlyStopping counter: 3 out of 10.0
EarlyStopping counter: 4 out of 10.0
EarlyStopping counter: 5 out of 10.0
EarlyStopping counter: 6 out of 10.0
EarlyStopping counter: 7 out of 10.0
Validation loss decreased (0.946390 --> 0.944167).  Saving model ...
EarlyStopping counter: 1 out of 10.0
EarlyStopping counter: 2 out of 10.0
EarlyStopping counter: 3 out of 10.0
EarlyStopping counter: 4 out of 10.0
Validation loss decreased (0.944167 --> 0.943787).  Saving model ...
Validation loss decreased (0.943787 --> 0.942791).  Saving model ...
EarlyStopping counter: 1 out of 10.0
EarlyStopping counter: 2 out of 10.0
Validation loss decreased (0.942791 --> 0.941290).  Saving model ...
EarlyStopping counter: 1 out of 10.0
Validation loss decreased (0.941290 --> 0.940823).  Saving model ...
EarlyStopping counter: 1 out of 10.0
EarlyStopping counter: 2 out of 10.0
EarlyStopping counter: 3 out of 10.0
EarlyStopping counter: 4 out of 10.0
EarlyStopping counter: 5 out of 10.0
EarlyStopping counter: 6 out of 10.0
EarlyStopping counter: 7 out of 10.0
EarlyStopping counter: 8 out of 10.0
EarlyStopping counter: 9 out of 10.0
EarlyStopping counter: 10 out of 10.0
/localscratch/yinan.29019325.0/env/lib/python3.7/site-packages/torch/nn/functional.py:1794: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.
  warnings.warn("nn.functional.tanh is deprecated. Use torch.tanh instead.")
wandb: Waiting for W&B process to finish, PID 256931... (success).
wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: \ 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: | 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: / 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: \ 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: | 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: / 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: \ 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: | 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: / 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb:                                                                                
wandb: Run history:
wandb:     e_F1 ▁▂▄▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇▇▇▇▇▇▇██▇█████████████
wandb:   e_loss █▇▇▇▆▆▆▅▅▄▄▄▃▃▃▃▃▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:     t_F1 ▁▁▂▂▃▃▄▄▄▅▅▅▅▆▆▆▆▆▆▆▇▇▇▇▇▇▇▇█▇▇█████████
wandb:   t_loss ██▇▇▇▇▆▆▆▅▆▅▅▅▄▄▄▄▄▃▃▃▃▃▃▂▂▂▂▂▂▂▂▂▂▂▁▁▁▁
wandb: 
wandb: Run summary:
wandb:     e_F1 63.09622
wandb:   e_loss 0.943
wandb:     t_F1 75.0712
wandb:   t_loss 0.72047
wandb: 
wandb: Synced 4 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Synced logical-totem-2: https://wandb.ai/yinanazhou/xl_512_bs_8_lr_1e06_es_10_lc_False_nr_True_sr_True_stem_False_lemma_False_repeat_2_fold_1/runs/1nqjxlhh
wandb: Find logs at: ./wandb/run-20220318_223333-1nqjxlhh/logs/debug.log
wandb: 

wandb: wandb version 0.12.11 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
2022-03-19 00:07:22.547864: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1
wandb: Tracking run with wandb version 0.12.5
wandb: Syncing run logical-cosmos-2
wandb: ⭐️ View project at https://wandb.ai/yinanazhou/xl_512_bs_8_lr_1e06_es_10_lc_False_nr_True_sr_True_stem_False_lemma_False_repeat_2_fold_2
wandb: 🚀 View run at https://wandb.ai/yinanazhou/xl_512_bs_8_lr_1e06_es_10_lc_False_nr_True_sr_True_stem_False_lemma_False_repeat_2_fold_2/runs/1pglgnfn
wandb: Run data is saved locally in /project/6002780/yinan/Thesis_MER_Lyrics/lyric-emotion/wandb/run-20220319_000719-1pglgnfn
wandb: Run `wandb offline` to turn off syncing.

Validation loss decreased (inf --> 1.416152).  Saving model ...
Validation loss decreased (1.416152 --> 1.397166).  Saving model ...
Validation loss decreased (1.397166 --> 1.383917).  Saving model ...
Validation loss decreased (1.383917 --> 1.373929).  Saving model ...
Validation loss decreased (1.373929 --> 1.366787).  Saving model ...
Validation loss decreased (1.366787 --> 1.361233).  Saving model ...
Validation loss decreased (1.361233 --> 1.356195).  Saving model ...
Validation loss decreased (1.356195 --> 1.351269).  Saving model ...
Validation loss decreased (1.351269 --> 1.346751).  Saving model ...
Validation loss decreased (1.346751 --> 1.342010).  Saving model ...
Validation loss decreased (1.342010 --> 1.337436).  Saving model ...
Validation loss decreased (1.337436 --> 1.332721).  Saving model ...
Validation loss decreased (1.332721 --> 1.328230).  Saving model ...
Validation loss decreased (1.328230 --> 1.323502).  Saving model ...
Validation loss decreased (1.323502 --> 1.317703).  Saving model ...
Validation loss decreased (1.317703 --> 1.312457).  Saving model ...
Validation loss decreased (1.312457 --> 1.306363).  Saving model ...
Validation loss decreased (1.306363 --> 1.300039).  Saving model ...
Validation loss decreased (1.300039 --> 1.293743).  Saving model ...
Validation loss decreased (1.293743 --> 1.287140).  Saving model ...
Validation loss decreased (1.287140 --> 1.280389).  Saving model ...
Validation loss decreased (1.280389 --> 1.273015).  Saving model ...
Validation loss decreased (1.273015 --> 1.265420).  Saving model ...
Validation loss decreased (1.265420 --> 1.257255).  Saving model ...
Validation loss decreased (1.257255 --> 1.248973).  Saving model ...
Validation loss decreased (1.248973 --> 1.241688).  Saving model ...
Validation loss decreased (1.241688 --> 1.233939).  Saving model ...
Validation loss decreased (1.233939 --> 1.226988).  Saving model ...
Validation loss decreased (1.226988 --> 1.219490).  Saving model ...
Validation loss decreased (1.219490 --> 1.211148).  Saving model ...
Validation loss decreased (1.211148 --> 1.203077).  Saving model ...
Validation loss decreased (1.203077 --> 1.194993).  Saving model ...
Validation loss decreased (1.194993 --> 1.186791).  Saving model ...
Validation loss decreased (1.186791 --> 1.180569).  Saving model ...
Validation loss decreased (1.180569 --> 1.173609).  Saving model ...
Validation loss decreased (1.173609 --> 1.167162).  Saving model ...
Validation loss decreased (1.167162 --> 1.161459).  Saving model ...
Validation loss decreased (1.161459 --> 1.154378).  Saving model ...
Validation loss decreased (1.154378 --> 1.149807).  Saving model ...
Validation loss decreased (1.149807 --> 1.143880).  Saving model ...
Validation loss decreased (1.143880 --> 1.138442).  Saving model ...
Validation loss decreased (1.138442 --> 1.131823).  Saving model ...
Validation loss decreased (1.131823 --> 1.126053).  Saving model ...
Validation loss decreased (1.126053 --> 1.121263).  Saving model ...
Validation loss decreased (1.121263 --> 1.114273).  Saving model ...
Validation loss decreased (1.114273 --> 1.109428).  Saving model ...
Validation loss decreased (1.109428 --> 1.105459).  Saving model ...
Validation loss decreased (1.105459 --> 1.099273).  Saving model ...
Validation loss decreased (1.099273 --> 1.094435).  Saving model ...
Validation loss decreased (1.094435 --> 1.090116).  Saving model ...
Validation loss decreased (1.090116 --> 1.086624).  Saving model ...
Validation loss decreased (1.086624 --> 1.082061).  Saving model ...
Validation loss decreased (1.082061 --> 1.077519).  Saving model ...
Validation loss decreased (1.077519 --> 1.074603).  Saving model ...
Validation loss decreased (1.074603 --> 1.070497).  Saving model ...
Validation loss decreased (1.070497 --> 1.066993).  Saving model ...
Validation loss decreased (1.066993 --> 1.063471).  Saving model ...
Validation loss decreased (1.063471 --> 1.059495).  Saving model ...
Validation loss decreased (1.059495 --> 1.055367).  Saving model ...
Validation loss decreased (1.055367 --> 1.052055).  Saving model ...
Validation loss decreased (1.052055 --> 1.047000).  Saving model ...
Validation loss decreased (1.047000 --> 1.044480).  Saving model ...
Validation loss decreased (1.044480 --> 1.042278).  Saving model ...
Validation loss decreased (1.042278 --> 1.037604).  Saving model ...
Validation loss decreased (1.037604 --> 1.034072).  Saving model ...
Validation loss decreased (1.034072 --> 1.031299).  Saving model ...
Validation loss decreased (1.031299 --> 1.028321).  Saving model ...
Validation loss decreased (1.028321 --> 1.025758).  Saving model ...
Validation loss decreased (1.025758 --> 1.021938).  Saving model ...
Validation loss decreased (1.021938 --> 1.017894).  Saving model ...
Validation loss decreased (1.017894 --> 1.014409).  Saving model ...
Validation loss decreased (1.014409 --> 1.010525).  Saving model ...
Validation loss decreased (1.010525 --> 1.008185).  Saving model ...
Validation loss decreased (1.008185 --> 1.004127).  Saving model ...
Validation loss decreased (1.004127 --> 1.002998).  Saving model ...
Validation loss decreased (1.002998 --> 1.001543).  Saving model ...
Validation loss decreased (1.001543 --> 0.998364).  Saving model ...
Validation loss decreased (0.998364 --> 0.993857).  Saving model ...
Validation loss decreased (0.993857 --> 0.991451).  Saving model ...
Validation loss decreased (0.991451 --> 0.989534).  Saving model ...
Validation loss decreased (0.989534 --> 0.987007).  Saving model ...
Validation loss decreased (0.987007 --> 0.985981).  Saving model ...
Validation loss decreased (0.985981 --> 0.984277).  Saving model ...
Validation loss decreased (0.984277 --> 0.981614).  Saving model ...
Validation loss decreased (0.981614 --> 0.980346).  Saving model ...
Validation loss decreased (0.980346 --> 0.978941).  Saving model ...
Validation loss decreased (0.978941 --> 0.977401).  Saving model ...
Validation loss decreased (0.977401 --> 0.975518).  Saving model ...
Validation loss decreased (0.975518 --> 0.974386).  Saving model ...
Validation loss decreased (0.974386 --> 0.972495).  Saving model ...
Validation loss decreased (0.972495 --> 0.970459).  Saving model ...
Validation loss decreased (0.970459 --> 0.969015).  Saving model ...
Validation loss decreased (0.969015 --> 0.967390).  Saving model ...
Validation loss decreased (0.967390 --> 0.967116).  Saving model ...
Validation loss decreased (0.967116 --> 0.965477).  Saving model ...
Validation loss decreased (0.965477 --> 0.964724).  Saving model ...
EarlyStopping counter: 1 out of 10.0
EarlyStopping counter: 2 out of 10.0
Validation loss decreased (0.964724 --> 0.963626).  Saving model ...
Validation loss decreased (0.963626 --> 0.962570).  Saving model ...
Validation loss decreased (0.962570 --> 0.961010).  Saving model ...
EarlyStopping counter: 1 out of 10.0
Validation loss decreased (0.961010 --> 0.960165).  Saving model ...
Validation loss decreased (0.960165 --> 0.959226).  Saving model ...
Validation loss decreased (0.959226 --> 0.956675).  Saving model ...
Validation loss decreased (0.956675 --> 0.955186).  Saving model ...
Validation loss decreased (0.955186 --> 0.954931).  Saving model ...
Validation loss decreased (0.954931 --> 0.951548).  Saving model ...
EarlyStopping counter: 1 out of 10.0
EarlyStopping counter: 2 out of 10.0
Validation loss decreased (0.951548 --> 0.951057).  Saving model ...
Validation loss decreased (0.951057 --> 0.949879).  Saving model ...
Validation loss decreased (0.949879 --> 0.949050).  Saving model ...
EarlyStopping counter: 1 out of 10.0
EarlyStopping counter: 2 out of 10.0
EarlyStopping counter: 3 out of 10.0
Validation loss decreased (0.949050 --> 0.948431).  Saving model ...
Validation loss decreased (0.948431 --> 0.945976).  Saving model ...
EarlyStopping counter: 1 out of 10.0
EarlyStopping counter: 2 out of 10.0
EarlyStopping counter: 3 out of 10.0
EarlyStopping counter: 4 out of 10.0
EarlyStopping counter: 5 out of 10.0
EarlyStopping counter: 6 out of 10.0
EarlyStopping counter: 7 out of 10.0
Validation loss decreased (0.945976 --> 0.945366).  Saving model ...
Validation loss decreased (0.945366 --> 0.944002).  Saving model ...
EarlyStopping counter: 1 out of 10.0
Validation loss decreased (0.944002 --> 0.942563).  Saving model ...
EarlyStopping counter: 1 out of 10.0
EarlyStopping counter: 2 out of 10.0
EarlyStopping counter: 3 out of 10.0
EarlyStopping counter: 4 out of 10.0
EarlyStopping counter: 5 out of 10.0
EarlyStopping counter: 6 out of 10.0
EarlyStopping counter: 7 out of 10.0
EarlyStopping counter: 8 out of 10.0
EarlyStopping counter: 9 out of 10.0
EarlyStopping counter: 10 out of 10.0
/localscratch/yinan.29019325.0/env/lib/python3.7/site-packages/torch/nn/functional.py:1794: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.
  warnings.warn("nn.functional.tanh is deprecated. Use torch.tanh instead.")
wandb: Waiting for W&B process to finish, PID 262030... (success).
wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: \ 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: | 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: / 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: \ 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: | 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: / 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: \ 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: | 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: / 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: \ 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb:                                                                                
wandb: Run history:
wandb:     e_F1 ▁▂▄▄▄▅▅▆▅▆▆▆▆▇▇▇▇▇▇▇▇▇▇▇▇▇██████████████
wandb:   e_loss ██▇▇▇▇▆▆▅▅▄▄▄▄▃▃▃▃▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:     t_F1 ▁▁▂▃▃▄▄▄▅▅▅▅▅▅▆▆▆▆▇▇▇▇▆▇▇▇▇▇▇▇▇██▇█▇████
wandb:   t_loss ███▇▇▇▇▇▆▆▆▅▅▅▅▄▄▄▄▄▄▄▃▃▃▃▃▂▃▂▂▂▂▂▁▂▂▁▁▁
wandb: 
wandb: Run summary:
wandb:     e_F1 60.24922
wandb:   e_loss 0.94752
wandb:     t_F1 71.60856
wandb:   t_loss 0.75265
wandb: 
wandb: Synced 4 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Synced logical-cosmos-2: https://wandb.ai/yinanazhou/xl_512_bs_8_lr_1e06_es_10_lc_False_nr_True_sr_True_stem_False_lemma_False_repeat_2_fold_2/runs/1pglgnfn
wandb: Find logs at: ./wandb/run-20220319_000719-1pglgnfn/logs/debug.log
wandb: 

wandb: wandb version 0.12.11 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
2022-03-19 01:34:55.145550: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1
wandb: Tracking run with wandb version 0.12.5
wandb: Syncing run fancy-water-2
wandb: ⭐️ View project at https://wandb.ai/yinanazhou/xl_512_bs_8_lr_1e06_es_10_lc_False_nr_True_sr_True_stem_False_lemma_False_repeat_3_fold_1
wandb: 🚀 View run at https://wandb.ai/yinanazhou/xl_512_bs_8_lr_1e06_es_10_lc_False_nr_True_sr_True_stem_False_lemma_False_repeat_3_fold_1/runs/136ug5qa
wandb: Run data is saved locally in /project/6002780/yinan/Thesis_MER_Lyrics/lyric-emotion/wandb/run-20220319_013450-136ug5qa
wandb: Run `wandb offline` to turn off syncing.

Validation loss decreased (inf --> 1.527289).  Saving model ...
Validation loss decreased (1.527289 --> 1.480746).  Saving model ...
Validation loss decreased (1.480746 --> 1.444705).  Saving model ...
Validation loss decreased (1.444705 --> 1.416209).  Saving model ...
Validation loss decreased (1.416209 --> 1.395008).  Saving model ...
Validation loss decreased (1.395008 --> 1.379950).  Saving model ...
Validation loss decreased (1.379950 --> 1.369163).  Saving model ...
Validation loss decreased (1.369163 --> 1.361403).  Saving model ...
Validation loss decreased (1.361403 --> 1.354489).  Saving model ...
Validation loss decreased (1.354489 --> 1.348882).  Saving model ...
Validation loss decreased (1.348882 --> 1.344463).  Saving model ...
Validation loss decreased (1.344463 --> 1.338934).  Saving model ...
Validation loss decreased (1.338934 --> 1.335001).  Saving model ...
Validation loss decreased (1.335001 --> 1.330204).  Saving model ...
Validation loss decreased (1.330204 --> 1.325087).  Saving model ...
Validation loss decreased (1.325087 --> 1.320058).  Saving model ...
Validation loss decreased (1.320058 --> 1.315369).  Saving model ...
Validation loss decreased (1.315369 --> 1.309158).  Saving model ...
Validation loss decreased (1.309158 --> 1.303604).  Saving model ...
Validation loss decreased (1.303604 --> 1.299470).  Saving model ...
Validation loss decreased (1.299470 --> 1.293875).  Saving model ...
Validation loss decreased (1.293875 --> 1.287390).  Saving model ...
Validation loss decreased (1.287390 --> 1.280383).  Saving model ...
Validation loss decreased (1.280383 --> 1.273701).  Saving model ...
Validation loss decreased (1.273701 --> 1.266871).  Saving model ...
Validation loss decreased (1.266871 --> 1.261922).  Saving model ...
Validation loss decreased (1.261922 --> 1.256151).  Saving model ...
Validation loss decreased (1.256151 --> 1.248343).  Saving model ...
Validation loss decreased (1.248343 --> 1.242062).  Saving model ...
Validation loss decreased (1.242062 --> 1.235375).  Saving model ...
Validation loss decreased (1.235375 --> 1.230273).  Saving model ...
Validation loss decreased (1.230273 --> 1.223055).  Saving model ...
Validation loss decreased (1.223055 --> 1.215297).  Saving model ...
Validation loss decreased (1.215297 --> 1.209255).  Saving model ...
Validation loss decreased (1.209255 --> 1.202986).  Saving model ...
Validation loss decreased (1.202986 --> 1.197789).  Saving model ...
Validation loss decreased (1.197789 --> 1.193181).  Saving model ...
Validation loss decreased (1.193181 --> 1.188398).  Saving model ...
Validation loss decreased (1.188398 --> 1.181851).  Saving model ...
Validation loss decreased (1.181851 --> 1.176815).  Saving model ...
Validation loss decreased (1.176815 --> 1.173956).  Saving model ...
Validation loss decreased (1.173956 --> 1.170456).  Saving model ...
Validation loss decreased (1.170456 --> 1.166585).  Saving model ...
Validation loss decreased (1.166585 --> 1.160016).  Saving model ...
Validation loss decreased (1.160016 --> 1.154131).  Saving model ...
Validation loss decreased (1.154131 --> 1.148988).  Saving model ...
Validation loss decreased (1.148988 --> 1.143470).  Saving model ...
Validation loss decreased (1.143470 --> 1.140686).  Saving model ...
Validation loss decreased (1.140686 --> 1.134837).  Saving model ...
Validation loss decreased (1.134837 --> 1.129910).  Saving model ...
Validation loss decreased (1.129910 --> 1.126067).  Saving model ...
Validation loss decreased (1.126067 --> 1.122883).  Saving model ...
Validation loss decreased (1.122883 --> 1.118650).  Saving model ...
Validation loss decreased (1.118650 --> 1.114229).  Saving model ...
Validation loss decreased (1.114229 --> 1.111156).  Saving model ...
Validation loss decreased (1.111156 --> 1.107277).  Saving model ...
Validation loss decreased (1.107277 --> 1.104243).  Saving model ...
Validation loss decreased (1.104243 --> 1.099714).  Saving model ...
Validation loss decreased (1.099714 --> 1.097371).  Saving model ...
Validation loss decreased (1.097371 --> 1.096562).  Saving model ...
Validation loss decreased (1.096562 --> 1.094743).  Saving model ...
Validation loss decreased (1.094743 --> 1.087194).  Saving model ...
Validation loss decreased (1.087194 --> 1.085230).  Saving model ...
Validation loss decreased (1.085230 --> 1.082017).  Saving model ...
Validation loss decreased (1.082017 --> 1.078599).  Saving model ...
Validation loss decreased (1.078599 --> 1.077234).  Saving model ...
EarlyStopping counter: 1 out of 10.0
Validation loss decreased (1.077234 --> 1.071472).  Saving model ...
Validation loss decreased (1.071472 --> 1.069995).  Saving model ...
EarlyStopping counter: 1 out of 10.0
Validation loss decreased (1.069995 --> 1.068041).  Saving model ...
Validation loss decreased (1.068041 --> 1.062284).  Saving model ...
Validation loss decreased (1.062284 --> 1.056196).  Saving model ...
EarlyStopping counter: 1 out of 10.0
Validation loss decreased (1.056196 --> 1.054563).  Saving model ...
Validation loss decreased (1.054563 --> 1.052733).  Saving model ...
Validation loss decreased (1.052733 --> 1.049445).  Saving model ...
Validation loss decreased (1.049445 --> 1.045815).  Saving model ...
Validation loss decreased (1.045815 --> 1.040924).  Saving model ...
Validation loss decreased (1.040924 --> 1.037740).  Saving model ...
Validation loss decreased (1.037740 --> 1.035485).  Saving model ...
Validation loss decreased (1.035485 --> 1.035394).  Saving model ...
Validation loss decreased (1.035394 --> 1.035056).  Saving model ...
Validation loss decreased (1.035056 --> 1.032454).  Saving model ...
EarlyStopping counter: 1 out of 10.0
Validation loss decreased (1.032454 --> 1.029966).  Saving model ...
EarlyStopping counter: 1 out of 10.0
Validation loss decreased (1.029966 --> 1.029553).  Saving model ...
Validation loss decreased (1.029553 --> 1.023787).  Saving model ...
Validation loss decreased (1.023787 --> 1.021480).  Saving model ...
EarlyStopping counter: 1 out of 10.0
EarlyStopping counter: 2 out of 10.0
EarlyStopping counter: 3 out of 10.0
EarlyStopping counter: 4 out of 10.0
Validation loss decreased (1.021480 --> 1.019056).  Saving model ...
EarlyStopping counter: 1 out of 10.0
EarlyStopping counter: 2 out of 10.0
Validation loss decreased (1.019056 --> 1.015029).  Saving model ...
Validation loss decreased (1.015029 --> 1.009303).  Saving model ...
EarlyStopping counter: 1 out of 10.0
EarlyStopping counter: 2 out of 10.0
EarlyStopping counter: 3 out of 10.0
EarlyStopping counter: 4 out of 10.0
EarlyStopping counter: 5 out of 10.0
EarlyStopping counter: 6 out of 10.0
EarlyStopping counter: 7 out of 10.0
EarlyStopping counter: 8 out of 10.0
EarlyStopping counter: 9 out of 10.0
EarlyStopping counter: 10 out of 10.0
/localscratch/yinan.29019325.0/env/lib/python3.7/site-packages/torch/nn/functional.py:1794: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.
  warnings.warn("nn.functional.tanh is deprecated. Use torch.tanh instead.")
wandb: Waiting for W&B process to finish, PID 4991... (success).
wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: \ 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: | 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: / 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: \ 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: | 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: / 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: \ 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: | 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb:                                                                                
wandb: Run history:
wandb:     e_F1 ▁▂▃▄▄▄▄▄▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇▇▇█▇▇████████████
wandb:   e_loss █▇▆▆▅▅▅▅▅▄▄▄▄▃▃▃▃▃▃▂▂▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁
wandb:     t_F1 ▁▁▂▂▃▃▄▄▄▅▅▅▅▅▅▅▆▅▆▆▆▆▆▇▇▇▇▇▇▇▇▇▇█▇███▇█
wandb:   t_loss █▇▇▇▆▆▆▆▆▅▅▅▅▅▅▄▄▄▄▄▄▃▃▃▃▂▂▂▃▂▂▂▂▁▂▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:     e_F1 57.47743
wandb:   e_loss 1.00988
wandb:     t_F1 70.26552
wandb:   t_loss 0.82193
wandb: 
wandb: Synced 4 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Synced fancy-water-2: https://wandb.ai/yinanazhou/xl_512_bs_8_lr_1e06_es_10_lc_False_nr_True_sr_True_stem_False_lemma_False_repeat_3_fold_1/runs/136ug5qa
wandb: Find logs at: ./wandb/run-20220319_013450-136ug5qa/logs/debug.log
wandb: 

wandb: wandb version 0.12.11 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
2022-03-19 02:44:20.991904: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1
wandb: Tracking run with wandb version 0.12.5
wandb: Syncing run valiant-fire-2
wandb: ⭐️ View project at https://wandb.ai/yinanazhou/xl_512_bs_8_lr_1e06_es_10_lc_False_nr_True_sr_True_stem_False_lemma_False_repeat_3_fold_2
wandb: 🚀 View run at https://wandb.ai/yinanazhou/xl_512_bs_8_lr_1e06_es_10_lc_False_nr_True_sr_True_stem_False_lemma_False_repeat_3_fold_2/runs/jyh8ovgy
wandb: Run data is saved locally in /project/6002780/yinan/Thesis_MER_Lyrics/lyric-emotion/wandb/run-20220319_024418-jyh8ovgy
wandb: Run `wandb offline` to turn off syncing.

Validation loss decreased (inf --> 1.399066).  Saving model ...
Validation loss decreased (1.399066 --> 1.390980).  Saving model ...
Validation loss decreased (1.390980 --> 1.384751).  Saving model ...
Validation loss decreased (1.384751 --> 1.378982).  Saving model ...
Validation loss decreased (1.378982 --> 1.373758).  Saving model ...
Validation loss decreased (1.373758 --> 1.369115).  Saving model ...
Validation loss decreased (1.369115 --> 1.365178).  Saving model ...
Validation loss decreased (1.365178 --> 1.361188).  Saving model ...
Validation loss decreased (1.361188 --> 1.357697).  Saving model ...
Validation loss decreased (1.357697 --> 1.353958).  Saving model ...
Validation loss decreased (1.353958 --> 1.350641).  Saving model ...
Validation loss decreased (1.350641 --> 1.346808).  Saving model ...
Validation loss decreased (1.346808 --> 1.342248).  Saving model ...
Validation loss decreased (1.342248 --> 1.338320).  Saving model ...
Validation loss decreased (1.338320 --> 1.334053).  Saving model ...
Validation loss decreased (1.334053 --> 1.329879).  Saving model ...
Validation loss decreased (1.329879 --> 1.325966).  Saving model ...
Validation loss decreased (1.325966 --> 1.321037).  Saving model ...
Validation loss decreased (1.321037 --> 1.316394).  Saving model ...
Validation loss decreased (1.316394 --> 1.311355).  Saving model ...
Validation loss decreased (1.311355 --> 1.306123).  Saving model ...
Validation loss decreased (1.306123 --> 1.299910).  Saving model ...
Validation loss decreased (1.299910 --> 1.294832).  Saving model ...
Validation loss decreased (1.294832 --> 1.289294).  Saving model ...
Validation loss decreased (1.289294 --> 1.283007).  Saving model ...
Validation loss decreased (1.283007 --> 1.276897).  Saving model ...
Validation loss decreased (1.276897 --> 1.269666).  Saving model ...
Validation loss decreased (1.269666 --> 1.261409).  Saving model ...
Validation loss decreased (1.261409 --> 1.253717).  Saving model ...
Validation loss decreased (1.253717 --> 1.246382).  Saving model ...
Validation loss decreased (1.246382 --> 1.237809).  Saving model ...
Validation loss decreased (1.237809 --> 1.230200).  Saving model ...
Validation loss decreased (1.230200 --> 1.222694).  Saving model ...
Validation loss decreased (1.222694 --> 1.215512).  Saving model ...
Validation loss decreased (1.215512 --> 1.208904).  Saving model ...
Validation loss decreased (1.208904 --> 1.201821).  Saving model ...
Validation loss decreased (1.201821 --> 1.194673).  Saving model ...
Validation loss decreased (1.194673 --> 1.188553).  Saving model ...
Validation loss decreased (1.188553 --> 1.183815).  Saving model ...
Validation loss decreased (1.183815 --> 1.177441).  Saving model ...
Validation loss decreased (1.177441 --> 1.170175).  Saving model ...
Validation loss decreased (1.170175 --> 1.163281).  Saving model ...
Validation loss decreased (1.163281 --> 1.157353).  Saving model ...
Validation loss decreased (1.157353 --> 1.150089).  Saving model ...
Validation loss decreased (1.150089 --> 1.144689).  Saving model ...
Validation loss decreased (1.144689 --> 1.138969).  Saving model ...
Validation loss decreased (1.138969 --> 1.135268).  Saving model ...
Validation loss decreased (1.135268 --> 1.131336).  Saving model ...
Validation loss decreased (1.131336 --> 1.130100).  Saving model ...
Validation loss decreased (1.130100 --> 1.124715).  Saving model ...
Validation loss decreased (1.124715 --> 1.116588).  Saving model ...
Validation loss decreased (1.116588 --> 1.112865).  Saving model ...
Validation loss decreased (1.112865 --> 1.106839).  Saving model ...
Validation loss decreased (1.106839 --> 1.099472).  Saving model ...
Validation loss decreased (1.099472 --> 1.095528).  Saving model ...
Validation loss decreased (1.095528 --> 1.090537).  Saving model ...
Validation loss decreased (1.090537 --> 1.086405).  Saving model ...
Validation loss decreased (1.086405 --> 1.080404).  Saving model ...
Validation loss decreased (1.080404 --> 1.075883).  Saving model ...
Validation loss decreased (1.075883 --> 1.072712).  Saving model ...
Validation loss decreased (1.072712 --> 1.068360).  Saving model ...
Validation loss decreased (1.068360 --> 1.062236).  Saving model ...
Validation loss decreased (1.062236 --> 1.058317).  Saving model ...
Validation loss decreased (1.058317 --> 1.053790).  Saving model ...
Validation loss decreased (1.053790 --> 1.047808).  Saving model ...
Validation loss decreased (1.047808 --> 1.042869).  Saving model ...
Validation loss decreased (1.042869 --> 1.037303).  Saving model ...
Validation loss decreased (1.037303 --> 1.034715).  Saving model ...
Validation loss decreased (1.034715 --> 1.032414).  Saving model ...
Validation loss decreased (1.032414 --> 1.030032).  Saving model ...
Validation loss decreased (1.030032 --> 1.024563).  Saving model ...
Validation loss decreased (1.024563 --> 1.019440).  Saving model ...
Validation loss decreased (1.019440 --> 1.016248).  Saving model ...
Validation loss decreased (1.016248 --> 1.013880).  Saving model ...
Validation loss decreased (1.013880 --> 1.011781).  Saving model ...
Validation loss decreased (1.011781 --> 1.009531).  Saving model ...
Validation loss decreased (1.009531 --> 1.004456).  Saving model ...
Validation loss decreased (1.004456 --> 1.002452).  Saving model ...
Validation loss decreased (1.002452 --> 0.997317).  Saving model ...
Validation loss decreased (0.997317 --> 0.993447).  Saving model ...
Validation loss decreased (0.993447 --> 0.991073).  Saving model ...
Validation loss decreased (0.991073 --> 0.986355).  Saving model ...
Validation loss decreased (0.986355 --> 0.983316).  Saving model ...
Validation loss decreased (0.983316 --> 0.981577).  Saving model ...
Validation loss decreased (0.981577 --> 0.977821).  Saving model ...
Validation loss decreased (0.977821 --> 0.974948).  Saving model ...
Validation loss decreased (0.974948 --> 0.973169).  Saving model ...
Validation loss decreased (0.973169 --> 0.970533).  Saving model ...
Validation loss decreased (0.970533 --> 0.966943).  Saving model ...
Validation loss decreased (0.966943 --> 0.965877).  Saving model ...
Validation loss decreased (0.965877 --> 0.962244).  Saving model ...
Validation loss decreased (0.962244 --> 0.960590).  Saving model ...
Validation loss decreased (0.960590 --> 0.959282).  Saving model ...
Validation loss decreased (0.959282 --> 0.956929).  Saving model ...
Validation loss decreased (0.956929 --> 0.953792).  Saving model ...
Validation loss decreased (0.953792 --> 0.951770).  Saving model ...
Validation loss decreased (0.951770 --> 0.950213).  Saving model ...
Validation loss decreased (0.950213 --> 0.947451).  Saving model ...
Validation loss decreased (0.947451 --> 0.945435).  Saving model ...
Validation loss decreased (0.945435 --> 0.941262).  Saving model ...
Validation loss decreased (0.941262 --> 0.939705).  Saving model ...
Validation loss decreased (0.939705 --> 0.937881).  Saving model ...
Validation loss decreased (0.937881 --> 0.937097).  Saving model ...
Validation loss decreased (0.937097 --> 0.934646).  Saving model ...
Validation loss decreased (0.934646 --> 0.932806).  Saving model ...
Validation loss decreased (0.932806 --> 0.931799).  Saving model ...
Validation loss decreased (0.931799 --> 0.930634).  Saving model ...
Validation loss decreased (0.930634 --> 0.928881).  Saving model ...
EarlyStopping counter: 1 out of 10.0
Validation loss decreased (0.928881 --> 0.926899).  Saving model ...
EarlyStopping counter: 1 out of 10.0
Validation loss decreased (0.926899 --> 0.925685).  Saving model ...
Validation loss decreased (0.925685 --> 0.924385).  Saving model ...
Validation loss decreased (0.924385 --> 0.922575).  Saving model ...
Validation loss decreased (0.922575 --> 0.921365).  Saving model ...
Validation loss decreased (0.921365 --> 0.920915).  Saving model ...
Validation loss decreased (0.920915 --> 0.918896).  Saving model ...
Validation loss decreased (0.918896 --> 0.918104).  Saving model ...
Validation loss decreased (0.918104 --> 0.916904).  Saving model ...
Validation loss decreased (0.916904 --> 0.916147).  Saving model ...
EarlyStopping counter: 1 out of 10.0
Validation loss decreased (0.916147 --> 0.915012).  Saving model ...
Validation loss decreased (0.915012 --> 0.913584).  Saving model ...
Validation loss decreased (0.913584 --> 0.912055).  Saving model ...
Validation loss decreased (0.912055 --> 0.911623).  Saving model ...
Validation loss decreased (0.911623 --> 0.909995).  Saving model ...
Validation loss decreased (0.909995 --> 0.909680).  Saving model ...
EarlyStopping counter: 1 out of 10.0
EarlyStopping counter: 2 out of 10.0
Validation loss decreased (0.909680 --> 0.909672).  Saving model ...
Validation loss decreased (0.909672 --> 0.909182).  Saving model ...
Validation loss decreased (0.909182 --> 0.908389).  Saving model ...
Validation loss decreased (0.908389 --> 0.908384).  Saving model ...
Validation loss decreased (0.908384 --> 0.907671).  Saving model ...
Validation loss decreased (0.907671 --> 0.906969).  Saving model ...
Validation loss decreased (0.906969 --> 0.906543).  Saving model ...
EarlyStopping counter: 1 out of 10.0
EarlyStopping counter: 2 out of 10.0
EarlyStopping counter: 3 out of 10.0
EarlyStopping counter: 4 out of 10.0
EarlyStopping counter: 5 out of 10.0
Validation loss decreased (0.906543 --> 0.906204).  Saving model ...
Validation loss decreased (0.906204 --> 0.905675).  Saving model ...
EarlyStopping counter: 1 out of 10.0
EarlyStopping counter: 2 out of 10.0
EarlyStopping counter: 3 out of 10.0
EarlyStopping counter: 4 out of 10.0
EarlyStopping counter: 5 out of 10.0
EarlyStopping counter: 6 out of 10.0
EarlyStopping counter: 7 out of 10.0
EarlyStopping counter: 8 out of 10.0
EarlyStopping counter: 9 out of 10.0
EarlyStopping counter: 10 out of 10.0
/localscratch/yinan.29019325.0/env/lib/python3.7/site-packages/torch/nn/functional.py:1794: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.
  warnings.warn("nn.functional.tanh is deprecated. Use torch.tanh instead.")
wandb: Waiting for W&B process to finish, PID 8753... (success).
wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: \ 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: | 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: / 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: \ 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: | 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: / 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: \ 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: | 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: / 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb:                                                                                
wandb: Run history:
wandb:     e_F1 ▁▂▄▄▅▅▅▆▆▆▆▆▆▆▇▇▇▇▇▇▇▇██████████████████
wandb:   e_loss ███▇▇▇▇▆▆▅▅▅▄▄▄▄▃▃▃▃▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:     t_F1 ▁▁▂▂▃▃▂▄▃▄▅▅▅▆▅▆▆▆▆▆▆▆▇▇▇▇▇▇▇▇▇▇▇█▇█████
wandb:   t_loss ███▇▇▇▇▇▇▆▆▅▅▅▅▄▄▄▄▄▃▄▃▃▃▃▃▂▂▂▂▂▂▁▂▂▁▁▁▁
wandb: 
wandb: Run summary:
wandb:     e_F1 62.81281
wandb:   e_loss 0.90801
wandb:     t_F1 72.63592
wandb:   t_loss 0.7312
wandb: 
wandb: Synced 4 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Synced valiant-fire-2: https://wandb.ai/yinanazhou/xl_512_bs_8_lr_1e06_es_10_lc_False_nr_True_sr_True_stem_False_lemma_False_repeat_3_fold_2/runs/jyh8ovgy
wandb: Find logs at: ./wandb/run-20220319_024418-jyh8ovgy/logs/debug.log
wandb: 

wandb: wandb version 0.12.11 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
2022-03-19 04:24:24.506590: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1
wandb: Tracking run with wandb version 0.12.5
wandb: Syncing run cerulean-water-2
wandb: ⭐️ View project at https://wandb.ai/yinanazhou/xl_512_bs_8_lr_1e06_es_10_lc_False_nr_True_sr_True_stem_False_lemma_False_repeat_4_fold_1
wandb: 🚀 View run at https://wandb.ai/yinanazhou/xl_512_bs_8_lr_1e06_es_10_lc_False_nr_True_sr_True_stem_False_lemma_False_repeat_4_fold_1/runs/2egslk9r
wandb: Run data is saved locally in /project/6002780/yinan/Thesis_MER_Lyrics/lyric-emotion/wandb/run-20220319_042421-2egslk9r
wandb: Run `wandb offline` to turn off syncing.

Validation loss decreased (inf --> 1.401047).  Saving model ...
Validation loss decreased (1.401047 --> 1.395431).  Saving model ...
Validation loss decreased (1.395431 --> 1.390528).  Saving model ...
Validation loss decreased (1.390528 --> 1.386234).  Saving model ...
Validation loss decreased (1.386234 --> 1.382363).  Saving model ...
Validation loss decreased (1.382363 --> 1.378723).  Saving model ...
Validation loss decreased (1.378723 --> 1.375303).  Saving model ...
Validation loss decreased (1.375303 --> 1.371586).  Saving model ...
Validation loss decreased (1.371586 --> 1.367740).  Saving model ...
Validation loss decreased (1.367740 --> 1.364003).  Saving model ...
Validation loss decreased (1.364003 --> 1.360225).  Saving model ...
Validation loss decreased (1.360225 --> 1.356331).  Saving model ...
Validation loss decreased (1.356331 --> 1.352182).  Saving model ...
Validation loss decreased (1.352182 --> 1.347729).  Saving model ...
Validation loss decreased (1.347729 --> 1.342374).  Saving model ...
Validation loss decreased (1.342374 --> 1.337637).  Saving model ...
Validation loss decreased (1.337637 --> 1.332842).  Saving model ...
Validation loss decreased (1.332842 --> 1.327236).  Saving model ...
Validation loss decreased (1.327236 --> 1.321790).  Saving model ...
Validation loss decreased (1.321790 --> 1.315979).  Saving model ...
Validation loss decreased (1.315979 --> 1.309458).  Saving model ...
Validation loss decreased (1.309458 --> 1.302983).  Saving model ...
Validation loss decreased (1.302983 --> 1.295720).  Saving model ...
Validation loss decreased (1.295720 --> 1.287839).  Saving model ...
Validation loss decreased (1.287839 --> 1.280571).  Saving model ...
Validation loss decreased (1.280571 --> 1.272836).  Saving model ...
Validation loss decreased (1.272836 --> 1.264817).  Saving model ...
Validation loss decreased (1.264817 --> 1.256776).  Saving model ...
Validation loss decreased (1.256776 --> 1.248813).  Saving model ...
Validation loss decreased (1.248813 --> 1.241010).  Saving model ...
Validation loss decreased (1.241010 --> 1.232549).  Saving model ...
Validation loss decreased (1.232549 --> 1.225236).  Saving model ...
Validation loss decreased (1.225236 --> 1.216797).  Saving model ...
Validation loss decreased (1.216797 --> 1.209763).  Saving model ...
Validation loss decreased (1.209763 --> 1.203481).  Saving model ...
Validation loss decreased (1.203481 --> 1.195513).  Saving model ...
Validation loss decreased (1.195513 --> 1.189385).  Saving model ...
Validation loss decreased (1.189385 --> 1.183634).  Saving model ...
Validation loss decreased (1.183634 --> 1.177611).  Saving model ...
Validation loss decreased (1.177611 --> 1.171255).  Saving model ...
Validation loss decreased (1.171255 --> 1.165583).  Saving model ...
Validation loss decreased (1.165583 --> 1.159319).  Saving model ...
Validation loss decreased (1.159319 --> 1.154463).  Saving model ...
Validation loss decreased (1.154463 --> 1.149143).  Saving model ...
Validation loss decreased (1.149143 --> 1.145096).  Saving model ...
Validation loss decreased (1.145096 --> 1.140034).  Saving model ...
Validation loss decreased (1.140034 --> 1.134675).  Saving model ...
Validation loss decreased (1.134675 --> 1.129928).  Saving model ...
Validation loss decreased (1.129928 --> 1.125806).  Saving model ...
Validation loss decreased (1.125806 --> 1.123185).  Saving model ...
Validation loss decreased (1.123185 --> 1.118381).  Saving model ...
Validation loss decreased (1.118381 --> 1.111422).  Saving model ...
Validation loss decreased (1.111422 --> 1.107013).  Saving model ...
Validation loss decreased (1.107013 --> 1.101602).  Saving model ...
Validation loss decreased (1.101602 --> 1.097904).  Saving model ...
Validation loss decreased (1.097904 --> 1.093311).  Saving model ...
Validation loss decreased (1.093311 --> 1.089445).  Saving model ...
Validation loss decreased (1.089445 --> 1.084853).  Saving model ...
Validation loss decreased (1.084853 --> 1.081184).  Saving model ...
Validation loss decreased (1.081184 --> 1.078739).  Saving model ...
Validation loss decreased (1.078739 --> 1.074794).  Saving model ...
Validation loss decreased (1.074794 --> 1.072373).  Saving model ...
Validation loss decreased (1.072373 --> 1.067163).  Saving model ...
Validation loss decreased (1.067163 --> 1.064460).  Saving model ...
Validation loss decreased (1.064460 --> 1.060630).  Saving model ...
Validation loss decreased (1.060630 --> 1.056396).  Saving model ...
Validation loss decreased (1.056396 --> 1.052324).  Saving model ...
Validation loss decreased (1.052324 --> 1.049703).  Saving model ...
Validation loss decreased (1.049703 --> 1.046741).  Saving model ...
Validation loss decreased (1.046741 --> 1.042742).  Saving model ...
Validation loss decreased (1.042742 --> 1.039404).  Saving model ...
Validation loss decreased (1.039404 --> 1.037641).  Saving model ...
Validation loss decreased (1.037641 --> 1.034517).  Saving model ...
Validation loss decreased (1.034517 --> 1.032340).  Saving model ...
Validation loss decreased (1.032340 --> 1.028949).  Saving model ...
Validation loss decreased (1.028949 --> 1.026263).  Saving model ...
Validation loss decreased (1.026263 --> 1.022196).  Saving model ...
Validation loss decreased (1.022196 --> 1.019918).  Saving model ...
Validation loss decreased (1.019918 --> 1.019505).  Saving model ...
Validation loss decreased (1.019505 --> 1.017138).  Saving model ...
Validation loss decreased (1.017138 --> 1.015204).  Saving model ...
Validation loss decreased (1.015204 --> 1.011524).  Saving model ...
Validation loss decreased (1.011524 --> 1.009385).  Saving model ...
Validation loss decreased (1.009385 --> 1.005079).  Saving model ...
Validation loss decreased (1.005079 --> 1.003157).  Saving model ...
Validation loss decreased (1.003157 --> 1.000005).  Saving model ...
Validation loss decreased (1.000005 --> 0.998190).  Saving model ...
Validation loss decreased (0.998190 --> 0.995599).  Saving model ...
Validation loss decreased (0.995599 --> 0.992558).  Saving model ...
Validation loss decreased (0.992558 --> 0.992129).  Saving model ...
Validation loss decreased (0.992129 --> 0.991560).  Saving model ...
Validation loss decreased (0.991560 --> 0.990049).  Saving model ...
Validation loss decreased (0.990049 --> 0.988895).  Saving model ...
Validation loss decreased (0.988895 --> 0.984540).  Saving model ...
EarlyStopping counter: 1 out of 10.0
Validation loss decreased (0.984540 --> 0.982021).  Saving model ...
Validation loss decreased (0.982021 --> 0.980294).  Saving model ...
Validation loss decreased (0.980294 --> 0.978556).  Saving model ...
Validation loss decreased (0.978556 --> 0.976539).  Saving model ...
Validation loss decreased (0.976539 --> 0.975585).  Saving model ...
EarlyStopping counter: 1 out of 10.0
Validation loss decreased (0.975585 --> 0.974047).  Saving model ...
Validation loss decreased (0.974047 --> 0.972827).  Saving model ...
Validation loss decreased (0.972827 --> 0.972057).  Saving model ...
Validation loss decreased (0.972057 --> 0.971381).  Saving model ...
Validation loss decreased (0.971381 --> 0.970035).  Saving model ...
Validation loss decreased (0.970035 --> 0.968614).  Saving model ...
EarlyStopping counter: 1 out of 10.0
EarlyStopping counter: 2 out of 10.0
EarlyStopping counter: 3 out of 10.0
Validation loss decreased (0.968614 --> 0.964338).  Saving model ...
Validation loss decreased (0.964338 --> 0.962307).  Saving model ...
Validation loss decreased (0.962307 --> 0.961907).  Saving model ...
EarlyStopping counter: 1 out of 10.0
EarlyStopping counter: 2 out of 10.0
Validation loss decreased (0.961907 --> 0.961840).  Saving model ...
Validation loss decreased (0.961840 --> 0.961074).  Saving model ...
Validation loss decreased (0.961074 --> 0.959145).  Saving model ...
Validation loss decreased (0.959145 --> 0.958043).  Saving model ...
Validation loss decreased (0.958043 --> 0.957462).  Saving model ...
Validation loss decreased (0.957462 --> 0.956690).  Saving model ...
EarlyStopping counter: 1 out of 10.0
Validation loss decreased (0.956690 --> 0.956396).  Saving model ...
Validation loss decreased (0.956396 --> 0.954045).  Saving model ...
EarlyStopping counter: 1 out of 10.0
EarlyStopping counter: 2 out of 10.0
EarlyStopping counter: 3 out of 10.0
EarlyStopping counter: 4 out of 10.0
EarlyStopping counter: 5 out of 10.0
EarlyStopping counter: 6 out of 10.0
EarlyStopping counter: 7 out of 10.0
Validation loss decreased (0.954045 --> 0.952397).  Saving model ...
Validation loss decreased (0.952397 --> 0.952365).  Saving model ...
EarlyStopping counter: 1 out of 10.0
EarlyStopping counter: 2 out of 10.0
EarlyStopping counter: 3 out of 10.0
Validation loss decreased (0.952365 --> 0.951590).  Saving model ...
EarlyStopping counter: 1 out of 10.0
EarlyStopping counter: 2 out of 10.0
EarlyStopping counter: 3 out of 10.0
EarlyStopping counter: 4 out of 10.0
EarlyStopping counter: 5 out of 10.0
EarlyStopping counter: 6 out of 10.0
EarlyStopping counter: 7 out of 10.0
Validation loss decreased (0.951590 --> 0.950986).  Saving model ...
EarlyStopping counter: 1 out of 10.0
EarlyStopping counter: 2 out of 10.0
EarlyStopping counter: 3 out of 10.0
Validation loss decreased (0.950986 --> 0.950146).  Saving model ...
EarlyStopping counter: 1 out of 10.0
Validation loss decreased (0.950146 --> 0.950104).  Saving model ...
EarlyStopping counter: 1 out of 10.0
EarlyStopping counter: 2 out of 10.0
EarlyStopping counter: 3 out of 10.0
EarlyStopping counter: 4 out of 10.0
EarlyStopping counter: 5 out of 10.0
EarlyStopping counter: 6 out of 10.0
EarlyStopping counter: 7 out of 10.0
EarlyStopping counter: 8 out of 10.0
EarlyStopping counter: 9 out of 10.0
EarlyStopping counter: 10 out of 10.0
/localscratch/yinan.29019325.0/env/lib/python3.7/site-packages/torch/nn/functional.py:1794: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.
  warnings.warn("nn.functional.tanh is deprecated. Use torch.tanh instead.")
wandb: Waiting for W&B process to finish, PID 14211... (success).
wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: \ 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: | 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: / 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: \ 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: | 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: / 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: \ 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: | 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb:                                                                                
wandb: Run history:
wandb:     e_F1 ▁▃▃▃▄▅▅▅▅▆▆▆▆▆▆▆▇▇▇▇▇▇▇▇▇███████████████
wandb:   e_loss ███▇▇▇▆▆▅▅▄▄▄▃▃▃▃▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:     t_F1 ▁▁▂▃▃▃▄▄▄▅▅▅▅▅▆▆▆▆▆▇▇▆▇▇▇▇▇▇▇▇▇▇▇████▇██
wandb:   t_loss ███▇▇▇▇▆▆▆▅▅▅▅▄▄▄▄▄▃▄▃▃▃▃▂▃▃▂▂▂▂▂▂▂▂▁▁▁▁
wandb: 
wandb: Run summary:
wandb:     e_F1 60.21009
wandb:   e_loss 0.95953
wandb:     t_F1 72.48903
wandb:   t_loss 0.70203
wandb: 
wandb: Synced 4 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Synced cerulean-water-2: https://wandb.ai/yinanazhou/xl_512_bs_8_lr_1e06_es_10_lc_False_nr_True_sr_True_stem_False_lemma_False_repeat_4_fold_1/runs/2egslk9r
wandb: Find logs at: ./wandb/run-20220319_042421-2egslk9r/logs/debug.log
wandb: 

wandb: wandb version 0.12.11 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
2022-03-19 06:09:20.692238: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1
wandb: Tracking run with wandb version 0.12.5
wandb: Syncing run copper-paper-2
wandb: ⭐️ View project at https://wandb.ai/yinanazhou/xl_512_bs_8_lr_1e06_es_10_lc_False_nr_True_sr_True_stem_False_lemma_False_repeat_4_fold_2
wandb: 🚀 View run at https://wandb.ai/yinanazhou/xl_512_bs_8_lr_1e06_es_10_lc_False_nr_True_sr_True_stem_False_lemma_False_repeat_4_fold_2/runs/16t3hxbu
wandb: Run data is saved locally in /project/6002780/yinan/Thesis_MER_Lyrics/lyric-emotion/wandb/run-20220319_060917-16t3hxbu
wandb: Run `wandb offline` to turn off syncing.

Validation loss decreased (inf --> 1.447366).  Saving model ...
Validation loss decreased (1.447366 --> 1.427468).  Saving model ...
Validation loss decreased (1.427468 --> 1.412229).  Saving model ...
Validation loss decreased (1.412229 --> 1.401251).  Saving model ...
Validation loss decreased (1.401251 --> 1.393035).  Saving model ...
Validation loss decreased (1.393035 --> 1.386895).  Saving model ...
Validation loss decreased (1.386895 --> 1.381612).  Saving model ...
Validation loss decreased (1.381612 --> 1.376418).  Saving model ...
Validation loss decreased (1.376418 --> 1.371261).  Saving model ...
Validation loss decreased (1.371261 --> 1.366243).  Saving model ...
Validation loss decreased (1.366243 --> 1.361477).  Saving model ...
Validation loss decreased (1.361477 --> 1.356901).  Saving model ...
Validation loss decreased (1.356901 --> 1.352384).  Saving model ...
Validation loss decreased (1.352384 --> 1.348078).  Saving model ...
Validation loss decreased (1.348078 --> 1.343240).  Saving model ...
Validation loss decreased (1.343240 --> 1.338049).  Saving model ...
Validation loss decreased (1.338049 --> 1.332877).  Saving model ...
Validation loss decreased (1.332877 --> 1.327356).  Saving model ...
Validation loss decreased (1.327356 --> 1.320791).  Saving model ...
Validation loss decreased (1.320791 --> 1.313253).  Saving model ...
Validation loss decreased (1.313253 --> 1.306604).  Saving model ...
Validation loss decreased (1.306604 --> 1.300534).  Saving model ...
Validation loss decreased (1.300534 --> 1.293878).  Saving model ...
Validation loss decreased (1.293878 --> 1.285831).  Saving model ...
Validation loss decreased (1.285831 --> 1.279103).  Saving model ...
Validation loss decreased (1.279103 --> 1.270483).  Saving model ...
Validation loss decreased (1.270483 --> 1.262607).  Saving model ...
Validation loss decreased (1.262607 --> 1.255421).  Saving model ...
Validation loss decreased (1.255421 --> 1.247134).  Saving model ...
Validation loss decreased (1.247134 --> 1.239261).  Saving model ...
Validation loss decreased (1.239261 --> 1.232248).  Saving model ...
Validation loss decreased (1.232248 --> 1.224016).  Saving model ...
Validation loss decreased (1.224016 --> 1.217292).  Saving model ...
Validation loss decreased (1.217292 --> 1.208453).  Saving model ...
Validation loss decreased (1.208453 --> 1.203629).  Saving model ...
Validation loss decreased (1.203629 --> 1.196207).  Saving model ...
Validation loss decreased (1.196207 --> 1.189045).  Saving model ...
Validation loss decreased (1.189045 --> 1.183506).  Saving model ...
Validation loss decreased (1.183506 --> 1.178308).  Saving model ...
Validation loss decreased (1.178308 --> 1.171878).  Saving model ...
Validation loss decreased (1.171878 --> 1.163599).  Saving model ...
Validation loss decreased (1.163599 --> 1.158292).  Saving model ...
Validation loss decreased (1.158292 --> 1.152409).  Saving model ...
Validation loss decreased (1.152409 --> 1.147450).  Saving model ...
Validation loss decreased (1.147450 --> 1.144792).  Saving model ...
Validation loss decreased (1.144792 --> 1.139421).  Saving model ...
Validation loss decreased (1.139421 --> 1.132086).  Saving model ...
Validation loss decreased (1.132086 --> 1.126606).  Saving model ...
Validation loss decreased (1.126606 --> 1.121687).  Saving model ...
Validation loss decreased (1.121687 --> 1.115123).  Saving model ...
Validation loss decreased (1.115123 --> 1.108195).  Saving model ...
Validation loss decreased (1.108195 --> 1.105814).  Saving model ...
Validation loss decreased (1.105814 --> 1.098884).  Saving model ...
Validation loss decreased (1.098884 --> 1.094478).  Saving model ...
Validation loss decreased (1.094478 --> 1.090501).  Saving model ...
Validation loss decreased (1.090501 --> 1.085330).  Saving model ...
Validation loss decreased (1.085330 --> 1.081500).  Saving model ...
Validation loss decreased (1.081500 --> 1.076407).  Saving model ...
Validation loss decreased (1.076407 --> 1.071822).  Saving model ...
Validation loss decreased (1.071822 --> 1.069472).  Saving model ...
Validation loss decreased (1.069472 --> 1.066717).  Saving model ...
Validation loss decreased (1.066717 --> 1.063520).  Saving model ...
Validation loss decreased (1.063520 --> 1.059374).  Saving model ...
Validation loss decreased (1.059374 --> 1.051455).  Saving model ...
Validation loss decreased (1.051455 --> 1.047790).  Saving model ...
Validation loss decreased (1.047790 --> 1.043986).  Saving model ...
Validation loss decreased (1.043986 --> 1.040314).  Saving model ...
Validation loss decreased (1.040314 --> 1.038291).  Saving model ...
Validation loss decreased (1.038291 --> 1.035133).  Saving model ...
Validation loss decreased (1.035133 --> 1.029635).  Saving model ...
Validation loss decreased (1.029635 --> 1.024998).  Saving model ...
Validation loss decreased (1.024998 --> 1.023641).  Saving model ...
Validation loss decreased (1.023641 --> 1.021384).  Saving model ...
Validation loss decreased (1.021384 --> 1.018174).  Saving model ...
Validation loss decreased (1.018174 --> 1.016104).  Saving model ...
Validation loss decreased (1.016104 --> 1.013154).  Saving model ...
Validation loss decreased (1.013154 --> 1.012744).  Saving model ...
Validation loss decreased (1.012744 --> 1.012625).  Saving model ...
Validation loss decreased (1.012625 --> 1.006117).  Saving model ...
Validation loss decreased (1.006117 --> 1.004082).  Saving model ...
Validation loss decreased (1.004082 --> 1.003486).  Saving model ...
EarlyStopping counter: 1 out of 10.0
Validation loss decreased (1.003486 --> 0.997907).  Saving model ...
Validation loss decreased (0.997907 --> 0.995654).  Saving model ...
Validation loss decreased (0.995654 --> 0.992423).  Saving model ...
Validation loss decreased (0.992423 --> 0.990802).  Saving model ...
Validation loss decreased (0.990802 --> 0.990516).  Saving model ...
Validation loss decreased (0.990516 --> 0.987182).  Saving model ...
Validation loss decreased (0.987182 --> 0.985050).  Saving model ...
EarlyStopping counter: 1 out of 10.0
EarlyStopping counter: 2 out of 10.0
Validation loss decreased (0.985050 --> 0.983484).  Saving model ...
Validation loss decreased (0.983484 --> 0.982658).  Saving model ...
Validation loss decreased (0.982658 --> 0.979117).  Saving model ...
Validation loss decreased (0.979117 --> 0.977808).  Saving model ...
EarlyStopping counter: 1 out of 10.0
EarlyStopping counter: 2 out of 10.0
Validation loss decreased (0.977808 --> 0.975165).  Saving model ...
Validation loss decreased (0.975165 --> 0.972947).  Saving model ...
Validation loss decreased (0.972947 --> 0.972403).  Saving model ...
Validation loss decreased (0.972403 --> 0.972174).  Saving model ...
EarlyStopping counter: 1 out of 10.0
EarlyStopping counter: 2 out of 10.0
EarlyStopping counter: 3 out of 10.0
Validation loss decreased (0.972174 --> 0.967321).  Saving model ...
Validation loss decreased (0.967321 --> 0.966918).  Saving model ...
Validation loss decreased (0.966918 --> 0.966035).  Saving model ...
Validation loss decreased (0.966035 --> 0.964207).  Saving model ...
EarlyStopping counter: 1 out of 10.0
EarlyStopping counter: 2 out of 10.0
Validation loss decreased (0.964207 --> 0.962968).  Saving model ...
Validation loss decreased (0.962968 --> 0.960866).  Saving model ...
EarlyStopping counter: 1 out of 10.0
Validation loss decreased (0.960866 --> 0.960021).  Saving model ...
Validation loss decreased (0.960021 --> 0.959827).  Saving model ...
EarlyStopping counter: 1 out of 10.0
EarlyStopping counter: 2 out of 10.0
EarlyStopping counter: 3 out of 10.0
EarlyStopping counter: 4 out of 10.0
EarlyStopping counter: 5 out of 10.0
Validation loss decreased (0.959827 --> 0.959556).  Saving model ...
EarlyStopping counter: 1 out of 10.0
EarlyStopping counter: 2 out of 10.0
EarlyStopping counter: 3 out of 10.0
EarlyStopping counter: 4 out of 10.0
Validation loss decreased (0.959556 --> 0.959195).  Saving model ...
Validation loss decreased (0.959195 --> 0.958137).  Saving model ...
EarlyStopping counter: 1 out of 10.0
EarlyStopping counter: 2 out of 10.0
EarlyStopping counter: 3 out of 10.0
EarlyStopping counter: 4 out of 10.0
EarlyStopping counter: 5 out of 10.0
EarlyStopping counter: 6 out of 10.0
EarlyStopping counter: 7 out of 10.0
EarlyStopping counter: 8 out of 10.0
EarlyStopping counter: 9 out of 10.0
EarlyStopping counter: 10 out of 10.0
/localscratch/yinan.29019325.0/env/lib/python3.7/site-packages/torch/nn/functional.py:1794: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.
  warnings.warn("nn.functional.tanh is deprecated. Use torch.tanh instead.")
wandb: Waiting for W&B process to finish, PID 19899... (success).
wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: \ 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: | 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: / 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: \ 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: | 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: / 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: \ 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: | 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: / 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb:                                                                                
wandb: Run history:
wandb:     e_F1 ▁▂▄▄▄▅▅▅▆▆▇▇▇▇▇▇▇▇▇▇████████████████████
wandb:   e_loss ██▇▇▇▇▆▆▅▅▅▄▄▄▃▃▃▃▃▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:     t_F1 ▁▁▂▂▂▃▃▄▄▅▅▄▅▅▆▅▆▆▆▆▆▇▆▇▇▇▇▇▇▇▇█▇█▇█▇██▇
wandb:   t_loss ██▇▇▇▇▇▆▆▆▆▆▅▅▅▅▄▄▄▄▄▃▃▃▃▃▃▂▂▂▂▂▂▂▂▂▂▁▁▁
wandb: 
wandb: Run summary:
wandb:     e_F1 59.90529
wandb:   e_loss 0.96149
wandb:     t_F1 73.1915
wandb:   t_loss 0.73457
wandb: 
wandb: Synced 4 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Synced copper-paper-2: https://wandb.ai/yinanazhou/xl_512_bs_8_lr_1e06_es_10_lc_False_nr_True_sr_True_stem_False_lemma_False_repeat_4_fold_2/runs/16t3hxbu
wandb: Find logs at: ./wandb/run-20220319_060917-16t3hxbu/logs/debug.log
wandb: 

wandb: wandb version 0.12.11 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
2022-03-19 07:38:25.669810: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1
wandb: Tracking run with wandb version 0.12.5
wandb: Syncing run polished-cloud-2
wandb: ⭐️ View project at https://wandb.ai/yinanazhou/xl_512_bs_8_lr_1e06_es_10_lc_False_nr_True_sr_True_stem_False_lemma_False_repeat_5_fold_1
wandb: 🚀 View run at https://wandb.ai/yinanazhou/xl_512_bs_8_lr_1e06_es_10_lc_False_nr_True_sr_True_stem_False_lemma_False_repeat_5_fold_1/runs/hiqr09yc
wandb: Run data is saved locally in /project/6002780/yinan/Thesis_MER_Lyrics/lyric-emotion/wandb/run-20220319_073822-hiqr09yc
wandb: Run `wandb offline` to turn off syncing.

Validation loss decreased (inf --> 1.403673).  Saving model ...
Validation loss decreased (1.403673 --> 1.388417).  Saving model ...
Validation loss decreased (1.388417 --> 1.377211).  Saving model ...
Validation loss decreased (1.377211 --> 1.368626).  Saving model ...
Validation loss decreased (1.368626 --> 1.361398).  Saving model ...
Validation loss decreased (1.361398 --> 1.355102).  Saving model ...
Validation loss decreased (1.355102 --> 1.349615).  Saving model ...
Validation loss decreased (1.349615 --> 1.344581).  Saving model ...
Validation loss decreased (1.344581 --> 1.339510).  Saving model ...
Validation loss decreased (1.339510 --> 1.334687).  Saving model ...
Validation loss decreased (1.334687 --> 1.329636).  Saving model ...
Validation loss decreased (1.329636 --> 1.324377).  Saving model ...
Validation loss decreased (1.324377 --> 1.319157).  Saving model ...
Validation loss decreased (1.319157 --> 1.313327).  Saving model ...
Validation loss decreased (1.313327 --> 1.307830).  Saving model ...
Validation loss decreased (1.307830 --> 1.302514).  Saving model ...
Validation loss decreased (1.302514 --> 1.296488).  Saving model ...
Validation loss decreased (1.296488 --> 1.291400).  Saving model ...
Validation loss decreased (1.291400 --> 1.285445).  Saving model ...
Validation loss decreased (1.285445 --> 1.279877).  Saving model ...
Validation loss decreased (1.279877 --> 1.273021).  Saving model ...
Validation loss decreased (1.273021 --> 1.266856).  Saving model ...
Validation loss decreased (1.266856 --> 1.260335).  Saving model ...
Validation loss decreased (1.260335 --> 1.254412).  Saving model ...
Validation loss decreased (1.254412 --> 1.248425).  Saving model ...
Validation loss decreased (1.248425 --> 1.242133).  Saving model ...
Validation loss decreased (1.242133 --> 1.236335).  Saving model ...
Validation loss decreased (1.236335 --> 1.230608).  Saving model ...
Validation loss decreased (1.230608 --> 1.223179).  Saving model ...
Validation loss decreased (1.223179 --> 1.217563).  Saving model ...
Validation loss decreased (1.217563 --> 1.211372).  Saving model ...
Validation loss decreased (1.211372 --> 1.204937).  Saving model ...
Validation loss decreased (1.204937 --> 1.198597).  Saving model ...
Validation loss decreased (1.198597 --> 1.191730).  Saving model ...
Validation loss decreased (1.191730 --> 1.185425).  Saving model ...
Validation loss decreased (1.185425 --> 1.180878).  Saving model ...
Validation loss decreased (1.180878 --> 1.173286).  Saving model ...
Validation loss decreased (1.173286 --> 1.166433).  Saving model ...
Validation loss decreased (1.166433 --> 1.160756).  Saving model ...
Validation loss decreased (1.160756 --> 1.155538).  Saving model ...
Validation loss decreased (1.155538 --> 1.149699).  Saving model ...
Validation loss decreased (1.149699 --> 1.144082).  Saving model ...
Validation loss decreased (1.144082 --> 1.137141).  Saving model ...
Validation loss decreased (1.137141 --> 1.131628).  Saving model ...
Validation loss decreased (1.131628 --> 1.126311).  Saving model ...
Validation loss decreased (1.126311 --> 1.121399).  Saving model ...
Validation loss decreased (1.121399 --> 1.116529).  Saving model ...
Validation loss decreased (1.116529 --> 1.110342).  Saving model ...
Validation loss decreased (1.110342 --> 1.105293).  Saving model ...
Validation loss decreased (1.105293 --> 1.099171).  Saving model ...
Validation loss decreased (1.099171 --> 1.094907).  Saving model ...
Validation loss decreased (1.094907 --> 1.089255).  Saving model ...
Validation loss decreased (1.089255 --> 1.083493).  Saving model ...
Validation loss decreased (1.083493 --> 1.078758).  Saving model ...
Validation loss decreased (1.078758 --> 1.074475).  Saving model ...
Validation loss decreased (1.074475 --> 1.069889).  Saving model ...
Validation loss decreased (1.069889 --> 1.065159).  Saving model ...
Validation loss decreased (1.065159 --> 1.059229).  Saving model ...
Validation loss decreased (1.059229 --> 1.054985).  Saving model ...
Validation loss decreased (1.054985 --> 1.050222).  Saving model ...
Validation loss decreased (1.050222 --> 1.045778).  Saving model ...
Validation loss decreased (1.045778 --> 1.042659).  Saving model ...
Validation loss decreased (1.042659 --> 1.039968).  Saving model ...
Validation loss decreased (1.039968 --> 1.034923).  Saving model ...
Validation loss decreased (1.034923 --> 1.032107).  Saving model ...
Validation loss decreased (1.032107 --> 1.027630).  Saving model ...
Validation loss decreased (1.027630 --> 1.022878).  Saving model ...
Validation loss decreased (1.022878 --> 1.019604).  Saving model ...
Validation loss decreased (1.019604 --> 1.017852).  Saving model ...
Validation loss decreased (1.017852 --> 1.013718).  Saving model ...
Validation loss decreased (1.013718 --> 1.011219).  Saving model ...
Validation loss decreased (1.011219 --> 1.007904).  Saving model ...
Validation loss decreased (1.007904 --> 1.005813).  Saving model ...
Validation loss decreased (1.005813 --> 1.002676).  Saving model ...
Validation loss decreased (1.002676 --> 0.998753).  Saving model ...
Validation loss decreased (0.998753 --> 0.996279).  Saving model ...
Validation loss decreased (0.996279 --> 0.991843).  Saving model ...
Validation loss decreased (0.991843 --> 0.988700).  Saving model ...
Validation loss decreased (0.988700 --> 0.985948).  Saving model ...
Validation loss decreased (0.985948 --> 0.983330).  Saving model ...
Validation loss decreased (0.983330 --> 0.981656).  Saving model ...
Validation loss decreased (0.981656 --> 0.978825).  Saving model ...
Validation loss decreased (0.978825 --> 0.976760).  Saving model ...
Validation loss decreased (0.976760 --> 0.973855).  Saving model ...
Validation loss decreased (0.973855 --> 0.972470).  Saving model ...
Validation loss decreased (0.972470 --> 0.971236).  Saving model ...
Validation loss decreased (0.971236 --> 0.967599).  Saving model ...
Validation loss decreased (0.967599 --> 0.962778).  Saving model ...
Validation loss decreased (0.962778 --> 0.960626).  Saving model ...
Validation loss decreased (0.960626 --> 0.960448).  Saving model ...
Validation loss decreased (0.960448 --> 0.958095).  Saving model ...
Validation loss decreased (0.958095 --> 0.955345).  Saving model ...
Validation loss decreased (0.955345 --> 0.953804).  Saving model ...
Validation loss decreased (0.953804 --> 0.950714).  Saving model ...
Validation loss decreased (0.950714 --> 0.949508).  Saving model ...
Validation loss decreased (0.949508 --> 0.948049).  Saving model ...
Validation loss decreased (0.948049 --> 0.947441).  Saving model ...
Validation loss decreased (0.947441 --> 0.945140).  Saving model ...
Validation loss decreased (0.945140 --> 0.943468).  Saving model ...
Validation loss decreased (0.943468 --> 0.941432).  Saving model ...
Validation loss decreased (0.941432 --> 0.938867).  Saving model ...
Validation loss decreased (0.938867 --> 0.937911).  Saving model ...
Validation loss decreased (0.937911 --> 0.936971).  Saving model ...
Validation loss decreased (0.936971 --> 0.935128).  Saving model ...
Validation loss decreased (0.935128 --> 0.933445).  Saving model ...
EarlyStopping counter: 1 out of 10.0
Validation loss decreased (0.933445 --> 0.932892).  Saving model ...
Validation loss decreased (0.932892 --> 0.930970).  Saving model ...
Validation loss decreased (0.930970 --> 0.929054).  Saving model ...
Validation loss decreased (0.929054 --> 0.928108).  Saving model ...
Validation loss decreased (0.928108 --> 0.927412).  Saving model ...
EarlyStopping counter: 1 out of 10.0
Validation loss decreased (0.927412 --> 0.927213).  Saving model ...
Validation loss decreased (0.927213 --> 0.925865).  Saving model ...
Validation loss decreased (0.925865 --> 0.924453).  Saving model ...
Validation loss decreased (0.924453 --> 0.923765).  Saving model ...
Validation loss decreased (0.923765 --> 0.922321).  Saving model ...
Validation loss decreased (0.922321 --> 0.920994).  Saving model ...
EarlyStopping counter: 1 out of 10.0
EarlyStopping counter: 2 out of 10.0
Validation loss decreased (0.920994 --> 0.920913).  Saving model ...
Validation loss decreased (0.920913 --> 0.919992).  Saving model ...
Validation loss decreased (0.919992 --> 0.919637).  Saving model ...
Validation loss decreased (0.919637 --> 0.918330).  Saving model ...
Validation loss decreased (0.918330 --> 0.917441).  Saving model ...
EarlyStopping counter: 1 out of 10.0
EarlyStopping counter: 2 out of 10.0
EarlyStopping counter: 3 out of 10.0
Validation loss decreased (0.917441 --> 0.916289).  Saving model ...
Validation loss decreased (0.916289 --> 0.915974).  Saving model ...
EarlyStopping counter: 1 out of 10.0
Validation loss decreased (0.915974 --> 0.915643).  Saving model ...
Validation loss decreased (0.915643 --> 0.914325).  Saving model ...
Validation loss decreased (0.914325 --> 0.914033).  Saving model ...
Validation loss decreased (0.914033 --> 0.913766).  Saving model ...
Validation loss decreased (0.913766 --> 0.913114).  Saving model ...
EarlyStopping counter: 1 out of 10.0
Validation loss decreased (0.913114 --> 0.912461).  Saving model ...
Validation loss decreased (0.912461 --> 0.911636).  Saving model ...
Validation loss decreased (0.911636 --> 0.910729).  Saving model ...
EarlyStopping counter: 1 out of 10.0
EarlyStopping counter: 2 out of 10.0
EarlyStopping counter: 3 out of 10.0
EarlyStopping counter: 4 out of 10.0
EarlyStopping counter: 5 out of 10.0
EarlyStopping counter: 6 out of 10.0
EarlyStopping counter: 7 out of 10.0
EarlyStopping counter: 8 out of 10.0
EarlyStopping counter: 9 out of 10.0
EarlyStopping counter: 10 out of 10.0
/localscratch/yinan.29019325.0/env/lib/python3.7/site-packages/torch/nn/functional.py:1794: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.
  warnings.warn("nn.functional.tanh is deprecated. Use torch.tanh instead.")
wandb: Waiting for W&B process to finish, PID 24761... (success).
wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: \ 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: | 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: / 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: \ 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: | 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: / 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: \ 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: | 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: / 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb:                                                                                
wandb: Run history:
wandb:     e_F1 ▁▂▃▄▅▅▅▆▆▆▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇███████████████
wandb:   e_loss ██▇▇▇▆▆▆▅▅▅▄▄▄▃▃▃▃▂▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:     t_F1 ▁▁▂▂▃▃▄▄▄▅▅▅▅▆▅▅▆▆▆▆▆▇▇▇▇▇▇▇▇▇▇██▇▇▇████
wandb:   t_loss ██▇▇▇▇▇▇▆▆▆▆▅▅▅▅▄▄▄▄▄▃▃▃▃▃▃▂▂▂▂▂▂▂▂▂▁▁▁▁
wandb: 
wandb: Run summary:
wandb:     e_F1 59.5733
wandb:   e_loss 0.9142
wandb:     t_F1 73.1629
wandb:   t_loss 0.70848
wandb: 
wandb: Synced 4 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Synced polished-cloud-2: https://wandb.ai/yinanazhou/xl_512_bs_8_lr_1e06_es_10_lc_False_nr_True_sr_True_stem_False_lemma_False_repeat_5_fold_1/runs/hiqr09yc
wandb: Find logs at: ./wandb/run-20220319_073822-hiqr09yc/logs/debug.log
wandb: 

wandb: wandb version 0.12.11 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
2022-03-19 09:11:08.308704: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1
wandb: Tracking run with wandb version 0.12.5
wandb: Syncing run cool-morning-2
wandb: ⭐️ View project at https://wandb.ai/yinanazhou/xl_512_bs_8_lr_1e06_es_10_lc_False_nr_True_sr_True_stem_False_lemma_False_repeat_5_fold_2
wandb: 🚀 View run at https://wandb.ai/yinanazhou/xl_512_bs_8_lr_1e06_es_10_lc_False_nr_True_sr_True_stem_False_lemma_False_repeat_5_fold_2/runs/2imn3vu4
wandb: Run data is saved locally in /project/6002780/yinan/Thesis_MER_Lyrics/lyric-emotion/wandb/run-20220319_091105-2imn3vu4
wandb: Run `wandb offline` to turn off syncing.

Validation loss decreased (inf --> 1.435641).  Saving model ...
Validation loss decreased (1.435641 --> 1.413356).  Saving model ...
Validation loss decreased (1.413356 --> 1.398221).  Saving model ...
Validation loss decreased (1.398221 --> 1.385576).  Saving model ...
Validation loss decreased (1.385576 --> 1.376607).  Saving model ...
Validation loss decreased (1.376607 --> 1.370081).  Saving model ...
Validation loss decreased (1.370081 --> 1.364175).  Saving model ...
Validation loss decreased (1.364175 --> 1.358895).  Saving model ...
Validation loss decreased (1.358895 --> 1.354081).  Saving model ...
Validation loss decreased (1.354081 --> 1.349818).  Saving model ...
Validation loss decreased (1.349818 --> 1.345586).  Saving model ...
Validation loss decreased (1.345586 --> 1.340988).  Saving model ...
Validation loss decreased (1.340988 --> 1.335618).  Saving model ...
Validation loss decreased (1.335618 --> 1.330669).  Saving model ...
Validation loss decreased (1.330669 --> 1.326311).  Saving model ...
Validation loss decreased (1.326311 --> 1.321908).  Saving model ...
Validation loss decreased (1.321908 --> 1.316944).  Saving model ...
Validation loss decreased (1.316944 --> 1.312281).  Saving model ...
Validation loss decreased (1.312281 --> 1.307820).  Saving model ...
Validation loss decreased (1.307820 --> 1.302722).  Saving model ...
Validation loss decreased (1.302722 --> 1.297018).  Saving model ...
Validation loss decreased (1.297018 --> 1.291580).  Saving model ...
Validation loss decreased (1.291580 --> 1.285864).  Saving model ...
Validation loss decreased (1.285864 --> 1.279070).  Saving model ...
Validation loss decreased (1.279070 --> 1.272357).  Saving model ...
Validation loss decreased (1.272357 --> 1.266030).  Saving model ...
Validation loss decreased (1.266030 --> 1.258695).  Saving model ...
Validation loss decreased (1.258695 --> 1.251329).  Saving model ...
Validation loss decreased (1.251329 --> 1.243965).  Saving model ...
Validation loss decreased (1.243965 --> 1.237694).  Saving model ...
Validation loss decreased (1.237694 --> 1.228906).  Saving model ...
Validation loss decreased (1.228906 --> 1.219417).  Saving model ...
Validation loss decreased (1.219417 --> 1.211779).  Saving model ...
Validation loss decreased (1.211779 --> 1.205331).  Saving model ...
Validation loss decreased (1.205331 --> 1.198580).  Saving model ...
Validation loss decreased (1.198580 --> 1.189050).  Saving model ...
Validation loss decreased (1.189050 --> 1.181519).  Saving model ...
Validation loss decreased (1.181519 --> 1.174266).  Saving model ...
Validation loss decreased (1.174266 --> 1.166561).  Saving model ...
Validation loss decreased (1.166561 --> 1.159912).  Saving model ...
Validation loss decreased (1.159912 --> 1.154798).  Saving model ...
Validation loss decreased (1.154798 --> 1.149293).  Saving model ...
Validation loss decreased (1.149293 --> 1.146591).  Saving model ...
Validation loss decreased (1.146591 --> 1.138926).  Saving model ...
Validation loss decreased (1.138926 --> 1.133919).  Saving model ...
Validation loss decreased (1.133919 --> 1.127998).  Saving model ...
Validation loss decreased (1.127998 --> 1.123156).  Saving model ...
Validation loss decreased (1.123156 --> 1.115619).  Saving model ...
Validation loss decreased (1.115619 --> 1.110105).  Saving model ...
Validation loss decreased (1.110105 --> 1.105237).  Saving model ...
Validation loss decreased (1.105237 --> 1.100812).  Saving model ...
Validation loss decreased (1.100812 --> 1.096639).  Saving model ...
Validation loss decreased (1.096639 --> 1.093603).  Saving model ...
Validation loss decreased (1.093603 --> 1.087809).  Saving model ...
Validation loss decreased (1.087809 --> 1.082320).  Saving model ...
Validation loss decreased (1.082320 --> 1.079136).  Saving model ...
Validation loss decreased (1.079136 --> 1.074155).  Saving model ...
Validation loss decreased (1.074155 --> 1.068085).  Saving model ...
Validation loss decreased (1.068085 --> 1.066001).  Saving model ...
Validation loss decreased (1.066001 --> 1.062461).  Saving model ...
Validation loss decreased (1.062461 --> 1.059256).  Saving model ...
Validation loss decreased (1.059256 --> 1.054138).  Saving model ...
Validation loss decreased (1.054138 --> 1.049422).  Saving model ...
Validation loss decreased (1.049422 --> 1.046654).  Saving model ...
Validation loss decreased (1.046654 --> 1.042290).  Saving model ...
Validation loss decreased (1.042290 --> 1.037671).  Saving model ...
Validation loss decreased (1.037671 --> 1.035412).  Saving model ...
Validation loss decreased (1.035412 --> 1.031428).  Saving model ...
Validation loss decreased (1.031428 --> 1.027493).  Saving model ...
Validation loss decreased (1.027493 --> 1.024270).  Saving model ...
Validation loss decreased (1.024270 --> 1.021413).  Saving model ...
Validation loss decreased (1.021413 --> 1.021155).  Saving model ...
Validation loss decreased (1.021155 --> 1.018252).  Saving model ...
Validation loss decreased (1.018252 --> 1.014116).  Saving model ...
Validation loss decreased (1.014116 --> 1.013163).  Saving model ...
Validation loss decreased (1.013163 --> 1.009301).  Saving model ...
Validation loss decreased (1.009301 --> 1.005489).  Saving model ...
Validation loss decreased (1.005489 --> 1.003425).  Saving model ...
Validation loss decreased (1.003425 --> 0.999234).  Saving model ...
Validation loss decreased (0.999234 --> 0.996456).  Saving model ...
Validation loss decreased (0.996456 --> 0.992500).  Saving model ...
Validation loss decreased (0.992500 --> 0.989411).  Saving model ...
Validation loss decreased (0.989411 --> 0.989206).  Saving model ...
Validation loss decreased (0.989206 --> 0.988471).  Saving model ...
Validation loss decreased (0.988471 --> 0.984361).  Saving model ...
Validation loss decreased (0.984361 --> 0.983470).  Saving model ...
Validation loss decreased (0.983470 --> 0.980141).  Saving model ...
EarlyStopping counter: 1 out of 10.0
Validation loss decreased (0.980141 --> 0.977498).  Saving model ...
EarlyStopping counter: 1 out of 10.0
Validation loss decreased (0.977498 --> 0.974422).  Saving model ...
Validation loss decreased (0.974422 --> 0.971215).  Saving model ...
Validation loss decreased (0.971215 --> 0.971188).  Saving model ...
Validation loss decreased (0.971188 --> 0.968036).  Saving model ...
Validation loss decreased (0.968036 --> 0.967170).  Saving model ...
Validation loss decreased (0.967170 --> 0.963971).  Saving model ...
Validation loss decreased (0.963971 --> 0.960823).  Saving model ...
Validation loss decreased (0.960823 --> 0.958137).  Saving model ...
Validation loss decreased (0.958137 --> 0.957409).  Saving model ...
Validation loss decreased (0.957409 --> 0.954920).  Saving model ...
Validation loss decreased (0.954920 --> 0.954573).  Saving model ...
EarlyStopping counter: 1 out of 10.0
Validation loss decreased (0.954573 --> 0.953414).  Saving model ...
Validation loss decreased (0.953414 --> 0.953231).  Saving model ...
Validation loss decreased (0.953231 --> 0.950625).  Saving model ...
Validation loss decreased (0.950625 --> 0.946489).  Saving model ...
Validation loss decreased (0.946489 --> 0.945152).  Saving model ...
Validation loss decreased (0.945152 --> 0.944056).  Saving model ...
EarlyStopping counter: 1 out of 10.0
Validation loss decreased (0.944056 --> 0.943760).  Saving model ...
Validation loss decreased (0.943760 --> 0.942076).  Saving model ...
EarlyStopping counter: 1 out of 10.0
EarlyStopping counter: 2 out of 10.0
Validation loss decreased (0.942076 --> 0.941486).  Saving model ...
Validation loss decreased (0.941486 --> 0.940988).  Saving model ...
Validation loss decreased (0.940988 --> 0.938837).  Saving model ...
EarlyStopping counter: 1 out of 10.0
EarlyStopping counter: 2 out of 10.0
Validation loss decreased (0.938837 --> 0.937766).  Saving model ...
Validation loss decreased (0.937766 --> 0.935440).  Saving model ...
Validation loss decreased (0.935440 --> 0.933847).  Saving model ...
Validation loss decreased (0.933847 --> 0.932096).  Saving model ...
EarlyStopping counter: 1 out of 10.0
EarlyStopping counter: 2 out of 10.0
Validation loss decreased (0.932096 --> 0.931529).  Saving model ...
EarlyStopping counter: 1 out of 10.0
EarlyStopping counter: 2 out of 10.0
EarlyStopping counter: 3 out of 10.0
Validation loss decreased (0.931529 --> 0.929416).  Saving model ...
Validation loss decreased (0.929416 --> 0.929134).  Saving model ...
Validation loss decreased (0.929134 --> 0.927510).  Saving model ...
EarlyStopping counter: 1 out of 10.0
Validation loss decreased (0.927510 --> 0.925877).  Saving model ...
EarlyStopping counter: 1 out of 10.0
EarlyStopping counter: 2 out of 10.0
EarlyStopping counter: 3 out of 10.0
EarlyStopping counter: 4 out of 10.0
EarlyStopping counter: 5 out of 10.0
EarlyStopping counter: 6 out of 10.0
EarlyStopping counter: 7 out of 10.0
Validation loss decreased (0.925877 --> 0.925232).  Saving model ...
Validation loss decreased (0.925232 --> 0.924869).  Saving model ...
EarlyStopping counter: 1 out of 10.0
Validation loss decreased (0.924869 --> 0.923906).  Saving model ...
Validation loss decreased (0.923906 --> 0.923571).  Saving model ...
Validation loss decreased (0.923571 --> 0.923350).  Saving model ...
Validation loss decreased (0.923350 --> 0.922549).  Saving model ...
EarlyStopping counter: 1 out of 10.0
EarlyStopping counter: 2 out of 10.0
EarlyStopping counter: 3 out of 10.0
EarlyStopping counter: 4 out of 10.0
EarlyStopping counter: 5 out of 10.0
Validation loss decreased (0.922549 --> 0.922349).  Saving model ...
EarlyStopping counter: 1 out of 10.0
EarlyStopping counter: 2 out of 10.0
EarlyStopping counter: 3 out of 10.0
EarlyStopping counter: 4 out of 10.0
EarlyStopping counter: 5 out of 10.0
EarlyStopping counter: 6 out of 10.0
EarlyStopping counter: 7 out of 10.0
EarlyStopping counter: 8 out of 10.0
EarlyStopping counter: 9 out of 10.0
EarlyStopping counter: 10 out of 10.0
/localscratch/yinan.29019325.0/env/lib/python3.7/site-packages/torch/nn/functional.py:1794: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.
  warnings.warn("nn.functional.tanh is deprecated. Use torch.tanh instead.")
wandb: Waiting for W&B process to finish, PID 29964... (success).
wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: \ 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: | 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: / 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: \ 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: | 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: / 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: \ 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: | 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: / 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb:                                                                                
wandb: Run history:
wandb:     e_F1 ▁▂▃▄▅▅▅▆▆▆▆▆▇▇▇▇▇▇▇▇████████████████████
wandb:   e_loss █▇▇▇▇▆▆▅▅▅▄▄▄▃▃▃▃▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:     t_F1 ▁▂▂▂▃▄▄▄▅▅▅▅▆▆▆▆▆▆▆▇▇▆▇▇▇▆▇▇▇▇▇▇█▇██▇███
wandb:   t_loss █▇▇▇▇▇▇▆▆▆▆▅▅▅▄▄▄▄▄▃▃▃▃▃▃▃▃▃▂▂▂▂▂▂▂▂▂▁▁▁
wandb: 
wandb: Run summary:
wandb:     e_F1 61.11666
wandb:   e_loss 0.92276
wandb:     t_F1 72.33551
wandb:   t_loss 0.71327
wandb: 
wandb: Synced 4 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Synced cool-morning-2: https://wandb.ai/yinanazhou/xl_512_bs_8_lr_1e06_es_10_lc_False_nr_True_sr_True_stem_False_lemma_False_repeat_5_fold_2/runs/2imn3vu4
wandb: Find logs at: ./wandb/run-20220319_091105-2imn3vu4/logs/debug.log
wandb: 

