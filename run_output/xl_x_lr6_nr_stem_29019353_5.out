Unloading StdEnv/2020

Due to MODULEPATH changes, the following have been reloaded:
  1) mii/1.1.1


The following have been reloaded with a version change:
  1) python/3.8.2 => python/3.7.4

Using base prefix '/cvmfs/soft.computecanada.ca/easybuild/software/2017/Core/python/3.7.4'
New python executable in /localscratch/yinan.29161863.0/env/bin/python
Installing setuptools, pip, wheel...
done.
Ignoring pip: markers 'python_version < "3"' don't match your environment
Looking in links: /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/nix/avx2, /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/nix/generic, /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic
Collecting pip
Installing collected packages: pip
  Found existing installation: pip 19.1.1
    Uninstalling pip-19.1.1:
      Successfully uninstalled pip-19.1.1
Successfully installed pip-21.2.3+computecanada
Looking in links: /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/nix/avx2, /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/nix/generic, /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/keras-2.8.0+computecanada-py2.py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/Keras_Preprocessing-1.1.2+computecanada-py3-none-any.whl
Requirement already satisfied: matplotlib in /cvmfs/soft.computecanada.ca/easybuild/software/2017/Core/scipy-stack/2019a/lib/python3.7/site-packages (from -r requirements.txt (line 3)) (3.0.2)
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/nltk-3.6.5+computecanada-py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/scikit_learn-0.22.1+computecanada-cp37-cp37m-linux_x86_64.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/tensorboard-2.3.0+computecanada-py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/tensorboard_plugin_wit-1.7.0+computecanada-py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/tensorflow_gpu-2.3.0+computecanada-cp37-cp37m-linux_x86_64.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/tensorflow_estimator-2.3.0+computecanada-py2.py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/tokenizers-0.5.2+computecanada-cp37-cp37m-linux_x86_64.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/nix/avx2/torch-1.4.0+computecanada-cp37-cp37m-linux_x86_64.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/torchtext-0.6.0+computecanada-py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/torchvision-0.8.2+computecanada-cp37-cp37m-linux_x86_64.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/transformers-2.5.1+computecanada-py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/urllib3-1.26.7+computecanada-py2.py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/joblib-1.1.0+computecanada-py2.py3-none-any.whl
ERROR: Could not find a version that satisfies the requirement regex>=2021.8.3 (from nltk) (from versions: 2018.1.10+computecanada, 2019.11.1+computecanada, 2020.11.13+computecanada)
ERROR: No matching distribution found for regex>=2021.8.3
Looking in links: /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/nix/avx2, /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/nix/generic, /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic
ERROR: Could not find a version that satisfies the requirement numpy==1.20.0+computacanada (from versions: 1.15.0+computecanada, 1.15.2+computecanada, 1.15.4+computecanada, 1.16.0+computecanada, 1.16.2+computecanada, 1.16.3+computecanada, 1.17.4+computecanada, 1.18.1+computecanada, 1.18.4+computecanada, 1.19.1+computecanada, 1.19.2+computecanada, 1.20.2+computecanada)
ERROR: No matching distribution found for numpy==1.20.0+computacanada
Looking in links: /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/nix/avx2, /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/nix/generic, /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/wandb-0.12.5+computecanada-py2.py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/sentry_sdk-1.5.0+computecanada-py2.py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/configparser-5.0.2+computecanada-py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/six-1.16.0+computecanada-py2.py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/subprocess32-3.5.4+computecanada-py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/yaspin-2.1.0+computecanada-py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/pathtools-0.1.2+computecanada-py3-none-any.whl
Requirement already satisfied: python-dateutil>=2.6.1 in /cvmfs/soft.computecanada.ca/easybuild/software/2017/Core/scipy-stack/2019a/lib/python3.7/site-packages (from wandb) (2.7.5)
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/docker_pycreds-0.4.0+computecanada-py2.py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/promise-2.3+computecanada-py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/GitPython-3.1.24+computecanada-py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/protobuf-3.19.4+computecanada-py2.py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/PyYAML-5.3.1+computecanada-cp37-cp37m-linux_x86_64.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/shortuuid-1.0.1+computecanada-py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/psutil-5.7.3+computecanada-cp37-cp37m-linux_x86_64.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/click-8.0.4+computecanada-py3-none-any.whl
Requirement already satisfied: requests<3,>=2.0.0 in /cvmfs/soft.computecanada.ca/easybuild/software/2017/Core/scipy-stack/2019a/lib/python3.7/site-packages (from wandb) (2.21.0)
Requirement already satisfied: importlib-metadata in /cvmfs/soft.computecanada.ca/easybuild/software/2017/Core/scipy-stack/2019a/lib/python3.7/site-packages (from Click!=8.0.0,>=7.0->wandb) (0.8)
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/gitdb-4.0.9+computecanada-py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/typing_extensions-4.0.1+computecanada-py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/smmap-5.0.0+computecanada-py3-none-any.whl
Requirement already satisfied: urllib3<1.25,>=1.21.1 in /cvmfs/soft.computecanada.ca/easybuild/software/2017/Core/scipy-stack/2019a/lib/python3.7/site-packages (from requests<3,>=2.0.0->wandb) (1.24.1)
Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /cvmfs/soft.computecanada.ca/easybuild/software/2017/Core/scipy-stack/2019a/lib/python3.7/site-packages (from requests<3,>=2.0.0->wandb) (3.0.4)
Requirement already satisfied: certifi>=2017.4.17 in /cvmfs/soft.computecanada.ca/easybuild/software/2017/Core/scipy-stack/2019a/lib/python3.7/site-packages (from requests<3,>=2.0.0->wandb) (2018.11.29)
Requirement already satisfied: idna<2.9,>=2.5 in /cvmfs/soft.computecanada.ca/easybuild/software/2017/Core/scipy-stack/2019a/lib/python3.7/site-packages (from requests<3,>=2.0.0->wandb) (2.8)
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/termcolor-1.1.0+computecanada-py3-none-any.whl
Requirement already satisfied: zipp>=0.3.2 in /cvmfs/soft.computecanada.ca/easybuild/software/2017/Core/scipy-stack/2019a/lib/python3.7/site-packages (from importlib-metadata->Click!=8.0.0,>=7.0->wandb) (0.3.3)
Installing collected packages: smmap, typing-extensions, termcolor, six, gitdb, yaspin, subprocess32, shortuuid, sentry-sdk, PyYAML, psutil, protobuf, promise, pathtools, GitPython, docker-pycreds, configparser, Click, wandb
  Attempting uninstall: six
    Found existing installation: six 1.12.0
    Not uninstalling six at /cvmfs/soft.computecanada.ca/easybuild/software/2017/Core/scipy-stack/2019a/lib/python3.7/site-packages, outside environment /localscratch/yinan.29161863.0/env
    Can't uninstall 'six'. No files were found to uninstall.
Successfully installed Click-8.0.4+computecanada GitPython-3.1.24+computecanada PyYAML-5.3.1+computecanada configparser-5.0.2+computecanada docker-pycreds-0.4.0+computecanada gitdb-4.0.9+computecanada pathtools-0.1.2+computecanada promise-2.3+computecanada protobuf-3.19.4+computecanada psutil-5.7.3+computecanada sentry-sdk-1.5.0+computecanada shortuuid-1.0.1+computecanada six-1.16.0+computecanada smmap-5.0.0+computecanada subprocess32-3.5.4+computecanada termcolor-1.1.0+computecanada typing-extensions-4.0.1+computecanada wandb-0.12.5+computecanada yaspin-2.1.0+computecanada
Looking in links: /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/nix/avx2, /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/nix/generic, /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic
ERROR: Could not find a version that satisfies the requirement sagemaker (from versions: none)
ERROR: No matching distribution found for sagemaker
Looking in links: /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/nix/avx2, /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/nix/generic, /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/torch-1.9.1+computecanada-cp37-cp37m-linux_x86_64.whl
Requirement already satisfied: typing-extensions in /localscratch/yinan.29161863.0/env/lib/python3.7/site-packages (from torch) (4.0.1+computecanada)
Installing collected packages: torch
Successfully installed torch-1.9.1+computecanada
Looking in links: /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/nix/avx2, /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/nix/generic, /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/transformers-2.5.1+computecanada-py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/sentencepiece-0.1.91+computecanada-cp37-cp37m-linux_x86_64.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/tokenizers-0.5.2+computecanada-cp37-cp37m-linux_x86_64.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/tqdm-4.63.0+computecanada-py2.py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/sacremoses-0.0.46+computecanada-py3-none-any.whl
Requirement already satisfied: requests in /cvmfs/soft.computecanada.ca/easybuild/software/2017/Core/scipy-stack/2019a/lib/python3.7/site-packages (from transformers==2.5.1+computecanada) (2.21.0)
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/regex-2020.11.13+computecanada-cp37-cp37m-linux_x86_64.whl
Requirement already satisfied: numpy in /cvmfs/soft.computecanada.ca/easybuild/software/2017/Core/scipy-stack/2019a/lib/python3.7/site-packages (from transformers==2.5.1+computecanada) (1.16.0)
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/boto3-1.21.14+computecanada-py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/filelock-3.4.2+computecanada-py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/s3transfer-0.5.1+computecanada-py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/botocore-1.24.14+computecanada-py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/jmespath-0.10.0+computecanada-py2.py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/urllib3-1.26.8+computecanada-py2.py3-none-any.whl
Requirement already satisfied: python-dateutil<3.0.0,>=2.1 in /cvmfs/soft.computecanada.ca/easybuild/software/2017/Core/scipy-stack/2019a/lib/python3.7/site-packages (from botocore<1.25.0,>=1.24.14->boto3->transformers==2.5.1+computecanada) (2.7.5)
Requirement already satisfied: six>=1.5 in /localscratch/yinan.29161863.0/env/lib/python3.7/site-packages (from python-dateutil<3.0.0,>=2.1->botocore<1.25.0,>=1.24.14->boto3->transformers==2.5.1+computecanada) (1.16.0+computecanada)
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/requests-2.27.1+computecanada-py2.py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/charset_normalizer-2.0.12+computecanada-py3-none-any.whl
Requirement already satisfied: certifi>=2017.4.17 in /cvmfs/soft.computecanada.ca/easybuild/software/2017/Core/scipy-stack/2019a/lib/python3.7/site-packages (from requests->transformers==2.5.1+computecanada) (2018.11.29)
Requirement already satisfied: idna<4,>=2.5 in /cvmfs/soft.computecanada.ca/easybuild/software/2017/Core/scipy-stack/2019a/lib/python3.7/site-packages (from requests->transformers==2.5.1+computecanada) (2.8)
Requirement already satisfied: click in /localscratch/yinan.29161863.0/env/lib/python3.7/site-packages (from sacremoses->transformers==2.5.1+computecanada) (8.0.4+computecanada)
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/joblib-1.1.0+computecanada-py2.py3-none-any.whl
Requirement already satisfied: importlib-metadata in /cvmfs/soft.computecanada.ca/easybuild/software/2017/Core/scipy-stack/2019a/lib/python3.7/site-packages (from click->sacremoses->transformers==2.5.1+computecanada) (0.8)
Requirement already satisfied: zipp>=0.3.2 in /cvmfs/soft.computecanada.ca/easybuild/software/2017/Core/scipy-stack/2019a/lib/python3.7/site-packages (from importlib-metadata->click->sacremoses->transformers==2.5.1+computecanada) (0.3.3)
Installing collected packages: urllib3, jmespath, botocore, tqdm, s3transfer, regex, joblib, charset-normalizer, tokenizers, sentencepiece, sacremoses, requests, filelock, boto3, transformers
  Attempting uninstall: urllib3
    Found existing installation: urllib3 1.24.1
    Not uninstalling urllib3 at /cvmfs/soft.computecanada.ca/easybuild/software/2017/Core/scipy-stack/2019a/lib/python3.7/site-packages, outside environment /localscratch/yinan.29161863.0/env
    Can't uninstall 'urllib3'. No files were found to uninstall.
  Attempting uninstall: requests
    Found existing installation: requests 2.21.0
    Not uninstalling requests at /cvmfs/soft.computecanada.ca/easybuild/software/2017/Core/scipy-stack/2019a/lib/python3.7/site-packages, outside environment /localscratch/yinan.29161863.0/env
    Can't uninstall 'requests'. No files were found to uninstall.
Successfully installed boto3-1.21.14+computecanada botocore-1.24.14+computecanada charset-normalizer-2.0.12+computecanada filelock-3.4.2+computecanada jmespath-0.10.0+computecanada joblib-1.1.0+computecanada regex-2020.11.13+computecanada requests-2.27.1+computecanada s3transfer-0.5.1+computecanada sacremoses-0.0.46+computecanada sentencepiece-0.1.91+computecanada tokenizers-0.5.2+computecanada tqdm-4.63.0+computecanada transformers-2.5.1+computecanada urllib3-1.26.8+computecanada
Looking in links: /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/nix/avx2, /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/nix/generic, /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/tensorflow_gpu-2.3.0+computecanada-cp37-cp37m-linux_x86_64.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/astunparse-1.6.3+computecanada-py2.py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/absl_py-1.0.0+computecanada-py3-none-any.whl
Requirement already satisfied: termcolor>=1.1.0 in /localscratch/yinan.29161863.0/env/lib/python3.7/site-packages (from tensorflow_gpu==2.3.0+computecanada) (1.1.0+computecanada)
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/grpcio-1.38.0+computecanada-cp37-cp37m-linux_x86_64.whl
Requirement already satisfied: protobuf>=3.9.2 in /localscratch/yinan.29161863.0/env/lib/python3.7/site-packages (from tensorflow_gpu==2.3.0+computecanada) (3.19.4+computecanada)
Requirement already satisfied: six>=1.12.0 in /localscratch/yinan.29161863.0/env/lib/python3.7/site-packages (from tensorflow_gpu==2.3.0+computecanada) (1.16.0+computecanada)
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/nix/avx2/h5py-2.10.0+computecanada-cp37-cp37m-linux_x86_64.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/Keras_Preprocessing-1.1.2+computecanada-py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/tensorboard-2.8.0+computecanada-py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/google_pasta-0.2.0+computecanada-py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/opt_einsum-3.3.0+computecanada-py3-none-any.whl
Requirement already satisfied: wheel>=0.26 in /localscratch/yinan.29161863.0/env/lib/python3.7/site-packages (from tensorflow_gpu==2.3.0+computecanada) (0.33.4)
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/tensorflow_estimator-2.3.0+computecanada-py2.py3-none-any.whl
Requirement already satisfied: numpy<1.19.0,>=1.16.0 in /cvmfs/soft.computecanada.ca/easybuild/software/2017/Core/scipy-stack/2019a/lib/python3.7/site-packages (from tensorflow_gpu==2.3.0+computecanada) (1.16.0)
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/gast-0.3.3+computecanada-py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/wrapt-1.11.2+computecanada-cp37-cp37m-linux_x86_64.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/nix/generic/scipy-1.4.1+computecanada-cp37-cp37m-linux_x86_64.whl
Requirement already satisfied: requests<3,>=2.21.0 in /localscratch/yinan.29161863.0/env/lib/python3.7/site-packages (from tensorboard<3,>=2.3.0->tensorflow_gpu==2.3.0+computecanada) (2.27.1+computecanada)
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/google_auth-2.3.3+computecanada-py2.py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/Werkzeug-2.0.3+computecanada-py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/google_auth_oauthlib-0.4.6+computecanada-py2.py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/Markdown-3.3.6+computecanada-py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/tensorboard_data_server-0.6.1+computecanada-py3-none-linux_x86_64.whl
Requirement already satisfied: setuptools>=41.0.0 in /localscratch/yinan.29161863.0/env/lib/python3.7/site-packages (from tensorboard<3,>=2.3.0->tensorflow_gpu==2.3.0+computecanada) (41.0.1)
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/tensorboard_plugin_wit-1.8.0+computecanada-py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/pyasn1_modules-0.2.8+computecanada-py2.py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/rsa-4.8+computecanada-py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/cachetools-4.2.4+computecanada-py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/requests_oauthlib-1.3.0+computecanada-py2.py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/importlib_metadata-4.10.1+computecanada-py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/zipp-3.7.0+computecanada-py3-none-any.whl
Requirement already satisfied: typing-extensions>=3.6.4 in /localscratch/yinan.29161863.0/env/lib/python3.7/site-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard<3,>=2.3.0->tensorflow_gpu==2.3.0+computecanada) (4.0.1+computecanada)
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/pyasn1-0.4.8+computecanada-py2.py3-none-any.whl
Requirement already satisfied: certifi>=2017.4.17 in /cvmfs/soft.computecanada.ca/easybuild/software/2017/Core/scipy-stack/2019a/lib/python3.7/site-packages (from requests<3,>=2.21.0->tensorboard<3,>=2.3.0->tensorflow_gpu==2.3.0+computecanada) (2018.11.29)
Requirement already satisfied: charset-normalizer~=2.0.0 in /localscratch/yinan.29161863.0/env/lib/python3.7/site-packages (from requests<3,>=2.21.0->tensorboard<3,>=2.3.0->tensorflow_gpu==2.3.0+computecanada) (2.0.12+computecanada)
Requirement already satisfied: urllib3<1.27,>=1.21.1 in /localscratch/yinan.29161863.0/env/lib/python3.7/site-packages (from requests<3,>=2.21.0->tensorboard<3,>=2.3.0->tensorflow_gpu==2.3.0+computecanada) (1.26.8+computecanada)
Requirement already satisfied: idna<4,>=2.5 in /cvmfs/soft.computecanada.ca/easybuild/software/2017/Core/scipy-stack/2019a/lib/python3.7/site-packages (from requests<3,>=2.21.0->tensorboard<3,>=2.3.0->tensorflow_gpu==2.3.0+computecanada) (2.8)
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/oauthlib-3.1.1+computecanada-py2.py3-none-any.whl
Installing collected packages: pyasn1, zipp, rsa, pyasn1-modules, oauthlib, cachetools, requests-oauthlib, importlib-metadata, google-auth, werkzeug, tensorboard-plugin-wit, tensorboard-data-server, markdown, grpcio, google-auth-oauthlib, absl-py, wrapt, tensorflow-estimator, tensorboard, scipy, opt-einsum, keras-preprocessing, h5py, google-pasta, gast, astunparse, tensorflow-gpu
  Attempting uninstall: pyasn1
    Found existing installation: pyasn1 0.4.3
    Not uninstalling pyasn1 at /cvmfs/soft.computecanada.ca/easybuild/software/2017/Core/scipy-stack/2019a/lib/python3.7/site-packages, outside environment /localscratch/yinan.29161863.0/env
    Can't uninstall 'pyasn1'. No files were found to uninstall.
  Attempting uninstall: zipp
    Found existing installation: zipp 0.3.3
    Not uninstalling zipp at /cvmfs/soft.computecanada.ca/easybuild/software/2017/Core/scipy-stack/2019a/lib/python3.7/site-packages, outside environment /localscratch/yinan.29161863.0/env
    Can't uninstall 'zipp'. No files were found to uninstall.
  Attempting uninstall: importlib-metadata
    Found existing installation: importlib-metadata 0.8
    Not uninstalling importlib-metadata at /cvmfs/soft.computecanada.ca/easybuild/software/2017/Core/scipy-stack/2019a/lib/python3.7/site-packages, outside environment /localscratch/yinan.29161863.0/env
    Can't uninstall 'importlib-metadata'. No files were found to uninstall.
  Attempting uninstall: scipy
    Found existing installation: scipy 1.2.0
    Not uninstalling scipy at /cvmfs/soft.computecanada.ca/easybuild/software/2017/Core/scipy-stack/2019a/lib/python3.7/site-packages, outside environment /localscratch/yinan.29161863.0/env
    Can't uninstall 'scipy'. No files were found to uninstall.
Successfully installed absl-py-1.0.0+computecanada astunparse-1.6.3+computecanada cachetools-4.2.4+computecanada gast-0.3.3+computecanada google-auth-2.3.3+computecanada google-auth-oauthlib-0.4.6+computecanada google-pasta-0.2.0+computecanada grpcio-1.38.0+computecanada h5py-2.10.0+computecanada importlib-metadata-4.10.1+computecanada keras-preprocessing-1.1.2+computecanada markdown-3.3.6+computecanada oauthlib-3.1.1+computecanada opt-einsum-3.3.0+computecanada pyasn1-0.4.8+computecanada pyasn1-modules-0.2.8+computecanada requests-oauthlib-1.3.0+computecanada rsa-4.8+computecanada scipy-1.4.1+computecanada tensorboard-2.8.0+computecanada tensorboard-data-server-0.6.1+computecanada tensorboard-plugin-wit-1.8.0+computecanada tensorflow-estimator-2.3.0+computecanada tensorflow-gpu-2.3.0+computecanada werkzeug-2.0.3+computecanada wrapt-1.11.2+computecanada zipp-3.7.0+computecanada
Looking in links: /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/nix/avx2, /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/nix/generic, /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/keras-2.8.0+computecanada-py2.py3-none-any.whl
Installing collected packages: Keras
Successfully installed Keras-2.8.0+computecanada
Looking in links: /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/nix/avx2, /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/nix/generic, /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/urllib3-1.26.7+computecanada-py2.py3-none-any.whl
Installing collected packages: urllib3
  Attempting uninstall: urllib3
    Found existing installation: urllib3 1.26.8+computecanada
    Uninstalling urllib3-1.26.8+computecanada:
      Successfully uninstalled urllib3-1.26.8+computecanada
Successfully installed urllib3-1.26.7+computecanada
Looking in links: /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/nix/avx2, /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/nix/generic, /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/nltk-3.7+computecanada-py3-none-any.whl
Requirement already satisfied: click in /localscratch/yinan.29161863.0/env/lib/python3.7/site-packages (from nltk) (8.0.4+computecanada)
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/nltk-3.6.5+computecanada-py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/nltk-3.6.3+computecanada-py3-none-any.whl
Requirement already satisfied: regex in /localscratch/yinan.29161863.0/env/lib/python3.7/site-packages (from nltk) (2020.11.13+computecanada)
Requirement already satisfied: tqdm in /localscratch/yinan.29161863.0/env/lib/python3.7/site-packages (from nltk) (4.63.0+computecanada)
Requirement already satisfied: joblib in /localscratch/yinan.29161863.0/env/lib/python3.7/site-packages (from nltk) (1.1.0+computecanada)
Requirement already satisfied: importlib-metadata in /localscratch/yinan.29161863.0/env/lib/python3.7/site-packages (from click->nltk) (4.10.1+computecanada)
Requirement already satisfied: typing-extensions>=3.6.4 in /localscratch/yinan.29161863.0/env/lib/python3.7/site-packages (from importlib-metadata->click->nltk) (4.0.1+computecanada)
Requirement already satisfied: zipp>=0.5 in /localscratch/yinan.29161863.0/env/lib/python3.7/site-packages (from importlib-metadata->click->nltk) (3.7.0+computecanada)
Installing collected packages: nltk
Successfully installed nltk-3.6.3+computecanada
Looking in links: /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/nix/avx2, /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/nix/generic, /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/scikit_learn-0.22.1+computecanada-cp37-cp37m-linux_x86_64.whl
Requirement already satisfied: numpy>=1.11.0 in /cvmfs/soft.computecanada.ca/easybuild/software/2017/Core/scipy-stack/2019a/lib/python3.7/site-packages (from scikit-learn==0.22.1) (1.16.0)
Requirement already satisfied: joblib>=0.11 in /localscratch/yinan.29161863.0/env/lib/python3.7/site-packages (from scikit-learn==0.22.1) (1.1.0+computecanada)
Requirement already satisfied: scipy>=0.17.0 in /localscratch/yinan.29161863.0/env/lib/python3.7/site-packages (from scikit-learn==0.22.1) (1.4.1+computecanada)
Installing collected packages: scikit-learn
Successfully installed scikit-learn-0.22.1+computecanada
Looking in links: /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/nix/avx2, /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/nix/generic, /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic
Requirement already satisfied: tokenizers==0.5.2 in /localscratch/yinan.29161863.0/env/lib/python3.7/site-packages (0.5.2+computecanada)
wandb: Appending key for api.wandb.ai to your netrc file: /home/yinan/.netrc
Starting Task
2022-03-17 21:23:36.296110: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1
[nltk_data] Downloading package stopwords to /home/yinan/nltk_data...
[nltk_data]   Package stopwords is already up-to-date!
[nltk_data] Downloading package wordnet to /home/yinan/nltk_data...
[nltk_data]   Package wordnet is already up-to-date!
wandb: Currently logged in as: yinanazhou (use `wandb login --relogin` to force relogin)
wandb: wandb version 0.12.11 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
2022-03-17 21:23:53.751390: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1
wandb: Tracking run with wandb version 0.12.5
wandb: Syncing run lucky-terrain-2
wandb: ⭐️ View project at https://wandb.ai/yinanazhou/xl_512_bs_8_lr_1e06_es_5_lc_False_nr_True_sr_False_stem_True_lemma_False_repeat_1_fold_1
wandb: 🚀 View run at https://wandb.ai/yinanazhou/xl_512_bs_8_lr_1e06_es_5_lc_False_nr_True_sr_False_stem_True_lemma_False_repeat_1_fold_1/runs/2ch0dbcf
wandb: Run data is saved locally in /project/6002780/yinan/Thesis_MER_Lyrics/lyric-emotion/wandb/run-20220317_212351-2ch0dbcf
wandb: Run `wandb offline` to turn off syncing.
wandb: Network error (ReadTimeout), entering retry loop.

Validation loss decreased (inf --> 1.429610).  Saving model ...
Validation loss decreased (1.429610 --> 1.410610).  Saving model ...
Validation loss decreased (1.410610 --> 1.394058).  Saving model ...
Validation loss decreased (1.394058 --> 1.380720).  Saving model ...
Validation loss decreased (1.380720 --> 1.370384).  Saving model ...
Validation loss decreased (1.370384 --> 1.362188).  Saving model ...
Validation loss decreased (1.362188 --> 1.355357).  Saving model ...
Validation loss decreased (1.355357 --> 1.349489).  Saving model ...
Validation loss decreased (1.349489 --> 1.344061).  Saving model ...
Validation loss decreased (1.344061 --> 1.337906).  Saving model ...
Validation loss decreased (1.337906 --> 1.332308).  Saving model ...
Validation loss decreased (1.332308 --> 1.327101).  Saving model ...
Validation loss decreased (1.327101 --> 1.321444).  Saving model ...
Validation loss decreased (1.321444 --> 1.315772).  Saving model ...
Validation loss decreased (1.315772 --> 1.309046).  Saving model ...
Validation loss decreased (1.309046 --> 1.303488).  Saving model ...
Validation loss decreased (1.303488 --> 1.298232).  Saving model ...
Validation loss decreased (1.298232 --> 1.293404).  Saving model ...
Validation loss decreased (1.293404 --> 1.287221).  Saving model ...
Validation loss decreased (1.287221 --> 1.279560).  Saving model ...
Validation loss decreased (1.279560 --> 1.272830).  Saving model ...
Validation loss decreased (1.272830 --> 1.268484).  Saving model ...
Validation loss decreased (1.268484 --> 1.263801).  Saving model ...
Validation loss decreased (1.263801 --> 1.257566).  Saving model ...
Validation loss decreased (1.257566 --> 1.252531).  Saving model ...
Validation loss decreased (1.252531 --> 1.247467).  Saving model ...
Validation loss decreased (1.247467 --> 1.243241).  Saving model ...
Validation loss decreased (1.243241 --> 1.238626).  Saving model ...
Validation loss decreased (1.238626 --> 1.235311).  Saving model ...
Validation loss decreased (1.235311 --> 1.231885).  Saving model ...
Validation loss decreased (1.231885 --> 1.226629).  Saving model ...
Validation loss decreased (1.226629 --> 1.221752).  Saving model ...
Validation loss decreased (1.221752 --> 1.218405).  Saving model ...
Validation loss decreased (1.218405 --> 1.214105).  Saving model ...
Validation loss decreased (1.214105 --> 1.212170).  Saving model ...
Validation loss decreased (1.212170 --> 1.210059).  Saving model ...
Validation loss decreased (1.210059 --> 1.208710).  Saving model ...
Validation loss decreased (1.208710 --> 1.201573).  Saving model ...
Validation loss decreased (1.201573 --> 1.197366).  Saving model ...
Validation loss decreased (1.197366 --> 1.194696).  Saving model ...
Validation loss decreased (1.194696 --> 1.191445).  Saving model ...
Validation loss decreased (1.191445 --> 1.187498).  Saving model ...
Validation loss decreased (1.187498 --> 1.183596).  Saving model ...
Validation loss decreased (1.183596 --> 1.180420).  Saving model ...
Validation loss decreased (1.180420 --> 1.177196).  Saving model ...
Validation loss decreased (1.177196 --> 1.174113).  Saving model ...
Validation loss decreased (1.174113 --> 1.171812).  Saving model ...
Validation loss decreased (1.171812 --> 1.168172).  Saving model ...
Validation loss decreased (1.168172 --> 1.162328).  Saving model ...
Validation loss decreased (1.162328 --> 1.159442).  Saving model ...
Validation loss decreased (1.159442 --> 1.156276).  Saving model ...
Validation loss decreased (1.156276 --> 1.154955).  Saving model ...
Validation loss decreased (1.154955 --> 1.153054).  Saving model ...
Validation loss decreased (1.153054 --> 1.149631).  Saving model ...
Validation loss decreased (1.149631 --> 1.148099).  Saving model ...
Validation loss decreased (1.148099 --> 1.142688).  Saving model ...
Validation loss decreased (1.142688 --> 1.141948).  Saving model ...
Validation loss decreased (1.141948 --> 1.139787).  Saving model ...
Validation loss decreased (1.139787 --> 1.136243).  Saving model ...
Validation loss decreased (1.136243 --> 1.135520).  Saving model ...
Validation loss decreased (1.135520 --> 1.134357).  Saving model ...
Validation loss decreased (1.134357 --> 1.127855).  Saving model ...
Validation loss decreased (1.127855 --> 1.123666).  Saving model ...
Validation loss decreased (1.123666 --> 1.123431).  Saving model ...
Validation loss decreased (1.123431 --> 1.122418).  Saving model ...
Validation loss decreased (1.122418 --> 1.115770).  Saving model ...
Validation loss decreased (1.115770 --> 1.113271).  Saving model ...
Validation loss decreased (1.113271 --> 1.113140).  Saving model ...
Validation loss decreased (1.113140 --> 1.111595).  Saving model ...
Validation loss decreased (1.111595 --> 1.111172).  Saving model ...
Validation loss decreased (1.111172 --> 1.105888).  Saving model ...
Validation loss decreased (1.105888 --> 1.101486).  Saving model ...
EarlyStopping counter: 1 out of 5.0
Validation loss decreased (1.101486 --> 1.098090).  Saving model ...
Validation loss decreased (1.098090 --> 1.095944).  Saving model ...
EarlyStopping counter: 1 out of 5.0
Validation loss decreased (1.095944 --> 1.095060).  Saving model ...
Validation loss decreased (1.095060 --> 1.091015).  Saving model ...
Validation loss decreased (1.091015 --> 1.090735).  Saving model ...
Validation loss decreased (1.090735 --> 1.085999).  Saving model ...
EarlyStopping counter: 1 out of 5.0
EarlyStopping counter: 2 out of 5.0
EarlyStopping counter: 3 out of 5.0
EarlyStopping counter: 4 out of 5.0
Validation loss decreased (1.085999 --> 1.079641).  Saving model ...
Validation loss decreased (1.079641 --> 1.078208).  Saving model ...
EarlyStopping counter: 1 out of 5.0
EarlyStopping counter: 2 out of 5.0
EarlyStopping counter: 3 out of 5.0
EarlyStopping counter: 4 out of 5.0
Validation loss decreased (1.078208 --> 1.077796).  Saving model ...
Validation loss decreased (1.077796 --> 1.074955).  Saving model ...
EarlyStopping counter: 1 out of 5.0
EarlyStopping counter: 2 out of 5.0
EarlyStopping counter: 3 out of 5.0
Validation loss decreased (1.074955 --> 1.074259).  Saving model ...
EarlyStopping counter: 1 out of 5.0
Validation loss decreased (1.074259 --> 1.070508).  Saving model ...
EarlyStopping counter: 1 out of 5.0
EarlyStopping counter: 2 out of 5.0
EarlyStopping counter: 3 out of 5.0
EarlyStopping counter: 4 out of 5.0
Validation loss decreased (1.070508 --> 1.066958).  Saving model ...
EarlyStopping counter: 1 out of 5.0
EarlyStopping counter: 2 out of 5.0
Validation loss decreased (1.066958 --> 1.066907).  Saving model ...
Validation loss decreased (1.066907 --> 1.063555).  Saving model ...
EarlyStopping counter: 1 out of 5.0
Validation loss decreased (1.063555 --> 1.062262).  Saving model ...
Validation loss decreased (1.062262 --> 1.058367).  Saving model ...
EarlyStopping counter: 1 out of 5.0
EarlyStopping counter: 2 out of 5.0
EarlyStopping counter: 3 out of 5.0
EarlyStopping counter: 4 out of 5.0
EarlyStopping counter: 5 out of 5.0
/localscratch/yinan.29161863.0/env/lib/python3.7/site-packages/torch/nn/functional.py:1794: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.
  warnings.warn("nn.functional.tanh is deprecated. Use torch.tanh instead.")
/localscratch/yinan.29161863.0/env/lib/python3.7/site-packages/transformers/optimization.py:155: UserWarning: This overload of add_ is deprecated:
	add_(Number alpha, Tensor other)
Consider using one of the following signatures instead:
	add_(Tensor other, *, Number alpha) (Triggered internally at  ../torch/csrc/utils/python_arg_parser.cpp:1025.)
  exp_avg.mul_(beta1).add_(1.0 - beta1, grad)
wandb: Waiting for W&B process to finish, PID 158647... (success).
wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: \ 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: | 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: / 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: \ 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: | 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: / 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: \ 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: | 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: / 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb:                                                                                
wandb: Run history:
wandb:     e_F1 ▁▂▃▅▅▅▆▆▆▆▆▆▇▇▇▇▇▇▇▇▇▇▇▇██▇█████████████
wandb:   e_loss █▇▇▆▆▆▅▅▅▄▄▄▄▄▃▃▃▃▃▃▂▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁
wandb:     t_F1 ▁▁▂▃▃▃▃▅▄▅▅▅▅▆▅▆▆▆▆▆▆▆▇▆▇▇▇▇▇▇▇▇▇▇▇▇████
wandb:   t_loss ██▇▇▇▇▇▆▆▅▅▅▅▅▄▄▄▄▄▄▄▃▃▃▃▃▂▃▂▃▂▂▂▂▂▂▁▁▁▁
wandb: 
wandb: Run summary:
wandb:     e_F1 56.04683
wandb:   e_loss 1.06572
wandb:     t_F1 68.89919
wandb:   t_loss 0.80444
wandb: 
wandb: Synced 4 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Synced lucky-terrain-2: https://wandb.ai/yinanazhou/xl_512_bs_8_lr_1e06_es_5_lc_False_nr_True_sr_False_stem_True_lemma_False_repeat_1_fold_1/runs/2ch0dbcf
wandb: Find logs at: ./wandb/run-20220317_212351-2ch0dbcf/logs/debug.log
wandb: 

wandb: wandb version 0.12.11 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
2022-03-17 22:37:53.967335: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1
wandb: Tracking run with wandb version 0.12.5
wandb: Syncing run peachy-plasma-2
wandb: ⭐️ View project at https://wandb.ai/yinanazhou/xl_512_bs_8_lr_1e06_es_5_lc_False_nr_True_sr_False_stem_True_lemma_False_repeat_1_fold_2
wandb: 🚀 View run at https://wandb.ai/yinanazhou/xl_512_bs_8_lr_1e06_es_5_lc_False_nr_True_sr_False_stem_True_lemma_False_repeat_1_fold_2/runs/hzua7hht
wandb: Run data is saved locally in /project/6002780/yinan/Thesis_MER_Lyrics/lyric-emotion/wandb/run-20220317_223751-hzua7hht
wandb: Run `wandb offline` to turn off syncing.

Validation loss decreased (inf --> 1.421779).  Saving model ...
Validation loss decreased (1.421779 --> 1.408924).  Saving model ...
Validation loss decreased (1.408924 --> 1.400073).  Saving model ...
Validation loss decreased (1.400073 --> 1.393346).  Saving model ...
Validation loss decreased (1.393346 --> 1.387036).  Saving model ...
Validation loss decreased (1.387036 --> 1.382103).  Saving model ...
Validation loss decreased (1.382103 --> 1.378066).  Saving model ...
Validation loss decreased (1.378066 --> 1.374128).  Saving model ...
Validation loss decreased (1.374128 --> 1.370380).  Saving model ...
Validation loss decreased (1.370380 --> 1.366964).  Saving model ...
Validation loss decreased (1.366964 --> 1.363341).  Saving model ...
Validation loss decreased (1.363341 --> 1.360012).  Saving model ...
Validation loss decreased (1.360012 --> 1.356653).  Saving model ...
Validation loss decreased (1.356653 --> 1.353124).  Saving model ...
Validation loss decreased (1.353124 --> 1.349878).  Saving model ...
Validation loss decreased (1.349878 --> 1.346201).  Saving model ...
Validation loss decreased (1.346201 --> 1.342378).  Saving model ...
Validation loss decreased (1.342378 --> 1.338585).  Saving model ...
Validation loss decreased (1.338585 --> 1.334402).  Saving model ...
Validation loss decreased (1.334402 --> 1.330153).  Saving model ...
Validation loss decreased (1.330153 --> 1.326327).  Saving model ...
Validation loss decreased (1.326327 --> 1.322179).  Saving model ...
Validation loss decreased (1.322179 --> 1.317473).  Saving model ...
Validation loss decreased (1.317473 --> 1.312461).  Saving model ...
Validation loss decreased (1.312461 --> 1.307544).  Saving model ...
Validation loss decreased (1.307544 --> 1.301334).  Saving model ...
Validation loss decreased (1.301334 --> 1.295865).  Saving model ...
Validation loss decreased (1.295865 --> 1.289761).  Saving model ...
Validation loss decreased (1.289761 --> 1.283488).  Saving model ...
Validation loss decreased (1.283488 --> 1.277612).  Saving model ...
Validation loss decreased (1.277612 --> 1.270754).  Saving model ...
Validation loss decreased (1.270754 --> 1.263814).  Saving model ...
Validation loss decreased (1.263814 --> 1.257729).  Saving model ...
Validation loss decreased (1.257729 --> 1.249889).  Saving model ...
Validation loss decreased (1.249889 --> 1.242304).  Saving model ...
Validation loss decreased (1.242304 --> 1.234580).  Saving model ...
Validation loss decreased (1.234580 --> 1.226630).  Saving model ...
Validation loss decreased (1.226630 --> 1.219205).  Saving model ...
Validation loss decreased (1.219205 --> 1.211205).  Saving model ...
Validation loss decreased (1.211205 --> 1.204137).  Saving model ...
Validation loss decreased (1.204137 --> 1.197222).  Saving model ...
Validation loss decreased (1.197222 --> 1.190488).  Saving model ...
Validation loss decreased (1.190488 --> 1.183757).  Saving model ...
Validation loss decreased (1.183757 --> 1.177083).  Saving model ...
Validation loss decreased (1.177083 --> 1.170754).  Saving model ...
Validation loss decreased (1.170754 --> 1.164630).  Saving model ...
Validation loss decreased (1.164630 --> 1.158719).  Saving model ...
Validation loss decreased (1.158719 --> 1.153415).  Saving model ...
Validation loss decreased (1.153415 --> 1.147653).  Saving model ...
Validation loss decreased (1.147653 --> 1.142880).  Saving model ...
Validation loss decreased (1.142880 --> 1.136940).  Saving model ...
Validation loss decreased (1.136940 --> 1.132206).  Saving model ...
Validation loss decreased (1.132206 --> 1.126039).  Saving model ...
Validation loss decreased (1.126039 --> 1.120943).  Saving model ...
Validation loss decreased (1.120943 --> 1.115317).  Saving model ...
Validation loss decreased (1.115317 --> 1.110000).  Saving model ...
Validation loss decreased (1.110000 --> 1.105362).  Saving model ...
Validation loss decreased (1.105362 --> 1.100753).  Saving model ...
Validation loss decreased (1.100753 --> 1.095398).  Saving model ...
Validation loss decreased (1.095398 --> 1.092297).  Saving model ...
Validation loss decreased (1.092297 --> 1.086107).  Saving model ...
Validation loss decreased (1.086107 --> 1.083285).  Saving model ...
Validation loss decreased (1.083285 --> 1.077764).  Saving model ...
Validation loss decreased (1.077764 --> 1.073390).  Saving model ...
Validation loss decreased (1.073390 --> 1.069421).  Saving model ...
Validation loss decreased (1.069421 --> 1.063934).  Saving model ...
Validation loss decreased (1.063934 --> 1.061499).  Saving model ...
Validation loss decreased (1.061499 --> 1.056797).  Saving model ...
Validation loss decreased (1.056797 --> 1.054088).  Saving model ...
Validation loss decreased (1.054088 --> 1.050217).  Saving model ...
Validation loss decreased (1.050217 --> 1.047003).  Saving model ...
Validation loss decreased (1.047003 --> 1.045176).  Saving model ...
Validation loss decreased (1.045176 --> 1.042841).  Saving model ...
Validation loss decreased (1.042841 --> 1.038715).  Saving model ...
Validation loss decreased (1.038715 --> 1.034173).  Saving model ...
Validation loss decreased (1.034173 --> 1.031823).  Saving model ...
Validation loss decreased (1.031823 --> 1.028316).  Saving model ...
Validation loss decreased (1.028316 --> 1.025562).  Saving model ...
Validation loss decreased (1.025562 --> 1.023831).  Saving model ...
Validation loss decreased (1.023831 --> 1.021205).  Saving model ...
Validation loss decreased (1.021205 --> 1.019423).  Saving model ...
Validation loss decreased (1.019423 --> 1.016845).  Saving model ...
Validation loss decreased (1.016845 --> 1.014988).  Saving model ...
Validation loss decreased (1.014988 --> 1.012081).  Saving model ...
Validation loss decreased (1.012081 --> 1.010245).  Saving model ...
Validation loss decreased (1.010245 --> 1.008403).  Saving model ...
Validation loss decreased (1.008403 --> 1.005664).  Saving model ...
Validation loss decreased (1.005664 --> 1.004758).  Saving model ...
Validation loss decreased (1.004758 --> 1.002338).  Saving model ...
Validation loss decreased (1.002338 --> 1.000746).  Saving model ...
Validation loss decreased (1.000746 --> 0.999821).  Saving model ...
Validation loss decreased (0.999821 --> 0.998305).  Saving model ...
Validation loss decreased (0.998305 --> 0.995585).  Saving model ...
Validation loss decreased (0.995585 --> 0.994581).  Saving model ...
Validation loss decreased (0.994581 --> 0.993483).  Saving model ...
Validation loss decreased (0.993483 --> 0.991439).  Saving model ...
Validation loss decreased (0.991439 --> 0.989220).  Saving model ...
Validation loss decreased (0.989220 --> 0.987613).  Saving model ...
Validation loss decreased (0.987613 --> 0.986213).  Saving model ...
Validation loss decreased (0.986213 --> 0.985489).  Saving model ...
Validation loss decreased (0.985489 --> 0.984732).  Saving model ...
Validation loss decreased (0.984732 --> 0.983667).  Saving model ...
Validation loss decreased (0.983667 --> 0.981983).  Saving model ...
Validation loss decreased (0.981983 --> 0.981055).  Saving model ...
Validation loss decreased (0.981055 --> 0.980338).  Saving model ...
Validation loss decreased (0.980338 --> 0.980282).  Saving model ...
Validation loss decreased (0.980282 --> 0.979270).  Saving model ...
Validation loss decreased (0.979270 --> 0.976986).  Saving model ...
EarlyStopping counter: 1 out of 5.0
EarlyStopping counter: 2 out of 5.0
Validation loss decreased (0.976986 --> 0.976876).  Saving model ...
Validation loss decreased (0.976876 --> 0.974945).  Saving model ...
EarlyStopping counter: 1 out of 5.0
Validation loss decreased (0.974945 --> 0.974457).  Saving model ...
Validation loss decreased (0.974457 --> 0.974060).  Saving model ...
Validation loss decreased (0.974060 --> 0.972934).  Saving model ...
Validation loss decreased (0.972934 --> 0.971951).  Saving model ...
Validation loss decreased (0.971951 --> 0.971024).  Saving model ...
Validation loss decreased (0.971024 --> 0.970878).  Saving model ...
EarlyStopping counter: 1 out of 5.0
Validation loss decreased (0.970878 --> 0.970388).  Saving model ...
Validation loss decreased (0.970388 --> 0.969603).  Saving model ...
Validation loss decreased (0.969603 --> 0.969488).  Saving model ...
Validation loss decreased (0.969488 --> 0.968605).  Saving model ...
EarlyStopping counter: 1 out of 5.0
EarlyStopping counter: 2 out of 5.0
Validation loss decreased (0.968605 --> 0.967824).  Saving model ...
EarlyStopping counter: 1 out of 5.0
EarlyStopping counter: 2 out of 5.0
EarlyStopping counter: 3 out of 5.0
EarlyStopping counter: 4 out of 5.0
EarlyStopping counter: 5 out of 5.0
/localscratch/yinan.29161863.0/env/lib/python3.7/site-packages/torch/nn/functional.py:1794: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.
  warnings.warn("nn.functional.tanh is deprecated. Use torch.tanh instead.")
wandb: Waiting for W&B process to finish, PID 162608... (success).
wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: \ 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: | 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: / 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: \ 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: | 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: / 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: \ 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: | 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: / 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb:                                                                                
wandb: Run history:
wandb:     e_F1 ▁▂▂▄▄▅▅▅▅▆▆▆▇▇▇▇▇▇▇▇████████████████████
wandb:   e_loss ██▇▇▇▇▇▆▆▆▅▅▅▄▄▄▃▃▃▃▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:     t_F1 ▁▂▂▂▂▃▃▃▄▄▄▅▅▅▆▅▆▆▆▆▆▆▇▆▇▇▇▇▇▇██▇███████
wandb:   t_loss ██▇▇▇▇▇▇▇▆▆▆▆▆▅▅▅▅▄▄▄▄▄▃▃▃▃▃▃▂▂▂▂▂▂▁▁▁▂▁
wandb: 
wandb: Run summary:
wandb:     e_F1 57.02927
wandb:   e_loss 0.96826
wandb:     t_F1 68.61341
wandb:   t_loss 0.79563
wandb: 
wandb: Synced 4 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Synced peachy-plasma-2: https://wandb.ai/yinanazhou/xl_512_bs_8_lr_1e06_es_5_lc_False_nr_True_sr_False_stem_True_lemma_False_repeat_1_fold_2/runs/hzua7hht
wandb: Find logs at: ./wandb/run-20220317_223751-hzua7hht/logs/debug.log
wandb: 

wandb: wandb version 0.12.11 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
2022-03-18 00:02:43.762017: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1
wandb: Tracking run with wandb version 0.12.5
wandb: Syncing run vague-plasma-2
wandb: ⭐️ View project at https://wandb.ai/yinanazhou/xl_512_bs_8_lr_1e06_es_5_lc_False_nr_True_sr_False_stem_True_lemma_False_repeat_2_fold_1
wandb: 🚀 View run at https://wandb.ai/yinanazhou/xl_512_bs_8_lr_1e06_es_5_lc_False_nr_True_sr_False_stem_True_lemma_False_repeat_2_fold_1/runs/28frlutp
wandb: Run data is saved locally in /project/6002780/yinan/Thesis_MER_Lyrics/lyric-emotion/wandb/run-20220318_000241-28frlutp
wandb: Run `wandb offline` to turn off syncing.

Validation loss decreased (inf --> 1.478925).  Saving model ...
Validation loss decreased (1.478925 --> 1.441552).  Saving model ...
Validation loss decreased (1.441552 --> 1.418990).  Saving model ...
Validation loss decreased (1.418990 --> 1.404470).  Saving model ...
Validation loss decreased (1.404470 --> 1.393258).  Saving model ...
Validation loss decreased (1.393258 --> 1.384547).  Saving model ...
Validation loss decreased (1.384547 --> 1.378320).  Saving model ...
Validation loss decreased (1.378320 --> 1.373291).  Saving model ...
Validation loss decreased (1.373291 --> 1.368421).  Saving model ...
Validation loss decreased (1.368421 --> 1.363952).  Saving model ...
Validation loss decreased (1.363952 --> 1.359542).  Saving model ...
Validation loss decreased (1.359542 --> 1.355123).  Saving model ...
Validation loss decreased (1.355123 --> 1.350510).  Saving model ...
Validation loss decreased (1.350510 --> 1.345046).  Saving model ...
Validation loss decreased (1.345046 --> 1.340469).  Saving model ...
Validation loss decreased (1.340469 --> 1.335574).  Saving model ...
Validation loss decreased (1.335574 --> 1.330514).  Saving model ...
Validation loss decreased (1.330514 --> 1.325354).  Saving model ...
Validation loss decreased (1.325354 --> 1.319772).  Saving model ...
Validation loss decreased (1.319772 --> 1.314209).  Saving model ...
Validation loss decreased (1.314209 --> 1.309265).  Saving model ...
Validation loss decreased (1.309265 --> 1.302913).  Saving model ...
Validation loss decreased (1.302913 --> 1.297149).  Saving model ...
Validation loss decreased (1.297149 --> 1.290492).  Saving model ...
Validation loss decreased (1.290492 --> 1.283819).  Saving model ...
Validation loss decreased (1.283819 --> 1.279112).  Saving model ...
Validation loss decreased (1.279112 --> 1.272243).  Saving model ...
Validation loss decreased (1.272243 --> 1.265532).  Saving model ...
Validation loss decreased (1.265532 --> 1.259257).  Saving model ...
Validation loss decreased (1.259257 --> 1.252485).  Saving model ...
Validation loss decreased (1.252485 --> 1.245664).  Saving model ...
Validation loss decreased (1.245664 --> 1.237808).  Saving model ...
Validation loss decreased (1.237808 --> 1.232109).  Saving model ...
Validation loss decreased (1.232109 --> 1.226973).  Saving model ...
Validation loss decreased (1.226973 --> 1.220554).  Saving model ...
Validation loss decreased (1.220554 --> 1.213722).  Saving model ...
Validation loss decreased (1.213722 --> 1.207132).  Saving model ...
Validation loss decreased (1.207132 --> 1.201389).  Saving model ...
Validation loss decreased (1.201389 --> 1.195015).  Saving model ...
Validation loss decreased (1.195015 --> 1.187380).  Saving model ...
Validation loss decreased (1.187380 --> 1.180463).  Saving model ...
Validation loss decreased (1.180463 --> 1.174754).  Saving model ...
Validation loss decreased (1.174754 --> 1.169613).  Saving model ...
Validation loss decreased (1.169613 --> 1.164411).  Saving model ...
Validation loss decreased (1.164411 --> 1.159223).  Saving model ...
Validation loss decreased (1.159223 --> 1.153520).  Saving model ...
Validation loss decreased (1.153520 --> 1.148319).  Saving model ...
Validation loss decreased (1.148319 --> 1.144037).  Saving model ...
Validation loss decreased (1.144037 --> 1.138777).  Saving model ...
Validation loss decreased (1.138777 --> 1.132939).  Saving model ...
Validation loss decreased (1.132939 --> 1.129547).  Saving model ...
Validation loss decreased (1.129547 --> 1.125134).  Saving model ...
Validation loss decreased (1.125134 --> 1.122404).  Saving model ...
Validation loss decreased (1.122404 --> 1.118774).  Saving model ...
Validation loss decreased (1.118774 --> 1.115491).  Saving model ...
Validation loss decreased (1.115491 --> 1.110354).  Saving model ...
Validation loss decreased (1.110354 --> 1.107386).  Saving model ...
Validation loss decreased (1.107386 --> 1.103537).  Saving model ...
Validation loss decreased (1.103537 --> 1.099281).  Saving model ...
Validation loss decreased (1.099281 --> 1.095453).  Saving model ...
Validation loss decreased (1.095453 --> 1.091445).  Saving model ...
Validation loss decreased (1.091445 --> 1.087875).  Saving model ...
Validation loss decreased (1.087875 --> 1.084363).  Saving model ...
Validation loss decreased (1.084363 --> 1.081221).  Saving model ...
Validation loss decreased (1.081221 --> 1.079770).  Saving model ...
Validation loss decreased (1.079770 --> 1.077310).  Saving model ...
Validation loss decreased (1.077310 --> 1.075533).  Saving model ...
Validation loss decreased (1.075533 --> 1.071626).  Saving model ...
Validation loss decreased (1.071626 --> 1.069195).  Saving model ...
Validation loss decreased (1.069195 --> 1.068309).  Saving model ...
Validation loss decreased (1.068309 --> 1.066027).  Saving model ...
Validation loss decreased (1.066027 --> 1.064351).  Saving model ...
Validation loss decreased (1.064351 --> 1.062194).  Saving model ...
Validation loss decreased (1.062194 --> 1.060196).  Saving model ...
Validation loss decreased (1.060196 --> 1.058003).  Saving model ...
Validation loss decreased (1.058003 --> 1.056632).  Saving model ...
Validation loss decreased (1.056632 --> 1.055263).  Saving model ...
Validation loss decreased (1.055263 --> 1.050829).  Saving model ...
Validation loss decreased (1.050829 --> 1.048914).  Saving model ...
Validation loss decreased (1.048914 --> 1.048560).  Saving model ...
Validation loss decreased (1.048560 --> 1.046629).  Saving model ...
Validation loss decreased (1.046629 --> 1.045168).  Saving model ...
Validation loss decreased (1.045168 --> 1.043171).  Saving model ...
Validation loss decreased (1.043171 --> 1.040614).  Saving model ...
EarlyStopping counter: 1 out of 5.0
Validation loss decreased (1.040614 --> 1.039422).  Saving model ...
EarlyStopping counter: 1 out of 5.0
Validation loss decreased (1.039422 --> 1.038984).  Saving model ...
Validation loss decreased (1.038984 --> 1.038872).  Saving model ...
Validation loss decreased (1.038872 --> 1.036078).  Saving model ...
Validation loss decreased (1.036078 --> 1.034461).  Saving model ...
EarlyStopping counter: 1 out of 5.0
Validation loss decreased (1.034461 --> 1.034400).  Saving model ...
Validation loss decreased (1.034400 --> 1.031897).  Saving model ...
Validation loss decreased (1.031897 --> 1.030669).  Saving model ...
Validation loss decreased (1.030669 --> 1.030051).  Saving model ...
EarlyStopping counter: 1 out of 5.0
EarlyStopping counter: 2 out of 5.0
Validation loss decreased (1.030051 --> 1.028590).  Saving model ...
Validation loss decreased (1.028590 --> 1.027111).  Saving model ...
EarlyStopping counter: 1 out of 5.0
EarlyStopping counter: 2 out of 5.0
Validation loss decreased (1.027111 --> 1.026221).  Saving model ...
EarlyStopping counter: 1 out of 5.0
Validation loss decreased (1.026221 --> 1.025980).  Saving model ...
Validation loss decreased (1.025980 --> 1.025556).  Saving model ...
Validation loss decreased (1.025556 --> 1.024394).  Saving model ...
Validation loss decreased (1.024394 --> 1.024359).  Saving model ...
EarlyStopping counter: 1 out of 5.0
EarlyStopping counter: 2 out of 5.0
EarlyStopping counter: 3 out of 5.0
EarlyStopping counter: 4 out of 5.0
Validation loss decreased (1.024359 --> 1.024100).  Saving model ...
Validation loss decreased (1.024100 --> 1.023325).  Saving model ...
Validation loss decreased (1.023325 --> 1.023171).  Saving model ...
EarlyStopping counter: 1 out of 5.0
EarlyStopping counter: 2 out of 5.0
EarlyStopping counter: 3 out of 5.0
Validation loss decreased (1.023171 --> 1.023048).  Saving model ...
EarlyStopping counter: 1 out of 5.0
EarlyStopping counter: 2 out of 5.0
EarlyStopping counter: 3 out of 5.0
Validation loss decreased (1.023048 --> 1.022973).  Saving model ...
EarlyStopping counter: 1 out of 5.0
EarlyStopping counter: 2 out of 5.0
EarlyStopping counter: 3 out of 5.0
EarlyStopping counter: 4 out of 5.0
EarlyStopping counter: 5 out of 5.0
/localscratch/yinan.29161863.0/env/lib/python3.7/site-packages/torch/nn/functional.py:1794: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.
  warnings.warn("nn.functional.tanh is deprecated. Use torch.tanh instead.")
wandb: Waiting for W&B process to finish, PID 167175... (success).
wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: \ 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: | 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: / 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: \ 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: | 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: / 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: \ 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: | 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: / 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb:                                                                                
wandb: Run history:
wandb:     e_F1 ▁▁▄▅▅▆▆▆▆▆▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇█▇█████████████
wandb:   e_loss █▇▇▇▆▆▆▅▅▅▄▄▄▃▃▃▃▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:     t_F1 ▁▁▂▂▄▃▃▃▄▅▅▅▆▆▆▆▆▆▇▇▇▇▇▇▇▇▇▇▇█▇▇████████
wandb:   t_loss ██▇▇▇▇▆▆▆▆▅▅▅▄▄▄▄▄▄▃▃▃▃▃▃▃▂▂▂▂▂▂▁▁▂▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:     e_F1 53.91599
wandb:   e_loss 1.02378
wandb:     t_F1 68.0254
wandb:   t_loss 0.80066
wandb: 
wandb: Synced 4 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Synced vague-plasma-2: https://wandb.ai/yinanazhou/xl_512_bs_8_lr_1e06_es_5_lc_False_nr_True_sr_False_stem_True_lemma_False_repeat_2_fold_1/runs/28frlutp
wandb: Find logs at: ./wandb/run-20220318_000241-28frlutp/logs/debug.log
wandb: 

wandb: wandb version 0.12.11 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
2022-03-18 01:27:45.614191: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1
wandb: Tracking run with wandb version 0.12.5
wandb: Syncing run denim-sky-2
wandb: ⭐️ View project at https://wandb.ai/yinanazhou/xl_512_bs_8_lr_1e06_es_5_lc_False_nr_True_sr_False_stem_True_lemma_False_repeat_2_fold_2
wandb: 🚀 View run at https://wandb.ai/yinanazhou/xl_512_bs_8_lr_1e06_es_5_lc_False_nr_True_sr_False_stem_True_lemma_False_repeat_2_fold_2/runs/85q384yo
wandb: Run data is saved locally in /project/6002780/yinan/Thesis_MER_Lyrics/lyric-emotion/wandb/run-20220318_012743-85q384yo
wandb: Run `wandb offline` to turn off syncing.

Validation loss decreased (inf --> 1.385684).  Saving model ...
Validation loss decreased (1.385684 --> 1.380074).  Saving model ...
Validation loss decreased (1.380074 --> 1.375424).  Saving model ...
Validation loss decreased (1.375424 --> 1.371193).  Saving model ...
Validation loss decreased (1.371193 --> 1.367535).  Saving model ...
Validation loss decreased (1.367535 --> 1.363611).  Saving model ...
Validation loss decreased (1.363611 --> 1.359614).  Saving model ...
Validation loss decreased (1.359614 --> 1.356001).  Saving model ...
Validation loss decreased (1.356001 --> 1.352773).  Saving model ...
Validation loss decreased (1.352773 --> 1.348948).  Saving model ...
Validation loss decreased (1.348948 --> 1.345694).  Saving model ...
Validation loss decreased (1.345694 --> 1.342181).  Saving model ...
Validation loss decreased (1.342181 --> 1.338623).  Saving model ...
Validation loss decreased (1.338623 --> 1.334708).  Saving model ...
Validation loss decreased (1.334708 --> 1.330876).  Saving model ...
Validation loss decreased (1.330876 --> 1.326855).  Saving model ...
Validation loss decreased (1.326855 --> 1.322827).  Saving model ...
Validation loss decreased (1.322827 --> 1.317642).  Saving model ...
Validation loss decreased (1.317642 --> 1.313299).  Saving model ...
Validation loss decreased (1.313299 --> 1.308673).  Saving model ...
Validation loss decreased (1.308673 --> 1.303717).  Saving model ...
Validation loss decreased (1.303717 --> 1.298494).  Saving model ...
Validation loss decreased (1.298494 --> 1.292969).  Saving model ...
Validation loss decreased (1.292969 --> 1.288833).  Saving model ...
Validation loss decreased (1.288833 --> 1.283357).  Saving model ...
Validation loss decreased (1.283357 --> 1.277577).  Saving model ...
Validation loss decreased (1.277577 --> 1.270995).  Saving model ...
Validation loss decreased (1.270995 --> 1.264733).  Saving model ...
Validation loss decreased (1.264733 --> 1.258597).  Saving model ...
Validation loss decreased (1.258597 --> 1.252677).  Saving model ...
Validation loss decreased (1.252677 --> 1.247310).  Saving model ...
Validation loss decreased (1.247310 --> 1.241276).  Saving model ...
Validation loss decreased (1.241276 --> 1.234700).  Saving model ...
Validation loss decreased (1.234700 --> 1.228770).  Saving model ...
Validation loss decreased (1.228770 --> 1.222288).  Saving model ...
Validation loss decreased (1.222288 --> 1.216857).  Saving model ...
Validation loss decreased (1.216857 --> 1.211398).  Saving model ...
Validation loss decreased (1.211398 --> 1.204154).  Saving model ...
Validation loss decreased (1.204154 --> 1.198657).  Saving model ...
Validation loss decreased (1.198657 --> 1.192536).  Saving model ...
Validation loss decreased (1.192536 --> 1.187171).  Saving model ...
Validation loss decreased (1.187171 --> 1.181531).  Saving model ...
Validation loss decreased (1.181531 --> 1.175692).  Saving model ...
Validation loss decreased (1.175692 --> 1.169311).  Saving model ...
Validation loss decreased (1.169311 --> 1.165559).  Saving model ...
Validation loss decreased (1.165559 --> 1.160296).  Saving model ...
Validation loss decreased (1.160296 --> 1.154641).  Saving model ...
Validation loss decreased (1.154641 --> 1.149570).  Saving model ...
Validation loss decreased (1.149570 --> 1.144259).  Saving model ...
Validation loss decreased (1.144259 --> 1.136208).  Saving model ...
Validation loss decreased (1.136208 --> 1.131141).  Saving model ...
Validation loss decreased (1.131141 --> 1.125359).  Saving model ...
Validation loss decreased (1.125359 --> 1.120826).  Saving model ...
Validation loss decreased (1.120826 --> 1.116157).  Saving model ...
Validation loss decreased (1.116157 --> 1.109849).  Saving model ...
Validation loss decreased (1.109849 --> 1.104570).  Saving model ...
Validation loss decreased (1.104570 --> 1.099769).  Saving model ...
Validation loss decreased (1.099769 --> 1.097342).  Saving model ...
Validation loss decreased (1.097342 --> 1.092485).  Saving model ...
Validation loss decreased (1.092485 --> 1.086824).  Saving model ...
Validation loss decreased (1.086824 --> 1.081904).  Saving model ...
Validation loss decreased (1.081904 --> 1.079049).  Saving model ...
Validation loss decreased (1.079049 --> 1.074623).  Saving model ...
Validation loss decreased (1.074623 --> 1.070929).  Saving model ...
Validation loss decreased (1.070929 --> 1.070112).  Saving model ...
Validation loss decreased (1.070112 --> 1.062460).  Saving model ...
Validation loss decreased (1.062460 --> 1.059486).  Saving model ...
Validation loss decreased (1.059486 --> 1.056048).  Saving model ...
Validation loss decreased (1.056048 --> 1.055109).  Saving model ...
Validation loss decreased (1.055109 --> 1.050823).  Saving model ...
Validation loss decreased (1.050823 --> 1.046185).  Saving model ...
Validation loss decreased (1.046185 --> 1.043805).  Saving model ...
Validation loss decreased (1.043805 --> 1.039627).  Saving model ...
Validation loss decreased (1.039627 --> 1.037538).  Saving model ...
Validation loss decreased (1.037538 --> 1.034148).  Saving model ...
Validation loss decreased (1.034148 --> 1.030002).  Saving model ...
Validation loss decreased (1.030002 --> 1.027011).  Saving model ...
Validation loss decreased (1.027011 --> 1.024235).  Saving model ...
Validation loss decreased (1.024235 --> 1.020598).  Saving model ...
Validation loss decreased (1.020598 --> 1.019498).  Saving model ...
Validation loss decreased (1.019498 --> 1.016868).  Saving model ...
Validation loss decreased (1.016868 --> 1.013012).  Saving model ...
Validation loss decreased (1.013012 --> 1.008307).  Saving model ...
Validation loss decreased (1.008307 --> 1.004606).  Saving model ...
EarlyStopping counter: 1 out of 5.0
Validation loss decreased (1.004606 --> 1.001966).  Saving model ...
Validation loss decreased (1.001966 --> 1.001818).  Saving model ...
Validation loss decreased (1.001818 --> 1.001230).  Saving model ...
Validation loss decreased (1.001230 --> 0.997509).  Saving model ...
Validation loss decreased (0.997509 --> 0.994190).  Saving model ...
Validation loss decreased (0.994190 --> 0.993185).  Saving model ...
Validation loss decreased (0.993185 --> 0.989953).  Saving model ...
Validation loss decreased (0.989953 --> 0.987845).  Saving model ...
Validation loss decreased (0.987845 --> 0.986188).  Saving model ...
Validation loss decreased (0.986188 --> 0.983901).  Saving model ...
Validation loss decreased (0.983901 --> 0.980336).  Saving model ...
Validation loss decreased (0.980336 --> 0.977864).  Saving model ...
EarlyStopping counter: 1 out of 5.0
EarlyStopping counter: 2 out of 5.0
Validation loss decreased (0.977864 --> 0.977254).  Saving model ...
Validation loss decreased (0.977254 --> 0.973265).  Saving model ...
Validation loss decreased (0.973265 --> 0.972066).  Saving model ...
Validation loss decreased (0.972066 --> 0.971981).  Saving model ...
Validation loss decreased (0.971981 --> 0.971369).  Saving model ...
EarlyStopping counter: 1 out of 5.0
Validation loss decreased (0.971369 --> 0.970032).  Saving model ...
EarlyStopping counter: 1 out of 5.0
Validation loss decreased (0.970032 --> 0.965429).  Saving model ...
EarlyStopping counter: 1 out of 5.0
Validation loss decreased (0.965429 --> 0.965162).  Saving model ...
Validation loss decreased (0.965162 --> 0.961536).  Saving model ...
Validation loss decreased (0.961536 --> 0.960549).  Saving model ...
EarlyStopping counter: 1 out of 5.0
Validation loss decreased (0.960549 --> 0.957360).  Saving model ...
Validation loss decreased (0.957360 --> 0.956878).  Saving model ...
Validation loss decreased (0.956878 --> 0.956328).  Saving model ...
Validation loss decreased (0.956328 --> 0.954878).  Saving model ...
EarlyStopping counter: 1 out of 5.0
EarlyStopping counter: 2 out of 5.0
Validation loss decreased (0.954878 --> 0.952636).  Saving model ...
Validation loss decreased (0.952636 --> 0.951972).  Saving model ...
Validation loss decreased (0.951972 --> 0.950713).  Saving model ...
Validation loss decreased (0.950713 --> 0.950154).  Saving model ...
Validation loss decreased (0.950154 --> 0.949522).  Saving model ...
EarlyStopping counter: 1 out of 5.0
EarlyStopping counter: 2 out of 5.0
EarlyStopping counter: 3 out of 5.0
Validation loss decreased (0.949522 --> 0.949000).  Saving model ...
Validation loss decreased (0.949000 --> 0.947036).  Saving model ...
EarlyStopping counter: 1 out of 5.0
Validation loss decreased (0.947036 --> 0.945280).  Saving model ...
Validation loss decreased (0.945280 --> 0.944420).  Saving model ...
EarlyStopping counter: 1 out of 5.0
EarlyStopping counter: 2 out of 5.0
Validation loss decreased (0.944420 --> 0.944321).  Saving model ...
Validation loss decreased (0.944321 --> 0.943739).  Saving model ...
Validation loss decreased (0.943739 --> 0.942881).  Saving model ...
EarlyStopping counter: 1 out of 5.0
EarlyStopping counter: 2 out of 5.0
EarlyStopping counter: 3 out of 5.0
Validation loss decreased (0.942881 --> 0.942622).  Saving model ...
EarlyStopping counter: 1 out of 5.0
EarlyStopping counter: 2 out of 5.0
EarlyStopping counter: 3 out of 5.0
Validation loss decreased (0.942622 --> 0.942079).  Saving model ...
Validation loss decreased (0.942079 --> 0.940095).  Saving model ...
EarlyStopping counter: 1 out of 5.0
EarlyStopping counter: 2 out of 5.0
EarlyStopping counter: 3 out of 5.0
EarlyStopping counter: 4 out of 5.0
EarlyStopping counter: 5 out of 5.0
/localscratch/yinan.29161863.0/env/lib/python3.7/site-packages/torch/nn/functional.py:1794: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.
  warnings.warn("nn.functional.tanh is deprecated. Use torch.tanh instead.")
wandb: Waiting for W&B process to finish, PID 171781... (success).
wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: \ 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: | 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: / 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: \ 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: | 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: / 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: \ 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: | 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: / 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb:                                                                                
wandb: Run history:
wandb:     e_F1 ▁▂▃▄▅▅▅▅▅▆▆▆▆▆▆▆▆▇▇▇▇▇▇▇▇▇▇▇████████████
wandb:   e_loss ███▇▇▇▇▆▆▅▅▅▅▄▄▄▃▃▃▃▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:     t_F1 ▁▁▂▂▃▃▃▄▄▄▄▅▅▆▅▆▆▆▆▆▆▇▆▇▇▇▇▇▇▇▇▇█▇▇██▇██
wandb:   t_loss █████▇▇▇▇▆▆▆▅▅▅▅▄▄▄▄▄▃▃▃▃▃▃▃▃▂▂▂▂▂▂▂▁▁▁▁
wandb: 
wandb: Run summary:
wandb:     e_F1 61.60009
wandb:   e_loss 0.9425
wandb:     t_F1 70.37022
wandb:   t_loss 0.75017
wandb: 
wandb: Synced 4 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Synced denim-sky-2: https://wandb.ai/yinanazhou/xl_512_bs_8_lr_1e06_es_5_lc_False_nr_True_sr_False_stem_True_lemma_False_repeat_2_fold_2/runs/85q384yo
wandb: Find logs at: ./wandb/run-20220318_012743-85q384yo/logs/debug.log
wandb: 

wandb: wandb version 0.12.11 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
2022-03-18 03:07:39.709929: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1
wandb: Tracking run with wandb version 0.12.5
wandb: Syncing run misty-frost-2
wandb: ⭐️ View project at https://wandb.ai/yinanazhou/xl_512_bs_8_lr_1e06_es_5_lc_False_nr_True_sr_False_stem_True_lemma_False_repeat_3_fold_1
wandb: 🚀 View run at https://wandb.ai/yinanazhou/xl_512_bs_8_lr_1e06_es_5_lc_False_nr_True_sr_False_stem_True_lemma_False_repeat_3_fold_1/runs/39yjwb93
wandb: Run data is saved locally in /project/6002780/yinan/Thesis_MER_Lyrics/lyric-emotion/wandb/run-20220318_030737-39yjwb93
wandb: Run `wandb offline` to turn off syncing.

Validation loss decreased (inf --> 1.487568).  Saving model ...
Validation loss decreased (1.487568 --> 1.454625).  Saving model ...
Validation loss decreased (1.454625 --> 1.430781).  Saving model ...
Validation loss decreased (1.430781 --> 1.413889).  Saving model ...
Validation loss decreased (1.413889 --> 1.400889).  Saving model ...
Validation loss decreased (1.400889 --> 1.390851).  Saving model ...
Validation loss decreased (1.390851 --> 1.384020).  Saving model ...
Validation loss decreased (1.384020 --> 1.378856).  Saving model ...
Validation loss decreased (1.378856 --> 1.374124).  Saving model ...
Validation loss decreased (1.374124 --> 1.369920).  Saving model ...
Validation loss decreased (1.369920 --> 1.365053).  Saving model ...
Validation loss decreased (1.365053 --> 1.359904).  Saving model ...
Validation loss decreased (1.359904 --> 1.354275).  Saving model ...
Validation loss decreased (1.354275 --> 1.348577).  Saving model ...
Validation loss decreased (1.348577 --> 1.341651).  Saving model ...
Validation loss decreased (1.341651 --> 1.334820).  Saving model ...
Validation loss decreased (1.334820 --> 1.327752).  Saving model ...
Validation loss decreased (1.327752 --> 1.320446).  Saving model ...
Validation loss decreased (1.320446 --> 1.312859).  Saving model ...
Validation loss decreased (1.312859 --> 1.304836).  Saving model ...
Validation loss decreased (1.304836 --> 1.297277).  Saving model ...
Validation loss decreased (1.297277 --> 1.291699).  Saving model ...
Validation loss decreased (1.291699 --> 1.283102).  Saving model ...
Validation loss decreased (1.283102 --> 1.275101).  Saving model ...
Validation loss decreased (1.275101 --> 1.266409).  Saving model ...
Validation loss decreased (1.266409 --> 1.259272).  Saving model ...
Validation loss decreased (1.259272 --> 1.252551).  Saving model ...
Validation loss decreased (1.252551 --> 1.246251).  Saving model ...
Validation loss decreased (1.246251 --> 1.238934).  Saving model ...
Validation loss decreased (1.238934 --> 1.230699).  Saving model ...
Validation loss decreased (1.230699 --> 1.224205).  Saving model ...
Validation loss decreased (1.224205 --> 1.219045).  Saving model ...
Validation loss decreased (1.219045 --> 1.212770).  Saving model ...
Validation loss decreased (1.212770 --> 1.208287).  Saving model ...
Validation loss decreased (1.208287 --> 1.201965).  Saving model ...
Validation loss decreased (1.201965 --> 1.196459).  Saving model ...
Validation loss decreased (1.196459 --> 1.191049).  Saving model ...
Validation loss decreased (1.191049 --> 1.186399).  Saving model ...
Validation loss decreased (1.186399 --> 1.180315).  Saving model ...
Validation loss decreased (1.180315 --> 1.175349).  Saving model ...
Validation loss decreased (1.175349 --> 1.170457).  Saving model ...
Validation loss decreased (1.170457 --> 1.167551).  Saving model ...
Validation loss decreased (1.167551 --> 1.163477).  Saving model ...
Validation loss decreased (1.163477 --> 1.154420).  Saving model ...
Validation loss decreased (1.154420 --> 1.150489).  Saving model ...
Validation loss decreased (1.150489 --> 1.146173).  Saving model ...
Validation loss decreased (1.146173 --> 1.141323).  Saving model ...
Validation loss decreased (1.141323 --> 1.136404).  Saving model ...
Validation loss decreased (1.136404 --> 1.133972).  Saving model ...
Validation loss decreased (1.133972 --> 1.126680).  Saving model ...
Validation loss decreased (1.126680 --> 1.122913).  Saving model ...
Validation loss decreased (1.122913 --> 1.120036).  Saving model ...
Validation loss decreased (1.120036 --> 1.116582).  Saving model ...
Validation loss decreased (1.116582 --> 1.113235).  Saving model ...
Validation loss decreased (1.113235 --> 1.108694).  Saving model ...
Validation loss decreased (1.108694 --> 1.104649).  Saving model ...
Validation loss decreased (1.104649 --> 1.102048).  Saving model ...
Validation loss decreased (1.102048 --> 1.098281).  Saving model ...
Validation loss decreased (1.098281 --> 1.091632).  Saving model ...
Validation loss decreased (1.091632 --> 1.088734).  Saving model ...
Validation loss decreased (1.088734 --> 1.086066).  Saving model ...
Validation loss decreased (1.086066 --> 1.084426).  Saving model ...
Validation loss decreased (1.084426 --> 1.079009).  Saving model ...
Validation loss decreased (1.079009 --> 1.077223).  Saving model ...
Validation loss decreased (1.077223 --> 1.076784).  Saving model ...
Validation loss decreased (1.076784 --> 1.072096).  Saving model ...
Validation loss decreased (1.072096 --> 1.068384).  Saving model ...
Validation loss decreased (1.068384 --> 1.064741).  Saving model ...
Validation loss decreased (1.064741 --> 1.061218).  Saving model ...
Validation loss decreased (1.061218 --> 1.060685).  Saving model ...
Validation loss decreased (1.060685 --> 1.055025).  Saving model ...
EarlyStopping counter: 1 out of 5.0
Validation loss decreased (1.055025 --> 1.053748).  Saving model ...
Validation loss decreased (1.053748 --> 1.050671).  Saving model ...
Validation loss decreased (1.050671 --> 1.047918).  Saving model ...
Validation loss decreased (1.047918 --> 1.047704).  Saving model ...
Validation loss decreased (1.047704 --> 1.046419).  Saving model ...
Validation loss decreased (1.046419 --> 1.045214).  Saving model ...
Validation loss decreased (1.045214 --> 1.040013).  Saving model ...
Validation loss decreased (1.040013 --> 1.037747).  Saving model ...
Validation loss decreased (1.037747 --> 1.034213).  Saving model ...
Validation loss decreased (1.034213 --> 1.033030).  Saving model ...
Validation loss decreased (1.033030 --> 1.032819).  Saving model ...
Validation loss decreased (1.032819 --> 1.030299).  Saving model ...
Validation loss decreased (1.030299 --> 1.027993).  Saving model ...
Validation loss decreased (1.027993 --> 1.026857).  Saving model ...
EarlyStopping counter: 1 out of 5.0
Validation loss decreased (1.026857 --> 1.023660).  Saving model ...
Validation loss decreased (1.023660 --> 1.022381).  Saving model ...
Validation loss decreased (1.022381 --> 1.020047).  Saving model ...
Validation loss decreased (1.020047 --> 1.017881).  Saving model ...
Validation loss decreased (1.017881 --> 1.015400).  Saving model ...
Validation loss decreased (1.015400 --> 1.014483).  Saving model ...
EarlyStopping counter: 1 out of 5.0
EarlyStopping counter: 2 out of 5.0
EarlyStopping counter: 3 out of 5.0
Validation loss decreased (1.014483 --> 1.012074).  Saving model ...
Validation loss decreased (1.012074 --> 1.011659).  Saving model ...
Validation loss decreased (1.011659 --> 1.010791).  Saving model ...
Validation loss decreased (1.010791 --> 1.010117).  Saving model ...
Validation loss decreased (1.010117 --> 1.005296).  Saving model ...
EarlyStopping counter: 1 out of 5.0
Validation loss decreased (1.005296 --> 1.003957).  Saving model ...
Validation loss decreased (1.003957 --> 1.001243).  Saving model ...
EarlyStopping counter: 1 out of 5.0
EarlyStopping counter: 2 out of 5.0
EarlyStopping counter: 3 out of 5.0
EarlyStopping counter: 4 out of 5.0
EarlyStopping counter: 5 out of 5.0
/localscratch/yinan.29161863.0/env/lib/python3.7/site-packages/torch/nn/functional.py:1794: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.
  warnings.warn("nn.functional.tanh is deprecated. Use torch.tanh instead.")
wandb: Waiting for W&B process to finish, PID 177236... (success).
wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: \ 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: | 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: / 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: \ 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: | 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: / 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: \ 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: | 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: / 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb:                                                                                
wandb: Run history:
wandb:     e_F1 ▁▂▃▄▄▄▄▄▅▅▅▆▆▆▆▇▇▇▇▇▇▇▇▇▇▇▇█▇███████████
wandb:   e_loss █▇▇▆▆▆▆▅▅▅▅▄▄▄▄▃▃▃▃▃▂▂▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁
wandb:     t_F1 ▁▁▂▂▃▃▄▄▄▄▅▅▅▅▅▅▆▅▆▆▆▆▆▇▇▇▇▇▇▇▇▇▇▇█▇▇█▇▇
wandb:   t_loss ██▇▇▇▆▆▆▆▆▅▅▅▅▅▅▄▄▄▄▄▃▃▃▃▃▃▃▃▂▂▂▂▂▁▁▁▁▂▁
wandb: 
wandb: Run summary:
wandb:     e_F1 57.23842
wandb:   e_loss 1.00591
wandb:     t_F1 63.68316
wandb:   t_loss 0.83879
wandb: 
wandb: Synced 4 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Synced misty-frost-2: https://wandb.ai/yinanazhou/xl_512_bs_8_lr_1e06_es_5_lc_False_nr_True_sr_False_stem_True_lemma_False_repeat_3_fold_1/runs/39yjwb93
wandb: Find logs at: ./wandb/run-20220318_030737-39yjwb93/logs/debug.log
wandb: 

wandb: wandb version 0.12.11 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
2022-03-18 04:19:57.888992: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1
wandb: Tracking run with wandb version 0.12.5
wandb: Syncing run breezy-grass-2
wandb: ⭐️ View project at https://wandb.ai/yinanazhou/xl_512_bs_8_lr_1e06_es_5_lc_False_nr_True_sr_False_stem_True_lemma_False_repeat_3_fold_2
wandb: 🚀 View run at https://wandb.ai/yinanazhou/xl_512_bs_8_lr_1e06_es_5_lc_False_nr_True_sr_False_stem_True_lemma_False_repeat_3_fold_2/runs/2do2qmh3
wandb: Run data is saved locally in /project/6002780/yinan/Thesis_MER_Lyrics/lyric-emotion/wandb/run-20220318_041955-2do2qmh3
wandb: Run `wandb offline` to turn off syncing.

Validation loss decreased (inf --> 1.429595).  Saving model ...
Validation loss decreased (1.429595 --> 1.409374).  Saving model ...
Validation loss decreased (1.409374 --> 1.394859).  Saving model ...
Validation loss decreased (1.394859 --> 1.384472).  Saving model ...
Validation loss decreased (1.384472 --> 1.376553).  Saving model ...
Validation loss decreased (1.376553 --> 1.370888).  Saving model ...
Validation loss decreased (1.370888 --> 1.365997).  Saving model ...
Validation loss decreased (1.365997 --> 1.361194).  Saving model ...
Validation loss decreased (1.361194 --> 1.356566).  Saving model ...
Validation loss decreased (1.356566 --> 1.352201).  Saving model ...
Validation loss decreased (1.352201 --> 1.347339).  Saving model ...
Validation loss decreased (1.347339 --> 1.342430).  Saving model ...
Validation loss decreased (1.342430 --> 1.337870).  Saving model ...
Validation loss decreased (1.337870 --> 1.333488).  Saving model ...
Validation loss decreased (1.333488 --> 1.328176).  Saving model ...
Validation loss decreased (1.328176 --> 1.321734).  Saving model ...
Validation loss decreased (1.321734 --> 1.315302).  Saving model ...
Validation loss decreased (1.315302 --> 1.309757).  Saving model ...
Validation loss decreased (1.309757 --> 1.303231).  Saving model ...
Validation loss decreased (1.303231 --> 1.296989).  Saving model ...
Validation loss decreased (1.296989 --> 1.290428).  Saving model ...
Validation loss decreased (1.290428 --> 1.283375).  Saving model ...
Validation loss decreased (1.283375 --> 1.276234).  Saving model ...
Validation loss decreased (1.276234 --> 1.270121).  Saving model ...
Validation loss decreased (1.270121 --> 1.262974).  Saving model ...
Validation loss decreased (1.262974 --> 1.255357).  Saving model ...
Validation loss decreased (1.255357 --> 1.247899).  Saving model ...
Validation loss decreased (1.247899 --> 1.241228).  Saving model ...
Validation loss decreased (1.241228 --> 1.235483).  Saving model ...
Validation loss decreased (1.235483 --> 1.229551).  Saving model ...
Validation loss decreased (1.229551 --> 1.223032).  Saving model ...
Validation loss decreased (1.223032 --> 1.217404).  Saving model ...
Validation loss decreased (1.217404 --> 1.210639).  Saving model ...
Validation loss decreased (1.210639 --> 1.204548).  Saving model ...
Validation loss decreased (1.204548 --> 1.198773).  Saving model ...
Validation loss decreased (1.198773 --> 1.193874).  Saving model ...
Validation loss decreased (1.193874 --> 1.188034).  Saving model ...
Validation loss decreased (1.188034 --> 1.181082).  Saving model ...
Validation loss decreased (1.181082 --> 1.175293).  Saving model ...
Validation loss decreased (1.175293 --> 1.168390).  Saving model ...
Validation loss decreased (1.168390 --> 1.163053).  Saving model ...
Validation loss decreased (1.163053 --> 1.158444).  Saving model ...
Validation loss decreased (1.158444 --> 1.154140).  Saving model ...
Validation loss decreased (1.154140 --> 1.149769).  Saving model ...
Validation loss decreased (1.149769 --> 1.144087).  Saving model ...
Validation loss decreased (1.144087 --> 1.138107).  Saving model ...
Validation loss decreased (1.138107 --> 1.132994).  Saving model ...
Validation loss decreased (1.132994 --> 1.128024).  Saving model ...
Validation loss decreased (1.128024 --> 1.124252).  Saving model ...
Validation loss decreased (1.124252 --> 1.118289).  Saving model ...
Validation loss decreased (1.118289 --> 1.114289).  Saving model ...
Validation loss decreased (1.114289 --> 1.110173).  Saving model ...
Validation loss decreased (1.110173 --> 1.104984).  Saving model ...
Validation loss decreased (1.104984 --> 1.102053).  Saving model ...
Validation loss decreased (1.102053 --> 1.095193).  Saving model ...
Validation loss decreased (1.095193 --> 1.091680).  Saving model ...
Validation loss decreased (1.091680 --> 1.087193).  Saving model ...
Validation loss decreased (1.087193 --> 1.083042).  Saving model ...
Validation loss decreased (1.083042 --> 1.079668).  Saving model ...
Validation loss decreased (1.079668 --> 1.075082).  Saving model ...
Validation loss decreased (1.075082 --> 1.070900).  Saving model ...
Validation loss decreased (1.070900 --> 1.068866).  Saving model ...
Validation loss decreased (1.068866 --> 1.066950).  Saving model ...
Validation loss decreased (1.066950 --> 1.060567).  Saving model ...
Validation loss decreased (1.060567 --> 1.056255).  Saving model ...
Validation loss decreased (1.056255 --> 1.052602).  Saving model ...
Validation loss decreased (1.052602 --> 1.049171).  Saving model ...
Validation loss decreased (1.049171 --> 1.045800).  Saving model ...
Validation loss decreased (1.045800 --> 1.044539).  Saving model ...
Validation loss decreased (1.044539 --> 1.041130).  Saving model ...
Validation loss decreased (1.041130 --> 1.036378).  Saving model ...
Validation loss decreased (1.036378 --> 1.032805).  Saving model ...
Validation loss decreased (1.032805 --> 1.030309).  Saving model ...
Validation loss decreased (1.030309 --> 1.028744).  Saving model ...
Validation loss decreased (1.028744 --> 1.026488).  Saving model ...
Validation loss decreased (1.026488 --> 1.025212).  Saving model ...
Validation loss decreased (1.025212 --> 1.020358).  Saving model ...
Validation loss decreased (1.020358 --> 1.017377).  Saving model ...
Validation loss decreased (1.017377 --> 1.015896).  Saving model ...
Validation loss decreased (1.015896 --> 1.014887).  Saving model ...
Validation loss decreased (1.014887 --> 1.012100).  Saving model ...
Validation loss decreased (1.012100 --> 1.008070).  Saving model ...
Validation loss decreased (1.008070 --> 1.005441).  Saving model ...
Validation loss decreased (1.005441 --> 1.004854).  Saving model ...
Validation loss decreased (1.004854 --> 1.002507).  Saving model ...
Validation loss decreased (1.002507 --> 0.999377).  Saving model ...
Validation loss decreased (0.999377 --> 0.997423).  Saving model ...
EarlyStopping counter: 1 out of 5.0
Validation loss decreased (0.997423 --> 0.994749).  Saving model ...
Validation loss decreased (0.994749 --> 0.991109).  Saving model ...
Validation loss decreased (0.991109 --> 0.988751).  Saving model ...
Validation loss decreased (0.988751 --> 0.987151).  Saving model ...
Validation loss decreased (0.987151 --> 0.984269).  Saving model ...
Validation loss decreased (0.984269 --> 0.983687).  Saving model ...
Validation loss decreased (0.983687 --> 0.983049).  Saving model ...
Validation loss decreased (0.983049 --> 0.981637).  Saving model ...
Validation loss decreased (0.981637 --> 0.979334).  Saving model ...
Validation loss decreased (0.979334 --> 0.978353).  Saving model ...
Validation loss decreased (0.978353 --> 0.976902).  Saving model ...
Validation loss decreased (0.976902 --> 0.974513).  Saving model ...
Validation loss decreased (0.974513 --> 0.973262).  Saving model ...
EarlyStopping counter: 1 out of 5.0
Validation loss decreased (0.973262 --> 0.971987).  Saving model ...
Validation loss decreased (0.971987 --> 0.970016).  Saving model ...
Validation loss decreased (0.970016 --> 0.968609).  Saving model ...
Validation loss decreased (0.968609 --> 0.966889).  Saving model ...
Validation loss decreased (0.966889 --> 0.964589).  Saving model ...
Validation loss decreased (0.964589 --> 0.963385).  Saving model ...
Validation loss decreased (0.963385 --> 0.961687).  Saving model ...
Validation loss decreased (0.961687 --> 0.961340).  Saving model ...
EarlyStopping counter: 1 out of 5.0
Validation loss decreased (0.961340 --> 0.960133).  Saving model ...
Validation loss decreased (0.960133 --> 0.959515).  Saving model ...
Validation loss decreased (0.959515 --> 0.958052).  Saving model ...
EarlyStopping counter: 1 out of 5.0
EarlyStopping counter: 2 out of 5.0
Validation loss decreased (0.958052 --> 0.957388).  Saving model ...
Validation loss decreased (0.957388 --> 0.954861).  Saving model ...
Validation loss decreased (0.954861 --> 0.953604).  Saving model ...
Validation loss decreased (0.953604 --> 0.953379).  Saving model ...
Validation loss decreased (0.953379 --> 0.953018).  Saving model ...
Validation loss decreased (0.953018 --> 0.952626).  Saving model ...
Validation loss decreased (0.952626 --> 0.952185).  Saving model ...
Validation loss decreased (0.952185 --> 0.950760).  Saving model ...
Validation loss decreased (0.950760 --> 0.949944).  Saving model ...
EarlyStopping counter: 1 out of 5.0
EarlyStopping counter: 2 out of 5.0
EarlyStopping counter: 3 out of 5.0
EarlyStopping counter: 4 out of 5.0
EarlyStopping counter: 5 out of 5.0
/localscratch/yinan.29161863.0/env/lib/python3.7/site-packages/torch/nn/functional.py:1794: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.
  warnings.warn("nn.functional.tanh is deprecated. Use torch.tanh instead.")
wandb: Waiting for W&B process to finish, PID 181114... (success).
wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: \ 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: | 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: / 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: \ 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: | 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: / 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: \ 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: | 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: / 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb:                                                                                
wandb: Run history:
wandb:     e_F1 ▁▂▄▄▅▅▅▅▆▆▆▆▆▆▆▇▇▇▇▇▇▇▇▇▇▇▇▇████████████
wandb:   e_loss ██▇▇▇▆▆▆▅▅▅▅▄▄▄▄▃▃▃▃▃▂▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁
wandb:     t_F1 ▁▂▂▃▃▄▄▅▄▅▅▅▅▆▆▅▆▆▆▇▇▆▇▇▇▇▇▇▇▇▇█▇▇▇█████
wandb:   t_loss ███▇▇▇▇▆▆▆▆▅▅▅▅▅▄▄▄▃▃▃▃▃▃▃▃▂▂▂▂▂▂▂▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:     e_F1 60.82344
wandb:   e_loss 0.95125
wandb:     t_F1 70.24928
wandb:   t_loss 0.80563
wandb: 
wandb: Synced 4 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Synced breezy-grass-2: https://wandb.ai/yinanazhou/xl_512_bs_8_lr_1e06_es_5_lc_False_nr_True_sr_False_stem_True_lemma_False_repeat_3_fold_2/runs/2do2qmh3
wandb: Find logs at: ./wandb/run-20220318_041955-2do2qmh3/logs/debug.log
wandb: 

wandb: wandb version 0.12.11 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
2022-03-18 05:42:48.733876: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1
wandb: Tracking run with wandb version 0.12.5
wandb: Syncing run misunderstood-wildflower-2
wandb: ⭐️ View project at https://wandb.ai/yinanazhou/xl_512_bs_8_lr_1e06_es_5_lc_False_nr_True_sr_False_stem_True_lemma_False_repeat_4_fold_1
wandb: 🚀 View run at https://wandb.ai/yinanazhou/xl_512_bs_8_lr_1e06_es_5_lc_False_nr_True_sr_False_stem_True_lemma_False_repeat_4_fold_1/runs/95yn94w5
wandb: Run data is saved locally in /project/6002780/yinan/Thesis_MER_Lyrics/lyric-emotion/wandb/run-20220318_054245-95yn94w5
wandb: Run `wandb offline` to turn off syncing.

Validation loss decreased (inf --> 1.475526).  Saving model ...
Validation loss decreased (1.475526 --> 1.436341).  Saving model ...
Validation loss decreased (1.436341 --> 1.410544).  Saving model ...
Validation loss decreased (1.410544 --> 1.393865).  Saving model ...
Validation loss decreased (1.393865 --> 1.382845).  Saving model ...
Validation loss decreased (1.382845 --> 1.374658).  Saving model ...
Validation loss decreased (1.374658 --> 1.368201).  Saving model ...
Validation loss decreased (1.368201 --> 1.362561).  Saving model ...
Validation loss decreased (1.362561 --> 1.357642).  Saving model ...
Validation loss decreased (1.357642 --> 1.352745).  Saving model ...
Validation loss decreased (1.352745 --> 1.348108).  Saving model ...
Validation loss decreased (1.348108 --> 1.343781).  Saving model ...
Validation loss decreased (1.343781 --> 1.339322).  Saving model ...
Validation loss decreased (1.339322 --> 1.334943).  Saving model ...
Validation loss decreased (1.334943 --> 1.330721).  Saving model ...
Validation loss decreased (1.330721 --> 1.326271).  Saving model ...
Validation loss decreased (1.326271 --> 1.321384).  Saving model ...
Validation loss decreased (1.321384 --> 1.316063).  Saving model ...
Validation loss decreased (1.316063 --> 1.311266).  Saving model ...
Validation loss decreased (1.311266 --> 1.306272).  Saving model ...
Validation loss decreased (1.306272 --> 1.301199).  Saving model ...
Validation loss decreased (1.301199 --> 1.295817).  Saving model ...
Validation loss decreased (1.295817 --> 1.289839).  Saving model ...
Validation loss decreased (1.289839 --> 1.284293).  Saving model ...
Validation loss decreased (1.284293 --> 1.278215).  Saving model ...
Validation loss decreased (1.278215 --> 1.272175).  Saving model ...
Validation loss decreased (1.272175 --> 1.265818).  Saving model ...
Validation loss decreased (1.265818 --> 1.259142).  Saving model ...
Validation loss decreased (1.259142 --> 1.252882).  Saving model ...
Validation loss decreased (1.252882 --> 1.246457).  Saving model ...
Validation loss decreased (1.246457 --> 1.239948).  Saving model ...
Validation loss decreased (1.239948 --> 1.233789).  Saving model ...
Validation loss decreased (1.233789 --> 1.227037).  Saving model ...
Validation loss decreased (1.227037 --> 1.220717).  Saving model ...
Validation loss decreased (1.220717 --> 1.215100).  Saving model ...
Validation loss decreased (1.215100 --> 1.210335).  Saving model ...
Validation loss decreased (1.210335 --> 1.205198).  Saving model ...
Validation loss decreased (1.205198 --> 1.199216).  Saving model ...
Validation loss decreased (1.199216 --> 1.193833).  Saving model ...
Validation loss decreased (1.193833 --> 1.188707).  Saving model ...
Validation loss decreased (1.188707 --> 1.183101).  Saving model ...
Validation loss decreased (1.183101 --> 1.177187).  Saving model ...
Validation loss decreased (1.177187 --> 1.172177).  Saving model ...
Validation loss decreased (1.172177 --> 1.166826).  Saving model ...
Validation loss decreased (1.166826 --> 1.161593).  Saving model ...
Validation loss decreased (1.161593 --> 1.156431).  Saving model ...
Validation loss decreased (1.156431 --> 1.151110).  Saving model ...
Validation loss decreased (1.151110 --> 1.146227).  Saving model ...
Validation loss decreased (1.146227 --> 1.141240).  Saving model ...
Validation loss decreased (1.141240 --> 1.136736).  Saving model ...
Validation loss decreased (1.136736 --> 1.132426).  Saving model ...
Validation loss decreased (1.132426 --> 1.128881).  Saving model ...
Validation loss decreased (1.128881 --> 1.124354).  Saving model ...
Validation loss decreased (1.124354 --> 1.120446).  Saving model ...
Validation loss decreased (1.120446 --> 1.116088).  Saving model ...
Validation loss decreased (1.116088 --> 1.111934).  Saving model ...
Validation loss decreased (1.111934 --> 1.107196).  Saving model ...
Validation loss decreased (1.107196 --> 1.103348).  Saving model ...
Validation loss decreased (1.103348 --> 1.100074).  Saving model ...
Validation loss decreased (1.100074 --> 1.097147).  Saving model ...
Validation loss decreased (1.097147 --> 1.094256).  Saving model ...
Validation loss decreased (1.094256 --> 1.090381).  Saving model ...
Validation loss decreased (1.090381 --> 1.087685).  Saving model ...
Validation loss decreased (1.087685 --> 1.084358).  Saving model ...
Validation loss decreased (1.084358 --> 1.081477).  Saving model ...
Validation loss decreased (1.081477 --> 1.079120).  Saving model ...
Validation loss decreased (1.079120 --> 1.075830).  Saving model ...
Validation loss decreased (1.075830 --> 1.072151).  Saving model ...
Validation loss decreased (1.072151 --> 1.069186).  Saving model ...
Validation loss decreased (1.069186 --> 1.065117).  Saving model ...
Validation loss decreased (1.065117 --> 1.063232).  Saving model ...
Validation loss decreased (1.063232 --> 1.060695).  Saving model ...
Validation loss decreased (1.060695 --> 1.058891).  Saving model ...
Validation loss decreased (1.058891 --> 1.055511).  Saving model ...
Validation loss decreased (1.055511 --> 1.054639).  Saving model ...
Validation loss decreased (1.054639 --> 1.049557).  Saving model ...
Validation loss decreased (1.049557 --> 1.046357).  Saving model ...
Validation loss decreased (1.046357 --> 1.044711).  Saving model ...
Validation loss decreased (1.044711 --> 1.042344).  Saving model ...
Validation loss decreased (1.042344 --> 1.040163).  Saving model ...
Validation loss decreased (1.040163 --> 1.039805).  Saving model ...
Validation loss decreased (1.039805 --> 1.038988).  Saving model ...
Validation loss decreased (1.038988 --> 1.035357).  Saving model ...
Validation loss decreased (1.035357 --> 1.033839).  Saving model ...
Validation loss decreased (1.033839 --> 1.032465).  Saving model ...
Validation loss decreased (1.032465 --> 1.030631).  Saving model ...
Validation loss decreased (1.030631 --> 1.029265).  Saving model ...
Validation loss decreased (1.029265 --> 1.028854).  Saving model ...
Validation loss decreased (1.028854 --> 1.026490).  Saving model ...
Validation loss decreased (1.026490 --> 1.023696).  Saving model ...
Validation loss decreased (1.023696 --> 1.023148).  Saving model ...
Validation loss decreased (1.023148 --> 1.019471).  Saving model ...
EarlyStopping counter: 1 out of 5.0
EarlyStopping counter: 2 out of 5.0
Validation loss decreased (1.019471 --> 1.016591).  Saving model ...
Validation loss decreased (1.016591 --> 1.015200).  Saving model ...
Validation loss decreased (1.015200 --> 1.014917).  Saving model ...
Validation loss decreased (1.014917 --> 1.013828).  Saving model ...
Validation loss decreased (1.013828 --> 1.012660).  Saving model ...
Validation loss decreased (1.012660 --> 1.010358).  Saving model ...
EarlyStopping counter: 1 out of 5.0
EarlyStopping counter: 2 out of 5.0
EarlyStopping counter: 3 out of 5.0
Validation loss decreased (1.010358 --> 1.009669).  Saving model ...
Validation loss decreased (1.009669 --> 1.007142).  Saving model ...
Validation loss decreased (1.007142 --> 1.005520).  Saving model ...
Validation loss decreased (1.005520 --> 1.003102).  Saving model ...
Validation loss decreased (1.003102 --> 1.002879).  Saving model ...
EarlyStopping counter: 1 out of 5.0
Validation loss decreased (1.002879 --> 1.001097).  Saving model ...
EarlyStopping counter: 1 out of 5.0
EarlyStopping counter: 2 out of 5.0
Validation loss decreased (1.001097 --> 1.000790).  Saving model ...
Validation loss decreased (1.000790 --> 0.999404).  Saving model ...
Validation loss decreased (0.999404 --> 0.999275).  Saving model ...
EarlyStopping counter: 1 out of 5.0
EarlyStopping counter: 2 out of 5.0
Validation loss decreased (0.999275 --> 0.995427).  Saving model ...
EarlyStopping counter: 1 out of 5.0
EarlyStopping counter: 2 out of 5.0
EarlyStopping counter: 3 out of 5.0
EarlyStopping counter: 4 out of 5.0
Validation loss decreased (0.995427 --> 0.994379).  Saving model ...
EarlyStopping counter: 1 out of 5.0
Validation loss decreased (0.994379 --> 0.992260).  Saving model ...
EarlyStopping counter: 1 out of 5.0
EarlyStopping counter: 2 out of 5.0
EarlyStopping counter: 3 out of 5.0
EarlyStopping counter: 4 out of 5.0
EarlyStopping counter: 5 out of 5.0
/localscratch/yinan.29161863.0/env/lib/python3.7/site-packages/torch/nn/functional.py:1794: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.
  warnings.warn("nn.functional.tanh is deprecated. Use torch.tanh instead.")
wandb: Waiting for W&B process to finish, PID 185585... (success).
wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: \ 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: | 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: / 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: \ 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: | 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: / 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: \ 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: | 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: / 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: \ 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: | 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb:                                                                                
wandb: Run history:
wandb:     e_F1 ▁▁▄▄▅▅▅▅▆▆▆▆▆▆▆▆▇▇▇▇▇▇▇▇▇▇██████████████
wandb:   e_loss █▇▇▇▆▆▆▆▅▅▅▄▄▄▄▃▃▃▃▂▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:     t_F1 ▁▂▃▃▃▄▄▄▅▅▅▅▆▅▆▆▆▆▇▇▇▇▇▇▇▇▇▇▇▇█▇████████
wandb:   t_loss █▇▇▇▇▆▆▆▆▆▅▅▅▅▄▄▄▄▄▄▃▃▃▃▃▃▃▃▂▂▂▂▂▂▂▂▁▁▁▁
wandb: 
wandb: Run summary:
wandb:     e_F1 58.57268
wandb:   e_loss 0.99279
wandb:     t_F1 68.3049
wandb:   t_loss 0.78539
wandb: 
wandb: Synced 4 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Synced misunderstood-wildflower-2: https://wandb.ai/yinanazhou/xl_512_bs_8_lr_1e06_es_5_lc_False_nr_True_sr_False_stem_True_lemma_False_repeat_4_fold_1/runs/95yn94w5
wandb: Find logs at: ./wandb/run-20220318_054245-95yn94w5/logs/debug.log
wandb: 

wandb: wandb version 0.12.11 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
2022-03-18 07:06:42.718188: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1
wandb: Tracking run with wandb version 0.12.5
wandb: Syncing run lively-deluge-2
wandb: ⭐️ View project at https://wandb.ai/yinanazhou/xl_512_bs_8_lr_1e06_es_5_lc_False_nr_True_sr_False_stem_True_lemma_False_repeat_4_fold_2
wandb: 🚀 View run at https://wandb.ai/yinanazhou/xl_512_bs_8_lr_1e06_es_5_lc_False_nr_True_sr_False_stem_True_lemma_False_repeat_4_fold_2/runs/1opqw6nd
wandb: Run data is saved locally in /project/6002780/yinan/Thesis_MER_Lyrics/lyric-emotion/wandb/run-20220318_070640-1opqw6nd
wandb: Run `wandb offline` to turn off syncing.

Validation loss decreased (inf --> 1.387784).  Saving model ...
Validation loss decreased (1.387784 --> 1.383173).  Saving model ...
Validation loss decreased (1.383173 --> 1.379409).  Saving model ...
Validation loss decreased (1.379409 --> 1.375890).  Saving model ...
Validation loss decreased (1.375890 --> 1.372132).  Saving model ...
Validation loss decreased (1.372132 --> 1.368524).  Saving model ...
Validation loss decreased (1.368524 --> 1.364882).  Saving model ...
Validation loss decreased (1.364882 --> 1.361099).  Saving model ...
Validation loss decreased (1.361099 --> 1.357248).  Saving model ...
Validation loss decreased (1.357248 --> 1.353537).  Saving model ...
Validation loss decreased (1.353537 --> 1.349504).  Saving model ...
Validation loss decreased (1.349504 --> 1.344725).  Saving model ...
Validation loss decreased (1.344725 --> 1.340510).  Saving model ...
Validation loss decreased (1.340510 --> 1.336647).  Saving model ...
Validation loss decreased (1.336647 --> 1.332530).  Saving model ...
Validation loss decreased (1.332530 --> 1.326925).  Saving model ...
Validation loss decreased (1.326925 --> 1.322207).  Saving model ...
Validation loss decreased (1.322207 --> 1.316830).  Saving model ...
Validation loss decreased (1.316830 --> 1.312378).  Saving model ...
Validation loss decreased (1.312378 --> 1.305706).  Saving model ...
Validation loss decreased (1.305706 --> 1.299850).  Saving model ...
Validation loss decreased (1.299850 --> 1.294968).  Saving model ...
Validation loss decreased (1.294968 --> 1.288457).  Saving model ...
Validation loss decreased (1.288457 --> 1.283247).  Saving model ...
Validation loss decreased (1.283247 --> 1.275520).  Saving model ...
Validation loss decreased (1.275520 --> 1.270610).  Saving model ...
Validation loss decreased (1.270610 --> 1.264125).  Saving model ...
Validation loss decreased (1.264125 --> 1.256707).  Saving model ...
Validation loss decreased (1.256707 --> 1.249236).  Saving model ...
Validation loss decreased (1.249236 --> 1.245586).  Saving model ...
Validation loss decreased (1.245586 --> 1.237310).  Saving model ...
Validation loss decreased (1.237310 --> 1.232397).  Saving model ...
Validation loss decreased (1.232397 --> 1.228047).  Saving model ...
Validation loss decreased (1.228047 --> 1.221668).  Saving model ...
Validation loss decreased (1.221668 --> 1.215425).  Saving model ...
Validation loss decreased (1.215425 --> 1.209208).  Saving model ...
Validation loss decreased (1.209208 --> 1.203633).  Saving model ...
Validation loss decreased (1.203633 --> 1.200842).  Saving model ...
Validation loss decreased (1.200842 --> 1.193359).  Saving model ...
Validation loss decreased (1.193359 --> 1.187591).  Saving model ...
Validation loss decreased (1.187591 --> 1.182133).  Saving model ...
Validation loss decreased (1.182133 --> 1.179387).  Saving model ...
Validation loss decreased (1.179387 --> 1.174920).  Saving model ...
Validation loss decreased (1.174920 --> 1.168001).  Saving model ...
Validation loss decreased (1.168001 --> 1.162012).  Saving model ...
Validation loss decreased (1.162012 --> 1.157551).  Saving model ...
Validation loss decreased (1.157551 --> 1.153519).  Saving model ...
Validation loss decreased (1.153519 --> 1.147109).  Saving model ...
Validation loss decreased (1.147109 --> 1.143891).  Saving model ...
EarlyStopping counter: 1 out of 5.0
Validation loss decreased (1.143891 --> 1.141726).  Saving model ...
Validation loss decreased (1.141726 --> 1.131978).  Saving model ...
Validation loss decreased (1.131978 --> 1.128115).  Saving model ...
Validation loss decreased (1.128115 --> 1.124387).  Saving model ...
Validation loss decreased (1.124387 --> 1.121454).  Saving model ...
Validation loss decreased (1.121454 --> 1.121378).  Saving model ...
Validation loss decreased (1.121378 --> 1.114021).  Saving model ...
Validation loss decreased (1.114021 --> 1.111042).  Saving model ...
Validation loss decreased (1.111042 --> 1.106854).  Saving model ...
Validation loss decreased (1.106854 --> 1.106699).  Saving model ...
Validation loss decreased (1.106699 --> 1.105271).  Saving model ...
Validation loss decreased (1.105271 --> 1.095377).  Saving model ...
Validation loss decreased (1.095377 --> 1.092550).  Saving model ...
Validation loss decreased (1.092550 --> 1.089111).  Saving model ...
EarlyStopping counter: 1 out of 5.0
Validation loss decreased (1.089111 --> 1.086900).  Saving model ...
Validation loss decreased (1.086900 --> 1.085096).  Saving model ...
Validation loss decreased (1.085096 --> 1.080940).  Saving model ...
Validation loss decreased (1.080940 --> 1.078618).  Saving model ...
Validation loss decreased (1.078618 --> 1.078080).  Saving model ...
Validation loss decreased (1.078080 --> 1.074134).  Saving model ...
Validation loss decreased (1.074134 --> 1.065773).  Saving model ...
Validation loss decreased (1.065773 --> 1.065325).  Saving model ...
Validation loss decreased (1.065325 --> 1.064143).  Saving model ...
Validation loss decreased (1.064143 --> 1.063571).  Saving model ...
Validation loss decreased (1.063571 --> 1.061656).  Saving model ...
Validation loss decreased (1.061656 --> 1.059759).  Saving model ...
Validation loss decreased (1.059759 --> 1.057228).  Saving model ...
Validation loss decreased (1.057228 --> 1.054222).  Saving model ...
Validation loss decreased (1.054222 --> 1.050077).  Saving model ...
Validation loss decreased (1.050077 --> 1.048986).  Saving model ...
Validation loss decreased (1.048986 --> 1.046253).  Saving model ...
Validation loss decreased (1.046253 --> 1.042509).  Saving model ...
EarlyStopping counter: 1 out of 5.0
Validation loss decreased (1.042509 --> 1.040052).  Saving model ...
Validation loss decreased (1.040052 --> 1.036432).  Saving model ...
EarlyStopping counter: 1 out of 5.0
EarlyStopping counter: 2 out of 5.0
EarlyStopping counter: 3 out of 5.0
Validation loss decreased (1.036432 --> 1.031211).  Saving model ...
EarlyStopping counter: 1 out of 5.0
EarlyStopping counter: 2 out of 5.0
Validation loss decreased (1.031211 --> 1.030360).  Saving model ...
Validation loss decreased (1.030360 --> 1.028381).  Saving model ...
Validation loss decreased (1.028381 --> 1.026464).  Saving model ...
EarlyStopping counter: 1 out of 5.0
Validation loss decreased (1.026464 --> 1.026260).  Saving model ...
Validation loss decreased (1.026260 --> 1.022577).  Saving model ...
EarlyStopping counter: 1 out of 5.0
EarlyStopping counter: 2 out of 5.0
Validation loss decreased (1.022577 --> 1.020738).  Saving model ...
EarlyStopping counter: 1 out of 5.0
EarlyStopping counter: 2 out of 5.0
Validation loss decreased (1.020738 --> 1.019973).  Saving model ...
EarlyStopping counter: 1 out of 5.0
Validation loss decreased (1.019973 --> 1.017768).  Saving model ...
Validation loss decreased (1.017768 --> 1.015200).  Saving model ...
EarlyStopping counter: 1 out of 5.0
EarlyStopping counter: 2 out of 5.0
EarlyStopping counter: 3 out of 5.0
EarlyStopping counter: 4 out of 5.0
EarlyStopping counter: 5 out of 5.0
/localscratch/yinan.29161863.0/env/lib/python3.7/site-packages/torch/nn/functional.py:1794: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.
  warnings.warn("nn.functional.tanh is deprecated. Use torch.tanh instead.")
wandb: Waiting for W&B process to finish, PID 190093... (success).
wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: \ 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: | 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: / 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: \ 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: | 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: / 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: \ 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: | 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: / 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb:                                                                                
wandb: Run history:
wandb:     e_F1 ▁▂▃▄▄▄▄▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇▇▇▇▇▇▇████████████
wandb:   e_loss ███▇▇▇▇▆▆▆▅▅▅▄▄▄▄▃▃▃▃▃▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁
wandb:     t_F1 ▁▂▂▂▃▃▃▄▄▄▄▅▅▅▅▆▆▆▆▆▆▇▆▆▆▆▇▇▇▇▇▇▇▇▇▇████
wandb:   t_loss ████▇▇▇▇▆▆▆▆▅▅▅▅▅▄▄▄▄▄▄▄▃▃▃▃▂▃▂▂▂▂▂▂▁▁▁▁
wandb: 
wandb: Run summary:
wandb:     e_F1 56.06761
wandb:   e_loss 1.02062
wandb:     t_F1 68.90228
wandb:   t_loss 0.82578
wandb: 
wandb: Synced 4 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Synced lively-deluge-2: https://wandb.ai/yinanazhou/xl_512_bs_8_lr_1e06_es_5_lc_False_nr_True_sr_False_stem_True_lemma_False_repeat_4_fold_2/runs/1opqw6nd
wandb: Find logs at: ./wandb/run-20220318_070640-1opqw6nd/logs/debug.log
wandb: 

wandb: wandb version 0.12.11 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
2022-03-18 08:20:16.061298: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1
wandb: Tracking run with wandb version 0.12.5
wandb: Syncing run dark-voice-2
wandb: ⭐️ View project at https://wandb.ai/yinanazhou/xl_512_bs_8_lr_1e06_es_5_lc_False_nr_True_sr_False_stem_True_lemma_False_repeat_5_fold_1
wandb: 🚀 View run at https://wandb.ai/yinanazhou/xl_512_bs_8_lr_1e06_es_5_lc_False_nr_True_sr_False_stem_True_lemma_False_repeat_5_fold_1/runs/234nbmey
wandb: Run data is saved locally in /project/6002780/yinan/Thesis_MER_Lyrics/lyric-emotion/wandb/run-20220318_082013-234nbmey
wandb: Run `wandb offline` to turn off syncing.

Validation loss decreased (inf --> 1.402122).  Saving model ...
Validation loss decreased (1.402122 --> 1.388841).  Saving model ...
Validation loss decreased (1.388841 --> 1.379074).  Saving model ...
Validation loss decreased (1.379074 --> 1.372498).  Saving model ...
Validation loss decreased (1.372498 --> 1.367757).  Saving model ...
Validation loss decreased (1.367757 --> 1.363342).  Saving model ...
Validation loss decreased (1.363342 --> 1.359398).  Saving model ...
Validation loss decreased (1.359398 --> 1.355407).  Saving model ...
Validation loss decreased (1.355407 --> 1.352196).  Saving model ...
Validation loss decreased (1.352196 --> 1.348860).  Saving model ...
Validation loss decreased (1.348860 --> 1.345188).  Saving model ...
Validation loss decreased (1.345188 --> 1.341289).  Saving model ...
Validation loss decreased (1.341289 --> 1.337447).  Saving model ...
Validation loss decreased (1.337447 --> 1.333252).  Saving model ...
Validation loss decreased (1.333252 --> 1.329071).  Saving model ...
Validation loss decreased (1.329071 --> 1.324950).  Saving model ...
Validation loss decreased (1.324950 --> 1.320647).  Saving model ...
Validation loss decreased (1.320647 --> 1.316089).  Saving model ...
Validation loss decreased (1.316089 --> 1.311028).  Saving model ...
Validation loss decreased (1.311028 --> 1.306543).  Saving model ...
Validation loss decreased (1.306543 --> 1.301775).  Saving model ...
Validation loss decreased (1.301775 --> 1.297791).  Saving model ...
Validation loss decreased (1.297791 --> 1.293806).  Saving model ...
Validation loss decreased (1.293806 --> 1.288697).  Saving model ...
Validation loss decreased (1.288697 --> 1.283360).  Saving model ...
Validation loss decreased (1.283360 --> 1.278210).  Saving model ...
Validation loss decreased (1.278210 --> 1.271645).  Saving model ...
Validation loss decreased (1.271645 --> 1.265616).  Saving model ...
Validation loss decreased (1.265616 --> 1.259461).  Saving model ...
Validation loss decreased (1.259461 --> 1.253198).  Saving model ...
Validation loss decreased (1.253198 --> 1.247592).  Saving model ...
Validation loss decreased (1.247592 --> 1.242156).  Saving model ...
Validation loss decreased (1.242156 --> 1.236635).  Saving model ...
Validation loss decreased (1.236635 --> 1.229497).  Saving model ...
Validation loss decreased (1.229497 --> 1.223975).  Saving model ...
Validation loss decreased (1.223975 --> 1.217879).  Saving model ...
Validation loss decreased (1.217879 --> 1.210438).  Saving model ...
Validation loss decreased (1.210438 --> 1.204980).  Saving model ...
Validation loss decreased (1.204980 --> 1.198229).  Saving model ...
Validation loss decreased (1.198229 --> 1.191277).  Saving model ...
Validation loss decreased (1.191277 --> 1.186252).  Saving model ...
Validation loss decreased (1.186252 --> 1.180108).  Saving model ...
Validation loss decreased (1.180108 --> 1.174723).  Saving model ...
Validation loss decreased (1.174723 --> 1.169530).  Saving model ...
Validation loss decreased (1.169530 --> 1.163579).  Saving model ...
Validation loss decreased (1.163579 --> 1.157189).  Saving model ...
Validation loss decreased (1.157189 --> 1.151994).  Saving model ...
Validation loss decreased (1.151994 --> 1.147011).  Saving model ...
Validation loss decreased (1.147011 --> 1.142138).  Saving model ...
Validation loss decreased (1.142138 --> 1.136193).  Saving model ...
Validation loss decreased (1.136193 --> 1.131422).  Saving model ...
Validation loss decreased (1.131422 --> 1.126506).  Saving model ...
Validation loss decreased (1.126506 --> 1.122751).  Saving model ...
Validation loss decreased (1.122751 --> 1.118789).  Saving model ...
Validation loss decreased (1.118789 --> 1.113976).  Saving model ...
Validation loss decreased (1.113976 --> 1.110319).  Saving model ...
Validation loss decreased (1.110319 --> 1.106559).  Saving model ...
Validation loss decreased (1.106559 --> 1.101853).  Saving model ...
Validation loss decreased (1.101853 --> 1.097398).  Saving model ...
Validation loss decreased (1.097398 --> 1.094208).  Saving model ...
Validation loss decreased (1.094208 --> 1.090138).  Saving model ...
Validation loss decreased (1.090138 --> 1.085820).  Saving model ...
Validation loss decreased (1.085820 --> 1.082322).  Saving model ...
Validation loss decreased (1.082322 --> 1.079352).  Saving model ...
Validation loss decreased (1.079352 --> 1.075763).  Saving model ...
Validation loss decreased (1.075763 --> 1.071814).  Saving model ...
Validation loss decreased (1.071814 --> 1.068528).  Saving model ...
Validation loss decreased (1.068528 --> 1.063283).  Saving model ...
Validation loss decreased (1.063283 --> 1.059650).  Saving model ...
Validation loss decreased (1.059650 --> 1.055179).  Saving model ...
Validation loss decreased (1.055179 --> 1.053547).  Saving model ...
Validation loss decreased (1.053547 --> 1.051808).  Saving model ...
Validation loss decreased (1.051808 --> 1.047689).  Saving model ...
Validation loss decreased (1.047689 --> 1.044233).  Saving model ...
Validation loss decreased (1.044233 --> 1.040648).  Saving model ...
Validation loss decreased (1.040648 --> 1.037799).  Saving model ...
Validation loss decreased (1.037799 --> 1.035721).  Saving model ...
Validation loss decreased (1.035721 --> 1.032476).  Saving model ...
Validation loss decreased (1.032476 --> 1.030989).  Saving model ...
Validation loss decreased (1.030989 --> 1.027090).  Saving model ...
Validation loss decreased (1.027090 --> 1.024272).  Saving model ...
Validation loss decreased (1.024272 --> 1.022567).  Saving model ...
Validation loss decreased (1.022567 --> 1.021608).  Saving model ...
Validation loss decreased (1.021608 --> 1.018302).  Saving model ...
Validation loss decreased (1.018302 --> 1.017699).  Saving model ...
Validation loss decreased (1.017699 --> 1.015326).  Saving model ...
Validation loss decreased (1.015326 --> 1.013055).  Saving model ...
Validation loss decreased (1.013055 --> 1.009513).  Saving model ...
Validation loss decreased (1.009513 --> 1.008108).  Saving model ...
Validation loss decreased (1.008108 --> 1.006266).  Saving model ...
Validation loss decreased (1.006266 --> 1.004754).  Saving model ...
Validation loss decreased (1.004754 --> 1.003194).  Saving model ...
Validation loss decreased (1.003194 --> 1.000918).  Saving model ...
Validation loss decreased (1.000918 --> 0.998888).  Saving model ...
Validation loss decreased (0.998888 --> 0.997678).  Saving model ...
Validation loss decreased (0.997678 --> 0.995732).  Saving model ...
Validation loss decreased (0.995732 --> 0.993837).  Saving model ...
Validation loss decreased (0.993837 --> 0.992202).  Saving model ...
Validation loss decreased (0.992202 --> 0.990155).  Saving model ...
Validation loss decreased (0.990155 --> 0.989264).  Saving model ...
Validation loss decreased (0.989264 --> 0.987547).  Saving model ...
Validation loss decreased (0.987547 --> 0.986822).  Saving model ...
Validation loss decreased (0.986822 --> 0.984053).  Saving model ...
Validation loss decreased (0.984053 --> 0.983232).  Saving model ...
Validation loss decreased (0.983232 --> 0.982364).  Saving model ...
Validation loss decreased (0.982364 --> 0.981676).  Saving model ...
Validation loss decreased (0.981676 --> 0.980437).  Saving model ...
Validation loss decreased (0.980437 --> 0.979861).  Saving model ...
Validation loss decreased (0.979861 --> 0.978195).  Saving model ...
EarlyStopping counter: 1 out of 5.0
Validation loss decreased (0.978195 --> 0.977260).  Saving model ...
Validation loss decreased (0.977260 --> 0.976219).  Saving model ...
Validation loss decreased (0.976219 --> 0.975967).  Saving model ...
Validation loss decreased (0.975967 --> 0.975279).  Saving model ...
Validation loss decreased (0.975279 --> 0.973489).  Saving model ...
Validation loss decreased (0.973489 --> 0.972823).  Saving model ...
Validation loss decreased (0.972823 --> 0.972010).  Saving model ...
Validation loss decreased (0.972010 --> 0.970836).  Saving model ...
Validation loss decreased (0.970836 --> 0.970524).  Saving model ...
Validation loss decreased (0.970524 --> 0.970098).  Saving model ...
Validation loss decreased (0.970098 --> 0.969912).  Saving model ...
Validation loss decreased (0.969912 --> 0.968348).  Saving model ...
Validation loss decreased (0.968348 --> 0.967866).  Saving model ...
Validation loss decreased (0.967866 --> 0.967536).  Saving model ...
Validation loss decreased (0.967536 --> 0.966445).  Saving model ...
EarlyStopping counter: 1 out of 5.0
EarlyStopping counter: 2 out of 5.0
EarlyStopping counter: 3 out of 5.0
EarlyStopping counter: 4 out of 5.0
EarlyStopping counter: 5 out of 5.0
/localscratch/yinan.29161863.0/env/lib/python3.7/site-packages/torch/nn/functional.py:1794: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.
  warnings.warn("nn.functional.tanh is deprecated. Use torch.tanh instead.")
wandb: Waiting for W&B process to finish, PID 194038... (success).
wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: \ 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: | 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: / 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: \ 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: | 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: / 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: \ 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: | 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: / 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: \ 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb:                                                                                
wandb: Run history:
wandb:     e_F1 ▁▃▄▄▄▅▅▅▅▅▆▆▆▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇████████████
wandb:   e_loss ██▇▇▇▇▇▆▆▆▅▅▅▄▄▄▄▃▃▃▃▂▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁
wandb:     t_F1 ▁▂▃▂▃▃▃▅▄▅▅▆▅▆▅▆▆▆▆▇▇▇▇▇▇▇▇▇▇▇▇█▇▇▇▇████
wandb:   t_loss ████▇▇▇▇▆▆▆▆▅▅▅▅▅▄▄▄▄▄▄▄▃▃▃▃▃▂▂▂▂▂▂▂▁▂▁▁
wandb: 
wandb: Run summary:
wandb:     e_F1 56.84152
wandb:   e_loss 0.96754
wandb:     t_F1 70.9034
wandb:   t_loss 0.75816
wandb: 
wandb: Synced 4 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Synced dark-voice-2: https://wandb.ai/yinanazhou/xl_512_bs_8_lr_1e06_es_5_lc_False_nr_True_sr_False_stem_True_lemma_False_repeat_5_fold_1/runs/234nbmey
wandb: Find logs at: ./wandb/run-20220318_082013-234nbmey/logs/debug.log
wandb: 

wandb: wandb version 0.12.11 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
2022-03-18 09:43:14.510762: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1
wandb: Tracking run with wandb version 0.12.5
wandb: Syncing run dainty-plant-2
wandb: ⭐️ View project at https://wandb.ai/yinanazhou/xl_512_bs_8_lr_1e06_es_5_lc_False_nr_True_sr_False_stem_True_lemma_False_repeat_5_fold_2
wandb: 🚀 View run at https://wandb.ai/yinanazhou/xl_512_bs_8_lr_1e06_es_5_lc_False_nr_True_sr_False_stem_True_lemma_False_repeat_5_fold_2/runs/2v9n4due
wandb: Run data is saved locally in /project/6002780/yinan/Thesis_MER_Lyrics/lyric-emotion/wandb/run-20220318_094311-2v9n4due
wandb: Run `wandb offline` to turn off syncing.

Validation loss decreased (inf --> 1.400491).  Saving model ...
Validation loss decreased (1.400491 --> 1.393929).  Saving model ...
Validation loss decreased (1.393929 --> 1.387904).  Saving model ...
Validation loss decreased (1.387904 --> 1.383659).  Saving model ...
Validation loss decreased (1.383659 --> 1.378829).  Saving model ...
Validation loss decreased (1.378829 --> 1.374709).  Saving model ...
Validation loss decreased (1.374709 --> 1.370619).  Saving model ...
Validation loss decreased (1.370619 --> 1.366504).  Saving model ...
Validation loss decreased (1.366504 --> 1.362951).  Saving model ...
Validation loss decreased (1.362951 --> 1.359215).  Saving model ...
Validation loss decreased (1.359215 --> 1.355373).  Saving model ...
Validation loss decreased (1.355373 --> 1.350956).  Saving model ...
Validation loss decreased (1.350956 --> 1.345927).  Saving model ...
Validation loss decreased (1.345927 --> 1.341292).  Saving model ...
Validation loss decreased (1.341292 --> 1.337387).  Saving model ...
Validation loss decreased (1.337387 --> 1.333246).  Saving model ...
Validation loss decreased (1.333246 --> 1.328598).  Saving model ...
Validation loss decreased (1.328598 --> 1.324213).  Saving model ...
Validation loss decreased (1.324213 --> 1.319885).  Saving model ...
Validation loss decreased (1.319885 --> 1.314364).  Saving model ...
Validation loss decreased (1.314364 --> 1.308059).  Saving model ...
Validation loss decreased (1.308059 --> 1.302018).  Saving model ...
Validation loss decreased (1.302018 --> 1.295974).  Saving model ...
Validation loss decreased (1.295974 --> 1.288464).  Saving model ...
Validation loss decreased (1.288464 --> 1.281527).  Saving model ...
Validation loss decreased (1.281527 --> 1.274072).  Saving model ...
Validation loss decreased (1.274072 --> 1.266799).  Saving model ...
Validation loss decreased (1.266799 --> 1.259462).  Saving model ...
Validation loss decreased (1.259462 --> 1.252428).  Saving model ...
Validation loss decreased (1.252428 --> 1.244463).  Saving model ...
Validation loss decreased (1.244463 --> 1.235817).  Saving model ...
Validation loss decreased (1.235817 --> 1.229436).  Saving model ...
Validation loss decreased (1.229436 --> 1.222925).  Saving model ...
Validation loss decreased (1.222925 --> 1.216996).  Saving model ...
Validation loss decreased (1.216996 --> 1.211118).  Saving model ...
Validation loss decreased (1.211118 --> 1.205559).  Saving model ...
Validation loss decreased (1.205559 --> 1.198873).  Saving model ...
Validation loss decreased (1.198873 --> 1.195250).  Saving model ...
Validation loss decreased (1.195250 --> 1.189469).  Saving model ...
Validation loss decreased (1.189469 --> 1.182929).  Saving model ...
Validation loss decreased (1.182929 --> 1.177948).  Saving model ...
Validation loss decreased (1.177948 --> 1.173224).  Saving model ...
Validation loss decreased (1.173224 --> 1.169450).  Saving model ...
Validation loss decreased (1.169450 --> 1.163883).  Saving model ...
Validation loss decreased (1.163883 --> 1.157333).  Saving model ...
Validation loss decreased (1.157333 --> 1.150867).  Saving model ...
Validation loss decreased (1.150867 --> 1.146618).  Saving model ...
Validation loss decreased (1.146618 --> 1.141803).  Saving model ...
Validation loss decreased (1.141803 --> 1.137457).  Saving model ...
Validation loss decreased (1.137457 --> 1.132860).  Saving model ...
Validation loss decreased (1.132860 --> 1.127286).  Saving model ...
Validation loss decreased (1.127286 --> 1.123982).  Saving model ...
Validation loss decreased (1.123982 --> 1.120008).  Saving model ...
Validation loss decreased (1.120008 --> 1.115865).  Saving model ...
Validation loss decreased (1.115865 --> 1.111030).  Saving model ...
Validation loss decreased (1.111030 --> 1.105264).  Saving model ...
Validation loss decreased (1.105264 --> 1.101764).  Saving model ...
Validation loss decreased (1.101764 --> 1.099219).  Saving model ...
Validation loss decreased (1.099219 --> 1.095567).  Saving model ...
Validation loss decreased (1.095567 --> 1.091234).  Saving model ...
Validation loss decreased (1.091234 --> 1.088584).  Saving model ...
Validation loss decreased (1.088584 --> 1.085431).  Saving model ...
Validation loss decreased (1.085431 --> 1.080228).  Saving model ...
Validation loss decreased (1.080228 --> 1.078914).  Saving model ...
Validation loss decreased (1.078914 --> 1.075856).  Saving model ...
Validation loss decreased (1.075856 --> 1.072572).  Saving model ...
Validation loss decreased (1.072572 --> 1.068459).  Saving model ...
Validation loss decreased (1.068459 --> 1.067192).  Saving model ...
Validation loss decreased (1.067192 --> 1.064224).  Saving model ...
Validation loss decreased (1.064224 --> 1.060273).  Saving model ...
Validation loss decreased (1.060273 --> 1.057693).  Saving model ...
Validation loss decreased (1.057693 --> 1.055164).  Saving model ...
Validation loss decreased (1.055164 --> 1.050531).  Saving model ...
Validation loss decreased (1.050531 --> 1.048610).  Saving model ...
Validation loss decreased (1.048610 --> 1.046083).  Saving model ...
Validation loss decreased (1.046083 --> 1.044783).  Saving model ...
Validation loss decreased (1.044783 --> 1.042063).  Saving model ...
Validation loss decreased (1.042063 --> 1.040106).  Saving model ...
Validation loss decreased (1.040106 --> 1.037887).  Saving model ...
Validation loss decreased (1.037887 --> 1.036563).  Saving model ...
Validation loss decreased (1.036563 --> 1.036216).  Saving model ...
Validation loss decreased (1.036216 --> 1.033974).  Saving model ...
Validation loss decreased (1.033974 --> 1.032980).  Saving model ...
Validation loss decreased (1.032980 --> 1.029201).  Saving model ...
Validation loss decreased (1.029201 --> 1.026161).  Saving model ...
Validation loss decreased (1.026161 --> 1.024292).  Saving model ...
Validation loss decreased (1.024292 --> 1.024253).  Saving model ...
Validation loss decreased (1.024253 --> 1.021820).  Saving model ...
Validation loss decreased (1.021820 --> 1.020795).  Saving model ...
Validation loss decreased (1.020795 --> 1.019313).  Saving model ...
Validation loss decreased (1.019313 --> 1.015791).  Saving model ...
Validation loss decreased (1.015791 --> 1.014167).  Saving model ...
Validation loss decreased (1.014167 --> 1.012648).  Saving model ...
EarlyStopping counter: 1 out of 5.0
Validation loss decreased (1.012648 --> 1.011493).  Saving model ...
Validation loss decreased (1.011493 --> 1.009464).  Saving model ...
Validation loss decreased (1.009464 --> 1.007112).  Saving model ...
Validation loss decreased (1.007112 --> 1.006839).  Saving model ...
Validation loss decreased (1.006839 --> 1.003680).  Saving model ...
Validation loss decreased (1.003680 --> 1.001889).  Saving model ...
Validation loss decreased (1.001889 --> 1.001710).  Saving model ...
EarlyStopping counter: 1 out of 5.0
Validation loss decreased (1.001710 --> 0.999355).  Saving model ...
Validation loss decreased (0.999355 --> 0.998497).  Saving model ...
Validation loss decreased (0.998497 --> 0.997117).  Saving model ...
Validation loss decreased (0.997117 --> 0.997002).  Saving model ...
Validation loss decreased (0.997002 --> 0.994525).  Saving model ...
EarlyStopping counter: 1 out of 5.0
Validation loss decreased (0.994525 --> 0.993597).  Saving model ...
Validation loss decreased (0.993597 --> 0.992798).  Saving model ...
Validation loss decreased (0.992798 --> 0.990363).  Saving model ...
Validation loss decreased (0.990363 --> 0.987506).  Saving model ...
EarlyStopping counter: 1 out of 5.0
EarlyStopping counter: 2 out of 5.0
EarlyStopping counter: 3 out of 5.0
EarlyStopping counter: 4 out of 5.0
EarlyStopping counter: 5 out of 5.0
/localscratch/yinan.29161863.0/env/lib/python3.7/site-packages/torch/nn/functional.py:1794: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.
  warnings.warn("nn.functional.tanh is deprecated. Use torch.tanh instead.")
wandb: Waiting for W&B process to finish, PID 198486... (success).
wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: \ 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: | 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: / 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: \ 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: | 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: / 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: \ 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: | 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: / 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb:                                                                                
wandb: Run history:
wandb:     e_F1 ▁▂▃▄▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇▇▇▇▇▇▇███████████████
wandb:   e_loss ███▇▇▇▇▆▆▆▅▅▅▄▄▄▄▃▃▃▃▃▂▂▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁
wandb:     t_F1 ▁▂▂▂▂▃▃▄▄▄▅▅▅▅▆▆▆▆▆▆▇▇▆▇▇▇▇█▇▇▇█████████
wandb:   t_loss █████▇▇▇▇▆▆▆▅▅▅▅▄▄▄▄▄▄▄▃▃▃▃▂▂▂▃▂▂▂▂▂▂▂▁▁
wandb: 
wandb: Run summary:
wandb:     e_F1 59.44849
wandb:   e_loss 0.98896
wandb:     t_F1 65.3774
wandb:   t_loss 0.83857
wandb: 
wandb: Synced 4 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Synced dainty-plant-2: https://wandb.ai/yinanazhou/xl_512_bs_8_lr_1e06_es_5_lc_False_nr_True_sr_False_stem_True_lemma_False_repeat_5_fold_2/runs/2v9n4due
wandb: Find logs at: ./wandb/run-20220318_094311-2v9n4due/logs/debug.log
wandb: 

