Unloading StdEnv/2020

Due to MODULEPATH changes, the following have been reloaded:
  1) mii/1.1.1


The following have been reloaded with a version change:
  1) python/3.8.2 => python/3.7.4

Using base prefix '/cvmfs/soft.computecanada.ca/easybuild/software/2017/Core/python/3.7.4'
New python executable in /localscratch/yinan.29028709.0/env/bin/python
Installing setuptools, pip, wheel...
done.
Ignoring pip: markers 'python_version < "3"' don't match your environment
Looking in links: /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/nix/avx2, /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/nix/generic, /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic
Collecting pip
Installing collected packages: pip
  Found existing installation: pip 19.1.1
    Uninstalling pip-19.1.1:
      Successfully uninstalled pip-19.1.1
Successfully installed pip-21.2.3+computecanada
Looking in links: /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/nix/avx2, /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/nix/generic, /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/keras-2.8.0+computecanada-py2.py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/Keras_Preprocessing-1.1.2+computecanada-py3-none-any.whl
Requirement already satisfied: matplotlib in /cvmfs/soft.computecanada.ca/easybuild/software/2017/Core/scipy-stack/2019a/lib/python3.7/site-packages (from -r requirements.txt (line 3)) (3.0.2)
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/nltk-3.6.5+computecanada-py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/scikit_learn-0.22.1+computecanada-cp37-cp37m-linux_x86_64.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/tensorboard-2.3.0+computecanada-py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/tensorboard_plugin_wit-1.7.0+computecanada-py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/tensorflow_gpu-2.3.0+computecanada-cp37-cp37m-linux_x86_64.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/tensorflow_estimator-2.3.0+computecanada-py2.py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/tokenizers-0.5.2+computecanada-cp37-cp37m-linux_x86_64.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/nix/avx2/torch-1.4.0+computecanada-cp37-cp37m-linux_x86_64.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/torchtext-0.6.0+computecanada-py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/torchvision-0.8.2+computecanada-cp37-cp37m-linux_x86_64.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/transformers-2.5.1+computecanada-py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/urllib3-1.26.7+computecanada-py2.py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/tqdm-4.63.0+computecanada-py2.py3-none-any.whl
ERROR: Could not find a version that satisfies the requirement regex>=2021.8.3 (from nltk) (from versions: 2018.1.10+computecanada, 2019.11.1+computecanada, 2020.11.13+computecanada)
ERROR: No matching distribution found for regex>=2021.8.3
Looking in links: /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/nix/avx2, /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/nix/generic, /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic
ERROR: Could not find a version that satisfies the requirement numpy==1.20.0+computacanada (from versions: 1.15.0+computecanada, 1.15.2+computecanada, 1.15.4+computecanada, 1.16.0+computecanada, 1.16.2+computecanada, 1.16.3+computecanada, 1.17.4+computecanada, 1.18.1+computecanada, 1.18.4+computecanada, 1.19.1+computecanada, 1.19.2+computecanada, 1.20.2+computecanada)
ERROR: No matching distribution found for numpy==1.20.0+computacanada
Looking in links: /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/nix/avx2, /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/nix/generic, /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/wandb-0.12.5+computecanada-py2.py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/yaspin-2.1.0+computecanada-py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/six-1.16.0+computecanada-py2.py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/docker_pycreds-0.4.0+computecanada-py2.py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/pathtools-0.1.2+computecanada-py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/promise-2.3+computecanada-py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/protobuf-3.19.4+computecanada-py2.py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/GitPython-3.1.24+computecanada-py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/sentry_sdk-1.5.0+computecanada-py2.py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/configparser-5.0.2+computecanada-py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/subprocess32-3.5.4+computecanada-py3-none-any.whl
Requirement already satisfied: python-dateutil>=2.6.1 in /cvmfs/soft.computecanada.ca/easybuild/software/2017/Core/scipy-stack/2019a/lib/python3.7/site-packages (from wandb) (2.7.5)
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/click-8.0.3+computecanada-py3-none-any.whl
Requirement already satisfied: requests<3,>=2.0.0 in /cvmfs/soft.computecanada.ca/easybuild/software/2017/Core/scipy-stack/2019a/lib/python3.7/site-packages (from wandb) (2.21.0)
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/shortuuid-1.0.1+computecanada-py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/psutil-5.7.3+computecanada-cp37-cp37m-linux_x86_64.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/PyYAML-5.3.1+computecanada-cp37-cp37m-linux_x86_64.whl
Requirement already satisfied: importlib-metadata in /cvmfs/soft.computecanada.ca/easybuild/software/2017/Core/scipy-stack/2019a/lib/python3.7/site-packages (from Click!=8.0.0,>=7.0->wandb) (0.8)
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/gitdb-4.0.9+computecanada-py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/typing_extensions-4.0.1+computecanada-py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/smmap-5.0.0+computecanada-py3-none-any.whl
Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /cvmfs/soft.computecanada.ca/easybuild/software/2017/Core/scipy-stack/2019a/lib/python3.7/site-packages (from requests<3,>=2.0.0->wandb) (3.0.4)
Requirement already satisfied: urllib3<1.25,>=1.21.1 in /cvmfs/soft.computecanada.ca/easybuild/software/2017/Core/scipy-stack/2019a/lib/python3.7/site-packages (from requests<3,>=2.0.0->wandb) (1.24.1)
Requirement already satisfied: certifi>=2017.4.17 in /cvmfs/soft.computecanada.ca/easybuild/software/2017/Core/scipy-stack/2019a/lib/python3.7/site-packages (from requests<3,>=2.0.0->wandb) (2018.11.29)
Requirement already satisfied: idna<2.9,>=2.5 in /cvmfs/soft.computecanada.ca/easybuild/software/2017/Core/scipy-stack/2019a/lib/python3.7/site-packages (from requests<3,>=2.0.0->wandb) (2.8)
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/termcolor-1.1.0+computecanada-py3-none-any.whl
Requirement already satisfied: zipp>=0.3.2 in /cvmfs/soft.computecanada.ca/easybuild/software/2017/Core/scipy-stack/2019a/lib/python3.7/site-packages (from importlib-metadata->Click!=8.0.0,>=7.0->wandb) (0.3.3)
Installing collected packages: smmap, typing-extensions, termcolor, six, gitdb, yaspin, subprocess32, shortuuid, sentry-sdk, PyYAML, psutil, protobuf, promise, pathtools, GitPython, docker-pycreds, configparser, Click, wandb
  Attempting uninstall: six
    Found existing installation: six 1.12.0
    Not uninstalling six at /cvmfs/soft.computecanada.ca/easybuild/software/2017/Core/scipy-stack/2019a/lib/python3.7/site-packages, outside environment /localscratch/yinan.29028709.0/env
    Can't uninstall 'six'. No files were found to uninstall.
Successfully installed Click-8.0.3+computecanada GitPython-3.1.24+computecanada PyYAML-5.3.1+computecanada configparser-5.0.2+computecanada docker-pycreds-0.4.0+computecanada gitdb-4.0.9+computecanada pathtools-0.1.2+computecanada promise-2.3+computecanada protobuf-3.19.4+computecanada psutil-5.7.3+computecanada sentry-sdk-1.5.0+computecanada shortuuid-1.0.1+computecanada six-1.16.0+computecanada smmap-5.0.0+computecanada subprocess32-3.5.4+computecanada termcolor-1.1.0+computecanada typing-extensions-4.0.1+computecanada wandb-0.12.5+computecanada yaspin-2.1.0+computecanada
Looking in links: /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/nix/avx2, /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/nix/generic, /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic
ERROR: Could not find a version that satisfies the requirement sagemaker (from versions: none)
ERROR: No matching distribution found for sagemaker
Looking in links: /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/nix/avx2, /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/nix/generic, /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/torch-1.9.1+computecanada-cp37-cp37m-linux_x86_64.whl
Requirement already satisfied: typing-extensions in /localscratch/yinan.29028709.0/env/lib/python3.7/site-packages (from torch) (4.0.1+computecanada)
Installing collected packages: torch
Successfully installed torch-1.9.1+computecanada
Looking in links: /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/nix/avx2, /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/nix/generic, /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/transformers-2.5.1+computecanada-py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/tokenizers-0.5.2+computecanada-cp37-cp37m-linux_x86_64.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/tqdm-4.63.0+computecanada-py2.py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/sacremoses-0.0.46+computecanada-py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/filelock-3.4.2+computecanada-py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/sentencepiece-0.1.91+computecanada-cp37-cp37m-linux_x86_64.whl
Requirement already satisfied: numpy in /cvmfs/soft.computecanada.ca/easybuild/software/2017/Core/scipy-stack/2019a/lib/python3.7/site-packages (from transformers==2.5.1+computecanada) (1.16.0)
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/boto3-1.20.52+computecanada-py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/regex-2020.11.13+computecanada-cp37-cp37m-linux_x86_64.whl
Requirement already satisfied: requests in /cvmfs/soft.computecanada.ca/easybuild/software/2017/Core/scipy-stack/2019a/lib/python3.7/site-packages (from transformers==2.5.1+computecanada) (2.21.0)
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/jmespath-0.10.0+computecanada-py2.py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/botocore-1.23.52+computecanada-py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/s3transfer-0.5.1+computecanada-py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/urllib3-1.26.8+computecanada-py2.py3-none-any.whl
Requirement already satisfied: python-dateutil<3.0.0,>=2.1 in /cvmfs/soft.computecanada.ca/easybuild/software/2017/Core/scipy-stack/2019a/lib/python3.7/site-packages (from botocore<1.24.0,>=1.23.52->boto3->transformers==2.5.1+computecanada) (2.7.5)
Requirement already satisfied: six>=1.5 in /localscratch/yinan.29028709.0/env/lib/python3.7/site-packages (from python-dateutil<3.0.0,>=2.1->botocore<1.24.0,>=1.23.52->boto3->transformers==2.5.1+computecanada) (1.16.0+computecanada)
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/requests-2.27.1+computecanada-py2.py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/charset_normalizer-2.0.11+computecanada-py3-none-any.whl
Requirement already satisfied: certifi>=2017.4.17 in /cvmfs/soft.computecanada.ca/easybuild/software/2017/Core/scipy-stack/2019a/lib/python3.7/site-packages (from requests->transformers==2.5.1+computecanada) (2018.11.29)
Requirement already satisfied: idna<4,>=2.5 in /cvmfs/soft.computecanada.ca/easybuild/software/2017/Core/scipy-stack/2019a/lib/python3.7/site-packages (from requests->transformers==2.5.1+computecanada) (2.8)
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/joblib-1.1.0+computecanada-py2.py3-none-any.whl
Requirement already satisfied: click in /localscratch/yinan.29028709.0/env/lib/python3.7/site-packages (from sacremoses->transformers==2.5.1+computecanada) (8.0.3+computecanada)
Requirement already satisfied: importlib-metadata in /cvmfs/soft.computecanada.ca/easybuild/software/2017/Core/scipy-stack/2019a/lib/python3.7/site-packages (from click->sacremoses->transformers==2.5.1+computecanada) (0.8)
Requirement already satisfied: zipp>=0.3.2 in /cvmfs/soft.computecanada.ca/easybuild/software/2017/Core/scipy-stack/2019a/lib/python3.7/site-packages (from importlib-metadata->click->sacremoses->transformers==2.5.1+computecanada) (0.3.3)
Installing collected packages: urllib3, jmespath, botocore, tqdm, s3transfer, regex, joblib, charset-normalizer, tokenizers, sentencepiece, sacremoses, requests, filelock, boto3, transformers
  Attempting uninstall: urllib3
    Found existing installation: urllib3 1.24.1
    Not uninstalling urllib3 at /cvmfs/soft.computecanada.ca/easybuild/software/2017/Core/scipy-stack/2019a/lib/python3.7/site-packages, outside environment /localscratch/yinan.29028709.0/env
    Can't uninstall 'urllib3'. No files were found to uninstall.
  Attempting uninstall: requests
    Found existing installation: requests 2.21.0
    Not uninstalling requests at /cvmfs/soft.computecanada.ca/easybuild/software/2017/Core/scipy-stack/2019a/lib/python3.7/site-packages, outside environment /localscratch/yinan.29028709.0/env
    Can't uninstall 'requests'. No files were found to uninstall.
Successfully installed boto3-1.20.52+computecanada botocore-1.23.52+computecanada charset-normalizer-2.0.11+computecanada filelock-3.4.2+computecanada jmespath-0.10.0+computecanada joblib-1.1.0+computecanada regex-2020.11.13+computecanada requests-2.27.1+computecanada s3transfer-0.5.1+computecanada sacremoses-0.0.46+computecanada sentencepiece-0.1.91+computecanada tokenizers-0.5.2+computecanada tqdm-4.63.0+computecanada transformers-2.5.1+computecanada urllib3-1.26.8+computecanada
Looking in links: /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/nix/avx2, /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/nix/generic, /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/tensorflow_gpu-2.3.0+computecanada-cp37-cp37m-linux_x86_64.whl
Requirement already satisfied: protobuf>=3.9.2 in /localscratch/yinan.29028709.0/env/lib/python3.7/site-packages (from tensorflow_gpu==2.3.0+computecanada) (3.19.4+computecanada)
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/opt_einsum-3.3.0+computecanada-py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/wrapt-1.11.2+computecanada-cp37-cp37m-linux_x86_64.whl
Requirement already satisfied: wheel>=0.26 in /localscratch/yinan.29028709.0/env/lib/python3.7/site-packages (from tensorflow_gpu==2.3.0+computecanada) (0.33.4)
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/astunparse-1.6.3+computecanada-py2.py3-none-any.whl
Requirement already satisfied: six>=1.12.0 in /localscratch/yinan.29028709.0/env/lib/python3.7/site-packages (from tensorflow_gpu==2.3.0+computecanada) (1.16.0+computecanada)
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/absl_py-1.0.0+computecanada-py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/google_pasta-0.2.0+computecanada-py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/gast-0.3.3+computecanada-py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/tensorboard-2.8.0+computecanada-py3-none-any.whl
Requirement already satisfied: numpy<1.19.0,>=1.16.0 in /cvmfs/soft.computecanada.ca/easybuild/software/2017/Core/scipy-stack/2019a/lib/python3.7/site-packages (from tensorflow_gpu==2.3.0+computecanada) (1.16.0)
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/grpcio-1.38.0+computecanada-cp37-cp37m-linux_x86_64.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/tensorflow_estimator-2.3.0+computecanada-py2.py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/nix/generic/scipy-1.4.1+computecanada-cp37-cp37m-linux_x86_64.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/nix/avx2/h5py-2.10.0+computecanada-cp37-cp37m-linux_x86_64.whl
Requirement already satisfied: termcolor>=1.1.0 in /localscratch/yinan.29028709.0/env/lib/python3.7/site-packages (from tensorflow_gpu==2.3.0+computecanada) (1.1.0+computecanada)
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/Keras_Preprocessing-1.1.2+computecanada-py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/google_auth_oauthlib-0.4.6+computecanada-py2.py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/google_auth-2.3.3+computecanada-py2.py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/tensorboard_data_server-0.6.1+computecanada-py3-none-linux_x86_64.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/Werkzeug-2.0.3+computecanada-py3-none-any.whl
Requirement already satisfied: setuptools>=41.0.0 in /localscratch/yinan.29028709.0/env/lib/python3.7/site-packages (from tensorboard<3,>=2.3.0->tensorflow_gpu==2.3.0+computecanada) (41.0.1)
Requirement already satisfied: requests<3,>=2.21.0 in /localscratch/yinan.29028709.0/env/lib/python3.7/site-packages (from tensorboard<3,>=2.3.0->tensorflow_gpu==2.3.0+computecanada) (2.27.1+computecanada)
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/Markdown-3.3.6+computecanada-py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/tensorboard_plugin_wit-1.8.0+computecanada-py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/rsa-4.8+computecanada-py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/pyasn1_modules-0.2.8+computecanada-py2.py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/cachetools-4.2.4+computecanada-py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/requests_oauthlib-1.3.0+computecanada-py2.py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/importlib_metadata-4.10.1+computecanada-py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/zipp-3.7.0+computecanada-py3-none-any.whl
Requirement already satisfied: typing-extensions>=3.6.4 in /localscratch/yinan.29028709.0/env/lib/python3.7/site-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard<3,>=2.3.0->tensorflow_gpu==2.3.0+computecanada) (4.0.1+computecanada)
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/pyasn1-0.4.8+computecanada-py2.py3-none-any.whl
Requirement already satisfied: charset-normalizer~=2.0.0 in /localscratch/yinan.29028709.0/env/lib/python3.7/site-packages (from requests<3,>=2.21.0->tensorboard<3,>=2.3.0->tensorflow_gpu==2.3.0+computecanada) (2.0.11+computecanada)
Requirement already satisfied: idna<4,>=2.5 in /cvmfs/soft.computecanada.ca/easybuild/software/2017/Core/scipy-stack/2019a/lib/python3.7/site-packages (from requests<3,>=2.21.0->tensorboard<3,>=2.3.0->tensorflow_gpu==2.3.0+computecanada) (2.8)
Requirement already satisfied: urllib3<1.27,>=1.21.1 in /localscratch/yinan.29028709.0/env/lib/python3.7/site-packages (from requests<3,>=2.21.0->tensorboard<3,>=2.3.0->tensorflow_gpu==2.3.0+computecanada) (1.26.8+computecanada)
Requirement already satisfied: certifi>=2017.4.17 in /cvmfs/soft.computecanada.ca/easybuild/software/2017/Core/scipy-stack/2019a/lib/python3.7/site-packages (from requests<3,>=2.21.0->tensorboard<3,>=2.3.0->tensorflow_gpu==2.3.0+computecanada) (2018.11.29)
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/oauthlib-3.1.1+computecanada-py2.py3-none-any.whl
Installing collected packages: pyasn1, zipp, rsa, pyasn1-modules, oauthlib, cachetools, requests-oauthlib, importlib-metadata, google-auth, werkzeug, tensorboard-plugin-wit, tensorboard-data-server, markdown, grpcio, google-auth-oauthlib, absl-py, wrapt, tensorflow-estimator, tensorboard, scipy, opt-einsum, keras-preprocessing, h5py, google-pasta, gast, astunparse, tensorflow-gpu
  Attempting uninstall: pyasn1
    Found existing installation: pyasn1 0.4.3
    Not uninstalling pyasn1 at /cvmfs/soft.computecanada.ca/easybuild/software/2017/Core/scipy-stack/2019a/lib/python3.7/site-packages, outside environment /localscratch/yinan.29028709.0/env
    Can't uninstall 'pyasn1'. No files were found to uninstall.
  Attempting uninstall: zipp
    Found existing installation: zipp 0.3.3
    Not uninstalling zipp at /cvmfs/soft.computecanada.ca/easybuild/software/2017/Core/scipy-stack/2019a/lib/python3.7/site-packages, outside environment /localscratch/yinan.29028709.0/env
    Can't uninstall 'zipp'. No files were found to uninstall.
  Attempting uninstall: importlib-metadata
    Found existing installation: importlib-metadata 0.8
    Not uninstalling importlib-metadata at /cvmfs/soft.computecanada.ca/easybuild/software/2017/Core/scipy-stack/2019a/lib/python3.7/site-packages, outside environment /localscratch/yinan.29028709.0/env
    Can't uninstall 'importlib-metadata'. No files were found to uninstall.
  Attempting uninstall: scipy
    Found existing installation: scipy 1.2.0
    Not uninstalling scipy at /cvmfs/soft.computecanada.ca/easybuild/software/2017/Core/scipy-stack/2019a/lib/python3.7/site-packages, outside environment /localscratch/yinan.29028709.0/env
    Can't uninstall 'scipy'. No files were found to uninstall.
Successfully installed absl-py-1.0.0+computecanada astunparse-1.6.3+computecanada cachetools-4.2.4+computecanada gast-0.3.3+computecanada google-auth-2.3.3+computecanada google-auth-oauthlib-0.4.6+computecanada google-pasta-0.2.0+computecanada grpcio-1.38.0+computecanada h5py-2.10.0+computecanada importlib-metadata-4.10.1+computecanada keras-preprocessing-1.1.2+computecanada markdown-3.3.6+computecanada oauthlib-3.1.1+computecanada opt-einsum-3.3.0+computecanada pyasn1-0.4.8+computecanada pyasn1-modules-0.2.8+computecanada requests-oauthlib-1.3.0+computecanada rsa-4.8+computecanada scipy-1.4.1+computecanada tensorboard-2.8.0+computecanada tensorboard-data-server-0.6.1+computecanada tensorboard-plugin-wit-1.8.0+computecanada tensorflow-estimator-2.3.0+computecanada tensorflow-gpu-2.3.0+computecanada werkzeug-2.0.3+computecanada wrapt-1.11.2+computecanada zipp-3.7.0+computecanada
Looking in links: /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/nix/avx2, /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/nix/generic, /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/keras-2.8.0+computecanada-py2.py3-none-any.whl
Installing collected packages: Keras
Successfully installed Keras-2.8.0+computecanada
Looking in links: /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/nix/avx2, /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/nix/generic, /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/urllib3-1.26.7+computecanada-py2.py3-none-any.whl
Installing collected packages: urllib3
  Attempting uninstall: urllib3
    Found existing installation: urllib3 1.26.8+computecanada
    Uninstalling urllib3-1.26.8+computecanada:
      Successfully uninstalled urllib3-1.26.8+computecanada
Successfully installed urllib3-1.26.7+computecanada
Looking in links: /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/nix/avx2, /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/nix/generic, /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/nltk-3.7+computecanada-py3-none-any.whl
Requirement already satisfied: tqdm in /localscratch/yinan.29028709.0/env/lib/python3.7/site-packages (from nltk) (4.63.0+computecanada)
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/nltk-3.6.5+computecanada-py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/nltk-3.6.3+computecanada-py3-none-any.whl
Requirement already satisfied: regex in /localscratch/yinan.29028709.0/env/lib/python3.7/site-packages (from nltk) (2020.11.13+computecanada)
Requirement already satisfied: click in /localscratch/yinan.29028709.0/env/lib/python3.7/site-packages (from nltk) (8.0.3+computecanada)
Requirement already satisfied: joblib in /localscratch/yinan.29028709.0/env/lib/python3.7/site-packages (from nltk) (1.1.0+computecanada)
Requirement already satisfied: importlib-metadata in /localscratch/yinan.29028709.0/env/lib/python3.7/site-packages (from click->nltk) (4.10.1+computecanada)
Requirement already satisfied: zipp>=0.5 in /localscratch/yinan.29028709.0/env/lib/python3.7/site-packages (from importlib-metadata->click->nltk) (3.7.0+computecanada)
Requirement already satisfied: typing-extensions>=3.6.4 in /localscratch/yinan.29028709.0/env/lib/python3.7/site-packages (from importlib-metadata->click->nltk) (4.0.1+computecanada)
Installing collected packages: nltk
Successfully installed nltk-3.6.3+computecanada
Looking in links: /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/nix/avx2, /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/nix/generic, /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/scikit_learn-0.22.1+computecanada-cp37-cp37m-linux_x86_64.whl
Requirement already satisfied: scipy>=0.17.0 in /localscratch/yinan.29028709.0/env/lib/python3.7/site-packages (from scikit-learn==0.22.1) (1.4.1+computecanada)
Requirement already satisfied: joblib>=0.11 in /localscratch/yinan.29028709.0/env/lib/python3.7/site-packages (from scikit-learn==0.22.1) (1.1.0+computecanada)
Requirement already satisfied: numpy>=1.11.0 in /cvmfs/soft.computecanada.ca/easybuild/software/2017/Core/scipy-stack/2019a/lib/python3.7/site-packages (from scikit-learn==0.22.1) (1.16.0)
Installing collected packages: scikit-learn
Successfully installed scikit-learn-0.22.1+computecanada
Looking in links: /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/nix/avx2, /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/nix/generic, /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic
Requirement already satisfied: tokenizers==0.5.2 in /localscratch/yinan.29028709.0/env/lib/python3.7/site-packages (0.5.2+computecanada)
wandb: Appending key for api.wandb.ai to your netrc file: /home/yinan/.netrc
Starting Task
2022-03-16 03:15:00.683117: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1
[nltk_data] Downloading package stopwords to /home/yinan/nltk_data...
[nltk_data]   Package stopwords is already up-to-date!
[nltk_data] Downloading package wordnet to /home/yinan/nltk_data...
[nltk_data]   Package wordnet is already up-to-date!
wandb: Currently logged in as: yinanazhou (use `wandb login --relogin` to force relogin)
wandb: wandb version 0.12.11 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
2022-03-16 03:15:19.479882: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1
wandb: Tracking run with wandb version 0.12.5
wandb: Syncing run lyric-donkey-2
wandb: â­ï¸ View project at https://wandb.ai/yinanazhou/xl_512_bs_8_lr_1e06_es_5_lc_True_nr_True_sr_True_stem_True_lemma_False_repeat_1_fold_1
wandb: ðŸš€ View run at https://wandb.ai/yinanazhou/xl_512_bs_8_lr_1e06_es_5_lc_True_nr_True_sr_True_stem_True_lemma_False_repeat_1_fold_1/runs/2j5iqy6s
wandb: Run data is saved locally in /project/6002780/yinan/Thesis_MER_Lyrics/lyric-emotion/wandb/run-20220316_031517-2j5iqy6s
wandb: Run `wandb offline` to turn off syncing.

Validation loss decreased (inf --> 1.430802).  Saving model ...
Validation loss decreased (1.430802 --> 1.412844).  Saving model ...
Validation loss decreased (1.412844 --> 1.397584).  Saving model ...
Validation loss decreased (1.397584 --> 1.386169).  Saving model ...
Validation loss decreased (1.386169 --> 1.377412).  Saving model ...
Validation loss decreased (1.377412 --> 1.369765).  Saving model ...
Validation loss decreased (1.369765 --> 1.364451).  Saving model ...
Validation loss decreased (1.364451 --> 1.359499).  Saving model ...
Validation loss decreased (1.359499 --> 1.355043).  Saving model ...
Validation loss decreased (1.355043 --> 1.350380).  Saving model ...
Validation loss decreased (1.350380 --> 1.346062).  Saving model ...
Validation loss decreased (1.346062 --> 1.342096).  Saving model ...
Validation loss decreased (1.342096 --> 1.338372).  Saving model ...
Validation loss decreased (1.338372 --> 1.334480).  Saving model ...
Validation loss decreased (1.334480 --> 1.330222).  Saving model ...
Validation loss decreased (1.330222 --> 1.326268).  Saving model ...
Validation loss decreased (1.326268 --> 1.322305).  Saving model ...
Validation loss decreased (1.322305 --> 1.318177).  Saving model ...
Validation loss decreased (1.318177 --> 1.313915).  Saving model ...
Validation loss decreased (1.313915 --> 1.308910).  Saving model ...
Validation loss decreased (1.308910 --> 1.304758).  Saving model ...
Validation loss decreased (1.304758 --> 1.300695).  Saving model ...
Validation loss decreased (1.300695 --> 1.296857).  Saving model ...
Validation loss decreased (1.296857 --> 1.292195).  Saving model ...
Validation loss decreased (1.292195 --> 1.287799).  Saving model ...
Validation loss decreased (1.287799 --> 1.283709).  Saving model ...
Validation loss decreased (1.283709 --> 1.279681).  Saving model ...
Validation loss decreased (1.279681 --> 1.276568).  Saving model ...
Validation loss decreased (1.276568 --> 1.274172).  Saving model ...
Validation loss decreased (1.274172 --> 1.271892).  Saving model ...
Validation loss decreased (1.271892 --> 1.269055).  Saving model ...
Validation loss decreased (1.269055 --> 1.264359).  Saving model ...
Validation loss decreased (1.264359 --> 1.263599).  Saving model ...
Validation loss decreased (1.263599 --> 1.258447).  Saving model ...
Validation loss decreased (1.258447 --> 1.258193).  Saving model ...
Validation loss decreased (1.258193 --> 1.254563).  Saving model ...
Validation loss decreased (1.254563 --> 1.252902).  Saving model ...
Validation loss decreased (1.252902 --> 1.249198).  Saving model ...
Validation loss decreased (1.249198 --> 1.247007).  Saving model ...
Validation loss decreased (1.247007 --> 1.244498).  Saving model ...
Validation loss decreased (1.244498 --> 1.240359).  Saving model ...
Validation loss decreased (1.240359 --> 1.235253).  Saving model ...
Validation loss decreased (1.235253 --> 1.232360).  Saving model ...
EarlyStopping counter: 1 out of 5.0
Validation loss decreased (1.232360 --> 1.229351).  Saving model ...
Validation loss decreased (1.229351 --> 1.226187).  Saving model ...
Validation loss decreased (1.226187 --> 1.225632).  Saving model ...
Validation loss decreased (1.225632 --> 1.222413).  Saving model ...
Validation loss decreased (1.222413 --> 1.221576).  Saving model ...
Validation loss decreased (1.221576 --> 1.217515).  Saving model ...
Validation loss decreased (1.217515 --> 1.217336).  Saving model ...
Validation loss decreased (1.217336 --> 1.213143).  Saving model ...
Validation loss decreased (1.213143 --> 1.211339).  Saving model ...
Validation loss decreased (1.211339 --> 1.209193).  Saving model ...
Validation loss decreased (1.209193 --> 1.207602).  Saving model ...
Validation loss decreased (1.207602 --> 1.202671).  Saving model ...
Validation loss decreased (1.202671 --> 1.198777).  Saving model ...
Validation loss decreased (1.198777 --> 1.195545).  Saving model ...
EarlyStopping counter: 1 out of 5.0
EarlyStopping counter: 2 out of 5.0
Validation loss decreased (1.195545 --> 1.188393).  Saving model ...
EarlyStopping counter: 1 out of 5.0
Validation loss decreased (1.188393 --> 1.181933).  Saving model ...
Validation loss decreased (1.181933 --> 1.181053).  Saving model ...
Validation loss decreased (1.181053 --> 1.180043).  Saving model ...
Validation loss decreased (1.180043 --> 1.174617).  Saving model ...
Validation loss decreased (1.174617 --> 1.173421).  Saving model ...
Validation loss decreased (1.173421 --> 1.170380).  Saving model ...
Validation loss decreased (1.170380 --> 1.168580).  Saving model ...
EarlyStopping counter: 1 out of 5.0
Validation loss decreased (1.168580 --> 1.166111).  Saving model ...
Validation loss decreased (1.166111 --> 1.165434).  Saving model ...
Validation loss decreased (1.165434 --> 1.162438).  Saving model ...
Validation loss decreased (1.162438 --> 1.155211).  Saving model ...
Validation loss decreased (1.155211 --> 1.152384).  Saving model ...
EarlyStopping counter: 1 out of 5.0
EarlyStopping counter: 2 out of 5.0
Validation loss decreased (1.152384 --> 1.148845).  Saving model ...
Validation loss decreased (1.148845 --> 1.145520).  Saving model ...
Validation loss decreased (1.145520 --> 1.142184).  Saving model ...
Validation loss decreased (1.142184 --> 1.141996).  Saving model ...
Validation loss decreased (1.141996 --> 1.141032).  Saving model ...
Validation loss decreased (1.141032 --> 1.139475).  Saving model ...
Validation loss decreased (1.139475 --> 1.138199).  Saving model ...
Validation loss decreased (1.138199 --> 1.132230).  Saving model ...
Validation loss decreased (1.132230 --> 1.126876).  Saving model ...
Validation loss decreased (1.126876 --> 1.126766).  Saving model ...
EarlyStopping counter: 1 out of 5.0
Validation loss decreased (1.126766 --> 1.125239).  Saving model ...
Validation loss decreased (1.125239 --> 1.123873).  Saving model ...
Validation loss decreased (1.123873 --> 1.120806).  Saving model ...
EarlyStopping counter: 1 out of 5.0
Validation loss decreased (1.120806 --> 1.120740).  Saving model ...
Validation loss decreased (1.120740 --> 1.119868).  Saving model ...
EarlyStopping counter: 1 out of 5.0
Validation loss decreased (1.119868 --> 1.116751).  Saving model ...
EarlyStopping counter: 1 out of 5.0
Validation loss decreased (1.116751 --> 1.114840).  Saving model ...
Validation loss decreased (1.114840 --> 1.111464).  Saving model ...
Validation loss decreased (1.111464 --> 1.111410).  Saving model ...
Validation loss decreased (1.111410 --> 1.111180).  Saving model ...
Validation loss decreased (1.111180 --> 1.109421).  Saving model ...
Validation loss decreased (1.109421 --> 1.103078).  Saving model ...
EarlyStopping counter: 1 out of 5.0
Validation loss decreased (1.103078 --> 1.102789).  Saving model ...
Validation loss decreased (1.102789 --> 1.098237).  Saving model ...
Validation loss decreased (1.098237 --> 1.095197).  Saving model ...
EarlyStopping counter: 1 out of 5.0
Validation loss decreased (1.095197 --> 1.094284).  Saving model ...
Validation loss decreased (1.094284 --> 1.087418).  Saving model ...
EarlyStopping counter: 1 out of 5.0
EarlyStopping counter: 2 out of 5.0
EarlyStopping counter: 3 out of 5.0
EarlyStopping counter: 4 out of 5.0
EarlyStopping counter: 5 out of 5.0
/localscratch/yinan.29028709.0/env/lib/python3.7/site-packages/torch/nn/functional.py:1794: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.
  warnings.warn("nn.functional.tanh is deprecated. Use torch.tanh instead.")
/localscratch/yinan.29028709.0/env/lib/python3.7/site-packages/transformers/optimization.py:155: UserWarning: This overload of add_ is deprecated:
	add_(Number alpha, Tensor other)
Consider using one of the following signatures instead:
	add_(Tensor other, *, Number alpha) (Triggered internally at  ../torch/csrc/utils/python_arg_parser.cpp:1025.)
  exp_avg.mul_(beta1).add_(1.0 - beta1, grad)
wandb: Waiting for W&B process to finish, PID 9811... (success).
wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: \ 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: | 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: / 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: \ 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: | 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: / 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: \ 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb:                                                                                
wandb: Run history:
wandb:     e_F1 â–â–‚â–ƒâ–„â–…â–…â–…â–…â–…â–…â–†â–†â–†â–†â–†â–†â–†â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ
wandb:   e_loss â–ˆâ–‡â–‡â–†â–†â–†â–†â–…â–…â–…â–…â–…â–„â–„â–„â–„â–„â–„â–„â–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–â–â–â–â–â–
wandb:     t_F1 â–â–‚â–ƒâ–ƒâ–ƒâ–ƒâ–„â–„â–„â–…â–„â–…â–…â–†â–†â–…â–†â–†â–†â–†â–‡â–‡â–†â–†â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–ˆâ–‡â–ˆâ–ˆâ–‡â–ˆâ–ˆ
wandb:   t_loss â–ˆâ–ˆâ–‡â–‡â–‡â–‡â–‡â–†â–†â–†â–…â–…â–…â–…â–…â–„â–„â–„â–„â–„â–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–â–‚â–â–
wandb: 
wandb: Run summary:
wandb:     e_F1 50.70225
wandb:   e_loss 1.08939
wandb:     t_F1 66.44114
wandb:   t_loss 0.85638
wandb: 
wandb: Synced 4 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Synced lyric-donkey-2: https://wandb.ai/yinanazhou/xl_512_bs_8_lr_1e06_es_5_lc_True_nr_True_sr_True_stem_True_lemma_False_repeat_1_fold_1/runs/2j5iqy6s
wandb: Find logs at: ./wandb/run-20220316_031517-2j5iqy6s/logs/debug.log
wandb: 

wandb: wandb version 0.12.11 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
2022-03-16 04:30:17.307796: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1
wandb: Tracking run with wandb version 0.12.5
wandb: Syncing run icy-haze-2
wandb: â­ï¸ View project at https://wandb.ai/yinanazhou/xl_512_bs_8_lr_1e06_es_5_lc_True_nr_True_sr_True_stem_True_lemma_False_repeat_1_fold_2
wandb: ðŸš€ View run at https://wandb.ai/yinanazhou/xl_512_bs_8_lr_1e06_es_5_lc_True_nr_True_sr_True_stem_True_lemma_False_repeat_1_fold_2/runs/38iy51ay
wandb: Run data is saved locally in /project/6002780/yinan/Thesis_MER_Lyrics/lyric-emotion/wandb/run-20220316_043014-38iy51ay
wandb: Run `wandb offline` to turn off syncing.

Validation loss decreased (inf --> 1.429004).  Saving model ...
Validation loss decreased (1.429004 --> 1.415296).  Saving model ...
Validation loss decreased (1.415296 --> 1.406395).  Saving model ...
Validation loss decreased (1.406395 --> 1.399192).  Saving model ...
Validation loss decreased (1.399192 --> 1.393254).  Saving model ...
Validation loss decreased (1.393254 --> 1.388325).  Saving model ...
Validation loss decreased (1.388325 --> 1.384678).  Saving model ...
Validation loss decreased (1.384678 --> 1.381327).  Saving model ...
Validation loss decreased (1.381327 --> 1.377974).  Saving model ...
Validation loss decreased (1.377974 --> 1.374655).  Saving model ...
Validation loss decreased (1.374655 --> 1.371583).  Saving model ...
Validation loss decreased (1.371583 --> 1.368376).  Saving model ...
Validation loss decreased (1.368376 --> 1.365546).  Saving model ...
Validation loss decreased (1.365546 --> 1.362571).  Saving model ...
Validation loss decreased (1.362571 --> 1.359507).  Saving model ...
Validation loss decreased (1.359507 --> 1.356481).  Saving model ...
Validation loss decreased (1.356481 --> 1.353746).  Saving model ...
Validation loss decreased (1.353746 --> 1.350866).  Saving model ...
Validation loss decreased (1.350866 --> 1.347892).  Saving model ...
Validation loss decreased (1.347892 --> 1.344798).  Saving model ...
Validation loss decreased (1.344798 --> 1.342013).  Saving model ...
Validation loss decreased (1.342013 --> 1.339012).  Saving model ...
Validation loss decreased (1.339012 --> 1.335664).  Saving model ...
Validation loss decreased (1.335664 --> 1.332528).  Saving model ...
Validation loss decreased (1.332528 --> 1.329046).  Saving model ...
Validation loss decreased (1.329046 --> 1.324884).  Saving model ...
Validation loss decreased (1.324884 --> 1.321414).  Saving model ...
Validation loss decreased (1.321414 --> 1.318026).  Saving model ...
Validation loss decreased (1.318026 --> 1.314330).  Saving model ...
Validation loss decreased (1.314330 --> 1.310519).  Saving model ...
Validation loss decreased (1.310519 --> 1.306465).  Saving model ...
Validation loss decreased (1.306465 --> 1.301827).  Saving model ...
Validation loss decreased (1.301827 --> 1.297660).  Saving model ...
Validation loss decreased (1.297660 --> 1.293411).  Saving model ...
Validation loss decreased (1.293411 --> 1.288000).  Saving model ...
Validation loss decreased (1.288000 --> 1.282367).  Saving model ...
Validation loss decreased (1.282367 --> 1.275923).  Saving model ...
Validation loss decreased (1.275923 --> 1.269628).  Saving model ...
Validation loss decreased (1.269628 --> 1.263763).  Saving model ...
Validation loss decreased (1.263763 --> 1.258115).  Saving model ...
Validation loss decreased (1.258115 --> 1.251745).  Saving model ...
Validation loss decreased (1.251745 --> 1.245387).  Saving model ...
Validation loss decreased (1.245387 --> 1.238761).  Saving model ...
Validation loss decreased (1.238761 --> 1.232266).  Saving model ...
Validation loss decreased (1.232266 --> 1.226515).  Saving model ...
Validation loss decreased (1.226515 --> 1.220234).  Saving model ...
Validation loss decreased (1.220234 --> 1.213293).  Saving model ...
Validation loss decreased (1.213293 --> 1.207292).  Saving model ...
Validation loss decreased (1.207292 --> 1.201706).  Saving model ...
Validation loss decreased (1.201706 --> 1.196136).  Saving model ...
Validation loss decreased (1.196136 --> 1.190042).  Saving model ...
Validation loss decreased (1.190042 --> 1.184805).  Saving model ...
Validation loss decreased (1.184805 --> 1.180651).  Saving model ...
Validation loss decreased (1.180651 --> 1.175726).  Saving model ...
Validation loss decreased (1.175726 --> 1.170496).  Saving model ...
Validation loss decreased (1.170496 --> 1.165380).  Saving model ...
Validation loss decreased (1.165380 --> 1.160597).  Saving model ...
Validation loss decreased (1.160597 --> 1.154874).  Saving model ...
Validation loss decreased (1.154874 --> 1.149553).  Saving model ...
Validation loss decreased (1.149553 --> 1.144204).  Saving model ...
Validation loss decreased (1.144204 --> 1.138827).  Saving model ...
Validation loss decreased (1.138827 --> 1.134348).  Saving model ...
Validation loss decreased (1.134348 --> 1.129323).  Saving model ...
Validation loss decreased (1.129323 --> 1.124179).  Saving model ...
Validation loss decreased (1.124179 --> 1.120449).  Saving model ...
Validation loss decreased (1.120449 --> 1.116892).  Saving model ...
Validation loss decreased (1.116892 --> 1.112831).  Saving model ...
Validation loss decreased (1.112831 --> 1.108191).  Saving model ...
Validation loss decreased (1.108191 --> 1.104451).  Saving model ...
Validation loss decreased (1.104451 --> 1.100931).  Saving model ...
Validation loss decreased (1.100931 --> 1.097074).  Saving model ...
Validation loss decreased (1.097074 --> 1.094288).  Saving model ...
Validation loss decreased (1.094288 --> 1.091089).  Saving model ...
Validation loss decreased (1.091089 --> 1.087174).  Saving model ...
Validation loss decreased (1.087174 --> 1.083130).  Saving model ...
Validation loss decreased (1.083130 --> 1.079267).  Saving model ...
Validation loss decreased (1.079267 --> 1.075948).  Saving model ...
Validation loss decreased (1.075948 --> 1.073067).  Saving model ...
Validation loss decreased (1.073067 --> 1.070348).  Saving model ...
Validation loss decreased (1.070348 --> 1.067822).  Saving model ...
Validation loss decreased (1.067822 --> 1.064842).  Saving model ...
Validation loss decreased (1.064842 --> 1.061684).  Saving model ...
Validation loss decreased (1.061684 --> 1.057582).  Saving model ...
Validation loss decreased (1.057582 --> 1.054783).  Saving model ...
Validation loss decreased (1.054783 --> 1.052268).  Saving model ...
Validation loss decreased (1.052268 --> 1.050413).  Saving model ...
Validation loss decreased (1.050413 --> 1.047915).  Saving model ...
Validation loss decreased (1.047915 --> 1.045343).  Saving model ...
Validation loss decreased (1.045343 --> 1.042692).  Saving model ...
Validation loss decreased (1.042692 --> 1.041075).  Saving model ...
Validation loss decreased (1.041075 --> 1.038060).  Saving model ...
Validation loss decreased (1.038060 --> 1.036938).  Saving model ...
Validation loss decreased (1.036938 --> 1.034380).  Saving model ...
Validation loss decreased (1.034380 --> 1.030912).  Saving model ...
Validation loss decreased (1.030912 --> 1.028637).  Saving model ...
Validation loss decreased (1.028637 --> 1.026263).  Saving model ...
Validation loss decreased (1.026263 --> 1.023660).  Saving model ...
Validation loss decreased (1.023660 --> 1.021691).  Saving model ...
Validation loss decreased (1.021691 --> 1.020419).  Saving model ...
Validation loss decreased (1.020419 --> 1.017888).  Saving model ...
Validation loss decreased (1.017888 --> 1.016590).  Saving model ...
Validation loss decreased (1.016590 --> 1.015410).  Saving model ...
Validation loss decreased (1.015410 --> 1.013809).  Saving model ...
Validation loss decreased (1.013809 --> 1.010937).  Saving model ...
Validation loss decreased (1.010937 --> 1.008874).  Saving model ...
Validation loss decreased (1.008874 --> 1.007830).  Saving model ...
Validation loss decreased (1.007830 --> 1.007293).  Saving model ...
Validation loss decreased (1.007293 --> 1.004893).  Saving model ...
Validation loss decreased (1.004893 --> 1.003806).  Saving model ...
Validation loss decreased (1.003806 --> 1.002450).  Saving model ...
Validation loss decreased (1.002450 --> 1.000147).  Saving model ...
Validation loss decreased (1.000147 --> 0.998011).  Saving model ...
Validation loss decreased (0.998011 --> 0.995998).  Saving model ...
Validation loss decreased (0.995998 --> 0.994675).  Saving model ...
Validation loss decreased (0.994675 --> 0.993985).  Saving model ...
Validation loss decreased (0.993985 --> 0.992735).  Saving model ...
Validation loss decreased (0.992735 --> 0.991096).  Saving model ...
Validation loss decreased (0.991096 --> 0.990210).  Saving model ...
Validation loss decreased (0.990210 --> 0.988618).  Saving model ...
Validation loss decreased (0.988618 --> 0.988186).  Saving model ...
Validation loss decreased (0.988186 --> 0.988149).  Saving model ...
Validation loss decreased (0.988149 --> 0.986830).  Saving model ...
Validation loss decreased (0.986830 --> 0.986606).  Saving model ...
Validation loss decreased (0.986606 --> 0.986156).  Saving model ...
Validation loss decreased (0.986156 --> 0.985204).  Saving model ...
Validation loss decreased (0.985204 --> 0.984650).  Saving model ...
Validation loss decreased (0.984650 --> 0.983429).  Saving model ...
Validation loss decreased (0.983429 --> 0.982161).  Saving model ...
Validation loss decreased (0.982161 --> 0.982084).  Saving model ...
Validation loss decreased (0.982084 --> 0.982064).  Saving model ...
EarlyStopping counter: 1 out of 5.0
Validation loss decreased (0.982064 --> 0.980030).  Saving model ...
EarlyStopping counter: 1 out of 5.0
EarlyStopping counter: 2 out of 5.0
Validation loss decreased (0.980030 --> 0.979170).  Saving model ...
Validation loss decreased (0.979170 --> 0.978690).  Saving model ...
EarlyStopping counter: 1 out of 5.0
Validation loss decreased (0.978690 --> 0.978447).  Saving model ...
Validation loss decreased (0.978447 --> 0.977163).  Saving model ...
Validation loss decreased (0.977163 --> 0.975998).  Saving model ...
EarlyStopping counter: 1 out of 5.0
EarlyStopping counter: 2 out of 5.0
Validation loss decreased (0.975998 --> 0.975610).  Saving model ...
Validation loss decreased (0.975610 --> 0.975089).  Saving model ...
EarlyStopping counter: 1 out of 5.0
Validation loss decreased (0.975089 --> 0.973981).  Saving model ...
EarlyStopping counter: 1 out of 5.0
EarlyStopping counter: 2 out of 5.0
EarlyStopping counter: 3 out of 5.0
Validation loss decreased (0.973981 --> 0.972828).  Saving model ...
EarlyStopping counter: 1 out of 5.0
EarlyStopping counter: 2 out of 5.0
EarlyStopping counter: 3 out of 5.0
EarlyStopping counter: 4 out of 5.0
EarlyStopping counter: 5 out of 5.0
/localscratch/yinan.29028709.0/env/lib/python3.7/site-packages/torch/nn/functional.py:1794: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.
  warnings.warn("nn.functional.tanh is deprecated. Use torch.tanh instead.")
wandb: Waiting for W&B process to finish, PID 13878... (success).
wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: \ 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: | 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: / 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: \ 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: | 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: / 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: \ 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: | 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: / 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb:                                                                                
wandb: Run history:
wandb:     e_F1 â–â–â–‚â–„â–„â–„â–„â–„â–„â–…â–…â–†â–†â–†â–†â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–ˆâ–‡â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ
wandb:   e_loss â–ˆâ–ˆâ–‡â–‡â–‡â–‡â–‡â–†â–†â–†â–†â–…â–…â–„â–„â–„â–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–‚â–‚â–‚â–‚â–‚â–‚â–‚â–â–â–â–â–â–â–â–â–â–â–â–
wandb:     t_F1 â–â–‚â–ƒâ–‚â–ƒâ–ƒâ–ƒâ–„â–„â–„â–„â–…â–…â–…â–…â–…â–†â–†â–†â–†â–‡â–†â–†â–†â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–ˆâ–‡â–ˆâ–‡â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ
wandb:   t_loss â–ˆâ–ˆâ–ˆâ–‡â–‡â–‡â–‡â–‡â–‡â–†â–†â–†â–†â–…â–…â–…â–…â–„â–…â–„â–„â–„â–„â–„â–ƒâ–ƒâ–ƒâ–ƒâ–‚â–‚â–‚â–‚â–‚â–‚â–‚â–â–â–â–â–
wandb: 
wandb: Run summary:
wandb:     e_F1 57.71674
wandb:   e_loss 0.97464
wandb:     t_F1 70.37135
wandb:   t_loss 0.81132
wandb: 
wandb: Synced 4 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Synced icy-haze-2: https://wandb.ai/yinanazhou/xl_512_bs_8_lr_1e06_es_5_lc_True_nr_True_sr_True_stem_True_lemma_False_repeat_1_fold_2/runs/38iy51ay
wandb: Find logs at: ./wandb/run-20220316_043014-38iy51ay/logs/debug.log
wandb: 

wandb: wandb version 0.12.11 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
2022-03-16 06:13:48.454662: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1
wandb: Tracking run with wandb version 0.12.5
wandb: Syncing run smart-sun-2
wandb: â­ï¸ View project at https://wandb.ai/yinanazhou/xl_512_bs_8_lr_1e06_es_5_lc_True_nr_True_sr_True_stem_True_lemma_False_repeat_2_fold_1
wandb: ðŸš€ View run at https://wandb.ai/yinanazhou/xl_512_bs_8_lr_1e06_es_5_lc_True_nr_True_sr_True_stem_True_lemma_False_repeat_2_fold_1/runs/3kbk4j4a
wandb: Run data is saved locally in /project/6002780/yinan/Thesis_MER_Lyrics/lyric-emotion/wandb/run-20220316_061345-3kbk4j4a
wandb: Run `wandb offline` to turn off syncing.

Validation loss decreased (inf --> 1.395643).  Saving model ...
Validation loss decreased (1.395643 --> 1.386950).  Saving model ...
Validation loss decreased (1.386950 --> 1.379661).  Saving model ...
Validation loss decreased (1.379661 --> 1.373592).  Saving model ...
Validation loss decreased (1.373592 --> 1.369102).  Saving model ...
Validation loss decreased (1.369102 --> 1.365174).  Saving model ...
Validation loss decreased (1.365174 --> 1.360836).  Saving model ...
Validation loss decreased (1.360836 --> 1.357223).  Saving model ...
Validation loss decreased (1.357223 --> 1.353794).  Saving model ...
Validation loss decreased (1.353794 --> 1.350342).  Saving model ...
Validation loss decreased (1.350342 --> 1.346825).  Saving model ...
Validation loss decreased (1.346825 --> 1.343385).  Saving model ...
Validation loss decreased (1.343385 --> 1.340101).  Saving model ...
Validation loss decreased (1.340101 --> 1.336503).  Saving model ...
Validation loss decreased (1.336503 --> 1.333420).  Saving model ...
Validation loss decreased (1.333420 --> 1.330108).  Saving model ...
Validation loss decreased (1.330108 --> 1.326466).  Saving model ...
Validation loss decreased (1.326466 --> 1.323086).  Saving model ...
Validation loss decreased (1.323086 --> 1.319037).  Saving model ...
Validation loss decreased (1.319037 --> 1.314950).  Saving model ...
Validation loss decreased (1.314950 --> 1.311070).  Saving model ...
Validation loss decreased (1.311070 --> 1.306696).  Saving model ...
Validation loss decreased (1.306696 --> 1.302943).  Saving model ...
Validation loss decreased (1.302943 --> 1.299881).  Saving model ...
Validation loss decreased (1.299881 --> 1.295706).  Saving model ...
Validation loss decreased (1.295706 --> 1.292057).  Saving model ...
Validation loss decreased (1.292057 --> 1.287452).  Saving model ...
Validation loss decreased (1.287452 --> 1.282763).  Saving model ...
Validation loss decreased (1.282763 --> 1.277774).  Saving model ...
Validation loss decreased (1.277774 --> 1.273536).  Saving model ...
Validation loss decreased (1.273536 --> 1.268879).  Saving model ...
Validation loss decreased (1.268879 --> 1.263862).  Saving model ...
Validation loss decreased (1.263862 --> 1.259497).  Saving model ...
Validation loss decreased (1.259497 --> 1.254444).  Saving model ...
Validation loss decreased (1.254444 --> 1.248850).  Saving model ...
Validation loss decreased (1.248850 --> 1.242769).  Saving model ...
Validation loss decreased (1.242769 --> 1.237338).  Saving model ...
Validation loss decreased (1.237338 --> 1.231503).  Saving model ...
Validation loss decreased (1.231503 --> 1.226179).  Saving model ...
Validation loss decreased (1.226179 --> 1.219926).  Saving model ...
Validation loss decreased (1.219926 --> 1.215751).  Saving model ...
Validation loss decreased (1.215751 --> 1.211415).  Saving model ...
Validation loss decreased (1.211415 --> 1.205401).  Saving model ...
Validation loss decreased (1.205401 --> 1.199317).  Saving model ...
Validation loss decreased (1.199317 --> 1.195339).  Saving model ...
Validation loss decreased (1.195339 --> 1.191733).  Saving model ...
Validation loss decreased (1.191733 --> 1.187833).  Saving model ...
Validation loss decreased (1.187833 --> 1.182969).  Saving model ...
Validation loss decreased (1.182969 --> 1.178115).  Saving model ...
Validation loss decreased (1.178115 --> 1.173372).  Saving model ...
Validation loss decreased (1.173372 --> 1.170006).  Saving model ...
Validation loss decreased (1.170006 --> 1.165818).  Saving model ...
Validation loss decreased (1.165818 --> 1.160983).  Saving model ...
Validation loss decreased (1.160983 --> 1.157644).  Saving model ...
Validation loss decreased (1.157644 --> 1.152993).  Saving model ...
Validation loss decreased (1.152993 --> 1.151328).  Saving model ...
Validation loss decreased (1.151328 --> 1.145220).  Saving model ...
Validation loss decreased (1.145220 --> 1.141251).  Saving model ...
Validation loss decreased (1.141251 --> 1.140080).  Saving model ...
Validation loss decreased (1.140080 --> 1.135998).  Saving model ...
Validation loss decreased (1.135998 --> 1.132450).  Saving model ...
Validation loss decreased (1.132450 --> 1.129750).  Saving model ...
Validation loss decreased (1.129750 --> 1.125948).  Saving model ...
Validation loss decreased (1.125948 --> 1.122608).  Saving model ...
Validation loss decreased (1.122608 --> 1.119907).  Saving model ...
Validation loss decreased (1.119907 --> 1.117432).  Saving model ...
Validation loss decreased (1.117432 --> 1.115762).  Saving model ...
Validation loss decreased (1.115762 --> 1.112921).  Saving model ...
Validation loss decreased (1.112921 --> 1.112504).  Saving model ...
Validation loss decreased (1.112504 --> 1.108603).  Saving model ...
Validation loss decreased (1.108603 --> 1.103973).  Saving model ...
Validation loss decreased (1.103973 --> 1.099910).  Saving model ...
Validation loss decreased (1.099910 --> 1.098683).  Saving model ...
Validation loss decreased (1.098683 --> 1.096136).  Saving model ...
Validation loss decreased (1.096136 --> 1.094784).  Saving model ...
Validation loss decreased (1.094784 --> 1.090451).  Saving model ...
Validation loss decreased (1.090451 --> 1.086735).  Saving model ...
Validation loss decreased (1.086735 --> 1.086504).  Saving model ...
Validation loss decreased (1.086504 --> 1.084594).  Saving model ...
Validation loss decreased (1.084594 --> 1.082106).  Saving model ...
Validation loss decreased (1.082106 --> 1.080786).  Saving model ...
Validation loss decreased (1.080786 --> 1.077001).  Saving model ...
Validation loss decreased (1.077001 --> 1.073731).  Saving model ...
Validation loss decreased (1.073731 --> 1.072310).  Saving model ...
Validation loss decreased (1.072310 --> 1.070591).  Saving model ...
Validation loss decreased (1.070591 --> 1.069363).  Saving model ...
Validation loss decreased (1.069363 --> 1.065618).  Saving model ...
Validation loss decreased (1.065618 --> 1.064013).  Saving model ...
Validation loss decreased (1.064013 --> 1.061913).  Saving model ...
Validation loss decreased (1.061913 --> 1.061000).  Saving model ...
EarlyStopping counter: 1 out of 5.0
Validation loss decreased (1.061000 --> 1.059476).  Saving model ...
EarlyStopping counter: 1 out of 5.0
Validation loss decreased (1.059476 --> 1.058885).  Saving model ...
Validation loss decreased (1.058885 --> 1.054602).  Saving model ...
Validation loss decreased (1.054602 --> 1.052448).  Saving model ...
Validation loss decreased (1.052448 --> 1.049910).  Saving model ...
EarlyStopping counter: 1 out of 5.0
EarlyStopping counter: 2 out of 5.0
Validation loss decreased (1.049910 --> 1.049713).  Saving model ...
EarlyStopping counter: 1 out of 5.0
Validation loss decreased (1.049713 --> 1.047546).  Saving model ...
Validation loss decreased (1.047546 --> 1.044393).  Saving model ...
Validation loss decreased (1.044393 --> 1.042192).  Saving model ...
EarlyStopping counter: 1 out of 5.0
Validation loss decreased (1.042192 --> 1.041650).  Saving model ...
EarlyStopping counter: 1 out of 5.0
Validation loss decreased (1.041650 --> 1.040940).  Saving model ...
Validation loss decreased (1.040940 --> 1.038138).  Saving model ...
Validation loss decreased (1.038138 --> 1.037962).  Saving model ...
EarlyStopping counter: 1 out of 5.0
EarlyStopping counter: 2 out of 5.0
EarlyStopping counter: 3 out of 5.0
Validation loss decreased (1.037962 --> 1.035274).  Saving model ...
Validation loss decreased (1.035274 --> 1.034141).  Saving model ...
Validation loss decreased (1.034141 --> 1.033672).  Saving model ...
Validation loss decreased (1.033672 --> 1.033490).  Saving model ...
EarlyStopping counter: 1 out of 5.0
Validation loss decreased (1.033490 --> 1.033019).  Saving model ...
Validation loss decreased (1.033019 --> 1.032709).  Saving model ...
Validation loss decreased (1.032709 --> 1.031890).  Saving model ...
EarlyStopping counter: 1 out of 5.0
EarlyStopping counter: 2 out of 5.0
EarlyStopping counter: 3 out of 5.0
EarlyStopping counter: 4 out of 5.0
Validation loss decreased (1.031890 --> 1.030378).  Saving model ...
EarlyStopping counter: 1 out of 5.0
EarlyStopping counter: 2 out of 5.0
EarlyStopping counter: 3 out of 5.0
Validation loss decreased (1.030378 --> 1.029658).  Saving model ...
Validation loss decreased (1.029658 --> 1.028371).  Saving model ...
EarlyStopping counter: 1 out of 5.0
EarlyStopping counter: 2 out of 5.0
Validation loss decreased (1.028371 --> 1.026891).  Saving model ...
Validation loss decreased (1.026891 --> 1.026256).  Saving model ...
EarlyStopping counter: 1 out of 5.0
EarlyStopping counter: 2 out of 5.0
EarlyStopping counter: 3 out of 5.0
EarlyStopping counter: 4 out of 5.0
EarlyStopping counter: 5 out of 5.0
/localscratch/yinan.29028709.0/env/lib/python3.7/site-packages/torch/nn/functional.py:1794: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.
  warnings.warn("nn.functional.tanh is deprecated. Use torch.tanh instead.")
wandb: Waiting for W&B process to finish, PID 19448... (success).
wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: \ 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: | 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: / 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: \ 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: | 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: / 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: \ 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb:                                                                                
wandb: Run history:
wandb:     e_F1 â–â–ƒâ–„â–…â–…â–…â–…â–†â–†â–†â–†â–†â–†â–†â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ
wandb:   e_loss â–ˆâ–ˆâ–‡â–‡â–‡â–‡â–†â–†â–†â–†â–…â–…â–„â–„â–„â–„â–ƒâ–ƒâ–ƒâ–ƒâ–‚â–‚â–‚â–‚â–‚â–‚â–‚â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:     t_F1 â–â–â–‚â–‚â–ƒâ–ƒâ–ƒâ–ƒâ–„â–„â–„â–…â–…â–…â–…â–…â–†â–…â–†â–‡â–†â–‡â–†â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ
wandb:   t_loss â–ˆâ–ˆâ–ˆâ–ˆâ–‡â–‡â–‡â–‡â–‡â–†â–†â–†â–…â–†â–…â–…â–„â–…â–„â–„â–„â–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–‚â–‚â–‚â–‚â–‚â–‚â–â–‚â–â–â–â–
wandb: 
wandb: Run summary:
wandb:     e_F1 53.85806
wandb:   e_loss 1.02793
wandb:     t_F1 69.33313
wandb:   t_loss 0.78256
wandb: 
wandb: Synced 4 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Synced smart-sun-2: https://wandb.ai/yinanazhou/xl_512_bs_8_lr_1e06_es_5_lc_True_nr_True_sr_True_stem_True_lemma_False_repeat_2_fold_1/runs/3kbk4j4a
wandb: Find logs at: ./wandb/run-20220316_061345-3kbk4j4a/logs/debug.log
wandb: 

wandb: wandb version 0.12.11 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
2022-03-16 07:47:28.199029: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1
wandb: Tracking run with wandb version 0.12.5
wandb: Syncing run bumbling-wave-1
wandb: â­ï¸ View project at https://wandb.ai/yinanazhou/xl_512_bs_8_lr_1e06_es_5_lc_True_nr_True_sr_True_stem_True_lemma_False_repeat_2_fold_2
wandb: ðŸš€ View run at https://wandb.ai/yinanazhou/xl_512_bs_8_lr_1e06_es_5_lc_True_nr_True_sr_True_stem_True_lemma_False_repeat_2_fold_2/runs/1qimx68f
wandb: Run data is saved locally in /project/6002780/yinan/Thesis_MER_Lyrics/lyric-emotion/wandb/run-20220316_074724-1qimx68f
wandb: Run `wandb offline` to turn off syncing.

Validation loss decreased (inf --> 1.398538).  Saving model ...
Validation loss decreased (1.398538 --> 1.391881).  Saving model ...
Validation loss decreased (1.391881 --> 1.385984).  Saving model ...
Validation loss decreased (1.385984 --> 1.380913).  Saving model ...
Validation loss decreased (1.380913 --> 1.376709).  Saving model ...
Validation loss decreased (1.376709 --> 1.372711).  Saving model ...
Validation loss decreased (1.372711 --> 1.369026).  Saving model ...
Validation loss decreased (1.369026 --> 1.365667).  Saving model ...
Validation loss decreased (1.365667 --> 1.362489).  Saving model ...
Validation loss decreased (1.362489 --> 1.359010).  Saving model ...
Validation loss decreased (1.359010 --> 1.355719).  Saving model ...
Validation loss decreased (1.355719 --> 1.352731).  Saving model ...
Validation loss decreased (1.352731 --> 1.349544).  Saving model ...
Validation loss decreased (1.349544 --> 1.346064).  Saving model ...
Validation loss decreased (1.346064 --> 1.342330).  Saving model ...
Validation loss decreased (1.342330 --> 1.338938).  Saving model ...
Validation loss decreased (1.338938 --> 1.335393).  Saving model ...
Validation loss decreased (1.335393 --> 1.331829).  Saving model ...
Validation loss decreased (1.331829 --> 1.328103).  Saving model ...
Validation loss decreased (1.328103 --> 1.324044).  Saving model ...
Validation loss decreased (1.324044 --> 1.320052).  Saving model ...
Validation loss decreased (1.320052 --> 1.315553).  Saving model ...
Validation loss decreased (1.315553 --> 1.310700).  Saving model ...
Validation loss decreased (1.310700 --> 1.305694).  Saving model ...
Validation loss decreased (1.305694 --> 1.301011).  Saving model ...
Validation loss decreased (1.301011 --> 1.296058).  Saving model ...
Validation loss decreased (1.296058 --> 1.290333).  Saving model ...
Validation loss decreased (1.290333 --> 1.285210).  Saving model ...
Validation loss decreased (1.285210 --> 1.279682).  Saving model ...
Validation loss decreased (1.279682 --> 1.275638).  Saving model ...
Validation loss decreased (1.275638 --> 1.270592).  Saving model ...
Validation loss decreased (1.270592 --> 1.265139).  Saving model ...
Validation loss decreased (1.265139 --> 1.260182).  Saving model ...
Validation loss decreased (1.260182 --> 1.255375).  Saving model ...
Validation loss decreased (1.255375 --> 1.250571).  Saving model ...
Validation loss decreased (1.250571 --> 1.245949).  Saving model ...
Validation loss decreased (1.245949 --> 1.240512).  Saving model ...
Validation loss decreased (1.240512 --> 1.235735).  Saving model ...
Validation loss decreased (1.235735 --> 1.232049).  Saving model ...
Validation loss decreased (1.232049 --> 1.227161).  Saving model ...
Validation loss decreased (1.227161 --> 1.221996).  Saving model ...
Validation loss decreased (1.221996 --> 1.217150).  Saving model ...
Validation loss decreased (1.217150 --> 1.212881).  Saving model ...
Validation loss decreased (1.212881 --> 1.208015).  Saving model ...
Validation loss decreased (1.208015 --> 1.202948).  Saving model ...
Validation loss decreased (1.202948 --> 1.199353).  Saving model ...
Validation loss decreased (1.199353 --> 1.195048).  Saving model ...
Validation loss decreased (1.195048 --> 1.191398).  Saving model ...
Validation loss decreased (1.191398 --> 1.186669).  Saving model ...
Validation loss decreased (1.186669 --> 1.182067).  Saving model ...
Validation loss decreased (1.182067 --> 1.176679).  Saving model ...
Validation loss decreased (1.176679 --> 1.174076).  Saving model ...
Validation loss decreased (1.174076 --> 1.169554).  Saving model ...
Validation loss decreased (1.169554 --> 1.164236).  Saving model ...
Validation loss decreased (1.164236 --> 1.160712).  Saving model ...
Validation loss decreased (1.160712 --> 1.158272).  Saving model ...
Validation loss decreased (1.158272 --> 1.153688).  Saving model ...
Validation loss decreased (1.153688 --> 1.149378).  Saving model ...
Validation loss decreased (1.149378 --> 1.145767).  Saving model ...
Validation loss decreased (1.145767 --> 1.141132).  Saving model ...
Validation loss decreased (1.141132 --> 1.137336).  Saving model ...
Validation loss decreased (1.137336 --> 1.131767).  Saving model ...
Validation loss decreased (1.131767 --> 1.126998).  Saving model ...
Validation loss decreased (1.126998 --> 1.120536).  Saving model ...
Validation loss decreased (1.120536 --> 1.119290).  Saving model ...
Validation loss decreased (1.119290 --> 1.116008).  Saving model ...
Validation loss decreased (1.116008 --> 1.112908).  Saving model ...
Validation loss decreased (1.112908 --> 1.109870).  Saving model ...
Validation loss decreased (1.109870 --> 1.109268).  Saving model ...
Validation loss decreased (1.109268 --> 1.104347).  Saving model ...
Validation loss decreased (1.104347 --> 1.100973).  Saving model ...
Validation loss decreased (1.100973 --> 1.096633).  Saving model ...
Validation loss decreased (1.096633 --> 1.091866).  Saving model ...
Validation loss decreased (1.091866 --> 1.088234).  Saving model ...
Validation loss decreased (1.088234 --> 1.084799).  Saving model ...
Validation loss decreased (1.084799 --> 1.082852).  Saving model ...
Validation loss decreased (1.082852 --> 1.078002).  Saving model ...
Validation loss decreased (1.078002 --> 1.075678).  Saving model ...
Validation loss decreased (1.075678 --> 1.071047).  Saving model ...
Validation loss decreased (1.071047 --> 1.067869).  Saving model ...
Validation loss decreased (1.067869 --> 1.063167).  Saving model ...
Validation loss decreased (1.063167 --> 1.060310).  Saving model ...
Validation loss decreased (1.060310 --> 1.057340).  Saving model ...
Validation loss decreased (1.057340 --> 1.054555).  Saving model ...
Validation loss decreased (1.054555 --> 1.052392).  Saving model ...
EarlyStopping counter: 1 out of 5.0
Validation loss decreased (1.052392 --> 1.050853).  Saving model ...
Validation loss decreased (1.050853 --> 1.047459).  Saving model ...
Validation loss decreased (1.047459 --> 1.043905).  Saving model ...
Validation loss decreased (1.043905 --> 1.039773).  Saving model ...
Validation loss decreased (1.039773 --> 1.038937).  Saving model ...
Validation loss decreased (1.038937 --> 1.038707).  Saving model ...
EarlyStopping counter: 1 out of 5.0
Validation loss decreased (1.038707 --> 1.035869).  Saving model ...
Validation loss decreased (1.035869 --> 1.029954).  Saving model ...
Validation loss decreased (1.029954 --> 1.028370).  Saving model ...
Validation loss decreased (1.028370 --> 1.025992).  Saving model ...
Validation loss decreased (1.025992 --> 1.021392).  Saving model ...
Validation loss decreased (1.021392 --> 1.016821).  Saving model ...
Validation loss decreased (1.016821 --> 1.016620).  Saving model ...
Validation loss decreased (1.016620 --> 1.013622).  Saving model ...
Validation loss decreased (1.013622 --> 1.012585).  Saving model ...
Validation loss decreased (1.012585 --> 1.010051).  Saving model ...
EarlyStopping counter: 1 out of 5.0
Validation loss decreased (1.010051 --> 1.008928).  Saving model ...
Validation loss decreased (1.008928 --> 1.006581).  Saving model ...
Validation loss decreased (1.006581 --> 1.005602).  Saving model ...
Validation loss decreased (1.005602 --> 1.003498).  Saving model ...
EarlyStopping counter: 1 out of 5.0
Validation loss decreased (1.003498 --> 1.003450).  Saving model ...
Validation loss decreased (1.003450 --> 1.000126).  Saving model ...
Validation loss decreased (1.000126 --> 0.997783).  Saving model ...
Validation loss decreased (0.997783 --> 0.997388).  Saving model ...
EarlyStopping counter: 1 out of 5.0
Validation loss decreased (0.997388 --> 0.994880).  Saving model ...
Validation loss decreased (0.994880 --> 0.991979).  Saving model ...
Validation loss decreased (0.991979 --> 0.989325).  Saving model ...
EarlyStopping counter: 1 out of 5.0
Validation loss decreased (0.989325 --> 0.988962).  Saving model ...
Validation loss decreased (0.988962 --> 0.987061).  Saving model ...
EarlyStopping counter: 1 out of 5.0
EarlyStopping counter: 2 out of 5.0
EarlyStopping counter: 3 out of 5.0
Validation loss decreased (0.987061 --> 0.982531).  Saving model ...
EarlyStopping counter: 1 out of 5.0
EarlyStopping counter: 2 out of 5.0
Validation loss decreased (0.982531 --> 0.980050).  Saving model ...
Validation loss decreased (0.980050 --> 0.979667).  Saving model ...
Validation loss decreased (0.979667 --> 0.977719).  Saving model ...
EarlyStopping counter: 1 out of 5.0
Validation loss decreased (0.977719 --> 0.975757).  Saving model ...
Validation loss decreased (0.975757 --> 0.972471).  Saving model ...
EarlyStopping counter: 1 out of 5.0
EarlyStopping counter: 2 out of 5.0
Validation loss decreased (0.972471 --> 0.971212).  Saving model ...
EarlyStopping counter: 1 out of 5.0
EarlyStopping counter: 2 out of 5.0
EarlyStopping counter: 3 out of 5.0
Validation loss decreased (0.971212 --> 0.966628).  Saving model ...
EarlyStopping counter: 1 out of 5.0
Validation loss decreased (0.966628 --> 0.964794).  Saving model ...
EarlyStopping counter: 1 out of 5.0
EarlyStopping counter: 2 out of 5.0
EarlyStopping counter: 3 out of 5.0
Validation loss decreased (0.964794 --> 0.964053).  Saving model ...
EarlyStopping counter: 1 out of 5.0
Validation loss decreased (0.964053 --> 0.961057).  Saving model ...
EarlyStopping counter: 1 out of 5.0
Validation loss decreased (0.961057 --> 0.959641).  Saving model ...
EarlyStopping counter: 1 out of 5.0
EarlyStopping counter: 2 out of 5.0
EarlyStopping counter: 3 out of 5.0
EarlyStopping counter: 4 out of 5.0
EarlyStopping counter: 5 out of 5.0
/localscratch/yinan.29028709.0/env/lib/python3.7/site-packages/torch/nn/functional.py:1794: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.
  warnings.warn("nn.functional.tanh is deprecated. Use torch.tanh instead.")
wandb: Waiting for W&B process to finish, PID 24492... (success).
wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: \ 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: | 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: / 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: \ 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: | 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: / 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: \ 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: | 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: / 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb:                                                                                
wandb: Run history:
wandb:     e_F1 â–â–‚â–ƒâ–„â–„â–…â–…â–…â–…â–…â–†â–†â–†â–†â–†â–†â–†â–†â–†â–†â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ
wandb:   e_loss â–ˆâ–ˆâ–ˆâ–‡â–‡â–‡â–‡â–†â–†â–†â–…â–…â–…â–„â–„â–„â–„â–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–‚â–‚â–‚â–‚â–‚â–‚â–‚â–â–â–â–â–â–â–â–â–â–
wandb:     t_F1 â–â–â–ƒâ–‚â–ƒâ–ƒâ–„â–ƒâ–„â–„â–„â–…â–…â–†â–†â–…â–†â–†â–†â–†â–†â–†â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–ˆâ–‡â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ
wandb:   t_loss â–ˆâ–ˆâ–ˆâ–ˆâ–‡â–‡â–‡â–‡â–‡â–†â–†â–†â–†â–…â–…â–…â–…â–„â–„â–„â–„â–„â–„â–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–‚â–‚â–‚â–‚â–‚â–‚â–â–â–â–â–
wandb: 
wandb: Run summary:
wandb:     e_F1 58.31006
wandb:   e_loss 0.96162
wandb:     t_F1 66.50103
wandb:   t_loss 0.81838
wandb: 
wandb: Synced 4 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Synced bumbling-wave-1: https://wandb.ai/yinanazhou/xl_512_bs_8_lr_1e06_es_5_lc_True_nr_True_sr_True_stem_True_lemma_False_repeat_2_fold_2/runs/1qimx68f
wandb: Find logs at: ./wandb/run-20220316_074724-1qimx68f/logs/debug.log
wandb: 

wandb: wandb version 0.12.11 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
2022-03-16 09:25:01.458125: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1
wandb: Tracking run with wandb version 0.12.5
wandb: Syncing run iconic-armadillo-1
wandb: â­ï¸ View project at https://wandb.ai/yinanazhou/xl_512_bs_8_lr_1e06_es_5_lc_True_nr_True_sr_True_stem_True_lemma_False_repeat_3_fold_1
wandb: ðŸš€ View run at https://wandb.ai/yinanazhou/xl_512_bs_8_lr_1e06_es_5_lc_True_nr_True_sr_True_stem_True_lemma_False_repeat_3_fold_1/runs/egd31jcx
wandb: Run data is saved locally in /project/6002780/yinan/Thesis_MER_Lyrics/lyric-emotion/wandb/run-20220316_092458-egd31jcx
wandb: Run `wandb offline` to turn off syncing.

Validation loss decreased (inf --> 1.467952).  Saving model ...
Validation loss decreased (1.467952 --> 1.438355).  Saving model ...
Validation loss decreased (1.438355 --> 1.418067).  Saving model ...
Validation loss decreased (1.418067 --> 1.403028).  Saving model ...
Validation loss decreased (1.403028 --> 1.391842).  Saving model ...
Validation loss decreased (1.391842 --> 1.383062).  Saving model ...
Validation loss decreased (1.383062 --> 1.376088).  Saving model ...
Validation loss decreased (1.376088 --> 1.370820).  Saving model ...
Validation loss decreased (1.370820 --> 1.366663).  Saving model ...
Validation loss decreased (1.366663 --> 1.363076).  Saving model ...
Validation loss decreased (1.363076 --> 1.359760).  Saving model ...
Validation loss decreased (1.359760 --> 1.356624).  Saving model ...
Validation loss decreased (1.356624 --> 1.353307).  Saving model ...
Validation loss decreased (1.353307 --> 1.350595).  Saving model ...
Validation loss decreased (1.350595 --> 1.347347).  Saving model ...
Validation loss decreased (1.347347 --> 1.344004).  Saving model ...
Validation loss decreased (1.344004 --> 1.340863).  Saving model ...
Validation loss decreased (1.340863 --> 1.337810).  Saving model ...
Validation loss decreased (1.337810 --> 1.334580).  Saving model ...
Validation loss decreased (1.334580 --> 1.331187).  Saving model ...
Validation loss decreased (1.331187 --> 1.328208).  Saving model ...
Validation loss decreased (1.328208 --> 1.324638).  Saving model ...
Validation loss decreased (1.324638 --> 1.321244).  Saving model ...
Validation loss decreased (1.321244 --> 1.317392).  Saving model ...
Validation loss decreased (1.317392 --> 1.313602).  Saving model ...
Validation loss decreased (1.313602 --> 1.309680).  Saving model ...
Validation loss decreased (1.309680 --> 1.306003).  Saving model ...
Validation loss decreased (1.306003 --> 1.301642).  Saving model ...
Validation loss decreased (1.301642 --> 1.297426).  Saving model ...
Validation loss decreased (1.297426 --> 1.292515).  Saving model ...
Validation loss decreased (1.292515 --> 1.286892).  Saving model ...
Validation loss decreased (1.286892 --> 1.281766).  Saving model ...
Validation loss decreased (1.281766 --> 1.276151).  Saving model ...
Validation loss decreased (1.276151 --> 1.272147).  Saving model ...
Validation loss decreased (1.272147 --> 1.265281).  Saving model ...
Validation loss decreased (1.265281 --> 1.259893).  Saving model ...
Validation loss decreased (1.259893 --> 1.255111).  Saving model ...
Validation loss decreased (1.255111 --> 1.250188).  Saving model ...
Validation loss decreased (1.250188 --> 1.243809).  Saving model ...
Validation loss decreased (1.243809 --> 1.238016).  Saving model ...
Validation loss decreased (1.238016 --> 1.233353).  Saving model ...
Validation loss decreased (1.233353 --> 1.227188).  Saving model ...
Validation loss decreased (1.227188 --> 1.222879).  Saving model ...
Validation loss decreased (1.222879 --> 1.219293).  Saving model ...
Validation loss decreased (1.219293 --> 1.213533).  Saving model ...
Validation loss decreased (1.213533 --> 1.209367).  Saving model ...
Validation loss decreased (1.209367 --> 1.205347).  Saving model ...
Validation loss decreased (1.205347 --> 1.200909).  Saving model ...
Validation loss decreased (1.200909 --> 1.196808).  Saving model ...
Validation loss decreased (1.196808 --> 1.192591).  Saving model ...
Validation loss decreased (1.192591 --> 1.188557).  Saving model ...
Validation loss decreased (1.188557 --> 1.183843).  Saving model ...
Validation loss decreased (1.183843 --> 1.182291).  Saving model ...
Validation loss decreased (1.182291 --> 1.179749).  Saving model ...
Validation loss decreased (1.179749 --> 1.175020).  Saving model ...
Validation loss decreased (1.175020 --> 1.171735).  Saving model ...
Validation loss decreased (1.171735 --> 1.166788).  Saving model ...
Validation loss decreased (1.166788 --> 1.163570).  Saving model ...
Validation loss decreased (1.163570 --> 1.161230).  Saving model ...
Validation loss decreased (1.161230 --> 1.159008).  Saving model ...
Validation loss decreased (1.159008 --> 1.156085).  Saving model ...
Validation loss decreased (1.156085 --> 1.150357).  Saving model ...
Validation loss decreased (1.150357 --> 1.147472).  Saving model ...
Validation loss decreased (1.147472 --> 1.142789).  Saving model ...
Validation loss decreased (1.142789 --> 1.137890).  Saving model ...
Validation loss decreased (1.137890 --> 1.136291).  Saving model ...
Validation loss decreased (1.136291 --> 1.135686).  Saving model ...
Validation loss decreased (1.135686 --> 1.132016).  Saving model ...
Validation loss decreased (1.132016 --> 1.128436).  Saving model ...
Validation loss decreased (1.128436 --> 1.126486).  Saving model ...
Validation loss decreased (1.126486 --> 1.123063).  Saving model ...
Validation loss decreased (1.123063 --> 1.117836).  Saving model ...
Validation loss decreased (1.117836 --> 1.114884).  Saving model ...
EarlyStopping counter: 1 out of 5.0
Validation loss decreased (1.114884 --> 1.112336).  Saving model ...
Validation loss decreased (1.112336 --> 1.110393).  Saving model ...
Validation loss decreased (1.110393 --> 1.106590).  Saving model ...
Validation loss decreased (1.106590 --> 1.106232).  Saving model ...
Validation loss decreased (1.106232 --> 1.104608).  Saving model ...
Validation loss decreased (1.104608 --> 1.099677).  Saving model ...
Validation loss decreased (1.099677 --> 1.097444).  Saving model ...
Validation loss decreased (1.097444 --> 1.091504).  Saving model ...
EarlyStopping counter: 1 out of 5.0
Validation loss decreased (1.091504 --> 1.089910).  Saving model ...
Validation loss decreased (1.089910 --> 1.086795).  Saving model ...
Validation loss decreased (1.086795 --> 1.084349).  Saving model ...
Validation loss decreased (1.084349 --> 1.081410).  Saving model ...
Validation loss decreased (1.081410 --> 1.080557).  Saving model ...
Validation loss decreased (1.080557 --> 1.079525).  Saving model ...
Validation loss decreased (1.079525 --> 1.075441).  Saving model ...
EarlyStopping counter: 1 out of 5.0
EarlyStopping counter: 2 out of 5.0
Validation loss decreased (1.075441 --> 1.075136).  Saving model ...
Validation loss decreased (1.075136 --> 1.070797).  Saving model ...
Validation loss decreased (1.070797 --> 1.067430).  Saving model ...
Validation loss decreased (1.067430 --> 1.064793).  Saving model ...
Validation loss decreased (1.064793 --> 1.062644).  Saving model ...
Validation loss decreased (1.062644 --> 1.062601).  Saving model ...
Validation loss decreased (1.062601 --> 1.057097).  Saving model ...
Validation loss decreased (1.057097 --> 1.057038).  Saving model ...
EarlyStopping counter: 1 out of 5.0
EarlyStopping counter: 2 out of 5.0
EarlyStopping counter: 3 out of 5.0
Validation loss decreased (1.057038 --> 1.056486).  Saving model ...
Validation loss decreased (1.056486 --> 1.054703).  Saving model ...
Validation loss decreased (1.054703 --> 1.053221).  Saving model ...
Validation loss decreased (1.053221 --> 1.051536).  Saving model ...
Validation loss decreased (1.051536 --> 1.049225).  Saving model ...
Validation loss decreased (1.049225 --> 1.047238).  Saving model ...
Validation loss decreased (1.047238 --> 1.042138).  Saving model ...
EarlyStopping counter: 1 out of 5.0
Validation loss decreased (1.042138 --> 1.038282).  Saving model ...
Validation loss decreased (1.038282 --> 1.035756).  Saving model ...
Validation loss decreased (1.035756 --> 1.033292).  Saving model ...
EarlyStopping counter: 1 out of 5.0
EarlyStopping counter: 2 out of 5.0
EarlyStopping counter: 3 out of 5.0
Validation loss decreased (1.033292 --> 1.032643).  Saving model ...
EarlyStopping counter: 1 out of 5.0
Validation loss decreased (1.032643 --> 1.028736).  Saving model ...
EarlyStopping counter: 1 out of 5.0
EarlyStopping counter: 2 out of 5.0
EarlyStopping counter: 3 out of 5.0
EarlyStopping counter: 4 out of 5.0
EarlyStopping counter: 5 out of 5.0
/localscratch/yinan.29028709.0/env/lib/python3.7/site-packages/torch/nn/functional.py:1794: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.
  warnings.warn("nn.functional.tanh is deprecated. Use torch.tanh instead.")
wandb: Waiting for W&B process to finish, PID 29888... (success).
wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: \ 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: | 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: / 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: \ 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: | 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: / 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: \ 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: | 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: / 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb:                                                                                
wandb: Run history:
wandb:     e_F1 â–â–‚â–ƒâ–„â–…â–…â–…â–…â–…â–†â–†â–†â–†â–†â–†â–†â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–ˆâ–‡â–‡â–ˆâ–‡â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ
wandb:   e_loss â–ˆâ–‡â–‡â–†â–†â–†â–†â–†â–…â–…â–…â–…â–„â–„â–„â–„â–„â–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–â–â–â–â–â–â–â–â–
wandb:     t_F1 â–â–â–‚â–‚â–ƒâ–ƒâ–„â–„â–„â–„â–…â–…â–…â–…â–…â–†â–…â–†â–†â–†â–†â–†â–†â–†â–‡â–†â–‡â–‡â–‡â–‡â–‡â–‡â–ˆâ–ˆâ–‡â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ
wandb:   t_loss â–ˆâ–ˆâ–‡â–‡â–‡â–‡â–†â–†â–†â–†â–†â–†â–…â–…â–…â–…â–…â–„â–„â–„â–„â–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–‚â–‚â–‚â–‚â–‚â–‚â–â–â–â–â–â–
wandb: 
wandb: Run summary:
wandb:     e_F1 54.54283
wandb:   e_loss 1.02917
wandb:     t_F1 68.37117
wandb:   t_loss 0.84615
wandb: 
wandb: Synced 4 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Synced iconic-armadillo-1: https://wandb.ai/yinanazhou/xl_512_bs_8_lr_1e06_es_5_lc_True_nr_True_sr_True_stem_True_lemma_False_repeat_3_fold_1/runs/egd31jcx
wandb: Find logs at: ./wandb/run-20220316_092458-egd31jcx/logs/debug.log
wandb: 

wandb: wandb version 0.12.11 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
2022-03-16 10:46:13.573559: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1
wandb: Tracking run with wandb version 0.12.5
wandb: Syncing run deft-resonance-1
wandb: â­ï¸ View project at https://wandb.ai/yinanazhou/xl_512_bs_8_lr_1e06_es_5_lc_True_nr_True_sr_True_stem_True_lemma_False_repeat_3_fold_2
wandb: ðŸš€ View run at https://wandb.ai/yinanazhou/xl_512_bs_8_lr_1e06_es_5_lc_True_nr_True_sr_True_stem_True_lemma_False_repeat_3_fold_2/runs/11kwf1s0
wandb: Run data is saved locally in /project/6002780/yinan/Thesis_MER_Lyrics/lyric-emotion/wandb/run-20220316_104610-11kwf1s0
wandb: Run `wandb offline` to turn off syncing.

Validation loss decreased (inf --> 1.416386).  Saving model ...
Validation loss decreased (1.416386 --> 1.402849).  Saving model ...
Validation loss decreased (1.402849 --> 1.392287).  Saving model ...
Validation loss decreased (1.392287 --> 1.384690).  Saving model ...
Validation loss decreased (1.384690 --> 1.378128).  Saving model ...
Validation loss decreased (1.378128 --> 1.372374).  Saving model ...
Validation loss decreased (1.372374 --> 1.368143).  Saving model ...
Validation loss decreased (1.368143 --> 1.363796).  Saving model ...
Validation loss decreased (1.363796 --> 1.359834).  Saving model ...
Validation loss decreased (1.359834 --> 1.355695).  Saving model ...
Validation loss decreased (1.355695 --> 1.351665).  Saving model ...
Validation loss decreased (1.351665 --> 1.347694).  Saving model ...
Validation loss decreased (1.347694 --> 1.344046).  Saving model ...
Validation loss decreased (1.344046 --> 1.340259).  Saving model ...
Validation loss decreased (1.340259 --> 1.336004).  Saving model ...
Validation loss decreased (1.336004 --> 1.331822).  Saving model ...
Validation loss decreased (1.331822 --> 1.327824).  Saving model ...
Validation loss decreased (1.327824 --> 1.323273).  Saving model ...
Validation loss decreased (1.323273 --> 1.318643).  Saving model ...
Validation loss decreased (1.318643 --> 1.313971).  Saving model ...
Validation loss decreased (1.313971 --> 1.309570).  Saving model ...
Validation loss decreased (1.309570 --> 1.304505).  Saving model ...
Validation loss decreased (1.304505 --> 1.299027).  Saving model ...
Validation loss decreased (1.299027 --> 1.293746).  Saving model ...
Validation loss decreased (1.293746 --> 1.288038).  Saving model ...
Validation loss decreased (1.288038 --> 1.282604).  Saving model ...
Validation loss decreased (1.282604 --> 1.277006).  Saving model ...
Validation loss decreased (1.277006 --> 1.271091).  Saving model ...
Validation loss decreased (1.271091 --> 1.265165).  Saving model ...
Validation loss decreased (1.265165 --> 1.259509).  Saving model ...
Validation loss decreased (1.259509 --> 1.253196).  Saving model ...
Validation loss decreased (1.253196 --> 1.246849).  Saving model ...
Validation loss decreased (1.246849 --> 1.241489).  Saving model ...
Validation loss decreased (1.241489 --> 1.235735).  Saving model ...
Validation loss decreased (1.235735 --> 1.230479).  Saving model ...
Validation loss decreased (1.230479 --> 1.225294).  Saving model ...
Validation loss decreased (1.225294 --> 1.219912).  Saving model ...
Validation loss decreased (1.219912 --> 1.214457).  Saving model ...
Validation loss decreased (1.214457 --> 1.208535).  Saving model ...
Validation loss decreased (1.208535 --> 1.203655).  Saving model ...
Validation loss decreased (1.203655 --> 1.198729).  Saving model ...
Validation loss decreased (1.198729 --> 1.193635).  Saving model ...
Validation loss decreased (1.193635 --> 1.188391).  Saving model ...
Validation loss decreased (1.188391 --> 1.183353).  Saving model ...
Validation loss decreased (1.183353 --> 1.179885).  Saving model ...
Validation loss decreased (1.179885 --> 1.176205).  Saving model ...
Validation loss decreased (1.176205 --> 1.171938).  Saving model ...
Validation loss decreased (1.171938 --> 1.168301).  Saving model ...
Validation loss decreased (1.168301 --> 1.163122).  Saving model ...
Validation loss decreased (1.163122 --> 1.158259).  Saving model ...
Validation loss decreased (1.158259 --> 1.154167).  Saving model ...
Validation loss decreased (1.154167 --> 1.149661).  Saving model ...
Validation loss decreased (1.149661 --> 1.145596).  Saving model ...
Validation loss decreased (1.145596 --> 1.140854).  Saving model ...
Validation loss decreased (1.140854 --> 1.136139).  Saving model ...
Validation loss decreased (1.136139 --> 1.132501).  Saving model ...
Validation loss decreased (1.132501 --> 1.129328).  Saving model ...
Validation loss decreased (1.129328 --> 1.125485).  Saving model ...
Validation loss decreased (1.125485 --> 1.123421).  Saving model ...
Validation loss decreased (1.123421 --> 1.120308).  Saving model ...
Validation loss decreased (1.120308 --> 1.117166).  Saving model ...
Validation loss decreased (1.117166 --> 1.113300).  Saving model ...
Validation loss decreased (1.113300 --> 1.109657).  Saving model ...
Validation loss decreased (1.109657 --> 1.106396).  Saving model ...
Validation loss decreased (1.106396 --> 1.101725).  Saving model ...
Validation loss decreased (1.101725 --> 1.099717).  Saving model ...
Validation loss decreased (1.099717 --> 1.095808).  Saving model ...
Validation loss decreased (1.095808 --> 1.092654).  Saving model ...
Validation loss decreased (1.092654 --> 1.090130).  Saving model ...
Validation loss decreased (1.090130 --> 1.087526).  Saving model ...
Validation loss decreased (1.087526 --> 1.085411).  Saving model ...
Validation loss decreased (1.085411 --> 1.081972).  Saving model ...
Validation loss decreased (1.081972 --> 1.079706).  Saving model ...
Validation loss decreased (1.079706 --> 1.076804).  Saving model ...
Validation loss decreased (1.076804 --> 1.073880).  Saving model ...
Validation loss decreased (1.073880 --> 1.071027).  Saving model ...
Validation loss decreased (1.071027 --> 1.069277).  Saving model ...
Validation loss decreased (1.069277 --> 1.067188).  Saving model ...
Validation loss decreased (1.067188 --> 1.064772).  Saving model ...
Validation loss decreased (1.064772 --> 1.062705).  Saving model ...
Validation loss decreased (1.062705 --> 1.060302).  Saving model ...
Validation loss decreased (1.060302 --> 1.057720).  Saving model ...
Validation loss decreased (1.057720 --> 1.055009).  Saving model ...
Validation loss decreased (1.055009 --> 1.052916).  Saving model ...
Validation loss decreased (1.052916 --> 1.050091).  Saving model ...
Validation loss decreased (1.050091 --> 1.047195).  Saving model ...
Validation loss decreased (1.047195 --> 1.043850).  Saving model ...
Validation loss decreased (1.043850 --> 1.041748).  Saving model ...
Validation loss decreased (1.041748 --> 1.040121).  Saving model ...
Validation loss decreased (1.040121 --> 1.039396).  Saving model ...
Validation loss decreased (1.039396 --> 1.036700).  Saving model ...
Validation loss decreased (1.036700 --> 1.034134).  Saving model ...
Validation loss decreased (1.034134 --> 1.032270).  Saving model ...
Validation loss decreased (1.032270 --> 1.030095).  Saving model ...
Validation loss decreased (1.030095 --> 1.028399).  Saving model ...
Validation loss decreased (1.028399 --> 1.026726).  Saving model ...
Validation loss decreased (1.026726 --> 1.023515).  Saving model ...
Validation loss decreased (1.023515 --> 1.020514).  Saving model ...
Validation loss decreased (1.020514 --> 1.019730).  Saving model ...
Validation loss decreased (1.019730 --> 1.017893).  Saving model ...
Validation loss decreased (1.017893 --> 1.016663).  Saving model ...
EarlyStopping counter: 1 out of 5.0
Validation loss decreased (1.016663 --> 1.013910).  Saving model ...
Validation loss decreased (1.013910 --> 1.012462).  Saving model ...
Validation loss decreased (1.012462 --> 1.009934).  Saving model ...
Validation loss decreased (1.009934 --> 1.007963).  Saving model ...
Validation loss decreased (1.007963 --> 1.006825).  Saving model ...
Validation loss decreased (1.006825 --> 1.004817).  Saving model ...
Validation loss decreased (1.004817 --> 1.003485).  Saving model ...
Validation loss decreased (1.003485 --> 1.002915).  Saving model ...
Validation loss decreased (1.002915 --> 1.002279).  Saving model ...
Validation loss decreased (1.002279 --> 1.000307).  Saving model ...
Validation loss decreased (1.000307 --> 0.998344).  Saving model ...
Validation loss decreased (0.998344 --> 0.995778).  Saving model ...
Validation loss decreased (0.995778 --> 0.993785).  Saving model ...
Validation loss decreased (0.993785 --> 0.991806).  Saving model ...
Validation loss decreased (0.991806 --> 0.990292).  Saving model ...
EarlyStopping counter: 1 out of 5.0
Validation loss decreased (0.990292 --> 0.989814).  Saving model ...
EarlyStopping counter: 1 out of 5.0
Validation loss decreased (0.989814 --> 0.988575).  Saving model ...
Validation loss decreased (0.988575 --> 0.987335).  Saving model ...
Validation loss decreased (0.987335 --> 0.987009).  Saving model ...
Validation loss decreased (0.987009 --> 0.984940).  Saving model ...
Validation loss decreased (0.984940 --> 0.984491).  Saving model ...
Validation loss decreased (0.984491 --> 0.983154).  Saving model ...
Validation loss decreased (0.983154 --> 0.982212).  Saving model ...
Validation loss decreased (0.982212 --> 0.981605).  Saving model ...
Validation loss decreased (0.981605 --> 0.980641).  Saving model ...
Validation loss decreased (0.980641 --> 0.980038).  Saving model ...
Validation loss decreased (0.980038 --> 0.978520).  Saving model ...
EarlyStopping counter: 1 out of 5.0
Validation loss decreased (0.978520 --> 0.976979).  Saving model ...
Validation loss decreased (0.976979 --> 0.974947).  Saving model ...
Validation loss decreased (0.974947 --> 0.974468).  Saving model ...
EarlyStopping counter: 1 out of 5.0
Validation loss decreased (0.974468 --> 0.973509).  Saving model ...
Validation loss decreased (0.973509 --> 0.972920).  Saving model ...
EarlyStopping counter: 1 out of 5.0
Validation loss decreased (0.972920 --> 0.972318).  Saving model ...
EarlyStopping counter: 1 out of 5.0
Validation loss decreased (0.972318 --> 0.972127).  Saving model ...
Validation loss decreased (0.972127 --> 0.971528).  Saving model ...
Validation loss decreased (0.971528 --> 0.969522).  Saving model ...
Validation loss decreased (0.969522 --> 0.969250).  Saving model ...
Validation loss decreased (0.969250 --> 0.968620).  Saving model ...
Validation loss decreased (0.968620 --> 0.968259).  Saving model ...
Validation loss decreased (0.968259 --> 0.967723).  Saving model ...
Validation loss decreased (0.967723 --> 0.966999).  Saving model ...
EarlyStopping counter: 1 out of 5.0
EarlyStopping counter: 2 out of 5.0
EarlyStopping counter: 3 out of 5.0
EarlyStopping counter: 4 out of 5.0
EarlyStopping counter: 5 out of 5.0
/localscratch/yinan.29028709.0/env/lib/python3.7/site-packages/torch/nn/functional.py:1794: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.
  warnings.warn("nn.functional.tanh is deprecated. Use torch.tanh instead.")
wandb: Waiting for W&B process to finish, PID 34304... (success).
wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: \ 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: | 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: / 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: \ 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: | 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: / 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: \ 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: | 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: / 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb:                                                                                
wandb: Run history:
wandb:     e_F1 â–â–â–ƒâ–„â–„â–…â–…â–…â–†â–†â–†â–†â–†â–†â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ
wandb:   e_loss â–ˆâ–ˆâ–‡â–‡â–‡â–‡â–†â–†â–…â–…â–…â–„â–„â–„â–„â–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–â–â–â–â–â–â–â–â–â–â–
wandb:     t_F1 â–â–‚â–‚â–ƒâ–ƒâ–ƒâ–ƒâ–„â–„â–…â–…â–…â–†â–†â–…â–†â–†â–†â–†â–†â–†â–†â–†â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–ˆâ–ˆâ–‡â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ
wandb:   t_loss â–ˆâ–ˆâ–ˆâ–‡â–‡â–‡â–‡â–†â–†â–†â–…â–…â–…â–…â–…â–…â–„â–„â–„â–„â–„â–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–‚â–‚â–‚â–‚â–‚â–‚â–‚â–â–â–â–â–
wandb: 
wandb: Run summary:
wandb:     e_F1 58.04784
wandb:   e_loss 0.96982
wandb:     t_F1 72.16259
wandb:   t_loss 0.767
wandb: 
wandb: Synced 4 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Synced deft-resonance-1: https://wandb.ai/yinanazhou/xl_512_bs_8_lr_1e06_es_5_lc_True_nr_True_sr_True_stem_True_lemma_False_repeat_3_fold_2/runs/11kwf1s0
wandb: Find logs at: ./wandb/run-20220316_104610-11kwf1s0/logs/debug.log
wandb: 

wandb: wandb version 0.12.11 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
2022-03-16 12:23:20.301467: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1
wandb: Tracking run with wandb version 0.12.5
wandb: Syncing run woven-sky-1
wandb: â­ï¸ View project at https://wandb.ai/yinanazhou/xl_512_bs_8_lr_1e06_es_5_lc_True_nr_True_sr_True_stem_True_lemma_False_repeat_4_fold_1
wandb: ðŸš€ View run at https://wandb.ai/yinanazhou/xl_512_bs_8_lr_1e06_es_5_lc_True_nr_True_sr_True_stem_True_lemma_False_repeat_4_fold_1/runs/gb3a0lr7
wandb: Run data is saved locally in /project/6002780/yinan/Thesis_MER_Lyrics/lyric-emotion/wandb/run-20220316_122317-gb3a0lr7
wandb: Run `wandb offline` to turn off syncing.

Validation loss decreased (inf --> 1.397882).  Saving model ...
Validation loss decreased (1.397882 --> 1.392842).  Saving model ...
Validation loss decreased (1.392842 --> 1.388338).  Saving model ...
Validation loss decreased (1.388338 --> 1.384347).  Saving model ...
Validation loss decreased (1.384347 --> 1.380599).  Saving model ...
Validation loss decreased (1.380599 --> 1.377039).  Saving model ...
Validation loss decreased (1.377039 --> 1.373662).  Saving model ...
Validation loss decreased (1.373662 --> 1.370034).  Saving model ...
Validation loss decreased (1.370034 --> 1.366969).  Saving model ...
Validation loss decreased (1.366969 --> 1.363725).  Saving model ...
Validation loss decreased (1.363725 --> 1.360542).  Saving model ...
Validation loss decreased (1.360542 --> 1.357230).  Saving model ...
Validation loss decreased (1.357230 --> 1.353864).  Saving model ...
Validation loss decreased (1.353864 --> 1.350365).  Saving model ...
Validation loss decreased (1.350365 --> 1.346465).  Saving model ...
Validation loss decreased (1.346465 --> 1.342772).  Saving model ...
Validation loss decreased (1.342772 --> 1.339233).  Saving model ...
Validation loss decreased (1.339233 --> 1.335425).  Saving model ...
Validation loss decreased (1.335425 --> 1.331919).  Saving model ...
Validation loss decreased (1.331919 --> 1.328023).  Saving model ...
Validation loss decreased (1.328023 --> 1.323801).  Saving model ...
Validation loss decreased (1.323801 --> 1.319483).  Saving model ...
Validation loss decreased (1.319483 --> 1.315121).  Saving model ...
Validation loss decreased (1.315121 --> 1.310599).  Saving model ...
Validation loss decreased (1.310599 --> 1.305793).  Saving model ...
Validation loss decreased (1.305793 --> 1.300921).  Saving model ...
Validation loss decreased (1.300921 --> 1.295721).  Saving model ...
Validation loss decreased (1.295721 --> 1.290797).  Saving model ...
Validation loss decreased (1.290797 --> 1.285022).  Saving model ...
Validation loss decreased (1.285022 --> 1.279215).  Saving model ...
Validation loss decreased (1.279215 --> 1.273522).  Saving model ...
Validation loss decreased (1.273522 --> 1.267571).  Saving model ...
Validation loss decreased (1.267571 --> 1.261429).  Saving model ...
Validation loss decreased (1.261429 --> 1.254984).  Saving model ...
Validation loss decreased (1.254984 --> 1.249251).  Saving model ...
Validation loss decreased (1.249251 --> 1.242218).  Saving model ...
Validation loss decreased (1.242218 --> 1.236226).  Saving model ...
Validation loss decreased (1.236226 --> 1.229431).  Saving model ...
Validation loss decreased (1.229431 --> 1.221675).  Saving model ...
Validation loss decreased (1.221675 --> 1.214234).  Saving model ...
Validation loss decreased (1.214234 --> 1.206237).  Saving model ...
Validation loss decreased (1.206237 --> 1.200295).  Saving model ...
Validation loss decreased (1.200295 --> 1.194983).  Saving model ...
Validation loss decreased (1.194983 --> 1.188619).  Saving model ...
Validation loss decreased (1.188619 --> 1.183708).  Saving model ...
Validation loss decreased (1.183708 --> 1.178194).  Saving model ...
Validation loss decreased (1.178194 --> 1.173840).  Saving model ...
Validation loss decreased (1.173840 --> 1.168846).  Saving model ...
Validation loss decreased (1.168846 --> 1.163517).  Saving model ...
Validation loss decreased (1.163517 --> 1.158617).  Saving model ...
Validation loss decreased (1.158617 --> 1.154726).  Saving model ...
Validation loss decreased (1.154726 --> 1.150229).  Saving model ...
Validation loss decreased (1.150229 --> 1.145902).  Saving model ...
Validation loss decreased (1.145902 --> 1.141107).  Saving model ...
Validation loss decreased (1.141107 --> 1.137666).  Saving model ...
Validation loss decreased (1.137666 --> 1.133357).  Saving model ...
Validation loss decreased (1.133357 --> 1.129731).  Saving model ...
Validation loss decreased (1.129731 --> 1.125349).  Saving model ...
Validation loss decreased (1.125349 --> 1.122105).  Saving model ...
Validation loss decreased (1.122105 --> 1.119616).  Saving model ...
Validation loss decreased (1.119616 --> 1.116863).  Saving model ...
Validation loss decreased (1.116863 --> 1.114149).  Saving model ...
Validation loss decreased (1.114149 --> 1.111166).  Saving model ...
Validation loss decreased (1.111166 --> 1.107698).  Saving model ...
Validation loss decreased (1.107698 --> 1.105312).  Saving model ...
Validation loss decreased (1.105312 --> 1.103828).  Saving model ...
Validation loss decreased (1.103828 --> 1.100301).  Saving model ...
Validation loss decreased (1.100301 --> 1.097264).  Saving model ...
Validation loss decreased (1.097264 --> 1.094662).  Saving model ...
Validation loss decreased (1.094662 --> 1.091988).  Saving model ...
Validation loss decreased (1.091988 --> 1.089643).  Saving model ...
Validation loss decreased (1.089643 --> 1.086490).  Saving model ...
Validation loss decreased (1.086490 --> 1.083339).  Saving model ...
Validation loss decreased (1.083339 --> 1.079146).  Saving model ...
Validation loss decreased (1.079146 --> 1.075051).  Saving model ...
Validation loss decreased (1.075051 --> 1.071814).  Saving model ...
Validation loss decreased (1.071814 --> 1.070099).  Saving model ...
Validation loss decreased (1.070099 --> 1.068074).  Saving model ...
Validation loss decreased (1.068074 --> 1.064754).  Saving model ...
Validation loss decreased (1.064754 --> 1.063300).  Saving model ...
Validation loss decreased (1.063300 --> 1.060975).  Saving model ...
Validation loss decreased (1.060975 --> 1.059059).  Saving model ...
Validation loss decreased (1.059059 --> 1.057095).  Saving model ...
Validation loss decreased (1.057095 --> 1.054686).  Saving model ...
Validation loss decreased (1.054686 --> 1.051759).  Saving model ...
Validation loss decreased (1.051759 --> 1.050067).  Saving model ...
Validation loss decreased (1.050067 --> 1.048682).  Saving model ...
Validation loss decreased (1.048682 --> 1.046623).  Saving model ...
Validation loss decreased (1.046623 --> 1.045032).  Saving model ...
Validation loss decreased (1.045032 --> 1.043457).  Saving model ...
Validation loss decreased (1.043457 --> 1.041130).  Saving model ...
Validation loss decreased (1.041130 --> 1.038149).  Saving model ...
Validation loss decreased (1.038149 --> 1.036501).  Saving model ...
Validation loss decreased (1.036501 --> 1.035828).  Saving model ...
Validation loss decreased (1.035828 --> 1.035333).  Saving model ...
Validation loss decreased (1.035333 --> 1.034991).  Saving model ...
Validation loss decreased (1.034991 --> 1.033396).  Saving model ...
Validation loss decreased (1.033396 --> 1.033039).  Saving model ...
Validation loss decreased (1.033039 --> 1.032231).  Saving model ...
Validation loss decreased (1.032231 --> 1.030498).  Saving model ...
Validation loss decreased (1.030498 --> 1.027465).  Saving model ...
Validation loss decreased (1.027465 --> 1.026853).  Saving model ...
Validation loss decreased (1.026853 --> 1.025158).  Saving model ...
Validation loss decreased (1.025158 --> 1.023941).  Saving model ...
Validation loss decreased (1.023941 --> 1.021477).  Saving model ...
Validation loss decreased (1.021477 --> 1.020766).  Saving model ...
Validation loss decreased (1.020766 --> 1.019775).  Saving model ...
Validation loss decreased (1.019775 --> 1.019561).  Saving model ...
Validation loss decreased (1.019561 --> 1.018494).  Saving model ...
Validation loss decreased (1.018494 --> 1.016837).  Saving model ...
Validation loss decreased (1.016837 --> 1.014568).  Saving model ...
Validation loss decreased (1.014568 --> 1.014062).  Saving model ...
Validation loss decreased (1.014062 --> 1.011752).  Saving model ...
Validation loss decreased (1.011752 --> 1.011211).  Saving model ...
EarlyStopping counter: 1 out of 5.0
Validation loss decreased (1.011211 --> 1.010076).  Saving model ...
EarlyStopping counter: 1 out of 5.0
EarlyStopping counter: 2 out of 5.0
EarlyStopping counter: 3 out of 5.0
Validation loss decreased (1.010076 --> 1.009480).  Saving model ...
Validation loss decreased (1.009480 --> 1.009444).  Saving model ...
EarlyStopping counter: 1 out of 5.0
Validation loss decreased (1.009444 --> 1.007021).  Saving model ...
EarlyStopping counter: 1 out of 5.0
EarlyStopping counter: 2 out of 5.0
EarlyStopping counter: 3 out of 5.0
EarlyStopping counter: 4 out of 5.0
EarlyStopping counter: 5 out of 5.0
/localscratch/yinan.29028709.0/env/lib/python3.7/site-packages/torch/nn/functional.py:1794: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.
  warnings.warn("nn.functional.tanh is deprecated. Use torch.tanh instead.")
wandb: Waiting for W&B process to finish, PID 39552... (success).
wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: \ 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: | 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: / 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: \ 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: | 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: / 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: \ 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: | 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: / 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb:                                                                                
wandb: Run history:
wandb:     e_F1 â–â–‚â–‚â–ƒâ–„â–„â–…â–…â–…â–…â–†â–†â–†â–†â–†â–‡â–†â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–ˆâ–ˆâ–‡â–ˆâ–‡â–‡â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ
wandb:   e_loss â–ˆâ–ˆâ–ˆâ–‡â–‡â–‡â–‡â–‡â–†â–†â–…â–…â–…â–„â–„â–„â–„â–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–â–â–â–â–â–â–â–â–â–
wandb:     t_F1 â–â–â–â–â–‚â–ƒâ–ƒâ–ƒâ–ƒâ–„â–„â–…â–…â–…â–…â–†â–…â–†â–†â–†â–‡â–†â–‡â–‡â–†â–†â–‡â–‡â–‡â–‡â–†â–‡â–‡â–‡â–‡â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ
wandb:   t_loss â–ˆâ–ˆâ–ˆâ–ˆâ–‡â–‡â–‡â–‡â–‡â–‡â–†â–†â–†â–…â–…â–…â–…â–…â–„â–„â–„â–„â–„â–ƒâ–ƒâ–ƒâ–ƒâ–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–â–‚â–â–â–
wandb: 
wandb: Run summary:
wandb:     e_F1 56.41235
wandb:   e_loss 1.00703
wandb:     t_F1 68.88319
wandb:   t_loss 0.83079
wandb: 
wandb: Synced 4 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Synced woven-sky-1: https://wandb.ai/yinanazhou/xl_512_bs_8_lr_1e06_es_5_lc_True_nr_True_sr_True_stem_True_lemma_False_repeat_4_fold_1/runs/gb3a0lr7
wandb: Find logs at: ./wandb/run-20220316_122317-gb3a0lr7/logs/debug.log
wandb: 

wandb: wandb version 0.12.11 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
2022-03-16 13:47:14.879420: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1
wandb: Tracking run with wandb version 0.12.5
wandb: Syncing run neat-donkey-1
wandb: â­ï¸ View project at https://wandb.ai/yinanazhou/xl_512_bs_8_lr_1e06_es_5_lc_True_nr_True_sr_True_stem_True_lemma_False_repeat_4_fold_2
wandb: ðŸš€ View run at https://wandb.ai/yinanazhou/xl_512_bs_8_lr_1e06_es_5_lc_True_nr_True_sr_True_stem_True_lemma_False_repeat_4_fold_2/runs/3s4m8u9d
wandb: Run data is saved locally in /project/6002780/yinan/Thesis_MER_Lyrics/lyric-emotion/wandb/run-20220316_134711-3s4m8u9d
wandb: Run `wandb offline` to turn off syncing.

Validation loss decreased (inf --> 1.397639).  Saving model ...
Validation loss decreased (1.397639 --> 1.386707).  Saving model ...
Validation loss decreased (1.386707 --> 1.378097).  Saving model ...
Validation loss decreased (1.378097 --> 1.371392).  Saving model ...
Validation loss decreased (1.371392 --> 1.366203).  Saving model ...
Validation loss decreased (1.366203 --> 1.361628).  Saving model ...
Validation loss decreased (1.361628 --> 1.357733).  Saving model ...
Validation loss decreased (1.357733 --> 1.354733).  Saving model ...
Validation loss decreased (1.354733 --> 1.351774).  Saving model ...
Validation loss decreased (1.351774 --> 1.348566).  Saving model ...
Validation loss decreased (1.348566 --> 1.345839).  Saving model ...
Validation loss decreased (1.345839 --> 1.342551).  Saving model ...
Validation loss decreased (1.342551 --> 1.339074).  Saving model ...
Validation loss decreased (1.339074 --> 1.334929).  Saving model ...
Validation loss decreased (1.334929 --> 1.331153).  Saving model ...
Validation loss decreased (1.331153 --> 1.327543).  Saving model ...
Validation loss decreased (1.327543 --> 1.323291).  Saving model ...
Validation loss decreased (1.323291 --> 1.319657).  Saving model ...
Validation loss decreased (1.319657 --> 1.315721).  Saving model ...
Validation loss decreased (1.315721 --> 1.311195).  Saving model ...
Validation loss decreased (1.311195 --> 1.305999).  Saving model ...
Validation loss decreased (1.305999 --> 1.301595).  Saving model ...
Validation loss decreased (1.301595 --> 1.295751).  Saving model ...
Validation loss decreased (1.295751 --> 1.291423).  Saving model ...
Validation loss decreased (1.291423 --> 1.286688).  Saving model ...
Validation loss decreased (1.286688 --> 1.281711).  Saving model ...
Validation loss decreased (1.281711 --> 1.277166).  Saving model ...
Validation loss decreased (1.277166 --> 1.271161).  Saving model ...
Validation loss decreased (1.271161 --> 1.265683).  Saving model ...
Validation loss decreased (1.265683 --> 1.259261).  Saving model ...
Validation loss decreased (1.259261 --> 1.253557).  Saving model ...
Validation loss decreased (1.253557 --> 1.247742).  Saving model ...
Validation loss decreased (1.247742 --> 1.241898).  Saving model ...
Validation loss decreased (1.241898 --> 1.237378).  Saving model ...
Validation loss decreased (1.237378 --> 1.229300).  Saving model ...
Validation loss decreased (1.229300 --> 1.223857).  Saving model ...
Validation loss decreased (1.223857 --> 1.217605).  Saving model ...
Validation loss decreased (1.217605 --> 1.213616).  Saving model ...
Validation loss decreased (1.213616 --> 1.208001).  Saving model ...
Validation loss decreased (1.208001 --> 1.203128).  Saving model ...
Validation loss decreased (1.203128 --> 1.198637).  Saving model ...
Validation loss decreased (1.198637 --> 1.195228).  Saving model ...
Validation loss decreased (1.195228 --> 1.193282).  Saving model ...
Validation loss decreased (1.193282 --> 1.186773).  Saving model ...
Validation loss decreased (1.186773 --> 1.182025).  Saving model ...
Validation loss decreased (1.182025 --> 1.175791).  Saving model ...
Validation loss decreased (1.175791 --> 1.174841).  Saving model ...
Validation loss decreased (1.174841 --> 1.169622).  Saving model ...
Validation loss decreased (1.169622 --> 1.169098).  Saving model ...
Validation loss decreased (1.169098 --> 1.166558).  Saving model ...
Validation loss decreased (1.166558 --> 1.162668).  Saving model ...
Validation loss decreased (1.162668 --> 1.159476).  Saving model ...
Validation loss decreased (1.159476 --> 1.157076).  Saving model ...
Validation loss decreased (1.157076 --> 1.150401).  Saving model ...
Validation loss decreased (1.150401 --> 1.146037).  Saving model ...
Validation loss decreased (1.146037 --> 1.143020).  Saving model ...
Validation loss decreased (1.143020 --> 1.140160).  Saving model ...
Validation loss decreased (1.140160 --> 1.138914).  Saving model ...
Validation loss decreased (1.138914 --> 1.133770).  Saving model ...
Validation loss decreased (1.133770 --> 1.131198).  Saving model ...
Validation loss decreased (1.131198 --> 1.127158).  Saving model ...
Validation loss decreased (1.127158 --> 1.124974).  Saving model ...
EarlyStopping counter: 1 out of 5.0
Validation loss decreased (1.124974 --> 1.121879).  Saving model ...
Validation loss decreased (1.121879 --> 1.119017).  Saving model ...
Validation loss decreased (1.119017 --> 1.116778).  Saving model ...
Validation loss decreased (1.116778 --> 1.113636).  Saving model ...
Validation loss decreased (1.113636 --> 1.111724).  Saving model ...
Validation loss decreased (1.111724 --> 1.109214).  Saving model ...
Validation loss decreased (1.109214 --> 1.105626).  Saving model ...
Validation loss decreased (1.105626 --> 1.102869).  Saving model ...
Validation loss decreased (1.102869 --> 1.101489).  Saving model ...
EarlyStopping counter: 1 out of 5.0
Validation loss decreased (1.101489 --> 1.096993).  Saving model ...
Validation loss decreased (1.096993 --> 1.091498).  Saving model ...
EarlyStopping counter: 1 out of 5.0
Validation loss decreased (1.091498 --> 1.085644).  Saving model ...
Validation loss decreased (1.085644 --> 1.085600).  Saving model ...
Validation loss decreased (1.085600 --> 1.081838).  Saving model ...
Validation loss decreased (1.081838 --> 1.079341).  Saving model ...
Validation loss decreased (1.079341 --> 1.076429).  Saving model ...
Validation loss decreased (1.076429 --> 1.073065).  Saving model ...
Validation loss decreased (1.073065 --> 1.072415).  Saving model ...
Validation loss decreased (1.072415 --> 1.070532).  Saving model ...
Validation loss decreased (1.070532 --> 1.070494).  Saving model ...
EarlyStopping counter: 1 out of 5.0
Validation loss decreased (1.070494 --> 1.067604).  Saving model ...
Validation loss decreased (1.067604 --> 1.062995).  Saving model ...
Validation loss decreased (1.062995 --> 1.061156).  Saving model ...
EarlyStopping counter: 1 out of 5.0
EarlyStopping counter: 2 out of 5.0
Validation loss decreased (1.061156 --> 1.059381).  Saving model ...
Validation loss decreased (1.059381 --> 1.053792).  Saving model ...
Validation loss decreased (1.053792 --> 1.053719).  Saving model ...
Validation loss decreased (1.053719 --> 1.052862).  Saving model ...
EarlyStopping counter: 1 out of 5.0
EarlyStopping counter: 2 out of 5.0
EarlyStopping counter: 3 out of 5.0
Validation loss decreased (1.052862 --> 1.046986).  Saving model ...
EarlyStopping counter: 1 out of 5.0
EarlyStopping counter: 2 out of 5.0
Validation loss decreased (1.046986 --> 1.044062).  Saving model ...
EarlyStopping counter: 1 out of 5.0
EarlyStopping counter: 2 out of 5.0
Validation loss decreased (1.044062 --> 1.039645).  Saving model ...
EarlyStopping counter: 1 out of 5.0
EarlyStopping counter: 2 out of 5.0
EarlyStopping counter: 3 out of 5.0
Validation loss decreased (1.039645 --> 1.037362).  Saving model ...
EarlyStopping counter: 1 out of 5.0
EarlyStopping counter: 2 out of 5.0
EarlyStopping counter: 3 out of 5.0
Validation loss decreased (1.037362 --> 1.035802).  Saving model ...
EarlyStopping counter: 1 out of 5.0
EarlyStopping counter: 2 out of 5.0
EarlyStopping counter: 3 out of 5.0
Validation loss decreased (1.035802 --> 1.035043).  Saving model ...
Validation loss decreased (1.035043 --> 1.033376).  Saving model ...
Validation loss decreased (1.033376 --> 1.033271).  Saving model ...
EarlyStopping counter: 1 out of 5.0
EarlyStopping counter: 2 out of 5.0
EarlyStopping counter: 3 out of 5.0
EarlyStopping counter: 4 out of 5.0
Validation loss decreased (1.033271 --> 1.029423).  Saving model ...
EarlyStopping counter: 1 out of 5.0
EarlyStopping counter: 2 out of 5.0
Validation loss decreased (1.029423 --> 1.027386).  Saving model ...
Validation loss decreased (1.027386 --> 1.026820).  Saving model ...
Validation loss decreased (1.026820 --> 1.025934).  Saving model ...
Validation loss decreased (1.025934 --> 1.025439).  Saving model ...
EarlyStopping counter: 1 out of 5.0
EarlyStopping counter: 2 out of 5.0
EarlyStopping counter: 3 out of 5.0
EarlyStopping counter: 4 out of 5.0
EarlyStopping counter: 5 out of 5.0
/localscratch/yinan.29028709.0/env/lib/python3.7/site-packages/torch/nn/functional.py:1794: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.
  warnings.warn("nn.functional.tanh is deprecated. Use torch.tanh instead.")
wandb: Waiting for W&B process to finish, PID 44089... (success).
wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: \ 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: | 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: / 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: \ 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: | 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: / 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: \ 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: | 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: / 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb:                                                                                
wandb: Run history:
wandb:     e_F1 â–â–‚â–„â–…â–†â–†â–†â–†â–‡â–†â–†â–‡â–†â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ
wandb:   e_loss â–ˆâ–ˆâ–‡â–‡â–‡â–‡â–†â–†â–†â–…â–…â–…â–„â–„â–„â–„â–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–â–â–â–â–â–â–â–â–â–â–
wandb:     t_F1 â–â–‚â–‚â–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–„â–„â–„â–…â–…â–†â–†â–†â–†â–†â–†â–†â–†â–†â–†â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–ˆâ–‡â–ˆâ–ˆâ–ˆ
wandb:   t_loss â–ˆâ–ˆâ–‡â–‡â–‡â–‡â–‡â–‡â–†â–†â–†â–†â–…â–…â–…â–…â–…â–„â–„â–„â–„â–„â–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–â–â–â–â–
wandb: 
wandb: Run summary:
wandb:     e_F1 57.90825
wandb:   e_loss 1.03126
wandb:     t_F1 68.34013
wandb:   t_loss 0.82876
wandb: 
wandb: Synced 4 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Synced neat-donkey-1: https://wandb.ai/yinanazhou/xl_512_bs_8_lr_1e06_es_5_lc_True_nr_True_sr_True_stem_True_lemma_False_repeat_4_fold_2/runs/3s4m8u9d
wandb: Find logs at: ./wandb/run-20220316_134711-3s4m8u9d/logs/debug.log
wandb: 

wandb: wandb version 0.12.11 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
2022-03-16 15:17:23.561132: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1
wandb: Tracking run with wandb version 0.12.5
wandb: Syncing run confused-grass-1
wandb: â­ï¸ View project at https://wandb.ai/yinanazhou/xl_512_bs_8_lr_1e06_es_5_lc_True_nr_True_sr_True_stem_True_lemma_False_repeat_5_fold_1
wandb: ðŸš€ View run at https://wandb.ai/yinanazhou/xl_512_bs_8_lr_1e06_es_5_lc_True_nr_True_sr_True_stem_True_lemma_False_repeat_5_fold_1/runs/228gikdi
wandb: Run data is saved locally in /project/6002780/yinan/Thesis_MER_Lyrics/lyric-emotion/wandb/run-20220316_151720-228gikdi
wandb: Run `wandb offline` to turn off syncing.

Validation loss decreased (inf --> 1.399048).  Saving model ...
Validation loss decreased (1.399048 --> 1.389987).  Saving model ...
Validation loss decreased (1.389987 --> 1.383130).  Saving model ...
Validation loss decreased (1.383130 --> 1.377867).  Saving model ...
Validation loss decreased (1.377867 --> 1.373634).  Saving model ...
Validation loss decreased (1.373634 --> 1.369468).  Saving model ...
Validation loss decreased (1.369468 --> 1.365624).  Saving model ...
Validation loss decreased (1.365624 --> 1.361970).  Saving model ...
Validation loss decreased (1.361970 --> 1.358565).  Saving model ...
Validation loss decreased (1.358565 --> 1.354862).  Saving model ...
Validation loss decreased (1.354862 --> 1.350935).  Saving model ...
Validation loss decreased (1.350935 --> 1.347003).  Saving model ...
Validation loss decreased (1.347003 --> 1.343228).  Saving model ...
Validation loss decreased (1.343228 --> 1.338692).  Saving model ...
Validation loss decreased (1.338692 --> 1.334941).  Saving model ...
Validation loss decreased (1.334941 --> 1.331488).  Saving model ...
Validation loss decreased (1.331488 --> 1.326995).  Saving model ...
Validation loss decreased (1.326995 --> 1.322797).  Saving model ...
Validation loss decreased (1.322797 --> 1.318377).  Saving model ...
Validation loss decreased (1.318377 --> 1.313693).  Saving model ...
Validation loss decreased (1.313693 --> 1.308919).  Saving model ...
Validation loss decreased (1.308919 --> 1.304513).  Saving model ...
Validation loss decreased (1.304513 --> 1.300035).  Saving model ...
Validation loss decreased (1.300035 --> 1.296123).  Saving model ...
Validation loss decreased (1.296123 --> 1.291493).  Saving model ...
Validation loss decreased (1.291493 --> 1.286542).  Saving model ...
Validation loss decreased (1.286542 --> 1.281524).  Saving model ...
Validation loss decreased (1.281524 --> 1.276771).  Saving model ...
Validation loss decreased (1.276771 --> 1.271915).  Saving model ...
Validation loss decreased (1.271915 --> 1.267697).  Saving model ...
Validation loss decreased (1.267697 --> 1.263281).  Saving model ...
Validation loss decreased (1.263281 --> 1.258046).  Saving model ...
Validation loss decreased (1.258046 --> 1.253502).  Saving model ...
Validation loss decreased (1.253502 --> 1.250396).  Saving model ...
Validation loss decreased (1.250396 --> 1.246353).  Saving model ...
Validation loss decreased (1.246353 --> 1.241106).  Saving model ...
Validation loss decreased (1.241106 --> 1.237973).  Saving model ...
Validation loss decreased (1.237973 --> 1.235039).  Saving model ...
Validation loss decreased (1.235039 --> 1.230945).  Saving model ...
Validation loss decreased (1.230945 --> 1.228945).  Saving model ...
Validation loss decreased (1.228945 --> 1.225578).  Saving model ...
Validation loss decreased (1.225578 --> 1.222389).  Saving model ...
Validation loss decreased (1.222389 --> 1.216833).  Saving model ...
Validation loss decreased (1.216833 --> 1.212940).  Saving model ...
Validation loss decreased (1.212940 --> 1.209374).  Saving model ...
Validation loss decreased (1.209374 --> 1.204357).  Saving model ...
Validation loss decreased (1.204357 --> 1.199708).  Saving model ...
Validation loss decreased (1.199708 --> 1.196781).  Saving model ...
Validation loss decreased (1.196781 --> 1.193270).  Saving model ...
Validation loss decreased (1.193270 --> 1.189097).  Saving model ...
Validation loss decreased (1.189097 --> 1.186980).  Saving model ...
Validation loss decreased (1.186980 --> 1.181871).  Saving model ...
Validation loss decreased (1.181871 --> 1.177175).  Saving model ...
Validation loss decreased (1.177175 --> 1.175321).  Saving model ...
Validation loss decreased (1.175321 --> 1.174082).  Saving model ...
Validation loss decreased (1.174082 --> 1.168578).  Saving model ...
Validation loss decreased (1.168578 --> 1.165758).  Saving model ...
Validation loss decreased (1.165758 --> 1.162246).  Saving model ...
Validation loss decreased (1.162246 --> 1.157325).  Saving model ...
Validation loss decreased (1.157325 --> 1.153321).  Saving model ...
Validation loss decreased (1.153321 --> 1.151237).  Saving model ...
Validation loss decreased (1.151237 --> 1.147431).  Saving model ...
Validation loss decreased (1.147431 --> 1.144533).  Saving model ...
Validation loss decreased (1.144533 --> 1.141252).  Saving model ...
Validation loss decreased (1.141252 --> 1.136913).  Saving model ...
Validation loss decreased (1.136913 --> 1.134492).  Saving model ...
Validation loss decreased (1.134492 --> 1.130026).  Saving model ...
Validation loss decreased (1.130026 --> 1.126909).  Saving model ...
Validation loss decreased (1.126909 --> 1.126150).  Saving model ...
Validation loss decreased (1.126150 --> 1.122500).  Saving model ...
Validation loss decreased (1.122500 --> 1.117585).  Saving model ...
Validation loss decreased (1.117585 --> 1.115349).  Saving model ...
Validation loss decreased (1.115349 --> 1.111181).  Saving model ...
Validation loss decreased (1.111181 --> 1.110169).  Saving model ...
Validation loss decreased (1.110169 --> 1.106918).  Saving model ...
Validation loss decreased (1.106918 --> 1.106423).  Saving model ...
Validation loss decreased (1.106423 --> 1.101653).  Saving model ...
Validation loss decreased (1.101653 --> 1.099538).  Saving model ...
Validation loss decreased (1.099538 --> 1.098507).  Saving model ...
Validation loss decreased (1.098507 --> 1.096027).  Saving model ...
Validation loss decreased (1.096027 --> 1.091351).  Saving model ...
Validation loss decreased (1.091351 --> 1.088882).  Saving model ...
Validation loss decreased (1.088882 --> 1.087112).  Saving model ...
Validation loss decreased (1.087112 --> 1.084516).  Saving model ...
Validation loss decreased (1.084516 --> 1.081320).  Saving model ...
Validation loss decreased (1.081320 --> 1.081014).  Saving model ...
Validation loss decreased (1.081014 --> 1.079098).  Saving model ...
Validation loss decreased (1.079098 --> 1.076890).  Saving model ...
Validation loss decreased (1.076890 --> 1.076407).  Saving model ...
Validation loss decreased (1.076407 --> 1.073480).  Saving model ...
Validation loss decreased (1.073480 --> 1.071964).  Saving model ...
Validation loss decreased (1.071964 --> 1.067243).  Saving model ...
Validation loss decreased (1.067243 --> 1.064613).  Saving model ...
EarlyStopping counter: 1 out of 5.0
Validation loss decreased (1.064613 --> 1.063477).  Saving model ...
Validation loss decreased (1.063477 --> 1.059096).  Saving model ...
Validation loss decreased (1.059096 --> 1.057791).  Saving model ...
Validation loss decreased (1.057791 --> 1.055122).  Saving model ...
Validation loss decreased (1.055122 --> 1.054131).  Saving model ...
EarlyStopping counter: 1 out of 5.0
Validation loss decreased (1.054131 --> 1.053376).  Saving model ...
Validation loss decreased (1.053376 --> 1.050769).  Saving model ...
Validation loss decreased (1.050769 --> 1.048567).  Saving model ...
Validation loss decreased (1.048567 --> 1.047035).  Saving model ...
Validation loss decreased (1.047035 --> 1.046047).  Saving model ...
Validation loss decreased (1.046047 --> 1.043646).  Saving model ...
EarlyStopping counter: 1 out of 5.0
Validation loss decreased (1.043646 --> 1.043160).  Saving model ...
EarlyStopping counter: 1 out of 5.0
Validation loss decreased (1.043160 --> 1.042290).  Saving model ...
Validation loss decreased (1.042290 --> 1.040111).  Saving model ...
Validation loss decreased (1.040111 --> 1.038552).  Saving model ...
Validation loss decreased (1.038552 --> 1.037995).  Saving model ...
Validation loss decreased (1.037995 --> 1.036361).  Saving model ...
Validation loss decreased (1.036361 --> 1.035280).  Saving model ...
Validation loss decreased (1.035280 --> 1.032758).  Saving model ...
Validation loss decreased (1.032758 --> 1.032298).  Saving model ...
Validation loss decreased (1.032298 --> 1.031767).  Saving model ...
EarlyStopping counter: 1 out of 5.0
EarlyStopping counter: 2 out of 5.0
EarlyStopping counter: 3 out of 5.0
Validation loss decreased (1.031767 --> 1.030836).  Saving model ...
Validation loss decreased (1.030836 --> 1.030491).  Saving model ...
Validation loss decreased (1.030491 --> 1.027419).  Saving model ...
EarlyStopping counter: 1 out of 5.0
EarlyStopping counter: 2 out of 5.0
EarlyStopping counter: 3 out of 5.0
Validation loss decreased (1.027419 --> 1.024502).  Saving model ...
Validation loss decreased (1.024502 --> 1.023776).  Saving model ...
Validation loss decreased (1.023776 --> 1.022742).  Saving model ...
EarlyStopping counter: 1 out of 5.0
EarlyStopping counter: 2 out of 5.0
EarlyStopping counter: 3 out of 5.0
Validation loss decreased (1.022742 --> 1.022405).  Saving model ...
Validation loss decreased (1.022405 --> 1.021999).  Saving model ...
EarlyStopping counter: 1 out of 5.0
EarlyStopping counter: 2 out of 5.0
Validation loss decreased (1.021999 --> 1.021068).  Saving model ...
Validation loss decreased (1.021068 --> 1.019368).  Saving model ...
EarlyStopping counter: 1 out of 5.0
EarlyStopping counter: 2 out of 5.0
Validation loss decreased (1.019368 --> 1.019028).  Saving model ...
EarlyStopping counter: 1 out of 5.0
EarlyStopping counter: 2 out of 5.0
EarlyStopping counter: 3 out of 5.0
EarlyStopping counter: 4 out of 5.0
EarlyStopping counter: 5 out of 5.0
/localscratch/yinan.29028709.0/env/lib/python3.7/site-packages/torch/nn/functional.py:1794: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.
  warnings.warn("nn.functional.tanh is deprecated. Use torch.tanh instead.")
wandb: Waiting for W&B process to finish, PID 48935... (success).
wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: \ 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: | 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: / 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: \ 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: | 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: / 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: \ 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: | 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: / 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb:                                                                                
wandb: Run history:
wandb:     e_F1 â–â–‚â–„â–„â–„â–„â–…â–…â–…â–…â–…â–…â–†â–†â–†â–†â–†â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ
wandb:   e_loss â–ˆâ–ˆâ–‡â–‡â–‡â–‡â–†â–†â–†â–…â–…â–…â–„â–„â–„â–„â–„â–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–‚â–‚â–‚â–‚â–‚â–‚â–‚â–â–â–â–â–â–â–â–â–â–â–
wandb:     t_F1 â–â–‚â–‚â–‚â–ƒâ–„â–„â–„â–„â–„â–…â–…â–…â–…â–…â–†â–†â–†â–†â–†â–†â–†â–†â–†â–†â–†â–‡â–†â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–ˆâ–ˆâ–ˆ
wandb:   t_loss â–ˆâ–ˆâ–ˆâ–ˆâ–‡â–‡â–‡â–‡â–‡â–†â–†â–†â–†â–…â–…â–…â–…â–„â–„â–„â–„â–„â–„â–„â–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–â–
wandb: 
wandb: Run summary:
wandb:     e_F1 54.91247
wandb:   e_loss 1.01973
wandb:     t_F1 70.68637
wandb:   t_loss 0.76967
wandb: 
wandb: Synced 4 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Synced confused-grass-1: https://wandb.ai/yinanazhou/xl_512_bs_8_lr_1e06_es_5_lc_True_nr_True_sr_True_stem_True_lemma_False_repeat_5_fold_1/runs/228gikdi
wandb: Find logs at: ./wandb/run-20220316_151720-228gikdi/logs/debug.log
wandb: 

wandb: wandb version 0.12.11 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
2022-03-16 16:52:37.026604: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1
wandb: Tracking run with wandb version 0.12.5
wandb: Syncing run electric-pond-1
wandb: â­ï¸ View project at https://wandb.ai/yinanazhou/xl_512_bs_8_lr_1e06_es_5_lc_True_nr_True_sr_True_stem_True_lemma_False_repeat_5_fold_2
wandb: ðŸš€ View run at https://wandb.ai/yinanazhou/xl_512_bs_8_lr_1e06_es_5_lc_True_nr_True_sr_True_stem_True_lemma_False_repeat_5_fold_2/runs/13t1y22y
wandb: Run data is saved locally in /project/6002780/yinan/Thesis_MER_Lyrics/lyric-emotion/wandb/run-20220316_165234-13t1y22y
wandb: Run `wandb offline` to turn off syncing.

Validation loss decreased (inf --> 1.432513).  Saving model ...
Validation loss decreased (1.432513 --> 1.411856).  Saving model ...
Validation loss decreased (1.411856 --> 1.399235).  Saving model ...
Validation loss decreased (1.399235 --> 1.387958).  Saving model ...
Validation loss decreased (1.387958 --> 1.379610).  Saving model ...
Validation loss decreased (1.379610 --> 1.373187).  Saving model ...
Validation loss decreased (1.373187 --> 1.367814).  Saving model ...
Validation loss decreased (1.367814 --> 1.362642).  Saving model ...
Validation loss decreased (1.362642 --> 1.358564).  Saving model ...
Validation loss decreased (1.358564 --> 1.354428).  Saving model ...
Validation loss decreased (1.354428 --> 1.350636).  Saving model ...
Validation loss decreased (1.350636 --> 1.347260).  Saving model ...
Validation loss decreased (1.347260 --> 1.343568).  Saving model ...
Validation loss decreased (1.343568 --> 1.339974).  Saving model ...
Validation loss decreased (1.339974 --> 1.335945).  Saving model ...
Validation loss decreased (1.335945 --> 1.332040).  Saving model ...
Validation loss decreased (1.332040 --> 1.327712).  Saving model ...
Validation loss decreased (1.327712 --> 1.323441).  Saving model ...
Validation loss decreased (1.323441 --> 1.318624).  Saving model ...
Validation loss decreased (1.318624 --> 1.314292).  Saving model ...
Validation loss decreased (1.314292 --> 1.310079).  Saving model ...
Validation loss decreased (1.310079 --> 1.305169).  Saving model ...
Validation loss decreased (1.305169 --> 1.301287).  Saving model ...
Validation loss decreased (1.301287 --> 1.296712).  Saving model ...
Validation loss decreased (1.296712 --> 1.291213).  Saving model ...
Validation loss decreased (1.291213 --> 1.285745).  Saving model ...
Validation loss decreased (1.285745 --> 1.280747).  Saving model ...
Validation loss decreased (1.280747 --> 1.275718).  Saving model ...
Validation loss decreased (1.275718 --> 1.270403).  Saving model ...
Validation loss decreased (1.270403 --> 1.264799).  Saving model ...
Validation loss decreased (1.264799 --> 1.259282).  Saving model ...
Validation loss decreased (1.259282 --> 1.252396).  Saving model ...
Validation loss decreased (1.252396 --> 1.247805).  Saving model ...
Validation loss decreased (1.247805 --> 1.240960).  Saving model ...
Validation loss decreased (1.240960 --> 1.233572).  Saving model ...
Validation loss decreased (1.233572 --> 1.229447).  Saving model ...
Validation loss decreased (1.229447 --> 1.222320).  Saving model ...
Validation loss decreased (1.222320 --> 1.215679).  Saving model ...
Validation loss decreased (1.215679 --> 1.210586).  Saving model ...
Validation loss decreased (1.210586 --> 1.204300).  Saving model ...
Validation loss decreased (1.204300 --> 1.197007).  Saving model ...
Validation loss decreased (1.197007 --> 1.193269).  Saving model ...
Validation loss decreased (1.193269 --> 1.187593).  Saving model ...
Validation loss decreased (1.187593 --> 1.181671).  Saving model ...
Validation loss decreased (1.181671 --> 1.176336).  Saving model ...
Validation loss decreased (1.176336 --> 1.171967).  Saving model ...
Validation loss decreased (1.171967 --> 1.165859).  Saving model ...
Validation loss decreased (1.165859 --> 1.162450).  Saving model ...
Validation loss decreased (1.162450 --> 1.156731).  Saving model ...
Validation loss decreased (1.156731 --> 1.151680).  Saving model ...
Validation loss decreased (1.151680 --> 1.147519).  Saving model ...
Validation loss decreased (1.147519 --> 1.142811).  Saving model ...
Validation loss decreased (1.142811 --> 1.138399).  Saving model ...
Validation loss decreased (1.138399 --> 1.136325).  Saving model ...
Validation loss decreased (1.136325 --> 1.132371).  Saving model ...
Validation loss decreased (1.132371 --> 1.129936).  Saving model ...
Validation loss decreased (1.129936 --> 1.126540).  Saving model ...
Validation loss decreased (1.126540 --> 1.122836).  Saving model ...
Validation loss decreased (1.122836 --> 1.119760).  Saving model ...
Validation loss decreased (1.119760 --> 1.115611).  Saving model ...
Validation loss decreased (1.115611 --> 1.113790).  Saving model ...
Validation loss decreased (1.113790 --> 1.111336).  Saving model ...
Validation loss decreased (1.111336 --> 1.107616).  Saving model ...
Validation loss decreased (1.107616 --> 1.103911).  Saving model ...
Validation loss decreased (1.103911 --> 1.100552).  Saving model ...
Validation loss decreased (1.100552 --> 1.099327).  Saving model ...
Validation loss decreased (1.099327 --> 1.096192).  Saving model ...
Validation loss decreased (1.096192 --> 1.089832).  Saving model ...
Validation loss decreased (1.089832 --> 1.087490).  Saving model ...
Validation loss decreased (1.087490 --> 1.085899).  Saving model ...
Validation loss decreased (1.085899 --> 1.083648).  Saving model ...
Validation loss decreased (1.083648 --> 1.080566).  Saving model ...
Validation loss decreased (1.080566 --> 1.077795).  Saving model ...
Validation loss decreased (1.077795 --> 1.076048).  Saving model ...
Validation loss decreased (1.076048 --> 1.072976).  Saving model ...
Validation loss decreased (1.072976 --> 1.072084).  Saving model ...
Validation loss decreased (1.072084 --> 1.068740).  Saving model ...
Validation loss decreased (1.068740 --> 1.067364).  Saving model ...
Validation loss decreased (1.067364 --> 1.064415).  Saving model ...
Validation loss decreased (1.064415 --> 1.063722).  Saving model ...
Validation loss decreased (1.063722 --> 1.062638).  Saving model ...
Validation loss decreased (1.062638 --> 1.060493).  Saving model ...
Validation loss decreased (1.060493 --> 1.059288).  Saving model ...
Validation loss decreased (1.059288 --> 1.056052).  Saving model ...
Validation loss decreased (1.056052 --> 1.055625).  Saving model ...
Validation loss decreased (1.055625 --> 1.053911).  Saving model ...
Validation loss decreased (1.053911 --> 1.050390).  Saving model ...
Validation loss decreased (1.050390 --> 1.046666).  Saving model ...
Validation loss decreased (1.046666 --> 1.046343).  Saving model ...
Validation loss decreased (1.046343 --> 1.044724).  Saving model ...
Validation loss decreased (1.044724 --> 1.043087).  Saving model ...
Validation loss decreased (1.043087 --> 1.040282).  Saving model ...
EarlyStopping counter: 1 out of 5.0
Validation loss decreased (1.040282 --> 1.039579).  Saving model ...
Validation loss decreased (1.039579 --> 1.036629).  Saving model ...
Validation loss decreased (1.036629 --> 1.033548).  Saving model ...
Validation loss decreased (1.033548 --> 1.031840).  Saving model ...
Validation loss decreased (1.031840 --> 1.031023).  Saving model ...
Validation loss decreased (1.031023 --> 1.029096).  Saving model ...
Validation loss decreased (1.029096 --> 1.027074).  Saving model ...
Validation loss decreased (1.027074 --> 1.026170).  Saving model ...
Validation loss decreased (1.026170 --> 1.025669).  Saving model ...
Validation loss decreased (1.025669 --> 1.023448).  Saving model ...
Validation loss decreased (1.023448 --> 1.022808).  Saving model ...
Validation loss decreased (1.022808 --> 1.022005).  Saving model ...
EarlyStopping counter: 1 out of 5.0
Validation loss decreased (1.022005 --> 1.020450).  Saving model ...
Validation loss decreased (1.020450 --> 1.017814).  Saving model ...
Validation loss decreased (1.017814 --> 1.015523).  Saving model ...
Validation loss decreased (1.015523 --> 1.015100).  Saving model ...
EarlyStopping counter: 1 out of 5.0
EarlyStopping counter: 2 out of 5.0
Validation loss decreased (1.015100 --> 1.013813).  Saving model ...
Validation loss decreased (1.013813 --> 1.010775).  Saving model ...
EarlyStopping counter: 1 out of 5.0
Validation loss decreased (1.010775 --> 1.009552).  Saving model ...
EarlyStopping counter: 1 out of 5.0
Validation loss decreased (1.009552 --> 1.008355).  Saving model ...
EarlyStopping counter: 1 out of 5.0
EarlyStopping counter: 2 out of 5.0
Validation loss decreased (1.008355 --> 1.007826).  Saving model ...
Validation loss decreased (1.007826 --> 1.006459).  Saving model ...
EarlyStopping counter: 1 out of 5.0
EarlyStopping counter: 2 out of 5.0
Validation loss decreased (1.006459 --> 1.003786).  Saving model ...
EarlyStopping counter: 1 out of 5.0
Validation loss decreased (1.003786 --> 1.002992).  Saving model ...
EarlyStopping counter: 1 out of 5.0
Validation loss decreased (1.002992 --> 1.001724).  Saving model ...
EarlyStopping counter: 1 out of 5.0
Validation loss decreased (1.001724 --> 1.000719).  Saving model ...
EarlyStopping counter: 1 out of 5.0
EarlyStopping counter: 2 out of 5.0
Validation loss decreased (1.000719 --> 0.999788).  Saving model ...
EarlyStopping counter: 1 out of 5.0
Validation loss decreased (0.999788 --> 0.997270).  Saving model ...
Validation loss decreased (0.997270 --> 0.995554).  Saving model ...
EarlyStopping counter: 1 out of 5.0
EarlyStopping counter: 2 out of 5.0
Validation loss decreased (0.995554 --> 0.994913).  Saving model ...
EarlyStopping counter: 1 out of 5.0
Validation loss decreased (0.994913 --> 0.993616).  Saving model ...
EarlyStopping counter: 1 out of 5.0
EarlyStopping counter: 2 out of 5.0
Validation loss decreased (0.993616 --> 0.993257).  Saving model ...
EarlyStopping counter: 1 out of 5.0
EarlyStopping counter: 2 out of 5.0
Validation loss decreased (0.993257 --> 0.992341).  Saving model ...
Validation loss decreased (0.992341 --> 0.992069).  Saving model ...
EarlyStopping counter: 1 out of 5.0
Validation loss decreased (0.992069 --> 0.989848).  Saving model ...
EarlyStopping counter: 1 out of 5.0
EarlyStopping counter: 2 out of 5.0
EarlyStopping counter: 3 out of 5.0
EarlyStopping counter: 4 out of 5.0
EarlyStopping counter: 5 out of 5.0
/localscratch/yinan.29028709.0/env/lib/python3.7/site-packages/torch/nn/functional.py:1794: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.
  warnings.warn("nn.functional.tanh is deprecated. Use torch.tanh instead.")
wandb: Waiting for W&B process to finish, PID 54051... (success).
wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: \ 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: | 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: / 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: \ 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: | 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: / 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: \ 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: | 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: / 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb:                                                                                
wandb: Run history:
wandb:     e_F1 â–â–‚â–„â–„â–…â–…â–…â–…â–…â–†â–†â–†â–†â–†â–†â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ
wandb:   e_loss â–ˆâ–ˆâ–‡â–‡â–‡â–†â–†â–†â–…â–…â–…â–„â–„â–„â–ƒâ–ƒâ–ƒâ–ƒâ–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:     t_F1 â–â–â–ƒâ–ƒâ–ƒâ–ƒâ–„â–„â–…â–„â–…â–…â–…â–†â–†â–†â–†â–†â–†â–†â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–ˆâ–ˆâ–ˆâ–ˆâ–‡â–ˆâ–ˆ
wandb:   t_loss â–ˆâ–ˆâ–‡â–‡â–‡â–‡â–†â–†â–†â–†â–…â–…â–…â–…â–„â–„â–„â–„â–„â–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–‚â–ƒâ–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–â–â–â–â–
wandb: 
wandb: Run summary:
wandb:     e_F1 58.24583
wandb:   e_loss 0.99097
wandb:     t_F1 70.7971
wandb:   t_loss 0.77382
wandb: 
wandb: Synced 4 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Synced electric-pond-1: https://wandb.ai/yinanazhou/xl_512_bs_8_lr_1e06_es_5_lc_True_nr_True_sr_True_stem_True_lemma_False_repeat_5_fold_2/runs/13t1y22y
wandb: Find logs at: ./wandb/run-20220316_165234-13t1y22y/logs/debug.log
wandb: 

