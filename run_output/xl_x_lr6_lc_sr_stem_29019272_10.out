Unloading StdEnv/2020

Due to MODULEPATH changes, the following have been reloaded:
  1) mii/1.1.1


The following have been reloaded with a version change:
  1) python/3.8.2 => python/3.7.4

Using base prefix '/cvmfs/soft.computecanada.ca/easybuild/software/2017/Core/python/3.7.4'
New python executable in /localscratch/yinan.29019272.0/env/bin/python
Installing setuptools, pip, wheel...
done.
Ignoring pip: markers 'python_version < "3"' don't match your environment
Looking in links: /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/nix/avx2, /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/nix/generic, /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic
Collecting pip
Installing collected packages: pip
  Found existing installation: pip 19.1.1
    Uninstalling pip-19.1.1:
      Successfully uninstalled pip-19.1.1
Successfully installed pip-21.2.3+computecanada
Looking in links: /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/nix/avx2, /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/nix/generic, /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/keras-2.8.0+computecanada-py2.py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/Keras_Preprocessing-1.1.2+computecanada-py3-none-any.whl
Requirement already satisfied: matplotlib in /cvmfs/soft.computecanada.ca/easybuild/software/2017/Core/scipy-stack/2019a/lib/python3.7/site-packages (from -r requirements.txt (line 3)) (3.0.2)
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/nltk-3.6.5+computecanada-py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/scikit_learn-0.22.1+computecanada-cp37-cp37m-linux_x86_64.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/tensorboard-2.3.0+computecanada-py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/tensorboard_plugin_wit-1.7.0+computecanada-py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/tensorflow_gpu-2.3.0+computecanada-cp37-cp37m-linux_x86_64.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/tensorflow_estimator-2.3.0+computecanada-py2.py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/tokenizers-0.5.2+computecanada-cp37-cp37m-linux_x86_64.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/nix/avx2/torch-1.4.0+computecanada-cp37-cp37m-linux_x86_64.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/torchtext-0.6.0+computecanada-py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/torchvision-0.8.2+computecanada-cp37-cp37m-linux_x86_64.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/transformers-2.5.1+computecanada-py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/urllib3-1.26.7+computecanada-py2.py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/joblib-1.1.0+computecanada-py2.py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/click-8.0.4+computecanada-py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/tqdm-4.63.0+computecanada-py2.py3-none-any.whl
ERROR: Could not find a version that satisfies the requirement regex>=2021.8.3 (from nltk) (from versions: 2018.1.10+computecanada, 2019.11.1+computecanada, 2020.11.13+computecanada)
ERROR: No matching distribution found for regex>=2021.8.3
Looking in links: /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/nix/avx2, /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/nix/generic, /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic
ERROR: Could not find a version that satisfies the requirement numpy==1.20.0+computacanada (from versions: 1.15.0+computecanada, 1.15.2+computecanada, 1.15.4+computecanada, 1.16.0+computecanada, 1.16.2+computecanada, 1.16.3+computecanada, 1.17.4+computecanada, 1.18.1+computecanada, 1.18.4+computecanada, 1.19.1+computecanada, 1.19.2+computecanada, 1.20.2+computecanada)
ERROR: No matching distribution found for numpy==1.20.0+computacanada
Looking in links: /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/nix/avx2, /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/nix/generic, /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/wandb-0.12.5+computecanada-py2.py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/configparser-5.0.2+computecanada-py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/docker_pycreds-0.4.0+computecanada-py2.py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/six-1.16.0+computecanada-py2.py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/psutil-5.7.3+computecanada-cp37-cp37m-linux_x86_64.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/subprocess32-3.5.4+computecanada-py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/protobuf-3.19.4+computecanada-py2.py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/PyYAML-5.3.1+computecanada-cp37-cp37m-linux_x86_64.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/click-8.0.4+computecanada-py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/promise-2.3+computecanada-py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/pathtools-0.1.2+computecanada-py3-none-any.whl
Requirement already satisfied: python-dateutil>=2.6.1 in /cvmfs/soft.computecanada.ca/easybuild/software/2017/Core/scipy-stack/2019a/lib/python3.7/site-packages (from wandb) (2.7.5)
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/sentry_sdk-1.5.0+computecanada-py2.py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/yaspin-2.1.0+computecanada-py3-none-any.whl
Requirement already satisfied: requests<3,>=2.0.0 in /cvmfs/soft.computecanada.ca/easybuild/software/2017/Core/scipy-stack/2019a/lib/python3.7/site-packages (from wandb) (2.21.0)
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/shortuuid-1.0.1+computecanada-py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/GitPython-3.1.24+computecanada-py3-none-any.whl
Requirement already satisfied: importlib-metadata in /cvmfs/soft.computecanada.ca/easybuild/software/2017/Core/scipy-stack/2019a/lib/python3.7/site-packages (from Click!=8.0.0,>=7.0->wandb) (0.8)
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/gitdb-4.0.9+computecanada-py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/typing_extensions-4.0.1+computecanada-py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/smmap-5.0.0+computecanada-py3-none-any.whl
Requirement already satisfied: certifi>=2017.4.17 in /cvmfs/soft.computecanada.ca/easybuild/software/2017/Core/scipy-stack/2019a/lib/python3.7/site-packages (from requests<3,>=2.0.0->wandb) (2018.11.29)
Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /cvmfs/soft.computecanada.ca/easybuild/software/2017/Core/scipy-stack/2019a/lib/python3.7/site-packages (from requests<3,>=2.0.0->wandb) (3.0.4)
Requirement already satisfied: urllib3<1.25,>=1.21.1 in /cvmfs/soft.computecanada.ca/easybuild/software/2017/Core/scipy-stack/2019a/lib/python3.7/site-packages (from requests<3,>=2.0.0->wandb) (1.24.1)
Requirement already satisfied: idna<2.9,>=2.5 in /cvmfs/soft.computecanada.ca/easybuild/software/2017/Core/scipy-stack/2019a/lib/python3.7/site-packages (from requests<3,>=2.0.0->wandb) (2.8)
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/termcolor-1.1.0+computecanada-py3-none-any.whl
Requirement already satisfied: zipp>=0.3.2 in /cvmfs/soft.computecanada.ca/easybuild/software/2017/Core/scipy-stack/2019a/lib/python3.7/site-packages (from importlib-metadata->Click!=8.0.0,>=7.0->wandb) (0.3.3)
Installing collected packages: smmap, typing-extensions, termcolor, six, gitdb, yaspin, subprocess32, shortuuid, sentry-sdk, PyYAML, psutil, protobuf, promise, pathtools, GitPython, docker-pycreds, configparser, Click, wandb
  Attempting uninstall: six
    Found existing installation: six 1.12.0
    Not uninstalling six at /cvmfs/soft.computecanada.ca/easybuild/software/2017/Core/scipy-stack/2019a/lib/python3.7/site-packages, outside environment /localscratch/yinan.29019272.0/env
    Can't uninstall 'six'. No files were found to uninstall.
Successfully installed Click-8.0.4+computecanada GitPython-3.1.24+computecanada PyYAML-5.3.1+computecanada configparser-5.0.2+computecanada docker-pycreds-0.4.0+computecanada gitdb-4.0.9+computecanada pathtools-0.1.2+computecanada promise-2.3+computecanada protobuf-3.19.4+computecanada psutil-5.7.3+computecanada sentry-sdk-1.5.0+computecanada shortuuid-1.0.1+computecanada six-1.16.0+computecanada smmap-5.0.0+computecanada subprocess32-3.5.4+computecanada termcolor-1.1.0+computecanada typing-extensions-4.0.1+computecanada wandb-0.12.5+computecanada yaspin-2.1.0+computecanada
Looking in links: /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/nix/avx2, /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/nix/generic, /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic
ERROR: Could not find a version that satisfies the requirement sagemaker (from versions: none)
ERROR: No matching distribution found for sagemaker
Looking in links: /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/nix/avx2, /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/nix/generic, /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/torch-1.9.1+computecanada-cp37-cp37m-linux_x86_64.whl
Requirement already satisfied: typing-extensions in /localscratch/yinan.29019272.0/env/lib/python3.7/site-packages (from torch) (4.0.1+computecanada)
Installing collected packages: torch
Successfully installed torch-1.9.1+computecanada
Looking in links: /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/nix/avx2, /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/nix/generic, /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/transformers-2.5.1+computecanada-py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/sentencepiece-0.1.91+computecanada-cp37-cp37m-linux_x86_64.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/sacremoses-0.0.46+computecanada-py3-none-any.whl
Requirement already satisfied: requests in /cvmfs/soft.computecanada.ca/easybuild/software/2017/Core/scipy-stack/2019a/lib/python3.7/site-packages (from transformers==2.5.1+computecanada) (2.21.0)
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/regex-2020.11.13+computecanada-cp37-cp37m-linux_x86_64.whl
Requirement already satisfied: numpy in /cvmfs/soft.computecanada.ca/easybuild/software/2017/Core/scipy-stack/2019a/lib/python3.7/site-packages (from transformers==2.5.1+computecanada) (1.16.0)
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/tqdm-4.63.0+computecanada-py2.py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/tokenizers-0.5.2+computecanada-cp37-cp37m-linux_x86_64.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/filelock-3.4.2+computecanada-py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/boto3-1.21.14+computecanada-py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/s3transfer-0.5.1+computecanada-py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/botocore-1.24.14+computecanada-py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/jmespath-0.10.0+computecanada-py2.py3-none-any.whl
Requirement already satisfied: python-dateutil<3.0.0,>=2.1 in /cvmfs/soft.computecanada.ca/easybuild/software/2017/Core/scipy-stack/2019a/lib/python3.7/site-packages (from botocore<1.25.0,>=1.24.14->boto3->transformers==2.5.1+computecanada) (2.7.5)
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/urllib3-1.26.8+computecanada-py2.py3-none-any.whl
Requirement already satisfied: six>=1.5 in /localscratch/yinan.29019272.0/env/lib/python3.7/site-packages (from python-dateutil<3.0.0,>=2.1->botocore<1.25.0,>=1.24.14->boto3->transformers==2.5.1+computecanada) (1.16.0+computecanada)
Requirement already satisfied: idna<2.9,>=2.5 in /cvmfs/soft.computecanada.ca/easybuild/software/2017/Core/scipy-stack/2019a/lib/python3.7/site-packages (from requests->transformers==2.5.1+computecanada) (2.8)
Requirement already satisfied: certifi>=2017.4.17 in /cvmfs/soft.computecanada.ca/easybuild/software/2017/Core/scipy-stack/2019a/lib/python3.7/site-packages (from requests->transformers==2.5.1+computecanada) (2018.11.29)
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/requests-2.27.1+computecanada-py2.py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/charset_normalizer-2.0.12+computecanada-py3-none-any.whl
Requirement already satisfied: click in /localscratch/yinan.29019272.0/env/lib/python3.7/site-packages (from sacremoses->transformers==2.5.1+computecanada) (8.0.4+computecanada)
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/joblib-1.1.0+computecanada-py2.py3-none-any.whl
Requirement already satisfied: importlib-metadata in /cvmfs/soft.computecanada.ca/easybuild/software/2017/Core/scipy-stack/2019a/lib/python3.7/site-packages (from click->sacremoses->transformers==2.5.1+computecanada) (0.8)
Requirement already satisfied: zipp>=0.3.2 in /cvmfs/soft.computecanada.ca/easybuild/software/2017/Core/scipy-stack/2019a/lib/python3.7/site-packages (from importlib-metadata->click->sacremoses->transformers==2.5.1+computecanada) (0.3.3)
Installing collected packages: urllib3, jmespath, botocore, tqdm, s3transfer, regex, joblib, charset-normalizer, tokenizers, sentencepiece, sacremoses, requests, filelock, boto3, transformers
  Attempting uninstall: urllib3
    Found existing installation: urllib3 1.24.1
    Not uninstalling urllib3 at /cvmfs/soft.computecanada.ca/easybuild/software/2017/Core/scipy-stack/2019a/lib/python3.7/site-packages, outside environment /localscratch/yinan.29019272.0/env
    Can't uninstall 'urllib3'. No files were found to uninstall.
  Attempting uninstall: requests
    Found existing installation: requests 2.21.0
    Not uninstalling requests at /cvmfs/soft.computecanada.ca/easybuild/software/2017/Core/scipy-stack/2019a/lib/python3.7/site-packages, outside environment /localscratch/yinan.29019272.0/env
    Can't uninstall 'requests'. No files were found to uninstall.
Successfully installed boto3-1.21.14+computecanada botocore-1.24.14+computecanada charset-normalizer-2.0.12+computecanada filelock-3.4.2+computecanada jmespath-0.10.0+computecanada joblib-1.1.0+computecanada regex-2020.11.13+computecanada requests-2.27.1+computecanada s3transfer-0.5.1+computecanada sacremoses-0.0.46+computecanada sentencepiece-0.1.91+computecanada tokenizers-0.5.2+computecanada tqdm-4.63.0+computecanada transformers-2.5.1+computecanada urllib3-1.26.8+computecanada
Looking in links: /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/nix/avx2, /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/nix/generic, /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/tensorflow_gpu-2.3.0+computecanada-cp37-cp37m-linux_x86_64.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/astunparse-1.6.3+computecanada-py2.py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/wrapt-1.11.2+computecanada-cp37-cp37m-linux_x86_64.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/nix/generic/scipy-1.4.1+computecanada-cp37-cp37m-linux_x86_64.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/gast-0.3.3+computecanada-py3-none-any.whl
Requirement already satisfied: wheel>=0.26 in /localscratch/yinan.29019272.0/env/lib/python3.7/site-packages (from tensorflow_gpu==2.3.0+computecanada) (0.33.4)
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/nix/avx2/h5py-2.10.0+computecanada-cp37-cp37m-linux_x86_64.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/Keras_Preprocessing-1.1.2+computecanada-py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/tensorboard-2.8.0+computecanada-py3-none-any.whl
Requirement already satisfied: six>=1.12.0 in /localscratch/yinan.29019272.0/env/lib/python3.7/site-packages (from tensorflow_gpu==2.3.0+computecanada) (1.16.0+computecanada)
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/grpcio-1.38.0+computecanada-cp37-cp37m-linux_x86_64.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/tensorflow_estimator-2.3.0+computecanada-py2.py3-none-any.whl
Requirement already satisfied: termcolor>=1.1.0 in /localscratch/yinan.29019272.0/env/lib/python3.7/site-packages (from tensorflow_gpu==2.3.0+computecanada) (1.1.0+computecanada)
Requirement already satisfied: numpy<1.19.0,>=1.16.0 in /cvmfs/soft.computecanada.ca/easybuild/software/2017/Core/scipy-stack/2019a/lib/python3.7/site-packages (from tensorflow_gpu==2.3.0+computecanada) (1.16.0)
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/google_pasta-0.2.0+computecanada-py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/absl_py-1.0.0+computecanada-py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/opt_einsum-3.3.0+computecanada-py3-none-any.whl
Requirement already satisfied: protobuf>=3.9.2 in /localscratch/yinan.29019272.0/env/lib/python3.7/site-packages (from tensorflow_gpu==2.3.0+computecanada) (3.19.4+computecanada)
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/google_auth_oauthlib-0.4.6+computecanada-py2.py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/Markdown-3.3.6+computecanada-py3-none-any.whl
Requirement already satisfied: setuptools>=41.0.0 in /localscratch/yinan.29019272.0/env/lib/python3.7/site-packages (from tensorboard<3,>=2.3.0->tensorflow_gpu==2.3.0+computecanada) (41.0.1)
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/Werkzeug-2.0.3+computecanada-py3-none-any.whl
Requirement already satisfied: requests<3,>=2.21.0 in /localscratch/yinan.29019272.0/env/lib/python3.7/site-packages (from tensorboard<3,>=2.3.0->tensorflow_gpu==2.3.0+computecanada) (2.27.1+computecanada)
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/tensorboard_plugin_wit-1.8.0+computecanada-py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/tensorboard_data_server-0.6.1+computecanada-py3-none-linux_x86_64.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/google_auth-2.3.3+computecanada-py2.py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/rsa-4.8+computecanada-py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/cachetools-4.2.4+computecanada-py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/pyasn1_modules-0.2.8+computecanada-py2.py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/requests_oauthlib-1.3.0+computecanada-py2.py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/importlib_metadata-4.10.1+computecanada-py3-none-any.whl
Requirement already satisfied: typing-extensions>=3.6.4 in /localscratch/yinan.29019272.0/env/lib/python3.7/site-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard<3,>=2.3.0->tensorflow_gpu==2.3.0+computecanada) (4.0.1+computecanada)
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/zipp-3.7.0+computecanada-py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/pyasn1-0.4.8+computecanada-py2.py3-none-any.whl
Requirement already satisfied: certifi>=2017.4.17 in /cvmfs/soft.computecanada.ca/easybuild/software/2017/Core/scipy-stack/2019a/lib/python3.7/site-packages (from requests<3,>=2.21.0->tensorboard<3,>=2.3.0->tensorflow_gpu==2.3.0+computecanada) (2018.11.29)
Requirement already satisfied: charset-normalizer~=2.0.0 in /localscratch/yinan.29019272.0/env/lib/python3.7/site-packages (from requests<3,>=2.21.0->tensorboard<3,>=2.3.0->tensorflow_gpu==2.3.0+computecanada) (2.0.12+computecanada)
Requirement already satisfied: urllib3<1.27,>=1.21.1 in /localscratch/yinan.29019272.0/env/lib/python3.7/site-packages (from requests<3,>=2.21.0->tensorboard<3,>=2.3.0->tensorflow_gpu==2.3.0+computecanada) (1.26.8+computecanada)
Requirement already satisfied: idna<4,>=2.5 in /cvmfs/soft.computecanada.ca/easybuild/software/2017/Core/scipy-stack/2019a/lib/python3.7/site-packages (from requests<3,>=2.21.0->tensorboard<3,>=2.3.0->tensorflow_gpu==2.3.0+computecanada) (2.8)
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/oauthlib-3.1.1+computecanada-py2.py3-none-any.whl
Installing collected packages: pyasn1, zipp, rsa, pyasn1-modules, oauthlib, cachetools, requests-oauthlib, importlib-metadata, google-auth, werkzeug, tensorboard-plugin-wit, tensorboard-data-server, markdown, grpcio, google-auth-oauthlib, absl-py, wrapt, tensorflow-estimator, tensorboard, scipy, opt-einsum, keras-preprocessing, h5py, google-pasta, gast, astunparse, tensorflow-gpu
  Attempting uninstall: pyasn1
    Found existing installation: pyasn1 0.4.3
    Not uninstalling pyasn1 at /cvmfs/soft.computecanada.ca/easybuild/software/2017/Core/scipy-stack/2019a/lib/python3.7/site-packages, outside environment /localscratch/yinan.29019272.0/env
    Can't uninstall 'pyasn1'. No files were found to uninstall.
  Attempting uninstall: zipp
    Found existing installation: zipp 0.3.3
    Not uninstalling zipp at /cvmfs/soft.computecanada.ca/easybuild/software/2017/Core/scipy-stack/2019a/lib/python3.7/site-packages, outside environment /localscratch/yinan.29019272.0/env
    Can't uninstall 'zipp'. No files were found to uninstall.
  Attempting uninstall: importlib-metadata
    Found existing installation: importlib-metadata 0.8
    Not uninstalling importlib-metadata at /cvmfs/soft.computecanada.ca/easybuild/software/2017/Core/scipy-stack/2019a/lib/python3.7/site-packages, outside environment /localscratch/yinan.29019272.0/env
    Can't uninstall 'importlib-metadata'. No files were found to uninstall.
  Attempting uninstall: scipy
    Found existing installation: scipy 1.2.0
    Not uninstalling scipy at /cvmfs/soft.computecanada.ca/easybuild/software/2017/Core/scipy-stack/2019a/lib/python3.7/site-packages, outside environment /localscratch/yinan.29019272.0/env
    Can't uninstall 'scipy'. No files were found to uninstall.
Successfully installed absl-py-1.0.0+computecanada astunparse-1.6.3+computecanada cachetools-4.2.4+computecanada gast-0.3.3+computecanada google-auth-2.3.3+computecanada google-auth-oauthlib-0.4.6+computecanada google-pasta-0.2.0+computecanada grpcio-1.38.0+computecanada h5py-2.10.0+computecanada importlib-metadata-4.10.1+computecanada keras-preprocessing-1.1.2+computecanada markdown-3.3.6+computecanada oauthlib-3.1.1+computecanada opt-einsum-3.3.0+computecanada pyasn1-0.4.8+computecanada pyasn1-modules-0.2.8+computecanada requests-oauthlib-1.3.0+computecanada rsa-4.8+computecanada scipy-1.4.1+computecanada tensorboard-2.8.0+computecanada tensorboard-data-server-0.6.1+computecanada tensorboard-plugin-wit-1.8.0+computecanada tensorflow-estimator-2.3.0+computecanada tensorflow-gpu-2.3.0+computecanada werkzeug-2.0.3+computecanada wrapt-1.11.2+computecanada zipp-3.7.0+computecanada
Looking in links: /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/nix/avx2, /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/nix/generic, /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/keras-2.8.0+computecanada-py2.py3-none-any.whl
Installing collected packages: Keras
Successfully installed Keras-2.8.0+computecanada
Looking in links: /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/nix/avx2, /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/nix/generic, /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/urllib3-1.26.7+computecanada-py2.py3-none-any.whl
Installing collected packages: urllib3
  Attempting uninstall: urllib3
    Found existing installation: urllib3 1.26.8+computecanada
    Uninstalling urllib3-1.26.8+computecanada:
      Successfully uninstalled urllib3-1.26.8+computecanada
Successfully installed urllib3-1.26.7+computecanada
Looking in links: /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/nix/avx2, /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/nix/generic, /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/nltk-3.7+computecanada-py3-none-any.whl
Requirement already satisfied: tqdm in /localscratch/yinan.29019272.0/env/lib/python3.7/site-packages (from nltk) (4.63.0+computecanada)
Requirement already satisfied: click in /localscratch/yinan.29019272.0/env/lib/python3.7/site-packages (from nltk) (8.0.4+computecanada)
Requirement already satisfied: joblib in /localscratch/yinan.29019272.0/env/lib/python3.7/site-packages (from nltk) (1.1.0+computecanada)
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/nltk-3.6.5+computecanada-py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/nltk-3.6.3+computecanada-py3-none-any.whl
Requirement already satisfied: regex in /localscratch/yinan.29019272.0/env/lib/python3.7/site-packages (from nltk) (2020.11.13+computecanada)
Requirement already satisfied: importlib-metadata in /localscratch/yinan.29019272.0/env/lib/python3.7/site-packages (from click->nltk) (4.10.1+computecanada)
Requirement already satisfied: zipp>=0.5 in /localscratch/yinan.29019272.0/env/lib/python3.7/site-packages (from importlib-metadata->click->nltk) (3.7.0+computecanada)
Requirement already satisfied: typing-extensions>=3.6.4 in /localscratch/yinan.29019272.0/env/lib/python3.7/site-packages (from importlib-metadata->click->nltk) (4.0.1+computecanada)
Installing collected packages: nltk
Successfully installed nltk-3.6.3+computecanada
Looking in links: /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/nix/avx2, /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/nix/generic, /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/scikit_learn-0.22.1+computecanada-cp37-cp37m-linux_x86_64.whl
Requirement already satisfied: numpy>=1.11.0 in /cvmfs/soft.computecanada.ca/easybuild/software/2017/Core/scipy-stack/2019a/lib/python3.7/site-packages (from scikit-learn==0.22.1) (1.16.0)
Requirement already satisfied: scipy>=0.17.0 in /localscratch/yinan.29019272.0/env/lib/python3.7/site-packages (from scikit-learn==0.22.1) (1.4.1+computecanada)
Requirement already satisfied: joblib>=0.11 in /localscratch/yinan.29019272.0/env/lib/python3.7/site-packages (from scikit-learn==0.22.1) (1.1.0+computecanada)
Installing collected packages: scikit-learn
Successfully installed scikit-learn-0.22.1+computecanada
Looking in links: /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/nix/avx2, /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/nix/generic, /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic
Requirement already satisfied: tokenizers==0.5.2 in /localscratch/yinan.29019272.0/env/lib/python3.7/site-packages (0.5.2+computecanada)
wandb: Appending key for api.wandb.ai to your netrc file: /home/yinan/.netrc
Starting Task
2022-03-17 07:17:27.163398: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1
[nltk_data] Downloading package stopwords to /home/yinan/nltk_data...
[nltk_data]   Package stopwords is already up-to-date!
[nltk_data] Downloading package wordnet to /home/yinan/nltk_data...
[nltk_data]   Package wordnet is already up-to-date!
wandb: Currently logged in as: yinanazhou (use `wandb login --relogin` to force relogin)
wandb: wandb version 0.12.11 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
2022-03-17 07:17:45.642911: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1
wandb: Tracking run with wandb version 0.12.5
wandb: Syncing run proud-feather-1
wandb: ⭐️ View project at https://wandb.ai/yinanazhou/xl_512_bs_8_lr_1e06_es_10_lc_True_nr_False_sr_True_stem_True_lemma_False_repeat_1_fold_1
wandb: 🚀 View run at https://wandb.ai/yinanazhou/xl_512_bs_8_lr_1e06_es_10_lc_True_nr_False_sr_True_stem_True_lemma_False_repeat_1_fold_1/runs/1v36ffsu
wandb: Run data is saved locally in /project/6002780/yinan/Thesis_MER_Lyrics/lyric-emotion/wandb/run-20220317_071743-1v36ffsu
wandb: Run `wandb offline` to turn off syncing.

Validation loss decreased (inf --> 1.430210).  Saving model ...
Validation loss decreased (1.430210 --> 1.412249).  Saving model ...
Validation loss decreased (1.412249 --> 1.397505).  Saving model ...
Validation loss decreased (1.397505 --> 1.384806).  Saving model ...
Validation loss decreased (1.384806 --> 1.375036).  Saving model ...
Validation loss decreased (1.375036 --> 1.366992).  Saving model ...
Validation loss decreased (1.366992 --> 1.360318).  Saving model ...
Validation loss decreased (1.360318 --> 1.354317).  Saving model ...
Validation loss decreased (1.354317 --> 1.349033).  Saving model ...
Validation loss decreased (1.349033 --> 1.343130).  Saving model ...
Validation loss decreased (1.343130 --> 1.337345).  Saving model ...
Validation loss decreased (1.337345 --> 1.332209).  Saving model ...
Validation loss decreased (1.332209 --> 1.326985).  Saving model ...
Validation loss decreased (1.326985 --> 1.322089).  Saving model ...
Validation loss decreased (1.322089 --> 1.316468).  Saving model ...
Validation loss decreased (1.316468 --> 1.311502).  Saving model ...
Validation loss decreased (1.311502 --> 1.306029).  Saving model ...
Validation loss decreased (1.306029 --> 1.300590).  Saving model ...
Validation loss decreased (1.300590 --> 1.295294).  Saving model ...
Validation loss decreased (1.295294 --> 1.289089).  Saving model ...
Validation loss decreased (1.289089 --> 1.283232).  Saving model ...
Validation loss decreased (1.283232 --> 1.277649).  Saving model ...
Validation loss decreased (1.277649 --> 1.271788).  Saving model ...
Validation loss decreased (1.271788 --> 1.266046).  Saving model ...
Validation loss decreased (1.266046 --> 1.260479).  Saving model ...
Validation loss decreased (1.260479 --> 1.255159).  Saving model ...
Validation loss decreased (1.255159 --> 1.249375).  Saving model ...
Validation loss decreased (1.249375 --> 1.244089).  Saving model ...
Validation loss decreased (1.244089 --> 1.239751).  Saving model ...
Validation loss decreased (1.239751 --> 1.234297).  Saving model ...
Validation loss decreased (1.234297 --> 1.229342).  Saving model ...
Validation loss decreased (1.229342 --> 1.224513).  Saving model ...
Validation loss decreased (1.224513 --> 1.219727).  Saving model ...
Validation loss decreased (1.219727 --> 1.214424).  Saving model ...
Validation loss decreased (1.214424 --> 1.210924).  Saving model ...
Validation loss decreased (1.210924 --> 1.206348).  Saving model ...
Validation loss decreased (1.206348 --> 1.201905).  Saving model ...
Validation loss decreased (1.201905 --> 1.197582).  Saving model ...
Validation loss decreased (1.197582 --> 1.194820).  Saving model ...
Validation loss decreased (1.194820 --> 1.190910).  Saving model ...
Validation loss decreased (1.190910 --> 1.184925).  Saving model ...
Validation loss decreased (1.184925 --> 1.182018).  Saving model ...
Validation loss decreased (1.182018 --> 1.179328).  Saving model ...
Validation loss decreased (1.179328 --> 1.175264).  Saving model ...
Validation loss decreased (1.175264 --> 1.172412).  Saving model ...
Validation loss decreased (1.172412 --> 1.167712).  Saving model ...
Validation loss decreased (1.167712 --> 1.163357).  Saving model ...
Validation loss decreased (1.163357 --> 1.162127).  Saving model ...
Validation loss decreased (1.162127 --> 1.156737).  Saving model ...
Validation loss decreased (1.156737 --> 1.151515).  Saving model ...
Validation loss decreased (1.151515 --> 1.148340).  Saving model ...
Validation loss decreased (1.148340 --> 1.145097).  Saving model ...
Validation loss decreased (1.145097 --> 1.142837).  Saving model ...
Validation loss decreased (1.142837 --> 1.141051).  Saving model ...
Validation loss decreased (1.141051 --> 1.138547).  Saving model ...
Validation loss decreased (1.138547 --> 1.131931).  Saving model ...
Validation loss decreased (1.131931 --> 1.129908).  Saving model ...
Validation loss decreased (1.129908 --> 1.126883).  Saving model ...
Validation loss decreased (1.126883 --> 1.121798).  Saving model ...
Validation loss decreased (1.121798 --> 1.120669).  Saving model ...
Validation loss decreased (1.120669 --> 1.118011).  Saving model ...
Validation loss decreased (1.118011 --> 1.116920).  Saving model ...
Validation loss decreased (1.116920 --> 1.112071).  Saving model ...
Validation loss decreased (1.112071 --> 1.109591).  Saving model ...
EarlyStopping counter: 1 out of 10.0
Validation loss decreased (1.109591 --> 1.106922).  Saving model ...
Validation loss decreased (1.106922 --> 1.103593).  Saving model ...
Validation loss decreased (1.103593 --> 1.098547).  Saving model ...
Validation loss decreased (1.098547 --> 1.095867).  Saving model ...
Validation loss decreased (1.095867 --> 1.092458).  Saving model ...
Validation loss decreased (1.092458 --> 1.088707).  Saving model ...
EarlyStopping counter: 1 out of 10.0
Validation loss decreased (1.088707 --> 1.085272).  Saving model ...
Validation loss decreased (1.085272 --> 1.082917).  Saving model ...
Validation loss decreased (1.082917 --> 1.080597).  Saving model ...
Validation loss decreased (1.080597 --> 1.079706).  Saving model ...
Validation loss decreased (1.079706 --> 1.079162).  Saving model ...
Validation loss decreased (1.079162 --> 1.076865).  Saving model ...
Validation loss decreased (1.076865 --> 1.071596).  Saving model ...
Validation loss decreased (1.071596 --> 1.068601).  Saving model ...
Validation loss decreased (1.068601 --> 1.068073).  Saving model ...
Validation loss decreased (1.068073 --> 1.066345).  Saving model ...
Validation loss decreased (1.066345 --> 1.064647).  Saving model ...
EarlyStopping counter: 1 out of 10.0
Validation loss decreased (1.064647 --> 1.060166).  Saving model ...
Validation loss decreased (1.060166 --> 1.059190).  Saving model ...
Validation loss decreased (1.059190 --> 1.056568).  Saving model ...
EarlyStopping counter: 1 out of 10.0
Validation loss decreased (1.056568 --> 1.054544).  Saving model ...
Validation loss decreased (1.054544 --> 1.050973).  Saving model ...
EarlyStopping counter: 1 out of 10.0
Validation loss decreased (1.050973 --> 1.050481).  Saving model ...
Validation loss decreased (1.050481 --> 1.048481).  Saving model ...
EarlyStopping counter: 1 out of 10.0
EarlyStopping counter: 2 out of 10.0
Validation loss decreased (1.048481 --> 1.047805).  Saving model ...
Validation loss decreased (1.047805 --> 1.044778).  Saving model ...
Validation loss decreased (1.044778 --> 1.040265).  Saving model ...
Validation loss decreased (1.040265 --> 1.038755).  Saving model ...
EarlyStopping counter: 1 out of 10.0
Validation loss decreased (1.038755 --> 1.037378).  Saving model ...
Validation loss decreased (1.037378 --> 1.036332).  Saving model ...
EarlyStopping counter: 1 out of 10.0
EarlyStopping counter: 2 out of 10.0
EarlyStopping counter: 3 out of 10.0
Validation loss decreased (1.036332 --> 1.033114).  Saving model ...
Validation loss decreased (1.033114 --> 1.032515).  Saving model ...
EarlyStopping counter: 1 out of 10.0
Validation loss decreased (1.032515 --> 1.029543).  Saving model ...
Validation loss decreased (1.029543 --> 1.026258).  Saving model ...
EarlyStopping counter: 1 out of 10.0
EarlyStopping counter: 2 out of 10.0
EarlyStopping counter: 3 out of 10.0
EarlyStopping counter: 4 out of 10.0
EarlyStopping counter: 5 out of 10.0
EarlyStopping counter: 6 out of 10.0
Validation loss decreased (1.026258 --> 1.024168).  Saving model ...
Validation loss decreased (1.024168 --> 1.023332).  Saving model ...
Validation loss decreased (1.023332 --> 1.022775).  Saving model ...
Validation loss decreased (1.022775 --> 1.020387).  Saving model ...
Validation loss decreased (1.020387 --> 1.018881).  Saving model ...
EarlyStopping counter: 1 out of 10.0
Validation loss decreased (1.018881 --> 1.018528).  Saving model ...
EarlyStopping counter: 1 out of 10.0
Validation loss decreased (1.018528 --> 1.016527).  Saving model ...
EarlyStopping counter: 1 out of 10.0
EarlyStopping counter: 2 out of 10.0
EarlyStopping counter: 3 out of 10.0
EarlyStopping counter: 4 out of 10.0
EarlyStopping counter: 5 out of 10.0
Validation loss decreased (1.016527 --> 1.015517).  Saving model ...
EarlyStopping counter: 1 out of 10.0
EarlyStopping counter: 2 out of 10.0
EarlyStopping counter: 3 out of 10.0
EarlyStopping counter: 4 out of 10.0
EarlyStopping counter: 5 out of 10.0
EarlyStopping counter: 6 out of 10.0
Validation loss decreased (1.015517 --> 1.015110).  Saving model ...
EarlyStopping counter: 1 out of 10.0
Validation loss decreased (1.015110 --> 1.014981).  Saving model ...
EarlyStopping counter: 1 out of 10.0
EarlyStopping counter: 2 out of 10.0
EarlyStopping counter: 3 out of 10.0
EarlyStopping counter: 4 out of 10.0
Validation loss decreased (1.014981 --> 1.014449).  Saving model ...
Validation loss decreased (1.014449 --> 1.013413).  Saving model ...
EarlyStopping counter: 1 out of 10.0
EarlyStopping counter: 2 out of 10.0
EarlyStopping counter: 3 out of 10.0
EarlyStopping counter: 4 out of 10.0
EarlyStopping counter: 5 out of 10.0
EarlyStopping counter: 6 out of 10.0
EarlyStopping counter: 7 out of 10.0
EarlyStopping counter: 8 out of 10.0
EarlyStopping counter: 9 out of 10.0
EarlyStopping counter: 10 out of 10.0
/localscratch/yinan.29019272.0/env/lib/python3.7/site-packages/torch/nn/functional.py:1794: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.
  warnings.warn("nn.functional.tanh is deprecated. Use torch.tanh instead.")
/localscratch/yinan.29019272.0/env/lib/python3.7/site-packages/transformers/optimization.py:155: UserWarning: This overload of add_ is deprecated:
	add_(Number alpha, Tensor other)
Consider using one of the following signatures instead:
	add_(Tensor other, *, Number alpha) (Triggered internally at  ../torch/csrc/utils/python_arg_parser.cpp:1025.)
  exp_avg.mul_(beta1).add_(1.0 - beta1, grad)
wandb: Waiting for W&B process to finish, PID 167607... (success).
wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: \ 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: | 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: / 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: \ 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: | 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: / 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: \ 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: | 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: / 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb:                                                                                
wandb: Run history:
wandb:     e_F1 ▁▂▃▄▅▅▆▆▆▆▆▆▆▆▇▇▇▇▇▇▇▇▇▇▇███████████████
wandb:   e_loss ██▇▇▆▆▅▅▅▄▄▄▄▃▃▃▃▂▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:     t_F1 ▁▁▂▃▃▄▄▄▅▅▅▅▅▆▆▇▆▆▇▆▇▇▇▇▇▇▇▇▇▇▇▇████████
wandb:   t_loss ███▇▇▆▆▆▆▆▅▅▅▄▄▄▄▄▃▃▃▃▃▃▃▂▂▂▂▂▂▂▁▂▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:     e_F1 57.22852
wandb:   e_loss 1.01541
wandb:     t_F1 71.07596
wandb:   t_loss 0.71646
wandb: 
wandb: Synced 4 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Synced proud-feather-1: https://wandb.ai/yinanazhou/xl_512_bs_8_lr_1e06_es_10_lc_True_nr_False_sr_True_stem_True_lemma_False_repeat_1_fold_1/runs/1v36ffsu
wandb: Find logs at: ./wandb/run-20220317_071743-1v36ffsu/logs/debug.log
wandb: 

wandb: wandb version 0.12.11 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
2022-03-17 08:58:47.863336: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1
wandb: Tracking run with wandb version 0.12.5
wandb: Syncing run eager-capybara-1
wandb: ⭐️ View project at https://wandb.ai/yinanazhou/xl_512_bs_8_lr_1e06_es_10_lc_True_nr_False_sr_True_stem_True_lemma_False_repeat_1_fold_2
wandb: 🚀 View run at https://wandb.ai/yinanazhou/xl_512_bs_8_lr_1e06_es_10_lc_True_nr_False_sr_True_stem_True_lemma_False_repeat_1_fold_2/runs/ul8ccja3
wandb: Run data is saved locally in /project/6002780/yinan/Thesis_MER_Lyrics/lyric-emotion/wandb/run-20220317_085845-ul8ccja3
wandb: Run `wandb offline` to turn off syncing.
wandb: Network error (ReadTimeout), entering retry loop.

Validation loss decreased (inf --> 1.411218).  Saving model ...
Validation loss decreased (1.411218 --> 1.403848).  Saving model ...
Validation loss decreased (1.403848 --> 1.398009).  Saving model ...
Validation loss decreased (1.398009 --> 1.392874).  Saving model ...
Validation loss decreased (1.392874 --> 1.387908).  Saving model ...
Validation loss decreased (1.387908 --> 1.384165).  Saving model ...
Validation loss decreased (1.384165 --> 1.380592).  Saving model ...
Validation loss decreased (1.380592 --> 1.376867).  Saving model ...
Validation loss decreased (1.376867 --> 1.373111).  Saving model ...
Validation loss decreased (1.373111 --> 1.368772).  Saving model ...
Validation loss decreased (1.368772 --> 1.364442).  Saving model ...
Validation loss decreased (1.364442 --> 1.360896).  Saving model ...
Validation loss decreased (1.360896 --> 1.356163).  Saving model ...
Validation loss decreased (1.356163 --> 1.351820).  Saving model ...
Validation loss decreased (1.351820 --> 1.347475).  Saving model ...
Validation loss decreased (1.347475 --> 1.343156).  Saving model ...
Validation loss decreased (1.343156 --> 1.338062).  Saving model ...
Validation loss decreased (1.338062 --> 1.332093).  Saving model ...
Validation loss decreased (1.332093 --> 1.326648).  Saving model ...
Validation loss decreased (1.326648 --> 1.320374).  Saving model ...
Validation loss decreased (1.320374 --> 1.314261).  Saving model ...
Validation loss decreased (1.314261 --> 1.307127).  Saving model ...
Validation loss decreased (1.307127 --> 1.299875).  Saving model ...
Validation loss decreased (1.299875 --> 1.293062).  Saving model ...
Validation loss decreased (1.293062 --> 1.285276).  Saving model ...
Validation loss decreased (1.285276 --> 1.276907).  Saving model ...
Validation loss decreased (1.276907 --> 1.268844).  Saving model ...
Validation loss decreased (1.268844 --> 1.260824).  Saving model ...
Validation loss decreased (1.260824 --> 1.251301).  Saving model ...
Validation loss decreased (1.251301 --> 1.242537).  Saving model ...
Validation loss decreased (1.242537 --> 1.232773).  Saving model ...
Validation loss decreased (1.232773 --> 1.223153).  Saving model ...
Validation loss decreased (1.223153 --> 1.213850).  Saving model ...
Validation loss decreased (1.213850 --> 1.204842).  Saving model ...
Validation loss decreased (1.204842 --> 1.196374).  Saving model ...
Validation loss decreased (1.196374 --> 1.188241).  Saving model ...
Validation loss decreased (1.188241 --> 1.179478).  Saving model ...
Validation loss decreased (1.179478 --> 1.171719).  Saving model ...
Validation loss decreased (1.171719 --> 1.163274).  Saving model ...
Validation loss decreased (1.163274 --> 1.154511).  Saving model ...
Validation loss decreased (1.154511 --> 1.146546).  Saving model ...
Validation loss decreased (1.146546 --> 1.140282).  Saving model ...
Validation loss decreased (1.140282 --> 1.132880).  Saving model ...
Validation loss decreased (1.132880 --> 1.127063).  Saving model ...
Validation loss decreased (1.127063 --> 1.121344).  Saving model ...
Validation loss decreased (1.121344 --> 1.114098).  Saving model ...
Validation loss decreased (1.114098 --> 1.110446).  Saving model ...
Validation loss decreased (1.110446 --> 1.104227).  Saving model ...
Validation loss decreased (1.104227 --> 1.099051).  Saving model ...
Validation loss decreased (1.099051 --> 1.093404).  Saving model ...
Validation loss decreased (1.093404 --> 1.089311).  Saving model ...
Validation loss decreased (1.089311 --> 1.083641).  Saving model ...
Validation loss decreased (1.083641 --> 1.079188).  Saving model ...
Validation loss decreased (1.079188 --> 1.078421).  Saving model ...
Validation loss decreased (1.078421 --> 1.073404).  Saving model ...
Validation loss decreased (1.073404 --> 1.068287).  Saving model ...
Validation loss decreased (1.068287 --> 1.060310).  Saving model ...
Validation loss decreased (1.060310 --> 1.056604).  Saving model ...
Validation loss decreased (1.056604 --> 1.052785).  Saving model ...
Validation loss decreased (1.052785 --> 1.048392).  Saving model ...
Validation loss decreased (1.048392 --> 1.044257).  Saving model ...
Validation loss decreased (1.044257 --> 1.042024).  Saving model ...
Validation loss decreased (1.042024 --> 1.040170).  Saving model ...
Validation loss decreased (1.040170 --> 1.039965).  Saving model ...
Validation loss decreased (1.039965 --> 1.036442).  Saving model ...
Validation loss decreased (1.036442 --> 1.031489).  Saving model ...
Validation loss decreased (1.031489 --> 1.025621).  Saving model ...
Validation loss decreased (1.025621 --> 1.022584).  Saving model ...
Validation loss decreased (1.022584 --> 1.015133).  Saving model ...
Validation loss decreased (1.015133 --> 1.014717).  Saving model ...
Validation loss decreased (1.014717 --> 1.009652).  Saving model ...
Validation loss decreased (1.009652 --> 1.006538).  Saving model ...
Validation loss decreased (1.006538 --> 1.002810).  Saving model ...
EarlyStopping counter: 1 out of 10.0
Validation loss decreased (1.002810 --> 1.001827).  Saving model ...
Validation loss decreased (1.001827 --> 0.998694).  Saving model ...
Validation loss decreased (0.998694 --> 0.997172).  Saving model ...
Validation loss decreased (0.997172 --> 0.991609).  Saving model ...
Validation loss decreased (0.991609 --> 0.988305).  Saving model ...
Validation loss decreased (0.988305 --> 0.986578).  Saving model ...
Validation loss decreased (0.986578 --> 0.982455).  Saving model ...
Validation loss decreased (0.982455 --> 0.981396).  Saving model ...
Validation loss decreased (0.981396 --> 0.979231).  Saving model ...
Validation loss decreased (0.979231 --> 0.977263).  Saving model ...
EarlyStopping counter: 1 out of 10.0
Validation loss decreased (0.977263 --> 0.974029).  Saving model ...
Validation loss decreased (0.974029 --> 0.970321).  Saving model ...
Validation loss decreased (0.970321 --> 0.965826).  Saving model ...
Validation loss decreased (0.965826 --> 0.965229).  Saving model ...
EarlyStopping counter: 1 out of 10.0
Validation loss decreased (0.965229 --> 0.964507).  Saving model ...
EarlyStopping counter: 1 out of 10.0
EarlyStopping counter: 2 out of 10.0
Validation loss decreased (0.964507 --> 0.962618).  Saving model ...
Validation loss decreased (0.962618 --> 0.960626).  Saving model ...
EarlyStopping counter: 1 out of 10.0
EarlyStopping counter: 2 out of 10.0
Validation loss decreased (0.960626 --> 0.957742).  Saving model ...
Validation loss decreased (0.957742 --> 0.955969).  Saving model ...
Validation loss decreased (0.955969 --> 0.951535).  Saving model ...
Validation loss decreased (0.951535 --> 0.950548).  Saving model ...
EarlyStopping counter: 1 out of 10.0
EarlyStopping counter: 2 out of 10.0
EarlyStopping counter: 3 out of 10.0
Validation loss decreased (0.950548 --> 0.947968).  Saving model ...
EarlyStopping counter: 1 out of 10.0
EarlyStopping counter: 2 out of 10.0
EarlyStopping counter: 3 out of 10.0
Validation loss decreased (0.947968 --> 0.947533).  Saving model ...
Validation loss decreased (0.947533 --> 0.945579).  Saving model ...
Validation loss decreased (0.945579 --> 0.943789).  Saving model ...
Validation loss decreased (0.943789 --> 0.943481).  Saving model ...
Validation loss decreased (0.943481 --> 0.942710).  Saving model ...
Validation loss decreased (0.942710 --> 0.941461).  Saving model ...
EarlyStopping counter: 1 out of 10.0
EarlyStopping counter: 2 out of 10.0
Validation loss decreased (0.941461 --> 0.940036).  Saving model ...
Validation loss decreased (0.940036 --> 0.937807).  Saving model ...
EarlyStopping counter: 1 out of 10.0
EarlyStopping counter: 2 out of 10.0
EarlyStopping counter: 3 out of 10.0
Validation loss decreased (0.937807 --> 0.935824).  Saving model ...
EarlyStopping counter: 1 out of 10.0
EarlyStopping counter: 2 out of 10.0
EarlyStopping counter: 3 out of 10.0
EarlyStopping counter: 4 out of 10.0
Validation loss decreased (0.935824 --> 0.935179).  Saving model ...
EarlyStopping counter: 1 out of 10.0
EarlyStopping counter: 2 out of 10.0
EarlyStopping counter: 3 out of 10.0
Validation loss decreased (0.935179 --> 0.934475).  Saving model ...
Validation loss decreased (0.934475 --> 0.932786).  Saving model ...
EarlyStopping counter: 1 out of 10.0
EarlyStopping counter: 2 out of 10.0
EarlyStopping counter: 3 out of 10.0
EarlyStopping counter: 4 out of 10.0
EarlyStopping counter: 5 out of 10.0
EarlyStopping counter: 6 out of 10.0
EarlyStopping counter: 7 out of 10.0
EarlyStopping counter: 8 out of 10.0
EarlyStopping counter: 9 out of 10.0
EarlyStopping counter: 10 out of 10.0
/localscratch/yinan.29019272.0/env/lib/python3.7/site-packages/torch/nn/functional.py:1794: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.
  warnings.warn("nn.functional.tanh is deprecated. Use torch.tanh instead.")
wandb: Waiting for W&B process to finish, PID 173019... (success).
wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: \ 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: | 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: / 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: \ 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: | 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: / 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: \ 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: | 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: / 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: \ 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb:                                                                                
wandb: Run history:
wandb:     e_F1 ▁▂▃▃▄▄▅▅▅▆▆▆▇▇▇▇▇▇▇▇▇▇█▇████████████████
wandb:   e_loss ███▇▇▇▇▆▆▅▅▄▄▄▃▃▃▃▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:     t_F1 ▁▂▂▂▂▃▃▄▄▄▄▅▅▅▅▆▅▆▆▆▆▆▇▆▇▇▇▇▇▇█▇█▇▇██▇██
wandb:   t_loss ████▇▇▇▇▇▆▆▆▆▅▅▅▅▄▄▄▄▄▃▃▃▃▃▃▃▂▂▂▂▂▂▂▁▂▁▁
wandb: 
wandb: Run summary:
wandb:     e_F1 58.95442
wandb:   e_loss 0.93996
wandb:     t_F1 73.60109
wandb:   t_loss 0.73208
wandb: 
wandb: Synced 4 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Synced eager-capybara-1: https://wandb.ai/yinanazhou/xl_512_bs_8_lr_1e06_es_10_lc_True_nr_False_sr_True_stem_True_lemma_False_repeat_1_fold_2/runs/ul8ccja3
wandb: Find logs at: ./wandb/run-20220317_085845-ul8ccja3/logs/debug.log
wandb: 

wandb: wandb version 0.12.11 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
2022-03-17 10:33:02.904880: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1
wandb: Tracking run with wandb version 0.12.5
wandb: Syncing run bright-snowball-1
wandb: ⭐️ View project at https://wandb.ai/yinanazhou/xl_512_bs_8_lr_1e06_es_10_lc_True_nr_False_sr_True_stem_True_lemma_False_repeat_2_fold_1
wandb: 🚀 View run at https://wandb.ai/yinanazhou/xl_512_bs_8_lr_1e06_es_10_lc_True_nr_False_sr_True_stem_True_lemma_False_repeat_2_fold_1/runs/hfklc6xq
wandb: Run data is saved locally in /project/6002780/yinan/Thesis_MER_Lyrics/lyric-emotion/wandb/run-20220317_103259-hfklc6xq
wandb: Run `wandb offline` to turn off syncing.

Validation loss decreased (inf --> 1.425603).  Saving model ...
Validation loss decreased (1.425603 --> 1.403689).  Saving model ...
Validation loss decreased (1.403689 --> 1.387734).  Saving model ...
Validation loss decreased (1.387734 --> 1.374753).  Saving model ...
Validation loss decreased (1.374753 --> 1.365037).  Saving model ...
Validation loss decreased (1.365037 --> 1.357428).  Saving model ...
Validation loss decreased (1.357428 --> 1.351121).  Saving model ...
Validation loss decreased (1.351121 --> 1.345856).  Saving model ...
Validation loss decreased (1.345856 --> 1.341303).  Saving model ...
Validation loss decreased (1.341303 --> 1.337379).  Saving model ...
Validation loss decreased (1.337379 --> 1.332800).  Saving model ...
Validation loss decreased (1.332800 --> 1.328781).  Saving model ...
Validation loss decreased (1.328781 --> 1.324729).  Saving model ...
Validation loss decreased (1.324729 --> 1.321057).  Saving model ...
Validation loss decreased (1.321057 --> 1.316756).  Saving model ...
Validation loss decreased (1.316756 --> 1.312510).  Saving model ...
Validation loss decreased (1.312510 --> 1.308058).  Saving model ...
Validation loss decreased (1.308058 --> 1.303747).  Saving model ...
Validation loss decreased (1.303747 --> 1.299166).  Saving model ...
Validation loss decreased (1.299166 --> 1.294372).  Saving model ...
Validation loss decreased (1.294372 --> 1.289681).  Saving model ...
Validation loss decreased (1.289681 --> 1.284530).  Saving model ...
Validation loss decreased (1.284530 --> 1.278971).  Saving model ...
Validation loss decreased (1.278971 --> 1.272899).  Saving model ...
Validation loss decreased (1.272899 --> 1.267354).  Saving model ...
Validation loss decreased (1.267354 --> 1.260754).  Saving model ...
Validation loss decreased (1.260754 --> 1.254531).  Saving model ...
Validation loss decreased (1.254531 --> 1.248564).  Saving model ...
Validation loss decreased (1.248564 --> 1.242858).  Saving model ...
Validation loss decreased (1.242858 --> 1.237041).  Saving model ...
Validation loss decreased (1.237041 --> 1.229929).  Saving model ...
Validation loss decreased (1.229929 --> 1.223089).  Saving model ...
Validation loss decreased (1.223089 --> 1.217006).  Saving model ...
Validation loss decreased (1.217006 --> 1.211005).  Saving model ...
Validation loss decreased (1.211005 --> 1.203123).  Saving model ...
Validation loss decreased (1.203123 --> 1.195635).  Saving model ...
Validation loss decreased (1.195635 --> 1.188785).  Saving model ...
Validation loss decreased (1.188785 --> 1.182112).  Saving model ...
Validation loss decreased (1.182112 --> 1.176433).  Saving model ...
Validation loss decreased (1.176433 --> 1.169248).  Saving model ...
Validation loss decreased (1.169248 --> 1.163651).  Saving model ...
Validation loss decreased (1.163651 --> 1.157558).  Saving model ...
Validation loss decreased (1.157558 --> 1.151840).  Saving model ...
Validation loss decreased (1.151840 --> 1.147236).  Saving model ...
Validation loss decreased (1.147236 --> 1.141765).  Saving model ...
Validation loss decreased (1.141765 --> 1.136686).  Saving model ...
Validation loss decreased (1.136686 --> 1.131664).  Saving model ...
Validation loss decreased (1.131664 --> 1.125518).  Saving model ...
Validation loss decreased (1.125518 --> 1.120796).  Saving model ...
Validation loss decreased (1.120796 --> 1.115186).  Saving model ...
Validation loss decreased (1.115186 --> 1.109457).  Saving model ...
Validation loss decreased (1.109457 --> 1.104611).  Saving model ...
Validation loss decreased (1.104611 --> 1.100086).  Saving model ...
Validation loss decreased (1.100086 --> 1.095344).  Saving model ...
Validation loss decreased (1.095344 --> 1.089844).  Saving model ...
Validation loss decreased (1.089844 --> 1.085682).  Saving model ...
Validation loss decreased (1.085682 --> 1.082693).  Saving model ...
Validation loss decreased (1.082693 --> 1.079290).  Saving model ...
Validation loss decreased (1.079290 --> 1.074960).  Saving model ...
Validation loss decreased (1.074960 --> 1.071517).  Saving model ...
Validation loss decreased (1.071517 --> 1.068248).  Saving model ...
Validation loss decreased (1.068248 --> 1.065283).  Saving model ...
Validation loss decreased (1.065283 --> 1.060981).  Saving model ...
Validation loss decreased (1.060981 --> 1.057408).  Saving model ...
Validation loss decreased (1.057408 --> 1.053220).  Saving model ...
Validation loss decreased (1.053220 --> 1.049295).  Saving model ...
Validation loss decreased (1.049295 --> 1.046841).  Saving model ...
Validation loss decreased (1.046841 --> 1.043442).  Saving model ...
Validation loss decreased (1.043442 --> 1.041113).  Saving model ...
Validation loss decreased (1.041113 --> 1.039768).  Saving model ...
Validation loss decreased (1.039768 --> 1.036658).  Saving model ...
Validation loss decreased (1.036658 --> 1.031348).  Saving model ...
Validation loss decreased (1.031348 --> 1.029653).  Saving model ...
Validation loss decreased (1.029653 --> 1.028189).  Saving model ...
Validation loss decreased (1.028189 --> 1.024484).  Saving model ...
Validation loss decreased (1.024484 --> 1.020421).  Saving model ...
Validation loss decreased (1.020421 --> 1.018362).  Saving model ...
Validation loss decreased (1.018362 --> 1.016563).  Saving model ...
Validation loss decreased (1.016563 --> 1.011571).  Saving model ...
Validation loss decreased (1.011571 --> 1.009727).  Saving model ...
Validation loss decreased (1.009727 --> 1.009155).  Saving model ...
Validation loss decreased (1.009155 --> 1.007531).  Saving model ...
Validation loss decreased (1.007531 --> 1.004196).  Saving model ...
Validation loss decreased (1.004196 --> 1.002816).  Saving model ...
Validation loss decreased (1.002816 --> 1.000436).  Saving model ...
Validation loss decreased (1.000436 --> 0.998987).  Saving model ...
Validation loss decreased (0.998987 --> 0.998738).  Saving model ...
Validation loss decreased (0.998738 --> 0.997188).  Saving model ...
Validation loss decreased (0.997188 --> 0.996579).  Saving model ...
Validation loss decreased (0.996579 --> 0.994509).  Saving model ...
Validation loss decreased (0.994509 --> 0.992983).  Saving model ...
Validation loss decreased (0.992983 --> 0.992243).  Saving model ...
Validation loss decreased (0.992243 --> 0.991648).  Saving model ...
Validation loss decreased (0.991648 --> 0.991589).  Saving model ...
Validation loss decreased (0.991589 --> 0.988125).  Saving model ...
Validation loss decreased (0.988125 --> 0.986215).  Saving model ...
Validation loss decreased (0.986215 --> 0.984386).  Saving model ...
Validation loss decreased (0.984386 --> 0.982563).  Saving model ...
Validation loss decreased (0.982563 --> 0.981931).  Saving model ...
Validation loss decreased (0.981931 --> 0.981352).  Saving model ...
Validation loss decreased (0.981352 --> 0.981237).  Saving model ...
Validation loss decreased (0.981237 --> 0.981009).  Saving model ...
Validation loss decreased (0.981009 --> 0.979915).  Saving model ...
Validation loss decreased (0.979915 --> 0.978372).  Saving model ...
EarlyStopping counter: 1 out of 10.0
EarlyStopping counter: 2 out of 10.0
Validation loss decreased (0.978372 --> 0.977183).  Saving model ...
Validation loss decreased (0.977183 --> 0.975276).  Saving model ...
EarlyStopping counter: 1 out of 10.0
EarlyStopping counter: 2 out of 10.0
EarlyStopping counter: 3 out of 10.0
Validation loss decreased (0.975276 --> 0.974404).  Saving model ...
EarlyStopping counter: 1 out of 10.0
Validation loss decreased (0.974404 --> 0.972453).  Saving model ...
EarlyStopping counter: 1 out of 10.0
EarlyStopping counter: 2 out of 10.0
EarlyStopping counter: 3 out of 10.0
EarlyStopping counter: 4 out of 10.0
EarlyStopping counter: 5 out of 10.0
EarlyStopping counter: 6 out of 10.0
EarlyStopping counter: 7 out of 10.0
EarlyStopping counter: 8 out of 10.0
EarlyStopping counter: 9 out of 10.0
EarlyStopping counter: 10 out of 10.0
/localscratch/yinan.29019272.0/env/lib/python3.7/site-packages/torch/nn/functional.py:1794: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.
  warnings.warn("nn.functional.tanh is deprecated. Use torch.tanh instead.")
wandb: Waiting for W&B process to finish, PID 178058... (success).
wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: \ 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: | 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: / 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: \ 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: | 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: / 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: \ 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: | 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: / 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: \ 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: | 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: / 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: \ 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: | 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: / 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb:                                                                                
wandb: Run history:
wandb:     e_F1 ▁▂▄▄▅▅▅▅▆▆▆▆▇▇▇▇▇▇▇▇▇▇▇▇████████████████
wandb:   e_loss █▇▇▇▆▆▆▆▅▅▅▅▄▄▄▃▃▃▃▃▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:     t_F1 ▁▂▃▃▃▃▄▄▄▅▅▅▅▅▆▆▆▆▆▆▆▇▇▇▇▇▇▇▇▇███▇██████
wandb:   t_loss █▇▇▇▇▇▇▆▆▆▆▅▅▅▅▅▄▄▄▄▄▄▃▃▃▃▃▂▂▂▂▂▂▂▂▂▂▂▁▁
wandb: 
wandb: Run summary:
wandb:     e_F1 58.5208
wandb:   e_loss 0.97391
wandb:     t_F1 70.12741
wandb:   t_loss 0.7907
wandb: 
wandb: Synced 4 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Synced bright-snowball-1: https://wandb.ai/yinanazhou/xl_512_bs_8_lr_1e06_es_10_lc_True_nr_False_sr_True_stem_True_lemma_False_repeat_2_fold_1/runs/hfklc6xq
wandb: Find logs at: ./wandb/run-20220317_103259-hfklc6xq/logs/debug.log
wandb: 

wandb: wandb version 0.12.11 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
2022-03-17 11:55:36.733151: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1
wandb: Tracking run with wandb version 0.12.5
wandb: Syncing run likely-cloud-1
wandb: ⭐️ View project at https://wandb.ai/yinanazhou/xl_512_bs_8_lr_1e06_es_10_lc_True_nr_False_sr_True_stem_True_lemma_False_repeat_2_fold_2
wandb: 🚀 View run at https://wandb.ai/yinanazhou/xl_512_bs_8_lr_1e06_es_10_lc_True_nr_False_sr_True_stem_True_lemma_False_repeat_2_fold_2/runs/1uldc5kr
wandb: Run data is saved locally in /project/6002780/yinan/Thesis_MER_Lyrics/lyric-emotion/wandb/run-20220317_115532-1uldc5kr
wandb: Run `wandb offline` to turn off syncing.

Validation loss decreased (inf --> 1.438859).  Saving model ...
Validation loss decreased (1.438859 --> 1.417797).  Saving model ...
Validation loss decreased (1.417797 --> 1.402162).  Saving model ...
Validation loss decreased (1.402162 --> 1.390604).  Saving model ...
Validation loss decreased (1.390604 --> 1.381884).  Saving model ...
Validation loss decreased (1.381884 --> 1.375592).  Saving model ...
Validation loss decreased (1.375592 --> 1.370102).  Saving model ...
Validation loss decreased (1.370102 --> 1.365228).  Saving model ...
Validation loss decreased (1.365228 --> 1.361204).  Saving model ...
Validation loss decreased (1.361204 --> 1.357103).  Saving model ...
Validation loss decreased (1.357103 --> 1.353164).  Saving model ...
Validation loss decreased (1.353164 --> 1.349393).  Saving model ...
Validation loss decreased (1.349393 --> 1.345655).  Saving model ...
Validation loss decreased (1.345655 --> 1.342139).  Saving model ...
Validation loss decreased (1.342139 --> 1.337963).  Saving model ...
Validation loss decreased (1.337963 --> 1.334362).  Saving model ...
Validation loss decreased (1.334362 --> 1.330013).  Saving model ...
Validation loss decreased (1.330013 --> 1.325409).  Saving model ...
Validation loss decreased (1.325409 --> 1.321232).  Saving model ...
Validation loss decreased (1.321232 --> 1.316731).  Saving model ...
Validation loss decreased (1.316731 --> 1.312063).  Saving model ...
Validation loss decreased (1.312063 --> 1.307173).  Saving model ...
Validation loss decreased (1.307173 --> 1.302172).  Saving model ...
Validation loss decreased (1.302172 --> 1.295910).  Saving model ...
Validation loss decreased (1.295910 --> 1.289893).  Saving model ...
Validation loss decreased (1.289893 --> 1.283876).  Saving model ...
Validation loss decreased (1.283876 --> 1.278179).  Saving model ...
Validation loss decreased (1.278179 --> 1.272811).  Saving model ...
Validation loss decreased (1.272811 --> 1.265946).  Saving model ...
Validation loss decreased (1.265946 --> 1.259527).  Saving model ...
Validation loss decreased (1.259527 --> 1.252009).  Saving model ...
Validation loss decreased (1.252009 --> 1.244555).  Saving model ...
Validation loss decreased (1.244555 --> 1.237158).  Saving model ...
Validation loss decreased (1.237158 --> 1.229900).  Saving model ...
Validation loss decreased (1.229900 --> 1.223426).  Saving model ...
Validation loss decreased (1.223426 --> 1.216269).  Saving model ...
Validation loss decreased (1.216269 --> 1.209188).  Saving model ...
Validation loss decreased (1.209188 --> 1.200900).  Saving model ...
Validation loss decreased (1.200900 --> 1.194595).  Saving model ...
Validation loss decreased (1.194595 --> 1.187783).  Saving model ...
Validation loss decreased (1.187783 --> 1.181453).  Saving model ...
Validation loss decreased (1.181453 --> 1.174074).  Saving model ...
Validation loss decreased (1.174074 --> 1.167478).  Saving model ...
Validation loss decreased (1.167478 --> 1.161758).  Saving model ...
Validation loss decreased (1.161758 --> 1.155144).  Saving model ...
Validation loss decreased (1.155144 --> 1.149901).  Saving model ...
Validation loss decreased (1.149901 --> 1.144484).  Saving model ...
Validation loss decreased (1.144484 --> 1.138633).  Saving model ...
Validation loss decreased (1.138633 --> 1.133182).  Saving model ...
Validation loss decreased (1.133182 --> 1.127805).  Saving model ...
Validation loss decreased (1.127805 --> 1.122953).  Saving model ...
Validation loss decreased (1.122953 --> 1.118363).  Saving model ...
Validation loss decreased (1.118363 --> 1.114702).  Saving model ...
Validation loss decreased (1.114702 --> 1.109796).  Saving model ...
Validation loss decreased (1.109796 --> 1.104441).  Saving model ...
Validation loss decreased (1.104441 --> 1.100659).  Saving model ...
Validation loss decreased (1.100659 --> 1.097084).  Saving model ...
Validation loss decreased (1.097084 --> 1.092224).  Saving model ...
Validation loss decreased (1.092224 --> 1.088108).  Saving model ...
Validation loss decreased (1.088108 --> 1.084196).  Saving model ...
Validation loss decreased (1.084196 --> 1.080598).  Saving model ...
Validation loss decreased (1.080598 --> 1.075491).  Saving model ...
Validation loss decreased (1.075491 --> 1.071932).  Saving model ...
Validation loss decreased (1.071932 --> 1.068434).  Saving model ...
Validation loss decreased (1.068434 --> 1.065360).  Saving model ...
Validation loss decreased (1.065360 --> 1.061973).  Saving model ...
Validation loss decreased (1.061973 --> 1.058424).  Saving model ...
Validation loss decreased (1.058424 --> 1.053933).  Saving model ...
Validation loss decreased (1.053933 --> 1.050494).  Saving model ...
Validation loss decreased (1.050494 --> 1.047660).  Saving model ...
Validation loss decreased (1.047660 --> 1.044540).  Saving model ...
Validation loss decreased (1.044540 --> 1.040655).  Saving model ...
Validation loss decreased (1.040655 --> 1.038396).  Saving model ...
Validation loss decreased (1.038396 --> 1.036057).  Saving model ...
Validation loss decreased (1.036057 --> 1.033133).  Saving model ...
Validation loss decreased (1.033133 --> 1.030138).  Saving model ...
Validation loss decreased (1.030138 --> 1.027225).  Saving model ...
Validation loss decreased (1.027225 --> 1.024918).  Saving model ...
Validation loss decreased (1.024918 --> 1.023008).  Saving model ...
Validation loss decreased (1.023008 --> 1.019947).  Saving model ...
Validation loss decreased (1.019947 --> 1.017834).  Saving model ...
Validation loss decreased (1.017834 --> 1.015780).  Saving model ...
Validation loss decreased (1.015780 --> 1.013412).  Saving model ...
Validation loss decreased (1.013412 --> 1.011708).  Saving model ...
Validation loss decreased (1.011708 --> 1.008693).  Saving model ...
Validation loss decreased (1.008693 --> 1.007948).  Saving model ...
Validation loss decreased (1.007948 --> 1.003818).  Saving model ...
Validation loss decreased (1.003818 --> 1.002567).  Saving model ...
Validation loss decreased (1.002567 --> 1.001013).  Saving model ...
Validation loss decreased (1.001013 --> 0.997740).  Saving model ...
Validation loss decreased (0.997740 --> 0.996696).  Saving model ...
Validation loss decreased (0.996696 --> 0.995798).  Saving model ...
Validation loss decreased (0.995798 --> 0.994909).  Saving model ...
Validation loss decreased (0.994909 --> 0.992063).  Saving model ...
Validation loss decreased (0.992063 --> 0.990458).  Saving model ...
Validation loss decreased (0.990458 --> 0.989303).  Saving model ...
Validation loss decreased (0.989303 --> 0.988554).  Saving model ...
Validation loss decreased (0.988554 --> 0.987657).  Saving model ...
Validation loss decreased (0.987657 --> 0.986621).  Saving model ...
Validation loss decreased (0.986621 --> 0.985189).  Saving model ...
Validation loss decreased (0.985189 --> 0.983199).  Saving model ...
Validation loss decreased (0.983199 --> 0.982851).  Saving model ...
Validation loss decreased (0.982851 --> 0.980799).  Saving model ...
Validation loss decreased (0.980799 --> 0.978813).  Saving model ...
Validation loss decreased (0.978813 --> 0.977073).  Saving model ...
Validation loss decreased (0.977073 --> 0.976458).  Saving model ...
Validation loss decreased (0.976458 --> 0.974072).  Saving model ...
EarlyStopping counter: 1 out of 10.0
Validation loss decreased (0.974072 --> 0.971868).  Saving model ...
EarlyStopping counter: 1 out of 10.0
Validation loss decreased (0.971868 --> 0.970922).  Saving model ...
Validation loss decreased (0.970922 --> 0.970191).  Saving model ...
Validation loss decreased (0.970191 --> 0.966768).  Saving model ...
EarlyStopping counter: 1 out of 10.0
EarlyStopping counter: 2 out of 10.0
Validation loss decreased (0.966768 --> 0.964850).  Saving model ...
Validation loss decreased (0.964850 --> 0.963251).  Saving model ...
Validation loss decreased (0.963251 --> 0.961806).  Saving model ...
Validation loss decreased (0.961806 --> 0.960255).  Saving model ...
EarlyStopping counter: 1 out of 10.0
Validation loss decreased (0.960255 --> 0.958837).  Saving model ...
EarlyStopping counter: 1 out of 10.0
EarlyStopping counter: 2 out of 10.0
EarlyStopping counter: 3 out of 10.0
Validation loss decreased (0.958837 --> 0.958182).  Saving model ...
Validation loss decreased (0.958182 --> 0.957628).  Saving model ...
Validation loss decreased (0.957628 --> 0.956142).  Saving model ...
Validation loss decreased (0.956142 --> 0.955511).  Saving model ...
Validation loss decreased (0.955511 --> 0.952349).  Saving model ...
Validation loss decreased (0.952349 --> 0.950652).  Saving model ...
EarlyStopping counter: 1 out of 10.0
EarlyStopping counter: 2 out of 10.0
EarlyStopping counter: 3 out of 10.0
EarlyStopping counter: 4 out of 10.0
EarlyStopping counter: 5 out of 10.0
EarlyStopping counter: 6 out of 10.0
EarlyStopping counter: 7 out of 10.0
Validation loss decreased (0.950652 --> 0.950229).  Saving model ...
EarlyStopping counter: 1 out of 10.0
EarlyStopping counter: 2 out of 10.0
EarlyStopping counter: 3 out of 10.0
Validation loss decreased (0.950229 --> 0.949449).  Saving model ...
Validation loss decreased (0.949449 --> 0.949156).  Saving model ...
Validation loss decreased (0.949156 --> 0.946349).  Saving model ...
EarlyStopping counter: 1 out of 10.0
EarlyStopping counter: 2 out of 10.0
EarlyStopping counter: 3 out of 10.0
EarlyStopping counter: 4 out of 10.0
EarlyStopping counter: 5 out of 10.0
EarlyStopping counter: 6 out of 10.0
EarlyStopping counter: 7 out of 10.0
EarlyStopping counter: 8 out of 10.0
EarlyStopping counter: 9 out of 10.0
EarlyStopping counter: 10 out of 10.0
/localscratch/yinan.29019272.0/env/lib/python3.7/site-packages/torch/nn/functional.py:1794: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.
  warnings.warn("nn.functional.tanh is deprecated. Use torch.tanh instead.")
wandb: Waiting for W&B process to finish, PID 182459... (success).
wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: \ 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: | 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: / 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: \ 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: | 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: / 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: \ 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: | 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: / 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb:                                                                                
wandb: Run history:
wandb:     e_F1 ▁▂▃▄▄▅▅▆▆▆▆▇▇▇▇▇▇▇▇▇▇▇███▇██████████████
wandb:   e_loss ██▇▇▇▆▆▆▅▅▅▄▄▄▃▃▃▃▂▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:     t_F1 ▁▁▂▃▃▃▄▄▅▅▅▅▆▆▆▆▆▆▇▇▆▇▇▇▇▇▇▇▇▇▇▇▇██▇▇███
wandb:   t_loss ███▇▇▇▇▆▆▆▆▅▅▄▄▄▄▄▄▃▃▃▃▃▃▃▂▂▂▂▂▂▂▁▂▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:     e_F1 60.75993
wandb:   e_loss 0.94965
wandb:     t_F1 70.81074
wandb:   t_loss 0.75937
wandb: 
wandb: Synced 4 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Synced likely-cloud-1: https://wandb.ai/yinanazhou/xl_512_bs_8_lr_1e06_es_10_lc_True_nr_False_sr_True_stem_True_lemma_False_repeat_2_fold_2/runs/1uldc5kr
wandb: Find logs at: ./wandb/run-20220317_115532-1uldc5kr/logs/debug.log
wandb: 

wandb: wandb version 0.12.11 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
2022-03-17 13:33:15.683916: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1
wandb: Tracking run with wandb version 0.12.5
wandb: Syncing run generous-forest-1
wandb: ⭐️ View project at https://wandb.ai/yinanazhou/xl_512_bs_8_lr_1e06_es_10_lc_True_nr_False_sr_True_stem_True_lemma_False_repeat_3_fold_1
wandb: 🚀 View run at https://wandb.ai/yinanazhou/xl_512_bs_8_lr_1e06_es_10_lc_True_nr_False_sr_True_stem_True_lemma_False_repeat_3_fold_1/runs/2l00ggj9
wandb: Run data is saved locally in /project/6002780/yinan/Thesis_MER_Lyrics/lyric-emotion/wandb/run-20220317_133312-2l00ggj9
wandb: Run `wandb offline` to turn off syncing.

Validation loss decreased (inf --> 1.406165).  Saving model ...
Validation loss decreased (1.406165 --> 1.399741).  Saving model ...
Validation loss decreased (1.399741 --> 1.393806).  Saving model ...
Validation loss decreased (1.393806 --> 1.389357).  Saving model ...
Validation loss decreased (1.389357 --> 1.384957).  Saving model ...
Validation loss decreased (1.384957 --> 1.380942).  Saving model ...
Validation loss decreased (1.380942 --> 1.376889).  Saving model ...
Validation loss decreased (1.376889 --> 1.373094).  Saving model ...
Validation loss decreased (1.373094 --> 1.369643).  Saving model ...
Validation loss decreased (1.369643 --> 1.365959).  Saving model ...
Validation loss decreased (1.365959 --> 1.362200).  Saving model ...
Validation loss decreased (1.362200 --> 1.358579).  Saving model ...
Validation loss decreased (1.358579 --> 1.355074).  Saving model ...
Validation loss decreased (1.355074 --> 1.351297).  Saving model ...
Validation loss decreased (1.351297 --> 1.346718).  Saving model ...
Validation loss decreased (1.346718 --> 1.342565).  Saving model ...
Validation loss decreased (1.342565 --> 1.337820).  Saving model ...
Validation loss decreased (1.337820 --> 1.333072).  Saving model ...
Validation loss decreased (1.333072 --> 1.328561).  Saving model ...
Validation loss decreased (1.328561 --> 1.323480).  Saving model ...
Validation loss decreased (1.323480 --> 1.317914).  Saving model ...
Validation loss decreased (1.317914 --> 1.312597).  Saving model ...
Validation loss decreased (1.312597 --> 1.306329).  Saving model ...
Validation loss decreased (1.306329 --> 1.300410).  Saving model ...
Validation loss decreased (1.300410 --> 1.294793).  Saving model ...
Validation loss decreased (1.294793 --> 1.288454).  Saving model ...
Validation loss decreased (1.288454 --> 1.282511).  Saving model ...
Validation loss decreased (1.282511 --> 1.275421).  Saving model ...
Validation loss decreased (1.275421 --> 1.268500).  Saving model ...
Validation loss decreased (1.268500 --> 1.260233).  Saving model ...
Validation loss decreased (1.260233 --> 1.252401).  Saving model ...
Validation loss decreased (1.252401 --> 1.245291).  Saving model ...
Validation loss decreased (1.245291 --> 1.239447).  Saving model ...
Validation loss decreased (1.239447 --> 1.233241).  Saving model ...
Validation loss decreased (1.233241 --> 1.226754).  Saving model ...
Validation loss decreased (1.226754 --> 1.221003).  Saving model ...
Validation loss decreased (1.221003 --> 1.214892).  Saving model ...
Validation loss decreased (1.214892 --> 1.210021).  Saving model ...
Validation loss decreased (1.210021 --> 1.205269).  Saving model ...
Validation loss decreased (1.205269 --> 1.200562).  Saving model ...
Validation loss decreased (1.200562 --> 1.194224).  Saving model ...
Validation loss decreased (1.194224 --> 1.186742).  Saving model ...
Validation loss decreased (1.186742 --> 1.180942).  Saving model ...
Validation loss decreased (1.180942 --> 1.174763).  Saving model ...
Validation loss decreased (1.174763 --> 1.170570).  Saving model ...
Validation loss decreased (1.170570 --> 1.164890).  Saving model ...
Validation loss decreased (1.164890 --> 1.159424).  Saving model ...
Validation loss decreased (1.159424 --> 1.155245).  Saving model ...
Validation loss decreased (1.155245 --> 1.148963).  Saving model ...
Validation loss decreased (1.148963 --> 1.143350).  Saving model ...
Validation loss decreased (1.143350 --> 1.137292).  Saving model ...
Validation loss decreased (1.137292 --> 1.131567).  Saving model ...
Validation loss decreased (1.131567 --> 1.127357).  Saving model ...
Validation loss decreased (1.127357 --> 1.121172).  Saving model ...
Validation loss decreased (1.121172 --> 1.116841).  Saving model ...
Validation loss decreased (1.116841 --> 1.112138).  Saving model ...
Validation loss decreased (1.112138 --> 1.106556).  Saving model ...
Validation loss decreased (1.106556 --> 1.102721).  Saving model ...
Validation loss decreased (1.102721 --> 1.098624).  Saving model ...
Validation loss decreased (1.098624 --> 1.093288).  Saving model ...
Validation loss decreased (1.093288 --> 1.091050).  Saving model ...
Validation loss decreased (1.091050 --> 1.086080).  Saving model ...
Validation loss decreased (1.086080 --> 1.083031).  Saving model ...
Validation loss decreased (1.083031 --> 1.078464).  Saving model ...
Validation loss decreased (1.078464 --> 1.076331).  Saving model ...
Validation loss decreased (1.076331 --> 1.072116).  Saving model ...
Validation loss decreased (1.072116 --> 1.068786).  Saving model ...
Validation loss decreased (1.068786 --> 1.065386).  Saving model ...
Validation loss decreased (1.065386 --> 1.061715).  Saving model ...
Validation loss decreased (1.061715 --> 1.058377).  Saving model ...
Validation loss decreased (1.058377 --> 1.055677).  Saving model ...
Validation loss decreased (1.055677 --> 1.051277).  Saving model ...
Validation loss decreased (1.051277 --> 1.048943).  Saving model ...
Validation loss decreased (1.048943 --> 1.044592).  Saving model ...
Validation loss decreased (1.044592 --> 1.041993).  Saving model ...
Validation loss decreased (1.041993 --> 1.036753).  Saving model ...
Validation loss decreased (1.036753 --> 1.033749).  Saving model ...
Validation loss decreased (1.033749 --> 1.030810).  Saving model ...
Validation loss decreased (1.030810 --> 1.030370).  Saving model ...
Validation loss decreased (1.030370 --> 1.028279).  Saving model ...
Validation loss decreased (1.028279 --> 1.024365).  Saving model ...
Validation loss decreased (1.024365 --> 1.021981).  Saving model ...
Validation loss decreased (1.021981 --> 1.019510).  Saving model ...
Validation loss decreased (1.019510 --> 1.018595).  Saving model ...
Validation loss decreased (1.018595 --> 1.015754).  Saving model ...
Validation loss decreased (1.015754 --> 1.014381).  Saving model ...
Validation loss decreased (1.014381 --> 1.010421).  Saving model ...
Validation loss decreased (1.010421 --> 1.008616).  Saving model ...
Validation loss decreased (1.008616 --> 1.007328).  Saving model ...
EarlyStopping counter: 1 out of 10.0
Validation loss decreased (1.007328 --> 1.005972).  Saving model ...
Validation loss decreased (1.005972 --> 1.005145).  Saving model ...
Validation loss decreased (1.005145 --> 1.001415).  Saving model ...
Validation loss decreased (1.001415 --> 0.997973).  Saving model ...
Validation loss decreased (0.997973 --> 0.995332).  Saving model ...
Validation loss decreased (0.995332 --> 0.993031).  Saving model ...
Validation loss decreased (0.993031 --> 0.992664).  Saving model ...
Validation loss decreased (0.992664 --> 0.989845).  Saving model ...
Validation loss decreased (0.989845 --> 0.987640).  Saving model ...
Validation loss decreased (0.987640 --> 0.987336).  Saving model ...
Validation loss decreased (0.987336 --> 0.986495).  Saving model ...
Validation loss decreased (0.986495 --> 0.983879).  Saving model ...
Validation loss decreased (0.983879 --> 0.983211).  Saving model ...
Validation loss decreased (0.983211 --> 0.980797).  Saving model ...
EarlyStopping counter: 1 out of 10.0
EarlyStopping counter: 2 out of 10.0
Validation loss decreased (0.980797 --> 0.978473).  Saving model ...
Validation loss decreased (0.978473 --> 0.977263).  Saving model ...
Validation loss decreased (0.977263 --> 0.976486).  Saving model ...
Validation loss decreased (0.976486 --> 0.971774).  Saving model ...
EarlyStopping counter: 1 out of 10.0
EarlyStopping counter: 2 out of 10.0
Validation loss decreased (0.971774 --> 0.970549).  Saving model ...
Validation loss decreased (0.970549 --> 0.969867).  Saving model ...
Validation loss decreased (0.969867 --> 0.968374).  Saving model ...
EarlyStopping counter: 1 out of 10.0
EarlyStopping counter: 2 out of 10.0
Validation loss decreased (0.968374 --> 0.966896).  Saving model ...
Validation loss decreased (0.966896 --> 0.966577).  Saving model ...
EarlyStopping counter: 1 out of 10.0
Validation loss decreased (0.966577 --> 0.965791).  Saving model ...
EarlyStopping counter: 1 out of 10.0
Validation loss decreased (0.965791 --> 0.965314).  Saving model ...
Validation loss decreased (0.965314 --> 0.964388).  Saving model ...
Validation loss decreased (0.964388 --> 0.964297).  Saving model ...
Validation loss decreased (0.964297 --> 0.963071).  Saving model ...
Validation loss decreased (0.963071 --> 0.961680).  Saving model ...
Validation loss decreased (0.961680 --> 0.961455).  Saving model ...
Validation loss decreased (0.961455 --> 0.961045).  Saving model ...
Validation loss decreased (0.961045 --> 0.960841).  Saving model ...
Validation loss decreased (0.960841 --> 0.960401).  Saving model ...
EarlyStopping counter: 1 out of 10.0
EarlyStopping counter: 2 out of 10.0
EarlyStopping counter: 3 out of 10.0
Validation loss decreased (0.960401 --> 0.959870).  Saving model ...
Validation loss decreased (0.959870 --> 0.958863).  Saving model ...
EarlyStopping counter: 1 out of 10.0
Validation loss decreased (0.958863 --> 0.958830).  Saving model ...
Validation loss decreased (0.958830 --> 0.956725).  Saving model ...
EarlyStopping counter: 1 out of 10.0
EarlyStopping counter: 2 out of 10.0
EarlyStopping counter: 3 out of 10.0
EarlyStopping counter: 4 out of 10.0
Validation loss decreased (0.956725 --> 0.955891).  Saving model ...
EarlyStopping counter: 1 out of 10.0
EarlyStopping counter: 2 out of 10.0
EarlyStopping counter: 3 out of 10.0
Validation loss decreased (0.955891 --> 0.954533).  Saving model ...
EarlyStopping counter: 1 out of 10.0
Validation loss decreased (0.954533 --> 0.953647).  Saving model ...
Validation loss decreased (0.953647 --> 0.952686).  Saving model ...
EarlyStopping counter: 1 out of 10.0
EarlyStopping counter: 2 out of 10.0
EarlyStopping counter: 3 out of 10.0
EarlyStopping counter: 4 out of 10.0
Validation loss decreased (0.952686 --> 0.952670).  Saving model ...
Validation loss decreased (0.952670 --> 0.950780).  Saving model ...
EarlyStopping counter: 1 out of 10.0
EarlyStopping counter: 2 out of 10.0
EarlyStopping counter: 3 out of 10.0
EarlyStopping counter: 4 out of 10.0
EarlyStopping counter: 5 out of 10.0
EarlyStopping counter: 6 out of 10.0
EarlyStopping counter: 7 out of 10.0
EarlyStopping counter: 8 out of 10.0
EarlyStopping counter: 9 out of 10.0
Validation loss decreased (0.950780 --> 0.950305).  Saving model ...
EarlyStopping counter: 1 out of 10.0
EarlyStopping counter: 2 out of 10.0
EarlyStopping counter: 3 out of 10.0
EarlyStopping counter: 4 out of 10.0
EarlyStopping counter: 5 out of 10.0
EarlyStopping counter: 6 out of 10.0
EarlyStopping counter: 7 out of 10.0
EarlyStopping counter: 8 out of 10.0
EarlyStopping counter: 9 out of 10.0
EarlyStopping counter: 10 out of 10.0
/localscratch/yinan.29019272.0/env/lib/python3.7/site-packages/torch/nn/functional.py:1794: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.
  warnings.warn("nn.functional.tanh is deprecated. Use torch.tanh instead.")
wandb: Waiting for W&B process to finish, PID 187756... (success).
wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: \ 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: | 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: / 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: \ 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: | 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: / 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: \ 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: | 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: / 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb:                                                                                
wandb: Run history:
wandb:     e_F1 ▁▂▃▄▄▅▅▅▅▆▆▆▇▇▇▇▇▇▇▇▇▇▇▇████████████████
wandb:   e_loss ██▇▇▇▆▆▆▅▅▄▄▄▃▃▃▃▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:     t_F1 ▁▂▂▂▃▃▄▄▅▅▅▅▅▅▆▆▆▆▇▆▆▇▇▇▇▇▇▇▇▇▇█▇▇██████
wandb:   t_loss ███▇▇▇▇▆▆▆▆▅▅▅▄▄▄▄▄▃▄▃▃▃▂▃▂▂▂▂▂▂▂▂▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:     e_F1 59.61593
wandb:   e_loss 0.95536
wandb:     t_F1 74.49552
wandb:   t_loss 0.69184
wandb: 
wandb: Synced 4 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Synced generous-forest-1: https://wandb.ai/yinanazhou/xl_512_bs_8_lr_1e06_es_10_lc_True_nr_False_sr_True_stem_True_lemma_False_repeat_3_fold_1/runs/2l00ggj9
wandb: Find logs at: ./wandb/run-20220317_133312-2l00ggj9/logs/debug.log
wandb: 

wandb: wandb version 0.12.11 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
2022-03-17 15:29:16.366206: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1
wandb: Tracking run with wandb version 0.12.5
wandb: Syncing run different-sea-1
wandb: ⭐️ View project at https://wandb.ai/yinanazhou/xl_512_bs_8_lr_1e06_es_10_lc_True_nr_False_sr_True_stem_True_lemma_False_repeat_3_fold_2
wandb: 🚀 View run at https://wandb.ai/yinanazhou/xl_512_bs_8_lr_1e06_es_10_lc_True_nr_False_sr_True_stem_True_lemma_False_repeat_3_fold_2/runs/3ghsyz60
wandb: Run data is saved locally in /project/6002780/yinan/Thesis_MER_Lyrics/lyric-emotion/wandb/run-20220317_152913-3ghsyz60
wandb: Run `wandb offline` to turn off syncing.

Validation loss decreased (inf --> 1.410402).  Saving model ...
Validation loss decreased (1.410402 --> 1.397851).  Saving model ...
Validation loss decreased (1.397851 --> 1.388113).  Saving model ...
Validation loss decreased (1.388113 --> 1.379809).  Saving model ...
Validation loss decreased (1.379809 --> 1.373253).  Saving model ...
Validation loss decreased (1.373253 --> 1.367836).  Saving model ...
Validation loss decreased (1.367836 --> 1.363435).  Saving model ...
Validation loss decreased (1.363435 --> 1.359035).  Saving model ...
Validation loss decreased (1.359035 --> 1.354811).  Saving model ...
Validation loss decreased (1.354811 --> 1.350461).  Saving model ...
Validation loss decreased (1.350461 --> 1.346612).  Saving model ...
Validation loss decreased (1.346612 --> 1.342538).  Saving model ...
Validation loss decreased (1.342538 --> 1.338608).  Saving model ...
Validation loss decreased (1.338608 --> 1.334687).  Saving model ...
Validation loss decreased (1.334687 --> 1.329942).  Saving model ...
Validation loss decreased (1.329942 --> 1.325631).  Saving model ...
Validation loss decreased (1.325631 --> 1.320701).  Saving model ...
Validation loss decreased (1.320701 --> 1.315546).  Saving model ...
Validation loss decreased (1.315546 --> 1.310587).  Saving model ...
Validation loss decreased (1.310587 --> 1.305758).  Saving model ...
Validation loss decreased (1.305758 --> 1.300089).  Saving model ...
Validation loss decreased (1.300089 --> 1.294404).  Saving model ...
Validation loss decreased (1.294404 --> 1.288549).  Saving model ...
Validation loss decreased (1.288549 --> 1.282543).  Saving model ...
Validation loss decreased (1.282543 --> 1.276528).  Saving model ...
Validation loss decreased (1.276528 --> 1.270704).  Saving model ...
Validation loss decreased (1.270704 --> 1.264981).  Saving model ...
Validation loss decreased (1.264981 --> 1.258939).  Saving model ...
Validation loss decreased (1.258939 --> 1.252541).  Saving model ...
Validation loss decreased (1.252541 --> 1.246762).  Saving model ...
Validation loss decreased (1.246762 --> 1.240325).  Saving model ...
Validation loss decreased (1.240325 --> 1.234169).  Saving model ...
Validation loss decreased (1.234169 --> 1.227544).  Saving model ...
Validation loss decreased (1.227544 --> 1.221100).  Saving model ...
Validation loss decreased (1.221100 --> 1.214003).  Saving model ...
Validation loss decreased (1.214003 --> 1.206697).  Saving model ...
Validation loss decreased (1.206697 --> 1.200381).  Saving model ...
Validation loss decreased (1.200381 --> 1.194157).  Saving model ...
Validation loss decreased (1.194157 --> 1.187086).  Saving model ...
Validation loss decreased (1.187086 --> 1.181528).  Saving model ...
Validation loss decreased (1.181528 --> 1.175001).  Saving model ...
Validation loss decreased (1.175001 --> 1.169871).  Saving model ...
Validation loss decreased (1.169871 --> 1.163611).  Saving model ...
Validation loss decreased (1.163611 --> 1.157983).  Saving model ...
Validation loss decreased (1.157983 --> 1.151711).  Saving model ...
Validation loss decreased (1.151711 --> 1.145553).  Saving model ...
Validation loss decreased (1.145553 --> 1.139858).  Saving model ...
Validation loss decreased (1.139858 --> 1.135432).  Saving model ...
Validation loss decreased (1.135432 --> 1.129325).  Saving model ...
Validation loss decreased (1.129325 --> 1.123939).  Saving model ...
Validation loss decreased (1.123939 --> 1.117384).  Saving model ...
Validation loss decreased (1.117384 --> 1.112282).  Saving model ...
Validation loss decreased (1.112282 --> 1.107750).  Saving model ...
Validation loss decreased (1.107750 --> 1.103074).  Saving model ...
Validation loss decreased (1.103074 --> 1.098452).  Saving model ...
Validation loss decreased (1.098452 --> 1.093364).  Saving model ...
Validation loss decreased (1.093364 --> 1.089432).  Saving model ...
Validation loss decreased (1.089432 --> 1.085682).  Saving model ...
Validation loss decreased (1.085682 --> 1.080574).  Saving model ...
Validation loss decreased (1.080574 --> 1.074573).  Saving model ...
Validation loss decreased (1.074573 --> 1.071413).  Saving model ...
Validation loss decreased (1.071413 --> 1.068219).  Saving model ...
Validation loss decreased (1.068219 --> 1.064205).  Saving model ...
Validation loss decreased (1.064205 --> 1.062385).  Saving model ...
Validation loss decreased (1.062385 --> 1.058511).  Saving model ...
Validation loss decreased (1.058511 --> 1.055247).  Saving model ...
Validation loss decreased (1.055247 --> 1.052543).  Saving model ...
Validation loss decreased (1.052543 --> 1.046583).  Saving model ...
Validation loss decreased (1.046583 --> 1.043332).  Saving model ...
Validation loss decreased (1.043332 --> 1.038883).  Saving model ...
Validation loss decreased (1.038883 --> 1.036487).  Saving model ...
Validation loss decreased (1.036487 --> 1.034112).  Saving model ...
Validation loss decreased (1.034112 --> 1.032627).  Saving model ...
Validation loss decreased (1.032627 --> 1.029369).  Saving model ...
Validation loss decreased (1.029369 --> 1.025312).  Saving model ...
Validation loss decreased (1.025312 --> 1.023429).  Saving model ...
Validation loss decreased (1.023429 --> 1.020049).  Saving model ...
Validation loss decreased (1.020049 --> 1.017630).  Saving model ...
Validation loss decreased (1.017630 --> 1.014517).  Saving model ...
Validation loss decreased (1.014517 --> 1.012919).  Saving model ...
Validation loss decreased (1.012919 --> 1.011004).  Saving model ...
Validation loss decreased (1.011004 --> 1.008055).  Saving model ...
Validation loss decreased (1.008055 --> 1.006132).  Saving model ...
Validation loss decreased (1.006132 --> 1.003437).  Saving model ...
Validation loss decreased (1.003437 --> 0.999947).  Saving model ...
Validation loss decreased (0.999947 --> 0.998519).  Saving model ...
Validation loss decreased (0.998519 --> 0.995467).  Saving model ...
Validation loss decreased (0.995467 --> 0.994775).  Saving model ...
Validation loss decreased (0.994775 --> 0.992776).  Saving model ...
Validation loss decreased (0.992776 --> 0.990961).  Saving model ...
Validation loss decreased (0.990961 --> 0.990134).  Saving model ...
EarlyStopping counter: 1 out of 10.0
Validation loss decreased (0.990134 --> 0.988270).  Saving model ...
Validation loss decreased (0.988270 --> 0.986047).  Saving model ...
Validation loss decreased (0.986047 --> 0.983015).  Saving model ...
Validation loss decreased (0.983015 --> 0.981374).  Saving model ...
Validation loss decreased (0.981374 --> 0.977857).  Saving model ...
Validation loss decreased (0.977857 --> 0.975585).  Saving model ...
EarlyStopping counter: 1 out of 10.0
EarlyStopping counter: 2 out of 10.0
Validation loss decreased (0.975585 --> 0.973826).  Saving model ...
Validation loss decreased (0.973826 --> 0.971787).  Saving model ...
Validation loss decreased (0.971787 --> 0.971215).  Saving model ...
EarlyStopping counter: 1 out of 10.0
Validation loss decreased (0.971215 --> 0.970631).  Saving model ...
Validation loss decreased (0.970631 --> 0.965663).  Saving model ...
EarlyStopping counter: 1 out of 10.0
Validation loss decreased (0.965663 --> 0.963063).  Saving model ...
Validation loss decreased (0.963063 --> 0.962046).  Saving model ...
EarlyStopping counter: 1 out of 10.0
EarlyStopping counter: 2 out of 10.0
Validation loss decreased (0.962046 --> 0.961609).  Saving model ...
Validation loss decreased (0.961609 --> 0.958282).  Saving model ...
EarlyStopping counter: 1 out of 10.0
EarlyStopping counter: 2 out of 10.0
EarlyStopping counter: 3 out of 10.0
Validation loss decreased (0.958282 --> 0.955995).  Saving model ...
Validation loss decreased (0.955995 --> 0.954622).  Saving model ...
EarlyStopping counter: 1 out of 10.0
Validation loss decreased (0.954622 --> 0.953274).  Saving model ...
EarlyStopping counter: 1 out of 10.0
Validation loss decreased (0.953274 --> 0.951636).  Saving model ...
EarlyStopping counter: 1 out of 10.0
EarlyStopping counter: 2 out of 10.0
EarlyStopping counter: 3 out of 10.0
EarlyStopping counter: 4 out of 10.0
Validation loss decreased (0.951636 --> 0.951124).  Saving model ...
Validation loss decreased (0.951124 --> 0.950825).  Saving model ...
Validation loss decreased (0.950825 --> 0.950651).  Saving model ...
EarlyStopping counter: 1 out of 10.0
EarlyStopping counter: 2 out of 10.0
EarlyStopping counter: 3 out of 10.0
Validation loss decreased (0.950651 --> 0.949525).  Saving model ...
EarlyStopping counter: 1 out of 10.0
EarlyStopping counter: 2 out of 10.0
Validation loss decreased (0.949525 --> 0.947760).  Saving model ...
EarlyStopping counter: 1 out of 10.0
EarlyStopping counter: 2 out of 10.0
EarlyStopping counter: 3 out of 10.0
EarlyStopping counter: 4 out of 10.0
EarlyStopping counter: 5 out of 10.0
EarlyStopping counter: 6 out of 10.0
EarlyStopping counter: 7 out of 10.0
EarlyStopping counter: 8 out of 10.0
EarlyStopping counter: 9 out of 10.0
EarlyStopping counter: 10 out of 10.0
/localscratch/yinan.29019272.0/env/lib/python3.7/site-packages/torch/nn/functional.py:1794: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.
  warnings.warn("nn.functional.tanh is deprecated. Use torch.tanh instead.")
wandb: Waiting for W&B process to finish, PID 193974... (success).
wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: \ 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: | 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: / 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: \ 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: | 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: / 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: \ 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: | 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb:                                                                                
wandb: Run history:
wandb:     e_F1 ▁▁▄▅▅▅▆▆▆▆▆▆▇▇▇▇▇▇▇▇▇▇▇▇████████████████
wandb:   e_loss ██▇▇▇▇▆▆▆▅▅▄▄▄▄▃▃▃▃▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:     t_F1 ▁▂▂▃▃▃▄▄▄▄▅▆▆▆▆▆▆▆▆▆▆▇▇▇▇▇▇▇▇▇▇▇▇███████
wandb:   t_loss ███▇▇▇▇▇▆▆▆▅▅▅▅▄▅▄▄▃▄▃▃▃▃▃▂▃▂▂▂▂▂▂▁▁▂▁▁▁
wandb: 
wandb: Run summary:
wandb:     e_F1 59.61551
wandb:   e_loss 0.95029
wandb:     t_F1 70.06686
wandb:   t_loss 0.75539
wandb: 
wandb: Synced 4 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Synced different-sea-1: https://wandb.ai/yinanazhou/xl_512_bs_8_lr_1e06_es_10_lc_True_nr_False_sr_True_stem_True_lemma_False_repeat_3_fold_2/runs/3ghsyz60
wandb: Find logs at: ./wandb/run-20220317_152913-3ghsyz60/logs/debug.log
wandb: 

wandb: wandb version 0.12.11 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
2022-03-17 17:01:37.125648: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1
wandb: Tracking run with wandb version 0.12.5
wandb: Syncing run copper-lion-1
wandb: ⭐️ View project at https://wandb.ai/yinanazhou/xl_512_bs_8_lr_1e06_es_10_lc_True_nr_False_sr_True_stem_True_lemma_False_repeat_4_fold_1
wandb: 🚀 View run at https://wandb.ai/yinanazhou/xl_512_bs_8_lr_1e06_es_10_lc_True_nr_False_sr_True_stem_True_lemma_False_repeat_4_fold_1/runs/1e325sik
wandb: Run data is saved locally in /project/6002780/yinan/Thesis_MER_Lyrics/lyric-emotion/wandb/run-20220317_170134-1e325sik
wandb: Run `wandb offline` to turn off syncing.

Validation loss decreased (inf --> 1.410674).  Saving model ...
Validation loss decreased (1.410674 --> 1.401211).  Saving model ...
Validation loss decreased (1.401211 --> 1.393633).  Saving model ...
Validation loss decreased (1.393633 --> 1.387687).  Saving model ...
Validation loss decreased (1.387687 --> 1.382338).  Saving model ...
Validation loss decreased (1.382338 --> 1.377631).  Saving model ...
Validation loss decreased (1.377631 --> 1.373393).  Saving model ...
Validation loss decreased (1.373393 --> 1.369526).  Saving model ...
Validation loss decreased (1.369526 --> 1.365653).  Saving model ...
Validation loss decreased (1.365653 --> 1.362091).  Saving model ...
Validation loss decreased (1.362091 --> 1.358494).  Saving model ...
Validation loss decreased (1.358494 --> 1.355153).  Saving model ...
Validation loss decreased (1.355153 --> 1.351813).  Saving model ...
Validation loss decreased (1.351813 --> 1.348229).  Saving model ...
Validation loss decreased (1.348229 --> 1.344677).  Saving model ...
Validation loss decreased (1.344677 --> 1.341027).  Saving model ...
Validation loss decreased (1.341027 --> 1.337336).  Saving model ...
Validation loss decreased (1.337336 --> 1.333525).  Saving model ...
Validation loss decreased (1.333525 --> 1.329150).  Saving model ...
Validation loss decreased (1.329150 --> 1.324860).  Saving model ...
Validation loss decreased (1.324860 --> 1.320377).  Saving model ...
Validation loss decreased (1.320377 --> 1.315164).  Saving model ...
Validation loss decreased (1.315164 --> 1.310273).  Saving model ...
Validation loss decreased (1.310273 --> 1.305306).  Saving model ...
Validation loss decreased (1.305306 --> 1.300021).  Saving model ...
Validation loss decreased (1.300021 --> 1.294137).  Saving model ...
Validation loss decreased (1.294137 --> 1.287317).  Saving model ...
Validation loss decreased (1.287317 --> 1.280575).  Saving model ...
Validation loss decreased (1.280575 --> 1.274676).  Saving model ...
Validation loss decreased (1.274676 --> 1.266828).  Saving model ...
Validation loss decreased (1.266828 --> 1.259608).  Saving model ...
Validation loss decreased (1.259608 --> 1.251156).  Saving model ...
Validation loss decreased (1.251156 --> 1.244346).  Saving model ...
Validation loss decreased (1.244346 --> 1.236639).  Saving model ...
Validation loss decreased (1.236639 --> 1.227564).  Saving model ...
Validation loss decreased (1.227564 --> 1.220133).  Saving model ...
Validation loss decreased (1.220133 --> 1.211974).  Saving model ...
Validation loss decreased (1.211974 --> 1.205583).  Saving model ...
Validation loss decreased (1.205583 --> 1.197484).  Saving model ...
Validation loss decreased (1.197484 --> 1.190799).  Saving model ...
Validation loss decreased (1.190799 --> 1.183257).  Saving model ...
Validation loss decreased (1.183257 --> 1.176348).  Saving model ...
Validation loss decreased (1.176348 --> 1.170696).  Saving model ...
Validation loss decreased (1.170696 --> 1.165897).  Saving model ...
Validation loss decreased (1.165897 --> 1.158972).  Saving model ...
Validation loss decreased (1.158972 --> 1.153497).  Saving model ...
Validation loss decreased (1.153497 --> 1.146898).  Saving model ...
Validation loss decreased (1.146898 --> 1.142241).  Saving model ...
Validation loss decreased (1.142241 --> 1.136084).  Saving model ...
Validation loss decreased (1.136084 --> 1.131216).  Saving model ...
Validation loss decreased (1.131216 --> 1.127423).  Saving model ...
Validation loss decreased (1.127423 --> 1.121608).  Saving model ...
Validation loss decreased (1.121608 --> 1.116815).  Saving model ...
Validation loss decreased (1.116815 --> 1.110215).  Saving model ...
Validation loss decreased (1.110215 --> 1.105835).  Saving model ...
Validation loss decreased (1.105835 --> 1.101172).  Saving model ...
Validation loss decreased (1.101172 --> 1.097245).  Saving model ...
Validation loss decreased (1.097245 --> 1.092774).  Saving model ...
Validation loss decreased (1.092774 --> 1.089920).  Saving model ...
Validation loss decreased (1.089920 --> 1.086799).  Saving model ...
Validation loss decreased (1.086799 --> 1.083701).  Saving model ...
Validation loss decreased (1.083701 --> 1.079523).  Saving model ...
Validation loss decreased (1.079523 --> 1.075550).  Saving model ...
Validation loss decreased (1.075550 --> 1.072475).  Saving model ...
Validation loss decreased (1.072475 --> 1.068299).  Saving model ...
Validation loss decreased (1.068299 --> 1.064227).  Saving model ...
Validation loss decreased (1.064227 --> 1.061785).  Saving model ...
Validation loss decreased (1.061785 --> 1.058646).  Saving model ...
Validation loss decreased (1.058646 --> 1.055983).  Saving model ...
Validation loss decreased (1.055983 --> 1.051756).  Saving model ...
Validation loss decreased (1.051756 --> 1.047394).  Saving model ...
Validation loss decreased (1.047394 --> 1.045367).  Saving model ...
Validation loss decreased (1.045367 --> 1.042007).  Saving model ...
Validation loss decreased (1.042007 --> 1.038860).  Saving model ...
Validation loss decreased (1.038860 --> 1.036889).  Saving model ...
Validation loss decreased (1.036889 --> 1.033133).  Saving model ...
Validation loss decreased (1.033133 --> 1.030003).  Saving model ...
Validation loss decreased (1.030003 --> 1.027736).  Saving model ...
Validation loss decreased (1.027736 --> 1.025434).  Saving model ...
Validation loss decreased (1.025434 --> 1.021027).  Saving model ...
Validation loss decreased (1.021027 --> 1.019073).  Saving model ...
Validation loss decreased (1.019073 --> 1.015942).  Saving model ...
Validation loss decreased (1.015942 --> 1.012888).  Saving model ...
Validation loss decreased (1.012888 --> 1.011834).  Saving model ...
Validation loss decreased (1.011834 --> 1.008286).  Saving model ...
EarlyStopping counter: 1 out of 10.0
EarlyStopping counter: 2 out of 10.0
Validation loss decreased (1.008286 --> 1.005187).  Saving model ...
Validation loss decreased (1.005187 --> 1.002511).  Saving model ...
Validation loss decreased (1.002511 --> 1.000771).  Saving model ...
Validation loss decreased (1.000771 --> 0.996755).  Saving model ...
Validation loss decreased (0.996755 --> 0.996062).  Saving model ...
Validation loss decreased (0.996062 --> 0.994850).  Saving model ...
Validation loss decreased (0.994850 --> 0.993053).  Saving model ...
Validation loss decreased (0.993053 --> 0.990706).  Saving model ...
Validation loss decreased (0.990706 --> 0.990359).  Saving model ...
Validation loss decreased (0.990359 --> 0.987838).  Saving model ...
Validation loss decreased (0.987838 --> 0.983515).  Saving model ...
Validation loss decreased (0.983515 --> 0.980877).  Saving model ...
EarlyStopping counter: 1 out of 10.0
EarlyStopping counter: 2 out of 10.0
Validation loss decreased (0.980877 --> 0.979176).  Saving model ...
Validation loss decreased (0.979176 --> 0.977311).  Saving model ...
Validation loss decreased (0.977311 --> 0.975165).  Saving model ...
Validation loss decreased (0.975165 --> 0.973191).  Saving model ...
Validation loss decreased (0.973191 --> 0.971650).  Saving model ...
EarlyStopping counter: 1 out of 10.0
Validation loss decreased (0.971650 --> 0.970716).  Saving model ...
EarlyStopping counter: 1 out of 10.0
Validation loss decreased (0.970716 --> 0.969725).  Saving model ...
EarlyStopping counter: 1 out of 10.0
Validation loss decreased (0.969725 --> 0.968979).  Saving model ...
EarlyStopping counter: 1 out of 10.0
Validation loss decreased (0.968979 --> 0.968157).  Saving model ...
Validation loss decreased (0.968157 --> 0.967897).  Saving model ...
Validation loss decreased (0.967897 --> 0.966844).  Saving model ...
Validation loss decreased (0.966844 --> 0.964039).  Saving model ...
Validation loss decreased (0.964039 --> 0.962964).  Saving model ...
Validation loss decreased (0.962964 --> 0.962768).  Saving model ...
Validation loss decreased (0.962768 --> 0.962591).  Saving model ...
Validation loss decreased (0.962591 --> 0.961543).  Saving model ...
EarlyStopping counter: 1 out of 10.0
EarlyStopping counter: 2 out of 10.0
Validation loss decreased (0.961543 --> 0.959998).  Saving model ...
EarlyStopping counter: 1 out of 10.0
Validation loss decreased (0.959998 --> 0.958538).  Saving model ...
EarlyStopping counter: 1 out of 10.0
EarlyStopping counter: 2 out of 10.0
EarlyStopping counter: 3 out of 10.0
EarlyStopping counter: 4 out of 10.0
Validation loss decreased (0.958538 --> 0.957942).  Saving model ...
EarlyStopping counter: 1 out of 10.0
EarlyStopping counter: 2 out of 10.0
EarlyStopping counter: 3 out of 10.0
EarlyStopping counter: 4 out of 10.0
EarlyStopping counter: 5 out of 10.0
Validation loss decreased (0.957942 --> 0.957651).  Saving model ...
EarlyStopping counter: 1 out of 10.0
EarlyStopping counter: 2 out of 10.0
EarlyStopping counter: 3 out of 10.0
EarlyStopping counter: 4 out of 10.0
EarlyStopping counter: 5 out of 10.0
EarlyStopping counter: 6 out of 10.0
EarlyStopping counter: 7 out of 10.0
EarlyStopping counter: 8 out of 10.0
Validation loss decreased (0.957651 --> 0.956974).  Saving model ...
EarlyStopping counter: 1 out of 10.0
EarlyStopping counter: 2 out of 10.0
EarlyStopping counter: 3 out of 10.0
EarlyStopping counter: 4 out of 10.0
EarlyStopping counter: 5 out of 10.0
EarlyStopping counter: 6 out of 10.0
EarlyStopping counter: 7 out of 10.0
EarlyStopping counter: 8 out of 10.0
EarlyStopping counter: 9 out of 10.0
EarlyStopping counter: 10 out of 10.0
/localscratch/yinan.29019272.0/env/lib/python3.7/site-packages/torch/nn/functional.py:1794: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.
  warnings.warn("nn.functional.tanh is deprecated. Use torch.tanh instead.")
wandb: Waiting for W&B process to finish, PID 198922... (success).
wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: \ 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: | 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: / 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: \ 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: | 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: / 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: \ 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: | 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: / 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb:                                                                                
wandb: Run history:
wandb:     e_F1 ▁▂▂▄▄▅▅▆▆▆▆▆▇▇▇▇▇███████████████████████
wandb:   e_loss ██▇▇▇▇▆▆▆▅▅▄▄▄▃▃▃▃▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:     t_F1 ▁▁▂▃▃▄▄▄▄▅▅▅▆▆▆▆▆▆▆▆▆▇▇▇▇▇▇▇▇▇▇████████▇
wandb:   t_loss ███▇▇▇▇▇▆▆▆▅▅▅▅▄▄▄▄▄▄▃▃▃▃▃▃▂▂▂▂▂▂▂▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:     e_F1 58.50976
wandb:   e_loss 0.96334
wandb:     t_F1 68.76166
wandb:   t_loss 0.75087
wandb: 
wandb: Synced 4 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Synced copper-lion-1: https://wandb.ai/yinanazhou/xl_512_bs_8_lr_1e06_es_10_lc_True_nr_False_sr_True_stem_True_lemma_False_repeat_4_fold_1/runs/1e325sik
wandb: Find logs at: ./wandb/run-20220317_170134-1e325sik/logs/debug.log
wandb: 

wandb: wandb version 0.12.11 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
2022-03-17 18:43:40.797618: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1
wandb: Tracking run with wandb version 0.12.5
wandb: Syncing run feasible-feather-1
wandb: ⭐️ View project at https://wandb.ai/yinanazhou/xl_512_bs_8_lr_1e06_es_10_lc_True_nr_False_sr_True_stem_True_lemma_False_repeat_4_fold_2
wandb: 🚀 View run at https://wandb.ai/yinanazhou/xl_512_bs_8_lr_1e06_es_10_lc_True_nr_False_sr_True_stem_True_lemma_False_repeat_4_fold_2/runs/6bdqaw77
wandb: Run data is saved locally in /project/6002780/yinan/Thesis_MER_Lyrics/lyric-emotion/wandb/run-20220317_184337-6bdqaw77
wandb: Run `wandb offline` to turn off syncing.

Validation loss decreased (inf --> 1.485639).  Saving model ...
Validation loss decreased (1.485639 --> 1.451735).  Saving model ...
Validation loss decreased (1.451735 --> 1.427838).  Saving model ...
Validation loss decreased (1.427838 --> 1.411849).  Saving model ...
Validation loss decreased (1.411849 --> 1.400524).  Saving model ...
Validation loss decreased (1.400524 --> 1.391313).  Saving model ...
Validation loss decreased (1.391313 --> 1.384282).  Saving model ...
Validation loss decreased (1.384282 --> 1.378248).  Saving model ...
Validation loss decreased (1.378248 --> 1.372349).  Saving model ...
Validation loss decreased (1.372349 --> 1.367522).  Saving model ...
Validation loss decreased (1.367522 --> 1.362853).  Saving model ...
Validation loss decreased (1.362853 --> 1.359051).  Saving model ...
Validation loss decreased (1.359051 --> 1.355082).  Saving model ...
Validation loss decreased (1.355082 --> 1.350473).  Saving model ...
Validation loss decreased (1.350473 --> 1.346114).  Saving model ...
Validation loss decreased (1.346114 --> 1.342040).  Saving model ...
Validation loss decreased (1.342040 --> 1.337488).  Saving model ...
Validation loss decreased (1.337488 --> 1.333095).  Saving model ...
Validation loss decreased (1.333095 --> 1.328131).  Saving model ...
Validation loss decreased (1.328131 --> 1.323556).  Saving model ...
Validation loss decreased (1.323556 --> 1.318399).  Saving model ...
Validation loss decreased (1.318399 --> 1.312589).  Saving model ...
Validation loss decreased (1.312589 --> 1.306462).  Saving model ...
Validation loss decreased (1.306462 --> 1.301761).  Saving model ...
Validation loss decreased (1.301761 --> 1.295501).  Saving model ...
Validation loss decreased (1.295501 --> 1.288228).  Saving model ...
Validation loss decreased (1.288228 --> 1.281560).  Saving model ...
Validation loss decreased (1.281560 --> 1.275092).  Saving model ...
Validation loss decreased (1.275092 --> 1.269670).  Saving model ...
Validation loss decreased (1.269670 --> 1.261932).  Saving model ...
Validation loss decreased (1.261932 --> 1.254201).  Saving model ...
Validation loss decreased (1.254201 --> 1.247598).  Saving model ...
Validation loss decreased (1.247598 --> 1.241592).  Saving model ...
Validation loss decreased (1.241592 --> 1.231205).  Saving model ...
Validation loss decreased (1.231205 --> 1.222245).  Saving model ...
Validation loss decreased (1.222245 --> 1.215257).  Saving model ...
Validation loss decreased (1.215257 --> 1.205327).  Saving model ...
Validation loss decreased (1.205327 --> 1.199276).  Saving model ...
Validation loss decreased (1.199276 --> 1.194313).  Saving model ...
Validation loss decreased (1.194313 --> 1.186295).  Saving model ...
Validation loss decreased (1.186295 --> 1.176075).  Saving model ...
Validation loss decreased (1.176075 --> 1.168966).  Saving model ...
Validation loss decreased (1.168966 --> 1.162462).  Saving model ...
Validation loss decreased (1.162462 --> 1.155762).  Saving model ...
Validation loss decreased (1.155762 --> 1.148573).  Saving model ...
Validation loss decreased (1.148573 --> 1.142184).  Saving model ...
Validation loss decreased (1.142184 --> 1.134538).  Saving model ...
Validation loss decreased (1.134538 --> 1.127411).  Saving model ...
Validation loss decreased (1.127411 --> 1.121764).  Saving model ...
Validation loss decreased (1.121764 --> 1.117411).  Saving model ...
Validation loss decreased (1.117411 --> 1.113377).  Saving model ...
Validation loss decreased (1.113377 --> 1.108486).  Saving model ...
Validation loss decreased (1.108486 --> 1.105946).  Saving model ...
Validation loss decreased (1.105946 --> 1.098225).  Saving model ...
Validation loss decreased (1.098225 --> 1.090938).  Saving model ...
Validation loss decreased (1.090938 --> 1.085852).  Saving model ...
Validation loss decreased (1.085852 --> 1.080584).  Saving model ...
Validation loss decreased (1.080584 --> 1.077485).  Saving model ...
Validation loss decreased (1.077485 --> 1.073784).  Saving model ...
Validation loss decreased (1.073784 --> 1.068680).  Saving model ...
Validation loss decreased (1.068680 --> 1.061108).  Saving model ...
Validation loss decreased (1.061108 --> 1.056119).  Saving model ...
Validation loss decreased (1.056119 --> 1.051450).  Saving model ...
Validation loss decreased (1.051450 --> 1.049268).  Saving model ...
Validation loss decreased (1.049268 --> 1.046644).  Saving model ...
Validation loss decreased (1.046644 --> 1.043890).  Saving model ...
Validation loss decreased (1.043890 --> 1.042553).  Saving model ...
Validation loss decreased (1.042553 --> 1.038069).  Saving model ...
Validation loss decreased (1.038069 --> 1.034447).  Saving model ...
Validation loss decreased (1.034447 --> 1.032977).  Saving model ...
Validation loss decreased (1.032977 --> 1.029139).  Saving model ...
Validation loss decreased (1.029139 --> 1.024009).  Saving model ...
Validation loss decreased (1.024009 --> 1.017997).  Saving model ...
Validation loss decreased (1.017997 --> 1.016860).  Saving model ...
Validation loss decreased (1.016860 --> 1.013518).  Saving model ...
Validation loss decreased (1.013518 --> 1.010722).  Saving model ...
Validation loss decreased (1.010722 --> 1.007939).  Saving model ...
Validation loss decreased (1.007939 --> 1.005336).  Saving model ...
Validation loss decreased (1.005336 --> 1.002888).  Saving model ...
Validation loss decreased (1.002888 --> 0.999921).  Saving model ...
Validation loss decreased (0.999921 --> 0.997598).  Saving model ...
Validation loss decreased (0.997598 --> 0.995590).  Saving model ...
Validation loss decreased (0.995590 --> 0.994373).  Saving model ...
Validation loss decreased (0.994373 --> 0.990151).  Saving model ...
Validation loss decreased (0.990151 --> 0.989342).  Saving model ...
Validation loss decreased (0.989342 --> 0.988394).  Saving model ...
Validation loss decreased (0.988394 --> 0.986604).  Saving model ...
Validation loss decreased (0.986604 --> 0.985396).  Saving model ...
Validation loss decreased (0.985396 --> 0.982966).  Saving model ...
Validation loss decreased (0.982966 --> 0.978768).  Saving model ...
Validation loss decreased (0.978768 --> 0.975728).  Saving model ...
Validation loss decreased (0.975728 --> 0.975367).  Saving model ...
Validation loss decreased (0.975367 --> 0.973348).  Saving model ...
Validation loss decreased (0.973348 --> 0.970120).  Saving model ...
EarlyStopping counter: 1 out of 10.0
Validation loss decreased (0.970120 --> 0.968291).  Saving model ...
Validation loss decreased (0.968291 --> 0.963668).  Saving model ...
Validation loss decreased (0.963668 --> 0.963422).  Saving model ...
Validation loss decreased (0.963422 --> 0.961363).  Saving model ...
Validation loss decreased (0.961363 --> 0.960150).  Saving model ...
Validation loss decreased (0.960150 --> 0.959479).  Saving model ...
Validation loss decreased (0.959479 --> 0.958932).  Saving model ...
Validation loss decreased (0.958932 --> 0.956245).  Saving model ...
EarlyStopping counter: 1 out of 10.0
Validation loss decreased (0.956245 --> 0.955010).  Saving model ...
Validation loss decreased (0.955010 --> 0.954915).  Saving model ...
EarlyStopping counter: 1 out of 10.0
Validation loss decreased (0.954915 --> 0.952626).  Saving model ...
Validation loss decreased (0.952626 --> 0.949774).  Saving model ...
Validation loss decreased (0.949774 --> 0.949202).  Saving model ...
EarlyStopping counter: 1 out of 10.0
EarlyStopping counter: 2 out of 10.0
Validation loss decreased (0.949202 --> 0.948369).  Saving model ...
EarlyStopping counter: 1 out of 10.0
Validation loss decreased (0.948369 --> 0.948301).  Saving model ...
Validation loss decreased (0.948301 --> 0.948217).  Saving model ...
EarlyStopping counter: 1 out of 10.0
Validation loss decreased (0.948217 --> 0.947722).  Saving model ...
Validation loss decreased (0.947722 --> 0.945333).  Saving model ...
EarlyStopping counter: 1 out of 10.0
EarlyStopping counter: 2 out of 10.0
Validation loss decreased (0.945333 --> 0.941795).  Saving model ...
EarlyStopping counter: 1 out of 10.0
EarlyStopping counter: 2 out of 10.0
EarlyStopping counter: 3 out of 10.0
EarlyStopping counter: 4 out of 10.0
EarlyStopping counter: 5 out of 10.0
EarlyStopping counter: 6 out of 10.0
Validation loss decreased (0.941795 --> 0.941418).  Saving model ...
EarlyStopping counter: 1 out of 10.0
EarlyStopping counter: 2 out of 10.0
Validation loss decreased (0.941418 --> 0.939448).  Saving model ...
EarlyStopping counter: 1 out of 10.0
Validation loss decreased (0.939448 --> 0.937754).  Saving model ...
Validation loss decreased (0.937754 --> 0.937729).  Saving model ...
EarlyStopping counter: 1 out of 10.0
EarlyStopping counter: 2 out of 10.0
EarlyStopping counter: 3 out of 10.0
EarlyStopping counter: 4 out of 10.0
EarlyStopping counter: 5 out of 10.0
EarlyStopping counter: 6 out of 10.0
EarlyStopping counter: 7 out of 10.0
EarlyStopping counter: 8 out of 10.0
EarlyStopping counter: 9 out of 10.0
EarlyStopping counter: 10 out of 10.0
/localscratch/yinan.29019272.0/env/lib/python3.7/site-packages/torch/nn/functional.py:1794: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.
  warnings.warn("nn.functional.tanh is deprecated. Use torch.tanh instead.")
wandb: Waiting for W&B process to finish, PID 204381... (success).
wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: \ 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: | 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: / 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: \ 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: | 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: / 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: \ 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: | 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: / 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb:                                                                                
wandb: Run history:
wandb:     e_F1 ▁▁▃▄▅▅▅▅▆▆▇▇▇▇▇▇▇▇██████████████████████
wandb:   e_loss █▇▇▇▇▆▆▆▅▅▅▄▄▄▃▃▃▃▂▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:     t_F1 ▁▂▂▃▃▄▄▄▄▅▅▆▅▅▆▆▆▆▇▇▇▇▇▇▇▇▇█▇█▇█████████
wandb:   t_loss ██▇▇▇▇▇▆▆▆▅▅▅▅▅▅▄▄▃▃▃▃▃▃▃▃▂▂▂▂▂▂▂▂▂▂▁▁▁▁
wandb: 
wandb: Run summary:
wandb:     e_F1 61.2447
wandb:   e_loss 0.9408
wandb:     t_F1 68.67906
wandb:   t_loss 0.7864
wandb: 
wandb: Synced 4 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Synced feasible-feather-1: https://wandb.ai/yinanazhou/xl_512_bs_8_lr_1e06_es_10_lc_True_nr_False_sr_True_stem_True_lemma_False_repeat_4_fold_2/runs/6bdqaw77
wandb: Find logs at: ./wandb/run-20220317_184337-6bdqaw77/logs/debug.log
wandb: 

wandb: wandb version 0.12.11 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
2022-03-17 20:18:39.934533: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1
wandb: Tracking run with wandb version 0.12.5
wandb: Syncing run pious-wildflower-1
wandb: ⭐️ View project at https://wandb.ai/yinanazhou/xl_512_bs_8_lr_1e06_es_10_lc_True_nr_False_sr_True_stem_True_lemma_False_repeat_5_fold_1
wandb: 🚀 View run at https://wandb.ai/yinanazhou/xl_512_bs_8_lr_1e06_es_10_lc_True_nr_False_sr_True_stem_True_lemma_False_repeat_5_fold_1/runs/ghr59n9f
wandb: Run data is saved locally in /project/6002780/yinan/Thesis_MER_Lyrics/lyric-emotion/wandb/run-20220317_201835-ghr59n9f
wandb: Run `wandb offline` to turn off syncing.

Validation loss decreased (inf --> 1.388183).  Saving model ...
Validation loss decreased (1.388183 --> 1.381230).  Saving model ...
Validation loss decreased (1.381230 --> 1.375586).  Saving model ...
Validation loss decreased (1.375586 --> 1.370884).  Saving model ...
Validation loss decreased (1.370884 --> 1.366683).  Saving model ...
Validation loss decreased (1.366683 --> 1.362825).  Saving model ...
Validation loss decreased (1.362825 --> 1.359106).  Saving model ...
Validation loss decreased (1.359106 --> 1.355453).  Saving model ...
Validation loss decreased (1.355453 --> 1.351539).  Saving model ...
Validation loss decreased (1.351539 --> 1.347932).  Saving model ...
Validation loss decreased (1.347932 --> 1.344383).  Saving model ...
Validation loss decreased (1.344383 --> 1.340494).  Saving model ...
Validation loss decreased (1.340494 --> 1.336483).  Saving model ...
Validation loss decreased (1.336483 --> 1.332738).  Saving model ...
Validation loss decreased (1.332738 --> 1.328636).  Saving model ...
Validation loss decreased (1.328636 --> 1.324350).  Saving model ...
Validation loss decreased (1.324350 --> 1.319618).  Saving model ...
Validation loss decreased (1.319618 --> 1.315452).  Saving model ...
Validation loss decreased (1.315452 --> 1.310780).  Saving model ...
Validation loss decreased (1.310780 --> 1.306101).  Saving model ...
Validation loss decreased (1.306101 --> 1.301484).  Saving model ...
Validation loss decreased (1.301484 --> 1.296019).  Saving model ...
Validation loss decreased (1.296019 --> 1.289770).  Saving model ...
Validation loss decreased (1.289770 --> 1.283407).  Saving model ...
Validation loss decreased (1.283407 --> 1.277500).  Saving model ...
Validation loss decreased (1.277500 --> 1.270948).  Saving model ...
Validation loss decreased (1.270948 --> 1.264337).  Saving model ...
Validation loss decreased (1.264337 --> 1.258342).  Saving model ...
Validation loss decreased (1.258342 --> 1.251548).  Saving model ...
Validation loss decreased (1.251548 --> 1.243962).  Saving model ...
Validation loss decreased (1.243962 --> 1.237765).  Saving model ...
Validation loss decreased (1.237765 --> 1.229449).  Saving model ...
Validation loss decreased (1.229449 --> 1.222539).  Saving model ...
Validation loss decreased (1.222539 --> 1.215776).  Saving model ...
Validation loss decreased (1.215776 --> 1.209193).  Saving model ...
Validation loss decreased (1.209193 --> 1.201694).  Saving model ...
Validation loss decreased (1.201694 --> 1.195855).  Saving model ...
Validation loss decreased (1.195855 --> 1.190543).  Saving model ...
Validation loss decreased (1.190543 --> 1.183941).  Saving model ...
Validation loss decreased (1.183941 --> 1.178537).  Saving model ...
Validation loss decreased (1.178537 --> 1.172704).  Saving model ...
Validation loss decreased (1.172704 --> 1.167048).  Saving model ...
Validation loss decreased (1.167048 --> 1.161608).  Saving model ...
Validation loss decreased (1.161608 --> 1.156609).  Saving model ...
Validation loss decreased (1.156609 --> 1.150725).  Saving model ...
Validation loss decreased (1.150725 --> 1.145095).  Saving model ...
Validation loss decreased (1.145095 --> 1.139350).  Saving model ...
Validation loss decreased (1.139350 --> 1.133762).  Saving model ...
Validation loss decreased (1.133762 --> 1.128212).  Saving model ...
Validation loss decreased (1.128212 --> 1.123838).  Saving model ...
Validation loss decreased (1.123838 --> 1.118364).  Saving model ...
Validation loss decreased (1.118364 --> 1.112847).  Saving model ...
Validation loss decreased (1.112847 --> 1.107824).  Saving model ...
Validation loss decreased (1.107824 --> 1.103055).  Saving model ...
Validation loss decreased (1.103055 --> 1.097976).  Saving model ...
Validation loss decreased (1.097976 --> 1.093557).  Saving model ...
Validation loss decreased (1.093557 --> 1.088999).  Saving model ...
Validation loss decreased (1.088999 --> 1.083666).  Saving model ...
Validation loss decreased (1.083666 --> 1.078884).  Saving model ...
Validation loss decreased (1.078884 --> 1.074563).  Saving model ...
Validation loss decreased (1.074563 --> 1.070765).  Saving model ...
Validation loss decreased (1.070765 --> 1.066322).  Saving model ...
Validation loss decreased (1.066322 --> 1.061604).  Saving model ...
Validation loss decreased (1.061604 --> 1.057776).  Saving model ...
Validation loss decreased (1.057776 --> 1.054649).  Saving model ...
Validation loss decreased (1.054649 --> 1.049522).  Saving model ...
Validation loss decreased (1.049522 --> 1.045436).  Saving model ...
Validation loss decreased (1.045436 --> 1.041861).  Saving model ...
Validation loss decreased (1.041861 --> 1.038488).  Saving model ...
Validation loss decreased (1.038488 --> 1.034563).  Saving model ...
Validation loss decreased (1.034563 --> 1.031014).  Saving model ...
Validation loss decreased (1.031014 --> 1.027820).  Saving model ...
Validation loss decreased (1.027820 --> 1.024203).  Saving model ...
Validation loss decreased (1.024203 --> 1.020732).  Saving model ...
Validation loss decreased (1.020732 --> 1.017429).  Saving model ...
Validation loss decreased (1.017429 --> 1.014537).  Saving model ...
Validation loss decreased (1.014537 --> 1.012623).  Saving model ...
Validation loss decreased (1.012623 --> 1.009570).  Saving model ...
Validation loss decreased (1.009570 --> 1.006790).  Saving model ...
Validation loss decreased (1.006790 --> 1.004528).  Saving model ...
Validation loss decreased (1.004528 --> 1.002693).  Saving model ...
Validation loss decreased (1.002693 --> 0.999935).  Saving model ...
Validation loss decreased (0.999935 --> 0.997717).  Saving model ...
Validation loss decreased (0.997717 --> 0.994860).  Saving model ...
Validation loss decreased (0.994860 --> 0.992657).  Saving model ...
Validation loss decreased (0.992657 --> 0.990448).  Saving model ...
Validation loss decreased (0.990448 --> 0.988847).  Saving model ...
Validation loss decreased (0.988847 --> 0.985434).  Saving model ...
Validation loss decreased (0.985434 --> 0.982862).  Saving model ...
Validation loss decreased (0.982862 --> 0.981298).  Saving model ...
Validation loss decreased (0.981298 --> 0.979285).  Saving model ...
Validation loss decreased (0.979285 --> 0.977515).  Saving model ...
Validation loss decreased (0.977515 --> 0.976315).  Saving model ...
Validation loss decreased (0.976315 --> 0.975168).  Saving model ...
Validation loss decreased (0.975168 --> 0.972008).  Saving model ...
Validation loss decreased (0.972008 --> 0.970275).  Saving model ...
Validation loss decreased (0.970275 --> 0.968363).  Saving model ...
Validation loss decreased (0.968363 --> 0.967493).  Saving model ...
Validation loss decreased (0.967493 --> 0.965762).  Saving model ...
Validation loss decreased (0.965762 --> 0.965161).  Saving model ...
Validation loss decreased (0.965161 --> 0.963881).  Saving model ...
Validation loss decreased (0.963881 --> 0.961938).  Saving model ...
Validation loss decreased (0.961938 --> 0.961763).  Saving model ...
Validation loss decreased (0.961763 --> 0.961141).  Saving model ...
Validation loss decreased (0.961141 --> 0.958460).  Saving model ...
Validation loss decreased (0.958460 --> 0.958367).  Saving model ...
Validation loss decreased (0.958367 --> 0.957714).  Saving model ...
Validation loss decreased (0.957714 --> 0.955978).  Saving model ...
Validation loss decreased (0.955978 --> 0.955480).  Saving model ...
EarlyStopping counter: 1 out of 10.0
Validation loss decreased (0.955480 --> 0.954674).  Saving model ...
Validation loss decreased (0.954674 --> 0.951619).  Saving model ...
EarlyStopping counter: 1 out of 10.0
EarlyStopping counter: 2 out of 10.0
Validation loss decreased (0.951619 --> 0.950386).  Saving model ...
Validation loss decreased (0.950386 --> 0.949799).  Saving model ...
Validation loss decreased (0.949799 --> 0.949629).  Saving model ...
Validation loss decreased (0.949629 --> 0.948232).  Saving model ...
Validation loss decreased (0.948232 --> 0.947474).  Saving model ...
Validation loss decreased (0.947474 --> 0.946301).  Saving model ...
EarlyStopping counter: 1 out of 10.0
Validation loss decreased (0.946301 --> 0.944707).  Saving model ...
EarlyStopping counter: 1 out of 10.0
EarlyStopping counter: 2 out of 10.0
EarlyStopping counter: 3 out of 10.0
EarlyStopping counter: 4 out of 10.0
Validation loss decreased (0.944707 --> 0.942832).  Saving model ...
Validation loss decreased (0.942832 --> 0.942303).  Saving model ...
Validation loss decreased (0.942303 --> 0.941903).  Saving model ...
EarlyStopping counter: 1 out of 10.0
EarlyStopping counter: 2 out of 10.0
EarlyStopping counter: 3 out of 10.0
EarlyStopping counter: 4 out of 10.0
EarlyStopping counter: 5 out of 10.0
EarlyStopping counter: 6 out of 10.0
EarlyStopping counter: 7 out of 10.0
EarlyStopping counter: 8 out of 10.0
EarlyStopping counter: 9 out of 10.0
EarlyStopping counter: 10 out of 10.0
/localscratch/yinan.29019272.0/env/lib/python3.7/site-packages/torch/nn/functional.py:1794: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.
  warnings.warn("nn.functional.tanh is deprecated. Use torch.tanh instead.")
wandb: Waiting for W&B process to finish, PID 209474... (success).
wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: \ 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: | 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: / 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: \ 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: | 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: / 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: \ 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: | 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: / 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb:                                                                                
wandb: Run history:
wandb:     e_F1 ▁▂▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇▇▇▇█████████████████
wandb:   e_loss ███▇▇▇▇▆▆▆▅▅▅▄▄▄▃▃▃▃▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:     t_F1 ▁▁▁▃▂▃▃▄▃▄▄▄▅▅▅▆▆▆▆▆▆▇▇▇▇▇▇▇▇▇█▇▇█▇█████
wandb:   t_loss ███▇▇▇▇▇▇▆▆▆▅▅▅▅▄▄▄▄▃▃▃▃▃▂▂▂▂▂▂▂▂▂▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:     e_F1 57.51174
wandb:   e_loss 0.94429
wandb:     t_F1 71.58398
wandb:   t_loss 0.76272
wandb: 
wandb: Synced 4 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Synced pious-wildflower-1: https://wandb.ai/yinanazhou/xl_512_bs_8_lr_1e06_es_10_lc_True_nr_False_sr_True_stem_True_lemma_False_repeat_5_fold_1/runs/ghr59n9f
wandb: Find logs at: ./wandb/run-20220317_201835-ghr59n9f/logs/debug.log
wandb: 

wandb: wandb version 0.12.11 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
2022-03-17 21:50:28.984263: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1
wandb: Tracking run with wandb version 0.12.5
wandb: Syncing run sleek-yogurt-1
wandb: ⭐️ View project at https://wandb.ai/yinanazhou/xl_512_bs_8_lr_1e06_es_10_lc_True_nr_False_sr_True_stem_True_lemma_False_repeat_5_fold_2
wandb: 🚀 View run at https://wandb.ai/yinanazhou/xl_512_bs_8_lr_1e06_es_10_lc_True_nr_False_sr_True_stem_True_lemma_False_repeat_5_fold_2/runs/1udb4yq3
wandb: Run data is saved locally in /project/6002780/yinan/Thesis_MER_Lyrics/lyric-emotion/wandb/run-20220317_215026-1udb4yq3
wandb: Run `wandb offline` to turn off syncing.
wandb: Network error (ReadTimeout), entering retry loop.

Validation loss decreased (inf --> 1.409882).  Saving model ...
Validation loss decreased (1.409882 --> 1.400240).  Saving model ...
Validation loss decreased (1.400240 --> 1.391940).  Saving model ...
Validation loss decreased (1.391940 --> 1.384620).  Saving model ...
Validation loss decreased (1.384620 --> 1.378420).  Saving model ...
Validation loss decreased (1.378420 --> 1.373044).  Saving model ...
Validation loss decreased (1.373044 --> 1.368895).  Saving model ...
Validation loss decreased (1.368895 --> 1.365218).  Saving model ...
Validation loss decreased (1.365218 --> 1.361378).  Saving model ...
Validation loss decreased (1.361378 --> 1.357751).  Saving model ...
Validation loss decreased (1.357751 --> 1.353665).  Saving model ...
Validation loss decreased (1.353665 --> 1.349789).  Saving model ...
Validation loss decreased (1.349789 --> 1.346165).  Saving model ...
Validation loss decreased (1.346165 --> 1.342257).  Saving model ...
Validation loss decreased (1.342257 --> 1.338448).  Saving model ...
Validation loss decreased (1.338448 --> 1.334401).  Saving model ...
Validation loss decreased (1.334401 --> 1.330381).  Saving model ...
Validation loss decreased (1.330381 --> 1.326306).  Saving model ...
Validation loss decreased (1.326306 --> 1.321876).  Saving model ...
Validation loss decreased (1.321876 --> 1.317851).  Saving model ...
Validation loss decreased (1.317851 --> 1.312915).  Saving model ...
Validation loss decreased (1.312915 --> 1.307832).  Saving model ...
Validation loss decreased (1.307832 --> 1.303719).  Saving model ...
Validation loss decreased (1.303719 --> 1.299090).  Saving model ...
Validation loss decreased (1.299090 --> 1.294098).  Saving model ...
Validation loss decreased (1.294098 --> 1.288846).  Saving model ...
Validation loss decreased (1.288846 --> 1.283350).  Saving model ...
Validation loss decreased (1.283350 --> 1.276105).  Saving model ...
Validation loss decreased (1.276105 --> 1.268429).  Saving model ...
Validation loss decreased (1.268429 --> 1.261628).  Saving model ...
Validation loss decreased (1.261628 --> 1.253455).  Saving model ...
Validation loss decreased (1.253455 --> 1.246219).  Saving model ...
Validation loss decreased (1.246219 --> 1.239285).  Saving model ...
Validation loss decreased (1.239285 --> 1.230880).  Saving model ...
Validation loss decreased (1.230880 --> 1.223174).  Saving model ...
Validation loss decreased (1.223174 --> 1.214662).  Saving model ...
Validation loss decreased (1.214662 --> 1.206203).  Saving model ...
Validation loss decreased (1.206203 --> 1.198415).  Saving model ...
Validation loss decreased (1.198415 --> 1.193432).  Saving model ...
Validation loss decreased (1.193432 --> 1.186406).  Saving model ...
Validation loss decreased (1.186406 --> 1.178270).  Saving model ...
Validation loss decreased (1.178270 --> 1.171318).  Saving model ...
Validation loss decreased (1.171318 --> 1.166808).  Saving model ...
Validation loss decreased (1.166808 --> 1.161926).  Saving model ...
Validation loss decreased (1.161926 --> 1.155421).  Saving model ...
Validation loss decreased (1.155421 --> 1.147693).  Saving model ...
Validation loss decreased (1.147693 --> 1.140170).  Saving model ...
Validation loss decreased (1.140170 --> 1.134800).  Saving model ...
Validation loss decreased (1.134800 --> 1.128450).  Saving model ...
Validation loss decreased (1.128450 --> 1.121664).  Saving model ...
Validation loss decreased (1.121664 --> 1.116764).  Saving model ...
Validation loss decreased (1.116764 --> 1.111710).  Saving model ...
Validation loss decreased (1.111710 --> 1.106204).  Saving model ...
Validation loss decreased (1.106204 --> 1.101273).  Saving model ...
Validation loss decreased (1.101273 --> 1.095795).  Saving model ...
Validation loss decreased (1.095795 --> 1.090897).  Saving model ...
Validation loss decreased (1.090897 --> 1.085545).  Saving model ...
Validation loss decreased (1.085545 --> 1.080470).  Saving model ...
Validation loss decreased (1.080470 --> 1.075885).  Saving model ...
Validation loss decreased (1.075885 --> 1.071777).  Saving model ...
Validation loss decreased (1.071777 --> 1.067143).  Saving model ...
Validation loss decreased (1.067143 --> 1.062900).  Saving model ...
Validation loss decreased (1.062900 --> 1.059042).  Saving model ...
Validation loss decreased (1.059042 --> 1.056550).  Saving model ...
Validation loss decreased (1.056550 --> 1.052206).  Saving model ...
Validation loss decreased (1.052206 --> 1.049246).  Saving model ...
Validation loss decreased (1.049246 --> 1.046132).  Saving model ...
Validation loss decreased (1.046132 --> 1.041222).  Saving model ...
Validation loss decreased (1.041222 --> 1.036729).  Saving model ...
Validation loss decreased (1.036729 --> 1.032558).  Saving model ...
Validation loss decreased (1.032558 --> 1.029530).  Saving model ...
Validation loss decreased (1.029530 --> 1.026306).  Saving model ...
Validation loss decreased (1.026306 --> 1.021001).  Saving model ...
Validation loss decreased (1.021001 --> 1.018100).  Saving model ...
Validation loss decreased (1.018100 --> 1.016300).  Saving model ...
Validation loss decreased (1.016300 --> 1.013067).  Saving model ...
Validation loss decreased (1.013067 --> 1.008871).  Saving model ...
Validation loss decreased (1.008871 --> 1.008361).  Saving model ...
Validation loss decreased (1.008361 --> 1.004083).  Saving model ...
Validation loss decreased (1.004083 --> 1.000538).  Saving model ...
Validation loss decreased (1.000538 --> 0.998915).  Saving model ...
Validation loss decreased (0.998915 --> 0.994864).  Saving model ...
Validation loss decreased (0.994864 --> 0.994631).  Saving model ...
Validation loss decreased (0.994631 --> 0.992871).  Saving model ...
Validation loss decreased (0.992871 --> 0.989778).  Saving model ...
Validation loss decreased (0.989778 --> 0.988322).  Saving model ...
Validation loss decreased (0.988322 --> 0.984660).  Saving model ...
Validation loss decreased (0.984660 --> 0.982550).  Saving model ...
Validation loss decreased (0.982550 --> 0.980115).  Saving model ...
Validation loss decreased (0.980115 --> 0.977729).  Saving model ...
Validation loss decreased (0.977729 --> 0.975389).  Saving model ...
Validation loss decreased (0.975389 --> 0.973857).  Saving model ...
Validation loss decreased (0.973857 --> 0.973155).  Saving model ...
Validation loss decreased (0.973155 --> 0.970665).  Saving model ...
Validation loss decreased (0.970665 --> 0.968379).  Saving model ...
Validation loss decreased (0.968379 --> 0.966001).  Saving model ...
Validation loss decreased (0.966001 --> 0.964513).  Saving model ...
Validation loss decreased (0.964513 --> 0.960854).  Saving model ...
Validation loss decreased (0.960854 --> 0.959748).  Saving model ...
Validation loss decreased (0.959748 --> 0.957761).  Saving model ...
Validation loss decreased (0.957761 --> 0.955147).  Saving model ...
Validation loss decreased (0.955147 --> 0.953835).  Saving model ...
Validation loss decreased (0.953835 --> 0.952355).  Saving model ...
Validation loss decreased (0.952355 --> 0.950854).  Saving model ...
Validation loss decreased (0.950854 --> 0.950052).  Saving model ...
Validation loss decreased (0.950052 --> 0.947238).  Saving model ...
Validation loss decreased (0.947238 --> 0.944400).  Saving model ...
Validation loss decreased (0.944400 --> 0.943752).  Saving model ...
Validation loss decreased (0.943752 --> 0.943192).  Saving model ...
Validation loss decreased (0.943192 --> 0.941981).  Saving model ...
Validation loss decreased (0.941981 --> 0.941549).  Saving model ...
Validation loss decreased (0.941549 --> 0.939707).  Saving model ...
EarlyStopping counter: 1 out of 10.0
Validation loss decreased (0.939707 --> 0.938251).  Saving model ...
Validation loss decreased (0.938251 --> 0.937504).  Saving model ...
Validation loss decreased (0.937504 --> 0.935082).  Saving model ...
EarlyStopping counter: 1 out of 10.0
Validation loss decreased (0.935082 --> 0.934689).  Saving model ...
Validation loss decreased (0.934689 --> 0.932360).  Saving model ...
Validation loss decreased (0.932360 --> 0.931889).  Saving model ...
EarlyStopping counter: 1 out of 10.0
Validation loss decreased (0.931889 --> 0.929899).  Saving model ...
Validation loss decreased (0.929899 --> 0.929095).  Saving model ...
EarlyStopping counter: 1 out of 10.0
EarlyStopping counter: 2 out of 10.0
EarlyStopping counter: 3 out of 10.0
Validation loss decreased (0.929095 --> 0.928785).  Saving model ...
Validation loss decreased (0.928785 --> 0.926836).  Saving model ...
Validation loss decreased (0.926836 --> 0.925066).  Saving model ...
EarlyStopping counter: 1 out of 10.0
EarlyStopping counter: 2 out of 10.0
Validation loss decreased (0.925066 --> 0.922866).  Saving model ...
EarlyStopping counter: 1 out of 10.0
EarlyStopping counter: 2 out of 10.0
EarlyStopping counter: 3 out of 10.0
Validation loss decreased (0.922866 --> 0.922512).  Saving model ...
EarlyStopping counter: 1 out of 10.0
EarlyStopping counter: 2 out of 10.0
Validation loss decreased (0.922512 --> 0.922472).  Saving model ...
EarlyStopping counter: 1 out of 10.0
Validation loss decreased (0.922472 --> 0.920788).  Saving model ...
EarlyStopping counter: 1 out of 10.0
EarlyStopping counter: 2 out of 10.0
Validation loss decreased (0.920788 --> 0.919765).  Saving model ...
Validation loss decreased (0.919765 --> 0.918204).  Saving model ...
EarlyStopping counter: 1 out of 10.0
EarlyStopping counter: 2 out of 10.0
EarlyStopping counter: 3 out of 10.0
EarlyStopping counter: 4 out of 10.0
Validation loss decreased (0.918204 --> 0.917779).  Saving model ...
EarlyStopping counter: 1 out of 10.0
EarlyStopping counter: 2 out of 10.0
EarlyStopping counter: 3 out of 10.0
Validation loss decreased (0.917779 --> 0.917497).  Saving model ...
Validation loss decreased (0.917497 --> 0.916588).  Saving model ...
Validation loss decreased (0.916588 --> 0.915893).  Saving model ...
Validation loss decreased (0.915893 --> 0.915557).  Saving model ...
EarlyStopping counter: 1 out of 10.0
Validation loss decreased (0.915557 --> 0.914437).  Saving model ...
EarlyStopping counter: 1 out of 10.0
EarlyStopping counter: 2 out of 10.0
EarlyStopping counter: 3 out of 10.0
EarlyStopping counter: 4 out of 10.0
EarlyStopping counter: 5 out of 10.0
EarlyStopping counter: 6 out of 10.0
EarlyStopping counter: 7 out of 10.0
EarlyStopping counter: 8 out of 10.0
EarlyStopping counter: 9 out of 10.0
EarlyStopping counter: 10 out of 10.0
/localscratch/yinan.29019272.0/env/lib/python3.7/site-packages/torch/nn/functional.py:1794: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.
  warnings.warn("nn.functional.tanh is deprecated. Use torch.tanh instead.")
wandb: Waiting for W&B process to finish, PID 214405... (success).
wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: \ 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: | 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: / 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: \ 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: | 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: / 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: \ 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: | 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: / 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb:                                                                                
wandb: Run history:
wandb:     e_F1 ▁▂▃▄▄▅▅▅▆▆▆▇▇▇▇▇▇▇▇█████████████████████
wandb:   e_loss ██▇▇▇▇▆▆▅▅▅▄▄▄▃▃▃▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:     t_F1 ▁▁▂▂▂▃▃▃▄▄▄▅▅▅▅▆▆▆▆▇▆▆▇▆▇▇▇▇▇█▇█▇▇▇█████
wandb:   t_loss ████▇▇▇▇▆▆▆▅▅▅▅▄▄▄▄▄▃▃▃▃▃▃▂▂▂▂▂▂▁▂▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:     e_F1 64.47284
wandb:   e_loss 0.91906
wandb:     t_F1 73.59745
wandb:   t_loss 0.71557
wandb: 
wandb: Synced 4 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Synced sleek-yogurt-1: https://wandb.ai/yinanazhou/xl_512_bs_8_lr_1e06_es_10_lc_True_nr_False_sr_True_stem_True_lemma_False_repeat_5_fold_2/runs/1udb4yq3
wandb: Find logs at: ./wandb/run-20220317_215026-1udb4yq3/logs/debug.log
wandb: 

