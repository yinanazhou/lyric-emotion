Unloading StdEnv/2020

Due to MODULEPATH changes, the following have been reloaded:
  1) mii/1.1.1


The following have been reloaded with a version change:
  1) python/3.8.2 => python/3.7.4

Using base prefix '/cvmfs/soft.computecanada.ca/easybuild/software/2017/Core/python/3.7.4'
New python executable in /localscratch/yinan.29785235.0/env/bin/python
Installing setuptools, pip, wheel...
done.
Ignoring pip: markers 'python_version < "3"' don't match your environment
Looking in links: /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/nix/avx2, /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/nix/generic, /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic
Collecting pip
Installing collected packages: pip
  Found existing installation: pip 19.1.1
    Uninstalling pip-19.1.1:
      Successfully uninstalled pip-19.1.1
Successfully installed pip-21.2.3+computecanada
Looking in links: /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/nix/avx2, /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/nix/generic, /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/keras-2.8.0+computecanada-py2.py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/Keras_Preprocessing-1.1.2+computecanada-py3-none-any.whl
Requirement already satisfied: matplotlib in /cvmfs/soft.computecanada.ca/easybuild/software/2017/Core/scipy-stack/2019a/lib/python3.7/site-packages (from -r requirements.txt (line 3)) (3.0.2)
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/nltk-3.6.5+computecanada-py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/scikit_learn-0.22.1+computecanada-cp37-cp37m-linux_x86_64.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/tensorboard-2.3.0+computecanada-py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/tensorboard_plugin_wit-1.7.0+computecanada-py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/tensorflow_gpu-2.3.0+computecanada-cp37-cp37m-linux_x86_64.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/tensorflow_estimator-2.3.0+computecanada-py2.py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/tokenizers-0.5.2+computecanada-cp37-cp37m-linux_x86_64.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/nix/avx2/torch-1.4.0+computecanada-cp37-cp37m-linux_x86_64.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/torchtext-0.6.0+computecanada-py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/torchvision-0.8.2+computecanada-cp37-cp37m-linux_x86_64.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/transformers-2.5.1+computecanada-py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/urllib3-1.26.7+computecanada-py2.py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/joblib-1.1.0+computecanada-py2.py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/click-8.1.0+computecanada-py3-none-any.whl
ERROR: Could not find a version that satisfies the requirement regex>=2021.8.3 (from nltk) (from versions: 2018.1.10+computecanada, 2019.11.1+computecanada, 2020.11.13+computecanada)
ERROR: No matching distribution found for regex>=2021.8.3
Looking in links: /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/nix/avx2, /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/nix/generic, /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic
ERROR: Could not find a version that satisfies the requirement numpy==1.20.0+computacanada (from versions: 1.15.0+computecanada, 1.15.2+computecanada, 1.15.4+computecanada, 1.16.0+computecanada, 1.16.2+computecanada, 1.16.3+computecanada, 1.17.4+computecanada, 1.18.1+computecanada, 1.18.4+computecanada, 1.19.1+computecanada, 1.19.2+computecanada, 1.20.2+computecanada)
ERROR: No matching distribution found for numpy==1.20.0+computacanada
Looking in links: /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/nix/avx2, /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/nix/generic, /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/wandb-0.12.5+computecanada-py2.py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/configparser-5.0.2+computecanada-py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/protobuf-3.19.4+computecanada-py2.py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/six-1.16.0+computecanada-py2.py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/pathtools-0.1.2+computecanada-py3-none-any.whl
Requirement already satisfied: requests<3,>=2.0.0 in /cvmfs/soft.computecanada.ca/easybuild/software/2017/Core/scipy-stack/2019a/lib/python3.7/site-packages (from wandb) (2.21.0)
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/psutil-5.7.3+computecanada-cp37-cp37m-linux_x86_64.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/promise-2.3+computecanada-py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/yaspin-2.1.0+computecanada-py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/GitPython-3.1.24+computecanada-py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/sentry_sdk-1.5.0+computecanada-py2.py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/docker_pycreds-0.4.0+computecanada-py2.py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/subprocess32-3.5.4+computecanada-py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/PyYAML-5.3.1+computecanada-cp37-cp37m-linux_x86_64.whl
Requirement already satisfied: python-dateutil>=2.6.1 in /cvmfs/soft.computecanada.ca/easybuild/software/2017/Core/scipy-stack/2019a/lib/python3.7/site-packages (from wandb) (2.7.5)
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/shortuuid-1.0.1+computecanada-py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/click-8.1.0+computecanada-py3-none-any.whl
Requirement already satisfied: importlib-metadata in /cvmfs/soft.computecanada.ca/easybuild/software/2017/Core/scipy-stack/2019a/lib/python3.7/site-packages (from Click!=8.0.0,>=7.0->wandb) (0.8)
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/typing_extensions-4.1.1+computecanada-py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/gitdb-4.0.9+computecanada-py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/smmap-5.0.0+computecanada-py3-none-any.whl
Requirement already satisfied: certifi>=2017.4.17 in /cvmfs/soft.computecanada.ca/easybuild/software/2017/Core/scipy-stack/2019a/lib/python3.7/site-packages (from requests<3,>=2.0.0->wandb) (2018.11.29)
Requirement already satisfied: urllib3<1.25,>=1.21.1 in /cvmfs/soft.computecanada.ca/easybuild/software/2017/Core/scipy-stack/2019a/lib/python3.7/site-packages (from requests<3,>=2.0.0->wandb) (1.24.1)
Requirement already satisfied: idna<2.9,>=2.5 in /cvmfs/soft.computecanada.ca/easybuild/software/2017/Core/scipy-stack/2019a/lib/python3.7/site-packages (from requests<3,>=2.0.0->wandb) (2.8)
Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /cvmfs/soft.computecanada.ca/easybuild/software/2017/Core/scipy-stack/2019a/lib/python3.7/site-packages (from requests<3,>=2.0.0->wandb) (3.0.4)
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/termcolor-1.1.0+computecanada-py3-none-any.whl
Requirement already satisfied: zipp>=0.3.2 in /cvmfs/soft.computecanada.ca/easybuild/software/2017/Core/scipy-stack/2019a/lib/python3.7/site-packages (from importlib-metadata->Click!=8.0.0,>=7.0->wandb) (0.3.3)
Installing collected packages: smmap, typing-extensions, termcolor, six, gitdb, yaspin, subprocess32, shortuuid, sentry-sdk, PyYAML, psutil, protobuf, promise, pathtools, GitPython, docker-pycreds, configparser, Click, wandb
  Attempting uninstall: six
    Found existing installation: six 1.12.0
    Not uninstalling six at /cvmfs/soft.computecanada.ca/easybuild/software/2017/Core/scipy-stack/2019a/lib/python3.7/site-packages, outside environment /localscratch/yinan.29785235.0/env
    Can't uninstall 'six'. No files were found to uninstall.
Successfully installed Click-8.1.0+computecanada GitPython-3.1.24+computecanada PyYAML-5.3.1+computecanada configparser-5.0.2+computecanada docker-pycreds-0.4.0+computecanada gitdb-4.0.9+computecanada pathtools-0.1.2+computecanada promise-2.3+computecanada protobuf-3.19.4+computecanada psutil-5.7.3+computecanada sentry-sdk-1.5.0+computecanada shortuuid-1.0.1+computecanada six-1.16.0+computecanada smmap-5.0.0+computecanada subprocess32-3.5.4+computecanada termcolor-1.1.0+computecanada typing-extensions-4.1.1+computecanada wandb-0.12.5+computecanada yaspin-2.1.0+computecanada
Looking in links: /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/nix/avx2, /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/nix/generic, /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic
ERROR: Could not find a version that satisfies the requirement sagemaker (from versions: none)
ERROR: No matching distribution found for sagemaker
Looking in links: /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/nix/avx2, /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/nix/generic, /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/torch-1.9.1+computecanada-cp37-cp37m-linux_x86_64.whl
Requirement already satisfied: typing-extensions in /localscratch/yinan.29785235.0/env/lib/python3.7/site-packages (from torch) (4.1.1+computecanada)
Installing collected packages: torch
Successfully installed torch-1.9.1+computecanada
Looking in links: /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/nix/avx2, /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/nix/generic, /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/transformers-2.5.1+computecanada-py3-none-any.whl
Requirement already satisfied: numpy in /cvmfs/soft.computecanada.ca/easybuild/software/2017/Core/scipy-stack/2019a/lib/python3.7/site-packages (from transformers==2.5.1+computecanada) (1.16.0)
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/filelock-3.4.2+computecanada-py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/tokenizers-0.5.2+computecanada-cp37-cp37m-linux_x86_64.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/tqdm-4.63.1+computecanada-py2.py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/sacremoses-0.0.49+computecanada-py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/boto3-1.21.14+computecanada-py3-none-any.whl
Requirement already satisfied: requests in /cvmfs/soft.computecanada.ca/easybuild/software/2017/Core/scipy-stack/2019a/lib/python3.7/site-packages (from transformers==2.5.1+computecanada) (2.21.0)
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/sentencepiece-0.1.91+computecanada-cp37-cp37m-linux_x86_64.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/regex-2020.11.13+computecanada-cp37-cp37m-linux_x86_64.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/botocore-1.24.14+computecanada-py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/jmespath-0.10.0+computecanada-py2.py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/s3transfer-0.5.1+computecanada-py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/urllib3-1.26.9+computecanada-py2.py3-none-any.whl
Requirement already satisfied: python-dateutil<3.0.0,>=2.1 in /cvmfs/soft.computecanada.ca/easybuild/software/2017/Core/scipy-stack/2019a/lib/python3.7/site-packages (from botocore<1.25.0,>=1.24.14->boto3->transformers==2.5.1+computecanada) (2.7.5)
Requirement already satisfied: six>=1.5 in /localscratch/yinan.29785235.0/env/lib/python3.7/site-packages (from python-dateutil<3.0.0,>=2.1->botocore<1.25.0,>=1.24.14->boto3->transformers==2.5.1+computecanada) (1.16.0+computecanada)
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/requests-2.27.1+computecanada-py2.py3-none-any.whl
Requirement already satisfied: idna<4,>=2.5 in /cvmfs/soft.computecanada.ca/easybuild/software/2017/Core/scipy-stack/2019a/lib/python3.7/site-packages (from requests->transformers==2.5.1+computecanada) (2.8)
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/charset_normalizer-2.0.12+computecanada-py3-none-any.whl
Requirement already satisfied: certifi>=2017.4.17 in /cvmfs/soft.computecanada.ca/easybuild/software/2017/Core/scipy-stack/2019a/lib/python3.7/site-packages (from requests->transformers==2.5.1+computecanada) (2018.11.29)
Requirement already satisfied: click in /localscratch/yinan.29785235.0/env/lib/python3.7/site-packages (from sacremoses->transformers==2.5.1+computecanada) (8.1.0+computecanada)
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/joblib-1.1.0+computecanada-py2.py3-none-any.whl
Requirement already satisfied: importlib-metadata in /cvmfs/soft.computecanada.ca/easybuild/software/2017/Core/scipy-stack/2019a/lib/python3.7/site-packages (from click->sacremoses->transformers==2.5.1+computecanada) (0.8)
Requirement already satisfied: zipp>=0.3.2 in /cvmfs/soft.computecanada.ca/easybuild/software/2017/Core/scipy-stack/2019a/lib/python3.7/site-packages (from importlib-metadata->click->sacremoses->transformers==2.5.1+computecanada) (0.3.3)
Installing collected packages: urllib3, jmespath, botocore, tqdm, s3transfer, regex, joblib, charset-normalizer, tokenizers, sentencepiece, sacremoses, requests, filelock, boto3, transformers
  Attempting uninstall: urllib3
    Found existing installation: urllib3 1.24.1
    Not uninstalling urllib3 at /cvmfs/soft.computecanada.ca/easybuild/software/2017/Core/scipy-stack/2019a/lib/python3.7/site-packages, outside environment /localscratch/yinan.29785235.0/env
    Can't uninstall 'urllib3'. No files were found to uninstall.
  Attempting uninstall: requests
    Found existing installation: requests 2.21.0
    Not uninstalling requests at /cvmfs/soft.computecanada.ca/easybuild/software/2017/Core/scipy-stack/2019a/lib/python3.7/site-packages, outside environment /localscratch/yinan.29785235.0/env
    Can't uninstall 'requests'. No files were found to uninstall.
Successfully installed boto3-1.21.14+computecanada botocore-1.24.14+computecanada charset-normalizer-2.0.12+computecanada filelock-3.4.2+computecanada jmespath-0.10.0+computecanada joblib-1.1.0+computecanada regex-2020.11.13+computecanada requests-2.27.1+computecanada s3transfer-0.5.1+computecanada sacremoses-0.0.49+computecanada sentencepiece-0.1.91+computecanada tokenizers-0.5.2+computecanada tqdm-4.63.1+computecanada transformers-2.5.1+computecanada urllib3-1.26.9+computecanada
Looking in links: /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/nix/avx2, /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/nix/generic, /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/tensorflow_gpu-2.3.0+computecanada-cp37-cp37m-linux_x86_64.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/wrapt-1.11.2+computecanada-cp37-cp37m-linux_x86_64.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/nix/avx2/h5py-2.10.0+computecanada-cp37-cp37m-linux_x86_64.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/tensorboard-2.8.0+computecanada-py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/nix/generic/scipy-1.4.1+computecanada-cp37-cp37m-linux_x86_64.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/Keras_Preprocessing-1.1.2+computecanada-py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/opt_einsum-3.3.0+computecanada-py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/google_pasta-0.2.0+computecanada-py3-none-any.whl
Requirement already satisfied: six>=1.12.0 in /localscratch/yinan.29785235.0/env/lib/python3.7/site-packages (from tensorflow_gpu==2.3.0+computecanada) (1.16.0+computecanada)
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/gast-0.3.3+computecanada-py3-none-any.whl
Requirement already satisfied: termcolor>=1.1.0 in /localscratch/yinan.29785235.0/env/lib/python3.7/site-packages (from tensorflow_gpu==2.3.0+computecanada) (1.1.0+computecanada)
Requirement already satisfied: numpy<1.19.0,>=1.16.0 in /cvmfs/soft.computecanada.ca/easybuild/software/2017/Core/scipy-stack/2019a/lib/python3.7/site-packages (from tensorflow_gpu==2.3.0+computecanada) (1.16.0)
Requirement already satisfied: protobuf>=3.9.2 in /localscratch/yinan.29785235.0/env/lib/python3.7/site-packages (from tensorflow_gpu==2.3.0+computecanada) (3.19.4+computecanada)
Requirement already satisfied: wheel>=0.26 in /localscratch/yinan.29785235.0/env/lib/python3.7/site-packages (from tensorflow_gpu==2.3.0+computecanada) (0.33.4)
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/astunparse-1.6.3+computecanada-py2.py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/grpcio-1.38.0+computecanada-cp37-cp37m-linux_x86_64.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/absl_py-1.0.0+computecanada-py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/tensorflow_estimator-2.3.0+computecanada-py2.py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/tensorboard_data_server-0.6.1+computecanada-py3-none-linux_x86_64.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/Werkzeug-2.0.3+computecanada-py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/google_auth_oauthlib-0.4.6+computecanada-py2.py3-none-any.whl
Requirement already satisfied: setuptools>=41.0.0 in /localscratch/yinan.29785235.0/env/lib/python3.7/site-packages (from tensorboard<3,>=2.3.0->tensorflow_gpu==2.3.0+computecanada) (41.0.1)
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/tensorboard_plugin_wit-1.8.0+computecanada-py3-none-any.whl
Requirement already satisfied: requests<3,>=2.21.0 in /localscratch/yinan.29785235.0/env/lib/python3.7/site-packages (from tensorboard<3,>=2.3.0->tensorflow_gpu==2.3.0+computecanada) (2.27.1+computecanada)
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/google_auth-2.3.3+computecanada-py2.py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/Markdown-3.3.6+computecanada-py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/rsa-4.8+computecanada-py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/cachetools-4.2.4+computecanada-py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/pyasn1_modules-0.2.8+computecanada-py2.py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/requests_oauthlib-1.3.0+computecanada-py2.py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/importlib_metadata-4.10.1+computecanada-py3-none-any.whl
Requirement already satisfied: typing-extensions>=3.6.4 in /localscratch/yinan.29785235.0/env/lib/python3.7/site-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard<3,>=2.3.0->tensorflow_gpu==2.3.0+computecanada) (4.1.1+computecanada)
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/zipp-3.7.0+computecanada-py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/pyasn1-0.4.8+computecanada-py2.py3-none-any.whl
Requirement already satisfied: idna<4,>=2.5 in /cvmfs/soft.computecanada.ca/easybuild/software/2017/Core/scipy-stack/2019a/lib/python3.7/site-packages (from requests<3,>=2.21.0->tensorboard<3,>=2.3.0->tensorflow_gpu==2.3.0+computecanada) (2.8)
Requirement already satisfied: charset-normalizer~=2.0.0 in /localscratch/yinan.29785235.0/env/lib/python3.7/site-packages (from requests<3,>=2.21.0->tensorboard<3,>=2.3.0->tensorflow_gpu==2.3.0+computecanada) (2.0.12+computecanada)
Requirement already satisfied: certifi>=2017.4.17 in /cvmfs/soft.computecanada.ca/easybuild/software/2017/Core/scipy-stack/2019a/lib/python3.7/site-packages (from requests<3,>=2.21.0->tensorboard<3,>=2.3.0->tensorflow_gpu==2.3.0+computecanada) (2018.11.29)
Requirement already satisfied: urllib3<1.27,>=1.21.1 in /localscratch/yinan.29785235.0/env/lib/python3.7/site-packages (from requests<3,>=2.21.0->tensorboard<3,>=2.3.0->tensorflow_gpu==2.3.0+computecanada) (1.26.9+computecanada)
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/oauthlib-3.1.1+computecanada-py2.py3-none-any.whl
Installing collected packages: pyasn1, zipp, rsa, pyasn1-modules, oauthlib, cachetools, requests-oauthlib, importlib-metadata, google-auth, werkzeug, tensorboard-plugin-wit, tensorboard-data-server, markdown, grpcio, google-auth-oauthlib, absl-py, wrapt, tensorflow-estimator, tensorboard, scipy, opt-einsum, keras-preprocessing, h5py, google-pasta, gast, astunparse, tensorflow-gpu
  Attempting uninstall: pyasn1
    Found existing installation: pyasn1 0.4.3
    Not uninstalling pyasn1 at /cvmfs/soft.computecanada.ca/easybuild/software/2017/Core/scipy-stack/2019a/lib/python3.7/site-packages, outside environment /localscratch/yinan.29785235.0/env
    Can't uninstall 'pyasn1'. No files were found to uninstall.
  Attempting uninstall: zipp
    Found existing installation: zipp 0.3.3
    Not uninstalling zipp at /cvmfs/soft.computecanada.ca/easybuild/software/2017/Core/scipy-stack/2019a/lib/python3.7/site-packages, outside environment /localscratch/yinan.29785235.0/env
    Can't uninstall 'zipp'. No files were found to uninstall.
  Attempting uninstall: importlib-metadata
    Found existing installation: importlib-metadata 0.8
    Not uninstalling importlib-metadata at /cvmfs/soft.computecanada.ca/easybuild/software/2017/Core/scipy-stack/2019a/lib/python3.7/site-packages, outside environment /localscratch/yinan.29785235.0/env
    Can't uninstall 'importlib-metadata'. No files were found to uninstall.
  Attempting uninstall: scipy
    Found existing installation: scipy 1.2.0
    Not uninstalling scipy at /cvmfs/soft.computecanada.ca/easybuild/software/2017/Core/scipy-stack/2019a/lib/python3.7/site-packages, outside environment /localscratch/yinan.29785235.0/env
    Can't uninstall 'scipy'. No files were found to uninstall.
Successfully installed absl-py-1.0.0+computecanada astunparse-1.6.3+computecanada cachetools-4.2.4+computecanada gast-0.3.3+computecanada google-auth-2.3.3+computecanada google-auth-oauthlib-0.4.6+computecanada google-pasta-0.2.0+computecanada grpcio-1.38.0+computecanada h5py-2.10.0+computecanada importlib-metadata-4.10.1+computecanada keras-preprocessing-1.1.2+computecanada markdown-3.3.6+computecanada oauthlib-3.1.1+computecanada opt-einsum-3.3.0+computecanada pyasn1-0.4.8+computecanada pyasn1-modules-0.2.8+computecanada requests-oauthlib-1.3.0+computecanada rsa-4.8+computecanada scipy-1.4.1+computecanada tensorboard-2.8.0+computecanada tensorboard-data-server-0.6.1+computecanada tensorboard-plugin-wit-1.8.0+computecanada tensorflow-estimator-2.3.0+computecanada tensorflow-gpu-2.3.0+computecanada werkzeug-2.0.3+computecanada wrapt-1.11.2+computecanada zipp-3.7.0+computecanada
Looking in links: /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/nix/avx2, /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/nix/generic, /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/keras-2.8.0+computecanada-py2.py3-none-any.whl
Installing collected packages: Keras
Successfully installed Keras-2.8.0+computecanada
Looking in links: /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/nix/avx2, /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/nix/generic, /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/urllib3-1.26.7+computecanada-py2.py3-none-any.whl
Installing collected packages: urllib3
  Attempting uninstall: urllib3
    Found existing installation: urllib3 1.26.9+computecanada
    Uninstalling urllib3-1.26.9+computecanada:
      Successfully uninstalled urllib3-1.26.9+computecanada
Successfully installed urllib3-1.26.7+computecanada
Looking in links: /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/nix/avx2, /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/nix/generic, /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/nltk-3.7+computecanada-py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/nltk-3.6.5+computecanada-py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/nltk-3.6.3+computecanada-py3-none-any.whl
Requirement already satisfied: regex in /localscratch/yinan.29785235.0/env/lib/python3.7/site-packages (from nltk) (2020.11.13+computecanada)
Requirement already satisfied: tqdm in /localscratch/yinan.29785235.0/env/lib/python3.7/site-packages (from nltk) (4.63.1+computecanada)
Requirement already satisfied: joblib in /localscratch/yinan.29785235.0/env/lib/python3.7/site-packages (from nltk) (1.1.0+computecanada)
Requirement already satisfied: click in /localscratch/yinan.29785235.0/env/lib/python3.7/site-packages (from nltk) (8.1.0+computecanada)
Requirement already satisfied: importlib-metadata in /localscratch/yinan.29785235.0/env/lib/python3.7/site-packages (from click->nltk) (4.10.1+computecanada)
Requirement already satisfied: typing-extensions>=3.6.4 in /localscratch/yinan.29785235.0/env/lib/python3.7/site-packages (from importlib-metadata->click->nltk) (4.1.1+computecanada)
Requirement already satisfied: zipp>=0.5 in /localscratch/yinan.29785235.0/env/lib/python3.7/site-packages (from importlib-metadata->click->nltk) (3.7.0+computecanada)
Installing collected packages: nltk
Successfully installed nltk-3.6.3+computecanada
Looking in links: /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/nix/avx2, /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/nix/generic, /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/scikit_learn-0.22.1+computecanada-cp37-cp37m-linux_x86_64.whl
Requirement already satisfied: numpy>=1.11.0 in /cvmfs/soft.computecanada.ca/easybuild/software/2017/Core/scipy-stack/2019a/lib/python3.7/site-packages (from scikit-learn==0.22.1) (1.16.0)
Requirement already satisfied: joblib>=0.11 in /localscratch/yinan.29785235.0/env/lib/python3.7/site-packages (from scikit-learn==0.22.1) (1.1.0+computecanada)
Requirement already satisfied: scipy>=0.17.0 in /localscratch/yinan.29785235.0/env/lib/python3.7/site-packages (from scikit-learn==0.22.1) (1.4.1+computecanada)
Installing collected packages: scikit-learn
Successfully installed scikit-learn-0.22.1+computecanada
Looking in links: /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/nix/avx2, /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/nix/generic, /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic
Requirement already satisfied: tokenizers==0.5.2 in /localscratch/yinan.29785235.0/env/lib/python3.7/site-packages (0.5.2+computecanada)
wandb: Appending key for api.wandb.ai to your netrc file: /home/yinan/.netrc
Starting Task
2022-03-31 06:02:35.592074: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1
[nltk_data] Downloading package stopwords to /home/yinan/nltk_data...
[nltk_data]   Package stopwords is already up-to-date!
[nltk_data] Downloading package wordnet to /home/yinan/nltk_data...
[nltk_data]   Package wordnet is already up-to-date!
wandb: Currently logged in as: yinanazhou (use `wandb login --relogin` to force relogin)
wandb: wandb version 0.12.11 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
2022-03-31 06:02:50.007330: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1
wandb: Tracking run with wandb version 0.12.5
wandb: Syncing run swept-sunset-2
wandb: ⭐️ View project at https://wandb.ai/yinanazhou/xl_512_bs_8_lr_1e06_es_3_lc_True_nr_True_sr_True_stem_False_lemma_True_repeat_1_fold_1
wandb: 🚀 View run at https://wandb.ai/yinanazhou/xl_512_bs_8_lr_1e06_es_3_lc_True_nr_True_sr_True_stem_False_lemma_True_repeat_1_fold_1/runs/3t63r5q5
wandb: Run data is saved locally in /project/6002780/yinan/Thesis_MER_Lyrics/lyric-emotion/wandb/run-20220331_060247-3t63r5q5
wandb: Run `wandb offline` to turn off syncing.

Validation loss decreased (inf --> 1.441050).  Saving model ...
Validation loss decreased (1.441050 --> 1.422546).  Saving model ...
Validation loss decreased (1.422546 --> 1.406987).  Saving model ...
Validation loss decreased (1.406987 --> 1.394437).  Saving model ...
Validation loss decreased (1.394437 --> 1.385030).  Saving model ...
Validation loss decreased (1.385030 --> 1.377016).  Saving model ...
Validation loss decreased (1.377016 --> 1.371314).  Saving model ...
Validation loss decreased (1.371314 --> 1.366144).  Saving model ...
Validation loss decreased (1.366144 --> 1.361522).  Saving model ...
Validation loss decreased (1.361522 --> 1.356556).  Saving model ...
Validation loss decreased (1.356556 --> 1.351467).  Saving model ...
Validation loss decreased (1.351467 --> 1.346667).  Saving model ...
Validation loss decreased (1.346667 --> 1.341938).  Saving model ...
Validation loss decreased (1.341938 --> 1.337148).  Saving model ...
Validation loss decreased (1.337148 --> 1.332648).  Saving model ...
Validation loss decreased (1.332648 --> 1.328454).  Saving model ...
Validation loss decreased (1.328454 --> 1.323934).  Saving model ...
Validation loss decreased (1.323934 --> 1.318981).  Saving model ...
Validation loss decreased (1.318981 --> 1.313722).  Saving model ...
Validation loss decreased (1.313722 --> 1.308605).  Saving model ...
Validation loss decreased (1.308605 --> 1.303833).  Saving model ...
Validation loss decreased (1.303833 --> 1.298572).  Saving model ...
Validation loss decreased (1.298572 --> 1.294304).  Saving model ...
Validation loss decreased (1.294304 --> 1.289001).  Saving model ...
Validation loss decreased (1.289001 --> 1.283986).  Saving model ...
Validation loss decreased (1.283986 --> 1.279423).  Saving model ...
Validation loss decreased (1.279423 --> 1.275605).  Saving model ...
Validation loss decreased (1.275605 --> 1.273295).  Saving model ...
Validation loss decreased (1.273295 --> 1.271246).  Saving model ...
Validation loss decreased (1.271246 --> 1.268588).  Saving model ...
Validation loss decreased (1.268588 --> 1.264408).  Saving model ...
Validation loss decreased (1.264408 --> 1.259131).  Saving model ...
Validation loss decreased (1.259131 --> 1.257839).  Saving model ...
Validation loss decreased (1.257839 --> 1.251614).  Saving model ...
Validation loss decreased (1.251614 --> 1.250597).  Saving model ...
Validation loss decreased (1.250597 --> 1.245848).  Saving model ...
Validation loss decreased (1.245848 --> 1.242941).  Saving model ...
Validation loss decreased (1.242941 --> 1.237915).  Saving model ...
Validation loss decreased (1.237915 --> 1.235737).  Saving model ...
Validation loss decreased (1.235737 --> 1.235414).  Saving model ...
Validation loss decreased (1.235414 --> 1.229424).  Saving model ...
Validation loss decreased (1.229424 --> 1.225860).  Saving model ...
Validation loss decreased (1.225860 --> 1.224981).  Saving model ...
Validation loss decreased (1.224981 --> 1.219308).  Saving model ...
Validation loss decreased (1.219308 --> 1.218950).  Saving model ...
Validation loss decreased (1.218950 --> 1.216117).  Saving model ...
Validation loss decreased (1.216117 --> 1.214318).  Saving model ...
Validation loss decreased (1.214318 --> 1.212653).  Saving model ...
Validation loss decreased (1.212653 --> 1.209030).  Saving model ...
Validation loss decreased (1.209030 --> 1.203927).  Saving model ...
Validation loss decreased (1.203927 --> 1.199859).  Saving model ...
Validation loss decreased (1.199859 --> 1.196007).  Saving model ...
Validation loss decreased (1.196007 --> 1.193905).  Saving model ...
Validation loss decreased (1.193905 --> 1.189473).  Saving model ...
EarlyStopping counter: 1 out of 3.0
Validation loss decreased (1.189473 --> 1.187035).  Saving model ...
Validation loss decreased (1.187035 --> 1.185654).  Saving model ...
Validation loss decreased (1.185654 --> 1.182188).  Saving model ...
Validation loss decreased (1.182188 --> 1.176013).  Saving model ...
EarlyStopping counter: 1 out of 3.0
Validation loss decreased (1.176013 --> 1.171099).  Saving model ...
EarlyStopping counter: 1 out of 3.0
Validation loss decreased (1.171099 --> 1.168495).  Saving model ...
Validation loss decreased (1.168495 --> 1.166129).  Saving model ...
Validation loss decreased (1.166129 --> 1.164369).  Saving model ...
Validation loss decreased (1.164369 --> 1.160331).  Saving model ...
Validation loss decreased (1.160331 --> 1.158230).  Saving model ...
Validation loss decreased (1.158230 --> 1.154337).  Saving model ...
Validation loss decreased (1.154337 --> 1.152773).  Saving model ...
Validation loss decreased (1.152773 --> 1.151421).  Saving model ...
Validation loss decreased (1.151421 --> 1.147668).  Saving model ...
Validation loss decreased (1.147668 --> 1.145653).  Saving model ...
Validation loss decreased (1.145653 --> 1.144194).  Saving model ...
Validation loss decreased (1.144194 --> 1.138765).  Saving model ...
Validation loss decreased (1.138765 --> 1.132761).  Saving model ...
Validation loss decreased (1.132761 --> 1.132460).  Saving model ...
EarlyStopping counter: 1 out of 3.0
Validation loss decreased (1.132460 --> 1.132265).  Saving model ...
Validation loss decreased (1.132265 --> 1.126817).  Saving model ...
Validation loss decreased (1.126817 --> 1.119659).  Saving model ...
EarlyStopping counter: 1 out of 3.0
EarlyStopping counter: 2 out of 3.0
EarlyStopping counter: 3 out of 3.0
/localscratch/yinan.29785235.0/env/lib/python3.7/site-packages/torch/nn/functional.py:1794: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.
  warnings.warn("nn.functional.tanh is deprecated. Use torch.tanh instead.")
/localscratch/yinan.29785235.0/env/lib/python3.7/site-packages/transformers/optimization.py:155: UserWarning: This overload of add_ is deprecated:
	add_(Number alpha, Tensor other)
Consider using one of the following signatures instead:
	add_(Tensor other, *, Number alpha) (Triggered internally at  ../torch/csrc/utils/python_arg_parser.cpp:1025.)
  exp_avg.mul_(beta1).add_(1.0 - beta1, grad)
wandb: Waiting for W&B process to finish, PID 51750... (success).
wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: \ 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: | 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: / 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: \ 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: | 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: / 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: \ 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: | 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: / 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: \ 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb:                                                                                
wandb: Run history:
wandb:     e_F1 ▁▁▃▃▄▄▄▅▅▅▅▅▆▅▆▆▆▆▆▆▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇█████
wandb:   e_loss █▇▇▆▆▆▆▆▅▅▅▅▄▄▄▄▄▄▄▄▃▃▃▃▃▃▃▂▂▂▂▂▂▂▂▁▁▁▁▁
wandb:     t_F1 ▁▂▂▃▃▃▄▃▄▄▅▅▅▅▅▅▆▆▆▆▆▆▇▇▇▇▇▇▇▇███▇██▇███
wandb:   t_loss ██▇▇▇▇▇▇▆▆▆▅▅▅▅▄▄▄▄▄▄▃▃▃▃▃▂▃▂▂▂▂▂▂▂▁▂▁▁▁
wandb: 
wandb: Run summary:
wandb:     e_F1 49.26654
wandb:   e_loss 1.12045
wandb:     t_F1 61.30426
wandb:   t_loss 0.9339
wandb: 
wandb: Synced 4 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Synced swept-sunset-2: https://wandb.ai/yinanazhou/xl_512_bs_8_lr_1e06_es_3_lc_True_nr_True_sr_True_stem_False_lemma_True_repeat_1_fold_1/runs/3t63r5q5
wandb: Find logs at: ./wandb/run-20220331_060247-3t63r5q5/logs/debug.log
wandb: 

wandb: wandb version 0.12.11 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
2022-03-31 06:56:37.767943: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1
wandb: Tracking run with wandb version 0.12.5
wandb: Syncing run fanciful-water-2
wandb: ⭐️ View project at https://wandb.ai/yinanazhou/xl_512_bs_8_lr_1e06_es_3_lc_True_nr_True_sr_True_stem_False_lemma_True_repeat_1_fold_2
wandb: 🚀 View run at https://wandb.ai/yinanazhou/xl_512_bs_8_lr_1e06_es_3_lc_True_nr_True_sr_True_stem_False_lemma_True_repeat_1_fold_2/runs/1g5bteqf
wandb: Run data is saved locally in /project/6002780/yinan/Thesis_MER_Lyrics/lyric-emotion/wandb/run-20220331_065634-1g5bteqf
wandb: Run `wandb offline` to turn off syncing.

Validation loss decreased (inf --> 1.478138).  Saving model ...
Validation loss decreased (1.478138 --> 1.447249).  Saving model ...
Validation loss decreased (1.447249 --> 1.422804).  Saving model ...
Validation loss decreased (1.422804 --> 1.405539).  Saving model ...
Validation loss decreased (1.405539 --> 1.393827).  Saving model ...
Validation loss decreased (1.393827 --> 1.384835).  Saving model ...
Validation loss decreased (1.384835 --> 1.377469).  Saving model ...
Validation loss decreased (1.377469 --> 1.370877).  Saving model ...
Validation loss decreased (1.370877 --> 1.365023).  Saving model ...
Validation loss decreased (1.365023 --> 1.360018).  Saving model ...
Validation loss decreased (1.360018 --> 1.355777).  Saving model ...
Validation loss decreased (1.355777 --> 1.351016).  Saving model ...
Validation loss decreased (1.351016 --> 1.346831).  Saving model ...
Validation loss decreased (1.346831 --> 1.342161).  Saving model ...
Validation loss decreased (1.342161 --> 1.338025).  Saving model ...
Validation loss decreased (1.338025 --> 1.333357).  Saving model ...
Validation loss decreased (1.333357 --> 1.328700).  Saving model ...
Validation loss decreased (1.328700 --> 1.323621).  Saving model ...
Validation loss decreased (1.323621 --> 1.319196).  Saving model ...
Validation loss decreased (1.319196 --> 1.314270).  Saving model ...
Validation loss decreased (1.314270 --> 1.308750).  Saving model ...
Validation loss decreased (1.308750 --> 1.303583).  Saving model ...
Validation loss decreased (1.303583 --> 1.297716).  Saving model ...
Validation loss decreased (1.297716 --> 1.291133).  Saving model ...
Validation loss decreased (1.291133 --> 1.286232).  Saving model ...
Validation loss decreased (1.286232 --> 1.281479).  Saving model ...
Validation loss decreased (1.281479 --> 1.275442).  Saving model ...
Validation loss decreased (1.275442 --> 1.268894).  Saving model ...
Validation loss decreased (1.268894 --> 1.262337).  Saving model ...
Validation loss decreased (1.262337 --> 1.254911).  Saving model ...
Validation loss decreased (1.254911 --> 1.248874).  Saving model ...
Validation loss decreased (1.248874 --> 1.242348).  Saving model ...
Validation loss decreased (1.242348 --> 1.234821).  Saving model ...
Validation loss decreased (1.234821 --> 1.228494).  Saving model ...
Validation loss decreased (1.228494 --> 1.222234).  Saving model ...
Validation loss decreased (1.222234 --> 1.216131).  Saving model ...
Validation loss decreased (1.216131 --> 1.209705).  Saving model ...
Validation loss decreased (1.209705 --> 1.203456).  Saving model ...
Validation loss decreased (1.203456 --> 1.196721).  Saving model ...
Validation loss decreased (1.196721 --> 1.190379).  Saving model ...
Validation loss decreased (1.190379 --> 1.184681).  Saving model ...
Validation loss decreased (1.184681 --> 1.178107).  Saving model ...
Validation loss decreased (1.178107 --> 1.172142).  Saving model ...
Validation loss decreased (1.172142 --> 1.165764).  Saving model ...
Validation loss decreased (1.165764 --> 1.160462).  Saving model ...
Validation loss decreased (1.160462 --> 1.154995).  Saving model ...
Validation loss decreased (1.154995 --> 1.148858).  Saving model ...
Validation loss decreased (1.148858 --> 1.144097).  Saving model ...
Validation loss decreased (1.144097 --> 1.137613).  Saving model ...
Validation loss decreased (1.137613 --> 1.131515).  Saving model ...
Validation loss decreased (1.131515 --> 1.125328).  Saving model ...
Validation loss decreased (1.125328 --> 1.119375).  Saving model ...
Validation loss decreased (1.119375 --> 1.113437).  Saving model ...
Validation loss decreased (1.113437 --> 1.108473).  Saving model ...
Validation loss decreased (1.108473 --> 1.102941).  Saving model ...
Validation loss decreased (1.102941 --> 1.097536).  Saving model ...
Validation loss decreased (1.097536 --> 1.093733).  Saving model ...
Validation loss decreased (1.093733 --> 1.088227).  Saving model ...
Validation loss decreased (1.088227 --> 1.082762).  Saving model ...
Validation loss decreased (1.082762 --> 1.077591).  Saving model ...
Validation loss decreased (1.077591 --> 1.074156).  Saving model ...
Validation loss decreased (1.074156 --> 1.070543).  Saving model ...
Validation loss decreased (1.070543 --> 1.066248).  Saving model ...
Validation loss decreased (1.066248 --> 1.064344).  Saving model ...
Validation loss decreased (1.064344 --> 1.057102).  Saving model ...
Validation loss decreased (1.057102 --> 1.053702).  Saving model ...
Validation loss decreased (1.053702 --> 1.049025).  Saving model ...
Validation loss decreased (1.049025 --> 1.044327).  Saving model ...
Validation loss decreased (1.044327 --> 1.039990).  Saving model ...
Validation loss decreased (1.039990 --> 1.037309).  Saving model ...
Validation loss decreased (1.037309 --> 1.031703).  Saving model ...
Validation loss decreased (1.031703 --> 1.028229).  Saving model ...
Validation loss decreased (1.028229 --> 1.021642).  Saving model ...
Validation loss decreased (1.021642 --> 1.018629).  Saving model ...
Validation loss decreased (1.018629 --> 1.016150).  Saving model ...
Validation loss decreased (1.016150 --> 1.011569).  Saving model ...
Validation loss decreased (1.011569 --> 1.008505).  Saving model ...
Validation loss decreased (1.008505 --> 1.004339).  Saving model ...
Validation loss decreased (1.004339 --> 1.001251).  Saving model ...
Validation loss decreased (1.001251 --> 0.998199).  Saving model ...
Validation loss decreased (0.998199 --> 0.995180).  Saving model ...
Validation loss decreased (0.995180 --> 0.991546).  Saving model ...
Validation loss decreased (0.991546 --> 0.989212).  Saving model ...
Validation loss decreased (0.989212 --> 0.986973).  Saving model ...
Validation loss decreased (0.986973 --> 0.986204).  Saving model ...
Validation loss decreased (0.986204 --> 0.983823).  Saving model ...
Validation loss decreased (0.983823 --> 0.980295).  Saving model ...
Validation loss decreased (0.980295 --> 0.977602).  Saving model ...
Validation loss decreased (0.977602 --> 0.973800).  Saving model ...
Validation loss decreased (0.973800 --> 0.971154).  Saving model ...
Validation loss decreased (0.971154 --> 0.968399).  Saving model ...
Validation loss decreased (0.968399 --> 0.965774).  Saving model ...
Validation loss decreased (0.965774 --> 0.963646).  Saving model ...
Validation loss decreased (0.963646 --> 0.960621).  Saving model ...
Validation loss decreased (0.960621 --> 0.958130).  Saving model ...
Validation loss decreased (0.958130 --> 0.955637).  Saving model ...
Validation loss decreased (0.955637 --> 0.954901).  Saving model ...
Validation loss decreased (0.954901 --> 0.952942).  Saving model ...
Validation loss decreased (0.952942 --> 0.950610).  Saving model ...
Validation loss decreased (0.950610 --> 0.949184).  Saving model ...
Validation loss decreased (0.949184 --> 0.947409).  Saving model ...
Validation loss decreased (0.947409 --> 0.943559).  Saving model ...
Validation loss decreased (0.943559 --> 0.941838).  Saving model ...
Validation loss decreased (0.941838 --> 0.940910).  Saving model ...
Validation loss decreased (0.940910 --> 0.940382).  Saving model ...
Validation loss decreased (0.940382 --> 0.938935).  Saving model ...
Validation loss decreased (0.938935 --> 0.936993).  Saving model ...
Validation loss decreased (0.936993 --> 0.936336).  Saving model ...
Validation loss decreased (0.936336 --> 0.934612).  Saving model ...
Validation loss decreased (0.934612 --> 0.933979).  Saving model ...
Validation loss decreased (0.933979 --> 0.931858).  Saving model ...
Validation loss decreased (0.931858 --> 0.931139).  Saving model ...
Validation loss decreased (0.931139 --> 0.928717).  Saving model ...
Validation loss decreased (0.928717 --> 0.927410).  Saving model ...
Validation loss decreased (0.927410 --> 0.925669).  Saving model ...
Validation loss decreased (0.925669 --> 0.924476).  Saving model ...
Validation loss decreased (0.924476 --> 0.923810).  Saving model ...
Validation loss decreased (0.923810 --> 0.923422).  Saving model ...
EarlyStopping counter: 1 out of 3.0
Validation loss decreased (0.923422 --> 0.922299).  Saving model ...
Validation loss decreased (0.922299 --> 0.922272).  Saving model ...
EarlyStopping counter: 1 out of 3.0
Validation loss decreased (0.922272 --> 0.920066).  Saving model ...
EarlyStopping counter: 1 out of 3.0
EarlyStopping counter: 2 out of 3.0
EarlyStopping counter: 3 out of 3.0
/localscratch/yinan.29785235.0/env/lib/python3.7/site-packages/torch/nn/functional.py:1794: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.
  warnings.warn("nn.functional.tanh is deprecated. Use torch.tanh instead.")
wandb: Waiting for W&B process to finish, PID 54644... (success).
wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: \ 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: | 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: / 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: \ 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: | 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: / 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: \ 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: | 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: / 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: \ 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb:                                                                                
wandb: Run history:
wandb:     e_F1 ▁▁▂▄▄▅▅▅▆▆▆▆▇▇▇▇▇▇▇▇▇▇▇█████████████████
wandb:   e_loss █▇▇▇▆▆▆▆▆▅▅▅▄▄▄▄▃▃▃▃▃▃▂▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁
wandb:     t_F1 ▁▁▂▃▃▃▄▃▄▄▄▅▅▅▆▅▆▆▆▆▆▇▇▇▆▇▇▆█▇▇▇██▇█████
wandb:   t_loss █▇▇▇▇▆▆▆▆▆▆▅▅▅▅▅▄▄▄▄▄▄▃▃▃▃▃▃▂▂▂▂▂▂▂▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:     e_F1 59.88918
wandb:   e_loss 0.92035
wandb:     t_F1 70.11721
wandb:   t_loss 0.83593
wandb: 
wandb: Synced 4 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Synced fanciful-water-2: https://wandb.ai/yinanazhou/xl_512_bs_8_lr_1e06_es_3_lc_True_nr_True_sr_True_stem_False_lemma_True_repeat_1_fold_2/runs/1g5bteqf
wandb: Find logs at: ./wandb/run-20220331_065634-1g5bteqf/logs/debug.log
wandb: 

wandb: wandb version 0.12.11 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
2022-03-31 08:20:37.735639: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1
wandb: Tracking run with wandb version 0.12.5
wandb: Syncing run icy-durian-2
wandb: ⭐️ View project at https://wandb.ai/yinanazhou/xl_512_bs_8_lr_1e06_es_3_lc_True_nr_True_sr_True_stem_False_lemma_True_repeat_2_fold_1
wandb: 🚀 View run at https://wandb.ai/yinanazhou/xl_512_bs_8_lr_1e06_es_3_lc_True_nr_True_sr_True_stem_False_lemma_True_repeat_2_fold_1/runs/lnqdc2ga
wandb: Run data is saved locally in /project/6002780/yinan/Thesis_MER_Lyrics/lyric-emotion/wandb/run-20220331_082034-lnqdc2ga
wandb: Run `wandb offline` to turn off syncing.

Validation loss decreased (inf --> 1.415690).  Saving model ...
Validation loss decreased (1.415690 --> 1.403476).  Saving model ...
Validation loss decreased (1.403476 --> 1.393336).  Saving model ...
Validation loss decreased (1.393336 --> 1.385420).  Saving model ...
Validation loss decreased (1.385420 --> 1.378542).  Saving model ...
Validation loss decreased (1.378542 --> 1.373326).  Saving model ...
Validation loss decreased (1.373326 --> 1.368267).  Saving model ...
Validation loss decreased (1.368267 --> 1.363214).  Saving model ...
Validation loss decreased (1.363214 --> 1.358447).  Saving model ...
Validation loss decreased (1.358447 --> 1.354285).  Saving model ...
Validation loss decreased (1.354285 --> 1.349824).  Saving model ...
Validation loss decreased (1.349824 --> 1.345878).  Saving model ...
Validation loss decreased (1.345878 --> 1.341131).  Saving model ...
Validation loss decreased (1.341131 --> 1.336660).  Saving model ...
Validation loss decreased (1.336660 --> 1.331949).  Saving model ...
Validation loss decreased (1.331949 --> 1.327698).  Saving model ...
Validation loss decreased (1.327698 --> 1.323181).  Saving model ...
Validation loss decreased (1.323181 --> 1.318115).  Saving model ...
Validation loss decreased (1.318115 --> 1.312892).  Saving model ...
Validation loss decreased (1.312892 --> 1.307210).  Saving model ...
Validation loss decreased (1.307210 --> 1.301275).  Saving model ...
Validation loss decreased (1.301275 --> 1.295795).  Saving model ...
Validation loss decreased (1.295795 --> 1.289826).  Saving model ...
Validation loss decreased (1.289826 --> 1.283903).  Saving model ...
Validation loss decreased (1.283903 --> 1.277386).  Saving model ...
Validation loss decreased (1.277386 --> 1.269968).  Saving model ...
Validation loss decreased (1.269968 --> 1.263099).  Saving model ...
Validation loss decreased (1.263099 --> 1.254754).  Saving model ...
Validation loss decreased (1.254754 --> 1.246600).  Saving model ...
Validation loss decreased (1.246600 --> 1.238814).  Saving model ...
Validation loss decreased (1.238814 --> 1.232045).  Saving model ...
Validation loss decreased (1.232045 --> 1.224974).  Saving model ...
Validation loss decreased (1.224974 --> 1.218668).  Saving model ...
Validation loss decreased (1.218668 --> 1.212468).  Saving model ...
Validation loss decreased (1.212468 --> 1.206637).  Saving model ...
Validation loss decreased (1.206637 --> 1.199834).  Saving model ...
Validation loss decreased (1.199834 --> 1.194463).  Saving model ...
Validation loss decreased (1.194463 --> 1.187515).  Saving model ...
Validation loss decreased (1.187515 --> 1.181258).  Saving model ...
Validation loss decreased (1.181258 --> 1.174791).  Saving model ...
Validation loss decreased (1.174791 --> 1.170286).  Saving model ...
Validation loss decreased (1.170286 --> 1.166230).  Saving model ...
Validation loss decreased (1.166230 --> 1.162031).  Saving model ...
Validation loss decreased (1.162031 --> 1.157434).  Saving model ...
Validation loss decreased (1.157434 --> 1.152167).  Saving model ...
Validation loss decreased (1.152167 --> 1.148584).  Saving model ...
Validation loss decreased (1.148584 --> 1.145006).  Saving model ...
Validation loss decreased (1.145006 --> 1.139107).  Saving model ...
Validation loss decreased (1.139107 --> 1.133657).  Saving model ...
Validation loss decreased (1.133657 --> 1.131071).  Saving model ...
Validation loss decreased (1.131071 --> 1.126759).  Saving model ...
Validation loss decreased (1.126759 --> 1.122804).  Saving model ...
Validation loss decreased (1.122804 --> 1.117676).  Saving model ...
Validation loss decreased (1.117676 --> 1.113923).  Saving model ...
Validation loss decreased (1.113923 --> 1.112076).  Saving model ...
Validation loss decreased (1.112076 --> 1.106846).  Saving model ...
Validation loss decreased (1.106846 --> 1.103115).  Saving model ...
Validation loss decreased (1.103115 --> 1.099492).  Saving model ...
Validation loss decreased (1.099492 --> 1.094161).  Saving model ...
Validation loss decreased (1.094161 --> 1.091781).  Saving model ...
Validation loss decreased (1.091781 --> 1.088128).  Saving model ...
Validation loss decreased (1.088128 --> 1.085568).  Saving model ...
Validation loss decreased (1.085568 --> 1.081137).  Saving model ...
Validation loss decreased (1.081137 --> 1.077405).  Saving model ...
Validation loss decreased (1.077405 --> 1.073343).  Saving model ...
Validation loss decreased (1.073343 --> 1.068585).  Saving model ...
Validation loss decreased (1.068585 --> 1.067225).  Saving model ...
Validation loss decreased (1.067225 --> 1.062800).  Saving model ...
Validation loss decreased (1.062800 --> 1.061198).  Saving model ...
Validation loss decreased (1.061198 --> 1.056152).  Saving model ...
Validation loss decreased (1.056152 --> 1.054189).  Saving model ...
Validation loss decreased (1.054189 --> 1.050916).  Saving model ...
Validation loss decreased (1.050916 --> 1.048386).  Saving model ...
Validation loss decreased (1.048386 --> 1.046504).  Saving model ...
Validation loss decreased (1.046504 --> 1.044660).  Saving model ...
Validation loss decreased (1.044660 --> 1.043051).  Saving model ...
Validation loss decreased (1.043051 --> 1.039280).  Saving model ...
Validation loss decreased (1.039280 --> 1.037467).  Saving model ...
Validation loss decreased (1.037467 --> 1.033248).  Saving model ...
Validation loss decreased (1.033248 --> 1.031257).  Saving model ...
Validation loss decreased (1.031257 --> 1.030619).  Saving model ...
Validation loss decreased (1.030619 --> 1.029216).  Saving model ...
Validation loss decreased (1.029216 --> 1.026849).  Saving model ...
Validation loss decreased (1.026849 --> 1.022712).  Saving model ...
EarlyStopping counter: 1 out of 3.0
Validation loss decreased (1.022712 --> 1.019817).  Saving model ...
Validation loss decreased (1.019817 --> 1.018924).  Saving model ...
Validation loss decreased (1.018924 --> 1.016802).  Saving model ...
Validation loss decreased (1.016802 --> 1.014585).  Saving model ...
Validation loss decreased (1.014585 --> 1.014197).  Saving model ...
EarlyStopping counter: 1 out of 3.0
Validation loss decreased (1.014197 --> 1.009070).  Saving model ...
EarlyStopping counter: 1 out of 3.0
EarlyStopping counter: 2 out of 3.0
Validation loss decreased (1.009070 --> 1.008907).  Saving model ...
Validation loss decreased (1.008907 --> 1.004901).  Saving model ...
Validation loss decreased (1.004901 --> 1.003400).  Saving model ...
EarlyStopping counter: 1 out of 3.0
Validation loss decreased (1.003400 --> 1.000829).  Saving model ...
Validation loss decreased (1.000829 --> 0.998821).  Saving model ...
Validation loss decreased (0.998821 --> 0.998240).  Saving model ...
Validation loss decreased (0.998240 --> 0.997144).  Saving model ...
EarlyStopping counter: 1 out of 3.0
Validation loss decreased (0.997144 --> 0.994188).  Saving model ...
Validation loss decreased (0.994188 --> 0.992106).  Saving model ...
Validation loss decreased (0.992106 --> 0.991293).  Saving model ...
EarlyStopping counter: 1 out of 3.0
EarlyStopping counter: 2 out of 3.0
EarlyStopping counter: 3 out of 3.0
/localscratch/yinan.29785235.0/env/lib/python3.7/site-packages/torch/nn/functional.py:1794: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.
  warnings.warn("nn.functional.tanh is deprecated. Use torch.tanh instead.")
wandb: Waiting for W&B process to finish, PID 59158... (success).
wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: \ 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: | 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: / 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: \ 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: | 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: / 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: \ 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: | 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: / 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb:                                                                                
wandb: Run history:
wandb:     e_F1 ▁▂▃▄▅▅▅▅▆▆▆▆▆▆▆▆▆▇▇▇▇▇▇▇▇▇▇▇▇███████████
wandb:   e_loss ██▇▇▇▇▆▆▆▆▅▅▅▄▄▄▄▃▃▃▃▃▃▂▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁
wandb:     t_F1 ▁▁▁▂▂▂▃▃▄▄▄▄▅▅▅▅▅▅▆▆▆▇▆▆▇▇▇▇▇▇▆▇▇█▇█▇█▇█
wandb:   t_loss ███▇▇▇▇▇▇▆▆▆▅▅▅▅▅▄▄▄▄▃▄▃▃▃▃▃▃▂▂▂▂▂▂▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:     e_F1 58.56808
wandb:   e_loss 0.99235
wandb:     t_F1 69.55512
wandb:   t_loss 0.81443
wandb: 
wandb: Synced 4 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Synced icy-durian-2: https://wandb.ai/yinanazhou/xl_512_bs_8_lr_1e06_es_3_lc_True_nr_True_sr_True_stem_False_lemma_True_repeat_2_fold_1/runs/lnqdc2ga
wandb: Find logs at: ./wandb/run-20220331_082034-lnqdc2ga/logs/debug.log
wandb: 

wandb: wandb version 0.12.11 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
2022-03-31 09:33:12.517677: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1
wandb: Tracking run with wandb version 0.12.5
wandb: Syncing run sunny-terrain-2
wandb: ⭐️ View project at https://wandb.ai/yinanazhou/xl_512_bs_8_lr_1e06_es_3_lc_True_nr_True_sr_True_stem_False_lemma_True_repeat_2_fold_2
wandb: 🚀 View run at https://wandb.ai/yinanazhou/xl_512_bs_8_lr_1e06_es_3_lc_True_nr_True_sr_True_stem_False_lemma_True_repeat_2_fold_2/runs/pa0q05fv
wandb: Run data is saved locally in /project/6002780/yinan/Thesis_MER_Lyrics/lyric-emotion/wandb/run-20220331_093309-pa0q05fv
wandb: Run `wandb offline` to turn off syncing.

Validation loss decreased (inf --> 1.394111).  Saving model ...
Validation loss decreased (1.394111 --> 1.386955).  Saving model ...
Validation loss decreased (1.386955 --> 1.381460).  Saving model ...
Validation loss decreased (1.381460 --> 1.376797).  Saving model ...
Validation loss decreased (1.376797 --> 1.373031).  Saving model ...
Validation loss decreased (1.373031 --> 1.369469).  Saving model ...
Validation loss decreased (1.369469 --> 1.366324).  Saving model ...
Validation loss decreased (1.366324 --> 1.363303).  Saving model ...
Validation loss decreased (1.363303 --> 1.360177).  Saving model ...
Validation loss decreased (1.360177 --> 1.357124).  Saving model ...
Validation loss decreased (1.357124 --> 1.353994).  Saving model ...
Validation loss decreased (1.353994 --> 1.351114).  Saving model ...
Validation loss decreased (1.351114 --> 1.347660).  Saving model ...
Validation loss decreased (1.347660 --> 1.344591).  Saving model ...
Validation loss decreased (1.344591 --> 1.341418).  Saving model ...
Validation loss decreased (1.341418 --> 1.338325).  Saving model ...
Validation loss decreased (1.338325 --> 1.334722).  Saving model ...
Validation loss decreased (1.334722 --> 1.330620).  Saving model ...
Validation loss decreased (1.330620 --> 1.326864).  Saving model ...
Validation loss decreased (1.326864 --> 1.322619).  Saving model ...
Validation loss decreased (1.322619 --> 1.319150).  Saving model ...
Validation loss decreased (1.319150 --> 1.315170).  Saving model ...
Validation loss decreased (1.315170 --> 1.310401).  Saving model ...
Validation loss decreased (1.310401 --> 1.305226).  Saving model ...
Validation loss decreased (1.305226 --> 1.299293).  Saving model ...
Validation loss decreased (1.299293 --> 1.293626).  Saving model ...
Validation loss decreased (1.293626 --> 1.287807).  Saving model ...
Validation loss decreased (1.287807 --> 1.282298).  Saving model ...
Validation loss decreased (1.282298 --> 1.276162).  Saving model ...
Validation loss decreased (1.276162 --> 1.270058).  Saving model ...
Validation loss decreased (1.270058 --> 1.262696).  Saving model ...
Validation loss decreased (1.262696 --> 1.256595).  Saving model ...
Validation loss decreased (1.256595 --> 1.250871).  Saving model ...
Validation loss decreased (1.250871 --> 1.245376).  Saving model ...
Validation loss decreased (1.245376 --> 1.241026).  Saving model ...
Validation loss decreased (1.241026 --> 1.232855).  Saving model ...
Validation loss decreased (1.232855 --> 1.225561).  Saving model ...
Validation loss decreased (1.225561 --> 1.220177).  Saving model ...
Validation loss decreased (1.220177 --> 1.216449).  Saving model ...
Validation loss decreased (1.216449 --> 1.209515).  Saving model ...
Validation loss decreased (1.209515 --> 1.204603).  Saving model ...
Validation loss decreased (1.204603 --> 1.199985).  Saving model ...
Validation loss decreased (1.199985 --> 1.193195).  Saving model ...
Validation loss decreased (1.193195 --> 1.190660).  Saving model ...
Validation loss decreased (1.190660 --> 1.184322).  Saving model ...
Validation loss decreased (1.184322 --> 1.178737).  Saving model ...
Validation loss decreased (1.178737 --> 1.173322).  Saving model ...
Validation loss decreased (1.173322 --> 1.168441).  Saving model ...
Validation loss decreased (1.168441 --> 1.161028).  Saving model ...
Validation loss decreased (1.161028 --> 1.157761).  Saving model ...
Validation loss decreased (1.157761 --> 1.154473).  Saving model ...
Validation loss decreased (1.154473 --> 1.149379).  Saving model ...
Validation loss decreased (1.149379 --> 1.146075).  Saving model ...
Validation loss decreased (1.146075 --> 1.140219).  Saving model ...
Validation loss decreased (1.140219 --> 1.134646).  Saving model ...
Validation loss decreased (1.134646 --> 1.129438).  Saving model ...
Validation loss decreased (1.129438 --> 1.125259).  Saving model ...
Validation loss decreased (1.125259 --> 1.121108).  Saving model ...
Validation loss decreased (1.121108 --> 1.118553).  Saving model ...
Validation loss decreased (1.118553 --> 1.117776).  Saving model ...
Validation loss decreased (1.117776 --> 1.111726).  Saving model ...
Validation loss decreased (1.111726 --> 1.105148).  Saving model ...
Validation loss decreased (1.105148 --> 1.103849).  Saving model ...
EarlyStopping counter: 1 out of 3.0
Validation loss decreased (1.103849 --> 1.102364).  Saving model ...
Validation loss decreased (1.102364 --> 1.097569).  Saving model ...
Validation loss decreased (1.097569 --> 1.092346).  Saving model ...
Validation loss decreased (1.092346 --> 1.088746).  Saving model ...
Validation loss decreased (1.088746 --> 1.085701).  Saving model ...
Validation loss decreased (1.085701 --> 1.081008).  Saving model ...
Validation loss decreased (1.081008 --> 1.074841).  Saving model ...
Validation loss decreased (1.074841 --> 1.069305).  Saving model ...
Validation loss decreased (1.069305 --> 1.068768).  Saving model ...
Validation loss decreased (1.068768 --> 1.064074).  Saving model ...
Validation loss decreased (1.064074 --> 1.061445).  Saving model ...
Validation loss decreased (1.061445 --> 1.061105).  Saving model ...
Validation loss decreased (1.061105 --> 1.059413).  Saving model ...
Validation loss decreased (1.059413 --> 1.055129).  Saving model ...
Validation loss decreased (1.055129 --> 1.052930).  Saving model ...
Validation loss decreased (1.052930 --> 1.049527).  Saving model ...
Validation loss decreased (1.049527 --> 1.047598).  Saving model ...
Validation loss decreased (1.047598 --> 1.044404).  Saving model ...
Validation loss decreased (1.044404 --> 1.040068).  Saving model ...
Validation loss decreased (1.040068 --> 1.034612).  Saving model ...
Validation loss decreased (1.034612 --> 1.032006).  Saving model ...
EarlyStopping counter: 1 out of 3.0
Validation loss decreased (1.032006 --> 1.031709).  Saving model ...
Validation loss decreased (1.031709 --> 1.029669).  Saving model ...
Validation loss decreased (1.029669 --> 1.027431).  Saving model ...
Validation loss decreased (1.027431 --> 1.025336).  Saving model ...
Validation loss decreased (1.025336 --> 1.020745).  Saving model ...
EarlyStopping counter: 1 out of 3.0
Validation loss decreased (1.020745 --> 1.016997).  Saving model ...
EarlyStopping counter: 1 out of 3.0
Validation loss decreased (1.016997 --> 1.013510).  Saving model ...
Validation loss decreased (1.013510 --> 1.011615).  Saving model ...
Validation loss decreased (1.011615 --> 1.010417).  Saving model ...
Validation loss decreased (1.010417 --> 1.006695).  Saving model ...
Validation loss decreased (1.006695 --> 1.004622).  Saving model ...
Validation loss decreased (1.004622 --> 1.001635).  Saving model ...
Validation loss decreased (1.001635 --> 0.999597).  Saving model ...
Validation loss decreased (0.999597 --> 0.998075).  Saving model ...
Validation loss decreased (0.998075 --> 0.994668).  Saving model ...
Validation loss decreased (0.994668 --> 0.991978).  Saving model ...
EarlyStopping counter: 1 out of 3.0
Validation loss decreased (0.991978 --> 0.990231).  Saving model ...
EarlyStopping counter: 1 out of 3.0
EarlyStopping counter: 2 out of 3.0
Validation loss decreased (0.990231 --> 0.989042).  Saving model ...
Validation loss decreased (0.989042 --> 0.985764).  Saving model ...
Validation loss decreased (0.985764 --> 0.982087).  Saving model ...
EarlyStopping counter: 1 out of 3.0
Validation loss decreased (0.982087 --> 0.979734).  Saving model ...
EarlyStopping counter: 1 out of 3.0
Validation loss decreased (0.979734 --> 0.979464).  Saving model ...
Validation loss decreased (0.979464 --> 0.978984).  Saving model ...
Validation loss decreased (0.978984 --> 0.975150).  Saving model ...
EarlyStopping counter: 1 out of 3.0
Validation loss decreased (0.975150 --> 0.974437).  Saving model ...
Validation loss decreased (0.974437 --> 0.971472).  Saving model ...
EarlyStopping counter: 1 out of 3.0
EarlyStopping counter: 2 out of 3.0
EarlyStopping counter: 3 out of 3.0
/localscratch/yinan.29785235.0/env/lib/python3.7/site-packages/torch/nn/functional.py:1794: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.
  warnings.warn("nn.functional.tanh is deprecated. Use torch.tanh instead.")
wandb: Waiting for W&B process to finish, PID 63047... (success).
wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: \ 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: | 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: / 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: \ 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: | 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: / 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: \ 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: | 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: / 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: \ 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: | 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb:                                                                                
wandb: Run history:
wandb:     e_F1 ▁▃▄▄▄▄▅▄▅▅▅▅▅▅▆▆▆▆▆▆▇▇▇▇▇▇▇▇▇█▇█████████
wandb:   e_loss ███▇▇▇▇▇▆▆▆▅▅▅▅▄▄▄▄▃▃▃▃▃▂▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁
wandb:     t_F1 ▁▂▂▂▃▃▄▄▄▄▄▅▅▅▅▅▆▆▆▆▆▆▆▇▆▆▇▇█▇▇▇▇█▇█▇███
wandb:   t_loss ███▇▇▇▇▇▇▆▆▆▆▅▅▅▅▅▄▄▄▄▄▃▃▄▃▃▃▃▂▃▂▂▂▂▂▂▁▁
wandb: 
wandb: Run summary:
wandb:     e_F1 58.67743
wandb:   e_loss 0.97407
wandb:     t_F1 66.12204
wandb:   t_loss 0.84881
wandb: 
wandb: Synced 4 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Synced sunny-terrain-2: https://wandb.ai/yinanazhou/xl_512_bs_8_lr_1e06_es_3_lc_True_nr_True_sr_True_stem_False_lemma_True_repeat_2_fold_2/runs/pa0q05fv
wandb: Find logs at: ./wandb/run-20220331_093309-pa0q05fv/logs/debug.log
wandb: 

wandb: wandb version 0.12.11 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
2022-03-31 10:54:51.274396: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1
wandb: Tracking run with wandb version 0.12.5
wandb: Syncing run true-wood-2
wandb: ⭐️ View project at https://wandb.ai/yinanazhou/xl_512_bs_8_lr_1e06_es_3_lc_True_nr_True_sr_True_stem_False_lemma_True_repeat_3_fold_1
wandb: 🚀 View run at https://wandb.ai/yinanazhou/xl_512_bs_8_lr_1e06_es_3_lc_True_nr_True_sr_True_stem_False_lemma_True_repeat_3_fold_1/runs/36kdajvv
wandb: Run data is saved locally in /project/6002780/yinan/Thesis_MER_Lyrics/lyric-emotion/wandb/run-20220331_105448-36kdajvv
wandb: Run `wandb offline` to turn off syncing.

Validation loss decreased (inf --> 1.396647).  Saving model ...
Validation loss decreased (1.396647 --> 1.388341).  Saving model ...
Validation loss decreased (1.388341 --> 1.381337).  Saving model ...
Validation loss decreased (1.381337 --> 1.375930).  Saving model ...
Validation loss decreased (1.375930 --> 1.371183).  Saving model ...
Validation loss decreased (1.371183 --> 1.367058).  Saving model ...
Validation loss decreased (1.367058 --> 1.363295).  Saving model ...
Validation loss decreased (1.363295 --> 1.359827).  Saving model ...
Validation loss decreased (1.359827 --> 1.355861).  Saving model ...
Validation loss decreased (1.355861 --> 1.352079).  Saving model ...
Validation loss decreased (1.352079 --> 1.347951).  Saving model ...
Validation loss decreased (1.347951 --> 1.344002).  Saving model ...
Validation loss decreased (1.344002 --> 1.340077).  Saving model ...
Validation loss decreased (1.340077 --> 1.336354).  Saving model ...
Validation loss decreased (1.336354 --> 1.331639).  Saving model ...
Validation loss decreased (1.331639 --> 1.327705).  Saving model ...
Validation loss decreased (1.327705 --> 1.323385).  Saving model ...
Validation loss decreased (1.323385 --> 1.319349).  Saving model ...
Validation loss decreased (1.319349 --> 1.315046).  Saving model ...
Validation loss decreased (1.315046 --> 1.310778).  Saving model ...
Validation loss decreased (1.310778 --> 1.306049).  Saving model ...
Validation loss decreased (1.306049 --> 1.300718).  Saving model ...
Validation loss decreased (1.300718 --> 1.295507).  Saving model ...
Validation loss decreased (1.295507 --> 1.289534).  Saving model ...
Validation loss decreased (1.289534 --> 1.284459).  Saving model ...
Validation loss decreased (1.284459 --> 1.279786).  Saving model ...
Validation loss decreased (1.279786 --> 1.274794).  Saving model ...
Validation loss decreased (1.274794 --> 1.268527).  Saving model ...
Validation loss decreased (1.268527 --> 1.262077).  Saving model ...
Validation loss decreased (1.262077 --> 1.257401).  Saving model ...
Validation loss decreased (1.257401 --> 1.249480).  Saving model ...
Validation loss decreased (1.249480 --> 1.243269).  Saving model ...
Validation loss decreased (1.243269 --> 1.238591).  Saving model ...
Validation loss decreased (1.238591 --> 1.233660).  Saving model ...
Validation loss decreased (1.233660 --> 1.227197).  Saving model ...
Validation loss decreased (1.227197 --> 1.220813).  Saving model ...
Validation loss decreased (1.220813 --> 1.215251).  Saving model ...
Validation loss decreased (1.215251 --> 1.208863).  Saving model ...
Validation loss decreased (1.208863 --> 1.204240).  Saving model ...
Validation loss decreased (1.204240 --> 1.197304).  Saving model ...
Validation loss decreased (1.197304 --> 1.190995).  Saving model ...
Validation loss decreased (1.190995 --> 1.186160).  Saving model ...
Validation loss decreased (1.186160 --> 1.180218).  Saving model ...
Validation loss decreased (1.180218 --> 1.175252).  Saving model ...
Validation loss decreased (1.175252 --> 1.168968).  Saving model ...
Validation loss decreased (1.168968 --> 1.162763).  Saving model ...
Validation loss decreased (1.162763 --> 1.160153).  Saving model ...
Validation loss decreased (1.160153 --> 1.154986).  Saving model ...
Validation loss decreased (1.154986 --> 1.153122).  Saving model ...
Validation loss decreased (1.153122 --> 1.148179).  Saving model ...
Validation loss decreased (1.148179 --> 1.144348).  Saving model ...
Validation loss decreased (1.144348 --> 1.139074).  Saving model ...
Validation loss decreased (1.139074 --> 1.134166).  Saving model ...
Validation loss decreased (1.134166 --> 1.132373).  Saving model ...
Validation loss decreased (1.132373 --> 1.127087).  Saving model ...
Validation loss decreased (1.127087 --> 1.124558).  Saving model ...
Validation loss decreased (1.124558 --> 1.121740).  Saving model ...
Validation loss decreased (1.121740 --> 1.116671).  Saving model ...
Validation loss decreased (1.116671 --> 1.112319).  Saving model ...
EarlyStopping counter: 1 out of 3.0
Validation loss decreased (1.112319 --> 1.107229).  Saving model ...
Validation loss decreased (1.107229 --> 1.103093).  Saving model ...
Validation loss decreased (1.103093 --> 1.098520).  Saving model ...
Validation loss decreased (1.098520 --> 1.096558).  Saving model ...
Validation loss decreased (1.096558 --> 1.093440).  Saving model ...
Validation loss decreased (1.093440 --> 1.091135).  Saving model ...
Validation loss decreased (1.091135 --> 1.087099).  Saving model ...
Validation loss decreased (1.087099 --> 1.085059).  Saving model ...
Validation loss decreased (1.085059 --> 1.080546).  Saving model ...
Validation loss decreased (1.080546 --> 1.076986).  Saving model ...
Validation loss decreased (1.076986 --> 1.074929).  Saving model ...
Validation loss decreased (1.074929 --> 1.071573).  Saving model ...
Validation loss decreased (1.071573 --> 1.065940).  Saving model ...
Validation loss decreased (1.065940 --> 1.062989).  Saving model ...
Validation loss decreased (1.062989 --> 1.060297).  Saving model ...
Validation loss decreased (1.060297 --> 1.060045).  Saving model ...
Validation loss decreased (1.060045 --> 1.056220).  Saving model ...
Validation loss decreased (1.056220 --> 1.054653).  Saving model ...
Validation loss decreased (1.054653 --> 1.050088).  Saving model ...
Validation loss decreased (1.050088 --> 1.048923).  Saving model ...
Validation loss decreased (1.048923 --> 1.044115).  Saving model ...
Validation loss decreased (1.044115 --> 1.042914).  Saving model ...
Validation loss decreased (1.042914 --> 1.041598).  Saving model ...
Validation loss decreased (1.041598 --> 1.037515).  Saving model ...
Validation loss decreased (1.037515 --> 1.033519).  Saving model ...
Validation loss decreased (1.033519 --> 1.030531).  Saving model ...
Validation loss decreased (1.030531 --> 1.030514).  Saving model ...
Validation loss decreased (1.030514 --> 1.030040).  Saving model ...
Validation loss decreased (1.030040 --> 1.026872).  Saving model ...
EarlyStopping counter: 1 out of 3.0
Validation loss decreased (1.026872 --> 1.026649).  Saving model ...
Validation loss decreased (1.026649 --> 1.024327).  Saving model ...
EarlyStopping counter: 1 out of 3.0
Validation loss decreased (1.024327 --> 1.021804).  Saving model ...
Validation loss decreased (1.021804 --> 1.020007).  Saving model ...
Validation loss decreased (1.020007 --> 1.016970).  Saving model ...
Validation loss decreased (1.016970 --> 1.012900).  Saving model ...
EarlyStopping counter: 1 out of 3.0
Validation loss decreased (1.012900 --> 1.010915).  Saving model ...
Validation loss decreased (1.010915 --> 1.009919).  Saving model ...
Validation loss decreased (1.009919 --> 1.007849).  Saving model ...
EarlyStopping counter: 1 out of 3.0
Validation loss decreased (1.007849 --> 1.004368).  Saving model ...
Validation loss decreased (1.004368 --> 1.003317).  Saving model ...
Validation loss decreased (1.003317 --> 1.002783).  Saving model ...
Validation loss decreased (1.002783 --> 0.997720).  Saving model ...
Validation loss decreased (0.997720 --> 0.997583).  Saving model ...
Validation loss decreased (0.997583 --> 0.997089).  Saving model ...
Validation loss decreased (0.997089 --> 0.993893).  Saving model ...
EarlyStopping counter: 1 out of 3.0
EarlyStopping counter: 2 out of 3.0
EarlyStopping counter: 3 out of 3.0
/localscratch/yinan.29785235.0/env/lib/python3.7/site-packages/torch/nn/functional.py:1794: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.
  warnings.warn("nn.functional.tanh is deprecated. Use torch.tanh instead.")
wandb: Waiting for W&B process to finish, PID 67456... (success).
wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: \ 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: | 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: / 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: \ 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: | 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: / 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: \ 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: | 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: / 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: \ 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: | 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb:                                                                                
wandb: Run history:
wandb:     e_F1 ▁▂▄▄▅▅▅▅▆▆▆▆▆▆▆▇▇▇▆▇▇▇▇▇▇▇▇▇▇▇▇▇████████
wandb:   e_loss ██▇▇▇▇▇▇▆▆▆▅▅▅▅▄▄▄▄▃▃▃▃▃▃▂▂▂▂▂▂▂▂▁▁▁▁▁▁▁
wandb:     t_F1 ▁▂▂▃▂▄▄▃▄▄▄▄▅▅▅▅▅▆▆▅▆▆▆▆▇▇▇▇▇▆▇▇▇▇███▇█▇
wandb:   t_loss ███▇▇▇▇▇▆▆▆▆▆▅▅▅▅▅▄▄▄▄▄▄▃▃▃▃▃▃▂▂▂▂▂▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:     e_F1 56.4391
wandb:   e_loss 0.99738
wandb:     t_F1 66.34006
wandb:   t_loss 0.86488
wandb: 
wandb: Synced 4 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Synced true-wood-2: https://wandb.ai/yinanazhou/xl_512_bs_8_lr_1e06_es_3_lc_True_nr_True_sr_True_stem_False_lemma_True_repeat_3_fold_1/runs/36kdajvv
wandb: Find logs at: ./wandb/run-20220331_105448-36kdajvv/logs/debug.log
wandb: 

wandb: wandb version 0.12.11 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
2022-03-31 12:09:27.832806: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1
wandb: Tracking run with wandb version 0.12.5
wandb: Syncing run hopeful-disco-2
wandb: ⭐️ View project at https://wandb.ai/yinanazhou/xl_512_bs_8_lr_1e06_es_3_lc_True_nr_True_sr_True_stem_False_lemma_True_repeat_3_fold_2
wandb: 🚀 View run at https://wandb.ai/yinanazhou/xl_512_bs_8_lr_1e06_es_3_lc_True_nr_True_sr_True_stem_False_lemma_True_repeat_3_fold_2/runs/1vyc8p8b
wandb: Run data is saved locally in /project/6002780/yinan/Thesis_MER_Lyrics/lyric-emotion/wandb/run-20220331_120924-1vyc8p8b
wandb: Run `wandb offline` to turn off syncing.

Validation loss decreased (inf --> 1.395030).  Saving model ...
Validation loss decreased (1.395030 --> 1.388928).  Saving model ...
Validation loss decreased (1.388928 --> 1.384075).  Saving model ...
Validation loss decreased (1.384075 --> 1.378541).  Saving model ...
Validation loss decreased (1.378541 --> 1.373749).  Saving model ...
Validation loss decreased (1.373749 --> 1.369658).  Saving model ...
Validation loss decreased (1.369658 --> 1.365559).  Saving model ...
Validation loss decreased (1.365559 --> 1.361126).  Saving model ...
Validation loss decreased (1.361126 --> 1.356697).  Saving model ...
Validation loss decreased (1.356697 --> 1.352334).  Saving model ...
Validation loss decreased (1.352334 --> 1.348182).  Saving model ...
Validation loss decreased (1.348182 --> 1.343696).  Saving model ...
Validation loss decreased (1.343696 --> 1.339292).  Saving model ...
Validation loss decreased (1.339292 --> 1.333908).  Saving model ...
Validation loss decreased (1.333908 --> 1.328551).  Saving model ...
Validation loss decreased (1.328551 --> 1.323077).  Saving model ...
Validation loss decreased (1.323077 --> 1.317382).  Saving model ...
Validation loss decreased (1.317382 --> 1.311704).  Saving model ...
Validation loss decreased (1.311704 --> 1.304815).  Saving model ...
Validation loss decreased (1.304815 --> 1.298920).  Saving model ...
Validation loss decreased (1.298920 --> 1.292855).  Saving model ...
Validation loss decreased (1.292855 --> 1.285752).  Saving model ...
Validation loss decreased (1.285752 --> 1.279247).  Saving model ...
Validation loss decreased (1.279247 --> 1.272857).  Saving model ...
Validation loss decreased (1.272857 --> 1.265072).  Saving model ...
Validation loss decreased (1.265072 --> 1.257889).  Saving model ...
Validation loss decreased (1.257889 --> 1.249601).  Saving model ...
Validation loss decreased (1.249601 --> 1.241041).  Saving model ...
Validation loss decreased (1.241041 --> 1.233414).  Saving model ...
Validation loss decreased (1.233414 --> 1.225486).  Saving model ...
Validation loss decreased (1.225486 --> 1.217366).  Saving model ...
Validation loss decreased (1.217366 --> 1.209482).  Saving model ...
Validation loss decreased (1.209482 --> 1.201643).  Saving model ...
Validation loss decreased (1.201643 --> 1.193885).  Saving model ...
Validation loss decreased (1.193885 --> 1.186275).  Saving model ...
Validation loss decreased (1.186275 --> 1.180768).  Saving model ...
Validation loss decreased (1.180768 --> 1.175924).  Saving model ...
Validation loss decreased (1.175924 --> 1.169338).  Saving model ...
Validation loss decreased (1.169338 --> 1.162794).  Saving model ...
Validation loss decreased (1.162794 --> 1.157921).  Saving model ...
Validation loss decreased (1.157921 --> 1.152267).  Saving model ...
Validation loss decreased (1.152267 --> 1.145799).  Saving model ...
Validation loss decreased (1.145799 --> 1.141003).  Saving model ...
Validation loss decreased (1.141003 --> 1.136305).  Saving model ...
Validation loss decreased (1.136305 --> 1.130615).  Saving model ...
Validation loss decreased (1.130615 --> 1.126953).  Saving model ...
Validation loss decreased (1.126953 --> 1.122580).  Saving model ...
Validation loss decreased (1.122580 --> 1.115544).  Saving model ...
Validation loss decreased (1.115544 --> 1.111111).  Saving model ...
Validation loss decreased (1.111111 --> 1.107688).  Saving model ...
Validation loss decreased (1.107688 --> 1.102114).  Saving model ...
Validation loss decreased (1.102114 --> 1.097748).  Saving model ...
Validation loss decreased (1.097748 --> 1.093137).  Saving model ...
Validation loss decreased (1.093137 --> 1.089312).  Saving model ...
Validation loss decreased (1.089312 --> 1.086120).  Saving model ...
Validation loss decreased (1.086120 --> 1.081658).  Saving model ...
Validation loss decreased (1.081658 --> 1.077338).  Saving model ...
Validation loss decreased (1.077338 --> 1.073232).  Saving model ...
Validation loss decreased (1.073232 --> 1.069187).  Saving model ...
Validation loss decreased (1.069187 --> 1.064228).  Saving model ...
Validation loss decreased (1.064228 --> 1.060752).  Saving model ...
Validation loss decreased (1.060752 --> 1.057708).  Saving model ...
Validation loss decreased (1.057708 --> 1.053973).  Saving model ...
Validation loss decreased (1.053973 --> 1.050342).  Saving model ...
Validation loss decreased (1.050342 --> 1.046793).  Saving model ...
Validation loss decreased (1.046793 --> 1.043709).  Saving model ...
Validation loss decreased (1.043709 --> 1.039539).  Saving model ...
Validation loss decreased (1.039539 --> 1.036492).  Saving model ...
Validation loss decreased (1.036492 --> 1.033901).  Saving model ...
Validation loss decreased (1.033901 --> 1.030974).  Saving model ...
Validation loss decreased (1.030974 --> 1.027724).  Saving model ...
Validation loss decreased (1.027724 --> 1.024520).  Saving model ...
Validation loss decreased (1.024520 --> 1.021255).  Saving model ...
Validation loss decreased (1.021255 --> 1.018069).  Saving model ...
Validation loss decreased (1.018069 --> 1.016028).  Saving model ...
Validation loss decreased (1.016028 --> 1.013420).  Saving model ...
Validation loss decreased (1.013420 --> 1.010756).  Saving model ...
Validation loss decreased (1.010756 --> 1.008209).  Saving model ...
Validation loss decreased (1.008209 --> 1.005837).  Saving model ...
Validation loss decreased (1.005837 --> 1.003512).  Saving model ...
Validation loss decreased (1.003512 --> 1.002917).  Saving model ...
Validation loss decreased (1.002917 --> 1.000939).  Saving model ...
Validation loss decreased (1.000939 --> 0.998721).  Saving model ...
Validation loss decreased (0.998721 --> 0.997190).  Saving model ...
Validation loss decreased (0.997190 --> 0.995189).  Saving model ...
Validation loss decreased (0.995189 --> 0.993648).  Saving model ...
Validation loss decreased (0.993648 --> 0.991403).  Saving model ...
Validation loss decreased (0.991403 --> 0.988263).  Saving model ...
Validation loss decreased (0.988263 --> 0.986449).  Saving model ...
Validation loss decreased (0.986449 --> 0.984001).  Saving model ...
Validation loss decreased (0.984001 --> 0.982532).  Saving model ...
Validation loss decreased (0.982532 --> 0.980023).  Saving model ...
Validation loss decreased (0.980023 --> 0.977067).  Saving model ...
Validation loss decreased (0.977067 --> 0.975593).  Saving model ...
Validation loss decreased (0.975593 --> 0.974885).  Saving model ...
Validation loss decreased (0.974885 --> 0.973744).  Saving model ...
Validation loss decreased (0.973744 --> 0.971043).  Saving model ...
Validation loss decreased (0.971043 --> 0.968800).  Saving model ...
Validation loss decreased (0.968800 --> 0.967040).  Saving model ...
EarlyStopping counter: 1 out of 3.0
EarlyStopping counter: 2 out of 3.0
Validation loss decreased (0.967040 --> 0.965441).  Saving model ...
Validation loss decreased (0.965441 --> 0.964103).  Saving model ...
Validation loss decreased (0.964103 --> 0.961011).  Saving model ...
Validation loss decreased (0.961011 --> 0.959199).  Saving model ...
Validation loss decreased (0.959199 --> 0.958800).  Saving model ...
Validation loss decreased (0.958800 --> 0.955660).  Saving model ...
Validation loss decreased (0.955660 --> 0.955033).  Saving model ...
Validation loss decreased (0.955033 --> 0.954241).  Saving model ...
Validation loss decreased (0.954241 --> 0.953918).  Saving model ...
Validation loss decreased (0.953918 --> 0.953762).  Saving model ...
Validation loss decreased (0.953762 --> 0.952474).  Saving model ...
Validation loss decreased (0.952474 --> 0.950875).  Saving model ...
Validation loss decreased (0.950875 --> 0.949289).  Saving model ...
Validation loss decreased (0.949289 --> 0.947582).  Saving model ...
Validation loss decreased (0.947582 --> 0.947119).  Saving model ...
Validation loss decreased (0.947119 --> 0.946014).  Saving model ...
Validation loss decreased (0.946014 --> 0.944425).  Saving model ...
Validation loss decreased (0.944425 --> 0.942123).  Saving model ...
Validation loss decreased (0.942123 --> 0.941409).  Saving model ...
Validation loss decreased (0.941409 --> 0.940619).  Saving model ...
Validation loss decreased (0.940619 --> 0.938933).  Saving model ...
EarlyStopping counter: 1 out of 3.0
EarlyStopping counter: 2 out of 3.0
EarlyStopping counter: 3 out of 3.0
/localscratch/yinan.29785235.0/env/lib/python3.7/site-packages/torch/nn/functional.py:1794: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.
  warnings.warn("nn.functional.tanh is deprecated. Use torch.tanh instead.")
wandb: Waiting for W&B process to finish, PID 71497... (success).
wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: \ 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: | 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: / 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: \ 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: | 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: / 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: \ 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: | 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: / 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: \ 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb:                                                                                
wandb: Run history:
wandb:     e_F1 ▁▂▃▄▄▅▅▅▆▆▆▆▆▆▆▇▆▇▇▇▇▇▇▇▇▇▇▇▇███████████
wandb:   e_loss ███▇▇▇▇▆▆▆▅▅▄▄▄▄▃▃▃▃▃▃▂▂▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁
wandb:     t_F1 ▁▁▂▂▂▃▄▄▄▄▅▅▆▅▅▆▆▆▆▆▆▆▇▆▇▇▇▇▇▇▇▇▇▇█▇▇███
wandb:   t_loss ███▇▇▇▇▇▆▆▆▆▅▅▅▅▅▄▄▄▄▄▃▃▃▃▃▂▂▂▂▂▂▂▂▂▂▁▂▁
wandb: 
wandb: Run summary:
wandb:     e_F1 60.24336
wandb:   e_loss 0.93921
wandb:     t_F1 67.90391
wandb:   t_loss 0.81965
wandb: 
wandb: Synced 4 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Synced hopeful-disco-2: https://wandb.ai/yinanazhou/xl_512_bs_8_lr_1e06_es_3_lc_True_nr_True_sr_True_stem_False_lemma_True_repeat_3_fold_2/runs/1vyc8p8b
wandb: Find logs at: ./wandb/run-20220331_120924-1vyc8p8b/logs/debug.log
wandb: 

wandb: wandb version 0.12.11 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
2022-03-31 13:32:08.502821: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1
wandb: Tracking run with wandb version 0.12.5
wandb: Syncing run easy-eon-2
wandb: ⭐️ View project at https://wandb.ai/yinanazhou/xl_512_bs_8_lr_1e06_es_3_lc_True_nr_True_sr_True_stem_False_lemma_True_repeat_4_fold_1
wandb: 🚀 View run at https://wandb.ai/yinanazhou/xl_512_bs_8_lr_1e06_es_3_lc_True_nr_True_sr_True_stem_False_lemma_True_repeat_4_fold_1/runs/26kqewe8
wandb: Run data is saved locally in /project/6002780/yinan/Thesis_MER_Lyrics/lyric-emotion/wandb/run-20220331_133205-26kqewe8
wandb: Run `wandb offline` to turn off syncing.

Validation loss decreased (inf --> 1.402031).  Saving model ...
Validation loss decreased (1.402031 --> 1.393583).  Saving model ...
Validation loss decreased (1.393583 --> 1.386645).  Saving model ...
Validation loss decreased (1.386645 --> 1.381292).  Saving model ...
Validation loss decreased (1.381292 --> 1.376573).  Saving model ...
Validation loss decreased (1.376573 --> 1.372664).  Saving model ...
Validation loss decreased (1.372664 --> 1.368572).  Saving model ...
Validation loss decreased (1.368572 --> 1.364745).  Saving model ...
Validation loss decreased (1.364745 --> 1.360811).  Saving model ...
Validation loss decreased (1.360811 --> 1.357006).  Saving model ...
Validation loss decreased (1.357006 --> 1.353278).  Saving model ...
Validation loss decreased (1.353278 --> 1.349237).  Saving model ...
Validation loss decreased (1.349237 --> 1.345116).  Saving model ...
Validation loss decreased (1.345116 --> 1.341432).  Saving model ...
Validation loss decreased (1.341432 --> 1.337257).  Saving model ...
Validation loss decreased (1.337257 --> 1.333017).  Saving model ...
Validation loss decreased (1.333017 --> 1.328703).  Saving model ...
Validation loss decreased (1.328703 --> 1.324062).  Saving model ...
Validation loss decreased (1.324062 --> 1.319541).  Saving model ...
Validation loss decreased (1.319541 --> 1.314267).  Saving model ...
Validation loss decreased (1.314267 --> 1.308690).  Saving model ...
Validation loss decreased (1.308690 --> 1.303609).  Saving model ...
Validation loss decreased (1.303609 --> 1.298094).  Saving model ...
Validation loss decreased (1.298094 --> 1.291817).  Saving model ...
Validation loss decreased (1.291817 --> 1.285723).  Saving model ...
Validation loss decreased (1.285723 --> 1.280086).  Saving model ...
Validation loss decreased (1.280086 --> 1.273608).  Saving model ...
Validation loss decreased (1.273608 --> 1.266847).  Saving model ...
Validation loss decreased (1.266847 --> 1.261015).  Saving model ...
Validation loss decreased (1.261015 --> 1.255080).  Saving model ...
Validation loss decreased (1.255080 --> 1.249156).  Saving model ...
Validation loss decreased (1.249156 --> 1.242503).  Saving model ...
Validation loss decreased (1.242503 --> 1.235648).  Saving model ...
Validation loss decreased (1.235648 --> 1.228690).  Saving model ...
Validation loss decreased (1.228690 --> 1.221979).  Saving model ...
Validation loss decreased (1.221979 --> 1.216453).  Saving model ...
Validation loss decreased (1.216453 --> 1.210452).  Saving model ...
Validation loss decreased (1.210452 --> 1.203998).  Saving model ...
Validation loss decreased (1.203998 --> 1.198288).  Saving model ...
Validation loss decreased (1.198288 --> 1.192151).  Saving model ...
Validation loss decreased (1.192151 --> 1.186943).  Saving model ...
Validation loss decreased (1.186943 --> 1.181878).  Saving model ...
Validation loss decreased (1.181878 --> 1.177181).  Saving model ...
Validation loss decreased (1.177181 --> 1.172263).  Saving model ...
Validation loss decreased (1.172263 --> 1.167576).  Saving model ...
Validation loss decreased (1.167576 --> 1.163663).  Saving model ...
Validation loss decreased (1.163663 --> 1.159349).  Saving model ...
Validation loss decreased (1.159349 --> 1.155279).  Saving model ...
Validation loss decreased (1.155279 --> 1.151209).  Saving model ...
Validation loss decreased (1.151209 --> 1.147148).  Saving model ...
Validation loss decreased (1.147148 --> 1.142913).  Saving model ...
Validation loss decreased (1.142913 --> 1.138971).  Saving model ...
Validation loss decreased (1.138971 --> 1.135503).  Saving model ...
Validation loss decreased (1.135503 --> 1.131435).  Saving model ...
Validation loss decreased (1.131435 --> 1.127716).  Saving model ...
Validation loss decreased (1.127716 --> 1.124179).  Saving model ...
Validation loss decreased (1.124179 --> 1.119618).  Saving model ...
Validation loss decreased (1.119618 --> 1.116028).  Saving model ...
Validation loss decreased (1.116028 --> 1.112985).  Saving model ...
Validation loss decreased (1.112985 --> 1.110337).  Saving model ...
Validation loss decreased (1.110337 --> 1.107154).  Saving model ...
Validation loss decreased (1.107154 --> 1.103590).  Saving model ...
Validation loss decreased (1.103590 --> 1.100819).  Saving model ...
Validation loss decreased (1.100819 --> 1.097801).  Saving model ...
Validation loss decreased (1.097801 --> 1.094563).  Saving model ...
Validation loss decreased (1.094563 --> 1.091443).  Saving model ...
Validation loss decreased (1.091443 --> 1.089166).  Saving model ...
Validation loss decreased (1.089166 --> 1.086229).  Saving model ...
Validation loss decreased (1.086229 --> 1.084615).  Saving model ...
Validation loss decreased (1.084615 --> 1.081230).  Saving model ...
Validation loss decreased (1.081230 --> 1.078205).  Saving model ...
Validation loss decreased (1.078205 --> 1.075867).  Saving model ...
Validation loss decreased (1.075867 --> 1.072089).  Saving model ...
Validation loss decreased (1.072089 --> 1.071150).  Saving model ...
Validation loss decreased (1.071150 --> 1.068785).  Saving model ...
Validation loss decreased (1.068785 --> 1.066081).  Saving model ...
Validation loss decreased (1.066081 --> 1.064496).  Saving model ...
Validation loss decreased (1.064496 --> 1.061870).  Saving model ...
Validation loss decreased (1.061870 --> 1.059516).  Saving model ...
Validation loss decreased (1.059516 --> 1.057595).  Saving model ...
Validation loss decreased (1.057595 --> 1.056339).  Saving model ...
Validation loss decreased (1.056339 --> 1.053877).  Saving model ...
Validation loss decreased (1.053877 --> 1.051673).  Saving model ...
Validation loss decreased (1.051673 --> 1.049811).  Saving model ...
Validation loss decreased (1.049811 --> 1.047730).  Saving model ...
Validation loss decreased (1.047730 --> 1.045059).  Saving model ...
EarlyStopping counter: 1 out of 3.0
Validation loss decreased (1.045059 --> 1.044149).  Saving model ...
Validation loss decreased (1.044149 --> 1.041626).  Saving model ...
Validation loss decreased (1.041626 --> 1.039852).  Saving model ...
Validation loss decreased (1.039852 --> 1.039364).  Saving model ...
Validation loss decreased (1.039364 --> 1.039340).  Saving model ...
Validation loss decreased (1.039340 --> 1.038837).  Saving model ...
Validation loss decreased (1.038837 --> 1.035851).  Saving model ...
Validation loss decreased (1.035851 --> 1.033777).  Saving model ...
Validation loss decreased (1.033777 --> 1.032376).  Saving model ...
Validation loss decreased (1.032376 --> 1.031373).  Saving model ...
Validation loss decreased (1.031373 --> 1.028718).  Saving model ...
Validation loss decreased (1.028718 --> 1.027543).  Saving model ...
Validation loss decreased (1.027543 --> 1.026074).  Saving model ...
Validation loss decreased (1.026074 --> 1.022900).  Saving model ...
Validation loss decreased (1.022900 --> 1.021189).  Saving model ...
Validation loss decreased (1.021189 --> 1.018945).  Saving model ...
EarlyStopping counter: 1 out of 3.0
EarlyStopping counter: 2 out of 3.0
Validation loss decreased (1.018945 --> 1.017624).  Saving model ...
EarlyStopping counter: 1 out of 3.0
Validation loss decreased (1.017624 --> 1.015880).  Saving model ...
Validation loss decreased (1.015880 --> 1.013883).  Saving model ...
EarlyStopping counter: 1 out of 3.0
Validation loss decreased (1.013883 --> 1.013865).  Saving model ...
Validation loss decreased (1.013865 --> 1.011522).  Saving model ...
EarlyStopping counter: 1 out of 3.0
Validation loss decreased (1.011522 --> 1.011269).  Saving model ...
Validation loss decreased (1.011269 --> 1.008328).  Saving model ...
Validation loss decreased (1.008328 --> 1.004186).  Saving model ...
EarlyStopping counter: 1 out of 3.0
Validation loss decreased (1.004186 --> 1.003605).  Saving model ...
Validation loss decreased (1.003605 --> 1.003582).  Saving model ...
EarlyStopping counter: 1 out of 3.0
EarlyStopping counter: 2 out of 3.0
EarlyStopping counter: 3 out of 3.0
/localscratch/yinan.29785235.0/env/lib/python3.7/site-packages/torch/nn/functional.py:1794: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.
  warnings.warn("nn.functional.tanh is deprecated. Use torch.tanh instead.")
wandb: Waiting for W&B process to finish, PID 75946... (success).
wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: \ 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: | 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: / 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: \ 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: | 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: / 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: \ 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: | 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: / 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb:                                                                                
wandb: Run history:
wandb:     e_F1 ▁▂▃▄▄▄▅▅▅▅▆▆▆▆▆▆▇▆▆▇▇▇▇▇▇▇▇▇▇▇▇▇████████
wandb:   e_loss ██▇▇▇▇▇▆▆▆▅▅▅▄▄▄▄▃▃▃▃▃▂▂▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁
wandb:     t_F1 ▁▂▂▃▂▃▄▃▄▄▅▅▅▅▅▆▆▆▆▆▆▆▇▇▇▇▇▇▇▇██████████
wandb:   t_loss ██▇▇▇▇▇▇▆▆▆▆▅▅▅▅▅▄▄▄▄▄▃▃▃▃▃▂▂▂▂▂▂▂▂▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:     e_F1 56.34778
wandb:   e_loss 1.00427
wandb:     t_F1 66.96708
wandb:   t_loss 0.80076
wandb: 
wandb: Synced 4 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Synced easy-eon-2: https://wandb.ai/yinanazhou/xl_512_bs_8_lr_1e06_es_3_lc_True_nr_True_sr_True_stem_False_lemma_True_repeat_4_fold_1/runs/26kqewe8
wandb: Find logs at: ./wandb/run-20220331_133205-26kqewe8/logs/debug.log
wandb: 

wandb: wandb version 0.12.11 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
2022-03-31 14:53:11.088550: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1
wandb: Tracking run with wandb version 0.12.5
wandb: Syncing run generous-fire-2
wandb: ⭐️ View project at https://wandb.ai/yinanazhou/xl_512_bs_8_lr_1e06_es_3_lc_True_nr_True_sr_True_stem_False_lemma_True_repeat_4_fold_2
wandb: 🚀 View run at https://wandb.ai/yinanazhou/xl_512_bs_8_lr_1e06_es_3_lc_True_nr_True_sr_True_stem_False_lemma_True_repeat_4_fold_2/runs/fcy80ikd
wandb: Run data is saved locally in /project/6002780/yinan/Thesis_MER_Lyrics/lyric-emotion/wandb/run-20220331_145308-fcy80ikd
wandb: Run `wandb offline` to turn off syncing.

Validation loss decreased (inf --> 1.432886).  Saving model ...
Validation loss decreased (1.432886 --> 1.417532).  Saving model ...
Validation loss decreased (1.417532 --> 1.406227).  Saving model ...
Validation loss decreased (1.406227 --> 1.398035).  Saving model ...
Validation loss decreased (1.398035 --> 1.391320).  Saving model ...
Validation loss decreased (1.391320 --> 1.385572).  Saving model ...
Validation loss decreased (1.385572 --> 1.380144).  Saving model ...
Validation loss decreased (1.380144 --> 1.374966).  Saving model ...
Validation loss decreased (1.374966 --> 1.370133).  Saving model ...
Validation loss decreased (1.370133 --> 1.365857).  Saving model ...
Validation loss decreased (1.365857 --> 1.361486).  Saving model ...
Validation loss decreased (1.361486 --> 1.357461).  Saving model ...
Validation loss decreased (1.357461 --> 1.353243).  Saving model ...
Validation loss decreased (1.353243 --> 1.348603).  Saving model ...
Validation loss decreased (1.348603 --> 1.344067).  Saving model ...
Validation loss decreased (1.344067 --> 1.339856).  Saving model ...
Validation loss decreased (1.339856 --> 1.335074).  Saving model ...
Validation loss decreased (1.335074 --> 1.330661).  Saving model ...
Validation loss decreased (1.330661 --> 1.326353).  Saving model ...
Validation loss decreased (1.326353 --> 1.321901).  Saving model ...
Validation loss decreased (1.321901 --> 1.316054).  Saving model ...
Validation loss decreased (1.316054 --> 1.310514).  Saving model ...
Validation loss decreased (1.310514 --> 1.305521).  Saving model ...
Validation loss decreased (1.305521 --> 1.300147).  Saving model ...
Validation loss decreased (1.300147 --> 1.294628).  Saving model ...
Validation loss decreased (1.294628 --> 1.290456).  Saving model ...
Validation loss decreased (1.290456 --> 1.284911).  Saving model ...
Validation loss decreased (1.284911 --> 1.279172).  Saving model ...
Validation loss decreased (1.279172 --> 1.271643).  Saving model ...
Validation loss decreased (1.271643 --> 1.264975).  Saving model ...
Validation loss decreased (1.264975 --> 1.256334).  Saving model ...
Validation loss decreased (1.256334 --> 1.248634).  Saving model ...
Validation loss decreased (1.248634 --> 1.241858).  Saving model ...
Validation loss decreased (1.241858 --> 1.235323).  Saving model ...
Validation loss decreased (1.235323 --> 1.231339).  Saving model ...
Validation loss decreased (1.231339 --> 1.226742).  Saving model ...
Validation loss decreased (1.226742 --> 1.217309).  Saving model ...
Validation loss decreased (1.217309 --> 1.211338).  Saving model ...
Validation loss decreased (1.211338 --> 1.206411).  Saving model ...
Validation loss decreased (1.206411 --> 1.201912).  Saving model ...
Validation loss decreased (1.201912 --> 1.195671).  Saving model ...
Validation loss decreased (1.195671 --> 1.191676).  Saving model ...
Validation loss decreased (1.191676 --> 1.186235).  Saving model ...
Validation loss decreased (1.186235 --> 1.181135).  Saving model ...
Validation loss decreased (1.181135 --> 1.175974).  Saving model ...
Validation loss decreased (1.175974 --> 1.169329).  Saving model ...
Validation loss decreased (1.169329 --> 1.162787).  Saving model ...
Validation loss decreased (1.162787 --> 1.159985).  Saving model ...
Validation loss decreased (1.159985 --> 1.153036).  Saving model ...
Validation loss decreased (1.153036 --> 1.149020).  Saving model ...
Validation loss decreased (1.149020 --> 1.144595).  Saving model ...
Validation loss decreased (1.144595 --> 1.143185).  Saving model ...
Validation loss decreased (1.143185 --> 1.138488).  Saving model ...
Validation loss decreased (1.138488 --> 1.137290).  Saving model ...
Validation loss decreased (1.137290 --> 1.132595).  Saving model ...
Validation loss decreased (1.132595 --> 1.126727).  Saving model ...
Validation loss decreased (1.126727 --> 1.117792).  Saving model ...
Validation loss decreased (1.117792 --> 1.114960).  Saving model ...
Validation loss decreased (1.114960 --> 1.112253).  Saving model ...
Validation loss decreased (1.112253 --> 1.105471).  Saving model ...
EarlyStopping counter: 1 out of 3.0
Validation loss decreased (1.105471 --> 1.102721).  Saving model ...
Validation loss decreased (1.102721 --> 1.099094).  Saving model ...
EarlyStopping counter: 1 out of 3.0
Validation loss decreased (1.099094 --> 1.095014).  Saving model ...
Validation loss decreased (1.095014 --> 1.084514).  Saving model ...
EarlyStopping counter: 1 out of 3.0
Validation loss decreased (1.084514 --> 1.079194).  Saving model ...
EarlyStopping counter: 1 out of 3.0
EarlyStopping counter: 2 out of 3.0
Validation loss decreased (1.079194 --> 1.078581).  Saving model ...
Validation loss decreased (1.078581 --> 1.074967).  Saving model ...
Validation loss decreased (1.074967 --> 1.069407).  Saving model ...
Validation loss decreased (1.069407 --> 1.068901).  Saving model ...
EarlyStopping counter: 1 out of 3.0
Validation loss decreased (1.068901 --> 1.066997).  Saving model ...
Validation loss decreased (1.066997 --> 1.064197).  Saving model ...
Validation loss decreased (1.064197 --> 1.061114).  Saving model ...
Validation loss decreased (1.061114 --> 1.059469).  Saving model ...
Validation loss decreased (1.059469 --> 1.056750).  Saving model ...
Validation loss decreased (1.056750 --> 1.051764).  Saving model ...
Validation loss decreased (1.051764 --> 1.048472).  Saving model ...
Validation loss decreased (1.048472 --> 1.046619).  Saving model ...
Validation loss decreased (1.046619 --> 1.044758).  Saving model ...
Validation loss decreased (1.044758 --> 1.043030).  Saving model ...
EarlyStopping counter: 1 out of 3.0
Validation loss decreased (1.043030 --> 1.039455).  Saving model ...
EarlyStopping counter: 1 out of 3.0
Validation loss decreased (1.039455 --> 1.038604).  Saving model ...
Validation loss decreased (1.038604 --> 1.031804).  Saving model ...
EarlyStopping counter: 1 out of 3.0
Validation loss decreased (1.031804 --> 1.029118).  Saving model ...
EarlyStopping counter: 1 out of 3.0
EarlyStopping counter: 2 out of 3.0
EarlyStopping counter: 3 out of 3.0
/localscratch/yinan.29785235.0/env/lib/python3.7/site-packages/torch/nn/functional.py:1794: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.
  warnings.warn("nn.functional.tanh is deprecated. Use torch.tanh instead.")
wandb: Waiting for W&B process to finish, PID 80275... (success).
wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: \ 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: | 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: / 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: \ 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: | 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: / 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: \ 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: | 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: / 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb:                                                                                
wandb: Run history:
wandb:     e_F1 ▁▂▂▄▄▅▅▅▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇▇▇▇▇▇██████████
wandb:   e_loss ██▇▇▇▇▆▆▆▆▆▅▅▅▅▄▄▄▄▃▃▃▃▃▂▂▂▂▂▂▂▂▂▁▁▁▁▁▁▁
wandb:     t_F1 ▁▂▂▂▃▃▃▃▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▆▇▇▇▆▇▇▇▇▇████▇█
wandb:   t_loss ██▇▇▇▇▇▇▆▆▆▆▆▅▅▅▅▅▅▄▄▄▄▃▄▃▃▃▃▂▂▂▂▂▂▂▂▁▂▁
wandb: 
wandb: Run summary:
wandb:     e_F1 57.44545
wandb:   e_loss 1.02915
wandb:     t_F1 63.72104
wandb:   t_loss 0.90424
wandb: 
wandb: Synced 4 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Synced generous-fire-2: https://wandb.ai/yinanazhou/xl_512_bs_8_lr_1e06_es_3_lc_True_nr_True_sr_True_stem_False_lemma_True_repeat_4_fold_2/runs/fcy80ikd
wandb: Find logs at: ./wandb/run-20220331_145308-fcy80ikd/logs/debug.log
wandb: 

wandb: wandb version 0.12.11 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
2022-03-31 15:56:11.920092: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1
wandb: Tracking run with wandb version 0.12.5
wandb: Syncing run comic-snowflake-2
wandb: ⭐️ View project at https://wandb.ai/yinanazhou/xl_512_bs_8_lr_1e06_es_3_lc_True_nr_True_sr_True_stem_False_lemma_True_repeat_5_fold_1
wandb: 🚀 View run at https://wandb.ai/yinanazhou/xl_512_bs_8_lr_1e06_es_3_lc_True_nr_True_sr_True_stem_False_lemma_True_repeat_5_fold_1/runs/202fsgfd
wandb: Run data is saved locally in /project/6002780/yinan/Thesis_MER_Lyrics/lyric-emotion/wandb/run-20220331_155609-202fsgfd
wandb: Run `wandb offline` to turn off syncing.

Validation loss decreased (inf --> 1.393930).  Saving model ...
Validation loss decreased (1.393930 --> 1.386430).  Saving model ...
Validation loss decreased (1.386430 --> 1.380603).  Saving model ...
Validation loss decreased (1.380603 --> 1.375622).  Saving model ...
Validation loss decreased (1.375622 --> 1.371331).  Saving model ...
Validation loss decreased (1.371331 --> 1.367253).  Saving model ...
Validation loss decreased (1.367253 --> 1.363455).  Saving model ...
Validation loss decreased (1.363455 --> 1.359521).  Saving model ...
Validation loss decreased (1.359521 --> 1.355321).  Saving model ...
Validation loss decreased (1.355321 --> 1.351604).  Saving model ...
Validation loss decreased (1.351604 --> 1.347726).  Saving model ...
Validation loss decreased (1.347726 --> 1.343672).  Saving model ...
Validation loss decreased (1.343672 --> 1.339779).  Saving model ...
Validation loss decreased (1.339779 --> 1.336436).  Saving model ...
Validation loss decreased (1.336436 --> 1.331954).  Saving model ...
Validation loss decreased (1.331954 --> 1.327473).  Saving model ...
Validation loss decreased (1.327473 --> 1.322453).  Saving model ...
Validation loss decreased (1.322453 --> 1.317408).  Saving model ...
Validation loss decreased (1.317408 --> 1.311396).  Saving model ...
Validation loss decreased (1.311396 --> 1.306011).  Saving model ...
Validation loss decreased (1.306011 --> 1.300917).  Saving model ...
Validation loss decreased (1.300917 --> 1.295942).  Saving model ...
Validation loss decreased (1.295942 --> 1.290146).  Saving model ...
Validation loss decreased (1.290146 --> 1.284348).  Saving model ...
Validation loss decreased (1.284348 --> 1.278486).  Saving model ...
Validation loss decreased (1.278486 --> 1.272891).  Saving model ...
Validation loss decreased (1.272891 --> 1.266233).  Saving model ...
Validation loss decreased (1.266233 --> 1.260095).  Saving model ...
Validation loss decreased (1.260095 --> 1.254376).  Saving model ...
Validation loss decreased (1.254376 --> 1.248569).  Saving model ...
Validation loss decreased (1.248569 --> 1.242978).  Saving model ...
Validation loss decreased (1.242978 --> 1.237438).  Saving model ...
Validation loss decreased (1.237438 --> 1.231962).  Saving model ...
Validation loss decreased (1.231962 --> 1.226128).  Saving model ...
Validation loss decreased (1.226128 --> 1.221012).  Saving model ...
Validation loss decreased (1.221012 --> 1.216346).  Saving model ...
Validation loss decreased (1.216346 --> 1.209896).  Saving model ...
Validation loss decreased (1.209896 --> 1.203228).  Saving model ...
Validation loss decreased (1.203228 --> 1.198721).  Saving model ...
Validation loss decreased (1.198721 --> 1.191656).  Saving model ...
Validation loss decreased (1.191656 --> 1.185812).  Saving model ...
Validation loss decreased (1.185812 --> 1.180901).  Saving model ...
Validation loss decreased (1.180901 --> 1.178014).  Saving model ...
Validation loss decreased (1.178014 --> 1.172770).  Saving model ...
Validation loss decreased (1.172770 --> 1.167607).  Saving model ...
Validation loss decreased (1.167607 --> 1.160584).  Saving model ...
Validation loss decreased (1.160584 --> 1.155977).  Saving model ...
Validation loss decreased (1.155977 --> 1.150610).  Saving model ...
Validation loss decreased (1.150610 --> 1.145989).  Saving model ...
Validation loss decreased (1.145989 --> 1.140724).  Saving model ...
Validation loss decreased (1.140724 --> 1.136598).  Saving model ...
Validation loss decreased (1.136598 --> 1.132801).  Saving model ...
Validation loss decreased (1.132801 --> 1.127656).  Saving model ...
Validation loss decreased (1.127656 --> 1.121288).  Saving model ...
Validation loss decreased (1.121288 --> 1.115630).  Saving model ...
Validation loss decreased (1.115630 --> 1.112188).  Saving model ...
Validation loss decreased (1.112188 --> 1.106521).  Saving model ...
Validation loss decreased (1.106521 --> 1.102158).  Saving model ...
Validation loss decreased (1.102158 --> 1.098171).  Saving model ...
Validation loss decreased (1.098171 --> 1.094018).  Saving model ...
Validation loss decreased (1.094018 --> 1.090924).  Saving model ...
Validation loss decreased (1.090924 --> 1.087761).  Saving model ...
Validation loss decreased (1.087761 --> 1.085178).  Saving model ...
Validation loss decreased (1.085178 --> 1.082622).  Saving model ...
Validation loss decreased (1.082622 --> 1.077840).  Saving model ...
Validation loss decreased (1.077840 --> 1.075902).  Saving model ...
Validation loss decreased (1.075902 --> 1.071878).  Saving model ...
Validation loss decreased (1.071878 --> 1.066832).  Saving model ...
Validation loss decreased (1.066832 --> 1.062315).  Saving model ...
Validation loss decreased (1.062315 --> 1.058207).  Saving model ...
Validation loss decreased (1.058207 --> 1.054355).  Saving model ...
Validation loss decreased (1.054355 --> 1.051165).  Saving model ...
Validation loss decreased (1.051165 --> 1.048224).  Saving model ...
Validation loss decreased (1.048224 --> 1.046358).  Saving model ...
Validation loss decreased (1.046358 --> 1.043758).  Saving model ...
Validation loss decreased (1.043758 --> 1.041826).  Saving model ...
Validation loss decreased (1.041826 --> 1.037251).  Saving model ...
Validation loss decreased (1.037251 --> 1.033169).  Saving model ...
Validation loss decreased (1.033169 --> 1.029940).  Saving model ...
Validation loss decreased (1.029940 --> 1.026853).  Saving model ...
Validation loss decreased (1.026853 --> 1.023432).  Saving model ...
Validation loss decreased (1.023432 --> 1.021459).  Saving model ...
Validation loss decreased (1.021459 --> 1.020661).  Saving model ...
Validation loss decreased (1.020661 --> 1.017161).  Saving model ...
Validation loss decreased (1.017161 --> 1.012923).  Saving model ...
Validation loss decreased (1.012923 --> 1.012340).  Saving model ...
Validation loss decreased (1.012340 --> 1.006859).  Saving model ...
Validation loss decreased (1.006859 --> 1.006844).  Saving model ...
EarlyStopping counter: 1 out of 3.0
Validation loss decreased (1.006844 --> 1.004275).  Saving model ...
Validation loss decreased (1.004275 --> 1.001169).  Saving model ...
EarlyStopping counter: 1 out of 3.0
Validation loss decreased (1.001169 --> 0.997609).  Saving model ...
Validation loss decreased (0.997609 --> 0.996768).  Saving model ...
Validation loss decreased (0.996768 --> 0.994155).  Saving model ...
Validation loss decreased (0.994155 --> 0.994031).  Saving model ...
Validation loss decreased (0.994031 --> 0.992613).  Saving model ...
Validation loss decreased (0.992613 --> 0.990680).  Saving model ...
Validation loss decreased (0.990680 --> 0.987823).  Saving model ...
EarlyStopping counter: 1 out of 3.0
Validation loss decreased (0.987823 --> 0.984917).  Saving model ...
EarlyStopping counter: 1 out of 3.0
Validation loss decreased (0.984917 --> 0.981010).  Saving model ...
Validation loss decreased (0.981010 --> 0.979200).  Saving model ...
Validation loss decreased (0.979200 --> 0.978142).  Saving model ...
EarlyStopping counter: 1 out of 3.0
Validation loss decreased (0.978142 --> 0.976522).  Saving model ...
Validation loss decreased (0.976522 --> 0.973168).  Saving model ...
Validation loss decreased (0.973168 --> 0.969351).  Saving model ...
Validation loss decreased (0.969351 --> 0.968512).  Saving model ...
EarlyStopping counter: 1 out of 3.0
Validation loss decreased (0.968512 --> 0.967510).  Saving model ...
Validation loss decreased (0.967510 --> 0.966585).  Saving model ...
Validation loss decreased (0.966585 --> 0.964156).  Saving model ...
Validation loss decreased (0.964156 --> 0.962858).  Saving model ...
Validation loss decreased (0.962858 --> 0.960671).  Saving model ...
Validation loss decreased (0.960671 --> 0.959640).  Saving model ...
Validation loss decreased (0.959640 --> 0.958658).  Saving model ...
EarlyStopping counter: 1 out of 3.0
EarlyStopping counter: 2 out of 3.0
Validation loss decreased (0.958658 --> 0.957822).  Saving model ...
Validation loss decreased (0.957822 --> 0.957285).  Saving model ...
Validation loss decreased (0.957285 --> 0.956713).  Saving model ...
Validation loss decreased (0.956713 --> 0.953824).  Saving model ...
Validation loss decreased (0.953824 --> 0.953099).  Saving model ...
Validation loss decreased (0.953099 --> 0.950013).  Saving model ...
EarlyStopping counter: 1 out of 3.0
Validation loss decreased (0.950013 --> 0.949684).  Saving model ...
EarlyStopping counter: 1 out of 3.0
EarlyStopping counter: 2 out of 3.0
EarlyStopping counter: 3 out of 3.0
/localscratch/yinan.29785235.0/env/lib/python3.7/site-packages/torch/nn/functional.py:1794: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.
  warnings.warn("nn.functional.tanh is deprecated. Use torch.tanh instead.")
wandb: Waiting for W&B process to finish, PID 83666... (success).
wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: \ 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: | 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: / 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: \ 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: | 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: / 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: \ 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: | 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: / 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb:                                                                                
wandb: Run history:
wandb:     e_F1 ▁▂▃▄▄▅▅▅▅▅▆▆▆▆▆▆▇▇▇▇▇▇▇▇▇▇▇█▇███████████
wandb:   e_loss ███▇▇▇▇▆▆▆▅▅▅▅▄▄▄▄▃▃▃▃▃▂▂▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁
wandb:     t_F1 ▁▁▂▂▂▃▄▄▄▅▅▄▆▅▆▆▆▆▇▆▆▇▇▇▇▇▇▇▇▇▇▇██▇█████
wandb:   t_loss ███▇▇▇▇▇▆▆▆▆▅▅▅▅▄▄▄▄▄▃▃▃▃▃▃▂▂▂▂▂▂▁▂▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:     e_F1 58.22064
wandb:   e_loss 0.95086
wandb:     t_F1 71.40041
wandb:   t_loss 0.77235
wandb: 
wandb: Synced 4 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Synced comic-snowflake-2: https://wandb.ai/yinanazhou/xl_512_bs_8_lr_1e06_es_3_lc_True_nr_True_sr_True_stem_False_lemma_True_repeat_5_fold_1/runs/202fsgfd
wandb: Find logs at: ./wandb/run-20220331_155609-202fsgfd/logs/debug.log
wandb: 

wandb: wandb version 0.12.11 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
2022-03-31 17:23:06.743507: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1
wandb: Tracking run with wandb version 0.12.5
wandb: Syncing run faithful-wave-1
wandb: ⭐️ View project at https://wandb.ai/yinanazhou/xl_512_bs_8_lr_1e06_es_3_lc_True_nr_True_sr_True_stem_False_lemma_True_repeat_5_fold_2
wandb: 🚀 View run at https://wandb.ai/yinanazhou/xl_512_bs_8_lr_1e06_es_3_lc_True_nr_True_sr_True_stem_False_lemma_True_repeat_5_fold_2/runs/38mcgc6r
wandb: Run data is saved locally in /project/6002780/yinan/Thesis_MER_Lyrics/lyric-emotion/wandb/run-20220331_172304-38mcgc6r
wandb: Run `wandb offline` to turn off syncing.

Validation loss decreased (inf --> 1.479965).  Saving model ...
Validation loss decreased (1.479965 --> 1.446425).  Saving model ...
Validation loss decreased (1.446425 --> 1.421927).  Saving model ...
Validation loss decreased (1.421927 --> 1.403784).  Saving model ...
Validation loss decreased (1.403784 --> 1.390306).  Saving model ...
Validation loss decreased (1.390306 --> 1.380122).  Saving model ...
Validation loss decreased (1.380122 --> 1.371797).  Saving model ...
Validation loss decreased (1.371797 --> 1.365621).  Saving model ...
Validation loss decreased (1.365621 --> 1.360207).  Saving model ...
Validation loss decreased (1.360207 --> 1.355294).  Saving model ...
Validation loss decreased (1.355294 --> 1.351161).  Saving model ...
Validation loss decreased (1.351161 --> 1.347128).  Saving model ...
Validation loss decreased (1.347128 --> 1.343630).  Saving model ...
Validation loss decreased (1.343630 --> 1.339870).  Saving model ...
Validation loss decreased (1.339870 --> 1.335255).  Saving model ...
Validation loss decreased (1.335255 --> 1.331040).  Saving model ...
Validation loss decreased (1.331040 --> 1.326957).  Saving model ...
Validation loss decreased (1.326957 --> 1.322429).  Saving model ...
Validation loss decreased (1.322429 --> 1.318029).  Saving model ...
Validation loss decreased (1.318029 --> 1.313429).  Saving model ...
Validation loss decreased (1.313429 --> 1.308380).  Saving model ...
Validation loss decreased (1.308380 --> 1.304097).  Saving model ...
Validation loss decreased (1.304097 --> 1.299301).  Saving model ...
Validation loss decreased (1.299301 --> 1.293934).  Saving model ...
Validation loss decreased (1.293934 --> 1.289180).  Saving model ...
Validation loss decreased (1.289180 --> 1.283176).  Saving model ...
Validation loss decreased (1.283176 --> 1.277762).  Saving model ...
Validation loss decreased (1.277762 --> 1.271233).  Saving model ...
Validation loss decreased (1.271233 --> 1.266369).  Saving model ...
Validation loss decreased (1.266369 --> 1.261087).  Saving model ...
Validation loss decreased (1.261087 --> 1.253632).  Saving model ...
Validation loss decreased (1.253632 --> 1.246008).  Saving model ...
Validation loss decreased (1.246008 --> 1.239875).  Saving model ...
Validation loss decreased (1.239875 --> 1.232896).  Saving model ...
Validation loss decreased (1.232896 --> 1.226462).  Saving model ...
Validation loss decreased (1.226462 --> 1.219635).  Saving model ...
Validation loss decreased (1.219635 --> 1.215295).  Saving model ...
Validation loss decreased (1.215295 --> 1.210754).  Saving model ...
Validation loss decreased (1.210754 --> 1.206335).  Saving model ...
Validation loss decreased (1.206335 --> 1.200142).  Saving model ...
Validation loss decreased (1.200142 --> 1.194999).  Saving model ...
Validation loss decreased (1.194999 --> 1.187195).  Saving model ...
Validation loss decreased (1.187195 --> 1.183334).  Saving model ...
Validation loss decreased (1.183334 --> 1.180221).  Saving model ...
Validation loss decreased (1.180221 --> 1.173298).  Saving model ...
Validation loss decreased (1.173298 --> 1.167295).  Saving model ...
Validation loss decreased (1.167295 --> 1.162701).  Saving model ...
Validation loss decreased (1.162701 --> 1.159748).  Saving model ...
Validation loss decreased (1.159748 --> 1.153727).  Saving model ...
Validation loss decreased (1.153727 --> 1.149359).  Saving model ...
Validation loss decreased (1.149359 --> 1.144663).  Saving model ...
Validation loss decreased (1.144663 --> 1.143200).  Saving model ...
Validation loss decreased (1.143200 --> 1.138685).  Saving model ...
Validation loss decreased (1.138685 --> 1.135079).  Saving model ...
Validation loss decreased (1.135079 --> 1.130615).  Saving model ...
Validation loss decreased (1.130615 --> 1.125223).  Saving model ...
Validation loss decreased (1.125223 --> 1.121006).  Saving model ...
Validation loss decreased (1.121006 --> 1.115774).  Saving model ...
Validation loss decreased (1.115774 --> 1.114158).  Saving model ...
Validation loss decreased (1.114158 --> 1.110325).  Saving model ...
Validation loss decreased (1.110325 --> 1.107192).  Saving model ...
Validation loss decreased (1.107192 --> 1.102260).  Saving model ...
Validation loss decreased (1.102260 --> 1.100450).  Saving model ...
Validation loss decreased (1.100450 --> 1.095967).  Saving model ...
Validation loss decreased (1.095967 --> 1.092742).  Saving model ...
Validation loss decreased (1.092742 --> 1.088978).  Saving model ...
Validation loss decreased (1.088978 --> 1.084741).  Saving model ...
EarlyStopping counter: 1 out of 3.0
Validation loss decreased (1.084741 --> 1.080983).  Saving model ...
Validation loss decreased (1.080983 --> 1.077149).  Saving model ...
Validation loss decreased (1.077149 --> 1.072826).  Saving model ...
Validation loss decreased (1.072826 --> 1.071116).  Saving model ...
Validation loss decreased (1.071116 --> 1.067783).  Saving model ...
Validation loss decreased (1.067783 --> 1.062131).  Saving model ...
Validation loss decreased (1.062131 --> 1.058283).  Saving model ...
Validation loss decreased (1.058283 --> 1.054300).  Saving model ...
Validation loss decreased (1.054300 --> 1.050199).  Saving model ...
Validation loss decreased (1.050199 --> 1.047678).  Saving model ...
Validation loss decreased (1.047678 --> 1.045786).  Saving model ...
Validation loss decreased (1.045786 --> 1.044452).  Saving model ...
Validation loss decreased (1.044452 --> 1.038716).  Saving model ...
Validation loss decreased (1.038716 --> 1.036919).  Saving model ...
Validation loss decreased (1.036919 --> 1.036121).  Saving model ...
Validation loss decreased (1.036121 --> 1.031945).  Saving model ...
Validation loss decreased (1.031945 --> 1.031707).  Saving model ...
Validation loss decreased (1.031707 --> 1.027416).  Saving model ...
Validation loss decreased (1.027416 --> 1.025742).  Saving model ...
Validation loss decreased (1.025742 --> 1.021975).  Saving model ...
Validation loss decreased (1.021975 --> 1.018787).  Saving model ...
Validation loss decreased (1.018787 --> 1.018777).  Saving model ...
Validation loss decreased (1.018777 --> 1.017361).  Saving model ...
Validation loss decreased (1.017361 --> 1.015266).  Saving model ...
Validation loss decreased (1.015266 --> 1.011191).  Saving model ...
EarlyStopping counter: 1 out of 3.0
EarlyStopping counter: 2 out of 3.0
EarlyStopping counter: 3 out of 3.0
/localscratch/yinan.29785235.0/env/lib/python3.7/site-packages/torch/nn/functional.py:1794: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.
  warnings.warn("nn.functional.tanh is deprecated. Use torch.tanh instead.")
wandb: Waiting for W&B process to finish, PID 88338... (success).
wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: \ 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: | 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: / 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: \ 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: | 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: / 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: \ 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: | 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: / 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb:                                                                                
wandb: Run history:
wandb:     e_F1 ▁▂▂▃▄▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇▇▇▇▇▇▇█████████████
wandb:   e_loss █▇▇▆▆▆▆▆▆▅▅▅▅▅▄▄▄▄▄▃▃▃▃▃▃▂▂▂▂▂▂▂▂▁▁▁▁▁▁▁
wandb:     t_F1 ▁▁▂▂▂▃▄▃▄▄▄▄▄▅▅▅▆▅▅▆▆▆▆▆▆▇▆▇▆▇▇▇▇▇▇███▇█
wandb:   t_loss █▇▇▇▇▆▆▆▆▆▆▆▅▅▅▅▅▄▄▄▄▄▃▃▃▃▃▃▃▃▂▂▂▂▂▁▂▁▁▁
wandb: 
wandb: Run summary:
wandb:     e_F1 55.44506
wandb:   e_loss 1.01167
wandb:     t_F1 65.92472
wandb:   t_loss 0.89039
wandb: 
wandb: Synced 4 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Synced faithful-wave-1: https://wandb.ai/yinanazhou/xl_512_bs_8_lr_1e06_es_3_lc_True_nr_True_sr_True_stem_False_lemma_True_repeat_5_fold_2/runs/38mcgc6r
wandb: Find logs at: ./wandb/run-20220331_172304-38mcgc6r/logs/debug.log
wandb: 

