Unloading StdEnv/2020

Due to MODULEPATH changes, the following have been reloaded:
  1) mii/1.1.1


The following have been reloaded with a version change:
  1) python/3.8.2 => python/3.7.4

Using base prefix '/cvmfs/soft.computecanada.ca/easybuild/software/2017/Core/python/3.7.4'
New python executable in /localscratch/yinan.29351707.0/env/bin/python
Installing setuptools, pip, wheel...
done.
Ignoring pip: markers 'python_version < "3"' don't match your environment
Looking in links: /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/nix/avx2, /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/nix/generic, /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic
Collecting pip
Installing collected packages: pip
  Found existing installation: pip 19.1.1
    Uninstalling pip-19.1.1:
      Successfully uninstalled pip-19.1.1
Successfully installed pip-21.2.3+computecanada
Looking in links: /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/nix/avx2, /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/nix/generic, /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/keras-2.8.0+computecanada-py2.py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/Keras_Preprocessing-1.1.2+computecanada-py3-none-any.whl
Requirement already satisfied: matplotlib in /cvmfs/soft.computecanada.ca/easybuild/software/2017/Core/scipy-stack/2019a/lib/python3.7/site-packages (from -r requirements.txt (line 3)) (3.0.2)
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/nltk-3.6.5+computecanada-py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/scikit_learn-0.22.1+computecanada-cp37-cp37m-linux_x86_64.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/tensorboard-2.3.0+computecanada-py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/tensorboard_plugin_wit-1.7.0+computecanada-py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/tensorflow_gpu-2.3.0+computecanada-cp37-cp37m-linux_x86_64.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/tensorflow_estimator-2.3.0+computecanada-py2.py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/tokenizers-0.5.2+computecanada-cp37-cp37m-linux_x86_64.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/nix/avx2/torch-1.4.0+computecanada-cp37-cp37m-linux_x86_64.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/torchtext-0.6.0+computecanada-py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/torchvision-0.8.2+computecanada-cp37-cp37m-linux_x86_64.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/transformers-2.5.1+computecanada-py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/urllib3-1.26.7+computecanada-py2.py3-none-any.whl
ERROR: Could not find a version that satisfies the requirement regex>=2021.8.3 (from nltk) (from versions: 2018.1.10+computecanada, 2019.11.1+computecanada, 2020.11.13+computecanada)
ERROR: No matching distribution found for regex>=2021.8.3
Looking in links: /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/nix/avx2, /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/nix/generic, /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic
ERROR: Could not find a version that satisfies the requirement numpy==1.20.0+computacanada (from versions: 1.15.0+computecanada, 1.15.2+computecanada, 1.15.4+computecanada, 1.16.0+computecanada, 1.16.2+computecanada, 1.16.3+computecanada, 1.17.4+computecanada, 1.18.1+computecanada, 1.18.4+computecanada, 1.19.1+computecanada, 1.19.2+computecanada, 1.20.2+computecanada)
ERROR: No matching distribution found for numpy==1.20.0+computacanada
Looking in links: /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/nix/avx2, /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/nix/generic, /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/wandb-0.12.5+computecanada-py2.py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/GitPython-3.1.24+computecanada-py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/subprocess32-3.5.4+computecanada-py3-none-any.whl
Requirement already satisfied: requests<3,>=2.0.0 in /cvmfs/soft.computecanada.ca/easybuild/software/2017/Core/scipy-stack/2019a/lib/python3.7/site-packages (from wandb) (2.21.0)
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/PyYAML-5.3.1+computecanada-cp37-cp37m-linux_x86_64.whl
Requirement already satisfied: python-dateutil>=2.6.1 in /cvmfs/soft.computecanada.ca/easybuild/software/2017/Core/scipy-stack/2019a/lib/python3.7/site-packages (from wandb) (2.7.5)
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/yaspin-2.1.0+computecanada-py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/shortuuid-1.0.1+computecanada-py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/configparser-5.0.2+computecanada-py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/psutil-5.7.3+computecanada-cp37-cp37m-linux_x86_64.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/six-1.16.0+computecanada-py2.py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/protobuf-3.19.4+computecanada-py2.py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/pathtools-0.1.2+computecanada-py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/sentry_sdk-1.5.0+computecanada-py2.py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/docker_pycreds-0.4.0+computecanada-py2.py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/promise-2.3+computecanada-py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/click-8.0.4+computecanada-py3-none-any.whl
Requirement already satisfied: importlib-metadata in /cvmfs/soft.computecanada.ca/easybuild/software/2017/Core/scipy-stack/2019a/lib/python3.7/site-packages (from Click!=8.0.0,>=7.0->wandb) (0.8)
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/typing_extensions-4.1.1+computecanada-py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/gitdb-4.0.9+computecanada-py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/smmap-5.0.0+computecanada-py3-none-any.whl
Requirement already satisfied: urllib3<1.25,>=1.21.1 in /cvmfs/soft.computecanada.ca/easybuild/software/2017/Core/scipy-stack/2019a/lib/python3.7/site-packages (from requests<3,>=2.0.0->wandb) (1.24.1)
Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /cvmfs/soft.computecanada.ca/easybuild/software/2017/Core/scipy-stack/2019a/lib/python3.7/site-packages (from requests<3,>=2.0.0->wandb) (3.0.4)
Requirement already satisfied: certifi>=2017.4.17 in /cvmfs/soft.computecanada.ca/easybuild/software/2017/Core/scipy-stack/2019a/lib/python3.7/site-packages (from requests<3,>=2.0.0->wandb) (2018.11.29)
Requirement already satisfied: idna<2.9,>=2.5 in /cvmfs/soft.computecanada.ca/easybuild/software/2017/Core/scipy-stack/2019a/lib/python3.7/site-packages (from requests<3,>=2.0.0->wandb) (2.8)
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/termcolor-1.1.0+computecanada-py3-none-any.whl
Requirement already satisfied: zipp>=0.3.2 in /cvmfs/soft.computecanada.ca/easybuild/software/2017/Core/scipy-stack/2019a/lib/python3.7/site-packages (from importlib-metadata->Click!=8.0.0,>=7.0->wandb) (0.3.3)
Installing collected packages: smmap, typing-extensions, termcolor, six, gitdb, yaspin, subprocess32, shortuuid, sentry-sdk, PyYAML, psutil, protobuf, promise, pathtools, GitPython, docker-pycreds, configparser, Click, wandb
  Attempting uninstall: six
    Found existing installation: six 1.12.0
    Not uninstalling six at /cvmfs/soft.computecanada.ca/easybuild/software/2017/Core/scipy-stack/2019a/lib/python3.7/site-packages, outside environment /localscratch/yinan.29351707.0/env
    Can't uninstall 'six'. No files were found to uninstall.
Successfully installed Click-8.0.4+computecanada GitPython-3.1.24+computecanada PyYAML-5.3.1+computecanada configparser-5.0.2+computecanada docker-pycreds-0.4.0+computecanada gitdb-4.0.9+computecanada pathtools-0.1.2+computecanada promise-2.3+computecanada protobuf-3.19.4+computecanada psutil-5.7.3+computecanada sentry-sdk-1.5.0+computecanada shortuuid-1.0.1+computecanada six-1.16.0+computecanada smmap-5.0.0+computecanada subprocess32-3.5.4+computecanada termcolor-1.1.0+computecanada typing-extensions-4.1.1+computecanada wandb-0.12.5+computecanada yaspin-2.1.0+computecanada
Looking in links: /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/nix/avx2, /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/nix/generic, /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic
ERROR: Could not find a version that satisfies the requirement sagemaker (from versions: none)
ERROR: No matching distribution found for sagemaker
Looking in links: /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/nix/avx2, /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/nix/generic, /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/torch-1.9.1+computecanada-cp37-cp37m-linux_x86_64.whl
Requirement already satisfied: typing-extensions in /localscratch/yinan.29351707.0/env/lib/python3.7/site-packages (from torch) (4.1.1+computecanada)
Installing collected packages: torch
Successfully installed torch-1.9.1+computecanada
Looking in links: /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/nix/avx2, /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/nix/generic, /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/transformers-2.5.1+computecanada-py3-none-any.whl
Requirement already satisfied: requests in /cvmfs/soft.computecanada.ca/easybuild/software/2017/Core/scipy-stack/2019a/lib/python3.7/site-packages (from transformers==2.5.1+computecanada) (2.21.0)
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/filelock-3.4.2+computecanada-py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/regex-2020.11.13+computecanada-cp37-cp37m-linux_x86_64.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/sacremoses-0.0.49+computecanada-py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/tqdm-4.63.1+computecanada-py2.py3-none-any.whl
Requirement already satisfied: numpy in /cvmfs/soft.computecanada.ca/easybuild/software/2017/Core/scipy-stack/2019a/lib/python3.7/site-packages (from transformers==2.5.1+computecanada) (1.16.0)
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/boto3-1.21.14+computecanada-py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/sentencepiece-0.1.91+computecanada-cp37-cp37m-linux_x86_64.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/tokenizers-0.5.2+computecanada-cp37-cp37m-linux_x86_64.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/jmespath-0.10.0+computecanada-py2.py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/botocore-1.24.14+computecanada-py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/s3transfer-0.5.1+computecanada-py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/urllib3-1.26.8+computecanada-py2.py3-none-any.whl
Requirement already satisfied: python-dateutil<3.0.0,>=2.1 in /cvmfs/soft.computecanada.ca/easybuild/software/2017/Core/scipy-stack/2019a/lib/python3.7/site-packages (from botocore<1.25.0,>=1.24.14->boto3->transformers==2.5.1+computecanada) (2.7.5)
Requirement already satisfied: six>=1.5 in /localscratch/yinan.29351707.0/env/lib/python3.7/site-packages (from python-dateutil<3.0.0,>=2.1->botocore<1.25.0,>=1.24.14->boto3->transformers==2.5.1+computecanada) (1.16.0+computecanada)
Requirement already satisfied: certifi>=2017.4.17 in /cvmfs/soft.computecanada.ca/easybuild/software/2017/Core/scipy-stack/2019a/lib/python3.7/site-packages (from requests->transformers==2.5.1+computecanada) (2018.11.29)
Requirement already satisfied: idna<2.9,>=2.5 in /cvmfs/soft.computecanada.ca/easybuild/software/2017/Core/scipy-stack/2019a/lib/python3.7/site-packages (from requests->transformers==2.5.1+computecanada) (2.8)
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/requests-2.27.1+computecanada-py2.py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/charset_normalizer-2.0.12+computecanada-py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/joblib-1.1.0+computecanada-py2.py3-none-any.whl
Requirement already satisfied: click in /localscratch/yinan.29351707.0/env/lib/python3.7/site-packages (from sacremoses->transformers==2.5.1+computecanada) (8.0.4+computecanada)
Requirement already satisfied: importlib-metadata in /cvmfs/soft.computecanada.ca/easybuild/software/2017/Core/scipy-stack/2019a/lib/python3.7/site-packages (from click->sacremoses->transformers==2.5.1+computecanada) (0.8)
Requirement already satisfied: zipp>=0.3.2 in /cvmfs/soft.computecanada.ca/easybuild/software/2017/Core/scipy-stack/2019a/lib/python3.7/site-packages (from importlib-metadata->click->sacremoses->transformers==2.5.1+computecanada) (0.3.3)
Installing collected packages: urllib3, jmespath, botocore, tqdm, s3transfer, regex, joblib, charset-normalizer, tokenizers, sentencepiece, sacremoses, requests, filelock, boto3, transformers
  Attempting uninstall: urllib3
    Found existing installation: urllib3 1.24.1
    Not uninstalling urllib3 at /cvmfs/soft.computecanada.ca/easybuild/software/2017/Core/scipy-stack/2019a/lib/python3.7/site-packages, outside environment /localscratch/yinan.29351707.0/env
    Can't uninstall 'urllib3'. No files were found to uninstall.
  Attempting uninstall: requests
    Found existing installation: requests 2.21.0
    Not uninstalling requests at /cvmfs/soft.computecanada.ca/easybuild/software/2017/Core/scipy-stack/2019a/lib/python3.7/site-packages, outside environment /localscratch/yinan.29351707.0/env
    Can't uninstall 'requests'. No files were found to uninstall.
Successfully installed boto3-1.21.14+computecanada botocore-1.24.14+computecanada charset-normalizer-2.0.12+computecanada filelock-3.4.2+computecanada jmespath-0.10.0+computecanada joblib-1.1.0+computecanada regex-2020.11.13+computecanada requests-2.27.1+computecanada s3transfer-0.5.1+computecanada sacremoses-0.0.49+computecanada sentencepiece-0.1.91+computecanada tokenizers-0.5.2+computecanada tqdm-4.63.1+computecanada transformers-2.5.1+computecanada urllib3-1.26.8+computecanada
Looking in links: /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/nix/avx2, /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/nix/generic, /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/tensorflow_gpu-2.3.0+computecanada-cp37-cp37m-linux_x86_64.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/nix/avx2/h5py-2.10.0+computecanada-cp37-cp37m-linux_x86_64.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/tensorboard-2.8.0+computecanada-py3-none-any.whl
Requirement already satisfied: six>=1.12.0 in /localscratch/yinan.29351707.0/env/lib/python3.7/site-packages (from tensorflow_gpu==2.3.0+computecanada) (1.16.0+computecanada)
Requirement already satisfied: numpy<1.19.0,>=1.16.0 in /cvmfs/soft.computecanada.ca/easybuild/software/2017/Core/scipy-stack/2019a/lib/python3.7/site-packages (from tensorflow_gpu==2.3.0+computecanada) (1.16.0)
Requirement already satisfied: wheel>=0.26 in /localscratch/yinan.29351707.0/env/lib/python3.7/site-packages (from tensorflow_gpu==2.3.0+computecanada) (0.33.4)
Requirement already satisfied: termcolor>=1.1.0 in /localscratch/yinan.29351707.0/env/lib/python3.7/site-packages (from tensorflow_gpu==2.3.0+computecanada) (1.1.0+computecanada)
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/opt_einsum-3.3.0+computecanada-py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/tensorflow_estimator-2.3.0+computecanada-py2.py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/nix/generic/scipy-1.4.1+computecanada-cp37-cp37m-linux_x86_64.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/google_pasta-0.2.0+computecanada-py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/grpcio-1.38.0+computecanada-cp37-cp37m-linux_x86_64.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/gast-0.3.3+computecanada-py3-none-any.whl
Requirement already satisfied: protobuf>=3.9.2 in /localscratch/yinan.29351707.0/env/lib/python3.7/site-packages (from tensorflow_gpu==2.3.0+computecanada) (3.19.4+computecanada)
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/Keras_Preprocessing-1.1.2+computecanada-py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/astunparse-1.6.3+computecanada-py2.py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/wrapt-1.11.2+computecanada-cp37-cp37m-linux_x86_64.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/absl_py-1.0.0+computecanada-py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/tensorboard_plugin_wit-1.8.0+computecanada-py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/Werkzeug-2.0.3+computecanada-py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/Markdown-3.3.6+computecanada-py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/google_auth_oauthlib-0.4.6+computecanada-py2.py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/google_auth-2.3.3+computecanada-py2.py3-none-any.whl
Requirement already satisfied: setuptools>=41.0.0 in /localscratch/yinan.29351707.0/env/lib/python3.7/site-packages (from tensorboard<3,>=2.3.0->tensorflow_gpu==2.3.0+computecanada) (41.0.1)
Requirement already satisfied: requests<3,>=2.21.0 in /localscratch/yinan.29351707.0/env/lib/python3.7/site-packages (from tensorboard<3,>=2.3.0->tensorflow_gpu==2.3.0+computecanada) (2.27.1+computecanada)
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/tensorboard_data_server-0.6.1+computecanada-py3-none-linux_x86_64.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/cachetools-4.2.4+computecanada-py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/pyasn1_modules-0.2.8+computecanada-py2.py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/rsa-4.8+computecanada-py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/requests_oauthlib-1.3.0+computecanada-py2.py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/importlib_metadata-4.10.1+computecanada-py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/zipp-3.7.0+computecanada-py3-none-any.whl
Requirement already satisfied: typing-extensions>=3.6.4 in /localscratch/yinan.29351707.0/env/lib/python3.7/site-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard<3,>=2.3.0->tensorflow_gpu==2.3.0+computecanada) (4.1.1+computecanada)
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/pyasn1-0.4.8+computecanada-py2.py3-none-any.whl
Requirement already satisfied: urllib3<1.27,>=1.21.1 in /localscratch/yinan.29351707.0/env/lib/python3.7/site-packages (from requests<3,>=2.21.0->tensorboard<3,>=2.3.0->tensorflow_gpu==2.3.0+computecanada) (1.26.8+computecanada)
Requirement already satisfied: idna<4,>=2.5 in /cvmfs/soft.computecanada.ca/easybuild/software/2017/Core/scipy-stack/2019a/lib/python3.7/site-packages (from requests<3,>=2.21.0->tensorboard<3,>=2.3.0->tensorflow_gpu==2.3.0+computecanada) (2.8)
Requirement already satisfied: certifi>=2017.4.17 in /cvmfs/soft.computecanada.ca/easybuild/software/2017/Core/scipy-stack/2019a/lib/python3.7/site-packages (from requests<3,>=2.21.0->tensorboard<3,>=2.3.0->tensorflow_gpu==2.3.0+computecanada) (2018.11.29)
Requirement already satisfied: charset-normalizer~=2.0.0 in /localscratch/yinan.29351707.0/env/lib/python3.7/site-packages (from requests<3,>=2.21.0->tensorboard<3,>=2.3.0->tensorflow_gpu==2.3.0+computecanada) (2.0.12+computecanada)
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/oauthlib-3.1.1+computecanada-py2.py3-none-any.whl
Installing collected packages: pyasn1, zipp, rsa, pyasn1-modules, oauthlib, cachetools, requests-oauthlib, importlib-metadata, google-auth, werkzeug, tensorboard-plugin-wit, tensorboard-data-server, markdown, grpcio, google-auth-oauthlib, absl-py, wrapt, tensorflow-estimator, tensorboard, scipy, opt-einsum, keras-preprocessing, h5py, google-pasta, gast, astunparse, tensorflow-gpu
  Attempting uninstall: pyasn1
    Found existing installation: pyasn1 0.4.3
    Not uninstalling pyasn1 at /cvmfs/soft.computecanada.ca/easybuild/software/2017/Core/scipy-stack/2019a/lib/python3.7/site-packages, outside environment /localscratch/yinan.29351707.0/env
    Can't uninstall 'pyasn1'. No files were found to uninstall.
  Attempting uninstall: zipp
    Found existing installation: zipp 0.3.3
    Not uninstalling zipp at /cvmfs/soft.computecanada.ca/easybuild/software/2017/Core/scipy-stack/2019a/lib/python3.7/site-packages, outside environment /localscratch/yinan.29351707.0/env
    Can't uninstall 'zipp'. No files were found to uninstall.
  Attempting uninstall: importlib-metadata
    Found existing installation: importlib-metadata 0.8
    Not uninstalling importlib-metadata at /cvmfs/soft.computecanada.ca/easybuild/software/2017/Core/scipy-stack/2019a/lib/python3.7/site-packages, outside environment /localscratch/yinan.29351707.0/env
    Can't uninstall 'importlib-metadata'. No files were found to uninstall.
  Attempting uninstall: scipy
    Found existing installation: scipy 1.2.0
    Not uninstalling scipy at /cvmfs/soft.computecanada.ca/easybuild/software/2017/Core/scipy-stack/2019a/lib/python3.7/site-packages, outside environment /localscratch/yinan.29351707.0/env
    Can't uninstall 'scipy'. No files were found to uninstall.
Successfully installed absl-py-1.0.0+computecanada astunparse-1.6.3+computecanada cachetools-4.2.4+computecanada gast-0.3.3+computecanada google-auth-2.3.3+computecanada google-auth-oauthlib-0.4.6+computecanada google-pasta-0.2.0+computecanada grpcio-1.38.0+computecanada h5py-2.10.0+computecanada importlib-metadata-4.10.1+computecanada keras-preprocessing-1.1.2+computecanada markdown-3.3.6+computecanada oauthlib-3.1.1+computecanada opt-einsum-3.3.0+computecanada pyasn1-0.4.8+computecanada pyasn1-modules-0.2.8+computecanada requests-oauthlib-1.3.0+computecanada rsa-4.8+computecanada scipy-1.4.1+computecanada tensorboard-2.8.0+computecanada tensorboard-data-server-0.6.1+computecanada tensorboard-plugin-wit-1.8.0+computecanada tensorflow-estimator-2.3.0+computecanada tensorflow-gpu-2.3.0+computecanada werkzeug-2.0.3+computecanada wrapt-1.11.2+computecanada zipp-3.7.0+computecanada
Looking in links: /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/nix/avx2, /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/nix/generic, /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/keras-2.8.0+computecanada-py2.py3-none-any.whl
Installing collected packages: Keras
Successfully installed Keras-2.8.0+computecanada
Looking in links: /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/nix/avx2, /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/nix/generic, /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/urllib3-1.26.7+computecanada-py2.py3-none-any.whl
Installing collected packages: urllib3
  Attempting uninstall: urllib3
    Found existing installation: urllib3 1.26.8+computecanada
    Uninstalling urllib3-1.26.8+computecanada:
      Successfully uninstalled urllib3-1.26.8+computecanada
Successfully installed urllib3-1.26.7+computecanada
Looking in links: /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/nix/avx2, /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/nix/generic, /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/nltk-3.7+computecanada-py3-none-any.whl
Requirement already satisfied: click in /localscratch/yinan.29351707.0/env/lib/python3.7/site-packages (from nltk) (8.0.4+computecanada)
Requirement already satisfied: tqdm in /localscratch/yinan.29351707.0/env/lib/python3.7/site-packages (from nltk) (4.63.1+computecanada)
Requirement already satisfied: joblib in /localscratch/yinan.29351707.0/env/lib/python3.7/site-packages (from nltk) (1.1.0+computecanada)
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/nltk-3.6.5+computecanada-py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/nltk-3.6.3+computecanada-py3-none-any.whl
Requirement already satisfied: regex in /localscratch/yinan.29351707.0/env/lib/python3.7/site-packages (from nltk) (2020.11.13+computecanada)
Requirement already satisfied: importlib-metadata in /localscratch/yinan.29351707.0/env/lib/python3.7/site-packages (from click->nltk) (4.10.1+computecanada)
Requirement already satisfied: zipp>=0.5 in /localscratch/yinan.29351707.0/env/lib/python3.7/site-packages (from importlib-metadata->click->nltk) (3.7.0+computecanada)
Requirement already satisfied: typing-extensions>=3.6.4 in /localscratch/yinan.29351707.0/env/lib/python3.7/site-packages (from importlib-metadata->click->nltk) (4.1.1+computecanada)
Installing collected packages: nltk
Successfully installed nltk-3.6.3+computecanada
Looking in links: /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/nix/avx2, /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/nix/generic, /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/scikit_learn-0.22.1+computecanada-cp37-cp37m-linux_x86_64.whl
Requirement already satisfied: joblib>=0.11 in /localscratch/yinan.29351707.0/env/lib/python3.7/site-packages (from scikit-learn==0.22.1) (1.1.0+computecanada)
Requirement already satisfied: scipy>=0.17.0 in /localscratch/yinan.29351707.0/env/lib/python3.7/site-packages (from scikit-learn==0.22.1) (1.4.1+computecanada)
Requirement already satisfied: numpy>=1.11.0 in /cvmfs/soft.computecanada.ca/easybuild/software/2017/Core/scipy-stack/2019a/lib/python3.7/site-packages (from scikit-learn==0.22.1) (1.16.0)
Installing collected packages: scikit-learn
Successfully installed scikit-learn-0.22.1+computecanada
Looking in links: /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/nix/avx2, /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/nix/generic, /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic
Requirement already satisfied: tokenizers==0.5.2 in /localscratch/yinan.29351707.0/env/lib/python3.7/site-packages (0.5.2+computecanada)
wandb: Appending key for api.wandb.ai to your netrc file: /home/yinan/.netrc
Starting Task
2022-03-27 15:52:07.336409: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1
[nltk_data] Downloading package stopwords to /home/yinan/nltk_data...
[nltk_data]   Package stopwords is already up-to-date!
[nltk_data] Downloading package wordnet to /home/yinan/nltk_data...
[nltk_data]   Package wordnet is already up-to-date!
wandb: Currently logged in as: yinanazhou (use `wandb login --relogin` to force relogin)
wandb: wandb version 0.12.11 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
2022-03-27 15:52:20.059360: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1
wandb: Tracking run with wandb version 0.12.5
wandb: Syncing run snowy-pine-2
wandb: â­ï¸ View project at https://wandb.ai/yinanazhou/xl_512_bs_8_lr_1e06_es_10_lc_False_nr_True_sr_True_stem_False_lemma_True_repeat_1_fold_1
wandb: ðŸš€ View run at https://wandb.ai/yinanazhou/xl_512_bs_8_lr_1e06_es_10_lc_False_nr_True_sr_True_stem_False_lemma_True_repeat_1_fold_1/runs/3mw4ks25
wandb: Run data is saved locally in /project/6002780/yinan/Thesis_MER_Lyrics/lyric-emotion/wandb/run-20220327_155217-3mw4ks25
wandb: Run `wandb offline` to turn off syncing.

Validation loss decreased (inf --> 1.429509).  Saving model ...
Validation loss decreased (1.429509 --> 1.410236).  Saving model ...
Validation loss decreased (1.410236 --> 1.393980).  Saving model ...
Validation loss decreased (1.393980 --> 1.380578).  Saving model ...
Validation loss decreased (1.380578 --> 1.370811).  Saving model ...
Validation loss decreased (1.370811 --> 1.362415).  Saving model ...
Validation loss decreased (1.362415 --> 1.355318).  Saving model ...
Validation loss decreased (1.355318 --> 1.349009).  Saving model ...
Validation loss decreased (1.349009 --> 1.343637).  Saving model ...
Validation loss decreased (1.343637 --> 1.337312).  Saving model ...
Validation loss decreased (1.337312 --> 1.330548).  Saving model ...
Validation loss decreased (1.330548 --> 1.324044).  Saving model ...
Validation loss decreased (1.324044 --> 1.316636).  Saving model ...
Validation loss decreased (1.316636 --> 1.310069).  Saving model ...
Validation loss decreased (1.310069 --> 1.302543).  Saving model ...
Validation loss decreased (1.302543 --> 1.296331).  Saving model ...
Validation loss decreased (1.296331 --> 1.289998).  Saving model ...
Validation loss decreased (1.289998 --> 1.284223).  Saving model ...
Validation loss decreased (1.284223 --> 1.277228).  Saving model ...
Validation loss decreased (1.277228 --> 1.270656).  Saving model ...
Validation loss decreased (1.270656 --> 1.265382).  Saving model ...
Validation loss decreased (1.265382 --> 1.259165).  Saving model ...
Validation loss decreased (1.259165 --> 1.255289).  Saving model ...
Validation loss decreased (1.255289 --> 1.250120).  Saving model ...
Validation loss decreased (1.250120 --> 1.244669).  Saving model ...
Validation loss decreased (1.244669 --> 1.238581).  Saving model ...
Validation loss decreased (1.238581 --> 1.235312).  Saving model ...
Validation loss decreased (1.235312 --> 1.231564).  Saving model ...
Validation loss decreased (1.231564 --> 1.227248).  Saving model ...
Validation loss decreased (1.227248 --> 1.222663).  Saving model ...
Validation loss decreased (1.222663 --> 1.216093).  Saving model ...
Validation loss decreased (1.216093 --> 1.212639).  Saving model ...
Validation loss decreased (1.212639 --> 1.208925).  Saving model ...
Validation loss decreased (1.208925 --> 1.204864).  Saving model ...
Validation loss decreased (1.204864 --> 1.202288).  Saving model ...
Validation loss decreased (1.202288 --> 1.196805).  Saving model ...
Validation loss decreased (1.196805 --> 1.193067).  Saving model ...
Validation loss decreased (1.193067 --> 1.188882).  Saving model ...
Validation loss decreased (1.188882 --> 1.186180).  Saving model ...
Validation loss decreased (1.186180 --> 1.183637).  Saving model ...
Validation loss decreased (1.183637 --> 1.178601).  Saving model ...
Validation loss decreased (1.178601 --> 1.171367).  Saving model ...
Validation loss decreased (1.171367 --> 1.166929).  Saving model ...
Validation loss decreased (1.166929 --> 1.162026).  Saving model ...
Validation loss decreased (1.162026 --> 1.159619).  Saving model ...
Validation loss decreased (1.159619 --> 1.154842).  Saving model ...
Validation loss decreased (1.154842 --> 1.152378).  Saving model ...
Validation loss decreased (1.152378 --> 1.147458).  Saving model ...
Validation loss decreased (1.147458 --> 1.143753).  Saving model ...
Validation loss decreased (1.143753 --> 1.139975).  Saving model ...
Validation loss decreased (1.139975 --> 1.136603).  Saving model ...
Validation loss decreased (1.136603 --> 1.131860).  Saving model ...
Validation loss decreased (1.131860 --> 1.129609).  Saving model ...
Validation loss decreased (1.129609 --> 1.128885).  Saving model ...
Validation loss decreased (1.128885 --> 1.127947).  Saving model ...
Validation loss decreased (1.127947 --> 1.122327).  Saving model ...
Validation loss decreased (1.122327 --> 1.119133).  Saving model ...
Validation loss decreased (1.119133 --> 1.118757).  Saving model ...
Validation loss decreased (1.118757 --> 1.115438).  Saving model ...
Validation loss decreased (1.115438 --> 1.113367).  Saving model ...
Validation loss decreased (1.113367 --> 1.110598).  Saving model ...
Validation loss decreased (1.110598 --> 1.107612).  Saving model ...
Validation loss decreased (1.107612 --> 1.101517).  Saving model ...
Validation loss decreased (1.101517 --> 1.101180).  Saving model ...
Validation loss decreased (1.101180 --> 1.099416).  Saving model ...
Validation loss decreased (1.099416 --> 1.094600).  Saving model ...
Validation loss decreased (1.094600 --> 1.093940).  Saving model ...
Validation loss decreased (1.093940 --> 1.093169).  Saving model ...
Validation loss decreased (1.093169 --> 1.090585).  Saving model ...
Validation loss decreased (1.090585 --> 1.089128).  Saving model ...
Validation loss decreased (1.089128 --> 1.086556).  Saving model ...
Validation loss decreased (1.086556 --> 1.082878).  Saving model ...
Validation loss decreased (1.082878 --> 1.080763).  Saving model ...
Validation loss decreased (1.080763 --> 1.077304).  Saving model ...
Validation loss decreased (1.077304 --> 1.076206).  Saving model ...
Validation loss decreased (1.076206 --> 1.076160).  Saving model ...
Validation loss decreased (1.076160 --> 1.075552).  Saving model ...
Validation loss decreased (1.075552 --> 1.073626).  Saving model ...
Validation loss decreased (1.073626 --> 1.071966).  Saving model ...
Validation loss decreased (1.071966 --> 1.068072).  Saving model ...
EarlyStopping counter: 1 out of 10.0
EarlyStopping counter: 2 out of 10.0
Validation loss decreased (1.068072 --> 1.068039).  Saving model ...
Validation loss decreased (1.068039 --> 1.064000).  Saving model ...
Validation loss decreased (1.064000 --> 1.060191).  Saving model ...
Validation loss decreased (1.060191 --> 1.058255).  Saving model ...
Validation loss decreased (1.058255 --> 1.057336).  Saving model ...
EarlyStopping counter: 1 out of 10.0
Validation loss decreased (1.057336 --> 1.057218).  Saving model ...
Validation loss decreased (1.057218 --> 1.055654).  Saving model ...
Validation loss decreased (1.055654 --> 1.054371).  Saving model ...
Validation loss decreased (1.054371 --> 1.051817).  Saving model ...
EarlyStopping counter: 1 out of 10.0
EarlyStopping counter: 2 out of 10.0
EarlyStopping counter: 3 out of 10.0
Validation loss decreased (1.051817 --> 1.049986).  Saving model ...
EarlyStopping counter: 1 out of 10.0
Validation loss decreased (1.049986 --> 1.044471).  Saving model ...
EarlyStopping counter: 1 out of 10.0
EarlyStopping counter: 2 out of 10.0
EarlyStopping counter: 3 out of 10.0
EarlyStopping counter: 4 out of 10.0
Validation loss decreased (1.044471 --> 1.043507).  Saving model ...
Validation loss decreased (1.043507 --> 1.041401).  Saving model ...
EarlyStopping counter: 1 out of 10.0
EarlyStopping counter: 2 out of 10.0
Validation loss decreased (1.041401 --> 1.040976).  Saving model ...
Validation loss decreased (1.040976 --> 1.040244).  Saving model ...
Validation loss decreased (1.040244 --> 1.038612).  Saving model ...
EarlyStopping counter: 1 out of 10.0
EarlyStopping counter: 2 out of 10.0
EarlyStopping counter: 3 out of 10.0
EarlyStopping counter: 4 out of 10.0
EarlyStopping counter: 5 out of 10.0
Validation loss decreased (1.038612 --> 1.038558).  Saving model ...
Validation loss decreased (1.038558 --> 1.037981).  Saving model ...
Validation loss decreased (1.037981 --> 1.037349).  Saving model ...
Validation loss decreased (1.037349 --> 1.032280).  Saving model ...
EarlyStopping counter: 1 out of 10.0
EarlyStopping counter: 2 out of 10.0
EarlyStopping counter: 3 out of 10.0
EarlyStopping counter: 4 out of 10.0
EarlyStopping counter: 5 out of 10.0
Validation loss decreased (1.032280 --> 1.031760).  Saving model ...
Validation loss decreased (1.031760 --> 1.030224).  Saving model ...
EarlyStopping counter: 1 out of 10.0
EarlyStopping counter: 2 out of 10.0
EarlyStopping counter: 3 out of 10.0
EarlyStopping counter: 4 out of 10.0
EarlyStopping counter: 5 out of 10.0
EarlyStopping counter: 6 out of 10.0
EarlyStopping counter: 7 out of 10.0
EarlyStopping counter: 8 out of 10.0
Validation loss decreased (1.030224 --> 1.029434).  Saving model ...
EarlyStopping counter: 1 out of 10.0
EarlyStopping counter: 2 out of 10.0
EarlyStopping counter: 3 out of 10.0
EarlyStopping counter: 4 out of 10.0
EarlyStopping counter: 5 out of 10.0
EarlyStopping counter: 6 out of 10.0
EarlyStopping counter: 7 out of 10.0
EarlyStopping counter: 8 out of 10.0
EarlyStopping counter: 9 out of 10.0
EarlyStopping counter: 10 out of 10.0
/localscratch/yinan.29351707.0/env/lib/python3.7/site-packages/torch/nn/functional.py:1794: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.
  warnings.warn("nn.functional.tanh is deprecated. Use torch.tanh instead.")
/localscratch/yinan.29351707.0/env/lib/python3.7/site-packages/transformers/optimization.py:155: UserWarning: This overload of add_ is deprecated:
	add_(Number alpha, Tensor other)
Consider using one of the following signatures instead:
	add_(Tensor other, *, Number alpha) (Triggered internally at  ../torch/csrc/utils/python_arg_parser.cpp:1025.)
  exp_avg.mul_(beta1).add_(1.0 - beta1, grad)
wandb: Waiting for W&B process to finish, PID 123243... (success).
wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: \ 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: | 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: / 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: \ 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: | 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: / 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: \ 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: | 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: / 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb:                                                                                
wandb: Run history:
wandb:     e_F1 â–â–‚â–ƒâ–„â–„â–…â–…â–…â–†â–†â–†â–†â–†â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ
wandb:   e_loss â–ˆâ–‡â–‡â–†â–†â–…â–…â–…â–…â–„â–„â–„â–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:     t_F1 â–â–‚â–‚â–ƒâ–ƒâ–„â–„â–…â–…â–…â–…â–…â–†â–†â–†â–…â–†â–‡â–‡â–†â–†â–‡â–‡â–‡â–‡â–ˆâ–‡â–‡â–‡â–‡â–‡â–ˆâ–‡â–ˆâ–‡â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ
wandb:   t_loss â–ˆâ–ˆâ–‡â–‡â–‡â–†â–†â–†â–…â–…â–…â–…â–„â–„â–„â–„â–„â–„â–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–â–â–â–â–
wandb: 
wandb: Run summary:
wandb:     e_F1 57.09591
wandb:   e_loss 1.03771
wandb:     t_F1 71.37365
wandb:   t_loss 0.70081
wandb: 
wandb: Synced 4 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Synced snowy-pine-2: https://wandb.ai/yinanazhou/xl_512_bs_8_lr_1e06_es_10_lc_False_nr_True_sr_True_stem_False_lemma_True_repeat_1_fold_1/runs/3mw4ks25
wandb: Find logs at: ./wandb/run-20220327_155217-3mw4ks25/logs/debug.log
wandb: 

wandb: wandb version 0.12.11 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
2022-03-27 17:23:59.600646: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1
wandb: Tracking run with wandb version 0.12.5
wandb: Syncing run happy-music-2
wandb: â­ï¸ View project at https://wandb.ai/yinanazhou/xl_512_bs_8_lr_1e06_es_10_lc_False_nr_True_sr_True_stem_False_lemma_True_repeat_1_fold_2
wandb: ðŸš€ View run at https://wandb.ai/yinanazhou/xl_512_bs_8_lr_1e06_es_10_lc_False_nr_True_sr_True_stem_False_lemma_True_repeat_1_fold_2/runs/1jcj9dvu
wandb: Run data is saved locally in /project/6002780/yinan/Thesis_MER_Lyrics/lyric-emotion/wandb/run-20220327_172355-1jcj9dvu
wandb: Run `wandb offline` to turn off syncing.

Validation loss decreased (inf --> 1.602565).  Saving model ...
Validation loss decreased (1.602565 --> 1.525258).  Saving model ...
Validation loss decreased (1.525258 --> 1.471236).  Saving model ...
Validation loss decreased (1.471236 --> 1.434480).  Saving model ...
Validation loss decreased (1.434480 --> 1.407494).  Saving model ...
Validation loss decreased (1.407494 --> 1.390710).  Saving model ...
Validation loss decreased (1.390710 --> 1.378826).  Saving model ...
Validation loss decreased (1.378826 --> 1.369546).  Saving model ...
Validation loss decreased (1.369546 --> 1.361968).  Saving model ...
Validation loss decreased (1.361968 --> 1.355415).  Saving model ...
Validation loss decreased (1.355415 --> 1.348711).  Saving model ...
Validation loss decreased (1.348711 --> 1.341615).  Saving model ...
Validation loss decreased (1.341615 --> 1.334631).  Saving model ...
Validation loss decreased (1.334631 --> 1.326536).  Saving model ...
Validation loss decreased (1.326536 --> 1.316822).  Saving model ...
Validation loss decreased (1.316822 --> 1.309107).  Saving model ...
Validation loss decreased (1.309107 --> 1.300775).  Saving model ...
Validation loss decreased (1.300775 --> 1.293958).  Saving model ...
Validation loss decreased (1.293958 --> 1.287254).  Saving model ...
Validation loss decreased (1.287254 --> 1.279461).  Saving model ...
Validation loss decreased (1.279461 --> 1.271161).  Saving model ...
Validation loss decreased (1.271161 --> 1.261719).  Saving model ...
Validation loss decreased (1.261719 --> 1.253891).  Saving model ...
Validation loss decreased (1.253891 --> 1.246826).  Saving model ...
Validation loss decreased (1.246826 --> 1.239775).  Saving model ...
Validation loss decreased (1.239775 --> 1.232868).  Saving model ...
Validation loss decreased (1.232868 --> 1.225198).  Saving model ...
Validation loss decreased (1.225198 --> 1.218549).  Saving model ...
Validation loss decreased (1.218549 --> 1.211984).  Saving model ...
Validation loss decreased (1.211984 --> 1.204173).  Saving model ...
Validation loss decreased (1.204173 --> 1.198443).  Saving model ...
Validation loss decreased (1.198443 --> 1.190532).  Saving model ...
Validation loss decreased (1.190532 --> 1.184182).  Saving model ...
Validation loss decreased (1.184182 --> 1.179085).  Saving model ...
Validation loss decreased (1.179085 --> 1.172289).  Saving model ...
Validation loss decreased (1.172289 --> 1.166168).  Saving model ...
Validation loss decreased (1.166168 --> 1.161701).  Saving model ...
Validation loss decreased (1.161701 --> 1.155514).  Saving model ...
Validation loss decreased (1.155514 --> 1.150159).  Saving model ...
Validation loss decreased (1.150159 --> 1.143935).  Saving model ...
Validation loss decreased (1.143935 --> 1.138185).  Saving model ...
Validation loss decreased (1.138185 --> 1.132259).  Saving model ...
Validation loss decreased (1.132259 --> 1.127661).  Saving model ...
Validation loss decreased (1.127661 --> 1.122513).  Saving model ...
Validation loss decreased (1.122513 --> 1.115767).  Saving model ...
Validation loss decreased (1.115767 --> 1.111515).  Saving model ...
Validation loss decreased (1.111515 --> 1.106913).  Saving model ...
Validation loss decreased (1.106913 --> 1.103839).  Saving model ...
Validation loss decreased (1.103839 --> 1.097341).  Saving model ...
Validation loss decreased (1.097341 --> 1.093221).  Saving model ...
Validation loss decreased (1.093221 --> 1.086960).  Saving model ...
Validation loss decreased (1.086960 --> 1.082153).  Saving model ...
Validation loss decreased (1.082153 --> 1.077157).  Saving model ...
Validation loss decreased (1.077157 --> 1.071330).  Saving model ...
Validation loss decreased (1.071330 --> 1.067441).  Saving model ...
Validation loss decreased (1.067441 --> 1.062794).  Saving model ...
Validation loss decreased (1.062794 --> 1.060282).  Saving model ...
Validation loss decreased (1.060282 --> 1.057238).  Saving model ...
Validation loss decreased (1.057238 --> 1.054625).  Saving model ...
Validation loss decreased (1.054625 --> 1.052862).  Saving model ...
Validation loss decreased (1.052862 --> 1.046906).  Saving model ...
Validation loss decreased (1.046906 --> 1.044164).  Saving model ...
Validation loss decreased (1.044164 --> 1.039523).  Saving model ...
Validation loss decreased (1.039523 --> 1.033915).  Saving model ...
Validation loss decreased (1.033915 --> 1.030973).  Saving model ...
Validation loss decreased (1.030973 --> 1.028299).  Saving model ...
Validation loss decreased (1.028299 --> 1.024136).  Saving model ...
Validation loss decreased (1.024136 --> 1.017978).  Saving model ...
Validation loss decreased (1.017978 --> 1.014648).  Saving model ...
Validation loss decreased (1.014648 --> 1.012581).  Saving model ...
Validation loss decreased (1.012581 --> 1.010137).  Saving model ...
Validation loss decreased (1.010137 --> 1.008046).  Saving model ...
Validation loss decreased (1.008046 --> 1.005302).  Saving model ...
Validation loss decreased (1.005302 --> 1.003789).  Saving model ...
Validation loss decreased (1.003789 --> 0.998609).  Saving model ...
Validation loss decreased (0.998609 --> 0.994494).  Saving model ...
Validation loss decreased (0.994494 --> 0.993021).  Saving model ...
Validation loss decreased (0.993021 --> 0.990236).  Saving model ...
Validation loss decreased (0.990236 --> 0.988250).  Saving model ...
Validation loss decreased (0.988250 --> 0.985690).  Saving model ...
Validation loss decreased (0.985690 --> 0.983775).  Saving model ...
Validation loss decreased (0.983775 --> 0.980584).  Saving model ...
Validation loss decreased (0.980584 --> 0.977339).  Saving model ...
Validation loss decreased (0.977339 --> 0.974968).  Saving model ...
Validation loss decreased (0.974968 --> 0.974946).  Saving model ...
Validation loss decreased (0.974946 --> 0.973395).  Saving model ...
Validation loss decreased (0.973395 --> 0.971287).  Saving model ...
Validation loss decreased (0.971287 --> 0.970825).  Saving model ...
Validation loss decreased (0.970825 --> 0.969837).  Saving model ...
Validation loss decreased (0.969837 --> 0.966991).  Saving model ...
Validation loss decreased (0.966991 --> 0.966865).  Saving model ...
Validation loss decreased (0.966865 --> 0.963888).  Saving model ...
Validation loss decreased (0.963888 --> 0.962367).  Saving model ...
Validation loss decreased (0.962367 --> 0.960216).  Saving model ...
Validation loss decreased (0.960216 --> 0.958416).  Saving model ...
Validation loss decreased (0.958416 --> 0.957659).  Saving model ...
EarlyStopping counter: 1 out of 10.0
Validation loss decreased (0.957659 --> 0.955251).  Saving model ...
Validation loss decreased (0.955251 --> 0.954135).  Saving model ...
Validation loss decreased (0.954135 --> 0.951796).  Saving model ...
EarlyStopping counter: 1 out of 10.0
Validation loss decreased (0.951796 --> 0.951362).  Saving model ...
Validation loss decreased (0.951362 --> 0.949777).  Saving model ...
EarlyStopping counter: 1 out of 10.0
EarlyStopping counter: 2 out of 10.0
Validation loss decreased (0.949777 --> 0.948219).  Saving model ...
Validation loss decreased (0.948219 --> 0.947457).  Saving model ...
Validation loss decreased (0.947457 --> 0.945544).  Saving model ...
Validation loss decreased (0.945544 --> 0.943691).  Saving model ...
Validation loss decreased (0.943691 --> 0.943266).  Saving model ...
EarlyStopping counter: 1 out of 10.0
Validation loss decreased (0.943266 --> 0.943084).  Saving model ...
Validation loss decreased (0.943084 --> 0.942140).  Saving model ...
EarlyStopping counter: 1 out of 10.0
Validation loss decreased (0.942140 --> 0.941561).  Saving model ...
Validation loss decreased (0.941561 --> 0.941115).  Saving model ...
Validation loss decreased (0.941115 --> 0.939674).  Saving model ...
Validation loss decreased (0.939674 --> 0.938969).  Saving model ...
Validation loss decreased (0.938969 --> 0.938103).  Saving model ...
Validation loss decreased (0.938103 --> 0.937728).  Saving model ...
Validation loss decreased (0.937728 --> 0.937032).  Saving model ...
Validation loss decreased (0.937032 --> 0.936261).  Saving model ...
EarlyStopping counter: 1 out of 10.0
EarlyStopping counter: 2 out of 10.0
Validation loss decreased (0.936261 --> 0.935466).  Saving model ...
EarlyStopping counter: 1 out of 10.0
EarlyStopping counter: 2 out of 10.0
EarlyStopping counter: 3 out of 10.0
EarlyStopping counter: 4 out of 10.0
EarlyStopping counter: 5 out of 10.0
EarlyStopping counter: 6 out of 10.0
EarlyStopping counter: 7 out of 10.0
EarlyStopping counter: 8 out of 10.0
EarlyStopping counter: 9 out of 10.0
EarlyStopping counter: 10 out of 10.0
/localscratch/yinan.29351707.0/env/lib/python3.7/site-packages/torch/nn/functional.py:1794: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.
  warnings.warn("nn.functional.tanh is deprecated. Use torch.tanh instead.")
wandb: Waiting for W&B process to finish, PID 128147... (success).
wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: \ 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: | 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: / 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: \ 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: | 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: / 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: \ 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: | 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: / 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb:                                                                                
wandb: Run history:
wandb:     e_F1 â–â–â–„â–„â–„â–…â–…â–†â–†â–†â–†â–†â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ
wandb:   e_loss â–ˆâ–‡â–†â–†â–†â–…â–…â–…â–„â–„â–„â–„â–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:     t_F1 â–â–‚â–‚â–ƒâ–ƒâ–„â–„â–„â–…â–…â–…â–…â–…â–†â–†â–†â–†â–†â–†â–†â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–ˆâ–‡â–‡â–‡â–ˆâ–ˆâ–‡â–ˆâ–ˆâ–ˆ
wandb:   t_loss â–ˆâ–‡â–‡â–†â–†â–†â–†â–†â–…â–…â–…â–…â–…â–„â–„â–„â–„â–„â–„â–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–â–â–â–â–â–
wandb: 
wandb: Run summary:
wandb:     e_F1 60.94269
wandb:   e_loss 0.93886
wandb:     t_F1 71.48486
wandb:   t_loss 0.76939
wandb: 
wandb: Synced 4 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Synced happy-music-2: https://wandb.ai/yinanazhou/xl_512_bs_8_lr_1e06_es_10_lc_False_nr_True_sr_True_stem_False_lemma_True_repeat_1_fold_2/runs/1jcj9dvu
wandb: Find logs at: ./wandb/run-20220327_172355-1jcj9dvu/logs/debug.log
wandb: 

wandb: wandb version 0.12.11 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
2022-03-27 18:53:20.561165: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1
wandb: Tracking run with wandb version 0.12.5
wandb: Syncing run upbeat-firebrand-2
wandb: â­ï¸ View project at https://wandb.ai/yinanazhou/xl_512_bs_8_lr_1e06_es_10_lc_False_nr_True_sr_True_stem_False_lemma_True_repeat_2_fold_1
wandb: ðŸš€ View run at https://wandb.ai/yinanazhou/xl_512_bs_8_lr_1e06_es_10_lc_False_nr_True_sr_True_stem_False_lemma_True_repeat_2_fold_1/runs/3iklkprc
wandb: Run data is saved locally in /project/6002780/yinan/Thesis_MER_Lyrics/lyric-emotion/wandb/run-20220327_185318-3iklkprc
wandb: Run `wandb offline` to turn off syncing.

Validation loss decreased (inf --> 1.451432).  Saving model ...
Validation loss decreased (1.451432 --> 1.420391).  Saving model ...
Validation loss decreased (1.420391 --> 1.399129).  Saving model ...
Validation loss decreased (1.399129 --> 1.384866).  Saving model ...
Validation loss decreased (1.384866 --> 1.375283).  Saving model ...
Validation loss decreased (1.375283 --> 1.368615).  Saving model ...
Validation loss decreased (1.368615 --> 1.362717).  Saving model ...
Validation loss decreased (1.362717 --> 1.357331).  Saving model ...
Validation loss decreased (1.357331 --> 1.352510).  Saving model ...
Validation loss decreased (1.352510 --> 1.347621).  Saving model ...
Validation loss decreased (1.347621 --> 1.342345).  Saving model ...
Validation loss decreased (1.342345 --> 1.337069).  Saving model ...
Validation loss decreased (1.337069 --> 1.332842).  Saving model ...
Validation loss decreased (1.332842 --> 1.327471).  Saving model ...
Validation loss decreased (1.327471 --> 1.321492).  Saving model ...
Validation loss decreased (1.321492 --> 1.314877).  Saving model ...
Validation loss decreased (1.314877 --> 1.307594).  Saving model ...
Validation loss decreased (1.307594 --> 1.300022).  Saving model ...
Validation loss decreased (1.300022 --> 1.293466).  Saving model ...
Validation loss decreased (1.293466 --> 1.285493).  Saving model ...
Validation loss decreased (1.285493 --> 1.277609).  Saving model ...
Validation loss decreased (1.277609 --> 1.269803).  Saving model ...
Validation loss decreased (1.269803 --> 1.261026).  Saving model ...
Validation loss decreased (1.261026 --> 1.252392).  Saving model ...
Validation loss decreased (1.252392 --> 1.244951).  Saving model ...
Validation loss decreased (1.244951 --> 1.236298).  Saving model ...
Validation loss decreased (1.236298 --> 1.227895).  Saving model ...
Validation loss decreased (1.227895 --> 1.221296).  Saving model ...
Validation loss decreased (1.221296 --> 1.213273).  Saving model ...
Validation loss decreased (1.213273 --> 1.205693).  Saving model ...
Validation loss decreased (1.205693 --> 1.196094).  Saving model ...
Validation loss decreased (1.196094 --> 1.189470).  Saving model ...
Validation loss decreased (1.189470 --> 1.182324).  Saving model ...
Validation loss decreased (1.182324 --> 1.174324).  Saving model ...
Validation loss decreased (1.174324 --> 1.167614).  Saving model ...
Validation loss decreased (1.167614 --> 1.160663).  Saving model ...
Validation loss decreased (1.160663 --> 1.154145).  Saving model ...
Validation loss decreased (1.154145 --> 1.148215).  Saving model ...
Validation loss decreased (1.148215 --> 1.142379).  Saving model ...
Validation loss decreased (1.142379 --> 1.135934).  Saving model ...
Validation loss decreased (1.135934 --> 1.129485).  Saving model ...
Validation loss decreased (1.129485 --> 1.123892).  Saving model ...
Validation loss decreased (1.123892 --> 1.118045).  Saving model ...
Validation loss decreased (1.118045 --> 1.112024).  Saving model ...
Validation loss decreased (1.112024 --> 1.108178).  Saving model ...
Validation loss decreased (1.108178 --> 1.102246).  Saving model ...
Validation loss decreased (1.102246 --> 1.097610).  Saving model ...
Validation loss decreased (1.097610 --> 1.093671).  Saving model ...
Validation loss decreased (1.093671 --> 1.087939).  Saving model ...
Validation loss decreased (1.087939 --> 1.083025).  Saving model ...
Validation loss decreased (1.083025 --> 1.078936).  Saving model ...
Validation loss decreased (1.078936 --> 1.074119).  Saving model ...
Validation loss decreased (1.074119 --> 1.069492).  Saving model ...
Validation loss decreased (1.069492 --> 1.064987).  Saving model ...
Validation loss decreased (1.064987 --> 1.061292).  Saving model ...
Validation loss decreased (1.061292 --> 1.056800).  Saving model ...
Validation loss decreased (1.056800 --> 1.053035).  Saving model ...
Validation loss decreased (1.053035 --> 1.049790).  Saving model ...
Validation loss decreased (1.049790 --> 1.045964).  Saving model ...
Validation loss decreased (1.045964 --> 1.043134).  Saving model ...
Validation loss decreased (1.043134 --> 1.041270).  Saving model ...
Validation loss decreased (1.041270 --> 1.038446).  Saving model ...
Validation loss decreased (1.038446 --> 1.034267).  Saving model ...
Validation loss decreased (1.034267 --> 1.030700).  Saving model ...
Validation loss decreased (1.030700 --> 1.027337).  Saving model ...
Validation loss decreased (1.027337 --> 1.023444).  Saving model ...
Validation loss decreased (1.023444 --> 1.021062).  Saving model ...
Validation loss decreased (1.021062 --> 1.017488).  Saving model ...
Validation loss decreased (1.017488 --> 1.014572).  Saving model ...
Validation loss decreased (1.014572 --> 1.011361).  Saving model ...
Validation loss decreased (1.011361 --> 1.007206).  Saving model ...
Validation loss decreased (1.007206 --> 1.004185).  Saving model ...
Validation loss decreased (1.004185 --> 1.001495).  Saving model ...
Validation loss decreased (1.001495 --> 0.999694).  Saving model ...
Validation loss decreased (0.999694 --> 0.996640).  Saving model ...
Validation loss decreased (0.996640 --> 0.994055).  Saving model ...
Validation loss decreased (0.994055 --> 0.992783).  Saving model ...
Validation loss decreased (0.992783 --> 0.990295).  Saving model ...
Validation loss decreased (0.990295 --> 0.989791).  Saving model ...
Validation loss decreased (0.989791 --> 0.988897).  Saving model ...
Validation loss decreased (0.988897 --> 0.987600).  Saving model ...
Validation loss decreased (0.987600 --> 0.985248).  Saving model ...
Validation loss decreased (0.985248 --> 0.981712).  Saving model ...
Validation loss decreased (0.981712 --> 0.980624).  Saving model ...
Validation loss decreased (0.980624 --> 0.978468).  Saving model ...
Validation loss decreased (0.978468 --> 0.976376).  Saving model ...
Validation loss decreased (0.976376 --> 0.973627).  Saving model ...
Validation loss decreased (0.973627 --> 0.972701).  Saving model ...
Validation loss decreased (0.972701 --> 0.971590).  Saving model ...
Validation loss decreased (0.971590 --> 0.969753).  Saving model ...
Validation loss decreased (0.969753 --> 0.968548).  Saving model ...
Validation loss decreased (0.968548 --> 0.968209).  Saving model ...
Validation loss decreased (0.968209 --> 0.967439).  Saving model ...
Validation loss decreased (0.967439 --> 0.965585).  Saving model ...
Validation loss decreased (0.965585 --> 0.963434).  Saving model ...
Validation loss decreased (0.963434 --> 0.961883).  Saving model ...
Validation loss decreased (0.961883 --> 0.960461).  Saving model ...
Validation loss decreased (0.960461 --> 0.958752).  Saving model ...
Validation loss decreased (0.958752 --> 0.957601).  Saving model ...
EarlyStopping counter: 1 out of 10.0
Validation loss decreased (0.957601 --> 0.956579).  Saving model ...
Validation loss decreased (0.956579 --> 0.955338).  Saving model ...
Validation loss decreased (0.955338 --> 0.953687).  Saving model ...
EarlyStopping counter: 1 out of 10.0
Validation loss decreased (0.953687 --> 0.952735).  Saving model ...
Validation loss decreased (0.952735 --> 0.952607).  Saving model ...
Validation loss decreased (0.952607 --> 0.951939).  Saving model ...
Validation loss decreased (0.951939 --> 0.951123).  Saving model ...
Validation loss decreased (0.951123 --> 0.950395).  Saving model ...
Validation loss decreased (0.950395 --> 0.949958).  Saving model ...
Validation loss decreased (0.949958 --> 0.949759).  Saving model ...
Validation loss decreased (0.949759 --> 0.949134).  Saving model ...
Validation loss decreased (0.949134 --> 0.947991).  Saving model ...
Validation loss decreased (0.947991 --> 0.947025).  Saving model ...
EarlyStopping counter: 1 out of 10.0
EarlyStopping counter: 2 out of 10.0
EarlyStopping counter: 3 out of 10.0
EarlyStopping counter: 4 out of 10.0
EarlyStopping counter: 5 out of 10.0
EarlyStopping counter: 6 out of 10.0
EarlyStopping counter: 7 out of 10.0
Validation loss decreased (0.947025 --> 0.945060).  Saving model ...
EarlyStopping counter: 1 out of 10.0
EarlyStopping counter: 2 out of 10.0
EarlyStopping counter: 3 out of 10.0
EarlyStopping counter: 4 out of 10.0
Validation loss decreased (0.945060 --> 0.944671).  Saving model ...
Validation loss decreased (0.944671 --> 0.943841).  Saving model ...
EarlyStopping counter: 1 out of 10.0
EarlyStopping counter: 2 out of 10.0
Validation loss decreased (0.943841 --> 0.942673).  Saving model ...
EarlyStopping counter: 1 out of 10.0
Validation loss decreased (0.942673 --> 0.942259).  Saving model ...
EarlyStopping counter: 1 out of 10.0
EarlyStopping counter: 2 out of 10.0
EarlyStopping counter: 3 out of 10.0
EarlyStopping counter: 4 out of 10.0
EarlyStopping counter: 5 out of 10.0
EarlyStopping counter: 6 out of 10.0
EarlyStopping counter: 7 out of 10.0
EarlyStopping counter: 8 out of 10.0
EarlyStopping counter: 9 out of 10.0
EarlyStopping counter: 10 out of 10.0
/localscratch/yinan.29351707.0/env/lib/python3.7/site-packages/torch/nn/functional.py:1794: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.
  warnings.warn("nn.functional.tanh is deprecated. Use torch.tanh instead.")
wandb: Waiting for W&B process to finish, PID 132906... (success).
wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: \ 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: | 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: / 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: \ 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: | 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: / 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: \ 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: | 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: / 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb:                                                                                
wandb: Run history:
wandb:     e_F1 â–â–‚â–„â–…â–…â–…â–…â–…â–†â–†â–†â–†â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ
wandb:   e_loss â–ˆâ–‡â–‡â–‡â–†â–†â–†â–…â–…â–„â–„â–„â–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–‚â–‚â–‚â–‚â–‚â–‚â–‚â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:     t_F1 â–â–â–‚â–ƒâ–ƒâ–ƒâ–„â–„â–„â–…â–…â–…â–…â–†â–†â–†â–†â–†â–†â–†â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–ˆâ–‡â–‡â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ
wandb:   t_loss â–ˆâ–ˆâ–‡â–‡â–‡â–‡â–†â–†â–†â–…â–†â–…â–…â–…â–„â–„â–„â–„â–„â–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–â–â–â–
wandb: 
wandb: Run summary:
wandb:     e_F1 62.6324
wandb:   e_loss 0.94508
wandb:     t_F1 74.87678
wandb:   t_loss 0.71905
wandb: 
wandb: Synced 4 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Synced upbeat-firebrand-2: https://wandb.ai/yinanazhou/xl_512_bs_8_lr_1e06_es_10_lc_False_nr_True_sr_True_stem_False_lemma_True_repeat_2_fold_1/runs/3iklkprc
wandb: Find logs at: ./wandb/run-20220327_185318-3iklkprc/logs/debug.log
wandb: 

wandb: wandb version 0.12.11 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
2022-03-27 20:27:44.828670: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1
wandb: Tracking run with wandb version 0.12.5
wandb: Syncing run wild-serenity-1
wandb: â­ï¸ View project at https://wandb.ai/yinanazhou/xl_512_bs_8_lr_1e06_es_10_lc_False_nr_True_sr_True_stem_False_lemma_True_repeat_2_fold_2
wandb: ðŸš€ View run at https://wandb.ai/yinanazhou/xl_512_bs_8_lr_1e06_es_10_lc_False_nr_True_sr_True_stem_False_lemma_True_repeat_2_fold_2/runs/j9bcrlqv
wandb: Run data is saved locally in /project/6002780/yinan/Thesis_MER_Lyrics/lyric-emotion/wandb/run-20220327_202742-j9bcrlqv
wandb: Run `wandb offline` to turn off syncing.

Validation loss decreased (inf --> 1.415982).  Saving model ...
Validation loss decreased (1.415982 --> 1.397046).  Saving model ...
Validation loss decreased (1.397046 --> 1.383821).  Saving model ...
Validation loss decreased (1.383821 --> 1.373817).  Saving model ...
Validation loss decreased (1.373817 --> 1.366622).  Saving model ...
Validation loss decreased (1.366622 --> 1.361038).  Saving model ...
Validation loss decreased (1.361038 --> 1.355987).  Saving model ...
Validation loss decreased (1.355987 --> 1.351061).  Saving model ...
Validation loss decreased (1.351061 --> 1.346544).  Saving model ...
Validation loss decreased (1.346544 --> 1.341768).  Saving model ...
Validation loss decreased (1.341768 --> 1.337202).  Saving model ...
Validation loss decreased (1.337202 --> 1.332518).  Saving model ...
Validation loss decreased (1.332518 --> 1.328004).  Saving model ...
Validation loss decreased (1.328004 --> 1.323292).  Saving model ...
Validation loss decreased (1.323292 --> 1.317538).  Saving model ...
Validation loss decreased (1.317538 --> 1.312273).  Saving model ...
Validation loss decreased (1.312273 --> 1.306207).  Saving model ...
Validation loss decreased (1.306207 --> 1.299858).  Saving model ...
Validation loss decreased (1.299858 --> 1.293618).  Saving model ...
Validation loss decreased (1.293618 --> 1.287054).  Saving model ...
Validation loss decreased (1.287054 --> 1.280358).  Saving model ...
Validation loss decreased (1.280358 --> 1.273064).  Saving model ...
Validation loss decreased (1.273064 --> 1.265483).  Saving model ...
Validation loss decreased (1.265483 --> 1.257242).  Saving model ...
Validation loss decreased (1.257242 --> 1.248931).  Saving model ...
Validation loss decreased (1.248931 --> 1.241696).  Saving model ...
Validation loss decreased (1.241696 --> 1.233967).  Saving model ...
Validation loss decreased (1.233967 --> 1.227047).  Saving model ...
Validation loss decreased (1.227047 --> 1.219540).  Saving model ...
Validation loss decreased (1.219540 --> 1.211155).  Saving model ...
Validation loss decreased (1.211155 --> 1.203103).  Saving model ...
Validation loss decreased (1.203103 --> 1.194965).  Saving model ...
Validation loss decreased (1.194965 --> 1.186759).  Saving model ...
Validation loss decreased (1.186759 --> 1.180538).  Saving model ...
Validation loss decreased (1.180538 --> 1.173510).  Saving model ...
Validation loss decreased (1.173510 --> 1.166938).  Saving model ...
Validation loss decreased (1.166938 --> 1.161187).  Saving model ...
Validation loss decreased (1.161187 --> 1.154060).  Saving model ...
Validation loss decreased (1.154060 --> 1.149415).  Saving model ...
Validation loss decreased (1.149415 --> 1.143555).  Saving model ...
Validation loss decreased (1.143555 --> 1.138026).  Saving model ...
Validation loss decreased (1.138026 --> 1.131403).  Saving model ...
Validation loss decreased (1.131403 --> 1.125548).  Saving model ...
Validation loss decreased (1.125548 --> 1.120798).  Saving model ...
Validation loss decreased (1.120798 --> 1.113911).  Saving model ...
Validation loss decreased (1.113911 --> 1.109111).  Saving model ...
Validation loss decreased (1.109111 --> 1.105079).  Saving model ...
Validation loss decreased (1.105079 --> 1.098780).  Saving model ...
Validation loss decreased (1.098780 --> 1.093929).  Saving model ...
Validation loss decreased (1.093929 --> 1.089608).  Saving model ...
Validation loss decreased (1.089608 --> 1.086016).  Saving model ...
Validation loss decreased (1.086016 --> 1.081420).  Saving model ...
Validation loss decreased (1.081420 --> 1.077008).  Saving model ...
Validation loss decreased (1.077008 --> 1.074020).  Saving model ...
Validation loss decreased (1.074020 --> 1.069858).  Saving model ...
Validation loss decreased (1.069858 --> 1.066493).  Saving model ...
Validation loss decreased (1.066493 --> 1.063022).  Saving model ...
Validation loss decreased (1.063022 --> 1.059036).  Saving model ...
Validation loss decreased (1.059036 --> 1.054870).  Saving model ...
Validation loss decreased (1.054870 --> 1.051480).  Saving model ...
Validation loss decreased (1.051480 --> 1.046320).  Saving model ...
Validation loss decreased (1.046320 --> 1.043669).  Saving model ...
Validation loss decreased (1.043669 --> 1.041573).  Saving model ...
Validation loss decreased (1.041573 --> 1.037345).  Saving model ...
Validation loss decreased (1.037345 --> 1.033806).  Saving model ...
Validation loss decreased (1.033806 --> 1.030913).  Saving model ...
Validation loss decreased (1.030913 --> 1.027921).  Saving model ...
Validation loss decreased (1.027921 --> 1.025388).  Saving model ...
Validation loss decreased (1.025388 --> 1.021776).  Saving model ...
Validation loss decreased (1.021776 --> 1.017630).  Saving model ...
Validation loss decreased (1.017630 --> 1.014052).  Saving model ...
Validation loss decreased (1.014052 --> 1.010266).  Saving model ...
Validation loss decreased (1.010266 --> 1.008039).  Saving model ...
Validation loss decreased (1.008039 --> 1.004113).  Saving model ...
Validation loss decreased (1.004113 --> 1.002943).  Saving model ...
Validation loss decreased (1.002943 --> 1.001346).  Saving model ...
Validation loss decreased (1.001346 --> 0.998146).  Saving model ...
Validation loss decreased (0.998146 --> 0.993666).  Saving model ...
Validation loss decreased (0.993666 --> 0.991128).  Saving model ...
Validation loss decreased (0.991128 --> 0.989081).  Saving model ...
Validation loss decreased (0.989081 --> 0.986690).  Saving model ...
Validation loss decreased (0.986690 --> 0.985624).  Saving model ...
Validation loss decreased (0.985624 --> 0.983653).  Saving model ...
Validation loss decreased (0.983653 --> 0.980951).  Saving model ...
Validation loss decreased (0.980951 --> 0.979577).  Saving model ...
Validation loss decreased (0.979577 --> 0.978312).  Saving model ...
Validation loss decreased (0.978312 --> 0.976722).  Saving model ...
Validation loss decreased (0.976722 --> 0.974867).  Saving model ...
Validation loss decreased (0.974867 --> 0.973885).  Saving model ...
Validation loss decreased (0.973885 --> 0.971906).  Saving model ...
Validation loss decreased (0.971906 --> 0.970146).  Saving model ...
Validation loss decreased (0.970146 --> 0.968657).  Saving model ...
Validation loss decreased (0.968657 --> 0.967038).  Saving model ...
Validation loss decreased (0.967038 --> 0.966602).  Saving model ...
Validation loss decreased (0.966602 --> 0.964864).  Saving model ...
Validation loss decreased (0.964864 --> 0.964165).  Saving model ...
EarlyStopping counter: 1 out of 10.0
EarlyStopping counter: 2 out of 10.0
Validation loss decreased (0.964165 --> 0.963402).  Saving model ...
Validation loss decreased (0.963402 --> 0.962195).  Saving model ...
Validation loss decreased (0.962195 --> 0.960587).  Saving model ...
EarlyStopping counter: 1 out of 10.0
Validation loss decreased (0.960587 --> 0.959633).  Saving model ...
Validation loss decreased (0.959633 --> 0.958755).  Saving model ...
Validation loss decreased (0.958755 --> 0.956167).  Saving model ...
Validation loss decreased (0.956167 --> 0.954685).  Saving model ...
Validation loss decreased (0.954685 --> 0.954212).  Saving model ...
Validation loss decreased (0.954212 --> 0.950985).  Saving model ...
EarlyStopping counter: 1 out of 10.0
EarlyStopping counter: 2 out of 10.0
Validation loss decreased (0.950985 --> 0.950628).  Saving model ...
Validation loss decreased (0.950628 --> 0.949498).  Saving model ...
Validation loss decreased (0.949498 --> 0.948677).  Saving model ...
EarlyStopping counter: 1 out of 10.0
EarlyStopping counter: 2 out of 10.0
EarlyStopping counter: 3 out of 10.0
Validation loss decreased (0.948677 --> 0.947913).  Saving model ...
Validation loss decreased (0.947913 --> 0.945471).  Saving model ...
EarlyStopping counter: 1 out of 10.0
EarlyStopping counter: 2 out of 10.0
EarlyStopping counter: 3 out of 10.0
EarlyStopping counter: 4 out of 10.0
EarlyStopping counter: 5 out of 10.0
EarlyStopping counter: 6 out of 10.0
EarlyStopping counter: 7 out of 10.0
Validation loss decreased (0.945471 --> 0.944418).  Saving model ...
Validation loss decreased (0.944418 --> 0.943215).  Saving model ...
EarlyStopping counter: 1 out of 10.0
Validation loss decreased (0.943215 --> 0.941848).  Saving model ...
EarlyStopping counter: 1 out of 10.0
EarlyStopping counter: 2 out of 10.0
EarlyStopping counter: 3 out of 10.0
EarlyStopping counter: 4 out of 10.0
EarlyStopping counter: 5 out of 10.0
EarlyStopping counter: 6 out of 10.0
EarlyStopping counter: 7 out of 10.0
EarlyStopping counter: 8 out of 10.0
EarlyStopping counter: 9 out of 10.0
EarlyStopping counter: 10 out of 10.0
/localscratch/yinan.29351707.0/env/lib/python3.7/site-packages/torch/nn/functional.py:1794: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.
  warnings.warn("nn.functional.tanh is deprecated. Use torch.tanh instead.")
wandb: Waiting for W&B process to finish, PID 137928... (success).
wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: \ 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: | 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: / 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: \ 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: | 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: / 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: \ 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: | 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: / 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb:                                                                                
wandb: Run history:
wandb:     e_F1 â–â–‚â–„â–„â–„â–…â–…â–…â–…â–†â–†â–†â–†â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ
wandb:   e_loss â–ˆâ–ˆâ–‡â–‡â–‡â–‡â–†â–†â–…â–…â–„â–„â–„â–„â–ƒâ–ƒâ–ƒâ–ƒâ–‚â–‚â–‚â–‚â–‚â–‚â–‚â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:     t_F1 â–â–â–‚â–ƒâ–ƒâ–„â–„â–„â–…â–…â–…â–…â–…â–…â–†â–†â–†â–†â–‡â–‡â–‡â–†â–†â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–ˆâ–ˆâ–‡â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ
wandb:   t_loss â–ˆâ–ˆâ–ˆâ–‡â–‡â–‡â–‡â–‡â–†â–†â–†â–…â–…â–…â–…â–„â–„â–„â–„â–„â–„â–„â–ƒâ–ƒâ–ƒâ–‚â–ƒâ–‚â–ƒâ–‚â–‚â–‚â–‚â–‚â–â–‚â–‚â–â–â–
wandb: 
wandb: Run summary:
wandb:     e_F1 60.27874
wandb:   e_loss 0.94663
wandb:     t_F1 71.63172
wandb:   t_loss 0.75314
wandb: 
wandb: Synced 4 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Synced wild-serenity-1: https://wandb.ai/yinanazhou/xl_512_bs_8_lr_1e06_es_10_lc_False_nr_True_sr_True_stem_False_lemma_True_repeat_2_fold_2/runs/j9bcrlqv
wandb: Find logs at: ./wandb/run-20220327_202742-j9bcrlqv/logs/debug.log
wandb: 

wandb: wandb version 0.12.11 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
2022-03-27 21:58:03.353456: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1
wandb: Tracking run with wandb version 0.12.5
wandb: Syncing run icy-glitter-1
wandb: â­ï¸ View project at https://wandb.ai/yinanazhou/xl_512_bs_8_lr_1e06_es_10_lc_False_nr_True_sr_True_stem_False_lemma_True_repeat_3_fold_1
wandb: ðŸš€ View run at https://wandb.ai/yinanazhou/xl_512_bs_8_lr_1e06_es_10_lc_False_nr_True_sr_True_stem_False_lemma_True_repeat_3_fold_1/runs/22e3a4bp
wandb: Run data is saved locally in /project/6002780/yinan/Thesis_MER_Lyrics/lyric-emotion/wandb/run-20220327_215800-22e3a4bp
wandb: Run `wandb offline` to turn off syncing.

Validation loss decreased (inf --> 1.527368).  Saving model ...
Validation loss decreased (1.527368 --> 1.480923).  Saving model ...
Validation loss decreased (1.480923 --> 1.444866).  Saving model ...
Validation loss decreased (1.444866 --> 1.416394).  Saving model ...
Validation loss decreased (1.416394 --> 1.395154).  Saving model ...
Validation loss decreased (1.395154 --> 1.380046).  Saving model ...
Validation loss decreased (1.380046 --> 1.369198).  Saving model ...
Validation loss decreased (1.369198 --> 1.361407).  Saving model ...
Validation loss decreased (1.361407 --> 1.354462).  Saving model ...
Validation loss decreased (1.354462 --> 1.348805).  Saving model ...
Validation loss decreased (1.348805 --> 1.344332).  Saving model ...
Validation loss decreased (1.344332 --> 1.338776).  Saving model ...
Validation loss decreased (1.338776 --> 1.334746).  Saving model ...
Validation loss decreased (1.334746 --> 1.329897).  Saving model ...
Validation loss decreased (1.329897 --> 1.324743).  Saving model ...
Validation loss decreased (1.324743 --> 1.319619).  Saving model ...
Validation loss decreased (1.319619 --> 1.314879).  Saving model ...
Validation loss decreased (1.314879 --> 1.308745).  Saving model ...
Validation loss decreased (1.308745 --> 1.303102).  Saving model ...
Validation loss decreased (1.303102 --> 1.298971).  Saving model ...
Validation loss decreased (1.298971 --> 1.293471).  Saving model ...
Validation loss decreased (1.293471 --> 1.286964).  Saving model ...
Validation loss decreased (1.286964 --> 1.280084).  Saving model ...
Validation loss decreased (1.280084 --> 1.273403).  Saving model ...
Validation loss decreased (1.273403 --> 1.266564).  Saving model ...
Validation loss decreased (1.266564 --> 1.261629).  Saving model ...
Validation loss decreased (1.261629 --> 1.255699).  Saving model ...
Validation loss decreased (1.255699 --> 1.247974).  Saving model ...
Validation loss decreased (1.247974 --> 1.241709).  Saving model ...
Validation loss decreased (1.241709 --> 1.234981).  Saving model ...
Validation loss decreased (1.234981 --> 1.229797).  Saving model ...
Validation loss decreased (1.229797 --> 1.222742).  Saving model ...
Validation loss decreased (1.222742 --> 1.214942).  Saving model ...
Validation loss decreased (1.214942 --> 1.208760).  Saving model ...
Validation loss decreased (1.208760 --> 1.202661).  Saving model ...
Validation loss decreased (1.202661 --> 1.197250).  Saving model ...
Validation loss decreased (1.197250 --> 1.192451).  Saving model ...
Validation loss decreased (1.192451 --> 1.187549).  Saving model ...
Validation loss decreased (1.187549 --> 1.180957).  Saving model ...
Validation loss decreased (1.180957 --> 1.175981).  Saving model ...
Validation loss decreased (1.175981 --> 1.173282).  Saving model ...
Validation loss decreased (1.173282 --> 1.169938).  Saving model ...
Validation loss decreased (1.169938 --> 1.165712).  Saving model ...
Validation loss decreased (1.165712 --> 1.159148).  Saving model ...
Validation loss decreased (1.159148 --> 1.153342).  Saving model ...
Validation loss decreased (1.153342 --> 1.148333).  Saving model ...
Validation loss decreased (1.148333 --> 1.142833).  Saving model ...
Validation loss decreased (1.142833 --> 1.139838).  Saving model ...
Validation loss decreased (1.139838 --> 1.134003).  Saving model ...
Validation loss decreased (1.134003 --> 1.128589).  Saving model ...
Validation loss decreased (1.128589 --> 1.124823).  Saving model ...
Validation loss decreased (1.124823 --> 1.121807).  Saving model ...
Validation loss decreased (1.121807 --> 1.117475).  Saving model ...
Validation loss decreased (1.117475 --> 1.112819).  Saving model ...
Validation loss decreased (1.112819 --> 1.110049).  Saving model ...
Validation loss decreased (1.110049 --> 1.105953).  Saving model ...
Validation loss decreased (1.105953 --> 1.103051).  Saving model ...
Validation loss decreased (1.103051 --> 1.098740).  Saving model ...
Validation loss decreased (1.098740 --> 1.096436).  Saving model ...
Validation loss decreased (1.096436 --> 1.095544).  Saving model ...
Validation loss decreased (1.095544 --> 1.093824).  Saving model ...
Validation loss decreased (1.093824 --> 1.086223).  Saving model ...
Validation loss decreased (1.086223 --> 1.084284).  Saving model ...
Validation loss decreased (1.084284 --> 1.080752).  Saving model ...
Validation loss decreased (1.080752 --> 1.077256).  Saving model ...
Validation loss decreased (1.077256 --> 1.076252).  Saving model ...
Validation loss decreased (1.076252 --> 1.076178).  Saving model ...
Validation loss decreased (1.076178 --> 1.070466).  Saving model ...
Validation loss decreased (1.070466 --> 1.069228).  Saving model ...
EarlyStopping counter: 1 out of 10.0
Validation loss decreased (1.069228 --> 1.067040).  Saving model ...
Validation loss decreased (1.067040 --> 1.061328).  Saving model ...
Validation loss decreased (1.061328 --> 1.055458).  Saving model ...
EarlyStopping counter: 1 out of 10.0
Validation loss decreased (1.055458 --> 1.053609).  Saving model ...
Validation loss decreased (1.053609 --> 1.051657).  Saving model ...
Validation loss decreased (1.051657 --> 1.048187).  Saving model ...
Validation loss decreased (1.048187 --> 1.044318).  Saving model ...
Validation loss decreased (1.044318 --> 1.039957).  Saving model ...
Validation loss decreased (1.039957 --> 1.036734).  Saving model ...
Validation loss decreased (1.036734 --> 1.034461).  Saving model ...
Validation loss decreased (1.034461 --> 1.034381).  Saving model ...
Validation loss decreased (1.034381 --> 1.034159).  Saving model ...
Validation loss decreased (1.034159 --> 1.031358).  Saving model ...
EarlyStopping counter: 1 out of 10.0
Validation loss decreased (1.031358 --> 1.028598).  Saving model ...
EarlyStopping counter: 1 out of 10.0
Validation loss decreased (1.028598 --> 1.028120).  Saving model ...
Validation loss decreased (1.028120 --> 1.022492).  Saving model ...
Validation loss decreased (1.022492 --> 1.020545).  Saving model ...
EarlyStopping counter: 1 out of 10.0
EarlyStopping counter: 2 out of 10.0
EarlyStopping counter: 3 out of 10.0
EarlyStopping counter: 4 out of 10.0
Validation loss decreased (1.020545 --> 1.017663).  Saving model ...
EarlyStopping counter: 1 out of 10.0
EarlyStopping counter: 2 out of 10.0
Validation loss decreased (1.017663 --> 1.013985).  Saving model ...
Validation loss decreased (1.013985 --> 1.008401).  Saving model ...
EarlyStopping counter: 1 out of 10.0
EarlyStopping counter: 2 out of 10.0
EarlyStopping counter: 3 out of 10.0
EarlyStopping counter: 4 out of 10.0
EarlyStopping counter: 5 out of 10.0
Validation loss decreased (1.008401 --> 1.007866).  Saving model ...
EarlyStopping counter: 1 out of 10.0
EarlyStopping counter: 2 out of 10.0
EarlyStopping counter: 3 out of 10.0
EarlyStopping counter: 4 out of 10.0
Validation loss decreased (1.007866 --> 1.005738).  Saving model ...
Validation loss decreased (1.005738 --> 1.005226).  Saving model ...
EarlyStopping counter: 1 out of 10.0
EarlyStopping counter: 2 out of 10.0
EarlyStopping counter: 3 out of 10.0
EarlyStopping counter: 4 out of 10.0
Validation loss decreased (1.005226 --> 1.004217).  Saving model ...
Validation loss decreased (1.004217 --> 1.003037).  Saving model ...
Validation loss decreased (1.003037 --> 1.001561).  Saving model ...
Validation loss decreased (1.001561 --> 0.999219).  Saving model ...
EarlyStopping counter: 1 out of 10.0
EarlyStopping counter: 2 out of 10.0
EarlyStopping counter: 3 out of 10.0
EarlyStopping counter: 4 out of 10.0
Validation loss decreased (0.999219 --> 0.997955).  Saving model ...
EarlyStopping counter: 1 out of 10.0
EarlyStopping counter: 2 out of 10.0
EarlyStopping counter: 3 out of 10.0
EarlyStopping counter: 4 out of 10.0
EarlyStopping counter: 5 out of 10.0
EarlyStopping counter: 6 out of 10.0
EarlyStopping counter: 7 out of 10.0
EarlyStopping counter: 8 out of 10.0
EarlyStopping counter: 9 out of 10.0
EarlyStopping counter: 10 out of 10.0
/localscratch/yinan.29351707.0/env/lib/python3.7/site-packages/torch/nn/functional.py:1794: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.
  warnings.warn("nn.functional.tanh is deprecated. Use torch.tanh instead.")
wandb: Waiting for W&B process to finish, PID 142741... (success).
wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: \ 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: | 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: / 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: \ 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: | 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: / 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: \ 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: | 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: / 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb:                                                                                
wandb: Run history:
wandb:     e_F1 â–â–‚â–„â–„â–„â–„â–„â–„â–…â–†â–†â–†â–†â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ
wandb:   e_loss â–ˆâ–‡â–†â–†â–†â–†â–…â–…â–…â–„â–„â–„â–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:     t_F1 â–â–â–‚â–ƒâ–‚â–ƒâ–„â–„â–„â–„â–…â–…â–…â–…â–…â–…â–…â–†â–†â–†â–†â–‡â–‡â–†â–†â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–ˆâ–ˆâ–‡â–ˆâ–ˆâ–ˆâ–ˆ
wandb:   t_loss â–ˆâ–ˆâ–‡â–‡â–‡â–†â–†â–†â–†â–†â–…â–…â–…â–…â–…â–„â–„â–„â–„â–„â–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–â–â–â–â–â–
wandb: 
wandb: Run summary:
wandb:     e_F1 57.86825
wandb:   e_loss 1.00149
wandb:     t_F1 72.79209
wandb:   t_loss 0.7391
wandb: 
wandb: Synced 4 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Synced icy-glitter-1: https://wandb.ai/yinanazhou/xl_512_bs_8_lr_1e06_es_10_lc_False_nr_True_sr_True_stem_False_lemma_True_repeat_3_fold_1/runs/22e3a4bp
wandb: Find logs at: ./wandb/run-20220327_215800-22e3a4bp/logs/debug.log
wandb: 

wandb: wandb version 0.12.11 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
2022-03-27 23:26:45.467179: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1
wandb: Tracking run with wandb version 0.12.5
wandb: Syncing run sunny-butterfly-1
wandb: â­ï¸ View project at https://wandb.ai/yinanazhou/xl_512_bs_8_lr_1e06_es_10_lc_False_nr_True_sr_True_stem_False_lemma_True_repeat_3_fold_2
wandb: ðŸš€ View run at https://wandb.ai/yinanazhou/xl_512_bs_8_lr_1e06_es_10_lc_False_nr_True_sr_True_stem_False_lemma_True_repeat_3_fold_2/runs/1xge6czh
wandb: Run data is saved locally in /project/6002780/yinan/Thesis_MER_Lyrics/lyric-emotion/wandb/run-20220327_232643-1xge6czh
wandb: Run `wandb offline` to turn off syncing.
wandb: Network error (ReadTimeout), entering retry loop.

Validation loss decreased (inf --> 1.403247).  Saving model ...
Validation loss decreased (1.403247 --> 1.386741).  Saving model ...
Validation loss decreased (1.386741 --> 1.374290).  Saving model ...
Validation loss decreased (1.374290 --> 1.364975).  Saving model ...
Validation loss decreased (1.364975 --> 1.357228).  Saving model ...
Validation loss decreased (1.357228 --> 1.350854).  Saving model ...
Validation loss decreased (1.350854 --> 1.345333).  Saving model ...
Validation loss decreased (1.345333 --> 1.340336).  Saving model ...
Validation loss decreased (1.340336 --> 1.335477).  Saving model ...
Validation loss decreased (1.335477 --> 1.330721).  Saving model ...
Validation loss decreased (1.330721 --> 1.325732).  Saving model ...
Validation loss decreased (1.325732 --> 1.320508).  Saving model ...
Validation loss decreased (1.320508 --> 1.315293).  Saving model ...
Validation loss decreased (1.315293 --> 1.311175).  Saving model ...
Validation loss decreased (1.311175 --> 1.306255).  Saving model ...
Validation loss decreased (1.306255 --> 1.300417).  Saving model ...
Validation loss decreased (1.300417 --> 1.294660).  Saving model ...
Validation loss decreased (1.294660 --> 1.288731).  Saving model ...
Validation loss decreased (1.288731 --> 1.282841).  Saving model ...
Validation loss decreased (1.282841 --> 1.276933).  Saving model ...
Validation loss decreased (1.276933 --> 1.270370).  Saving model ...
Validation loss decreased (1.270370 --> 1.264022).  Saving model ...
Validation loss decreased (1.264022 --> 1.256931).  Saving model ...
Validation loss decreased (1.256931 --> 1.250557).  Saving model ...
Validation loss decreased (1.250557 --> 1.242977).  Saving model ...
Validation loss decreased (1.242977 --> 1.235757).  Saving model ...
Validation loss decreased (1.235757 --> 1.228145).  Saving model ...
Validation loss decreased (1.228145 --> 1.220429).  Saving model ...
Validation loss decreased (1.220429 --> 1.213305).  Saving model ...
Validation loss decreased (1.213305 --> 1.205955).  Saving model ...
Validation loss decreased (1.205955 --> 1.198529).  Saving model ...
Validation loss decreased (1.198529 --> 1.191001).  Saving model ...
Validation loss decreased (1.191001 --> 1.182389).  Saving model ...
Validation loss decreased (1.182389 --> 1.174403).  Saving model ...
Validation loss decreased (1.174403 --> 1.166378).  Saving model ...
Validation loss decreased (1.166378 --> 1.158353).  Saving model ...
Validation loss decreased (1.158353 --> 1.148970).  Saving model ...
Validation loss decreased (1.148970 --> 1.141154).  Saving model ...
Validation loss decreased (1.141154 --> 1.133824).  Saving model ...
Validation loss decreased (1.133824 --> 1.125731).  Saving model ...
Validation loss decreased (1.125731 --> 1.118403).  Saving model ...
Validation loss decreased (1.118403 --> 1.111436).  Saving model ...
Validation loss decreased (1.111436 --> 1.105357).  Saving model ...
Validation loss decreased (1.105357 --> 1.100539).  Saving model ...
Validation loss decreased (1.100539 --> 1.093688).  Saving model ...
Validation loss decreased (1.093688 --> 1.086718).  Saving model ...
Validation loss decreased (1.086718 --> 1.081047).  Saving model ...
Validation loss decreased (1.081047 --> 1.077040).  Saving model ...
Validation loss decreased (1.077040 --> 1.071743).  Saving model ...
Validation loss decreased (1.071743 --> 1.066293).  Saving model ...
Validation loss decreased (1.066293 --> 1.061046).  Saving model ...
Validation loss decreased (1.061046 --> 1.055653).  Saving model ...
Validation loss decreased (1.055653 --> 1.051078).  Saving model ...
Validation loss decreased (1.051078 --> 1.047060).  Saving model ...
Validation loss decreased (1.047060 --> 1.042138).  Saving model ...
Validation loss decreased (1.042138 --> 1.038135).  Saving model ...
Validation loss decreased (1.038135 --> 1.032572).  Saving model ...
Validation loss decreased (1.032572 --> 1.027946).  Saving model ...
Validation loss decreased (1.027946 --> 1.024272).  Saving model ...
Validation loss decreased (1.024272 --> 1.020833).  Saving model ...
Validation loss decreased (1.020833 --> 1.017091).  Saving model ...
Validation loss decreased (1.017091 --> 1.013370).  Saving model ...
Validation loss decreased (1.013370 --> 1.008659).  Saving model ...
Validation loss decreased (1.008659 --> 1.004667).  Saving model ...
Validation loss decreased (1.004667 --> 1.001812).  Saving model ...
Validation loss decreased (1.001812 --> 0.998098).  Saving model ...
Validation loss decreased (0.998098 --> 0.995599).  Saving model ...
Validation loss decreased (0.995599 --> 0.991485).  Saving model ...
Validation loss decreased (0.991485 --> 0.988000).  Saving model ...
Validation loss decreased (0.988000 --> 0.984586).  Saving model ...
Validation loss decreased (0.984586 --> 0.983567).  Saving model ...
Validation loss decreased (0.983567 --> 0.979414).  Saving model ...
Validation loss decreased (0.979414 --> 0.975510).  Saving model ...
Validation loss decreased (0.975510 --> 0.971880).  Saving model ...
Validation loss decreased (0.971880 --> 0.968243).  Saving model ...
Validation loss decreased (0.968243 --> 0.966578).  Saving model ...
Validation loss decreased (0.966578 --> 0.964059).  Saving model ...
Validation loss decreased (0.964059 --> 0.962364).  Saving model ...
Validation loss decreased (0.962364 --> 0.960653).  Saving model ...
Validation loss decreased (0.960653 --> 0.958804).  Saving model ...
Validation loss decreased (0.958804 --> 0.955220).  Saving model ...
Validation loss decreased (0.955220 --> 0.950948).  Saving model ...
Validation loss decreased (0.950948 --> 0.949186).  Saving model ...
Validation loss decreased (0.949186 --> 0.948399).  Saving model ...
Validation loss decreased (0.948399 --> 0.945860).  Saving model ...
Validation loss decreased (0.945860 --> 0.944726).  Saving model ...
EarlyStopping counter: 1 out of 10.0
Validation loss decreased (0.944726 --> 0.941869).  Saving model ...
Validation loss decreased (0.941869 --> 0.939088).  Saving model ...
Validation loss decreased (0.939088 --> 0.935002).  Saving model ...
Validation loss decreased (0.935002 --> 0.933029).  Saving model ...
Validation loss decreased (0.933029 --> 0.931864).  Saving model ...
Validation loss decreased (0.931864 --> 0.929007).  Saving model ...
Validation loss decreased (0.929007 --> 0.927177).  Saving model ...
Validation loss decreased (0.927177 --> 0.924713).  Saving model ...
Validation loss decreased (0.924713 --> 0.923512).  Saving model ...
Validation loss decreased (0.923512 --> 0.921240).  Saving model ...
Validation loss decreased (0.921240 --> 0.920531).  Saving model ...
Validation loss decreased (0.920531 --> 0.920292).  Saving model ...
Validation loss decreased (0.920292 --> 0.917217).  Saving model ...
Validation loss decreased (0.917217 --> 0.916824).  Saving model ...
Validation loss decreased (0.916824 --> 0.915778).  Saving model ...
Validation loss decreased (0.915778 --> 0.913732).  Saving model ...
Validation loss decreased (0.913732 --> 0.911848).  Saving model ...
Validation loss decreased (0.911848 --> 0.909774).  Saving model ...
Validation loss decreased (0.909774 --> 0.908388).  Saving model ...
Validation loss decreased (0.908388 --> 0.906756).  Saving model ...
Validation loss decreased (0.906756 --> 0.905502).  Saving model ...
Validation loss decreased (0.905502 --> 0.905166).  Saving model ...
Validation loss decreased (0.905166 --> 0.904338).  Saving model ...
Validation loss decreased (0.904338 --> 0.902776).  Saving model ...
Validation loss decreased (0.902776 --> 0.901625).  Saving model ...
Validation loss decreased (0.901625 --> 0.900834).  Saving model ...
Validation loss decreased (0.900834 --> 0.899553).  Saving model ...
Validation loss decreased (0.899553 --> 0.898074).  Saving model ...
EarlyStopping counter: 1 out of 10.0
Validation loss decreased (0.898074 --> 0.897352).  Saving model ...
Validation loss decreased (0.897352 --> 0.897122).  Saving model ...
Validation loss decreased (0.897122 --> 0.896271).  Saving model ...
EarlyStopping counter: 1 out of 10.0
Validation loss decreased (0.896271 --> 0.895838).  Saving model ...
Validation loss decreased (0.895838 --> 0.894744).  Saving model ...
Validation loss decreased (0.894744 --> 0.893844).  Saving model ...
EarlyStopping counter: 1 out of 10.0
Validation loss decreased (0.893844 --> 0.893597).  Saving model ...
Validation loss decreased (0.893597 --> 0.892794).  Saving model ...
EarlyStopping counter: 1 out of 10.0
Validation loss decreased (0.892794 --> 0.891764).  Saving model ...
EarlyStopping counter: 1 out of 10.0
EarlyStopping counter: 2 out of 10.0
Validation loss decreased (0.891764 --> 0.891632).  Saving model ...
Validation loss decreased (0.891632 --> 0.889513).  Saving model ...
Validation loss decreased (0.889513 --> 0.888997).  Saving model ...
EarlyStopping counter: 1 out of 10.0
EarlyStopping counter: 2 out of 10.0
EarlyStopping counter: 3 out of 10.0
EarlyStopping counter: 4 out of 10.0
EarlyStopping counter: 5 out of 10.0
EarlyStopping counter: 6 out of 10.0
EarlyStopping counter: 7 out of 10.0
EarlyStopping counter: 8 out of 10.0
EarlyStopping counter: 9 out of 10.0
Validation loss decreased (0.888997 --> 0.887631).  Saving model ...
EarlyStopping counter: 1 out of 10.0
EarlyStopping counter: 2 out of 10.0
EarlyStopping counter: 3 out of 10.0
EarlyStopping counter: 4 out of 10.0
EarlyStopping counter: 5 out of 10.0
EarlyStopping counter: 6 out of 10.0
EarlyStopping counter: 7 out of 10.0
EarlyStopping counter: 8 out of 10.0
EarlyStopping counter: 9 out of 10.0
EarlyStopping counter: 10 out of 10.0
/localscratch/yinan.29351707.0/env/lib/python3.7/site-packages/torch/nn/functional.py:1794: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.
  warnings.warn("nn.functional.tanh is deprecated. Use torch.tanh instead.")
wandb: Waiting for W&B process to finish, PID 147487... (success).
wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: \ 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: | 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: / 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: \ 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: | 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: / 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: \ 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: | 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: / 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb:                                                                                
wandb: Run history:
wandb:     e_F1 â–â–‚â–ƒâ–„â–„â–…â–…â–†â–†â–†â–†â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ
wandb:   e_loss â–ˆâ–ˆâ–‡â–‡â–‡â–†â–†â–†â–…â–…â–„â–„â–„â–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–‚â–‚â–‚â–‚â–‚â–‚â–‚â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:     t_F1 â–â–‚â–‚â–ƒâ–ƒâ–„â–„â–„â–„â–…â–…â–…â–…â–†â–†â–†â–†â–†â–†â–†â–†â–†â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–ˆâ–‡â–ˆâ–ˆâ–‡â–ˆâ–ˆâ–ˆ
wandb:   t_loss â–ˆâ–ˆâ–ˆâ–‡â–‡â–‡â–‡â–†â–†â–†â–…â–…â–…â–…â–…â–„â–„â–„â–„â–„â–„â–ƒâ–ƒâ–ƒâ–‚â–ƒâ–‚â–ƒâ–‚â–‚â–‚â–‚â–â–‚â–â–â–‚â–â–â–
wandb: 
wandb: Run summary:
wandb:     e_F1 64.05936
wandb:   e_loss 0.88874
wandb:     t_F1 71.74701
wandb:   t_loss 0.74578
wandb: 
wandb: Synced 4 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Synced sunny-butterfly-1: https://wandb.ai/yinanazhou/xl_512_bs_8_lr_1e06_es_10_lc_False_nr_True_sr_True_stem_False_lemma_True_repeat_3_fold_2/runs/1xge6czh
wandb: Find logs at: ./wandb/run-20220327_232643-1xge6czh/logs/debug.log
wandb: 

wandb: wandb version 0.12.11 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
2022-03-28 01:06:31.835657: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1
wandb: Tracking run with wandb version 0.12.5
wandb: Syncing run restful-sea-1
wandb: â­ï¸ View project at https://wandb.ai/yinanazhou/xl_512_bs_8_lr_1e06_es_10_lc_False_nr_True_sr_True_stem_False_lemma_True_repeat_4_fold_1
wandb: ðŸš€ View run at https://wandb.ai/yinanazhou/xl_512_bs_8_lr_1e06_es_10_lc_False_nr_True_sr_True_stem_False_lemma_True_repeat_4_fold_1/runs/889veizq
wandb: Run data is saved locally in /project/6002780/yinan/Thesis_MER_Lyrics/lyric-emotion/wandb/run-20220328_010626-889veizq
wandb: Run `wandb offline` to turn off syncing.

Validation loss decreased (inf --> 1.389447).  Saving model ...
Validation loss decreased (1.389447 --> 1.377294).  Saving model ...
Validation loss decreased (1.377294 --> 1.368338).  Saving model ...
Validation loss decreased (1.368338 --> 1.361594).  Saving model ...
Validation loss decreased (1.361594 --> 1.356032).  Saving model ...
Validation loss decreased (1.356032 --> 1.350927).  Saving model ...
Validation loss decreased (1.350927 --> 1.346167).  Saving model ...
Validation loss decreased (1.346167 --> 1.341692).  Saving model ...
Validation loss decreased (1.341692 --> 1.337645).  Saving model ...
Validation loss decreased (1.337645 --> 1.333463).  Saving model ...
Validation loss decreased (1.333463 --> 1.328860).  Saving model ...
Validation loss decreased (1.328860 --> 1.324365).  Saving model ...
Validation loss decreased (1.324365 --> 1.319783).  Saving model ...
Validation loss decreased (1.319783 --> 1.315128).  Saving model ...
Validation loss decreased (1.315128 --> 1.310309).  Saving model ...
Validation loss decreased (1.310309 --> 1.304932).  Saving model ...
Validation loss decreased (1.304932 --> 1.299924).  Saving model ...
Validation loss decreased (1.299924 --> 1.294380).  Saving model ...
Validation loss decreased (1.294380 --> 1.289014).  Saving model ...
Validation loss decreased (1.289014 --> 1.282720).  Saving model ...
Validation loss decreased (1.282720 --> 1.276030).  Saving model ...
Validation loss decreased (1.276030 --> 1.269378).  Saving model ...
Validation loss decreased (1.269378 --> 1.262547).  Saving model ...
Validation loss decreased (1.262547 --> 1.255630).  Saving model ...
Validation loss decreased (1.255630 --> 1.248653).  Saving model ...
Validation loss decreased (1.248653 --> 1.242709).  Saving model ...
Validation loss decreased (1.242709 --> 1.235468).  Saving model ...
Validation loss decreased (1.235468 --> 1.228575).  Saving model ...
Validation loss decreased (1.228575 --> 1.222581).  Saving model ...
Validation loss decreased (1.222581 --> 1.216139).  Saving model ...
Validation loss decreased (1.216139 --> 1.209349).  Saving model ...
Validation loss decreased (1.209349 --> 1.203378).  Saving model ...
Validation loss decreased (1.203378 --> 1.198091).  Saving model ...
Validation loss decreased (1.198091 --> 1.190661).  Saving model ...
Validation loss decreased (1.190661 --> 1.185500).  Saving model ...
Validation loss decreased (1.185500 --> 1.179430).  Saving model ...
Validation loss decreased (1.179430 --> 1.173771).  Saving model ...
Validation loss decreased (1.173771 --> 1.167655).  Saving model ...
Validation loss decreased (1.167655 --> 1.162368).  Saving model ...
Validation loss decreased (1.162368 --> 1.157629).  Saving model ...
Validation loss decreased (1.157629 --> 1.153137).  Saving model ...
Validation loss decreased (1.153137 --> 1.147103).  Saving model ...
Validation loss decreased (1.147103 --> 1.142382).  Saving model ...
Validation loss decreased (1.142382 --> 1.138096).  Saving model ...
Validation loss decreased (1.138096 --> 1.131472).  Saving model ...
Validation loss decreased (1.131472 --> 1.126031).  Saving model ...
Validation loss decreased (1.126031 --> 1.122670).  Saving model ...
Validation loss decreased (1.122670 --> 1.116830).  Saving model ...
Validation loss decreased (1.116830 --> 1.112421).  Saving model ...
Validation loss decreased (1.112421 --> 1.107456).  Saving model ...
Validation loss decreased (1.107456 --> 1.102135).  Saving model ...
Validation loss decreased (1.102135 --> 1.097778).  Saving model ...
Validation loss decreased (1.097778 --> 1.094342).  Saving model ...
Validation loss decreased (1.094342 --> 1.091022).  Saving model ...
Validation loss decreased (1.091022 --> 1.087241).  Saving model ...
Validation loss decreased (1.087241 --> 1.083784).  Saving model ...
Validation loss decreased (1.083784 --> 1.079566).  Saving model ...
Validation loss decreased (1.079566 --> 1.075290).  Saving model ...
Validation loss decreased (1.075290 --> 1.071011).  Saving model ...
Validation loss decreased (1.071011 --> 1.066949).  Saving model ...
Validation loss decreased (1.066949 --> 1.062862).  Saving model ...
Validation loss decreased (1.062862 --> 1.059282).  Saving model ...
Validation loss decreased (1.059282 --> 1.055190).  Saving model ...
Validation loss decreased (1.055190 --> 1.052765).  Saving model ...
Validation loss decreased (1.052765 --> 1.050276).  Saving model ...
Validation loss decreased (1.050276 --> 1.046014).  Saving model ...
Validation loss decreased (1.046014 --> 1.042659).  Saving model ...
Validation loss decreased (1.042659 --> 1.039353).  Saving model ...
Validation loss decreased (1.039353 --> 1.035648).  Saving model ...
Validation loss decreased (1.035648 --> 1.033355).  Saving model ...
Validation loss decreased (1.033355 --> 1.030116).  Saving model ...
Validation loss decreased (1.030116 --> 1.026424).  Saving model ...
Validation loss decreased (1.026424 --> 1.024074).  Saving model ...
Validation loss decreased (1.024074 --> 1.021162).  Saving model ...
Validation loss decreased (1.021162 --> 1.019522).  Saving model ...
Validation loss decreased (1.019522 --> 1.017253).  Saving model ...
Validation loss decreased (1.017253 --> 1.013877).  Saving model ...
Validation loss decreased (1.013877 --> 1.012232).  Saving model ...
Validation loss decreased (1.012232 --> 1.010079).  Saving model ...
Validation loss decreased (1.010079 --> 1.007395).  Saving model ...
Validation loss decreased (1.007395 --> 1.005762).  Saving model ...
Validation loss decreased (1.005762 --> 1.004145).  Saving model ...
Validation loss decreased (1.004145 --> 1.002526).  Saving model ...
Validation loss decreased (1.002526 --> 0.999298).  Saving model ...
Validation loss decreased (0.999298 --> 0.996619).  Saving model ...
Validation loss decreased (0.996619 --> 0.994499).  Saving model ...
Validation loss decreased (0.994499 --> 0.992910).  Saving model ...
Validation loss decreased (0.992910 --> 0.991532).  Saving model ...
Validation loss decreased (0.991532 --> 0.989408).  Saving model ...
Validation loss decreased (0.989408 --> 0.988982).  Saving model ...
Validation loss decreased (0.988982 --> 0.987568).  Saving model ...
Validation loss decreased (0.987568 --> 0.985735).  Saving model ...
Validation loss decreased (0.985735 --> 0.984216).  Saving model ...
Validation loss decreased (0.984216 --> 0.982247).  Saving model ...
Validation loss decreased (0.982247 --> 0.981167).  Saving model ...
Validation loss decreased (0.981167 --> 0.978961).  Saving model ...
Validation loss decreased (0.978961 --> 0.978542).  Saving model ...
Validation loss decreased (0.978542 --> 0.975890).  Saving model ...
Validation loss decreased (0.975890 --> 0.974758).  Saving model ...
Validation loss decreased (0.974758 --> 0.973592).  Saving model ...
Validation loss decreased (0.973592 --> 0.973117).  Saving model ...
EarlyStopping counter: 1 out of 10.0
Validation loss decreased (0.973117 --> 0.971512).  Saving model ...
EarlyStopping counter: 1 out of 10.0
Validation loss decreased (0.971512 --> 0.969478).  Saving model ...
Validation loss decreased (0.969478 --> 0.968881).  Saving model ...
Validation loss decreased (0.968881 --> 0.966996).  Saving model ...
Validation loss decreased (0.966996 --> 0.965300).  Saving model ...
Validation loss decreased (0.965300 --> 0.964183).  Saving model ...
EarlyStopping counter: 1 out of 10.0
Validation loss decreased (0.964183 --> 0.964173).  Saving model ...
Validation loss decreased (0.964173 --> 0.962736).  Saving model ...
EarlyStopping counter: 1 out of 10.0
Validation loss decreased (0.962736 --> 0.962100).  Saving model ...
Validation loss decreased (0.962100 --> 0.961385).  Saving model ...
EarlyStopping counter: 1 out of 10.0
EarlyStopping counter: 2 out of 10.0
EarlyStopping counter: 3 out of 10.0
Validation loss decreased (0.961385 --> 0.959087).  Saving model ...
Validation loss decreased (0.959087 --> 0.958616).  Saving model ...
Validation loss decreased (0.958616 --> 0.958143).  Saving model ...
EarlyStopping counter: 1 out of 10.0
Validation loss decreased (0.958143 --> 0.956589).  Saving model ...
Validation loss decreased (0.956589 --> 0.956121).  Saving model ...
Validation loss decreased (0.956121 --> 0.955493).  Saving model ...
EarlyStopping counter: 1 out of 10.0
Validation loss decreased (0.955493 --> 0.955254).  Saving model ...
EarlyStopping counter: 1 out of 10.0
EarlyStopping counter: 2 out of 10.0
EarlyStopping counter: 3 out of 10.0
EarlyStopping counter: 4 out of 10.0
EarlyStopping counter: 5 out of 10.0
EarlyStopping counter: 6 out of 10.0
EarlyStopping counter: 7 out of 10.0
EarlyStopping counter: 8 out of 10.0
EarlyStopping counter: 9 out of 10.0
EarlyStopping counter: 10 out of 10.0
/localscratch/yinan.29351707.0/env/lib/python3.7/site-packages/torch/nn/functional.py:1794: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.
  warnings.warn("nn.functional.tanh is deprecated. Use torch.tanh instead.")
wandb: Waiting for W&B process to finish, PID 152858... (success).
wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: \ 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: | 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: / 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: \ 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: | 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: / 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: \ 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: | 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: / 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: \ 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: | 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: / 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: \ 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: | 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: / 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: \ 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb:                                                                                
wandb: Run history:
wandb:     e_F1 â–â–‚â–ƒâ–…â–…â–…â–…â–…â–…â–…â–†â–†â–†â–†â–†â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ
wandb:   e_loss â–ˆâ–ˆâ–‡â–‡â–‡â–‡â–†â–†â–†â–…â–…â–…â–„â–„â–„â–ƒâ–ƒâ–ƒâ–ƒâ–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:     t_F1 â–â–‚â–ƒâ–ƒâ–ƒâ–ƒâ–„â–„â–…â–…â–…â–…â–…â–†â–†â–†â–†â–†â–†â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–ˆâ–‡â–‡â–ˆâ–‡â–ˆâ–‡â–ˆâ–‡â–ˆâ–ˆâ–ˆ
wandb:   t_loss â–ˆâ–ˆâ–ˆâ–‡â–‡â–‡â–‡â–†â–†â–†â–…â–…â–…â–…â–„â–„â–„â–„â–„â–„â–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–‚â–‚â–‚â–‚â–‚â–‚â–‚â–â–â–â–â–â–â–
wandb: 
wandb: Run summary:
wandb:     e_F1 60.52867
wandb:   e_loss 0.95821
wandb:     t_F1 73.51733
wandb:   t_loss 0.69776
wandb: 
wandb: Synced 4 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Synced restful-sea-1: https://wandb.ai/yinanazhou/xl_512_bs_8_lr_1e06_es_10_lc_False_nr_True_sr_True_stem_False_lemma_True_repeat_4_fold_1/runs/889veizq
wandb: Find logs at: ./wandb/run-20220328_010626-889veizq/logs/debug.log
wandb: 

wandb: wandb version 0.12.11 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
2022-03-28 02:37:15.083287: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1
wandb: Tracking run with wandb version 0.12.5
wandb: Syncing run sparkling-aardvark-1
wandb: â­ï¸ View project at https://wandb.ai/yinanazhou/xl_512_bs_8_lr_1e06_es_10_lc_False_nr_True_sr_True_stem_False_lemma_True_repeat_4_fold_2
wandb: ðŸš€ View run at https://wandb.ai/yinanazhou/xl_512_bs_8_lr_1e06_es_10_lc_False_nr_True_sr_True_stem_False_lemma_True_repeat_4_fold_2/runs/3evrzc0a
wandb: Run data is saved locally in /project/6002780/yinan/Thesis_MER_Lyrics/lyric-emotion/wandb/run-20220328_023712-3evrzc0a
wandb: Run `wandb offline` to turn off syncing.

Validation loss decreased (inf --> 1.449963).  Saving model ...
Validation loss decreased (1.449963 --> 1.421678).  Saving model ...
Validation loss decreased (1.421678 --> 1.399326).  Saving model ...
Validation loss decreased (1.399326 --> 1.382628).  Saving model ...
Validation loss decreased (1.382628 --> 1.370197).  Saving model ...
Validation loss decreased (1.370197 --> 1.360182).  Saving model ...
Validation loss decreased (1.360182 --> 1.351494).  Saving model ...
Validation loss decreased (1.351494 --> 1.344355).  Saving model ...
Validation loss decreased (1.344355 --> 1.337253).  Saving model ...
Validation loss decreased (1.337253 --> 1.331596).  Saving model ...
Validation loss decreased (1.331596 --> 1.326268).  Saving model ...
Validation loss decreased (1.326268 --> 1.321484).  Saving model ...
Validation loss decreased (1.321484 --> 1.316531).  Saving model ...
Validation loss decreased (1.316531 --> 1.311223).  Saving model ...
Validation loss decreased (1.311223 --> 1.305499).  Saving model ...
Validation loss decreased (1.305499 --> 1.300454).  Saving model ...
Validation loss decreased (1.300454 --> 1.294395).  Saving model ...
Validation loss decreased (1.294395 --> 1.288268).  Saving model ...
Validation loss decreased (1.288268 --> 1.281233).  Saving model ...
Validation loss decreased (1.281233 --> 1.274898).  Saving model ...
Validation loss decreased (1.274898 --> 1.270657).  Saving model ...
Validation loss decreased (1.270657 --> 1.264861).  Saving model ...
Validation loss decreased (1.264861 --> 1.257242).  Saving model ...
Validation loss decreased (1.257242 --> 1.252128).  Saving model ...
Validation loss decreased (1.252128 --> 1.244697).  Saving model ...
Validation loss decreased (1.244697 --> 1.237078).  Saving model ...
Validation loss decreased (1.237078 --> 1.229391).  Saving model ...
Validation loss decreased (1.229391 --> 1.220549).  Saving model ...
Validation loss decreased (1.220549 --> 1.213341).  Saving model ...
Validation loss decreased (1.213341 --> 1.207166).  Saving model ...
Validation loss decreased (1.207166 --> 1.198882).  Saving model ...
Validation loss decreased (1.198882 --> 1.192443).  Saving model ...
Validation loss decreased (1.192443 --> 1.184806).  Saving model ...
Validation loss decreased (1.184806 --> 1.181340).  Saving model ...
Validation loss decreased (1.181340 --> 1.175761).  Saving model ...
Validation loss decreased (1.175761 --> 1.168684).  Saving model ...
Validation loss decreased (1.168684 --> 1.161597).  Saving model ...
Validation loss decreased (1.161597 --> 1.155249).  Saving model ...
Validation loss decreased (1.155249 --> 1.149735).  Saving model ...
Validation loss decreased (1.149735 --> 1.139966).  Saving model ...
Validation loss decreased (1.139966 --> 1.133501).  Saving model ...
Validation loss decreased (1.133501 --> 1.130037).  Saving model ...
Validation loss decreased (1.130037 --> 1.124453).  Saving model ...
Validation loss decreased (1.124453 --> 1.122710).  Saving model ...
Validation loss decreased (1.122710 --> 1.119026).  Saving model ...
Validation loss decreased (1.119026 --> 1.111428).  Saving model ...
Validation loss decreased (1.111428 --> 1.104904).  Saving model ...
Validation loss decreased (1.104904 --> 1.099606).  Saving model ...
Validation loss decreased (1.099606 --> 1.093972).  Saving model ...
Validation loss decreased (1.093972 --> 1.089252).  Saving model ...
Validation loss decreased (1.089252 --> 1.085354).  Saving model ...
Validation loss decreased (1.085354 --> 1.079035).  Saving model ...
Validation loss decreased (1.079035 --> 1.074919).  Saving model ...
Validation loss decreased (1.074919 --> 1.069580).  Saving model ...
Validation loss decreased (1.069580 --> 1.064999).  Saving model ...
Validation loss decreased (1.064999 --> 1.060967).  Saving model ...
Validation loss decreased (1.060967 --> 1.057408).  Saving model ...
Validation loss decreased (1.057408 --> 1.051369).  Saving model ...
Validation loss decreased (1.051369 --> 1.049637).  Saving model ...
Validation loss decreased (1.049637 --> 1.047792).  Saving model ...
Validation loss decreased (1.047792 --> 1.043289).  Saving model ...
Validation loss decreased (1.043289 --> 1.039759).  Saving model ...
Validation loss decreased (1.039759 --> 1.035250).  Saving model ...
Validation loss decreased (1.035250 --> 1.030007).  Saving model ...
Validation loss decreased (1.030007 --> 1.026423).  Saving model ...
Validation loss decreased (1.026423 --> 1.024724).  Saving model ...
Validation loss decreased (1.024724 --> 1.023810).  Saving model ...
Validation loss decreased (1.023810 --> 1.020747).  Saving model ...
Validation loss decreased (1.020747 --> 1.016963).  Saving model ...
Validation loss decreased (1.016963 --> 1.011327).  Saving model ...
Validation loss decreased (1.011327 --> 1.010468).  Saving model ...
Validation loss decreased (1.010468 --> 1.007914).  Saving model ...
Validation loss decreased (1.007914 --> 1.003536).  Saving model ...
Validation loss decreased (1.003536 --> 1.001348).  Saving model ...
Validation loss decreased (1.001348 --> 0.999423).  Saving model ...
EarlyStopping counter: 1 out of 10.0
Validation loss decreased (0.999423 --> 0.996713).  Saving model ...
Validation loss decreased (0.996713 --> 0.992939).  Saving model ...
Validation loss decreased (0.992939 --> 0.989811).  Saving model ...
EarlyStopping counter: 1 out of 10.0
EarlyStopping counter: 2 out of 10.0
Validation loss decreased (0.989811 --> 0.987680).  Saving model ...
Validation loss decreased (0.987680 --> 0.985960).  Saving model ...
Validation loss decreased (0.985960 --> 0.983266).  Saving model ...
Validation loss decreased (0.983266 --> 0.979702).  Saving model ...
Validation loss decreased (0.979702 --> 0.979198).  Saving model ...
Validation loss decreased (0.979198 --> 0.978358).  Saving model ...
Validation loss decreased (0.978358 --> 0.978225).  Saving model ...
EarlyStopping counter: 1 out of 10.0
EarlyStopping counter: 2 out of 10.0
Validation loss decreased (0.978225 --> 0.974250).  Saving model ...
Validation loss decreased (0.974250 --> 0.973653).  Saving model ...
Validation loss decreased (0.973653 --> 0.971755).  Saving model ...
Validation loss decreased (0.971755 --> 0.970854).  Saving model ...
Validation loss decreased (0.970854 --> 0.969829).  Saving model ...
Validation loss decreased (0.969829 --> 0.968413).  Saving model ...
Validation loss decreased (0.968413 --> 0.966064).  Saving model ...
Validation loss decreased (0.966064 --> 0.964440).  Saving model ...
EarlyStopping counter: 1 out of 10.0
Validation loss decreased (0.964440 --> 0.963614).  Saving model ...
EarlyStopping counter: 1 out of 10.0
EarlyStopping counter: 2 out of 10.0
EarlyStopping counter: 3 out of 10.0
Validation loss decreased (0.963614 --> 0.961859).  Saving model ...
Validation loss decreased (0.961859 --> 0.958809).  Saving model ...
Validation loss decreased (0.958809 --> 0.957991).  Saving model ...
EarlyStopping counter: 1 out of 10.0
EarlyStopping counter: 2 out of 10.0
EarlyStopping counter: 3 out of 10.0
Validation loss decreased (0.957991 --> 0.955466).  Saving model ...
EarlyStopping counter: 1 out of 10.0
EarlyStopping counter: 2 out of 10.0
EarlyStopping counter: 3 out of 10.0
EarlyStopping counter: 4 out of 10.0
EarlyStopping counter: 5 out of 10.0
Validation loss decreased (0.955466 --> 0.954379).  Saving model ...
EarlyStopping counter: 1 out of 10.0
EarlyStopping counter: 2 out of 10.0
EarlyStopping counter: 3 out of 10.0
EarlyStopping counter: 4 out of 10.0
EarlyStopping counter: 5 out of 10.0
Validation loss decreased (0.954379 --> 0.951665).  Saving model ...
Validation loss decreased (0.951665 --> 0.951162).  Saving model ...
EarlyStopping counter: 1 out of 10.0
EarlyStopping counter: 2 out of 10.0
EarlyStopping counter: 3 out of 10.0
EarlyStopping counter: 4 out of 10.0
EarlyStopping counter: 5 out of 10.0
EarlyStopping counter: 6 out of 10.0
EarlyStopping counter: 7 out of 10.0
EarlyStopping counter: 8 out of 10.0
EarlyStopping counter: 9 out of 10.0
EarlyStopping counter: 10 out of 10.0
/localscratch/yinan.29351707.0/env/lib/python3.7/site-packages/torch/nn/functional.py:1794: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.
  warnings.warn("nn.functional.tanh is deprecated. Use torch.tanh instead.")
wandb: Waiting for W&B process to finish, PID 157673... (success).
wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: \ 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: | 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: / 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: \ 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: | 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: / 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: \ 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: | 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: / 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb:                                                                                
wandb: Run history:
wandb:     e_F1 â–â–‚â–ƒâ–„â–…â–…â–…â–…â–†â–†â–†â–†â–‡â–‡â–‡â–‡â–‡â–‡â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ
wandb:   e_loss â–ˆâ–‡â–‡â–‡â–†â–†â–†â–…â–…â–…â–„â–„â–„â–„â–ƒâ–ƒâ–ƒâ–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:     t_F1 â–â–â–‚â–‚â–ƒâ–ƒâ–„â–„â–„â–„â–…â–…â–…â–…â–†â–†â–†â–†â–‡â–†â–†â–‡â–‡â–†â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ
wandb:   t_loss â–ˆâ–ˆâ–‡â–‡â–‡â–‡â–‡â–†â–†â–†â–†â–…â–…â–…â–…â–„â–„â–„â–„â–ƒâ–„â–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–â–â–â–
wandb: 
wandb: Run summary:
wandb:     e_F1 61.12491
wandb:   e_loss 0.95324
wandb:     t_F1 70.6992
wandb:   t_loss 0.76228
wandb: 
wandb: Synced 4 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Synced sparkling-aardvark-1: https://wandb.ai/yinanazhou/xl_512_bs_8_lr_1e06_es_10_lc_False_nr_True_sr_True_stem_False_lemma_True_repeat_4_fold_2/runs/3evrzc0a
wandb: Find logs at: ./wandb/run-20220328_023712-3evrzc0a/logs/debug.log
wandb: 

wandb: wandb version 0.12.11 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
2022-03-28 04:04:46.181380: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1
wandb: Tracking run with wandb version 0.12.5
wandb: Syncing run winter-pine-1
wandb: â­ï¸ View project at https://wandb.ai/yinanazhou/xl_512_bs_8_lr_1e06_es_10_lc_False_nr_True_sr_True_stem_False_lemma_True_repeat_5_fold_1
wandb: ðŸš€ View run at https://wandb.ai/yinanazhou/xl_512_bs_8_lr_1e06_es_10_lc_False_nr_True_sr_True_stem_False_lemma_True_repeat_5_fold_1/runs/2obwmtb7
wandb: Run data is saved locally in /project/6002780/yinan/Thesis_MER_Lyrics/lyric-emotion/wandb/run-20220328_040443-2obwmtb7
wandb: Run `wandb offline` to turn off syncing.

Validation loss decreased (inf --> 1.405862).  Saving model ...
Validation loss decreased (1.405862 --> 1.394143).  Saving model ...
Validation loss decreased (1.394143 --> 1.384631).  Saving model ...
Validation loss decreased (1.384631 --> 1.377359).  Saving model ...
Validation loss decreased (1.377359 --> 1.371532).  Saving model ...
Validation loss decreased (1.371532 --> 1.366205).  Saving model ...
Validation loss decreased (1.366205 --> 1.361487).  Saving model ...
Validation loss decreased (1.361487 --> 1.356925).  Saving model ...
Validation loss decreased (1.356925 --> 1.352191).  Saving model ...
Validation loss decreased (1.352191 --> 1.347451).  Saving model ...
Validation loss decreased (1.347451 --> 1.343127).  Saving model ...
Validation loss decreased (1.343127 --> 1.338731).  Saving model ...
Validation loss decreased (1.338731 --> 1.334056).  Saving model ...
Validation loss decreased (1.334056 --> 1.328871).  Saving model ...
Validation loss decreased (1.328871 --> 1.323493).  Saving model ...
Validation loss decreased (1.323493 --> 1.318094).  Saving model ...
Validation loss decreased (1.318094 --> 1.312487).  Saving model ...
Validation loss decreased (1.312487 --> 1.307392).  Saving model ...
Validation loss decreased (1.307392 --> 1.301807).  Saving model ...
Validation loss decreased (1.301807 --> 1.295514).  Saving model ...
Validation loss decreased (1.295514 --> 1.289464).  Saving model ...
Validation loss decreased (1.289464 --> 1.283194).  Saving model ...
Validation loss decreased (1.283194 --> 1.277017).  Saving model ...
Validation loss decreased (1.277017 --> 1.270179).  Saving model ...
Validation loss decreased (1.270179 --> 1.263610).  Saving model ...
Validation loss decreased (1.263610 --> 1.256932).  Saving model ...
Validation loss decreased (1.256932 --> 1.249921).  Saving model ...
Validation loss decreased (1.249921 --> 1.243619).  Saving model ...
Validation loss decreased (1.243619 --> 1.237376).  Saving model ...
Validation loss decreased (1.237376 --> 1.230844).  Saving model ...
Validation loss decreased (1.230844 --> 1.225345).  Saving model ...
Validation loss decreased (1.225345 --> 1.218292).  Saving model ...
Validation loss decreased (1.218292 --> 1.213412).  Saving model ...
Validation loss decreased (1.213412 --> 1.207001).  Saving model ...
Validation loss decreased (1.207001 --> 1.200610).  Saving model ...
Validation loss decreased (1.200610 --> 1.194335).  Saving model ...
Validation loss decreased (1.194335 --> 1.187351).  Saving model ...
Validation loss decreased (1.187351 --> 1.181592).  Saving model ...
Validation loss decreased (1.181592 --> 1.177943).  Saving model ...
Validation loss decreased (1.177943 --> 1.171560).  Saving model ...
Validation loss decreased (1.171560 --> 1.164508).  Saving model ...
Validation loss decreased (1.164508 --> 1.158801).  Saving model ...
Validation loss decreased (1.158801 --> 1.153741).  Saving model ...
Validation loss decreased (1.153741 --> 1.147946).  Saving model ...
Validation loss decreased (1.147946 --> 1.142164).  Saving model ...
Validation loss decreased (1.142164 --> 1.136698).  Saving model ...
Validation loss decreased (1.136698 --> 1.129953).  Saving model ...
Validation loss decreased (1.129953 --> 1.123003).  Saving model ...
Validation loss decreased (1.123003 --> 1.120277).  Saving model ...
Validation loss decreased (1.120277 --> 1.114612).  Saving model ...
Validation loss decreased (1.114612 --> 1.108004).  Saving model ...
Validation loss decreased (1.108004 --> 1.103683).  Saving model ...
Validation loss decreased (1.103683 --> 1.097348).  Saving model ...
Validation loss decreased (1.097348 --> 1.092997).  Saving model ...
Validation loss decreased (1.092997 --> 1.089513).  Saving model ...
Validation loss decreased (1.089513 --> 1.083945).  Saving model ...
Validation loss decreased (1.083945 --> 1.078151).  Saving model ...
Validation loss decreased (1.078151 --> 1.074247).  Saving model ...
Validation loss decreased (1.074247 --> 1.070175).  Saving model ...
Validation loss decreased (1.070175 --> 1.065593).  Saving model ...
Validation loss decreased (1.065593 --> 1.061030).  Saving model ...
Validation loss decreased (1.061030 --> 1.056668).  Saving model ...
Validation loss decreased (1.056668 --> 1.053428).  Saving model ...
Validation loss decreased (1.053428 --> 1.049505).  Saving model ...
Validation loss decreased (1.049505 --> 1.047044).  Saving model ...
Validation loss decreased (1.047044 --> 1.043491).  Saving model ...
Validation loss decreased (1.043491 --> 1.039206).  Saving model ...
Validation loss decreased (1.039206 --> 1.036432).  Saving model ...
Validation loss decreased (1.036432 --> 1.031682).  Saving model ...
Validation loss decreased (1.031682 --> 1.026667).  Saving model ...
Validation loss decreased (1.026667 --> 1.024595).  Saving model ...
Validation loss decreased (1.024595 --> 1.021254).  Saving model ...
Validation loss decreased (1.021254 --> 1.017741).  Saving model ...
Validation loss decreased (1.017741 --> 1.015324).  Saving model ...
Validation loss decreased (1.015324 --> 1.013618).  Saving model ...
Validation loss decreased (1.013618 --> 1.010192).  Saving model ...
Validation loss decreased (1.010192 --> 1.006481).  Saving model ...
Validation loss decreased (1.006481 --> 1.002644).  Saving model ...
Validation loss decreased (1.002644 --> 0.999336).  Saving model ...
Validation loss decreased (0.999336 --> 0.995520).  Saving model ...
Validation loss decreased (0.995520 --> 0.992040).  Saving model ...
Validation loss decreased (0.992040 --> 0.990628).  Saving model ...
Validation loss decreased (0.990628 --> 0.988391).  Saving model ...
Validation loss decreased (0.988391 --> 0.986874).  Saving model ...
Validation loss decreased (0.986874 --> 0.984790).  Saving model ...
Validation loss decreased (0.984790 --> 0.984008).  Saving model ...
Validation loss decreased (0.984008 --> 0.982222).  Saving model ...
Validation loss decreased (0.982222 --> 0.978511).  Saving model ...
Validation loss decreased (0.978511 --> 0.976665).  Saving model ...
Validation loss decreased (0.976665 --> 0.973686).  Saving model ...
Validation loss decreased (0.973686 --> 0.970076).  Saving model ...
Validation loss decreased (0.970076 --> 0.969463).  Saving model ...
Validation loss decreased (0.969463 --> 0.968449).  Saving model ...
Validation loss decreased (0.968449 --> 0.966025).  Saving model ...
Validation loss decreased (0.966025 --> 0.964445).  Saving model ...
Validation loss decreased (0.964445 --> 0.963281).  Saving model ...
Validation loss decreased (0.963281 --> 0.961145).  Saving model ...
Validation loss decreased (0.961145 --> 0.959138).  Saving model ...
Validation loss decreased (0.959138 --> 0.956503).  Saving model ...
Validation loss decreased (0.956503 --> 0.955501).  Saving model ...
Validation loss decreased (0.955501 --> 0.953999).  Saving model ...
Validation loss decreased (0.953999 --> 0.952564).  Saving model ...
Validation loss decreased (0.952564 --> 0.951248).  Saving model ...
Validation loss decreased (0.951248 --> 0.949260).  Saving model ...
Validation loss decreased (0.949260 --> 0.949052).  Saving model ...
Validation loss decreased (0.949052 --> 0.948424).  Saving model ...
Validation loss decreased (0.948424 --> 0.946806).  Saving model ...
Validation loss decreased (0.946806 --> 0.945587).  Saving model ...
Validation loss decreased (0.945587 --> 0.944141).  Saving model ...
Validation loss decreased (0.944141 --> 0.943104).  Saving model ...
Validation loss decreased (0.943104 --> 0.941909).  Saving model ...
Validation loss decreased (0.941909 --> 0.940400).  Saving model ...
Validation loss decreased (0.940400 --> 0.940217).  Saving model ...
Validation loss decreased (0.940217 --> 0.938483).  Saving model ...
EarlyStopping counter: 1 out of 10.0
EarlyStopping counter: 2 out of 10.0
Validation loss decreased (0.938483 --> 0.937000).  Saving model ...
Validation loss decreased (0.937000 --> 0.936380).  Saving model ...
Validation loss decreased (0.936380 --> 0.936066).  Saving model ...
Validation loss decreased (0.936066 --> 0.934464).  Saving model ...
Validation loss decreased (0.934464 --> 0.933341).  Saving model ...
Validation loss decreased (0.933341 --> 0.933112).  Saving model ...
Validation loss decreased (0.933112 --> 0.932680).  Saving model ...
EarlyStopping counter: 1 out of 10.0
Validation loss decreased (0.932680 --> 0.932413).  Saving model ...
Validation loss decreased (0.932413 --> 0.931822).  Saving model ...
Validation loss decreased (0.931822 --> 0.930416).  Saving model ...
EarlyStopping counter: 1 out of 10.0
EarlyStopping counter: 2 out of 10.0
Validation loss decreased (0.930416 --> 0.929858).  Saving model ...
EarlyStopping counter: 1 out of 10.0
EarlyStopping counter: 2 out of 10.0
Validation loss decreased (0.929858 --> 0.929745).  Saving model ...
EarlyStopping counter: 1 out of 10.0
Validation loss decreased (0.929745 --> 0.929555).  Saving model ...
EarlyStopping counter: 1 out of 10.0
Validation loss decreased (0.929555 --> 0.929227).  Saving model ...
EarlyStopping counter: 1 out of 10.0
Validation loss decreased (0.929227 --> 0.928554).  Saving model ...
Validation loss decreased (0.928554 --> 0.927627).  Saving model ...
EarlyStopping counter: 1 out of 10.0
EarlyStopping counter: 2 out of 10.0
Validation loss decreased (0.927627 --> 0.927479).  Saving model ...
EarlyStopping counter: 1 out of 10.0
EarlyStopping counter: 2 out of 10.0
EarlyStopping counter: 3 out of 10.0
EarlyStopping counter: 4 out of 10.0
EarlyStopping counter: 5 out of 10.0
EarlyStopping counter: 6 out of 10.0
EarlyStopping counter: 7 out of 10.0
EarlyStopping counter: 8 out of 10.0
EarlyStopping counter: 9 out of 10.0
EarlyStopping counter: 10 out of 10.0
/localscratch/yinan.29351707.0/env/lib/python3.7/site-packages/torch/nn/functional.py:1794: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.
  warnings.warn("nn.functional.tanh is deprecated. Use torch.tanh instead.")
wandb: Waiting for W&B process to finish, PID 162354... (success).
wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: \ 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: | 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: / 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: \ 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: | 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: / 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: \ 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: | 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: / 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb:                                                                                
wandb: Run history:
wandb:     e_F1 â–â–â–ƒâ–ƒâ–„â–„â–…â–…â–…â–†â–†â–†â–†â–†â–†â–†â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ
wandb:   e_loss â–ˆâ–ˆâ–‡â–‡â–‡â–‡â–†â–†â–…â–…â–…â–„â–„â–„â–ƒâ–ƒâ–ƒâ–ƒâ–‚â–‚â–‚â–‚â–‚â–‚â–‚â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:     t_F1 â–â–â–‚â–‚â–ƒâ–ƒâ–ƒâ–„â–ƒâ–„â–„â–…â–…â–…â–…â–…â–†â–…â–†â–†â–‡â–†â–†â–‡â–†â–‡â–‡â–‡â–‡â–‡â–‡â–ˆâ–‡â–‡â–‡â–ˆâ–‡â–ˆâ–ˆâ–ˆ
wandb:   t_loss â–ˆâ–ˆâ–ˆâ–ˆâ–‡â–‡â–‡â–‡â–†â–†â–†â–…â–…â–…â–…â–…â–„â–„â–„â–„â–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–â–â–â–â–
wandb: 
wandb: Run summary:
wandb:     e_F1 59.98595
wandb:   e_loss 0.93143
wandb:     t_F1 75.83852
wandb:   t_loss 0.70382
wandb: 
wandb: Synced 4 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Synced winter-pine-1: https://wandb.ai/yinanazhou/xl_512_bs_8_lr_1e06_es_10_lc_False_nr_True_sr_True_stem_False_lemma_True_repeat_5_fold_1/runs/2obwmtb7
wandb: Find logs at: ./wandb/run-20220328_040443-2obwmtb7/logs/debug.log
wandb: 

wandb: wandb version 0.12.11 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
2022-03-28 05:46:19.442670: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1
wandb: Tracking run with wandb version 0.12.5
wandb: Syncing run tough-sun-1
wandb: â­ï¸ View project at https://wandb.ai/yinanazhou/xl_512_bs_8_lr_1e06_es_10_lc_False_nr_True_sr_True_stem_False_lemma_True_repeat_5_fold_2
wandb: ðŸš€ View run at https://wandb.ai/yinanazhou/xl_512_bs_8_lr_1e06_es_10_lc_False_nr_True_sr_True_stem_False_lemma_True_repeat_5_fold_2/runs/1xh07pcu
wandb: Run data is saved locally in /project/6002780/yinan/Thesis_MER_Lyrics/lyric-emotion/wandb/run-20220328_054617-1xh07pcu
wandb: Run `wandb offline` to turn off syncing.

Validation loss decreased (inf --> 1.434840).  Saving model ...
Validation loss decreased (1.434840 --> 1.412619).  Saving model ...
Validation loss decreased (1.412619 --> 1.397563).  Saving model ...
Validation loss decreased (1.397563 --> 1.385006).  Saving model ...
Validation loss decreased (1.385006 --> 1.376078).  Saving model ...
Validation loss decreased (1.376078 --> 1.369532).  Saving model ...
Validation loss decreased (1.369532 --> 1.363639).  Saving model ...
Validation loss decreased (1.363639 --> 1.358351).  Saving model ...
Validation loss decreased (1.358351 --> 1.353542).  Saving model ...
Validation loss decreased (1.353542 --> 1.349254).  Saving model ...
Validation loss decreased (1.349254 --> 1.345027).  Saving model ...
Validation loss decreased (1.345027 --> 1.340406).  Saving model ...
Validation loss decreased (1.340406 --> 1.335049).  Saving model ...
Validation loss decreased (1.335049 --> 1.330025).  Saving model ...
Validation loss decreased (1.330025 --> 1.325607).  Saving model ...
Validation loss decreased (1.325607 --> 1.321177).  Saving model ...
Validation loss decreased (1.321177 --> 1.316303).  Saving model ...
Validation loss decreased (1.316303 --> 1.311600).  Saving model ...
Validation loss decreased (1.311600 --> 1.307141).  Saving model ...
Validation loss decreased (1.307141 --> 1.302058).  Saving model ...
Validation loss decreased (1.302058 --> 1.296335).  Saving model ...
Validation loss decreased (1.296335 --> 1.290869).  Saving model ...
Validation loss decreased (1.290869 --> 1.285166).  Saving model ...
Validation loss decreased (1.285166 --> 1.278516).  Saving model ...
Validation loss decreased (1.278516 --> 1.271900).  Saving model ...
Validation loss decreased (1.271900 --> 1.265574).  Saving model ...
Validation loss decreased (1.265574 --> 1.258352).  Saving model ...
Validation loss decreased (1.258352 --> 1.251054).  Saving model ...
Validation loss decreased (1.251054 --> 1.243713).  Saving model ...
Validation loss decreased (1.243713 --> 1.237474).  Saving model ...
Validation loss decreased (1.237474 --> 1.228775).  Saving model ...
Validation loss decreased (1.228775 --> 1.219311).  Saving model ...
Validation loss decreased (1.219311 --> 1.211727).  Saving model ...
Validation loss decreased (1.211727 --> 1.205197).  Saving model ...
Validation loss decreased (1.205197 --> 1.198163).  Saving model ...
Validation loss decreased (1.198163 --> 1.188708).  Saving model ...
Validation loss decreased (1.188708 --> 1.180985).  Saving model ...
Validation loss decreased (1.180985 --> 1.173808).  Saving model ...
Validation loss decreased (1.173808 --> 1.166151).  Saving model ...
Validation loss decreased (1.166151 --> 1.159311).  Saving model ...
Validation loss decreased (1.159311 --> 1.154103).  Saving model ...
Validation loss decreased (1.154103 --> 1.148541).  Saving model ...
Validation loss decreased (1.148541 --> 1.145461).  Saving model ...
Validation loss decreased (1.145461 --> 1.137696).  Saving model ...
Validation loss decreased (1.137696 --> 1.132727).  Saving model ...
Validation loss decreased (1.132727 --> 1.126819).  Saving model ...
Validation loss decreased (1.126819 --> 1.121948).  Saving model ...
Validation loss decreased (1.121948 --> 1.114704).  Saving model ...
Validation loss decreased (1.114704 --> 1.109092).  Saving model ...
Validation loss decreased (1.109092 --> 1.104194).  Saving model ...
Validation loss decreased (1.104194 --> 1.099908).  Saving model ...
Validation loss decreased (1.099908 --> 1.095479).  Saving model ...
Validation loss decreased (1.095479 --> 1.092470).  Saving model ...
Validation loss decreased (1.092470 --> 1.086998).  Saving model ...
Validation loss decreased (1.086998 --> 1.081581).  Saving model ...
Validation loss decreased (1.081581 --> 1.078469).  Saving model ...
Validation loss decreased (1.078469 --> 1.073438).  Saving model ...
Validation loss decreased (1.073438 --> 1.067549).  Saving model ...
Validation loss decreased (1.067549 --> 1.065387).  Saving model ...
Validation loss decreased (1.065387 --> 1.061786).  Saving model ...
Validation loss decreased (1.061786 --> 1.058765).  Saving model ...
Validation loss decreased (1.058765 --> 1.053842).  Saving model ...
Validation loss decreased (1.053842 --> 1.048979).  Saving model ...
Validation loss decreased (1.048979 --> 1.046204).  Saving model ...
Validation loss decreased (1.046204 --> 1.041669).  Saving model ...
Validation loss decreased (1.041669 --> 1.037104).  Saving model ...
Validation loss decreased (1.037104 --> 1.035033).  Saving model ...
Validation loss decreased (1.035033 --> 1.031084).  Saving model ...
Validation loss decreased (1.031084 --> 1.027279).  Saving model ...
Validation loss decreased (1.027279 --> 1.024004).  Saving model ...
Validation loss decreased (1.024004 --> 1.021271).  Saving model ...
Validation loss decreased (1.021271 --> 1.020771).  Saving model ...
Validation loss decreased (1.020771 --> 1.017916).  Saving model ...
Validation loss decreased (1.017916 --> 1.013885).  Saving model ...
Validation loss decreased (1.013885 --> 1.013039).  Saving model ...
Validation loss decreased (1.013039 --> 1.009037).  Saving model ...
Validation loss decreased (1.009037 --> 1.004930).  Saving model ...
Validation loss decreased (1.004930 --> 1.002750).  Saving model ...
Validation loss decreased (1.002750 --> 0.999052).  Saving model ...
Validation loss decreased (0.999052 --> 0.996248).  Saving model ...
Validation loss decreased (0.996248 --> 0.992182).  Saving model ...
Validation loss decreased (0.992182 --> 0.989023).  Saving model ...
Validation loss decreased (0.989023 --> 0.988748).  Saving model ...
Validation loss decreased (0.988748 --> 0.988320).  Saving model ...
Validation loss decreased (0.988320 --> 0.984044).  Saving model ...
Validation loss decreased (0.984044 --> 0.983342).  Saving model ...
Validation loss decreased (0.983342 --> 0.980189).  Saving model ...
EarlyStopping counter: 1 out of 10.0
Validation loss decreased (0.980189 --> 0.977313).  Saving model ...
EarlyStopping counter: 1 out of 10.0
Validation loss decreased (0.977313 --> 0.974214).  Saving model ...
Validation loss decreased (0.974214 --> 0.971021).  Saving model ...
EarlyStopping counter: 1 out of 10.0
Validation loss decreased (0.971021 --> 0.968148).  Saving model ...
Validation loss decreased (0.968148 --> 0.967533).  Saving model ...
Validation loss decreased (0.967533 --> 0.964241).  Saving model ...
Validation loss decreased (0.964241 --> 0.961103).  Saving model ...
Validation loss decreased (0.961103 --> 0.958287).  Saving model ...
Validation loss decreased (0.958287 --> 0.957855).  Saving model ...
Validation loss decreased (0.957855 --> 0.955349).  Saving model ...
Validation loss decreased (0.955349 --> 0.954634).  Saving model ...
EarlyStopping counter: 1 out of 10.0
Validation loss decreased (0.954634 --> 0.953436).  Saving model ...
Validation loss decreased (0.953436 --> 0.953331).  Saving model ...
Validation loss decreased (0.953331 --> 0.950775).  Saving model ...
Validation loss decreased (0.950775 --> 0.946603).  Saving model ...
Validation loss decreased (0.946603 --> 0.945240).  Saving model ...
Validation loss decreased (0.945240 --> 0.944026).  Saving model ...
EarlyStopping counter: 1 out of 10.0
Validation loss decreased (0.944026 --> 0.943655).  Saving model ...
Validation loss decreased (0.943655 --> 0.941925).  Saving model ...
EarlyStopping counter: 1 out of 10.0
EarlyStopping counter: 2 out of 10.0
Validation loss decreased (0.941925 --> 0.941248).  Saving model ...
Validation loss decreased (0.941248 --> 0.940726).  Saving model ...
Validation loss decreased (0.940726 --> 0.938801).  Saving model ...
EarlyStopping counter: 1 out of 10.0
EarlyStopping counter: 2 out of 10.0
Validation loss decreased (0.938801 --> 0.937974).  Saving model ...
Validation loss decreased (0.937974 --> 0.935794).  Saving model ...
Validation loss decreased (0.935794 --> 0.934183).  Saving model ...
Validation loss decreased (0.934183 --> 0.932386).  Saving model ...
EarlyStopping counter: 1 out of 10.0
EarlyStopping counter: 2 out of 10.0
Validation loss decreased (0.932386 --> 0.931715).  Saving model ...
EarlyStopping counter: 1 out of 10.0
EarlyStopping counter: 2 out of 10.0
EarlyStopping counter: 3 out of 10.0
Validation loss decreased (0.931715 --> 0.929840).  Saving model ...
Validation loss decreased (0.929840 --> 0.929593).  Saving model ...
Validation loss decreased (0.929593 --> 0.927947).  Saving model ...
EarlyStopping counter: 1 out of 10.0
Validation loss decreased (0.927947 --> 0.926106).  Saving model ...
EarlyStopping counter: 1 out of 10.0
EarlyStopping counter: 2 out of 10.0
EarlyStopping counter: 3 out of 10.0
EarlyStopping counter: 4 out of 10.0
EarlyStopping counter: 5 out of 10.0
EarlyStopping counter: 6 out of 10.0
EarlyStopping counter: 7 out of 10.0
Validation loss decreased (0.926106 --> 0.925532).  Saving model ...
Validation loss decreased (0.925532 --> 0.925250).  Saving model ...
EarlyStopping counter: 1 out of 10.0
Validation loss decreased (0.925250 --> 0.924916).  Saving model ...
Validation loss decreased (0.924916 --> 0.924337).  Saving model ...
Validation loss decreased (0.924337 --> 0.924028).  Saving model ...
Validation loss decreased (0.924028 --> 0.923368).  Saving model ...
EarlyStopping counter: 1 out of 10.0
EarlyStopping counter: 2 out of 10.0
EarlyStopping counter: 3 out of 10.0
EarlyStopping counter: 4 out of 10.0
EarlyStopping counter: 5 out of 10.0
Validation loss decreased (0.923368 --> 0.923001).  Saving model ...
EarlyStopping counter: 1 out of 10.0
EarlyStopping counter: 2 out of 10.0
EarlyStopping counter: 3 out of 10.0
EarlyStopping counter: 4 out of 10.0
EarlyStopping counter: 5 out of 10.0
EarlyStopping counter: 6 out of 10.0
EarlyStopping counter: 7 out of 10.0
EarlyStopping counter: 8 out of 10.0
EarlyStopping counter: 9 out of 10.0
EarlyStopping counter: 10 out of 10.0
/localscratch/yinan.29351707.0/env/lib/python3.7/site-packages/torch/nn/functional.py:1794: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.
  warnings.warn("nn.functional.tanh is deprecated. Use torch.tanh instead.")
wandb: Waiting for W&B process to finish, PID 167774... (success).
wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: \ 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: | 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: / 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: \ 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: | 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: / 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: \ 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: | 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: / 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb:                                                                                
wandb: Run history:
wandb:     e_F1 â–â–‚â–ƒâ–„â–…â–…â–…â–…â–†â–†â–†â–‡â–†â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ
wandb:   e_loss â–ˆâ–‡â–‡â–‡â–‡â–†â–†â–…â–…â–…â–„â–„â–„â–ƒâ–ƒâ–ƒâ–ƒâ–‚â–‚â–‚â–‚â–‚â–‚â–‚â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:     t_F1 â–â–‚â–‚â–‚â–ƒâ–„â–„â–„â–…â–…â–…â–…â–…â–†â–†â–†â–†â–†â–†â–†â–‡â–‡â–‡â–‡â–‡â–†â–‡â–‡â–‡â–‡â–‡â–‡â–ˆâ–‡â–ˆâ–ˆâ–‡â–ˆâ–ˆâ–ˆ
wandb:   t_loss â–ˆâ–‡â–‡â–‡â–‡â–‡â–‡â–†â–†â–†â–†â–…â–…â–…â–„â–„â–„â–„â–„â–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–â–â–
wandb: 
wandb: Run summary:
wandb:     e_F1 61.49954
wandb:   e_loss 0.92386
wandb:     t_F1 72.56015
wandb:   t_loss 0.71175
wandb: 
wandb: Synced 4 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Synced tough-sun-1: https://wandb.ai/yinanazhou/xl_512_bs_8_lr_1e06_es_10_lc_False_nr_True_sr_True_stem_False_lemma_True_repeat_5_fold_2/runs/1xh07pcu
wandb: Find logs at: ./wandb/run-20220328_054617-1xh07pcu/logs/debug.log
wandb: 

