Unloading StdEnv/2020

Due to MODULEPATH changes, the following have been reloaded:
  1) mii/1.1.1


The following have been reloaded with a version change:
  1) python/3.8.2 => python/3.7.4

Using base prefix '/cvmfs/soft.computecanada.ca/easybuild/software/2017/Core/python/3.7.4'
New python executable in /localscratch/yinan.28698853.0/env/bin/python
Installing setuptools, pip, wheel...
done.
Ignoring pip: markers 'python_version < "3"' don't match your environment
Looking in links: /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/nix/avx2, /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/nix/generic, /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic
Collecting pip
Installing collected packages: pip
  Found existing installation: pip 19.1.1
    Uninstalling pip-19.1.1:
      Successfully uninstalled pip-19.1.1
Successfully installed pip-21.2.3+computecanada
Looking in links: /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/nix/avx2, /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/nix/generic, /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/keras-2.8.0+computecanada-py2.py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/Keras_Preprocessing-1.1.2+computecanada-py3-none-any.whl
Requirement already satisfied: matplotlib in /cvmfs/soft.computecanada.ca/easybuild/software/2017/Core/scipy-stack/2019a/lib/python3.7/site-packages (from -r requirements.txt (line 3)) (3.0.2)
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/nltk-3.6.5+computecanada-py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/scikit_learn-0.22.1+computecanada-cp37-cp37m-linux_x86_64.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/tensorboard-2.3.0+computecanada-py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/tensorboard_plugin_wit-1.7.0+computecanada-py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/tensorflow_gpu-2.3.0+computecanada-cp37-cp37m-linux_x86_64.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/tensorflow_estimator-2.3.0+computecanada-py2.py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/tokenizers-0.5.2+computecanada-cp37-cp37m-linux_x86_64.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/nix/avx2/torch-1.4.0+computecanada-cp37-cp37m-linux_x86_64.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/torchtext-0.6.0+computecanada-py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/torchvision-0.8.2+computecanada-cp37-cp37m-linux_x86_64.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/transformers-2.5.1+computecanada-py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/urllib3-1.26.7+computecanada-py2.py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/joblib-1.1.0+computecanada-py2.py3-none-any.whl
ERROR: Could not find a version that satisfies the requirement regex>=2021.8.3 (from nltk) (from versions: 2018.1.10+computecanada, 2019.11.1+computecanada, 2020.11.13+computecanada)
ERROR: No matching distribution found for regex>=2021.8.3
Looking in links: /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/nix/avx2, /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/nix/generic, /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic
ERROR: Could not find a version that satisfies the requirement numpy==1.20.0+computacanada (from versions: 1.15.0+computecanada, 1.15.2+computecanada, 1.15.4+computecanada, 1.16.0+computecanada, 1.16.2+computecanada, 1.16.3+computecanada, 1.17.4+computecanada, 1.18.1+computecanada, 1.18.4+computecanada, 1.19.1+computecanada, 1.19.2+computecanada, 1.20.2+computecanada)
ERROR: No matching distribution found for numpy==1.20.0+computacanada
Looking in links: /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/nix/avx2, /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/nix/generic, /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/wandb-0.12.5+computecanada-py2.py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/six-1.16.0+computecanada-py2.py3-none-any.whl
Requirement already satisfied: python-dateutil>=2.6.1 in /cvmfs/soft.computecanada.ca/easybuild/software/2017/Core/scipy-stack/2019a/lib/python3.7/site-packages (from wandb) (2.7.5)
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/sentry_sdk-1.5.0+computecanada-py2.py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/protobuf-3.19.4+computecanada-py2.py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/yaspin-2.1.0+computecanada-py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/docker_pycreds-0.4.0+computecanada-py2.py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/pathtools-0.1.2+computecanada-py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/configparser-5.0.2+computecanada-py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/PyYAML-5.3.1+computecanada-cp37-cp37m-linux_x86_64.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/promise-2.3+computecanada-py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/shortuuid-1.0.1+computecanada-py3-none-any.whl
Requirement already satisfied: requests<3,>=2.0.0 in /cvmfs/soft.computecanada.ca/easybuild/software/2017/Core/scipy-stack/2019a/lib/python3.7/site-packages (from wandb) (2.21.0)
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/subprocess32-3.5.4+computecanada-py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/GitPython-3.1.24+computecanada-py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/click-8.0.3+computecanada-py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/psutil-5.7.3+computecanada-cp37-cp37m-linux_x86_64.whl
Requirement already satisfied: importlib-metadata in /cvmfs/soft.computecanada.ca/easybuild/software/2017/Core/scipy-stack/2019a/lib/python3.7/site-packages (from Click!=8.0.0,>=7.0->wandb) (0.8)
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/typing_extensions-4.0.1+computecanada-py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/gitdb-4.0.9+computecanada-py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/smmap-5.0.0+computecanada-py3-none-any.whl
Requirement already satisfied: certifi>=2017.4.17 in /cvmfs/soft.computecanada.ca/easybuild/software/2017/Core/scipy-stack/2019a/lib/python3.7/site-packages (from requests<3,>=2.0.0->wandb) (2018.11.29)
Requirement already satisfied: idna<2.9,>=2.5 in /cvmfs/soft.computecanada.ca/easybuild/software/2017/Core/scipy-stack/2019a/lib/python3.7/site-packages (from requests<3,>=2.0.0->wandb) (2.8)
Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /cvmfs/soft.computecanada.ca/easybuild/software/2017/Core/scipy-stack/2019a/lib/python3.7/site-packages (from requests<3,>=2.0.0->wandb) (3.0.4)
Requirement already satisfied: urllib3<1.25,>=1.21.1 in /cvmfs/soft.computecanada.ca/easybuild/software/2017/Core/scipy-stack/2019a/lib/python3.7/site-packages (from requests<3,>=2.0.0->wandb) (1.24.1)
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/termcolor-1.1.0+computecanada-py3-none-any.whl
Requirement already satisfied: zipp>=0.3.2 in /cvmfs/soft.computecanada.ca/easybuild/software/2017/Core/scipy-stack/2019a/lib/python3.7/site-packages (from importlib-metadata->Click!=8.0.0,>=7.0->wandb) (0.3.3)
Installing collected packages: smmap, typing-extensions, termcolor, six, gitdb, yaspin, subprocess32, shortuuid, sentry-sdk, PyYAML, psutil, protobuf, promise, pathtools, GitPython, docker-pycreds, configparser, Click, wandb
  Attempting uninstall: six
    Found existing installation: six 1.12.0
    Not uninstalling six at /cvmfs/soft.computecanada.ca/easybuild/software/2017/Core/scipy-stack/2019a/lib/python3.7/site-packages, outside environment /localscratch/yinan.28698853.0/env
    Can't uninstall 'six'. No files were found to uninstall.
Successfully installed Click-8.0.3+computecanada GitPython-3.1.24+computecanada PyYAML-5.3.1+computecanada configparser-5.0.2+computecanada docker-pycreds-0.4.0+computecanada gitdb-4.0.9+computecanada pathtools-0.1.2+computecanada promise-2.3+computecanada protobuf-3.19.4+computecanada psutil-5.7.3+computecanada sentry-sdk-1.5.0+computecanada shortuuid-1.0.1+computecanada six-1.16.0+computecanada smmap-5.0.0+computecanada subprocess32-3.5.4+computecanada termcolor-1.1.0+computecanada typing-extensions-4.0.1+computecanada wandb-0.12.5+computecanada yaspin-2.1.0+computecanada
Looking in links: /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/nix/avx2, /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/nix/generic, /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic
ERROR: Could not find a version that satisfies the requirement sagemaker (from versions: none)
ERROR: No matching distribution found for sagemaker
Looking in links: /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/nix/avx2, /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/nix/generic, /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/torch-1.9.1+computecanada-cp37-cp37m-linux_x86_64.whl
Requirement already satisfied: typing-extensions in /localscratch/yinan.28698853.0/env/lib/python3.7/site-packages (from torch) (4.0.1+computecanada)
Installing collected packages: torch
Successfully installed torch-1.9.1+computecanada
Looking in links: /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/nix/avx2, /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/nix/generic, /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/transformers-2.5.1+computecanada-py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/tqdm-4.63.0+computecanada-py2.py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/regex-2020.11.13+computecanada-cp37-cp37m-linux_x86_64.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/sacremoses-0.0.46+computecanada-py3-none-any.whl
Requirement already satisfied: requests in /cvmfs/soft.computecanada.ca/easybuild/software/2017/Core/scipy-stack/2019a/lib/python3.7/site-packages (from transformers==2.5.1+computecanada) (2.21.0)
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/filelock-3.4.2+computecanada-py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/sentencepiece-0.1.91+computecanada-cp37-cp37m-linux_x86_64.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/tokenizers-0.5.2+computecanada-cp37-cp37m-linux_x86_64.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/boto3-1.20.52+computecanada-py3-none-any.whl
Requirement already satisfied: numpy in /cvmfs/soft.computecanada.ca/easybuild/software/2017/Core/scipy-stack/2019a/lib/python3.7/site-packages (from transformers==2.5.1+computecanada) (1.16.0)
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/jmespath-0.10.0+computecanada-py2.py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/s3transfer-0.5.1+computecanada-py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/botocore-1.23.52+computecanada-py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/urllib3-1.26.8+computecanada-py2.py3-none-any.whl
Requirement already satisfied: python-dateutil<3.0.0,>=2.1 in /cvmfs/soft.computecanada.ca/easybuild/software/2017/Core/scipy-stack/2019a/lib/python3.7/site-packages (from botocore<1.24.0,>=1.23.52->boto3->transformers==2.5.1+computecanada) (2.7.5)
Requirement already satisfied: six>=1.5 in /localscratch/yinan.28698853.0/env/lib/python3.7/site-packages (from python-dateutil<3.0.0,>=2.1->botocore<1.24.0,>=1.23.52->boto3->transformers==2.5.1+computecanada) (1.16.0+computecanada)
Requirement already satisfied: certifi>=2017.4.17 in /cvmfs/soft.computecanada.ca/easybuild/software/2017/Core/scipy-stack/2019a/lib/python3.7/site-packages (from requests->transformers==2.5.1+computecanada) (2018.11.29)
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/requests-2.27.1+computecanada-py2.py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/charset_normalizer-2.0.11+computecanada-py3-none-any.whl
Requirement already satisfied: idna<4,>=2.5 in /cvmfs/soft.computecanada.ca/easybuild/software/2017/Core/scipy-stack/2019a/lib/python3.7/site-packages (from requests->transformers==2.5.1+computecanada) (2.8)
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/joblib-1.1.0+computecanada-py2.py3-none-any.whl
Requirement already satisfied: click in /localscratch/yinan.28698853.0/env/lib/python3.7/site-packages (from sacremoses->transformers==2.5.1+computecanada) (8.0.3+computecanada)
Requirement already satisfied: importlib-metadata in /cvmfs/soft.computecanada.ca/easybuild/software/2017/Core/scipy-stack/2019a/lib/python3.7/site-packages (from click->sacremoses->transformers==2.5.1+computecanada) (0.8)
Requirement already satisfied: zipp>=0.3.2 in /cvmfs/soft.computecanada.ca/easybuild/software/2017/Core/scipy-stack/2019a/lib/python3.7/site-packages (from importlib-metadata->click->sacremoses->transformers==2.5.1+computecanada) (0.3.3)
Installing collected packages: urllib3, jmespath, botocore, tqdm, s3transfer, regex, joblib, charset-normalizer, tokenizers, sentencepiece, sacremoses, requests, filelock, boto3, transformers
  Attempting uninstall: urllib3
    Found existing installation: urllib3 1.24.1
    Not uninstalling urllib3 at /cvmfs/soft.computecanada.ca/easybuild/software/2017/Core/scipy-stack/2019a/lib/python3.7/site-packages, outside environment /localscratch/yinan.28698853.0/env
    Can't uninstall 'urllib3'. No files were found to uninstall.
  Attempting uninstall: requests
    Found existing installation: requests 2.21.0
    Not uninstalling requests at /cvmfs/soft.computecanada.ca/easybuild/software/2017/Core/scipy-stack/2019a/lib/python3.7/site-packages, outside environment /localscratch/yinan.28698853.0/env
    Can't uninstall 'requests'. No files were found to uninstall.
Successfully installed boto3-1.20.52+computecanada botocore-1.23.52+computecanada charset-normalizer-2.0.11+computecanada filelock-3.4.2+computecanada jmespath-0.10.0+computecanada joblib-1.1.0+computecanada regex-2020.11.13+computecanada requests-2.27.1+computecanada s3transfer-0.5.1+computecanada sacremoses-0.0.46+computecanada sentencepiece-0.1.91+computecanada tokenizers-0.5.2+computecanada tqdm-4.63.0+computecanada transformers-2.5.1+computecanada urllib3-1.26.8+computecanada
Looking in links: /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/nix/avx2, /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/nix/generic, /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/tensorflow_gpu-2.3.0+computecanada-cp37-cp37m-linux_x86_64.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/absl_py-1.0.0+computecanada-py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/tensorflow_estimator-2.3.0+computecanada-py2.py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/nix/generic/scipy-1.4.1+computecanada-cp37-cp37m-linux_x86_64.whl
Requirement already satisfied: termcolor>=1.1.0 in /localscratch/yinan.28698853.0/env/lib/python3.7/site-packages (from tensorflow_gpu==2.3.0+computecanada) (1.1.0+computecanada)
Requirement already satisfied: protobuf>=3.9.2 in /localscratch/yinan.28698853.0/env/lib/python3.7/site-packages (from tensorflow_gpu==2.3.0+computecanada) (3.19.4+computecanada)
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/tensorboard-2.8.0+computecanada-py3-none-any.whl
Requirement already satisfied: numpy<1.19.0,>=1.16.0 in /cvmfs/soft.computecanada.ca/easybuild/software/2017/Core/scipy-stack/2019a/lib/python3.7/site-packages (from tensorflow_gpu==2.3.0+computecanada) (1.16.0)
Requirement already satisfied: six>=1.12.0 in /localscratch/yinan.28698853.0/env/lib/python3.7/site-packages (from tensorflow_gpu==2.3.0+computecanada) (1.16.0+computecanada)
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/nix/avx2/h5py-2.10.0+computecanada-cp37-cp37m-linux_x86_64.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/Keras_Preprocessing-1.1.2+computecanada-py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/wrapt-1.11.2+computecanada-cp37-cp37m-linux_x86_64.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/opt_einsum-3.3.0+computecanada-py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/gast-0.3.3+computecanada-py3-none-any.whl
Requirement already satisfied: wheel>=0.26 in /localscratch/yinan.28698853.0/env/lib/python3.7/site-packages (from tensorflow_gpu==2.3.0+computecanada) (0.33.4)
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/google_pasta-0.2.0+computecanada-py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/astunparse-1.6.3+computecanada-py2.py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/grpcio-1.38.0+computecanada-cp37-cp37m-linux_x86_64.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/Markdown-3.3.6+computecanada-py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/google_auth-2.3.3+computecanada-py2.py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/tensorboard_data_server-0.6.1+computecanada-py3-none-linux_x86_64.whl
Requirement already satisfied: requests<3,>=2.21.0 in /localscratch/yinan.28698853.0/env/lib/python3.7/site-packages (from tensorboard<3,>=2.3.0->tensorflow_gpu==2.3.0+computecanada) (2.27.1+computecanada)
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/Werkzeug-2.0.3+computecanada-py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/google_auth_oauthlib-0.4.6+computecanada-py2.py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/tensorboard_plugin_wit-1.8.0+computecanada-py3-none-any.whl
Requirement already satisfied: setuptools>=41.0.0 in /localscratch/yinan.28698853.0/env/lib/python3.7/site-packages (from tensorboard<3,>=2.3.0->tensorflow_gpu==2.3.0+computecanada) (41.0.1)
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/pyasn1_modules-0.2.8+computecanada-py2.py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/rsa-4.8+computecanada-py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/cachetools-4.2.4+computecanada-py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/requests_oauthlib-1.3.0+computecanada-py2.py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/importlib_metadata-4.10.1+computecanada-py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/zipp-3.7.0+computecanada-py3-none-any.whl
Requirement already satisfied: typing-extensions>=3.6.4 in /localscratch/yinan.28698853.0/env/lib/python3.7/site-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard<3,>=2.3.0->tensorflow_gpu==2.3.0+computecanada) (4.0.1+computecanada)
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/pyasn1-0.4.8+computecanada-py2.py3-none-any.whl
Requirement already satisfied: idna<4,>=2.5 in /cvmfs/soft.computecanada.ca/easybuild/software/2017/Core/scipy-stack/2019a/lib/python3.7/site-packages (from requests<3,>=2.21.0->tensorboard<3,>=2.3.0->tensorflow_gpu==2.3.0+computecanada) (2.8)
Requirement already satisfied: certifi>=2017.4.17 in /cvmfs/soft.computecanada.ca/easybuild/software/2017/Core/scipy-stack/2019a/lib/python3.7/site-packages (from requests<3,>=2.21.0->tensorboard<3,>=2.3.0->tensorflow_gpu==2.3.0+computecanada) (2018.11.29)
Requirement already satisfied: charset-normalizer~=2.0.0 in /localscratch/yinan.28698853.0/env/lib/python3.7/site-packages (from requests<3,>=2.21.0->tensorboard<3,>=2.3.0->tensorflow_gpu==2.3.0+computecanada) (2.0.11+computecanada)
Requirement already satisfied: urllib3<1.27,>=1.21.1 in /localscratch/yinan.28698853.0/env/lib/python3.7/site-packages (from requests<3,>=2.21.0->tensorboard<3,>=2.3.0->tensorflow_gpu==2.3.0+computecanada) (1.26.8+computecanada)
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/oauthlib-3.1.1+computecanada-py2.py3-none-any.whl
Installing collected packages: pyasn1, zipp, rsa, pyasn1-modules, oauthlib, cachetools, requests-oauthlib, importlib-metadata, google-auth, werkzeug, tensorboard-plugin-wit, tensorboard-data-server, markdown, grpcio, google-auth-oauthlib, absl-py, wrapt, tensorflow-estimator, tensorboard, scipy, opt-einsum, keras-preprocessing, h5py, google-pasta, gast, astunparse, tensorflow-gpu
  Attempting uninstall: pyasn1
    Found existing installation: pyasn1 0.4.3
    Not uninstalling pyasn1 at /cvmfs/soft.computecanada.ca/easybuild/software/2017/Core/scipy-stack/2019a/lib/python3.7/site-packages, outside environment /localscratch/yinan.28698853.0/env
    Can't uninstall 'pyasn1'. No files were found to uninstall.
  Attempting uninstall: zipp
    Found existing installation: zipp 0.3.3
    Not uninstalling zipp at /cvmfs/soft.computecanada.ca/easybuild/software/2017/Core/scipy-stack/2019a/lib/python3.7/site-packages, outside environment /localscratch/yinan.28698853.0/env
    Can't uninstall 'zipp'. No files were found to uninstall.
  Attempting uninstall: importlib-metadata
    Found existing installation: importlib-metadata 0.8
    Not uninstalling importlib-metadata at /cvmfs/soft.computecanada.ca/easybuild/software/2017/Core/scipy-stack/2019a/lib/python3.7/site-packages, outside environment /localscratch/yinan.28698853.0/env
    Can't uninstall 'importlib-metadata'. No files were found to uninstall.
  Attempting uninstall: scipy
    Found existing installation: scipy 1.2.0
    Not uninstalling scipy at /cvmfs/soft.computecanada.ca/easybuild/software/2017/Core/scipy-stack/2019a/lib/python3.7/site-packages, outside environment /localscratch/yinan.28698853.0/env
    Can't uninstall 'scipy'. No files were found to uninstall.
Successfully installed absl-py-1.0.0+computecanada astunparse-1.6.3+computecanada cachetools-4.2.4+computecanada gast-0.3.3+computecanada google-auth-2.3.3+computecanada google-auth-oauthlib-0.4.6+computecanada google-pasta-0.2.0+computecanada grpcio-1.38.0+computecanada h5py-2.10.0+computecanada importlib-metadata-4.10.1+computecanada keras-preprocessing-1.1.2+computecanada markdown-3.3.6+computecanada oauthlib-3.1.1+computecanada opt-einsum-3.3.0+computecanada pyasn1-0.4.8+computecanada pyasn1-modules-0.2.8+computecanada requests-oauthlib-1.3.0+computecanada rsa-4.8+computecanada scipy-1.4.1+computecanada tensorboard-2.8.0+computecanada tensorboard-data-server-0.6.1+computecanada tensorboard-plugin-wit-1.8.0+computecanada tensorflow-estimator-2.3.0+computecanada tensorflow-gpu-2.3.0+computecanada werkzeug-2.0.3+computecanada wrapt-1.11.2+computecanada zipp-3.7.0+computecanada
Looking in links: /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/nix/avx2, /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/nix/generic, /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/keras-2.8.0+computecanada-py2.py3-none-any.whl
Installing collected packages: Keras
Successfully installed Keras-2.8.0+computecanada
Looking in links: /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/nix/avx2, /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/nix/generic, /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/urllib3-1.26.7+computecanada-py2.py3-none-any.whl
Installing collected packages: urllib3
  Attempting uninstall: urllib3
    Found existing installation: urllib3 1.26.8+computecanada
    Uninstalling urllib3-1.26.8+computecanada:
      Successfully uninstalled urllib3-1.26.8+computecanada
Successfully installed urllib3-1.26.7+computecanada
Looking in links: /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/nix/avx2, /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/nix/generic, /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/nltk-3.7+computecanada-py3-none-any.whl
Requirement already satisfied: click in /localscratch/yinan.28698853.0/env/lib/python3.7/site-packages (from nltk) (8.0.3+computecanada)
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/nltk-3.6.5+computecanada-py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/nltk-3.6.3+computecanada-py3-none-any.whl
Requirement already satisfied: regex in /localscratch/yinan.28698853.0/env/lib/python3.7/site-packages (from nltk) (2020.11.13+computecanada)
Requirement already satisfied: joblib in /localscratch/yinan.28698853.0/env/lib/python3.7/site-packages (from nltk) (1.1.0+computecanada)
Requirement already satisfied: tqdm in /localscratch/yinan.28698853.0/env/lib/python3.7/site-packages (from nltk) (4.63.0+computecanada)
Requirement already satisfied: importlib-metadata in /localscratch/yinan.28698853.0/env/lib/python3.7/site-packages (from click->nltk) (4.10.1+computecanada)
Requirement already satisfied: zipp>=0.5 in /localscratch/yinan.28698853.0/env/lib/python3.7/site-packages (from importlib-metadata->click->nltk) (3.7.0+computecanada)
Requirement already satisfied: typing-extensions>=3.6.4 in /localscratch/yinan.28698853.0/env/lib/python3.7/site-packages (from importlib-metadata->click->nltk) (4.0.1+computecanada)
Installing collected packages: nltk
Successfully installed nltk-3.6.3+computecanada
Looking in links: /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/nix/avx2, /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/nix/generic, /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/scikit_learn-0.22.1+computecanada-cp37-cp37m-linux_x86_64.whl
Requirement already satisfied: joblib>=0.11 in /localscratch/yinan.28698853.0/env/lib/python3.7/site-packages (from scikit-learn==0.22.1) (1.1.0+computecanada)
Requirement already satisfied: scipy>=0.17.0 in /localscratch/yinan.28698853.0/env/lib/python3.7/site-packages (from scikit-learn==0.22.1) (1.4.1+computecanada)
Requirement already satisfied: numpy>=1.11.0 in /cvmfs/soft.computecanada.ca/easybuild/software/2017/Core/scipy-stack/2019a/lib/python3.7/site-packages (from scikit-learn==0.22.1) (1.16.0)
Installing collected packages: scikit-learn
Successfully installed scikit-learn-0.22.1+computecanada
Looking in links: /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/nix/avx2, /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/nix/generic, /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic
Requirement already satisfied: tokenizers==0.5.2 in /localscratch/yinan.28698853.0/env/lib/python3.7/site-packages (0.5.2+computecanada)
wandb: Appending key for api.wandb.ai to your netrc file: /home/yinan/.netrc
Starting Task
2022-03-15 02:21:43.439647: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1
[nltk_data] Downloading package stopwords to /home/yinan/nltk_data...
[nltk_data]   Package stopwords is already up-to-date!
[nltk_data] Downloading package wordnet to /home/yinan/nltk_data...
[nltk_data]   Package wordnet is already up-to-date!
wandb: Currently logged in as: yinanazhou (use `wandb login --relogin` to force relogin)
wandb: wandb version 0.12.11 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
2022-03-15 02:21:54.463149: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1
wandb: Tracking run with wandb version 0.12.5
wandb: Syncing run generous-durian-2
wandb: ⭐️ View project at https://wandb.ai/yinanazhou/xl_512_bs_8_lr_1e06_es_15_lc_True_nr_True_sr_True_stem_False_lemma_False_repeat_1_fold_1
wandb: 🚀 View run at https://wandb.ai/yinanazhou/xl_512_bs_8_lr_1e06_es_15_lc_True_nr_True_sr_True_stem_False_lemma_False_repeat_1_fold_1/runs/2o388rqu
wandb: Run data is saved locally in /project/6002780/yinan/Thesis_MER_Lyrics/lyric-emotion/wandb/run-20220315_022152-2o388rqu
wandb: Run `wandb offline` to turn off syncing.

Validation loss decreased (inf --> 1.441675).  Saving model ...
Validation loss decreased (1.441675 --> 1.423186).  Saving model ...
Validation loss decreased (1.423186 --> 1.407739).  Saving model ...
Validation loss decreased (1.407739 --> 1.395278).  Saving model ...
Validation loss decreased (1.395278 --> 1.385952).  Saving model ...
Validation loss decreased (1.385952 --> 1.378015).  Saving model ...
Validation loss decreased (1.378015 --> 1.372319).  Saving model ...
Validation loss decreased (1.372319 --> 1.367101).  Saving model ...
Validation loss decreased (1.367101 --> 1.362449).  Saving model ...
Validation loss decreased (1.362449 --> 1.357497).  Saving model ...
Validation loss decreased (1.357497 --> 1.352490).  Saving model ...
Validation loss decreased (1.352490 --> 1.347691).  Saving model ...
Validation loss decreased (1.347691 --> 1.342970).  Saving model ...
Validation loss decreased (1.342970 --> 1.338242).  Saving model ...
Validation loss decreased (1.338242 --> 1.333882).  Saving model ...
Validation loss decreased (1.333882 --> 1.329833).  Saving model ...
Validation loss decreased (1.329833 --> 1.325409).  Saving model ...
Validation loss decreased (1.325409 --> 1.320543).  Saving model ...
Validation loss decreased (1.320543 --> 1.315317).  Saving model ...
Validation loss decreased (1.315317 --> 1.310341).  Saving model ...
Validation loss decreased (1.310341 --> 1.305684).  Saving model ...
Validation loss decreased (1.305684 --> 1.300396).  Saving model ...
Validation loss decreased (1.300396 --> 1.296148).  Saving model ...
Validation loss decreased (1.296148 --> 1.290671).  Saving model ...
Validation loss decreased (1.290671 --> 1.285830).  Saving model ...
Validation loss decreased (1.285830 --> 1.281224).  Saving model ...
Validation loss decreased (1.281224 --> 1.277315).  Saving model ...
Validation loss decreased (1.277315 --> 1.275066).  Saving model ...
Validation loss decreased (1.275066 --> 1.273085).  Saving model ...
Validation loss decreased (1.273085 --> 1.270585).  Saving model ...
Validation loss decreased (1.270585 --> 1.266308).  Saving model ...
Validation loss decreased (1.266308 --> 1.261046).  Saving model ...
Validation loss decreased (1.261046 --> 1.259798).  Saving model ...
Validation loss decreased (1.259798 --> 1.253288).  Saving model ...
Validation loss decreased (1.253288 --> 1.252226).  Saving model ...
Validation loss decreased (1.252226 --> 1.247537).  Saving model ...
Validation loss decreased (1.247537 --> 1.244679).  Saving model ...
Validation loss decreased (1.244679 --> 1.239517).  Saving model ...
Validation loss decreased (1.239517 --> 1.237540).  Saving model ...
Validation loss decreased (1.237540 --> 1.237170).  Saving model ...
Validation loss decreased (1.237170 --> 1.230621).  Saving model ...
Validation loss decreased (1.230621 --> 1.227196).  Saving model ...
Validation loss decreased (1.227196 --> 1.226575).  Saving model ...
Validation loss decreased (1.226575 --> 1.221086).  Saving model ...
Validation loss decreased (1.221086 --> 1.220941).  Saving model ...
Validation loss decreased (1.220941 --> 1.218210).  Saving model ...
Validation loss decreased (1.218210 --> 1.216324).  Saving model ...
Validation loss decreased (1.216324 --> 1.214311).  Saving model ...
Validation loss decreased (1.214311 --> 1.210619).  Saving model ...
Validation loss decreased (1.210619 --> 1.205541).  Saving model ...
Validation loss decreased (1.205541 --> 1.201404).  Saving model ...
Validation loss decreased (1.201404 --> 1.197768).  Saving model ...
Validation loss decreased (1.197768 --> 1.195982).  Saving model ...
Validation loss decreased (1.195982 --> 1.191534).  Saving model ...
EarlyStopping counter: 1 out of 15.0
Validation loss decreased (1.191534 --> 1.189415).  Saving model ...
Validation loss decreased (1.189415 --> 1.188133).  Saving model ...
Validation loss decreased (1.188133 --> 1.184564).  Saving model ...
Validation loss decreased (1.184564 --> 1.178266).  Saving model ...
Validation loss decreased (1.178266 --> 1.178206).  Saving model ...
Validation loss decreased (1.178206 --> 1.173006).  Saving model ...
EarlyStopping counter: 1 out of 15.0
Validation loss decreased (1.173006 --> 1.170363).  Saving model ...
Validation loss decreased (1.170363 --> 1.168316).  Saving model ...
Validation loss decreased (1.168316 --> 1.166168).  Saving model ...
Validation loss decreased (1.166168 --> 1.161845).  Saving model ...
Validation loss decreased (1.161845 --> 1.159450).  Saving model ...
Validation loss decreased (1.159450 --> 1.155724).  Saving model ...
Validation loss decreased (1.155724 --> 1.154208).  Saving model ...
Validation loss decreased (1.154208 --> 1.152667).  Saving model ...
Validation loss decreased (1.152667 --> 1.149243).  Saving model ...
Validation loss decreased (1.149243 --> 1.147071).  Saving model ...
Validation loss decreased (1.147071 --> 1.145694).  Saving model ...
Validation loss decreased (1.145694 --> 1.140263).  Saving model ...
Validation loss decreased (1.140263 --> 1.134228).  Saving model ...
Validation loss decreased (1.134228 --> 1.133849).  Saving model ...
EarlyStopping counter: 1 out of 15.0
Validation loss decreased (1.133849 --> 1.133062).  Saving model ...
Validation loss decreased (1.133062 --> 1.128384).  Saving model ...
Validation loss decreased (1.128384 --> 1.120717).  Saving model ...
EarlyStopping counter: 1 out of 15.0
EarlyStopping counter: 2 out of 15.0
EarlyStopping counter: 3 out of 15.0
EarlyStopping counter: 4 out of 15.0
Validation loss decreased (1.120717 --> 1.117917).  Saving model ...
Validation loss decreased (1.117917 --> 1.108810).  Saving model ...
Validation loss decreased (1.108810 --> 1.104728).  Saving model ...
EarlyStopping counter: 1 out of 15.0
EarlyStopping counter: 2 out of 15.0
EarlyStopping counter: 3 out of 15.0
Validation loss decreased (1.104728 --> 1.100717).  Saving model ...
Validation loss decreased (1.100717 --> 1.098361).  Saving model ...
EarlyStopping counter: 1 out of 15.0
EarlyStopping counter: 2 out of 15.0
EarlyStopping counter: 3 out of 15.0
EarlyStopping counter: 4 out of 15.0
EarlyStopping counter: 5 out of 15.0
Validation loss decreased (1.098361 --> 1.096441).  Saving model ...
Validation loss decreased (1.096441 --> 1.094552).  Saving model ...
EarlyStopping counter: 1 out of 15.0
Validation loss decreased (1.094552 --> 1.092270).  Saving model ...
Validation loss decreased (1.092270 --> 1.090155).  Saving model ...
Validation loss decreased (1.090155 --> 1.084891).  Saving model ...
EarlyStopping counter: 1 out of 15.0
Validation loss decreased (1.084891 --> 1.084865).  Saving model ...
Validation loss decreased (1.084865 --> 1.081225).  Saving model ...
Validation loss decreased (1.081225 --> 1.078288).  Saving model ...
Validation loss decreased (1.078288 --> 1.077156).  Saving model ...
Validation loss decreased (1.077156 --> 1.075131).  Saving model ...
Validation loss decreased (1.075131 --> 1.071867).  Saving model ...
EarlyStopping counter: 1 out of 15.0
EarlyStopping counter: 2 out of 15.0
EarlyStopping counter: 3 out of 15.0
EarlyStopping counter: 4 out of 15.0
EarlyStopping counter: 5 out of 15.0
Validation loss decreased (1.071867 --> 1.071482).  Saving model ...
EarlyStopping counter: 1 out of 15.0
Validation loss decreased (1.071482 --> 1.068983).  Saving model ...
Validation loss decreased (1.068983 --> 1.067395).  Saving model ...
Validation loss decreased (1.067395 --> 1.065161).  Saving model ...
Validation loss decreased (1.065161 --> 1.063052).  Saving model ...
Validation loss decreased (1.063052 --> 1.062935).  Saving model ...
Validation loss decreased (1.062935 --> 1.058124).  Saving model ...
EarlyStopping counter: 1 out of 15.0
EarlyStopping counter: 2 out of 15.0
EarlyStopping counter: 3 out of 15.0
EarlyStopping counter: 4 out of 15.0
EarlyStopping counter: 5 out of 15.0
EarlyStopping counter: 6 out of 15.0
EarlyStopping counter: 7 out of 15.0
EarlyStopping counter: 8 out of 15.0
EarlyStopping counter: 9 out of 15.0
Validation loss decreased (1.058124 --> 1.054475).  Saving model ...
Validation loss decreased (1.054475 --> 1.053281).  Saving model ...
EarlyStopping counter: 1 out of 15.0
EarlyStopping counter: 2 out of 15.0
Validation loss decreased (1.053281 --> 1.050996).  Saving model ...
EarlyStopping counter: 1 out of 15.0
EarlyStopping counter: 2 out of 15.0
EarlyStopping counter: 3 out of 15.0
EarlyStopping counter: 4 out of 15.0
EarlyStopping counter: 5 out of 15.0
EarlyStopping counter: 6 out of 15.0
EarlyStopping counter: 7 out of 15.0
Validation loss decreased (1.050996 --> 1.050884).  Saving model ...
EarlyStopping counter: 1 out of 15.0
EarlyStopping counter: 2 out of 15.0
EarlyStopping counter: 3 out of 15.0
EarlyStopping counter: 4 out of 15.0
Validation loss decreased (1.050884 --> 1.049476).  Saving model ...
EarlyStopping counter: 1 out of 15.0
EarlyStopping counter: 2 out of 15.0
EarlyStopping counter: 3 out of 15.0
EarlyStopping counter: 4 out of 15.0
Validation loss decreased (1.049476 --> 1.048471).  Saving model ...
Validation loss decreased (1.048471 --> 1.045348).  Saving model ...
Validation loss decreased (1.045348 --> 1.044734).  Saving model ...
EarlyStopping counter: 1 out of 15.0
EarlyStopping counter: 2 out of 15.0
EarlyStopping counter: 3 out of 15.0
EarlyStopping counter: 4 out of 15.0
EarlyStopping counter: 5 out of 15.0
EarlyStopping counter: 6 out of 15.0
Validation loss decreased (1.044734 --> 1.042540).  Saving model ...
EarlyStopping counter: 1 out of 15.0
EarlyStopping counter: 2 out of 15.0
EarlyStopping counter: 3 out of 15.0
EarlyStopping counter: 4 out of 15.0
EarlyStopping counter: 5 out of 15.0
EarlyStopping counter: 6 out of 15.0
EarlyStopping counter: 7 out of 15.0
EarlyStopping counter: 8 out of 15.0
EarlyStopping counter: 9 out of 15.0
EarlyStopping counter: 10 out of 15.0
EarlyStopping counter: 11 out of 15.0
EarlyStopping counter: 12 out of 15.0
EarlyStopping counter: 13 out of 15.0
EarlyStopping counter: 14 out of 15.0
EarlyStopping counter: 15 out of 15.0
/localscratch/yinan.28698853.0/env/lib/python3.7/site-packages/torch/nn/functional.py:1794: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.
  warnings.warn("nn.functional.tanh is deprecated. Use torch.tanh instead.")
/localscratch/yinan.28698853.0/env/lib/python3.7/site-packages/transformers/optimization.py:155: UserWarning: This overload of add_ is deprecated:
	add_(Number alpha, Tensor other)
Consider using one of the following signatures instead:
	add_(Tensor other, *, Number alpha) (Triggered internally at  ../torch/csrc/utils/python_arg_parser.cpp:1025.)
  exp_avg.mul_(beta1).add_(1.0 - beta1, grad)
wandb: Waiting for W&B process to finish, PID 200079... (success).
wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: \ 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: | 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: / 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: \ 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: | 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: / 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: \ 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: | 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: / 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb:                                                                                
wandb: Run history:
wandb:     e_F1 ▁▂▃▄▄▅▅▅▅▆▆▆▆▆▆▆▆▇▇▇▇▇▇█████████████████
wandb:   e_loss █▇▇▆▆▆▅▅▅▄▄▄▄▃▃▃▃▃▂▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:     t_F1 ▁▂▂▃▄▄▄▄▅▅▅▅▅▆▆▆▆▆▆▆▆▆▆▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇██
wandb:   t_loss █▇▇▇▇▆▆▆▅▅▅▅▅▄▄▄▄▄▄▃▃▃▃▃▃▃▂▃▂▂▂▂▂▂▂▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:     e_F1 55.24249
wandb:   e_loss 1.04808
wandb:     t_F1 75.60335
wandb:   t_loss 0.67205
wandb: 
wandb: Synced 4 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Synced generous-durian-2: https://wandb.ai/yinanazhou/xl_512_bs_8_lr_1e06_es_15_lc_True_nr_True_sr_True_stem_False_lemma_False_repeat_1_fold_1/runs/2o388rqu
wandb: Find logs at: ./wandb/run-20220315_022152-2o388rqu/logs/debug.log
wandb: 

wandb: wandb version 0.12.11 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
2022-03-15 04:17:30.989540: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1
wandb: Tracking run with wandb version 0.12.5
wandb: Syncing run cerulean-shape-2
wandb: ⭐️ View project at https://wandb.ai/yinanazhou/xl_512_bs_8_lr_1e06_es_15_lc_True_nr_True_sr_True_stem_False_lemma_False_repeat_1_fold_2
wandb: 🚀 View run at https://wandb.ai/yinanazhou/xl_512_bs_8_lr_1e06_es_15_lc_True_nr_True_sr_True_stem_False_lemma_False_repeat_1_fold_2/runs/1cn5nzk8
wandb: Run data is saved locally in /project/6002780/yinan/Thesis_MER_Lyrics/lyric-emotion/wandb/run-20220315_041728-1cn5nzk8
wandb: Run `wandb offline` to turn off syncing.

Validation loss decreased (inf --> 1.421672).  Saving model ...
Validation loss decreased (1.421672 --> 1.400863).  Saving model ...
Validation loss decreased (1.400863 --> 1.386358).  Saving model ...
Validation loss decreased (1.386358 --> 1.376003).  Saving model ...
Validation loss decreased (1.376003 --> 1.367940).  Saving model ...
Validation loss decreased (1.367940 --> 1.360871).  Saving model ...
Validation loss decreased (1.360871 --> 1.355256).  Saving model ...
Validation loss decreased (1.355256 --> 1.349920).  Saving model ...
Validation loss decreased (1.349920 --> 1.345532).  Saving model ...
Validation loss decreased (1.345532 --> 1.341352).  Saving model ...
Validation loss decreased (1.341352 --> 1.337436).  Saving model ...
Validation loss decreased (1.337436 --> 1.332821).  Saving model ...
Validation loss decreased (1.332821 --> 1.327830).  Saving model ...
Validation loss decreased (1.327830 --> 1.323057).  Saving model ...
Validation loss decreased (1.323057 --> 1.318486).  Saving model ...
Validation loss decreased (1.318486 --> 1.313003).  Saving model ...
Validation loss decreased (1.313003 --> 1.307890).  Saving model ...
Validation loss decreased (1.307890 --> 1.303359).  Saving model ...
Validation loss decreased (1.303359 --> 1.297588).  Saving model ...
Validation loss decreased (1.297588 --> 1.292136).  Saving model ...
Validation loss decreased (1.292136 --> 1.286153).  Saving model ...
Validation loss decreased (1.286153 --> 1.280815).  Saving model ...
Validation loss decreased (1.280815 --> 1.274806).  Saving model ...
Validation loss decreased (1.274806 --> 1.268840).  Saving model ...
Validation loss decreased (1.268840 --> 1.261420).  Saving model ...
Validation loss decreased (1.261420 --> 1.255428).  Saving model ...
Validation loss decreased (1.255428 --> 1.248691).  Saving model ...
Validation loss decreased (1.248691 --> 1.241980).  Saving model ...
Validation loss decreased (1.241980 --> 1.235983).  Saving model ...
Validation loss decreased (1.235983 --> 1.228672).  Saving model ...
Validation loss decreased (1.228672 --> 1.222280).  Saving model ...
Validation loss decreased (1.222280 --> 1.215119).  Saving model ...
Validation loss decreased (1.215119 --> 1.208175).  Saving model ...
Validation loss decreased (1.208175 --> 1.200392).  Saving model ...
Validation loss decreased (1.200392 --> 1.193134).  Saving model ...
Validation loss decreased (1.193134 --> 1.184601).  Saving model ...
Validation loss decreased (1.184601 --> 1.177943).  Saving model ...
Validation loss decreased (1.177943 --> 1.170470).  Saving model ...
Validation loss decreased (1.170470 --> 1.163636).  Saving model ...
Validation loss decreased (1.163636 --> 1.155933).  Saving model ...
Validation loss decreased (1.155933 --> 1.148450).  Saving model ...
Validation loss decreased (1.148450 --> 1.142112).  Saving model ...
Validation loss decreased (1.142112 --> 1.136145).  Saving model ...
Validation loss decreased (1.136145 --> 1.130484).  Saving model ...
Validation loss decreased (1.130484 --> 1.123887).  Saving model ...
Validation loss decreased (1.123887 --> 1.117035).  Saving model ...
Validation loss decreased (1.117035 --> 1.110237).  Saving model ...
Validation loss decreased (1.110237 --> 1.105117).  Saving model ...
Validation loss decreased (1.105117 --> 1.098592).  Saving model ...
Validation loss decreased (1.098592 --> 1.093564).  Saving model ...
Validation loss decreased (1.093564 --> 1.088993).  Saving model ...
Validation loss decreased (1.088993 --> 1.083585).  Saving model ...
Validation loss decreased (1.083585 --> 1.077671).  Saving model ...
Validation loss decreased (1.077671 --> 1.072959).  Saving model ...
Validation loss decreased (1.072959 --> 1.068138).  Saving model ...
Validation loss decreased (1.068138 --> 1.063638).  Saving model ...
Validation loss decreased (1.063638 --> 1.059326).  Saving model ...
Validation loss decreased (1.059326 --> 1.054074).  Saving model ...
Validation loss decreased (1.054074 --> 1.049336).  Saving model ...
Validation loss decreased (1.049336 --> 1.046422).  Saving model ...
Validation loss decreased (1.046422 --> 1.041858).  Saving model ...
Validation loss decreased (1.041858 --> 1.037097).  Saving model ...
Validation loss decreased (1.037097 --> 1.034203).  Saving model ...
Validation loss decreased (1.034203 --> 1.030765).  Saving model ...
Validation loss decreased (1.030765 --> 1.028655).  Saving model ...
Validation loss decreased (1.028655 --> 1.025579).  Saving model ...
Validation loss decreased (1.025579 --> 1.022041).  Saving model ...
Validation loss decreased (1.022041 --> 1.018070).  Saving model ...
Validation loss decreased (1.018070 --> 1.015079).  Saving model ...
Validation loss decreased (1.015079 --> 1.011010).  Saving model ...
Validation loss decreased (1.011010 --> 1.008478).  Saving model ...
Validation loss decreased (1.008478 --> 1.004804).  Saving model ...
Validation loss decreased (1.004804 --> 1.001806).  Saving model ...
Validation loss decreased (1.001806 --> 0.998974).  Saving model ...
Validation loss decreased (0.998974 --> 0.995943).  Saving model ...
Validation loss decreased (0.995943 --> 0.993728).  Saving model ...
Validation loss decreased (0.993728 --> 0.991197).  Saving model ...
Validation loss decreased (0.991197 --> 0.987231).  Saving model ...
Validation loss decreased (0.987231 --> 0.985046).  Saving model ...
Validation loss decreased (0.985046 --> 0.982155).  Saving model ...
Validation loss decreased (0.982155 --> 0.979982).  Saving model ...
Validation loss decreased (0.979982 --> 0.976420).  Saving model ...
Validation loss decreased (0.976420 --> 0.974717).  Saving model ...
Validation loss decreased (0.974717 --> 0.972484).  Saving model ...
Validation loss decreased (0.972484 --> 0.970306).  Saving model ...
Validation loss decreased (0.970306 --> 0.968277).  Saving model ...
Validation loss decreased (0.968277 --> 0.965461).  Saving model ...
Validation loss decreased (0.965461 --> 0.963262).  Saving model ...
Validation loss decreased (0.963262 --> 0.960870).  Saving model ...
Validation loss decreased (0.960870 --> 0.959857).  Saving model ...
Validation loss decreased (0.959857 --> 0.957688).  Saving model ...
Validation loss decreased (0.957688 --> 0.955742).  Saving model ...
Validation loss decreased (0.955742 --> 0.954803).  Saving model ...
Validation loss decreased (0.954803 --> 0.952551).  Saving model ...
Validation loss decreased (0.952551 --> 0.950140).  Saving model ...
Validation loss decreased (0.950140 --> 0.948835).  Saving model ...
Validation loss decreased (0.948835 --> 0.946977).  Saving model ...
Validation loss decreased (0.946977 --> 0.945854).  Saving model ...
Validation loss decreased (0.945854 --> 0.944134).  Saving model ...
Validation loss decreased (0.944134 --> 0.942809).  Saving model ...
Validation loss decreased (0.942809 --> 0.942129).  Saving model ...
Validation loss decreased (0.942129 --> 0.941306).  Saving model ...
Validation loss decreased (0.941306 --> 0.938578).  Saving model ...
Validation loss decreased (0.938578 --> 0.937853).  Saving model ...
Validation loss decreased (0.937853 --> 0.936779).  Saving model ...
EarlyStopping counter: 1 out of 15.0
Validation loss decreased (0.936779 --> 0.935534).  Saving model ...
EarlyStopping counter: 1 out of 15.0
Validation loss decreased (0.935534 --> 0.934899).  Saving model ...
Validation loss decreased (0.934899 --> 0.933279).  Saving model ...
Validation loss decreased (0.933279 --> 0.932294).  Saving model ...
Validation loss decreased (0.932294 --> 0.931923).  Saving model ...
Validation loss decreased (0.931923 --> 0.931672).  Saving model ...
Validation loss decreased (0.931672 --> 0.930090).  Saving model ...
EarlyStopping counter: 1 out of 15.0
Validation loss decreased (0.930090 --> 0.929270).  Saving model ...
Validation loss decreased (0.929270 --> 0.927750).  Saving model ...
Validation loss decreased (0.927750 --> 0.926909).  Saving model ...
EarlyStopping counter: 1 out of 15.0
Validation loss decreased (0.926909 --> 0.926123).  Saving model ...
EarlyStopping counter: 1 out of 15.0
Validation loss decreased (0.926123 --> 0.926044).  Saving model ...
Validation loss decreased (0.926044 --> 0.925715).  Saving model ...
Validation loss decreased (0.925715 --> 0.925168).  Saving model ...
Validation loss decreased (0.925168 --> 0.924649).  Saving model ...
Validation loss decreased (0.924649 --> 0.923351).  Saving model ...
EarlyStopping counter: 1 out of 15.0
Validation loss decreased (0.923351 --> 0.922787).  Saving model ...
EarlyStopping counter: 1 out of 15.0
EarlyStopping counter: 2 out of 15.0
EarlyStopping counter: 3 out of 15.0
EarlyStopping counter: 4 out of 15.0
Validation loss decreased (0.922787 --> 0.922614).  Saving model ...
Validation loss decreased (0.922614 --> 0.922265).  Saving model ...
EarlyStopping counter: 1 out of 15.0
EarlyStopping counter: 2 out of 15.0
EarlyStopping counter: 3 out of 15.0
Validation loss decreased (0.922265 --> 0.922098).  Saving model ...
Validation loss decreased (0.922098 --> 0.921118).  Saving model ...
EarlyStopping counter: 1 out of 15.0
EarlyStopping counter: 2 out of 15.0
EarlyStopping counter: 3 out of 15.0
EarlyStopping counter: 4 out of 15.0
EarlyStopping counter: 5 out of 15.0
EarlyStopping counter: 6 out of 15.0
EarlyStopping counter: 7 out of 15.0
EarlyStopping counter: 8 out of 15.0
EarlyStopping counter: 9 out of 15.0
EarlyStopping counter: 10 out of 15.0
EarlyStopping counter: 11 out of 15.0
EarlyStopping counter: 12 out of 15.0
EarlyStopping counter: 13 out of 15.0
EarlyStopping counter: 14 out of 15.0
EarlyStopping counter: 15 out of 15.0
/localscratch/yinan.28698853.0/env/lib/python3.7/site-packages/torch/nn/functional.py:1794: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.
  warnings.warn("nn.functional.tanh is deprecated. Use torch.tanh instead.")
wandb: Waiting for W&B process to finish, PID 206287... (success).
wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: \ 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: | 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: / 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: \ 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: | 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: / 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: \ 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: | 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: / 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb:                                                                                
wandb: Run history:
wandb:     e_F1 ▁▂▄▅▅▆▆▇▇▇▇▇▇███████████████████████████
wandb:   e_loss ██▇▇▇▆▆▆▅▅▄▄▄▃▃▃▃▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:     t_F1 ▁▂▃▃▃▃▄▄▄▅▄▅▅▅▆▆▆▆▆▆▆▆▇▆▇▇▇▇▇▇▇▇█▇▇█████
wandb:   t_loss ██▇▇▇▇▇▆▆▆▆▆▅▅▅▅▄▄▄▄▄▄▃▃▃▃▃▃▃▃▂▂▂▂▂▁▂▁▁▁
wandb: 
wandb: Run summary:
wandb:     e_F1 59.39858
wandb:   e_loss 0.92337
wandb:     t_F1 74.90633
wandb:   t_loss 0.67933
wandb: 
wandb: Synced 4 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Synced cerulean-shape-2: https://wandb.ai/yinanazhou/xl_512_bs_8_lr_1e06_es_15_lc_True_nr_True_sr_True_stem_False_lemma_False_repeat_1_fold_2/runs/1cn5nzk8
wandb: Find logs at: ./wandb/run-20220315_041728-1cn5nzk8/logs/debug.log
wandb: 

wandb: wandb version 0.12.11 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
2022-03-15 05:59:36.199559: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1
wandb: Tracking run with wandb version 0.12.5
wandb: Syncing run amber-bush-2
wandb: ⭐️ View project at https://wandb.ai/yinanazhou/xl_512_bs_8_lr_1e06_es_15_lc_True_nr_True_sr_True_stem_False_lemma_False_repeat_2_fold_1
wandb: 🚀 View run at https://wandb.ai/yinanazhou/xl_512_bs_8_lr_1e06_es_15_lc_True_nr_True_sr_True_stem_False_lemma_False_repeat_2_fold_1/runs/1a3vhpy2
wandb: Run data is saved locally in /project/6002780/yinan/Thesis_MER_Lyrics/lyric-emotion/wandb/run-20220315_055933-1a3vhpy2
wandb: Run `wandb offline` to turn off syncing.

Validation loss decreased (inf --> 1.404627).  Saving model ...
Validation loss decreased (1.404627 --> 1.396246).  Saving model ...
Validation loss decreased (1.396246 --> 1.389379).  Saving model ...
Validation loss decreased (1.389379 --> 1.383568).  Saving model ...
Validation loss decreased (1.383568 --> 1.378622).  Saving model ...
Validation loss decreased (1.378622 --> 1.374032).  Saving model ...
Validation loss decreased (1.374032 --> 1.369483).  Saving model ...
Validation loss decreased (1.369483 --> 1.365167).  Saving model ...
Validation loss decreased (1.365167 --> 1.361050).  Saving model ...
Validation loss decreased (1.361050 --> 1.356469).  Saving model ...
Validation loss decreased (1.356469 --> 1.352091).  Saving model ...
Validation loss decreased (1.352091 --> 1.347943).  Saving model ...
Validation loss decreased (1.347943 --> 1.343789).  Saving model ...
Validation loss decreased (1.343789 --> 1.339225).  Saving model ...
Validation loss decreased (1.339225 --> 1.334267).  Saving model ...
Validation loss decreased (1.334267 --> 1.329371).  Saving model ...
Validation loss decreased (1.329371 --> 1.324013).  Saving model ...
Validation loss decreased (1.324013 --> 1.318264).  Saving model ...
Validation loss decreased (1.318264 --> 1.312268).  Saving model ...
Validation loss decreased (1.312268 --> 1.306572).  Saving model ...
Validation loss decreased (1.306572 --> 1.300467).  Saving model ...
Validation loss decreased (1.300467 --> 1.294106).  Saving model ...
Validation loss decreased (1.294106 --> 1.287063).  Saving model ...
Validation loss decreased (1.287063 --> 1.280649).  Saving model ...
Validation loss decreased (1.280649 --> 1.273738).  Saving model ...
Validation loss decreased (1.273738 --> 1.266278).  Saving model ...
Validation loss decreased (1.266278 --> 1.259242).  Saving model ...
Validation loss decreased (1.259242 --> 1.252279).  Saving model ...
Validation loss decreased (1.252279 --> 1.245600).  Saving model ...
Validation loss decreased (1.245600 --> 1.238012).  Saving model ...
Validation loss decreased (1.238012 --> 1.230839).  Saving model ...
Validation loss decreased (1.230839 --> 1.223621).  Saving model ...
Validation loss decreased (1.223621 --> 1.216786).  Saving model ...
Validation loss decreased (1.216786 --> 1.211494).  Saving model ...
Validation loss decreased (1.211494 --> 1.204545).  Saving model ...
Validation loss decreased (1.204545 --> 1.198902).  Saving model ...
Validation loss decreased (1.198902 --> 1.191076).  Saving model ...
Validation loss decreased (1.191076 --> 1.185764).  Saving model ...
Validation loss decreased (1.185764 --> 1.180826).  Saving model ...
Validation loss decreased (1.180826 --> 1.174612).  Saving model ...
Validation loss decreased (1.174612 --> 1.169620).  Saving model ...
Validation loss decreased (1.169620 --> 1.164633).  Saving model ...
Validation loss decreased (1.164633 --> 1.159705).  Saving model ...
Validation loss decreased (1.159705 --> 1.154355).  Saving model ...
Validation loss decreased (1.154355 --> 1.148714).  Saving model ...
Validation loss decreased (1.148714 --> 1.146168).  Saving model ...
Validation loss decreased (1.146168 --> 1.142056).  Saving model ...
Validation loss decreased (1.142056 --> 1.137049).  Saving model ...
Validation loss decreased (1.137049 --> 1.132349).  Saving model ...
Validation loss decreased (1.132349 --> 1.129493).  Saving model ...
Validation loss decreased (1.129493 --> 1.126086).  Saving model ...
Validation loss decreased (1.126086 --> 1.122182).  Saving model ...
Validation loss decreased (1.122182 --> 1.118015).  Saving model ...
Validation loss decreased (1.118015 --> 1.113520).  Saving model ...
Validation loss decreased (1.113520 --> 1.110241).  Saving model ...
Validation loss decreased (1.110241 --> 1.107389).  Saving model ...
Validation loss decreased (1.107389 --> 1.104411).  Saving model ...
Validation loss decreased (1.104411 --> 1.098634).  Saving model ...
Validation loss decreased (1.098634 --> 1.096506).  Saving model ...
Validation loss decreased (1.096506 --> 1.094669).  Saving model ...
Validation loss decreased (1.094669 --> 1.090741).  Saving model ...
Validation loss decreased (1.090741 --> 1.084204).  Saving model ...
Validation loss decreased (1.084204 --> 1.080450).  Saving model ...
Validation loss decreased (1.080450 --> 1.077789).  Saving model ...
Validation loss decreased (1.077789 --> 1.073750).  Saving model ...
Validation loss decreased (1.073750 --> 1.070525).  Saving model ...
Validation loss decreased (1.070525 --> 1.066916).  Saving model ...
Validation loss decreased (1.066916 --> 1.064769).  Saving model ...
Validation loss decreased (1.064769 --> 1.064339).  Saving model ...
Validation loss decreased (1.064339 --> 1.061178).  Saving model ...
Validation loss decreased (1.061178 --> 1.055881).  Saving model ...
Validation loss decreased (1.055881 --> 1.052891).  Saving model ...
Validation loss decreased (1.052891 --> 1.051198).  Saving model ...
Validation loss decreased (1.051198 --> 1.046604).  Saving model ...
Validation loss decreased (1.046604 --> 1.045595).  Saving model ...
Validation loss decreased (1.045595 --> 1.044007).  Saving model ...
Validation loss decreased (1.044007 --> 1.039749).  Saving model ...
Validation loss decreased (1.039749 --> 1.038654).  Saving model ...
Validation loss decreased (1.038654 --> 1.037282).  Saving model ...
Validation loss decreased (1.037282 --> 1.034934).  Saving model ...
Validation loss decreased (1.034934 --> 1.034820).  Saving model ...
Validation loss decreased (1.034820 --> 1.034306).  Saving model ...
Validation loss decreased (1.034306 --> 1.031007).  Saving model ...
Validation loss decreased (1.031007 --> 1.029781).  Saving model ...
Validation loss decreased (1.029781 --> 1.027230).  Saving model ...
Validation loss decreased (1.027230 --> 1.023953).  Saving model ...
Validation loss decreased (1.023953 --> 1.022131).  Saving model ...
Validation loss decreased (1.022131 --> 1.019058).  Saving model ...
Validation loss decreased (1.019058 --> 1.016005).  Saving model ...
Validation loss decreased (1.016005 --> 1.015737).  Saving model ...
Validation loss decreased (1.015737 --> 1.014178).  Saving model ...
EarlyStopping counter: 1 out of 15.0
Validation loss decreased (1.014178 --> 1.011599).  Saving model ...
Validation loss decreased (1.011599 --> 1.009731).  Saving model ...
EarlyStopping counter: 1 out of 15.0
Validation loss decreased (1.009731 --> 1.007839).  Saving model ...
Validation loss decreased (1.007839 --> 1.005874).  Saving model ...
Validation loss decreased (1.005874 --> 1.003135).  Saving model ...
EarlyStopping counter: 1 out of 15.0
EarlyStopping counter: 2 out of 15.0
EarlyStopping counter: 3 out of 15.0
Validation loss decreased (1.003135 --> 1.000086).  Saving model ...
Validation loss decreased (1.000086 --> 0.997823).  Saving model ...
Validation loss decreased (0.997823 --> 0.996467).  Saving model ...
Validation loss decreased (0.996467 --> 0.994322).  Saving model ...
Validation loss decreased (0.994322 --> 0.993899).  Saving model ...
Validation loss decreased (0.993899 --> 0.992763).  Saving model ...
Validation loss decreased (0.992763 --> 0.992155).  Saving model ...
Validation loss decreased (0.992155 --> 0.991286).  Saving model ...
EarlyStopping counter: 1 out of 15.0
EarlyStopping counter: 2 out of 15.0
Validation loss decreased (0.991286 --> 0.989778).  Saving model ...
EarlyStopping counter: 1 out of 15.0
EarlyStopping counter: 2 out of 15.0
EarlyStopping counter: 3 out of 15.0
EarlyStopping counter: 4 out of 15.0
Validation loss decreased (0.989778 --> 0.989294).  Saving model ...
Validation loss decreased (0.989294 --> 0.988326).  Saving model ...
Validation loss decreased (0.988326 --> 0.986330).  Saving model ...
EarlyStopping counter: 1 out of 15.0
EarlyStopping counter: 2 out of 15.0
Validation loss decreased (0.986330 --> 0.984385).  Saving model ...
Validation loss decreased (0.984385 --> 0.983569).  Saving model ...
Validation loss decreased (0.983569 --> 0.981817).  Saving model ...
EarlyStopping counter: 1 out of 15.0
Validation loss decreased (0.981817 --> 0.981132).  Saving model ...
EarlyStopping counter: 1 out of 15.0
Validation loss decreased (0.981132 --> 0.980589).  Saving model ...
EarlyStopping counter: 1 out of 15.0
EarlyStopping counter: 2 out of 15.0
EarlyStopping counter: 3 out of 15.0
EarlyStopping counter: 4 out of 15.0
Validation loss decreased (0.980589 --> 0.980336).  Saving model ...
Validation loss decreased (0.980336 --> 0.980142).  Saving model ...
EarlyStopping counter: 1 out of 15.0
EarlyStopping counter: 2 out of 15.0
EarlyStopping counter: 3 out of 15.0
EarlyStopping counter: 4 out of 15.0
EarlyStopping counter: 5 out of 15.0
EarlyStopping counter: 6 out of 15.0
Validation loss decreased (0.980142 --> 0.980060).  Saving model ...
EarlyStopping counter: 1 out of 15.0
EarlyStopping counter: 2 out of 15.0
Validation loss decreased (0.980060 --> 0.979161).  Saving model ...
EarlyStopping counter: 1 out of 15.0
EarlyStopping counter: 2 out of 15.0
EarlyStopping counter: 3 out of 15.0
EarlyStopping counter: 4 out of 15.0
EarlyStopping counter: 5 out of 15.0
EarlyStopping counter: 6 out of 15.0
EarlyStopping counter: 7 out of 15.0
EarlyStopping counter: 8 out of 15.0
EarlyStopping counter: 9 out of 15.0
EarlyStopping counter: 10 out of 15.0
EarlyStopping counter: 11 out of 15.0
EarlyStopping counter: 12 out of 15.0
EarlyStopping counter: 13 out of 15.0
EarlyStopping counter: 14 out of 15.0
EarlyStopping counter: 15 out of 15.0
/localscratch/yinan.28698853.0/env/lib/python3.7/site-packages/torch/nn/functional.py:1794: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.
  warnings.warn("nn.functional.tanh is deprecated. Use torch.tanh instead.")
wandb: Waiting for W&B process to finish, PID 211719... (success).
wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: \ 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: | 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: / 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: \ 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: | 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: / 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: \ 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: | 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: / 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: \ 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: | 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: / 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: \ 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: | 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: / 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: \ 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: | 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: / 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: \ 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: | 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: / 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: \ 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: | 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: / 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: \ 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: | 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: / 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: \ 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: | 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb:                                                                                
wandb: Run history:
wandb:     e_F1 ▁▃▄▄▅▆▆▆▆▇▇▇▇▇▇▇▇▇▇▇▇███▇███████████████
wandb:   e_loss ██▇▇▇▆▆▅▅▄▄▄▄▃▃▃▃▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:     t_F1 ▁▂▃▂▃▄▄▄▄▅▅▅▅▅▆▆▆▆▆▆▆▆▇▆▇▇▇▇▇▇▇▇▇▇██▇███
wandb:   t_loss ██▇█▇▇▇▆▆▆▆▅▅▅▅▅▄▄▄▄▃▄▃▃▃▃▃▃▃▂▂▂▂▂▂▂▂▂▁▁
wandb: 
wandb: Run summary:
wandb:     e_F1 60.76441
wandb:   e_loss 0.98211
wandb:     t_F1 75.33796
wandb:   t_loss 0.65751
wandb: 
wandb: Synced 4 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Synced amber-bush-2: https://wandb.ai/yinanazhou/xl_512_bs_8_lr_1e06_es_15_lc_True_nr_True_sr_True_stem_False_lemma_False_repeat_2_fold_1/runs/1a3vhpy2
wandb: Find logs at: ./wandb/run-20220315_055933-1a3vhpy2/logs/debug.log
wandb: 

wandb: wandb version 0.12.11 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
2022-03-15 07:45:10.073031: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1
wandb: Tracking run with wandb version 0.12.5
wandb: Syncing run lively-haze-2
wandb: ⭐️ View project at https://wandb.ai/yinanazhou/xl_512_bs_8_lr_1e06_es_15_lc_True_nr_True_sr_True_stem_False_lemma_False_repeat_2_fold_2
wandb: 🚀 View run at https://wandb.ai/yinanazhou/xl_512_bs_8_lr_1e06_es_15_lc_True_nr_True_sr_True_stem_False_lemma_False_repeat_2_fold_2/runs/qmu87ia7
wandb: Run data is saved locally in /project/6002780/yinan/Thesis_MER_Lyrics/lyric-emotion/wandb/run-20220315_074507-qmu87ia7
wandb: Run `wandb offline` to turn off syncing.

Validation loss decreased (inf --> 1.414292).  Saving model ...
Validation loss decreased (1.414292 --> 1.399752).  Saving model ...
Validation loss decreased (1.399752 --> 1.388851).  Saving model ...
Validation loss decreased (1.388851 --> 1.380401).  Saving model ...
Validation loss decreased (1.380401 --> 1.373222).  Saving model ...
Validation loss decreased (1.373222 --> 1.367070).  Saving model ...
Validation loss decreased (1.367070 --> 1.361676).  Saving model ...
Validation loss decreased (1.361676 --> 1.356847).  Saving model ...
Validation loss decreased (1.356847 --> 1.352915).  Saving model ...
Validation loss decreased (1.352915 --> 1.348287).  Saving model ...
Validation loss decreased (1.348287 --> 1.343899).  Saving model ...
Validation loss decreased (1.343899 --> 1.339512).  Saving model ...
Validation loss decreased (1.339512 --> 1.335456).  Saving model ...
Validation loss decreased (1.335456 --> 1.330785).  Saving model ...
Validation loss decreased (1.330785 --> 1.326381).  Saving model ...
Validation loss decreased (1.326381 --> 1.321740).  Saving model ...
Validation loss decreased (1.321740 --> 1.317002).  Saving model ...
Validation loss decreased (1.317002 --> 1.312207).  Saving model ...
Validation loss decreased (1.312207 --> 1.307578).  Saving model ...
Validation loss decreased (1.307578 --> 1.302174).  Saving model ...
Validation loss decreased (1.302174 --> 1.296736).  Saving model ...
Validation loss decreased (1.296736 --> 1.290997).  Saving model ...
Validation loss decreased (1.290997 --> 1.284808).  Saving model ...
Validation loss decreased (1.284808 --> 1.279113).  Saving model ...
Validation loss decreased (1.279113 --> 1.273970).  Saving model ...
Validation loss decreased (1.273970 --> 1.267723).  Saving model ...
Validation loss decreased (1.267723 --> 1.261851).  Saving model ...
Validation loss decreased (1.261851 --> 1.254978).  Saving model ...
Validation loss decreased (1.254978 --> 1.248573).  Saving model ...
Validation loss decreased (1.248573 --> 1.241396).  Saving model ...
Validation loss decreased (1.241396 --> 1.234815).  Saving model ...
Validation loss decreased (1.234815 --> 1.228171).  Saving model ...
Validation loss decreased (1.228171 --> 1.221400).  Saving model ...
Validation loss decreased (1.221400 --> 1.214475).  Saving model ...
Validation loss decreased (1.214475 --> 1.207708).  Saving model ...
Validation loss decreased (1.207708 --> 1.201884).  Saving model ...
Validation loss decreased (1.201884 --> 1.195218).  Saving model ...
Validation loss decreased (1.195218 --> 1.188971).  Saving model ...
Validation loss decreased (1.188971 --> 1.184265).  Saving model ...
Validation loss decreased (1.184265 --> 1.178640).  Saving model ...
Validation loss decreased (1.178640 --> 1.173991).  Saving model ...
Validation loss decreased (1.173991 --> 1.167511).  Saving model ...
Validation loss decreased (1.167511 --> 1.163322).  Saving model ...
Validation loss decreased (1.163322 --> 1.158436).  Saving model ...
Validation loss decreased (1.158436 --> 1.152714).  Saving model ...
Validation loss decreased (1.152714 --> 1.147041).  Saving model ...
Validation loss decreased (1.147041 --> 1.141226).  Saving model ...
Validation loss decreased (1.141226 --> 1.136820).  Saving model ...
Validation loss decreased (1.136820 --> 1.131089).  Saving model ...
Validation loss decreased (1.131089 --> 1.125092).  Saving model ...
Validation loss decreased (1.125092 --> 1.122114).  Saving model ...
Validation loss decreased (1.122114 --> 1.117585).  Saving model ...
Validation loss decreased (1.117585 --> 1.112299).  Saving model ...
Validation loss decreased (1.112299 --> 1.107524).  Saving model ...
Validation loss decreased (1.107524 --> 1.105385).  Saving model ...
Validation loss decreased (1.105385 --> 1.101733).  Saving model ...
Validation loss decreased (1.101733 --> 1.095895).  Saving model ...
Validation loss decreased (1.095895 --> 1.091307).  Saving model ...
Validation loss decreased (1.091307 --> 1.086589).  Saving model ...
Validation loss decreased (1.086589 --> 1.083969).  Saving model ...
Validation loss decreased (1.083969 --> 1.080334).  Saving model ...
Validation loss decreased (1.080334 --> 1.077348).  Saving model ...
Validation loss decreased (1.077348 --> 1.073469).  Saving model ...
Validation loss decreased (1.073469 --> 1.070423).  Saving model ...
Validation loss decreased (1.070423 --> 1.066308).  Saving model ...
Validation loss decreased (1.066308 --> 1.062368).  Saving model ...
Validation loss decreased (1.062368 --> 1.056449).  Saving model ...
Validation loss decreased (1.056449 --> 1.053717).  Saving model ...
Validation loss decreased (1.053717 --> 1.051004).  Saving model ...
EarlyStopping counter: 1 out of 15.0
Validation loss decreased (1.051004 --> 1.047913).  Saving model ...
Validation loss decreased (1.047913 --> 1.044239).  Saving model ...
Validation loss decreased (1.044239 --> 1.041285).  Saving model ...
Validation loss decreased (1.041285 --> 1.038116).  Saving model ...
Validation loss decreased (1.038116 --> 1.034176).  Saving model ...
Validation loss decreased (1.034176 --> 1.030988).  Saving model ...
Validation loss decreased (1.030988 --> 1.028434).  Saving model ...
Validation loss decreased (1.028434 --> 1.027308).  Saving model ...
Validation loss decreased (1.027308 --> 1.025526).  Saving model ...
Validation loss decreased (1.025526 --> 1.023038).  Saving model ...
Validation loss decreased (1.023038 --> 1.019374).  Saving model ...
Validation loss decreased (1.019374 --> 1.017031).  Saving model ...
Validation loss decreased (1.017031 --> 1.015040).  Saving model ...
Validation loss decreased (1.015040 --> 1.013344).  Saving model ...
Validation loss decreased (1.013344 --> 1.009706).  Saving model ...
Validation loss decreased (1.009706 --> 1.006867).  Saving model ...
Validation loss decreased (1.006867 --> 1.003629).  Saving model ...
Validation loss decreased (1.003629 --> 1.002676).  Saving model ...
Validation loss decreased (1.002676 --> 1.000852).  Saving model ...
Validation loss decreased (1.000852 --> 0.998883).  Saving model ...
Validation loss decreased (0.998883 --> 0.997080).  Saving model ...
Validation loss decreased (0.997080 --> 0.994769).  Saving model ...
Validation loss decreased (0.994769 --> 0.991462).  Saving model ...
EarlyStopping counter: 1 out of 15.0
Validation loss decreased (0.991462 --> 0.988154).  Saving model ...
Validation loss decreased (0.988154 --> 0.986807).  Saving model ...
EarlyStopping counter: 1 out of 15.0
Validation loss decreased (0.986807 --> 0.985465).  Saving model ...
Validation loss decreased (0.985465 --> 0.983962).  Saving model ...
Validation loss decreased (0.983962 --> 0.980048).  Saving model ...
EarlyStopping counter: 1 out of 15.0
Validation loss decreased (0.980048 --> 0.976917).  Saving model ...
Validation loss decreased (0.976917 --> 0.973739).  Saving model ...
EarlyStopping counter: 1 out of 15.0
Validation loss decreased (0.973739 --> 0.972927).  Saving model ...
Validation loss decreased (0.972927 --> 0.971737).  Saving model ...
Validation loss decreased (0.971737 --> 0.969476).  Saving model ...
Validation loss decreased (0.969476 --> 0.965393).  Saving model ...
Validation loss decreased (0.965393 --> 0.964920).  Saving model ...
EarlyStopping counter: 1 out of 15.0
Validation loss decreased (0.964920 --> 0.963729).  Saving model ...
EarlyStopping counter: 1 out of 15.0
Validation loss decreased (0.963729 --> 0.961054).  Saving model ...
Validation loss decreased (0.961054 --> 0.959185).  Saving model ...
EarlyStopping counter: 1 out of 15.0
EarlyStopping counter: 2 out of 15.0
Validation loss decreased (0.959185 --> 0.955832).  Saving model ...
Validation loss decreased (0.955832 --> 0.955108).  Saving model ...
Validation loss decreased (0.955108 --> 0.954110).  Saving model ...
EarlyStopping counter: 1 out of 15.0
Validation loss decreased (0.954110 --> 0.953238).  Saving model ...
Validation loss decreased (0.953238 --> 0.951705).  Saving model ...
Validation loss decreased (0.951705 --> 0.951267).  Saving model ...
Validation loss decreased (0.951267 --> 0.950277).  Saving model ...
Validation loss decreased (0.950277 --> 0.949233).  Saving model ...
EarlyStopping counter: 1 out of 15.0
EarlyStopping counter: 2 out of 15.0
EarlyStopping counter: 3 out of 15.0
Validation loss decreased (0.949233 --> 0.946116).  Saving model ...
EarlyStopping counter: 1 out of 15.0
EarlyStopping counter: 2 out of 15.0
EarlyStopping counter: 3 out of 15.0
Validation loss decreased (0.946116 --> 0.946083).  Saving model ...
EarlyStopping counter: 1 out of 15.0
Validation loss decreased (0.946083 --> 0.945170).  Saving model ...
Validation loss decreased (0.945170 --> 0.943759).  Saving model ...
Validation loss decreased (0.943759 --> 0.940311).  Saving model ...
EarlyStopping counter: 1 out of 15.0
EarlyStopping counter: 2 out of 15.0
EarlyStopping counter: 3 out of 15.0
EarlyStopping counter: 4 out of 15.0
EarlyStopping counter: 5 out of 15.0
EarlyStopping counter: 6 out of 15.0
EarlyStopping counter: 7 out of 15.0
EarlyStopping counter: 8 out of 15.0
EarlyStopping counter: 9 out of 15.0
EarlyStopping counter: 10 out of 15.0
EarlyStopping counter: 11 out of 15.0
EarlyStopping counter: 12 out of 15.0
EarlyStopping counter: 13 out of 15.0
EarlyStopping counter: 14 out of 15.0
EarlyStopping counter: 15 out of 15.0
/localscratch/yinan.28698853.0/env/lib/python3.7/site-packages/torch/nn/functional.py:1794: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.
  warnings.warn("nn.functional.tanh is deprecated. Use torch.tanh instead.")
wandb: Waiting for W&B process to finish, PID 217365... (success).
wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: \ 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: | 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: / 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: \ 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: | 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: / 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: \ 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: | 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: / 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb:                                                                                
wandb: Run history:
wandb:     e_F1 ▁▂▂▄▄▅▅▆▆▆▆▆▆▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇████████████
wandb:   e_loss ██▇▇▇▇▆▆▅▅▅▄▄▄▄▃▃▃▃▂▂▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁
wandb:     t_F1 ▁▁▂▂▃▃▄▄▅▅▅▅▅▅▆▆▆▆▆▆▆▇▇▇▇▇▇▇▇██▇█▇█▇████
wandb:   t_loss ███▇▇▇▇▆▆▆▆▅▅▅▅▄▄▄▄▄▄▃▃▃▃▃▃▃▂▂▂▂▁▂▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:     e_F1 59.86455
wandb:   e_loss 0.94499
wandb:     t_F1 70.37411
wandb:   t_loss 0.76359
wandb: 
wandb: Synced 4 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Synced lively-haze-2: https://wandb.ai/yinanazhou/xl_512_bs_8_lr_1e06_es_15_lc_True_nr_True_sr_True_stem_False_lemma_False_repeat_2_fold_2/runs/qmu87ia7
wandb: Find logs at: ./wandb/run-20220315_074507-qmu87ia7/logs/debug.log
wandb: 

wandb: wandb version 0.12.11 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
2022-03-15 09:20:43.208195: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1
wandb: Tracking run with wandb version 0.12.5
wandb: Syncing run different-gorge-2
wandb: ⭐️ View project at https://wandb.ai/yinanazhou/xl_512_bs_8_lr_1e06_es_15_lc_True_nr_True_sr_True_stem_False_lemma_False_repeat_3_fold_1
wandb: 🚀 View run at https://wandb.ai/yinanazhou/xl_512_bs_8_lr_1e06_es_15_lc_True_nr_True_sr_True_stem_False_lemma_False_repeat_3_fold_1/runs/2gk3ofd7
wandb: Run data is saved locally in /project/6002780/yinan/Thesis_MER_Lyrics/lyric-emotion/wandb/run-20220315_092040-2gk3ofd7
wandb: Run `wandb offline` to turn off syncing.

Validation loss decreased (inf --> 1.470445).  Saving model ...
Validation loss decreased (1.470445 --> 1.444739).  Saving model ...
Validation loss decreased (1.444739 --> 1.424989).  Saving model ...
Validation loss decreased (1.424989 --> 1.410357).  Saving model ...
Validation loss decreased (1.410357 --> 1.399861).  Saving model ...
Validation loss decreased (1.399861 --> 1.390749).  Saving model ...
Validation loss decreased (1.390749 --> 1.382024).  Saving model ...
Validation loss decreased (1.382024 --> 1.375412).  Saving model ...
Validation loss decreased (1.375412 --> 1.369652).  Saving model ...
Validation loss decreased (1.369652 --> 1.363901).  Saving model ...
Validation loss decreased (1.363901 --> 1.358785).  Saving model ...
Validation loss decreased (1.358785 --> 1.354399).  Saving model ...
Validation loss decreased (1.354399 --> 1.350160).  Saving model ...
Validation loss decreased (1.350160 --> 1.345272).  Saving model ...
Validation loss decreased (1.345272 --> 1.340207).  Saving model ...
Validation loss decreased (1.340207 --> 1.335420).  Saving model ...
Validation loss decreased (1.335420 --> 1.329494).  Saving model ...
Validation loss decreased (1.329494 --> 1.324370).  Saving model ...
Validation loss decreased (1.324370 --> 1.317847).  Saving model ...
Validation loss decreased (1.317847 --> 1.311669).  Saving model ...
Validation loss decreased (1.311669 --> 1.305213).  Saving model ...
Validation loss decreased (1.305213 --> 1.298425).  Saving model ...
Validation loss decreased (1.298425 --> 1.291635).  Saving model ...
Validation loss decreased (1.291635 --> 1.286461).  Saving model ...
Validation loss decreased (1.286461 --> 1.280849).  Saving model ...
Validation loss decreased (1.280849 --> 1.273953).  Saving model ...
Validation loss decreased (1.273953 --> 1.266865).  Saving model ...
Validation loss decreased (1.266865 --> 1.262910).  Saving model ...
Validation loss decreased (1.262910 --> 1.254989).  Saving model ...
Validation loss decreased (1.254989 --> 1.248201).  Saving model ...
Validation loss decreased (1.248201 --> 1.241349).  Saving model ...
Validation loss decreased (1.241349 --> 1.232738).  Saving model ...
Validation loss decreased (1.232738 --> 1.227774).  Saving model ...
Validation loss decreased (1.227774 --> 1.223269).  Saving model ...
Validation loss decreased (1.223269 --> 1.217900).  Saving model ...
Validation loss decreased (1.217900 --> 1.209619).  Saving model ...
Validation loss decreased (1.209619 --> 1.203606).  Saving model ...
Validation loss decreased (1.203606 --> 1.196009).  Saving model ...
Validation loss decreased (1.196009 --> 1.192020).  Saving model ...
Validation loss decreased (1.192020 --> 1.187550).  Saving model ...
Validation loss decreased (1.187550 --> 1.185039).  Saving model ...
Validation loss decreased (1.185039 --> 1.180483).  Saving model ...
Validation loss decreased (1.180483 --> 1.175726).  Saving model ...
Validation loss decreased (1.175726 --> 1.170488).  Saving model ...
Validation loss decreased (1.170488 --> 1.163451).  Saving model ...
Validation loss decreased (1.163451 --> 1.162095).  Saving model ...
Validation loss decreased (1.162095 --> 1.157212).  Saving model ...
Validation loss decreased (1.157212 --> 1.150953).  Saving model ...
Validation loss decreased (1.150953 --> 1.147374).  Saving model ...
Validation loss decreased (1.147374 --> 1.142637).  Saving model ...
Validation loss decreased (1.142637 --> 1.139340).  Saving model ...
Validation loss decreased (1.139340 --> 1.136955).  Saving model ...
Validation loss decreased (1.136955 --> 1.128780).  Saving model ...
Validation loss decreased (1.128780 --> 1.124914).  Saving model ...
EarlyStopping counter: 1 out of 15.0
Validation loss decreased (1.124914 --> 1.121138).  Saving model ...
Validation loss decreased (1.121138 --> 1.117301).  Saving model ...
Validation loss decreased (1.117301 --> 1.114658).  Saving model ...
Validation loss decreased (1.114658 --> 1.106782).  Saving model ...
Validation loss decreased (1.106782 --> 1.102006).  Saving model ...
Validation loss decreased (1.102006 --> 1.095692).  Saving model ...
Validation loss decreased (1.095692 --> 1.093621).  Saving model ...
Validation loss decreased (1.093621 --> 1.092182).  Saving model ...
Validation loss decreased (1.092182 --> 1.091118).  Saving model ...
Validation loss decreased (1.091118 --> 1.084589).  Saving model ...
Validation loss decreased (1.084589 --> 1.082073).  Saving model ...
Validation loss decreased (1.082073 --> 1.077577).  Saving model ...
Validation loss decreased (1.077577 --> 1.071761).  Saving model ...
EarlyStopping counter: 1 out of 15.0
Validation loss decreased (1.071761 --> 1.071097).  Saving model ...
Validation loss decreased (1.071097 --> 1.066895).  Saving model ...
Validation loss decreased (1.066895 --> 1.066118).  Saving model ...
Validation loss decreased (1.066118 --> 1.062953).  Saving model ...
Validation loss decreased (1.062953 --> 1.062036).  Saving model ...
Validation loss decreased (1.062036 --> 1.056478).  Saving model ...
Validation loss decreased (1.056478 --> 1.053451).  Saving model ...
Validation loss decreased (1.053451 --> 1.052896).  Saving model ...
Validation loss decreased (1.052896 --> 1.051572).  Saving model ...
Validation loss decreased (1.051572 --> 1.046772).  Saving model ...
Validation loss decreased (1.046772 --> 1.046095).  Saving model ...
Validation loss decreased (1.046095 --> 1.042395).  Saving model ...
Validation loss decreased (1.042395 --> 1.039671).  Saving model ...
Validation loss decreased (1.039671 --> 1.038405).  Saving model ...
Validation loss decreased (1.038405 --> 1.036619).  Saving model ...
Validation loss decreased (1.036619 --> 1.035378).  Saving model ...
Validation loss decreased (1.035378 --> 1.031538).  Saving model ...
Validation loss decreased (1.031538 --> 1.028494).  Saving model ...
Validation loss decreased (1.028494 --> 1.025627).  Saving model ...
Validation loss decreased (1.025627 --> 1.023696).  Saving model ...
Validation loss decreased (1.023696 --> 1.022136).  Saving model ...
EarlyStopping counter: 1 out of 15.0
EarlyStopping counter: 2 out of 15.0
Validation loss decreased (1.022136 --> 1.018300).  Saving model ...
Validation loss decreased (1.018300 --> 1.011587).  Saving model ...
EarlyStopping counter: 1 out of 15.0
EarlyStopping counter: 2 out of 15.0
Validation loss decreased (1.011587 --> 1.008531).  Saving model ...
EarlyStopping counter: 1 out of 15.0
Validation loss decreased (1.008531 --> 1.007590).  Saving model ...
Validation loss decreased (1.007590 --> 1.005180).  Saving model ...
Validation loss decreased (1.005180 --> 1.002017).  Saving model ...
Validation loss decreased (1.002017 --> 1.000937).  Saving model ...
EarlyStopping counter: 1 out of 15.0
Validation loss decreased (1.000937 --> 0.999687).  Saving model ...
EarlyStopping counter: 1 out of 15.0
EarlyStopping counter: 2 out of 15.0
Validation loss decreased (0.999687 --> 0.999372).  Saving model ...
Validation loss decreased (0.999372 --> 0.999179).  Saving model ...
Validation loss decreased (0.999179 --> 0.998234).  Saving model ...
EarlyStopping counter: 1 out of 15.0
Validation loss decreased (0.998234 --> 0.995187).  Saving model ...
EarlyStopping counter: 1 out of 15.0
Validation loss decreased (0.995187 --> 0.992656).  Saving model ...
EarlyStopping counter: 1 out of 15.0
EarlyStopping counter: 2 out of 15.0
EarlyStopping counter: 3 out of 15.0
EarlyStopping counter: 4 out of 15.0
Validation loss decreased (0.992656 --> 0.990100).  Saving model ...
Validation loss decreased (0.990100 --> 0.989659).  Saving model ...
EarlyStopping counter: 1 out of 15.0
EarlyStopping counter: 2 out of 15.0
EarlyStopping counter: 3 out of 15.0
Validation loss decreased (0.989659 --> 0.987508).  Saving model ...
EarlyStopping counter: 1 out of 15.0
EarlyStopping counter: 2 out of 15.0
EarlyStopping counter: 3 out of 15.0
Validation loss decreased (0.987508 --> 0.985798).  Saving model ...
EarlyStopping counter: 1 out of 15.0
EarlyStopping counter: 2 out of 15.0
EarlyStopping counter: 3 out of 15.0
EarlyStopping counter: 4 out of 15.0
Validation loss decreased (0.985798 --> 0.984121).  Saving model ...
EarlyStopping counter: 1 out of 15.0
EarlyStopping counter: 2 out of 15.0
EarlyStopping counter: 3 out of 15.0
EarlyStopping counter: 4 out of 15.0
EarlyStopping counter: 5 out of 15.0
EarlyStopping counter: 6 out of 15.0
Validation loss decreased (0.984121 --> 0.983153).  Saving model ...
Validation loss decreased (0.983153 --> 0.980361).  Saving model ...
EarlyStopping counter: 1 out of 15.0
Validation loss decreased (0.980361 --> 0.980091).  Saving model ...
EarlyStopping counter: 1 out of 15.0
EarlyStopping counter: 2 out of 15.0
EarlyStopping counter: 3 out of 15.0
EarlyStopping counter: 4 out of 15.0
EarlyStopping counter: 5 out of 15.0
EarlyStopping counter: 6 out of 15.0
EarlyStopping counter: 7 out of 15.0
EarlyStopping counter: 8 out of 15.0
EarlyStopping counter: 9 out of 15.0
EarlyStopping counter: 10 out of 15.0
EarlyStopping counter: 11 out of 15.0
EarlyStopping counter: 12 out of 15.0
EarlyStopping counter: 13 out of 15.0
EarlyStopping counter: 14 out of 15.0
EarlyStopping counter: 15 out of 15.0
/localscratch/yinan.28698853.0/env/lib/python3.7/site-packages/torch/nn/functional.py:1794: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.
  warnings.warn("nn.functional.tanh is deprecated. Use torch.tanh instead.")
wandb: Waiting for W&B process to finish, PID 222495... (success).
wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: \ 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: | 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: / 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: \ 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: | 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: / 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: \ 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: | 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: / 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb:                                                                                
wandb: Run history:
wandb:     e_F1 ▁▂▃▅▅▅▅▆▆▆▆▆▆▆▇▇▇▇▇▇▇▇▇▇████████████████
wandb:   e_loss █▇▇▇▆▆▆▅▅▄▄▄▄▃▃▃▃▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:     t_F1 ▁▁▃▃▃▄▄▄▅▅▅▆▅▆▆▆▆▆▆▆▆▇▇▇▇▇▇▇▇▇█▇███▇████
wandb:   t_loss ██▇▇▇▇▆▆▆▅▅▅▅▅▅▄▄▄▄▄▃▃▃▃▃▃▃▂▃▂▂▂▂▂▂▂▂▁▁▁
wandb: 
wandb: Run summary:
wandb:     e_F1 58.98416
wandb:   e_loss 0.99111
wandb:     t_F1 75.85711
wandb:   t_loss 0.68704
wandb: 
wandb: Synced 4 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Synced different-gorge-2: https://wandb.ai/yinanazhou/xl_512_bs_8_lr_1e06_es_15_lc_True_nr_True_sr_True_stem_False_lemma_False_repeat_3_fold_1/runs/2gk3ofd7
wandb: Find logs at: ./wandb/run-20220315_092040-2gk3ofd7/logs/debug.log
wandb: 

wandb: wandb version 0.12.11 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
2022-03-15 11:01:41.581870: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1
wandb: Tracking run with wandb version 0.12.5
wandb: Syncing run lucky-totem-2
wandb: ⭐️ View project at https://wandb.ai/yinanazhou/xl_512_bs_8_lr_1e06_es_15_lc_True_nr_True_sr_True_stem_False_lemma_False_repeat_3_fold_2
wandb: 🚀 View run at https://wandb.ai/yinanazhou/xl_512_bs_8_lr_1e06_es_15_lc_True_nr_True_sr_True_stem_False_lemma_False_repeat_3_fold_2/runs/3hzw5w2x
wandb: Run data is saved locally in /project/6002780/yinan/Thesis_MER_Lyrics/lyric-emotion/wandb/run-20220315_110138-3hzw5w2x
wandb: Run `wandb offline` to turn off syncing.
wandb: Network error (ReadTimeout), entering retry loop.
slurmstepd: error: *** JOB 28698853 ON cdr2586 CANCELLED AT 2022-03-15T12:18:20 DUE TO TIME LIMIT ***
