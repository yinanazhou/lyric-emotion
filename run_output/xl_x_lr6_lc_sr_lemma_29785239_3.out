Unloading StdEnv/2020

Due to MODULEPATH changes, the following have been reloaded:
  1) mii/1.1.1


The following have been reloaded with a version change:
  1) python/3.8.2 => python/3.7.4

Using base prefix '/cvmfs/soft.computecanada.ca/easybuild/software/2017/Core/python/3.7.4'
New python executable in /localscratch/yinan.29785239.0/env/bin/python
Installing setuptools, pip, wheel...
done.
Ignoring pip: markers 'python_version < "3"' don't match your environment
Looking in links: /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/nix/avx2, /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/nix/generic, /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic
Collecting pip
Installing collected packages: pip
  Found existing installation: pip 19.1.1
    Uninstalling pip-19.1.1:
      Successfully uninstalled pip-19.1.1
Successfully installed pip-21.2.3+computecanada
Looking in links: /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/nix/avx2, /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/nix/generic, /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/keras-2.8.0+computecanada-py2.py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/Keras_Preprocessing-1.1.2+computecanada-py3-none-any.whl
Requirement already satisfied: matplotlib in /cvmfs/soft.computecanada.ca/easybuild/software/2017/Core/scipy-stack/2019a/lib/python3.7/site-packages (from -r requirements.txt (line 3)) (3.0.2)
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/nltk-3.6.5+computecanada-py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/scikit_learn-0.22.1+computecanada-cp37-cp37m-linux_x86_64.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/tensorboard-2.3.0+computecanada-py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/tensorboard_plugin_wit-1.7.0+computecanada-py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/tensorflow_gpu-2.3.0+computecanada-cp37-cp37m-linux_x86_64.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/tensorflow_estimator-2.3.0+computecanada-py2.py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/tokenizers-0.5.2+computecanada-cp37-cp37m-linux_x86_64.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/nix/avx2/torch-1.4.0+computecanada-cp37-cp37m-linux_x86_64.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/torchtext-0.6.0+computecanada-py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/torchvision-0.8.2+computecanada-cp37-cp37m-linux_x86_64.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/transformers-2.5.1+computecanada-py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/urllib3-1.26.7+computecanada-py2.py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/joblib-1.1.0+computecanada-py2.py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/tqdm-4.63.1+computecanada-py2.py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/click-8.1.0+computecanada-py3-none-any.whl
ERROR: Could not find a version that satisfies the requirement regex>=2021.8.3 (from nltk) (from versions: 2018.1.10+computecanada, 2019.11.1+computecanada, 2020.11.13+computecanada)
ERROR: No matching distribution found for regex>=2021.8.3
Looking in links: /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/nix/avx2, /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/nix/generic, /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic
ERROR: Could not find a version that satisfies the requirement numpy==1.20.0+computacanada (from versions: 1.15.0+computecanada, 1.15.2+computecanada, 1.15.4+computecanada, 1.16.0+computecanada, 1.16.2+computecanada, 1.16.3+computecanada, 1.17.4+computecanada, 1.18.1+computecanada, 1.18.4+computecanada, 1.19.1+computecanada, 1.19.2+computecanada, 1.20.2+computecanada)
ERROR: No matching distribution found for numpy==1.20.0+computacanada
Looking in links: /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/nix/avx2, /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/nix/generic, /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/wandb-0.12.5+computecanada-py2.py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/click-8.1.0+computecanada-py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/protobuf-3.19.4+computecanada-py2.py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/GitPython-3.1.24+computecanada-py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/pathtools-0.1.2+computecanada-py3-none-any.whl
Requirement already satisfied: python-dateutil>=2.6.1 in /cvmfs/soft.computecanada.ca/easybuild/software/2017/Core/scipy-stack/2019a/lib/python3.7/site-packages (from wandb) (2.7.5)
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/six-1.16.0+computecanada-py2.py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/sentry_sdk-1.5.0+computecanada-py2.py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/yaspin-2.1.0+computecanada-py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/shortuuid-1.0.1+computecanada-py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/subprocess32-3.5.4+computecanada-py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/promise-2.3+computecanada-py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/psutil-5.7.3+computecanada-cp37-cp37m-linux_x86_64.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/PyYAML-5.3.1+computecanada-cp37-cp37m-linux_x86_64.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/configparser-5.0.2+computecanada-py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/docker_pycreds-0.4.0+computecanada-py2.py3-none-any.whl
Requirement already satisfied: requests<3,>=2.0.0 in /cvmfs/soft.computecanada.ca/easybuild/software/2017/Core/scipy-stack/2019a/lib/python3.7/site-packages (from wandb) (2.21.0)
Requirement already satisfied: importlib-metadata in /cvmfs/soft.computecanada.ca/easybuild/software/2017/Core/scipy-stack/2019a/lib/python3.7/site-packages (from Click!=8.0.0,>=7.0->wandb) (0.8)
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/gitdb-4.0.9+computecanada-py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/typing_extensions-4.1.1+computecanada-py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/smmap-5.0.0+computecanada-py3-none-any.whl
Requirement already satisfied: idna<2.9,>=2.5 in /cvmfs/soft.computecanada.ca/easybuild/software/2017/Core/scipy-stack/2019a/lib/python3.7/site-packages (from requests<3,>=2.0.0->wandb) (2.8)
Requirement already satisfied: urllib3<1.25,>=1.21.1 in /cvmfs/soft.computecanada.ca/easybuild/software/2017/Core/scipy-stack/2019a/lib/python3.7/site-packages (from requests<3,>=2.0.0->wandb) (1.24.1)
Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /cvmfs/soft.computecanada.ca/easybuild/software/2017/Core/scipy-stack/2019a/lib/python3.7/site-packages (from requests<3,>=2.0.0->wandb) (3.0.4)
Requirement already satisfied: certifi>=2017.4.17 in /cvmfs/soft.computecanada.ca/easybuild/software/2017/Core/scipy-stack/2019a/lib/python3.7/site-packages (from requests<3,>=2.0.0->wandb) (2018.11.29)
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/termcolor-1.1.0+computecanada-py3-none-any.whl
Requirement already satisfied: zipp>=0.3.2 in /cvmfs/soft.computecanada.ca/easybuild/software/2017/Core/scipy-stack/2019a/lib/python3.7/site-packages (from importlib-metadata->Click!=8.0.0,>=7.0->wandb) (0.3.3)
Installing collected packages: smmap, typing-extensions, termcolor, six, gitdb, yaspin, subprocess32, shortuuid, sentry-sdk, PyYAML, psutil, protobuf, promise, pathtools, GitPython, docker-pycreds, configparser, Click, wandb
  Attempting uninstall: six
    Found existing installation: six 1.12.0
    Not uninstalling six at /cvmfs/soft.computecanada.ca/easybuild/software/2017/Core/scipy-stack/2019a/lib/python3.7/site-packages, outside environment /localscratch/yinan.29785239.0/env
    Can't uninstall 'six'. No files were found to uninstall.
Successfully installed Click-8.1.0+computecanada GitPython-3.1.24+computecanada PyYAML-5.3.1+computecanada configparser-5.0.2+computecanada docker-pycreds-0.4.0+computecanada gitdb-4.0.9+computecanada pathtools-0.1.2+computecanada promise-2.3+computecanada protobuf-3.19.4+computecanada psutil-5.7.3+computecanada sentry-sdk-1.5.0+computecanada shortuuid-1.0.1+computecanada six-1.16.0+computecanada smmap-5.0.0+computecanada subprocess32-3.5.4+computecanada termcolor-1.1.0+computecanada typing-extensions-4.1.1+computecanada wandb-0.12.5+computecanada yaspin-2.1.0+computecanada
Looking in links: /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/nix/avx2, /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/nix/generic, /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic
ERROR: Could not find a version that satisfies the requirement sagemaker (from versions: none)
ERROR: No matching distribution found for sagemaker
Looking in links: /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/nix/avx2, /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/nix/generic, /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/torch-1.9.1+computecanada-cp37-cp37m-linux_x86_64.whl
Requirement already satisfied: typing-extensions in /localscratch/yinan.29785239.0/env/lib/python3.7/site-packages (from torch) (4.1.1+computecanada)
Installing collected packages: torch
Successfully installed torch-1.9.1+computecanada
Looking in links: /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/nix/avx2, /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/nix/generic, /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/transformers-2.5.1+computecanada-py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/tqdm-4.63.1+computecanada-py2.py3-none-any.whl
Requirement already satisfied: numpy in /cvmfs/soft.computecanada.ca/easybuild/software/2017/Core/scipy-stack/2019a/lib/python3.7/site-packages (from transformers==2.5.1+computecanada) (1.16.0)
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/sentencepiece-0.1.91+computecanada-cp37-cp37m-linux_x86_64.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/regex-2020.11.13+computecanada-cp37-cp37m-linux_x86_64.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/tokenizers-0.5.2+computecanada-cp37-cp37m-linux_x86_64.whl
Requirement already satisfied: requests in /cvmfs/soft.computecanada.ca/easybuild/software/2017/Core/scipy-stack/2019a/lib/python3.7/site-packages (from transformers==2.5.1+computecanada) (2.21.0)
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/boto3-1.21.14+computecanada-py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/sacremoses-0.0.49+computecanada-py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/filelock-3.4.2+computecanada-py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/jmespath-0.10.0+computecanada-py2.py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/botocore-1.24.14+computecanada-py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/s3transfer-0.5.1+computecanada-py3-none-any.whl
Requirement already satisfied: python-dateutil<3.0.0,>=2.1 in /cvmfs/soft.computecanada.ca/easybuild/software/2017/Core/scipy-stack/2019a/lib/python3.7/site-packages (from botocore<1.25.0,>=1.24.14->boto3->transformers==2.5.1+computecanada) (2.7.5)
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/urllib3-1.26.9+computecanada-py2.py3-none-any.whl
Requirement already satisfied: six>=1.5 in /localscratch/yinan.29785239.0/env/lib/python3.7/site-packages (from python-dateutil<3.0.0,>=2.1->botocore<1.25.0,>=1.24.14->boto3->transformers==2.5.1+computecanada) (1.16.0+computecanada)
Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /cvmfs/soft.computecanada.ca/easybuild/software/2017/Core/scipy-stack/2019a/lib/python3.7/site-packages (from requests->transformers==2.5.1+computecanada) (3.0.4)
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/requests-2.27.1+computecanada-py2.py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/charset_normalizer-2.0.12+computecanada-py3-none-any.whl
Requirement already satisfied: certifi>=2017.4.17 in /cvmfs/soft.computecanada.ca/easybuild/software/2017/Core/scipy-stack/2019a/lib/python3.7/site-packages (from requests->transformers==2.5.1+computecanada) (2018.11.29)
Requirement already satisfied: idna<4,>=2.5 in /cvmfs/soft.computecanada.ca/easybuild/software/2017/Core/scipy-stack/2019a/lib/python3.7/site-packages (from requests->transformers==2.5.1+computecanada) (2.8)
Requirement already satisfied: click in /localscratch/yinan.29785239.0/env/lib/python3.7/site-packages (from sacremoses->transformers==2.5.1+computecanada) (8.1.0+computecanada)
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/joblib-1.1.0+computecanada-py2.py3-none-any.whl
Requirement already satisfied: importlib-metadata in /cvmfs/soft.computecanada.ca/easybuild/software/2017/Core/scipy-stack/2019a/lib/python3.7/site-packages (from click->sacremoses->transformers==2.5.1+computecanada) (0.8)
Requirement already satisfied: zipp>=0.3.2 in /cvmfs/soft.computecanada.ca/easybuild/software/2017/Core/scipy-stack/2019a/lib/python3.7/site-packages (from importlib-metadata->click->sacremoses->transformers==2.5.1+computecanada) (0.3.3)
Installing collected packages: urllib3, jmespath, botocore, tqdm, s3transfer, regex, joblib, charset-normalizer, tokenizers, sentencepiece, sacremoses, requests, filelock, boto3, transformers
  Attempting uninstall: urllib3
    Found existing installation: urllib3 1.24.1
    Not uninstalling urllib3 at /cvmfs/soft.computecanada.ca/easybuild/software/2017/Core/scipy-stack/2019a/lib/python3.7/site-packages, outside environment /localscratch/yinan.29785239.0/env
    Can't uninstall 'urllib3'. No files were found to uninstall.
  Attempting uninstall: requests
    Found existing installation: requests 2.21.0
    Not uninstalling requests at /cvmfs/soft.computecanada.ca/easybuild/software/2017/Core/scipy-stack/2019a/lib/python3.7/site-packages, outside environment /localscratch/yinan.29785239.0/env
    Can't uninstall 'requests'. No files were found to uninstall.
Successfully installed boto3-1.21.14+computecanada botocore-1.24.14+computecanada charset-normalizer-2.0.12+computecanada filelock-3.4.2+computecanada jmespath-0.10.0+computecanada joblib-1.1.0+computecanada regex-2020.11.13+computecanada requests-2.27.1+computecanada s3transfer-0.5.1+computecanada sacremoses-0.0.49+computecanada sentencepiece-0.1.91+computecanada tokenizers-0.5.2+computecanada tqdm-4.63.1+computecanada transformers-2.5.1+computecanada urllib3-1.26.9+computecanada
Looking in links: /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/nix/avx2, /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/nix/generic, /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/tensorflow_gpu-2.3.0+computecanada-cp37-cp37m-linux_x86_64.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/wrapt-1.11.2+computecanada-cp37-cp37m-linux_x86_64.whl
Requirement already satisfied: wheel>=0.26 in /localscratch/yinan.29785239.0/env/lib/python3.7/site-packages (from tensorflow_gpu==2.3.0+computecanada) (0.33.4)
Requirement already satisfied: protobuf>=3.9.2 in /localscratch/yinan.29785239.0/env/lib/python3.7/site-packages (from tensorflow_gpu==2.3.0+computecanada) (3.19.4+computecanada)
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/nix/avx2/h5py-2.10.0+computecanada-cp37-cp37m-linux_x86_64.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/tensorflow_estimator-2.3.0+computecanada-py2.py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/google_pasta-0.2.0+computecanada-py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/absl_py-1.0.0+computecanada-py3-none-any.whl
Requirement already satisfied: termcolor>=1.1.0 in /localscratch/yinan.29785239.0/env/lib/python3.7/site-packages (from tensorflow_gpu==2.3.0+computecanada) (1.1.0+computecanada)
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/tensorboard-2.8.0+computecanada-py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/astunparse-1.6.3+computecanada-py2.py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/Keras_Preprocessing-1.1.2+computecanada-py3-none-any.whl
Requirement already satisfied: numpy<1.19.0,>=1.16.0 in /cvmfs/soft.computecanada.ca/easybuild/software/2017/Core/scipy-stack/2019a/lib/python3.7/site-packages (from tensorflow_gpu==2.3.0+computecanada) (1.16.0)
Requirement already satisfied: six>=1.12.0 in /localscratch/yinan.29785239.0/env/lib/python3.7/site-packages (from tensorflow_gpu==2.3.0+computecanada) (1.16.0+computecanada)
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/gast-0.3.3+computecanada-py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/opt_einsum-3.3.0+computecanada-py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/nix/generic/scipy-1.4.1+computecanada-cp37-cp37m-linux_x86_64.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/grpcio-1.38.0+computecanada-cp37-cp37m-linux_x86_64.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/google_auth-2.3.3+computecanada-py2.py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/tensorboard_data_server-0.6.1+computecanada-py3-none-linux_x86_64.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/google_auth_oauthlib-0.4.6+computecanada-py2.py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/Markdown-3.3.6+computecanada-py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/Werkzeug-2.0.3+computecanada-py3-none-any.whl
Requirement already satisfied: requests<3,>=2.21.0 in /localscratch/yinan.29785239.0/env/lib/python3.7/site-packages (from tensorboard<3,>=2.3.0->tensorflow_gpu==2.3.0+computecanada) (2.27.1+computecanada)
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/tensorboard_plugin_wit-1.8.0+computecanada-py3-none-any.whl
Requirement already satisfied: setuptools>=41.0.0 in /localscratch/yinan.29785239.0/env/lib/python3.7/site-packages (from tensorboard<3,>=2.3.0->tensorflow_gpu==2.3.0+computecanada) (41.0.1)
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/rsa-4.8+computecanada-py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/cachetools-4.2.4+computecanada-py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/pyasn1_modules-0.2.8+computecanada-py2.py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/requests_oauthlib-1.3.0+computecanada-py2.py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/importlib_metadata-4.10.1+computecanada-py3-none-any.whl
Requirement already satisfied: typing-extensions>=3.6.4 in /localscratch/yinan.29785239.0/env/lib/python3.7/site-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard<3,>=2.3.0->tensorflow_gpu==2.3.0+computecanada) (4.1.1+computecanada)
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/zipp-3.7.0+computecanada-py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/pyasn1-0.4.8+computecanada-py2.py3-none-any.whl
Requirement already satisfied: certifi>=2017.4.17 in /cvmfs/soft.computecanada.ca/easybuild/software/2017/Core/scipy-stack/2019a/lib/python3.7/site-packages (from requests<3,>=2.21.0->tensorboard<3,>=2.3.0->tensorflow_gpu==2.3.0+computecanada) (2018.11.29)
Requirement already satisfied: idna<4,>=2.5 in /cvmfs/soft.computecanada.ca/easybuild/software/2017/Core/scipy-stack/2019a/lib/python3.7/site-packages (from requests<3,>=2.21.0->tensorboard<3,>=2.3.0->tensorflow_gpu==2.3.0+computecanada) (2.8)
Requirement already satisfied: charset-normalizer~=2.0.0 in /localscratch/yinan.29785239.0/env/lib/python3.7/site-packages (from requests<3,>=2.21.0->tensorboard<3,>=2.3.0->tensorflow_gpu==2.3.0+computecanada) (2.0.12+computecanada)
Requirement already satisfied: urllib3<1.27,>=1.21.1 in /localscratch/yinan.29785239.0/env/lib/python3.7/site-packages (from requests<3,>=2.21.0->tensorboard<3,>=2.3.0->tensorflow_gpu==2.3.0+computecanada) (1.26.9+computecanada)
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/oauthlib-3.1.1+computecanada-py2.py3-none-any.whl
Installing collected packages: pyasn1, zipp, rsa, pyasn1-modules, oauthlib, cachetools, requests-oauthlib, importlib-metadata, google-auth, werkzeug, tensorboard-plugin-wit, tensorboard-data-server, markdown, grpcio, google-auth-oauthlib, absl-py, wrapt, tensorflow-estimator, tensorboard, scipy, opt-einsum, keras-preprocessing, h5py, google-pasta, gast, astunparse, tensorflow-gpu
  Attempting uninstall: pyasn1
    Found existing installation: pyasn1 0.4.3
    Not uninstalling pyasn1 at /cvmfs/soft.computecanada.ca/easybuild/software/2017/Core/scipy-stack/2019a/lib/python3.7/site-packages, outside environment /localscratch/yinan.29785239.0/env
    Can't uninstall 'pyasn1'. No files were found to uninstall.
  Attempting uninstall: zipp
    Found existing installation: zipp 0.3.3
    Not uninstalling zipp at /cvmfs/soft.computecanada.ca/easybuild/software/2017/Core/scipy-stack/2019a/lib/python3.7/site-packages, outside environment /localscratch/yinan.29785239.0/env
    Can't uninstall 'zipp'. No files were found to uninstall.
  Attempting uninstall: importlib-metadata
    Found existing installation: importlib-metadata 0.8
    Not uninstalling importlib-metadata at /cvmfs/soft.computecanada.ca/easybuild/software/2017/Core/scipy-stack/2019a/lib/python3.7/site-packages, outside environment /localscratch/yinan.29785239.0/env
    Can't uninstall 'importlib-metadata'. No files were found to uninstall.
  Attempting uninstall: scipy
    Found existing installation: scipy 1.2.0
    Not uninstalling scipy at /cvmfs/soft.computecanada.ca/easybuild/software/2017/Core/scipy-stack/2019a/lib/python3.7/site-packages, outside environment /localscratch/yinan.29785239.0/env
    Can't uninstall 'scipy'. No files were found to uninstall.
Successfully installed absl-py-1.0.0+computecanada astunparse-1.6.3+computecanada cachetools-4.2.4+computecanada gast-0.3.3+computecanada google-auth-2.3.3+computecanada google-auth-oauthlib-0.4.6+computecanada google-pasta-0.2.0+computecanada grpcio-1.38.0+computecanada h5py-2.10.0+computecanada importlib-metadata-4.10.1+computecanada keras-preprocessing-1.1.2+computecanada markdown-3.3.6+computecanada oauthlib-3.1.1+computecanada opt-einsum-3.3.0+computecanada pyasn1-0.4.8+computecanada pyasn1-modules-0.2.8+computecanada requests-oauthlib-1.3.0+computecanada rsa-4.8+computecanada scipy-1.4.1+computecanada tensorboard-2.8.0+computecanada tensorboard-data-server-0.6.1+computecanada tensorboard-plugin-wit-1.8.0+computecanada tensorflow-estimator-2.3.0+computecanada tensorflow-gpu-2.3.0+computecanada werkzeug-2.0.3+computecanada wrapt-1.11.2+computecanada zipp-3.7.0+computecanada
Looking in links: /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/nix/avx2, /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/nix/generic, /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/keras-2.8.0+computecanada-py2.py3-none-any.whl
Installing collected packages: Keras
Successfully installed Keras-2.8.0+computecanada
Looking in links: /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/nix/avx2, /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/nix/generic, /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/urllib3-1.26.7+computecanada-py2.py3-none-any.whl
Installing collected packages: urllib3
  Attempting uninstall: urllib3
    Found existing installation: urllib3 1.26.9+computecanada
    Uninstalling urllib3-1.26.9+computecanada:
      Successfully uninstalled urllib3-1.26.9+computecanada
Successfully installed urllib3-1.26.7+computecanada
Looking in links: /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/nix/avx2, /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/nix/generic, /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/nltk-3.7+computecanada-py3-none-any.whl
Requirement already satisfied: joblib in /localscratch/yinan.29785239.0/env/lib/python3.7/site-packages (from nltk) (1.1.0+computecanada)
Requirement already satisfied: click in /localscratch/yinan.29785239.0/env/lib/python3.7/site-packages (from nltk) (8.1.0+computecanada)
Requirement already satisfied: tqdm in /localscratch/yinan.29785239.0/env/lib/python3.7/site-packages (from nltk) (4.63.1+computecanada)
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/nltk-3.6.5+computecanada-py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/nltk-3.6.3+computecanada-py3-none-any.whl
Requirement already satisfied: regex in /localscratch/yinan.29785239.0/env/lib/python3.7/site-packages (from nltk) (2020.11.13+computecanada)
Requirement already satisfied: importlib-metadata in /localscratch/yinan.29785239.0/env/lib/python3.7/site-packages (from click->nltk) (4.10.1+computecanada)
Requirement already satisfied: typing-extensions>=3.6.4 in /localscratch/yinan.29785239.0/env/lib/python3.7/site-packages (from importlib-metadata->click->nltk) (4.1.1+computecanada)
Requirement already satisfied: zipp>=0.5 in /localscratch/yinan.29785239.0/env/lib/python3.7/site-packages (from importlib-metadata->click->nltk) (3.7.0+computecanada)
Installing collected packages: nltk
Successfully installed nltk-3.6.3+computecanada
Looking in links: /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/nix/avx2, /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/nix/generic, /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/scikit_learn-0.22.1+computecanada-cp37-cp37m-linux_x86_64.whl
Requirement already satisfied: joblib>=0.11 in /localscratch/yinan.29785239.0/env/lib/python3.7/site-packages (from scikit-learn==0.22.1) (1.1.0+computecanada)
Requirement already satisfied: numpy>=1.11.0 in /cvmfs/soft.computecanada.ca/easybuild/software/2017/Core/scipy-stack/2019a/lib/python3.7/site-packages (from scikit-learn==0.22.1) (1.16.0)
Requirement already satisfied: scipy>=0.17.0 in /localscratch/yinan.29785239.0/env/lib/python3.7/site-packages (from scikit-learn==0.22.1) (1.4.1+computecanada)
Installing collected packages: scikit-learn
Successfully installed scikit-learn-0.22.1+computecanada
Looking in links: /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/nix/avx2, /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/nix/generic, /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic
Requirement already satisfied: tokenizers==0.5.2 in /localscratch/yinan.29785239.0/env/lib/python3.7/site-packages (0.5.2+computecanada)
wandb: Appending key for api.wandb.ai to your netrc file: /home/yinan/.netrc
Starting Task
2022-03-31 07:07:59.885874: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1
[nltk_data] Downloading package stopwords to /home/yinan/nltk_data...
[nltk_data]   Package stopwords is already up-to-date!
[nltk_data] Downloading package wordnet to /home/yinan/nltk_data...
[nltk_data]   Package wordnet is already up-to-date!
wandb: Currently logged in as: yinanazhou (use `wandb login --relogin` to force relogin)
wandb: wandb version 0.12.11 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
2022-03-31 07:08:14.742235: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1
wandb: Tracking run with wandb version 0.12.5
wandb: Syncing run swept-wave-2
wandb: ⭐️ View project at https://wandb.ai/yinanazhou/xl_512_bs_8_lr_1e06_es_3_lc_True_nr_False_sr_True_stem_False_lemma_True_repeat_1_fold_1
wandb: 🚀 View run at https://wandb.ai/yinanazhou/xl_512_bs_8_lr_1e06_es_3_lc_True_nr_False_sr_True_stem_False_lemma_True_repeat_1_fold_1/runs/4zencmxr
wandb: Run data is saved locally in /project/6002780/yinan/Thesis_MER_Lyrics/lyric-emotion/wandb/run-20220331_070812-4zencmxr
wandb: Run `wandb offline` to turn off syncing.

Validation loss decreased (inf --> 1.438662).  Saving model ...
Validation loss decreased (1.438662 --> 1.418969).  Saving model ...
Validation loss decreased (1.418969 --> 1.403382).  Saving model ...
Validation loss decreased (1.403382 --> 1.390048).  Saving model ...
Validation loss decreased (1.390048 --> 1.379928).  Saving model ...
Validation loss decreased (1.379928 --> 1.371191).  Saving model ...
Validation loss decreased (1.371191 --> 1.363661).  Saving model ...
Validation loss decreased (1.363661 --> 1.356854).  Saving model ...
Validation loss decreased (1.356854 --> 1.350653).  Saving model ...
Validation loss decreased (1.350653 --> 1.344162).  Saving model ...
Validation loss decreased (1.344162 --> 1.337356).  Saving model ...
Validation loss decreased (1.337356 --> 1.331363).  Saving model ...
Validation loss decreased (1.331363 --> 1.325025).  Saving model ...
Validation loss decreased (1.325025 --> 1.318984).  Saving model ...
Validation loss decreased (1.318984 --> 1.312663).  Saving model ...
Validation loss decreased (1.312663 --> 1.306021).  Saving model ...
Validation loss decreased (1.306021 --> 1.299364).  Saving model ...
Validation loss decreased (1.299364 --> 1.292628).  Saving model ...
Validation loss decreased (1.292628 --> 1.285848).  Saving model ...
Validation loss decreased (1.285848 --> 1.279659).  Saving model ...
Validation loss decreased (1.279659 --> 1.273118).  Saving model ...
Validation loss decreased (1.273118 --> 1.265195).  Saving model ...
Validation loss decreased (1.265195 --> 1.258462).  Saving model ...
Validation loss decreased (1.258462 --> 1.250862).  Saving model ...
Validation loss decreased (1.250862 --> 1.245325).  Saving model ...
Validation loss decreased (1.245325 --> 1.237701).  Saving model ...
Validation loss decreased (1.237701 --> 1.231093).  Saving model ...
Validation loss decreased (1.231093 --> 1.226174).  Saving model ...
Validation loss decreased (1.226174 --> 1.221484).  Saving model ...
Validation loss decreased (1.221484 --> 1.216581).  Saving model ...
Validation loss decreased (1.216581 --> 1.210763).  Saving model ...
Validation loss decreased (1.210763 --> 1.205853).  Saving model ...
Validation loss decreased (1.205853 --> 1.201370).  Saving model ...
Validation loss decreased (1.201370 --> 1.195136).  Saving model ...
Validation loss decreased (1.195136 --> 1.191259).  Saving model ...
Validation loss decreased (1.191259 --> 1.187036).  Saving model ...
Validation loss decreased (1.187036 --> 1.182244).  Saving model ...
Validation loss decreased (1.182244 --> 1.177507).  Saving model ...
Validation loss decreased (1.177507 --> 1.174492).  Saving model ...
Validation loss decreased (1.174492 --> 1.171837).  Saving model ...
Validation loss decreased (1.171837 --> 1.165009).  Saving model ...
Validation loss decreased (1.165009 --> 1.160841).  Saving model ...
Validation loss decreased (1.160841 --> 1.159077).  Saving model ...
Validation loss decreased (1.159077 --> 1.154768).  Saving model ...
Validation loss decreased (1.154768 --> 1.150731).  Saving model ...
Validation loss decreased (1.150731 --> 1.145090).  Saving model ...
Validation loss decreased (1.145090 --> 1.141891).  Saving model ...
Validation loss decreased (1.141891 --> 1.140450).  Saving model ...
Validation loss decreased (1.140450 --> 1.133511).  Saving model ...
Validation loss decreased (1.133511 --> 1.129204).  Saving model ...
Validation loss decreased (1.129204 --> 1.124862).  Saving model ...
Validation loss decreased (1.124862 --> 1.120329).  Saving model ...
Validation loss decreased (1.120329 --> 1.117900).  Saving model ...
Validation loss decreased (1.117900 --> 1.116377).  Saving model ...
Validation loss decreased (1.116377 --> 1.114637).  Saving model ...
Validation loss decreased (1.114637 --> 1.108824).  Saving model ...
Validation loss decreased (1.108824 --> 1.106498).  Saving model ...
Validation loss decreased (1.106498 --> 1.102776).  Saving model ...
Validation loss decreased (1.102776 --> 1.097893).  Saving model ...
Validation loss decreased (1.097893 --> 1.096522).  Saving model ...
Validation loss decreased (1.096522 --> 1.091725).  Saving model ...
Validation loss decreased (1.091725 --> 1.088873).  Saving model ...
Validation loss decreased (1.088873 --> 1.084478).  Saving model ...
Validation loss decreased (1.084478 --> 1.083351).  Saving model ...
Validation loss decreased (1.083351 --> 1.083036).  Saving model ...
Validation loss decreased (1.083036 --> 1.076852).  Saving model ...
EarlyStopping counter: 1 out of 3.0
Validation loss decreased (1.076852 --> 1.070606).  Saving model ...
Validation loss decreased (1.070606 --> 1.068511).  Saving model ...
Validation loss decreased (1.068511 --> 1.066234).  Saving model ...
Validation loss decreased (1.066234 --> 1.062005).  Saving model ...
Validation loss decreased (1.062005 --> 1.060731).  Saving model ...
Validation loss decreased (1.060731 --> 1.058138).  Saving model ...
Validation loss decreased (1.058138 --> 1.055929).  Saving model ...
Validation loss decreased (1.055929 --> 1.052316).  Saving model ...
Validation loss decreased (1.052316 --> 1.048966).  Saving model ...
Validation loss decreased (1.048966 --> 1.048540).  Saving model ...
Validation loss decreased (1.048540 --> 1.048481).  Saving model ...
Validation loss decreased (1.048481 --> 1.042755).  Saving model ...
Validation loss decreased (1.042755 --> 1.039268).  Saving model ...
Validation loss decreased (1.039268 --> 1.038113).  Saving model ...
Validation loss decreased (1.038113 --> 1.038083).  Saving model ...
Validation loss decreased (1.038083 --> 1.036442).  Saving model ...
Validation loss decreased (1.036442 --> 1.036103).  Saving model ...
Validation loss decreased (1.036103 --> 1.031876).  Saving model ...
Validation loss decreased (1.031876 --> 1.030939).  Saving model ...
Validation loss decreased (1.030939 --> 1.028169).  Saving model ...
Validation loss decreased (1.028169 --> 1.027279).  Saving model ...
Validation loss decreased (1.027279 --> 1.023100).  Saving model ...
Validation loss decreased (1.023100 --> 1.021130).  Saving model ...
Validation loss decreased (1.021130 --> 1.020388).  Saving model ...
Validation loss decreased (1.020388 --> 1.019426).  Saving model ...
Validation loss decreased (1.019426 --> 1.018741).  Saving model ...
EarlyStopping counter: 1 out of 3.0
Validation loss decreased (1.018741 --> 1.017610).  Saving model ...
Validation loss decreased (1.017610 --> 1.016525).  Saving model ...
Validation loss decreased (1.016525 --> 1.014403).  Saving model ...
Validation loss decreased (1.014403 --> 1.011787).  Saving model ...
Validation loss decreased (1.011787 --> 1.009583).  Saving model ...
Validation loss decreased (1.009583 --> 1.009387).  Saving model ...
Validation loss decreased (1.009387 --> 1.007883).  Saving model ...
EarlyStopping counter: 1 out of 3.0
Validation loss decreased (1.007883 --> 1.006802).  Saving model ...
Validation loss decreased (1.006802 --> 1.004851).  Saving model ...
Validation loss decreased (1.004851 --> 1.003764).  Saving model ...
Validation loss decreased (1.003764 --> 0.999239).  Saving model ...
Validation loss decreased (0.999239 --> 0.999113).  Saving model ...
Validation loss decreased (0.999113 --> 0.998331).  Saving model ...
Validation loss decreased (0.998331 --> 0.996616).  Saving model ...
Validation loss decreased (0.996616 --> 0.995545).  Saving model ...
EarlyStopping counter: 1 out of 3.0
EarlyStopping counter: 2 out of 3.0
EarlyStopping counter: 3 out of 3.0
/localscratch/yinan.29785239.0/env/lib/python3.7/site-packages/torch/nn/functional.py:1794: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.
  warnings.warn("nn.functional.tanh is deprecated. Use torch.tanh instead.")
/localscratch/yinan.29785239.0/env/lib/python3.7/site-packages/transformers/optimization.py:155: UserWarning: This overload of add_ is deprecated:
	add_(Number alpha, Tensor other)
Consider using one of the following signatures instead:
	add_(Tensor other, *, Number alpha) (Triggered internally at  ../torch/csrc/utils/python_arg_parser.cpp:1025.)
  exp_avg.mul_(beta1).add_(1.0 - beta1, grad)
wandb: Waiting for W&B process to finish, PID 232998... (success).
wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: \ 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: | 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: / 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: \ 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: | 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: / 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: \ 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: | 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: / 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb:                                                                                
wandb: Run history:
wandb:     e_F1 ▁▂▂▄▄▅▅▅▅▅▅▆▆▆▆▇▇▇▇▇▇▇▇▇▇▇█▇████████████
wandb:   e_loss █▇▇▇▆▆▆▅▅▅▅▄▄▄▄▄▃▃▃▃▃▃▂▂▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁
wandb:     t_F1 ▁▂▃▃▃▃▃▄▄▅▅▅▅▆▆▆▆▆▆▆▆▆▆▆▇▇▇▇▇▇▇▇██▇█████
wandb:   t_loss ██▇▇▇▇▆▆▆▅▅▅▅▄▄▄▄▄▄▃▃▃▃▃▃▃▂▂▂▂▂▂▂▂▂▂▁▁▁▁
wandb: 
wandb: Run summary:
wandb:     e_F1 56.12954
wandb:   e_loss 0.999
wandb:     t_F1 67.91439
wandb:   t_loss 0.81192
wandb: 
wandb: Synced 4 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Synced swept-wave-2: https://wandb.ai/yinanazhou/xl_512_bs_8_lr_1e06_es_3_lc_True_nr_False_sr_True_stem_False_lemma_True_repeat_1_fold_1/runs/4zencmxr
wandb: Find logs at: ./wandb/run-20220331_070812-4zencmxr/logs/debug.log
wandb: 

wandb: wandb version 0.12.11 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
2022-03-31 08:21:06.974566: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1
wandb: Tracking run with wandb version 0.12.5
wandb: Syncing run sunny-yogurt-2
wandb: ⭐️ View project at https://wandb.ai/yinanazhou/xl_512_bs_8_lr_1e06_es_3_lc_True_nr_False_sr_True_stem_False_lemma_True_repeat_1_fold_2
wandb: 🚀 View run at https://wandb.ai/yinanazhou/xl_512_bs_8_lr_1e06_es_3_lc_True_nr_False_sr_True_stem_False_lemma_True_repeat_1_fold_2/runs/3gh2g78e
wandb: Run data is saved locally in /project/6002780/yinan/Thesis_MER_Lyrics/lyric-emotion/wandb/run-20220331_082104-3gh2g78e
wandb: Run `wandb offline` to turn off syncing.

Validation loss decreased (inf --> 1.397130).  Saving model ...
Validation loss decreased (1.397130 --> 1.385341).  Saving model ...
Validation loss decreased (1.385341 --> 1.376223).  Saving model ...
Validation loss decreased (1.376223 --> 1.368208).  Saving model ...
Validation loss decreased (1.368208 --> 1.362061).  Saving model ...
Validation loss decreased (1.362061 --> 1.356401).  Saving model ...
Validation loss decreased (1.356401 --> 1.350742).  Saving model ...
Validation loss decreased (1.350742 --> 1.345534).  Saving model ...
Validation loss decreased (1.345534 --> 1.340285).  Saving model ...
Validation loss decreased (1.340285 --> 1.335759).  Saving model ...
Validation loss decreased (1.335759 --> 1.331034).  Saving model ...
Validation loss decreased (1.331034 --> 1.326076).  Saving model ...
Validation loss decreased (1.326076 --> 1.320726).  Saving model ...
Validation loss decreased (1.320726 --> 1.314836).  Saving model ...
Validation loss decreased (1.314836 --> 1.309352).  Saving model ...
Validation loss decreased (1.309352 --> 1.303440).  Saving model ...
Validation loss decreased (1.303440 --> 1.298087).  Saving model ...
Validation loss decreased (1.298087 --> 1.291892).  Saving model ...
Validation loss decreased (1.291892 --> 1.285686).  Saving model ...
Validation loss decreased (1.285686 --> 1.279155).  Saving model ...
Validation loss decreased (1.279155 --> 1.272723).  Saving model ...
Validation loss decreased (1.272723 --> 1.266023).  Saving model ...
Validation loss decreased (1.266023 --> 1.258755).  Saving model ...
Validation loss decreased (1.258755 --> 1.252284).  Saving model ...
Validation loss decreased (1.252284 --> 1.244899).  Saving model ...
Validation loss decreased (1.244899 --> 1.236806).  Saving model ...
Validation loss decreased (1.236806 --> 1.228772).  Saving model ...
Validation loss decreased (1.228772 --> 1.220450).  Saving model ...
Validation loss decreased (1.220450 --> 1.212443).  Saving model ...
Validation loss decreased (1.212443 --> 1.206024).  Saving model ...
Validation loss decreased (1.206024 --> 1.199406).  Saving model ...
Validation loss decreased (1.199406 --> 1.193479).  Saving model ...
Validation loss decreased (1.193479 --> 1.186128).  Saving model ...
Validation loss decreased (1.186128 --> 1.178264).  Saving model ...
Validation loss decreased (1.178264 --> 1.171934).  Saving model ...
Validation loss decreased (1.171934 --> 1.166310).  Saving model ...
Validation loss decreased (1.166310 --> 1.157537).  Saving model ...
Validation loss decreased (1.157537 --> 1.151128).  Saving model ...
Validation loss decreased (1.151128 --> 1.144291).  Saving model ...
Validation loss decreased (1.144291 --> 1.138229).  Saving model ...
Validation loss decreased (1.138229 --> 1.130731).  Saving model ...
Validation loss decreased (1.130731 --> 1.122726).  Saving model ...
Validation loss decreased (1.122726 --> 1.116178).  Saving model ...
Validation loss decreased (1.116178 --> 1.108926).  Saving model ...
Validation loss decreased (1.108926 --> 1.102052).  Saving model ...
Validation loss decreased (1.102052 --> 1.096855).  Saving model ...
Validation loss decreased (1.096855 --> 1.091433).  Saving model ...
Validation loss decreased (1.091433 --> 1.086304).  Saving model ...
Validation loss decreased (1.086304 --> 1.081536).  Saving model ...
Validation loss decreased (1.081536 --> 1.077427).  Saving model ...
Validation loss decreased (1.077427 --> 1.072684).  Saving model ...
Validation loss decreased (1.072684 --> 1.067934).  Saving model ...
Validation loss decreased (1.067934 --> 1.061868).  Saving model ...
Validation loss decreased (1.061868 --> 1.055770).  Saving model ...
Validation loss decreased (1.055770 --> 1.050219).  Saving model ...
Validation loss decreased (1.050219 --> 1.045028).  Saving model ...
Validation loss decreased (1.045028 --> 1.042924).  Saving model ...
Validation loss decreased (1.042924 --> 1.038601).  Saving model ...
Validation loss decreased (1.038601 --> 1.030592).  Saving model ...
Validation loss decreased (1.030592 --> 1.026370).  Saving model ...
Validation loss decreased (1.026370 --> 1.021296).  Saving model ...
Validation loss decreased (1.021296 --> 1.018320).  Saving model ...
Validation loss decreased (1.018320 --> 1.016108).  Saving model ...
Validation loss decreased (1.016108 --> 1.012089).  Saving model ...
Validation loss decreased (1.012089 --> 1.008012).  Saving model ...
Validation loss decreased (1.008012 --> 1.003275).  Saving model ...
Validation loss decreased (1.003275 --> 0.999899).  Saving model ...
Validation loss decreased (0.999899 --> 0.995374).  Saving model ...
Validation loss decreased (0.995374 --> 0.990993).  Saving model ...
Validation loss decreased (0.990993 --> 0.988356).  Saving model ...
Validation loss decreased (0.988356 --> 0.983922).  Saving model ...
Validation loss decreased (0.983922 --> 0.979985).  Saving model ...
Validation loss decreased (0.979985 --> 0.976930).  Saving model ...
Validation loss decreased (0.976930 --> 0.973725).  Saving model ...
Validation loss decreased (0.973725 --> 0.970635).  Saving model ...
Validation loss decreased (0.970635 --> 0.967184).  Saving model ...
Validation loss decreased (0.967184 --> 0.965104).  Saving model ...
Validation loss decreased (0.965104 --> 0.961538).  Saving model ...
Validation loss decreased (0.961538 --> 0.958345).  Saving model ...
Validation loss decreased (0.958345 --> 0.955970).  Saving model ...
Validation loss decreased (0.955970 --> 0.954104).  Saving model ...
Validation loss decreased (0.954104 --> 0.951511).  Saving model ...
Validation loss decreased (0.951511 --> 0.950387).  Saving model ...
Validation loss decreased (0.950387 --> 0.948425).  Saving model ...
Validation loss decreased (0.948425 --> 0.946269).  Saving model ...
Validation loss decreased (0.946269 --> 0.943394).  Saving model ...
Validation loss decreased (0.943394 --> 0.941777).  Saving model ...
Validation loss decreased (0.941777 --> 0.939579).  Saving model ...
Validation loss decreased (0.939579 --> 0.936579).  Saving model ...
Validation loss decreased (0.936579 --> 0.935756).  Saving model ...
Validation loss decreased (0.935756 --> 0.935488).  Saving model ...
Validation loss decreased (0.935488 --> 0.932952).  Saving model ...
EarlyStopping counter: 1 out of 3.0
Validation loss decreased (0.932952 --> 0.930441).  Saving model ...
Validation loss decreased (0.930441 --> 0.928993).  Saving model ...
Validation loss decreased (0.928993 --> 0.927366).  Saving model ...
Validation loss decreased (0.927366 --> 0.926203).  Saving model ...
EarlyStopping counter: 1 out of 3.0
Validation loss decreased (0.926203 --> 0.925235).  Saving model ...
Validation loss decreased (0.925235 --> 0.923289).  Saving model ...
Validation loss decreased (0.923289 --> 0.922370).  Saving model ...
Validation loss decreased (0.922370 --> 0.920272).  Saving model ...
Validation loss decreased (0.920272 --> 0.919239).  Saving model ...
Validation loss decreased (0.919239 --> 0.918097).  Saving model ...
Validation loss decreased (0.918097 --> 0.916938).  Saving model ...
EarlyStopping counter: 1 out of 3.0
EarlyStopping counter: 2 out of 3.0
Validation loss decreased (0.916938 --> 0.916106).  Saving model ...
Validation loss decreased (0.916106 --> 0.914981).  Saving model ...
Validation loss decreased (0.914981 --> 0.912735).  Saving model ...
Validation loss decreased (0.912735 --> 0.912157).  Saving model ...
Validation loss decreased (0.912157 --> 0.912048).  Saving model ...
EarlyStopping counter: 1 out of 3.0
EarlyStopping counter: 2 out of 3.0
EarlyStopping counter: 3 out of 3.0
/localscratch/yinan.29785239.0/env/lib/python3.7/site-packages/torch/nn/functional.py:1794: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.
  warnings.warn("nn.functional.tanh is deprecated. Use torch.tanh instead.")
wandb: Waiting for W&B process to finish, PID 236930... (success).
wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: \ 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: | 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: / 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: \ 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: | 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: / 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: \ 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: | 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: / 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb:                                                                                
wandb: Run history:
wandb:     e_F1 ▁▁▂▃▄▅▆▆▆▆▆▇▇▇▇▇▇▇▇▇▇▇▇▇████████████████
wandb:   e_loss ██▇▇▇▇▆▆▆▆▅▅▅▄▄▄▄▃▃▃▃▃▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁
wandb:     t_F1 ▁▁▂▂▃▃▃▃▃▄▅▅▅▅▆▅▅▆▆▆▆▆▆▇▇▆▇▇▇▇▇▇▇▇█▇▇██▇
wandb:   t_loss ██▇█▇▇▇▇▇▆▆▆▆▆▅▅▅▅▄▄▄▄▄▃▃▃▃▃▂▃▂▂▂▂▂▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:     e_F1 61.51128
wandb:   e_loss 0.914
wandb:     t_F1 69.09202
wandb:   t_loss 0.79398
wandb: 
wandb: Synced 4 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Synced sunny-yogurt-2: https://wandb.ai/yinanazhou/xl_512_bs_8_lr_1e06_es_3_lc_True_nr_False_sr_True_stem_False_lemma_True_repeat_1_fold_2/runs/3gh2g78e
wandb: Find logs at: ./wandb/run-20220331_082104-3gh2g78e/logs/debug.log
wandb: 

wandb: wandb version 0.12.11 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
2022-03-31 09:35:37.643444: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1
wandb: Tracking run with wandb version 0.12.5
wandb: Syncing run summer-bird-2
wandb: ⭐️ View project at https://wandb.ai/yinanazhou/xl_512_bs_8_lr_1e06_es_3_lc_True_nr_False_sr_True_stem_False_lemma_True_repeat_2_fold_1
wandb: 🚀 View run at https://wandb.ai/yinanazhou/xl_512_bs_8_lr_1e06_es_3_lc_True_nr_False_sr_True_stem_False_lemma_True_repeat_2_fold_1/runs/u40fo4n3
wandb: Run data is saved locally in /project/6002780/yinan/Thesis_MER_Lyrics/lyric-emotion/wandb/run-20220331_093534-u40fo4n3
wandb: Run `wandb offline` to turn off syncing.

Validation loss decreased (inf --> 1.426607).  Saving model ...
Validation loss decreased (1.426607 --> 1.413634).  Saving model ...
Validation loss decreased (1.413634 --> 1.402982).  Saving model ...
Validation loss decreased (1.402982 --> 1.393803).  Saving model ...
Validation loss decreased (1.393803 --> 1.386249).  Saving model ...
Validation loss decreased (1.386249 --> 1.380047).  Saving model ...
Validation loss decreased (1.380047 --> 1.373965).  Saving model ...
Validation loss decreased (1.373965 --> 1.368768).  Saving model ...
Validation loss decreased (1.368768 --> 1.363626).  Saving model ...
Validation loss decreased (1.363626 --> 1.358180).  Saving model ...
Validation loss decreased (1.358180 --> 1.353511).  Saving model ...
Validation loss decreased (1.353511 --> 1.349080).  Saving model ...
Validation loss decreased (1.349080 --> 1.344881).  Saving model ...
Validation loss decreased (1.344881 --> 1.340252).  Saving model ...
Validation loss decreased (1.340252 --> 1.335488).  Saving model ...
Validation loss decreased (1.335488 --> 1.330906).  Saving model ...
Validation loss decreased (1.330906 --> 1.325921).  Saving model ...
Validation loss decreased (1.325921 --> 1.321076).  Saving model ...
Validation loss decreased (1.321076 --> 1.316128).  Saving model ...
Validation loss decreased (1.316128 --> 1.310925).  Saving model ...
Validation loss decreased (1.310925 --> 1.305158).  Saving model ...
Validation loss decreased (1.305158 --> 1.299774).  Saving model ...
Validation loss decreased (1.299774 --> 1.293780).  Saving model ...
Validation loss decreased (1.293780 --> 1.287895).  Saving model ...
Validation loss decreased (1.287895 --> 1.280984).  Saving model ...
Validation loss decreased (1.280984 --> 1.274323).  Saving model ...
Validation loss decreased (1.274323 --> 1.267759).  Saving model ...
Validation loss decreased (1.267759 --> 1.260013).  Saving model ...
Validation loss decreased (1.260013 --> 1.252681).  Saving model ...
Validation loss decreased (1.252681 --> 1.245303).  Saving model ...
Validation loss decreased (1.245303 --> 1.237300).  Saving model ...
Validation loss decreased (1.237300 --> 1.229836).  Saving model ...
Validation loss decreased (1.229836 --> 1.220464).  Saving model ...
Validation loss decreased (1.220464 --> 1.211617).  Saving model ...
Validation loss decreased (1.211617 --> 1.202658).  Saving model ...
Validation loss decreased (1.202658 --> 1.192785).  Saving model ...
Validation loss decreased (1.192785 --> 1.182948).  Saving model ...
Validation loss decreased (1.182948 --> 1.173274).  Saving model ...
Validation loss decreased (1.173274 --> 1.164503).  Saving model ...
Validation loss decreased (1.164503 --> 1.153907).  Saving model ...
Validation loss decreased (1.153907 --> 1.144585).  Saving model ...
Validation loss decreased (1.144585 --> 1.135211).  Saving model ...
Validation loss decreased (1.135211 --> 1.127759).  Saving model ...
Validation loss decreased (1.127759 --> 1.119583).  Saving model ...
Validation loss decreased (1.119583 --> 1.111673).  Saving model ...
Validation loss decreased (1.111673 --> 1.104418).  Saving model ...
Validation loss decreased (1.104418 --> 1.098455).  Saving model ...
Validation loss decreased (1.098455 --> 1.091310).  Saving model ...
Validation loss decreased (1.091310 --> 1.084852).  Saving model ...
Validation loss decreased (1.084852 --> 1.078082).  Saving model ...
Validation loss decreased (1.078082 --> 1.071066).  Saving model ...
Validation loss decreased (1.071066 --> 1.065172).  Saving model ...
Validation loss decreased (1.065172 --> 1.060413).  Saving model ...
Validation loss decreased (1.060413 --> 1.055313).  Saving model ...
Validation loss decreased (1.055313 --> 1.050226).  Saving model ...
Validation loss decreased (1.050226 --> 1.046282).  Saving model ...
Validation loss decreased (1.046282 --> 1.041955).  Saving model ...
Validation loss decreased (1.041955 --> 1.038037).  Saving model ...
Validation loss decreased (1.038037 --> 1.033524).  Saving model ...
Validation loss decreased (1.033524 --> 1.029790).  Saving model ...
Validation loss decreased (1.029790 --> 1.025259).  Saving model ...
Validation loss decreased (1.025259 --> 1.022044).  Saving model ...
Validation loss decreased (1.022044 --> 1.019269).  Saving model ...
Validation loss decreased (1.019269 --> 1.016017).  Saving model ...
Validation loss decreased (1.016017 --> 1.013346).  Saving model ...
Validation loss decreased (1.013346 --> 1.010368).  Saving model ...
Validation loss decreased (1.010368 --> 1.008128).  Saving model ...
Validation loss decreased (1.008128 --> 1.006163).  Saving model ...
Validation loss decreased (1.006163 --> 1.002265).  Saving model ...
Validation loss decreased (1.002265 --> 0.999868).  Saving model ...
Validation loss decreased (0.999868 --> 0.997554).  Saving model ...
Validation loss decreased (0.997554 --> 0.995535).  Saving model ...
Validation loss decreased (0.995535 --> 0.992710).  Saving model ...
Validation loss decreased (0.992710 --> 0.989561).  Saving model ...
Validation loss decreased (0.989561 --> 0.987327).  Saving model ...
EarlyStopping counter: 1 out of 3.0
Validation loss decreased (0.987327 --> 0.985482).  Saving model ...
Validation loss decreased (0.985482 --> 0.981511).  Saving model ...
Validation loss decreased (0.981511 --> 0.978190).  Saving model ...
Validation loss decreased (0.978190 --> 0.976578).  Saving model ...
Validation loss decreased (0.976578 --> 0.976185).  Saving model ...
EarlyStopping counter: 1 out of 3.0
Validation loss decreased (0.976185 --> 0.975742).  Saving model ...
Validation loss decreased (0.975742 --> 0.972973).  Saving model ...
Validation loss decreased (0.972973 --> 0.970266).  Saving model ...
Validation loss decreased (0.970266 --> 0.969958).  Saving model ...
Validation loss decreased (0.969958 --> 0.969403).  Saving model ...
Validation loss decreased (0.969403 --> 0.967061).  Saving model ...
EarlyStopping counter: 1 out of 3.0
Validation loss decreased (0.967061 --> 0.964978).  Saving model ...
Validation loss decreased (0.964978 --> 0.964127).  Saving model ...
Validation loss decreased (0.964127 --> 0.963509).  Saving model ...
EarlyStopping counter: 1 out of 3.0
Validation loss decreased (0.963509 --> 0.962180).  Saving model ...
Validation loss decreased (0.962180 --> 0.960350).  Saving model ...
Validation loss decreased (0.960350 --> 0.960290).  Saving model ...
Validation loss decreased (0.960290 --> 0.959167).  Saving model ...
Validation loss decreased (0.959167 --> 0.957953).  Saving model ...
Validation loss decreased (0.957953 --> 0.957226).  Saving model ...
Validation loss decreased (0.957226 --> 0.956630).  Saving model ...
Validation loss decreased (0.956630 --> 0.955796).  Saving model ...
Validation loss decreased (0.955796 --> 0.955755).  Saving model ...
EarlyStopping counter: 1 out of 3.0
Validation loss decreased (0.955755 --> 0.955630).  Saving model ...
Validation loss decreased (0.955630 --> 0.953414).  Saving model ...
Validation loss decreased (0.953414 --> 0.953231).  Saving model ...
Validation loss decreased (0.953231 --> 0.951871).  Saving model ...
EarlyStopping counter: 1 out of 3.0
EarlyStopping counter: 2 out of 3.0
EarlyStopping counter: 3 out of 3.0
/localscratch/yinan.29785239.0/env/lib/python3.7/site-packages/torch/nn/functional.py:1794: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.
  warnings.warn("nn.functional.tanh is deprecated. Use torch.tanh instead.")
wandb: Waiting for W&B process to finish, PID 240923... (success).
wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: \ 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: | 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: / 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: \ 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: | 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: / 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: \ 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: | 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: / 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: \ 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb:                                                                                
wandb: Run history:
wandb:     e_F1 ▁▂▃▃▄▅▅▅▆▆▆▆▆▆▇▇▇▇▇▇▇▇██▇▇▇▇▇▇▇█████████
wandb:   e_loss ██▇▇▇▇▇▆▆▆▆▅▅▄▄▄▃▃▃▃▂▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁
wandb:     t_F1 ▁▁▂▂▂▂▃▃▄▃▄▄▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇▇▇▇▇█▇███████
wandb:   t_loss ███▇▇▇▇▇▇▆▆▆▆▅▅▅▅▄▄▄▄▃▃▃▃▃▃▃▂▂▂▂▂▂▁▂▁▁▁▁
wandb: 
wandb: Run summary:
wandb:     e_F1 59.91718
wandb:   e_loss 0.95341
wandb:     t_F1 69.74452
wandb:   t_loss 0.81647
wandb: 
wandb: Synced 4 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Synced summer-bird-2: https://wandb.ai/yinanazhou/xl_512_bs_8_lr_1e06_es_3_lc_True_nr_False_sr_True_stem_False_lemma_True_repeat_2_fold_1/runs/u40fo4n3
wandb: Find logs at: ./wandb/run-20220331_093534-u40fo4n3/logs/debug.log
wandb: 

wandb: wandb version 0.12.11 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
2022-03-31 10:48:41.982242: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1
wandb: Tracking run with wandb version 0.12.5
wandb: Syncing run solar-microwave-2
wandb: ⭐️ View project at https://wandb.ai/yinanazhou/xl_512_bs_8_lr_1e06_es_3_lc_True_nr_False_sr_True_stem_False_lemma_True_repeat_2_fold_2
wandb: 🚀 View run at https://wandb.ai/yinanazhou/xl_512_bs_8_lr_1e06_es_3_lc_True_nr_False_sr_True_stem_False_lemma_True_repeat_2_fold_2/runs/uwnfgr75
wandb: Run data is saved locally in /project/6002780/yinan/Thesis_MER_Lyrics/lyric-emotion/wandb/run-20220331_104838-uwnfgr75
wandb: Run `wandb offline` to turn off syncing.

Validation loss decreased (inf --> 1.420611).  Saving model ...
Validation loss decreased (1.420611 --> 1.413149).  Saving model ...
Validation loss decreased (1.413149 --> 1.406260).  Saving model ...
Validation loss decreased (1.406260 --> 1.400329).  Saving model ...
Validation loss decreased (1.400329 --> 1.395449).  Saving model ...
Validation loss decreased (1.395449 --> 1.391174).  Saving model ...
Validation loss decreased (1.391174 --> 1.386926).  Saving model ...
Validation loss decreased (1.386926 --> 1.383155).  Saving model ...
Validation loss decreased (1.383155 --> 1.379064).  Saving model ...
Validation loss decreased (1.379064 --> 1.375343).  Saving model ...
Validation loss decreased (1.375343 --> 1.371591).  Saving model ...
Validation loss decreased (1.371591 --> 1.367647).  Saving model ...
Validation loss decreased (1.367647 --> 1.364329).  Saving model ...
Validation loss decreased (1.364329 --> 1.360488).  Saving model ...
Validation loss decreased (1.360488 --> 1.356644).  Saving model ...
Validation loss decreased (1.356644 --> 1.352715).  Saving model ...
Validation loss decreased (1.352715 --> 1.348960).  Saving model ...
Validation loss decreased (1.348960 --> 1.344848).  Saving model ...
Validation loss decreased (1.344848 --> 1.340543).  Saving model ...
Validation loss decreased (1.340543 --> 1.336435).  Saving model ...
Validation loss decreased (1.336435 --> 1.332336).  Saving model ...
Validation loss decreased (1.332336 --> 1.327841).  Saving model ...
Validation loss decreased (1.327841 --> 1.322307).  Saving model ...
Validation loss decreased (1.322307 --> 1.317397).  Saving model ...
Validation loss decreased (1.317397 --> 1.312298).  Saving model ...
Validation loss decreased (1.312298 --> 1.306786).  Saving model ...
Validation loss decreased (1.306786 --> 1.301302).  Saving model ...
Validation loss decreased (1.301302 --> 1.294627).  Saving model ...
Validation loss decreased (1.294627 --> 1.288252).  Saving model ...
Validation loss decreased (1.288252 --> 1.281920).  Saving model ...
Validation loss decreased (1.281920 --> 1.274846).  Saving model ...
Validation loss decreased (1.274846 --> 1.266126).  Saving model ...
Validation loss decreased (1.266126 --> 1.259014).  Saving model ...
Validation loss decreased (1.259014 --> 1.251603).  Saving model ...
Validation loss decreased (1.251603 --> 1.242115).  Saving model ...
Validation loss decreased (1.242115 --> 1.234207).  Saving model ...
Validation loss decreased (1.234207 --> 1.226585).  Saving model ...
Validation loss decreased (1.226585 --> 1.218958).  Saving model ...
Validation loss decreased (1.218958 --> 1.212328).  Saving model ...
Validation loss decreased (1.212328 --> 1.204650).  Saving model ...
Validation loss decreased (1.204650 --> 1.197736).  Saving model ...
Validation loss decreased (1.197736 --> 1.190454).  Saving model ...
Validation loss decreased (1.190454 --> 1.184055).  Saving model ...
Validation loss decreased (1.184055 --> 1.175387).  Saving model ...
Validation loss decreased (1.175387 --> 1.168905).  Saving model ...
Validation loss decreased (1.168905 --> 1.162920).  Saving model ...
Validation loss decreased (1.162920 --> 1.156382).  Saving model ...
Validation loss decreased (1.156382 --> 1.149358).  Saving model ...
Validation loss decreased (1.149358 --> 1.142133).  Saving model ...
Validation loss decreased (1.142133 --> 1.134692).  Saving model ...
Validation loss decreased (1.134692 --> 1.128525).  Saving model ...
Validation loss decreased (1.128525 --> 1.121604).  Saving model ...
Validation loss decreased (1.121604 --> 1.114843).  Saving model ...
Validation loss decreased (1.114843 --> 1.108913).  Saving model ...
Validation loss decreased (1.108913 --> 1.102525).  Saving model ...
Validation loss decreased (1.102525 --> 1.097760).  Saving model ...
Validation loss decreased (1.097760 --> 1.094883).  Saving model ...
Validation loss decreased (1.094883 --> 1.090823).  Saving model ...
Validation loss decreased (1.090823 --> 1.086698).  Saving model ...
Validation loss decreased (1.086698 --> 1.081224).  Saving model ...
Validation loss decreased (1.081224 --> 1.075501).  Saving model ...
Validation loss decreased (1.075501 --> 1.069661).  Saving model ...
Validation loss decreased (1.069661 --> 1.066407).  Saving model ...
Validation loss decreased (1.066407 --> 1.062638).  Saving model ...
Validation loss decreased (1.062638 --> 1.059654).  Saving model ...
Validation loss decreased (1.059654 --> 1.055387).  Saving model ...
Validation loss decreased (1.055387 --> 1.051133).  Saving model ...
Validation loss decreased (1.051133 --> 1.048668).  Saving model ...
Validation loss decreased (1.048668 --> 1.043352).  Saving model ...
Validation loss decreased (1.043352 --> 1.037654).  Saving model ...
Validation loss decreased (1.037654 --> 1.035111).  Saving model ...
Validation loss decreased (1.035111 --> 1.031568).  Saving model ...
Validation loss decreased (1.031568 --> 1.028105).  Saving model ...
Validation loss decreased (1.028105 --> 1.023561).  Saving model ...
Validation loss decreased (1.023561 --> 1.018187).  Saving model ...
Validation loss decreased (1.018187 --> 1.015226).  Saving model ...
Validation loss decreased (1.015226 --> 1.013282).  Saving model ...
Validation loss decreased (1.013282 --> 1.010568).  Saving model ...
Validation loss decreased (1.010568 --> 1.007848).  Saving model ...
Validation loss decreased (1.007848 --> 1.003646).  Saving model ...
Validation loss decreased (1.003646 --> 1.002007).  Saving model ...
Validation loss decreased (1.002007 --> 1.001552).  Saving model ...
Validation loss decreased (1.001552 --> 0.998715).  Saving model ...
Validation loss decreased (0.998715 --> 0.995618).  Saving model ...
Validation loss decreased (0.995618 --> 0.993622).  Saving model ...
Validation loss decreased (0.993622 --> 0.990050).  Saving model ...
Validation loss decreased (0.990050 --> 0.986957).  Saving model ...
Validation loss decreased (0.986957 --> 0.984383).  Saving model ...
Validation loss decreased (0.984383 --> 0.982813).  Saving model ...
Validation loss decreased (0.982813 --> 0.981795).  Saving model ...
Validation loss decreased (0.981795 --> 0.980751).  Saving model ...
Validation loss decreased (0.980751 --> 0.978653).  Saving model ...
Validation loss decreased (0.978653 --> 0.975738).  Saving model ...
Validation loss decreased (0.975738 --> 0.972448).  Saving model ...
Validation loss decreased (0.972448 --> 0.969808).  Saving model ...
Validation loss decreased (0.969808 --> 0.967977).  Saving model ...
Validation loss decreased (0.967977 --> 0.967605).  Saving model ...
Validation loss decreased (0.967605 --> 0.966519).  Saving model ...
Validation loss decreased (0.966519 --> 0.963650).  Saving model ...
Validation loss decreased (0.963650 --> 0.961519).  Saving model ...
Validation loss decreased (0.961519 --> 0.960137).  Saving model ...
Validation loss decreased (0.960137 --> 0.958667).  Saving model ...
Validation loss decreased (0.958667 --> 0.957685).  Saving model ...
Validation loss decreased (0.957685 --> 0.956849).  Saving model ...
EarlyStopping counter: 1 out of 3.0
Validation loss decreased (0.956849 --> 0.955267).  Saving model ...
Validation loss decreased (0.955267 --> 0.951195).  Saving model ...
Validation loss decreased (0.951195 --> 0.950313).  Saving model ...
Validation loss decreased (0.950313 --> 0.949998).  Saving model ...
Validation loss decreased (0.949998 --> 0.949603).  Saving model ...
Validation loss decreased (0.949603 --> 0.948307).  Saving model ...
Validation loss decreased (0.948307 --> 0.946074).  Saving model ...
Validation loss decreased (0.946074 --> 0.943350).  Saving model ...
Validation loss decreased (0.943350 --> 0.942737).  Saving model ...
Validation loss decreased (0.942737 --> 0.941763).  Saving model ...
Validation loss decreased (0.941763 --> 0.938853).  Saving model ...
Validation loss decreased (0.938853 --> 0.937345).  Saving model ...
EarlyStopping counter: 1 out of 3.0
Validation loss decreased (0.937345 --> 0.936803).  Saving model ...
EarlyStopping counter: 1 out of 3.0
EarlyStopping counter: 2 out of 3.0
EarlyStopping counter: 3 out of 3.0
/localscratch/yinan.29785239.0/env/lib/python3.7/site-packages/torch/nn/functional.py:1794: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.
  warnings.warn("nn.functional.tanh is deprecated. Use torch.tanh instead.")
wandb: Waiting for W&B process to finish, PID 244847... (success).
wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: \ 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: | 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: / 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: \ 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: | 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: / 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: \ 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: | 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: / 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb:                                                                                
wandb: Run history:
wandb:     e_F1 ▁▁▂▂▂▃▄▄▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇▇▇▇▇▇▇▇██████████
wandb:   e_loss ███▇▇▇▇▇▆▆▆▅▅▅▄▄▄▄▃▃▃▃▃▂▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁
wandb:     t_F1 ▁▁▂▂▂▃▃▃▃▄▅▅▅▆▆▅▆▆▆▆▆▇▇▆▇▇▇▇█▇▇██▇█▇████
wandb:   t_loss ███▇█▇▇▇▇▇▆▆▆▆▅▅▅▅▄▄▄▄▃▃▃▃▃▃▂▂▂▂▂▂▂▂▂▁▁▁
wandb: 
wandb: Run summary:
wandb:     e_F1 61.86861
wandb:   e_loss 0.9373
wandb:     t_F1 69.79197
wandb:   t_loss 0.77999
wandb: 
wandb: Synced 4 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Synced solar-microwave-2: https://wandb.ai/yinanazhou/xl_512_bs_8_lr_1e06_es_3_lc_True_nr_False_sr_True_stem_False_lemma_True_repeat_2_fold_2/runs/uwnfgr75
wandb: Find logs at: ./wandb/run-20220331_104838-uwnfgr75/logs/debug.log
wandb: 

wandb: wandb version 0.12.11 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
2022-03-31 12:08:15.348898: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1
wandb: Tracking run with wandb version 0.12.5
wandb: Syncing run frosty-cosmos-2
wandb: ⭐️ View project at https://wandb.ai/yinanazhou/xl_512_bs_8_lr_1e06_es_3_lc_True_nr_False_sr_True_stem_False_lemma_True_repeat_3_fold_1
wandb: 🚀 View run at https://wandb.ai/yinanazhou/xl_512_bs_8_lr_1e06_es_3_lc_True_nr_False_sr_True_stem_False_lemma_True_repeat_3_fold_1/runs/2frcvxux
wandb: Run data is saved locally in /project/6002780/yinan/Thesis_MER_Lyrics/lyric-emotion/wandb/run-20220331_120812-2frcvxux
wandb: Run `wandb offline` to turn off syncing.

Validation loss decreased (inf --> 1.789921).  Saving model ...
Validation loss decreased (1.789921 --> 1.646074).  Saving model ...
Validation loss decreased (1.646074 --> 1.533376).  Saving model ...
Validation loss decreased (1.533376 --> 1.456813).  Saving model ...
Validation loss decreased (1.456813 --> 1.408144).  Saving model ...
Validation loss decreased (1.408144 --> 1.378407).  Saving model ...
Validation loss decreased (1.378407 --> 1.360220).  Saving model ...
Validation loss decreased (1.360220 --> 1.348215).  Saving model ...
Validation loss decreased (1.348215 --> 1.340051).  Saving model ...
Validation loss decreased (1.340051 --> 1.333249).  Saving model ...
Validation loss decreased (1.333249 --> 1.326844).  Saving model ...
Validation loss decreased (1.326844 --> 1.320370).  Saving model ...
Validation loss decreased (1.320370 --> 1.314816).  Saving model ...
Validation loss decreased (1.314816 --> 1.308428).  Saving model ...
Validation loss decreased (1.308428 --> 1.302858).  Saving model ...
Validation loss decreased (1.302858 --> 1.296729).  Saving model ...
Validation loss decreased (1.296729 --> 1.290599).  Saving model ...
Validation loss decreased (1.290599 --> 1.285453).  Saving model ...
Validation loss decreased (1.285453 --> 1.279587).  Saving model ...
Validation loss decreased (1.279587 --> 1.272518).  Saving model ...
Validation loss decreased (1.272518 --> 1.266048).  Saving model ...
Validation loss decreased (1.266048 --> 1.260195).  Saving model ...
Validation loss decreased (1.260195 --> 1.254144).  Saving model ...
Validation loss decreased (1.254144 --> 1.247886).  Saving model ...
Validation loss decreased (1.247886 --> 1.242604).  Saving model ...
Validation loss decreased (1.242604 --> 1.236627).  Saving model ...
Validation loss decreased (1.236627 --> 1.230871).  Saving model ...
Validation loss decreased (1.230871 --> 1.225131).  Saving model ...
Validation loss decreased (1.225131 --> 1.219182).  Saving model ...
Validation loss decreased (1.219182 --> 1.213086).  Saving model ...
Validation loss decreased (1.213086 --> 1.207819).  Saving model ...
Validation loss decreased (1.207819 --> 1.201503).  Saving model ...
Validation loss decreased (1.201503 --> 1.195623).  Saving model ...
Validation loss decreased (1.195623 --> 1.190072).  Saving model ...
Validation loss decreased (1.190072 --> 1.184056).  Saving model ...
Validation loss decreased (1.184056 --> 1.178834).  Saving model ...
Validation loss decreased (1.178834 --> 1.174113).  Saving model ...
Validation loss decreased (1.174113 --> 1.166265).  Saving model ...
Validation loss decreased (1.166265 --> 1.161049).  Saving model ...
Validation loss decreased (1.161049 --> 1.156621).  Saving model ...
Validation loss decreased (1.156621 --> 1.151019).  Saving model ...
Validation loss decreased (1.151019 --> 1.146658).  Saving model ...
Validation loss decreased (1.146658 --> 1.141148).  Saving model ...
Validation loss decreased (1.141148 --> 1.137685).  Saving model ...
Validation loss decreased (1.137685 --> 1.132100).  Saving model ...
Validation loss decreased (1.132100 --> 1.127545).  Saving model ...
Validation loss decreased (1.127545 --> 1.122861).  Saving model ...
Validation loss decreased (1.122861 --> 1.118759).  Saving model ...
Validation loss decreased (1.118759 --> 1.113275).  Saving model ...
Validation loss decreased (1.113275 --> 1.108490).  Saving model ...
Validation loss decreased (1.108490 --> 1.104796).  Saving model ...
Validation loss decreased (1.104796 --> 1.099311).  Saving model ...
Validation loss decreased (1.099311 --> 1.094377).  Saving model ...
Validation loss decreased (1.094377 --> 1.090549).  Saving model ...
Validation loss decreased (1.090549 --> 1.087948).  Saving model ...
Validation loss decreased (1.087948 --> 1.082361).  Saving model ...
Validation loss decreased (1.082361 --> 1.078710).  Saving model ...
Validation loss decreased (1.078710 --> 1.075184).  Saving model ...
Validation loss decreased (1.075184 --> 1.071693).  Saving model ...
Validation loss decreased (1.071693 --> 1.065996).  Saving model ...
Validation loss decreased (1.065996 --> 1.061348).  Saving model ...
Validation loss decreased (1.061348 --> 1.057593).  Saving model ...
Validation loss decreased (1.057593 --> 1.053930).  Saving model ...
Validation loss decreased (1.053930 --> 1.051675).  Saving model ...
Validation loss decreased (1.051675 --> 1.047407).  Saving model ...
Validation loss decreased (1.047407 --> 1.044189).  Saving model ...
Validation loss decreased (1.044189 --> 1.040629).  Saving model ...
Validation loss decreased (1.040629 --> 1.036214).  Saving model ...
Validation loss decreased (1.036214 --> 1.032839).  Saving model ...
Validation loss decreased (1.032839 --> 1.030983).  Saving model ...
Validation loss decreased (1.030983 --> 1.027555).  Saving model ...
Validation loss decreased (1.027555 --> 1.026051).  Saving model ...
Validation loss decreased (1.026051 --> 1.022832).  Saving model ...
Validation loss decreased (1.022832 --> 1.019604).  Saving model ...
Validation loss decreased (1.019604 --> 1.017560).  Saving model ...
Validation loss decreased (1.017560 --> 1.014294).  Saving model ...
Validation loss decreased (1.014294 --> 1.012321).  Saving model ...
Validation loss decreased (1.012321 --> 1.009740).  Saving model ...
Validation loss decreased (1.009740 --> 1.008436).  Saving model ...
Validation loss decreased (1.008436 --> 1.005672).  Saving model ...
Validation loss decreased (1.005672 --> 1.003910).  Saving model ...
Validation loss decreased (1.003910 --> 1.002174).  Saving model ...
Validation loss decreased (1.002174 --> 1.001141).  Saving model ...
Validation loss decreased (1.001141 --> 0.998367).  Saving model ...
Validation loss decreased (0.998367 --> 0.995971).  Saving model ...
Validation loss decreased (0.995971 --> 0.994274).  Saving model ...
Validation loss decreased (0.994274 --> 0.992045).  Saving model ...
Validation loss decreased (0.992045 --> 0.990453).  Saving model ...
Validation loss decreased (0.990453 --> 0.988809).  Saving model ...
Validation loss decreased (0.988809 --> 0.986602).  Saving model ...
Validation loss decreased (0.986602 --> 0.985161).  Saving model ...
Validation loss decreased (0.985161 --> 0.983077).  Saving model ...
Validation loss decreased (0.983077 --> 0.981881).  Saving model ...
EarlyStopping counter: 1 out of 3.0
Validation loss decreased (0.981881 --> 0.979964).  Saving model ...
Validation loss decreased (0.979964 --> 0.978439).  Saving model ...
Validation loss decreased (0.978439 --> 0.976138).  Saving model ...
Validation loss decreased (0.976138 --> 0.975763).  Saving model ...
Validation loss decreased (0.975763 --> 0.975073).  Saving model ...
Validation loss decreased (0.975073 --> 0.974846).  Saving model ...
Validation loss decreased (0.974846 --> 0.972557).  Saving model ...
Validation loss decreased (0.972557 --> 0.970904).  Saving model ...
Validation loss decreased (0.970904 --> 0.970034).  Saving model ...
Validation loss decreased (0.970034 --> 0.969532).  Saving model ...
Validation loss decreased (0.969532 --> 0.968552).  Saving model ...
Validation loss decreased (0.968552 --> 0.967373).  Saving model ...
Validation loss decreased (0.967373 --> 0.965770).  Saving model ...
Validation loss decreased (0.965770 --> 0.964535).  Saving model ...
EarlyStopping counter: 1 out of 3.0
Validation loss decreased (0.964535 --> 0.963581).  Saving model ...
Validation loss decreased (0.963581 --> 0.963076).  Saving model ...
EarlyStopping counter: 1 out of 3.0
Validation loss decreased (0.963076 --> 0.961921).  Saving model ...
Validation loss decreased (0.961921 --> 0.961223).  Saving model ...
Validation loss decreased (0.961223 --> 0.960534).  Saving model ...
EarlyStopping counter: 1 out of 3.0
Validation loss decreased (0.960534 --> 0.960124).  Saving model ...
Validation loss decreased (0.960124 --> 0.958001).  Saving model ...
EarlyStopping counter: 1 out of 3.0
EarlyStopping counter: 2 out of 3.0
EarlyStopping counter: 3 out of 3.0
/localscratch/yinan.29785239.0/env/lib/python3.7/site-packages/torch/nn/functional.py:1794: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.
  warnings.warn("nn.functional.tanh is deprecated. Use torch.tanh instead.")
wandb: Waiting for W&B process to finish, PID 249154... (success).
wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: \ 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: | 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: / 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: \ 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: | 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: / 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: \ 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: | 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: / 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: \ 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb:                                                                                
wandb: Run history:
wandb:     e_F1 ▁▁▄▄▅▅▅▆▆▆▆▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇████████████
wandb:   e_loss █▅▄▄▄▄▄▄▃▃▃▃▃▃▃▂▂▂▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:     t_F1 ▁▁▂▃▃▃▄▄▄▅▅▅▅▅▆▆▆▆▆▆▆▇▇▇▇▇▇▇▇█▇█████████
wandb:   t_loss █▆▅▅▅▅▅▅▄▄▄▄▄▄▄▃▃▃▃▃▃▃▂▂▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:     e_F1 60.55428
wandb:   e_loss 0.95813
wandb:     t_F1 68.36222
wandb:   t_loss 0.79614
wandb: 
wandb: Synced 4 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Synced frosty-cosmos-2: https://wandb.ai/yinanazhou/xl_512_bs_8_lr_1e06_es_3_lc_True_nr_False_sr_True_stem_False_lemma_True_repeat_3_fold_1/runs/2frcvxux
wandb: Find logs at: ./wandb/run-20220331_120812-2frcvxux/logs/debug.log
wandb: 

wandb: wandb version 0.12.11 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
2022-03-31 13:28:26.596495: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1
wandb: Tracking run with wandb version 0.12.5
wandb: Syncing run legendary-vortex-2
wandb: ⭐️ View project at https://wandb.ai/yinanazhou/xl_512_bs_8_lr_1e06_es_3_lc_True_nr_False_sr_True_stem_False_lemma_True_repeat_3_fold_2
wandb: 🚀 View run at https://wandb.ai/yinanazhou/xl_512_bs_8_lr_1e06_es_3_lc_True_nr_False_sr_True_stem_False_lemma_True_repeat_3_fold_2/runs/1eny14nh
wandb: Run data is saved locally in /project/6002780/yinan/Thesis_MER_Lyrics/lyric-emotion/wandb/run-20220331_132823-1eny14nh
wandb: Run `wandb offline` to turn off syncing.

Validation loss decreased (inf --> 1.421435).  Saving model ...
Validation loss decreased (1.421435 --> 1.409575).  Saving model ...
Validation loss decreased (1.409575 --> 1.400869).  Saving model ...
Validation loss decreased (1.400869 --> 1.394474).  Saving model ...
Validation loss decreased (1.394474 --> 1.388603).  Saving model ...
Validation loss decreased (1.388603 --> 1.383592).  Saving model ...
Validation loss decreased (1.383592 --> 1.379223).  Saving model ...
Validation loss decreased (1.379223 --> 1.374975).  Saving model ...
Validation loss decreased (1.374975 --> 1.370795).  Saving model ...
Validation loss decreased (1.370795 --> 1.366322).  Saving model ...
Validation loss decreased (1.366322 --> 1.362138).  Saving model ...
Validation loss decreased (1.362138 --> 1.357836).  Saving model ...
Validation loss decreased (1.357836 --> 1.353575).  Saving model ...
Validation loss decreased (1.353575 --> 1.349336).  Saving model ...
Validation loss decreased (1.349336 --> 1.345074).  Saving model ...
Validation loss decreased (1.345074 --> 1.340384).  Saving model ...
Validation loss decreased (1.340384 --> 1.335717).  Saving model ...
Validation loss decreased (1.335717 --> 1.330293).  Saving model ...
Validation loss decreased (1.330293 --> 1.325135).  Saving model ...
Validation loss decreased (1.325135 --> 1.320176).  Saving model ...
Validation loss decreased (1.320176 --> 1.314049).  Saving model ...
Validation loss decreased (1.314049 --> 1.308038).  Saving model ...
Validation loss decreased (1.308038 --> 1.302110).  Saving model ...
Validation loss decreased (1.302110 --> 1.295519).  Saving model ...
Validation loss decreased (1.295519 --> 1.288113).  Saving model ...
Validation loss decreased (1.288113 --> 1.280746).  Saving model ...
Validation loss decreased (1.280746 --> 1.272285).  Saving model ...
Validation loss decreased (1.272285 --> 1.264931).  Saving model ...
Validation loss decreased (1.264931 --> 1.256589).  Saving model ...
Validation loss decreased (1.256589 --> 1.248300).  Saving model ...
Validation loss decreased (1.248300 --> 1.239584).  Saving model ...
Validation loss decreased (1.239584 --> 1.232089).  Saving model ...
Validation loss decreased (1.232089 --> 1.223348).  Saving model ...
Validation loss decreased (1.223348 --> 1.214996).  Saving model ...
Validation loss decreased (1.214996 --> 1.207023).  Saving model ...
Validation loss decreased (1.207023 --> 1.199844).  Saving model ...
Validation loss decreased (1.199844 --> 1.191299).  Saving model ...
Validation loss decreased (1.191299 --> 1.183751).  Saving model ...
Validation loss decreased (1.183751 --> 1.176528).  Saving model ...
Validation loss decreased (1.176528 --> 1.169666).  Saving model ...
Validation loss decreased (1.169666 --> 1.162938).  Saving model ...
Validation loss decreased (1.162938 --> 1.157225).  Saving model ...
Validation loss decreased (1.157225 --> 1.150536).  Saving model ...
Validation loss decreased (1.150536 --> 1.144725).  Saving model ...
Validation loss decreased (1.144725 --> 1.138136).  Saving model ...
Validation loss decreased (1.138136 --> 1.133209).  Saving model ...
Validation loss decreased (1.133209 --> 1.128150).  Saving model ...
Validation loss decreased (1.128150 --> 1.123445).  Saving model ...
Validation loss decreased (1.123445 --> 1.118123).  Saving model ...
Validation loss decreased (1.118123 --> 1.112776).  Saving model ...
Validation loss decreased (1.112776 --> 1.107741).  Saving model ...
Validation loss decreased (1.107741 --> 1.102746).  Saving model ...
Validation loss decreased (1.102746 --> 1.098287).  Saving model ...
Validation loss decreased (1.098287 --> 1.094933).  Saving model ...
Validation loss decreased (1.094933 --> 1.092775).  Saving model ...
Validation loss decreased (1.092775 --> 1.089168).  Saving model ...
Validation loss decreased (1.089168 --> 1.084354).  Saving model ...
Validation loss decreased (1.084354 --> 1.079153).  Saving model ...
Validation loss decreased (1.079153 --> 1.074382).  Saving model ...
Validation loss decreased (1.074382 --> 1.069875).  Saving model ...
Validation loss decreased (1.069875 --> 1.065255).  Saving model ...
Validation loss decreased (1.065255 --> 1.060548).  Saving model ...
Validation loss decreased (1.060548 --> 1.056819).  Saving model ...
Validation loss decreased (1.056819 --> 1.052398).  Saving model ...
Validation loss decreased (1.052398 --> 1.048207).  Saving model ...
Validation loss decreased (1.048207 --> 1.045223).  Saving model ...
Validation loss decreased (1.045223 --> 1.042670).  Saving model ...
Validation loss decreased (1.042670 --> 1.039410).  Saving model ...
Validation loss decreased (1.039410 --> 1.036967).  Saving model ...
Validation loss decreased (1.036967 --> 1.031867).  Saving model ...
Validation loss decreased (1.031867 --> 1.029043).  Saving model ...
Validation loss decreased (1.029043 --> 1.025942).  Saving model ...
Validation loss decreased (1.025942 --> 1.021810).  Saving model ...
Validation loss decreased (1.021810 --> 1.019775).  Saving model ...
Validation loss decreased (1.019775 --> 1.014865).  Saving model ...
Validation loss decreased (1.014865 --> 1.012907).  Saving model ...
Validation loss decreased (1.012907 --> 1.010865).  Saving model ...
Validation loss decreased (1.010865 --> 1.010288).  Saving model ...
Validation loss decreased (1.010288 --> 1.005860).  Saving model ...
Validation loss decreased (1.005860 --> 1.000974).  Saving model ...
Validation loss decreased (1.000974 --> 0.999268).  Saving model ...
Validation loss decreased (0.999268 --> 0.996809).  Saving model ...
Validation loss decreased (0.996809 --> 0.995083).  Saving model ...
Validation loss decreased (0.995083 --> 0.994526).  Saving model ...
Validation loss decreased (0.994526 --> 0.993658).  Saving model ...
Validation loss decreased (0.993658 --> 0.989129).  Saving model ...
Validation loss decreased (0.989129 --> 0.983510).  Saving model ...
Validation loss decreased (0.983510 --> 0.980736).  Saving model ...
Validation loss decreased (0.980736 --> 0.980008).  Saving model ...
Validation loss decreased (0.980008 --> 0.978679).  Saving model ...
Validation loss decreased (0.978679 --> 0.977910).  Saving model ...
Validation loss decreased (0.977910 --> 0.976239).  Saving model ...
Validation loss decreased (0.976239 --> 0.971842).  Saving model ...
Validation loss decreased (0.971842 --> 0.968013).  Saving model ...
Validation loss decreased (0.968013 --> 0.967269).  Saving model ...
EarlyStopping counter: 1 out of 3.0
Validation loss decreased (0.967269 --> 0.967243).  Saving model ...
Validation loss decreased (0.967243 --> 0.966135).  Saving model ...
Validation loss decreased (0.966135 --> 0.962277).  Saving model ...
Validation loss decreased (0.962277 --> 0.959538).  Saving model ...
Validation loss decreased (0.959538 --> 0.957356).  Saving model ...
Validation loss decreased (0.957356 --> 0.955734).  Saving model ...
Validation loss decreased (0.955734 --> 0.955461).  Saving model ...
Validation loss decreased (0.955461 --> 0.954453).  Saving model ...
EarlyStopping counter: 1 out of 3.0
Validation loss decreased (0.954453 --> 0.953967).  Saving model ...
Validation loss decreased (0.953967 --> 0.951253).  Saving model ...
Validation loss decreased (0.951253 --> 0.949287).  Saving model ...
Validation loss decreased (0.949287 --> 0.946713).  Saving model ...
Validation loss decreased (0.946713 --> 0.944741).  Saving model ...
EarlyStopping counter: 1 out of 3.0
EarlyStopping counter: 2 out of 3.0
EarlyStopping counter: 3 out of 3.0
/localscratch/yinan.29785239.0/env/lib/python3.7/site-packages/torch/nn/functional.py:1794: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.
  warnings.warn("nn.functional.tanh is deprecated. Use torch.tanh instead.")
wandb: Waiting for W&B process to finish, PID 253441... (success).
wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: \ 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: | 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: / 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: \ 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: | 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: / 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: \ 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: | 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: / 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb:                                                                                
wandb: Run history:
wandb:     e_F1 ▁▁▃▃▄▄▄▅▅▅▆▆▆▆▆▆▆▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇███████
wandb:   e_loss ██▇▇▇▇▇▆▆▆▆▅▅▅▄▄▄▄▃▃▃▃▃▂▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁
wandb:     t_F1 ▁▂▂▂▃▃▃▄▄▄▅▅▅▅▅▆▆▆▆▆▆▆▇▆▆▇▇▇▇▇▇▇▇▇█▇▇▇██
wandb:   t_loss ██▇▇▇▇▇▇▆▆▆▆▆▅▅▅▅▅▄▄▄▄▃▃▃▃▃▃▂▂▂▂▂▂▂▁▂▂▁▁
wandb: 
wandb: Run summary:
wandb:     e_F1 60.44137
wandb:   e_loss 0.94735
wandb:     t_F1 67.33511
wandb:   t_loss 0.85124
wandb: 
wandb: Synced 4 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Synced legendary-vortex-2: https://wandb.ai/yinanazhou/xl_512_bs_8_lr_1e06_es_3_lc_True_nr_False_sr_True_stem_False_lemma_True_repeat_3_fold_2/runs/1eny14nh
wandb: Find logs at: ./wandb/run-20220331_132823-1eny14nh/logs/debug.log
wandb: 

wandb: wandb version 0.12.11 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
2022-03-31 14:42:58.880983: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1
wandb: Tracking run with wandb version 0.12.5
wandb: Syncing run resilient-tree-1
wandb: ⭐️ View project at https://wandb.ai/yinanazhou/xl_512_bs_8_lr_1e06_es_3_lc_True_nr_False_sr_True_stem_False_lemma_True_repeat_4_fold_1
wandb: 🚀 View run at https://wandb.ai/yinanazhou/xl_512_bs_8_lr_1e06_es_3_lc_True_nr_False_sr_True_stem_False_lemma_True_repeat_4_fold_1/runs/1abx8cle
wandb: Run data is saved locally in /project/6002780/yinan/Thesis_MER_Lyrics/lyric-emotion/wandb/run-20220331_144256-1abx8cle
wandb: Run `wandb offline` to turn off syncing.

Validation loss decreased (inf --> 1.535146).  Saving model ...
Validation loss decreased (1.535146 --> 1.497772).  Saving model ...
Validation loss decreased (1.497772 --> 1.469340).  Saving model ...
Validation loss decreased (1.469340 --> 1.445839).  Saving model ...
Validation loss decreased (1.445839 --> 1.427235).  Saving model ...
Validation loss decreased (1.427235 --> 1.413496).  Saving model ...
Validation loss decreased (1.413496 --> 1.402248).  Saving model ...
Validation loss decreased (1.402248 --> 1.393052).  Saving model ...
Validation loss decreased (1.393052 --> 1.384831).  Saving model ...
Validation loss decreased (1.384831 --> 1.377231).  Saving model ...
Validation loss decreased (1.377231 --> 1.369938).  Saving model ...
Validation loss decreased (1.369938 --> 1.362541).  Saving model ...
Validation loss decreased (1.362541 --> 1.356045).  Saving model ...
Validation loss decreased (1.356045 --> 1.349754).  Saving model ...
Validation loss decreased (1.349754 --> 1.343104).  Saving model ...
Validation loss decreased (1.343104 --> 1.336455).  Saving model ...
Validation loss decreased (1.336455 --> 1.329066).  Saving model ...
Validation loss decreased (1.329066 --> 1.322306).  Saving model ...
Validation loss decreased (1.322306 --> 1.314828).  Saving model ...
Validation loss decreased (1.314828 --> 1.307591).  Saving model ...
Validation loss decreased (1.307591 --> 1.299132).  Saving model ...
Validation loss decreased (1.299132 --> 1.290398).  Saving model ...
Validation loss decreased (1.290398 --> 1.282449).  Saving model ...
Validation loss decreased (1.282449 --> 1.273762).  Saving model ...
Validation loss decreased (1.273762 --> 1.265694).  Saving model ...
Validation loss decreased (1.265694 --> 1.258395).  Saving model ...
Validation loss decreased (1.258395 --> 1.251136).  Saving model ...
Validation loss decreased (1.251136 --> 1.242992).  Saving model ...
Validation loss decreased (1.242992 --> 1.235207).  Saving model ...
Validation loss decreased (1.235207 --> 1.227715).  Saving model ...
Validation loss decreased (1.227715 --> 1.220204).  Saving model ...
Validation loss decreased (1.220204 --> 1.212725).  Saving model ...
Validation loss decreased (1.212725 --> 1.205707).  Saving model ...
Validation loss decreased (1.205707 --> 1.198805).  Saving model ...
Validation loss decreased (1.198805 --> 1.192672).  Saving model ...
Validation loss decreased (1.192672 --> 1.185681).  Saving model ...
Validation loss decreased (1.185681 --> 1.179604).  Saving model ...
Validation loss decreased (1.179604 --> 1.173861).  Saving model ...
Validation loss decreased (1.173861 --> 1.168351).  Saving model ...
Validation loss decreased (1.168351 --> 1.162878).  Saving model ...
Validation loss decreased (1.162878 --> 1.157149).  Saving model ...
Validation loss decreased (1.157149 --> 1.151584).  Saving model ...
Validation loss decreased (1.151584 --> 1.145657).  Saving model ...
Validation loss decreased (1.145657 --> 1.139995).  Saving model ...
Validation loss decreased (1.139995 --> 1.134328).  Saving model ...
Validation loss decreased (1.134328 --> 1.129671).  Saving model ...
Validation loss decreased (1.129671 --> 1.124187).  Saving model ...
Validation loss decreased (1.124187 --> 1.119601).  Saving model ...
Validation loss decreased (1.119601 --> 1.114470).  Saving model ...
Validation loss decreased (1.114470 --> 1.109554).  Saving model ...
Validation loss decreased (1.109554 --> 1.104794).  Saving model ...
Validation loss decreased (1.104794 --> 1.100074).  Saving model ...
Validation loss decreased (1.100074 --> 1.095200).  Saving model ...
Validation loss decreased (1.095200 --> 1.091611).  Saving model ...
Validation loss decreased (1.091611 --> 1.087590).  Saving model ...
Validation loss decreased (1.087590 --> 1.083221).  Saving model ...
Validation loss decreased (1.083221 --> 1.078020).  Saving model ...
Validation loss decreased (1.078020 --> 1.073721).  Saving model ...
Validation loss decreased (1.073721 --> 1.070211).  Saving model ...
Validation loss decreased (1.070211 --> 1.066328).  Saving model ...
Validation loss decreased (1.066328 --> 1.062449).  Saving model ...
Validation loss decreased (1.062449 --> 1.059440).  Saving model ...
Validation loss decreased (1.059440 --> 1.055663).  Saving model ...
Validation loss decreased (1.055663 --> 1.052075).  Saving model ...
Validation loss decreased (1.052075 --> 1.047500).  Saving model ...
Validation loss decreased (1.047500 --> 1.044608).  Saving model ...
Validation loss decreased (1.044608 --> 1.040657).  Saving model ...
Validation loss decreased (1.040657 --> 1.037215).  Saving model ...
Validation loss decreased (1.037215 --> 1.034661).  Saving model ...
Validation loss decreased (1.034661 --> 1.031019).  Saving model ...
Validation loss decreased (1.031019 --> 1.028517).  Saving model ...
Validation loss decreased (1.028517 --> 1.025820).  Saving model ...
Validation loss decreased (1.025820 --> 1.023730).  Saving model ...
Validation loss decreased (1.023730 --> 1.020404).  Saving model ...
Validation loss decreased (1.020404 --> 1.017865).  Saving model ...
Validation loss decreased (1.017865 --> 1.015533).  Saving model ...
Validation loss decreased (1.015533 --> 1.012991).  Saving model ...
Validation loss decreased (1.012991 --> 1.010486).  Saving model ...
Validation loss decreased (1.010486 --> 1.007856).  Saving model ...
Validation loss decreased (1.007856 --> 1.006514).  Saving model ...
Validation loss decreased (1.006514 --> 1.004267).  Saving model ...
Validation loss decreased (1.004267 --> 1.001554).  Saving model ...
Validation loss decreased (1.001554 --> 0.999260).  Saving model ...
Validation loss decreased (0.999260 --> 0.997626).  Saving model ...
Validation loss decreased (0.997626 --> 0.995251).  Saving model ...
Validation loss decreased (0.995251 --> 0.993962).  Saving model ...
Validation loss decreased (0.993962 --> 0.991164).  Saving model ...
Validation loss decreased (0.991164 --> 0.990365).  Saving model ...
Validation loss decreased (0.990365 --> 0.989062).  Saving model ...
Validation loss decreased (0.989062 --> 0.987040).  Saving model ...
Validation loss decreased (0.987040 --> 0.984922).  Saving model ...
Validation loss decreased (0.984922 --> 0.983060).  Saving model ...
Validation loss decreased (0.983060 --> 0.981092).  Saving model ...
Validation loss decreased (0.981092 --> 0.979798).  Saving model ...
Validation loss decreased (0.979798 --> 0.978766).  Saving model ...
Validation loss decreased (0.978766 --> 0.976533).  Saving model ...
Validation loss decreased (0.976533 --> 0.975787).  Saving model ...
Validation loss decreased (0.975787 --> 0.974797).  Saving model ...
Validation loss decreased (0.974797 --> 0.973841).  Saving model ...
Validation loss decreased (0.973841 --> 0.972916).  Saving model ...
Validation loss decreased (0.972916 --> 0.971350).  Saving model ...
Validation loss decreased (0.971350 --> 0.969571).  Saving model ...
Validation loss decreased (0.969571 --> 0.966540).  Saving model ...
EarlyStopping counter: 1 out of 3.0
Validation loss decreased (0.966540 --> 0.966165).  Saving model ...
Validation loss decreased (0.966165 --> 0.964311).  Saving model ...
Validation loss decreased (0.964311 --> 0.963962).  Saving model ...
Validation loss decreased (0.963962 --> 0.962191).  Saving model ...
Validation loss decreased (0.962191 --> 0.961387).  Saving model ...
EarlyStopping counter: 1 out of 3.0
EarlyStopping counter: 2 out of 3.0
Validation loss decreased (0.961387 --> 0.960859).  Saving model ...
Validation loss decreased (0.960859 --> 0.959078).  Saving model ...
EarlyStopping counter: 1 out of 3.0
Validation loss decreased (0.959078 --> 0.958206).  Saving model ...
Validation loss decreased (0.958206 --> 0.956514).  Saving model ...
Validation loss decreased (0.956514 --> 0.956207).  Saving model ...
Validation loss decreased (0.956207 --> 0.955306).  Saving model ...
Validation loss decreased (0.955306 --> 0.955060).  Saving model ...
EarlyStopping counter: 1 out of 3.0
EarlyStopping counter: 2 out of 3.0
Validation loss decreased (0.955060 --> 0.954845).  Saving model ...
Validation loss decreased (0.954845 --> 0.954634).  Saving model ...
Validation loss decreased (0.954634 --> 0.952725).  Saving model ...
EarlyStopping counter: 1 out of 3.0
EarlyStopping counter: 2 out of 3.0
EarlyStopping counter: 3 out of 3.0
/localscratch/yinan.29785239.0/env/lib/python3.7/site-packages/torch/nn/functional.py:1794: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.
  warnings.warn("nn.functional.tanh is deprecated. Use torch.tanh instead.")
wandb: Waiting for W&B process to finish, PID 257443... (success).
wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: \ 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: | 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: / 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: \ 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: | 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: / 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: \ 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: | 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: / 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb:                                                                                
wandb: Run history:
wandb:     e_F1 ▁▁▂▃▅▅▆▆▆▆▆▆▇▇▇▇▇▇▇▇▇▇▇▇████████████████
wandb:   e_loss █▇▆▆▆▆▅▅▅▄▄▄▄▃▃▃▃▃▂▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:     t_F1 ▁▁▂▃▃▃▄▄▅▅▅▅▅▆▆▆▆▆▇▆▆▆▇▇▇▇▇▇▇▇▇█▇█▇█▇███
wandb:   t_loss █▇▇▇▆▆▆▆▅▅▅▅▄▄▄▄▄▄▃▃▃▃▃▃▂▂▂▂▂▂▂▂▂▂▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:     e_F1 60.24312
wandb:   e_loss 0.95438
wandb:     t_F1 70.87323
wandb:   t_loss 0.77449
wandb: 
wandb: Synced 4 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Synced resilient-tree-1: https://wandb.ai/yinanazhou/xl_512_bs_8_lr_1e06_es_3_lc_True_nr_False_sr_True_stem_False_lemma_True_repeat_4_fold_1/runs/1abx8cle
wandb: Find logs at: ./wandb/run-20220331_144256-1abx8cle/logs/debug.log
wandb: 

wandb: wandb version 0.12.11 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
2022-03-31 16:06:26.592108: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1
wandb: Tracking run with wandb version 0.12.5
wandb: Syncing run radiant-wind-1
wandb: ⭐️ View project at https://wandb.ai/yinanazhou/xl_512_bs_8_lr_1e06_es_3_lc_True_nr_False_sr_True_stem_False_lemma_True_repeat_4_fold_2
wandb: 🚀 View run at https://wandb.ai/yinanazhou/xl_512_bs_8_lr_1e06_es_3_lc_True_nr_False_sr_True_stem_False_lemma_True_repeat_4_fold_2/runs/1gyj70kh
wandb: Run data is saved locally in /project/6002780/yinan/Thesis_MER_Lyrics/lyric-emotion/wandb/run-20220331_160624-1gyj70kh
wandb: Run `wandb offline` to turn off syncing.

Validation loss decreased (inf --> 1.421443).  Saving model ...
Validation loss decreased (1.421443 --> 1.403598).  Saving model ...
Validation loss decreased (1.403598 --> 1.390202).  Saving model ...
Validation loss decreased (1.390202 --> 1.379885).  Saving model ...
Validation loss decreased (1.379885 --> 1.371209).  Saving model ...
Validation loss decreased (1.371209 --> 1.364538).  Saving model ...
Validation loss decreased (1.364538 --> 1.358659).  Saving model ...
Validation loss decreased (1.358659 --> 1.353428).  Saving model ...
Validation loss decreased (1.353428 --> 1.348737).  Saving model ...
Validation loss decreased (1.348737 --> 1.344210).  Saving model ...
Validation loss decreased (1.344210 --> 1.339979).  Saving model ...
Validation loss decreased (1.339979 --> 1.335562).  Saving model ...
Validation loss decreased (1.335562 --> 1.331410).  Saving model ...
Validation loss decreased (1.331410 --> 1.327887).  Saving model ...
Validation loss decreased (1.327887 --> 1.323239).  Saving model ...
Validation loss decreased (1.323239 --> 1.318597).  Saving model ...
Validation loss decreased (1.318597 --> 1.313421).  Saving model ...
Validation loss decreased (1.313421 --> 1.308765).  Saving model ...
Validation loss decreased (1.308765 --> 1.304143).  Saving model ...
Validation loss decreased (1.304143 --> 1.298586).  Saving model ...
Validation loss decreased (1.298586 --> 1.293341).  Saving model ...
Validation loss decreased (1.293341 --> 1.287962).  Saving model ...
Validation loss decreased (1.287962 --> 1.281724).  Saving model ...
Validation loss decreased (1.281724 --> 1.274300).  Saving model ...
Validation loss decreased (1.274300 --> 1.266515).  Saving model ...
Validation loss decreased (1.266515 --> 1.258511).  Saving model ...
Validation loss decreased (1.258511 --> 1.251027).  Saving model ...
Validation loss decreased (1.251027 --> 1.242863).  Saving model ...
Validation loss decreased (1.242863 --> 1.234782).  Saving model ...
Validation loss decreased (1.234782 --> 1.227053).  Saving model ...
Validation loss decreased (1.227053 --> 1.218013).  Saving model ...
Validation loss decreased (1.218013 --> 1.209571).  Saving model ...
Validation loss decreased (1.209571 --> 1.199108).  Saving model ...
Validation loss decreased (1.199108 --> 1.191561).  Saving model ...
Validation loss decreased (1.191561 --> 1.182627).  Saving model ...
Validation loss decreased (1.182627 --> 1.172860).  Saving model ...
Validation loss decreased (1.172860 --> 1.165100).  Saving model ...
Validation loss decreased (1.165100 --> 1.156222).  Saving model ...
Validation loss decreased (1.156222 --> 1.147224).  Saving model ...
Validation loss decreased (1.147224 --> 1.139458).  Saving model ...
Validation loss decreased (1.139458 --> 1.132843).  Saving model ...
Validation loss decreased (1.132843 --> 1.122281).  Saving model ...
Validation loss decreased (1.122281 --> 1.116806).  Saving model ...
Validation loss decreased (1.116806 --> 1.111397).  Saving model ...
Validation loss decreased (1.111397 --> 1.103759).  Saving model ...
Validation loss decreased (1.103759 --> 1.097724).  Saving model ...
Validation loss decreased (1.097724 --> 1.090593).  Saving model ...
Validation loss decreased (1.090593 --> 1.085083).  Saving model ...
Validation loss decreased (1.085083 --> 1.079171).  Saving model ...
Validation loss decreased (1.079171 --> 1.074538).  Saving model ...
Validation loss decreased (1.074538 --> 1.069887).  Saving model ...
Validation loss decreased (1.069887 --> 1.064565).  Saving model ...
Validation loss decreased (1.064565 --> 1.060416).  Saving model ...
Validation loss decreased (1.060416 --> 1.055605).  Saving model ...
Validation loss decreased (1.055605 --> 1.051852).  Saving model ...
Validation loss decreased (1.051852 --> 1.047385).  Saving model ...
Validation loss decreased (1.047385 --> 1.043573).  Saving model ...
Validation loss decreased (1.043573 --> 1.039682).  Saving model ...
Validation loss decreased (1.039682 --> 1.033984).  Saving model ...
Validation loss decreased (1.033984 --> 1.030926).  Saving model ...
Validation loss decreased (1.030926 --> 1.027814).  Saving model ...
Validation loss decreased (1.027814 --> 1.023480).  Saving model ...
Validation loss decreased (1.023480 --> 1.019723).  Saving model ...
Validation loss decreased (1.019723 --> 1.016255).  Saving model ...
Validation loss decreased (1.016255 --> 1.013162).  Saving model ...
Validation loss decreased (1.013162 --> 1.009905).  Saving model ...
Validation loss decreased (1.009905 --> 1.007372).  Saving model ...
Validation loss decreased (1.007372 --> 1.003821).  Saving model ...
Validation loss decreased (1.003821 --> 0.998465).  Saving model ...
Validation loss decreased (0.998465 --> 0.995165).  Saving model ...
Validation loss decreased (0.995165 --> 0.992318).  Saving model ...
Validation loss decreased (0.992318 --> 0.989393).  Saving model ...
Validation loss decreased (0.989393 --> 0.987286).  Saving model ...
Validation loss decreased (0.987286 --> 0.986383).  Saving model ...
Validation loss decreased (0.986383 --> 0.984220).  Saving model ...
Validation loss decreased (0.984220 --> 0.980714).  Saving model ...
Validation loss decreased (0.980714 --> 0.978637).  Saving model ...
Validation loss decreased (0.978637 --> 0.977320).  Saving model ...
Validation loss decreased (0.977320 --> 0.974970).  Saving model ...
Validation loss decreased (0.974970 --> 0.970920).  Saving model ...
Validation loss decreased (0.970920 --> 0.968019).  Saving model ...
Validation loss decreased (0.968019 --> 0.964315).  Saving model ...
Validation loss decreased (0.964315 --> 0.963499).  Saving model ...
Validation loss decreased (0.963499 --> 0.961871).  Saving model ...
Validation loss decreased (0.961871 --> 0.958913).  Saving model ...
Validation loss decreased (0.958913 --> 0.956764).  Saving model ...
Validation loss decreased (0.956764 --> 0.955539).  Saving model ...
EarlyStopping counter: 1 out of 3.0
Validation loss decreased (0.955539 --> 0.954341).  Saving model ...
Validation loss decreased (0.954341 --> 0.952919).  Saving model ...
Validation loss decreased (0.952919 --> 0.951346).  Saving model ...
EarlyStopping counter: 1 out of 3.0
EarlyStopping counter: 2 out of 3.0
Validation loss decreased (0.951346 --> 0.949816).  Saving model ...
Validation loss decreased (0.949816 --> 0.948032).  Saving model ...
Validation loss decreased (0.948032 --> 0.944186).  Saving model ...
EarlyStopping counter: 1 out of 3.0
Validation loss decreased (0.944186 --> 0.942894).  Saving model ...
Validation loss decreased (0.942894 --> 0.942767).  Saving model ...
Validation loss decreased (0.942767 --> 0.942392).  Saving model ...
Validation loss decreased (0.942392 --> 0.940266).  Saving model ...
Validation loss decreased (0.940266 --> 0.937058).  Saving model ...
Validation loss decreased (0.937058 --> 0.936286).  Saving model ...
EarlyStopping counter: 1 out of 3.0
EarlyStopping counter: 2 out of 3.0
Validation loss decreased (0.936286 --> 0.934450).  Saving model ...
Validation loss decreased (0.934450 --> 0.934405).  Saving model ...
Validation loss decreased (0.934405 --> 0.934307).  Saving model ...
Validation loss decreased (0.934307 --> 0.934253).  Saving model ...
Validation loss decreased (0.934253 --> 0.932966).  Saving model ...
Validation loss decreased (0.932966 --> 0.932779).  Saving model ...
EarlyStopping counter: 1 out of 3.0
Validation loss decreased (0.932779 --> 0.932060).  Saving model ...
Validation loss decreased (0.932060 --> 0.931392).  Saving model ...
Validation loss decreased (0.931392 --> 0.929804).  Saving model ...
EarlyStopping counter: 1 out of 3.0
EarlyStopping counter: 2 out of 3.0
Validation loss decreased (0.929804 --> 0.928147).  Saving model ...
Validation loss decreased (0.928147 --> 0.926824).  Saving model ...
EarlyStopping counter: 1 out of 3.0
EarlyStopping counter: 2 out of 3.0
EarlyStopping counter: 3 out of 3.0
/localscratch/yinan.29785239.0/env/lib/python3.7/site-packages/torch/nn/functional.py:1794: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.
  warnings.warn("nn.functional.tanh is deprecated. Use torch.tanh instead.")
wandb: Waiting for W&B process to finish, PID 261925... (success).
wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: \ 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: | 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: / 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: \ 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: | 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: / 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: \ 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: | 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: / 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: \ 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb:                                                                                
wandb: Run history:
wandb:     e_F1 ▁▃▃▄▄▅▅▅▅▆▆▆▆▇▇▇▇▇▇▇▇▇▇▇▇▇██████████████
wandb:   e_loss █▇▇▇▇▇▆▆▆▅▅▅▄▄▄▃▃▃▃▃▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:     t_F1 ▁▂▂▂▃▃▃▄▄▄▅▅▅▅▆▆▆▆▆▆▆▆▆▆▆▇▇▇▆▇▇▇▇▇▇▇██▇█
wandb:   t_loss ██▇▇▇▇▇▇▆▆▆▆▅▅▅▄▄▄▄▄▄▄▃▃▃▃▂▃▃▂▂▂▂▁▂▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:     e_F1 63.64281
wandb:   e_loss 0.92966
wandb:     t_F1 70.90328
wandb:   t_loss 0.789
wandb: 
wandb: Synced 4 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Synced radiant-wind-1: https://wandb.ai/yinanazhou/xl_512_bs_8_lr_1e06_es_3_lc_True_nr_False_sr_True_stem_False_lemma_True_repeat_4_fold_2/runs/1gyj70kh
wandb: Find logs at: ./wandb/run-20220331_160624-1gyj70kh/logs/debug.log
wandb: 

wandb: wandb version 0.12.11 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
2022-03-31 17:26:28.511508: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1
wandb: Tracking run with wandb version 0.12.5
wandb: Syncing run azure-dawn-1
wandb: ⭐️ View project at https://wandb.ai/yinanazhou/xl_512_bs_8_lr_1e06_es_3_lc_True_nr_False_sr_True_stem_False_lemma_True_repeat_5_fold_1
wandb: 🚀 View run at https://wandb.ai/yinanazhou/xl_512_bs_8_lr_1e06_es_3_lc_True_nr_False_sr_True_stem_False_lemma_True_repeat_5_fold_1/runs/2596wua1
wandb: Run data is saved locally in /project/6002780/yinan/Thesis_MER_Lyrics/lyric-emotion/wandb/run-20220331_172626-2596wua1
wandb: Run `wandb offline` to turn off syncing.

Validation loss decreased (inf --> 1.428424).  Saving model ...
Validation loss decreased (1.428424 --> 1.411248).  Saving model ...
Validation loss decreased (1.411248 --> 1.397978).  Saving model ...
Validation loss decreased (1.397978 --> 1.388525).  Saving model ...
Validation loss decreased (1.388525 --> 1.379834).  Saving model ...
Validation loss decreased (1.379834 --> 1.373170).  Saving model ...
Validation loss decreased (1.373170 --> 1.367182).  Saving model ...
Validation loss decreased (1.367182 --> 1.361611).  Saving model ...
Validation loss decreased (1.361611 --> 1.357361).  Saving model ...
Validation loss decreased (1.357361 --> 1.352642).  Saving model ...
Validation loss decreased (1.352642 --> 1.348020).  Saving model ...
Validation loss decreased (1.348020 --> 1.343330).  Saving model ...
Validation loss decreased (1.343330 --> 1.338912).  Saving model ...
Validation loss decreased (1.338912 --> 1.334020).  Saving model ...
Validation loss decreased (1.334020 --> 1.328646).  Saving model ...
Validation loss decreased (1.328646 --> 1.323080).  Saving model ...
Validation loss decreased (1.323080 --> 1.317653).  Saving model ...
Validation loss decreased (1.317653 --> 1.312060).  Saving model ...
Validation loss decreased (1.312060 --> 1.305965).  Saving model ...
Validation loss decreased (1.305965 --> 1.298923).  Saving model ...
Validation loss decreased (1.298923 --> 1.291031).  Saving model ...
Validation loss decreased (1.291031 --> 1.284281).  Saving model ...
Validation loss decreased (1.284281 --> 1.275974).  Saving model ...
Validation loss decreased (1.275974 --> 1.267004).  Saving model ...
Validation loss decreased (1.267004 --> 1.256374).  Saving model ...
Validation loss decreased (1.256374 --> 1.247412).  Saving model ...
Validation loss decreased (1.247412 --> 1.237343).  Saving model ...
Validation loss decreased (1.237343 --> 1.227636).  Saving model ...
Validation loss decreased (1.227636 --> 1.219650).  Saving model ...
Validation loss decreased (1.219650 --> 1.211539).  Saving model ...
Validation loss decreased (1.211539 --> 1.203856).  Saving model ...
Validation loss decreased (1.203856 --> 1.196150).  Saving model ...
Validation loss decreased (1.196150 --> 1.189532).  Saving model ...
Validation loss decreased (1.189532 --> 1.182420).  Saving model ...
Validation loss decreased (1.182420 --> 1.176123).  Saving model ...
Validation loss decreased (1.176123 --> 1.169829).  Saving model ...
Validation loss decreased (1.169829 --> 1.163697).  Saving model ...
Validation loss decreased (1.163697 --> 1.158639).  Saving model ...
Validation loss decreased (1.158639 --> 1.153035).  Saving model ...
Validation loss decreased (1.153035 --> 1.148016).  Saving model ...
Validation loss decreased (1.148016 --> 1.142783).  Saving model ...
Validation loss decreased (1.142783 --> 1.137916).  Saving model ...
Validation loss decreased (1.137916 --> 1.132411).  Saving model ...
Validation loss decreased (1.132411 --> 1.127485).  Saving model ...
Validation loss decreased (1.127485 --> 1.123618).  Saving model ...
Validation loss decreased (1.123618 --> 1.118199).  Saving model ...
Validation loss decreased (1.118199 --> 1.113487).  Saving model ...
Validation loss decreased (1.113487 --> 1.108722).  Saving model ...
Validation loss decreased (1.108722 --> 1.104069).  Saving model ...
Validation loss decreased (1.104069 --> 1.099492).  Saving model ...
Validation loss decreased (1.099492 --> 1.094604).  Saving model ...
Validation loss decreased (1.094604 --> 1.090413).  Saving model ...
Validation loss decreased (1.090413 --> 1.086218).  Saving model ...
Validation loss decreased (1.086218 --> 1.082642).  Saving model ...
Validation loss decreased (1.082642 --> 1.077677).  Saving model ...
Validation loss decreased (1.077677 --> 1.073845).  Saving model ...
Validation loss decreased (1.073845 --> 1.070001).  Saving model ...
Validation loss decreased (1.070001 --> 1.064772).  Saving model ...
Validation loss decreased (1.064772 --> 1.060881).  Saving model ...
Validation loss decreased (1.060881 --> 1.057043).  Saving model ...
Validation loss decreased (1.057043 --> 1.053268).  Saving model ...
Validation loss decreased (1.053268 --> 1.049674).  Saving model ...
Validation loss decreased (1.049674 --> 1.046791).  Saving model ...
Validation loss decreased (1.046791 --> 1.042500).  Saving model ...
Validation loss decreased (1.042500 --> 1.039389).  Saving model ...
Validation loss decreased (1.039389 --> 1.035557).  Saving model ...
Validation loss decreased (1.035557 --> 1.033057).  Saving model ...
Validation loss decreased (1.033057 --> 1.029207).  Saving model ...
Validation loss decreased (1.029207 --> 1.026300).  Saving model ...
Validation loss decreased (1.026300 --> 1.023418).  Saving model ...
Validation loss decreased (1.023418 --> 1.021774).  Saving model ...
Validation loss decreased (1.021774 --> 1.019079).  Saving model ...
Validation loss decreased (1.019079 --> 1.016591).  Saving model ...
Validation loss decreased (1.016591 --> 1.013529).  Saving model ...
Validation loss decreased (1.013529 --> 1.009975).  Saving model ...
Validation loss decreased (1.009975 --> 1.007081).  Saving model ...
Validation loss decreased (1.007081 --> 1.005807).  Saving model ...
Validation loss decreased (1.005807 --> 1.002284).  Saving model ...
Validation loss decreased (1.002284 --> 1.001624).  Saving model ...
Validation loss decreased (1.001624 --> 1.000628).  Saving model ...
Validation loss decreased (1.000628 --> 0.996110).  Saving model ...
Validation loss decreased (0.996110 --> 0.993237).  Saving model ...
Validation loss decreased (0.993237 --> 0.992468).  Saving model ...
Validation loss decreased (0.992468 --> 0.991961).  Saving model ...
Validation loss decreased (0.991961 --> 0.990846).  Saving model ...
Validation loss decreased (0.990846 --> 0.987307).  Saving model ...
Validation loss decreased (0.987307 --> 0.985092).  Saving model ...
Validation loss decreased (0.985092 --> 0.982397).  Saving model ...
Validation loss decreased (0.982397 --> 0.981032).  Saving model ...
Validation loss decreased (0.981032 --> 0.980057).  Saving model ...
Validation loss decreased (0.980057 --> 0.978727).  Saving model ...
Validation loss decreased (0.978727 --> 0.978315).  Saving model ...
EarlyStopping counter: 1 out of 3.0
Validation loss decreased (0.978315 --> 0.977401).  Saving model ...
Validation loss decreased (0.977401 --> 0.976195).  Saving model ...
Validation loss decreased (0.976195 --> 0.973845).  Saving model ...
Validation loss decreased (0.973845 --> 0.971360).  Saving model ...
Validation loss decreased (0.971360 --> 0.969599).  Saving model ...
Validation loss decreased (0.969599 --> 0.967504).  Saving model ...
Validation loss decreased (0.967504 --> 0.966807).  Saving model ...
Validation loss decreased (0.966807 --> 0.965390).  Saving model ...
Validation loss decreased (0.965390 --> 0.963702).  Saving model ...
Validation loss decreased (0.963702 --> 0.961550).  Saving model ...
Validation loss decreased (0.961550 --> 0.959920).  Saving model ...
Validation loss decreased (0.959920 --> 0.959059).  Saving model ...
EarlyStopping counter: 1 out of 3.0
Validation loss decreased (0.959059 --> 0.956839).  Saving model ...
Validation loss decreased (0.956839 --> 0.956424).  Saving model ...
Validation loss decreased (0.956424 --> 0.953928).  Saving model ...
Validation loss decreased (0.953928 --> 0.953432).  Saving model ...
Validation loss decreased (0.953432 --> 0.952739).  Saving model ...
EarlyStopping counter: 1 out of 3.0
EarlyStopping counter: 2 out of 3.0
Validation loss decreased (0.952739 --> 0.951879).  Saving model ...
EarlyStopping counter: 1 out of 3.0
Validation loss decreased (0.951879 --> 0.950728).  Saving model ...
Validation loss decreased (0.950728 --> 0.950250).  Saving model ...
EarlyStopping counter: 1 out of 3.0
Validation loss decreased (0.950250 --> 0.949310).  Saving model ...
EarlyStopping counter: 1 out of 3.0
EarlyStopping counter: 2 out of 3.0
Validation loss decreased (0.949310 --> 0.949294).  Saving model ...
Validation loss decreased (0.949294 --> 0.947214).  Saving model ...
Validation loss decreased (0.947214 --> 0.946746).  Saving model ...
EarlyStopping counter: 1 out of 3.0
Validation loss decreased (0.946746 --> 0.945985).  Saving model ...
EarlyStopping counter: 1 out of 3.0
Validation loss decreased (0.945985 --> 0.945640).  Saving model ...
EarlyStopping counter: 1 out of 3.0
EarlyStopping counter: 2 out of 3.0
Validation loss decreased (0.945640 --> 0.945251).  Saving model ...
EarlyStopping counter: 1 out of 3.0
EarlyStopping counter: 2 out of 3.0
Validation loss decreased (0.945251 --> 0.944173).  Saving model ...
Validation loss decreased (0.944173 --> 0.943802).  Saving model ...
EarlyStopping counter: 1 out of 3.0
EarlyStopping counter: 2 out of 3.0
EarlyStopping counter: 3 out of 3.0
/localscratch/yinan.29785239.0/env/lib/python3.7/site-packages/torch/nn/functional.py:1794: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.
  warnings.warn("nn.functional.tanh is deprecated. Use torch.tanh instead.")
wandb: Waiting for W&B process to finish, PID 4464... (success).
wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: \ 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: | 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: / 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: \ 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: | 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: / 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: \ 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: | 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: / 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb:                                                                                
wandb: Run history:
wandb:     e_F1 ▁▂▃▄▄▅▅▅▆▆▆▆▆▇▇▇▇▇▇▇▇▇██████████████████
wandb:   e_loss ██▇▇▇▇▆▆▅▅▄▄▄▄▃▃▃▃▂▂▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:     t_F1 ▁▁▂▃▃▃▃▅▄▅▅▅▆▅▆▆▆▆▆▆▆▇▆▇▆▇▇▇▇▇▇▇█▇█▇▇███
wandb:   t_loss ███▇▇▇▇▆▆▆▅▅▅▅▄▄▄▄▄▃▃▃▃▃▃▃▂▂▂▂▂▂▂▂▂▂▁▁▁▁
wandb: 
wandb: Run summary:
wandb:     e_F1 58.74876
wandb:   e_loss 0.94397
wandb:     t_F1 74.9701
wandb:   t_loss 0.74206
wandb: 
wandb: Synced 4 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Synced azure-dawn-1: https://wandb.ai/yinanazhou/xl_512_bs_8_lr_1e06_es_3_lc_True_nr_False_sr_True_stem_False_lemma_True_repeat_5_fold_1/runs/2596wua1
wandb: Find logs at: ./wandb/run-20220331_172626-2596wua1/logs/debug.log
wandb: 

wandb: wandb version 0.12.11 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
2022-03-31 18:54:32.988773: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1
wandb: Tracking run with wandb version 0.12.5
wandb: Syncing run revived-tree-1
wandb: ⭐️ View project at https://wandb.ai/yinanazhou/xl_512_bs_8_lr_1e06_es_3_lc_True_nr_False_sr_True_stem_False_lemma_True_repeat_5_fold_2
wandb: 🚀 View run at https://wandb.ai/yinanazhou/xl_512_bs_8_lr_1e06_es_3_lc_True_nr_False_sr_True_stem_False_lemma_True_repeat_5_fold_2/runs/2ose97n6
wandb: Run data is saved locally in /project/6002780/yinan/Thesis_MER_Lyrics/lyric-emotion/wandb/run-20220331_185430-2ose97n6
wandb: Run `wandb offline` to turn off syncing.
slurmstepd: error: *** JOB 29785239 ON cdr2635 CANCELLED AT 2022-03-31T19:26:43 ***
