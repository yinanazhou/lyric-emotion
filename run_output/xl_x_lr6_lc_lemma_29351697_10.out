Unloading StdEnv/2020

Due to MODULEPATH changes, the following have been reloaded:
  1) mii/1.1.1


The following have been reloaded with a version change:
  1) python/3.8.2 => python/3.7.4

Using base prefix '/cvmfs/soft.computecanada.ca/easybuild/software/2017/Core/python/3.7.4'
New python executable in /localscratch/yinan.29351697.0/env/bin/python
Installing setuptools, pip, wheel...
done.
Ignoring pip: markers 'python_version < "3"' don't match your environment
Looking in links: /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/nix/avx2, /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/nix/generic, /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic
Collecting pip
Installing collected packages: pip
  Found existing installation: pip 19.1.1
    Uninstalling pip-19.1.1:
      Successfully uninstalled pip-19.1.1
Successfully installed pip-21.2.3+computecanada
Looking in links: /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/nix/avx2, /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/nix/generic, /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/keras-2.8.0+computecanada-py2.py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/Keras_Preprocessing-1.1.2+computecanada-py3-none-any.whl
Requirement already satisfied: matplotlib in /cvmfs/soft.computecanada.ca/easybuild/software/2017/Core/scipy-stack/2019a/lib/python3.7/site-packages (from -r requirements.txt (line 3)) (3.0.2)
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/nltk-3.6.5+computecanada-py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/scikit_learn-0.22.1+computecanada-cp37-cp37m-linux_x86_64.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/tensorboard-2.3.0+computecanada-py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/tensorboard_plugin_wit-1.7.0+computecanada-py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/tensorflow_gpu-2.3.0+computecanada-cp37-cp37m-linux_x86_64.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/tensorflow_estimator-2.3.0+computecanada-py2.py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/tokenizers-0.5.2+computecanada-cp37-cp37m-linux_x86_64.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/nix/avx2/torch-1.4.0+computecanada-cp37-cp37m-linux_x86_64.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/torchtext-0.6.0+computecanada-py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/torchvision-0.8.2+computecanada-cp37-cp37m-linux_x86_64.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/transformers-2.5.1+computecanada-py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/urllib3-1.26.7+computecanada-py2.py3-none-any.whl
ERROR: Could not find a version that satisfies the requirement regex>=2021.8.3 (from nltk) (from versions: 2018.1.10+computecanada, 2019.11.1+computecanada, 2020.11.13+computecanada)
ERROR: No matching distribution found for regex>=2021.8.3
Looking in links: /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/nix/avx2, /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/nix/generic, /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic
ERROR: Could not find a version that satisfies the requirement numpy==1.20.0+computacanada (from versions: 1.15.0+computecanada, 1.15.2+computecanada, 1.15.4+computecanada, 1.16.0+computecanada, 1.16.2+computecanada, 1.16.3+computecanada, 1.17.4+computecanada, 1.18.1+computecanada, 1.18.4+computecanada, 1.19.1+computecanada, 1.19.2+computecanada, 1.20.2+computecanada)
ERROR: No matching distribution found for numpy==1.20.0+computacanada
Looking in links: /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/nix/avx2, /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/nix/generic, /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/wandb-0.12.5+computecanada-py2.py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/configparser-5.0.2+computecanada-py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/psutil-5.7.3+computecanada-cp37-cp37m-linux_x86_64.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/protobuf-3.19.4+computecanada-py2.py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/docker_pycreds-0.4.0+computecanada-py2.py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/click-8.0.4+computecanada-py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/sentry_sdk-1.5.0+computecanada-py2.py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/yaspin-2.1.0+computecanada-py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/PyYAML-5.3.1+computecanada-cp37-cp37m-linux_x86_64.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/promise-2.3+computecanada-py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/subprocess32-3.5.4+computecanada-py3-none-any.whl
Requirement already satisfied: python-dateutil>=2.6.1 in /cvmfs/soft.computecanada.ca/easybuild/software/2017/Core/scipy-stack/2019a/lib/python3.7/site-packages (from wandb) (2.7.5)
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/shortuuid-1.0.1+computecanada-py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/six-1.16.0+computecanada-py2.py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/pathtools-0.1.2+computecanada-py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/GitPython-3.1.24+computecanada-py3-none-any.whl
Requirement already satisfied: requests<3,>=2.0.0 in /cvmfs/soft.computecanada.ca/easybuild/software/2017/Core/scipy-stack/2019a/lib/python3.7/site-packages (from wandb) (2.21.0)
Requirement already satisfied: importlib-metadata in /cvmfs/soft.computecanada.ca/easybuild/software/2017/Core/scipy-stack/2019a/lib/python3.7/site-packages (from Click!=8.0.0,>=7.0->wandb) (0.8)
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/typing_extensions-4.0.1+computecanada-py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/gitdb-4.0.9+computecanada-py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/smmap-5.0.0+computecanada-py3-none-any.whl
Requirement already satisfied: urllib3<1.25,>=1.21.1 in /cvmfs/soft.computecanada.ca/easybuild/software/2017/Core/scipy-stack/2019a/lib/python3.7/site-packages (from requests<3,>=2.0.0->wandb) (1.24.1)
Requirement already satisfied: certifi>=2017.4.17 in /cvmfs/soft.computecanada.ca/easybuild/software/2017/Core/scipy-stack/2019a/lib/python3.7/site-packages (from requests<3,>=2.0.0->wandb) (2018.11.29)
Requirement already satisfied: idna<2.9,>=2.5 in /cvmfs/soft.computecanada.ca/easybuild/software/2017/Core/scipy-stack/2019a/lib/python3.7/site-packages (from requests<3,>=2.0.0->wandb) (2.8)
Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /cvmfs/soft.computecanada.ca/easybuild/software/2017/Core/scipy-stack/2019a/lib/python3.7/site-packages (from requests<3,>=2.0.0->wandb) (3.0.4)
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/termcolor-1.1.0+computecanada-py3-none-any.whl
Requirement already satisfied: zipp>=0.3.2 in /cvmfs/soft.computecanada.ca/easybuild/software/2017/Core/scipy-stack/2019a/lib/python3.7/site-packages (from importlib-metadata->Click!=8.0.0,>=7.0->wandb) (0.3.3)
Installing collected packages: smmap, typing-extensions, termcolor, six, gitdb, yaspin, subprocess32, shortuuid, sentry-sdk, PyYAML, psutil, protobuf, promise, pathtools, GitPython, docker-pycreds, configparser, Click, wandb
  Attempting uninstall: six
    Found existing installation: six 1.12.0
    Not uninstalling six at /cvmfs/soft.computecanada.ca/easybuild/software/2017/Core/scipy-stack/2019a/lib/python3.7/site-packages, outside environment /localscratch/yinan.29351697.0/env
    Can't uninstall 'six'. No files were found to uninstall.
Successfully installed Click-8.0.4+computecanada GitPython-3.1.24+computecanada PyYAML-5.3.1+computecanada configparser-5.0.2+computecanada docker-pycreds-0.4.0+computecanada gitdb-4.0.9+computecanada pathtools-0.1.2+computecanada promise-2.3+computecanada protobuf-3.19.4+computecanada psutil-5.7.3+computecanada sentry-sdk-1.5.0+computecanada shortuuid-1.0.1+computecanada six-1.16.0+computecanada smmap-5.0.0+computecanada subprocess32-3.5.4+computecanada termcolor-1.1.0+computecanada typing-extensions-4.0.1+computecanada wandb-0.12.5+computecanada yaspin-2.1.0+computecanada
Looking in links: /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/nix/avx2, /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/nix/generic, /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic
ERROR: Could not find a version that satisfies the requirement sagemaker (from versions: none)
ERROR: No matching distribution found for sagemaker
Looking in links: /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/nix/avx2, /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/nix/generic, /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/torch-1.9.1+computecanada-cp37-cp37m-linux_x86_64.whl
Requirement already satisfied: typing-extensions in /localscratch/yinan.29351697.0/env/lib/python3.7/site-packages (from torch) (4.0.1+computecanada)
Installing collected packages: torch
Successfully installed torch-1.9.1+computecanada
Looking in links: /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/nix/avx2, /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/nix/generic, /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/transformers-2.5.1+computecanada-py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/sentencepiece-0.1.91+computecanada-cp37-cp37m-linux_x86_64.whl
Requirement already satisfied: requests in /cvmfs/soft.computecanada.ca/easybuild/software/2017/Core/scipy-stack/2019a/lib/python3.7/site-packages (from transformers==2.5.1+computecanada) (2.21.0)
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/tokenizers-0.5.2+computecanada-cp37-cp37m-linux_x86_64.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/sacremoses-0.0.46+computecanada-py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/tqdm-4.63.0+computecanada-py2.py3-none-any.whl
Requirement already satisfied: numpy in /cvmfs/soft.computecanada.ca/easybuild/software/2017/Core/scipy-stack/2019a/lib/python3.7/site-packages (from transformers==2.5.1+computecanada) (1.16.0)
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/filelock-3.4.2+computecanada-py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/boto3-1.21.14+computecanada-py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/regex-2020.11.13+computecanada-cp37-cp37m-linux_x86_64.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/botocore-1.24.14+computecanada-py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/jmespath-0.10.0+computecanada-py2.py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/s3transfer-0.5.1+computecanada-py3-none-any.whl
Requirement already satisfied: python-dateutil<3.0.0,>=2.1 in /cvmfs/soft.computecanada.ca/easybuild/software/2017/Core/scipy-stack/2019a/lib/python3.7/site-packages (from botocore<1.25.0,>=1.24.14->boto3->transformers==2.5.1+computecanada) (2.7.5)
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/urllib3-1.26.8+computecanada-py2.py3-none-any.whl
Requirement already satisfied: six>=1.5 in /localscratch/yinan.29351697.0/env/lib/python3.7/site-packages (from python-dateutil<3.0.0,>=2.1->botocore<1.25.0,>=1.24.14->boto3->transformers==2.5.1+computecanada) (1.16.0+computecanada)
Requirement already satisfied: idna<2.9,>=2.5 in /cvmfs/soft.computecanada.ca/easybuild/software/2017/Core/scipy-stack/2019a/lib/python3.7/site-packages (from requests->transformers==2.5.1+computecanada) (2.8)
Requirement already satisfied: certifi>=2017.4.17 in /cvmfs/soft.computecanada.ca/easybuild/software/2017/Core/scipy-stack/2019a/lib/python3.7/site-packages (from requests->transformers==2.5.1+computecanada) (2018.11.29)
Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /cvmfs/soft.computecanada.ca/easybuild/software/2017/Core/scipy-stack/2019a/lib/python3.7/site-packages (from requests->transformers==2.5.1+computecanada) (3.0.4)
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/requests-2.27.1+computecanada-py2.py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/charset_normalizer-2.0.12+computecanada-py3-none-any.whl
Requirement already satisfied: click in /localscratch/yinan.29351697.0/env/lib/python3.7/site-packages (from sacremoses->transformers==2.5.1+computecanada) (8.0.4+computecanada)
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/joblib-1.1.0+computecanada-py2.py3-none-any.whl
Requirement already satisfied: importlib-metadata in /cvmfs/soft.computecanada.ca/easybuild/software/2017/Core/scipy-stack/2019a/lib/python3.7/site-packages (from click->sacremoses->transformers==2.5.1+computecanada) (0.8)
Requirement already satisfied: zipp>=0.3.2 in /cvmfs/soft.computecanada.ca/easybuild/software/2017/Core/scipy-stack/2019a/lib/python3.7/site-packages (from importlib-metadata->click->sacremoses->transformers==2.5.1+computecanada) (0.3.3)
Installing collected packages: urllib3, jmespath, botocore, tqdm, s3transfer, regex, joblib, charset-normalizer, tokenizers, sentencepiece, sacremoses, requests, filelock, boto3, transformers
  Attempting uninstall: urllib3
    Found existing installation: urllib3 1.24.1
    Not uninstalling urllib3 at /cvmfs/soft.computecanada.ca/easybuild/software/2017/Core/scipy-stack/2019a/lib/python3.7/site-packages, outside environment /localscratch/yinan.29351697.0/env
    Can't uninstall 'urllib3'. No files were found to uninstall.
  Attempting uninstall: requests
    Found existing installation: requests 2.21.0
    Not uninstalling requests at /cvmfs/soft.computecanada.ca/easybuild/software/2017/Core/scipy-stack/2019a/lib/python3.7/site-packages, outside environment /localscratch/yinan.29351697.0/env
    Can't uninstall 'requests'. No files were found to uninstall.
Successfully installed boto3-1.21.14+computecanada botocore-1.24.14+computecanada charset-normalizer-2.0.12+computecanada filelock-3.4.2+computecanada jmespath-0.10.0+computecanada joblib-1.1.0+computecanada regex-2020.11.13+computecanada requests-2.27.1+computecanada s3transfer-0.5.1+computecanada sacremoses-0.0.46+computecanada sentencepiece-0.1.91+computecanada tokenizers-0.5.2+computecanada tqdm-4.63.0+computecanada transformers-2.5.1+computecanada urllib3-1.26.8+computecanada
Looking in links: /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/nix/avx2, /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/nix/generic, /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/tensorflow_gpu-2.3.0+computecanada-cp37-cp37m-linux_x86_64.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/nix/avx2/h5py-2.10.0+computecanada-cp37-cp37m-linux_x86_64.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/gast-0.3.3+computecanada-py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/Keras_Preprocessing-1.1.2+computecanada-py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/grpcio-1.38.0+computecanada-cp37-cp37m-linux_x86_64.whl
Requirement already satisfied: termcolor>=1.1.0 in /localscratch/yinan.29351697.0/env/lib/python3.7/site-packages (from tensorflow_gpu==2.3.0+computecanada) (1.1.0+computecanada)
Requirement already satisfied: wheel>=0.26 in /localscratch/yinan.29351697.0/env/lib/python3.7/site-packages (from tensorflow_gpu==2.3.0+computecanada) (0.33.4)
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/opt_einsum-3.3.0+computecanada-py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/wrapt-1.11.2+computecanada-cp37-cp37m-linux_x86_64.whl
Requirement already satisfied: protobuf>=3.9.2 in /localscratch/yinan.29351697.0/env/lib/python3.7/site-packages (from tensorflow_gpu==2.3.0+computecanada) (3.19.4+computecanada)
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/google_pasta-0.2.0+computecanada-py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/astunparse-1.6.3+computecanada-py2.py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/tensorboard-2.8.0+computecanada-py3-none-any.whl
Requirement already satisfied: six>=1.12.0 in /localscratch/yinan.29351697.0/env/lib/python3.7/site-packages (from tensorflow_gpu==2.3.0+computecanada) (1.16.0+computecanada)
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/nix/generic/scipy-1.4.1+computecanada-cp37-cp37m-linux_x86_64.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/tensorflow_estimator-2.3.0+computecanada-py2.py3-none-any.whl
Requirement already satisfied: numpy<1.19.0,>=1.16.0 in /cvmfs/soft.computecanada.ca/easybuild/software/2017/Core/scipy-stack/2019a/lib/python3.7/site-packages (from tensorflow_gpu==2.3.0+computecanada) (1.16.0)
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/absl_py-1.0.0+computecanada-py3-none-any.whl
Requirement already satisfied: setuptools>=41.0.0 in /localscratch/yinan.29351697.0/env/lib/python3.7/site-packages (from tensorboard<3,>=2.3.0->tensorflow_gpu==2.3.0+computecanada) (41.0.1)
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/Markdown-3.3.6+computecanada-py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/tensorboard_plugin_wit-1.8.0+computecanada-py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/google_auth_oauthlib-0.4.6+computecanada-py2.py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/Werkzeug-2.0.3+computecanada-py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/tensorboard_data_server-0.6.1+computecanada-py3-none-linux_x86_64.whl
Requirement already satisfied: requests<3,>=2.21.0 in /localscratch/yinan.29351697.0/env/lib/python3.7/site-packages (from tensorboard<3,>=2.3.0->tensorflow_gpu==2.3.0+computecanada) (2.27.1+computecanada)
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/google_auth-2.3.3+computecanada-py2.py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/pyasn1_modules-0.2.8+computecanada-py2.py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/rsa-4.8+computecanada-py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/cachetools-4.2.4+computecanada-py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/requests_oauthlib-1.3.0+computecanada-py2.py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/importlib_metadata-4.10.1+computecanada-py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/zipp-3.7.0+computecanada-py3-none-any.whl
Requirement already satisfied: typing-extensions>=3.6.4 in /localscratch/yinan.29351697.0/env/lib/python3.7/site-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard<3,>=2.3.0->tensorflow_gpu==2.3.0+computecanada) (4.0.1+computecanada)
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/pyasn1-0.4.8+computecanada-py2.py3-none-any.whl
Requirement already satisfied: urllib3<1.27,>=1.21.1 in /localscratch/yinan.29351697.0/env/lib/python3.7/site-packages (from requests<3,>=2.21.0->tensorboard<3,>=2.3.0->tensorflow_gpu==2.3.0+computecanada) (1.26.8+computecanada)
Requirement already satisfied: certifi>=2017.4.17 in /cvmfs/soft.computecanada.ca/easybuild/software/2017/Core/scipy-stack/2019a/lib/python3.7/site-packages (from requests<3,>=2.21.0->tensorboard<3,>=2.3.0->tensorflow_gpu==2.3.0+computecanada) (2018.11.29)
Requirement already satisfied: charset-normalizer~=2.0.0 in /localscratch/yinan.29351697.0/env/lib/python3.7/site-packages (from requests<3,>=2.21.0->tensorboard<3,>=2.3.0->tensorflow_gpu==2.3.0+computecanada) (2.0.12+computecanada)
Requirement already satisfied: idna<4,>=2.5 in /cvmfs/soft.computecanada.ca/easybuild/software/2017/Core/scipy-stack/2019a/lib/python3.7/site-packages (from requests<3,>=2.21.0->tensorboard<3,>=2.3.0->tensorflow_gpu==2.3.0+computecanada) (2.8)
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/oauthlib-3.1.1+computecanada-py2.py3-none-any.whl
Installing collected packages: pyasn1, zipp, rsa, pyasn1-modules, oauthlib, cachetools, requests-oauthlib, importlib-metadata, google-auth, werkzeug, tensorboard-plugin-wit, tensorboard-data-server, markdown, grpcio, google-auth-oauthlib, absl-py, wrapt, tensorflow-estimator, tensorboard, scipy, opt-einsum, keras-preprocessing, h5py, google-pasta, gast, astunparse, tensorflow-gpu
  Attempting uninstall: pyasn1
    Found existing installation: pyasn1 0.4.3
    Not uninstalling pyasn1 at /cvmfs/soft.computecanada.ca/easybuild/software/2017/Core/scipy-stack/2019a/lib/python3.7/site-packages, outside environment /localscratch/yinan.29351697.0/env
    Can't uninstall 'pyasn1'. No files were found to uninstall.
  Attempting uninstall: zipp
    Found existing installation: zipp 0.3.3
    Not uninstalling zipp at /cvmfs/soft.computecanada.ca/easybuild/software/2017/Core/scipy-stack/2019a/lib/python3.7/site-packages, outside environment /localscratch/yinan.29351697.0/env
    Can't uninstall 'zipp'. No files were found to uninstall.
  Attempting uninstall: importlib-metadata
    Found existing installation: importlib-metadata 0.8
    Not uninstalling importlib-metadata at /cvmfs/soft.computecanada.ca/easybuild/software/2017/Core/scipy-stack/2019a/lib/python3.7/site-packages, outside environment /localscratch/yinan.29351697.0/env
    Can't uninstall 'importlib-metadata'. No files were found to uninstall.
  Attempting uninstall: scipy
    Found existing installation: scipy 1.2.0
    Not uninstalling scipy at /cvmfs/soft.computecanada.ca/easybuild/software/2017/Core/scipy-stack/2019a/lib/python3.7/site-packages, outside environment /localscratch/yinan.29351697.0/env
    Can't uninstall 'scipy'. No files were found to uninstall.
Successfully installed absl-py-1.0.0+computecanada astunparse-1.6.3+computecanada cachetools-4.2.4+computecanada gast-0.3.3+computecanada google-auth-2.3.3+computecanada google-auth-oauthlib-0.4.6+computecanada google-pasta-0.2.0+computecanada grpcio-1.38.0+computecanada h5py-2.10.0+computecanada importlib-metadata-4.10.1+computecanada keras-preprocessing-1.1.2+computecanada markdown-3.3.6+computecanada oauthlib-3.1.1+computecanada opt-einsum-3.3.0+computecanada pyasn1-0.4.8+computecanada pyasn1-modules-0.2.8+computecanada requests-oauthlib-1.3.0+computecanada rsa-4.8+computecanada scipy-1.4.1+computecanada tensorboard-2.8.0+computecanada tensorboard-data-server-0.6.1+computecanada tensorboard-plugin-wit-1.8.0+computecanada tensorflow-estimator-2.3.0+computecanada tensorflow-gpu-2.3.0+computecanada werkzeug-2.0.3+computecanada wrapt-1.11.2+computecanada zipp-3.7.0+computecanada
Looking in links: /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/nix/avx2, /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/nix/generic, /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/keras-2.8.0+computecanada-py2.py3-none-any.whl
Installing collected packages: Keras
Successfully installed Keras-2.8.0+computecanada
Looking in links: /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/nix/avx2, /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/nix/generic, /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/urllib3-1.26.7+computecanada-py2.py3-none-any.whl
Installing collected packages: urllib3
  Attempting uninstall: urllib3
    Found existing installation: urllib3 1.26.8+computecanada
    Uninstalling urllib3-1.26.8+computecanada:
      Successfully uninstalled urllib3-1.26.8+computecanada
Successfully installed urllib3-1.26.7+computecanada
Looking in links: /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/nix/avx2, /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/nix/generic, /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/nltk-3.7+computecanada-py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/nltk-3.6.5+computecanada-py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/nltk-3.6.3+computecanada-py3-none-any.whl
Requirement already satisfied: regex in /localscratch/yinan.29351697.0/env/lib/python3.7/site-packages (from nltk) (2020.11.13+computecanada)
Requirement already satisfied: click in /localscratch/yinan.29351697.0/env/lib/python3.7/site-packages (from nltk) (8.0.4+computecanada)
Requirement already satisfied: joblib in /localscratch/yinan.29351697.0/env/lib/python3.7/site-packages (from nltk) (1.1.0+computecanada)
Requirement already satisfied: tqdm in /localscratch/yinan.29351697.0/env/lib/python3.7/site-packages (from nltk) (4.63.0+computecanada)
Requirement already satisfied: importlib-metadata in /localscratch/yinan.29351697.0/env/lib/python3.7/site-packages (from click->nltk) (4.10.1+computecanada)
Requirement already satisfied: zipp>=0.5 in /localscratch/yinan.29351697.0/env/lib/python3.7/site-packages (from importlib-metadata->click->nltk) (3.7.0+computecanada)
Requirement already satisfied: typing-extensions>=3.6.4 in /localscratch/yinan.29351697.0/env/lib/python3.7/site-packages (from importlib-metadata->click->nltk) (4.0.1+computecanada)
Installing collected packages: nltk
Successfully installed nltk-3.6.3+computecanada
Looking in links: /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/nix/avx2, /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/nix/generic, /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/scikit_learn-0.22.1+computecanada-cp37-cp37m-linux_x86_64.whl
Requirement already satisfied: numpy>=1.11.0 in /cvmfs/soft.computecanada.ca/easybuild/software/2017/Core/scipy-stack/2019a/lib/python3.7/site-packages (from scikit-learn==0.22.1) (1.16.0)
Requirement already satisfied: joblib>=0.11 in /localscratch/yinan.29351697.0/env/lib/python3.7/site-packages (from scikit-learn==0.22.1) (1.1.0+computecanada)
Requirement already satisfied: scipy>=0.17.0 in /localscratch/yinan.29351697.0/env/lib/python3.7/site-packages (from scikit-learn==0.22.1) (1.4.1+computecanada)
Installing collected packages: scikit-learn
Successfully installed scikit-learn-0.22.1+computecanada
Looking in links: /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/nix/avx2, /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/nix/generic, /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic
Requirement already satisfied: tokenizers==0.5.2 in /localscratch/yinan.29351697.0/env/lib/python3.7/site-packages (0.5.2+computecanada)
wandb: Appending key for api.wandb.ai to your netrc file: /home/yinan/.netrc
Starting Task
2022-03-24 06:45:24.714364: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1
[nltk_data] Downloading package stopwords to /home/yinan/nltk_data...
[nltk_data]   Package stopwords is already up-to-date!
[nltk_data] Downloading package wordnet to /home/yinan/nltk_data...
[nltk_data]   Package wordnet is already up-to-date!
wandb: Currently logged in as: yinanazhou (use `wandb login --relogin` to force relogin)
wandb: wandb version 0.12.11 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
2022-03-24 06:45:39.378255: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1
wandb: Tracking run with wandb version 0.12.5
wandb: Syncing run revived-sun-5
wandb: ⭐️ View project at https://wandb.ai/yinanazhou/xl_512_bs_8_lr_1e06_es_10_lc_True_nr_False_sr_False_stem_False_lemma_True_repeat_1_fold_1
wandb: 🚀 View run at https://wandb.ai/yinanazhou/xl_512_bs_8_lr_1e06_es_10_lc_True_nr_False_sr_False_stem_False_lemma_True_repeat_1_fold_1/runs/18z2ogd6
wandb: Run data is saved locally in /project/6002780/yinan/Thesis_MER_Lyrics/lyric-emotion/wandb/run-20220324_064537-18z2ogd6
wandb: Run `wandb offline` to turn off syncing.

Validation loss decreased (inf --> 1.433387).  Saving model ...
Validation loss decreased (1.433387 --> 1.413981).  Saving model ...
Validation loss decreased (1.413981 --> 1.397822).  Saving model ...
Validation loss decreased (1.397822 --> 1.384927).  Saving model ...
Validation loss decreased (1.384927 --> 1.374721).  Saving model ...
Validation loss decreased (1.374721 --> 1.365957).  Saving model ...
Validation loss decreased (1.365957 --> 1.358616).  Saving model ...
Validation loss decreased (1.358616 --> 1.352624).  Saving model ...
Validation loss decreased (1.352624 --> 1.347371).  Saving model ...
Validation loss decreased (1.347371 --> 1.341487).  Saving model ...
Validation loss decreased (1.341487 --> 1.335491).  Saving model ...
Validation loss decreased (1.335491 --> 1.330084).  Saving model ...
Validation loss decreased (1.330084 --> 1.324555).  Saving model ...
Validation loss decreased (1.324555 --> 1.319240).  Saving model ...
Validation loss decreased (1.319240 --> 1.314237).  Saving model ...
Validation loss decreased (1.314237 --> 1.308590).  Saving model ...
Validation loss decreased (1.308590 --> 1.303107).  Saving model ...
Validation loss decreased (1.303107 --> 1.296859).  Saving model ...
Validation loss decreased (1.296859 --> 1.290189).  Saving model ...
Validation loss decreased (1.290189 --> 1.282792).  Saving model ...
Validation loss decreased (1.282792 --> 1.275819).  Saving model ...
Validation loss decreased (1.275819 --> 1.268752).  Saving model ...
Validation loss decreased (1.268752 --> 1.262562).  Saving model ...
Validation loss decreased (1.262562 --> 1.255516).  Saving model ...
Validation loss decreased (1.255516 --> 1.247164).  Saving model ...
Validation loss decreased (1.247164 --> 1.239761).  Saving model ...
Validation loss decreased (1.239761 --> 1.233390).  Saving model ...
Validation loss decreased (1.233390 --> 1.226658).  Saving model ...
Validation loss decreased (1.226658 --> 1.220915).  Saving model ...
Validation loss decreased (1.220915 --> 1.215830).  Saving model ...
Validation loss decreased (1.215830 --> 1.207669).  Saving model ...
Validation loss decreased (1.207669 --> 1.203214).  Saving model ...
Validation loss decreased (1.203214 --> 1.200058).  Saving model ...
Validation loss decreased (1.200058 --> 1.193948).  Saving model ...
Validation loss decreased (1.193948 --> 1.186832).  Saving model ...
Validation loss decreased (1.186832 --> 1.183043).  Saving model ...
Validation loss decreased (1.183043 --> 1.175233).  Saving model ...
Validation loss decreased (1.175233 --> 1.170703).  Saving model ...
Validation loss decreased (1.170703 --> 1.168870).  Saving model ...
Validation loss decreased (1.168870 --> 1.166053).  Saving model ...
Validation loss decreased (1.166053 --> 1.161387).  Saving model ...
Validation loss decreased (1.161387 --> 1.154649).  Saving model ...
Validation loss decreased (1.154649 --> 1.151328).  Saving model ...
Validation loss decreased (1.151328 --> 1.147662).  Saving model ...
Validation loss decreased (1.147662 --> 1.144545).  Saving model ...
Validation loss decreased (1.144545 --> 1.139429).  Saving model ...
Validation loss decreased (1.139429 --> 1.135583).  Saving model ...
Validation loss decreased (1.135583 --> 1.132313).  Saving model ...
Validation loss decreased (1.132313 --> 1.126347).  Saving model ...
Validation loss decreased (1.126347 --> 1.123219).  Saving model ...
Validation loss decreased (1.123219 --> 1.117370).  Saving model ...
Validation loss decreased (1.117370 --> 1.114682).  Saving model ...
Validation loss decreased (1.114682 --> 1.112565).  Saving model ...
Validation loss decreased (1.112565 --> 1.108434).  Saving model ...
EarlyStopping counter: 1 out of 10.0
Validation loss decreased (1.108434 --> 1.104441).  Saving model ...
Validation loss decreased (1.104441 --> 1.099149).  Saving model ...
Validation loss decreased (1.099149 --> 1.093575).  Saving model ...
Validation loss decreased (1.093575 --> 1.088544).  Saving model ...
EarlyStopping counter: 1 out of 10.0
Validation loss decreased (1.088544 --> 1.088525).  Saving model ...
Validation loss decreased (1.088525 --> 1.084370).  Saving model ...
Validation loss decreased (1.084370 --> 1.080092).  Saving model ...
Validation loss decreased (1.080092 --> 1.076291).  Saving model ...
Validation loss decreased (1.076291 --> 1.076033).  Saving model ...
Validation loss decreased (1.076033 --> 1.072529).  Saving model ...
Validation loss decreased (1.072529 --> 1.070793).  Saving model ...
Validation loss decreased (1.070793 --> 1.066482).  Saving model ...
Validation loss decreased (1.066482 --> 1.062048).  Saving model ...
Validation loss decreased (1.062048 --> 1.059040).  Saving model ...
Validation loss decreased (1.059040 --> 1.055943).  Saving model ...
Validation loss decreased (1.055943 --> 1.053744).  Saving model ...
Validation loss decreased (1.053744 --> 1.053065).  Saving model ...
Validation loss decreased (1.053065 --> 1.049087).  Saving model ...
Validation loss decreased (1.049087 --> 1.046876).  Saving model ...
Validation loss decreased (1.046876 --> 1.045297).  Saving model ...
Validation loss decreased (1.045297 --> 1.042906).  Saving model ...
Validation loss decreased (1.042906 --> 1.040165).  Saving model ...
Validation loss decreased (1.040165 --> 1.037659).  Saving model ...
Validation loss decreased (1.037659 --> 1.034924).  Saving model ...
EarlyStopping counter: 1 out of 10.0
EarlyStopping counter: 2 out of 10.0
EarlyStopping counter: 3 out of 10.0
Validation loss decreased (1.034924 --> 1.032577).  Saving model ...
Validation loss decreased (1.032577 --> 1.028134).  Saving model ...
Validation loss decreased (1.028134 --> 1.025002).  Saving model ...
Validation loss decreased (1.025002 --> 1.021671).  Saving model ...
EarlyStopping counter: 1 out of 10.0
Validation loss decreased (1.021671 --> 1.021181).  Saving model ...
Validation loss decreased (1.021181 --> 1.019643).  Saving model ...
Validation loss decreased (1.019643 --> 1.015952).  Saving model ...
Validation loss decreased (1.015952 --> 1.011357).  Saving model ...
EarlyStopping counter: 1 out of 10.0
EarlyStopping counter: 2 out of 10.0
EarlyStopping counter: 3 out of 10.0
Validation loss decreased (1.011357 --> 1.010495).  Saving model ...
Validation loss decreased (1.010495 --> 1.009749).  Saving model ...
Validation loss decreased (1.009749 --> 1.006114).  Saving model ...
EarlyStopping counter: 1 out of 10.0
Validation loss decreased (1.006114 --> 1.005783).  Saving model ...
Validation loss decreased (1.005783 --> 1.003774).  Saving model ...
EarlyStopping counter: 1 out of 10.0
EarlyStopping counter: 2 out of 10.0
EarlyStopping counter: 3 out of 10.0
Validation loss decreased (1.003774 --> 1.002238).  Saving model ...
Validation loss decreased (1.002238 --> 0.998459).  Saving model ...
EarlyStopping counter: 1 out of 10.0
EarlyStopping counter: 2 out of 10.0
Validation loss decreased (0.998459 --> 0.996030).  Saving model ...
Validation loss decreased (0.996030 --> 0.992690).  Saving model ...
Validation loss decreased (0.992690 --> 0.991956).  Saving model ...
EarlyStopping counter: 1 out of 10.0
EarlyStopping counter: 2 out of 10.0
EarlyStopping counter: 3 out of 10.0
EarlyStopping counter: 4 out of 10.0
EarlyStopping counter: 5 out of 10.0
Validation loss decreased (0.991956 --> 0.990560).  Saving model ...
Validation loss decreased (0.990560 --> 0.989200).  Saving model ...
EarlyStopping counter: 1 out of 10.0
Validation loss decreased (0.989200 --> 0.986148).  Saving model ...
Validation loss decreased (0.986148 --> 0.985434).  Saving model ...
Validation loss decreased (0.985434 --> 0.984380).  Saving model ...
Validation loss decreased (0.984380 --> 0.982830).  Saving model ...
EarlyStopping counter: 1 out of 10.0
Validation loss decreased (0.982830 --> 0.982290).  Saving model ...
EarlyStopping counter: 1 out of 10.0
EarlyStopping counter: 2 out of 10.0
EarlyStopping counter: 3 out of 10.0
EarlyStopping counter: 4 out of 10.0
EarlyStopping counter: 5 out of 10.0
EarlyStopping counter: 6 out of 10.0
EarlyStopping counter: 7 out of 10.0
Validation loss decreased (0.982290 --> 0.982124).  Saving model ...
Validation loss decreased (0.982124 --> 0.979782).  Saving model ...
EarlyStopping counter: 1 out of 10.0
EarlyStopping counter: 2 out of 10.0
EarlyStopping counter: 3 out of 10.0
EarlyStopping counter: 4 out of 10.0
EarlyStopping counter: 5 out of 10.0
EarlyStopping counter: 6 out of 10.0
EarlyStopping counter: 7 out of 10.0
EarlyStopping counter: 8 out of 10.0
EarlyStopping counter: 9 out of 10.0
EarlyStopping counter: 10 out of 10.0
/localscratch/yinan.29351697.0/env/lib/python3.7/site-packages/torch/nn/functional.py:1794: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.
  warnings.warn("nn.functional.tanh is deprecated. Use torch.tanh instead.")
/localscratch/yinan.29351697.0/env/lib/python3.7/site-packages/transformers/optimization.py:155: UserWarning: This overload of add_ is deprecated:
	add_(Number alpha, Tensor other)
Consider using one of the following signatures instead:
	add_(Tensor other, *, Number alpha) (Triggered internally at  ../torch/csrc/utils/python_arg_parser.cpp:1025.)
  exp_avg.mul_(beta1).add_(1.0 - beta1, grad)
wandb: Waiting for W&B process to finish, PID 43949... (success).
wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: \ 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: | 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: / 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: \ 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: | 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: / 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: \ 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: | 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: / 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: \ 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb:                                                                                
wandb: Run history:
wandb:     e_F1 ▁▂▃▄▅▆▆▆▆▆▆▆▆▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇████████████
wandb:   e_loss ██▇▇▆▆▆▅▅▄▄▄▄▃▃▃▃▃▂▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:     t_F1 ▁▁▂▃▃▄▄▅▅▅▅▅▅▆▆▅▆▆▆▆▆▇▆▇▇▇▇▇▇▇█▇▇█▇▇████
wandb:   t_loss ██▇▇▇▆▆▆▆▅▅▅▅▄▄▄▄▄▃▃▃▃▃▃▂▂▂▂▂▂▂▂▂▂▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:     e_F1 59.99516
wandb:   e_loss 0.98373
wandb:     t_F1 74.65099
wandb:   t_loss 0.71104
wandb: 
wandb: Synced 4 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Synced revived-sun-5: https://wandb.ai/yinanazhou/xl_512_bs_8_lr_1e06_es_10_lc_True_nr_False_sr_False_stem_False_lemma_True_repeat_1_fold_1/runs/18z2ogd6
wandb: Find logs at: ./wandb/run-20220324_064537-18z2ogd6/logs/debug.log
wandb: 

wandb: wandb version 0.12.11 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
2022-03-24 08:17:59.967509: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1
wandb: Tracking run with wandb version 0.12.5
wandb: Syncing run dainty-sunset-5
wandb: ⭐️ View project at https://wandb.ai/yinanazhou/xl_512_bs_8_lr_1e06_es_10_lc_True_nr_False_sr_False_stem_False_lemma_True_repeat_1_fold_2
wandb: 🚀 View run at https://wandb.ai/yinanazhou/xl_512_bs_8_lr_1e06_es_10_lc_True_nr_False_sr_False_stem_False_lemma_True_repeat_1_fold_2/runs/3hdgzgn1
wandb: Run data is saved locally in /project/6002780/yinan/Thesis_MER_Lyrics/lyric-emotion/wandb/run-20220324_081757-3hdgzgn1
wandb: Run `wandb offline` to turn off syncing.

Validation loss decreased (inf --> 1.637617).  Saving model ...
Validation loss decreased (1.637617 --> 1.569711).  Saving model ...
Validation loss decreased (1.569711 --> 1.517678).  Saving model ...
Validation loss decreased (1.517678 --> 1.481642).  Saving model ...
Validation loss decreased (1.481642 --> 1.451533).  Saving model ...
Validation loss decreased (1.451533 --> 1.430918).  Saving model ...
Validation loss decreased (1.430918 --> 1.415539).  Saving model ...
Validation loss decreased (1.415539 --> 1.404095).  Saving model ...
Validation loss decreased (1.404095 --> 1.395169).  Saving model ...
Validation loss decreased (1.395169 --> 1.387975).  Saving model ...
Validation loss decreased (1.387975 --> 1.381084).  Saving model ...
Validation loss decreased (1.381084 --> 1.374122).  Saving model ...
Validation loss decreased (1.374122 --> 1.367167).  Saving model ...
Validation loss decreased (1.367167 --> 1.360463).  Saving model ...
Validation loss decreased (1.360463 --> 1.352800).  Saving model ...
Validation loss decreased (1.352800 --> 1.346209).  Saving model ...
Validation loss decreased (1.346209 --> 1.339175).  Saving model ...
Validation loss decreased (1.339175 --> 1.333028).  Saving model ...
Validation loss decreased (1.333028 --> 1.326323).  Saving model ...
Validation loss decreased (1.326323 --> 1.318548).  Saving model ...
Validation loss decreased (1.318548 --> 1.309664).  Saving model ...
Validation loss decreased (1.309664 --> 1.299358).  Saving model ...
Validation loss decreased (1.299358 --> 1.289752).  Saving model ...
Validation loss decreased (1.289752 --> 1.282007).  Saving model ...
Validation loss decreased (1.282007 --> 1.273056).  Saving model ...
Validation loss decreased (1.273056 --> 1.264568).  Saving model ...
Validation loss decreased (1.264568 --> 1.255350).  Saving model ...
Validation loss decreased (1.255350 --> 1.245576).  Saving model ...
Validation loss decreased (1.245576 --> 1.237645).  Saving model ...
Validation loss decreased (1.237645 --> 1.229916).  Saving model ...
Validation loss decreased (1.229916 --> 1.222482).  Saving model ...
Validation loss decreased (1.222482 --> 1.214064).  Saving model ...
Validation loss decreased (1.214064 --> 1.206682).  Saving model ...
Validation loss decreased (1.206682 --> 1.199418).  Saving model ...
Validation loss decreased (1.199418 --> 1.191753).  Saving model ...
Validation loss decreased (1.191753 --> 1.184694).  Saving model ...
Validation loss decreased (1.184694 --> 1.177800).  Saving model ...
Validation loss decreased (1.177800 --> 1.170446).  Saving model ...
Validation loss decreased (1.170446 --> 1.163320).  Saving model ...
Validation loss decreased (1.163320 --> 1.157689).  Saving model ...
Validation loss decreased (1.157689 --> 1.151255).  Saving model ...
Validation loss decreased (1.151255 --> 1.145451).  Saving model ...
Validation loss decreased (1.145451 --> 1.138705).  Saving model ...
Validation loss decreased (1.138705 --> 1.133162).  Saving model ...
Validation loss decreased (1.133162 --> 1.126811).  Saving model ...
Validation loss decreased (1.126811 --> 1.123277).  Saving model ...
Validation loss decreased (1.123277 --> 1.115582).  Saving model ...
Validation loss decreased (1.115582 --> 1.110202).  Saving model ...
Validation loss decreased (1.110202 --> 1.105627).  Saving model ...
Validation loss decreased (1.105627 --> 1.099573).  Saving model ...
Validation loss decreased (1.099573 --> 1.092196).  Saving model ...
Validation loss decreased (1.092196 --> 1.089481).  Saving model ...
Validation loss decreased (1.089481 --> 1.085281).  Saving model ...
Validation loss decreased (1.085281 --> 1.079250).  Saving model ...
Validation loss decreased (1.079250 --> 1.073706).  Saving model ...
Validation loss decreased (1.073706 --> 1.068999).  Saving model ...
Validation loss decreased (1.068999 --> 1.064306).  Saving model ...
Validation loss decreased (1.064306 --> 1.058283).  Saving model ...
Validation loss decreased (1.058283 --> 1.055811).  Saving model ...
Validation loss decreased (1.055811 --> 1.053210).  Saving model ...
Validation loss decreased (1.053210 --> 1.051516).  Saving model ...
Validation loss decreased (1.051516 --> 1.049545).  Saving model ...
Validation loss decreased (1.049545 --> 1.042098).  Saving model ...
Validation loss decreased (1.042098 --> 1.037204).  Saving model ...
Validation loss decreased (1.037204 --> 1.036592).  Saving model ...
Validation loss decreased (1.036592 --> 1.032813).  Saving model ...
Validation loss decreased (1.032813 --> 1.027213).  Saving model ...
Validation loss decreased (1.027213 --> 1.023811).  Saving model ...
Validation loss decreased (1.023811 --> 1.018100).  Saving model ...
Validation loss decreased (1.018100 --> 1.016113).  Saving model ...
Validation loss decreased (1.016113 --> 1.011980).  Saving model ...
Validation loss decreased (1.011980 --> 1.011124).  Saving model ...
Validation loss decreased (1.011124 --> 1.007389).  Saving model ...
Validation loss decreased (1.007389 --> 1.002698).  Saving model ...
Validation loss decreased (1.002698 --> 1.000930).  Saving model ...
Validation loss decreased (1.000930 --> 0.996922).  Saving model ...
Validation loss decreased (0.996922 --> 0.993681).  Saving model ...
Validation loss decreased (0.993681 --> 0.993175).  Saving model ...
Validation loss decreased (0.993175 --> 0.990607).  Saving model ...
Validation loss decreased (0.990607 --> 0.988494).  Saving model ...
Validation loss decreased (0.988494 --> 0.986232).  Saving model ...
Validation loss decreased (0.986232 --> 0.982886).  Saving model ...
Validation loss decreased (0.982886 --> 0.981323).  Saving model ...
Validation loss decreased (0.981323 --> 0.978591).  Saving model ...
Validation loss decreased (0.978591 --> 0.975818).  Saving model ...
EarlyStopping counter: 1 out of 10.0
Validation loss decreased (0.975818 --> 0.973748).  Saving model ...
Validation loss decreased (0.973748 --> 0.972569).  Saving model ...
Validation loss decreased (0.972569 --> 0.971096).  Saving model ...
Validation loss decreased (0.971096 --> 0.968443).  Saving model ...
EarlyStopping counter: 1 out of 10.0
Validation loss decreased (0.968443 --> 0.967268).  Saving model ...
Validation loss decreased (0.967268 --> 0.967132).  Saving model ...
Validation loss decreased (0.967132 --> 0.962529).  Saving model ...
Validation loss decreased (0.962529 --> 0.960666).  Saving model ...
Validation loss decreased (0.960666 --> 0.958585).  Saving model ...
Validation loss decreased (0.958585 --> 0.956729).  Saving model ...
Validation loss decreased (0.956729 --> 0.956077).  Saving model ...
Validation loss decreased (0.956077 --> 0.953676).  Saving model ...
Validation loss decreased (0.953676 --> 0.952287).  Saving model ...
EarlyStopping counter: 1 out of 10.0
EarlyStopping counter: 2 out of 10.0
EarlyStopping counter: 3 out of 10.0
EarlyStopping counter: 4 out of 10.0
Validation loss decreased (0.952287 --> 0.952191).  Saving model ...
Validation loss decreased (0.952191 --> 0.950223).  Saving model ...
Validation loss decreased (0.950223 --> 0.950220).  Saving model ...
Validation loss decreased (0.950220 --> 0.950003).  Saving model ...
Validation loss decreased (0.950003 --> 0.949670).  Saving model ...
EarlyStopping counter: 1 out of 10.0
Validation loss decreased (0.949670 --> 0.949658).  Saving model ...
Validation loss decreased (0.949658 --> 0.949193).  Saving model ...
EarlyStopping counter: 1 out of 10.0
EarlyStopping counter: 2 out of 10.0
Validation loss decreased (0.949193 --> 0.948504).  Saving model ...
Validation loss decreased (0.948504 --> 0.945773).  Saving model ...
Validation loss decreased (0.945773 --> 0.944670).  Saving model ...
EarlyStopping counter: 1 out of 10.0
EarlyStopping counter: 2 out of 10.0
EarlyStopping counter: 3 out of 10.0
EarlyStopping counter: 4 out of 10.0
EarlyStopping counter: 5 out of 10.0
EarlyStopping counter: 6 out of 10.0
EarlyStopping counter: 7 out of 10.0
EarlyStopping counter: 8 out of 10.0
EarlyStopping counter: 9 out of 10.0
EarlyStopping counter: 10 out of 10.0
/localscratch/yinan.29351697.0/env/lib/python3.7/site-packages/torch/nn/functional.py:1794: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.
  warnings.warn("nn.functional.tanh is deprecated. Use torch.tanh instead.")
wandb: Waiting for W&B process to finish, PID 48914... (success).
wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: \ 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: | 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: / 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: \ 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: | 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: / 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: \ 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: | 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: / 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: \ 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: | 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb:                                                                                
wandb: Run history:
wandb:     e_F1 ▁▁▂▃▄▅▅▆▆▇▇▇▇▇▇▇▇▇▇█▇███████████████████
wandb:   e_loss █▆▆▅▅▅▅▄▄▄▄▃▃▃▃▃▂▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:     t_F1 ▁▂▂▃▃▃▄▄▄▄▄▅▅▅▆▆▆▆▆▆▇▇▇▇▇▇▇▇▇▇▇▇████████
wandb:   t_loss █▇▆▆▆▆▅▅▅▅▅▅▅▄▄▄▄▄▃▃▃▃▃▃▂▃▂▂▂▂▂▂▂▂▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:     e_F1 59.82529
wandb:   e_loss 0.9492
wandb:     t_F1 70.95621
wandb:   t_loss 0.74282
wandb: 
wandb: Synced 4 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Synced dainty-sunset-5: https://wandb.ai/yinanazhou/xl_512_bs_8_lr_1e06_es_10_lc_True_nr_False_sr_False_stem_False_lemma_True_repeat_1_fold_2/runs/3hdgzgn1
wandb: Find logs at: ./wandb/run-20220324_081757-3hdgzgn1/logs/debug.log
wandb: 

wandb: wandb version 0.12.11 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
2022-03-24 09:40:18.552324: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1
wandb: Tracking run with wandb version 0.12.5
wandb: Syncing run gallant-sky-5
wandb: ⭐️ View project at https://wandb.ai/yinanazhou/xl_512_bs_8_lr_1e06_es_10_lc_True_nr_False_sr_False_stem_False_lemma_True_repeat_2_fold_1
wandb: 🚀 View run at https://wandb.ai/yinanazhou/xl_512_bs_8_lr_1e06_es_10_lc_True_nr_False_sr_False_stem_False_lemma_True_repeat_2_fold_1/runs/26rg2evo
wandb: Run data is saved locally in /project/6002780/yinan/Thesis_MER_Lyrics/lyric-emotion/wandb/run-20220324_094015-26rg2evo
wandb: Run `wandb offline` to turn off syncing.

Validation loss decreased (inf --> 1.437048).  Saving model ...
Validation loss decreased (1.437048 --> 1.418369).  Saving model ...
Validation loss decreased (1.418369 --> 1.403020).  Saving model ...
Validation loss decreased (1.403020 --> 1.390938).  Saving model ...
Validation loss decreased (1.390938 --> 1.381492).  Saving model ...
Validation loss decreased (1.381492 --> 1.373631).  Saving model ...
Validation loss decreased (1.373631 --> 1.366051).  Saving model ...
Validation loss decreased (1.366051 --> 1.360034).  Saving model ...
Validation loss decreased (1.360034 --> 1.354503).  Saving model ...
Validation loss decreased (1.354503 --> 1.349172).  Saving model ...
Validation loss decreased (1.349172 --> 1.343556).  Saving model ...
Validation loss decreased (1.343556 --> 1.338175).  Saving model ...
Validation loss decreased (1.338175 --> 1.332215).  Saving model ...
Validation loss decreased (1.332215 --> 1.327251).  Saving model ...
Validation loss decreased (1.327251 --> 1.322155).  Saving model ...
Validation loss decreased (1.322155 --> 1.315851).  Saving model ...
Validation loss decreased (1.315851 --> 1.310039).  Saving model ...
Validation loss decreased (1.310039 --> 1.303581).  Saving model ...
Validation loss decreased (1.303581 --> 1.297680).  Saving model ...
Validation loss decreased (1.297680 --> 1.290901).  Saving model ...
Validation loss decreased (1.290901 --> 1.284077).  Saving model ...
Validation loss decreased (1.284077 --> 1.276513).  Saving model ...
Validation loss decreased (1.276513 --> 1.268677).  Saving model ...
Validation loss decreased (1.268677 --> 1.261140).  Saving model ...
Validation loss decreased (1.261140 --> 1.255531).  Saving model ...
Validation loss decreased (1.255531 --> 1.249760).  Saving model ...
Validation loss decreased (1.249760 --> 1.243560).  Saving model ...
Validation loss decreased (1.243560 --> 1.237974).  Saving model ...
Validation loss decreased (1.237974 --> 1.231415).  Saving model ...
Validation loss decreased (1.231415 --> 1.224477).  Saving model ...
Validation loss decreased (1.224477 --> 1.217676).  Saving model ...
Validation loss decreased (1.217676 --> 1.210981).  Saving model ...
Validation loss decreased (1.210981 --> 1.206487).  Saving model ...
Validation loss decreased (1.206487 --> 1.200468).  Saving model ...
Validation loss decreased (1.200468 --> 1.194617).  Saving model ...
Validation loss decreased (1.194617 --> 1.189555).  Saving model ...
Validation loss decreased (1.189555 --> 1.184155).  Saving model ...
Validation loss decreased (1.184155 --> 1.177746).  Saving model ...
Validation loss decreased (1.177746 --> 1.172045).  Saving model ...
Validation loss decreased (1.172045 --> 1.166595).  Saving model ...
Validation loss decreased (1.166595 --> 1.161519).  Saving model ...
Validation loss decreased (1.161519 --> 1.155543).  Saving model ...
Validation loss decreased (1.155543 --> 1.149725).  Saving model ...
Validation loss decreased (1.149725 --> 1.144333).  Saving model ...
Validation loss decreased (1.144333 --> 1.138982).  Saving model ...
Validation loss decreased (1.138982 --> 1.134487).  Saving model ...
Validation loss decreased (1.134487 --> 1.129537).  Saving model ...
Validation loss decreased (1.129537 --> 1.124406).  Saving model ...
Validation loss decreased (1.124406 --> 1.119564).  Saving model ...
Validation loss decreased (1.119564 --> 1.114420).  Saving model ...
Validation loss decreased (1.114420 --> 1.108849).  Saving model ...
Validation loss decreased (1.108849 --> 1.103893).  Saving model ...
Validation loss decreased (1.103893 --> 1.101589).  Saving model ...
Validation loss decreased (1.101589 --> 1.097265).  Saving model ...
Validation loss decreased (1.097265 --> 1.091609).  Saving model ...
Validation loss decreased (1.091609 --> 1.087555).  Saving model ...
Validation loss decreased (1.087555 --> 1.084143).  Saving model ...
Validation loss decreased (1.084143 --> 1.078821).  Saving model ...
Validation loss decreased (1.078821 --> 1.074864).  Saving model ...
Validation loss decreased (1.074864 --> 1.071371).  Saving model ...
Validation loss decreased (1.071371 --> 1.067720).  Saving model ...
Validation loss decreased (1.067720 --> 1.064270).  Saving model ...
Validation loss decreased (1.064270 --> 1.059624).  Saving model ...
Validation loss decreased (1.059624 --> 1.057027).  Saving model ...
Validation loss decreased (1.057027 --> 1.052478).  Saving model ...
Validation loss decreased (1.052478 --> 1.049077).  Saving model ...
Validation loss decreased (1.049077 --> 1.044327).  Saving model ...
Validation loss decreased (1.044327 --> 1.042608).  Saving model ...
Validation loss decreased (1.042608 --> 1.038998).  Saving model ...
Validation loss decreased (1.038998 --> 1.035164).  Saving model ...
Validation loss decreased (1.035164 --> 1.032672).  Saving model ...
Validation loss decreased (1.032672 --> 1.030601).  Saving model ...
Validation loss decreased (1.030601 --> 1.028998).  Saving model ...
Validation loss decreased (1.028998 --> 1.026120).  Saving model ...
Validation loss decreased (1.026120 --> 1.023560).  Saving model ...
Validation loss decreased (1.023560 --> 1.020979).  Saving model ...
Validation loss decreased (1.020979 --> 1.019806).  Saving model ...
Validation loss decreased (1.019806 --> 1.017987).  Saving model ...
Validation loss decreased (1.017987 --> 1.014303).  Saving model ...
Validation loss decreased (1.014303 --> 1.011155).  Saving model ...
Validation loss decreased (1.011155 --> 1.010068).  Saving model ...
Validation loss decreased (1.010068 --> 1.008360).  Saving model ...
Validation loss decreased (1.008360 --> 1.005768).  Saving model ...
Validation loss decreased (1.005768 --> 1.004706).  Saving model ...
Validation loss decreased (1.004706 --> 1.004668).  Saving model ...
Validation loss decreased (1.004668 --> 1.002985).  Saving model ...
Validation loss decreased (1.002985 --> 1.000414).  Saving model ...
Validation loss decreased (1.000414 --> 0.998953).  Saving model ...
Validation loss decreased (0.998953 --> 0.995742).  Saving model ...
EarlyStopping counter: 1 out of 10.0
Validation loss decreased (0.995742 --> 0.994968).  Saving model ...
Validation loss decreased (0.994968 --> 0.992247).  Saving model ...
Validation loss decreased (0.992247 --> 0.990365).  Saving model ...
Validation loss decreased (0.990365 --> 0.988408).  Saving model ...
Validation loss decreased (0.988408 --> 0.987237).  Saving model ...
EarlyStopping counter: 1 out of 10.0
Validation loss decreased (0.987237 --> 0.986176).  Saving model ...
Validation loss decreased (0.986176 --> 0.984082).  Saving model ...
Validation loss decreased (0.984082 --> 0.982046).  Saving model ...
Validation loss decreased (0.982046 --> 0.980907).  Saving model ...
Validation loss decreased (0.980907 --> 0.980088).  Saving model ...
Validation loss decreased (0.980088 --> 0.979719).  Saving model ...
Validation loss decreased (0.979719 --> 0.977835).  Saving model ...
Validation loss decreased (0.977835 --> 0.977716).  Saving model ...
Validation loss decreased (0.977716 --> 0.976041).  Saving model ...
EarlyStopping counter: 1 out of 10.0
Validation loss decreased (0.976041 --> 0.974163).  Saving model ...
Validation loss decreased (0.974163 --> 0.973355).  Saving model ...
EarlyStopping counter: 1 out of 10.0
Validation loss decreased (0.973355 --> 0.972487).  Saving model ...
Validation loss decreased (0.972487 --> 0.971558).  Saving model ...
EarlyStopping counter: 1 out of 10.0
Validation loss decreased (0.971558 --> 0.971505).  Saving model ...
EarlyStopping counter: 1 out of 10.0
Validation loss decreased (0.971505 --> 0.970326).  Saving model ...
Validation loss decreased (0.970326 --> 0.969137).  Saving model ...
EarlyStopping counter: 1 out of 10.0
EarlyStopping counter: 2 out of 10.0
EarlyStopping counter: 3 out of 10.0
Validation loss decreased (0.969137 --> 0.968991).  Saving model ...
EarlyStopping counter: 1 out of 10.0
EarlyStopping counter: 2 out of 10.0
EarlyStopping counter: 3 out of 10.0
EarlyStopping counter: 4 out of 10.0
Validation loss decreased (0.968991 --> 0.968492).  Saving model ...
Validation loss decreased (0.968492 --> 0.968420).  Saving model ...
EarlyStopping counter: 1 out of 10.0
EarlyStopping counter: 2 out of 10.0
EarlyStopping counter: 3 out of 10.0
EarlyStopping counter: 4 out of 10.0
EarlyStopping counter: 5 out of 10.0
EarlyStopping counter: 6 out of 10.0
EarlyStopping counter: 7 out of 10.0
Validation loss decreased (0.968420 --> 0.968354).  Saving model ...
EarlyStopping counter: 1 out of 10.0
EarlyStopping counter: 2 out of 10.0
EarlyStopping counter: 3 out of 10.0
EarlyStopping counter: 4 out of 10.0
EarlyStopping counter: 5 out of 10.0
EarlyStopping counter: 6 out of 10.0
EarlyStopping counter: 7 out of 10.0
EarlyStopping counter: 8 out of 10.0
EarlyStopping counter: 9 out of 10.0
EarlyStopping counter: 10 out of 10.0
/localscratch/yinan.29351697.0/env/lib/python3.7/site-packages/torch/nn/functional.py:1794: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.
  warnings.warn("nn.functional.tanh is deprecated. Use torch.tanh instead.")
wandb: Waiting for W&B process to finish, PID 53309... (success).
wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: \ 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: | 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: / 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: \ 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: | 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: / 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: \ 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: | 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: / 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: \ 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb:                                                                                
wandb: Run history:
wandb:     e_F1 ▁▂▃▄▄▄▄▅▅▆▆▆▆▆▇▇▇▇▇▇▇▇▇▇▇▇▇▇████████████
wandb:   e_loss ██▇▇▆▆▆▅▅▅▄▄▄▃▃▃▃▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:     t_F1 ▁▁▂▂▃▃▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇▇█▇▇█▇▇▇███████
wandb:   t_loss ██▇▇▇▇▇▆▆▆▅▅▅▅▅▄▄▄▄▄▃▃▃▃▃▃▂▂▂▂▂▂▂▂▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:     e_F1 62.66072
wandb:   e_loss 0.97479
wandb:     t_F1 72.55894
wandb:   t_loss 0.69293
wandb: 
wandb: Synced 4 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Synced gallant-sky-5: https://wandb.ai/yinanazhou/xl_512_bs_8_lr_1e06_es_10_lc_True_nr_False_sr_False_stem_False_lemma_True_repeat_2_fold_1/runs/26rg2evo
wandb: Find logs at: ./wandb/run-20220324_094015-26rg2evo/logs/debug.log
wandb: 

wandb: wandb version 0.12.11 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
2022-03-24 11:15:32.750874: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1
wandb: Tracking run with wandb version 0.12.5
wandb: Syncing run prime-feather-4
wandb: ⭐️ View project at https://wandb.ai/yinanazhou/xl_512_bs_8_lr_1e06_es_10_lc_True_nr_False_sr_False_stem_False_lemma_True_repeat_2_fold_2
wandb: 🚀 View run at https://wandb.ai/yinanazhou/xl_512_bs_8_lr_1e06_es_10_lc_True_nr_False_sr_False_stem_False_lemma_True_repeat_2_fold_2/runs/e6jggyuv
wandb: Run data is saved locally in /project/6002780/yinan/Thesis_MER_Lyrics/lyric-emotion/wandb/run-20220324_111530-e6jggyuv
wandb: Run `wandb offline` to turn off syncing.

Validation loss decreased (inf --> 1.466987).  Saving model ...
Validation loss decreased (1.466987 --> 1.440327).  Saving model ...
Validation loss decreased (1.440327 --> 1.419311).  Saving model ...
Validation loss decreased (1.419311 --> 1.402520).  Saving model ...
Validation loss decreased (1.402520 --> 1.389084).  Saving model ...
Validation loss decreased (1.389084 --> 1.379700).  Saving model ...
Validation loss decreased (1.379700 --> 1.371661).  Saving model ...
Validation loss decreased (1.371661 --> 1.365032).  Saving model ...
Validation loss decreased (1.365032 --> 1.358195).  Saving model ...
Validation loss decreased (1.358195 --> 1.352566).  Saving model ...
Validation loss decreased (1.352566 --> 1.347515).  Saving model ...
Validation loss decreased (1.347515 --> 1.342107).  Saving model ...
Validation loss decreased (1.342107 --> 1.337210).  Saving model ...
Validation loss decreased (1.337210 --> 1.331704).  Saving model ...
Validation loss decreased (1.331704 --> 1.326077).  Saving model ...
Validation loss decreased (1.326077 --> 1.321030).  Saving model ...
Validation loss decreased (1.321030 --> 1.315623).  Saving model ...
Validation loss decreased (1.315623 --> 1.309652).  Saving model ...
Validation loss decreased (1.309652 --> 1.303311).  Saving model ...
Validation loss decreased (1.303311 --> 1.296617).  Saving model ...
Validation loss decreased (1.296617 --> 1.290435).  Saving model ...
Validation loss decreased (1.290435 --> 1.282831).  Saving model ...
Validation loss decreased (1.282831 --> 1.275973).  Saving model ...
Validation loss decreased (1.275973 --> 1.268967).  Saving model ...
Validation loss decreased (1.268967 --> 1.260259).  Saving model ...
Validation loss decreased (1.260259 --> 1.252904).  Saving model ...
Validation loss decreased (1.252904 --> 1.245437).  Saving model ...
Validation loss decreased (1.245437 --> 1.239582).  Saving model ...
Validation loss decreased (1.239582 --> 1.232262).  Saving model ...
Validation loss decreased (1.232262 --> 1.224948).  Saving model ...
Validation loss decreased (1.224948 --> 1.215207).  Saving model ...
Validation loss decreased (1.215207 --> 1.206894).  Saving model ...
Validation loss decreased (1.206894 --> 1.199584).  Saving model ...
Validation loss decreased (1.199584 --> 1.192288).  Saving model ...
Validation loss decreased (1.192288 --> 1.183876).  Saving model ...
Validation loss decreased (1.183876 --> 1.178917).  Saving model ...
Validation loss decreased (1.178917 --> 1.171666).  Saving model ...
Validation loss decreased (1.171666 --> 1.164231).  Saving model ...
Validation loss decreased (1.164231 --> 1.154600).  Saving model ...
Validation loss decreased (1.154600 --> 1.147239).  Saving model ...
Validation loss decreased (1.147239 --> 1.141590).  Saving model ...
Validation loss decreased (1.141590 --> 1.135205).  Saving model ...
Validation loss decreased (1.135205 --> 1.130532).  Saving model ...
Validation loss decreased (1.130532 --> 1.125515).  Saving model ...
Validation loss decreased (1.125515 --> 1.117653).  Saving model ...
Validation loss decreased (1.117653 --> 1.114574).  Saving model ...
Validation loss decreased (1.114574 --> 1.110885).  Saving model ...
Validation loss decreased (1.110885 --> 1.105317).  Saving model ...
Validation loss decreased (1.105317 --> 1.098037).  Saving model ...
Validation loss decreased (1.098037 --> 1.092598).  Saving model ...
Validation loss decreased (1.092598 --> 1.089774).  Saving model ...
Validation loss decreased (1.089774 --> 1.085217).  Saving model ...
Validation loss decreased (1.085217 --> 1.080832).  Saving model ...
Validation loss decreased (1.080832 --> 1.078159).  Saving model ...
Validation loss decreased (1.078159 --> 1.073714).  Saving model ...
Validation loss decreased (1.073714 --> 1.071238).  Saving model ...
Validation loss decreased (1.071238 --> 1.065797).  Saving model ...
Validation loss decreased (1.065797 --> 1.061989).  Saving model ...
Validation loss decreased (1.061989 --> 1.056462).  Saving model ...
Validation loss decreased (1.056462 --> 1.053633).  Saving model ...
Validation loss decreased (1.053633 --> 1.048065).  Saving model ...
Validation loss decreased (1.048065 --> 1.045205).  Saving model ...
Validation loss decreased (1.045205 --> 1.043706).  Saving model ...
Validation loss decreased (1.043706 --> 1.040562).  Saving model ...
Validation loss decreased (1.040562 --> 1.037155).  Saving model ...
Validation loss decreased (1.037155 --> 1.035485).  Saving model ...
Validation loss decreased (1.035485 --> 1.029259).  Saving model ...
Validation loss decreased (1.029259 --> 1.026395).  Saving model ...
Validation loss decreased (1.026395 --> 1.023898).  Saving model ...
Validation loss decreased (1.023898 --> 1.020142).  Saving model ...
Validation loss decreased (1.020142 --> 1.014810).  Saving model ...
Validation loss decreased (1.014810 --> 1.011877).  Saving model ...
EarlyStopping counter: 1 out of 10.0
Validation loss decreased (1.011877 --> 1.005642).  Saving model ...
Validation loss decreased (1.005642 --> 1.001506).  Saving model ...
Validation loss decreased (1.001506 --> 0.997483).  Saving model ...
Validation loss decreased (0.997483 --> 0.995832).  Saving model ...
Validation loss decreased (0.995832 --> 0.993408).  Saving model ...
Validation loss decreased (0.993408 --> 0.990253).  Saving model ...
Validation loss decreased (0.990253 --> 0.988114).  Saving model ...
Validation loss decreased (0.988114 --> 0.985638).  Saving model ...
Validation loss decreased (0.985638 --> 0.982452).  Saving model ...
Validation loss decreased (0.982452 --> 0.981789).  Saving model ...
Validation loss decreased (0.981789 --> 0.980513).  Saving model ...
Validation loss decreased (0.980513 --> 0.977162).  Saving model ...
Validation loss decreased (0.977162 --> 0.974335).  Saving model ...
Validation loss decreased (0.974335 --> 0.970209).  Saving model ...
Validation loss decreased (0.970209 --> 0.968492).  Saving model ...
EarlyStopping counter: 1 out of 10.0
Validation loss decreased (0.968492 --> 0.968303).  Saving model ...
Validation loss decreased (0.968303 --> 0.965318).  Saving model ...
Validation loss decreased (0.965318 --> 0.960837).  Saving model ...
Validation loss decreased (0.960837 --> 0.960254).  Saving model ...
Validation loss decreased (0.960254 --> 0.956133).  Saving model ...
Validation loss decreased (0.956133 --> 0.954956).  Saving model ...
Validation loss decreased (0.954956 --> 0.951551).  Saving model ...
Validation loss decreased (0.951551 --> 0.951246).  Saving model ...
Validation loss decreased (0.951246 --> 0.948370).  Saving model ...
EarlyStopping counter: 1 out of 10.0
EarlyStopping counter: 2 out of 10.0
Validation loss decreased (0.948370 --> 0.948156).  Saving model ...
Validation loss decreased (0.948156 --> 0.947778).  Saving model ...
Validation loss decreased (0.947778 --> 0.943976).  Saving model ...
EarlyStopping counter: 1 out of 10.0
Validation loss decreased (0.943976 --> 0.941642).  Saving model ...
Validation loss decreased (0.941642 --> 0.941155).  Saving model ...
Validation loss decreased (0.941155 --> 0.940505).  Saving model ...
Validation loss decreased (0.940505 --> 0.936880).  Saving model ...
EarlyStopping counter: 1 out of 10.0
Validation loss decreased (0.936880 --> 0.934921).  Saving model ...
Validation loss decreased (0.934921 --> 0.931238).  Saving model ...
EarlyStopping counter: 1 out of 10.0
EarlyStopping counter: 2 out of 10.0
EarlyStopping counter: 3 out of 10.0
Validation loss decreased (0.931238 --> 0.931047).  Saving model ...
Validation loss decreased (0.931047 --> 0.928772).  Saving model ...
Validation loss decreased (0.928772 --> 0.928018).  Saving model ...
Validation loss decreased (0.928018 --> 0.926546).  Saving model ...
Validation loss decreased (0.926546 --> 0.924282).  Saving model ...
EarlyStopping counter: 1 out of 10.0
EarlyStopping counter: 2 out of 10.0
EarlyStopping counter: 3 out of 10.0
Validation loss decreased (0.924282 --> 0.923530).  Saving model ...
Validation loss decreased (0.923530 --> 0.922762).  Saving model ...
Validation loss decreased (0.922762 --> 0.922218).  Saving model ...
Validation loss decreased (0.922218 --> 0.920148).  Saving model ...
Validation loss decreased (0.920148 --> 0.919916).  Saving model ...
Validation loss decreased (0.919916 --> 0.919803).  Saving model ...
Validation loss decreased (0.919803 --> 0.919506).  Saving model ...
Validation loss decreased (0.919506 --> 0.919152).  Saving model ...
Validation loss decreased (0.919152 --> 0.917368).  Saving model ...
EarlyStopping counter: 1 out of 10.0
EarlyStopping counter: 2 out of 10.0
Validation loss decreased (0.917368 --> 0.917264).  Saving model ...
Validation loss decreased (0.917264 --> 0.915663).  Saving model ...
EarlyStopping counter: 1 out of 10.0
EarlyStopping counter: 2 out of 10.0
EarlyStopping counter: 3 out of 10.0
EarlyStopping counter: 4 out of 10.0
EarlyStopping counter: 5 out of 10.0
EarlyStopping counter: 6 out of 10.0
EarlyStopping counter: 7 out of 10.0
EarlyStopping counter: 8 out of 10.0
EarlyStopping counter: 9 out of 10.0
EarlyStopping counter: 10 out of 10.0
/localscratch/yinan.29351697.0/env/lib/python3.7/site-packages/torch/nn/functional.py:1794: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.
  warnings.warn("nn.functional.tanh is deprecated. Use torch.tanh instead.")
wandb: Waiting for W&B process to finish, PID 58408... (success).
wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: \ 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: | 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: / 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: \ 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: | 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb:                                                                                
wandb: Run history:
wandb:     e_F1 ▁▁▃▄▄▅▅▆▆▇▇▇▇▇▇▇▇▇██████████████████████
wandb:   e_loss █▇▇▇▆▆▆▅▅▅▄▄▄▄▃▃▃▃▃▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:     t_F1 ▁▁▂▃▃▃▄▄▅▅▅▅▅▆▅▆▆▆▆▆▇▆▆▇▇▇▇▇▇▇▇▇▇██████▇
wandb:   t_loss ██▇▇▇▇▆▆▆▆▅▅▅▅▅▄▄▄▄▃▃▃▃▃▃▂▂▂▂▂▂▂▂▂▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:     e_F1 61.99631
wandb:   e_loss 0.91814
wandb:     t_F1 72.8369
wandb:   t_loss 0.72552
wandb: 
wandb: Synced 4 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Synced prime-feather-4: https://wandb.ai/yinanazhou/xl_512_bs_8_lr_1e06_es_10_lc_True_nr_False_sr_False_stem_False_lemma_True_repeat_2_fold_2/runs/e6jggyuv
wandb: Find logs at: ./wandb/run-20220324_111530-e6jggyuv/logs/debug.log
wandb: 

wandb: wandb version 0.12.11 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
2022-03-24 12:51:23.716296: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1
wandb: Tracking run with wandb version 0.12.5
wandb: Syncing run gallant-sound-3
wandb: ⭐️ View project at https://wandb.ai/yinanazhou/xl_512_bs_8_lr_1e06_es_10_lc_True_nr_False_sr_False_stem_False_lemma_True_repeat_3_fold_1
wandb: 🚀 View run at https://wandb.ai/yinanazhou/xl_512_bs_8_lr_1e06_es_10_lc_True_nr_False_sr_False_stem_False_lemma_True_repeat_3_fold_1/runs/1w8ms2je
wandb: Run data is saved locally in /project/6002780/yinan/Thesis_MER_Lyrics/lyric-emotion/wandb/run-20220324_125121-1w8ms2je
wandb: Run `wandb offline` to turn off syncing.

Validation loss decreased (inf --> 1.431370).  Saving model ...
Validation loss decreased (1.431370 --> 1.417945).  Saving model ...
Validation loss decreased (1.417945 --> 1.407779).  Saving model ...
Validation loss decreased (1.407779 --> 1.399613).  Saving model ...
Validation loss decreased (1.399613 --> 1.392864).  Saving model ...
Validation loss decreased (1.392864 --> 1.386890).  Saving model ...
Validation loss decreased (1.386890 --> 1.381738).  Saving model ...
Validation loss decreased (1.381738 --> 1.376486).  Saving model ...
Validation loss decreased (1.376486 --> 1.371965).  Saving model ...
Validation loss decreased (1.371965 --> 1.367267).  Saving model ...
Validation loss decreased (1.367267 --> 1.362583).  Saving model ...
Validation loss decreased (1.362583 --> 1.358379).  Saving model ...
Validation loss decreased (1.358379 --> 1.354126).  Saving model ...
Validation loss decreased (1.354126 --> 1.349584).  Saving model ...
Validation loss decreased (1.349584 --> 1.345349).  Saving model ...
Validation loss decreased (1.345349 --> 1.340805).  Saving model ...
Validation loss decreased (1.340805 --> 1.335609).  Saving model ...
Validation loss decreased (1.335609 --> 1.331316).  Saving model ...
Validation loss decreased (1.331316 --> 1.325730).  Saving model ...
Validation loss decreased (1.325730 --> 1.320245).  Saving model ...
Validation loss decreased (1.320245 --> 1.314043).  Saving model ...
Validation loss decreased (1.314043 --> 1.308175).  Saving model ...
Validation loss decreased (1.308175 --> 1.301878).  Saving model ...
Validation loss decreased (1.301878 --> 1.294793).  Saving model ...
Validation loss decreased (1.294793 --> 1.287969).  Saving model ...
Validation loss decreased (1.287969 --> 1.279635).  Saving model ...
Validation loss decreased (1.279635 --> 1.272222).  Saving model ...
Validation loss decreased (1.272222 --> 1.264487).  Saving model ...
Validation loss decreased (1.264487 --> 1.255816).  Saving model ...
Validation loss decreased (1.255816 --> 1.247143).  Saving model ...
Validation loss decreased (1.247143 --> 1.237834).  Saving model ...
Validation loss decreased (1.237834 --> 1.229036).  Saving model ...
Validation loss decreased (1.229036 --> 1.220690).  Saving model ...
Validation loss decreased (1.220690 --> 1.212031).  Saving model ...
Validation loss decreased (1.212031 --> 1.204100).  Saving model ...
Validation loss decreased (1.204100 --> 1.196786).  Saving model ...
Validation loss decreased (1.196786 --> 1.189606).  Saving model ...
Validation loss decreased (1.189606 --> 1.181977).  Saving model ...
Validation loss decreased (1.181977 --> 1.174313).  Saving model ...
Validation loss decreased (1.174313 --> 1.166871).  Saving model ...
Validation loss decreased (1.166871 --> 1.159596).  Saving model ...
Validation loss decreased (1.159596 --> 1.153355).  Saving model ...
Validation loss decreased (1.153355 --> 1.146038).  Saving model ...
Validation loss decreased (1.146038 --> 1.139321).  Saving model ...
Validation loss decreased (1.139321 --> 1.132779).  Saving model ...
Validation loss decreased (1.132779 --> 1.125405).  Saving model ...
Validation loss decreased (1.125405 --> 1.119050).  Saving model ...
Validation loss decreased (1.119050 --> 1.112275).  Saving model ...
Validation loss decreased (1.112275 --> 1.107236).  Saving model ...
Validation loss decreased (1.107236 --> 1.101278).  Saving model ...
Validation loss decreased (1.101278 --> 1.095944).  Saving model ...
Validation loss decreased (1.095944 --> 1.090894).  Saving model ...
Validation loss decreased (1.090894 --> 1.087061).  Saving model ...
Validation loss decreased (1.087061 --> 1.082210).  Saving model ...
Validation loss decreased (1.082210 --> 1.078165).  Saving model ...
Validation loss decreased (1.078165 --> 1.072654).  Saving model ...
Validation loss decreased (1.072654 --> 1.067875).  Saving model ...
Validation loss decreased (1.067875 --> 1.063311).  Saving model ...
Validation loss decreased (1.063311 --> 1.060254).  Saving model ...
Validation loss decreased (1.060254 --> 1.054758).  Saving model ...
Validation loss decreased (1.054758 --> 1.051091).  Saving model ...
Validation loss decreased (1.051091 --> 1.047219).  Saving model ...
Validation loss decreased (1.047219 --> 1.044007).  Saving model ...
Validation loss decreased (1.044007 --> 1.039982).  Saving model ...
Validation loss decreased (1.039982 --> 1.037017).  Saving model ...
Validation loss decreased (1.037017 --> 1.034132).  Saving model ...
Validation loss decreased (1.034132 --> 1.030063).  Saving model ...
Validation loss decreased (1.030063 --> 1.025349).  Saving model ...
Validation loss decreased (1.025349 --> 1.020179).  Saving model ...
Validation loss decreased (1.020179 --> 1.016250).  Saving model ...
Validation loss decreased (1.016250 --> 1.015270).  Saving model ...
Validation loss decreased (1.015270 --> 1.010998).  Saving model ...
Validation loss decreased (1.010998 --> 1.006651).  Saving model ...
Validation loss decreased (1.006651 --> 1.003812).  Saving model ...
Validation loss decreased (1.003812 --> 1.001988).  Saving model ...
Validation loss decreased (1.001988 --> 1.000198).  Saving model ...
Validation loss decreased (1.000198 --> 0.997185).  Saving model ...
Validation loss decreased (0.997185 --> 0.993137).  Saving model ...
Validation loss decreased (0.993137 --> 0.990087).  Saving model ...
Validation loss decreased (0.990087 --> 0.986386).  Saving model ...
Validation loss decreased (0.986386 --> 0.984707).  Saving model ...
Validation loss decreased (0.984707 --> 0.982187).  Saving model ...
Validation loss decreased (0.982187 --> 0.980978).  Saving model ...
Validation loss decreased (0.980978 --> 0.978444).  Saving model ...
Validation loss decreased (0.978444 --> 0.977096).  Saving model ...
Validation loss decreased (0.977096 --> 0.976102).  Saving model ...
Validation loss decreased (0.976102 --> 0.973969).  Saving model ...
Validation loss decreased (0.973969 --> 0.971561).  Saving model ...
Validation loss decreased (0.971561 --> 0.970574).  Saving model ...
Validation loss decreased (0.970574 --> 0.968583).  Saving model ...
Validation loss decreased (0.968583 --> 0.967257).  Saving model ...
Validation loss decreased (0.967257 --> 0.966660).  Saving model ...
Validation loss decreased (0.966660 --> 0.964375).  Saving model ...
EarlyStopping counter: 1 out of 10.0
Validation loss decreased (0.964375 --> 0.963363).  Saving model ...
Validation loss decreased (0.963363 --> 0.962679).  Saving model ...
Validation loss decreased (0.962679 --> 0.961703).  Saving model ...
Validation loss decreased (0.961703 --> 0.959855).  Saving model ...
Validation loss decreased (0.959855 --> 0.958971).  Saving model ...
Validation loss decreased (0.958971 --> 0.955216).  Saving model ...
Validation loss decreased (0.955216 --> 0.954076).  Saving model ...
Validation loss decreased (0.954076 --> 0.952105).  Saving model ...
Validation loss decreased (0.952105 --> 0.951457).  Saving model ...
Validation loss decreased (0.951457 --> 0.951235).  Saving model ...
Validation loss decreased (0.951235 --> 0.949776).  Saving model ...
EarlyStopping counter: 1 out of 10.0
Validation loss decreased (0.949776 --> 0.948589).  Saving model ...
EarlyStopping counter: 1 out of 10.0
Validation loss decreased (0.948589 --> 0.946478).  Saving model ...
Validation loss decreased (0.946478 --> 0.946054).  Saving model ...
Validation loss decreased (0.946054 --> 0.944745).  Saving model ...
EarlyStopping counter: 1 out of 10.0
EarlyStopping counter: 2 out of 10.0
Validation loss decreased (0.944745 --> 0.944319).  Saving model ...
Validation loss decreased (0.944319 --> 0.943666).  Saving model ...
Validation loss decreased (0.943666 --> 0.941822).  Saving model ...
Validation loss decreased (0.941822 --> 0.941615).  Saving model ...
Validation loss decreased (0.941615 --> 0.940001).  Saving model ...
EarlyStopping counter: 1 out of 10.0
EarlyStopping counter: 2 out of 10.0
Validation loss decreased (0.940001 --> 0.939864).  Saving model ...
Validation loss decreased (0.939864 --> 0.938830).  Saving model ...
EarlyStopping counter: 1 out of 10.0
EarlyStopping counter: 2 out of 10.0
EarlyStopping counter: 3 out of 10.0
EarlyStopping counter: 4 out of 10.0
EarlyStopping counter: 5 out of 10.0
Validation loss decreased (0.938830 --> 0.938396).  Saving model ...
Validation loss decreased (0.938396 --> 0.937856).  Saving model ...
EarlyStopping counter: 1 out of 10.0
EarlyStopping counter: 2 out of 10.0
EarlyStopping counter: 3 out of 10.0
EarlyStopping counter: 4 out of 10.0
EarlyStopping counter: 5 out of 10.0
EarlyStopping counter: 6 out of 10.0
EarlyStopping counter: 7 out of 10.0
EarlyStopping counter: 8 out of 10.0
EarlyStopping counter: 9 out of 10.0
EarlyStopping counter: 10 out of 10.0
/localscratch/yinan.29351697.0/env/lib/python3.7/site-packages/torch/nn/functional.py:1794: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.
  warnings.warn("nn.functional.tanh is deprecated. Use torch.tanh instead.")
wandb: Waiting for W&B process to finish, PID 63537... (success).
wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: \ 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: | 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: / 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: \ 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: | 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: / 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: \ 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: | 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: / 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb:                                                                                
wandb: Run history:
wandb:     e_F1 ▁▂▂▄▄▅▆▆▆▆▆▆▆▇▇▇▇▇▇▇▇▇▇▇████████████████
wandb:   e_loss ██▇▇▇▇▆▆▆▅▅▄▄▄▃▃▃▃▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:     t_F1 ▁▁▂▂▂▃▃▄▄▄▅▅▅▆▅▆▆▆▇▆▆▇▆▆▆▇▇▇▇▇▇▇▇█▇▇████
wandb:   t_loss ██▇▇▇▇▇▇▆▆▆▅▅▅▅▅▄▄▄▄▄▃▃▃▃▃▃▂▂▂▂▂▂▂▂▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:     e_F1 59.66312
wandb:   e_loss 0.93991
wandb:     t_F1 72.90129
wandb:   t_loss 0.74278
wandb: 
wandb: Synced 4 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Synced gallant-sound-3: https://wandb.ai/yinanazhou/xl_512_bs_8_lr_1e06_es_10_lc_True_nr_False_sr_False_stem_False_lemma_True_repeat_3_fold_1/runs/1w8ms2je
wandb: Find logs at: ./wandb/run-20220324_125121-1w8ms2je/logs/debug.log
wandb: 

wandb: wandb version 0.12.11 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
2022-03-24 14:23:14.582857: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1
wandb: Tracking run with wandb version 0.12.5
wandb: Syncing run comic-darkness-3
wandb: ⭐️ View project at https://wandb.ai/yinanazhou/xl_512_bs_8_lr_1e06_es_10_lc_True_nr_False_sr_False_stem_False_lemma_True_repeat_3_fold_2
wandb: 🚀 View run at https://wandb.ai/yinanazhou/xl_512_bs_8_lr_1e06_es_10_lc_True_nr_False_sr_False_stem_False_lemma_True_repeat_3_fold_2/runs/2e1kntwt
wandb: Run data is saved locally in /project/6002780/yinan/Thesis_MER_Lyrics/lyric-emotion/wandb/run-20220324_142311-2e1kntwt
wandb: Run `wandb offline` to turn off syncing.

Validation loss decreased (inf --> 1.399829).  Saving model ...
Validation loss decreased (1.399829 --> 1.391629).  Saving model ...
Validation loss decreased (1.391629 --> 1.385343).  Saving model ...
Validation loss decreased (1.385343 --> 1.380020).  Saving model ...
Validation loss decreased (1.380020 --> 1.375183).  Saving model ...
Validation loss decreased (1.375183 --> 1.370834).  Saving model ...
Validation loss decreased (1.370834 --> 1.366536).  Saving model ...
Validation loss decreased (1.366536 --> 1.362693).  Saving model ...
Validation loss decreased (1.362693 --> 1.358486).  Saving model ...
Validation loss decreased (1.358486 --> 1.354343).  Saving model ...
Validation loss decreased (1.354343 --> 1.350652).  Saving model ...
Validation loss decreased (1.350652 --> 1.347151).  Saving model ...
Validation loss decreased (1.347151 --> 1.343135).  Saving model ...
Validation loss decreased (1.343135 --> 1.338927).  Saving model ...
Validation loss decreased (1.338927 --> 1.334477).  Saving model ...
Validation loss decreased (1.334477 --> 1.330237).  Saving model ...
Validation loss decreased (1.330237 --> 1.325651).  Saving model ...
Validation loss decreased (1.325651 --> 1.320314).  Saving model ...
Validation loss decreased (1.320314 --> 1.314846).  Saving model ...
Validation loss decreased (1.314846 --> 1.309095).  Saving model ...
Validation loss decreased (1.309095 --> 1.302712).  Saving model ...
Validation loss decreased (1.302712 --> 1.295685).  Saving model ...
Validation loss decreased (1.295685 --> 1.288306).  Saving model ...
Validation loss decreased (1.288306 --> 1.281062).  Saving model ...
Validation loss decreased (1.281062 --> 1.272190).  Saving model ...
Validation loss decreased (1.272190 --> 1.263668).  Saving model ...
Validation loss decreased (1.263668 --> 1.255747).  Saving model ...
Validation loss decreased (1.255747 --> 1.246141).  Saving model ...
Validation loss decreased (1.246141 --> 1.236413).  Saving model ...
Validation loss decreased (1.236413 --> 1.227638).  Saving model ...
Validation loss decreased (1.227638 --> 1.219029).  Saving model ...
Validation loss decreased (1.219029 --> 1.209087).  Saving model ...
Validation loss decreased (1.209087 --> 1.199518).  Saving model ...
Validation loss decreased (1.199518 --> 1.191151).  Saving model ...
Validation loss decreased (1.191151 --> 1.183721).  Saving model ...
Validation loss decreased (1.183721 --> 1.177797).  Saving model ...
Validation loss decreased (1.177797 --> 1.171609).  Saving model ...
Validation loss decreased (1.171609 --> 1.165278).  Saving model ...
Validation loss decreased (1.165278 --> 1.159419).  Saving model ...
Validation loss decreased (1.159419 --> 1.152884).  Saving model ...
Validation loss decreased (1.152884 --> 1.146332).  Saving model ...
Validation loss decreased (1.146332 --> 1.139667).  Saving model ...
Validation loss decreased (1.139667 --> 1.133052).  Saving model ...
Validation loss decreased (1.133052 --> 1.127759).  Saving model ...
Validation loss decreased (1.127759 --> 1.123299).  Saving model ...
Validation loss decreased (1.123299 --> 1.118005).  Saving model ...
Validation loss decreased (1.118005 --> 1.112372).  Saving model ...
Validation loss decreased (1.112372 --> 1.106246).  Saving model ...
Validation loss decreased (1.106246 --> 1.100158).  Saving model ...
Validation loss decreased (1.100158 --> 1.093860).  Saving model ...
Validation loss decreased (1.093860 --> 1.091116).  Saving model ...
Validation loss decreased (1.091116 --> 1.086466).  Saving model ...
Validation loss decreased (1.086466 --> 1.082581).  Saving model ...
Validation loss decreased (1.082581 --> 1.077430).  Saving model ...
Validation loss decreased (1.077430 --> 1.072069).  Saving model ...
Validation loss decreased (1.072069 --> 1.067917).  Saving model ...
Validation loss decreased (1.067917 --> 1.062998).  Saving model ...
Validation loss decreased (1.062998 --> 1.058363).  Saving model ...
Validation loss decreased (1.058363 --> 1.054969).  Saving model ...
Validation loss decreased (1.054969 --> 1.050856).  Saving model ...
Validation loss decreased (1.050856 --> 1.047997).  Saving model ...
Validation loss decreased (1.047997 --> 1.045863).  Saving model ...
Validation loss decreased (1.045863 --> 1.042790).  Saving model ...
Validation loss decreased (1.042790 --> 1.039618).  Saving model ...
Validation loss decreased (1.039618 --> 1.033870).  Saving model ...
Validation loss decreased (1.033870 --> 1.030723).  Saving model ...
Validation loss decreased (1.030723 --> 1.027437).  Saving model ...
Validation loss decreased (1.027437 --> 1.025508).  Saving model ...
Validation loss decreased (1.025508 --> 1.020498).  Saving model ...
Validation loss decreased (1.020498 --> 1.017723).  Saving model ...
Validation loss decreased (1.017723 --> 1.014515).  Saving model ...
Validation loss decreased (1.014515 --> 1.011818).  Saving model ...
Validation loss decreased (1.011818 --> 1.009817).  Saving model ...
Validation loss decreased (1.009817 --> 1.006875).  Saving model ...
Validation loss decreased (1.006875 --> 1.003600).  Saving model ...
Validation loss decreased (1.003600 --> 1.001272).  Saving model ...
Validation loss decreased (1.001272 --> 0.997573).  Saving model ...
Validation loss decreased (0.997573 --> 0.994294).  Saving model ...
Validation loss decreased (0.994294 --> 0.992234).  Saving model ...
Validation loss decreased (0.992234 --> 0.990848).  Saving model ...
Validation loss decreased (0.990848 --> 0.988850).  Saving model ...
Validation loss decreased (0.988850 --> 0.986038).  Saving model ...
Validation loss decreased (0.986038 --> 0.984754).  Saving model ...
Validation loss decreased (0.984754 --> 0.982826).  Saving model ...
Validation loss decreased (0.982826 --> 0.982299).  Saving model ...
Validation loss decreased (0.982299 --> 0.979407).  Saving model ...
Validation loss decreased (0.979407 --> 0.978069).  Saving model ...
Validation loss decreased (0.978069 --> 0.975897).  Saving model ...
EarlyStopping counter: 1 out of 10.0
Validation loss decreased (0.975897 --> 0.975204).  Saving model ...
Validation loss decreased (0.975204 --> 0.972849).  Saving model ...
Validation loss decreased (0.972849 --> 0.970780).  Saving model ...
Validation loss decreased (0.970780 --> 0.967950).  Saving model ...
Validation loss decreased (0.967950 --> 0.965887).  Saving model ...
Validation loss decreased (0.965887 --> 0.964162).  Saving model ...
Validation loss decreased (0.964162 --> 0.963760).  Saving model ...
EarlyStopping counter: 1 out of 10.0
Validation loss decreased (0.963760 --> 0.961221).  Saving model ...
Validation loss decreased (0.961221 --> 0.959107).  Saving model ...
Validation loss decreased (0.959107 --> 0.957039).  Saving model ...
Validation loss decreased (0.957039 --> 0.956162).  Saving model ...
Validation loss decreased (0.956162 --> 0.955980).  Saving model ...
Validation loss decreased (0.955980 --> 0.954556).  Saving model ...
Validation loss decreased (0.954556 --> 0.953717).  Saving model ...
Validation loss decreased (0.953717 --> 0.952133).  Saving model ...
Validation loss decreased (0.952133 --> 0.950612).  Saving model ...
Validation loss decreased (0.950612 --> 0.949870).  Saving model ...
Validation loss decreased (0.949870 --> 0.948509).  Saving model ...
Validation loss decreased (0.948509 --> 0.948088).  Saving model ...
Validation loss decreased (0.948088 --> 0.946770).  Saving model ...
Validation loss decreased (0.946770 --> 0.944116).  Saving model ...
EarlyStopping counter: 1 out of 10.0
EarlyStopping counter: 2 out of 10.0
Validation loss decreased (0.944116 --> 0.942651).  Saving model ...
Validation loss decreased (0.942651 --> 0.939343).  Saving model ...
Validation loss decreased (0.939343 --> 0.937825).  Saving model ...
EarlyStopping counter: 1 out of 10.0
Validation loss decreased (0.937825 --> 0.937766).  Saving model ...
EarlyStopping counter: 1 out of 10.0
EarlyStopping counter: 2 out of 10.0
EarlyStopping counter: 3 out of 10.0
EarlyStopping counter: 4 out of 10.0
Validation loss decreased (0.937766 --> 0.937089).  Saving model ...
Validation loss decreased (0.937089 --> 0.936939).  Saving model ...
Validation loss decreased (0.936939 --> 0.935571).  Saving model ...
EarlyStopping counter: 1 out of 10.0
EarlyStopping counter: 2 out of 10.0
EarlyStopping counter: 3 out of 10.0
Validation loss decreased (0.935571 --> 0.933914).  Saving model ...
Validation loss decreased (0.933914 --> 0.933731).  Saving model ...
EarlyStopping counter: 1 out of 10.0
EarlyStopping counter: 2 out of 10.0
Validation loss decreased (0.933731 --> 0.932474).  Saving model ...
EarlyStopping counter: 1 out of 10.0
EarlyStopping counter: 2 out of 10.0
EarlyStopping counter: 3 out of 10.0
EarlyStopping counter: 4 out of 10.0
Validation loss decreased (0.932474 --> 0.931599).  Saving model ...
EarlyStopping counter: 1 out of 10.0
EarlyStopping counter: 2 out of 10.0
EarlyStopping counter: 3 out of 10.0
EarlyStopping counter: 4 out of 10.0
EarlyStopping counter: 5 out of 10.0
EarlyStopping counter: 6 out of 10.0
EarlyStopping counter: 7 out of 10.0
EarlyStopping counter: 8 out of 10.0
EarlyStopping counter: 9 out of 10.0
EarlyStopping counter: 10 out of 10.0
/localscratch/yinan.29351697.0/env/lib/python3.7/site-packages/torch/nn/functional.py:1794: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.
  warnings.warn("nn.functional.tanh is deprecated. Use torch.tanh instead.")
wandb: Waiting for W&B process to finish, PID 68690... (success).
wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: \ 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: | 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: / 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: \ 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: | 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: / 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: \ 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: | 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: / 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb:                                                                                
wandb: Run history:
wandb:     e_F1 ▁▂▃▄▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇▇▇▇▇▇█▇▇█████████████
wandb:   e_loss ███▇▇▇▆▆▅▅▅▄▄▃▃▃▃▃▂▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:     t_F1 ▁▁▂▂▂▃▃▄▄▄▅▅▅▅▅▆▆▆▆▆▆▇▆▇▇▇▇▇▇▇█▇████▇███
wandb:   t_loss █████▇▇▆▆▆▆▅▅▅▅▄▄▄▄▃▄▃▃▃▃▃▂▃▂▂▂▂▂▂▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:     e_F1 64.39632
wandb:   e_loss 0.93301
wandb:     t_F1 73.02334
wandb:   t_loss 0.71706
wandb: 
wandb: Synced 4 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Synced comic-darkness-3: https://wandb.ai/yinanazhou/xl_512_bs_8_lr_1e06_es_10_lc_True_nr_False_sr_False_stem_False_lemma_True_repeat_3_fold_2/runs/2e1kntwt
wandb: Find logs at: ./wandb/run-20220324_142311-2e1kntwt/logs/debug.log
wandb: 

wandb: wandb version 0.12.11 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
2022-03-24 15:59:30.859407: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1
wandb: Tracking run with wandb version 0.12.5
wandb: Syncing run icy-cherry-3
wandb: ⭐️ View project at https://wandb.ai/yinanazhou/xl_512_bs_8_lr_1e06_es_10_lc_True_nr_False_sr_False_stem_False_lemma_True_repeat_4_fold_1
wandb: 🚀 View run at https://wandb.ai/yinanazhou/xl_512_bs_8_lr_1e06_es_10_lc_True_nr_False_sr_False_stem_False_lemma_True_repeat_4_fold_1/runs/1q2sxmi0
wandb: Run data is saved locally in /project/6002780/yinan/Thesis_MER_Lyrics/lyric-emotion/wandb/run-20220324_155928-1q2sxmi0
wandb: Run `wandb offline` to turn off syncing.

Validation loss decreased (inf --> 1.449515).  Saving model ...
Validation loss decreased (1.449515 --> 1.423453).  Saving model ...
Validation loss decreased (1.423453 --> 1.402620).  Saving model ...
Validation loss decreased (1.402620 --> 1.387107).  Saving model ...
Validation loss decreased (1.387107 --> 1.375387).  Saving model ...
Validation loss decreased (1.375387 --> 1.366044).  Saving model ...
Validation loss decreased (1.366044 --> 1.358525).  Saving model ...
Validation loss decreased (1.358525 --> 1.353009).  Saving model ...
Validation loss decreased (1.353009 --> 1.347618).  Saving model ...
Validation loss decreased (1.347618 --> 1.342984).  Saving model ...
Validation loss decreased (1.342984 --> 1.338516).  Saving model ...
Validation loss decreased (1.338516 --> 1.334033).  Saving model ...
Validation loss decreased (1.334033 --> 1.329911).  Saving model ...
Validation loss decreased (1.329911 --> 1.325669).  Saving model ...
Validation loss decreased (1.325669 --> 1.321498).  Saving model ...
Validation loss decreased (1.321498 --> 1.316793).  Saving model ...
Validation loss decreased (1.316793 --> 1.312099).  Saving model ...
Validation loss decreased (1.312099 --> 1.307143).  Saving model ...
Validation loss decreased (1.307143 --> 1.302270).  Saving model ...
Validation loss decreased (1.302270 --> 1.297184).  Saving model ...
Validation loss decreased (1.297184 --> 1.292066).  Saving model ...
Validation loss decreased (1.292066 --> 1.287035).  Saving model ...
Validation loss decreased (1.287035 --> 1.282014).  Saving model ...
Validation loss decreased (1.282014 --> 1.276881).  Saving model ...
Validation loss decreased (1.276881 --> 1.271281).  Saving model ...
Validation loss decreased (1.271281 --> 1.265111).  Saving model ...
Validation loss decreased (1.265111 --> 1.259319).  Saving model ...
Validation loss decreased (1.259319 --> 1.254024).  Saving model ...
Validation loss decreased (1.254024 --> 1.247829).  Saving model ...
Validation loss decreased (1.247829 --> 1.242087).  Saving model ...
Validation loss decreased (1.242087 --> 1.236665).  Saving model ...
Validation loss decreased (1.236665 --> 1.231391).  Saving model ...
Validation loss decreased (1.231391 --> 1.225226).  Saving model ...
Validation loss decreased (1.225226 --> 1.219644).  Saving model ...
Validation loss decreased (1.219644 --> 1.214392).  Saving model ...
Validation loss decreased (1.214392 --> 1.208050).  Saving model ...
Validation loss decreased (1.208050 --> 1.202589).  Saving model ...
Validation loss decreased (1.202589 --> 1.197289).  Saving model ...
Validation loss decreased (1.197289 --> 1.192889).  Saving model ...
Validation loss decreased (1.192889 --> 1.187774).  Saving model ...
Validation loss decreased (1.187774 --> 1.183219).  Saving model ...
Validation loss decreased (1.183219 --> 1.178738).  Saving model ...
Validation loss decreased (1.178738 --> 1.173631).  Saving model ...
Validation loss decreased (1.173631 --> 1.170083).  Saving model ...
Validation loss decreased (1.170083 --> 1.164333).  Saving model ...
Validation loss decreased (1.164333 --> 1.158242).  Saving model ...
Validation loss decreased (1.158242 --> 1.152306).  Saving model ...
Validation loss decreased (1.152306 --> 1.146756).  Saving model ...
Validation loss decreased (1.146756 --> 1.141689).  Saving model ...
Validation loss decreased (1.141689 --> 1.136892).  Saving model ...
Validation loss decreased (1.136892 --> 1.132060).  Saving model ...
Validation loss decreased (1.132060 --> 1.126953).  Saving model ...
Validation loss decreased (1.126953 --> 1.122770).  Saving model ...
Validation loss decreased (1.122770 --> 1.118290).  Saving model ...
Validation loss decreased (1.118290 --> 1.113622).  Saving model ...
Validation loss decreased (1.113622 --> 1.108676).  Saving model ...
Validation loss decreased (1.108676 --> 1.103904).  Saving model ...
Validation loss decreased (1.103904 --> 1.099805).  Saving model ...
Validation loss decreased (1.099805 --> 1.094618).  Saving model ...
Validation loss decreased (1.094618 --> 1.090730).  Saving model ...
Validation loss decreased (1.090730 --> 1.087255).  Saving model ...
Validation loss decreased (1.087255 --> 1.083851).  Saving model ...
Validation loss decreased (1.083851 --> 1.080217).  Saving model ...
Validation loss decreased (1.080217 --> 1.076471).  Saving model ...
Validation loss decreased (1.076471 --> 1.072590).  Saving model ...
Validation loss decreased (1.072590 --> 1.069171).  Saving model ...
Validation loss decreased (1.069171 --> 1.065295).  Saving model ...
Validation loss decreased (1.065295 --> 1.062497).  Saving model ...
Validation loss decreased (1.062497 --> 1.058610).  Saving model ...
Validation loss decreased (1.058610 --> 1.054932).  Saving model ...
Validation loss decreased (1.054932 --> 1.051000).  Saving model ...
Validation loss decreased (1.051000 --> 1.047737).  Saving model ...
Validation loss decreased (1.047737 --> 1.044639).  Saving model ...
Validation loss decreased (1.044639 --> 1.041998).  Saving model ...
Validation loss decreased (1.041998 --> 1.039745).  Saving model ...
Validation loss decreased (1.039745 --> 1.036846).  Saving model ...
Validation loss decreased (1.036846 --> 1.034184).  Saving model ...
Validation loss decreased (1.034184 --> 1.031912).  Saving model ...
Validation loss decreased (1.031912 --> 1.029510).  Saving model ...
Validation loss decreased (1.029510 --> 1.026702).  Saving model ...
Validation loss decreased (1.026702 --> 1.023982).  Saving model ...
Validation loss decreased (1.023982 --> 1.021513).  Saving model ...
Validation loss decreased (1.021513 --> 1.019500).  Saving model ...
Validation loss decreased (1.019500 --> 1.017029).  Saving model ...
Validation loss decreased (1.017029 --> 1.015217).  Saving model ...
Validation loss decreased (1.015217 --> 1.013230).  Saving model ...
Validation loss decreased (1.013230 --> 1.010265).  Saving model ...
Validation loss decreased (1.010265 --> 1.007953).  Saving model ...
Validation loss decreased (1.007953 --> 1.006010).  Saving model ...
Validation loss decreased (1.006010 --> 1.003676).  Saving model ...
Validation loss decreased (1.003676 --> 1.001835).  Saving model ...
Validation loss decreased (1.001835 --> 0.999740).  Saving model ...
Validation loss decreased (0.999740 --> 0.998632).  Saving model ...
Validation loss decreased (0.998632 --> 0.996700).  Saving model ...
Validation loss decreased (0.996700 --> 0.994552).  Saving model ...
Validation loss decreased (0.994552 --> 0.992006).  Saving model ...
Validation loss decreased (0.992006 --> 0.990408).  Saving model ...
Validation loss decreased (0.990408 --> 0.989875).  Saving model ...
Validation loss decreased (0.989875 --> 0.988445).  Saving model ...
Validation loss decreased (0.988445 --> 0.986491).  Saving model ...
Validation loss decreased (0.986491 --> 0.986073).  Saving model ...
Validation loss decreased (0.986073 --> 0.985549).  Saving model ...
Validation loss decreased (0.985549 --> 0.983769).  Saving model ...
Validation loss decreased (0.983769 --> 0.982087).  Saving model ...
Validation loss decreased (0.982087 --> 0.979199).  Saving model ...
Validation loss decreased (0.979199 --> 0.978560).  Saving model ...
Validation loss decreased (0.978560 --> 0.976817).  Saving model ...
Validation loss decreased (0.976817 --> 0.975740).  Saving model ...
Validation loss decreased (0.975740 --> 0.974823).  Saving model ...
Validation loss decreased (0.974823 --> 0.973242).  Saving model ...
Validation loss decreased (0.973242 --> 0.971537).  Saving model ...
Validation loss decreased (0.971537 --> 0.970228).  Saving model ...
Validation loss decreased (0.970228 --> 0.969016).  Saving model ...
EarlyStopping counter: 1 out of 10.0
EarlyStopping counter: 2 out of 10.0
Validation loss decreased (0.969016 --> 0.966267).  Saving model ...
Validation loss decreased (0.966267 --> 0.965972).  Saving model ...
Validation loss decreased (0.965972 --> 0.964467).  Saving model ...
EarlyStopping counter: 1 out of 10.0
Validation loss decreased (0.964467 --> 0.963714).  Saving model ...
Validation loss decreased (0.963714 --> 0.962198).  Saving model ...
Validation loss decreased (0.962198 --> 0.960357).  Saving model ...
Validation loss decreased (0.960357 --> 0.959550).  Saving model ...
EarlyStopping counter: 1 out of 10.0
Validation loss decreased (0.959550 --> 0.959233).  Saving model ...
EarlyStopping counter: 1 out of 10.0
EarlyStopping counter: 2 out of 10.0
EarlyStopping counter: 3 out of 10.0
EarlyStopping counter: 4 out of 10.0
Validation loss decreased (0.959233 --> 0.957402).  Saving model ...
EarlyStopping counter: 1 out of 10.0
EarlyStopping counter: 2 out of 10.0
Validation loss decreased (0.957402 --> 0.956717).  Saving model ...
EarlyStopping counter: 1 out of 10.0
EarlyStopping counter: 2 out of 10.0
EarlyStopping counter: 3 out of 10.0
EarlyStopping counter: 4 out of 10.0
Validation loss decreased (0.956717 --> 0.956348).  Saving model ...
Validation loss decreased (0.956348 --> 0.954562).  Saving model ...
EarlyStopping counter: 1 out of 10.0
Validation loss decreased (0.954562 --> 0.954510).  Saving model ...
Validation loss decreased (0.954510 --> 0.954359).  Saving model ...
EarlyStopping counter: 1 out of 10.0
EarlyStopping counter: 2 out of 10.0
EarlyStopping counter: 3 out of 10.0
Validation loss decreased (0.954359 --> 0.953718).  Saving model ...
EarlyStopping counter: 1 out of 10.0
EarlyStopping counter: 2 out of 10.0
EarlyStopping counter: 3 out of 10.0
EarlyStopping counter: 4 out of 10.0
EarlyStopping counter: 5 out of 10.0
EarlyStopping counter: 6 out of 10.0
EarlyStopping counter: 7 out of 10.0
EarlyStopping counter: 8 out of 10.0
EarlyStopping counter: 9 out of 10.0
EarlyStopping counter: 10 out of 10.0
/localscratch/yinan.29351697.0/env/lib/python3.7/site-packages/torch/nn/functional.py:1794: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.
  warnings.warn("nn.functional.tanh is deprecated. Use torch.tanh instead.")
wandb: Waiting for W&B process to finish, PID 73793... (success).
wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: \ 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: | 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: / 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: \ 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: | 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: / 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: \ 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: | 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: / 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb:                                                                                
wandb: Run history:
wandb:     e_F1 ▁▂▄▅▅▅▅▅▆▆▆▆▆▆▇▇▇▇▇▇▇▇▇█████████████████
wandb:   e_loss █▇▇▇▆▆▆▅▅▅▄▄▄▄▃▃▃▃▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:     t_F1 ▁▂▂▃▄▄▄▅▅▅▅▆▆▆▆▆▆▆▇▆▆▇▇▇▆▇▇▇▇▇▇███▇█████
wandb:   t_loss ██▇▇▇▇▇▆▆▆▅▅▅▅▄▄▄▄▄▄▃▃▃▃▃▃▃▂▂▂▂▂▂▂▂▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:     e_F1 58.58533
wandb:   e_loss 0.95652
wandb:     t_F1 72.92238
wandb:   t_loss 0.70986
wandb: 
wandb: Synced 4 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Synced icy-cherry-3: https://wandb.ai/yinanazhou/xl_512_bs_8_lr_1e06_es_10_lc_True_nr_False_sr_False_stem_False_lemma_True_repeat_4_fold_1/runs/1q2sxmi0
wandb: Find logs at: ./wandb/run-20220324_155928-1q2sxmi0/logs/debug.log
wandb: 

wandb: wandb version 0.12.11 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
2022-03-24 17:41:54.376122: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1
wandb: Tracking run with wandb version 0.12.5
wandb: Syncing run balmy-terrain-2
wandb: ⭐️ View project at https://wandb.ai/yinanazhou/xl_512_bs_8_lr_1e06_es_10_lc_True_nr_False_sr_False_stem_False_lemma_True_repeat_4_fold_2
wandb: 🚀 View run at https://wandb.ai/yinanazhou/xl_512_bs_8_lr_1e06_es_10_lc_True_nr_False_sr_False_stem_False_lemma_True_repeat_4_fold_2/runs/3elsa316
wandb: Run data is saved locally in /project/6002780/yinan/Thesis_MER_Lyrics/lyric-emotion/wandb/run-20220324_174152-3elsa316
wandb: Run `wandb offline` to turn off syncing.

Validation loss decreased (inf --> 1.528937).  Saving model ...
Validation loss decreased (1.528937 --> 1.480151).  Saving model ...
Validation loss decreased (1.480151 --> 1.445870).  Saving model ...
Validation loss decreased (1.445870 --> 1.422314).  Saving model ...
Validation loss decreased (1.422314 --> 1.405206).  Saving model ...
Validation loss decreased (1.405206 --> 1.393270).  Saving model ...
Validation loss decreased (1.393270 --> 1.383265).  Saving model ...
Validation loss decreased (1.383265 --> 1.375916).  Saving model ...
Validation loss decreased (1.375916 --> 1.370347).  Saving model ...
Validation loss decreased (1.370347 --> 1.365337).  Saving model ...
Validation loss decreased (1.365337 --> 1.360846).  Saving model ...
Validation loss decreased (1.360846 --> 1.355904).  Saving model ...
Validation loss decreased (1.355904 --> 1.350893).  Saving model ...
Validation loss decreased (1.350893 --> 1.346232).  Saving model ...
Validation loss decreased (1.346232 --> 1.341369).  Saving model ...
Validation loss decreased (1.341369 --> 1.336461).  Saving model ...
Validation loss decreased (1.336461 --> 1.331570).  Saving model ...
Validation loss decreased (1.331570 --> 1.326470).  Saving model ...
Validation loss decreased (1.326470 --> 1.321063).  Saving model ...
Validation loss decreased (1.321063 --> 1.315104).  Saving model ...
Validation loss decreased (1.315104 --> 1.309360).  Saving model ...
Validation loss decreased (1.309360 --> 1.303809).  Saving model ...
Validation loss decreased (1.303809 --> 1.298460).  Saving model ...
Validation loss decreased (1.298460 --> 1.291708).  Saving model ...
Validation loss decreased (1.291708 --> 1.285274).  Saving model ...
Validation loss decreased (1.285274 --> 1.277800).  Saving model ...
Validation loss decreased (1.277800 --> 1.269626).  Saving model ...
Validation loss decreased (1.269626 --> 1.262875).  Saving model ...
Validation loss decreased (1.262875 --> 1.256450).  Saving model ...
Validation loss decreased (1.256450 --> 1.246950).  Saving model ...
Validation loss decreased (1.246950 --> 1.238336).  Saving model ...
Validation loss decreased (1.238336 --> 1.229521).  Saving model ...
Validation loss decreased (1.229521 --> 1.222536).  Saving model ...
Validation loss decreased (1.222536 --> 1.214953).  Saving model ...
Validation loss decreased (1.214953 --> 1.206592).  Saving model ...
Validation loss decreased (1.206592 --> 1.200035).  Saving model ...
Validation loss decreased (1.200035 --> 1.192417).  Saving model ...
Validation loss decreased (1.192417 --> 1.185834).  Saving model ...
Validation loss decreased (1.185834 --> 1.179967).  Saving model ...
Validation loss decreased (1.179967 --> 1.171929).  Saving model ...
Validation loss decreased (1.171929 --> 1.165048).  Saving model ...
Validation loss decreased (1.165048 --> 1.156763).  Saving model ...
Validation loss decreased (1.156763 --> 1.148434).  Saving model ...
Validation loss decreased (1.148434 --> 1.142154).  Saving model ...
Validation loss decreased (1.142154 --> 1.135831).  Saving model ...
Validation loss decreased (1.135831 --> 1.127557).  Saving model ...
Validation loss decreased (1.127557 --> 1.120109).  Saving model ...
Validation loss decreased (1.120109 --> 1.112481).  Saving model ...
Validation loss decreased (1.112481 --> 1.105608).  Saving model ...
Validation loss decreased (1.105608 --> 1.098282).  Saving model ...
Validation loss decreased (1.098282 --> 1.091692).  Saving model ...
Validation loss decreased (1.091692 --> 1.086171).  Saving model ...
Validation loss decreased (1.086171 --> 1.082107).  Saving model ...
Validation loss decreased (1.082107 --> 1.074904).  Saving model ...
Validation loss decreased (1.074904 --> 1.068812).  Saving model ...
Validation loss decreased (1.068812 --> 1.064076).  Saving model ...
Validation loss decreased (1.064076 --> 1.059234).  Saving model ...
Validation loss decreased (1.059234 --> 1.054775).  Saving model ...
Validation loss decreased (1.054775 --> 1.051041).  Saving model ...
Validation loss decreased (1.051041 --> 1.046289).  Saving model ...
Validation loss decreased (1.046289 --> 1.042112).  Saving model ...
Validation loss decreased (1.042112 --> 1.037876).  Saving model ...
Validation loss decreased (1.037876 --> 1.034402).  Saving model ...
Validation loss decreased (1.034402 --> 1.031099).  Saving model ...
Validation loss decreased (1.031099 --> 1.029181).  Saving model ...
Validation loss decreased (1.029181 --> 1.023184).  Saving model ...
Validation loss decreased (1.023184 --> 1.018461).  Saving model ...
Validation loss decreased (1.018461 --> 1.016664).  Saving model ...
Validation loss decreased (1.016664 --> 1.012210).  Saving model ...
Validation loss decreased (1.012210 --> 1.008402).  Saving model ...
Validation loss decreased (1.008402 --> 1.007567).  Saving model ...
Validation loss decreased (1.007567 --> 1.005538).  Saving model ...
Validation loss decreased (1.005538 --> 1.002787).  Saving model ...
Validation loss decreased (1.002787 --> 1.001441).  Saving model ...
Validation loss decreased (1.001441 --> 0.998092).  Saving model ...
Validation loss decreased (0.998092 --> 0.994506).  Saving model ...
Validation loss decreased (0.994506 --> 0.991640).  Saving model ...
Validation loss decreased (0.991640 --> 0.985206).  Saving model ...
Validation loss decreased (0.985206 --> 0.983809).  Saving model ...
Validation loss decreased (0.983809 --> 0.982707).  Saving model ...
Validation loss decreased (0.982707 --> 0.979333).  Saving model ...
Validation loss decreased (0.979333 --> 0.974555).  Saving model ...
Validation loss decreased (0.974555 --> 0.973542).  Saving model ...
EarlyStopping counter: 1 out of 10.0
Validation loss decreased (0.973542 --> 0.970781).  Saving model ...
Validation loss decreased (0.970781 --> 0.968545).  Saving model ...
Validation loss decreased (0.968545 --> 0.965947).  Saving model ...
Validation loss decreased (0.965947 --> 0.965283).  Saving model ...
EarlyStopping counter: 1 out of 10.0
Validation loss decreased (0.965283 --> 0.961883).  Saving model ...
Validation loss decreased (0.961883 --> 0.959186).  Saving model ...
EarlyStopping counter: 1 out of 10.0
Validation loss decreased (0.959186 --> 0.956439).  Saving model ...
EarlyStopping counter: 1 out of 10.0
Validation loss decreased (0.956439 --> 0.955388).  Saving model ...
Validation loss decreased (0.955388 --> 0.952959).  Saving model ...
Validation loss decreased (0.952959 --> 0.949305).  Saving model ...
Validation loss decreased (0.949305 --> 0.946753).  Saving model ...
Validation loss decreased (0.946753 --> 0.943686).  Saving model ...
EarlyStopping counter: 1 out of 10.0
EarlyStopping counter: 2 out of 10.0
Validation loss decreased (0.943686 --> 0.941977).  Saving model ...
Validation loss decreased (0.941977 --> 0.941514).  Saving model ...
Validation loss decreased (0.941514 --> 0.939273).  Saving model ...
Validation loss decreased (0.939273 --> 0.938244).  Saving model ...
EarlyStopping counter: 1 out of 10.0
EarlyStopping counter: 2 out of 10.0
EarlyStopping counter: 3 out of 10.0
Validation loss decreased (0.938244 --> 0.937004).  Saving model ...
Validation loss decreased (0.937004 --> 0.934954).  Saving model ...
Validation loss decreased (0.934954 --> 0.934034).  Saving model ...
Validation loss decreased (0.934034 --> 0.933707).  Saving model ...
Validation loss decreased (0.933707 --> 0.932335).  Saving model ...
EarlyStopping counter: 1 out of 10.0
Validation loss decreased (0.932335 --> 0.931244).  Saving model ...
Validation loss decreased (0.931244 --> 0.930979).  Saving model ...
Validation loss decreased (0.930979 --> 0.928748).  Saving model ...
EarlyStopping counter: 1 out of 10.0
EarlyStopping counter: 2 out of 10.0
Validation loss decreased (0.928748 --> 0.927274).  Saving model ...
EarlyStopping counter: 1 out of 10.0
EarlyStopping counter: 2 out of 10.0
Validation loss decreased (0.927274 --> 0.924923).  Saving model ...
Validation loss decreased (0.924923 --> 0.923477).  Saving model ...
EarlyStopping counter: 1 out of 10.0
EarlyStopping counter: 2 out of 10.0
EarlyStopping counter: 3 out of 10.0
EarlyStopping counter: 4 out of 10.0
EarlyStopping counter: 5 out of 10.0
EarlyStopping counter: 6 out of 10.0
Validation loss decreased (0.923477 --> 0.923300).  Saving model ...
Validation loss decreased (0.923300 --> 0.922378).  Saving model ...
EarlyStopping counter: 1 out of 10.0
EarlyStopping counter: 2 out of 10.0
EarlyStopping counter: 3 out of 10.0
EarlyStopping counter: 4 out of 10.0
EarlyStopping counter: 5 out of 10.0
EarlyStopping counter: 6 out of 10.0
EarlyStopping counter: 7 out of 10.0
EarlyStopping counter: 8 out of 10.0
EarlyStopping counter: 9 out of 10.0
Validation loss decreased (0.922378 --> 0.922203).  Saving model ...
EarlyStopping counter: 1 out of 10.0
EarlyStopping counter: 2 out of 10.0
EarlyStopping counter: 3 out of 10.0
EarlyStopping counter: 4 out of 10.0
EarlyStopping counter: 5 out of 10.0
EarlyStopping counter: 6 out of 10.0
EarlyStopping counter: 7 out of 10.0
EarlyStopping counter: 8 out of 10.0
EarlyStopping counter: 9 out of 10.0
EarlyStopping counter: 10 out of 10.0
/localscratch/yinan.29351697.0/env/lib/python3.7/site-packages/torch/nn/functional.py:1794: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.
  warnings.warn("nn.functional.tanh is deprecated. Use torch.tanh instead.")
wandb: Waiting for W&B process to finish, PID 79270... (success).
wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: \ 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: | 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: / 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: \ 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: | 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: / 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: \ 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: | 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: / 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb:                                                                                
wandb: Run history:
wandb:     e_F1 ▁▁▃▄▄▄▅▅▅▆▆▆▇▇▇▇▇▇██████████████████████
wandb:   e_loss █▇▇▆▆▆▆▅▅▄▄▄▃▃▃▃▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:     t_F1 ▁▁▂▃▃▄▄▅▅▅▅▅▆▆▆▆▆▆▆▆▇▇▇▇▇▇▇▇▇▇▇▇███████▇
wandb:   t_loss █▇▇▇▆▆▆▆▆▅▅▅▅▄▄▄▄▄▄▃▃▃▃▃▃▂▂▂▂▂▂▂▁▂▂▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:     e_F1 64.54918
wandb:   e_loss 0.92261
wandb:     t_F1 70.9802
wandb:   t_loss 0.72575
wandb: 
wandb: Synced 4 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Synced balmy-terrain-2: https://wandb.ai/yinanazhou/xl_512_bs_8_lr_1e06_es_10_lc_True_nr_False_sr_False_stem_False_lemma_True_repeat_4_fold_2/runs/3elsa316
wandb: Find logs at: ./wandb/run-20220324_174152-3elsa316/logs/debug.log
wandb: 

wandb: wandb version 0.12.11 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
2022-03-24 19:22:15.887140: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1
wandb: Tracking run with wandb version 0.12.5
wandb: Syncing run wandering-thunder-2
wandb: ⭐️ View project at https://wandb.ai/yinanazhou/xl_512_bs_8_lr_1e06_es_10_lc_True_nr_False_sr_False_stem_False_lemma_True_repeat_5_fold_1
wandb: 🚀 View run at https://wandb.ai/yinanazhou/xl_512_bs_8_lr_1e06_es_10_lc_True_nr_False_sr_False_stem_False_lemma_True_repeat_5_fold_1/runs/3o8uyjb2
wandb: Run data is saved locally in /project/6002780/yinan/Thesis_MER_Lyrics/lyric-emotion/wandb/run-20220324_192213-3o8uyjb2
wandb: Run `wandb offline` to turn off syncing.

Validation loss decreased (inf --> 1.476364).  Saving model ...
Validation loss decreased (1.476364 --> 1.440225).  Saving model ...
Validation loss decreased (1.440225 --> 1.414787).  Saving model ...
Validation loss decreased (1.414787 --> 1.397220).  Saving model ...
Validation loss decreased (1.397220 --> 1.384119).  Saving model ...
Validation loss decreased (1.384119 --> 1.373538).  Saving model ...
Validation loss decreased (1.373538 --> 1.365552).  Saving model ...
Validation loss decreased (1.365552 --> 1.358867).  Saving model ...
Validation loss decreased (1.358867 --> 1.352931).  Saving model ...
Validation loss decreased (1.352931 --> 1.347419).  Saving model ...
Validation loss decreased (1.347419 --> 1.342021).  Saving model ...
Validation loss decreased (1.342021 --> 1.336999).  Saving model ...
Validation loss decreased (1.336999 --> 1.332360).  Saving model ...
Validation loss decreased (1.332360 --> 1.327551).  Saving model ...
Validation loss decreased (1.327551 --> 1.322350).  Saving model ...
Validation loss decreased (1.322350 --> 1.317014).  Saving model ...
Validation loss decreased (1.317014 --> 1.311694).  Saving model ...
Validation loss decreased (1.311694 --> 1.306701).  Saving model ...
Validation loss decreased (1.306701 --> 1.301544).  Saving model ...
Validation loss decreased (1.301544 --> 1.296379).  Saving model ...
Validation loss decreased (1.296379 --> 1.290622).  Saving model ...
Validation loss decreased (1.290622 --> 1.284940).  Saving model ...
Validation loss decreased (1.284940 --> 1.279289).  Saving model ...
Validation loss decreased (1.279289 --> 1.272832).  Saving model ...
Validation loss decreased (1.272832 --> 1.267066).  Saving model ...
Validation loss decreased (1.267066 --> 1.260551).  Saving model ...
Validation loss decreased (1.260551 --> 1.252719).  Saving model ...
Validation loss decreased (1.252719 --> 1.245316).  Saving model ...
Validation loss decreased (1.245316 --> 1.237974).  Saving model ...
Validation loss decreased (1.237974 --> 1.229747).  Saving model ...
Validation loss decreased (1.229747 --> 1.222314).  Saving model ...
Validation loss decreased (1.222314 --> 1.213662).  Saving model ...
Validation loss decreased (1.213662 --> 1.205867).  Saving model ...
Validation loss decreased (1.205867 --> 1.198659).  Saving model ...
Validation loss decreased (1.198659 --> 1.188604).  Saving model ...
Validation loss decreased (1.188604 --> 1.180480).  Saving model ...
Validation loss decreased (1.180480 --> 1.173484).  Saving model ...
Validation loss decreased (1.173484 --> 1.167051).  Saving model ...
Validation loss decreased (1.167051 --> 1.160240).  Saving model ...
Validation loss decreased (1.160240 --> 1.153844).  Saving model ...
Validation loss decreased (1.153844 --> 1.148034).  Saving model ...
Validation loss decreased (1.148034 --> 1.140747).  Saving model ...
Validation loss decreased (1.140747 --> 1.133351).  Saving model ...
Validation loss decreased (1.133351 --> 1.127666).  Saving model ...
Validation loss decreased (1.127666 --> 1.123097).  Saving model ...
Validation loss decreased (1.123097 --> 1.117553).  Saving model ...
Validation loss decreased (1.117553 --> 1.112581).  Saving model ...
Validation loss decreased (1.112581 --> 1.107965).  Saving model ...
Validation loss decreased (1.107965 --> 1.103037).  Saving model ...
Validation loss decreased (1.103037 --> 1.097565).  Saving model ...
Validation loss decreased (1.097565 --> 1.092969).  Saving model ...
Validation loss decreased (1.092969 --> 1.087960).  Saving model ...
Validation loss decreased (1.087960 --> 1.085178).  Saving model ...
Validation loss decreased (1.085178 --> 1.080948).  Saving model ...
Validation loss decreased (1.080948 --> 1.077107).  Saving model ...
Validation loss decreased (1.077107 --> 1.074271).  Saving model ...
Validation loss decreased (1.074271 --> 1.070763).  Saving model ...
Validation loss decreased (1.070763 --> 1.068377).  Saving model ...
Validation loss decreased (1.068377 --> 1.064897).  Saving model ...
Validation loss decreased (1.064897 --> 1.061070).  Saving model ...
Validation loss decreased (1.061070 --> 1.058696).  Saving model ...
Validation loss decreased (1.058696 --> 1.054009).  Saving model ...
Validation loss decreased (1.054009 --> 1.049463).  Saving model ...
Validation loss decreased (1.049463 --> 1.046960).  Saving model ...
Validation loss decreased (1.046960 --> 1.042353).  Saving model ...
Validation loss decreased (1.042353 --> 1.040144).  Saving model ...
Validation loss decreased (1.040144 --> 1.038630).  Saving model ...
Validation loss decreased (1.038630 --> 1.038610).  Saving model ...
Validation loss decreased (1.038610 --> 1.033517).  Saving model ...
Validation loss decreased (1.033517 --> 1.027435).  Saving model ...
Validation loss decreased (1.027435 --> 1.023791).  Saving model ...
Validation loss decreased (1.023791 --> 1.021848).  Saving model ...
Validation loss decreased (1.021848 --> 1.019942).  Saving model ...
Validation loss decreased (1.019942 --> 1.019211).  Saving model ...
Validation loss decreased (1.019211 --> 1.017108).  Saving model ...
Validation loss decreased (1.017108 --> 1.011401).  Saving model ...
Validation loss decreased (1.011401 --> 1.010816).  Saving model ...
Validation loss decreased (1.010816 --> 1.008887).  Saving model ...
Validation loss decreased (1.008887 --> 1.005680).  Saving model ...
Validation loss decreased (1.005680 --> 1.004499).  Saving model ...
Validation loss decreased (1.004499 --> 1.001162).  Saving model ...
Validation loss decreased (1.001162 --> 1.000457).  Saving model ...
Validation loss decreased (1.000457 --> 0.999677).  Saving model ...
Validation loss decreased (0.999677 --> 0.998617).  Saving model ...
Validation loss decreased (0.998617 --> 0.998486).  Saving model ...
EarlyStopping counter: 1 out of 10.0
Validation loss decreased (0.998486 --> 0.992208).  Saving model ...
Validation loss decreased (0.992208 --> 0.990290).  Saving model ...
Validation loss decreased (0.990290 --> 0.989693).  Saving model ...
EarlyStopping counter: 1 out of 10.0
Validation loss decreased (0.989693 --> 0.986073).  Saving model ...
Validation loss decreased (0.986073 --> 0.984746).  Saving model ...
Validation loss decreased (0.984746 --> 0.983408).  Saving model ...
Validation loss decreased (0.983408 --> 0.979969).  Saving model ...
EarlyStopping counter: 1 out of 10.0
Validation loss decreased (0.979969 --> 0.979814).  Saving model ...
Validation loss decreased (0.979814 --> 0.978901).  Saving model ...
EarlyStopping counter: 1 out of 10.0
EarlyStopping counter: 2 out of 10.0
EarlyStopping counter: 3 out of 10.0
Validation loss decreased (0.978901 --> 0.977977).  Saving model ...
Validation loss decreased (0.977977 --> 0.976090).  Saving model ...
EarlyStopping counter: 1 out of 10.0
Validation loss decreased (0.976090 --> 0.975945).  Saving model ...
Validation loss decreased (0.975945 --> 0.975698).  Saving model ...
Validation loss decreased (0.975698 --> 0.974615).  Saving model ...
Validation loss decreased (0.974615 --> 0.970243).  Saving model ...
Validation loss decreased (0.970243 --> 0.967238).  Saving model ...
EarlyStopping counter: 1 out of 10.0
EarlyStopping counter: 2 out of 10.0
EarlyStopping counter: 3 out of 10.0
EarlyStopping counter: 4 out of 10.0
Validation loss decreased (0.967238 --> 0.964410).  Saving model ...
Validation loss decreased (0.964410 --> 0.963326).  Saving model ...
EarlyStopping counter: 1 out of 10.0
EarlyStopping counter: 2 out of 10.0
EarlyStopping counter: 3 out of 10.0
EarlyStopping counter: 4 out of 10.0
EarlyStopping counter: 5 out of 10.0
EarlyStopping counter: 6 out of 10.0
EarlyStopping counter: 7 out of 10.0
Validation loss decreased (0.963326 --> 0.962247).  Saving model ...
Validation loss decreased (0.962247 --> 0.961361).  Saving model ...
EarlyStopping counter: 1 out of 10.0
EarlyStopping counter: 2 out of 10.0
EarlyStopping counter: 3 out of 10.0
EarlyStopping counter: 4 out of 10.0
Validation loss decreased (0.961361 --> 0.960602).  Saving model ...
EarlyStopping counter: 1 out of 10.0
EarlyStopping counter: 2 out of 10.0
EarlyStopping counter: 3 out of 10.0
Validation loss decreased (0.960602 --> 0.959454).  Saving model ...
EarlyStopping counter: 1 out of 10.0
EarlyStopping counter: 2 out of 10.0
EarlyStopping counter: 3 out of 10.0
EarlyStopping counter: 4 out of 10.0
EarlyStopping counter: 5 out of 10.0
Validation loss decreased (0.959454 --> 0.959333).  Saving model ...
EarlyStopping counter: 1 out of 10.0
EarlyStopping counter: 2 out of 10.0
EarlyStopping counter: 3 out of 10.0
EarlyStopping counter: 4 out of 10.0
EarlyStopping counter: 5 out of 10.0
Validation loss decreased (0.959333 --> 0.957876).  Saving model ...
EarlyStopping counter: 1 out of 10.0
EarlyStopping counter: 2 out of 10.0
EarlyStopping counter: 3 out of 10.0
EarlyStopping counter: 4 out of 10.0
EarlyStopping counter: 5 out of 10.0
EarlyStopping counter: 6 out of 10.0
EarlyStopping counter: 7 out of 10.0
EarlyStopping counter: 8 out of 10.0
EarlyStopping counter: 9 out of 10.0
EarlyStopping counter: 10 out of 10.0
/localscratch/yinan.29351697.0/env/lib/python3.7/site-packages/torch/nn/functional.py:1794: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.
  warnings.warn("nn.functional.tanh is deprecated. Use torch.tanh instead.")
wandb: Waiting for W&B process to finish, PID 84608... (success).
wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: \ 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: | 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: / 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: \ 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: | 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: / 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: \ 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: | 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: / 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: \ 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: | 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb:                                                                                
wandb: Run history:
wandb:     e_F1 ▁▁▃▄▄▅▅▆▆▆▇▇▇▇▇▇▇▇▇▇▇▇▇▇███▇████████████
wandb:   e_loss █▇▇▆▆▆▆▅▅▄▄▃▃▃▃▂▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:     t_F1 ▁▂▃▃▃▄▄▅▅▅▅▅▆▅▆▆▆▆▆▆▇▇▇▇▇▇▇▇▇▇▇▇▇█▇█████
wandb:   t_loss █▇▇▇▇▇▆▆▆▅▅▅▅▅▄▄▄▄▄▄▃▃▃▃▃▃▂▂▂▂▂▂▂▂▂▁▂▂▁▁
wandb: 
wandb: Run summary:
wandb:     e_F1 60.97379
wandb:   e_loss 0.96073
wandb:     t_F1 77.2043
wandb:   t_loss 0.6703
wandb: 
wandb: Synced 4 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Synced wandering-thunder-2: https://wandb.ai/yinanazhou/xl_512_bs_8_lr_1e06_es_10_lc_True_nr_False_sr_False_stem_False_lemma_True_repeat_5_fold_1/runs/3o8uyjb2
wandb: Find logs at: ./wandb/run-20220324_192213-3o8uyjb2/logs/debug.log
wandb: 

wandb: wandb version 0.12.11 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
2022-03-24 21:02:03.580189: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1
wandb: Tracking run with wandb version 0.12.5
wandb: Syncing run ancient-hill-2
wandb: ⭐️ View project at https://wandb.ai/yinanazhou/xl_512_bs_8_lr_1e06_es_10_lc_True_nr_False_sr_False_stem_False_lemma_True_repeat_5_fold_2
wandb: 🚀 View run at https://wandb.ai/yinanazhou/xl_512_bs_8_lr_1e06_es_10_lc_True_nr_False_sr_False_stem_False_lemma_True_repeat_5_fold_2/runs/1awvmd7o
wandb: Run data is saved locally in /project/6002780/yinan/Thesis_MER_Lyrics/lyric-emotion/wandb/run-20220324_210201-1awvmd7o
wandb: Run `wandb offline` to turn off syncing.

Validation loss decreased (inf --> 1.515249).  Saving model ...
Validation loss decreased (1.515249 --> 1.469255).  Saving model ...
Validation loss decreased (1.469255 --> 1.435391).  Saving model ...
Validation loss decreased (1.435391 --> 1.410137).  Saving model ...
Validation loss decreased (1.410137 --> 1.390046).  Saving model ...
Validation loss decreased (1.390046 --> 1.375457).  Saving model ...
Validation loss decreased (1.375457 --> 1.364916).  Saving model ...
Validation loss decreased (1.364916 --> 1.356679).  Saving model ...
Validation loss decreased (1.356679 --> 1.349711).  Saving model ...
Validation loss decreased (1.349711 --> 1.343438).  Saving model ...
Validation loss decreased (1.343438 --> 1.336726).  Saving model ...
Validation loss decreased (1.336726 --> 1.330648).  Saving model ...
Validation loss decreased (1.330648 --> 1.325295).  Saving model ...
Validation loss decreased (1.325295 --> 1.319142).  Saving model ...
Validation loss decreased (1.319142 --> 1.313045).  Saving model ...
Validation loss decreased (1.313045 --> 1.306921).  Saving model ...
Validation loss decreased (1.306921 --> 1.299767).  Saving model ...
Validation loss decreased (1.299767 --> 1.292999).  Saving model ...
Validation loss decreased (1.292999 --> 1.286505).  Saving model ...
Validation loss decreased (1.286505 --> 1.278633).  Saving model ...
Validation loss decreased (1.278633 --> 1.270446).  Saving model ...
Validation loss decreased (1.270446 --> 1.263051).  Saving model ...
Validation loss decreased (1.263051 --> 1.255654).  Saving model ...
Validation loss decreased (1.255654 --> 1.249098).  Saving model ...
Validation loss decreased (1.249098 --> 1.241574).  Saving model ...
Validation loss decreased (1.241574 --> 1.233568).  Saving model ...
Validation loss decreased (1.233568 --> 1.225232).  Saving model ...
Validation loss decreased (1.225232 --> 1.217106).  Saving model ...
Validation loss decreased (1.217106 --> 1.209168).  Saving model ...
Validation loss decreased (1.209168 --> 1.201051).  Saving model ...
Validation loss decreased (1.201051 --> 1.193482).  Saving model ...
Validation loss decreased (1.193482 --> 1.186403).  Saving model ...
Validation loss decreased (1.186403 --> 1.180454).  Saving model ...
Validation loss decreased (1.180454 --> 1.172301).  Saving model ...
Validation loss decreased (1.172301 --> 1.166482).  Saving model ...
Validation loss decreased (1.166482 --> 1.160058).  Saving model ...
Validation loss decreased (1.160058 --> 1.153338).  Saving model ...
Validation loss decreased (1.153338 --> 1.145603).  Saving model ...
Validation loss decreased (1.145603 --> 1.138715).  Saving model ...
Validation loss decreased (1.138715 --> 1.132574).  Saving model ...
Validation loss decreased (1.132574 --> 1.127872).  Saving model ...
Validation loss decreased (1.127872 --> 1.121710).  Saving model ...
Validation loss decreased (1.121710 --> 1.116342).  Saving model ...
Validation loss decreased (1.116342 --> 1.108868).  Saving model ...
Validation loss decreased (1.108868 --> 1.103045).  Saving model ...
Validation loss decreased (1.103045 --> 1.097702).  Saving model ...
Validation loss decreased (1.097702 --> 1.092813).  Saving model ...
Validation loss decreased (1.092813 --> 1.088371).  Saving model ...
Validation loss decreased (1.088371 --> 1.083252).  Saving model ...
Validation loss decreased (1.083252 --> 1.080001).  Saving model ...
Validation loss decreased (1.080001 --> 1.073890).  Saving model ...
Validation loss decreased (1.073890 --> 1.071577).  Saving model ...
Validation loss decreased (1.071577 --> 1.066043).  Saving model ...
Validation loss decreased (1.066043 --> 1.060072).  Saving model ...
Validation loss decreased (1.060072 --> 1.057068).  Saving model ...
Validation loss decreased (1.057068 --> 1.053183).  Saving model ...
Validation loss decreased (1.053183 --> 1.049990).  Saving model ...
Validation loss decreased (1.049990 --> 1.043394).  Saving model ...
Validation loss decreased (1.043394 --> 1.039721).  Saving model ...
Validation loss decreased (1.039721 --> 1.034451).  Saving model ...
Validation loss decreased (1.034451 --> 1.029713).  Saving model ...
Validation loss decreased (1.029713 --> 1.026677).  Saving model ...
Validation loss decreased (1.026677 --> 1.023267).  Saving model ...
Validation loss decreased (1.023267 --> 1.020539).  Saving model ...
Validation loss decreased (1.020539 --> 1.015598).  Saving model ...
Validation loss decreased (1.015598 --> 1.012492).  Saving model ...
Validation loss decreased (1.012492 --> 1.008802).  Saving model ...
Validation loss decreased (1.008802 --> 1.006302).  Saving model ...
Validation loss decreased (1.006302 --> 1.003153).  Saving model ...
Validation loss decreased (1.003153 --> 1.000523).  Saving model ...
Validation loss decreased (1.000523 --> 0.995970).  Saving model ...
Validation loss decreased (0.995970 --> 0.993099).  Saving model ...
Validation loss decreased (0.993099 --> 0.990410).  Saving model ...
Validation loss decreased (0.990410 --> 0.990354).  Saving model ...
Validation loss decreased (0.990354 --> 0.986462).  Saving model ...
Validation loss decreased (0.986462 --> 0.982633).  Saving model ...
Validation loss decreased (0.982633 --> 0.980256).  Saving model ...
Validation loss decreased (0.980256 --> 0.979217).  Saving model ...
Validation loss decreased (0.979217 --> 0.976186).  Saving model ...
Validation loss decreased (0.976186 --> 0.973723).  Saving model ...
Validation loss decreased (0.973723 --> 0.972827).  Saving model ...
Validation loss decreased (0.972827 --> 0.969978).  Saving model ...
Validation loss decreased (0.969978 --> 0.967237).  Saving model ...
Validation loss decreased (0.967237 --> 0.964234).  Saving model ...
Validation loss decreased (0.964234 --> 0.961191).  Saving model ...
Validation loss decreased (0.961191 --> 0.958836).  Saving model ...
Validation loss decreased (0.958836 --> 0.956065).  Saving model ...
Validation loss decreased (0.956065 --> 0.952629).  Saving model ...
Validation loss decreased (0.952629 --> 0.952111).  Saving model ...
Validation loss decreased (0.952111 --> 0.949729).  Saving model ...
Validation loss decreased (0.949729 --> 0.949609).  Saving model ...
Validation loss decreased (0.949609 --> 0.947636).  Saving model ...
Validation loss decreased (0.947636 --> 0.946301).  Saving model ...
EarlyStopping counter: 1 out of 10.0
EarlyStopping counter: 2 out of 10.0
EarlyStopping counter: 3 out of 10.0
Validation loss decreased (0.946301 --> 0.941935).  Saving model ...
Validation loss decreased (0.941935 --> 0.940052).  Saving model ...
Validation loss decreased (0.940052 --> 0.937756).  Saving model ...
Validation loss decreased (0.937756 --> 0.936733).  Saving model ...
EarlyStopping counter: 1 out of 10.0
Validation loss decreased (0.936733 --> 0.935851).  Saving model ...
EarlyStopping counter: 1 out of 10.0
Validation loss decreased (0.935851 --> 0.933752).  Saving model ...
Validation loss decreased (0.933752 --> 0.932361).  Saving model ...
Validation loss decreased (0.932361 --> 0.931892).  Saving model ...
EarlyStopping counter: 1 out of 10.0
Validation loss decreased (0.931892 --> 0.930532).  Saving model ...
Validation loss decreased (0.930532 --> 0.926275).  Saving model ...
EarlyStopping counter: 1 out of 10.0
EarlyStopping counter: 2 out of 10.0
Validation loss decreased (0.926275 --> 0.925233).  Saving model ...
Validation loss decreased (0.925233 --> 0.923982).  Saving model ...
EarlyStopping counter: 1 out of 10.0
EarlyStopping counter: 2 out of 10.0
Validation loss decreased (0.923982 --> 0.922570).  Saving model ...
Validation loss decreased (0.922570 --> 0.920503).  Saving model ...
EarlyStopping counter: 1 out of 10.0
Validation loss decreased (0.920503 --> 0.920315).  Saving model ...
EarlyStopping counter: 1 out of 10.0
Validation loss decreased (0.920315 --> 0.920261).  Saving model ...
Validation loss decreased (0.920261 --> 0.920088).  Saving model ...
EarlyStopping counter: 1 out of 10.0
EarlyStopping counter: 2 out of 10.0
EarlyStopping counter: 3 out of 10.0
Validation loss decreased (0.920088 --> 0.920006).  Saving model ...
Validation loss decreased (0.920006 --> 0.919010).  Saving model ...
Validation loss decreased (0.919010 --> 0.917676).  Saving model ...
EarlyStopping counter: 1 out of 10.0
EarlyStopping counter: 2 out of 10.0
Validation loss decreased (0.917676 --> 0.916232).  Saving model ...
EarlyStopping counter: 1 out of 10.0
EarlyStopping counter: 2 out of 10.0
Validation loss decreased (0.916232 --> 0.915419).  Saving model ...
EarlyStopping counter: 1 out of 10.0
EarlyStopping counter: 2 out of 10.0
EarlyStopping counter: 3 out of 10.0
EarlyStopping counter: 4 out of 10.0
EarlyStopping counter: 5 out of 10.0
Validation loss decreased (0.915419 --> 0.915008).  Saving model ...
Validation loss decreased (0.915008 --> 0.913972).  Saving model ...
EarlyStopping counter: 1 out of 10.0
EarlyStopping counter: 2 out of 10.0
EarlyStopping counter: 3 out of 10.0
EarlyStopping counter: 4 out of 10.0
EarlyStopping counter: 5 out of 10.0
EarlyStopping counter: 6 out of 10.0
EarlyStopping counter: 7 out of 10.0
EarlyStopping counter: 8 out of 10.0
EarlyStopping counter: 9 out of 10.0
EarlyStopping counter: 10 out of 10.0
/localscratch/yinan.29351697.0/env/lib/python3.7/site-packages/torch/nn/functional.py:1794: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.
  warnings.warn("nn.functional.tanh is deprecated. Use torch.tanh instead.")
wandb: Waiting for W&B process to finish, PID 89920... (success).
wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: \ 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: | 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: / 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: \ 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: | 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: / 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: \ 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: | 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: / 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb:                                                                                
wandb: Run history:
wandb:     e_F1 ▁▂▄▅▄▅▅▅▆▆▇▇▇▇▇▇▇▇██████████████████████
wandb:   e_loss █▇▇▆▆▆▅▅▄▄▄▄▃▃▃▃▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:     t_F1 ▁▂▃▃▄▄▄▄▅▅▆▅▆▆▆▇▇▇▇▇▇▇▇▇▇▇▇▇▇███████▇███
wandb:   t_loss █▇▇▇▆▆▆▆▅▅▅▅▅▄▄▃▃▃▃▃▃▃▃▃▂▂▂▂▂▂▂▁▁▂▁▂▁▁▁▁
wandb: 
wandb: Run summary:
wandb:     e_F1 62.83459
wandb:   e_loss 0.91736
wandb:     t_F1 73.2957
wandb:   t_loss 0.70015
wandb: 
wandb: Synced 4 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Synced ancient-hill-2: https://wandb.ai/yinanazhou/xl_512_bs_8_lr_1e06_es_10_lc_True_nr_False_sr_False_stem_False_lemma_True_repeat_5_fold_2/runs/1awvmd7o
wandb: Find logs at: ./wandb/run-20220324_210201-1awvmd7o/logs/debug.log
wandb: 

