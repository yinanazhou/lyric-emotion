Unloading StdEnv/2020

Due to MODULEPATH changes, the following have been reloaded:
  1) mii/1.1.1


The following have been reloaded with a version change:
  1) python/3.8.2 => python/3.7.4

Using base prefix '/cvmfs/soft.computecanada.ca/easybuild/software/2017/Core/python/3.7.4'
New python executable in /localscratch/yinan.29152578.0/env/bin/python
Installing setuptools, pip, wheel...
done.
Ignoring pip: markers 'python_version < "3"' don't match your environment
Looking in links: /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/nix/avx2, /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/nix/generic, /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic
Collecting pip
Installing collected packages: pip
  Found existing installation: pip 19.1.1
    Uninstalling pip-19.1.1:
      Successfully uninstalled pip-19.1.1
Successfully installed pip-21.2.3+computecanada
Looking in links: /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/nix/avx2, /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/nix/generic, /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/keras-2.8.0+computecanada-py2.py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/Keras_Preprocessing-1.1.2+computecanada-py3-none-any.whl
Requirement already satisfied: matplotlib in /cvmfs/soft.computecanada.ca/easybuild/software/2017/Core/scipy-stack/2019a/lib/python3.7/site-packages (from -r requirements.txt (line 3)) (3.0.2)
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/nltk-3.6.5+computecanada-py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/scikit_learn-0.22.1+computecanada-cp37-cp37m-linux_x86_64.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/tensorboard-2.3.0+computecanada-py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/tensorboard_plugin_wit-1.7.0+computecanada-py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/tensorflow_gpu-2.3.0+computecanada-cp37-cp37m-linux_x86_64.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/tensorflow_estimator-2.3.0+computecanada-py2.py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/tokenizers-0.5.2+computecanada-cp37-cp37m-linux_x86_64.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/nix/avx2/torch-1.4.0+computecanada-cp37-cp37m-linux_x86_64.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/torchtext-0.6.0+computecanada-py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/torchvision-0.8.2+computecanada-cp37-cp37m-linux_x86_64.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/transformers-2.5.1+computecanada-py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/urllib3-1.26.7+computecanada-py2.py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/tqdm-4.63.0+computecanada-py2.py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/click-8.0.4+computecanada-py3-none-any.whl
ERROR: Could not find a version that satisfies the requirement regex>=2021.8.3 (from nltk) (from versions: 2018.1.10+computecanada, 2019.11.1+computecanada, 2020.11.13+computecanada)
ERROR: No matching distribution found for regex>=2021.8.3
Looking in links: /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/nix/avx2, /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/nix/generic, /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic
ERROR: Could not find a version that satisfies the requirement numpy==1.20.0+computacanada (from versions: 1.15.0+computecanada, 1.15.2+computecanada, 1.15.4+computecanada, 1.16.0+computecanada, 1.16.2+computecanada, 1.16.3+computecanada, 1.17.4+computecanada, 1.18.1+computecanada, 1.18.4+computecanada, 1.19.1+computecanada, 1.19.2+computecanada, 1.20.2+computecanada)
ERROR: No matching distribution found for numpy==1.20.0+computacanada
Looking in links: /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/nix/avx2, /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/nix/generic, /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/wandb-0.12.5+computecanada-py2.py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/six-1.16.0+computecanada-py2.py3-none-any.whl
Requirement already satisfied: python-dateutil>=2.6.1 in /cvmfs/soft.computecanada.ca/easybuild/software/2017/Core/scipy-stack/2019a/lib/python3.7/site-packages (from wandb) (2.7.5)
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/configparser-5.0.2+computecanada-py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/protobuf-3.19.4+computecanada-py2.py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/PyYAML-5.3.1+computecanada-cp37-cp37m-linux_x86_64.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/click-8.0.4+computecanada-py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/yaspin-2.1.0+computecanada-py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/GitPython-3.1.24+computecanada-py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/sentry_sdk-1.5.0+computecanada-py2.py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/promise-2.3+computecanada-py3-none-any.whl
Requirement already satisfied: requests<3,>=2.0.0 in /cvmfs/soft.computecanada.ca/easybuild/software/2017/Core/scipy-stack/2019a/lib/python3.7/site-packages (from wandb) (2.21.0)
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/pathtools-0.1.2+computecanada-py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/shortuuid-1.0.1+computecanada-py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/docker_pycreds-0.4.0+computecanada-py2.py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/psutil-5.7.3+computecanada-cp37-cp37m-linux_x86_64.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/subprocess32-3.5.4+computecanada-py3-none-any.whl
Requirement already satisfied: importlib-metadata in /cvmfs/soft.computecanada.ca/easybuild/software/2017/Core/scipy-stack/2019a/lib/python3.7/site-packages (from Click!=8.0.0,>=7.0->wandb) (0.8)
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/typing_extensions-4.0.1+computecanada-py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/gitdb-4.0.9+computecanada-py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/smmap-5.0.0+computecanada-py3-none-any.whl
Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /cvmfs/soft.computecanada.ca/easybuild/software/2017/Core/scipy-stack/2019a/lib/python3.7/site-packages (from requests<3,>=2.0.0->wandb) (3.0.4)
Requirement already satisfied: certifi>=2017.4.17 in /cvmfs/soft.computecanada.ca/easybuild/software/2017/Core/scipy-stack/2019a/lib/python3.7/site-packages (from requests<3,>=2.0.0->wandb) (2018.11.29)
Requirement already satisfied: idna<2.9,>=2.5 in /cvmfs/soft.computecanada.ca/easybuild/software/2017/Core/scipy-stack/2019a/lib/python3.7/site-packages (from requests<3,>=2.0.0->wandb) (2.8)
Requirement already satisfied: urllib3<1.25,>=1.21.1 in /cvmfs/soft.computecanada.ca/easybuild/software/2017/Core/scipy-stack/2019a/lib/python3.7/site-packages (from requests<3,>=2.0.0->wandb) (1.24.1)
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/termcolor-1.1.0+computecanada-py3-none-any.whl
Requirement already satisfied: zipp>=0.3.2 in /cvmfs/soft.computecanada.ca/easybuild/software/2017/Core/scipy-stack/2019a/lib/python3.7/site-packages (from importlib-metadata->Click!=8.0.0,>=7.0->wandb) (0.3.3)
Installing collected packages: smmap, typing-extensions, termcolor, six, gitdb, yaspin, subprocess32, shortuuid, sentry-sdk, PyYAML, psutil, protobuf, promise, pathtools, GitPython, docker-pycreds, configparser, Click, wandb
  Attempting uninstall: six
    Found existing installation: six 1.12.0
    Not uninstalling six at /cvmfs/soft.computecanada.ca/easybuild/software/2017/Core/scipy-stack/2019a/lib/python3.7/site-packages, outside environment /localscratch/yinan.29152578.0/env
    Can't uninstall 'six'. No files were found to uninstall.
Successfully installed Click-8.0.4+computecanada GitPython-3.1.24+computecanada PyYAML-5.3.1+computecanada configparser-5.0.2+computecanada docker-pycreds-0.4.0+computecanada gitdb-4.0.9+computecanada pathtools-0.1.2+computecanada promise-2.3+computecanada protobuf-3.19.4+computecanada psutil-5.7.3+computecanada sentry-sdk-1.5.0+computecanada shortuuid-1.0.1+computecanada six-1.16.0+computecanada smmap-5.0.0+computecanada subprocess32-3.5.4+computecanada termcolor-1.1.0+computecanada typing-extensions-4.0.1+computecanada wandb-0.12.5+computecanada yaspin-2.1.0+computecanada
Looking in links: /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/nix/avx2, /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/nix/generic, /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic
ERROR: Could not find a version that satisfies the requirement sagemaker (from versions: none)
ERROR: No matching distribution found for sagemaker
Looking in links: /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/nix/avx2, /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/nix/generic, /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/torch-1.9.1+computecanada-cp37-cp37m-linux_x86_64.whl
Requirement already satisfied: typing-extensions in /localscratch/yinan.29152578.0/env/lib/python3.7/site-packages (from torch) (4.0.1+computecanada)
Installing collected packages: torch
Successfully installed torch-1.9.1+computecanada
Looking in links: /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/nix/avx2, /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/nix/generic, /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/transformers-2.5.1+computecanada-py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/sentencepiece-0.1.91+computecanada-cp37-cp37m-linux_x86_64.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/boto3-1.21.14+computecanada-py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/sacremoses-0.0.46+computecanada-py3-none-any.whl
Requirement already satisfied: requests in /cvmfs/soft.computecanada.ca/easybuild/software/2017/Core/scipy-stack/2019a/lib/python3.7/site-packages (from transformers==2.5.1+computecanada) (2.21.0)
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/tokenizers-0.5.2+computecanada-cp37-cp37m-linux_x86_64.whl
Requirement already satisfied: numpy in /cvmfs/soft.computecanada.ca/easybuild/software/2017/Core/scipy-stack/2019a/lib/python3.7/site-packages (from transformers==2.5.1+computecanada) (1.16.0)
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/tqdm-4.63.0+computecanada-py2.py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/filelock-3.4.2+computecanada-py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/regex-2020.11.13+computecanada-cp37-cp37m-linux_x86_64.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/jmespath-0.10.0+computecanada-py2.py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/botocore-1.24.14+computecanada-py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/s3transfer-0.5.1+computecanada-py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/urllib3-1.26.8+computecanada-py2.py3-none-any.whl
Requirement already satisfied: python-dateutil<3.0.0,>=2.1 in /cvmfs/soft.computecanada.ca/easybuild/software/2017/Core/scipy-stack/2019a/lib/python3.7/site-packages (from botocore<1.25.0,>=1.24.14->boto3->transformers==2.5.1+computecanada) (2.7.5)
Requirement already satisfied: six>=1.5 in /localscratch/yinan.29152578.0/env/lib/python3.7/site-packages (from python-dateutil<3.0.0,>=2.1->botocore<1.25.0,>=1.24.14->boto3->transformers==2.5.1+computecanada) (1.16.0+computecanada)
Requirement already satisfied: idna<2.9,>=2.5 in /cvmfs/soft.computecanada.ca/easybuild/software/2017/Core/scipy-stack/2019a/lib/python3.7/site-packages (from requests->transformers==2.5.1+computecanada) (2.8)
Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /cvmfs/soft.computecanada.ca/easybuild/software/2017/Core/scipy-stack/2019a/lib/python3.7/site-packages (from requests->transformers==2.5.1+computecanada) (3.0.4)
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/requests-2.27.1+computecanada-py2.py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/charset_normalizer-2.0.12+computecanada-py3-none-any.whl
Requirement already satisfied: certifi>=2017.4.17 in /cvmfs/soft.computecanada.ca/easybuild/software/2017/Core/scipy-stack/2019a/lib/python3.7/site-packages (from requests->transformers==2.5.1+computecanada) (2018.11.29)
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/joblib-1.1.0+computecanada-py2.py3-none-any.whl
Requirement already satisfied: click in /localscratch/yinan.29152578.0/env/lib/python3.7/site-packages (from sacremoses->transformers==2.5.1+computecanada) (8.0.4+computecanada)
Requirement already satisfied: importlib-metadata in /cvmfs/soft.computecanada.ca/easybuild/software/2017/Core/scipy-stack/2019a/lib/python3.7/site-packages (from click->sacremoses->transformers==2.5.1+computecanada) (0.8)
Requirement already satisfied: zipp>=0.3.2 in /cvmfs/soft.computecanada.ca/easybuild/software/2017/Core/scipy-stack/2019a/lib/python3.7/site-packages (from importlib-metadata->click->sacremoses->transformers==2.5.1+computecanada) (0.3.3)
Installing collected packages: urllib3, jmespath, botocore, tqdm, s3transfer, regex, joblib, charset-normalizer, tokenizers, sentencepiece, sacremoses, requests, filelock, boto3, transformers
  Attempting uninstall: urllib3
    Found existing installation: urllib3 1.24.1
    Not uninstalling urllib3 at /cvmfs/soft.computecanada.ca/easybuild/software/2017/Core/scipy-stack/2019a/lib/python3.7/site-packages, outside environment /localscratch/yinan.29152578.0/env
    Can't uninstall 'urllib3'. No files were found to uninstall.
  Attempting uninstall: requests
    Found existing installation: requests 2.21.0
    Not uninstalling requests at /cvmfs/soft.computecanada.ca/easybuild/software/2017/Core/scipy-stack/2019a/lib/python3.7/site-packages, outside environment /localscratch/yinan.29152578.0/env
    Can't uninstall 'requests'. No files were found to uninstall.
Successfully installed boto3-1.21.14+computecanada botocore-1.24.14+computecanada charset-normalizer-2.0.12+computecanada filelock-3.4.2+computecanada jmespath-0.10.0+computecanada joblib-1.1.0+computecanada regex-2020.11.13+computecanada requests-2.27.1+computecanada s3transfer-0.5.1+computecanada sacremoses-0.0.46+computecanada sentencepiece-0.1.91+computecanada tokenizers-0.5.2+computecanada tqdm-4.63.0+computecanada transformers-2.5.1+computecanada urllib3-1.26.8+computecanada
Looking in links: /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/nix/avx2, /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/nix/generic, /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/tensorflow_gpu-2.3.0+computecanada-cp37-cp37m-linux_x86_64.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/astunparse-1.6.3+computecanada-py2.py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/tensorboard-2.8.0+computecanada-py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/Keras_Preprocessing-1.1.2+computecanada-py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/tensorflow_estimator-2.3.0+computecanada-py2.py3-none-any.whl
Requirement already satisfied: termcolor>=1.1.0 in /localscratch/yinan.29152578.0/env/lib/python3.7/site-packages (from tensorflow_gpu==2.3.0+computecanada) (1.1.0+computecanada)
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/wrapt-1.11.2+computecanada-cp37-cp37m-linux_x86_64.whl
Requirement already satisfied: six>=1.12.0 in /localscratch/yinan.29152578.0/env/lib/python3.7/site-packages (from tensorflow_gpu==2.3.0+computecanada) (1.16.0+computecanada)
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/grpcio-1.38.0+computecanada-cp37-cp37m-linux_x86_64.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/google_pasta-0.2.0+computecanada-py3-none-any.whl
Requirement already satisfied: wheel>=0.26 in /localscratch/yinan.29152578.0/env/lib/python3.7/site-packages (from tensorflow_gpu==2.3.0+computecanada) (0.33.4)
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/opt_einsum-3.3.0+computecanada-py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/absl_py-1.0.0+computecanada-py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/nix/generic/scipy-1.4.1+computecanada-cp37-cp37m-linux_x86_64.whl
Requirement already satisfied: protobuf>=3.9.2 in /localscratch/yinan.29152578.0/env/lib/python3.7/site-packages (from tensorflow_gpu==2.3.0+computecanada) (3.19.4+computecanada)
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/gast-0.3.3+computecanada-py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/nix/avx2/h5py-2.10.0+computecanada-cp37-cp37m-linux_x86_64.whl
Requirement already satisfied: numpy<1.19.0,>=1.16.0 in /cvmfs/soft.computecanada.ca/easybuild/software/2017/Core/scipy-stack/2019a/lib/python3.7/site-packages (from tensorflow_gpu==2.3.0+computecanada) (1.16.0)
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/tensorboard_plugin_wit-1.8.0+computecanada-py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/Markdown-3.3.6+computecanada-py3-none-any.whl
Requirement already satisfied: requests<3,>=2.21.0 in /localscratch/yinan.29152578.0/env/lib/python3.7/site-packages (from tensorboard<3,>=2.3.0->tensorflow_gpu==2.3.0+computecanada) (2.27.1+computecanada)
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/Werkzeug-2.0.3+computecanada-py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/google_auth_oauthlib-0.4.6+computecanada-py2.py3-none-any.whl
Requirement already satisfied: setuptools>=41.0.0 in /localscratch/yinan.29152578.0/env/lib/python3.7/site-packages (from tensorboard<3,>=2.3.0->tensorflow_gpu==2.3.0+computecanada) (41.0.1)
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/google_auth-2.3.3+computecanada-py2.py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/tensorboard_data_server-0.6.1+computecanada-py3-none-linux_x86_64.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/rsa-4.8+computecanada-py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/pyasn1_modules-0.2.8+computecanada-py2.py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/cachetools-4.2.4+computecanada-py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/requests_oauthlib-1.3.0+computecanada-py2.py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/importlib_metadata-4.10.1+computecanada-py3-none-any.whl
Requirement already satisfied: typing-extensions>=3.6.4 in /localscratch/yinan.29152578.0/env/lib/python3.7/site-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard<3,>=2.3.0->tensorflow_gpu==2.3.0+computecanada) (4.0.1+computecanada)
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/zipp-3.7.0+computecanada-py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/pyasn1-0.4.8+computecanada-py2.py3-none-any.whl
Requirement already satisfied: urllib3<1.27,>=1.21.1 in /localscratch/yinan.29152578.0/env/lib/python3.7/site-packages (from requests<3,>=2.21.0->tensorboard<3,>=2.3.0->tensorflow_gpu==2.3.0+computecanada) (1.26.8+computecanada)
Requirement already satisfied: idna<4,>=2.5 in /cvmfs/soft.computecanada.ca/easybuild/software/2017/Core/scipy-stack/2019a/lib/python3.7/site-packages (from requests<3,>=2.21.0->tensorboard<3,>=2.3.0->tensorflow_gpu==2.3.0+computecanada) (2.8)
Requirement already satisfied: certifi>=2017.4.17 in /cvmfs/soft.computecanada.ca/easybuild/software/2017/Core/scipy-stack/2019a/lib/python3.7/site-packages (from requests<3,>=2.21.0->tensorboard<3,>=2.3.0->tensorflow_gpu==2.3.0+computecanada) (2018.11.29)
Requirement already satisfied: charset-normalizer~=2.0.0 in /localscratch/yinan.29152578.0/env/lib/python3.7/site-packages (from requests<3,>=2.21.0->tensorboard<3,>=2.3.0->tensorflow_gpu==2.3.0+computecanada) (2.0.12+computecanada)
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/oauthlib-3.1.1+computecanada-py2.py3-none-any.whl
Installing collected packages: pyasn1, zipp, rsa, pyasn1-modules, oauthlib, cachetools, requests-oauthlib, importlib-metadata, google-auth, werkzeug, tensorboard-plugin-wit, tensorboard-data-server, markdown, grpcio, google-auth-oauthlib, absl-py, wrapt, tensorflow-estimator, tensorboard, scipy, opt-einsum, keras-preprocessing, h5py, google-pasta, gast, astunparse, tensorflow-gpu
  Attempting uninstall: pyasn1
    Found existing installation: pyasn1 0.4.3
    Not uninstalling pyasn1 at /cvmfs/soft.computecanada.ca/easybuild/software/2017/Core/scipy-stack/2019a/lib/python3.7/site-packages, outside environment /localscratch/yinan.29152578.0/env
    Can't uninstall 'pyasn1'. No files were found to uninstall.
  Attempting uninstall: zipp
    Found existing installation: zipp 0.3.3
    Not uninstalling zipp at /cvmfs/soft.computecanada.ca/easybuild/software/2017/Core/scipy-stack/2019a/lib/python3.7/site-packages, outside environment /localscratch/yinan.29152578.0/env
    Can't uninstall 'zipp'. No files were found to uninstall.
  Attempting uninstall: importlib-metadata
    Found existing installation: importlib-metadata 0.8
    Not uninstalling importlib-metadata at /cvmfs/soft.computecanada.ca/easybuild/software/2017/Core/scipy-stack/2019a/lib/python3.7/site-packages, outside environment /localscratch/yinan.29152578.0/env
    Can't uninstall 'importlib-metadata'. No files were found to uninstall.
  Attempting uninstall: scipy
    Found existing installation: scipy 1.2.0
    Not uninstalling scipy at /cvmfs/soft.computecanada.ca/easybuild/software/2017/Core/scipy-stack/2019a/lib/python3.7/site-packages, outside environment /localscratch/yinan.29152578.0/env
    Can't uninstall 'scipy'. No files were found to uninstall.
Successfully installed absl-py-1.0.0+computecanada astunparse-1.6.3+computecanada cachetools-4.2.4+computecanada gast-0.3.3+computecanada google-auth-2.3.3+computecanada google-auth-oauthlib-0.4.6+computecanada google-pasta-0.2.0+computecanada grpcio-1.38.0+computecanada h5py-2.10.0+computecanada importlib-metadata-4.10.1+computecanada keras-preprocessing-1.1.2+computecanada markdown-3.3.6+computecanada oauthlib-3.1.1+computecanada opt-einsum-3.3.0+computecanada pyasn1-0.4.8+computecanada pyasn1-modules-0.2.8+computecanada requests-oauthlib-1.3.0+computecanada rsa-4.8+computecanada scipy-1.4.1+computecanada tensorboard-2.8.0+computecanada tensorboard-data-server-0.6.1+computecanada tensorboard-plugin-wit-1.8.0+computecanada tensorflow-estimator-2.3.0+computecanada tensorflow-gpu-2.3.0+computecanada werkzeug-2.0.3+computecanada wrapt-1.11.2+computecanada zipp-3.7.0+computecanada
Looking in links: /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/nix/avx2, /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/nix/generic, /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/keras-2.8.0+computecanada-py2.py3-none-any.whl
Installing collected packages: Keras
Successfully installed Keras-2.8.0+computecanada
Looking in links: /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/nix/avx2, /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/nix/generic, /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/urllib3-1.26.7+computecanada-py2.py3-none-any.whl
Installing collected packages: urllib3
  Attempting uninstall: urllib3
    Found existing installation: urllib3 1.26.8+computecanada
    Uninstalling urllib3-1.26.8+computecanada:
      Successfully uninstalled urllib3-1.26.8+computecanada
Successfully installed urllib3-1.26.7+computecanada
Looking in links: /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/nix/avx2, /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/nix/generic, /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/nltk-3.7+computecanada-py3-none-any.whl
Requirement already satisfied: click in /localscratch/yinan.29152578.0/env/lib/python3.7/site-packages (from nltk) (8.0.4+computecanada)
Requirement already satisfied: tqdm in /localscratch/yinan.29152578.0/env/lib/python3.7/site-packages (from nltk) (4.63.0+computecanada)
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/nltk-3.6.5+computecanada-py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/nltk-3.6.3+computecanada-py3-none-any.whl
Requirement already satisfied: regex in /localscratch/yinan.29152578.0/env/lib/python3.7/site-packages (from nltk) (2020.11.13+computecanada)
Requirement already satisfied: joblib in /localscratch/yinan.29152578.0/env/lib/python3.7/site-packages (from nltk) (1.1.0+computecanada)
Requirement already satisfied: importlib-metadata in /localscratch/yinan.29152578.0/env/lib/python3.7/site-packages (from click->nltk) (4.10.1+computecanada)
Requirement already satisfied: typing-extensions>=3.6.4 in /localscratch/yinan.29152578.0/env/lib/python3.7/site-packages (from importlib-metadata->click->nltk) (4.0.1+computecanada)
Requirement already satisfied: zipp>=0.5 in /localscratch/yinan.29152578.0/env/lib/python3.7/site-packages (from importlib-metadata->click->nltk) (3.7.0+computecanada)
Installing collected packages: nltk
Successfully installed nltk-3.6.3+computecanada
Looking in links: /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/nix/avx2, /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/nix/generic, /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/scikit_learn-0.22.1+computecanada-cp37-cp37m-linux_x86_64.whl
Requirement already satisfied: joblib>=0.11 in /localscratch/yinan.29152578.0/env/lib/python3.7/site-packages (from scikit-learn==0.22.1) (1.1.0+computecanada)
Requirement already satisfied: scipy>=0.17.0 in /localscratch/yinan.29152578.0/env/lib/python3.7/site-packages (from scikit-learn==0.22.1) (1.4.1+computecanada)
Requirement already satisfied: numpy>=1.11.0 in /cvmfs/soft.computecanada.ca/easybuild/software/2017/Core/scipy-stack/2019a/lib/python3.7/site-packages (from scikit-learn==0.22.1) (1.16.0)
Installing collected packages: scikit-learn
Successfully installed scikit-learn-0.22.1+computecanada
Looking in links: /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/nix/avx2, /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/nix/generic, /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic
Requirement already satisfied: tokenizers==0.5.2 in /localscratch/yinan.29152578.0/env/lib/python3.7/site-packages (0.5.2+computecanada)
wandb: Appending key for api.wandb.ai to your netrc file: /home/yinan/.netrc
Starting Task
2022-03-17 17:30:28.835712: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1
[nltk_data] Downloading package stopwords to /home/yinan/nltk_data...
[nltk_data]   Package stopwords is already up-to-date!
[nltk_data] Downloading package wordnet to /home/yinan/nltk_data...
[nltk_data]   Package wordnet is already up-to-date!
wandb: Currently logged in as: yinanazhou (use `wandb login --relogin` to force relogin)
wandb: wandb version 0.12.11 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
2022-03-17 17:30:38.970075: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1
wandb: Tracking run with wandb version 0.12.5
wandb: Syncing run cosmic-star-2
wandb: ⭐️ View project at https://wandb.ai/yinanazhou/xl_512_bs_8_lr_1e06_es_5_lc_False_nr_True_sr_False_stem_False_lemma_False_repeat_1_fold_1
wandb: 🚀 View run at https://wandb.ai/yinanazhou/xl_512_bs_8_lr_1e06_es_5_lc_False_nr_True_sr_False_stem_False_lemma_False_repeat_1_fold_1/runs/eg03aqi8
wandb: Run data is saved locally in /project/6002780/yinan/Thesis_MER_Lyrics/lyric-emotion/wandb/run-20220317_173036-eg03aqi8
wandb: Run `wandb offline` to turn off syncing.

Validation loss decreased (inf --> 1.433229).  Saving model ...
Validation loss decreased (1.433229 --> 1.413110).  Saving model ...
Validation loss decreased (1.413110 --> 1.396176).  Saving model ...
Validation loss decreased (1.396176 --> 1.382279).  Saving model ...
Validation loss decreased (1.382279 --> 1.371598).  Saving model ...
Validation loss decreased (1.371598 --> 1.362808).  Saving model ...
Validation loss decreased (1.362808 --> 1.355502).  Saving model ...
Validation loss decreased (1.355502 --> 1.348385).  Saving model ...
Validation loss decreased (1.348385 --> 1.342372).  Saving model ...
Validation loss decreased (1.342372 --> 1.335795).  Saving model ...
Validation loss decreased (1.335795 --> 1.329027).  Saving model ...
Validation loss decreased (1.329027 --> 1.322893).  Saving model ...
Validation loss decreased (1.322893 --> 1.315562).  Saving model ...
Validation loss decreased (1.315562 --> 1.308531).  Saving model ...
Validation loss decreased (1.308531 --> 1.300847).  Saving model ...
Validation loss decreased (1.300847 --> 1.293341).  Saving model ...
Validation loss decreased (1.293341 --> 1.286067).  Saving model ...
Validation loss decreased (1.286067 --> 1.280456).  Saving model ...
Validation loss decreased (1.280456 --> 1.272807).  Saving model ...
Validation loss decreased (1.272807 --> 1.265423).  Saving model ...
Validation loss decreased (1.265423 --> 1.258489).  Saving model ...
Validation loss decreased (1.258489 --> 1.252704).  Saving model ...
Validation loss decreased (1.252704 --> 1.248509).  Saving model ...
Validation loss decreased (1.248509 --> 1.243048).  Saving model ...
Validation loss decreased (1.243048 --> 1.237602).  Saving model ...
Validation loss decreased (1.237602 --> 1.232497).  Saving model ...
Validation loss decreased (1.232497 --> 1.228624).  Saving model ...
Validation loss decreased (1.228624 --> 1.222904).  Saving model ...
Validation loss decreased (1.222904 --> 1.217716).  Saving model ...
Validation loss decreased (1.217716 --> 1.213962).  Saving model ...
Validation loss decreased (1.213962 --> 1.208696).  Saving model ...
Validation loss decreased (1.208696 --> 1.204166).  Saving model ...
Validation loss decreased (1.204166 --> 1.201181).  Saving model ...
Validation loss decreased (1.201181 --> 1.196231).  Saving model ...
Validation loss decreased (1.196231 --> 1.192928).  Saving model ...
Validation loss decreased (1.192928 --> 1.188185).  Saving model ...
Validation loss decreased (1.188185 --> 1.186707).  Saving model ...
Validation loss decreased (1.186707 --> 1.180769).  Saving model ...
Validation loss decreased (1.180769 --> 1.176273).  Saving model ...
Validation loss decreased (1.176273 --> 1.174058).  Saving model ...
Validation loss decreased (1.174058 --> 1.169737).  Saving model ...
Validation loss decreased (1.169737 --> 1.164110).  Saving model ...
Validation loss decreased (1.164110 --> 1.161612).  Saving model ...
Validation loss decreased (1.161612 --> 1.159056).  Saving model ...
Validation loss decreased (1.159056 --> 1.154592).  Saving model ...
Validation loss decreased (1.154592 --> 1.151696).  Saving model ...
Validation loss decreased (1.151696 --> 1.149983).  Saving model ...
Validation loss decreased (1.149983 --> 1.144778).  Saving model ...
Validation loss decreased (1.144778 --> 1.138887).  Saving model ...
Validation loss decreased (1.138887 --> 1.135738).  Saving model ...
Validation loss decreased (1.135738 --> 1.130622).  Saving model ...
Validation loss decreased (1.130622 --> 1.128961).  Saving model ...
Validation loss decreased (1.128961 --> 1.126676).  Saving model ...
Validation loss decreased (1.126676 --> 1.123249).  Saving model ...
Validation loss decreased (1.123249 --> 1.122328).  Saving model ...
Validation loss decreased (1.122328 --> 1.118860).  Saving model ...
Validation loss decreased (1.118860 --> 1.116236).  Saving model ...
Validation loss decreased (1.116236 --> 1.112946).  Saving model ...
Validation loss decreased (1.112946 --> 1.108449).  Saving model ...
Validation loss decreased (1.108449 --> 1.106706).  Saving model ...
Validation loss decreased (1.106706 --> 1.106023).  Saving model ...
Validation loss decreased (1.106023 --> 1.102541).  Saving model ...
Validation loss decreased (1.102541 --> 1.099072).  Saving model ...
Validation loss decreased (1.099072 --> 1.096845).  Saving model ...
Validation loss decreased (1.096845 --> 1.096474).  Saving model ...
Validation loss decreased (1.096474 --> 1.091677).  Saving model ...
Validation loss decreased (1.091677 --> 1.089817).  Saving model ...
Validation loss decreased (1.089817 --> 1.089247).  Saving model ...
Validation loss decreased (1.089247 --> 1.086168).  Saving model ...
EarlyStopping counter: 1 out of 5.0
Validation loss decreased (1.086168 --> 1.083329).  Saving model ...
Validation loss decreased (1.083329 --> 1.076753).  Saving model ...
Validation loss decreased (1.076753 --> 1.075939).  Saving model ...
Validation loss decreased (1.075939 --> 1.073958).  Saving model ...
Validation loss decreased (1.073958 --> 1.072206).  Saving model ...
Validation loss decreased (1.072206 --> 1.071090).  Saving model ...
Validation loss decreased (1.071090 --> 1.066725).  Saving model ...
Validation loss decreased (1.066725 --> 1.065381).  Saving model ...
EarlyStopping counter: 1 out of 5.0
Validation loss decreased (1.065381 --> 1.061086).  Saving model ...
EarlyStopping counter: 1 out of 5.0
EarlyStopping counter: 2 out of 5.0
Validation loss decreased (1.061086 --> 1.060310).  Saving model ...
Validation loss decreased (1.060310 --> 1.058683).  Saving model ...
Validation loss decreased (1.058683 --> 1.051627).  Saving model ...
Validation loss decreased (1.051627 --> 1.050971).  Saving model ...
Validation loss decreased (1.050971 --> 1.050159).  Saving model ...
EarlyStopping counter: 1 out of 5.0
EarlyStopping counter: 2 out of 5.0
EarlyStopping counter: 3 out of 5.0
Validation loss decreased (1.050159 --> 1.049028).  Saving model ...
Validation loss decreased (1.049028 --> 1.047804).  Saving model ...
Validation loss decreased (1.047804 --> 1.043642).  Saving model ...
EarlyStopping counter: 1 out of 5.0
EarlyStopping counter: 2 out of 5.0
Validation loss decreased (1.043642 --> 1.043066).  Saving model ...
EarlyStopping counter: 1 out of 5.0
Validation loss decreased (1.043066 --> 1.040295).  Saving model ...
EarlyStopping counter: 1 out of 5.0
EarlyStopping counter: 2 out of 5.0
Validation loss decreased (1.040295 --> 1.039640).  Saving model ...
Validation loss decreased (1.039640 --> 1.039431).  Saving model ...
Validation loss decreased (1.039431 --> 1.036350).  Saving model ...
Validation loss decreased (1.036350 --> 1.034026).  Saving model ...
EarlyStopping counter: 1 out of 5.0
EarlyStopping counter: 2 out of 5.0
Validation loss decreased (1.034026 --> 1.032194).  Saving model ...
Validation loss decreased (1.032194 --> 1.031806).  Saving model ...
Validation loss decreased (1.031806 --> 1.030418).  Saving model ...
Validation loss decreased (1.030418 --> 1.028683).  Saving model ...
EarlyStopping counter: 1 out of 5.0
EarlyStopping counter: 2 out of 5.0
EarlyStopping counter: 3 out of 5.0
EarlyStopping counter: 4 out of 5.0
EarlyStopping counter: 5 out of 5.0
/localscratch/yinan.29152578.0/env/lib/python3.7/site-packages/torch/nn/functional.py:1794: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.
  warnings.warn("nn.functional.tanh is deprecated. Use torch.tanh instead.")
/localscratch/yinan.29152578.0/env/lib/python3.7/site-packages/transformers/optimization.py:155: UserWarning: This overload of add_ is deprecated:
	add_(Number alpha, Tensor other)
Consider using one of the following signatures instead:
	add_(Tensor other, *, Number alpha) (Triggered internally at  ../torch/csrc/utils/python_arg_parser.cpp:1025.)
  exp_avg.mul_(beta1).add_(1.0 - beta1, grad)
wandb: Waiting for W&B process to finish, PID 140423... (success).
wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: \ 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: | 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: / 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: \ 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: | 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: / 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: \ 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: | 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: / 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: \ 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: | 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: / 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: \ 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: | 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: / 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb:                                                                                
wandb: Run history:
wandb:     e_F1 ▁▂▃▃▄▄▅▅▅▅▆▆▆▆▆▆▆▇▇▇▇▇▇▇▇▇▇▇▇▇▇█████████
wandb:   e_loss █▇▇▆▆▆▅▅▅▄▄▄▄▄▃▃▃▃▃▃▂▂▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁
wandb:     t_F1 ▁▁▃▃▃▄▄▄▅▅▅▅▅▆▆▆▆▆▆▆▆▇▇▇▇▇▇▇▆▇▇▇▇▇▇▇████
wandb:   t_loss ██▇▇▇▇▆▆▆▅▅▅▅▅▄▄▄▄▃▄▃▃▃▃▃▃▂▂▂▂▂▂▂▂▂▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:     e_F1 58.67857
wandb:   e_loss 1.03221
wandb:     t_F1 70.30957
wandb:   t_loss 0.78571
wandb: 
wandb: Synced 4 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Synced cosmic-star-2: https://wandb.ai/yinanazhou/xl_512_bs_8_lr_1e06_es_5_lc_False_nr_True_sr_False_stem_False_lemma_False_repeat_1_fold_1/runs/eg03aqi8
wandb: Find logs at: ./wandb/run-20220317_173036-eg03aqi8/logs/debug.log
wandb: 

wandb: wandb version 0.12.11 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
2022-03-17 18:45:19.525887: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1
wandb: Tracking run with wandb version 0.12.5
wandb: Syncing run floral-silence-2
wandb: ⭐️ View project at https://wandb.ai/yinanazhou/xl_512_bs_8_lr_1e06_es_5_lc_False_nr_True_sr_False_stem_False_lemma_False_repeat_1_fold_2
wandb: 🚀 View run at https://wandb.ai/yinanazhou/xl_512_bs_8_lr_1e06_es_5_lc_False_nr_True_sr_False_stem_False_lemma_False_repeat_1_fold_2/runs/zkack2yr
wandb: Run data is saved locally in /project/6002780/yinan/Thesis_MER_Lyrics/lyric-emotion/wandb/run-20220317_184516-zkack2yr
wandb: Run `wandb offline` to turn off syncing.
wandb: Network error (ReadTimeout), entering retry loop.

Validation loss decreased (inf --> 1.419059).  Saving model ...
Validation loss decreased (1.419059 --> 1.405567).  Saving model ...
Validation loss decreased (1.405567 --> 1.395964).  Saving model ...
Validation loss decreased (1.395964 --> 1.388771).  Saving model ...
Validation loss decreased (1.388771 --> 1.382477).  Saving model ...
Validation loss decreased (1.382477 --> 1.377022).  Saving model ...
Validation loss decreased (1.377022 --> 1.372619).  Saving model ...
Validation loss decreased (1.372619 --> 1.368376).  Saving model ...
Validation loss decreased (1.368376 --> 1.364049).  Saving model ...
Validation loss decreased (1.364049 --> 1.359988).  Saving model ...
Validation loss decreased (1.359988 --> 1.355726).  Saving model ...
Validation loss decreased (1.355726 --> 1.351704).  Saving model ...
Validation loss decreased (1.351704 --> 1.347661).  Saving model ...
Validation loss decreased (1.347661 --> 1.343243).  Saving model ...
Validation loss decreased (1.343243 --> 1.338997).  Saving model ...
Validation loss decreased (1.338997 --> 1.334591).  Saving model ...
Validation loss decreased (1.334591 --> 1.329839).  Saving model ...
Validation loss decreased (1.329839 --> 1.324683).  Saving model ...
Validation loss decreased (1.324683 --> 1.319477).  Saving model ...
Validation loss decreased (1.319477 --> 1.314099).  Saving model ...
Validation loss decreased (1.314099 --> 1.308898).  Saving model ...
Validation loss decreased (1.308898 --> 1.303340).  Saving model ...
Validation loss decreased (1.303340 --> 1.297140).  Saving model ...
Validation loss decreased (1.297140 --> 1.290615).  Saving model ...
Validation loss decreased (1.290615 --> 1.284265).  Saving model ...
Validation loss decreased (1.284265 --> 1.276635).  Saving model ...
Validation loss decreased (1.276635 --> 1.268472).  Saving model ...
Validation loss decreased (1.268472 --> 1.260325).  Saving model ...
Validation loss decreased (1.260325 --> 1.252008).  Saving model ...
Validation loss decreased (1.252008 --> 1.244132).  Saving model ...
Validation loss decreased (1.244132 --> 1.234263).  Saving model ...
Validation loss decreased (1.234263 --> 1.224124).  Saving model ...
Validation loss decreased (1.224124 --> 1.215556).  Saving model ...
Validation loss decreased (1.215556 --> 1.205339).  Saving model ...
Validation loss decreased (1.205339 --> 1.196154).  Saving model ...
Validation loss decreased (1.196154 --> 1.186872).  Saving model ...
Validation loss decreased (1.186872 --> 1.178426).  Saving model ...
Validation loss decreased (1.178426 --> 1.171076).  Saving model ...
Validation loss decreased (1.171076 --> 1.164329).  Saving model ...
Validation loss decreased (1.164329 --> 1.157543).  Saving model ...
Validation loss decreased (1.157543 --> 1.150719).  Saving model ...
Validation loss decreased (1.150719 --> 1.146264).  Saving model ...
Validation loss decreased (1.146264 --> 1.140586).  Saving model ...
Validation loss decreased (1.140586 --> 1.132460).  Saving model ...
Validation loss decreased (1.132460 --> 1.125920).  Saving model ...
Validation loss decreased (1.125920 --> 1.119133).  Saving model ...
Validation loss decreased (1.119133 --> 1.114892).  Saving model ...
Validation loss decreased (1.114892 --> 1.109422).  Saving model ...
Validation loss decreased (1.109422 --> 1.104348).  Saving model ...
Validation loss decreased (1.104348 --> 1.097853).  Saving model ...
Validation loss decreased (1.097853 --> 1.093003).  Saving model ...
Validation loss decreased (1.093003 --> 1.088061).  Saving model ...
Validation loss decreased (1.088061 --> 1.083290).  Saving model ...
Validation loss decreased (1.083290 --> 1.076986).  Saving model ...
Validation loss decreased (1.076986 --> 1.073134).  Saving model ...
Validation loss decreased (1.073134 --> 1.067351).  Saving model ...
Validation loss decreased (1.067351 --> 1.061152).  Saving model ...
Validation loss decreased (1.061152 --> 1.056823).  Saving model ...
Validation loss decreased (1.056823 --> 1.052965).  Saving model ...
Validation loss decreased (1.052965 --> 1.048102).  Saving model ...
Validation loss decreased (1.048102 --> 1.041705).  Saving model ...
Validation loss decreased (1.041705 --> 1.038238).  Saving model ...
Validation loss decreased (1.038238 --> 1.034242).  Saving model ...
Validation loss decreased (1.034242 --> 1.030250).  Saving model ...
Validation loss decreased (1.030250 --> 1.026247).  Saving model ...
Validation loss decreased (1.026247 --> 1.021285).  Saving model ...
Validation loss decreased (1.021285 --> 1.019047).  Saving model ...
Validation loss decreased (1.019047 --> 1.014132).  Saving model ...
Validation loss decreased (1.014132 --> 1.010318).  Saving model ...
Validation loss decreased (1.010318 --> 1.007126).  Saving model ...
Validation loss decreased (1.007126 --> 1.003153).  Saving model ...
Validation loss decreased (1.003153 --> 1.001491).  Saving model ...
Validation loss decreased (1.001491 --> 0.997474).  Saving model ...
Validation loss decreased (0.997474 --> 0.994637).  Saving model ...
Validation loss decreased (0.994637 --> 0.991624).  Saving model ...
Validation loss decreased (0.991624 --> 0.989024).  Saving model ...
Validation loss decreased (0.989024 --> 0.984891).  Saving model ...
Validation loss decreased (0.984891 --> 0.982227).  Saving model ...
Validation loss decreased (0.982227 --> 0.980689).  Saving model ...
Validation loss decreased (0.980689 --> 0.977055).  Saving model ...
Validation loss decreased (0.977055 --> 0.976065).  Saving model ...
Validation loss decreased (0.976065 --> 0.973974).  Saving model ...
Validation loss decreased (0.973974 --> 0.971091).  Saving model ...
Validation loss decreased (0.971091 --> 0.968751).  Saving model ...
Validation loss decreased (0.968751 --> 0.967691).  Saving model ...
Validation loss decreased (0.967691 --> 0.966484).  Saving model ...
Validation loss decreased (0.966484 --> 0.964969).  Saving model ...
Validation loss decreased (0.964969 --> 0.962517).  Saving model ...
Validation loss decreased (0.962517 --> 0.961530).  Saving model ...
Validation loss decreased (0.961530 --> 0.959740).  Saving model ...
Validation loss decreased (0.959740 --> 0.958486).  Saving model ...
Validation loss decreased (0.958486 --> 0.957264).  Saving model ...
Validation loss decreased (0.957264 --> 0.955544).  Saving model ...
Validation loss decreased (0.955544 --> 0.953517).  Saving model ...
Validation loss decreased (0.953517 --> 0.951363).  Saving model ...
Validation loss decreased (0.951363 --> 0.948646).  Saving model ...
Validation loss decreased (0.948646 --> 0.946886).  Saving model ...
Validation loss decreased (0.946886 --> 0.945510).  Saving model ...
Validation loss decreased (0.945510 --> 0.944087).  Saving model ...
Validation loss decreased (0.944087 --> 0.942573).  Saving model ...
Validation loss decreased (0.942573 --> 0.941133).  Saving model ...
Validation loss decreased (0.941133 --> 0.939760).  Saving model ...
Validation loss decreased (0.939760 --> 0.938206).  Saving model ...
Validation loss decreased (0.938206 --> 0.936729).  Saving model ...
Validation loss decreased (0.936729 --> 0.935734).  Saving model ...
EarlyStopping counter: 1 out of 5.0
EarlyStopping counter: 2 out of 5.0
Validation loss decreased (0.935734 --> 0.933258).  Saving model ...
Validation loss decreased (0.933258 --> 0.932875).  Saving model ...
Validation loss decreased (0.932875 --> 0.932748).  Saving model ...
Validation loss decreased (0.932748 --> 0.932092).  Saving model ...
Validation loss decreased (0.932092 --> 0.930231).  Saving model ...
EarlyStopping counter: 1 out of 5.0
Validation loss decreased (0.930231 --> 0.929800).  Saving model ...
Validation loss decreased (0.929800 --> 0.929020).  Saving model ...
Validation loss decreased (0.929020 --> 0.928852).  Saving model ...
EarlyStopping counter: 1 out of 5.0
Validation loss decreased (0.928852 --> 0.927810).  Saving model ...
EarlyStopping counter: 1 out of 5.0
EarlyStopping counter: 2 out of 5.0
Validation loss decreased (0.927810 --> 0.926683).  Saving model ...
EarlyStopping counter: 1 out of 5.0
EarlyStopping counter: 2 out of 5.0
EarlyStopping counter: 3 out of 5.0
EarlyStopping counter: 4 out of 5.0
EarlyStopping counter: 5 out of 5.0
/localscratch/yinan.29152578.0/env/lib/python3.7/site-packages/torch/nn/functional.py:1794: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.
  warnings.warn("nn.functional.tanh is deprecated. Use torch.tanh instead.")
wandb: Waiting for W&B process to finish, PID 144428... (success).
wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: \ 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: | 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: / 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: \ 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: | 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: / 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: \ 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: | 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: / 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb:                                                                                
wandb: Run history:
wandb:     e_F1 ▁▂▃▄▄▅▅▆▆▆▆▆▇▇▇▇▇▇▇▇████████████████████
wandb:   e_loss ██▇▇▇▇▇▆▆▆▅▅▄▄▄▄▃▃▃▃▂▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁
wandb:     t_F1 ▁▁▂▂▂▃▃▃▄▃▅▄▄▅▅▆▅▅▆▆▆▆▆▇▇▇▇▇▇█▇▇█▇██████
wandb:   t_loss ██▇▇▇▇▇▇▇▇▆▆▆▅▅▅▅▅▄▄▄▄▄▃▃▃▃▃▃▂▂▂▂▂▂▂▁▁▁▁
wandb: 
wandb: Run summary:
wandb:     e_F1 60.12966
wandb:   e_loss 0.92786
wandb:     t_F1 71.34242
wandb:   t_loss 0.78558
wandb: 
wandb: Synced 4 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Synced floral-silence-2: https://wandb.ai/yinanazhou/xl_512_bs_8_lr_1e06_es_5_lc_False_nr_True_sr_False_stem_False_lemma_False_repeat_1_fold_2/runs/zkack2yr
wandb: Find logs at: ./wandb/run-20220317_184516-zkack2yr/logs/debug.log
wandb: 

wandb: wandb version 0.12.11 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
2022-03-17 20:09:03.473491: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1
wandb: Tracking run with wandb version 0.12.5
wandb: Syncing run generous-butterfly-2
wandb: ⭐️ View project at https://wandb.ai/yinanazhou/xl_512_bs_8_lr_1e06_es_5_lc_False_nr_True_sr_False_stem_False_lemma_False_repeat_2_fold_1
wandb: 🚀 View run at https://wandb.ai/yinanazhou/xl_512_bs_8_lr_1e06_es_5_lc_False_nr_True_sr_False_stem_False_lemma_False_repeat_2_fold_1/runs/2nnrij9y
wandb: Run data is saved locally in /project/6002780/yinan/Thesis_MER_Lyrics/lyric-emotion/wandb/run-20220317_200901-2nnrij9y
wandb: Run `wandb offline` to turn off syncing.

Validation loss decreased (inf --> 1.425835).  Saving model ...
Validation loss decreased (1.425835 --> 1.405728).  Saving model ...
Validation loss decreased (1.405728 --> 1.390190).  Saving model ...
Validation loss decreased (1.390190 --> 1.379094).  Saving model ...
Validation loss decreased (1.379094 --> 1.370332).  Saving model ...
Validation loss decreased (1.370332 --> 1.363671).  Saving model ...
Validation loss decreased (1.363671 --> 1.357910).  Saving model ...
Validation loss decreased (1.357910 --> 1.352381).  Saving model ...
Validation loss decreased (1.352381 --> 1.347621).  Saving model ...
Validation loss decreased (1.347621 --> 1.342909).  Saving model ...
Validation loss decreased (1.342909 --> 1.338101).  Saving model ...
Validation loss decreased (1.338101 --> 1.332724).  Saving model ...
Validation loss decreased (1.332724 --> 1.327574).  Saving model ...
Validation loss decreased (1.327574 --> 1.322076).  Saving model ...
Validation loss decreased (1.322076 --> 1.316977).  Saving model ...
Validation loss decreased (1.316977 --> 1.311029).  Saving model ...
Validation loss decreased (1.311029 --> 1.305182).  Saving model ...
Validation loss decreased (1.305182 --> 1.298793).  Saving model ...
Validation loss decreased (1.298793 --> 1.292285).  Saving model ...
Validation loss decreased (1.292285 --> 1.284313).  Saving model ...
Validation loss decreased (1.284313 --> 1.277171).  Saving model ...
Validation loss decreased (1.277171 --> 1.270042).  Saving model ...
Validation loss decreased (1.270042 --> 1.261203).  Saving model ...
Validation loss decreased (1.261203 --> 1.251214).  Saving model ...
Validation loss decreased (1.251214 --> 1.242318).  Saving model ...
Validation loss decreased (1.242318 --> 1.234137).  Saving model ...
Validation loss decreased (1.234137 --> 1.226888).  Saving model ...
Validation loss decreased (1.226888 --> 1.219111).  Saving model ...
Validation loss decreased (1.219111 --> 1.211248).  Saving model ...
Validation loss decreased (1.211248 --> 1.205355).  Saving model ...
Validation loss decreased (1.205355 --> 1.197095).  Saving model ...
Validation loss decreased (1.197095 --> 1.190352).  Saving model ...
Validation loss decreased (1.190352 --> 1.182570).  Saving model ...
Validation loss decreased (1.182570 --> 1.176483).  Saving model ...
Validation loss decreased (1.176483 --> 1.170633).  Saving model ...
Validation loss decreased (1.170633 --> 1.164101).  Saving model ...
Validation loss decreased (1.164101 --> 1.158628).  Saving model ...
Validation loss decreased (1.158628 --> 1.154214).  Saving model ...
Validation loss decreased (1.154214 --> 1.149751).  Saving model ...
Validation loss decreased (1.149751 --> 1.144600).  Saving model ...
Validation loss decreased (1.144600 --> 1.139222).  Saving model ...
Validation loss decreased (1.139222 --> 1.133527).  Saving model ...
Validation loss decreased (1.133527 --> 1.126430).  Saving model ...
Validation loss decreased (1.126430 --> 1.121225).  Saving model ...
Validation loss decreased (1.121225 --> 1.113524).  Saving model ...
Validation loss decreased (1.113524 --> 1.109142).  Saving model ...
Validation loss decreased (1.109142 --> 1.104761).  Saving model ...
Validation loss decreased (1.104761 --> 1.099342).  Saving model ...
Validation loss decreased (1.099342 --> 1.096514).  Saving model ...
Validation loss decreased (1.096514 --> 1.091649).  Saving model ...
Validation loss decreased (1.091649 --> 1.088119).  Saving model ...
Validation loss decreased (1.088119 --> 1.082284).  Saving model ...
Validation loss decreased (1.082284 --> 1.078134).  Saving model ...
Validation loss decreased (1.078134 --> 1.074747).  Saving model ...
Validation loss decreased (1.074747 --> 1.071520).  Saving model ...
Validation loss decreased (1.071520 --> 1.065219).  Saving model ...
Validation loss decreased (1.065219 --> 1.061664).  Saving model ...
Validation loss decreased (1.061664 --> 1.057106).  Saving model ...
Validation loss decreased (1.057106 --> 1.052202).  Saving model ...
Validation loss decreased (1.052202 --> 1.049333).  Saving model ...
Validation loss decreased (1.049333 --> 1.046380).  Saving model ...
Validation loss decreased (1.046380 --> 1.042568).  Saving model ...
Validation loss decreased (1.042568 --> 1.040031).  Saving model ...
Validation loss decreased (1.040031 --> 1.036286).  Saving model ...
Validation loss decreased (1.036286 --> 1.031984).  Saving model ...
Validation loss decreased (1.031984 --> 1.029332).  Saving model ...
Validation loss decreased (1.029332 --> 1.025494).  Saving model ...
Validation loss decreased (1.025494 --> 1.021673).  Saving model ...
Validation loss decreased (1.021673 --> 1.018085).  Saving model ...
Validation loss decreased (1.018085 --> 1.017025).  Saving model ...
Validation loss decreased (1.017025 --> 1.014838).  Saving model ...
Validation loss decreased (1.014838 --> 1.011095).  Saving model ...
Validation loss decreased (1.011095 --> 1.008525).  Saving model ...
Validation loss decreased (1.008525 --> 1.004686).  Saving model ...
Validation loss decreased (1.004686 --> 1.002918).  Saving model ...
EarlyStopping counter: 1 out of 5.0
Validation loss decreased (1.002918 --> 1.000031).  Saving model ...
Validation loss decreased (1.000031 --> 0.997792).  Saving model ...
Validation loss decreased (0.997792 --> 0.996416).  Saving model ...
Validation loss decreased (0.996416 --> 0.996373).  Saving model ...
Validation loss decreased (0.996373 --> 0.994136).  Saving model ...
Validation loss decreased (0.994136 --> 0.992359).  Saving model ...
Validation loss decreased (0.992359 --> 0.989508).  Saving model ...
Validation loss decreased (0.989508 --> 0.985262).  Saving model ...
Validation loss decreased (0.985262 --> 0.983364).  Saving model ...
Validation loss decreased (0.983364 --> 0.983137).  Saving model ...
Validation loss decreased (0.983137 --> 0.982247).  Saving model ...
Validation loss decreased (0.982247 --> 0.979973).  Saving model ...
Validation loss decreased (0.979973 --> 0.978826).  Saving model ...
Validation loss decreased (0.978826 --> 0.976420).  Saving model ...
Validation loss decreased (0.976420 --> 0.974636).  Saving model ...
Validation loss decreased (0.974636 --> 0.973038).  Saving model ...
Validation loss decreased (0.973038 --> 0.971186).  Saving model ...
EarlyStopping counter: 1 out of 5.0
EarlyStopping counter: 2 out of 5.0
Validation loss decreased (0.971186 --> 0.970022).  Saving model ...
Validation loss decreased (0.970022 --> 0.968529).  Saving model ...
Validation loss decreased (0.968529 --> 0.968132).  Saving model ...
Validation loss decreased (0.968132 --> 0.966914).  Saving model ...
Validation loss decreased (0.966914 --> 0.964554).  Saving model ...
Validation loss decreased (0.964554 --> 0.964396).  Saving model ...
EarlyStopping counter: 1 out of 5.0
Validation loss decreased (0.964396 --> 0.962243).  Saving model ...
Validation loss decreased (0.962243 --> 0.959618).  Saving model ...
EarlyStopping counter: 1 out of 5.0
Validation loss decreased (0.959618 --> 0.957944).  Saving model ...
Validation loss decreased (0.957944 --> 0.957482).  Saving model ...
Validation loss decreased (0.957482 --> 0.955267).  Saving model ...
Validation loss decreased (0.955267 --> 0.955018).  Saving model ...
EarlyStopping counter: 1 out of 5.0
EarlyStopping counter: 2 out of 5.0
Validation loss decreased (0.955018 --> 0.954868).  Saving model ...
Validation loss decreased (0.954868 --> 0.954440).  Saving model ...
EarlyStopping counter: 1 out of 5.0
EarlyStopping counter: 2 out of 5.0
EarlyStopping counter: 3 out of 5.0
EarlyStopping counter: 4 out of 5.0
EarlyStopping counter: 5 out of 5.0
/localscratch/yinan.29152578.0/env/lib/python3.7/site-packages/torch/nn/functional.py:1794: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.
  warnings.warn("nn.functional.tanh is deprecated. Use torch.tanh instead.")
wandb: Waiting for W&B process to finish, PID 148925... (success).
wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: \ 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: | 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: / 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: \ 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: | 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: / 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: \ 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: | 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: / 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb:                                                                                
wandb: Run history:
wandb:     e_F1 ▁▂▄▅▅▅▅▅▆▇▇▇▇▇▇▇▇▇▇▇▇▇██████████████████
wandb:   e_loss █▇▇▇▇▆▆▆▅▅▅▄▄▄▄▃▃▃▃▃▂▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁
wandb:     t_F1 ▁▂▂▂▃▄▃▄▄▄▅▅▆▆▅▆▆▆▆▆▇▆▆▇▇▇▇▇▇▇█▇▇█▇▇█▇██
wandb:   t_loss █▇▇▇▇▇▆▆▆▆▅▅▅▅▅▄▄▄▄▄▃▃▃▃▃▃▂▃▂▂▂▂▂▂▁▂▁▁▁▁
wandb: 
wandb: Run summary:
wandb:     e_F1 57.47456
wandb:   e_loss 0.9545
wandb:     t_F1 73.83926
wandb:   t_loss 0.7557
wandb: 
wandb: Synced 4 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Synced generous-butterfly-2: https://wandb.ai/yinanazhou/xl_512_bs_8_lr_1e06_es_5_lc_False_nr_True_sr_False_stem_False_lemma_False_repeat_2_fold_1/runs/2nnrij9y
wandb: Find logs at: ./wandb/run-20220317_200901-2nnrij9y/logs/debug.log
wandb: 

wandb: wandb version 0.12.11 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
2022-03-17 21:27:32.350491: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1
wandb: Tracking run with wandb version 0.12.5
wandb: Syncing run iconic-capybara-2
wandb: ⭐️ View project at https://wandb.ai/yinanazhou/xl_512_bs_8_lr_1e06_es_5_lc_False_nr_True_sr_False_stem_False_lemma_False_repeat_2_fold_2
wandb: 🚀 View run at https://wandb.ai/yinanazhou/xl_512_bs_8_lr_1e06_es_5_lc_False_nr_True_sr_False_stem_False_lemma_False_repeat_2_fold_2/runs/2wntw52x
wandb: Run data is saved locally in /project/6002780/yinan/Thesis_MER_Lyrics/lyric-emotion/wandb/run-20220317_212729-2wntw52x
wandb: Run `wandb offline` to turn off syncing.
wandb: Network error (ReadTimeout), entering retry loop.

Validation loss decreased (inf --> 1.427363).  Saving model ...
Validation loss decreased (1.427363 --> 1.411836).  Saving model ...
Validation loss decreased (1.411836 --> 1.399656).  Saving model ...
Validation loss decreased (1.399656 --> 1.389124).  Saving model ...
Validation loss decreased (1.389124 --> 1.380149).  Saving model ...
Validation loss decreased (1.380149 --> 1.372990).  Saving model ...
Validation loss decreased (1.372990 --> 1.366351).  Saving model ...
Validation loss decreased (1.366351 --> 1.359615).  Saving model ...
Validation loss decreased (1.359615 --> 1.353719).  Saving model ...
Validation loss decreased (1.353719 --> 1.348199).  Saving model ...
Validation loss decreased (1.348199 --> 1.342782).  Saving model ...
Validation loss decreased (1.342782 --> 1.337063).  Saving model ...
Validation loss decreased (1.337063 --> 1.331687).  Saving model ...
Validation loss decreased (1.331687 --> 1.326172).  Saving model ...
Validation loss decreased (1.326172 --> 1.320468).  Saving model ...
Validation loss decreased (1.320468 --> 1.314689).  Saving model ...
Validation loss decreased (1.314689 --> 1.308353).  Saving model ...
Validation loss decreased (1.308353 --> 1.302844).  Saving model ...
Validation loss decreased (1.302844 --> 1.297383).  Saving model ...
Validation loss decreased (1.297383 --> 1.291712).  Saving model ...
Validation loss decreased (1.291712 --> 1.284844).  Saving model ...
Validation loss decreased (1.284844 --> 1.277055).  Saving model ...
Validation loss decreased (1.277055 --> 1.269589).  Saving model ...
Validation loss decreased (1.269589 --> 1.261923).  Saving model ...
Validation loss decreased (1.261923 --> 1.255130).  Saving model ...
Validation loss decreased (1.255130 --> 1.247380).  Saving model ...
Validation loss decreased (1.247380 --> 1.240240).  Saving model ...
Validation loss decreased (1.240240 --> 1.232754).  Saving model ...
Validation loss decreased (1.232754 --> 1.225000).  Saving model ...
Validation loss decreased (1.225000 --> 1.218219).  Saving model ...
Validation loss decreased (1.218219 --> 1.210812).  Saving model ...
Validation loss decreased (1.210812 --> 1.204172).  Saving model ...
Validation loss decreased (1.204172 --> 1.196629).  Saving model ...
Validation loss decreased (1.196629 --> 1.189337).  Saving model ...
Validation loss decreased (1.189337 --> 1.183467).  Saving model ...
Validation loss decreased (1.183467 --> 1.177260).  Saving model ...
Validation loss decreased (1.177260 --> 1.171219).  Saving model ...
Validation loss decreased (1.171219 --> 1.164321).  Saving model ...
Validation loss decreased (1.164321 --> 1.159336).  Saving model ...
Validation loss decreased (1.159336 --> 1.153275).  Saving model ...
Validation loss decreased (1.153275 --> 1.146088).  Saving model ...
Validation loss decreased (1.146088 --> 1.142748).  Saving model ...
Validation loss decreased (1.142748 --> 1.135457).  Saving model ...
Validation loss decreased (1.135457 --> 1.129808).  Saving model ...
Validation loss decreased (1.129808 --> 1.125154).  Saving model ...
Validation loss decreased (1.125154 --> 1.119121).  Saving model ...
Validation loss decreased (1.119121 --> 1.113983).  Saving model ...
Validation loss decreased (1.113983 --> 1.108880).  Saving model ...
Validation loss decreased (1.108880 --> 1.102500).  Saving model ...
Validation loss decreased (1.102500 --> 1.097072).  Saving model ...
Validation loss decreased (1.097072 --> 1.091930).  Saving model ...
Validation loss decreased (1.091930 --> 1.086976).  Saving model ...
Validation loss decreased (1.086976 --> 1.082244).  Saving model ...
Validation loss decreased (1.082244 --> 1.076587).  Saving model ...
Validation loss decreased (1.076587 --> 1.071781).  Saving model ...
Validation loss decreased (1.071781 --> 1.067437).  Saving model ...
Validation loss decreased (1.067437 --> 1.065130).  Saving model ...
Validation loss decreased (1.065130 --> 1.060635).  Saving model ...
Validation loss decreased (1.060635 --> 1.056034).  Saving model ...
Validation loss decreased (1.056034 --> 1.050627).  Saving model ...
Validation loss decreased (1.050627 --> 1.048573).  Saving model ...
Validation loss decreased (1.048573 --> 1.046028).  Saving model ...
Validation loss decreased (1.046028 --> 1.040076).  Saving model ...
Validation loss decreased (1.040076 --> 1.038190).  Saving model ...
Validation loss decreased (1.038190 --> 1.034883).  Saving model ...
Validation loss decreased (1.034883 --> 1.031026).  Saving model ...
Validation loss decreased (1.031026 --> 1.028489).  Saving model ...
Validation loss decreased (1.028489 --> 1.022808).  Saving model ...
Validation loss decreased (1.022808 --> 1.019558).  Saving model ...
Validation loss decreased (1.019558 --> 1.016465).  Saving model ...
Validation loss decreased (1.016465 --> 1.014188).  Saving model ...
Validation loss decreased (1.014188 --> 1.009701).  Saving model ...
Validation loss decreased (1.009701 --> 1.006887).  Saving model ...
Validation loss decreased (1.006887 --> 1.005067).  Saving model ...
Validation loss decreased (1.005067 --> 1.001715).  Saving model ...
Validation loss decreased (1.001715 --> 0.998359).  Saving model ...
Validation loss decreased (0.998359 --> 0.995220).  Saving model ...
Validation loss decreased (0.995220 --> 0.991984).  Saving model ...
Validation loss decreased (0.991984 --> 0.988461).  Saving model ...
Validation loss decreased (0.988461 --> 0.986462).  Saving model ...
Validation loss decreased (0.986462 --> 0.985170).  Saving model ...
Validation loss decreased (0.985170 --> 0.980579).  Saving model ...
Validation loss decreased (0.980579 --> 0.980393).  Saving model ...
Validation loss decreased (0.980393 --> 0.978549).  Saving model ...
Validation loss decreased (0.978549 --> 0.976892).  Saving model ...
Validation loss decreased (0.976892 --> 0.975387).  Saving model ...
Validation loss decreased (0.975387 --> 0.972569).  Saving model ...
Validation loss decreased (0.972569 --> 0.970066).  Saving model ...
Validation loss decreased (0.970066 --> 0.967694).  Saving model ...
Validation loss decreased (0.967694 --> 0.965651).  Saving model ...
Validation loss decreased (0.965651 --> 0.963574).  Saving model ...
Validation loss decreased (0.963574 --> 0.962846).  Saving model ...
Validation loss decreased (0.962846 --> 0.958706).  Saving model ...
Validation loss decreased (0.958706 --> 0.957164).  Saving model ...
Validation loss decreased (0.957164 --> 0.953207).  Saving model ...
Validation loss decreased (0.953207 --> 0.952373).  Saving model ...
Validation loss decreased (0.952373 --> 0.950689).  Saving model ...
Validation loss decreased (0.950689 --> 0.949625).  Saving model ...
Validation loss decreased (0.949625 --> 0.948754).  Saving model ...
Validation loss decreased (0.948754 --> 0.946720).  Saving model ...
Validation loss decreased (0.946720 --> 0.945605).  Saving model ...
Validation loss decreased (0.945605 --> 0.944851).  Saving model ...
EarlyStopping counter: 1 out of 5.0
Validation loss decreased (0.944851 --> 0.943755).  Saving model ...
Validation loss decreased (0.943755 --> 0.942863).  Saving model ...
Validation loss decreased (0.942863 --> 0.941351).  Saving model ...
Validation loss decreased (0.941351 --> 0.939887).  Saving model ...
EarlyStopping counter: 1 out of 5.0
EarlyStopping counter: 2 out of 5.0
Validation loss decreased (0.939887 --> 0.938599).  Saving model ...
Validation loss decreased (0.938599 --> 0.934516).  Saving model ...
Validation loss decreased (0.934516 --> 0.931918).  Saving model ...
EarlyStopping counter: 1 out of 5.0
EarlyStopping counter: 2 out of 5.0
EarlyStopping counter: 3 out of 5.0
EarlyStopping counter: 4 out of 5.0
Validation loss decreased (0.931918 --> 0.930747).  Saving model ...
Validation loss decreased (0.930747 --> 0.930361).  Saving model ...
EarlyStopping counter: 1 out of 5.0
EarlyStopping counter: 2 out of 5.0
EarlyStopping counter: 3 out of 5.0
Validation loss decreased (0.930361 --> 0.930194).  Saving model ...
Validation loss decreased (0.930194 --> 0.927983).  Saving model ...
EarlyStopping counter: 1 out of 5.0
EarlyStopping counter: 2 out of 5.0
EarlyStopping counter: 3 out of 5.0
EarlyStopping counter: 4 out of 5.0
EarlyStopping counter: 5 out of 5.0
/localscratch/yinan.29152578.0/env/lib/python3.7/site-packages/torch/nn/functional.py:1794: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.
  warnings.warn("nn.functional.tanh is deprecated. Use torch.tanh instead.")
wandb: Waiting for W&B process to finish, PID 153147... (success).
wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: \ 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: | 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: / 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: \ 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: | 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: / 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: \ 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: | 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: / 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb:                                                                                
wandb: Run history:
wandb:     e_F1 ▁▂▂▃▃▄▅▅▅▆▅▆▆▆▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇██████████
wandb:   e_loss ██▇▇▇▆▆▆▆▅▅▅▄▄▄▃▃▃▃▃▂▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁
wandb:     t_F1 ▁▂▂▂▂▃▃▄▄▄▅▅▅▅▆▆▆▆▆▇▆▆▆▇▇▇▇▇▇▇▇▇▇▇▇█████
wandb:   t_loss ███▇▇▇▇▆▆▆▅▆▅▅▅▅▄▄▄▄▄▃▃▃▃▃▃▃▂▂▂▂▂▂▂▂▂▁▁▁
wandb: 
wandb: Run summary:
wandb:     e_F1 61.52283
wandb:   e_loss 0.9316
wandb:     t_F1 70.48751
wandb:   t_loss 0.77324
wandb: 
wandb: Synced 4 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Synced iconic-capybara-2: https://wandb.ai/yinanazhou/xl_512_bs_8_lr_1e06_es_5_lc_False_nr_True_sr_False_stem_False_lemma_False_repeat_2_fold_2/runs/2wntw52x
wandb: Find logs at: ./wandb/run-20220317_212729-2wntw52x/logs/debug.log
wandb: 

wandb: wandb version 0.12.11 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
2022-03-17 22:48:04.697491: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1
wandb: Tracking run with wandb version 0.12.5
wandb: Syncing run divine-darkness-2
wandb: ⭐️ View project at https://wandb.ai/yinanazhou/xl_512_bs_8_lr_1e06_es_5_lc_False_nr_True_sr_False_stem_False_lemma_False_repeat_3_fold_1
wandb: 🚀 View run at https://wandb.ai/yinanazhou/xl_512_bs_8_lr_1e06_es_5_lc_False_nr_True_sr_False_stem_False_lemma_False_repeat_3_fold_1/runs/3h692jxy
wandb: Run data is saved locally in /project/6002780/yinan/Thesis_MER_Lyrics/lyric-emotion/wandb/run-20220317_224801-3h692jxy
wandb: Run `wandb offline` to turn off syncing.

Validation loss decreased (inf --> 1.442867).  Saving model ...
Validation loss decreased (1.442867 --> 1.416862).  Saving model ...
Validation loss decreased (1.416862 --> 1.396803).  Saving model ...
Validation loss decreased (1.396803 --> 1.382644).  Saving model ...
Validation loss decreased (1.382644 --> 1.372422).  Saving model ...
Validation loss decreased (1.372422 --> 1.364473).  Saving model ...
Validation loss decreased (1.364473 --> 1.358362).  Saving model ...
Validation loss decreased (1.358362 --> 1.352960).  Saving model ...
Validation loss decreased (1.352960 --> 1.348188).  Saving model ...
Validation loss decreased (1.348188 --> 1.343215).  Saving model ...
Validation loss decreased (1.343215 --> 1.339015).  Saving model ...
Validation loss decreased (1.339015 --> 1.334441).  Saving model ...
Validation loss decreased (1.334441 --> 1.329849).  Saving model ...
Validation loss decreased (1.329849 --> 1.324979).  Saving model ...
Validation loss decreased (1.324979 --> 1.320420).  Saving model ...
Validation loss decreased (1.320420 --> 1.314688).  Saving model ...
Validation loss decreased (1.314688 --> 1.309683).  Saving model ...
Validation loss decreased (1.309683 --> 1.305239).  Saving model ...
Validation loss decreased (1.305239 --> 1.299460).  Saving model ...
Validation loss decreased (1.299460 --> 1.293981).  Saving model ...
Validation loss decreased (1.293981 --> 1.287505).  Saving model ...
Validation loss decreased (1.287505 --> 1.281985).  Saving model ...
Validation loss decreased (1.281985 --> 1.276146).  Saving model ...
Validation loss decreased (1.276146 --> 1.269974).  Saving model ...
Validation loss decreased (1.269974 --> 1.263406).  Saving model ...
Validation loss decreased (1.263406 --> 1.257450).  Saving model ...
Validation loss decreased (1.257450 --> 1.250286).  Saving model ...
Validation loss decreased (1.250286 --> 1.244113).  Saving model ...
Validation loss decreased (1.244113 --> 1.235388).  Saving model ...
Validation loss decreased (1.235388 --> 1.227250).  Saving model ...
Validation loss decreased (1.227250 --> 1.219219).  Saving model ...
Validation loss decreased (1.219219 --> 1.213616).  Saving model ...
Validation loss decreased (1.213616 --> 1.203310).  Saving model ...
Validation loss decreased (1.203310 --> 1.194887).  Saving model ...
Validation loss decreased (1.194887 --> 1.184956).  Saving model ...
Validation loss decreased (1.184956 --> 1.179958).  Saving model ...
Validation loss decreased (1.179958 --> 1.174177).  Saving model ...
Validation loss decreased (1.174177 --> 1.166286).  Saving model ...
Validation loss decreased (1.166286 --> 1.160552).  Saving model ...
Validation loss decreased (1.160552 --> 1.154231).  Saving model ...
Validation loss decreased (1.154231 --> 1.147393).  Saving model ...
Validation loss decreased (1.147393 --> 1.142527).  Saving model ...
Validation loss decreased (1.142527 --> 1.134982).  Saving model ...
Validation loss decreased (1.134982 --> 1.129575).  Saving model ...
Validation loss decreased (1.129575 --> 1.123948).  Saving model ...
Validation loss decreased (1.123948 --> 1.119784).  Saving model ...
Validation loss decreased (1.119784 --> 1.115711).  Saving model ...
Validation loss decreased (1.115711 --> 1.111897).  Saving model ...
Validation loss decreased (1.111897 --> 1.110042).  Saving model ...
Validation loss decreased (1.110042 --> 1.104826).  Saving model ...
Validation loss decreased (1.104826 --> 1.102527).  Saving model ...
Validation loss decreased (1.102527 --> 1.095717).  Saving model ...
Validation loss decreased (1.095717 --> 1.091221).  Saving model ...
Validation loss decreased (1.091221 --> 1.087255).  Saving model ...
Validation loss decreased (1.087255 --> 1.081295).  Saving model ...
Validation loss decreased (1.081295 --> 1.078019).  Saving model ...
Validation loss decreased (1.078019 --> 1.075680).  Saving model ...
Validation loss decreased (1.075680 --> 1.075035).  Saving model ...
Validation loss decreased (1.075035 --> 1.071439).  Saving model ...
Validation loss decreased (1.071439 --> 1.070272).  Saving model ...
Validation loss decreased (1.070272 --> 1.066857).  Saving model ...
Validation loss decreased (1.066857 --> 1.063974).  Saving model ...
Validation loss decreased (1.063974 --> 1.058534).  Saving model ...
Validation loss decreased (1.058534 --> 1.056115).  Saving model ...
Validation loss decreased (1.056115 --> 1.054148).  Saving model ...
Validation loss decreased (1.054148 --> 1.050389).  Saving model ...
Validation loss decreased (1.050389 --> 1.049611).  Saving model ...
Validation loss decreased (1.049611 --> 1.045568).  Saving model ...
Validation loss decreased (1.045568 --> 1.042994).  Saving model ...
Validation loss decreased (1.042994 --> 1.037348).  Saving model ...
Validation loss decreased (1.037348 --> 1.034959).  Saving model ...
Validation loss decreased (1.034959 --> 1.031502).  Saving model ...
EarlyStopping counter: 1 out of 5.0
Validation loss decreased (1.031502 --> 1.031335).  Saving model ...
Validation loss decreased (1.031335 --> 1.028627).  Saving model ...
Validation loss decreased (1.028627 --> 1.025566).  Saving model ...
Validation loss decreased (1.025566 --> 1.022645).  Saving model ...
Validation loss decreased (1.022645 --> 1.021943).  Saving model ...
Validation loss decreased (1.021943 --> 1.016759).  Saving model ...
Validation loss decreased (1.016759 --> 1.013286).  Saving model ...
Validation loss decreased (1.013286 --> 1.013113).  Saving model ...
EarlyStopping counter: 1 out of 5.0
Validation loss decreased (1.013113 --> 1.010856).  Saving model ...
EarlyStopping counter: 1 out of 5.0
Validation loss decreased (1.010856 --> 1.007638).  Saving model ...
Validation loss decreased (1.007638 --> 1.005204).  Saving model ...
Validation loss decreased (1.005204 --> 1.003918).  Saving model ...
Validation loss decreased (1.003918 --> 1.003251).  Saving model ...
Validation loss decreased (1.003251 --> 1.000536).  Saving model ...
EarlyStopping counter: 1 out of 5.0
Validation loss decreased (1.000536 --> 0.997489).  Saving model ...
Validation loss decreased (0.997489 --> 0.992146).  Saving model ...
EarlyStopping counter: 1 out of 5.0
Validation loss decreased (0.992146 --> 0.990956).  Saving model ...
Validation loss decreased (0.990956 --> 0.987831).  Saving model ...
EarlyStopping counter: 1 out of 5.0
EarlyStopping counter: 2 out of 5.0
EarlyStopping counter: 3 out of 5.0
EarlyStopping counter: 4 out of 5.0
EarlyStopping counter: 5 out of 5.0
/localscratch/yinan.29152578.0/env/lib/python3.7/site-packages/torch/nn/functional.py:1794: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.
  warnings.warn("nn.functional.tanh is deprecated. Use torch.tanh instead.")
wandb: Waiting for W&B process to finish, PID 157438... (success).
wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: \ 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: | 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: / 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: \ 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: | 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: / 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: \ 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: | 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: / 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb:                                                                                
wandb: Run history:
wandb:     e_F1 ▁▂▃▃▅▅▅▅▆▆▆▆▆▆▆▇▇▇▇▇▇▇▇▇▇▇██████████████
wandb:   e_loss █▇▇▇▆▆▆▆▆▅▅▅▅▄▄▄▃▃▃▃▃▃▂▂▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁
wandb:     t_F1 ▁▂▂▂▃▃▃▄▄▄▅▄▅▅▅▅▆▆▆▆▆▆▇▇▆▇▇▇▇▇▇▇▇█▇██▇██
wandb:   t_loss ██▇▇▇▇▆▆▆▆▆▆▅▅▅▅▄▄▄▄▄▃▃▃▃▃▂▃▃▂▂▂▂▂▂▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:     e_F1 56.75471
wandb:   e_loss 0.98876
wandb:     t_F1 68.69354
wandb:   t_loss 0.8212
wandb: 
wandb: Synced 4 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Synced divine-darkness-2: https://wandb.ai/yinanazhou/xl_512_bs_8_lr_1e06_es_5_lc_False_nr_True_sr_False_stem_False_lemma_False_repeat_3_fold_1/runs/3h692jxy
wandb: Find logs at: ./wandb/run-20220317_224801-3h692jxy/logs/debug.log
wandb: 

wandb: wandb version 0.12.11 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
2022-03-17 23:52:43.607335: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1
wandb: Tracking run with wandb version 0.12.5
wandb: Syncing run peach-armadillo-2
wandb: ⭐️ View project at https://wandb.ai/yinanazhou/xl_512_bs_8_lr_1e06_es_5_lc_False_nr_True_sr_False_stem_False_lemma_False_repeat_3_fold_2
wandb: 🚀 View run at https://wandb.ai/yinanazhou/xl_512_bs_8_lr_1e06_es_5_lc_False_nr_True_sr_False_stem_False_lemma_False_repeat_3_fold_2/runs/1c4jfhq8
wandb: Run data is saved locally in /project/6002780/yinan/Thesis_MER_Lyrics/lyric-emotion/wandb/run-20220317_235240-1c4jfhq8
wandb: Run `wandb offline` to turn off syncing.

Validation loss decreased (inf --> 1.464934).  Saving model ...
Validation loss decreased (1.464934 --> 1.438537).  Saving model ...
Validation loss decreased (1.438537 --> 1.417597).  Saving model ...
Validation loss decreased (1.417597 --> 1.400033).  Saving model ...
Validation loss decreased (1.400033 --> 1.387468).  Saving model ...
Validation loss decreased (1.387468 --> 1.377364).  Saving model ...
Validation loss decreased (1.377364 --> 1.369243).  Saving model ...
Validation loss decreased (1.369243 --> 1.363102).  Saving model ...
Validation loss decreased (1.363102 --> 1.357602).  Saving model ...
Validation loss decreased (1.357602 --> 1.351983).  Saving model ...
Validation loss decreased (1.351983 --> 1.347059).  Saving model ...
Validation loss decreased (1.347059 --> 1.341750).  Saving model ...
Validation loss decreased (1.341750 --> 1.336795).  Saving model ...
Validation loss decreased (1.336795 --> 1.332080).  Saving model ...
Validation loss decreased (1.332080 --> 1.326481).  Saving model ...
Validation loss decreased (1.326481 --> 1.321195).  Saving model ...
Validation loss decreased (1.321195 --> 1.315637).  Saving model ...
Validation loss decreased (1.315637 --> 1.309677).  Saving model ...
Validation loss decreased (1.309677 --> 1.304954).  Saving model ...
Validation loss decreased (1.304954 --> 1.298953).  Saving model ...
Validation loss decreased (1.298953 --> 1.292247).  Saving model ...
Validation loss decreased (1.292247 --> 1.286101).  Saving model ...
Validation loss decreased (1.286101 --> 1.280349).  Saving model ...
Validation loss decreased (1.280349 --> 1.273965).  Saving model ...
Validation loss decreased (1.273965 --> 1.267705).  Saving model ...
Validation loss decreased (1.267705 --> 1.260013).  Saving model ...
Validation loss decreased (1.260013 --> 1.252700).  Saving model ...
Validation loss decreased (1.252700 --> 1.247359).  Saving model ...
Validation loss decreased (1.247359 --> 1.240262).  Saving model ...
Validation loss decreased (1.240262 --> 1.234197).  Saving model ...
Validation loss decreased (1.234197 --> 1.228183).  Saving model ...
Validation loss decreased (1.228183 --> 1.220514).  Saving model ...
Validation loss decreased (1.220514 --> 1.211811).  Saving model ...
Validation loss decreased (1.211811 --> 1.204529).  Saving model ...
Validation loss decreased (1.204529 --> 1.197910).  Saving model ...
Validation loss decreased (1.197910 --> 1.193561).  Saving model ...
Validation loss decreased (1.193561 --> 1.187455).  Saving model ...
Validation loss decreased (1.187455 --> 1.180269).  Saving model ...
Validation loss decreased (1.180269 --> 1.174272).  Saving model ...
Validation loss decreased (1.174272 --> 1.168741).  Saving model ...
Validation loss decreased (1.168741 --> 1.164788).  Saving model ...
Validation loss decreased (1.164788 --> 1.160603).  Saving model ...
Validation loss decreased (1.160603 --> 1.155328).  Saving model ...
Validation loss decreased (1.155328 --> 1.149229).  Saving model ...
Validation loss decreased (1.149229 --> 1.144564).  Saving model ...
Validation loss decreased (1.144564 --> 1.137879).  Saving model ...
Validation loss decreased (1.137879 --> 1.132475).  Saving model ...
Validation loss decreased (1.132475 --> 1.127625).  Saving model ...
Validation loss decreased (1.127625 --> 1.122564).  Saving model ...
Validation loss decreased (1.122564 --> 1.116794).  Saving model ...
Validation loss decreased (1.116794 --> 1.111073).  Saving model ...
Validation loss decreased (1.111073 --> 1.107418).  Saving model ...
Validation loss decreased (1.107418 --> 1.103807).  Saving model ...
Validation loss decreased (1.103807 --> 1.097048).  Saving model ...
Validation loss decreased (1.097048 --> 1.093863).  Saving model ...
Validation loss decreased (1.093863 --> 1.088531).  Saving model ...
Validation loss decreased (1.088531 --> 1.084152).  Saving model ...
Validation loss decreased (1.084152 --> 1.079468).  Saving model ...
Validation loss decreased (1.079468 --> 1.073900).  Saving model ...
Validation loss decreased (1.073900 --> 1.071326).  Saving model ...
Validation loss decreased (1.071326 --> 1.066892).  Saving model ...
Validation loss decreased (1.066892 --> 1.062458).  Saving model ...
Validation loss decreased (1.062458 --> 1.059782).  Saving model ...
Validation loss decreased (1.059782 --> 1.056371).  Saving model ...
Validation loss decreased (1.056371 --> 1.053112).  Saving model ...
Validation loss decreased (1.053112 --> 1.048900).  Saving model ...
Validation loss decreased (1.048900 --> 1.046509).  Saving model ...
Validation loss decreased (1.046509 --> 1.043501).  Saving model ...
Validation loss decreased (1.043501 --> 1.038851).  Saving model ...
Validation loss decreased (1.038851 --> 1.033845).  Saving model ...
Validation loss decreased (1.033845 --> 1.031207).  Saving model ...
Validation loss decreased (1.031207 --> 1.026452).  Saving model ...
Validation loss decreased (1.026452 --> 1.023508).  Saving model ...
Validation loss decreased (1.023508 --> 1.021770).  Saving model ...
Validation loss decreased (1.021770 --> 1.021344).  Saving model ...
Validation loss decreased (1.021344 --> 1.016627).  Saving model ...
Validation loss decreased (1.016627 --> 1.015261).  Saving model ...
Validation loss decreased (1.015261 --> 1.011842).  Saving model ...
Validation loss decreased (1.011842 --> 1.007744).  Saving model ...
Validation loss decreased (1.007744 --> 1.003062).  Saving model ...
Validation loss decreased (1.003062 --> 1.000932).  Saving model ...
Validation loss decreased (1.000932 --> 0.999131).  Saving model ...
Validation loss decreased (0.999131 --> 0.994744).  Saving model ...
Validation loss decreased (0.994744 --> 0.992416).  Saving model ...
Validation loss decreased (0.992416 --> 0.987806).  Saving model ...
Validation loss decreased (0.987806 --> 0.986256).  Saving model ...
Validation loss decreased (0.986256 --> 0.983897).  Saving model ...
Validation loss decreased (0.983897 --> 0.980648).  Saving model ...
EarlyStopping counter: 1 out of 5.0
Validation loss decreased (0.980648 --> 0.980646).  Saving model ...
Validation loss decreased (0.980646 --> 0.976943).  Saving model ...
Validation loss decreased (0.976943 --> 0.973110).  Saving model ...
Validation loss decreased (0.973110 --> 0.971097).  Saving model ...
Validation loss decreased (0.971097 --> 0.967822).  Saving model ...
Validation loss decreased (0.967822 --> 0.966014).  Saving model ...
Validation loss decreased (0.966014 --> 0.963386).  Saving model ...
Validation loss decreased (0.963386 --> 0.962049).  Saving model ...
Validation loss decreased (0.962049 --> 0.959010).  Saving model ...
Validation loss decreased (0.959010 --> 0.957544).  Saving model ...
Validation loss decreased (0.957544 --> 0.956269).  Saving model ...
Validation loss decreased (0.956269 --> 0.952695).  Saving model ...
Validation loss decreased (0.952695 --> 0.951957).  Saving model ...
Validation loss decreased (0.951957 --> 0.949923).  Saving model ...
EarlyStopping counter: 1 out of 5.0
Validation loss decreased (0.949923 --> 0.948858).  Saving model ...
Validation loss decreased (0.948858 --> 0.947387).  Saving model ...
EarlyStopping counter: 1 out of 5.0
Validation loss decreased (0.947387 --> 0.945410).  Saving model ...
Validation loss decreased (0.945410 --> 0.943756).  Saving model ...
EarlyStopping counter: 1 out of 5.0
Validation loss decreased (0.943756 --> 0.943353).  Saving model ...
Validation loss decreased (0.943353 --> 0.940832).  Saving model ...
Validation loss decreased (0.940832 --> 0.939386).  Saving model ...
Validation loss decreased (0.939386 --> 0.938878).  Saving model ...
Validation loss decreased (0.938878 --> 0.938225).  Saving model ...
Validation loss decreased (0.938225 --> 0.936545).  Saving model ...
Validation loss decreased (0.936545 --> 0.935613).  Saving model ...
EarlyStopping counter: 1 out of 5.0
Validation loss decreased (0.935613 --> 0.934874).  Saving model ...
Validation loss decreased (0.934874 --> 0.934629).  Saving model ...
Validation loss decreased (0.934629 --> 0.933876).  Saving model ...
Validation loss decreased (0.933876 --> 0.933487).  Saving model ...
Validation loss decreased (0.933487 --> 0.933429).  Saving model ...
Validation loss decreased (0.933429 --> 0.933304).  Saving model ...
Validation loss decreased (0.933304 --> 0.932333).  Saving model ...
Validation loss decreased (0.932333 --> 0.929982).  Saving model ...
Validation loss decreased (0.929982 --> 0.929586).  Saving model ...
Validation loss decreased (0.929586 --> 0.929547).  Saving model ...
EarlyStopping counter: 1 out of 5.0
EarlyStopping counter: 2 out of 5.0
Validation loss decreased (0.929547 --> 0.929408).  Saving model ...
EarlyStopping counter: 1 out of 5.0
EarlyStopping counter: 2 out of 5.0
EarlyStopping counter: 3 out of 5.0
Validation loss decreased (0.929408 --> 0.928176).  Saving model ...
EarlyStopping counter: 1 out of 5.0
EarlyStopping counter: 2 out of 5.0
Validation loss decreased (0.928176 --> 0.927865).  Saving model ...
EarlyStopping counter: 1 out of 5.0
EarlyStopping counter: 2 out of 5.0
Validation loss decreased (0.927865 --> 0.927467).  Saving model ...
Validation loss decreased (0.927467 --> 0.927208).  Saving model ...
EarlyStopping counter: 1 out of 5.0
EarlyStopping counter: 2 out of 5.0
EarlyStopping counter: 3 out of 5.0
EarlyStopping counter: 4 out of 5.0
EarlyStopping counter: 5 out of 5.0
/localscratch/yinan.29152578.0/env/lib/python3.7/site-packages/torch/nn/functional.py:1794: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.
  warnings.warn("nn.functional.tanh is deprecated. Use torch.tanh instead.")
wandb: Waiting for W&B process to finish, PID 160962... (success).
wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: \ 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: | 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: / 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: \ 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: | 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: / 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: \ 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: | 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: / 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb:                                                                                
wandb: Run history:
wandb:     e_F1 ▁▁▂▄▄▅▅▅▅▅▆▆▆▆▆▆▇▇▇▇▇▇▇▇▇▇██████████████
wandb:   e_loss █▇▇▇▆▆▆▆▅▅▄▄▄▄▃▃▃▃▃▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:     t_F1 ▁▂▃▃▃▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▆▆▇▇▇▇▇▇▇███▇█▇█████
wandb:   t_loss ██▇▇▇▇▇▆▆▆▅▅▅▅▅▄▄▄▄▄▄▃▃▃▃▃▃▃▂▂▂▂▂▂▂▁▂▁▁▁
wandb: 
wandb: Run summary:
wandb:     e_F1 61.27769
wandb:   e_loss 0.92747
wandb:     t_F1 71.46328
wandb:   t_loss 0.72095
wandb: 
wandb: Synced 4 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Synced peach-armadillo-2: https://wandb.ai/yinanazhou/xl_512_bs_8_lr_1e06_es_5_lc_False_nr_True_sr_False_stem_False_lemma_False_repeat_3_fold_2/runs/1c4jfhq8
wandb: Find logs at: ./wandb/run-20220317_235240-1c4jfhq8/logs/debug.log
wandb: 

wandb: wandb version 0.12.11 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
2022-03-18 01:24:54.837366: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1
wandb: Tracking run with wandb version 0.12.5
wandb: Syncing run fresh-lion-2
wandb: ⭐️ View project at https://wandb.ai/yinanazhou/xl_512_bs_8_lr_1e06_es_5_lc_False_nr_True_sr_False_stem_False_lemma_False_repeat_4_fold_1
wandb: 🚀 View run at https://wandb.ai/yinanazhou/xl_512_bs_8_lr_1e06_es_5_lc_False_nr_True_sr_False_stem_False_lemma_False_repeat_4_fold_1/runs/16c9ytg9
wandb: Run data is saved locally in /project/6002780/yinan/Thesis_MER_Lyrics/lyric-emotion/wandb/run-20220318_012451-16c9ytg9
wandb: Run `wandb offline` to turn off syncing.

Validation loss decreased (inf --> 1.454580).  Saving model ...
Validation loss decreased (1.454580 --> 1.423662).  Saving model ...
Validation loss decreased (1.423662 --> 1.403209).  Saving model ...
Validation loss decreased (1.403209 --> 1.388146).  Saving model ...
Validation loss decreased (1.388146 --> 1.378766).  Saving model ...
Validation loss decreased (1.378766 --> 1.371383).  Saving model ...
Validation loss decreased (1.371383 --> 1.365910).  Saving model ...
Validation loss decreased (1.365910 --> 1.360977).  Saving model ...
Validation loss decreased (1.360977 --> 1.356161).  Saving model ...
Validation loss decreased (1.356161 --> 1.351713).  Saving model ...
Validation loss decreased (1.351713 --> 1.347056).  Saving model ...
Validation loss decreased (1.347056 --> 1.342194).  Saving model ...
Validation loss decreased (1.342194 --> 1.337911).  Saving model ...
Validation loss decreased (1.337911 --> 1.333099).  Saving model ...
Validation loss decreased (1.333099 --> 1.327741).  Saving model ...
Validation loss decreased (1.327741 --> 1.322808).  Saving model ...
Validation loss decreased (1.322808 --> 1.317073).  Saving model ...
Validation loss decreased (1.317073 --> 1.311008).  Saving model ...
Validation loss decreased (1.311008 --> 1.305611).  Saving model ...
Validation loss decreased (1.305611 --> 1.299901).  Saving model ...
Validation loss decreased (1.299901 --> 1.294376).  Saving model ...
Validation loss decreased (1.294376 --> 1.288310).  Saving model ...
Validation loss decreased (1.288310 --> 1.282765).  Saving model ...
Validation loss decreased (1.282765 --> 1.276171).  Saving model ...
Validation loss decreased (1.276171 --> 1.269590).  Saving model ...
Validation loss decreased (1.269590 --> 1.262585).  Saving model ...
Validation loss decreased (1.262585 --> 1.255666).  Saving model ...
Validation loss decreased (1.255666 --> 1.247816).  Saving model ...
Validation loss decreased (1.247816 --> 1.240501).  Saving model ...
Validation loss decreased (1.240501 --> 1.233928).  Saving model ...
Validation loss decreased (1.233928 --> 1.227920).  Saving model ...
Validation loss decreased (1.227920 --> 1.220870).  Saving model ...
Validation loss decreased (1.220870 --> 1.214376).  Saving model ...
Validation loss decreased (1.214376 --> 1.207619).  Saving model ...
Validation loss decreased (1.207619 --> 1.202096).  Saving model ...
Validation loss decreased (1.202096 --> 1.195602).  Saving model ...
Validation loss decreased (1.195602 --> 1.189574).  Saving model ...
Validation loss decreased (1.189574 --> 1.183718).  Saving model ...
Validation loss decreased (1.183718 --> 1.177342).  Saving model ...
Validation loss decreased (1.177342 --> 1.172333).  Saving model ...
Validation loss decreased (1.172333 --> 1.167793).  Saving model ...
Validation loss decreased (1.167793 --> 1.162388).  Saving model ...
Validation loss decreased (1.162388 --> 1.157161).  Saving model ...
Validation loss decreased (1.157161 --> 1.152959).  Saving model ...
Validation loss decreased (1.152959 --> 1.148959).  Saving model ...
Validation loss decreased (1.148959 --> 1.143029).  Saving model ...
Validation loss decreased (1.143029 --> 1.136851).  Saving model ...
Validation loss decreased (1.136851 --> 1.134884).  Saving model ...
Validation loss decreased (1.134884 --> 1.128514).  Saving model ...
Validation loss decreased (1.128514 --> 1.126982).  Saving model ...
Validation loss decreased (1.126982 --> 1.124411).  Saving model ...
Validation loss decreased (1.124411 --> 1.119704).  Saving model ...
Validation loss decreased (1.119704 --> 1.115624).  Saving model ...
Validation loss decreased (1.115624 --> 1.112135).  Saving model ...
Validation loss decreased (1.112135 --> 1.107021).  Saving model ...
Validation loss decreased (1.107021 --> 1.102190).  Saving model ...
Validation loss decreased (1.102190 --> 1.098166).  Saving model ...
Validation loss decreased (1.098166 --> 1.095607).  Saving model ...
Validation loss decreased (1.095607 --> 1.091006).  Saving model ...
Validation loss decreased (1.091006 --> 1.088088).  Saving model ...
Validation loss decreased (1.088088 --> 1.086147).  Saving model ...
Validation loss decreased (1.086147 --> 1.082691).  Saving model ...
Validation loss decreased (1.082691 --> 1.078127).  Saving model ...
Validation loss decreased (1.078127 --> 1.074912).  Saving model ...
Validation loss decreased (1.074912 --> 1.072359).  Saving model ...
Validation loss decreased (1.072359 --> 1.067830).  Saving model ...
Validation loss decreased (1.067830 --> 1.063998).  Saving model ...
Validation loss decreased (1.063998 --> 1.061433).  Saving model ...
Validation loss decreased (1.061433 --> 1.057688).  Saving model ...
Validation loss decreased (1.057688 --> 1.054415).  Saving model ...
Validation loss decreased (1.054415 --> 1.052241).  Saving model ...
Validation loss decreased (1.052241 --> 1.049905).  Saving model ...
Validation loss decreased (1.049905 --> 1.047230).  Saving model ...
Validation loss decreased (1.047230 --> 1.044992).  Saving model ...
Validation loss decreased (1.044992 --> 1.042002).  Saving model ...
Validation loss decreased (1.042002 --> 1.039724).  Saving model ...
Validation loss decreased (1.039724 --> 1.037177).  Saving model ...
Validation loss decreased (1.037177 --> 1.034843).  Saving model ...
Validation loss decreased (1.034843 --> 1.032935).  Saving model ...
Validation loss decreased (1.032935 --> 1.031186).  Saving model ...
Validation loss decreased (1.031186 --> 1.027874).  Saving model ...
Validation loss decreased (1.027874 --> 1.026422).  Saving model ...
Validation loss decreased (1.026422 --> 1.023295).  Saving model ...
Validation loss decreased (1.023295 --> 1.020778).  Saving model ...
Validation loss decreased (1.020778 --> 1.019459).  Saving model ...
Validation loss decreased (1.019459 --> 1.017034).  Saving model ...
Validation loss decreased (1.017034 --> 1.014237).  Saving model ...
Validation loss decreased (1.014237 --> 1.011522).  Saving model ...
Validation loss decreased (1.011522 --> 1.010734).  Saving model ...
Validation loss decreased (1.010734 --> 1.009228).  Saving model ...
Validation loss decreased (1.009228 --> 1.008648).  Saving model ...
Validation loss decreased (1.008648 --> 1.006961).  Saving model ...
Validation loss decreased (1.006961 --> 1.004356).  Saving model ...
Validation loss decreased (1.004356 --> 1.002304).  Saving model ...
Validation loss decreased (1.002304 --> 0.999768).  Saving model ...
Validation loss decreased (0.999768 --> 0.998310).  Saving model ...
Validation loss decreased (0.998310 --> 0.997728).  Saving model ...
EarlyStopping counter: 1 out of 5.0
Validation loss decreased (0.997728 --> 0.996447).  Saving model ...
Validation loss decreased (0.996447 --> 0.995989).  Saving model ...
Validation loss decreased (0.995989 --> 0.994214).  Saving model ...
Validation loss decreased (0.994214 --> 0.992291).  Saving model ...
Validation loss decreased (0.992291 --> 0.991984).  Saving model ...
Validation loss decreased (0.991984 --> 0.990749).  Saving model ...
Validation loss decreased (0.990749 --> 0.989057).  Saving model ...
Validation loss decreased (0.989057 --> 0.988317).  Saving model ...
Validation loss decreased (0.988317 --> 0.986321).  Saving model ...
Validation loss decreased (0.986321 --> 0.984619).  Saving model ...
Validation loss decreased (0.984619 --> 0.983729).  Saving model ...
Validation loss decreased (0.983729 --> 0.983555).  Saving model ...
Validation loss decreased (0.983555 --> 0.983239).  Saving model ...
EarlyStopping counter: 1 out of 5.0
Validation loss decreased (0.983239 --> 0.981783).  Saving model ...
Validation loss decreased (0.981783 --> 0.981018).  Saving model ...
EarlyStopping counter: 1 out of 5.0
Validation loss decreased (0.981018 --> 0.980570).  Saving model ...
Validation loss decreased (0.980570 --> 0.978363).  Saving model ...
Validation loss decreased (0.978363 --> 0.977039).  Saving model ...
EarlyStopping counter: 1 out of 5.0
EarlyStopping counter: 2 out of 5.0
EarlyStopping counter: 3 out of 5.0
EarlyStopping counter: 4 out of 5.0
EarlyStopping counter: 5 out of 5.0
/localscratch/yinan.29152578.0/env/lib/python3.7/site-packages/torch/nn/functional.py:1794: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.
  warnings.warn("nn.functional.tanh is deprecated. Use torch.tanh instead.")
wandb: Waiting for W&B process to finish, PID 165933... (success).
wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: \ 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: | 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: / 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: \ 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: | 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: / 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: \ 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: | 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: / 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb:                                                                                
wandb: Run history:
wandb:     e_F1 ▁▃▄▄▄▄▅▅▆▆▆▆▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇█████████████
wandb:   e_loss █▇▇▆▆▆▆▆▅▅▅▄▄▄▄▃▃▃▃▃▂▂▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁
wandb:     t_F1 ▁▂▃▃▄▄▄▄▄▅▄▅▆▆▆▆▆▆▆▆▆▆▇▆▇▇▇▇▇▇▇▇██▇██▇██
wandb:   t_loss █▇▇▇▇▆▆▆▆▆▆▅▅▅▄▄▄▄▄▄▃▃▃▃▃▃▃▂▂▂▂▂▂▂▂▁▁▁▂▁
wandb: 
wandb: Run summary:
wandb:     e_F1 57.69196
wandb:   e_loss 0.97739
wandb:     t_F1 69.50108
wandb:   t_loss 0.76304
wandb: 
wandb: Synced 4 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Synced fresh-lion-2: https://wandb.ai/yinanazhou/xl_512_bs_8_lr_1e06_es_5_lc_False_nr_True_sr_False_stem_False_lemma_False_repeat_4_fold_1/runs/16c9ytg9
wandb: Find logs at: ./wandb/run-20220318_012451-16c9ytg9/logs/debug.log
wandb: 

wandb: wandb version 0.12.11 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
2022-03-18 02:45:20.349008: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1
wandb: Tracking run with wandb version 0.12.5
wandb: Syncing run happy-river-2
wandb: ⭐️ View project at https://wandb.ai/yinanazhou/xl_512_bs_8_lr_1e06_es_5_lc_False_nr_True_sr_False_stem_False_lemma_False_repeat_4_fold_2
wandb: 🚀 View run at https://wandb.ai/yinanazhou/xl_512_bs_8_lr_1e06_es_5_lc_False_nr_True_sr_False_stem_False_lemma_False_repeat_4_fold_2/runs/21z091aw
wandb: Run data is saved locally in /project/6002780/yinan/Thesis_MER_Lyrics/lyric-emotion/wandb/run-20220318_024517-21z091aw
wandb: Run `wandb offline` to turn off syncing.

Validation loss decreased (inf --> 1.406911).  Saving model ...
Validation loss decreased (1.406911 --> 1.396084).  Saving model ...
Validation loss decreased (1.396084 --> 1.388050).  Saving model ...
Validation loss decreased (1.388050 --> 1.381819).  Saving model ...
Validation loss decreased (1.381819 --> 1.376221).  Saving model ...
Validation loss decreased (1.376221 --> 1.370801).  Saving model ...
Validation loss decreased (1.370801 --> 1.365824).  Saving model ...
Validation loss decreased (1.365824 --> 1.360935).  Saving model ...
Validation loss decreased (1.360935 --> 1.355771).  Saving model ...
Validation loss decreased (1.355771 --> 1.351144).  Saving model ...
Validation loss decreased (1.351144 --> 1.346100).  Saving model ...
Validation loss decreased (1.346100 --> 1.340972).  Saving model ...
Validation loss decreased (1.340972 --> 1.336085).  Saving model ...
Validation loss decreased (1.336085 --> 1.330578).  Saving model ...
Validation loss decreased (1.330578 --> 1.324867).  Saving model ...
Validation loss decreased (1.324867 --> 1.318812).  Saving model ...
Validation loss decreased (1.318812 --> 1.313279).  Saving model ...
Validation loss decreased (1.313279 --> 1.307141).  Saving model ...
Validation loss decreased (1.307141 --> 1.300762).  Saving model ...
Validation loss decreased (1.300762 --> 1.292813).  Saving model ...
Validation loss decreased (1.292813 --> 1.285300).  Saving model ...
Validation loss decreased (1.285300 --> 1.278402).  Saving model ...
Validation loss decreased (1.278402 --> 1.271084).  Saving model ...
Validation loss decreased (1.271084 --> 1.262540).  Saving model ...
Validation loss decreased (1.262540 --> 1.254080).  Saving model ...
Validation loss decreased (1.254080 --> 1.245884).  Saving model ...
Validation loss decreased (1.245884 --> 1.236490).  Saving model ...
Validation loss decreased (1.236490 --> 1.226551).  Saving model ...
Validation loss decreased (1.226551 --> 1.215653).  Saving model ...
Validation loss decreased (1.215653 --> 1.207527).  Saving model ...
Validation loss decreased (1.207527 --> 1.200223).  Saving model ...
Validation loss decreased (1.200223 --> 1.192077).  Saving model ...
Validation loss decreased (1.192077 --> 1.183744).  Saving model ...
Validation loss decreased (1.183744 --> 1.177469).  Saving model ...
Validation loss decreased (1.177469 --> 1.171159).  Saving model ...
Validation loss decreased (1.171159 --> 1.163091).  Saving model ...
Validation loss decreased (1.163091 --> 1.157606).  Saving model ...
Validation loss decreased (1.157606 --> 1.152359).  Saving model ...
Validation loss decreased (1.152359 --> 1.144632).  Saving model ...
Validation loss decreased (1.144632 --> 1.138068).  Saving model ...
Validation loss decreased (1.138068 --> 1.130933).  Saving model ...
Validation loss decreased (1.130933 --> 1.125677).  Saving model ...
Validation loss decreased (1.125677 --> 1.118217).  Saving model ...
Validation loss decreased (1.118217 --> 1.112616).  Saving model ...
Validation loss decreased (1.112616 --> 1.108826).  Saving model ...
Validation loss decreased (1.108826 --> 1.101221).  Saving model ...
Validation loss decreased (1.101221 --> 1.097268).  Saving model ...
Validation loss decreased (1.097268 --> 1.096017).  Saving model ...
Validation loss decreased (1.096017 --> 1.089319).  Saving model ...
Validation loss decreased (1.089319 --> 1.082929).  Saving model ...
Validation loss decreased (1.082929 --> 1.079025).  Saving model ...
Validation loss decreased (1.079025 --> 1.075572).  Saving model ...
Validation loss decreased (1.075572 --> 1.073975).  Saving model ...
Validation loss decreased (1.073975 --> 1.067531).  Saving model ...
Validation loss decreased (1.067531 --> 1.062492).  Saving model ...
Validation loss decreased (1.062492 --> 1.058551).  Saving model ...
Validation loss decreased (1.058551 --> 1.054810).  Saving model ...
Validation loss decreased (1.054810 --> 1.052543).  Saving model ...
Validation loss decreased (1.052543 --> 1.047854).  Saving model ...
Validation loss decreased (1.047854 --> 1.044601).  Saving model ...
Validation loss decreased (1.044601 --> 1.041766).  Saving model ...
Validation loss decreased (1.041766 --> 1.039789).  Saving model ...
Validation loss decreased (1.039789 --> 1.035623).  Saving model ...
Validation loss decreased (1.035623 --> 1.035129).  Saving model ...
Validation loss decreased (1.035129 --> 1.030706).  Saving model ...
Validation loss decreased (1.030706 --> 1.028923).  Saving model ...
Validation loss decreased (1.028923 --> 1.025007).  Saving model ...
Validation loss decreased (1.025007 --> 1.021518).  Saving model ...
Validation loss decreased (1.021518 --> 1.019427).  Saving model ...
Validation loss decreased (1.019427 --> 1.014564).  Saving model ...
Validation loss decreased (1.014564 --> 1.013577).  Saving model ...
EarlyStopping counter: 1 out of 5.0
Validation loss decreased (1.013577 --> 1.012451).  Saving model ...
EarlyStopping counter: 1 out of 5.0
Validation loss decreased (1.012451 --> 1.012287).  Saving model ...
Validation loss decreased (1.012287 --> 1.009334).  Saving model ...
Validation loss decreased (1.009334 --> 1.007680).  Saving model ...
Validation loss decreased (1.007680 --> 1.005832).  Saving model ...
Validation loss decreased (1.005832 --> 1.002093).  Saving model ...
EarlyStopping counter: 1 out of 5.0
Validation loss decreased (1.002093 --> 0.997262).  Saving model ...
Validation loss decreased (0.997262 --> 0.996131).  Saving model ...
Validation loss decreased (0.996131 --> 0.994099).  Saving model ...
Validation loss decreased (0.994099 --> 0.993088).  Saving model ...
Validation loss decreased (0.993088 --> 0.991764).  Saving model ...
EarlyStopping counter: 1 out of 5.0
EarlyStopping counter: 2 out of 5.0
Validation loss decreased (0.991764 --> 0.989979).  Saving model ...
Validation loss decreased (0.989979 --> 0.989353).  Saving model ...
EarlyStopping counter: 1 out of 5.0
Validation loss decreased (0.989353 --> 0.987140).  Saving model ...
Validation loss decreased (0.987140 --> 0.985194).  Saving model ...
Validation loss decreased (0.985194 --> 0.983250).  Saving model ...
EarlyStopping counter: 1 out of 5.0
EarlyStopping counter: 2 out of 5.0
EarlyStopping counter: 3 out of 5.0
Validation loss decreased (0.983250 --> 0.982229).  Saving model ...
Validation loss decreased (0.982229 --> 0.982106).  Saving model ...
EarlyStopping counter: 1 out of 5.0
Validation loss decreased (0.982106 --> 0.979090).  Saving model ...
EarlyStopping counter: 1 out of 5.0
EarlyStopping counter: 2 out of 5.0
EarlyStopping counter: 3 out of 5.0
EarlyStopping counter: 4 out of 5.0
EarlyStopping counter: 5 out of 5.0
/localscratch/yinan.29152578.0/env/lib/python3.7/site-packages/torch/nn/functional.py:1794: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.
  warnings.warn("nn.functional.tanh is deprecated. Use torch.tanh instead.")
wandb: Waiting for W&B process to finish, PID 170324... (success).
wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: \ 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: | 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: / 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: \ 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: | 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: / 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: \ 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: | 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: / 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: \ 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb:                                                                                
wandb: Run history:
wandb:     e_F1 ▁▁▃▅▅▅▅▅▆▆▆▆▇▇▇▇▇▇▇▇▇███████████████████
wandb:   e_loss ██▇▇▇▇▆▆▆▅▅▅▄▄▄▃▃▃▃▃▂▂▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁
wandb:     t_F1 ▁▁▂▂▃▃▄▄▄▅▄▅▅▅▆▆▆▆▆▆▇▆▆▇▇▇▇▇▇▇▇▇▇█▇▇████
wandb:   t_loss ███▇▇▇▇▇▆▆▆▆▅▅▅▅▅▄▄▄▄▄▃▃▃▃▃▂▂▂▂▂▂▁▂▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:     e_F1 58.66499
wandb:   e_loss 0.98408
wandb:     t_F1 71.46521
wandb:   t_loss 0.81104
wandb: 
wandb: Synced 4 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Synced happy-river-2: https://wandb.ai/yinanazhou/xl_512_bs_8_lr_1e06_es_5_lc_False_nr_True_sr_False_stem_False_lemma_False_repeat_4_fold_2/runs/21z091aw
wandb: Find logs at: ./wandb/run-20220318_024517-21z091aw/logs/debug.log
wandb: 

wandb: wandb version 0.12.11 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
2022-03-18 03:55:15.539121: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1
wandb: Tracking run with wandb version 0.12.5
wandb: Syncing run rosy-totem-2
wandb: ⭐️ View project at https://wandb.ai/yinanazhou/xl_512_bs_8_lr_1e06_es_5_lc_False_nr_True_sr_False_stem_False_lemma_False_repeat_5_fold_1
wandb: 🚀 View run at https://wandb.ai/yinanazhou/xl_512_bs_8_lr_1e06_es_5_lc_False_nr_True_sr_False_stem_False_lemma_False_repeat_5_fold_1/runs/3imc37ro
wandb: Run data is saved locally in /project/6002780/yinan/Thesis_MER_Lyrics/lyric-emotion/wandb/run-20220318_035512-3imc37ro
wandb: Run `wandb offline` to turn off syncing.

Validation loss decreased (inf --> 1.529619).  Saving model ...
Validation loss decreased (1.529619 --> 1.471132).  Saving model ...
Validation loss decreased (1.471132 --> 1.425736).  Saving model ...
Validation loss decreased (1.425736 --> 1.392362).  Saving model ...
Validation loss decreased (1.392362 --> 1.368286).  Saving model ...
Validation loss decreased (1.368286 --> 1.351891).  Saving model ...
Validation loss decreased (1.351891 --> 1.340646).  Saving model ...
Validation loss decreased (1.340646 --> 1.332573).  Saving model ...
Validation loss decreased (1.332573 --> 1.327536).  Saving model ...
Validation loss decreased (1.327536 --> 1.322817).  Saving model ...
Validation loss decreased (1.322817 --> 1.317539).  Saving model ...
Validation loss decreased (1.317539 --> 1.311894).  Saving model ...
Validation loss decreased (1.311894 --> 1.306356).  Saving model ...
Validation loss decreased (1.306356 --> 1.302229).  Saving model ...
Validation loss decreased (1.302229 --> 1.296430).  Saving model ...
Validation loss decreased (1.296430 --> 1.290638).  Saving model ...
Validation loss decreased (1.290638 --> 1.284110).  Saving model ...
Validation loss decreased (1.284110 --> 1.277384).  Saving model ...
Validation loss decreased (1.277384 --> 1.271762).  Saving model ...
Validation loss decreased (1.271762 --> 1.266137).  Saving model ...
Validation loss decreased (1.266137 --> 1.260571).  Saving model ...
Validation loss decreased (1.260571 --> 1.255243).  Saving model ...
Validation loss decreased (1.255243 --> 1.248572).  Saving model ...
Validation loss decreased (1.248572 --> 1.242414).  Saving model ...
Validation loss decreased (1.242414 --> 1.236791).  Saving model ...
Validation loss decreased (1.236791 --> 1.230706).  Saving model ...
Validation loss decreased (1.230706 --> 1.223308).  Saving model ...
Validation loss decreased (1.223308 --> 1.218138).  Saving model ...
Validation loss decreased (1.218138 --> 1.211301).  Saving model ...
Validation loss decreased (1.211301 --> 1.205003).  Saving model ...
Validation loss decreased (1.205003 --> 1.197386).  Saving model ...
Validation loss decreased (1.197386 --> 1.194887).  Saving model ...
Validation loss decreased (1.194887 --> 1.186228).  Saving model ...
Validation loss decreased (1.186228 --> 1.180730).  Saving model ...
Validation loss decreased (1.180730 --> 1.174373).  Saving model ...
Validation loss decreased (1.174373 --> 1.168952).  Saving model ...
Validation loss decreased (1.168952 --> 1.161225).  Saving model ...
Validation loss decreased (1.161225 --> 1.156981).  Saving model ...
Validation loss decreased (1.156981 --> 1.151891).  Saving model ...
Validation loss decreased (1.151891 --> 1.144921).  Saving model ...
Validation loss decreased (1.144921 --> 1.138591).  Saving model ...
Validation loss decreased (1.138591 --> 1.133617).  Saving model ...
Validation loss decreased (1.133617 --> 1.128080).  Saving model ...
Validation loss decreased (1.128080 --> 1.124908).  Saving model ...
Validation loss decreased (1.124908 --> 1.119474).  Saving model ...
Validation loss decreased (1.119474 --> 1.113681).  Saving model ...
Validation loss decreased (1.113681 --> 1.107186).  Saving model ...
Validation loss decreased (1.107186 --> 1.102115).  Saving model ...
Validation loss decreased (1.102115 --> 1.100152).  Saving model ...
Validation loss decreased (1.100152 --> 1.095589).  Saving model ...
Validation loss decreased (1.095589 --> 1.089594).  Saving model ...
Validation loss decreased (1.089594 --> 1.084017).  Saving model ...
Validation loss decreased (1.084017 --> 1.080393).  Saving model ...
Validation loss decreased (1.080393 --> 1.073861).  Saving model ...
Validation loss decreased (1.073861 --> 1.072169).  Saving model ...
Validation loss decreased (1.072169 --> 1.066911).  Saving model ...
Validation loss decreased (1.066911 --> 1.061894).  Saving model ...
Validation loss decreased (1.061894 --> 1.059016).  Saving model ...
Validation loss decreased (1.059016 --> 1.053372).  Saving model ...
Validation loss decreased (1.053372 --> 1.050154).  Saving model ...
Validation loss decreased (1.050154 --> 1.045371).  Saving model ...
Validation loss decreased (1.045371 --> 1.041226).  Saving model ...
Validation loss decreased (1.041226 --> 1.038074).  Saving model ...
Validation loss decreased (1.038074 --> 1.032735).  Saving model ...
Validation loss decreased (1.032735 --> 1.029161).  Saving model ...
Validation loss decreased (1.029161 --> 1.025636).  Saving model ...
Validation loss decreased (1.025636 --> 1.023503).  Saving model ...
Validation loss decreased (1.023503 --> 1.018908).  Saving model ...
Validation loss decreased (1.018908 --> 1.014228).  Saving model ...
Validation loss decreased (1.014228 --> 1.010576).  Saving model ...
Validation loss decreased (1.010576 --> 1.008552).  Saving model ...
Validation loss decreased (1.008552 --> 1.006022).  Saving model ...
Validation loss decreased (1.006022 --> 1.000845).  Saving model ...
Validation loss decreased (1.000845 --> 0.999871).  Saving model ...
Validation loss decreased (0.999871 --> 0.997625).  Saving model ...
Validation loss decreased (0.997625 --> 0.994867).  Saving model ...
Validation loss decreased (0.994867 --> 0.990723).  Saving model ...
Validation loss decreased (0.990723 --> 0.986720).  Saving model ...
Validation loss decreased (0.986720 --> 0.984918).  Saving model ...
Validation loss decreased (0.984918 --> 0.983050).  Saving model ...
Validation loss decreased (0.983050 --> 0.981559).  Saving model ...
Validation loss decreased (0.981559 --> 0.977581).  Saving model ...
Validation loss decreased (0.977581 --> 0.977388).  Saving model ...
Validation loss decreased (0.977388 --> 0.972613).  Saving model ...
Validation loss decreased (0.972613 --> 0.970785).  Saving model ...
Validation loss decreased (0.970785 --> 0.967333).  Saving model ...
Validation loss decreased (0.967333 --> 0.966580).  Saving model ...
Validation loss decreased (0.966580 --> 0.964871).  Saving model ...
Validation loss decreased (0.964871 --> 0.964247).  Saving model ...
Validation loss decreased (0.964247 --> 0.960901).  Saving model ...
Validation loss decreased (0.960901 --> 0.959902).  Saving model ...
Validation loss decreased (0.959902 --> 0.956820).  Saving model ...
Validation loss decreased (0.956820 --> 0.953814).  Saving model ...
EarlyStopping counter: 1 out of 5.0
Validation loss decreased (0.953814 --> 0.951816).  Saving model ...
Validation loss decreased (0.951816 --> 0.951268).  Saving model ...
Validation loss decreased (0.951268 --> 0.947487).  Saving model ...
Validation loss decreased (0.947487 --> 0.946816).  Saving model ...
EarlyStopping counter: 1 out of 5.0
Validation loss decreased (0.946816 --> 0.945590).  Saving model ...
Validation loss decreased (0.945590 --> 0.941289).  Saving model ...
Validation loss decreased (0.941289 --> 0.940467).  Saving model ...
Validation loss decreased (0.940467 --> 0.937720).  Saving model ...
Validation loss decreased (0.937720 --> 0.937644).  Saving model ...
Validation loss decreased (0.937644 --> 0.936395).  Saving model ...
EarlyStopping counter: 1 out of 5.0
Validation loss decreased (0.936395 --> 0.932974).  Saving model ...
Validation loss decreased (0.932974 --> 0.930932).  Saving model ...
Validation loss decreased (0.930932 --> 0.930172).  Saving model ...
EarlyStopping counter: 1 out of 5.0
Validation loss decreased (0.930172 --> 0.927675).  Saving model ...
EarlyStopping counter: 1 out of 5.0
Validation loss decreased (0.927675 --> 0.926619).  Saving model ...
Validation loss decreased (0.926619 --> 0.924682).  Saving model ...
Validation loss decreased (0.924682 --> 0.923233).  Saving model ...
Validation loss decreased (0.923233 --> 0.923066).  Saving model ...
EarlyStopping counter: 1 out of 5.0
EarlyStopping counter: 2 out of 5.0
Validation loss decreased (0.923066 --> 0.920743).  Saving model ...
Validation loss decreased (0.920743 --> 0.920267).  Saving model ...
Validation loss decreased (0.920267 --> 0.918965).  Saving model ...
Validation loss decreased (0.918965 --> 0.918051).  Saving model ...
EarlyStopping counter: 1 out of 5.0
Validation loss decreased (0.918051 --> 0.917401).  Saving model ...
Validation loss decreased (0.917401 --> 0.916906).  Saving model ...
Validation loss decreased (0.916906 --> 0.916666).  Saving model ...
EarlyStopping counter: 1 out of 5.0
EarlyStopping counter: 2 out of 5.0
EarlyStopping counter: 3 out of 5.0
EarlyStopping counter: 4 out of 5.0
Validation loss decreased (0.916666 --> 0.916121).  Saving model ...
Validation loss decreased (0.916121 --> 0.914696).  Saving model ...
EarlyStopping counter: 1 out of 5.0
EarlyStopping counter: 2 out of 5.0
EarlyStopping counter: 3 out of 5.0
EarlyStopping counter: 4 out of 5.0
EarlyStopping counter: 5 out of 5.0
/localscratch/yinan.29152578.0/env/lib/python3.7/site-packages/torch/nn/functional.py:1794: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.
  warnings.warn("nn.functional.tanh is deprecated. Use torch.tanh instead.")
wandb: Waiting for W&B process to finish, PID 174080... (success).
wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: \ 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: | 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: / 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: \ 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: | 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: / 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: \ 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: | 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: / 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb:                                                                                
wandb: Run history:
wandb:     e_F1 ▁▂▄▄▄▄▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇▇▇▇████████████████
wandb:   e_loss █▇▆▆▆▆▅▅▅▅▄▄▄▄▃▃▃▃▃▂▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:     t_F1 ▁▁▃▃▄▄▄▄▄▅▅▅▅▅▆▅▆▆▆▆▆▇▇▇▇▇▇▇▇▇▇▇▇███▇███
wandb:   t_loss █▇▇▇▇▆▆▆▆▅▅▅▅▅▄▄▄▄▄▃▃▃▃▃▃▃▃▂▂▂▂▂▂▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:     e_F1 59.97932
wandb:   e_loss 0.91531
wandb:     t_F1 71.55497
wandb:   t_loss 0.75957
wandb: 
wandb: Synced 4 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Synced rosy-totem-2: https://wandb.ai/yinanazhou/xl_512_bs_8_lr_1e06_es_5_lc_False_nr_True_sr_False_stem_False_lemma_False_repeat_5_fold_1/runs/3imc37ro
wandb: Find logs at: ./wandb/run-20220318_035512-3imc37ro/logs/debug.log
wandb: 

wandb: wandb version 0.12.11 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
2022-03-18 05:23:38.793472: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1
wandb: Tracking run with wandb version 0.12.5
wandb: Syncing run apricot-blaze-2
wandb: ⭐️ View project at https://wandb.ai/yinanazhou/xl_512_bs_8_lr_1e06_es_5_lc_False_nr_True_sr_False_stem_False_lemma_False_repeat_5_fold_2
wandb: 🚀 View run at https://wandb.ai/yinanazhou/xl_512_bs_8_lr_1e06_es_5_lc_False_nr_True_sr_False_stem_False_lemma_False_repeat_5_fold_2/runs/mqqv5xta
wandb: Run data is saved locally in /project/6002780/yinan/Thesis_MER_Lyrics/lyric-emotion/wandb/run-20220318_052334-mqqv5xta
wandb: Run `wandb offline` to turn off syncing.

Validation loss decreased (inf --> 1.388183).  Saving model ...
Validation loss decreased (1.388183 --> 1.382147).  Saving model ...
Validation loss decreased (1.382147 --> 1.376975).  Saving model ...
Validation loss decreased (1.376975 --> 1.372026).  Saving model ...
Validation loss decreased (1.372026 --> 1.367451).  Saving model ...
Validation loss decreased (1.367451 --> 1.363079).  Saving model ...
Validation loss decreased (1.363079 --> 1.358885).  Saving model ...
Validation loss decreased (1.358885 --> 1.354698).  Saving model ...
Validation loss decreased (1.354698 --> 1.350070).  Saving model ...
Validation loss decreased (1.350070 --> 1.345691).  Saving model ...
Validation loss decreased (1.345691 --> 1.340778).  Saving model ...
Validation loss decreased (1.340778 --> 1.335853).  Saving model ...
Validation loss decreased (1.335853 --> 1.331397).  Saving model ...
Validation loss decreased (1.331397 --> 1.326279).  Saving model ...
Validation loss decreased (1.326279 --> 1.320706).  Saving model ...
Validation loss decreased (1.320706 --> 1.315717).  Saving model ...
Validation loss decreased (1.315717 --> 1.309713).  Saving model ...
Validation loss decreased (1.309713 --> 1.303113).  Saving model ...
Validation loss decreased (1.303113 --> 1.296608).  Saving model ...
Validation loss decreased (1.296608 --> 1.289291).  Saving model ...
Validation loss decreased (1.289291 --> 1.281970).  Saving model ...
Validation loss decreased (1.281970 --> 1.273872).  Saving model ...
Validation loss decreased (1.273872 --> 1.265900).  Saving model ...
Validation loss decreased (1.265900 --> 1.258277).  Saving model ...
Validation loss decreased (1.258277 --> 1.249650).  Saving model ...
Validation loss decreased (1.249650 --> 1.240883).  Saving model ...
Validation loss decreased (1.240883 --> 1.231866).  Saving model ...
Validation loss decreased (1.231866 --> 1.223173).  Saving model ...
Validation loss decreased (1.223173 --> 1.214608).  Saving model ...
Validation loss decreased (1.214608 --> 1.207416).  Saving model ...
Validation loss decreased (1.207416 --> 1.199550).  Saving model ...
Validation loss decreased (1.199550 --> 1.190209).  Saving model ...
Validation loss decreased (1.190209 --> 1.181173).  Saving model ...
Validation loss decreased (1.181173 --> 1.172871).  Saving model ...
Validation loss decreased (1.172871 --> 1.164788).  Saving model ...
Validation loss decreased (1.164788 --> 1.157455).  Saving model ...
Validation loss decreased (1.157455 --> 1.151998).  Saving model ...
Validation loss decreased (1.151998 --> 1.144100).  Saving model ...
Validation loss decreased (1.144100 --> 1.137326).  Saving model ...
Validation loss decreased (1.137326 --> 1.130082).  Saving model ...
Validation loss decreased (1.130082 --> 1.123546).  Saving model ...
Validation loss decreased (1.123546 --> 1.116412).  Saving model ...
Validation loss decreased (1.116412 --> 1.112300).  Saving model ...
Validation loss decreased (1.112300 --> 1.105285).  Saving model ...
Validation loss decreased (1.105285 --> 1.099715).  Saving model ...
Validation loss decreased (1.099715 --> 1.097057).  Saving model ...
Validation loss decreased (1.097057 --> 1.090570).  Saving model ...
Validation loss decreased (1.090570 --> 1.087395).  Saving model ...
Validation loss decreased (1.087395 --> 1.084312).  Saving model ...
Validation loss decreased (1.084312 --> 1.078684).  Saving model ...
Validation loss decreased (1.078684 --> 1.072922).  Saving model ...
Validation loss decreased (1.072922 --> 1.068185).  Saving model ...
Validation loss decreased (1.068185 --> 1.065203).  Saving model ...
Validation loss decreased (1.065203 --> 1.060392).  Saving model ...
Validation loss decreased (1.060392 --> 1.058079).  Saving model ...
Validation loss decreased (1.058079 --> 1.054458).  Saving model ...
Validation loss decreased (1.054458 --> 1.050570).  Saving model ...
Validation loss decreased (1.050570 --> 1.048367).  Saving model ...
Validation loss decreased (1.048367 --> 1.045507).  Saving model ...
Validation loss decreased (1.045507 --> 1.042491).  Saving model ...
Validation loss decreased (1.042491 --> 1.039053).  Saving model ...
Validation loss decreased (1.039053 --> 1.036867).  Saving model ...
Validation loss decreased (1.036867 --> 1.032981).  Saving model ...
Validation loss decreased (1.032981 --> 1.029851).  Saving model ...
Validation loss decreased (1.029851 --> 1.026151).  Saving model ...
Validation loss decreased (1.026151 --> 1.022840).  Saving model ...
Validation loss decreased (1.022840 --> 1.020048).  Saving model ...
Validation loss decreased (1.020048 --> 1.019603).  Saving model ...
Validation loss decreased (1.019603 --> 1.017013).  Saving model ...
Validation loss decreased (1.017013 --> 1.014986).  Saving model ...
Validation loss decreased (1.014986 --> 1.011820).  Saving model ...
Validation loss decreased (1.011820 --> 1.011137).  Saving model ...
Validation loss decreased (1.011137 --> 1.007016).  Saving model ...
Validation loss decreased (1.007016 --> 1.004348).  Saving model ...
Validation loss decreased (1.004348 --> 1.001299).  Saving model ...
Validation loss decreased (1.001299 --> 0.999935).  Saving model ...
Validation loss decreased (0.999935 --> 0.998834).  Saving model ...
Validation loss decreased (0.998834 --> 0.995984).  Saving model ...
Validation loss decreased (0.995984 --> 0.993820).  Saving model ...
EarlyStopping counter: 1 out of 5.0
Validation loss decreased (0.993820 --> 0.992928).  Saving model ...
Validation loss decreased (0.992928 --> 0.989264).  Saving model ...
Validation loss decreased (0.989264 --> 0.987284).  Saving model ...
Validation loss decreased (0.987284 --> 0.986600).  Saving model ...
Validation loss decreased (0.986600 --> 0.983911).  Saving model ...
Validation loss decreased (0.983911 --> 0.982247).  Saving model ...
EarlyStopping counter: 1 out of 5.0
EarlyStopping counter: 2 out of 5.0
Validation loss decreased (0.982247 --> 0.981099).  Saving model ...
Validation loss decreased (0.981099 --> 0.979420).  Saving model ...
EarlyStopping counter: 1 out of 5.0
Validation loss decreased (0.979420 --> 0.974684).  Saving model ...
Validation loss decreased (0.974684 --> 0.973583).  Saving model ...
EarlyStopping counter: 1 out of 5.0
EarlyStopping counter: 2 out of 5.0
EarlyStopping counter: 3 out of 5.0
Validation loss decreased (0.973583 --> 0.970843).  Saving model ...
Validation loss decreased (0.970843 --> 0.969963).  Saving model ...
Validation loss decreased (0.969963 --> 0.969341).  Saving model ...
Validation loss decreased (0.969341 --> 0.966279).  Saving model ...
EarlyStopping counter: 1 out of 5.0
Validation loss decreased (0.966279 --> 0.965259).  Saving model ...
Validation loss decreased (0.965259 --> 0.961900).  Saving model ...
EarlyStopping counter: 1 out of 5.0
EarlyStopping counter: 2 out of 5.0
Validation loss decreased (0.961900 --> 0.961402).  Saving model ...
Validation loss decreased (0.961402 --> 0.960542).  Saving model ...
EarlyStopping counter: 1 out of 5.0
Validation loss decreased (0.960542 --> 0.958603).  Saving model ...
Validation loss decreased (0.958603 --> 0.958471).  Saving model ...
Validation loss decreased (0.958471 --> 0.956820).  Saving model ...
EarlyStopping counter: 1 out of 5.0
EarlyStopping counter: 2 out of 5.0
Validation loss decreased (0.956820 --> 0.955061).  Saving model ...
Validation loss decreased (0.955061 --> 0.954947).  Saving model ...
EarlyStopping counter: 1 out of 5.0
Validation loss decreased (0.954947 --> 0.954820).  Saving model ...
EarlyStopping counter: 1 out of 5.0
EarlyStopping counter: 2 out of 5.0
EarlyStopping counter: 3 out of 5.0
EarlyStopping counter: 4 out of 5.0
EarlyStopping counter: 5 out of 5.0
/localscratch/yinan.29152578.0/env/lib/python3.7/site-packages/torch/nn/functional.py:1794: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.
  warnings.warn("nn.functional.tanh is deprecated. Use torch.tanh instead.")
wandb: Waiting for W&B process to finish, PID 178832... (success).
wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: \ 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: | 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: / 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: \ 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: | 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: / 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb:                                                                                
wandb: Run history:
wandb:     e_F1 ▁▂▃▃▄▄▅▅▅▆▆▆▇▇▇██▇▇▇████████████████████
wandb:   e_loss ███▇▇▇▇▆▆▅▅▄▄▄▃▃▃▃▃▂▂▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁
wandb:     t_F1 ▁▂▂▂▃▃▃▃▄▅▄▅▅▆▅▆▅▆▆▆▇▇▇▇▇▇▇▇▇▇█▇▇█▇█████
wandb:   t_loss ████▇▇▇▇▆▆▆▅▅▅▅▅▄▄▄▄▃▃▃▃▃▂▂▃▂▂▂▂▂▁▂▂▁▁▁▁
wandb: 
wandb: Run summary:
wandb:     e_F1 60.12962
wandb:   e_loss 0.95527
wandb:     t_F1 69.871
wandb:   t_loss 0.77871
wandb: 
wandb: Synced 4 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Synced apricot-blaze-2: https://wandb.ai/yinanazhou/xl_512_bs_8_lr_1e06_es_5_lc_False_nr_True_sr_False_stem_False_lemma_False_repeat_5_fold_2/runs/mqqv5xta
wandb: Find logs at: ./wandb/run-20220318_052334-mqqv5xta/logs/debug.log
wandb: 

