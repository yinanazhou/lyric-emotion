Unloading StdEnv/2020

Due to MODULEPATH changes, the following have been reloaded:
  1) mii/1.1.1


The following have been reloaded with a version change:
  1) python/3.8.2 => python/3.7.4

Using base prefix '/cvmfs/soft.computecanada.ca/easybuild/software/2017/Core/python/3.7.4'
New python executable in /localscratch/yinan.28869511.0/env/bin/python
Installing setuptools, pip, wheel...
done.
Ignoring pip: markers 'python_version < "3"' don't match your environment
Looking in links: /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/nix/avx2, /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/nix/generic, /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic
Collecting pip
Installing collected packages: pip
  Found existing installation: pip 19.1.1
    Uninstalling pip-19.1.1:
      Successfully uninstalled pip-19.1.1
Successfully installed pip-21.2.3+computecanada
Looking in links: /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/nix/avx2, /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/nix/generic, /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/keras-2.8.0+computecanada-py2.py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/Keras_Preprocessing-1.1.2+computecanada-py3-none-any.whl
Requirement already satisfied: matplotlib in /cvmfs/soft.computecanada.ca/easybuild/software/2017/Core/scipy-stack/2019a/lib/python3.7/site-packages (from -r requirements.txt (line 3)) (3.0.2)
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/nltk-3.6.5+computecanada-py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/scikit_learn-0.22.1+computecanada-cp37-cp37m-linux_x86_64.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/tensorboard-2.3.0+computecanada-py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/tensorboard_plugin_wit-1.7.0+computecanada-py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/tensorflow_gpu-2.3.0+computecanada-cp37-cp37m-linux_x86_64.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/tensorflow_estimator-2.3.0+computecanada-py2.py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/tokenizers-0.5.2+computecanada-cp37-cp37m-linux_x86_64.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/nix/avx2/torch-1.4.0+computecanada-cp37-cp37m-linux_x86_64.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/torchtext-0.6.0+computecanada-py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/torchvision-0.8.2+computecanada-cp37-cp37m-linux_x86_64.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/transformers-2.5.1+computecanada-py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/urllib3-1.26.7+computecanada-py2.py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/joblib-1.1.0+computecanada-py2.py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/click-8.0.3+computecanada-py3-none-any.whl
ERROR: Could not find a version that satisfies the requirement regex>=2021.8.3 (from nltk) (from versions: 2018.1.10+computecanada, 2019.11.1+computecanada, 2020.11.13+computecanada)
ERROR: No matching distribution found for regex>=2021.8.3
Looking in links: /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/nix/avx2, /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/nix/generic, /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic
ERROR: Could not find a version that satisfies the requirement numpy==1.20.0+computacanada (from versions: 1.15.0+computecanada, 1.15.2+computecanada, 1.15.4+computecanada, 1.16.0+computecanada, 1.16.2+computecanada, 1.16.3+computecanada, 1.17.4+computecanada, 1.18.1+computecanada, 1.18.4+computecanada, 1.19.1+computecanada, 1.19.2+computecanada, 1.20.2+computecanada)
ERROR: No matching distribution found for numpy==1.20.0+computacanada
Looking in links: /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/nix/avx2, /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/nix/generic, /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/wandb-0.12.5+computecanada-py2.py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/psutil-5.7.3+computecanada-cp37-cp37m-linux_x86_64.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/subprocess32-3.5.4+computecanada-py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/configparser-5.0.2+computecanada-py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/six-1.16.0+computecanada-py2.py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/protobuf-3.19.4+computecanada-py2.py3-none-any.whl
Requirement already satisfied: python-dateutil>=2.6.1 in /cvmfs/soft.computecanada.ca/easybuild/software/2017/Core/scipy-stack/2019a/lib/python3.7/site-packages (from wandb) (2.7.5)
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/shortuuid-1.0.1+computecanada-py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/pathtools-0.1.2+computecanada-py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/promise-2.3+computecanada-py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/click-8.0.3+computecanada-py3-none-any.whl
Requirement already satisfied: requests<3,>=2.0.0 in /cvmfs/soft.computecanada.ca/easybuild/software/2017/Core/scipy-stack/2019a/lib/python3.7/site-packages (from wandb) (2.21.0)
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/GitPython-3.1.24+computecanada-py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/yaspin-2.1.0+computecanada-py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/docker_pycreds-0.4.0+computecanada-py2.py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/PyYAML-5.3.1+computecanada-cp37-cp37m-linux_x86_64.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/sentry_sdk-1.5.0+computecanada-py2.py3-none-any.whl
Requirement already satisfied: importlib-metadata in /cvmfs/soft.computecanada.ca/easybuild/software/2017/Core/scipy-stack/2019a/lib/python3.7/site-packages (from Click!=8.0.0,>=7.0->wandb) (0.8)
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/typing_extensions-4.0.1+computecanada-py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/gitdb-4.0.9+computecanada-py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/smmap-5.0.0+computecanada-py3-none-any.whl
Requirement already satisfied: certifi>=2017.4.17 in /cvmfs/soft.computecanada.ca/easybuild/software/2017/Core/scipy-stack/2019a/lib/python3.7/site-packages (from requests<3,>=2.0.0->wandb) (2018.11.29)
Requirement already satisfied: idna<2.9,>=2.5 in /cvmfs/soft.computecanada.ca/easybuild/software/2017/Core/scipy-stack/2019a/lib/python3.7/site-packages (from requests<3,>=2.0.0->wandb) (2.8)
Requirement already satisfied: urllib3<1.25,>=1.21.1 in /cvmfs/soft.computecanada.ca/easybuild/software/2017/Core/scipy-stack/2019a/lib/python3.7/site-packages (from requests<3,>=2.0.0->wandb) (1.24.1)
Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /cvmfs/soft.computecanada.ca/easybuild/software/2017/Core/scipy-stack/2019a/lib/python3.7/site-packages (from requests<3,>=2.0.0->wandb) (3.0.4)
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/termcolor-1.1.0+computecanada-py3-none-any.whl
Requirement already satisfied: zipp>=0.3.2 in /cvmfs/soft.computecanada.ca/easybuild/software/2017/Core/scipy-stack/2019a/lib/python3.7/site-packages (from importlib-metadata->Click!=8.0.0,>=7.0->wandb) (0.3.3)
Installing collected packages: smmap, typing-extensions, termcolor, six, gitdb, yaspin, subprocess32, shortuuid, sentry-sdk, PyYAML, psutil, protobuf, promise, pathtools, GitPython, docker-pycreds, configparser, Click, wandb
  Attempting uninstall: six
    Found existing installation: six 1.12.0
    Not uninstalling six at /cvmfs/soft.computecanada.ca/easybuild/software/2017/Core/scipy-stack/2019a/lib/python3.7/site-packages, outside environment /localscratch/yinan.28869511.0/env
    Can't uninstall 'six'. No files were found to uninstall.
Successfully installed Click-8.0.3+computecanada GitPython-3.1.24+computecanada PyYAML-5.3.1+computecanada configparser-5.0.2+computecanada docker-pycreds-0.4.0+computecanada gitdb-4.0.9+computecanada pathtools-0.1.2+computecanada promise-2.3+computecanada protobuf-3.19.4+computecanada psutil-5.7.3+computecanada sentry-sdk-1.5.0+computecanada shortuuid-1.0.1+computecanada six-1.16.0+computecanada smmap-5.0.0+computecanada subprocess32-3.5.4+computecanada termcolor-1.1.0+computecanada typing-extensions-4.0.1+computecanada wandb-0.12.5+computecanada yaspin-2.1.0+computecanada
Looking in links: /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/nix/avx2, /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/nix/generic, /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic
ERROR: Could not find a version that satisfies the requirement sagemaker (from versions: none)
ERROR: No matching distribution found for sagemaker
Looking in links: /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/nix/avx2, /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/nix/generic, /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/torch-1.9.1+computecanada-cp37-cp37m-linux_x86_64.whl
Requirement already satisfied: typing-extensions in /localscratch/yinan.28869511.0/env/lib/python3.7/site-packages (from torch) (4.0.1+computecanada)
Installing collected packages: torch
Successfully installed torch-1.9.1+computecanada
Looking in links: /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/nix/avx2, /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/nix/generic, /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/transformers-2.5.1+computecanada-py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/tqdm-4.63.0+computecanada-py2.py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/filelock-3.4.2+computecanada-py3-none-any.whl
Requirement already satisfied: numpy in /cvmfs/soft.computecanada.ca/easybuild/software/2017/Core/scipy-stack/2019a/lib/python3.7/site-packages (from transformers==2.5.1+computecanada) (1.16.0)
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/regex-2020.11.13+computecanada-cp37-cp37m-linux_x86_64.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/boto3-1.20.52+computecanada-py3-none-any.whl
Requirement already satisfied: requests in /cvmfs/soft.computecanada.ca/easybuild/software/2017/Core/scipy-stack/2019a/lib/python3.7/site-packages (from transformers==2.5.1+computecanada) (2.21.0)
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/sentencepiece-0.1.91+computecanada-cp37-cp37m-linux_x86_64.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/tokenizers-0.5.2+computecanada-cp37-cp37m-linux_x86_64.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/sacremoses-0.0.46+computecanada-py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/jmespath-0.10.0+computecanada-py2.py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/botocore-1.23.52+computecanada-py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/s3transfer-0.5.1+computecanada-py3-none-any.whl
Requirement already satisfied: python-dateutil<3.0.0,>=2.1 in /cvmfs/soft.computecanada.ca/easybuild/software/2017/Core/scipy-stack/2019a/lib/python3.7/site-packages (from botocore<1.24.0,>=1.23.52->boto3->transformers==2.5.1+computecanada) (2.7.5)
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/urllib3-1.26.8+computecanada-py2.py3-none-any.whl
Requirement already satisfied: six>=1.5 in /localscratch/yinan.28869511.0/env/lib/python3.7/site-packages (from python-dateutil<3.0.0,>=2.1->botocore<1.24.0,>=1.23.52->boto3->transformers==2.5.1+computecanada) (1.16.0+computecanada)
Requirement already satisfied: certifi>=2017.4.17 in /cvmfs/soft.computecanada.ca/easybuild/software/2017/Core/scipy-stack/2019a/lib/python3.7/site-packages (from requests->transformers==2.5.1+computecanada) (2018.11.29)
Requirement already satisfied: idna<2.9,>=2.5 in /cvmfs/soft.computecanada.ca/easybuild/software/2017/Core/scipy-stack/2019a/lib/python3.7/site-packages (from requests->transformers==2.5.1+computecanada) (2.8)
Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /cvmfs/soft.computecanada.ca/easybuild/software/2017/Core/scipy-stack/2019a/lib/python3.7/site-packages (from requests->transformers==2.5.1+computecanada) (3.0.4)
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/requests-2.27.1+computecanada-py2.py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/charset_normalizer-2.0.11+computecanada-py3-none-any.whl
Requirement already satisfied: click in /localscratch/yinan.28869511.0/env/lib/python3.7/site-packages (from sacremoses->transformers==2.5.1+computecanada) (8.0.3+computecanada)
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/joblib-1.1.0+computecanada-py2.py3-none-any.whl
Requirement already satisfied: importlib-metadata in /cvmfs/soft.computecanada.ca/easybuild/software/2017/Core/scipy-stack/2019a/lib/python3.7/site-packages (from click->sacremoses->transformers==2.5.1+computecanada) (0.8)
Requirement already satisfied: zipp>=0.3.2 in /cvmfs/soft.computecanada.ca/easybuild/software/2017/Core/scipy-stack/2019a/lib/python3.7/site-packages (from importlib-metadata->click->sacremoses->transformers==2.5.1+computecanada) (0.3.3)
Installing collected packages: urllib3, jmespath, botocore, tqdm, s3transfer, regex, joblib, charset-normalizer, tokenizers, sentencepiece, sacremoses, requests, filelock, boto3, transformers
  Attempting uninstall: urllib3
    Found existing installation: urllib3 1.24.1
    Not uninstalling urllib3 at /cvmfs/soft.computecanada.ca/easybuild/software/2017/Core/scipy-stack/2019a/lib/python3.7/site-packages, outside environment /localscratch/yinan.28869511.0/env
    Can't uninstall 'urllib3'. No files were found to uninstall.
  Attempting uninstall: requests
    Found existing installation: requests 2.21.0
    Not uninstalling requests at /cvmfs/soft.computecanada.ca/easybuild/software/2017/Core/scipy-stack/2019a/lib/python3.7/site-packages, outside environment /localscratch/yinan.28869511.0/env
    Can't uninstall 'requests'. No files were found to uninstall.
Successfully installed boto3-1.20.52+computecanada botocore-1.23.52+computecanada charset-normalizer-2.0.11+computecanada filelock-3.4.2+computecanada jmespath-0.10.0+computecanada joblib-1.1.0+computecanada regex-2020.11.13+computecanada requests-2.27.1+computecanada s3transfer-0.5.1+computecanada sacremoses-0.0.46+computecanada sentencepiece-0.1.91+computecanada tokenizers-0.5.2+computecanada tqdm-4.63.0+computecanada transformers-2.5.1+computecanada urllib3-1.26.8+computecanada
Looking in links: /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/nix/avx2, /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/nix/generic, /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/tensorflow_gpu-2.3.0+computecanada-cp37-cp37m-linux_x86_64.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/nix/avx2/h5py-2.10.0+computecanada-cp37-cp37m-linux_x86_64.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/gast-0.3.3+computecanada-py3-none-any.whl
Requirement already satisfied: protobuf>=3.9.2 in /localscratch/yinan.28869511.0/env/lib/python3.7/site-packages (from tensorflow_gpu==2.3.0+computecanada) (3.19.4+computecanada)
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/astunparse-1.6.3+computecanada-py2.py3-none-any.whl
Requirement already satisfied: termcolor>=1.1.0 in /localscratch/yinan.28869511.0/env/lib/python3.7/site-packages (from tensorflow_gpu==2.3.0+computecanada) (1.1.0+computecanada)
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/opt_einsum-3.3.0+computecanada-py3-none-any.whl
Requirement already satisfied: wheel>=0.26 in /localscratch/yinan.28869511.0/env/lib/python3.7/site-packages (from tensorflow_gpu==2.3.0+computecanada) (0.33.4)
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/Keras_Preprocessing-1.1.2+computecanada-py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/absl_py-1.0.0+computecanada-py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/wrapt-1.11.2+computecanada-cp37-cp37m-linux_x86_64.whl
Requirement already satisfied: six>=1.12.0 in /localscratch/yinan.28869511.0/env/lib/python3.7/site-packages (from tensorflow_gpu==2.3.0+computecanada) (1.16.0+computecanada)
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/nix/generic/scipy-1.4.1+computecanada-cp37-cp37m-linux_x86_64.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/google_pasta-0.2.0+computecanada-py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/grpcio-1.38.0+computecanada-cp37-cp37m-linux_x86_64.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/tensorboard-2.8.0+computecanada-py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/tensorflow_estimator-2.3.0+computecanada-py2.py3-none-any.whl
Requirement already satisfied: numpy<1.19.0,>=1.16.0 in /cvmfs/soft.computecanada.ca/easybuild/software/2017/Core/scipy-stack/2019a/lib/python3.7/site-packages (from tensorflow_gpu==2.3.0+computecanada) (1.16.0)
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/Markdown-3.3.6+computecanada-py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/Werkzeug-2.0.3+computecanada-py3-none-any.whl
Requirement already satisfied: requests<3,>=2.21.0 in /localscratch/yinan.28869511.0/env/lib/python3.7/site-packages (from tensorboard<3,>=2.3.0->tensorflow_gpu==2.3.0+computecanada) (2.27.1+computecanada)
Requirement already satisfied: setuptools>=41.0.0 in /localscratch/yinan.28869511.0/env/lib/python3.7/site-packages (from tensorboard<3,>=2.3.0->tensorflow_gpu==2.3.0+computecanada) (41.0.1)
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/google_auth_oauthlib-0.4.6+computecanada-py2.py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/google_auth-2.3.3+computecanada-py2.py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/tensorboard_data_server-0.6.1+computecanada-py3-none-linux_x86_64.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/tensorboard_plugin_wit-1.8.0+computecanada-py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/cachetools-4.2.4+computecanada-py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/pyasn1_modules-0.2.8+computecanada-py2.py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/rsa-4.8+computecanada-py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/requests_oauthlib-1.3.0+computecanada-py2.py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/importlib_metadata-4.10.1+computecanada-py3-none-any.whl
Requirement already satisfied: typing-extensions>=3.6.4 in /localscratch/yinan.28869511.0/env/lib/python3.7/site-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard<3,>=2.3.0->tensorflow_gpu==2.3.0+computecanada) (4.0.1+computecanada)
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/zipp-3.7.0+computecanada-py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/pyasn1-0.4.8+computecanada-py2.py3-none-any.whl
Requirement already satisfied: charset-normalizer~=2.0.0 in /localscratch/yinan.28869511.0/env/lib/python3.7/site-packages (from requests<3,>=2.21.0->tensorboard<3,>=2.3.0->tensorflow_gpu==2.3.0+computecanada) (2.0.11+computecanada)
Requirement already satisfied: urllib3<1.27,>=1.21.1 in /localscratch/yinan.28869511.0/env/lib/python3.7/site-packages (from requests<3,>=2.21.0->tensorboard<3,>=2.3.0->tensorflow_gpu==2.3.0+computecanada) (1.26.8+computecanada)
Requirement already satisfied: certifi>=2017.4.17 in /cvmfs/soft.computecanada.ca/easybuild/software/2017/Core/scipy-stack/2019a/lib/python3.7/site-packages (from requests<3,>=2.21.0->tensorboard<3,>=2.3.0->tensorflow_gpu==2.3.0+computecanada) (2018.11.29)
Requirement already satisfied: idna<4,>=2.5 in /cvmfs/soft.computecanada.ca/easybuild/software/2017/Core/scipy-stack/2019a/lib/python3.7/site-packages (from requests<3,>=2.21.0->tensorboard<3,>=2.3.0->tensorflow_gpu==2.3.0+computecanada) (2.8)
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/oauthlib-3.1.1+computecanada-py2.py3-none-any.whl
Installing collected packages: pyasn1, zipp, rsa, pyasn1-modules, oauthlib, cachetools, requests-oauthlib, importlib-metadata, google-auth, werkzeug, tensorboard-plugin-wit, tensorboard-data-server, markdown, grpcio, google-auth-oauthlib, absl-py, wrapt, tensorflow-estimator, tensorboard, scipy, opt-einsum, keras-preprocessing, h5py, google-pasta, gast, astunparse, tensorflow-gpu
  Attempting uninstall: pyasn1
    Found existing installation: pyasn1 0.4.3
    Not uninstalling pyasn1 at /cvmfs/soft.computecanada.ca/easybuild/software/2017/Core/scipy-stack/2019a/lib/python3.7/site-packages, outside environment /localscratch/yinan.28869511.0/env
    Can't uninstall 'pyasn1'. No files were found to uninstall.
  Attempting uninstall: zipp
    Found existing installation: zipp 0.3.3
    Not uninstalling zipp at /cvmfs/soft.computecanada.ca/easybuild/software/2017/Core/scipy-stack/2019a/lib/python3.7/site-packages, outside environment /localscratch/yinan.28869511.0/env
    Can't uninstall 'zipp'. No files were found to uninstall.
  Attempting uninstall: importlib-metadata
    Found existing installation: importlib-metadata 0.8
    Not uninstalling importlib-metadata at /cvmfs/soft.computecanada.ca/easybuild/software/2017/Core/scipy-stack/2019a/lib/python3.7/site-packages, outside environment /localscratch/yinan.28869511.0/env
    Can't uninstall 'importlib-metadata'. No files were found to uninstall.
  Attempting uninstall: scipy
    Found existing installation: scipy 1.2.0
    Not uninstalling scipy at /cvmfs/soft.computecanada.ca/easybuild/software/2017/Core/scipy-stack/2019a/lib/python3.7/site-packages, outside environment /localscratch/yinan.28869511.0/env
    Can't uninstall 'scipy'. No files were found to uninstall.
Successfully installed absl-py-1.0.0+computecanada astunparse-1.6.3+computecanada cachetools-4.2.4+computecanada gast-0.3.3+computecanada google-auth-2.3.3+computecanada google-auth-oauthlib-0.4.6+computecanada google-pasta-0.2.0+computecanada grpcio-1.38.0+computecanada h5py-2.10.0+computecanada importlib-metadata-4.10.1+computecanada keras-preprocessing-1.1.2+computecanada markdown-3.3.6+computecanada oauthlib-3.1.1+computecanada opt-einsum-3.3.0+computecanada pyasn1-0.4.8+computecanada pyasn1-modules-0.2.8+computecanada requests-oauthlib-1.3.0+computecanada rsa-4.8+computecanada scipy-1.4.1+computecanada tensorboard-2.8.0+computecanada tensorboard-data-server-0.6.1+computecanada tensorboard-plugin-wit-1.8.0+computecanada tensorflow-estimator-2.3.0+computecanada tensorflow-gpu-2.3.0+computecanada werkzeug-2.0.3+computecanada wrapt-1.11.2+computecanada zipp-3.7.0+computecanada
Looking in links: /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/nix/avx2, /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/nix/generic, /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/keras-2.8.0+computecanada-py2.py3-none-any.whl
Installing collected packages: Keras
Successfully installed Keras-2.8.0+computecanada
Looking in links: /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/nix/avx2, /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/nix/generic, /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/urllib3-1.26.7+computecanada-py2.py3-none-any.whl
Installing collected packages: urllib3
  Attempting uninstall: urllib3
    Found existing installation: urllib3 1.26.8+computecanada
    Uninstalling urllib3-1.26.8+computecanada:
      Successfully uninstalled urllib3-1.26.8+computecanada
Successfully installed urllib3-1.26.7+computecanada
Looking in links: /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/nix/avx2, /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/nix/generic, /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/nltk-3.7+computecanada-py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/nltk-3.6.5+computecanada-py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/nltk-3.6.3+computecanada-py3-none-any.whl
Requirement already satisfied: regex in /localscratch/yinan.28869511.0/env/lib/python3.7/site-packages (from nltk) (2020.11.13+computecanada)
Requirement already satisfied: joblib in /localscratch/yinan.28869511.0/env/lib/python3.7/site-packages (from nltk) (1.1.0+computecanada)
Requirement already satisfied: click in /localscratch/yinan.28869511.0/env/lib/python3.7/site-packages (from nltk) (8.0.3+computecanada)
Requirement already satisfied: tqdm in /localscratch/yinan.28869511.0/env/lib/python3.7/site-packages (from nltk) (4.63.0+computecanada)
Requirement already satisfied: importlib-metadata in /localscratch/yinan.28869511.0/env/lib/python3.7/site-packages (from click->nltk) (4.10.1+computecanada)
Requirement already satisfied: zipp>=0.5 in /localscratch/yinan.28869511.0/env/lib/python3.7/site-packages (from importlib-metadata->click->nltk) (3.7.0+computecanada)
Requirement already satisfied: typing-extensions>=3.6.4 in /localscratch/yinan.28869511.0/env/lib/python3.7/site-packages (from importlib-metadata->click->nltk) (4.0.1+computecanada)
Installing collected packages: nltk
Successfully installed nltk-3.6.3+computecanada
Looking in links: /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/nix/avx2, /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/nix/generic, /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/scikit_learn-0.22.1+computecanada-cp37-cp37m-linux_x86_64.whl
Requirement already satisfied: scipy>=0.17.0 in /localscratch/yinan.28869511.0/env/lib/python3.7/site-packages (from scikit-learn==0.22.1) (1.4.1+computecanada)
Requirement already satisfied: numpy>=1.11.0 in /cvmfs/soft.computecanada.ca/easybuild/software/2017/Core/scipy-stack/2019a/lib/python3.7/site-packages (from scikit-learn==0.22.1) (1.16.0)
Requirement already satisfied: joblib>=0.11 in /localscratch/yinan.28869511.0/env/lib/python3.7/site-packages (from scikit-learn==0.22.1) (1.1.0+computecanada)
Installing collected packages: scikit-learn
Successfully installed scikit-learn-0.22.1+computecanada
Looking in links: /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/nix/avx2, /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/nix/generic, /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic
Requirement already satisfied: tokenizers==0.5.2 in /localscratch/yinan.28869511.0/env/lib/python3.7/site-packages (0.5.2+computecanada)
wandb: Appending key for api.wandb.ai to your netrc file: /home/yinan/.netrc
Starting Task
2022-03-13 19:45:58.941865: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1
[nltk_data] Downloading package stopwords to /home/yinan/nltk_data...
[nltk_data]   Package stopwords is already up-to-date!
[nltk_data] Downloading package wordnet to /home/yinan/nltk_data...
[nltk_data]   Package wordnet is already up-to-date!
wandb: Currently logged in as: yinanazhou (use `wandb login --relogin` to force relogin)
wandb: wandb version 0.12.11 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
2022-03-13 19:46:09.702487: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1
wandb: Tracking run with wandb version 0.12.5
wandb: Syncing run mango-mousse-2
wandb: ⭐️ View project at https://wandb.ai/yinanazhou/xl_512_bs_8_lr_1e06_es_5_lc_True_nr_False_sr_False_stem_False_lemma_False_repeat_1_fold_1
wandb: 🚀 View run at https://wandb.ai/yinanazhou/xl_512_bs_8_lr_1e06_es_5_lc_True_nr_False_sr_False_stem_False_lemma_False_repeat_1_fold_1/runs/okshgyev
wandb: Run data is saved locally in /project/6002780/yinan/Thesis_MER_Lyrics/lyric-emotion/wandb/run-20220313_194607-okshgyev
wandb: Run `wandb offline` to turn off syncing.

Validation loss decreased (inf --> 1.433313).  Saving model ...
Validation loss decreased (1.433313 --> 1.413823).  Saving model ...
Validation loss decreased (1.413823 --> 1.397634).  Saving model ...
Validation loss decreased (1.397634 --> 1.384729).  Saving model ...
Validation loss decreased (1.384729 --> 1.374505).  Saving model ...
Validation loss decreased (1.374505 --> 1.365789).  Saving model ...
Validation loss decreased (1.365789 --> 1.358431).  Saving model ...
Validation loss decreased (1.358431 --> 1.352422).  Saving model ...
Validation loss decreased (1.352422 --> 1.347176).  Saving model ...
Validation loss decreased (1.347176 --> 1.341239).  Saving model ...
Validation loss decreased (1.341239 --> 1.335240).  Saving model ...
Validation loss decreased (1.335240 --> 1.329805).  Saving model ...
Validation loss decreased (1.329805 --> 1.324280).  Saving model ...
Validation loss decreased (1.324280 --> 1.319049).  Saving model ...
Validation loss decreased (1.319049 --> 1.314033).  Saving model ...
Validation loss decreased (1.314033 --> 1.308356).  Saving model ...
Validation loss decreased (1.308356 --> 1.302842).  Saving model ...
Validation loss decreased (1.302842 --> 1.296422).  Saving model ...
Validation loss decreased (1.296422 --> 1.289807).  Saving model ...
Validation loss decreased (1.289807 --> 1.282416).  Saving model ...
Validation loss decreased (1.282416 --> 1.275527).  Saving model ...
Validation loss decreased (1.275527 --> 1.268434).  Saving model ...
Validation loss decreased (1.268434 --> 1.262217).  Saving model ...
Validation loss decreased (1.262217 --> 1.255003).  Saving model ...
Validation loss decreased (1.255003 --> 1.246530).  Saving model ...
Validation loss decreased (1.246530 --> 1.239448).  Saving model ...
Validation loss decreased (1.239448 --> 1.233109).  Saving model ...
Validation loss decreased (1.233109 --> 1.226549).  Saving model ...
Validation loss decreased (1.226549 --> 1.220859).  Saving model ...
Validation loss decreased (1.220859 --> 1.215898).  Saving model ...
Validation loss decreased (1.215898 --> 1.207550).  Saving model ...
Validation loss decreased (1.207550 --> 1.203158).  Saving model ...
Validation loss decreased (1.203158 --> 1.199874).  Saving model ...
Validation loss decreased (1.199874 --> 1.194043).  Saving model ...
Validation loss decreased (1.194043 --> 1.186784).  Saving model ...
Validation loss decreased (1.186784 --> 1.182782).  Saving model ...
Validation loss decreased (1.182782 --> 1.174996).  Saving model ...
Validation loss decreased (1.174996 --> 1.170641).  Saving model ...
Validation loss decreased (1.170641 --> 1.168795).  Saving model ...
Validation loss decreased (1.168795 --> 1.166190).  Saving model ...
Validation loss decreased (1.166190 --> 1.161606).  Saving model ...
Validation loss decreased (1.161606 --> 1.154363).  Saving model ...
Validation loss decreased (1.154363 --> 1.150958).  Saving model ...
Validation loss decreased (1.150958 --> 1.147520).  Saving model ...
Validation loss decreased (1.147520 --> 1.144593).  Saving model ...
Validation loss decreased (1.144593 --> 1.139181).  Saving model ...
Validation loss decreased (1.139181 --> 1.135060).  Saving model ...
Validation loss decreased (1.135060 --> 1.131736).  Saving model ...
Validation loss decreased (1.131736 --> 1.125831).  Saving model ...
Validation loss decreased (1.125831 --> 1.122838).  Saving model ...
Validation loss decreased (1.122838 --> 1.116849).  Saving model ...
Validation loss decreased (1.116849 --> 1.114160).  Saving model ...
Validation loss decreased (1.114160 --> 1.112123).  Saving model ...
Validation loss decreased (1.112123 --> 1.107845).  Saving model ...
EarlyStopping counter: 1 out of 5.0
Validation loss decreased (1.107845 --> 1.104358).  Saving model ...
Validation loss decreased (1.104358 --> 1.099308).  Saving model ...
Validation loss decreased (1.099308 --> 1.093686).  Saving model ...
Validation loss decreased (1.093686 --> 1.088410).  Saving model ...
EarlyStopping counter: 1 out of 5.0
EarlyStopping counter: 2 out of 5.0
Validation loss decreased (1.088410 --> 1.084482).  Saving model ...
Validation loss decreased (1.084482 --> 1.080187).  Saving model ...
Validation loss decreased (1.080187 --> 1.076264).  Saving model ...
Validation loss decreased (1.076264 --> 1.075939).  Saving model ...
Validation loss decreased (1.075939 --> 1.072168).  Saving model ...
Validation loss decreased (1.072168 --> 1.070593).  Saving model ...
Validation loss decreased (1.070593 --> 1.066321).  Saving model ...
Validation loss decreased (1.066321 --> 1.061729).  Saving model ...
Validation loss decreased (1.061729 --> 1.058850).  Saving model ...
Validation loss decreased (1.058850 --> 1.056024).  Saving model ...
Validation loss decreased (1.056024 --> 1.053853).  Saving model ...
Validation loss decreased (1.053853 --> 1.053145).  Saving model ...
Validation loss decreased (1.053145 --> 1.049757).  Saving model ...
Validation loss decreased (1.049757 --> 1.047381).  Saving model ...
Validation loss decreased (1.047381 --> 1.045632).  Saving model ...
Validation loss decreased (1.045632 --> 1.043149).  Saving model ...
Validation loss decreased (1.043149 --> 1.040299).  Saving model ...
Validation loss decreased (1.040299 --> 1.038331).  Saving model ...
Validation loss decreased (1.038331 --> 1.035407).  Saving model ...
EarlyStopping counter: 1 out of 5.0
EarlyStopping counter: 2 out of 5.0
EarlyStopping counter: 3 out of 5.0
Validation loss decreased (1.035407 --> 1.032995).  Saving model ...
Validation loss decreased (1.032995 --> 1.028982).  Saving model ...
Validation loss decreased (1.028982 --> 1.025926).  Saving model ...
Validation loss decreased (1.025926 --> 1.022435).  Saving model ...
EarlyStopping counter: 1 out of 5.0
Validation loss decreased (1.022435 --> 1.022078).  Saving model ...
Validation loss decreased (1.022078 --> 1.020968).  Saving model ...
Validation loss decreased (1.020968 --> 1.016995).  Saving model ...
Validation loss decreased (1.016995 --> 1.012141).  Saving model ...
EarlyStopping counter: 1 out of 5.0
EarlyStopping counter: 2 out of 5.0
EarlyStopping counter: 3 out of 5.0
Validation loss decreased (1.012141 --> 1.011276).  Saving model ...
Validation loss decreased (1.011276 --> 1.010986).  Saving model ...
Validation loss decreased (1.010986 --> 1.007363).  Saving model ...
EarlyStopping counter: 1 out of 5.0
Validation loss decreased (1.007363 --> 1.006843).  Saving model ...
Validation loss decreased (1.006843 --> 1.004297).  Saving model ...
EarlyStopping counter: 1 out of 5.0
EarlyStopping counter: 2 out of 5.0
EarlyStopping counter: 3 out of 5.0
Validation loss decreased (1.004297 --> 1.002877).  Saving model ...
Validation loss decreased (1.002877 --> 0.999693).  Saving model ...
EarlyStopping counter: 1 out of 5.0
EarlyStopping counter: 2 out of 5.0
Validation loss decreased (0.999693 --> 0.996690).  Saving model ...
Validation loss decreased (0.996690 --> 0.993643).  Saving model ...
Validation loss decreased (0.993643 --> 0.993407).  Saving model ...
EarlyStopping counter: 1 out of 5.0
EarlyStopping counter: 2 out of 5.0
EarlyStopping counter: 3 out of 5.0
EarlyStopping counter: 4 out of 5.0
EarlyStopping counter: 5 out of 5.0
/localscratch/yinan.28869511.0/env/lib/python3.7/site-packages/torch/nn/functional.py:1794: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.
  warnings.warn("nn.functional.tanh is deprecated. Use torch.tanh instead.")
/localscratch/yinan.28869511.0/env/lib/python3.7/site-packages/transformers/optimization.py:155: UserWarning: This overload of add_ is deprecated:
	add_(Number alpha, Tensor other)
Consider using one of the following signatures instead:
	add_(Tensor other, *, Number alpha) (Triggered internally at  ../torch/csrc/utils/python_arg_parser.cpp:1025.)
  exp_avg.mul_(beta1).add_(1.0 - beta1, grad)
wandb: Waiting for W&B process to finish, PID 3193... (success).
wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: \ 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: | 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: / 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: \ 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: | 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: / 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: \ 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: | 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb:                                                                                
wandb: Run history:
wandb:     e_F1 ▁▁▃▄▅▅▆▆▆▆▆▆▆▆▇▇▇▇▇▇▇▇▇▇▇▇▇█████████████
wandb:   e_loss █▇▇▇▆▆▆▅▅▅▅▄▄▄▄▃▃▃▃▃▃▂▂▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁
wandb:     t_F1 ▁▁▂▂▃▃▄▄▄▄▅▅▅▅▅▆▆▅▆▆▆▆▆▇▇▇▇▇▇▇▇█▇▇██▇██▇
wandb:   t_loss ██▇▇▇▇▇▆▆▆▅▅▅▅▄▄▄▄▄▄▃▃▃▃▃▂▃▂▂▂▂▂▂▂▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:     e_F1 58.54424
wandb:   e_loss 0.99451
wandb:     t_F1 67.40949
wandb:   t_loss 0.80032
wandb: 
wandb: Synced 4 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Synced mango-mousse-2: https://wandb.ai/yinanazhou/xl_512_bs_8_lr_1e06_es_5_lc_True_nr_False_sr_False_stem_False_lemma_False_repeat_1_fold_1/runs/okshgyev
wandb: Find logs at: ./wandb/run-20220313_194607-okshgyev/logs/debug.log
wandb: 

wandb: wandb version 0.12.11 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
2022-03-13 21:03:19.267995: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1
wandb: Tracking run with wandb version 0.12.5
wandb: Syncing run cookies-n-cream-brulee-2
wandb: ⭐️ View project at https://wandb.ai/yinanazhou/xl_512_bs_8_lr_1e06_es_5_lc_True_nr_False_sr_False_stem_False_lemma_False_repeat_1_fold_2
wandb: 🚀 View run at https://wandb.ai/yinanazhou/xl_512_bs_8_lr_1e06_es_5_lc_True_nr_False_sr_False_stem_False_lemma_False_repeat_1_fold_2/runs/3k1dz4a3
wandb: Run data is saved locally in /project/6002780/yinan/Thesis_MER_Lyrics/lyric-emotion/wandb/run-20220313_210315-3k1dz4a3
wandb: Run `wandb offline` to turn off syncing.

Validation loss decreased (inf --> 1.390173).  Saving model ...
Validation loss decreased (1.390173 --> 1.378118).  Saving model ...
Validation loss decreased (1.378118 --> 1.369837).  Saving model ...
Validation loss decreased (1.369837 --> 1.362784).  Saving model ...
Validation loss decreased (1.362784 --> 1.357126).  Saving model ...
Validation loss decreased (1.357126 --> 1.352578).  Saving model ...
Validation loss decreased (1.352578 --> 1.348388).  Saving model ...
Validation loss decreased (1.348388 --> 1.343497).  Saving model ...
Validation loss decreased (1.343497 --> 1.338796).  Saving model ...
Validation loss decreased (1.338796 --> 1.333909).  Saving model ...
Validation loss decreased (1.333909 --> 1.329434).  Saving model ...
Validation loss decreased (1.329434 --> 1.324680).  Saving model ...
Validation loss decreased (1.324680 --> 1.319973).  Saving model ...
Validation loss decreased (1.319973 --> 1.314891).  Saving model ...
Validation loss decreased (1.314891 --> 1.309671).  Saving model ...
Validation loss decreased (1.309671 --> 1.304946).  Saving model ...
Validation loss decreased (1.304946 --> 1.299443).  Saving model ...
Validation loss decreased (1.299443 --> 1.293322).  Saving model ...
Validation loss decreased (1.293322 --> 1.287453).  Saving model ...
Validation loss decreased (1.287453 --> 1.281156).  Saving model ...
Validation loss decreased (1.281156 --> 1.274858).  Saving model ...
Validation loss decreased (1.274858 --> 1.268739).  Saving model ...
Validation loss decreased (1.268739 --> 1.262259).  Saving model ...
Validation loss decreased (1.262259 --> 1.255486).  Saving model ...
Validation loss decreased (1.255486 --> 1.247669).  Saving model ...
Validation loss decreased (1.247669 --> 1.240597).  Saving model ...
Validation loss decreased (1.240597 --> 1.233882).  Saving model ...
Validation loss decreased (1.233882 --> 1.226594).  Saving model ...
Validation loss decreased (1.226594 --> 1.218776).  Saving model ...
Validation loss decreased (1.218776 --> 1.211245).  Saving model ...
Validation loss decreased (1.211245 --> 1.202139).  Saving model ...
Validation loss decreased (1.202139 --> 1.194920).  Saving model ...
Validation loss decreased (1.194920 --> 1.187069).  Saving model ...
Validation loss decreased (1.187069 --> 1.179438).  Saving model ...
Validation loss decreased (1.179438 --> 1.172069).  Saving model ...
Validation loss decreased (1.172069 --> 1.164679).  Saving model ...
Validation loss decreased (1.164679 --> 1.158158).  Saving model ...
Validation loss decreased (1.158158 --> 1.151573).  Saving model ...
Validation loss decreased (1.151573 --> 1.145372).  Saving model ...
Validation loss decreased (1.145372 --> 1.138627).  Saving model ...
Validation loss decreased (1.138627 --> 1.131983).  Saving model ...
Validation loss decreased (1.131983 --> 1.125682).  Saving model ...
Validation loss decreased (1.125682 --> 1.118503).  Saving model ...
Validation loss decreased (1.118503 --> 1.112467).  Saving model ...
Validation loss decreased (1.112467 --> 1.106002).  Saving model ...
Validation loss decreased (1.106002 --> 1.101277).  Saving model ...
Validation loss decreased (1.101277 --> 1.095488).  Saving model ...
Validation loss decreased (1.095488 --> 1.092250).  Saving model ...
Validation loss decreased (1.092250 --> 1.089056).  Saving model ...
Validation loss decreased (1.089056 --> 1.082989).  Saving model ...
Validation loss decreased (1.082989 --> 1.076561).  Saving model ...
Validation loss decreased (1.076561 --> 1.073772).  Saving model ...
Validation loss decreased (1.073772 --> 1.069579).  Saving model ...
Validation loss decreased (1.069579 --> 1.066019).  Saving model ...
Validation loss decreased (1.066019 --> 1.061972).  Saving model ...
Validation loss decreased (1.061972 --> 1.055210).  Saving model ...
Validation loss decreased (1.055210 --> 1.049223).  Saving model ...
Validation loss decreased (1.049223 --> 1.046293).  Saving model ...
Validation loss decreased (1.046293 --> 1.044690).  Saving model ...
Validation loss decreased (1.044690 --> 1.040870).  Saving model ...
Validation loss decreased (1.040870 --> 1.035372).  Saving model ...
Validation loss decreased (1.035372 --> 1.031771).  Saving model ...
Validation loss decreased (1.031771 --> 1.029168).  Saving model ...
Validation loss decreased (1.029168 --> 1.026158).  Saving model ...
Validation loss decreased (1.026158 --> 1.023034).  Saving model ...
Validation loss decreased (1.023034 --> 1.021266).  Saving model ...
Validation loss decreased (1.021266 --> 1.016125).  Saving model ...
Validation loss decreased (1.016125 --> 1.012904).  Saving model ...
Validation loss decreased (1.012904 --> 1.010119).  Saving model ...
Validation loss decreased (1.010119 --> 1.008118).  Saving model ...
Validation loss decreased (1.008118 --> 1.003446).  Saving model ...
Validation loss decreased (1.003446 --> 1.001488).  Saving model ...
Validation loss decreased (1.001488 --> 0.999229).  Saving model ...
Validation loss decreased (0.999229 --> 0.997039).  Saving model ...
Validation loss decreased (0.997039 --> 0.993829).  Saving model ...
Validation loss decreased (0.993829 --> 0.991866).  Saving model ...
Validation loss decreased (0.991866 --> 0.990031).  Saving model ...
Validation loss decreased (0.990031 --> 0.988256).  Saving model ...
Validation loss decreased (0.988256 --> 0.988239).  Saving model ...
Validation loss decreased (0.988239 --> 0.987464).  Saving model ...
Validation loss decreased (0.987464 --> 0.984805).  Saving model ...
Validation loss decreased (0.984805 --> 0.982558).  Saving model ...
Validation loss decreased (0.982558 --> 0.982228).  Saving model ...
Validation loss decreased (0.982228 --> 0.979631).  Saving model ...
Validation loss decreased (0.979631 --> 0.979487).  Saving model ...
Validation loss decreased (0.979487 --> 0.975801).  Saving model ...
EarlyStopping counter: 1 out of 5.0
EarlyStopping counter: 2 out of 5.0
Validation loss decreased (0.975801 --> 0.974087).  Saving model ...
EarlyStopping counter: 1 out of 5.0
Validation loss decreased (0.974087 --> 0.970756).  Saving model ...
Validation loss decreased (0.970756 --> 0.967884).  Saving model ...
Validation loss decreased (0.967884 --> 0.966877).  Saving model ...
Validation loss decreased (0.966877 --> 0.965929).  Saving model ...
Validation loss decreased (0.965929 --> 0.964349).  Saving model ...
Validation loss decreased (0.964349 --> 0.962770).  Saving model ...
Validation loss decreased (0.962770 --> 0.961815).  Saving model ...
EarlyStopping counter: 1 out of 5.0
Validation loss decreased (0.961815 --> 0.959933).  Saving model ...
EarlyStopping counter: 1 out of 5.0
EarlyStopping counter: 2 out of 5.0
Validation loss decreased (0.959933 --> 0.959105).  Saving model ...
Validation loss decreased (0.959105 --> 0.958851).  Saving model ...
EarlyStopping counter: 1 out of 5.0
Validation loss decreased (0.958851 --> 0.958663).  Saving model ...
Validation loss decreased (0.958663 --> 0.958331).  Saving model ...
Validation loss decreased (0.958331 --> 0.957644).  Saving model ...
EarlyStopping counter: 1 out of 5.0
EarlyStopping counter: 2 out of 5.0
EarlyStopping counter: 3 out of 5.0
Validation loss decreased (0.957644 --> 0.955466).  Saving model ...
EarlyStopping counter: 1 out of 5.0
EarlyStopping counter: 2 out of 5.0
EarlyStopping counter: 3 out of 5.0
EarlyStopping counter: 4 out of 5.0
Validation loss decreased (0.955466 --> 0.954992).  Saving model ...
EarlyStopping counter: 1 out of 5.0
EarlyStopping counter: 2 out of 5.0
EarlyStopping counter: 3 out of 5.0
EarlyStopping counter: 4 out of 5.0
EarlyStopping counter: 5 out of 5.0
/localscratch/yinan.28869511.0/env/lib/python3.7/site-packages/torch/nn/functional.py:1794: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.
  warnings.warn("nn.functional.tanh is deprecated. Use torch.tanh instead.")
wandb: Waiting for W&B process to finish, PID 7367... (success).
wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: \ 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: | 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: / 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: \ 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: | 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: / 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: \ 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: | 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: / 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb:                                                                                
wandb: Run history:
wandb:     e_F1 ▁▄▄▅▅▅▆▆▆▆▆▇▇▇▇▇▇▇▇▇█▇▇▇████████████████
wandb:   e_loss ██▇▇▇▇▆▆▆▅▅▅▄▄▄▃▃▃▃▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:     t_F1 ▁▂▂▃▃▃▃▄▄▄▅▅▅▅▆▆▆▆▇▇▇▆▇▇▇▇▇▇▇▇▇█████████
wandb:   t_loss ███▇▇▇▇▇▇▆▆▆▆▅▅▅▄▄▄▄▄▄▄▃▃▃▃▂▂▂▂▂▂▂▂▂▁▂▁▁
wandb: 
wandb: Run summary:
wandb:     e_F1 58.79798
wandb:   e_loss 0.95705
wandb:     t_F1 70.97894
wandb:   t_loss 0.7735
wandb: 
wandb: Synced 4 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Synced cookies-n-cream-brulee-2: https://wandb.ai/yinanazhou/xl_512_bs_8_lr_1e06_es_5_lc_True_nr_False_sr_False_stem_False_lemma_False_repeat_1_fold_2/runs/3k1dz4a3
wandb: Find logs at: ./wandb/run-20220313_210315-3k1dz4a3/logs/debug.log
wandb: 

wandb: wandb version 0.12.11 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
2022-03-13 22:21:13.123865: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1
wandb: Tracking run with wandb version 0.12.5
wandb: Syncing run hershey-crumble-2
wandb: ⭐️ View project at https://wandb.ai/yinanazhou/xl_512_bs_8_lr_1e06_es_5_lc_True_nr_False_sr_False_stem_False_lemma_False_repeat_2_fold_1
wandb: 🚀 View run at https://wandb.ai/yinanazhou/xl_512_bs_8_lr_1e06_es_5_lc_True_nr_False_sr_False_stem_False_lemma_False_repeat_2_fold_1/runs/n91so05h
wandb: Run data is saved locally in /project/6002780/yinan/Thesis_MER_Lyrics/lyric-emotion/wandb/run-20220313_222110-n91so05h
wandb: Run `wandb offline` to turn off syncing.

Validation loss decreased (inf --> 1.391851).  Saving model ...
Validation loss decreased (1.391851 --> 1.388299).  Saving model ...
Validation loss decreased (1.388299 --> 1.384737).  Saving model ...
Validation loss decreased (1.384737 --> 1.381325).  Saving model ...
Validation loss decreased (1.381325 --> 1.378124).  Saving model ...
Validation loss decreased (1.378124 --> 1.374751).  Saving model ...
Validation loss decreased (1.374751 --> 1.371380).  Saving model ...
Validation loss decreased (1.371380 --> 1.367979).  Saving model ...
Validation loss decreased (1.367979 --> 1.364433).  Saving model ...
Validation loss decreased (1.364433 --> 1.360998).  Saving model ...
Validation loss decreased (1.360998 --> 1.357369).  Saving model ...
Validation loss decreased (1.357369 --> 1.353455).  Saving model ...
Validation loss decreased (1.353455 --> 1.349390).  Saving model ...
Validation loss decreased (1.349390 --> 1.345107).  Saving model ...
Validation loss decreased (1.345107 --> 1.340915).  Saving model ...
Validation loss decreased (1.340915 --> 1.336184).  Saving model ...
Validation loss decreased (1.336184 --> 1.331048).  Saving model ...
Validation loss decreased (1.331048 --> 1.325846).  Saving model ...
Validation loss decreased (1.325846 --> 1.320542).  Saving model ...
Validation loss decreased (1.320542 --> 1.314345).  Saving model ...
Validation loss decreased (1.314345 --> 1.307605).  Saving model ...
Validation loss decreased (1.307605 --> 1.300516).  Saving model ...
Validation loss decreased (1.300516 --> 1.293368).  Saving model ...
Validation loss decreased (1.293368 --> 1.285800).  Saving model ...
Validation loss decreased (1.285800 --> 1.277463).  Saving model ...
Validation loss decreased (1.277463 --> 1.268898).  Saving model ...
Validation loss decreased (1.268898 --> 1.259007).  Saving model ...
Validation loss decreased (1.259007 --> 1.250487).  Saving model ...
Validation loss decreased (1.250487 --> 1.240421).  Saving model ...
Validation loss decreased (1.240421 --> 1.229252).  Saving model ...
Validation loss decreased (1.229252 --> 1.218872).  Saving model ...
Validation loss decreased (1.218872 --> 1.208467).  Saving model ...
Validation loss decreased (1.208467 --> 1.199324).  Saving model ...
Validation loss decreased (1.199324 --> 1.191014).  Saving model ...
Validation loss decreased (1.191014 --> 1.180958).  Saving model ...
Validation loss decreased (1.180958 --> 1.170548).  Saving model ...
Validation loss decreased (1.170548 --> 1.161864).  Saving model ...
Validation loss decreased (1.161864 --> 1.153243).  Saving model ...
Validation loss decreased (1.153243 --> 1.146404).  Saving model ...
Validation loss decreased (1.146404 --> 1.140139).  Saving model ...
Validation loss decreased (1.140139 --> 1.133184).  Saving model ...
Validation loss decreased (1.133184 --> 1.127160).  Saving model ...
Validation loss decreased (1.127160 --> 1.120160).  Saving model ...
Validation loss decreased (1.120160 --> 1.115290).  Saving model ...
Validation loss decreased (1.115290 --> 1.110873).  Saving model ...
Validation loss decreased (1.110873 --> 1.103882).  Saving model ...
Validation loss decreased (1.103882 --> 1.098321).  Saving model ...
Validation loss decreased (1.098321 --> 1.093272).  Saving model ...
Validation loss decreased (1.093272 --> 1.088873).  Saving model ...
Validation loss decreased (1.088873 --> 1.083901).  Saving model ...
Validation loss decreased (1.083901 --> 1.079154).  Saving model ...
Validation loss decreased (1.079154 --> 1.074074).  Saving model ...
Validation loss decreased (1.074074 --> 1.069838).  Saving model ...
Validation loss decreased (1.069838 --> 1.065628).  Saving model ...
Validation loss decreased (1.065628 --> 1.062027).  Saving model ...
Validation loss decreased (1.062027 --> 1.057318).  Saving model ...
Validation loss decreased (1.057318 --> 1.054353).  Saving model ...
Validation loss decreased (1.054353 --> 1.049400).  Saving model ...
Validation loss decreased (1.049400 --> 1.046608).  Saving model ...
Validation loss decreased (1.046608 --> 1.042631).  Saving model ...
Validation loss decreased (1.042631 --> 1.039885).  Saving model ...
Validation loss decreased (1.039885 --> 1.036616).  Saving model ...
Validation loss decreased (1.036616 --> 1.032656).  Saving model ...
Validation loss decreased (1.032656 --> 1.030405).  Saving model ...
Validation loss decreased (1.030405 --> 1.026526).  Saving model ...
Validation loss decreased (1.026526 --> 1.022952).  Saving model ...
Validation loss decreased (1.022952 --> 1.020451).  Saving model ...
Validation loss decreased (1.020451 --> 1.018480).  Saving model ...
Validation loss decreased (1.018480 --> 1.015227).  Saving model ...
Validation loss decreased (1.015227 --> 1.013752).  Saving model ...
Validation loss decreased (1.013752 --> 1.011104).  Saving model ...
Validation loss decreased (1.011104 --> 1.008654).  Saving model ...
Validation loss decreased (1.008654 --> 1.006379).  Saving model ...
Validation loss decreased (1.006379 --> 1.003422).  Saving model ...
Validation loss decreased (1.003422 --> 1.001060).  Saving model ...
Validation loss decreased (1.001060 --> 0.998995).  Saving model ...
Validation loss decreased (0.998995 --> 0.996633).  Saving model ...
Validation loss decreased (0.996633 --> 0.995160).  Saving model ...
Validation loss decreased (0.995160 --> 0.993834).  Saving model ...
Validation loss decreased (0.993834 --> 0.992658).  Saving model ...
Validation loss decreased (0.992658 --> 0.992358).  Saving model ...
Validation loss decreased (0.992358 --> 0.990348).  Saving model ...
Validation loss decreased (0.990348 --> 0.988368).  Saving model ...
Validation loss decreased (0.988368 --> 0.986791).  Saving model ...
Validation loss decreased (0.986791 --> 0.984659).  Saving model ...
Validation loss decreased (0.984659 --> 0.983286).  Saving model ...
Validation loss decreased (0.983286 --> 0.981783).  Saving model ...
Validation loss decreased (0.981783 --> 0.981705).  Saving model ...
Validation loss decreased (0.981705 --> 0.981044).  Saving model ...
Validation loss decreased (0.981044 --> 0.978494).  Saving model ...
Validation loss decreased (0.978494 --> 0.977543).  Saving model ...
Validation loss decreased (0.977543 --> 0.975096).  Saving model ...
Validation loss decreased (0.975096 --> 0.974429).  Saving model ...
Validation loss decreased (0.974429 --> 0.973773).  Saving model ...
Validation loss decreased (0.973773 --> 0.972479).  Saving model ...
Validation loss decreased (0.972479 --> 0.971854).  Saving model ...
Validation loss decreased (0.971854 --> 0.971590).  Saving model ...
Validation loss decreased (0.971590 --> 0.971162).  Saving model ...
Validation loss decreased (0.971162 --> 0.971065).  Saving model ...
Validation loss decreased (0.971065 --> 0.969570).  Saving model ...
Validation loss decreased (0.969570 --> 0.967344).  Saving model ...
EarlyStopping counter: 1 out of 5.0
Validation loss decreased (0.967344 --> 0.967110).  Saving model ...
EarlyStopping counter: 1 out of 5.0
Validation loss decreased (0.967110 --> 0.966081).  Saving model ...
EarlyStopping counter: 1 out of 5.0
Validation loss decreased (0.966081 --> 0.966066).  Saving model ...
Validation loss decreased (0.966066 --> 0.965571).  Saving model ...
Validation loss decreased (0.965571 --> 0.964976).  Saving model ...
EarlyStopping counter: 1 out of 5.0
EarlyStopping counter: 2 out of 5.0
EarlyStopping counter: 3 out of 5.0
EarlyStopping counter: 4 out of 5.0
EarlyStopping counter: 5 out of 5.0
/localscratch/yinan.28869511.0/env/lib/python3.7/site-packages/torch/nn/functional.py:1794: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.
  warnings.warn("nn.functional.tanh is deprecated. Use torch.tanh instead.")
wandb: Waiting for W&B process to finish, PID 11555... (success).
wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: \ 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: | 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: / 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: \ 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: | 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: / 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: \ 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: | 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: / 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb:                                                                                
wandb: Run history:
wandb:     e_F1 ▁▂▂▂▃▃▃▄▅▅▅▅▆▆▆▇▇▇▇█▇▇▇▇████████████████
wandb:   e_loss ████▇▇▇▇▆▆▆▅▅▄▄▃▃▃▃▃▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:     t_F1 ▁▁▁▂▂▂▃▃▃▄▄▅▅▅▅▅▆▆▇▆▆▆▆▇▇▇▇▇▇▇▇▇▇▇██████
wandb:   t_loss ████▇▇▇▇▇▆▆▆▅▅▅▅▄▄▄▄▃▄▃▃▃▃▂▂▂▂▂▂▂▂▂▂▂▁▁▁
wandb: 
wandb: Run summary:
wandb:     e_F1 61.51519
wandb:   e_loss 0.96603
wandb:     t_F1 72.15452
wandb:   t_loss 0.76386
wandb: 
wandb: Synced 4 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Synced hershey-crumble-2: https://wandb.ai/yinanazhou/xl_512_bs_8_lr_1e06_es_5_lc_True_nr_False_sr_False_stem_False_lemma_False_repeat_2_fold_1/runs/n91so05h
wandb: Find logs at: ./wandb/run-20220313_222110-n91so05h/logs/debug.log
wandb: 

wandb: wandb version 0.12.11 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
2022-03-13 23:37:06.467816: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1
wandb: Tracking run with wandb version 0.12.5
wandb: Syncing run mud-brownie-2
wandb: ⭐️ View project at https://wandb.ai/yinanazhou/xl_512_bs_8_lr_1e06_es_5_lc_True_nr_False_sr_False_stem_False_lemma_False_repeat_2_fold_2
wandb: 🚀 View run at https://wandb.ai/yinanazhou/xl_512_bs_8_lr_1e06_es_5_lc_True_nr_False_sr_False_stem_False_lemma_False_repeat_2_fold_2/runs/lvsxsfsq
wandb: Run data is saved locally in /project/6002780/yinan/Thesis_MER_Lyrics/lyric-emotion/wandb/run-20220313_233703-lvsxsfsq
wandb: Run `wandb offline` to turn off syncing.

Validation loss decreased (inf --> 1.403753).  Saving model ...
Validation loss decreased (1.403753 --> 1.390359).  Saving model ...
Validation loss decreased (1.390359 --> 1.379835).  Saving model ...
Validation loss decreased (1.379835 --> 1.372847).  Saving model ...
Validation loss decreased (1.372847 --> 1.366736).  Saving model ...
Validation loss decreased (1.366736 --> 1.361781).  Saving model ...
Validation loss decreased (1.361781 --> 1.357541).  Saving model ...
Validation loss decreased (1.357541 --> 1.353538).  Saving model ...
Validation loss decreased (1.353538 --> 1.349585).  Saving model ...
Validation loss decreased (1.349585 --> 1.345355).  Saving model ...
Validation loss decreased (1.345355 --> 1.341407).  Saving model ...
Validation loss decreased (1.341407 --> 1.336840).  Saving model ...
Validation loss decreased (1.336840 --> 1.332440).  Saving model ...
Validation loss decreased (1.332440 --> 1.328156).  Saving model ...
Validation loss decreased (1.328156 --> 1.323375).  Saving model ...
Validation loss decreased (1.323375 --> 1.318615).  Saving model ...
Validation loss decreased (1.318615 --> 1.313078).  Saving model ...
Validation loss decreased (1.313078 --> 1.307802).  Saving model ...
Validation loss decreased (1.307802 --> 1.302024).  Saving model ...
Validation loss decreased (1.302024 --> 1.296984).  Saving model ...
Validation loss decreased (1.296984 --> 1.291154).  Saving model ...
Validation loss decreased (1.291154 --> 1.284192).  Saving model ...
Validation loss decreased (1.284192 --> 1.278276).  Saving model ...
Validation loss decreased (1.278276 --> 1.272252).  Saving model ...
Validation loss decreased (1.272252 --> 1.265911).  Saving model ...
Validation loss decreased (1.265911 --> 1.259311).  Saving model ...
Validation loss decreased (1.259311 --> 1.251726).  Saving model ...
Validation loss decreased (1.251726 --> 1.245405).  Saving model ...
Validation loss decreased (1.245405 --> 1.238695).  Saving model ...
Validation loss decreased (1.238695 --> 1.230175).  Saving model ...
Validation loss decreased (1.230175 --> 1.221656).  Saving model ...
Validation loss decreased (1.221656 --> 1.213226).  Saving model ...
Validation loss decreased (1.213226 --> 1.205535).  Saving model ...
Validation loss decreased (1.205535 --> 1.198066).  Saving model ...
Validation loss decreased (1.198066 --> 1.190218).  Saving model ...
Validation loss decreased (1.190218 --> 1.181700).  Saving model ...
Validation loss decreased (1.181700 --> 1.173684).  Saving model ...
Validation loss decreased (1.173684 --> 1.167824).  Saving model ...
Validation loss decreased (1.167824 --> 1.160402).  Saving model ...
Validation loss decreased (1.160402 --> 1.153030).  Saving model ...
Validation loss decreased (1.153030 --> 1.146220).  Saving model ...
Validation loss decreased (1.146220 --> 1.139604).  Saving model ...
Validation loss decreased (1.139604 --> 1.134758).  Saving model ...
Validation loss decreased (1.134758 --> 1.129922).  Saving model ...
Validation loss decreased (1.129922 --> 1.122542).  Saving model ...
Validation loss decreased (1.122542 --> 1.116326).  Saving model ...
Validation loss decreased (1.116326 --> 1.112020).  Saving model ...
Validation loss decreased (1.112020 --> 1.106754).  Saving model ...
Validation loss decreased (1.106754 --> 1.100055).  Saving model ...
Validation loss decreased (1.100055 --> 1.093687).  Saving model ...
Validation loss decreased (1.093687 --> 1.088389).  Saving model ...
Validation loss decreased (1.088389 --> 1.082893).  Saving model ...
Validation loss decreased (1.082893 --> 1.077770).  Saving model ...
Validation loss decreased (1.077770 --> 1.071565).  Saving model ...
Validation loss decreased (1.071565 --> 1.066762).  Saving model ...
Validation loss decreased (1.066762 --> 1.060966).  Saving model ...
Validation loss decreased (1.060966 --> 1.056970).  Saving model ...
Validation loss decreased (1.056970 --> 1.053085).  Saving model ...
Validation loss decreased (1.053085 --> 1.049722).  Saving model ...
Validation loss decreased (1.049722 --> 1.044826).  Saving model ...
Validation loss decreased (1.044826 --> 1.040506).  Saving model ...
Validation loss decreased (1.040506 --> 1.036296).  Saving model ...
Validation loss decreased (1.036296 --> 1.033309).  Saving model ...
Validation loss decreased (1.033309 --> 1.028262).  Saving model ...
Validation loss decreased (1.028262 --> 1.023885).  Saving model ...
Validation loss decreased (1.023885 --> 1.019682).  Saving model ...
Validation loss decreased (1.019682 --> 1.017038).  Saving model ...
Validation loss decreased (1.017038 --> 1.012524).  Saving model ...
Validation loss decreased (1.012524 --> 1.008198).  Saving model ...
Validation loss decreased (1.008198 --> 1.005991).  Saving model ...
Validation loss decreased (1.005991 --> 1.005558).  Saving model ...
Validation loss decreased (1.005558 --> 1.001315).  Saving model ...
Validation loss decreased (1.001315 --> 0.997035).  Saving model ...
Validation loss decreased (0.997035 --> 0.996060).  Saving model ...
Validation loss decreased (0.996060 --> 0.992898).  Saving model ...
Validation loss decreased (0.992898 --> 0.991054).  Saving model ...
Validation loss decreased (0.991054 --> 0.988369).  Saving model ...
Validation loss decreased (0.988369 --> 0.984609).  Saving model ...
Validation loss decreased (0.984609 --> 0.981021).  Saving model ...
Validation loss decreased (0.981021 --> 0.977073).  Saving model ...
Validation loss decreased (0.977073 --> 0.976794).  Saving model ...
Validation loss decreased (0.976794 --> 0.975922).  Saving model ...
Validation loss decreased (0.975922 --> 0.974143).  Saving model ...
Validation loss decreased (0.974143 --> 0.971248).  Saving model ...
Validation loss decreased (0.971248 --> 0.967261).  Saving model ...
Validation loss decreased (0.967261 --> 0.964520).  Saving model ...
Validation loss decreased (0.964520 --> 0.963545).  Saving model ...
Validation loss decreased (0.963545 --> 0.963115).  Saving model ...
Validation loss decreased (0.963115 --> 0.960620).  Saving model ...
Validation loss decreased (0.960620 --> 0.958837).  Saving model ...
Validation loss decreased (0.958837 --> 0.957517).  Saving model ...
Validation loss decreased (0.957517 --> 0.956474).  Saving model ...
Validation loss decreased (0.956474 --> 0.955890).  Saving model ...
Validation loss decreased (0.955890 --> 0.953892).  Saving model ...
Validation loss decreased (0.953892 --> 0.951518).  Saving model ...
Validation loss decreased (0.951518 --> 0.949232).  Saving model ...
Validation loss decreased (0.949232 --> 0.946798).  Saving model ...
Validation loss decreased (0.946798 --> 0.945336).  Saving model ...
Validation loss decreased (0.945336 --> 0.943606).  Saving model ...
Validation loss decreased (0.943606 --> 0.941911).  Saving model ...
Validation loss decreased (0.941911 --> 0.939912).  Saving model ...
Validation loss decreased (0.939912 --> 0.938070).  Saving model ...
Validation loss decreased (0.938070 --> 0.936965).  Saving model ...
Validation loss decreased (0.936965 --> 0.934918).  Saving model ...
EarlyStopping counter: 1 out of 5.0
Validation loss decreased (0.934918 --> 0.934059).  Saving model ...
Validation loss decreased (0.934059 --> 0.932136).  Saving model ...
Validation loss decreased (0.932136 --> 0.932100).  Saving model ...
Validation loss decreased (0.932100 --> 0.932068).  Saving model ...
Validation loss decreased (0.932068 --> 0.931783).  Saving model ...
Validation loss decreased (0.931783 --> 0.930688).  Saving model ...
Validation loss decreased (0.930688 --> 0.929478).  Saving model ...
Validation loss decreased (0.929478 --> 0.926664).  Saving model ...
EarlyStopping counter: 1 out of 5.0
Validation loss decreased (0.926664 --> 0.925387).  Saving model ...
Validation loss decreased (0.925387 --> 0.923334).  Saving model ...
Validation loss decreased (0.923334 --> 0.922516).  Saving model ...
Validation loss decreased (0.922516 --> 0.921253).  Saving model ...
Validation loss decreased (0.921253 --> 0.920228).  Saving model ...
Validation loss decreased (0.920228 --> 0.919986).  Saving model ...
EarlyStopping counter: 1 out of 5.0
Validation loss decreased (0.919986 --> 0.919187).  Saving model ...
Validation loss decreased (0.919187 --> 0.917886).  Saving model ...
Validation loss decreased (0.917886 --> 0.917661).  Saving model ...
Validation loss decreased (0.917661 --> 0.917483).  Saving model ...
Validation loss decreased (0.917483 --> 0.916308).  Saving model ...
EarlyStopping counter: 1 out of 5.0
Validation loss decreased (0.916308 --> 0.916273).  Saving model ...
Validation loss decreased (0.916273 --> 0.915616).  Saving model ...
Validation loss decreased (0.915616 --> 0.914803).  Saving model ...
EarlyStopping counter: 1 out of 5.0
Validation loss decreased (0.914803 --> 0.913236).  Saving model ...
EarlyStopping counter: 1 out of 5.0
Validation loss decreased (0.913236 --> 0.912842).  Saving model ...
EarlyStopping counter: 1 out of 5.0
Validation loss decreased (0.912842 --> 0.912186).  Saving model ...
EarlyStopping counter: 1 out of 5.0
Validation loss decreased (0.912186 --> 0.911336).  Saving model ...
Validation loss decreased (0.911336 --> 0.910510).  Saving model ...
EarlyStopping counter: 1 out of 5.0
EarlyStopping counter: 2 out of 5.0
EarlyStopping counter: 3 out of 5.0
Validation loss decreased (0.910510 --> 0.909790).  Saving model ...
Validation loss decreased (0.909790 --> 0.909420).  Saving model ...
EarlyStopping counter: 1 out of 5.0
EarlyStopping counter: 2 out of 5.0
EarlyStopping counter: 3 out of 5.0
EarlyStopping counter: 4 out of 5.0
EarlyStopping counter: 5 out of 5.0
/localscratch/yinan.28869511.0/env/lib/python3.7/site-packages/torch/nn/functional.py:1794: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.
  warnings.warn("nn.functional.tanh is deprecated. Use torch.tanh instead.")
wandb: Waiting for W&B process to finish, PID 15689... (success).
wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: \ 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: | 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: / 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: \ 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: | 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: / 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: \ 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: | 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: / 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb:                                                                                
wandb: Run history:
wandb:     e_F1 ▁▂▄▄▄▄▄▅▅▅▆▆▆▆▆▆▆▆▇▇▇▇▇▇▇▇▇▇▇▇██████████
wandb:   e_loss ██▇▇▇▇▆▆▆▅▅▄▄▄▃▃▃▃▃▂▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:     t_F1 ▁▂▂▂▃▃▄▄▄▄▅▅▅▅▆▆▆▆▆▆▆▆▆▆▇▇▇▇▇▇▇▇█▇▇█▇███
wandb:   t_loss ███▇▇▇▇▇▆▆▆▅▅▅▅▄▄▄▄▄▃▃▃▃▃▂▃▂▂▂▂▂▂▂▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:     e_F1 64.41082
wandb:   e_loss 0.91108
wandb:     t_F1 74.90616
wandb:   t_loss 0.70017
wandb: 
wandb: Synced 4 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Synced mud-brownie-2: https://wandb.ai/yinanazhou/xl_512_bs_8_lr_1e06_es_5_lc_True_nr_False_sr_False_stem_False_lemma_False_repeat_2_fold_2/runs/lvsxsfsq
wandb: Find logs at: ./wandb/run-20220313_233703-lvsxsfsq/logs/debug.log
wandb: 

wandb: wandb version 0.12.11 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
2022-03-14 01:16:01.409090: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1
wandb: Tracking run with wandb version 0.12.5
wandb: Syncing run apple-bun-2
wandb: ⭐️ View project at https://wandb.ai/yinanazhou/xl_512_bs_8_lr_1e06_es_5_lc_True_nr_False_sr_False_stem_False_lemma_False_repeat_3_fold_1
wandb: 🚀 View run at https://wandb.ai/yinanazhou/xl_512_bs_8_lr_1e06_es_5_lc_True_nr_False_sr_False_stem_False_lemma_False_repeat_3_fold_1/runs/7vlrzbnb
wandb: Run data is saved locally in /project/6002780/yinan/Thesis_MER_Lyrics/lyric-emotion/wandb/run-20220314_011558-7vlrzbnb
wandb: Run `wandb offline` to turn off syncing.

Validation loss decreased (inf --> 1.431518).  Saving model ...
Validation loss decreased (1.431518 --> 1.410153).  Saving model ...
Validation loss decreased (1.410153 --> 1.394947).  Saving model ...
Validation loss decreased (1.394947 --> 1.383012).  Saving model ...
Validation loss decreased (1.383012 --> 1.373460).  Saving model ...
Validation loss decreased (1.373460 --> 1.366067).  Saving model ...
Validation loss decreased (1.366067 --> 1.359385).  Saving model ...
Validation loss decreased (1.359385 --> 1.353283).  Saving model ...
Validation loss decreased (1.353283 --> 1.348170).  Saving model ...
Validation loss decreased (1.348170 --> 1.343377).  Saving model ...
Validation loss decreased (1.343377 --> 1.338513).  Saving model ...
Validation loss decreased (1.338513 --> 1.333848).  Saving model ...
Validation loss decreased (1.333848 --> 1.328896).  Saving model ...
Validation loss decreased (1.328896 --> 1.324080).  Saving model ...
Validation loss decreased (1.324080 --> 1.319456).  Saving model ...
Validation loss decreased (1.319456 --> 1.314599).  Saving model ...
Validation loss decreased (1.314599 --> 1.309741).  Saving model ...
Validation loss decreased (1.309741 --> 1.304983).  Saving model ...
Validation loss decreased (1.304983 --> 1.300215).  Saving model ...
Validation loss decreased (1.300215 --> 1.294628).  Saving model ...
Validation loss decreased (1.294628 --> 1.288872).  Saving model ...
Validation loss decreased (1.288872 --> 1.282998).  Saving model ...
Validation loss decreased (1.282998 --> 1.277263).  Saving model ...
Validation loss decreased (1.277263 --> 1.271463).  Saving model ...
Validation loss decreased (1.271463 --> 1.265233).  Saving model ...
Validation loss decreased (1.265233 --> 1.259581).  Saving model ...
Validation loss decreased (1.259581 --> 1.253069).  Saving model ...
Validation loss decreased (1.253069 --> 1.245971).  Saving model ...
Validation loss decreased (1.245971 --> 1.239798).  Saving model ...
Validation loss decreased (1.239798 --> 1.232794).  Saving model ...
Validation loss decreased (1.232794 --> 1.226148).  Saving model ...
Validation loss decreased (1.226148 --> 1.219214).  Saving model ...
Validation loss decreased (1.219214 --> 1.212299).  Saving model ...
Validation loss decreased (1.212299 --> 1.206660).  Saving model ...
Validation loss decreased (1.206660 --> 1.199442).  Saving model ...
Validation loss decreased (1.199442 --> 1.191278).  Saving model ...
Validation loss decreased (1.191278 --> 1.184701).  Saving model ...
Validation loss decreased (1.184701 --> 1.176980).  Saving model ...
Validation loss decreased (1.176980 --> 1.169445).  Saving model ...
Validation loss decreased (1.169445 --> 1.161762).  Saving model ...
Validation loss decreased (1.161762 --> 1.154819).  Saving model ...
Validation loss decreased (1.154819 --> 1.147597).  Saving model ...
Validation loss decreased (1.147597 --> 1.140410).  Saving model ...
Validation loss decreased (1.140410 --> 1.133038).  Saving model ...
Validation loss decreased (1.133038 --> 1.129248).  Saving model ...
Validation loss decreased (1.129248 --> 1.123471).  Saving model ...
Validation loss decreased (1.123471 --> 1.117663).  Saving model ...
Validation loss decreased (1.117663 --> 1.111659).  Saving model ...
Validation loss decreased (1.111659 --> 1.105975).  Saving model ...
Validation loss decreased (1.105975 --> 1.099846).  Saving model ...
Validation loss decreased (1.099846 --> 1.096715).  Saving model ...
Validation loss decreased (1.096715 --> 1.091685).  Saving model ...
Validation loss decreased (1.091685 --> 1.085827).  Saving model ...
Validation loss decreased (1.085827 --> 1.082896).  Saving model ...
Validation loss decreased (1.082896 --> 1.079236).  Saving model ...
Validation loss decreased (1.079236 --> 1.073252).  Saving model ...
Validation loss decreased (1.073252 --> 1.067868).  Saving model ...
Validation loss decreased (1.067868 --> 1.064799).  Saving model ...
Validation loss decreased (1.064799 --> 1.061662).  Saving model ...
Validation loss decreased (1.061662 --> 1.059060).  Saving model ...
Validation loss decreased (1.059060 --> 1.055708).  Saving model ...
Validation loss decreased (1.055708 --> 1.051565).  Saving model ...
Validation loss decreased (1.051565 --> 1.048596).  Saving model ...
Validation loss decreased (1.048596 --> 1.045595).  Saving model ...
Validation loss decreased (1.045595 --> 1.043399).  Saving model ...
Validation loss decreased (1.043399 --> 1.039508).  Saving model ...
Validation loss decreased (1.039508 --> 1.034171).  Saving model ...
Validation loss decreased (1.034171 --> 1.032600).  Saving model ...
Validation loss decreased (1.032600 --> 1.029781).  Saving model ...
Validation loss decreased (1.029781 --> 1.024114).  Saving model ...
Validation loss decreased (1.024114 --> 1.023452).  Saving model ...
Validation loss decreased (1.023452 --> 1.021139).  Saving model ...
Validation loss decreased (1.021139 --> 1.018237).  Saving model ...
Validation loss decreased (1.018237 --> 1.014663).  Saving model ...
Validation loss decreased (1.014663 --> 1.012550).  Saving model ...
Validation loss decreased (1.012550 --> 1.010899).  Saving model ...
Validation loss decreased (1.010899 --> 1.009660).  Saving model ...
Validation loss decreased (1.009660 --> 1.006449).  Saving model ...
Validation loss decreased (1.006449 --> 1.004878).  Saving model ...
Validation loss decreased (1.004878 --> 1.002129).  Saving model ...
Validation loss decreased (1.002129 --> 0.999987).  Saving model ...
Validation loss decreased (0.999987 --> 0.996813).  Saving model ...
EarlyStopping counter: 1 out of 5.0
Validation loss decreased (0.996813 --> 0.996592).  Saving model ...
Validation loss decreased (0.996592 --> 0.993240).  Saving model ...
EarlyStopping counter: 1 out of 5.0
EarlyStopping counter: 2 out of 5.0
Validation loss decreased (0.993240 --> 0.990313).  Saving model ...
Validation loss decreased (0.990313 --> 0.989645).  Saving model ...
Validation loss decreased (0.989645 --> 0.989489).  Saving model ...
Validation loss decreased (0.989489 --> 0.989378).  Saving model ...
Validation loss decreased (0.989378 --> 0.989199).  Saving model ...
Validation loss decreased (0.989199 --> 0.984495).  Saving model ...
Validation loss decreased (0.984495 --> 0.983933).  Saving model ...
Validation loss decreased (0.983933 --> 0.980574).  Saving model ...
EarlyStopping counter: 1 out of 5.0
EarlyStopping counter: 2 out of 5.0
Validation loss decreased (0.980574 --> 0.976799).  Saving model ...
Validation loss decreased (0.976799 --> 0.974367).  Saving model ...
Validation loss decreased (0.974367 --> 0.974234).  Saving model ...
Validation loss decreased (0.974234 --> 0.971823).  Saving model ...
Validation loss decreased (0.971823 --> 0.971005).  Saving model ...
EarlyStopping counter: 1 out of 5.0
EarlyStopping counter: 2 out of 5.0
Validation loss decreased (0.971005 --> 0.969172).  Saving model ...
EarlyStopping counter: 1 out of 5.0
Validation loss decreased (0.969172 --> 0.969059).  Saving model ...
Validation loss decreased (0.969059 --> 0.967398).  Saving model ...
EarlyStopping counter: 1 out of 5.0
Validation loss decreased (0.967398 --> 0.964720).  Saving model ...
Validation loss decreased (0.964720 --> 0.964500).  Saving model ...
Validation loss decreased (0.964500 --> 0.963593).  Saving model ...
EarlyStopping counter: 1 out of 5.0
EarlyStopping counter: 2 out of 5.0
EarlyStopping counter: 3 out of 5.0
Validation loss decreased (0.963593 --> 0.963024).  Saving model ...
Validation loss decreased (0.963024 --> 0.962721).  Saving model ...
EarlyStopping counter: 1 out of 5.0
EarlyStopping counter: 2 out of 5.0
Validation loss decreased (0.962721 --> 0.962227).  Saving model ...
EarlyStopping counter: 1 out of 5.0
EarlyStopping counter: 2 out of 5.0
EarlyStopping counter: 3 out of 5.0
Validation loss decreased (0.962227 --> 0.960083).  Saving model ...
EarlyStopping counter: 1 out of 5.0
EarlyStopping counter: 2 out of 5.0
EarlyStopping counter: 3 out of 5.0
Validation loss decreased (0.960083 --> 0.959873).  Saving model ...
Validation loss decreased (0.959873 --> 0.957322).  Saving model ...
EarlyStopping counter: 1 out of 5.0
EarlyStopping counter: 2 out of 5.0
EarlyStopping counter: 3 out of 5.0
EarlyStopping counter: 4 out of 5.0
EarlyStopping counter: 5 out of 5.0
/localscratch/yinan.28869511.0/env/lib/python3.7/site-packages/torch/nn/functional.py:1794: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.
  warnings.warn("nn.functional.tanh is deprecated. Use torch.tanh instead.")
wandb: Waiting for W&B process to finish, PID 21012... (success).
wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: \ 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: | 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: / 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: \ 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: | 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: / 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: \ 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: | 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: / 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb:                                                                                
wandb: Run history:
wandb:     e_F1 ▁▂▄▄▅▅▆▅▆▆▆▆▆▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇███████████
wandb:   e_loss ██▇▇▇▆▆▆▅▅▅▄▄▄▃▃▃▃▂▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:     t_F1 ▁▂▃▃▄▄▅▄▅▅▅▅▆▆▆▆▇▆▇▇▇▇▇▇▇█▇▇█████▇██████
wandb:   t_loss ██▇▇▇▇▆▆▆▆▆▆▅▅▄▅▄▄▄▃▃▃▃▃▃▂▂▂▂▂▂▂▂▂▂▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:     e_F1 59.79865
wandb:   e_loss 0.9576
wandb:     t_F1 71.87082
wandb:   t_loss 0.74577
wandb: 
wandb: Synced 4 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Synced apple-bun-2: https://wandb.ai/yinanazhou/xl_512_bs_8_lr_1e06_es_5_lc_True_nr_False_sr_False_stem_False_lemma_False_repeat_3_fold_1/runs/7vlrzbnb
wandb: Find logs at: ./wandb/run-20220314_011558-7vlrzbnb/logs/debug.log
wandb: 

wandb: wandb version 0.12.11 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
2022-03-14 02:42:19.634233: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1
wandb: Tracking run with wandb version 0.12.5
wandb: Syncing run elderberry-meringue-2
wandb: ⭐️ View project at https://wandb.ai/yinanazhou/xl_512_bs_8_lr_1e06_es_5_lc_True_nr_False_sr_False_stem_False_lemma_False_repeat_3_fold_2
wandb: 🚀 View run at https://wandb.ai/yinanazhou/xl_512_bs_8_lr_1e06_es_5_lc_True_nr_False_sr_False_stem_False_lemma_False_repeat_3_fold_2/runs/265cods1
wandb: Run data is saved locally in /project/6002780/yinan/Thesis_MER_Lyrics/lyric-emotion/wandb/run-20220314_024216-265cods1
wandb: Run `wandb offline` to turn off syncing.

Validation loss decreased (inf --> 1.407989).  Saving model ...
Validation loss decreased (1.407989 --> 1.397010).  Saving model ...
Validation loss decreased (1.397010 --> 1.388224).  Saving model ...
Validation loss decreased (1.388224 --> 1.381015).  Saving model ...
Validation loss decreased (1.381015 --> 1.374690).  Saving model ...
Validation loss decreased (1.374690 --> 1.369318).  Saving model ...
Validation loss decreased (1.369318 --> 1.364203).  Saving model ...
Validation loss decreased (1.364203 --> 1.359838).  Saving model ...
Validation loss decreased (1.359838 --> 1.355287).  Saving model ...
Validation loss decreased (1.355287 --> 1.350726).  Saving model ...
Validation loss decreased (1.350726 --> 1.346061).  Saving model ...
Validation loss decreased (1.346061 --> 1.341527).  Saving model ...
Validation loss decreased (1.341527 --> 1.336914).  Saving model ...
Validation loss decreased (1.336914 --> 1.332349).  Saving model ...
Validation loss decreased (1.332349 --> 1.327511).  Saving model ...
Validation loss decreased (1.327511 --> 1.322700).  Saving model ...
Validation loss decreased (1.322700 --> 1.317551).  Saving model ...
Validation loss decreased (1.317551 --> 1.311710).  Saving model ...
Validation loss decreased (1.311710 --> 1.305285).  Saving model ...
Validation loss decreased (1.305285 --> 1.299887).  Saving model ...
Validation loss decreased (1.299887 --> 1.293043).  Saving model ...
Validation loss decreased (1.293043 --> 1.285821).  Saving model ...
Validation loss decreased (1.285821 --> 1.277873).  Saving model ...
Validation loss decreased (1.277873 --> 1.269824).  Saving model ...
Validation loss decreased (1.269824 --> 1.261750).  Saving model ...
Validation loss decreased (1.261750 --> 1.253292).  Saving model ...
Validation loss decreased (1.253292 --> 1.245281).  Saving model ...
Validation loss decreased (1.245281 --> 1.236157).  Saving model ...
Validation loss decreased (1.236157 --> 1.228075).  Saving model ...
Validation loss decreased (1.228075 --> 1.220654).  Saving model ...
Validation loss decreased (1.220654 --> 1.212215).  Saving model ...
Validation loss decreased (1.212215 --> 1.204108).  Saving model ...
Validation loss decreased (1.204108 --> 1.196514).  Saving model ...
Validation loss decreased (1.196514 --> 1.188847).  Saving model ...
Validation loss decreased (1.188847 --> 1.182169).  Saving model ...
Validation loss decreased (1.182169 --> 1.176609).  Saving model ...
Validation loss decreased (1.176609 --> 1.169472).  Saving model ...
Validation loss decreased (1.169472 --> 1.160543).  Saving model ...
Validation loss decreased (1.160543 --> 1.153618).  Saving model ...
Validation loss decreased (1.153618 --> 1.150015).  Saving model ...
Validation loss decreased (1.150015 --> 1.142527).  Saving model ...
Validation loss decreased (1.142527 --> 1.136717).  Saving model ...
Validation loss decreased (1.136717 --> 1.130705).  Saving model ...
Validation loss decreased (1.130705 --> 1.125099).  Saving model ...
Validation loss decreased (1.125099 --> 1.118561).  Saving model ...
Validation loss decreased (1.118561 --> 1.112850).  Saving model ...
Validation loss decreased (1.112850 --> 1.107457).  Saving model ...
Validation loss decreased (1.107457 --> 1.101188).  Saving model ...
Validation loss decreased (1.101188 --> 1.096245).  Saving model ...
Validation loss decreased (1.096245 --> 1.089482).  Saving model ...
Validation loss decreased (1.089482 --> 1.084521).  Saving model ...
Validation loss decreased (1.084521 --> 1.080842).  Saving model ...
Validation loss decreased (1.080842 --> 1.077157).  Saving model ...
Validation loss decreased (1.077157 --> 1.070641).  Saving model ...
Validation loss decreased (1.070641 --> 1.067801).  Saving model ...
Validation loss decreased (1.067801 --> 1.062962).  Saving model ...
Validation loss decreased (1.062962 --> 1.058363).  Saving model ...
Validation loss decreased (1.058363 --> 1.055083).  Saving model ...
Validation loss decreased (1.055083 --> 1.051385).  Saving model ...
Validation loss decreased (1.051385 --> 1.046976).  Saving model ...
Validation loss decreased (1.046976 --> 1.042256).  Saving model ...
Validation loss decreased (1.042256 --> 1.038547).  Saving model ...
Validation loss decreased (1.038547 --> 1.035891).  Saving model ...
Validation loss decreased (1.035891 --> 1.032136).  Saving model ...
Validation loss decreased (1.032136 --> 1.027868).  Saving model ...
Validation loss decreased (1.027868 --> 1.022805).  Saving model ...
Validation loss decreased (1.022805 --> 1.018666).  Saving model ...
Validation loss decreased (1.018666 --> 1.015557).  Saving model ...
Validation loss decreased (1.015557 --> 1.013660).  Saving model ...
Validation loss decreased (1.013660 --> 1.011612).  Saving model ...
Validation loss decreased (1.011612 --> 1.009910).  Saving model ...
Validation loss decreased (1.009910 --> 1.007439).  Saving model ...
Validation loss decreased (1.007439 --> 1.004911).  Saving model ...
Validation loss decreased (1.004911 --> 1.000839).  Saving model ...
Validation loss decreased (1.000839 --> 0.996835).  Saving model ...
Validation loss decreased (0.996835 --> 0.995760).  Saving model ...
Validation loss decreased (0.995760 --> 0.993640).  Saving model ...
Validation loss decreased (0.993640 --> 0.989923).  Saving model ...
Validation loss decreased (0.989923 --> 0.988132).  Saving model ...
Validation loss decreased (0.988132 --> 0.987282).  Saving model ...
Validation loss decreased (0.987282 --> 0.984426).  Saving model ...
Validation loss decreased (0.984426 --> 0.983128).  Saving model ...
EarlyStopping counter: 1 out of 5.0
Validation loss decreased (0.983128 --> 0.981055).  Saving model ...
Validation loss decreased (0.981055 --> 0.977806).  Saving model ...
Validation loss decreased (0.977806 --> 0.975269).  Saving model ...
Validation loss decreased (0.975269 --> 0.972139).  Saving model ...
EarlyStopping counter: 1 out of 5.0
Validation loss decreased (0.972139 --> 0.971053).  Saving model ...
Validation loss decreased (0.971053 --> 0.966706).  Saving model ...
Validation loss decreased (0.966706 --> 0.964539).  Saving model ...
Validation loss decreased (0.964539 --> 0.962313).  Saving model ...
EarlyStopping counter: 1 out of 5.0
Validation loss decreased (0.962313 --> 0.958884).  Saving model ...
Validation loss decreased (0.958884 --> 0.956808).  Saving model ...
EarlyStopping counter: 1 out of 5.0
EarlyStopping counter: 2 out of 5.0
Validation loss decreased (0.956808 --> 0.954577).  Saving model ...
Validation loss decreased (0.954577 --> 0.952246).  Saving model ...
EarlyStopping counter: 1 out of 5.0
EarlyStopping counter: 2 out of 5.0
EarlyStopping counter: 3 out of 5.0
Validation loss decreased (0.952246 --> 0.951482).  Saving model ...
Validation loss decreased (0.951482 --> 0.949545).  Saving model ...
Validation loss decreased (0.949545 --> 0.947859).  Saving model ...
Validation loss decreased (0.947859 --> 0.947596).  Saving model ...
Validation loss decreased (0.947596 --> 0.946216).  Saving model ...
Validation loss decreased (0.946216 --> 0.943838).  Saving model ...
Validation loss decreased (0.943838 --> 0.943108).  Saving model ...
Validation loss decreased (0.943108 --> 0.942692).  Saving model ...
Validation loss decreased (0.942692 --> 0.942001).  Saving model ...
Validation loss decreased (0.942001 --> 0.941475).  Saving model ...
Validation loss decreased (0.941475 --> 0.941225).  Saving model ...
EarlyStopping counter: 1 out of 5.0
Validation loss decreased (0.941225 --> 0.939077).  Saving model ...
Validation loss decreased (0.939077 --> 0.937178).  Saving model ...
EarlyStopping counter: 1 out of 5.0
EarlyStopping counter: 2 out of 5.0
EarlyStopping counter: 3 out of 5.0
Validation loss decreased (0.937178 --> 0.936289).  Saving model ...
Validation loss decreased (0.936289 --> 0.935321).  Saving model ...
EarlyStopping counter: 1 out of 5.0
Validation loss decreased (0.935321 --> 0.935313).  Saving model ...
Validation loss decreased (0.935313 --> 0.934783).  Saving model ...
EarlyStopping counter: 1 out of 5.0
EarlyStopping counter: 2 out of 5.0
EarlyStopping counter: 3 out of 5.0
EarlyStopping counter: 4 out of 5.0
EarlyStopping counter: 5 out of 5.0
/localscratch/yinan.28869511.0/env/lib/python3.7/site-packages/torch/nn/functional.py:1794: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.
  warnings.warn("nn.functional.tanh is deprecated. Use torch.tanh instead.")
wandb: Waiting for W&B process to finish, PID 25844... (success).
wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: \ 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: | 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: / 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: \ 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: | 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: / 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: \ 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: | 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: / 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb:                                                                                
wandb: Run history:
wandb:     e_F1 ▁▁▃▃▄▅▆▆▆▆▆▆▆▆▇▇▇▇▇▇▇▇▇▇▇██▇████████████
wandb:   e_loss ██▇▇▇▇▇▆▆▅▅▅▄▄▄▃▃▃▃▃▂▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁
wandb:     t_F1 ▁▂▂▃▃▃▃▄▅▅▅▅▆▆▆▆▆▆▆▆▆▆▇▇▇▇▇▇▇█▇▇████████
wandb:   t_loss ████▇▇▇▇▆▆▆▆▅▅▅▄▅▄▄▄▃▃▃▃▃▃▂▂▂▂▂▁▂▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:     e_F1 62.37298
wandb:   e_loss 0.9366
wandb:     t_F1 68.51961
wandb:   t_loss 0.758
wandb: 
wandb: Synced 4 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Synced elderberry-meringue-2: https://wandb.ai/yinanazhou/xl_512_bs_8_lr_1e06_es_5_lc_True_nr_False_sr_False_stem_False_lemma_False_repeat_3_fold_2/runs/265cods1
wandb: Find logs at: ./wandb/run-20220314_024216-265cods1/logs/debug.log
wandb: 

wandb: wandb version 0.12.11 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
2022-03-14 04:03:27.151934: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1
wandb: Tracking run with wandb version 0.12.5
wandb: Syncing run cookie-flambee-2
wandb: ⭐️ View project at https://wandb.ai/yinanazhou/xl_512_bs_8_lr_1e06_es_5_lc_True_nr_False_sr_False_stem_False_lemma_False_repeat_4_fold_1
wandb: 🚀 View run at https://wandb.ai/yinanazhou/xl_512_bs_8_lr_1e06_es_5_lc_True_nr_False_sr_False_stem_False_lemma_False_repeat_4_fold_1/runs/3dv16ux1
wandb: Run data is saved locally in /project/6002780/yinan/Thesis_MER_Lyrics/lyric-emotion/wandb/run-20220314_040324-3dv16ux1
wandb: Run `wandb offline` to turn off syncing.

Validation loss decreased (inf --> 1.481189).  Saving model ...
Validation loss decreased (1.481189 --> 1.446896).  Saving model ...
Validation loss decreased (1.446896 --> 1.422481).  Saving model ...
Validation loss decreased (1.422481 --> 1.404909).  Saving model ...
Validation loss decreased (1.404909 --> 1.390742).  Saving model ...
Validation loss decreased (1.390742 --> 1.380547).  Saving model ...
Validation loss decreased (1.380547 --> 1.373017).  Saving model ...
Validation loss decreased (1.373017 --> 1.366671).  Saving model ...
Validation loss decreased (1.366671 --> 1.360928).  Saving model ...
Validation loss decreased (1.360928 --> 1.355648).  Saving model ...
Validation loss decreased (1.355648 --> 1.350764).  Saving model ...
Validation loss decreased (1.350764 --> 1.345866).  Saving model ...
Validation loss decreased (1.345866 --> 1.340978).  Saving model ...
Validation loss decreased (1.340978 --> 1.335885).  Saving model ...
Validation loss decreased (1.335885 --> 1.330244).  Saving model ...
Validation loss decreased (1.330244 --> 1.325036).  Saving model ...
Validation loss decreased (1.325036 --> 1.319782).  Saving model ...
Validation loss decreased (1.319782 --> 1.314551).  Saving model ...
Validation loss decreased (1.314551 --> 1.308996).  Saving model ...
Validation loss decreased (1.308996 --> 1.303520).  Saving model ...
Validation loss decreased (1.303520 --> 1.297376).  Saving model ...
Validation loss decreased (1.297376 --> 1.291573).  Saving model ...
Validation loss decreased (1.291573 --> 1.285464).  Saving model ...
Validation loss decreased (1.285464 --> 1.279117).  Saving model ...
Validation loss decreased (1.279117 --> 1.272709).  Saving model ...
Validation loss decreased (1.272709 --> 1.265413).  Saving model ...
Validation loss decreased (1.265413 --> 1.259085).  Saving model ...
Validation loss decreased (1.259085 --> 1.251734).  Saving model ...
Validation loss decreased (1.251734 --> 1.244955).  Saving model ...
Validation loss decreased (1.244955 --> 1.237691).  Saving model ...
Validation loss decreased (1.237691 --> 1.231195).  Saving model ...
Validation loss decreased (1.231195 --> 1.224771).  Saving model ...
Validation loss decreased (1.224771 --> 1.217688).  Saving model ...
Validation loss decreased (1.217688 --> 1.210891).  Saving model ...
Validation loss decreased (1.210891 --> 1.204824).  Saving model ...
Validation loss decreased (1.204824 --> 1.197350).  Saving model ...
Validation loss decreased (1.197350 --> 1.189776).  Saving model ...
Validation loss decreased (1.189776 --> 1.183605).  Saving model ...
Validation loss decreased (1.183605 --> 1.176479).  Saving model ...
Validation loss decreased (1.176479 --> 1.169781).  Saving model ...
Validation loss decreased (1.169781 --> 1.164000).  Saving model ...
Validation loss decreased (1.164000 --> 1.158771).  Saving model ...
Validation loss decreased (1.158771 --> 1.153446).  Saving model ...
Validation loss decreased (1.153446 --> 1.146586).  Saving model ...
Validation loss decreased (1.146586 --> 1.140851).  Saving model ...
Validation loss decreased (1.140851 --> 1.135680).  Saving model ...
Validation loss decreased (1.135680 --> 1.130185).  Saving model ...
Validation loss decreased (1.130185 --> 1.125538).  Saving model ...
Validation loss decreased (1.125538 --> 1.120714).  Saving model ...
Validation loss decreased (1.120714 --> 1.115512).  Saving model ...
Validation loss decreased (1.115512 --> 1.110424).  Saving model ...
Validation loss decreased (1.110424 --> 1.106074).  Saving model ...
Validation loss decreased (1.106074 --> 1.101750).  Saving model ...
Validation loss decreased (1.101750 --> 1.098104).  Saving model ...
Validation loss decreased (1.098104 --> 1.093702).  Saving model ...
Validation loss decreased (1.093702 --> 1.088387).  Saving model ...
Validation loss decreased (1.088387 --> 1.085041).  Saving model ...
Validation loss decreased (1.085041 --> 1.081657).  Saving model ...
Validation loss decreased (1.081657 --> 1.078416).  Saving model ...
Validation loss decreased (1.078416 --> 1.073250).  Saving model ...
Validation loss decreased (1.073250 --> 1.069301).  Saving model ...
Validation loss decreased (1.069301 --> 1.066328).  Saving model ...
Validation loss decreased (1.066328 --> 1.064301).  Saving model ...
Validation loss decreased (1.064301 --> 1.060185).  Saving model ...
Validation loss decreased (1.060185 --> 1.057849).  Saving model ...
Validation loss decreased (1.057849 --> 1.054011).  Saving model ...
Validation loss decreased (1.054011 --> 1.050389).  Saving model ...
Validation loss decreased (1.050389 --> 1.048552).  Saving model ...
Validation loss decreased (1.048552 --> 1.043961).  Saving model ...
Validation loss decreased (1.043961 --> 1.039823).  Saving model ...
Validation loss decreased (1.039823 --> 1.036731).  Saving model ...
Validation loss decreased (1.036731 --> 1.035121).  Saving model ...
Validation loss decreased (1.035121 --> 1.032568).  Saving model ...
Validation loss decreased (1.032568 --> 1.030652).  Saving model ...
Validation loss decreased (1.030652 --> 1.028857).  Saving model ...
Validation loss decreased (1.028857 --> 1.025350).  Saving model ...
Validation loss decreased (1.025350 --> 1.022776).  Saving model ...
Validation loss decreased (1.022776 --> 1.020049).  Saving model ...
Validation loss decreased (1.020049 --> 1.017396).  Saving model ...
Validation loss decreased (1.017396 --> 1.015134).  Saving model ...
Validation loss decreased (1.015134 --> 1.013628).  Saving model ...
Validation loss decreased (1.013628 --> 1.010825).  Saving model ...
Validation loss decreased (1.010825 --> 1.009711).  Saving model ...
Validation loss decreased (1.009711 --> 1.006029).  Saving model ...
Validation loss decreased (1.006029 --> 1.004481).  Saving model ...
Validation loss decreased (1.004481 --> 1.003280).  Saving model ...
Validation loss decreased (1.003280 --> 1.000967).  Saving model ...
Validation loss decreased (1.000967 --> 0.998272).  Saving model ...
Validation loss decreased (0.998272 --> 0.998259).  Saving model ...
Validation loss decreased (0.998259 --> 0.996334).  Saving model ...
Validation loss decreased (0.996334 --> 0.995012).  Saving model ...
Validation loss decreased (0.995012 --> 0.991286).  Saving model ...
Validation loss decreased (0.991286 --> 0.990868).  Saving model ...
Validation loss decreased (0.990868 --> 0.990697).  Saving model ...
Validation loss decreased (0.990697 --> 0.987901).  Saving model ...
Validation loss decreased (0.987901 --> 0.987049).  Saving model ...
Validation loss decreased (0.987049 --> 0.985904).  Saving model ...
Validation loss decreased (0.985904 --> 0.984932).  Saving model ...
Validation loss decreased (0.984932 --> 0.984010).  Saving model ...
Validation loss decreased (0.984010 --> 0.982245).  Saving model ...
Validation loss decreased (0.982245 --> 0.980968).  Saving model ...
Validation loss decreased (0.980968 --> 0.979280).  Saving model ...
Validation loss decreased (0.979280 --> 0.979059).  Saving model ...
Validation loss decreased (0.979059 --> 0.976383).  Saving model ...
Validation loss decreased (0.976383 --> 0.975968).  Saving model ...
Validation loss decreased (0.975968 --> 0.973145).  Saving model ...
Validation loss decreased (0.973145 --> 0.970849).  Saving model ...
EarlyStopping counter: 1 out of 5.0
EarlyStopping counter: 2 out of 5.0
Validation loss decreased (0.970849 --> 0.970168).  Saving model ...
Validation loss decreased (0.970168 --> 0.967085).  Saving model ...
Validation loss decreased (0.967085 --> 0.966855).  Saving model ...
Validation loss decreased (0.966855 --> 0.965906).  Saving model ...
Validation loss decreased (0.965906 --> 0.963374).  Saving model ...
Validation loss decreased (0.963374 --> 0.962828).  Saving model ...
Validation loss decreased (0.962828 --> 0.962517).  Saving model ...
Validation loss decreased (0.962517 --> 0.962300).  Saving model ...
EarlyStopping counter: 1 out of 5.0
Validation loss decreased (0.962300 --> 0.961330).  Saving model ...
Validation loss decreased (0.961330 --> 0.960849).  Saving model ...
EarlyStopping counter: 1 out of 5.0
EarlyStopping counter: 2 out of 5.0
Validation loss decreased (0.960849 --> 0.959141).  Saving model ...
Validation loss decreased (0.959141 --> 0.956968).  Saving model ...
EarlyStopping counter: 1 out of 5.0
Validation loss decreased (0.956968 --> 0.955757).  Saving model ...
EarlyStopping counter: 1 out of 5.0
EarlyStopping counter: 2 out of 5.0
EarlyStopping counter: 3 out of 5.0
EarlyStopping counter: 4 out of 5.0
EarlyStopping counter: 5 out of 5.0
/localscratch/yinan.28869511.0/env/lib/python3.7/site-packages/torch/nn/functional.py:1794: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.
  warnings.warn("nn.functional.tanh is deprecated. Use torch.tanh instead.")
wandb: Waiting for W&B process to finish, PID 30239... (success).
wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: \ 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: | 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: / 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: \ 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: | 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: / 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: \ 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: | 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb:                                                                                
wandb: Run history:
wandb:     e_F1 ▁▁▃▄▄▅▅▅▆▆▆▆▆▇▇▇▇▇▇▇▇█▇█████████████████
wandb:   e_loss █▇▇▇▆▆▆▆▅▅▅▄▄▄▄▃▃▃▃▂▂▂▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁
wandb:     t_F1 ▁▂▃▃▄▄▃▄▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇▇▇▇▇▇▇▇███▇█████
wandb:   t_loss █▇▇▇▇▇▆▆▆▆▅▅▅▅▄▄▄▄▃▃▃▃▃▃▃▂▂▂▂▂▂▂▂▁▂▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:     e_F1 58.9
wandb:   e_loss 0.95651
wandb:     t_F1 69.84402
wandb:   t_loss 0.75945
wandb: 
wandb: Synced 4 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Synced cookie-flambee-2: https://wandb.ai/yinanazhou/xl_512_bs_8_lr_1e06_es_5_lc_True_nr_False_sr_False_stem_False_lemma_False_repeat_4_fold_1/runs/3dv16ux1
wandb: Find logs at: ./wandb/run-20220314_040324-3dv16ux1/logs/debug.log
wandb: 

wandb: wandb version 0.12.11 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
2022-03-14 05:28:54.226134: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1
wandb: Tracking run with wandb version 0.12.5
wandb: Syncing run neapolitan-cobbler-2
wandb: ⭐️ View project at https://wandb.ai/yinanazhou/xl_512_bs_8_lr_1e06_es_5_lc_True_nr_False_sr_False_stem_False_lemma_False_repeat_4_fold_2
wandb: 🚀 View run at https://wandb.ai/yinanazhou/xl_512_bs_8_lr_1e06_es_5_lc_True_nr_False_sr_False_stem_False_lemma_False_repeat_4_fold_2/runs/29gi1s36
wandb: Run data is saved locally in /project/6002780/yinan/Thesis_MER_Lyrics/lyric-emotion/wandb/run-20220314_052851-29gi1s36
wandb: Run `wandb offline` to turn off syncing.
slurmstepd: error: *** JOB 28869511 ON cdr2618 CANCELLED AT 2022-03-14T05:42:25 DUE TO TIME LIMIT ***
