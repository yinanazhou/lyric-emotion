Unloading StdEnv/2020

Due to MODULEPATH changes, the following have been reloaded:
  1) mii/1.1.1


The following have been reloaded with a version change:
  1) python/3.8.2 => python/3.7.4

Using base prefix '/cvmfs/soft.computecanada.ca/easybuild/software/2017/Core/python/3.7.4'
New python executable in /localscratch/yinan.28944956.0/env/bin/python
Installing setuptools, pip, wheel...
done.
Ignoring pip: markers 'python_version < "3"' don't match your environment
Looking in links: /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/nix/avx2, /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/nix/generic, /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic
Collecting pip
Installing collected packages: pip
  Found existing installation: pip 19.1.1
    Uninstalling pip-19.1.1:
      Successfully uninstalled pip-19.1.1
Successfully installed pip-21.2.3+computecanada
Looking in links: /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/nix/avx2, /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/nix/generic, /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/keras-2.8.0+computecanada-py2.py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/Keras_Preprocessing-1.1.2+computecanada-py3-none-any.whl
Requirement already satisfied: matplotlib in /cvmfs/soft.computecanada.ca/easybuild/software/2017/Core/scipy-stack/2019a/lib/python3.7/site-packages (from -r requirements.txt (line 3)) (3.0.2)
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/nltk-3.6.5+computecanada-py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/scikit_learn-0.22.1+computecanada-cp37-cp37m-linux_x86_64.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/tensorboard-2.3.0+computecanada-py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/tensorboard_plugin_wit-1.7.0+computecanada-py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/tensorflow_gpu-2.3.0+computecanada-cp37-cp37m-linux_x86_64.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/tensorflow_estimator-2.3.0+computecanada-py2.py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/tokenizers-0.5.2+computecanada-cp37-cp37m-linux_x86_64.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/nix/avx2/torch-1.4.0+computecanada-cp37-cp37m-linux_x86_64.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/torchtext-0.6.0+computecanada-py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/torchvision-0.8.2+computecanada-cp37-cp37m-linux_x86_64.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/transformers-2.5.1+computecanada-py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/urllib3-1.26.7+computecanada-py2.py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/tqdm-4.63.0+computecanada-py2.py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/joblib-1.1.0+computecanada-py2.py3-none-any.whl
ERROR: Could not find a version that satisfies the requirement regex>=2021.8.3 (from nltk) (from versions: 2018.1.10+computecanada, 2019.11.1+computecanada, 2020.11.13+computecanada)
ERROR: No matching distribution found for regex>=2021.8.3
Looking in links: /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/nix/avx2, /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/nix/generic, /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic
ERROR: Could not find a version that satisfies the requirement numpy==1.20.0+computacanada (from versions: 1.15.0+computecanada, 1.15.2+computecanada, 1.15.4+computecanada, 1.16.0+computecanada, 1.16.2+computecanada, 1.16.3+computecanada, 1.17.4+computecanada, 1.18.1+computecanada, 1.18.4+computecanada, 1.19.1+computecanada, 1.19.2+computecanada, 1.20.2+computecanada)
ERROR: No matching distribution found for numpy==1.20.0+computacanada
Looking in links: /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/nix/avx2, /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/nix/generic, /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/wandb-0.12.5+computecanada-py2.py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/yaspin-2.1.0+computecanada-py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/subprocess32-3.5.4+computecanada-py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/promise-2.3+computecanada-py3-none-any.whl
Requirement already satisfied: requests<3,>=2.0.0 in /cvmfs/soft.computecanada.ca/easybuild/software/2017/Core/scipy-stack/2019a/lib/python3.7/site-packages (from wandb) (2.21.0)
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/GitPython-3.1.24+computecanada-py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/docker_pycreds-0.4.0+computecanada-py2.py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/six-1.16.0+computecanada-py2.py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/protobuf-3.19.4+computecanada-py2.py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/pathtools-0.1.2+computecanada-py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/sentry_sdk-1.5.0+computecanada-py2.py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/click-8.0.3+computecanada-py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/PyYAML-5.3.1+computecanada-cp37-cp37m-linux_x86_64.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/psutil-5.7.3+computecanada-cp37-cp37m-linux_x86_64.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/shortuuid-1.0.1+computecanada-py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/configparser-5.0.2+computecanada-py3-none-any.whl
Requirement already satisfied: python-dateutil>=2.6.1 in /cvmfs/soft.computecanada.ca/easybuild/software/2017/Core/scipy-stack/2019a/lib/python3.7/site-packages (from wandb) (2.7.5)
Requirement already satisfied: importlib-metadata in /cvmfs/soft.computecanada.ca/easybuild/software/2017/Core/scipy-stack/2019a/lib/python3.7/site-packages (from Click!=8.0.0,>=7.0->wandb) (0.8)
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/typing_extensions-4.0.1+computecanada-py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/gitdb-4.0.9+computecanada-py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/smmap-5.0.0+computecanada-py3-none-any.whl
Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /cvmfs/soft.computecanada.ca/easybuild/software/2017/Core/scipy-stack/2019a/lib/python3.7/site-packages (from requests<3,>=2.0.0->wandb) (3.0.4)
Requirement already satisfied: certifi>=2017.4.17 in /cvmfs/soft.computecanada.ca/easybuild/software/2017/Core/scipy-stack/2019a/lib/python3.7/site-packages (from requests<3,>=2.0.0->wandb) (2018.11.29)
Requirement already satisfied: idna<2.9,>=2.5 in /cvmfs/soft.computecanada.ca/easybuild/software/2017/Core/scipy-stack/2019a/lib/python3.7/site-packages (from requests<3,>=2.0.0->wandb) (2.8)
Requirement already satisfied: urllib3<1.25,>=1.21.1 in /cvmfs/soft.computecanada.ca/easybuild/software/2017/Core/scipy-stack/2019a/lib/python3.7/site-packages (from requests<3,>=2.0.0->wandb) (1.24.1)
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/termcolor-1.1.0+computecanada-py3-none-any.whl
Requirement already satisfied: zipp>=0.3.2 in /cvmfs/soft.computecanada.ca/easybuild/software/2017/Core/scipy-stack/2019a/lib/python3.7/site-packages (from importlib-metadata->Click!=8.0.0,>=7.0->wandb) (0.3.3)
Installing collected packages: smmap, typing-extensions, termcolor, six, gitdb, yaspin, subprocess32, shortuuid, sentry-sdk, PyYAML, psutil, protobuf, promise, pathtools, GitPython, docker-pycreds, configparser, Click, wandb
  Attempting uninstall: six
    Found existing installation: six 1.12.0
    Not uninstalling six at /cvmfs/soft.computecanada.ca/easybuild/software/2017/Core/scipy-stack/2019a/lib/python3.7/site-packages, outside environment /localscratch/yinan.28944956.0/env
    Can't uninstall 'six'. No files were found to uninstall.
Successfully installed Click-8.0.3+computecanada GitPython-3.1.24+computecanada PyYAML-5.3.1+computecanada configparser-5.0.2+computecanada docker-pycreds-0.4.0+computecanada gitdb-4.0.9+computecanada pathtools-0.1.2+computecanada promise-2.3+computecanada protobuf-3.19.4+computecanada psutil-5.7.3+computecanada sentry-sdk-1.5.0+computecanada shortuuid-1.0.1+computecanada six-1.16.0+computecanada smmap-5.0.0+computecanada subprocess32-3.5.4+computecanada termcolor-1.1.0+computecanada typing-extensions-4.0.1+computecanada wandb-0.12.5+computecanada yaspin-2.1.0+computecanada
Looking in links: /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/nix/avx2, /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/nix/generic, /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic
ERROR: Could not find a version that satisfies the requirement sagemaker (from versions: none)
ERROR: No matching distribution found for sagemaker
Looking in links: /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/nix/avx2, /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/nix/generic, /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/torch-1.9.1+computecanada-cp37-cp37m-linux_x86_64.whl
Requirement already satisfied: typing-extensions in /localscratch/yinan.28944956.0/env/lib/python3.7/site-packages (from torch) (4.0.1+computecanada)
Installing collected packages: torch
Successfully installed torch-1.9.1+computecanada
Looking in links: /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/nix/avx2, /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/nix/generic, /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/transformers-2.5.1+computecanada-py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/regex-2020.11.13+computecanada-cp37-cp37m-linux_x86_64.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/tokenizers-0.5.2+computecanada-cp37-cp37m-linux_x86_64.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/sentencepiece-0.1.91+computecanada-cp37-cp37m-linux_x86_64.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/filelock-3.4.2+computecanada-py3-none-any.whl
Requirement already satisfied: requests in /cvmfs/soft.computecanada.ca/easybuild/software/2017/Core/scipy-stack/2019a/lib/python3.7/site-packages (from transformers==2.5.1+computecanada) (2.21.0)
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/tqdm-4.63.0+computecanada-py2.py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/boto3-1.20.52+computecanada-py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/sacremoses-0.0.46+computecanada-py3-none-any.whl
Requirement already satisfied: numpy in /cvmfs/soft.computecanada.ca/easybuild/software/2017/Core/scipy-stack/2019a/lib/python3.7/site-packages (from transformers==2.5.1+computecanada) (1.16.0)
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/s3transfer-0.5.1+computecanada-py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/jmespath-0.10.0+computecanada-py2.py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/botocore-1.23.52+computecanada-py3-none-any.whl
Requirement already satisfied: python-dateutil<3.0.0,>=2.1 in /cvmfs/soft.computecanada.ca/easybuild/software/2017/Core/scipy-stack/2019a/lib/python3.7/site-packages (from botocore<1.24.0,>=1.23.52->boto3->transformers==2.5.1+computecanada) (2.7.5)
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/urllib3-1.26.8+computecanada-py2.py3-none-any.whl
Requirement already satisfied: six>=1.5 in /localscratch/yinan.28944956.0/env/lib/python3.7/site-packages (from python-dateutil<3.0.0,>=2.1->botocore<1.24.0,>=1.23.52->boto3->transformers==2.5.1+computecanada) (1.16.0+computecanada)
Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /cvmfs/soft.computecanada.ca/easybuild/software/2017/Core/scipy-stack/2019a/lib/python3.7/site-packages (from requests->transformers==2.5.1+computecanada) (3.0.4)
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/requests-2.27.1+computecanada-py2.py3-none-any.whl
Requirement already satisfied: idna<4,>=2.5 in /cvmfs/soft.computecanada.ca/easybuild/software/2017/Core/scipy-stack/2019a/lib/python3.7/site-packages (from requests->transformers==2.5.1+computecanada) (2.8)
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/charset_normalizer-2.0.11+computecanada-py3-none-any.whl
Requirement already satisfied: certifi>=2017.4.17 in /cvmfs/soft.computecanada.ca/easybuild/software/2017/Core/scipy-stack/2019a/lib/python3.7/site-packages (from requests->transformers==2.5.1+computecanada) (2018.11.29)
Requirement already satisfied: click in /localscratch/yinan.28944956.0/env/lib/python3.7/site-packages (from sacremoses->transformers==2.5.1+computecanada) (8.0.3+computecanada)
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/joblib-1.1.0+computecanada-py2.py3-none-any.whl
Requirement already satisfied: importlib-metadata in /cvmfs/soft.computecanada.ca/easybuild/software/2017/Core/scipy-stack/2019a/lib/python3.7/site-packages (from click->sacremoses->transformers==2.5.1+computecanada) (0.8)
Requirement already satisfied: zipp>=0.3.2 in /cvmfs/soft.computecanada.ca/easybuild/software/2017/Core/scipy-stack/2019a/lib/python3.7/site-packages (from importlib-metadata->click->sacremoses->transformers==2.5.1+computecanada) (0.3.3)
Installing collected packages: urllib3, jmespath, botocore, tqdm, s3transfer, regex, joblib, charset-normalizer, tokenizers, sentencepiece, sacremoses, requests, filelock, boto3, transformers
  Attempting uninstall: urllib3
    Found existing installation: urllib3 1.24.1
    Not uninstalling urllib3 at /cvmfs/soft.computecanada.ca/easybuild/software/2017/Core/scipy-stack/2019a/lib/python3.7/site-packages, outside environment /localscratch/yinan.28944956.0/env
    Can't uninstall 'urllib3'. No files were found to uninstall.
  Attempting uninstall: requests
    Found existing installation: requests 2.21.0
    Not uninstalling requests at /cvmfs/soft.computecanada.ca/easybuild/software/2017/Core/scipy-stack/2019a/lib/python3.7/site-packages, outside environment /localscratch/yinan.28944956.0/env
    Can't uninstall 'requests'. No files were found to uninstall.
Successfully installed boto3-1.20.52+computecanada botocore-1.23.52+computecanada charset-normalizer-2.0.11+computecanada filelock-3.4.2+computecanada jmespath-0.10.0+computecanada joblib-1.1.0+computecanada regex-2020.11.13+computecanada requests-2.27.1+computecanada s3transfer-0.5.1+computecanada sacremoses-0.0.46+computecanada sentencepiece-0.1.91+computecanada tokenizers-0.5.2+computecanada tqdm-4.63.0+computecanada transformers-2.5.1+computecanada urllib3-1.26.8+computecanada
Looking in links: /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/nix/avx2, /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/nix/generic, /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/tensorflow_gpu-2.3.0+computecanada-cp37-cp37m-linux_x86_64.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/google_pasta-0.2.0+computecanada-py3-none-any.whl
Requirement already satisfied: termcolor>=1.1.0 in /localscratch/yinan.28944956.0/env/lib/python3.7/site-packages (from tensorflow_gpu==2.3.0+computecanada) (1.1.0+computecanada)
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/astunparse-1.6.3+computecanada-py2.py3-none-any.whl
Requirement already satisfied: numpy<1.19.0,>=1.16.0 in /cvmfs/soft.computecanada.ca/easybuild/software/2017/Core/scipy-stack/2019a/lib/python3.7/site-packages (from tensorflow_gpu==2.3.0+computecanada) (1.16.0)
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/wrapt-1.11.2+computecanada-cp37-cp37m-linux_x86_64.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/tensorboard-2.8.0+computecanada-py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/gast-0.3.3+computecanada-py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/grpcio-1.38.0+computecanada-cp37-cp37m-linux_x86_64.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/opt_einsum-3.3.0+computecanada-py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/tensorflow_estimator-2.3.0+computecanada-py2.py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/absl_py-1.0.0+computecanada-py3-none-any.whl
Requirement already satisfied: protobuf>=3.9.2 in /localscratch/yinan.28944956.0/env/lib/python3.7/site-packages (from tensorflow_gpu==2.3.0+computecanada) (3.19.4+computecanada)
Requirement already satisfied: wheel>=0.26 in /localscratch/yinan.28944956.0/env/lib/python3.7/site-packages (from tensorflow_gpu==2.3.0+computecanada) (0.33.4)
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/Keras_Preprocessing-1.1.2+computecanada-py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/nix/avx2/h5py-2.10.0+computecanada-cp37-cp37m-linux_x86_64.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/nix/generic/scipy-1.4.1+computecanada-cp37-cp37m-linux_x86_64.whl
Requirement already satisfied: six>=1.12.0 in /localscratch/yinan.28944956.0/env/lib/python3.7/site-packages (from tensorflow_gpu==2.3.0+computecanada) (1.16.0+computecanada)
Requirement already satisfied: setuptools>=41.0.0 in /localscratch/yinan.28944956.0/env/lib/python3.7/site-packages (from tensorboard<3,>=2.3.0->tensorflow_gpu==2.3.0+computecanada) (41.0.1)
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/tensorboard_data_server-0.6.1+computecanada-py3-none-linux_x86_64.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/Werkzeug-2.0.3+computecanada-py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/google_auth-2.3.3+computecanada-py2.py3-none-any.whl
Requirement already satisfied: requests<3,>=2.21.0 in /localscratch/yinan.28944956.0/env/lib/python3.7/site-packages (from tensorboard<3,>=2.3.0->tensorflow_gpu==2.3.0+computecanada) (2.27.1+computecanada)
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/tensorboard_plugin_wit-1.8.0+computecanada-py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/google_auth_oauthlib-0.4.6+computecanada-py2.py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/Markdown-3.3.6+computecanada-py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/pyasn1_modules-0.2.8+computecanada-py2.py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/rsa-4.8+computecanada-py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/cachetools-4.2.4+computecanada-py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/requests_oauthlib-1.3.0+computecanada-py2.py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/importlib_metadata-4.10.1+computecanada-py3-none-any.whl
Requirement already satisfied: typing-extensions>=3.6.4 in /localscratch/yinan.28944956.0/env/lib/python3.7/site-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard<3,>=2.3.0->tensorflow_gpu==2.3.0+computecanada) (4.0.1+computecanada)
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/zipp-3.7.0+computecanada-py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/pyasn1-0.4.8+computecanada-py2.py3-none-any.whl
Requirement already satisfied: charset-normalizer~=2.0.0 in /localscratch/yinan.28944956.0/env/lib/python3.7/site-packages (from requests<3,>=2.21.0->tensorboard<3,>=2.3.0->tensorflow_gpu==2.3.0+computecanada) (2.0.11+computecanada)
Requirement already satisfied: idna<4,>=2.5 in /cvmfs/soft.computecanada.ca/easybuild/software/2017/Core/scipy-stack/2019a/lib/python3.7/site-packages (from requests<3,>=2.21.0->tensorboard<3,>=2.3.0->tensorflow_gpu==2.3.0+computecanada) (2.8)
Requirement already satisfied: urllib3<1.27,>=1.21.1 in /localscratch/yinan.28944956.0/env/lib/python3.7/site-packages (from requests<3,>=2.21.0->tensorboard<3,>=2.3.0->tensorflow_gpu==2.3.0+computecanada) (1.26.8+computecanada)
Requirement already satisfied: certifi>=2017.4.17 in /cvmfs/soft.computecanada.ca/easybuild/software/2017/Core/scipy-stack/2019a/lib/python3.7/site-packages (from requests<3,>=2.21.0->tensorboard<3,>=2.3.0->tensorflow_gpu==2.3.0+computecanada) (2018.11.29)
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/oauthlib-3.1.1+computecanada-py2.py3-none-any.whl
Installing collected packages: pyasn1, zipp, rsa, pyasn1-modules, oauthlib, cachetools, requests-oauthlib, importlib-metadata, google-auth, werkzeug, tensorboard-plugin-wit, tensorboard-data-server, markdown, grpcio, google-auth-oauthlib, absl-py, wrapt, tensorflow-estimator, tensorboard, scipy, opt-einsum, keras-preprocessing, h5py, google-pasta, gast, astunparse, tensorflow-gpu
  Attempting uninstall: pyasn1
    Found existing installation: pyasn1 0.4.3
    Not uninstalling pyasn1 at /cvmfs/soft.computecanada.ca/easybuild/software/2017/Core/scipy-stack/2019a/lib/python3.7/site-packages, outside environment /localscratch/yinan.28944956.0/env
    Can't uninstall 'pyasn1'. No files were found to uninstall.
  Attempting uninstall: zipp
    Found existing installation: zipp 0.3.3
    Not uninstalling zipp at /cvmfs/soft.computecanada.ca/easybuild/software/2017/Core/scipy-stack/2019a/lib/python3.7/site-packages, outside environment /localscratch/yinan.28944956.0/env
    Can't uninstall 'zipp'. No files were found to uninstall.
  Attempting uninstall: importlib-metadata
    Found existing installation: importlib-metadata 0.8
    Not uninstalling importlib-metadata at /cvmfs/soft.computecanada.ca/easybuild/software/2017/Core/scipy-stack/2019a/lib/python3.7/site-packages, outside environment /localscratch/yinan.28944956.0/env
    Can't uninstall 'importlib-metadata'. No files were found to uninstall.
  Attempting uninstall: scipy
    Found existing installation: scipy 1.2.0
    Not uninstalling scipy at /cvmfs/soft.computecanada.ca/easybuild/software/2017/Core/scipy-stack/2019a/lib/python3.7/site-packages, outside environment /localscratch/yinan.28944956.0/env
    Can't uninstall 'scipy'. No files were found to uninstall.
Successfully installed absl-py-1.0.0+computecanada astunparse-1.6.3+computecanada cachetools-4.2.4+computecanada gast-0.3.3+computecanada google-auth-2.3.3+computecanada google-auth-oauthlib-0.4.6+computecanada google-pasta-0.2.0+computecanada grpcio-1.38.0+computecanada h5py-2.10.0+computecanada importlib-metadata-4.10.1+computecanada keras-preprocessing-1.1.2+computecanada markdown-3.3.6+computecanada oauthlib-3.1.1+computecanada opt-einsum-3.3.0+computecanada pyasn1-0.4.8+computecanada pyasn1-modules-0.2.8+computecanada requests-oauthlib-1.3.0+computecanada rsa-4.8+computecanada scipy-1.4.1+computecanada tensorboard-2.8.0+computecanada tensorboard-data-server-0.6.1+computecanada tensorboard-plugin-wit-1.8.0+computecanada tensorflow-estimator-2.3.0+computecanada tensorflow-gpu-2.3.0+computecanada werkzeug-2.0.3+computecanada wrapt-1.11.2+computecanada zipp-3.7.0+computecanada
Looking in links: /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/nix/avx2, /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/nix/generic, /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/keras-2.8.0+computecanada-py2.py3-none-any.whl
Installing collected packages: Keras
Successfully installed Keras-2.8.0+computecanada
Looking in links: /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/nix/avx2, /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/nix/generic, /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/urllib3-1.26.7+computecanada-py2.py3-none-any.whl
Installing collected packages: urllib3
  Attempting uninstall: urllib3
    Found existing installation: urllib3 1.26.8+computecanada
    Uninstalling urllib3-1.26.8+computecanada:
      Successfully uninstalled urllib3-1.26.8+computecanada
Successfully installed urllib3-1.26.7+computecanada
Looking in links: /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/nix/avx2, /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/nix/generic, /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/nltk-3.7+computecanada-py3-none-any.whl
Requirement already satisfied: tqdm in /localscratch/yinan.28944956.0/env/lib/python3.7/site-packages (from nltk) (4.63.0+computecanada)
Requirement already satisfied: click in /localscratch/yinan.28944956.0/env/lib/python3.7/site-packages (from nltk) (8.0.3+computecanada)
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/nltk-3.6.5+computecanada-py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/nltk-3.6.3+computecanada-py3-none-any.whl
Requirement already satisfied: joblib in /localscratch/yinan.28944956.0/env/lib/python3.7/site-packages (from nltk) (1.1.0+computecanada)
Requirement already satisfied: regex in /localscratch/yinan.28944956.0/env/lib/python3.7/site-packages (from nltk) (2020.11.13+computecanada)
Requirement already satisfied: importlib-metadata in /localscratch/yinan.28944956.0/env/lib/python3.7/site-packages (from click->nltk) (4.10.1+computecanada)
Requirement already satisfied: typing-extensions>=3.6.4 in /localscratch/yinan.28944956.0/env/lib/python3.7/site-packages (from importlib-metadata->click->nltk) (4.0.1+computecanada)
Requirement already satisfied: zipp>=0.5 in /localscratch/yinan.28944956.0/env/lib/python3.7/site-packages (from importlib-metadata->click->nltk) (3.7.0+computecanada)
Installing collected packages: nltk
Successfully installed nltk-3.6.3+computecanada
Looking in links: /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/nix/avx2, /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/nix/generic, /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/scikit_learn-0.22.1+computecanada-cp37-cp37m-linux_x86_64.whl
Requirement already satisfied: joblib>=0.11 in /localscratch/yinan.28944956.0/env/lib/python3.7/site-packages (from scikit-learn==0.22.1) (1.1.0+computecanada)
Requirement already satisfied: scipy>=0.17.0 in /localscratch/yinan.28944956.0/env/lib/python3.7/site-packages (from scikit-learn==0.22.1) (1.4.1+computecanada)
Requirement already satisfied: numpy>=1.11.0 in /cvmfs/soft.computecanada.ca/easybuild/software/2017/Core/scipy-stack/2019a/lib/python3.7/site-packages (from scikit-learn==0.22.1) (1.16.0)
Installing collected packages: scikit-learn
Successfully installed scikit-learn-0.22.1+computecanada
Looking in links: /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/nix/avx2, /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/nix/generic, /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic
Requirement already satisfied: tokenizers==0.5.2 in /localscratch/yinan.28944956.0/env/lib/python3.7/site-packages (0.5.2+computecanada)
wandb: Appending key for api.wandb.ai to your netrc file: /home/yinan/.netrc
Starting Task
2022-03-14 23:08:57.459306: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1
[nltk_data] Downloading package stopwords to /home/yinan/nltk_data...
[nltk_data]   Package stopwords is already up-to-date!
[nltk_data] Downloading package wordnet to /home/yinan/nltk_data...
[nltk_data]   Package wordnet is already up-to-date!
wandb: Currently logged in as: yinanazhou (use `wandb login --relogin` to force relogin)
wandb: wandb version 0.12.11 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
2022-03-14 23:09:11.627700: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1
wandb: Tracking run with wandb version 0.12.5
wandb: Syncing run absurd-dream-2
wandb: â­ï¸ View project at https://wandb.ai/yinanazhou/xl_512_bs_8_lr_1e06_es_10_lc_True_nr_False_sr_False_stem_False_lemma_True_repeat_1_fold_1
wandb: ðŸš€ View run at https://wandb.ai/yinanazhou/xl_512_bs_8_lr_1e06_es_10_lc_True_nr_False_sr_False_stem_False_lemma_True_repeat_1_fold_1/runs/2bl09n18
wandb: Run data is saved locally in /project/6002780/yinan/Thesis_MER_Lyrics/lyric-emotion/wandb/run-20220314_230909-2bl09n18
wandb: Run `wandb offline` to turn off syncing.

Validation loss decreased (inf --> 1.433387).  Saving model ...
Validation loss decreased (1.433387 --> 1.413981).  Saving model ...
Validation loss decreased (1.413981 --> 1.397822).  Saving model ...
Validation loss decreased (1.397822 --> 1.384927).  Saving model ...
Validation loss decreased (1.384927 --> 1.374721).  Saving model ...
Validation loss decreased (1.374721 --> 1.365957).  Saving model ...
Validation loss decreased (1.365957 --> 1.358616).  Saving model ...
Validation loss decreased (1.358616 --> 1.352624).  Saving model ...
Validation loss decreased (1.352624 --> 1.347371).  Saving model ...
Validation loss decreased (1.347371 --> 1.341487).  Saving model ...
Validation loss decreased (1.341487 --> 1.335491).  Saving model ...
Validation loss decreased (1.335491 --> 1.330084).  Saving model ...
Validation loss decreased (1.330084 --> 1.324555).  Saving model ...
Validation loss decreased (1.324555 --> 1.319240).  Saving model ...
Validation loss decreased (1.319240 --> 1.314237).  Saving model ...
Validation loss decreased (1.314237 --> 1.308590).  Saving model ...
Validation loss decreased (1.308590 --> 1.303107).  Saving model ...
Validation loss decreased (1.303107 --> 1.296859).  Saving model ...
Validation loss decreased (1.296859 --> 1.290189).  Saving model ...
Validation loss decreased (1.290189 --> 1.282792).  Saving model ...
Validation loss decreased (1.282792 --> 1.275819).  Saving model ...
Validation loss decreased (1.275819 --> 1.268752).  Saving model ...
Validation loss decreased (1.268752 --> 1.262562).  Saving model ...
Validation loss decreased (1.262562 --> 1.255516).  Saving model ...
Validation loss decreased (1.255516 --> 1.247164).  Saving model ...
Validation loss decreased (1.247164 --> 1.239761).  Saving model ...
Validation loss decreased (1.239761 --> 1.233390).  Saving model ...
Validation loss decreased (1.233390 --> 1.226658).  Saving model ...
Validation loss decreased (1.226658 --> 1.220915).  Saving model ...
Validation loss decreased (1.220915 --> 1.215830).  Saving model ...
Validation loss decreased (1.215830 --> 1.207669).  Saving model ...
Validation loss decreased (1.207669 --> 1.203214).  Saving model ...
Validation loss decreased (1.203214 --> 1.200058).  Saving model ...
Validation loss decreased (1.200058 --> 1.193948).  Saving model ...
Validation loss decreased (1.193948 --> 1.186832).  Saving model ...
Validation loss decreased (1.186832 --> 1.183043).  Saving model ...
Validation loss decreased (1.183043 --> 1.175233).  Saving model ...
Validation loss decreased (1.175233 --> 1.170703).  Saving model ...
Validation loss decreased (1.170703 --> 1.168870).  Saving model ...
Validation loss decreased (1.168870 --> 1.166053).  Saving model ...
Validation loss decreased (1.166053 --> 1.161387).  Saving model ...
Validation loss decreased (1.161387 --> 1.154649).  Saving model ...
Validation loss decreased (1.154649 --> 1.151328).  Saving model ...
Validation loss decreased (1.151328 --> 1.147662).  Saving model ...
Validation loss decreased (1.147662 --> 1.144545).  Saving model ...
Validation loss decreased (1.144545 --> 1.139429).  Saving model ...
Validation loss decreased (1.139429 --> 1.135583).  Saving model ...
Validation loss decreased (1.135583 --> 1.132313).  Saving model ...
Validation loss decreased (1.132313 --> 1.126347).  Saving model ...
Validation loss decreased (1.126347 --> 1.123219).  Saving model ...
Validation loss decreased (1.123219 --> 1.117370).  Saving model ...
Validation loss decreased (1.117370 --> 1.114682).  Saving model ...
Validation loss decreased (1.114682 --> 1.112565).  Saving model ...
Validation loss decreased (1.112565 --> 1.108434).  Saving model ...
EarlyStopping counter: 1 out of 10.0
Validation loss decreased (1.108434 --> 1.104441).  Saving model ...
Validation loss decreased (1.104441 --> 1.099149).  Saving model ...
Validation loss decreased (1.099149 --> 1.093575).  Saving model ...
Validation loss decreased (1.093575 --> 1.088544).  Saving model ...
EarlyStopping counter: 1 out of 10.0
Validation loss decreased (1.088544 --> 1.088525).  Saving model ...
Validation loss decreased (1.088525 --> 1.084370).  Saving model ...
Validation loss decreased (1.084370 --> 1.080092).  Saving model ...
Validation loss decreased (1.080092 --> 1.076291).  Saving model ...
Validation loss decreased (1.076291 --> 1.076033).  Saving model ...
Validation loss decreased (1.076033 --> 1.072529).  Saving model ...
Validation loss decreased (1.072529 --> 1.070793).  Saving model ...
Validation loss decreased (1.070793 --> 1.066482).  Saving model ...
Validation loss decreased (1.066482 --> 1.062048).  Saving model ...
Validation loss decreased (1.062048 --> 1.059040).  Saving model ...
Validation loss decreased (1.059040 --> 1.055943).  Saving model ...
Validation loss decreased (1.055943 --> 1.053744).  Saving model ...
Validation loss decreased (1.053744 --> 1.053065).  Saving model ...
Validation loss decreased (1.053065 --> 1.049087).  Saving model ...
Validation loss decreased (1.049087 --> 1.046876).  Saving model ...
Validation loss decreased (1.046876 --> 1.045297).  Saving model ...
Validation loss decreased (1.045297 --> 1.042906).  Saving model ...
Validation loss decreased (1.042906 --> 1.040165).  Saving model ...
Validation loss decreased (1.040165 --> 1.037659).  Saving model ...
Validation loss decreased (1.037659 --> 1.034924).  Saving model ...
EarlyStopping counter: 1 out of 10.0
EarlyStopping counter: 2 out of 10.0
EarlyStopping counter: 3 out of 10.0
Validation loss decreased (1.034924 --> 1.032577).  Saving model ...
Validation loss decreased (1.032577 --> 1.028134).  Saving model ...
Validation loss decreased (1.028134 --> 1.025002).  Saving model ...
Validation loss decreased (1.025002 --> 1.021671).  Saving model ...
EarlyStopping counter: 1 out of 10.0
Validation loss decreased (1.021671 --> 1.021181).  Saving model ...
Validation loss decreased (1.021181 --> 1.019643).  Saving model ...
Validation loss decreased (1.019643 --> 1.015952).  Saving model ...
Validation loss decreased (1.015952 --> 1.011357).  Saving model ...
EarlyStopping counter: 1 out of 10.0
EarlyStopping counter: 2 out of 10.0
EarlyStopping counter: 3 out of 10.0
Validation loss decreased (1.011357 --> 1.010495).  Saving model ...
Validation loss decreased (1.010495 --> 1.009749).  Saving model ...
Validation loss decreased (1.009749 --> 1.006114).  Saving model ...
EarlyStopping counter: 1 out of 10.0
Validation loss decreased (1.006114 --> 1.005783).  Saving model ...
Validation loss decreased (1.005783 --> 1.003774).  Saving model ...
EarlyStopping counter: 1 out of 10.0
EarlyStopping counter: 2 out of 10.0
EarlyStopping counter: 3 out of 10.0
Validation loss decreased (1.003774 --> 1.002238).  Saving model ...
Validation loss decreased (1.002238 --> 0.998459).  Saving model ...
EarlyStopping counter: 1 out of 10.0
EarlyStopping counter: 2 out of 10.0
Validation loss decreased (0.998459 --> 0.996030).  Saving model ...
Validation loss decreased (0.996030 --> 0.992690).  Saving model ...
Validation loss decreased (0.992690 --> 0.991956).  Saving model ...
EarlyStopping counter: 1 out of 10.0
EarlyStopping counter: 2 out of 10.0
EarlyStopping counter: 3 out of 10.0
EarlyStopping counter: 4 out of 10.0
EarlyStopping counter: 5 out of 10.0
Validation loss decreased (0.991956 --> 0.990560).  Saving model ...
Validation loss decreased (0.990560 --> 0.989200).  Saving model ...
EarlyStopping counter: 1 out of 10.0
Validation loss decreased (0.989200 --> 0.986148).  Saving model ...
Validation loss decreased (0.986148 --> 0.985434).  Saving model ...
Validation loss decreased (0.985434 --> 0.984380).  Saving model ...
Validation loss decreased (0.984380 --> 0.982830).  Saving model ...
EarlyStopping counter: 1 out of 10.0
Validation loss decreased (0.982830 --> 0.982290).  Saving model ...
EarlyStopping counter: 1 out of 10.0
EarlyStopping counter: 2 out of 10.0
EarlyStopping counter: 3 out of 10.0
EarlyStopping counter: 4 out of 10.0
EarlyStopping counter: 5 out of 10.0
EarlyStopping counter: 6 out of 10.0
EarlyStopping counter: 7 out of 10.0
Validation loss decreased (0.982290 --> 0.982124).  Saving model ...
Validation loss decreased (0.982124 --> 0.979782).  Saving model ...
EarlyStopping counter: 1 out of 10.0
EarlyStopping counter: 2 out of 10.0
EarlyStopping counter: 3 out of 10.0
EarlyStopping counter: 4 out of 10.0
EarlyStopping counter: 5 out of 10.0
EarlyStopping counter: 6 out of 10.0
EarlyStopping counter: 7 out of 10.0
EarlyStopping counter: 8 out of 10.0
EarlyStopping counter: 9 out of 10.0
EarlyStopping counter: 10 out of 10.0
/localscratch/yinan.28944956.0/env/lib/python3.7/site-packages/torch/nn/functional.py:1794: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.
  warnings.warn("nn.functional.tanh is deprecated. Use torch.tanh instead.")
/localscratch/yinan.28944956.0/env/lib/python3.7/site-packages/transformers/optimization.py:155: UserWarning: This overload of add_ is deprecated:
	add_(Number alpha, Tensor other)
Consider using one of the following signatures instead:
	add_(Tensor other, *, Number alpha) (Triggered internally at  ../torch/csrc/utils/python_arg_parser.cpp:1025.)
  exp_avg.mul_(beta1).add_(1.0 - beta1, grad)
wandb: Waiting for W&B process to finish, PID 219376... (success).
wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: \ 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: | 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: / 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: \ 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: | 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: / 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: \ 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: | 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: / 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb:                                                                                
wandb: Run history:
wandb:     e_F1 â–â–‚â–ƒâ–„â–…â–†â–†â–†â–†â–†â–†â–†â–†â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ
wandb:   e_loss â–ˆâ–ˆâ–‡â–‡â–†â–†â–†â–…â–…â–„â–„â–„â–„â–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:     t_F1 â–â–â–‚â–ƒâ–ƒâ–„â–„â–…â–…â–…â–…â–…â–…â–†â–†â–…â–†â–†â–†â–†â–†â–‡â–†â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–ˆâ–‡â–‡â–ˆâ–‡â–‡â–ˆâ–ˆâ–ˆâ–ˆ
wandb:   t_loss â–ˆâ–ˆâ–‡â–‡â–‡â–†â–†â–†â–†â–…â–…â–…â–…â–„â–„â–„â–„â–„â–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–â–â–â–â–â–
wandb: 
wandb: Run summary:
wandb:     e_F1 59.99516
wandb:   e_loss 0.98373
wandb:     t_F1 74.65099
wandb:   t_loss 0.71104
wandb: 
wandb: Synced 4 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Synced absurd-dream-2: https://wandb.ai/yinanazhou/xl_512_bs_8_lr_1e06_es_10_lc_True_nr_False_sr_False_stem_False_lemma_True_repeat_1_fold_1/runs/2bl09n18
wandb: Find logs at: ./wandb/run-20220314_230909-2bl09n18/logs/debug.log
wandb: 

wandb: wandb version 0.12.11 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
2022-03-15 00:43:25.184590: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1
wandb: Tracking run with wandb version 0.12.5
wandb: Syncing run winter-grass-2
wandb: â­ï¸ View project at https://wandb.ai/yinanazhou/xl_512_bs_8_lr_1e06_es_10_lc_True_nr_False_sr_False_stem_False_lemma_True_repeat_1_fold_2
wandb: ðŸš€ View run at https://wandb.ai/yinanazhou/xl_512_bs_8_lr_1e06_es_10_lc_True_nr_False_sr_False_stem_False_lemma_True_repeat_1_fold_2/runs/28yfvqdc
wandb: Run data is saved locally in /project/6002780/yinan/Thesis_MER_Lyrics/lyric-emotion/wandb/run-20220315_004322-28yfvqdc
wandb: Run `wandb offline` to turn off syncing.

Validation loss decreased (inf --> 1.637617).  Saving model ...
Validation loss decreased (1.637617 --> 1.569711).  Saving model ...
Validation loss decreased (1.569711 --> 1.517678).  Saving model ...
Validation loss decreased (1.517678 --> 1.481642).  Saving model ...
Validation loss decreased (1.481642 --> 1.451533).  Saving model ...
Validation loss decreased (1.451533 --> 1.430918).  Saving model ...
Validation loss decreased (1.430918 --> 1.415539).  Saving model ...
Validation loss decreased (1.415539 --> 1.404095).  Saving model ...
Validation loss decreased (1.404095 --> 1.395169).  Saving model ...
Validation loss decreased (1.395169 --> 1.387975).  Saving model ...
Validation loss decreased (1.387975 --> 1.381084).  Saving model ...
Validation loss decreased (1.381084 --> 1.374122).  Saving model ...
Validation loss decreased (1.374122 --> 1.367167).  Saving model ...
Validation loss decreased (1.367167 --> 1.360463).  Saving model ...
Validation loss decreased (1.360463 --> 1.352800).  Saving model ...
Validation loss decreased (1.352800 --> 1.346209).  Saving model ...
Validation loss decreased (1.346209 --> 1.339175).  Saving model ...
Validation loss decreased (1.339175 --> 1.333028).  Saving model ...
Validation loss decreased (1.333028 --> 1.326323).  Saving model ...
Validation loss decreased (1.326323 --> 1.318548).  Saving model ...
Validation loss decreased (1.318548 --> 1.309664).  Saving model ...
Validation loss decreased (1.309664 --> 1.299358).  Saving model ...
Validation loss decreased (1.299358 --> 1.289752).  Saving model ...
Validation loss decreased (1.289752 --> 1.282007).  Saving model ...
Validation loss decreased (1.282007 --> 1.273056).  Saving model ...
Validation loss decreased (1.273056 --> 1.264568).  Saving model ...
Validation loss decreased (1.264568 --> 1.255350).  Saving model ...
Validation loss decreased (1.255350 --> 1.245576).  Saving model ...
Validation loss decreased (1.245576 --> 1.237645).  Saving model ...
Validation loss decreased (1.237645 --> 1.229916).  Saving model ...
Validation loss decreased (1.229916 --> 1.222482).  Saving model ...
Validation loss decreased (1.222482 --> 1.214064).  Saving model ...
Validation loss decreased (1.214064 --> 1.206682).  Saving model ...
Validation loss decreased (1.206682 --> 1.199418).  Saving model ...
Validation loss decreased (1.199418 --> 1.191753).  Saving model ...
Validation loss decreased (1.191753 --> 1.184694).  Saving model ...
Validation loss decreased (1.184694 --> 1.177800).  Saving model ...
Validation loss decreased (1.177800 --> 1.170446).  Saving model ...
Validation loss decreased (1.170446 --> 1.163320).  Saving model ...
Validation loss decreased (1.163320 --> 1.157689).  Saving model ...
Validation loss decreased (1.157689 --> 1.151255).  Saving model ...
Validation loss decreased (1.151255 --> 1.145451).  Saving model ...
Validation loss decreased (1.145451 --> 1.138705).  Saving model ...
Validation loss decreased (1.138705 --> 1.133162).  Saving model ...
Validation loss decreased (1.133162 --> 1.126811).  Saving model ...
Validation loss decreased (1.126811 --> 1.123277).  Saving model ...
Validation loss decreased (1.123277 --> 1.115582).  Saving model ...
Validation loss decreased (1.115582 --> 1.110202).  Saving model ...
Validation loss decreased (1.110202 --> 1.105627).  Saving model ...
Validation loss decreased (1.105627 --> 1.099573).  Saving model ...
Validation loss decreased (1.099573 --> 1.092196).  Saving model ...
Validation loss decreased (1.092196 --> 1.089481).  Saving model ...
Validation loss decreased (1.089481 --> 1.085281).  Saving model ...
Validation loss decreased (1.085281 --> 1.079250).  Saving model ...
Validation loss decreased (1.079250 --> 1.073706).  Saving model ...
Validation loss decreased (1.073706 --> 1.068999).  Saving model ...
Validation loss decreased (1.068999 --> 1.064306).  Saving model ...
Validation loss decreased (1.064306 --> 1.058283).  Saving model ...
Validation loss decreased (1.058283 --> 1.055811).  Saving model ...
Validation loss decreased (1.055811 --> 1.053210).  Saving model ...
Validation loss decreased (1.053210 --> 1.051516).  Saving model ...
Validation loss decreased (1.051516 --> 1.049545).  Saving model ...
Validation loss decreased (1.049545 --> 1.042098).  Saving model ...
Validation loss decreased (1.042098 --> 1.037204).  Saving model ...
Validation loss decreased (1.037204 --> 1.036592).  Saving model ...
Validation loss decreased (1.036592 --> 1.032813).  Saving model ...
Validation loss decreased (1.032813 --> 1.027213).  Saving model ...
Validation loss decreased (1.027213 --> 1.023811).  Saving model ...
Validation loss decreased (1.023811 --> 1.018100).  Saving model ...
Validation loss decreased (1.018100 --> 1.016113).  Saving model ...
Validation loss decreased (1.016113 --> 1.011980).  Saving model ...
Validation loss decreased (1.011980 --> 1.011124).  Saving model ...
Validation loss decreased (1.011124 --> 1.007389).  Saving model ...
Validation loss decreased (1.007389 --> 1.002698).  Saving model ...
Validation loss decreased (1.002698 --> 1.000930).  Saving model ...
Validation loss decreased (1.000930 --> 0.996922).  Saving model ...
Validation loss decreased (0.996922 --> 0.993681).  Saving model ...
Validation loss decreased (0.993681 --> 0.993175).  Saving model ...
Validation loss decreased (0.993175 --> 0.990607).  Saving model ...
Validation loss decreased (0.990607 --> 0.988494).  Saving model ...
Validation loss decreased (0.988494 --> 0.986232).  Saving model ...
Validation loss decreased (0.986232 --> 0.982886).  Saving model ...
Validation loss decreased (0.982886 --> 0.981323).  Saving model ...
Validation loss decreased (0.981323 --> 0.978591).  Saving model ...
Validation loss decreased (0.978591 --> 0.975818).  Saving model ...
EarlyStopping counter: 1 out of 10.0
Validation loss decreased (0.975818 --> 0.973748).  Saving model ...
Validation loss decreased (0.973748 --> 0.972569).  Saving model ...
Validation loss decreased (0.972569 --> 0.971096).  Saving model ...
Validation loss decreased (0.971096 --> 0.968443).  Saving model ...
EarlyStopping counter: 1 out of 10.0
Validation loss decreased (0.968443 --> 0.967268).  Saving model ...
Validation loss decreased (0.967268 --> 0.967132).  Saving model ...
Validation loss decreased (0.967132 --> 0.962529).  Saving model ...
Validation loss decreased (0.962529 --> 0.960666).  Saving model ...
Validation loss decreased (0.960666 --> 0.958585).  Saving model ...
Validation loss decreased (0.958585 --> 0.956729).  Saving model ...
Validation loss decreased (0.956729 --> 0.956077).  Saving model ...
Validation loss decreased (0.956077 --> 0.953676).  Saving model ...
Validation loss decreased (0.953676 --> 0.952287).  Saving model ...
EarlyStopping counter: 1 out of 10.0
EarlyStopping counter: 2 out of 10.0
EarlyStopping counter: 3 out of 10.0
EarlyStopping counter: 4 out of 10.0
Validation loss decreased (0.952287 --> 0.952191).  Saving model ...
Validation loss decreased (0.952191 --> 0.950223).  Saving model ...
Validation loss decreased (0.950223 --> 0.950220).  Saving model ...
Validation loss decreased (0.950220 --> 0.950003).  Saving model ...
Validation loss decreased (0.950003 --> 0.949670).  Saving model ...
EarlyStopping counter: 1 out of 10.0
Validation loss decreased (0.949670 --> 0.949658).  Saving model ...
Validation loss decreased (0.949658 --> 0.949193).  Saving model ...
EarlyStopping counter: 1 out of 10.0
EarlyStopping counter: 2 out of 10.0
Validation loss decreased (0.949193 --> 0.948504).  Saving model ...
Validation loss decreased (0.948504 --> 0.945773).  Saving model ...
Validation loss decreased (0.945773 --> 0.944670).  Saving model ...
EarlyStopping counter: 1 out of 10.0
EarlyStopping counter: 2 out of 10.0
EarlyStopping counter: 3 out of 10.0
EarlyStopping counter: 4 out of 10.0
EarlyStopping counter: 5 out of 10.0
EarlyStopping counter: 6 out of 10.0
EarlyStopping counter: 7 out of 10.0
EarlyStopping counter: 8 out of 10.0
EarlyStopping counter: 9 out of 10.0
EarlyStopping counter: 10 out of 10.0
/localscratch/yinan.28944956.0/env/lib/python3.7/site-packages/torch/nn/functional.py:1794: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.
  warnings.warn("nn.functional.tanh is deprecated. Use torch.tanh instead.")
wandb: Waiting for W&B process to finish, PID 224436... (success).
wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: \ 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: | 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: / 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: \ 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: | 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: / 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: \ 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: | 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: / 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb:                                                                                
wandb: Run history:
wandb:     e_F1 â–â–â–‚â–ƒâ–„â–…â–…â–†â–†â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–ˆâ–‡â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ
wandb:   e_loss â–ˆâ–†â–†â–…â–…â–…â–…â–„â–„â–„â–„â–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:     t_F1 â–â–‚â–‚â–ƒâ–ƒâ–ƒâ–„â–„â–„â–„â–„â–…â–…â–…â–†â–†â–†â–†â–†â–†â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ
wandb:   t_loss â–ˆâ–‡â–†â–†â–†â–†â–…â–…â–…â–…â–…â–…â–…â–„â–„â–„â–„â–„â–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–‚â–ƒâ–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–â–â–â–â–â–
wandb: 
wandb: Run summary:
wandb:     e_F1 59.82529
wandb:   e_loss 0.9492
wandb:     t_F1 70.95621
wandb:   t_loss 0.74282
wandb: 
wandb: Synced 4 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Synced winter-grass-2: https://wandb.ai/yinanazhou/xl_512_bs_8_lr_1e06_es_10_lc_True_nr_False_sr_False_stem_False_lemma_True_repeat_1_fold_2/runs/28yfvqdc
wandb: Find logs at: ./wandb/run-20220315_004322-28yfvqdc/logs/debug.log
wandb: 

wandb: wandb version 0.12.11 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
2022-03-15 02:06:38.379886: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1
wandb: Tracking run with wandb version 0.12.5
wandb: Syncing run avid-glitter-2
wandb: â­ï¸ View project at https://wandb.ai/yinanazhou/xl_512_bs_8_lr_1e06_es_10_lc_True_nr_False_sr_False_stem_False_lemma_True_repeat_2_fold_1
wandb: ðŸš€ View run at https://wandb.ai/yinanazhou/xl_512_bs_8_lr_1e06_es_10_lc_True_nr_False_sr_False_stem_False_lemma_True_repeat_2_fold_1/runs/3tkmnznb
wandb: Run data is saved locally in /project/6002780/yinan/Thesis_MER_Lyrics/lyric-emotion/wandb/run-20220315_020635-3tkmnznb
wandb: Run `wandb offline` to turn off syncing.

Validation loss decreased (inf --> 1.437048).  Saving model ...
Validation loss decreased (1.437048 --> 1.418369).  Saving model ...
Validation loss decreased (1.418369 --> 1.403020).  Saving model ...
Validation loss decreased (1.403020 --> 1.390938).  Saving model ...
Validation loss decreased (1.390938 --> 1.381492).  Saving model ...
Validation loss decreased (1.381492 --> 1.373631).  Saving model ...
Validation loss decreased (1.373631 --> 1.366051).  Saving model ...
Validation loss decreased (1.366051 --> 1.360034).  Saving model ...
Validation loss decreased (1.360034 --> 1.354503).  Saving model ...
Validation loss decreased (1.354503 --> 1.349172).  Saving model ...
Validation loss decreased (1.349172 --> 1.343556).  Saving model ...
Validation loss decreased (1.343556 --> 1.338175).  Saving model ...
Validation loss decreased (1.338175 --> 1.332215).  Saving model ...
Validation loss decreased (1.332215 --> 1.327251).  Saving model ...
Validation loss decreased (1.327251 --> 1.322155).  Saving model ...
Validation loss decreased (1.322155 --> 1.315851).  Saving model ...
Validation loss decreased (1.315851 --> 1.310039).  Saving model ...
Validation loss decreased (1.310039 --> 1.303581).  Saving model ...
Validation loss decreased (1.303581 --> 1.297680).  Saving model ...
Validation loss decreased (1.297680 --> 1.290901).  Saving model ...
Validation loss decreased (1.290901 --> 1.284077).  Saving model ...
Validation loss decreased (1.284077 --> 1.276513).  Saving model ...
Validation loss decreased (1.276513 --> 1.268677).  Saving model ...
Validation loss decreased (1.268677 --> 1.261140).  Saving model ...
Validation loss decreased (1.261140 --> 1.255531).  Saving model ...
Validation loss decreased (1.255531 --> 1.249760).  Saving model ...
Validation loss decreased (1.249760 --> 1.243560).  Saving model ...
Validation loss decreased (1.243560 --> 1.237974).  Saving model ...
Validation loss decreased (1.237974 --> 1.231415).  Saving model ...
Validation loss decreased (1.231415 --> 1.224477).  Saving model ...
Validation loss decreased (1.224477 --> 1.217676).  Saving model ...
Validation loss decreased (1.217676 --> 1.210981).  Saving model ...
Validation loss decreased (1.210981 --> 1.206487).  Saving model ...
Validation loss decreased (1.206487 --> 1.200468).  Saving model ...
Validation loss decreased (1.200468 --> 1.194617).  Saving model ...
Validation loss decreased (1.194617 --> 1.189555).  Saving model ...
Validation loss decreased (1.189555 --> 1.184155).  Saving model ...
Validation loss decreased (1.184155 --> 1.177746).  Saving model ...
Validation loss decreased (1.177746 --> 1.172045).  Saving model ...
Validation loss decreased (1.172045 --> 1.166595).  Saving model ...
Validation loss decreased (1.166595 --> 1.161519).  Saving model ...
Validation loss decreased (1.161519 --> 1.155543).  Saving model ...
Validation loss decreased (1.155543 --> 1.149725).  Saving model ...
Validation loss decreased (1.149725 --> 1.144333).  Saving model ...
Validation loss decreased (1.144333 --> 1.138982).  Saving model ...
Validation loss decreased (1.138982 --> 1.134487).  Saving model ...
Validation loss decreased (1.134487 --> 1.129537).  Saving model ...
Validation loss decreased (1.129537 --> 1.124406).  Saving model ...
Validation loss decreased (1.124406 --> 1.119564).  Saving model ...
Validation loss decreased (1.119564 --> 1.114420).  Saving model ...
Validation loss decreased (1.114420 --> 1.108849).  Saving model ...
Validation loss decreased (1.108849 --> 1.103893).  Saving model ...
Validation loss decreased (1.103893 --> 1.101589).  Saving model ...
Validation loss decreased (1.101589 --> 1.097265).  Saving model ...
Validation loss decreased (1.097265 --> 1.091609).  Saving model ...
Validation loss decreased (1.091609 --> 1.087555).  Saving model ...
Validation loss decreased (1.087555 --> 1.084143).  Saving model ...
Validation loss decreased (1.084143 --> 1.078821).  Saving model ...
Validation loss decreased (1.078821 --> 1.074864).  Saving model ...
Validation loss decreased (1.074864 --> 1.071371).  Saving model ...
Validation loss decreased (1.071371 --> 1.067720).  Saving model ...
Validation loss decreased (1.067720 --> 1.064270).  Saving model ...
Validation loss decreased (1.064270 --> 1.059624).  Saving model ...
Validation loss decreased (1.059624 --> 1.057027).  Saving model ...
Validation loss decreased (1.057027 --> 1.052478).  Saving model ...
Validation loss decreased (1.052478 --> 1.049077).  Saving model ...
Validation loss decreased (1.049077 --> 1.044327).  Saving model ...
Validation loss decreased (1.044327 --> 1.042608).  Saving model ...
Validation loss decreased (1.042608 --> 1.038998).  Saving model ...
Validation loss decreased (1.038998 --> 1.035164).  Saving model ...
Validation loss decreased (1.035164 --> 1.032672).  Saving model ...
Validation loss decreased (1.032672 --> 1.030601).  Saving model ...
Validation loss decreased (1.030601 --> 1.028998).  Saving model ...
Validation loss decreased (1.028998 --> 1.026120).  Saving model ...
Validation loss decreased (1.026120 --> 1.023560).  Saving model ...
Validation loss decreased (1.023560 --> 1.020979).  Saving model ...
Validation loss decreased (1.020979 --> 1.019806).  Saving model ...
Validation loss decreased (1.019806 --> 1.017987).  Saving model ...
Validation loss decreased (1.017987 --> 1.014303).  Saving model ...
Validation loss decreased (1.014303 --> 1.011155).  Saving model ...
Validation loss decreased (1.011155 --> 1.010068).  Saving model ...
Validation loss decreased (1.010068 --> 1.008360).  Saving model ...
Validation loss decreased (1.008360 --> 1.005768).  Saving model ...
Validation loss decreased (1.005768 --> 1.004706).  Saving model ...
Validation loss decreased (1.004706 --> 1.004668).  Saving model ...
Validation loss decreased (1.004668 --> 1.002985).  Saving model ...
Validation loss decreased (1.002985 --> 1.000414).  Saving model ...
Validation loss decreased (1.000414 --> 0.998953).  Saving model ...
Validation loss decreased (0.998953 --> 0.995742).  Saving model ...
EarlyStopping counter: 1 out of 10.0
Validation loss decreased (0.995742 --> 0.994968).  Saving model ...
Validation loss decreased (0.994968 --> 0.992247).  Saving model ...
Validation loss decreased (0.992247 --> 0.990365).  Saving model ...
Validation loss decreased (0.990365 --> 0.988408).  Saving model ...
Validation loss decreased (0.988408 --> 0.987237).  Saving model ...
EarlyStopping counter: 1 out of 10.0
Validation loss decreased (0.987237 --> 0.986176).  Saving model ...
Validation loss decreased (0.986176 --> 0.984082).  Saving model ...
Validation loss decreased (0.984082 --> 0.982046).  Saving model ...
Validation loss decreased (0.982046 --> 0.980907).  Saving model ...
Validation loss decreased (0.980907 --> 0.980088).  Saving model ...
Validation loss decreased (0.980088 --> 0.979719).  Saving model ...
Validation loss decreased (0.979719 --> 0.977835).  Saving model ...
Validation loss decreased (0.977835 --> 0.977716).  Saving model ...
Validation loss decreased (0.977716 --> 0.976041).  Saving model ...
EarlyStopping counter: 1 out of 10.0
Validation loss decreased (0.976041 --> 0.974163).  Saving model ...
Validation loss decreased (0.974163 --> 0.973355).  Saving model ...
EarlyStopping counter: 1 out of 10.0
Validation loss decreased (0.973355 --> 0.972487).  Saving model ...
Validation loss decreased (0.972487 --> 0.971558).  Saving model ...
EarlyStopping counter: 1 out of 10.0
Validation loss decreased (0.971558 --> 0.971505).  Saving model ...
EarlyStopping counter: 1 out of 10.0
Validation loss decreased (0.971505 --> 0.970326).  Saving model ...
Validation loss decreased (0.970326 --> 0.969137).  Saving model ...
EarlyStopping counter: 1 out of 10.0
EarlyStopping counter: 2 out of 10.0
EarlyStopping counter: 3 out of 10.0
Validation loss decreased (0.969137 --> 0.968991).  Saving model ...
EarlyStopping counter: 1 out of 10.0
EarlyStopping counter: 2 out of 10.0
EarlyStopping counter: 3 out of 10.0
EarlyStopping counter: 4 out of 10.0
Validation loss decreased (0.968991 --> 0.968492).  Saving model ...
Validation loss decreased (0.968492 --> 0.968420).  Saving model ...
EarlyStopping counter: 1 out of 10.0
EarlyStopping counter: 2 out of 10.0
EarlyStopping counter: 3 out of 10.0
EarlyStopping counter: 4 out of 10.0
EarlyStopping counter: 5 out of 10.0
EarlyStopping counter: 6 out of 10.0
EarlyStopping counter: 7 out of 10.0
Validation loss decreased (0.968420 --> 0.968354).  Saving model ...
EarlyStopping counter: 1 out of 10.0
EarlyStopping counter: 2 out of 10.0
EarlyStopping counter: 3 out of 10.0
EarlyStopping counter: 4 out of 10.0
EarlyStopping counter: 5 out of 10.0
EarlyStopping counter: 6 out of 10.0
EarlyStopping counter: 7 out of 10.0
EarlyStopping counter: 8 out of 10.0
EarlyStopping counter: 9 out of 10.0
EarlyStopping counter: 10 out of 10.0
/localscratch/yinan.28944956.0/env/lib/python3.7/site-packages/torch/nn/functional.py:1794: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.
  warnings.warn("nn.functional.tanh is deprecated. Use torch.tanh instead.")
wandb: Waiting for W&B process to finish, PID 228926... (success).
wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: \ 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: | 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: / 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: \ 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: | 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: / 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: \ 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: | 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: / 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: \ 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb:                                                                                
wandb: Run history:
wandb:     e_F1 â–â–‚â–ƒâ–„â–„â–„â–„â–…â–…â–†â–†â–†â–†â–†â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ
wandb:   e_loss â–ˆâ–ˆâ–‡â–‡â–†â–†â–†â–…â–…â–…â–„â–„â–„â–ƒâ–ƒâ–ƒâ–ƒâ–‚â–‚â–‚â–‚â–‚â–‚â–‚â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:     t_F1 â–â–â–‚â–‚â–ƒâ–ƒâ–„â–„â–…â–…â–…â–…â–…â–…â–†â–†â–†â–†â–†â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–ˆâ–‡â–‡â–ˆâ–‡â–‡â–‡â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ
wandb:   t_loss â–ˆâ–ˆâ–‡â–‡â–‡â–‡â–‡â–†â–†â–†â–…â–…â–…â–…â–…â–„â–„â–„â–„â–„â–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–â–â–â–â–â–
wandb: 
wandb: Run summary:
wandb:     e_F1 62.66072
wandb:   e_loss 0.97479
wandb:     t_F1 72.55894
wandb:   t_loss 0.69293
wandb: 
wandb: Synced 4 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Synced avid-glitter-2: https://wandb.ai/yinanazhou/xl_512_bs_8_lr_1e06_es_10_lc_True_nr_False_sr_False_stem_False_lemma_True_repeat_2_fold_1/runs/3tkmnznb
wandb: Find logs at: ./wandb/run-20220315_020635-3tkmnznb/logs/debug.log
wandb: 

wandb: wandb version 0.12.11 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
2022-03-15 03:40:54.012217: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1
wandb: Tracking run with wandb version 0.12.5
wandb: Syncing run twilight-cherry-2
wandb: â­ï¸ View project at https://wandb.ai/yinanazhou/xl_512_bs_8_lr_1e06_es_10_lc_True_nr_False_sr_False_stem_False_lemma_True_repeat_2_fold_2
wandb: ðŸš€ View run at https://wandb.ai/yinanazhou/xl_512_bs_8_lr_1e06_es_10_lc_True_nr_False_sr_False_stem_False_lemma_True_repeat_2_fold_2/runs/1pxu1z2u
wandb: Run data is saved locally in /project/6002780/yinan/Thesis_MER_Lyrics/lyric-emotion/wandb/run-20220315_034051-1pxu1z2u
wandb: Run `wandb offline` to turn off syncing.

Validation loss decreased (inf --> 1.466987).  Saving model ...
Validation loss decreased (1.466987 --> 1.440327).  Saving model ...
Validation loss decreased (1.440327 --> 1.419311).  Saving model ...
Validation loss decreased (1.419311 --> 1.402520).  Saving model ...
Validation loss decreased (1.402520 --> 1.389084).  Saving model ...
Validation loss decreased (1.389084 --> 1.379700).  Saving model ...
Validation loss decreased (1.379700 --> 1.371661).  Saving model ...
Validation loss decreased (1.371661 --> 1.365032).  Saving model ...
Validation loss decreased (1.365032 --> 1.358195).  Saving model ...
Validation loss decreased (1.358195 --> 1.352566).  Saving model ...
Validation loss decreased (1.352566 --> 1.347515).  Saving model ...
Validation loss decreased (1.347515 --> 1.342107).  Saving model ...
Validation loss decreased (1.342107 --> 1.337210).  Saving model ...
Validation loss decreased (1.337210 --> 1.331704).  Saving model ...
Validation loss decreased (1.331704 --> 1.326077).  Saving model ...
Validation loss decreased (1.326077 --> 1.321030).  Saving model ...
Validation loss decreased (1.321030 --> 1.315623).  Saving model ...
Validation loss decreased (1.315623 --> 1.309652).  Saving model ...
Validation loss decreased (1.309652 --> 1.303311).  Saving model ...
Validation loss decreased (1.303311 --> 1.296617).  Saving model ...
Validation loss decreased (1.296617 --> 1.290435).  Saving model ...
Validation loss decreased (1.290435 --> 1.282831).  Saving model ...
Validation loss decreased (1.282831 --> 1.275973).  Saving model ...
Validation loss decreased (1.275973 --> 1.268967).  Saving model ...
Validation loss decreased (1.268967 --> 1.260259).  Saving model ...
Validation loss decreased (1.260259 --> 1.252904).  Saving model ...
Validation loss decreased (1.252904 --> 1.245437).  Saving model ...
Validation loss decreased (1.245437 --> 1.239582).  Saving model ...
Validation loss decreased (1.239582 --> 1.232262).  Saving model ...
Validation loss decreased (1.232262 --> 1.224948).  Saving model ...
Validation loss decreased (1.224948 --> 1.215207).  Saving model ...
Validation loss decreased (1.215207 --> 1.206894).  Saving model ...
Validation loss decreased (1.206894 --> 1.199584).  Saving model ...
Validation loss decreased (1.199584 --> 1.192288).  Saving model ...
Validation loss decreased (1.192288 --> 1.183876).  Saving model ...
Validation loss decreased (1.183876 --> 1.178917).  Saving model ...
Validation loss decreased (1.178917 --> 1.171666).  Saving model ...
Validation loss decreased (1.171666 --> 1.164231).  Saving model ...
Validation loss decreased (1.164231 --> 1.154600).  Saving model ...
Validation loss decreased (1.154600 --> 1.147239).  Saving model ...
Validation loss decreased (1.147239 --> 1.141590).  Saving model ...
Validation loss decreased (1.141590 --> 1.135205).  Saving model ...
Validation loss decreased (1.135205 --> 1.130532).  Saving model ...
Validation loss decreased (1.130532 --> 1.125515).  Saving model ...
Validation loss decreased (1.125515 --> 1.117653).  Saving model ...
Validation loss decreased (1.117653 --> 1.114574).  Saving model ...
Validation loss decreased (1.114574 --> 1.110885).  Saving model ...
Validation loss decreased (1.110885 --> 1.105317).  Saving model ...
Validation loss decreased (1.105317 --> 1.098037).  Saving model ...
Validation loss decreased (1.098037 --> 1.092598).  Saving model ...
Validation loss decreased (1.092598 --> 1.089774).  Saving model ...
Validation loss decreased (1.089774 --> 1.085217).  Saving model ...
Validation loss decreased (1.085217 --> 1.080832).  Saving model ...
Validation loss decreased (1.080832 --> 1.078159).  Saving model ...
Validation loss decreased (1.078159 --> 1.073714).  Saving model ...
Validation loss decreased (1.073714 --> 1.071238).  Saving model ...
Validation loss decreased (1.071238 --> 1.065797).  Saving model ...
Validation loss decreased (1.065797 --> 1.061989).  Saving model ...
Validation loss decreased (1.061989 --> 1.056462).  Saving model ...
Validation loss decreased (1.056462 --> 1.053633).  Saving model ...
Validation loss decreased (1.053633 --> 1.048065).  Saving model ...
Validation loss decreased (1.048065 --> 1.045205).  Saving model ...
Validation loss decreased (1.045205 --> 1.043706).  Saving model ...
Validation loss decreased (1.043706 --> 1.040562).  Saving model ...
Validation loss decreased (1.040562 --> 1.037155).  Saving model ...
Validation loss decreased (1.037155 --> 1.035485).  Saving model ...
Validation loss decreased (1.035485 --> 1.029259).  Saving model ...
Validation loss decreased (1.029259 --> 1.026395).  Saving model ...
Validation loss decreased (1.026395 --> 1.023898).  Saving model ...
Validation loss decreased (1.023898 --> 1.020142).  Saving model ...
Validation loss decreased (1.020142 --> 1.014810).  Saving model ...
Validation loss decreased (1.014810 --> 1.011877).  Saving model ...
EarlyStopping counter: 1 out of 10.0
Validation loss decreased (1.011877 --> 1.005642).  Saving model ...
Validation loss decreased (1.005642 --> 1.001506).  Saving model ...
Validation loss decreased (1.001506 --> 0.997483).  Saving model ...
Validation loss decreased (0.997483 --> 0.995832).  Saving model ...
Validation loss decreased (0.995832 --> 0.993408).  Saving model ...
Validation loss decreased (0.993408 --> 0.990253).  Saving model ...
Validation loss decreased (0.990253 --> 0.988114).  Saving model ...
Validation loss decreased (0.988114 --> 0.985638).  Saving model ...
Validation loss decreased (0.985638 --> 0.982452).  Saving model ...
Validation loss decreased (0.982452 --> 0.981789).  Saving model ...
Validation loss decreased (0.981789 --> 0.980513).  Saving model ...
Validation loss decreased (0.980513 --> 0.977162).  Saving model ...
Validation loss decreased (0.977162 --> 0.974335).  Saving model ...
Validation loss decreased (0.974335 --> 0.970209).  Saving model ...
Validation loss decreased (0.970209 --> 0.968492).  Saving model ...
EarlyStopping counter: 1 out of 10.0
Validation loss decreased (0.968492 --> 0.968303).  Saving model ...
Validation loss decreased (0.968303 --> 0.965318).  Saving model ...
Validation loss decreased (0.965318 --> 0.960837).  Saving model ...
Validation loss decreased (0.960837 --> 0.960254).  Saving model ...
Validation loss decreased (0.960254 --> 0.956133).  Saving model ...
Validation loss decreased (0.956133 --> 0.954956).  Saving model ...
Validation loss decreased (0.954956 --> 0.951551).  Saving model ...
Validation loss decreased (0.951551 --> 0.951246).  Saving model ...
Validation loss decreased (0.951246 --> 0.948370).  Saving model ...
EarlyStopping counter: 1 out of 10.0
EarlyStopping counter: 2 out of 10.0
Validation loss decreased (0.948370 --> 0.948156).  Saving model ...
Validation loss decreased (0.948156 --> 0.947778).  Saving model ...
Validation loss decreased (0.947778 --> 0.943976).  Saving model ...
EarlyStopping counter: 1 out of 10.0
Validation loss decreased (0.943976 --> 0.941642).  Saving model ...
Validation loss decreased (0.941642 --> 0.941155).  Saving model ...
Validation loss decreased (0.941155 --> 0.940505).  Saving model ...
Validation loss decreased (0.940505 --> 0.936880).  Saving model ...
EarlyStopping counter: 1 out of 10.0
Validation loss decreased (0.936880 --> 0.934921).  Saving model ...
Validation loss decreased (0.934921 --> 0.931238).  Saving model ...
EarlyStopping counter: 1 out of 10.0
EarlyStopping counter: 2 out of 10.0
EarlyStopping counter: 3 out of 10.0
Validation loss decreased (0.931238 --> 0.931047).  Saving model ...
Validation loss decreased (0.931047 --> 0.928772).  Saving model ...
Validation loss decreased (0.928772 --> 0.928018).  Saving model ...
Validation loss decreased (0.928018 --> 0.926546).  Saving model ...
Validation loss decreased (0.926546 --> 0.924282).  Saving model ...
EarlyStopping counter: 1 out of 10.0
EarlyStopping counter: 2 out of 10.0
EarlyStopping counter: 3 out of 10.0
Validation loss decreased (0.924282 --> 0.923530).  Saving model ...
Validation loss decreased (0.923530 --> 0.922762).  Saving model ...
Validation loss decreased (0.922762 --> 0.922218).  Saving model ...
Validation loss decreased (0.922218 --> 0.920148).  Saving model ...
Validation loss decreased (0.920148 --> 0.919916).  Saving model ...
Validation loss decreased (0.919916 --> 0.919803).  Saving model ...
Validation loss decreased (0.919803 --> 0.919506).  Saving model ...
Validation loss decreased (0.919506 --> 0.919152).  Saving model ...
Validation loss decreased (0.919152 --> 0.917368).  Saving model ...
EarlyStopping counter: 1 out of 10.0
EarlyStopping counter: 2 out of 10.0
Validation loss decreased (0.917368 --> 0.917264).  Saving model ...
Validation loss decreased (0.917264 --> 0.915663).  Saving model ...
EarlyStopping counter: 1 out of 10.0
EarlyStopping counter: 2 out of 10.0
EarlyStopping counter: 3 out of 10.0
EarlyStopping counter: 4 out of 10.0
EarlyStopping counter: 5 out of 10.0
EarlyStopping counter: 6 out of 10.0
EarlyStopping counter: 7 out of 10.0
EarlyStopping counter: 8 out of 10.0
EarlyStopping counter: 9 out of 10.0
EarlyStopping counter: 10 out of 10.0
/localscratch/yinan.28944956.0/env/lib/python3.7/site-packages/torch/nn/functional.py:1794: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.
  warnings.warn("nn.functional.tanh is deprecated. Use torch.tanh instead.")
wandb: Waiting for W&B process to finish, PID 233951... (success).
wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: \ 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: | 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: / 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: \ 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: | 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: / 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: \ 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: | 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: / 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb:                                                                                
wandb: Run history:
wandb:     e_F1 â–â–â–ƒâ–„â–„â–…â–…â–†â–†â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ
wandb:   e_loss â–ˆâ–‡â–‡â–‡â–†â–†â–†â–…â–…â–…â–„â–„â–„â–„â–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–‚â–‚â–‚â–‚â–‚â–‚â–‚â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:     t_F1 â–â–â–‚â–ƒâ–ƒâ–ƒâ–„â–„â–…â–…â–…â–…â–…â–†â–…â–†â–†â–†â–†â–†â–‡â–†â–†â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‡
wandb:   t_loss â–ˆâ–ˆâ–‡â–‡â–‡â–‡â–†â–†â–†â–†â–…â–…â–…â–…â–…â–„â–„â–„â–„â–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–â–â–â–â–â–
wandb: 
wandb: Run summary:
wandb:     e_F1 61.99631
wandb:   e_loss 0.91814
wandb:     t_F1 72.8369
wandb:   t_loss 0.72552
wandb: 
wandb: Synced 4 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Synced twilight-cherry-2: https://wandb.ai/yinanazhou/xl_512_bs_8_lr_1e06_es_10_lc_True_nr_False_sr_False_stem_False_lemma_True_repeat_2_fold_2/runs/1pxu1z2u
wandb: Find logs at: ./wandb/run-20220315_034051-1pxu1z2u/logs/debug.log
wandb: 

wandb: wandb version 0.12.11 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
2022-03-15 05:16:12.592365: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1
wandb: Tracking run with wandb version 0.12.5
wandb: Syncing run sparkling-lake-2
wandb: â­ï¸ View project at https://wandb.ai/yinanazhou/xl_512_bs_8_lr_1e06_es_10_lc_True_nr_False_sr_False_stem_False_lemma_True_repeat_3_fold_1
wandb: ðŸš€ View run at https://wandb.ai/yinanazhou/xl_512_bs_8_lr_1e06_es_10_lc_True_nr_False_sr_False_stem_False_lemma_True_repeat_3_fold_1/runs/j1wyios0
wandb: Run data is saved locally in /project/6002780/yinan/Thesis_MER_Lyrics/lyric-emotion/wandb/run-20220315_051608-j1wyios0
wandb: Run `wandb offline` to turn off syncing.

Validation loss decreased (inf --> 1.431370).  Saving model ...
Validation loss decreased (1.431370 --> 1.417945).  Saving model ...
Validation loss decreased (1.417945 --> 1.407779).  Saving model ...
Validation loss decreased (1.407779 --> 1.399613).  Saving model ...
Validation loss decreased (1.399613 --> 1.392864).  Saving model ...
Validation loss decreased (1.392864 --> 1.386890).  Saving model ...
Validation loss decreased (1.386890 --> 1.381738).  Saving model ...
Validation loss decreased (1.381738 --> 1.376486).  Saving model ...
Validation loss decreased (1.376486 --> 1.371965).  Saving model ...
Validation loss decreased (1.371965 --> 1.367267).  Saving model ...
Validation loss decreased (1.367267 --> 1.362583).  Saving model ...
Validation loss decreased (1.362583 --> 1.358379).  Saving model ...
Validation loss decreased (1.358379 --> 1.354126).  Saving model ...
Validation loss decreased (1.354126 --> 1.349584).  Saving model ...
Validation loss decreased (1.349584 --> 1.345349).  Saving model ...
Validation loss decreased (1.345349 --> 1.340805).  Saving model ...
Validation loss decreased (1.340805 --> 1.335609).  Saving model ...
Validation loss decreased (1.335609 --> 1.331316).  Saving model ...
Validation loss decreased (1.331316 --> 1.325730).  Saving model ...
Validation loss decreased (1.325730 --> 1.320245).  Saving model ...
Validation loss decreased (1.320245 --> 1.314043).  Saving model ...
Validation loss decreased (1.314043 --> 1.308175).  Saving model ...
Validation loss decreased (1.308175 --> 1.301878).  Saving model ...
Validation loss decreased (1.301878 --> 1.294793).  Saving model ...
Validation loss decreased (1.294793 --> 1.287969).  Saving model ...
Validation loss decreased (1.287969 --> 1.279635).  Saving model ...
Validation loss decreased (1.279635 --> 1.272222).  Saving model ...
Validation loss decreased (1.272222 --> 1.264487).  Saving model ...
Validation loss decreased (1.264487 --> 1.255816).  Saving model ...
Validation loss decreased (1.255816 --> 1.247143).  Saving model ...
Validation loss decreased (1.247143 --> 1.237834).  Saving model ...
Validation loss decreased (1.237834 --> 1.229036).  Saving model ...
Validation loss decreased (1.229036 --> 1.220690).  Saving model ...
Validation loss decreased (1.220690 --> 1.212031).  Saving model ...
Validation loss decreased (1.212031 --> 1.204100).  Saving model ...
Validation loss decreased (1.204100 --> 1.196786).  Saving model ...
Validation loss decreased (1.196786 --> 1.189606).  Saving model ...
Validation loss decreased (1.189606 --> 1.181977).  Saving model ...
Validation loss decreased (1.181977 --> 1.174313).  Saving model ...
Validation loss decreased (1.174313 --> 1.166871).  Saving model ...
Validation loss decreased (1.166871 --> 1.159596).  Saving model ...
Validation loss decreased (1.159596 --> 1.153355).  Saving model ...
Validation loss decreased (1.153355 --> 1.146038).  Saving model ...
Validation loss decreased (1.146038 --> 1.139321).  Saving model ...
Validation loss decreased (1.139321 --> 1.132779).  Saving model ...
Validation loss decreased (1.132779 --> 1.125405).  Saving model ...
Validation loss decreased (1.125405 --> 1.119050).  Saving model ...
Validation loss decreased (1.119050 --> 1.112275).  Saving model ...
Validation loss decreased (1.112275 --> 1.107236).  Saving model ...
Validation loss decreased (1.107236 --> 1.101278).  Saving model ...
Validation loss decreased (1.101278 --> 1.095944).  Saving model ...
Validation loss decreased (1.095944 --> 1.090894).  Saving model ...
Validation loss decreased (1.090894 --> 1.087061).  Saving model ...
Validation loss decreased (1.087061 --> 1.082210).  Saving model ...
Validation loss decreased (1.082210 --> 1.078165).  Saving model ...
Validation loss decreased (1.078165 --> 1.072654).  Saving model ...
Validation loss decreased (1.072654 --> 1.067875).  Saving model ...
Validation loss decreased (1.067875 --> 1.063311).  Saving model ...
Validation loss decreased (1.063311 --> 1.060254).  Saving model ...
Validation loss decreased (1.060254 --> 1.054758).  Saving model ...
Validation loss decreased (1.054758 --> 1.051091).  Saving model ...
Validation loss decreased (1.051091 --> 1.047219).  Saving model ...
Validation loss decreased (1.047219 --> 1.044007).  Saving model ...
Validation loss decreased (1.044007 --> 1.039982).  Saving model ...
Validation loss decreased (1.039982 --> 1.037017).  Saving model ...
Validation loss decreased (1.037017 --> 1.034132).  Saving model ...
Validation loss decreased (1.034132 --> 1.030063).  Saving model ...
Validation loss decreased (1.030063 --> 1.025349).  Saving model ...
Validation loss decreased (1.025349 --> 1.020179).  Saving model ...
Validation loss decreased (1.020179 --> 1.016250).  Saving model ...
Validation loss decreased (1.016250 --> 1.015270).  Saving model ...
Validation loss decreased (1.015270 --> 1.010998).  Saving model ...
Validation loss decreased (1.010998 --> 1.006651).  Saving model ...
Validation loss decreased (1.006651 --> 1.003812).  Saving model ...
Validation loss decreased (1.003812 --> 1.001988).  Saving model ...
Validation loss decreased (1.001988 --> 1.000198).  Saving model ...
Validation loss decreased (1.000198 --> 0.997185).  Saving model ...
Validation loss decreased (0.997185 --> 0.993137).  Saving model ...
Validation loss decreased (0.993137 --> 0.990087).  Saving model ...
Validation loss decreased (0.990087 --> 0.986386).  Saving model ...
Validation loss decreased (0.986386 --> 0.984707).  Saving model ...
Validation loss decreased (0.984707 --> 0.982187).  Saving model ...
Validation loss decreased (0.982187 --> 0.980978).  Saving model ...
Validation loss decreased (0.980978 --> 0.978444).  Saving model ...
Validation loss decreased (0.978444 --> 0.977096).  Saving model ...
Validation loss decreased (0.977096 --> 0.976102).  Saving model ...
Validation loss decreased (0.976102 --> 0.973969).  Saving model ...
Validation loss decreased (0.973969 --> 0.971561).  Saving model ...
Validation loss decreased (0.971561 --> 0.970574).  Saving model ...
Validation loss decreased (0.970574 --> 0.968583).  Saving model ...
Validation loss decreased (0.968583 --> 0.967257).  Saving model ...
Validation loss decreased (0.967257 --> 0.966660).  Saving model ...
Validation loss decreased (0.966660 --> 0.964375).  Saving model ...
EarlyStopping counter: 1 out of 10.0
Validation loss decreased (0.964375 --> 0.963363).  Saving model ...
Validation loss decreased (0.963363 --> 0.962679).  Saving model ...
Validation loss decreased (0.962679 --> 0.961703).  Saving model ...
Validation loss decreased (0.961703 --> 0.959855).  Saving model ...
Validation loss decreased (0.959855 --> 0.958971).  Saving model ...
Validation loss decreased (0.958971 --> 0.955216).  Saving model ...
Validation loss decreased (0.955216 --> 0.954076).  Saving model ...
Validation loss decreased (0.954076 --> 0.952105).  Saving model ...
Validation loss decreased (0.952105 --> 0.951457).  Saving model ...
Validation loss decreased (0.951457 --> 0.951235).  Saving model ...
Validation loss decreased (0.951235 --> 0.949776).  Saving model ...
EarlyStopping counter: 1 out of 10.0
Validation loss decreased (0.949776 --> 0.948589).  Saving model ...
EarlyStopping counter: 1 out of 10.0
Validation loss decreased (0.948589 --> 0.946478).  Saving model ...
Validation loss decreased (0.946478 --> 0.946054).  Saving model ...
Validation loss decreased (0.946054 --> 0.944745).  Saving model ...
EarlyStopping counter: 1 out of 10.0
EarlyStopping counter: 2 out of 10.0
Validation loss decreased (0.944745 --> 0.944319).  Saving model ...
Validation loss decreased (0.944319 --> 0.943666).  Saving model ...
Validation loss decreased (0.943666 --> 0.941822).  Saving model ...
Validation loss decreased (0.941822 --> 0.941615).  Saving model ...
Validation loss decreased (0.941615 --> 0.940001).  Saving model ...
EarlyStopping counter: 1 out of 10.0
EarlyStopping counter: 2 out of 10.0
Validation loss decreased (0.940001 --> 0.939864).  Saving model ...
Validation loss decreased (0.939864 --> 0.938830).  Saving model ...
EarlyStopping counter: 1 out of 10.0
EarlyStopping counter: 2 out of 10.0
EarlyStopping counter: 3 out of 10.0
EarlyStopping counter: 4 out of 10.0
EarlyStopping counter: 5 out of 10.0
Validation loss decreased (0.938830 --> 0.938396).  Saving model ...
Validation loss decreased (0.938396 --> 0.937856).  Saving model ...
EarlyStopping counter: 1 out of 10.0
EarlyStopping counter: 2 out of 10.0
EarlyStopping counter: 3 out of 10.0
EarlyStopping counter: 4 out of 10.0
EarlyStopping counter: 5 out of 10.0
EarlyStopping counter: 6 out of 10.0
EarlyStopping counter: 7 out of 10.0
EarlyStopping counter: 8 out of 10.0
EarlyStopping counter: 9 out of 10.0
EarlyStopping counter: 10 out of 10.0
/localscratch/yinan.28944956.0/env/lib/python3.7/site-packages/torch/nn/functional.py:1794: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.
  warnings.warn("nn.functional.tanh is deprecated. Use torch.tanh instead.")
wandb: Waiting for W&B process to finish, PID 239052... (success).
wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: \ 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: | 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: / 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb:                                                                                
wandb: Run history:
wandb:     e_F1 â–â–‚â–‚â–„â–„â–…â–†â–†â–†â–†â–†â–†â–†â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ
wandb:   e_loss â–ˆâ–ˆâ–‡â–‡â–‡â–‡â–†â–†â–†â–…â–…â–„â–„â–„â–ƒâ–ƒâ–ƒâ–ƒâ–‚â–‚â–‚â–‚â–‚â–‚â–‚â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:     t_F1 â–â–â–‚â–‚â–‚â–ƒâ–ƒâ–„â–„â–„â–…â–…â–…â–†â–…â–†â–†â–†â–‡â–†â–†â–‡â–†â–†â–†â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–ˆâ–‡â–‡â–ˆâ–ˆâ–ˆâ–ˆ
wandb:   t_loss â–ˆâ–ˆâ–‡â–‡â–‡â–‡â–‡â–‡â–†â–†â–†â–…â–…â–…â–…â–…â–„â–„â–„â–„â–„â–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–â–â–â–â–
wandb: 
wandb: Run summary:
wandb:     e_F1 59.66312
wandb:   e_loss 0.93991
wandb:     t_F1 72.90129
wandb:   t_loss 0.74278
wandb: 
wandb: Synced 4 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Synced sparkling-lake-2: https://wandb.ai/yinanazhou/xl_512_bs_8_lr_1e06_es_10_lc_True_nr_False_sr_False_stem_False_lemma_True_repeat_3_fold_1/runs/j1wyios0
wandb: Find logs at: ./wandb/run-20220315_051608-j1wyios0/logs/debug.log
wandb: 

wandb: wandb version 0.12.11 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
2022-03-15 06:47:49.014627: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1
wandb: Tracking run with wandb version 0.12.5
wandb: Syncing run scarlet-totem-2
wandb: â­ï¸ View project at https://wandb.ai/yinanazhou/xl_512_bs_8_lr_1e06_es_10_lc_True_nr_False_sr_False_stem_False_lemma_True_repeat_3_fold_2
wandb: ðŸš€ View run at https://wandb.ai/yinanazhou/xl_512_bs_8_lr_1e06_es_10_lc_True_nr_False_sr_False_stem_False_lemma_True_repeat_3_fold_2/runs/22iasfhf
wandb: Run data is saved locally in /project/6002780/yinan/Thesis_MER_Lyrics/lyric-emotion/wandb/run-20220315_064745-22iasfhf
wandb: Run `wandb offline` to turn off syncing.

Validation loss decreased (inf --> 1.399829).  Saving model ...
Validation loss decreased (1.399829 --> 1.391629).  Saving model ...
Validation loss decreased (1.391629 --> 1.385343).  Saving model ...
Validation loss decreased (1.385343 --> 1.380020).  Saving model ...
Validation loss decreased (1.380020 --> 1.375183).  Saving model ...
Validation loss decreased (1.375183 --> 1.370834).  Saving model ...
Validation loss decreased (1.370834 --> 1.366536).  Saving model ...
Validation loss decreased (1.366536 --> 1.362693).  Saving model ...
Validation loss decreased (1.362693 --> 1.358486).  Saving model ...
Validation loss decreased (1.358486 --> 1.354343).  Saving model ...
Validation loss decreased (1.354343 --> 1.350652).  Saving model ...
Validation loss decreased (1.350652 --> 1.347151).  Saving model ...
Validation loss decreased (1.347151 --> 1.343135).  Saving model ...
Validation loss decreased (1.343135 --> 1.338927).  Saving model ...
Validation loss decreased (1.338927 --> 1.334477).  Saving model ...
Validation loss decreased (1.334477 --> 1.330237).  Saving model ...
Validation loss decreased (1.330237 --> 1.325651).  Saving model ...
Validation loss decreased (1.325651 --> 1.320314).  Saving model ...
Validation loss decreased (1.320314 --> 1.314846).  Saving model ...
Validation loss decreased (1.314846 --> 1.309095).  Saving model ...
Validation loss decreased (1.309095 --> 1.302712).  Saving model ...
Validation loss decreased (1.302712 --> 1.295685).  Saving model ...
Validation loss decreased (1.295685 --> 1.288306).  Saving model ...
Validation loss decreased (1.288306 --> 1.281062).  Saving model ...
Validation loss decreased (1.281062 --> 1.272190).  Saving model ...
Validation loss decreased (1.272190 --> 1.263668).  Saving model ...
Validation loss decreased (1.263668 --> 1.255747).  Saving model ...
Validation loss decreased (1.255747 --> 1.246141).  Saving model ...
Validation loss decreased (1.246141 --> 1.236413).  Saving model ...
Validation loss decreased (1.236413 --> 1.227638).  Saving model ...
Validation loss decreased (1.227638 --> 1.219029).  Saving model ...
Validation loss decreased (1.219029 --> 1.209087).  Saving model ...
Validation loss decreased (1.209087 --> 1.199518).  Saving model ...
Validation loss decreased (1.199518 --> 1.191151).  Saving model ...
Validation loss decreased (1.191151 --> 1.183721).  Saving model ...
Validation loss decreased (1.183721 --> 1.177797).  Saving model ...
Validation loss decreased (1.177797 --> 1.171609).  Saving model ...
Validation loss decreased (1.171609 --> 1.165278).  Saving model ...
Validation loss decreased (1.165278 --> 1.159419).  Saving model ...
Validation loss decreased (1.159419 --> 1.152884).  Saving model ...
Validation loss decreased (1.152884 --> 1.146332).  Saving model ...
Validation loss decreased (1.146332 --> 1.139667).  Saving model ...
Validation loss decreased (1.139667 --> 1.133052).  Saving model ...
Validation loss decreased (1.133052 --> 1.127759).  Saving model ...
Validation loss decreased (1.127759 --> 1.123299).  Saving model ...
Validation loss decreased (1.123299 --> 1.118005).  Saving model ...
Validation loss decreased (1.118005 --> 1.112372).  Saving model ...
Validation loss decreased (1.112372 --> 1.106246).  Saving model ...
Validation loss decreased (1.106246 --> 1.100158).  Saving model ...
Validation loss decreased (1.100158 --> 1.093860).  Saving model ...
Validation loss decreased (1.093860 --> 1.091116).  Saving model ...
Validation loss decreased (1.091116 --> 1.086466).  Saving model ...
Validation loss decreased (1.086466 --> 1.082581).  Saving model ...
Validation loss decreased (1.082581 --> 1.077430).  Saving model ...
Validation loss decreased (1.077430 --> 1.072069).  Saving model ...
Validation loss decreased (1.072069 --> 1.067917).  Saving model ...
Validation loss decreased (1.067917 --> 1.062998).  Saving model ...
Validation loss decreased (1.062998 --> 1.058363).  Saving model ...
Validation loss decreased (1.058363 --> 1.054969).  Saving model ...
Validation loss decreased (1.054969 --> 1.050856).  Saving model ...
Validation loss decreased (1.050856 --> 1.047997).  Saving model ...
Validation loss decreased (1.047997 --> 1.045863).  Saving model ...
Validation loss decreased (1.045863 --> 1.042790).  Saving model ...
Validation loss decreased (1.042790 --> 1.039618).  Saving model ...
Validation loss decreased (1.039618 --> 1.033870).  Saving model ...
Validation loss decreased (1.033870 --> 1.030723).  Saving model ...
Validation loss decreased (1.030723 --> 1.027437).  Saving model ...
Validation loss decreased (1.027437 --> 1.025508).  Saving model ...
Validation loss decreased (1.025508 --> 1.020498).  Saving model ...
Validation loss decreased (1.020498 --> 1.017723).  Saving model ...
Validation loss decreased (1.017723 --> 1.014515).  Saving model ...
Validation loss decreased (1.014515 --> 1.011818).  Saving model ...
Validation loss decreased (1.011818 --> 1.009817).  Saving model ...
Validation loss decreased (1.009817 --> 1.006875).  Saving model ...
Validation loss decreased (1.006875 --> 1.003600).  Saving model ...
Validation loss decreased (1.003600 --> 1.001272).  Saving model ...
Validation loss decreased (1.001272 --> 0.997573).  Saving model ...
Validation loss decreased (0.997573 --> 0.994294).  Saving model ...
Validation loss decreased (0.994294 --> 0.992234).  Saving model ...
Validation loss decreased (0.992234 --> 0.990848).  Saving model ...
Validation loss decreased (0.990848 --> 0.988850).  Saving model ...
Validation loss decreased (0.988850 --> 0.986038).  Saving model ...
Validation loss decreased (0.986038 --> 0.984754).  Saving model ...
Validation loss decreased (0.984754 --> 0.982826).  Saving model ...
Validation loss decreased (0.982826 --> 0.982299).  Saving model ...
Validation loss decreased (0.982299 --> 0.979407).  Saving model ...
Validation loss decreased (0.979407 --> 0.978069).  Saving model ...
Validation loss decreased (0.978069 --> 0.975897).  Saving model ...
EarlyStopping counter: 1 out of 10.0
Validation loss decreased (0.975897 --> 0.975204).  Saving model ...
Validation loss decreased (0.975204 --> 0.972849).  Saving model ...
Validation loss decreased (0.972849 --> 0.970780).  Saving model ...
Validation loss decreased (0.970780 --> 0.967950).  Saving model ...
Validation loss decreased (0.967950 --> 0.965887).  Saving model ...
Validation loss decreased (0.965887 --> 0.964162).  Saving model ...
Validation loss decreased (0.964162 --> 0.963760).  Saving model ...
EarlyStopping counter: 1 out of 10.0
Validation loss decreased (0.963760 --> 0.961221).  Saving model ...
Validation loss decreased (0.961221 --> 0.959107).  Saving model ...
Validation loss decreased (0.959107 --> 0.957039).  Saving model ...
Validation loss decreased (0.957039 --> 0.956162).  Saving model ...
Validation loss decreased (0.956162 --> 0.955980).  Saving model ...
Validation loss decreased (0.955980 --> 0.954556).  Saving model ...
Validation loss decreased (0.954556 --> 0.953717).  Saving model ...
Validation loss decreased (0.953717 --> 0.952133).  Saving model ...
Validation loss decreased (0.952133 --> 0.950612).  Saving model ...
Validation loss decreased (0.950612 --> 0.949870).  Saving model ...
Validation loss decreased (0.949870 --> 0.948509).  Saving model ...
Validation loss decreased (0.948509 --> 0.948088).  Saving model ...
Validation loss decreased (0.948088 --> 0.946770).  Saving model ...
Validation loss decreased (0.946770 --> 0.944116).  Saving model ...
EarlyStopping counter: 1 out of 10.0
EarlyStopping counter: 2 out of 10.0
Validation loss decreased (0.944116 --> 0.942651).  Saving model ...
Validation loss decreased (0.942651 --> 0.939343).  Saving model ...
Validation loss decreased (0.939343 --> 0.937825).  Saving model ...
EarlyStopping counter: 1 out of 10.0
Validation loss decreased (0.937825 --> 0.937766).  Saving model ...
EarlyStopping counter: 1 out of 10.0
EarlyStopping counter: 2 out of 10.0
EarlyStopping counter: 3 out of 10.0
EarlyStopping counter: 4 out of 10.0
Validation loss decreased (0.937766 --> 0.937089).  Saving model ...
Validation loss decreased (0.937089 --> 0.936939).  Saving model ...
Validation loss decreased (0.936939 --> 0.935571).  Saving model ...
EarlyStopping counter: 1 out of 10.0
EarlyStopping counter: 2 out of 10.0
EarlyStopping counter: 3 out of 10.0
Validation loss decreased (0.935571 --> 0.933914).  Saving model ...
Validation loss decreased (0.933914 --> 0.933731).  Saving model ...
EarlyStopping counter: 1 out of 10.0
EarlyStopping counter: 2 out of 10.0
Validation loss decreased (0.933731 --> 0.932474).  Saving model ...
EarlyStopping counter: 1 out of 10.0
EarlyStopping counter: 2 out of 10.0
EarlyStopping counter: 3 out of 10.0
EarlyStopping counter: 4 out of 10.0
Validation loss decreased (0.932474 --> 0.931599).  Saving model ...
EarlyStopping counter: 1 out of 10.0
EarlyStopping counter: 2 out of 10.0
EarlyStopping counter: 3 out of 10.0
EarlyStopping counter: 4 out of 10.0
EarlyStopping counter: 5 out of 10.0
EarlyStopping counter: 6 out of 10.0
EarlyStopping counter: 7 out of 10.0
EarlyStopping counter: 8 out of 10.0
EarlyStopping counter: 9 out of 10.0
EarlyStopping counter: 10 out of 10.0
/localscratch/yinan.28944956.0/env/lib/python3.7/site-packages/torch/nn/functional.py:1794: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.
  warnings.warn("nn.functional.tanh is deprecated. Use torch.tanh instead.")
wandb: Waiting for W&B process to finish, PID 243949... (success).
wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: \ 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: | 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: / 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: \ 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: | 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: / 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: \ 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: | 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: / 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb:                                                                                
wandb: Run history:
wandb:     e_F1 â–â–‚â–ƒâ–„â–…â–…â–…â–…â–†â–†â–†â–†â–†â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–ˆâ–‡â–‡â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ
wandb:   e_loss â–ˆâ–ˆâ–ˆâ–‡â–‡â–‡â–†â–†â–…â–…â–…â–„â–„â–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:     t_F1 â–â–â–‚â–‚â–‚â–ƒâ–ƒâ–„â–„â–„â–…â–…â–…â–…â–…â–†â–†â–†â–†â–†â–†â–‡â–†â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–ˆâ–‡â–ˆâ–ˆâ–ˆâ–ˆâ–‡â–ˆâ–ˆâ–ˆ
wandb:   t_loss â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‡â–‡â–†â–†â–†â–†â–…â–…â–…â–…â–„â–„â–„â–„â–ƒâ–„â–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–‚â–ƒâ–‚â–‚â–‚â–‚â–‚â–‚â–â–â–â–â–â–
wandb: 
wandb: Run summary:
wandb:     e_F1 64.39632
wandb:   e_loss 0.93301
wandb:     t_F1 73.02334
wandb:   t_loss 0.71706
wandb: 
wandb: Synced 4 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Synced scarlet-totem-2: https://wandb.ai/yinanazhou/xl_512_bs_8_lr_1e06_es_10_lc_True_nr_False_sr_False_stem_False_lemma_True_repeat_3_fold_2/runs/22iasfhf
wandb: Find logs at: ./wandb/run-20220315_064745-22iasfhf/logs/debug.log
wandb: 

wandb: wandb version 0.12.11 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
2022-03-15 08:24:40.737584: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1
wandb: Tracking run with wandb version 0.12.5
wandb: Syncing run azure-waterfall-2
wandb: â­ï¸ View project at https://wandb.ai/yinanazhou/xl_512_bs_8_lr_1e06_es_10_lc_True_nr_False_sr_False_stem_False_lemma_True_repeat_4_fold_1
wandb: ðŸš€ View run at https://wandb.ai/yinanazhou/xl_512_bs_8_lr_1e06_es_10_lc_True_nr_False_sr_False_stem_False_lemma_True_repeat_4_fold_1/runs/1igl9kgl
wandb: Run data is saved locally in /project/6002780/yinan/Thesis_MER_Lyrics/lyric-emotion/wandb/run-20220315_082437-1igl9kgl
wandb: Run `wandb offline` to turn off syncing.
slurmstepd: error: *** JOB 28944956 ON cdr2630 CANCELLED AT 2022-03-15T09:06:26 DUE TO TIME LIMIT ***
