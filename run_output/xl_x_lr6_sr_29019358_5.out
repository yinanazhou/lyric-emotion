Unloading StdEnv/2020

Due to MODULEPATH changes, the following have been reloaded:
  1) mii/1.1.1


The following have been reloaded with a version change:
  1) python/3.8.2 => python/3.7.4

Using base prefix '/cvmfs/soft.computecanada.ca/easybuild/software/2017/Core/python/3.7.4'
New python executable in /localscratch/yinan.29163121.0/env/bin/python
Installing setuptools, pip, wheel...
done.
Ignoring pip: markers 'python_version < "3"' don't match your environment
Looking in links: /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/nix/avx2, /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/nix/generic, /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic
Collecting pip
Installing collected packages: pip
  Found existing installation: pip 19.1.1
    Uninstalling pip-19.1.1:
      Successfully uninstalled pip-19.1.1
Successfully installed pip-21.2.3+computecanada
Looking in links: /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/nix/avx2, /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/nix/generic, /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/keras-2.8.0+computecanada-py2.py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/Keras_Preprocessing-1.1.2+computecanada-py3-none-any.whl
Requirement already satisfied: matplotlib in /cvmfs/soft.computecanada.ca/easybuild/software/2017/Core/scipy-stack/2019a/lib/python3.7/site-packages (from -r requirements.txt (line 3)) (3.0.2)
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/nltk-3.6.5+computecanada-py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/scikit_learn-0.22.1+computecanada-cp37-cp37m-linux_x86_64.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/tensorboard-2.3.0+computecanada-py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/tensorboard_plugin_wit-1.7.0+computecanada-py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/tensorflow_gpu-2.3.0+computecanada-cp37-cp37m-linux_x86_64.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/tensorflow_estimator-2.3.0+computecanada-py2.py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/tokenizers-0.5.2+computecanada-cp37-cp37m-linux_x86_64.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/nix/avx2/torch-1.4.0+computecanada-cp37-cp37m-linux_x86_64.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/torchtext-0.6.0+computecanada-py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/torchvision-0.8.2+computecanada-cp37-cp37m-linux_x86_64.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/transformers-2.5.1+computecanada-py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/urllib3-1.26.7+computecanada-py2.py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/tqdm-4.63.0+computecanada-py2.py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/joblib-1.1.0+computecanada-py2.py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/click-8.0.4+computecanada-py3-none-any.whl
ERROR: Could not find a version that satisfies the requirement regex>=2021.8.3 (from nltk) (from versions: 2018.1.10+computecanada, 2019.11.1+computecanada, 2020.11.13+computecanada)
ERROR: No matching distribution found for regex>=2021.8.3
Looking in links: /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/nix/avx2, /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/nix/generic, /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic
ERROR: Could not find a version that satisfies the requirement numpy==1.20.0+computacanada (from versions: 1.15.0+computecanada, 1.15.2+computecanada, 1.15.4+computecanada, 1.16.0+computecanada, 1.16.2+computecanada, 1.16.3+computecanada, 1.17.4+computecanada, 1.18.1+computecanada, 1.18.4+computecanada, 1.19.1+computecanada, 1.19.2+computecanada, 1.20.2+computecanada)
ERROR: No matching distribution found for numpy==1.20.0+computacanada
Looking in links: /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/nix/avx2, /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/nix/generic, /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/wandb-0.12.5+computecanada-py2.py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/docker_pycreds-0.4.0+computecanada-py2.py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/shortuuid-1.0.1+computecanada-py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/subprocess32-3.5.4+computecanada-py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/promise-2.3+computecanada-py3-none-any.whl
Requirement already satisfied: python-dateutil>=2.6.1 in /cvmfs/soft.computecanada.ca/easybuild/software/2017/Core/scipy-stack/2019a/lib/python3.7/site-packages (from wandb) (2.7.5)
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/click-8.0.4+computecanada-py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/psutil-5.7.3+computecanada-cp37-cp37m-linux_x86_64.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/configparser-5.0.2+computecanada-py3-none-any.whl
Requirement already satisfied: requests<3,>=2.0.0 in /cvmfs/soft.computecanada.ca/easybuild/software/2017/Core/scipy-stack/2019a/lib/python3.7/site-packages (from wandb) (2.21.0)
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/GitPython-3.1.24+computecanada-py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/protobuf-3.19.4+computecanada-py2.py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/sentry_sdk-1.5.0+computecanada-py2.py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/yaspin-2.1.0+computecanada-py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/PyYAML-5.3.1+computecanada-cp37-cp37m-linux_x86_64.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/pathtools-0.1.2+computecanada-py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/six-1.16.0+computecanada-py2.py3-none-any.whl
Requirement already satisfied: importlib-metadata in /cvmfs/soft.computecanada.ca/easybuild/software/2017/Core/scipy-stack/2019a/lib/python3.7/site-packages (from Click!=8.0.0,>=7.0->wandb) (0.8)
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/typing_extensions-4.0.1+computecanada-py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/gitdb-4.0.9+computecanada-py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/smmap-5.0.0+computecanada-py3-none-any.whl
Requirement already satisfied: idna<2.9,>=2.5 in /cvmfs/soft.computecanada.ca/easybuild/software/2017/Core/scipy-stack/2019a/lib/python3.7/site-packages (from requests<3,>=2.0.0->wandb) (2.8)
Requirement already satisfied: certifi>=2017.4.17 in /cvmfs/soft.computecanada.ca/easybuild/software/2017/Core/scipy-stack/2019a/lib/python3.7/site-packages (from requests<3,>=2.0.0->wandb) (2018.11.29)
Requirement already satisfied: urllib3<1.25,>=1.21.1 in /cvmfs/soft.computecanada.ca/easybuild/software/2017/Core/scipy-stack/2019a/lib/python3.7/site-packages (from requests<3,>=2.0.0->wandb) (1.24.1)
Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /cvmfs/soft.computecanada.ca/easybuild/software/2017/Core/scipy-stack/2019a/lib/python3.7/site-packages (from requests<3,>=2.0.0->wandb) (3.0.4)
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/termcolor-1.1.0+computecanada-py3-none-any.whl
Requirement already satisfied: zipp>=0.3.2 in /cvmfs/soft.computecanada.ca/easybuild/software/2017/Core/scipy-stack/2019a/lib/python3.7/site-packages (from importlib-metadata->Click!=8.0.0,>=7.0->wandb) (0.3.3)
Installing collected packages: smmap, typing-extensions, termcolor, six, gitdb, yaspin, subprocess32, shortuuid, sentry-sdk, PyYAML, psutil, protobuf, promise, pathtools, GitPython, docker-pycreds, configparser, Click, wandb
  Attempting uninstall: six
    Found existing installation: six 1.12.0
    Not uninstalling six at /cvmfs/soft.computecanada.ca/easybuild/software/2017/Core/scipy-stack/2019a/lib/python3.7/site-packages, outside environment /localscratch/yinan.29163121.0/env
    Can't uninstall 'six'. No files were found to uninstall.
Successfully installed Click-8.0.4+computecanada GitPython-3.1.24+computecanada PyYAML-5.3.1+computecanada configparser-5.0.2+computecanada docker-pycreds-0.4.0+computecanada gitdb-4.0.9+computecanada pathtools-0.1.2+computecanada promise-2.3+computecanada protobuf-3.19.4+computecanada psutil-5.7.3+computecanada sentry-sdk-1.5.0+computecanada shortuuid-1.0.1+computecanada six-1.16.0+computecanada smmap-5.0.0+computecanada subprocess32-3.5.4+computecanada termcolor-1.1.0+computecanada typing-extensions-4.0.1+computecanada wandb-0.12.5+computecanada yaspin-2.1.0+computecanada
Looking in links: /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/nix/avx2, /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/nix/generic, /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic
ERROR: Could not find a version that satisfies the requirement sagemaker (from versions: none)
ERROR: No matching distribution found for sagemaker
Looking in links: /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/nix/avx2, /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/nix/generic, /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/torch-1.9.1+computecanada-cp37-cp37m-linux_x86_64.whl
Requirement already satisfied: typing-extensions in /localscratch/yinan.29163121.0/env/lib/python3.7/site-packages (from torch) (4.0.1+computecanada)
Installing collected packages: torch
Successfully installed torch-1.9.1+computecanada
Looking in links: /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/nix/avx2, /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/nix/generic, /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/transformers-2.5.1+computecanada-py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/boto3-1.21.14+computecanada-py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/sentencepiece-0.1.91+computecanada-cp37-cp37m-linux_x86_64.whl
Requirement already satisfied: numpy in /cvmfs/soft.computecanada.ca/easybuild/software/2017/Core/scipy-stack/2019a/lib/python3.7/site-packages (from transformers==2.5.1+computecanada) (1.16.0)
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/sacremoses-0.0.46+computecanada-py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/tqdm-4.63.0+computecanada-py2.py3-none-any.whl
Requirement already satisfied: requests in /cvmfs/soft.computecanada.ca/easybuild/software/2017/Core/scipy-stack/2019a/lib/python3.7/site-packages (from transformers==2.5.1+computecanada) (2.21.0)
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/filelock-3.4.2+computecanada-py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/regex-2020.11.13+computecanada-cp37-cp37m-linux_x86_64.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/tokenizers-0.5.2+computecanada-cp37-cp37m-linux_x86_64.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/s3transfer-0.5.1+computecanada-py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/botocore-1.24.14+computecanada-py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/jmespath-0.10.0+computecanada-py2.py3-none-any.whl
Requirement already satisfied: python-dateutil<3.0.0,>=2.1 in /cvmfs/soft.computecanada.ca/easybuild/software/2017/Core/scipy-stack/2019a/lib/python3.7/site-packages (from botocore<1.25.0,>=1.24.14->boto3->transformers==2.5.1+computecanada) (2.7.5)
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/urllib3-1.26.8+computecanada-py2.py3-none-any.whl
Requirement already satisfied: six>=1.5 in /localscratch/yinan.29163121.0/env/lib/python3.7/site-packages (from python-dateutil<3.0.0,>=2.1->botocore<1.25.0,>=1.24.14->boto3->transformers==2.5.1+computecanada) (1.16.0+computecanada)
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/requests-2.27.1+computecanada-py2.py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/charset_normalizer-2.0.12+computecanada-py3-none-any.whl
Requirement already satisfied: certifi>=2017.4.17 in /cvmfs/soft.computecanada.ca/easybuild/software/2017/Core/scipy-stack/2019a/lib/python3.7/site-packages (from requests->transformers==2.5.1+computecanada) (2018.11.29)
Requirement already satisfied: idna<4,>=2.5 in /cvmfs/soft.computecanada.ca/easybuild/software/2017/Core/scipy-stack/2019a/lib/python3.7/site-packages (from requests->transformers==2.5.1+computecanada) (2.8)
Requirement already satisfied: click in /localscratch/yinan.29163121.0/env/lib/python3.7/site-packages (from sacremoses->transformers==2.5.1+computecanada) (8.0.4+computecanada)
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/joblib-1.1.0+computecanada-py2.py3-none-any.whl
Requirement already satisfied: importlib-metadata in /cvmfs/soft.computecanada.ca/easybuild/software/2017/Core/scipy-stack/2019a/lib/python3.7/site-packages (from click->sacremoses->transformers==2.5.1+computecanada) (0.8)
Requirement already satisfied: zipp>=0.3.2 in /cvmfs/soft.computecanada.ca/easybuild/software/2017/Core/scipy-stack/2019a/lib/python3.7/site-packages (from importlib-metadata->click->sacremoses->transformers==2.5.1+computecanada) (0.3.3)
Installing collected packages: urllib3, jmespath, botocore, tqdm, s3transfer, regex, joblib, charset-normalizer, tokenizers, sentencepiece, sacremoses, requests, filelock, boto3, transformers
  Attempting uninstall: urllib3
    Found existing installation: urllib3 1.24.1
    Not uninstalling urllib3 at /cvmfs/soft.computecanada.ca/easybuild/software/2017/Core/scipy-stack/2019a/lib/python3.7/site-packages, outside environment /localscratch/yinan.29163121.0/env
    Can't uninstall 'urllib3'. No files were found to uninstall.
  Attempting uninstall: requests
    Found existing installation: requests 2.21.0
    Not uninstalling requests at /cvmfs/soft.computecanada.ca/easybuild/software/2017/Core/scipy-stack/2019a/lib/python3.7/site-packages, outside environment /localscratch/yinan.29163121.0/env
    Can't uninstall 'requests'. No files were found to uninstall.
Successfully installed boto3-1.21.14+computecanada botocore-1.24.14+computecanada charset-normalizer-2.0.12+computecanada filelock-3.4.2+computecanada jmespath-0.10.0+computecanada joblib-1.1.0+computecanada regex-2020.11.13+computecanada requests-2.27.1+computecanada s3transfer-0.5.1+computecanada sacremoses-0.0.46+computecanada sentencepiece-0.1.91+computecanada tokenizers-0.5.2+computecanada tqdm-4.63.0+computecanada transformers-2.5.1+computecanada urllib3-1.26.8+computecanada
Looking in links: /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/nix/avx2, /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/nix/generic, /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/tensorflow_gpu-2.3.0+computecanada-cp37-cp37m-linux_x86_64.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/gast-0.3.3+computecanada-py3-none-any.whl
Requirement already satisfied: wheel>=0.26 in /localscratch/yinan.29163121.0/env/lib/python3.7/site-packages (from tensorflow_gpu==2.3.0+computecanada) (0.33.4)
Requirement already satisfied: numpy<1.19.0,>=1.16.0 in /cvmfs/soft.computecanada.ca/easybuild/software/2017/Core/scipy-stack/2019a/lib/python3.7/site-packages (from tensorflow_gpu==2.3.0+computecanada) (1.16.0)
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/opt_einsum-3.3.0+computecanada-py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/tensorboard-2.8.0+computecanada-py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/grpcio-1.38.0+computecanada-cp37-cp37m-linux_x86_64.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/wrapt-1.11.2+computecanada-cp37-cp37m-linux_x86_64.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/nix/generic/scipy-1.4.1+computecanada-cp37-cp37m-linux_x86_64.whl
Requirement already satisfied: protobuf>=3.9.2 in /localscratch/yinan.29163121.0/env/lib/python3.7/site-packages (from tensorflow_gpu==2.3.0+computecanada) (3.19.4+computecanada)
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/tensorflow_estimator-2.3.0+computecanada-py2.py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/Keras_Preprocessing-1.1.2+computecanada-py3-none-any.whl
Requirement already satisfied: termcolor>=1.1.0 in /localscratch/yinan.29163121.0/env/lib/python3.7/site-packages (from tensorflow_gpu==2.3.0+computecanada) (1.1.0+computecanada)
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/absl_py-1.0.0+computecanada-py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/astunparse-1.6.3+computecanada-py2.py3-none-any.whl
Requirement already satisfied: six>=1.12.0 in /localscratch/yinan.29163121.0/env/lib/python3.7/site-packages (from tensorflow_gpu==2.3.0+computecanada) (1.16.0+computecanada)
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/google_pasta-0.2.0+computecanada-py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/nix/avx2/h5py-2.10.0+computecanada-cp37-cp37m-linux_x86_64.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/Werkzeug-2.0.3+computecanada-py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/google_auth-2.3.3+computecanada-py2.py3-none-any.whl
Requirement already satisfied: requests<3,>=2.21.0 in /localscratch/yinan.29163121.0/env/lib/python3.7/site-packages (from tensorboard<3,>=2.3.0->tensorflow_gpu==2.3.0+computecanada) (2.27.1+computecanada)
Requirement already satisfied: setuptools>=41.0.0 in /localscratch/yinan.29163121.0/env/lib/python3.7/site-packages (from tensorboard<3,>=2.3.0->tensorflow_gpu==2.3.0+computecanada) (41.0.1)
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/google_auth_oauthlib-0.4.6+computecanada-py2.py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/tensorboard_data_server-0.6.1+computecanada-py3-none-linux_x86_64.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/tensorboard_plugin_wit-1.8.0+computecanada-py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/Markdown-3.3.6+computecanada-py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/pyasn1_modules-0.2.8+computecanada-py2.py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/rsa-4.8+computecanada-py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/cachetools-4.2.4+computecanada-py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/requests_oauthlib-1.3.0+computecanada-py2.py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/importlib_metadata-4.10.1+computecanada-py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/zipp-3.7.0+computecanada-py3-none-any.whl
Requirement already satisfied: typing-extensions>=3.6.4 in /localscratch/yinan.29163121.0/env/lib/python3.7/site-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard<3,>=2.3.0->tensorflow_gpu==2.3.0+computecanada) (4.0.1+computecanada)
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/pyasn1-0.4.8+computecanada-py2.py3-none-any.whl
Requirement already satisfied: certifi>=2017.4.17 in /cvmfs/soft.computecanada.ca/easybuild/software/2017/Core/scipy-stack/2019a/lib/python3.7/site-packages (from requests<3,>=2.21.0->tensorboard<3,>=2.3.0->tensorflow_gpu==2.3.0+computecanada) (2018.11.29)
Requirement already satisfied: urllib3<1.27,>=1.21.1 in /localscratch/yinan.29163121.0/env/lib/python3.7/site-packages (from requests<3,>=2.21.0->tensorboard<3,>=2.3.0->tensorflow_gpu==2.3.0+computecanada) (1.26.8+computecanada)
Requirement already satisfied: idna<4,>=2.5 in /cvmfs/soft.computecanada.ca/easybuild/software/2017/Core/scipy-stack/2019a/lib/python3.7/site-packages (from requests<3,>=2.21.0->tensorboard<3,>=2.3.0->tensorflow_gpu==2.3.0+computecanada) (2.8)
Requirement already satisfied: charset-normalizer~=2.0.0 in /localscratch/yinan.29163121.0/env/lib/python3.7/site-packages (from requests<3,>=2.21.0->tensorboard<3,>=2.3.0->tensorflow_gpu==2.3.0+computecanada) (2.0.12+computecanada)
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/oauthlib-3.1.1+computecanada-py2.py3-none-any.whl
Installing collected packages: pyasn1, zipp, rsa, pyasn1-modules, oauthlib, cachetools, requests-oauthlib, importlib-metadata, google-auth, werkzeug, tensorboard-plugin-wit, tensorboard-data-server, markdown, grpcio, google-auth-oauthlib, absl-py, wrapt, tensorflow-estimator, tensorboard, scipy, opt-einsum, keras-preprocessing, h5py, google-pasta, gast, astunparse, tensorflow-gpu
  Attempting uninstall: pyasn1
    Found existing installation: pyasn1 0.4.3
    Not uninstalling pyasn1 at /cvmfs/soft.computecanada.ca/easybuild/software/2017/Core/scipy-stack/2019a/lib/python3.7/site-packages, outside environment /localscratch/yinan.29163121.0/env
    Can't uninstall 'pyasn1'. No files were found to uninstall.
  Attempting uninstall: zipp
    Found existing installation: zipp 0.3.3
    Not uninstalling zipp at /cvmfs/soft.computecanada.ca/easybuild/software/2017/Core/scipy-stack/2019a/lib/python3.7/site-packages, outside environment /localscratch/yinan.29163121.0/env
    Can't uninstall 'zipp'. No files were found to uninstall.
  Attempting uninstall: importlib-metadata
    Found existing installation: importlib-metadata 0.8
    Not uninstalling importlib-metadata at /cvmfs/soft.computecanada.ca/easybuild/software/2017/Core/scipy-stack/2019a/lib/python3.7/site-packages, outside environment /localscratch/yinan.29163121.0/env
    Can't uninstall 'importlib-metadata'. No files were found to uninstall.
  Attempting uninstall: scipy
    Found existing installation: scipy 1.2.0
    Not uninstalling scipy at /cvmfs/soft.computecanada.ca/easybuild/software/2017/Core/scipy-stack/2019a/lib/python3.7/site-packages, outside environment /localscratch/yinan.29163121.0/env
    Can't uninstall 'scipy'. No files were found to uninstall.
Successfully installed absl-py-1.0.0+computecanada astunparse-1.6.3+computecanada cachetools-4.2.4+computecanada gast-0.3.3+computecanada google-auth-2.3.3+computecanada google-auth-oauthlib-0.4.6+computecanada google-pasta-0.2.0+computecanada grpcio-1.38.0+computecanada h5py-2.10.0+computecanada importlib-metadata-4.10.1+computecanada keras-preprocessing-1.1.2+computecanada markdown-3.3.6+computecanada oauthlib-3.1.1+computecanada opt-einsum-3.3.0+computecanada pyasn1-0.4.8+computecanada pyasn1-modules-0.2.8+computecanada requests-oauthlib-1.3.0+computecanada rsa-4.8+computecanada scipy-1.4.1+computecanada tensorboard-2.8.0+computecanada tensorboard-data-server-0.6.1+computecanada tensorboard-plugin-wit-1.8.0+computecanada tensorflow-estimator-2.3.0+computecanada tensorflow-gpu-2.3.0+computecanada werkzeug-2.0.3+computecanada wrapt-1.11.2+computecanada zipp-3.7.0+computecanada
Looking in links: /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/nix/avx2, /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/nix/generic, /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/keras-2.8.0+computecanada-py2.py3-none-any.whl
Installing collected packages: Keras
Successfully installed Keras-2.8.0+computecanada
Looking in links: /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/nix/avx2, /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/nix/generic, /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/urllib3-1.26.7+computecanada-py2.py3-none-any.whl
Installing collected packages: urllib3
  Attempting uninstall: urllib3
    Found existing installation: urllib3 1.26.8+computecanada
    Uninstalling urllib3-1.26.8+computecanada:
      Successfully uninstalled urllib3-1.26.8+computecanada
Successfully installed urllib3-1.26.7+computecanada
Looking in links: /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/nix/avx2, /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/nix/generic, /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/nltk-3.7+computecanada-py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/nltk-3.6.5+computecanada-py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/nltk-3.6.3+computecanada-py3-none-any.whl
Requirement already satisfied: tqdm in /localscratch/yinan.29163121.0/env/lib/python3.7/site-packages (from nltk) (4.63.0+computecanada)
Requirement already satisfied: joblib in /localscratch/yinan.29163121.0/env/lib/python3.7/site-packages (from nltk) (1.1.0+computecanada)
Requirement already satisfied: regex in /localscratch/yinan.29163121.0/env/lib/python3.7/site-packages (from nltk) (2020.11.13+computecanada)
Requirement already satisfied: click in /localscratch/yinan.29163121.0/env/lib/python3.7/site-packages (from nltk) (8.0.4+computecanada)
Requirement already satisfied: importlib-metadata in /localscratch/yinan.29163121.0/env/lib/python3.7/site-packages (from click->nltk) (4.10.1+computecanada)
Requirement already satisfied: typing-extensions>=3.6.4 in /localscratch/yinan.29163121.0/env/lib/python3.7/site-packages (from importlib-metadata->click->nltk) (4.0.1+computecanada)
Requirement already satisfied: zipp>=0.5 in /localscratch/yinan.29163121.0/env/lib/python3.7/site-packages (from importlib-metadata->click->nltk) (3.7.0+computecanada)
Installing collected packages: nltk
Successfully installed nltk-3.6.3+computecanada
Looking in links: /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/nix/avx2, /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/nix/generic, /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/scikit_learn-0.22.1+computecanada-cp37-cp37m-linux_x86_64.whl
Requirement already satisfied: joblib>=0.11 in /localscratch/yinan.29163121.0/env/lib/python3.7/site-packages (from scikit-learn==0.22.1) (1.1.0+computecanada)
Requirement already satisfied: scipy>=0.17.0 in /localscratch/yinan.29163121.0/env/lib/python3.7/site-packages (from scikit-learn==0.22.1) (1.4.1+computecanada)
Requirement already satisfied: numpy>=1.11.0 in /cvmfs/soft.computecanada.ca/easybuild/software/2017/Core/scipy-stack/2019a/lib/python3.7/site-packages (from scikit-learn==0.22.1) (1.16.0)
Installing collected packages: scikit-learn
Successfully installed scikit-learn-0.22.1+computecanada
Looking in links: /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/nix/avx2, /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/nix/generic, /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic
Requirement already satisfied: tokenizers==0.5.2 in /localscratch/yinan.29163121.0/env/lib/python3.7/site-packages (0.5.2+computecanada)
wandb: Appending key for api.wandb.ai to your netrc file: /home/yinan/.netrc
Starting Task
2022-03-17 22:13:33.990387: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1
[nltk_data] Downloading package stopwords to /home/yinan/nltk_data...
[nltk_data]   Package stopwords is already up-to-date!
[nltk_data] Downloading package wordnet to /home/yinan/nltk_data...
[nltk_data]   Package wordnet is already up-to-date!
wandb: Currently logged in as: yinanazhou (use `wandb login --relogin` to force relogin)
wandb: wandb version 0.12.11 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
2022-03-17 22:13:41.384366: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1
wandb: Tracking run with wandb version 0.12.5
wandb: Syncing run worthy-fog-2
wandb: ⭐️ View project at https://wandb.ai/yinanazhou/xl_512_bs_8_lr_1e06_es_5_lc_False_nr_False_sr_True_stem_False_lemma_False_repeat_1_fold_1
wandb: 🚀 View run at https://wandb.ai/yinanazhou/xl_512_bs_8_lr_1e06_es_5_lc_False_nr_False_sr_True_stem_False_lemma_False_repeat_1_fold_1/runs/2mqnfz0k
wandb: Run data is saved locally in /project/6002780/yinan/Thesis_MER_Lyrics/lyric-emotion/wandb/run-20220317_221339-2mqnfz0k
wandb: Run `wandb offline` to turn off syncing.

Validation loss decreased (inf --> 1.427634).  Saving model ...
Validation loss decreased (1.427634 --> 1.407890).  Saving model ...
Validation loss decreased (1.407890 --> 1.391092).  Saving model ...
Validation loss decreased (1.391092 --> 1.378354).  Saving model ...
Validation loss decreased (1.378354 --> 1.368354).  Saving model ...
Validation loss decreased (1.368354 --> 1.358864).  Saving model ...
Validation loss decreased (1.358864 --> 1.351233).  Saving model ...
Validation loss decreased (1.351233 --> 1.344785).  Saving model ...
Validation loss decreased (1.344785 --> 1.339057).  Saving model ...
Validation loss decreased (1.339057 --> 1.332830).  Saving model ...
Validation loss decreased (1.332830 --> 1.325896).  Saving model ...
Validation loss decreased (1.325896 --> 1.320483).  Saving model ...
Validation loss decreased (1.320483 --> 1.313196).  Saving model ...
Validation loss decreased (1.313196 --> 1.306760).  Saving model ...
Validation loss decreased (1.306760 --> 1.299403).  Saving model ...
Validation loss decreased (1.299403 --> 1.291941).  Saving model ...
Validation loss decreased (1.291941 --> 1.284379).  Saving model ...
Validation loss decreased (1.284379 --> 1.277515).  Saving model ...
Validation loss decreased (1.277515 --> 1.269098).  Saving model ...
Validation loss decreased (1.269098 --> 1.261555).  Saving model ...
Validation loss decreased (1.261555 --> 1.254810).  Saving model ...
Validation loss decreased (1.254810 --> 1.247065).  Saving model ...
Validation loss decreased (1.247065 --> 1.240767).  Saving model ...
Validation loss decreased (1.240767 --> 1.232513).  Saving model ...
Validation loss decreased (1.232513 --> 1.225693).  Saving model ...
Validation loss decreased (1.225693 --> 1.218072).  Saving model ...
Validation loss decreased (1.218072 --> 1.214171).  Saving model ...
Validation loss decreased (1.214171 --> 1.207632).  Saving model ...
Validation loss decreased (1.207632 --> 1.199322).  Saving model ...
Validation loss decreased (1.199322 --> 1.195482).  Saving model ...
Validation loss decreased (1.195482 --> 1.187913).  Saving model ...
Validation loss decreased (1.187913 --> 1.181648).  Saving model ...
Validation loss decreased (1.181648 --> 1.180704).  Saving model ...
Validation loss decreased (1.180704 --> 1.173219).  Saving model ...
Validation loss decreased (1.173219 --> 1.169318).  Saving model ...
Validation loss decreased (1.169318 --> 1.165172).  Saving model ...
Validation loss decreased (1.165172 --> 1.160725).  Saving model ...
Validation loss decreased (1.160725 --> 1.154045).  Saving model ...
Validation loss decreased (1.154045 --> 1.151521).  Saving model ...
Validation loss decreased (1.151521 --> 1.147711).  Saving model ...
Validation loss decreased (1.147711 --> 1.142857).  Saving model ...
Validation loss decreased (1.142857 --> 1.137463).  Saving model ...
Validation loss decreased (1.137463 --> 1.134584).  Saving model ...
Validation loss decreased (1.134584 --> 1.130979).  Saving model ...
Validation loss decreased (1.130979 --> 1.125704).  Saving model ...
Validation loss decreased (1.125704 --> 1.120424).  Saving model ...
Validation loss decreased (1.120424 --> 1.117576).  Saving model ...
Validation loss decreased (1.117576 --> 1.113193).  Saving model ...
Validation loss decreased (1.113193 --> 1.109162).  Saving model ...
Validation loss decreased (1.109162 --> 1.105871).  Saving model ...
Validation loss decreased (1.105871 --> 1.100484).  Saving model ...
Validation loss decreased (1.100484 --> 1.095978).  Saving model ...
Validation loss decreased (1.095978 --> 1.090830).  Saving model ...
Validation loss decreased (1.090830 --> 1.087201).  Saving model ...
Validation loss decreased (1.087201 --> 1.086079).  Saving model ...
Validation loss decreased (1.086079 --> 1.082679).  Saving model ...
Validation loss decreased (1.082679 --> 1.080545).  Saving model ...
Validation loss decreased (1.080545 --> 1.077914).  Saving model ...
Validation loss decreased (1.077914 --> 1.073281).  Saving model ...
Validation loss decreased (1.073281 --> 1.072754).  Saving model ...
Validation loss decreased (1.072754 --> 1.071195).  Saving model ...
Validation loss decreased (1.071195 --> 1.068948).  Saving model ...
Validation loss decreased (1.068948 --> 1.063747).  Saving model ...
Validation loss decreased (1.063747 --> 1.062170).  Saving model ...
Validation loss decreased (1.062170 --> 1.060296).  Saving model ...
Validation loss decreased (1.060296 --> 1.055550).  Saving model ...
Validation loss decreased (1.055550 --> 1.054609).  Saving model ...
Validation loss decreased (1.054609 --> 1.054045).  Saving model ...
Validation loss decreased (1.054045 --> 1.050805).  Saving model ...
Validation loss decreased (1.050805 --> 1.045988).  Saving model ...
Validation loss decreased (1.045988 --> 1.044792).  Saving model ...
Validation loss decreased (1.044792 --> 1.041103).  Saving model ...
Validation loss decreased (1.041103 --> 1.038043).  Saving model ...
Validation loss decreased (1.038043 --> 1.034067).  Saving model ...
Validation loss decreased (1.034067 --> 1.032766).  Saving model ...
Validation loss decreased (1.032766 --> 1.030950).  Saving model ...
EarlyStopping counter: 1 out of 5.0
Validation loss decreased (1.030950 --> 1.030262).  Saving model ...
Validation loss decreased (1.030262 --> 1.024752).  Saving model ...
EarlyStopping counter: 1 out of 5.0
Validation loss decreased (1.024752 --> 1.023614).  Saving model ...
Validation loss decreased (1.023614 --> 1.020147).  Saving model ...
Validation loss decreased (1.020147 --> 1.018712).  Saving model ...
Validation loss decreased (1.018712 --> 1.017526).  Saving model ...
Validation loss decreased (1.017526 --> 1.012715).  Saving model ...
Validation loss decreased (1.012715 --> 1.009871).  Saving model ...
Validation loss decreased (1.009871 --> 1.009408).  Saving model ...
EarlyStopping counter: 1 out of 5.0
EarlyStopping counter: 2 out of 5.0
Validation loss decreased (1.009408 --> 1.007126).  Saving model ...
Validation loss decreased (1.007126 --> 1.007018).  Saving model ...
Validation loss decreased (1.007018 --> 1.005920).  Saving model ...
Validation loss decreased (1.005920 --> 1.003522).  Saving model ...
EarlyStopping counter: 1 out of 5.0
EarlyStopping counter: 2 out of 5.0
Validation loss decreased (1.003522 --> 1.000777).  Saving model ...
Validation loss decreased (1.000777 --> 1.000668).  Saving model ...
Validation loss decreased (1.000668 --> 0.999832).  Saving model ...
Validation loss decreased (0.999832 --> 0.998146).  Saving model ...
EarlyStopping counter: 1 out of 5.0
Validation loss decreased (0.998146 --> 0.997942).  Saving model ...
EarlyStopping counter: 1 out of 5.0
Validation loss decreased (0.997942 --> 0.995829).  Saving model ...
EarlyStopping counter: 1 out of 5.0
EarlyStopping counter: 2 out of 5.0
Validation loss decreased (0.995829 --> 0.995735).  Saving model ...
Validation loss decreased (0.995735 --> 0.995070).  Saving model ...
Validation loss decreased (0.995070 --> 0.995024).  Saving model ...
Validation loss decreased (0.995024 --> 0.992044).  Saving model ...
Validation loss decreased (0.992044 --> 0.990643).  Saving model ...
EarlyStopping counter: 1 out of 5.0
EarlyStopping counter: 2 out of 5.0
EarlyStopping counter: 3 out of 5.0
EarlyStopping counter: 4 out of 5.0
EarlyStopping counter: 5 out of 5.0
/localscratch/yinan.29163121.0/env/lib/python3.7/site-packages/torch/nn/functional.py:1794: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.
  warnings.warn("nn.functional.tanh is deprecated. Use torch.tanh instead.")
/localscratch/yinan.29163121.0/env/lib/python3.7/site-packages/transformers/optimization.py:155: UserWarning: This overload of add_ is deprecated:
	add_(Number alpha, Tensor other)
Consider using one of the following signatures instead:
	add_(Tensor other, *, Number alpha) (Triggered internally at  ../torch/csrc/utils/python_arg_parser.cpp:1025.)
  exp_avg.mul_(beta1).add_(1.0 - beta1, grad)
wandb: Waiting for W&B process to finish, PID 204581... (success).
wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: \ 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: | 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: / 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: \ 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: | 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: / 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: \ 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: | 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: / 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb:                                                                                
wandb: Run history:
wandb:     e_F1 ▁▂▃▄▅▅▅▅▅▆▆▆▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇█████████████
wandb:   e_loss █▇▇▇▆▆▆▅▅▅▄▄▄▄▃▃▃▃▃▂▂▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁
wandb:     t_F1 ▁▂▃▂▃▃▄▄▄▄▅▅▅▅▆▆▆▆▇▆▇▆▆▇▇▇▇▇▇▇▇▇▇▇▇█▇█▇█
wandb:   t_loss ██▇▇▇▇▆▆▆▆▅▅▅▅▄▄▄▄▃▄▃▃▃▃▃▃▂▃▂▂▂▂▂▂▂▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:     e_F1 57.98486
wandb:   e_loss 0.99356
wandb:     t_F1 69.76965
wandb:   t_loss 0.77652
wandb: 
wandb: Synced 4 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Synced worthy-fog-2: https://wandb.ai/yinanazhou/xl_512_bs_8_lr_1e06_es_5_lc_False_nr_False_sr_True_stem_False_lemma_False_repeat_1_fold_1/runs/2mqnfz0k
wandb: Find logs at: ./wandb/run-20220317_221339-2mqnfz0k/logs/debug.log
wandb: 

wandb: wandb version 0.12.11 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
2022-03-17 23:29:23.319673: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1
wandb: Tracking run with wandb version 0.12.5
wandb: Syncing run lilac-dust-2
wandb: ⭐️ View project at https://wandb.ai/yinanazhou/xl_512_bs_8_lr_1e06_es_5_lc_False_nr_False_sr_True_stem_False_lemma_False_repeat_1_fold_2
wandb: 🚀 View run at https://wandb.ai/yinanazhou/xl_512_bs_8_lr_1e06_es_5_lc_False_nr_False_sr_True_stem_False_lemma_False_repeat_1_fold_2/runs/2ga490ah
wandb: Run data is saved locally in /project/6002780/yinan/Thesis_MER_Lyrics/lyric-emotion/wandb/run-20220317_232921-2ga490ah
wandb: Run `wandb offline` to turn off syncing.

Validation loss decreased (inf --> 1.413348).  Saving model ...
Validation loss decreased (1.413348 --> 1.400915).  Saving model ...
Validation loss decreased (1.400915 --> 1.392376).  Saving model ...
Validation loss decreased (1.392376 --> 1.385495).  Saving model ...
Validation loss decreased (1.385495 --> 1.379109).  Saving model ...
Validation loss decreased (1.379109 --> 1.373556).  Saving model ...
Validation loss decreased (1.373556 --> 1.368965).  Saving model ...
Validation loss decreased (1.368965 --> 1.364227).  Saving model ...
Validation loss decreased (1.364227 --> 1.359714).  Saving model ...
Validation loss decreased (1.359714 --> 1.355284).  Saving model ...
Validation loss decreased (1.355284 --> 1.351021).  Saving model ...
Validation loss decreased (1.351021 --> 1.346568).  Saving model ...
Validation loss decreased (1.346568 --> 1.342035).  Saving model ...
Validation loss decreased (1.342035 --> 1.337409).  Saving model ...
Validation loss decreased (1.337409 --> 1.333313).  Saving model ...
Validation loss decreased (1.333313 --> 1.328757).  Saving model ...
Validation loss decreased (1.328757 --> 1.323585).  Saving model ...
Validation loss decreased (1.323585 --> 1.318071).  Saving model ...
Validation loss decreased (1.318071 --> 1.312239).  Saving model ...
Validation loss decreased (1.312239 --> 1.306922).  Saving model ...
Validation loss decreased (1.306922 --> 1.300872).  Saving model ...
Validation loss decreased (1.300872 --> 1.294913).  Saving model ...
Validation loss decreased (1.294913 --> 1.287801).  Saving model ...
Validation loss decreased (1.287801 --> 1.280970).  Saving model ...
Validation loss decreased (1.280970 --> 1.274799).  Saving model ...
Validation loss decreased (1.274799 --> 1.266662).  Saving model ...
Validation loss decreased (1.266662 --> 1.259619).  Saving model ...
Validation loss decreased (1.259619 --> 1.251373).  Saving model ...
Validation loss decreased (1.251373 --> 1.243149).  Saving model ...
Validation loss decreased (1.243149 --> 1.235243).  Saving model ...
Validation loss decreased (1.235243 --> 1.225179).  Saving model ...
Validation loss decreased (1.225179 --> 1.215518).  Saving model ...
Validation loss decreased (1.215518 --> 1.207564).  Saving model ...
Validation loss decreased (1.207564 --> 1.198282).  Saving model ...
Validation loss decreased (1.198282 --> 1.189867).  Saving model ...
Validation loss decreased (1.189867 --> 1.180875).  Saving model ...
Validation loss decreased (1.180875 --> 1.172913).  Saving model ...
Validation loss decreased (1.172913 --> 1.165315).  Saving model ...
Validation loss decreased (1.165315 --> 1.157705).  Saving model ...
Validation loss decreased (1.157705 --> 1.149902).  Saving model ...
Validation loss decreased (1.149902 --> 1.143200).  Saving model ...
Validation loss decreased (1.143200 --> 1.137632).  Saving model ...
Validation loss decreased (1.137632 --> 1.131843).  Saving model ...
Validation loss decreased (1.131843 --> 1.126027).  Saving model ...
Validation loss decreased (1.126027 --> 1.119518).  Saving model ...
Validation loss decreased (1.119518 --> 1.113888).  Saving model ...
Validation loss decreased (1.113888 --> 1.107471).  Saving model ...
Validation loss decreased (1.107471 --> 1.102689).  Saving model ...
Validation loss decreased (1.102689 --> 1.096581).  Saving model ...
Validation loss decreased (1.096581 --> 1.091394).  Saving model ...
Validation loss decreased (1.091394 --> 1.085298).  Saving model ...
Validation loss decreased (1.085298 --> 1.079353).  Saving model ...
Validation loss decreased (1.079353 --> 1.072461).  Saving model ...
Validation loss decreased (1.072461 --> 1.068324).  Saving model ...
Validation loss decreased (1.068324 --> 1.062954).  Saving model ...
Validation loss decreased (1.062954 --> 1.059028).  Saving model ...
Validation loss decreased (1.059028 --> 1.054327).  Saving model ...
Validation loss decreased (1.054327 --> 1.049397).  Saving model ...
Validation loss decreased (1.049397 --> 1.043955).  Saving model ...
Validation loss decreased (1.043955 --> 1.039360).  Saving model ...
Validation loss decreased (1.039360 --> 1.035109).  Saving model ...
Validation loss decreased (1.035109 --> 1.030789).  Saving model ...
Validation loss decreased (1.030789 --> 1.026636).  Saving model ...
Validation loss decreased (1.026636 --> 1.022786).  Saving model ...
Validation loss decreased (1.022786 --> 1.020450).  Saving model ...
Validation loss decreased (1.020450 --> 1.013793).  Saving model ...
Validation loss decreased (1.013793 --> 1.010904).  Saving model ...
Validation loss decreased (1.010904 --> 1.007224).  Saving model ...
Validation loss decreased (1.007224 --> 1.004316).  Saving model ...
Validation loss decreased (1.004316 --> 1.000479).  Saving model ...
Validation loss decreased (1.000479 --> 0.998786).  Saving model ...
Validation loss decreased (0.998786 --> 0.995092).  Saving model ...
Validation loss decreased (0.995092 --> 0.993451).  Saving model ...
Validation loss decreased (0.993451 --> 0.991589).  Saving model ...
Validation loss decreased (0.991589 --> 0.986849).  Saving model ...
Validation loss decreased (0.986849 --> 0.983669).  Saving model ...
Validation loss decreased (0.983669 --> 0.981759).  Saving model ...
Validation loss decreased (0.981759 --> 0.979481).  Saving model ...
Validation loss decreased (0.979481 --> 0.976918).  Saving model ...
Validation loss decreased (0.976918 --> 0.973881).  Saving model ...
Validation loss decreased (0.973881 --> 0.971007).  Saving model ...
Validation loss decreased (0.971007 --> 0.968547).  Saving model ...
Validation loss decreased (0.968547 --> 0.966306).  Saving model ...
Validation loss decreased (0.966306 --> 0.963046).  Saving model ...
Validation loss decreased (0.963046 --> 0.960855).  Saving model ...
Validation loss decreased (0.960855 --> 0.958217).  Saving model ...
Validation loss decreased (0.958217 --> 0.956068).  Saving model ...
EarlyStopping counter: 1 out of 5.0
Validation loss decreased (0.956068 --> 0.954907).  Saving model ...
Validation loss decreased (0.954907 --> 0.953231).  Saving model ...
Validation loss decreased (0.953231 --> 0.952259).  Saving model ...
Validation loss decreased (0.952259 --> 0.948727).  Saving model ...
Validation loss decreased (0.948727 --> 0.948284).  Saving model ...
Validation loss decreased (0.948284 --> 0.947495).  Saving model ...
Validation loss decreased (0.947495 --> 0.945426).  Saving model ...
Validation loss decreased (0.945426 --> 0.945295).  Saving model ...
EarlyStopping counter: 1 out of 5.0
EarlyStopping counter: 2 out of 5.0
Validation loss decreased (0.945295 --> 0.943819).  Saving model ...
Validation loss decreased (0.943819 --> 0.942674).  Saving model ...
Validation loss decreased (0.942674 --> 0.939236).  Saving model ...
Validation loss decreased (0.939236 --> 0.938938).  Saving model ...
Validation loss decreased (0.938938 --> 0.936931).  Saving model ...
EarlyStopping counter: 1 out of 5.0
EarlyStopping counter: 2 out of 5.0
EarlyStopping counter: 3 out of 5.0
EarlyStopping counter: 4 out of 5.0
Validation loss decreased (0.936931 --> 0.934177).  Saving model ...
EarlyStopping counter: 1 out of 5.0
EarlyStopping counter: 2 out of 5.0
Validation loss decreased (0.934177 --> 0.932730).  Saving model ...
EarlyStopping counter: 1 out of 5.0
EarlyStopping counter: 2 out of 5.0
EarlyStopping counter: 3 out of 5.0
EarlyStopping counter: 4 out of 5.0
EarlyStopping counter: 5 out of 5.0
/localscratch/yinan.29163121.0/env/lib/python3.7/site-packages/torch/nn/functional.py:1794: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.
  warnings.warn("nn.functional.tanh is deprecated. Use torch.tanh instead.")
wandb: Waiting for W&B process to finish, PID 208645... (success).
wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: \ 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: | 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: / 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: \ 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: | 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: / 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: \ 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: | 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: / 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb:                                                                                
wandb: Run history:
wandb:     e_F1 ▁▂▃▃▄▅▅▅▆▆▆▇▇▇▇▇▇▇▇█████████████████████
wandb:   e_loss ██▇▇▇▇▇▆▆▆▅▅▅▄▄▄▃▃▃▃▃▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁
wandb:     t_F1 ▁▁▂▂▃▃▃▃▄▄▄▅▅▅▅▅▆▆▆▆▆▆▇▆▇▇▇▇▇▇█▇▇███████
wandb:   t_loss ███▇▇▇▇▇▇▆▆▆▆▅▅▅▄▄▄▄▄▄▄▃▃▃▃▂▃▃▂▂▂▂▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:     e_F1 59.07915
wandb:   e_loss 0.93349
wandb:     t_F1 69.84589
wandb:   t_loss 0.80725
wandb: 
wandb: Synced 4 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Synced lilac-dust-2: https://wandb.ai/yinanazhou/xl_512_bs_8_lr_1e06_es_5_lc_False_nr_False_sr_True_stem_False_lemma_False_repeat_1_fold_2/runs/2ga490ah
wandb: Find logs at: ./wandb/run-20220317_232921-2ga490ah/logs/debug.log
wandb: 

wandb: wandb version 0.12.11 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
2022-03-18 00:44:46.749520: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1
wandb: Tracking run with wandb version 0.12.5
wandb: Syncing run apricot-eon-2
wandb: ⭐️ View project at https://wandb.ai/yinanazhou/xl_512_bs_8_lr_1e06_es_5_lc_False_nr_False_sr_True_stem_False_lemma_False_repeat_2_fold_1
wandb: 🚀 View run at https://wandb.ai/yinanazhou/xl_512_bs_8_lr_1e06_es_5_lc_False_nr_False_sr_True_stem_False_lemma_False_repeat_2_fold_1/runs/2xcvi1nv
wandb: Run data is saved locally in /project/6002780/yinan/Thesis_MER_Lyrics/lyric-emotion/wandb/run-20220318_004444-2xcvi1nv
wandb: Run `wandb offline` to turn off syncing.

Validation loss decreased (inf --> 1.483655).  Saving model ...
Validation loss decreased (1.483655 --> 1.454711).  Saving model ...
Validation loss decreased (1.454711 --> 1.433596).  Saving model ...
Validation loss decreased (1.433596 --> 1.416743).  Saving model ...
Validation loss decreased (1.416743 --> 1.404097).  Saving model ...
Validation loss decreased (1.404097 --> 1.393644).  Saving model ...
Validation loss decreased (1.393644 --> 1.385439).  Saving model ...
Validation loss decreased (1.385439 --> 1.378678).  Saving model ...
Validation loss decreased (1.378678 --> 1.372651).  Saving model ...
Validation loss decreased (1.372651 --> 1.367041).  Saving model ...
Validation loss decreased (1.367041 --> 1.361779).  Saving model ...
Validation loss decreased (1.361779 --> 1.356025).  Saving model ...
Validation loss decreased (1.356025 --> 1.349836).  Saving model ...
Validation loss decreased (1.349836 --> 1.344176).  Saving model ...
Validation loss decreased (1.344176 --> 1.338325).  Saving model ...
Validation loss decreased (1.338325 --> 1.332384).  Saving model ...
Validation loss decreased (1.332384 --> 1.326442).  Saving model ...
Validation loss decreased (1.326442 --> 1.319319).  Saving model ...
Validation loss decreased (1.319319 --> 1.312160).  Saving model ...
Validation loss decreased (1.312160 --> 1.304185).  Saving model ...
Validation loss decreased (1.304185 --> 1.295627).  Saving model ...
Validation loss decreased (1.295627 --> 1.286751).  Saving model ...
Validation loss decreased (1.286751 --> 1.278830).  Saving model ...
Validation loss decreased (1.278830 --> 1.271281).  Saving model ...
Validation loss decreased (1.271281 --> 1.264592).  Saving model ...
Validation loss decreased (1.264592 --> 1.253932).  Saving model ...
Validation loss decreased (1.253932 --> 1.245578).  Saving model ...
Validation loss decreased (1.245578 --> 1.236754).  Saving model ...
Validation loss decreased (1.236754 --> 1.230187).  Saving model ...
Validation loss decreased (1.230187 --> 1.220017).  Saving model ...
Validation loss decreased (1.220017 --> 1.212844).  Saving model ...
Validation loss decreased (1.212844 --> 1.205417).  Saving model ...
Validation loss decreased (1.205417 --> 1.198708).  Saving model ...
Validation loss decreased (1.198708 --> 1.192202).  Saving model ...
Validation loss decreased (1.192202 --> 1.184410).  Saving model ...
Validation loss decreased (1.184410 --> 1.175425).  Saving model ...
Validation loss decreased (1.175425 --> 1.167614).  Saving model ...
Validation loss decreased (1.167614 --> 1.163574).  Saving model ...
Validation loss decreased (1.163574 --> 1.158472).  Saving model ...
Validation loss decreased (1.158472 --> 1.151543).  Saving model ...
Validation loss decreased (1.151543 --> 1.143034).  Saving model ...
Validation loss decreased (1.143034 --> 1.137223).  Saving model ...
Validation loss decreased (1.137223 --> 1.129071).  Saving model ...
Validation loss decreased (1.129071 --> 1.122466).  Saving model ...
Validation loss decreased (1.122466 --> 1.120224).  Saving model ...
Validation loss decreased (1.120224 --> 1.115056).  Saving model ...
Validation loss decreased (1.115056 --> 1.109991).  Saving model ...
Validation loss decreased (1.109991 --> 1.103468).  Saving model ...
Validation loss decreased (1.103468 --> 1.095365).  Saving model ...
Validation loss decreased (1.095365 --> 1.093144).  Saving model ...
Validation loss decreased (1.093144 --> 1.087600).  Saving model ...
Validation loss decreased (1.087600 --> 1.081759).  Saving model ...
Validation loss decreased (1.081759 --> 1.076357).  Saving model ...
Validation loss decreased (1.076357 --> 1.073679).  Saving model ...
Validation loss decreased (1.073679 --> 1.068052).  Saving model ...
Validation loss decreased (1.068052 --> 1.063019).  Saving model ...
Validation loss decreased (1.063019 --> 1.059564).  Saving model ...
Validation loss decreased (1.059564 --> 1.055427).  Saving model ...
Validation loss decreased (1.055427 --> 1.049016).  Saving model ...
Validation loss decreased (1.049016 --> 1.046714).  Saving model ...
Validation loss decreased (1.046714 --> 1.044326).  Saving model ...
Validation loss decreased (1.044326 --> 1.038136).  Saving model ...
Validation loss decreased (1.038136 --> 1.035941).  Saving model ...
Validation loss decreased (1.035941 --> 1.032317).  Saving model ...
EarlyStopping counter: 1 out of 5.0
Validation loss decreased (1.032317 --> 1.027818).  Saving model ...
Validation loss decreased (1.027818 --> 1.026163).  Saving model ...
Validation loss decreased (1.026163 --> 1.021788).  Saving model ...
Validation loss decreased (1.021788 --> 1.017587).  Saving model ...
Validation loss decreased (1.017587 --> 1.012485).  Saving model ...
Validation loss decreased (1.012485 --> 1.008372).  Saving model ...
Validation loss decreased (1.008372 --> 1.006106).  Saving model ...
Validation loss decreased (1.006106 --> 1.004135).  Saving model ...
Validation loss decreased (1.004135 --> 1.002177).  Saving model ...
Validation loss decreased (1.002177 --> 1.000147).  Saving model ...
Validation loss decreased (1.000147 --> 0.997465).  Saving model ...
Validation loss decreased (0.997465 --> 0.992469).  Saving model ...
Validation loss decreased (0.992469 --> 0.990056).  Saving model ...
Validation loss decreased (0.990056 --> 0.987773).  Saving model ...
Validation loss decreased (0.987773 --> 0.986863).  Saving model ...
Validation loss decreased (0.986863 --> 0.982729).  Saving model ...
Validation loss decreased (0.982729 --> 0.982083).  Saving model ...
Validation loss decreased (0.982083 --> 0.979592).  Saving model ...
Validation loss decreased (0.979592 --> 0.975429).  Saving model ...
Validation loss decreased (0.975429 --> 0.973130).  Saving model ...
EarlyStopping counter: 1 out of 5.0
Validation loss decreased (0.973130 --> 0.971749).  Saving model ...
Validation loss decreased (0.971749 --> 0.969044).  Saving model ...
Validation loss decreased (0.969044 --> 0.967444).  Saving model ...
Validation loss decreased (0.967444 --> 0.967312).  Saving model ...
Validation loss decreased (0.967312 --> 0.964459).  Saving model ...
Validation loss decreased (0.964459 --> 0.961948).  Saving model ...
EarlyStopping counter: 1 out of 5.0
Validation loss decreased (0.961948 --> 0.961317).  Saving model ...
Validation loss decreased (0.961317 --> 0.960517).  Saving model ...
Validation loss decreased (0.960517 --> 0.959682).  Saving model ...
Validation loss decreased (0.959682 --> 0.958392).  Saving model ...
Validation loss decreased (0.958392 --> 0.954775).  Saving model ...
EarlyStopping counter: 1 out of 5.0
Validation loss decreased (0.954775 --> 0.953493).  Saving model ...
Validation loss decreased (0.953493 --> 0.951688).  Saving model ...
Validation loss decreased (0.951688 --> 0.950982).  Saving model ...
Validation loss decreased (0.950982 --> 0.948832).  Saving model ...
EarlyStopping counter: 1 out of 5.0
EarlyStopping counter: 2 out of 5.0
Validation loss decreased (0.948832 --> 0.948372).  Saving model ...
Validation loss decreased (0.948372 --> 0.946148).  Saving model ...
EarlyStopping counter: 1 out of 5.0
Validation loss decreased (0.946148 --> 0.945653).  Saving model ...
Validation loss decreased (0.945653 --> 0.944098).  Saving model ...
EarlyStopping counter: 1 out of 5.0
Validation loss decreased (0.944098 --> 0.943742).  Saving model ...
Validation loss decreased (0.943742 --> 0.943742).  Saving model ...
Validation loss decreased (0.943742 --> 0.942268).  Saving model ...
Validation loss decreased (0.942268 --> 0.941558).  Saving model ...
EarlyStopping counter: 1 out of 5.0
EarlyStopping counter: 2 out of 5.0
EarlyStopping counter: 3 out of 5.0
EarlyStopping counter: 4 out of 5.0
EarlyStopping counter: 5 out of 5.0
/localscratch/yinan.29163121.0/env/lib/python3.7/site-packages/torch/nn/functional.py:1794: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.
  warnings.warn("nn.functional.tanh is deprecated. Use torch.tanh instead.")
wandb: Waiting for W&B process to finish, PID 212681... (success).
wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: \ 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: | 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: / 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: \ 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: | 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: / 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb:                                                                                
wandb: Run history:
wandb:     e_F1 ▁▂▃▄▄▄▄▅▅▅▆▆▆▆▆▆▇▇▇▇▇▇▇▇▇▇██████████████
wandb:   e_loss █▇▇▆▆▆▆▅▅▅▅▄▄▄▃▃▃▃▃▂▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:     t_F1 ▁▂▂▃▃▄▄▄▄▄▅▅▆▆▆▆▆▆▆▇▆▇▇▇▇▇▇▇▇▇▇█▇▇█▇████
wandb:   t_loss █▇▇▇▆▆▆▆▆▆▅▅▅▅▄▄▄▄▄▃▃▃▃▃▃▂▂▂▂▂▂▂▂▂▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:     e_F1 59.82099
wandb:   e_loss 0.94196
wandb:     t_F1 71.20463
wandb:   t_loss 0.78022
wandb: 
wandb: Synced 4 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Synced apricot-eon-2: https://wandb.ai/yinanazhou/xl_512_bs_8_lr_1e06_es_5_lc_False_nr_False_sr_True_stem_False_lemma_False_repeat_2_fold_1/runs/2xcvi1nv
wandb: Find logs at: ./wandb/run-20220318_004444-2xcvi1nv/logs/debug.log
wandb: 

wandb: wandb version 0.12.11 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
2022-03-18 02:02:55.156287: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1
wandb: Tracking run with wandb version 0.12.5
wandb: Syncing run worthy-night-2
wandb: ⭐️ View project at https://wandb.ai/yinanazhou/xl_512_bs_8_lr_1e06_es_5_lc_False_nr_False_sr_True_stem_False_lemma_False_repeat_2_fold_2
wandb: 🚀 View run at https://wandb.ai/yinanazhou/xl_512_bs_8_lr_1e06_es_5_lc_False_nr_False_sr_True_stem_False_lemma_False_repeat_2_fold_2/runs/36jemlo6
wandb: Run data is saved locally in /project/6002780/yinan/Thesis_MER_Lyrics/lyric-emotion/wandb/run-20220318_020252-36jemlo6
wandb: Run `wandb offline` to turn off syncing.

Validation loss decreased (inf --> 1.407513).  Saving model ...
Validation loss decreased (1.407513 --> 1.392573).  Saving model ...
Validation loss decreased (1.392573 --> 1.382013).  Saving model ...
Validation loss decreased (1.382013 --> 1.374583).  Saving model ...
Validation loss decreased (1.374583 --> 1.368445).  Saving model ...
Validation loss decreased (1.368445 --> 1.363548).  Saving model ...
Validation loss decreased (1.363548 --> 1.359637).  Saving model ...
Validation loss decreased (1.359637 --> 1.355717).  Saving model ...
Validation loss decreased (1.355717 --> 1.351566).  Saving model ...
Validation loss decreased (1.351566 --> 1.347535).  Saving model ...
Validation loss decreased (1.347535 --> 1.343574).  Saving model ...
Validation loss decreased (1.343574 --> 1.339273).  Saving model ...
Validation loss decreased (1.339273 --> 1.334833).  Saving model ...
Validation loss decreased (1.334833 --> 1.330627).  Saving model ...
Validation loss decreased (1.330627 --> 1.325458).  Saving model ...
Validation loss decreased (1.325458 --> 1.320643).  Saving model ...
Validation loss decreased (1.320643 --> 1.315536).  Saving model ...
Validation loss decreased (1.315536 --> 1.310606).  Saving model ...
Validation loss decreased (1.310606 --> 1.304943).  Saving model ...
Validation loss decreased (1.304943 --> 1.299947).  Saving model ...
Validation loss decreased (1.299947 --> 1.293651).  Saving model ...
Validation loss decreased (1.293651 --> 1.286209).  Saving model ...
Validation loss decreased (1.286209 --> 1.280950).  Saving model ...
Validation loss decreased (1.280950 --> 1.276465).  Saving model ...
Validation loss decreased (1.276465 --> 1.269871).  Saving model ...
Validation loss decreased (1.269871 --> 1.263860).  Saving model ...
Validation loss decreased (1.263860 --> 1.256959).  Saving model ...
Validation loss decreased (1.256959 --> 1.252350).  Saving model ...
Validation loss decreased (1.252350 --> 1.245406).  Saving model ...
Validation loss decreased (1.245406 --> 1.239047).  Saving model ...
Validation loss decreased (1.239047 --> 1.232558).  Saving model ...
Validation loss decreased (1.232558 --> 1.226125).  Saving model ...
Validation loss decreased (1.226125 --> 1.218517).  Saving model ...
Validation loss decreased (1.218517 --> 1.212290).  Saving model ...
Validation loss decreased (1.212290 --> 1.206547).  Saving model ...
Validation loss decreased (1.206547 --> 1.196146).  Saving model ...
Validation loss decreased (1.196146 --> 1.187427).  Saving model ...
Validation loss decreased (1.187427 --> 1.178702).  Saving model ...
Validation loss decreased (1.178702 --> 1.169279).  Saving model ...
Validation loss decreased (1.169279 --> 1.162004).  Saving model ...
Validation loss decreased (1.162004 --> 1.155474).  Saving model ...
Validation loss decreased (1.155474 --> 1.148307).  Saving model ...
Validation loss decreased (1.148307 --> 1.140364).  Saving model ...
Validation loss decreased (1.140364 --> 1.134829).  Saving model ...
Validation loss decreased (1.134829 --> 1.126986).  Saving model ...
Validation loss decreased (1.126986 --> 1.123453).  Saving model ...
Validation loss decreased (1.123453 --> 1.117040).  Saving model ...
Validation loss decreased (1.117040 --> 1.111295).  Saving model ...
Validation loss decreased (1.111295 --> 1.103620).  Saving model ...
Validation loss decreased (1.103620 --> 1.097830).  Saving model ...
Validation loss decreased (1.097830 --> 1.090754).  Saving model ...
Validation loss decreased (1.090754 --> 1.085777).  Saving model ...
Validation loss decreased (1.085777 --> 1.080071).  Saving model ...
Validation loss decreased (1.080071 --> 1.074501).  Saving model ...
Validation loss decreased (1.074501 --> 1.070525).  Saving model ...
Validation loss decreased (1.070525 --> 1.067629).  Saving model ...
Validation loss decreased (1.067629 --> 1.064737).  Saving model ...
Validation loss decreased (1.064737 --> 1.059290).  Saving model ...
Validation loss decreased (1.059290 --> 1.054574).  Saving model ...
Validation loss decreased (1.054574 --> 1.051399).  Saving model ...
Validation loss decreased (1.051399 --> 1.047433).  Saving model ...
Validation loss decreased (1.047433 --> 1.044364).  Saving model ...
Validation loss decreased (1.044364 --> 1.039869).  Saving model ...
Validation loss decreased (1.039869 --> 1.034043).  Saving model ...
Validation loss decreased (1.034043 --> 1.031581).  Saving model ...
Validation loss decreased (1.031581 --> 1.028953).  Saving model ...
Validation loss decreased (1.028953 --> 1.024769).  Saving model ...
Validation loss decreased (1.024769 --> 1.021892).  Saving model ...
Validation loss decreased (1.021892 --> 1.019870).  Saving model ...
Validation loss decreased (1.019870 --> 1.018319).  Saving model ...
Validation loss decreased (1.018319 --> 1.013766).  Saving model ...
Validation loss decreased (1.013766 --> 1.010047).  Saving model ...
Validation loss decreased (1.010047 --> 1.005811).  Saving model ...
Validation loss decreased (1.005811 --> 1.004995).  Saving model ...
Validation loss decreased (1.004995 --> 1.001072).  Saving model ...
Validation loss decreased (1.001072 --> 0.999086).  Saving model ...
Validation loss decreased (0.999086 --> 0.995014).  Saving model ...
Validation loss decreased (0.995014 --> 0.991855).  Saving model ...
Validation loss decreased (0.991855 --> 0.989594).  Saving model ...
Validation loss decreased (0.989594 --> 0.986099).  Saving model ...
Validation loss decreased (0.986099 --> 0.985989).  Saving model ...
Validation loss decreased (0.985989 --> 0.983836).  Saving model ...
Validation loss decreased (0.983836 --> 0.979863).  Saving model ...
Validation loss decreased (0.979863 --> 0.978650).  Saving model ...
Validation loss decreased (0.978650 --> 0.974252).  Saving model ...
Validation loss decreased (0.974252 --> 0.970044).  Saving model ...
EarlyStopping counter: 1 out of 5.0
EarlyStopping counter: 2 out of 5.0
Validation loss decreased (0.970044 --> 0.968094).  Saving model ...
Validation loss decreased (0.968094 --> 0.964928).  Saving model ...
Validation loss decreased (0.964928 --> 0.963213).  Saving model ...
Validation loss decreased (0.963213 --> 0.961936).  Saving model ...
Validation loss decreased (0.961936 --> 0.961300).  Saving model ...
Validation loss decreased (0.961300 --> 0.959404).  Saving model ...
Validation loss decreased (0.959404 --> 0.958740).  Saving model ...
Validation loss decreased (0.958740 --> 0.957182).  Saving model ...
Validation loss decreased (0.957182 --> 0.955639).  Saving model ...
EarlyStopping counter: 1 out of 5.0
Validation loss decreased (0.955639 --> 0.954449).  Saving model ...
Validation loss decreased (0.954449 --> 0.951627).  Saving model ...
Validation loss decreased (0.951627 --> 0.950310).  Saving model ...
Validation loss decreased (0.950310 --> 0.947265).  Saving model ...
Validation loss decreased (0.947265 --> 0.945946).  Saving model ...
Validation loss decreased (0.945946 --> 0.944255).  Saving model ...
Validation loss decreased (0.944255 --> 0.944141).  Saving model ...
Validation loss decreased (0.944141 --> 0.941742).  Saving model ...
Validation loss decreased (0.941742 --> 0.941060).  Saving model ...
Validation loss decreased (0.941060 --> 0.940762).  Saving model ...
EarlyStopping counter: 1 out of 5.0
EarlyStopping counter: 2 out of 5.0
EarlyStopping counter: 3 out of 5.0
Validation loss decreased (0.940762 --> 0.939720).  Saving model ...
Validation loss decreased (0.939720 --> 0.936641).  Saving model ...
Validation loss decreased (0.936641 --> 0.935738).  Saving model ...
Validation loss decreased (0.935738 --> 0.935154).  Saving model ...
Validation loss decreased (0.935154 --> 0.935080).  Saving model ...
Validation loss decreased (0.935080 --> 0.933437).  Saving model ...
Validation loss decreased (0.933437 --> 0.932038).  Saving model ...
Validation loss decreased (0.932038 --> 0.931109).  Saving model ...
EarlyStopping counter: 1 out of 5.0
EarlyStopping counter: 2 out of 5.0
Validation loss decreased (0.931109 --> 0.930927).  Saving model ...
Validation loss decreased (0.930927 --> 0.930819).  Saving model ...
Validation loss decreased (0.930819 --> 0.930655).  Saving model ...
Validation loss decreased (0.930655 --> 0.930221).  Saving model ...
Validation loss decreased (0.930221 --> 0.928523).  Saving model ...
EarlyStopping counter: 1 out of 5.0
EarlyStopping counter: 2 out of 5.0
EarlyStopping counter: 3 out of 5.0
EarlyStopping counter: 4 out of 5.0
Validation loss decreased (0.928523 --> 0.926301).  Saving model ...
Validation loss decreased (0.926301 --> 0.925299).  Saving model ...
EarlyStopping counter: 1 out of 5.0
EarlyStopping counter: 2 out of 5.0
EarlyStopping counter: 3 out of 5.0
Validation loss decreased (0.925299 --> 0.925174).  Saving model ...
EarlyStopping counter: 1 out of 5.0
EarlyStopping counter: 2 out of 5.0
EarlyStopping counter: 3 out of 5.0
EarlyStopping counter: 4 out of 5.0
EarlyStopping counter: 5 out of 5.0
/localscratch/yinan.29163121.0/env/lib/python3.7/site-packages/torch/nn/functional.py:1794: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.
  warnings.warn("nn.functional.tanh is deprecated. Use torch.tanh instead.")
wandb: Waiting for W&B process to finish, PID 217013... (success).
wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: \ 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: | 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: / 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: \ 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: | 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: / 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: \ 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: | 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: / 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb:                                                                                
wandb: Run history:
wandb:     e_F1 ▁▃▄▄▄▄▄▄▅▅▅▅▅▆▆▆▆▇▇▇▇▇▇▇▇▇▇▇▇▇█▇████████
wandb:   e_loss ██▇▇▇▇▆▆▆▆▅▅▄▄▄▃▃▃▃▂▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:     t_F1 ▁▂▂▂▃▃▄▄▄▅▅▅▆▅▅▆▆▆▇▆▆▇▆▇▇▇▇▇▇█▇▇████████
wandb:   t_loss ███▇▇▇▇▇▆▆▆▅▅▅▅▄▄▄▄▄▃▃▃▃▃▃▂▂▂▂▂▂▂▂▁▂▁▁▁▁
wandb: 
wandb: Run summary:
wandb:     e_F1 63.25554
wandb:   e_loss 0.92538
wandb:     t_F1 73.22497
wandb:   t_loss 0.72021
wandb: 
wandb: Synced 4 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Synced worthy-night-2: https://wandb.ai/yinanazhou/xl_512_bs_8_lr_1e06_es_5_lc_False_nr_False_sr_True_stem_False_lemma_False_repeat_2_fold_2/runs/36jemlo6
wandb: Find logs at: ./wandb/run-20220318_020252-36jemlo6/logs/debug.log
wandb: 

wandb: wandb version 0.12.11 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
2022-03-18 03:35:17.928446: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1
wandb: Tracking run with wandb version 0.12.5
wandb: Syncing run soft-leaf-2
wandb: ⭐️ View project at https://wandb.ai/yinanazhou/xl_512_bs_8_lr_1e06_es_5_lc_False_nr_False_sr_True_stem_False_lemma_False_repeat_3_fold_1
wandb: 🚀 View run at https://wandb.ai/yinanazhou/xl_512_bs_8_lr_1e06_es_5_lc_False_nr_False_sr_True_stem_False_lemma_False_repeat_3_fold_1/runs/25n411c5
wandb: Run data is saved locally in /project/6002780/yinan/Thesis_MER_Lyrics/lyric-emotion/wandb/run-20220318_033513-25n411c5
wandb: Run `wandb offline` to turn off syncing.

Validation loss decreased (inf --> 1.428793).  Saving model ...
Validation loss decreased (1.428793 --> 1.417455).  Saving model ...
Validation loss decreased (1.417455 --> 1.408260).  Saving model ...
Validation loss decreased (1.408260 --> 1.401438).  Saving model ...
Validation loss decreased (1.401438 --> 1.394992).  Saving model ...
Validation loss decreased (1.394992 --> 1.389451).  Saving model ...
Validation loss decreased (1.389451 --> 1.384209).  Saving model ...
Validation loss decreased (1.384209 --> 1.379782).  Saving model ...
Validation loss decreased (1.379782 --> 1.374879).  Saving model ...
Validation loss decreased (1.374879 --> 1.370503).  Saving model ...
Validation loss decreased (1.370503 --> 1.365997).  Saving model ...
Validation loss decreased (1.365997 --> 1.361236).  Saving model ...
Validation loss decreased (1.361236 --> 1.356817).  Saving model ...
Validation loss decreased (1.356817 --> 1.351851).  Saving model ...
Validation loss decreased (1.351851 --> 1.346657).  Saving model ...
Validation loss decreased (1.346657 --> 1.341406).  Saving model ...
Validation loss decreased (1.341406 --> 1.335561).  Saving model ...
Validation loss decreased (1.335561 --> 1.329084).  Saving model ...
Validation loss decreased (1.329084 --> 1.322547).  Saving model ...
Validation loss decreased (1.322547 --> 1.315117).  Saving model ...
Validation loss decreased (1.315117 --> 1.307649).  Saving model ...
Validation loss decreased (1.307649 --> 1.298826).  Saving model ...
Validation loss decreased (1.298826 --> 1.290725).  Saving model ...
Validation loss decreased (1.290725 --> 1.281950).  Saving model ...
Validation loss decreased (1.281950 --> 1.273009).  Saving model ...
Validation loss decreased (1.273009 --> 1.264526).  Saving model ...
Validation loss decreased (1.264526 --> 1.256243).  Saving model ...
Validation loss decreased (1.256243 --> 1.250025).  Saving model ...
Validation loss decreased (1.250025 --> 1.241797).  Saving model ...
Validation loss decreased (1.241797 --> 1.233019).  Saving model ...
Validation loss decreased (1.233019 --> 1.224959).  Saving model ...
Validation loss decreased (1.224959 --> 1.218897).  Saving model ...
Validation loss decreased (1.218897 --> 1.211150).  Saving model ...
Validation loss decreased (1.211150 --> 1.202726).  Saving model ...
Validation loss decreased (1.202726 --> 1.193878).  Saving model ...
Validation loss decreased (1.193878 --> 1.186607).  Saving model ...
Validation loss decreased (1.186607 --> 1.179822).  Saving model ...
Validation loss decreased (1.179822 --> 1.172858).  Saving model ...
Validation loss decreased (1.172858 --> 1.166240).  Saving model ...
Validation loss decreased (1.166240 --> 1.160803).  Saving model ...
Validation loss decreased (1.160803 --> 1.153556).  Saving model ...
Validation loss decreased (1.153556 --> 1.147433).  Saving model ...
Validation loss decreased (1.147433 --> 1.140539).  Saving model ...
Validation loss decreased (1.140539 --> 1.135290).  Saving model ...
Validation loss decreased (1.135290 --> 1.129958).  Saving model ...
Validation loss decreased (1.129958 --> 1.122756).  Saving model ...
Validation loss decreased (1.122756 --> 1.116699).  Saving model ...
Validation loss decreased (1.116699 --> 1.111183).  Saving model ...
Validation loss decreased (1.111183 --> 1.104943).  Saving model ...
Validation loss decreased (1.104943 --> 1.100068).  Saving model ...
Validation loss decreased (1.100068 --> 1.094213).  Saving model ...
Validation loss decreased (1.094213 --> 1.089611).  Saving model ...
Validation loss decreased (1.089611 --> 1.085180).  Saving model ...
Validation loss decreased (1.085180 --> 1.080107).  Saving model ...
Validation loss decreased (1.080107 --> 1.075206).  Saving model ...
Validation loss decreased (1.075206 --> 1.071109).  Saving model ...
Validation loss decreased (1.071109 --> 1.065008).  Saving model ...
Validation loss decreased (1.065008 --> 1.059737).  Saving model ...
Validation loss decreased (1.059737 --> 1.055154).  Saving model ...
Validation loss decreased (1.055154 --> 1.054554).  Saving model ...
Validation loss decreased (1.054554 --> 1.051997).  Saving model ...
Validation loss decreased (1.051997 --> 1.051080).  Saving model ...
Validation loss decreased (1.051080 --> 1.043722).  Saving model ...
Validation loss decreased (1.043722 --> 1.039445).  Saving model ...
Validation loss decreased (1.039445 --> 1.034065).  Saving model ...
Validation loss decreased (1.034065 --> 1.031010).  Saving model ...
Validation loss decreased (1.031010 --> 1.027077).  Saving model ...
Validation loss decreased (1.027077 --> 1.023834).  Saving model ...
Validation loss decreased (1.023834 --> 1.021280).  Saving model ...
Validation loss decreased (1.021280 --> 1.018263).  Saving model ...
Validation loss decreased (1.018263 --> 1.013937).  Saving model ...
Validation loss decreased (1.013937 --> 1.010179).  Saving model ...
Validation loss decreased (1.010179 --> 1.008608).  Saving model ...
Validation loss decreased (1.008608 --> 1.002709).  Saving model ...
Validation loss decreased (1.002709 --> 0.998563).  Saving model ...
Validation loss decreased (0.998563 --> 0.996455).  Saving model ...
Validation loss decreased (0.996455 --> 0.995380).  Saving model ...
Validation loss decreased (0.995380 --> 0.992866).  Saving model ...
Validation loss decreased (0.992866 --> 0.991551).  Saving model ...
Validation loss decreased (0.991551 --> 0.989826).  Saving model ...
Validation loss decreased (0.989826 --> 0.987096).  Saving model ...
Validation loss decreased (0.987096 --> 0.984582).  Saving model ...
Validation loss decreased (0.984582 --> 0.979877).  Saving model ...
Validation loss decreased (0.979877 --> 0.977348).  Saving model ...
EarlyStopping counter: 1 out of 5.0
Validation loss decreased (0.977348 --> 0.974870).  Saving model ...
EarlyStopping counter: 1 out of 5.0
Validation loss decreased (0.974870 --> 0.971666).  Saving model ...
Validation loss decreased (0.971666 --> 0.969746).  Saving model ...
EarlyStopping counter: 1 out of 5.0
EarlyStopping counter: 2 out of 5.0
EarlyStopping counter: 3 out of 5.0
Validation loss decreased (0.969746 --> 0.966176).  Saving model ...
EarlyStopping counter: 1 out of 5.0
Validation loss decreased (0.966176 --> 0.964520).  Saving model ...
Validation loss decreased (0.964520 --> 0.963630).  Saving model ...
Validation loss decreased (0.963630 --> 0.961518).  Saving model ...
Validation loss decreased (0.961518 --> 0.959030).  Saving model ...
EarlyStopping counter: 1 out of 5.0
EarlyStopping counter: 2 out of 5.0
Validation loss decreased (0.959030 --> 0.957916).  Saving model ...
EarlyStopping counter: 1 out of 5.0
Validation loss decreased (0.957916 --> 0.955582).  Saving model ...
Validation loss decreased (0.955582 --> 0.953890).  Saving model ...
Validation loss decreased (0.953890 --> 0.952131).  Saving model ...
EarlyStopping counter: 1 out of 5.0
Validation loss decreased (0.952131 --> 0.951168).  Saving model ...
EarlyStopping counter: 1 out of 5.0
EarlyStopping counter: 2 out of 5.0
EarlyStopping counter: 3 out of 5.0
EarlyStopping counter: 4 out of 5.0
EarlyStopping counter: 5 out of 5.0
/localscratch/yinan.29163121.0/env/lib/python3.7/site-packages/torch/nn/functional.py:1794: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.
  warnings.warn("nn.functional.tanh is deprecated. Use torch.tanh instead.")
wandb: Waiting for W&B process to finish, PID 221955... (success).
wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: \ 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: | 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: / 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: \ 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: | 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: / 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: \ 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: | 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: / 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb:                                                                                
wandb: Run history:
wandb:     e_F1 ▁▁▂▃▄▅▅▆▆▆▆▆▆▇▇▇▇▇▇▇▇▇▇▇▇▇▇█████████████
wandb:   e_loss ██▇▇▇▇▇▆▆▆▅▅▅▄▄▄▄▃▃▃▃▃▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁
wandb:     t_F1 ▁▁▂▂▃▃▃▄▄▄▄▅▅▅▅▆▆▆▇▆▇▆▇▇▇▇▇█▇██▇████████
wandb:   t_loss ███▇▇▇▇▇▇▆▆▆▆▅▅▅▄▄▄▄▄▄▃▃▃▃▃▂▂▂▂▂▂▂▂▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:     e_F1 61.16633
wandb:   e_loss 0.95384
wandb:     t_F1 67.84564
wandb:   t_loss 0.82946
wandb: 
wandb: Synced 4 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Synced soft-leaf-2: https://wandb.ai/yinanazhou/xl_512_bs_8_lr_1e06_es_5_lc_False_nr_False_sr_True_stem_False_lemma_False_repeat_3_fold_1/runs/25n411c5
wandb: Find logs at: ./wandb/run-20220318_033513-25n411c5/logs/debug.log
wandb: 

wandb: wandb version 0.12.11 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
2022-03-18 04:48:42.060940: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1
wandb: Tracking run with wandb version 0.12.5
wandb: Syncing run revived-surf-2
wandb: ⭐️ View project at https://wandb.ai/yinanazhou/xl_512_bs_8_lr_1e06_es_5_lc_False_nr_False_sr_True_stem_False_lemma_False_repeat_3_fold_2
wandb: 🚀 View run at https://wandb.ai/yinanazhou/xl_512_bs_8_lr_1e06_es_5_lc_False_nr_False_sr_True_stem_False_lemma_False_repeat_3_fold_2/runs/1txn1m7f
wandb: Run data is saved locally in /project/6002780/yinan/Thesis_MER_Lyrics/lyric-emotion/wandb/run-20220318_044839-1txn1m7f
wandb: Run `wandb offline` to turn off syncing.

Validation loss decreased (inf --> 1.504539).  Saving model ...
Validation loss decreased (1.504539 --> 1.467272).  Saving model ...
Validation loss decreased (1.467272 --> 1.439594).  Saving model ...
Validation loss decreased (1.439594 --> 1.420042).  Saving model ...
Validation loss decreased (1.420042 --> 1.404695).  Saving model ...
Validation loss decreased (1.404695 --> 1.393422).  Saving model ...
Validation loss decreased (1.393422 --> 1.384676).  Saving model ...
Validation loss decreased (1.384676 --> 1.377316).  Saving model ...
Validation loss decreased (1.377316 --> 1.370508).  Saving model ...
Validation loss decreased (1.370508 --> 1.363895).  Saving model ...
Validation loss decreased (1.363895 --> 1.358157).  Saving model ...
Validation loss decreased (1.358157 --> 1.351763).  Saving model ...
Validation loss decreased (1.351763 --> 1.345181).  Saving model ...
Validation loss decreased (1.345181 --> 1.338925).  Saving model ...
Validation loss decreased (1.338925 --> 1.332312).  Saving model ...
Validation loss decreased (1.332312 --> 1.324665).  Saving model ...
Validation loss decreased (1.324665 --> 1.317172).  Saving model ...
Validation loss decreased (1.317172 --> 1.310194).  Saving model ...
Validation loss decreased (1.310194 --> 1.302485).  Saving model ...
Validation loss decreased (1.302485 --> 1.293877).  Saving model ...
Validation loss decreased (1.293877 --> 1.285302).  Saving model ...
Validation loss decreased (1.285302 --> 1.275799).  Saving model ...
Validation loss decreased (1.275799 --> 1.265851).  Saving model ...
Validation loss decreased (1.265851 --> 1.258473).  Saving model ...
Validation loss decreased (1.258473 --> 1.250055).  Saving model ...
Validation loss decreased (1.250055 --> 1.240565).  Saving model ...
Validation loss decreased (1.240565 --> 1.232464).  Saving model ...
Validation loss decreased (1.232464 --> 1.223850).  Saving model ...
Validation loss decreased (1.223850 --> 1.214815).  Saving model ...
Validation loss decreased (1.214815 --> 1.207332).  Saving model ...
Validation loss decreased (1.207332 --> 1.199327).  Saving model ...
Validation loss decreased (1.199327 --> 1.192568).  Saving model ...
Validation loss decreased (1.192568 --> 1.186989).  Saving model ...
Validation loss decreased (1.186989 --> 1.177579).  Saving model ...
Validation loss decreased (1.177579 --> 1.172905).  Saving model ...
Validation loss decreased (1.172905 --> 1.165975).  Saving model ...
Validation loss decreased (1.165975 --> 1.157503).  Saving model ...
Validation loss decreased (1.157503 --> 1.150983).  Saving model ...
Validation loss decreased (1.150983 --> 1.141144).  Saving model ...
Validation loss decreased (1.141144 --> 1.134727).  Saving model ...
Validation loss decreased (1.134727 --> 1.125934).  Saving model ...
Validation loss decreased (1.125934 --> 1.117854).  Saving model ...
Validation loss decreased (1.117854 --> 1.115405).  Saving model ...
Validation loss decreased (1.115405 --> 1.107869).  Saving model ...
Validation loss decreased (1.107869 --> 1.104196).  Saving model ...
Validation loss decreased (1.104196 --> 1.100796).  Saving model ...
Validation loss decreased (1.100796 --> 1.097746).  Saving model ...
Validation loss decreased (1.097746 --> 1.087278).  Saving model ...
Validation loss decreased (1.087278 --> 1.079019).  Saving model ...
Validation loss decreased (1.079019 --> 1.073356).  Saving model ...
Validation loss decreased (1.073356 --> 1.070078).  Saving model ...
Validation loss decreased (1.070078 --> 1.064234).  Saving model ...
Validation loss decreased (1.064234 --> 1.057023).  Saving model ...
Validation loss decreased (1.057023 --> 1.048441).  Saving model ...
Validation loss decreased (1.048441 --> 1.042651).  Saving model ...
Validation loss decreased (1.042651 --> 1.037440).  Saving model ...
Validation loss decreased (1.037440 --> 1.033741).  Saving model ...
Validation loss decreased (1.033741 --> 1.031810).  Saving model ...
Validation loss decreased (1.031810 --> 1.024424).  Saving model ...
Validation loss decreased (1.024424 --> 1.019141).  Saving model ...
Validation loss decreased (1.019141 --> 1.016072).  Saving model ...
Validation loss decreased (1.016072 --> 1.011802).  Saving model ...
Validation loss decreased (1.011802 --> 1.009722).  Saving model ...
Validation loss decreased (1.009722 --> 1.002839).  Saving model ...
Validation loss decreased (1.002839 --> 0.998425).  Saving model ...
Validation loss decreased (0.998425 --> 0.996422).  Saving model ...
Validation loss decreased (0.996422 --> 0.993228).  Saving model ...
Validation loss decreased (0.993228 --> 0.989451).  Saving model ...
Validation loss decreased (0.989451 --> 0.983136).  Saving model ...
Validation loss decreased (0.983136 --> 0.980600).  Saving model ...
Validation loss decreased (0.980600 --> 0.975175).  Saving model ...
Validation loss decreased (0.975175 --> 0.974228).  Saving model ...
Validation loss decreased (0.974228 --> 0.969476).  Saving model ...
Validation loss decreased (0.969476 --> 0.967798).  Saving model ...
Validation loss decreased (0.967798 --> 0.964504).  Saving model ...
Validation loss decreased (0.964504 --> 0.960618).  Saving model ...
Validation loss decreased (0.960618 --> 0.957308).  Saving model ...
Validation loss decreased (0.957308 --> 0.955646).  Saving model ...
Validation loss decreased (0.955646 --> 0.951833).  Saving model ...
Validation loss decreased (0.951833 --> 0.949364).  Saving model ...
Validation loss decreased (0.949364 --> 0.949135).  Saving model ...
Validation loss decreased (0.949135 --> 0.946533).  Saving model ...
Validation loss decreased (0.946533 --> 0.942074).  Saving model ...
Validation loss decreased (0.942074 --> 0.938926).  Saving model ...
Validation loss decreased (0.938926 --> 0.936844).  Saving model ...
Validation loss decreased (0.936844 --> 0.934397).  Saving model ...
Validation loss decreased (0.934397 --> 0.931452).  Saving model ...
EarlyStopping counter: 1 out of 5.0
EarlyStopping counter: 2 out of 5.0
Validation loss decreased (0.931452 --> 0.929386).  Saving model ...
Validation loss decreased (0.929386 --> 0.927981).  Saving model ...
Validation loss decreased (0.927981 --> 0.927795).  Saving model ...
Validation loss decreased (0.927795 --> 0.927626).  Saving model ...
Validation loss decreased (0.927626 --> 0.924333).  Saving model ...
Validation loss decreased (0.924333 --> 0.918396).  Saving model ...
Validation loss decreased (0.918396 --> 0.914159).  Saving model ...
Validation loss decreased (0.914159 --> 0.914050).  Saving model ...
Validation loss decreased (0.914050 --> 0.913109).  Saving model ...
Validation loss decreased (0.913109 --> 0.911110).  Saving model ...
Validation loss decreased (0.911110 --> 0.910139).  Saving model ...
EarlyStopping counter: 1 out of 5.0
Validation loss decreased (0.910139 --> 0.909661).  Saving model ...
EarlyStopping counter: 1 out of 5.0
EarlyStopping counter: 2 out of 5.0
EarlyStopping counter: 3 out of 5.0
EarlyStopping counter: 4 out of 5.0
Validation loss decreased (0.909661 --> 0.904750).  Saving model ...
EarlyStopping counter: 1 out of 5.0
Validation loss decreased (0.904750 --> 0.904216).  Saving model ...
Validation loss decreased (0.904216 --> 0.901717).  Saving model ...
EarlyStopping counter: 1 out of 5.0
Validation loss decreased (0.901717 --> 0.900611).  Saving model ...
EarlyStopping counter: 1 out of 5.0
EarlyStopping counter: 2 out of 5.0
EarlyStopping counter: 3 out of 5.0
EarlyStopping counter: 4 out of 5.0
Validation loss decreased (0.900611 --> 0.899121).  Saving model ...
Validation loss decreased (0.899121 --> 0.896929).  Saving model ...
EarlyStopping counter: 1 out of 5.0
Validation loss decreased (0.896929 --> 0.896649).  Saving model ...
Validation loss decreased (0.896649 --> 0.895228).  Saving model ...
EarlyStopping counter: 1 out of 5.0
EarlyStopping counter: 2 out of 5.0
Validation loss decreased (0.895228 --> 0.893715).  Saving model ...
EarlyStopping counter: 1 out of 5.0
EarlyStopping counter: 2 out of 5.0
EarlyStopping counter: 3 out of 5.0
EarlyStopping counter: 4 out of 5.0
EarlyStopping counter: 5 out of 5.0
/localscratch/yinan.29163121.0/env/lib/python3.7/site-packages/torch/nn/functional.py:1794: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.
  warnings.warn("nn.functional.tanh is deprecated. Use torch.tanh instead.")
wandb: Waiting for W&B process to finish, PID 225906... (success).
wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: \ 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: | 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: / 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: \ 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: | 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: / 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: \ 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: | 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: / 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb:                                                                                
wandb: Run history:
wandb:     e_F1 ▁▁▂▃▃▄▅▅▅▆▆▆▆▆▆▇▇▇▇▇▇▇▇▇▇███████████████
wandb:   e_loss █▇▇▇▆▆▆▅▅▅▄▄▄▄▄▃▃▃▃▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:     t_F1 ▁▁▂▂▃▄▄▅▅▅▅▅▆▆▆▆▆▆▆▆▆▇▇▇▇▇▇█▇██▇██▇█████
wandb:   t_loss █▇▇▇▇▆▆▆▆▆▅▅▅▄▄▄▄▄▄▄▃▃▃▃▃▃▂▂▂▂▂▂▂▂▂▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:     e_F1 62.86991
wandb:   e_loss 0.89819
wandb:     t_F1 70.84519
wandb:   t_loss 0.77367
wandb: 
wandb: Synced 4 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Synced revived-surf-2: https://wandb.ai/yinanazhou/xl_512_bs_8_lr_1e06_es_5_lc_False_nr_False_sr_True_stem_False_lemma_False_repeat_3_fold_2/runs/1txn1m7f
wandb: Find logs at: ./wandb/run-20220318_044839-1txn1m7f/logs/debug.log
wandb: 

wandb: wandb version 0.12.11 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
2022-03-18 06:13:03.942838: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1
wandb: Tracking run with wandb version 0.12.5
wandb: Syncing run morning-capybara-2
wandb: ⭐️ View project at https://wandb.ai/yinanazhou/xl_512_bs_8_lr_1e06_es_5_lc_False_nr_False_sr_True_stem_False_lemma_False_repeat_4_fold_1
wandb: 🚀 View run at https://wandb.ai/yinanazhou/xl_512_bs_8_lr_1e06_es_5_lc_False_nr_False_sr_True_stem_False_lemma_False_repeat_4_fold_1/runs/1pfqqlce
wandb: Run data is saved locally in /project/6002780/yinan/Thesis_MER_Lyrics/lyric-emotion/wandb/run-20220318_061259-1pfqqlce
wandb: Run `wandb offline` to turn off syncing.

Validation loss decreased (inf --> 1.532627).  Saving model ...
Validation loss decreased (1.532627 --> 1.480565).  Saving model ...
Validation loss decreased (1.480565 --> 1.440386).  Saving model ...
Validation loss decreased (1.440386 --> 1.411345).  Saving model ...
Validation loss decreased (1.411345 --> 1.390040).  Saving model ...
Validation loss decreased (1.390040 --> 1.375212).  Saving model ...
Validation loss decreased (1.375212 --> 1.364033).  Saving model ...
Validation loss decreased (1.364033 --> 1.356153).  Saving model ...
Validation loss decreased (1.356153 --> 1.350321).  Saving model ...
Validation loss decreased (1.350321 --> 1.345029).  Saving model ...
Validation loss decreased (1.345029 --> 1.340135).  Saving model ...
Validation loss decreased (1.340135 --> 1.335129).  Saving model ...
Validation loss decreased (1.335129 --> 1.329272).  Saving model ...
Validation loss decreased (1.329272 --> 1.324094).  Saving model ...
Validation loss decreased (1.324094 --> 1.318391).  Saving model ...
Validation loss decreased (1.318391 --> 1.312373).  Saving model ...
Validation loss decreased (1.312373 --> 1.306572).  Saving model ...
Validation loss decreased (1.306572 --> 1.299565).  Saving model ...
Validation loss decreased (1.299565 --> 1.292452).  Saving model ...
Validation loss decreased (1.292452 --> 1.284389).  Saving model ...
Validation loss decreased (1.284389 --> 1.276381).  Saving model ...
Validation loss decreased (1.276381 --> 1.267222).  Saving model ...
Validation loss decreased (1.267222 --> 1.259745).  Saving model ...
Validation loss decreased (1.259745 --> 1.252190).  Saving model ...
Validation loss decreased (1.252190 --> 1.245278).  Saving model ...
Validation loss decreased (1.245278 --> 1.238535).  Saving model ...
Validation loss decreased (1.238535 --> 1.233122).  Saving model ...
Validation loss decreased (1.233122 --> 1.226614).  Saving model ...
Validation loss decreased (1.226614 --> 1.219620).  Saving model ...
Validation loss decreased (1.219620 --> 1.212308).  Saving model ...
Validation loss decreased (1.212308 --> 1.205076).  Saving model ...
Validation loss decreased (1.205076 --> 1.198245).  Saving model ...
Validation loss decreased (1.198245 --> 1.192350).  Saving model ...
Validation loss decreased (1.192350 --> 1.186091).  Saving model ...
Validation loss decreased (1.186091 --> 1.178961).  Saving model ...
Validation loss decreased (1.178961 --> 1.171575).  Saving model ...
Validation loss decreased (1.171575 --> 1.165426).  Saving model ...
Validation loss decreased (1.165426 --> 1.159758).  Saving model ...
Validation loss decreased (1.159758 --> 1.154359).  Saving model ...
Validation loss decreased (1.154359 --> 1.148448).  Saving model ...
Validation loss decreased (1.148448 --> 1.142003).  Saving model ...
Validation loss decreased (1.142003 --> 1.137259).  Saving model ...
Validation loss decreased (1.137259 --> 1.132700).  Saving model ...
Validation loss decreased (1.132700 --> 1.126908).  Saving model ...
Validation loss decreased (1.126908 --> 1.120615).  Saving model ...
Validation loss decreased (1.120615 --> 1.114979).  Saving model ...
Validation loss decreased (1.114979 --> 1.109168).  Saving model ...
Validation loss decreased (1.109168 --> 1.103403).  Saving model ...
Validation loss decreased (1.103403 --> 1.099208).  Saving model ...
Validation loss decreased (1.099208 --> 1.093374).  Saving model ...
Validation loss decreased (1.093374 --> 1.089150).  Saving model ...
Validation loss decreased (1.089150 --> 1.085806).  Saving model ...
Validation loss decreased (1.085806 --> 1.081350).  Saving model ...
Validation loss decreased (1.081350 --> 1.078432).  Saving model ...
Validation loss decreased (1.078432 --> 1.075225).  Saving model ...
Validation loss decreased (1.075225 --> 1.070881).  Saving model ...
Validation loss decreased (1.070881 --> 1.067321).  Saving model ...
Validation loss decreased (1.067321 --> 1.062984).  Saving model ...
Validation loss decreased (1.062984 --> 1.058641).  Saving model ...
Validation loss decreased (1.058641 --> 1.054769).  Saving model ...
Validation loss decreased (1.054769 --> 1.051978).  Saving model ...
Validation loss decreased (1.051978 --> 1.048425).  Saving model ...
Validation loss decreased (1.048425 --> 1.047249).  Saving model ...
Validation loss decreased (1.047249 --> 1.043171).  Saving model ...
Validation loss decreased (1.043171 --> 1.040597).  Saving model ...
Validation loss decreased (1.040597 --> 1.037270).  Saving model ...
Validation loss decreased (1.037270 --> 1.033705).  Saving model ...
Validation loss decreased (1.033705 --> 1.030137).  Saving model ...
Validation loss decreased (1.030137 --> 1.027791).  Saving model ...
Validation loss decreased (1.027791 --> 1.027385).  Saving model ...
Validation loss decreased (1.027385 --> 1.022884).  Saving model ...
Validation loss decreased (1.022884 --> 1.019899).  Saving model ...
Validation loss decreased (1.019899 --> 1.018475).  Saving model ...
Validation loss decreased (1.018475 --> 1.016820).  Saving model ...
Validation loss decreased (1.016820 --> 1.012487).  Saving model ...
Validation loss decreased (1.012487 --> 1.010946).  Saving model ...
Validation loss decreased (1.010946 --> 1.009381).  Saving model ...
Validation loss decreased (1.009381 --> 1.006820).  Saving model ...
Validation loss decreased (1.006820 --> 1.003708).  Saving model ...
Validation loss decreased (1.003708 --> 0.999873).  Saving model ...
Validation loss decreased (0.999873 --> 0.998742).  Saving model ...
Validation loss decreased (0.998742 --> 0.997036).  Saving model ...
Validation loss decreased (0.997036 --> 0.995888).  Saving model ...
Validation loss decreased (0.995888 --> 0.992889).  Saving model ...
Validation loss decreased (0.992889 --> 0.991212).  Saving model ...
Validation loss decreased (0.991212 --> 0.988879).  Saving model ...
Validation loss decreased (0.988879 --> 0.986912).  Saving model ...
EarlyStopping counter: 1 out of 5.0
Validation loss decreased (0.986912 --> 0.983199).  Saving model ...
Validation loss decreased (0.983199 --> 0.981223).  Saving model ...
Validation loss decreased (0.981223 --> 0.980775).  Saving model ...
Validation loss decreased (0.980775 --> 0.979140).  Saving model ...
Validation loss decreased (0.979140 --> 0.977691).  Saving model ...
Validation loss decreased (0.977691 --> 0.977028).  Saving model ...
Validation loss decreased (0.977028 --> 0.973431).  Saving model ...
Validation loss decreased (0.973431 --> 0.971405).  Saving model ...
Validation loss decreased (0.971405 --> 0.970831).  Saving model ...
Validation loss decreased (0.970831 --> 0.969924).  Saving model ...
Validation loss decreased (0.969924 --> 0.966891).  Saving model ...
Validation loss decreased (0.966891 --> 0.963666).  Saving model ...
EarlyStopping counter: 1 out of 5.0
EarlyStopping counter: 2 out of 5.0
EarlyStopping counter: 3 out of 5.0
EarlyStopping counter: 4 out of 5.0
Validation loss decreased (0.963666 --> 0.963340).  Saving model ...
Validation loss decreased (0.963340 --> 0.962103).  Saving model ...
Validation loss decreased (0.962103 --> 0.960381).  Saving model ...
Validation loss decreased (0.960381 --> 0.960233).  Saving model ...
Validation loss decreased (0.960233 --> 0.958990).  Saving model ...
Validation loss decreased (0.958990 --> 0.957765).  Saving model ...
Validation loss decreased (0.957765 --> 0.957674).  Saving model ...
EarlyStopping counter: 1 out of 5.0
EarlyStopping counter: 2 out of 5.0
Validation loss decreased (0.957674 --> 0.956705).  Saving model ...
Validation loss decreased (0.956705 --> 0.956457).  Saving model ...
EarlyStopping counter: 1 out of 5.0
EarlyStopping counter: 2 out of 5.0
EarlyStopping counter: 3 out of 5.0
Validation loss decreased (0.956457 --> 0.954668).  Saving model ...
EarlyStopping counter: 1 out of 5.0
EarlyStopping counter: 2 out of 5.0
EarlyStopping counter: 3 out of 5.0
EarlyStopping counter: 4 out of 5.0
Validation loss decreased (0.954668 --> 0.953761).  Saving model ...
EarlyStopping counter: 1 out of 5.0
EarlyStopping counter: 2 out of 5.0
EarlyStopping counter: 3 out of 5.0
EarlyStopping counter: 4 out of 5.0
EarlyStopping counter: 5 out of 5.0
/localscratch/yinan.29163121.0/env/lib/python3.7/site-packages/torch/nn/functional.py:1794: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.
  warnings.warn("nn.functional.tanh is deprecated. Use torch.tanh instead.")
wandb: Waiting for W&B process to finish, PID 230450... (success).
wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: \ 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: | 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: / 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: \ 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: | 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: / 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: \ 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: | 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: / 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb:                                                                                
wandb: Run history:
wandb:     e_F1 ▁▂▅▅▅▅▅▆▆▆▆▇▇▇▇▇▇▇██████████████████████
wandb:   e_loss █▇▆▆▆▆▅▅▅▄▄▄▄▃▃▃▃▃▂▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:     t_F1 ▁▁▂▃▃▄▄▄▅▅▅▅▅▅▅▆▆▆▆▇▇▇▇▇▇▇▇▇▇▇▇█▇▇▇▇████
wandb:   t_loss ██▇▇▆▆▆▆▆▅▅▅▅▄▄▄▄▄▃▃▃▃▃▃▂▂▂▂▂▂▂▂▂▂▂▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:     e_F1 58.61519
wandb:   e_loss 0.95754
wandb:     t_F1 66.77789
wandb:   t_loss 0.76792
wandb: 
wandb: Synced 4 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Synced morning-capybara-2: https://wandb.ai/yinanazhou/xl_512_bs_8_lr_1e06_es_5_lc_False_nr_False_sr_True_stem_False_lemma_False_repeat_4_fold_1/runs/1pfqqlce
wandb: Find logs at: ./wandb/run-20220318_061259-1pfqqlce/logs/debug.log
wandb: 

wandb: wandb version 0.12.11 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
2022-03-18 07:37:30.827796: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1
wandb: Tracking run with wandb version 0.12.5
wandb: Syncing run smooth-rain-2
wandb: ⭐️ View project at https://wandb.ai/yinanazhou/xl_512_bs_8_lr_1e06_es_5_lc_False_nr_False_sr_True_stem_False_lemma_False_repeat_4_fold_2
wandb: 🚀 View run at https://wandb.ai/yinanazhou/xl_512_bs_8_lr_1e06_es_5_lc_False_nr_False_sr_True_stem_False_lemma_False_repeat_4_fold_2/runs/3nv6rpy5
wandb: Run data is saved locally in /project/6002780/yinan/Thesis_MER_Lyrics/lyric-emotion/wandb/run-20220318_073727-3nv6rpy5
wandb: Run `wandb offline` to turn off syncing.

Validation loss decreased (inf --> 1.399216).  Saving model ...
Validation loss decreased (1.399216 --> 1.386116).  Saving model ...
Validation loss decreased (1.386116 --> 1.375879).  Saving model ...
Validation loss decreased (1.375879 --> 1.367501).  Saving model ...
Validation loss decreased (1.367501 --> 1.360972).  Saving model ...
Validation loss decreased (1.360972 --> 1.355287).  Saving model ...
Validation loss decreased (1.355287 --> 1.349841).  Saving model ...
Validation loss decreased (1.349841 --> 1.345027).  Saving model ...
Validation loss decreased (1.345027 --> 1.339550).  Saving model ...
Validation loss decreased (1.339550 --> 1.334862).  Saving model ...
Validation loss decreased (1.334862 --> 1.329687).  Saving model ...
Validation loss decreased (1.329687 --> 1.324637).  Saving model ...
Validation loss decreased (1.324637 --> 1.319111).  Saving model ...
Validation loss decreased (1.319111 --> 1.313933).  Saving model ...
Validation loss decreased (1.313933 --> 1.307801).  Saving model ...
Validation loss decreased (1.307801 --> 1.301482).  Saving model ...
Validation loss decreased (1.301482 --> 1.295707).  Saving model ...
Validation loss decreased (1.295707 --> 1.289548).  Saving model ...
Validation loss decreased (1.289548 --> 1.282989).  Saving model ...
Validation loss decreased (1.282989 --> 1.276729).  Saving model ...
Validation loss decreased (1.276729 --> 1.269338).  Saving model ...
Validation loss decreased (1.269338 --> 1.260796).  Saving model ...
Validation loss decreased (1.260796 --> 1.251636).  Saving model ...
Validation loss decreased (1.251636 --> 1.242079).  Saving model ...
Validation loss decreased (1.242079 --> 1.233025).  Saving model ...
Validation loss decreased (1.233025 --> 1.224342).  Saving model ...
Validation loss decreased (1.224342 --> 1.215152).  Saving model ...
Validation loss decreased (1.215152 --> 1.205390).  Saving model ...
Validation loss decreased (1.205390 --> 1.195761).  Saving model ...
Validation loss decreased (1.195761 --> 1.185722).  Saving model ...
Validation loss decreased (1.185722 --> 1.176762).  Saving model ...
Validation loss decreased (1.176762 --> 1.167526).  Saving model ...
Validation loss decreased (1.167526 --> 1.161542).  Saving model ...
Validation loss decreased (1.161542 --> 1.152325).  Saving model ...
Validation loss decreased (1.152325 --> 1.145777).  Saving model ...
Validation loss decreased (1.145777 --> 1.138810).  Saving model ...
Validation loss decreased (1.138810 --> 1.132537).  Saving model ...
Validation loss decreased (1.132537 --> 1.124987).  Saving model ...
Validation loss decreased (1.124987 --> 1.118974).  Saving model ...
Validation loss decreased (1.118974 --> 1.112477).  Saving model ...
Validation loss decreased (1.112477 --> 1.106156).  Saving model ...
Validation loss decreased (1.106156 --> 1.100212).  Saving model ...
Validation loss decreased (1.100212 --> 1.094738).  Saving model ...
Validation loss decreased (1.094738 --> 1.091405).  Saving model ...
Validation loss decreased (1.091405 --> 1.087448).  Saving model ...
Validation loss decreased (1.087448 --> 1.081912).  Saving model ...
Validation loss decreased (1.081912 --> 1.077274).  Saving model ...
Validation loss decreased (1.077274 --> 1.072064).  Saving model ...
Validation loss decreased (1.072064 --> 1.066834).  Saving model ...
Validation loss decreased (1.066834 --> 1.063126).  Saving model ...
Validation loss decreased (1.063126 --> 1.058094).  Saving model ...
Validation loss decreased (1.058094 --> 1.051841).  Saving model ...
Validation loss decreased (1.051841 --> 1.047662).  Saving model ...
Validation loss decreased (1.047662 --> 1.041949).  Saving model ...
Validation loss decreased (1.041949 --> 1.037506).  Saving model ...
Validation loss decreased (1.037506 --> 1.034714).  Saving model ...
Validation loss decreased (1.034714 --> 1.030880).  Saving model ...
Validation loss decreased (1.030880 --> 1.029402).  Saving model ...
Validation loss decreased (1.029402 --> 1.025990).  Saving model ...
Validation loss decreased (1.025990 --> 1.023312).  Saving model ...
Validation loss decreased (1.023312 --> 1.018925).  Saving model ...
Validation loss decreased (1.018925 --> 1.014535).  Saving model ...
Validation loss decreased (1.014535 --> 1.009589).  Saving model ...
Validation loss decreased (1.009589 --> 1.006514).  Saving model ...
Validation loss decreased (1.006514 --> 1.003806).  Saving model ...
Validation loss decreased (1.003806 --> 0.999639).  Saving model ...
Validation loss decreased (0.999639 --> 0.998108).  Saving model ...
Validation loss decreased (0.998108 --> 0.994492).  Saving model ...
Validation loss decreased (0.994492 --> 0.991087).  Saving model ...
Validation loss decreased (0.991087 --> 0.989064).  Saving model ...
Validation loss decreased (0.989064 --> 0.987011).  Saving model ...
Validation loss decreased (0.987011 --> 0.984555).  Saving model ...
Validation loss decreased (0.984555 --> 0.982826).  Saving model ...
Validation loss decreased (0.982826 --> 0.981045).  Saving model ...
Validation loss decreased (0.981045 --> 0.976743).  Saving model ...
Validation loss decreased (0.976743 --> 0.975991).  Saving model ...
Validation loss decreased (0.975991 --> 0.973248).  Saving model ...
Validation loss decreased (0.973248 --> 0.967353).  Saving model ...
Validation loss decreased (0.967353 --> 0.965780).  Saving model ...
EarlyStopping counter: 1 out of 5.0
Validation loss decreased (0.965780 --> 0.964524).  Saving model ...
EarlyStopping counter: 1 out of 5.0
Validation loss decreased (0.964524 --> 0.960925).  Saving model ...
Validation loss decreased (0.960925 --> 0.958853).  Saving model ...
EarlyStopping counter: 1 out of 5.0
EarlyStopping counter: 2 out of 5.0
Validation loss decreased (0.958853 --> 0.956993).  Saving model ...
Validation loss decreased (0.956993 --> 0.955760).  Saving model ...
Validation loss decreased (0.955760 --> 0.955166).  Saving model ...
EarlyStopping counter: 1 out of 5.0
Validation loss decreased (0.955166 --> 0.953689).  Saving model ...
Validation loss decreased (0.953689 --> 0.952545).  Saving model ...
Validation loss decreased (0.952545 --> 0.952161).  Saving model ...
EarlyStopping counter: 1 out of 5.0
Validation loss decreased (0.952161 --> 0.949448).  Saving model ...
EarlyStopping counter: 1 out of 5.0
Validation loss decreased (0.949448 --> 0.948256).  Saving model ...
EarlyStopping counter: 1 out of 5.0
Validation loss decreased (0.948256 --> 0.947225).  Saving model ...
Validation loss decreased (0.947225 --> 0.946385).  Saving model ...
Validation loss decreased (0.946385 --> 0.942755).  Saving model ...
EarlyStopping counter: 1 out of 5.0
EarlyStopping counter: 2 out of 5.0
EarlyStopping counter: 3 out of 5.0
Validation loss decreased (0.942755 --> 0.941064).  Saving model ...
EarlyStopping counter: 1 out of 5.0
EarlyStopping counter: 2 out of 5.0
EarlyStopping counter: 3 out of 5.0
EarlyStopping counter: 4 out of 5.0
EarlyStopping counter: 5 out of 5.0
/localscratch/yinan.29163121.0/env/lib/python3.7/site-packages/torch/nn/functional.py:1794: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.
  warnings.warn("nn.functional.tanh is deprecated. Use torch.tanh instead.")
wandb: Waiting for W&B process to finish, PID 234951... (success).
wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: \ 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: | 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: / 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: \ 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: | 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: / 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: \ 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: | 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: / 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb:                                                                                
wandb: Run history:
wandb:     e_F1 ▁▂▄▄▄▅▅▅▅▆▆▆▆▆▆▇▇▇▇▇▇▇▇▇▇███████████████
wandb:   e_loss ██▇▇▇▇▆▆▆▅▅▅▄▄▄▃▃▃▃▃▂▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁
wandb:     t_F1 ▁▂▂▃▃▃▃▄▄▄▅▅▅▅▆▅▆▆▆▇▆▆▇▇▇▇▇▇▇▇█▇▇▇▇▇▇▇▇█
wandb:   t_loss ██▇▇▇▇▇▆▆▆▆▅▅▅▅▅▅▄▄▄▄▄▃▃▃▃▃▂▃▂▂▂▂▂▂▂▂▂▁▁
wandb: 
wandb: Run summary:
wandb:     e_F1 63.15155
wandb:   e_loss 0.94469
wandb:     t_F1 71.53434
wandb:   t_loss 0.78182
wandb: 
wandb: Synced 4 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Synced smooth-rain-2: https://wandb.ai/yinanazhou/xl_512_bs_8_lr_1e06_es_5_lc_False_nr_False_sr_True_stem_False_lemma_False_repeat_4_fold_2/runs/3nv6rpy5
wandb: Find logs at: ./wandb/run-20220318_073727-3nv6rpy5/logs/debug.log
wandb: 

wandb: wandb version 0.12.11 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
2022-03-18 08:49:41.711072: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1
wandb: Tracking run with wandb version 0.12.5
wandb: Syncing run genial-forest-2
wandb: ⭐️ View project at https://wandb.ai/yinanazhou/xl_512_bs_8_lr_1e06_es_5_lc_False_nr_False_sr_True_stem_False_lemma_False_repeat_5_fold_1
wandb: 🚀 View run at https://wandb.ai/yinanazhou/xl_512_bs_8_lr_1e06_es_5_lc_False_nr_False_sr_True_stem_False_lemma_False_repeat_5_fold_1/runs/3p6etp9s
wandb: Run data is saved locally in /project/6002780/yinan/Thesis_MER_Lyrics/lyric-emotion/wandb/run-20220318_084938-3p6etp9s
wandb: Run `wandb offline` to turn off syncing.

Validation loss decreased (inf --> 1.416742).  Saving model ...
Validation loss decreased (1.416742 --> 1.396754).  Saving model ...
Validation loss decreased (1.396754 --> 1.383026).  Saving model ...
Validation loss decreased (1.383026 --> 1.373010).  Saving model ...
Validation loss decreased (1.373010 --> 1.365156).  Saving model ...
Validation loss decreased (1.365156 --> 1.358839).  Saving model ...
Validation loss decreased (1.358839 --> 1.354279).  Saving model ...
Validation loss decreased (1.354279 --> 1.349199).  Saving model ...
Validation loss decreased (1.349199 --> 1.344528).  Saving model ...
Validation loss decreased (1.344528 --> 1.339861).  Saving model ...
Validation loss decreased (1.339861 --> 1.334693).  Saving model ...
Validation loss decreased (1.334693 --> 1.329831).  Saving model ...
Validation loss decreased (1.329831 --> 1.324513).  Saving model ...
Validation loss decreased (1.324513 --> 1.319001).  Saving model ...
Validation loss decreased (1.319001 --> 1.312957).  Saving model ...
Validation loss decreased (1.312957 --> 1.306899).  Saving model ...
Validation loss decreased (1.306899 --> 1.301598).  Saving model ...
Validation loss decreased (1.301598 --> 1.294540).  Saving model ...
Validation loss decreased (1.294540 --> 1.287060).  Saving model ...
Validation loss decreased (1.287060 --> 1.279269).  Saving model ...
Validation loss decreased (1.279269 --> 1.270138).  Saving model ...
Validation loss decreased (1.270138 --> 1.262193).  Saving model ...
Validation loss decreased (1.262193 --> 1.253996).  Saving model ...
Validation loss decreased (1.253996 --> 1.247031).  Saving model ...
Validation loss decreased (1.247031 --> 1.239579).  Saving model ...
Validation loss decreased (1.239579 --> 1.230611).  Saving model ...
Validation loss decreased (1.230611 --> 1.222057).  Saving model ...
Validation loss decreased (1.222057 --> 1.214572).  Saving model ...
Validation loss decreased (1.214572 --> 1.208226).  Saving model ...
Validation loss decreased (1.208226 --> 1.199868).  Saving model ...
Validation loss decreased (1.199868 --> 1.192401).  Saving model ...
Validation loss decreased (1.192401 --> 1.185878).  Saving model ...
Validation loss decreased (1.185878 --> 1.178106).  Saving model ...
Validation loss decreased (1.178106 --> 1.170871).  Saving model ...
Validation loss decreased (1.170871 --> 1.164657).  Saving model ...
Validation loss decreased (1.164657 --> 1.158233).  Saving model ...
Validation loss decreased (1.158233 --> 1.150865).  Saving model ...
Validation loss decreased (1.150865 --> 1.144602).  Saving model ...
Validation loss decreased (1.144602 --> 1.139856).  Saving model ...
Validation loss decreased (1.139856 --> 1.133483).  Saving model ...
Validation loss decreased (1.133483 --> 1.127246).  Saving model ...
Validation loss decreased (1.127246 --> 1.121874).  Saving model ...
Validation loss decreased (1.121874 --> 1.118047).  Saving model ...
Validation loss decreased (1.118047 --> 1.115347).  Saving model ...
Validation loss decreased (1.115347 --> 1.110719).  Saving model ...
Validation loss decreased (1.110719 --> 1.104129).  Saving model ...
Validation loss decreased (1.104129 --> 1.093703).  Saving model ...
Validation loss decreased (1.093703 --> 1.090163).  Saving model ...
Validation loss decreased (1.090163 --> 1.083554).  Saving model ...
Validation loss decreased (1.083554 --> 1.079528).  Saving model ...
Validation loss decreased (1.079528 --> 1.076101).  Saving model ...
Validation loss decreased (1.076101 --> 1.072146).  Saving model ...
Validation loss decreased (1.072146 --> 1.067295).  Saving model ...
Validation loss decreased (1.067295 --> 1.063130).  Saving model ...
Validation loss decreased (1.063130 --> 1.059693).  Saving model ...
Validation loss decreased (1.059693 --> 1.055555).  Saving model ...
Validation loss decreased (1.055555 --> 1.051534).  Saving model ...
Validation loss decreased (1.051534 --> 1.047980).  Saving model ...
Validation loss decreased (1.047980 --> 1.044189).  Saving model ...
Validation loss decreased (1.044189 --> 1.040860).  Saving model ...
Validation loss decreased (1.040860 --> 1.038326).  Saving model ...
Validation loss decreased (1.038326 --> 1.033130).  Saving model ...
Validation loss decreased (1.033130 --> 1.027081).  Saving model ...
Validation loss decreased (1.027081 --> 1.024580).  Saving model ...
Validation loss decreased (1.024580 --> 1.021274).  Saving model ...
Validation loss decreased (1.021274 --> 1.017792).  Saving model ...
Validation loss decreased (1.017792 --> 1.014008).  Saving model ...
Validation loss decreased (1.014008 --> 1.010425).  Saving model ...
Validation loss decreased (1.010425 --> 1.007301).  Saving model ...
Validation loss decreased (1.007301 --> 1.004173).  Saving model ...
Validation loss decreased (1.004173 --> 1.000120).  Saving model ...
Validation loss decreased (1.000120 --> 0.997589).  Saving model ...
EarlyStopping counter: 1 out of 5.0
Validation loss decreased (0.997589 --> 0.993383).  Saving model ...
Validation loss decreased (0.993383 --> 0.992285).  Saving model ...
Validation loss decreased (0.992285 --> 0.989237).  Saving model ...
Validation loss decreased (0.989237 --> 0.987704).  Saving model ...
Validation loss decreased (0.987704 --> 0.983749).  Saving model ...
EarlyStopping counter: 1 out of 5.0
Validation loss decreased (0.983749 --> 0.980967).  Saving model ...
Validation loss decreased (0.980967 --> 0.977600).  Saving model ...
Validation loss decreased (0.977600 --> 0.973471).  Saving model ...
Validation loss decreased (0.973471 --> 0.969434).  Saving model ...
Validation loss decreased (0.969434 --> 0.967712).  Saving model ...
Validation loss decreased (0.967712 --> 0.965853).  Saving model ...
EarlyStopping counter: 1 out of 5.0
Validation loss decreased (0.965853 --> 0.964610).  Saving model ...
Validation loss decreased (0.964610 --> 0.960144).  Saving model ...
EarlyStopping counter: 1 out of 5.0
EarlyStopping counter: 2 out of 5.0
Validation loss decreased (0.960144 --> 0.958614).  Saving model ...
Validation loss decreased (0.958614 --> 0.957275).  Saving model ...
Validation loss decreased (0.957275 --> 0.952356).  Saving model ...
Validation loss decreased (0.952356 --> 0.949290).  Saving model ...
Validation loss decreased (0.949290 --> 0.948389).  Saving model ...
EarlyStopping counter: 1 out of 5.0
Validation loss decreased (0.948389 --> 0.944048).  Saving model ...
Validation loss decreased (0.944048 --> 0.944046).  Saving model ...
EarlyStopping counter: 1 out of 5.0
EarlyStopping counter: 2 out of 5.0
Validation loss decreased (0.944046 --> 0.941602).  Saving model ...
Validation loss decreased (0.941602 --> 0.938668).  Saving model ...
EarlyStopping counter: 1 out of 5.0
Validation loss decreased (0.938668 --> 0.936866).  Saving model ...
Validation loss decreased (0.936866 --> 0.934196).  Saving model ...
EarlyStopping counter: 1 out of 5.0
EarlyStopping counter: 2 out of 5.0
Validation loss decreased (0.934196 --> 0.933776).  Saving model ...
Validation loss decreased (0.933776 --> 0.932389).  Saving model ...
EarlyStopping counter: 1 out of 5.0
EarlyStopping counter: 2 out of 5.0
Validation loss decreased (0.932389 --> 0.931412).  Saving model ...
Validation loss decreased (0.931412 --> 0.929754).  Saving model ...
Validation loss decreased (0.929754 --> 0.927305).  Saving model ...
EarlyStopping counter: 1 out of 5.0
EarlyStopping counter: 2 out of 5.0
Validation loss decreased (0.927305 --> 0.926391).  Saving model ...
EarlyStopping counter: 1 out of 5.0
Validation loss decreased (0.926391 --> 0.925758).  Saving model ...
EarlyStopping counter: 1 out of 5.0
Validation loss decreased (0.925758 --> 0.925710).  Saving model ...
Validation loss decreased (0.925710 --> 0.922510).  Saving model ...
EarlyStopping counter: 1 out of 5.0
EarlyStopping counter: 2 out of 5.0
EarlyStopping counter: 3 out of 5.0
EarlyStopping counter: 4 out of 5.0
EarlyStopping counter: 5 out of 5.0
/localscratch/yinan.29163121.0/env/lib/python3.7/site-packages/torch/nn/functional.py:1794: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.
  warnings.warn("nn.functional.tanh is deprecated. Use torch.tanh instead.")
wandb: Waiting for W&B process to finish, PID 238820... (success).
wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: \ 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: | 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: / 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: \ 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: | 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: / 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: \ 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: | 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb:                                                                                
wandb: Run history:
wandb:     e_F1 ▁▃▄▄▄▄▄▅▅▆▆▆▆▆▆▇▇▇▇▇▇▇▇▇▇▇██████████████
wandb:   e_loss █▇▇▇▇▆▆▆▅▅▅▄▄▄▄▃▃▃▃▃▂▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁
wandb:     t_F1 ▁▂▃▃▄▄▄▄▅▅▅▅▅▆▆▆▆▆▆▆▇▆▇▇▆▇▇▆▇▇▇▇▇█▇▇▇▇██
wandb:   t_loss ██▇▇▇▇▇▆▆▆▆▅▅▅▅▄▄▄▄▄▄▄▃▃▃▃▃▃▂▂▂▂▂▂▂▂▁▂▁▁
wandb: 
wandb: Run summary:
wandb:     e_F1 60.50317
wandb:   e_loss 0.92862
wandb:     t_F1 74.56804
wandb:   t_loss 0.72757
wandb: 
wandb: Synced 4 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Synced genial-forest-2: https://wandb.ai/yinanazhou/xl_512_bs_8_lr_1e06_es_5_lc_False_nr_False_sr_True_stem_False_lemma_False_repeat_5_fold_1/runs/3p6etp9s
wandb: Find logs at: ./wandb/run-20220318_084938-3p6etp9s/logs/debug.log
wandb: 

wandb: wandb version 0.12.11 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
2022-03-18 10:12:52.812698: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1
wandb: Tracking run with wandb version 0.12.5
wandb: Syncing run devout-energy-2
wandb: ⭐️ View project at https://wandb.ai/yinanazhou/xl_512_bs_8_lr_1e06_es_5_lc_False_nr_False_sr_True_stem_False_lemma_False_repeat_5_fold_2
wandb: 🚀 View run at https://wandb.ai/yinanazhou/xl_512_bs_8_lr_1e06_es_5_lc_False_nr_False_sr_True_stem_False_lemma_False_repeat_5_fold_2/runs/2nqh25pd
wandb: Run data is saved locally in /project/6002780/yinan/Thesis_MER_Lyrics/lyric-emotion/wandb/run-20220318_101249-2nqh25pd
wandb: Run `wandb offline` to turn off syncing.

Validation loss decreased (inf --> 1.383214).  Saving model ...
Validation loss decreased (1.383214 --> 1.377284).  Saving model ...
Validation loss decreased (1.377284 --> 1.372312).  Saving model ...
Validation loss decreased (1.372312 --> 1.367220).  Saving model ...
Validation loss decreased (1.367220 --> 1.362592).  Saving model ...
Validation loss decreased (1.362592 --> 1.358177).  Saving model ...
Validation loss decreased (1.358177 --> 1.353319).  Saving model ...
Validation loss decreased (1.353319 --> 1.348722).  Saving model ...
Validation loss decreased (1.348722 --> 1.343967).  Saving model ...
Validation loss decreased (1.343967 --> 1.339485).  Saving model ...
Validation loss decreased (1.339485 --> 1.334500).  Saving model ...
Validation loss decreased (1.334500 --> 1.329163).  Saving model ...
Validation loss decreased (1.329163 --> 1.324494).  Saving model ...
Validation loss decreased (1.324494 --> 1.319023).  Saving model ...
Validation loss decreased (1.319023 --> 1.313559).  Saving model ...
Validation loss decreased (1.313559 --> 1.308136).  Saving model ...
Validation loss decreased (1.308136 --> 1.301828).  Saving model ...
Validation loss decreased (1.301828 --> 1.295579).  Saving model ...
Validation loss decreased (1.295579 --> 1.289365).  Saving model ...
Validation loss decreased (1.289365 --> 1.282343).  Saving model ...
Validation loss decreased (1.282343 --> 1.274955).  Saving model ...
Validation loss decreased (1.274955 --> 1.266987).  Saving model ...
Validation loss decreased (1.266987 --> 1.258747).  Saving model ...
Validation loss decreased (1.258747 --> 1.251151).  Saving model ...
Validation loss decreased (1.251151 --> 1.242872).  Saving model ...
Validation loss decreased (1.242872 --> 1.234582).  Saving model ...
Validation loss decreased (1.234582 --> 1.226365).  Saving model ...
Validation loss decreased (1.226365 --> 1.217781).  Saving model ...
Validation loss decreased (1.217781 --> 1.208939).  Saving model ...
Validation loss decreased (1.208939 --> 1.200451).  Saving model ...
Validation loss decreased (1.200451 --> 1.192458).  Saving model ...
Validation loss decreased (1.192458 --> 1.183570).  Saving model ...
Validation loss decreased (1.183570 --> 1.174875).  Saving model ...
Validation loss decreased (1.174875 --> 1.165031).  Saving model ...
Validation loss decreased (1.165031 --> 1.156342).  Saving model ...
Validation loss decreased (1.156342 --> 1.146581).  Saving model ...
Validation loss decreased (1.146581 --> 1.138939).  Saving model ...
Validation loss decreased (1.138939 --> 1.131199).  Saving model ...
Validation loss decreased (1.131199 --> 1.120972).  Saving model ...
Validation loss decreased (1.120972 --> 1.111988).  Saving model ...
Validation loss decreased (1.111988 --> 1.102729).  Saving model ...
Validation loss decreased (1.102729 --> 1.094408).  Saving model ...
Validation loss decreased (1.094408 --> 1.088302).  Saving model ...
Validation loss decreased (1.088302 --> 1.080752).  Saving model ...
Validation loss decreased (1.080752 --> 1.075056).  Saving model ...
Validation loss decreased (1.075056 --> 1.069380).  Saving model ...
Validation loss decreased (1.069380 --> 1.061485).  Saving model ...
Validation loss decreased (1.061485 --> 1.054460).  Saving model ...
Validation loss decreased (1.054460 --> 1.049960).  Saving model ...
Validation loss decreased (1.049960 --> 1.044022).  Saving model ...
Validation loss decreased (1.044022 --> 1.038592).  Saving model ...
Validation loss decreased (1.038592 --> 1.033257).  Saving model ...
Validation loss decreased (1.033257 --> 1.029087).  Saving model ...
Validation loss decreased (1.029087 --> 1.025724).  Saving model ...
Validation loss decreased (1.025724 --> 1.019238).  Saving model ...
Validation loss decreased (1.019238 --> 1.014494).  Saving model ...
Validation loss decreased (1.014494 --> 1.012532).  Saving model ...
Validation loss decreased (1.012532 --> 1.008174).  Saving model ...
Validation loss decreased (1.008174 --> 1.004706).  Saving model ...
Validation loss decreased (1.004706 --> 1.000643).  Saving model ...
Validation loss decreased (1.000643 --> 0.997651).  Saving model ...
Validation loss decreased (0.997651 --> 0.993375).  Saving model ...
Validation loss decreased (0.993375 --> 0.988357).  Saving model ...
Validation loss decreased (0.988357 --> 0.985194).  Saving model ...
Validation loss decreased (0.985194 --> 0.982718).  Saving model ...
Validation loss decreased (0.982718 --> 0.978505).  Saving model ...
Validation loss decreased (0.978505 --> 0.975747).  Saving model ...
Validation loss decreased (0.975747 --> 0.974502).  Saving model ...
Validation loss decreased (0.974502 --> 0.971490).  Saving model ...
Validation loss decreased (0.971490 --> 0.969841).  Saving model ...
Validation loss decreased (0.969841 --> 0.966484).  Saving model ...
Validation loss decreased (0.966484 --> 0.963912).  Saving model ...
Validation loss decreased (0.963912 --> 0.961682).  Saving model ...
Validation loss decreased (0.961682 --> 0.959132).  Saving model ...
Validation loss decreased (0.959132 --> 0.956972).  Saving model ...
Validation loss decreased (0.956972 --> 0.955440).  Saving model ...
Validation loss decreased (0.955440 --> 0.953137).  Saving model ...
Validation loss decreased (0.953137 --> 0.950914).  Saving model ...
Validation loss decreased (0.950914 --> 0.947046).  Saving model ...
Validation loss decreased (0.947046 --> 0.946873).  Saving model ...
Validation loss decreased (0.946873 --> 0.945142).  Saving model ...
Validation loss decreased (0.945142 --> 0.943774).  Saving model ...
EarlyStopping counter: 1 out of 5.0
Validation loss decreased (0.943774 --> 0.941815).  Saving model ...
Validation loss decreased (0.941815 --> 0.938964).  Saving model ...
Validation loss decreased (0.938964 --> 0.935922).  Saving model ...
EarlyStopping counter: 1 out of 5.0
Validation loss decreased (0.935922 --> 0.934712).  Saving model ...
EarlyStopping counter: 1 out of 5.0
EarlyStopping counter: 2 out of 5.0
Validation loss decreased (0.934712 --> 0.931846).  Saving model ...
Validation loss decreased (0.931846 --> 0.928828).  Saving model ...
Validation loss decreased (0.928828 --> 0.926382).  Saving model ...
EarlyStopping counter: 1 out of 5.0
Validation loss decreased (0.926382 --> 0.922626).  Saving model ...
EarlyStopping counter: 1 out of 5.0
Validation loss decreased (0.922626 --> 0.922265).  Saving model ...
Validation loss decreased (0.922265 --> 0.920305).  Saving model ...
Validation loss decreased (0.920305 --> 0.919827).  Saving model ...
Validation loss decreased (0.919827 --> 0.919434).  Saving model ...
EarlyStopping counter: 1 out of 5.0
Validation loss decreased (0.919434 --> 0.918053).  Saving model ...
Validation loss decreased (0.918053 --> 0.914093).  Saving model ...
EarlyStopping counter: 1 out of 5.0
EarlyStopping counter: 2 out of 5.0
Validation loss decreased (0.914093 --> 0.913948).  Saving model ...
Validation loss decreased (0.913948 --> 0.911161).  Saving model ...
EarlyStopping counter: 1 out of 5.0
Validation loss decreased (0.911161 --> 0.910228).  Saving model ...
Validation loss decreased (0.910228 --> 0.910208).  Saving model ...
Validation loss decreased (0.910208 --> 0.909456).  Saving model ...
EarlyStopping counter: 1 out of 5.0
EarlyStopping counter: 2 out of 5.0
EarlyStopping counter: 3 out of 5.0
EarlyStopping counter: 4 out of 5.0
EarlyStopping counter: 5 out of 5.0
/localscratch/yinan.29163121.0/env/lib/python3.7/site-packages/torch/nn/functional.py:1794: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.
  warnings.warn("nn.functional.tanh is deprecated. Use torch.tanh instead.")
wandb: Waiting for W&B process to finish, PID 243290... (success).
wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: \ 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: | 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: / 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: \ 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: | 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: / 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: \ 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: | 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: / 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb:                                                                                
wandb: Run history:
wandb:     e_F1 ▁▂▃▃▄▄▅▅▆▆▆▆▇▇▇▇▇▇▇▇▇▇▇▇▇▇████▇█████████
wandb:   e_loss ███▇▇▇▇▆▆▆▅▅▄▄▄▃▃▃▃▃▂▂▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁
wandb:     t_F1 ▁▂▂▂▃▃▃▃▄▅▅▅▅▆▆▆▆▆▆▇▆▆▇▆▇▇▇▇▇▇▇▇▇██▇██▇█
wandb:   t_loss ███▇▇▇▇▇▇▆▆▆▅▅▅▄▄▄▄▄▄▃▃▃▃▃▃▃▃▂▂▂▂▂▂▂▁▁▁▁
wandb: 
wandb: Run summary:
wandb:     e_F1 63.23006
wandb:   e_loss 0.91215
wandb:     t_F1 70.22095
wandb:   t_loss 0.79146
wandb: 
wandb: Synced 4 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Synced devout-energy-2: https://wandb.ai/yinanazhou/xl_512_bs_8_lr_1e06_es_5_lc_False_nr_False_sr_True_stem_False_lemma_False_repeat_5_fold_2/runs/2nqh25pd
wandb: Find logs at: ./wandb/run-20220318_101249-2nqh25pd/logs/debug.log
wandb: 

